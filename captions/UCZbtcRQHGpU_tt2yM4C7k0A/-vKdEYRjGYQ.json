[
  {
    "text": "[Music] you're listening to JS party a weekly",
    "start": "3930",
    "end": "9880"
  },
  {
    "text": "celebration of JavaScript and the web find us on the web at JSP party. FM on",
    "start": "9880",
    "end": "16680"
  },
  {
    "text": "the fediverse at JS party at Chang log. social and of course wherever you get",
    "start": "16680",
    "end": "22199"
  },
  {
    "text": "your podcasts just search for JS party you'll find us thanks to our partners at fly launch your app near your users for",
    "start": "22199",
    "end": "30080"
  },
  {
    "text": "Peak Performance fly makes it easy learn more at fly.io okay hey it's party time",
    "start": "30080",
    "end": "37900"
  },
  {
    "text": "[Music] [Applause]",
    "start": "37900",
    "end": "43380"
  },
  {
    "text": "[Applause] [Music] [Applause]",
    "start": "48010",
    "end": "53070"
  },
  {
    "text": "y'all hello JS party people I'm kall I'm your host today and I am doing another",
    "start": "55000",
    "end": "61359"
  },
  {
    "text": "one of these fun deep dive interviews I'm joined today with Tes Kumar tus how",
    "start": "61359",
    "end": "67360"
  },
  {
    "text": "you doing man hey it's good to be here I'm doing well thanks thanks I am excited to have you on I think we had",
    "start": "67360",
    "end": "72799"
  },
  {
    "text": "you on the show once before maybe a year or two ago and we got deep into like The",
    "start": "72799",
    "end": "77960"
  },
  {
    "text": "Vibes and like how to have good energy and succeed today we're doing a more focused technical topic you have been",
    "start": "77960",
    "end": "85119"
  },
  {
    "text": "getting really into a topic that's interesting to me which is AI or llm agents um and doing it in JavaScript",
    "start": "85119",
    "end": "91680"
  },
  {
    "text": "which is different than what I've been doing it in so I really excited to get into there but let's maybe kind of start give our listeners a little bit of a",
    "start": "91680",
    "end": "97880"
  },
  {
    "text": "background if they didn't listen to that old episode who you are how you got into this stuff um and it feels like a bit of",
    "start": "97880",
    "end": "103399"
  },
  {
    "text": "a shift from where you started so yeah kind of curious how you got here yeah",
    "start": "103399",
    "end": "108439"
  },
  {
    "text": "I'm tagious if you didn't listen to the last episode no no worries I have been a",
    "start": "108439",
    "end": "114119"
  },
  {
    "text": "web engineer for most of my life I got into it as a kid from from age eight just sort of building things with the",
    "start": "114119",
    "end": "119479"
  },
  {
    "text": "front page Ag and Dream Weaver and had an internship at 15 and I'd say that's where my professional career began and",
    "start": "119479",
    "end": "125920"
  },
  {
    "text": "then you know I'm just sort of been doing that for the past 16 years eventually um you know some people some",
    "start": "125920",
    "end": "132840"
  },
  {
    "text": "leaders um recognized that I had a gift for communication specifically I'm talking about Gia morous from verel who",
    "start": "132840",
    "end": "139480"
  },
  {
    "text": "um asked me to come lead developer relations at at zeit back then for a little while um and that was sort of my",
    "start": "139480",
    "end": "145040"
  },
  {
    "text": "getting into developer relations which was where I was when we did the last um JS party episode I was the director of",
    "start": "145040",
    "end": "150480"
  },
  {
    "text": "developer relations at Zeta which is a serverless database company and there it's run by some great friends and yeah",
    "start": "150480",
    "end": "156360"
  },
  {
    "text": "and and today um as you mentioned I'm doing a lot of AI I I work as a developer relations engineer for",
    "start": "156360",
    "end": "162720"
  },
  {
    "text": "generative AI or gen at at data stacks and what my whole job is to live and breathe gen and understand it as deeply",
    "start": "162720",
    "end": "169800"
  },
  {
    "text": "as I can so I can teach it with as much quality and as much Fidelity as I can um so data STX is heavily focused on rag",
    "start": "169800",
    "end": "178040"
  },
  {
    "text": "that's like bringing real time context into prompts that we send to larger language models and so we help them like",
    "start": "178040",
    "end": "184840"
  },
  {
    "text": "come up to date and hallucinate less but you know there's also the whole other",
    "start": "184840",
    "end": "190360"
  },
  {
    "text": "side of the equation which is agentic workflows which is which is where I've been spending a lot of my sort of",
    "start": "190360",
    "end": "195920"
  },
  {
    "text": "extracurricular time let's say where um you know this technique rag for those listening it stands for retrieval",
    "start": "195920",
    "end": "201760"
  },
  {
    "text": "augmented Generation Um and essentially as a developer you retrieve some data and you give it as a prompt to the llm",
    "start": "201760",
    "end": "208239"
  },
  {
    "text": "and you use it to augment generated output so that's rag but with agentic workflows this changes a little bit",
    "start": "208239",
    "end": "214200"
  },
  {
    "text": "where instead of you the developer doing the retrieval the llm itself can sort of recognize when it's time to call a tool",
    "start": "214200",
    "end": "221799"
  },
  {
    "text": "that's actually just one tenant agent I'm happy to talk about agent workflows and a broader sense but rag initiated by",
    "start": "221799",
    "end": "228080"
  },
  {
    "text": "agents where they themselves retrieve data is is something that I've also been working on so yeah yeah awesome well",
    "start": "228080",
    "end": "233760"
  },
  {
    "text": "yeah let's maybe start with agent because I feel like that is a word that gets thrown around a lot sometimes I",
    "start": "233760",
    "end": "240360"
  },
  {
    "text": "feel like people use agent to mean anything that is I don't understand what it means but it's going to do something for me so how do you define what an",
    "start": "240360",
    "end": "247560"
  },
  {
    "text": "agent is in this sort of new world yeah that's a good question I think I just",
    "start": "247560",
    "end": "252920"
  },
  {
    "text": "follow a number of experts uh definitions of this thing I I I tend not to try and coin terms myself um mainly",
    "start": "252920",
    "end": "259720"
  },
  {
    "text": "because I'm just not very credential if we're being honest but so how do I see agents I summarize it I summate it I'm",
    "start": "259720",
    "end": "266639"
  },
  {
    "text": "trying to find the right word I deduce it from def definitions from industry experts who have gone before me so",
    "start": "266639",
    "end": "272520"
  },
  {
    "text": "people like Andrew ing the founder of corsera now the founder of deeplearning.ai I think he's got some great content about this where he",
    "start": "272520",
    "end": "279800"
  },
  {
    "text": "defines agentic workflows as workflows that have llms perform three tasks",
    "start": "279800",
    "end": "285360"
  },
  {
    "text": "either all three or a subset of them um and those are reflection meaning generate some output and tell and",
    "start": "285360",
    "end": "291039"
  },
  {
    "text": "reflect on it is it good is it not and then like iteratively work on it until it cannot be improved further so there's reflection there's tool calling as I",
    "start": "291039",
    "end": "298199"
  },
  {
    "text": "mentioned with drag where the where the large language model will sort of like a human being right recognize for example",
    "start": "298199",
    "end": "303600"
  },
  {
    "text": "if you ask me to do a complex calculation like 324 divided by 9 * 7 I",
    "start": "303600",
    "end": "309560"
  },
  {
    "text": "I just be like it's time to get a calculator I'll just I'll recognize that this is the sort of boundary of my capabilities and go use a tool so number",
    "start": "309560",
    "end": "316759"
  },
  {
    "text": "two is tool calling um and number three was I I think it was agent collaboration",
    "start": "316759",
    "end": "322680"
  },
  {
    "text": "where you have yeah it's llm as judge it's this model where a capable model",
    "start": "322680",
    "end": "328080"
  },
  {
    "text": "pun intended coordinates lesser capable models towards an outcome you want right so it's like GPD 40 being the most",
    "start": "328080",
    "end": "334080"
  },
  {
    "text": "capable of opening eyes models would orchestrate like three or four different 3.5 turbo models that are doing various",
    "start": "334080",
    "end": "339759"
  },
  {
    "text": "tasks or generations and so those three either one of them or all of them make up according to Andrew Ing and agent",
    "start": "339759",
    "end": "346199"
  },
  {
    "text": "workflow according to David ked the like AI agents are an implementation of the actor model which is just a programming",
    "start": "346199",
    "end": "352880"
  },
  {
    "text": "model where you have an entity called an actor that that sort of Acts in response",
    "start": "352880",
    "end": "358479"
  },
  {
    "text": "to observing its environment so the classic implementation of the actor model is Pac-Man actually a great",
    "start": "358479",
    "end": "364240"
  },
  {
    "text": "example of AI but rule-based AI where the rules are known ahead of time is Pac-Man right where you have Pac-Man the",
    "start": "364240",
    "end": "370280"
  },
  {
    "text": "little yellow Pizza thing and it's observing the environment where the ghosts where the cherries were the dots",
    "start": "370280",
    "end": "376720"
  },
  {
    "text": "and you as the as the player take on the role of the actor right um but there's",
    "start": "376720",
    "end": "381880"
  },
  {
    "text": "also demo mode where the actor model is in play um and according to David kid this implements agentic workflows um",
    "start": "381880",
    "end": "389360"
  },
  {
    "text": "however it's rule based it's not generative but it's still an agentic workflow where Pac-Man is an agent so I",
    "start": "389360",
    "end": "394840"
  },
  {
    "text": "just take a mishmash of those two these are the preeminent leaders in the space in my mind and you know marry them and",
    "start": "394840",
    "end": "400479"
  },
  {
    "text": "that's the working definition that I have for agent so it's not a sentence it's not a nutshell but I'm trying to give you more sort of a broad framework",
    "start": "400479",
    "end": "407160"
  },
  {
    "text": "of how I see agent workflows I have seen this term abused where people will build maybe abused is too strong but people",
    "start": "407160",
    "end": "413759"
  },
  {
    "text": "will build a custom GPT this is a feature you can use um from open eyes GPT 4 and they just build a custom GPT",
    "start": "413759",
    "end": "420560"
  },
  {
    "text": "add a system prompt add some like knowledge that GPT 4 can do rag on and call this an agent I disagree I don't",
    "start": "420560",
    "end": "427360"
  },
  {
    "text": "think that's an agent that's just a rag application it doesn't really do any of the things like we talked about",
    "start": "427360",
    "end": "433080"
  },
  {
    "text": "reflection tool calling collaboration or observing an environment and responding accordingly so I'd say those four",
    "start": "433080",
    "end": "438840"
  },
  {
    "text": "tenants make an agent an agent interesting maybe another way we could take this is like what what would you",
    "start": "438840",
    "end": "444360"
  },
  {
    "text": "use an agent for when is this the right tool to sort of pull out of the tool chest yeah I think you know the term",
    "start": "444360",
    "end": "451400"
  },
  {
    "text": "agent is so cool right because it applies to human beings and we tend to anthropomorphize AI a little bit I'm not",
    "start": "451400",
    "end": "458160"
  },
  {
    "text": "saying it's right or wrong I'm not qualified to make that judgment but I think it's the same when would you use a human agent for what and this this maybe",
    "start": "458160",
    "end": "465199"
  },
  {
    "text": "will trigger some doomers like oh my gosh they're going to take our jobs I think it will take jobs there's no",
    "start": "465199",
    "end": "470319"
  },
  {
    "text": "question about that um and so I I think it's good to be prepared but I would use so for example I have a podcast we",
    "start": "470319",
    "end": "475840"
  },
  {
    "text": "actually use Riverside the application we're using to record this and you know Riverside has some great capabilities",
    "start": "475840",
    "end": "481599"
  },
  {
    "text": "with web hooks as does cal.com which is a really great scheduling tool and so what what we use agents for is to",
    "start": "481599",
    "end": "489440"
  },
  {
    "text": "orchestrate across a variety of web hooks operations that a team of people would do and so my podcast is run",
    "start": "489440",
    "end": "495960"
  },
  {
    "text": "entirely by some AI agents it's not fully automated end to endend but for example like if you know you schedule a",
    "start": "495960",
    "end": "503400"
  },
  {
    "text": "an episode with me depending on which scheduling link you use one is experimental where we experiment and use",
    "start": "503400",
    "end": "509000"
  },
  {
    "text": "the agent workflow and the other one is just manual right so if you schedule with an agent link what will happen is",
    "start": "509000",
    "end": "515240"
  },
  {
    "text": "it will immediately as soon as the event is scheduled will fire off an agentic task to discover you so who is Kevin",
    "start": "515240",
    "end": "522919"
  },
  {
    "text": "Ball what okay this email address on the calendar invite let's go find where it occurs on the internet and okay GitHub",
    "start": "522919",
    "end": "528440"
  },
  {
    "text": "okay Twitter Okay Google and then it's going to um find out things that you're",
    "start": "528440",
    "end": "533839"
  },
  {
    "text": "passionate about the whole point of my podcast contagious code is to take what people are passionate about and make",
    "start": "533839",
    "end": "539320"
  },
  {
    "text": "that that contagious to the listeners and so it will find literally this is the task to that the agent has it finds",
    "start": "539320",
    "end": "544680"
  },
  {
    "text": "what you're passionate about and then we'll construct like a a discussion outline for the length of our discussion",
    "start": "544680",
    "end": "550680"
  },
  {
    "text": "and then upload that to probably GitHub or Google Drive we're still deciding I right now it's gists on GitHub so if you",
    "start": "550680",
    "end": "556200"
  },
  {
    "text": "go on my GitHub gist there's a bunch I'm using my access token so just like they'll make the discussion outlines um and then it will attach that link to the",
    "start": "556200",
    "end": "562720"
  },
  {
    "text": "calendar invite right so then when we come to record we both have the discussion that the job is done after we",
    "start": "562720",
    "end": "568720"
  },
  {
    "text": "record there's similar post-processing steps all of this you know used to be done by people but doesn't need to be",
    "start": "568720",
    "end": "574560"
  },
  {
    "text": "anymore so where would I use agents the same place I would use human agents as as much as I can yeah so are you",
    "start": "574560",
    "end": "580600"
  },
  {
    "text": "building those yourself yeah um I actually I'm building and have well I've built a framework similar to nextjs I've",
    "start": "580600",
    "end": "588160"
  },
  {
    "text": "showed you this off podcast where you know you just Define a bunch of tools",
    "start": "588160",
    "end": "593200"
  },
  {
    "text": "and the large language model will just like a human being will recognize when okay I don't know so for example go find",
    "start": "593200",
    "end": "599079"
  },
  {
    "text": "out what Kevin ball is passionate about if you don't have the right tools the larger language model would be like Hey",
    "start": "599079",
    "end": "605120"
  },
  {
    "text": "listen I I I can't I don't like you go to GPD 3. or it will confidently make something up and it'll be like hey this",
    "start": "605120",
    "end": "612160"
  },
  {
    "text": "person over there I mean for my name in particular it there's a couple famous people with that name and so it would",
    "start": "612160",
    "end": "617720"
  },
  {
    "text": "probably tell me that tell you that I'm a football player or an actor or something like that right which you know",
    "start": "617720",
    "end": "624040"
  },
  {
    "text": "you you may be are but but um exactly and if you go to GPD 3.5 turbo for examp",
    "start": "624040",
    "end": "629360"
  },
  {
    "text": "example it will just say I I don't have the the capacity to browse the internet something like that right but the moment",
    "start": "629360",
    "end": "634720"
  },
  {
    "text": "you introduce these tools it can do that and so it's iterative it's up to the developer in developer land to just",
    "start": "634720",
    "end": "640720"
  },
  {
    "text": "Define a bunch of tools and pray to the AI gods that it will use it how the AI",
    "start": "640720",
    "end": "645880"
  },
  {
    "text": "actually knows when to call the tool is part of its training data and as we know open AI doesn't make any of that public",
    "start": "645880",
    "end": "651160"
  },
  {
    "text": "but meta does and so does mistol so you can just pick your model that you can also and I do run this stuff locally so",
    "start": "651160",
    "end": "657440"
  },
  {
    "text": "it's not in someone's Cloud where they can steal my data since it's really just single user I I run this totally like at",
    "start": "657440",
    "end": "663959"
  },
  {
    "text": "home right I've got AMA I've got mistol 8X 22b which has support for function calling it just it works on a single it",
    "start": "663959",
    "end": "670720"
  },
  {
    "text": "doesn't need to scale because it's not mass market yet so yeah well and so for this audience who's probably well maybe",
    "start": "670720",
    "end": "677839"
  },
  {
    "text": "they're playing with these tools maybe they're not AMA is yeah good good thanks for mentioning AMA so if anyone's",
    "start": "677839",
    "end": "684639"
  },
  {
    "text": "familiar with Docker I suspect they are it's JS party and we've probably built like a no. JS server and dockerized it",
    "start": "684639",
    "end": "690079"
  },
  {
    "text": "um so Docker is a way to run servers and things software in in what are called containers these are abstractions on a",
    "start": "690079",
    "end": "695839"
  },
  {
    "text": "virtual machine so it's just a nice isolated environment the team from Docker a large portion of them quit and",
    "start": "695839",
    "end": "701399"
  },
  {
    "text": "went to start and join a company called AMA and AMA is basically like Docker but for llms like the syntax so you have a",
    "start": "701399",
    "end": "708720"
  },
  {
    "text": "you have a AMA file it's called a model file so like a Docker file it's literally the concept overlap is",
    "start": "708720",
    "end": "714320"
  },
  {
    "text": "incredible like in Docker you have a Docker file with amaama you have a model file and you write syntax that looks",
    "start": "714320",
    "end": "719959"
  },
  {
    "text": "exactly like Docker file right from and then you specify the base model so Mistral 7B and then you can add like a",
    "start": "719959",
    "end": "726519"
  },
  {
    "text": "system prompt you can do a bunch of stuff if you just have a from statement and using the CLI type AMA run it will",
    "start": "726519",
    "end": "732639"
  },
  {
    "text": "run that model locally for you and then you can you know just use it like you would in llm generate me an email ask",
    "start": "732639",
    "end": "738800"
  },
  {
    "text": "questions about whatever it will do it locally on your GPU the cool thing about AMA is it's a centralized effort to be",
    "start": "738800",
    "end": "745959"
  },
  {
    "text": "able to run large language models across a variety of Hardware architectures so it will if you",
    "start": "745959",
    "end": "751560"
  },
  {
    "text": "download it from Mac OS silicon with apple silicon it will just work if you download on Windows it will it's like the docker Principle as well so it's",
    "start": "751560",
    "end": "757839"
  },
  {
    "text": "really cool so you can use AMA to then I also mentioned some models that maybe people aren't exposed to every day gp4",
    "start": "757839",
    "end": "764440"
  },
  {
    "text": "and gp3 and these are the models behind chat GPT um that open AI gives you but",
    "start": "764440",
    "end": "769639"
  },
  {
    "text": "open AI is highly controversial because they are not public nothing is open about this company it's the whole thing",
    "start": "769639",
    "end": "775160"
  },
  {
    "text": "about like you name yourself to cover up your greatest weakness right they they are not open at all yeah you just",
    "start": "775160",
    "end": "781720"
  },
  {
    "text": "called me like rich tages or something cuz I'm really not or something you know and so their weights they're actual",
    "start": "781720",
    "end": "787360"
  },
  {
    "text": "models not open source um the training data not open source They Don't Really publish papers as often as things like",
    "start": "787360",
    "end": "793120"
  },
  {
    "text": "Google brain or um even meta I think meta is doing a tremendous good job a really good job of um being open with",
    "start": "793120",
    "end": "799639"
  },
  {
    "text": "the meta should have a department called open Ai and it'll actually be open and any case maybe you don't want to use those models there's a French company",
    "start": "799639",
    "end": "806399"
  },
  {
    "text": "called mistol I say that proudly as a resident of the the European Union that has a bunch of open- source models these",
    "start": "806399",
    "end": "812560"
  },
  {
    "text": "models are fully open source you can clone them locally you can tweak them you can fine-tune them you can do whatever you want and so what I run is",
    "start": "812560",
    "end": "819079"
  },
  {
    "text": "mistol ax22 this is their largest open source model that has support for function calling and I run that with AMA",
    "start": "819079",
    "end": "826040"
  },
  {
    "text": "so AMA is an inference engine to answer your question in a super long-winded way AMA is a inference engine that you can",
    "start": "826040",
    "end": "831880"
  },
  {
    "text": "run either locally or in the cloud and then you pair that with a a language model and then you basically can build",
    "start": "831880",
    "end": "837519"
  },
  {
    "text": "your own chat GPT awesome so let's come back to your agent framework you showed",
    "start": "837519",
    "end": "842600"
  },
  {
    "text": "me a little bit you said it's like NEX in in JavaScript is that open source can people play with it not yet mainly",
    "start": "842600",
    "end": "849320"
  },
  {
    "text": "because I feel like in my and I may be wrong here but in my mind before I open source something I want to make sure",
    "start": "849320",
    "end": "854800"
  },
  {
    "text": "it's it's already useful but I'm not sure it's clean enough you know it's it's sort of like how you get dressed",
    "start": "854800",
    "end": "860920"
  },
  {
    "text": "before you go out usually ideally hopefully it's not dressed and so not",
    "start": "860920",
    "end": "866920"
  },
  {
    "text": "yet also there's people um friends Sunil P from party kit and David Ked from stle",
    "start": "866920",
    "end": "872639"
  },
  {
    "text": "working on exactly the same thing and there's his open source so David um has stat. aent that's his agent library and",
    "start": "872639",
    "end": "880240"
  },
  {
    "text": "that's fully open source and ready to go I think he's still working on the documentation but it will be soon if not",
    "start": "880240",
    "end": "885920"
  },
  {
    "text": "already done and so if you were starting today would you use stately or would you still build your own no I build my own I",
    "start": "885920",
    "end": "893279"
  },
  {
    "text": "i' I've always built M you know like I I I really don't do you built your own react right that was your famous talk for a while yeah I don't do like npm",
    "start": "893279",
    "end": "900519"
  },
  {
    "text": "create next app I I will like instead what I'll do is npm in it npm install",
    "start": "900519",
    "end": "905560"
  },
  {
    "text": "react react Dom next and I'll like bootstrap everything myself you know because I I sort of like that control I",
    "start": "905560",
    "end": "911320"
  },
  {
    "text": "I think it's sort of like the car enthusiasts who will only drive stick shift even though there's you know some",
    "start": "911320",
    "end": "917360"
  },
  {
    "text": "would say better ways it's it's like that I I like the the raw control it's so hard to get a stick shift in the",
    "start": "917360",
    "end": "922720"
  },
  {
    "text": "states these days not really yeah nobody carries them anymore it's really depressing I wonder if we can do a an",
    "start": "922720",
    "end": "930079"
  },
  {
    "text": "electric stick shift how would that work that'd be so interesting I don't think I mean it's a total sideline but electric",
    "start": "930079",
    "end": "937040"
  },
  {
    "text": "motors part of the advantage is that they don't they can continuously apply torque throughout all those so you don't",
    "start": "937040",
    "end": "942399"
  },
  {
    "text": "need to shift gears in the same way yeah but you want to feel something it's it's like the way that they they have um they",
    "start": "942399",
    "end": "948319"
  },
  {
    "text": "will play engine sounds right for the electric like yeah the the Hyundai Elantra the new electric one is just",
    "start": "948319",
    "end": "955120"
  },
  {
    "text": "absolutely bananas they actually have like paddle shifters it's electric it's fully electric but they have paddle shifters and they mimic the torque it's",
    "start": "955120",
    "end": "961440"
  },
  {
    "text": "it's [Music]",
    "start": "961440",
    "end": "973040"
  },
  {
    "text": "wild what's up friends I'm here with faras Abad founder and CEO of socket",
    "start": "973040",
    "end": "978720"
  },
  {
    "text": "socket helps to protect the best engineering teams out there with their developer First Security platform and so",
    "start": "978720",
    "end": "984399"
  },
  {
    "text": "for Ross speaking of developer first socket is developer first what does that mean what do you mean by being developer",
    "start": "984399",
    "end": "990279"
  },
  {
    "text": "first most security software is typically sold to Executive so it tends to suck to actually use it so the",
    "start": "990279",
    "end": "996920"
  },
  {
    "text": "company the vendor goes in and makes a sale the executive thinks it looks good but they don't actually care at all what",
    "start": "996920",
    "end": "1002600"
  },
  {
    "text": "the developer experience is of the tool so I think that's where I would start the first pro problem with security tools is they're sold to Executives in",
    "start": "1002600",
    "end": "1008440"
  },
  {
    "text": "the best case those tools get purchased and they just sit around on the Shelf bothering nobody and protecting nobody",
    "start": "1008440",
    "end": "1013639"
  },
  {
    "text": "but in the worst case they get rolled out and they prevent developers from getting things done and they just get all up in your face with alerts and",
    "start": "1013639",
    "end": "1019560"
  },
  {
    "text": "pointless noise that isn't actionable and if you actually go and fix those alerts you're not even improving security because a lot of the time those",
    "start": "1019560",
    "end": "1026480"
  },
  {
    "text": "vulnerabilities are super low impact that's like the dirty secret of vulnerabilities is most of them are low impact they're either in Dev",
    "start": "1026480",
    "end": "1032558"
  },
  {
    "text": "dependencies so they're never going to run in production or they're really difficult to exploit or if you exploit",
    "start": "1032559",
    "end": "1038160"
  },
  {
    "text": "them there's nothing really there it's like a you know a denial of service uh in some random component and in reality",
    "start": "1038160",
    "end": "1043880"
  },
  {
    "text": "like that's just such a low risk in terms of just your priorities of things you need to work on as a developer yeah I I would actually say probably 90 or",
    "start": "1043880",
    "end": "1050760"
  },
  {
    "text": "95% of the vulnerability alerts that developers are used to seeing from other tools are just completely pointless",
    "start": "1050760",
    "end": "1057240"
  },
  {
    "text": "they're just fake work and fixing them doesn't even meaningfully improve security at all dang tell it like it is fr us that's the status quo uh we come",
    "start": "1057240",
    "end": "1064919"
  },
  {
    "text": "in a socket and we're like look there are real threats out there we see packages getting hijacked getting",
    "start": "1064919",
    "end": "1070440"
  },
  {
    "text": "compromised every day like this happens on an hourly basis if you go to the socket website socket. you can see uh we",
    "start": "1070440",
    "end": "1077200"
  },
  {
    "text": "have a feed of packages that we've identified ifed and a lot of them or in the last couple hours we've seen malicious code go up on npm so this is",
    "start": "1077200",
    "end": "1083600"
  },
  {
    "text": "like a real threat so the first thing we do is we just say look let's focus on those threats those are intentionally",
    "start": "1083600",
    "end": "1089120"
  },
  {
    "text": "introduced attacks those are code that you never want to run even once on your system you never want to ship that to",
    "start": "1089120",
    "end": "1095320"
  },
  {
    "text": "production because you're going to lose customer data you're going to lose you know your personal data on your laptop",
    "start": "1095320",
    "end": "1100520"
  },
  {
    "text": "and you need to identify those threats before you install those packages and in order to do that you need to be proactive and that's what socket does",
    "start": "1100520",
    "end": "1107000"
  },
  {
    "text": "we're really trying to bring to light the real threats that matter and that's the whole design behind socket to be",
    "start": "1107000",
    "end": "1112960"
  },
  {
    "text": "that way for developers whether you have it protect yourself your team and your software from the threats that really",
    "start": "1112960",
    "end": "1118440"
  },
  {
    "text": "matter don't do fake work use socket socket dodev that's",
    "start": "1118440",
    "end": "1125679"
  },
  {
    "text": "s.dev book a demo install the GitHub app install the socket CLI whatever it takes",
    "start": "1125880",
    "end": "1131600"
  },
  {
    "text": "to take the next step do it go to socket. deev again socket dodev",
    "start": "1131600",
    "end": "1139960"
  },
  {
    "text": "let's say somebody wanted to follow your footsteps and build it from the ground up because they wanted to explore all",
    "start": "1142080",
    "end": "1147159"
  },
  {
    "text": "the different pieces how do you interact from JavaScript with these models like what what does that end up looking like",
    "start": "1147159",
    "end": "1154600"
  },
  {
    "text": "this is a great question it's not difficult I want to I want to just preface by saying that and and you know people say aages but you say it's not",
    "start": "1154600",
    "end": "1161480"
  },
  {
    "text": "difficult and then you tell us to do it difficult yeah you built react on a in a 30 minute uh or maybe it was an hour",
    "start": "1161480",
    "end": "1167880"
  },
  {
    "text": "talk right really like it just takes a I hope I'm not being like you know Difficult about this but I think it just",
    "start": "1167880",
    "end": "1174039"
  },
  {
    "text": "takes a little bit of thought so how do you do it you I I regret now wearing this black T-shirt based on what I'm about to say but you you would use the",
    "start": "1174039",
    "end": "1180679"
  },
  {
    "text": "versel AIS SDK oh my gosh but it I'm getting like flashbacks to my old job at",
    "start": "1180679",
    "end": "1185799"
  },
  {
    "text": "Zite anyway um the versel AISD K is a really great piece of software and it",
    "start": "1185799",
    "end": "1190919"
  },
  {
    "text": "again it's not it's very capable but I use it because I'm confident I could build it given the time right I so for",
    "start": "1190919",
    "end": "1198320"
  },
  {
    "text": "my thing with abstraction is I typically don't trust blackbox abstractions unless I know how they work on the inside and",
    "start": "1198320",
    "end": "1204039"
  },
  {
    "text": "then I'm like yeah cool this saves me a bunch of time if I don't know how they work on the inside I tend to be uncomfortable to the point where I have",
    "start": "1204039",
    "end": "1210159"
  },
  {
    "text": "to build it myself or at least a Bare Bones like like I did with react so that I understand kind of what's happening okay so the versel AI SDK what does it",
    "start": "1210159",
    "end": "1217360"
  },
  {
    "text": "do it's it's pretty cool you you there it exports a function called create Ai and you can give it a language model to",
    "start": "1217360",
    "end": "1224360"
  },
  {
    "text": "talk to think of it as an abstraction on top of like the open AI API SDK open AI",
    "start": "1224360",
    "end": "1229400"
  },
  {
    "text": "SDK and the mistol SD so a lot of these large language model as a service",
    "start": "1229400",
    "end": "1234880"
  },
  {
    "text": "companies like open Ai and mistol and replicate and whatever they all have sdks and the sdks are not standardized",
    "start": "1234880",
    "end": "1242120"
  },
  {
    "text": "like JavaScript is a standardized programming language right but these sdks aren't standardized and so if you want to if you build your entire company",
    "start": "1242120",
    "end": "1248440"
  },
  {
    "text": "on like open AI gbd4 o and then you're like ah this is way too expensive we need to shift to self-hosted mistol",
    "start": "1248440",
    "end": "1255480"
  },
  {
    "text": "that's going to be painful like changing from one API one SDK excuse me to another and so the versel a a SDK is a",
    "start": "1255480",
    "end": "1263480"
  },
  {
    "text": "general SDK where you can just swap out the language model pretty easily and that it can do that because it the",
    "start": "1263480",
    "end": "1269440"
  },
  {
    "text": "language model is just a an input parameter and the functions you call use that input parameter so it's very nice",
    "start": "1269440",
    "end": "1275240"
  },
  {
    "text": "and standardized so I would use that with the AISD K they have as part of the",
    "start": "1275240",
    "end": "1280480"
  },
  {
    "text": "model that you give as the input parameter you also can pass in an array of tools and what what what is a tool a",
    "start": "1280480",
    "end": "1287279"
  },
  {
    "text": "tool is just a function literally an async JavaScript function that does a task and returns a message so think of",
    "start": "1287279",
    "end": "1295600"
  },
  {
    "text": "it this way when you call the openai API right and you send a prompt the role of",
    "start": "1295600",
    "end": "1302000"
  },
  {
    "text": "the message you're sending is user and the content of this message is convert",
    "start": "1302000",
    "end": "1307559"
  },
  {
    "text": "for me $100 into Euros that's the prompt now if there's no tools the response will be I",
    "start": "1307559",
    "end": "1314919"
  },
  {
    "text": "don't know how to do that with today's exchange rate but here's some nonsense based on some exchange rate I imagined",
    "start": "1314919",
    "end": "1320039"
  },
  {
    "text": "it won't say that but that's what that's what you get it will confidently tell you the wrong answer yeah unfortunately it won't even say this is nonsense and",
    "start": "1320039",
    "end": "1326320"
  },
  {
    "text": "so that's how you would call the SDK but when you add in tools as this input",
    "start": "1326320",
    "end": "1332080"
  },
  {
    "text": "parameter how does a tool look a tool indeed it's just a function but this function also has metadata so the",
    "start": "1332080",
    "end": "1338200"
  },
  {
    "text": "metadata has a description and it's literally just a plain text description and a schema of input parameters and",
    "start": "1338200",
    "end": "1345200"
  },
  {
    "text": "this is just a Zod schema so it's a it's a JavaScript object you can have keys and values right and so based on the",
    "start": "1345200",
    "end": "1351679"
  },
  {
    "text": "description of the metadata of the tool the large language model will call it",
    "start": "1351679",
    "end": "1357760"
  },
  {
    "text": "because it's a language model and the the tie here is really language so if the description of your tool using the",
    "start": "1357760",
    "end": "1363760"
  },
  {
    "text": "versel AIS dek is get the current exchange rate or get a list of current",
    "start": "1363760",
    "end": "1369960"
  },
  {
    "text": "exchange that's the description then the language model will see okay it's just Vector similarity right we'll see the",
    "start": "1369960",
    "end": "1375120"
  },
  {
    "text": "input prompt contains exchange rate I don't know this tool contains exchange rate I'm just going to call this and",
    "start": "1375120",
    "end": "1380919"
  },
  {
    "text": "hope for the best and that tool will return a message so we talked about the role being user and the content being",
    "start": "1380919",
    "end": "1386840"
  },
  {
    "text": "your prompt the tool will return a message where the role is tool call and the content is whatever that function",
    "start": "1386840",
    "end": "1393080"
  },
  {
    "text": "returned as a string and so then open AI um or the large language model has been trained to recognize the Json where the",
    "start": "1393080",
    "end": "1399039"
  },
  {
    "text": "type is tool call and will take that and add it to its context aha now the exchange rates are this I'm going to I",
    "start": "1399039",
    "end": "1406159"
  },
  {
    "text": "got this from the tool I'm going to generate some text for you so this is rag really um tool calling is",
    "start": "1406159",
    "end": "1411919"
  },
  {
    "text": "rag because it did retrieve the exchange rates and then used it to generate its own output to augment its own generated",
    "start": "1411919",
    "end": "1418240"
  },
  {
    "text": "output I should say but yeah that's how the AISD K Works how would I build this it's exactly like that I would add the",
    "start": "1418240",
    "end": "1423559"
  },
  {
    "text": "AISD K to my project create an instance of their AI inference function object",
    "start": "1423559",
    "end": "1430840"
  },
  {
    "text": "and pass in a bunch of tools and then just send prompts to it that and that basically is just my this is why also I",
    "start": "1430840",
    "end": "1437039"
  },
  {
    "text": "don't feel like open sourcing it cuz it's not like revolutionary it's just using another Library also stat Le's AI",
    "start": "1437039",
    "end": "1444720"
  },
  {
    "text": "agent framework is exactly the same also nextjs is exactly the same it's just",
    "start": "1444720",
    "end": "1451360"
  },
  {
    "text": "using react in an opinionated way but nextjs is open source so maybe I should open source my thing but I think you",
    "start": "1451360",
    "end": "1456640"
  },
  {
    "text": "should yeah I think you should absolutely open source it it's part of I mean even if it's not ready say it's not ready but you're learning in public and",
    "start": "1456640",
    "end": "1463039"
  },
  {
    "text": "you're showing people you're talking about it I'd love to see how you do it one caveat with this though is that it",
    "start": "1463039",
    "end": "1468399"
  },
  {
    "text": "does get very expensive this is why I I opt to run the models locally cuz then it's free but to run this at scale like",
    "start": "1468399",
    "end": "1476240"
  },
  {
    "text": "as as in like multi-user workloads is going to always be expensive at this point in time so that's something people",
    "start": "1476240",
    "end": "1482559"
  },
  {
    "text": "should probably know about yeah well that moves into a topic area around gachas for this and like one that I've",
    "start": "1482559",
    "end": "1488919"
  },
  {
    "text": "definitely noticed playing with these tools and then trying to help developers use these tools is I think calling llms",
    "start": "1488919",
    "end": "1497039"
  },
  {
    "text": "artificial intelligence maybe gets in the way of people using them well because if you think of them as",
    "start": "1497039",
    "end": "1502640"
  },
  {
    "text": "intelligence you expect them to be able to for example infer things that to a human seem the same but yeah going back",
    "start": "1502640",
    "end": "1509679"
  },
  {
    "text": "to your tool description like the text of that description is really important it should linguistically be very close",
    "start": "1509679",
    "end": "1517200"
  },
  {
    "text": "to the language that will trigger when it wants to do this yeah there there's",
    "start": "1517200",
    "end": "1522440"
  },
  {
    "text": "one caveat here cuz they can also translate this is absolutely bananas if somebody's speaking Korean with the language model and is like you know",
    "start": "1522440",
    "end": "1528600"
  },
  {
    "text": "convert this currency in Korean it will still do it because the the vector dimensional space transcends like",
    "start": "1528600",
    "end": "1535240"
  },
  {
    "text": "language the way we know it and I think that's very cool yeah no it's super cool and they they are very powerful and when",
    "start": "1535240",
    "end": "1543080"
  },
  {
    "text": "I've used them sometimes like it's it's similar to what you're talking about in terms of Black Box these are sort of black boxes yeah and the lines between",
    "start": "1543080",
    "end": "1551120"
  },
  {
    "text": "what works and what doesn't for example referencing a tool call often are unintuitive I'm trying to think of a",
    "start": "1551120",
    "end": "1556360"
  },
  {
    "text": "good example but like you us language that to me might mean the same thing will not trigger it at all absolutely",
    "start": "1556360",
    "end": "1562240"
  },
  {
    "text": "yeah I'm totally picking up what you're putting down um and I think this is why I I did go a level deeper and you just",
    "start": "1562240",
    "end": "1569520"
  },
  {
    "text": "trained my own model that does tool calling which now I I see it you know I see the Matrix so to speak and I I think",
    "start": "1569520",
    "end": "1575440"
  },
  {
    "text": "it's very important to always look at the the person behind the curtain yeah",
    "start": "1575440",
    "end": "1580640"
  },
  {
    "text": "and so we I'm happy to go down that trail if you want and we actually have an episode on on my podcast with um Kyle",
    "start": "1580640",
    "end": "1586200"
  },
  {
    "text": "Corbett the founder and CEO of a company called pipe that does fine-tuning as a service it's very cool full disclosure",
    "start": "1586200",
    "end": "1592720"
  },
  {
    "text": "I'm an investor so I I need to disclose that but he is just you know a genius about fine-tuning and Tool calling and",
    "start": "1592720",
    "end": "1598720"
  },
  {
    "text": "machine he's got a background in this stuff he's had it for years and so he was able to teach me a lot and I did eventually come up with a large language",
    "start": "1598720",
    "end": "1605799"
  },
  {
    "text": "model completely my own that can call the right tools and so on and like it's it makes sense now so so when you do",
    "start": "1605799",
    "end": "1612480"
  },
  {
    "text": "that are you also implementing that in JavaScript the wrapping around it or is it like how does that work yeah you",
    "start": "1612480",
    "end": "1619440"
  },
  {
    "text": "can't as far as I know so I haven't fine-tuned models in JavaScript mainly because I need access to my gpus which I",
    "start": "1619440",
    "end": "1626919"
  },
  {
    "text": "know you can do with tensorflow.js I just haven't the the Tooling in Python is just fundamentally different and",
    "start": "1626919",
    "end": "1633240"
  },
  {
    "text": "fundamentally better like you've got so many you could like npm install the",
    "start": "1633240",
    "end": "1638360"
  },
  {
    "text": "ecosystem of things you can use in Python for your machine learning workflows are just unparalleled and",
    "start": "1638360",
    "end": "1644440"
  },
  {
    "text": "really this is the great Gap like if if the JavaScript ecosystem wants to mobilize and like create like an",
    "start": "1644440",
    "end": "1650120"
  },
  {
    "text": "equivalent level of tooling that python has in JavaScript we could really like",
    "start": "1650120",
    "end": "1655840"
  },
  {
    "text": "take over the space but for whatever reason we don't have it um what am I talking about well specifically hugging",
    "start": "1655840",
    "end": "1662039"
  },
  {
    "text": "face the company um for those who maybe don't get to play with this hugging face is like GitHub but for machine learning models people can upload their models",
    "start": "1662039",
    "end": "1668320"
  },
  {
    "text": "there and Fork them and clone them and download them do whatever they want at least the ones that are open source um so hugging face is just the biggest",
    "start": "1668320",
    "end": "1674840"
  },
  {
    "text": "contributor to the python ecosystem they have a great Library called Transformer this thing is bananas it's it's like the",
    "start": "1674840",
    "end": "1681519"
  },
  {
    "text": "the Bedrock of all fine-tuning operations that that you would do maybe as an Enthusiast I can't speak for like",
    "start": "1681519",
    "end": "1686919"
  },
  {
    "text": "Academia and research and people with h100s from Nvidia but for me with my Apple silicon like hugging face",
    "start": "1686919",
    "end": "1693159"
  },
  {
    "text": "Transformers comes with so many great declarative abstractions out of the box for example you instantiate a trainer",
    "start": "1693159",
    "end": "1699600"
  },
  {
    "text": "it's a class and you give it a bunch of hyperparameters like this is my I want this many epic epics epochs however",
    "start": "1699600",
    "end": "1705720"
  },
  {
    "text": "people say it I I want um this learning rate and so on and so forth and then once you've configured this instance you",
    "start": "1705720",
    "end": "1711679"
  },
  {
    "text": "literally just call trainer. train how cool is that and it it will do that and it will look for a GPU if if you have",
    "start": "1711679",
    "end": "1719320"
  },
  {
    "text": "one it's called an MPS device or it will try it best effort to do it on your CPU",
    "start": "1719320",
    "end": "1724440"
  },
  {
    "text": "and will probably crash your system I've crashed my computer many times but all of this in JavaScript is just at this",
    "start": "1724440",
    "end": "1730000"
  },
  {
    "text": "point in time not as accessible because of the ecosystem as it is in Python interesting so something you talked",
    "start": "1730000",
    "end": "1735320"
  },
  {
    "text": "about there you said you've crashed your computer and you are running everything locally so how like what are the gotas",
    "start": "1735320",
    "end": "1740840"
  },
  {
    "text": "if you want to start running locally How likely are you to crash things how fast or slow is this like what what does that",
    "start": "1740840",
    "end": "1747279"
  },
  {
    "text": "end up looking like yeah that's a great question you're unlikely to crash things especially like so I'm working on um a",
    "start": "1747279",
    "end": "1754960"
  },
  {
    "text": "20121 MacBook Pro with an M1 chip um it's pretty old it's 3 years old it's a",
    "start": "1754960",
    "end": "1761000"
  },
  {
    "text": "very old device and it works just fine it's pretty much impossible to crash",
    "start": "1761000",
    "end": "1766159"
  },
  {
    "text": "unless you really get around it for example example the Mac OS kernel is really extremely worldclass at making",
    "start": "1766159",
    "end": "1773799"
  },
  {
    "text": "sure you don't crash the system there's plenty of safeguards in place so what will typically happen is your application itself will freeze so not",
    "start": "1773799",
    "end": "1780399"
  },
  {
    "text": "your entire system and at some point it will say hey this thing's taking too long do you want to force it to quit and the colonel will just pull the kill",
    "start": "1780399",
    "end": "1786080"
  },
  {
    "text": "switch very cool there's a way around this using a environment variable so",
    "start": "1786080",
    "end": "1791240"
  },
  {
    "text": "pytorch is the thing that's causing the memory problems pytorch is an open source library from meta that helps with",
    "start": "1791240",
    "end": "1798000"
  },
  {
    "text": "machine learning and so pytorch allows you to set a environment variable called",
    "start": "1798000",
    "end": "1804159"
  },
  {
    "text": "MPS high water mark ratio and this is at",
    "start": "1804159",
    "end": "1809240"
  },
  {
    "text": "what point do you you know throw an outof memory exception because like high",
    "start": "1809240",
    "end": "1814480"
  },
  {
    "text": "water mark literally means you're about to reach the the water mark the the level where if this is a tide pool",
    "start": "1814480",
    "end": "1820559"
  },
  {
    "text": "you're going to start losing water you know you're going to overflow literally I love the the language we have in computer science overflow Watermark Etc",
    "start": "1820559",
    "end": "1827519"
  },
  {
    "text": "so you set this it's a threshold before overflow at which point pytorch will just kill the process you can set that",
    "start": "1827519",
    "end": "1834720"
  },
  {
    "text": "to zero right and then what will happen is you just completely bypass so you're like you know what if we have an overflow we have an overflow I'll just",
    "start": "1834720",
    "end": "1840919"
  },
  {
    "text": "like hard reboot so you set that to zero and then you'll crash your system um because all your GPU all your CPU is",
    "start": "1840919",
    "end": "1848519"
  },
  {
    "text": "going to be consumed and you're not going to have free resources to like respond to the caps lock key and turn",
    "start": "1848519",
    "end": "1854399"
  },
  {
    "text": "the light green you're not going to have resources to so what you're saying is unless unless you go out of your way to",
    "start": "1854399",
    "end": "1859600"
  },
  {
    "text": "tell your computer it's okay to crash it's not going to crash um and just to understand you reference pytorch that's",
    "start": "1859600",
    "end": "1864679"
  },
  {
    "text": "getting run by AMA under the covers or you're explicitly running that no no I'm explicitly running it I I think to be",
    "start": "1864679",
    "end": "1870120"
  },
  {
    "text": "fair hugging face Transformers runs it yeah so my fine tunes by the way just to make this really accessible to everyone",
    "start": "1870120",
    "end": "1875760"
  },
  {
    "text": "is I I do it through a Jupiter notebook for those who aren't familiar with this Jupiter is just a big Json file that has",
    "start": "1875760",
    "end": "1882720"
  },
  {
    "text": "like cells and each cell runs in isolation but their shared scope so it's like a it's literally it looks like a",
    "start": "1882720",
    "end": "1889120"
  },
  {
    "text": "notebook with code Snippets and you can run those code Snippets it's it's basically like text snippet text snippet",
    "start": "1889120",
    "end": "1894639"
  },
  {
    "text": "text snippet and you can run Snippets in isolation and they share scope so you can say like a VAR a equals 1 in a",
    "start": "1894639",
    "end": "1901399"
  },
  {
    "text": "snippet somewhere high above and then way down under a bunch of text you could reference a and it would just know the value and the reason I do this is",
    "start": "1901399",
    "end": "1907760"
  },
  {
    "text": "because where there's these Snippets in a notebook there's also checkpoints meaning I could go up to the point where",
    "start": "1907760",
    "end": "1913840"
  },
  {
    "text": "I run npm install safely and then the step after that could crash but I'll still have my dependencies you know and",
    "start": "1913840",
    "end": "1920960"
  },
  {
    "text": "so that's really cool for an iterative training process because with fine tuning and training machine learning",
    "start": "1920960",
    "end": "1926440"
  },
  {
    "text": "models you have to load a bunch of stuff into memory and sort of keep it there and the loading takes time so if the",
    "start": "1926440",
    "end": "1931519"
  },
  {
    "text": "loading step crashes then you have to load it again and again so it's really cool that you're able to just load things into memory and run an inference",
    "start": "1931519",
    "end": "1939159"
  },
  {
    "text": "later and if the inference fails the stuff's still in memory yeah so unless you go out of your way you're not going to crash things I recommend going out of",
    "start": "1939159",
    "end": "1945440"
  },
  {
    "text": "your way cuz you're still not going to like we're we're very protected you're not worst casee your computer becomes",
    "start": "1945440",
    "end": "1950559"
  },
  {
    "text": "fully unresponsive and then you press and hold the power button for like 10 seconds and it just does a reboot and",
    "start": "1950559",
    "end": "1955880"
  },
  {
    "text": "you're fine like nothing will explode so it's worth playing so coming back then",
    "start": "1955880",
    "end": "1961200"
  },
  {
    "text": "peeling back the layers right so if you wanted to get involved or start playing with this stuff like the simplest thing",
    "start": "1961200",
    "end": "1967559"
  },
  {
    "text": "which most people have done is you just go to one of these online services right you go to chat gbt or something like that you play with it there you see what",
    "start": "1967559",
    "end": "1973519"
  },
  {
    "text": "can this thing do for me in this setting next layer is you're using some sort of",
    "start": "1973519",
    "end": "1979360"
  },
  {
    "text": "local code maybe it's an agentic framework something like that but you're still interacting with an online model",
    "start": "1979360",
    "end": "1985559"
  },
  {
    "text": "or API an online API right you don't have to do anything one layer beyond that you're downloading AMA running a a",
    "start": "1985559",
    "end": "1992639"
  },
  {
    "text": "local model of some sort now let's talk briefly about like levels of local resources right so you're you're in a",
    "start": "1992639",
    "end": "1998679"
  },
  {
    "text": "three-year-old MacBook Pro I'm guessing something like 16 gigs of memory or something like that like how much do you",
    "start": "1998679",
    "end": "2004799"
  },
  {
    "text": "need to run these things locally that's the cool thing about AMA they will work on anything and if they don't they're",
    "start": "2004799",
    "end": "2011960"
  },
  {
    "text": "explicit about it UPF front so that's the promise with AMA is they detect your it's sort of like Docker right you don't",
    "start": "2011960",
    "end": "2017840"
  },
  {
    "text": "really think of like what Hardware am I working on you just like in your Docker file you're like from Ubuntu whatever like do it and it will virtualize that",
    "start": "2017840",
    "end": "2024679"
  },
  {
    "text": "for you and AMA is exactly the same so it really is there's quite a bit of interop um it'll work on three-year-old",
    "start": "2024679",
    "end": "2031039"
  },
  {
    "text": "devices it'll work on Windows it'll work on Linux it's it's pretty cool okay so now you've got your local model yeah",
    "start": "2031039",
    "end": "2036200"
  },
  {
    "text": "you're probably at this layer still not find tuning but you're just running against a local model using your your",
    "start": "2036200",
    "end": "2041919"
  },
  {
    "text": "JavaScript or I guess it looked like um the versel SDK is typescript so Nick n",
    "start": "2041919",
    "end": "2047080"
  },
  {
    "text": "will be happy he'll be willing to play with it yeah but uh well let me let me say this if you want to go the local",
    "start": "2047080",
    "end": "2052919"
  },
  {
    "text": "route you you need you need really just two things and none of them are JavaScript but you can add JavaScript",
    "start": "2052919",
    "end": "2058599"
  },
  {
    "text": "later we'll talk about that in a second but just to make sure just to get really clear if you want to run any large language model or frankly any machine",
    "start": "2058599",
    "end": "2065040"
  },
  {
    "text": "learning model locally you just need two things one is a very very typically large file called the weights and this",
    "start": "2065040",
    "end": "2072560"
  },
  {
    "text": "is literally a new world Network it's think of it as a brain on your computer",
    "start": "2072560",
    "end": "2077679"
  },
  {
    "text": "right these are like orders of gigabytes so 70 gigabytes sometimes terabytes they're very sometimes paby they're very",
    "start": "2077679",
    "end": "2083440"
  },
  {
    "text": "very large and what all they are are big almost almost graph-like data structures",
    "start": "2083440",
    "end": "2090079"
  },
  {
    "text": "with a bunch of nodes and a bunch of edges and each node has a number associated with it like this is the",
    "start": "2090079",
    "end": "2096200"
  },
  {
    "text": "think of it as like if you see a sound board from an audio engineer's desk you know there's like a billion different",
    "start": "2096200",
    "end": "2101800"
  },
  {
    "text": "knobs for like EQ settings and volume and stuff that's it right and so turning these knobs is how inference works is",
    "start": "2101800",
    "end": "2108960"
  },
  {
    "text": "how training works like setting the values on each knob is is basically the training process so you have this huge file that's the weights and you have an",
    "start": "2108960",
    "end": "2115839"
  },
  {
    "text": "inference engine something to run the algorithm that those weights Express they take an input they they pass it",
    "start": "2115839",
    "end": "2122480"
  },
  {
    "text": "through those weights and get a predicted output with some degree of certainty um the inference engine the",
    "start": "2122480",
    "end": "2128200"
  },
  {
    "text": "lowest level of inference engine is something called llama CPP it's exactly what it sounds like it's it runs in C+",
    "start": "2128200",
    "end": "2134760"
  },
  {
    "text": "it's very like for me this is beyond the scope of my knowledge o Lama abstracts on top of llama CPP and and just makes",
    "start": "2134760",
    "end": "2141440"
  },
  {
    "text": "it more comfortable for people like me um so you need those two files that's it now if you're running inference locally",
    "start": "2141440",
    "end": "2147400"
  },
  {
    "text": "meaning you can send input tokens you get output tokens you can say hey chat GPT was 2 plus4 you get six or not chat",
    "start": "2147400",
    "end": "2153240"
  },
  {
    "text": "GPT hey local model what's 2 plus4 you get six maybe um then the inference engines typically expose a web API or",
    "start": "2153240",
    "end": "2161960"
  },
  {
    "text": "you can wrap it with a web API AMA runs a web API on Local Host it's some weird",
    "start": "2161960",
    "end": "2167240"
  },
  {
    "text": "Port like Local Host port and like five-digit thing but once that's running locally then you can just do a fetch",
    "start": "2167240",
    "end": "2174240"
  },
  {
    "text": "request in JavaScript to it the cool thing about ama's HTTP API is that it's",
    "start": "2174240",
    "end": "2179480"
  },
  {
    "text": "100% open AI compatible so you could literally like run an inference with chat GPT copy that as Fetch and change",
    "start": "2179480",
    "end": "2187079"
  },
  {
    "text": "the url to instead of like you know chat gp.com whatever Local Host Port something SL whatever and it will just",
    "start": "2187079",
    "end": "2192640"
  },
  {
    "text": "work with your local model well and that that gives a really low barrier to entry",
    "start": "2192640",
    "end": "2198160"
  },
  {
    "text": "for just hacking around with code here because now suddenly you don't have to worry about a number of things you don't have to worry about signing up for an",
    "start": "2198160",
    "end": "2204200"
  },
  {
    "text": "API based account on chat GPT because that's a separate thing than their web interface you don't have to worry about",
    "start": "2204200",
    "end": "2210480"
  },
  {
    "text": "are they stealing my data what are they doing with it where is it going you don't have to worry about any of this",
    "start": "2210480",
    "end": "2215800"
  },
  {
    "text": "stuff now yes what are the shortcomings right GPT 40 you mentioned is sort of like state-of-the-art highest power",
    "start": "2215800",
    "end": "2222000"
  },
  {
    "text": "model like if I step down to using something like you're using mraw 8X 22b",
    "start": "2222000",
    "end": "2229160"
  },
  {
    "text": "like how is that going to feel different oh it's going to feel very different as a consequence of these models being",
    "start": "2229160",
    "end": "2235359"
  },
  {
    "text": "ethical and open source they kind of suck it's like it's like it's like if anyone's um if anyone's used gone from",
    "start": "2235359",
    "end": "2243040"
  },
  {
    "text": "like Adobe Photoshop to like the which was I don't know if you remember this was like the old I do remember",
    "start": "2243040",
    "end": "2248720"
  },
  {
    "text": "I I spent a lot of time in because I didn't want to pay for Photoshop and it was miserable yeah EXA it's exactly",
    "start": "2248720",
    "end": "2254240"
  },
  {
    "text": "like that it's like going from Mac OS to Linux it's the tax of Open Source it just really really sucks but you can",
    "start": "2254240",
    "end": "2261319"
  },
  {
    "text": "work around it right you can through some system prompt engineering through some rag and honestly through",
    "start": "2261319",
    "end": "2268240"
  },
  {
    "text": "fine-tuning there's a model called mistol 7B instruct it was like purpose",
    "start": "2268240",
    "end": "2273280"
  },
  {
    "text": "built for fine tuning and so this is this is the secret sauce this is what people should be doing is you work with",
    "start": "2273280",
    "end": "2278880"
  },
  {
    "text": "a crappy model and over time you tend to get some really good inferences and so you collect all your good inferences",
    "start": "2278880",
    "end": "2285200"
  },
  {
    "text": "pair them up with the prompts that led to them and then use those to fine-tune a smaller model like M 7B instruct and",
    "start": "2285200",
    "end": "2291359"
  },
  {
    "text": "then you've got a really high quality model that's specialized at at what you want and then you can run it locally and",
    "start": "2291359",
    "end": "2297400"
  },
  {
    "text": "it's going to be better than it will probably outperform GPD 40 for your use cases because it it's just more",
    "start": "2297400",
    "end": "2302440"
  },
  {
    "text": "intimately knows your data yeah well and this I think highlights one of the things that going to these smaller",
    "start": "2302440",
    "end": "2308079"
  },
  {
    "text": "models does is it peels back once again the layers of like if you go and interact with chat GPT it can kind of",
    "start": "2308079",
    "end": "2314359"
  },
  {
    "text": "just feel like magic and that's dangerous because it means that you assume that it's better than it is you",
    "start": "2314359",
    "end": "2321160"
  },
  {
    "text": "assume that it can do all of these different things and it will try and it will look good in a lot of different",
    "start": "2321160",
    "end": "2326720"
  },
  {
    "text": "ways but it's so powerful that yeah it demos incredibly well it gets really really close most of the time out of the",
    "start": "2326720",
    "end": "2333680"
  },
  {
    "text": "box and it's hard to see like what is actually happening under the there it just it feels magical yeah sorry to",
    "start": "2333680",
    "end": "2339560"
  },
  {
    "text": "interrupt you know especially tool calling feels so magical right how does how does it call a function what but",
    "start": "2339560",
    "end": "2345440"
  },
  {
    "text": "this is just training data text in text out yeah so you get down to those smaller models and you start to see that",
    "start": "2345440",
    "end": "2350800"
  },
  {
    "text": "a little bit more raw and you say oh yeah it's just it's just making it up",
    "start": "2350800",
    "end": "2355920"
  },
  {
    "text": "based on pattern matching and you can get better at how you present patterns",
    "start": "2355920",
    "end": "2361400"
  },
  {
    "text": "to it you can teach it the patterns that matter to you yes and it will then produce patterns that also matter more",
    "start": "2361400",
    "end": "2366760"
  },
  {
    "text": "to you I think also what's worth noting is the large language models themselves don't really call any tools right they",
    "start": "2366760",
    "end": "2373359"
  },
  {
    "text": "they return data they return text that then a layer in front of them on open AI",
    "start": "2373359",
    "end": "2378720"
  },
  {
    "text": "side or whatever end there can reason about the format of string It produced and then call the function so it's not",
    "start": "2378720",
    "end": "2384359"
  },
  {
    "text": "like the large language models have function calling capabilities they have text generation capabilities they'll just generate like some Json like think",
    "start": "2384359",
    "end": "2391480"
  },
  {
    "text": "of an object with URL this and parameters that and then your API that",
    "start": "2391480",
    "end": "2398599"
  },
  {
    "text": "talks to the language model will receive this string parse it and then call a tool and then return text after that so",
    "start": "2398599",
    "end": "2404960"
  },
  {
    "text": "like you said it it seems magical but it's just layers of apis on layers of apis well you can you can peel back the",
    "start": "2404960",
    "end": "2411400"
  },
  {
    "text": "layers on that too even within like a chat gbt just ask it to to render Json or ask it to render yaml it turns out",
    "start": "2411400",
    "end": "2418240"
  },
  {
    "text": "yaml is a really nice language for large language models compared to Json because it encodes meaning in the spaces and it",
    "start": "2418240",
    "end": "2425480"
  },
  {
    "text": "like is very human readable which means means it's very close to language which means it's something they grock really",
    "start": "2425480",
    "end": "2431160"
  },
  {
    "text": "well but yeah you can do all sorts of things you can ask it to instead of just outputting an answer output three",
    "start": "2431160",
    "end": "2437480"
  },
  {
    "text": "answers output a summary of your conversation so far inside a summary tag and then your answer okay sure it will",
    "start": "2437480",
    "end": "2443800"
  },
  {
    "text": "do that yeah exactly so I I just I want people to know that it's it's not magic and I do want people to also like care",
    "start": "2443800",
    "end": "2452480"
  },
  {
    "text": "about the the magician behind the magic you know I think that's that's really going to be important for us as we move",
    "start": "2452480",
    "end": "2458280"
  },
  {
    "text": "forward um in the AI age also one thing I I want to clarify and this is speculative but I think there's a lot of",
    "start": "2458280",
    "end": "2465880"
  },
  {
    "text": "positive veilance casting on like oh my gosh open AI released chat GPT and it was so great and they did good for Humanity and so on but if we balance",
    "start": "2465880",
    "end": "2473599"
  },
  {
    "text": "that out a little bit with what we know about big Tech and capitalism I think another side that's worth discussing",
    "start": "2473599",
    "end": "2479079"
  },
  {
    "text": "that I just don't see us discussing enough is the idea that they just really needed human feedback because the way",
    "start": "2479079",
    "end": "2485400"
  },
  {
    "text": "you make these language models really great is through a technique called rhf or reinforcement learning with human feedback they need people to do text",
    "start": "2485400",
    "end": "2492000"
  },
  {
    "text": "Generations at scale and you know click on the thumbs up or thumbs down because this helps them create new models new",
    "start": "2492000",
    "end": "2498839"
  },
  {
    "text": "like gp4 is just a successor to GP 3.5 because 100 million users used it and",
    "start": "2498839",
    "end": "2504280"
  },
  {
    "text": "then clicked on thumbs up and thumbs down and they use those to find tun gbd 3.5 and so on and so on so without that",
    "start": "2504280",
    "end": "2510079"
  },
  {
    "text": "open AI wouldn't be open AI today and I think that's that's another reason to so",
    "start": "2510079",
    "end": "2515480"
  },
  {
    "text": "it's not I I challenged the idea that it's just like fully altruistic like we're going to give something good to humanity and do research they also need",
    "start": "2515480",
    "end": "2522560"
  },
  {
    "text": "us as much as we need it so yeah well I think this gets into a little bit of",
    "start": "2522560",
    "end": "2528079"
  },
  {
    "text": "like one of the challenges being a software developer is we tend to jump to",
    "start": "2528079",
    "end": "2534040"
  },
  {
    "text": "binaries we like to to nail things down and so I talk with a lot of developers who are either AI is the future of",
    "start": "2534040",
    "end": "2539920"
  },
  {
    "text": "everything or possibly even more common this stuff is all",
    "start": "2539920",
    "end": "2545440"
  },
  {
    "text": "both just not good for anything and I think what's much more interesting to me",
    "start": "2545440",
    "end": "2551520"
  },
  {
    "text": "is like the line along the way of saying like the hype machine is the hype machine it's going to do what it's going to do it's going to go crazy and a lot",
    "start": "2551520",
    "end": "2558119"
  },
  {
    "text": "of the stuff they're saying is not there and as you highlight like they have their reasons for doing it right like",
    "start": "2558119",
    "end": "2563480"
  },
  {
    "text": "Sam Altman's not out there talking about AGI because he actually thinks it's",
    "start": "2563480",
    "end": "2568800"
  },
  {
    "text": "coming he's doing that because it pumps up open Ai and it gets all sorts of outcomes that he wants out of it like",
    "start": "2568800",
    "end": "2574760"
  },
  {
    "text": "he's not as far as I can tell an altruist any of that yeah and also should they discover AGI they have a an",
    "start": "2574760",
    "end": "2582280"
  },
  {
    "text": "incentive to not reveal that they've discovered AGI right because it would give Microsoft and the stakeholders an",
    "start": "2582280",
    "end": "2588040"
  },
  {
    "text": "enormous advantage in the market so why why would you then share that or open source that unless you absolutely have",
    "start": "2588040",
    "end": "2594040"
  },
  {
    "text": "to but how can you absolutely have to unless you have people overlooking you and holding you accountable to do that",
    "start": "2594040",
    "end": "2599119"
  },
  {
    "text": "which as far as I know they don't so yeah it's it's worth I think those discussions are exceedingly important as",
    "start": "2599119",
    "end": "2605680"
  },
  {
    "text": "AI continues to grow and [Music]",
    "start": "2605680",
    "end": "2613590"
  },
  {
    "text": "hey friends I'm here with Brian Clark VP a product at neon you know we use neon",
    "start": "2615319",
    "end": "2620359"
  },
  {
    "text": "we love neon so Brian you're both a fan and a listener of the show so you kind of know what our shows are about who we",
    "start": "2620359",
    "end": "2627720"
  },
  {
    "text": "reach and of those folks that listen to our podcasts what do you think they need",
    "start": "2627720",
    "end": "2632760"
  },
  {
    "text": "to know most about neon I think the thing I found in talking to developers",
    "start": "2632760",
    "end": "2638160"
  },
  {
    "text": "is that they really don't understand they don't understand database branches sometimes they'll say is this expensive",
    "start": "2638160",
    "end": "2644400"
  },
  {
    "text": "or is it slow or like I don't really understand where it fits in and so we're changing the the face of it a bit to",
    "start": "2644400",
    "end": "2651960"
  },
  {
    "text": "like maybe Focus Less on branching because that's the tool and more on like maybe calling it database previews so",
    "start": "2651960",
    "end": "2657160"
  },
  {
    "text": "you can better see how it fits into your development environment the more people can understand oh I get it like hey any",
    "start": "2657160",
    "end": "2664079"
  },
  {
    "text": "changes you make they don't affect production like this is a seate copy the cost of those changes is only the",
    "start": "2664079",
    "end": "2670440"
  },
  {
    "text": "difference between production and whatever changes you made so if you deleted a bunch of things or added new",
    "start": "2670440",
    "end": "2677280"
  },
  {
    "text": "data things like that you're only actually paying the difference because we use copy on right so I think it's like these sets of things is what I have",
    "start": "2677280",
    "end": "2683960"
  },
  {
    "text": "the team really focused on getting people to really grasp database preview environments and then like what's the",
    "start": "2683960",
    "end": "2689880"
  },
  {
    "text": "advantage and like can I use it in my system and that's where I'm like yeah like you should be taking this system on",
    "start": "2689880",
    "end": "2695680"
  },
  {
    "text": "like this will increase your confidence it doesn't cost a lot it's super fast",
    "start": "2695680",
    "end": "2701000"
  },
  {
    "text": "that idea isn't out there and I think it's because it's not in most products most databases don't have this kind of",
    "start": "2701000",
    "end": "2706800"
  },
  {
    "text": "integration okay so a concern I've heard out there is why not just run postgress local why database branching why preview",
    "start": "2706800",
    "end": "2714400"
  },
  {
    "text": "branches however you want to frame it a serverless managed in the cloud",
    "start": "2714400",
    "end": "2719440"
  },
  {
    "text": "postgress may be more latent or slower than a local copy it may cost more",
    "start": "2719440",
    "end": "2725119"
  },
  {
    "text": "there's more storage buunk this help me understand the true cost the true speed",
    "start": "2725119",
    "end": "2730599"
  },
  {
    "text": "lay it on me so in a pull request like a preview environment this system is fast",
    "start": "2730599",
    "end": "2736400"
  },
  {
    "text": "so neon databases spin up in 500 milliseconds or less you're not affecting the speed of your cicd system",
    "start": "2736400",
    "end": "2744760"
  },
  {
    "text": "at all the copy on right for our storage means that there's no actual operation",
    "start": "2744760",
    "end": "2750359"
  },
  {
    "text": "it's like a kind of a null operation when we create a branch you instantly have access to the production data but",
    "start": "2750359",
    "end": "2756400"
  },
  {
    "text": "nothing has changed only until you start writing do we actually save the differences there yeah you're not paying for extra extra data",
    "start": "2756400",
    "end": "2762720"
  },
  {
    "text": "it's not like you're creating a fork and then you like allocate a whole other 200 GB storage system and a whole other",
    "start": "2762720",
    "end": "2768520"
  },
  {
    "text": "separate compute we attach compute directly to the original storage yeah those things are super fast and that's",
    "start": "2768520",
    "end": "2774079"
  },
  {
    "text": "in the the poll request environment for the most part on your desktop environment or your laptop environment",
    "start": "2774079",
    "end": "2779359"
  },
  {
    "text": "you won't notice a Slowdown there um and you can do reset and things like that so you can make a bunch of changes you can",
    "start": "2779359",
    "end": "2786000"
  },
  {
    "text": "use our CLI and do Branch reset and it'll just reset with whatever the parent Branch was but I I completely",
    "start": "2786000",
    "end": "2792680"
  },
  {
    "text": "understand that the need for people that want to have a purely local environment uh and I want to get there so neon is",
    "start": "2792680",
    "end": "2799359"
  },
  {
    "text": "super fast production managed serverless databases that are basically never idle",
    "start": "2799359",
    "end": "2805400"
  },
  {
    "text": "they wake up in less than 500 milliseconds that's fast it's Managed IT",
    "start": "2805400",
    "end": "2810559"
  },
  {
    "text": "scales it branches what else do you need learn more at neon.pdf",
    "start": "2810559",
    "end": "2817119"
  },
  {
    "text": "Neo n. te neon.pdf",
    "start": "2817119",
    "end": "2822220"
  },
  {
    "text": "[Music]",
    "start": "2822220",
    "end": "2826720"
  },
  {
    "text": "how do you see this playing out in the ecosystem yeah I I will add we at the",
    "start": "2847280",
    "end": "2852880"
  },
  {
    "text": "podcast grew in terms of production efficiency by 100% we literally doubled",
    "start": "2852880",
    "end": "2858960"
  },
  {
    "text": "the amount of episodes we ship from once a week to twice a week because of the agentic workflows and it's it's me there",
    "start": "2858960",
    "end": "2865640"
  },
  {
    "text": "there's no one else that works on this podcast other than me and a bunch of agents and you know each episode is",
    "start": "2865640",
    "end": "2871520"
  },
  {
    "text": "nearly 2 hours and it's it's quite a bit of work but that's the power of Agents where can people use this I think that's",
    "start": "2871520",
    "end": "2877319"
  },
  {
    "text": "a really great question I think we just have to get curious a little bit because as I mentioned anything that you could",
    "start": "2877319",
    "end": "2883440"
  },
  {
    "text": "do with a human that is even yourself I could I could produce all this podcast stuff myself manually right but there's",
    "start": "2883440",
    "end": "2890960"
  },
  {
    "text": "a better way and so I think where people can use this is in the places that they're already spending manual energy",
    "start": "2890960",
    "end": "2898480"
  },
  {
    "text": "so for example I know Runners people who will go for a run and they'll get into straa and look at their stats and be",
    "start": "2898480",
    "end": "2905119"
  },
  {
    "text": "like oh I was slow today or as fast today what if you didn't have to do that you just go for your run jump in the",
    "start": "2905119",
    "end": "2911000"
  },
  {
    "text": "shower come out and you just have a summary like hey this is how you stacked up to like all the other workouts and",
    "start": "2911000",
    "end": "2916520"
  },
  {
    "text": "and it's not reactive where you're like having to send a prompt and get a get a response it's proactive like you",
    "start": "2916520",
    "end": "2922040"
  },
  {
    "text": "literally like just go about your day and somewhere your agent interrupts you with like just so you know your run today was actually better than your past",
    "start": "2922040",
    "end": "2928040"
  },
  {
    "text": "like three efforts in the same route things like that or another place people can use this is so I think Apple",
    "start": "2928040",
    "end": "2934440"
  },
  {
    "text": "intelligence actually is going to change the game on this because Apple intelligence makes AI personal I think",
    "start": "2934440",
    "end": "2940760"
  },
  {
    "text": "for the first time ever and I think what they not maybe not talking about but I",
    "start": "2940760",
    "end": "2946119"
  },
  {
    "text": "think this future is coming is the age of not just personal AI but proactive AI so not reactive I send you a prompt you",
    "start": "2946119",
    "end": "2952480"
  },
  {
    "text": "send me your generation it's more I'm just going to go out my day and you're going to tell me things that are super useful for example you know I could have",
    "start": "2952480",
    "end": "2959240"
  },
  {
    "text": "a calendar event next week for lunch with Yani evalo and I forget about it",
    "start": "2959240",
    "end": "2964760"
  },
  {
    "text": "right and so I go play tennis and then I I come back from tennis and my AI agent is like hey just so you know you have a",
    "start": "2964760",
    "end": "2970040"
  },
  {
    "text": "lunch with Yanni next week um and there's no location in the calendar invite by the way you the last time you",
    "start": "2970040",
    "end": "2975160"
  },
  {
    "text": "both talked you like this place so I went and made a reservation for you and it's attached to the calendar V now that",
    "start": "2975160",
    "end": "2980680"
  },
  {
    "text": "whole thing just happens right and that can happen with a gentic workflow so I think this is where people will end up using it or should end up using it um we",
    "start": "2980680",
    "end": "2987280"
  },
  {
    "text": "don't live in that future today but we will and I think there's companies to be started there and open source projects",
    "start": "2987280",
    "end": "2993520"
  },
  {
    "text": "to be made and a lot of stuff there am I going to start one of these companies absolutely not I just don't care enough",
    "start": "2993520",
    "end": "3000160"
  },
  {
    "text": "I like I care about the we talked about this Kevin I care about the the novelty and the not not so much the novelty but",
    "start": "3000160",
    "end": "3006599"
  },
  {
    "text": "the the complexity of it I care about how it works and knowing how it works and the the person behind the curtain",
    "start": "3006599",
    "end": "3013599"
  },
  {
    "text": "but I know all that and and that sort of removes the fun from building it because cool yes I I I can and so it's this",
    "start": "3013599",
    "end": "3020359"
  },
  {
    "text": "weird thing where when I recognize I can build something I don't you know but when I when I when I'm chasing the",
    "start": "3020359",
    "end": "3026119"
  },
  {
    "text": "knowledge then I build a bunch of stuff so anyway so it sounds like essentially think about what you're doing today that",
    "start": "3026119",
    "end": "3033480"
  },
  {
    "text": "you would rather not be doing and see if you can figure out how to get an AI to do it yeah because like I was just going",
    "start": "3033480",
    "end": "3038760"
  },
  {
    "text": "to say one of the things that I think people talk about is this future where the machines take over and then what do",
    "start": "3038760",
    "end": "3045319"
  },
  {
    "text": "we do you know the Doomer Theory and some people see this as a good thing right like the machines run everything",
    "start": "3045319",
    "end": "3051040"
  },
  {
    "text": "and we just like paint all day and eat pizza and chill and do Sports and whatever we want I think we could make",
    "start": "3051040",
    "end": "3057119"
  },
  {
    "text": "that future like you said do the thing like you know automate away the things you don't want to do with agents and just live your life so that's sort of",
    "start": "3057119",
    "end": "3063319"
  },
  {
    "text": "what I would do that's what I'm doing actually with my podcast one of the things that I've found playing with these tools is at least in their current",
    "start": "3063319",
    "end": "3070760"
  },
  {
    "text": "state they're really not good at things like decision making but they're pretty good at I want you to do a thing go and",
    "start": "3070760",
    "end": "3076359"
  },
  {
    "text": "do it especially if you're willing to spend some time to like figure out how do I tune this prompt how do I write the right tools or how do I ask the AI to",
    "start": "3076359",
    "end": "3082720"
  },
  {
    "text": "write the right tools get it to do things and so I I think there's kind of an interesting question there around you",
    "start": "3082720",
    "end": "3090079"
  },
  {
    "text": "can we use these tools to get rid of the dredge work but then Elevate the interesting decisionmaking ideation",
    "start": "3090079",
    "end": "3095839"
  },
  {
    "text": "exploration pieces in your example that you shared personally I wouldn't want it to book a restaurant but I'd want it to",
    "start": "3095839",
    "end": "3102359"
  },
  {
    "text": "suggest it and say hey here's the restaurant do you want me to book it and then I can make that decision and then",
    "start": "3102359",
    "end": "3107960"
  },
  {
    "text": "it can go and do that the work for me yeah and and you know dialing in that threshold is I think also where a lot of",
    "start": "3107960",
    "end": "3113920"
  },
  {
    "text": "the complexity in the work is so I think apple and again goes does this really well right where it uses open a eyes",
    "start": "3113920",
    "end": "3120920"
  },
  {
    "text": "models as a tool literally it it we talked about tool calling Apple intelligence they have a small on device",
    "start": "3120920",
    "end": "3126400"
  },
  {
    "text": "model that does tool calling but to another llm and I think that that's pretty cool and I think we'll see a lot",
    "start": "3126400",
    "end": "3131559"
  },
  {
    "text": "of that as well well I think that's that's the model that for me I want to bring this back to to for developers",
    "start": "3131559",
    "end": "3138520"
  },
  {
    "text": "right like the danger is either you dismiss these as they're not useful at all or you think they're magic and",
    "start": "3138520",
    "end": "3144240"
  },
  {
    "text": "they'll do everything they're just tools they're useful tools they create some",
    "start": "3144240",
    "end": "3149359"
  },
  {
    "text": "new capabilities some very powerful capabilities but we need to figure out how we incorporate those tools in the",
    "start": "3149359",
    "end": "3155280"
  },
  {
    "text": "software we're writing yeah and there was this scientist The Godfather of AI Dr Hinton right who was working at",
    "start": "3155280",
    "end": "3161240"
  },
  {
    "text": "Google and who left Google so that he could speak more freely about the dangers of AI and he mentioned that",
    "start": "3161240",
    "end": "3166319"
  },
  {
    "text": "within the next few years I forget how many I think it was 20 or so years forgive me but he says within the next",
    "start": "3166319",
    "end": "3171839"
  },
  {
    "text": "few years there's a 50/50 chance that artificial intelligence will be smarter",
    "start": "3171839",
    "end": "3177000"
  },
  {
    "text": "than human beings and if you listen to him speak it sounds like really dangerous and scary it sounds like and",
    "start": "3177000",
    "end": "3183960"
  },
  {
    "text": "he says you know the only instance in existence that we have where something",
    "start": "3183960",
    "end": "3190160"
  },
  {
    "text": "less capable controls something more capable is when a baby controls the",
    "start": "3190160",
    "end": "3196280"
  },
  {
    "text": "mother to feed it but like this is rare there's no other instance where something less capable control something",
    "start": "3196280",
    "end": "3202799"
  },
  {
    "text": "more capable and so his his theory is that in the next 20 or so years there's a 50/50 chance that we'll achieve ASI or",
    "start": "3202799",
    "end": "3209599"
  },
  {
    "text": "artificial super intelligence and this will be more capable than us therefore it will control us but I tend to not",
    "start": "3209599",
    "end": "3216319"
  },
  {
    "text": "agree with this very and and it's kind of stupid for me to like disagree with such a you established person right but",
    "start": "3216319",
    "end": "3222000"
  },
  {
    "text": "at this time in history there's like robotics is the bottleneck like so what if ASI controls us in a smart we just",
    "start": "3222000",
    "end": "3229280"
  },
  {
    "text": "like it can't really do anything in the physical world at this point in time and so yes maybe you know some systems will",
    "start": "3229280",
    "end": "3235079"
  },
  {
    "text": "go wrong and things will be deleted or whatever restaurants will be booked but we'll we'll recognize we messed up and",
    "start": "3235079",
    "end": "3240839"
  },
  {
    "text": "adjust it we always do we did like with the airline industry this was new and in when it was nent planes would literally",
    "start": "3240839",
    "end": "3246440"
  },
  {
    "text": "fall out of the sky there's so many incidents of like PanAm and km and Cath Pacific having all kinds of issues but",
    "start": "3246440",
    "end": "3252680"
  },
  {
    "text": "now it's the safest way to travel and I think that's part of the human story is",
    "start": "3252680",
    "end": "3257839"
  },
  {
    "text": "that we'll introduce the right safety measures and it'll it'll be okay we'll make mistakes along the way but I think",
    "start": "3257839",
    "end": "3262960"
  },
  {
    "text": "we'll we'll get there I also feel like there's a little bit around the development of AI that reminds me of",
    "start": "3262960",
    "end": "3268480"
  },
  {
    "text": "fusion in the sense that like people have been saying we're 5 to 10 years away from fusion power for the last 60",
    "start": "3268480",
    "end": "3276280"
  },
  {
    "text": "years and we maybe will'll get there but like it just keeps being there and I",
    "start": "3276280",
    "end": "3281960"
  },
  {
    "text": "feel like that has been true in the AI world as well people like oh my gosh we're going to match human intelligence",
    "start": "3281960",
    "end": "3287640"
  },
  {
    "text": "in the next 10 years and like you can find people saying that going back almost as far as there are computers",
    "start": "3287640",
    "end": "3293680"
  },
  {
    "text": "because I think part of it is you get so into thinking about these computers that you maybe don't realize the extent of",
    "start": "3293680",
    "end": "3300920"
  },
  {
    "text": "what actually happens in human intelligence like we do a lot more than next token prediction yeah although",
    "start": "3300920",
    "end": "3306960"
  },
  {
    "text": "although the thing that makes us human that sets us apart from lesser animals",
    "start": "3306960",
    "end": "3312119"
  },
  {
    "text": "is the prefrontal cortex is the activ is the center of the brain that literally literally just does predictions and and",
    "start": "3312119",
    "end": "3319319"
  },
  {
    "text": "based on those predictions will either you know will quiet down other circuits or raise their activity um will inhibit",
    "start": "3319319",
    "end": "3324599"
  },
  {
    "text": "or excite but like PR addictions are so crucial to The Human Experience and so I",
    "start": "3324599",
    "end": "3330520"
  },
  {
    "text": "think it's important to not undervalue that but also not overvalue it and so next token prediction is still",
    "start": "3330520",
    "end": "3336480"
  },
  {
    "text": "prediction you know on some level so we will see yeah I mean I I just I think my",
    "start": "3336480",
    "end": "3341839"
  },
  {
    "text": "personal opinion this is another example of our um ability to get fooled into",
    "start": "3341839",
    "end": "3347400"
  },
  {
    "text": "thinking s-curves are exponentials are there any things that you that we haven't talked about that",
    "start": "3347400",
    "end": "3353720"
  },
  {
    "text": "you would like to leave our listeners with yeah I I I I mean I work at data",
    "start": "3353720",
    "end": "3359359"
  },
  {
    "text": "stack so I'd love it if they check out our tools we make we make a vector database that's super useful for similarity search but I think one thing",
    "start": "3359359",
    "end": "3365640"
  },
  {
    "text": "that we make that not not enough people are hyped about as I am is something called Lang flow it's a low code and no",
    "start": "3365640",
    "end": "3371400"
  },
  {
    "text": "code builder for Rag and other gen workflows it's really cool so like you",
    "start": "3371400",
    "end": "3376680"
  },
  {
    "text": "you have this drag and drop style interface where you can generate rag pipelines and other things and it it makes these things more accessible this",
    "start": "3376680",
    "end": "3383119"
  },
  {
    "text": "is what I'm excited about right it's the democratization of gen it makes it more accessible to a wider net of people and",
    "start": "3383119",
    "end": "3389680"
  },
  {
    "text": "you know I was talking to swix Sean Wang the founder of small Ai and he mentioned dude it's like the internet just began",
    "start": "3389680",
    "end": "3396039"
  },
  {
    "text": "and there's a lot of work to be done and there's a lot of there's a lot of room at the table and so a lot of our work",
    "start": "3396039",
    "end": "3402520"
  },
  {
    "text": "ought to be spent on making this stuff accessible so that's what I'm really into that's what I would invite people",
    "start": "3402520",
    "end": "3408319"
  },
  {
    "text": "to do as well is is come and play and if there's questions you have and if there's support you need I'm here um Kevin you're here A bunch of us are you",
    "start": "3408319",
    "end": "3414799"
  },
  {
    "text": "know we've been around for a little bit bit longer and we're happy to support you absolutely yeah this stuff is going",
    "start": "3414799",
    "end": "3421839"
  },
  {
    "text": "fast but despite like all of the hype around how many people have tried it and",
    "start": "3421839",
    "end": "3426880"
  },
  {
    "text": "all these different things it's still very early days we haven't figured out how to use these things effectively in",
    "start": "3426880",
    "end": "3432839"
  },
  {
    "text": "very many instances I love this agent example that you have because it is concrete visible and it has clearly",
    "start": "3432839",
    "end": "3439880"
  },
  {
    "text": "accelerated your work and I think there's many many more opportunities out there so yeah let's let's close with",
    "start": "3439880",
    "end": "3445799"
  },
  {
    "text": "that of it's early days you can still get involved in this stuff I do think it is going to transform our industry so I",
    "start": "3445799",
    "end": "3451960"
  },
  {
    "text": "think the head in the sand approach is probably not the right one like if you're looking for what's your next learning thing maybe not the next front",
    "start": "3451960",
    "end": "3459280"
  },
  {
    "text": "end framework instead look at stately Ai and how you can interact with llms using",
    "start": "3459280",
    "end": "3464720"
  },
  {
    "text": "typescript yeah all right with that thank you Tas I'm kall and this has been",
    "start": "3464720",
    "end": "3471079"
  },
  {
    "text": "JS party catch youall next week",
    "start": "3471079",
    "end": "3475480"
  },
  {
    "text": "next up on the Pod Nick and Chris are joined by Josh Goldberg to discuss the",
    "start": "3481240",
    "end": "3487640"
  },
  {
    "text": "latest updates from es lint typescript eslint and the new flat config format",
    "start": "3487640",
    "end": "3493760"
  },
  {
    "text": "subscribe now if you haven't already head to JSP party. FM for all the ways",
    "start": "3493760",
    "end": "3499680"
  },
  {
    "text": "and if you're missing out on our weekly Chang log newsletter SLP podcast pop in your email address and join Jo 22,000",
    "start": "3499680",
    "end": "3507280"
  },
  {
    "text": "plus forward looking devs who keep up the easy way by letting me do it for them get in on it at Chang log.com",
    "start": "3507280",
    "end": "3516319"
  },
  {
    "text": "snews special thanks to our partners at fly.io and to our longtime sponsors",
    "start": "3516319",
    "end": "3522079"
  },
  {
    "text": "Sentry save 100 bucks off the team plan by using Code Chang log when you sign up",
    "start": "3522079",
    "end": "3527839"
  },
  {
    "text": "at sentry.io and of course thank you to break master cylinder our beat freaking residence I'm here for your sound needs",
    "start": "3527839",
    "end": "3535240"
  },
  {
    "text": "if you dig our beat do yourself a favor and type change log beats into Spotify Apple music or your favorite music",
    "start": "3535240",
    "end": "3542440"
  },
  {
    "text": "streaming platform thank me later that is all for now but come back and party",
    "start": "3542440",
    "end": "3548359"
  },
  {
    "text": "with us again next week [Music]",
    "start": "3548359",
    "end": "3561739"
  }
]
[
  {
    "text": "there are a ton of things that get me excited from a practical perspective one initiative that we are participating in",
    "start": "80",
    "end": "7520"
  },
  {
    "text": "is called met per the real world impact and real world improvements that we're going to see from this can be very",
    "start": "7520",
    "end": "14160"
  },
  {
    "text": "profound because it's about medical Ai and getting better performance estimates in medical AI is actually a very",
    "start": "14160",
    "end": "20160"
  },
  {
    "text": "fundamental challenge so that's something I'm quite keen on contributing",
    "start": "20160",
    "end": "26119"
  },
  {
    "text": "too big thanks to our partners Len fley and launch Darkly we love Leno they keep it fast and simple check them out at",
    "start": "27000",
    "end": "33559"
  },
  {
    "text": "lin.com changelog our bandwidth is provided by fastly learn more at fastly.com and get your feature Flags",
    "start": "33559",
    "end": "40480"
  },
  {
    "text": "powered by launch Darkly get a demo at launch dark.com this episode is brought to you by our friends at Rudder stack",
    "start": "40480",
    "end": "47399"
  },
  {
    "text": "and we're calling all data Engineers to check out ruter stack cloud and start building smart customer data pipelines Rudder stack is Warehouse first no more",
    "start": "47399",
    "end": "54879"
  },
  {
    "text": "silos rstack build your customer data Lake on your data warehouse not theirs enabling all functionality of a CDP with",
    "start": "54879",
    "end": "61960"
  },
  {
    "text": "more security and retaining full ownership of your data it's open source and API first R stack can be easily",
    "start": "61960",
    "end": "69080"
  },
  {
    "text": "integrated into your existing development processes and because they're open source you can see all their code so you don't have to worry",
    "start": "69080",
    "end": "75439"
  },
  {
    "text": "about vendor lock in or black boxes and best of all they have transparent pricing stop paying your CDP a premium",
    "start": "75439",
    "end": "81280"
  },
  {
    "text": "to store your data R stack is free up to 500,000 events and pricing scales transparently from there learn more and",
    "start": "81280",
    "end": "88240"
  },
  {
    "text": "get started at rack.com again ruter stack.com that's r u DD r s",
    "start": "88240",
    "end": "94360"
  },
  {
    "text": "a [Music]",
    "start": "94360",
    "end": "104680"
  },
  {
    "text": "k.com welcome to practical AI a weekly podcast that makes artificial intelligence practical productive and",
    "start": "105040",
    "end": "111960"
  },
  {
    "text": "accessible to everyone this is where conversations around AI machine learning and data science happen join the",
    "start": "111960",
    "end": "117960"
  },
  {
    "text": "community and slack with us around various topics of the show at kw.com community and follow us on Twitter we're",
    "start": "117960",
    "end": "123920"
  },
  {
    "text": "at practical [Music]",
    "start": "123920",
    "end": "130840"
  },
  {
    "text": "a well welcome to another episode of practical AI this is Daniel whack I'm a",
    "start": "130840",
    "end": "137200"
  },
  {
    "text": "data scientist with s International and I'm joined as always by my co-host Chris",
    "start": "137200",
    "end": "142599"
  },
  {
    "text": "Benson who is a tech strategist at Lockheed Martin how was your Thanksgiving Chris it was us",
    "start": "142599",
    "end": "148319"
  },
  {
    "text": "Thanksgiving for those listeners that aren't in the US might not be aware it was very good nice family stuff flew",
    "start": "148319",
    "end": "155280"
  },
  {
    "text": "around the plane things like that and now we're into the holiday season and uh",
    "start": "155280",
    "end": "160560"
  },
  {
    "text": "you know looking forward to uh to see what uh what kind of machine learning gifts are under the tree this year yes",
    "start": "160560",
    "end": "166800"
  },
  {
    "text": "well in the spirit of Distributing machine learning to all the boys and",
    "start": "166800",
    "end": "173360"
  },
  {
    "text": "girls maybe not by Santa but but a couple weeks ago you and I had a convers",
    "start": "173360",
    "end": "180000"
  },
  {
    "text": "ation about Federated learning now neither you or I is an expert in that",
    "start": "180000",
    "end": "186120"
  },
  {
    "text": "area or a practitioner in that area although I I think it was a good conversation but today we're privileged",
    "start": "186120",
    "end": "192360"
  },
  {
    "text": "to have uh Daniel boel with us who is one of the creators of flower which is",
    "start": "192360",
    "end": "197840"
  },
  {
    "text": "one of the the open source Federated learning Frameworks that we talked about he's a co-founder at adap and a visiting",
    "start": "197840",
    "end": "205239"
  },
  {
    "text": "researcher at University of Cambridge welcome Daniel thanks thanks for having",
    "start": "205239",
    "end": "210439"
  },
  {
    "text": "yeah well as you heard Chris and I were talking about Federated learning without",
    "start": "210439",
    "end": "215959"
  },
  {
    "text": "being experts in Federated learning so maybe to follow up on that conversation and maybe for people that didn't hear",
    "start": "215959",
    "end": "222400"
  },
  {
    "text": "that conversation could you just give us a a sketch of what Federated learning is",
    "start": "222400",
    "end": "229959"
  },
  {
    "text": "and then we can take it from there yeah of course I'm happy to so Federated learning is a way to train models across",
    "start": "229959",
    "end": "237560"
  },
  {
    "text": "multiple data sets that's the the very easy take on it so you might be",
    "start": "237560",
    "end": "242640"
  },
  {
    "text": "wondering how does this work the way you do it in in Federated learning and and let's just start off by giving an",
    "start": "242640",
    "end": "248680"
  },
  {
    "text": "example let's say we have for example a group of hospitals they have some",
    "start": "248680",
    "end": "254840"
  },
  {
    "text": "in-house data but due to regulations they cannot share this data and they cannot put this data in the cloud and",
    "start": "254840",
    "end": "261600"
  },
  {
    "text": "they can't use the usual machine learning workflow where you basically collect all of the data in a central",
    "start": "261600",
    "end": "267160"
  },
  {
    "text": "repository and then train your model on it so that's not an option for them um so they might",
    "start": "267160",
    "end": "273440"
  },
  {
    "text": "be interested in using Federated learning and how would a a Federated learning setup then then work in such a",
    "start": "273440",
    "end": "279560"
  },
  {
    "text": "scenario so the way it works is that you have your plain old machine learning model say it's a your network like for",
    "start": "279560",
    "end": "286479"
  },
  {
    "text": "example a CNN that does some kind of image classification maybe you want to look at Radiology images for example and",
    "start": "286479",
    "end": "294199"
  },
  {
    "text": "you would initialize this model in a central place let's call this the central server and the central server",
    "start": "294199",
    "end": "300919"
  },
  {
    "text": "would after initializing the model send this model out to all of the participating hospitals so it would send",
    "start": "300919",
    "end": "307520"
  },
  {
    "text": "the uninitialized model but there there are other variants of it just to say this for the sake of completeness but in",
    "start": "307520",
    "end": "313240"
  },
  {
    "text": "our initial example just to to explain the very basic version of it they would send out the initialized model so model",
    "start": "313240",
    "end": "320560"
  },
  {
    "text": "that hasn't learned anything yet the model would then be trained locally within each Hospital on the data that is",
    "start": "320560",
    "end": "328120"
  },
  {
    "text": "available locally so Hospital obviously has a different data set they would",
    "start": "328120",
    "end": "333199"
  },
  {
    "text": "train the model not not until convergence but they would only train it for a little while so let's say they",
    "start": "333199",
    "end": "339000"
  },
  {
    "text": "would train it for for one or two Epoch and after they trained the model for one or two Epoch they would send the updated",
    "start": "339000",
    "end": "345440"
  },
  {
    "text": "model parameters or the gradients that they accumulated back to the central server so that way they don't have to",
    "start": "345440",
    "end": "351240"
  },
  {
    "text": "share the data the data stays where it originated the data always stays within",
    "start": "351240",
    "end": "356319"
  },
  {
    "text": "each participating hospital and the central server would only give get the refined model parameters so the model",
    "start": "356319",
    "end": "361880"
  },
  {
    "text": "parameters that have been trained for one or two Epoch it would get that from all of the participating hospitals and",
    "start": "361880",
    "end": "368160"
  },
  {
    "text": "what the central server then does is it Aggregates those parameters in the simplest version it just does a weighted",
    "start": "368160",
    "end": "374479"
  },
  {
    "text": "average over these parameters what I just described is a way of initializing mod sending it out training it locally",
    "start": "374479",
    "end": "381039"
  },
  {
    "text": "collecting the updated parameters and then aggregating the parameters that is one single round of Federated learning",
    "start": "381039",
    "end": "388039"
  },
  {
    "text": "and then what you usually do is you perform these rounds over and over again until the model converges and the",
    "start": "388039",
    "end": "393880"
  },
  {
    "text": "interesting part about it is why organizations actually do this is they get access to a lot more data than they",
    "start": "393880",
    "end": "401400"
  },
  {
    "text": "had before so we've probably all had this experience especially in Practical AI project that often times there is",
    "start": "401400",
    "end": "409000"
  },
  {
    "text": "just not enough data and having more data beats any fancy model architecture",
    "start": "409000",
    "end": "414120"
  },
  {
    "text": "so in this case Federated learning solves this data access problem they can collaborate on the model training",
    "start": "414120",
    "end": "419680"
  },
  {
    "text": "without having to share the underlying training data yeah that's Su just of it that's a good explanation it's much",
    "start": "419680",
    "end": "425319"
  },
  {
    "text": "better than the one we were trying a few weeks ago yeah we should link this episode to that one because it took us",
    "start": "425319",
    "end": "432000"
  },
  {
    "text": "half an hour to get there we just need to voice over what he just said to what we said you totally yeah I mean left out",
    "start": "432000",
    "end": "439280"
  },
  {
    "text": "a ton of detail right I get it but we can ask you questions and find out what",
    "start": "439280",
    "end": "444800"
  },
  {
    "text": "some of that is and looking forward to that so as a starter it's very clear given the data is distributed in terms",
    "start": "444800",
    "end": "451960"
  },
  {
    "text": "of where it's located and given laws and regulations and other such things that",
    "start": "451960",
    "end": "457840"
  },
  {
    "text": "may constrain the training process with privacy concerns and stuff it's very",
    "start": "457840",
    "end": "463199"
  },
  {
    "text": "clear what the advantage is in Federated learning what also might be considered some disadvantages or maybe another way",
    "start": "463199",
    "end": "470520"
  },
  {
    "text": "of asking it is when you do consolidate the model after you've done the Federated learning and stuff what is the",
    "start": "470520",
    "end": "477000"
  },
  {
    "text": "delta in a train model versus if you had not done that if you had been able to to aggregate kind of in the traditional way",
    "start": "477000",
    "end": "483560"
  },
  {
    "text": "all the data into one spot and train it in the traditional way we've done before Federated learning what's the difference",
    "start": "483560",
    "end": "489080"
  },
  {
    "text": "in what you get as an output you know or is there much of one yeah there is a difference um the biggest difference I",
    "start": "489080",
    "end": "495720"
  },
  {
    "text": "shall say is obviously in convergence time because you have these rounds of communication and also the averaging",
    "start": "495720",
    "end": "502039"
  },
  {
    "text": "process has some some impact there often as researchers we make these comparisons",
    "start": "502039",
    "end": "507479"
  },
  {
    "text": "between centralized learning and Federated aspects of it the interesting bit is that this comparison is somewhat",
    "start": "507479",
    "end": "514839"
  },
  {
    "text": "artificial um because it's not something that one would face in reality very",
    "start": "514839",
    "end": "520000"
  },
  {
    "text": "often it's either Federated learning or nothing we've seen this in the past",
    "start": "520000",
    "end": "525120"
  },
  {
    "text": "right if we look a little bit at the journey that machine learning and deep learning now now took is the somewhere",
    "start": "525120",
    "end": "531480"
  },
  {
    "text": "around 2012 we really realize that by making these models bigger we suddenly",
    "start": "531480",
    "end": "536880"
  },
  {
    "text": "get better accuracy so there was this this image met net moment and then a couple of other moments like this um",
    "start": "536880",
    "end": "543000"
  },
  {
    "text": "afterwards and we saw that we can achieve ever greater accuracy and and then other performance metrics with",
    "start": "543000",
    "end": "549680"
  },
  {
    "text": "these models and the thing is we always when we when we read a research paper",
    "start": "549680",
    "end": "554880"
  },
  {
    "text": "for example and when we look at these recent advances it's often quite fascinating and it's often in the",
    "start": "554880",
    "end": "561160"
  },
  {
    "text": "context of webscale companies like in Google or Facebook who have these massive amounts of data inhouse but then",
    "start": "561160",
    "end": "568240"
  },
  {
    "text": "often in practice there this realization that okay I'm I read about this cool technique I'm trying to apply to my",
    "start": "568240",
    "end": "575079"
  },
  {
    "text": "problem and suddenly I don't get the amazing results that I expected to have so the question is what what happened",
    "start": "575079",
    "end": "581240"
  },
  {
    "text": "right and in many cases the answer is really that the amount of data and the",
    "start": "581240",
    "end": "586440"
  },
  {
    "text": "diversity that that you have in your local data set is just not enough and the interesting thing and and the thing",
    "start": "586440",
    "end": "592560"
  },
  {
    "text": "that got us very interested in Federated learning was this realization that for",
    "start": "592560",
    "end": "597760"
  },
  {
    "text": "many of those cases you might not have a large data set on your own but there are",
    "start": "597760",
    "end": "603600"
  },
  {
    "text": "a lot of others just like you who are facing the same Challenge and who might",
    "start": "603600",
    "end": "608920"
  },
  {
    "text": "want to train the same model but they also have some data but not enough data for a very good model I mean we could",
    "start": "608920",
    "end": "615839"
  },
  {
    "text": "obviously solve this if we could put all of this data in in a just in a single destination in a single cloud account",
    "start": "615839",
    "end": "622160"
  },
  {
    "text": "and then trade a model on it but that's something that just doesn't happen it doesn't happen for regulatory reasons it",
    "start": "622160",
    "end": "628839"
  },
  {
    "text": "doesn't happen for confidentiality reasons for example corporations they have a lot of",
    "start": "628839",
    "end": "634000"
  },
  {
    "text": "financial data and they might want to have models that prject predict certain aspects about these data but again it's",
    "start": "634000",
    "end": "640600"
  },
  {
    "text": "it's it's a thing of confidentiality it's something they would never share and the types of use cases that",
    "start": "640600",
    "end": "646480"
  },
  {
    "text": "Federated learning gets used for sometimes we are surprised ourselves and where exactly these companies are",
    "start": "646480",
    "end": "652880"
  },
  {
    "text": "hesitant to share data for example there was one case where a couple of manufacturing companies they all",
    "start": "652880",
    "end": "659480"
  },
  {
    "text": "operating the same manufacturing machine and they want to train a model that does predictive maintenance basically for",
    "start": "659480",
    "end": "665600"
  },
  {
    "text": "this machine to predict whether this machine is likely going to fail so whether they need to do some manual",
    "start": "665600",
    "end": "670880"
  },
  {
    "text": "maintenance or something like that and one would think that this is a case where they could just collaborate and",
    "start": "670880",
    "end": "676440"
  },
  {
    "text": "they could just put all of their machine sensory data in a cloud account and train a a predictive maintenance model",
    "start": "676440",
    "end": "681639"
  },
  {
    "text": "no they don't why don't they collaborate um on this well the reason is that the",
    "start": "681639",
    "end": "686959"
  },
  {
    "text": "data that they have from running these machine could allow others to see how often they run these machines which",
    "start": "686959",
    "end": "693079"
  },
  {
    "text": "could allow others to draw some conclusions about how many parts they're producing which is highly confidential",
    "start": "693079",
    "end": "699360"
  },
  {
    "text": "so even in those seemingly easy cases in reality it's not that easy so that's",
    "start": "699360",
    "end": "704720"
  },
  {
    "text": "almost a perfect leading for what I wanted to ask next is that Federated learning it sounds like offers different",
    "start": "704720",
    "end": "711680"
  },
  {
    "text": "business models from maybe some of the things we've done in the past or even among competitors directly cooperating",
    "start": "711680",
    "end": "718200"
  },
  {
    "text": "so have you you seen this start to happen yet or maybe maybe consortiums come into being and they may include",
    "start": "718200",
    "end": "724680"
  },
  {
    "text": "direct competitors who are all in the same line of business they want to protect their data so that they don't give away competitive intelligence and",
    "start": "724680",
    "end": "731760"
  },
  {
    "text": "Federated learning through a Consortium or some other structure similar to that might be a way to everyone benefit from",
    "start": "731760",
    "end": "738880"
  },
  {
    "text": "that and get the new model without giving away the secret sauce so to speak do you expect to see more of that kind",
    "start": "738880",
    "end": "745680"
  },
  {
    "text": "of thing we are sort of seeing this um the way it usually starts out is that",
    "start": "745680",
    "end": "750720"
  },
  {
    "text": "organizations who are maybe not direct competitors maybe they are somewhat in",
    "start": "750720",
    "end": "755800"
  },
  {
    "text": "the same space but they're not um like like the toughest competitors they start to get together yeah in some cases it",
    "start": "755800",
    "end": "762519"
  },
  {
    "text": "can even be the suborganizations of a larger Enterprise for example because they are also often facing these",
    "start": "762519",
    "end": "769519"
  },
  {
    "text": "restrictions for sharing data but then we also see that sometimes even real really strong competitors they get",
    "start": "769519",
    "end": "776120"
  },
  {
    "text": "together because they see something else as a threat to their business model and they see that this is an a way to to",
    "start": "776120",
    "end": "783160"
  },
  {
    "text": "collaborate without sharing this as you call the secret source and the interesting bit is that the way I",
    "start": "783160",
    "end": "789360"
  },
  {
    "text": "described Federated learning in the beginning this is really end to endend Federated learning where you initialize the model just globally and then you",
    "start": "789360",
    "end": "796880"
  },
  {
    "text": "train the model end to end with all participating parties this is not the only model that's possible right I want",
    "start": "796880",
    "end": "803040"
  },
  {
    "text": "to describe one which I think is quite interesting um especially for this case where you have sort of competing",
    "start": "803040",
    "end": "809600"
  },
  {
    "text": "organizations collaborating and it's one where you train a certain part of the model in a Federated fashion across",
    "start": "809600",
    "end": "816320"
  },
  {
    "text": "multiple data sets and then other parts of the model you just train it yourself on your local data so this is pretty",
    "start": "816320",
    "end": "822720"
  },
  {
    "text": "interesting because you can in such a federation you can for example train the entire backbone of a model but then the",
    "start": "822720",
    "end": "829519"
  },
  {
    "text": "last few layers the head of the model you don't train this in a Federated fashion you leave that up to each of the",
    "start": "829519",
    "end": "835720"
  },
  {
    "text": "participating organizations to do it themselves so everyone ends up with a similar yet different model and everyone",
    "start": "835720",
    "end": "843360"
  },
  {
    "text": "has something where they say okay we benefit from this Federation but we are not giving away everything one important",
    "start": "843360",
    "end": "849720"
  },
  {
    "text": "thing to mention though is that there are different types of Federated learning so you can roughly categorize",
    "start": "849720",
    "end": "855920"
  },
  {
    "text": "it into two different types one is this cross Silo type that we just talked about where different organizations",
    "start": "855920",
    "end": "862759"
  },
  {
    "text": "collaborate with each other the other type that we often see also in the scientific literature is the cross",
    "start": "862759",
    "end": "869759"
  },
  {
    "text": "device setting where you would usually typically you would have one Organization for example think about",
    "start": "869759",
    "end": "876279"
  },
  {
    "text": "Google or Apple for example and this organization would have access to a large number of devices for example",
    "start": "876279",
    "end": "883399"
  },
  {
    "text": "mobile devices like an Android phones or iOS phones and the goal in this case is also to train a model to train a model",
    "start": "883399",
    "end": "889920"
  },
  {
    "text": "across all of these devices and these devices they hold data that is also where you wouldn't want to upload this",
    "start": "889920",
    "end": "895680"
  },
  {
    "text": "data to the cloud so this is the cross device setting where a single organization trains these models without",
    "start": "895680",
    "end": "902519"
  },
  {
    "text": "access to the underlying trading",
    "start": "902519",
    "end": "905959"
  },
  {
    "text": "[Music]",
    "start": "910820",
    "end": "913940"
  },
  {
    "text": "[Music]",
    "start": "917540",
    "end": "920769"
  },
  {
    "text": "data this episode is brought to you by Me Myself and AI it's a podcast on",
    "start": "922880",
    "end": "928319"
  },
  {
    "text": "artificial intell Ence and business and it's produced by our friends at MIT slow management review and Boston Consulting",
    "start": "928319",
    "end": "934319"
  },
  {
    "text": "Group the question is why do only 10% of company succeed with artificial intelligence that's the question they",
    "start": "934319",
    "end": "940279"
  },
  {
    "text": "aim to answer with this podcast here's Google Cloud's will granis on an unusual AI challenge when I think about what AI",
    "start": "940279",
    "end": "947680"
  },
  {
    "text": "is I find the algorithms mathematically fascinating but I find the use of the algorithms far more fascinating because",
    "start": "947680",
    "end": "954079"
  },
  {
    "text": "from a technical perspective we're finding correlations and extremely high dimensional nonlinear spaces it's",
    "start": "954079",
    "end": "961040"
  },
  {
    "text": "statistics at scale in some sense right we're finding these correlations between a and b and those algorithms are are",
    "start": "961040",
    "end": "966800"
  },
  {
    "text": "really interesting and I'm still teaching those now and they're fun but what's more interesting to me is what do",
    "start": "966800",
    "end": "972319"
  },
  {
    "text": "those correlations mean for the people all right me myself in AI is a collaboration between MIT slow management review and Boston Consulting",
    "start": "972319",
    "end": "978920"
  },
  {
    "text": "Group it's available wherever you get your podcast just search Me Myself and",
    "start": "978920",
    "end": "985160"
  },
  {
    "text": "AI [Music]",
    "start": "987920",
    "end": "996149"
  },
  {
    "text": "So Daniel you I think we've mostly talked about some of the kind of data",
    "start": "1004319",
    "end": "1011040"
  },
  {
    "text": "Centric motivations for Federated learning or maybe privacy Focus or whatever it is competitive type of",
    "start": "1011040",
    "end": "1017680"
  },
  {
    "text": "advantages but but I'm also thinking of like the devices on which the actual",
    "start": "1017680",
    "end": "1023639"
  },
  {
    "text": "training is happening so like if I'm thinking of the centralized model I'm thinking of like oh I'm going to spin up",
    "start": "1023639",
    "end": "1029839"
  },
  {
    "text": "like a pod of gpus and a really expensive pod of gpus and do like all my",
    "start": "1029839",
    "end": "1036120"
  },
  {
    "text": "training there and and get my data there somehow so am I correct that you could",
    "start": "1036120",
    "end": "1041760"
  },
  {
    "text": "have some sort of infrastructure savings with this where the actual computation",
    "start": "1041760",
    "end": "1046798"
  },
  {
    "text": "is happening on those those Edge devices and you're doing a smaller amount of",
    "start": "1046799",
    "end": "1052000"
  },
  {
    "text": "aggregation and updating of the model centrally could you talk to that a little bit and what what people have",
    "start": "1052000",
    "end": "1057080"
  },
  {
    "text": "seen and how they look at infrastructure in that in that way yes that's a very interesting question the answer is as",
    "start": "1057080",
    "end": "1063520"
  },
  {
    "text": "almost always in the engineering it depends so um as as you noted correctly",
    "start": "1063520",
    "end": "1068720"
  },
  {
    "text": "in the centralized setting you have a pretty well- defined stack that uh that",
    "start": "1068720",
    "end": "1074760"
  },
  {
    "text": "there there's not a lot that changes from one setup to another you usually have some kind of x86 processor and then",
    "start": "1074760",
    "end": "1081480"
  },
  {
    "text": "you have a usually you have a g Nvidia GPU attached to that you have Linux running on that machine and then the",
    "start": "1081480",
    "end": "1087559"
  },
  {
    "text": "biggest choice you have is whether to use tensorflow P torch or or Jacks nowadays in the Federated setting that's",
    "start": "1087559",
    "end": "1093919"
  },
  {
    "text": "quite different in the Federate setting you can have anything as a client starting from a even a tiny embedded",
    "start": "1093919",
    "end": "1101120"
  },
  {
    "text": "device there's research going on in that direction then you can have something like an Apple Watch or a mobile phone or",
    "start": "1101120",
    "end": "1108280"
  },
  {
    "text": "you can have some bigger device like a tablet or a laptop you can have your standard x86 server that I just",
    "start": "1108280",
    "end": "1114720"
  },
  {
    "text": "described or you can even have a much larger compute cluster if you're in the cross Silo setting where you have a ton",
    "start": "1114720",
    "end": "1121159"
  },
  {
    "text": "of data and one of these organizations has massive inhouse infastructure you can have a HPC cluster as a client so",
    "start": "1121159",
    "end": "1129039"
  },
  {
    "text": "this is obviously quite interesting and also challenging from an infrastructure and just um software perspective in some",
    "start": "1129039",
    "end": "1136240"
  },
  {
    "text": "cases you can actually and there is some recent research for example from from",
    "start": "1136240",
    "end": "1142039"
  },
  {
    "text": "the group in in Cambridge that I'm involved with about the CO2 impact of these workloads comparing for example",
    "start": "1142039",
    "end": "1147960"
  },
  {
    "text": "the CO2 impact and this obviously quite related to your question about the CO2 impact of Federated workloads versus",
    "start": "1147960",
    "end": "1154760"
  },
  {
    "text": "Central workloads and the interesting bit is that it's not you can't say it in general I actually it's quite an",
    "start": "1154760",
    "end": "1161280"
  },
  {
    "text": "interesting thing because I originally expected Federated learning to do much worse because you have these",
    "start": "1161280",
    "end": "1167520"
  },
  {
    "text": "communication rounds and it takes longer to converge so obviously it must have a higher CO2 impact it turned out that",
    "start": "1167520",
    "end": "1173840"
  },
  {
    "text": "that's not necessarily the case because in some situations the reason is once you hear it it's it's quite obvious but",
    "start": "1173840",
    "end": "1180400"
  },
  {
    "text": "it was surprising to me in the central setting you have the major impact on uh",
    "start": "1180400",
    "end": "1186000"
  },
  {
    "text": "the CO2 emissions is the cooling so you have active cooling of your GPU clusters",
    "start": "1186000",
    "end": "1191600"
  },
  {
    "text": "in the Federated setting you don't necessarily have cooling you have additional cost for communication but",
    "start": "1191600",
    "end": "1197760"
  },
  {
    "text": "then if you have a mobile Edge device these Edge devices they are usually passively cooled so they are running the",
    "start": "1197760",
    "end": "1203520"
  },
  {
    "text": "workload and they produce the result um without um ever needing energy for cooling so that can be quite good but",
    "start": "1203520",
    "end": "1211200"
  },
  {
    "text": "obviously it depends a lot on the workload the type of model you train and the number of communication rounds you",
    "start": "1211200",
    "end": "1216480"
  },
  {
    "text": "do and and other aspects in terms of infrastructure cost this sort of answers",
    "start": "1216480",
    "end": "1221760"
  },
  {
    "text": "this question as well because you can have in some cases if you have for example the cross device setting then",
    "start": "1221760",
    "end": "1227720"
  },
  {
    "text": "obviously if you're not the one operating these devices then you don't have to pay for the energy that that",
    "start": "1227720",
    "end": "1233159"
  },
  {
    "text": "goes into training usually um when companies do this they're very careful about it they do it in a very careful",
    "start": "1233159",
    "end": "1239559"
  },
  {
    "text": "way so they wait until the device is plugged in until the device is connected to Wi-Fi until it's fully charged and",
    "start": "1239559",
    "end": "1246000"
  },
  {
    "text": "idle and only then um they do the Federated learning to not impact user experience or not to not drain the",
    "start": "1246000",
    "end": "1252080"
  },
  {
    "text": "battery or things like that in the cross Silo setting there's I wouldn't say that there much of a difference in terms of",
    "start": "1252080",
    "end": "1258320"
  },
  {
    "text": "INF infastructure you need well each company needs the infrastructure they would need anyways and then you need one",
    "start": "1258320",
    "end": "1264960"
  },
  {
    "text": "additional server so that's pretty similar especially in the crosso setting where you often have large models you do",
    "start": "1264960",
    "end": "1271279"
  },
  {
    "text": "have a lot of network bandwidth that you need so that's something that you should consider you talked a little bit about",
    "start": "1271279",
    "end": "1277960"
  },
  {
    "text": "the training time you talked a little bit about what's happening on the device I think what's happening in the back of",
    "start": "1277960",
    "end": "1283200"
  },
  {
    "text": "my mind as I'm thinking like okay I've got all of these devices and there's sort of various axes along which they",
    "start": "1283200",
    "end": "1288799"
  },
  {
    "text": "could change right I I could have like the computational power of that edge device or the client and then I've got",
    "start": "1288799",
    "end": "1295720"
  },
  {
    "text": "also like the number of samples that are available for training on that device I'm thinking if and maybe you could",
    "start": "1295720",
    "end": "1302480"
  },
  {
    "text": "speak to this I'm thinking like in the scenario of like a low power Edge device or a phone like I'm going to have very",
    "start": "1302480",
    "end": "1309720"
  },
  {
    "text": "few samples which might be a sort of quick update on that device of the model",
    "start": "1309720",
    "end": "1316360"
  },
  {
    "text": "and communicate the parameters back whereas like as the kind of amount of data that you",
    "start": "1316360",
    "end": "1322480"
  },
  {
    "text": "have on the client is larger you sort of need more computational power at least more time to do the update is that kind",
    "start": "1322480",
    "end": "1329600"
  },
  {
    "text": "of how that tradeoff happens in practice yes absolutely I mean yeah obviously if",
    "start": "1329600",
    "end": "1335600"
  },
  {
    "text": "you have more data on a device you need more time to train the model on the data but this is actually also a very",
    "start": "1335600",
    "end": "1341480"
  },
  {
    "text": "interesting aspect not just in terms of practical things like communication bandwidth and so on but it's also quite",
    "start": "1341480",
    "end": "1348200"
  },
  {
    "text": "interesting in from a more fundamental perspective namely in the both in the",
    "start": "1348200",
    "end": "1353600"
  },
  {
    "text": "cross device setting and in the cross Silo setting usually the data in these partitions as we like to call them the",
    "start": "1353600",
    "end": "1360039"
  },
  {
    "text": "data in these partitions is coming from different distributions so it's what we like to call it non-id data and this",
    "start": "1360039",
    "end": "1367480"
  },
  {
    "text": "actually has a has an impact on the learning um process there are certain scenarios which are very rare in in",
    "start": "1367480",
    "end": "1374720"
  },
  {
    "text": "Practical setting but there are scenarios actually where the data distribution with in each partition can",
    "start": "1374720",
    "end": "1379919"
  },
  {
    "text": "be so different that it's just not possible that these workloads converge and this is something where where a lot",
    "start": "1379919",
    "end": "1385400"
  },
  {
    "text": "of research is going on on how to make a Federated learning more robust towards",
    "start": "1385400",
    "end": "1390679"
  },
  {
    "text": "such scenarios and yeah the Practical aspects of it are also quite interesting because if you have multiple clients in",
    "start": "1390679",
    "end": "1398200"
  },
  {
    "text": "the same workload one of these clients just has very few data examples and another client has tons of data examples",
    "start": "1398200",
    "end": "1405200"
  },
  {
    "text": "for example we all know that one type of person that takes very few photos when they're on vacation and we all know that",
    "start": "1405200",
    "end": "1412279"
  },
  {
    "text": "are the type of person who takes a ton of photos when they're on vacation so this is a a very practical example for",
    "start": "1412279",
    "end": "1418360"
  },
  {
    "text": "different amounts of data on each device in such a scenario when you instruct a",
    "start": "1418360",
    "end": "1424159"
  },
  {
    "text": "client to do for example one epoc on their data then obviously this one client will be the update will be coming",
    "start": "1424159",
    "end": "1430840"
  },
  {
    "text": "back much much faster so what you want to have in your entire system is some",
    "start": "1430840",
    "end": "1436360"
  },
  {
    "text": "robustness towards clients who either take a very long time because they have so much data or towards even real",
    "start": "1436360",
    "end": "1442640"
  },
  {
    "text": "stragglers who I don't know maybe the device is suddenly get getting busy with other things which delays the update",
    "start": "1442640",
    "end": "1449039"
  },
  {
    "text": "coming back so this is something where your software infrastructure needs to be able to handle these kinds of cases and",
    "start": "1449039",
    "end": "1455640"
  },
  {
    "text": "it's also something where you need appropriate ways of handling it on the",
    "start": "1455640",
    "end": "1461039"
  },
  {
    "text": "server side so the one obvious or or the one the easiest thing to do is obviously to discard those clients that are taking",
    "start": "1461039",
    "end": "1468640"
  },
  {
    "text": "a long time that are strugglers but then there are more clever ways to approach this for example to let this client know",
    "start": "1468640",
    "end": "1474520"
  },
  {
    "text": "hey your time is running out we are about to close the around why don't you submit your partial update but then your",
    "start": "1474520",
    "end": "1480679"
  },
  {
    "text": "server side and the aggregation logic it needs to be able to handle those partial updates coming from clients so Daniel",
    "start": "1480679",
    "end": "1487399"
  },
  {
    "text": "you've talked a little bit about like certain client devices being stragglers",
    "start": "1487399",
    "end": "1492960"
  },
  {
    "text": "from one perspective but I'm curious in terms of how the Federated learning",
    "start": "1492960",
    "end": "1498480"
  },
  {
    "text": "Community is thinking about things like bias and data so like if I'm a data",
    "start": "1498480",
    "end": "1503559"
  },
  {
    "text": "scientist in like a central location I'm seeing maybe updates to my model but I'm",
    "start": "1503559",
    "end": "1509200"
  },
  {
    "text": "not seeing the data that is producing those updates to the weights and biases",
    "start": "1509200",
    "end": "1514640"
  },
  {
    "text": "of of my model so if there's bias in terms of those in client devices like",
    "start": "1514640",
    "end": "1520679"
  },
  {
    "text": "maybe 97% of my client devices are being operated by males and I I have some",
    "start": "1520679",
    "end": "1526559"
  },
  {
    "text": "gender bias in the data that that's coming back are there ways that the community is thinking about that and",
    "start": "1526559",
    "end": "1532360"
  },
  {
    "text": "ways to address that sort of I guess maybe maybe there's a term for it I'm thinking of it like client bias yeah any",
    "start": "1532360",
    "end": "1538640"
  },
  {
    "text": "thoughts there yes absolutely it's a very good question and it's it's a very important question there are different",
    "start": "1538640",
    "end": "1545000"
  },
  {
    "text": "ways to think about it one way is or or one approach that one topic that the community thinks about a lot is how to",
    "start": "1545000",
    "end": "1551320"
  },
  {
    "text": "address that from an a rithmic perspective so there are approaches for example qair Federated learning that",
    "start": "1551320",
    "end": "1557880"
  },
  {
    "text": "tackle this from an algorithmic perspective so when you collect updates you can do this in a certain way and you",
    "start": "1557880",
    "end": "1564120"
  },
  {
    "text": "can try for example there many different approaches but one thing you could do is you could try to address that for",
    "start": "1564120",
    "end": "1570000"
  },
  {
    "text": "example through the aaging process it's a weighted averaging so there are ways to influence this another perspective is",
    "start": "1570000",
    "end": "1577200"
  },
  {
    "text": "more from a more intuitive and more practical perspective in the sense that you can think of faged learning as a way",
    "start": "1577200",
    "end": "1585640"
  },
  {
    "text": "compared to centralized learning to actually over come bias because you can over not overcome it completely but um",
    "start": "1585640",
    "end": "1592360"
  },
  {
    "text": "that's what not not what I mean but help to overcome it in the sense that you can suddenly get access to more training",
    "start": "1592360",
    "end": "1598840"
  },
  {
    "text": "data and hopefully more representative training data and then you can make better decisions about how to train your",
    "start": "1598840",
    "end": "1605279"
  },
  {
    "text": "model and what kind of pieces of data to include in your training process how to",
    "start": "1605279",
    "end": "1610440"
  },
  {
    "text": "sample these data examples that you have on the clients and a lot of those related",
    "start": "1610440",
    "end": "1616960"
  },
  {
    "text": "questions [Music]",
    "start": "1617240",
    "end": "1625480"
  },
  {
    "text": "earlier in the show you heard a teaser from our friends behind the podcast Me Myself and Ai and my slow management",
    "start": "1625480",
    "end": "1631480"
  },
  {
    "text": "review and Boston Consulting Group came together to produce this awesome podcast and every episode host Sam and Sherin",
    "start": "1631480",
    "end": "1637799"
  },
  {
    "text": "talk to leaders that are engaged in the theory and the practice of AI I remember one project we had we were uh training a",
    "start": "1637799",
    "end": "1646000"
  },
  {
    "text": "chatbot and it turned out we used raw you know logs all privacy assured and everything but we used these uh logs",
    "start": "1646000",
    "end": "1652679"
  },
  {
    "text": "that a customer had provided because they wanted to see if we could build a better model and it turns out that the",
    "start": "1652679",
    "end": "1658120"
  },
  {
    "text": "chat agent wasn't exactly speaking the way we'd want another human being to speak to us and why because people get",
    "start": "1658120",
    "end": "1665200"
  },
  {
    "text": "pretty upset when they're talking to customer support and the language that",
    "start": "1665200",
    "end": "1671000"
  },
  {
    "text": "they use isn't necessarily language I think we would use with each other uh you know on this podcast all right me",
    "start": "1671000",
    "end": "1677080"
  },
  {
    "text": "myself and I as a collab between MIT slow management review and Boston Consulting Group it's available wherever",
    "start": "1677080",
    "end": "1682440"
  },
  {
    "text": "you get your podcast just search Me Myself and [Music]",
    "start": "1682440",
    "end": "1707120"
  },
  {
    "text": "AI",
    "start": "1707120",
    "end": "1710120"
  },
  {
    "text": "well Daniel this is practical AI so we definitely should get into the practicalities of how Federated learning",
    "start": "1712159",
    "end": "1719880"
  },
  {
    "text": "can be implemented and I think you're you're probably one of the better people to speak to that because you've been",
    "start": "1719880",
    "end": "1726120"
  },
  {
    "text": "heavily involved and one of the creators of the flower framework so maybe just to",
    "start": "1726120",
    "end": "1731519"
  },
  {
    "text": "to start out our discussion around that could you talk about kind of the backstory of flower the motivation",
    "start": "1731519",
    "end": "1738159"
  },
  {
    "text": "behind it and and what it is yeah absolutely trying to do my best so when we started out on this journey we",
    "start": "1738159",
    "end": "1744960"
  },
  {
    "text": "obviously we got excited about fed learning for the reasons I was stating earlier so we we were actually in real",
    "start": "1744960",
    "end": "1751919"
  },
  {
    "text": "industry projects we were facing these challenges where we saw that the data these organizations had in house was",
    "start": "1751919",
    "end": "1758200"
  },
  {
    "text": "just not enough but we saw that there were other organizations who had similar challenges and and we saw the potential",
    "start": "1758200",
    "end": "1764519"
  },
  {
    "text": "to build collaborative approaches there and the only way to do this these kinds of collaborations would be the only way",
    "start": "1764519",
    "end": "1770919"
  },
  {
    "text": "that would be feasible would be if the underlying Trader daing would not have to be shared this was sort of the",
    "start": "1770919",
    "end": "1776720"
  },
  {
    "text": "setting that we were in when we first looked at Federated learning and at the time we obviously looked at our",
    "start": "1776720",
    "end": "1782399"
  },
  {
    "text": "Solutions but there wasn't really a solution that was a really good fit for our requirements one of our requirements",
    "start": "1782399",
    "end": "1789120"
  },
  {
    "text": "was obviously because we were coming from this we were looking at these practical problems was that we could",
    "start": "1789120",
    "end": "1795039"
  },
  {
    "text": "build a system that we can then at a later Point move move into production so obviously you you would start out with",
    "start": "1795039",
    "end": "1800600"
  },
  {
    "text": "some prototyping and see if you could get such a workload to converge but then at a later point if you cannot move this",
    "start": "1800600",
    "end": "1807080"
  },
  {
    "text": "in production then why would you invest in this right so this was one of our hard requirements and then for moving a",
    "start": "1807080",
    "end": "1814039"
  },
  {
    "text": "Federated learning or Federated analytics workload into production there are a ton of associated challenges with",
    "start": "1814039",
    "end": "1821640"
  },
  {
    "text": "that I was hitting at the the this large heterogeneity that we see on the client side so being able to integrate with an",
    "start": "1821640",
    "end": "1828200"
  },
  {
    "text": "device mobile device server HBC cluster this is something we thought was higher on our priority list so at the time we",
    "start": "1828200",
    "end": "1835399"
  },
  {
    "text": "didn't really see any solution that that was a fit to the requirements that we",
    "start": "1835399",
    "end": "1840799"
  },
  {
    "text": "had we sort of had to shift our focus a little bit away from building this one particular system that we had in mind",
    "start": "1840799",
    "end": "1846840"
  },
  {
    "text": "and we we shifted a focus away to first building the infrastructure that we had in mind for it out of that we build a",
    "start": "1846840",
    "end": "1853480"
  },
  {
    "text": "prototype for that and then out of that prototype we gathered a lot of learning sub viously and eventually at the",
    "start": "1853480",
    "end": "1859880"
  },
  {
    "text": "beginning of last year tner my co-founder and I we said um okay let's start a company and build this",
    "start": "1859880",
    "end": "1865799"
  },
  {
    "text": "infrastructure to bring these advances that we see and this huge potential um to make this really accessible for",
    "start": "1865799",
    "end": "1871720"
  },
  {
    "text": "others to use as well the flower framework is probably obvious by now that that one of the reasons um the",
    "start": "1871720",
    "end": "1877320"
  },
  {
    "text": "flower framework is there is that we want to enable everyone to build such",
    "start": "1877320",
    "end": "1882480"
  },
  {
    "text": "work laws because there's a lot of details going on under the hood that are not easy to implement and if you just",
    "start": "1882480",
    "end": "1888840"
  },
  {
    "text": "want to do Federated learning it would obviously be a a huge hurdle for others to First build this infrastructure",
    "start": "1888840",
    "end": "1895320"
  },
  {
    "text": "before they then can build their actual workload we wanted to make this easy we wanted to make it easy to start in",
    "start": "1895320",
    "end": "1901320"
  },
  {
    "text": "research and then gradually enhance this workloads and move them to to production eventually and then to operate them in",
    "start": "1901320",
    "end": "1907480"
  },
  {
    "text": "production this is also something we we haven't quite seen in other Frameworks other Frameworks that we've seen are",
    "start": "1907480",
    "end": "1912600"
  },
  {
    "text": "usually um focused on one thing for example focused on being a good simulation engine but then you can't",
    "start": "1912600",
    "end": "1918919"
  },
  {
    "text": "take these workloads and move them into production and the other opportunity that we saw and this is part of this",
    "start": "1918919",
    "end": "1924559"
  },
  {
    "text": "user Journey making it easy to start prototype something is the opportunity to be compatible with all of the um",
    "start": "1924559",
    "end": "1931639"
  },
  {
    "text": "machine learning Frameworks that we seeing out there so we see huge excitement about cancer flow and pytorch",
    "start": "1931639",
    "end": "1937360"
  },
  {
    "text": "obviously um those are the the dominating Frameworks I should say now there's a lot of excitement about jacks",
    "start": "1937360",
    "end": "1943440"
  },
  {
    "text": "by many people and there are these um other Frameworks which are also relevant sometimes relevant for very specific",
    "start": "1943440",
    "end": "1949760"
  },
  {
    "text": "cases and the opportunity that we saw is well sort of based around this story you",
    "start": "1949760",
    "end": "1954799"
  },
  {
    "text": "have an existing machine learning project what's the minimal amount of code changes that you that you have to",
    "start": "1954799",
    "end": "1960760"
  },
  {
    "text": "do in order to Federate this thing and we have code examples on that where you can take an existing workload and then",
    "start": "1960760",
    "end": "1966720"
  },
  {
    "text": "Federate it in in less than 20 lines of code which is actually I still find it amazing given the amount of things that",
    "start": "1966720",
    "end": "1973720"
  },
  {
    "text": "are going on under the hood yeah and you mentioned supporting all of these different Frameworks which does seem",
    "start": "1973720",
    "end": "1979840"
  },
  {
    "text": "like a big task and I'm kind of looking through the flower usage examples and the documentation and I also love just",
    "start": "1979840",
    "end": "1987440"
  },
  {
    "text": "you know I mean you explicitly say it's a friendly framework which I think is great you talked about accessibility",
    "start": "1987440",
    "end": "1993840"
  },
  {
    "text": "you've got a very friendly flower logo and so yeah I think it you know it puts up an inviting front for people which I",
    "start": "1993840",
    "end": "2001080"
  },
  {
    "text": "think is cool because it is a it can be like you said a very overwhelming complicated thing to get into were",
    "start": "2001080",
    "end": "2008000"
  },
  {
    "text": "talking about supporting these different Frameworks and maybe you could give a sense of like it seems like a big task",
    "start": "2008000",
    "end": "2014240"
  },
  {
    "text": "to support all of those in this way and I see that the main kind of way in which",
    "start": "2014240",
    "end": "2020320"
  },
  {
    "text": "you wrap things with flower is like creating this class python class maybe",
    "start": "2020320",
    "end": "2025679"
  },
  {
    "text": "that wraps certain methods and within those you can Define your own sort of",
    "start": "2025679",
    "end": "2031080"
  },
  {
    "text": "tensorflow or pie torch or whatever ways to fit or get parameters of a model or",
    "start": "2031080",
    "end": "2036639"
  },
  {
    "text": "whatever it is did you purposely create that structure because you had this vision of supporting the multiple",
    "start": "2036639",
    "end": "2041720"
  },
  {
    "text": "Frameworks and am I representing that accurately yes absolutely we call it flower the friendly Federated learning",
    "start": "2041720",
    "end": "2048320"
  },
  {
    "text": "framework exactly for that reason so we want to be friendly in many different dimensions actually we want to be",
    "start": "2048320",
    "end": "2053480"
  },
  {
    "text": "friendly when it comes to different machine learning Frameworks we want to be friendly when it comes to different device types we want to be friendly when",
    "start": "2053480",
    "end": "2060200"
  },
  {
    "text": "it comes to different transport mechanisms so we we actually have this is not something that is up front on the",
    "start": "2060200",
    "end": "2065280"
  },
  {
    "text": "website but we have different transport mechanisms build in and you you can swap these out actually so the building in",
    "start": "2065280",
    "end": "2071240"
  },
  {
    "text": "support for different Frameworks this was something that we intended to do from the very beginning and there's",
    "start": "2071240",
    "end": "2077398"
  },
  {
    "text": "different layers to this that are important or or at least interesting to understand so one layer is the client",
    "start": "2077399",
    "end": "2083398"
  },
  {
    "text": "class that you just described so when you build your client in Python then you would create a a subass of client so",
    "start": "2083399",
    "end": "2091000"
  },
  {
    "text": "flower. client. client um is what the class is called or a subass of flower.",
    "start": "2091000",
    "end": "2096240"
  },
  {
    "text": "client. numpy client which is even easier to implement and you basically just need to add these few lines of code",
    "start": "2096240",
    "end": "2103000"
  },
  {
    "text": "that then call into your existing machine learning pipelines which is on",
    "start": "2103000",
    "end": "2108040"
  },
  {
    "text": "the one hand a simple concept but on the other hand a very powerful concept because it allows you when you implement",
    "start": "2108040",
    "end": "2114200"
  },
  {
    "text": "these classes it allows you to call arbitrary python libraries so for example one good and one important",
    "start": "2114200",
    "end": "2120839"
  },
  {
    "text": "example for that is the support for differential privacy we sometimes get requests hey that does flower come with",
    "start": "2120839",
    "end": "2127680"
  },
  {
    "text": "differential FY built in and actually the answer is we don't have to because",
    "start": "2127680",
    "end": "2133320"
  },
  {
    "text": "you can for example for for a pytorch based workload you can use this SL called opacus which is gives you a sort",
    "start": "2133320",
    "end": "2140480"
  },
  {
    "text": "of a differential private SD Optimizer that you can plug into your workload and then you can just use it and the amazing",
    "start": "2140480",
    "end": "2147520"
  },
  {
    "text": "thing about this is that with the flower framework doesn't even have to change if there's a new library coming out a new",
    "start": "2147520",
    "end": "2153400"
  },
  {
    "text": "approach coming out for what you can do on the client side you can just integrate it with arbitrary code the",
    "start": "2153400",
    "end": "2158680"
  },
  {
    "text": "other layer that is maybe interesting to understand maybe not so much for researchers who who do most of their",
    "start": "2158680",
    "end": "2164680"
  },
  {
    "text": "day-to-day work in Python but to others who want to maybe more deeply integrate this in a in the automotive setting or",
    "start": "2164680",
    "end": "2172160"
  },
  {
    "text": "or something similar to that they wouldn't want to use Python for their on device processing so they would use they",
    "start": "2172160",
    "end": "2178760"
  },
  {
    "text": "would want to use a different language for example c um to do that in the",
    "start": "2178760",
    "end": "2183920"
  },
  {
    "text": "automotive world there's this C dialect called Mr C that you have to use for",
    "start": "2183920",
    "end": "2189040"
  },
  {
    "text": "safety purposes for example it prevents you from using recursion and other things like that things that are been considered unsafe in the automotive",
    "start": "2189040",
    "end": "2195560"
  },
  {
    "text": "world and in those scenarios you can still integrate your device with flower",
    "start": "2195560",
    "end": "2202400"
  },
  {
    "text": "by um directly handling the events that are coming from the server so in the end FL has been designed in a way where the",
    "start": "2202400",
    "end": "2209040"
  },
  {
    "text": "client side is actually rather easy to implement and if you have something that is running on C or C++ all you would",
    "start": "2209040",
    "end": "2215800"
  },
  {
    "text": "have to do is you would have to establish connection to the server the server would then occasionally select",
    "start": "2215800",
    "end": "2221200"
  },
  {
    "text": "this client and when it selects the client it sends it a message you on the client side you have to handle this",
    "start": "2221200",
    "end": "2226280"
  },
  {
    "text": "message you can do your processing it doesn't have to be any of the well-known uh machine learning Frameworks you can",
    "start": "2226280",
    "end": "2231839"
  },
  {
    "text": "handc code the type of model that you have and then you send back a message containing your update for example um",
    "start": "2231839",
    "end": "2238160"
  },
  {
    "text": "the gradients that you collected that's awesome I love that sort of client agnostic Focus it's cool one of the",
    "start": "2238160",
    "end": "2244359"
  },
  {
    "text": "things I was curious about because as a practitioner I'm kind of in and out and I'll do other things in my job and and",
    "start": "2244359",
    "end": "2250359"
  },
  {
    "text": "when I'm coming back in I'm having to kind of go how did I do that before and stuff and one of the things that I've noticed in the industry is that the",
    "start": "2250359",
    "end": "2257200"
  },
  {
    "text": "barriers to be able to access or utilize machine learning are getting lower and",
    "start": "2257200",
    "end": "2262960"
  },
  {
    "text": "there's a lot of Tools around usability coming out what does the story look like for flower and maybe for Federate",
    "start": "2262960",
    "end": "2269119"
  },
  {
    "text": "learning at large as you have more users out there of various technical",
    "start": "2269119",
    "end": "2274680"
  },
  {
    "text": "capability and maybe gradually you know having that technical requirement going",
    "start": "2274680",
    "end": "2279720"
  },
  {
    "text": "lower and lower as the tooling gets better how will Federated learning fit into that world where more users with",
    "start": "2279720",
    "end": "2285760"
  },
  {
    "text": "less specific skill in this area are accessing these tools and creating models of various types what does that",
    "start": "2285760",
    "end": "2291720"
  },
  {
    "text": "look like there that's a great question so I'm sometimes saying that we've been or maybe we still are I'm not perfectly",
    "start": "2291720",
    "end": "2298920"
  },
  {
    "text": "sure on that in a pre- tensorflow era when it comes to Federated learning it was the case for a long time that if you",
    "start": "2298920",
    "end": "2305960"
  },
  {
    "text": "wanted to build a f learning workload you usually had research scientist type",
    "start": "2305960",
    "end": "2311599"
  },
  {
    "text": "of person start out to prototype this um make a simulation of it and if that converges then you could actually you",
    "start": "2311599",
    "end": "2318880"
  },
  {
    "text": "could make the decision that you want to have this in production but then you would basically start from scratch and",
    "start": "2318880",
    "end": "2324560"
  },
  {
    "text": "you would implement it in quote unquote real system with I don't know Java or",
    "start": "2324560",
    "end": "2329599"
  },
  {
    "text": "C++ or something like that so you had to build these systems um by hand and there's a for example that there's a",
    "start": "2329599",
    "end": "2335880"
  },
  {
    "text": "blog post that compar Federated learning Frameworks and before flower was around",
    "start": "2335880",
    "end": "2341520"
  },
  {
    "text": "the conclusion was really if you want to build this workl a Federated loading system and you want to build it in",
    "start": "2341520",
    "end": "2347960"
  },
  {
    "text": "really a production environment then your best option is to just build it from scratch by hand they've recently",
    "start": "2347960",
    "end": "2354040"
  },
  {
    "text": "updated this blog post to say that for their scenario they choose to use flower for that obviously I'm happy about that",
    "start": "2354040",
    "end": "2359960"
  },
  {
    "text": "but it's still not a super super polished um experience so flow makes it a lot easier to start out on that",
    "start": "2359960",
    "end": "2365560"
  },
  {
    "text": "Journey but it's still a couple of moving pieces that you should sort of",
    "start": "2365560",
    "end": "2372119"
  },
  {
    "text": "understand to make informed decisions about how to configure your workload for example that's something that is",
    "start": "2372119",
    "end": "2378680"
  },
  {
    "text": "obviously one of our priorities to make this even easier to make it even less likely that if you are not an expert on",
    "start": "2378680",
    "end": "2385760"
  },
  {
    "text": "this that you are configuring something building something that might not be a good choice in production so one of the",
    "start": "2385760",
    "end": "2391920"
  },
  {
    "text": "things that we take very seriously is that we build in the right defaults so one of the defaults for example that",
    "start": "2391920",
    "end": "2397400"
  },
  {
    "text": "flower framework is following that is for certain types of workloads is it's the goto recommendation is that the",
    "start": "2397400",
    "end": "2403960"
  },
  {
    "text": "flower framework when it gets updates from clients it does not persist these",
    "start": "2403960",
    "end": "2409920"
  },
  {
    "text": "updates in any way so this these individual updates from clients um they could allow you to to Peak into it and",
    "start": "2409920",
    "end": "2417040"
  },
  {
    "text": "to draw some at least some minor conclusions about the client's data set and therefore the recommendation is to",
    "start": "2417040",
    "end": "2422839"
  },
  {
    "text": "receive these updates only keep them in memory and only for the um minim minimum amount of time absolutely necessary so",
    "start": "2422839",
    "end": "2429880"
  },
  {
    "text": "once you aggregated it with other updates you can safely discard it and another very related thing is that for",
    "start": "2429880",
    "end": "2436359"
  },
  {
    "text": "example the server does not lck any client specific metrics by default so",
    "start": "2436359",
    "end": "2441680"
  },
  {
    "text": "those are things that we are trying to build in that if you just start the server with all defaults that it makes",
    "start": "2441680",
    "end": "2448640"
  },
  {
    "text": "something that does takes a sensible approach but then obviously there are more advanced users and they want to",
    "start": "2448640",
    "end": "2454359"
  },
  {
    "text": "customize it so the perspective is make defaults sort of safe as safe as we can",
    "start": "2454359",
    "end": "2459880"
  },
  {
    "text": "and then allow more advanced users to customize these workloads so as we close",
    "start": "2459880",
    "end": "2465560"
  },
  {
    "text": "out here I'm interested to hear about you know what is like one or a couple",
    "start": "2465560",
    "end": "2471960"
  },
  {
    "text": "things that like really excites you about the future of flower and maybe",
    "start": "2471960",
    "end": "2477480"
  },
  {
    "text": "it's its applications within the wider context of Federated learning what's the one thing or or the couple things that",
    "start": "2477480",
    "end": "2484359"
  },
  {
    "text": "really get you excited about where this is headed or maybe sort of within the road map of flower there are a ton of",
    "start": "2484359",
    "end": "2491119"
  },
  {
    "text": "things that get me excited both from a research perspective but also from a",
    "start": "2491119",
    "end": "2496640"
  },
  {
    "text": "practical perspective from a research perspective we just launched a preview",
    "start": "2496640",
    "end": "2502240"
  },
  {
    "text": "of a new feature that we are calling the virtual client engine the virtual client engine is something that well it manages",
    "start": "2502240",
    "end": "2509200"
  },
  {
    "text": "clients as virtual clients so so those clients they don't actually exist in memory and what this gives you sounds",
    "start": "2509200",
    "end": "2515599"
  },
  {
    "text": "pretty trivial but what this gives you this amazing scalability for your research workloads so we did a survey of",
    "start": "2515599",
    "end": "2523400"
  },
  {
    "text": "research papers and looked at what the scale of these workloads is in in the research um of those experiments and",
    "start": "2523400",
    "end": "2530359"
  },
  {
    "text": "they really um the vast majority of papers they used up to 100 clients and",
    "start": "2530359",
    "end": "2536520"
  },
  {
    "text": "also up to 100 clients doing work concurrently so so training concurrently for example so you can have a large",
    "start": "2536520",
    "end": "2543160"
  },
  {
    "text": "client pool you can have a client pool of I don't know 10,000 clients but they would have only a hundred of them um",
    "start": "2543160",
    "end": "2549359"
  },
  {
    "text": "participating in the same round and this is something that is likely due to",
    "start": "2549359",
    "end": "2555160"
  },
  {
    "text": "Resource constraints because those workloads can get very heavy and the systems that we read about from industry",
    "start": "2555160",
    "end": "2561880"
  },
  {
    "text": "they are at a vastly different scale so they have millions or tens of millions or even hundreds of millions of clients",
    "start": "2561880",
    "end": "2568319"
  },
  {
    "text": "in such a workload and this is quite interesting and also quite an important challenge to address because obviously",
    "start": "2568319",
    "end": "2575119"
  },
  {
    "text": "we we want to have research that eventually translates to the real world to practical setting and if the scale in",
    "start": "2575119",
    "end": "2582240"
  },
  {
    "text": "research is a very different scale from the Practical settings it's less likely that the research that we're conducting",
    "start": "2582240",
    "end": "2588240"
  },
  {
    "text": "will translate um into the Practical setting so the virtual client managers is one thing where we demonstrated on",
    "start": "2588240",
    "end": "2594040"
  },
  {
    "text": "quite average Hardware actually we ran a workload with 15 million clients in it",
    "start": "2594040",
    "end": "2599200"
  },
  {
    "text": "and a thousand of these clients training concurrently and this worked super well um so so I'm quite excited about that",
    "start": "2599200",
    "end": "2605319"
  },
  {
    "text": "one and and especially quite excited to see what the community is going to do with that that's from a research",
    "start": "2605319",
    "end": "2610480"
  },
  {
    "text": "perspective and we have a couple of things in the pipeline that we are going to announce over the over the coming months also from a practical perspective",
    "start": "2610480",
    "end": "2617680"
  },
  {
    "text": "that's maybe even more more exciting in terms of the real outcomes that we're going to see um from that one initiative",
    "start": "2617680",
    "end": "2625240"
  },
  {
    "text": "that we are for example participating in is called met per which is a um hosted",
    "start": "2625240",
    "end": "2632520"
  },
  {
    "text": "by ml Commons which is sort of the the organization that emerged out of ml per so met proof is a is a way to use",
    "start": "2632520",
    "end": "2639520"
  },
  {
    "text": "Federated evaluation to get a better understanding of the performance of medical AI models it also requires",
    "start": "2639520",
    "end": "2646440"
  },
  {
    "text": "Federated infrastructure we put the paper on archive the entire met proof group put the paper on archive a couple",
    "start": "2646440",
    "end": "2652200"
  },
  {
    "text": "of weeks ago super interesting read highly recommended and this is something where you can really see that the real",
    "start": "2652200",
    "end": "2658359"
  },
  {
    "text": "world impact and real world improvements that we're going to see from this can be very profound because it's uh it's about",
    "start": "2658359",
    "end": "2664800"
  },
  {
    "text": "medical Ai and medical getting better per performance estimates in medical AI is actually a very fundamental Challenge",
    "start": "2664800",
    "end": "2671760"
  },
  {
    "text": "and once we have these barrier estimates it is much safer to roll out medical AI models much much faster and apart from",
    "start": "2671760",
    "end": "2679240"
  },
  {
    "text": "um from met Pro there are also a couple of other initiatives in the medical AI space and the duct Discovery Space that",
    "start": "2679240",
    "end": "2686400"
  },
  {
    "text": "I'm very excited about because any advance our infrastructure will help in",
    "start": "2686400",
    "end": "2692000"
  },
  {
    "text": "generating can have a very profound impact on society as a whole so that's something thing I'm quite keen on",
    "start": "2692000",
    "end": "2698559"
  },
  {
    "text": "contributing to well Daniel I'm super excited about all of the things that you've mentioned in terms of things on",
    "start": "2698559",
    "end": "2705240"
  },
  {
    "text": "the road map of research with flow or practical uses of of flower and Federated learning and really appreciate",
    "start": "2705240",
    "end": "2712119"
  },
  {
    "text": "you joining us and talking us through everything on the podcast uh appreciate it and we'll include some show notes in",
    "start": "2712119",
    "end": "2718880"
  },
  {
    "text": "our show hosting for flower and all the wonderful things that you've talked",
    "start": "2718880",
    "end": "2723960"
  },
  {
    "text": "about but yeah thank you so much for joining and looking forward to uh keeping tabs on Flow thanks for having",
    "start": "2723960",
    "end": "2731960"
  },
  {
    "text": "me that's our show thanks for listening for more like this check out our Master",
    "start": "2732640",
    "end": "2737880"
  },
  {
    "text": "feed it is all change Log podcasts in one easy to consume place let your",
    "start": "2737880",
    "end": "2743119"
  },
  {
    "text": "podcast app snag everything we produce and then pick and choose which ones to listen to subscribe today at Chang",
    "start": "2743119",
    "end": "2749240"
  },
  {
    "text": "log.com slm or just search for change log master in your podcast app of choice you'll find it special thanks to break",
    "start": "2749240",
    "end": "2756319"
  },
  {
    "text": "master cylinder for providing our music and to our longtime sponsors fastly launch darkley and lenoe that's all for",
    "start": "2756319",
    "end": "2763520"
  },
  {
    "text": "this week we'll talk to you again next [Music]",
    "start": "2763520",
    "end": "2773920"
  },
  {
    "text": "[Music]",
    "start": "2777940",
    "end": "2784939"
  },
  {
    "text": "time [Music]",
    "start": "2785920",
    "end": "2792889"
  },
  {
    "text": "k",
    "start": "2793839",
    "end": "2796839"
  }
]
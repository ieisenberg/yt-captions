[
  {
    "text": "[Music]",
    "start": "280",
    "end": "4040"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspire to or are",
    "start": "6720",
    "end": "13920"
  },
  {
    "text": "curious how AI related Tech is changing the world this is the show for you thank",
    "start": "13920",
    "end": "20519"
  },
  {
    "text": "you to our partners at fly.io the home of",
    "start": "20519",
    "end": "25759"
  },
  {
    "text": "changelog.md 30 plus regions on six continents so you can launch your app",
    "start": "28960",
    "end": "34440"
  },
  {
    "text": "near your users learn more at [Music]",
    "start": "34440",
    "end": "42160"
  },
  {
    "text": "fly.io welcome to another episode of practical AI this is Daniel whack I am",
    "start": "42160",
    "end": "48280"
  },
  {
    "text": "CEO and founder at prediction guard and really excited today to be joined by Dr",
    "start": "48280",
    "end": "54480"
  },
  {
    "text": "Reza khabib uh who is CEO and co-founder at human Loop how you doing Reza hi",
    "start": "54480",
    "end": "60440"
  },
  {
    "text": "Daniel it's a pleasure to be here I'm doing very well um yeah thanks for having me on yeah yeah super excited to",
    "start": "60440",
    "end": "67320"
  },
  {
    "text": "talk with you I'm mainly excited to talk with you selfishly because I see the",
    "start": "67320",
    "end": "73280"
  },
  {
    "text": "amazing things that human Loop is is doing and the Really critical problems that you're thinking about and every day",
    "start": "73280",
    "end": "79799"
  },
  {
    "text": "of my life it's like how am I managing prompts and how does this next model",
    "start": "79799",
    "end": "86320"
  },
  {
    "text": "that I'm upgrading to how do my prompts do in that model model and how am I constructing workflows around using llms",
    "start": "86320",
    "end": "94360"
  },
  {
    "text": "which it definitely seems to be the main thrust of some of the things that you're",
    "start": "94360",
    "end": "99560"
  },
  {
    "text": "thinking about at human Loop before we get into the specifics of those things at human Loop would you mind setting the",
    "start": "99560",
    "end": "106399"
  },
  {
    "text": "context for us in terms of workflows around these llms collaboration on team",
    "start": "106399",
    "end": "112479"
  },
  {
    "text": "like how did you start thinking about this problem and what does that mean in",
    "start": "112479",
    "end": "117560"
  },
  {
    "text": "reality for those working in industry right now maybe more generally than at",
    "start": "117560",
    "end": "122759"
  },
  {
    "text": "human Loop yeah absolutely so I guess on the on the question of like how I came to be working on this problem it was",
    "start": "122759",
    "end": "128039"
  },
  {
    "text": "really something that my co-founders Peter and Jordan and I had been working on for a very long time actually so you",
    "start": "128039",
    "end": "133040"
  },
  {
    "text": "know previously Peter and I did phds together around this area and then when we started the company it was a little",
    "start": "133040",
    "end": "138840"
  },
  {
    "text": "while after transfer learning had started to work in NLP for the first time and we were mostly helping companies fine tune smaller models but",
    "start": "138840",
    "end": "145920"
  },
  {
    "text": "then sometime Midway through 2022 we became Absol convinced that the rate of",
    "start": "145920",
    "end": "152120"
  },
  {
    "text": "progress for these larger models was so high it was going to start to Eclipse essentially everything else in terms of",
    "start": "152120",
    "end": "157319"
  },
  {
    "text": "performance but more importantly in terms of usability right it was the first time that instead of having to",
    "start": "157319",
    "end": "162800"
  },
  {
    "text": "like hand annotate a new data set for every new problem there was this new way of customizing AI models which was that",
    "start": "162800",
    "end": "168840"
  },
  {
    "text": "you could write instructions in natural language and have a reasonable expectation that the model would then do",
    "start": "168840",
    "end": "174200"
  },
  {
    "text": "that thing and that was Unthinkable you know at the start of 2022 I would say or maybe a little bit earlier and so that's",
    "start": "174200",
    "end": "180879"
  },
  {
    "text": "really what made us want to go work on this because we realized that the potential impact of NLP was already",
    "start": "180879",
    "end": "187200"
  },
  {
    "text": "there but the accessibility had been expanded so far and the capabilities of the models had increased so much that",
    "start": "187200",
    "end": "193159"
  },
  {
    "text": "there was a a particular moment to go do this but at the same time it introduces a whole bunch of new challenges right so",
    "start": "193159",
    "end": "199680"
  },
  {
    "text": "I guess historically the people who were building AI systems were machine learning experts the way that you would do it is you would collect annotated",
    "start": "199680",
    "end": "206120"
  },
  {
    "text": "data you'd find tune a custom model it was typically being used for like one specific task at a time there was a",
    "start": "206120",
    "end": "212360"
  },
  {
    "text": "correct answer so it was easy to evaluate and with LMS the power also brings new challenges so the way that",
    "start": "212360",
    "end": "219519"
  },
  {
    "text": "you customize these models is by writing these natural language instructions which are prompts and typically that",
    "start": "219519",
    "end": "225080"
  },
  {
    "text": "means that the people involved don't need to be as Technical and usually we see actually that the the best people to",
    "start": "225080",
    "end": "230799"
  },
  {
    "text": "do prompt engineering tend to have domain expertise so often it's a product manager or someone else within a company",
    "start": "230799",
    "end": "236840"
  },
  {
    "text": "who's leading The Prompt engineering efforts but you ALS have this new artifact lying around which is the",
    "start": "236840",
    "end": "242200"
  },
  {
    "text": "prompt and it has a similar impact to code on your end application so it needs to be versioned and managed and treated",
    "start": "242200",
    "end": "248760"
  },
  {
    "text": "with the same level of respect and rigor that you would treat normal code but somehow you also need to have the right",
    "start": "248760",
    "end": "254319"
  },
  {
    "text": "workflows and collaboration that lets the non-technical people work with the engineers on the product or the less",
    "start": "254319",
    "end": "260079"
  },
  {
    "text": "technical people and then the extra challenge that comes with it as well is that it's very subjective to measure",
    "start": "260079",
    "end": "266120"
  },
  {
    "text": "performance here so in traditional code we're used to runting unit tasks integration tests regression tests we",
    "start": "266120",
    "end": "271759"
  },
  {
    "text": "know what good looks like and how to measure it and even in traditional machine learning you know there's a",
    "start": "271759",
    "end": "277759"
  },
  {
    "text": "ground truth data set people calculate metrics but once you go into generative AI it tends to be harder to say what is",
    "start": "277759",
    "end": "285000"
  },
  {
    "text": "the correct answer and so when that becomes difficult then measuring performance becomes hard if measuring",
    "start": "285000",
    "end": "290360"
  },
  {
    "text": "performance is hard how do you know when you make changes if you're going to cause regressions or you know all the",
    "start": "290360",
    "end": "295600"
  },
  {
    "text": "different design choices you have in developing an app how do you make those design choices is if you don't have good",
    "start": "295600",
    "end": "300880"
  },
  {
    "text": "metrics of performance and so those are the problems that motivated what we've built and really human Loop exists to",
    "start": "300880",
    "end": "307479"
  },
  {
    "text": "solve both of these problems so to help companies with the tasks of finding the best prompts managing versioning them",
    "start": "307479",
    "end": "313759"
  },
  {
    "text": "dealing with collaboration but then also helping you do the evaluation that's needed to have confidence that the",
    "start": "313759",
    "end": "319800"
  },
  {
    "text": "models are going to behave as you expect in production and as related to these",
    "start": "319800",
    "end": "324880"
  },
  {
    "text": "things um maybe you can start with one that you would like to start with and go to the others but in terms of managing",
    "start": "324880",
    "end": "332880"
  },
  {
    "text": "versioning prompts evaluating the performance of these models dealing with regressions as you've kind of seen",
    "start": "332880",
    "end": "339400"
  },
  {
    "text": "people try to do this across probably a lot of different clients a lot of",
    "start": "339400",
    "end": "344520"
  },
  {
    "text": "different Industries how are people trying to manage this in maybe some good",
    "start": "344520",
    "end": "351199"
  },
  {
    "text": "ways and some bad ways yeah I think we see a lot of companies go on a bit of a journey so early on you know people are",
    "start": "351199",
    "end": "357919"
  },
  {
    "text": "excited about generative AI LM there's a lot of hype around it now so some people in the company just go try things out",
    "start": "357919",
    "end": "363960"
  },
  {
    "text": "and often they'll start off using one of the large you know publicly available model so open AI or anthropic cohere one",
    "start": "363960",
    "end": "370080"
  },
  {
    "text": "of these they'll prototype in their own kind of playground environment that those providers have they'll eyeball a",
    "start": "370080",
    "end": "375800"
  },
  {
    "text": "few examples maybe they'll grab a a couple of libraries that support orchestration and they'll put together a",
    "start": "375800",
    "end": "381160"
  },
  {
    "text": "prototype and the first version is fairly easy to build it's you know it's very quick to get to like the first wow",
    "start": "381160",
    "end": "387720"
  },
  {
    "text": "moment and then as people start moving towards production and they start iterating from that you know maybe 80%",
    "start": "387720",
    "end": "394560"
  },
  {
    "text": "good enough version to something that they really trust they start to run into these problems of like oh I've got like 20 different versions of this prompt and",
    "start": "394560",
    "end": "401240"
  },
  {
    "text": "I'm storing it as a string in code and actually I want to be able to collaborate with a colleague on this and so now we're sharing things you know",
    "start": "401240",
    "end": "408039"
  },
  {
    "text": "either via screen sharing or we're like both you know we've had some serious companies you would have heard of who are sending their model configs to each",
    "start": "408039",
    "end": "414759"
  },
  {
    "text": "other via Microsoft teams and obviously you know you wouldn't send someone important piece of code through slack or",
    "start": "414759",
    "end": "421759"
  },
  {
    "text": "teams or something like this but because the collaboration software isn't there to bridge this technical non-technical",
    "start": "421759",
    "end": "426960"
  },
  {
    "text": "divide those are the kind of problems we see and so at this point typically a year ago people would start building",
    "start": "426960",
    "end": "433000"
  },
  {
    "text": "their own solution so more often than not like this was when people would start building in-house tools increasingly because there are companies",
    "start": "433000",
    "end": "439440"
  },
  {
    "text": "like human loop around that's usually when someone books a demo with us and they say Hey you know we've reached this",
    "start": "439440",
    "end": "445080"
  },
  {
    "text": "point where actually managing these artifacts has become cumbersome we're worried wored about the quality of what",
    "start": "445080",
    "end": "451039"
  },
  {
    "text": "we're producing do you have a solution to help and the way that human Loop helps at least on the prompt management",
    "start": "451039",
    "end": "456520"
  },
  {
    "text": "side is we have this interactive environment it's a little bit like those open AI playgrounds or the anthropic",
    "start": "456520",
    "end": "461800"
  },
  {
    "text": "playground but a lot more fully featured and designed for actual development so it's collaborative it has History built",
    "start": "461800",
    "end": "468039"
  },
  {
    "text": "in you can connect variables and data sets and so it becomes like a development environment for your sort of",
    "start": "468039",
    "end": "474080"
  },
  {
    "text": "llm application you can prototype the application interact with it try out a few things and then people progress from",
    "start": "474080",
    "end": "480520"
  },
  {
    "text": "that development environment into production through evaluation and monitoring you mentioned this kind of in",
    "start": "480520",
    "end": "487720"
  },
  {
    "text": "passing I'd love to dig into it a little bit more you mentioned kind of the types of people that are coming you know at",
    "start": "487720",
    "end": "494400"
  },
  {
    "text": "the table in designing these systems and oftentimes domain experts you know",
    "start": "494400",
    "end": "499479"
  },
  {
    "text": "previously in working as a data scientist it was always kind of assumed oh you need to talk to the domain",
    "start": "499479",
    "end": "505560"
  },
  {
    "text": "experts but it's sort of like at least for many years it was like data scientists talk to The Domain experts",
    "start": "505560",
    "end": "511680"
  },
  {
    "text": "and then go off and build their thing the domain experts were not involved in the sort of building of the system and",
    "start": "511680",
    "end": "519039"
  },
  {
    "text": "even then like the data scientists were maybe building things that were kind of",
    "start": "519039",
    "end": "524159"
  },
  {
    "text": "foreign to software engineers and what I'm hearing you say is you kind of got",
    "start": "524159",
    "end": "529320"
  },
  {
    "text": "like these multiple layers you have like domain experts who might not be that technical you've got maybe Ai and data",
    "start": "529320",
    "end": "537480"
  },
  {
    "text": "people who are using this kind of unique set of tools maybe even they're hosting their own models and then you've got",
    "start": "537480",
    "end": "543800"
  },
  {
    "text": "like product software engineering people seems like a much more complicated landscape of interactions how have you",
    "start": "543800",
    "end": "552000"
  },
  {
    "text": "seen this kind of play out in reality in terms of non-technical people and Technical people both working together",
    "start": "552000",
    "end": "559200"
  },
  {
    "text": "on something that is ultimately something implemented in code and run as",
    "start": "559200",
    "end": "564240"
  },
  {
    "text": "an application I actually think one of the most exciting things about LMS the",
    "start": "564240",
    "end": "569560"
  },
  {
    "text": "progress in AI in general is that product managers and subject matter experts can for the first time be very",
    "start": "569560",
    "end": "575760"
  },
  {
    "text": "directly involved in implementing these applications so I think it's always been the case that the PM or someone like",
    "start": "575760",
    "end": "582079"
  },
  {
    "text": "that you know is the person who distills the problem speaks to the customers produces the spec but there's this translation step where they sort of",
    "start": "582079",
    "end": "589079"
  },
  {
    "text": "produce that PRD document and then someone else goes off and implements it and because we're now able to program at",
    "start": "589079",
    "end": "595920"
  },
  {
    "text": "least some of the application in natural language actually it's exess to those people very directly and it's worth",
    "start": "595920",
    "end": "601839"
  },
  {
    "text": "maybe having a concrete example so like I use um an AI Note Taker for a lot of my sales calls and it records the call",
    "start": "601839",
    "end": "608279"
  },
  {
    "text": "and then I get a summary afterwards and the app actually allows you to choose a lot of different types of summary so you",
    "start": "608279",
    "end": "613480"
  },
  {
    "text": "can say hey I'm a salesperson I want a summary that will extract budget and authority and need and timeline versus",
    "start": "613480",
    "end": "620600"
  },
  {
    "text": "you can say oh actually I had a product interview and I want a different type of summary and if you think about developing that application the person",
    "start": "620600",
    "end": "627640"
  },
  {
    "text": "who has the knowledge that's need needed to say what a good summary is and to write the prompt for the model is the",
    "start": "627640",
    "end": "633760"
  },
  {
    "text": "person who has that domain expertise it's not the software engineer but obviously the prompt is only one piece",
    "start": "633760",
    "end": "639000"
  },
  {
    "text": "of the application right if you got a question answering system there's usually retrieval as part of this there",
    "start": "639000",
    "end": "644880"
  },
  {
    "text": "may be other components usually the llm is a block in a wider application so you obviously still need the software",
    "start": "644880",
    "end": "651160"
  },
  {
    "text": "Engineers around because they're implementing the bulk of the application but the product managers can be much",
    "start": "651160",
    "end": "656519"
  },
  {
    "text": "more directly involved and then you know actually we see increasingly less involvement from machine learning or AI",
    "start": "656519",
    "end": "663720"
  },
  {
    "text": "experts and less people are fine-tuning their own models so for the majority of product teams we're seeing there is a an",
    "start": "663720",
    "end": "670560"
  },
  {
    "text": "AI platform team that maybe facilitates setting things up but the bulk of the work is led by the product managers and",
    "start": "670560",
    "end": "678040"
  },
  {
    "text": "then the engineers and one interesting example of this on the extreme end is one of our customers it's a very large",
    "start": "678040",
    "end": "683959"
  },
  {
    "text": "edtech company they actually do not let their Engineers edit the prompts so they have a team of Ling who do prompt",
    "start": "683959",
    "end": "690200"
  },
  {
    "text": "development the linguists finalize the prompts they're saved in a serialized format and they go to production but",
    "start": "690200",
    "end": "695959"
  },
  {
    "text": "it's a oneway transfer so the engineers can't edit them because they're not considered able to assess the the actual",
    "start": "695959",
    "end": "703600"
  },
  {
    "text": "outputs even though they are responsible for the rest of the application just thinking about how teams interact and",
    "start": "703600",
    "end": "709760"
  },
  {
    "text": "who's doing what it seems like the problems that you've laid out are I",
    "start": "709760",
    "end": "714839"
  },
  {
    "text": "think very clear and worth solving but it's probably hard to think about well am I building a developer tool or am I",
    "start": "714839",
    "end": "722720"
  },
  {
    "text": "building like something that these non-technical people interact with or is it both how did you think about that as",
    "start": "722720",
    "end": "728880"
  },
  {
    "text": "you kind of entered into the stages of bringing human Loop into existence I",
    "start": "728880",
    "end": "734399"
  },
  {
    "text": "think it has to be both and the honest answer is it evolved kind of organically by you know going to customers speaking",
    "start": "734399",
    "end": "741199"
  },
  {
    "text": "to them about their problems and trying to figure out what the best version of a solution looked like so we didn't set out to build a tool that needed to do",
    "start": "741199",
    "end": "748240"
  },
  {
    "text": "both of these things but I think the reality is you know given the problems that people face you do need both and",
    "start": "748240",
    "end": "754360"
  },
  {
    "text": "you know an analogy to think about might be something like figma right like figma is somewhere where multiple different",
    "start": "754360",
    "end": "759839"
  },
  {
    "text": "stakeholders come together to iterate on things and to develop them and provide feedback and I think you need something",
    "start": "759839",
    "end": "765800"
  },
  {
    "text": "analogist to that for Gen although it's not an exact analogy because we also need to attach the evaluation to this so",
    "start": "765800",
    "end": "772279"
  },
  {
    "text": "it's almost by necessity that we've had to do that but I also think that um it's very exciting right and the reason I",
    "start": "772279",
    "end": "778720"
  },
  {
    "text": "think it's exciting is because it is expanding who can be involved in developing these",
    "start": "778720",
    "end": "783740"
  },
  {
    "text": "[Music]",
    "start": "783740",
    "end": "791230"
  },
  {
    "text": "[Applause] [Music]",
    "start": "791230",
    "end": "800239"
  },
  {
    "text": "applications if you're listening you know software is buil from thousands of small technical choices and some of",
    "start": "801040",
    "end": "807120"
  },
  {
    "text": "these seemingly inconsequential choices can have a profound impact on the economics of Internet services who gets",
    "start": "807120",
    "end": "814000"
  },
  {
    "text": "to participate in them build them and profit from them this is especially true for artificial intelligence where the",
    "start": "814000",
    "end": "820720"
  },
  {
    "text": "decisions we make today can determine who can have access to world changing Technologies and who can decide their",
    "start": "820720",
    "end": "826240"
  },
  {
    "text": "future read write own building the next era of the internet is a new book from",
    "start": "826240",
    "end": "831680"
  },
  {
    "text": "startup investor Chris Dixon that explores the decisions that took us from open networks governed by communities to",
    "start": "831680",
    "end": "837800"
  },
  {
    "text": "massive social networks run internet Giants this book read WR own is a call",
    "start": "837800",
    "end": "843000"
  },
  {
    "text": "to action for building a new era of the internet that puts people in charge from",
    "start": "843000",
    "end": "848639"
  },
  {
    "text": "an projects that compensate creators for their work to protocols that fund open- Source contributions this is our chance",
    "start": "848639",
    "end": "855600"
  },
  {
    "text": "to build the internet we want not the one we inherited order your copy of read",
    "start": "855600",
    "end": "860759"
  },
  {
    "text": "write own today or go to readr own.com to learn",
    "start": "860759",
    "end": "865840"
  },
  {
    "text": "[Music] more [Music]",
    "start": "865840",
    "end": "879920"
  },
  {
    "text": "you mentioned how this environment of domain experts coming together and",
    "start": "879920",
    "end": "885079"
  },
  {
    "text": "Technical teams coming together in a collaborative environment opens up new",
    "start": "885079",
    "end": "890360"
  },
  {
    "text": "possibilities for both collaboration and Innovation I'm wondering if at this",
    "start": "890360",
    "end": "895519"
  },
  {
    "text": "point you could kind of just lay out we've talked about the problems we've talked about those involved and those",
    "start": "895519",
    "end": "901519"
  },
  {
    "text": "kind of that would use such a system or a platform to enable this these kind of workflows could you describe a little",
    "start": "901519",
    "end": "908160"
  },
  {
    "text": "bit more what human Loop is specifically in terms of both what it can do and kind",
    "start": "908160",
    "end": "916160"
  },
  {
    "text": "of how these different personas engage with the system yeah so I guess in terms of what it can do concretely it's",
    "start": "916160",
    "end": "923959"
  },
  {
    "text": "firstly helping you with prompt iteration versioning and management and then with valtion and monitoring and the",
    "start": "923959",
    "end": "930199"
  },
  {
    "text": "way it does that is there's a web app and there's a web UI where people are coming in and in that UI is an",
    "start": "930199",
    "end": "936519"
  },
  {
    "text": "interactive playground like environment where people basically try out different prompts they can compare them side by",
    "start": "936519",
    "end": "942480"
  },
  {
    "text": "side with different models they can try them with different inputs when they find versions that they think are good",
    "start": "942480",
    "end": "947720"
  },
  {
    "text": "they save them and then those can be deployed from that environment to production or even to a development or",
    "start": "947720",
    "end": "954079"
  },
  {
    "text": "staging environment so that's the kind of development stage and then once you have something that's developed what's",
    "start": "954079",
    "end": "960000"
  },
  {
    "text": "very typical is people then want to put in evaluation steps into place so you can Define gold standard test sets and",
    "start": "960000",
    "end": "967120"
  },
  {
    "text": "then you can Define evaluators within human Loop and evaluators are ways of scoring the outputs of a model or a",
    "start": "967120",
    "end": "973560"
  },
  {
    "text": "sequence of models because oftentimes you know the llm is part of a wider application and so the way that scoring",
    "start": "973560",
    "end": "979240"
  },
  {
    "text": "works is um there's very traditional metrics that you would have in code for any machine Learning System so Precision",
    "start": "979240",
    "end": "986120"
  },
  {
    "text": "recall Rouge blue these kind of scores that anyone from a machine learning background would already be familiar with but what's new in the in the kind",
    "start": "986120",
    "end": "992880"
  },
  {
    "text": "of llm space is also things that help when things are more subjective so we have the ability to do model as judge",
    "start": "992880",
    "end": "999160"
  },
  {
    "text": "where you might actually prompt another llm to score the output in some way this can be particularly useful when you're",
    "start": "999160",
    "end": "1005839"
  },
  {
    "text": "trying to measure things like hallucination right so a very common thing to do is to ask the model you know",
    "start": "1005839",
    "end": "1011560"
  },
  {
    "text": "is the final answer contained within the retrieved context or is it possible to infer the answer from the retrieved",
    "start": "1011560",
    "end": "1018440"
  },
  {
    "text": "context and you can calculate those scores and then the final way is we also support human evaluation so in some",
    "start": "1018440",
    "end": "1024400"
  },
  {
    "text": "cases you know you really do want either feedback from an end user or from an internal annotator involved as well and",
    "start": "1024400",
    "end": "1031678"
  },
  {
    "text": "so we allow you to gather that feedback either from your live production application and have it you know logged",
    "start": "1031679",
    "end": "1037798"
  },
  {
    "text": "against your data or you can cue internal annotation tasks from a team and I can maybe tell you a little bit",
    "start": "1037799",
    "end": "1043839"
  },
  {
    "text": "more about sort of in production feedback because that's something that that's actually where we started yeah yeah go ahead would love to hear more",
    "start": "1043839",
    "end": "1049880"
  },
  {
    "text": "yeah so I think that because it's so subjective for a lot of the applications that people are building whether it be",
    "start": "1049880",
    "end": "1055880"
  },
  {
    "text": "email generation question answering a language learning app there isn't a correct answer quote unquote and so",
    "start": "1055880",
    "end": "1062919"
  },
  {
    "text": "people want to measure how things are actually performing with their end users and so human Loop makes it very easy to",
    "start": "1062919",
    "end": "1068799"
  },
  {
    "text": "capture different sources of end user feedback and that might be explicit feedback things like thumbs up thumbs",
    "start": "1068799",
    "end": "1074640"
  },
  {
    "text": "down votes that you see in chat GPT but it can also be more implicit signals so",
    "start": "1074640",
    "end": "1079960"
  },
  {
    "text": "how did the user behave after they were shown some generated content did they progress to the next stage of the",
    "start": "1079960",
    "end": "1085919"
  },
  {
    "text": "application did they send the generated email did they edit the text and all of that feedback data becomes useful both",
    "start": "1085919",
    "end": "1093679"
  },
  {
    "text": "for debugging and also for fine-tuning the model later on so that evaluation",
    "start": "1093679",
    "end": "1099039"
  },
  {
    "text": "data becomes this Rich resource that allows you to continuously improve your application over time yeah that's",
    "start": "1099039",
    "end": "1104480"
  },
  {
    "text": "awesome and I know that that fits in so maybe you could talk a little bit about",
    "start": "1104480",
    "end": "1110640"
  },
  {
    "text": "how you're one of the things that you mentioned earlier is you're seeing fewer people do fine-tuning which I I see this",
    "start": "1110640",
    "end": "1117840"
  },
  {
    "text": "very commonly as a it's not an irrelevant point but it's maybe a",
    "start": "1117840",
    "end": "1123039"
  },
  {
    "text": "misconception where like a lot of teams come into this space and they just assume they're going to be fine-tuning",
    "start": "1123039",
    "end": "1129240"
  },
  {
    "text": "their models and often what they end up doing is fine-tuning their workflows or",
    "start": "1129240",
    "end": "1135080"
  },
  {
    "text": "their language model chains or their retrieval the data that they're retrieving or their prompt formats or",
    "start": "1135080",
    "end": "1141600"
  },
  {
    "text": "that templates or that sort of thing they're not really fine-tuning and I think there's this really blurred line",
    "start": "1141600",
    "end": "1147919"
  },
  {
    "text": "right now for many teams that are adopting AI into their organization",
    "start": "1147919",
    "end": "1154520"
  },
  {
    "text": "where they'll frequently just use the term oh I'm training the AI to do this",
    "start": "1154520",
    "end": "1159679"
  },
  {
    "text": "and now it's better right but all they've really done is just inject some data into their prompts or or something",
    "start": "1159679",
    "end": "1166039"
  },
  {
    "text": "like that so could you maybe help like clarify that distinction and also in",
    "start": "1166039",
    "end": "1172840"
  },
  {
    "text": "reality what you're seeing people do with this capability of evaluation both",
    "start": "1172840",
    "end": "1178240"
  },
  {
    "text": "online and offline and how that's filtering back into upgrades to the",
    "start": "1178240",
    "end": "1183559"
  },
  {
    "text": "system or actual fine tunes of models yeah so I guess you're right there's a lot of jargon involved and especially",
    "start": "1183559",
    "end": "1189559"
  },
  {
    "text": "for people who are new to the field the word fine-tuning has a colloquial meaning and then it has a technical",
    "start": "1189559",
    "end": "1194880"
  },
  {
    "text": "meaning in machine learning and the two end up being blurred so you know F tuning in a machine learning context",
    "start": "1194880",
    "end": "1200520"
  },
  {
    "text": "usually means doing some extra training on the base model where you're actually changing the weights of the model given",
    "start": "1200520",
    "end": "1207280"
  },
  {
    "text": "some sets of example pairs of inputs outputs that you want and then obviously there's like prompt engineering and",
    "start": "1207280",
    "end": "1213559"
  },
  {
    "text": "adapt and maybe Context Engineering where you're changing the instructions to the language model or you're changing",
    "start": "1213559",
    "end": "1219320"
  },
  {
    "text": "the uh data that's set into the context or how the you know an agent system might be set up and both are really",
    "start": "1219320",
    "end": "1225360"
  },
  {
    "text": "important typically the advice we give the majority of our customer customers and what we see play out in practice is",
    "start": "1225360",
    "end": "1231799"
  },
  {
    "text": "to that people should first push the limits of prompt engineering because it's very fast it's easy to do and it",
    "start": "1231799",
    "end": "1239039"
  },
  {
    "text": "can have like very high impact especially around changing the uh sort of outputs and also in helping the model",
    "start": "1239039",
    "end": "1245480"
  },
  {
    "text": "have the right data that's needed to answer the question so prompt engineering is kind of usually where most people start and sometimes where",
    "start": "1245480",
    "end": "1251919"
  },
  {
    "text": "people finish as well and fine-tuning tends to be useful either if people are",
    "start": "1251919",
    "end": "1257679"
  },
  {
    "text": "trying to improve Pro latency or cost or if they have like a particular tone of voice or output constraint that they",
    "start": "1257679",
    "end": "1263760"
  },
  {
    "text": "want to enforce so you know if people want they model to Output valid Json then fine tuning might be a great way to",
    "start": "1263760",
    "end": "1270120"
  },
  {
    "text": "achieve that or if they want to use a local private model because it needs to run on an edge device or something like",
    "start": "1270120",
    "end": "1275480"
  },
  {
    "text": "this then fine tuning I think is a great candidate and it can also let you reduce costs because oftentimes you can fine",
    "start": "1275480",
    "end": "1281559"
  },
  {
    "text": "tune a smaller model to get similar performance the analogy I like to use is fine tuning is a bit like compilation",
    "start": "1281559",
    "end": "1287880"
  },
  {
    "text": "right you have a you youve already sort of built your first version of the language when you want to optimize it you might use a",
    "start": "1287880",
    "end": "1293440"
  },
  {
    "text": "compiled language and you've got a kind of compiled binary I think there was a second part to your question but just",
    "start": "1293440",
    "end": "1299039"
  },
  {
    "text": "remind me actually I've lost the second part yeah basically you mentioned that maybe fewer people are doing fine tunes",
    "start": "1299039",
    "end": "1307360"
  },
  {
    "text": "um maybe you could comment on I don't know if you have a sense of of why that",
    "start": "1307360",
    "end": "1313279"
  },
  {
    "text": "is or how you would see that sort of progressing into into this year as more",
    "start": "1313279",
    "end": "1318960"
  },
  {
    "text": "and more people adopt this technology and maybe get better tooling around the",
    "start": "1318960",
    "end": "1324159"
  },
  {
    "text": "let's not call it fine-tuning so we don't mix all the jargon but the the iterative development of these systems",
    "start": "1324159",
    "end": "1331480"
  },
  {
    "text": "do you see that Trend continuing or um how do you see that kind of going into",
    "start": "1331480",
    "end": "1336679"
  },
  {
    "text": "maybe larger or wider um adoption in 2024 yeah so I think that we've",
    "start": "1336679",
    "end": "1342840"
  },
  {
    "text": "definitely seen less fine-tuning than we thought we would see when we started you know when we launched human loop back",
    "start": "1342840",
    "end": "1349080"
  },
  {
    "text": "this version of human loop back in 2022 and I think that's been true of others as well like I've spoken to friends at",
    "start": "1349080",
    "end": "1354360"
  },
  {
    "text": "openai and open is expecting there will be more fine-tuning in the future but they've been surprised that there wasn't",
    "start": "1354360",
    "end": "1360600"
  },
  {
    "text": "more initially I think some of that is because prompt engineering has turned out to be remarkably powerful and also",
    "start": "1360600",
    "end": "1367039"
  },
  {
    "text": "because some of the changes that people want to do to these models are more about getting factual context into the",
    "start": "1367039",
    "end": "1373159"
  },
  {
    "text": "model so one of the downsides of llms today is they're obviously trained on the public internet so they don't",
    "start": "1373159",
    "end": "1378840"
  },
  {
    "text": "necessarily know private information about your company they tend not to know information past the training date of",
    "start": "1378840",
    "end": "1384080"
  },
  {
    "text": "the model and you know one way you might have thought you could overcome that is I'm going to fine-tune the model on my",
    "start": "1384080",
    "end": "1389960"
  },
  {
    "text": "company's data but I think in practice what people are finding is a better solution to that is to use a hybrid",
    "start": "1389960",
    "end": "1396320"
  },
  {
    "text": "system of search or or information retrieval plus generation so what's come to be known as like rag or retrieval",
    "start": "1396320",
    "end": "1402919"
  },
  {
    "text": "augmented generation has turned out to be a really good solution to this problem and so the main reasons to fine",
    "start": "1402919",
    "end": "1409320"
  },
  {
    "text": "tune now are more about optimizing cost and latency and maybe a little bit tone of voice but they're not needed so much",
    "start": "1409320",
    "end": "1416840"
  },
  {
    "text": "to adapt the model to a specific use case and fine tuning is a heavier Duty operation because it takes longer you",
    "start": "1416840",
    "end": "1424200"
  },
  {
    "text": "know you can edit a prompt very quickly and then see what the impact is fine-tuning you need to have the data",
    "start": "1424200",
    "end": "1429400"
  },
  {
    "text": "set that you want to fine-tune on and then you need to run a training job and then evaluate that job afterwards so",
    "start": "1429400",
    "end": "1435360"
  },
  {
    "text": "there are certainly circumstances where it's going to make sense I think especially anyone who wants to use a private open source model will likely",
    "start": "1435360",
    "end": "1442000"
  },
  {
    "text": "find themselves wanting to do more fine-tuning but the quality of of prompt engineering and the distance you can go",
    "start": "1442000",
    "end": "1447480"
  },
  {
    "text": "with it I think took a lot of people by surprise and on that note you mentioned the closed proprietary model ecos system",
    "start": "1447480",
    "end": "1455000"
  },
  {
    "text": "versus open models that people might host in their own environment and or fine-tune on on their own data I know",
    "start": "1455000",
    "end": "1462600"
  },
  {
    "text": "that human Loop like you you explicitly say that you kind of have all of the",
    "start": "1462600",
    "end": "1467640"
  },
  {
    "text": "models you're you're integrating these sort of closed models and integrate with open models why and how is that kind of",
    "start": "1467640",
    "end": "1476000"
  },
  {
    "text": "decided to kind of include all of those and in terms of the mix of what you're",
    "start": "1476000",
    "end": "1481919"
  },
  {
    "text": "seeing with people's implementations how do you see this sort of proliferation of open models",
    "start": "1481919",
    "end": "1489120"
  },
  {
    "text": "impacting the the workflows that you're supporting in the future so the reason for supporting them again is largely",
    "start": "1489120",
    "end": "1495799"
  },
  {
    "text": "customer pull right what we were finding is that many of our customers were using a mixture of models for different use",
    "start": "1495799",
    "end": "1503000"
  },
  {
    "text": "cases either because the large proprietary ones had slightly different performance trade-offs or because there",
    "start": "1503000",
    "end": "1508919"
  },
  {
    "text": "were use cases where they cared about privacy or they cared about latency and so they couldn't use a public model for",
    "start": "1508919",
    "end": "1515200"
  },
  {
    "text": "those instances and so we had to support all of them it really was something that",
    "start": "1515200",
    "end": "1520360"
  },
  {
    "text": "it would it wouldn't be a useful product to a customers if it could only use it for one particular model and the way",
    "start": "1520360",
    "end": "1525760"
  },
  {
    "text": "we've got around this is that like we try to integrate all all the publicly available ones but we also make it easy for people to connect their own models",
    "start": "1525760",
    "end": "1532679"
  },
  {
    "text": "so they don't necessarily need us you know as long as they expose the appropriate apis you can plug in any",
    "start": "1532679",
    "end": "1537760"
  },
  {
    "text": "model uh to human Loop that would be a matter of connect or hosting the model",
    "start": "1537760",
    "end": "1542919"
  },
  {
    "text": "and making sure that the API contract that you're expecting in terms of responses from a model server that maybe",
    "start": "1542919",
    "end": "1550520"
  },
  {
    "text": "someone's running in their own AWS or wherever would fulfill that that contract that's exactly right yeah and",
    "start": "1550520",
    "end": "1558399"
  },
  {
    "text": "terms of you know the the proliferation of Open Source and and how that's going you know I think there's still a performance Gap at the moment between",
    "start": "1558399",
    "end": "1565600"
  },
  {
    "text": "the very best Clos model so between a gbd4 or some of the better models from anthropic and the best open source but",
    "start": "1565600",
    "end": "1572279"
  },
  {
    "text": "it is closing right so the latest models from say uh mistra have proved to be very good llama 2 was very good",
    "start": "1572279",
    "end": "1579399"
  },
  {
    "text": "increasingly you're not paying as big a performance Gap though there is still one but you need to have high volumes",
    "start": "1579399",
    "end": "1585200"
  },
  {
    "text": "for it to be economically competitive to host your own model so the main reasons we see people doing it are related to",
    "start": "1585200",
    "end": "1592000"
  },
  {
    "text": "data privacy companies that for whatever reason you know cannot or don't want to send data to a third party end up um",
    "start": "1592000",
    "end": "1600440"
  },
  {
    "text": "using open source and then also anyone who's doing things on edge and who wants sort of real time or very low latency",
    "start": "1600440",
    "end": "1607120"
  },
  {
    "text": "ends up using open [Music]",
    "start": "1607120",
    "end": "1613440"
  },
  {
    "text": "source this is a chang log news break van. a is a python rag framework for",
    "start": "1613440",
    "end": "1621679"
  },
  {
    "text": "accurate text tosql generation it lets you chat with any relational database by",
    "start": "1621679",
    "end": "1627480"
  },
  {
    "text": "accurately generating SQL queries trained via rag which stands for",
    "start": "1627480",
    "end": "1632960"
  },
  {
    "text": "retrieval augmented generation to use with any llm that you want you load up",
    "start": "1632960",
    "end": "1639360"
  },
  {
    "text": "your data definitions your documentation and any raw SQL queries you have laying",
    "start": "1639360",
    "end": "1644600"
  },
  {
    "text": "around into Vana and then you're off to the races van Ana boasts high accuracy",
    "start": "1644600",
    "end": "1650120"
  },
  {
    "text": "on complex data sets excellent security and privacy because your database contents are never sent to the llm or a",
    "start": "1650120",
    "end": "1657520"
  },
  {
    "text": "vector DB it boasts the ability to self-learn by choosing to autot train on",
    "start": "1657520",
    "end": "1663440"
  },
  {
    "text": "successful queries and a choose your own front-end approach with front ends provided for Jupiter notebook streamlit",
    "start": "1663440",
    "end": "1671360"
  },
  {
    "text": "flask and slack you just heard one of our five top stories from Monday's",
    "start": "1671360",
    "end": "1677559"
  },
  {
    "text": "change log news subscribe to the podcast to get all of the week's top stories and pop your email address in at Chang",
    "start": "1677559",
    "end": "1684399"
  },
  {
    "text": "blog.com newws to also receive our free companion email with even more developer",
    "start": "1684399",
    "end": "1689799"
  },
  {
    "text": "news worth your attention once again that's",
    "start": "1689799",
    "end": "1694840"
  },
  {
    "text": "[Music] changelog.md love for you to maybe",
    "start": "1695450",
    "end": "1703000"
  },
  {
    "text": "describe if you can we we've kind of talked about the problems that you're addressing we've talked about about the",
    "start": "1703000",
    "end": "1709480"
  },
  {
    "text": "sort of workflows that you're enabling the evaluation some trends that you're seeing but I'd love for you to describe",
    "start": "1709480",
    "end": "1716159"
  },
  {
    "text": "if you can maybe for like a non-technical Persona like a domain expert who's engaging with the human",
    "start": "1716159",
    "end": "1722960"
  },
  {
    "text": "loop system and maybe for a more technical person who's integrating you",
    "start": "1722960",
    "end": "1728840"
  },
  {
    "text": "know data sources or other things what does it look like to use the human loop",
    "start": "1728840",
    "end": "1735840"
  },
  {
    "text": "system maybe describe the roles in in which these people are like what they're",
    "start": "1735840",
    "end": "1741880"
  },
  {
    "text": "trying to do from each perspective because I think that might be instructive for people that are trying",
    "start": "1741880",
    "end": "1747640"
  },
  {
    "text": "to engage domain experts and Technical people in a collaboration around these problems absolutely so maybe it might be",
    "start": "1747640",
    "end": "1754159"
  },
  {
    "text": "helpful to have a kind of imagined concrete example so a very common example we see is people building some",
    "start": "1754159",
    "end": "1759880"
  },
  {
    "text": "kind of question answering system maybe it's for their internal customer service staff or maybe they want to replace an",
    "start": "1759880",
    "end": "1765559"
  },
  {
    "text": "FAQ that uh sorry I'm just going to drink of water maybe they're trying to build some kind of internal question answering system to replace something or",
    "start": "1765559",
    "end": "1773200"
  },
  {
    "text": "an FAQ or that kind of thing so there's a set of documents or questions going to come in there'll be a retrieval step and",
    "start": "1773200",
    "end": "1778600"
  },
  {
    "text": "then they want to generate an answer so typically the the PMS or the domain experts would be figuring out you know",
    "start": "1778600",
    "end": "1784840"
  },
  {
    "text": "what are the requirements of the system what does good look like what do we want it to build and the engineers will be",
    "start": "1784840",
    "end": "1790440"
  },
  {
    "text": "building the retrieval part orchestrating all the model calls in code integrating the human Loop apis",
    "start": "1790440",
    "end": "1796640"
  },
  {
    "text": "into their system and also usually they lead on setting up evaluation so maybe",
    "start": "1796640",
    "end": "1802200"
  },
  {
    "text": "once it's set up the domain experts might continue to do the evaluation themselves but the engineers tend to set",
    "start": "1802200",
    "end": "1807679"
  },
  {
    "text": "it up the first time so if you're the domain expert typically you would start off in our playground environment where",
    "start": "1807679",
    "end": "1813600"
  },
  {
    "text": "you can just try things out so the engineers might connect a database to human Loop for you so maybe they'll",
    "start": "1813600",
    "end": "1819120"
  },
  {
    "text": "store the data in a vector database um and connect that to human Loop and then once you're in that environment you",
    "start": "1819120",
    "end": "1824760"
  },
  {
    "text": "could try different prompts to the models you could try them to cheap 4 to coher to an open source model see what",
    "start": "1824760",
    "end": "1831000"
  },
  {
    "text": "impact that has see if you're getting answers that you like right often times early on it's not in the right tone of",
    "start": "1831000",
    "end": "1836559"
  },
  {
    "text": "voice or the retrieval system is not quite right and so the model it's not giving factually correct answers so it",
    "start": "1836559",
    "end": "1842039"
  },
  {
    "text": "takes a certain amount of iteration to get to the point where even when you eyeball it it's looking appropriate and",
    "start": "1842039",
    "end": "1847799"
  },
  {
    "text": "usually at that point people then move to doing a little bit more of a rigorous evaluation so they might generate either",
    "start": "1847799",
    "end": "1854080"
  },
  {
    "text": "automatically or internally a set of test cases and they'll also come up with a set of evaluation criteria that matter",
    "start": "1854080",
    "end": "1860480"
  },
  {
    "text": "to them in their context they'll set up that evaluation run it and then usually at that point they might deploy to",
    "start": "1860480",
    "end": "1866919"
  },
  {
    "text": "production so that's the point at which things would you know end up with real users they start Gathering user feedback",
    "start": "1866919",
    "end": "1873080"
  },
  {
    "text": "and usually the Situation's not finished at that point because people then you know look at the production logs or they",
    "start": "1873080",
    "end": "1878720"
  },
  {
    "text": "look at the real usage data and they will filter based on the evaluation criteria and they might say hey show me",
    "start": "1878720",
    "end": "1883960"
  },
  {
    "text": "the ones that didn't result in a good outcome and then they'll try and debug them and some way maybe make a change to",
    "start": "1883960",
    "end": "1889240"
  },
  {
    "text": "a prompt rerun the evaluation and submit it and so the engineers are doing the orchestration of the code they're",
    "start": "1889240",
    "end": "1896240"
  },
  {
    "text": "typically making the model calls they'll add login calls to human Loop so the way that works there's a couple of ways of",
    "start": "1896240",
    "end": "1902919"
  },
  {
    "text": "doing the integration but you can imagine every time you call the model you're effectively also logging back to human Loop what the inputs and outputs",
    "start": "1902919",
    "end": "1909279"
  },
  {
    "text": "were as well as any user feedback data and then the the domain experts are typically looking at the data analyzing",
    "start": "1909279",
    "end": "1916159"
  },
  {
    "text": "it debugging making decisions how to improve things and they're able to actually take some of those actions",
    "start": "1916159",
    "end": "1921720"
  },
  {
    "text": "themselves in the UI yeah and so if I just kind of abstract that a bit to",
    "start": "1921720",
    "end": "1928760"
  },
  {
    "text": "maybe give people a frame of thinking it sounds like there's kind of this framework setup where there's data",
    "start": "1928760",
    "end": "1935480"
  },
  {
    "text": "sources there's maybe logging calls within an application a version of an",
    "start": "1935480",
    "end": "1941320"
  },
  {
    "text": "application there's if you're using a hosted model or if you're using um a",
    "start": "1941320",
    "end": "1946840"
  },
  {
    "text": "proprietary API you you decide that and so it's kind of set up and then there's",
    "start": "1946840",
    "end": "1952919"
  },
  {
    "text": "maybe an evaluation or prototyping phase let's call it where uh the domain experts try",
    "start": "1952919",
    "end": "1959000"
  },
  {
    "text": "their prompting eventually they find prompts that they think will work well for these various steps in a workflow or",
    "start": "1959000",
    "end": "1966000"
  },
  {
    "text": "something like that those are pushed as you said I think one way into the actual",
    "start": "1966000",
    "end": "1971519"
  },
  {
    "text": "code or applications such that the domain experts are are in charge of the",
    "start": "1971519",
    "end": "1976720"
  },
  {
    "text": "prompting to some degree and as you're logging feedback into the system the",
    "start": "1976720",
    "end": "1982679"
  },
  {
    "text": "domain experts are able to iterate on their prompts which hopefully then improve the system and those are then",
    "start": "1982679",
    "end": "1988120"
  },
  {
    "text": "pushed back into the production system maybe after an evaluation or something",
    "start": "1988120",
    "end": "1993279"
  },
  {
    "text": "is that a fair representation yeah I think that's a great representation thanks for articulating it so clearly",
    "start": "1993279",
    "end": "1999120"
  },
  {
    "text": "and the kinds of things that the evaluation becomes useful for is avoiding regression say right so people",
    "start": "1999120",
    "end": "2004840"
  },
  {
    "text": "might notice one type of problem they go in and they change to prompt or they change the retrieval system and they",
    "start": "2004840",
    "end": "2009919"
  },
  {
    "text": "want to make sure they don't break what was already working and so having good evaluation in place helps with that and",
    "start": "2009919",
    "end": "2015840"
  },
  {
    "text": "then maybe it's also worth because I think we didn't sort of do this at the beginning just thinking about like what are the components of these llm",
    "start": "2015840",
    "end": "2022799"
  },
  {
    "text": "applications so I think you're exactly right we sort of think of the blocks of you know LM map being composed of a base",
    "start": "2022799",
    "end": "2028639"
  },
  {
    "text": "model so that might be a private fine tune model or one of these large public ones um a prompt template which is",
    "start": "2028639",
    "end": "2035240"
  },
  {
    "text": "usually an instruction to the model that might have Gap in it for retrieve data or context a data collection strategy",
    "start": "2035240",
    "end": "2043760"
  },
  {
    "text": "and then that whole thing of like data collection prompt template and model might be chained together in a loop or",
    "start": "2043760",
    "end": "2050599"
  },
  {
    "text": "might be repeated you know one after another and uh there's an extra complexity which is the models might",
    "start": "2050599",
    "end": "2056800"
  },
  {
    "text": "also be allowed to call tools or apis so but I think those pieces to get taken",
    "start": "2056800",
    "end": "2061878"
  },
  {
    "text": "together more or less comprehensively cover things so tools data retrieval prompt template and base model are the",
    "start": "2061879",
    "end": "2068440"
  },
  {
    "text": "main components but then within each of those you have a lot of design choices and freedom and so you know you have a",
    "start": "2068440",
    "end": "2074679"
  },
  {
    "text": "combinator large number of decisions to get right when building one of these applications one of the things that you",
    "start": "2074679",
    "end": "2080599"
  },
  {
    "text": "mentioned is uh this evaluation phase of what goes on as helping prevent",
    "start": "2080599",
    "end": "2086599"
  },
  {
    "text": "regressions because in sort of testing behaviorally the output of the models",
    "start": "2086599",
    "end": "2092200"
  },
  {
    "text": "you might make one change on a small set of examples that looks like it's improving things but has sort of",
    "start": "2092200",
    "end": "2098680"
  },
  {
    "text": "different Behavior across a wide range of examples I'm wondering also um I",
    "start": "2098680",
    "end": "2104119"
  },
  {
    "text": "could imagine two scenarios you know models are being released all the time whether it's upgrading from this version",
    "start": "2104119",
    "end": "2110520"
  },
  {
    "text": "of a GPT model to the next version or this Mistral fine tune to this one over",
    "start": "2110520",
    "end": "2116040"
  },
  {
    "text": "here I'm thinking even you know in the past few days we've been we've been using uh the neural chat model from",
    "start": "2116040",
    "end": "2121920"
  },
  {
    "text": "Intel a good bit and there's a version of that that neural magic released that's a sparsified version of that",
    "start": "2121920",
    "end": "2129440"
  },
  {
    "text": "where they pruned out some of the weights and and the layers to make it more efficient and to run on better or",
    "start": "2129440",
    "end": "2136920"
  },
  {
    "text": "or not better Hardware but more commodity Hardware that's more widely available and so one of the questions",
    "start": "2136920",
    "end": "2141960"
  },
  {
    "text": "that we were discussing is well we could flip the version of this model to the sparse one but we have to decide on how",
    "start": "2141960",
    "end": "2150200"
  },
  {
    "text": "to evaluate that over the use cases that we care about because you could look at the output for like a few test prompts",
    "start": "2150200",
    "end": "2157319"
  },
  {
    "text": "right and it might look similar or good or even better but on a wider scale",
    "start": "2157319",
    "end": "2163200"
  },
  {
    "text": "might be quite different in ways that you don't expect so I could see that the",
    "start": "2163200",
    "end": "2168880"
  },
  {
    "text": "evaluation also being used for that but I could also see where if you're upgrading to a new model it could just",
    "start": "2168880",
    "end": "2174839"
  },
  {
    "text": "throw everything up in the air in terms of like oh this is an entirely different prompt format right or um this is a",
    "start": "2174839",
    "end": "2182680"
  },
  {
    "text": "whole new uh behavior from this new model that is distinct from an old model",
    "start": "2182680",
    "end": "2188480"
  },
  {
    "text": "so how how are you seeing people navigate that landscape of model upgrades I think you should just view it",
    "start": "2188480",
    "end": "2194760"
  },
  {
    "text": "as a you know a change as you would to any other part of the system and hopefully the desired behavior of the model is not changing so even if the",
    "start": "2194760",
    "end": "2201920"
  },
  {
    "text": "model is changed you know you still want to run your regression test and say okay are we meeting a minimum threshold that",
    "start": "2201920",
    "end": "2207839"
  },
  {
    "text": "we had on these gold standard tests set before in general I think evaluation we",
    "start": "2207839",
    "end": "2213040"
  },
  {
    "text": "see it happening at sort of three different stages during development there's during this interactive stage",
    "start": "2213040",
    "end": "2219040"
  },
  {
    "text": "very early on when you're prototyping you want fast feedback you're just looking to get a sense of you know is",
    "start": "2219040",
    "end": "2224319"
  },
  {
    "text": "this even working appropriately at that stage you know eyeballing examples and looking at things side by side in a very",
    "start": "2224319",
    "end": "2230680"
  },
  {
    "text": "interactive way can be helpful and interactive testing can also be helpful for adversarial testing so you know a",
    "start": "2230680",
    "end": "2236599"
  },
  {
    "text": "fixed test set doesn't tell you what will happen when a user who actually wants to break the system comes in so a",
    "start": "2236599",
    "end": "2242520"
  },
  {
    "text": "concrete example of this you know one of our customers has children as their end",
    "start": "2242520",
    "end": "2247920"
  },
  {
    "text": "users and they want to make sure that things are age appropriate so they have guard rails in place but when they come",
    "start": "2247920",
    "end": "2253520"
  },
  {
    "text": "to test the system they don't want to just test it for against you know a use Cas an input that's benign they want to",
    "start": "2253520",
    "end": "2261400"
  },
  {
    "text": "see like if we try if we really red team this can we break it and there interactive testing can be very helpful",
    "start": "2261400",
    "end": "2267839"
  },
  {
    "text": "and then the next place where you kind of want testing in place is this regression testing where you have a fixed set of evaluators on a test set",
    "start": "2267839",
    "end": "2274839"
  },
  {
    "text": "and you want to know when I make a change does it get worse and the final place we see people using it is actually for monitoring so okay I'm in production",
    "start": "2274839",
    "end": "2281920"
  },
  {
    "text": "now there's new data flowing through I may not have the ground truth answer but I can still set up different forms of",
    "start": "2281920",
    "end": "2287800"
  },
  {
    "text": "evaluator and I want to be alerted if the performance drops below some threshold so one of the things that I've",
    "start": "2287800",
    "end": "2295200"
  },
  {
    "text": "been thinking about throughout our conversation here and that that's I think highlighted by what you just mentioned and sort of the upgrades to",
    "start": "2295200",
    "end": "2302599"
  },
  {
    "text": "one's workflow and the various levels at which such a platform can benefit uh",
    "start": "2302599",
    "end": "2309319"
  },
  {
    "text": "teams and it made me think of you know used to I have a background in in",
    "start": "2309319",
    "end": "2315599"
  },
  {
    "text": "physics and there were plenty of physics teams or collaborators that we worked with you know we were writing code and",
    "start": "2315599",
    "end": "2322640"
  },
  {
    "text": "not doing great sort of Version Control practices and not everyone was using",
    "start": "2322640",
    "end": "2328319"
  },
  {
    "text": "GitHub and there's sort of collaboration challenges associated with that which",
    "start": "2328319",
    "end": "2334599"
  },
  {
    "text": "are obviously solved by great code collaboration systems that are of various forms that",
    "start": "2334599",
    "end": "2340640"
  },
  {
    "text": "have been developed over over time and I think there's probably a parallel here with some of the collaboration systems",
    "start": "2340640",
    "end": "2347800"
  },
  {
    "text": "that are being built around both playgrounds and prompts and evaluation",
    "start": "2347800",
    "end": "2353000"
  },
  {
    "text": "I'm wondering if you could um if there's any examples from clients that you've",
    "start": "2353000",
    "end": "2358680"
  },
  {
    "text": "worked with or maybe it's just interesting use cases of surprising things they've been able to do when",
    "start": "2358680",
    "end": "2364960"
  },
  {
    "text": "going from sort of doing things ad hoc and maybe versioning prompts in",
    "start": "2364960",
    "end": "2370280"
  },
  {
    "text": "spreadsheets or whatever it might be to actually being able to work in a more seamless way between domain experts and",
    "start": "2370280",
    "end": "2377880"
  },
  {
    "text": "Technical staff are there any clients or use cases or surprising stories that um",
    "start": "2377880",
    "end": "2384240"
  },
  {
    "text": "that come to mind it's a good question I'm kind of thinking through them to see you know what the more interesting examples might be I think that",
    "start": "2384240",
    "end": "2391800"
  },
  {
    "text": "fundamentally it's not necessarily enabling completely new Behavior right but it's making the old Behavior",
    "start": "2391800",
    "end": "2397839"
  },
  {
    "text": "significantly faster and less error prone so you know certainly fewer",
    "start": "2397839",
    "end": "2403200"
  },
  {
    "text": "mistakes and less time spent you know one okay so a surprising example publicly listed company and they told me",
    "start": "2403200",
    "end": "2409920"
  },
  {
    "text": "that one of the issues they were having is because they were sharing these prompt configs in teams they were having",
    "start": "2409920",
    "end": "2417240"
  },
  {
    "text": "differences in Behavior based on whites space being copied so the you know someone was like playing around with the",
    "start": "2417240",
    "end": "2423040"
  },
  {
    "text": "opening eye playground they'd copy paste it into teams that person would copy paste from teams into code and there was",
    "start": "2423040",
    "end": "2429720"
  },
  {
    "text": "small Whit space differences and you wouldn't think it should expect affect the models but it actually did and so",
    "start": "2429720",
    "end": "2435280"
  },
  {
    "text": "they would then get performance differences they couldn't explain and actually it just turned out that you know you shouldn't be sharing your code",
    "start": "2435280",
    "end": "2442160"
  },
  {
    "text": "via team right so I guess that's one one surprising example I think another thing",
    "start": "2442160",
    "end": "2447359"
  },
  {
    "text": "as well is the complexity of apps that people are now beginning to be able to",
    "start": "2447359",
    "end": "2452720"
  },
  {
    "text": "build so increasingly I think people are building simple agents right I think",
    "start": "2452720",
    "end": "2459079"
  },
  {
    "text": "more complex agents are still not super reliable but a trend that we've been hearing a lot about from our customers",
    "start": "2459079",
    "end": "2464480"
  },
  {
    "text": "recently is people trying to build assistants that can use their existing software so you know an example of this",
    "start": "2464480",
    "end": "2472079"
  },
  {
    "text": "is you know Ironclad is a is a company that's added a lot of llm based features",
    "start": "2472079",
    "end": "2477160"
  },
  {
    "text": "to their product and they actually are able to automate a lot of workflows that were previously being done by humans",
    "start": "2477160",
    "end": "2484640"
  },
  {
    "text": "because the models can use the apis that exist within the Ironclad software so they're actually you know able to",
    "start": "2484640",
    "end": "2490640"
  },
  {
    "text": "leverage their existing infrastructure but to get that to work they had to innovate quite a lot in tooling and in",
    "start": "2490640",
    "end": "2496359"
  },
  {
    "text": "fact you know this is in the plug for human Loop Ironclad in this case built a system called rivet which is their own",
    "start": "2496359",
    "end": "2502520"
  },
  {
    "text": "open-source you know prompt engineering and iteration framework but I think it's a good example of you know in order to",
    "start": "2502520",
    "end": "2508760"
  },
  {
    "text": "achieve the complexity of that use case this happened to be before tools like human loop around they had to build",
    "start": "2508760",
    "end": "2514240"
  },
  {
    "text": "something themselves um and it's quite sophisticated tooling I actually think rivet's great so people should check",
    "start": "2514240",
    "end": "2519480"
  },
  {
    "text": "that out as well it's an open source Library anyone can go and get the tool so yeah I I think the surprising things",
    "start": "2519480",
    "end": "2524960"
  },
  {
    "text": "are like how error prone things are without good tooling and and the crazy ways in which people are solving",
    "start": "2524960",
    "end": "2530359"
  },
  {
    "text": "problems another example of a mistake that we saw someone do is two different people triggered exactly the same",
    "start": "2530359",
    "end": "2535680"
  },
  {
    "text": "annotation job so they had annotation and spreadsheets and uh they both outsourced the same job to different",
    "start": "2535680",
    "end": "2542280"
  },
  {
    "text": "annotation teams uh which is obviously an expensive mistake to make so very ER",
    "start": "2542280",
    "end": "2547319"
  },
  {
    "text": "prone and then I think also just like impossible to scale to more complex agentic use cases well you you already",
    "start": "2547319",
    "end": "2554400"
  },
  {
    "text": "kind of alluded to some uh trends that you're seeing moving forward as we kind",
    "start": "2554400",
    "end": "2560559"
  },
  {
    "text": "of draw to a close here I'd love to know from someone who's seeing a lot of",
    "start": "2560559",
    "end": "2565760"
  },
  {
    "text": "different use cases being enabled through human Loop and and your platform what's exciting for you as you move into",
    "start": "2565760",
    "end": "2574200"
  },
  {
    "text": "this next year in terms of maybe things that are happening in in AI more broadly",
    "start": "2574200",
    "end": "2580559"
  },
  {
    "text": "or things that are being enabled by human Loop or things that are on your road map that you can't wait for them to",
    "start": "2580559",
    "end": "2587800"
  },
  {
    "text": "to go live what uh as you're lying in bed at night and getting excited for for",
    "start": "2587800",
    "end": "2593160"
  },
  {
    "text": "the next day of AI stuff what's on your mind so AI more broadly I just feel the rate of progress of capabilities is both",
    "start": "2593160",
    "end": "2600960"
  },
  {
    "text": "exciting and scary right it's extremely fast multimodal models better generative models models with increased reasoning I",
    "start": "2600960",
    "end": "2607960"
  },
  {
    "text": "think the range of possible applications is expanding very quickly as the capabilities of the models expand I",
    "start": "2607960",
    "end": "2614240"
  },
  {
    "text": "think people have been excited about agent use cases for a while right systems that can act on their own and",
    "start": "2614240",
    "end": "2620480"
  },
  {
    "text": "and go off and Achieve something for you but in practice we've not seen that many people succeed in production with those",
    "start": "2620480",
    "end": "2626680"
  },
  {
    "text": "there are a couple of examples ironcloud being a good one but it feels like we're still at the very beginning of that and",
    "start": "2626680",
    "end": "2632760"
  },
  {
    "text": "I think I'm excited about seeing more people get to success with that I'd say that the most common you know successful",
    "start": "2632760",
    "end": "2639319"
  },
  {
    "text": "applications we've seen today are mostly either retrieval augmented applications",
    "start": "2639319",
    "end": "2644440"
  },
  {
    "text": "or more simple you know llm applications but increasingly I'm excited about seeing agents in production and also",
    "start": "2644440",
    "end": "2650240"
  },
  {
    "text": "multimodal models in production in terms of things that I'm particularly excited about from Human Loop is I think us",
    "start": "2650240",
    "end": "2656880"
  },
  {
    "text": "becoming a proactive rather than a passive platform so today the product managers and the engineers Drive the",
    "start": "2656880",
    "end": "2663400"
  },
  {
    "text": "changes on human Loop but I think that something that we're going to hopefully released later this year is actually",
    "start": "2663400",
    "end": "2669240"
  },
  {
    "text": "where the system you know human Loop itself can start proactively suggesting improvements to your application because",
    "start": "2669240",
    "end": "2675119"
  },
  {
    "text": "we have the evaluation data because we have all the prompts we can start saying things to you like hey you know we have",
    "start": "2675119",
    "end": "2680960"
  },
  {
    "text": "a new prompt for this application it's a lot shorter than the one you have it scores similar on eval data if you",
    "start": "2680960",
    "end": "2686480"
  },
  {
    "text": "upgrade we think we can cut your costs by 40% and allowing people to then accept that change and so going from A",
    "start": "2686480",
    "end": "2692599"
  },
  {
    "text": "system that is observing to a system that's actually uh intervening that's that's awesome yeah well I definitely",
    "start": "2692599",
    "end": "2698760"
  },
  {
    "text": "look forward to seeing how that rolls out and really appreciate the work that that you and the team at human Loop are",
    "start": "2698760",
    "end": "2705520"
  },
  {
    "text": "doing to help us upgrade our our workflows and enable these sort of more",
    "start": "2705520",
    "end": "2710640"
  },
  {
    "text": "complicated use cases so thank you so much for taking time out of that work to join us uh it's been a been a pleasure",
    "start": "2710640",
    "end": "2717280"
  },
  {
    "text": "uh really enjoyed the conversation thanks so much for having me [Music]",
    "start": "2717280",
    "end": "2724179"
  },
  {
    "text": "Daniel all right that is practical AI for this week subscribe now if you haven't",
    "start": "2725960",
    "end": "2733480"
  },
  {
    "text": "already head to practical aai FM for all the ways and join our free slack team",
    "start": "2733480",
    "end": "2740280"
  },
  {
    "text": "where you can hang out with Daniel Chris and the entire change log Community sign up today at practical ai. fm/ Community",
    "start": "2740280",
    "end": "2750319"
  },
  {
    "text": "thanks again to our partners at fly.io to our beat freaking residence breakmaster cylinder and to you for",
    "start": "2750319",
    "end": "2756720"
  },
  {
    "text": "listen listening we appreciate you spending time with us that's all for now we'll talk to you again next",
    "start": "2756720",
    "end": "2764318"
  },
  {
    "text": "[Music]",
    "start": "2767160",
    "end": "2772760"
  },
  {
    "text": "time",
    "start": "2772760",
    "end": "2775760"
  }
]
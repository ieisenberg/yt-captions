[
  {
    "text": "like there's a",
    "start": "2879",
    "end": "3840"
  },
  {
    "text": "very straightforward way of cutting down",
    "start": "3840",
    "end": "7359"
  },
  {
    "text": "the latency",
    "start": "7359",
    "end": "8639"
  },
  {
    "text": "like the tail latency in your requests",
    "start": "8639",
    "end": "11200"
  },
  {
    "text": "so if you have a request let's say that",
    "start": "11200",
    "end": "13120"
  },
  {
    "text": "you have a request that you send into a",
    "start": "13120",
    "end": "14719"
  },
  {
    "text": "server and it takes",
    "start": "14719",
    "end": "16400"
  },
  {
    "text": "five milliseconds 99 of the time",
    "start": "16400",
    "end": "19760"
  },
  {
    "text": "but then there's one percent of the time",
    "start": "19760",
    "end": "21439"
  },
  {
    "text": "that it takes one minute",
    "start": "21439",
    "end": "23199"
  },
  {
    "text": "which is not good so what you could do",
    "start": "23199",
    "end": "25760"
  },
  {
    "text": "is",
    "start": "25760",
    "end": "26400"
  },
  {
    "text": "make that call multiple times and you're",
    "start": "26400",
    "end": "28960"
  },
  {
    "text": "gonna do it with",
    "start": "28960",
    "end": "30000"
  },
  {
    "text": "with cancellation so you're gonna do",
    "start": "30000",
    "end": "31920"
  },
  {
    "text": "context with cancel",
    "start": "31920",
    "end": "33200"
  },
  {
    "text": "of your original context and then what",
    "start": "33200",
    "end": "35600"
  },
  {
    "text": "you're gonna do is you're gonna use the",
    "start": "35600",
    "end": "36880"
  },
  {
    "text": "same context for all of those calls",
    "start": "36880",
    "end": "39440"
  },
  {
    "text": "and have defer cancel at the top of your",
    "start": "39440",
    "end": "42480"
  },
  {
    "text": "function",
    "start": "42480",
    "end": "43360"
  },
  {
    "text": "and then as soon as any of those values",
    "start": "43360",
    "end": "46079"
  },
  {
    "text": "returns",
    "start": "46079",
    "end": "46719"
  },
  {
    "text": "and you return from that function the",
    "start": "46719",
    "end": "48800"
  },
  {
    "text": "rest will be canceled",
    "start": "48800",
    "end": "50160"
  },
  {
    "text": "and that's gonna take down your 99th",
    "start": "50160",
    "end": "52000"
  },
  {
    "text": "percentile from like",
    "start": "52000",
    "end": "53600"
  },
  {
    "text": "one minute down to five milliseconds so",
    "start": "53600",
    "end": "56079"
  },
  {
    "text": "that's like",
    "start": "56079",
    "end": "56719"
  },
  {
    "text": "small things that you can get a lot of",
    "start": "56719",
    "end": "58879"
  },
  {
    "text": "performance",
    "start": "58879",
    "end": "59760"
  },
  {
    "text": "especially when you're using a server",
    "start": "59760",
    "end": "62000"
  },
  {
    "text": "that is",
    "start": "62000",
    "end": "62800"
  },
  {
    "text": "not something you manage so you cannot",
    "start": "62800",
    "end": "65198"
  },
  {
    "text": "go and complain about complaining to",
    "start": "65199",
    "end": "66960"
  },
  {
    "text": "them about like hey you're 99 percent",
    "start": "66960",
    "end": "68880"
  },
  {
    "text": "latency is awful you can still fix a",
    "start": "68880",
    "end": "71360"
  },
  {
    "text": "bike doing this little hack",
    "start": "71360",
    "end": "79360"
  }
]
[
  {
    "start": "0",
    "end": "43000"
  },
  {
    "text": "[Music]",
    "start": "280",
    "end": "5779"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspire to or are",
    "start": "6720",
    "end": "13920"
  },
  {
    "text": "curious how AI related Tech is changing the world this is the show for you thank",
    "start": "13920",
    "end": "20519"
  },
  {
    "text": "you to our partners at fly.io the home of",
    "start": "20519",
    "end": "25759"
  },
  {
    "text": "changelog.md 30 plus regions on six continents so you can launch your app",
    "start": "28960",
    "end": "34440"
  },
  {
    "text": "near your users learn more at",
    "start": "34440",
    "end": "38718"
  },
  {
    "text": "[Music] fly.io welcome to another episode of the",
    "start": "39550",
    "end": "45520"
  },
  {
    "start": "43000",
    "end": "118000"
  },
  {
    "text": "Practical AI podcast my name is Daniel whack I am CEO and founder at prediction",
    "start": "45520",
    "end": "51760"
  },
  {
    "text": "guard and I'm joined as always by my co-host Chris Benson who is a principal",
    "start": "51760",
    "end": "57120"
  },
  {
    "text": "AI research engineer at locked Martin how you doing Chris doing great today daniiel how's it going it's going great",
    "start": "57120",
    "end": "63480"
  },
  {
    "text": "the sun is out and uh summer is upon us along with uh lots of new AI models and",
    "start": "63480",
    "end": "70680"
  },
  {
    "text": "excitement going on in the space and on that note uh specifically as related to",
    "start": "70680",
    "end": "76320"
  },
  {
    "text": "large language models we're really excited to have with us today yov who is",
    "start": "76320",
    "end": "82200"
  },
  {
    "text": "the co-founder and co-ceo of AI 21 and professor ameritus at Stanford welcome",
    "start": "82200",
    "end": "89079"
  },
  {
    "text": "yov how you doing I'm doing good really a pleasure to be with you guys yeah yeah we're we're so",
    "start": "89079",
    "end": "95200"
  },
  {
    "text": "excited to have you on it's a a show we've been wanting to have for for some time now I'm wondering if you could kind",
    "start": "95200",
    "end": "103119"
  },
  {
    "text": "of give us a little bit of the background of AI 21 and specifically",
    "start": "103119",
    "end": "108880"
  },
  {
    "text": "maybe how you view AI 21 as fitting into this wider landscape of llm companies",
    "start": "108880",
    "end": "117479"
  },
  {
    "text": "and technology so maybe a good starting point will be to say why we started the",
    "start": "117479",
    "end": "122680"
  },
  {
    "text": "company in the first place a little over six years ago we started the company",
    "start": "122680",
    "end": "127719"
  },
  {
    "text": "because we believe that deep learning remember at the time llms were not a",
    "start": "127719",
    "end": "132800"
  },
  {
    "text": "thing but deep learning was mostly applied to Vision we believe that modern dayi uh requires deep learning it's a",
    "start": "132800",
    "end": "140000"
  },
  {
    "text": "necessary component but not sufficient we believe that certain aspects of intelligence this thing we often call",
    "start": "140000",
    "end": "146360"
  },
  {
    "text": "reasoning will not emerge purely from the statistics and it's the sort of thing AI did back",
    "start": "146360",
    "end": "152480"
  },
  {
    "text": "in the uh in the 80s and we believe that uh we left money on the table and it's",
    "start": "152480",
    "end": "158200"
  },
  {
    "text": "time to bring the two together that's why we started the company uh now fast forward today where what does the",
    "start": "158200",
    "end": "164760"
  },
  {
    "text": "landscape look like and where do we fit in so although I said that large language model so very quickly we fell",
    "start": "164760",
    "end": "171519"
  },
  {
    "text": "into llms uh we uh we the heaviest uses of gpt3 when it came out uh we decided",
    "start": "171519",
    "end": "177760"
  },
  {
    "text": "to roll our own and really Lang anguage is where the action is because we often say that Machine Vision is a lens into",
    "start": "177760",
    "end": "184760"
  },
  {
    "text": "the human eye but language is a lens into the human mind because there's no",
    "start": "184760",
    "end": "190080"
  },
  {
    "text": "thought as intricate and nuanced as you want that can't in some way be expressed",
    "start": "190080",
    "end": "195599"
  },
  {
    "text": "in language uh vision is an quote unquote easy problem of course it's not easy but there's something to understand",
    "start": "195599",
    "end": "203200"
  },
  {
    "text": "that this is a phone I don't really care what the pixel is way on the on the side",
    "start": "203200",
    "end": "208720"
  },
  {
    "text": "here always exact true but it's really primarily true that's not true with language language connections matter",
    "start": "208720",
    "end": "215080"
  },
  {
    "text": "terribly you change a word here the whole meaning of the sentence changes in general you can't escape semantics when",
    "start": "215080",
    "end": "221439"
  },
  {
    "text": "you deal with uh with language and so it's harder but if you crack it that's",
    "start": "221439",
    "end": "226680"
  },
  {
    "text": "gold uh if you look at the Enterprise from the beginning we were focused on the Enterprise 80% of the data in the",
    "start": "226680",
    "end": "233280"
  },
  {
    "text": "Enterprise is text mostly um either not used or way underused and there's a",
    "start": "233280",
    "end": "239360"
  },
  {
    "text": "really good opportunity there and that's kind of been our Focus so of course we're not the only uh people uh with",
    "start": "239360",
    "end": "246040"
  },
  {
    "text": "large language models um we are one of the handful of companies that do really",
    "start": "246040",
    "end": "252680"
  },
  {
    "text": "large very capable language models our first model was called Jurassic 1 was",
    "start": "252680",
    "end": "258919"
  },
  {
    "text": "going back a few years it was not a most Innovative model but it was a good Workhorse it was uh GPT like Auto",
    "start": "258919",
    "end": "266680"
  },
  {
    "text": "regressive left to right model and at the time was slightly bigger slightly better than gpt3 of course both those",
    "start": "266680",
    "end": "272639"
  },
  {
    "text": "models are by now Eclipse we very recently released our most recent model",
    "start": "272639",
    "end": "277720"
  },
  {
    "text": "called Jamba which is uh very interesting in a number of ways and we",
    "start": "277720",
    "end": "283440"
  },
  {
    "text": "can dig deeper but maybe at uh you know 30,000 feet architecturally it's uh it's different",
    "start": "283440",
    "end": "290360"
  },
  {
    "text": "it's not pure Transformer model it really is mostly based on structur Space",
    "start": "290360",
    "end": "298000"
  },
  {
    "text": "structured space state model sssm as they're called and we can speak about",
    "start": "298000",
    "end": "303720"
  },
  {
    "text": "the advantages and disadvantages of those but basically we took that architecture and added elements of",
    "start": "303720",
    "end": "310240"
  },
  {
    "text": "Transformers the attention layer to get the bo of Both Worlds and you get performance that is as good as any model",
    "start": "310240",
    "end": "316720"
  },
  {
    "text": "of its size better than most of its kind of size group and extremely efficient we",
    "start": "316720",
    "end": "324080"
  },
  {
    "text": "have a context length that's larger than any other model in the size like a you know we released the the version",
    "start": "324080",
    "end": "329360"
  },
  {
    "text": "released has a 250k context window length although we trained it up to a",
    "start": "329360",
    "end": "334919"
  },
  {
    "text": "million and yet it all fits onto a single 80 gigabyte GPU and so your show",
    "start": "334919",
    "end": "343440"
  },
  {
    "text": "is titled practically I this starts to make it practical that's great and speaking of practicalities uh you",
    "start": "343440",
    "end": "350280"
  },
  {
    "start": "346000",
    "end": "522000"
  },
  {
    "text": "mentioned the focus on Enterprise from the beginning you also mentioned that a lot of data in the Enterprise is kind of",
    "start": "350280",
    "end": "357560"
  },
  {
    "text": "locked up in this unstructured text I remember when I first got into data science the the focus is oh we're",
    "start": "357560",
    "end": "364680"
  },
  {
    "text": "going to do big data and all of this cool analytics stuff with data warehouses and I think that's sort of",
    "start": "364680",
    "end": "371080"
  },
  {
    "text": "waned a little bit I'm wondering if you could talk to the that point like why",
    "start": "371080",
    "end": "376360"
  },
  {
    "text": "are Enterprises what types of value can they get out of this sort of text that's",
    "start": "376360",
    "end": "382039"
  },
  {
    "text": "sitting around and because I think maybe a lot of listeners maybe they've tried",
    "start": "382039",
    "end": "387479"
  },
  {
    "text": "you know these chat interfaces whether it chat GPT or gemini or whatever but",
    "start": "387479",
    "end": "393120"
  },
  {
    "text": "maybe they're less exposed to the workloads that enterprises are doing",
    "start": "393120",
    "end": "399000"
  },
  {
    "text": "with llms so could you give us a picture of how Enterprises are unlocking value",
    "start": "399000",
    "end": "405120"
  },
  {
    "text": "with that kind of 80% of text Data maybe just by way of example or at a high level sure and really the use cases are",
    "start": "405120",
    "end": "413039"
  },
  {
    "text": "quite broad the industries are very broad whether it's Finance or Healthcare education or you know you name it and",
    "start": "413039",
    "end": "419919"
  },
  {
    "text": "the use cases are very are varied but to pick some concrete ones let's say uh you",
    "start": "419919",
    "end": "425919"
  },
  {
    "text": "have uh manuals they're companies with thousands of manuals and whether it's",
    "start": "425919",
    "end": "431280"
  },
  {
    "text": "the end user wanting to uh I recently needed I had a new sort of oven",
    "start": "431280",
    "end": "437160"
  },
  {
    "text": "microwave combination and for the life of me I couldn't find the relevant information in the manual so I searched",
    "start": "437160",
    "end": "443319"
  },
  {
    "text": "online and so on it'd be really convenient to go and ask a question get the just the right answer but even if",
    "start": "443319",
    "end": "448960"
  },
  {
    "text": "it's not the user it could be the tech support person who themselves want to",
    "start": "448960",
    "end": "454160"
  },
  {
    "text": "get quick answers that's an example we call this contextual answers another would be summarization rather than",
    "start": "454160",
    "end": "461120"
  },
  {
    "text": "response to a specific query you have this 10K report that came out and you",
    "start": "461120",
    "end": "467360"
  },
  {
    "text": "want a py summarization of it maybe a summarization geared toward certain aspect you care about so that be another",
    "start": "467360",
    "end": "473919"
  },
  {
    "text": "use case these are both um wave of consuming data there's of course gen is",
    "start": "473919",
    "end": "480120"
  },
  {
    "text": "a terrible name uh but uh we won't find that battle you're stuck with it well",
    "start": "480120",
    "end": "485840"
  },
  {
    "text": "you know you'll get me started I'll start complaining about gen about AGI and so on uh but certainly some use",
    "start": "485840",
    "end": "492680"
  },
  {
    "text": "cases call for producing information not only consuming information so for example one of our use cases very",
    "start": "492680",
    "end": "499240"
  },
  {
    "text": "successful our product descriptions you have companies uh retailers and you know e-commerce companies who have thousands",
    "start": "499240",
    "end": "506400"
  },
  {
    "text": "of Products that come online constantly and writing a product description is labor intensive error prone expensive",
    "start": "506400",
    "end": "514279"
  },
  {
    "text": "timec consuming and we're able to compress all of that dramatically so",
    "start": "514279",
    "end": "520959"
  },
  {
    "text": "these are some use cases I'm kind of uh Curious also as you're looking at these",
    "start": "520959",
    "end": "526080"
  },
  {
    "start": "522000",
    "end": "567000"
  },
  {
    "text": "opportunities in the Enterprise uh and addressing these various use cases as a",
    "start": "526080",
    "end": "531240"
  },
  {
    "text": "company who is creating models and putting them out there for Enterprises to use for people who have not you know",
    "start": "531240",
    "end": "538680"
  },
  {
    "text": "are not in the industry itself how do you as a co-founder and CEO see your",
    "start": "538680",
    "end": "544360"
  },
  {
    "text": "company as like how do you say let's go do this like we see the value in this uh compared to others that are making",
    "start": "544360",
    "end": "550640"
  },
  {
    "text": "models like in other words if you say I'm going to make a model what is it about that motivation which makes you",
    "start": "550640",
    "end": "556920"
  },
  {
    "text": "think you'll make a difference in that Enterprise Market uh you know and you're kind of representing all companies that",
    "start": "556920",
    "end": "563560"
  },
  {
    "text": "do so just to shed some insight on on how a Founder thinks in the space I wouldn't uh preport to to represent the",
    "start": "563560",
    "end": "570519"
  },
  {
    "start": "567000",
    "end": "867000"
  },
  {
    "text": "entire industry as I'll speak for ourselves fair enough o overshot on my asking no worries but uh maybe somebody",
    "start": "570519",
    "end": "577399"
  },
  {
    "text": "is comment to others so first of all the Baseline is a general purpose very capable model there's a need for that",
    "start": "577399",
    "end": "584480"
  },
  {
    "text": "now uh there are companies who provide services using other people's um models and that's totally legit if you actually",
    "start": "584480",
    "end": "591240"
  },
  {
    "text": "own the model that you can do things that you wouldn't be able to do otherwise and our emphasis in addition",
    "start": "591240",
    "end": "598120"
  },
  {
    "text": "to the general capability of the model is in order to make it practical there",
    "start": "598120",
    "end": "604160"
  },
  {
    "text": "are two things especially in the Enterprise so if you're you know using uh you know a chatbot to you know write",
    "start": "604160",
    "end": "612360"
  },
  {
    "text": "homework assignment the stakes are low a mistake doesn't carry a big penalty uh",
    "start": "612360",
    "end": "618120"
  },
  {
    "text": "and probably won't somebody nobody would read it anyway but um if you're writing a memo to your bus or uh to your prize",
    "start": "618120",
    "end": "625920"
  },
  {
    "text": "client and if you're brilliant 95% of the time and garbage 5% of the time you're dead",
    "start": "625920",
    "end": "632480"
  },
  {
    "text": "in the water and so reliability is key and as we know white language models are",
    "start": "632480",
    "end": "638440"
  },
  {
    "text": "these amazing creative knowledgeable system but probabilistic and so you will",
    "start": "638440",
    "end": "644920"
  },
  {
    "text": "get I don't like here's another term I don't like hallucination but you'll get stuff that either isn't grounded in fact",
    "start": "644920",
    "end": "650600"
  },
  {
    "text": "doesn't make logical sense and so on and so you can't do that so you need to get high reliability that's number one I'll",
    "start": "650600",
    "end": "656880"
  },
  {
    "text": "tell you in a moment how we do that but the other thing it needs to be uh efficient you know for every customer",
    "start": "656880",
    "end": "663240"
  },
  {
    "text": "query you're going to pay $10 to answer it and it'll take you 20 seconds to answer it that's not no good either and",
    "start": "663240",
    "end": "670639"
  },
  {
    "text": "so you need to address that also so we have several things we're doing in this regard the first is what we call task",
    "start": "670639",
    "end": "677279"
  },
  {
    "text": "specific models in addition to our general purpose model like Jamba that came out we uh provide language models",
    "start": "677279",
    "end": "685000"
  },
  {
    "text": "that tailored to specific use cases you can think about it as a Matrix you have",
    "start": "685000",
    "end": "690440"
  },
  {
    "text": "Industries and you have use cases and it turns out that while initially some you know you might think that oh I'm going",
    "start": "690440",
    "end": "696880"
  },
  {
    "text": "to do a healthc care llm or a finance uh that's a little bit boiling the ocean",
    "start": "696880",
    "end": "703279"
  },
  {
    "text": "you want to be more specific and one way to specific is to think about what I'm going to use it for these are the columns so for example take uh",
    "start": "703279",
    "end": "711200"
  },
  {
    "text": "summarization um that's a specific task and now you can optimize your system and",
    "start": "711200",
    "end": "716959"
  },
  {
    "text": "I am deliberately saying system and not language models I'll tell you in a moment why but you can optimize that to",
    "start": "716959",
    "end": "722839"
  },
  {
    "text": "that use case so all companies now are experimenting with multiple Solutions as",
    "start": "722839",
    "end": "727959"
  },
  {
    "text": "they should and um in this particular use case a very large financial",
    "start": "727959",
    "end": "733199"
  },
  {
    "text": "institution took several of their financial documents several hundred and",
    "start": "733199",
    "end": "738959"
  },
  {
    "text": "tested various Solutions our task specific model and summarization and some of the general purpose models of",
    "start": "738959",
    "end": "746160"
  },
  {
    "text": "you know other companies and ours were just hands down better in terms of the quality of the answers they got there",
    "start": "746160",
    "end": "751839"
  },
  {
    "text": "was no hallucination if you pardon the expression very on point very uh",
    "start": "751839",
    "end": "757240"
  },
  {
    "text": "grounded and so on because it optimized the task but by the way if the system is",
    "start": "757240",
    "end": "763800"
  },
  {
    "text": "a fraction of the size of the general purpose model so you get the answers immediately and the cost of serving is",
    "start": "763800",
    "end": "770920"
  },
  {
    "text": "low and this enables use cases that this latency and unit economics enable use",
    "start": "770920",
    "end": "778839"
  },
  {
    "text": "cases that would just be unrealistic otherwise so our TX specific models are",
    "start": "778839",
    "end": "785360"
  },
  {
    "text": "one approach and maybe I won't overload my answer with saying why it's not only modeled but we'll get to AI systems the",
    "start": "785360",
    "end": "792720"
  },
  {
    "text": "other is and it's related having models are highly efficient that goes to Jamba",
    "start": "792720",
    "end": "797760"
  },
  {
    "text": "as an example of a model that's very capable but not big if I to jump ahead",
    "start": "797760",
    "end": "804440"
  },
  {
    "text": "and you know let's think about 2024 what are we going to see in the space among on other things uh you'll see focus on",
    "start": "804440",
    "end": "812440"
  },
  {
    "text": "total cost of ownership of the reality of serving these models you're going to see a focus on",
    "start": "812440",
    "end": "818720"
  },
  {
    "text": "reliability uh and you're also going to see focus on not the term I hate agents",
    "start": "818720",
    "end": "824480"
  },
  {
    "text": "uh but AI systems that are more elaborate than this transactional interaction with long mod tokens in you",
    "start": "824480",
    "end": "831839"
  },
  {
    "text": "know few seconds token back thank you on to the next one more elaborate so this is I think what's going to happen",
    "start": "831839",
    "end": "838000"
  },
  {
    "text": "technologically in the industry you're also going to see correlate with that the industry moved from what today's",
    "start": "838000",
    "end": "844160"
  },
  {
    "text": "mass experimentation to actual deployments uh we're we're seeing signs",
    "start": "844160",
    "end": "849320"
  },
  {
    "text": "of it now and I think 24 you'll see this uh sort of face shift there also",
    "start": "849320",
    "end": "856759"
  },
  {
    "text": "[Music]",
    "start": "859000",
    "end": "862080"
  },
  {
    "text": "[Music] this is a chang log news break on April",
    "start": "868600",
    "end": "875279"
  },
  {
    "text": "18th meta released the latest version of their open is large language model with",
    "start": "875279",
    "end": "881519"
  },
  {
    "text": "state-of-the-art performance The Verge rounds it up like this quote meta claims",
    "start": "881519",
    "end": "887160"
  },
  {
    "text": "both sizes of llama 3 beat similarly sized models like Google's Gemma and",
    "start": "887160",
    "end": "892519"
  },
  {
    "text": "Gemini mistal 7B and anthropics Claude 3 in certain benchmarking tests in the m",
    "start": "892519",
    "end": "899079"
  },
  {
    "text": "mlu Benchmark which typically measures general knowledge llama 38b performed",
    "start": "899079",
    "end": "904839"
  },
  {
    "text": "significantly better than both Gemma 7B and mistal 7B while llama 370b slightly",
    "start": "904839",
    "end": "910920"
  },
  {
    "text": "edged Gemini Pro 1.5 end quote What followed was your typical X Bros posting",
    "start": "910920",
    "end": "918000"
  },
  {
    "text": "n mind blowing demos of what llama 3 can accomplish where n equals the number",
    "start": "918000",
    "end": "923440"
  },
  {
    "text": "that a rival xbo just posted plus one not very interesting but two things that",
    "start": "923440",
    "end": "928519"
  },
  {
    "text": "did St stand out as interesting to me about this announcement first they didn't compare llama 3 to gp4 at all so",
    "start": "928519",
    "end": "935639"
  },
  {
    "text": "we can only assume it's still comes up short when compared to open AI is best second they continue to call Llama open",
    "start": "935639",
    "end": "942440"
  },
  {
    "text": "source even though the license retains the commercial requirement of your business not being too big which is 700",
    "start": "942440",
    "end": "949319"
  },
  {
    "text": "million monthly active users so I guess llama 3 is open for businesses of all sizes depending on how you define all",
    "start": "949319",
    "end": "957040"
  },
  {
    "text": "and sizes you just heard one of our five top stories from Monday's Chang log news",
    "start": "957040",
    "end": "963759"
  },
  {
    "start": "958000",
    "end": "984000"
  },
  {
    "text": "subscribe to the podcast to get all of the week's top stories and pop your email address in at",
    "start": "963759",
    "end": "970800"
  },
  {
    "text": "changelog.md per news worth your attention once again that's changel",
    "start": "973079",
    "end": "978120"
  },
  {
    "text": "log.com [Music]",
    "start": "978120",
    "end": "984040"
  },
  {
    "start": "984000",
    "end": "1021000"
  },
  {
    "text": "newws so you have I love that you bring in this element of of thinking about AI",
    "start": "984040",
    "end": "990839"
  },
  {
    "text": "systems not just large language models or the model maybe that ties a little bit into what you were just talking",
    "start": "990839",
    "end": "997319"
  },
  {
    "text": "about about more complicated workloads or automations that are likely coming as",
    "start": "997319",
    "end": "1003680"
  },
  {
    "text": "part of the solutions that people are building but I'm wondering if you could comment on that like where where does",
    "start": "1003680",
    "end": "1009120"
  },
  {
    "text": "systematic thinking and the thinking about architecting AI systems fit within",
    "start": "1009120",
    "end": "1015519"
  },
  {
    "text": "what you're seeing people do now and what you think needs to happen for them to get value out of these models so the",
    "start": "1015519",
    "end": "1022560"
  },
  {
    "start": "1021000",
    "end": "1178000"
  },
  {
    "text": "part of the answer that I'm comfortable speaking about are has to do with what is out there already and the others I'll",
    "start": "1022560",
    "end": "1029079"
  },
  {
    "text": "speculate maybe at a little more higher level so even if you look at task",
    "start": "1029079",
    "end": "1034199"
  },
  {
    "text": "specific model they're really not models they're little systems So when you say",
    "start": "1034199",
    "end": "1039918"
  },
  {
    "text": "want to do summarization and you say I care about these elements there's a little data processing and reasoning",
    "start": "1039919",
    "end": "1046360"
  },
  {
    "text": "goes on before you call the language model so you feed it you don't just stick it in the context you actually do",
    "start": "1046360",
    "end": "1052440"
  },
  {
    "text": "some reasoning so you can steer the model the right direction and then when you get something back you don't just",
    "start": "1052440",
    "end": "1058799"
  },
  {
    "text": "spit it out you don't uh sort of sample temperature zero and give the top answer you get answers and you evaluate them",
    "start": "1058799",
    "end": "1065600"
  },
  {
    "text": "with validators and only when you're confident that the answer is uh legit",
    "start": "1065600",
    "end": "1071919"
  },
  {
    "text": "you return to the user and it may sound very expensive but actually the",
    "start": "1071919",
    "end": "1077360"
  },
  {
    "text": "operation of an llm totally dominates in terms of the compute resources and time",
    "start": "1077360",
    "end": "1083480"
  },
  {
    "text": "these other elements and that's an example of a system around the language model but that's a baby step what you're",
    "start": "1083480",
    "end": "1090200"
  },
  {
    "text": "going to see is and you're already seeing it now but right now it's uh people touching parts of the elephant",
    "start": "1090200",
    "end": "1095960"
  },
  {
    "text": "and doing it in a very ad hockey way but you're going to see people stitching",
    "start": "1095960",
    "end": "1101880"
  },
  {
    "text": "together multiple call to a language model because a task may require multiple things and it's not just",
    "start": "1101880",
    "end": "1107919"
  },
  {
    "text": "chaining it can be more complicated scripts that you're running but you can't just do it it's not like writing a",
    "start": "1107919",
    "end": "1114520"
  },
  {
    "text": "you know a script you know a script familiar scripting language uh and running it because the Computing",
    "start": "1114520",
    "end": "1121559"
  },
  {
    "text": "elements here are different they're expensive and they're error prone and if",
    "start": "1121559",
    "end": "1127280"
  },
  {
    "text": "you just for example Cascade C language model number one it can be very expensive and second these errors",
    "start": "1127280",
    "end": "1134640"
  },
  {
    "text": "compounds and you get at the end much more noise than signal and so you need to worry about that you need to execute",
    "start": "1134640",
    "end": "1142799"
  },
  {
    "text": "differently and so that's an example of what you'll see and there are other aspects of these AI systems that you'll",
    "start": "1142799",
    "end": "1150520"
  },
  {
    "text": "see come into play the term orchestration is often used here it means different things to different",
    "start": "1150520",
    "end": "1156360"
  },
  {
    "text": "people but very much you have these elements that are running either sequentially or in parallel somehow you",
    "start": "1156360",
    "end": "1162720"
  },
  {
    "text": "need to execute this execution kind of like an operating system but uh an",
    "start": "1162720",
    "end": "1168240"
  },
  {
    "text": "operating system consistent with AI elements and so we and other people use the term aios again an overloaded term",
    "start": "1168240",
    "end": "1175520"
  },
  {
    "text": "doesn't mean anything precise but that's the spirit of things I kind of want to get maybe to the roles that are",
    "start": "1175520",
    "end": "1181799"
  },
  {
    "text": "interacting with this AI OS because I think one of the things people are struggling with is how do I put the",
    "start": "1181799",
    "end": "1188840"
  },
  {
    "text": "right talent in place to build these because you're talking about like programmatic operational systematic",
    "start": "1188840",
    "end": "1196240"
  },
  {
    "text": "thinking which is kind of like there's an ele of engineering there but it's not",
    "start": "1196240",
    "end": "1201640"
  },
  {
    "text": "people that are necessarily building their own models they're architecting these Solutions and putting the right",
    "start": "1201640",
    "end": "1208440"
  },
  {
    "text": "checks the right validations in place they're creating you know more than chains these workflows and there's some",
    "start": "1208440",
    "end": "1216480"
  },
  {
    "text": "Engineers coming to the table there but there's also domain experts who maybe are able to speak into some of how the",
    "start": "1216480",
    "end": "1223880"
  },
  {
    "text": "models are prompted so um do you have any kind of observ",
    "start": "1223880",
    "end": "1229159"
  },
  {
    "text": "from your experience with how people are putting together teams to architect",
    "start": "1229159",
    "end": "1234520"
  },
  {
    "text": "these Solutions and these systems like you've just described is it from your perspective still going to be a heavy",
    "start": "1234520",
    "end": "1242720"
  },
  {
    "text": "kind of engineering dominated type of process going forward or are you seeing",
    "start": "1242720",
    "end": "1247840"
  },
  {
    "text": "a mix what what's your observation there so my answer won't be based on an observation because the systems don't",
    "start": "1247840",
    "end": "1254679"
  },
  {
    "text": "exist yet they're baby solutioned right now but but uh I don't think they",
    "start": "1254679",
    "end": "1260080"
  },
  {
    "text": "represent what we will'll see going forward but um in answering your",
    "start": "1260080",
    "end": "1265280"
  },
  {
    "text": "question it very much will be a mix there will be companies such as ours",
    "start": "1265280",
    "end": "1270480"
  },
  {
    "text": "that will put in the foundational uh infrastructure to run these complicated flows these will have to be extensible",
    "start": "1270480",
    "end": "1278440"
  },
  {
    "text": "systems and they'll be extensible in a variety of ways some of them absolutely",
    "start": "1278440",
    "end": "1283960"
  },
  {
    "text": "you'll be able to have programmers write actual code and insert the code there",
    "start": "1283960",
    "end": "1289120"
  },
  {
    "text": "but there absolutely will be a role for low code or even no code specification",
    "start": "1289120",
    "end": "1294960"
  },
  {
    "text": "of the flow you want on top of this uh framework there will be uh a data",
    "start": "1294960",
    "end": "1302159"
  },
  {
    "text": "scientist that will write uh validations of various kinds and data pipelines for",
    "start": "1302159",
    "end": "1308039"
  },
  {
    "text": "sure and so I think everybody from the developer to the data scientist to the",
    "start": "1308039",
    "end": "1316120"
  },
  {
    "text": "business user who's somewhat SA to the end user who just wants a system that",
    "start": "1316120",
    "end": "1321200"
  },
  {
    "text": "works everybody will have a role and interaction and we haven't mentioned devops yet devops here is going to be",
    "start": "1321200",
    "end": "1327480"
  },
  {
    "text": "very important also as we've kind of talked around the ecosystem a little bit and what you know about systems",
    "start": "1327480",
    "end": "1333799"
  },
  {
    "start": "1328000",
    "end": "1486000"
  },
  {
    "text": "themselves can we turn a little bit and could you tell us a little bit about as we're leading toward into Jamba but I'd",
    "start": "1333799",
    "end": "1340320"
  },
  {
    "text": "like to know a little bit about kind of where where the company has been and some of the models that you have have",
    "start": "1340320",
    "end": "1346080"
  },
  {
    "text": "put out there leading into to this one and kind of the heritage of how you've developed that would really be",
    "start": "1346080",
    "end": "1352320"
  },
  {
    "text": "interested in kind of how you've pursued that since you started the company I can divided into three periods in our long",
    "start": "1352320",
    "end": "1360720"
  },
  {
    "text": "history of six years that's an eon in AI these days you know that's I had a different color hair when we",
    "start": "1360720",
    "end": "1368080"
  },
  {
    "text": "started as I said we started by building Jurassic one we just felt like uh we",
    "start": "1368080",
    "end": "1373919"
  },
  {
    "text": "absolutely had to build it uh and we did we innovated there but in a minor way we",
    "start": "1373919",
    "end": "1379760"
  },
  {
    "text": "you know we had a vocabulary that was five times the size of what was common at the time it was rather than 50,000",
    "start": "1379760",
    "end": "1386480"
  },
  {
    "text": "tokens we had 250,000 but slightly larger than gp3 not to make a point just because it worked",
    "start": "1386480",
    "end": "1392000"
  },
  {
    "text": "out that way 178 billion parameters uh a dense model and that served us well but",
    "start": "1392000",
    "end": "1399520"
  },
  {
    "text": "uh the next phase in our sort of so we we did many things we had our own application called War tune that done",
    "start": "1399520",
    "end": "1406039"
  },
  {
    "text": "very well a reading and writing assistant uh using our technology but um on the models themselves the next thing",
    "start": "1406039",
    "end": "1413000"
  },
  {
    "text": "we put out are our task specific models which basically is not really distillation it's and it's not just",
    "start": "1413000",
    "end": "1418559"
  },
  {
    "text": "fine-tuning like I said it's putting a system around it but at the end of the day you get something compact for",
    "start": "1418559",
    "end": "1424120"
  },
  {
    "text": "certain use cases and that set is growing that was our second uh phase and",
    "start": "1424120",
    "end": "1430039"
  },
  {
    "text": "the third phase was uh really seeking a way to make these models fundamentally",
    "start": "1430039",
    "end": "1436400"
  },
  {
    "text": "more scalable more efficient to serve especially in this era of you know rag",
    "start": "1436400",
    "end": "1442240"
  },
  {
    "text": "uh kind of solutions so you have stuff that you want to kind of bring in at",
    "start": "1442240",
    "end": "1448480"
  },
  {
    "text": "inference time to influence the output of the system and at some point the",
    "start": "1448480",
    "end": "1454039"
  },
  {
    "text": "system chokes you know we had a context Windows of 4K then 8K then 16k now",
    "start": "1454039",
    "end": "1460440"
  },
  {
    "text": "although some bigger numbers are thrown out but most models choke at 32k maybe 64k that's not enough if you want to put",
    "start": "1460440",
    "end": "1467960"
  },
  {
    "text": "so we wanted something that now if you were to run it on you know 64 uh h100s",
    "start": "1467960",
    "end": "1475799"
  },
  {
    "text": "uh you can do a lot of things but that's not realistic so the question was how to get something that efficient that can",
    "start": "1475799",
    "end": "1482240"
  },
  {
    "text": "run effectively on a small footprint and that's how we got to Jamba with Jamba",
    "start": "1482240",
    "end": "1487440"
  },
  {
    "start": "1486000",
    "end": "1696000"
  },
  {
    "text": "you mentioned taking some things from kind of the Mamba architecture this sort",
    "start": "1487440",
    "end": "1492960"
  },
  {
    "text": "of SSM and adding in some Transformer based things for those that aren't",
    "start": "1492960",
    "end": "1498360"
  },
  {
    "text": "amiliar with the kind of background with those types of models maybe the kind of",
    "start": "1498360",
    "end": "1504679"
  },
  {
    "text": "non- Transformer models that people were exploring could you give a little bit of",
    "start": "1504679",
    "end": "1509799"
  },
  {
    "text": "context to that and why it was important for I mean you've already mentioned efficiency and other things but why you",
    "start": "1509799",
    "end": "1517320"
  },
  {
    "text": "felt it was kind of important in this generation of model to pull the trigger in a slightly different architectural",
    "start": "1517320",
    "end": "1523760"
  },
  {
    "text": "Direction sure and for this maybe we could uh double kick a little bit about about how these system are architected",
    "start": "1523760",
    "end": "1531000"
  },
  {
    "text": "so at some point the dominant architecture where the RN and the uh you know these and then lstms as you go left",
    "start": "1531000",
    "end": "1538520"
  },
  {
    "text": "to right the system uh doesn't remember the distant path what it does it carries",
    "start": "1538520",
    "end": "1543919"
  },
  {
    "text": "with it a state that somehow encapsulate everything that it's seen so far that's",
    "start": "1543919",
    "end": "1549399"
  },
  {
    "text": "quite powerful but as this path gets long it gets harder and harder to encode",
    "start": "1549399",
    "end": "1555480"
  },
  {
    "text": "and access that information that's we encode and uh it worked fine for vision because",
    "start": "1555480",
    "end": "1563000"
  },
  {
    "text": "this in Vision object recognition is something very local it's a iconic iconic in the sense that what you see is",
    "start": "1563000",
    "end": "1569120"
  },
  {
    "text": "what you get right like I said the phone you know this is a phone I don't care what's here so I go along I hit the",
    "start": "1569120",
    "end": "1574760"
  },
  {
    "text": "phone so I don't need to remember but in language different and in fact if you looked at the benchmarks by the way",
    "start": "1574760",
    "end": "1581120"
  },
  {
    "text": "another pet peeve of mine benchmarks are can be very misleading but that aside uh if you looked at the naal langage",
    "start": "1581120",
    "end": "1587520"
  },
  {
    "text": "benchmarks they kind of puted along with not much progress until Transformers came in and Transformers again",
    "start": "1587520",
    "end": "1593799"
  },
  {
    "text": "coincidentally what is it about six years now they changed the architecture and they had the attention mechanism",
    "start": "1593799",
    "end": "1600399"
  },
  {
    "text": "that says no I mean as I'm going along I can relate disperate pieces of information and that allowed you to uh",
    "start": "1600399",
    "end": "1607960"
  },
  {
    "text": "do things you couldn't do otherwise and that's great so the quality the aners shut up you pay a price because the",
    "start": "1607960",
    "end": "1616000"
  },
  {
    "text": "complexity is quadratic now in the context length and that kills you which",
    "start": "1616000",
    "end": "1621679"
  },
  {
    "text": "wasn't the case with RNN or lstms there it's linear I mean you just and so the",
    "start": "1621679",
    "end": "1628640"
  },
  {
    "text": "question is how can you have your cake and eat it to enjoy the benefits of being to relate disperate kind of pieces",
    "start": "1628640",
    "end": "1634480"
  },
  {
    "text": "of information and yet have something that's if not linear close to linear and so Mamba so first let's say Mamba is a",
    "start": "1634480",
    "end": "1643039"
  },
  {
    "text": "straight kind of left to right uh what's called SSM model and uh this structure",
    "start": "1643039",
    "end": "1648240"
  },
  {
    "text": "safe space but uh its Innovation was it was a version that allows you to actually paraliz the training and much",
    "start": "1648240",
    "end": "1655679"
  },
  {
    "text": "more efficient but it still suffered from the uh lower quality of answers and",
    "start": "1655679",
    "end": "1661320"
  },
  {
    "text": "so what our guys did was say okay we'll take this as a basic building block and mumai is all of what four months old now",
    "start": "1661320",
    "end": "1669559"
  },
  {
    "text": "cademia recently yeah but uh said that seem like a really good idea but let's",
    "start": "1669559",
    "end": "1675240"
  },
  {
    "text": "now take elements of the Transformer architecture and put it in so every few in now case",
    "start": "1675240",
    "end": "1682440"
  },
  {
    "text": "it was every eight or 16 depending on which version layers you put an attention mechanism so you take a little",
    "start": "1682440",
    "end": "1689240"
  },
  {
    "text": "performance hit but not nearly as much as if you had Transformers all the way so that's kind of how it LEDs to this",
    "start": "1689240",
    "end": "1695039"
  },
  {
    "text": "particular architecture well yoav you you did mention that Mamba is only a",
    "start": "1695039",
    "end": "1700159"
  },
  {
    "start": "1696000",
    "end": "1954000"
  },
  {
    "text": "recently released architecture and published architecture but you've been able to move quite quickly and I want to",
    "start": "1700159",
    "end": "1707279"
  },
  {
    "text": "talk a little bit about Jamba and the the release and all of that but prior to that it might be interesting for",
    "start": "1707279",
    "end": "1713039"
  },
  {
    "text": "listeners you know most of our listeners aren't sitting in a company that is",
    "start": "1713039",
    "end": "1718279"
  },
  {
    "text": "trying to be a foundation model builder building these kind of more general",
    "start": "1718279",
    "end": "1723519"
  },
  {
    "text": "purpose models I'm wondering if you could give a picture a little bit um behind the scenes whatever you think",
    "start": "1723519",
    "end": "1729840"
  },
  {
    "text": "would be interesting on what does it actually take to go from hey this idea",
    "start": "1729840",
    "end": "1735760"
  },
  {
    "text": "we want to mix kind of get the best of both world with Mamba and Transformers",
    "start": "1735760",
    "end": "1741039"
  },
  {
    "text": "um all the way to hey here's our blog post releasing a model what were some of",
    "start": "1741039",
    "end": "1746480"
  },
  {
    "text": "the challenges in that kind of middle Zone and what is that process like to",
    "start": "1746480",
    "end": "1751600"
  },
  {
    "text": "determine you know from data set to exact architecture and the sort of final",
    "start": "1751600",
    "end": "1757720"
  },
  {
    "text": "training runs so first I'll say that um I don't think that everybody needs to be",
    "start": "1757720",
    "end": "1763840"
  },
  {
    "text": "building Foundation models but as I said to somebody some somebody organizations",
    "start": "1763840",
    "end": "1769559"
  },
  {
    "text": "that Technical and wants to remain relevant even if they're not building",
    "start": "1769559",
    "end": "1775480"
  },
  {
    "text": "Foundation models they should understand how they're built and if they really put",
    "start": "1775480",
    "end": "1780919"
  },
  {
    "text": "their mind to it and their resources they could build one because it really gives you a visceral deep sense of",
    "start": "1780919",
    "end": "1786440"
  },
  {
    "text": "what's going on now regarding the the Jamba we actually try to be very",
    "start": "1786440",
    "end": "1791679"
  },
  {
    "text": "transparent you know people so this is our first open source model and um the",
    "start": "1791679",
    "end": "1797519"
  },
  {
    "text": "reason we did it uh was that it is very novel and there's lots of more",
    "start": "1797519",
    "end": "1803880"
  },
  {
    "text": "experimentation to be done here optimization serving the uh you know training these models can't be done on",
    "start": "1803880",
    "end": "1810559"
  },
  {
    "text": "every uh type of infrastructure serving them similarly and where you do serve",
    "start": "1810559",
    "end": "1815960"
  },
  {
    "text": "them right now we've had several years to optimize the serving of uh Transformers we wanted to enable the",
    "start": "1815960",
    "end": "1823279"
  },
  {
    "text": "community to innovate here and so we were quite uh explicit it in our white",
    "start": "1823279",
    "end": "1828720"
  },
  {
    "text": "paper perhaps unusually so relative to the industry so so the listeners who",
    "start": "1828720",
    "end": "1834200"
  },
  {
    "text": "want to kind of get the Nitty Gritty um I really encourage them to look at the technical white paper but um I can tell",
    "start": "1834200",
    "end": "1840720"
  },
  {
    "text": "you there been a ton of uh experimentation and ablations that our guys did trading off very lots of people",
    "start": "1840720",
    "end": "1848399"
  },
  {
    "text": "use the term hyperparameters it's a it hides a lot of things are very different",
    "start": "1848399",
    "end": "1853440"
  },
  {
    "text": "from one another but how many layers do you want and you know how many mamba layers how many attention layers batch",
    "start": "1853440",
    "end": "1860720"
  },
  {
    "text": "sizes um all kinds of stuff that and know where what really makes the",
    "start": "1860720",
    "end": "1865880"
  },
  {
    "text": "difference it's hard to sometimes understand what makes the difference and again we try to share the for example",
    "start": "1865880",
    "end": "1872760"
  },
  {
    "text": "Mamba I said that M performance doesn't compete with a performance of comparably",
    "start": "1872760",
    "end": "1878960"
  },
  {
    "text": "sized Transformer models but that's at the when you look at the details it's",
    "start": "1878960",
    "end": "1884480"
  },
  {
    "text": "actually quite competitive on many of the benchmarks but then there are a few that it's really bad at and that gives",
    "start": "1884480",
    "end": "1891240"
  },
  {
    "text": "you a clue of why that's the case it can latch on to surface formulations and and",
    "start": "1891240",
    "end": "1897120"
  },
  {
    "text": "syntax that the Transformers managed to just abstract away from and so we describe how you know you made this",
    "start": "1897120",
    "end": "1903360"
  },
  {
    "text": "observation you correct for it there's a lots of details that go into making these decisions and then there's also",
    "start": "1903360",
    "end": "1910880"
  },
  {
    "text": "pragmatic decisions for example we wanted a model that will fit on a single",
    "start": "1910880",
    "end": "1916720"
  },
  {
    "text": "80 gb GPU that was a design decision and from that emanated a few things that you",
    "start": "1916720",
    "end": "1922639"
  },
  {
    "text": "know U we did put a bigger model and you know certain contact windows will fit",
    "start": "1922639",
    "end": "1928240"
  },
  {
    "text": "there others won't it's still you know 256k is humongous compared to the",
    "start": "1928240",
    "end": "1934519"
  },
  {
    "text": "alternative but we can also do a million and larger but not on a single GPU and",
    "start": "1934519",
    "end": "1941159"
  },
  {
    "text": "so those are some of the design decisions and the rationale honestly it is a process although condensed a",
    "start": "1941159",
    "end": "1948519"
  },
  {
    "text": "process that involved you know hundreds of decisions that led to what we uh put",
    "start": "1948519",
    "end": "1954200"
  },
  {
    "start": "1954000",
    "end": "2047000"
  },
  {
    "text": "out that was a really great explanation I appreciate that it's as you were going",
    "start": "1954200",
    "end": "1960399"
  },
  {
    "text": "through it and I was thinking about the applicability for Jamba in the Enterprise and kind of bringing the",
    "start": "1960399",
    "end": "1966080"
  },
  {
    "text": "Innovation I'm curious is why I know you had kind of alluded to the fact that uh",
    "start": "1966080",
    "end": "1972200"
  },
  {
    "text": "Jamba early in the explanation was kind of the First open- Source model and so I was wondering as you're trying to enable",
    "start": "1972200",
    "end": "1978440"
  },
  {
    "text": "Enterprise Innovation what was the change in your thought process that made you decide to go open source with Jamba",
    "start": "1978440",
    "end": "1985440"
  },
  {
    "text": "versus the earlier models what was the thinking around that I was curious as you said it and wanted to wait till we got to the end yeah um it really was uh",
    "start": "1985440",
    "end": "1993840"
  },
  {
    "text": "very simple we felt like if we were the only ones augmenting and pushing on this",
    "start": "1993840",
    "end": "2000360"
  },
  {
    "text": "model it wouldn't Advance as fast as it could and we saw that within Days of our",
    "start": "2000360",
    "end": "2006760"
  },
  {
    "text": "putting it out there there was I think today I haven't tracked but when I looked about a week ago there 30,000",
    "start": "2006760",
    "end": "2012639"
  },
  {
    "text": "downloads and I forget how many Forks but a large number of forks some fine so",
    "start": "2012639",
    "end": "2018159"
  },
  {
    "text": "by the way very important to say what we put out is a base model not a fine tune model and we're very clear about it and",
    "start": "2018159",
    "end": "2023919"
  },
  {
    "text": "we caution people for using it for production purposes or for user facing",
    "start": "2023919",
    "end": "2030559"
  },
  {
    "text": "uh application and of course we'll be coming out with our uh in fact we've announced uh that uh it's available for",
    "start": "2030559",
    "end": "2038679"
  },
  {
    "text": "preview our aligned model but we felt like there's it was really important for the community to add value to this",
    "start": "2038679",
    "end": "2046519"
  },
  {
    "text": "architecture and that's why we did it for those that are listening a little bit later on the podcast so it looks",
    "start": "2046519",
    "end": "2051760"
  },
  {
    "start": "2047000",
    "end": "2223000"
  },
  {
    "text": "like Jamba at the time we're recording this was released at least on hugging face um well it was updated 15 days ago",
    "start": "2051760",
    "end": "2059599"
  },
  {
    "text": "and I see the the blog post um at the end of March I believe but now on",
    "start": "2059599",
    "end": "2064720"
  },
  {
    "text": "hugging face there's sort of 38 models I see with Jamba in the name that's sort",
    "start": "2064720",
    "end": "2070960"
  },
  {
    "text": "of not including those maybe that forked and just created their own special name",
    "start": "2070960",
    "end": "2077040"
  },
  {
    "text": "so already you're seeing this kind of explosion of a model family I guess",
    "start": "2077040",
    "end": "2083158"
  },
  {
    "text": "which is quite interesting I'm wondering over time as a company you mentioned",
    "start": "2083159",
    "end": "2089358"
  },
  {
    "text": "kind of not being the only ones working on the model family and wanting to see it become more is that observation kind",
    "start": "2089359",
    "end": "2097000"
  },
  {
    "text": "of based on what you've seen in other model families whether it be llama 2 or mistl and others and there's sort of",
    "start": "2097000",
    "end": "2102920"
  },
  {
    "text": "because when I look at a model like that that's released I almost immediately and I know people you mentioned devops",
    "start": "2102920",
    "end": "2109480"
  },
  {
    "text": "people have automated pipelines in place to create the quantized version of of",
    "start": "2109480",
    "end": "2114839"
  },
  {
    "text": "this or um fine-tune it for that on their their data set we had the the news",
    "start": "2114839",
    "end": "2120920"
  },
  {
    "text": "research we had a discussion about new research and what they're doing in in some of this area as well so what is the",
    "start": "2120920",
    "end": "2127280"
  },
  {
    "text": "sour of innovation that you're hoping for with the kind of Jamba model family",
    "start": "2127280",
    "end": "2133000"
  },
  {
    "text": "is it you mentioned fine tunes or you know you releasing the bass model there could be fine tunes but I think also",
    "start": "2133000",
    "end": "2139760"
  },
  {
    "text": "there could be much more than that so what are you kind of hoping to see as people get handson with the model and",
    "start": "2139760",
    "end": "2147200"
  },
  {
    "text": "try to explore various elements of how to use it yeah uh fine-tuning is",
    "start": "2147200",
    "end": "2152440"
  },
  {
    "text": "happening will happen uh like I say we have our own fine tun or aligned model",
    "start": "2152440",
    "end": "2159000"
  },
  {
    "text": "and but that's not the reason we put it out there the reason we put it out there",
    "start": "2159000",
    "end": "2164040"
  },
  {
    "text": "is that people can contribute to the very model so others can benefit from it",
    "start": "2164040",
    "end": "2170079"
  },
  {
    "text": "and I think there's at least two areas where a lot of value can be brought one",
    "start": "2170079",
    "end": "2175200"
  },
  {
    "text": "is serving efficiency for example when you consume it on hugging face it's less",
    "start": "2175200",
    "end": "2181680"
  },
  {
    "text": "efficient than we consume it on our platform because we have optimized the serving and we'll continue to optimiz",
    "start": "2181680",
    "end": "2187680"
  },
  {
    "text": "imiz but a lot of smart people out there and we'd love for them to optimize it",
    "start": "2187680",
    "end": "2192760"
  },
  {
    "text": "further and everybody will benefit including us that's one thing the other thing is that I think it's a really we",
    "start": "2192760",
    "end": "2200359"
  },
  {
    "text": "would really value it if this kind of model were able to be trained on",
    "start": "2200359",
    "end": "2207319"
  },
  {
    "text": "multiple types of infrastructure which currently isn't the case and uh so I",
    "start": "2207319",
    "end": "2212880"
  },
  {
    "text": "think by putting it out there people now they can look at the white paper they can look at the model and they can now",
    "start": "2212880",
    "end": "2218880"
  },
  {
    "text": "enable further training of such models which will benefit everybody including us so as we start to wind up here um",
    "start": "2218880",
    "end": "2226800"
  },
  {
    "start": "2223000",
    "end": "2375000"
  },
  {
    "text": "fascinating discussion thank you very much for taking us through all the Insight I like to wind up asking kind of",
    "start": "2226800",
    "end": "2234520"
  },
  {
    "text": "where you think things are going and and if you could address it potentially at two levels both kind of where your own",
    "start": "2234520",
    "end": "2241359"
  },
  {
    "text": "organization uh expects to go what kind of thinking you have over whatever Horizon is on your mind but also give us",
    "start": "2241359",
    "end": "2249400"
  },
  {
    "text": "insight into how you think the industry as a whole is progressing and and how you expect that kind of servicing the",
    "start": "2249400",
    "end": "2256560"
  },
  {
    "text": "Enterprise need to evolve and you know with the strategies that are out there",
    "start": "2256560",
    "end": "2261640"
  },
  {
    "text": "we'd love to understand how you're seeing the world in that way I think the key notion is reliability trust and",
    "start": "2261640",
    "end": "2269640"
  },
  {
    "text": "reliability uh you need to have the same kind of trust in the system to be able",
    "start": "2269640",
    "end": "2275720"
  },
  {
    "text": "to predict what they'll do be able to understand what they did as you do with other pieces of software you know we",
    "start": "2275720",
    "end": "2282520"
  },
  {
    "text": "always have uh errors you know uh even the Pentium had a bug but that's an",
    "start": "2282520",
    "end": "2288720"
  },
  {
    "text": "exception whereas currently it's the rule for language models so that can't be in the Enterprise and everything that",
    "start": "2288720",
    "end": "2296359"
  },
  {
    "text": "I think about what's going to happen in the Enterprise orients around that I think you'll see uh special purpose",
    "start": "2296359",
    "end": "2303720"
  },
  {
    "text": "models like our Tas specific models I think you'll see uh uh AI systems",
    "start": "2303720",
    "end": "2309319"
  },
  {
    "text": "increasingly sophisticated and robust right now they're not robust they're experimental but you'll see me more AI",
    "start": "2309319",
    "end": "2314920"
  },
  {
    "text": "system and I think um this may sound philosophical so bear with me but um",
    "start": "2314920",
    "end": "2322440"
  },
  {
    "text": "there's a question within thei Community do these language model actually",
    "start": "2322440",
    "end": "2328200"
  },
  {
    "text": "understand what they're talking about they they spit out this incredibly convincing stuff very smart something on",
    "start": "2328200",
    "end": "2335040"
  },
  {
    "text": "point and how can they not understand and it sometimes they're totally stupid and everybody we all have favorite",
    "start": "2335040",
    "end": "2341440"
  },
  {
    "text": "examples and I think we need to get to the point where we believe that the",
    "start": "2341440",
    "end": "2347640"
  },
  {
    "text": "system actually understand what they're talking about and what understanding is",
    "start": "2347640",
    "end": "2353839"
  },
  {
    "text": "is again it sounds philosophical and there's a philosophical aspect to it for sure but it has very practical",
    "start": "2353839",
    "end": "2361520"
  },
  {
    "text": "ramifications and so when I think about the future all these pragmatic things task specific model AI systems but in",
    "start": "2361520",
    "end": "2369720"
  },
  {
    "text": "the background this notion of understanding these system need to really understand that's what I'm looking at yeah that's great well I",
    "start": "2369720",
    "end": "2377359"
  },
  {
    "start": "2375000",
    "end": "2472000"
  },
  {
    "text": "think as a part of the development towards that certainly open models and",
    "start": "2377359",
    "end": "2384520"
  },
  {
    "text": "Innovation around these model families like we talked about I hope is a key piece of that and from a member of the",
    "start": "2384520",
    "end": "2390440"
  },
  {
    "text": "community just want to express my thanks to AI 21 for being a leader both in",
    "start": "2390440",
    "end": "2396319"
  },
  {
    "text": "terms of the thinking and infrastructure and innovation in this area but also a leader in terms of",
    "start": "2396319",
    "end": "2402400"
  },
  {
    "text": "putting things out there for the community to to work on as a community so thank you for what you've done with",
    "start": "2402400",
    "end": "2408599"
  },
  {
    "text": "with Jamba and really excited to to follow AI 21 and and where you're headed",
    "start": "2408599",
    "end": "2414000"
  },
  {
    "text": "next so thank you so much for joining us yob it's been a pleasure thanks very much for having",
    "start": "2414000",
    "end": "2419210"
  },
  {
    "text": "[Music]",
    "start": "2419210",
    "end": "2425359"
  },
  {
    "text": "me all right that is practical AI for this week subscribe now if you haven't",
    "start": "2425359",
    "end": "2432160"
  },
  {
    "text": "already head to practical AI FM for all the ways and join our free slack team",
    "start": "2432160",
    "end": "2439000"
  },
  {
    "text": "where you can hang out with Daniel Chris and the entire change log Community sign up today at practical ai. fm/ Community",
    "start": "2439000",
    "end": "2449040"
  },
  {
    "text": "thanks again to our partners at fly toio to our beat freaking residence breakmaster cylinder and to you for",
    "start": "2449040",
    "end": "2455520"
  },
  {
    "text": "listening we appreciate you spend any time with us that's all for now we'll talk to you again next time",
    "start": "2455520",
    "end": "2462560"
  },
  {
    "text": "[Music]",
    "start": "2462560",
    "end": "2469770"
  }
]
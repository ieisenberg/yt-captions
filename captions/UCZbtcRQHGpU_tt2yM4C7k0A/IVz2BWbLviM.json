[
  {
    "text": "[Music]",
    "start": "70",
    "end": "2349"
  },
  {
    "text": "welcome back friends this week on the change law we're taking you to the hallway track of the Linux foundation's",
    "start": "8920",
    "end": "14160"
  },
  {
    "text": "open source Summit North America 2023 in Vancouver Canada this episode is part of",
    "start": "14160",
    "end": "20119"
  },
  {
    "text": "our maintainer month celebration along with GitHub and many others check it out at maintainer month. github.com today's",
    "start": "20119",
    "end": "28400"
  },
  {
    "text": "Anthology episode features beond Lou co-founder and CTO at source graph Denny",
    "start": "28400",
    "end": "33559"
  },
  {
    "text": "Lee developer Advocate at data bricks and Stella Beerman executive director",
    "start": "33559",
    "end": "38680"
  },
  {
    "text": "and head of research at El Luther AI the common denominator of these conversations is open-source Ai bangl",
    "start": "38680",
    "end": "47039"
  },
  {
    "text": "and his team at source graph are focused on enabling more developers to understand code and their approach to a",
    "start": "47039",
    "end": "52840"
  },
  {
    "text": "completely open source model agnostic coding assistant called Cody has significant interest from us Danny and",
    "start": "52840",
    "end": "60320"
  },
  {
    "text": "the team at data bricks recently released Dolly 2.0 this is the first open-source instruction following llm",
    "start": "60320",
    "end": "67960"
  },
  {
    "text": "that has been fine-tuned on a human generated instruction data set and is licensed for research and commercial use",
    "start": "67960",
    "end": "75240"
  },
  {
    "text": "and still up Beerman gave the keynote address on gen of AI and works at the base layer doing open source research",
    "start": "75240",
    "end": "83119"
  },
  {
    "text": "model training and AI ethics she trained the El Luther AI pithia model family",
    "start": "83119",
    "end": "88520"
  },
  {
    "text": "that data bricks used to create Dolly 2.0 a massive thank you to our friends",
    "start": "88520",
    "end": "93640"
  },
  {
    "text": "at GitHub for sponsoring us to attend this conference as part of maintainer [Music]",
    "start": "93640",
    "end": "101790"
  },
  {
    "text": "[Music] month okay before the show kicks off I'm",
    "start": "104000",
    "end": "110240"
  },
  {
    "text": "here with one of our sponsors at Dev cycle CTO and co-founder Jonathan Norris",
    "start": "110240",
    "end": "116159"
  },
  {
    "text": "so Jonathan my main question I guess if I'm handing off my my feature Flags to you all is my uptime dependent on your",
    "start": "116159",
    "end": "124600"
  },
  {
    "text": "uptime like if if you're down am I down we've designed into all the sdks and and",
    "start": "124600",
    "end": "130800"
  },
  {
    "text": "all the apis apis fail right that's a a cardinal rule of the internet so all the sdks have been designed with kind of",
    "start": "130800",
    "end": "137480"
  },
  {
    "text": "defaults and caching mechanisms and all that stuff in place so that yeah if our CDN is down our apis are down it'll sort",
    "start": "137480",
    "end": "144560"
  },
  {
    "text": "of fall back to those defaults or or those cach values in those sdks so that",
    "start": "144560",
    "end": "149800"
  },
  {
    "text": "handles for those blips pretty easily and then we rely on cloud flare as our sort of Main High load Edge provider so",
    "start": "149800",
    "end": "157319"
  },
  {
    "text": "all of our Ed apis are through Cloud flare and they're also operating as a CDN for assets so obviously relying on a",
    "start": "157319",
    "end": "163440"
  },
  {
    "text": "large provider like that that runs such a large percentage of the internet means that yeah you're not relying on our",
    "start": "163440",
    "end": "169120"
  },
  {
    "text": "ability to keep AWS instances running properly you're relying on sort of cloud flare and ability to sort of make sure",
    "start": "169120",
    "end": "174959"
  },
  {
    "text": "the internet still works as they control such a large percentage of it so so yeah we've architect in a way that it doesn't",
    "start": "174959",
    "end": "181120"
  },
  {
    "text": "sort of rely on our our apis to be up all the time and our databases to be up all the time to to have that that good",
    "start": "181120",
    "end": "187319"
  },
  {
    "text": "reliability well that's good news okay so how do you accomplish that one of the",
    "start": "187319",
    "end": "192480"
  },
  {
    "text": "core sort of architectural decisions we made with our platform when we designed it was trying to move the decisioning",
    "start": "192480",
    "end": "198319"
  },
  {
    "text": "logic of your feature flags as close to the end user and end device as possible so we did that with those local",
    "start": "198319",
    "end": "204959"
  },
  {
    "text": "bucketing server sdks that are using sort of a shared web assembly core and then we have edge-based apis that are",
    "start": "204959",
    "end": "212200"
  },
  {
    "text": "also powered by web assembly to serve sort of those client SDK usages so things like web and mobile apps so",
    "start": "212200",
    "end": "218879"
  },
  {
    "text": "that's one of our core principles is to try to get that decisioning logic as close to the end device as possible and",
    "start": "218879",
    "end": "224840"
  },
  {
    "text": "this is probably one of the only use cases where performance really matters because you want your feature Flags to",
    "start": "224840",
    "end": "230000"
  },
  {
    "text": "load really really quickly so you can render your website or you can render your your mobile app really quickly and so yeah we definitely understand that",
    "start": "230000",
    "end": "236760"
  },
  {
    "text": "your feater flag and tool needs to be fast and needs to be really really performant so if you want a fast feature",
    "start": "236760",
    "end": "242640"
  },
  {
    "text": "flagging tool that's performant and is not going to impact your uptime check out our friends at Dev cycle that's Dev",
    "start": "242640",
    "end": "250200"
  },
  {
    "text": "cycle.com changw pod and for those curious they have a free forever tier",
    "start": "250200",
    "end": "255879"
  },
  {
    "text": "that you can try out and prove yourself and your team this is going to work for you so check it out def cycle.com SL",
    "start": "255879",
    "end": "264199"
  },
  {
    "text": "change law pod and tell me sent you",
    "start": "264199",
    "end": "271600"
  },
  {
    "text": "[Music]",
    "start": "275880",
    "end": "284180"
  },
  {
    "text": "so Cody yeah c y this a big deal uh we think it is seems like it yeah yeah",
    "start": "284840",
    "end": "291800"
  },
  {
    "text": "wasn't it uh Source graph 4.0 last year was relaunched as the intelligence",
    "start": "291800",
    "end": "297000"
  },
  {
    "text": "platform Y is that right cuz before not just but just code search which was cool",
    "start": "297000",
    "end": "302199"
  },
  {
    "text": "but hard to really map out the ecosystem and you you want some all the space in",
    "start": "302199",
    "end": "307400"
  },
  {
    "text": "there but there was a limit to code search and you had to expand and the insights the intelligence and now",
    "start": "307400",
    "end": "312560"
  },
  {
    "text": "obviously code is just like one more layer on top of insights yeah totally so you know as as you know like Source",
    "start": "312560",
    "end": "317840"
  },
  {
    "text": "graph historically has been focused on the problem of code understanding so heavily inspired by tools like code",
    "start": "317840",
    "end": "324080"
  },
  {
    "text": "search inside Google or tbgs inside Facebook these kind of systems that indexed you know your company code base",
    "start": "324080",
    "end": "330199"
  },
  {
    "text": "as well as your your open source dependencies and and made that easy to search and and navigate uh and and",
    "start": "330199",
    "end": "336639"
  },
  {
    "text": "that's what's been powering the business for the past 10 years it is actually you know uh uh the 10th year of of",
    "start": "336639",
    "end": "342600"
  },
  {
    "text": "congratulations I was just wondering about that W yeah when we first met you it had to be about a decade ago yeah I",
    "start": "342600",
    "end": "348400"
  },
  {
    "text": "think Source graph just either didn't exist or just had existed Source graph",
    "start": "348400",
    "end": "353639"
  },
  {
    "text": "ex when we met this was like gopher I think it 2014 first or second gopher goer yeah and you had this vision of you",
    "start": "353639",
    "end": "361280"
  },
  {
    "text": "know Source graph and I'm wondering 10 years later like have you achieved that Vision has the vision changed Etc you",
    "start": "361280",
    "end": "368599"
  },
  {
    "text": "know our mission was always to to enable everyone to to code and uh we actually",
    "start": "368599",
    "end": "373759"
  },
  {
    "text": "took a uh a look at our seed seed deck um oh uh recently uh you know it kind of",
    "start": "373759",
    "end": "380800"
  },
  {
    "text": "Tri down Lane it was very quaint we were very we're very bad at uh PowerPoint you're probably a lot better at it now",
    "start": "380800",
    "end": "387160"
  },
  {
    "text": "uh not really better at the pitch maybe maybe slightly ref but largely like I",
    "start": "387160",
    "end": "394960"
  },
  {
    "text": "could deliver that pitch today off that deck it's basically the now I mean it's",
    "start": "394960",
    "end": "400199"
  },
  {
    "text": "just the the the pitch of source craft which is like there's never been more code in the world uh most of your job as",
    "start": "400199",
    "end": "405319"
  },
  {
    "text": "as an engineer or software creator is understanding all the code that already exists in your organization um because",
    "start": "405319",
    "end": "411800"
  },
  {
    "text": "that is all Upstream of figuring out what code you want to write and then once we actually figure out what you need to build like that's almost the",
    "start": "411800",
    "end": "417039"
  },
  {
    "text": "easy part it's also the fun part right cuz you're building new things and and shipping stuff but we help you get to that point of uh you know creation and",
    "start": "417039",
    "end": "424199"
  },
  {
    "text": "and enjoyment by helping you pick up all that context so right traditionally that's been like search right just like",
    "start": "424199",
    "end": "429560"
  },
  {
    "text": "Google's been web search uh but then these large language models have now uh come on the scene and in some ways",
    "start": "429560",
    "end": "435879"
  },
  {
    "text": "they're disruptive to kind of like search engines but in other ways they're highly complimentary so um you know",
    "start": "435879",
    "end": "441720"
  },
  {
    "text": "anyone who's used chat I just less it's just less right it's more like the last thing you do when you can't get the",
    "start": "441720",
    "end": "447879"
  },
  {
    "text": "answer elsewhere right like I guess I'll go Google it yeah although technically Google is a weird thing because I will",
    "start": "447879",
    "end": "454240"
  },
  {
    "text": "search a product and they think I want to buy it not research it right it's like I want to learn about the thing and",
    "start": "454240",
    "end": "461199"
  },
  {
    "text": "those who are teaching about the thing and how it integrates other things not where can I buy it and for how much yeah",
    "start": "461199",
    "end": "466840"
  },
  {
    "text": "so there's like zero context there like they're incentivized it seems to point you to places that you can purchase it",
    "start": "466840",
    "end": "473680"
  },
  {
    "text": "not learn how to use it yeah yeah I mean I think there's an interesting which is the opposite of chat gbt",
    "start": "473680",
    "end": "480039"
  },
  {
    "text": "yeah so so there's there's kind of like pluses and minuses to to both right like with with Google you get um results to",
    "start": "480039",
    "end": "486919"
  },
  {
    "text": "actual web pages and you can kind of Judge them based on the domain and it's kind of like more primary source material which is which is useful it's",
    "start": "486919",
    "end": "493080"
  },
  {
    "text": "also live you know you get results from 2023 rather than 2021 whereas CH that'll",
    "start": "493080",
    "end": "499800"
  },
  {
    "text": "change uh that's a temporary thing right I mean the delay will be temporary eventually it'll it'll catch up well I",
    "start": "499800",
    "end": "506199"
  },
  {
    "text": "mean gbd4 is is still um it came out recently 202 right but isn't the plugins and all",
    "start": "506199",
    "end": "511919"
  },
  {
    "text": "that stuff where it's like okay the model is old but it has access to new data so the plugins is actually where it",
    "start": "511919",
    "end": "517159"
  },
  {
    "text": "gets interesting because that's where things get really powerful in my opinion because if you ask TP with the plugins",
    "start": "517159",
    "end": "522279"
  },
  {
    "text": "enabled it can go and browse the web on your behalf uh so it's not just the the",
    "start": "522279",
    "end": "527640"
  },
  {
    "text": "base model uh you know trying to answer your question from memory anymore it's",
    "start": "527640",
    "end": "532880"
  },
  {
    "text": "actually going stuff in in you essentially Googling for for things right it has access to what you would do",
    "start": "532880",
    "end": "538480"
  },
  {
    "text": "behind the scenes exact exactly so it's the best of both worlds and essentially we're doing that uh with Cody but in",
    "start": "538480",
    "end": "545240"
  },
  {
    "text": "your editor for developers so basically combining large language models like gbd4 or uh anthropics claw uh model and",
    "start": "545240",
    "end": "554959"
  },
  {
    "text": "then combining that with power with the like the most advanced code search engine in the world so it's the best of",
    "start": "554959",
    "end": "560440"
  },
  {
    "text": "all worlds it gives you highly context aware and specific answers about your",
    "start": "560440",
    "end": "565480"
  },
  {
    "text": "code and it can also generate code that's kind of tuned to the specific pattern in your code base not just the",
    "start": "565480",
    "end": "570760"
  },
  {
    "text": "kind of like median stack Overflow or or open source code how did you get there how did you think wow I mean obviously",
    "start": "570760",
    "end": "577720"
  },
  {
    "text": "llms are a big deal yep right this new wave of intelligence that we have access",
    "start": "577720",
    "end": "583240"
  },
  {
    "text": "to is how far back is this in the making has this been years or has it been like",
    "start": "583240",
    "end": "588920"
  },
  {
    "text": "wow chat GPT is crazy November chat gpt3 November okay we got to move yeah like",
    "start": "588920",
    "end": "595399"
  },
  {
    "text": "how far back does this go yeah good question yeah so for for me personally it's it's kind of a bit of a homecoming",
    "start": "595399",
    "end": "600720"
  },
  {
    "text": "so like my first interest in computer science actually was was machine learning and artificial intelligence",
    "start": "600720",
    "end": "605920"
  },
  {
    "text": "that's what I did a lot of my ungrad doing was actually uh part of the Stanford AI lab uh doing Vision research",
    "start": "605920",
    "end": "611880"
  },
  {
    "text": "in those days under professor dapne kler she's my adviser uh and so I did a lot of work there it was super interesting",
    "start": "611880",
    "end": "618600"
  },
  {
    "text": "and I felt really passionate about it there's just a lot of you know elegant math that goes into things and it feels",
    "start": "618600",
    "end": "623800"
  },
  {
    "text": "like you're kind of like poking at some of the Hidden Truths of of the universe a little bit um but the technology at",
    "start": "623800",
    "end": "629480"
  },
  {
    "text": "that point was just uh it was nowhere near you know commercializable um and so I decided to pursue my other passion",
    "start": "629480",
    "end": "635920"
  },
  {
    "text": "which is developer productivity and Dev tools and kind of like stayed on top of of the research as as it was coming",
    "start": "635920",
    "end": "642000"
  },
  {
    "text": "along and um I think one of the inflection points for us was the release of GPD 3 because that was kind of a step",
    "start": "642000",
    "end": "648519"
  },
  {
    "text": "function increase in in the quality of the language models and we started to see some potential applications to",
    "start": "648519",
    "end": "655120"
  },
  {
    "text": "developer tools and code and we really started in Earnest Maybe a little over a year ago maybe 12 to 18",
    "start": "655120",
    "end": "661920"
  },
  {
    "text": "months ago um experimenting with the kind of like internal representations of the language models as a way to enhance",
    "start": "661920",
    "end": "668440"
  },
  {
    "text": "code search so uh we actually put out a uh an experiment called Cod search. a uh",
    "start": "668440",
    "end": "674880"
  },
  {
    "text": "that uses embeddings to enhance uh uh you know the quality of code search results that you get and and that was",
    "start": "674880",
    "end": "681320"
  },
  {
    "text": "pretty successful as an experiment um I think we released that uh probably middle of last year so about a year ago",
    "start": "681320",
    "end": "688000"
  },
  {
    "text": "uh and that kind of started down the road and then of course when chat PD came out um that was also another big",
    "start": "688000",
    "end": "693720"
  },
  {
    "text": "inflection point and um that's when we started to think you know very seriously about kind of like a chat-based uh",
    "start": "693720",
    "end": "700279"
  },
  {
    "text": "interaction uh that could happen in your editor have all the advantages of chat TBT but know about the specific context",
    "start": "700279",
    "end": "706399"
  },
  {
    "text": "of your code and so for Cody specifically I think first commit was uh December 1 or something like that and by",
    "start": "706399",
    "end": "714040"
  },
  {
    "text": "February we basically had a version that we're you know having users and customers try and then uh March was when",
    "start": "714040",
    "end": "719680"
  },
  {
    "text": "we rolled out to our first Enterprise customer so it's just been like this Whirlwind of development activity uh and",
    "start": "719680",
    "end": "726160"
  },
  {
    "text": "I don't know I I I cannot remember a time where I've been more excited and uh",
    "start": "726160",
    "end": "731360"
  },
  {
    "text": "just eager to to build stuff cuz it's we're living through interesting times right now it is this is the uh the",
    "start": "731360",
    "end": "738440"
  },
  {
    "text": "Eureka moment that we've all been waiting for basically right I mean this is the invention of the internet all over again potentially the iPhone level",
    "start": "738440",
    "end": "746279"
  },
  {
    "text": "you know invention I think it's a a dramatic paradigm shift in how we think as as engineers and software developers",
    "start": "746279",
    "end": "752160"
  },
  {
    "text": "like yeah how do we learn how do we leverage how do we augment yeah you know it's just insane what is available to",
    "start": "752160",
    "end": "760320"
  },
  {
    "text": "somebody who doesn't have an understanding to quickly get understanding and then be you know performing in a certain task or whatever",
    "start": "760320",
    "end": "767040"
  },
  {
    "text": "because of the llms that are available and how it works it's so crazy the chat interface is pretty simple though right",
    "start": "767040",
    "end": "774160"
  },
  {
    "text": "like the simple the Simplicity of a chat interface did you expect this Eureka",
    "start": "774160",
    "end": "779480"
  },
  {
    "text": "moment to be simply chat like as you've been you I mean like it's it's it's a",
    "start": "779480",
    "end": "784720"
  },
  {
    "text": "web app yeah it's not something else it's a web interface it's a chat interface I I think so so you know I'm",
    "start": "784720",
    "end": "792040"
  },
  {
    "text": "I'm a programmer by background so I've been like pushing I I've been trying to spread the gospel of a textual based",
    "start": "792040",
    "end": "797959"
  },
  {
    "text": "input for you know as long as I can remember obviously it's it's mostly fallen on deaf ears because you know the",
    "start": "797959",
    "end": "803720"
  },
  {
    "text": "the non-programming world is like what you know command line that's what are we in like the 19 80s right um but I",
    "start": "803720",
    "end": "811800"
  },
  {
    "text": "actually think uh philosophically like textual input the the reason I like it",
    "start": "811800",
    "end": "817120"
  },
  {
    "text": "is because if you think about just like the io like bit rate of human computer interaction it's like we live in a time",
    "start": "817120",
    "end": "823320"
  },
  {
    "text": "where like we have 4K screens uh running at you know 60 or 120 hertz like the the",
    "start": "823320",
    "end": "830600"
  },
  {
    "text": "sheer amount of like data that computers can feed into us through eyeballs is huge whereas in kind of like the point",
    "start": "830600",
    "end": "837519"
  },
  {
    "text": "click you know Mouse world it's like how many bits per second can you really feed into the computer as a human right and",
    "start": "837519",
    "end": "844199"
  },
  {
    "text": "now textual input you know doesn't get us all the way there to you know 4K times uh you know 60 HZ but it does it",
    "start": "844199",
    "end": "851560"
  },
  {
    "text": "basically like 10 X's or or more like the the the input bit rate uh of of what we can do to instruct machines I think",
    "start": "851560",
    "end": "858040"
  },
  {
    "text": "it's it's a great win for kind of like human agency like we want to be programming the computers not the other",
    "start": "858040",
    "end": "863079"
  },
  {
    "text": "way around right and I think a lot of the technology that has emerged over the past you know 10 15 years has been kind",
    "start": "863079",
    "end": "868880"
  },
  {
    "text": "of computers programming us as as humans a little bit in terms of like all the stuff that we consume and so yeah I'm",
    "start": "868880",
    "end": "875880"
  },
  {
    "text": "I'm super excited for textual based inputs I think Chad is kind of like uh a subset of of that um the way we we think",
    "start": "875880",
    "end": "882560"
  },
  {
    "text": "about Cody evolving is is really it's going to evolve in the direction of just like this Rich repple so it's not it's",
    "start": "882560",
    "end": "888519"
  },
  {
    "text": "not necessarily going to be like a oh it's a humanlike thing that you talk with conversationally it's more like if",
    "start": "888519",
    "end": "895079"
  },
  {
    "text": "you want to do search you type something that looks like a search query it knows that you want to do a search shows you search results if you ask a",
    "start": "895079",
    "end": "900839"
  },
  {
    "text": "highle question it knows you're asking a high LEL question it gives you an answer that integrates the context of your code",
    "start": "900839",
    "end": "906959"
  },
  {
    "text": "base if you want to ask a question about your production logs or maybe something uh about some uh something someone said",
    "start": "906959",
    "end": "912839"
  },
  {
    "text": "in chat or like a an issue or a code review should pull context from those sources and and integrate that and and",
    "start": "912839",
    "end": "920440"
  },
  {
    "text": "uh both synthesize and answer to your specific question but also like refer you back to the primary sources so that you can go and like dig deeper and and",
    "start": "920440",
    "end": "927560"
  },
  {
    "text": "understand more fully how it got answer so we think chat is just the starting point it's really just like this Rich",
    "start": "927560",
    "end": "932839"
  },
  {
    "text": "rippel that's going to integrate like all sorts of contexts like whatever uh you know piece of information is",
    "start": "932839",
    "end": "938759"
  },
  {
    "text": "relevant to you creating software uh this is kind of like the thing that focuses that and pulls it all in it",
    "start": "938759",
    "end": "944199"
  },
  {
    "text": "really seems like that at least as an interface you're seeing that as the future of what source graph is isn't it",
    "start": "944199",
    "end": "949800"
  },
  {
    "text": "or is there more to Source graph than that in the future so the way we think about it is like we we spent the past 10",
    "start": "949800",
    "end": "955880"
  },
  {
    "text": "years building the world's most advanced code understanding tool so so we have the best code search we have the best code graph so the the global reference",
    "start": "955880",
    "end": "962720"
  },
  {
    "text": "graph um across you know all the different languages in the world uh we have a large scale code uh modification",
    "start": "962720",
    "end": "969279"
  },
  {
    "text": "refactoring system and and a system to track high level Insight so there's all these like backend capabilities that are",
    "start": "969279",
    "end": "975040"
  },
  {
    "text": "really really powerful and uh what language models have done is given us a",
    "start": "975040",
    "end": "980120"
  },
  {
    "text": "really really nice beginner friendly interface to all that power and I think you're going to see this across uh all",
    "start": "980120",
    "end": "986199"
  },
  {
    "text": "kinds of software it's like historically build power user tools has been difficult because the on-ramp to uh",
    "start": "986199",
    "end": "992279"
  },
  {
    "text": "getting full full uh taking full advantage of those tools has been a little steep requires education yeah",
    "start": "992279",
    "end": "998440"
  },
  {
    "text": "yeah and so like if if you're worried about the on-ramp maybe you end up constraining your product a little bit",
    "start": "998440",
    "end": "1003560"
  },
  {
    "text": "uh just to make it simp simpler dumb it down for for the beginning user but you lose out on the power I think that trade-off is is no longer going to be as",
    "start": "1003560",
    "end": "1010959"
  },
  {
    "text": "severe now with with language models and so uh at source graph we're basically thinking uh rethinking the user",
    "start": "1010959",
    "end": "1018040"
  },
  {
    "text": "interaction of of the entire experience like the the underlying capabilities and underlying",
    "start": "1018040",
    "end": "1023279"
  },
  {
    "text": "Tech uh is not changing that's still if anything that's gotten more valuable now because you can feed it into the language model and instantly get value",
    "start": "1023279",
    "end": "1029438"
  },
  {
    "text": "out of it um but the entire like user interaction layer um I think needs to be rethought and uh Cody as your AI editor",
    "start": "1029439",
    "end": "1036360"
  },
  {
    "text": "assistant um is kind of like the first iteration of of that uh thought process",
    "start": "1036360",
    "end": "1041558"
  },
  {
    "text": "how did you iterate to the interface you're at now and is it a constant Evolution yeah I mean it's it's pretty",
    "start": "1041559",
    "end": "1047600"
  },
  {
    "text": "much like hm I think that would be a good idea let me go hack it together and see how it plays and you play around with it and then you kind of experience",
    "start": "1047600",
    "end": "1053760"
  },
  {
    "text": "it yourself you build conviction in your own mind and then you maybe share it with one or two other teammates and see",
    "start": "1053760",
    "end": "1058880"
  },
  {
    "text": "if you know they have the same wow moment and if they do that's usually a pretty good sign that you're onto",
    "start": "1058880",
    "end": "1064080"
  },
  {
    "text": "something and you know there might be more details to hammer out to to make it more accessible to everyone but you know",
    "start": "1064080",
    "end": "1069760"
  },
  {
    "text": "if you can convince yourself and at least like you know two or three other smart people out there that uh there's",
    "start": "1069760",
    "end": "1074799"
  },
  {
    "text": "something you know worth investigating I think that's typically a pretty good sign that you're on to something how do you get access to Cody not so much get",
    "start": "1074799",
    "end": "1081559"
  },
  {
    "text": "access but how do you use it in the source craft world like how do you how does it appear how do you conjure it",
    "start": "1081559",
    "end": "1087360"
  },
  {
    "text": "yeah so it's just an editor extension um you can download it from the vs code Marketplace it's uh available now uh and",
    "start": "1087360",
    "end": "1093280"
  },
  {
    "text": "it's free to use um and uh we have other editors on the way intj is very high",
    "start": "1093280",
    "end": "1099240"
  },
  {
    "text": "priority for us also neovim and of course my editor of choice Emax um of",
    "start": "1099240",
    "end": "1105480"
  },
  {
    "text": "course and you know we're developing it completely in the open as well so like Cody itself is completely open source",
    "start": "1105840",
    "end": "1112240"
  },
  {
    "text": "and Apache licensed um and uh to get access to it to start using it you just",
    "start": "1112240",
    "end": "1117440"
  },
  {
    "text": "install the extension into your editor uh and start using it it opens up in a sidebar you can chat with it we also do",
    "start": "1117440",
    "end": "1123520"
  },
  {
    "text": "inline completions um so you know as you're typing we can complete code again taking advantage of the kind of like",
    "start": "1123520",
    "end": "1130400"
  },
  {
    "text": "baked dead knowledge of the language model plus the context of your specific code base um so generating like very",
    "start": "1130400",
    "end": "1137000"
  },
  {
    "text": "high quality completions um and yeah it's it's it's generally",
    "start": "1137000",
    "end": "1142039"
  },
  {
    "text": "just as simple as installing the extension and and and then you're off to the races a source graph account first",
    "start": "1142039",
    "end": "1148120"
  },
  {
    "text": "right yeah so you do have to off through Source graph uh because that's how we I mean we wouldn't be able to provide it",
    "start": "1148120",
    "end": "1153840"
  },
  {
    "text": "for free if if you didn't off through Source craft because on the back end we're calling out to different language model providers and um we're also",
    "start": "1153840",
    "end": "1160520"
  },
  {
    "text": "running a couple of our own okay so accessible then not having to install",
    "start": "1160520",
    "end": "1166960"
  },
  {
    "text": "Source graph have it scale my repository like the traditional way you provide intelligence which is to leverage",
    "start": "1166960",
    "end": "1173039"
  },
  {
    "text": "literally Source graph on my repo I can just simply off through Source graph have an extension in my vs coder yeah in",
    "start": "1173039",
    "end": "1181000"
  },
  {
    "text": "the future emac exactly potentially they're kind of loosely coupled like we don't we don't we don't believe in",
    "start": "1181000",
    "end": "1187000"
  },
  {
    "text": "strong coupling just for the sake of you know selling you more software and and I think with Cody the the design",
    "start": "1187000",
    "end": "1193000"
  },
  {
    "text": "philosophy was like look if you Connected To Source craft it does get a lot better it's like if you gave a really smart person access to Google",
    "start": "1193000",
    "end": "1198840"
  },
  {
    "text": "they're going to be a lot smarter about answering uh your questions yeah um but if if you don't give them Google they're",
    "start": "1198840",
    "end": "1204320"
  },
  {
    "text": "still smart person and so Cody will still fetch context from kind of like your local code uh using non-source",
    "start": "1204320",
    "end": "1210400"
  },
  {
    "text": "graph uh mechanisms if if you're just running it Standalone yeah how does it get this intelligence as an extension",
    "start": "1210400",
    "end": "1216440"
  },
  {
    "text": "like how does that explain how that works like I've got it on my local repo it's an extension how does it get the",
    "start": "1216440",
    "end": "1221480"
  },
  {
    "text": "intelligence from my codebase yeah so it's basically um I mean think think of",
    "start": "1221480",
    "end": "1226640"
  },
  {
    "text": "the way that you would like understand and or or or build a mental model what's going on in a codebase as a human uh you",
    "start": "1226640",
    "end": "1233320"
  },
  {
    "text": "might you know search for some pieces of functionality you might read through the readme um click on a couple search",
    "start": "1233320",
    "end": "1238679"
  },
  {
    "text": "results it does all that it's reading my read me right away uh yeah basically so when you ask a question it uh Cody will",
    "start": "1238679",
    "end": "1245799"
  },
  {
    "text": "ping Source graph for hey what are the the most relevant pieces of documentation or source code in your",
    "start": "1245799",
    "end": "1251400"
  },
  {
    "text": "code base and then essentially you know quote unquote read them as a language model and use that as context for answering question so if you ask like a",
    "start": "1251400",
    "end": "1258120"
  },
  {
    "text": "general purpose question it'll typically read the read me if you ask a more targeted question like oh how do you do this this you know one specific thing",
    "start": "1258120",
    "end": "1264559"
  },
  {
    "text": "like you know read a PDF or whatever uh it'll go find the the places in source code where you're you know it it",
    "start": "1264559",
    "end": "1271080"
  },
  {
    "text": "processes PDFs and read that in and then interpret that uh uh through the lens of answering your question in real time",
    "start": "1271080",
    "end": "1277799"
  },
  {
    "text": "yeah yeah yeah is there a latency to the question to the Gathering and like what's the speed if I said yeah that",
    "start": "1277799",
    "end": "1284679"
  },
  {
    "text": "example how does my application you know compile PDF from a markdown file for",
    "start": "1284679",
    "end": "1289880"
  },
  {
    "text": "example yeah so it typically gets back to you within like one or two seconds and and most of the latency is actually",
    "start": "1289880",
    "end": "1294960"
  },
  {
    "text": "just the language model latency so it depends on what language model you're choosing to use underneath the Hood um all the source graft stuff is super fast",
    "start": "1294960",
    "end": "1301080"
  },
  {
    "text": "because that's just I mean there's no like yeah it's Source graph is fast we've spent the past 10 years making it",
    "start": "1301080",
    "end": "1306279"
  },
  {
    "text": "very fast and there's no like you know billions of linear algebra operations",
    "start": "1306279",
    "end": "1311919"
  },
  {
    "text": "happening with Source craft sourcc is just you know classical uh you know CPU based uh you know okay code and and text",
    "start": "1311919",
    "end": "1319480"
  },
  {
    "text": "about privacy yeah so privacy is extremely important to us both in terms of you",
    "start": "1319480",
    "end": "1324840"
  },
  {
    "text": "know individual developers and our Enterprise customers like the last thing they want to do is have their private code be used as training data into you",
    "start": "1324840",
    "end": "1332360"
  },
  {
    "text": "know some general purpose model that's going to leak their sensitive IP to the rest of the world so um we basically",
    "start": "1332360",
    "end": "1338440"
  },
  {
    "text": "negotiated zero retention policies with all our proprietary language model providers which means that your data is",
    "start": "1338440",
    "end": "1344679"
  },
  {
    "text": "never going to get used as training data for a model and not only that uh the",
    "start": "1344679",
    "end": "1349919"
  },
  {
    "text": "language model providers will forget uh your data as soon as the request is complete so like there there is no",
    "start": "1349919",
    "end": "1356679"
  },
  {
    "text": "persistence in terms of like you know remembering the the code that you send over to complete a request that just",
    "start": "1356679",
    "end": "1362200"
  },
  {
    "text": "gets forgotten as soon as the language model generates a request for Cody um",
    "start": "1362200",
    "end": "1368320"
  },
  {
    "text": "and then for the rest of it I mean Source graph has always taken uh user privacy and and code privacy very seriously it's why we've been able to",
    "start": "1368320",
    "end": "1374799"
  },
  {
    "text": "serve yeah the sorts of Enterprise customers that we do and um I know why that's important but why spell it out",
    "start": "1374799",
    "end": "1380840"
  },
  {
    "text": "why is that important what your this zero attention policy what's the real breakdown of that privacy why is it",
    "start": "1380840",
    "end": "1386080"
  },
  {
    "text": "important to the men users so from from a company's point of view it's important",
    "start": "1386080",
    "end": "1391520"
  },
  {
    "text": "because you don't want to leak uh portions of your code base or have them persisted in the logs of some third party data provider um as an individual",
    "start": "1391520",
    "end": "1398720"
  },
  {
    "text": "developer I think it's it's just important to to give you control over over your own data um and I think that's",
    "start": "1398720",
    "end": "1404320"
  },
  {
    "text": "going to be an especially important thing uh in in this new world that we're living in where um you know before",
    "start": "1404320",
    "end": "1412039"
  },
  {
    "text": "private data was was valuable um you know it carries value it tells you things about a a certain person or the",
    "start": "1412039",
    "end": "1418520"
  },
  {
    "text": "way they work and that can be used for you know purposes both good and bad search history it's like search history",
    "start": "1418520",
    "end": "1425400"
  },
  {
    "text": "right you can tell L about a person by their search history their watch History their like history totally now it's use for a whole another reason right yeah",
    "start": "1425400",
    "end": "1431760"
  },
  {
    "text": "and and I think it's important to grant our users and customers uh control uh and ownership o over that data because",
    "start": "1431760",
    "end": "1438159"
  },
  {
    "text": "it is your data and I think with language models like language models just uh they like 10x the value and the",
    "start": "1438159",
    "end": "1444520"
  },
  {
    "text": "sensitivity of that data uh because now instead of you know just like feeding it into like a gen one uh AI model or",
    "start": "1444520",
    "end": "1452720"
  },
  {
    "text": "exposing it to some other human you could feed it into one of these large language models that could you know kind of like memorize everything about you as",
    "start": "1452720",
    "end": "1458960"
  },
  {
    "text": "a person or or or a programmer um and you know in some ways maybe that's good",
    "start": "1458960",
    "end": "1464440"
  },
  {
    "text": "like if you're open to that if if you're willing to share your data we could potentially train language models that you know emulate some of the the best",
    "start": "1464440",
    "end": "1470919"
  },
  {
    "text": "and brightest programmers in existence but we ultimately we think that should be you your personal exct how exposive is that in",
    "start": "1470919",
    "end": "1478559"
  },
  {
    "text": "this in the sign up or the acceptance of the Cody license or the you know this GA",
    "start": "1478559",
    "end": "1484240"
  },
  {
    "text": "to now you know widespread usage how do you how explicit are you with a new signup that says I want to use Cody do",
    "start": "1484240",
    "end": "1490480"
  },
  {
    "text": "you say privacy and all these things you just said basically how clear is that uh so when you first install it there's",
    "start": "1490480",
    "end": "1496320"
  },
  {
    "text": "kind of like a terms of use that pops up and you cannot use Cody unless you read through and accept it how many words is",
    "start": "1496320",
    "end": "1502760"
  },
  {
    "text": "in that that uh cosos uh it fits uh on like basically one page without",
    "start": "1502760",
    "end": "1508120"
  },
  {
    "text": "scrolling okay so a, words maybe um 500 yeah 250 maybe not 250 I think it's probably",
    "start": "1508120",
    "end": "1515480"
  },
  {
    "text": "250 to 500 uh I I have to go back and check specifically but like digestible in a in a minute yeah we're we're not",
    "start": "1515480",
    "end": "1522600"
  },
  {
    "text": "trying to be one of those companies that tries to hide stuff well what I mean by that isless trying to say are you hiding it more how clear are you being cuz it",
    "start": "1522600",
    "end": "1529240"
  },
  {
    "text": "seems like you care to be clear yeah so is that like a Paramount thing for you",
    "start": "1529240",
    "end": "1534320"
  },
  {
    "text": "all to be so clear that you say hey privacy matters we don't collect there zero retention it's spelled out really",
    "start": "1534320",
    "end": "1539840"
  },
  {
    "text": "clear it's a bullet list saying basically saying what exactly what you said privacy matters we don't collect data in this way we're not using yeah",
    "start": "1539840",
    "end": "1547240"
  },
  {
    "text": "basically well Tammy our our wonderful legal counsel I I write it I'm just Kidd we all know Chad gbt wrote it",
    "start": "1547240",
    "end": "1554279"
  },
  {
    "text": "okay let's be serious here actually you know that's a great use case for for cat",
    "start": "1554279",
    "end": "1559399"
  },
  {
    "text": "gbt if if you're asked to accept one of these like lengthy end us it in there and summarize this past it in there and",
    "start": "1559399",
    "end": "1564919"
  },
  {
    "text": "summarize it tell anything fishy uh yes that would be cool for sure that's the",
    "start": "1564919",
    "end": "1570480"
  },
  {
    "text": "best I cannot wait honestly for that to come out what are the loopholes in this contract woo I have nefarious action on",
    "start": "1570480",
    "end": "1577080"
  },
  {
    "text": "the other side what are my loopholes to get out right you know what I mean yep for bad or good I guess you could use",
    "start": "1577080",
    "end": "1582120"
  },
  {
    "text": "that in the bad side or the good side but GPT for X where X is literally everything right is going to be like",
    "start": "1582120",
    "end": "1587960"
  },
  {
    "text": "there's going to be one specifically trained for lawyer lawyering yeah yeah I",
    "start": "1587960",
    "end": "1593039"
  },
  {
    "text": "I think um you know language models will be a huge democratizing force in in many domains you know it's",
    "start": "1593039",
    "end": "1598840"
  },
  {
    "text": "democratizing understanding of of legal Concepts democratizing access to software creation I think it's going to",
    "start": "1598840",
    "end": "1604919"
  },
  {
    "text": "be it's there's going to be a huge expansion of of the uh percentage of people that's going to be able to access",
    "start": "1604919",
    "end": "1611640"
  },
  {
    "text": "those knowledge domains right so let's say I'm a happy GitHub co-pilot user mhm",
    "start": "1611640",
    "end": "1618000"
  },
  {
    "text": "oh yeah would I install Cody alongside this and be happier would I be less happy are these compe like is this a",
    "start": "1618000",
    "end": "1624600"
  },
  {
    "text": "zero sum game do I need go all in on Cody what are your thoughts on that uh I think it's the exact opposite of a zero",
    "start": "1624600",
    "end": "1630399"
  },
  {
    "text": "sum game I think there's like so much left to build that uh you know the the market is is huge and and vastly growing",
    "start": "1630399",
    "end": "1638200"
  },
  {
    "text": "um we do have uh features that copilot doesn't have so you know currently they",
    "start": "1638200",
    "end": "1643559"
  },
  {
    "text": "don't have uh kind of like a chat-based uh you know textual input to ask High Lev questions about the the code um I",
    "start": "1643559",
    "end": "1651799"
  },
  {
    "text": "think that's coming in in copile X to some extent they announced that but it's not out yet I don't think it's not out yet and if if you look at the video the",
    "start": "1651799",
    "end": "1657880"
  },
  {
    "text": "the kind of context fetching they're doing it's basically like you know your currently open file explain that and and Cody is already doing much much more",
    "start": "1657880",
    "end": "1663960"
  },
  {
    "text": "than that it's it's reading uh even if you ask it a question about the the current file it would actually go and read other files in your codebase that",
    "start": "1663960",
    "end": "1670000"
  },
  {
    "text": "it thinks are related and and use that to inform your answer so so we think you know the power of source craft gives us",
    "start": "1670000",
    "end": "1675399"
  },
  {
    "text": "a bit of a Competitive Edge there with the kind of High Lev questions and onboarding and kind of like rubber",
    "start": "1675399",
    "end": "1681840"
  },
  {
    "text": "ducking a use case and then for completions you know I I think copot is is great um but for for completions",
    "start": "1681840",
    "end": "1688799"
  },
  {
    "text": "we're we're essentially doing the same thing so like the completions that Cody generates it takes uh into account that",
    "start": "1688799",
    "end": "1694159"
  },
  {
    "text": "same context when it's it's completing code so that means it's it's better able to kind of mimic or or emulate the the",
    "start": "1694159",
    "end": "1702640"
  },
  {
    "text": "patterns and be best practices in your specific code base and again because",
    "start": "1702640",
    "end": "1707799"
  },
  {
    "text": "we're kind of Open Source and model agnostic we are just integrating all the best language models as as they come",
    "start": "1707799",
    "end": "1714559"
  },
  {
    "text": "online so I think you know anthropic I don't know when this episode's uh going out but anthropic today okay pretty",
    "start": "1714559",
    "end": "1720120"
  },
  {
    "text": "quick the 24th yeah so anthropic just announced today that they have a new version of Claude that has a an",
    "start": "1720120",
    "end": "1725519"
  },
  {
    "text": "incredible like 100,000 token context window it's just like a ow or I think",
    "start": "1725519",
    "end": "1730799"
  },
  {
    "text": "like orders of magnitude more than than uh what was previously available and uh",
    "start": "1730799",
    "end": "1736279"
  },
  {
    "text": "that should be I by the the time this episode goes goes online that it should be available in Cody whereas you know",
    "start": "1736279",
    "end": "1742039"
  },
  {
    "text": "co-pilot I think there like uh maybe someone from GitHub can correct me if I'm wrong but I think they're still using the Codex model which was released",
    "start": "1742039",
    "end": "1748799"
  },
  {
    "text": "in like 2021 or something um and so it's it's a much smaller model um that only",
    "start": "1748799",
    "end": "1754679"
  },
  {
    "text": "has around like 2,000 tokens of of context window and much more basic context fetching it's already incredibly",
    "start": "1754679",
    "end": "1761159"
  },
  {
    "text": "useful but I think we're we're kind of taking it Taking to the next level a little bit so open source and model",
    "start": "1761159",
    "end": "1766720"
  },
  {
    "text": "agnostic open source model agnostic we're not locking you into to like a vertical",
    "start": "1766720",
    "end": "1772240"
  },
  {
    "text": "proprietary platform proxy friendly uh also Enterprise friendly you know Source",
    "start": "1772240",
    "end": "1778039"
  },
  {
    "text": "craft we we we made ourselves easy to use in both cloud and on premises",
    "start": "1778039",
    "end": "1783200"
  },
  {
    "text": "environments so we're just trying to do the best thing for our customers and and for developers at large so because",
    "start": "1783200",
    "end": "1789640"
  },
  {
    "text": "you're model agnostic does that mean that you're not you're not doing any of the training of the Bas layer models so",
    "start": "1789640",
    "end": "1796840"
  },
  {
    "text": "do you also sidestep legal concerns cuz I know like with with codex and co-pilot there's been there's at least one high",
    "start": "1796840",
    "end": "1803399"
  },
  {
    "text": "profile lawsuit that's pending like there's there's legal things happening there's going to be things litigated I'm",
    "start": "1803399",
    "end": "1809919"
  },
  {
    "text": "wondering if you're in the target for that now with Cody or if you're just not because is other people's models no",
    "start": "1809919",
    "end": "1815320"
  },
  {
    "text": "we're we're very mindful of that and um we actually integrate models in in a couple different ways so we do it for",
    "start": "1815320",
    "end": "1820799"
  },
  {
    "text": "kind of like the chat based autocomplete there's a separate model we use for code completions and and there's another",
    "start": "1820799",
    "end": "1825840"
  },
  {
    "text": "model that we use for like embeddings based uh uh code search and information retrieval um and it's kind of like a mix",
    "start": "1825840",
    "end": "1831960"
  },
  {
    "text": "and match like we sometimes we'll use like a a proprietary off the-shelf model other times we'll we'll use the model",
    "start": "1831960",
    "end": "1837159"
  },
  {
    "text": "that we find tuned um but for the ones that uh the models that we do rely on external service providers for um we're",
    "start": "1837159",
    "end": "1845360"
  },
  {
    "text": "very mindful of the kind of like evolving legal and IP landscape and so one of the things that we're we're",
    "start": "1845360",
    "end": "1851120"
  },
  {
    "text": "currently building is is basically like copyright code uh or or copied code detection and if you think about it like",
    "start": "1851120",
    "end": "1857559"
  },
  {
    "text": "Source graph as a code search engine is is kind of like in in a great position to to build this feature it's like if",
    "start": "1857559",
    "end": "1862880"
  },
  {
    "text": "you emit a line of code or you write a line of code uh that is you know",
    "start": "1862880",
    "end": "1868000"
  },
  {
    "text": "verbatim copied from uh somewhere else uh in open source or or even in in your",
    "start": "1868000",
    "end": "1873960"
  },
  {
    "text": "own proprietary code base you you might be worried about just like code duplication we can we can flag that for you because we built we've been building",
    "start": "1873960",
    "end": "1880200"
  },
  {
    "text": "code search for the past 10 years yeah cool stuff man so moving fast what comes",
    "start": "1880200",
    "end": "1886720"
  },
  {
    "text": "next [Laughter] when are you going to drop Cody 2 it's",
    "start": "1886720",
    "end": "1892039"
  },
  {
    "text": "probably like a week from now right yeah uh that's a great question I mean we are just kind of like firing all on all",
    "start": "1892039",
    "end": "1897840"
  },
  {
    "text": "cylinders here um we have a lot of interesting directions to explore like one One Direction or one dimension that",
    "start": "1897840",
    "end": "1903919"
  },
  {
    "text": "we're expanding in is just integrating more pieces of context so one of the reasons why we wanted to open source",
    "start": "1903919",
    "end": "1909519"
  },
  {
    "text": "Cody um is because we just want to be able to integrate like context from wherever it is and not be limited by you",
    "start": "1909519",
    "end": "1915519"
  },
  {
    "text": "know a single you know code host or a single platform it's like there's so much institutional knowledge uh that's",
    "start": "1915519",
    "end": "1921240"
  },
  {
    "text": "in many different systems it might be in slack it might be in uh you know GitHub issues it might be in your code review",
    "start": "1921240",
    "end": "1927200"
  },
  {
    "text": "Tool uh it might be in your production logs and so we want to build Integrations into Cody that just pull in",
    "start": "1927200",
    "end": "1933600"
  },
  {
    "text": "all this context and I think the the best way to do that is just to make this this kind of like platform uh this",
    "start": "1933600",
    "end": "1938880"
  },
  {
    "text": "orchestrator of sorts like open source and and accessible to to everyone yeah um the other dimension that that is very",
    "start": "1938880",
    "end": "1945519"
  },
  {
    "text": "exciting to us is is going deep into the model layer so we've already started to do this for the embeddings based uh like",
    "start": "1945519",
    "end": "1951039"
  },
  {
    "text": "Code retrieval um but I think we're we're exploring some uh models that are related to code generation and",
    "start": "1951039",
    "end": "1957120"
  },
  {
    "text": "potentially even like the chat based completions at some point um and that's going to be interesting because it's",
    "start": "1957120",
    "end": "1962760"
  },
  {
    "text": "it's going to allow us to incorporate pieces of source graph into the actual like training process and there's been some research there that shows that uh",
    "start": "1962760",
    "end": "1969279"
  },
  {
    "text": "incorporating like search engines into training uh language models actually you know yields very nice uh properties in",
    "start": "1969279",
    "end": "1975799"
  },
  {
    "text": "terms of like lower latency but uh higher quality um and it's also important to a lot of our customers because a lot of them are you know large",
    "start": "1975799",
    "end": "1982480"
  },
  {
    "text": "corporations they Deploy on premises and uh even the zero retention policy where",
    "start": "1982480",
    "end": "1987919"
  },
  {
    "text": "you know the code is forgotten as soon as it's uh you know sent back over uh is not good enough for for some of our",
    "start": "1987919",
    "end": "1993679"
  },
  {
    "text": "customers so they want to completely be able to self-host this and uh you know we plan to serve them as well how high",
    "start": "1993679",
    "end": "1999840"
  },
  {
    "text": "up the stack like the conceptual stack do you think Cody can get or maybe any",
    "start": "1999840",
    "end": "2005320"
  },
  {
    "text": "AI tooling with Cod genen with regards to like how I instructed as a developer yeah you know cuz right now",
    "start": "2005320",
    "end": "2011919"
  },
  {
    "text": "we're very much like okay it's autocomplete there's a function here right I can tell it write me a thing",
    "start": "2011919",
    "end": "2017519"
  },
  {
    "text": "that connects to an API and parses the Json or whatever and it can can spit that out but like how high up the stat",
    "start": "2017519",
    "end": "2023559"
  },
  {
    "text": "can I get can I say you know write me a Facebook Facebook for dogs you know and",
    "start": "2023559",
    "end": "2029159"
  },
  {
    "text": "be done for instance or like user stories can I write some user stories and it go from there what do you think that's a great question I mean we've all",
    "start": "2029159",
    "end": "2034880"
  },
  {
    "text": "seen uh the Twitter demos by now now where you know someone is like you know gp4 like build me an app and you know it",
    "start": "2034880",
    "end": "2041320"
  },
  {
    "text": "creates a working app and whole website I think if if you actually gone through and and tried that in practice yourself",
    "start": "2041320",
    "end": "2047159"
  },
  {
    "text": "you soon realize like hey you can get to like a working app pretty quickly just through like instructing it using",
    "start": "2047159",
    "end": "2053960"
  },
  {
    "text": "English or or natural language but then you get a little bit further down that path and you're like oh I wanted to do",
    "start": "2053960",
    "end": "2059158"
  },
  {
    "text": "this I wanted to do that can you add this Bel whistle there's kind of this like combinatorial complexity that emerges as you add like different",
    "start": "2059159",
    "end": "2065398"
  },
  {
    "text": "features and you're kind of diverg from like the common path and then and then it falls apart like I actually tried",
    "start": "2065399",
    "end": "2071240"
  },
  {
    "text": "this myself like I I tried to write a complete app uh is actually a prototype for for the next version of Cody okay um",
    "start": "2071240",
    "end": "2078200"
  },
  {
    "text": "I tried to do it by not writing a single line of code just by writing English and I got like 80% of the way there in like",
    "start": "2078200",
    "end": "2085638"
  },
  {
    "text": "30 minutes and I was like this is amazing like this is the future like I'm never going to code again and then the",
    "start": "2085639",
    "end": "2091398"
  },
  {
    "text": "remaining 20% literally took like 4 hours and I was banging my head against the wall because you know I asked to do",
    "start": "2091399",
    "end": "2097240"
  },
  {
    "text": "one thing and then it did did it but then it kind of like screwed up this other thing and it became kind of this",
    "start": "2097240",
    "end": "2102599"
  },
  {
    "text": "like whack-a-mole problem so we're not all the way there yet but I think I think the way we think about it is like",
    "start": "2102599",
    "end": "2107839"
  },
  {
    "text": "Cody right now is at the point where if you ask it uh this is another thing I tried the other day like I wanted to add",
    "start": "2107839",
    "end": "2113240"
  },
  {
    "text": "a new feature to Cody uh Cody has these things called recipes which are kind of like templated interactions with uh Cody",
    "start": "2113240",
    "end": "2119640"
  },
  {
    "text": "so like write a unit test or generate a dock string or you know smell my code you know give me some feedback yeah I",
    "start": "2119640",
    "end": "2125119"
  },
  {
    "text": "wanted to add a new recipe and I basically asked Cody hey I want to add a new recipe to Cody uh what parts of the",
    "start": "2125119",
    "end": "2130920"
  },
  {
    "text": "code should I modify and it basically showed me all the parts of the code that were relevant and then it generated the",
    "start": "2130920",
    "end": "2136320"
  },
  {
    "text": "code for the new recipe using the existing recipes as like a reference point uh and I basically got it done",
    "start": "2136320",
    "end": "2142079"
  },
  {
    "text": "like 5 minutes and it was amazing so like I was still obviously in the hot seat there I was still uh calling the shots but it turned something that",
    "start": "2142079",
    "end": "2149119"
  },
  {
    "text": "probably would have been uh at least 30 minutes maybe an hour you know if I got frustrated or or or distracted into",
    "start": "2149119",
    "end": "2154680"
  },
  {
    "text": "something that was like 5 minutes and that was actually that was actually the interview question we were using for interviewing on on the",
    "start": "2154680",
    "end": "2160440"
  },
  {
    "text": "AI team so after that we had to go back and like revamp that like this is too easy too easy now everything just got",
    "start": "2160440",
    "end": "2166520"
  },
  {
    "text": "easier yeah do you think this is like a a step change in what we can do and then",
    "start": "2166520",
    "end": "2172760"
  },
  {
    "text": "we're going to Plateau right here for a while and like refine and you know do more stuff but kind of like stay at this",
    "start": "2172760",
    "end": "2178920"
  },
  {
    "text": "level of quote unquote intelligence or do you think it's like just the sky is the limit from here on out like which I",
    "start": "2178920",
    "end": "2185119"
  },
  {
    "text": "mean obviously just conjecture at this point Ching to predict I mean it's it's very challenging to predict uh you know",
    "start": "2185119",
    "end": "2190200"
  },
  {
    "text": "I might be eating my words um in in another 6 months but like you know on the spectrum of you know oh it's just",
    "start": "2190200",
    "end": "2197040"
  },
  {
    "text": "like glorified autocomplete and it doesn't really know anything to all all the way to like you know AGI Doomer you",
    "start": "2197040",
    "end": "2202240"
  },
  {
    "text": "know let's let's nuke the GPU data centers oh my gosh um I where do you fall yeah I don't give",
    "start": "2202240",
    "end": "2209640"
  },
  {
    "text": "him ideas cancel cancel cancel honestly I I think a lot of the discourse uh on that",
    "start": "2209640",
    "end": "2216160"
  },
  {
    "text": "end of the spectrum has just gotten kind of crazy um like the way the way I view it is this is a really powerful tool",
    "start": "2216160",
    "end": "2221880"
  },
  {
    "text": "it's an amazing new technology and you know it can be used for for evil certainly as as any technology can but",
    "start": "2221880",
    "end": "2228440"
  },
  {
    "text": "uh I'm a techno Optimist and I think this will largely be like positively impactful uh for the world um and I",
    "start": "2228440",
    "end": "2234920"
  },
  {
    "text": "don't really see it you know replacing uh programmers it might change the way we think about programming or you know",
    "start": "2234920",
    "end": "2240800"
  },
  {
    "text": "software creation uh there's certainly going to be a lot more people that are going to be empowered to create software",
    "start": "2240800",
    "end": "2246280"
  },
  {
    "text": "now um and I think there there'll be kind of a spectrum of people um from you know",
    "start": "2246280",
    "end": "2251400"
  },
  {
    "text": "those who who write software uh just by describing it in in natural language all the way to the people who are kind of",
    "start": "2251400",
    "end": "2257920"
  },
  {
    "text": "like building the the core kernels uh of of kind of like the operating systems of",
    "start": "2257920",
    "end": "2263560"
  },
  {
    "text": "the future that form like the solid foundation that you know pack in the really important you know data structures and algori algorithms and and",
    "start": "2263560",
    "end": "2270319"
  },
  {
    "text": "and core architecture around which everyone else can uh you know throw their you know ideas and and and stuff",
    "start": "2270319",
    "end": "2276880"
  },
  {
    "text": "so there'll be like a huge Spectrum I think you know we'll almost think of it in terms of like the way we think of",
    "start": "2276880",
    "end": "2282640"
  },
  {
    "text": "like reading and writing now where like you know you have many different forms of reading and writing like there's people just like Reading Writing stuff",
    "start": "2282640",
    "end": "2289359"
  },
  {
    "text": "on Twitter you know that's that's one form of writing and then there's other people who write you know long books right that span you know uh many years",
    "start": "2289359",
    "end": "2296319"
  },
  {
    "text": "of intense research and I think the future of code looks something like that it's the ultimate",
    "start": "2296319",
    "end": "2301920"
  },
  {
    "text": "flattener you you see that book The World is Flat yeah yeah it's like that like for a while there it was",
    "start": "2301920",
    "end": "2307760"
  },
  {
    "text": "Outsourcing and now it's sort of like just accessibility to everybody now yeah you know people who don't know much",
    "start": "2307760",
    "end": "2314000"
  },
  {
    "text": "about Coke can learn about code and level up pretty quickly and so the access The Catered access to have uh a",
    "start": "2314000",
    "end": "2322560"
  },
  {
    "text": "patient whether person or not like I have conversations with chat GPT and I swear I'm like I tell my wife I'm like",
    "start": "2322560",
    "end": "2329079"
  },
  {
    "text": "I'm literally talking to a machine and I get it but we 30 40 rounds back and",
    "start": "2329079",
    "end": "2335880"
  },
  {
    "text": "forth through whatever it might be and it's very much like a conversation I'd have with Jared if he would give me the",
    "start": "2335880",
    "end": "2341359"
  },
  {
    "text": "time and patience and if you wouldn't get frustrated you know what I mean and so it's a better very Pati yeah well not",
    "start": "2341359",
    "end": "2348119"
  },
  {
    "text": "necessarily but you know the world now has access to a patient yeah uh sidecar",
    "start": "2348119",
    "end": "2353760"
  },
  {
    "text": "that's quite intelligent that will get even more intelligent whether you call it artificial intelligence or not you",
    "start": "2353760",
    "end": "2359480"
  },
  {
    "text": "know it has Intelligence behind it some knowledge yeah and it's accessible right now I agree humans are still necessary",
    "start": "2359480",
    "end": "2367640"
  },
  {
    "text": "thank thank the Lord um but wow it's super flat now and a lot a lot more",
    "start": "2367640",
    "end": "2372680"
  },
  {
    "text": "people have access to what could be totally and what might be because of this and and that's a fantastic thing I",
    "start": "2372680",
    "end": "2378160"
  },
  {
    "text": "think of you know there's that Steve Jobs quote where he said computers are amazing because they're they're like a bicycle for the human mind they allow a",
    "start": "2378160",
    "end": "2385640"
  },
  {
    "text": "much more I think he drawing comparisons to like you know how different animals get around and like a a a human walking",
    "start": "2385640",
    "end": "2391720"
  },
  {
    "text": "is like very inefficient but a human on a bicycle is like more efficient than like the the the fastest cheetah or",
    "start": "2391720",
    "end": "2397560"
  },
  {
    "text": "whatever right I think like what what language models um are are capable of doing is instead of like a bicycle now",
    "start": "2397560",
    "end": "2404640"
  },
  {
    "text": "we each have like a race car or or a rocket ship now we're still in the driver's seat right like we're still steering it and telling you where to go",
    "start": "2404640",
    "end": "2410720"
  },
  {
    "text": "but it's just it's way more leverage uh for any given uh individual so great",
    "start": "2410720",
    "end": "2416640"
  },
  {
    "text": "thing if you know you love being creative you love dreaming up you know new ideas um and and ways to to solve",
    "start": "2416640",
    "end": "2423440"
  },
  {
    "text": "problems one more question on the business side of things how has growth been because of Cody that's a great",
    "start": "2423440",
    "end": "2430160"
  },
  {
    "text": "question um Cody is I you almost would not believe it if",
    "start": "2430160",
    "end": "2437400"
  },
  {
    "text": "uh I described it to you but um Cody is literally like the most magical thing to to happen to the source graph go to",
    "start": "2437400",
    "end": "2444480"
  },
  {
    "text": "market uh or or sales uh motion since basically when we started the company",
    "start": "2444480",
    "end": "2449839"
  },
  {
    "text": "ever basically uh I've been paying attention for a while that's why I that question cuz like youve had trouble getting growth cuz you got to install a",
    "start": "2449839",
    "end": "2455160"
  },
  {
    "text": "server or go cloud and you got to examine the code base then you got to learn how to search the code which is",
    "start": "2455160",
    "end": "2460480"
  },
  {
    "text": "all like friction points so so one of the like transparently one of the the challenges that we had as a business is",
    "start": "2460480",
    "end": "2465640"
  },
  {
    "text": "you know we we had a couple of sub uh subsets of the programmer population",
    "start": "2465640",
    "end": "2472160"
  },
  {
    "text": "that were were very eager to adopt Source craft is basically if you used a tool like Source craft before you want to use it again so if you're an ex",
    "start": "2472160",
    "end": "2478440"
  },
  {
    "text": "googler ex facebooker X drop boxer or you know X microsof you know in in a",
    "start": "2478440",
    "end": "2484200"
  },
  {
    "text": "couple teams you kind of got it immed medely uh and then everyone else is like oh is it like grep or is it like contr",
    "start": "2484200",
    "end": "2491640"
  },
  {
    "text": "f and we we would lose a lot of people along the way I think with Cody it's it's at the point where not only does",
    "start": "2491640",
    "end": "2498599"
  },
  {
    "text": "any programmer get it right away they're like oh holy like uh you know you just asked to explain this like very",
    "start": "2498599",
    "end": "2504920"
  },
  {
    "text": "complex code in in English and gave me like really good explanation um even like non-technical stakeholders so like",
    "start": "2504920",
    "end": "2511560"
  },
  {
    "text": "as we sell to larger and larger companies a lot of times you know in the room is is someone with like a uh I",
    "start": "2511560",
    "end": "2517880"
  },
  {
    "text": "don't know uh CEO or like board of directors or uh you know non-technical",
    "start": "2517880",
    "end": "2524040"
  },
  {
    "text": "some someone who's pretty distant from from the code uh traditionally speaking and uh they get it too cuz yeah you know",
    "start": "2524040",
    "end": "2531920"
  },
  {
    "text": "we were in a pitch meeting the the other week where it was like a large kind of Fortune 500 Energy company and there was",
    "start": "2531920",
    "end": "2538200"
  },
  {
    "text": "not a program in the room it was just kind of like you know high level business owners um who are all very",
    "start": "2538200",
    "end": "2543839"
  },
  {
    "text": "skeptical until we got to Cody we opened up you know one of their open source libraries and asked Cody to",
    "start": "2543839",
    "end": "2549559"
  },
  {
    "text": "explain what it was going and and one person leaned in and they were like you know I'm I haven't coded in like 30",
    "start": "2549559",
    "end": "2555640"
  },
  {
    "text": "years and even I would get value out of this so yeah it's it's just absolutely incredible your total adjustable Market",
    "start": "2555640",
    "end": "2561960"
  },
  {
    "text": "got a lot bigger yeah yeah yeah cuz like what is an engineer now um I think it's",
    "start": "2561960",
    "end": "2567319"
  },
  {
    "text": "like it in in a couple years uh almost every human in the world will be",
    "start": "2567319",
    "end": "2572760"
  },
  {
    "text": "empowered to create software in in some some fashion you said before that Cody",
    "start": "2572760",
    "end": "2578200"
  },
  {
    "text": "leverages all that Source graph is today the intelligence yep will that always be true I guess is maybe the more basic way",
    "start": "2578200",
    "end": "2585040"
  },
  {
    "text": "to answer that or ask that question because at some point if this is the you know the the largest Arc in your hockey",
    "start": "2585040",
    "end": "2592200"
  },
  {
    "text": "stick growth yeah and all the up from here is you know not so much Cody related but Cody driven really yeah does",
    "start": "2592200",
    "end": "2599680"
  },
  {
    "text": "what source graft do at large now eventually become less and less important and the primary interface",
    "start": "2599680",
    "end": "2605400"
  },
  {
    "text": "really is this natural language Cod interface that explains my code that's a great question",
    "start": "2605400",
    "end": "2611359"
  },
  {
    "text": "it's like you know does does AI just like swallow all of programming at some point like at some point do we cease to",
    "start": "2611359",
    "end": "2617319"
  },
  {
    "text": "write uh kind of like old traditional like systems oriented uh software in the",
    "start": "2617319",
    "end": "2623720"
  },
  {
    "text": "Von noyman you can't wrote that code what yeah you wrote a for Loop",
    "start": "2623720",
    "end": "2629240"
  },
  {
    "text": "instead of just like asking it nicely to repeat something forget code search I don't even read code like why you",
    "start": "2629240",
    "end": "2636160"
  },
  {
    "text": "reading code let alone searching it right yeah I you know this is still very early days",
    "start": "2636160",
    "end": "2643040"
  },
  {
    "text": "so uh it it's very difficult to predict but the way I think about it it I think about it in in terms of like maybe we",
    "start": "2643040",
    "end": "2650520"
  },
  {
    "text": "have there are different types of computers that can exist in the world like a traditional you know like PC",
    "start": "2650520",
    "end": "2657119"
  },
  {
    "text": "that's one type of computer you could maybe say like the human brain is another type of computer um and then",
    "start": "2657119",
    "end": "2662680"
  },
  {
    "text": "these language models I think they're they're a new type of computer and they do some things a lot better than you",
    "start": "2662680",
    "end": "2670000"
  },
  {
    "text": "know the PC type of computer did uh and then some things much worse like they're far less precise um I think I saw a",
    "start": "2670000",
    "end": "2677640"
  },
  {
    "text": "tweet the other day where someone repeatedly asked you know GPD 4 whether you know four was greater than one and",
    "start": "2677640",
    "end": "2683240"
  },
  {
    "text": "then at some point GPD 4 got unsure of itself and said oh no actually I was mistaken you know one is greater than",
    "start": "2683240",
    "end": "2688920"
  },
  {
    "text": "four my gosh I apologize yeah exactly exactly yeah I apologize so I think",
    "start": "2688920",
    "end": "2695000"
  },
  {
    "text": "these two types of computers are actually very complimentary and so like the most powerful systems are going to",
    "start": "2695000",
    "end": "2700800"
  },
  {
    "text": "be the ones that combine both and feed the inputs of one and the outputs of the other uh and and synthesize them in a",
    "start": "2700800",
    "end": "2708319"
  },
  {
    "text": "way that's truly powerful and and we're already seeing early examples of this like Cody is one you know we use kind of",
    "start": "2708319",
    "end": "2713559"
  },
  {
    "text": "like the the chompsky style like code understanding Tech with the the more",
    "start": "2713559",
    "end": "2719000"
  },
  {
    "text": "norvig style you know language models um being search is another you know where uh they're using chat GPT uh for for the",
    "start": "2719000",
    "end": "2726040"
  },
  {
    "text": "AI part of it but they're still relying on kind of traditional B web search and so I think we'll see a lot of hybrid systems emerge that combine The Best of",
    "start": "2726040",
    "end": "2732640"
  },
  {
    "text": "Both Worlds yeah exciting times thanks for talking to us yeah thanks for having me on good seeing you again good talking",
    "start": "2732640",
    "end": "2739400"
  },
  {
    "text": "pleasure chatting with you oh that was fun that's exit you guys are good at this I'm excited for",
    "start": "2739400",
    "end": "2745410"
  },
  {
    "text": "[Music]",
    "start": "2745410",
    "end": "2749699"
  },
  {
    "text": "you [Music]",
    "start": "2754880",
    "end": "2760280"
  },
  {
    "text": "so in the sponsor of minod here in the breaks I'm here with Tom who Dev Advocate at Sentry on the code COV team",
    "start": "2760280",
    "end": "2767359"
  },
  {
    "text": "so Tom tell me about Sentry's acquisition of code COV and in particular how is this improving the",
    "start": "2767359",
    "end": "2773079"
  },
  {
    "text": "Sentry platform when I think about the acquisition when I think about how does Sentry use code COV or conversely how",
    "start": "2773079",
    "end": "2779839"
  },
  {
    "text": "does codeup you Sentry like I think of code cup and I think of the time of deploy when you're a sofware developer",
    "start": "2779839",
    "end": "2786200"
  },
  {
    "text": "you have your lifecycle you write your code you test your code you deploy and then your code goes into production and then you sort of fix good bugs and I",
    "start": "2786200",
    "end": "2792520"
  },
  {
    "text": "sort of think of that split in time as like when you actually do that deploy now where code cup is really useful is",
    "start": "2792520",
    "end": "2798520"
  },
  {
    "text": "before deploy time it's when you are developing your code it's when you're saying hey like I want to make sure this is going to work I want to make sure",
    "start": "2798520",
    "end": "2804760"
  },
  {
    "text": "that I have as few bugs as possible I want to make sure that I thought of all the errors and all the edge cases and whatnot and Sentry is the flip side of",
    "start": "2804760",
    "end": "2812480"
  },
  {
    "text": "that it says hey what happens when you hit production right when you have a bug and you need to understand what's",
    "start": "2812480",
    "end": "2817599"
  },
  {
    "text": "happening in that bug you need to understand the context around it you need to understand where it's happening what the stack Trace looks like what",
    "start": "2817599",
    "end": "2823160"
  },
  {
    "text": "other local variables you know exist at that time so that you can debug that uh and hopefully you don't see that error",
    "start": "2823160",
    "end": "2829400"
  },
  {
    "text": "case again when I think of like oh what can Sentry do with COV or what can COV do with Sentry it's sort of taking that",
    "start": "2829400",
    "end": "2835960"
  },
  {
    "text": "entire spectrum of the developer life cycle of hey what can we do to make sure that you ship the the least buggy code",
    "start": "2835960",
    "end": "2843040"
  },
  {
    "text": "that you can and when you do come to a bug that is expected you can fix it as quickly as possible right because you",
    "start": "2843040",
    "end": "2849200"
  },
  {
    "text": "know as developers we we want to write good code we want to make sure that people can use the code that we written",
    "start": "2849200",
    "end": "2855000"
  },
  {
    "text": "we want to make sure that they're happy with the product they're happy with the software and it works the way that we expected to if we can build a product",
    "start": "2855000",
    "end": "2861040"
  },
  {
    "text": "you know the century plus code cuff thing to make sure that you are drisking your code changes uh and drisking your",
    "start": "2861040",
    "end": "2868400"
  },
  {
    "text": "your software then you know we've hopefully done to developer Community as service so Tom you say bring your test",
    "start": "2868400",
    "end": "2876119"
  },
  {
    "text": "and you'll handle the rest break it down for me how does a team get started with code COV you know what you bring to the",
    "start": "2876119",
    "end": "2882559"
  },
  {
    "text": "table is like testing and you bring your coverage reports and what Cod COV does is we say hey give us your coverage",
    "start": "2882559",
    "end": "2888920"
  },
  {
    "text": "reports give us access to your code base so that we can you know overlay code coverage on top of it and give us access",
    "start": "2888920",
    "end": "2894760"
  },
  {
    "text": "to your cicd and so with those things what we do and what code cover is really",
    "start": "2894760",
    "end": "2899839"
  },
  {
    "text": "powerful at is that it's not just hey like this is your code coverage number it's hey here's a code coverage number",
    "start": "2899839",
    "end": "2906160"
  },
  {
    "text": "and your viewer also knows and other piece parts of your organization know as well so it's not just you dealing with",
    "start": "2906160",
    "end": "2912079"
  },
  {
    "text": "code coverage and saying I don't really know what to do with this because we take your code coverage we analyze it",
    "start": "2912079",
    "end": "2917760"
  },
  {
    "text": "and we throw it back to you into your developer workflow uh and by developer workflow I mean your pull request your",
    "start": "2917760",
    "end": "2922839"
  },
  {
    "text": "merge request and we give it to you as a comment so that you can see oh great this was my code coverage change um but",
    "start": "2922839",
    "end": "2928920"
  },
  {
    "text": "not only do you see this sort of information but your reviewer also sees it and they can tell oh great you've tested your code or you haven't tested",
    "start": "2928920",
    "end": "2934960"
  },
  {
    "text": "your code and we also give you a status check which says Hey like you've met whatever your team's decision on what",
    "start": "2934960",
    "end": "2941160"
  },
  {
    "text": "your code coverage should be or you haven't met that goal whatever it happens to be and so code COV is particularly powerful in making sure",
    "start": "2941160",
    "end": "2947920"
  },
  {
    "text": "that code coverage is not just a thing that you're doing on your own Island as a developer but that your entire team",
    "start": "2947920",
    "end": "2953440"
  },
  {
    "text": "can get involved with and can make decisions very cool thank you Tom so hey listeners head to sentury and check them",
    "start": "2953440",
    "end": "2960160"
  },
  {
    "text": "out sentry.io and use our code change log so the cool thing is is our listeners you",
    "start": "2960160",
    "end": "2967480"
  },
  {
    "text": "get the team plan for free for 3 months not 1 month not two months 3 months yes",
    "start": "2967480",
    "end": "2974680"
  },
  {
    "text": "the team plan for free for 3 months use the code change log again",
    "start": "2974680",
    "end": "2980040"
  },
  {
    "text": "sentry.io that's scn t y. and use the code change log also",
    "start": "2980040",
    "end": "2986480"
  },
  {
    "text": "check out our friends over at code COV that's code. like code coverage but just",
    "start": "2986480",
    "end": "2993240"
  },
  {
    "text": "shorten to code COV code COV iio",
    "start": "2993240",
    "end": "2998680"
  },
  {
    "text": "[Music]",
    "start": "3001460",
    "end": "3005530"
  },
  {
    "text": "enjoy so now we're now we're fine tuned here we're ready to go so I see what you did there swine tuned I think is what",
    "start": "3018319",
    "end": "3026200"
  },
  {
    "text": "you were trying to say well no I think it was a dolly reference fine tune so yeah it was a pun it was a pun work with",
    "start": "3026200",
    "end": "3033000"
  },
  {
    "text": "this jar I mean Adam and I are already on the same page what the heck man Adam's puns are on point always he never",
    "start": "3033000",
    "end": "3038880"
  },
  {
    "text": "misses with a pun all right thank you all right so we have Denny Lee from data",
    "start": "3038880",
    "end": "3044920"
  },
  {
    "text": "bricks or data bricks data bricks data bricks is that the official it's not Canadian or American thing it's just data bricks it's just data bricks here",
    "start": "3044920",
    "end": "3051799"
  },
  {
    "text": "to talk about Dolly 2 but first I hear you're a Just in Time conference",
    "start": "3051799",
    "end": "3058160"
  },
  {
    "text": "presenter tell us what this means well I think the the context was that you were asking me hey what's your presentation",
    "start": "3058160",
    "end": "3065200"
  },
  {
    "text": "that's what you asked me first and I was actually responding I don't remember the name nor do I remember I I do remember",
    "start": "3065200",
    "end": "3071319"
  },
  {
    "text": "the concepts at least I do have that part but I don't remember the name nor are the slides done yet and and this is",
    "start": "3071319",
    "end": "3078599"
  },
  {
    "text": "normal and it starts in 30 minutes no no no no no no no tomorrow no no tomorrow tomorrow tomorrow I'm just simply saying",
    "start": "3078599",
    "end": "3084200"
  },
  {
    "text": "that it is common for me to go ahead and not do a thing until 30 minutes before",
    "start": "3084200",
    "end": "3089839"
  },
  {
    "text": "the actual presentation to create the slides so you're a procrastinator yes I'm a very good one that's not",
    "start": "3089839",
    "end": "3096240"
  },
  {
    "text": "procrastination optimization efficiency efficiency why sweat over the details until you have to exactly exactly",
    "start": "3096240",
    "end": "3102359"
  },
  {
    "text": "because what if you start 30 minutes before but you realize the details required 45 minutes so I had this one",
    "start": "3102359",
    "end": "3109160"
  },
  {
    "text": "time where actually Budd of mine Thomas Kaiser he and I went ahead and did a presentation where he so he's from",
    "start": "3109160",
    "end": "3114520"
  },
  {
    "text": "Denmark I'm from Seattle we're both in I don't know where some other City to do",
    "start": "3114520",
    "end": "3119599"
  },
  {
    "text": "the presentation somewhere in the world somewhere in the world so we actually got together but we realized we actually hadn't done squat on the slides until 30",
    "start": "3119599",
    "end": "3126880"
  },
  {
    "text": "minutes before the actual session and guess what 30 minutes before put together the slides bam we're good to go",
    "start": "3126880",
    "end": "3133720"
  },
  {
    "text": "so has it ever bit you uh I'm sure tomorrow I'm sure at some point it will",
    "start": "3133720",
    "end": "3140119"
  },
  {
    "text": "bite me uh I guess the context is I've gotten away with it so far so I'm going",
    "start": "3140119",
    "end": "3145920"
  },
  {
    "text": "to go with it and enough times that you have full confidence yes fair enough yes or at least I know how to fake it so",
    "start": "3145920",
    "end": "3152720"
  },
  {
    "text": "what would you like to know about Dolly about Dolly one well how he came about with dolly 1. dolly let's start with why all right let's start with why and then",
    "start": "3152720",
    "end": "3158640"
  },
  {
    "text": "how all right so let's go backwards a little bit you're talking all the way back three weeks ago okay rough roughly",
    "start": "3158640",
    "end": "3164960"
  },
  {
    "text": "four no in the days of your yeah in the days of your four weeks ago all right so the one of the things that and I want to",
    "start": "3164960",
    "end": "3171680"
  },
  {
    "text": "give credit we credit to Mike Conover is the guy who actually figured it out okay now we were using a much older",
    "start": "3171680",
    "end": "3179280"
  },
  {
    "text": "particular model uh and we're going like this would this work right and what it",
    "start": "3179280",
    "end": "3184680"
  },
  {
    "text": "Bol down to is that there's a supposition that could you take an older model fine-tune it with good data and",
    "start": "3184680",
    "end": "3190720"
  },
  {
    "text": "still actually end up getting good results with the key point being that hey we're only going to pay $30 to R to",
    "start": "3190720",
    "end": "3197720"
  },
  {
    "text": "actually train the data as opposed to oh the tens of millions of dollars that you would have to do and could you do it",
    "start": "3197720",
    "end": "3204440"
  },
  {
    "text": "that was Theos position for Dolly 1.0 and sure enough we were right basically",
    "start": "3204440",
    "end": "3209640"
  },
  {
    "text": "it was about $30 worth of uh training time on what was what is not considered",
    "start": "3209640",
    "end": "3215319"
  },
  {
    "text": "public data so that's why it's Dolly 1.0 so we could give you them weights we can give you the model but we couldn't give you the data because the data itself was",
    "start": "3215319",
    "end": "3221520"
  },
  {
    "text": "actually not public but you owned it no no no that was the in fact I believe was the chat the same data that chat was",
    "start": "3221520",
    "end": "3227760"
  },
  {
    "text": "using so so we could give you the weight again that's open source but we can't do the data because the data is actually chat gbt okay all right so and so then",
    "start": "3227760",
    "end": "3234680"
  },
  {
    "text": "we're going wa wait we actually used only a tiny amount of data and it still came out with some pretty decent results",
    "start": "3234680",
    "end": "3240920"
  },
  {
    "text": "okay let's let's go ahead and say why don't we generate our own data so again",
    "start": "3240920",
    "end": "3246599"
  },
  {
    "text": "take credit where credit is do our Founders went ahead and said hey why don't we just get we have about 5,000 employees at data breaks now this is my",
    "start": "3246599",
    "end": "3253160"
  },
  {
    "text": "favorite part yeah let's just go ahead and generate our own data so for 2 weeks that's literally all we did we had",
    "start": "3253160",
    "end": "3258760"
  },
  {
    "text": "basically basically a bunch of uh employees dumping in data in like in a Q&A type style format with seven",
    "start": "3258760",
    "end": "3264440"
  },
  {
    "text": "different categories it's all listed out there so I don't remember all all those details anymore um I worked on the t-shirts so at least I was helpful on",
    "start": "3264440",
    "end": "3270960"
  },
  {
    "text": "that part love the T-shirt that's a good one no one's seen this right now but it's a well yeah it is a podcast so that",
    "start": "3270960",
    "end": "3276359"
  },
  {
    "text": "that tends draw draw a word picture Adam dude a sheep come on man it's dolly dolly dolly my gosh oh my goodness you",
    "start": "3276359",
    "end": "3284160"
  },
  {
    "text": "thought he was on point okay so Dolly the sheep a clone right it's a clone right so that's the",
    "start": "3284160",
    "end": "3290400"
  },
  {
    "text": "whole context yes so we go ahead and actually get that up and running and then we're like hey now now we've got",
    "start": "3290400",
    "end": "3295520"
  },
  {
    "text": "15,000 plus so set of of of Q&A style new information all brand new and we're",
    "start": "3295520",
    "end": "3302640"
  },
  {
    "text": "publicly giving it away right so not so the actual data set if you go to hugging face or datab brick Labs SL dolly or",
    "start": "3302640",
    "end": "3310240"
  },
  {
    "text": "whatever the the GitHub site is yeah basically all that data is there okay all 15,000 lines uh not sorry lines",
    "start": "3310240",
    "end": "3317799"
  },
  {
    "text": "15,000 Q&A okay and then we train that data set again using the same old model",
    "start": "3317799",
    "end": "3324359"
  },
  {
    "text": "from 2 years ago okay okay and we ran that and then basically what was really cool about this is that it talk cost us about $100",
    "start": "3324359",
    "end": "3331960"
  },
  {
    "text": "worth of training but it's pretty good and if you ask some pointed questions on this stuff it actually responds really",
    "start": "3331960",
    "end": "3338000"
  },
  {
    "text": "really well for example I've got like some examples where I'm actually asking coffee questions and the coffee",
    "start": "3338000",
    "end": "3343359"
  },
  {
    "text": "questions answers are okay I'll give chat gbt 4.0 a lot of credit yeah it is",
    "start": "3343359",
    "end": "3349200"
  },
  {
    "text": "much more verbose than what Dolly 2.0 can provide but in terms of correctness it is correct they both are the same",
    "start": "3349200",
    "end": "3356000"
  },
  {
    "text": "level of correctness between Dolly to. uh and chat gbd4 I actually have it on my own like uh it's on my own GitHub",
    "start": "3356000",
    "end": "3362520"
  },
  {
    "text": "somewhere like a r or actually explain all that mainly because I was actually running it on an M1 Mac too because I was goofing off and fine well that's",
    "start": "3362520",
    "end": "3369680"
  },
  {
    "text": "amazing right there yeah let me first just say as a daily user of chat GPT sometimes verbose is not desirable and",
    "start": "3369680",
    "end": "3377160"
  },
  {
    "text": "I'm like dude I actually will tell to to be brief or in one sentence give me because I'm so sick of the word salad",
    "start": "3377160",
    "end": "3384160"
  },
  {
    "text": "that spits out I'm like I just want the answer the answers are you know useful but sometimes you're like waiting for it",
    "start": "3384160",
    "end": "3389319"
  },
  {
    "text": "to tell me the whole history of the thing you're like no well don't you want to know like the retrospective while you're at it I'm I'm being very",
    "start": "3389319",
    "end": "3395280"
  },
  {
    "text": "sarcastic yes can't tell it's a podcast we're all eye rolling each other on that one we are that was Major eye rolls so",
    "start": "3395280",
    "end": "3403440"
  },
  {
    "text": "using it mhm let's say I've never used anything but chat gpt's web UI but I'm a",
    "start": "3403440",
    "end": "3410280"
  },
  {
    "text": "developer sure and I want my own I want Dolly to answer my questions yes what",
    "start": "3410280",
    "end": "3415319"
  },
  {
    "text": "does that process look like for folks okay so you've got two choices or no no I should rephrase slight you've got many",
    "start": "3415319",
    "end": "3420720"
  },
  {
    "text": "choices in fact but the most common choices are we have a datab bricks notebook that's in the dolly GitHub that",
    "start": "3420720",
    "end": "3427039"
  },
  {
    "text": "you can just download for free run it now then you're going to tell me but Denny I don't want to use data bricks",
    "start": "3427039",
    "end": "3433880"
  },
  {
    "text": "that's fair I would prefer you to but I understand if you don't that's fine go to hugging face the uh the instructions",
    "start": "3433880",
    "end": "3440559"
  },
  {
    "text": "are all right there on how to use it in fact uh like I was saying I was actually playing with it so that that way I could optimize for an M1 Mac and so that the",
    "start": "3440559",
    "end": "3447559"
  },
  {
    "text": "answers could come back faster uh my only problem was that when I started testing it there was a obvious buck and",
    "start": "3447559",
    "end": "3453000"
  },
  {
    "text": "Pie torch okay so the because the basically when we told it to go ahead and use the M1 it was giving us back",
    "start": "3453000",
    "end": "3459559"
  },
  {
    "text": "garbage answers like it wasn't even like actual answers it's like it it was literally like like nonsensical",
    "start": "3459559",
    "end": "3465799"
  },
  {
    "text": "characters right and then F and when we use CPU mode it we perfectly fine so but then just as was about to create a new",
    "start": "3465799",
    "end": "3472599"
  },
  {
    "text": "issue on P torch they fixed it no that's a good thing I know I know but I also had the fix so oh you had the fix okay",
    "start": "3472599",
    "end": "3480400"
  },
  {
    "text": "that's a I get you you're about to have my time you're wasting my time D it but",
    "start": "3480400",
    "end": "3485440"
  },
  {
    "text": "no no that but it's fun but basically the idea is that that obviously okay I shouldn't say Obviously you probably",
    "start": "3485440",
    "end": "3491039"
  },
  {
    "text": "don't want to train within M1 but you can definitely do inerts with M1 sorry the Q&A so you got your data so how do",
    "start": "3491039",
    "end": "3496920"
  },
  {
    "text": "you collect that data and how do you format it so that Dolly can understand it I'm assuming you're saying so don't",
    "start": "3496920",
    "end": "3503599"
  },
  {
    "text": "use datab Brak data you could do the same thing like you did absolutely literally when when we asked people to fill out was a Google form okay that's",
    "start": "3503599",
    "end": "3510599"
  },
  {
    "text": "literally it and what were the questions oh no no they would could produce the questions and then the answers they",
    "start": "3510599",
    "end": "3516720"
  },
  {
    "text": "would ask a question and then provide a detailed answer for it I see how an",
    "start": "3516720",
    "end": "3522880"
  },
  {
    "text": "espresso how do you make to chose it wouldn't even be how do you make an espresso for example let's be very specific okay uh it would say what are",
    "start": "3522880",
    "end": "3530599"
  },
  {
    "text": "the what are the particular features of great espresso okay and then we would",
    "start": "3530599",
    "end": "3537599"
  },
  {
    "text": "talk about okay you are required to have a fine grind you required to uh using a",
    "start": "3537599",
    "end": "3543680"
  },
  {
    "text": "conical bur grinder uh there's a religious war between flat bir Grinders and conle bur Grinders I put in conical bur grinder so yeah I'm sure the flat",
    "start": "3543680",
    "end": "3550240"
  },
  {
    "text": "bur Grinders are pissed off that that that's not the answer that they're going to get from DOL that's bias you're putting bias into yes absolutely there's",
    "start": "3550240",
    "end": "3555599"
  },
  {
    "text": "absolutely 100% bias let's not pretend there isn't okay okay so it also requires you to actually have coffee",
    "start": "3555599",
    "end": "3561079"
  },
  {
    "text": "beans made roasted in a particular way it also requires you to have the espresso water boiled at a particular",
    "start": "3561079",
    "end": "3566960"
  },
  {
    "text": "temperature okay so you put all of those details down that's the idea like so",
    "start": "3566960",
    "end": "3572520"
  },
  {
    "text": "another words it's not just like okay hi how are you like what's great espresso uh you buy it from espresso vachi in",
    "start": "3572520",
    "end": "3578440"
  },
  {
    "text": "Seattle I mean while that's true and I'm basically I don't own any stock in them by the way but they are easily the best",
    "start": "3578440",
    "end": "3583920"
  },
  {
    "text": "coffee who's the brand against espresso Vace in seatt espresso V yeah David Sher is a is a magician when it comes to",
    "start": "3583920",
    "end": "3590520"
  },
  {
    "text": "Espresso but um but the context is like w as much as I want to just provide an answer like that the reality is no that",
    "start": "3590520",
    "end": "3596720"
  },
  {
    "text": "obviously we can't train that bad we actually need have verbosity to provide context provide proof if you want to put",
    "start": "3596720",
    "end": "3602799"
  },
  {
    "text": "it that way mhm because there's going to be other people putting other answers too oh so for example in this case I'm",
    "start": "3602799",
    "end": "3609720"
  },
  {
    "text": "just going to call a buddy mine Rob Reed he's a fellow cyclist he's also a fellow coffee addict I know he also put some uh",
    "start": "3609720",
    "end": "3616280"
  },
  {
    "text": "coffee answers aside there as well okay so between everybody that put coffee answers in there that's actually",
    "start": "3616280",
    "end": "3622520"
  },
  {
    "text": "literally you're coming getting data from myself from Rob and a few other folks from well data bricks right right",
    "start": "3622520",
    "end": "3628200"
  },
  {
    "text": "and how many instructions are in there that you guys put in the 5,000 employees uh 5,000 employees put 15,000 15,000 so",
    "start": "3628200",
    "end": "3636160"
  },
  {
    "text": "it's remark if you think about it that's remarkably small we were always under the impression when we started this",
    "start": "3636160",
    "end": "3641559"
  },
  {
    "text": "process that this we would require hundreds of thousands or like Millions how does it know you gave it coffee",
    "start": "3641559",
    "end": "3647480"
  },
  {
    "text": "instructions yeah yeah yeah no we were something like I said dolly 1.0 shocked us like it really shocked us because we",
    "start": "3647480",
    "end": "3654160"
  },
  {
    "text": "thought we would need to put in a lot more data we thought we would need to do a lot more training and then in the end we're like wow this is not bad I mean",
    "start": "3654160",
    "end": "3662160"
  },
  {
    "text": "it's not perfect but it's not bad actually and so from a business perspective what ends up happening is",
    "start": "3662160",
    "end": "3667559"
  },
  {
    "text": "like if you have your own business now your data like you don't need like a million things you've got 15,000 pieces",
    "start": "3667559",
    "end": "3674799"
  },
  {
    "text": "of information now the great thing and I'm not telling you to use Dolly by the way I mean obviously go use it if you want to but I'm saying use any open",
    "start": "3674799",
    "end": "3682000"
  },
  {
    "text": "source model I don't care which one that way you get to go ahead and keep it and have have your data as your IP so you as",
    "start": "3682000",
    "end": "3689720"
  },
  {
    "text": "a business end up like using the data actually in a good way right where you actually make it advantageous for you",
    "start": "3689720",
    "end": "3696400"
  },
  {
    "text": "yet also keeping the Privacy for the users that make up that data at the exact same time so the move is you have",
    "start": "3696400",
    "end": "3701440"
  },
  {
    "text": "these I don't know if this is technically what a foundational model is or you have these models that are large enough language models right right and",
    "start": "3701440",
    "end": "3708720"
  },
  {
    "text": "then each company or each org or each use case says okay now we're going to fine-tune it the right l or not it is",
    "start": "3708720",
    "end": "3716319"
  },
  {
    "text": "and apply it to us right and there going to be all sorts exactly there's all sorts of models out there there already",
    "start": "3716319",
    "end": "3723920"
  },
  {
    "text": "like a lot of people were asking me originally like hey okay well then that mean you need to use Dolly I'm like no",
    "start": "3723920",
    "end": "3729000"
  },
  {
    "text": "no no no dolly was just us proving that it can be done that's all it was so",
    "start": "3729000",
    "end": "3734960"
  },
  {
    "text": "there are a lot of really good companies whether it's hugging face or anybody else that produces solid open source",
    "start": "3734960",
    "end": "3740559"
  },
  {
    "text": "large language models use those too because the whole point is that you can use it yourself run it with smaller",
    "start": "3740559",
    "end": "3746720"
  },
  {
    "text": "amounts of data have really good answers and you're paying a hundred bucks at least in our case we did bucks to train",
    "start": "3746720",
    "end": "3752960"
  },
  {
    "text": "it right so we're like okay that's actually worth your business you're protecting the privacy of your users",
    "start": "3752960",
    "end": "3758400"
  },
  {
    "text": "you're going ahead and actually having relatively solid answers and you're not basically giving your data away to",
    "start": "3758400",
    "end": "3764839"
  },
  {
    "text": "another service because that's the key thing about when you use a service right that you're basically giving away your",
    "start": "3764839",
    "end": "3770240"
  },
  {
    "text": "data so they can go train against the two right right now I know Microsoft and open AI for example calling those two",
    "start": "3770240",
    "end": "3776480"
  },
  {
    "text": "out in a positive way not a negative usually I'm a former Microsoft employee so I'm allowed being negative if I want to but this is actually me being",
    "start": "3776480",
    "end": "3781640"
  },
  {
    "text": "positive um they actually have introduced concept saying you can pay more to train right uh and then they'll",
    "start": "3781640",
    "end": "3790319"
  },
  {
    "text": "never actually use your data but I don't remember the the cost but it is definitely paying more yeah yeah so well",
    "start": "3790319",
    "end": "3798119"
  },
  {
    "text": "it's not as valuable to them so it makes sense as a transaction exactly so then becomes more of a transaction that way exactly so have you seen the googlers",
    "start": "3798119",
    "end": "3805240"
  },
  {
    "text": "leaked memo about we have no moat cuz isn't this like everybody talks about that memo and what's interesting about",
    "start": "3805240",
    "end": "3811319"
  },
  {
    "text": "that whole concept is that I I know it sounds sideways but I was about to actually give you another context and",
    "start": "3811319",
    "end": "3816720"
  },
  {
    "text": "this is actually again M con over I want to give credit attribution to the guy who actually said it what's really",
    "start": "3816720",
    "end": "3821760"
  },
  {
    "text": "interesting about this whole thing when they talk about Mo or talk about everything else is that more more fundamentally we could have done this",
    "start": "3821760",
    "end": "3828680"
  },
  {
    "text": "two years ago we could have taken this concept of basically saying small amount of data",
    "start": "3828680",
    "end": "3835720"
  },
  {
    "text": "foundational model fine-tune it and actually have good results so all of us",
    "start": "3835720",
    "end": "3841520"
  },
  {
    "text": "were focusing on I need a bigger model I need to T bump more data I need to scrape the entire freaking internet and",
    "start": "3841520",
    "end": "3848760"
  },
  {
    "text": "Chuck it all into the getting model spend tens of millions of dollars warp every single GPU until Azure basically",
    "start": "3848760",
    "end": "3855200"
  },
  {
    "text": "melt in order to go ahead and train this thing till the heat death of the universe exactly and then meanwhile I was like or we literally could have",
    "start": "3855200",
    "end": "3861920"
  },
  {
    "text": "taken a foundational model that was okay to good a 100 bucks and Bam we get",
    "start": "3861920",
    "end": "3869599"
  },
  {
    "text": "something good yeah so when they talk about like the there's no moat and all this other stuff between open source and not literally my attitude toward this",
    "start": "3869599",
    "end": "3876359"
  },
  {
    "text": "whole thing is like no just step backwards for a second okay the realities we could have done this we all",
    "start": "3876359",
    "end": "3881880"
  },
  {
    "text": "got attracted to the idea the the shiny thing of ooh bigger more bigger more larger more that's all we got attracted",
    "start": "3881880",
    "end": "3888520"
  },
  {
    "text": "to and so in the end I'm going I don't care like",
    "start": "3888520",
    "end": "3895440"
  },
  {
    "text": "these companies the ones that quote unquote are trying to build them out around themselves what they're doing they're trying to make sure that they",
    "start": "3895440",
    "end": "3901279"
  },
  {
    "text": "have a service in which you will give them your data and then by definition",
    "start": "3901279",
    "end": "3907440"
  },
  {
    "text": "you will give away your competitive Advantage right simple's that for the folks that don't want to do that which I",
    "start": "3907440",
    "end": "3913799"
  },
  {
    "text": "think is the vast majority then my attitude is like quite simple then don't do that and build your",
    "start": "3913799",
    "end": "3919640"
  },
  {
    "text": "own model now how about if I'm the general consumer I just want to pump out",
    "start": "3919640",
    "end": "3925359"
  },
  {
    "text": "a good blog template for me to work with yeah absolutely why not yeah like seriously",
    "start": "3925359",
    "end": "3931279"
  },
  {
    "text": "I'm not I'm not trying to say these Services aren't worthwhile quite the opposite chat GB is fun very valuable oh",
    "start": "3931279",
    "end": "3936400"
  },
  {
    "text": "yeah it's extremely valuable in fact I've already had it pumping out code for me just for the just for just for shits",
    "start": "3936400",
    "end": "3941559"
  },
  {
    "text": "and giggles yeah so my rust is it's going to pump out some slides for you here soon for tomorrow that's a good idea I should test out that yeah yeah so",
    "start": "3941559",
    "end": "3948160"
  },
  {
    "text": "take that 30 minutes turn in the 12 oh yeah that'd be perfect yeah but see you get my drift like so I was yeah totally yeah so my rusty my my rust code is",
    "start": "3948160",
    "end": "3955200"
  },
  {
    "text": "Rusty uh and so basically I was he was using chat jbd to basically pump out a bunch of rust code for me I'm like hey",
    "start": "3955200",
    "end": "3961640"
  },
  {
    "text": "this is a good great bowler plate now I've got something to work with and boom now I can start writing again right yeah so what is data Brooks's play in this",
    "start": "3961640",
    "end": "3968599"
  },
  {
    "text": "chess game like what's your guys' angle our angle is quite simple you've got a ton of data you need to ETL it process",
    "start": "3968599",
    "end": "3976640"
  },
  {
    "text": "it in the first place then you need to have a platform to run machine learning or data science or AI or whatever",
    "start": "3976640",
    "end": "3984240"
  },
  {
    "text": "freaking wording you want to use okay whether it's llms today deep learning",
    "start": "3984240",
    "end": "3989720"
  },
  {
    "text": "yesterday or tomorrow uh image optical uh resolutions uh object recognition I",
    "start": "3989720",
    "end": "3997119"
  },
  {
    "text": "don't care okay the point is that you have a ton of data you need to be able to process it you need to be able to",
    "start": "3997119",
    "end": "4003559"
  },
  {
    "text": "access every single open- Source system or service data break play is quite simple",
    "start": "4003559",
    "end": "4009920"
  },
  {
    "text": "we just make it easy for you to do any of it yeah that's it that's all that's our only play let make it easy yeah yeah",
    "start": "4009920",
    "end": "4016440"
  },
  {
    "text": "are you for I guess then people owning their own data it seems that that that's your so so here here's the thing I'm",
    "start": "4016440",
    "end": "4023680"
  },
  {
    "text": "absolutely for both from a data bricks perspective but also from an open source perspective right so I I'm an opensource",
    "start": "4023680",
    "end": "4030119"
  },
  {
    "text": "contributor I contributed to Apache spark and ml flow and I'm also a maintainer for Delta Lake okay and so",
    "start": "4030119",
    "end": "4037160"
  },
  {
    "text": "yeah I I by definition I'm always going to lean toward open source which means you should own your data data should be",
    "start": "4037160",
    "end": "4043480"
  },
  {
    "text": "competitive Advantage everything else should be open source basically for all intents and purposes I'm even for things",
    "start": "4043480",
    "end": "4049279"
  },
  {
    "text": "like differential privacy and privacy preserving histograms to basically protect your data so and I can go on on",
    "start": "4049279",
    "end": "4055319"
  },
  {
    "text": "a diet tribe on that so let's not do that but the context is it's not I'm not saying though these services like open",
    "start": "4055319",
    "end": "4062400"
  },
  {
    "text": "AI or you know Bing or whatever else aren't worthwhile they are they're cheap they're helpful in fact training other",
    "start": "4062400",
    "end": "4069599"
  },
  {
    "text": "systems isn't necessarily a bad thing either it so for me it's not about don't do it it's about knowing what you're",
    "start": "4069599",
    "end": "4077039"
  },
  {
    "text": "doing right that's it yeah transparency exactly that's it that's that's my if",
    "start": "4077039",
    "end": "4082079"
  },
  {
    "text": "you want to use open AI uh within a DAT platform we make it easy we have a for",
    "start": "4082079",
    "end": "4087359"
  },
  {
    "text": "cry Alla we add a SQL syntax directly so you can literally write spark SQL which basically is a is at this point is",
    "start": "4087359",
    "end": "4093760"
  },
  {
    "text": "basically a anti- SQL compliance right you literally write SQL to go ahead and access your open AI to to run an nlm",
    "start": "4093760",
    "end": "4101278"
  },
  {
    "text": "model directly against your data so literally party hardy have fun so it's",
    "start": "4101279",
    "end": "4106359"
  },
  {
    "text": "not our our attitude isn't so much like don't use one versus the other our attitude is very much no no no just know",
    "start": "4106359",
    "end": "4112159"
  },
  {
    "text": "what you're doing understand when you're using something like a service understand when it makes sense for you",
    "start": "4112159",
    "end": "4118000"
  },
  {
    "text": "to build your own model and we also make it easy for you to build maintain train",
    "start": "4118000",
    "end": "4123318"
  },
  {
    "text": "infer against that model that's it so I mentioned we have our transcripts as open source right we got everything",
    "start": "4123319",
    "end": "4128920"
  },
  {
    "text": "we're saying here when it hits the podcast it's going to be transcribed into words how are ways we can use Dolly",
    "start": "4128920",
    "end": "4134960"
  },
  {
    "text": "2.0 this open model that you're talking about this this direction how can we leverage these transcripts for our",
    "start": "4134960",
    "end": "4141120"
  },
  {
    "text": "personal betterment as oh as a podcast company so for example as a podcast company one of the first things in fact",
    "start": "4141120",
    "end": "4146359"
  },
  {
    "text": "I'm actually already doing this technically for Delta Lake okay is that we do we also have podcast ourselves okay so what are we doing though uh I'm",
    "start": "4146359",
    "end": "4153440"
  },
  {
    "text": "spending time and effort to generate blogs based off of the podcasts why",
    "start": "4153440",
    "end": "4158960"
  },
  {
    "text": "because it's better for Google SEO search right it's not it's not like I'm trying to just repeat the same thing I'm",
    "start": "4158960",
    "end": "4164440"
  },
  {
    "text": "just trying to summarize because you know we we talked about barbecue in the beginning right we talked about coffee",
    "start": "4164440",
    "end": "4169719"
  },
  {
    "text": "we probably don't need all of those details inside the transcrip of the podcast for a Blog you want people to go",
    "start": "4169719",
    "end": "4175880"
  },
  {
    "text": "ahead and actually understand what they're talking about when it comes to Dolly cool we generate a Blog based off",
    "start": "4175880",
    "end": "4181679"
  },
  {
    "text": "of this conversation it can summarize it get to the key points boom there you go",
    "start": "4181679",
    "end": "4187480"
  },
  {
    "text": "it simplifies the whole process so that way you're not spending exorbitant hours trying to figure out how to basically",
    "start": "4187480",
    "end": "4195320"
  },
  {
    "text": "synthesize the key points out of our conversation right now right so it's",
    "start": "4195320",
    "end": "4200560"
  },
  {
    "text": "still time for you to review and look to make sure the model isn't giving you garbage it's still time for a producer",
    "start": "4200560",
    "end": "4207199"
  },
  {
    "text": "or for any other person who is knowledgeable in this field to validate the statements maybe I'm full of you",
    "start": "4207199",
    "end": "4212640"
  },
  {
    "text": "know BS of all I know right and then so you get next like oh yeah yeah I don't know Denny's full of it forget it it",
    "start": "4212640",
    "end": "4218679"
  },
  {
    "text": "most likely be the the conle versus flat bir grinder but again you know that's that's a whole other story sum just I'm",
    "start": "4218679",
    "end": "4224800"
  },
  {
    "text": "I'm on your team as me I'm conical team conical there you go perfect see so but",
    "start": "4224800",
    "end": "4230159"
  },
  {
    "text": "the context is like we can go ahead and actually use these systems to simplify would it be cheaper and easier if we",
    "start": "4230159",
    "end": "4235840"
  },
  {
    "text": "just went ahead and did like chat JB to do it yeah go for it could you would it be worthwhile to do it in your own Dolly",
    "start": "4235840",
    "end": "4243199"
  },
  {
    "text": "model absolutely because you have your own style right so if you have your own",
    "start": "4243199",
    "end": "4249000"
  },
  {
    "text": "style if it's building if dolly or any other open source model again I want to be very clear here who going ahead and",
    "start": "4249000",
    "end": "4255320"
  },
  {
    "text": "be trained against your transcripts it will then be able to start writing blogs",
    "start": "4255320",
    "end": "4260880"
  },
  {
    "text": "based off of your style right that's the cool thing about it is it cool to actually chain like that or is it better",
    "start": "4260880",
    "end": "4267480"
  },
  {
    "text": "to go with a foundational model and then just our stuff or it be cooler to be like well start with Dolly because it",
    "start": "4267480",
    "end": "4272880"
  },
  {
    "text": "has instructions and then add our style and then maybe add something else literally my answer is all of the above",
    "start": "4272880",
    "end": "4278159"
  },
  {
    "text": "because weever want we don't we don't know because that's the whole point different foundational models will",
    "start": "4278159",
    "end": "4283320"
  },
  {
    "text": "provide different at will be better at different things as simple as that some models will be better at for example",
    "start": "4283320",
    "end": "4289679"
  },
  {
    "text": "conversations some models will be better for writing purposes there's a like um I'm uh uh um uh Nat dodev uh I'm",
    "start": "4289679",
    "end": "4298320"
  },
  {
    "text": "forgetting the guy's name oh my God I don't believe I spaced out on that he's a nobody so yeah he's",
    "start": "4298320",
    "end": "4305159"
  },
  {
    "text": "he's a small guy yeah okay so n Freeman OB former CEO of GitHub okay so slightly important guy he nat. Dev is an awesome",
    "start": "4305159",
    "end": "4312719"
  },
  {
    "text": "playground for example where you can test out a lot of different models already and you're literally just",
    "start": "4312719",
    "end": "4318120"
  },
  {
    "text": "chucking like hey let me try with chat gbd3 let me try with vuna whatever else you and literally you will see with the",
    "start": "4318120",
    "end": "4325400"
  },
  {
    "text": "same question especially if we do the compare playground section different answers from the different models yeah",
    "start": "4325400",
    "end": "4331880"
  },
  {
    "text": "so yeah like literally you got to play a little bit to figure out which model makes sense for you yeah yeah",
    "start": "4331880",
    "end": "4337440"
  },
  {
    "text": "interesting love it well thanks for talking with us Denny glad to always aside from your opinions on coffee and",
    "start": "4337440",
    "end": "4345280"
  },
  {
    "text": "whatnot you're you're pretty good just all a dude yeah you know those are fighting words I",
    "start": "4345280",
    "end": "4350440"
  },
  {
    "text": "just want to say that okay those are fighting words Ah that's good all right",
    "start": "4350440",
    "end": "4355480"
  },
  {
    "text": "gentlemen thank you very much yes thank you all [Music]",
    "start": "4355480",
    "end": "4369310"
  },
  {
    "text": "right hey friends this episode is brought to you by by ciq the founding",
    "start": "4369679",
    "end": "4375159"
  },
  {
    "text": "sponsor and partner of Rocky Linux Enterprise Linux the open source Community way and I'm here with Gregor",
    "start": "4375159",
    "end": "4381000"
  },
  {
    "text": "kurer the founder and CEO of ciq and the creator of Rocky Linux so Greg I know",
    "start": "4381000",
    "end": "4388239"
  },
  {
    "text": "that a lot of people are still sort of catching up to some degree with what went down with sentos the red hat",
    "start": "4388239",
    "end": "4395760"
  },
  {
    "text": "acquisition and just the massive shift that required everyone using sentos to do give me a can you give me a glimpse",
    "start": "4395760",
    "end": "4402679"
  },
  {
    "text": "into what happened there we've seen a number of cases in the open source Community where projects were pivoted",
    "start": "4402679",
    "end": "4408480"
  },
  {
    "text": "due to business agenda or commercial needs we saw that happen with sentos sentos was one of the primary one of the",
    "start": "4408480",
    "end": "4415600"
  },
  {
    "text": "biggest Enterprise operating systems ever people were using it all over the",
    "start": "4415600",
    "end": "4420920"
  },
  {
    "text": "place Enterprise organizations and professional it teams were all leveraging sentos for Centos to be",
    "start": "4420920",
    "end": "4428199"
  },
  {
    "text": "stripped away from the community and removed as a suitable option to meet their needs created a massive pain point",
    "start": "4428199",
    "end": "4435560"
  },
  {
    "text": "and a gap within the industry as one of the founders of sentos I really took this to heart and I wanted to ensure",
    "start": "4435560",
    "end": "4442280"
  },
  {
    "text": "that this does not happen again and that is what we created with Rocky Linux and",
    "start": "4442280",
    "end": "4448320"
  },
  {
    "text": "the resf okay you mentioned the RF what is that and what is its relationship to",
    "start": "4448320",
    "end": "4454520"
  },
  {
    "text": "Rocky Linux the the rsf is the rocky enterprise software foundation and it is",
    "start": "4454520",
    "end": "4460719"
  },
  {
    "text": "a organization that we created to hold ourselves responsible to what it is that",
    "start": "4460719",
    "end": "4467400"
  },
  {
    "text": "we've promised that we're going to do with the community it is community run it is community-led we have a board of",
    "start": "4467400",
    "end": "4474239"
  },
  {
    "text": "directors which uh is comprised of a number of people that have a huge amount of experience both with Linux as well as",
    "start": "4474239",
    "end": "4481080"
  },
  {
    "text": "open source and community and from this organization we solidify the governance",
    "start": "4481080",
    "end": "4487040"
  },
  {
    "text": "of how we are to manage Rocky Linux and any other projects that come and join in",
    "start": "4487040",
    "end": "4492560"
  },
  {
    "text": "this vision sounds good Greg I love it so Enterprise Linux the open source way",
    "start": "4492560",
    "end": "4497880"
  },
  {
    "text": "the Community Way has a home at Rocky Linux in the rsf check it out and learn",
    "start": "4497880",
    "end": "4504120"
  },
  {
    "text": "more at Rocky linux.org changelog again Rocky linux.org SL change",
    "start": "4504120",
    "end": "4512480"
  },
  {
    "text": "log [Music]",
    "start": "4522199",
    "end": "4529639"
  },
  {
    "text": "all right Stella Beerman yeah and you're with I'm going to also butcher the name of the org elther AI elther El Luther AI",
    "start": "4529639",
    "end": "4538159"
  },
  {
    "text": "yes okay what is this what is a Luther AI y we're just talking uh with datab bricks about Dolly this is right yes",
    "start": "4538159",
    "end": "4544800"
  },
  {
    "text": "correct right so uh that was built on top of a open source language model okay",
    "start": "4544800",
    "end": "4551040"
  },
  {
    "text": "yes I trained that okay so you're underneath Dolly yes okay so you",
    "start": "4551040",
    "end": "4557360"
  },
  {
    "text": "personally trained it yes okay what's what's the model uh it's called Pia P um",
    "start": "4557360",
    "end": "4563400"
  },
  {
    "text": "it's a it's a suite of language models actually that we put out a couple months",
    "start": "4563400",
    "end": "4568440"
  },
  {
    "text": "ago okay um but in general Luther ey has trained several of the largest open source language models in the world in",
    "start": "4568440",
    "end": "4574199"
  },
  {
    "text": "the past three years okay there nice so what do you want to tell the world then",
    "start": "4574199",
    "end": "4579560"
  },
  {
    "text": "what do I want to tell the world um honestly didn't think that in advance",
    "start": "4579560",
    "end": "4585000"
  },
  {
    "text": "okay all right well World know what should the world know about what you do in terms of training models that that",
    "start": "4585000",
    "end": "4591800"
  },
  {
    "text": "brex uses it's open source Etc honestly especially like the open source World should really know that the the AI world",
    "start": "4591800",
    "end": "4599239"
  },
  {
    "text": "really needs help from the open source Community r large uh that's actually broadly speaking why I'm here at the",
    "start": "4599239",
    "end": "4605560"
  },
  {
    "text": "Linux open source Summit okay uh you know we're we're struggling with a lot of issues about maintainability issues",
    "start": "4605560",
    "end": "4613280"
  },
  {
    "text": "about licensing issues about regulation um issues about building sustainable",
    "start": "4613280",
    "end": "4619560"
  },
  {
    "text": "ecosystems that the open source Community r large has been doing working on for for years if not decades yeah and",
    "start": "4619560",
    "end": "4627159"
  },
  {
    "text": "a lot of people in the AI world are a little too proud to ask for help from uh non- aai people uh which is definitely a a real",
    "start": "4627159",
    "end": "4634480"
  },
  {
    "text": "systemic problem but there's I think a lot of if people are excited about",
    "start": "4634480",
    "end": "4640960"
  },
  {
    "text": "Foundation models large language models what you want to call them um and want to get involved and don't know or want",
    "start": "4640960",
    "end": "4647000"
  },
  {
    "text": "to help and don't know that much about AI there's a ton of Open Source work",
    "start": "4647000",
    "end": "4652800"
  },
  {
    "text": "that that needs to be done that we need help with um to build a a robust and",
    "start": "4652800",
    "end": "4658280"
  },
  {
    "text": "enduring Eco system where is the money coming from where's the money coming from great question so at alther AI we",
    "start": "4658280",
    "end": "4666719"
  },
  {
    "text": "re we recently formed a nonprofit um and we have donations from",
    "start": "4666719",
    "end": "4671920"
  },
  {
    "text": "a number of companies most most prominently uh Google stability Ai and",
    "start": "4671920",
    "end": "4678080"
  },
  {
    "text": "and hugging face okay um and cor weave are among our biggest sponsors we have",
    "start": "4678080",
    "end": "4683880"
  },
  {
    "text": "also been applying for Grants uh from Mostly the US government to pay for our",
    "start": "4683880",
    "end": "4690040"
  },
  {
    "text": "uh I guess forthcoming research and work in terms of like Computing resources it's actually like training these really",
    "start": "4690040",
    "end": "4697080"
  },
  {
    "text": "large language models is not that expensive which is like is that a secret",
    "start": "4697080",
    "end": "4703040"
  },
  {
    "text": "I don't I don't know I don't know if it's a secret or or what but like I",
    "start": "4703040",
    "end": "4708080"
  },
  {
    "text": "think that the Cs World kind of got used to the idea that anything can be done on",
    "start": "4708080",
    "end": "4714960"
  },
  {
    "text": "like a personal laptop and that that's kind of what constitutes a reasonable",
    "start": "4714960",
    "end": "4720480"
  },
  {
    "text": "amount of money to spend on a paper and like that's great there that's there's a huge accessibility Bo for doing that but",
    "start": "4720480",
    "end": "4726600"
  },
  {
    "text": "training these large language models it is pricey um you know it's it's not something that anyone can do on their on",
    "start": "4726600",
    "end": "4732360"
  },
  {
    "text": "their own but it's not ruinously expensive there are thousands of companies in around the",
    "start": "4732360",
    "end": "4740000"
  },
  {
    "text": "world that can afford to this there are dozens of universities that can afford to this and by and large they just",
    "start": "4740000",
    "end": "4745080"
  },
  {
    "text": "haven't been okay um so a model that you trained yeah how much did that cost uh",
    "start": "4745080",
    "end": "4752199"
  },
  {
    "text": "so we train so it's part of a suite of models that had like 28 in it total uh",
    "start": "4752199",
    "end": "4759080"
  },
  {
    "text": "but altogether that was like less than $800,000 the large just model one training run would probably be like",
    "start": "4759080",
    "end": "4767239"
  },
  {
    "text": "$200,000 not bad which which that's more than a laptop which is more than a laptop it's it's not like a mindboggling",
    "start": "4767239",
    "end": "4773800"
  },
  {
    "text": "amount of money and it's less than a Super Bowl commercial it's true yeah so right now the largest open source well",
    "start": "4773800",
    "end": "4783159"
  },
  {
    "text": "okay the second largest open source English language model in the world is called GTB neox uh we trained that I",
    "start": "4783159",
    "end": "4788800"
  },
  {
    "text": "trained that my organization and that cost us about",
    "start": "4788800",
    "end": "4795000"
  },
  {
    "text": "$350,000 or would have if if we weren't given the compute for free but like $350,000 for the second largest open",
    "start": "4795000",
    "end": "4801800"
  },
  {
    "text": "source language model in the world and at the time we released it it was the largest uh later someone else trained a",
    "start": "4801800",
    "end": "4806840"
  },
  {
    "text": "a bigger model with sponsorship from the Russian government but it's for there",
    "start": "4806840",
    "end": "4813040"
  },
  {
    "text": "there's so GTB 3 came out in 2020 and for about 2 years almost nobody was",
    "start": "4813040",
    "end": "4821360"
  },
  {
    "text": "training in open sourcing langage model um Google was doing it with similar",
    "start": "4821360",
    "end": "4826840"
  },
  {
    "text": "models but not like the same kinds of models that GT3 is um and we were doing it it it was really not that expensive",
    "start": "4826840",
    "end": "4833639"
  },
  {
    "text": "uh we we got into it on compute that we got for free through a Google research",
    "start": "4833639",
    "end": "4839480"
  },
  {
    "text": "Computing program called the tensorflow research cloud and you know with that we trained a 6 billion perimeter language",
    "start": "4839480",
    "end": "4846600"
  },
  {
    "text": "model the one that underpins the the the first version of Dolly that uh that he was talking about that's been that's",
    "start": "4846600",
    "end": "4852800"
  },
  {
    "text": "been extremely widely used deployed in a whole bunch of different industry and and research contexts and and been",
    "start": "4852800",
    "end": "4858320"
  },
  {
    "text": "hugely successful and it was literally just like Google gave us for free yeah it ran preemptively on their research CL",
    "start": "4858320",
    "end": "4865280"
  },
  {
    "text": "basically the idea of TRC is that they have a research cluster that they don't always use all of and so other",
    "start": "4865280",
    "end": "4872480"
  },
  {
    "text": "researchers um independent researchers academics nonprofits can apply to be able to run preempt preemptable jobs on",
    "start": "4872480",
    "end": "4879600"
  },
  {
    "text": "their research cluster and just use the compute that they're not using at the time and using that we trained this model in",
    "start": "4879600",
    "end": "4885400"
  },
  {
    "text": "like two and a half months wow and it was a really big deal when it came out",
    "start": "4885400",
    "end": "4890440"
  },
  {
    "text": "it was the largest model of its of its type in the world by a sizable margin it was about three times the size of the",
    "start": "4890440",
    "end": "4897120"
  },
  {
    "text": "four four times the size of the largest open source model of its type in the world yeah and the the Pia models we",
    "start": "4897120",
    "end": "4906120"
  },
  {
    "text": "trained on like 12 a100 gpus for a couple weeks which is certainly a lot of",
    "start": "4906120",
    "end": "4911920"
  },
  {
    "text": "computing resources but it's not like mindboggling amounts of compute there are lots and lots and lots of companies that have that that",
    "start": "4911920",
    "end": "4918360"
  },
  {
    "text": "could you know it's it's less about it actually being too expensive and more",
    "start": "4918360",
    "end": "4923400"
  },
  {
    "text": "about kind of having the political will to actually go do it yeah are you focused on training open source models",
    "start": "4923400",
    "end": "4929719"
  },
  {
    "text": "is that your focus so our focus is on open source AI research in general um",
    "start": "4929719",
    "end": "4935520"
  },
  {
    "text": "our kind of area of expertise is large scale Ai and most of what we do is language models but we've also worked on",
    "start": "4935520",
    "end": "4941960"
  },
  {
    "text": "training and in releasing uh other kinds of large scale AI models so we are part of the open fold project uh so deep mind",
    "start": "4941960",
    "end": "4950120"
  },
  {
    "text": "created a uh algorithm for for modeling protein interactions uh called Alpha",
    "start": "4950120",
    "end": "4956000"
  },
  {
    "text": "fold that was a a really big deal and we helped some academics scale up their",
    "start": "4956000",
    "end": "4961120"
  },
  {
    "text": "research and and get that and replicate that and release it open source um we've done some stuff in the text image space",
    "start": "4961120",
    "end": "4967560"
  },
  {
    "text": "both on our own and some of our staff have uh have kind of gone on and worked at stability on on some of their",
    "start": "4967560",
    "end": "4973600"
  },
  {
    "text": "language uh sorry image models and we are a big proponent of Open Source research in general so our",
    "start": "4973600",
    "end": "4980840"
  },
  {
    "text": "kind of the reason we decided to start training these large language models was back in the summer of like 2020 we",
    "start": "4980840",
    "end": "4987960"
  },
  {
    "text": "thought you know this GTB 3 thing is going to be a major player in the future",
    "start": "4987960",
    "end": "4993440"
  },
  {
    "text": "of AI and it's going to be really essential if you want to be if you want to be doing something",
    "start": "4993440",
    "end": "5000080"
  },
  {
    "text": "meaningful in AI you you probably want to know how these things work you want to be able to experiment with them we",
    "start": "5000080",
    "end": "5005280"
  },
  {
    "text": "want to have access to them and back then you couldn't even pay open AI to let you use the model yeah they announced that they had it and that was",
    "start": "5005280",
    "end": "5011440"
  },
  {
    "text": "it and so we said well what the hell let's try to train a model like that we'll we'll learn something along the",
    "start": "5011440",
    "end": "5016639"
  },
  {
    "text": "way and so we started building like an open source infrastructure for training large language models we created a data",
    "start": "5016639",
    "end": "5023600"
  },
  {
    "text": "set called the pile um which is now kind of the deao standard for training large language models we created a uh",
    "start": "5023600",
    "end": "5031400"
  },
  {
    "text": "evaluation Suite for uh consistently evaluating language models because everyone runs their",
    "start": "5031400",
    "end": "5037400"
  },
  {
    "text": "evaluations a little differently and there's huge reproducibility issues um so we built a framework that we could",
    "start": "5037400",
    "end": "5043159"
  },
  {
    "text": "release some in source and and run on our own models run on other people's models and actually have kind of",
    "start": "5043159",
    "end": "5048480"
  },
  {
    "text": "meaningful Apples to Apples comparisons and we started training large language models we trained a 2.7 billion",
    "start": "5048480",
    "end": "5053800"
  },
  {
    "text": "parameter model which is like a little bit bigger than uh gtv2 was at the time",
    "start": "5053800",
    "end": "5059159"
  },
  {
    "text": "and then we started training larger models 6 billion parameters um was the largest open source GT3 style language",
    "start": "5059159",
    "end": "5065400"
  },
  {
    "text": "model in the world 20 billion parameters was the largest language model of of any",
    "start": "5065400",
    "end": "5070520"
  },
  {
    "text": "sort uh to be a Rel open source in the world you know since then there's been a lot more investment and willingness to",
    "start": "5070520",
    "end": "5078480"
  },
  {
    "text": "train and release models there's several companies that are now doing it so Mosaic is a company that released a n i",
    "start": "5078480",
    "end": "5086199"
  },
  {
    "text": "want to say something a large language model uh that's that seems really excellent uh like last week",
    "start": "5086199",
    "end": "5093159"
  },
  {
    "text": "there is meta which has been training and and releasing sort of models um they'll tell you that they're open",
    "start": "5093159",
    "end": "5099239"
  },
  {
    "text": "source releasing models but that's just not actually correct um they're under non-commercial licenses and they're",
    "start": "5099239",
    "end": "5105960"
  },
  {
    "text": "they're not open source despite their rhetoric to the contrary but uh there's there's a whole bunch of companies",
    "start": "5105960",
    "end": "5111440"
  },
  {
    "text": "stability AI is training L language model so now there's a lot more people in the space in doing it and releasing",
    "start": "5111440",
    "end": "5117119"
  },
  {
    "text": "it and honestly from my point of view like we got into training large language models mostly because we wanted to study them we wanted to enable people to do",
    "start": "5117119",
    "end": "5124239"
  },
  {
    "text": "essential research on interpretability ethics alignment understanding how these models work why these models work and",
    "start": "5124239",
    "end": "5130040"
  },
  {
    "text": "what they're doing so that we can design better models and so that we can know what appropriate and inappropriate",
    "start": "5130040",
    "end": "5136639"
  },
  {
    "text": "deployment contexts for them are and so now that there's a lot more people working in kind of this open source uh",
    "start": "5136639",
    "end": "5142719"
  },
  {
    "text": "training space we're moving more towards uh you know doing that kind of scientific research that we've always",
    "start": "5142719",
    "end": "5148040"
  },
  {
    "text": "wanted to do so in the past 6 months we've been doing a lot of work in uh",
    "start": "5148040",
    "end": "5154080"
  },
  {
    "text": "interpreting language models and kind of understanding why they behave the way they do um my personal kind of area",
    "start": "5154080",
    "end": "5160239"
  },
  {
    "text": "focus is tracing the behavior of language models back to their actual training data so the models that uh the",
    "start": "5160239",
    "end": "5166920"
  },
  {
    "text": "do2 was trained on uh the Pia Suite what kind of makes that special is that most",
    "start": "5166920",
    "end": "5172280"
  },
  {
    "text": "language model Suites are very ad hoc constructed I I'm calling them Suites",
    "start": "5172280",
    "end": "5177760"
  },
  {
    "text": "because you have several models that are similar of different sizes right um so like the op Suite by meta for example",
    "start": "5177760",
    "end": "5183560"
  },
  {
    "text": "ranges from 125 million parameters to 175 billion parameters uh but they're",
    "start": "5183560",
    "end": "5189719"
  },
  {
    "text": "they're not actually very consistent between them uh some of them even have different architectures they have different data order they there's a lot",
    "start": "5189719",
    "end": "5196679"
  },
  {
    "text": "of of stuff that kind of limits your ability to understand to do controlled",
    "start": "5196679",
    "end": "5202040"
  },
  {
    "text": "experiments on these models and so we sat down and we said if we wanted to design from the ground up a suite of",
    "start": "5202040",
    "end": "5207480"
  },
  {
    "text": "large language models that was designed to enable scientific research what would it look like what kind kinds of",
    "start": "5207480",
    "end": "5212639"
  },
  {
    "text": "properties would it have what kinds of experiments do we think people are going to want to do that we're going to need to enable and we we built this list of",
    "start": "5212639",
    "end": "5219040"
  },
  {
    "text": "requirements and then created a a model Suite that satisfies that so it was trained on entirely publicly available",
    "start": "5219040",
    "end": "5225239"
  },
  {
    "text": "data um all of the training it was trained on the same data every model in the Su was trained on the same data in the same order and we have a whole lot",
    "start": "5225239",
    "end": "5232199"
  },
  {
    "text": "of intermediate checkpoints that are safe so if you want to know um you know after 10 billion tokens how each model",
    "start": "5232199",
    "end": "5238360"
  },
  {
    "text": "in the suite is performing you can go and grab those checkpoints after 10 billion tokens and then you can say okay",
    "start": "5238360",
    "end": "5244159"
  },
  {
    "text": "what's the next data point it saw during training after 10 billion tokens what was the 10 10 billion first token and you can actually use some some stuff",
    "start": "5244159",
    "end": "5251600"
  },
  {
    "text": "we've uploaded to the internet to to actually load that data in in the same order it's seen by the models you can study kind of how being exposed to",
    "start": "5251600",
    "end": "5258159"
  },
  {
    "text": "particular training data influences Model Behavior Uh so we've been using this to right now primarily to study",
    "start": "5258159",
    "end": "5264280"
  },
  {
    "text": "memorization understanding cuz language models have aity for reproducing long",
    "start": "5264280",
    "end": "5269719"
  },
  {
    "text": "exact sequences from their training corpa and we're interested in understanding what causes memorization why certain",
    "start": "5269719",
    "end": "5276800"
  },
  {
    "text": "strings get memorized and others don't right now I'm I'm wrapping up our kind of first paper on that we have some more",
    "start": "5276800",
    "end": "5282719"
  },
  {
    "text": "research in the works trying to understand you know looking at the the actual models throughout the course of",
    "start": "5282719",
    "end": "5288119"
  },
  {
    "text": "training and looking at kind of the training data points that they see and trying to reverse engineer what that actual interaction between the model and",
    "start": "5288119",
    "end": "5294920"
  },
  {
    "text": "the and the data is and yeah this is something I'm I'm personally really high on most interpretability research right",
    "start": "5294920",
    "end": "5300960"
  },
  {
    "text": "now is kind of focused on Final trained models as like pre-existing artifacts so",
    "start": "5300960",
    "end": "5306360"
  },
  {
    "text": "you have this this trained model and you want to understand what behaviors it has um but you know my perspective as",
    "start": "5306360",
    "end": "5312840"
  },
  {
    "text": "someone who trains these models is much more focused on kind of where they come from and what especially like my",
    "start": "5312840",
    "end": "5320000"
  },
  {
    "text": "overarching goal is to kind of you know if I as a person who trains a large language model have a particular desire",
    "start": "5320000",
    "end": "5325719"
  },
  {
    "text": "for a property the model has a property the model doesn't have what decisions can I make to actually influence that",
    "start": "5325719",
    "end": "5331199"
  },
  {
    "text": "and to make the model have the properties I want it to have so if there's data I don't want it to memorize is there a way that I can know ahead of",
    "start": "5331199",
    "end": "5337320"
  },
  {
    "text": "time what's going to be memorized that's the the paper that we have that we actually just released on on archive",
    "start": "5337320",
    "end": "5342440"
  },
  {
    "text": "about forecasting what is going to be memorized before you actually train the model is that to make it less Black Box more like you deploy it and you don't",
    "start": "5342440",
    "end": "5348600"
  },
  {
    "text": "know what it can do so that you can sort of understand okay here's the data here's how it's trained to sort of have",
    "start": "5348600",
    "end": "5354119"
  },
  {
    "text": "a a more clarity of what the box actually contains versus this black box of is that why that's that is what the",
    "start": "5354119",
    "end": "5359760"
  },
  {
    "text": "the field of interpretability is about in general and I would say kind of building on that that what what my research is about in particular is not",
    "start": "5359760",
    "end": "5367800"
  },
  {
    "text": "not just opening up that black box and looking inside and understanding what the model is actually doing but understanding where it came from and how",
    "start": "5367800",
    "end": "5374719"
  },
  {
    "text": "how we can build boxes that are are are more transparent from the ground up predictable maybe even yeah yeah cuz I",
    "start": "5374719",
    "end": "5380800"
  },
  {
    "text": "mean that's one of the fears is is uh you know especially with like Bing uh",
    "start": "5380800",
    "end": "5385840"
  },
  {
    "text": "when they put that out there I think what it threatened the person like there was a like there was some sort of like threat on Humanity essentially and it's",
    "start": "5385840",
    "end": "5392480"
  },
  {
    "text": "like you deploy this thing out into the world and you don't understand what it actually do is that to be more",
    "start": "5392480",
    "end": "5397679"
  },
  {
    "text": "predictable more absolutely controll degre sorry and even designable like say",
    "start": "5397679",
    "end": "5403800"
  },
  {
    "text": "well forget these things remember these things yeah that uh the designability is a really big component I think that's",
    "start": "5403800",
    "end": "5409840"
  },
  {
    "text": "going to become huge in the future and really it hasn't been studied primarily cuz people haven't had the tools very",
    "start": "5409840",
    "end": "5415880"
  },
  {
    "text": "few model Suites have intermediate checkpoints at all um a lot of publicly released models weren't trained on",
    "start": "5415880",
    "end": "5422000"
  },
  {
    "text": "publicly released data sets or if they were trained on publicly released data sets they didn't tell you what order it",
    "start": "5422000",
    "end": "5427880"
  },
  {
    "text": "was trained on and it turns out that matters a lot um what saw early in training what saw late in training and",
    "start": "5427880",
    "end": "5433440"
  },
  {
    "text": "so there there's really a a huge reproducibility issue in terms of under like if you want to dig in and really",
    "start": "5433440",
    "end": "5439840"
  },
  {
    "text": "understand how data by data data point by data point the model is learning to",
    "start": "5439840",
    "end": "5445360"
  },
  {
    "text": "behave you need to be able to basically fully reproduce the training not actually because you're not going to spend a couple hundred thousand dolls",
    "start": "5445360",
    "end": "5452239"
  },
  {
    "text": "but at least in principle you need to be able to inspect individual data points know when it's going to get loaded understand kind of how it works and this",
    "start": "5452239",
    "end": "5458040"
  },
  {
    "text": "is something that we've put a huge amount of of of resources into both on the training side as well as kind of on",
    "start": "5458040",
    "end": "5463199"
  },
  {
    "text": "the engineering side it was not easy but you can actually reproduce our model",
    "start": "5463199",
    "end": "5468520"
  },
  {
    "text": "training exactly so if you take the the codebase that we used to train this Mo these pythia models and you pick a",
    "start": "5468520",
    "end": "5475560"
  },
  {
    "text": "checkpoint and you load that checkpoint and you resume training from that checkpoint you will end up with the same",
    "start": "5475560",
    "end": "5480800"
  },
  {
    "text": "fully trained model that we did exactly that's important that is really important it's important",
    "start": "5480800",
    "end": "5486360"
  },
  {
    "text": "because if you want to understand how to design models you need to understand how they're changing over the course of",
    "start": "5486360",
    "end": "5491800"
  },
  {
    "text": "training and that is is really picity and really sensitive to a lot of of",
    "start": "5491800",
    "end": "5497080"
  },
  {
    "text": "implementation specific details that tend to not get released how far in the future do you think since you're at the",
    "start": "5497080",
    "end": "5503239"
  },
  {
    "text": "training level you're like the the ground level of if this is the Eureka moment for Humanity yeah right how far",
    "start": "5503239",
    "end": "5510119"
  },
  {
    "text": "in the future do you think and and do you have fear trepidation hope like where will this take us as Humanity I",
    "start": "5510119",
    "end": "5517800"
  },
  {
    "text": "really don't know um my kind of attitude is that the recent par like there was a",
    "start": "5517800",
    "end": "5523400"
  },
  {
    "text": "really big paradigm shift in 2020 with the release of GTB 3 um and the",
    "start": "5523400",
    "end": "5528520"
  },
  {
    "text": "aggressive focus on scaling and people really changed their attitudes towards like how to design language models and",
    "start": "5528520",
    "end": "5535239"
  },
  {
    "text": "kind of how they can be used and what they can be used for in a sense we got really lucky because it wasn't that dangerous you know there there were a",
    "start": "5535239",
    "end": "5540840"
  },
  {
    "text": "lot of fears about what GT3 could do um and and by and large it turned out to be",
    "start": "5540840",
    "end": "5546560"
  },
  {
    "text": "pretty safe there wasn't all that much harm done and a lot of the fears turned out to be not come to fruition and you",
    "start": "5546560",
    "end": "5552840"
  },
  {
    "text": "know kind of looking forward I think the really important thing to think about is we we obviously can't predict the next",
    "start": "5552840",
    "end": "5558760"
  },
  {
    "text": "paradigm shift but building tools that allow us to hopefully more readily adopt",
    "start": "5558760",
    "end": "5564800"
  },
  {
    "text": "and adapt and respond to Future Paradigm shifts in in large scale AI so that you",
    "start": "5564800",
    "end": "5570400"
  },
  {
    "text": "know one day they're probably will be something that gets develop that is dangerous and we want to be able to be I",
    "start": "5570400",
    "end": "5576239"
  },
  {
    "text": "guess ready for that yeah yeah cool well what are some touch points people who are interested in what you're up to want",
    "start": "5576239",
    "end": "5582800"
  },
  {
    "text": "to help out want to give money want to read more where can people connect with you so the best place to connect with us",
    "start": "5582800",
    "end": "5589360"
  },
  {
    "text": "is our Discord server um we are a research institute but we actually operate basically entirely in in the",
    "start": "5589360",
    "end": "5596080"
  },
  {
    "text": "public view uh we're distributed all over the world and we do our research in",
    "start": "5596080",
    "end": "5601960"
  },
  {
    "text": "a public Discord and anyone can join anyone can drop in read about what we're getting up to hang out with us chat with",
    "start": "5601960",
    "end": "5607480"
  },
  {
    "text": "us about about AI so our Discord server is discord. g/ alther aai um there's",
    "start": "5607480",
    "end": "5613520"
  },
  {
    "text": "also a link on our website which is Al luther. Shing um we'll L it up the show notes",
    "start": "5613520",
    "end": "5619239"
  },
  {
    "text": "for sure yeah yeah and yeah we're we're always happy to take on more volunteers",
    "start": "5619239",
    "end": "5624800"
  },
  {
    "text": "um we have a small professional staff um and a large number of volunteers that help out as well how small small uh like",
    "start": "5624800",
    "end": "5631760"
  },
  {
    "text": "10 full-time M plays okay and if they go to the Discord server what can they do there what can they expect from the",
    "start": "5631760",
    "end": "5636880"
  },
  {
    "text": "Discord server like you're there others are there yeah so you can chat about AI",
    "start": "5636880",
    "end": "5642119"
  },
  {
    "text": "uh we have a bunch of discussion channels where people talk about kind of Cutting Edge Trends in artificial intelligence honestly like I don't",
    "start": "5642119",
    "end": "5648639"
  },
  {
    "text": "really follow AI publication news anymore cuz I just follow my Discord server and everything that's important",
    "start": "5648639",
    "end": "5654480"
  },
  {
    "text": "shows up for me there you go which is a really nice place to be but you can you can talk with us you can talk with other researchers we have a large amount of",
    "start": "5654480",
    "end": "5661600"
  },
  {
    "text": "researchers at The Cutting Edge of AI I can't count the number of times that someone's posted a paper and been like hey this is really cool like does anyone",
    "start": "5661600",
    "end": "5668159"
  },
  {
    "text": "know anything about this and someone just like tags the guy who wrote the paper that happens all the time we have people from open AI anthropic meta like",
    "start": "5668159",
    "end": "5675760"
  },
  {
    "text": "all the major Labs who come deep mind come and and chat about language models give advice uh give you know",
    "start": "5675760",
    "end": "5682000"
  },
  {
    "text": "perspectives on on research and talk about kind of how things are going uh you can also get involved with ongoing",
    "start": "5682000",
    "end": "5688440"
  },
  {
    "text": "research projects so we have a dozen is on goinging research projects ranging from learning to train figuring out how",
    "start": "5688440",
    "end": "5695000"
  },
  {
    "text": "to train better language models to training language models in other languages so if you look at like the",
    "start": "5695000",
    "end": "5700560"
  },
  {
    "text": "list of the 100 largest language models in the world basically all of them are English or Chinese yeah and you know so",
    "start": "5700560",
    "end": "5707760"
  },
  {
    "text": "if if you want to spread the benefits of this technology and the ability to kind of use and and understand this",
    "start": "5707760",
    "end": "5713760"
  },
  {
    "text": "technology to the world large like not everyone speaks English and Chinese and even the people who do often also speak",
    "start": "5713760",
    "end": "5720440"
  },
  {
    "text": "other languages that they care about so we're training um we've trained and relas several uh Korean language models",
    "start": "5720440",
    "end": "5727639"
  },
  {
    "text": "um we're currently training uh with the plan of releasing some indic language models uh as well as some uh romance",
    "start": "5727639",
    "end": "5735080"
  },
  {
    "text": "language models so yeah on the developing new model side we do research like that um on the interpretability",
    "start": "5735080",
    "end": "5740880"
  },
  {
    "text": "side we do a lot of a lot of different stuff understanding training dyamics understanding how to evaluate language",
    "start": "5740880",
    "end": "5746360"
  },
  {
    "text": "models understanding how to kind of extract the best information from them we recently started up some work on kind",
    "start": "5746360",
    "end": "5752320"
  },
  {
    "text": "of red teaming them and trying to understand you know there's a lot of stuff out there right now about promp tacking about how people are trying to",
    "start": "5752320",
    "end": "5758400"
  },
  {
    "text": "put filters on language models and they're kind of not really very successful and trying to understand like",
    "start": "5758400",
    "end": "5763480"
  },
  {
    "text": "what the Dynamics of that is like whether you can uh build meaningful safeguards around these things or",
    "start": "5763480",
    "end": "5769119"
  },
  {
    "text": "whether it's always going to be subverted we do a lot of work like that as well very cool well thanks for coming",
    "start": "5769119",
    "end": "5774639"
  },
  {
    "text": "on the show Stella yeah much pleasure it was awesome having this deep dive with you I love that thank you great to meet",
    "start": "5774639",
    "end": "5780520"
  },
  {
    "text": "you guys yeah so if you'd have told me a few years ago that I'd be going to an",
    "start": "5780520",
    "end": "5787400"
  },
  {
    "text": "open-source Summit and talking about AI in open source at this level from Cody a",
    "start": "5787400",
    "end": "5796119"
  },
  {
    "text": "coding assistant to data bricks and training models on small data sets to",
    "start": "5796119",
    "end": "5802159"
  },
  {
    "text": "Stella's work and the Luther ai's work on opening ey research and all these",
    "start": "5802159",
    "end": "5808000"
  },
  {
    "text": "things that' be real that' be touchable that' be usable to today to transform my",
    "start": "5808000",
    "end": "5813119"
  },
  {
    "text": "work to transform your work to transform the world around me I would not have believed it but it's true we're here and",
    "start": "5813119",
    "end": "5821040"
  },
  {
    "text": "this show was awesome so hope you enjoyed it once again a big thank you to our friends at GitHub for sponsoring us",
    "start": "5821040",
    "end": "5828159"
  },
  {
    "text": "to go to this conference as part of maintainer month there is a small bonus",
    "start": "5828159",
    "end": "5834960"
  },
  {
    "text": "for plus plus subscribers so stick around for that if you're not a plus plus subscriber it's too easy change",
    "start": "5834960",
    "end": "5841440"
  },
  {
    "text": "log.com plusus plus we drop the ads we obviously give you bonus content we",
    "start": "5841440",
    "end": "5847719"
  },
  {
    "text": "bring you a little closer to the metal and the best part you directly support us 10 bucks a month 100 bucks a year",
    "start": "5847719",
    "end": "5855080"
  },
  {
    "text": "change.com pluspl that's it this Show's done thanks for tuning in we will see you on",
    "start": "5855080",
    "end": "5864119"
  },
  {
    "text": "[Music] [Applause] Friday",
    "start": "5865610",
    "end": "5873199"
  },
  {
    "text": "[Music]",
    "start": "5873300",
    "end": "5877249"
  },
  {
    "text": "l",
    "start": "5883920",
    "end": "5886880"
  }
]
[
  {
    "text": "[Music]",
    "start": "330",
    "end": "4089"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspire to or are",
    "start": "7160",
    "end": "13759"
  },
  {
    "text": "curious how AI related Technologies are changing the world this is the show for you thank you to our partners at fastly",
    "start": "13759",
    "end": "21119"
  },
  {
    "text": "for shipping all of our pods super fast to wherever you listen check them out at",
    "start": "21119",
    "end": "26240"
  },
  {
    "text": "fast.com and to our friends that fly deploy your app and database close to",
    "start": "26240",
    "end": "31359"
  },
  {
    "text": "your users no Ops required learn more at",
    "start": "31359",
    "end": "37000"
  },
  {
    "text": "[Music] fly.io welcome to another episode of",
    "start": "37140",
    "end": "44559"
  },
  {
    "text": "practical AI this is Daniel whack I'm a data scientist and founder of a company",
    "start": "44559",
    "end": "49760"
  },
  {
    "text": "called prediction guard and I'm joined as always by my co-host Chris Benson who is a tech strategist at locked Martin",
    "start": "49760",
    "end": "56960"
  },
  {
    "text": "how you doing Chris doing very well enjoying this uh fine Springtime weather of",
    "start": "56960",
    "end": "62280"
  },
  {
    "text": "llms yes the spring llm Bloom I guess that's right that's right all right well",
    "start": "62280",
    "end": "68040"
  },
  {
    "text": "I don't even think we can use the word bloom CU that's loaded now yeah I was going to say that has a whole different meaning there's no word that's not",
    "start": "68040",
    "end": "75159"
  },
  {
    "text": "loaded with some sort of AI meaning at this point yeah we should just go straight to Our Guest yeah including",
    "start": "75159",
    "end": "81720"
  },
  {
    "text": "llamas um which uh we're excited today to have with us Jerry Leu who is",
    "start": "81720",
    "end": "87960"
  },
  {
    "text": "co-founder and creator of llama index welcome Jerry yeah thanks uh Daniel and",
    "start": "87960",
    "end": "93479"
  },
  {
    "text": "Chris for having me super excited to be here yeah um I'm really excited because we've had a few conversations in the",
    "start": "93479",
    "end": "99920"
  },
  {
    "text": "past and I've used uh llama index and some of my own work and also kind of",
    "start": "99920",
    "end": "105159"
  },
  {
    "text": "tried some integration stuff with various data sources so I'm really excited to hear a little bit more of the",
    "start": "105159",
    "end": "110759"
  },
  {
    "text": "story and kind of the vision behind the project if I'm just reading from the docs llama index is about connecting",
    "start": "110759",
    "end": "118560"
  },
  {
    "text": "llms or large language models with external data so maybe a first question",
    "start": "118560",
    "end": "123719"
  },
  {
    "text": "kind of a general question not specific to llama index necessarily is like why",
    "start": "123719",
    "end": "128720"
  },
  {
    "text": "would one want to connect large language models with external data yeah it's a",
    "start": "128720",
    "end": "135200"
  },
  {
    "text": "good question and so for those of you who are already in the space of LM application development this uh might",
    "start": "135200",
    "end": "141480"
  },
  {
    "text": "sound obvious to you but for those of you who might be still somewhat unfamiliar large language models have a",
    "start": "141480",
    "end": "146760"
  },
  {
    "text": "lot of different sorts of capabilities that are really good at answering questions you know doing tasks being",
    "start": "146760",
    "end": "152319"
  },
  {
    "text": "able to summarize stuff basically anything you throw at it like generate a short story write a poem it can do and",
    "start": "152319",
    "end": "157879"
  },
  {
    "text": "the default mode of interacting with a language model like chat GPT is that you would write stuff to it you know in a",
    "start": "157879",
    "end": "164000"
  },
  {
    "text": "chat like interface this query would hit the model and you'd get back some output I think one of the next questions that",
    "start": "164000",
    "end": "169800"
  },
  {
    "text": "people will get into especially as they're trying to explore building applications on top of large language",
    "start": "169800",
    "end": "175159"
  },
  {
    "text": "models is how can this language model understand my own private dat data right",
    "start": "175159",
    "end": "180560"
  },
  {
    "text": "whether you're kind of like a single person or you're an entire organization and these days there's like a lot of",
    "start": "180560",
    "end": "186560"
  },
  {
    "text": "different ways for actually trying to incorporate new knowledge into a language model the models themselves are",
    "start": "186560",
    "end": "191879"
  },
  {
    "text": "trained on just like a giant Corpus of data and so if you're like an ml researcher your default mode is just how",
    "start": "191879",
    "end": "197519"
  },
  {
    "text": "can I train this model on more data so that I can try to memorize this knowledge right and the algorithm there",
    "start": "197519",
    "end": "202640"
  },
  {
    "text": "is basically through some certain like gradient descents or the weights or R draft or any sort of like fancy ml",
    "start": "202640",
    "end": "208000"
  },
  {
    "text": "algorithm that actually includes the knowledge and the weights of the model itself I think one interesting thing",
    "start": "208000",
    "end": "213319"
  },
  {
    "text": "about large language models these days is that uh instead of like training the model you can actually take the model as",
    "start": "213319",
    "end": "219400"
  },
  {
    "text": "is and just like figure out how to have it reason over new information and so",
    "start": "219400",
    "end": "225040"
  },
  {
    "text": "for instance like use that input prompt as like the cache space to feed a new information tell to reason over that",
    "start": "225040",
    "end": "231040"
  },
  {
    "text": "data and to answer questions over that data and I think that's very interesting because you can take the model itself",
    "start": "231040",
    "end": "237400"
  },
  {
    "text": "which you know has been trained on a variety of data but doesn't necessarily have inherent knowledge about you know",
    "start": "237400",
    "end": "242599"
  },
  {
    "text": "you as a person or your organization data but then you can tell it hey here's some new data that I have now given this",
    "start": "242599",
    "end": "249640"
  },
  {
    "text": "data how can I answer the following questions and this is part of the stck that a lot of people are discovering",
    "start": "249640",
    "end": "255200"
  },
  {
    "text": "these days where uh you can actually just use the language model itself as a pre-trained service and then um wrap",
    "start": "255200",
    "end": "261600"
  },
  {
    "text": "that in this overall Software System to incorporate your data with the language model cool yeah and your project is",
    "start": "261600",
    "end": "269000"
  },
  {
    "text": "called uh index now when I before the past like few months or six months or",
    "start": "269000",
    "end": "274320"
  },
  {
    "text": "whatever when I was thinking about like indices or an index one of the things that first came to my mind was like oh I",
    "start": "274320",
    "end": "280280"
  },
  {
    "text": "have a database maybe and there's an index that I use to query over that",
    "start": "280280",
    "end": "286479"
  },
  {
    "text": "database and some of that is a little bit like fuzzy magic to me um in terms",
    "start": "286479",
    "end": "292520"
  },
  {
    "text": "of how that actually works at the lower level in a database but like what is this idea of an index or indexing in the",
    "start": "292520",
    "end": "300160"
  },
  {
    "text": "context of llama index or in the context of data augmentation for large language",
    "start": "300160",
    "end": "305919"
  },
  {
    "text": "models it's kind of funny I think when we first started the name it was a bit more of like a casual naming convention",
    "start": "305919",
    "end": "312240"
  },
  {
    "text": "you know it used to be called GPT index and I kind of made up the name because it sounded uh roughly relevant to what I",
    "start": "312240",
    "end": "318039"
  },
  {
    "text": "was building at the time um but I think over time especially as it's morphed into more of a project that people are",
    "start": "318039",
    "end": "324319"
  },
  {
    "text": "actually using this concept of the index has become a bit more concrete and so I can articulate that a bit better the",
    "start": "324319",
    "end": "329880"
  },
  {
    "text": "idea of llama index is you know just to step back and talk about the overall uh purpose of the project is to make it",
    "start": "329880",
    "end": "336440"
  },
  {
    "text": "really easy and powerful and fast and cheap to connect your language models with your own private data and we have a",
    "start": "336440",
    "end": "342000"
  },
  {
    "text": "few constructs to do so within uh llama index and so part of the way you can",
    "start": "342000",
    "end": "347240"
  },
  {
    "text": "think about llama index is how can we build some sort of stateful service around your private data around",
    "start": "347240",
    "end": "353680"
  },
  {
    "text": "something that at the moment is somewhat stateless like the language model call is a stateless service right because you",
    "start": "353680",
    "end": "359639"
  },
  {
    "text": "feed in some input and you get back some output so how can we wrap that in a safle service around your own data",
    "start": "359639",
    "end": "364840"
  },
  {
    "text": "sources so that you know if you want to ask a question or tell the LM to do something it can reference that state",
    "start": "364840",
    "end": "371080"
  },
  {
    "text": "that you you have stored and so if you think about any sort of like data system there's the raw data that's stored",
    "start": "371080",
    "end": "377319"
  },
  {
    "text": "somewhere in some storage system there might be like indexes or views like similar to like a database analogy where",
    "start": "377319",
    "end": "383880"
  },
  {
    "text": "you can kind of look at the data in different ways and I can talk a little bit about how that works and then there's usually some sort of like query",
    "start": "383880",
    "end": "390280"
  },
  {
    "text": "interface right that you can actually query and retrieve the data so if you look at like a SQL database right you",
    "start": "390280",
    "end": "396039"
  },
  {
    "text": "have you know the raw data stored uh in in some sort of tables you can Define different indexes over different columns",
    "start": "396039",
    "end": "402240"
  },
  {
    "text": "and then the query interface is like a SQL interface you you run SQL and then it'll be able to execute the query against your database and there's a lot",
    "start": "402240",
    "end": "409080"
  },
  {
    "text": "of like kind of roughly similar Concepts that apply to thinking about the Llama",
    "start": "409080",
    "end": "414160"
  },
  {
    "text": "index itself as this tool set because if we're going to build this like stateful service right on top um that can",
    "start": "414160",
    "end": "420160"
  },
  {
    "text": "integrate with large language models by the way to clarify we're not like really solving the storage uh part uh right we",
    "start": "420160",
    "end": "427199"
  },
  {
    "text": "integrate with like a ton of different Vector storage providers we integrate with like other databases too but if you",
    "start": "427199",
    "end": "432280"
  },
  {
    "text": "even think about us as like some sort of data interface or orchestration you know there's a raw data which needs to be stored somewhere and so if you have like",
    "start": "432280",
    "end": "438960"
  },
  {
    "text": "a bunch of text documents you need to store that in like a a vector database or magod DB or S3 um all those types of",
    "start": "438960",
    "end": "446360"
  },
  {
    "text": "things and then you can Define these different indexes on top of this uh data and the way we think about indexes is",
    "start": "446360",
    "end": "453000"
  },
  {
    "text": "how do we structure your data in the right way so that you can retrieve it later for use with LMS and so then I can",
    "start": "453000",
    "end": "459599"
  },
  {
    "text": "talk a little bit how this works but the set of like indexes that you can Define is actually pretty interesting basically",
    "start": "459599",
    "end": "464800"
  },
  {
    "text": "the set of data structures that offers like a view of your data in different ways and then you wrap that in this",
    "start": "464800",
    "end": "469919"
  },
  {
    "text": "overall query interface that can you know use these indexes on top of your data to do retrieval and LM synthesis",
    "start": "469919",
    "end": "477840"
  },
  {
    "text": "and give you back a final answer and so I would look at this in terms of like the components of the overall system",
    "start": "477840",
    "end": "483560"
  },
  {
    "text": "there's just like if you're building this like stateful service there's these three components uh how do you you know",
    "start": "483560",
    "end": "488919"
  },
  {
    "text": "address the store of the raw data index it and then query it so uh I want to actually pull you back for just a moment",
    "start": "488919",
    "end": "495520"
  },
  {
    "text": "uh as we're kind of learning this and if you're an app developer and you're interested in creating a stateful",
    "start": "495520",
    "end": "500879"
  },
  {
    "text": "service and you've started kind of going down the path about like well there's kind of the old school way of going and",
    "start": "500879",
    "end": "507080"
  },
  {
    "text": "doing a SQL query and all that and now we're using llm models and adding our data to it I know that we've kind of",
    "start": "507080",
    "end": "513800"
  },
  {
    "text": "gone beyond that just a little bit but if you can back up and talk a little bit about what are you getting if you're the",
    "start": "513800",
    "end": "518880"
  },
  {
    "text": "app developer and you're listening to this and you're trying to understand like why would I go down that path I'm",
    "start": "518880",
    "end": "525160"
  },
  {
    "text": "you know I sense that there's value there but we haven't talked about it versus a robust set of SQL queries on",
    "start": "525160",
    "end": "531040"
  },
  {
    "text": "your own data why would you bring in that large language model in the beginning what is it bringing to bear",
    "start": "531040",
    "end": "536399"
  },
  {
    "text": "that's worth all of that effort could you talk a little bit about that Baseline value add to it yeah that's a",
    "start": "536399",
    "end": "543079"
  },
  {
    "text": "really good question and I think I might have jumped the gun a little bit so I appreciate you uh bring me back no worries it's because you're excited as",
    "start": "543079",
    "end": "549680"
  },
  {
    "text": "are we but I I also want to make sure that people listening have a chance to truly understand it at the same way that",
    "start": "549680",
    "end": "555560"
  },
  {
    "text": "you are definitely I think one thing about language models that's very powerful is their ability to just",
    "start": "555560",
    "end": "562000"
  },
  {
    "text": "comprehend unstructured text and also natural language and so this matters in",
    "start": "562000",
    "end": "567480"
  },
  {
    "text": "both ways in terms of how you can store the data as well as query the data because now you know let's say you're",
    "start": "567480",
    "end": "573200"
  },
  {
    "text": "the end user you can just type in a Naple language like English question right ideally into this interface and",
    "start": "573200",
    "end": "579880"
  },
  {
    "text": "get back a response and so the setup is way easier than having to learn SQL over some source of data or you know having",
    "start": "579880",
    "end": "586760"
  },
  {
    "text": "to even code up like this very complex like pipeline to try to you know like parse the data in different ways um",
    "start": "586760",
    "end": "593920"
  },
  {
    "text": "because you could treat the language model itself as a blackbox feed us something get something out right and so",
    "start": "593920",
    "end": "599120"
  },
  {
    "text": "I think that by itself is a very very powerful tool and I think these days people are trying to figure out what you",
    "start": "599120",
    "end": "604680"
  },
  {
    "text": "can do with that tool so another kind of like illustrative example of like the power of language models using this as",
    "start": "604680",
    "end": "611880"
  },
  {
    "text": "like intelligent natural language interface is you actually don't have to do a ton of data parsing when you",
    "start": "611880",
    "end": "617200"
  },
  {
    "text": "actually feed in a data so for instance let's say you have a PDF document or",
    "start": "617200",
    "end": "623120"
  },
  {
    "text": "like any sort of like Microsoft Word document or even an HTML web page just copy and paste that entire thing right",
    "start": "623120",
    "end": "629720"
  },
  {
    "text": "you know just extract the text from it dump it into the input prompt and then just like tell the LM hey here's just",
    "start": "629720",
    "end": "636040"
  },
  {
    "text": "this like giant blob of text side copied over now given this text can you please answer this following question and the",
    "start": "636040",
    "end": "642200"
  },
  {
    "text": "crazy thing is the language model can actually do that assuming you know it fits within the promp space and that's",
    "start": "642200",
    "end": "648079"
  },
  {
    "text": "also very powerful because this kind of affects the way you do like ETL and data pipelining right in the traditional",
    "start": "648079",
    "end": "654320"
  },
  {
    "text": "sense if you had a bunch of this like unstructured text you'd have to spend either manual effort or write a complic",
    "start": "654320",
    "end": "659519"
  },
  {
    "text": "program to pull out the relevant bits from this text parse it into some table store it and then You' overun seq or",
    "start": "659519",
    "end": "665880"
  },
  {
    "text": "some other like query over this text whereas here you know with the power of language models you can store this text",
    "start": "665880",
    "end": "672160"
  },
  {
    "text": "in a bit more of like a messy unstructured format uh as like raw natural language and then still figure",
    "start": "672160",
    "end": "678200"
  },
  {
    "text": "out a way to pull out this unstructured text just dump it into the input prompt and ask a question over is it",
    "start": "678200",
    "end": "683839"
  },
  {
    "text": "conceivable uh with what you were saying if I'm thinking as an app developer about diving into this that I'm hearing",
    "start": "683839",
    "end": "690120"
  },
  {
    "text": "you say you're going to do this which is an additional thing to learn and be able to go you know it's an additional skill",
    "start": "690120",
    "end": "696000"
  },
  {
    "text": "set that you're adding on but I also hear you talking about other things that I used to have to do that maybe I don't",
    "start": "696000",
    "end": "701639"
  },
  {
    "text": "have to do anymore and to some degree is it realistic to say from an effort standpoint it becomes a wash once you",
    "start": "701639",
    "end": "708600"
  },
  {
    "text": "have the skills a little bit or maybe even you're gaining more power and doing less work along the way to do it so that",
    "start": "708600",
    "end": "715440"
  },
  {
    "text": "it's kind of like uh of course you would do it going forward is that a fair way of thinking about it yeah so it's an",
    "start": "715440",
    "end": "720600"
  },
  {
    "text": "interesting way of thinking about it because I think the high Lev question is just like you know what parts have become easier and what parts have gotten",
    "start": "720600",
    "end": "727200"
  },
  {
    "text": "harder uh once you have this language model technology because on one hand things have gotten a bit easier and",
    "start": "727200",
    "end": "733880"
  },
  {
    "text": "Powerful to build these expressive like question answering systems with less effort you know you take in this giant",
    "start": "733880",
    "end": "739399"
  },
  {
    "text": "blob of unstructured text you know figure out how to store it you feed it into the language model and then all of",
    "start": "739399",
    "end": "744600"
  },
  {
    "text": "a sudden you can ask these questions over these like files that you couldn't really do before with more kind of like",
    "start": "744600",
    "end": "749639"
  },
  {
    "text": "traditional AI Technologies or just like manual programming that said I think this new paradigm kind of involves its",
    "start": "749639",
    "end": "756079"
  },
  {
    "text": "own set of challenges that I'm happy to talk about I think there's uh a lot of like Stacks emerging about how to make",
    "start": "756079",
    "end": "761920"
  },
  {
    "text": "the best use of language models on top of your data and there's some very basic stuff that's happening these days but",
    "start": "761920",
    "end": "767519"
  },
  {
    "text": "there's also kind of like more um advanced stuff that we're working on and I do think it's very interesting to",
    "start": "767519",
    "end": "774000"
  },
  {
    "text": "think about what are the technical logical challenges that are preventing us from unlocking the capabilities of",
    "start": "774000",
    "end": "780160"
  },
  {
    "text": "language models um because again with a very basic stack uh and again like you can see this if you just like play",
    "start": "780160",
    "end": "786040"
  },
  {
    "text": "around trbt you can already get a ton of value from your data by just like doing some very basic processing on top of it",
    "start": "786040",
    "end": "792800"
  },
  {
    "text": "and you can start asking questions that you couldn't really ask before but you know with some more advanced",
    "start": "792800",
    "end": "797839"
  },
  {
    "text": "capabilities and some once you're solving some more interesting technical problems what are kind of like the additional queries that can ask on top",
    "start": "797839",
    "end": "804440"
  },
  {
    "text": "of your data that you also couldn't do before before we jump into so I want to kind of dive into the Weeds about like",
    "start": "804440",
    "end": "810800"
  },
  {
    "text": "the two things that you talked about like how do I index my data how do I query my data all the goodness around",
    "start": "810800",
    "end": "815920"
  },
  {
    "text": "that in llama index before we do that maybe just as also like a to set the",
    "start": "815920",
    "end": "821600"
  },
  {
    "text": "stage for some people that are coming into this and maybe parsing some of the jargon that's thrown around so one of",
    "start": "821600",
    "end": "827839"
  },
  {
    "text": "the other things that people are really kind of diving into is thinking about like how do I Engineer my prompts how do",
    "start": "827839",
    "end": "834079"
  },
  {
    "text": "I chain prompts together and all of that sort of thing and could you highlight because my at least the way I would",
    "start": "834079",
    "end": "840399"
  },
  {
    "text": "phrase it like those two things are complementary with the things that you're doing with llama index but could",
    "start": "840399",
    "end": "846639"
  },
  {
    "text": "you kind of help people understand like how do those pieces fit together in terms of like architecting one of these",
    "start": "846639",
    "end": "852120"
  },
  {
    "text": "systems I guess in the end LM application development to put it in a very oversimplified view is just some",
    "start": "852120",
    "end": "858680"
  },
  {
    "text": "fancy form of prompt engineering and prompt chaining right it's actually not super different with how we're thinking",
    "start": "858680",
    "end": "863920"
  },
  {
    "text": "about building this interface with data and so just as a very basic example you know if you're kind of coming into the",
    "start": "863920",
    "end": "869320"
  },
  {
    "text": "space fresh like a very basic prompt that you could put into a language model is something like the following here is",
    "start": "869320",
    "end": "876600"
  },
  {
    "text": "my question right and then you put the question here and then you put in here's some context and then in this context",
    "start": "876600",
    "end": "882519"
  },
  {
    "text": "variable you just dump all the context that could be R into the question right you copy and paste a blog post you copy",
    "start": "882519",
    "end": "888040"
  },
  {
    "text": "and paste like API documentation just copy and paste it into the input prompt space and then now the bottom say given",
    "start": "888040",
    "end": "894199"
  },
  {
    "text": "this context give me the answer to this question and you send it to a language model and then you get back an answer so",
    "start": "894199",
    "end": "899600"
  },
  {
    "text": "that's like the most basic like question answer prompt that you could use to kind of perform some sort of like question",
    "start": "899600",
    "end": "905079"
  },
  {
    "text": "answering and um over your data it really is just prompting right because you're putting stuff into the prompts",
    "start": "905079",
    "end": "911199"
  },
  {
    "text": "you have this overall prompt template and you have variables that you want to fill in I think one interesting kind of",
    "start": "911199",
    "end": "916720"
  },
  {
    "text": "like challenge that arises is how can you feed in contexts that exceeds the prompt window cuz for gpt3 it's 4,000",
    "start": "916720",
    "end": "924079"
  },
  {
    "text": "tokens for anthropic I guess it's like 100,000 tokens but like if you look at like an Uber SC 10K filing it's like",
    "start": "924079",
    "end": "931120"
  },
  {
    "text": "160,000 tokens right so if you want to ask a question like what's the summary of this entire document or like what are",
    "start": "931120",
    "end": "936880"
  },
  {
    "text": "the risk factors in this very specific section of the document how do you feed that entire thing in so that you can basically answer the following question",
    "start": "936880",
    "end": "944040"
  },
  {
    "text": "and I think that's where things get a little bit more interesting because you can basically do one or more of the",
    "start": "944040",
    "end": "949480"
  },
  {
    "text": "following things one is you could have some external model uh like it's something separate from the language",
    "start": "949480",
    "end": "955199"
  },
  {
    "text": "model prompt that's actually doing retrieval over your data to figure out what exactly is the best context to",
    "start": "955199",
    "end": "961240"
  },
  {
    "text": "actually fit within this promp space two is you can do some sort of uh synthesis",
    "start": "961240",
    "end": "966959"
  },
  {
    "text": "strategies to synthesize an answer over long context even if that context doesn't actually fit into the prompt for",
    "start": "966959",
    "end": "973199"
  },
  {
    "text": "instance you could chain repeated LM calls over sequential truncks of data to then combine the answers together to",
    "start": "973199",
    "end": "979040"
  },
  {
    "text": "actually give you back a final answer that's one example in the end all this architecture is just kind of designed",
    "start": "979040",
    "end": "984560"
  },
  {
    "text": "around being able to feed in some input to the llm and get back some output and the the core of that really is a proping",
    "start": "984560",
    "end": "990720"
  },
  {
    "text": "right and so part of this is just like developing an overall system around the [Music]",
    "start": "990720",
    "end": "1001390"
  },
  {
    "text": "[Applause] [Music]",
    "start": "1001390",
    "end": "1007639"
  },
  {
    "text": "promting well Jerry um you had mentioned kind of these three levels of",
    "start": "1007639",
    "end": "1013000"
  },
  {
    "text": "integrating external data into your llm application there's sort of data ingestion and there's like indexing and",
    "start": "1013000",
    "end": "1019920"
  },
  {
    "text": "query I'm assuming data ingestion has to do with like oh I'm going to connect to",
    "start": "1019920",
    "end": "1026480"
  },
  {
    "text": "the Google Docs API and like pull the data over and then indexing and query",
    "start": "1026480",
    "end": "1032240"
  },
  {
    "text": "build on top of that but before we dive into those second two phases which is where I think a lot of the cool stuff",
    "start": "1032240",
    "end": "1038400"
  },
  {
    "text": "that you're doing is found what should we know about sort of data in the data ingestion layer in terms of relevance to",
    "start": "1038400",
    "end": "1046558"
  },
  {
    "text": "how llama index Builds on that and other things the data inje side is just like",
    "start": "1046559",
    "end": "1051760"
  },
  {
    "text": "the entry point to building a language model application on top of your own data I think LMS are cool I want to use",
    "start": "1051760",
    "end": "1057760"
  },
  {
    "text": "it on top of some existing Services what are those services and how can I load in data from those Services one component",
    "start": "1057760",
    "end": "1064039"
  },
  {
    "text": "of llama index is this kind of like Community Driven Hub of data loaders called llama Hub where we just offer a",
    "start": "1064039",
    "end": "1071400"
  },
  {
    "text": "variety of different data connectors to a lot of different Services I think we have over like 90 something different data connectors now and these include",
    "start": "1071400",
    "end": "1078120"
  },
  {
    "text": "like connect a file format so for instance like PDF files HTML files like",
    "start": "1078120",
    "end": "1083159"
  },
  {
    "text": "PowerPoints images even they can include connectors to apis like notion slack",
    "start": "1083159",
    "end": "1088720"
  },
  {
    "text": "Discord Salesforce actually sorry we we actually don't have Salesforce yet that's something that we want um but we",
    "start": "1088720",
    "end": "1094640"
  },
  {
    "text": "hav yeah it' be it'd be very useful uh if you're interested in contributing a Salesforce loader please I would love",
    "start": "1094640",
    "end": "1100559"
  },
  {
    "text": "that and then the next part is just like being able to uh connect to kind of like different sorts of multimo formats like",
    "start": "1100559",
    "end": "1107799"
  },
  {
    "text": "audio images which I think I've already mentioned so the idea here is you have all this data it's stored in some format",
    "start": "1107799",
    "end": "1113400"
  },
  {
    "text": "it's unstructured it could be text or it could even be like images or some other format how do you just like load in this",
    "start": "1113400",
    "end": "1118919"
  },
  {
    "text": "data in a pretty simple Manner and just wrap it with some overall document obstruction so there's not a ton of tech",
    "start": "1118919",
    "end": "1124960"
  },
  {
    "text": "going on here and the reason it's more just like a convenience utility for developers to just like easily load in a",
    "start": "1124960",
    "end": "1131120"
  },
  {
    "text": "bunch of data and again going back to the earlier point the reason there's not too much Tech is LMS are very good at",
    "start": "1131120",
    "end": "1137200"
  },
  {
    "text": "reasoning over unstructured information so you actually don't need to do like a ton of parsing on top of this data that",
    "start": "1137200",
    "end": "1142919"
  },
  {
    "text": "you load to basically get some decent results from the language model and so once you actually load in this data in a",
    "start": "1142919",
    "end": "1148280"
  },
  {
    "text": "lightweight container you can then use it for some of the downstream test like indexing and query awesome yeah and I",
    "start": "1148280",
    "end": "1154400"
  },
  {
    "text": "see like this is I think where things get super interesting like I mentioned so in L index I'm in the docs right now",
    "start": "1154400",
    "end": "1161760"
  },
  {
    "text": "like you mention list and table and tree and Vector store and structured store and Knowledge Graph and empty indic",
    "start": "1161760",
    "end": "1169600"
  },
  {
    "text": "could you describe like generally how to think about an index within llama index",
    "start": "1169600",
    "end": "1175640"
  },
  {
    "text": "and then like why are there multiple of these and what categories generally do",
    "start": "1175640",
    "end": "1181039"
  },
  {
    "text": "they fit in one way of thinking about this is just taking a step back at a high level what exactly does the data",
    "start": "1181039",
    "end": "1187080"
  },
  {
    "text": "pipeline look like if you're building a LM application so we started with data inje where you load in a document from",
    "start": "1187080",
    "end": "1193240"
  },
  {
    "text": "some data source like a PDF document or API and now you have this unstructured document The Next Step typically is you",
    "start": "1193240",
    "end": "1200159"
  },
  {
    "text": "want to Chunk Up the text into text chunks so let's say uh naively let's say you have just a giant blob a text from a",
    "start": "1200159",
    "end": "1207200"
  },
  {
    "text": "PDF you can split it you know every 4,000 words or so or every 500 words into some some set of text trunks this",
    "start": "1207200",
    "end": "1214880"
  },
  {
    "text": "just allows you to store this text in units that are easier to feed into the language model and a lot of this is a",
    "start": "1214880",
    "end": "1221080"
  },
  {
    "text": "function of the fact that the language model itself has limited prompt space right so you want to be able to chunk up",
    "start": "1221080",
    "end": "1226360"
  },
  {
    "text": "a longer document into a set of smaller trunks now you have these trunks they're stored somewhere they could be stored",
    "start": "1226360",
    "end": "1232640"
  },
  {
    "text": "for instance within a vector database for instance like a pine cone we vi8 chroma they could also be stored for",
    "start": "1232640",
    "end": "1238520"
  },
  {
    "text": "instance like a a document store like magod DB or it could store like file system on your local disk now they're",
    "start": "1238520",
    "end": "1245280"
  },
  {
    "text": "stored the next part is how do you actually want to Define some sort of structure over this data a basic way of",
    "start": "1245280",
    "end": "1252280"
  },
  {
    "text": "like defining some sort of like structure over this data and this is where we got into indices is just like adding and embedding to each chunk and",
    "start": "1252280",
    "end": "1259159"
  },
  {
    "text": "so if you have a set of texts how do you define like an embedding for each set of texts and that in itself could be",
    "start": "1259159",
    "end": "1265559"
  },
  {
    "text": "treated as like an index right an index is just like a lightweight view over your data the vector index is just",
    "start": "1265559",
    "end": "1272240"
  },
  {
    "text": "adding and edding to each piece of text there's other sorts of indexes that you could Define to Define this like view",
    "start": "1272240",
    "end": "1277760"
  },
  {
    "text": "over your data there's a keyword uh table that we have where you just have a mapping from keywords to the underlying",
    "start": "1277760",
    "end": "1284120"
  },
  {
    "text": "text you could have like a flat list uh where you just like basically store subset of node IDs as like its own index",
    "start": "1284120",
    "end": "1291200"
  },
  {
    "text": "before I get into the technicals of like the indexes and you know like what they actually do one thing to maybe think",
    "start": "1291200",
    "end": "1296919"
  },
  {
    "text": "about is just like what are the end questions that you want to ask and what are some of the use cases that you'd",
    "start": "1296919",
    "end": "1303200"
  },
  {
    "text": "want to solve before you dive into that I was going to ask you really quick could you define what an embedding is",
    "start": "1303200",
    "end": "1308600"
  },
  {
    "text": "for those people who are learning large language models at this point just so they'll understand what it is when you say you're defining that as the index",
    "start": "1308600",
    "end": "1315279"
  },
  {
    "text": "and Bings is a part of kind of a very common stack of mering these days around this Alim data system that's emerging",
    "start": "1315279",
    "end": "1322440"
  },
  {
    "text": "and so an embedding is just a vector of numbers usually like floating Point numbers you could have like a hundred of",
    "start": "1322440",
    "end": "1328000"
  },
  {
    "text": "them a thousand of them it depends on the specific embedding model and the way an embedding works it's just think about",
    "start": "1328000",
    "end": "1334720"
  },
  {
    "text": "this list of numbers as a condensed representation of the piece of content that you have you know if you can",
    "start": "1334720",
    "end": "1340400"
  },
  {
    "text": "somehow in a very abstract manner take in some piece of context let's say this paragraph is about um the biography of",
    "start": "1340400",
    "end": "1346960"
  },
  {
    "text": "like a famous singer right and and then you get an embedding from that it's a string of numbers the embedding has",
    "start": "1346960",
    "end": "1353080"
  },
  {
    "text": "certain properties such that uh this string of numbers is closer to other numbers that are semantically about like",
    "start": "1353080",
    "end": "1359720"
  },
  {
    "text": "similar content and farther away from other strings and numbers representing text that are farther away in terms of",
    "start": "1359720",
    "end": "1365480"
  },
  {
    "text": "semantic content so for instance like if you look at the biography of a singer it's going to be pretty close to",
    "start": "1365480",
    "end": "1371400"
  },
  {
    "text": "biography of another singer versus if it's about I don't know like the American Revolution or something like",
    "start": "1371400",
    "end": "1377279"
  },
  {
    "text": "that embedding will probably be a little bit further away and so it's a way of like condensing a piece of text into",
    "start": "1377279",
    "end": "1382799"
  },
  {
    "text": "some Vector of numbers that has some mathematical properties where you can measure similarity between you know different pieces of content maybe this",
    "start": "1382799",
    "end": "1389640"
  },
  {
    "text": "is another point of Distinction and I I get all these questions very often so I think it's useful to discuss them on the",
    "start": "1389640",
    "end": "1395760"
  },
  {
    "text": "show like last week at odsc I got a lot of these sorts of questions so like we're talking about bringing in data",
    "start": "1395760",
    "end": "1403400"
  },
  {
    "text": "creating an index to access that data that index might involve like a vector",
    "start": "1403400",
    "end": "1409760"
  },
  {
    "text": "store or embeddings but llama index is sort of not a a vector store like it's",
    "start": "1409760",
    "end": "1416039"
  },
  {
    "text": "cool to be a a vector database company right now but llama index is is something different and like again these",
    "start": "1416039",
    "end": "1421720"
  },
  {
    "text": "are two things that are complimentary I think could you draw out that distinction a little bit just to help people kind of formulate those",
    "start": "1421720",
    "end": "1428880"
  },
  {
    "text": "compartments in their mind I think these days there's a lot of vector store providers and they handle a lot of the",
    "start": "1428880",
    "end": "1435120"
  },
  {
    "text": "underlying storage components and so if you look at like a pine cone or wv8 they're actually dealing with the",
    "start": "1435120",
    "end": "1441279"
  },
  {
    "text": "storage of these unstructured documents one thing that we want to do is leverage these existing kind of like storage",
    "start": "1441279",
    "end": "1447840"
  },
  {
    "text": "systems and expose query interfaces that I guess a broader range of query",
    "start": "1447840",
    "end": "1453279"
  },
  {
    "text": "interfaces beyond the ones that are just like directly offered by a vector store and so for instance a vector store will",
    "start": "1453279",
    "end": "1459120"
  },
  {
    "text": "offer a query interface where you can typically query you know the set of documents with an embedding plus like a",
    "start": "1459120",
    "end": "1465039"
  },
  {
    "text": "set of metadata filters plus maybe some additional parameters but we're really trying to build this like broader set of",
    "start": "1465039",
    "end": "1471159"
  },
  {
    "text": "like abstractions and tools through our indices our quer interfaces plus like other abstractions that we have under",
    "start": "1471159",
    "end": "1476919"
  },
  {
    "text": "the hood to basically uh perform like more interesting and advanced operations and manage the interaction between your",
    "start": "1476919",
    "end": "1483399"
  },
  {
    "text": "language model and your data and almost like be a data orchestrator on top of your existing Storage Solutions and so",
    "start": "1483399",
    "end": "1489440"
  },
  {
    "text": "we do see ourselves as separate because we're not trying to build the underlying Storage Solutions we're more trying to",
    "start": "1489440",
    "end": "1494520"
  },
  {
    "text": "provide a lot of this like Advanced query interface capability to the end user using the power of language models",
    "start": "1494520",
    "end": "1500600"
  },
  {
    "text": "on top of your data I think we got a little bit off track a little bit but I think it was good um so kind of circling",
    "start": "1500600",
    "end": "1507360"
  },
  {
    "text": "back to the the indices that are available in llama index and you've",
    "start": "1507360",
    "end": "1513080"
  },
  {
    "text": "talked about like this pipeline of of processing and potentially like one index being like a vector store and",
    "start": "1513080",
    "end": "1520240"
  },
  {
    "text": "maybe listeners are a little bit more familiar with kind of like vector search",
    "start": "1520240",
    "end": "1526000"
  },
  {
    "text": "or semantic search or that sort of of thing with everything that's going on but you have much more than that like",
    "start": "1526000",
    "end": "1532720"
  },
  {
    "text": "these other patterns and these other indices that enable other patterns um could you describe like some of those",
    "start": "1532720",
    "end": "1539080"
  },
  {
    "text": "Alternatives or additions to like vector store index and when and how they might",
    "start": "1539080",
    "end": "1545640"
  },
  {
    "text": "come into play yeah that's a good question and maybe just to kind of like frame this with a bit of context I think",
    "start": "1545640",
    "end": "1551919"
  },
  {
    "text": "it's useful to think about uh certain use cases for each index so the thing about uh Vector index or uh being able",
    "start": "1551919",
    "end": "1559080"
  },
  {
    "text": "to use a vector store is that they're typically well suited for applications where you want to ask kind of like",
    "start": "1559080",
    "end": "1565720"
  },
  {
    "text": "fact-based questions and so if you want to ask a question about like specific facts in your knowledge purpose using a",
    "start": "1565720",
    "end": "1571320"
  },
  {
    "text": "vector store tends to be pretty effective for instance let's say your question is let's say your knowledge purpose is about like American history",
    "start": "1571320",
    "end": "1577520"
  },
  {
    "text": "or something right and your question is hey like what happened you know in the year of 1780 that type of question tends",
    "start": "1577520",
    "end": "1584279"
  },
  {
    "text": "to lend well to using a vector store because the way the overall system works is you would take this query you would",
    "start": "1584279",
    "end": "1590279"
  },
  {
    "text": "generate an embedding for the query you would first do retrieval from the Spectra store in order to fetch back the",
    "start": "1590279",
    "end": "1596559"
  },
  {
    "text": "most relevant chunks to the query and then you would put this into the input prompt of the language model and so the",
    "start": "1596559",
    "end": "1602960"
  },
  {
    "text": "set of retrieve items that you would get would be those that are most semantically similar to your query",
    "start": "1602960",
    "end": "1608440"
  },
  {
    "text": "through embedding distance right so again like going back to embeddings like the closer different embeddings are",
    "start": "1608440",
    "end": "1613960"
  },
  {
    "text": "between your query and your context the more relevant that context is and the farther part it is than the less",
    "start": "1613960",
    "end": "1619520"
  },
  {
    "text": "relevant and so you get back the most relevant context to query feed it to a language model get back an answer there",
    "start": "1619520",
    "end": "1625200"
  },
  {
    "text": "are other settings where standard top K EMB betting based look up and I can dive into this uh in as much technical depth",
    "start": "1625200",
    "end": "1631880"
  },
  {
    "text": "that you guys would want to but there's a settings R standard kind of like topk EMB batting base retrieval doesn't work",
    "start": "1631880",
    "end": "1637360"
  },
  {
    "text": "well right and one example where it doesn't typically work well and this is a very basic example is if you just want",
    "start": "1637360",
    "end": "1643120"
  },
  {
    "text": "to get a summary of like an entire document or an entire set of documents let's say you know instead of like",
    "start": "1643120",
    "end": "1649799"
  },
  {
    "text": "asking a question about a specific fact like what happened in like you know 1776 maybe you just want to ask the language",
    "start": "1649799",
    "end": "1655600"
  },
  {
    "text": "model could you just give me an entire like summary of American history in like the 1800s that type of question tends to",
    "start": "1655600",
    "end": "1662840"
  },
  {
    "text": "not lend well to embeding Bas luckup because you typically fix like a top K value when you do eding based luup and",
    "start": "1662840",
    "end": "1669000"
  },
  {
    "text": "you would get back very specific context but sometimes you really want the language bottle to go through all the different contexts within your data so a",
    "start": "1669000",
    "end": "1676120"
  },
  {
    "text": "vector index with storing it with embedding would create a query interface where you can only fetch like the K most",
    "start": "1676120",
    "end": "1681919"
  },
  {
    "text": "relevant nodes if you store it for instance with like a list index you could store the items in a way such that",
    "start": "1681919",
    "end": "1687799"
  },
  {
    "text": "it's just like a flat list right so when you li query this list index you actually get back all the relevant items",
    "start": "1687799",
    "end": "1694159"
  },
  {
    "text": "within this list and then you'd feed it to our synthesis module to synthesize the final answer so the way you do",
    "start": "1694159",
    "end": "1700440"
  },
  {
    "text": "retrieval over different indices actually depends on the nature of these indices another just like a very basic",
    "start": "1700440",
    "end": "1706760"
  },
  {
    "text": "example is that we we also have like a keyword table index where you can kind of like look up specific items by",
    "start": "1706760",
    "end": "1713080"
  },
  {
    "text": "keywords right instead of through like embedding based distance keywords for instance are typically good for stuff",
    "start": "1713080",
    "end": "1719559"
  },
  {
    "text": "that requires High precision and a little bit like lower recall so you really want to fetch like specific items",
    "start": "1719559",
    "end": "1725480"
  },
  {
    "text": "that match exactly to the keywords uh this has the advantage of actually allowing you to retrieve a bit more",
    "start": "1725480",
    "end": "1730960"
  },
  {
    "text": "precise context than something that like vector based embedding lookup doesn't the way I think about this is like a lot",
    "start": "1730960",
    "end": "1737200"
  },
  {
    "text": "of what llama and next wants to provide is this overall query interface over",
    "start": "1737200",
    "end": "1742399"
  },
  {
    "text": "your data given any class of queries that you might want to ask whether it's like a fact-based question whether it's",
    "start": "1742399",
    "end": "1748760"
  },
  {
    "text": "a summary question or whether it's you know some more interesting questions we want to provide the tool set so that you",
    "start": "1748760",
    "end": "1755200"
  },
  {
    "text": "can answer those questions and indices like defining like the right structure of your data is just one step of this",
    "start": "1755200",
    "end": "1761360"
  },
  {
    "text": "overall process and helping us achieve this vision of like a very like generalizable query interface over your",
    "start": "1761360",
    "end": "1767519"
  },
  {
    "text": "data some examples of like different types of queries that we support there's the fact-based question look up which is",
    "start": "1767519",
    "end": "1773679"
  },
  {
    "text": "like semantic search using Vector eddings you can ask like summarization questions uh through you know using our",
    "start": "1773679",
    "end": "1779480"
  },
  {
    "text": "list index you could actually run like uh structured queries so you could if you have a SQL database you could",
    "start": "1779480",
    "end": "1785159"
  },
  {
    "text": "actually run like structured analytics over your database and do like text to SQL you can do like compare contrast",
    "start": "1785159",
    "end": "1790799"
  },
  {
    "text": "type queries where you can actually look at different documents within your collection and then like look at the",
    "start": "1790799",
    "end": "1796279"
  },
  {
    "text": "differences between them you could even look at like temporal queries where you can reason about like time and then go",
    "start": "1796279",
    "end": "1802279"
  },
  {
    "text": "forwards and backwards and basically kind of like say hey this event actually happened after this event here is the",
    "start": "1802279",
    "end": "1808399"
  },
  {
    "text": "right answer to this question that you're asking about and so a lot of what uh llama index uh does provide is a set",
    "start": "1808399",
    "end": "1815519"
  },
  {
    "text": "of like tools the indices the data iners a query interface to solve like any of these queries that you might want to",
    "start": "1815519",
    "end": "1822050"
  },
  {
    "text": "[Music] answer",
    "start": "1822050",
    "end": "1829960"
  },
  {
    "text": "[Music] so Jerry you really got me thinking a",
    "start": "1835850",
    "end": "1843120"
  },
  {
    "text": "lot about this the possibilities of the query schemes is pretty darn cool you",
    "start": "1843120",
    "end": "1848399"
  },
  {
    "text": "know we kind of started with ingest and moved into kind of indexing and now we're talking about queries could you",
    "start": "1848399",
    "end": "1853480"
  },
  {
    "text": "kind of give me uh an example with the tool it a little bit more of a practical",
    "start": "1853480",
    "end": "1858799"
  },
  {
    "text": "level because you kind of Hit the concepts about like what the possibilities are but as someone who hasn't used the tool myself I'm trying",
    "start": "1858799",
    "end": "1864919"
  },
  {
    "text": "to get a sense of what that workflow is like pick what would probably be like a",
    "start": "1864919",
    "end": "1870080"
  },
  {
    "text": "really common query scheme that you're doing and dive into that just a little bit to give us a sense of a Hands-On",
    "start": "1870080",
    "end": "1875799"
  },
  {
    "text": "practical you know fingers on keyboard sense of it cuz I'm trying to get a sense of where I'm going to go for",
    "start": "1875799",
    "end": "1881080"
  },
  {
    "text": "playing after we get done with the episode so I want to try it 100% I think one thing that has popped up pretty",
    "start": "1881080",
    "end": "1888720"
  },
  {
    "text": "extensively after talking to a variety of different users is actually financial analysis I think looking at SEC 10ks",
    "start": "1888720",
    "end": "1894600"
  },
  {
    "text": "tends to be a pretty popular example uh if you look at the anthropic clad example they also use SEC 10ks and my",
    "start": "1894600",
    "end": "1901000"
  },
  {
    "text": "guess the reason it's popular is one there's just like a ton of texts and so it's just very hard to parse uh if you",
    "start": "1901000",
    "end": "1906760"
  },
  {
    "text": "read it as a human two it's like a useful thing for people in like financial institutions like Consulting",
    "start": "1906760",
    "end": "1912480"
  },
  {
    "text": "because you want to like compare and contrast the performance of like different businesses you know and look at the performance across years believe",
    "start": "1912480",
    "end": "1919000"
  },
  {
    "text": "it or not I actually read 10ks a lot and that would be a really useful example for me believe it or I'm I'm not kidding",
    "start": "1919000",
    "end": "1925399"
  },
  {
    "text": "you as a result we've actually been playing around with it a decent amount too yeah some of the cool like things",
    "start": "1925399",
    "end": "1931519"
  },
  {
    "text": "that we've been that we're showing that llama index can do on top of your 10ks is for instance let's say you have like",
    "start": "1931519",
    "end": "1936720"
  },
  {
    "text": "two companies let's say Uber and left right for the year 2021 you can actually ask a question like can you actually",
    "start": "1936720",
    "end": "1942639"
  },
  {
    "text": "compare and contrast the risk factors for Uber and LIF or their quarterly earnings uh across like these two documents one is the Uber 10K one is a",
    "start": "1942639",
    "end": "1949600"
  },
  {
    "text": "lift 10K this is actually an example where if you do like just topk embedding based look up the query fails because if",
    "start": "1949600",
    "end": "1957639"
  },
  {
    "text": "you ask the question you know compare and contrast Uber and lift and don't do anything to it and let's say you know",
    "start": "1957639",
    "end": "1963600"
  },
  {
    "text": "your Uber and left documents are just in some one vector index you don't really",
    "start": "1963600",
    "end": "1968880"
  },
  {
    "text": "have a guarantee you're going to fetch the relevant context to this question that to be able to answer this thoroughly right and then the model",
    "start": "1968880",
    "end": "1975039"
  },
  {
    "text": "might hallucinate you'll get back the wrong answer and then you know with it's just not a good experience I think what you typically want to do is have some",
    "start": "1975039",
    "end": "1981399"
  },
  {
    "text": "sort of like nicer abstraction layer on top of this query that can actually kind of map that query to some plan that that",
    "start": "1981399",
    "end": "1988760"
  },
  {
    "text": "would roughly be like how a human would think about like executing uh or answering this question let's say you",
    "start": "1988760",
    "end": "1993919"
  },
  {
    "text": "want to compare and contrast the financial performance of uber and lft in the year 2021 well first okay what was",
    "start": "1993919",
    "end": "1999840"
  },
  {
    "text": "the financial performance of uber in 2021 what was the financial performance uplift you break it down into those two",
    "start": "1999840",
    "end": "2005720"
  },
  {
    "text": "questions and then for each question use it to kind of like look over your respective uh index let's say you have",
    "start": "2005720",
    "end": "2012399"
  },
  {
    "text": "an index corresponding to Uber and a index corresponding to LIF get back the answer right get back the actual kind of",
    "start": "2012399",
    "end": "2019559"
  },
  {
    "text": "like revenue for instance for Uber and LIF and then like synthesize both them at the top level again be able to like",
    "start": "2019559",
    "end": "2026639"
  },
  {
    "text": "pull in the individual components you extracted from each document and then synthesize a final response that's able",
    "start": "2026639",
    "end": "2031799"
  },
  {
    "text": "to compare the the two so that's like an example of something that we can actually do pretty well with w index and",
    "start": "2031799",
    "end": "2038200"
  },
  {
    "text": "we have like a variety of tool sets for allowing to do that and that's an example of query that's kind of more",
    "start": "2038200",
    "end": "2043519"
  },
  {
    "text": "advanced because it requires comparisons Beyond just like kind of asking stuff over a single document another example",
    "start": "2043519",
    "end": "2049760"
  },
  {
    "text": "just to kind of like take the 10K analogy further is let's say you have the yearly reports of the same company",
    "start": "2049760",
    "end": "2055599"
  },
  {
    "text": "across different years let's say from like 2018 to 2022 you can ask a question like did Revenue like decline uh go up",
    "start": "2055599",
    "end": "2062440"
  },
  {
    "text": "or down in the last like 3 years and then you could actually do a very similar process where given the query",
    "start": "2062440",
    "end": "2068960"
  },
  {
    "text": "interface that we provide break this question down into some questions over each year pull out the revenue and then",
    "start": "2068960",
    "end": "2074839"
  },
  {
    "text": "basically at the end do a comparison step to see whether or not it increase or decline just as an aside to any",
    "start": "2074839",
    "end": "2080520"
  },
  {
    "text": "listeners out there wondering why on Earth somebody would read 10ks uh especially considering that our audience",
    "start": "2080520",
    "end": "2085800"
  },
  {
    "text": "is focused on on data and such as that if you want to learn about another technology company and really understand",
    "start": "2085800",
    "end": "2091919"
  },
  {
    "text": "what it does and be able to compare it this is an example where you can gain tremendous intelligence on another",
    "start": "2091919",
    "end": "2098640"
  },
  {
    "text": "company with publicly available information and by comparing multi-year 10ks like you just said you'll learn way",
    "start": "2098640",
    "end": "2105359"
  },
  {
    "text": "more about that company than its own employees know about it so anyway just thought I'd mention that as an aside",
    "start": "2105359",
    "end": "2111040"
  },
  {
    "text": "yeah I look forward to hearing your success with uh speeding up your workflows around reading the Tim case",
    "start": "2111040",
    "end": "2117119"
  },
  {
    "text": "Chris with llama index I'm excited about this this is going to save me a lot of time Jerry I uh one of the things that",
    "start": "2117119",
    "end": "2124280"
  },
  {
    "text": "we talked a little bit about in one of our previous conversations which I know you've also thought very deeply about",
    "start": "2124280",
    "end": "2130240"
  },
  {
    "text": "and um even have like a portion of the the docs and functionality in llama index um devoted to is evaluation like",
    "start": "2130240",
    "end": "2139200"
  },
  {
    "text": "query response evaluation like how do I know my large language model like barfed",
    "start": "2139200",
    "end": "2146200"
  },
  {
    "text": "up an answer right based on some query and I pulled in some external data and I",
    "start": "2146200",
    "end": "2152560"
  },
  {
    "text": "you know inserted some context and maybe I strung a few things together like how",
    "start": "2152560",
    "end": "2157839"
  },
  {
    "text": "am I to evaluate the output of that could you give us a maybe a high level",
    "start": "2157839",
    "end": "2162880"
  },
  {
    "text": "from your perspective how you think about this evaluation problem and then maybe go into a little bit of some of",
    "start": "2162880",
    "end": "2168560"
  },
  {
    "text": "the things that you're exploring in that space yeah totally just uh paresis like uh we are super interested in evaluation",
    "start": "2168560",
    "end": "2175400"
  },
  {
    "text": "or more tailored towards this interface of like your data with LMS I can dive into that a bit more and we have some",
    "start": "2175400",
    "end": "2181720"
  },
  {
    "text": "initial evaluation capabilities but we're super like Community oriented like we'd love to just like you know kind of",
    "start": "2181720",
    "end": "2187119"
  },
  {
    "text": "like chat with there's a lot of like different tool sets out there that allow you to do like different types of evals",
    "start": "2187119",
    "end": "2192160"
  },
  {
    "text": "over your data and building like nice interfaces for doing so and so I think this is an area of active exploration",
    "start": "2192160",
    "end": "2197760"
  },
  {
    "text": "and interest for us as well and so just kind of thinking about this a little bit more deeply though evaluation is very",
    "start": "2197760",
    "end": "2203880"
  },
  {
    "text": "interesting because there is the evaluation of each language model call itself and then there is the evaluation",
    "start": "2203880",
    "end": "2210440"
  },
  {
    "text": "of the overall system um and so diving into this bit more like at a very basic level if you have a language model you",
    "start": "2210440",
    "end": "2216599"
  },
  {
    "text": "have an input and you get back some output you can try to validate whether or not that output is correct right",
    "start": "2216599",
    "end": "2221880"
  },
  {
    "text": "given a single language model call did the model actually give you the correct answer given the input did it spit out",
    "start": "2221880",
    "end": "2227920"
  },
  {
    "text": "garbage did it like hallucinate that type of thing the interesting thing about a lot of systems that are emerging",
    "start": "2227920",
    "end": "2233200"
  },
  {
    "text": "these days is that they're really like systems around like a repeated sequence of language model calls and this applies",
    "start": "2233200",
    "end": "2239240"
  },
  {
    "text": "whether or not you're dealing with like the more agent based framework which you know you ask a question it can like just",
    "start": "2239240",
    "end": "2244440"
  },
  {
    "text": "repeatedly kind of like do react trainer thought prompting or like be able to pick a tool but the end result is it's",
    "start": "2244440",
    "end": "2250480"
  },
  {
    "text": "able to give you back a response another example this like Auto GPT where you just let it run for like 5 minutes and",
    "start": "2250480",
    "end": "2255800"
  },
  {
    "text": "just like keeps on doing stuff like over and over again until it gives you back something or you know even in the case of retrieval augmented generation is",
    "start": "2255800",
    "end": "2262359"
  },
  {
    "text": "just like a fancy name for roughly like what we're doing with llama index which is like a query interface over your data",
    "start": "2262359",
    "end": "2267640"
  },
  {
    "text": "like even with within our system there could be a sequence of repeated LM calls but the end result is that you send in",
    "start": "2267640",
    "end": "2273680"
  },
  {
    "text": "some input into the system and you get back some output you know given this high level system how do you evaluate the input and output properly I think in",
    "start": "2273680",
    "end": "2280680"
  },
  {
    "text": "traditional machine learning typically what you want to have is you want to have like ground truth labels for every input that you send in so if you like",
    "start": "2280680",
    "end": "2287359"
  },
  {
    "text": "for instance ask a question you want to know the ground truth answer and you want to compare the predicted answer to the ground truth answer and see how well",
    "start": "2287359",
    "end": "2294079"
  },
  {
    "text": "the predicted answer matches up this is still like uh something that people are exploring these days even in the space",
    "start": "2294079",
    "end": "2300079"
  },
  {
    "text": "of Dr of AI and LMS you have ground truth like text and then you have predicted text and you want some way of",
    "start": "2300079",
    "end": "2306240"
  },
  {
    "text": "scoring how close isct a text is to ground truth text I think the core set of eval modules that we have within",
    "start": "2306240",
    "end": "2312480"
  },
  {
    "text": "llama index actually are ground truth free or label-free and that part in itself is actually very interesting",
    "start": "2312480",
    "end": "2318960"
  },
  {
    "text": "because you have this input uh you ask a question you get back this predicted response you also get back the retrieve",
    "start": "2318960",
    "end": "2325400"
  },
  {
    "text": "like sources like the documents themselves what we found is that you can actually make another llm call to just",
    "start": "2325400",
    "end": "2332680"
  },
  {
    "text": "like compare the sources against the response and then also compare the query against the sources and on the response",
    "start": "2332680",
    "end": "2338280"
  },
  {
    "text": "to see how well all two or three of these components match up and this doesn't require you to actually specify",
    "start": "2338280",
    "end": "2344400"
  },
  {
    "text": "what the ground truth answer is you just look at the predicted answer see if it matches up to the query or the context",
    "start": "2344400",
    "end": "2350480"
  },
  {
    "text": "in a separate llm call and it's interesting because one it makes use of LM based evaluation which is kind of",
    "start": "2350480",
    "end": "2357280"
  },
  {
    "text": "like an interesting way to think about it basically using the language model to evaluate itself right I'm sure there's like downsides which we can get into but",
    "start": "2357280",
    "end": "2363839"
  },
  {
    "text": "you know a lot of people are doing it these days too and then the second part is it doesn't require any ground truth",
    "start": "2363839",
    "end": "2369040"
  },
  {
    "text": "because you're using the language model to evaluate the capabilities of its own answer plus context you don't actually",
    "start": "2369040",
    "end": "2374560"
  },
  {
    "text": "need to as a human feed in the actual answer and the benefit of this is that it just saves a bunch of time and cost you don't actually need to like label",
    "start": "2374560",
    "end": "2381079"
  },
  {
    "text": "your entire data set to run evals I still think this overall like space is probably relatively early um I think",
    "start": "2381079",
    "end": "2387920"
  },
  {
    "text": "there's still some big questions around like latency and cost if you're trying to really do LM based evals more fully",
    "start": "2387920",
    "end": "2394480"
  },
  {
    "text": "like using the LM to evaluate a large data set takes a lot of time and costs a lot of money and so this is generally",
    "start": "2394480",
    "end": "2400560"
  },
  {
    "text": "kind of like an area that we're still kind of like actively thinking about yeah that's awesome as we kind of like",
    "start": "2400560",
    "end": "2406720"
  },
  {
    "text": "get near to the end here I know things are like progressing so quickly I can't",
    "start": "2406720",
    "end": "2411960"
  },
  {
    "text": "keep up with all of your Tweet threads about like awesome new stuff that's happening in in llama index but I know",
    "start": "2411960",
    "end": "2418520"
  },
  {
    "text": "there's a lot um as you look to kind of the next year and like where your mind is at what you really want to dive into",
    "start": "2418520",
    "end": "2425119"
  },
  {
    "text": "and also what what's really exciting to you about the field there's a lot of people excited about a lot of different",
    "start": "2425119",
    "end": "2431560"
  },
  {
    "text": "things but from your perspective having been in the trenches building large language model applications interacting",
    "start": "2431560",
    "end": "2438280"
  },
  {
    "text": "with users of llama index what is it that really excites you moving into this next year in terms of the possibilities",
    "start": "2438280",
    "end": "2446079"
  },
  {
    "text": "the real practical possibilities on the horizon and how kind of our development workflows will be changing in the near",
    "start": "2446079",
    "end": "2453319"
  },
  {
    "text": "future yeah totally I think there's a few related components to this that I'm",
    "start": "2453319",
    "end": "2458359"
  },
  {
    "text": "both excited for as well as like you know the challenges that we're going to solve probably the first component is",
    "start": "2458359",
    "end": "2464119"
  },
  {
    "text": "just being able to build this automated query interface over your data you know if you're looking at all the query use",
    "start": "2464119",
    "end": "2469680"
  },
  {
    "text": "cases that we solv one of the key questions that we keep going back to is here's a new use case on top of this",
    "start": "2469680",
    "end": "2474800"
  },
  {
    "text": "data and here's a new question that you'd want to ask how do we like figure out how to best like fulfill that query",
    "start": "2474800",
    "end": "2481000"
  },
  {
    "text": "request right and I think um especially as your data sources become more complicated then it's just like had",
    "start": "2481000",
    "end": "2487440"
  },
  {
    "text": "think about like how to index and structure the data properly how do you think about interesting automated",
    "start": "2487440",
    "end": "2493240"
  },
  {
    "text": "interactions that happen at the query layer between the language model and your data how do we like basically just like make sure we solve this request and",
    "start": "2493240",
    "end": "2500040"
  },
  {
    "text": "then the second component to this is we want to make sure that we build this interface I can handle any type of query",
    "start": "2500040",
    "end": "2505880"
  },
  {
    "text": "you throw at it now how do we do this in a way that is like cheap fast and easy to use for a lot of users once they move",
    "start": "2505880",
    "end": "2512240"
  },
  {
    "text": "on beyond the initial prototyping phase they think about starting to minimize like cost and lency and then think about",
    "start": "2512240",
    "end": "2517680"
  },
  {
    "text": "how do you like pick the best models for the job right there's like the open AI API which uh works well generally you",
    "start": "2517680",
    "end": "2523599"
  },
  {
    "text": "know they're probably the best model out there but it it can also be quite slow and then there's also these like open source L popping up probably like a few",
    "start": "2523599",
    "end": "2530760"
  },
  {
    "text": "new ones every week and then how do users make the best decisions whether to use that over their data and then I",
    "start": "2530760",
    "end": "2535880"
  },
  {
    "text": "think the next part to this is you know a lot of llm development is moving in this overall trend of like automated",
    "start": "2535880",
    "end": "2542640"
  },
  {
    "text": "reasoning right if you look at like agents and tools it's and auto gbt and all this stuff it's just like how do you",
    "start": "2542640",
    "end": "2547680"
  },
  {
    "text": "make like automated decisions over your data and then I think as a consequence there's always going to be this",
    "start": "2547680",
    "end": "2553520"
  },
  {
    "text": "trade-off between how few constraints can we give it and how many like like should we give it more constraints or",
    "start": "2553520",
    "end": "2559520"
  },
  {
    "text": "fewer constraints right because if fewer constraints you give to something like this it has more flexibility to",
    "start": "2559520",
    "end": "2564599"
  },
  {
    "text": "potentially do way more things but then also just like error right like it it'll just like make mistakes and then there's",
    "start": "2564599",
    "end": "2570839"
  },
  {
    "text": "no really no way to correct it easily and you can't really trust the decisions whereas if you kind of like strain the",
    "start": "2570839",
    "end": "2577640"
  },
  {
    "text": "outputs of these like automated decision makers or agents then you can",
    "start": "2577640",
    "end": "2582760"
  },
  {
    "text": "potentially get more interpretable outputs maybe at the cost of like a little bit of flexibility in terms of",
    "start": "2582760",
    "end": "2587839"
  },
  {
    "text": "functionality and I think we've been thinking a lot about that with respect to like the data retrieval and synthesis space too right like how can we give you",
    "start": "2587839",
    "end": "2596079"
  },
  {
    "text": "back results uh that are expressive but also you know like perform well and aren going to make mistakes like a ton of",
    "start": "2596079",
    "end": "2602480"
  },
  {
    "text": "time awesome yeah well I'm really happy that we had a chance to talk through all the great llama index things and make",
    "start": "2602480",
    "end": "2610240"
  },
  {
    "text": "sure if you're not following Jerry on on Twitter find him there he posts a lot of great stuff um that they're working on",
    "start": "2610240",
    "end": "2617079"
  },
  {
    "text": "and of course you can find llama index if you just search for llama index there's like a great set of docs and all",
    "start": "2617079",
    "end": "2622720"
  },
  {
    "text": "those things we'll make sure we include those links in our show notes for people to find out about that and uh get linked",
    "start": "2622720",
    "end": "2629000"
  },
  {
    "text": "to their docs and their blog and all the good things so um check out llama index and uh thank you so much for joining us",
    "start": "2629000",
    "end": "2635559"
  },
  {
    "text": "Jerry it's been awesome [Music]",
    "start": "2635559",
    "end": "2645160"
  },
  {
    "text": "thank you for listening to practical AI your next step is to subscribe now if",
    "start": "2645160",
    "end": "2650760"
  },
  {
    "text": "you haven't already and if you're a longtime listener of the show help us reach more people by sharing practical",
    "start": "2650760",
    "end": "2656680"
  },
  {
    "text": "AI with your friends and colleagues thanks once again to fastly and fly for partnering with us to bring you all",
    "start": "2656680",
    "end": "2662359"
  },
  {
    "text": "Chang doog podcasts check out what they're up to at fastly.com and fly .io",
    "start": "2662359",
    "end": "2668240"
  },
  {
    "text": "and to our beat freaking residents break master cylinder for continuously cranking out the best beats in the biz",
    "start": "2668240",
    "end": "2673920"
  },
  {
    "text": "that's all for now we'll talk to you again next [Music]",
    "start": "2673920",
    "end": "2688920"
  },
  {
    "text": "time",
    "start": "2688920",
    "end": "2691920"
  }
]
[
  {
    "text": "[Music]",
    "start": "330",
    "end": "5829"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspire to or are",
    "start": "7160",
    "end": "13759"
  },
  {
    "text": "curious how AI related Technologies are changing the world this is the show for you thank you to our partners at fastly",
    "start": "13759",
    "end": "21160"
  },
  {
    "text": "for shipping all of our pods super fast to wherever you listen check them out at",
    "start": "21160",
    "end": "26199"
  },
  {
    "text": "fast.com and to our friends at fly deploy your app and database close to",
    "start": "26199",
    "end": "31359"
  },
  {
    "text": "your users no Ops required learn more at",
    "start": "31359",
    "end": "37000"
  },
  {
    "text": "[Music]",
    "start": "37140",
    "end": "42360"
  },
  {
    "text": "fly.io welcome to another fully connected episode of practical AI in",
    "start": "42360",
    "end": "48199"
  },
  {
    "text": "these episodes Chris and I keep you fully connected with everything that's happening in the AI Community we'll",
    "start": "48199",
    "end": "54840"
  },
  {
    "text": "cover some of the latest news and we'll cover some learning resources that'll help you level up your machine learning",
    "start": "54840",
    "end": "61600"
  },
  {
    "text": "game I'm Daniel whack I'm the founder of prediction guard and I'm joined as always by my co-host Chris Benson who is",
    "start": "61600",
    "end": "69240"
  },
  {
    "text": "a tech strategist at locked Martin how you doing Chris doing very well today Daniel how are you I'm doing great I am",
    "start": "69240",
    "end": "76520"
  },
  {
    "text": "uh uncharacteristically joining this episode from the lobby of a Hampton Inn",
    "start": "76520",
    "end": "82680"
  },
  {
    "text": "in Nashville Tennessee so um if our listeners hear any any background noise",
    "start": "82680",
    "end": "87960"
  },
  {
    "text": "they they know what that is but uh you have a built-in audience right there a built-in audience the people in this",
    "start": "87960",
    "end": "94799"
  },
  {
    "text": "Lobby are unexpectedly learning about AI today which I'm happy to happy to do yeah out",
    "start": "94799",
    "end": "102520"
  },
  {
    "text": "here visiting a customer onsite and um yeah it's nice to sit back and take a",
    "start": "102520",
    "end": "108680"
  },
  {
    "text": "break from that and talk about all the cool stuff going on excellent well I'll tell you what you know we have had so",
    "start": "108680",
    "end": "115320"
  },
  {
    "text": "many questions and uh about kind of sorting out all the things that have happened the last few months and over",
    "start": "115320",
    "end": "122479"
  },
  {
    "text": "the last year um and we've done a couple of episodes where trying to kind of clear out like generative AI what's in",
    "start": "122479",
    "end": "129160"
  },
  {
    "text": "it uh what llms are how they relate and stuff like that what do you think about taking a little bit of a deep dive into",
    "start": "129160",
    "end": "136239"
  },
  {
    "text": "large language models and kind of all the things that make them up because there's a lot of lingo being hurled",
    "start": "136239",
    "end": "142440"
  },
  {
    "text": "about these days yeah yeah I think maybe even outside of llms there's this",
    "start": "142440",
    "end": "149360"
  },
  {
    "text": "perception that the model whether it be for image generation or video generation or",
    "start": "149360",
    "end": "155800"
  },
  {
    "text": "language generation that the model is the application so when you are creating",
    "start": "155800",
    "end": "163480"
  },
  {
    "text": "value the sort of model whether that be you know llama 2 or stable diffusion",
    "start": "163480",
    "end": "168840"
  },
  {
    "text": "Excel or whatever that somehow the model is is the application like it's",
    "start": "168840",
    "end": "174200"
  },
  {
    "text": "providing the functionality that your users want and that's basically a",
    "start": "174200",
    "end": "179360"
  },
  {
    "text": "falsehood I would say um and there's this whole ecosystem of tooling that's",
    "start": "179360",
    "end": "185400"
  },
  {
    "text": "developing around this and one of the things that I sent you recently which I",
    "start": "185400",
    "end": "191040"
  },
  {
    "text": "think does a good job at illustrating some of the various things",
    "start": "191040",
    "end": "196159"
  },
  {
    "text": "that are part of this new ecosystem or this new generative AI app stack was",
    "start": "196159",
    "end": "202040"
  },
  {
    "text": "created by um andreon Horwitz they created a figure that's like emerging",
    "start": "202040",
    "end": "207200"
  },
  {
    "text": "llm appstack we'll link it in our show notes I think it goes though maybe more",
    "start": "207200",
    "end": "212720"
  },
  {
    "text": "generally than llms and but that provides a maybe a nice framework to",
    "start": "212720",
    "end": "218080"
  },
  {
    "text": "talk through some of these things now of course they're providing their own look at this stack especially because they're",
    "start": "218080",
    "end": "226319"
  },
  {
    "text": "invested in many of the companies that they highlight on the stack but I think regardless of that they're trying to",
    "start": "226319",
    "end": "233599"
  },
  {
    "text": "help people understand how some of these things fit together have you seen this picture I have and I appreciated when",
    "start": "233599",
    "end": "239920"
  },
  {
    "text": "you pointed it out a while back there uh it definitely is an interesting I haven't seen anything quite like it in",
    "start": "239920",
    "end": "245720"
  },
  {
    "text": "terms of putting it together and some things they seem to dive into more than others in the chart it will be",
    "start": "245720",
    "end": "251480"
  },
  {
    "text": "interesting to see how we parse it going forward here yeah and maybe we could just take some of these categories and",
    "start": "251480",
    "end": "259560"
  },
  {
    "text": "talk them through in terms of the terminology that's used and how they fit",
    "start": "259560",
    "end": "265600"
  },
  {
    "text": "into the overall ecosystem so you know we can take a an easy example here which",
    "start": "265600",
    "end": "271880"
  },
  {
    "text": "is one of the things that they call out which is Playground now I think this is",
    "start": "271880",
    "end": "277720"
  },
  {
    "text": "probably the place where many people start their generative AI Journey let's",
    "start": "277720",
    "end": "284280"
  },
  {
    "text": "say um so they either go to I think within the playground category there",
    "start": "284280",
    "end": "289360"
  },
  {
    "text": "would be like chat GPT might might fit in that category where you're prompting a model it's interactive it's a UI like",
    "start": "289360",
    "end": "296720"
  },
  {
    "text": "you can put stuff in you can put in a prompt and get an output right now chat",
    "start": "296720",
    "end": "301880"
  },
  {
    "text": "GPT is maybe a little bit more than that because there's a chat thread and all of that um but there's other playgrounds as",
    "start": "301880",
    "end": "308800"
  },
  {
    "text": "well so you can think of spaces on hugging face that allow you to use",
    "start": "308800",
    "end": "314840"
  },
  {
    "text": "stable diffusion or allow you to use other types of models there's other",
    "start": "314840",
    "end": "321800"
  },
  {
    "text": "proprietary kind of playgrounds that are either part of a product or are their",
    "start": "321800",
    "end": "326960"
  },
  {
    "text": "own products so open AI has their own ground within their platform you can log in and try out your prompts there's .ev",
    "start": "326960",
    "end": "335720"
  },
  {
    "text": "which is a cool one that kind of allows you to compare one model to the other there's other products like I would say",
    "start": "335720",
    "end": "342240"
  },
  {
    "text": "something like quip drop which is a tool that lets you use stable diffusion and",
    "start": "342240",
    "end": "347440"
  },
  {
    "text": "you can just go there there's you can try out prompts for free um you can pay up if you need to use it more so there's",
    "start": "347440",
    "end": "354479"
  },
  {
    "text": "a limit to that but there's a lot of these playgrounds floating around and that's often where people start things",
    "start": "354479",
    "end": "361479"
  },
  {
    "text": "it's funny the playground itself as a as a category has a lot of subcategories I",
    "start": "361479",
    "end": "366759"
  },
  {
    "text": "think to it because you know you've already kind of called out kind of the diversity of what You' you know in the",
    "start": "366759",
    "end": "372120"
  },
  {
    "text": "cloud providers for instance all the big cloud providers have their own playground areas Nvidia has a playground",
    "start": "372120",
    "end": "377919"
  },
  {
    "text": "area I think it's almost becoming a a ubiquitous uh notion and of course all",
    "start": "377919",
    "end": "383000"
  },
  {
    "text": "those playground areas for the commercial entities are focused on their products and services definitely but",
    "start": "383000",
    "end": "388759"
  },
  {
    "text": "trying to trying to bring some cool factor to it so yeah it's almost like a",
    "start": "388759",
    "end": "394280"
  },
  {
    "text": "demo or experimentation interface if we Define this playground category it's",
    "start": "394280",
    "end": "400039"
  },
  {
    "text": "usually but not always a browser based playground uh or a browser based",
    "start": "400039",
    "end": "405880"
  },
  {
    "text": "interface where you can try to prompt a model and see what the output is like I",
    "start": "405880",
    "end": "411440"
  },
  {
    "text": "think that would kind of generally be true maybe there's some caveats to certain ones like mid Journey For",
    "start": "411440",
    "end": "417000"
  },
  {
    "text": "example is a Discord bot or there is still a Discord bot that you could use maybe that fits into the playground but",
    "start": "417000",
    "end": "424080"
  },
  {
    "text": "generally these are interactive and useful for",
    "start": "424080",
    "end": "429560"
  },
  {
    "text": "experimentation but not necessarily useful to like build an application yeah",
    "start": "429560",
    "end": "436400"
  },
  {
    "text": "I agree and and another thing to note about it from a characteristic standpoint is not only is it really it's",
    "start": "436400",
    "end": "442919"
  },
  {
    "text": "not made for you to go build your own thing it's made for you to try kind of the stuff of whatever organization is",
    "start": "442919",
    "end": "449160"
  },
  {
    "text": "doing but they do do it uh they provide the resources so by being in a browser you",
    "start": "449160",
    "end": "455160"
  },
  {
    "text": "don't have to have a GPU on your laptop you don't have to have resources yeah yeah you don't have to have all the",
    "start": "455160",
    "end": "460319"
  },
  {
    "text": "things through various means they set up all that for you on the back end whether it be just calling a service or whether",
    "start": "460319",
    "end": "466680"
  },
  {
    "text": "it be creating a temporary environment through virtualization but it is a good way to either to test out a new product",
    "start": "466680",
    "end": "473560"
  },
  {
    "text": "line or to or to just get your toes wet a little bit if you want to try some stuff out maybe you've been listening to",
    "start": "473560",
    "end": "479960"
  },
  {
    "text": "the Practical AIA podcast for a little while and you want to uh a particular topic grabs you that would be a good",
    "start": "479960",
    "end": "485879"
  },
  {
    "text": "place to go yeah and I think within that same vein you could transition to talk about this other category which is not",
    "start": "485879",
    "end": "494319"
  },
  {
    "text": "unique to the generative AI app stack let's call it but it's still part of the",
    "start": "494319",
    "end": "500759"
  },
  {
    "text": "stack which they have called out app hosting so that's like very generic right so in here would fit things like",
    "start": "500759",
    "end": "508879"
  },
  {
    "text": "vers or I would say you know generally like the cloud providers right and the",
    "start": "508879",
    "end": "514719"
  },
  {
    "text": "various ways that you can host things whether that be in Amazon with ECS or app Runner or whatever that is or in",
    "start": "514719",
    "end": "521640"
  },
  {
    "text": "even your own infrastructure your own on-prem infrastructure if you host things now there are I would say a",
    "start": "521640",
    "end": "528560"
  },
  {
    "text": "number of Hosting providers that are kind of cool and trendy and people that",
    "start": "528560",
    "end": "534880"
  },
  {
    "text": "are building new AI apps they seem to gravitate towards like let's say versell",
    "start": "534880",
    "end": "540079"
  },
  {
    "text": "and a lot of front-end developers that use versell which I think it's amazing platform so cool that hasn't",
    "start": "540079",
    "end": "547040"
  },
  {
    "text": "traditionally been like a data sciency hosting way of doing things but it",
    "start": "547040",
    "end": "553160"
  },
  {
    "text": "represents I think this new wave of application developers that are developing applications integrating Ai",
    "start": "553160",
    "end": "561279"
  },
  {
    "text": "and you see some of those now kind of coming into or being exposed in this",
    "start": "561279",
    "end": "567360"
  },
  {
    "text": "kind of wider appstack which is a good thing because we've talked for a long time even as we opened this conversation",
    "start": "567360",
    "end": "574519"
  },
  {
    "text": "up saying the model is not the app you know you you have to wrap the model with some goodness to get the value out of it",
    "start": "574519",
    "end": "581640"
  },
  {
    "text": "to be productive with it and so I personally like the fact that we're seeing the model hosting and the app",
    "start": "581640",
    "end": "588640"
  },
  {
    "text": "hosting are starting to merge because I think that's more manageable over time it's less being in its own special",
    "start": "588640",
    "end": "594360"
  },
  {
    "text": "category and it's more about okay every app in the future is going to have models in it and so you know we're",
    "start": "594360",
    "end": "600640"
  },
  {
    "text": "accommodating that notion so I I like seeing it go there I've been waiting for that for a while yeah and to really",
    "start": "600640",
    "end": "606720"
  },
  {
    "text": "clarify and Define things you could kind of think about like the playground that we talked about as an app that has been",
    "start": "606720",
    "end": "614760"
  },
  {
    "text": "developed by these different people that illustrates some llm functionality but it's usually not the app that you're",
    "start": "614760",
    "end": "621519"
  },
  {
    "text": "going to build you're going to build another app that is exposed to your users that uses the functionality and",
    "start": "621519",
    "end": "627399"
  },
  {
    "text": "you'll need to host that either in ways that people have been hosting things for a long time or new interesting patterns",
    "start": "627399",
    "end": "634360"
  },
  {
    "text": "that are popping up like things that model is doing or maybe things that front-end developers really like to use",
    "start": "634360",
    "end": "641079"
  },
  {
    "text": "like for sale and and other things but there's still that app hosting side now",
    "start": "641079",
    "end": "646600"
  },
  {
    "text": "where I think things get interesting is you have the playground you have the app hosting but regardless of both of those",
    "start": "646600",
    "end": "654000"
  },
  {
    "text": "what happens under the hood and this is I think where things get quite interesting and where there's a lot of",
    "start": "654000",
    "end": "660880"
  },
  {
    "text": "differences in the kind of emerging generative AI stack compared to the",
    "start": "660880",
    "end": "666920"
  },
  {
    "text": "maybe more traditional non- AI stack in the middle of the diagram um that we're",
    "start": "666920",
    "end": "672880"
  },
  {
    "text": "talking about this emerging llm app stack diagram which I think also is",
    "start": "672880",
    "end": "677959"
  },
  {
    "text": "again more General is this layer of orchestration so I don't know about you",
    "start": "677959",
    "end": "684720"
  },
  {
    "text": "Chris but I'm old enough I guess you don't have to be that old I don't think",
    "start": "684720",
    "end": "691040"
  },
  {
    "text": "to um when someone says orchestration I think of like kubernetes or like",
    "start": "691040",
    "end": "696399"
  },
  {
    "text": "container orchestration maybe that's my own bias coming from working in a few",
    "start": "696399",
    "end": "702440"
  },
  {
    "text": "microservices oriented startups and that sort of thing but this is distinctly not",
    "start": "702440",
    "end": "708959"
  },
  {
    "text": "the orchestration that's being called out here in the in the generative AI app",
    "start": "708959",
    "end": "714000"
  },
  {
    "text": "stack there's a level of orchestration which in some of my workshops I've been",
    "start": "714000",
    "end": "719959"
  },
  {
    "text": "kind of referring to as almost like a convenience layer think about like when",
    "start": "719959",
    "end": "726160"
  },
  {
    "text": "you're interacting with a model let's give a really concrete example let's say I want to do question and answer with an",
    "start": "726160",
    "end": "732360"
  },
  {
    "text": "llm I need to somehow get a context for",
    "start": "732360",
    "end": "737639"
  },
  {
    "text": "answering the question I need to insert the question and that context into a prompt and then I need to send that",
    "start": "737639",
    "end": "744839"
  },
  {
    "text": "prompt to a model I need to get the result back and maybe do some like clean up on it like I I have some stop tokens",
    "start": "744839",
    "end": "752519"
  },
  {
    "text": "or I want it you know to end at a certain punctuation mark or or whatever",
    "start": "752519",
    "end": "757639"
  },
  {
    "text": "that is that's all convenience what I would consider sort of this convenience",
    "start": "757639",
    "end": "763880"
  },
  {
    "text": "and what they're calling orchestration around the call to the model and so this",
    "start": "763880",
    "end": "771279"
  },
  {
    "text": "orchestration layer I think has to do with prompt templates generating prompts",
    "start": "771279",
    "end": "778560"
  },
  {
    "text": "chain of prompts agents uh plugging in data sources like plugins these are all",
    "start": "778560",
    "end": "785519"
  },
  {
    "text": "things that kind of circle around your AI calls but aren't the AI model yeah I",
    "start": "785519",
    "end": "793839"
  },
  {
    "text": "mean it's the software around it you know just to simplify a little bit Yeah and maybe tooling yeah orchestration",
    "start": "793839",
    "end": "800519"
  },
  {
    "text": "tooling yeah yeah it's the stuff you have to wrap the model with to make it usable in a productive sense and from",
    "start": "800519",
    "end": "807320"
  },
  {
    "text": "the moment that I saw that word that was almost the very first thing that grabbed me you know those you know little",
    "start": "807320",
    "end": "812399"
  },
  {
    "text": "psychological Quirk where you kind of notice the thing that sticks out yeah that's the thing that stuck out was they",
    "start": "812399",
    "end": "817680"
  },
  {
    "text": "it's a big bucket that they're calling orchestration which is a loaded word that can mean a lot of different things",
    "start": "817680",
    "end": "824399"
  },
  {
    "text": "depending on what it is you're trying to do and the examples that they list in that category are are all somewhat",
    "start": "824399",
    "end": "830639"
  },
  {
    "text": "diverse as well I think that was the first point where I thought well it's a chart with the creator has a has a bias",
    "start": "830639",
    "end": "838600"
  },
  {
    "text": "there what are some of the ways I'm just curious when we think about this kind of orchestration as they say wrapping",
    "start": "838600",
    "end": "845320"
  },
  {
    "text": "around and providing the convenience any ways that you would break that up like how you think about it you mentioned",
    "start": "845320",
    "end": "850720"
  },
  {
    "text": "convenience and stuff but they go from something like python as a programming language to Lang chain to chat GPT all",
    "start": "850720",
    "end": "858519"
  },
  {
    "text": "three very distinct kinds of of entities yeah I think that you're kind of seeing",
    "start": "858519",
    "end": "864000"
  },
  {
    "text": "a number of things happen here the first one that they call out is python SL DIY",
    "start": "864000",
    "end": "870279"
  },
  {
    "text": "so you're seeing a lot of roll your own kind of convenience functionality built",
    "start": "870279",
    "end": "875560"
  },
  {
    "text": "up around llms but I do think one of the big players here would be like Lang",
    "start": "875560",
    "end": "881519"
  },
  {
    "text": "chain and and what they're doing cuz if you look again at those kind of layers of what's available there you have maybe",
    "start": "881519",
    "end": "889399"
  },
  {
    "text": "categories that I would call out if we just take Lang chain as an example categories that I would call out of this",
    "start": "889399",
    "end": "895880"
  },
  {
    "text": "sort of orchestration functionality would be templating so this would be",
    "start": "895880",
    "end": "900959"
  },
  {
    "text": "like prompt templates for example or templating uh in terms of chains so",
    "start": "900959",
    "end": "907639"
  },
  {
    "text": "manually setting up a chain of things that can be called in one call there's",
    "start": "907639",
    "end": "913160"
  },
  {
    "text": "also an automation component of it maybe the or this is a way that orchestration",
    "start": "913160",
    "end": "920160"
  },
  {
    "text": "kind of fits with the older way the orchestration term is used in like",
    "start": "920160",
    "end": "925759"
  },
  {
    "text": "devops and other things where some of it could be automation related to with",
    "start": "925759",
    "end": "931440"
  },
  {
    "text": "things like agents or something like that where you have an agent that automates certain functionality it's not",
    "start": "931440",
    "end": "939240"
  },
  {
    "text": "the llm itself but it's really automations around calling the llms or",
    "start": "939240",
    "end": "945560"
  },
  {
    "text": "the other generative AI models to generate a an image or what have you they also kind of have some separate",
    "start": "945560",
    "end": "952199"
  },
  {
    "text": "callouts you know for apis and plugins and then they have uh which we can hit",
    "start": "952199",
    "end": "957480"
  },
  {
    "text": "in a moment they kind of have a collection of the the maintenance items you know the things to keep the lights",
    "start": "957480",
    "end": "963079"
  },
  {
    "text": "on if you will logging and caching and and things like that how do you look at",
    "start": "963079",
    "end": "968279"
  },
  {
    "text": "that breakdown the way they have it yeah so I think this is where they kind of",
    "start": "968279",
    "end": "975000"
  },
  {
    "text": "have the orchestration piece in the middle there as connecting a couple",
    "start": "975000",
    "end": "980800"
  },
  {
    "text": "different things one of those would be what I would consider I think more on the data or resource side and then one",
    "start": "980800",
    "end": "988360"
  },
  {
    "text": "is more on the model side so I think we could split it into those two major categories so what are you orchestrating",
    "start": "988360",
    "end": "994480"
  },
  {
    "text": "when you're orchestrating something with Lang chain or similar well you're orchestrating connections to resources",
    "start": "994480",
    "end": "1002720"
  },
  {
    "text": "I'll use the term resources because it might not be data per se it might be",
    "start": "1002720",
    "end": "1008560"
  },
  {
    "text": "like you say like an API or another platform like zapier or you know wolf",
    "start": "1008560",
    "end": "1014639"
  },
  {
    "text": "from alpha something like that the other side of that is the model side",
    "start": "1014639",
    "end": "1019759"
  },
  {
    "text": "both the model hosting and some really useful tooling around that but let's",
    "start": "1019759",
    "end": "1025880"
  },
  {
    "text": "start on the resource side so as you mentioned you might orchestrate things like one of the things that I found both",
    "start": "1025880",
    "end": "1031880"
  },
  {
    "text": "really fun to do and useful is to orchestrate calls into like a Google",
    "start": "1031880",
    "end": "1037760"
  },
  {
    "text": "search so if I want to pull in some context on the Fly then I might do want",
    "start": "1037760",
    "end": "1043839"
  },
  {
    "text": "to do a Google search that's a call to an API so that's a resource or a plugin",
    "start": "1043839",
    "end": "1049039"
  },
  {
    "text": "that might be conveniently integrated into your orchestration layer either via something",
    "start": "1049039",
    "end": "1056520"
  },
  {
    "text": "like Lang chain or via your own DIY code another side of this would be the actual",
    "start": "1056520",
    "end": "1063720"
  },
  {
    "text": "data and the data pipelines which are your own data or data that you've",
    "start": "1063720",
    "end": "1070360"
  },
  {
    "text": "gathered or is relevant to your problem so again if we're thinking about this sort of set of resources that could be",
    "start": "1070360",
    "end": "1076240"
  },
  {
    "text": "orchestrated into your app maybe you have a set of documentation that you",
    "start": "1076240",
    "end": "1082200"
  },
  {
    "text": "want to generate answers to questions out of or maybe you have a bunch of",
    "start": "1082200",
    "end": "1087559"
  },
  {
    "text": "images that you want to use to fine-tune stable diffusion or something like that",
    "start": "1087559",
    "end": "1093360"
  },
  {
    "text": "having data and integrating it into models isn't new and so the things that",
    "start": "1093360",
    "end": "1099280"
  },
  {
    "text": "are called out in this particular image like data pipelines those are also not",
    "start": "1099280",
    "end": "1104960"
  },
  {
    "text": "new and are part of this app stack if you're integrating your own data so",
    "start": "1104960",
    "end": "1110360"
  },
  {
    "text": "things like data bricks or airflow or padm or tools to parse data so PDF",
    "start": "1110360",
    "end": "1118880"
  },
  {
    "text": "parsers or unstructured data parsers or image parsers or image resizing or all",
    "start": "1118880",
    "end": "1125440"
  },
  {
    "text": "of that sort of stuff still fits into the data pipelining piece and so you've either got your data coming from apis",
    "start": "1125440",
    "end": "1134400"
  },
  {
    "text": "which might be a resource that you're orchestrating or you've got your data coming from your data sources which",
    "start": "1134400",
    "end": "1141280"
  },
  {
    "text": "might be traditional data sources of any type from databases to unstructured",
    "start": "1141280",
    "end": "1149559"
  },
  {
    "text": "[Music] data this is a chang log news break it's",
    "start": "1149990",
    "end": "1156640"
  },
  {
    "text": "official advancements in computer vision have rendered captas obsolete as new",
    "start": "1156640",
    "end": "1163000"
  },
  {
    "text": "research shows AI Bots are 15% more accurate than humans at picking which",
    "start": "1163000",
    "end": "1169120"
  },
  {
    "text": "images have a bridge or sign or a bicycle or whatever in them the researchers recruited 1,400 participants",
    "start": "1169120",
    "end": "1175760"
  },
  {
    "text": "to test websites that used capture puzzles which account for 120 of the world's 200 most popular websites the",
    "start": "1175760",
    "end": "1183120"
  },
  {
    "text": "bot's accuracy ranges from 85 to 100% with the majority above 96% meanwhile",
    "start": "1183120",
    "end": "1189440"
  },
  {
    "text": "Weir Mortals check in at AP pathetic 50 to 85% accuracy and we answer slower",
    "start": "1189440",
    "end": "1195840"
  },
  {
    "text": "than the robots to add insult injury I've surmised this for months now as",
    "start": "1195840",
    "end": "1201320"
  },
  {
    "text": "we've been unable to ward off spam account Creations on changel law.com no matter which shiny new Capa service we",
    "start": "1201320",
    "end": "1207760"
  },
  {
    "text": "tried there are other efforts in the works besides Capa in order to differentiate between robots and humans",
    "start": "1207760",
    "end": "1214480"
  },
  {
    "text": "but so far the robots are winning you just heard one of our five top stories",
    "start": "1214480",
    "end": "1220640"
  },
  {
    "text": "from Monday's Chang log news subscribe to the podcast to get all of the week's top stories and pop your email address",
    "start": "1220640",
    "end": "1227200"
  },
  {
    "text": "in at Chang blog.com /ne to also receive our free companion email with even more",
    "start": "1227200",
    "end": "1233120"
  },
  {
    "text": "developer news worth your attention once again that's",
    "start": "1233120",
    "end": "1238679"
  },
  {
    "text": "[Music]",
    "start": "1239230",
    "end": "1244790"
  },
  {
    "text": "changelog.md and the vector database piece and I have to say I've just got to",
    "start": "1257200",
    "end": "1263840"
  },
  {
    "text": "recommend that our listeners if they haven't listen to our very recent",
    "start": "1263840",
    "end": "1269080"
  },
  {
    "text": "episode about Vector databases because that episode goes into way more depth in",
    "start": "1269080",
    "end": "1274960"
  },
  {
    "text": "terms of what a vector database is and why people are using it but just for a quick recap part of what you might want",
    "start": "1274960",
    "end": "1282840"
  },
  {
    "text": "to do with generative AI models is find relevant data that's relevant to a user",
    "start": "1282840",
    "end": "1290559"
  },
  {
    "text": "query and somehow orchestrate that into your llm calls either for chat or",
    "start": "1290559",
    "end": "1296720"
  },
  {
    "text": "question answering or maybe even into a image generation or a video generation in order to find relevant data what",
    "start": "1296720",
    "end": "1305600"
  },
  {
    "text": "people have found is that they would like to do a vector or an embedding search on their own data to find",
    "start": "1305600",
    "end": "1312200"
  },
  {
    "text": "relevant data and again you can find out much more about that in our our previous episode but that's called in this",
    "start": "1312200",
    "end": "1319120"
  },
  {
    "text": "appstack as probably something unique that's developing which is not just having data pipelines and data bases but",
    "start": "1319120",
    "end": "1327279"
  },
  {
    "text": "having data flow through an embedding model and into a vector database where",
    "start": "1327279",
    "end": "1334799"
  },
  {
    "text": "you're performing semantic searches I mean at the end of the day it's a database that's very it works well for",
    "start": "1334799",
    "end": "1341760"
  },
  {
    "text": "the kind of operation that we're doing here whereas some of the traditional things that we had been working on for",
    "start": "1341760",
    "end": "1346799"
  },
  {
    "text": "years before there's kind of a context shifting in terms of how you're handling data what data is how it's organized uh",
    "start": "1346799",
    "end": "1353799"
  },
  {
    "text": "so this makes a lot more sense yeah and uh it should call out here too part of",
    "start": "1353799",
    "end": "1359240"
  },
  {
    "text": "the stack here and I'm glad that they called it out in this way in the schematic that we're looking at is the",
    "start": "1359240",
    "end": "1366240"
  },
  {
    "text": "embedding model so a lot of people are talking about these Vector databases but",
    "start": "1366240",
    "end": "1371400"
  },
  {
    "text": "in order to store a vector in a vector database there is a very relevant",
    "start": "1371400",
    "end": "1377440"
  },
  {
    "text": "component to this step back which is the actual model that you're using to create",
    "start": "1377440",
    "end": "1382880"
  },
  {
    "text": "embeddings and not all are created equal so think about if you're working on an",
    "start": "1382880",
    "end": "1389640"
  },
  {
    "text": "image problem right you may use a pre-trained feature extractor type model",
    "start": "1389640",
    "end": "1397279"
  },
  {
    "text": "from hugging face to extract vectors that your images uh so put an image and",
    "start": "1397279",
    "end": "1402679"
  },
  {
    "text": "get a vector out but if you're working with both image and text for example maybe you're going to something like CP",
    "start": "1402679",
    "end": "1410120"
  },
  {
    "text": "or one of those a related model that's able to embed both images and text in a",
    "start": "1410120",
    "end": "1417240"
  },
  {
    "text": "similar semantic space but if you're only using text there's a whole bunch of",
    "start": "1417240",
    "end": "1422840"
  },
  {
    "text": "of course choices and all of those don't perform equally for different types of",
    "start": "1422840",
    "end": "1429400"
  },
  {
    "text": "tasks as well there's um if you search on hugging face or just do a Google search for a hugging face embeddings",
    "start": "1429400",
    "end": "1437919"
  },
  {
    "text": "leaderboard board there's actually a separate leaderboard so hugging face has a leaderboard for open models and how",
    "start": "1437919",
    "end": "1445360"
  },
  {
    "text": "those score and various metrics they also have a leaderboard for embeddings",
    "start": "1445360",
    "end": "1450520"
  },
  {
    "text": "and you can click through the different tasks let's say you're doing retrieval tasks like we're talking about here from",
    "start": "1450520",
    "end": "1456120"
  },
  {
    "text": "a vector database you can see which embeddings perform the best according to",
    "start": "1456120",
    "end": "1461840"
  },
  {
    "text": "a variety of benchmarks in retrieval or in summarization or other things do you",
    "start": "1461840",
    "end": "1468399"
  },
  {
    "text": "use that a lot when you're putting models uh and storing them into Vector databases and figuring out the",
    "start": "1468399",
    "end": "1473840"
  },
  {
    "text": "embeddings do you tend to go and see what is going on because right now there's so much happening in that space",
    "start": "1473840",
    "end": "1479960"
  },
  {
    "text": "is that make for a good guidepost for you yeah yeah and I think what is also",
    "start": "1479960",
    "end": "1485880"
  },
  {
    "text": "useful is looking at those performance metrics but also at least on the hugging",
    "start": "1485880",
    "end": "1491200"
  },
  {
    "text": "face leaderboard and some other leaderboards so if you search for if you're working with text one of the",
    "start": "1491200",
    "end": "1497520"
  },
  {
    "text": "major tools for creating these embeddings in a really useful way is called sentence",
    "start": "1497520",
    "end": "1502720"
  },
  {
    "text": "Transformers and they have their own table where they have measured and",
    "start": "1502720",
    "end": "1507919"
  },
  {
    "text": "Benchmark various embeddings that can be integrated in in sentence Transformers",
    "start": "1507919",
    "end": "1513360"
  },
  {
    "text": "that's useful but it's also useful to look at the columns whether you're looking in the hugging face leaderboard",
    "start": "1513360",
    "end": "1519279"
  },
  {
    "text": "or the sentence Transformers or wherever you're looking at the size of the embedding and the speed of the embedding",
    "start": "1519279",
    "end": "1527480"
  },
  {
    "text": "because it was called out when we had our Vector database discussion but only in passing let's say you want to embed",
    "start": "1527480",
    "end": "1534559"
  },
  {
    "text": "you know 200,000 PDFs so I just ran across this use case with some of the",
    "start": "1534559",
    "end": "1540760"
  },
  {
    "text": "work that we're doing and it can take a really really really really long time",
    "start": "1540760",
    "end": "1547240"
  },
  {
    "text": "depending on how you implement it to both parse and embed a significant number of PDFs the same would be true",
    "start": "1547240",
    "end": "1554000"
  },
  {
    "text": "for documents or other text or other types of data even and so when you're",
    "start": "1554000",
    "end": "1559799"
  },
  {
    "text": "looking at that there's two implications here one is how fast am I able to",
    "start": "1559799",
    "end": "1565159"
  },
  {
    "text": "generate these embeddings do I have to use a GPU or can I use a CPU because",
    "start": "1565159",
    "end": "1570799"
  },
  {
    "text": "there's going to be a different speed on gpus versus CPUs and how big are the embeddings this is another kind of",
    "start": "1570799",
    "end": "1577799"
  },
  {
    "text": "interesting piece which is if I got embeddings that are thousand or more in",
    "start": "1577799",
    "end": "1584279"
  },
  {
    "text": "dimension that's going to take up a lot more room in my database and on disk",
    "start": "1584279",
    "end": "1590279"
  },
  {
    "text": "than embeddings that are 256 or something like that so there's also",
    "start": "1590279",
    "end": "1596240"
  },
  {
    "text": "storage and moving around data implications to how you choose this",
    "start": "1596240",
    "end": "1601320"
  },
  {
    "text": "embedding space so there's a lot of I think practical things that maybe people",
    "start": "1601320",
    "end": "1606880"
  },
  {
    "text": "skip over here when they're just doing a prototype with Lang chain and some Vector database it's easy but then it as",
    "start": "1606880",
    "end": "1614720"
  },
  {
    "text": "soon as you try to put all your data in it gets much harder you rais a question",
    "start": "1614720",
    "end": "1620480"
  },
  {
    "text": "in my mind and I'm going to throw it out you may or may not be familiar with what the answer would be but when you're",
    "start": "1620480",
    "end": "1626720"
  },
  {
    "text": "looking at Vector databases and you're looking at all these you know the diversity in in embedding possibilities",
    "start": "1626720",
    "end": "1631840"
  },
  {
    "text": "here and the fact that that has kind of physical layer uh consequences you know",
    "start": "1631840",
    "end": "1637600"
  },
  {
    "text": "in terms of storage and stuff like that are we seeing that in vector or other",
    "start": "1637600",
    "end": "1643279"
  },
  {
    "text": "database uh Arenas where they're trying to accommodate this new approach to capturing data in terms of having",
    "start": "1643279",
    "end": "1650120"
  },
  {
    "text": "embeddings the way of vector you know with the rise of vector databases it seems that there would be a whole lot of",
    "start": "1650120",
    "end": "1655960"
  },
  {
    "text": "kind of vendor related research on how you do that because to your point a moment ago you're talking about data",
    "start": "1655960",
    "end": "1663240"
  },
  {
    "text": "it's such a volume that poor architecture in terms of what's under the hood could have some pretty big",
    "start": "1663240",
    "end": "1669720"
  },
  {
    "text": "consequences there yeah I think that's definitely true and there was a point that was made in one of our last",
    "start": "1669720",
    "end": "1676720"
  },
  {
    "text": "episodes that the vendors for these things are having different priorities",
    "start": "1676720",
    "end": "1681760"
  },
  {
    "text": "that don't always align so some are optimizing for how much data how quickly",
    "start": "1681760",
    "end": "1687799"
  },
  {
    "text": "you can get a large amount of data in but maybe they're not as optimized for",
    "start": "1687799",
    "end": "1693039"
  },
  {
    "text": "the query speed some are optimizing for query speed but it might be really slow to get data in and so that's one piece",
    "start": "1693039",
    "end": "1702919"
  },
  {
    "text": "of it I think another piece of it is how large of an embedding do you need and",
    "start": "1702919",
    "end": "1710000"
  },
  {
    "text": "how complicated is your retrieval problem right I would recommend that people do some testing around this",
    "start": "1710000",
    "end": "1716720"
  },
  {
    "text": "because let's say you have a 100,000 documents that are very very similar one",
    "start": "1716720",
    "end": "1722360"
  },
  {
    "text": "to another or 100,000 images that are very very similar to one another and the",
    "start": "1722360",
    "end": "1728919"
  },
  {
    "text": "retrieval problem is actually semantically very difficult you might need a larger embedding and more kind of",
    "start": "1728919",
    "end": "1737159"
  },
  {
    "text": "power even like optimization around the query like reranking and other things to",
    "start": "1737159",
    "end": "1742399"
  },
  {
    "text": "get the data that you need whereas if you have you know 100,000 images and",
    "start": "1742399",
    "end": "1748360"
  },
  {
    "text": "they're all fairly different well maybe you don't need to go to some of those links so yeah I think that that's also",
    "start": "1748360",
    "end": "1756480"
  },
  {
    "text": "part of this problem and people are still filling out the best practices",
    "start": "1756480",
    "end": "1761760"
  },
  {
    "text": "around some of this partially because it's this kind of new part of the AI",
    "start": "1761760",
    "end": "1767360"
  },
  {
    "text": "stack and partially because things are constantly updating as well so if you",
    "start": "1767360",
    "end": "1772720"
  },
  {
    "text": "use this embedding today there's an better one tomorrow and Vector databases are updating all the time so it's also",
    "start": "1772720",
    "end": "1779360"
  },
  {
    "text": "just a very Dynamic time here as we look at the chart here and there's kind of",
    "start": "1779360",
    "end": "1784720"
  },
  {
    "text": "the three that we referred to earlier that are that are kind of together and those are llm cach logging SL llm Ops",
    "start": "1784720",
    "end": "1793080"
  },
  {
    "text": "and validation first of all could you kind of describe what's encompassed in each of those and also kind of why are",
    "start": "1793080",
    "end": "1801120"
  },
  {
    "text": "they fit together why are we seeing those lumped in one category here one super category yeah so if you think",
    "start": "1801120",
    "end": "1807399"
  },
  {
    "text": "about what we've talked about so far there's this new generative AI stack whether you're doing images or language",
    "start": "1807399",
    "end": "1813519"
  },
  {
    "text": "or whatever there's an application side which might just be the playground or it might be your own application there's a",
    "start": "1813519",
    "end": "1821159"
  },
  {
    "text": "data and resources side which is what we've talked about with integrating apis and data sources and then there's like a",
    "start": "1821159",
    "end": "1828799"
  },
  {
    "text": "third arm here which is the model side and all of those are kind of connected",
    "start": "1828799",
    "end": "1834039"
  },
  {
    "text": "through the orchestration layer the automation layer the convenience layer whatever you want to end up calling that",
    "start": "1834039",
    "end": "1839880"
  },
  {
    "text": "so on now we're kind of going to this third arm of the model side and we can",
    "start": "1839880",
    "end": "1846840"
  },
  {
    "text": "come back to it here in a second but one side of this is just hosting the models and having an API around them which we",
    "start": "1846840",
    "end": "1852519"
  },
  {
    "text": "can come back to but between the model and your orchestration layer almost as",
    "start": "1852519",
    "end": "1858720"
  },
  {
    "text": "um maybe we could call it like model middleware I I'll just go ahead coin",
    "start": "1858720",
    "end": "1864519"
  },
  {
    "text": "that I just coined it on maybe people are already referring to it that way and I didn't coin it but model middleware",
    "start": "1864519",
    "end": "1871399"
  },
  {
    "text": "sits kind of either wrapping around or in between your orchestration layer and",
    "start": "1871399",
    "end": "1877320"
  },
  {
    "text": "your model hosting and these are the things that you're referring to around caching logging validation probably the",
    "start": "1877320",
    "end": "1883960"
  },
  {
    "text": "one that people are most familiar with if they are familiar with one of these",
    "start": "1883960",
    "end": "1889799"
  },
  {
    "text": "would be the logging layer which is again something that is kind of a Dev",
    "start": "1889799",
    "end": "1896159"
  },
  {
    "text": "opsy infrastructure term but here we might think of very specific type of",
    "start": "1896159",
    "end": "1902240"
  },
  {
    "text": "logging like model logging which might be more natively supported in things",
    "start": "1902240",
    "end": "1908799"
  },
  {
    "text": "like weights and biases or clear ml or these other kind of ml Ops type of",
    "start": "1908799",
    "end": "1915919"
  },
  {
    "text": "solutions where you're logging requests that are coming in prompts that are",
    "start": "1915919",
    "end": "1921880"
  },
  {
    "text": "being provided response time GPU usage all the kind of model related things and",
    "start": "1921880",
    "end": "1930399"
  },
  {
    "text": "you want to put those into you know graphs and other things so there may be",
    "start": "1930399",
    "end": "1935559"
  },
  {
    "text": "specific kinds of logging so how quickly on average is my model responding what",
    "start": "1935559",
    "end": "1943240"
  },
  {
    "text": "is the latency between making a prompt or a request and getting a resp response",
    "start": "1943240",
    "end": "1948679"
  },
  {
    "text": "how much GPU usage is my model using and do I need more replicas of that model",
    "start": "1948679",
    "end": "1955200"
  },
  {
    "text": "these sorts of things can be really helpful as you're putting things into production so that's a a first of these",
    "start": "1955200",
    "end": "1962000"
  },
  {
    "text": "middleware [Music]",
    "start": "1962000",
    "end": "1976840"
  },
  {
    "text": "layers [Music] so Chris um the other middle Weare",
    "start": "1976840",
    "end": "1983240"
  },
  {
    "text": "layers I would say that have been called out at least in what we're looking at is are validation and caching so I'll talk",
    "start": "1983240",
    "end": "1990519"
  },
  {
    "text": "about caching and we can talk about validation a little bit which is close to my heart but caching uh let's say",
    "start": "1990519",
    "end": "1998000"
  },
  {
    "text": "that again this already happens in a lot of different applications so think about",
    "start": "1998000",
    "end": "2003720"
  },
  {
    "text": "like a general API application if someone makes a request for data in your",
    "start": "2003720",
    "end": "2008799"
  },
  {
    "text": "database and you retrieve that data and then the next user asks for the same",
    "start": "2008799",
    "end": "2013960"
  },
  {
    "text": "data in your database the proper and smart thing to do would not be to do two",
    "start": "2013960",
    "end": "2020559"
  },
  {
    "text": "retrievals right but to cach that data in the application layer in memory so",
    "start": "2020559",
    "end": "2026720"
  },
  {
    "text": "that you can respond very quickly and reduce the number of times that you're reaching out to your database and things",
    "start": "2026720",
    "end": "2031880"
  },
  {
    "text": "like that I notice in this chart that some of the examples that they put for caching such as r and SQL light and such",
    "start": "2031880",
    "end": "2039000"
  },
  {
    "text": "are are very typical and long-term players in the appdev world yep so does",
    "start": "2039000",
    "end": "2044559"
  },
  {
    "text": "that beg the question at least for me begging the question that when you're",
    "start": "2044559",
    "end": "2049599"
  },
  {
    "text": "caching like you're really talking about for the input here's an output whether it goes to a model or not is it is it",
    "start": "2049599",
    "end": "2056158"
  },
  {
    "text": "really just application data that you're caching at that point so it's caching in that sense but I think there's maybe",
    "start": "2056159",
    "end": "2063079"
  },
  {
    "text": "implications to it that go beyond kind of normal caching so",
    "start": "2063079",
    "end": "2068240"
  },
  {
    "text": "if you you know running AI models is expensive most of the time because you",
    "start": "2068240",
    "end": "2074079"
  },
  {
    "text": "have to run them on some type of specialized Hardware right if I've got a model running on two A1 100s right I",
    "start": "2074079",
    "end": "2083000"
  },
  {
    "text": "would rather not have four replicas of that model I would rather just have one",
    "start": "2083000",
    "end": "2089599"
  },
  {
    "text": "if I can um because I don't want to pay for all those gpus so part of it is really related to cost and performance",
    "start": "2089599",
    "end": "2097800"
  },
  {
    "text": "so it's also for a large model this is mainly for large models I would say",
    "start": "2097800",
    "end": "2104079"
  },
  {
    "text": "you've got a lot of cost either because you're running that model on really",
    "start": "2104079",
    "end": "2110119"
  },
  {
    "text": "specialized Hardware or because like if I'm calling out to GPT 4 it's really",
    "start": "2110119",
    "end": "2116280"
  },
  {
    "text": "expensive to do a lot of requests to gp4 right so in order to deal with that if",
    "start": "2116280",
    "end": "2122760"
  },
  {
    "text": "you have a prompt input you can cache that prompt and if users are asking the",
    "start": "2122760",
    "end": "2127920"
  },
  {
    "text": "same question I would rather just send them back the same response from gp4 my",
    "start": "2127920",
    "end": "2133920"
  },
  {
    "text": "large llama 270 billion model or whatever it is I'm going to respond to them the same way based on the same or a",
    "start": "2133920",
    "end": "2142880"
  },
  {
    "text": "similar input the other implication to this which in my mind it sort of fits",
    "start": "2142880",
    "end": "2149079"
  },
  {
    "text": "into caching but maybe not in the traditional sense so I normally think of",
    "start": "2149079",
    "end": "2155079"
  },
  {
    "text": "caching as like oh I'm going to cash things things in memory or locally at the application layer but if you're",
    "start": "2155079",
    "end": "2162240"
  },
  {
    "text": "caching prompts and responses there's a real opportunity to leverage that data",
    "start": "2162240",
    "end": "2170800"
  },
  {
    "text": "to build your own sort of competitive Moe with your specific generative AI",
    "start": "2170800",
    "end": "2177920"
  },
  {
    "text": "application so for example like you've got a user base they're prompting all of",
    "start": "2177920",
    "end": "2183359"
  },
  {
    "text": "these sorts of things all of a sudden if you're saving all of that data and the responses that you're giving you're",
    "start": "2183359",
    "end": "2190079"
  },
  {
    "text": "essentially starting to form your own domain specific data set that you could",
    "start": "2190079",
    "end": "2195800"
  },
  {
    "text": "kind of Leverage in a very competitive way in in kind of two senses one is",
    "start": "2195800",
    "end": "2201480"
  },
  {
    "text": "right now if you're using a really expensive model to make those responses maybe you start saving those",
    "start": "2201480",
    "end": "2209560"
  },
  {
    "text": "responses from the really expensive model and you can use that data to fine-tune a smaller model that might be",
    "start": "2209560",
    "end": "2216560"
  },
  {
    "text": "more performant and cost effective in the long term so it's operational kind of play the other way is if you're",
    "start": "2216560",
    "end": "2223599"
  },
  {
    "text": "Gathering that over time and you actually have the resources to human label that or give your own human",
    "start": "2223599",
    "end": "2230079"
  },
  {
    "text": "preferences on that or certain annotations on that that now is your own",
    "start": "2230079",
    "end": "2237119"
  },
  {
    "text": "kind of advantage in fine-tuning either one of these generative models or your",
    "start": "2237119",
    "end": "2242640"
  },
  {
    "text": "own internal model for the domain that you're working in so it's caching but",
    "start": "2242640",
    "end": "2249000"
  },
  {
    "text": "that's almost like a feedback or data curation side of things as well so you",
    "start": "2249000",
    "end": "2255760"
  },
  {
    "text": "mentioned earlier that validation was close to your heart yeah so as our users",
    "start": "2255760",
    "end": "2261680"
  },
  {
    "text": "know I think part of the tooling that I'm building with prediction guard would fit into this category it would actually",
    "start": "2261680",
    "end": "2268119"
  },
  {
    "text": "span I think more categories it kind of span between validation and",
    "start": "2268119",
    "end": "2273359"
  },
  {
    "text": "orchestration and model hosting so there's kind of a little bit of overlap there but this validation layer really",
    "start": "2273359",
    "end": "2281200"
  },
  {
    "text": "has to do with the fact that generative AI models across the board I think",
    "start": "2281200",
    "end": "2286560"
  },
  {
    "text": "people would say are there's a lot of concerns around reliability privacy security compliance",
    "start": "2286560",
    "end": "2294160"
  },
  {
    "text": "what have you and so there's a rising number of tools that are addressing some",
    "start": "2294160",
    "end": "2300319"
  },
  {
    "text": "or all of those issues so whether it be putting controls on the output of your",
    "start": "2300319",
    "end": "2305359"
  },
  {
    "text": "llm again think about this like a middle layer my llm produces something harmful",
    "start": "2305359",
    "end": "2311520"
  },
  {
    "text": "as output or my generative AI model generates an image that is not fit for",
    "start": "2311520",
    "end": "2317560"
  },
  {
    "text": "my users I want to somehow catch that and correct it if I can right or I want",
    "start": "2317560",
    "end": "2324960"
  },
  {
    "text": "to put certain things into my model but I want to make sure that I'm not putting in either private or sensitive data or I",
    "start": "2324960",
    "end": "2332079"
  },
  {
    "text": "want to structure the output of my model in a certain way into certain structures or types like like Json or integer or",
    "start": "2332079",
    "end": "2339000"
  },
  {
    "text": "float all of these sorts of things kind of I personally would break this apart",
    "start": "2339000",
    "end": "2344680"
  },
  {
    "text": "probably into maybe like validation type and structure and then",
    "start": "2344680",
    "end": "2351760"
  },
  {
    "text": "like security related things because there's a lot here there's validation which is like is my output what I want",
    "start": "2351760",
    "end": "2358319"
  },
  {
    "text": "it to be there's security related things which is am I okay with putting the",
    "start": "2358319",
    "end": "2364400"
  },
  {
    "text": "current request into my model and or sending the output back to my users and",
    "start": "2364400",
    "end": "2370520"
  },
  {
    "text": "then there's type and structuring things so with images like is the image upscaled appropriately for my use case",
    "start": "2370520",
    "end": "2378359"
  },
  {
    "text": "or with text if I'm putting in something and wanting Json back is it actually valid Json that's more of a structure",
    "start": "2378359",
    "end": "2386520"
  },
  {
    "text": "type checking type of thing so there's a lot in this category and I think you can",
    "start": "2386520",
    "end": "2392200"
  },
  {
    "text": "you're probably getting the fact that I'm thinking a lot about this and and there's a lot here but um yeah other",
    "start": "2392200",
    "end": "2399240"
  },
  {
    "text": "things fitting into this category would I think cool one um called rebuff which",
    "start": "2399240",
    "end": "2404440"
  },
  {
    "text": "uh is doing kind of checking for prompt injections for example that's like part of that security side of things there's",
    "start": "2404440",
    "end": "2412040"
  },
  {
    "text": "things um like prediction guard and guard rails guidance outlines now that",
    "start": "2412040",
    "end": "2417720"
  },
  {
    "text": "do type and structure type of things there is also I would say a layer of",
    "start": "2417720",
    "end": "2424160"
  },
  {
    "text": "this which a lot of people are implementing in the kind of roll your own python DIY way as well which in uh",
    "start": "2424160",
    "end": "2432880"
  },
  {
    "text": "prediction guard we Implement some of these but also people are implementing them in their own systems like",
    "start": "2432880",
    "end": "2439200"
  },
  {
    "text": "self-consistency sampling like calling a mo model multiple times and either using",
    "start": "2439200",
    "end": "2444760"
  },
  {
    "text": "the out choosing between the output or merging the output in some interesting way or things like that this sort of",
    "start": "2444760",
    "end": "2451760"
  },
  {
    "text": "consistency stuff I think a lot of people are are rolling their own too what do you think is start winding up",
    "start": "2451760",
    "end": "2458480"
  },
  {
    "text": "here what do you think are some of the the takeaways from this chart you know or what brings top of mind uh things",
    "start": "2458480",
    "end": "2465760"
  },
  {
    "text": "that people as they look at it might benefit from how would you see it in the large yeah it's a good question I think",
    "start": "2465760",
    "end": "2472560"
  },
  {
    "text": "one major takeaway one thing to keep in mind is the model is only a small part",
    "start": "2472560",
    "end": "2479880"
  },
  {
    "text": "of the whole app stack here in a similar way to like used to when a thing existed",
    "start": "2479880",
    "end": "2485839"
  },
  {
    "text": "called data science we would say uh training a model is only a very small",
    "start": "2485839",
    "end": "2491359"
  },
  {
    "text": "part of the kind of endtoend data science life cycle of a project um",
    "start": "2491359",
    "end": "2497720"
  },
  {
    "text": "there's a lot of other things involved and I think here you know you can make a similar conclusion that the tendency is",
    "start": "2497720",
    "end": "2503960"
  },
  {
    "text": "to think of the model as the application but there's really a lot more involved and there's our friends over at latent",
    "start": "2503960",
    "end": "2510640"
  },
  {
    "text": "space would say this is really where AI engineering comes into play this space",
    "start": "2510640",
    "end": "2516560"
  },
  {
    "text": "of AI engineering is seems to be developing into a real thing whether you",
    "start": "2516560",
    "end": "2522720"
  },
  {
    "text": "call it that word or not it is part of what this is so that's one takeaway I",
    "start": "2522720",
    "end": "2528640"
  },
  {
    "text": "think the other takeaway is maybe just kind of forming this mental model around",
    "start": "2528640",
    "end": "2535800"
  },
  {
    "text": "these three spokes of the stack so you've got your app an app hosting",
    "start": "2535800",
    "end": "2542119"
  },
  {
    "text": "you've got your data and your resources and you've got your model and your model middleware and all that kind of middle",
    "start": "2542119",
    "end": "2548559"
  },
  {
    "text": "Hub would be some sort of orchestration that you're performing either in a DIY",
    "start": "2548559",
    "end": "2554520"
  },
  {
    "text": "way or with things like Ling chain to connect all of those pieces together so",
    "start": "2554520",
    "end": "2559839"
  },
  {
    "text": "you're probably horseed by now because we've pulled so much information out of you this was a really really good dive",
    "start": "2559839",
    "end": "2567599"
  },
  {
    "text": "you know it's one particular Publisher's way of looking at it but we've never",
    "start": "2567599",
    "end": "2572760"
  },
  {
    "text": "really dived into all the components of the infrastructure of a stack with this kind of and and I think most people",
    "start": "2572760",
    "end": "2579359"
  },
  {
    "text": "haven't had a chance to see it yet because so much of this has really Arisen in recent months thanks for kind",
    "start": "2579359",
    "end": "2585079"
  },
  {
    "text": "of uh wearing half of a guest hat along the way here and taking us through this",
    "start": "2585079",
    "end": "2590599"
  },
  {
    "text": "on on this fully connected episode yeah and I think um in terms of learning",
    "start": "2590599",
    "end": "2595880"
  },
  {
    "text": "about these things I think people can check out our show notes we'll have a link to the diagram that we've been",
    "start": "2595880",
    "end": "2603559"
  },
  {
    "text": "discussing here I would say learning wise this helps you organize your",
    "start": "2603559",
    "end": "2608760"
  },
  {
    "text": "thought process but to really get an intuition around these things you can look at various examples in this diagram",
    "start": "2608760",
    "end": "2615400"
  },
  {
    "text": "and go to their docs and try out some of that there's a variety of kind of endtoend examples as well that are",
    "start": "2615400",
    "end": "2622960"
  },
  {
    "text": "pretty typical these days like in language if you're doing kind of a chat over your docs thing that involves a",
    "start": "2622960",
    "end": "2629040"
  },
  {
    "text": "model and a data layer and an application layer so just building one of these example apps I think could give",
    "start": "2629040",
    "end": "2637200"
  },
  {
    "text": "people the kind of learning and that sort of thing that they need but um yeah",
    "start": "2637200",
    "end": "2642440"
  },
  {
    "text": "it's been fun I it's always helpful to talk these things out loud with You Chris I I find it very useful well I",
    "start": "2642440",
    "end": "2648480"
  },
  {
    "text": "learn a lot every time we do this so thanks a lot man yeah yeah we'll we'll see you next week see you next",
    "start": "2648480",
    "end": "2654400"
  },
  {
    "text": "[Music]",
    "start": "2654400",
    "end": "2661880"
  },
  {
    "text": "week thank you for listening to practical AI your next step is to",
    "start": "2661880",
    "end": "2667240"
  },
  {
    "text": "subscribe now if you haven't already and if you're a longtime listener of the show help us reach more people by",
    "start": "2667240",
    "end": "2673520"
  },
  {
    "text": "sharing practical AI with your friends and colleagues thanks once again to fastly and fly for partnering with us to",
    "start": "2673520",
    "end": "2679599"
  },
  {
    "text": "bring you all change talk podcasts check out what they're up to at fastly.com and",
    "start": "2679599",
    "end": "2685000"
  },
  {
    "text": "fly.io and to our beat freaking residents breakmaster cylinder for continuously cranking out the best beats",
    "start": "2685000",
    "end": "2690760"
  },
  {
    "text": "in the biz that's all for now we'll talk to you again next [Music]",
    "start": "2690760",
    "end": "2696040"
  },
  {
    "text": "time [Music]",
    "start": "2696040",
    "end": "2705920"
  }
]
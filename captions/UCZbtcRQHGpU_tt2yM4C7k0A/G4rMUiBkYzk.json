[
  {
    "text": "B with for change log is provided by fastly learn more at fastly.com we move",
    "start": "80",
    "end": "6040"
  },
  {
    "text": "fast and fix things here at change log because of rbar check them out at rar.com and we're hosted on Leno servers",
    "start": "6040",
    "end": "12799"
  },
  {
    "text": "head to lin.com changelog this episode is brought to you by digital ocean they now have CPU",
    "start": "12799",
    "end": "19560"
  },
  {
    "text": "optimized droplets with dedicated hyper threads from best in-class Intel CPUs",
    "start": "19560",
    "end": "25199"
  },
  {
    "text": "for all your machine learning and batch processing needs you can easily spin up their oneclick machine learning and AI",
    "start": "25199",
    "end": "31039"
  },
  {
    "text": "application image this gives you immediate access to Python 3 R Jupiter",
    "start": "31039",
    "end": "36200"
  },
  {
    "text": "notebook tensor flow s kit and pytorch use our special link to get a $100",
    "start": "36200",
    "end": "42239"
  },
  {
    "text": "credit for digital ocean and try today for free head to do. changelog once",
    "start": "42239",
    "end": "48160"
  },
  {
    "text": "again do. [Music]",
    "start": "48160",
    "end": "58920"
  },
  {
    "text": "changelog welcome to practical AI a weekly podcast",
    "start": "58920",
    "end": "66479"
  },
  {
    "text": "about making artificial intelligence practical productive and accessible to everyone this is where conversations",
    "start": "66479",
    "end": "72880"
  },
  {
    "text": "around AI machine learning and data science happen join the community and select with us around various topics of",
    "start": "72880",
    "end": "78240"
  },
  {
    "text": "the show at change.com Community follow us on Twitter we're at practical aifm",
    "start": "78240",
    "end": "83560"
  },
  {
    "text": "and now on the [Music] show hi there this is Chris Benson and",
    "start": "83560",
    "end": "91720"
  },
  {
    "text": "welcome to another fully connected episode of practical AI where Daniel and I will keep you fully connected with",
    "start": "91720",
    "end": "98360"
  },
  {
    "text": "everything that's happening in the AI Community uh we take some time to discuss the latest AI news and we dig",
    "start": "98360",
    "end": "104159"
  },
  {
    "text": "into learning resources to help you level up on your machine learning game how's it going today Daniel oh it's going great I'm excited about some of",
    "start": "104159",
    "end": "110840"
  },
  {
    "text": "the news we got going on today yeah it's uh I love the format the way we're diving into it for those of you who may",
    "start": "110840",
    "end": "117079"
  },
  {
    "text": "have listened to our last fully connected episode it I think it was uh hopefully it was as good experience for",
    "start": "117079",
    "end": "122399"
  },
  {
    "text": "you um we're definitely listening to your feedback trying to shape the show to better serve your needs going forward",
    "start": "122399",
    "end": "128640"
  },
  {
    "text": "yeah and I think that there's I mean I've been talking to a couple people this week there's just so much going on it's good to just have a chance to for",
    "start": "128640",
    "end": "136040"
  },
  {
    "text": "me personally just to have a chance to talk through some of these things cuz there's so much going on there's so many",
    "start": "136040",
    "end": "141760"
  },
  {
    "text": "topics there's so much jargon to kind of uh try to put some of that into words is",
    "start": "141760",
    "end": "147040"
  },
  {
    "text": "I think uh helpful and and uh we're kind of learning along with uh everybody",
    "start": "147040",
    "end": "152959"
  },
  {
    "text": "listening so uh keep us keep us uh honest and let us know what we get right or wrong as we're going through this",
    "start": "152959",
    "end": "158959"
  },
  {
    "text": "stuff yep and if you haven't already we hope you'll join us in our slack community at changel log.com and we have",
    "start": "158959",
    "end": "166120"
  },
  {
    "text": "great feedback great conversations that are happening there between the shows we're also uh on LinkedIn in a LinkedIn",
    "start": "166120",
    "end": "172200"
  },
  {
    "text": "group and we hope you'll join us on LinkedIn you can just search for practical AI awesome well this week as I",
    "start": "172200",
    "end": "178400"
  },
  {
    "text": "was kind of going through and looking through through Twitter and various news sources one of the things that or the",
    "start": "178400",
    "end": "185319"
  },
  {
    "text": "themes that came up when I was looking through things was really having to do with all the things that happen after we",
    "start": "185319",
    "end": "193680"
  },
  {
    "text": "train our AI so the question is you know we've trained an AI model what next so",
    "start": "193680",
    "end": "200200"
  },
  {
    "text": "in your opinion Chris what what happens next what happens after you train an AI model how you know what do you do how is",
    "start": "200200",
    "end": "206519"
  },
  {
    "text": "it useful yeah it's funny before I answer that I'll just note that this is the side of things that we tend not to",
    "start": "206519",
    "end": "212560"
  },
  {
    "text": "uh to think about too much until we get there you know the courses that are out there really focused on training and",
    "start": "212560",
    "end": "218560"
  },
  {
    "text": "architecture and you know people will kind of say okay I've got it and but your model doesn't do any good until you",
    "start": "218560",
    "end": "223840"
  },
  {
    "text": "deploy it into the real world and it's it's useful for your customer for your end user I know that as I was learning",
    "start": "223840",
    "end": "230000"
  },
  {
    "text": "my way up through it uh through the field this has been a bit of a challenge because uh the deployment environments",
    "start": "230000",
    "end": "235760"
  },
  {
    "text": "and what you're targeting for deployment can be very different and the standards have been slow to arrive there that's",
    "start": "235760",
    "end": "242280"
  },
  {
    "text": "changing now but um it's definitely uh as I started out before some of these",
    "start": "242280",
    "end": "247319"
  },
  {
    "text": "standard approaches were starting to come into being every vendor was different and that was a real pain yeah",
    "start": "247319",
    "end": "253200"
  },
  {
    "text": "and for those of you that are new to some of this jargon too what we're talking about here you know you can kind of think about this AI model as a sort",
    "start": "253200",
    "end": "260799"
  },
  {
    "text": "of really complicated function that's has a bunch of parameters in it and so when we do training we're using a whole",
    "start": "260799",
    "end": "267400"
  },
  {
    "text": "lot of data through this training proc process to tunee and tweak th all of those parameters of our model so we",
    "start": "267400",
    "end": "273520"
  },
  {
    "text": "might have you know millions of these parameters that parameterize our AI model function to do something you know",
    "start": "273520",
    "end": "280120"
  },
  {
    "text": "to you know transform an incoming image into an indication of objects in that",
    "start": "280120",
    "end": "285240"
  },
  {
    "text": "image for example so the question is you know once we've gone through that process and set our parameters now we",
    "start": "285240",
    "end": "291880"
  },
  {
    "text": "have this function that can transform data what do we do with it so what are what are some of the things that you've",
    "start": "291880",
    "end": "298280"
  },
  {
    "text": "done after training or you've needed to do after training or you've seen other people do after this kind of training",
    "start": "298280",
    "end": "305080"
  },
  {
    "text": "process Chris well honestly uh a lot of it involves uh cooperating with other teams in midsize or larger companies if",
    "start": "305080",
    "end": "311960"
  },
  {
    "text": "you're in a small company it may be just yourself but you've got to a model is only useful if you are able to integrate",
    "start": "311960",
    "end": "318400"
  },
  {
    "text": "it into some software that's going to go out uh onto your target device where you're deploying and um and that's a",
    "start": "318400",
    "end": "324639"
  },
  {
    "text": "whole different set of skills yeah so when you say integrate it what what is the integration or what are you",
    "start": "324639",
    "end": "331919"
  },
  {
    "text": "integrating really so you would take a trained model and you have to put it",
    "start": "331919",
    "end": "337840"
  },
  {
    "text": "into a software package and and therefore the model has to be in a form that's usable and by usable it means you",
    "start": "337840",
    "end": "344560"
  },
  {
    "text": "have a a trained neural network that is able to operate on the hardware and",
    "start": "344560",
    "end": "349720"
  },
  {
    "text": "software environment that you need to put it in uh in the end and that it needs to be able to have access to the",
    "start": "349720",
    "end": "355120"
  },
  {
    "text": "data that is going to be feeding through it for inferencing purposes so that you're actually operating and and those",
    "start": "355120",
    "end": "360280"
  },
  {
    "text": "are there's a lot of stuff to think about there that your traditional data scientists may never have had to deal",
    "start": "360280",
    "end": "366800"
  },
  {
    "text": "with before there's a lot of software engineering and maybe even systems engineering involved in trying to get it",
    "start": "366800",
    "end": "371840"
  },
  {
    "text": "out there and so I thought this was a great topic to go ahead and delve into and uh and talk about what those pain",
    "start": "371840",
    "end": "377319"
  },
  {
    "text": "points are yeah so I I'm glad you kind of brought off the software engineering side of things and and you know if",
    "start": "377319",
    "end": "382720"
  },
  {
    "text": "you're if you're trying to code some you know AI stuff whether you're a software",
    "start": "382720",
    "end": "388199"
  },
  {
    "text": "engineer or not you probably know that you know this idea of functions or handlers classes are part of uh part of",
    "start": "388199",
    "end": "395520"
  },
  {
    "text": "software that we build and so I think you know in my mind what what as I'm kind of translating what you're saying",
    "start": "395520",
    "end": "401800"
  },
  {
    "text": "Chris I'm thinking about in a web server that's serving a website or something right we might have a whole bunch of",
    "start": "401800",
    "end": "407919"
  },
  {
    "text": "functions that do something like you give it a specific request and it gives you content back maybe a a picture or a",
    "start": "407919",
    "end": "414440"
  },
  {
    "text": "video or just some HTML or Json or something and so in integrating AI into",
    "start": "414440",
    "end": "421199"
  },
  {
    "text": "that really we're saying that at some point in those functions or classes or other things that are part of the",
    "start": "421199",
    "end": "427599"
  },
  {
    "text": "software that's running in production in our company somewhere in there we're actually accessing this model that",
    "start": "427599",
    "end": "434319"
  },
  {
    "text": "you've mentioned and so it has to be in some form like you said to be accessed and most of the time that's a trained",
    "start": "434319",
    "end": "441199"
  },
  {
    "text": "form in other words we train our model and then we save it somehow and then we load that saved or serialized model into",
    "start": "441199",
    "end": "449199"
  },
  {
    "text": "one of of these functions and then just execute the data transformation that it does like I said from image to objects",
    "start": "449199",
    "end": "455919"
  },
  {
    "text": "or something like that and that process of utilizing the function is is called inference so with that I don't know did",
    "start": "455919",
    "end": "463720"
  },
  {
    "text": "I miss anything there Chris or any jargon that you think is is relevant no I think another word that you might use",
    "start": "463720",
    "end": "469520"
  },
  {
    "text": "is to simplify things is just think of it as you need to wrap your model up as a software component and just as your",
    "start": "469520",
    "end": "476720"
  },
  {
    "text": "whatever your software that you're deploying may have a number of components that that make it up the",
    "start": "476720",
    "end": "481759"
  },
  {
    "text": "models are also components they're components wrapped in whatever language you're deploying in so it may be that",
    "start": "481759",
    "end": "486960"
  },
  {
    "text": "while you're training your model in Python in tensorflow or pytorch or",
    "start": "486960",
    "end": "492879"
  },
  {
    "text": "whatever you're using uh it may be that you're deploying in C your C++ or Java",
    "start": "492879",
    "end": "498120"
  },
  {
    "text": "or I know you and I love go as well and and those May to where you're you're you're doing the inferencing as oppos to",
    "start": "498120",
    "end": "503759"
  },
  {
    "text": "the training through that way and that so and you you think of the model as a piece of that software component going",
    "start": "503759",
    "end": "509080"
  },
  {
    "text": "forward and and it's part of deployment you think of all the things that that surround software engineering and",
    "start": "509080",
    "end": "514640"
  },
  {
    "text": "deployment go into that yeah so when you've deployed models in this way a lot of times how what what's been the access",
    "start": "514640",
    "end": "522800"
  },
  {
    "text": "pattern or how have people interacted with the model I know for me it's been a lot of times integrating the model into",
    "start": "522800",
    "end": "529040"
  },
  {
    "text": "some sort of API we can talk about a little bit more later as related to some of the news but essentially just where",
    "start": "529040",
    "end": "536519"
  },
  {
    "text": "it's integrated into kind of like a web service where you would make a request for a prediction and get back a result",
    "start": "536519",
    "end": "542480"
  },
  {
    "text": "have you seen other other patterns that's that's the one I've seen most often probably yeah it's always in in",
    "start": "542480",
    "end": "548519"
  },
  {
    "text": "the form using it Loosely as a service if I've seen web services use most often on server side where you may not be uh",
    "start": "548519",
    "end": "556279"
  },
  {
    "text": "constrained by your connectivity and stuff uh a lot of times though if your deployment Target is an iot device or a",
    "start": "556279",
    "end": "562839"
  },
  {
    "text": "mobile device you you still have an API but it's really it is operating as a function you know to use the the phrase",
    "start": "562839",
    "end": "568600"
  },
  {
    "text": "you were using earlier that's that's just the API may not be a public API that your software component is using",
    "start": "568600",
    "end": "574720"
  },
  {
    "text": "inside your your group of software components that constitute Your solution it doesn't really matter uh in my view",
    "start": "574720",
    "end": "581480"
  },
  {
    "text": "so long as that you are essentially following the best practices of the environment in which you're coding and",
    "start": "581480",
    "end": "586839"
  },
  {
    "text": "what your your deployment Target is made up of so makes sense yes that brings us right into really some of the news that",
    "start": "586839",
    "end": "594160"
  },
  {
    "text": "is related to this that that came up this week first let's let's kind of focus in on this inference service or",
    "start": "594160",
    "end": "600720"
  },
  {
    "text": "servers bit of things one of the things that I saw come out this week was",
    "start": "600720",
    "end": "605800"
  },
  {
    "text": "announcement from Nvidia that their tensor RT inference server was now open",
    "start": "605800",
    "end": "612920"
  },
  {
    "text": "source so tensor RT I think it's been around a little bit but this was the official announcement of the tensor RT",
    "start": "612920",
    "end": "620360"
  },
  {
    "text": "inference server officially as an open- source project now so this is this is a",
    "start": "620360",
    "end": "626839"
  },
  {
    "text": "project from Nvidia and part of the goal in my understanding of tensor RT is to",
    "start": "626839",
    "end": "634920"
  },
  {
    "text": "perform these inferences that we've been talking about so post trainining your model when you're actually utilizing",
    "start": "634920",
    "end": "641000"
  },
  {
    "text": "your model is to do that in a very very optimized way maybe on certain",
    "start": "641000",
    "end": "646240"
  },
  {
    "text": "specialized hardware for example on gpus which Nvidia of course is concerned with",
    "start": "646240",
    "end": "652560"
  },
  {
    "text": "so um so it was exciting to see this actually be open- sourced and available",
    "start": "652560",
    "end": "658000"
  },
  {
    "text": "for the community it seems like there's a bunch of great stuff in there it also includes examples of how developers",
    "start": "658000",
    "end": "664920"
  },
  {
    "text": "could extend tensor RT to do things like custom pre- and postprocessing and",
    "start": "664920",
    "end": "670040"
  },
  {
    "text": "integrate additional framework back in so more than just tensor flow but like",
    "start": "670040",
    "end": "675320"
  },
  {
    "text": "Cafe 2 and others via the Onyx framework that we've talked about here quite a bit",
    "start": "675320",
    "end": "680560"
  },
  {
    "text": "which is pretty cool so yeah I was excited to see this I know that you've utilized gpus probably more than than I",
    "start": "680560",
    "end": "687000"
  },
  {
    "text": "have Chris have you ever tried to integrate the inference side of things on gpus uh yeah it's I know working at",
    "start": "687000",
    "end": "694800"
  },
  {
    "text": "at some of the the employers that I've had and for our cases we always have a product or service that we're supporting",
    "start": "694800",
    "end": "700839"
  },
  {
    "text": "we're always deploying and so you know one of the the great things about tensorrt was really the first one that I",
    "start": "700839",
    "end": "707160"
  },
  {
    "text": "got into in it kind of at scale and it does a number of optimizations to your",
    "start": "707160",
    "end": "712959"
  },
  {
    "text": "model uh specific to deployment So you you're essentially taking your model and",
    "start": "712959",
    "end": "718440"
  },
  {
    "text": "putting it through this this process that Nvidia has where it it optimizes it for inference and then deploys it and um",
    "start": "718440",
    "end": "724680"
  },
  {
    "text": "I'm not really surprised to see that Nvidia has open source their infant server because they have uh they've been",
    "start": "724680",
    "end": "730320"
  },
  {
    "text": "leading the way in a lot of areas and and forcing some of the other previous um you know giants like Intel to play",
    "start": "730320",
    "end": "737760"
  },
  {
    "text": "catchup for a while but now we're starting to see the market stabilize a little bit and and seeing more than one",
    "start": "737760",
    "end": "743000"
  },
  {
    "text": "player out there and so if they want to continue to be the leader open sourcing",
    "start": "743000",
    "end": "748160"
  },
  {
    "text": "their uh their t RT technology is a is a very sensible thing to do to make it accessible so I applaud the move on",
    "start": "748160",
    "end": "754600"
  },
  {
    "text": "their on their part and wish they had done this earlier when we were first learning it because it you know being",
    "start": "754600",
    "end": "759760"
  },
  {
    "text": "open source now we can we can figure out what our problems are on our own a little bit better obviously by going through the source code and uh and not",
    "start": "759760",
    "end": "766639"
  },
  {
    "text": "having to worry as much about bugs that aren't documented that kind of thing so uh it's it's a great move on nvidia's part yeah and um I mean the I guess one",
    "start": "766639",
    "end": "774560"
  },
  {
    "text": "thing to point out here um and correct me if I'm wrong because I think you have more more experience here but it seems",
    "start": "774560",
    "end": "780680"
  },
  {
    "text": "like tensor RT a lot of the focus is in optimization not necessarily on the kind",
    "start": "780680",
    "end": "786680"
  },
  {
    "text": "of setting up an API to access your that's correct your model although I do",
    "start": "786680",
    "end": "792680"
  },
  {
    "text": "see that you know they have this statement in the article about you know to help developers with their efforts",
    "start": "792680",
    "end": "798199"
  },
  {
    "text": "the tensor uh inference server documentation includes various things including I think there is a tutorial in",
    "start": "798199",
    "end": "805160"
  },
  {
    "text": "there that they've Illustrated how to set up a rest API with with tensor RT",
    "start": "805160",
    "end": "810399"
  },
  {
    "text": "and um we'll link that in the in the show notes of course but um I think that's definitely a helpful thing cuz at",
    "start": "810399",
    "end": "816560"
  },
  {
    "text": "some points I've seen a bunch of it's hard for me at least when I see a bunch of stuff about optimization um but then",
    "start": "816560",
    "end": "823079"
  },
  {
    "text": "I still struggle with the integration part like we talked about initially so I'm glad to see them at least uh have",
    "start": "823079",
    "end": "829160"
  },
  {
    "text": "some some examples in that regard yeah I think uh I think tensor RT started with",
    "start": "829160",
    "end": "834639"
  },
  {
    "text": "with those deployment optimizations and that was kind of its foundation but it's definitely provided more and more tools",
    "start": "834639",
    "end": "841160"
  },
  {
    "text": "for developers and devops Engineers to be able to get this out into the real world and I and and we're seeing a",
    "start": "841160",
    "end": "846480"
  },
  {
    "text": "general push in Industry to do that from these companies that are supporting you know with gpus and other and other",
    "start": "846480",
    "end": "852639"
  },
  {
    "text": "Technologies to get that out so it's getting easier and easier to use these and and tensor RT is has definitely been",
    "start": "852639",
    "end": "858360"
  },
  {
    "text": "a big part of that for NVIDIA yeah and speaking of running inference on",
    "start": "858360",
    "end": "864000"
  },
  {
    "text": "Specialized Hardware you were mentioning to me right before the show about um something that you saw from Amazon right",
    "start": "864000",
    "end": "871519"
  },
  {
    "text": "yeah Amazon is like we've seen with other providers they have uh announced",
    "start": "871519",
    "end": "876600"
  },
  {
    "text": "that they're launching their own uh machine learning chip uh it's not something they're planning to sell",
    "start": "876600",
    "end": "881920"
  },
  {
    "text": "they're going to be driving some of the servers uh in aw this way in the article",
    "start": "881920",
    "end": "887040"
  },
  {
    "text": "that I was referencing which was a CNBC article they use the phrase taking on Nvidia and Intel but I think to some",
    "start": "887040",
    "end": "893079"
  },
  {
    "text": "degree it's it's them reducing their risk or dependency on specific vendors I don't think we're going to see you know",
    "start": "893079",
    "end": "899399"
  },
  {
    "text": "vendors out of uh AWS entirely anytime soon but Amazon now uh not only is able",
    "start": "899399",
    "end": "905759"
  },
  {
    "text": "has more tools in the tool set in terms of chips that support these this type of of work but also it gives them leverage",
    "start": "905759",
    "end": "912800"
  },
  {
    "text": "with those vendors uh in terms of the pricing they're going to go so it's all good from my standpoint uh in in that",
    "start": "912800",
    "end": "918880"
  },
  {
    "text": "I'm hoping that this drives prices down it gives them a little bit of Leverage and uh Nvidia Intel and Amazon all end",
    "start": "918880",
    "end": "925600"
  },
  {
    "text": "up lowering prices um I hope it doesn't uh I hope it doesn't take another path from that yeah let me know if you if you",
    "start": "925600",
    "end": "931519"
  },
  {
    "text": "think this is a good analogy because I'm I'm not sure that it is but you know Google like all the cloud providers now",
    "start": "931519",
    "end": "938839"
  },
  {
    "text": "pretty much have GPU support right and I think most of those are Nvidia gpus but",
    "start": "938839",
    "end": "944639"
  },
  {
    "text": "also Google has kind of developed this TPU architecture right which is only available in Google Cloud it seems like",
    "start": "944639",
    "end": "952680"
  },
  {
    "text": "now Amazon is kind of doing maybe not the same type of play but doing some",
    "start": "952680",
    "end": "958319"
  },
  {
    "text": "sort of uh specialized Hardware that's maybe only going to be available in AWS",
    "start": "958319",
    "end": "965120"
  },
  {
    "text": "um is that do you think kind of a similar play or I do I do I think that",
    "start": "965120",
    "end": "970279"
  },
  {
    "text": "and you know if we go back to the episode where we had nvidia's Chief scientist bill D on and he he schooled",
    "start": "970279",
    "end": "977079"
  },
  {
    "text": "us all in you know gpus versus tpus and as6 and and such and you know all the",
    "start": "977079",
    "end": "983240"
  },
  {
    "text": "different Hardware possibilities here uh he talked about kind of the rise of as6 and you know the T you could think think",
    "start": "983240",
    "end": "989040"
  },
  {
    "text": "of the TPU to paraphrase him is is almost a lighter version a GPU has a whole bunch more to it other than just",
    "start": "989040",
    "end": "995720"
  },
  {
    "text": "doing the math necessary in a neural network and so I think you're seeing these kind of very specific chips coming",
    "start": "995720",
    "end": "1003160"
  },
  {
    "text": "out uh with Amazon and with the with the Google TPU and you know the gpus have that same capability but they also have",
    "start": "1003160",
    "end": "1009759"
  },
  {
    "text": "a whole bunch more but it it seems to be that as people really focus on that specialization of doing the Matrix",
    "start": "1009759",
    "end": "1016680"
  },
  {
    "text": "mathematics the matrix multiplication it is it's really kind of commoditizing the industry because they instead of trying",
    "start": "1016680",
    "end": "1022519"
  },
  {
    "text": "to to recreate an entire GPU competitively they're really focusing on this use case yeah but it seems to me at",
    "start": "1022519",
    "end": "1029678"
  },
  {
    "text": "least um and I you know I'm not a hardware expert but it seems to me like all of these people are coming up with",
    "start": "1029679",
    "end": "1035760"
  },
  {
    "text": "all of these different architectures including you know Intel having the midus uh stuff and other people having",
    "start": "1035760",
    "end": "1043959"
  },
  {
    "text": "specialized Hardware it seems like there's just a lot of kind of architectures to support now and that",
    "start": "1043959",
    "end": "1050480"
  },
  {
    "text": "does seem like a challenge you know maybe maybe these projects like Onyx are",
    "start": "1050480",
    "end": "1055960"
  },
  {
    "text": "a way to kind of mitigate that challenge cuz now we might want to train model and",
    "start": "1055960",
    "end": "1061960"
  },
  {
    "text": "we do that let's say in P torture tensor flow but we may want to deploy the",
    "start": "1061960",
    "end": "1067280"
  },
  {
    "text": "inference on one of many different architectures so I don't know that it",
    "start": "1067280",
    "end": "1072440"
  },
  {
    "text": "seems like there needs to be a central point for standardizing our model",
    "start": "1072440",
    "end": "1078240"
  },
  {
    "text": "artifact and I've at least had some success with Onyx in that respect and so those aren't",
    "start": "1078240",
    "end": "1085120"
  },
  {
    "text": "familiar we we've mentioned Onyx on the show a few times so it's the open neural network exchange format which is a",
    "start": "1085120",
    "end": "1091000"
  },
  {
    "text": "collaboration between a bunch of people including uh Facebook and um Microsoft",
    "start": "1091000",
    "end": "1096120"
  },
  {
    "text": "and Amazon I think but it's still pretty rough so in some respects like if you're trying to uh if you're trying to",
    "start": "1096120",
    "end": "1104120"
  },
  {
    "text": "serialize a a model from Psych learn to Onyx for example there's a little a few",
    "start": "1104120",
    "end": "1109679"
  },
  {
    "text": "rough edges there at least in my respect or my history with at least with the docs but it is a really great ambitious",
    "start": "1109679",
    "end": "1116760"
  },
  {
    "text": "project and I certainly hope that they succeed because I definitely see a lot of problems that could arise from trying",
    "start": "1116760",
    "end": "1122960"
  },
  {
    "text": "to support all of these different architectures um seems hard yeah I I",
    "start": "1122960",
    "end": "1128159"
  },
  {
    "text": "agree with you and I think I think Onyx is was a fantastic first way of",
    "start": "1128159",
    "end": "1133520"
  },
  {
    "text": "providing that that commonality across these different technology platforms and I think that there is still a lot of",
    "start": "1133520",
    "end": "1139960"
  },
  {
    "text": "room especially within the open source world of producing other tools with with a similar intent just as Onyx has",
    "start": "1139960",
    "end": "1146960"
  },
  {
    "text": "provided us that common format there may be a number of deployment tools that come out where where a deployer can",
    "start": "1146960",
    "end": "1153440"
  },
  {
    "text": "focus on learning that as a as kind of a standard baced approach rather than all the individual stuff I know that in a",
    "start": "1153440",
    "end": "1160480"
  },
  {
    "text": "prior company uh we were deploying to both tensor RT and um something that",
    "start": "1160480",
    "end": "1166280"
  },
  {
    "text": "I'll I'll bring up which is the Snapdragon from Qualcomm while the workflows had similarities they were",
    "start": "1166280",
    "end": "1172760"
  },
  {
    "text": "they were completely different workflows that we had to learn and we had people in the team that kind of specialized in",
    "start": "1172760",
    "end": "1178240"
  },
  {
    "text": "either approach and stuff it would be really great if you could Target one workflow that would work across vendors",
    "start": "1178240",
    "end": "1184159"
  },
  {
    "text": "in that way abstract that away so right before uh just a second ago Chris you",
    "start": "1184159",
    "end": "1190159"
  },
  {
    "text": "mentioned that you had worked with this Snapdragon before which um I'll let you",
    "start": "1190159",
    "end": "1195600"
  },
  {
    "text": "describe here in a second but one of the other trends that I saw kind of in the news and updates in in the world of AI",
    "start": "1195600",
    "end": "1202960"
  },
  {
    "text": "this uh this past week was some stuff having to do with running inference running models in the browser on mobile",
    "start": "1202960",
    "end": "1210679"
  },
  {
    "text": "on client devices and iot devices this kind of idea of pushing models out of",
    "start": "1210679",
    "end": "1216960"
  },
  {
    "text": "you know always being run in the cloud in some service in the cloud into kind",
    "start": "1216960",
    "end": "1222360"
  },
  {
    "text": "of more towards the quote unquote Edge or the client devices is this a trend",
    "start": "1222360",
    "end": "1227799"
  },
  {
    "text": "that you've been seeing as well yeah I think it's it's interesting um I think that you're seeing a lot of inferencing",
    "start": "1227799",
    "end": "1233600"
  },
  {
    "text": "being pushed out to the edge and I know that uh that is been specific use cases that I've dealt with have had to do with",
    "start": "1233600",
    "end": "1240520"
  },
  {
    "text": "um mobile devices that were TR that were kind of leveling up and and getting a a Snapdragon in them that we've deployed",
    "start": "1240520",
    "end": "1247440"
  },
  {
    "text": "to uh and also iot and so I think you know the world that we're at right now",
    "start": "1247440",
    "end": "1253159"
  },
  {
    "text": "you have lots of mobile and iot devices that are not nearly powerful enough I think with the recognition that",
    "start": "1253159",
    "end": "1258880"
  },
  {
    "text": "inferencing is being pushed to the edge you're seeing a number of vendors starting to uh to sign up with",
    "start": "1258880",
    "end": "1264080"
  },
  {
    "text": "Snapdragon or similar types of Technologies basically low power inferencing engines that can be deployed",
    "start": "1264080",
    "end": "1270159"
  },
  {
    "text": "to inexpensive Hardware on the edge with very limited Computing resource and and so uh I think you're going to see that",
    "start": "1270159",
    "end": "1277039"
  },
  {
    "text": "type of thing all over the place um and I think that's a given at this point where it's where you're inferencing",
    "start": "1277039",
    "end": "1282760"
  },
  {
    "text": "workload is distributed between the cloud and the edge as it makes sense uh I think the big question now is whether",
    "start": "1282760",
    "end": "1288799"
  },
  {
    "text": "or not uh there's enough use cases of doing actually training on the edge uh",
    "start": "1288799",
    "end": "1294440"
  },
  {
    "text": "whether or not that uh becomes a thing I don't think that's really taken hold there's certainly lots of conversations",
    "start": "1294440",
    "end": "1299640"
  },
  {
    "text": "around it but I haven't seen it personally in Industry you know actually being deployed in a production sense",
    "start": "1299640",
    "end": "1306240"
  },
  {
    "text": "yeah so in in the cases where you're talking about when you were using the Snapdragon thing the the neural",
    "start": "1306240",
    "end": "1311640"
  },
  {
    "text": "processing engine the motivation for pushing that inferencing out to a mobile",
    "start": "1311640",
    "end": "1319080"
  },
  {
    "text": "or it sounds like in your case an iot device maybe a sensor or something like that what was the motivation for that",
    "start": "1319080",
    "end": "1324720"
  },
  {
    "text": "was it like connectivity was it efficiency or timing or what what was the primary motivation yeah it it really",
    "start": "1324720",
    "end": "1332039"
  },
  {
    "text": "depends on the resource environment that you're deploying into and also what the",
    "start": "1332039",
    "end": "1337240"
  },
  {
    "text": "performance parameters are of your of actually operating you know on whatever",
    "start": "1337240",
    "end": "1342840"
  },
  {
    "text": "by resource environment you mean the actual resources on the device that you're deploying to or yeah well that",
    "start": "1342840",
    "end": "1349960"
  },
  {
    "text": "CPU or or something yeah and there can be a number of cases an example that I had uh personal experience in was in",
    "start": "1349960",
    "end": "1357279"
  },
  {
    "text": "speech recognition and natural language processing where you may need to uh you",
    "start": "1357279",
    "end": "1362480"
  },
  {
    "text": "don't have time or you may not have an environment equipped with the right network connections to pass to the cloud",
    "start": "1362480",
    "end": "1368200"
  },
  {
    "text": "and then pass back there there's latency involved in that if you're in an environment where you simply don't have time for that you know you know a few",
    "start": "1368200",
    "end": "1375279"
  },
  {
    "text": "two10 of a second delay or whatever it is that you're dealing with in some cases there are speech recognition",
    "start": "1375279",
    "end": "1380760"
  },
  {
    "text": "Technologies where the use case requires that you start processing before you're even done necessarily speaking a",
    "start": "1380760",
    "end": "1386559"
  },
  {
    "text": "sentence so you may be already uh having processed the first part of this sentence I'm saying right now before I",
    "start": "1386559",
    "end": "1393240"
  },
  {
    "text": "finish this second part it may be that the latency issues get in the way I've seen some very specific constraints",
    "start": "1393240",
    "end": "1398559"
  },
  {
    "text": "around that in industry and there may be some situations where you can go either way um where you can have it be",
    "start": "1398559",
    "end": "1404000"
  },
  {
    "text": "cloud-based but I think I think as inferencing becomes uh easier and cheaper on the edge you're going to see",
    "start": "1404000",
    "end": "1409640"
  },
  {
    "text": "it more and more to where instead of it being specifically a constraint you're going to see where does it make sense to put this you know from a a cost benefit",
    "start": "1409640",
    "end": "1416679"
  },
  {
    "text": "analysis yeah I'm thinking back to that um our way back at our episode three",
    "start": "1416679",
    "end": "1422440"
  },
  {
    "text": "where uh the the team at Penn State was kind of deploying this app for African",
    "start": "1422440",
    "end": "1428520"
  },
  {
    "text": "Farmers that would classify plants I'm guessing I don't know but I'm guessing",
    "start": "1428520",
    "end": "1433799"
  },
  {
    "text": "that there's probably connectivity issues for the devices when they put them out in the field which is literally",
    "start": "1433799",
    "end": "1439480"
  },
  {
    "text": "the field like the farming field right in this case so I imagine that like they",
    "start": "1439480",
    "end": "1445120"
  },
  {
    "text": "can't necessarily rely on inferencing cloud environment because they simply",
    "start": "1445120",
    "end": "1450840"
  },
  {
    "text": "just can't connect so I think there's like this one issue of you know maybe just not being able to connect and",
    "start": "1450840",
    "end": "1456600"
  },
  {
    "text": "having to run that on the device but of course there's issues with that I I remember them talking about inferencing",
    "start": "1456600",
    "end": "1463760"
  },
  {
    "text": "you know really if I remember right kind of draining the battery of the device and that sort of thing so there are I",
    "start": "1463760",
    "end": "1469399"
  },
  {
    "text": "know there are you know constraints here I don't think you know you can totally just export everything right now to the",
    "start": "1469399",
    "end": "1476679"
  },
  {
    "text": "to these low power devices and expect things to work work out great but um there is some encouraging signs one",
    "start": "1476679",
    "end": "1483480"
  },
  {
    "text": "interesting thing that I wanted to bring up which I've seen referenced a few times this week one in particular uh I",
    "start": "1483480",
    "end": "1490559"
  },
  {
    "text": "saw this release of the Onyx JS project from Microsoft which is a project for",
    "start": "1490559",
    "end": "1498399"
  },
  {
    "text": "running models and model related operations in your browser in JavaScript",
    "start": "1498399",
    "end": "1505360"
  },
  {
    "text": "um so there's there's a similar project tensorflow JS which is specific to tensorflow and I'm sure that there's",
    "start": "1505360",
    "end": "1510919"
  },
  {
    "text": "other JavaScript uh Frameworks out there I'm not I'm not a huge JavaScript person",
    "start": "1510919",
    "end": "1517000"
  },
  {
    "text": "but in my understanding so in addition to these things that we've talked about in terms of connectivity and all of that",
    "start": "1517000",
    "end": "1523440"
  },
  {
    "text": "there's actually a huge privacy and data element to where you run inferencing so",
    "start": "1523440",
    "end": "1532120"
  },
  {
    "text": "it could be that when you run training you run it in a very you know uh on a",
    "start": "1532120",
    "end": "1538200"
  },
  {
    "text": "big beefy server in the cloud and the reason why you do that is because you have to process a ton of data maybe",
    "start": "1538200",
    "end": "1544360"
  },
  {
    "text": "you're processing 200 terabytes of data or something like that but maybe that data it doesn't include sensitive data",
    "start": "1544360",
    "end": "1551720"
  },
  {
    "text": "or something maybe it's anonymized in some some case but then if you if you transfer that model over and run it in",
    "start": "1551720",
    "end": "1558720"
  },
  {
    "text": "someone's browser and then you're running the inference in their browser you may be processing their particular",
    "start": "1558720",
    "end": "1565440"
  },
  {
    "text": "data like you processing the feed off of their webcam for example right and if",
    "start": "1565440",
    "end": "1570760"
  },
  {
    "text": "you're doing that obviously that could be very sensitive data and so one thing you could do is transfer all of that",
    "start": "1570760",
    "end": "1576919"
  },
  {
    "text": "data up into the cloud do your inferencing in the cloud but then you're essentially you know taking possession",
    "start": "1576919",
    "end": "1583080"
  },
  {
    "text": "of all of that sensitive data whereas if you run the model actually in the browser",
    "start": "1583080",
    "end": "1588760"
  },
  {
    "text": "and do the inferencing there then the user sensitive data actually just stays",
    "start": "1588760",
    "end": "1594399"
  },
  {
    "text": "on their device so you can kind of totally maybe not totally but you can avoid many of these uh kind of privacy",
    "start": "1594399",
    "end": "1602200"
  },
  {
    "text": "and security related issues in terms of H how and what data you're processing",
    "start": "1602200",
    "end": "1608120"
  },
  {
    "text": "where yeah and you know and there's other considerations like a while back uh in an episode we were talking about",
    "start": "1608120",
    "end": "1614360"
  },
  {
    "text": "the general data protection regulation gdpr uh in the European Union which is",
    "start": "1614360",
    "end": "1619559"
  },
  {
    "text": "actually though it's only officially applied there many organizations are applying it globally so they don't have",
    "start": "1619559",
    "end": "1624679"
  },
  {
    "text": "to support multiple business approaches and processes and it may very well be that by running by doing the inferencing",
    "start": "1624679",
    "end": "1631320"
  },
  {
    "text": "in your browser for instance instead of passing up to a cloud you're able to uh fit within particular regulations in a",
    "start": "1631320",
    "end": "1637399"
  },
  {
    "text": "given country where you're not actually moving the data the model can be deployed widely but the data has to stay where it is and therefore that might be",
    "start": "1637399",
    "end": "1644120"
  },
  {
    "text": "the only option or one of the only options that you have short of having servers in every jurisdiction that",
    "start": "1644120",
    "end": "1649200"
  },
  {
    "text": "you're going to operate in so there there's a strong use case going forward from a regulatory standpoint for being",
    "start": "1649200",
    "end": "1654600"
  },
  {
    "text": "able to just do it right there in the end user browser and let them keep the data private it never moves it it takes",
    "start": "1654600",
    "end": "1660960"
  },
  {
    "text": "the whole uh regulatory concern at least that aspect of it out of the picture yeah I think there are with everything",
    "start": "1660960",
    "end": "1667760"
  },
  {
    "text": "that we've talked about before and I guess everything related to this there's always trade-offs right it seems like I",
    "start": "1667760",
    "end": "1673320"
  },
  {
    "text": "was talking to a friend of mine who is at a startup and part of their startup",
    "start": "1673320",
    "end": "1679720"
  },
  {
    "text": "you know IP and uh really the the secret sauce of what they're doing is in their",
    "start": "1679720",
    "end": "1685559"
  },
  {
    "text": "machine learning model right but then if you take that model and then you push it out to someone's client device and run",
    "start": "1685559",
    "end": "1692559"
  },
  {
    "text": "it in their browser of course there's always the opportunity for you're releasing that model out into the wild",
    "start": "1692559",
    "end": "1698159"
  },
  {
    "text": "and people can just maybe just take it and you know uh look at the view source and in browser and figure out how to get",
    "start": "1698159",
    "end": "1704679"
  },
  {
    "text": "your model and and utilize it and and all of that so I know I know that he was concerned about about those risks but",
    "start": "1704679",
    "end": "1711600"
  },
  {
    "text": "it's probably I don't know in my mind maybe the benefits outweigh the cost because in the same way there have been",
    "start": "1711600",
    "end": "1717360"
  },
  {
    "text": "a lot of papers that have shown even for doing inferencing in the cloud if you're exposing some service that does",
    "start": "1717360",
    "end": "1723360"
  },
  {
    "text": "inferencing for like image recognition or or something like that it only takes",
    "start": "1723360",
    "end": "1728640"
  },
  {
    "text": "a certain number of requests to that API to be able to kind of uh mock or or",
    "start": "1728640",
    "end": "1735240"
  },
  {
    "text": "spoof that machine learning model and actually create a a duplicate of it so I",
    "start": "1735240",
    "end": "1740360"
  },
  {
    "text": "guess there'll always be those you know those tradeoffs but there is kind of this transfer of the model to the",
    "start": "1740360",
    "end": "1746840"
  },
  {
    "text": "client's device which probably has some trade-offs there but also you know these models aren't super small and if you",
    "start": "1746840",
    "end": "1753279"
  },
  {
    "text": "want to update them over time maybe there are some you know storage or battery or other sorts of issues going",
    "start": "1753279",
    "end": "1761080"
  },
  {
    "text": "on there so I'll be interested to see you know how how people deal with those",
    "start": "1761080",
    "end": "1766279"
  },
  {
    "text": "trade-offs and what end ends up becoming the the driving force there yeah and",
    "start": "1766279",
    "end": "1771799"
  },
  {
    "text": "kind of to go back full circle you know that's when we talk about these deployment Technologies such as nvidia's",
    "start": "1771799",
    "end": "1778279"
  },
  {
    "text": "tensor RT or the snap dragon neural processing engine which is called Snappy for short those optimizations we made",
    "start": "1778279",
    "end": "1785840"
  },
  {
    "text": "they they literally will change the architecture of the model that you have trained when you're deploying and they",
    "start": "1785840",
    "end": "1791360"
  },
  {
    "text": "and um there's a number of techniques that they apply to optimize that so that's part of that deployment of models",
    "start": "1791360",
    "end": "1797120"
  },
  {
    "text": "out I think the way I see it is it's it's great to have all these choices and options that are finally coming into uh",
    "start": "1797120",
    "end": "1804080"
  },
  {
    "text": "into into being um in in the software engineering World there have been over the years the evolution of software has",
    "start": "1804080",
    "end": "1810720"
  },
  {
    "text": "given us many choices for client side and server side and how we going to choose to distribute workloads and such",
    "start": "1810720",
    "end": "1816640"
  },
  {
    "text": "and fortunately we're seeing that same Evolution happen fairly quickly since there's already you know there's already",
    "start": "1816640",
    "end": "1822919"
  },
  {
    "text": "a road map on that from the software engineering World we're seeing that being applied to uh data science and AI",
    "start": "1822919",
    "end": "1829200"
  },
  {
    "text": "technology specifically fairly quickly at this point you know we're measuring it now in in weeks and months is instead",
    "start": "1829200",
    "end": "1834919"
  },
  {
    "text": "of years or even decades the way it took in software engineering so I think having different ways of deploying a",
    "start": "1834919",
    "end": "1841399"
  },
  {
    "text": "given thing a given model uh in the days ahead is going to is going to make allow us to best serve our customers in that",
    "start": "1841399",
    "end": "1848080"
  },
  {
    "text": "way so I I choice is good yeah and choice is good I mean in the sense of cost too like you've already mentioned",
    "start": "1848080",
    "end": "1853799"
  },
  {
    "text": "if there's more more choices out there for this type of specialized Hardware you you know I know that this has been a",
    "start": "1853799",
    "end": "1859360"
  },
  {
    "text": "big win for Intel's uh chips that are in drones and you can plug in via USB stick",
    "start": "1859360",
    "end": "1864880"
  },
  {
    "text": "and stuff it just allows people to do you know fun things really quickly with deep learning and also functional things",
    "start": "1864880",
    "end": "1871960"
  },
  {
    "text": "that are really crucial to certain um certain products and so I think that you",
    "start": "1871960",
    "end": "1877200"
  },
  {
    "text": "ultimately win as a consumer right I I've kind of stopped well part of me still wants to buy a big you know GPU",
    "start": "1877200",
    "end": "1884320"
  },
  {
    "text": "workstation which I probably will never do cuz I don't have all the money but uh but the other side of me says you know",
    "start": "1884320",
    "end": "1891799"
  },
  {
    "text": "well at this point it doesn't matter because I can get any sort of specialized hardware for doing this stuff in the cloud and moreover I can",
    "start": "1891799",
    "end": "1898760"
  },
  {
    "text": "you know go and buy one of these chips that I can integrate into my Raspberry Pi or another fun device and just build",
    "start": "1898760",
    "end": "1906360"
  },
  {
    "text": "some fun projects and when I need more compute power then I just spin up more more on the cloud so yeah I'm glad that",
    "start": "1906360",
    "end": "1913519"
  },
  {
    "text": "I don't have to you know keep that saving going for a a huge uge GPU",
    "start": "1913519",
    "end": "1918559"
  },
  {
    "text": "machine that they'll sit in my in my office although it probably be good for heating um just through through uh",
    "start": "1918559",
    "end": "1925760"
  },
  {
    "text": "employers I've had I've had the the privilege of having uh access to dgx ons",
    "start": "1925760",
    "end": "1931240"
  },
  {
    "text": "uh at this point dgx 2s and those are machines from Nvidia right yeah those",
    "start": "1931240",
    "end": "1936320"
  },
  {
    "text": "are supercomputers from Nvidia and and also uh the workstation which is essentially half of a ggx one at least",
    "start": "1936320",
    "end": "1942880"
  },
  {
    "text": "that's what it was the specs may have changed and and they're those are all very very expensive but those are for uh",
    "start": "1942880",
    "end": "1948399"
  },
  {
    "text": "training at scale uh very very complex models and it's it's great to see I think right now we're seeing so many",
    "start": "1948399",
    "end": "1954799"
  },
  {
    "text": "players getting into the space with as6 and tpus are the equivalent and such uh",
    "start": "1954799",
    "end": "1960200"
  },
  {
    "text": "and and there's now choice in Hardware uh and and that is really commoditizing the entire field so I I think I think",
    "start": "1960200",
    "end": "1966600"
  },
  {
    "text": "it's becoming very reasonable to get into deep learning for small projects the way we do in software engineering",
    "start": "1966600",
    "end": "1972120"
  },
  {
    "text": "where you know you might you might go to work and have a primary large scale project you're working on for your employer but then then you'd come home",
    "start": "1972120",
    "end": "1978519"
  },
  {
    "text": "at night and on weekends and work on on something that's really passion driven and I think that is becoming more and",
    "start": "1978519",
    "end": "1983639"
  },
  {
    "text": "more viable for uh data scientists who are really into deep learning and and for software Engineers who are getting",
    "start": "1983639",
    "end": "1989000"
  },
  {
    "text": "into deep learning so it's uh I I think I think we'll continue to see that I still think we're going to have",
    "start": "1989000",
    "end": "1995159"
  },
  {
    "text": "incredibly expensive AI supercomputers uh you know the djx2 is substantially more powerful and more expensive uh than",
    "start": "1995159",
    "end": "2002200"
  },
  {
    "text": "the djx1 was we're seeing a breath of what's available out there yeah and kind",
    "start": "2002200",
    "end": "2007519"
  },
  {
    "text": "of turning now from all of that news and great stuff about inference and Hardware",
    "start": "2007519",
    "end": "2013840"
  },
  {
    "text": "uh to some things that will help us as we build those you know passion projects",
    "start": "2013840",
    "end": "2019159"
  },
  {
    "text": "or try to figure out um how we can do inference at our at our new uh at our",
    "start": "2019159",
    "end": "2025480"
  },
  {
    "text": "company or on their new project we'll kind of turn now to the part of fully connected where we share some learning",
    "start": "2025480",
    "end": "2031760"
  },
  {
    "text": "resources in particular we're going to share some with you today as related to this topic of inference one of the ones",
    "start": "2031760",
    "end": "2038919"
  },
  {
    "text": "that I really like that I think if you're new to this whole idea of what happens after training my AI model maybe",
    "start": "2038919",
    "end": "2046399"
  },
  {
    "text": "you didn't know that there was something that happened after that maybe you didn't know about this whole idea of",
    "start": "2046399",
    "end": "2052158"
  },
  {
    "text": "integrating models into apis this article it's called rise of the model",
    "start": "2052159",
    "end": "2058919"
  },
  {
    "text": "servers which sounds very scary actually sounds like a movie doesn't it it it does it should be made into a movie but",
    "start": "2058919",
    "end": "2065800"
  },
  {
    "text": "it's from uh sorry if I mispronounce the name but Alex viati and it's on medium",
    "start": "2065800",
    "end": "2072079"
  },
  {
    "text": "and it says Rise of the model servers new tools for deploying machine learning models to production and I just found",
    "start": "2072079",
    "end": "2077919"
  },
  {
    "text": "this to be a really good summary article in terms of first telling what a model server is which we've kind of already",
    "start": "2077919",
    "end": "2084638"
  },
  {
    "text": "discussed here but she goes into a little bit more detail and then she just goes through and gives you five",
    "start": "2084639",
    "end": "2091118"
  },
  {
    "text": "different kind of common choices for this which includes tensor RT which we already discussed but it also includes",
    "start": "2091119",
    "end": "2097920"
  },
  {
    "text": "something that I've used before which is model server for Apache mxet includes tensorflow serving Clipper and deep",
    "start": "2097920",
    "end": "2104160"
  },
  {
    "text": "detect she goes through and talks about each one but also gives you a link to the various repos and the papers that",
    "start": "2104160",
    "end": "2110240"
  },
  {
    "text": "are relevant so it's a good it's a good jumping off point if you're new to this whole side of how to do inference or set",
    "start": "2110240",
    "end": "2117119"
  },
  {
    "text": "up inference servers yeah there's uh another thing just to note is I know we've talked about uh tensor RT Nvidia",
    "start": "2117119",
    "end": "2125200"
  },
  {
    "text": "has some some great tutorials and references on their Dev blogs uh Nvidia",
    "start": "2125200",
    "end": "2130720"
  },
  {
    "text": "it's Dev blogs. nvidia.com that you can get into and learn about that and and since I also mentioned the Qualcomm",
    "start": "2130720",
    "end": "2137359"
  },
  {
    "text": "Snapdragon and the snappy Snapdragon neural processing engine they're SDK",
    "start": "2137359",
    "end": "2142400"
  },
  {
    "text": "which you can find at developer. qualcomm.com has a lot of good material on how that you can jump into that so",
    "start": "2142400",
    "end": "2148200"
  },
  {
    "text": "those are two vendor specific uh sources that I know that I personally have used quite a lot uh over the last over the",
    "start": "2148200",
    "end": "2154160"
  },
  {
    "text": "last Snappy I didn't get that acronym until right now I've never SNP Snappy",
    "start": "2154160",
    "end": "2160400"
  },
  {
    "text": "and Ah that's a good one I mean it's not immediately obvious to me but uh but",
    "start": "2160400",
    "end": "2165599"
  },
  {
    "text": "still a good play on their part that's a that's a catchy one yep the last thing I wanted to share was just um so as I",
    "start": "2165599",
    "end": "2172440"
  },
  {
    "text": "mentioned I'm a Noob at JavaScript and a lot of things along with that but if",
    "start": "2172440",
    "end": "2178560"
  },
  {
    "text": "you've been uh kind of interested in that side of things about running AI in the browser maybe you would just want to",
    "start": "2178560",
    "end": "2185440"
  },
  {
    "text": "learn a little bit of JavaScript and want to learn a little bit of AI at the same time there we'll put these in the",
    "start": "2185440",
    "end": "2191839"
  },
  {
    "text": "Show links of course all of these links but if you're interested in this Onyx JS project that was just released they have",
    "start": "2191839",
    "end": "2198000"
  },
  {
    "text": "some examples um and demos and a demo site that's on their uh GitHub and then",
    "start": "2198000",
    "end": "2205079"
  },
  {
    "text": "also there is a a link that we'll put there for the tensorflow JS tutorials so",
    "start": "2205079",
    "end": "2211440"
  },
  {
    "text": "they have in these tutorials kind of a a natural progression from core concept so",
    "start": "2211440",
    "end": "2218119"
  },
  {
    "text": "they talk about you know the the specific things such as tensors and operations and models and layers and how",
    "start": "2218119",
    "end": "2224319"
  },
  {
    "text": "those are represented in Java Script all the way down to more complicated things like you know uh doing uh synthetic data",
    "start": "2224319",
    "end": "2233920"
  },
  {
    "text": "and webcam data webg API layer for for Caris um all of these sorts of things",
    "start": "2233920",
    "end": "2241119"
  },
  {
    "text": "that that might be a little bit more um little bit more advanced so that that will probably get you a little bit",
    "start": "2241119",
    "end": "2246599"
  },
  {
    "text": "further at at at this point so it's definitely something that I kind of want to explore a little bit as I mentioned I",
    "start": "2246599",
    "end": "2253119"
  },
  {
    "text": "I'm pretty new to that that side of things yeah I've done JavaScript over the years uh but more Focus probably",
    "start": "2253119",
    "end": "2259359"
  },
  {
    "text": "like mod people most people on uh mostly frontend development uh like emberjs and",
    "start": "2259359",
    "end": "2264520"
  },
  {
    "text": "these days I use react and obviously you use nodejs for all sorts of stuff whether you're coding or not but um I I",
    "start": "2264520",
    "end": "2270920"
  },
  {
    "text": "haven't really delved into this applying the J JavaScript skills into uh into the",
    "start": "2270920",
    "end": "2276280"
  },
  {
    "text": "deep learning world so I I think I really need to dive into this and see what it has and understand how it can fit into other things that I've done in",
    "start": "2276280",
    "end": "2283000"
  },
  {
    "text": "JavaScript yeah so I I heard a talk once and um I'll have to remember who it was",
    "start": "2283000",
    "end": "2288040"
  },
  {
    "text": "but I remember the statement was that you know no one codes in JavaScript but everybody codes in JavaScript I think",
    "start": "2288040",
    "end": "2293520"
  },
  {
    "text": "that was the the the statement so uh yeah so I think that brings us to the to",
    "start": "2293520",
    "end": "2299200"
  },
  {
    "text": "the end of our fully connected episode so for all of you not JavaScript",
    "start": "2299200",
    "end": "2304599"
  },
  {
    "text": "programmers JavaScript programmers out there appreciate uh you're going through this this journey learning a little bit",
    "start": "2304599",
    "end": "2310359"
  },
  {
    "text": "about inference with us like I say we'll put all of these show all these links in our show notes and would really",
    "start": "2310359",
    "end": "2316560"
  },
  {
    "text": "appreciate you finding us on uh changel log.com commmunity connecting with us on",
    "start": "2316560",
    "end": "2322119"
  },
  {
    "text": "LinkedIn and hope to hear about uh all the things that you're finding interesting in the world of AI right now",
    "start": "2322119",
    "end": "2328920"
  },
  {
    "text": "and uh Chris we'll talk to you later sounds good Daniel I'll talk to you",
    "start": "2328920",
    "end": "2334200"
  },
  {
    "text": "later all right thank you for tuning into this episode of practical AI if you enjoyed the show do us a favor go on",
    "start": "2334200",
    "end": "2340200"
  },
  {
    "text": "iTunes give us a rating go in your podcast app and favored it if you are on Twitter or social network share a link",
    "start": "2340200",
    "end": "2345800"
  },
  {
    "text": "with a friend whatever you got to do share the show with a friend if you enjoyed it and band with for change log is provided by fastly learn more at",
    "start": "2345800",
    "end": "2352359"
  },
  {
    "text": "fastly.com and we catch our errors before our users do here at changelog because of robbar check them out at",
    "start": "2352359",
    "end": "2357640"
  },
  {
    "text": "roar.com changelog and we're hosted on Leno Cloud servers head to lin.com",
    "start": "2357640",
    "end": "2363119"
  },
  {
    "text": "changelog check them out support this show this episode is hosted by Daniel whack and Chris Benson editing is done",
    "start": "2363119",
    "end": "2370079"
  },
  {
    "text": "by Tim Smith the music is by break master cylinder and you can find more shows just like this at changel law.com",
    "start": "2370079",
    "end": "2376839"
  },
  {
    "text": "when you go there pop in your email address get our weekly email keeping you up to date with the news and podcast for",
    "start": "2376839",
    "end": "2382960"
  },
  {
    "text": "developers in your inbox every single week thanks for tuning in we'll see you next",
    "start": "2382960",
    "end": "2388450"
  },
  {
    "text": "[Music] week",
    "start": "2388450",
    "end": "2395480"
  }
]
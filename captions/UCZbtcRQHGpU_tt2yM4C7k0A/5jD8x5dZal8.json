[
  {
    "text": "today's models are actually not models like we need a new name because there's something that doesn't exist like what",
    "start": "80",
    "end": "5200"
  },
  {
    "text": "do you call an encoder and a decoder working together to make an auto encoder or variational encoder right they're not",
    "start": "5200",
    "end": "10759"
  },
  {
    "text": "models it's collections of models interacting together same for Transformers right so that's really what the lighting modules about you pass in",
    "start": "10759",
    "end": "16920"
  },
  {
    "text": "these models into it and then how they interact together is abstracted by that right and I think that's a missing",
    "start": "16920",
    "end": "22359"
  },
  {
    "text": "abstraction that was not there so it's important to decouple that because now I have this single file that's completely",
    "start": "22359",
    "end": "28679"
  },
  {
    "text": "self-contained that I can share with my team across in a different division and their problem might be completely",
    "start": "28679",
    "end": "34520"
  },
  {
    "text": "different with a different data set and they don't have to ever change the code on that model all they have to do is change what Hardware they're using and",
    "start": "34520",
    "end": "40399"
  },
  {
    "text": "then what the data set is so it makes code extremely interoperable right so I think people come to lightning because",
    "start": "40399",
    "end": "46800"
  },
  {
    "text": "they want to train a multiple gpus and so on but that's only like a very small part of it I think once you get into it you see that the rest of it is the",
    "start": "46800",
    "end": "53640"
  },
  {
    "text": "ability to collaborate with pi and be able to have reproducible and scalable",
    "start": "53640",
    "end": "58920"
  },
  {
    "text": "code big thanks to our partners Leno fastly and launch Darkly we love Leno they keep",
    "start": "58920",
    "end": "64640"
  },
  {
    "text": "it fast and simple check them out at lin.com changelog our bandwidth is provided by fastly learn more at",
    "start": "64640",
    "end": "71439"
  },
  {
    "text": "fastly.com and get your feature Flags powered by lunch darkley get a demo at lunch dark.com",
    "start": "71439",
    "end": "78320"
  },
  {
    "text": "this episode is brought to you by our friends at O'Reilly many you know O'Reilly for their animal techbooks and",
    "start": "79000",
    "end": "84360"
  },
  {
    "text": "their conferences but you may not know they have an online learning platform as well the platform has all their books",
    "start": "84360",
    "end": "90720"
  },
  {
    "text": "all their videos and all their conference talks plus you can learn by doing with live online training courses",
    "start": "90720",
    "end": "96799"
  },
  {
    "text": "and virtual conferences certification practice exams and interactive sandboxes and scenarios to practice coding",
    "start": "96799",
    "end": "103399"
  },
  {
    "text": "alongside what you're learning they cover a ton of Technology topics machine learning AI programming languages devops",
    "start": "103399",
    "end": "110759"
  },
  {
    "text": "data science Cloud containers security and even soft skills like business",
    "start": "110759",
    "end": "116520"
  },
  {
    "text": "management and presentation skills you name it it is all in there if you need to keep your team or yourself up to",
    "start": "116520",
    "end": "122759"
  },
  {
    "text": "speed on their Tech skills then check out ay's online learning platform learn more and keep your team skills sharp at",
    "start": "122759",
    "end": "128280"
  },
  {
    "text": "a.com changelog again a.com [Music]",
    "start": "128280",
    "end": "139960"
  },
  {
    "text": "changelog welcome to practical AI a weekly podcast that makes artificial intelligence practical productive and",
    "start": "140400",
    "end": "147360"
  },
  {
    "text": "accessible to everyone this is where conversation around AI machine learning and data science happen join the",
    "start": "147360",
    "end": "153360"
  },
  {
    "text": "community and slack with us around various topics of the show at cha.com community and follow us on Twitter we're",
    "start": "153360",
    "end": "159319"
  },
  {
    "text": "at practical [Music]",
    "start": "159319",
    "end": "166280"
  },
  {
    "text": "aifm welcome to another episode of practical AI this is Daniel whack I am a",
    "start": "166280",
    "end": "172519"
  },
  {
    "text": "data scientist with s International and I'm joined as always by my co-host Chris",
    "start": "172519",
    "end": "177959"
  },
  {
    "text": "Benson who is a tech strateg IST at loed Martin and this week we have a really",
    "start": "177959",
    "end": "184040"
  },
  {
    "text": "exciting show I'm pumped to talk about this we have William Falcon with us who",
    "start": "184040",
    "end": "189080"
  },
  {
    "text": "is creator of pytorch lightning and CEO of grid AI welcome Willian well thank",
    "start": "189080",
    "end": "194519"
  },
  {
    "text": "you guys for having me really excited to chat with you yeah yeah we are as well and I think I might have even mentioned",
    "start": "194519",
    "end": "200440"
  },
  {
    "text": "this to Chris on our slack Channel but I saw you like on Twitter when grid AI was",
    "start": "200440",
    "end": "205760"
  },
  {
    "text": "launched there was like a screencast of like this is things that you can do with",
    "start": "205760",
    "end": "211040"
  },
  {
    "text": "grid Ai and it was one of those moments I don't know if you've ever seen like a Kelsey high tower demo in like the",
    "start": "211040",
    "end": "216879"
  },
  {
    "text": "kubernetes world or something like that it was one of those moments where was like things just sort of snowballed and",
    "start": "216879",
    "end": "222239"
  },
  {
    "text": "then all of the sudden you were running like you were running models on all these gpus in the cloud with very little",
    "start": "222239",
    "end": "227680"
  },
  {
    "text": "effort and it was pretty cool so I'm excited to dive into that at some point yeah I'll share it yeah cool so maybe",
    "start": "227680",
    "end": "235239"
  },
  {
    "text": "before we get to there let's maybe start at pytorch lightning people might have heard of pytorch they might have heard",
    "start": "235239",
    "end": "241959"
  },
  {
    "text": "of lightning I know lightning kind of shows up in my Twitter feed quite a bit",
    "start": "241959",
    "end": "247000"
  },
  {
    "text": "could you just give us a little bit of context for what pytorch lightning is and how people can use it where it might",
    "start": "247000",
    "end": "253920"
  },
  {
    "text": "fit into people's workflow yeah so I think you know I'll talk a little of my experience to understand the motivation",
    "start": "253920",
    "end": "259759"
  },
  {
    "text": "behind it right because I think my sense from speaking to people in the community is that we've all had very similar",
    "start": "259759",
    "end": "265600"
  },
  {
    "text": "problems and thought about very similar approaches right the difference is you know we open sourced this and a lot of",
    "start": "265600",
    "end": "271360"
  },
  {
    "text": "people started contributing to it so I started out you know I was a software engineer and I was working in finance",
    "start": "271360",
    "end": "277120"
  },
  {
    "text": "and before that I guess I was on undergrad and I was starting you know to do research and I'd been working as a",
    "start": "277120",
    "end": "283960"
  },
  {
    "text": "software engineer and when I got into AI research it was in Neuroscience right so computational neuroscience and we were",
    "start": "283960",
    "end": "290280"
  },
  {
    "text": "trying to take a neural activity from the brain and trying to reconstruct what",
    "start": "290280",
    "end": "295400"
  },
  {
    "text": "generated that right and that was in the context of you know eyesight basically and so what happened there is none of us",
    "start": "295400",
    "end": "302680"
  },
  {
    "text": "were like really really big engineers in deep learning like we weren't experts right and so I started training models",
    "start": "302680",
    "end": "308639"
  },
  {
    "text": "and you know back then I was using theano right which is like a very old framework and I remember the first time",
    "start": "308639",
    "end": "314759"
  },
  {
    "text": "we got something wrong on GPU and it was like magical because suddenly my time went from months to like a few days and",
    "start": "314759",
    "end": "320440"
  },
  {
    "text": "I was like great and that research continued and what I found myself doing",
    "start": "320440",
    "end": "325800"
  },
  {
    "text": "over and over back then was I'd have an idea about something that wasn't quite that right so in neural decoding it's",
    "start": "325800",
    "end": "332240"
  },
  {
    "text": "basically like translating a sequence of signals into something an image or",
    "start": "332240",
    "end": "338479"
  },
  {
    "text": "another signal right so it's a translation problem in essence and so you could do things like Gans Auto",
    "start": "338479",
    "end": "344000"
  },
  {
    "text": "encoders you could do things like regression so many ideas and I would want to try a few different approaches with my teammates and we would have to",
    "start": "344000",
    "end": "351280"
  },
  {
    "text": "copy the code over and over again right you would either Fork the project and then kind of like copy that code over",
    "start": "351280",
    "end": "357160"
  },
  {
    "text": "and then if something new came out like multi-gpu training you have to then write it into all the code that you did and so suddenly you're maintaining like",
    "start": "357160",
    "end": "363240"
  },
  {
    "text": "10 different files that are all doing the same thing and I started abstracting that into like a kind of joint class I",
    "start": "363240",
    "end": "368520"
  },
  {
    "text": "think we all honestly I think all of us kind of do this at some point and I think at that point I'd been",
    "start": "368520",
    "end": "374440"
  },
  {
    "text": "using SK learn for a while so I loved like their fit and all those methods and so I was like okay well whatever let's",
    "start": "374440",
    "end": "379520"
  },
  {
    "text": "just call it fit and do that and then I transitioned to tensorflow because we needed to get into multiple gpus and it",
    "start": "379520",
    "end": "385639"
  },
  {
    "text": "was really hard to do in theano so that took our training time dramatically down and then you know continue working that",
    "start": "385639",
    "end": "391400"
  },
  {
    "text": "it for a while but the problem is like it just continued every time I wanted to do something new you had to copy that",
    "start": "391400",
    "end": "397120"
  },
  {
    "text": "code over and then new things came out all the time like there was just a different way of training and it was",
    "start": "397120",
    "end": "402360"
  },
  {
    "text": "really hard to go back and and copy and paste all that stuff I kind of I left that project for a bit and then kind of",
    "start": "402360",
    "end": "408479"
  },
  {
    "text": "went into the startup world right and I spent a few years putting NLP models into production and there it was less",
    "start": "408479",
    "end": "414479"
  },
  {
    "text": "about focus on training and more about deploying models and so I was just like cool quick Baseline and just like put",
    "start": "414479",
    "end": "420120"
  },
  {
    "text": "that thing in there and see what happens right I was less concerned about solving like a very unique problem and more",
    "start": "420120",
    "end": "426000"
  },
  {
    "text": "about hey I have the data here I just want I don't care what the model is I just want to see some results right so",
    "start": "426000",
    "end": "431560"
  },
  {
    "text": "we got that working and ended up you know scaling that to a company that got Acquired and that was basically using",
    "start": "431560",
    "end": "437560"
  },
  {
    "text": "NLP to help you know lowincome first generation students figure out how to pay for college or text message which",
    "start": "437560",
    "end": "442800"
  },
  {
    "text": "was really cool and from there I started my PhD and kind of like started that",
    "start": "442800",
    "end": "448879"
  },
  {
    "text": "research flow again and then you know coming from the startup world I was like how do I bring that Speed and Agility to",
    "start": "448879",
    "end": "455560"
  },
  {
    "text": "research right because we all know this and I think Kathy talks about this I mean we all know this firsthand but like",
    "start": "455560",
    "end": "462319"
  },
  {
    "text": "the outcome of doing anything with AI nowadays is honestly a function of how fast you iterate their ideas right",
    "start": "462319",
    "end": "468440"
  },
  {
    "text": "because like 90% of your ideas are going to fail and then one or two are going to work and then you're good to go so literally just how fast can you power",
    "start": "468440",
    "end": "474879"
  },
  {
    "text": "through those ideas is probably the single biggest predictor of if that thing's going to work or not so I knew",
    "start": "474879",
    "end": "480360"
  },
  {
    "text": "that and I wanted to bring that ability to my you know PHT research I was like hey maybe I can finish this thing in",
    "start": "480360",
    "end": "485560"
  },
  {
    "text": "like three years right as opposed to six or whatever ambitious yeah uh looking back",
    "start": "485560",
    "end": "491120"
  },
  {
    "text": "now it's not a good idea but yeah that was that was the goal right and so I know the feeling yeah and so I took my",
    "start": "491120",
    "end": "497199"
  },
  {
    "text": "code from my undergrad days and you know kind of brushed it off and then at that point I I switched to py torch so I was",
    "start": "497199",
    "end": "502479"
  },
  {
    "text": "like okay well let me just rewrite this thing in pyour and see how it goes so I started working with again NLP at that",
    "start": "502479",
    "end": "507960"
  },
  {
    "text": "point and then we moved into like Audio Research right to do speech synthesis and so on and all of that using the same",
    "start": "507960",
    "end": "514200"
  },
  {
    "text": "code right so it was interesting because like the first code was for NLP and then I modified it to work for audio and then",
    "start": "514200",
    "end": "520919"
  },
  {
    "text": "vision and so on and then eventually I don't think it was quite there at that abstraction level yet because I was",
    "start": "520919",
    "end": "526200"
  },
  {
    "text": "still having to do a lot of this spoke code but then I don't know what happened like I guess over the winter something",
    "start": "526200",
    "end": "531360"
  },
  {
    "text": "clicked and then you know the trainer got factored out and then it just became obvious that at that point you need to",
    "start": "531360",
    "end": "536600"
  },
  {
    "text": "separate the model from the hardware and so that's what lightning became came then I open source and then I Jo Facebook at research that summer as an",
    "start": "536600",
    "end": "543640"
  },
  {
    "text": "internet fair and you know continued my PhD research and there you have a giant cluster right and I was like okay well",
    "start": "543640",
    "end": "550079"
  },
  {
    "text": "you know if I have Facebook resources what can I do and and you know very ambitious in",
    "start": "550079",
    "end": "555920"
  },
  {
    "text": "terms of like trying to do research ideas so we were trying to scale up like massive data sets on the cluster as much",
    "start": "555920",
    "end": "561920"
  },
  {
    "text": "as we could right so I was consistently training you know 500 GPU models that kind of stuff all the time at fair with",
    "start": "561920",
    "end": "568959"
  },
  {
    "text": "this framework and then you know people noticed because that the cluster there was like a handful of teams across",
    "start": "568959",
    "end": "574200"
  },
  {
    "text": "Facebook that was using the cluster that efficiently but the rest of the teams weren't because like it takes a lot to",
    "start": "574200",
    "end": "579720"
  },
  {
    "text": "do you know training at scale and so you know I started working with those people because they're experts at this right",
    "start": "579720",
    "end": "585240"
  },
  {
    "text": "and so we embedded a lot of those practices into lightning and then ended up with a framework now that can do",
    "start": "585240",
    "end": "590680"
  },
  {
    "text": "really scalable training and then at that point you know there was some adoption internally then adoption externally and then it just kind of took",
    "start": "590680",
    "end": "596839"
  },
  {
    "text": "off after that but you know I came at it from how do I move really fast through research knowing what I know about",
    "start": "596839",
    "end": "602600"
  },
  {
    "text": "putting models into production as well and knowing what I know about doing research as well right so it's just kind of like having both requirements made it",
    "start": "602600",
    "end": "610000"
  },
  {
    "text": "really interesting and what's really cool now is that it's evolved into you know my vision really was you and I all",
    "start": "610000",
    "end": "616920"
  },
  {
    "text": "three of us are going to code the exact same thing in our own projects right we're going to code half Precision we're going to code sastic weight averaging",
    "start": "616920",
    "end": "623360"
  },
  {
    "text": "we're going to code whatever new thing comes up but why weighs that effort like that's not the job the job is to like",
    "start": "623360",
    "end": "628800"
  },
  {
    "text": "you know if you're lock Martin I don't know predict metal whatever right like find you know deficiency and materials I",
    "start": "628800",
    "end": "634880"
  },
  {
    "text": "don't know what you guys do there right but that'll work that'll work I think that's exactly what Chris I",
    "start": "634880",
    "end": "640839"
  },
  {
    "text": "assume so that's the goal the goal is not to figure out how to implement you know stasic weight averaging right so",
    "start": "640839",
    "end": "647279"
  },
  {
    "text": "what's cool now is that I mean I think we're approaching 500 contributors but these are all like top researchers and",
    "start": "647279",
    "end": "652880"
  },
  {
    "text": "phds all over the world who Implement these things and put them into papers and then you know within a few hours",
    "start": "652880",
    "end": "658360"
  },
  {
    "text": "it's ready and available for everyone so do you have to know how half Precision works with you know I don't know on gpus",
    "start": "658360",
    "end": "665160"
  },
  {
    "text": "you don't right but you just know that it's going to save your memory and so it's been basically turned into a community project and my vision was",
    "start": "665160",
    "end": "672079"
  },
  {
    "text": "really like can we build like the world's research lab basically right can we have all access to top researchers",
    "start": "672079",
    "end": "677880"
  },
  {
    "text": "and resources and and that's how it's happened so far so I noticed as you're kind of going through the story it seems",
    "start": "677880",
    "end": "685240"
  },
  {
    "text": "like as you progressed over those years through the different aspects of your own life and you're kind of looking at",
    "start": "685240",
    "end": "691399"
  },
  {
    "text": "the same problem through multiple lenses as you're going from you know software development and then you're doing",
    "start": "691399",
    "end": "697480"
  },
  {
    "text": "research and then you're at Facebook doing research and the scales are changing it seems very much like like",
    "start": "697480",
    "end": "703160"
  },
  {
    "text": "you were scratching your own itch but being having the benefit of taking into account multiple perceptions of that",
    "start": "703160",
    "end": "710600"
  },
  {
    "text": "problem so that you ended up having a very rich understanding of what was needed and how it could satisfy multiple",
    "start": "710600",
    "end": "717440"
  },
  {
    "text": "user groups do do you think that's a fair assessment or am I missing the boat it seems like it was a really smart way",
    "start": "717440",
    "end": "724040"
  },
  {
    "text": "of building a robust project from different perspectives all world into one yeah I mean I think that's right I",
    "start": "724040",
    "end": "729920"
  },
  {
    "text": "think like I said you know none of this was ever because I was trying to build anything for anyone else right I was trying to make myself move faster",
    "start": "729920",
    "end": "736480"
  },
  {
    "text": "research right I think like once other people started using it they gave me the",
    "start": "736480",
    "end": "741600"
  },
  {
    "text": "perspective there right and they put those constraints and I mean lightning is not where it is today because of me",
    "start": "741600",
    "end": "746639"
  },
  {
    "text": "it's there because of the community right like there's no way I could have ever created this by myself right I think like I could see the idea and see",
    "start": "746639",
    "end": "753320"
  },
  {
    "text": "the templates but a lot of my job has been to guide the community and maintain standards maintain uh usability right so",
    "start": "753320",
    "end": "759920"
  },
  {
    "text": "I care a lot about user experience so and I don't want to remember a lot of stuff so there just been a lot of guidance there as well but at the end of",
    "start": "759920",
    "end": "766560"
  },
  {
    "text": "the day it's a community that's done a lot of this right but I think like holistically having to focus on a lot of",
    "start": "766560",
    "end": "773480"
  },
  {
    "text": "domains has made it super General right because doing NLP is very different from",
    "start": "773480",
    "end": "779279"
  },
  {
    "text": "vision and it's very different from you know reinforcement learning and metal learning and so on and it's not obvious to know where they overlap so it's been",
    "start": "779279",
    "end": "786519"
  },
  {
    "text": "kind of research project really in the long run right how do you factor out deep learning code and make it interruptable yeah so that's been an",
    "start": "786519",
    "end": "793199"
  },
  {
    "text": "interesting Journey so far you mentioned when you were introducing the motivation",
    "start": "793199",
    "end": "798680"
  },
  {
    "text": "behind lightning the idea of decoupling models from hardware and I noticed like",
    "start": "798680",
    "end": "805560"
  },
  {
    "text": "even just on if I look at the repository for lightning you talk about you know pytorch lightning is just organized",
    "start": "805560",
    "end": "812839"
  },
  {
    "text": "pytorch and it's organized to sort of decouple science from engineering and so you've got this model side and the",
    "start": "812839",
    "end": "818000"
  },
  {
    "text": "hardware side could you dive into that a little bit more and talk about the specifics of what does it mean if I'm",
    "start": "818000",
    "end": "823560"
  },
  {
    "text": "using lightning what does it mean that my model is disentangled or decoupled from the hardware both practically in",
    "start": "823560",
    "end": "830639"
  },
  {
    "text": "terms of how I write the code and like what happens like once I hit fit like you're talking about yeah so when we're",
    "start": "830639",
    "end": "837320"
  },
  {
    "text": "working I mean look I think if you're working at a company or any team really even research if you're working with",
    "start": "837320",
    "end": "842920"
  },
  {
    "text": "multiple people you need the ability to share code and if you're at a company or even University lab you want to share",
    "start": "842920",
    "end": "848880"
  },
  {
    "text": "code across teams right and that's really hard to do without something like lightning because what happens is people",
    "start": "848880",
    "end": "855880"
  },
  {
    "text": "tend to intermingle a lot of stuff like data model and Hardware into the same",
    "start": "855880",
    "end": "861279"
  },
  {
    "text": "files right well you know one team may not have gpus or may have different types of gpus or may only be using CPUs",
    "start": "861279",
    "end": "867279"
  },
  {
    "text": "or your production requirements mean that you can only use CPUs for inference right so there are a lot of constraints",
    "start": "867279",
    "end": "872399"
  },
  {
    "text": "there and I guess if you're not thinking about it how we are from the abstract level you won't really realize that like",
    "start": "872399",
    "end": "879240"
  },
  {
    "text": "a lot of the reasons why a lot of that code doesn't operate together is because you're mixing the hardware with the model code right and that's something",
    "start": "879240",
    "end": "885920"
  },
  {
    "text": "that you know took us four years probably to get there to to see this right to have these insights and what",
    "start": "885920",
    "end": "891320"
  },
  {
    "text": "that means is that we can factor out deep learning code into three major areas well at least four I guess maybe",
    "start": "891320",
    "end": "896560"
  },
  {
    "text": "and we'll find more right I mean it's ongoing research so one is training code right so this is anything that has to do",
    "start": "896560",
    "end": "902040"
  },
  {
    "text": "with linking your model to the machine specifically so how do you do the",
    "start": "902040",
    "end": "907079"
  },
  {
    "text": "backward pass you know backward pass on distributor is very different from just on CPUs right at least technically",
    "start": "907079",
    "end": "912240"
  },
  {
    "text": "speaking what happens if you have half Precision there what happens if you're seeing stochastic with averaging what happens if you have truncated back steps",
    "start": "912240",
    "end": "918279"
  },
  {
    "text": "right so there are a lot of details that go into it so all of that is handled by the trainer and this is the stuff that",
    "start": "918279",
    "end": "923839"
  },
  {
    "text": "you're going to do over and over again right doesn't matter if you're doing audio or speech or VIs you're always",
    "start": "923839",
    "end": "929399"
  },
  {
    "text": "going to have a backward pass you're always going to have a training Loop and so on the model is the thing that changes the model is it's not just you",
    "start": "929399",
    "end": "936319"
  },
  {
    "text": "know I like to think about models I guess lightning we have this concept of a lightning module and to me a lightning",
    "start": "936319",
    "end": "941800"
  },
  {
    "text": "module is more of a system right so you know we can think about a model like I don't know like a convolutional network",
    "start": "941800",
    "end": "947360"
  },
  {
    "text": "or a linear regression model right just like a a self-contained module today's models are actually not models like we",
    "start": "947360",
    "end": "954199"
  },
  {
    "text": "need a new name because there's something that doesn't exist and I think the lightning module which is a system right because models now interact with",
    "start": "954199",
    "end": "959800"
  },
  {
    "text": "each other like what do you call an encoder and a decoder working together to make an auto encoder or variational",
    "start": "959800",
    "end": "965199"
  },
  {
    "text": "encoder right they're not models it's collections of models interacting together same for Transformers right so",
    "start": "965199",
    "end": "970639"
  },
  {
    "text": "that's really what the lighting module is about you pass in these models into it and then how they interact together is abstracted by that right and I think",
    "start": "970639",
    "end": "977560"
  },
  {
    "text": "that's a missing abstraction that was not there and which is why people were jumping through so many hoops right to be like oh well how do you do Gans how",
    "start": "977560",
    "end": "983759"
  },
  {
    "text": "do you do this other stuff so it's important to decouple that because now I have this single file that's completely",
    "start": "983759",
    "end": "989680"
  },
  {
    "text": "self-contained that I can now share with my team across in a different division and their problem might be completely",
    "start": "989680",
    "end": "995560"
  },
  {
    "text": "different with a different data set and they don't have to ever change the code on that model all they have to do is change what Hardware they're using and",
    "start": "995560",
    "end": "1001440"
  },
  {
    "text": "then what the data set is as long as it conforms to the API that the model is expecting it works so it makes code",
    "start": "1001440",
    "end": "1007199"
  },
  {
    "text": "extremely interoperable right so I think people come to lightning because they want to you know train a multiple gpus",
    "start": "1007199",
    "end": "1013360"
  },
  {
    "text": "and so on and under the hood we have this API called accelerators that lets you do that but that's only like a very",
    "start": "1013360",
    "end": "1019120"
  },
  {
    "text": "small part of it I think once you get into it you see that the rest of it is the ability to collaborate with piers",
    "start": "1019120",
    "end": "1024240"
  },
  {
    "text": "and be able to have reproducible and scalable [Music]",
    "start": "1024240",
    "end": "1042558"
  },
  {
    "text": "code this episode is brought to you by snowplow analytics snowplow is the",
    "start": "1042559",
    "end": "1048079"
  },
  {
    "text": "behavioral data management platform for data teams maximize the value of your",
    "start": "1048079",
    "end": "1053120"
  },
  {
    "text": "behavioral data using snowplow insights a managed data platform that's built on leading open source Tech leveraged by",
    "start": "1053120",
    "end": "1060160"
  },
  {
    "text": "tens of thousands of users capture and process high quality behavioral data from all your platforms and your",
    "start": "1060160",
    "end": "1066480"
  },
  {
    "text": "products and deliver that data to your Cloud destination of choice when marketing needs to make data informed",
    "start": "1066480",
    "end": "1071720"
  },
  {
    "text": "decisions when product needs Next Level understanding and when analytics needs rich and accurate data snowplow is the",
    "start": "1071720",
    "end": "1078280"
  },
  {
    "text": "solution for data teams who want to manage the collection processing and warehousing of data across all their",
    "start": "1078280",
    "end": "1083840"
  },
  {
    "text": "platforms and products get started and experience no plow data for yourself at snowplow analytics.com again snowplow",
    "start": "1083840",
    "end": "1091080"
  },
  {
    "text": "analytics.com [Music]",
    "start": "1091080",
    "end": "1104559"
  },
  {
    "text": "thank you for the great introduction to what lightning is is and how to think",
    "start": "1104559",
    "end": "1110799"
  },
  {
    "text": "about some of the abstractions that you're working with I'm wondering if you could maybe share a little bit I've seen",
    "start": "1110799",
    "end": "1117200"
  },
  {
    "text": "some different stories online but I was wondering from your experience with the community that's working with this could",
    "start": "1117200",
    "end": "1123480"
  },
  {
    "text": "you provide any sort of stories around how people have been able to scale things up with lightning maybe in your",
    "start": "1123480",
    "end": "1131080"
  },
  {
    "text": "own work or maybe you know stories that you like to highlight I mean there are a lot of companies and Labs using",
    "start": "1131080",
    "end": "1137600"
  },
  {
    "text": "lightning today right so you can get on GitHub and and see that for yourself I think I don't know the exact numbers but",
    "start": "1137600",
    "end": "1144440"
  },
  {
    "text": "it's definitely like you know the thousands like few thousands of them right and they go from Pharma to retail",
    "start": "1144440",
    "end": "1154039"
  },
  {
    "text": "to anything you can think of right and I think today what's interesting is that",
    "start": "1154039",
    "end": "1159760"
  },
  {
    "text": "you know when I run into these people because they're you know we're coming to work with them on grid on some of them it's interesting to hear the use cases",
    "start": "1159760",
    "end": "1165880"
  },
  {
    "text": "right like stuff that I would never imagine right because I'm not at a company doing this kind of stuff so that's why I made the joke about lcky",
    "start": "1165880",
    "end": "1171799"
  },
  {
    "text": "Martin but I'm sure you guys are doing much more advanced stuff unless I'm building you know planes there's no way",
    "start": "1171799",
    "end": "1177000"
  },
  {
    "text": "that I'd know to do that right so what's cool is just like it's been super flexible I think there are public cases",
    "start": "1177000",
    "end": "1183240"
  },
  {
    "text": "that we can talk about I mean there are blog posts by big companies like Nvidia Facebook and so on about how they use",
    "start": "1183240",
    "end": "1189400"
  },
  {
    "text": "lighning right so you can read that and I think something that we do specifically in the community is like we really like to kind of protect our",
    "start": "1189400",
    "end": "1196200"
  },
  {
    "text": "partners because like this is a community and we want to keep people's work fairly private as well so I won't",
    "start": "1196200",
    "end": "1202320"
  },
  {
    "text": "get into too many details so I'm just pointing you to open sources that you can look at and how they use it right but these are Big projects as well and",
    "start": "1202320",
    "end": "1208480"
  },
  {
    "text": "there are probably about 3,000 projects now that you sliding that you can literally just go to see them so the",
    "start": "1208480",
    "end": "1214480"
  },
  {
    "text": "companies that have open sourced their work you can see what projects they working on so it's everything from like video prediction to segmentation to NLP",
    "start": "1214480",
    "end": "1223039"
  },
  {
    "text": "right to summarization to classification we integrate really well with basically most Frameworks out there so if you use",
    "start": "1223039",
    "end": "1229440"
  },
  {
    "text": "anything that's P torch based it's very likely going to work with lightning off the bat now in terms of scaling I mean I",
    "start": "1229440",
    "end": "1236720"
  },
  {
    "text": "personally we've done it internally right but we've also heard from the corporate partners that they're training things on yeah I mean I guess the number",
    "start": "1236720",
    "end": "1245360"
  },
  {
    "text": "I don't know there's no real limit so far I guess is whatever P torch supports however many gpus you can get",
    "start": "1245360",
    "end": "1251320"
  },
  {
    "text": "your hands on yeah and like you know that's a big part of grid now right it's like with grid enlightening you can literally type in I don't know a",
    "start": "1251320",
    "end": "1257080"
  },
  {
    "text": "thousand gpus and if you have have the Amazon quota like great you know um and",
    "start": "1257080",
    "end": "1262600"
  },
  {
    "text": "then we we can give you as many as we can as well but there's no limitation right so you just have to run it and",
    "start": "1262600",
    "end": "1267799"
  },
  {
    "text": "like I know it sounds crazy but you literally just have to run it and then it'll just work right so it's just a",
    "start": "1267799",
    "end": "1273000"
  },
  {
    "text": "function of the compute there I mean a few weeks ago no it's like a month ago at this point we did a collaboration",
    "start": "1273000",
    "end": "1278880"
  },
  {
    "text": "with Microsoft so Microsoft has this Library called Deep speed which is really cool Facebook has one also with",
    "start": "1278880",
    "end": "1284200"
  },
  {
    "text": "the fair scale team and basically it lets you scale up models dramatically by helping you use CPU memory efficiently",
    "start": "1284200",
    "end": "1291039"
  },
  {
    "text": "and you know the way you Shard gradients and the way you Shard parameters across gpus really helps so we were able to",
    "start": "1291039",
    "end": "1297960"
  },
  {
    "text": "train a GPT model I think it was like I remember it was like 20 billion",
    "start": "1297960",
    "end": "1304320"
  },
  {
    "text": "parameters or something like that so we have a case study for that so just for context like the original gpt3 was I",
    "start": "1304320",
    "end": "1311200"
  },
  {
    "text": "don't remember it was like hold let me see here 160 billion parameters or something like that so I don't want to",
    "start": "1311200",
    "end": "1317440"
  },
  {
    "text": "misquote you number but basically whatever the original gpt3 was I think it was like onethird of that well only",
    "start": "1317440",
    "end": "1323640"
  },
  {
    "text": "eight gpus so that's crazy just I don't think anyone in Industry needs that much",
    "start": "1323640",
    "end": "1329440"
  },
  {
    "text": "I haven't seen people use that much so I'm just saying like that that's a pretty good lower",
    "start": "1329440",
    "end": "1335600"
  },
  {
    "text": "bound 175 billion that's or at least that's what Google is telling me on a",
    "start": "1335600",
    "end": "1341080"
  },
  {
    "text": "search yeah so you were very close and you said you were running that on what eight gpus yeah on A1 100s only eight of",
    "start": "1341080",
    "end": "1347640"
  },
  {
    "text": "them and I mean it's a100 so they're much bigger than v100s but I mean we'll be doing more tests uh that was with d",
    "start": "1347640",
    "end": "1354080"
  },
  {
    "text": "just literally and what's cool about it is if you're just using lightning on your trainer you just say I think it's like plugin equals deep speed like a",
    "start": "1354080",
    "end": "1361360"
  },
  {
    "text": "string called Deep speed just by doing that you get that out of the box right so that's the kind of stuff that we",
    "start": "1361360",
    "end": "1366720"
  },
  {
    "text": "embed into training so you know do you have to know how to do that you don't but now you get that benefit so I wanted",
    "start": "1366720",
    "end": "1372880"
  },
  {
    "text": "to real quick pop in one thing before we kind of start moving on on this there are some people that are listening that",
    "start": "1372880",
    "end": "1378640"
  },
  {
    "text": "may not they may even be not pie torch users they might be tensorflow users but they're thinking about switching you know we always get into conversations",
    "start": "1378640",
    "end": "1385760"
  },
  {
    "text": "how does a workflow look like when you're integrating pytorch lightning into your workflow uh you're using the",
    "start": "1385760",
    "end": "1391600"
  },
  {
    "text": "rest of the ecosystem could you at a high level just for those who haven't used it and maybe not have the something",
    "start": "1391600",
    "end": "1398200"
  },
  {
    "text": "directly that they're going oh yeah I've done similar to that I can just add lightning to that what that looks like what that savings why is it called",
    "start": "1398200",
    "end": "1404279"
  },
  {
    "text": "lightning for them they're kind of going oh there's this thing that may really help me can you kind just top off a",
    "start": "1404279",
    "end": "1409960"
  },
  {
    "text": "little bit of a workflow on how I go from the beginning to getting something productively deployed and what that",
    "start": "1409960",
    "end": "1415520"
  },
  {
    "text": "looks like for somebody who hasn't seen it before yeah absolutely wait so I found the block post so it was actually",
    "start": "1415520",
    "end": "1420679"
  },
  {
    "text": "45 billion parameters that we scaled it up on 8100s and uh you can look it up but it's called accessible multibillion",
    "start": "1420679",
    "end": "1427120"
  },
  {
    "text": "parameter model training with pie torch lightning and deep speed we'll link it in the show notes yeah sounds good okay",
    "start": "1427120",
    "end": "1433480"
  },
  {
    "text": "so basically it's how do you adopt lightning into your workflow right so I mean obviously if you're coming from not",
    "start": "1433480",
    "end": "1439279"
  },
  {
    "text": "P torch then you would just you know start with lightning there's um there's a very simple read me there like I would",
    "start": "1439279",
    "end": "1445240"
  },
  {
    "text": "say you know copy paste. readme there's a m this example on there and you just run it you'll notice those people will",
    "start": "1445240",
    "end": "1451480"
  },
  {
    "text": "say well but where are the advanced examples and my point is that that is the advanced example like all you have to do is change the data and it'll still",
    "start": "1451480",
    "end": "1457080"
  },
  {
    "text": "work for image that right so that's great that's the beauty of it there's no different example for that I mean we put",
    "start": "1457080",
    "end": "1463320"
  },
  {
    "text": "it if you want but at the end of the day just change your data and set gpus to 64 and you're good to to go so that's the",
    "start": "1463320",
    "end": "1470080"
  },
  {
    "text": "easy part right so if you're coming outside of P torch then you can do that if you're coming from within P torch then what T people tend to do is when",
    "start": "1470080",
    "end": "1476360"
  },
  {
    "text": "they start a new project they'll either start it on Lightning directly or they'll convert their existing projects into lightning so it is really a",
    "start": "1476360",
    "end": "1483760"
  },
  {
    "text": "refactor on your pie torch project right so you basically take your main Loop",
    "start": "1483760",
    "end": "1489240"
  },
  {
    "text": "code which usually looks something like you know you initialize a model you set a bunch of flags you set some sort of",
    "start": "1489240",
    "end": "1495200"
  },
  {
    "text": "Arc pars arguments and then you download some data or link it somehow and then",
    "start": "1495200",
    "end": "1500279"
  },
  {
    "text": "you know it's all boiler plate and then there's like a loop two Loops in there which is like you know four EPO and EPO",
    "start": "1500279",
    "end": "1506919"
  },
  {
    "text": "and then you have in there four batch in your data loader and then you start training so literally everything up to",
    "start": "1506919",
    "end": "1513799"
  },
  {
    "text": "that four batch in your data loader is deleted right so it's gone yeah so then",
    "start": "1513799",
    "end": "1519080"
  },
  {
    "text": "the only thing that you need to track is what's in there right which is like the we call that the training step which is the meat of what you want I mean think",
    "start": "1519080",
    "end": "1524840"
  },
  {
    "text": "about when you're doing work like that's where you spend your time on so that goes into this function called the training step and then the training step",
    "start": "1524840",
    "end": "1531360"
  },
  {
    "text": "goes all the way from taking your badge into generating a loss that you return with that gradient attach right so some",
    "start": "1531360",
    "end": "1537000"
  },
  {
    "text": "graph so um you know it could be a few lines usually it's only a few lines",
    "start": "1537000",
    "end": "1542039"
  },
  {
    "text": "because that's that's most of what you're doing um now the model that you left at the top that one you can keep it",
    "start": "1542039",
    "end": "1547960"
  },
  {
    "text": "separate and just pass it into lightning module and just use it you know soft. model equals model or you can Define",
    "start": "1547960",
    "end": "1553159"
  },
  {
    "text": "that model within the lightning module right so you can literally copy paste the layers and all that into the lightning module if you want because the",
    "start": "1553159",
    "end": "1559240"
  },
  {
    "text": "lighting module is an nn. module at the end of the day so that gets you basically most of it then you need to",
    "start": "1559240",
    "end": "1565120"
  },
  {
    "text": "find your Optimizer and bring it into a function called configure optimizers and then you just return it there right so",
    "start": "1565120",
    "end": "1571720"
  },
  {
    "text": "then you you know you're going to link up the parameters through that as well so that's three methods right that's your init that's your training step and",
    "start": "1571720",
    "end": "1577520"
  },
  {
    "text": "then that's your configure Optimizer and then the rest of that is optional after",
    "start": "1577520",
    "end": "1582640"
  },
  {
    "text": "that right so forward we don't actually need it we use the forward method for inference right so you train a model and",
    "start": "1582640",
    "end": "1590159"
  },
  {
    "text": "you for example an auto encoder right so an auto encoder has two sides an encoder and a decoder the encoder Maps some",
    "start": "1590159",
    "end": "1595640"
  },
  {
    "text": "input into some space and embedding and then the decoder maps that embedding back into some space so an auto encoder",
    "start": "1595640",
    "end": "1601880"
  },
  {
    "text": "can be used in two ways you can use it as a you know embedder basically so you can take an image and get an embedding",
    "start": "1601880",
    "end": "1607720"
  },
  {
    "text": "for it and then you know do similarity search and so on so if you're building like a visual engine or something you would do that or you can use a decoder",
    "start": "1607720",
    "end": "1614200"
  },
  {
    "text": "for sampling you can give it a random vector and it'll give you an image for example or you know text or whatever you",
    "start": "1614200",
    "end": "1619320"
  },
  {
    "text": "want so depending on what your use case is that's how you're going to implement the forward because the forward is",
    "start": "1619320",
    "end": "1625600"
  },
  {
    "text": "what's going to be called in production right you're going to call the model with the input to it so we actually",
    "start": "1625600",
    "end": "1630799"
  },
  {
    "text": "allow the model to be torch scripted and put into Onyx as well on and NX I guess",
    "start": "1630799",
    "end": "1636000"
  },
  {
    "text": "for production use cases it's literally a function called two Tor script2 Onyx and then you're good to go and it does",
    "start": "1636000",
    "end": "1641559"
  },
  {
    "text": "all the things for you and then you know you just have to get the inputs transform it pass it through and then do",
    "start": "1641559",
    "end": "1647080"
  },
  {
    "text": "the return so it's very simple now there's other stuff left so that's literally it so you just have to copy",
    "start": "1647080",
    "end": "1653279"
  },
  {
    "text": "that stuff and then anything else that's left is usually around data or maybe validation or or testing the validation",
    "start": "1653279",
    "end": "1660559"
  },
  {
    "text": "we have a validation step and a test step as well where you can just copy paste that code in there if you want a validation Loop or test Loop for the",
    "start": "1660559",
    "end": "1667559"
  },
  {
    "text": "data you can leave it assist you can just pass in the data loaders directly to lightning or you can use something",
    "start": "1667559",
    "end": "1673200"
  },
  {
    "text": "called the data module which is a completely optional abstraction but it's uh basically captures your training",
    "start": "1673200",
    "end": "1679120"
  },
  {
    "text": "validation and test data loader into one class and couples of transforms as well because what usually happens in big",
    "start": "1679120",
    "end": "1685760"
  },
  {
    "text": "companies is that you know I'm working on I don't know let's say I'm doing I guess maybe selling something right and",
    "start": "1685760",
    "end": "1693600"
  },
  {
    "text": "so I'm selling clothing and so I have the data set of our inventory with images and so on and then when I give it",
    "start": "1693600",
    "end": "1700519"
  },
  {
    "text": "to you you're going to be like hey how did you transformed images did you crop it did you random flip what did you do right so unless I give you that code",
    "start": "1700519",
    "end": "1707120"
  },
  {
    "text": "then it's going to be a little bit hard hard and we could mess it up so the data module embeds all of that so I just have to say here's a data module for the",
    "start": "1707120",
    "end": "1713840"
  },
  {
    "text": "clothing data set and you just run it and you know it's going to be consistent across the board no matter how you run it so that's an optional I mean highly",
    "start": "1713840",
    "end": "1720279"
  },
  {
    "text": "encourage abstraction but it's optional yeah that's basically it so if you do it I would just recommend like don't delete",
    "start": "1720279",
    "end": "1727279"
  },
  {
    "text": "your project just do the refractor first put it into Lightning Run it once right you can run it on CP when you do it with",
    "start": "1727279",
    "end": "1733679"
  },
  {
    "text": "lightning you're going to be able to run it on your local machine with CPUs or gpus take a batch data from your data",
    "start": "1733679",
    "end": "1739440"
  },
  {
    "text": "set or a single example and overfit both models like your original code and this",
    "start": "1739440",
    "end": "1744519"
  },
  {
    "text": "one with the same seat and everything and make sure you get the same result and then once you get that then you're good to go you know you didn't mess it up at that point you can go ahead and",
    "start": "1744519",
    "end": "1751039"
  },
  {
    "text": "say GPU is equals you know 128 and then off you go so it sounds like that if I'm",
    "start": "1751039",
    "end": "1757279"
  },
  {
    "text": "a pytorch developer and I'm already using that API I'm creating the layers",
    "start": "1757279",
    "end": "1763519"
  },
  {
    "text": "of my model I don't have to like throw out the way that I",
    "start": "1763519",
    "end": "1768760"
  },
  {
    "text": "the way that I created that model in some ways I get to sort of delete a bunch of my code having to do with like",
    "start": "1768760",
    "end": "1775720"
  },
  {
    "text": "the you know Hardware stuff and some of the other training related things and I",
    "start": "1775720",
    "end": "1781279"
  },
  {
    "text": "can keep my model sort of refactor it into this pytorch module the lightning",
    "start": "1781279",
    "end": "1786679"
  },
  {
    "text": "module and then called the trainer and essentially then I now have less code",
    "start": "1786679",
    "end": "1792360"
  },
  {
    "text": "but my code is also more more robust in that I can run that training on a whole",
    "start": "1792360",
    "end": "1797480"
  },
  {
    "text": "variety of hardware and that sort of thing am I basically summarizing that correct or anything you would you would",
    "start": "1797480",
    "end": "1803039"
  },
  {
    "text": "change about that and it's more readable right you can literally give it to your colleagues and then they know to go to training St to see what's happening",
    "start": "1803039",
    "end": "1809240"
  },
  {
    "text": "otherwise what do you do today you're like hey here's this like seven lines on GitHub that crazy you know you can",
    "start": "1809240",
    "end": "1814640"
  },
  {
    "text": "actually they're like wait where where is it what you're doing because most of it it's like boilerplate uh training",
    "start": "1814640",
    "end": "1819840"
  },
  {
    "text": "stuff right now you can be like hey here's exactly what I'm doing they're like oh you're sampling the lat and space before doing this thing oh",
    "start": "1819840",
    "end": "1826159"
  },
  {
    "text": "interesting right it's not mingled with all this other stuff so it's very easy to read as well you know I joke but it",
    "start": "1826159",
    "end": "1832039"
  },
  {
    "text": "is kind of like cleaning yeah like cleaning your house I guess like imagine I guess roses right so maybe this is a",
    "start": "1832039",
    "end": "1837960"
  },
  {
    "text": "good example so a rose you have to cut it from a bush and trim all the stuff and then you know you get this like bulb",
    "start": "1837960",
    "end": "1843120"
  },
  {
    "text": "at the end which is what you care about it feels like that it's like no one's adding these other leaves because they",
    "start": "1843120",
    "end": "1848240"
  },
  {
    "text": "want to it's because they have to right so when you refactor your code it's the sense of like okay it's a lot cleaner",
    "start": "1848240",
    "end": "1854559"
  },
  {
    "text": "now like I just removed a lot of unnecessary stuff and also that you're likely to mess up right like we test",
    "start": "1854559",
    "end": "1860240"
  },
  {
    "text": "very very thoroughly and we have thousands of people testing this stuff so did we mess up the backward pass",
    "start": "1860240",
    "end": "1865679"
  },
  {
    "text": "definitely not right did you mess it up hopefully [Music]",
    "start": "1865679",
    "end": "1873749"
  },
  {
    "text": "[Music] not change log Plus+ is the best way for",
    "start": "1880850",
    "end": "1887960"
  },
  {
    "text": "you to directly support practical AI join today and unlock access to a",
    "start": "1887960",
    "end": "1893240"
  },
  {
    "text": "private feed that makes the ads disappear gets you closer to the metal and help sustain our production of",
    "start": "1893240",
    "end": "1899639"
  },
  {
    "text": "practical AI into the future simply follow the change log Plus+ Link in your",
    "start": "1899639",
    "end": "1905399"
  },
  {
    "text": "show notes or Point your favorite web browser to changel log.com Plus+ once again that's changel log.com",
    "start": "1905399",
    "end": "1913320"
  },
  {
    "text": "/pl plus changelog Plus+",
    "start": "1913320",
    "end": "1919840"
  },
  {
    "text": "[Music]",
    "start": "1921190",
    "end": "1928480"
  },
  {
    "text": "better okay I want to kind of circle all the way back to where our conversation started because I want to get back to",
    "start": "1928480",
    "end": "1934679"
  },
  {
    "text": "that cool demo that I saw on Twitter about grid AI so maybe you could just",
    "start": "1934679",
    "end": "1939919"
  },
  {
    "text": "give us a little bit of sense of what grid AI is kind of how it came about how",
    "start": "1939919",
    "end": "1945480"
  },
  {
    "text": "it's maybe connected to the lightning Community if at all and then we can get into some of the details about what it",
    "start": "1945480",
    "end": "1952200"
  },
  {
    "text": "enables so I mean as you saw from my story like I care a lot about reproducibility and speed of iteration",
    "start": "1952200",
    "end": "1958360"
  },
  {
    "text": "and something that I thought a lot about as we were doing research and you know",
    "start": "1958360",
    "end": "1963399"
  },
  {
    "text": "building lighing was in a corporate setting you would want to scale this stuff up on a lot of compute and you",
    "start": "1963399",
    "end": "1970279"
  },
  {
    "text": "have Cloud resources and all these different things so the requirements for training at scale in a company are very",
    "start": "1970279",
    "end": "1975639"
  },
  {
    "text": "different right than just like on a Google Cod or kago it's just like a very different world right so you know it's",
    "start": "1975639",
    "end": "1981799"
  },
  {
    "text": "funny because you know deployment also goes into that people are like oh here you go you deployed on this thing it's",
    "start": "1981799",
    "end": "1986960"
  },
  {
    "text": "like well yeah but like most apis most real machine learning systems are not just an API right so we know that I mean",
    "start": "1986960",
    "end": "1994440"
  },
  {
    "text": "a lot of us build these models we've all been at companies before as well at scale so we know exactly the pain points there so the thing that kept coming up",
    "start": "1994440",
    "end": "2001600"
  },
  {
    "text": "is like cool lightning is letting me do all this but how do I you know I'm still having to do all of this Cloud stuff",
    "start": "2001600",
    "end": "2008120"
  },
  {
    "text": "like why you know if I ask for 32 gpus on Lightning yeah lightning will do the thing but like you need to give me the",
    "start": "2008120",
    "end": "2014000"
  },
  {
    "text": "32 gpus and giving you the 32 gpus that's a lot of work to do it consistently and at scale and cheaply so",
    "start": "2014000",
    "end": "2020360"
  },
  {
    "text": "that you don't have to burn resources right so what people end up doing generally they build these like ad hoc",
    "start": "2020360",
    "end": "2026080"
  },
  {
    "text": "internal Solutions they're like you know kind of put together bash scripts or things that like they string together",
    "start": "2026080",
    "end": "2031960"
  },
  {
    "text": "like a semblance of a platform and and they're great and like yeah you will get things running but like you won't be",
    "start": "2031960",
    "end": "2037799"
  },
  {
    "text": "able to just you know scale them down immediately you wanton to be able to have really fast build times because they're highly optimized you want to",
    "start": "2037799",
    "end": "2044000"
  },
  {
    "text": "have real-time logs you want to have real time metrics you want to have time Integrations right so all of these spells and whistles when these things",
    "start": "2044000",
    "end": "2050440"
  },
  {
    "text": "happen internally they usually get pushed away because they're not a company priority because it shouldn't be like you know you're building airplanes",
    "start": "2050440",
    "end": "2056560"
  },
  {
    "text": "you're not building machine learning platforms right so you're normally not going to put the effort into making all",
    "start": "2056560",
    "end": "2062720"
  },
  {
    "text": "the things that we care about as you know researchers and data sciences and machine learning engineers in there so",
    "start": "2062720",
    "end": "2068560"
  },
  {
    "text": "it's just going to make your life a lot harder so it's about how do we bring that whole experience and Encompass that model development cycle in a scalable",
    "start": "2068560",
    "end": "2075960"
  },
  {
    "text": "way for the needs of like companies and even big Labs right because like most serus AI Labs they're training things on",
    "start": "2075960",
    "end": "2081760"
  },
  {
    "text": "the very very large scales as well because training is a big part of the picture it's not just a deployment I",
    "start": "2081760",
    "end": "2086800"
  },
  {
    "text": "think the deployment is interesting but it's a lot easier because we've been deploying websites and things forever",
    "start": "2086800",
    "end": "2092040"
  },
  {
    "text": "right but we haven't been training for that long it's kind of a newer thing so that's really the focus of great is to",
    "start": "2092040",
    "end": "2097520"
  },
  {
    "text": "just completely eliminate the paino that was left from using Lightning by not even having to deal with it you just",
    "start": "2097520",
    "end": "2103839"
  },
  {
    "text": "type in 32 gpus and it just happens right so I'm wondering there's still a",
    "start": "2103839",
    "end": "2109839"
  },
  {
    "text": "lot of people I think and maybe I have a misconception about this that they think like maybe training models on gpus in",
    "start": "2109839",
    "end": "2118079"
  },
  {
    "text": "the cloud is always going to be more expensive than training on a sort of like you're going to buy a on-prem",
    "start": "2118079",
    "end": "2125200"
  },
  {
    "text": "server and and do it inhouse based on sort of your experience with that and like the current sort of state of cloud",
    "start": "2125200",
    "end": "2132480"
  },
  {
    "text": "providers and all of that is that perception mostly driven by the fact that you know and I feel very seen by",
    "start": "2132480",
    "end": "2139680"
  },
  {
    "text": "the comment about like you have all these bash scripts strung together that's like my life maybe um but is it",
    "start": "2139680",
    "end": "2147160"
  },
  {
    "text": "because like that way of doing things is a bit inefficient and you waste a lot of",
    "start": "2147160",
    "end": "2154359"
  },
  {
    "text": "resources and and that sort of thing or where do you think think that perception is coming from and do you think it's",
    "start": "2154359",
    "end": "2159599"
  },
  {
    "text": "accurate I guess is is my question I think yeah I think you hit it right on the nail like if your system isn't",
    "start": "2159599",
    "end": "2164640"
  },
  {
    "text": "efficient then it's more efficient to have your own machines right because like running on grid means that we",
    "start": "2164640",
    "end": "2171000"
  },
  {
    "text": "install your dependencies everything you do link up your data in a matter of minutes if not seconds right people",
    "start": "2171000",
    "end": "2176440"
  },
  {
    "text": "don't generally optimize their stuff in the back end to do that so what they end up doing is they want to run in the local machines because they don't have",
    "start": "2176440",
    "end": "2182240"
  },
  {
    "text": "to install their environments they don't have to do all this stuff again right it's just there and it's repeatable and things start immediately so it's a lot",
    "start": "2182240",
    "end": "2187640"
  },
  {
    "text": "cheaper I'm not going to say that running on your local stuff is not generally cheaper if you're doing things",
    "start": "2187640",
    "end": "2192839"
  },
  {
    "text": "247 but you're limited by bursting capabilities right so you're never going",
    "start": "2192839",
    "end": "2197880"
  },
  {
    "text": "to have you know I don't know how many gpus AWS has but it's got to be hundreds of thousands right so if you have to hit",
    "start": "2197880",
    "end": "2204079"
  },
  {
    "text": "a deadline or do something really quick and even go through ideas fast if you're buying your own gpus you're going to be",
    "start": "2204079",
    "end": "2210839"
  },
  {
    "text": "limited by how many you have there right so it's going to be more like sequential",
    "start": "2210839",
    "end": "2216079"
  },
  {
    "text": "model building as opposed to asynchronous building so with grid you can go spin up 200 gpus run for 5",
    "start": "2216079",
    "end": "2222200"
  },
  {
    "text": "minutes and shut them down and you just got a lot done right whereas on your own machines even if you were to do it",
    "start": "2222200",
    "end": "2228000"
  },
  {
    "text": "yourself on the cloud you would probably not even get the models running for you know 20 minutes and 30 while you spin up",
    "start": "2228000",
    "end": "2233560"
  },
  {
    "text": "the machine set up the all that stuff right so I can take $100 on grid and get",
    "start": "2233560",
    "end": "2238680"
  },
  {
    "text": "more GPU minutes out of it than you would normally with without optimal systems right so it's just very very",
    "start": "2238680",
    "end": "2245280"
  },
  {
    "text": "optimized now I do think that people need to know about things I mean we do a lot to lower the cost right and I think",
    "start": "2245280",
    "end": "2250800"
  },
  {
    "text": "one of those things is spot instances right so spot instances are machines that can be killed at any time by AWS",
    "start": "2250800",
    "end": "2259240"
  },
  {
    "text": "right or whatever cloud provider you're using and then at that point you're kind of done right and so but the nice thing",
    "start": "2259240",
    "end": "2264839"
  },
  {
    "text": "about spot is that it will be like I don't know 50 to 80% the discount right",
    "start": "2264839",
    "end": "2270640"
  },
  {
    "text": "so if a GPU cost $3 an hour it could be like 30 cents an hour to maybe a dollar",
    "start": "2270640",
    "end": "2276520"
  },
  {
    "text": "an hour right so really depends so I think what you're saying is true because I did the calculus myself and I in fact",
    "start": "2276520",
    "end": "2281680"
  },
  {
    "text": "I have like blog post on how to build your own gpus for this reason but that was only four 1080 TI right and it cost",
    "start": "2281680",
    "end": "2289440"
  },
  {
    "text": "me maybe six grand to build that machine which is great now $6,000 if I'm paying",
    "start": "2289440",
    "end": "2294640"
  },
  {
    "text": "full GPU prices I'll burn through that in like two weeks for sure right but if I'm paying spot prices then that's going",
    "start": "2294640",
    "end": "2301119"
  },
  {
    "text": "to that changes a game and then not only that but if I'm getting more training minutes out of that that's a lot better",
    "start": "2301119",
    "end": "2306880"
  },
  {
    "text": "and then you fact during depreciation on this other stuff plus maintenance then it actually becomes a little bit",
    "start": "2306880",
    "end": "2312000"
  },
  {
    "text": "competitive right it does I'm curious you know and we're talking a lot about the training could you talk a little bit",
    "start": "2312000",
    "end": "2317480"
  },
  {
    "text": "about grid ai's deployment story and what that is and in my mind one of the things like speaking for myself I'll be",
    "start": "2317480",
    "end": "2323960"
  },
  {
    "text": "training centrally in the cloud and stuff but at the end of the day I got to get my model or my system of models out",
    "start": "2323960",
    "end": "2330119"
  },
  {
    "text": "there into something often some sort of edge device not cloud-based you know something that's a physical thing out in",
    "start": "2330119",
    "end": "2336319"
  },
  {
    "text": "the real world can can you talk about how you work with grid AI to affect that yeah so today grid doesn't support",
    "start": "2336319",
    "end": "2342520"
  },
  {
    "text": "deployments right so the thing that we like to focus on is making sure that we really na certain experiences before",
    "start": "2342520",
    "end": "2348680"
  },
  {
    "text": "moving on to other things right so we will support deployment at some point probably very soon right but the thing",
    "start": "2348680",
    "end": "2354000"
  },
  {
    "text": "is like I don't think that we're fully fully optimal on the training side yet like I think we want to provide a really",
    "start": "2354000",
    "end": "2359040"
  },
  {
    "text": "world-class experience there so for our users today like you know you can access artifacts you can get model checkpoints",
    "start": "2359040",
    "end": "2365680"
  },
  {
    "text": "and all that stuff so the deployment most users have a deployment system in house already so they can just take the",
    "start": "2365680",
    "end": "2370920"
  },
  {
    "text": "artifacts and do their thing right so we're not blocking any of that and all of these things are like URL based and if it's lightning like I mean that's",
    "start": "2370920",
    "end": "2377200"
  },
  {
    "text": "very easy to do now we're going to make it a lot easier for sure like you know kind of the way that we do things but",
    "start": "2377200",
    "end": "2382920"
  },
  {
    "text": "today we are laser focus on training but I will say I think like working with Grid at this stage is great because I",
    "start": "2382920",
    "end": "2389160"
  },
  {
    "text": "think companies will be able to help us influence that road map right and help us build something that they really care",
    "start": "2389160",
    "end": "2394560"
  },
  {
    "text": "about as well because as soon as we start getting into deployment like we're going to do it our way right and we have",
    "start": "2394560",
    "end": "2399760"
  },
  {
    "text": "a very special way of doing things so we hope that we have the feedback from the community and users to make sure that",
    "start": "2399760",
    "end": "2405000"
  },
  {
    "text": "we're doing it in like a a really useful way and how as a user of grid AI because this is really fascinating to me because",
    "start": "2405000",
    "end": "2411800"
  },
  {
    "text": "I've even been struggling to get some in-house gpus just with supply chain issues and all of those things so",
    "start": "2411800",
    "end": "2417680"
  },
  {
    "text": "running things on the cloud is something that we're actively you know thinking a lot about and doing it in an optimized",
    "start": "2417680",
    "end": "2423800"
  },
  {
    "text": "way now we kind of talked before about going safe from pytorch to pytorch lightning let's say I've got my python",
    "start": "2423800",
    "end": "2431440"
  },
  {
    "text": "code I'm using lightning it works great and now I want to run it with grid AI on",
    "start": "2431440",
    "end": "2437560"
  },
  {
    "text": "you know 100 gpus in the cloud what does that look like do I need to set up my cloud account set up billing on that",
    "start": "2437560",
    "end": "2444520"
  },
  {
    "text": "side and then set up my grid account and then use a grid tool to connect them",
    "start": "2444520",
    "end": "2449880"
  },
  {
    "text": "both how does that whole flow work from that point so I think yeah that's a good",
    "start": "2449880",
    "end": "2455520"
  },
  {
    "text": "question okay so generally I like to think about what we're trying to do like you know the lead between I don't know",
    "start": "2455520",
    "end": "2462200"
  },
  {
    "text": "like Windows machines to MAC machines right like where things just work right so what is that Apple experience for",
    "start": "2462200",
    "end": "2468079"
  },
  {
    "text": "machine learning right and I think to answer your question it's very very easy",
    "start": "2468079",
    "end": "2473599"
  },
  {
    "text": "it's not as easy as I want it to be today but it will be so basically there are a few ways right so we have three",
    "start": "2473599",
    "end": "2480119"
  },
  {
    "text": "tiers of usage on grid right we have the community tier which is free it literally you're just paying the AWS",
    "start": "2480119",
    "end": "2485760"
  },
  {
    "text": "compute right there's nothing in there we're just orchestrating stuff for you but it doesn't really work for teams and",
    "start": "2485760",
    "end": "2491119"
  },
  {
    "text": "like big companies right because there's a lot of stuff that needs to happen so there we have the teams and Enterprise tiers that let you do those kind of",
    "start": "2491119",
    "end": "2496960"
  },
  {
    "text": "things on the community tier you literally have to do nothing you just copy paste the link to a GitHub file you",
    "start": "2496960",
    "end": "2503000"
  },
  {
    "text": "paste it into the UI or use the CLI and you select how many gpus you want and you press enter and you're done right",
    "start": "2503000",
    "end": "2509599"
  },
  {
    "text": "like it's it's that easy dependencies are automatically pulled for you they're you know inference from the code that",
    "start": "2509599",
    "end": "2515319"
  },
  {
    "text": "you have your requirements all that stuff so we try to do as much as possible yes there will be times when",
    "start": "2515319",
    "end": "2520720"
  },
  {
    "text": "that fails and we will you know work with you to figure out what happened and you know make sure that we get it done",
    "start": "2520720",
    "end": "2525960"
  },
  {
    "text": "but you know dependency management is a big deal for everyone and it's really hard problem to solve so it's going to",
    "start": "2525960",
    "end": "2531319"
  },
  {
    "text": "take us a while to fully solve that problem but if you are at a company or at a big lab like usually that's you",
    "start": "2531319",
    "end": "2537520"
  },
  {
    "text": "know we call that Community tier that's going to work great for like site projects and public data and stuff like that kagle you know prototyping things",
    "start": "2537520",
    "end": "2544119"
  },
  {
    "text": "sure if your data is not secret then it's fine so for academics as well but if you have corporate data then you're",
    "start": "2544119",
    "end": "2550119"
  },
  {
    "text": "going to be on the teams or Enterprise tier right there what you end up doing is we basically link up your Cloud",
    "start": "2550119",
    "end": "2555720"
  },
  {
    "text": "accounts right so you just set it up through grid you pass in credentials through there and then those keys let us",
    "start": "2555720",
    "end": "2561280"
  },
  {
    "text": "control resources on your behalf only as much as you allow us to right to make sure that we orchestrate everything in",
    "start": "2561280",
    "end": "2567079"
  },
  {
    "text": "your Cloud so it's kind of this hybrid on Prem versus not on Prem we also offer umrem if people want it so once you do",
    "start": "2567079",
    "end": "2573440"
  },
  {
    "text": "that you basically put in your Cloud credentials in there then you're good to go when you run stuff on grid instead of",
    "start": "2573440",
    "end": "2579440"
  },
  {
    "text": "running on the grid Cloud which is a community Cloud you just select your Cloud whatever you named it and then you just run on it right and that means you",
    "start": "2579440",
    "end": "2585920"
  },
  {
    "text": "can link up as many of these as you want as well as we kind of wind up here one of the things that's really struck me through the conversation is is that you",
    "start": "2585920",
    "end": "2592680"
  },
  {
    "text": "are a man of substantial vision and as we kind of wind up I'm really curious if",
    "start": "2592680",
    "end": "2597720"
  },
  {
    "text": "you would kind of look out a little bit beyond just you know the next product cycle and that kind of thing into where",
    "start": "2597720",
    "end": "2604119"
  },
  {
    "text": "you want to go both with grid Ai and where you see the larger industry going",
    "start": "2604119",
    "end": "2609160"
  },
  {
    "text": "in general in terms of trying to make this work a little bit better for people and take the struggle out of it that you",
    "start": "2609160",
    "end": "2615440"
  },
  {
    "text": "clearly have been working on for a while in various capacities could you tell us a little bit about what future you think",
    "start": "2615440",
    "end": "2621400"
  },
  {
    "text": "we're going toward and and what you would like to shape it and how you would like to shape it you know when I started",
    "start": "2621400",
    "end": "2627000"
  },
  {
    "text": "in research I was really disappointed that I had to do so much work over and over again that other people were doing",
    "start": "2627000",
    "end": "2633440"
  },
  {
    "text": "and that I had to learn so much just to you know decode a little bit of neuro",
    "start": "2633440",
    "end": "2638680"
  },
  {
    "text": "activity right and the world that I would love to kind of help bring to the table is a",
    "start": "2638680",
    "end": "2646640"
  },
  {
    "text": "world where the person the scientist the researcher the machine Lear engineer the person that has the knowledge of",
    "start": "2646640",
    "end": "2651800"
  },
  {
    "text": "whatever they're building right the doctor the biologist the mechanical engineer you know you name it the person",
    "start": "2651800",
    "end": "2657440"
  },
  {
    "text": "who really knows their domain can basically focus on that and not like",
    "start": "2657440",
    "end": "2662480"
  },
  {
    "text": "have machine learning and all of this Cloud stuff just kind of Fade Into the background right and just be",
    "start": "2662480",
    "end": "2667760"
  },
  {
    "text": "like Wi-Fi just like your cell phone signal like you don't think about it right you're just working on your problem so how do we take that leap and",
    "start": "2667760",
    "end": "2674240"
  },
  {
    "text": "I think that's what we're trying to solve are we there yet no but we're definitely on track and you know I think",
    "start": "2674240",
    "end": "2679920"
  },
  {
    "text": "that working with a lot of amazing companies and getting to make sure that we support their use cases is what's",
    "start": "2679920",
    "end": "2685680"
  },
  {
    "text": "going to help us get there so the person who builds the models who has the ideas that doctor they can be the ones to",
    "start": "2685680",
    "end": "2692160"
  },
  {
    "text": "actually you know train and deploy the stuff because you know at the end of the day I think that deployment is literally",
    "start": "2692160",
    "end": "2697839"
  },
  {
    "text": "just another training cycle except to dat us live and you're not back propagating into your model right that's",
    "start": "2697839",
    "end": "2703160"
  },
  {
    "text": "awesome thank you so much for talking to us about grid Ai and lightning it's been really wonderful and like I say we'll",
    "start": "2703160",
    "end": "2709599"
  },
  {
    "text": "put show notes and everything the relevant links that we've talked about in terms of lightning and grid AI",
    "start": "2709599",
    "end": "2715400"
  },
  {
    "text": "definitely check it out and yeah thank you so much for joining us William it's been a pleasure well thank you guys this",
    "start": "2715400",
    "end": "2720800"
  },
  {
    "text": "is really fun conversation thank you thank you for listening to practical",
    "start": "2720800",
    "end": "2727400"
  },
  {
    "text": "AI we appreciate your time and your attention if you enjoyed this episode help us out by spreading the word think",
    "start": "2727400",
    "end": "2734640"
  },
  {
    "text": "of a friend think of a colleague somebody who would benefit from listening to it and send him a link we'd",
    "start": "2734640",
    "end": "2739880"
  },
  {
    "text": "really appreciate it practical AI is hosted by Chris Benson and Daniel wh neck it's produced by Jared Santo with",
    "start": "2739880",
    "end": "2746559"
  },
  {
    "text": "music by break master cylinder thanks again to our sponsors fastly lenoe and launch darkley that's our show we hope",
    "start": "2746559",
    "end": "2753400"
  },
  {
    "text": "you enjoyed it and we'll talk to you again next week",
    "start": "2753400",
    "end": "2758920"
  },
  {
    "text": "[Music]",
    "start": "2761030",
    "end": "2764239"
  },
  {
    "text": "[Music]",
    "start": "2768290",
    "end": "2784040"
  },
  {
    "text": "k l",
    "start": "2784040",
    "end": "2787200"
  }
]
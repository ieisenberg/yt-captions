[
  {
    "text": "it's a three-step process so you pre-train a language model then you gather this sort of human preference",
    "start": "359",
    "end": "7719"
  },
  {
    "text": "data and train a reward model now the second reward model is trained to take",
    "start": "7719",
    "end": "16400"
  },
  {
    "text": "in a prompt and a response and score it like a human would score it according to",
    "start": "16400",
    "end": "21840"
  },
  {
    "text": "preference it's actually trained on the human preference data and it outputs a prediction of what a human preference",
    "start": "21840",
    "end": "28320"
  },
  {
    "text": "might be on this output the third and final step is that you",
    "start": "28320",
    "end": "33520"
  },
  {
    "text": "fine-tune a copy of your original language model using this trained reward",
    "start": "33520",
    "end": "39680"
  },
  {
    "text": "model and a reinforcement learning",
    "start": "39680",
    "end": "44480"
  },
  {
    "text": "[Music]",
    "start": "47120",
    "end": "50820"
  },
  {
    "text": "Loop welcome to practical AI a weekly podcast making artificial intelligence",
    "start": "52960",
    "end": "58680"
  },
  {
    "text": "practical productive and accessible to everyone subscribe now if you haven't already head to practical AI FM for all",
    "start": "58680",
    "end": "65920"
  },
  {
    "text": "the ways special thanks to our partners at fastly for delivering our shows super fast to wherever you listen check them",
    "start": "65920",
    "end": "73119"
  },
  {
    "text": "out at fastly.com and to our friends at fly.io we deploy our app servers close",
    "start": "73119",
    "end": "79119"
  },
  {
    "text": "to our users and you can too learn more at [Music]",
    "start": "79119",
    "end": "88640"
  },
  {
    "text": "fly.io welcome welcome to another fully connected episode of the Practical AI",
    "start": "88640",
    "end": "93840"
  },
  {
    "text": "podcast these episodes are where Chris and I keep you fully connected with everything that's happening in the AI",
    "start": "93840",
    "end": "100159"
  },
  {
    "text": "Community we'll take some time to discuss the latest AI news and then dig into some learning resources to help you",
    "start": "100159",
    "end": "107759"
  },
  {
    "text": "level up your machine learning game I'm Daniel whack I'm a data scientist with s",
    "start": "107759",
    "end": "113320"
  },
  {
    "text": "International and I'm joined as always by my co-host Chris Benson who is a tech strategist at locked Martin how you",
    "start": "113320",
    "end": "120200"
  },
  {
    "text": "doing Chris doing very well Happy New Year 2023 this is our first conversation",
    "start": "120200",
    "end": "126280"
  },
  {
    "text": "yeah happy New Year this is the first one we're recording in the year 2023 um looking already to be an",
    "start": "126280",
    "end": "133840"
  },
  {
    "text": "exciting year for AI things hope you got a bit of a refreshing break over winter",
    "start": "133840",
    "end": "140360"
  },
  {
    "text": "cuz there's a lot of I'm guessing it's going to be a whirlwind of AI stuff this year I think it is going to be a",
    "start": "140360",
    "end": "146519"
  },
  {
    "text": "whirlwind uh I didn't get a rest over the break because having nothing to do with AI are animal nonprofit uh we had",
    "start": "146519",
    "end": "154400"
  },
  {
    "text": "all the winter weather uh that most people in the US were aware of and we had we were doing animal emergency so we",
    "start": "154400",
    "end": "159640"
  },
  {
    "text": "saved a whole bunch of lives which made the lack of rest worthwhile um but there",
    "start": "159640",
    "end": "164800"
  },
  {
    "text": "was a lack of rest there was a lack of rest but we did a lot of good but interestingly the conversation we're",
    "start": "164800",
    "end": "170040"
  },
  {
    "text": "going to have today will play into that very non-ai side of my life because we're starting to see some crossovers",
    "start": "170040",
    "end": "176680"
  },
  {
    "text": "we'll see in a few minutes here yeah it's interesting you know um um so today spoiler alert we're going to be talking",
    "start": "176680",
    "end": "182920"
  },
  {
    "text": "about chat GPT um you've probably been expecting us to talk about chat GPT for",
    "start": "182920",
    "end": "187959"
  },
  {
    "text": "some time one of the things we wanted to do is really dig into the internals of",
    "start": "187959",
    "end": "193799"
  },
  {
    "text": "chat GPT how it works and its implications and so we wanted to do it justice which is is partially why um we",
    "start": "193799",
    "end": "200799"
  },
  {
    "text": "wanted to take some time and prep for that but it is interesting also to get a",
    "start": "200799",
    "end": "206000"
  },
  {
    "text": "little bit of perspective now that chat GPT has been out for not that long but a little while over Christmas you know I",
    "start": "206000",
    "end": "213840"
  },
  {
    "text": "was at Christmas with with my family and uh even at our family Christmas dinner",
    "start": "213840",
    "end": "220159"
  },
  {
    "text": "my dad was asking me about chat GPT and you know I at my church I had people",
    "start": "220159",
    "end": "226519"
  },
  {
    "text": "come up to me and ask about chat GPT who aren't don't work in Tech or anything like that and my barber you know whoever",
    "start": "226519",
    "end": "234760"
  },
  {
    "text": "is in my life it seems like they're at least aware of chat G PT they might not",
    "start": "234760",
    "end": "241400"
  },
  {
    "text": "know exactly what it is but they know that it's a big deal are you having a similar experience very very similar to",
    "start": "241400",
    "end": "248799"
  },
  {
    "text": "that and and for folks Daniel and I haven't talked through the holidays so you know this is the first time I'm hearing it just as you are and I'm",
    "start": "248799",
    "end": "255239"
  },
  {
    "text": "having the same experience and it's been really notable that we've you know the each new large language model uh comes",
    "start": "255239",
    "end": "261720"
  },
  {
    "text": "out and you know the various GPT series and we talk about it this is the one that's crossed over into mainstream",
    "start": "261720",
    "end": "268479"
  },
  {
    "text": "awareness and broad use and I mentioned as we were getting into the conversation",
    "start": "268479",
    "end": "274440"
  },
  {
    "text": "that it's now crossing over from the technical and AI side of my life into the non-technical and animal side as we",
    "start": "274440",
    "end": "281759"
  },
  {
    "text": "do things like narratives uh both written in video and educational material this is an amazing tool that",
    "start": "281759",
    "end": "289560"
  },
  {
    "text": "completely non AI focused people can use productively to really do good in the",
    "start": "289560",
    "end": "295639"
  },
  {
    "text": "world and get things done that they want so it's been really interesting to see how this one has been different from the",
    "start": "295639",
    "end": "301479"
  },
  {
    "text": "gpts before yeah so in your case it's something that like as you're creating",
    "start": "301479",
    "end": "309280"
  },
  {
    "text": "content you see it as potentially playing a role in whatever scripts or",
    "start": "309280",
    "end": "315240"
  },
  {
    "text": "articles or whatever that might be is that right absolutely it it's uh been quite humbling in that way experimenting",
    "start": "315240",
    "end": "322160"
  },
  {
    "text": "what was possible because the the quality of of the outputs are typically",
    "start": "322160",
    "end": "327360"
  },
  {
    "text": "much better than I can do by myself I've done that both in terms of I'm writing a children's story to teach children about",
    "start": "327360",
    "end": "333840"
  },
  {
    "text": "animals and I've been experimenting with it and every time I write something and then I seed it into chat gbt it does a",
    "start": "333840",
    "end": "340400"
  },
  {
    "text": "better job than me so it's been very humbling in that way I think of myself as a decent writer as well and then the",
    "start": "340400",
    "end": "347280"
  },
  {
    "text": "quality of video output is just uh has been quite good and there's a little workflow but it means that we can do",
    "start": "347280",
    "end": "355039"
  },
  {
    "text": "more good in the world faster it accelerates the ability to put out great content and so I think that this is one",
    "start": "355039",
    "end": "363000"
  },
  {
    "text": "of those uh inflection points that we've seen not just on a technical mirror but in the World At Large well your usage",
    "start": "363000",
    "end": "370800"
  },
  {
    "text": "has seems to be much more useful and valuable than my usage which has mostly",
    "start": "370800",
    "end": "376720"
  },
  {
    "text": "been things like writing I I remember I had chat GPT write a new Christmas Carol",
    "start": "376720",
    "end": "382280"
  },
  {
    "text": "for me about the three wise men in the style of a rap song by",
    "start": "382280",
    "end": "388039"
  },
  {
    "text": "Eminem I have to say it was it was a great rap song I didn't record it",
    "start": "388039",
    "end": "393479"
  },
  {
    "text": "because I'm not Eminem but I sent it to his people and we're having discussions",
    "start": "393479",
    "end": "398639"
  },
  {
    "text": "so okay yeah I I can't believe you're you're not sharing that with us well maybe before we jump in I I",
    "start": "398639",
    "end": "406319"
  },
  {
    "text": "think some of what we wanted to do today was just like describe a bit of like what chat GPT is what the interface",
    "start": "406319",
    "end": "412160"
  },
  {
    "text": "looks like what you can do but then really do a deep dive on what are the guts of the system why is it different",
    "start": "412160",
    "end": "418560"
  },
  {
    "text": "than what's come before in what ways is it similar to things that have come",
    "start": "418560",
    "end": "423680"
  },
  {
    "text": "before both of those things are true and so we want to do a deep dive and then think about some of the implications so",
    "start": "423680",
    "end": "430199"
  },
  {
    "text": "buckle up um hopefully this will be fun first off it is called chat GPT which is",
    "start": "430199",
    "end": "435720"
  },
  {
    "text": "interesting so the interface that they've chosen for this and the sort of design of the system is a chat interface",
    "start": "435720",
    "end": "442120"
  },
  {
    "text": "so if you go to chat gp. open.com you need to create an",
    "start": "442120",
    "end": "448160"
  },
  {
    "text": "account and we can talk about some of the implications around that in a second when you log in it gives you some",
    "start": "448160",
    "end": "455479"
  },
  {
    "text": "examples of what you can do some example capabilities and some limitations I found this interesting and we can talk",
    "start": "455479",
    "end": "462240"
  },
  {
    "text": "about it later some of how they describe the limitations and they release the model but the basic idea is there's a",
    "start": "462240",
    "end": "468400"
  },
  {
    "text": "chat interface you can type a prompt and it will respond and then you can actually continue to have dialogue with",
    "start": "468400",
    "end": "474479"
  },
  {
    "text": "the system so you can say you know tell me more about that or uh I don't",
    "start": "474479",
    "end": "480120"
  },
  {
    "text": "understand this part you know explain that bit more so some of the examples that they give are you know explain",
    "start": "480120",
    "end": "486039"
  },
  {
    "text": "Quantum Computing in simple terms prompt or how do I make an HTTP request in",
    "start": "486039",
    "end": "492039"
  },
  {
    "text": "JavaScript so there's even a you know it can output code um it can help you debug code like I mentioned it can provide",
    "start": "492039",
    "end": "499199"
  },
  {
    "text": "lyrics or scripts or structured types of things like the M&M song so um yeah",
    "start": "499199",
    "end": "505520"
  },
  {
    "text": "that's the basic input output um how did you find this sort of interface Chris in",
    "start": "505520",
    "end": "511960"
  },
  {
    "text": "terms of your own usage as related to like building scripts and other things",
    "start": "511960",
    "end": "517120"
  },
  {
    "text": "it's been interesting um in that it will take it a direction like as I've been trying out the children's story thing is",
    "start": "517120",
    "end": "524080"
  },
  {
    "text": "something I've been playing with and seeing where where chat GP chooses to take the beginning of a seat of a",
    "start": "524080",
    "end": "529800"
  },
  {
    "text": "narrative like I would start off with you know once upon a time there was a precocious raccoon named Pandora because",
    "start": "529800",
    "end": "536440"
  },
  {
    "text": "that's the hero in the story and it's been interesting to see how it's taken it but it's also it will go off in",
    "start": "536440",
    "end": "542279"
  },
  {
    "text": "directions I don't want so then I'll ask questions to kind of steer it a little bit and it will come back so it doesn't",
    "start": "542279",
    "end": "547959"
  },
  {
    "text": "it's not final output but it's producing a body of narrative that's better than I",
    "start": "547959",
    "end": "554839"
  },
  {
    "text": "could have done by far and so I find myself instead of being the creator of the story I'm kind of editing it to make",
    "start": "554839",
    "end": "560640"
  },
  {
    "text": "it work but it's a collaboration in a sense between this is one of those first",
    "start": "560640",
    "end": "566440"
  },
  {
    "text": "points where we've talked in an aspiring way about collab oration with AI for a long time but I now am doing that and",
    "start": "566440",
    "end": "573920"
  },
  {
    "text": "steering it in different ways with the uh entering in the chat and seeing where it went and asking specific questions",
    "start": "573920",
    "end": "579480"
  },
  {
    "text": "about the story it's been quite remarkable for the first time it's like having a partner in the process it just",
    "start": "579480",
    "end": "587120"
  },
  {
    "text": "happens to be that the partner is not human in this case a friend of mine uh Brent seagull uh has been also playing",
    "start": "587120",
    "end": "593600"
  },
  {
    "text": "with it a lot doing some stuff on him and that's how he described it as well he was looking at some different topics",
    "start": "593600",
    "end": "599560"
  },
  {
    "text": "and he said you know it's like having a dozen worldclass scientists for the",
    "start": "599560",
    "end": "605279"
  },
  {
    "text": "things that he was focusing on right they available to you and they're not wrong you know they never get it wrong",
    "start": "605279",
    "end": "612079"
  },
  {
    "text": "you know he had some pretty cool stuff that he was working on in a very different uh thing but it's that sense",
    "start": "612079",
    "end": "617240"
  },
  {
    "text": "of collaboration with the technology in a real life sense that's really",
    "start": "617240",
    "end": "622360"
  },
  {
    "text": "different now from the way it was before this well um as you were chatting which",
    "start": "622360",
    "end": "627680"
  },
  {
    "text": "though some great context I asked chat GPT the following what state-of-the-art",
    "start": "627680",
    "end": "633760"
  },
  {
    "text": "AI topics does the Practical AI podcast need to cover in 2023 and who should",
    "start": "633760",
    "end": "639320"
  },
  {
    "text": "they reach out to for interviews and the response so you're ready for what we'll",
    "start": "639320",
    "end": "644959"
  },
  {
    "text": "cover in 2023 let's hear it uh chat GPT said it's difficult to predict exactly",
    "start": "644959",
    "end": "651320"
  },
  {
    "text": "what the state-of-the-art and AI will be in 2023 definitely an interesting start",
    "start": "651320",
    "end": "656399"
  },
  {
    "text": "yeah as the field is evolving rapidly however some topics that might be worth covering include machine learning",
    "start": "656399",
    "end": "663560"
  },
  {
    "text": "interpretability and explainability and then it actually gives a blurb about what that is AI safety and ethics so",
    "start": "663560",
    "end": "671440"
  },
  {
    "text": "that's right in your wheelhouse and it gives an explanation of that natural language processing so we can continue",
    "start": "671440",
    "end": "677680"
  },
  {
    "text": "to talk about my favorite topic of NLP in 2023 and uh computer vision was their",
    "start": "677680",
    "end": "683600"
  },
  {
    "text": "other one and they said to find guests to interview on these topics you might consider reaching out to researchers and",
    "start": "683600",
    "end": "689000"
  },
  {
    "text": "prct practitioners working in these areas very sensible some suggestions include Rachel Thomas co-founder of",
    "start": "689000",
    "end": "697680"
  },
  {
    "text": "fast.ai Tim nck gabu co-lead of the ethical artificial intelligence team at",
    "start": "697680",
    "end": "703720"
  },
  {
    "text": "Google which is interesting that it gave that response because that is not",
    "start": "703720",
    "end": "709040"
  },
  {
    "text": "factually correct anymore as she is not with Google and actually that was in the",
    "start": "709040",
    "end": "714720"
  },
  {
    "text": "news quite a bit it was that was a that was a significant story in the AI World",
    "start": "714720",
    "end": "720000"
  },
  {
    "text": "a few months ago and then it gives a few others including Yan laon who you know",
    "start": "720000",
    "end": "725120"
  },
  {
    "text": "of course we would love to have him on the show we' love to have Rachel and timet as well um on the show but yeah",
    "start": "725120",
    "end": "730880"
  },
  {
    "text": "interesting so a few things I guess that strike me as an example with this",
    "start": "730880",
    "end": "736279"
  },
  {
    "text": "certain case is the output is definitely natural and coherent right so that is",
    "start": "736279",
    "end": "743079"
  },
  {
    "text": "thing one that's striking thing two for me is there's actually a good bit of",
    "start": "743079",
    "end": "748399"
  },
  {
    "text": "like structuring that goes on here so they actually give you know 1 2 3 four",
    "start": "748399",
    "end": "754440"
  },
  {
    "text": "the topics that we need to cover and then a bulleted list of the people that we need to have on the show yeah thing",
    "start": "754440",
    "end": "760320"
  },
  {
    "text": "three is despite it being coherent and natural it is not fully correct",
    "start": "760320",
    "end": "767079"
  },
  {
    "text": "factually right so that's maybe another element of of this you know it's funny I",
    "start": "767079",
    "end": "774000"
  },
  {
    "text": "because we've seen a fair amount of criticism about you know chat gbt getting things wrong and stuff I find it",
    "start": "774000",
    "end": "781920"
  },
  {
    "text": "curious that as we talk to humans uh about human things we get things wrong",
    "start": "781920",
    "end": "787199"
  },
  {
    "text": "constantly and factchecking and you know was that misinformation or was it just unintentional and and yet we hold these",
    "start": "787199",
    "end": "794839"
  },
  {
    "text": "Technologies to such a a perfect standard that we ourselves completely unable to hold up you know I wouldn't",
    "start": "794839",
    "end": "801639"
  },
  {
    "text": "want to ask one question and assume that it was 100% right but sure it makes it a little bit more interesting to me that",
    "start": "801639",
    "end": "808480"
  },
  {
    "text": "collaboration I I dare say takes on a human element by having error in it yeah and we'll talk a",
    "start": "808480",
    "end": "816920"
  },
  {
    "text": "little bit later about the interaction between this and humans and where the burden lies I do think that the",
    "start": "816920",
    "end": "825160"
  },
  {
    "text": "interface that they've provided and being explicit about limitations that's a good thing now certain people might um",
    "start": "825160",
    "end": "832240"
  },
  {
    "text": "kind of go back and forth on this model is not open access right like you can",
    "start": "832240",
    "end": "838320"
  },
  {
    "text": "sign up and create an account and a lot of people have done that and you can interact with it but like the model",
    "start": "838320",
    "end": "844160"
  },
  {
    "text": "Waits itself and you know it's not released publicly in that sense even if",
    "start": "844160",
    "end": "849639"
  },
  {
    "text": "a lot of people can use it for free at the moment there's pros and cons there but I think it's interesting that this",
    "start": "849639",
    "end": "856560"
  },
  {
    "text": "model as opposed to gpt3 earlier it was I think easier for the general",
    "start": "856560",
    "end": "863279"
  },
  {
    "text": "population to interact with this model right away in comparison with GPT three",
    "start": "863279",
    "end": "870040"
  },
  {
    "text": "which you know had a very long prolonged kind of weight list and timing and all of that and lots of explanation so it",
    "start": "870040",
    "end": "878040"
  },
  {
    "text": "seems like that they've kind of shifted the scales a little bit in terms of making access to run the model more open",
    "start": "878040",
    "end": "886720"
  },
  {
    "text": "while still maintaining it as a closed model and providing limitations so it's",
    "start": "886720",
    "end": "891880"
  },
  {
    "text": "interesting to see also that kind of shift in Dynamics which I think probably was influenced by the fact that you know",
    "start": "891880",
    "end": "899320"
  },
  {
    "text": "actual Open Access models like stable diffusion and O others have taken off so",
    "start": "899320",
    "end": "905000"
  },
  {
    "text": "widely so quickly because they are more Open Access wise and so I felt like we",
    "start": "905000",
    "end": "911600"
  },
  {
    "text": "saw open AI shift a little bit in how they released this while still kind of",
    "start": "911600",
    "end": "917120"
  },
  {
    "text": "maintaining some of the elements of how they released gpt3 and others I I agree",
    "start": "917120",
    "end": "922480"
  },
  {
    "text": "with that yeah I mean we've seen that kind of evolution as they've explored release approaches over time you know",
    "start": "922480",
    "end": "929240"
  },
  {
    "text": "with in iterations and such I think one of the things that we've seen you know",
    "start": "929240",
    "end": "934759"
  },
  {
    "text": "across this is the fact that every time a breakthrough comes on we're starting",
    "start": "934759",
    "end": "939959"
  },
  {
    "text": "to have fairly quick followup once people know that something is possible they manage to kind of reverse engineer",
    "start": "939959",
    "end": "945880"
  },
  {
    "text": "it so I suspect that uh aside from Strictly jat GPT that we will see some",
    "start": "945880",
    "end": "952160"
  },
  {
    "text": "fast followers pretty [Music]",
    "start": "952160",
    "end": "957369"
  },
  {
    "text": "soon [Music]",
    "start": "957920",
    "end": "963079"
  },
  {
    "text": "all right Chris Let's uh get into the technical details of this which I know I'm excited to chat through no I guess",
    "start": "963959",
    "end": "971519"
  },
  {
    "text": "pun intended in that case oh boy there's kind of two elements of this that I think are important to talk about before",
    "start": "971519",
    "end": "977519"
  },
  {
    "text": "we talk about what actually was done with chat GPT specifically and these two",
    "start": "977519",
    "end": "984199"
  },
  {
    "text": "things are more General than chat GPT um one is is sort of the GPT family of",
    "start": "984199",
    "end": "992240"
  },
  {
    "text": "language models and those types of language models and then also a technology or approach called",
    "start": "992240",
    "end": "999000"
  },
  {
    "text": "reinforcement learning from Human feedback those two things kind of combined here to create the chat GPT",
    "start": "999000",
    "end": "1008440"
  },
  {
    "text": "system and these two types of models and approach have been applied more widely",
    "start": "1008440",
    "end": "1015000"
  },
  {
    "text": "in other cases and by other people but here they were applied by open AI so starting to talk about this sort of",
    "start": "1015000",
    "end": "1021279"
  },
  {
    "text": "language family model of gpts we had GPT and gpt2 and gpt3 and GPT 3.5 and I",
    "start": "1021279",
    "end": "1029360"
  },
  {
    "text": "don't know what to be honest I don't know what number we're on now but these",
    "start": "1029360",
    "end": "1034880"
  },
  {
    "text": "GPT language models are just that they're a language model and there're a",
    "start": "1034880",
    "end": "1040079"
  },
  {
    "text": "specific type of language model called a causal language model people might be",
    "start": "1040079",
    "end": "1045839"
  },
  {
    "text": "familiar or at least have heard the words causal language model CLM or mass",
    "start": "1045839",
    "end": "1051160"
  },
  {
    "text": "language model MLM so Mass language model kind of takes a sentence and the",
    "start": "1051160",
    "end": "1057200"
  },
  {
    "text": "what it's trained to do is kind of for one word that's masked in the sentence or taken out or given a special token",
    "start": "1057200",
    "end": "1064320"
  },
  {
    "text": "it's trained to predict that based on everything else in the sentence so it it sort of looks both ways at the sentence",
    "start": "1064320",
    "end": "1070960"
  },
  {
    "text": "and tries to predict the mask GPT is is not a mass language model it's a causal",
    "start": "1070960",
    "end": "1076760"
  },
  {
    "text": "language model which means that it's trained to predict the next word in a",
    "start": "1076760",
    "end": "1082360"
  },
  {
    "text": "sequence of words or in a sequence of tokens whatever those tokens might be it",
    "start": "1082360",
    "end": "1087880"
  },
  {
    "text": "does that and it predicts the next word in the sequence but it does it based on all of the previous words and it does",
    "start": "1087880",
    "end": "1095559"
  },
  {
    "text": "that sequentially so as you go through the sentence the training methodology is",
    "start": "1095559",
    "end": "1101080"
  },
  {
    "text": "what they call Auto regressive means that it predicts the next thing from all the previous things and then once it's",
    "start": "1101080",
    "end": "1107000"
  },
  {
    "text": "predict that next thing then it predict the next next thing based on all the previous things and then the next next",
    "start": "1107000",
    "end": "1112919"
  },
  {
    "text": "next thing and Etc and that's the auto regressive part of it I suppose we're",
    "start": "1112919",
    "end": "1118520"
  },
  {
    "text": "kind of seeing that in action uh because when you're using the interface it doesn't just give you the entire output",
    "start": "1118520",
    "end": "1125159"
  },
  {
    "text": "all at one time it comes back with text you see the text developing much as if",
    "start": "1125159",
    "end": "1130600"
  },
  {
    "text": "you were typing it you know on the screen yourself um so I guess it you're gradually seeing each of those",
    "start": "1130600",
    "end": "1136240"
  },
  {
    "text": "iterations coming back yeah and I think in the original gpt3 interface or the",
    "start": "1136240",
    "end": "1142039"
  },
  {
    "text": "playground that we both played with you kind of see this as well you kind of give a prompt and then it then it",
    "start": "1142039",
    "end": "1148640"
  },
  {
    "text": "generates this text out and that allows it also to be very flexible right and produce these structures and also allows",
    "start": "1148640",
    "end": "1155240"
  },
  {
    "text": "it to be flexible between different tasks like if you start prompting it",
    "start": "1155240",
    "end": "1160600"
  },
  {
    "text": "with question answers it sort of learns that pattern and in a sort of few shot",
    "start": "1160600",
    "end": "1166360"
  },
  {
    "text": "way and then starts predicting next question and answers or something like that or if you want a script or if you",
    "start": "1166360",
    "end": "1172440"
  },
  {
    "text": "want a narrative or if you want something else it kind of adapts in that few shot learning sort of way which is a",
    "start": "1172440",
    "end": "1179799"
  },
  {
    "text": "key element of this GPT or causal language model structure and GPT is not",
    "start": "1179799",
    "end": "1184880"
  },
  {
    "text": "the only one there's other ones but this is the family which GPT sits in and you",
    "start": "1184880",
    "end": "1190640"
  },
  {
    "text": "mentioned just as a two-c sideline you mentioned F shot do you want to real quick just for those who may not be",
    "start": "1190640",
    "end": "1195799"
  },
  {
    "text": "familiar yeah so kind of some jargon few shot zero shot is thrown around a zero",
    "start": "1195799",
    "end": "1202280"
  },
  {
    "text": "shot prediction or usage of a model means that maybe you're using a model on",
    "start": "1202280",
    "end": "1209080"
  },
  {
    "text": "inputs or a type of input that it's never seen before even though it's seen maybe similar things so this happens",
    "start": "1209080",
    "end": "1216200"
  },
  {
    "text": "with like machine translation models that are multilingual maybe because you might have in your training data like",
    "start": "1216200",
    "end": "1222760"
  },
  {
    "text": "English to French and you know Arabic to Spanish but you don't have examples",
    "start": "1222760",
    "end": "1229640"
  },
  {
    "text": "English to Spanish but you have English and Spanish data in the data set and so you could still ask that model to try to",
    "start": "1229640",
    "end": "1236480"
  },
  {
    "text": "Output in English to Spanish translation and actually that can kind of work in certain scenarios F shot means that",
    "start": "1236480",
    "end": "1244280"
  },
  {
    "text": "you're not quite doing it that way but you're providing a a small number of",
    "start": "1244280",
    "end": "1249760"
  },
  {
    "text": "prompts that kind of guide the language model into the type of thing that you're wanting to do so in the",
    "start": "1249760",
    "end": "1257280"
  },
  {
    "text": "gpt3 inter interface or playground if you remember you can kind of start with a question answer template and provide",
    "start": "1257280",
    "end": "1264120"
  },
  {
    "text": "some examples and then you can provide the next one and it'll answer it for you um and so you provide that set of",
    "start": "1264120",
    "end": "1270559"
  },
  {
    "text": "templates or prompts and this kind of gets into this idea of prompt engineering and that sort of thing",
    "start": "1270559",
    "end": "1276480"
  },
  {
    "text": "because these models are so flexible so that was the original paper from gpt3 was titled something like you know",
    "start": "1276480",
    "end": "1283360"
  },
  {
    "text": "language models or few shot Learners or something like that that was one of the big Ideas there",
    "start": "1283360",
    "end": "1289279"
  },
  {
    "text": "that kind of gets us to GPT and language models but Chad GPT well I guess it is a model like that",
    "start": "1289279",
    "end": "1297679"
  },
  {
    "text": "so it is a GPT based model but the reason why the system is so powerful is",
    "start": "1297679",
    "end": "1303840"
  },
  {
    "text": "because it's a language model that has been trained in a very unique way um",
    "start": "1303840",
    "end": "1311440"
  },
  {
    "text": "that has proved to be actually quite valuable and that's that it is a GPT",
    "start": "1311440",
    "end": "1317320"
  },
  {
    "text": "based model that was trained using reinforcement learning from Human feedback or R lhf reinforcement learning",
    "start": "1317320",
    "end": "1324799"
  },
  {
    "text": "from Human feedback we'll link to this in the uh show notes but there is a",
    "start": "1324799",
    "end": "1330640"
  },
  {
    "text": "really great article on the hugging face blog from Nathan Lambert Luis kriado um",
    "start": "1330640",
    "end": "1337600"
  },
  {
    "text": "Leonardo van Vera and Alex havala called reinforcement learning from Human",
    "start": "1337600",
    "end": "1343320"
  },
  {
    "text": "feedback and they talk about chat GPT and other like models so we're going to",
    "start": "1343320",
    "end": "1349240"
  },
  {
    "text": "pull a lot of our insights from this article so thank you to all of you for writing this article because it was",
    "start": "1349240",
    "end": "1355520"
  },
  {
    "text": "really helpful much more helpful than the maybe the open AI blog by itself um",
    "start": "1355520",
    "end": "1361720"
  },
  {
    "text": "the major idea here with reinforcement learning from Human feedback is trying",
    "start": "1361720",
    "end": "1366799"
  },
  {
    "text": "to answer the question like can we use human feedback on generated text as a",
    "start": "1366799",
    "end": "1372960"
  },
  {
    "text": "measure of performance that goes beyond sort of just like automated measures of",
    "start": "1372960",
    "end": "1378919"
  },
  {
    "text": "performance so how do we integrate human feedback into the loop of training a model as a performance metric and in",
    "start": "1378919",
    "end": "1386320"
  },
  {
    "text": "that way we're sort of training a language model but we're also training it in ways that match human preference",
    "start": "1386320",
    "end": "1393080"
  },
  {
    "text": "for answers so human preference is a key piece of this and I think that's why you",
    "start": "1393080",
    "end": "1398320"
  },
  {
    "text": "know people like chat GPT is we prefer the things that it outputs right I don't",
    "start": "1398320",
    "end": "1404320"
  },
  {
    "text": "know if that was the case for you like with just a raw language model like G pt3 you can get some cool stuff output",
    "start": "1404320",
    "end": "1411960"
  },
  {
    "text": "but it might not fit your preferences of like how a human would actually respond",
    "start": "1411960",
    "end": "1417240"
  },
  {
    "text": "to something you know going back to the example I mentioned in the beginning that was the trick for me was you know",
    "start": "1417240",
    "end": "1422799"
  },
  {
    "text": "like using the children's story as an example I had a specific rough narrative",
    "start": "1422799",
    "end": "1428279"
  },
  {
    "text": "in mind because I'm trying to teach and there are certain points that I'm trying to illustrate and obviously it doesn't",
    "start": "1428279",
    "end": "1434640"
  },
  {
    "text": "know that the model but the model if you work with the model being being able to kind of you know continue to point it",
    "start": "1434640",
    "end": "1441480"
  },
  {
    "text": "the right way that was that was very interesting I I'm am curious going back to what you were talking about a moment",
    "start": "1441480",
    "end": "1446600"
  },
  {
    "text": "ago with you know the reinforcement learning with the human feedback how does that scale you know because if we",
    "start": "1446600",
    "end": "1453520"
  },
  {
    "text": "were to compare this for a moment I know this is very much a kind of a newbie question but for those of us who are not",
    "start": "1453520",
    "end": "1459400"
  },
  {
    "text": "you know deeply into language models you know when we were looking at other types of models a couple of years two three",
    "start": "1459400",
    "end": "1465320"
  },
  {
    "text": "four five years ago um there was always a challenge about getting human feedback to scale with the amount of training",
    "start": "1465320",
    "end": "1471520"
  },
  {
    "text": "data how is that tackled in this approach so that you can do reinforcement learning that way but it",
    "start": "1471520",
    "end": "1477679"
  },
  {
    "text": "scales to you know what we're doing at GPT there's actually like a whole Loop of models involved here and different",
    "start": "1477679",
    "end": "1484399"
  },
  {
    "text": "training sets that are of different scales and different models that are of different scales so let me talk through",
    "start": "1484399",
    "end": "1491440"
  },
  {
    "text": "a little bit of that and I hopefully that will become more clear cuz yeah obviously human feedback is expensive in",
    "start": "1491440",
    "end": "1498399"
  },
  {
    "text": "in terms of gathering it right so how much of this do you need so there's three steps the the process with which",
    "start": "1498399",
    "end": "1505720"
  },
  {
    "text": "chat GPT was trained and other models using this reinforcement learning from Human feedback approach it's a",
    "start": "1505720",
    "end": "1511880"
  },
  {
    "text": "three-step process so you pre-train a language model which is not new we've been doing that for quite some time",
    "start": "1511880",
    "end": "1518440"
  },
  {
    "text": "right you pre-train a language model then you gather this sort of human",
    "start": "1518440",
    "end": "1524159"
  },
  {
    "text": "preference data and train a reward model now this second reward model is trained",
    "start": "1524159",
    "end": "1532600"
  },
  {
    "text": "to take in a prompt and a response and score it like a human would score it",
    "start": "1532600",
    "end": "1539159"
  },
  {
    "text": "according to preference it's actually trained on the human preference data and it outputs a prediction of what a human",
    "start": "1539159",
    "end": "1545600"
  },
  {
    "text": "preference might be on this output and then the third and final step is that",
    "start": "1545600",
    "end": "1551279"
  },
  {
    "text": "you fine-tune a copy of your original language model using this trained reward",
    "start": "1551279",
    "end": "1558559"
  },
  {
    "text": "model and a reinforcement learning Loop sort is it kind of the discriminator",
    "start": "1558559",
    "end": "1564480"
  },
  {
    "text": "you're using the reward model as the discriminator in that or it's like uh in a in a reinforcement learning Loop you",
    "start": "1564480",
    "end": "1571960"
  },
  {
    "text": "would have a kind of policy which outputs like what you should do next",
    "start": "1571960",
    "end": "1577360"
  },
  {
    "text": "sort of thing and then you have some type of reward system that rewards the",
    "start": "1577360",
    "end": "1582679"
  },
  {
    "text": "agent for acting according to the policy or not so in this case the reward model",
    "start": "1582679",
    "end": "1588120"
  },
  {
    "text": "is outputting that reward or that preference and the language model is actually acting as the policy here so",
    "start": "1588120",
    "end": "1595640"
  },
  {
    "text": "you have an original language model that is kind of your original policy and isn't fine-tuned yet according to human",
    "start": "1595640",
    "end": "1602360"
  },
  {
    "text": "feedback then you gather some human feedback like actual human feedback",
    "start": "1602360",
    "end": "1607480"
  },
  {
    "text": "train a reward model to simulate that human feedback and then you fine-tune a",
    "start": "1607480",
    "end": "1614000"
  },
  {
    "text": "copy of your original language model a copy of your policy with the this uh",
    "start": "1614000",
    "end": "1619039"
  },
  {
    "text": "reward model and so the pre-trained language model it could be any language",
    "start": "1619039",
    "end": "1624279"
  },
  {
    "text": "model it doesn't have to be a gpt3 but in the case of open AI it was",
    "start": "1624279",
    "end": "1630240"
  },
  {
    "text": "gpt3 but you have an original language model and that language model could just be a general pre-trained language model",
    "start": "1630240",
    "end": "1636559"
  },
  {
    "text": "or you could additionally fine-tune that model and maybe for a domain or a",
    "start": "1636559",
    "end": "1641919"
  },
  {
    "text": "specific type of output you want so that's your pre-trained language model and the step two to get the reward model",
    "start": "1641919",
    "end": "1649480"
  },
  {
    "text": "what you do is you start outputting data from your original policy from your",
    "start": "1649480",
    "end": "1654919"
  },
  {
    "text": "original language model and you have humans rate it maybe you combine that",
    "start": "1654919",
    "end": "1660919"
  },
  {
    "text": "with certain human output or certain other uh outputs and you have human rating so that way you're kind of you're",
    "start": "1660919",
    "end": "1667360"
  },
  {
    "text": "creating a training set for your reward model which includes human labels of",
    "start": "1667360",
    "end": "1674640"
  },
  {
    "text": "their preference then in also in this step two you then train a reward model",
    "start": "1674640",
    "end": "1680880"
  },
  {
    "text": "using that data that you've gathered from humans to Output the preference now to your point of like how does this",
    "start": "1680880",
    "end": "1688480"
  },
  {
    "text": "scale well the fine-tuning of the policy is done kind of with this automated",
    "start": "1688480",
    "end": "1693600"
  },
  {
    "text": "reinforcement learning Loop but you do need humans to generate enough data to",
    "start": "1693600",
    "end": "1699039"
  },
  {
    "text": "train your reward model that's used in that Loop and what's interesting is and the hugging face blog makes this point",
    "start": "1699039",
    "end": "1706120"
  },
  {
    "text": "is that different people or different groups that have applied this",
    "start": "1706120",
    "end": "1711200"
  },
  {
    "text": "reinforcement learning from Human feedback have used different sized reward models and obviously as the size",
    "start": "1711200",
    "end": "1718000"
  },
  {
    "text": "of your reward model increases you need more data to train it that would be a general general rule in the case of open",
    "start": "1718000",
    "end": "1725880"
  },
  {
    "text": "AI their main language model was like 175 billion parameters and the reward model was much much smaller 6 billion",
    "start": "1725880",
    "end": "1733679"
  },
  {
    "text": "parameters in other cases people have done similarly SI models and so I think",
    "start": "1733679",
    "end": "1740279"
  },
  {
    "text": "that is an open question like how should these models sizewise be related to one",
    "start": "1740279",
    "end": "1745919"
  },
  {
    "text": "another what types of models should you use for your reward model and how much human feedback do you need I to be",
    "start": "1745919",
    "end": "1752840"
  },
  {
    "text": "honest I think those are open research questions let me ask you another question on that with us getting high",
    "start": "1752840",
    "end": "1758919"
  },
  {
    "text": "quality output that is comparable to human output uh very closely um and",
    "start": "1758919",
    "end": "1764600"
  },
  {
    "text": "where if you were to get that output you would find a very difficult time knowing whether it was the model or",
    "start": "1764600",
    "end": "1770480"
  },
  {
    "text": "human that did that does that potentially go back in to train further reward models where you're using",
    "start": "1770480",
    "end": "1775919"
  },
  {
    "text": "essentially synthetic data as the output of a previously trained and so you can",
    "start": "1775919",
    "end": "1781080"
  },
  {
    "text": "build on it and uh essentially there's a point where you have enough data where you're largely able to take humans back",
    "start": "1781080",
    "end": "1787399"
  },
  {
    "text": "out you recognizing it's the tool of the day but in the future you can take humans back out of that Loop of",
    "start": "1787399",
    "end": "1793399"
  },
  {
    "text": "providing the reward uh model to do that do you anticipate that that would be a reasonable",
    "start": "1793399",
    "end": "1798840"
  },
  {
    "text": "expectation I think in this methodology the reinforcement learning from Human",
    "start": "1798840",
    "end": "1804279"
  },
  {
    "text": "feedback one of the goals in that middle step is to get enough human feedback",
    "start": "1804279",
    "end": "1809799"
  },
  {
    "text": "that you kind of reduce the harm and the helpfulness of the output model so this",
    "start": "1809799",
    "end": "1817440"
  },
  {
    "text": "is really addressing I think some of those kind of problems with large language models of hallucination and",
    "start": "1817440",
    "end": "1824559"
  },
  {
    "text": "harmful effects General output and you can address those what what I think is the finding here is you can address",
    "start": "1824559",
    "end": "1831080"
  },
  {
    "text": "those with humans in the loop rather than humans totally out of the loop now",
    "start": "1831080",
    "end": "1836960"
  },
  {
    "text": "here in the next uh step that we'll describe in the process humans are taken back out of the loop to fine-tune the",
    "start": "1836960",
    "end": "1844279"
  },
  {
    "text": "model but there that Central piece so this three-step process of starting with",
    "start": "1844279",
    "end": "1850320"
  },
  {
    "text": "a language model on one end ending with a reinforcement learning trained model",
    "start": "1850320",
    "end": "1856279"
  },
  {
    "text": "on the other end has this middle step that I think is a really key piece of it",
    "start": "1856279",
    "end": "1862120"
  },
  {
    "text": "that actually helps the utility of the output and potentially reducing harm of",
    "start": "1862120",
    "end": "1867519"
  },
  {
    "text": "the output which is that human feedback [Music]",
    "start": "1867519",
    "end": "1878608"
  },
  {
    "text": "piece all right Chris we're about to the end of this reinforcement learning from",
    "start": "1878639",
    "end": "1883679"
  },
  {
    "text": "Human feedback loop just uh in summary the the loop is we have a pre-trained",
    "start": "1883679",
    "end": "1889519"
  },
  {
    "text": "language model then we gather this human feedback or rating of the output to",
    "start": "1889519",
    "end": "1896760"
  },
  {
    "text": "train a reward model now we're actually going to use that reward model so in the final step of the process we make a copy",
    "start": "1896760",
    "end": "1904559"
  },
  {
    "text": "of the original language model or the policy so you have an original policy and you have a copy of the policy or a",
    "start": "1904559",
    "end": "1912320"
  },
  {
    "text": "original language model and a copy of the language model you put in a prompt",
    "start": "1912320",
    "end": "1918039"
  },
  {
    "text": "to each of those models and then you get an output from each of those models then",
    "start": "1918039",
    "end": "1923799"
  },
  {
    "text": "you use a sort of constrained reward function where you actually penalize if",
    "start": "1923799",
    "end": "1930880"
  },
  {
    "text": "the updated model is straying too far away from the original model because I think what theyve found is you know if",
    "start": "1930880",
    "end": "1937639"
  },
  {
    "text": "you allow it to sort of just take any direction in the output you want it can have computationally some optimization",
    "start": "1937639",
    "end": "1945159"
  },
  {
    "text": "problems so you kind of gradually change this language model from the original",
    "start": "1945159",
    "end": "1950399"
  },
  {
    "text": "and you have a penalty for how far that output Strays from the original output",
    "start": "1950399",
    "end": "1957000"
  },
  {
    "text": "and then you score that output with this reward model that you've created and the way that they're doing the updates for",
    "start": "1957000",
    "end": "1963240"
  },
  {
    "text": "chat GPT and some of these others with a reinforcement algorithm called proximal",
    "start": "1963240",
    "end": "1968679"
  },
  {
    "text": "policy optimization which you have sort of two levels of what in physics I would",
    "start": "1968679",
    "end": "1974559"
  },
  {
    "text": "think of as adiabatic change meaning like things don't don't change too quickly um one is you don't stray from",
    "start": "1974559",
    "end": "1981799"
  },
  {
    "text": "the original policy output too much or you're penalized from that and secondly this reinforcement learning algorithm",
    "start": "1981799",
    "end": "1989480"
  },
  {
    "text": "called po um prevents you from making twoo big of updates to your model weights in each",
    "start": "1989480",
    "end": "1996480"
  },
  {
    "text": "step that way you don't have again this kind of a hard optimization to do but in",
    "start": "1996480",
    "end": "2003000"
  },
  {
    "text": "summary you kind of have these two models the original one the updated one you output a prompt from both of them",
    "start": "2003000",
    "end": "2009000"
  },
  {
    "text": "those go into your reward function um which includes a penalty element for",
    "start": "2009000",
    "end": "2015399"
  },
  {
    "text": "straining too far from the same output it also includes the actual estimated",
    "start": "2015399",
    "end": "2020840"
  },
  {
    "text": "reward or estimated preference from your reward model and then that reward is",
    "start": "2020840",
    "end": "2026159"
  },
  {
    "text": "then used to update the weights of your copy model or your new policy using this",
    "start": "2026159",
    "end": "2034200"
  },
  {
    "text": "PO reinforcement learning algorithm so hopefully there's some diagrams in the post that I",
    "start": "2034200",
    "end": "2040600"
  },
  {
    "text": "think are quite helpful it's a bit hard on a podcast but hopefully that Loop makes some sense in terms of how you're",
    "start": "2040600",
    "end": "2047039"
  },
  {
    "text": "updating this and this updated policy or this updated language model is the model",
    "start": "2047039",
    "end": "2052839"
  },
  {
    "text": "that is used so this is like the chat GPT model that comes out of the end I",
    "start": "2052839",
    "end": "2057878"
  },
  {
    "text": "think given the limitations of our medium here I think that was a very lucid explanation of translating it so",
    "start": "2057879",
    "end": "2064320"
  },
  {
    "text": "appreciate that I definitely learned some good I know formulas you can ask chat GPT to Output all of the right",
    "start": "2064320",
    "end": "2071320"
  },
  {
    "text": "formulas and I'm sure it would do a fine job where do you think we're going from",
    "start": "2071320",
    "end": "2076560"
  },
  {
    "text": "here like as you have looked at this progression of these models over that we've covered on the show over time with",
    "start": "2076560",
    "end": "2083839"
  },
  {
    "text": "chat GPT in particular it's been I've been kind of amazed at what it could do and using it but I'm really really",
    "start": "2083839",
    "end": "2090158"
  },
  {
    "text": "curious about where this is going and I think it's capturing a lot of people's imagination in that way that are outside",
    "start": "2090159",
    "end": "2095599"
  },
  {
    "text": "the field like what's next I think there's still open research questions here that are worth exploring and then",
    "start": "2095599",
    "end": "2102280"
  },
  {
    "text": "there's like workflow and practical implications I think on the first side",
    "start": "2102280",
    "end": "2108599"
  },
  {
    "text": "as was mentioned already and we were discussing this reward model as far as I can tell it's not totally determined",
    "start": "2108599",
    "end": "2115640"
  },
  {
    "text": "like what the architecture of this reward model should look like how big it should be in relation to the model that",
    "start": "2115640",
    "end": "2122800"
  },
  {
    "text": "you're fine-tuning how much human feedback should you use how does the amount of human feedback that you get",
    "start": "2122800",
    "end": "2129560"
  },
  {
    "text": "influence the harmfulness or the utility of the output and that sort of thing so",
    "start": "2129560",
    "end": "2135400"
  },
  {
    "text": "I think there's a lot to explore around that dynamic between the reward model and the the language model in addition I",
    "start": "2135400",
    "end": "2142240"
  },
  {
    "text": "mean language models are still being developed right so chat GPT used the GPT",
    "start": "2142240",
    "end": "2150000"
  },
  {
    "text": "3.5 language model as this original policy right and they actually used a",
    "start": "2150000",
    "end": "2155480"
  },
  {
    "text": "fine-tune version of that using supervised methods and human chat",
    "start": "2155480",
    "end": "2161119"
  },
  {
    "text": "conversations so they started with a fine-tune version of chat or of GPT 3.5",
    "start": "2161119",
    "end": "2168040"
  },
  {
    "text": "so obviously we're going to have a GPT 4 GPT 5 we're going to have other language models from other providers right from",
    "start": "2168040",
    "end": "2175960"
  },
  {
    "text": "other research groups you know big science or Google or Microsoft or",
    "start": "2175960",
    "end": "2181400"
  },
  {
    "text": "whoever is developing these other language models we're going to have updated versions of those so I think we",
    "start": "2181400",
    "end": "2186440"
  },
  {
    "text": "can see a research Direction with this where people are trying different pre-train models as their original",
    "start": "2186440",
    "end": "2192079"
  },
  {
    "text": "policy where people are trying different reward models where they're mixing them up in interesting ways where they're",
    "start": "2192079",
    "end": "2198160"
  },
  {
    "text": "maybe using slightly modified versions of the PO algorithm or other reinforcement learning algorithms to do",
    "start": "2198160",
    "end": "2205520"
  },
  {
    "text": "the updates so there's a research Direction where I think we'll just see a lot of",
    "start": "2205520",
    "end": "2210760"
  },
  {
    "text": "Exploration with this kind of template as the structure that they're exploring",
    "start": "2210760",
    "end": "2216319"
  },
  {
    "text": "the second piece which is maybe more interesting to some of our audiences like what are the implications of this",
    "start": "2216319",
    "end": "2222640"
  },
  {
    "text": "in terms of people's workflow that was about to ask you that if you hadn't gone there so yeah I don't know what are your",
    "start": "2222640",
    "end": "2229800"
  },
  {
    "text": "initial thoughts there Chris it's less about the technical aspects of the model and more about going back to the user",
    "start": "2229800",
    "end": "2235880"
  },
  {
    "text": "interface considerations that we talked about earlier in the conversation I would be amazed if the community at",
    "start": "2235880",
    "end": "2242119"
  },
  {
    "text": "large not just open AI hasn't understood the impact of making choices like that it may not be specific to the model",
    "start": "2242119",
    "end": "2248680"
  },
  {
    "text": "development but how you're putting it out there and they're seeing widespread adoption you know when you go into their",
    "start": "2248680",
    "end": "2254760"
  },
  {
    "text": "interface uh you get a warning right off the bat we're experiencing exceptionally high demand please hang in tight as we",
    "start": "2254760",
    "end": "2261599"
  },
  {
    "text": "scale our systems and I think that's indicative of the fact that people who",
    "start": "2261599",
    "end": "2266760"
  },
  {
    "text": "are not normally listeners of this podcast are starting to find a lot of utility for the first time ever it'll be",
    "start": "2266760",
    "end": "2273599"
  },
  {
    "text": "interesting you know we keep talking about exponential growth in this field and these amazing you know kind of mini",
    "start": "2273599",
    "end": "2280119"
  },
  {
    "text": "revolutions along the way but this is that first point where it's probably going orders of magnitude broader in",
    "start": "2280119",
    "end": "2286800"
  },
  {
    "text": "terms of applicability to different workflows and audiences so and as we're looking at you know you're combining",
    "start": "2286800",
    "end": "2293839"
  },
  {
    "text": "just for a moment going back and combining natural language with the large language models with with",
    "start": "2293839",
    "end": "2299720"
  },
  {
    "text": "generative capabilities with reinforcement learning and we're kind of seeing we saw slices of each of these",
    "start": "2299720",
    "end": "2306880"
  },
  {
    "text": "fields over the last few years developing and we've been talking about this Fusion of the fields and so how",
    "start": "2306880",
    "end": "2313280"
  },
  {
    "text": "soon before we start seeing uh entertainment you know that that is that is being heavily heavily based on these",
    "start": "2313280",
    "end": "2321400"
  },
  {
    "text": "Technologies I'm seeing it in my little tiny nonprofit because we can suddenly",
    "start": "2321400",
    "end": "2327319"
  },
  {
    "text": "leverage this to put out content to help folks in a charitable fashion that we",
    "start": "2327319",
    "end": "2333839"
  },
  {
    "text": "can do at least 10 times as much as we would have been able to before by taking advantage of these and so I think we're",
    "start": "2333839",
    "end": "2340440"
  },
  {
    "text": "at that inflection point now where this will be the first and as we have a continuing episodes through the course",
    "start": "2340440",
    "end": "2346599"
  },
  {
    "text": "of this year and some new things come out whether it's from open II or or similar things from other organizations",
    "start": "2346599",
    "end": "2353240"
  },
  {
    "text": "I think we're getting to that point where it's really hitting broadly in real life so I'm really fascinated I",
    "start": "2353240",
    "end": "2359520"
  },
  {
    "text": "would love to hear from our listeners on ways that they're using this technology",
    "start": "2359520",
    "end": "2364880"
  },
  {
    "text": "what they think might come next and how they are envisioning using it within their own organizational missions to",
    "start": "2364880",
    "end": "2371480"
  },
  {
    "text": "accomplish what they want it's a fascinating moment in history of AI that we're in right the second and one one",
    "start": "2371480",
    "end": "2377599"
  },
  {
    "text": "thing which I can't claim as my own Insight that I stole from Twitter but I",
    "start": "2377599",
    "end": "2383560"
  },
  {
    "text": "think has really shifted my thinking a little bit on this subject is so this is",
    "start": "2383560",
    "end": "2388760"
  },
  {
    "text": "actually a tweet from Chris Albin who uh is the director of machine learning at",
    "start": "2388760",
    "end": "2394800"
  },
  {
    "text": "Wikipedia and the the statement he made which I think was was really insightful and maybe other people are having",
    "start": "2394800",
    "end": "2401040"
  },
  {
    "text": "similar observations but he said sci-fi got it wrong we assumed AI would be",
    "start": "2401040",
    "end": "2407560"
  },
  {
    "text": "super logical and humans would provide creativity but in reality it's the",
    "start": "2407560",
    "end": "2413400"
  },
  {
    "text": "opposite generative AI is good at getting an approximately correct output",
    "start": "2413400",
    "end": "2418960"
  },
  {
    "text": "but if you need precision and accuracy you need a human uh end quote so I think",
    "start": "2418960",
    "end": "2424079"
  },
  {
    "text": "the observation here is like and we've talked about this on the show with language models also language models are",
    "start": "2424079",
    "end": "2431040"
  },
  {
    "text": "really good at actually at naturalness creativity apparent coherence right like",
    "start": "2431040",
    "end": "2436760"
  },
  {
    "text": "that actually is what they're good at but they get the facts and the Precision",
    "start": "2436760",
    "end": "2441920"
  },
  {
    "text": "and the accuracy wrong many times right so whereas I think in the past people",
    "start": "2441920",
    "end": "2447800"
  },
  {
    "text": "have thought the unique thing about what humans can provide in an AI driven",
    "start": "2447800",
    "end": "2453880"
  },
  {
    "text": "system is creativity not logic and that sort of",
    "start": "2453880",
    "end": "2459040"
  },
  {
    "text": "thing actually the the opposite is really the case right like the AI bits",
    "start": "2459040",
    "end": "2464240"
  },
  {
    "text": "are really driving the creativity and the humans are enforcing the logic the",
    "start": "2464240",
    "end": "2470520"
  },
  {
    "text": "facts the accuracy and the Precision I that has really shifted like I think I've been realizing",
    "start": "2470520",
    "end": "2477599"
  },
  {
    "text": "that over time but that statement really put some words to I think what what I was thinking it's comforting in a way",
    "start": "2477599",
    "end": "2485200"
  },
  {
    "text": "and the reason I say that is we talk in times past about creativity coming from",
    "start": "2485200",
    "end": "2490440"
  },
  {
    "text": "the humans rather than the machines and yet the evidence that we've been looking at over these last couple of years has",
    "start": "2490440",
    "end": "2496640"
  },
  {
    "text": "been not that and so I have actually been wondering what role is there for",
    "start": "2496640",
    "end": "2501920"
  },
  {
    "text": "the humans in that equation so the fact that it's flip-flop back it's the inverse of what our expectation was it",
    "start": "2501920",
    "end": "2509400"
  },
  {
    "text": "still means there's room for a human uh in the picture and that's a little bit of a comforting moment it may not be",
    "start": "2509400",
    "end": "2515160"
  },
  {
    "text": "what we thought it would be but there's still a place and uh and I think that's probably a good high note to leave",
    "start": "2515160",
    "end": "2521040"
  },
  {
    "text": "people with on the note of things being useful to humans and humans getting",
    "start": "2521040",
    "end": "2527160"
  },
  {
    "text": "involved we did want to leave you with a few learning resources to explore things related to chat GPT of course play",
    "start": "2527160",
    "end": "2534319"
  },
  {
    "text": "around with chat GPT you can go on the website and interact with it we'll provide the link but also I would really",
    "start": "2534319",
    "end": "2541960"
  },
  {
    "text": "highly recommend that you look at this hugging face blog about reinforcement learning from Human feedback",
    "start": "2541960",
    "end": "2547680"
  },
  {
    "text": "there's actually a bunch of links in there as well to other things that you can kind of spin off and look at like",
    "start": "2547680",
    "end": "2552880"
  },
  {
    "text": "the PO algorithm and other things uh in there also there's a good reference I",
    "start": "2552880",
    "end": "2558680"
  },
  {
    "text": "always love looking back at J Al Mar's descriptions of how certain language models work uh he has one on GPT uh 3",
    "start": "2558680",
    "end": "2566839"
  },
  {
    "text": "and other GPT um actually a number on GPT different uh different uh from",
    "start": "2566839",
    "end": "2572800"
  },
  {
    "text": "different perspectives and then there's a interesting article on G gpt3 architecture on a napkin from a Blog",
    "start": "2572800",
    "end": "2581280"
  },
  {
    "text": "Dugas CH I found it quite interesting how they describe some of the things there I like that one as well yeah yeah",
    "start": "2581280",
    "end": "2588680"
  },
  {
    "text": "so go ahead and check those out those are great learning resources they're all free you can take a look at them and",
    "start": "2588680",
    "end": "2594280"
  },
  {
    "text": "learn in more detail some of the things that we only had uh you know 45 minutes",
    "start": "2594280",
    "end": "2600040"
  },
  {
    "text": "to talk about here on the podcast in our social media channels I'm encouraging our listeners to share with us some of",
    "start": "2600040",
    "end": "2607000"
  },
  {
    "text": "the the ways they're using the technology I'm really waiting to hear that uh and you know the the more unique",
    "start": "2607000",
    "end": "2612960"
  },
  {
    "text": "uh the better yeah sounds great let us know what you're creating with chat GPT it's been a fun one Chris good to chat",
    "start": "2612960",
    "end": "2619240"
  },
  {
    "text": "with you absolutely thank you very much for the uh incredibly Lucid explanation it certainly uh helps me understand and",
    "start": "2619240",
    "end": "2626720"
  },
  {
    "text": "appreciate it as always Daniel talk to you next week uhuh [Music]",
    "start": "2626720",
    "end": "2634079"
  },
  {
    "text": "byebye all right that is our show for this week",
    "start": "2636040",
    "end": "2641440"
  },
  {
    "text": "if you dig it don't forget to subscribe head to practical AI FM for all the ways",
    "start": "2641440",
    "end": "2647359"
  },
  {
    "text": "and if practical AI has benefited your life Pay It Forward by sharing the show with a friend or a colleague word of",
    "start": "2647359",
    "end": "2653440"
  },
  {
    "text": "mouth is the number one way people find shows like ours thanks again to fastly for fronting our static assets to fly.io",
    "start": "2653440",
    "end": "2660680"
  },
  {
    "text": "for back in our Dynamic requests to break master cylinder for the beats and to you for listening we appreciate you",
    "start": "2660680",
    "end": "2666720"
  },
  {
    "text": "that's all for now we'll talk to you again on the next [Music]",
    "start": "2666720",
    "end": "2682720"
  },
  {
    "text": "one",
    "start": "2682720",
    "end": "2685720"
  }
]
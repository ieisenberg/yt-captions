[
  {
    "text": "I love machine learning I made a career of it I don't bring these things up just to make data scientists feel bad I've been sort of studying different failures",
    "start": "40",
    "end": "7200"
  },
  {
    "text": "in machine learning and Ai and algorithmic systems and if you watch you know I see one or two every week now and",
    "start": "7200",
    "end": "14559"
  },
  {
    "text": "that's been going on for almost two years and so I study these things to learn about how these systems fail so",
    "start": "14559",
    "end": "22279"
  },
  {
    "text": "that we can help our clients and help other people not have the same failures but surely governments must be taking",
    "start": "22279",
    "end": "28920"
  },
  {
    "text": "notice of the same level of AI incidents B with for change log is",
    "start": "28920",
    "end": "35280"
  },
  {
    "text": "provided by fastly learn more at fastly.com we move fast and fix things",
    "start": "35280",
    "end": "40399"
  },
  {
    "text": "here at change law because of rbar check them out at rar.com and we're hosted on Leno Cloud servers head to lin.com",
    "start": "40399",
    "end": "49360"
  },
  {
    "text": "changelog lenoe is our Cloud Sero Choice grab the Nano plan for just $5 a month",
    "start": "50640",
    "end": "56480"
  },
  {
    "text": "just five bucks that gets you a gig of RAM a blazing fast 25 gig SSD and 1",
    "start": "56480",
    "end": "61519"
  },
  {
    "text": "terab of transfer let's be honest you can go a long ways on that five bucks when you do need to scale up their",
    "start": "61519",
    "end": "67520"
  },
  {
    "text": "prices are predictable so you can put your calculator down you won't need it we've been running change.com on Leno",
    "start": "67520",
    "end": "72680"
  },
  {
    "text": "for years and we've always impressed by the reward winning support team check them out at lin.com",
    "start": "72680",
    "end": "78799"
  },
  {
    "text": "changelog once again that's lin.com",
    "start": "78799",
    "end": "83520"
  },
  {
    "text": "[Music] changelog",
    "start": "85980",
    "end": "91920"
  },
  {
    "text": "welcome to practical AI a weekly podcast that makes artificial intelligence practical productive and accessible to",
    "start": "92560",
    "end": "99040"
  },
  {
    "text": "everyone this is where conversations around AI machine learning and data science happen join the community and",
    "start": "99040",
    "end": "105040"
  },
  {
    "text": "slack with us around various topics of the show at chain.com community and follow us on Twitter we at practical",
    "start": "105040",
    "end": "113240"
  },
  {
    "text": "[Music] aifm welcome to another episode of",
    "start": "113300",
    "end": "120920"
  },
  {
    "text": "practical AI this is Daniel whack I am a data scientist with s International and",
    "start": "120920",
    "end": "127680"
  },
  {
    "text": "I'm joined as always by my co-host Chris Benson who is a principal emerging technology strategist at loed Martin how",
    "start": "127680",
    "end": "135640"
  },
  {
    "text": "you doing Chris I am doing fine how are you today Daniel doing well um as we're recording this it was uh in in the US",
    "start": "135640",
    "end": "143280"
  },
  {
    "text": "the day after a long holiday weekend uh Labor Day did you get to spend some time",
    "start": "143280",
    "end": "148800"
  },
  {
    "text": "with your family and uh and relax a little bit Chris we did we had good family times vegan hot dogs and such as",
    "start": "148800",
    "end": "155160"
  },
  {
    "text": "that excellent stuff yeah yeah yeah I we have a specific brand of uh of Veggie",
    "start": "155160",
    "end": "160519"
  },
  {
    "text": "dog we like afterwards we'll have to sidebar and uh and discuss that yeah my",
    "start": "160519",
    "end": "165959"
  },
  {
    "text": "wife's come up with a special recipe in Stu so can share that yeah it's good okay definitely yeah and I I spent some",
    "start": "165959",
    "end": "172720"
  },
  {
    "text": "of the weekend talking to my brother-in-law um if you've been listening uh some listeners might know that my brother-in-law lives with us and",
    "start": "172720",
    "end": "179680"
  },
  {
    "text": "uh we were talking about the new Nvidia cards that were uh announced and he's",
    "start": "179680",
    "end": "185519"
  },
  {
    "text": "already specked out a machine of course he's building a gaming machine but um we were talking about like the price points",
    "start": "185519",
    "end": "191560"
  },
  {
    "text": "and everything and he was saying you know for how much lower of a price you could get so you know the level of the",
    "start": "191560",
    "end": "198480"
  },
  {
    "text": "previous generation which was way more expensive and uh you know I was looking a little bit at the 3090 and what",
    "start": "198480",
    "end": "205360"
  },
  {
    "text": "they're doing and everything it's pretty exciting stuff I have to say are you following that at all Chris I am absolutely is you're talking there I got",
    "start": "205360",
    "end": "211760"
  },
  {
    "text": "to ask so is your machine the one you built all working and happy and everything yeah it's it's all working um",
    "start": "211760",
    "end": "217840"
  },
  {
    "text": "I did a few different um models on there trained those for a a project we're",
    "start": "217840",
    "end": "223280"
  },
  {
    "text": "doing at s and that worked really well it's it's uh no problems yet it I kind",
    "start": "223280",
    "end": "228519"
  },
  {
    "text": "of kept um you know there's not much installed on it I basically have Docker installed and that's how I'm running all",
    "start": "228519",
    "end": "234480"
  },
  {
    "text": "of everything so just using like the published tensorflow images and Nvidia",
    "start": "234480",
    "end": "240680"
  },
  {
    "text": "images and then you know training from there so it's worked out pretty good so far at some point you need to share your",
    "start": "240680",
    "end": "246599"
  },
  {
    "text": "specs and stuff yeah I will I shared them in our slack channel so listeners know we have a community slack Channel",
    "start": "246599",
    "end": "253040"
  },
  {
    "text": "and uh that's um you can find that at changel log.com community and um and we",
    "start": "253040",
    "end": "258359"
  },
  {
    "text": "discussed it a little bit there but I'm definitely going to have to do a legitimate um you know blog post I just haven't haven't done it yet shame on me",
    "start": "258359",
    "end": "265680"
  },
  {
    "text": "but uh sounds good waiting for it yeah definitely I'm pretty excited if you remember Chris uh way back in the day",
    "start": "265680",
    "end": "273520"
  },
  {
    "text": "actually episode 4 we had uh Andrew Bert on talking about uh at that point we",
    "start": "273520",
    "end": "279840"
  },
  {
    "text": "were talking about I think gdpr and Regulation and some other things as they relate to AI um and we're really excited",
    "start": "279840",
    "end": "286520"
  },
  {
    "text": "to have Andrew Bert and also Patrick Hall with us today they're both from B&H",
    "start": "286520",
    "end": "292160"
  },
  {
    "text": "doai Andrew is a managing partner there Patrick is a principal scientist and um",
    "start": "292160",
    "end": "297919"
  },
  {
    "text": "this is a pretty interesting new uh Law Firm focused on AI and analytics and",
    "start": "297919",
    "end": "303280"
  },
  {
    "text": "other things which is pretty cool we'll we'll talk about that a bit but um maybe first uh let's just get some",
    "start": "303280",
    "end": "309240"
  },
  {
    "text": "introductions Andrew do you want to start us out and tell us a little bit about your background remind us about your background and how you ended up",
    "start": "309240",
    "end": "315960"
  },
  {
    "text": "where you're at now yeah happily and thanks both uh uh for for having me and and and us on and um yeah it's fun to be",
    "start": "315960",
    "end": "323400"
  },
  {
    "text": "back and see you know how much things have changed in the last couple years yeah yeah we're still going it's been",
    "start": "323400",
    "end": "329120"
  },
  {
    "text": "crazy yeah well uh despite all of the fame the fame and fortune right what to do how",
    "start": "329120",
    "end": "336240"
  },
  {
    "text": "how to find podcasting you know set up in your Mansion yeah I mean it's just really nice to see has got to your guys'",
    "start": "336240",
    "end": "341960"
  },
  {
    "text": "heads you know well anyway so so my background so I'm a lawyer and also a",
    "start": "341960",
    "end": "347560"
  },
  {
    "text": "technologist I spent many years kind of working at the intersection of Law and and risk and Technology um I spent a few",
    "start": "347560",
    "end": "354880"
  },
  {
    "text": "years for the FBI cyber division um since 2016 I've also been with am muta I",
    "start": "354880",
    "end": "359919"
  },
  {
    "text": "was on last time in my capacity is with the muta and basically through throughout all of this time I have been",
    "start": "359919",
    "end": "366080"
  },
  {
    "text": "really the only lawyer in a room full of data scientists and technologists and people wanting to do really cool stuff",
    "start": "366080",
    "end": "372160"
  },
  {
    "text": "with data often times sensitive data or data and regulated environments um and",
    "start": "372160",
    "end": "377240"
  },
  {
    "text": "it has brought me to this conclusion which I've seen over and over um which is that the biggest problems with AI and",
    "start": "377240",
    "end": "383440"
  },
  {
    "text": "machine learning in my view are no longer Technical and in fact a lot of it",
    "start": "383440",
    "end": "388520"
  },
  {
    "text": "to me seems like it's been productized the biggest challenges and I've seen this in practice like being the only",
    "start": "388520",
    "end": "394560"
  },
  {
    "text": "lawyer in these rooms is legal it's ethical it's policy related and so I've",
    "start": "394560",
    "end": "399720"
  },
  {
    "text": "started to see these really really really big challenges um stand in the way of really exciting technology",
    "start": "399720",
    "end": "405599"
  },
  {
    "text": "projects and so all of that kind of LED Patrick and and myself to start B&H doai",
    "start": "405599",
    "end": "412759"
  },
  {
    "text": "which is a boutique law firm uh based in Washington DC it's the only place in the country uh where lawyers and non-",
    "start": "412759",
    "end": "419199"
  },
  {
    "text": "lawyers can actually jointly run law firms um and so we can talk about like why that is and why that exemption",
    "start": "419199",
    "end": "425599"
  },
  {
    "text": "exists but really we're we're the first to do this with data science and our core thesis is that the only way to to",
    "start": "425599",
    "end": "431680"
  },
  {
    "text": "to do data science right the only way to really kind of get all the value and and and minimize all the risks is by really",
    "start": "431680",
    "end": "438199"
  },
  {
    "text": "comingling these these types of expertise the legal and the policy really really closely with the technical",
    "start": "438199",
    "end": "443800"
  },
  {
    "text": "and the data science so that's the 50,000 foot um nutshell and we're just about we launched right at the end of",
    "start": "443800",
    "end": "450160"
  },
  {
    "text": "March so we're just about 5 months into uh into our journey and it's been a lot of fun awesome yeah that's that's super",
    "start": "450160",
    "end": "456080"
  },
  {
    "text": "great we're also really excited uh Patrick thank you for joining as well it's great to great to meet you and get",
    "start": "456080",
    "end": "461800"
  },
  {
    "text": "the connection through Andrew um could you tell us a little bit about about your background and how you ended up",
    "start": "461800",
    "end": "467039"
  },
  {
    "text": "working uh together with with Andrew on this yeah of course I'm I'm happy to be",
    "start": "467039",
    "end": "472199"
  },
  {
    "text": "here and um my journey with with machine learning I don't you know started many",
    "start": "472199",
    "end": "478560"
  },
  {
    "text": "moons ago at SAS Institute in in North Carolina and I think that that was",
    "start": "478560",
    "end": "483599"
  },
  {
    "text": "really formative for me it seems like some data scientists don't even know about SAS anymore but it's a you know",
    "start": "483599",
    "end": "491360"
  },
  {
    "text": "roughly three billion doll company that's been making billions of dollars off analytics and machine learning and",
    "start": "491360",
    "end": "497400"
  },
  {
    "text": "AI for decades and um just just being a part of that organization which largely lives",
    "start": "497400",
    "end": "504240"
  },
  {
    "text": "sort of outside of the ml hype sphere but but makes more money than almost any other ml company and just this awareness",
    "start": "504240",
    "end": "511800"
  },
  {
    "text": "that there was a right way to do things that's decades old is was really formative for me and after that I joined",
    "start": "511800",
    "end": "517839"
  },
  {
    "text": "the sort of uh Topsy Turvy ml startup world with at H2O where I you know I",
    "start": "517839",
    "end": "525560"
  },
  {
    "text": "kind of LED their their efforts in in responsible machine learning for for three to four years and and we came up",
    "start": "525560",
    "end": "532160"
  },
  {
    "text": "with a a decent product and I think like Andrew you know I came to the same conclusion but but I saw like and said",
    "start": "532160",
    "end": "539839"
  },
  {
    "text": "you know not only does the technology exist to sort of make machine learning more transparent and more trustworthy uh",
    "start": "539839",
    "end": "547079"
  },
  {
    "text": "hopefully more fair but it's already being productized so so it's reaching a certain level of maturity and really",
    "start": "547079",
    "end": "553600"
  },
  {
    "text": "what I see you know like Andrew said I think the next round of challenges for machine learning are not going to be",
    "start": "553600",
    "end": "559480"
  },
  {
    "text": "technical they're going to be policy and and Regulation and and legal and and human interactions with AI and machine",
    "start": "559480",
    "end": "566240"
  },
  {
    "text": "learning and and that's why I I joined Andrew on this joury J cuz cuz I saw a lot of the same things he did and and it",
    "start": "566240",
    "end": "572560"
  },
  {
    "text": "was an easy pitch actually once he explained it to me so happy to be here on the podcast and happy to be here with",
    "start": "572560",
    "end": "577959"
  },
  {
    "text": "B&H a thank you very much for joining us and uh it's nice to meet you Andrew",
    "start": "577959",
    "end": "583680"
  },
  {
    "text": "having Andrew back is like having an old friend back uh from her very beginning as you mentioned so you know Andrew you",
    "start": "583680",
    "end": "589440"
  },
  {
    "text": "touched on it already a little bit in your intro and Patrick you did as well but can you T you know you're at this",
    "start": "589440",
    "end": "596240"
  },
  {
    "text": "really unique position of of you have the entire landscape of law with the entire landscape of AI at this jux toos",
    "start": "596240",
    "end": "604680"
  },
  {
    "text": "where they are starting to merge and you know last time uh you came you gave us the the general data protection",
    "start": "604680",
    "end": "612120"
  },
  {
    "text": "regulation Deep dive as part of that and we talked about the fact that there wasn't a whole lot in terms of of laws",
    "start": "612120",
    "end": "618720"
  },
  {
    "text": "and regulations out there and then you know on top of that since then we've",
    "start": "618720",
    "end": "623839"
  },
  {
    "text": "really gotten deep into AI ethics um I know like in my own case I was leading",
    "start": "623839",
    "end": "628920"
  },
  {
    "text": "AI ethics for Led Martin for a while I just stepped out of that position but but learned a lot so much has happened",
    "start": "628920",
    "end": "634920"
  },
  {
    "text": "since we had you on last in this space can you uh together guys can y'all kind",
    "start": "634920",
    "end": "640760"
  },
  {
    "text": "of describe what the space looks like and what some of the complexity it with the the Landscapes at large given so",
    "start": "640760",
    "end": "647480"
  },
  {
    "text": "many things touching ethics all of these together yeah happily I'll start and",
    "start": "647480",
    "end": "653279"
  },
  {
    "text": "then there's a danger of me going on too long so Patrick can jump in please do so um I think from my perspective I guess",
    "start": "653279",
    "end": "660279"
  },
  {
    "text": "from a very high level what I have seen is I think the prospect of AI machine learning and I'm really for now I'm just",
    "start": "660279",
    "end": "665959"
  },
  {
    "text": "using those two terms interchangeably we we can we can dive more into why we might want to use one term versus the",
    "start": "665959",
    "end": "672120"
  },
  {
    "text": "other I'm very happy with that um as Chris probably knows from previous of my discussions other people might not be so",
    "start": "672120",
    "end": "678800"
  },
  {
    "text": "much but uh okay yeah you're you're in a safe space okay all right cool that means a lot that means a lot to me um so",
    "start": "678800",
    "end": "685000"
  },
  {
    "text": "I think the prospect of what AI can do the value I think has only begun to increase over time and I think there's a",
    "start": "685000",
    "end": "691560"
  },
  {
    "text": "wide recognition both in industry and by governments and regulators and the way that I think about the value is that",
    "start": "691560",
    "end": "698240"
  },
  {
    "text": "what AI does really really well is it scales decision- making in volume and and and speed and so if you just think",
    "start": "698240",
    "end": "705839"
  },
  {
    "text": "about that so we have this tool I mean it's been around for a while but let's say in the last five years the value has",
    "start": "705839",
    "end": "711440"
  },
  {
    "text": "become more clear and it's become used more and more you have this thing that can make huge amounts of decisions at",
    "start": "711440",
    "end": "716600"
  },
  {
    "text": "really high speeds so the progression is almost natural so as that type of tool",
    "start": "716600",
    "end": "721639"
  },
  {
    "text": "starts to be used more and more in the real world there a huge amount of concerns that that are associated with",
    "start": "721639",
    "end": "726839"
  },
  {
    "text": "it you know the slightest bias in something like that ends up being magnified the slightest security bug can",
    "start": "726839",
    "end": "733920"
  },
  {
    "text": "be magnified what you have is I I think really the same things that make this technology so powerful which is it can",
    "start": "733920",
    "end": "739800"
  },
  {
    "text": "do so much in such little times so efficiently also mean that that really any of the risks end up being greatly",
    "start": "739800",
    "end": "746199"
  },
  {
    "text": "magnified so I think over the last few years there has been this recognition that you know if we don't get this right",
    "start": "746199",
    "end": "752720"
  },
  {
    "text": "if we we really don't refine what it means to manage all of these different liabilities we're going to be in a world",
    "start": "752720",
    "end": "758839"
  },
  {
    "text": "of trouble and so that's what I have seen there's a really wonderful um paper from algorithm watch called Paper Tigers",
    "start": "758839",
    "end": "766320"
  },
  {
    "text": "which I can't remember the number but it it actually studied something like 120",
    "start": "766320",
    "end": "771360"
  },
  {
    "text": "maybe more ethical AI Frameworks released in the last couple of years and the title is called Paper Tigers because",
    "start": "771360",
    "end": "778920"
  },
  {
    "text": "the Frameworks don't really have teeth and so I think it's a to me the rise of",
    "start": "778920",
    "end": "784600"
  },
  {
    "text": "like the corporate ethical AI framework I think is a really good sign that we have an issue like something is wrong on",
    "start": "784600",
    "end": "791519"
  },
  {
    "text": "the other hand studies like that from algorithm watch I think are also kind of indicative of the fact that we are",
    "start": "791519",
    "end": "797440"
  },
  {
    "text": "nowhere close to solving it and so anyway that that's what this landscape kind of looks like for my perspective",
    "start": "797440",
    "end": "804160"
  },
  {
    "text": "I'll jump in real quickly F first I want to Echo Andrew's last statement you know you know and because I think that that",
    "start": "804160",
    "end": "810560"
  },
  {
    "text": "some of as a technologist right when I say things I think like I think the technology exists to to help with some",
    "start": "810560",
    "end": "816680"
  },
  {
    "text": "of these problems I want to be very clear that you know technology alone will never solve these problems right technology is just one of of many",
    "start": "816680",
    "end": "823639"
  },
  {
    "text": "necessary pieces but to add on to what Andrew was saying you know and and I need to be also need to be very clear",
    "start": "823639",
    "end": "829959"
  },
  {
    "text": "like I I love machine learning I I've made a career of it I don't bring these things up just to make data scientists",
    "start": "829959",
    "end": "835120"
  },
  {
    "text": "feel bad I've been sort of studying different failures and machine learning and Ai and algorithmic systems and if",
    "start": "835120",
    "end": "842480"
  },
  {
    "text": "you watch you know I see one or two every week now and that's been going on for almost two years and so you know I I",
    "start": "842480",
    "end": "851240"
  },
  {
    "text": "study these things to learn about how these systems fail so that we can help our clients and help other people not",
    "start": "851240",
    "end": "858040"
  },
  {
    "text": "have the same failures but surely government must be taking notice of the",
    "start": "858040",
    "end": "863440"
  },
  {
    "text": "same level of AI incidents and so I think that's another reason why we see companies and governments so just this",
    "start": "863440",
    "end": "870720"
  },
  {
    "text": "year organizations like the Federal Trade Commission and finra the uh Financial IND industry regulatory",
    "start": "870720",
    "end": "878040"
  },
  {
    "text": "Authority have issued these sort of long treatises on on the use of AI that",
    "start": "878040",
    "end": "883199"
  },
  {
    "text": "Andrew and I think is sort of forecasting or telegraphing future regulation so so I think there's you",
    "start": "883199",
    "end": "889720"
  },
  {
    "text": "know Andrew sort of focused or brought up the idea that the corporations are waking up to this and I certainly agree with that and I think that governments",
    "start": "889720",
    "end": "896199"
  },
  {
    "text": "are also starting to notice the way that that AI fails react to that yeah I want to ask kind of a followup a little bit",
    "start": "896199",
    "end": "902639"
  },
  {
    "text": "to that and and that is you know when you talk about the failure of ethical Frameworks for AI they're very limited",
    "start": "902639",
    "end": "909240"
  },
  {
    "text": "you know they're they're aspirational they kind of talk about these ideas that you want to constrain your operations",
    "start": "909240",
    "end": "915839"
  },
  {
    "text": "with but as you pointed out I think the phrase used was they have no teeth and and I I certainly agree with that I",
    "start": "915839",
    "end": "921160"
  },
  {
    "text": "think one of the challenges that I'm expecting over the next couple years is",
    "start": "921160",
    "end": "926279"
  },
  {
    "text": "as organizations uh either create or adopt Frameworks to to utilize for that",
    "start": "926279",
    "end": "932639"
  },
  {
    "text": "the devil is going to be in the details the devil is in how do you integrate that in with your legal structure uh at",
    "start": "932639",
    "end": "938120"
  },
  {
    "text": "your at your organization how do you uh integrate that in with your operations and how you serve your customers um and",
    "start": "938120",
    "end": "944759"
  },
  {
    "text": "so there's a great deal of of work to do in terms of figuring out how you",
    "start": "944759",
    "end": "950440"
  },
  {
    "text": "customize that framework down to your organization specifics do you have any",
    "start": "950440",
    "end": "955600"
  },
  {
    "text": "kind of guidance on that at large I mean would do you agree that that is the case",
    "start": "955600",
    "end": "961040"
  },
  {
    "text": "and how would you advise organizations to think about it you know so I've adopted a framework what's next honestly",
    "start": "961040",
    "end": "968319"
  },
  {
    "text": "that's exactly why we exist we just see this huge gap between the people thinking about the laws and the policies",
    "start": "968319",
    "end": "974440"
  },
  {
    "text": "and then you know the data scientists and the engineers who actually have to go operationalize it what we've seen in",
    "start": "974440",
    "end": "980000"
  },
  {
    "text": "practice time and time again is these big Frameworks usually called ethical AI sometimes you know trustworthy or",
    "start": "980000",
    "end": "986160"
  },
  {
    "text": "responsible Ai and it makes everyone feel feel good and their aspirational it's great and then it gets to the you",
    "start": "986160",
    "end": "991560"
  },
  {
    "text": "know the folks in the trenches and the business units and they say this is great but I can't do this like there's a",
    "start": "991560",
    "end": "998160"
  },
  {
    "text": "Chasm that we need to cross it's hard yeah it's very hard and so that is why",
    "start": "998160",
    "end": "1003199"
  },
  {
    "text": "we exist I think one of our big things is that AI has been around for a while",
    "start": "1003199",
    "end": "1008399"
  },
  {
    "text": "um we don't need to start from scratch there are a host of regulatory actual",
    "start": "1008399",
    "end": "1013959"
  },
  {
    "text": "oversight documents and then also guidance documents that actually are are tried and tested some are five decades",
    "start": "1013959",
    "end": "1019639"
  },
  {
    "text": "old dealing with discrimination some are about 15 years old just dealing with model risk um so there are actually lots",
    "start": "1019639",
    "end": "1026079"
  },
  {
    "text": "of places that we can start with um and as a law firm that's what we start with how have Regulators especially in",
    "start": "1026079",
    "end": "1032079"
  },
  {
    "text": "finance and anti-discrimination like what have they done what does the case law say and it turns out like there is a",
    "start": "1032079",
    "end": "1038640"
  },
  {
    "text": "lot that we can work with so that Gap that Chasm what it looks like is is this huge gap is actually not that deep and",
    "start": "1038640",
    "end": "1044880"
  },
  {
    "text": "it's not that wide I don't want to minimize how hard this can be but there are number of practical things that that",
    "start": "1044880",
    "end": "1050600"
  },
  {
    "text": "organizations like have been doing and can do for whatever reason I think largely because the lawyers and and the",
    "start": "1050600",
    "end": "1057160"
  },
  {
    "text": "technical folks just don't talk enough to each other I think a lot of these methods are are are",
    "start": "1057160",
    "end": "1064000"
  },
  {
    "text": "[Music]",
    "start": "1069650",
    "end": "1077840"
  },
  {
    "text": "underappreciated hi I'm Matt and I'd love to tell you about pce dodev past dodev is a",
    "start": "1077840",
    "end": "1085520"
  },
  {
    "text": "minimalist task management and async by default communication tool our screen recording feature is actually very",
    "start": "1085520",
    "end": "1091559"
  },
  {
    "text": "popular wherever you can leave a comment just like how easy it is to upload a file you can record your window or the",
    "start": "1091559",
    "end": "1098360"
  },
  {
    "text": "entire screen and upload it as a video to the team sometimes a screen recording",
    "start": "1098360",
    "end": "1104000"
  },
  {
    "text": "is the perfect way to explain something you know whether it's a bug that only happens for you or maybe more",
    "start": "1104000",
    "end": "1110559"
  },
  {
    "text": "optimistically a new feature that you can't wait to show off and the Showcase feature takes that a step further and",
    "start": "1110559",
    "end": "1116480"
  },
  {
    "text": "lets you highlight progress which is a much more positive experience than trying to make up estimations out of",
    "start": "1116480",
    "end": "1121960"
  },
  {
    "text": "thin air so please learn more and start your free trial at past.",
    "start": "1121960",
    "end": "1128279"
  },
  {
    "text": "[Music] deev",
    "start": "1135970",
    "end": "1140720"
  },
  {
    "text": "I'm really interested I know that you came out with some things recently around like a an AI incident response",
    "start": "1142640",
    "end": "1150039"
  },
  {
    "text": "checklist which I'm I'm super interested to dive into the details a little bit but before we do that I'm just kind of",
    "start": "1150039",
    "end": "1155960"
  },
  {
    "text": "curious to kind of talk generally about AI incidents um so um where my mind is",
    "start": "1155960",
    "end": "1162919"
  },
  {
    "text": "going with this is there like we have some experience with software incidents right and there's certainly software",
    "start": "1162919",
    "end": "1168360"
  },
  {
    "text": "that drives things that you know can make a huge impact on on people like you",
    "start": "1168360",
    "end": "1173799"
  },
  {
    "text": "know software in a medical setting or in a medical device or something that's not AI but if it malfunctions you know",
    "start": "1173799",
    "end": "1181520"
  },
  {
    "text": "someone's Health could be at risk or um you know you could expose uh private",
    "start": "1181520",
    "end": "1186640"
  },
  {
    "text": "information or or something like that right and there's there's those things that definitely do exist out there what",
    "start": "1186640",
    "end": "1193559"
  },
  {
    "text": "are the sort of liabilities about AI applications in particular particular",
    "start": "1193559",
    "end": "1199320"
  },
  {
    "text": "that might differentiate them from some of these things that maybe we've been dealing with for some time uh Patrick",
    "start": "1199320",
    "end": "1205960"
  },
  {
    "text": "you have any opinion on that yeah yeah and and you know I'm I'm not a lawyer so I'm gonna yeah have to let Andrew",
    "start": "1205960",
    "end": "1212760"
  },
  {
    "text": "comment on on the legal liability side but but I can say you know we see let's",
    "start": "1212760",
    "end": "1218840"
  },
  {
    "text": "say in in the tech media and and sort of broader media we we see a big focus on discrimination and of course um you know",
    "start": "1218840",
    "end": "1227640"
  },
  {
    "text": "discriminatory algorithms AI is is not something that that we want out there in",
    "start": "1227640",
    "end": "1233400"
  },
  {
    "text": "the world at all but we we also try to to sort of direct people to to other",
    "start": "1233400",
    "end": "1239080"
  },
  {
    "text": "problems like privacy you know you mentioned data security you mentioned and and so you know when I when I look",
    "start": "1239080",
    "end": "1246000"
  },
  {
    "text": "at some of these AI incidents I've been tracking I'd say they they mostly break down into maybe four categories so",
    "start": "1246000",
    "end": "1254440"
  },
  {
    "text": "discrimination probably being the biggest one and and we've seen some very troubling things there but also you know",
    "start": "1254440",
    "end": "1261200"
  },
  {
    "text": "consumer privacy data privacy security people essentially being kind of sloppy",
    "start": "1261200",
    "end": "1266480"
  },
  {
    "text": "with sensitive data that's used to train AI systems or data that's generated by AI systems and then a final one that I",
    "start": "1266480",
    "end": "1272840"
  },
  {
    "text": "see fairly often to is this idea of no intervenability in a machine learning",
    "start": "1272840",
    "end": "1279080"
  },
  {
    "text": "system or or sometimes it's called computer says no where the main failure of the algorithm was just that it's a",
    "start": "1279080",
    "end": "1285559"
  },
  {
    "text": "black box right it it's making decisions that impact people's lives that that may or may not be correct but the consumer",
    "start": "1285559",
    "end": "1292000"
  },
  {
    "text": "of the decision has absolutely no ability to appeal the decision and I think that's a huge mistake and another",
    "start": "1292000",
    "end": "1297640"
  },
  {
    "text": "type of of AI incident that I see fairly often so I'll leave it at those four sort of categories that I observe and",
    "start": "1297640",
    "end": "1303200"
  },
  {
    "text": "maybe let Andrew sort of chime in on the legal liabilities is that okay okay yeah that's good I'm I'm curious on that last",
    "start": "1303200",
    "end": "1309200"
  },
  {
    "text": "one actually because it's an interesting category and of course we've talked about the sort of um interpretability",
    "start": "1309200",
    "end": "1316600"
  },
  {
    "text": "issues and other things on the podcast before in that last category in terms of",
    "start": "1316600",
    "end": "1321679"
  },
  {
    "text": "the incident itself is is the problem mostly more weighted on the side of like",
    "start": "1321679",
    "end": "1327039"
  },
  {
    "text": "interpretability and not not kind of digging into the model or is it more on the like the computer has made the",
    "start": "1327039",
    "end": "1332600"
  },
  {
    "text": "decision and there's no way to sort of back out that decision like it just happens and like you know like a person",
    "start": "1332600",
    "end": "1339480"
  },
  {
    "text": "is denied Insurance because they're deemed high- risk and there's no way for them to like you know uh like you say",
    "start": "1339480",
    "end": "1346039"
  },
  {
    "text": "appeal that or or something which side of those those is it more weighted on I I think what I see in practice is it",
    "start": "1346039",
    "end": "1352159"
  },
  {
    "text": "ends up being the ladder right right and this goes back to the comment of Technology can't really solve these",
    "start": "1352159",
    "end": "1357440"
  },
  {
    "text": "problems so the sort of two biggest incidents in my mind when I hear computer says no or no intervenability",
    "start": "1357440",
    "end": "1363760"
  },
  {
    "text": "no appeal or overy capabilities is compass which is a a risk assessment",
    "start": "1363760",
    "end": "1369720"
  },
  {
    "text": "instrument that's used to help in pre-trial and and parole decisions and",
    "start": "1369720",
    "end": "1375240"
  },
  {
    "text": "then uh the recent a levels scandal in in the UK where hundreds of thousands of students had their grades adjusted by an",
    "start": "1375240",
    "end": "1381880"
  },
  {
    "text": "algorithm and in both these cases it seems that the algorithm itself was was at least well tested and well understood",
    "start": "1381880",
    "end": "1388679"
  },
  {
    "text": "by its operators but the way it was presented to its consumers was as this",
    "start": "1388679",
    "end": "1393799"
  },
  {
    "text": "sort of unappealable voice of God that's going to ruin your life and and so I I spent three years deep deep deep in in",
    "start": "1393799",
    "end": "1401640"
  },
  {
    "text": "explainable machine learning and interpretable models I sadly don't think that that's the problem here I think",
    "start": "1401640",
    "end": "1406679"
  },
  {
    "text": "that of course that can be a problem that the algorithm isn't interpretable and and that's something that I object",
    "start": "1406679",
    "end": "1412600"
  },
  {
    "text": "to in in almost all cases but the big incidents that are coming to my mind are more are more processed problems or more",
    "start": "1412600",
    "end": "1419000"
  },
  {
    "text": "human problems I would also just just to add to that I think there's certainly this like kind of the problem where",
    "start": "1419000",
    "end": "1425760"
  },
  {
    "text": "there's an algorithm that's deployed you know in a public setting where there really is this like it's it's",
    "start": "1425760",
    "end": "1432080"
  },
  {
    "text": "just there's almost like this tension between the authority of the algorithm and then everyone who you know who's",
    "start": "1432080",
    "end": "1437840"
  },
  {
    "text": "subject to it and that certainly there is a problem there but just to get more operational",
    "start": "1437840",
    "end": "1443440"
  },
  {
    "text": "in terms of day-to-day one of the things that we see in practice involved in in AI incident response is that that same",
    "start": "1443440",
    "end": "1450200"
  },
  {
    "text": "Dynamic can also happen between the developers of an algorithm or of a model",
    "start": "1450200",
    "end": "1455400"
  },
  {
    "text": "and the model itself once it's deployed and so if something wrong H so it's not",
    "start": "1455400",
    "end": "1460520"
  },
  {
    "text": "just consumer decision to model really good point really it's also if something bad is happening if there is an incident",
    "start": "1460520",
    "end": "1467520"
  },
  {
    "text": "if there is some instance of discrimination or potential hacking or data breach then we have this problem",
    "start": "1467520",
    "end": "1473799"
  },
  {
    "text": "where Patrick calls this debugging and I I think it might be worth giving Patrick a proverbial soap box and and let him",
    "start": "1473799",
    "end": "1480240"
  },
  {
    "text": "talk about debugging shortly but if there is a situation where we have potential liability and the data",
    "start": "1480240",
    "end": "1487600"
  },
  {
    "text": "scientists actually need to fix it we have the same type of of clash and what we've seen in practice is it can take an",
    "start": "1487600",
    "end": "1494120"
  },
  {
    "text": "extraordinar long period of time for the data scientist to one make the decision and the business units do we pull this",
    "start": "1494120",
    "end": "1500720"
  },
  {
    "text": "from production is the liability greater than the business value so should it be pulled from production what do we do how",
    "start": "1500720",
    "end": "1506840"
  },
  {
    "text": "do we debug it I think once um a model goes live so to speak there ends up",
    "start": "1506840",
    "end": "1512240"
  },
  {
    "text": "being this kind of a very similar Dynamic and so we see on a practical",
    "start": "1512240",
    "end": "1517840"
  },
  {
    "text": "basis in terms of thinking about risk and liability we see a huge number of organizations doing things that are much",
    "start": "1517840",
    "end": "1524799"
  },
  {
    "text": "smaller you know decisions of much smaller scales struggling with this when something goes wrong and just really",
    "start": "1524799",
    "end": "1530120"
  },
  {
    "text": "quickly building out that AI instant response plan just like you'd build out a response plan for other Mission",
    "start": "1530120",
    "end": "1536480"
  },
  {
    "text": "critical computer systems can help address a lot of those questions that Andrew is bringing up right A lot of",
    "start": "1536480",
    "end": "1541559"
  },
  {
    "text": "these questions that we see Team struggling with internally if you actually spend spend the time to",
    "start": "1541559",
    "end": "1546840"
  },
  {
    "text": "generate that checklist then you'll have better answers for this when the time comes yeah and you mentioned the",
    "start": "1546840",
    "end": "1553360"
  },
  {
    "text": "debugging thing which um I definitely I resonate with that a lot so I I don't want to lose that uh for sure I know",
    "start": "1553360",
    "end": "1560360"
  },
  {
    "text": "like a lot of times when I talk to teams I I do some advising and training and stuff and a lot of times I think people",
    "start": "1560360",
    "end": "1567080"
  },
  {
    "text": "have in their mind like oh we train this model like we kind of wrap it in our API",
    "start": "1567080",
    "end": "1572679"
  },
  {
    "text": "or whatever or embed it in our API and like it operates and like the unit tests",
    "start": "1572679",
    "end": "1578919"
  },
  {
    "text": "are like around like the API and like oh can I process this you know Json payload",
    "start": "1578919",
    "end": "1585200"
  },
  {
    "text": "right it's not around the model itself so a apparently that's something that you're passionate about as Andrew",
    "start": "1585200",
    "end": "1591120"
  },
  {
    "text": "alluded Patrick so Patrick do you want to say anything about that in terms of debugging and like yeah you know the",
    "start": "1591120",
    "end": "1596600"
  },
  {
    "text": "state of debugging especially around incidents when when something goes wrong with an AI model or something unexpected",
    "start": "1596600",
    "end": "1603399"
  },
  {
    "text": "happens yeah so if you guys will permit me when I'm done chatting I I'll put two",
    "start": "1603399",
    "end": "1608559"
  },
  {
    "text": "links in the zoom chat yeah yeah we'll include those in the show notes as well for the episode be great I hope they're",
    "start": "1608559",
    "end": "1615440"
  },
  {
    "text": "useful we've gotten some positive feedback on them so yeah I I think there's two levels of debugging right",
    "start": "1615440",
    "end": "1621799"
  },
  {
    "text": "two major categories of debugging and and you brought up one when you said unit test of the API great please God do",
    "start": "1621799",
    "end": "1628720"
  },
  {
    "text": "that I'd include that in sort of just sort of normal it system debugging right",
    "start": "1628720",
    "end": "1635159"
  },
  {
    "text": "unit testing yeah something that people have been doing for quite some time but and I can't explain this you know aside",
    "start": "1635159",
    "end": "1642039"
  },
  {
    "text": "from sort of a a sad level of of hype and exceptionalism in in data science",
    "start": "1642039",
    "end": "1647200"
  },
  {
    "text": "culture people in general in my experience are failing to apply General",
    "start": "1647200",
    "end": "1653440"
  },
  {
    "text": "software based best practices to their machine learning and I like I said I",
    "start": "1653440",
    "end": "1659640"
  },
  {
    "text": "can't explain this except for sort of sad and regrettable cultural phenomena",
    "start": "1659640",
    "end": "1664880"
  },
  {
    "text": "so that's one main issue I see Patrick I'll say I deal with that every day trying to get our our devops folks and",
    "start": "1664880",
    "end": "1671960"
  },
  {
    "text": "our developers working with ML makes no sense makes no sense to me so machine learning is essentially you know",
    "start": "1671960",
    "end": "1678919"
  },
  {
    "text": "given its complexity given its drift characteristics right it it's likely",
    "start": "1678919",
    "end": "1684559"
  },
  {
    "text": "even more volatile than than say some other Mission critical software assets and so why data scientists are giving a",
    "start": "1684559",
    "end": "1691760"
  },
  {
    "text": "pass on basic software quality I'll never understand okay and so that would be one thing to REM remedy just just",
    "start": "1691760",
    "end": "1698799"
  },
  {
    "text": "ASAP and of course we debug our other Mission critical software assets right",
    "start": "1698799",
    "end": "1704000"
  },
  {
    "text": "so so we should be debugging our machine Learning Systems just just using basic software best practices so so that's",
    "start": "1704000",
    "end": "1709799"
  },
  {
    "text": "part one of of model debugging and I I truly believe that there's no such thing as responsible AI or trustworthy AI",
    "start": "1709799",
    "end": "1717039"
  },
  {
    "text": "without basic software best practices then we get into actually testing the machine learning itself right and and",
    "start": "1717039",
    "end": "1723000"
  },
  {
    "text": "that's more difficult and and much more of sort of a new field and I've got some ideas around that I'm certainly not the",
    "start": "1723000",
    "end": "1729320"
  },
  {
    "text": "only one there was a conference workshop at icml must have been last year when we",
    "start": "1729320",
    "end": "1735919"
  },
  {
    "text": "could still fly maybe two years ago I'll put the link in the chat where where some of the world's leading academics got together and discussed this so I",
    "start": "1735919",
    "end": "1742880"
  },
  {
    "text": "would say that just in general debugging of the the machine Learning System itself comes down to at least from a",
    "start": "1742880",
    "end": "1749720"
  },
  {
    "text": "practical standpoint sort of sensitivity analysis right where is my system unstable residual analysis where where",
    "start": "1749720",
    "end": "1756760"
  },
  {
    "text": "is my system making errors and can I can I try to understand those and reduce those security audits right we're we're",
    "start": "1756760",
    "end": "1763760"
  },
  {
    "text": "well aware that that there are now attacks that directly uh affect machine Learning System so so doing red teaming",
    "start": "1763760",
    "end": "1770480"
  },
  {
    "text": "and Bug bounties and and security audits on those known security vulnerabilities of mL of course discrimination testing",
    "start": "1770480",
    "end": "1776840"
  },
  {
    "text": "and and discrimination remediation is a big one here yeah this is all super it's",
    "start": "1776840",
    "end": "1782720"
  },
  {
    "text": "it's resonating with me so much I know um Chris and I have talked and I have conversations every day with like you",
    "start": "1782720",
    "end": "1788640"
  },
  {
    "text": "know you're talking about probing the sensitivities and all that it's so it's so important um and it's actually like",
    "start": "1788640",
    "end": "1795320"
  },
  {
    "text": "in a lot of cases it doesn't require that much extra work and I think something that people don't realize as",
    "start": "1795320",
    "end": "1801120"
  },
  {
    "text": "well is to some degree um a major component of this is doing these sort of",
    "start": "1801120",
    "end": "1806240"
  },
  {
    "text": "tests actually allows you to be a better data scientist or or produce better work",
    "start": "1806240",
    "end": "1812200"
  },
  {
    "text": "right because you're actually you understand the behavior of your model more and you're finding those places",
    "start": "1812200",
    "end": "1817399"
  },
  {
    "text": "where it misbehaves and you're able to deal with those in a sort of confined test space where you actually the end",
    "start": "1817399",
    "end": "1825039"
  },
  {
    "text": "product becomes actually better your model is actually better in the and more robust thanks for allowing me time to",
    "start": "1825039",
    "end": "1831000"
  },
  {
    "text": "pause and Google my my sort of last Model debugging practical thing which is which is Benchmark models right like",
    "start": "1831000",
    "end": "1836679"
  },
  {
    "text": "having a simple trustworthy interpretable model to compare your more complex model against I think is is another super important thing there just",
    "start": "1836679",
    "end": "1843360"
  },
  {
    "text": "to Echo your comments sometimes it's a lot more work sometimes it's not a lot more work it will make your work better",
    "start": "1843360",
    "end": "1849799"
  },
  {
    "text": "but but seriously when we're talking about data scientists who are on average paid very very well even if it's a lot",
    "start": "1849799",
    "end": "1856120"
  },
  {
    "text": "of work you know with great power comes great responsibility and we just need to start taking more responsibility for the",
    "start": "1856120",
    "end": "1863080"
  },
  {
    "text": "systems that we're making so I actually want to swing things back over to uh Andrew for just a moment and Andrew I've",
    "start": "1863080",
    "end": "1870519"
  },
  {
    "text": "been sitting here as we've been talking pondering something that you said a few minutes ago you were talking about you",
    "start": "1870519",
    "end": "1876080"
  },
  {
    "text": "know case law and I guess that's opposed to statutory law things that I don't normally think about on a day-to-day",
    "start": "1876080",
    "end": "1882159"
  },
  {
    "text": "basis but I know you do can we just Define those terms too because I think there's probably a lot of people that",
    "start": "1882159",
    "end": "1887399"
  },
  {
    "text": "are like maybe confused a little bit and then I'll ask after that go ahead okay happily yes so so especially in the US",
    "start": "1887399",
    "end": "1893880"
  },
  {
    "text": "which is a a common law system the way that laws work and the places that laws come from vary and so there can be a",
    "start": "1893880",
    "end": "1900320"
  },
  {
    "text": "regulatory agency which will propagate rules you can think of like the FDA which has like you know they are in",
    "start": "1900320",
    "end": "1906480"
  },
  {
    "text": "charge of Food and Drug you can have congresses and state legislators which will say pass a law that is like doing X",
    "start": "1906480",
    "end": "1914120"
  },
  {
    "text": "is a crime so like don't do X or bad things will happen and then there's also case law and case law kind of evolves",
    "start": "1914120",
    "end": "1921120"
  },
  {
    "text": "over time from the courts and case law is basically arises on a decision by",
    "start": "1921120",
    "end": "1926159"
  },
  {
    "text": "decision basis so there'll be you know there'll be a case um someone you know there'll be controversy that that runs",
    "start": "1926159",
    "end": "1932960"
  },
  {
    "text": "some party in in in court um and then the decision that's made as as that",
    "start": "1932960",
    "end": "1938480"
  },
  {
    "text": "issue is being resolved um comes from just a larger body of case law and so one of the things I think I was thinking",
    "start": "1938480",
    "end": "1944799"
  },
  {
    "text": "about in in the world of anti-discrimination is we have all of these regulations both from Regulatory",
    "start": "1944799",
    "end": "1950559"
  },
  {
    "text": "Agencies and we have statutes from from Congress saying basically don't discriminate and don't discriminate in",
    "start": "1950559",
    "end": "1956120"
  },
  {
    "text": "these environments but it turns out it's really really difficult to figure out exactly what counts as discrimination in",
    "start": "1956120",
    "end": "1962840"
  },
  {
    "text": "a society that's really just like marked by profound inequities and so a lot of",
    "start": "1962840",
    "end": "1968480"
  },
  {
    "text": "the give and take and a lot of figuring out what exactly does this mean and how do you balance the usefulness of a model",
    "start": "1968480",
    "end": "1974799"
  },
  {
    "text": "with its potential discriminatory impact like that way comes from case law and it comes from courts and so we can look at",
    "start": "1974799",
    "end": "1981399"
  },
  {
    "text": "the guidance that comes from um government agencies as we try to figure out what the right way to approach these",
    "start": "1981399",
    "end": "1986880"
  },
  {
    "text": "issues are and then we can also look from like specific cases and say okay at this one specific time you know this",
    "start": "1986880",
    "end": "1993120"
  },
  {
    "text": "group ran into an issue and and here here is how the Judiciary uh solved it so hopefully that was a u we can get the",
    "start": "1993120",
    "end": "2000440"
  },
  {
    "text": "like Schoolhouse Rocks the bill we we we can feature that also in the show notes you're going to sing that at the end of",
    "start": "2000440",
    "end": "2005600"
  },
  {
    "text": "the show right yes exactly anytime I talk to anyone that's that's like I put on a pain in the top half perfect okay",
    "start": "2005600",
    "end": "2013799"
  },
  {
    "text": "you'll have to get pictures of that to to fit out anyway so you've already covered part of what I was going to ask and that is you know we've talked about",
    "start": "2013799",
    "end": "2021000"
  },
  {
    "text": "the fact that there's not a lot of AI specific statutory law you know and so",
    "start": "2021000",
    "end": "2027799"
  },
  {
    "text": "it sounds like you really start with regulation and case law and kind of connect that in with the kind of AI data",
    "start": "2027799",
    "end": "2035720"
  },
  {
    "text": "context is that a fair way and terms of how you would operate in the space so just like Patrick can't explain why data",
    "start": "2035720",
    "end": "2042639"
  },
  {
    "text": "scientists hold themselves to different like security standards than you know traditional software developers I can't",
    "start": "2042639",
    "end": "2048800"
  },
  {
    "text": "explain why there isn't more awareness of just the liabilities that existing laws place on AI so it's true there's no",
    "start": "2048800",
    "end": "2057358"
  },
  {
    "text": "National AI law there are very few laws that that say you know those creating",
    "start": "2057359",
    "end": "2062800"
  },
  {
    "text": "artificial intelligence shall not do this so it you're right that it's not that Direct",
    "start": "2062800",
    "end": "2068520"
  },
  {
    "text": "um but there are a huge number of ways that existing laws impact AI systems and",
    "start": "2068520",
    "end": "2073679"
  },
  {
    "text": "so one of the things that that I kind of feel like I say over and over again is",
    "start": "2073679",
    "end": "2079638"
  },
  {
    "text": "that the liabilities are not new and we've been dealing with a lot of these for a while so I I'm I'm happy to list",
    "start": "2079639",
    "end": "2085560"
  },
  {
    "text": "some but so there I think the three most obvious are security and privacy and",
    "start": "2085560",
    "end": "2090800"
  },
  {
    "text": "discrimination if an AI model uh discriminates serious liability can ensue if there are privacy uh violations",
    "start": "2090800",
    "end": "2099200"
  },
  {
    "text": "so basically those can happen all sorts of ways but just as simple as using data for the wrong reason when it was",
    "start": "2099200",
    "end": "2105359"
  },
  {
    "text": "collected for one reason but then used to to train a model for another that's a privacy violation um security violations",
    "start": "2105359",
    "end": "2112760"
  },
  {
    "text": "I think it's it's fairly intuitive how you can I think at a high level the attack service for AI is just very much",
    "start": "2112760",
    "end": "2120599"
  },
  {
    "text": "different than traditional software so an adversary might be able to manipulate the model or steal data or gain access",
    "start": "2120599",
    "end": "2127160"
  },
  {
    "text": "so those are kind of the intuitive things and there are laws governing all of that at the same time there are",
    "start": "2127160",
    "end": "2133040"
  },
  {
    "text": "things as basic as negligent standards so if you create an AI model and it goes",
    "start": "2133040",
    "end": "2139040"
  },
  {
    "text": "and someone is harmed e either physically or emotionally or something breaks we have all sorts of negligence",
    "start": "2139040",
    "end": "2144839"
  },
  {
    "text": "and product liability laws and um just because they don't say AI doesn't mean",
    "start": "2144839",
    "end": "2151319"
  },
  {
    "text": "that they're any less applicable so um there are a whole host I should say new laws are clearly coming like Patrick",
    "start": "2151319",
    "end": "2157800"
  },
  {
    "text": "said the FTC in particular the commissioner gave a speech I actually have it somewhere on my desk I can pull",
    "start": "2157800",
    "end": "2164079"
  },
  {
    "text": "it up but she gave a speech in January and the FTC has been doing every couple months something similar and she",
    "start": "2164079",
    "end": "2169640"
  },
  {
    "text": "basically said we're coming for ai ai is responsible for huge and growing amount of harms and the FTC is going to",
    "start": "2169640",
    "end": "2176839"
  },
  {
    "text": "regulate it even more so new laws are definitely coming and I think that that is not kind of controversial to say but",
    "start": "2176839",
    "end": "2183920"
  },
  {
    "text": "the laws on the books right now already do impact um AI quite quite",
    "start": "2183920",
    "end": "2189079"
  },
  {
    "text": "significantly and I think I can add that some of the work in in just the very",
    "start": "2189079",
    "end": "2194440"
  },
  {
    "text": "first months of our Law Firm has been AI violating sort of local laws right not",
    "start": "2194440",
    "end": "2201680"
  },
  {
    "text": "these big Federal AOA or or ficra Equal Credit Opportunity Act or Fair Credit",
    "start": "2201680",
    "end": "2207680"
  },
  {
    "text": "Reporting Act but concerns about AI violating more local laws that I never",
    "start": "2207680",
    "end": "2212880"
  },
  {
    "text": "would have thought of Andrew probably thought about it but I never would have thought about it",
    "start": "2212880",
    "end": "2219519"
  },
  {
    "text": "[Music]",
    "start": "2219810",
    "end": "2230860"
  },
  {
    "text": "change log Plus+ is the best way for you to directly support practical AI join",
    "start": "2231720",
    "end": "2238000"
  },
  {
    "text": "today and unlock access to a private feed that makes the ads disappear gets you closer to the metal and help sustain",
    "start": "2238000",
    "end": "2245240"
  },
  {
    "text": "our production of practical AI into into the future simply follow the Chang log",
    "start": "2245240",
    "end": "2250720"
  },
  {
    "text": "Plus+ Link in your show notes or Point your favorite web browser to Chang log.com plusus plus once again that's",
    "start": "2250720",
    "end": "2258680"
  },
  {
    "text": "changel log.com slpl plus changelog Plus+ it's",
    "start": "2258680",
    "end": "2266800"
  },
  {
    "text": "[Applause] [Music]",
    "start": "2268960",
    "end": "2273760"
  },
  {
    "text": "better we've got into a little bit of of the sorts of liabilities and incidents",
    "start": "2274839",
    "end": "2280880"
  },
  {
    "text": "that can happen and I'd love to kind of switch gears a little bit and talk about",
    "start": "2280880",
    "end": "2285960"
  },
  {
    "text": "this incident response uh checklist that that you've developed I think is that's a pretty cool thing um and maybe we",
    "start": "2285960",
    "end": "2292560"
  },
  {
    "text": "could start out by just asking you know how this came about was this something that you envisioned even you know even",
    "start": "2292560",
    "end": "2298960"
  },
  {
    "text": "before starting the law firm or did it come out of your sort of initial conversations with clients or or how did",
    "start": "2298960",
    "end": "2304599"
  },
  {
    "text": "this develop as as something useful so I think this was not the first thing we had in",
    "start": "2304599",
    "end": "2309640"
  },
  {
    "text": "mind you know when we launched the law firm I think we assumed that we would be kind of involved in lot lots of",
    "start": "2309640",
    "end": "2316359"
  },
  {
    "text": "preventative work you know way before something bad happens and frankly coming out of the gate we started to see that",
    "start": "2316359",
    "end": "2323000"
  },
  {
    "text": "people were reaching out to us once something bad had occurred you know frequently it's not a good we don't",
    "start": "2323000",
    "end": "2329359"
  },
  {
    "text": "recommend it you know call lawyers um call risk folks before you're in trouble",
    "start": "2329359",
    "end": "2335280"
  },
  {
    "text": "when you start building a critical machine learning process produ that's when to call Legal oversight ethics",
    "start": "2335280",
    "end": "2340599"
  },
  {
    "text": "people end yeah so we very much want to help for us as an example we want to",
    "start": "2340599",
    "end": "2346319"
  },
  {
    "text": "help folks way before we're actually needed what we've learned is sadly that's not how things work in practice",
    "start": "2346319",
    "end": "2351920"
  },
  {
    "text": "and very frequently it takes something bad happening for you know data scientists and lawyers to say kind of oh",
    "start": "2351920",
    "end": "2358079"
  },
  {
    "text": "crap there you know we have a gap and so I used to work at the FBI cyber division",
    "start": "2358079",
    "end": "2363440"
  },
  {
    "text": "um I'm actually got certified as a traditional cyber incident response Handler and so I was very familiar with",
    "start": "2363440",
    "end": "2369960"
  },
  {
    "text": "the six stages of incident response and one of the the things Patrick and I did very early on is we went through the",
    "start": "2369960",
    "end": "2377200"
  },
  {
    "text": "traditional you know textbooks that I've been trained on the traditional inent response and we said we're going to look",
    "start": "2377200",
    "end": "2383480"
  },
  {
    "text": "at all of the the bad things we're being exposed to you know we're seeing clients struggle with and all of the other",
    "start": "2383480",
    "end": "2389240"
  },
  {
    "text": "liabilities that could happen with AI and we're just going to go through and see how does current incident response",
    "start": "2389240",
    "end": "2395280"
  },
  {
    "text": "practices measure up and and also in our experience you know the answer is they don't AI is shiny and new and different",
    "start": "2395280",
    "end": "2401720"
  },
  {
    "text": "and there's this hype cycle and as a result the incident responders just kind of it's just out of their purview and so",
    "start": "2401720",
    "end": "2408839"
  },
  {
    "text": "we went through and we realized that there could be a very severe AI incident",
    "start": "2408839",
    "end": "2414520"
  },
  {
    "text": "creating huge amounts of liabilities in fact one that we are involved in now is",
    "start": "2414520",
    "end": "2419599"
  },
  {
    "text": "for like a Fortune 100 the board is deeply involved the CEO's butt is on the",
    "start": "2419599",
    "end": "2424680"
  },
  {
    "text": "line and we went through the traditional Conant response and you could go through",
    "start": "2424680",
    "end": "2430079"
  },
  {
    "text": "that you know check mark by check mark and everything would be okay you wouldn't have even known anything was",
    "start": "2430079",
    "end": "2435119"
  },
  {
    "text": "wrong with with the AI in question and so that kind of I think woke us up to the fact that this is something",
    "start": "2435119",
    "end": "2441480"
  },
  {
    "text": "different this is something new and also there's really no guidance on how do you respond when there's an incident um and",
    "start": "2441480",
    "end": "2447839"
  },
  {
    "text": "so we we we put this together and we love model risk management practices that are mostly in in financial services",
    "start": "2447839",
    "end": "2455400"
  },
  {
    "text": "and highly related to this this uh guidance from the Federal Reserve called",
    "start": "2455400",
    "end": "2461720"
  },
  {
    "text": "sr17 which is A masterful Treatise on on model risk management neither did model",
    "start": "2461720",
    "end": "2468119"
  },
  {
    "text": "risk management as it exists today I'm sure it will mature to include this but model risk management as it exists today",
    "start": "2468119",
    "end": "2475440"
  },
  {
    "text": "also did not include you know exact ways to to react to AI incidents right so so",
    "start": "2475440",
    "end": "2481680"
  },
  {
    "text": "there was nothing in traditional cyber security response and there were things in model risk management that would help",
    "start": "2481680",
    "end": "2488240"
  },
  {
    "text": "but nothing that actually you know told you how to respond or to prepare to respond yeah I'm curious what we um as",
    "start": "2488240",
    "end": "2495319"
  },
  {
    "text": "you went through those things that are existing and best practices that had already been developed what are a couple",
    "start": "2495319",
    "end": "2501800"
  },
  {
    "text": "examples of where maybe uh you know existing incident response plans just",
    "start": "2501800",
    "end": "2508240"
  },
  {
    "text": "wouldn't cut it or would leave something out in terms of of AI and machine learning so there are many ways that",
    "start": "2508240",
    "end": "2514599"
  },
  {
    "text": "there can be AI incidents and I actually I'm getting a little concern that I think people are just only assuming that",
    "start": "2514599",
    "end": "2520079"
  },
  {
    "text": "the worst that AI can do is discriminate because there's so much in the news and frankly about 15 years ago there weren't",
    "start": "2520079",
    "end": "2527800"
  },
  {
    "text": "mandatory breach reporting guidelines so there there are legal requirements now that say if there's a breach or a hack",
    "start": "2527800",
    "end": "2533319"
  },
  {
    "text": "you need to report it so now we know all the bad stuff that's happening before those no one really did and we're in an",
    "start": "2533319",
    "end": "2540160"
  },
  {
    "text": "analogous situation with AI where all this bad stuff is happening but there's no incentive for anyone to share it so",
    "start": "2540160",
    "end": "2547760"
  },
  {
    "text": "the public is in the dark but anyway so at the risk of of doubling down on discrimination let's say you have an",
    "start": "2547760",
    "end": "2554200"
  },
  {
    "text": "apple Goldman situation which you know their their credit model was reportedly discriminating females there are many",
    "start": "2554200",
    "end": "2560680"
  },
  {
    "text": "different ways that AI can discriminate but let's just say you have something that's discriminating let's say it has",
    "start": "2560680",
    "end": "2566480"
  },
  {
    "text": "been deployed and exposed to you know I don't know many hundreds of thousands a million whatever consumers the question",
    "start": "2566480",
    "end": "2573440"
  },
  {
    "text": "is how do you know that that model is discriminating and how do you know the the depth of that discrimination and you",
    "start": "2573440",
    "end": "2580119"
  },
  {
    "text": "could go and and so that would be an incident let's say you have a model that's been deployed against a you know",
    "start": "2580119",
    "end": "2585839"
  },
  {
    "text": "a million people and let's say 20% of those decisions have been in some shape or form discriminatory that's bad",
    "start": "2585839",
    "end": "2592760"
  },
  {
    "text": "there's lots of liability it's a huge incident 200,000 people I mean in practice we're seeing that the numbers",
    "start": "2592760",
    "end": "2598599"
  },
  {
    "text": "are even higher but huge amounts of people could be impacted and a traditional incident response would say",
    "start": "2598599",
    "end": "2605559"
  },
  {
    "text": "okay well is the model available ailable um has its Integrity been broken has anyone bro breached its confidentiality",
    "start": "2605559",
    "end": "2612240"
  },
  {
    "text": "is the data being used in line with privacy policies like all the traditional questions just don't get at",
    "start": "2612240",
    "end": "2618520"
  },
  {
    "text": "this really really huge liability and so what can happen in practice is an organization will deploy a model like",
    "start": "2618520",
    "end": "2624839"
  },
  {
    "text": "this and then frequently like the media will discover that there's something wrong or there'll be like a Twitter",
    "start": "2624839",
    "end": "2631160"
  },
  {
    "text": "posting saying like what wait a minute you know um uh you know I'm a member of a disadvantage community and you know my",
    "start": "2631160",
    "end": "2637640"
  },
  {
    "text": "spouse is not and the model treated us differently and then suddenly the sky is",
    "start": "2637640",
    "end": "2642839"
  },
  {
    "text": "falling on these organizations so anyway so that model I think in itself is a signal that that something's broken I",
    "start": "2642839",
    "end": "2649200"
  },
  {
    "text": "can summarize my comments really quickly typical in computer instant",
    "start": "2649200",
    "end": "2656040"
  },
  {
    "text": "response doesn't address machine learning security yet in and what we saw",
    "start": "2656040",
    "end": "2662200"
  },
  {
    "text": "it it may soon in the future but it doesn't yet and then model risk management",
    "start": "2662200",
    "end": "2667640"
  },
  {
    "text": "typically not in all cases typically doesn't address security and privacy and in some cases discrimination issues like",
    "start": "2667640",
    "end": "2675119"
  },
  {
    "text": "Andrew mentioned and so there's just kind of a gap in the the two main",
    "start": "2675119",
    "end": "2680359"
  },
  {
    "text": "practices which are both great you know that we're not saying anything negative about these they're both great but they just have a little bit of a gap when it",
    "start": "2680359",
    "end": "2686680"
  },
  {
    "text": "comes to Ai and so you know I think that that's where the AI incident response",
    "start": "2686680",
    "end": "2692359"
  },
  {
    "text": "checklist comes in because we try to fill in those gaps so we've kind of talked about the check checklist itself",
    "start": "2692359",
    "end": "2698280"
  },
  {
    "text": "but one of the comments you made a little while ago was the time to connect with us is really before that happens so",
    "start": "2698280",
    "end": "2706480"
  },
  {
    "text": "if you're a company out there and you have you know limited resources limited budget and you're trying to",
    "start": "2706480",
    "end": "2714400"
  },
  {
    "text": "justify why they should engage you before an incident happens to try to you",
    "start": "2714400",
    "end": "2719960"
  },
  {
    "text": "know you know work through their operations ahead of time what are some good justifications what what are things",
    "start": "2719960",
    "end": "2725400"
  },
  {
    "text": "that you've seen where you're like if you come in ahead of time you're going to save money you're going to save",
    "start": "2725400",
    "end": "2731079"
  },
  {
    "text": "a lot of Heartache H how do you approach that I'll try on this one and and Andrew can kind of jump in and correct me so so",
    "start": "2731079",
    "end": "2739079"
  },
  {
    "text": "one you know all models are wrong some models are useful right your machine learning model is going to be wrong okay",
    "start": "2739079",
    "end": "2747280"
  },
  {
    "text": "uh and so when it's wrong something bad can happen right and and so the the",
    "start": "2747280",
    "end": "2753160"
  },
  {
    "text": "question is really how prepared are you for that bad thing to happen and what will the cost in terms of human value or",
    "start": "2753160",
    "end": "2760559"
  },
  {
    "text": "monetary value be when that bad thing happens so so we try to to sort of gauge",
    "start": "2760559",
    "end": "2766040"
  },
  {
    "text": "AI incidents by the organization's preparedness and by the materiality of",
    "start": "2766040",
    "end": "2772040"
  },
  {
    "text": "of the incident and so your machine learning model will be wrong right so you just have to get ready for that",
    "start": "2772040",
    "end": "2777240"
  },
  {
    "text": "that's where I'll leave it except to say that in our experience it's much cheaper and much easier to deal with it before",
    "start": "2777240",
    "end": "2783200"
  },
  {
    "text": "you're on the front page of the New York Times before you have letters from senators you know it's a very reasonable",
    "start": "2783200",
    "end": "2789319"
  },
  {
    "text": "expense and companies are probably already budgeting for in their traditional sort of software budgets",
    "start": "2789319",
    "end": "2794599"
  },
  {
    "text": "whereas it can explode on the other side of the incident as as Andrew likes to say on the right side of Boom the cost",
    "start": "2794599",
    "end": "2801040"
  },
  {
    "text": "can explode right because then you're talking about reputational problems potential regulatory problems potential",
    "start": "2801040",
    "end": "2807240"
  },
  {
    "text": "litigation problems so I'll let I'll let Andrew chiman and correct me if I'm wrong on the right side of boom yeah",
    "start": "2807240",
    "end": "2813720"
  },
  {
    "text": "yeah yeah so we have in the National Security world there's a left of boom right of boom boom is the bad thing and",
    "start": "2813720",
    "end": "2820079"
  },
  {
    "text": "left is before and and right is after and so I mean so your question I I think",
    "start": "2820079",
    "end": "2825200"
  },
  {
    "text": "is is one of the most frustrating parts of of of some of what we do and I think",
    "start": "2825200",
    "end": "2830720"
  },
  {
    "text": "in terms of of folks in information security and data protection RIT large which is um there's kind of this",
    "start": "2830720",
    "end": "2837640"
  },
  {
    "text": "intuition well if something bad hasn't happened already why should I be spending time and money on it um and I",
    "start": "2837640",
    "end": "2844839"
  },
  {
    "text": "think it's that is even worse in the world of of AI because AI is subject to so much hype and we still see people who",
    "start": "2844839",
    "end": "2851800"
  },
  {
    "text": "have this kind of belief well my AI could never be wrong my data scientists are so expensive they could never do and",
    "start": "2851800",
    "end": "2859240"
  },
  {
    "text": "honestly it's just it's a real problem so so what we typically say um in practice to our our clients who haven't",
    "start": "2859240",
    "end": "2866119"
  },
  {
    "text": "yet had a bad thing happen they are precious few is basically we say well",
    "start": "2866119",
    "end": "2871599"
  },
  {
    "text": "there there are two answers one is you need to like Patrick said you need to at least be prepared for the bad thing to",
    "start": "2871599",
    "end": "2878599"
  },
  {
    "text": "happen you need to know what the bad thing is so that when it happens it doesn't occur for a year until someone",
    "start": "2878599",
    "end": "2884319"
  },
  {
    "text": "tweets about it and then there's an investigation so you need to be able to know what it is you want to avoid how",
    "start": "2884319",
    "end": "2890160"
  },
  {
    "text": "are you going to be looking for it and measuring it and then what are you going to do when you measure it and so those",
    "start": "2890160",
    "end": "2895559"
  },
  {
    "text": "are kind of typically that's like the starter package you know that's like really kind of like the baby steps and",
    "start": "2895559",
    "end": "2903040"
  },
  {
    "text": "and anyone any organization deploying AI needs to have those things worked out",
    "start": "2903040",
    "end": "2909200"
  },
  {
    "text": "one it's the right thing to do and it's just like responsible but two it will save them from a world of hurt if and",
    "start": "2909200",
    "end": "2916240"
  },
  {
    "text": "when something goes wrong the second thing that that we say is that honestly",
    "start": "2916240",
    "end": "2921440"
  },
  {
    "text": "just in terms of the financial resources it just does not cost a lot of money to",
    "start": "2921440",
    "end": "2927400"
  },
  {
    "text": "to prepare and it costs a huge amount of money to respond and so one of the things that that we'll do is we'll say",
    "start": "2927400",
    "end": "2933720"
  },
  {
    "text": "you know you're investing in AI because you believe it's transformational because you believe it has so much value",
    "start": "2933720",
    "end": "2939160"
  },
  {
    "text": "and the liability is directly tied to the value you would not you know like the greater the value the higher the",
    "start": "2939160",
    "end": "2946200"
  },
  {
    "text": "chances that if something goes wrong it's going to be big and so you really can't separate the two so if you believe",
    "start": "2946200",
    "end": "2952319"
  },
  {
    "text": "that AI is worth investing in and you believe it's going to change your business it is just one I would say",
    "start": "2952319",
    "end": "2959040"
  },
  {
    "text": "irresponsible we don't tell that to clients we typically don't unless it's really bad but it's just really misadvised and ill-advised to be putting",
    "start": "2959040",
    "end": "2967720"
  },
  {
    "text": "making such a big bet on something and kind of doing that blind there's a quote that I I love that that I I keep",
    "start": "2967720",
    "end": "2974280"
  },
  {
    "text": "stealing from Patrick which is that even microwaves have troubleshooting manuals something as as small and as simple as a",
    "start": "2974280",
    "end": "2981400"
  },
  {
    "text": "microwave um and yet AI is deployed in practice all over without troubleshooting manuals without plans",
    "start": "2981400",
    "end": "2987599"
  },
  {
    "text": "for what happens when something goes wrong and so I think at minimum there's just kind of this basic level of",
    "start": "2987599",
    "end": "2993200"
  },
  {
    "text": "preparedness that organizations should be willing to invest in and then hopefully they never have to pour money",
    "start": "2993200",
    "end": "2999280"
  },
  {
    "text": "you know into a response but it's a real issue yeah and there's definitely like I",
    "start": "2999280",
    "end": "3004960"
  },
  {
    "text": "I can see like in this topic people could also argue well like I don't really know I can't anticipate all of",
    "start": "3004960",
    "end": "3011760"
  },
  {
    "text": "the bad things that could happen but at the same time there are some like simple things that like you can't anticipate",
    "start": "3011760",
    "end": "3017520"
  },
  {
    "text": "right like you can create adversarial examples pretty easily to like test the sensitivity and robustness of your model",
    "start": "3017520",
    "end": "3024359"
  },
  {
    "text": "also like I think it was Andrew you were talking about like when your model goes wrong and then like which users were",
    "start": "3024359",
    "end": "3030880"
  },
  {
    "text": "impacted by this like a lot of people just like throw their model up like model. PB on S3 and that's the name of",
    "start": "3030880",
    "end": "3039400"
  },
  {
    "text": "it and then when they update it they just like overwrite that file right and like of course that's going to create",
    "start": "3039400",
    "end": "3045799"
  },
  {
    "text": "all sorts of amazingly terrible issues when you have to figure out something like what you were talking about so even",
    "start": "3045799",
    "end": "3052920"
  },
  {
    "text": "just like a simple thing like hey could it be conce that I would need to know which model",
    "start": "3052920",
    "end": "3059400"
  },
  {
    "text": "operated on which data from users yeah that's probably fairly conceivable that's something I've seen like people",
    "start": "3059400",
    "end": "3065720"
  },
  {
    "text": "tend to make that excuse too I'd really like to jump in here and I'll I'll try not to be too negative you know having",
    "start": "3065720",
    "end": "3072119"
  },
  {
    "text": "having spent four years in Silicon Valley data scientists are paid a lot okay a lot more than like a general",
    "start": "3072119",
    "end": "3077880"
  },
  {
    "text": "practitioner physician and I'm starting to have sort of personal emotional problems with this",
    "start": "3077880",
    "end": "3084000"
  },
  {
    "text": "idea of of someone who makes2 200 300 Grand a year saying I can't think about",
    "start": "3084000",
    "end": "3089440"
  },
  {
    "text": "how the system is going to fail okay well one you know just take some time and Google about it and and see how",
    "start": "3089440",
    "end": "3096240"
  },
  {
    "text": "systems like yours have failed right and and just open the newspaper right there's there's there's evidence of",
    "start": "3096240",
    "end": "3102359"
  },
  {
    "text": "discriminatory machine learning all over the news right so again I I'll bring up this idea of of studying AI inance much",
    "start": "3102359",
    "end": "3109359"
  },
  {
    "text": "like people studied airplane crashes and continue to study airplane crashes right and so I use the analogy of nuclear",
    "start": "3109359",
    "end": "3115680"
  },
  {
    "text": "power plant or nuclear reactors and airplanes and and I know those aren't exactly right the barrier to entry is a",
    "start": "3115680",
    "end": "3121520"
  },
  {
    "text": "lot higher the impact of a failure is a lot more immediate but there's things to be learned there and and so you know we",
    "start": "3121520",
    "end": "3128280"
  },
  {
    "text": "studied the ways the airplanes crashed in an effort to make them safer and that was just part of the profession of",
    "start": "3128280",
    "end": "3135599"
  },
  {
    "text": "Aviation and I'm really personally becoming tired of of sort of why data scientist would not have a you know have",
    "start": "3135599",
    "end": "3142319"
  },
  {
    "text": "some kind of out for this like oh I get paid too much to do this like that doesn't make any sense sense so I guess",
    "start": "3142319",
    "end": "3148359"
  },
  {
    "text": "as we come to the conclusion today I was wondering if you could kind of tell us",
    "start": "3148359",
    "end": "3154640"
  },
  {
    "text": "as insiders at this jux deposition of Law and AI what you're expecting to see over the next few years you know clearly",
    "start": "3154640",
    "end": "3161240"
  },
  {
    "text": "this is a new field it's growing rapidly what are you seeing and what do you",
    "start": "3161240",
    "end": "3166480"
  },
  {
    "text": "expect to grow into uh as you move forward with your new firm yeah so I would say and and it's been interesting",
    "start": "3166480",
    "end": "3173599"
  },
  {
    "text": "because we also kind of coming out of the gate have in discussions with a whole host of regulators I think you",
    "start": "3173599",
    "end": "3181440"
  },
  {
    "text": "know there's a direct connection between the headlines about things happening when AI goes wrong and and those are",
    "start": "3181440",
    "end": "3187319"
  },
  {
    "text": "only a fraction of what's actually happening out there then kind of public concern about this and then regulatory",
    "start": "3187319",
    "end": "3193760"
  },
  {
    "text": "reaction and so Regulators are going to kind of up the ante so to speak um in",
    "start": "3193760",
    "end": "3199480"
  },
  {
    "text": "terms of what the liabilities are and so I really see two Futures and they're",
    "start": "3199480",
    "end": "3205720"
  },
  {
    "text": "both probably better than the one you know the present I think the one that I'm I'm gunning for and why Patrick and",
    "start": "3205720",
    "end": "3212119"
  },
  {
    "text": "I you know launched this the b.i this Boutique Law Firm is because I think there's an opportunity for data",
    "start": "3212119",
    "end": "3217920"
  },
  {
    "text": "scientists to work together with policy folks and legal folks and get this right",
    "start": "3217920",
    "end": "3223880"
  },
  {
    "text": "and kind of be proactive rather than reactive our aim is to help that happen so I think that's one future where",
    "start": "3223880",
    "end": "3231079"
  },
  {
    "text": "before there's any really major incident we kind of as this I'm going to say community but it's not really Community",
    "start": "3231079",
    "end": "3236960"
  },
  {
    "text": "it's not like a legal and but as you know as a group can start to build out best practices and even Dan what you",
    "start": "3236960",
    "end": "3243040"
  },
  {
    "text": "were saying about just like documentation and like not overriding models when they're updated or at least",
    "start": "3243040",
    "end": "3248599"
  },
  {
    "text": "you know like just some basic basic best practices I can see a future that is",
    "start": "3248599",
    "end": "3254079"
  },
  {
    "text": "frankly a lot less bumpy and where maybe like the hype of AI can actually be you know be met in practice um I also see",
    "start": "3254079",
    "end": "3261079"
  },
  {
    "text": "another future which is probably most likely and I think what kind of Patrick's like frustration is indicative",
    "start": "3261079",
    "end": "3267040"
  },
  {
    "text": "of is where Regulators just say this is not good enough and kind of slap down some much more stringent standards",
    "start": "3267040",
    "end": "3273440"
  },
  {
    "text": "that's where things appear to be heading although it's it's not inevitable but if I had to guess I would say kind of just",
    "start": "3273440",
    "end": "3279760"
  },
  {
    "text": "like we were with you know frankly I was going to say GDP but I think CCPA is a little bit more stringent CCPA is this",
    "start": "3279760",
    "end": "3286079"
  },
  {
    "text": "very overbearing privacy regulation that came through California that now basically affects almost any big",
    "start": "3286079",
    "end": "3292960"
  },
  {
    "text": "organization using data in the US I think the likelihood if we're not careful is that there is going to be the",
    "start": "3292960",
    "end": "3299400"
  },
  {
    "text": "same type of thing and then every single data scientist is going to have you know specific additional trainings and",
    "start": "3299400",
    "end": "3305839"
  },
  {
    "text": "they're going to have specific additional forms and they're going to have kind of lawyers breathing down their neck who might not necessarily",
    "start": "3305839",
    "end": "3312760"
  },
  {
    "text": "kind of fully understand all the nuances of their their day-to-day so I think no matter what the life of a data scientist",
    "start": "3312760",
    "end": "3318799"
  },
  {
    "text": "is going to change um risks are increasing it's going to be harder just to deploy models without illustrating",
    "start": "3318799",
    "end": "3325359"
  },
  {
    "text": "how those risks have been reduced produced and I think how that happens is really kind of up to us and I think",
    "start": "3325359",
    "end": "3330880"
  },
  {
    "text": "Smart Companies you know I'm obviously biased but I think smart companies and organizations I think will start to think about this stuff now so that",
    "start": "3330880",
    "end": "3338359"
  },
  {
    "text": "they're not surprised when all this happens for sure yeah sadly I think I'm I'm more aligned with Andrew's sort of",
    "start": "3338359",
    "end": "3344720"
  },
  {
    "text": "second scenario I think we're in for um a a bumpy road where Ai and ml",
    "start": "3344720",
    "end": "3351440"
  },
  {
    "text": "are on a collision course with the law over the next I don't know decade or two I think it's important to mentioned you",
    "start": "3351440",
    "end": "3356839"
  },
  {
    "text": "know in this topic that that we see government agencies internationally of course Singapore UK all over Europe",
    "start": "3356839",
    "end": "3363640"
  },
  {
    "text": "issuing very detailed AI guidance but we also in the US just this year and and",
    "start": "3363640",
    "end": "3369680"
  },
  {
    "text": "end of last year saw FTC cftc uh cfpb FDA and probably several more that I",
    "start": "3369680",
    "end": "3376799"
  },
  {
    "text": "can't remember off the top of my head sort of releasing draft guidance or other sort of steps towards regulation",
    "start": "3376799",
    "end": "3383280"
  },
  {
    "text": "so I do think sort of Regulation is imminent and sadly I expected to kind of",
    "start": "3383280",
    "end": "3389400"
  },
  {
    "text": "be a bumpy road but but I hope Andrew's first scenario is is what actually happens that's certainly that would be more pleasant scenario yeah hopefully",
    "start": "3389400",
    "end": "3396599"
  },
  {
    "text": "we've got a a good number of uh listeners on this episode who are interested in the practicalities of this",
    "start": "3396599",
    "end": "3403039"
  },
  {
    "text": "and I think this is super practical in the sense that you know hey uh this is a",
    "start": "3403039",
    "end": "3408119"
  },
  {
    "text": "a call to our listeners before we go down that second path let's take stock of what we're doing and Institute some",
    "start": "3408119",
    "end": "3413920"
  },
  {
    "text": "responsible practices in our own workflows you know there's simple things like like we're talking about that you",
    "start": "3413920",
    "end": "3419160"
  },
  {
    "text": "can do um I've taken down the the links that we've been chatting about you know super practical things that we'll Link",
    "start": "3419160",
    "end": "3425799"
  },
  {
    "text": "in the show notes um specifically there's a great page that that b. has",
    "start": "3425799",
    "end": "3430839"
  },
  {
    "text": "put together with a lot of links contained in that page and the AI incident response checklist we'll",
    "start": "3430839",
    "end": "3436839"
  },
  {
    "text": "include that right at the top of our show notes so definitely check that out and take stock of you know how your",
    "start": "3436839",
    "end": "3442079"
  },
  {
    "text": "organization is approaching this and hopefully we can follow that form happier path as practitioners so yeah",
    "start": "3442079",
    "end": "3449160"
  },
  {
    "text": "definitely check that out thank you both Patrick and Andrew for joining us this has been super interesting and really",
    "start": "3449160",
    "end": "3454680"
  },
  {
    "text": "important discussion so we appreciate that and wish you luck with the new firm and all the great things you're doing",
    "start": "3454680",
    "end": "3460400"
  },
  {
    "text": "well thank you so much it's been fun as always and I hope it's been helpful your this yeah thanks for having me this was",
    "start": "3460400",
    "end": "3465480"
  },
  {
    "text": "a fun [Music] discussion do you have questions praise",
    "start": "3465480",
    "end": "3471559"
  },
  {
    "text": "or constructive criticism about the conversation you just heard comment on this and every episode of practical AI",
    "start": "3471559",
    "end": "3478599"
  },
  {
    "text": "on Chang log.com just open your show notes follow the discuss on changelog",
    "start": "3478599",
    "end": "3484039"
  },
  {
    "text": "news link and let your voice be heard practical AI is hosted by Daniel",
    "start": "3484039",
    "end": "3490000"
  },
  {
    "text": "Whit neack and Chris Benson it's produced by Jared Santo that's me and our music is provided by the mysterious",
    "start": "3490000",
    "end": "3496119"
  },
  {
    "text": "breakmaster cylinder we're brought to you by some amazing sponsors special thanks to fley lenoe and rollbar and a",
    "start": "3496119",
    "end": "3503559"
  },
  {
    "text": "special shout out to those listening on our adree chog Plus+ feed if that's you",
    "start": "3503559",
    "end": "3508720"
  },
  {
    "text": "you're awesome if that's not you well you're awesome too but you can learn all about it at Chang log.com SL",
    "start": "3508720",
    "end": "3515480"
  },
  {
    "text": "Plus+ that's all for now we'll talk to you again next [Music]",
    "start": "3515480",
    "end": "3527000"
  },
  {
    "text": "week",
    "start": "3527000",
    "end": "3530000"
  }
]
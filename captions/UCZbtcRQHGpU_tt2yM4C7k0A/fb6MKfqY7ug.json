[
  {
    "text": "hey how's it going I'm your host gahard Lazo and you're listening to ship it a podcast about getting your best ideas",
    "start": "560",
    "end": "8120"
  },
  {
    "text": "into the world and seeing what happens we talk about code Ops infrastructure",
    "start": "8120",
    "end": "13480"
  },
  {
    "text": "and the people that make it happen yes we focus on the people because everything else is an implementation",
    "start": "13480",
    "end": "20439"
  },
  {
    "text": "detail today I'm joined by Alex kmos author of promix an Elixir Prometheus",
    "start": "20439",
    "end": "26160"
  },
  {
    "text": "metrics Library beam radio host as well as n Plus magician if you have been",
    "start": "26160",
    "end": "31599"
  },
  {
    "text": "following the",
    "start": "31599",
    "end": "34200"
  },
  {
    "text": "changelog.md grade if you had any Friday evening plans cancel them we will be",
    "start": "47800",
    "end": "53960"
  },
  {
    "text": "streaming live on our YouTube channel a Friday evening changer.com deploy of",
    "start": "53960",
    "end": "59320"
  },
  {
    "text": "earling 4 we'll be observing the impact of this upgrade with promx in grafana",
    "start": "59320",
    "end": "65840"
  },
  {
    "text": "Cloud you don't want to miss that big thanks to our partners fastly launch",
    "start": "65840",
    "end": "71040"
  },
  {
    "text": "darkle and linode our bandwidth is provided by fastly learn more at fastly.com feature Flags powered by",
    "start": "71040",
    "end": "77600"
  },
  {
    "text": "launch dark.com and we love Leno they keep it fast and simple check them out",
    "start": "77600",
    "end": "83439"
  },
  {
    "text": "at lin.com",
    "start": "83439",
    "end": "86200"
  },
  {
    "text": "changelog [Music] this episode of ship it is brought to you by render the zero devops Cloud that",
    "start": "88920",
    "end": "95840"
  },
  {
    "text": "empowers you to ship faster than your competitors here's HRA goel CEO of render sharing why developers choose",
    "start": "95840",
    "end": "101720"
  },
  {
    "text": "render over Heroku and how they're innovating much faster a lot of render customers come to us from huku and they",
    "start": "101720",
    "end": "108240"
  },
  {
    "text": "tell us render is what huku could have been I think it's because we offer a more streamlined approach to hosting",
    "start": "108240",
    "end": "115040"
  },
  {
    "text": "modern Cloud applications at a significantly better price point applications on render heal themselves",
    "start": "115040",
    "end": "122039"
  },
  {
    "text": "and scale automatically giving developers the features and flexibility of something like kubernetes but without",
    "start": "122039",
    "end": "129160"
  },
  {
    "text": "any of the complexity we're always working to bring the latest industry advances to our platform so your",
    "start": "129160",
    "end": "135440"
  },
  {
    "text": "applications can Leverage The state-of-the-art in the cloud without you having to do or learn anything all",
    "start": "135440",
    "end": "141560"
  },
  {
    "text": "right learn more about how render compares to Heroku at [Music]",
    "start": "141560",
    "end": "148840"
  },
  {
    "text": "render.png and to ask questions about the render platform again that's",
    "start": "148840",
    "end": "154840"
  },
  {
    "text": "[Music]",
    "start": "156900",
    "end": "159939"
  },
  {
    "text": "[Music]",
    "start": "162330",
    "end": "165469"
  },
  {
    "text": "[Music]",
    "start": "168630",
    "end": "174529"
  },
  {
    "text": "render.png Alex kmos some of you may know him from beam radio for those that",
    "start": "178760",
    "end": "183799"
  },
  {
    "text": "are listening Elixir we have Elixir tips I think going tip 100 landed not long",
    "start": "183799",
    "end": "189360"
  },
  {
    "text": "ago right that was like a I do indeed yeah and then I'm I'm taking a small height is from Twitter tips regarding",
    "start": "189360",
    "end": "195879"
  },
  {
    "text": "Alexa right we'll be back into it shortly don't worry everyone yeah so Alex has been around in the airline",
    "start": "195879",
    "end": "201680"
  },
  {
    "text": "Elixir Community for some years now I don't know how many I think it's got to be like six years now I read Sasha U's",
    "start": "201680",
    "end": "209000"
  },
  {
    "text": "book elixir back in 2015 and was hooked on the on the beam since then yeah I",
    "start": "209000",
    "end": "214360"
  },
  {
    "text": "guess it's been since 2015 I've been working on the beam that sounds awesome so the way I know you Alex is from the",
    "start": "214360",
    "end": "220920"
  },
  {
    "text": "work that you've been doing on the change lock app which is happens to be in Elixir Phoenix Earline behind the",
    "start": "220920",
    "end": "226319"
  },
  {
    "text": "scenes app they've been doing some fantastic optimizations especially with those n plus1 queries thank goodness for",
    "start": "226319",
    "end": "232439"
  },
  {
    "text": "that because the website will be much slower without oh yeah yeah and those things didn't happen in void right so",
    "start": "232439",
    "end": "238400"
  },
  {
    "text": "you had this amazing Library which you just happen to have I don't know how many libraries you have but I'm sure you",
    "start": "238400",
    "end": "244200"
  },
  {
    "text": "have a few but this is prom X or promex as I like to pronounce it because of that underscore and promx can you tell",
    "start": "244200",
    "end": "251640"
  },
  {
    "text": "us a bit more about that what that is the library sure thing I guess the elevator pitch for promx is that you",
    "start": "251640",
    "end": "258280"
  },
  {
    "text": "drop in this one Library you add it to your application supervision tree and then you do some slight configuration",
    "start": "258280",
    "end": "265440"
  },
  {
    "text": "kind of like in the you know like Ecto repo where you slightly configure your repo you slightly configure your promix",
    "start": "265440",
    "end": "271360"
  },
  {
    "text": "module and then you say hey I want a you metric plugin for Phoenix metric plugin",
    "start": "271360",
    "end": "277120"
  },
  {
    "text": "for Ecto I also have one for Obin and liveu so you kind of pull in whatever plugins you want that are applicable to",
    "start": "277120",
    "end": "282759"
  },
  {
    "text": "your project and then that's literally it that's all you have to do and then you have Prometheus metrics for all the",
    "start": "282759",
    "end": "288479"
  },
  {
    "text": "plugins that you configured and then for every plugin that I write that captures Prometheus metrics there is also a",
    "start": "288479",
    "end": "294759"
  },
  {
    "text": "corresponding grafana dashboard that promx will also upload to grafana for you if you choose to have PRX do that I",
    "start": "294759",
    "end": "301680"
  },
  {
    "text": "mean it's kind of like an end to-end solution for monitoring and I mean you could set PRX up and get dashboards and",
    "start": "301680",
    "end": "308080"
  },
  {
    "text": "metrics in like five minutes I really like that part especially the grafana dashboard sometimes it's so difficult to",
    "start": "308080",
    "end": "314680"
  },
  {
    "text": "integrate it just right get the correct labels get the correct things like what happens when there's an update then you",
    "start": "314680",
    "end": "320960"
  },
  {
    "text": "have to update the grafana dashboard and the one really interesting thing that promx I'm pronouncing it the way you're",
    "start": "320960",
    "end": "327120"
  },
  {
    "text": "pronouncing it Alex it's your library right so you're boss here so promx I",
    "start": "327120",
    "end": "332960"
  },
  {
    "text": "like it how it manages all aspects of metrics all the way from the erlang VM",
    "start": "332960",
    "end": "339280"
  },
  {
    "text": "all the metrics not just erlang metrics but also as you mentioned all those libraries all those components right of an Elixir Phoenix app and end to end",
    "start": "339280",
    "end": "349120"
  },
  {
    "text": "including when you have new deploys exactly I thought those annotations were so sweet right because it basically owns",
    "start": "349120",
    "end": "355919"
  },
  {
    "text": "the entire chain it will annotate your grafana dash boards when they're deploys",
    "start": "355919",
    "end": "361039"
  },
  {
    "text": "I thought it was amazing like never mind managing them which is super cool you also get annotations as to who deployed",
    "start": "361039",
    "end": "367479"
  },
  {
    "text": "and wit commit was deployed that was so cool oh yeah yeah I mean these have been pain points for me personally um",
    "start": "367479",
    "end": "373599"
  },
  {
    "text": "probably since like 2017 because I've been using Prometheus and gra for some time now and I felt like every project I",
    "start": "373599",
    "end": "379360"
  },
  {
    "text": "was doing the same boiler plate every single time like with the annotations and stuff like that but even after I set",
    "start": "379360",
    "end": "385440"
  },
  {
    "text": "up that boiler plate I'd still have problems where it's like oh look a library maintainer update their Prometheus package and you got some",
    "start": "385440",
    "end": "391720"
  },
  {
    "text": "slightly different metrics and now I have to manually know about that and then go pull down their Json definition",
    "start": "391720",
    "end": "397280"
  },
  {
    "text": "for the uh you know the the gra dashboard and then I have to go into gra copy and paste it you know lo and behold",
    "start": "397280",
    "end": "403039"
  },
  {
    "text": "there's some slight label discrepancies and like this churn all the time there had to have been better way I've been",
    "start": "403039",
    "end": "408639"
  },
  {
    "text": "playing around with these ideas for probably a couple years now yeah I mean promx is kind of that materialization of",
    "start": "408639",
    "end": "414000"
  },
  {
    "text": "all those ideas and it's I mean it's slightly opinionated I feel like a good tool should have some opinions",
    "start": "414000",
    "end": "420120"
  },
  {
    "text": "if those opinions align with the you know the library consumers that's great else you know maybe look elsewhere and",
    "start": "420120",
    "end": "426800"
  },
  {
    "text": "see if some other Solutions fit your problems better yeah that's right so I remember when um you were early days I",
    "start": "426800",
    "end": "433800"
  },
  {
    "text": "say maybe the beginning the beginning of promx when um we were trying to figure out like what dashboards are missing and",
    "start": "433800",
    "end": "439840"
  },
  {
    "text": "can we improve them slightly so I remember us working together a little bit it wasn't a massive amount but just",
    "start": "439840",
    "end": "445000"
  },
  {
    "text": "enough to make them nice the integration was really nice I remember when you added support for custom dashboards",
    "start": "445000",
    "end": "452400"
  },
  {
    "text": "which we do make use of by the way so we have some custom dashboards as well that promx can upload for you that was a",
    "start": "452400",
    "end": "459759"
  },
  {
    "text": "great feature so now we store our grafana Cloud dashboards with the app",
    "start": "459759",
    "end": "465919"
  },
  {
    "text": "and promx updates them so we have like nice Version Control going around and",
    "start": "465919",
    "end": "470960"
  },
  {
    "text": "you heard that right we do use graphon cloud we used to run our own grafana but then it was much easier to set up",
    "start": "470960",
    "end": "477680"
  },
  {
    "text": "grafana agent scrape all the metrics scrape all the logs from our apps from all the pods from everything we have",
    "start": "477680",
    "end": "484560"
  },
  {
    "text": "even the node exporter integration in the graan cloud agent we ship all those things to graan Cloud promx handles most",
    "start": "484560",
    "end": "493000"
  },
  {
    "text": "of the dashboards for us which is really cool and we have that nice integration going from our infrastructure which is",
    "start": "493000",
    "end": "499159"
  },
  {
    "text": "running kubernetes implementation detail I suppose but we have a really nice setup all version controlled and proex",
    "start": "499159",
    "end": "505280"
  },
  {
    "text": "handles a lot of the automation between the grafana cloud and our app or shall I say the other way around between our app",
    "start": "505280",
    "end": "511639"
  },
  {
    "text": "and graan Cloud so just to backtrack a little bit all this was possible I think",
    "start": "511639",
    "end": "517919"
  },
  {
    "text": "the beginning was the application so changel log.com it's publicly available freely available the source code it's in",
    "start": "517919",
    "end": "524760"
  },
  {
    "text": "Phoenix application that was an excellent idea Jared I don't want to say it's one of the best ones you've had but",
    "start": "524760",
    "end": "530720"
  },
  {
    "text": "it was a genius idea right to do that that was so good and what that meant is that we were exposed to this whole",
    "start": "530720",
    "end": "538079"
  },
  {
    "text": "ecosystem which is erlang Elixir Phoenix and there's so many good things",
    "start": "538079",
    "end": "543880"
  },
  {
    "text": "happening in it so the app change log is running Phoenix 1.5 right now Elixir 111",
    "start": "543880",
    "end": "550399"
  },
  {
    "text": "but 1.12 just came out so I'm really excited to try that out and erlang 23",
    "start": "550399",
    "end": "556120"
  },
  {
    "text": "but as we all know erlang 24 got shipped not long ago and that is an amazing",
    "start": "556120",
    "end": "562480"
  },
  {
    "text": "release what gets you excited about Earl Lang 24 Alex I think the biggest thing",
    "start": "562480",
    "end": "567519"
  },
  {
    "text": "is probably the most obvious one which is Justus in time compiler that landed in np24 that has some big promises in store",
    "start": "567519",
    "end": "575560"
  },
  {
    "text": "I think for everyone running Elixir and Phoenix applications I think a few months ago I was actually playing around",
    "start": "575560",
    "end": "580680"
  },
  {
    "text": "with the OTP 24 release and I had like a dummy Phoenix app and I just hit it with",
    "start": "580680",
    "end": "585959"
  },
  {
    "text": "an hctp stress tester and it was a very simple app I don't even think it had like a database back end to it it was",
    "start": "585959",
    "end": "592200"
  },
  {
    "text": "literally just you know pass some Json get a response back and there were measurable differences between the OTP P",
    "start": "592200",
    "end": "599440"
  },
  {
    "text": "24 I think it was release candidate one I was running at the time and OTP 23 and",
    "start": "599440",
    "end": "606160"
  },
  {
    "text": "I was pretty impressed that with just a very simple Hello World style uh you rest end point you still saw some pretty",
    "start": "606160",
    "end": "612720"
  },
  {
    "text": "big performance gains so I'm really curious to see you know people taking measurements in production with with",
    "start": "612720",
    "end": "618680"
  },
  {
    "text": "actual live traffic and see you know what the performance characteristics look like for applications with the",
    "start": "618680",
    "end": "624240"
  },
  {
    "text": "change over yeah I mean change law can definitely benefit from that it would be great to measure by how much I think",
    "start": "624240",
    "end": "630800"
  },
  {
    "text": "that's one of the plans right to try now that OTP 24 is properly out we had the",
    "start": "630800",
    "end": "635959"
  },
  {
    "text": "first patch release land and we also had just today a few hours ago thanks to Twitter and thanks to Alex arm support",
    "start": "635959",
    "end": "643079"
  },
  {
    "text": "arm 64 support for OTP 24 with ad Jus in time compiler so for those that have",
    "start": "643079",
    "end": "650720"
  },
  {
    "text": "tried it or would like to try it and are wondering why the performance increases between 30 and 50% so it can be up to",
    "start": "650720",
    "end": "659360"
  },
  {
    "text": "50% faster whatever you're running just simply by upgrading to 24 and yeah",
    "start": "659360",
    "end": "664880"
  },
  {
    "text": "depending on how it was compiled how your code was compiled it could be even higher so it depends based on which",
    "start": "664880",
    "end": "670680"
  },
  {
    "text": "optimizations you're picking up from OTP 24 okay so how would someone using promx",
    "start": "670680",
    "end": "679079"
  },
  {
    "text": "how would someone figure out what is faster so you have your app your Phoenix",
    "start": "679079",
    "end": "685920"
  },
  {
    "text": "app or your Elixir app I'm imagining that promx works with Elixir as well you don't have to have Phoenix is that right",
    "start": "685920",
    "end": "692839"
  },
  {
    "text": "yeah and the idea was to decouple the two because you may want to grab Prometheus metrics on your application but maybe it's like a who knows like a",
    "start": "692839",
    "end": "699560"
  },
  {
    "text": "like a q worker right there's not going to be a phoenix component there but as we all know Prometheus needs to scrape",
    "start": "699560",
    "end": "704880"
  },
  {
    "text": "something over hctp unless you're using a remote right we'll get into that maybe a little bit later so promix actually",
    "start": "704880",
    "end": "710800"
  },
  {
    "text": "does ship with a very very lightweight HTTP server and it'll just serve your",
    "start": "710800",
    "end": "715839"
  },
  {
    "text": "your metrics for you so you can very easily run promx inside of like a q worker expose that one end point and",
    "start": "715839",
    "end": "722680"
  },
  {
    "text": "have you know your Prometheus instance come and scrape it at its regular interval yeah that's right and you",
    "start": "722680",
    "end": "728240"
  },
  {
    "text": "expose metrics just metrics yes yeah for now it's just metrics earlier you",
    "start": "728240",
    "end": "734519"
  },
  {
    "text": "mentioned Graf's uh grafana agent and the idea is to eventually ship that as",
    "start": "734519",
    "end": "739680"
  },
  {
    "text": "part of promx it'll be like an optional download So as promx is starting if you configure it to push Prometheus metrics",
    "start": "739680",
    "end": "746959"
  },
  {
    "text": "you can have promix download the the agent get it up and running in a supervision tree then you don't even",
    "start": "746959",
    "end": "752079"
  },
  {
    "text": "need to have promic serve up an HTTP server you can push metrics directly and I've actually used graff's Cloud",
    "start": "752079",
    "end": "758279"
  },
  {
    "text": "offering it's it's quite nice and it makes the observability story super super nice especially in like if you're",
    "start": "758279",
    "end": "764480"
  },
  {
    "text": "running in Heroku or gigix or places where maybe you don't own the infrastructure end to end and it's tough",
    "start": "764480",
    "end": "769800"
  },
  {
    "text": "to have a Prometheus instance scraping your stuff over the public internet so remote right gravana agent all super",
    "start": "769800",
    "end": "776480"
  },
  {
    "text": "exciting things and hopefully coming soon to promise that's really interesting so this is",
    "start": "776480",
    "end": "783040"
  },
  {
    "text": "such an amazing piece of information which I don't know how I've missed but I'm glad that you mentioned this because",
    "start": "783040",
    "end": "789760"
  },
  {
    "text": "we were thinking a couple of weeks back how can we run the Chang lock app on",
    "start": "789760",
    "end": "795440"
  },
  {
    "text": "render and have all the metrics and all the logs shipped to graan Cloud without",
    "start": "795440",
    "end": "802560"
  },
  {
    "text": "having to set up something else that scrapes the metrics and Tails the logs and then forwards them so",
    "start": "802560",
    "end": "809560"
  },
  {
    "text": "this is super exciting because you have metrics already I am feature requesting logs",
    "start": "809560",
    "end": "817079"
  },
  {
    "text": "please so that we can ship the logs as well using the grafana cloud agent which",
    "start": "817079",
    "end": "823480"
  },
  {
    "text": "I know it supports them and then the only thing remaining would be traces which by the way it also supports so we",
    "start": "823480",
    "end": "831279"
  },
  {
    "text": "have the metrics the events or metrics logs and events that is a very special",
    "start": "831279",
    "end": "836800"
  },
  {
    "text": "Trio can you tell us a bit more about about that Alex what are your thoughts on that special Trio we could start with",
    "start": "836800",
    "end": "842440"
  },
  {
    "text": "the abstract and then we can work down into the technical nitty-gritty so those three that you mentioned just so happen",
    "start": "842440",
    "end": "847600"
  },
  {
    "text": "to be the pillars of observability all three of those are the three pillars of observability it's theorized that if you",
    "start": "847600",
    "end": "853199"
  },
  {
    "text": "have all three of these pillars in your app you've achieved the coveted observability and all your sres and your",
    "start": "853199",
    "end": "859759"
  },
  {
    "text": "devops people in your organization will come and shake your hand and all will be well in the world but",
    "start": "859759",
    "end": "866240"
  },
  {
    "text": "um jokes aside the idea is that these three different types of observability tools yield different",
    "start": "866240",
    "end": "874000"
  },
  {
    "text": "benefits for your application so with logs if you're capturing uh logs in your",
    "start": "874000",
    "end": "879399"
  },
  {
    "text": "applications or your services you can see you know in very very you know nitty-gritty detail what's happening on",
    "start": "879399",
    "end": "886160"
  },
  {
    "text": "every single request what's happening you know if there are errors if there are warnings if you're having trouble connecting to other services you get",
    "start": "886160",
    "end": "892320"
  },
  {
    "text": "very very fine grain detail as to what's going on this is super awesome and uh",
    "start": "892320",
    "end": "897560"
  },
  {
    "text": "it's very helpful to have this very in-depth information problem is that you can kind of be inundated by too much",
    "start": "897560",
    "end": "903959"
  },
  {
    "text": "information and it's very difficult to kind of extrapolate higher meaning out of all this nitty-gritty detail then if",
    "start": "903959",
    "end": "911839"
  },
  {
    "text": "you've ever run like an elk stack and had to administer that you know the Pains of you know trying to index all",
    "start": "911839",
    "end": "918759"
  },
  {
    "text": "this data you know then you might say okay let's Only log what's important and I'm sure people with the production apps",
    "start": "918759",
    "end": "924880"
  },
  {
    "text": "have had their devops people come to them and say hey let's dial back the logging it's a little too much and elastic search is just Keeling over so",
    "start": "924880",
    "end": "932279"
  },
  {
    "text": "you know then then you reach for other tools like metrics you know metrics eventually find their way into some sort",
    "start": "932279",
    "end": "937959"
  },
  {
    "text": "of a Time series database and they're usually pretty efficient in comparison to logs because they're more bounded",
    "start": "937959",
    "end": "944440"
  },
  {
    "text": "right you have a measurement you have a time stamp and you have some labels associated with that you know a little srisk there because that kind of depends",
    "start": "944440",
    "end": "951040"
  },
  {
    "text": "on what your time series database of choices but that's that's kind of roughly speaking what what goes into",
    "start": "951040",
    "end": "957399"
  },
  {
    "text": "capturing time series data so given that you've paired down what information you're capturing you could start a lot",
    "start": "957399",
    "end": "964240"
  },
  {
    "text": "more efficiently and it's a lot easier to query and you can keep these for way way way longer periods of time but the",
    "start": "964240",
    "end": "971079"
  },
  {
    "text": "problem is there that you've you've now traded off you know High Fidelity logs for you know explicit metrics that",
    "start": "971079",
    "end": "977319"
  },
  {
    "text": "you're capturing over time so again tradeoff and there different tools for the job and you kind of reach for for",
    "start": "977319",
    "end": "983040"
  },
  {
    "text": "what's best at that particular point in time and then traces is kind of like a a merger of the two la and metrics where",
    "start": "983040",
    "end": "989720"
  },
  {
    "text": "you can see how long your application is sitting in different parts of the application if you're making external",
    "start": "989720",
    "end": "996279"
  },
  {
    "text": "service calls how long are you waiting for those external service calls if you have something like ISO set up and you",
    "start": "996279",
    "end": "1001839"
  },
  {
    "text": "can track you know requests across Services you can see how long it takes to you know bounce across service AB c",
    "start": "1001839",
    "end": "1007560"
  },
  {
    "text": "and d and how long it takes to unroll and go all the way back to the original caller and then again you get some metadata associated with those traces",
    "start": "1007560",
    "end": "1014319"
  },
  {
    "text": "and time stamps and stuff like that so again all three of these are different tools they have some overlap but it's",
    "start": "1014319",
    "end": "1021000"
  },
  {
    "text": "really a matter of picking the best tool for the job and it'd be nice if you have all three of those in your you know in",
    "start": "1021000",
    "end": "1026760"
  },
  {
    "text": "your company or application but uh in the real world it is tough to get all three of these stood up and and running",
    "start": "1026760",
    "end": "1032959"
  },
  {
    "text": "efficiently and and running effectively I really like the way you think about this I have to say there is something",
    "start": "1032959",
    "end": "1038720"
  },
  {
    "text": "pragmatic about it and something like you can have this within five minutes but I also am very aware because",
    "start": "1038720",
    "end": "1046400"
  },
  {
    "text": "I've been following charity majors honeycomb and those perspectives for",
    "start": "1046400",
    "end": "1051880"
  },
  {
    "text": "many years and my understanding is that the only thing you should care about is",
    "start": "1051880",
    "end": "1057760"
  },
  {
    "text": "events and if you have a data store that understands arbitrarily wide events",
    "start": "1057760",
    "end": "1063160"
  },
  {
    "text": "something that can query them just in time at scale then you don't have to trade off the cardinality constraints",
    "start": "1063160",
    "end": "1070480"
  },
  {
    "text": "that metrics have versus the volume of logs that is just too much and the",
    "start": "1070480",
    "end": "1076760"
  },
  {
    "text": "indexing and how basically that happen happens behind the scenes so the implementation that limits you to how",
    "start": "1076760",
    "end": "1082520"
  },
  {
    "text": "use those logs so I think that perspective is very interesting and I",
    "start": "1082520",
    "end": "1087960"
  },
  {
    "text": "will definitely follow up on that some more in the context of the show of",
    "start": "1087960",
    "end": "1093240"
  },
  {
    "text": "shipit but I'm also aware of where we are today and when I say we I mean the",
    "start": "1093240",
    "end": "1098679"
  },
  {
    "text": "change lock app what we have already set up and that ideal which is everything in",
    "start": "1098679",
    "end": "1104559"
  },
  {
    "text": "an event I think whether we want to or not I can see how we are going on the",
    "start": "1104559",
    "end": "1109840"
  },
  {
    "text": "journey maybe some are more frustrated others are more enlightened but I can see how events potentially have the",
    "start": "1109840",
    "end": "1118200"
  },
  {
    "text": "answer to all these things but right now the reality is that we still have to make this choice between metrics or logs",
    "start": "1118200",
    "end": "1127360"
  },
  {
    "text": "traces as well and they're like separate components and I think that grafana cloud is doing a pretty good job with",
    "start": "1127360",
    "end": "1135240"
  },
  {
    "text": "cortex which is a Prometheus that scales basically lowkey which is for indexing",
    "start": "1135240",
    "end": "1140840"
  },
  {
    "text": "logs and it's great to derive insights out of that and Tempo which I haven't used yet which is for traces but there",
    "start": "1140840",
    "end": "1147400"
  },
  {
    "text": "are like these like the three components in the grafana cloud that serve these three different functions I think it's",
    "start": "1147400",
    "end": "1154159"
  },
  {
    "text": "very interesting to get to that tool which unifies them all and gravana Cloud",
    "start": "1154159",
    "end": "1159440"
  },
  {
    "text": "could be it but there are others as well now I'm not going to go through all the names because that's boring but what is",
    "start": "1159440",
    "end": "1165600"
  },
  {
    "text": "interesting is that that we seem to be going in the same direction and we may argue between ourselves",
    "start": "1165600",
    "end": "1171200"
  },
  {
    "text": "whether the pillars of observability are a thing or are just you know a big joke",
    "start": "1171200",
    "end": "1176720"
  },
  {
    "text": "right different perspectives but I think ultimately what really matters is being",
    "start": "1176720",
    "end": "1182400"
  },
  {
    "text": "able to understand what is happening in your application or what is happening with your website or your service or",
    "start": "1182400",
    "end": "1189440"
  },
  {
    "text": "whatever unknown unknowns I'm not going to open that kind of worms but the point being is do you understand what is",
    "start": "1189440",
    "end": "1195480"
  },
  {
    "text": "happening it may be imperfect it may be limited but do you have at least like an",
    "start": "1195480",
    "end": "1200960"
  },
  {
    "text": "idea of where to look where the problems are and I do know that promex helped us",
    "start": "1200960",
    "end": "1206679"
  },
  {
    "text": "or helped you with the N plus1 queries right it was very obvious hey we have a",
    "start": "1206679",
    "end": "1211880"
  },
  {
    "text": "problem with Necto and this is what that problem looks like and this is how we fix it and yes we fixed it does llang 24",
    "start": "1211880",
    "end": "1218000"
  },
  {
    "text": "improve things to llang 23 in with what way and we can answer those questions as",
    "start": "1218000",
    "end": "1223039"
  },
  {
    "text": "well so I think the monitoring is not going anywhere and I think everybody respects it for what it is but we also",
    "start": "1223039",
    "end": "1230120"
  },
  {
    "text": "are aware that there are better ways and we should improve this so with that in mind where do you see promx going what",
    "start": "1230120",
    "end": "1237400"
  },
  {
    "text": "are the hopes and the goals for the project yeah sure thing so I'm goingon to First address a couple points that",
    "start": "1237400",
    "end": "1244440"
  },
  {
    "text": "you made and then I'll and then I'll answer the question sure and this is just my own personal opinion I don't see",
    "start": "1244440",
    "end": "1249559"
  },
  {
    "text": "everything rolling up into one solution I I just don't think it's feasible at the moment like would it be nice if",
    "start": "1249559",
    "end": "1255120"
  },
  {
    "text": "everything was an event and we could easily search it and everything is you know hunky dory I think everyone would",
    "start": "1255120",
    "end": "1260799"
  },
  {
    "text": "agree yes they'll be great and I think we've tried this in the past where you know stuff everything in Elk write some",
    "start": "1260799",
    "end": "1267400"
  },
  {
    "text": "nice redx expressions and extrapolate metrics from those redx expressions from your elastic search database and from",
    "start": "1267400",
    "end": "1274840"
  },
  {
    "text": "organizations that I've been at that have gone down that route it's extremely painful I think for now for the foreal",
    "start": "1274840",
    "end": "1280679"
  },
  {
    "text": "of future having kind of those like explicit tools for explicit purposes I think makes sense just because they're",
    "start": "1280679",
    "end": "1288480"
  },
  {
    "text": "very different problems that are trying to be solved and trying to have you know one unifying tool that does all the",
    "start": "1288480",
    "end": "1294120"
  },
  {
    "text": "things I don't think will pan out well but I do like the approach that grafana is taking and the observability",
    "start": "1294120",
    "end": "1301480"
  },
  {
    "text": "community in general where they're trying to provide Bridges from you know one pillar to another a perfect example",
    "start": "1301480",
    "end": "1308200"
  },
  {
    "text": "is exemplars in Prometheus right where your Prometheus metrics can have an Exemplar tag on them and it'll",
    "start": "1308200",
    "end": "1314919"
  },
  {
    "text": "effectively say hey this metric data point is is applicable to this trace and",
    "start": "1314919",
    "end": "1320720"
  },
  {
    "text": "you can kind of jump and say okay something weird is happening here in the metrics I'm getting a ton of 500s let me",
    "start": "1320720",
    "end": "1325880"
  },
  {
    "text": "look at an Exemplar for that 500 and you can click through and you can kind of shift your focus from metrics and go to",
    "start": "1325880",
    "end": "1333240"
  },
  {
    "text": "traces but still have that context of that that problem that I was having 500s so I think I like that approach better",
    "start": "1333240",
    "end": "1340240"
  },
  {
    "text": "where it's you can bounce between the different pillars of observability but still have the context of I'm trying to",
    "start": "1340240",
    "end": "1345480"
  },
  {
    "text": "solve this problem what is going on at this moment in time so I like that approach again you know that's just my",
    "start": "1345480",
    "end": "1352159"
  },
  {
    "text": "personal opinion and to that end and I'll go back to your original question now I would like to get promic to a",
    "start": "1352159",
    "end": "1357240"
  },
  {
    "text": "point where it does take into account things like you know traces and you could use exemplars and if grafana agent",
    "start": "1357240",
    "end": "1362600"
  },
  {
    "text": "is incorporated into promx you could very very easily use like CIS log and Export logs from your application via",
    "start": "1362600",
    "end": "1370080"
  },
  {
    "text": "CIS log to graphon agent then those find their way to Loki so I don't want to",
    "start": "1370080",
    "end": "1375919"
  },
  {
    "text": "tailor promic solely to grafana but I do see that grafana is offering a lot of",
    "start": "1375919",
    "end": "1381480"
  },
  {
    "text": "tooling that's very very powerful and I would love to leverage it so hope that answers the question there I think",
    "start": "1381480",
    "end": "1388240"
  },
  {
    "text": "that's a very interesting perspective I love [Music]",
    "start": "1388240",
    "end": "1404799"
  },
  {
    "text": "that this episode is brought to you by our friend at cockroach lab the makers",
    "start": "1404799",
    "end": "1410240"
  },
  {
    "text": "of cockroach DB the most highly evolved database on the planet with cockroach DB",
    "start": "1410240",
    "end": "1415760"
  },
  {
    "text": "you can scale fast survive anything and Thrive everywhere it's open source",
    "start": "1415760",
    "end": "1421360"
  },
  {
    "text": "postgress wire compatible and kubernetes friendly which means you can launch and run it anywhere for those who need more",
    "start": "1421360",
    "end": "1427559"
  },
  {
    "text": "you can build and skill fast with cockroach Cloud which is cockroach DB hosted as a service it's the simplest",
    "start": "1427559",
    "end": "1433240"
  },
  {
    "text": "way to deploy DB and is available instantly on AWS and Google Cloud with",
    "start": "1433240",
    "end": "1438400"
  },
  {
    "text": "cockroach Cloud a team of worldclass sres maintains and manages your database infrastructure so you can focus Less on",
    "start": "1438400",
    "end": "1445000"
  },
  {
    "text": "Ops and more on code get started for free with a 30-day free trial or try their new forever free tier that's super",
    "start": "1445000",
    "end": "1450880"
  },
  {
    "text": "generous head to cockr labs.com changelog to learn more again cockroach labs.com",
    "start": "1450880",
    "end": "1457760"
  },
  {
    "text": "[Music]",
    "start": "1458480",
    "end": "1465679"
  },
  {
    "text": "changelog that was a really interesting point that you've made Alex just before we took the break and I would like to",
    "start": "1465679",
    "end": "1471039"
  },
  {
    "text": "dig into it a little bit more I would like to hear more about proex the hopes and goals because I think there's more",
    "start": "1471039",
    "end": "1476159"
  },
  {
    "text": "on pack there but I found it very interesting how the exemplars that you have in metrics how they link to traces",
    "start": "1476159",
    "end": "1483480"
  },
  {
    "text": "and you mentioned something very interesting about logs and how a lot of",
    "start": "1483480",
    "end": "1488799"
  },
  {
    "text": "information can be derived from them if the logs are in the right format so in",
    "start": "1488799",
    "end": "1495120"
  },
  {
    "text": "our change log app just to give that example we have a lot of logs actually",
    "start": "1495120",
    "end": "1500279"
  },
  {
    "text": "most logs are still in the standard unstructured format so you have like",
    "start": "1500279",
    "end": "1505880"
  },
  {
    "text": "long lines of text and that's okay but that's where the regex are needed to",
    "start": "1505880",
    "end": "1512720"
  },
  {
    "text": "extract meaning from those lines so the thing which I found to work a lot better for example Ingress Eng Gen",
    "start": "1512720",
    "end": "1519640"
  },
  {
    "text": "X which we also run is to use Json logging so we put all the different",
    "start": "1519640",
    "end": "1525200"
  },
  {
    "text": "information which you can think of them as metrics in that one very wide event which is like the log line so for",
    "start": "1525200",
    "end": "1532679"
  },
  {
    "text": "example status 200 how many bytes how long it took which was the refer stuff",
    "start": "1532679",
    "end": "1538520"
  },
  {
    "text": "like that and that information when it ends up in Loki writing loog ql queries",
    "start": "1538520",
    "end": "1545159"
  },
  {
    "text": "which are very similar to promql queries makes it easy to",
    "start": "1545159",
    "end": "1550720"
  },
  {
    "text": "derive graphs which you would typically get from metrics from your logs so then",
    "start": "1550720",
    "end": "1557880"
  },
  {
    "text": "and the boundaries between metrics and logs are blurry like you don't really know whether was this a log or was this",
    "start": "1557880",
    "end": "1564200"
  },
  {
    "text": "a metric does it really matter it's what your understanding is from metrics and",
    "start": "1564200",
    "end": "1569760"
  },
  {
    "text": "logs so that makes me wonder how are logs and metrics different if you use",
    "start": "1569760",
    "end": "1575960"
  },
  {
    "text": "logs as Json and you have this arbitrarily wide metric if you wish",
    "start": "1575960",
    "end": "1581880"
  },
  {
    "text": "because it's kind of metric right you have all these metrics like status as I said bytes time taken all those are",
    "start": "1581880",
    "end": "1588159"
  },
  {
    "text": "metrics and they all appear in a single line so what is the difference then between the metrics that you get in",
    "start": "1588159",
    "end": "1593760"
  },
  {
    "text": "Prometheus which have a slightly different format and the values like at the end and you have many metrics that",
    "start": "1593760",
    "end": "1599520"
  },
  {
    "text": "you may put together like for example for samples or summaries but in logs are slightly different and yet the end",
    "start": "1599520",
    "end": "1605480"
  },
  {
    "text": "result is very very similar what are your thoughts on that yeah I think uh in",
    "start": "1605480",
    "end": "1610520"
  },
  {
    "text": "the spirit of uh you know just in time jit I think that's effective what we're doing with logs when we try to",
    "start": "1610520",
    "end": "1615880"
  },
  {
    "text": "extrapolate metrics out of them is through this event Into The Ether with a whole bunch of data associated with it",
    "start": "1615880",
    "end": "1622880"
  },
  {
    "text": "maybe we don't know what we want to do with it at the end but uh you know given that given that that event is in the",
    "start": "1622880",
    "end": "1629159"
  },
  {
    "text": "database we can extrapolate some metrics out of it so we're just in time kind of getting some metrics out of that",
    "start": "1629159",
    "end": "1636320"
  },
  {
    "text": "log you could do that you you could go down that route I think that for some",
    "start": "1636320",
    "end": "1642120"
  },
  {
    "text": "scenarios that may be your only option like let's say you're running an external service and all it's giving you",
    "start": "1642120",
    "end": "1647360"
  },
  {
    "text": "is structured logs out there's no way to tie in you know maybe um an agent inside",
    "start": "1647360",
    "end": "1652640"
  },
  {
    "text": "of there or get internal events and and hook in your own Prometheus exporter for some scenarios that may be your only",
    "start": "1652640",
    "end": "1659519"
  },
  {
    "text": "option and then I think that's a valid use case and you know read the structured logs and generate some",
    "start": "1659519",
    "end": "1665919"
  },
  {
    "text": "metrics out of them but for when you can control those things I think storing them in a Time series database I think",
    "start": "1665919",
    "end": "1673039"
  },
  {
    "text": "will be beneficial for the team because it's less stress on the infrastructure it'll be far more performant so it's",
    "start": "1673039",
    "end": "1679840"
  },
  {
    "text": "again a bit of a trade-off there as to what route you go down that's interesting okay so PRX big on metrics",
    "start": "1679840",
    "end": "1688600"
  },
  {
    "text": "maybe logs are you thinking maybe logs perhaps I think the extent of the log",
    "start": "1688600",
    "end": "1694360"
  },
  {
    "text": "support out of PRX will be just the the shipping mechanism given that the the",
    "start": "1694360",
    "end": "1699799"
  },
  {
    "text": "plan is to have grafana agent as part of promx as kind of like an optional download you can Target that promx AG or",
    "start": "1699799",
    "end": "1707000"
  },
  {
    "text": "that graphon agent for you know exporting logs to Loki but I don't think promix will transform into a library",
    "start": "1707000",
    "end": "1713840"
  },
  {
    "text": "where it also provides like structured logging mechanisms I think there's some there's some good stuff already built",
    "start": "1713840",
    "end": "1719360"
  },
  {
    "text": "into the Elixir logger on that front but that's not a problem i' like to tackle",
    "start": "1719360",
    "end": "1724799"
  },
  {
    "text": "in the promic library yep okay that makes sense what about events uh so like",
    "start": "1724799",
    "end": "1731320"
  },
  {
    "text": "traces for example I'm thinking events that we where we have from the airline",
    "start": "1731320",
    "end": "1736600"
  },
  {
    "text": "library and the airline ecosystem right we have it's very rich in that it can expose all sorts of events and I think",
    "start": "1736600",
    "end": "1742679"
  },
  {
    "text": "this is where we are touching on the open Telemetry and the sort of things",
    "start": "1742679",
    "end": "1747760"
  },
  {
    "text": "that the airline and elixir ecosystem have going for them which I think is a very good implementation the very good",
    "start": "1747760",
    "end": "1754559"
  },
  {
    "text": "story around Telemetry ah yes yeah so let's rewind a little bit out of of",
    "start": "1754559",
    "end": "1759600"
  },
  {
    "text": "promx and talk about what you're hinting at here so there are a couple projects in The Elixir and earling ecosystem so",
    "start": "1759600",
    "end": "1767159"
  },
  {
    "text": "open Telemetry as far as I understand right now is an implementation of the open Telemetry spec I think it's solely",
    "start": "1767159",
    "end": "1774200"
  },
  {
    "text": "just for tracing I think even that Library so open Telemetry builds upon another Elixir and earling Library",
    "start": "1774200",
    "end": "1781399"
  },
  {
    "text": "called Telemetry and that lives in a GitHub organization I think it's beam",
    "start": "1781399",
    "end": "1786840"
  },
  {
    "text": "Das Telemetry but that Library so Telemetry offers Library authors a way",
    "start": "1786840",
    "end": "1793519"
  },
  {
    "text": "to surface internal Library events to",
    "start": "1793519",
    "end": "1798640"
  },
  {
    "text": "who's ever using that Library it's completely agnostic for how you structure these things aside from you",
    "start": "1798640",
    "end": "1804960"
  },
  {
    "text": "capture some measurements associated with that event and some metadata that's pretty much it so every Library can",
    "start": "1804960",
    "end": "1810200"
  },
  {
    "text": "Surface events and you as the consumer of that Library can say Okay I want to pull out these measurements from the event and maybe this metadata from the",
    "start": "1810200",
    "end": "1817399"
  },
  {
    "text": "event so a perfect example would be the Phoenix web framework will surface an event when it's you know completed a",
    "start": "1817399",
    "end": "1824039"
  },
  {
    "text": "request and when it's serviced a request and inside of that event it'll have a a measurement for how long it took to",
    "start": "1824039",
    "end": "1829640"
  },
  {
    "text": "service that uh request that'll be your duration and the metadata may be the route that the person hit the response",
    "start": "1829640",
    "end": "1836679"
  },
  {
    "text": "status code the length of the response payload etc etc and then if you choose",
    "start": "1836679",
    "end": "1843240"
  },
  {
    "text": "to hook on to that Telemetry event you can use all that data if you don't hook on to that event it's effectively like a",
    "start": "1843240",
    "end": "1848799"
  },
  {
    "text": "noop so you're not losing any you know performance per se here that's effectively how promx works all these",
    "start": "1848799",
    "end": "1855360"
  },
  {
    "text": "libraries that I attached to are emitting these Telemetry events I just so happen to hook into all these",
    "start": "1855360",
    "end": "1860519"
  },
  {
    "text": "Telemetry events and then generate uh Prometheus metrics out of them so I think the story there in you know Elixir",
    "start": "1860519",
    "end": "1867600"
  },
  {
    "text": "and earling is very unique because the ecosystem has kind of said okay we're all going to use these foundary uh you",
    "start": "1867600",
    "end": "1874440"
  },
  {
    "text": "know building blocks and now I think the last time I looked on Hex PM I think",
    "start": "1874440",
    "end": "1880000"
  },
  {
    "text": "there were like 140 libraries using Telemetry which means now across the ecosystem we have this you know",
    "start": "1880000",
    "end": "1885720"
  },
  {
    "text": "ubiquitous language for how do we surface internal events in our libraries which is which is very very powerful",
    "start": "1885720",
    "end": "1892039"
  },
  {
    "text": "because now I don't need to learn how Phoenix exports events and how Obin",
    "start": "1892039",
    "end": "1897240"
  },
  {
    "text": "exports events and how Ecto exports events like it's all the same thing I just need to hook into like an ID for",
    "start": "1897240",
    "end": "1903240"
  },
  {
    "text": "what that event is and I'm off to the races at that point and I can capture kind of any any information that I like",
    "start": "1903240",
    "end": "1910000"
  },
  {
    "text": "that explains why PRX was such a I would say straightforward but almost like it",
    "start": "1910000",
    "end": "1917039"
  },
  {
    "text": "was obvious how to put it together it was obvious what users want and need because",
    "start": "1917039",
    "end": "1924679"
  },
  {
    "text": "you have all these libraries that expose these events they're there you can consume them so Ecto this week Oben next",
    "start": "1924679",
    "end": "1933120"
  },
  {
    "text": "week I'm simplifying it a lot but uh roughly that's how you're able to ship",
    "start": "1933120",
    "end": "1938679"
  },
  {
    "text": "support for all the different libraries because they all standardized on how",
    "start": "1938679",
    "end": "1943720"
  },
  {
    "text": "they expose events is that a fair summary yeah that's exactly right it is",
    "start": "1943720",
    "end": "1949000"
  },
  {
    "text": "quite a bit simplified simplification yeah cuz a lot of times I I'll sit down to write a like a promx plugin and as",
    "start": "1949000",
    "end": "1955919"
  },
  {
    "text": "I'm writing the plugin I'm like I need some more data here so I'll make a PR to the library author and then say hey I",
    "start": "1955919",
    "end": "1961720"
  },
  {
    "text": "think we need some additional metadata here or some additional measurements and then we have to go through that PR cycle",
    "start": "1961720",
    "end": "1967000"
  },
  {
    "text": "then I have to wait for a new release to get cut and then I have to make the gr on of dashboards so there's a good amount of work but yeah effectively",
    "start": "1967000",
    "end": "1972399"
  },
  {
    "text": "that's it it's see what events that Library emits hook into them convert them into uh you know meaningful",
    "start": "1972399",
    "end": "1979080"
  },
  {
    "text": "Prometheus metrics make the Graff on a dashboard and then ship it h that's a",
    "start": "1979080",
    "end": "1984360"
  },
  {
    "text": "good one actually I like that especially the last part especially the Shipp it part okay I thought you like",
    "start": "1984360",
    "end": "1989880"
  },
  {
    "text": "that okay so you have all these events so I'm wondering if you're ingesting",
    "start": "1989880",
    "end": "1995320"
  },
  {
    "text": "events you're translating them into metrics is there a point where you could",
    "start": "1995320",
    "end": "2001519"
  },
  {
    "text": "just expose those events raw and then something like for example honeycomb which loves events could just consume",
    "start": "2001519",
    "end": "2008480"
  },
  {
    "text": "them and I think that's how the honeycomb agent in some languages works right they just expose the raw events so",
    "start": "2008480",
    "end": "2015760"
  },
  {
    "text": "I I mean I'd have to play around with that and see some of these events have a lot a lot of metadata associated with",
    "start": "2015760",
    "end": "2021960"
  },
  {
    "text": "them again let's say that honeycomb is infinitely scalable and it doesn't take any compute time yeah sure thing just",
    "start": "2021960",
    "end": "2028399"
  },
  {
    "text": "dump like you a couple thousand lines of metadata per event into honeycomb but",
    "start": "2028399",
    "end": "2034799"
  },
  {
    "text": "I'd have to play around with honeycomb specifically to see if if if that's even possible I'm also fascinated by it",
    "start": "2034799",
    "end": "2040480"
  },
  {
    "text": "because I think the take is very interesting and I can see the uniqueness I would like to understand it more how",
    "start": "2040480",
    "end": "2046600"
  },
  {
    "text": "they make that possible for sure and the challenge is I mean if they pulled it",
    "start": "2046600",
    "end": "2052200"
  },
  {
    "text": "off which apparently they have that's impressive and I think it takes like an understanding of how complicated these",
    "start": "2052200",
    "end": "2058158"
  },
  {
    "text": "layers are just understand like what a feet that is in itself so that's",
    "start": "2058159",
    "end": "2063480"
  },
  {
    "text": "interesting okay so we have Telemetry we",
    "start": "2063480",
    "end": "2068800"
  },
  {
    "text": "have promx you mentioned about plugins is there anything specific that you'd",
    "start": "2068800",
    "end": "2075158"
  },
  {
    "text": "like to add to promx next anything that users are maybe asking for anything that you'd like to ship which you know would",
    "start": "2075159",
    "end": "2082118"
  },
  {
    "text": "be a hit yes aside from the grafana agent which I think some people are excited about um one thing I am big fan",
    "start": "2082119",
    "end": "2090520"
  },
  {
    "text": "please so one thing I forgot to mention was so in addition to supporting all these first-party plugins and gravana",
    "start": "2090520",
    "end": "2096398"
  },
  {
    "text": "dashboards and you kind of hinted at this before you know users of promx are encouraged to make their own promx",
    "start": "2096399",
    "end": "2102440"
  },
  {
    "text": "plugins and their own graphon dashboards and those plugins and dashboards are treated identical to how the first party",
    "start": "2102440",
    "end": "2109800"
  },
  {
    "text": "things are so you're able to upload those dashboards automatically on application in it you know your events",
    "start": "2109800",
    "end": "2115160"
  },
  {
    "text": "will be attached automatically so all those first-party plugins are kind of like dog fooding the architecture I",
    "start": "2115160",
    "end": "2121119"
  },
  {
    "text": "wanted to see how easy it was to create plugins and dashboards and have them all kind of coexist together so the idea is",
    "start": "2121119",
    "end": "2128560"
  },
  {
    "text": "that you use promic for all the like shared libraries in the ecosystem and then you write your own plugins and",
    "start": "2128560",
    "end": "2134880"
  },
  {
    "text": "graphon dashboards for things that are specific to your business that uh you know obviously are not going to be supported in in PRX yeah so that's one",
    "start": "2134880",
    "end": "2141800"
  },
  {
    "text": "thing I forgot to touch on and what was the original question I was asking about like if",
    "start": "2141800",
    "end": "2146839"
  },
  {
    "text": "there are any specific libraries that you are looking to integrate with and I'm looking at the available plugins",
    "start": "2146839",
    "end": "2152839"
  },
  {
    "text": "list and I can see which ones are stable this is by the way on github.com for",
    "start": "2152839",
    "end": "2158319"
  },
  {
    "text": "slaos with a kou for/ promore exex and",
    "start": "2158319",
    "end": "2163680"
  },
  {
    "text": "there's a list of available plugins bunch of them are stable uh Phoenix Oben Ecto Phoenix beam and the application",
    "start": "2163680",
    "end": "2171319"
  },
  {
    "text": "and then some are coming soon like Broadway absinth I'm not sure whether I'm pronouncing that correctly and a few",
    "start": "2171319",
    "end": "2177839"
  },
  {
    "text": "just like the booze right I don't know I really don't know yeah me neither okay",
    "start": "2177839",
    "end": "2184440"
  },
  {
    "text": "so Broadway that plugin is more or less done I made some changes to Broadway itself and those changes were were",
    "start": "2184440",
    "end": "2190640"
  },
  {
    "text": "accepted and merged into the Broadway project I don't think there's been a release cut as of as of us recording",
    "start": "2190640",
    "end": "2196160"
  },
  {
    "text": "right now so that plugin is kind of on hold until a a release gets cut and then I can kind of you know say that promx",
    "start": "2196160",
    "end": "2202920"
  },
  {
    "text": "depends on this version of of Broadway if you choose to use the Broadway plugin because I added some additional Telemetry events the idea is to get",
    "start": "2202920",
    "end": "2209760"
  },
  {
    "text": "Broadway wrapped up for those who don't know what Broadway is it's a really really Nifty Library where you can drop",
    "start": "2209760",
    "end": "2217119"
  },
  {
    "text": "it into your project and you could read from various q implementations and it takes care of a lot of the kind of",
    "start": "2217119",
    "end": "2223359"
  },
  {
    "text": "boiler plate and setting up a uh you know concurrent and parallelized worker so you can read from rabbit and you can",
    "start": "2223359",
    "end": "2229680"
  },
  {
    "text": "configure hey I want the you know 100 beam processes reading from rabbit at the same time and processing the work",
    "start": "2229680",
    "end": "2236280"
  },
  {
    "text": "from there and I think it's it supports rabbit Kofa and I think redus as well",
    "start": "2236280",
    "end": "2241839"
  },
  {
    "text": "but yeah Broadway is on the list and then absin is on the list after that because that's the Elixir graphql",
    "start": "2241839",
    "end": "2249760"
  },
  {
    "text": "framework so that seems to be pretty popular yeah after those two are wrapped up I'm just going to go on Hex PM see",
    "start": "2249760",
    "end": "2256160"
  },
  {
    "text": "which one has the most downloads after that and just you know think of that as a priority cue yeah whatever libraries",
    "start": "2256160",
    "end": "2262040"
  },
  {
    "text": "have the most downloads that are the most popular just make plugins for them as long as they support um they support",
    "start": "2262040",
    "end": "2268240"
  },
  {
    "text": "Telemetry that makes so much sense of course it's like the way you put it it's obvious what's most popular that thing",
    "start": "2268240",
    "end": "2275160"
  },
  {
    "text": "okay well that will have the most users and will be most successful and you know people find most useful so yeah that",
    "start": "2275160",
    "end": "2281520"
  },
  {
    "text": "makes perfect sense I like that very [Music]",
    "start": "2281520",
    "end": "2293240"
  },
  {
    "text": "sensible this episode is brought to you by Leno gone are the days when Amazon",
    "start": "2293240",
    "end": "2298319"
  },
  {
    "text": "web services was the only cloud provider in town Leno Stands Tall to offer cloud computing developers trust easily",
    "start": "2298319",
    "end": "2304760"
  },
  {
    "text": "deployed Cloud compute storage and networking in seconds with a full featured API CLI and Cloud manager with",
    "start": "2304760",
    "end": "2312560"
  },
  {
    "text": "a userfriendly interface whether you're working on a personal project or managing your Enterprises infrastructure",
    "start": "2312560",
    "end": "2318119"
  },
  {
    "text": "Leno has the pricing scale and support you need to launch and scale in the cloud get started with $100 in free",
    "start": "2318119",
    "end": "2325720"
  },
  {
    "text": "credit at lin.com changelog again lin.com SL change",
    "start": "2325720",
    "end": "2332450"
  },
  {
    "text": "[Music] log",
    "start": "2332450",
    "end": "2338800"
  },
  {
    "text": "so one of the things that we wanted to do I think we're mentioning this towards the beginning of the show we were saying",
    "start": "2341440",
    "end": "2347000"
  },
  {
    "text": "how earling 24 just shipped think it was a few weeks ago the final 24 release we",
    "start": "2347000",
    "end": "2354200"
  },
  {
    "text": "have the first patch release and we wanted to upgrade the Chang lock app to use erlang 24 so here's the plan by the",
    "start": "2354200",
    "end": "2362160"
  },
  {
    "text": "time you're listening to this either next day or a few days after",
    "start": "2362160",
    "end": "2367440"
  },
  {
    "text": "we will be performing a live upgrade on the change.com website from earling 23",
    "start": "2367440",
    "end": "2373680"
  },
  {
    "text": "to earling 24 we have PRX running we have all the metrics and we will see",
    "start": "2373680",
    "end": "2381079"
  },
  {
    "text": "live what difference r24 makes the change.com promx is obviously",
    "start": "2381079",
    "end": "2387319"
  },
  {
    "text": "instrumental all the metrics and all the logs get shipped to graan Cloud so that's how we will be observing things",
    "start": "2387319",
    "end": "2393920"
  },
  {
    "text": "and we'll be commenting out like what is different what is better what is worse",
    "start": "2393920",
    "end": "2399440"
  },
  {
    "text": "so with that in mind I'm wondering if there's any assumptions or expectations",
    "start": "2399440",
    "end": "2405480"
  },
  {
    "text": "that we can set ahead of time what are you thinking Alex yeah so I've been thinking about this for a little while",
    "start": "2405480",
    "end": "2411400"
  },
  {
    "text": "because measuring things before and after changes it just excites me to see that you made a change and you have some",
    "start": "2411400",
    "end": "2418040"
  },
  {
    "text": "measurable differences between how it was before and how it is afterwards so I've been thinking about this and some",
    "start": "2418040",
    "end": "2423319"
  },
  {
    "text": "of my hypotheses are that memory usage will go up slightly because that interpreted codee that was",
    "start": "2423319",
    "end": "2429480"
  },
  {
    "text": "compiled to Native needs to be stored somewhere so memory usage will go up slightly and then I imagine you know",
    "start": "2429480",
    "end": "2437560"
  },
  {
    "text": "most things CPU bound will be sped up so serializing and deserializing from Json",
    "start": "2437560",
    "end": "2443079"
  },
  {
    "text": "serializing and deserializing from postrest database all these things we should see a considerable change in",
    "start": "2443079",
    "end": "2449319"
  },
  {
    "text": "performance those are kind of top of mind at the moment so how about you I'm thinking",
    "start": "2449319",
    "end": "2456720"
  },
  {
    "text": "think that the end result that the users will see because of those serialization",
    "start": "2456720",
    "end": "2463520"
  },
  {
    "text": "speed UPS is a lower latency so responses will be",
    "start": "2463520",
    "end": "2470119"
  },
  {
    "text": "quicker now if you have listen to the Chang log 2021 setup you will know that",
    "start": "2470119",
    "end": "2477720"
  },
  {
    "text": "if you're accessing Chang log you're going through the CDN so every single request now goes through fastly and what",
    "start": "2477720",
    "end": "2484079"
  },
  {
    "text": "that means is that the responses are already 10 times faster or maybe faster",
    "start": "2484079",
    "end": "2490119"
  },
  {
    "text": "still so your responses are served within 50 milliseconds and that's what",
    "start": "2490119",
    "end": "2495839"
  },
  {
    "text": "graan cloud the probes are telling us so the website is already very fast because it's surf from fastly what we will see",
    "start": "2495839",
    "end": "2502440"
  },
  {
    "text": "however we have probes that also hit the website directly so expect the response latency if you go directly to the back",
    "start": "2502440",
    "end": "2509119"
  },
  {
    "text": "end or to the origin as the CDN calls it it will be slightly lower I also expect us the post SQL maybe not the the",
    "start": "2509119",
    "end": "2516760"
  },
  {
    "text": "queries necessarily but the responses as you mentioned Alex because of the serialization to be slightly faster so I",
    "start": "2516760",
    "end": "2522960"
  },
  {
    "text": "would expect the data from the database to load quicker and it will also result",
    "start": "2522960",
    "end": "2528839"
  },
  {
    "text": "in a quicker response times to the end users I'm very curious what happens with",
    "start": "2528839",
    "end": "2534200"
  },
  {
    "text": "context switches are we going to have fewer context switches so like less work",
    "start": "2534200",
    "end": "2539800"
  },
  {
    "text": "on the CPU or more and obviously Contex switches are not just like the work the CPU does but I think things will be a",
    "start": "2539800",
    "end": "2545839"
  },
  {
    "text": "lot less work to do so fewer Contex switches CP utilization I think it will go slightly down but right now we don't",
    "start": "2545839",
    "end": "2552520"
  },
  {
    "text": "have to worry about that because we have 32 CPUs all the AMD epics the latest one",
    "start": "2552520",
    "end": "2557720"
  },
  {
    "text": "thank you lenot those are amazing I mean everything is so much quicker and we have the nvme ssds it's just everything",
    "start": "2557720",
    "end": "2564920"
  },
  {
    "text": "is super quick but yeah for more I mean listen to the 2021 change lock setup where we cover some of these I think the",
    "start": "2564920",
    "end": "2570839"
  },
  {
    "text": "block post will come out so that's what I expect to see so will it make a difference for the users I don't think",
    "start": "2570839",
    "end": "2577440"
  },
  {
    "text": "it will because they have the CDN right so everything is already super quick as fast as it can be you have TLS",
    "start": "2577440",
    "end": "2583160"
  },
  {
    "text": "optimizations you have data locality have all the good stuff right because the CDN just serves requests from where",
    "start": "2583160",
    "end": "2589800"
  },
  {
    "text": "you are for the logged in users because obviously those requests we can't cash things will be slightly quicker so for",
    "start": "2589800",
    "end": "2596200"
  },
  {
    "text": "Adam for Jared whoever is working on the admin those things will be quicker",
    "start": "2596200",
    "end": "2601280"
  },
  {
    "text": "another thing which I do know that we do we do background processing on like some of the S3 files the logs and stuff like",
    "start": "2601280",
    "end": "2606960"
  },
  {
    "text": "that so I expect those to be quicker but I don't know by how much I think we're using Oben for that aren't we Alex yeah",
    "start": "2606960",
    "end": "2613800"
  },
  {
    "text": "yeah we're using Oben to I think Obin was was set up uh just to send out like",
    "start": "2613800",
    "end": "2619200"
  },
  {
    "text": "asynchronous emails I don't know if there's any other work being done by openen but now that you mention those",
    "start": "2619200",
    "end": "2625000"
  },
  {
    "text": "things we probably should have metrics in place to capture uh those S3 processing jobs and see how long they",
    "start": "2625000",
    "end": "2630440"
  },
  {
    "text": "take pre and post OTP 24 yeah that's right that's actually a good one that would be great one to add okay I'm",
    "start": "2630440",
    "end": "2637119"
  },
  {
    "text": "really looking forward to that and if you've listened to this you can watch it live and if you haven't that's okay",
    "start": "2637119",
    "end": "2643480"
  },
  {
    "text": "you'll see it on Twitter we will post maybe we'll even like do a scheduled live stream does that make sense for you",
    "start": "2643480",
    "end": "2650040"
  },
  {
    "text": "Alex what do you think yeah that works for me okay so KN imp prom two we'll",
    "start": "2650040",
    "end": "2655119"
  },
  {
    "text": "schedule it we'll say on this time at this day at this hour okay I like that that's a great idea actually so we'll",
    "start": "2655119",
    "end": "2661520"
  },
  {
    "text": "have like at least a few days of heads up and then you can listen to this and then you can watch that how we do it",
    "start": "2661520",
    "end": "2668119"
  },
  {
    "text": "great that makes me very excited okay so we're approaching the end I",
    "start": "2668119",
    "end": "2675200"
  },
  {
    "text": "think we need to end on a high because it's Friday when we recording this it was a good week and the weekend is just",
    "start": "2675200",
    "end": "2681960"
  },
  {
    "text": "around the corner so what do you have planned for this weekend Alex anything fun uh this weekend I think I have one",
    "start": "2681960",
    "end": "2689880"
  },
  {
    "text": "thing that I want to do in promx but then I'll be building a garden so I'll be outdoors using the table saw and the",
    "start": "2689880",
    "end": "2696040"
  },
  {
    "text": "the saw and the nail gun and putting together some nice garden beds okay well",
    "start": "2696040",
    "end": "2702000"
  },
  {
    "text": "that sounds amazing you have to balance all the PRX and all their laner Elixir work somehow right oh yeah oh yeah okay",
    "start": "2702000",
    "end": "2709599"
  },
  {
    "text": "you need to find a healthy balance between open source work the full-time job and a little bit of fun for yourself",
    "start": "2709599",
    "end": "2715960"
  },
  {
    "text": "yeah that's for sure so building a garden that sounds amazing you must be either very good or very brave I'm not",
    "start": "2715960",
    "end": "2722119"
  },
  {
    "text": "sure which one like either gray DIY or very brave you'll figure it out which",
    "start": "2722119",
    "end": "2728200"
  },
  {
    "text": "one is it I think I don't want to be arrogant or anything but I think I'm a decent diyer I also used to Tinker",
    "start": "2728200",
    "end": "2735040"
  },
  {
    "text": "around with cars quite a bit you know before I had a family MH when I was okay to be financially irresponsible and you",
    "start": "2735040",
    "end": "2741079"
  },
  {
    "text": "know buy you know a $3,000 motor just because I felt like it nowadays you",
    "start": "2741079",
    "end": "2746599"
  },
  {
    "text": "can't do that okay different times right yeah exactly world I could buy a motorcycle",
    "start": "2746599",
    "end": "2753079"
  },
  {
    "text": "anytime I wanted to you know I didn't have to worry about about uh providing for my kiddos MH I go with safe Hobbies",
    "start": "2753079",
    "end": "2760839"
  },
  {
    "text": "like building guarding beds or doing some woodworking okay that's that sounds great that sounds great so I hope the",
    "start": "2760839",
    "end": "2766960"
  },
  {
    "text": "weather is going to be great because for me the weather has been rubbish for like all week windy I won't say it's cold but",
    "start": "2766960",
    "end": "2773640"
  },
  {
    "text": "it's it's not nice it's it's rainy it's been raining all day every day we had some downpours as well so it hasn't been",
    "start": "2773640",
    "end": "2779240"
  },
  {
    "text": "really great and Ryan I'm looking at it like I was going to do the barbecue I love barbecuing the proper charcoal one",
    "start": "2779240",
    "end": "2785440"
  },
  {
    "text": "the weather is not good so I know maybe we get a parasol out so it doesn't rain and I barbecue",
    "start": "2785440",
    "end": "2790880"
  },
  {
    "text": "regardless maybe I don't know but what we have to do is post the pictures",
    "start": "2790880",
    "end": "2797000"
  },
  {
    "text": "because how can people appreciate how good of a DIY you actually are if they don't see your work so well played sir",
    "start": "2797000",
    "end": "2803119"
  },
  {
    "text": "well played all right I'll have I'll have to take some selfies I usually St from the Selfies yeah and videos those",
    "start": "2803119",
    "end": "2809559"
  },
  {
    "text": "are very important because if you don't take videos someone else could be do you the work and you just take pictures no",
    "start": "2809559",
    "end": "2815119"
  },
  {
    "text": "that would never happen right only movies never never all right Alex",
    "start": "2815119",
    "end": "2820480"
  },
  {
    "text": "well it's been a pleasure to have you on the show I really enjoy this I'm looking",
    "start": "2820480",
    "end": "2825559"
  },
  {
    "text": "forward to doing what we said we will do that's super exciting shipping Lang 24",
    "start": "2825559",
    "end": "2830760"
  },
  {
    "text": "for change.com that'll be great and which version of prox are we at now do",
    "start": "2830760",
    "end": "2836880"
  },
  {
    "text": "you know which one is the latest uh so the latest well I don't remember I think",
    "start": "2836880",
    "end": "2842319"
  },
  {
    "text": "1.1.0 is the latest and I think the change log is on",
    "start": "2842319",
    "end": "2847440"
  },
  {
    "text": "1.0.1 right so not that far behind but okay we'll bump it up that's great okay",
    "start": "2847440",
    "end": "2853160"
  },
  {
    "text": "so we ship that that is exciting ship a garden in the meantime as well maybe barbecue we'll see this has been",
    "start": "2853160",
    "end": "2859200"
  },
  {
    "text": "tremendous fun thank you Alex looking forward to next time yeah likewise",
    "start": "2859200",
    "end": "2865839"
  },
  {
    "text": "thanks that's it for this episode of shipit thank you for tuning in we have a",
    "start": "2867400",
    "end": "2872520"
  },
  {
    "text": "bunch of podcasts for developers at change log that you should check out subscribe to the master feed at Chang",
    "start": "2872520",
    "end": "2878960"
  },
  {
    "text": "log.com to get everything we ship I want to",
    "start": "2878960",
    "end": "2884240"
  },
  {
    "text": "personally invite you to join your fellow Chang loggers at Chang log.com",
    "start": "2884240",
    "end": "2889960"
  },
  {
    "text": "Community it's free to join and stay leaving on the other hand will cost you some happiness credits come hang with us",
    "start": "2889960",
    "end": "2897440"
  },
  {
    "text": "in slack they're no imposters everyone is welcome huge thanks again to our",
    "start": "2897440",
    "end": "2902559"
  },
  {
    "text": "partners fastly launch Darkly and M out also thanks to break master cylinder for",
    "start": "2902559",
    "end": "2908920"
  },
  {
    "text": "making all our awesome beats that's it for this week see you next",
    "start": "2908920",
    "end": "2914640"
  },
  {
    "text": "[Music]",
    "start": "2914640",
    "end": "2935040"
  },
  {
    "text": "week [Music]",
    "start": "2935040",
    "end": "2943359"
  },
  {
    "text": "love",
    "start": "2943359",
    "end": "2946318"
  }
]
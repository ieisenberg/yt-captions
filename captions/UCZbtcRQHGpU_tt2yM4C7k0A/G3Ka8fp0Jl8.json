[
  {
    "text": "[Music]",
    "start": "280",
    "end": "4040"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspired to or",
    "start": "6720",
    "end": "13080"
  },
  {
    "text": "are curious how AI related Tech is changing the world this is the show for you we just dropped dance party our",
    "start": "13080",
    "end": "21199"
  },
  {
    "text": "third fulllength album on Chang log beats buy it on band camp and iTunes or",
    "start": "21199",
    "end": "26640"
  },
  {
    "text": "stream it on Spotify Apple music and the rest Link in the show notes thank you to our partners at fly.io launch your app",
    "start": "26640",
    "end": "34600"
  },
  {
    "text": "close to your users find out how at [Music]",
    "start": "34600",
    "end": "42320"
  },
  {
    "text": "fly.io welcome to another episode of practical AI this is Daniel whack I am",
    "start": "42320",
    "end": "48719"
  },
  {
    "text": "the CEO and founder at prediction guard and I'm joined as always by my co-host",
    "start": "48719",
    "end": "54280"
  },
  {
    "text": "Chris Benson who is a tech strategist at locked Martin how you doing Chris doing great today was nice seeing you a few",
    "start": "54280",
    "end": "60960"
  },
  {
    "text": "days ago uh in person and In the Flesh in the flesh yeah that was great I think",
    "start": "60960",
    "end": "66280"
  },
  {
    "text": "you posted a picture on LinkedIn so uh if anybody doesn't know what we look like and and has some crazy reason to",
    "start": "66280",
    "end": "72479"
  },
  {
    "text": "want to know there's a smiling mug of us on Daniel's profile so yes yes and uh",
    "start": "72479",
    "end": "78880"
  },
  {
    "text": "what the reason we met is I was on a client visit on site and we were",
    "start": "78880",
    "end": "84720"
  },
  {
    "text": "prototyping out some stuff like chat over your docs and natural language to",
    "start": "84720",
    "end": "90079"
  },
  {
    "text": "sequel stuff and all sorts of things with prediction guard and one of the models that we were using was from new",
    "start": "90079",
    "end": "96640"
  },
  {
    "text": "research um and that works out great because we have curan multra here who is",
    "start": "96640",
    "end": "102720"
  },
  {
    "text": "from uh news research uh co-founder and researcher there so welcome glad to have",
    "start": "102720",
    "end": "108159"
  },
  {
    "text": "you Karan hey oh thanks for having me I'm I'm extremely excited to chat with you guys yeah like I said um I'm a huge",
    "start": "108159",
    "end": "116240"
  },
  {
    "text": "Well I this is our first time meeting but I feel like we're already friend because I've I've had so much of my own",
    "start": "116240",
    "end": "123360"
  },
  {
    "text": "benefit and interaction in working with models from new research a lot of amazing models that you've posted on",
    "start": "123360",
    "end": "130399"
  },
  {
    "text": "hugging face and research that you're doing I'm wondering if you could just give us a little bit of a background",
    "start": "130399",
    "end": "137080"
  },
  {
    "text": "about uh noose specifically and kind of how you came together as researchers and",
    "start": "137080",
    "end": "145080"
  },
  {
    "text": "started to me from the sidelines it seemed like oh all of a sudden there's these amazing models on hugging face and",
    "start": "145080",
    "end": "151280"
  },
  {
    "text": "I don't know who these people are these new research people but they're amazing um so give us a little bit of the",
    "start": "151280",
    "end": "156599"
  },
  {
    "text": "backstory there absolutely yeah um so just as a general overview We Are One",
    "start": "156599",
    "end": "162080"
  },
  {
    "text": "Part like open source research organization we put these models out for free we put a lot of research out for",
    "start": "162080",
    "end": "167519"
  },
  {
    "text": "free some data sets so people can build on top of these open models on the other hand we're very recently a company as",
    "start": "167519",
    "end": "175000"
  },
  {
    "text": "well a C Corp so we've uh been working pretty hard after getting some seed",
    "start": "175000",
    "end": "180280"
  },
  {
    "text": "funding on uh building together some some exciting stuff I I won't go too into on during the overview point but uh",
    "start": "180280",
    "end": "187400"
  },
  {
    "text": "we're continuing to do our open source research and development and release of models indefinitely the way we started",
    "start": "187400",
    "end": "194120"
  },
  {
    "text": "is very interesting and it would be pretty out of nowhere to to the outside for sure it was it was extremely fast",
    "start": "194120",
    "end": "200760"
  },
  {
    "text": "for us we are a collective of people who have been playing around in the open",
    "start": "200760",
    "end": "205920"
  },
  {
    "text": "source language model space for a while ranging from like GPT two release to llama release to like the first",
    "start": "205920",
    "end": "212720"
  },
  {
    "text": "Transformers paper we've got people from various eras of gen of when they came in",
    "start": "212720",
    "end": "218760"
  },
  {
    "text": "and for myself it was gpt2 uh I stumbled upon a collab notebook and uh started",
    "start": "218760",
    "end": "223920"
  },
  {
    "text": "fine-tuning made some Edgar Allen Poe and Lovecraft Tunes I've done the same that's awesome",
    "start": "223920",
    "end": "230239"
  },
  {
    "text": "and we just got pulled into this world of look at these next token predictors",
    "start": "230239",
    "end": "235920"
  },
  {
    "text": "that are just managing to smatter together the most wonderful and amazing stories that slowly turned into a deeper and",
    "start": "235920",
    "end": "242079"
  },
  {
    "text": "deeper dive of well how can I use this for learning information how can I learn",
    "start": "242079",
    "end": "247200"
  },
  {
    "text": "to use this for production and automation right it's evolved over time for us we started off just working with",
    "start": "247200",
    "end": "254720"
  },
  {
    "text": "different open source collectives actually once open AI kind of released gpt3 and had Clos sourced it you know we",
    "start": "254720",
    "end": "261919"
  },
  {
    "text": "were used to open source gpt2 we were like oh man what are we going to do like how are we going to continue to play with the level of customization and",
    "start": "261919",
    "end": "268360"
  },
  {
    "text": "interactivity that we had with gpt2 then Uther had released gptj 6B the Cobalt AI",
    "start": "268360",
    "end": "275880"
  },
  {
    "text": "Community this community of people who tune models and inference models started to pop up I think around 2020 uh 2021",
    "start": "275880",
    "end": "284360"
  },
  {
    "text": "with in the face of this so a lot of us started to have places to centralize and",
    "start": "284360",
    "end": "289479"
  },
  {
    "text": "play with these models we got to contribute and learn how to become better open source AI developers Etc",
    "start": "289479",
    "end": "297120"
  },
  {
    "text": "eventually there was a need for more concrete organizations to do this kind",
    "start": "297120",
    "end": "302880"
  },
  {
    "text": "of focused work on the the creation of these models we were stuck with like",
    "start": "302880",
    "end": "308360"
  },
  {
    "text": "okay architectures for a while like Pia but thanks to meta you know we wouldn't be here without meta I'll say that first",
    "start": "308360",
    "end": "315120"
  },
  {
    "text": "and foremost like the great llama yeah yeah like prior to llama right like everyone's like oh Facebook evil like my",
    "start": "315120",
    "end": "322280"
  },
  {
    "text": "data Etc and here we are like they are kind of like the Shepherds of this new",
    "start": "322280",
    "end": "327960"
  },
  {
    "text": "era of the open source AI movement so when llama came out there was a paper that came out called alpaca by Stanford",
    "start": "327960",
    "end": "335120"
  },
  {
    "text": "lab right and this was about distilling data from bigger models like gpt3 chat",
    "start": "335120",
    "end": "341240"
  },
  {
    "text": "GPT gp4 and being able to train smaller models on that distilled synthetic data",
    "start": "341240",
    "end": "348280"
  },
  {
    "text": "something they called instruction data so that alpaca format really opened up",
    "start": "348280",
    "end": "353400"
  },
  {
    "text": "the playing field for everybody to start making these instruct style models these actual four prod use sty styal models so",
    "start": "353400",
    "end": "361840"
  },
  {
    "text": "there was an idea I had in my head of well the alpaca guys are using only gbt 3.5 outputs what if I only generated gbt",
    "start": "361840",
    "end": "369720"
  },
  {
    "text": "4 outputs it'll be a little expensive but you'll probably get a better model out of it than alpaca at the same time",
    "start": "369720",
    "end": "376039"
  },
  {
    "text": "that I was looking at this there was a guy on Twitter named technium who had just started putting together his own",
    "start": "376039",
    "end": "382720"
  },
  {
    "text": "synthetic data set based off alpaca and the GPT 4 only as well so I was working",
    "start": "382720",
    "end": "388199"
  },
  {
    "text": "with a group at the time called open Assistant under lion their really big nonprofit and while I was working on",
    "start": "388199",
    "end": "395479"
  },
  {
    "text": "that we had some gpus they were cool with us using towards uh the development of new models so I reached out to",
    "start": "395479",
    "end": "402280"
  },
  {
    "text": "technium and I said hey I have a little bit of compute you have gp4 data in the same format I have gp4 data in the same",
    "start": "402280",
    "end": "408880"
  },
  {
    "text": "format let's train a model so we trained a model called gp4 X vicuna this model",
    "start": "408880",
    "end": "415599"
  },
  {
    "text": "was on the vicuna fine tune we fine tuned to fine tune basically the vuno model was a alpaca style fun and we",
    "start": "415599",
    "end": "422840"
  },
  {
    "text": "tried our data set on top of it it was good it was okay then we thought you know we'll probably get a better result",
    "start": "422840",
    "end": "428919"
  },
  {
    "text": "if we just train on the Bas llama model and the resulting model was the very",
    "start": "428919",
    "end": "434479"
  },
  {
    "text": "first Hermes model gotcha the OG the OG and and",
    "start": "434479",
    "end": "439919"
  },
  {
    "text": "that's kind of how it started to come together was uh we both had a data",
    "start": "439919",
    "end": "445240"
  },
  {
    "text": "thesis on use gbd4 only and follow alpaca and we trained on llama and we got Hermes and we didn't know what",
    "start": "445240",
    "end": "452319"
  },
  {
    "text": "benchmarks were we didn't know anything about any of this stuff we just made a model and it got a ton of attention we",
    "start": "452319",
    "end": "460039"
  },
  {
    "text": "put it out under this name noose research noose comes from the Greek word",
    "start": "460039",
    "end": "465479"
  },
  {
    "text": "for intellect we thought it' be good name for AI company uh but it was it was just a",
    "start": "465479",
    "end": "470960"
  },
  {
    "text": "place for you know fun projects and fine tunes and stuff it was just a name we were using for our collaboration and",
    "start": "470960",
    "end": "478000"
  },
  {
    "text": "people started swarming and asking you know what's news research like what's this sudden like mystical like uh open",
    "start": "478000",
    "end": "484280"
  },
  {
    "text": "source organization that like put out this like best model and we're like best model like we just you know we just",
    "start": "484280",
    "end": "490120"
  },
  {
    "text": "tried something it was it was really organic and it got to the point that people started telling us you know you",
    "start": "490120",
    "end": "495960"
  },
  {
    "text": "must have trained on the benchmarks like these are doing too well and we were like what's",
    "start": "495960",
    "end": "501199"
  },
  {
    "text": "benchmarks like we we're not really like uh coming from an academic place as much",
    "start": "501199",
    "end": "506360"
  },
  {
    "text": "as from like a Enthusiast that became so committed that it became our life right it became our day-to-day yeah so from",
    "start": "506360",
    "end": "513399"
  },
  {
    "text": "there uh people started to ask us can I join news research now there wasn't a",
    "start": "513399",
    "end": "518440"
  },
  {
    "text": "news research to join there just two guys right what ended up happening was we formed a private Discord server and",
    "start": "518440",
    "end": "525560"
  },
  {
    "text": "we thought there's a lot of people who range from somebody who's like 16 17",
    "start": "525560",
    "end": "531519"
  },
  {
    "text": "years old Savant on Twitter hasn't even been to college yet insane that Transformer stuff to uh mid-30s is you",
    "start": "531519",
    "end": "539800"
  },
  {
    "text": "know working a really really good fanges job and just wants to really create and",
    "start": "539800",
    "end": "545399"
  },
  {
    "text": "let loose that was another class of volunteer and then you have you know older gentleman who has already exited a",
    "start": "545399",
    "end": "552560"
  },
  {
    "text": "company or something who has just been playing with code for a while and wants to jump in and hang out so we ended up",
    "start": "552560",
    "end": "558040"
  },
  {
    "text": "being this really eclectic group you know we don't know what your name is we don't know what your race is we don't know your gender anything it's just",
    "start": "558040",
    "end": "563959"
  },
  {
    "text": "Discord profile picture Twitter profile picture right so we came together GRE to",
    "start": "563959",
    "end": "569800"
  },
  {
    "text": "about like 40 people all working together on various different projects like Hermes Tunes data synthesis the",
    "start": "569800",
    "end": "576480"
  },
  {
    "text": "cppy bar series context length extension Etc and just from this kind of",
    "start": "576480",
    "end": "581600"
  },
  {
    "text": "interaction between Twitter and Discord and bringing people in that we thought were cool we ended up becoming what",
    "start": "581600",
    "end": "587399"
  },
  {
    "text": "people will call Open Source research org yeah that you sort of stumbled into",
    "start": "587399",
    "end": "592800"
  },
  {
    "text": "creating this amazing uh research organization which is ruling the world",
    "start": "592800",
    "end": "598680"
  },
  {
    "text": "which is awesome it's what open AI might have been oh well yeah it's really sweet",
    "start": "598680",
    "end": "605880"
  },
  {
    "text": "thank you guys yeah and I I love it it's so cool to hear that story and that",
    "start": "605880",
    "end": "612200"
  },
  {
    "text": "background and I see like in my own sort of little snapshots here and there like",
    "start": "612200",
    "end": "617240"
  },
  {
    "text": "I'm connecting that in my mind over the the past couple years as I've as I've seen you all post different models and",
    "start": "617240",
    "end": "623399"
  },
  {
    "text": "that sort of thing this is something I you know we've definitely touched on on the show before but some of our",
    "start": "623399",
    "end": "628920"
  },
  {
    "text": "listeners ERS might not kind of fully grasp when you say the sort of like",
    "start": "628920",
    "end": "633959"
  },
  {
    "text": "synthetic data sets that you were focused on and in this um alpaca format",
    "start": "633959",
    "end": "639639"
  },
  {
    "text": "could you kind of explain a little bit like we've talked a lot about fine-tuning and you know preference",
    "start": "639639",
    "end": "644880"
  },
  {
    "text": "tuning and rhf and different things but what does it specifically mean that like you would take synthetic data what does",
    "start": "644880",
    "end": "652399"
  },
  {
    "text": "that mean in in your case and like why why does that result in something good",
    "start": "652399",
    "end": "658480"
  },
  {
    "text": "in in fine an open model people might think oh this is synthetic data why should I expect it to like be any good",
    "start": "658480",
    "end": "665440"
  },
  {
    "text": "so could you kind of help explain that subject a little bit yeah absolutely so",
    "start": "665440",
    "end": "671480"
  },
  {
    "text": "I mean out of context synthetic is like as meaningless as like artificial right it could data is data but in this case",
    "start": "671480",
    "end": "678200"
  },
  {
    "text": "it's referring to a particular class of data that's been generated by another language model or another AI another",
    "start": "678200",
    "end": "684639"
  },
  {
    "text": "diffusion model Etc that can actually be used to further train models now you might say why would you want to do",
    "start": "684639",
    "end": "690639"
  },
  {
    "text": "something like that how is it helpful what was important to us is we were all GPU poor right we were all running on",
    "start": "690639",
    "end": "696920"
  },
  {
    "text": "laptops or maybe a 3090 maybe a 4090 like as individuals we we don't have data centers so training or even tuning",
    "start": "696920",
    "end": "704720"
  },
  {
    "text": "like a large model in the early days like 70 billion parameters something like that was just unfeasible for us and",
    "start": "704720",
    "end": "710959"
  },
  {
    "text": "knowing that gbt 3 is like something like 175 billion parameters and 3.5 and",
    "start": "710959",
    "end": "716600"
  },
  {
    "text": "four can only go up from there the question became how can we make these small 7 billion parameter models even",
    "start": "716600",
    "end": "724560"
  },
  {
    "text": "compete with these massive massive ones these ones that I want to run offline these ones that I might want to run on",
    "start": "724560",
    "end": "730399"
  },
  {
    "text": "an edge device on a phone on a drone Etc right like how can I make them even useful so there's two things to talk",
    "start": "730399",
    "end": "737839"
  },
  {
    "text": "about here one is synthetic data and the other is distillation right so synthetic data is just referring to like any kind",
    "start": "737839",
    "end": "745079"
  },
  {
    "text": "of data that's created by a model in this case the reason that's useful is in",
    "start": "745079",
    "end": "751560"
  },
  {
    "text": "particular distillation so if I told you to go study comp ey for 10 years for",
    "start": "751560",
    "end": "759519"
  },
  {
    "text": "example and and put in that massive time investment and really focus on General programming and then I told you you know",
    "start": "759519",
    "end": "765680"
  },
  {
    "text": "now it's time for you to learn about Ai and Transformers and stuff and put you through all the math prerequisites Etc",
    "start": "765680",
    "end": "770760"
  },
  {
    "text": "like you're going to come out with like a really strong Foundation of how to do",
    "start": "770760",
    "end": "775920"
  },
  {
    "text": "the work but the problem is you've put in a massive time in investment now if I take that guy who spent 10 years doing",
    "start": "775920",
    "end": "782519"
  },
  {
    "text": "engineering then another five years doing Ai and I ask him hey can you teach somebody like just really important like",
    "start": "782519",
    "end": "790079"
  },
  {
    "text": "compressed tidbits that'll help them just get up and running to do the work that's data distillation right that's",
    "start": "790079",
    "end": "795880"
  },
  {
    "text": "knowledge distillation so you look at these big models like a Claude or a 70b",
    "start": "795880",
    "end": "801040"
  },
  {
    "text": "model or gb4 and you can see like they're amazing they're brilliant at everything they have a bunch of high",
    "start": "801040",
    "end": "806639"
  },
  {
    "text": "quality data they're trained on and they have a bunch of lowquality data they're trained on that they can interact with",
    "start": "806639",
    "end": "813959"
  },
  {
    "text": "and Express in a high quality form so instead of me having to read a massive",
    "start": "813959",
    "end": "819680"
  },
  {
    "text": "10 pager for why some chemical reaction or some like tax Bas process like",
    "start": "819680",
    "end": "825800"
  },
  {
    "text": "whatever you want it to be like instead of reading a massive document on that and then feeding that to a language model we can just have that really smart",
    "start": "825800",
    "end": "833199"
  },
  {
    "text": "model that already understands it really well compress that information into an instruction or into a conversation uh",
    "start": "833199",
    "end": "841079"
  },
  {
    "text": "into like two sentences three sentences five sentences like half a page and we",
    "start": "841079",
    "end": "846320"
  },
  {
    "text": "can just train a much smaller model on that compressed information and it will",
    "start": "846320",
    "end": "853079"
  },
  {
    "text": "learn the compressed information you know to the degree that a language model learns something you know not perfectly",
    "start": "853079",
    "end": "859120"
  },
  {
    "text": "but uh because of that what the alpaca guys did was they generated a bunch of seed tasks from gbt 3.5 on various",
    "start": "859120",
    "end": "867240"
  },
  {
    "text": "different domains and topics and create these kind of compressed instructions with instruction an input question from",
    "start": "867240",
    "end": "874000"
  },
  {
    "text": "the user and then an answer so the instruction could be like given the following math equation explain step by",
    "start": "874000",
    "end": "880680"
  },
  {
    "text": "step why this is the answer and then the input is the equation which is your your question and then the output is the",
    "start": "880680",
    "end": "887680"
  },
  {
    "text": "compressed answer so all of that we can take as one sample in the data set and",
    "start": "887680",
    "end": "892800"
  },
  {
    "text": "we can make hundreds of thousands or millions of samples like that of various different domains and various different",
    "start": "892800",
    "end": "898680"
  },
  {
    "text": "tasks so the alpaca guys did this less than 100K examples I believe and they",
    "start": "898680",
    "end": "903720"
  },
  {
    "text": "trained the Llama models on these and they found massive boosts to Performance",
    "start": "903720",
    "end": "909759"
  },
  {
    "text": "that this distilled information like a human successfully uh compresses and transfers over so when I saw that and",
    "start": "909759",
    "end": "916759"
  },
  {
    "text": "then independently when technium saw that and then independently when many others saw that we were like this is so",
    "start": "916759",
    "end": "922639"
  },
  {
    "text": "intuitive this is exactly how I've learned anything by just going on Discord and Twitter and bothering people",
    "start": "922639",
    "end": "928160"
  },
  {
    "text": "to give me the compress bit of how I do something we should try doing this with even higher quality models than 3.5 so",
    "start": "928160",
    "end": "935920"
  },
  {
    "text": "we created I can't remember the exact number at the moment but at least 50,000",
    "start": "935920",
    "end": "941759"
  },
  {
    "text": "maybe 100,000 examples originally for Hermes one like this just using gbd4 and",
    "start": "941759",
    "end": "947759"
  },
  {
    "text": "then uh we trained on that and ended up getting performance that was extremely",
    "start": "947759",
    "end": "953800"
  },
  {
    "text": "extremely like massive boost compared to the other models that were not trained using this kind of method so without",
    "start": "953800",
    "end": "961440"
  },
  {
    "text": "these Giants that have already established themselves in the space we wouldn't be here like without open AI",
    "start": "961440",
    "end": "967880"
  },
  {
    "text": "without meta like we literally wouldn't have the model and the data to do the kind of work that we did to make Hermes",
    "start": "967880",
    "end": "974519"
  },
  {
    "text": "what it allowed for us is like for local models to finally be like comprehensible",
    "start": "974519",
    "end": "980160"
  },
  {
    "text": "and for us to finally have like offline capabilities to kind of take the good stuff from something like gb4 or",
    "start": "980160",
    "end": "986639"
  },
  {
    "text": "something else and make it uncensored so it still has all this understanding of",
    "start": "986639",
    "end": "991720"
  },
  {
    "text": "all these topics but it doesn't have all that rhf inside it necessarily that safety ises it so that when people",
    "start": "991720",
    "end": "999519"
  },
  {
    "text": "utilize the model has all this intelligence but it's has more freedom of thought to kind of Converse with you on topics that open AI May reject gotcha",
    "start": "999519",
    "end": "1007600"
  },
  {
    "text": "one of the things I was curious about as you were going through that was a few episodes back Daniel and I were kind of talking about the effect of model",
    "start": "1007600",
    "end": "1014519"
  },
  {
    "text": "licensing you know on the community and the different kind of license concerns",
    "start": "1014519",
    "end": "1019600"
  },
  {
    "text": "that were coming out from whether it be you know meta open AI you name the organization is that ever a challenge",
    "start": "1019600",
    "end": "1025600"
  },
  {
    "text": "for you since you're kind of using those to get started in terms of the inputs has that been a concern or or do you",
    "start": "1025600",
    "end": "1031520"
  },
  {
    "text": "anticipate it being a concern I think that of course like generally like us",
    "start": "1031520",
    "end": "1036640"
  },
  {
    "text": "International regulation on this stuff is evolving the conversation is evolving very much so naturally there is like you",
    "start": "1036640",
    "end": "1044000"
  },
  {
    "text": "have to keep it top of mind you have to think about these kind of things but thankfully because all of our model releases are like open- source and we",
    "start": "1044000",
    "end": "1050960"
  },
  {
    "text": "don't profit from them like if somebody goes off and creates a product using our model you know good for them but we",
    "start": "1050960",
    "end": "1057600"
  },
  {
    "text": "don't necessarily take on that liability or that worry of saying hey like we're",
    "start": "1057600",
    "end": "1063600"
  },
  {
    "text": "going to sell you this model that was created with gb4 outputs we we actually actively try to stay away from doing",
    "start": "1063600",
    "end": "1069720"
  },
  {
    "text": "that but because the data distillation Paradigm is so effective you know if a model comes out that's better than gp4",
    "start": "1069720",
    "end": "1076440"
  },
  {
    "text": "and it's open source and I can can use it locally and in their to it says you",
    "start": "1076440",
    "end": "1081600"
  },
  {
    "text": "know you can use this to make a commercial model then we can apply the same techniques that we've been preparing and researching and",
    "start": "1081600",
    "end": "1087360"
  },
  {
    "text": "understanding from these close models and use it there so right now like we don't stand to or try to or have any",
    "start": "1087360",
    "end": "1095400"
  },
  {
    "text": "plans to profit from using any of these outputs we're not about that because we",
    "start": "1095400",
    "end": "1100640"
  },
  {
    "text": "want to be careful and respectful of these model creators but that and these companies but that being said we're",
    "start": "1100640",
    "end": "1106679"
  },
  {
    "text": "learning all these techniques and developing all these techniques that will be useful for when that time comes",
    "start": "1106679",
    "end": "1111880"
  },
  {
    "text": "and for when that's available especially with the Advent of something like mistol uh if we do distillation from a mistro",
    "start": "1111880",
    "end": "1118159"
  },
  {
    "text": "model like mistal medium or something like that that's completely from my understanding you know barring their to",
    "start": "1118159",
    "end": "1124120"
  },
  {
    "text": "saying otherwise but I believe it it doesn't uh it's completely okay in that situation for us to create models like",
    "start": "1124120",
    "end": "1131640"
  },
  {
    "text": "this that can be used commercially Etc regarding the to stuff though like as",
    "start": "1131640",
    "end": "1137320"
  },
  {
    "text": "much as we air on the side of caution I'd find it hard to see a company",
    "start": "1137320",
    "end": "1143520"
  },
  {
    "text": "enforce their to when these larger models are likely trained",
    "start": "1143520",
    "end": "1150360"
  },
  {
    "text": "on not all copyright free stuff like I'd find it hard pressed to believe that",
    "start": "1150360",
    "end": "1156440"
  },
  {
    "text": "these closed Source companies their models are you know totally copyright free and totally copyright clean so if",
    "start": "1156440",
    "end": "1164320"
  },
  {
    "text": "some other company that was feeling a little more rambunctious than ourselves was to say you know we are going to",
    "start": "1164320",
    "end": "1170080"
  },
  {
    "text": "commercially release on this I imagine it'd be difficult for them to become",
    "start": "1170080",
    "end": "1175679"
  },
  {
    "text": "after without the other group opening their books and there's actually a pretty interesting interaction that",
    "start": "1175679",
    "end": "1181039"
  },
  {
    "text": "happened regarding this between Google and uh open AI if you guys are familiar so yeah I saw this U",
    "start": "1181039",
    "end": "1188640"
  },
  {
    "text": "interesting picture the other day it was like the interesting web of AI and it was like how Microsoft Google open AI",
    "start": "1188640",
    "end": "1197120"
  },
  {
    "text": "like it's like on one side there's the ones and it shows how they're connected to the other ones is like this visualization and like how many of them",
    "start": "1197120",
    "end": "1204640"
  },
  {
    "text": "overlap in these strange ways between like whether it's uh together or mistol",
    "start": "1204640",
    "end": "1210679"
  },
  {
    "text": "or meta Google Microsoft open AI is sort of very interesting web of connections",
    "start": "1210679",
    "end": "1218280"
  },
  {
    "text": "that that probably Mak some of these things rather difficult leave it for the lawyers to sort out yeah yeah that's the",
    "start": "1218280",
    "end": "1224600"
  },
  {
    "text": "thing is like we can look at an example right like you hear that phrase like good artist copy great artist steal",
    "start": "1224600",
    "end": "1229880"
  },
  {
    "text": "right like so the data distillers we're copying right like we're just distilling this information like we're trying to",
    "start": "1229880",
    "end": "1236280"
  },
  {
    "text": "like make our models more like those and we don't really plan to commercialize we're just doing it for free for",
    "start": "1236280",
    "end": "1241360"
  },
  {
    "text": "everyone but the great artists are you know Google you know like you look at Bard and it tells you you know I was",
    "start": "1241360",
    "end": "1248280"
  },
  {
    "text": "made by open AI now it's fine for our open source model to say I was made by open a because we're very transparent about this is trained on gbt outputs but",
    "start": "1248280",
    "end": "1255240"
  },
  {
    "text": "when Bard violates the to with a paid product yeah bold yeah that says like I",
    "start": "1255240",
    "end": "1261280"
  },
  {
    "text": "was trained by open AI right You' think that open AI would come after this multi-billion dollar company like",
    "start": "1261280",
    "end": "1267400"
  },
  {
    "text": "immediately right instead you see a tweet from first you see Google deny it",
    "start": "1267400",
    "end": "1272840"
  },
  {
    "text": "then you see a tweet from Sam Alman which was something along the lines of I'm paraphrasing here something along",
    "start": "1272840",
    "end": "1278200"
  },
  {
    "text": "the lines of I'm not mad that they trained on our outputs I'm mad that they lied about it and I'm sitting there like",
    "start": "1278200",
    "end": "1286080"
  },
  {
    "text": "okay you're mad about this but like don't you aren't you going to pursue the legal action in your terms of services",
    "start": "1286080",
    "end": "1291960"
  },
  {
    "text": "no no because everyone would have to open their books up too that being said",
    "start": "1291960",
    "end": "1297039"
  },
  {
    "text": "I don't condone the commercial use of that kind of stuff like the release like making a paid model from gbd4 outputs",
    "start": "1297039",
    "end": "1304159"
  },
  {
    "text": "like I wouldn't advise anyone sell a model made with them just because like you know we want to respect people like",
    "start": "1304159",
    "end": "1310600"
  },
  {
    "text": "to and stuff they worked hard and spent billions to make this stuff or hundreds of millions however much they spent but",
    "start": "1310600",
    "end": "1317360"
  },
  {
    "text": "there is certainly room for hypocrisy in the in that Realm of the large corpse",
    "start": "1317360",
    "end": "1324039"
  },
  {
    "text": "but that's my thoughts on on the licensing stuff and that's definitely my own individual thoughts like we're a",
    "start": "1324039",
    "end": "1330799"
  },
  {
    "text": "pretty decentralized Collective at news so you'll find people with all sorts of opinions all over the place and as a",
    "start": "1330799",
    "end": "1337520"
  },
  {
    "text": "company we don't hold any view whatsoever on that yeah um I'm wondering",
    "start": "1337520",
    "end": "1343200"
  },
  {
    "text": "maybe this gets a little bit to the distributed nature of this but I I know that there's sort of various collection",
    "start": "1343200",
    "end": "1348760"
  },
  {
    "text": "s of what the news research group has done over time you mentioned Hermes but",
    "start": "1348760",
    "end": "1354760"
  },
  {
    "text": "then there's there's these other kind of categories of things too like the yarn models capy Bara puffen obsidian just",
    "start": "1354760",
    "end": "1362799"
  },
  {
    "text": "looking over the hugging face now I'm wondering if you could just give us like from your perspective a little bit of a",
    "start": "1362799",
    "end": "1369919"
  },
  {
    "text": "map of these different things and like how people might categorize the different collections of what noose has",
    "start": "1369919",
    "end": "1376600"
  },
  {
    "text": "done I definitely want to talk about like the future things and ongoing things as well but as it stands now what",
    "start": "1376600",
    "end": "1382799"
  },
  {
    "text": "are the kind of major categories of what the collective has invested in over",
    "start": "1382799",
    "end": "1389159"
  },
  {
    "text": "their time in over time certainly certainly so uh within the stuff that's viewable on hugging face at least we've",
    "start": "1389159",
    "end": "1395880"
  },
  {
    "text": "got the Hermes series of which like I I told you guys the initial story of how it went down but uh from there technium",
    "start": "1395880",
    "end": "1402720"
  },
  {
    "text": "kept going I haven't personally had any interaction with the Hermes model since the initial from there Tech just",
    "start": "1402720",
    "end": "1409720"
  },
  {
    "text": "continued to create more and more synthetic data collect from more and more sources use more and more open data",
    "start": "1409720",
    "end": "1415440"
  },
  {
    "text": "sets and he's just got the I guess award-winning like data thesis he the guy really knows how to go about uh",
    "start": "1415440",
    "end": "1422039"
  },
  {
    "text": "curating and synthesizing good data so technium it's his baby the Hermes",
    "start": "1422039",
    "end": "1427919"
  },
  {
    "text": "project so everything you've seen since is really his work and anyone who has kind of collaborated with him but almost",
    "start": "1427919",
    "end": "1434080"
  },
  {
    "text": "like it's you can't call it anything a solo project because of the open data sets we use too like like everything is",
    "start": "1434080",
    "end": "1439520"
  },
  {
    "text": "built on the shoulders of giants and the shoulders of each other as little people but uh Tech really has helmed the Hermes",
    "start": "1439520",
    "end": "1446039"
  },
  {
    "text": "initiative so far I think that's our most popular model series and he released the open Hermes as well because",
    "start": "1446039",
    "end": "1452440"
  },
  {
    "text": "we had some data in the original Hermes that we never released publicly and uh we wanted to make that kind of an option",
    "start": "1452440",
    "end": "1458919"
  },
  {
    "text": "for everybody so that's Hermes still follows the same kind of philosophy of",
    "start": "1458919",
    "end": "1464120"
  },
  {
    "text": "synthetic data and it now uses the chat ml format instead of the outpa format is what we kind of upgraded to then you've",
    "start": "1464120",
    "end": "1471559"
  },
  {
    "text": "got uh Kappy Bara and Puffin which are both done by a volunteer and uh you know",
    "start": "1471559",
    "end": "1476600"
  },
  {
    "text": "OG member ldj who you may be familiar with Luigi Danielle Jr so the kibara",
    "start": "1476600",
    "end": "1483080"
  },
  {
    "text": "series was uh using an amplify instruct method this novel method that uh ldj had",
    "start": "1483080",
    "end": "1489279"
  },
  {
    "text": "worked on alongside another one of our researchers Jay so ldj and Jay can get",
    "start": "1489279",
    "end": "1494360"
  },
  {
    "text": "confusing but uh the two of them worked on the copy bar series created the data set trained the models and then Puffin",
    "start": "1494360",
    "end": "1501600"
  },
  {
    "text": "was uh the idea of using handpicked smaller samples from some of our larger",
    "start": "1501600",
    "end": "1506840"
  },
  {
    "text": "data sets to make Sleek data sets for an easy tune and see how that works kind of",
    "start": "1506840",
    "end": "1512399"
  },
  {
    "text": "uh in the spirit of the Lima paper where they just used a few examples to get really good results those are really the",
    "start": "1512399",
    "end": "1519480"
  },
  {
    "text": "popular Tunes using synthetic data for like General use yarn is this novel",
    "start": "1519480",
    "end": "1525799"
  },
  {
    "text": "context length extension method at the time of creating by IM Mozilla also known as Jeffrey canel and Bowen Pang",
    "start": "1525799",
    "end": "1533360"
  },
  {
    "text": "also known as block 97 alongside uh enrio Chipotle and a Luther AI so what",
    "start": "1533360",
    "end": "1541159"
  },
  {
    "text": "happened there was these guys were already looking into Contex like the extension for a while and uh when we",
    "start": "1541159",
    "end": "1546880"
  },
  {
    "text": "kind of came under the news Banner to do the work uh it opened up a little bit of resources from compute sponsorships it",
    "start": "1546880",
    "end": "1554200"
  },
  {
    "text": "opened up a more centralized place for them to be able to do that collaboration",
    "start": "1554200",
    "end": "1559600"
  },
  {
    "text": "I had no hand in in uh the yarn models whatsoever and that's the exciting thing",
    "start": "1559600",
    "end": "1565159"
  },
  {
    "text": "is everyone really gets to work in their own spheres in their own kind of autonomous circles and then we just",
    "start": "1565159",
    "end": "1570919"
  },
  {
    "text": "check in and see you know how's the research going how's it coming along because we really work with people that",
    "start": "1570919",
    "end": "1575960"
  },
  {
    "text": "we heavily believe in and we believe in their idea so if we don't already have an idea we kind of just say you know",
    "start": "1575960",
    "end": "1582480"
  },
  {
    "text": "please freely create because we brought you in because what you will freely create will push forth our agenda anyway",
    "start": "1582480",
    "end": "1589840"
  },
  {
    "text": "so I think those are our big model releases and series that we have available outside of that we have a",
    "start": "1589840",
    "end": "1595919"
  },
  {
    "text": "bunch of stuff on our GitHub as well stuff that's being worked on stuff that",
    "start": "1595919",
    "end": "1601000"
  },
  {
    "text": "hasn't necessarily come out yet there's a lot of that so I got a question for you is a",
    "start": "1601000",
    "end": "1606559"
  },
  {
    "text": "followup it's pretty fascinating the story that you've been telling us here because of that kind of organic you know",
    "start": "1606559",
    "end": "1612880"
  },
  {
    "text": "creation of the organization or Collective and I'm wondering as you've done that and you kind of went through",
    "start": "1612880",
    "end": "1618720"
  },
  {
    "text": "and talked about the different model groups and kind of talked about you know the owners or spiritual owners if you",
    "start": "1618720",
    "end": "1623960"
  },
  {
    "text": "will of each of those families how do the different members of the collective interact to kind of share like how do",
    "start": "1623960",
    "end": "1630880"
  },
  {
    "text": "you each push each other along or share information or give ideas so that cross",
    "start": "1630880",
    "end": "1636840"
  },
  {
    "text": "family efforts can kind of benefit from the overall Collective and as you said",
    "start": "1636840",
    "end": "1642200"
  },
  {
    "text": "now a C Corp and you guys are more organized at this point so what kind of culture is developed around those",
    "start": "1642200",
    "end": "1648159"
  },
  {
    "text": "Communications and learnings yeah absolutely I mean when it started it was just like a small Discord maybe like 10",
    "start": "1648159",
    "end": "1654480"
  },
  {
    "text": "people from there like we kind of created more channels as people wanted to work on more things and we had",
    "start": "1654480",
    "end": "1660440"
  },
  {
    "text": "initially split up into like three four different topics or sectors that people could assign themselves to one being",
    "start": "1660440",
    "end": "1667760"
  },
  {
    "text": "data synthesis of course so we can kind of find new novel methods and formats for distillation and the creation of",
    "start": "1667760",
    "end": "1673320"
  },
  {
    "text": "synthetic data one being training like people who are just like really good at training hyber pram stuff and people who",
    "start": "1673320",
    "end": "1680799"
  },
  {
    "text": "will come up with new architectures and new techniques another being agents a group of people who want to actually try",
    "start": "1680799",
    "end": "1686519"
  },
  {
    "text": "to build tools and do autonomous work with this stuff and then we had this one category that it was a prediction for",
    "start": "1686519",
    "end": "1692880"
  },
  {
    "text": "the future of simulation so we had people that were very interested in kind of bringing this stuff into simulation",
    "start": "1692880",
    "end": "1698600"
  },
  {
    "text": "into Unity into kind of seeing how all these things came together and it was interesting because the training built",
    "start": "1698600",
    "end": "1704960"
  },
  {
    "text": "on the data synthesis the agents build on the training and then the Sim would build on the agents was kind of the idea",
    "start": "1704960",
    "end": "1710960"
  },
  {
    "text": "so everybody needed to work together because all those things are so intrinsically connected but people would",
    "start": "1710960",
    "end": "1716320"
  },
  {
    "text": "have specializations on kind of where in that workflow they wanted to work we didn't end up doing a lot on the Sim",
    "start": "1716320",
    "end": "1722240"
  },
  {
    "text": "side of things now recently there's a lot more interest uh because we have a lot more you know capability generally",
    "start": "1722240",
    "end": "1728399"
  },
  {
    "text": "as the AI Community does you know but as we've grown to we went to 40 people it",
    "start": "1728399",
    "end": "1734320"
  },
  {
    "text": "was fine now we've gone to like 5,000 people in the Discord it's a little unwieldy there so uh what we do is we",
    "start": "1734320",
    "end": "1742159"
  },
  {
    "text": "kind of tear people in you come into the Discord you can see maybe two channels and then we give people a developer role",
    "start": "1742159",
    "end": "1748760"
  },
  {
    "text": "but we don't really let people select their own roles because we want to make sure we can kind of sort through people we know to kind of let them through and",
    "start": "1748760",
    "end": "1756159"
  },
  {
    "text": "even as we do open source research a lot of it is unreleased and we want to make sure that it's kind of protected before",
    "start": "1756159",
    "end": "1762640"
  },
  {
    "text": "release uh so we create this developer role so people can then see like way more channels of just general",
    "start": "1762640",
    "end": "1769279"
  },
  {
    "text": "development and development conversation and from there as we see you know contributors who have started to do more",
    "start": "1769279",
    "end": "1776880"
  },
  {
    "text": "work or show more passion towards contributing to news in a particular field or who have some reputation or",
    "start": "1776880",
    "end": "1782480"
  },
  {
    "text": "some portfolio in a particular field then we'll assign them one of those roles and that will open up the family",
    "start": "1782480",
    "end": "1789000"
  },
  {
    "text": "of channels relating to those roles and our current projects surrounding that role so like data synthesis projects",
    "start": "1789000",
    "end": "1795159"
  },
  {
    "text": "agent projects training projects Etc so we kind of just tear it out so people can interact and people who have been",
    "start": "1795159",
    "end": "1801640"
  },
  {
    "text": "around for a while or people we consider fellows or part of the cohort they can usually see pretty much everything so",
    "start": "1801640",
    "end": "1808000"
  },
  {
    "text": "they're pretty effective and serving as coordinators for the cross communication between these different channels and",
    "start": "1808000",
    "end": "1814720"
  },
  {
    "text": "groups and even if something has like a particular uh someone has a particular role or some channel has a particular",
    "start": "1814720",
    "end": "1821080"
  },
  {
    "text": "role it's supposed to be a part of like it's still Discord and we're still very chill so like people will still work on",
    "start": "1821080",
    "end": "1828440"
  },
  {
    "text": "like various different overlaps inside of just one channel as [Music]",
    "start": "1828440",
    "end": "1838460"
  },
  {
    "text": "well if you're listening you know that artificial intelligence is revolutionizing the way we produce",
    "start": "1842880",
    "end": "1849240"
  },
  {
    "text": "information changing Society culture Politics the economy but it's also",
    "start": "1849240",
    "end": "1854679"
  },
  {
    "text": "created a world of AI generated content in including deep fakes so how can we",
    "start": "1854679",
    "end": "1859760"
  },
  {
    "text": "tell what's real online read write own building the next era of the internet a",
    "start": "1859760",
    "end": "1865440"
  },
  {
    "text": "new book from entrepreneur and investor Chris Dixon explores one possible solution to the internet's authenticity",
    "start": "1865440",
    "end": "1872399"
  },
  {
    "text": "problem blockchains from AI that tracks its source material to generative programs that compensate rather than",
    "start": "1872399",
    "end": "1879120"
  },
  {
    "text": "cannibalize creators read write own is a call to action for a more open",
    "start": "1879120",
    "end": "1884399"
  },
  {
    "text": "transparent and Democratic internet one that opens the black box of AI tracks the origins we see online and much more",
    "start": "1884399",
    "end": "1892240"
  },
  {
    "text": "this is our chance to reimagine world changing Technologies to build the internet we want not the one we",
    "start": "1892240",
    "end": "1898279"
  },
  {
    "text": "inherited order your copy of read WR own today or go to read write own.com to",
    "start": "1898279",
    "end": "1904960"
  },
  {
    "text": "learn [Music]",
    "start": "1904960",
    "end": "1915220"
  },
  {
    "text": "more hi have a uh selfish question which now that this is one of the advantages",
    "start": "1916639",
    "end": "1922799"
  },
  {
    "text": "of doing the podcast they get to talk to all the amazing people doing amazing things and learn from them but I'm",
    "start": "1922799",
    "end": "1929039"
  },
  {
    "text": "wondering as a person who is also trying to fine-tune some models either just for",
    "start": "1929039",
    "end": "1934919"
  },
  {
    "text": "my own enjoyment and and learning but also fine-tuning models for specific",
    "start": "1934919",
    "end": "1940039"
  },
  {
    "text": "tasks and in uh specific uh customer use cases and that sort of thing there's a",
    "start": "1940039",
    "end": "1946039"
  },
  {
    "text": "lot of people out there I think many of our list ERS who are thinking like since you being part of this Collective have",
    "start": "1946039",
    "end": "1951960"
  },
  {
    "text": "worked for you know since the sort of dawn of of these many you know the",
    "start": "1951960",
    "end": "1957760"
  },
  {
    "text": "proliferation of fine tunes from llama and Etc and as you've seen all that as",
    "start": "1957760",
    "end": "1962840"
  },
  {
    "text": "you're doing more and more fine tunes now as you're looking towards the future do you have any kind of good advice or",
    "start": "1962840",
    "end": "1970480"
  },
  {
    "text": "things to keep in mind for all those like fine tuners out there that are thinking about grabbing something off of",
    "start": "1970480",
    "end": "1977480"
  },
  {
    "text": "hugging face creating their own versions of these models maybe they have their own ideas about a specific take on on a",
    "start": "1977480",
    "end": "1985360"
  },
  {
    "text": "Model um any general tips that you found to be really useful over time or like",
    "start": "1985360",
    "end": "1991559"
  },
  {
    "text": "pitfalls that you'd like to highlight yeah I mean I can I can try to think of a few off the top of head I'll say that",
    "start": "1991559",
    "end": "1998240"
  },
  {
    "text": "hyper parameters are really important and uh it's important to try to get that right it's going to vary from model to",
    "start": "1998240",
    "end": "2004360"
  },
  {
    "text": "model but a lot of the time some people think hyper pams like don't matter as much uh to like obsess over and some",
    "start": "2004360",
    "end": "2011200"
  },
  {
    "text": "people think it's like a secret sauce as well so I'd say like try to do a lot of research into like good hyper prams like",
    "start": "2011200",
    "end": "2018320"
  },
  {
    "text": "good learning rate like I'd also say like I could be totally wrong about this as I am not the trainer of Hermes today",
    "start": "2018320",
    "end": "2025760"
  },
  {
    "text": "or a lot of these models but something I personally believe in a lot is like ignore like people telling you to only",
    "start": "2025760",
    "end": "2031399"
  },
  {
    "text": "train for like x amount of time like if you're not overfitting like just keep going like if you can if you have the",
    "start": "2031399",
    "end": "2037200"
  },
  {
    "text": "compute like keep training and keep going like train for more tokens more Epoch like that's something I I heavily",
    "start": "2037200",
    "end": "2043200"
  },
  {
    "text": "believe in uh in terms of trainers to use there's a lot of people who make their own scripts for specialty stuff",
    "start": "2043200",
    "end": "2050040"
  },
  {
    "text": "and there's of course like you know you can just use hugging face but the library we use is called axolot axo l o",
    "start": "2050040",
    "end": "2058280"
  },
  {
    "text": "TL like the animal uh by Casias uh Wing Leon of the Open Access Collective we",
    "start": "2058280",
    "end": "2064398"
  },
  {
    "text": "think Axel is probably the best general purpose trainer for for luras Q lauras fine tunes Etc it like any open- Source",
    "start": "2064399",
    "end": "2072599"
  },
  {
    "text": "repository is buggy and stuff you're going to have to work out but it's in my",
    "start": "2072599",
    "end": "2077638"
  },
  {
    "text": "opinion probably the easiest and most effective trainer to use for like pretty much any model architecture available",
    "start": "2077639",
    "end": "2084440"
  },
  {
    "text": "right now so I definitely Point everybody towards Axel awesome yeah that's super useful we'll share some",
    "start": "2084440",
    "end": "2090878"
  },
  {
    "text": "links in uh in our show notes as well so people make sure and check that stuff",
    "start": "2090879",
    "end": "2096118"
  },
  {
    "text": "out another kind of interesting question um as you see you know I think we saw",
    "start": "2096119",
    "end": "2102760"
  },
  {
    "text": "these waves of of models that came out maybe around uh synthetic data fine",
    "start": "2102760",
    "end": "2108480"
  },
  {
    "text": "tunes or or other types of fine tunes I see this like interesting sort of thing",
    "start": "2108480",
    "end": "2114599"
  },
  {
    "text": "happening over the past however many months you know not that long in the scheme of things but in the AI World",
    "start": "2114599",
    "end": "2121320"
  },
  {
    "text": "maybe a while where we're kind of now like there's a lot of interesting approaches more so than just fine but",
    "start": "2121320",
    "end": "2128160"
  },
  {
    "text": "like mixture of experts and merging and of course multimodal stuff coming out now I see news kind of dabbling in that",
    "start": "2128160",
    "end": "2136160"
  },
  {
    "text": "you don't have to answer for the whole Collective but as there's so many of these things coming out and different",
    "start": "2136160",
    "end": "2141320"
  },
  {
    "text": "approaches what are some of the things within that doesn't have to be one of",
    "start": "2141320",
    "end": "2146680"
  },
  {
    "text": "those but what are some of the things on on your mind kind of moving forward uh or on uh n's mind kind of more generally",
    "start": "2146680",
    "end": "2154440"
  },
  {
    "text": "sure um I'll try to go from like simple to complex on the kind of stuff that",
    "start": "2154440",
    "end": "2159920"
  },
  {
    "text": "sounds great I think that definitely just like straight up instruction tuning is great there's other ways to tune like",
    "start": "2159920",
    "end": "2166920"
  },
  {
    "text": "the Evol instruct method I would advise people to try to create new instruction methodologies that allow us to make even",
    "start": "2166920",
    "end": "2173640"
  },
  {
    "text": "better formatted data people don't spend enough time trying to create new instruct formats uh and we've definitely",
    "start": "2173640",
    "end": "2180440"
  },
  {
    "text": "been swamped with not doing that as well so I think towards the general Community it's a really easy place to get started",
    "start": "2180440",
    "end": "2187200"
  },
  {
    "text": "you don't need to really know how to code so much as think about how a human might more effectively phrase something",
    "start": "2187200",
    "end": "2192839"
  },
  {
    "text": "or format something and kind of remix from there I think that's like probably the easiest place to start then there's",
    "start": "2192839",
    "end": "2199079"
  },
  {
    "text": "a model merging right model merging is great you can just like take two models and Frankenstein them together to",
    "start": "2199079",
    "end": "2204960"
  },
  {
    "text": "question mark results you know you got to just try and see what happens and and feel it out then from there I would say",
    "start": "2204960",
    "end": "2212480"
  },
  {
    "text": "there's stuff like DPO there's rhf DPO like this kind of r WS things that can",
    "start": "2212480",
    "end": "2218720"
  },
  {
    "text": "let you like enable rejections or create censorship or put some kind of General",
    "start": "2218720",
    "end": "2224880"
  },
  {
    "text": "concept or attitude towards the model uh we found that to be pretty effective with the latest news Hermes mixol DPO it",
    "start": "2224880",
    "end": "2232240"
  },
  {
    "text": "seems like people really like it and prefer it over just the sft so that's",
    "start": "2232240",
    "end": "2237440"
  },
  {
    "text": "another thing that I'd heavily recommend from there we get a little more complex",
    "start": "2237440",
    "end": "2242960"
  },
  {
    "text": "we have some reward model stuff we're working on that I won't speak to just yet outside of saying we're working on it that we think is going to be like",
    "start": "2242960",
    "end": "2249359"
  },
  {
    "text": "pretty big for reasoning boosts of course there's techniques like Chain of Thought and tree of thought for like",
    "start": "2249359",
    "end": "2254720"
  },
  {
    "text": "multi-step prompting creating data sets even out of that for any of these",
    "start": "2254720",
    "end": "2260359"
  },
  {
    "text": "purposes I've already mentioned is going to be really effective now to stuff that",
    "start": "2260359",
    "end": "2265520"
  },
  {
    "text": "maybe not everybody can actually a lot of people would already be able to do this there's like something that we like to call over at new activations hacking",
    "start": "2265520",
    "end": "2273359"
  },
  {
    "text": "where you're kind of uh messing with the way that a model I'm trying to think",
    "start": "2273359",
    "end": "2278400"
  },
  {
    "text": "about how to say this in like the most layman's terms like you're trying to mess with how a model like generally",
    "start": "2278400",
    "end": "2283560"
  },
  {
    "text": "Vibes about something so rather than just doing a system prompt or something like that you",
    "start": "2283560",
    "end": "2289319"
  },
  {
    "text": "can actually like change the the model vectors to kind of be like more political about something less political",
    "start": "2289319",
    "end": "2294880"
  },
  {
    "text": "about something more tur more specific and it has far more effect and control",
    "start": "2294880",
    "end": "2300599"
  },
  {
    "text": "over a model than a system prompt it's basically like a system prompt that like tells it to embody certain characteristics but it's not something",
    "start": "2300599",
    "end": "2307240"
  },
  {
    "text": "you can really uh jailbreak or get around as far as my testing is shown",
    "start": "2307240",
    "end": "2312480"
  },
  {
    "text": "certainly not as easily as a system prompt like we have no problem jailbreaking even the most censored",
    "start": "2312480",
    "end": "2318319"
  },
  {
    "text": "closed models today like it can be done by anybody with the right words right but um this activation stuff it really",
    "start": "2318319",
    "end": "2325319"
  },
  {
    "text": "creates a bit more of a robustness and Fidelity to the concepts that you're trying to tell it to embody there's a",
    "start": "2325319",
    "end": "2331640"
  },
  {
    "text": "few more I'm trying to think of that would be useful for people uh one thing is soft prompting it's not really around",
    "start": "2331640",
    "end": "2338680"
  },
  {
    "text": "anymore it used to be pretty big during the gpj like pre- llama days and the Cobalt AI guys really pioneered the use",
    "start": "2338680",
    "end": "2345680"
  },
  {
    "text": "of it in the open source Community but a soft prompt basically takes like massive prompt and and compresses it down to",
    "start": "2345680",
    "end": "2352880"
  },
  {
    "text": "like way less tokens so you can give your model like a huge prompt like huge system prompt or huge amount of",
    "start": "2352880",
    "end": "2359200"
  },
  {
    "text": "information and use like way less tokens so soft prompting is cool it's not going",
    "start": "2359200",
    "end": "2364359"
  },
  {
    "text": "to be too difficult to like update it for like llama mistro like today's architectures it's just like nobody has",
    "start": "2364359",
    "end": "2370880"
  },
  {
    "text": "really done it that I've seen so you know to the community if you guys do that please",
    "start": "2370880",
    "end": "2377599"
  },
  {
    "text": "share um that's actually much easier than the activation stuff I think and then finally probably the hardest",
    "start": "2377599",
    "end": "2384480"
  },
  {
    "text": "unsolved is like uh sampling methods like today we use like top K top P like",
    "start": "2384480",
    "end": "2391520"
  },
  {
    "text": "you know nucleus sampling Etc whatever like there's better ways to pick tokens",
    "start": "2391520",
    "end": "2396599"
  },
  {
    "text": "for sure there's better ways to judge the value of tokens for sure and everyone has been too kind of concerned",
    "start": "2396599",
    "end": "2403119"
  },
  {
    "text": "with higher levels to get that low and do whatever the magic math is that I can't do that would uh you know enable",
    "start": "2403119",
    "end": "2410440"
  },
  {
    "text": "some steering and some uh even Beyond steering like alternative sampling",
    "start": "2410440",
    "end": "2416560"
  },
  {
    "text": "paradigms and I think that would probably bring the biggest change in transformation to literally all models",
    "start": "2416560",
    "end": "2423920"
  },
  {
    "text": "regardless of the tune regardless of the architecture Etc get pulled off so really looking forward",
    "start": "2423920",
    "end": "2430000"
  },
  {
    "text": "to something like that happening in the space that was a lot of really good advice that you have there I was sitting",
    "start": "2430000",
    "end": "2435440"
  },
  {
    "text": "there trying to take notes while while you're were talking through it and everything going wait but he said that",
    "start": "2435440",
    "end": "2440480"
  },
  {
    "text": "too and he said that too a really good answer there um thank you for that as we",
    "start": "2440480",
    "end": "2445599"
  },
  {
    "text": "are starting to wind up here uh wanted to ask you I know about as we're recording this is looks like it was just",
    "start": "2445599",
    "end": "2451920"
  },
  {
    "text": "over three weeks ago about four weeks ago when we release uh this episode you guys announced uh your $5.2 million seed",
    "start": "2451920",
    "end": "2460680"
  },
  {
    "text": "financing round so congratulations on that that was pretty amazing thank you",
    "start": "2460680",
    "end": "2466040"
  },
  {
    "text": "and I'm kind of wondering so like you've kind of started with this kind of fairy tale story of kind of organically",
    "start": "2466040",
    "end": "2472200"
  },
  {
    "text": "building from the ground up you know yourself you connect with somebody else a few other people join you get to",
    "start": "2472200",
    "end": "2478040"
  },
  {
    "text": "thousands of people contributing you Fin and and really producing amazing work",
    "start": "2478040",
    "end": "2484800"
  },
  {
    "text": "and then uh you're incorporating and now got the seed round coming where does",
    "start": "2484800",
    "end": "2490079"
  },
  {
    "text": "that lead you it's kind of a skies the limit kind of scenario it seems you know that now that you're you're kind of",
    "start": "2490079",
    "end": "2495920"
  },
  {
    "text": "launching in uh you know on that you know as a corporation as you said where can you go from here what do you",
    "start": "2495920",
    "end": "2501599"
  },
  {
    "text": "anticipate over the next couple of years or or even several years out you know",
    "start": "2501599",
    "end": "2507040"
  },
  {
    "text": "what's the vision what do you want to achieve you've come a long way so far what's next AGI no I'm just",
    "start": "2507040",
    "end": "2514400"
  },
  {
    "text": "kidding I believe you if you said it actually I mean like you know someone will do it",
    "start": "2514400",
    "end": "2519920"
  },
  {
    "text": "but uh and then you'll distill the knowledge then we'll distill and then you you'll run the AI on your on your",
    "start": "2519920",
    "end": "2526680"
  },
  {
    "text": "neural link or on your contact lens or something right uh but for us like",
    "start": "2526680",
    "end": "2533160"
  },
  {
    "text": "there's a huge focus on locality there's a huge focus on offline there's a huge focus on take the power back run the",
    "start": "2533160",
    "end": "2538760"
  },
  {
    "text": "model yourself do everything at home like that's big for us and at the same time of course we believe in scale but",
    "start": "2538760",
    "end": "2544960"
  },
  {
    "text": "there's this idea that you know there's so much unsolved at the model size why don't we do that before we go to a trillion params because we",
    "start": "2544960",
    "end": "2551839"
  },
  {
    "text": "can scale those realizations but for us like there's certainly you know a transformation and change in attitude",
    "start": "2551839",
    "end": "2558280"
  },
  {
    "text": "and in pressures from going from Pure open source volunteer to as well having kind of this more corporate Branch could",
    "start": "2558280",
    "end": "2565240"
  },
  {
    "text": "created as well but that being said it's been pretty consistent our ethos and our",
    "start": "2565240",
    "end": "2571520"
  },
  {
    "text": "motivation for why we do this and like you said it really was organic in the sense that like we're of the times we're",
    "start": "2571520",
    "end": "2578359"
  },
  {
    "text": "a product of the atmosphere of the AI Community like people have said nice things like you guys are setting the",
    "start": "2578359",
    "end": "2584119"
  },
  {
    "text": "trend and it's not really true so much as the truth is like we are one of many embodiments of the sentiment that the",
    "start": "2584119",
    "end": "2590520"
  },
  {
    "text": "community has and that the world has we think like there's more than one news research in this world you know there's",
    "start": "2590520",
    "end": "2596079"
  },
  {
    "text": "alignment Labs there's pigmalion there's Cobalt there's people who have been around before us people who will come",
    "start": "2596079",
    "end": "2601319"
  },
  {
    "text": "along the way people who have already formed since we have and there's lots of people who have kind of embodied the",
    "start": "2601319",
    "end": "2608559"
  },
  {
    "text": "news research ethos and it's not really just our ethos as much as the overall community's ethos they people who have",
    "start": "2608559",
    "end": "2614559"
  },
  {
    "text": "come before us people who will come along the way uh who do very very similar style of work as us this kind of",
    "start": "2614559",
    "end": "2622119"
  },
  {
    "text": "open work and I think that's got everything to do with the fact that like this is what the people want uh we are",
    "start": "2622119",
    "end": "2628839"
  },
  {
    "text": "just the every man just like everybody else we're not like uh billionaires or",
    "start": "2628839",
    "end": "2633920"
  },
  {
    "text": "super like all x Facebook or anything like that we're we're just a bunch of",
    "start": "2633920",
    "end": "2639119"
  },
  {
    "text": "people who really really care about this who who want to see everyone have access",
    "start": "2639119",
    "end": "2644480"
  },
  {
    "text": "to language models everyone be able to automate their lives everyone be able to push their understanding of any topic to",
    "start": "2644480",
    "end": "2651559"
  },
  {
    "text": "the next level and our work as we become an organization that's looking to you",
    "start": "2651559",
    "end": "2657599"
  },
  {
    "text": "know be a company and create Revenue Etc we won't let it tamper or hinder any of",
    "start": "2657599",
    "end": "2663440"
  },
  {
    "text": "the open source work we do in fact we want it to empower all of that work because we believe that the tools and",
    "start": "2663440",
    "end": "2669920"
  },
  {
    "text": "the developments and services that we will be providing as a corporation will",
    "start": "2669920",
    "end": "2675079"
  },
  {
    "text": "only serve to better feed the entire open source Community we're not really",
    "start": "2675079",
    "end": "2680640"
  },
  {
    "text": "looking to suddenly make like a closed Hermes or something like that we're more looking to create tools and do research",
    "start": "2680640",
    "end": "2688359"
  },
  {
    "text": "that makes your open Hermes far more effective far better and uh you know",
    "start": "2688359",
    "end": "2694280"
  },
  {
    "text": "good enough that you may want to pay for that tool uh it sounds like something I would pay",
    "start": "2694280",
    "end": "2699720"
  },
  {
    "text": "for that's for sure thank you yeah it's super inspiring I I really appreciate",
    "start": "2699720",
    "end": "2705200"
  },
  {
    "text": "you uh taking time current to talk with us I thoroughly enjoyed this because I I'm such a fan of of everything you all",
    "start": "2705200",
    "end": "2712119"
  },
  {
    "text": "are doing and the community that you've built so thank you for saying true to that culture and and what you're doing",
    "start": "2712119",
    "end": "2718680"
  },
  {
    "text": "and I'm really looking forward to seeing what what happens in the future and and where things head and I I hope that we",
    "start": "2718680",
    "end": "2725119"
  },
  {
    "text": "can talk again and have uh news back on the show and in a year when of course everything will be different in the AI",
    "start": "2725119",
    "end": "2731800"
  },
  {
    "text": "world and I'm sure you'll still be doing uh interesting things so yeah you're always welcome back on the show thank",
    "start": "2731800",
    "end": "2737599"
  },
  {
    "text": "you so much it's been a pleasure to chat with you guys thanks for being so candid and I'm glad we were able to kind of",
    "start": "2737599",
    "end": "2744160"
  },
  {
    "text": "push our message forth more and thanks for the validation you and the community have given us to keep doing this great",
    "start": "2744160",
    "end": "2749200"
  },
  {
    "text": "work all right thanks we'll talk soon see [Music]",
    "start": "2749200",
    "end": "2755920"
  },
  {
    "text": "you [Music] that is practically I for this week",
    "start": "2755920",
    "end": "2761640"
  },
  {
    "text": "thanks for listening subscribe now if you haven't yet head to practical AI FM",
    "start": "2761640",
    "end": "2767119"
  },
  {
    "text": "for all the ways and don't forget to check out our fresh Chang log beats the Dance Party album is on Spotify Apple",
    "start": "2767119",
    "end": "2774640"
  },
  {
    "text": "music and the rest there's a link in the show notes for you thanks once again to our partners at fly.io to our beat",
    "start": "2774640",
    "end": "2782160"
  },
  {
    "text": "freaking residence break master cylinder and to you for listening that's all for now we'll talk to you again next",
    "start": "2782160",
    "end": "2789960"
  },
  {
    "text": "[Music]",
    "start": "2790100",
    "end": "2795860"
  },
  {
    "text": "time",
    "start": "2797559",
    "end": "2800559"
  }
]
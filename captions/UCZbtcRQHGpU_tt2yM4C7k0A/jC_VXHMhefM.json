[
  {
    "text": "[Music]",
    "start": "280",
    "end": "4040"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspire to or are",
    "start": "6720",
    "end": "13920"
  },
  {
    "text": "curious how AI related Tech is changing the world this is the show for you thank",
    "start": "13920",
    "end": "20519"
  },
  {
    "text": "you to our partners at fly.io the home of",
    "start": "20519",
    "end": "25759"
  },
  {
    "text": "changelog.md 30 plus regions on six continents so you can launch your app",
    "start": "28960",
    "end": "34399"
  },
  {
    "text": "near your users learn more at [Music]",
    "start": "34399",
    "end": "44000"
  },
  {
    "text": "fly.io okay friends I'm here with Annie ston over at fly Annie you know we use",
    "start": "44000",
    "end": "50199"
  },
  {
    "text": "fly here at changel we love fly it is such an awesome platform and we love building on it but for those who don't",
    "start": "50199",
    "end": "56320"
  },
  {
    "text": "know much about fly what's special about building on fly fly gives you a lot of",
    "start": "56320",
    "end": "62199"
  },
  {
    "text": "flexibility like a lot of flexibility on multiple fronts and on top of that you get so I've talked a lot about the the",
    "start": "62199",
    "end": "69520"
  },
  {
    "text": "networking and that's obviously one thing but there's various data stores that we partner with that are really",
    "start": "69520",
    "end": "75640"
  },
  {
    "text": "easy to use um actually one of my favorite Partners is Tigress I can't say",
    "start": "75640",
    "end": "81280"
  },
  {
    "text": "enough good things about them when it comes to object storage I've I never in my life thought I would have so many",
    "start": "81280",
    "end": "86799"
  },
  {
    "text": "opinions about object storage but I do now tigis is is a partner of fly and it's S3 compatible object storage that",
    "start": "86799",
    "end": "93880"
  },
  {
    "text": "basically seems like it's a CDN but is not it's basically object storage that's globally distributed without needing to",
    "start": "93880",
    "end": "100799"
  },
  {
    "text": "actually set up a CDN at all it's B it's like automatically distributed around the world um and it's also incredibly",
    "start": "100799",
    "end": "107600"
  },
  {
    "text": "easy to use and set up like creating a bucket is literally one command so it's Partners like that that I think are this",
    "start": "107600",
    "end": "114040"
  },
  {
    "text": "sort of extra icing on top of fly that really makes it sort of the platform that has everything that you need so we",
    "start": "114040",
    "end": "120360"
  },
  {
    "text": "use Tigress here at change log are they built on top of fly is this one of those examples of being able to build on fly",
    "start": "120360",
    "end": "127759"
  },
  {
    "text": "yeah so tigis is built on top of fly's infrastructure and that's what allows it to be globally distributed I do have a",
    "start": "127759",
    "end": "133760"
  },
  {
    "text": "video on this but basically the way it works is whenever like let's say a user",
    "start": "133760",
    "end": "138879"
  },
  {
    "text": "uploads an asset to a particular bucket well that gets uploaded directly to the",
    "start": "138879",
    "end": "144440"
  },
  {
    "text": "region closest to the user whereas with a CDN there's sort of like a centralized place where assets need to get copi and",
    "start": "144440",
    "end": "150120"
  },
  {
    "text": "then eventually they get sort of trickled out to all of the different global locations whereas with Tigress the moment you upload something it's",
    "start": "150120",
    "end": "156800"
  },
  {
    "text": "available in that region instantly and then it's eventually cashed in all the other regions as well as it's requested",
    "start": "156800",
    "end": "162519"
  },
  {
    "text": "in fact with Tigress you don't even have to select which regions things are stored in you just get these regions for",
    "start": "162519",
    "end": "168080"
  },
  {
    "text": "free and then on top of that it is so much easier to work with I I feel like",
    "start": "168080",
    "end": "173280"
  },
  {
    "text": "the way they manage permissions the way they handle bucket creation making things public or private is just so much",
    "start": "173280",
    "end": "180440"
  },
  {
    "text": "simpler than other Solutions um and the good news is that you don't actually need to change your code if you're",
    "start": "180440",
    "end": "186040"
  },
  {
    "text": "already using S3 it's S3 compatible so like whatever SDK you're using is probably just fine and all you got to do",
    "start": "186040",
    "end": "191519"
  },
  {
    "text": "is update the credentials so it's super easy very cool thanks Annie so fly has",
    "start": "191519",
    "end": "196959"
  },
  {
    "text": "everything you need over 3 million applications including ours here at change log multiple applications have",
    "start": "196959",
    "end": "203560"
  },
  {
    "text": "launched on fly boosted by global anycast low balancing zero configuration",
    "start": "203560",
    "end": "209319"
  },
  {
    "text": "private networking Hardware isolation instant wire guard VPN connections push",
    "start": "209319",
    "end": "214920"
  },
  {
    "text": "button deployments that scale of thousands of instances it's all there for you right now deploy your app in 5",
    "start": "214920",
    "end": "220720"
  },
  {
    "text": "minutes go to fly.io again [Music]",
    "start": "220720",
    "end": "234199"
  },
  {
    "text": "fly.io welcome to another episode of the Practical AI podcast this is Daniel",
    "start": "235159",
    "end": "240760"
  },
  {
    "text": "whack I am CEO at prediction guard where we're building a private secur gen AI",
    "start": "240760",
    "end": "246560"
  },
  {
    "text": "platform and I'm joined as always by Chris Benson who is a principal AI research engineer at locked Martin how",
    "start": "246560",
    "end": "253760"
  },
  {
    "text": "you doing Chris great today Daniel how are you it's a it's a beautiful beautiful fall day and you know a good",
    "start": "253760",
    "end": "261799"
  },
  {
    "text": "day to take a walk around the block and think about interesting AI things and",
    "start": "261799",
    "end": "267520"
  },
  {
    "text": "clear clear your mind before getting back into some some data collaboration",
    "start": "267520",
    "end": "272720"
  },
  {
    "text": "which is what we're going to talk about today Chris I I don't know if you remember our conversation um my it was",
    "start": "272720",
    "end": "278759"
  },
  {
    "text": "it was just me on that one but with bingson Chua who who talked about broccoli AI the type of AI That's uh",
    "start": "278759",
    "end": "286560"
  },
  {
    "text": "healthy for organizations and uh in that episode he he made a call out to argila which was a",
    "start": "286560",
    "end": "292960"
  },
  {
    "text": "big part of um of his solution that he was developing uh in in a particular",
    "start": "292960",
    "end": "298479"
  },
  {
    "text": "vertical and really happy today that we have with us Ben Burton Shaw who is a",
    "start": "298479",
    "end": "304240"
  },
  {
    "text": "machine learning engineer at argila and also uh David barenstein who is a",
    "start": "304240",
    "end": "310440"
  },
  {
    "text": "developer Advocate engineer uh working on building argila and is still label at hugging face welcome David and Ben thank",
    "start": "310440",
    "end": "317800"
  },
  {
    "text": "you great to be here hi thanks for having us yeah so like I was saying I",
    "start": "317800",
    "end": "323120"
  },
  {
    "text": "think for some time maybe if you're coming from a data science perspective",
    "start": "323120",
    "end": "329479"
  },
  {
    "text": "the there's been tooling maybe around data that manages you know training data",
    "start": "329479",
    "end": "335919"
  },
  {
    "text": "sets or evaluation sets or maybe mlops tooling and this sort of thing um and",
    "start": "335919",
    "end": "341440"
  },
  {
    "text": "part of that has to do with preparation and curation of data sets but I I found",
    "start": "341440",
    "end": "347039"
  },
  {
    "text": "interesting I I mentioned the previous conversation with bingson he talked a lot about collaborating with his sort of",
    "start": "347039",
    "end": "355560"
  },
  {
    "text": "subject matter experts in his company around the data sets he was creating for for text classification and that's where",
    "start": "355560",
    "end": "362280"
  },
  {
    "text": "AR Gila came up so I'm wondering if maybe one of you could talk a little bit at a at a higher level when when you're",
    "start": "362280",
    "end": "369319"
  },
  {
    "text": "talking about data collaboration in the context of the current kind of AI",
    "start": "369319",
    "end": "375280"
  },
  {
    "text": "environment what what does that mean generally and how would you maybe distinguish that from previous",
    "start": "375280",
    "end": "382360"
  },
  {
    "text": "generations of of Tooling in maybe similar or different ways so data",
    "start": "382360",
    "end": "387520"
  },
  {
    "text": "collaboration at least from from our point of view is kind of the collaboration between both the domain level experts that really have uh High",
    "start": "387520",
    "end": "394560"
  },
  {
    "text": "domain knowledge actually know what they're talking about in terms of the data the inputs and the outputs that the",
    "start": "394560",
    "end": "400240"
  },
  {
    "text": "models are supposed to give within their domain and then you have the data scientist or the AI engineers and and",
    "start": "400240",
    "end": "406479"
  },
  {
    "text": "this side of the coin that are more technical they know from a technical point of view what the models expect and what the model should output and then",
    "start": "406479",
    "end": "413599"
  },
  {
    "text": "the collaboration between them is yeah now even even higher because nowadays you can actually prompt uh LMS with",
    "start": "413599",
    "end": "420319"
  },
  {
    "text": "natural language and you actually need to ensure that both the models actually perform well and also the yeah prompts",
    "start": "420319",
    "end": "426360"
  },
  {
    "text": "and and these kind of things so the collaboration is even even more important nowadays and that's also the",
    "start": "426360",
    "end": "431840"
  },
  {
    "text": "case for still the case for Tech cat models and and these kind of things which we also yeah support within a I",
    "start": "431840",
    "end": "438080"
  },
  {
    "text": "guess maybe in the context of let's say there's a new a new team that's",
    "start": "438080",
    "end": "443520"
  },
  {
    "text": "exploring the adoption of AI technology maybe for the first time maybe they're not coming from that data Science",
    "start": "443520",
    "end": "450039"
  },
  {
    "text": "Background the sort of heavy mlop stuff but maybe they've been excited by this",
    "start": "450039",
    "end": "455400"
  },
  {
    "text": "latest wave of of AI Technologies how would you go about helping them",
    "start": "455400",
    "end": "460840"
  },
  {
    "text": "understand how their own data the data that they would curate the data that they would that they would maybe",
    "start": "460840",
    "end": "467120"
  },
  {
    "text": "collaborate on is relevant to and where that fits into the the certain workflow",
    "start": "467120",
    "end": "473039"
  },
  {
    "text": "so yeah imagine someone may be familiar with what you can do with uh chat GPT or",
    "start": "473039",
    "end": "479639"
  },
  {
    "text": "pasting in certain documents or other things um and now they're kind of wrestling through how to set up their",
    "start": "479639",
    "end": "486120"
  },
  {
    "text": "own domain specific AI workflows in their organization what what would you kind of describe about how their own",
    "start": "486120",
    "end": "492319"
  },
  {
    "text": "domain data and how collaborating around that fits into common AI workflows yeah",
    "start": "492319",
    "end": "498319"
  },
  {
    "text": "so something that I like to think about a lot around this subject is like um",
    "start": "498319",
    "end": "503520"
  },
  {
    "text": "machine learning textbooks and they often talk about modeling a problem as well as building a model right there's a",
    "start": "503520",
    "end": "510479"
  },
  {
    "text": "famous mama and mattera cycle and in that when you model a problem you're",
    "start": "510479",
    "end": "515919"
  },
  {
    "text": "basically trying to explain and Define the problem so I have articles and I need to know whether they are a positive",
    "start": "515919",
    "end": "524279"
  },
  {
    "text": "or negative rating and I'm describing that problem and then I'm going to need to describe that problem to a domain",
    "start": "524279",
    "end": "530640"
  },
  {
    "text": "expert or an annotator through guidelines and when I can describe that problem in such a way that the annotator",
    "start": "530640",
    "end": "538120"
  },
  {
    "text": "or the domain expert answers that question clearly enough then I know that that's a modeled and clear problem and",
    "start": "538120",
    "end": "544480"
  },
  {
    "text": "it's something that I could then take on to build a model around um in simple terms it makes sense",
    "start": "544480",
    "end": "550959"
  },
  {
    "text": "and so I think when you're going into a new space that generat of AI and you're",
    "start": "550959",
    "end": "556320"
  },
  {
    "text": "trying to understand your business context around these tools you can start off by modeling the problem in simple",
    "start": "556320",
    "end": "562519"
  },
  {
    "text": "terms by looking at the data and saying okay does this label make sense to this articles if I sort all these articles",
    "start": "562519",
    "end": "569000"
  },
  {
    "text": "down by these labels or by this ranking are these the kinds of things I'm expecting starting off at quite low",
    "start": "569000",
    "end": "575399"
  },
  {
    "text": "numbers right like single articles and kind of building up to tens and hundreds and as you do that you begin to",
    "start": "575399",
    "end": "582079"
  },
  {
    "text": "understand and also iterate on the problem and kind of change it and adapt it as you go and once you've got up to a",
    "start": "582079",
    "end": "588120"
  },
  {
    "text": "reasonable scale of the problem you can then say all right this is something that a machine learning model could",
    "start": "588120",
    "end": "593680"
  },
  {
    "text": "learn I guess on on that front maybe one of the the big confus",
    "start": "593680",
    "end": "599959"
  },
  {
    "text": "that I've seen floating around these days is the kind of data that's relevant",
    "start": "599959",
    "end": "606360"
  },
  {
    "text": "to some of these workflows so it might be easy for people to think about a",
    "start": "606360",
    "end": "613560"
  },
  {
    "text": "labeled data set for a text classification problem right like here's this text coming in I'm going to label",
    "start": "613560",
    "end": "618839"
  },
  {
    "text": "it spam or not spam or in some categories but I think sometimes a sentiment that I've got very often is",
    "start": "618839",
    "end": "626519"
  },
  {
    "text": "hey our company has this big file store right of of documents and somehow I'm",
    "start": "626519",
    "end": "632920"
  },
  {
    "text": "going to you know fine-tune quote unquote an generative model with this",
    "start": "632920",
    "end": "639399"
  },
  {
    "text": "just this blob of documents and then it will perform better for me and there's",
    "start": "639399",
    "end": "644600"
  },
  {
    "text": "two elements of that that are kind of mushy one is like well to what end for",
    "start": "644600",
    "end": "650680"
  },
  {
    "text": "what task right what what are you trying to do and then also how you curate that data then really matters is is this a",
    "start": "650680",
    "end": "657560"
  },
  {
    "text": "sentiment that you all are seeing or or how for this latest wave of models like",
    "start": "657560",
    "end": "662959"
  },
  {
    "text": "how would you describe if a company has a bunch of of documents um and they're",
    "start": "662959",
    "end": "668040"
  },
  {
    "text": "in this situation they're like hey we know we have data and we know that these models can get better and maybe we could",
    "start": "668040",
    "end": "674920"
  },
  {
    "text": "even create our own private model with our own domain of data what would you",
    "start": "674920",
    "end": "679959"
  },
  {
    "text": "walk them through to explain where to start with that process and how to start curating their data Maybe in a less",
    "start": "679959",
    "end": "686880"
  },
  {
    "text": "General way but towards some in I think in these scenarios it's always good to",
    "start": "686880",
    "end": "692240"
  },
  {
    "text": "First establish a a baseline or a benchmark uh because what we often see is that people come to us or come to",
    "start": "692240",
    "end": "699320"
  },
  {
    "text": "like the open source space they say okay we really want to find youa model we really want to do like a super extensive",
    "start": "699320",
    "end": "705600"
  },
  {
    "text": "rack Pipeline with all of the bells and whistles in included and then kind of start working on on these documents but",
    "start": "705600",
    "end": "711959"
  },
  {
    "text": "what we often see is that they don't even have a bench line to actually start with uh so that's normally what we",
    "start": "711959",
    "end": "717279"
  },
  {
    "text": "recommend also whenever you work with the pipeline ensure that all of the documents that you index are actually",
    "start": "717279",
    "end": "723240"
  },
  {
    "text": "properly indexed properly chunked whenever you actually execute a pipeline and you would store these these retrieve",
    "start": "723240",
    "end": "729639"
  },
  {
    "text": "documents or these uh based on the question and the queries um in rgl or",
    "start": "729639",
    "end": "735120"
  },
  {
    "text": "any other data anation tool you can actually have a look at the documents see if they make sense see if the uh",
    "start": "735120",
    "end": "741240"
  },
  {
    "text": "retrieval makes sense but also if the generated output made sense and then whenever you have that Baseline set up",
    "start": "741240",
    "end": "746680"
  },
  {
    "text": "from there actually start iterating and and kind of making additions to your pipeline shall I add ranking potentially",
    "start": "746680",
    "end": "752880"
  },
  {
    "text": "to the retrieval if the retrieval isn't functioning properly shall I add a fine tune version of the model should I",
    "start": "752880",
    "end": "758720"
  },
  {
    "text": "switch from the latest llama model of three billion to 7 billion or these kind",
    "start": "758720",
    "end": "764240"
  },
  {
    "text": "of things and then from there on you can actually consider maybe either fine tuning model if that's actually needed",
    "start": "764240",
    "end": "769560"
  },
  {
    "text": "or fine-tuning one of the retriever or or these kind of things as you're saying that is you're speaking from uh this",
    "start": "769560",
    "end": "776079"
  },
  {
    "text": "kind of profound expertise you have and I think a lot of folks really have trouble just getting started and and",
    "start": "776079",
    "end": "781480"
  },
  {
    "text": "like you asked some great questions there um but I think some of those are really tough for someone who's just",
    "start": "781480",
    "end": "787160"
  },
  {
    "text": "getting into it like which way to go and some of the selections that you would go with that could you talk a little bit",
    "start": "787160",
    "end": "793320"
  },
  {
    "text": "about kind of go back over the same thing but um kind of make up a little workflow you know that's kind of",
    "start": "793320",
    "end": "798839"
  },
  {
    "text": "Hands-On on just like you might see this and this is how I would decide that just for a moment just so people can kind of",
    "start": "798839",
    "end": "805079"
  },
  {
    "text": "grasp kind of the thought process you're going because you kind of described a process but uh if you could be a little",
    "start": "805079",
    "end": "810399"
  },
  {
    "text": "bit more descriptive about that um I think when I talk to people once they get going they kind of go to the next",
    "start": "810399",
    "end": "816800"
  },
  {
    "text": "step and go to the next step and go to the next step but the first four or five uh big question marks at the beginning",
    "start": "816800",
    "end": "822360"
  },
  {
    "text": "they don't know which one to handle so I can add some practical steps onto that that I've worked with in the past if I",
    "start": "822360",
    "end": "829240"
  },
  {
    "text": "that'd be fantastic yeah so one thing that you can do that is really straightforward is actually to write",
    "start": "829240",
    "end": "835959"
  },
  {
    "text": "down a list of the kinds of questions that you're expecting your system to",
    "start": "835959",
    "end": "841160"
  },
  {
    "text": "answer and you can get that list by speaking to domain experts or if you are a domain expert you can write it",
    "start": "841160",
    "end": "846959"
  },
  {
    "text": "yourself right and it doesn't need to be an extensive exhaustive list it can be quite a small starting set you can then",
    "start": "846959",
    "end": "854120"
  },
  {
    "text": "take those questions away and start to look at documents or pools and sections of documents from this Lake that you",
    "start": "854120",
    "end": "860320"
  },
  {
    "text": "potentially have and Associate those documents with those questions and then start to look if a a model can answer",
    "start": "860320",
    "end": "869440"
  },
  {
    "text": "those questions with those documents in fact by not even building anything by",
    "start": "869440",
    "end": "874880"
  },
  {
    "text": "starting to use say chat GPT or hugging chat or any of these kind of interfaces and just seeing this very very low",
    "start": "874880",
    "end": "881639"
  },
  {
    "text": "simple Benchmark see is that feasible whilst at the same time starting to ask",
    "start": "881639",
    "end": "888240"
  },
  {
    "text": "yourself can I as a domain expert answer this and that's kind of where our Gilla comes in at the very first step so you",
    "start": "888240",
    "end": "894600"
  },
  {
    "text": "start to put these documents in front of people with those questions and you start to search through those documents",
    "start": "894600",
    "end": "901759"
  },
  {
    "text": "and say to people can you answer this question or here's an answer from a a model to this question in a very small",
    "start": "901759",
    "end": "909199"
  },
  {
    "text": "setting and you start to get uh basic early signals of quality and from there",
    "start": "909199",
    "end": "915560"
  },
  {
    "text": "you would start to introduce proper retrieval so you would scale up your doc",
    "start": "915560",
    "end": "921399"
  },
  {
    "text": "you would take all of your documents say you had 100 documents associated with your 10 questions you put all those 100",
    "start": "921399",
    "end": "927000"
  },
  {
    "text": "documents in an index and iterate over your 10 questions and see okay are the right documents aligning with the right",
    "start": "927000",
    "end": "933480"
  },
  {
    "text": "questions here then you start to scale up your documents and make it more and more of a real world situation you would",
    "start": "933480",
    "end": "939440"
  },
  {
    "text": "start to scale up your questions you could do both of these synthetically and",
    "start": "939440",
    "end": "944839"
  },
  {
    "text": "then if you still started to see positive signals you could start to scale um and if you start to see",
    "start": "944839",
    "end": "950880"
  },
  {
    "text": "negative signals I'm no longer getting the right documents associated with the right questions I personally would always",
    "start": "950880",
    "end": "957160"
  },
  {
    "text": "start from the simp simplest levers in a rag setup and what I mean there is that",
    "start": "957160",
    "end": "963800"
  },
  {
    "text": "you have a number of different things that you can optimize so you have retrieval you can optimize it",
    "start": "963800",
    "end": "970120"
  },
  {
    "text": "semantically or you can optimize it in a rule-based retrieval you can optimize",
    "start": "970120",
    "end": "976040"
  },
  {
    "text": "the generative model you can optimize The Prompt and the simplest move movers",
    "start": "976040",
    "end": "981399"
  },
  {
    "text": "the simplest levers are the rule based retrieval the word search and then the",
    "start": "981399",
    "end": "986639"
  },
  {
    "text": "semantic search so why would first of all add like a hybrid search what happens if I make sure that there's an",
    "start": "986639",
    "end": "992199"
  },
  {
    "text": "exact match in that document for the word in my query does that improve or um",
    "start": "992199",
    "end": "997319"
  },
  {
    "text": "improve my results and and then I would just move through that process",
    "start": "997319",
    "end": "1003160"
  },
  {
    "text": "[Music] basically what's up friends I'm here",
    "start": "1010110",
    "end": "1016399"
  },
  {
    "text": "with a friend of mine a good friend of mine Michael grenwich CEO and founder of",
    "start": "1016399",
    "end": "1021440"
  },
  {
    "text": "workos work OSS is the all-in-one Enterprise SSO and a whole lot more",
    "start": "1021440",
    "end": "1026600"
  },
  {
    "text": "solution for everyone from a brand new startup to a Enterprise and all the AI",
    "start": "1026600",
    "end": "1032839"
  },
  {
    "text": "apps in between so Michael when is too early or too late to begin to think about being Enterprise ready it's not",
    "start": "1032839",
    "end": "1039959"
  },
  {
    "text": "just a single point in time where people make this transition it occurs at many steps of the business Enterprise single",
    "start": "1039959",
    "end": "1046000"
  },
  {
    "text": "sign on like samle o you usually don't need that until you have users you're not going to need that when you're",
    "start": "1046000",
    "end": "1051600"
  },
  {
    "text": "getting started and we call it an Enterprise feature but I think what you'll find is there's companies when",
    "start": "1051600",
    "end": "1056919"
  },
  {
    "text": "you sell to like a 50 person company they might want this they actually if especially if they care about security they might want that capability in it so",
    "start": "1056919",
    "end": "1063280"
  },
  {
    "text": "it's more of like SB features even if they're Tech forward at work OS we provide a ton of other stuff that we",
    "start": "1063280",
    "end": "1069320"
  },
  {
    "text": "give away for free for people ear earlier in their life cycle we just don't charge you for it so that authkit stuff I mentioned that identity service",
    "start": "1069320",
    "end": "1076720"
  },
  {
    "text": "we give that away for free up to a million users 1 million users and this",
    "start": "1076720",
    "end": "1082000"
  },
  {
    "text": "competes with ozero and other platforms that have much much lower free plans I'm talking like 10,000 50,000 like we give",
    "start": "1082000",
    "end": "1089159"
  },
  {
    "text": "you a million free because we really want to give developers the best tools and capabilities to build their products",
    "start": "1089159",
    "end": "1094400"
  },
  {
    "text": "faster you know to go to market much much faster and where we charge people money for the service is on these",
    "start": "1094400",
    "end": "1099919"
  },
  {
    "text": "Enterprise things if you end up being successful and grow and scale up Market that's where we monetize and that's also",
    "start": "1099919",
    "end": "1105480"
  },
  {
    "text": "when you're making money as a business so we really like to align you know our incentives across that so we have people",
    "start": "1105480",
    "end": "1111200"
  },
  {
    "text": "using oit that are brand new apps just getting started companies in YC combinator side projects hackathon",
    "start": "1111200",
    "end": "1117720"
  },
  {
    "text": "things you know things that are not necessarily commercial Focus but could be someday they're kind of future",
    "start": "1117720",
    "end": "1122799"
  },
  {
    "text": "proofing their Tech stack by using work OS on the other side we have companies much much later that are really big who",
    "start": "1122799",
    "end": "1129799"
  },
  {
    "text": "typically don't like us talking about them their logos you know CU they're uh big big customers but they say hey we we",
    "start": "1129799",
    "end": "1136320"
  },
  {
    "text": "tried to build the stuff or we have some existing technology but we're sort of unhappy with it the developer that built",
    "start": "1136320",
    "end": "1141480"
  },
  {
    "text": "it maybe has left I was talking last week with a company that does over a billion in Revenue each year and their",
    "start": "1141480",
    "end": "1147200"
  },
  {
    "text": "skim connection the user provisioning was written last summer by an intern who's no longer obviously at the company",
    "start": "1147200",
    "end": "1152880"
  },
  {
    "text": "and the thing doesn't really work and so they're looking for a solution for that so there's a really wide spectrum we'll",
    "start": "1152880",
    "end": "1157960"
  },
  {
    "text": "we'll serve companies that are in a you know their office is in a coffee shop or their living room all the way through they have a you know their own building",
    "start": "1157960",
    "end": "1164200"
  },
  {
    "text": "in Downtown San Francisco or New York or something and it's the same platform same technology same tools on both sides",
    "start": "1164200",
    "end": "1170320"
  },
  {
    "text": "the volume is obviously different and sometimes the way we support them from a kind of customer support perspective is a little bit different their needs are",
    "start": "1170320",
    "end": "1176320"
  },
  {
    "text": "different but same technology same platform just like AWS right you can use AWS and pay them $10 a month you can",
    "start": "1176320",
    "end": "1182039"
  },
  {
    "text": "also pay them $10 million a month same product or more for sure or more well no",
    "start": "1182039",
    "end": "1187440"
  },
  {
    "text": "matter where you're at on your Enterprise ready Journey work OS has a solution for you the trusted by",
    "start": "1187440",
    "end": "1193840"
  },
  {
    "text": "perplexity copy. a Alum versel indeed and so many more you can learn more and",
    "start": "1193840",
    "end": "1200360"
  },
  {
    "text": "check them out at work.com that's W ko.com again",
    "start": "1200360",
    "end": "1209480"
  },
  {
    "text": "[Music]",
    "start": "1210460",
    "end": "1220778"
  },
  {
    "text": "work.com I'm guessing that you all you know the fact that you're supporting all of these use cases on top of argila on",
    "start": "1222440",
    "end": "1230520"
  },
  {
    "text": "the data side makes me think um like you say there's so many things to optimize",
    "start": "1230520",
    "end": "1235919"
  },
  {
    "text": "in terms of that rag process but there's also so many AI workflows that are being",
    "start": "1235919",
    "end": "1242320"
  },
  {
    "text": "uh thought of whether that be you know code generation or assistance or um you",
    "start": "1242320",
    "end": "1248200"
  },
  {
    "text": "know content generation information extraction but then you kind of go beyond that yeah David you mentioned",
    "start": "1248200",
    "end": "1253880"
  },
  {
    "text": "text classification and of course there's image use cases so I'm wondering",
    "start": "1253880",
    "end": "1259039"
  },
  {
    "text": "uh from you all do the at this point you know one of the things Chris and I have talked about on the show a bit is you",
    "start": "1259039",
    "end": "1265840"
  },
  {
    "text": "know we're still big proponents and you know believe that in Enterprises a lot of times there is a lot of mixing of you",
    "start": "1265840",
    "end": "1273720"
  },
  {
    "text": "know rule-based systems and more uh kind of traditional I guess if you want to",
    "start": "1273720",
    "end": "1278880"
  },
  {
    "text": "think about it that way machine learning and smaller models and then bringing in these larger gen models as kind of",
    "start": "1278880",
    "end": "1285760"
  },
  {
    "text": "orchestrators or inter you know query layer things and that's a story we've",
    "start": "1285760",
    "end": "1291279"
  },
  {
    "text": "been kind of telling but I think it's interesting that we have both of you here in the sense that like you really",
    "start": "1291279",
    "end": "1297480"
  },
  {
    "text": "I'm sure there's certain things that you don't or can't track about what you're doing but just even anecdotally out of",
    "start": "1297480",
    "end": "1303640"
  },
  {
    "text": "the the users that you're supporting on on argila what have you seen in terms of",
    "start": "1303640",
    "end": "1309279"
  },
  {
    "text": "what what is the mix between those you know using argila for the sort of maybe",
    "start": "1309279",
    "end": "1314720"
  },
  {
    "text": "what people would consider traditional data science type of models like text classification and or image",
    "start": "1314720",
    "end": "1321240"
  },
  {
    "text": "classification type of things and these um maybe newer workflows like Rag and",
    "start": "1321240",
    "end": "1326799"
  },
  {
    "text": "and other things how how do you see that balance and do you see people using both or one or the other yeah any any",
    "start": "1326799",
    "end": "1334120"
  },
  {
    "text": "insights there I think we recently had this uh company from from Germany Alam",
    "start": "1334120",
    "end": "1339360"
  },
  {
    "text": "mines over at one of our uh meetups that we that we host and they had a interesting use case where they",
    "start": "1339360",
    "end": "1345640"
  },
  {
    "text": "collaborated with this um healthcare insurance platform form in in Germany and one of the things that you see with",
    "start": "1345640",
    "end": "1351840"
  },
  {
    "text": "large language models is that these U yeah Lang large language models can't really produce German language properly",
    "start": "1351840",
    "end": "1358200"
  },
  {
    "text": "they're mostly TR trained on English text and that was also one of one of their issues and what they did was",
    "start": "1358200",
    "end": "1365559"
  },
  {
    "text": "actually a yeah huge classification and and generation pipeline combining yeah a",
    "start": "1365559",
    "end": "1371279"
  },
  {
    "text": "lot of these techniques where they would initially get an email in that they would classify to a a certain category",
    "start": "1371279",
    "end": "1378039"
  },
  {
    "text": "then BAS Bas on the category they would kind of Define what kind of email template what kind of prom template they",
    "start": "1378039",
    "end": "1383640"
  },
  {
    "text": "would use then based on the prom template they would kind of start generating and composing one of these",
    "start": "1383640",
    "end": "1389440"
  },
  {
    "text": "response emails that you would expect for like customer query uh requests coming in for the healthcare insurance",
    "start": "1389440",
    "end": "1395120"
  },
  {
    "text": "companies and then in order to actually ensure that the formatting and phrasing",
    "start": "1395120",
    "end": "1400159"
  },
  {
    "text": "and the German language was applied properly they would then based on that prompt regenerate the email once more so",
    "start": "1400159",
    "end": "1408000"
  },
  {
    "text": "prompt llm to kind of improve the quality of the initial proposed output and then after all of these different",
    "start": "1408000",
    "end": "1414159"
  },
  {
    "text": "steps of classification of retrieval augmented generation of an initial uh",
    "start": "1414159",
    "end": "1419640"
  },
  {
    "text": "like generation and a regeneration they would then end up with their eventual output so what we see is that all of",
    "start": "1419640",
    "end": "1427720"
  },
  {
    "text": "these yeah techniques are normally combined and also a thing that that yeah we are strong Believers in is that",
    "start": "1427720",
    "end": "1434400"
  },
  {
    "text": "whenever there's a small smaller model or an easier approach applicable why not go for that instead of using one",
    "start": "1434400",
    "end": "1440840"
  },
  {
    "text": "of these super big large language models so if you can just classify is this relevant or is this not relevant and",
    "start": "1440840",
    "end": "1447279"
  },
  {
    "text": "based on that actually decide what to do that makes a lot of sense and also uh",
    "start": "1447279",
    "end": "1453279"
  },
  {
    "text": "one of the interesting things that I've seen um one of these open source platforms hch out uh out there using is",
    "start": "1453279",
    "end": "1460480"
  },
  {
    "text": "also this query classification uh pipeline where they would classify incoming quaries as either a key",
    "start": "1460480",
    "end": "1468760"
  },
  {
    "text": "terminology search a question query or actually a a phrase for for an llm to",
    "start": "1468760",
    "end": "1474520"
  },
  {
    "text": "actually start pting llm and based on that actually redirect all of their barriers to to the correct model and",
    "start": "1474520",
    "end": "1480720"
  },
  {
    "text": "that's also an interesting approach that we've seen quick follow up on that and uh it's just something I want to draw",
    "start": "1480720",
    "end": "1487520"
  },
  {
    "text": "out because we've drawn it out across some other episodes a bit you were just making a recommendation kind of go for",
    "start": "1487520",
    "end": "1492880"
  },
  {
    "text": "the smaller model versus the larger model could you for people trying to follow and you know there's you know the",
    "start": "1492880",
    "end": "1498840"
  },
  {
    "text": "Divergent mindsets could you take just a second and say why why you would advocate for that what the benefit what",
    "start": "1498840",
    "end": "1505480"
  },
  {
    "text": "the virtue is in the context of everything else I I would say is uh like",
    "start": "1505480",
    "end": "1510880"
  },
  {
    "text": "smaller models are generally hostable by yourself so it's more private smaller models they are more cost efficient uh",
    "start": "1510880",
    "end": "1519039"
  },
  {
    "text": "smaller models can also be fine-tuned easier to your specific use case so even",
    "start": "1519039",
    "end": "1524200"
  },
  {
    "text": "what we what we see a lot of people coming to us about is actually find tuning llms but even the the big",
    "start": "1524200",
    "end": "1530799"
  },
  {
    "text": "companies out there with huge huge amounts of money and resources and dedicated research teams uh still have",
    "start": "1530799",
    "end": "1537000"
  },
  {
    "text": "like difficulties for on on fine-tuning llms so whenever you instead of within your retrieval augmented generation",
    "start": "1537000",
    "end": "1543600"
  },
  {
    "text": "pipeline um fine tune like the nlm for the generation part you can actually choose to to fine-tune one of these",
    "start": "1543600",
    "end": "1550440"
  },
  {
    "text": "retriever models that that you can actually fine tune on uh consumer grade Hardware you can actually fine tune it",
    "start": "1550440",
    "end": "1555840"
  },
  {
    "text": "very easily on any arbitary uh data scientist developer device and then",
    "start": "1555840",
    "end": "1561000"
  },
  {
    "text": "instead of like having to deploy anything on one of the cloud providers you you can start with that and for in",
    "start": "1561000",
    "end": "1568360"
  },
  {
    "text": "in a similar reasoning for for a Rec pipeline whenever you provide an LM with with garbage within such a retrieve",
    "start": "1568360",
    "end": "1575000"
  },
  {
    "text": "augmented generation pipeline you actually also ensure that there's yeah less relevant contact and the the output",
    "start": "1575000",
    "end": "1581240"
  },
  {
    "text": "of the LM llm is also going to be worse yeah I've seen a lot of cases where I",
    "start": "1581240",
    "end": "1587360"
  },
  {
    "text": "think it was tra fer who was on the show he advocated for this hierarchy of how you should approach these problems and",
    "start": "1587360",
    "end": "1594039"
  },
  {
    "text": "there's like you know maybe seven things on his hierarchy that you should try before fine-tuning and I think in a lot",
    "start": "1594039",
    "end": "1600080"
  },
  {
    "text": "of cases I've seen people maybe jump to that they're like oh I forget which one",
    "start": "1600080",
    "end": "1605720"
  },
  {
    "text": "of you said this but you know this naive rag approach didn't get me quite there so now I need to fine tune when in",
    "start": "1605720",
    "end": "1612159"
  },
  {
    "text": "reality there's sort of a huge number of things in between those two places and",
    "start": "1612159",
    "end": "1617960"
  },
  {
    "text": "you might end up just getting a worse performing model depending on how you go about the finetune one of the things uh",
    "start": "1617960",
    "end": "1625360"
  },
  {
    "text": "uh David you kind of walk through these different the the example of the specific company that had these",
    "start": "1625360",
    "end": "1630640"
  },
  {
    "text": "workflows that involved a variety of different operations which I assume you",
    "start": "1630640",
    "end": "1636480"
  },
  {
    "text": "know to Ben you mentioning earlier starting with a test set and that sort of thing and how to think about the",
    "start": "1636480",
    "end": "1643279"
  },
  {
    "text": "tasks I'm wondering if you can specifically now talk just a little bit about RG",
    "start": "1643279",
    "end": "1648799"
  },
  {
    "text": "specifically people might might be familiar generally with like data annotation they might be familiar you",
    "start": "1648799",
    "end": "1655840"
  },
  {
    "text": "know maybe even with how to upload some data to quote fine-tune some of these",
    "start": "1655840",
    "end": "1660960"
  },
  {
    "text": "models in an API sense or maybe even in a more advanced uh way with Q Laura or",
    "start": "1660960",
    "end": "1667279"
  },
  {
    "text": "or something like that but could you take a a minute and just talk through kind of our gila's approach to data",
    "start": "1667279",
    "end": "1674440"
  },
  {
    "text": "annotation and data collaboration and like it it's kind of part on a podcast because we don't have a visual to show",
    "start": "1674440",
    "end": "1680880"
  },
  {
    "text": "for people but as best you can you know help people to imagine you know if I'm using arila uh to to do data",
    "start": "1680880",
    "end": "1688720"
  },
  {
    "text": "collaboration what does that look like in terms of what I would set up and what who's involved what actions are they",
    "start": "1688720",
    "end": "1694960"
  },
  {
    "text": "doing that sort of thing Aila there's two sides to it right so there's a a",
    "start": "1694960",
    "end": "1700679"
  },
  {
    "text": "python SDK which is intended for the AI machine learning engineer and there's a",
    "start": "1700679",
    "end": "1706640"
  },
  {
    "text": "a UI which is intended for your domain expert in reality the engineers often",
    "start": "1706640",
    "end": "1712840"
  },
  {
    "text": "also use the the UI and you kind of iterate on that as you would because it gives you a representation of your task",
    "start": "1712840",
    "end": "1719039"
  },
  {
    "text": "but there's these two sides the UI is kind of lightweight it can be deployed in a Docker container or on hugging face",
    "start": "1719039",
    "end": "1725640"
  },
  {
    "text": "spases it's really easy to spin up and the SDK is really about describing a",
    "start": "1725640",
    "end": "1733159"
  },
  {
    "text": "feedback task and describing the kind of information that you want so you use python classes to construct your data",
    "start": "1733159",
    "end": "1740039"
  },
  {
    "text": "set settings you'll say okay my fields are a piece of text a chat or an image",
    "start": "1740039",
    "end": "1748440"
  },
  {
    "text": "and the questions are a text question so like some kind of feedback a comment for",
    "start": "1748440",
    "end": "1753760"
  },
  {
    "text": "example a label question so so positive or negative labels for example a rating",
    "start": "1753760",
    "end": "1761240"
  },
  {
    "text": "say between one and five or a ranking so um example one is better than example",
    "start": "1761240",
    "end": "1767000"
  },
  {
    "text": "two and you can rank a set of examples and with that definition of a",
    "start": "1767000",
    "end": "1772960"
  },
  {
    "text": "feedback task you can create that on your server on in your UI and then you",
    "start": "1772960",
    "end": "1778480"
  },
  {
    "text": "can push what we call records your your samples into that data set and then the",
    "start": "1778480",
    "end": "1785159"
  },
  {
    "text": "they'll be shown within the UI and your annotator can see all of the questions they'll have nice descriptions that were",
    "start": "1785159",
    "end": "1790559"
  },
  {
    "text": "defined in the SDK they can tweak and kind of change those as well if you need in the UI because that's a little bit",
    "start": "1790559",
    "end": "1796320"
  },
  {
    "text": "easier you can distri distribute the task between a team so you can say okay",
    "start": "1796320",
    "end": "1801440"
  },
  {
    "text": "this record will be accepted once we have at least two uh reviews of it you",
    "start": "1801440",
    "end": "1806640"
  },
  {
    "text": "can say that some questions are required and some aren't and they can skip through some of the questions the UI has",
    "start": "1806640",
    "end": "1812919"
  },
  {
    "text": "a loads of keyboard shortcuts like with numbers and arrows and returns so you can move through it like really fast",
    "start": "1812919",
    "end": "1819000"
  },
  {
    "text": "it's kind of optimized for that and different sort of screen sizes one thing we're starting to see is that as llms",
    "start": "1819000",
    "end": "1825559"
  },
  {
    "text": "get really good at quite long documents some of the stuff that they're dealing with is like a multi-page document or a",
    "start": "1825559",
    "end": "1832840"
  },
  {
    "text": "really detailed image and then a chat conversation and then we want like a",
    "start": "1832840",
    "end": "1837919"
  },
  {
    "text": "comment and a ranking question so it's just like a lot of information in the screen so the UI kind of scales a bit",
    "start": "1837919",
    "end": "1844679"
  },
  {
    "text": "like an IDE like so you can drag it around to give yourself enough width to seal this stuff and then you can move",
    "start": "1844679",
    "end": "1851039"
  },
  {
    "text": "through it in a reasonably efficient way with the keyboard shortcuts and stuff interesting and what do you see as kind",
    "start": "1851039",
    "end": "1857000"
  },
  {
    "text": "of the the backgrounds of the roles of people that are using this tool because",
    "start": "1857000",
    "end": "1862639"
  },
  {
    "text": "one of the interesting things from my perspective especially with this kind of",
    "start": "1862639",
    "end": "1868880"
  },
  {
    "text": "latest wave is there there's maybe less data scientists kind of AI people that",
    "start": "1868880",
    "end": "1875200"
  },
  {
    "text": "that their background and more software engineers and and just you know non-technical domain experts so how do",
    "start": "1875200",
    "end": "1882399"
  },
  {
    "text": "you kind of think about the roles within that and what are you seeing in terms of who's using the system for us I think",
    "start": "1882399",
    "end": "1890200"
  },
  {
    "text": "it's yeah the from from the SDK python side it's really still developers and",
    "start": "1890200",
    "end": "1896120"
  },
  {
    "text": "then from the UI side it's like anyone in in the team that needs to have some data labeled with domain knowledge often",
    "start": "1896120",
    "end": "1903440"
  },
  {
    "text": "these are also going to be like the the AI experts and the one of the cool things is that whenever an AI expert",
    "start": "1903440",
    "end": "1911080"
  },
  {
    "text": "actually sets up a data set besides these fields and questions they can actually come up with some uh",
    "start": "1911080",
    "end": "1916120"
  },
  {
    "text": "interesting features that they can add on top of the data set they are also able to add like semantic search uh like",
    "start": "1916120",
    "end": "1922919"
  },
  {
    "text": "attach records or semantic representation of the records to one of the records which actually enables the",
    "start": "1922919",
    "end": "1928679"
  },
  {
    "text": "the users within the UI to label way more efficiently so for example if someone sees a very representative",
    "start": "1928679",
    "end": "1935760"
  },
  {
    "text": "example of something that's that bad within their data set they can do semantic search find the most similar",
    "start": "1935760",
    "end": "1941720"
  },
  {
    "text": "documents and then continue with with the labeling uh on top of that besides that you can also for example filter",
    "start": "1941720",
    "end": "1948360"
  },
  {
    "text": "based on model certainties so let's say that your model is very uncertain about an initial prediction that you have",
    "start": "1948360",
    "end": "1954279"
  },
  {
    "text": "within your UI and it's really interesting for the domain expert or for the data scientist to to go and and have",
    "start": "1954279",
    "end": "1960840"
  },
  {
    "text": "a look at that specific uh record or this like range of uncertainties and",
    "start": "1960840",
    "end": "1966120"
  },
  {
    "text": "then based on that the labeling or like the the data accuration or whatever you would like to call it becomes way more",
    "start": "1966120",
    "end": "1972720"
  },
  {
    "text": "engaging and way way more interesting and on top of that another thing that we are uh starting to explore is actually",
    "start": "1972720",
    "end": "1979039"
  },
  {
    "text": "using this AI feedback and and synthetic data within our gel as well um and",
    "start": "1979039",
    "end": "1984120"
  },
  {
    "text": "that's actually one of the other products that we're working on and it's called DC label so nowadays what you can",
    "start": "1984120",
    "end": "1990399"
  },
  {
    "text": "do with llms is also actually use llms to evaluate like questions for example",
    "start": "1990399",
    "end": "1996320"
  },
  {
    "text": "to evaluate whether uh something is label a b or c or whether something is a",
    "start": "1996320",
    "end": "2001559"
  },
  {
    "text": "good or bad response and you see all all kinds of uh like tools open source tools",
    "start": "2001559",
    "end": "2006960"
  },
  {
    "text": "out there and that's also a thing that we are looking at for integrating with the UI where instead of doing this more",
    "start": "2006960",
    "end": "2013159"
  },
  {
    "text": "from a data science SDK perspective um users without any technical knowledge",
    "start": "2013159",
    "end": "2018320"
  },
  {
    "text": "would actually be able to tweak these guidelines that Ben highlighted earlier and then say okay maybe instead of",
    "start": "2018320",
    "end": "2024679"
  },
  {
    "text": "taking this into account you should focus a bit more on like the the harm uh that potentially is within within your",
    "start": "2024679",
    "end": "2031080"
  },
  {
    "text": "data or the risks that are within your data and then you would be able to prompt an llm once again to kind of",
    "start": "2031080",
    "end": "2036559"
  },
  {
    "text": "label your data and then you wouldn't directly need the python SDK anymore I was thinking about",
    "start": "2036559",
    "end": "2043120"
  },
  {
    "text": "as you were describing that um I work at a large organization um and we certainly have a lot of domain experts uh in the",
    "start": "2043120",
    "end": "2049679"
  },
  {
    "text": "organization I work at that are either non-technical or semi- Technical and as",
    "start": "2049679",
    "end": "2055118"
  },
  {
    "text": "users they will sometimes find it intimidating you know kind of getting into all this as they're starting a",
    "start": "2055119",
    "end": "2060520"
  },
  {
    "text": "project could you talk a little bit about what it's like for a non-technical person to sit down with argila and start",
    "start": "2060520",
    "end": "2067760"
  },
  {
    "text": "to work in a productive way what what is that experience like for them because it's one thing like the the technical",
    "start": "2067760",
    "end": "2073919"
  },
  {
    "text": "people kind of just know they dive into it they're going to use the SDK they've used other sdks but um there can be a",
    "start": "2073919",
    "end": "2080320"
  },
  {
    "text": "bit of handholding for people who are not used to that could you describe the the user experience for that non-technical subject matter expert",
    "start": "2080320",
    "end": "2086919"
  },
  {
    "text": "coming in and what labeling is like and just kind of paint uh a picture of words",
    "start": "2086919",
    "end": "2092280"
  },
  {
    "text": "on what their what their experience might be like yeah I mean one thing I guess I'd start off by saying is that",
    "start": "2092280",
    "end": "2098720"
  },
  {
    "text": "arilla is kind of the latest iteration of a problem that has existed for a long",
    "start": "2098720",
    "end": "2104560"
  },
  {
    "text": "time in machine learning and data science right about collecting feedback from domain experts and it's kind of",
    "start": "2104560",
    "end": "2110240"
  },
  {
    "text": "gone through spreadsheets and various other tools that were substandard and really bad user",
    "start": "2110240",
    "end": "2118240"
  },
  {
    "text": "experiences where domain experts were were asked for information that information was extracted and then",
    "start": "2118240",
    "end": "2124880"
  },
  {
    "text": "models have been trained really poorly on that information so as a field we",
    "start": "2124880",
    "end": "2131160"
  },
  {
    "text": "kind of know that it's something that we have to take really seriously and and that's kind of what our Giller is built on top of right that's part of our DNA",
    "start": "2131160",
    "end": "2138119"
  },
  {
    "text": "as as a product it's like optimizing the feedback process as a",
    "start": "2138119",
    "end": "2143400"
  },
  {
    "text": "user experience problem and so when the user sits down to use our Gilla the",
    "start": "2143400",
    "end": "2149200"
  },
  {
    "text": "intention is that all of the information should be right there in front of them inside their single like record view so",
    "start": "2149200",
    "end": "2157079"
  },
  {
    "text": "what that means is they've got a set of guidelines that are edited in markdown they can contain images links to various",
    "start": "2157079",
    "end": "2165079"
  },
  {
    "text": "Pages or other external documents if they need and they can just kind of scroll through that it's always there it's always available they've then also",
    "start": "2165079",
    "end": "2172079"
  },
  {
    "text": "got like basic metrics so they'll know how many records They they've got left how many they've labeled they can view",
    "start": "2172079",
    "end": "2178440"
  },
  {
    "text": "their kind of team status and see what's going on and then on the left they have their fields which they can scroll",
    "start": "2178440",
    "end": "2185079"
  },
  {
    "text": "through and on the right they'll have a a set of question questions as I said they can move through these in keyboard",
    "start": "2185079",
    "end": "2190880"
  },
  {
    "text": "shortcuts and they can switch the view so that they can scroll kind of infinitely or they can move into a kind",
    "start": "2190880",
    "end": "2197400"
  },
  {
    "text": "of page swiping which yeah if you're looking at really small records with like a couple of lines and and you're",
    "start": "2197400",
    "end": "2202839"
  },
  {
    "text": "just assigning a symbol label to you can do that in bulk so as we said you could use say um semantic search give me all",
    "start": "2202839",
    "end": "2210680"
  },
  {
    "text": "the records that are similar to this one and I'll bulk label those or you could search for terms inside those records",
    "start": "2210680",
    "end": "2216560"
  },
  {
    "text": "and you bulk label those and then once you're finished you'll know about it and",
    "start": "2216560",
    "end": "2221720"
  },
  {
    "text": "one of the interesting things that but I've I've done personally quite often is sit together with the domain experts and",
    "start": "2221720",
    "end": "2229000"
  },
  {
    "text": "the AI Engineers to kind of walk them to how to configure our Gilla most usefully",
    "start": "2229000",
    "end": "2235119"
  },
  {
    "text": "for both of them and then the domain exports come with a lot of things to the table like like I I want to see this",
    "start": "2235119",
    "end": "2241640"
  },
  {
    "text": "specific representation what if we could do this what if we could do that that then the AI Engineers think about like",
    "start": "2241640",
    "end": "2247200"
  },
  {
    "text": "the data side of things uh is this possible from our point of view from our side and then me as a like mediator so",
    "start": "2247200",
    "end": "2254119"
  },
  {
    "text": "to say can I make the most out of the arela configuration and that's also how we see this collaboration process going",
    "start": "2254119",
    "end": "2261640"
  },
  {
    "text": "where domain experts really work together also with AI Engineers because AI Engineers or machine learning",
    "start": "2261640",
    "end": "2267000"
  },
  {
    "text": "Engineers actually know what's possible from the data what it means to to get high quality data for fine juning model",
    "start": "2267000",
    "end": "2273599"
  },
  {
    "text": "because whenever a domain engineer uh comes up with something that's useful for for them in terms of labeling",
    "start": "2273599",
    "end": "2279640"
  },
  {
    "text": "doesn't mean necessarily that it's actually propw data that's going to come out of there in terms of fine tuning a",
    "start": "2279640",
    "end": "2286040"
  },
  {
    "text": "model and that's also a part of I guess the collaboration that we're talking [Music]",
    "start": "2286040",
    "end": "2302409"
  },
  {
    "text": "about what's up friends I've got something exciting to share with you today a sleep technology that's pushing",
    "start": "2304920",
    "end": "2310200"
  },
  {
    "text": "the boundaries of what's possible in our bedrooms let me introduce you to eight sleep and their Cutting Edge pod 4 ultra",
    "start": "2310200",
    "end": "2318560"
  },
  {
    "text": "now I haven't gotten mine yet but it's on its way I'm literally counting the days so what exactly is the Pod for",
    "start": "2318560",
    "end": "2324960"
  },
  {
    "text": "Ultra imagine a high-tech mattress cover that you can easily add to any bed but",
    "start": "2324960",
    "end": "2330880"
  },
  {
    "text": "this isn't just any cover it is packed with sensors Heating and Cooling elements and it's all controlled by",
    "start": "2330880",
    "end": "2337480"
  },
  {
    "text": "sophisticated AI algorithms it's like having a sleep lab a smart thermostat",
    "start": "2337480",
    "end": "2343440"
  },
  {
    "text": "and a personal sleep coach all rolled into a single device it uses a network of sensors to track a wide array of",
    "start": "2343440",
    "end": "2351240"
  },
  {
    "text": "Biometrics while you sleep sleep stages heart rate variability respiratory rate temperature and more it uses Precision",
    "start": "2351240",
    "end": "2358560"
  },
  {
    "text": "temperature control to regulate your body sleep cycles it can cool you down to a chilly 55° fhe or warm you up to a",
    "start": "2358560",
    "end": "2367079"
  },
  {
    "text": "good nice solid temperature of 110 F and it does this separately for each side of",
    "start": "2367079",
    "end": "2373640"
  },
  {
    "text": "the bed this means you and your partner can have your own ideal sleep temperatures but the really cool part is",
    "start": "2373640",
    "end": "2380480"
  },
  {
    "text": "that the Pod uses Ai and it uses machine learning to learn your sleep patterns",
    "start": "2380480",
    "end": "2386480"
  },
  {
    "text": "over time and it uses this data to automatically adjust the temperature your bed throughout the night according",
    "start": "2386480",
    "end": "2392720"
  },
  {
    "text": "to your body's preferences instead of just giving you some stats it understands them and it does something",
    "start": "2392720",
    "end": "2398720"
  },
  {
    "text": "about it your bed literally gets smarter as you sleep over time and all this functionality is accessible through a",
    "start": "2398720",
    "end": "2405599"
  },
  {
    "text": "comprehensive mobile app you get sleep analytics Trends over time and you even get a daily sleep Fitness score now I",
    "start": "2405599",
    "end": "2413200"
  },
  {
    "text": "don't have mine yet it is on its way thanks to our friends over at sleep and I'm literally cutting the days I get it",
    "start": "2413200",
    "end": "2419599"
  },
  {
    "text": "cuz I love this stuff but if you're ready to take your sleep and your recovery to the next level head over to",
    "start": "2419599",
    "end": "2425280"
  },
  {
    "text": "8sleep.com practice itical Ai and use our code practical AI to get 350 bucks off your",
    "start": "2425280",
    "end": "2432440"
  },
  {
    "text": "very own pod 4 ultra and you can try it free for 30 days I don't think you want",
    "start": "2432440",
    "end": "2437560"
  },
  {
    "text": "to send it back but you can if you want to they're currently shipping to the US Canada United Kingdom Europe and",
    "start": "2437560",
    "end": "2445119"
  },
  {
    "text": "Australia again 8sleep.com practical aai",
    "start": "2445119",
    "end": "2451550"
  },
  {
    "text": "[Music]",
    "start": "2451550",
    "end": "2469159"
  },
  {
    "text": "I want to maybe um double click on something that David you just said in in sort of passing which I think is is",
    "start": "2469319",
    "end": "2476040"
  },
  {
    "text": "quite significant and I don't know if um some people might have caught it but when you were talking about the still",
    "start": "2476040",
    "end": "2481280"
  },
  {
    "text": "label you also talked about AI feedback so AI feedback and synthetic data so I'd",
    "start": "2481280",
    "end": "2487480"
  },
  {
    "text": "love to get into those topics a little bit maybe first coming from the AI feedback side I think this is super",
    "start": "2487480",
    "end": "2493880"
  },
  {
    "text": "interesting because um you know Ben you talked about how this is a kind of more",
    "start": "2493880",
    "end": "2499040"
  },
  {
    "text": "General problem that people have been have been looking at in various ways from various perspectives for a long",
    "start": "2499040",
    "end": "2505280"
  },
  {
    "text": "time in terms of this data collaboration labeling piece but there is this kind of",
    "start": "2505280",
    "end": "2511800"
  },
  {
    "text": "very interesting element now where we have the ability to utilize these very",
    "start": "2511800",
    "end": "2517240"
  },
  {
    "text": "powerful maybe general purpose instruction following type of models to",
    "start": "2517240",
    "end": "2523839"
  },
  {
    "text": "actually act as labelers within the system or at least generate you know",
    "start": "2523839",
    "end": "2529880"
  },
  {
    "text": "drafts of of labels or or feedback or even preferences and uh scores and and",
    "start": "2529880",
    "end": "2536520"
  },
  {
    "text": "all all of those sorts of things so I'm wondering if uh one of you could speak to that uh some people might find this",
    "start": "2536520",
    "end": "2543440"
  },
  {
    "text": "kind of strange that we're kind of giving feedback to AI systems with AI",
    "start": "2543440",
    "end": "2549680"
  },
  {
    "text": "systems which seems circular and maybe like why would that work or just sort of",
    "start": "2549680",
    "end": "2555400"
  },
  {
    "text": "maybe that's kind of produces some weird feelings for people but I think it is a significant thing that is happening and",
    "start": "2555400",
    "end": "2562319"
  },
  {
    "text": "um so yeah either of you would want to kind of dive into that what what does it specifically mean in AI feedback how are",
    "start": "2562319",
    "end": "2569000"
  },
  {
    "text": "you seeing that being used most productively so when we create a data set either manually or or with AI",
    "start": "2569000",
    "end": "2576599"
  },
  {
    "text": "feedback AI generation we have all the information there to understand the problem we have a set of guidelines we",
    "start": "2576599",
    "end": "2583040"
  },
  {
    "text": "have a set of labels definitions of those labels with documents and definitions of those documents we give",
    "start": "2583040",
    "end": "2588400"
  },
  {
    "text": "those to a manual annotator or we'll go out and collect those documents and and we give those documents the manual",
    "start": "2588400",
    "end": "2594079"
  },
  {
    "text": "annotate and we're trying to describe that problem so that the person understands it to create the data we can",
    "start": "2594079",
    "end": "2599359"
  },
  {
    "text": "essentially take all of the same resources and give those to an llm and get the llm to perform the same steps so",
    "start": "2599359",
    "end": "2606079"
  },
  {
    "text": "there's two parts to that there's a a generative part where the llm can generate documents so let's say we've",
    "start": "2606079",
    "end": "2613599"
  },
  {
    "text": "got a 100 documents in our data set but we want 10,000 we can say um generate a",
    "start": "2613599",
    "end": "2619319"
  },
  {
    "text": "document like this one but and add variation on top of that and we can uh",
    "start": "2619319",
    "end": "2625480"
  },
  {
    "text": "it fan out our data set our documents from 100 to 10,000 we could then take",
    "start": "2625480",
    "end": "2631680"
  },
  {
    "text": "those same documents or a pool of documents from elsewhere and we could get feedback on that so that could be",
    "start": "2631680",
    "end": "2638960"
  },
  {
    "text": "qualitative feedback tell me which of these documents are relevant to this task tell me which of these documents",
    "start": "2638960",
    "end": "2645760"
  },
  {
    "text": "are of a high quality are concise are detailed these kind of attributes so we",
    "start": "2645760",
    "end": "2651240"
  },
  {
    "text": "could filter down our large data set or our generated data set to the best documents we could also add labels so we",
    "start": "2651240",
    "end": "2658480"
  },
  {
    "text": "could say um tell me which of these documents relates to my business use case or not these kind of things apply",
    "start": "2658480",
    "end": "2665599"
  },
  {
    "text": "topics to these documents and then we can in doing so create a classification data set right from those",
    "start": "2665599",
    "end": "2672119"
  },
  {
    "text": "labels or we could um in one example take a set of documents and use a",
    "start": "2672119",
    "end": "2677839"
  },
  {
    "text": "generative model to generate questions or queries about those documents and we could use that to create a Q&A data set",
    "start": "2677839",
    "end": "2685680"
  },
  {
    "text": "or a retrieval data set where we generate search queries based on documents when you're doing that and",
    "start": "2685680",
    "end": "2691319"
  },
  {
    "text": "you're generating the data sets uh with another you know model how much do you",
    "start": "2691319",
    "end": "2697040"
  },
  {
    "text": "you have to worry about hallucination playing into that it sounds like you have a good process for kind of trying to catch it uh there but uh is that a",
    "start": "2697040",
    "end": "2704520"
  },
  {
    "text": "small issue is that a larger issue any any guidance on that that's one of the main issues definitely like it is",
    "start": "2704520",
    "end": "2711680"
  },
  {
    "text": "probably the main issue and so really it's about both sides of that process",
    "start": "2711680",
    "end": "2717720"
  },
  {
    "text": "that I described that generating side and that evaluating side so you get the",
    "start": "2717720",
    "end": "2722839"
  },
  {
    "text": "large langage models to do as much as possible to expose hallucination by evaluating themselves and typically",
    "start": "2722839",
    "end": "2729880"
  },
  {
    "text": "you're getting larger models to evaluate so that that they're a more performant",
    "start": "2729880",
    "end": "2735400"
  },
  {
    "text": "model and they should hallucinate less the task of identifying hallucinations is not the same as as generating a",
    "start": "2735400",
    "end": "2741800"
  },
  {
    "text": "document so typically llms are better identifying hallucinations and nonsense if you give them the context then they",
    "start": "2741800",
    "end": "2748559"
  },
  {
    "text": "are not generating it and so you combine that within a pipeline and then you",
    "start": "2748559",
    "end": "2754960"
  },
  {
    "text": "would take that to a domain expert in a tool like Argilla and so that's really why we have these two tools right dist",
    "start": "2754960",
    "end": "2761800"
  },
  {
    "text": "label and arilla because kind of without arilla dist label would suffer from a",
    "start": "2761800",
    "end": "2768040"
  },
  {
    "text": "lot of those problems right yeah and I I guess that brings us to the the second tool the this so label which I I know",
    "start": "2768040",
    "end": "2775319"
  },
  {
    "text": "has some to do with this synthetic data piece as well and I'm I'm really intrigued to hear about this because I",
    "start": "2775319",
    "end": "2780960"
  },
  {
    "text": "also see you know some of what you have on the on the documentation about you",
    "start": "2780960",
    "end": "2786720"
  },
  {
    "text": "know what are people building with distill label um I do note you know a couple of data sets like the open Hermes",
    "start": "2786720",
    "end": "2794640"
  },
  {
    "text": "data set the Intel Orca DPO data set these are data sets that have been part",
    "start": "2794640",
    "end": "2800559"
  },
  {
    "text": "of the the lineage of of models that I've found very very useful so first off",
    "start": "2800559",
    "end": "2806720"
  },
  {
    "text": "thanks for for building tooling that's created really useful models in in my",
    "start": "2806720",
    "end": "2811839"
  },
  {
    "text": "own life but um beyond that uh yeah David do you want to go into a little bit about what distill label is and",
    "start": "2811839",
    "end": "2818359"
  },
  {
    "text": "maybe even tie into some of those things and how it's proven to be a a useful piece of the um the process in creating",
    "start": "2818359",
    "end": "2826240"
  },
  {
    "text": "some of those models I think yeah the idea of this label kind of started to to",
    "start": "2826240",
    "end": "2832200"
  },
  {
    "text": "done like half half a year ago more or less or maybe a year ago where we saw these initial um yeah new models coming",
    "start": "2832200",
    "end": "2839800"
  },
  {
    "text": "out like alaka and Dolly from from datab breaks apaka from Stanford um where",
    "start": "2839800",
    "end": "2846400"
  },
  {
    "text": "there were like and um data sets being generated with openai Frontier models",
    "start": "2846400",
    "end": "2853079"
  },
  {
    "text": "being evaluated with open Frontier models and then published and actually used for for fine-tuning one of these",
    "start": "2853079",
    "end": "2859000"
  },
  {
    "text": "models so apparently there was like were research groups where companies kind of investing time in this but what we also",
    "start": "2859000",
    "end": "2864520"
  },
  {
    "text": "saw is when we would kind of upload these data sets into arilla actually start looking at the data that there were a lot of flaws with within there",
    "start": "2864520",
    "end": "2871599"
  },
  {
    "text": "and then whenever like Ultra feedback which is one of these specific papers that really started to scale the",
    "start": "2871599",
    "end": "2877480"
  },
  {
    "text": "synthetic data and AI feedback concept came out we thought okay maybe it's worth to um look into like a package",
    "start": "2877480",
    "end": "2885200"
  },
  {
    "text": "that can actually help us facilitate kind of creating data sets that we can then eventually fine-tune within AR Jill",
    "start": "2885200",
    "end": "2892240"
  },
  {
    "text": "and that's when we started yeah work on the initial version of this label so it's kind of like application Frameworks",
    "start": "2892240",
    "end": "2899319"
  },
  {
    "text": "like Lama index or or L chain if you're familiar with those but then specifically focused on on synthetic",
    "start": "2899319",
    "end": "2906200"
  },
  {
    "text": "data gener a and AI feedback so what we try to do is uh organize everything into",
    "start": "2906200",
    "end": "2912599"
  },
  {
    "text": "this pip planning structure we have either steps that are about basic data",
    "start": "2912599",
    "end": "2917920"
  },
  {
    "text": "operations uh tasks that are about prompt templates or prompting um and",
    "start": "2917920",
    "end": "2923160"
  },
  {
    "text": "prom templates you can think about either providing feedback maybe rewriting some initial input that you",
    "start": "2923160",
    "end": "2928400"
  },
  {
    "text": "provide to that promp template or maybe uh like ranking or like generating from from scratch or these kind of things and",
    "start": "2928400",
    "end": "2935440"
  },
  {
    "text": "then uh these task are actually executed by llms um and these are then all like",
    "start": "2935440",
    "end": "2940799"
  },
  {
    "text": "fit together within uh within a pipelining structure um the thing for",
    "start": "2940799",
    "end": "2946319"
  },
  {
    "text": "these task is that nowadays we actually look at all of the most recent research implementations or most recent reearch",
    "start": "2946319",
    "end": "2952680"
  },
  {
    "text": "papers and we try to implement them uh whenever they come out and are are actually relevant for synthetic data",
    "start": "2952680",
    "end": "2959319"
  },
  {
    "text": "generation so you really go from like the kind of finicky prompt engineering so to say to well evaluated PR PRS that",
    "start": "2959319",
    "end": "2967160"
  },
  {
    "text": "we've implemented and the nice thing about our pipelining structure is also that we run everything asynchronously so",
    "start": "2967160",
    "end": "2974760"
  },
  {
    "text": "there's multiple like llm executions being done at once which will really speed up your pipeline and on top of",
    "start": "2974760",
    "end": "2981640"
  },
  {
    "text": "that we also cache all of the intermediary results so as you can imagine uh calling the open AI API can",
    "start": "2981640",
    "end": "2988200"
  },
  {
    "text": "be quite costly and whenever you run a pipeline uh there can go a lot of things",
    "start": "2988200",
    "end": "2993720"
  },
  {
    "text": "can go wrong but whenever you actually reun our p Lines within this label you actually have these cash results already",
    "start": "2993720",
    "end": "2999960"
  },
  {
    "text": "there so you would avoid kind of incurring additional costs whenever something within the pipeline breaks",
    "start": "2999960",
    "end": "3006119"
  },
  {
    "text": "yeah that's that's awesome and I know that one element of this is the kind of",
    "start": "3006119",
    "end": "3011319"
  },
  {
    "text": "creation of synthetic data for further fine-tuning llms um you know to increase",
    "start": "3011319",
    "end": "3017960"
  },
  {
    "text": "performance or or maybe to some sort of alignment goal or something like that but also um I know from working with a",
    "start": "3017960",
    "end": "3025960"
  },
  {
    "text": "lot of you know healthc care companies manufacturers others that are more",
    "start": "3025960",
    "end": "3032680"
  },
  {
    "text": "security privacy conscious in my day job part of the pitch around synthetic data",
    "start": "3032680",
    "end": "3039440"
  },
  {
    "text": "is is maybe also creating data sets that might not kind of poison llms with a",
    "start": "3039440",
    "end": "3047119"
  },
  {
    "text": "bunch of your own sort of private information that could be sort of exposed as part of an answer that",
    "start": "3047119",
    "end": "3053640"
  },
  {
    "text": "someone prompts the model in some way and this data is you know embedded in the in the data set and and all of that",
    "start": "3053640",
    "end": "3059440"
  },
  {
    "text": "so yeah I I would definitely encourage people to check out this still label and you said it's been around for half a",
    "start": "3059440",
    "end": "3065480"
  },
  {
    "text": "year so how have you how have you seen the kind of usage and and adoption so",
    "start": "3065480",
    "end": "3070839"
  },
  {
    "text": "far the usage and adoption has been quite quite good in terms of the number",
    "start": "3070839",
    "end": "3076000"
  },
  {
    "text": "of data sets that have been released so uh you you mentioned the the uh Intel Orca DPO data set which was an example",
    "start": "3076000",
    "end": "3083440"
  },
  {
    "text": "use case of how we uh were initially using it where we had this original data",
    "start": "3083440",
    "end": "3089559"
  },
  {
    "text": "set that had been labeled by by Intel employees with preferences of what would be like the preferred response to a give",
    "start": "3089559",
    "end": "3096760"
  },
  {
    "text": "prompt and we actually used this label to kind of clean that based on asking uh",
    "start": "3096760",
    "end": "3102400"
  },
  {
    "text": "prompting llms ourselves to re-evaluate these chosen rejected pairs within the",
    "start": "3102400",
    "end": "3107480"
  },
  {
    "text": "original data set uh filtering out all of the ambiguity so sometimes the llm",
    "start": "3107480",
    "end": "3113040"
  },
  {
    "text": "wouldn't align with the original chosen rejected pair and based on that we were actually able to scale down the data set",
    "start": "3113040",
    "end": "3119680"
  },
  {
    "text": "by 50% um leading to less training time and also leading to a higher performing",
    "start": "3119680",
    "end": "3125480"
  },
  {
    "text": "model and that was yeah one of the really famous examples that kind of inspired some some people within the",
    "start": "3125480",
    "end": "3131319"
  },
  {
    "text": "open source Community to actually start looking at this label to start using this label to generate data sets there",
    "start": "3131319",
    "end": "3137640"
  },
  {
    "text": "are some hugging phase uh teams that actually have been generating millions and millions of rows of of synthetic",
    "start": "3137640",
    "end": "3144079"
  },
  {
    "text": "data using this C label and that's pretty cool to to see that that people are actually using it at skill and",
    "start": "3144079",
    "end": "3151520"
  },
  {
    "text": "besides that there's also these uh like smaller company so to say but uh like Alam mind the German consulty the German",
    "start": "3151520",
    "end": "3159040"
  },
  {
    "text": "startup that I mentioned before using it to also rewrite and and resynthesize uh",
    "start": "3159040",
    "end": "3165119"
  },
  {
    "text": "emails within like actual production use cases it's really fascinating you guys",
    "start": "3165119",
    "end": "3170520"
  },
  {
    "text": "are pushing the state-of-the-art uh in in a big way with with the work that",
    "start": "3170520",
    "end": "3175839"
  },
  {
    "text": "you've done um in dista label and argila where do you think things are going like",
    "start": "3175839",
    "end": "3181400"
  },
  {
    "text": "how when you're when you're kind of end of whatever your task is of the day and you're kind of just letting your mind",
    "start": "3181400",
    "end": "3187079"
  },
  {
    "text": "Wonder uh and thinking about the future where do each of y'all go in terms of what you think's going to happen what",
    "start": "3187079",
    "end": "3193079"
  },
  {
    "text": "you're excited about what you're hoping will happen um what you might be working on in a few months or maybe a year or",
    "start": "3193079",
    "end": "3199520"
  },
  {
    "text": "two what are your thoughts I suppose for me it's about two main things and the",
    "start": "3199520",
    "end": "3205520"
  },
  {
    "text": "first would be ities so moving out of text and into image and audio and video",
    "start": "3205520",
    "end": "3212240"
  },
  {
    "text": "and also kind of ux environments so that mainly in our Gilla but also in dist",
    "start": "3212240",
    "end": "3218280"
  },
  {
    "text": "label that we can generate synthetic data sets in different modalities and that we can review those and that that's",
    "start": "3218280",
    "end": "3224799"
  },
  {
    "text": "a yeah necessity and something that we're already working on and we've already got features around but we've got kind of more coming and then the",
    "start": "3224799",
    "end": "3231319"
  },
  {
    "text": "second one which I suppose is a bit more far-fetched and that that's a bit more about kind of tightening the loop",
    "start": "3231319",
    "end": "3238359"
  },
  {
    "text": "between the various part various applications so between dis label Argilla and the application that you're",
    "start": "3238359",
    "end": "3244160"
  },
  {
    "text": "building so that you can deal with feedback as it's coming from your domain expert that's using your application and",
    "start": "3244160",
    "end": "3250400"
  },
  {
    "text": "potentially a Giller at the same time so we can kind of synthesize on top of that to evaluate that feedback that we're",
    "start": "3250400",
    "end": "3256400"
  },
  {
    "text": "getting and generate based on that feedback so we can add that into our Giller and then we can respond to that",
    "start": "3256400",
    "end": "3262839"
  },
  {
    "text": "um synthetic generation that synthetic data and then can use that to train our model this kind of tight Loop between",
    "start": "3262839",
    "end": "3270480"
  },
  {
    "text": "yeah the end use of the application and our feedback yeah and for for me it kind of aligns with what you mentioned before",
    "start": "3270480",
    "end": "3277480"
  },
  {
    "text": "man like the multimodality uh smaller more efficient models things that can actually run on device I've been playing",
    "start": "3277480",
    "end": "3283920"
  },
  {
    "text": "around with this uh app this morning that you can actually load local llm into like a small smaller like qn or",
    "start": "3283920",
    "end": "3291839"
  },
  {
    "text": "Lama model from from meta and it actually runs on an iPhone 13 which is really cool it's private it runs quite",
    "start": "3291839",
    "end": "3298280"
  },
  {
    "text": "quickly and a thing that I been wanting to play around with is these speech to speech models where you can actually",
    "start": "3298280",
    "end": "3304160"
  },
  {
    "text": "have real time speech to speech I'm currently learning uh Spanish at the moment and one of the kind of difficult",
    "start": "3304160",
    "end": "3310040"
  },
  {
    "text": "things there is uh not being secure to enough to actually talk to to people out",
    "start": "3310040",
    "end": "3315440"
  },
  {
    "text": "on the streets and and these kind of things so whenever you would be able to kind of practice it at home uh privately",
    "start": "3315440",
    "end": "3320960"
  },
  {
    "text": "on your device kind of talk talk some Spanish into an LM get some Spanish back maybe some corrections in English these",
    "start": "3320960",
    "end": "3326680"
  },
  {
    "text": "kind of scenarios are are super cool for me whenever they would be able to come",
    "start": "3326680",
    "end": "3332839"
  },
  {
    "text": "true yeah this is Mu Bueno and um yeah I've been been really really excited to",
    "start": "3332839",
    "end": "3338880"
  },
  {
    "text": "to talk to you both and would love to have you both back on the show sometime to update on those things thank you for",
    "start": "3338880",
    "end": "3345720"
  },
  {
    "text": "what you all are doing both in in terms of tooling and um you know uh argila and",
    "start": "3345720",
    "end": "3350960"
  },
  {
    "text": "hugging face more broadly in terms of of how you're driving things uh forward in the community and",
    "start": "3350960",
    "end": "3356799"
  },
  {
    "text": "especially the the open source side so thank you both thank you for taking time to to talk with us and um hope to talk",
    "start": "3356799",
    "end": "3363960"
  },
  {
    "text": "again soon yeah thank you and thanks for having us thank [Music]",
    "start": "3363960",
    "end": "3374640"
  },
  {
    "text": "you all right that is practical AI for this week subscribe now if you haven't",
    "start": "3374640",
    "end": "3381480"
  },
  {
    "text": "already head to practical a.m for all the ways and join our free slack team",
    "start": "3381480",
    "end": "3388319"
  },
  {
    "text": "where you can hang out with Daniel Chris and the entire change log Community sign up today at practical ai. fm/ Community",
    "start": "3388319",
    "end": "3398319"
  },
  {
    "text": "thanks again to our partners at fly.io to our beat freaking residence breakmaster cylinder and to you for",
    "start": "3398319",
    "end": "3404839"
  },
  {
    "text": "listening we appreciate you spending time with us that's all for now we'll talk to you again next time",
    "start": "3404839",
    "end": "3413240"
  },
  {
    "text": "[Music]",
    "start": "3415130",
    "end": "3420640"
  },
  {
    "text": "K look",
    "start": "3420640",
    "end": "3423760"
  }
]
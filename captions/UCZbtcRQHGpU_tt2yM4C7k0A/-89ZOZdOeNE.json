[
  {
    "text": "we have started a project on this it's to combine these systems this quality estimation systems with the machine",
    "start": "480",
    "end": "6720"
  },
  {
    "text": "translation itself so that is something that we started working on this but I believe that you can work on this for",
    "start": "6720",
    "end": "13000"
  },
  {
    "text": "the next few years and there is a lot of things that we can improve there yeah that gets me really excited I think it's",
    "start": "13000",
    "end": "19720"
  },
  {
    "text": "a a direction that it's going to be really nice this is the quality aware decoding project that is basically what",
    "start": "19720",
    "end": "26279"
  },
  {
    "text": "I just mentioned about what we have been talking about of having this quality predictions about the hypothesis",
    "start": "26279",
    "end": "32879"
  },
  {
    "text": "translations the idea behind this project that uh hiard is talking about is what if we bring the quality",
    "start": "32879",
    "end": "38200"
  },
  {
    "text": "estimation or comment already to inside the Mt process and then we can make the",
    "start": "38200",
    "end": "45399"
  },
  {
    "text": "machine translation aware or more aware about its quality having a signal from a",
    "start": "45399",
    "end": "50559"
  },
  {
    "text": "different model so this is what this project is",
    "start": "50559",
    "end": "54960"
  },
  {
    "text": "about [Music]",
    "start": "58920",
    "end": "63049"
  },
  {
    "text": "welcome to practical AI a weekly podcast making artificial intelligence practical",
    "start": "64400",
    "end": "69960"
  },
  {
    "text": "productive and accessible to everyone subscribe now if you haven't already head to practical a FM for all the ways",
    "start": "69960",
    "end": "77400"
  },
  {
    "text": "special thanks to our partners at fastly for delivering our shows super fast to wherever you listen check them out at",
    "start": "77400",
    "end": "84360"
  },
  {
    "text": "f.com and to our friends at fly.io we deploy our app servers close to our",
    "start": "84360",
    "end": "90040"
  },
  {
    "text": "users and you can too learn more at [Music]",
    "start": "90040",
    "end": "99040"
  },
  {
    "text": "fly.io welcome to another episode of practical AI this is Daniel whack I'm a",
    "start": "99040",
    "end": "104320"
  },
  {
    "text": "data scientist with SI International and I'm joined this week by Ricardo Ray and",
    "start": "104320",
    "end": "110799"
  },
  {
    "text": "Jose Souza from unbabel uh here at emnlp 2022 in Abu Dhabi how you doing guys hi",
    "start": "110799",
    "end": "117759"
  },
  {
    "text": "we are fine hi good yeah how's uh emlp for you so so far we have been mostly",
    "start": "117759",
    "end": "123880"
  },
  {
    "text": "attending a WMT Workshop yeah and what's the WMT what is that stand for right WMT",
    "start": "123880",
    "end": "130200"
  },
  {
    "text": "stands for workshop on statistical translation workshop on machine translation on machine translation but",
    "start": "130200",
    "end": "135720"
  },
  {
    "text": "it was this is an historical acronym because it's actually now a a conference",
    "start": "135720",
    "end": "141120"
  },
  {
    "text": "it's I would say that it's the main Conference of machine translation and it has been happening for several years and",
    "start": "141120",
    "end": "148120"
  },
  {
    "text": "it's always collocated with the M NP so it's nice because it's one of the biggest NLP conferences together with",
    "start": "148120",
    "end": "155200"
  },
  {
    "text": "the biggest Mt conference yeah it's mostly attended by uh researchers so not",
    "start": "155200",
    "end": "162000"
  },
  {
    "text": "so much about by people in localization industry but it's interesting to know",
    "start": "162000",
    "end": "167400"
  },
  {
    "text": "what's happening in terms of research the latest approaches and methodologies for evaluation as well so yeah and is",
    "start": "167400",
    "end": "174840"
  },
  {
    "text": "that the industry that unbabel is in could you just give people a little bit of an understanding of what unb is sure",
    "start": "174840",
    "end": "180920"
  },
  {
    "text": "so amabo is a translation company we provide translations trying to unite The",
    "start": "180920",
    "end": "187799"
  },
  {
    "text": "Best of Both Worlds which is using machine translation and professional translators to provide these",
    "start": "187799",
    "end": "194159"
  },
  {
    "text": "translations and The Best of Both Worlds what because if you only rely on",
    "start": "194159",
    "end": "199440"
  },
  {
    "text": "translators themselves it's very difficult to scale this process of translation to different volumes of",
    "start": "199440",
    "end": "205599"
  },
  {
    "text": "content and that's why you use machine translation to speed up this process and then use the translators to correct if",
    "start": "205599",
    "end": "213400"
  },
  {
    "text": "necessary and that's I I think the biggest uh difference of ubble to other",
    "start": "213400",
    "end": "219200"
  },
  {
    "text": "companies which is we are the Pioneers to use something called quality estimation to actually decide whether if",
    "start": "219200",
    "end": "226319"
  },
  {
    "text": "we should post edit or not the translations and I guess uh we we are",
    "start": "226319",
    "end": "231360"
  },
  {
    "text": "big on also evaluation technology evaluation and I think hiard can talk about Comet yeah like what J explained",
    "start": "231360",
    "end": "240879"
  },
  {
    "text": "about the difference between combining humans and mty so if you have a mechanism that tells you that your",
    "start": "240879",
    "end": "247200"
  },
  {
    "text": "machine transation output is perfect then you don't need a human but for you",
    "start": "247200",
    "end": "252439"
  },
  {
    "text": "to do this you clearly need a very reliable quality estimation system A",
    "start": "252439",
    "end": "257919"
  },
  {
    "text": "system that receives that translation and is able to give you an accurate score for that translation and that's",
    "start": "257919",
    "end": "264840"
  },
  {
    "text": "why uh andb has been focusing for so many years on specific specifically",
    "start": "264840",
    "end": "270160"
  },
  {
    "text": "quality estimation and also evaluation evaluation it's a little bit more",
    "start": "270160",
    "end": "275280"
  },
  {
    "text": "General it can also include things like metrics where you compare the translation output with a a reference",
    "start": "275280",
    "end": "282000"
  },
  {
    "text": "translation that you believe to be perfect and it's what people typically use when training models and stuff like",
    "start": "282000",
    "end": "287639"
  },
  {
    "text": "that for the past few years we have been developing a metric that is uh being widely adopt by the research community",
    "start": "287639",
    "end": "294800"
  },
  {
    "text": "and also the industry which is called Comet comet has been very successful in",
    "start": "294800",
    "end": "300680"
  },
  {
    "text": "the last two years and yeah it was developed by us um we also developed a a",
    "start": "300680",
    "end": "307199"
  },
  {
    "text": "quality estimation framework that was also gained a lot of the traction three",
    "start": "307199",
    "end": "312479"
  },
  {
    "text": "years ago I think yeah 2019 it was yeah called open qwi which is basically",
    "start": "312479",
    "end": "318759"
  },
  {
    "text": "similar in the in terms of the model approach and everything but it does not rely on a reference so it's what we use",
    "start": "318759",
    "end": "326479"
  },
  {
    "text": "internally for performing quality estimation yeah I think this sums up a little bit that that said just one thing",
    "start": "326479",
    "end": "333520"
  },
  {
    "text": "is that all of this is only possible because over the years andabo established some quality controls for",
    "start": "333520",
    "end": "339720"
  },
  {
    "text": "the translations and uh this is started by using something a framework called",
    "start": "339720",
    "end": "346360"
  },
  {
    "text": "MQM which stands for multi-dimensional Quality metric which is basically a",
    "start": "346360",
    "end": "352199"
  },
  {
    "text": "typology and then guidelines on how to use this typology with different phenomena that happens when people when",
    "start": "352199",
    "end": "359240"
  },
  {
    "text": "transl is made that goes from accuracy you know whether the the translations are",
    "start": "359240",
    "end": "366000"
  },
  {
    "text": "adequate if they're fluent and then there's a whole taxonomy about that so",
    "start": "366000",
    "end": "371639"
  },
  {
    "text": "this kind of evaluation enabled us to accumulate data about the quality of",
    "start": "371639",
    "end": "377120"
  },
  {
    "text": "translations over time that we can then use to train quality estimation or a",
    "start": "377120",
    "end": "382240"
  },
  {
    "text": "metric uh evolation models yeah so this seems different I I think some listeners",
    "start": "382240",
    "end": "387639"
  },
  {
    "text": "probably in their experience with like modeling in other domains or with other data are probably familiar with like a",
    "start": "387639",
    "end": "394120"
  },
  {
    "text": "confidence score or a probability so this goes like Way Beyond that right so just to clarify this is not like just a",
    "start": "394120",
    "end": "400919"
  },
  {
    "text": "a confidence score coming out of your model like the of of translation but this is actually a metric that you're",
    "start": "400919",
    "end": "407160"
  },
  {
    "text": "running on the output of your model is that right exactly yeah exactly yeah and",
    "start": "407160",
    "end": "412280"
  },
  {
    "text": "um so explain maybe um comment a little bit because that has like gained so much traction what is maybe different about",
    "start": "412280",
    "end": "419919"
  },
  {
    "text": "Comet another you know popular one I know for machine translation is called Blue so what distinguishes comet as",
    "start": "419919",
    "end": "427240"
  },
  {
    "text": "different from maybe that or like other metrics that are out there so like you were saying blur is a very well-known",
    "start": "427240",
    "end": "434440"
  },
  {
    "text": "metric but BL is a lexical metric and this means that blur will take the empty",
    "start": "434440",
    "end": "440400"
  },
  {
    "text": "output and it will compare with a reference that was created from a human",
    "start": "440400",
    "end": "446000"
  },
  {
    "text": "and usually the typical setup is that we we only compare that empty output with a",
    "start": "446000",
    "end": "451440"
  },
  {
    "text": "single reference and as we might know there are multiple ways to to translate",
    "start": "451440",
    "end": "457639"
  },
  {
    "text": "a specific sentence so a lot of times blow will give a very low score for a",
    "start": "457639",
    "end": "463599"
  },
  {
    "text": "very good translation because of that sometimes it also gives you a very high score for a b a very bad translation",
    "start": "463599",
    "end": "471479"
  },
  {
    "text": "because of another aspect of B it's that it's going to give the same weight to all worlds so if you have a a named",
    "start": "471479",
    "end": "478800"
  },
  {
    "text": "entity that is is not correctly translated it's going to be like one word that is missing from being perfect",
    "start": "478800",
    "end": "486599"
  },
  {
    "text": "and blow will give a very high score if you miss like a punctuation the score",
    "start": "486599",
    "end": "491720"
  },
  {
    "text": "penalty will be exactly the same although the errors are completely different in terms of severity just one",
    "start": "491720",
    "end": "497120"
  },
  {
    "text": "thing uh to differentiate between just to explain a little bit more blur is that the way that it looks at both the",
    "start": "497120",
    "end": "504199"
  },
  {
    "text": "translation hypothesis and the references looking at the each word and trying to understand if there is an",
    "start": "504199",
    "end": "511000"
  },
  {
    "text": "overlap of each word with the reference so and it does that for combinations of",
    "start": "511000",
    "end": "516919"
  },
  {
    "text": "for for one or or for combinations of two three and four words usually which you call engrams so and then it has a",
    "start": "516919",
    "end": "524360"
  },
  {
    "text": "brevity penalty that is basically to penalize if the translation is too small to too too short so that's basically the",
    "start": "524360",
    "end": "531480"
  },
  {
    "text": "rational and there is a class of Matrix uh called like that I think we are calling lexical Matrix yeah lexical",
    "start": "531480",
    "end": "537640"
  },
  {
    "text": "Matrix yeah uh so TR which is translation error rate it's similar to that chrf it's similar to that but chrf",
    "start": "537640",
    "end": "544920"
  },
  {
    "text": "goes at the Character level so this is a class of things that is very different",
    "start": "544920",
    "end": "550000"
  },
  {
    "text": "from Comet I think yeah Comet takes advantage of uh the representations",
    "start": "550000",
    "end": "555160"
  },
  {
    "text": "coming for large language models like xlm herberta we have been using xlm herberta and uh basically those",
    "start": "555160",
    "end": "562279"
  },
  {
    "text": "representations allow you to compare words in a embedding space so two words that might not be exactly the same but",
    "start": "562279",
    "end": "568200"
  },
  {
    "text": "have the exact same meaning the comet will use those representations",
    "start": "568200",
    "end": "573600"
  },
  {
    "text": "to Output a score now the other thing that we add on top is that we train",
    "start": "573600",
    "end": "579720"
  },
  {
    "text": "those representations to be more suitable for the specific task of a",
    "start": "579720",
    "end": "585160"
  },
  {
    "text": "machine translation evaluation and I'm saying this because this is a very important difference from other metrics",
    "start": "585160",
    "end": "591839"
  },
  {
    "text": "that have also been proposed like Bird score where because of the fact that you don't have any fine tuning on top if you",
    "start": "591839",
    "end": "599880"
  },
  {
    "text": "use Bird score and you you say I love you or I hate you because love and hate",
    "start": "599880",
    "end": "605839"
  },
  {
    "text": "will have similar embeddings the score will be very high when in fact they are",
    "start": "605839",
    "end": "611440"
  },
  {
    "text": "the complete opposites so we start from a pre-training model but then by",
    "start": "611440",
    "end": "616959"
  },
  {
    "text": "training the model with some supervision from Human labels on errors the model",
    "start": "616959",
    "end": "623560"
  },
  {
    "text": "learns that I love you or I hate you on for this specific task they are complete",
    "start": "623560",
    "end": "629360"
  },
  {
    "text": "opposite and I I think that kind of splits apart Comet from all the metrics",
    "start": "629360",
    "end": "635120"
  },
  {
    "text": "that were being proposed before that either fall into the lexical category or into the embedding category yeah that's",
    "start": "635120",
    "end": "642200"
  },
  {
    "text": "great and you also mentioned um just in passing like there was another kind of category of quality estimation that",
    "start": "642200",
    "end": "648519"
  },
  {
    "text": "didn't require a reference could you talk about that a little bit Yeah so the idea is very similar to the idea of",
    "start": "648519",
    "end": "654399"
  },
  {
    "text": "comet so the difference is that when you have access to a reference which is the case of comet but when you create the",
    "start": "654399",
    "end": "661320"
  },
  {
    "text": "embeddings for the empty output they will be perfectly aligned with the embeddings from the reference because",
    "start": "661320",
    "end": "667920"
  },
  {
    "text": "they are in on the exact same language on quality estimation you are comparing",
    "start": "667920",
    "end": "673200"
  },
  {
    "text": "it directly to the source so the embeddings will not align perfectly and",
    "start": "673200",
    "end": "678959"
  },
  {
    "text": "still what happens is that during training using human supervision the model learns to what is correct and what",
    "start": "678959",
    "end": "686320"
  },
  {
    "text": "is incorrect only comparing the empty output direct with the with the source",
    "start": "686320",
    "end": "692519"
  },
  {
    "text": "so quality estimation serves a different kind of application than the metrix like blow chrf and Comet which is usually I",
    "start": "692519",
    "end": "701160"
  },
  {
    "text": "want to know what is the quality of specific sentences or translations given their Source sentences for Comet usually",
    "start": "701160",
    "end": "708440"
  },
  {
    "text": "what you're more interested Comet or or the other uh metrics you're more interested in understanding the",
    "start": "708440",
    "end": "713880"
  },
  {
    "text": "difference between models or Mt systems so you're evaluating at some sort of try",
    "start": "713880",
    "end": "719519"
  },
  {
    "text": "to understand at some sort of um test set level or evaluation set level so that you can decide whether I go with",
    "start": "719519",
    "end": "725800"
  },
  {
    "text": "model empty Model A B or C and then in quality estimation is basically to take",
    "start": "725800",
    "end": "730920"
  },
  {
    "text": "decisions on the fly at real time in which I cannot wait for someone to make a reference or a post Edition and decide",
    "start": "730920",
    "end": "738720"
  },
  {
    "text": "okay can I thrust this translation if I don't should I throw it out is that bad",
    "start": "738720",
    "end": "743839"
  },
  {
    "text": "that they should do it from scratch or I can still give it to someone that can repurpose this and rephrase it you know",
    "start": "743839",
    "end": "750560"
  },
  {
    "text": "so they are slightly different in their applications but this is something that you can talk about about Trends uh they",
    "start": "750560",
    "end": "756680"
  },
  {
    "text": "start to like I think hiard was teasing to intersect themselves a bit I would",
    "start": "756680",
    "end": "763480"
  },
  {
    "text": "say that the the metric field so the evaluation on the metrix side was stuck",
    "start": "763480",
    "end": "769800"
  },
  {
    "text": "with BL for a long time quality estimation on the other hand was I feel",
    "start": "769800",
    "end": "775199"
  },
  {
    "text": "that there were more research and more innovation on that field actually that",
    "start": "775199",
    "end": "781040"
  },
  {
    "text": "was our motivation when we built Comet we tried to replicate what was being done the stateof of the-art of what was",
    "start": "781040",
    "end": "787519"
  },
  {
    "text": "being done on quality estimation we tried to bring it to the metric field",
    "start": "787519",
    "end": "792760"
  },
  {
    "text": "and now the modeling approaches are very similar but it was viewed as two",
    "start": "792760",
    "end": "798279"
  },
  {
    "text": "completely different tasks for years so just just to give Insight on what uh a",
    "start": "798279",
    "end": "804519"
  },
  {
    "text": "bit of context on on what hiard said about the progress in quality estimation so I did my PhD on working on this uh",
    "start": "804519",
    "end": "812000"
  },
  {
    "text": "kind of problem and I I finished like in 2015 so I was working from 2012 until",
    "start": "812000",
    "end": "818480"
  },
  {
    "text": "2015 on problems around this and the approaches back then they were basically",
    "start": "818480",
    "end": "823880"
  },
  {
    "text": "using feature based approaches like classical machine learning and with deep",
    "start": "823880",
    "end": "829160"
  },
  {
    "text": "learning and access to embeddings and now large protain models this very very",
    "start": "829160",
    "end": "836519"
  },
  {
    "text": "fast shifted to to this kind of approach and the performance of these models of",
    "start": "836519",
    "end": "842279"
  },
  {
    "text": "this approaches also are much better than when I used to First work on this",
    "start": "842279",
    "end": "847399"
  },
  {
    "text": "so the quality of these quality submission models nowadays that they are very useful you can actually do a lot of",
    "start": "847399",
    "end": "853000"
  },
  {
    "text": "things with them like I was saying and yeah I just wanted to complement that because for me it was I was not working",
    "start": "853000",
    "end": "858480"
  },
  {
    "text": "on the field specifically this problem for I don't know three years I guess when I came back to it it was wow now",
    "start": "858480",
    "end": "865480"
  },
  {
    "text": "it's really up to everything you know",
    "start": "865480",
    "end": "871040"
  },
  {
    "text": "could you explain a little bit so you mentioned how like in Comet or in these other models you might be comparing like",
    "start": "876759",
    "end": "882639"
  },
  {
    "text": "the embeddings of of words but I words don't always map like one to one between",
    "start": "882639",
    "end": "888279"
  },
  {
    "text": "languages and sometimes I don't know if you're looking at sentences or other things but could you describe like some",
    "start": "888279",
    "end": "893519"
  },
  {
    "text": "of the I guess what are the main challenges looking forward that like aren't solved yet in terms of like next",
    "start": "893519",
    "end": "899800"
  },
  {
    "text": "steps with quality estimation and things that you're looking at now that you see as as open problems yeah you actually",
    "start": "899800",
    "end": "906000"
  },
  {
    "text": "touched a very nice very nice point it's I wouldn't say that it's not that the",
    "start": "906000",
    "end": "911600"
  },
  {
    "text": "words don't align very well but sometimes what we see is that the embeding themselves for certain specific",
    "start": "911600",
    "end": "918880"
  },
  {
    "text": "uh words are not uh discriminative enough and we have seen some for",
    "start": "918880",
    "end": "925000"
  },
  {
    "text": "instance if you translate the sentence this IPO costs 50 cents you translate it to Portuguese and the translation needs",
    "start": "925000",
    "end": "932079"
  },
  {
    "text": "I'm not going to say it in Portuguese but pretend that I'm speaking portes the perfect translation would also be 50 cents but for some reason DMT might have",
    "start": "932079",
    "end": "939199"
  },
  {
    "text": "hallucinated and say that it's 500 cents so it's basically changing the price of",
    "start": "939199",
    "end": "945360"
  },
  {
    "text": "an nio and this is a critical error in much scenarios but if you look at the",
    "start": "945360",
    "end": "950440"
  },
  {
    "text": "embedding space of the 500 or the embedding of 5050 it's going to be very",
    "start": "950440",
    "end": "957600"
  },
  {
    "text": "similar and it's to be very hard for the neuron Network that is trying to",
    "start": "957600",
    "end": "963399"
  },
  {
    "text": "differentiate these two things it's going to be a very hard task because there is no not enough signal you also",
    "start": "963399",
    "end": "970199"
  },
  {
    "text": "see the same thing with some named entities and currently there has been uh",
    "start": "970199",
    "end": "975959"
  },
  {
    "text": "some work some progress in trying to look at the Quality estimation and metrics and try to figure out why they",
    "start": "975959",
    "end": "982040"
  },
  {
    "text": "are not working for this kind of very specific phenomena actually yesterday we",
    "start": "982040",
    "end": "987480"
  },
  {
    "text": "had a lot of uh presentations about challenge sets that try to test Matrix",
    "start": "987480",
    "end": "993120"
  },
  {
    "text": "for this specific phenomena so in WMT we have several competitions several what",
    "start": "993120",
    "end": "999759"
  },
  {
    "text": "we call share tasks and um inside the metrix share task where people are trying to compete to create better",
    "start": "999759",
    "end": "1006720"
  },
  {
    "text": "metric there was also a share task that it's we call this challenge set subtask",
    "start": "1006720",
    "end": "1013279"
  },
  {
    "text": "where people submit examples that are challenging for metrics and then the",
    "start": "1013279",
    "end": "1018480"
  },
  {
    "text": "particip ANS from the metrix task have to score those examples and then we get the scores back to the developers of the",
    "start": "1018480",
    "end": "1025438"
  },
  {
    "text": "challenges for them to analyze and a lot of people looked into this and tried to",
    "start": "1025439",
    "end": "1031678"
  },
  {
    "text": "make some suggestions for future work in how to improve metrics for this so if you guys are interested in this I take a",
    "start": "1031679",
    "end": "1039160"
  },
  {
    "text": "look at the findings from the metric task cuz they are interesting findings on on and pointers for future work in",
    "start": "1039160",
    "end": "1045640"
  },
  {
    "text": "this this area one of the problems of this model based Mt evaluation",
    "start": "1045640",
    "end": "1051200"
  },
  {
    "text": "approaches is that you know first they are based on the data that the pre-train models were trained on so there there's",
    "start": "1051200",
    "end": "1059440"
  },
  {
    "text": "everything there there's bias and there's the limited amount or it can be a lot of data as well but all the",
    "start": "1059440",
    "end": "1066400"
  },
  {
    "text": "idiosyncrasies of that data are encoded in the pre-train models then when you fine-tune this for the specific tasks",
    "start": "1066400",
    "end": "1073720"
  },
  {
    "text": "that they they need to work on namely quality estimation and Mt evaluation they also are limited in in data in the",
    "start": "1073720",
    "end": "1080960"
  },
  {
    "text": "sense that we have orders of magnitude less label data for this F tuning",
    "start": "1080960",
    "end": "1086000"
  },
  {
    "text": "process so this can have its biases and it can have also like uh taking the",
    "start": "1086000",
    "end": "1091440"
  },
  {
    "text": "example of Apple for some reason you you never seen Apple the company but you saw only for the fruit so you start to every",
    "start": "1091440",
    "end": "1098559"
  },
  {
    "text": "time you see apple you translate that to the fruit you know uh you you actually say that it's if the model translates",
    "start": "1098559",
    "end": "1103960"
  },
  {
    "text": "that to the to the fruit the evaluation thing is going to say ah it's fine because in the evaluation data that you",
    "start": "1103960",
    "end": "1110120"
  },
  {
    "text": "used to train the the model you never saw for some reason the brand so and",
    "start": "1110120",
    "end": "1115280"
  },
  {
    "text": "this is related to the named entity problem that hiard was saying so I think",
    "start": "1115280",
    "end": "1121440"
  },
  {
    "text": "one step we are giving the first step as a community to understand that now and you know really poke it and see okay",
    "start": "1121440",
    "end": "1128159"
  },
  {
    "text": "there's a hole here uh and now the next step is how to you know alleviate that",
    "start": "1128159",
    "end": "1133960"
  },
  {
    "text": "problem I I don't think it's possible to alleviate completely solve but we are for sure I I will try to alleviate this",
    "start": "1133960",
    "end": "1140520"
  },
  {
    "text": "for these models now there is a and there are a lot of complaints also of people not complaints but you know even",
    "start": "1140520",
    "end": "1147320"
  },
  {
    "text": "us when we are using different models not only ours we see that these models fall short sometimes and this can be",
    "start": "1147320",
    "end": "1154039"
  },
  {
    "text": "very bad in a commercial setting or even in sensitive scenarios in which if you",
    "start": "1154039",
    "end": "1159760"
  },
  {
    "text": "get two cents and the translate the the model that translated this to I don't know 2 million that's not very nice",
    "start": "1159760",
    "end": "1167360"
  },
  {
    "text": "right you might have some legal implications with that so yeah I don't",
    "start": "1167360",
    "end": "1172400"
  },
  {
    "text": "know other other other open problems I think for me one big problem is that and",
    "start": "1172400",
    "end": "1178400"
  },
  {
    "text": "and this is also Trend that we see in the metrix and in the quality estimation task is that bigger models have better",
    "start": "1178400",
    "end": "1184400"
  },
  {
    "text": "predictive power so people usually what they are doing is just throw more gpus",
    "start": "1184400",
    "end": "1190760"
  },
  {
    "text": "at it and and just train a bigger model and this seems to be giving improvements as well but the problem is that not",
    "start": "1190760",
    "end": "1198039"
  },
  {
    "text": "every prot ier can actually use these models once they are trained because they take they need bigger and bigger uh",
    "start": "1198039",
    "end": "1205679"
  },
  {
    "text": "gpus which are costlier even at inference time so we actually had a",
    "start": "1205679",
    "end": "1210919"
  },
  {
    "text": "paper in EMT the European Association for machine translation conference that was actually making Comet smaller and",
    "start": "1210919",
    "end": "1219080"
  },
  {
    "text": "it's like a diminutive in the name of the paper the name of the model is Comino which is a diminutive of comet",
    "start": "1219080",
    "end": "1225799"
  },
  {
    "text": "like Portuguese very Portuguese way to say it and it was also a first step towards",
    "start": "1225799",
    "end": "1230919"
  },
  {
    "text": "that but I think there's a lot to be done for all the other models and also for Comet yeah definitely I I think uh",
    "start": "1230919",
    "end": "1237480"
  },
  {
    "text": "cometin was just a first step into that direction we there is a lot of things that can be improved in distillation of",
    "start": "1237480",
    "end": "1244799"
  },
  {
    "text": "these models even the evaluation models like we did for com and not just for evaluation we have been focusing this",
    "start": "1244799",
    "end": "1252240"
  },
  {
    "text": "podcast a little bit on evaluation but um on machine translation you have the",
    "start": "1252240",
    "end": "1257679"
  },
  {
    "text": "same problem on machine translation bigger models have been um achieving",
    "start": "1257679",
    "end": "1263320"
  },
  {
    "text": "impressive machine translation quality but it's very hard for everyone to",
    "start": "1263320",
    "end": "1268720"
  },
  {
    "text": "develop those models and it's even harder for for people to deploy those models um we face this at in bble we",
    "start": "1268720",
    "end": "1276360"
  },
  {
    "text": "develop our own machine translation systems and we have seen this trend we get improvements if we keep scaling our",
    "start": "1276360",
    "end": "1283720"
  },
  {
    "text": "empties but then we have difficulties serving those empties and uh it's also",
    "start": "1283720",
    "end": "1291080"
  },
  {
    "text": "we know that not every company has the capacity to build such big models like",
    "start": "1291080",
    "end": "1296240"
  },
  {
    "text": "uh big tech companies develop so yeah it's not just in the evaluation side but",
    "start": "1296240",
    "end": "1301679"
  },
  {
    "text": "also in the machine translation side it is like something that people should look forward to it's without losing",
    "start": "1301679",
    "end": "1307559"
  },
  {
    "text": "performance how to make these things smaller and easier to deploy yeah when",
    "start": "1307559",
    "end": "1312640"
  },
  {
    "text": "you say on the so on the model side specifically like Jose you mentioned sort of models getting bigger and bigger",
    "start": "1312640",
    "end": "1320360"
  },
  {
    "text": "um some people might have seen like nice uh gify about like an encoder decoder in",
    "start": "1320360",
    "end": "1326200"
  },
  {
    "text": "one language coming in and one language coming out and Transformer models but what what are some things others are",
    "start": "1326200",
    "end": "1332120"
  },
  {
    "text": "exploring maybe yourselves that like are either um different approaches or you mentioned distillation all these other",
    "start": "1332120",
    "end": "1338159"
  },
  {
    "text": "things to make models smaller but are there um different architectures or techniques being explored I think I saw",
    "start": "1338159",
    "end": "1344720"
  },
  {
    "text": "one of your papers something about like KNN Mt or something I don't know if you can speak to that but yeah we just at",
    "start": "1344720",
    "end": "1351640"
  },
  {
    "text": "this moment there is a poster on the usage of kmt for the chat share task so",
    "start": "1351640",
    "end": "1357679"
  },
  {
    "text": "this is something called I think this is broadly called Dynamic adaptation and one approach to that is doing kmt that",
    "start": "1357679",
    "end": "1365880"
  },
  {
    "text": "rather than actually fully fine-tuning one base model like one of these large prain models you actually just do some",
    "start": "1365880",
    "end": "1373679"
  },
  {
    "text": "data retrieval approach in which you combine the contents of a dat store that",
    "start": "1373679",
    "end": "1379320"
  },
  {
    "text": "has relevant data for the use case that you're trying to serve with machine translation and then at decoding time",
    "start": "1379320",
    "end": "1385799"
  },
  {
    "text": "when you are assembling the translation using the translation probabilities of the model you interpolate these",
    "start": "1385799",
    "end": "1392240"
  },
  {
    "text": "probabilities with the probabilities of words or Expressions contained in the in",
    "start": "1392240",
    "end": "1397720"
  },
  {
    "text": "the data store so this way you avoid having to fully fine-tune a model for",
    "start": "1397720",
    "end": "1402919"
  },
  {
    "text": "each use case that you have and this is something that we started to research and Approach at babble but I just must",
    "start": "1402919",
    "end": "1409400"
  },
  {
    "text": "say that this doesn't solve the problem of the base model being big you just avoid fine-tuning it completely so",
    "start": "1409400",
    "end": "1416960"
  },
  {
    "text": "there's still the problem of okay how do I shrink or compress this model so that",
    "start": "1416960",
    "end": "1423320"
  },
  {
    "text": "it can reliably and cheaply explor it for translation and this is like you",
    "start": "1423320",
    "end": "1430520"
  },
  {
    "text": "said distillation quantization and other compressing techniques just complement",
    "start": "1430520",
    "end": "1436559"
  },
  {
    "text": "what uh was saying about the the Keen nearest neighbor approach another very",
    "start": "1436559",
    "end": "1442880"
  },
  {
    "text": "big advantage of this is that it's very easy to combine with translation memories which we know that they are",
    "start": "1442880",
    "end": "1448799"
  },
  {
    "text": "wildly used in a translation industry and this is a seamless way to basically",
    "start": "1448799",
    "end": "1454279"
  },
  {
    "text": "take the Mt and make the Mt work with those translation memories because you can build this data store that will help",
    "start": "1454279",
    "end": "1460760"
  },
  {
    "text": "the model to translate the content accordingly so just to add that also",
    "start": "1460760",
    "end": "1466480"
  },
  {
    "text": "which I believe that it's very important for the localization uh industry in general great yeah well we've talked a",
    "start": "1466480",
    "end": "1473919"
  },
  {
    "text": "lot about uh challenges I guess which is is fun to talk about at a at a research conference for sure what are what are",
    "start": "1473919",
    "end": "1480200"
  },
  {
    "text": "some things just like generally about like the machine translation industry or or unbabel or other things that you make",
    "start": "1480200",
    "end": "1487679"
  },
  {
    "text": "both of you sort of excited and you know optimistic about the future what are some of those things that that excite",
    "start": "1487679",
    "end": "1493559"
  },
  {
    "text": "you it doesn't have to be an Mt or you know things you've seen at this conference or things that you're following that give you some um",
    "start": "1493559",
    "end": "1500559"
  },
  {
    "text": "encouragement and excitement about the future of the space where we're working actually I'm very passionate about the",
    "start": "1500559",
    "end": "1506720"
  },
  {
    "text": "evaluation in general I think that shows up in my work cuz I I mostly work on evaluation I've been getting very",
    "start": "1506720",
    "end": "1513880"
  },
  {
    "text": "excited with the progress that we have been doing in evaluation I think um like",
    "start": "1513880",
    "end": "1519559"
  },
  {
    "text": "we have started a project on this that we it's to combine these systems this",
    "start": "1519559",
    "end": "1524720"
  },
  {
    "text": "quality estimation systems with the machine translation itself self so that",
    "start": "1524720",
    "end": "1529840"
  },
  {
    "text": "is something that we we started working on this but I I believe that you can work on this for the next few years and",
    "start": "1529840",
    "end": "1536880"
  },
  {
    "text": "there is a lot of things that we can improve there yeah that gets me really excited I think it's a a direction that",
    "start": "1536880",
    "end": "1543279"
  },
  {
    "text": "it's going to be really nice yeah uh this is the quality aware uh decoding",
    "start": "1543279",
    "end": "1548679"
  },
  {
    "text": "project that is basically what I just mentioned about what we have been talking about of having this quality",
    "start": "1548679",
    "end": "1554679"
  },
  {
    "text": "predictions about the hypothesis translations the a behind this project that uh hiard is talking about is what",
    "start": "1554679",
    "end": "1561320"
  },
  {
    "text": "if we bring the quality estimation or comment already to inside the Mt process",
    "start": "1561320",
    "end": "1567559"
  },
  {
    "text": "and then we can make the machine translation aware or more aware about",
    "start": "1567559",
    "end": "1573320"
  },
  {
    "text": "its quality having a signal from a different model so this is what this project is about so we we have a paper",
    "start": "1573320",
    "end": "1580000"
  },
  {
    "text": "at nro this year uh describing that so yeah this is pretty exciting and I think",
    "start": "1580000",
    "end": "1585799"
  },
  {
    "text": "in terms of uh more broad challenges what I find interesting is that I don't",
    "start": "1585799",
    "end": "1590919"
  },
  {
    "text": "believe that translation is solved I think a few years ago some people",
    "start": "1590919",
    "end": "1596320"
  },
  {
    "text": "claimed that there was human parity between Mt systems or some Mt models and",
    "start": "1596320",
    "end": "1602440"
  },
  {
    "text": "humans and translators but then what it turned out that the actual translators",
    "start": "1602440",
    "end": "1608840"
  },
  {
    "text": "that were used were not really professional translators like I know English right but I'm not a native",
    "start": "1608840",
    "end": "1615080"
  },
  {
    "text": "speaker and I cannot translate everything so I'm not a subject matter expert on different topics so I cannot",
    "start": "1615080",
    "end": "1621399"
  },
  {
    "text": "actually if you give me some chemistry content to translate into English from Portuguese I I I I cannot do it right so",
    "start": "1621399",
    "end": "1628640"
  },
  {
    "text": "I think what's exciting is to see that the technology is allowing us to translate better and better maybe",
    "start": "1628640",
    "end": "1633880"
  },
  {
    "text": "compared to me as a non-native speaker when I'm translating some content but",
    "start": "1633880",
    "end": "1638960"
  },
  {
    "text": "still there's a lot of there are a lot of challenges to actually translate very well very specific content that is um",
    "start": "1638960",
    "end": "1647080"
  },
  {
    "text": "you know requires very specific terminology and very specific way of",
    "start": "1647080",
    "end": "1653159"
  },
  {
    "text": "actually building the sentences and what is much better is actually the fluency",
    "start": "1653159",
    "end": "1658799"
  },
  {
    "text": "that these machine translation models are giving nowadays but what remains still a challenge is that sometimes the",
    "start": "1658799",
    "end": "1665600"
  },
  {
    "text": "translations they look very good but they are not on point so they are not adequate they are talking about",
    "start": "1665600",
    "end": "1670880"
  },
  {
    "text": "something slightly different or completely different so I think this is exciting I mean not not everything is",
    "start": "1670880",
    "end": "1677559"
  },
  {
    "text": "solved but at the same time is encouraging right is encouraging in this sense so yeah uh great well as we close",
    "start": "1677559",
    "end": "1683559"
  },
  {
    "text": "out here um where can people find out more about unbabel and specifically maybe some of this uh research that",
    "start": "1683559",
    "end": "1690080"
  },
  {
    "text": "that's going on and and also um uh you mentioned beforehand that unbabel was possibly hiring as well where could",
    "start": "1690080",
    "end": "1696519"
  },
  {
    "text": "people find out about that right so we have our website like babble.com and we have our Twitter handle like at amabo",
    "start": "1696519",
    "end": "1703960"
  },
  {
    "text": "you can follow our news from there we are just put up a research blog in which",
    "start": "1703960",
    "end": "1709960"
  },
  {
    "text": "we are going to be uh writing about our research this is going to be possibly in",
    "start": "1709960",
    "end": "1715600"
  },
  {
    "text": "the links in your info box I don't know yeah we'll put it in the show notes for sure and yeah um we are also hiring soon",
    "start": "1715600",
    "end": "1722600"
  },
  {
    "text": "like we are starting to accept applications for the next year for uh research scientists uh in different",
    "start": "1722600",
    "end": "1729200"
  },
  {
    "text": "levels and different geographies so soab we didn't talk about it but it was born",
    "start": "1729200",
    "end": "1734559"
  },
  {
    "text": "in in Portugal in Lisbon but now we have offices all around the world we have",
    "start": "1734559",
    "end": "1739720"
  },
  {
    "text": "offices in the west coast in the US in the east coast London you know and some other places in Europe and we are going",
    "start": "1739720",
    "end": "1746960"
  },
  {
    "text": "to post this also to give an email for contact for people who are interested in other the research that we're doing and",
    "start": "1746960",
    "end": "1752640"
  },
  {
    "text": "and other works we don't we have open positions not only for research scientists but also for the engineers",
    "start": "1752640",
    "end": "1759240"
  },
  {
    "text": "and other positions that are not technical so well uh yeah thank you Jose thank you Ricardo um really appreciate",
    "start": "1759240",
    "end": "1765559"
  },
  {
    "text": "you taking time I know there's a lot of good posters around to see and all that so thanks for taking time thanks Daniel",
    "start": "1765559",
    "end": "1771200"
  },
  {
    "text": "thank [Music]",
    "start": "1771200",
    "end": "1779880"
  },
  {
    "text": "you all right that is our show for this week if you dig it don't forget to",
    "start": "1779880",
    "end": "1785279"
  },
  {
    "text": "subscribe head to practical a FM for all the ways and if practical AI has",
    "start": "1785279",
    "end": "1790600"
  },
  {
    "text": "benefited your life Pay It Forward by sharing the show with a friend or a colleague word of mouth is the number",
    "start": "1790600",
    "end": "1796320"
  },
  {
    "text": "one way people find shows like ours thanks again to fastly for fronting our static assets to fly.io for backing our",
    "start": "1796320",
    "end": "1803399"
  },
  {
    "text": "Dynamic requests to break master cylinder for the beats and to you for listening we appreciate you that's all",
    "start": "1803399",
    "end": "1809080"
  },
  {
    "text": "for now we'll talk to you again on the next [Music]",
    "start": "1809080",
    "end": "1816019"
  },
  {
    "text": "[Music]",
    "start": "1819040",
    "end": "1822990"
  },
  {
    "text": "one",
    "start": "1824720",
    "end": "1827720"
  }
]
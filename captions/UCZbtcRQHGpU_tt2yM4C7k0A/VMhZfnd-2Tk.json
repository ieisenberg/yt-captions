[
  {
    "text": "bandwith for change log is provided by fastly learn more at fastly.com we move",
    "start": "40",
    "end": "5560"
  },
  {
    "text": "fast and fix things here at change log because of robbar check them out at rar.com and we're hosted on Leno Cloud",
    "start": "5560",
    "end": "11840"
  },
  {
    "text": "servers at the lin.com changelog this episode is brought to you",
    "start": "11840",
    "end": "17279"
  },
  {
    "text": "by digital ocean the simplest Cloud platform out there and we're excited to share they now offer dedicated virtual",
    "start": "17279",
    "end": "24519"
  },
  {
    "text": "droplets and unlike standard droplets which use shared virtual CPU threads they're two performance plans general",
    "start": "24519",
    "end": "31199"
  },
  {
    "text": "purpose and CPU optimized they have dedicated virtual CPU threads this",
    "start": "31199",
    "end": "36399"
  },
  {
    "text": "translates to higher performance and increased consistency during CPU intensive processes so if you have build",
    "start": "36399",
    "end": "42039"
  },
  {
    "text": "boxes cicd video encoding machine learning ad serving Game servers databases batch processing data mining",
    "start": "42039",
    "end": "48960"
  },
  {
    "text": "application servers or active front-end web servers that need to be full Duty CPU all day every day then check out",
    "start": "48960",
    "end": "55640"
  },
  {
    "text": "digital oceans dedicated virtual CPU droplets pricing is very competitive at 40 bucks a month learn more and get",
    "start": "55640",
    "end": "62239"
  },
  {
    "text": "started for free with a $100 credit at do. changelog again do. change",
    "start": "62239",
    "end": "69540"
  },
  {
    "text": "[Music]",
    "start": "69540",
    "end": "72819"
  },
  {
    "text": "[Music]",
    "start": "75390",
    "end": "80479"
  },
  {
    "text": "log welcome to practical AI a weekly podcast about making artificial intelligence practical productive and",
    "start": "80479",
    "end": "87680"
  },
  {
    "text": "accessible to everyone this is where conversations around AI machine learning and data science happen join the",
    "start": "87680",
    "end": "94119"
  },
  {
    "text": "community and select with us around various topics of the show at change.com Community follow us on Twitter we're at",
    "start": "94119",
    "end": "99799"
  },
  {
    "text": "practical aifm and now on to the [Music]",
    "start": "99799",
    "end": "106000"
  },
  {
    "text": "show welcome to another fully connected episode of practical AI where my co-host",
    "start": "106000",
    "end": "113119"
  },
  {
    "text": "Chris and I keep you fully connected with everything that's happening in the AI Community we're going to take some",
    "start": "113119",
    "end": "119520"
  },
  {
    "text": "time to discuss the latest AI news and we'll dig into some learning resources to help you level up your machine",
    "start": "119520",
    "end": "125880"
  },
  {
    "text": "learning game so I'm joined today by my co-host Chris Benson who's a chief strategist for AI high performance",
    "start": "125880",
    "end": "133520"
  },
  {
    "text": "Computing and AI ethics at locki Martin and I'm Daniel whack I'm a data",
    "start": "133520",
    "end": "138920"
  },
  {
    "text": "scientist with s International how's it going Chris it's going great I'm excited",
    "start": "138920",
    "end": "144280"
  },
  {
    "text": "today yeah me too how's how's the week been for you the week's been good uh",
    "start": "144280",
    "end": "150360"
  },
  {
    "text": "just lots of uh lotss of stuff at work uh was traveling about a week ago was up in Boston at live Works um and uh been",
    "start": "150360",
    "end": "158440"
  },
  {
    "text": "doing lots of interesting stuff in high performance Computing and AI ethics and um artificial intelligence as a field",
    "start": "158440",
    "end": "165319"
  },
  {
    "text": "just keeps getting more and more interesting in terms of what we're doing and uh just at large and and all the",
    "start": "165319",
    "end": "170519"
  },
  {
    "text": "places you can go in it so it's great time to be in it yeah well hopefully hopefully I'll survive I'm working on a",
    "start": "170519",
    "end": "176720"
  },
  {
    "text": "little bit of a jet lag right now um as you know last week I was in India which was was great um was in Bangalore but uh",
    "start": "176720",
    "end": "186239"
  },
  {
    "text": "India was great but getting back from India was quite a chore um so it turns out I was on an Air India flight um",
    "start": "186239",
    "end": "194599"
  },
  {
    "text": "which they don't fly through Pakistani airspace because of obvious reasons yeah",
    "start": "194599",
    "end": "201519"
  },
  {
    "text": "um but then while I was in India this tension happened between the US and Iran",
    "start": "201519",
    "end": "206560"
  },
  {
    "text": "and the US put restrictions on planes coming to and fro over Iranian airspace",
    "start": "206560",
    "end": "212760"
  },
  {
    "text": "which is the reroute that Air India does you know as it kind of goes around",
    "start": "212760",
    "end": "218879"
  },
  {
    "text": "Pakistan um and then over the Arctic back to Chicago so finding a route back",
    "start": "218879",
    "end": "225000"
  },
  {
    "text": "to where I needed to get uh turned out to be rather interesting um so uh I got",
    "start": "225000",
    "end": "230959"
  },
  {
    "text": "back a lot later than expected and uh yeah it's I think 2 A.M 2 about 2 a.m.",
    "start": "230959",
    "end": "237159"
  },
  {
    "text": "now in uh in Bangalore so hopefully uh bear with me if I start going off on a",
    "start": "237159",
    "end": "243280"
  },
  {
    "text": "tangent not a problem but we'll wake you up though cuz uh this is a special episode for us it's our 50th episode it",
    "start": "243280",
    "end": "250040"
  },
  {
    "text": "is congratulations on 50th episode pretty crazy it it does so it's gone by",
    "start": "250040",
    "end": "256560"
  },
  {
    "text": "so fast over the past year and uh you know just the the idea that we've put out that much content uh and that we",
    "start": "256560",
    "end": "263479"
  },
  {
    "text": "actually have people that still want to listen to us after doing that um I I'm Amazed by that every day yeah definitely",
    "start": "263479",
    "end": "270560"
  },
  {
    "text": "uh thank you to all the listeners it's been great to kind of gradually get more and more connected to the listeners and",
    "start": "270560",
    "end": "277680"
  },
  {
    "text": "uh listeners engaging on our slack Channel um on LinkedIn and other places it's just really great to hear that",
    "start": "277680",
    "end": "284039"
  },
  {
    "text": "you're appreciating some of the content but also great to hear some of your ideas that we've been able to filter",
    "start": "284039",
    "end": "289880"
  },
  {
    "text": "into the show so keep those coming thank you so much for listening we really appreciate all of you and uh really want",
    "start": "289880",
    "end": "297280"
  },
  {
    "text": "to engage with all of you in in our Comm community so make sure and check that out at ch.com",
    "start": "297280",
    "end": "303960"
  },
  {
    "text": "Community but I I just got to say when when we get messages from people out there or people engaging Us in the",
    "start": "303960",
    "end": "309800"
  },
  {
    "text": "communities and stuff uh it is just enormously exciting uh because uh it's",
    "start": "309800",
    "end": "315240"
  },
  {
    "text": "kind of the reason that we're doing it and the fact that people are out there not only are they listening but they're saying hey what about this I'd love to",
    "start": "315240",
    "end": "321479"
  },
  {
    "text": "hear that and hey here's a suggestion or hey I know somebody who would be great on your show it just it makes the whole",
    "start": "321479",
    "end": "327880"
  },
  {
    "text": "thing wonderful uh and it's I know that sounds a littleit corny but it's true yeah it is super encouraging um so keep",
    "start": "327880",
    "end": "336039"
  },
  {
    "text": "that coming we're really excited about episode 50 um this is kind of a celebration for us and so we were",
    "start": "336039",
    "end": "342560"
  },
  {
    "text": "talking before the show of like how what what should we do to celebrate episode",
    "start": "342560",
    "end": "347639"
  },
  {
    "text": "number 50 and what we came up with was kind of uh to Loop all the way back to",
    "start": "347639",
    "end": "354720"
  },
  {
    "text": "kind of where things started um you know with AI uh and with practical Ai and",
    "start": "354720",
    "end": "362400"
  },
  {
    "text": "that's to devote this kind of celebratory episode to one of our favorite things which is the neural net",
    "start": "362400",
    "end": "370160"
  },
  {
    "text": "um absolutely yeah so we thought we would so we've talked about a lot of neural Nets on the show obviously and",
    "start": "370160",
    "end": "376319"
  },
  {
    "text": "and many Advanced uh sort of architectures and applications and all of that um but we've never actually just",
    "start": "376319",
    "end": "383840"
  },
  {
    "text": "talked about the neuronet itself where it came from and just kind of in brief",
    "start": "383840",
    "end": "390599"
  },
  {
    "text": "um and from scratch what a neural net is what makes it a neural net and um we",
    "start": "390599",
    "end": "395639"
  },
  {
    "text": "thought this would be a great episode to kind of circle back to that starting point yep I absolutely one one of the",
    "start": "395639",
    "end": "401720"
  },
  {
    "text": "kind of one of the common comments that we get back uh that I've had conversations with several people about",
    "start": "401720",
    "end": "408319"
  },
  {
    "text": "um including the young man that is at the Chinese restaurant 2 miles from my house because he actually listens to the",
    "start": "408319",
    "end": "414639"
  },
  {
    "text": "podcast uh but he's not a data scientist and and he made some comments to me a while back he said you know um you guys",
    "start": "414639",
    "end": "421080"
  },
  {
    "text": "are are really good so long as you don't do jargon and we've been and and we took that as a point to not to be very",
    "start": "421080",
    "end": "426800"
  },
  {
    "text": "careful about that but he said that you know sometimes um we get a little bit out there for where he's at and he's",
    "start": "426800",
    "end": "432360"
  },
  {
    "text": "he's very interested in the topic but um we've never really done a true intro to neural net type of uh show and uh it",
    "start": "432360",
    "end": "440120"
  },
  {
    "text": "occurred to me that for those people out there who were trying to jump in and may find it a little bit intimidating I",
    "start": "440120",
    "end": "445440"
  },
  {
    "text": "can't think of a better way to celebrate kind of a milestone episode yep sounds great great so why don't why don't we",
    "start": "445440",
    "end": "450840"
  },
  {
    "text": "start with giving just a little bit of history about the neural net itself so",
    "start": "450840",
    "end": "456960"
  },
  {
    "text": "neural Nets are not new they've actually been around for quite some time do you know when sort of neural Nets came onto",
    "start": "456960",
    "end": "463599"
  },
  {
    "text": "the scene Chris sometime around World War II if I recall correctly uh do you",
    "start": "463599",
    "end": "471000"
  },
  {
    "text": "have the specifics yeah so if you just um you can just search Google for like",
    "start": "471000",
    "end": "476599"
  },
  {
    "text": "uh neuronet history and you know there's several lists that come up that have varying uh you know variations of the",
    "start": "476599",
    "end": "485039"
  },
  {
    "text": "various dates and and and facts and all of that but generally people include kind of a date around the mid",
    "start": "485039",
    "end": "493039"
  },
  {
    "text": "1940s when the first kind of computational model for neural networks came out it's a guy named uh I'm I'm",
    "start": "493039",
    "end": "500400"
  },
  {
    "text": "sorry if I'm mispronouncing this I I don't really hear this name too much but Warren mccullock and Walter pittz um",
    "start": "500400",
    "end": "507639"
  },
  {
    "text": "created a these computational models um really that paved the way for both sort",
    "start": "507639",
    "end": "514719"
  },
  {
    "text": "of modeling biological processes like actually neurons in our brain or or neural networks in our brain and then uh",
    "start": "514719",
    "end": "522680"
  },
  {
    "text": "kind of more uh practical applications of of neural networks yeah and then I",
    "start": "522680",
    "end": "529120"
  },
  {
    "text": "think there was a kind of the next major step was when the perceptron uh was invented and that was by a guy named",
    "start": "529120",
    "end": "535160"
  },
  {
    "text": "Frank Rosen blot uh in 1958 so uh we're getting from for me we're getting a little bit closer to my year of birth uh",
    "start": "535160",
    "end": "542440"
  },
  {
    "text": "not quite there yet not quite that old um but that that really set off kind of",
    "start": "542440",
    "end": "547959"
  },
  {
    "text": "you know one of the the early waves of of research in this area yeah PE people are sometimes surprised because there's",
    "start": "547959",
    "end": "555079"
  },
  {
    "text": "a lot been a lot of talk about neural networks recently um but maybe they didn't hear it a while back so these",
    "start": "555079",
    "end": "561560"
  },
  {
    "text": "these sorts of things have been around for quite some time in research and like",
    "start": "561560",
    "end": "566640"
  },
  {
    "text": "you were saying moving up through like the 60s 70s they were a topic of research but I think that a big shift",
    "start": "566640",
    "end": "573839"
  },
  {
    "text": "happened in the 1980s kind of up to the mid mid90s um and this is where things like",
    "start": "573839",
    "end": "581200"
  },
  {
    "text": "deep learning and back propagation so these kind of larger neural networks um",
    "start": "581200",
    "end": "587079"
  },
  {
    "text": "and uh and applications to different types of data came came around um so up",
    "start": "587079",
    "end": "592600"
  },
  {
    "text": "until this point people were researching neural networks but they hadn't really figured out a way to kind make them",
    "start": "592600",
    "end": "600040"
  },
  {
    "text": "bigger and and learn more complicated patterns so before that they were pretty",
    "start": "600040",
    "end": "605200"
  },
  {
    "text": "limited towards like linear um divisions between Class you know linear class",
    "start": "605200",
    "end": "611680"
  },
  {
    "text": "boundaries and these different things but um a as they saw that they needed to model more complicated relationships",
    "start": "611680",
    "end": "618040"
  },
  {
    "text": "they saw that kind of the size of the networks needed to increase but they didn't really have a good way of",
    "start": "618040",
    "end": "623399"
  },
  {
    "text": "training those sorts of neural networks and that that kind of changed in the 80s that's true and that's uh there's I have",
    "start": "623399",
    "end": "629680"
  },
  {
    "text": "a a special affinity for that time period because um in 1992 is actually when I first became aware of neural",
    "start": "629680",
    "end": "636440"
  },
  {
    "text": "networks and that's before uh like the the the name deep learning was applied to it um and was before anyone was",
    "start": "636440",
    "end": "642240"
  },
  {
    "text": "calling them deep neural networks necessarily um my father uh worked for loed Martin uh just like I do uh he",
    "start": "642240",
    "end": "648839"
  },
  {
    "text": "would have been shocked that I do at this point but um he worked there and there was an event uh that really",
    "start": "648839",
    "end": "655000"
  },
  {
    "text": "affected me in a very personal way uh and that was that there was a plane uh",
    "start": "655000",
    "end": "660279"
  },
  {
    "text": "called the F-22 at the time it was the yf-22 which is still uh kind of the world's top Air superiority fighter in",
    "start": "660279",
    "end": "667000"
  },
  {
    "text": "other words for for dog fighting you might say and it there were two prototypes and one of those prototypes",
    "start": "667000",
    "end": "673360"
  },
  {
    "text": "was doing some testing at Edwards Air Force Base and they were testing avionics on it and there was a",
    "start": "673360",
    "end": "679399"
  },
  {
    "text": "malfunction and uh they fortunately was it was close to the ground and the plane slammed into the ground and went",
    "start": "679399",
    "end": "684920"
  },
  {
    "text": "skidding in a fiery uh ball down the runway for for quite a ways and the the pilot got out the test pilot got out and",
    "start": "684920",
    "end": "691360"
  },
  {
    "text": "got away safely um but as the aftermath of that my both of my parents were on",
    "start": "691360",
    "end": "697000"
  },
  {
    "text": "the F22 team the core team that that built the avionics for the plane and my father was assigned to uh help solve",
    "start": "697000",
    "end": "704839"
  },
  {
    "text": "that avionics thing and and as part of that uh he was using neural networks of the day and he started with feed forward",
    "start": "704839",
    "end": "712040"
  },
  {
    "text": "which in in back propagation which we'll talk about in a few minutes um and moved on to other architectures uh but uh that",
    "start": "712040",
    "end": "718600"
  },
  {
    "text": "was really special because he would come home and there's all sorts of classified stuff he would not talk about but in",
    "start": "718600",
    "end": "723839"
  },
  {
    "text": "terms of the actual science we' come home and he introduced me to neural networks and this was our dinner table",
    "start": "723839",
    "end": "729639"
  },
  {
    "text": "talk for a while and um and as he made progress into different areas and he would explain it to me at night and I",
    "start": "729639",
    "end": "736079"
  },
  {
    "text": "would ask questions um but you know before so that's going back to when I and I was a college student at the time",
    "start": "736079",
    "end": "742440"
  },
  {
    "text": "and so it was a really interesting um way for me to kind of get into it and a very practical problem and obviously the",
    "start": "742440",
    "end": "748240"
  },
  {
    "text": "problem was solved and the F22 is is in service today and so um anyway but that's that's how I originally came to",
    "start": "748240",
    "end": "754880"
  },
  {
    "text": "be aware of them yeah and that's where you first started getting the ideas for this great uh podcast practical AI I'm",
    "start": "754880",
    "end": "762000"
  },
  {
    "text": "sure I don't know if if podcasting was was not a thing um but yeah uh this time was",
    "start": "762000",
    "end": "770360"
  },
  {
    "text": "really um really where some interesting things came on the scene that was recognized actually this year with this",
    "start": "770360",
    "end": "776480"
  },
  {
    "text": "year's Turing award which uh went to like and Hinton and Benjo for things",
    "start": "776480",
    "end": "781519"
  },
  {
    "text": "like back propagation and the sort of ideas around deep learning um and that",
    "start": "781519",
    "end": "787279"
  },
  {
    "text": "that was big news recently um but there was this kind of time period of the 1980s and kind of up to the mid",
    "start": "787279",
    "end": "795320"
  },
  {
    "text": "1990s where things were getting really exciting and then there was a sort of",
    "start": "795320",
    "end": "800560"
  },
  {
    "text": "die off of interest in these sorts of methods some people call this the the AI",
    "start": "800560",
    "end": "805680"
  },
  {
    "text": "winter um and yeah that kind of that kind of led up almost to the to the mid",
    "start": "805680",
    "end": "812160"
  },
  {
    "text": "2000s so um this was a time when kind of these these methodologies were were",
    "start": "812160",
    "end": "818399"
  },
  {
    "text": "known but the problem was that the kind of as these networks got larger and",
    "start": "818399",
    "end": "823560"
  },
  {
    "text": "larger of course they had more parameters that needed to be fitted um and that required more data and more",
    "start": "823560",
    "end": "830320"
  },
  {
    "text": "compute and so there was kind of this lag of the actual data and compute that was needed and along with that the",
    "start": "830320",
    "end": "836839"
  },
  {
    "text": "adoption that we've seen recently so that really kicked into gear maybe in the mid 2000s and on where people really",
    "start": "836839",
    "end": "843399"
  },
  {
    "text": "had access to a lot of compute a lot of data and um really were able to plug",
    "start": "843399",
    "end": "849600"
  },
  {
    "text": "that into these Advanced methods yeah it it's it really got kicked off uh by a",
    "start": "849600",
    "end": "855759"
  },
  {
    "text": "guy who had been in the field for a while kind of coming out of this AI winter um by Jeffrey Hinton uh and he is",
    "start": "855759",
    "end": "862320"
  },
  {
    "text": "he's kind of one of the Legends in this field um and he started research and at",
    "start": "862320",
    "end": "867600"
  },
  {
    "text": "first people as he kind of and I think he he continued through the through that AI winter but um while while everybody",
    "start": "867600",
    "end": "874360"
  },
  {
    "text": "else was turning to other things um and I would I would argue that it was really some of his initial and kind of in this",
    "start": "874360",
    "end": "881600"
  },
  {
    "text": "latest wave since the mid 2000s um that kind of kicked it off uh and and he is",
    "start": "881600",
    "end": "886959"
  },
  {
    "text": "really um I credit him with coming out of the AI winter and and kind of being",
    "start": "886959",
    "end": "892120"
  },
  {
    "text": "at the moment that we're at now yeah and you know recently of course Google has",
    "start": "892120",
    "end": "897360"
  },
  {
    "text": "switched kind of from a mobile first to AI first uh approach to to their",
    "start": "897360",
    "end": "903839"
  },
  {
    "text": "business in general um and that's kind of sparked a lot of interest from a lot",
    "start": "903839",
    "end": "908880"
  },
  {
    "text": "of other industry leaders as well so pretty much all the big tech companies now um along with a you know a host of",
    "start": "908880",
    "end": "917800"
  },
  {
    "text": "startups and smaller companies have really switched to a focus on AI in",
    "start": "917800",
    "end": "923639"
  },
  {
    "text": "terms of research and development and the methodologies that are powering their their products so AI has kind of",
    "start": "923639",
    "end": "930880"
  },
  {
    "text": "at this point become a new layer in the software stack that's enabling new sorts of functionalities in um in applications",
    "start": "930880",
    "end": "939560"
  },
  {
    "text": "and you know at the core of most all of those AI systems are neural networks",
    "start": "939560",
    "end": "946360"
  },
  {
    "text": "these things that started back in the' 40s that were kind of envisioned and built up over time but um the the core",
    "start": "946360",
    "end": "954079"
  },
  {
    "text": "idea is there um it is the the neural network now not a lot of people will",
    "start": "954079",
    "end": "959800"
  },
  {
    "text": "kind of argue about what AI encompasses and the sorts of methods that are Ai and aren't AI um and there's certainly a lot",
    "start": "959800",
    "end": "966800"
  },
  {
    "text": "of methods that aren't just kind of simple neural networks there's non- neural network uh methodologies there's",
    "start": "966800",
    "end": "973040"
  },
  {
    "text": "a lot of other machine learning type of methodologies but really the neural network is kind of the core piece that's",
    "start": "973040",
    "end": "980360"
  },
  {
    "text": "that's powering a bunch of things in Industry now and really is the focus of",
    "start": "980360",
    "end": "985560"
  },
  {
    "text": "a lot of the the AI research that's that's going on which is which is why we're focusing on on them that's true",
    "start": "985560",
    "end": "992319"
  },
  {
    "text": "and that was I have to say that was very well said um because the reality is when you put uh when you put different people",
    "start": "992319",
    "end": "1000040"
  },
  {
    "text": "in this field uh data scientists and deep learning engineers and you ask them",
    "start": "1000040",
    "end": "1005279"
  },
  {
    "text": "what AI is um you're going to get a lot of different answers um and I was actually in an event where that it",
    "start": "1005279",
    "end": "1010920"
  },
  {
    "text": "almost comically uh you know demonstrate itself uh in that way um it was an adobe",
    "start": "1010920",
    "end": "1017560"
  },
  {
    "text": "event which which was a live broadcast on Facebook and I was one of 10 people",
    "start": "1017560",
    "end": "1023120"
  },
  {
    "text": "uh that came and participated and there was a lot of stuff we agreed on but the one thing that all of us had different",
    "start": "1023120",
    "end": "1028880"
  },
  {
    "text": "viewpoints on was exactly what constituted artificial intelligence today um and without without delving any",
    "start": "1028880",
    "end": "1037120"
  },
  {
    "text": "further I just found that fascinating that that they introduced us as experts whether whether we were or not but that",
    "start": "1037120",
    "end": "1043240"
  },
  {
    "text": "we were we were uh positioned in that way and yet none of us could agree on the the basic definition of the",
    "start": "1043240",
    "end": "1051270"
  },
  {
    "text": "[Music]",
    "start": "1051270",
    "end": "1056660"
  },
  {
    "text": "field the data engineering podcast is a weekly deep dive on Modern data management with the engineers and",
    "start": "1057559",
    "end": "1064080"
  },
  {
    "text": "entrepreneurs who are shaping the industry go behind the scenes on the tools techniques and difficulties of",
    "start": "1064080",
    "end": "1069559"
  },
  {
    "text": "data engineering so you can learn and keep up with the knowledge to make you and your business successful can you",
    "start": "1069559",
    "end": "1075440"
  },
  {
    "text": "give a bit of an outline about the motivation for choosing Jupiter notebooks in particular as the core",
    "start": "1075440",
    "end": "1080919"
  },
  {
    "text": "interface for your data teams yeah and actually uh when I first joined uh Netflix it was sort of tossed at me and",
    "start": "1080919",
    "end": "1087159"
  },
  {
    "text": "I was definitely like are we crazy and the answer was like we might be a little crazy go to dataengineering podcast.com",
    "start": "1087159",
    "end": "1093520"
  },
  {
    "text": "to listen subscribe and share it with your friends and",
    "start": "1093520",
    "end": "1099039"
  },
  {
    "text": "[Music]",
    "start": "1100380",
    "end": "1107760"
  },
  {
    "text": "colleagues Okay so we've talked about kind of a little bit of the history of",
    "start": "1107760",
    "end": "1113280"
  },
  {
    "text": "neural networks and we've talked about you know how they came onto the scene and really that they're powering a lot",
    "start": "1113280",
    "end": "1119440"
  },
  {
    "text": "of these big Tech Innovations um but before we jump into kind of the very very specifics of a",
    "start": "1119440",
    "end": "1127039"
  },
  {
    "text": "neural network and and what it is um I think it would be useful to kind of just",
    "start": "1127039",
    "end": "1132159"
  },
  {
    "text": "give a a real um broad definition of",
    "start": "1132159",
    "end": "1137200"
  },
  {
    "text": "supervised the super supervised learning and there there's you know a lot of different types of machine learning",
    "start": "1137200",
    "end": "1144360"
  },
  {
    "text": "models out there some of which are kind of unsupervised and semi-supervised but the bulk of uh models that people kind",
    "start": "1144360",
    "end": "1151159"
  },
  {
    "text": "of get into when they're first getting into Ai and machine learning are supervised uh learning models and I",
    "start": "1151159",
    "end": "1156760"
  },
  {
    "text": "think that would be a good framework for us to talk about neural networks within",
    "start": "1156760",
    "end": "1161799"
  },
  {
    "text": "um yeah just going to say when when I'm talking about neural networks in an introductory thing I I pretty much I may",
    "start": "1161799",
    "end": "1167919"
  },
  {
    "text": "allude to some other things that are out there but supervised learning is definitely the place to start um it's",
    "start": "1167919",
    "end": "1173799"
  },
  {
    "text": "kind of the basics and you learn the basics and then you can build on it in a lot of different directions yep so um",
    "start": "1173799",
    "end": "1179799"
  },
  {
    "text": "let's kind of I I when I'm teaching classes I I normally try to introduce some type of kind of model problem that",
    "start": "1179799",
    "end": "1187600"
  },
  {
    "text": "people can have in the back of their minds when I'm thinking about supervised learning you might think about like um",
    "start": "1187600",
    "end": "1194280"
  },
  {
    "text": "let's try to model the number of uh or or let's say let's try to model our",
    "start": "1194280",
    "end": "1200640"
  },
  {
    "text": "sales for the month based on the number of users on our website or something like that now one way you could do that",
    "start": "1200640",
    "end": "1207880"
  },
  {
    "text": "is by creating a sort of function like a function in code that would take in your",
    "start": "1207880",
    "end": "1213559"
  },
  {
    "text": "number of users and output your sales and most often that would include some type of like model definition and some",
    "start": "1213559",
    "end": "1221480"
  },
  {
    "text": "parameters so it's like you might input a number of users and then multiply that by a parameter or a coefficient and out",
    "start": "1221480",
    "end": "1228200"
  },
  {
    "text": "comes your for uh sales so that's a model definition with a parameter now",
    "start": "1228200",
    "end": "1233440"
  },
  {
    "text": "the big thing that separates kind of machine learning functions versus kind",
    "start": "1233440",
    "end": "1238880"
  },
  {
    "text": "of regular code functions is that regular code functions that definition and parameters are kind of set by domain",
    "start": "1238880",
    "end": "1246400"
  },
  {
    "text": "knowledge and someone coding them in whereas in a machine learning context I like to think about those parameters",
    "start": "1246400",
    "end": "1253000"
  },
  {
    "text": "being set by kind of trial and error or an iterative process of looking at a",
    "start": "1253000",
    "end": "1259400"
  },
  {
    "text": "bunch of examples and trying to make predictions um for all of those examples",
    "start": "1259400",
    "end": "1264880"
  },
  {
    "text": "and then fitting or setting those parameters based on this sort of iterative process overall that's kind of",
    "start": "1264880",
    "end": "1271279"
  },
  {
    "text": "how I have the picture in my mind does that kind of make sense Chris or do you have a sort of different view no I I",
    "start": "1271279",
    "end": "1277600"
  },
  {
    "text": "think I have I think I would see it the same way uh I think one easy way to think about it is if if you look at uh",
    "start": "1277600",
    "end": "1284600"
  },
  {
    "text": "solving problems programmatically uh up you know until you get to deep learning",
    "start": "1284600",
    "end": "1290120"
  },
  {
    "text": "in other words just using kind OFA more traditional programming you explicitly uh are are going and giving the program",
    "start": "1290120",
    "end": "1297960"
  },
  {
    "text": "commands on what you're going to do and and you might think of it in a very simplistic way as lots of if then type",
    "start": "1297960",
    "end": "1304320"
  },
  {
    "text": "statements um lots of case statements and you're having to think of all the things whereas this way of doing it",
    "start": "1304320",
    "end": "1310360"
  },
  {
    "text": "where you where machine learning the model is is learning what it needs to to do is sort of implicit it's figuring it",
    "start": "1310360",
    "end": "1317480"
  },
  {
    "text": "out for you and it's kind of a different uh programming uh Paradigm uh in large in computer science Beyond just just the",
    "start": "1317480",
    "end": "1324919"
  },
  {
    "text": "what deep learning is so if you if you think of it as um the the the job of",
    "start": "1324919",
    "end": "1330400"
  },
  {
    "text": "training the model is now to go figure out what it needs as opposed to being told what it needs um it kind of put you",
    "start": "1330400",
    "end": "1336080"
  },
  {
    "text": "in the right frame for learning this um I I would uh I would say you know some people when we use the words like uh you",
    "start": "1336080",
    "end": "1342679"
  },
  {
    "text": "know the computer figures it out or the computer learns they kind of have this view of like oh I'm going to go put my",
    "start": "1342679",
    "end": "1348679"
  },
  {
    "text": "laptop like in the corner of my office and then kind of sprinkle some special fairy dust on it and it's going to kind",
    "start": "1348679",
    "end": "1354640"
  },
  {
    "text": "of uh spontaneously start learning things about the world um but really um",
    "start": "1354640",
    "end": "1361039"
  },
  {
    "text": "yeah at the I you know you don't have some of that laying around in your kitchen or something yeah I'll borrow it",
    "start": "1361039",
    "end": "1367120"
  },
  {
    "text": "from my seven-year-old daughter yeah yeah maybe um so in reality what there is is there's always a sort of model",
    "start": "1367120",
    "end": "1374480"
  },
  {
    "text": "definition remember thinking of our kind of users to sales there's some definition and there's some number of",
    "start": "1374480",
    "end": "1379760"
  },
  {
    "text": "parameters that parameterize that model definition um it might be the you know",
    "start": "1379760",
    "end": "1385720"
  },
  {
    "text": "the coefficients multiplication or or what we call a bias which is kind of a a",
    "start": "1385720",
    "end": "1391080"
  },
  {
    "text": "number that we add on to the definition um but there's some model definition in those parameters and what we mean by",
    "start": "1391080",
    "end": "1397480"
  },
  {
    "text": "learning or training isn't just that it kind of our computer has it's at the",
    "start": "1397480",
    "end": "1402880"
  },
  {
    "text": "right temperature and the right conditions and year of the month and the stars align and it starts learning it's",
    "start": "1402880",
    "end": "1408080"
  },
  {
    "text": "that the parameters are set through an iterative process of looking at a bunch of training examples of examples of what",
    "start": "1408080",
    "end": "1416520"
  },
  {
    "text": "input is and should be and what output should be so there's a bunch of examples of there's this input and this should be",
    "start": "1416520",
    "end": "1423840"
  },
  {
    "text": "the output there's this input and this should be the output and there's a training process which is just",
    "start": "1423840",
    "end": "1430200"
  },
  {
    "text": "another function written in code that iteratively looks over all of these",
    "start": "1430200",
    "end": "1435960"
  },
  {
    "text": "examples and fits these parameters such that the model can then make",
    "start": "1435960",
    "end": "1441919"
  },
  {
    "text": "predictions on new examples that it hasn't seen yet so it isn't that this there's kind of the spontaneous learning",
    "start": "1441919",
    "end": "1448000"
  },
  {
    "text": "that happens it's really kind of something much more benign it's that there's a bunch of examples and",
    "start": "1448000",
    "end": "1454520"
  },
  {
    "text": "computers are good at repetitive tasks right and so we just have the computer look at these examples over and over",
    "start": "1454520",
    "end": "1460679"
  },
  {
    "text": "again and tweak these parameters until we we get a good set of parameters to",
    "start": "1460679",
    "end": "1465760"
  },
  {
    "text": "parameterize this model definition and then we can make new new uh predictions so that first process is called the",
    "start": "1465760",
    "end": "1472440"
  },
  {
    "text": "training process and then when we make new predictions that's called the inference or or prediction process so in",
    "start": "1472440",
    "end": "1479919"
  },
  {
    "text": "the training process we've talked about making the little tweaks um and that's called error correction and so uh as as",
    "start": "1479919",
    "end": "1487559"
  },
  {
    "text": "Daniel was talking about we we we already when we're in training we already know what the ground truth is",
    "start": "1487559",
    "end": "1493240"
  },
  {
    "text": "for any given example and and the model is essentially trying to find that with",
    "start": "1493240",
    "end": "1499320"
  },
  {
    "text": "with where it's trained to up to that point and then it actually uh it it says",
    "start": "1499320",
    "end": "1504919"
  },
  {
    "text": "okay I have a result in this training cycle and then I have uh the uh the",
    "start": "1504919",
    "end": "1510840"
  },
  {
    "text": "ground truth and there's a difference in the two and I'm going to use an error correction algorithm to say what should",
    "start": "1510840",
    "end": "1517159"
  },
  {
    "text": "I do what tweaking should I do in this case when my result isn't what I know to be the ground Truth uh in the training",
    "start": "1517159",
    "end": "1524039"
  },
  {
    "text": "set so it it it is uh it is an algorithm that is driving that that tweaking uh",
    "start": "1524039",
    "end": "1529720"
  },
  {
    "text": "but it is able to uh to use that algorithm based on the data that it's come upon on that particular cycle so",
    "start": "1529720",
    "end": "1536480"
  },
  {
    "text": "let's maybe uh make this a little bit more concrete now so we've talked about you know supervised learning in general",
    "start": "1536480",
    "end": "1543520"
  },
  {
    "text": "and that there's this definition and parameters that are set so what does that look like for a neural network so",
    "start": "1543520",
    "end": "1550159"
  },
  {
    "text": "in a neural network there's these kind of subunits I have a overall definition",
    "start": "1550159",
    "end": "1556000"
  },
  {
    "text": "and then I have a bunch of kind of sub defition within that or you could think about it",
    "start": "1556000",
    "end": "1561080"
  },
  {
    "text": "if you're programmer like a function that calls a bunch of kind of sub functions underneath it and these",
    "start": "1561080",
    "end": "1566440"
  },
  {
    "text": "subunits or sub definitions are called neurons and so each of these neurons",
    "start": "1566440",
    "end": "1571679"
  },
  {
    "text": "kind of have its own inputs and outputs um with its own definition and its own",
    "start": "1571679",
    "end": "1577000"
  },
  {
    "text": "set of parameters and these parameters for the neuron are often called weights",
    "start": "1577000",
    "end": "1582960"
  },
  {
    "text": "and biases so again you can kind of think of my overall definition of my model",
    "start": "1582960",
    "end": "1588760"
  },
  {
    "text": "containing a bunch of these sub definitions of neurons that are linked together in in some way and that",
    "start": "1588760",
    "end": "1595240"
  },
  {
    "text": "together that assembly of neurons make up what's called a neural network",
    "start": "1595240",
    "end": "1600799"
  },
  {
    "text": "architecture so that just that architecture just means there's a bunch of these kind of subunits each of them",
    "start": "1600799",
    "end": "1606960"
  },
  {
    "text": "have a definition and some parameters that that can be can be set um now uh",
    "start": "1606960",
    "end": "1614600"
  },
  {
    "text": "now there's a lot of different ways that you can set up those those neurons so so maybe we should look at you know a kind",
    "start": "1614600",
    "end": "1620360"
  },
  {
    "text": "of common way to set up one of these neurons yeah like a fully connected feed forward is a good starting point yep so",
    "start": "1620360",
    "end": "1627120"
  },
  {
    "text": "maybe uh do you want to do you want to start there Chris sure So Daniel was just talking about these units of",
    "start": "1627120",
    "end": "1633039"
  },
  {
    "text": "neurons and if you're if you want to paint a picture in your mind as you listen you could think of each one of",
    "start": "1633039",
    "end": "1638320"
  },
  {
    "text": "those the way they're usually depicted graphically is as a little circle and you could think of it as a little circle",
    "start": "1638320",
    "end": "1644080"
  },
  {
    "text": "that has some stuff inside it which we'll talk about in a moment but you take of those circles and you line you",
    "start": "1644080",
    "end": "1650480"
  },
  {
    "text": "line a few circles up into a row and you and and so you have a row of circles and",
    "start": "1650480",
    "end": "1656039"
  },
  {
    "text": "then at that point uh you line up a second row and maybe a third row and so there's some number of rows in number of",
    "start": "1656039",
    "end": "1663480"
  },
  {
    "text": "rows that you have there and there's some special relationships between each of those layers so if you take for every",
    "start": "1663480",
    "end": "1669840"
  },
  {
    "text": "neuron in that first layer it is connected to each of the neurons in the",
    "start": "1669840",
    "end": "1675360"
  },
  {
    "text": "second layer but to none of the neurons in its own layer um and so in that second layer you recreate that and so",
    "start": "1675360",
    "end": "1682039"
  },
  {
    "text": "each neuron in a given layer is connected to all the neurons in the previous layer and all the neurons in",
    "start": "1682039",
    "end": "1688200"
  },
  {
    "text": "the next layer but none of the neurons in its own layer um and so you can kind of Envision this this mesh of of rows of",
    "start": "1688200",
    "end": "1696880"
  },
  {
    "text": "little circles in that way and you start from one side to go in as an input and then you come out the other side and",
    "start": "1696880",
    "end": "1702919"
  },
  {
    "text": "that that is the basic uh image in your mind of how you might think about a fully connected uh feed forward Network",
    "start": "1702919",
    "end": "1709360"
  },
  {
    "text": "and I I'll I'll note one other thing is uh these shows where Daniel and I talk about topics uh on our own without a",
    "start": "1709360",
    "end": "1715559"
  },
  {
    "text": "guest you may have noticed that they're called fully connected episodes this is what we're referring to it was named after this how clever mhm uh you",
    "start": "1715559",
    "end": "1722840"
  },
  {
    "text": "mentioned that each of these uh nodes or neurons is is fully connected in this",
    "start": "1722840",
    "end": "1729559"
  },
  {
    "text": "sort of is in this sort of network and each one has its own inputs and outputs",
    "start": "1729559",
    "end": "1735039"
  },
  {
    "text": "now if we dig into one of these neurons um to think about kind of what's inside",
    "start": "1735039",
    "end": "1740240"
  },
  {
    "text": "of that bubble and again you know you can think about that visually like a like a bubble or a node or if you're",
    "start": "1740240",
    "end": "1746080"
  },
  {
    "text": "kind of a programmer you might think about it as one of these kind of sub functions under under a big function but",
    "start": "1746080",
    "end": "1753000"
  },
  {
    "text": "it has its own inputs and outputs and if we think about it maybe as just having a couple inputs let's say X1 and two now",
    "start": "1753000",
    "end": "1759960"
  },
  {
    "text": "what happens inside of that Circle or inside of that neuron well there's some",
    "start": "1759960",
    "end": "1765360"
  },
  {
    "text": "kind of simple things that happen often um so one way we could think about processing these inputs uh in the neuron",
    "start": "1765360",
    "end": "1773000"
  },
  {
    "text": "is to just add them up right and so in a kind of linear regression sort of way we",
    "start": "1773000",
    "end": "1778519"
  },
  {
    "text": "could multiply each of my inputs X1 and X2 by a couple coefficients uh let's say",
    "start": "1778519",
    "end": "1785080"
  },
  {
    "text": "W1 and W2 those are often called weights so I just add up the two things after I",
    "start": "1785080",
    "end": "1790360"
  },
  {
    "text": "multiply them by coefficients and then I might add in like a an intercept or a",
    "start": "1790360",
    "end": "1796279"
  },
  {
    "text": "constant um and you know so just X1 X2 plus something and that's often called a",
    "start": "1796279",
    "end": "1802559"
  },
  {
    "text": "bias so in this case there I would have like three parameters that I that I parameterize the way I'm combining these",
    "start": "1802559",
    "end": "1810000"
  },
  {
    "text": "inputs and so each of my X1 and X2 come in I I combine them together in this way",
    "start": "1810000",
    "end": "1815880"
  },
  {
    "text": "and that's all good and fine except um you know most relationships in our world",
    "start": "1815880",
    "end": "1821039"
  },
  {
    "text": "aren't linear um so it might be good to introduce some nonlinearity into this",
    "start": "1821039",
    "end": "1827200"
  },
  {
    "text": "combination and that's where a thing called an activation function comes in which is just a a nonlinear function",
    "start": "1827200",
    "end": "1833919"
  },
  {
    "text": "that's kind of applied to this combination of inputs to give it some nonlinearity in common functions that",
    "start": "1833919",
    "end": "1839799"
  },
  {
    "text": "are used are like sigmoid or Ru or other functions uh hyperbolic tangent that are",
    "start": "1839799",
    "end": "1847120"
  },
  {
    "text": "applied to this combination of inputs so when my inputs come into that node or",
    "start": "1847120",
    "end": "1852360"
  },
  {
    "text": "that Circle they're just kind of added up in a special way and then output out the other end and all of my neurons in",
    "start": "1852360",
    "end": "1860840"
  },
  {
    "text": "my network kind of do similar sorts of simple operations that are parameterized",
    "start": "1860840",
    "end": "1866440"
  },
  {
    "text": "in a similar way so each neuron has a certain number of inputs they're combined together using some parameters",
    "start": "1866440",
    "end": "1873960"
  },
  {
    "text": "and then output is a number and that's kind of what each what each neuron does that was a very good explanation there",
    "start": "1873960",
    "end": "1881039"
  },
  {
    "text": "um and so as you as you as these inputs start flowing through these layers and",
    "start": "1881039",
    "end": "1887000"
  },
  {
    "text": "they're doing this currently so the inputs come in it hits all the neurons in that first layer simultaneously",
    "start": "1887000",
    "end": "1894559"
  },
  {
    "text": "everything that Daniel was just talking about happens in each of those neurons in that first layer and as they go",
    "start": "1894559",
    "end": "1899799"
  },
  {
    "text": "through their transfer function that adds the nonlinearity and then they go out and the output of each one of those",
    "start": "1899799",
    "end": "1906440"
  },
  {
    "text": "neurons in that first layer goes to all of the neurons in the second layer and",
    "start": "1906440",
    "end": "1911519"
  },
  {
    "text": "is combined remember since they're fully connected there's lots of inputs potentially coming in and they're all",
    "start": "1911519",
    "end": "1916720"
  },
  {
    "text": "summed up again in each Just the Way Daniel described and so this happens concurrent in in concurrency at each",
    "start": "1916720",
    "end": "1923440"
  },
  {
    "text": "layer and it goes through layer by layer by layer till you get to an output and then you either you discover at that",
    "start": "1923440",
    "end": "1930200"
  },
  {
    "text": "point that um if you're while you're going through this training process that um you have some values coming out and",
    "start": "1930200",
    "end": "1936679"
  },
  {
    "text": "you compare that against what you know to be the ground truth that's in your training data set you know what the result is while you're trying to train",
    "start": "1936679",
    "end": "1943480"
  },
  {
    "text": "and that's when your error correction comes in where you have to say Okay well I've ended up with an output and it's",
    "start": "1943480",
    "end": "1949919"
  },
  {
    "text": "not quite what I was hoping it would be so I need to change uh I need to change the values uh throughout the",
    "start": "1949919",
    "end": "1958159"
  },
  {
    "text": "architecture uh there's the the initial thing that most people learn and and is",
    "start": "1958159",
    "end": "1963880"
  },
  {
    "text": "most widely used is called back propagation um and that's where you work your way back through the layers through",
    "start": "1963880",
    "end": "1969240"
  },
  {
    "text": "a set of algorithms that make little tweaks all the way through your layers and then hey guess what you you've done",
    "start": "1969240",
    "end": "1975320"
  },
  {
    "text": "one full cycle and it's time to go to the next row of your data to train that and you do that whole process over and",
    "start": "1975320",
    "end": "1981720"
  },
  {
    "text": "over again yep it's it's kind of like uh you might think about if you're trying to set these weights and biases manually",
    "start": "1981720",
    "end": "1989679"
  },
  {
    "text": "as as a human what we would do is just kind of try to make you know make an initial choice for them try to make some",
    "start": "1989679",
    "end": "1996399"
  },
  {
    "text": "predictions and then see if our predictions were good or bad and kind of adjust the parameters accordingly and",
    "start": "1996399",
    "end": "2002000"
  },
  {
    "text": "then just do that over and over so that's what the computer is doing is essentially a bunch of trial and error it's making some predictions and of",
    "start": "2002000",
    "end": "2008880"
  },
  {
    "text": "course there's more sophisticated ways of updating the the weights and biases",
    "start": "2008880",
    "end": "2014840"
  },
  {
    "text": "rather than just kind of randomly making choices for updates um and that's where kind of this gradient descent comes in",
    "start": "2014840",
    "end": "2021320"
  },
  {
    "text": "but essentially we're just making those Corrections now I think an kind of interesting thing to to add in here is",
    "start": "2021320",
    "end": "2030519"
  },
  {
    "text": "we're always talking about models and like what you know we have a neural network model we have this type of model",
    "start": "2030519",
    "end": "2037320"
  },
  {
    "text": "so here we've talked about the kind of definition of the neural network we've talked about all of the parameters that",
    "start": "2037320",
    "end": "2043159"
  },
  {
    "text": "need to be fit for this neural network we've talked about the training process that trains or fits all of these",
    "start": "2043159",
    "end": "2049599"
  },
  {
    "text": "parameters and then we've talked about the inference or prediction phase in which we use all of that to make",
    "start": "2049599",
    "end": "2056280"
  },
  {
    "text": "predictions so I'm kind of curious in your mind Chris what do you consider the",
    "start": "2056280",
    "end": "2061760"
  },
  {
    "text": "model like what is the model in your mind amongst all of that so the way I would think of a model is I think of it",
    "start": "2061760",
    "end": "2068679"
  },
  {
    "text": "when you start out with these layers of neurons lined up and and we're talking about the simplest use case obviously",
    "start": "2068679",
    "end": "2076240"
  },
  {
    "text": "and there are you can you can add a lot of different uh complexity to this uh",
    "start": "2076240",
    "end": "2082158"
  },
  {
    "text": "over time to achieve different architectures and there are many many architectures out there um when someone talks about a model though I typically",
    "start": "2082159",
    "end": "2088599"
  },
  {
    "text": "think of a trained architecture if you think of a fully connected feed forward architecture uh as being something",
    "start": "2088599",
    "end": "2095358"
  },
  {
    "text": "you're training when it gets done it has a purpose it's trying to create it's its",
    "start": "2095359",
    "end": "2100440"
  },
  {
    "text": "purpose is to make inferences about a particular set of inputs to give you an output and that's what I would call a",
    "start": "2100440",
    "end": "2107280"
  },
  {
    "text": "train model it's it's the architecture at work that that is uh Deployable one",
    "start": "2107280",
    "end": "2112520"
  },
  {
    "text": "thing that we didn't mention briefly uh is that is is when you're training a",
    "start": "2112520",
    "end": "2118440"
  },
  {
    "text": "model how do you know when you've gotten there and I just wanted to note that uh",
    "start": "2118440",
    "end": "2123520"
  },
  {
    "text": "it's it's it's arbitrary based on your use case in that uh we've been talking about the fact that when you get to each",
    "start": "2123520",
    "end": "2130160"
  },
  {
    "text": "uh the end of each cycle in training you have some sort of uh Delta between what",
    "start": "2130160",
    "end": "2136040"
  },
  {
    "text": "you have and what you know to be the truth and so that is an error that you have there there's a it's it's a it's a",
    "start": "2136040",
    "end": "2142960"
  },
  {
    "text": "a degree of error and you have to decide for your use case how much error can you tolerate uh if you can tolerate more",
    "start": "2142960",
    "end": "2149920"
  },
  {
    "text": "error because it's not a very critical uh need and you know if it happened to be wrong it might not it might not be a",
    "start": "2149920",
    "end": "2156480"
  },
  {
    "text": "terrible thing then you can can probably achieve training quicker and deploy because it's not if it's a life and death thing and it has to be extremely",
    "start": "2156480",
    "end": "2163680"
  },
  {
    "text": "accurate uh then you need a very small error uh in your final product and therefore you may take quite a bit more",
    "start": "2163680",
    "end": "2169960"
  },
  {
    "text": "training to achieve that and I just wanted to note that's how you know when your training is over is that you've",
    "start": "2169960",
    "end": "2175160"
  },
  {
    "text": "achieved an acceptable level of error for your use case Chris uh you were just talking about kind of the acceptable",
    "start": "2175160",
    "end": "2182520"
  },
  {
    "text": "level of of error with a neural network and I think something that you know needs to be here is that these nodes or",
    "start": "2182520",
    "end": "2190680"
  },
  {
    "text": "these neurons can be assembled in all sorts of from simple to very complicated",
    "start": "2190680",
    "end": "2196160"
  },
  {
    "text": "ways and you could have sort of layer after layer of these um that might be",
    "start": "2196160",
    "end": "2201640"
  },
  {
    "text": "fully connected might not be fully connected um but as soon as you start adding these things up or putting them",
    "start": "2201640",
    "end": "2208359"
  },
  {
    "text": "assembling them in all sorts of complicated ways which is really what's done in deep learning then you start",
    "start": "2208359",
    "end": "2214640"
  },
  {
    "text": "accumulating a a ton of parameters so in some of these you know in some of these",
    "start": "2214640",
    "end": "2220160"
  },
  {
    "text": "recent models let's say like Transformer models that have come out for language there's millions in fact hundreds of",
    "start": "2220160",
    "end": "2226800"
  },
  {
    "text": "millions of parameters that need to be set and so when you're thinking about the compute and the data that's needed",
    "start": "2226800",
    "end": "2233760"
  },
  {
    "text": "to actually train these models or fit all of those parameters now you can kind of understand why a lot of data and a",
    "start": "2233760",
    "end": "2240880"
  },
  {
    "text": "lot of compute is needed because you can't have like 300 million parameters",
    "start": "2240880",
    "end": "2246079"
  },
  {
    "text": "and then like 2,00 training examples and call it good and say that's going to set",
    "start": "2246079",
    "end": "2251400"
  },
  {
    "text": "all of your parameters you have to have a significant amount of data for you to be able to kind of learn the complicated",
    "start": "2251400",
    "end": "2258000"
  },
  {
    "text": "patterns and fit all these parameters so a ton of compute and a ton of um a ton",
    "start": "2258000",
    "end": "2264119"
  },
  {
    "text": "of data is needed absolutely it's I think in calling out the scale that",
    "start": "2264119",
    "end": "2269280"
  },
  {
    "text": "you're talking about there is important because it is uh it is a distinguishing factor between this particular tool in",
    "start": "2269280",
    "end": "2276200"
  },
  {
    "text": "data science and other tools that we've all worked with previously um I think it's you know and and people say okay I",
    "start": "2276200",
    "end": "2283960"
  },
  {
    "text": "understand that and and they're they shortly upon coming into the field you learn that there is special Hardware",
    "start": "2283960",
    "end": "2290319"
  },
  {
    "text": "used for the computation and people uh have often ask me why is that I've heard GPU and stuff like that and um and that",
    "start": "2290319",
    "end": "2297640"
  },
  {
    "text": "is the fact that to do these computations which are actually uh they're not they're not complex but it",
    "start": "2297640",
    "end": "2304520"
  },
  {
    "text": "is a field of linear algebra it's called Matrix multiplication and as Daniel just",
    "start": "2304520",
    "end": "2310119"
  },
  {
    "text": "pointed out when he was talking about the scale of the parameters and and you might have very large architectures with",
    "start": "2310119",
    "end": "2316000"
  },
  {
    "text": "many many neurons and that that are all concurrently doing uh these mathematical operations you it it it lends it lends",
    "start": "2316000",
    "end": "2324160"
  },
  {
    "text": "to efficiency to have uh Hardware that is able to do this type of computation",
    "start": "2324160",
    "end": "2330160"
  },
  {
    "text": "uh much faster than than the hardware that came before and that's why you hear about uh gpus and tpus versus something",
    "start": "2330160",
    "end": "2337760"
  },
  {
    "text": "that we may have all grown up with which was the CPU you know driving our laptop and stuff and that is that this Hardware",
    "start": "2337760",
    "end": "2344319"
  },
  {
    "text": "enables these math enables the mathematical operations that have to happen at such scale um and that that it",
    "start": "2344319",
    "end": "2351200"
  },
  {
    "text": "that the fact that you have that relationship there is really distinguishes this particular data",
    "start": "2351200",
    "end": "2358400"
  },
  {
    "text": "science toolbox from others and makes it expensive in some cases oh boy um yeah",
    "start": "2358400",
    "end": "2365680"
  },
  {
    "text": "so we we've talked about the neural uh or neurons we've talked about",
    "start": "2365680",
    "end": "2370880"
  },
  {
    "text": "architectures or or combinations of these neurons we've talked about what it takes to fit all of these parameters of",
    "start": "2370880",
    "end": "2377760"
  },
  {
    "text": "the neurons but we haven't actually got to maybe what's the most important point",
    "start": "2377760",
    "end": "2384119"
  },
  {
    "text": "which is why do neural networks work so if you think about kind of what we've",
    "start": "2384119",
    "end": "2389640"
  },
  {
    "text": "done it's it's somewhat um arbitrary in some ways in the sense that we've just",
    "start": "2389640",
    "end": "2395720"
  },
  {
    "text": "put a bunch of functions all together in a in a row that combine things over and",
    "start": "2395720",
    "end": "2401200"
  },
  {
    "text": "over that's that's kind of simplifying things but it's it's really what we're doing there's inputs and those are fed",
    "start": "2401200",
    "end": "2408200"
  },
  {
    "text": "through a bunch of things that combine them over and over and then output something that combines that output over",
    "start": "2408200",
    "end": "2413440"
  },
  {
    "text": "and over um and you know why why does that sort of thing work um and the way I",
    "start": "2413440",
    "end": "2419880"
  },
  {
    "text": "kind of like to think about it I'm curious about you know how you think about it and I know there's more",
    "start": "2419880",
    "end": "2425280"
  },
  {
    "text": "formalisms we can put around it but the way I like to think about it is you know if I have a relationship let's say",
    "start": "2425280",
    "end": "2431520"
  },
  {
    "text": "between some input and output and I'm thinking of like again the users and sales example that might be a fairly you",
    "start": "2431520",
    "end": "2439200"
  },
  {
    "text": "know simple relationship it might just be a proportional one that I can that I can model via one or two parameters and",
    "start": "2439200",
    "end": "2446920"
  },
  {
    "text": "I just put that in and you know there's a simple relationship there but there's a lot more complicated relationships in",
    "start": "2446920",
    "end": "2453720"
  },
  {
    "text": "our world like you know if I'm trying to detect a face and image there's a lot of important things there from from color",
    "start": "2453720",
    "end": "2460920"
  },
  {
    "text": "to edges to certain features of the face and it's really hard for me to write",
    "start": "2460920",
    "end": "2467200"
  },
  {
    "text": "down a definition using my own domain knowledge that kind of is a definition",
    "start": "2467200",
    "end": "2472240"
  },
  {
    "text": "of a model of a face and so the way I think about neural networks is kind of",
    "start": "2472240",
    "end": "2477560"
  },
  {
    "text": "just saying well okay I'm not even going to try to write down this sort of domain knowledge definition what I'm going to",
    "start": "2477560",
    "end": "2483720"
  },
  {
    "text": "do is make my model definition as complic ated as it needs to be such that",
    "start": "2483720",
    "end": "2490280"
  },
  {
    "text": "whatever the relationships are between my input and output whatever those happen to be I'm able to account for",
    "start": "2490280",
    "end": "2497040"
  },
  {
    "text": "those complexities because my model is is parameterized in s such a complex way",
    "start": "2497040",
    "end": "2504000"
  },
  {
    "text": "and so this takes some of the some of the burden off of the programmer the",
    "start": "2504000",
    "end": "2509200"
  },
  {
    "text": "domain expert and really puts it on the computer in terms of computation and data um because I all the Assumption I",
    "start": "2509200",
    "end": "2517280"
  },
  {
    "text": "making is that there is a relationship between my input and output and if my definition is complicated enough I'm",
    "start": "2517280",
    "end": "2523160"
  },
  {
    "text": "going to be able to parameterize it to to model that that that is actually a",
    "start": "2523160",
    "end": "2528240"
  },
  {
    "text": "great explanation I really like how you said that um and it's I think it differentiates uh from a number of other",
    "start": "2528240",
    "end": "2535800"
  },
  {
    "text": "approaches one might take and so um you know when we are using neural networks",
    "start": "2535800",
    "end": "2542200"
  },
  {
    "text": "to solve really complex problems um we'll try there's a balance act that",
    "start": "2542200",
    "end": "2547640"
  },
  {
    "text": "we're trying to do um the bigger the architecture the more computation you're",
    "start": "2547640",
    "end": "2553119"
  },
  {
    "text": "introducing into it by default um but you need it and and you can actually",
    "start": "2553119",
    "end": "2558880"
  },
  {
    "text": "have there there's actually uh mathematically the ability you could have a a feedforward network with a",
    "start": "2558880",
    "end": "2565280"
  },
  {
    "text": "single hidden layer and I since we haven't specifically mentioned the word hidden uh think about this neural",
    "start": "2565280",
    "end": "2571119"
  },
  {
    "text": "network architecture that we talked about and you had that input layer of neurons and then the second layer uh",
    "start": "2571119",
    "end": "2577240"
  },
  {
    "text": "only takes the output from the first layer and then it passes its output to a third layer which is your output so you",
    "start": "2577240",
    "end": "2583200"
  },
  {
    "text": "have a hidden uh I'm sorry an input a hidden and an output and um there is a",
    "start": "2583200",
    "end": "2588800"
  },
  {
    "text": "mathematical equation called the universal approximation theorem so you can go look it up on wekipedia um which",
    "start": "2588800",
    "end": "2594920"
  },
  {
    "text": "and it it notes that a feed for network with a single hidden layer uh containing a finite number of neurons can",
    "start": "2594920",
    "end": "2601440"
  },
  {
    "text": "approximate continuous functions and that sounds like you know not not a very impressive statement to make but I think",
    "start": "2601440",
    "end": "2608040"
  },
  {
    "text": "it's it's pretty amazing and that there's it's saying you can approximate all sorts of different functions out",
    "start": "2608040",
    "end": "2613920"
  },
  {
    "text": "there uh and I think that's really important because it it lends itself to why this is so powerful and going back to what you said a moment ago Daniel you",
    "start": "2613920",
    "end": "2620599"
  },
  {
    "text": "mentioned the fact that we'll add complexity because if you have a really complex function that one hidden layer",
    "start": "2620599",
    "end": "2627319"
  },
  {
    "text": "might eventually get there but it may be unreasonable in terms of its uh the time it takes to train it to get there to get",
    "start": "2627319",
    "end": "2633640"
  },
  {
    "text": "within what is an allowable error for you and so the way we get around that is we either add more neurons or we add",
    "start": "2633640",
    "end": "2641119"
  },
  {
    "text": "more layers to it and we so we deliberately add complexity before we know what the solution is and in doing",
    "start": "2641119",
    "end": "2647200"
  },
  {
    "text": "that it gives it gives the this matrix multiplication a lot more options on",
    "start": "2647200",
    "end": "2653119"
  },
  {
    "text": "finding all those little things the you know here's a line and here's how here's a a line with another line that creates",
    "start": "2653119",
    "end": "2659640"
  },
  {
    "text": "a shape and you know and L and behold it turns into uh part of the face or something eventually and so by having",
    "start": "2659640",
    "end": "2665880"
  },
  {
    "text": "these layers that complexity allows you to pick apart pieces of it and do it and",
    "start": "2665880",
    "end": "2670960"
  },
  {
    "text": "so you're balancing how big of a neuron how big of a network do I want uh for computational expense versus what do my",
    "start": "2670960",
    "end": "2678200"
  },
  {
    "text": "problem require um and so it's a it's when you get into this field you learn that you have to balance that and then",
    "start": "2678200",
    "end": "2684400"
  },
  {
    "text": "you uh and then obviously have various architectures that lend themselves to solving particular problems speaking of",
    "start": "2684400",
    "end": "2690680"
  },
  {
    "text": "uh getting into this field I think maybe you know with the few minutes that we have left here Chris it might be good to",
    "start": "2690680",
    "end": "2697559"
  },
  {
    "text": "just talk about you know if you're getting into this field or if you really like you've done some tutorials with",
    "start": "2697559",
    "end": "2704760"
  },
  {
    "text": "neural networks but you don't kind of have this fundamental understanding of how they operate um how can you get some",
    "start": "2704760",
    "end": "2711160"
  },
  {
    "text": "of that intuition about how neural networks operate I know one of the things that that I did in the past that",
    "start": "2711160",
    "end": "2717520"
  },
  {
    "text": "was really really helpful for me was implementing kind of a simple feedforward neural network uh from",
    "start": "2717520",
    "end": "2725280"
  },
  {
    "text": "scratch and I did that for the iris classification problem which is kind of",
    "start": "2725280",
    "end": "2730440"
  },
  {
    "text": "a a very well- defined classic problem in machine learning where you're trying to classify types of Iris flowers based",
    "start": "2730440",
    "end": "2738400"
  },
  {
    "text": "on the measurements of their petals and um I did this in uh in the go language",
    "start": "2738400",
    "end": "2744839"
  },
  {
    "text": "um because I I was also interested in in that and using that um but I think whatever language you use it it doesn't",
    "start": "2744839",
    "end": "2751240"
  },
  {
    "text": "really matter but just kind of uh introducing each of these components like the neuron the activation function",
    "start": "2751240",
    "end": "2759000"
  },
  {
    "text": "this Loop of training um is really really useful to gain a fundamental understanding and one one way if if",
    "start": "2759000",
    "end": "2765640"
  },
  {
    "text": "that's kind of intimidating to you I might recommend the uh great book from Joel Gru uh called data science from",
    "start": "2765640",
    "end": "2772559"
  },
  {
    "text": "scratch he just released a second edition of that book and um he added in",
    "start": "2772559",
    "end": "2778160"
  },
  {
    "text": "uh a bunch of things about neural networks uh deep learning recurrent neural networks but in that book he kind",
    "start": "2778160",
    "end": "2783720"
  },
  {
    "text": "of walks you through some implementations ofur Neal networks from scratch using Python and so I think",
    "start": "2783720",
    "end": "2790720"
  },
  {
    "text": "that's a it's a really great way to gain this fundamental uh intuition and um",
    "start": "2790720",
    "end": "2795920"
  },
  {
    "text": "something that I think would be even good for for me to do uh occasionally in",
    "start": "2795920",
    "end": "2801720"
  },
  {
    "text": "different languages or in different ways to kind of help me keep that that intuition yeah not only that there are",
    "start": "2801720",
    "end": "2808520"
  },
  {
    "text": "so many um there's so many approaches I really think it's such a great time to get into this field right now um it's",
    "start": "2808520",
    "end": "2815680"
  },
  {
    "text": "it's it has I won't call it mature but it it has matured a lot in the last few years and back when you and I were first",
    "start": "2815680",
    "end": "2822640"
  },
  {
    "text": "looking at it um incidentally that's that's what I did as well in in same programming language I I created a toy",
    "start": "2822640",
    "end": "2828880"
  },
  {
    "text": "neural network uh in go uh just to make sure that I was understood where where I",
    "start": "2828880",
    "end": "2835160"
  },
  {
    "text": "wanted to start from and you know all the pieces made sense to me um it was it was more of a a science you know",
    "start": "2835160",
    "end": "2841200"
  },
  {
    "text": "experiment kind of thing um and and before moving into Frameworks which is where the real action is but there's a",
    "start": "2841200",
    "end": "2847200"
  },
  {
    "text": "lot of learning s if if you're into books there's all sorts of different books um there's the uh there's the Deep",
    "start": "2847200",
    "end": "2852760"
  },
  {
    "text": "learning textbook uh which is uh which was written by several of the The Luminaries in the field uh you got to",
    "start": "2852760",
    "end": "2860520"
  },
  {
    "text": "love your math if you want to jump into that one if you're very comfortable with your linear algebra and your Calculus then that's a great place to go if",
    "start": "2860520",
    "end": "2866920"
  },
  {
    "text": "you're not so then it's a good reference to try to work toward but you might want to find some some books that uh cater to",
    "start": "2866920",
    "end": "2873640"
  },
  {
    "text": "whatever your knowledge level is and also there there's a whole bunch of of really fantastic courses online of",
    "start": "2873640",
    "end": "2880280"
  },
  {
    "text": "course Sarah has them Microsoft Google um there's a bunch out there and so",
    "start": "2880280",
    "end": "2885960"
  },
  {
    "text": "whatever your approach to learning is however you consume uh new information",
    "start": "2885960",
    "end": "2891839"
  },
  {
    "text": "best uh I can almost guarantee there's there's a high value way of doing that uh that that you can cater it around",
    "start": "2891839",
    "end": "2897880"
  },
  {
    "text": "yourself I I know that didn't really exist when we were uh doing ours originally um but the last 2 three years",
    "start": "2897880",
    "end": "2904480"
  },
  {
    "text": "it's just exploded yeah there's there's great online resources um I really like the machine learning crash course uh",
    "start": "2904480",
    "end": "2911680"
  },
  {
    "text": "from Google there's of course the fast. AI material that's all online that people love so it's a great time to get",
    "start": "2911680",
    "end": "2918920"
  },
  {
    "text": "into the field and um this is you know hopefully this has given you a sense of",
    "start": "2918920",
    "end": "2924200"
  },
  {
    "text": "what neural networks are or given you a refresher in that um to really encourage you that like we we can you know get",
    "start": "2924200",
    "end": "2931079"
  },
  {
    "text": "some intuition about what's going on under the hood here and and that's not too far away from you it's within reach",
    "start": "2931079",
    "end": "2937160"
  },
  {
    "text": "so if you have a passion about this stuff you know get involved dive into some resources let us know if you need",
    "start": "2937160",
    "end": "2943440"
  },
  {
    "text": "help uh finding those resources um and yeah I'm I'm just uh excited about the",
    "start": "2943440",
    "end": "2949559"
  },
  {
    "text": "next 50 episodes that we get to dive into more about AI Chris I am too I hope I hope uh people listening out there",
    "start": "2949559",
    "end": "2956240"
  },
  {
    "text": "will join us in the various communities we're on slack we're on LinkedIn we're",
    "start": "2956240",
    "end": "2961280"
  },
  {
    "text": "on Twitter uh and and we really do have a lot of great conversations and as we look toward the next 50 the episodes we",
    "start": "2961280",
    "end": "2967640"
  },
  {
    "text": "really want your input what do you want to hear about who do you want to hear from what topics are of interest to you",
    "start": "2967640",
    "end": "2974200"
  },
  {
    "text": "um and and we really want to build the next 50 episodes around you yep and uh",
    "start": "2974200",
    "end": "2979520"
  },
  {
    "text": "congrats again Chris uh great great uh to be doing this with you and uh looking",
    "start": "2979520",
    "end": "2985520"
  },
  {
    "text": "forward to to the future episodes we'll see you next week see you next week thank",
    "start": "2985520",
    "end": "2991720"
  },
  {
    "text": "you all right thank you for tuning into this episode of practical AI if you enjoyed the show do us a favor go on",
    "start": "2991720",
    "end": "2997720"
  },
  {
    "text": "iTunes give us a rating go in your podcast app and favored it if you are on Twitter or social network share a link",
    "start": "2997720",
    "end": "3003319"
  },
  {
    "text": "with a friend whatever you got to do share the show with a friend if you enjoyed it and band withd for change log is provided by fastly learn more at",
    "start": "3003319",
    "end": "3009880"
  },
  {
    "text": "fastly.com and we catch our erors before our users do here at changelog because of robbar check them out at rar.com",
    "start": "3009880",
    "end": "3016160"
  },
  {
    "text": "changelog and we're hosted on Leno Cloud servers head to lin.com changelog check",
    "start": "3016160",
    "end": "3021799"
  },
  {
    "text": "them out support this show this episode is hosted by Daniel whitenack and Chris Benson the music is by breakmaster",
    "start": "3021799",
    "end": "3028760"
  },
  {
    "text": "cylinder and you can find more shows just like this at changel law.com when you go there pop in your email address",
    "start": "3028760",
    "end": "3035319"
  },
  {
    "text": "get our weekly email keeping you up to date with the news and podcast for developers in your inbox every single",
    "start": "3035319",
    "end": "3041119"
  },
  {
    "text": "week thanks for tuning in we'll see you next [Music]",
    "start": "3041119",
    "end": "3053240"
  },
  {
    "text": "week",
    "start": "3053240",
    "end": "3056240"
  }
]
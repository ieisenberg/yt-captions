[
  {
    "text": "[Music]",
    "start": "330",
    "end": "5829"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspire to or are",
    "start": "7160",
    "end": "13759"
  },
  {
    "text": "curious how AI related Technologies are changing the world this is the show for you thank you to our partners at fastly",
    "start": "13759",
    "end": "21160"
  },
  {
    "text": "for shipping all of our pods super fast to wherever you listen check them out at",
    "start": "21160",
    "end": "26240"
  },
  {
    "text": "fast.com and to our friends at fly deploy your app and database close to",
    "start": "26240",
    "end": "31359"
  },
  {
    "text": "your users no Ops required learn more at",
    "start": "31359",
    "end": "37000"
  },
  {
    "text": "[Music]",
    "start": "37140",
    "end": "42399"
  },
  {
    "text": "fly.io welcome to another fully connected episode of practical AI in",
    "start": "42399",
    "end": "47960"
  },
  {
    "text": "these episodes Chris and I keep you fully connected with everything that's happening in the AI Community we're",
    "start": "47960",
    "end": "54840"
  },
  {
    "text": "going to take some time to discuss the latest AI news and then we'll share some learning resources to help you level up",
    "start": "54840",
    "end": "61640"
  },
  {
    "text": "your machine learning game this is Daniel Whit neck I'm a founder and data scientist at prediction guard and I'm",
    "start": "61640",
    "end": "68640"
  },
  {
    "text": "joined as always by my co-host Chris Benson who is a tech strategist at loed",
    "start": "68640",
    "end": "74439"
  },
  {
    "text": "Martin how you doing Chris doing cool I'm trying to figure out how did we survive before all these great new",
    "start": "74439",
    "end": "80799"
  },
  {
    "text": "models and stuff like it's changed oh yeah it's been crazy yeah I I just",
    "start": "80799",
    "end": "87280"
  },
  {
    "text": "created a um a post for LinkedIn and I was like grabbing text putting it into",
    "start": "87280",
    "end": "94079"
  },
  {
    "text": "chat GPT like getting nice rephrasing and then like oh I need an image and in",
    "start": "94079",
    "end": "100000"
  },
  {
    "text": "particular we'll talk about it a little bit in this episode but I was like oh there's this free Willie model from",
    "start": "100000",
    "end": "105960"
  },
  {
    "text": "stable AI which is like whale themed right and then I've got the Llama thing so I just went to stable diffusion Excel",
    "start": "105960",
    "end": "113880"
  },
  {
    "text": "on clip drop and said hey generate me an image with a whale and a llama together",
    "start": "113880",
    "end": "120000"
  },
  {
    "text": "and you know how do I even post to LinkedIn before without these things",
    "start": "120000",
    "end": "125840"
  },
  {
    "text": "it's like a different world yeah 2023 versus 2022 is totally different the",
    "start": "125840",
    "end": "131640"
  },
  {
    "text": "content generation the way you code it's a different world yeah and this week as",
    "start": "131640",
    "end": "138760"
  },
  {
    "text": "most weeks are it seems like in 2023 had some pretty groundbreaking announcements",
    "start": "138760",
    "end": "146640"
  },
  {
    "text": "and releases um which we're going to dive into a bunch of those things there's there's just a huge amount to",
    "start": "146640",
    "end": "153040"
  },
  {
    "text": "update on and I think it's a good time for one of these episodes between you and I to just parse through some of the",
    "start": "153040",
    "end": "159959"
  },
  {
    "text": "new stuff that is hitting our feeds so yeah well I mentioned llama um one of",
    "start": "159959",
    "end": "167239"
  },
  {
    "text": "the big things this week was llama 2 but I think before we jump into llama 2 which I think was maybe the main thing",
    "start": "167239",
    "end": "174560"
  },
  {
    "text": "dominating at least my world this week it it might be worth just taking a little bit of time to highlight",
    "start": "174560",
    "end": "180599"
  },
  {
    "text": "something outside of the stream of large language models which also crossed my",
    "start": "180599",
    "end": "186720"
  },
  {
    "text": "desk this week which I thought was really cool it's this latest version of",
    "start": "186720",
    "end": "192799"
  },
  {
    "text": "Nerf this is work from Google presented at iccv uh 2023 so it's called zip Nerf",
    "start": "192799",
    "end": "202480"
  },
  {
    "text": "anti-alias grid based neural Radiance field that's quite a name right there it",
    "start": "202480",
    "end": "208040"
  },
  {
    "text": "is quite a name um stands for neural Radiance Fields so Nerf it's like camel",
    "start": "208040",
    "end": "214280"
  },
  {
    "text": "cased in capital N Small E then Capital RF Nerf these are fully connected neural",
    "start": "214280",
    "end": "221840"
  },
  {
    "text": "networks that create unique novel views of complicated 3D scenes based on a set",
    "start": "221840",
    "end": "230560"
  },
  {
    "text": "of images that are input so I don't know if you seen that video yet I'm looking",
    "start": "230560",
    "end": "236640"
  },
  {
    "text": "at it as we are talking and when you say the video I know which video you're talking about cuz it's amazing I've just",
    "start": "236640",
    "end": "242959"
  },
  {
    "text": "left it on it's pretty spectacular yeah so this is a podcast so it's hard to",
    "start": "242959",
    "end": "248200"
  },
  {
    "text": "express some of this for people if you just search for zip Nerf you can go to",
    "start": "248200",
    "end": "253480"
  },
  {
    "text": "the page for this paper which is a great summary but there's a video on the page",
    "start": "253480",
    "end": "258840"
  },
  {
    "text": "and just to describe what it is imagine this kind of complicated house with a",
    "start": "258840",
    "end": "265240"
  },
  {
    "text": "bunch of different rooms and an outdoor patio sort of Garden area yeah and the",
    "start": "265240",
    "end": "270720"
  },
  {
    "text": "video is actually this kind of almost like a drone fly through of the house",
    "start": "270720",
    "end": "276280"
  },
  {
    "text": "and then the outdoor area if you imagine a drone flying through a house there's",
    "start": "276280",
    "end": "281560"
  },
  {
    "text": "hats and coats and toys and couches and plants and all sorts of things everywhere but the video is extremely",
    "start": "281560",
    "end": "289080"
  },
  {
    "text": "seamless and it's not generated by a drone it's actually just generated by",
    "start": "289080",
    "end": "294520"
  },
  {
    "text": "interpolating between a whole bunch of 2D images",
    "start": "294520",
    "end": "300240"
  },
  {
    "text": "and then interpolating from that the 3D scene so yeah I don't know what are your",
    "start": "300240",
    "end": "306440"
  },
  {
    "text": "impressions Chris first of all the the from the perspective the Drone flight if you will that you have as a perspective",
    "start": "306440",
    "end": "312639"
  },
  {
    "text": "viewing it is like the best drone operator in the history of the world yeah it would probably be hard to get",
    "start": "312639",
    "end": "317720"
  },
  {
    "text": "one to do that yeah yeah you're not going to get a real drone operator that could fly that amazingly you know and",
    "start": "317720",
    "end": "324160"
  },
  {
    "text": "get those things it's just phenomenal and the house is like for a moment you",
    "start": "324160",
    "end": "329199"
  },
  {
    "text": "look at it and I mean it is it looks real but I have noticed it's cluttery",
    "start": "329199",
    "end": "335360"
  },
  {
    "text": "but it's immaculately clean at the same time as well um the the Clutter is",
    "start": "335360",
    "end": "341520"
  },
  {
    "text": "cleanly distributed and stuff so um I wish when my house was cluttered it looked as beautiful as this house uh it",
    "start": "341520",
    "end": "348160"
  },
  {
    "text": "doesn't but but yeah I mean just like if you didn't know if you weren't listening to the you know practical AI podcast to",
    "start": "348160",
    "end": "354919"
  },
  {
    "text": "go look at it or something like that and you just stumbled upon it you'd think it was a drone video you know if you didn't",
    "start": "354919",
    "end": "360479"
  },
  {
    "text": "have the education you go oh my God this is just really cool I wonder how you know wonder what they're doing here but",
    "start": "360479",
    "end": "366639"
  },
  {
    "text": "it's indistinguishable from real life for all practical purposes yeah and so it's based on 2D images and then there",
    "start": "366639",
    "end": "373039"
  },
  {
    "text": "are these generated interpolations which maybe gets to there was something that",
    "start": "373039",
    "end": "378120"
  },
  {
    "text": "we were talking about prior to hitting the record button which was this whole",
    "start": "378120",
    "end": "383880"
  },
  {
    "text": "field of generative AI is sometimes conflated with large language models or",
    "start": "383880",
    "end": "390240"
  },
  {
    "text": "chat GP but there's a whole lot going on in generative AI That's not language",
    "start": "390240",
    "end": "395680"
  },
  {
    "text": "related or maybe even based on language related prompts so I mentioned that image that I generated for my LinkedIn",
    "start": "395680",
    "end": "402639"
  },
  {
    "text": "post that was still an a text prompted into an model that generated an image",
    "start": "402639",
    "end": "409319"
  },
  {
    "text": "but here what we're seeing is we've got static 2D images that are input to a",
    "start": "409319",
    "end": "415160"
  },
  {
    "text": "model that's actually generating a whole bunch of different pers perspectives",
    "start": "415160",
    "end": "420199"
  },
  {
    "text": "that are synthesized in a 3D scene so this is I would say still fitting into",
    "start": "420199",
    "end": "428039"
  },
  {
    "text": "our current landscape and world of generative AI but it's not a text in",
    "start": "428039",
    "end": "434800"
  },
  {
    "text": "text out or text in image out model right and I think people there's so much",
    "start": "434800",
    "end": "440840"
  },
  {
    "text": "coming at people right now I think you know we keep talking about that this year in the 5 years we've been doing",
    "start": "440840",
    "end": "446039"
  },
  {
    "text": "this podcast we've never had a moment like the last few months where things have been coming new things",
    "start": "446039",
    "end": "451680"
  },
  {
    "text": "have been coming at people so fast new terms new models and people are trying to distinguish so it's pretty I think",
    "start": "451680",
    "end": "457240"
  },
  {
    "text": "it's pretty fair that people are trying to make sense of how they relate together and there's there's a lot of connecting between you know the the idea",
    "start": "457240",
    "end": "464280"
  },
  {
    "text": "of generative and the idea of large language models overlap in a lot of areas and you have models that are both",
    "start": "464280",
    "end": "469479"
  },
  {
    "text": "and you have models that are just one and stuff but I think it's a Brave New World right now in terms of the the",
    "start": "469479",
    "end": "474520"
  },
  {
    "text": "amount every show we're just trying to figure out what matters right now because there's a lot we're not hitting",
    "start": "474520",
    "end": "479759"
  },
  {
    "text": "yeah and this side of things maybe like the 3D or video or image based side of",
    "start": "479759",
    "end": "486319"
  },
  {
    "text": "things I know has its own set of kind of transformative use cases that are popping out I even remember a little",
    "start": "486319",
    "end": "493800"
  },
  {
    "text": "while ago there was some technology I think from Shopify but others have done this as well where maybe you have a room",
    "start": "493800",
    "end": "502560"
  },
  {
    "text": "in your house and you want to see how you can transform it with new furniture",
    "start": "502560",
    "end": "508159"
  },
  {
    "text": "or something that of course could buy this is a real kind of e-commerce or",
    "start": "508159",
    "end": "513360"
  },
  {
    "text": "retail sort of use case for some of this scen technology of a different kind if",
    "start": "513360",
    "end": "520240"
  },
  {
    "text": "you think of this sort of technology that can take 2D things and create these 3D scenes certainly there's use cases",
    "start": "520240",
    "end": "528760"
  },
  {
    "text": "Within game development for example but even other cases where maybe AI has",
    "start": "528760",
    "end": "535839"
  },
  {
    "text": "never impacted the process as much like in real estate for example you know how",
    "start": "535839",
    "end": "542160"
  },
  {
    "text": "expensive is it to literally have a person come out with specialized camera",
    "start": "542160",
    "end": "548200"
  },
  {
    "text": "gear I know that we've had this in the past where it takes a special person to",
    "start": "548200",
    "end": "553880"
  },
  {
    "text": "come out with special camera gear to capture the kind of 3D walkthrough essentially the street view walkth",
    "start": "553880",
    "end": "559760"
  },
  {
    "text": "through of your house and map that onto an actual schematic of your house and",
    "start": "559760",
    "end": "565880"
  },
  {
    "text": "here if you imagine someone maybe I'm now selling my house myself without a",
    "start": "565880",
    "end": "572600"
  },
  {
    "text": "real estate agent and I can take an app potentially and go through my house just",
    "start": "572600",
    "end": "578360"
  },
  {
    "text": "taking 2D images and create this really cool kind of fly around 3D view that's",
    "start": "578360",
    "end": "584880"
  },
  {
    "text": "interactive that's really I think a powerful transformative change for a",
    "start": "584880",
    "end": "590480"
  },
  {
    "text": "number of different Industries I came across a company called Luma AI in one of the posts about this technology I",
    "start": "590480",
    "end": "597519"
  },
  {
    "text": "don't know exactly how much of the if they're even using the zip Nerf stuff but certainly some things related to",
    "start": "597519",
    "end": "604079"
  },
  {
    "text": "Nerf to take these 2D images and they have an app that will create 3D views",
    "start": "604079",
    "end": "611200"
  },
  {
    "text": "which is is pretty cool to see some of this kind of hit actual real users we",
    "start": "611200",
    "end": "616680"
  },
  {
    "text": "keep talking about the fact that we've hit this inflection point where it's hitting all the you don't have to be in the AI world you know for this to have a",
    "start": "616680",
    "end": "623040"
  },
  {
    "text": "big impact and so you know it's very easy looking at the zip Nerf uh video to",
    "start": "623040",
    "end": "629600"
  },
  {
    "text": "imagine walking around with your cell phone on an app and you're you're just kind of like walking around and the app",
    "start": "629600",
    "end": "635880"
  },
  {
    "text": "takes care of whether it's video or whether it's still images or what and it just uploads it to this and produces",
    "start": "635880",
    "end": "641839"
  },
  {
    "text": "this you know amazing you know so it's not your walk around that it's doing it takes that as raw video but then it",
    "start": "641839",
    "end": "648200"
  },
  {
    "text": "produces this super high quality thing so yeah I mean I think this is another case where there's this one technology",
    "start": "648200",
    "end": "654160"
  },
  {
    "text": "with thousands of of use case possibilities you know where it just changes everything yeah and maybe also",
    "start": "654160",
    "end": "659800"
  },
  {
    "text": "in the it'd be curious to know your reaction to this also with respect to kind of the industrial use cases where",
    "start": "659800",
    "end": "668720"
  },
  {
    "text": "I've been thinking about of course like capturing 3D scenes is very important",
    "start": "668720",
    "end": "675040"
  },
  {
    "text": "for example for simulated environments where you're trying to maybe train an",
    "start": "675040",
    "end": "680440"
  },
  {
    "text": "agent or you even kind of an industrial training for human sort of sort of",
    "start": "680440",
    "end": "687959"
  },
  {
    "text": "scenario where you want to kind of take someone into an environment that it's",
    "start": "687959",
    "end": "693519"
  },
  {
    "text": "physically hard to bring a lot of people into yeah or there could be safety issues and such yeah safety issues I",
    "start": "693519",
    "end": "700560"
  },
  {
    "text": "don't know if that that Sparks things in your mind I think in the industrial sense this could have a more B2B sort of",
    "start": "700560",
    "end": "709240"
  },
  {
    "text": "impact than just a consumer app right sure I mean a simple thing and this is",
    "start": "709240",
    "end": "714800"
  },
  {
    "text": "I'm I'm making something up in the next thing I say but it's very easy for me to imagine",
    "start": "714800",
    "end": "719920"
  },
  {
    "text": "uh intelligence agencies that are you know like if you go back some years to when Osama Bin Laden was found uh and",
    "start": "719920",
    "end": "725959"
  },
  {
    "text": "they had you know various imagery and stuff but with stuff like this they might take all those images that they're",
    "start": "725959",
    "end": "731320"
  },
  {
    "text": "getting from various sources and produce you know a high like a fly over a very",
    "start": "731320",
    "end": "736880"
  },
  {
    "text": "yeah fly over and very photorealistic of certain parts of the compound where that kind of imagery and that can be used in",
    "start": "736880",
    "end": "742959"
  },
  {
    "text": "a military operation subsequently I'm making that up so don't nobody should take that as a thing but it's not hard",
    "start": "742959",
    "end": "749399"
  },
  {
    "text": "to imagine that it's not hard to imagine a lot of factory uses and other industrial things where you have safety",
    "start": "749399",
    "end": "756079"
  },
  {
    "text": "issues you have uh limited access kind of concerns um where you're trying to convey that but there's a lot of mundane",
    "start": "756079",
    "end": "762920"
  },
  {
    "text": "things there's a lot of homebased things in small business B things as you pointed out the real estate one earlier",
    "start": "762920",
    "end": "768120"
  },
  {
    "text": "so this is just one technology that we're talking about so far yeah and I",
    "start": "768120",
    "end": "773480"
  },
  {
    "text": "think what you're saying it illustrates how this is impacting very large organizations all",
    "start": "773480",
    "end": "780199"
  },
  {
    "text": "the way down to small organizations yeah sole proprietorships yeah and it's",
    "start": "780199",
    "end": "786639"
  },
  {
    "text": "interesting how like if we just take this use case for example these kind of",
    "start": "786639",
    "end": "792360"
  },
  {
    "text": "3D scenes kind of large scale organizations that maybe their bread and",
    "start": "792360",
    "end": "798199"
  },
  {
    "text": "butter was either the compute associated with like rendering videos and 3D scenes",
    "start": "798199",
    "end": "805880"
  },
  {
    "text": "or their Hardware providers that that are creating specialized kind of 3D type",
    "start": "805880",
    "end": "812680"
  },
  {
    "text": "of equipment like their whole business model they've got to be thinking similar",
    "start": "812680",
    "end": "818399"
  },
  {
    "text": "to other organizations that are dealing with maybe language related problems that are thinking about these things",
    "start": "818399",
    "end": "824000"
  },
  {
    "text": "with respect to llms there's a fundamental shift in maybe how their businesses will operate but then at the",
    "start": "824000",
    "end": "830160"
  },
  {
    "text": "same time it provides an opportunity for the kind of small to medium businesses",
    "start": "830160",
    "end": "835320"
  },
  {
    "text": "to embrace this technology very quickly and actually make Innovative products",
    "start": "835320",
    "end": "843160"
  },
  {
    "text": "that can be widely adopted very quickly and actually be competitors within an",
    "start": "843160",
    "end": "848759"
  },
  {
    "text": "established market so there's an established market for 3D things that",
    "start": "848759",
    "end": "854360"
  },
  {
    "text": "has been quite expensive over time in terms of access to that technology so",
    "start": "854360",
    "end": "860440"
  },
  {
    "text": "now that whole Market's going to change I think a lot of the players will be these kind of small to medium siiz",
    "start": "860440",
    "end": "866160"
  },
  {
    "text": "businesses I agree I think there's a moment here kind of ironically cuz people are so worried about like the",
    "start": "866160",
    "end": "872560"
  },
  {
    "text": "impact on human creativity because of all these models and stuff like that but on a more positive note there's this",
    "start": "872560",
    "end": "878440"
  },
  {
    "text": "huge opportunity that you're just now alluding to for people that if you can connect the dots as things are coming",
    "start": "878440",
    "end": "884399"
  },
  {
    "text": "out and you can stay on top of it it's a great equalizer and so it will clearly",
    "start": "884399",
    "end": "889480"
  },
  {
    "text": "change many many markets that are out there and many many Industries and so",
    "start": "889480",
    "end": "894720"
  },
  {
    "text": "there's huge opportunities for those who want to Surge ahead at this moment and take advantage of that um and so I think",
    "start": "894720",
    "end": "902199"
  },
  {
    "text": "that the message we tend to see in the media tends to be a little bit doomy and gloomy on that but it kind of discounts",
    "start": "902199",
    "end": "907720"
  },
  {
    "text": "the fact that change isn't always a bad thing people are afraid of it but uh there's huge huge opportunities here as",
    "start": "907720",
    "end": "915079"
  },
  {
    "text": "well uh if people uh choose to go find [Music]",
    "start": "915079",
    "end": "925040"
  },
  {
    "text": "[Applause] [Music] them [Applause]",
    "start": "925040",
    "end": "932969"
  },
  {
    "text": "well Chris there is a new llama in town I know llama to llama 2 uh basically",
    "start": "933519",
    "end": "943079"
  },
  {
    "text": "destroyed all of my feeds and concentration this week when it was",
    "start": "943079",
    "end": "949079"
  },
  {
    "text": "released because it is quite to me an encouraging thing but also another",
    "start": "949079",
    "end": "955360"
  },
  {
    "text": "transformative step in in what we're doing so llama 2 for those that maybe",
    "start": "955360",
    "end": "962680"
  },
  {
    "text": "lack the context here meta or Facebook or however you want to refer to it meta",
    "start": "962680",
    "end": "969319"
  },
  {
    "text": "had released a large language model called llama which was extremely useful it was",
    "start": "969319",
    "end": "978000"
  },
  {
    "text": "a it was a model where you could host it yourself as opposed to like open AI you",
    "start": "978000",
    "end": "983600"
  },
  {
    "text": "could get the weights and host it yourself but the original llama had a very restrict",
    "start": "983600",
    "end": "990120"
  },
  {
    "text": "licensing and access sort of pattern even though you could kind of download the weights from maybe like a bit",
    "start": "990120",
    "end": "995800"
  },
  {
    "text": "torrent link or something like that and those propagated technically if you got those",
    "start": "995800",
    "end": "1001440"
  },
  {
    "text": "weights you were still restricted by a license that prevented commercial use",
    "start": "1001440",
    "end": "1007880"
  },
  {
    "text": "cases specifically and now with llama 2 meta",
    "start": "1007880",
    "end": "1013480"
  },
  {
    "text": "has released the kind of follow on to llama and we can talk through some of what the difference are and what it is",
    "start": "1013480",
    "end": "1020680"
  },
  {
    "text": "and some of what went into it but I think one of the biggest things which is",
    "start": "1020680",
    "end": "1026280"
  },
  {
    "text": "I think going to create this huge ripple effect throughout the industry is that",
    "start": "1026280",
    "end": "1031880"
  },
  {
    "text": "they've released it with a commercial license as long as on the day that llama",
    "start": "1031880",
    "end": "1038319"
  },
  {
    "text": "2 was released you as a commercial entity don't have greater than 700",
    "start": "1038319",
    "end": "1045959"
  },
  {
    "text": "million monthly active users you can use it for commercial purposes so maybe if",
    "start": "1045959",
    "end": "1052160"
  },
  {
    "text": "my company maybe later on has 700 million monthly active users which would",
    "start": "1052160",
    "end": "1057360"
  },
  {
    "text": "be great probably never but there'll be something past Lama to by then though yes if it does though I could still",
    "start": "1057360",
    "end": "1063280"
  },
  {
    "text": "actually use it because it's only on the release date so on the release date which was was this week if as long as",
    "start": "1063280",
    "end": "1069480"
  },
  {
    "text": "you didn't have greater than 700 million monthly active users you can use this in",
    "start": "1069480",
    "end": "1075559"
  },
  {
    "text": "your business for commercial use cases and I think that's going to have a huge",
    "start": "1075559",
    "end": "1080679"
  },
  {
    "text": "ripple effect Downstream and we can talk about the model itself here in a second",
    "start": "1080679",
    "end": "1085919"
  },
  {
    "text": "but maybe just I'll pause there to get your reaction on that Chris it made me smile when I heard that because it's",
    "start": "1085919",
    "end": "1091480"
  },
  {
    "text": "kind of like saying so long as you don't compete with us at meta you can use this for commercial oh oh it's totally true",
    "start": "1091480",
    "end": "1097440"
  },
  {
    "text": "yeah like who is that right so that's Snapchat yes Tik Tock right um like you",
    "start": "1097440",
    "end": "1104600"
  },
  {
    "text": "you can think of yeah you can think of who this is and I guess way to put this is it's not totally open source quote",
    "start": "1104600",
    "end": "1113520"
  },
  {
    "text": "unquote like we wouldn't call this a maybe open source in the kind of",
    "start": "1113520",
    "end": "1118600"
  },
  {
    "text": "official definition of Open Source yes but it's certainly commercially available to a very wide set of people",
    "start": "1118600",
    "end": "1127640"
  },
  {
    "text": "yep you know one of the first things I noticed when this came out on their page and they're talk you know there's",
    "start": "1127640",
    "end": "1133280"
  },
  {
    "text": "there's and I'm diving into like the specifics of the model here is we had an episode not too long and you were",
    "start": "1133280",
    "end": "1139640"
  },
  {
    "text": "describing about kind of the I believe it was the 7 billion limit you know in terms of Hardware usage and stuff and",
    "start": "1139640",
    "end": "1146440"
  },
  {
    "text": "having been taught that by you uh I immediately locked in on the smallest being 7 billion there as and I thought",
    "start": "1146440",
    "end": "1153960"
  },
  {
    "text": "ah this is what Daniel has taught all of us about that limitation on on accessibility and who can do it so you",
    "start": "1153960",
    "end": "1160440"
  },
  {
    "text": "know it has the 13 billion and the 70 billion size but I I definitely picked up on the seven billion which I'm",
    "start": "1160440",
    "end": "1166120"
  },
  {
    "text": "assuming is going back to what you were teaching us a few episodes back yeah and",
    "start": "1166120",
    "end": "1171640"
  },
  {
    "text": "so um just to fill in a little bit on that so the Llama 2 release includes",
    "start": "1171640",
    "end": "1177200"
  },
  {
    "text": "three sizes so again thinking back to what are the kind of characteristics of",
    "start": "1177200",
    "end": "1184080"
  },
  {
    "text": "large language models that kind of matter as you're considering using them one is license we've already talked",
    "start": "1184080",
    "end": "1189720"
  },
  {
    "text": "about that a little bit here we might revisit it here in a second another is size because that influences both the",
    "start": "1189720",
    "end": "1196960"
  },
  {
    "text": "hardware that you need to run it and also it's kind of ease of deployment",
    "start": "1196960",
    "end": "1202919"
  },
  {
    "text": "so llama 2 is released in 7 billion parameter 13 billion parameter and 70 billion parameter sizes and then there's",
    "start": "1202919",
    "end": "1211880"
  },
  {
    "text": "also of course the training data and that sort of thing that's related to this and and how it's fine-tuned or",
    "start": "1211880",
    "end": "1219520"
  },
  {
    "text": "instruction tuned so llama 2 has released in these three sizes both as a",
    "start": "1219520",
    "end": "1225960"
  },
  {
    "text": "base large language model and and a chat fine-tuned model so there's the 7",
    "start": "1225960",
    "end": "1233640"
  },
  {
    "text": "billion 13 and 70 billion llama twos and then there's the 713 and 70 billion",
    "start": "1233640",
    "end": "1240120"
  },
  {
    "text": "llama 2 chat models which we can talk about that fine tuning here in a second",
    "start": "1240120",
    "end": "1245640"
  },
  {
    "text": "but yes you're right Chris in that 7 billion I could reasonably pull that into a collab notebook and maybe with a",
    "start": "1245640",
    "end": "1254400"
  },
  {
    "text": "few tricks but with certainly with the great tooling from hugging face including ways to load it in even 4 bit",
    "start": "1254400",
    "end": "1263000"
  },
  {
    "text": "or other quantizations I can run that you know on a T4 for example in Google",
    "start": "1263000",
    "end": "1269080"
  },
  {
    "text": "collab with some of the great tooling that's out there so not needing to have a huge cluster the 70 billion even with",
    "start": "1269080",
    "end": "1277799"
  },
  {
    "text": "that that's kind of another limit where using some of these tricks I've",
    "start": "1277799",
    "end": "1283159"
  },
  {
    "text": "definitely seen people running the 70 billion parameter model on",
    "start": "1283159",
    "end": "1289320"
  },
  {
    "text": "a100 again loading in for bit with some of the quantization stuff and all that the 70 billion is certainly going to be",
    "start": "1289320",
    "end": "1295919"
  },
  {
    "text": "more difficult to run it might require multi multiple gpus but that's kind of that sizing",
    "start": "1295919",
    "end": "1302320"
  },
  {
    "text": "range for people to have in mind and how accessible things are and yeah how might",
    "start": "1302320",
    "end": "1308880"
  },
  {
    "text": "you I'm just curious if you're looking at these you're a business out there or or data scientist and can you make up a",
    "start": "1308880",
    "end": "1315600"
  },
  {
    "text": "couple of use cases that you might Target with each of these where you might say oh I want to go 13 on this not",
    "start": "1315600",
    "end": "1321320"
  },
  {
    "text": "7 not 70 for something like this can you imagine something like this I'm putting you on the spot yeah I think I mean",
    "start": "1321320",
    "end": "1327440"
  },
  {
    "text": "there's certainly innumerable use cases but I think maybe two distinctions that people could have in their mind is if",
    "start": "1327440",
    "end": "1334120"
  },
  {
    "text": "you want like your own private chat GPT right or like a another way you could",
    "start": "1334120",
    "end": "1340720"
  },
  {
    "text": "think about it is a very general purpose model like you could do anything with this model like any specific prompt",
    "start": "1340720",
    "end": "1347520"
  },
  {
    "text": "whatever you're probably going to look towards that higher end the 70 billion parameter model for that kind of almost",
    "start": "1347520",
    "end": "1355880"
  },
  {
    "text": "chat GPT like performance you're going to have to go much higher but as we've",
    "start": "1355880",
    "end": "1361600"
  },
  {
    "text": "talked about on the show before most businesses don't need a general purpose",
    "start": "1361600",
    "end": "1366880"
  },
  {
    "text": "model they need a model to do a thing and so or a task or a set of tasks and",
    "start": "1366880",
    "end": "1373320"
  },
  {
    "text": "so in that case I think businesses because this is open and commercially",
    "start": "1373320",
    "end": "1379000"
  },
  {
    "text": "licensed businesses that could take those 7 and3 billion parameter models",
    "start": "1379000",
    "end": "1384400"
  },
  {
    "text": "and fine-tune them for a task in their business which also is increasingly has",
    "start": "1384400",
    "end": "1390760"
  },
  {
    "text": "amazing tooling around it again from from hugging face and others with the PFT library with parameter efficient",
    "start": "1390760",
    "end": "1397440"
  },
  {
    "text": "fine-tuning and the Laura technique which is the low rank adapter technique",
    "start": "1397440",
    "end": "1403600"
  },
  {
    "text": "which basically only adapts an existing model it's kind of an adapter technique",
    "start": "1403600",
    "end": "1409080"
  },
  {
    "text": "rather than retraining uh a bunch of the the original model this opens up",
    "start": "1409080",
    "end": "1414600"
  },
  {
    "text": "fine-tuning possibilities in these smaller models where that fine-tune for an organization is going to perform",
    "start": "1414600",
    "end": "1420720"
  },
  {
    "text": "probably better than any general purpose model out there and because it's that",
    "start": "1420720",
    "end": "1425960"
  },
  {
    "text": "smaller size you can run it on a reasonable set of Hardware that's not going to require you to you know buy",
    "start": "1425960",
    "end": "1432240"
  },
  {
    "text": "your own GPU cluster to host the thing right so that's kind of a maybe a range of use cases that people could did have",
    "start": "1432240",
    "end": "1438960"
  },
  {
    "text": "in mind I I have one more question for you before we abandon this 7 billion to 70 billion uh being an order magnitude",
    "start": "1438960",
    "end": "1446400"
  },
  {
    "text": "jump on that why would you have something fairly close to that at 13 billion parameters like what's the",
    "start": "1446400",
    "end": "1453279"
  },
  {
    "text": "difference in seven and 13 when the next step is all the way up to 70 what what's the rationality you think yeah so it is",
    "start": "1453279",
    "end": "1460520"
  },
  {
    "text": "interesting actually if I'm understanding right from some of the sources that I've that I've been reading",
    "start": "1460520",
    "end": "1467679"
  },
  {
    "text": "there was actually a I forget if it was 30 or 34 billion parameter model that",
    "start": "1467679",
    "end": "1473200"
  },
  {
    "text": "they were also had in pre-release and were tuning so there was another one",
    "start": "1473200",
    "end": "1478640"
  },
  {
    "text": "that kind of fit in that slot that is kind of missing that Gap like you're talking about like if you think of MPT",
    "start": "1478640",
    "end": "1485360"
  },
  {
    "text": "MPT has a 30 billion parameter model that fits in that kind of Gap my",
    "start": "1485360",
    "end": "1491640"
  },
  {
    "text": "understanding um and you know if our listeners can correct me if I'm wrong please do but my understanding is that",
    "start": "1491640",
    "end": "1498399"
  },
  {
    "text": "they actually did test that size of model and found it to not pass their",
    "start": "1498399",
    "end": "1503679"
  },
  {
    "text": "kind of safety parameters around harmful potentially harmful output or not",
    "start": "1503679",
    "end": "1509919"
  },
  {
    "text": "truthful output that sort of thing so they decided actually to hold that back so it could be possible as they",
    "start": "1509919",
    "end": "1517120"
  },
  {
    "text": "instruction tune and get human feedback potentially more iterations of",
    "start": "1517120",
    "end": "1522960"
  },
  {
    "text": "reinforcement learning from Human feedback there may be a model that they release in that parameter range so that",
    "start": "1522960",
    "end": "1529520"
  },
  {
    "text": "was one thing that that happened I think it is interesting you know several",
    "start": "1529520",
    "end": "1535760"
  },
  {
    "text": "different things here that are unique about this model specifically or maybe the release as",
    "start": "1535760",
    "end": "1542159"
  },
  {
    "text": "well other than the license is they were fairly vague on the data that went into",
    "start": "1542159",
    "end": "1549799"
  },
  {
    "text": "the pre-training so they talked specifically about some very intense",
    "start": "1549799",
    "end": "1555039"
  },
  {
    "text": "data cleaning and filtering that they did on public data sets and it was trained on more data than the",
    "start": "1555039",
    "end": "1562640"
  },
  {
    "text": "original llama but they're fairly vague on the mix of that data and all of that",
    "start": "1562640",
    "end": "1568480"
  },
  {
    "text": "so that may be related to feedback they got on the data sets that were used in",
    "start": "1568480",
    "end": "1573679"
  },
  {
    "text": "the first llama I I don't know but the technical paper was mostly related to the the modeling and fine-tuning",
    "start": "1573679",
    "end": "1581320"
  },
  {
    "text": "trickery and methodologies that they used which was interesting and one of",
    "start": "1581320",
    "end": "1587399"
  },
  {
    "text": "those interest elements of the way that they fine-tune this model was I think the reward",
    "start": "1587399",
    "end": "1594720"
  },
  {
    "text": "modeling so if you remember like the GPT family of models the MPT Falcon these",
    "start": "1594720",
    "end": "1600880"
  },
  {
    "text": "different models one of the things that is often done with these models is this",
    "start": "1600880",
    "end": "1605960"
  },
  {
    "text": "process of reinforcement learning through human feedback which is this",
    "start": "1605960",
    "end": "1611919"
  },
  {
    "text": "process and we covered this on a previous episode which we can link in the show notes but actually using human",
    "start": "1611919",
    "end": "1617679"
  },
  {
    "text": "preferences to score the output of a model and then actually use reinforcement learning to",
    "start": "1617679",
    "end": "1624279"
  },
  {
    "text": "correct the model to better align with human preferences or human feedback they",
    "start": "1624279",
    "end": "1629679"
  },
  {
    "text": "actually use two separate reward models in this fine-tuning of the chatbase",
    "start": "1629679",
    "end": "1635200"
  },
  {
    "text": "model one that was related to helpfulness and then the other one which was related to safety and one of the",
    "start": "1635200",
    "end": "1642960"
  },
  {
    "text": "interesting things that they talked about in the paper was how sometimes those things can kind of work against",
    "start": "1642960",
    "end": "1650279"
  },
  {
    "text": "each other if you're trying to do both of them at the same time so they actually separated out the reward models",
    "start": "1650279",
    "end": "1656919"
  },
  {
    "text": "that they used for the chat fine-tuning into these two reward models one for helpfulness and one for safety which is",
    "start": "1656919",
    "end": "1664159"
  },
  {
    "text": "quite interesting I [Music]",
    "start": "1664159",
    "end": "1675920"
  },
  {
    "text": "think [Music] so Chris maybe just a couple other",
    "start": "1677120",
    "end": "1683919"
  },
  {
    "text": "things related to llama and then I want to see your feedback on code interpreter",
    "start": "1683919",
    "end": "1690480"
  },
  {
    "text": "as well because we haven't talked about that yet on the show and maybe Claude too if we can get to it yeah we got to",
    "start": "1690480",
    "end": "1695960"
  },
  {
    "text": "mention Claude 2 as well because they were both big releases yeah so um just one maybe other note which I find quite",
    "start": "1695960",
    "end": "1703600"
  },
  {
    "text": "interesting and actually I would love uh our previous guest Damian's thoughts on this this uh who was in our last episode",
    "start": "1703600",
    "end": "1710559"
  },
  {
    "text": "about the legal implications of generative AI but one of the interesting things about the Llama license in",
    "start": "1710559",
    "end": "1717240"
  },
  {
    "text": "addition to it allowing this commercial usage is that there is a technically a",
    "start": "1717240",
    "end": "1723720"
  },
  {
    "text": "restriction in the Llama license that says you will not use llama materials",
    "start": "1723720",
    "end": "1729399"
  },
  {
    "text": "which includes the model weights and Etc or any output or results of the law",
    "start": "1729399",
    "end": "1734559"
  },
  {
    "text": "materials to improve any other large language model model excluding llama 2",
    "start": "1734559",
    "end": "1740760"
  },
  {
    "text": "or derivative Works thereof so essentially what this means is if you're using llama 2 and you want to fine-tune",
    "start": "1740760",
    "end": "1747919"
  },
  {
    "text": "a model or you're fine-tuning a model off of llama 2 outputs you're stuck with",
    "start": "1747919",
    "end": "1755000"
  },
  {
    "text": "llama 2 basically llama 2 is your model and that you're going to stick with llama 2 so you couldn't for example",
    "start": "1755000",
    "end": "1761480"
  },
  {
    "text": "technically take the Llama outputs from llama 2 and",
    "start": "1761480",
    "end": "1767039"
  },
  {
    "text": "fine-tune say Dolly 3 billion right that would not be allowed by the license and",
    "start": "1767039",
    "end": "1773559"
  },
  {
    "text": "of course that's something that people are doing all over the place they're taking outputs from GPT 4 and",
    "start": "1773559",
    "end": "1780519"
  },
  {
    "text": "fine-tuning a different model or taking outputs from a large model like you know",
    "start": "1780519",
    "end": "1786480"
  },
  {
    "text": "maybe llama 270 billion now um and fine-tuning another model that's smaller",
    "start": "1786480",
    "end": "1793559"
  },
  {
    "text": "based on a certain type of prompt or something so this is rest restricting",
    "start": "1793559",
    "end": "1799200"
  },
  {
    "text": "that family of models that you're allowed to do that sort of thing with which I is the first time I've seen that",
    "start": "1799200",
    "end": "1805519"
  },
  {
    "text": "and I think it's kind of interesting yes it strikes me as a as another Mark Zuckerberg anti-c competitiveness you",
    "start": "1805519",
    "end": "1811799"
  },
  {
    "text": "know thing which which he's fairly famous for I mean that's kind of even before this yeah and how could you",
    "start": "1811799",
    "end": "1817159"
  },
  {
    "text": "enforce such a thing yeah I I that was my next question to you is is there any",
    "start": "1817159",
    "end": "1822919"
  },
  {
    "text": "possible way that you could conceive of to actually know that from an enforceability point I have no idea I I",
    "start": "1822919",
    "end": "1829919"
  },
  {
    "text": "don't either so it seems It's like a it's a licensed thing and it will concern the lawyers but it's hard to",
    "start": "1829919",
    "end": "1835720"
  },
  {
    "text": "imagine I mean going back to our conversation last week once you have output and that output is input to more",
    "start": "1835720",
    "end": "1843000"
  },
  {
    "text": "output and you know there's a point where it becomes very very very difficult to know what the what the",
    "start": "1843000",
    "end": "1848360"
  },
  {
    "text": "sourcing really was so and the fine tunes are already appearing off of llama",
    "start": "1848360",
    "end": "1855279"
  },
  {
    "text": "2 so the most notable probably is free Willie which is from stability Ai and is",
    "start": "1855279",
    "end": "1861960"
  },
  {
    "text": "a fine-tune of the largest 70 billion model but there's other ones coming out",
    "start": "1861960",
    "end": "1867120"
  },
  {
    "text": "as well and so I think we're about to see just a huge explosion of these llama",
    "start": "1867120",
    "end": "1873960"
  },
  {
    "text": "2 based models for a whole variety of purposes and who knows how they will fit",
    "start": "1873960",
    "end": "1879240"
  },
  {
    "text": "into that licensing restriction or how open people will be about that but it's",
    "start": "1879240",
    "end": "1885480"
  },
  {
    "text": "about to start the fine tunes are already coming yeah well you know to your point earlier they weren't terribly",
    "start": "1885480",
    "end": "1891200"
  },
  {
    "text": "clear about the data that they were sourcing from their own standpoint yeah and I find it interesting a little",
    "start": "1891200",
    "end": "1897440"
  },
  {
    "text": "ironic a bit of a double standard maybe yeah a little bit of a double standard right there in terms of like we're not",
    "start": "1897440",
    "end": "1903240"
  },
  {
    "text": "going to tell you everything about how we're doing input but by the way you better not use our output for your you know for other so yeah a little",
    "start": "1903240",
    "end": "1909799"
  },
  {
    "text": "interesting do you think there's any risk of a wall Garden kind of concept",
    "start": "1909799",
    "end": "1914840"
  },
  {
    "text": "happening in large language models if others were to follow this lead on",
    "start": "1914840",
    "end": "1920840"
  },
  {
    "text": "anti-competitive yeah it will be interesting I think it is a notable",
    "start": "1920840",
    "end": "1926000"
  },
  {
    "text": "Trend that the first llama from meta was not open for commercial at all and now they're opening it up for commercial",
    "start": "1926000",
    "end": "1931960"
  },
  {
    "text": "purposes and you know maybe there's a separate Trend that will happen with some of these use based restrictions",
    "start": "1931960",
    "end": "1938760"
  },
  {
    "text": "that people are importing into their licenses and how useful those things are",
    "start": "1938760",
    "end": "1943799"
  },
  {
    "text": "over time that will May shift and we'll see those things die off or maybe if they're enforced and there's precedent",
    "start": "1943799",
    "end": "1950200"
  },
  {
    "text": "maybe we'll see something go the other way I'm not sure but speaking of models",
    "start": "1950200",
    "end": "1955840"
  },
  {
    "text": "that you might get their output and use it to train other models uh that is",
    "start": "1955840",
    "end": "1961159"
  },
  {
    "text": "these large scale proprietary closed models from people like open Ai and",
    "start": "1961159",
    "end": "1967360"
  },
  {
    "text": "anthropic and others we've got a couple of things that we haven't talked about on the show yet which people should",
    "start": "1967360",
    "end": "1973639"
  },
  {
    "text": "probably have on their Radar Radar um one of those is clae 2 uh what do you",
    "start": "1973639",
    "end": "1980799"
  },
  {
    "text": "think about clae 2 from anthropic yeah I've been I've been playing around with it a lot in the last week uh and I kind",
    "start": "1980799",
    "end": "1988039"
  },
  {
    "text": "of have a set of things that I try over and over again they're kind of my standard tasks as new models come out",
    "start": "1988039",
    "end": "1994159"
  },
  {
    "text": "and some of them are coding and some of them are content generation which are kind of the two big things that I use most often it was interesting you can",
    "start": "1994159",
    "end": "2000600"
  },
  {
    "text": "put you know the input size for Claud 2 is much larger than the others like much",
    "start": "2000600",
    "end": "2006519"
  },
  {
    "text": "much larger much much much larger so 100,000 tokens yeah and so it's had me",
    "start": "2006519",
    "end": "2012559"
  },
  {
    "text": "kind of change the way I'm approaching it in that by contrast with like chat GPT and you're trying to figure out with",
    "start": "2012559",
    "end": "2019480"
  },
  {
    "text": "with the limits that you have both on input and output how do you kind of prompt engineer your way to get you know",
    "start": "2019480",
    "end": "2025480"
  },
  {
    "text": "where you're trying to go which has become this whole skill set we've been talking about you know in recent months",
    "start": "2025480",
    "end": "2031000"
  },
  {
    "text": "and yet Claud 2 almost kind of wipes that out a little bit in some ways not not in all ways and that you can hit it",
    "start": "2031000",
    "end": "2037159"
  },
  {
    "text": "with a much larger uh input space and and so it's changing how I'm thinking",
    "start": "2037159",
    "end": "2042320"
  },
  {
    "text": "about kind of getting to the output that I want and the output is a bit different it's not the same um I'm getting out",
    "start": "2042320",
    "end": "2048919"
  },
  {
    "text": "different outputs from from all the models so yeah they're not all the same definitely I think my biggest thing is",
    "start": "2048919",
    "end": "2054839"
  },
  {
    "text": "with all these new releases I'm trying to figure out how do I use each one when do I I'm trying to develop my own",
    "start": "2054839",
    "end": "2060480"
  },
  {
    "text": "strategy on when do I go to chat GPT by default like when's that the right thing and that's changing as we'll talk about",
    "start": "2060480",
    "end": "2066280"
  },
  {
    "text": "with things like plugins and stuff that's evolving but then Claud 2 comes out and then you have you know on the open source side as we just talked about",
    "start": "2066280",
    "end": "2072599"
  },
  {
    "text": "with llama 2 so I think trying to understand all the tools in the toolbox",
    "start": "2072599",
    "end": "2078398"
  },
  {
    "text": "in relation to each other has been interesting so Claude 2 I'm I'm really focused right now primarily on on large",
    "start": "2078399",
    "end": "2084480"
  },
  {
    "text": "content output is kind of where I've landed on that and the 100K context length of Claud 2 is",
    "start": "2084480",
    "end": "2092079"
  },
  {
    "text": "something I find really compelling as well there was also a significant paper",
    "start": "2092079",
    "end": "2097800"
  },
  {
    "text": "that came out that caused a lot of waves in terms of context length and thinking about that which showed kind of as you",
    "start": "2097800",
    "end": "2105880"
  },
  {
    "text": "increase context length you lose any significance of the middle bit of that context so the beginning and end is more",
    "start": "2105880",
    "end": "2113240"
  },
  {
    "text": "important in terms of what makes the output of the of the model quality or",
    "start": "2113240",
    "end": "2119440"
  },
  {
    "text": "not in terms of how you would measure that and so we'll link to that paper",
    "start": "2119440",
    "end": "2124599"
  },
  {
    "text": "maybe in the show notes as well but I've tried some things I mean I don't know",
    "start": "2124599",
    "end": "2129880"
  },
  {
    "text": "exactly all of the details again Claude is one of these closed models so I don't know all the details of how they're",
    "start": "2129880",
    "end": "2136320"
  },
  {
    "text": "doing things and because it's sitting behind an API it's hard to know how those things evolve over time but for",
    "start": "2136320",
    "end": "2142720"
  },
  {
    "text": "example I I took one of the things with Claud 2 is I just took one of our complete podcast transcripts so a full",
    "start": "2142720",
    "end": "2149640"
  },
  {
    "text": "episode so 45 minutes of audio transcript I took episode 225 which I",
    "start": "2149640",
    "end": "2155480"
  },
  {
    "text": "really enjoyed talking a lot about the things that I'm working on right now with prediction guard and just asked it",
    "start": "2155480",
    "end": "2162760"
  },
  {
    "text": "to give me a summary of the main takeaways and you know paste it in the whole thing and it's like a fairly good",
    "start": "2162760",
    "end": "2170119"
  },
  {
    "text": "comprehensive takeaways like many companies ban usage of certain llms blah",
    "start": "2170119",
    "end": "2175480"
  },
  {
    "text": "blah blah you know prediction guard is trying to provide easy access structuring validation compliance",
    "start": "2175480",
    "end": "2181440"
  },
  {
    "text": "features for llms uh making llm usage easier blah blah blah and it gives these",
    "start": "2181440",
    "end": "2187079"
  },
  {
    "text": "great take ways and then I asked you know hey suggest a few future episodes",
    "start": "2187079",
    "end": "2193839"
  },
  {
    "text": "that we could do that maybe cover a related topics but things that weren't covered in this episode pretty good some",
    "start": "2193839",
    "end": "2201480"
  },
  {
    "text": "of them are kind of generic right a look at current state of AI agents and",
    "start": "2201480",
    "end": "2207160"
  },
  {
    "text": "automation how close are we to no code AI app generation blah blah blah so that",
    "start": "2207160",
    "end": "2212800"
  },
  {
    "text": "all kind of off of this large context of the transcript input was interesting I'm",
    "start": "2212800",
    "end": "2218880"
  },
  {
    "text": "curious um I'm going to put you on the spot also as someone who's working on your own product and I know this is not",
    "start": "2218880",
    "end": "2225119"
  },
  {
    "text": "a prediction guard episode but I'm asking on my own behalf and on behalf of the listener how do you as someone who",
    "start": "2225119",
    "end": "2230599"
  },
  {
    "text": "is looking at these different models how do you think of those different models how do you kind of structure them in",
    "start": "2230599",
    "end": "2235960"
  },
  {
    "text": "your mind in terms of what you're offering you've been evolving rapidly over the last few months and I'm always curious to see kind of where your heads",
    "start": "2235960",
    "end": "2242240"
  },
  {
    "text": "at on this now as you're looking at them yeah I think the things consistently that I'm seeing are are that I made a",
    "start": "2242240",
    "end": "2249359"
  },
  {
    "text": "post on LinkedIn about this as well even my own applications that I'm building",
    "start": "2249359",
    "end": "2254560"
  },
  {
    "text": "llm based applications having access to multiple models rather than a single",
    "start": "2254560",
    "end": "2260800"
  },
  {
    "text": "model I think is a really nice usage pattern where if you the easier we can",
    "start": "2260800",
    "end": "2267359"
  },
  {
    "text": "make it and there's there's other people that are doing this as well other you know in prediction guard you can query a",
    "start": "2267359",
    "end": "2274119"
  },
  {
    "text": "whole bunch of models at the same time concurrently there other systems that will let you look at that output as well",
    "start": "2274119",
    "end": "2281079"
  },
  {
    "text": "so uh nat. deev and some of the toolbar stuff that swix is doing um we had a",
    "start": "2281079",
    "end": "2288720"
  },
  {
    "text": "collaboration with him in the Laten space podcast so the more you can tie these things together and look at the",
    "start": "2288720",
    "end": "2295040"
  },
  {
    "text": "output or automatically analyze the output of multiple models at the same time I think that's really useful",
    "start": "2295040",
    "end": "2301000"
  },
  {
    "text": "because it it's hard to generally evaluate these models until you start evaluating them for your use case and",
    "start": "2301000",
    "end": "2307880"
  },
  {
    "text": "building intuition about them for your own use case so I think the pitfall that people maybe fall into is saying oh I'm",
    "start": "2307880",
    "end": "2315040"
  },
  {
    "text": "going to use this model before they've even tested that for their use case right try creating a set of evaluation",
    "start": "2315040",
    "end": "2323560"
  },
  {
    "text": "examples for your own use case and then try out a bunch of different models for that and also try out the things that",
    "start": "2323560",
    "end": "2330560"
  },
  {
    "text": "are becoming more standard kind of operating procedures for building llm applications like looking at at the",
    "start": "2330560",
    "end": "2337760"
  },
  {
    "text": "consistency of outputs running a post generation validity or um factuality",
    "start": "2337760",
    "end": "2345400"
  },
  {
    "text": "check on the output so checking a language model with a language model doing input filtering and all these",
    "start": "2345400",
    "end": "2352280"
  },
  {
    "text": "sorts of more engineering related things so those are some of the things that I'm seeing but having access to a bunch of",
    "start": "2352280",
    "end": "2359200"
  },
  {
    "text": "models at the same time I think is a is something that can really boost your",
    "start": "2359200",
    "end": "2364400"
  },
  {
    "text": "productivity I appreciate that the uh and tour listeners we we're not making it a prediction guard show or episode",
    "start": "2364400",
    "end": "2370920"
  },
  {
    "text": "but as a co-host Daniel's Excursion through this and his professional has made him in my view one of the world's",
    "start": "2370920",
    "end": "2378000"
  },
  {
    "text": "true experts in how to look at all these together and since we have the benefit of him co-hosting the podcast uh I'm",
    "start": "2378000",
    "end": "2385040"
  },
  {
    "text": "going to continue to take advantage of that expertise uh for all of us thanks Chris so sorry about that Daniel sorry",
    "start": "2385040",
    "end": "2391520"
  },
  {
    "text": "for putting on the spot yeah no no worries I think the other thing maybe to highlight with Claud 2 and something",
    "start": "2391520",
    "end": "2399480"
  },
  {
    "text": "that you were talking about in chat before we jumped into this episode was CLA 2 versus or maybe anthropic and",
    "start": "2399480",
    "end": "2407079"
  },
  {
    "text": "their offerings versus open AI how do we understand that like how do we categorize these things I think one of",
    "start": "2407079",
    "end": "2413000"
  },
  {
    "text": "the interesting things with Claud 2 so we've seen both anthropic and their Claud models and open Ai and their GPT",
    "start": "2413000",
    "end": "2420920"
  },
  {
    "text": "models increase context size over time GPT models not quite as far as Claude",
    "start": "2420920",
    "end": "2426880"
  },
  {
    "text": "but both have increased they've also both added in some of this functionality",
    "start": "2426880",
    "end": "2433119"
  },
  {
    "text": "which I think is very interesting CLA 2 I think first if I'm not wrong the ability to add in your own data so in",
    "start": "2433119",
    "end": "2441280"
  },
  {
    "text": "Cloud 2 there's a little attachment button and you can upload PDFs or text",
    "start": "2441280",
    "end": "2446520"
  },
  {
    "text": "files or csvs and have that inserted into the context of your prompt which I",
    "start": "2446520",
    "end": "2452200"
  },
  {
    "text": "think is of course extremely powerful we've talked about adding in external data into generative models and",
    "start": "2452200",
    "end": "2458880"
  },
  {
    "text": "grounding models in the past it's very powerful now open AI is doing this in a",
    "start": "2458880",
    "end": "2464720"
  },
  {
    "text": "slightly different way and I think this is something worth calling out on the podcast is with their new code",
    "start": "2464720",
    "end": "2470440"
  },
  {
    "text": "interpreter beta feature within chat GPT you can upload data but it's processed",
    "start": "2470440",
    "end": "2479280"
  },
  {
    "text": "through the code interpreter in a different way than what Claud is doing so we all know that chat GPT and GPT",
    "start": "2479280",
    "end": "2486599"
  },
  {
    "text": "models can generate really good code and specifically good python code and so what open AI has done for their kind of",
    "start": "2486599",
    "end": "2494520"
  },
  {
    "text": "data processing agent within chat GPT is",
    "start": "2494520",
    "end": "2499720"
  },
  {
    "text": "said well let's just have our model generate python code then we'll hook up",
    "start": "2499720",
    "end": "2505960"
  },
  {
    "text": "the chat GPT interface to a python interpreter and just go ahead and execute that code for you over your data",
    "start": "2505960",
    "end": "2512920"
  },
  {
    "text": "and then give you the the output so this is maybe a distinction that people can have in their mind Claud to you can",
    "start": "2512920",
    "end": "2519359"
  },
  {
    "text": "upload this huge amount of context you can upload files inserted into the prompt as far as I know they're not",
    "start": "2519359",
    "end": "2525520"
  },
  {
    "text": "running any kind of code interpreter type thing under the hood Chad GPT might",
    "start": "2525520",
    "end": "2532520"
  },
  {
    "text": "not be inserting all of that into the prompt but they're actually saying well what if we decompose what you're wanting",
    "start": "2532520",
    "end": "2539119"
  },
  {
    "text": "me to do with this external data into something that can be executed by a sort",
    "start": "2539119",
    "end": "2544720"
  },
  {
    "text": "of agent type of workflow where you upload your data and ask me to like",
    "start": "2544720",
    "end": "2551599"
  },
  {
    "text": "do some analysis over it I'm going to generate some code so the language model generates some code and then that code",
    "start": "2551599",
    "end": "2558559"
  },
  {
    "text": "is actually executed in the background returns a result which is then fed back",
    "start": "2558559",
    "end": "2563880"
  },
  {
    "text": "through a model to give you generated output back in the interface so it's actually a multi-stage thing happening",
    "start": "2563880",
    "end": "2570920"
  },
  {
    "text": "in code interpreter in open AI it effectively produces a no code solution",
    "start": "2570920",
    "end": "2576400"
  },
  {
    "text": "you know where you get an output and you're just kind of skipping the whole thing you know instead of instead of",
    "start": "2576400",
    "end": "2581640"
  },
  {
    "text": "using the language model to generate your own code and to be your code assist and all that and then you're still doing",
    "start": "2581640",
    "end": "2586960"
  },
  {
    "text": "it it's kind of skipping that whole step right there yeah and I can give an example I actually ran prior to the show",
    "start": "2586960",
    "end": "2594319"
  },
  {
    "text": "so I have Claude and the open aai code interpreter Side by Side open and I",
    "start": "2594319",
    "end": "2600599"
  },
  {
    "text": "uploaded a file with a bunch of Yuba which is a language in Africa",
    "start": "2600599",
    "end": "2606599"
  },
  {
    "text": "transcription out of audio which are from the Bible TTS project that we worked with Ki and masakan on and so I",
    "start": "2606599",
    "end": "2614280"
  },
  {
    "text": "uploaded this file which includes this Yoruba text in a CSV format open AI said",
    "start": "2614280",
    "end": "2620559"
  },
  {
    "text": "great you've uploaded this file let's start by loading and examining the context and then it has this sort of",
    "start": "2620559",
    "end": "2627400"
  },
  {
    "text": "show work button and you can see the actual code that it generated which is",
    "start": "2627400",
    "end": "2632800"
  },
  {
    "text": "Panda's code to import the CSV and then output some examples and so you can expand that and",
    "start": "2632800",
    "end": "2640160"
  },
  {
    "text": "actually see the code that it ran under the hood and the conclusions that the agent came to then I asked it okay well",
    "start": "2640160",
    "end": "2646839"
  },
  {
    "text": "plot the distribution of the transcript links are there any anomalies and then again it says Hey show work and you can",
    "start": "2646839",
    "end": "2654000"
  },
  {
    "text": "see it's importing map plot lib it's taking in the CSV it's actually creating",
    "start": "2654000",
    "end": "2659920"
  },
  {
    "text": "the plot and actually generates an image out of the transcripts it says I didn't",
    "start": "2659920",
    "end": "2665359"
  },
  {
    "text": "find any anomalies they're all kind of within the same distribution there's not any anomalies then I asked it can you",
    "start": "2665359",
    "end": "2671800"
  },
  {
    "text": "translate all the Yuba to English and that's where it it ended up stopping because it said no I'm not good at doing",
    "start": "2671800",
    "end": "2678839"
  },
  {
    "text": "that and quad actually stopped there as well and said no I'm not going to do that I also uploaded the yubal",
    "start": "2678839",
    "end": "2685839"
  },
  {
    "text": "alignments to Claude And it said hey sure let me analyze these transcripts and it just output some general like",
    "start": "2685839",
    "end": "2693880"
  },
  {
    "text": "there 50 audio links the transcript links there's no p python code there it just gave me some takeaways right and",
    "start": "2693880",
    "end": "2700720"
  },
  {
    "text": "then I said are there any anomalies and it said I I checked and I can't find any",
    "start": "2700720",
    "end": "2705880"
  },
  {
    "text": "and could you translate it and it said unfortunately I can't so it's all still a chat based thing so you can see kind",
    "start": "2705880",
    "end": "2711559"
  },
  {
    "text": "of different approaches to this complicated workflow of having almost an",
    "start": "2711559",
    "end": "2716920"
  },
  {
    "text": "assistant agent executing code for you versus putting more context in the",
    "start": "2716920",
    "end": "2722480"
  },
  {
    "text": "language model and having it reason over that context so they're almost getting their own strengths at different types",
    "start": "2722480",
    "end": "2729280"
  },
  {
    "text": "of approaches to problems would that be fair yeah so that's another way of thinking about it is as you start",
    "start": "2729280",
    "end": "2735800"
  },
  {
    "text": "understanding how the different uh large language models approach a problem and the tooling that might be better or",
    "start": "2735800",
    "end": "2742960"
  },
  {
    "text": "worse for a given use case that also will help you kind of pick which way you want to go in addition to maybe just",
    "start": "2742960",
    "end": "2748119"
  },
  {
    "text": "using multiple models as you talked about earlier yeah exactly and there's so much to dive into on all these topics",
    "start": "2748119",
    "end": "2755800"
  },
  {
    "text": "that we've covered today I'm going to make sure that we include some really good learning resources for people in",
    "start": "2755800",
    "end": "2761400"
  },
  {
    "text": "the show notes so make sure and click on some of those there's a guide from data",
    "start": "2761400",
    "end": "2766559"
  },
  {
    "text": "genen on the neural Radiance field stuff the Nerf stuff that you can learn a bit more about that there's a hugging face",
    "start": "2766559",
    "end": "2773760"
  },
  {
    "text": "post and a Phil Schmidt post um on llama 2 that are both really practical kind of",
    "start": "2773760",
    "end": "2779319"
  },
  {
    "text": "how do you run it how do you fine-tune it what does it mean and then there's a a nice post from the one useful thing um",
    "start": "2779319",
    "end": "2788520"
  },
  {
    "text": "Ethan mik blog or newsletter about code interpreter and how to get it set up and",
    "start": "2788520",
    "end": "2794319"
  },
  {
    "text": "some things to try so we'll link that in our show notes and I think people should dig in get hands on with this stuff",
    "start": "2794319",
    "end": "2800520"
  },
  {
    "text": "things are things are updating quickly and the only way to really get that intuition about things is to dive in and",
    "start": "2800520",
    "end": "2807119"
  },
  {
    "text": "get hands on it is it's the most interesting moment we've had in the in the AI revolution of recent years and",
    "start": "2807119",
    "end": "2813640"
  },
  {
    "text": "just so much cool stuff right now uh anyway thank you for taking us through all the uh the understanding and",
    "start": "2813640",
    "end": "2820079"
  },
  {
    "text": "explanation of these things yeah definitely is is good uh good time hopefully people enjoy the rest of their",
    "start": "2820079",
    "end": "2826920"
  },
  {
    "text": "week and maybe go see Oppenheimer or Barbie depending on your which of those",
    "start": "2826920",
    "end": "2832200"
  },
  {
    "text": "is most interesting to you but we'll see you next time Chris see you later [Music]",
    "start": "2832200",
    "end": "2839400"
  },
  {
    "text": "thanks thank you for listening to practical AI your next step is to",
    "start": "2839400",
    "end": "2844680"
  },
  {
    "text": "subscribe now if you haven't already and if you're a longtime listener of the show help us reach more people by",
    "start": "2844680",
    "end": "2851040"
  },
  {
    "text": "sharing practical AI with your friends and colleagues thanks once again to fastly and fly for partnering with us to",
    "start": "2851040",
    "end": "2857119"
  },
  {
    "text": "bring you all Chang doog podcasts check out what they're up to at fastly.com and",
    "start": "2857119",
    "end": "2862520"
  },
  {
    "text": "fly.io and to our beat freaking residence break master cylinder for continuously cranking out the best beats",
    "start": "2862520",
    "end": "2868280"
  },
  {
    "text": "in the biz that's all for now we'll talk to you again next [Music]",
    "start": "2868280",
    "end": "2875839"
  },
  {
    "text": "time [Music]",
    "start": "2875839",
    "end": "2887719"
  },
  {
    "text": "K look",
    "start": "2889319",
    "end": "2892440"
  }
]
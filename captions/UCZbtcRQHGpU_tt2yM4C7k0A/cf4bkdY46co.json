[
  {
    "text": "with a kind of traditional continuous deployment pipeline it's pretty much only goes one way so you have the code",
    "start": "40",
    "end": "7520"
  },
  {
    "text": "you produce the server you deploy it and that's kind of it but with mlops you're",
    "start": "7520",
    "end": "12719"
  },
  {
    "text": "sort of always continuously have this loop back you're producing more data from the system that has the model",
    "start": "12719",
    "end": "18840"
  },
  {
    "text": "deployed which gets fed back into the beginning of this process to become more training data for the model so you kind",
    "start": "18840",
    "end": "25240"
  },
  {
    "text": "of have this circular nature that makes it a little bit interesting",
    "start": "25240",
    "end": "31960"
  },
  {
    "text": "this episode is brought to you by signal wire signal wire offers apis sdks and",
    "start": "34440",
    "end": "40680"
  },
  {
    "text": "Edge networks around the world for building the realest realtime video and video communication apps with less than",
    "start": "40680",
    "end": "47600"
  },
  {
    "text": "50 milliseconds of latency they use websockets to deliver 300% lower latency than apis built on rest making it ideal",
    "start": "47600",
    "end": "55480"
  },
  {
    "text": "for apps where every millisecond and responsiveness makes a difference like apps that need instant natural language",
    "start": "55480",
    "end": "62160"
  },
  {
    "text": "understanding realtime Machine Vision or large scale video and audio conferencing here's what makes them different they",
    "start": "62160",
    "end": "67960"
  },
  {
    "text": "use MCU multi-point control unit that mixes all video and all audio feeds on",
    "start": "67960",
    "end": "73840"
  },
  {
    "text": "the server side and then distributes a single unified stream back to every",
    "start": "73840",
    "end": "79000"
  },
  {
    "text": "participant that way every participant in the apps you ship experience the same video and the same audio your apps have",
    "start": "79000",
    "end": "85880"
  },
  {
    "text": "none of the awkward audio effects obvious lag and jumpy video it's all smooth great ux creating a more lifelike",
    "start": "85880",
    "end": "93280"
  },
  {
    "text": "virtual experience without compromising audio or the video quality head to Signal wire.com video mention go time to",
    "start": "93280",
    "end": "99280"
  },
  {
    "text": "receive an extra 5,000 video minutes again go to Signal wire.com videoo and",
    "start": "99280",
    "end": "105200"
  },
  {
    "text": "remember to mention go [Music]",
    "start": "105200",
    "end": "113760"
  },
  {
    "text": "time let's do it it's go time welcome to go",
    "start": "118840",
    "end": "124439"
  },
  {
    "text": "time your source for diverse discussions from around the go Community special thanks to our partners at fastly for",
    "start": "124439",
    "end": "130920"
  },
  {
    "text": "making sure you receive our MP3s super fast all around the world check them out",
    "start": "130920",
    "end": "136160"
  },
  {
    "text": "at fastly.com we record live each and every Tuesday at 3 p.m. us Eastern come",
    "start": "136160",
    "end": "142640"
  },
  {
    "text": "hang with the go time crew and chat along in the go time FM channel of go ver slack okay here we go",
    "start": "142640",
    "end": "151760"
  },
  {
    "text": "hi hi I am joined today by my co-host Johnny hi Johnny how are you doing hello",
    "start": "155160",
    "end": "161720"
  },
  {
    "text": "happy New Year this is like my first episode since yeah since the year",
    "start": "161720",
    "end": "166879"
  },
  {
    "text": "started it's first episode of 2022 wait is this really just the first episode of this podcast for the year no I'm I'm",
    "start": "166879",
    "end": "173640"
  },
  {
    "text": "sure we release some already but this is the first one recorded in the New Year for me at least I'm not sure there were",
    "start": "173640",
    "end": "179800"
  },
  {
    "text": "were other episodes but we will find out mystery and we are joined today by Mike",
    "start": "179800",
    "end": "185879"
  },
  {
    "text": "eam hi Mike it's great to have you yeah it's great to be here and you are",
    "start": "185879",
    "end": "191480"
  },
  {
    "text": "joining us from the overseas side or from Johnny side of the overseas so you",
    "start": "191480",
    "end": "197760"
  },
  {
    "text": "two are based in the US but you are based in Brooklyn Maryland Maryland not",
    "start": "197760",
    "end": "204040"
  },
  {
    "text": "too far actually both East Coasters yeah is there a time difference between you two nope okay well we have six hours",
    "start": "204040",
    "end": "210480"
  },
  {
    "text": "apart to here to Berlin so that's 9:00 p.m. here fun way to start the year for",
    "start": "210480",
    "end": "218000"
  },
  {
    "text": "me so Mike you are a tech lead and a software engineer at tekon yeah or a",
    "start": "218000",
    "end": "225560"
  },
  {
    "text": "tchon AI I should say because the name of the product as you told me is tekon and tekon is Building Systems to operate",
    "start": "225560",
    "end": "233159"
  },
  {
    "text": "and manage feature pipelines and data sets for production machine learning applications for all sorts of customer",
    "start": "233159",
    "end": "239640"
  },
  {
    "text": "customers that we all know and you used to be a googler in Google you were working on indexing and serving",
    "start": "239640",
    "end": "246000"
  },
  {
    "text": "infrastructure for web search yep fun so can you tell us a little bit on where",
    "start": "246000",
    "end": "254120"
  },
  {
    "text": "you work and what do you do there yeah so um tecton's a company that was",
    "start": "254120",
    "end": "260959"
  },
  {
    "text": "founded like late 2019 the co-founders were all at Uber",
    "start": "260959",
    "end": "266680"
  },
  {
    "text": "prior to starting the company uh where they worked on a feature store product or internal product called Michelangelo",
    "start": "266680",
    "end": "274160"
  },
  {
    "text": "I think we'll get into a little bit later in the podcast what it means to have a future store product but that's",
    "start": "274160",
    "end": "279479"
  },
  {
    "text": "kind of where they met each other and got to know each other and I will pause you for one second to say that all the different names that you're mentioning",
    "start": "279479",
    "end": "285320"
  },
  {
    "text": "for example project Michelangelo we will include in the show notes so if you want",
    "start": "285320",
    "end": "290639"
  },
  {
    "text": "to read more about this fun project you can find it in the show notes yeah definitely so yeah company was started",
    "start": "290639",
    "end": "297039"
  },
  {
    "text": "around 2019 I joined joined March of 2019 I was like the first engineer that joined",
    "start": "297039",
    "end": "303880"
  },
  {
    "text": "outside of the founders so I've kind of worked on pretty much every part of the product since pretty near the beginning",
    "start": "303880",
    "end": "309759"
  },
  {
    "text": "when it was just very early prototypes uh to where we are now so the company's",
    "start": "309759",
    "end": "315000"
  },
  {
    "text": "like 55 people now around there you know got a couple different sub teams in the engineering team so we're I would guess",
    "start": "315000",
    "end": "321720"
  },
  {
    "text": "kind of a midsize company now our main product is still this proprietary",
    "start": "321720",
    "end": "327080"
  },
  {
    "text": "feature store that we've been working on since the beginning um but we've also started contributing to another open",
    "start": "327080",
    "end": "332720"
  },
  {
    "text": "source feature store product called Feast kind of the lead maintainer and starter of the project works at tekon",
    "start": "332720",
    "end": "339080"
  },
  {
    "text": "now so we're kind of working on both those so both the products the Enterprise and the Open Source One are",
    "start": "339080",
    "end": "345960"
  },
  {
    "text": "feature stores that's right what's a feature store I think you um you know it's very kind of buzzwordy term right",
    "start": "345960",
    "end": "353400"
  },
  {
    "text": "now so I think you'll probably see a lot of people trying to explain it in different ways or having a different",
    "start": "353400",
    "end": "358960"
  },
  {
    "text": "idea about what it is oh we used to we just went through the whole servoless um thing so we're we're yeah we're",
    "start": "358960",
    "end": "364360"
  },
  {
    "text": "accustomed new year new term new year new term yeah I'll do my best to give my take on what it is feuture stores kind",
    "start": "364360",
    "end": "372319"
  },
  {
    "text": "of they're part of this like broader concept called mlops which you mentioned before that's all about kind of applying",
    "start": "372319",
    "end": "380000"
  },
  {
    "text": "like a devop style mindset to getting machine learning applications and production feuture stores aim to solve",
    "start": "380000",
    "end": "387400"
  },
  {
    "text": "kind of one piece of that Pipeline and that's managing feature definitions and",
    "start": "387400",
    "end": "393319"
  },
  {
    "text": "feature data so you could kind of break down into a couple different components",
    "start": "393319",
    "end": "398919"
  },
  {
    "text": "what a feature store is I would say the primary thing is that it acts as a source of Truth for your feature",
    "start": "398919",
    "end": "405000"
  },
  {
    "text": "definitions within your organization or your team whoever is like working on your model basically the idea is that",
    "start": "405000",
    "end": "411759"
  },
  {
    "text": "you just have a single place where you define what a feature is um instead of having multiple different copies",
    "start": "411759",
    "end": "418199"
  },
  {
    "text": "potentially the same feature defition or just having a bunch of different systems where all your features are all spread all over the place in our case we have",
    "start": "418199",
    "end": "425919"
  },
  {
    "text": "data scientists and data Engineers Define those features generally as a SQL query which is kind of a tool that those",
    "start": "425919",
    "end": "432639"
  },
  {
    "text": "types of roles are typically familiar with and the idea is that you know they can do it in one place and not have to",
    "start": "432639",
    "end": "439160"
  },
  {
    "text": "prototype it using SQL and then later hand it over to another team to builds a production version of that feature using",
    "start": "439160",
    "end": "445280"
  },
  {
    "text": "Java or go or something like that and then have those things get out of sync the first aspect is just having a single",
    "start": "445280",
    "end": "450879"
  },
  {
    "text": "place where the features defined I will pause you just here to go one question deeper and ask for those who are just",
    "start": "450879",
    "end": "458919"
  },
  {
    "text": "really focused on like Becca and web servers and in that little world what is a feature yeah that's a important",
    "start": "458919",
    "end": "465879"
  },
  {
    "text": "question you could probably have a very kind of like mathematical definition of this but generally like the features are",
    "start": "465879",
    "end": "473039"
  },
  {
    "text": "sort of the engineered inputs that go into a machine learning model so when",
    "start": "473039",
    "end": "478360"
  },
  {
    "text": "you're in the process of making a machine learning model you sort of have an algorithm that takes in some values",
    "start": "478360",
    "end": "484240"
  },
  {
    "text": "and it uses those to predict an outcome and generally when you're building these systems you kind of engineer those",
    "start": "484240",
    "end": "490360"
  },
  {
    "text": "values to encode some sort of like domain knowledge about the system you're trying to model so if you have a bunch",
    "start": "490360",
    "end": "497360"
  },
  {
    "text": "of let's say raw data about users in a system and maybe you're trying to",
    "start": "497360",
    "end": "502639"
  },
  {
    "text": "predict like a product they might be interested in buying as someone who kind of inv you know knows a bit about what",
    "start": "502639",
    "end": "510440"
  },
  {
    "text": "might predict what people might want to buy you might say okay I think their age might be kind of an important",
    "start": "510440",
    "end": "516440"
  },
  {
    "text": "determinant of what things they might be interested in so then you can build a feature that based on your raw data",
    "start": "516440",
    "end": "522680"
  },
  {
    "text": "let's say like a database of all of your user information just extracts the age as a number and so you're kind of like",
    "start": "522680",
    "end": "529240"
  },
  {
    "text": "distilling down things that you think might be important to the model training system and that process is like super",
    "start": "529240",
    "end": "535080"
  },
  {
    "text": "important for building models that actually perform well because the model training algorithms are now actually",
    "start": "535080",
    "end": "540760"
  },
  {
    "text": "quite sophisticated and and you know they can produce really good results but you're always going to get better outcomes if you kind of have better data",
    "start": "540760",
    "end": "547760"
  },
  {
    "text": "going into the training is the objective of a feature to make it a reusable part",
    "start": "547760",
    "end": "554640"
  },
  {
    "text": "of the workflow for building these models what is the objective of having a feature yeah so I think definitely in an",
    "start": "554640",
    "end": "562320"
  },
  {
    "text": "ml Ops context you might say that you want it to be reusable like you can certainly build machine Learning Systems",
    "start": "562320",
    "end": "568880"
  },
  {
    "text": "where all of the work is just done in a silo and you don't reuse it across different models ever but you're probably going to",
    "start": "568880",
    "end": "575880"
  },
  {
    "text": "have better outcomes for your organization if you ever have more than one model like you're probably going to",
    "start": "575880",
    "end": "581240"
  },
  {
    "text": "have better outcomes if you can kind of share that work across different models so that's definitely something that people try to use feature stores to um",
    "start": "581240",
    "end": "588760"
  },
  {
    "text": "achieve now how granular you gave an example about sort of U um having having",
    "start": "588760",
    "end": "593920"
  },
  {
    "text": "a deterministic way of getting someone's age right giving your data model your schema your data store whatever wherever",
    "start": "593920",
    "end": "599560"
  },
  {
    "text": "you stting your user information is the point to have these things sort of very granular to the point where to ease the",
    "start": "599560",
    "end": "606440"
  },
  {
    "text": "ReUse because they are like very small in scope they do one thing and one thing well kind of thing and you can just",
    "start": "606440",
    "end": "612120"
  },
  {
    "text": "chain them as part of your model yeah I think some of that depends a bit on what",
    "start": "612120",
    "end": "617279"
  },
  {
    "text": "types of techniques you're using to build the model so from the perspective of someone who's building a feature",
    "start": "617279",
    "end": "623000"
  },
  {
    "text": "store we kind of just want to make sure that we support whatever types of",
    "start": "623000",
    "end": "628120"
  },
  {
    "text": "features that people want to encode in the system and so you can have really generic things like age but you can also",
    "start": "628120",
    "end": "634839"
  },
  {
    "text": "get even super specific features that are something that's like specific to a",
    "start": "634839",
    "end": "639959"
  },
  {
    "text": "certain product and user combination so I think there there's like a variety of",
    "start": "639959",
    "end": "645279"
  },
  {
    "text": "answers to that so a feature then is part of the set of inputs that you're feeding into your model yeah so you use",
    "start": "645279",
    "end": "651880"
  },
  {
    "text": "it both for training so you'll provide basically a bunch of previous examples of feature values as well as the outcome",
    "start": "651880",
    "end": "660200"
  },
  {
    "text": "so an example would be I might have a bunch of features about a perspective Shopper like let's say their age maybe",
    "start": "660200",
    "end": "668040"
  },
  {
    "text": "the last 10 things they had searched for would be in there encoded somehow things",
    "start": "668040",
    "end": "673360"
  },
  {
    "text": "of that nature and then I would have an outcome which would be like did they buy",
    "start": "673360",
    "end": "678440"
  },
  {
    "text": "a product or what products did they buy and then during model training uh you",
    "start": "678440",
    "end": "683839"
  },
  {
    "text": "provide all these examples and then a model is the result of that and then",
    "start": "683839",
    "end": "689279"
  },
  {
    "text": "later on you can basically use that model to predict the outcome from just",
    "start": "689279",
    "end": "694320"
  },
  {
    "text": "the inputs so in the example I gave before you would if you're trying to predict while they're shopping what it",
    "start": "694320",
    "end": "700360"
  },
  {
    "text": "is that they might be interested in buying you have just those feature values as inputs you feed that into your",
    "start": "700360",
    "end": "706079"
  },
  {
    "text": "model serving system and then you get out a predicted outcome so I'm trying to figure out where features fit and S of",
    "start": "706079",
    "end": "713959"
  },
  {
    "text": "the greater set of tools that you would use if we talking sort of personalization here for for example I",
    "start": "713959",
    "end": "719800"
  },
  {
    "text": "do know in having used some commercial um personalization um products that there's different sort of U um",
    "start": "719800",
    "end": "726120"
  },
  {
    "text": "algorithms that are used and and different sort of models that I use to rather different sort of approaches to",
    "start": "726120",
    "end": "732320"
  },
  {
    "text": "training right and being able to sort of produce recommendations if I like example you gave if I've liked a few",
    "start": "732320",
    "end": "739399"
  },
  {
    "text": "things searched for a few things then this should be right the next set of things that that you might like kind of",
    "start": "739399",
    "end": "744760"
  },
  {
    "text": "like going on Amazon and and you search for one thing you see other recommendations you're like oh I'm",
    "start": "744760",
    "end": "749839"
  },
  {
    "text": "seeing things I didn't know I wanted yeah or you go to you know Netflix and you watch something and all of a sudden it's recommending other things right so",
    "start": "749839",
    "end": "756320"
  },
  {
    "text": "these kinds of recommender systems it sounds like these are a kind of problem",
    "start": "756320",
    "end": "762199"
  },
  {
    "text": "right that the features that you're creating right would feed into sort of helping these kinds of problems so I'm",
    "start": "762199",
    "end": "768160"
  },
  {
    "text": "trying to imagine in my head where in the layer of things needed to have a",
    "start": "768160",
    "end": "774040"
  },
  {
    "text": "fully operational recommendation engine right where what unit where is the",
    "start": "774040",
    "end": "779199"
  },
  {
    "text": "feature at is it one of the first things that you do as somebody who's building sort of a model or want wants to train a",
    "start": "779199",
    "end": "786079"
  },
  {
    "text": "model like is it like what's what's the workflow like what is that into the picture yeah so I think it is one of the",
    "start": "786079",
    "end": "791800"
  },
  {
    "text": "first things you would start thinking about but I think another kind of important aspect of mlops in comparison",
    "start": "791800",
    "end": "798880"
  },
  {
    "text": "to devops is that you have to go through a lot of Cycles so you might start thinking about features at the beginning",
    "start": "798880",
    "end": "804959"
  },
  {
    "text": "but to really effectively build ml systems you to be able to quickly go through a lot of Cycles where you build",
    "start": "804959",
    "end": "812240"
  },
  {
    "text": "the features you build a model you see how it performs and then that can give you more information about maybe I need",
    "start": "812240",
    "end": "819120"
  },
  {
    "text": "to tweak my feature definitions or possibly just I need to get more data or",
    "start": "819120",
    "end": "824160"
  },
  {
    "text": "something of that nature so I think it's like it is one of the first things you would think about but you also kind of",
    "start": "824160",
    "end": "830320"
  },
  {
    "text": "have to be continuously monitoring what the values of your features are looking like if you need to change the",
    "start": "830320",
    "end": "835959"
  },
  {
    "text": "definitions if you need to add new ones throughout the lifetime of the mod so what makes features I guess",
    "start": "835959",
    "end": "842120"
  },
  {
    "text": "sophisticated enough or complex enough to require their own data store yeah so",
    "start": "842120",
    "end": "847959"
  },
  {
    "text": "there's a couple of interesting requirements from like a systems engineering perspective when it comes to feature data one of the biggest ones is",
    "start": "847959",
    "end": "855600"
  },
  {
    "text": "that I mentioned that you kind of end up using feature values in two main places you use them once when you're building",
    "start": "855600",
    "end": "862839"
  },
  {
    "text": "the model or training the model as part of your your process of deploying like a machine Learning System but you also",
    "start": "862839",
    "end": "869279"
  },
  {
    "text": "need to use it in production once you have the model deployed in order to actually make the predictions and so",
    "start": "869279",
    "end": "875880"
  },
  {
    "text": "it's the same sort of logic that defines the feature values but you need to apply it in two different places and you have",
    "start": "875880",
    "end": "883199"
  },
  {
    "text": "different performance requirements for those two different use cases so generally when you're making a",
    "start": "883199",
    "end": "888800"
  },
  {
    "text": "prediction in the context of most like recommender systems for instance you have a user generally that's kind of",
    "start": "888800",
    "end": "895880"
  },
  {
    "text": "sitting there at the other end of the connection wai waiting for search results to be ranked or something like",
    "start": "895880",
    "end": "901480"
  },
  {
    "text": "that so you obviously want that to happen quickly and so in that kind of online context when you're making a",
    "start": "901480",
    "end": "907120"
  },
  {
    "text": "prediction the latency is very important so lots of times people have requirements of something like 10",
    "start": "907120",
    "end": "913320"
  },
  {
    "text": "millisecs in order to retrieve feature values because that's only one piece of this whole process that has to happen of",
    "start": "913320",
    "end": "918920"
  },
  {
    "text": "making prediction whereas when you're training the model the latency is not super important I mean you obviously",
    "start": "918920",
    "end": "925279"
  },
  {
    "text": "don't want people sitting around for hours waiting for training to happen but the throughput is more important in that",
    "start": "925279",
    "end": "931319"
  },
  {
    "text": "case um is generally the more examples you can put into training like the better results you're going to get so",
    "start": "931319",
    "end": "938440"
  },
  {
    "text": "it's a different like set of priorities for those two different contexts that you need the feature values and in",
    "start": "938440",
    "end": "943959"
  },
  {
    "text": "addition to the performance requirements being different in the online case you're generally looking for the",
    "start": "943959",
    "end": "949680"
  },
  {
    "text": "freshest data so you want the most recent version of a feature value so like that doesn't make sense with the",
    "start": "949680",
    "end": "955720"
  },
  {
    "text": "age example I've been using but you know if you're talking about a feature that's like the last product that someone",
    "start": "955720",
    "end": "962120"
  },
  {
    "text": "bought you want that to represent to be updated very quickly after someone makes a purchase so you want those to be fresh",
    "start": "962120",
    "end": "968800"
  },
  {
    "text": "and have the most recent copy whereas in the training or offline contexts you",
    "start": "968800",
    "end": "974240"
  },
  {
    "text": "want to get the correct value for like a historical point in time so you want to",
    "start": "974240",
    "end": "979680"
  },
  {
    "text": "be retrieving the feature value as of the example that you're Computing the features for so the interface looks a",
    "start": "979680",
    "end": "986279"
  },
  {
    "text": "little bit different in addition to the requirements for performance would you say that the reason that feature stores",
    "start": "986279",
    "end": "992880"
  },
  {
    "text": "kind of became a thing rather recently is that we expect faster everything like",
    "start": "992880",
    "end": "1000680"
  },
  {
    "text": "you said like Fast search results and everything so for example feature stores were not really around five years ago",
    "start": "1000680",
    "end": "1006800"
  },
  {
    "text": "yeah I think that's a big part of it is like the performance requirements I also just think that people are trying to",
    "start": "1006800",
    "end": "1013120"
  },
  {
    "text": "deploy these machine Learning Systems in a much like larger variety businesses",
    "start": "1013120",
    "end": "1019199"
  },
  {
    "text": "and products than they were maybe five or 10 years ago you know I think like",
    "start": "1019199",
    "end": "1024480"
  },
  {
    "text": "really large tech companies have had some form of what I'm talking about for quite a long time you know Google",
    "start": "1024480",
    "end": "1030678"
  },
  {
    "text": "Facebook but now it's there's really like a lot of smaller organizations that are trying to build these types of",
    "start": "1030679",
    "end": "1036558"
  },
  {
    "text": "things and running into these problems that like they can't put as many Engineers on as you know a Google or a",
    "start": "1036559",
    "end": "1043079"
  },
  {
    "text": "Facebook and so there's a lot more interest in like trying to find these kind of off-the-shelf systems that help out so given that this is sort of um",
    "start": "1043079",
    "end": "1050480"
  },
  {
    "text": "This falls in the category of sort of ml Ops as we've been referring to it is this meant for the people that sort of",
    "start": "1050480",
    "end": "1058760"
  },
  {
    "text": "uh operate right these systems because it sounded like I'm trying not to conflate the people actually building",
    "start": "1058760",
    "end": "1065000"
  },
  {
    "text": "and training those models right with the people actually running those things right so there's a seam there but I'm",
    "start": "1065000",
    "end": "1070559"
  },
  {
    "text": "not quite sure where where on which side of the fence um basically the feature store users and operators fall yeah",
    "start": "1070559",
    "end": "1078200"
  },
  {
    "text": "that's that's a good question so I mean the answer is that both of those categories are users of feature store",
    "start": "1078200",
    "end": "1084159"
  },
  {
    "text": "systems typically and really like one of the most important things that a feature sort can do is provide a clean seam",
    "start": "1084159",
    "end": "1091240"
  },
  {
    "text": "between those two different roles so I briefly mentioned before but like before",
    "start": "1091240",
    "end": "1096520"
  },
  {
    "text": "people were kind of integrating this feature store concept into their workflows often times the way a feature",
    "start": "1096520",
    "end": "1102440"
  },
  {
    "text": "would make it into production would be a data scientist would kind of you know do the exploration and the data",
    "start": "1102440",
    "end": "1108919"
  },
  {
    "text": "come upon insights and figure out what feature values they wanted and they would generally test those out by doing",
    "start": "1108919",
    "end": "1115919"
  },
  {
    "text": "something like writing SQL or maybe using a kind of ad hoc python script and",
    "start": "1115919",
    "end": "1120960"
  },
  {
    "text": "cutting data up with pandas or something along those lines that would produce data that was good enough to do the",
    "start": "1120960",
    "end": "1126720"
  },
  {
    "text": "training but maybe wouldn't actually meet the performance requirements so doing the actual online suring piece and",
    "start": "1126720",
    "end": "1133240"
  },
  {
    "text": "then often what would happen is that the SQL queries or the Python scripts or whatever they are would kind of just get",
    "start": "1133240",
    "end": "1138720"
  },
  {
    "text": "handed to a data engineering team they would have to decipher whatever it was that was going on and translate that",
    "start": "1138720",
    "end": "1145200"
  },
  {
    "text": "into a system that could compute the features in real time there often times were mistakes made in that process",
    "start": "1145200",
    "end": "1150960"
  },
  {
    "text": "people didn't quite understand what was going on in one version or the other and if you have discrepancies between the",
    "start": "1150960",
    "end": "1156880"
  },
  {
    "text": "training system and the online system it really really hurts the performance of your model typically so the whole idea",
    "start": "1156880",
    "end": "1162280"
  },
  {
    "text": "with the feature store is that we can just have the data scientists Define their features once in a way that they",
    "start": "1162280",
    "end": "1169080"
  },
  {
    "text": "understand so we support SQL we also support defining them in in Python if",
    "start": "1169080",
    "end": "1174159"
  },
  {
    "text": "people prefer that but once they've done that it already is meeting the performance requirements that are kind",
    "start": "1174159",
    "end": "1180159"
  },
  {
    "text": "of needed on the data engineering side is we you know behind the scenes do a lot of like Prem materializing feature",
    "start": "1180159",
    "end": "1187000"
  },
  {
    "text": "values and things like that in order to make sure that they can be served like promptly when they're needed by the",
    "start": "1187000",
    "end": "1192039"
  },
  {
    "text": "model suring system so we have one interface that's or one part of the",
    "start": "1192039",
    "end": "1197320"
  },
  {
    "text": "interface that's kind of focused towards the data scientists that are doing exploration defining new features and then another piece that is focused",
    "start": "1197320",
    "end": "1204440"
  },
  {
    "text": "towards people that are operating the serving systems and integrating them into cicd pipelines and things like that",
    "start": "1204440",
    "end": "1211799"
  },
  {
    "text": "yeah a company I used to work for in the past they had exactly what you described there was the data science/engineering",
    "start": "1211799",
    "end": "1218559"
  },
  {
    "text": "team who were building models and like taking data in crunching and coming up with new ideas and new rules kind of you",
    "start": "1218559",
    "end": "1227039"
  },
  {
    "text": "know if if this then and perform this action and then they would just hand over those python chunks of code to the",
    "start": "1227039",
    "end": "1234559"
  },
  {
    "text": "go team which is the beckon team and then now translate this into the system that's exactly what it's solving so it's",
    "start": "1234559",
    "end": "1241400"
  },
  {
    "text": "been a couple of years but yeah that's very much in my personal world of context at least yeah that's not error",
    "start": "1241400",
    "end": "1247520"
  },
  {
    "text": "prone at all yeah even just translating from python to go you would lose some of the",
    "start": "1247520",
    "end": "1253679"
  },
  {
    "text": "Precision that they found or like something interesting yeah I mean sometimes you know model Training",
    "start": "1253679",
    "end": "1258960"
  },
  {
    "text": "Systems can even kind of latch on to little quirks of behavior that like you wouldn't really think about when you're",
    "start": "1258960",
    "end": "1264600"
  },
  {
    "text": "doing this translation but even if there's some edge cases where certain numerical libraries you're using or",
    "start": "1264600",
    "end": "1270919"
  },
  {
    "text": "something behave differently it can really cause a lot of problems that are are quite difficult to find",
    "start": "1270919",
    "end": "1278440"
  },
  {
    "text": "[Music]",
    "start": "1281430",
    "end": "1287039"
  },
  {
    "text": "yeah this episode is brought to you by our",
    "start": "1287039",
    "end": "1293000"
  },
  {
    "text": "friends at fire hydrant fire hydrant is the reliability platform for every developer incidents impact everyone not",
    "start": "1293000",
    "end": "1300200"
  },
  {
    "text": "just sres fire hydrant gives teams the tools to maintain service cataloges respond to incidents communicate through",
    "start": "1300200",
    "end": "1306440"
  },
  {
    "text": "status pages and learn with retrospectives what would normally be manual air prone tasks across the entire",
    "start": "1306440",
    "end": "1312440"
  },
  {
    "text": "spectrum of responding to an incident this can all be automated in every way with fire hydrant fire hydrant gives you",
    "start": "1312440",
    "end": "1318840"
  },
  {
    "text": "incident tooling to manage incidents of any type with any severity with consistency you can declare and mitigate",
    "start": "1318840",
    "end": "1325520"
  },
  {
    "text": "incidents all inside slack service cataloges allow service owners to improve operational maturity and",
    "start": "1325520",
    "end": "1331320"
  },
  {
    "text": "document all your deploys in your service catalog incident analytics like extract meaningful insights about your",
    "start": "1331320",
    "end": "1336840"
  },
  {
    "text": "reliability over any facet of your incident or the people who respond to them and at the heart of it all incident",
    "start": "1336840",
    "end": "1343080"
  },
  {
    "text": "runbooks they let you create custom automation roles to convert manual tasks into automated reliable repeatable",
    "start": "1343080",
    "end": "1349559"
  },
  {
    "text": "sequences that run when you want create slack channels J tickets Zoom Bridges",
    "start": "1349559",
    "end": "1354679"
  },
  {
    "text": "instantly after declaring an incident now your processes can be consistent and automatic try fire hydrant free for 14",
    "start": "1354679",
    "end": "1361320"
  },
  {
    "text": "days get access to every feature no credit card required get started at fireh hydrant doio again fireh hydrant",
    "start": "1361320",
    "end": "1369050"
  },
  {
    "text": "[Music]",
    "start": "1369050",
    "end": "1376960"
  },
  {
    "text": "doio [Music]",
    "start": "1376960",
    "end": "1387010"
  },
  {
    "text": "so we asked you to Define some things Mike and um I guess we covered a little",
    "start": "1387159",
    "end": "1392400"
  },
  {
    "text": "bit what is your definition of mlops but maybe you can kind of say that for us",
    "start": "1392400",
    "end": "1398159"
  },
  {
    "text": "how do you see this and how do you see this different from the devops in the infrastructure is a thing so you",
    "start": "1398159",
    "end": "1404480"
  },
  {
    "text": "mentioned for example how many life cycles yeah from my perspective the most significant difference is that with",
    "start": "1404480",
    "end": "1411559"
  },
  {
    "text": "devops generally you're talking about deploying servers or some other programs",
    "start": "1411559",
    "end": "1416880"
  },
  {
    "text": "into production so kind of got this pipeline that's going from some code in",
    "start": "1416880",
    "end": "1422279"
  },
  {
    "text": "your git repository or wherever it is and then you're compiling it to these artifacts that end up in production and",
    "start": "1422279",
    "end": "1428600"
  },
  {
    "text": "of course there's some steps there to make sure maybe you're doing Canary deployments to make sure you're not",
    "start": "1428600",
    "end": "1433799"
  },
  {
    "text": "breaking things and you're testing and making sure everything works reliably but the actual transformation of the",
    "start": "1433799",
    "end": "1439679"
  },
  {
    "text": "code to the the server is actually pretty straightforward and fast and with",
    "start": "1439679",
    "end": "1444760"
  },
  {
    "text": "mlops it's really kind of an extension of the same thing it's just that that process of transforming the raw data",
    "start": "1444760",
    "end": "1451799"
  },
  {
    "text": "into the final product which is like a model in this case is really quite a lot",
    "start": "1451799",
    "end": "1458000"
  },
  {
    "text": "more complex so it takes longer either because there's like manual steps that",
    "start": "1458000",
    "end": "1463600"
  },
  {
    "text": "are involved or because some of these Training Systems actually take a sign amount of computational power and time",
    "start": "1463600",
    "end": "1470039"
  },
  {
    "text": "to produce the results you've got different kind of disciplines involved with different stages of that pipeline",
    "start": "1470039",
    "end": "1477159"
  },
  {
    "text": "so there's data scientists data Engineers so multiple different kind of stakeholders and people that are",
    "start": "1477159",
    "end": "1483520"
  },
  {
    "text": "concerned with that Pipeline and so really it's just like a lot more there's a lot more complex pieces involved is",
    "start": "1483520",
    "end": "1490159"
  },
  {
    "text": "like is the main difference that I see in addition to taking longer it's also",
    "start": "1490159",
    "end": "1495360"
  },
  {
    "text": "with a kind of traditional continuous deployment pipeline it's pretty much only goes one way so you have the code",
    "start": "1495360",
    "end": "1503279"
  },
  {
    "text": "you produce the server you deploy it and then that's kind of it but with mlops you're sort of always continuously have",
    "start": "1503279",
    "end": "1510159"
  },
  {
    "text": "this loop back because you're producing more data from the system that has the",
    "start": "1510159",
    "end": "1515440"
  },
  {
    "text": "model deployed which kind of gets fed back into the beginning of this process to become more training data for the",
    "start": "1515440",
    "end": "1522120"
  },
  {
    "text": "model which you'll then deploy later so you kind of have this circular nature",
    "start": "1522120",
    "end": "1527880"
  },
  {
    "text": "that makes it a little bit interesting as well so yeah I mean I think that's really the biggest difference I think a",
    "start": "1527880",
    "end": "1533559"
  },
  {
    "text": "couple other things are I mean I mentioned this a little bit already but you really have a lot of different kind",
    "start": "1533559",
    "end": "1540279"
  },
  {
    "text": "of skills and roles involved with most ml systems than you do with a typical Software System so you have people that",
    "start": "1540279",
    "end": "1546520"
  },
  {
    "text": "are just you know straight up software Engineers they're data engineers and then there are people are data scientists who are technical but you",
    "start": "1546520",
    "end": "1553960"
  },
  {
    "text": "know they understand things more in like statistics and math and they have certain software tools that they want to",
    "start": "1553960",
    "end": "1560159"
  },
  {
    "text": "use like pandas SQL but don't necessarily like understand the whole",
    "start": "1560159",
    "end": "1566840"
  },
  {
    "text": "like I think a lot of D data scientists wouldn't be super happy if you ask them to like set up microservices by",
    "start": "1566840",
    "end": "1572000"
  },
  {
    "text": "themselves and things like that and so I think you kind of have to spend more",
    "start": "1572000",
    "end": "1578080"
  },
  {
    "text": "time thinking about the different roles that are involved in making the system operate well and make sure that you can",
    "start": "1578080",
    "end": "1583840"
  },
  {
    "text": "kind of accommodate what they want to do at different stages in the pipeline there's two names for this right there's",
    "start": "1583840",
    "end": "1589799"
  },
  {
    "text": "mlops and there's AI Ops oh like I want to say it sounds like we're splitting",
    "start": "1589799",
    "end": "1595880"
  },
  {
    "text": "hairs but I don't know enough to know for sure so I did a tiny bit of a research on Google Trends and things",
    "start": "1595880",
    "end": "1602200"
  },
  {
    "text": "like this AI Ops is more common in the Americas ml Ops is more common in Europe",
    "start": "1602200",
    "end": "1609760"
  },
  {
    "text": "and Asia but they really mean the same thing it kind of means the same thing I mean of course you you can go into",
    "start": "1609760",
    "end": "1616679"
  },
  {
    "text": "splitting hairs but this is kind of practically interchangeable right I was also curious kind of if you write that",
    "start": "1616679",
    "end": "1623559"
  },
  {
    "text": "as one word or two words well I typically use mlops actually as one word",
    "start": "1623559",
    "end": "1628960"
  },
  {
    "text": "and your base in the US yeah you're breaking the statistics but I usually do like a",
    "start": "1628960",
    "end": "1634720"
  },
  {
    "text": "capital m capital L capital O and then the rest lowercase I don't know if what",
    "start": "1634720",
    "end": "1640039"
  },
  {
    "text": "the statistics are on that but I think some people do it all caps and there's a bit of a disagreement there and other",
    "start": "1640039",
    "end": "1646440"
  },
  {
    "text": "way then it's just m mops or mops yeah can be confusing what",
    "start": "1646440",
    "end": "1652039"
  },
  {
    "text": "is this mops thing I keep seeing everywhere that a new product I'm happy",
    "start": "1652039",
    "end": "1657799"
  },
  {
    "text": "to say that very few people actually write with a space but I guess that kind of makes sense because you already write",
    "start": "1657799",
    "end": "1663120"
  },
  {
    "text": "devops as one word so it kind of continues that one but if anybody was curious about that here's all the",
    "start": "1663120",
    "end": "1668480"
  },
  {
    "text": "information you need on the terminology I will say I am curious where go fits into this wonderful world of of",
    "start": "1668480",
    "end": "1676519"
  },
  {
    "text": "mops yeah great question so I can kind of give you some perspective on how we're",
    "start": "1676519",
    "end": "1682720"
  },
  {
    "text": "using it at my company and then maybe a little bit on how I think it's going in the outside ecosystem although I'm",
    "start": "1682720",
    "end": "1689360"
  },
  {
    "text": "obviously more familiar with what we're doing so I mentioned before we have this",
    "start": "1689360",
    "end": "1694799"
  },
  {
    "text": "online serving interface for the system where um low latency is one of the big requirements and so that's primarily",
    "start": "1694799",
    "end": "1701600"
  },
  {
    "text": "where we're applying go at tecton so we have basically a server that uh we",
    "start": "1701600",
    "end": "1707039"
  },
  {
    "text": "deploy for every customer that is taking in Online requests for feature values and",
    "start": "1707039",
    "end": "1715159"
  },
  {
    "text": "we basically have a bit of a hybrid between pre- materializing the data and",
    "start": "1715159",
    "end": "1721080"
  },
  {
    "text": "then so we have some of it pre- materialized but we do some kind of final aggregation steps at serving time",
    "start": "1721080",
    "end": "1727039"
  },
  {
    "text": "and that's to make incremental updates easier when people need like frequently updated values so we basically have a",
    "start": "1727039",
    "end": "1733440"
  },
  {
    "text": "bunch of pree materialized data if we get this request coming in and we aggregate do final aggregations and then",
    "start": "1733440",
    "end": "1740760"
  },
  {
    "text": "return that result to the user so it's a pretty straightforward thing it's doing but like latency is really important",
    "start": "1740760",
    "end": "1747440"
  },
  {
    "text": "both keeping it low and then also keeping it consistent because typically people are concerned with how their tail",
    "start": "1747440",
    "end": "1753159"
  },
  {
    "text": "latency is looking so you you want to make sure that you control that and keep everything pretty consistent and so",
    "start": "1753159",
    "end": "1758919"
  },
  {
    "text": "that's where we've depl playy go the reason we chose go for this use case for me it really I mean the biggest thing",
    "start": "1758919",
    "end": "1765679"
  },
  {
    "text": "came down to the tools that gives you for kind of doing performance tuning and",
    "start": "1765679",
    "end": "1771440"
  },
  {
    "text": "being able to dig into performance problems you know things like the um the",
    "start": "1771440",
    "end": "1776480"
  },
  {
    "text": "built-in tracing and profiling like we've used really extensively in order",
    "start": "1776480",
    "end": "1781919"
  },
  {
    "text": "to meet our performance targets for this component so I think it's worked out really great for us was go the first",
    "start": "1781919",
    "end": "1788080"
  },
  {
    "text": "choice for this or did you started something and switched go was the first thing we used for this component yeah",
    "start": "1788080",
    "end": "1795120"
  },
  {
    "text": "trying to remember it's been a while now I don't think we like super seriously considered other options I mean we kind",
    "start": "1795120",
    "end": "1801399"
  },
  {
    "text": "of by necessity have a large part of the system right written in Python because",
    "start": "1801399",
    "end": "1806480"
  },
  {
    "text": "that's our SDK that we give the data scientists is you know they they're kind of expecting python there so I mean we",
    "start": "1806480",
    "end": "1814440"
  },
  {
    "text": "probably briefly considered it but I don't think it it would have worked with the performance requirements we have",
    "start": "1814440",
    "end": "1820320"
  },
  {
    "text": "interestingly we actually do have a python interpreter embedded in this go",
    "start": "1820320",
    "end": "1825840"
  },
  {
    "text": "server is we allow people to do sort of we call them",
    "start": "1825840",
    "end": "1831640"
  },
  {
    "text": "on demand Transformations so they're able to put in Transformations that run basically during serving time and you",
    "start": "1831640",
    "end": "1838200"
  },
  {
    "text": "might want to use that functionality for instance to compute a feature which is",
    "start": "1838200",
    "end": "1844399"
  },
  {
    "text": "like a combination of something in the user's history but also like a query that they're making that you're actively",
    "start": "1844399",
    "end": "1850559"
  },
  {
    "text": "making prediction for so you might want to have a feature which is like a silly",
    "start": "1850559",
    "end": "1855720"
  },
  {
    "text": "example would be like whether the you know what the difference in the length of the query and the last query was or",
    "start": "1855720",
    "end": "1861279"
  },
  {
    "text": "something like that and you would do that inside the python interpreter inside on the feature server so it is a",
    "start": "1861279",
    "end": "1866639"
  },
  {
    "text": "little bit of a a hybrid but like 95% of it is all ritten and go hey now you have me curious about this thing you've",
    "start": "1866639",
    "end": "1872720"
  },
  {
    "text": "embedded inside of there so this is not like a um you know you're getting like a",
    "start": "1872720",
    "end": "1878000"
  },
  {
    "text": "raw python string literal and then you're shelling out to some python runtime and then getting results back",
    "start": "1878000",
    "end": "1883799"
  },
  {
    "text": "this is like you're actually like interpreting the python code in Translating that into what you need to",
    "start": "1883799",
    "end": "1889039"
  },
  {
    "text": "then do so we are running a full python interpreter we're not like translating the python into some okay yeah that that",
    "start": "1889039",
    "end": "1896279"
  },
  {
    "text": "would be pretty cool but we're not doing that now but I'm like you need to open source that",
    "start": "1896279",
    "end": "1901320"
  },
  {
    "text": "thing I have actually kind of looked into this there are projects floating around that will let you do like",
    "start": "1901320",
    "end": "1908200"
  },
  {
    "text": "basically compile python down to lvm B code or something and then you could",
    "start": "1908200",
    "end": "1913440"
  },
  {
    "text": "potentially link that into a go binary we haven't really seriously investigated that I mean most of these",
    "start": "1913440",
    "end": "1920159"
  },
  {
    "text": "Transformations are doing quite simple things they're not super performance intensive so we haven't really seen the",
    "start": "1920159",
    "end": "1926880"
  },
  {
    "text": "need but it's something we could look at doing potentially so this was done really to solve not really a technical",
    "start": "1926880",
    "end": "1934960"
  },
  {
    "text": "problem but more of a meeting your users like internal right users where they are",
    "start": "1934960",
    "end": "1940720"
  },
  {
    "text": "kind of thing because if python is what they know and that's their tool that's the thing that they know best supporting",
    "start": "1940720",
    "end": "1948000"
  },
  {
    "text": "that to some degree right was sort of the goal not really because it couldn't have been done and go right yeah that",
    "start": "1948000",
    "end": "1955200"
  },
  {
    "text": "was definitely the main thing is that our our customers writing these are primarily familiar with python there's",
    "start": "1955200",
    "end": "1962360"
  },
  {
    "text": "also a bit of a nice thing technically with python and that you can just take",
    "start": "1962360",
    "end": "1968279"
  },
  {
    "text": "you know the function definition as a string and just you know send it to the server and so you don't have to worry",
    "start": "1968279",
    "end": "1975440"
  },
  {
    "text": "about like linking it into the binary and restarting the server every time there's a new configuration basically",
    "start": "1975440",
    "end": "1982120"
  },
  {
    "text": "that's something I'm sure we could have figured out with go but we just haven't really had like a strong need to do it I",
    "start": "1982120",
    "end": "1988080"
  },
  {
    "text": "know there are other systems like um I might be misaking here but I believe Airbnb has like published they have like",
    "start": "1988080",
    "end": "1994600"
  },
  {
    "text": "an internal feature store products where I think they I think they have an equivalent concept where they have",
    "start": "1994600",
    "end": "2000120"
  },
  {
    "text": "people write the transformations in Rust maybe um and they can make this whole thing like super fast but I think that's",
    "start": "2000120",
    "end": "2006440"
  },
  {
    "text": "kind of like a an outlier case like most of our users when they're writing these things are doing very simple additions or or very",
    "start": "2006440",
    "end": "2014240"
  },
  {
    "text": "small Transformations that really only take like a few hundred micros seconds generally so we haven't seen a need",
    "start": "2014240",
    "end": "2020480"
  },
  {
    "text": "would you say that go is generally a good choice for machine learning Ops for mlops lops mops yeah I mean I think",
    "start": "2020480",
    "end": "2029679"
  },
  {
    "text": "so I think you'll find kind of at the various layers of the ml op stack there",
    "start": "2029679",
    "end": "2035240"
  },
  {
    "text": "always going to be these components that are pretty latency sensitive like across",
    "start": "2035240",
    "end": "2041279"
  },
  {
    "text": "most of the customers I've talked to generally like pretty low latency for the end to end system is like a pretty",
    "start": "2041279",
    "end": "2046880"
  },
  {
    "text": "important requirement and I really like go for that purpose I mean it's not necessarily that the language itself is",
    "start": "2046880",
    "end": "2053839"
  },
  {
    "text": "somehow super fast compared to other languages out there in fact we've had issues with like the garbage collector",
    "start": "2053839",
    "end": "2060040"
  },
  {
    "text": "and stuff that you know we might not have had in other languages but really for me the tools that it gives you to",
    "start": "2060040",
    "end": "2066358"
  },
  {
    "text": "kind of identify these problems and deal with them are make it like a really good choice so even if you know there are",
    "start": "2066359",
    "end": "2073560"
  },
  {
    "text": "issues that come up I like confident that we can like solve them quickly without spending a ton of time trying to",
    "start": "2073560",
    "end": "2079240"
  },
  {
    "text": "figure out what's going on and that is worth the price of admission my friend yeah definitely and I would say the other",
    "start": "2079240",
    "end": "2085960"
  },
  {
    "text": "thing too is that there's I mean in the kind of broader mlops ecosystem like I I",
    "start": "2085960",
    "end": "2092118"
  },
  {
    "text": "think a lot of a lot of people are kind of using kubernetes as part of the solution that they're deploying and um I",
    "start": "2092119",
    "end": "2100280"
  },
  {
    "text": "found that just like being familiar with go and the ecosystem is really helpful in that space because it's like pretty",
    "start": "2100280",
    "end": "2106240"
  },
  {
    "text": "easy to just if you're confused at why something is behaving in a certain way you can just like go look at the code",
    "start": "2106240",
    "end": "2112320"
  },
  {
    "text": "figure it out so I think that's pretty helpful too being kind of familiar with the ecosystem so you mentioned the",
    "start": "2112320",
    "end": "2117839"
  },
  {
    "text": "toolings as a thing that is super useful for you in your world as a developer in",
    "start": "2117839",
    "end": "2123599"
  },
  {
    "text": "the in the world of lops interesting I would really expect that you also mention something like the speed of the",
    "start": "2123599",
    "end": "2130040"
  },
  {
    "text": "language because it is really fast it is certainly fast compared to something like python in my previous Life as a you",
    "start": "2130040",
    "end": "2138280"
  },
  {
    "text": "know software engineer at Google we were mostly using C++ so it's like compared to that it's not like intrinsically",
    "start": "2138280",
    "end": "2145480"
  },
  {
    "text": "faster right sure okay and so for me I guess given my background I just look at",
    "start": "2145480",
    "end": "2151079"
  },
  {
    "text": "the tooling and the ease of making everything work as the main advantage but I guess you were coming the other",
    "start": "2151079",
    "end": "2156520"
  },
  {
    "text": "way from like having written a lot of python it would probably be a different story it's all relative",
    "start": "2156520",
    "end": "2162470"
  },
  {
    "text": "[Music]",
    "start": "2162470",
    "end": "2172699"
  },
  {
    "text": "yeah hey Jared here one of the things we can count on in the software industry is",
    "start": "2173119",
    "end": "2179520"
  },
  {
    "text": "change the state-ofthe-art changes so fast in fact that keeping up can feel like a whole other job on top of your",
    "start": "2179520",
    "end": "2186280"
  },
  {
    "text": "actual job that's why we created change log weekly it's our totally free",
    "start": "2186280",
    "end": "2191480"
  },
  {
    "text": "newsletter that we drop in your inbox each and every Sunday we link to the latest news the best articles and the",
    "start": "2191480",
    "end": "2198760"
  },
  {
    "text": "most interesting projects that you should be aware of we also add a little commentary from us saying why",
    "start": "2198760",
    "end": "2204480"
  },
  {
    "text": "something's important pointing you to other instances of a trend or just making a dorky joke to keep it Lively so",
    "start": "2204480",
    "end": "2210520"
  },
  {
    "text": "if you haven't yet I recommend subscribing to change log weekly and help us help you keep up with the latest",
    "start": "2210520",
    "end": "2217160"
  },
  {
    "text": "head to chain.com weekly and sign up today again it's totally free and we never spam you yuck one last time that's",
    "start": "2217160",
    "end": "2225560"
  },
  {
    "text": "Chang law.com [Music]",
    "start": "2225560",
    "end": "2239839"
  },
  {
    "text": "weekly when did you start writing go what got you into this yeah so it was at",
    "start": "2239839",
    "end": "2245440"
  },
  {
    "text": "Google I think I was trying to remember before I came",
    "start": "2245440",
    "end": "2250480"
  },
  {
    "text": "on here I think it was probably around 2015 was the first time mhm and it was",
    "start": "2250480",
    "end": "2256440"
  },
  {
    "text": "not kind of the primary thing I did there so like I said like it was most of C++ but I worked a lot on the basically",
    "start": "2256440",
    "end": "2265599"
  },
  {
    "text": "experiments system for web search at Google and a big piece of that was that",
    "start": "2265599",
    "end": "2271839"
  },
  {
    "text": "all of the different front ends that were serving Google search would be basically creating kind of kind of structured application logs of",
    "start": "2271839",
    "end": "2278800"
  },
  {
    "text": "everybody's interactions constantly and they would all get crunched down into a",
    "start": "2278800",
    "end": "2284000"
  },
  {
    "text": "bunch of business metrics every day and those metrics were what drove all the experiments that were going on at Google",
    "start": "2284000",
    "end": "2290640"
  },
  {
    "text": "basically there' be like thousands of these experiments running at a time and the whole pipeline for crunching all",
    "start": "2290640",
    "end": "2298240"
  },
  {
    "text": "those logs down into metrics was at the time I was involved with it written and go and it still is it was before that",
    "start": "2298240",
    "end": "2306240"
  },
  {
    "text": "had been all written in this like domain specific language called Sall which was",
    "start": "2306240",
    "end": "2312359"
  },
  {
    "text": "actually created by Rob Pike so there's a bit of a connection to go there as well yeah at the time I was working on",
    "start": "2312359",
    "end": "2318880"
  },
  {
    "text": "it everything was in go that system had like there were a bunch of different teams at Google that would contribute",
    "start": "2318880",
    "end": "2324880"
  },
  {
    "text": "their own metric to it so like the image search team would have metrics having to do with images there would be some that",
    "start": "2324880",
    "end": "2331240"
  },
  {
    "text": "were common across all the different search properties but basically there were like a ton of people contributing",
    "start": "2331240",
    "end": "2336599"
  },
  {
    "text": "these metrics and so there was a library for creating them and I spent some time",
    "start": "2336599",
    "end": "2341920"
  },
  {
    "text": "working on that library because we were changing how things were logged in search front ends and so we had to make",
    "start": "2341920",
    "end": "2347520"
  },
  {
    "text": "sure that people we weren't breaking people's metrics when we were doing that so that's how I got involved right and",
    "start": "2347520",
    "end": "2352720"
  },
  {
    "text": "go basically was trying to not break people that were Downstream of the changes I was making and that's also",
    "start": "2352720",
    "end": "2359640"
  },
  {
    "text": "would you say the main language for you now right some python but most of this yeah we've got definitely a mix all of",
    "start": "2359640",
    "end": "2366640"
  },
  {
    "text": "our online serving stuff is written and go there's the python for the the customer facing stuff and then just for",
    "start": "2366640",
    "end": "2372520"
  },
  {
    "text": "variety we have cotlin that's uh involved in some of the more kind of like management and orchestration",
    "start": "2372520",
    "end": "2379480"
  },
  {
    "text": "systems that are kind of off to the side and feast is the open source project",
    "start": "2379480",
    "end": "2385040"
  },
  {
    "text": "right yes and it has some go it has some go um I'm frankly less familiar with the",
    "start": "2385040",
    "end": "2393000"
  },
  {
    "text": "exact composition of everything on on the feast side um they're a lot more python focused because they basically",
    "start": "2393000",
    "end": "2400560"
  },
  {
    "text": "run a lot more of the feature Source system sort of inside the client whereas",
    "start": "2400560",
    "end": "2406400"
  },
  {
    "text": "Ton's kind of architected with more things living on the back end but they do have some Go mixed in there as well",
    "start": "2406400",
    "end": "2412760"
  },
  {
    "text": "okay so anybody who's listening and wants to dive into this a little bit by contributing code can do this yeah in",
    "start": "2412760",
    "end": "2420160"
  },
  {
    "text": "the repo of feast yeah Feast is a a good place to start I love the wiki and I",
    "start": "2420160",
    "end": "2425839"
  },
  {
    "text": "love the document ation I have to say a feast it's a great job with that yeah they've done a a really good job with",
    "start": "2425839",
    "end": "2431119"
  },
  {
    "text": "all that stuff cool okay and journy is like as we laughed earlier quickly",
    "start": "2431119",
    "end": "2438520"
  },
  {
    "text": "scheming through everything and now is becoming the the expert in justing data yeah like next week interview me on on",
    "start": "2438520",
    "end": "2445640"
  },
  {
    "text": "mops I'll have all the answers but then I will include the",
    "start": "2445640",
    "end": "2450680"
  },
  {
    "text": "question on the difference from lops to IOP then I guess comes the fun part on",
    "start": "2450680",
    "end": "2459599"
  },
  {
    "text": "this journey you want to ask anything before we start talking about unpopular parts let's get to the unpopular stuff",
    "start": "2459599",
    "end": "2466119"
  },
  {
    "text": "all [Music]",
    "start": "2466119",
    "end": "2472359"
  },
  {
    "text": "right I actually think you should probably [Music]",
    "start": "2472359",
    "end": "2482440"
  },
  {
    "text": "leave I don't know if I'm supposed to say this and I'm sorry if not but the performer of this wonderful song has",
    "start": "2482440",
    "end": "2489359"
  },
  {
    "text": "a birthday today finally turning 18 so if you see Matt on",
    "start": "2489359",
    "end": "2495640"
  },
  {
    "text": "Twitter wish him a happy birthday but only if you're listening to the live recording actually you know what even if",
    "start": "2495640",
    "end": "2501480"
  },
  {
    "text": "you're listening afterwards it's all just say hi to Matt you know you don't need to say happy birthday just say hey",
    "start": "2501480",
    "end": "2506720"
  },
  {
    "text": "Matt he's finally an adult maybe he'll grow up maybe he'll grow",
    "start": "2506720",
    "end": "2513079"
  },
  {
    "text": "up that's an unpopular opinion I guess",
    "start": "2513079",
    "end": "2518240"
  },
  {
    "text": "Matt we love you very much it's all in good vibes Mike do you have an unpopular opinion for us yes I have an in popular",
    "start": "2518599",
    "end": "2525359"
  },
  {
    "text": "opinion so it's not Tech related which I hope is okay but it's all good that's not popular I really just don't like",
    "start": "2525359",
    "end": "2531960"
  },
  {
    "text": "maple syrup is my unpopular opinion even on Pancakes on waffles I just don't",
    "start": "2531960",
    "end": "2538040"
  },
  {
    "text": "don't do it so that's my opinion okay Johnny I saw a tweet from you from the",
    "start": "2538040",
    "end": "2543240"
  },
  {
    "text": "weekend that you were making pancakes yeah yeah my uh you know I have young kids and they love themselves a pancake",
    "start": "2543240",
    "end": "2549160"
  },
  {
    "text": "especially the syrup so it seems almost Universal just not",
    "start": "2549160",
    "end": "2555119"
  },
  {
    "text": "for me what don't you like about it Mike how sticky it is is a big big part of it is it more or less sticky than honey",
    "start": "2555119",
    "end": "2561839"
  },
  {
    "text": "somehow it feels more to me I don't know if that's chemically accurate but um",
    "start": "2561839",
    "end": "2567160"
  },
  {
    "text": "that's my perception anyway and we've got a lot of uh Canadians working at tekon actually back the CEO is Canadian",
    "start": "2567160",
    "end": "2575559"
  },
  {
    "text": "so I hope if they hear this I don't get uh you know ostracized but oh you don't like uh",
    "start": "2575559",
    "end": "2582000"
  },
  {
    "text": "syrup a well there you have it unpopular",
    "start": "2582000",
    "end": "2587160"
  },
  {
    "text": "opinion yeah I think the most funny opinions we have is in the context of food so great choice for an unpopular",
    "start": "2587160",
    "end": "2594160"
  },
  {
    "text": "opinion there will be a Twitter survey we will see how unpopular is your unpopular opinion and you might get into",
    "start": "2594160",
    "end": "2601240"
  },
  {
    "text": "the top five or low five are you supposed to have the most people disagree with you I mean you know it's a",
    "start": "2601240",
    "end": "2608359"
  },
  {
    "text": "goal it's we all have life goals so why why not this one okay hopefully I do",
    "start": "2608359",
    "end": "2613880"
  },
  {
    "text": "well then cool all right well that was a very interesting conversation and I think",
    "start": "2613880",
    "end": "2620040"
  },
  {
    "text": "it's a rather New Field at least in our context of gophers this mops in general",
    "start": "2620040",
    "end": "2626119"
  },
  {
    "text": "but also feature stores in specific and we will be providing links for you to",
    "start": "2626119",
    "end": "2631640"
  },
  {
    "text": "learn if you want to dive into that or if you want to contribute code to feast",
    "start": "2631640",
    "end": "2636920"
  },
  {
    "text": "and we also want to say thank you to Mike for joining us and for teaching us",
    "start": "2636920",
    "end": "2642359"
  },
  {
    "text": "so many interesting things indeed thank you for having me thanks everyone all right",
    "start": "2642359",
    "end": "2648359"
  },
  {
    "text": "y'all if you enjoyed this conversation about ml Ops in go check out our other",
    "start": "2650480",
    "end": "2656319"
  },
  {
    "text": "pod that focuses exclusively on AI and ml related things it's called practical",
    "start": "2656319",
    "end": "2662240"
  },
  {
    "text": "Ai and it's hosted by fellow Gophers Daniel wh neack and Chris Benson you can find it at practical a.m or in your",
    "start": "2662240",
    "end": "2669200"
  },
  {
    "text": "favorite podcast app just search for practical AI you'll find it and of course the Galaxy brain move is to",
    "start": "2669200",
    "end": "2674559"
  },
  {
    "text": "subscribe to our Master feed then your podcast app grabs every show we produce including backstage which you can't get",
    "start": "2674559",
    "end": "2681040"
  },
  {
    "text": "anywhere else and you can just pick and choose the episodes that interest you most check it out at changel log.com or",
    "start": "2681040",
    "end": "2688440"
  },
  {
    "text": "by sechs for changelog Master feed go time is produced by Jared Santo with music by our beat freaking residents",
    "start": "2688440",
    "end": "2694240"
  },
  {
    "text": "break master cylinder thanks again to our partners at fastly for shipping our shows super fast all around the world",
    "start": "2694240",
    "end": "2700480"
  },
  {
    "text": "Natalie and Johnny will be back next week they'll be talking apis with a team behind API toolkit we'll talk to you",
    "start": "2700480",
    "end": "2707079"
  },
  {
    "text": "again next time on go [Music]",
    "start": "2707079",
    "end": "2713919"
  },
  {
    "text": "time",
    "start": "2716119",
    "end": "2719119"
  }
]
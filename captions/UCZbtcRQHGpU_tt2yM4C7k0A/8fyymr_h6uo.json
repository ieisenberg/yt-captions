[
  {
    "text": "B with for change log is provided by fastly learn more at fastly.com we move",
    "start": "80",
    "end": "6040"
  },
  {
    "text": "fast and fix things here at Chang log because of rbar check them out at rar.com and we're hosted on Leno servers",
    "start": "6040",
    "end": "12799"
  },
  {
    "text": "head to lin.com changelog this episode is brought to you by digital ocean they now have CPU",
    "start": "12799",
    "end": "19560"
  },
  {
    "text": "optimized droplets with dedicated hyper threads from best in-class Intel CPUs",
    "start": "19560",
    "end": "25199"
  },
  {
    "text": "for all your machine learning and batch processing needs you can easily spin up their oneclick machine learning and AI",
    "start": "25199",
    "end": "31039"
  },
  {
    "text": "application image this gives you immediate access to Python 3 R Jupiter",
    "start": "31039",
    "end": "36200"
  },
  {
    "text": "notebook tensor flow s kit and pytorch use our special link to get a $100",
    "start": "36200",
    "end": "42239"
  },
  {
    "text": "credit for digital ocean and try today for free head to do. changelog once",
    "start": "42239",
    "end": "48160"
  },
  {
    "text": "again do. [Music]",
    "start": "48160",
    "end": "58920"
  },
  {
    "text": "changelog welcome to practical AI a weekly podcast",
    "start": "58920",
    "end": "66479"
  },
  {
    "text": "about making artificial intelligence practical productive and accessible to everyone this is where conversations",
    "start": "66479",
    "end": "72880"
  },
  {
    "text": "around AI machine learning and data science happen join the community and slack with us around various topics of",
    "start": "72880",
    "end": "78240"
  },
  {
    "text": "the show at change.com Community follow us on Twitter we're at practical aifm",
    "start": "78240",
    "end": "83560"
  },
  {
    "text": "and now on the [Music] show Welcome to another practical AI",
    "start": "83560",
    "end": "91640"
  },
  {
    "text": "Chris I know that you've had a number of jobs throughout your career was the hiring process always super smooth for",
    "start": "91640",
    "end": "99000"
  },
  {
    "text": "you anything but I've been hired more than a few times and I've hired lots of people over the years and no for me at",
    "start": "99000",
    "end": "106320"
  },
  {
    "text": "least way way more art than science so I'm looking forward to uh to maybe learning something here yeah we've got",
    "start": "106320",
    "end": "113479"
  },
  {
    "text": "uh Lindsay zaga with us welcome Lindsay hi nice to be here yeah did did I get the name right yeah you did good okay",
    "start": "113479",
    "end": "120039"
  },
  {
    "text": "perfect well I'm excited to have you on the show today I know me as well kind of with with Chris I've had some awkward",
    "start": "120039",
    "end": "126479"
  },
  {
    "text": "experiences in the hiring process I've done well at interviewing I've crashed in the interviewing process I've done",
    "start": "126479",
    "end": "133080"
  },
  {
    "text": "well and bad at assessments and coding things and and uh we're just excited to",
    "start": "133080",
    "end": "138239"
  },
  {
    "text": "have you because we're going to be talking today about your work with AI and hiring and also bias in AI so super",
    "start": "138239",
    "end": "146040"
  },
  {
    "text": "great to have you here it'd be great if we could just hear a little bit about your background I know you started out",
    "start": "146040",
    "end": "151400"
  },
  {
    "text": "in Academia and then eventually moved into industry so give us a little bit of your story sure I studied physics so I",
    "start": "151400",
    "end": "159239"
  },
  {
    "text": "uh did my undergrad here in Utah the University of Utah and then I did a master's and PhD at Rice University in",
    "start": "159239",
    "end": "165879"
  },
  {
    "text": "Houston Texas and a postdoc in Germany as well so during that time I was in the",
    "start": "165879",
    "end": "172200"
  },
  {
    "text": "field of nanophotonics I studying um and doing experiments on how Nano particles",
    "start": "172200",
    "end": "178560"
  },
  {
    "text": "interact with light so building laser setups and kind of pretty different world than what I'm in now uh when I",
    "start": "178560",
    "end": "186400"
  },
  {
    "text": "went into graduate school I really wanted to work with my hands I thought I didn't want to sit at a computer all day",
    "start": "186400",
    "end": "192640"
  },
  {
    "text": "but to my surprise what I actually enjoyed the most about my work was writing code to analyze data so when I",
    "start": "192640",
    "end": "199799"
  },
  {
    "text": "did transition into industry data science ended up being a really good fit kind of relies on a lot of those similar",
    "start": "199799",
    "end": "206200"
  },
  {
    "text": "problem solving skills that I learned obviously having a strong math background was useful and you know",
    "start": "206200",
    "end": "212319"
  },
  {
    "text": "analyzing analyzing data writing code to analyze data so it was kind of a a good",
    "start": "212319",
    "end": "217400"
  },
  {
    "text": "fit the right place at the right time my transition um and you guys talked about job interviewing I'll say I I've written",
    "start": "217400",
    "end": "224720"
  },
  {
    "text": "a blog post about this but my transition from Academia to industry was a lot more",
    "start": "224720",
    "end": "229959"
  },
  {
    "text": "difficult than I expected I was doing well in Academia so I kind of thought",
    "start": "229959",
    "end": "235000"
  },
  {
    "text": "would be easy for me to transition into industry and really kind of was naive",
    "start": "235000",
    "end": "240319"
  },
  {
    "text": "about the importance of connections you know I had a CV not a resume but a CV",
    "start": "240319",
    "end": "246040"
  },
  {
    "text": "with Publications on it and things that people in Industry don't really care about so I came into the whole industry",
    "start": "246040",
    "end": "253400"
  },
  {
    "text": "job World a little naive and ended up applying for a lot of jobs online and",
    "start": "253400",
    "end": "258600"
  },
  {
    "text": "going through this process and many people have probably been through it where you apply for a job through what's",
    "start": "258600",
    "end": "264000"
  },
  {
    "text": "called an applicant tracking system and an ATS and you enter all your",
    "start": "264000",
    "end": "269080"
  },
  {
    "text": "information you upload your resume and then you have to re-enter all the information in and then all your",
    "start": "269080",
    "end": "276000"
  },
  {
    "text": "information kind of gets parsed into PL text and you finally submit you know and you you spent all this time kind of",
    "start": "276000",
    "end": "282199"
  },
  {
    "text": "trying to personalize your cover letter and you submit and you just never hear",
    "start": "282199",
    "end": "287560"
  },
  {
    "text": "anything again so it's kind of this black hole I hate those systems uh whe whether I'm an applicant or a hiring",
    "start": "287560",
    "end": "293759"
  },
  {
    "text": "manager either way they're terrible yeah I hate how you format your resume perfectly and you get it all flashy",
    "start": "293759",
    "end": "300160"
  },
  {
    "text": "looking and then you go through the system and then you realize that you just have to like put it in as plain",
    "start": "300160",
    "end": "305440"
  },
  {
    "text": "text or something and all of that work is for not exactly and there's a lot of gaming in the system which I didn't know",
    "start": "305440",
    "end": "313080"
  },
  {
    "text": "and and maybe I would have benefited from knowing this at the time but there's actually like there's a website",
    "start": "313080",
    "end": "318479"
  },
  {
    "text": "can't remember what it's called but you can go and see you put in a job posting and then you put in your cover letter or",
    "start": "318479",
    "end": "324199"
  },
  {
    "text": "your resume and it will tell you the likelihood of getting past these ATS filters and it's",
    "start": "324199",
    "end": "330160"
  },
  {
    "text": "literally just a lot of times it's just like a keyword match and I always felt like that was a little weird to just",
    "start": "330160",
    "end": "337360"
  },
  {
    "text": "like put the exact keywords that are in the job posting in my in my application",
    "start": "337360",
    "end": "342759"
  },
  {
    "text": "but it turns out that does help you get past these filters a lot of times these filters are pretty simple they're",
    "start": "342759",
    "end": "348039"
  },
  {
    "text": "looking for certain keywords or they're looking for certain School you went to or GPA which is silly because we found a",
    "start": "348039",
    "end": "355319"
  },
  {
    "text": "lot of times that doesn't really tie to job performance very strongly at all but the bottom line is you know companies",
    "start": "355319",
    "end": "361560"
  },
  {
    "text": "just have so many applicants they need some way of filtering through people and",
    "start": "361560",
    "end": "367000"
  },
  {
    "text": "I went away from the experience feeling like something's wrong with this system when me and so many people that I know",
    "start": "367000",
    "end": "372919"
  },
  {
    "text": "that had phds and once they got a job they did really well they were just passed up by so many companies the",
    "start": "372919",
    "end": "379639"
  },
  {
    "text": "companies are losing out as well that story is kind of my motivation of of why",
    "start": "379639",
    "end": "385000"
  },
  {
    "text": "I I care about hiring and kind of fixing this bro broken system now you're director of data science at higher viiew",
    "start": "385000",
    "end": "391240"
  },
  {
    "text": "is that correct yes yeah and what does higher view do is it one of these systems or what what do you work on and",
    "start": "391240",
    "end": "397400"
  },
  {
    "text": "what does the company do no yeah we're not an applicant tracking system although we do a lot of times have to work with them integrate into them we",
    "start": "397400",
    "end": "405560"
  },
  {
    "text": "are a video interviewing company so our philosophy is that a resume and and a",
    "start": "405560",
    "end": "411319"
  },
  {
    "text": "cover letter are not a very good representation of a person so you know we started years ago with a video",
    "start": "411319",
    "end": "418440"
  },
  {
    "text": "interviewing platform and our most popular product is called an on demand interview which is asynchronous our",
    "start": "418440",
    "end": "425400"
  },
  {
    "text": "customers are companies that create interviews they can have any different",
    "start": "425400",
    "end": "431639"
  },
  {
    "text": "types of questions they can have professional football player ask the question they can do all sorts of",
    "start": "431639",
    "end": "437319"
  },
  {
    "text": "interesting things they can send the same interview out to many different people and the people record themselves",
    "start": "437319",
    "end": "442919"
  },
  {
    "text": "answering questions on their own time and then the companies can review those interviews on their own time so that's a",
    "start": "442919",
    "end": "448960"
  },
  {
    "text": "very pop popular product and that was you know kind of our our main product for a long time because it kind of",
    "start": "448960",
    "end": "454840"
  },
  {
    "text": "replaces this resume phone screening like initial stage of the funnel because",
    "start": "454840",
    "end": "461240"
  },
  {
    "text": "we've all experienced you know looking at resum√©s and they all look the same and it's really hard to differentiate",
    "start": "461240",
    "end": "466680"
  },
  {
    "text": "people but once you hear them talk about what they're interested in and how they communicate you can get a better feel",
    "start": "466680",
    "end": "472520"
  },
  {
    "text": "for who they are so we had a lot of success with that product but we still had this issue of volume like I said",
    "start": "472520",
    "end": "479039"
  },
  {
    "text": "before like companies are just getting so many applicants that it's impossible for them to actually look at all of them",
    "start": "479039",
    "end": "485159"
  },
  {
    "text": "and and the way it ends up going today is that a lot of people are just randomly ignored so we started building",
    "start": "485159",
    "end": "492440"
  },
  {
    "text": "our AI product a few years back where we said we have all this this Rich data",
    "start": "492440",
    "end": "497520"
  },
  {
    "text": "from job interviews and if our customers can tell us who ended up being good at a",
    "start": "497520",
    "end": "503280"
  },
  {
    "text": "job and who is bad at a job and that what that is depends totally on the job so we have some performance metrics",
    "start": "503280",
    "end": "509800"
  },
  {
    "text": "around um you know this person was a really good salesperson they sold a lot and this person wasn't can we train",
    "start": "509800",
    "end": "516039"
  },
  {
    "text": "algorithms to notice patterns between you know people who are top performers in a job and and others so that is the",
    "start": "516039",
    "end": "524760"
  },
  {
    "text": "assessments product that I work on so would it be fair to say that you're kind of focusing on using machine learning to",
    "start": "524760",
    "end": "532240"
  },
  {
    "text": "take the bias out of the process of hiring and and if so how does that work how does that manifest itself how do you",
    "start": "532240",
    "end": "538839"
  },
  {
    "text": "train to get get rid of that yeah so it is a common question that we get pretty immediately when people hear about what",
    "start": "538839",
    "end": "544800"
  },
  {
    "text": "they do what we do is a little bit of like oh this is creepy and how how do you know what the algorithm is doing how",
    "start": "544800",
    "end": "550959"
  },
  {
    "text": "do you know it's not bias so you know algorithms are really good at stereotyping and that can be an issue",
    "start": "550959",
    "end": "557600"
  },
  {
    "text": "anywhere where AI is used if there's any bias in the training data or just even",
    "start": "557600",
    "end": "563519"
  },
  {
    "text": "under representation in the training data of certain groups the algorithm could mirror that bias so do you mean",
    "start": "563519",
    "end": "571399"
  },
  {
    "text": "kind of like if there's only a representation of certain type of candidates let's say then your algorithm",
    "start": "571399",
    "end": "578560"
  },
  {
    "text": "might behave differently when it's trained on that data according to uh when it sees those candidates versus you",
    "start": "578560",
    "end": "585160"
  },
  {
    "text": "know candidates that weren't in the in the pool in the training pool is is that kind of a a fair statement sure and I",
    "start": "585160",
    "end": "592040"
  },
  {
    "text": "think an even bigger issue is if there's a small number of like say there's only",
    "start": "592040",
    "end": "597399"
  },
  {
    "text": "one female software engineer and she wasn't very good then the algorithm takes that and says oh every time I've",
    "start": "597399",
    "end": "604800"
  },
  {
    "text": "seen someone act like this or talk like this they were bad so if there's no one",
    "start": "604800",
    "end": "610760"
  },
  {
    "text": "the algorithm doesn't learn as strong of patterns although it it could and and it's something you want to look out for",
    "start": "610760",
    "end": "616560"
  },
  {
    "text": "but um a lot of times uh under representation or just explicit you know",
    "start": "616560",
    "end": "622000"
  },
  {
    "text": "bias like in the data which which we do sometimes see and depending on how subjective that performance metric is",
    "start": "622000",
    "end": "629360"
  },
  {
    "text": "that can be strong and depending on the country as well we've seen it um vary and kind of like like manager ratings",
    "start": "629360",
    "end": "636760"
  },
  {
    "text": "and things that are subjective like that so we definitely prefer objective metrics like sales numbers call handle",
    "start": "636760",
    "end": "642480"
  },
  {
    "text": "time you know kind of productivity measures things like that I'm curious have you had more of a challenge on this",
    "start": "642480",
    "end": "649800"
  },
  {
    "text": "front in certain industries I'm not sure which Industries you know high viiew is is working with you mentioned sales a",
    "start": "649800",
    "end": "655720"
  },
  {
    "text": "little bit maybe software engineering do you have to kind of approach this as far as your models go differently in",
    "start": "655720",
    "end": "662120"
  },
  {
    "text": "different Industries or is this something that's kind of a problem across the board yeah I would say it's",
    "start": "662120",
    "end": "668200"
  },
  {
    "text": "probably more on a company level um or a cultural level that we we notice",
    "start": "668200",
    "end": "674040"
  },
  {
    "text": "differences so a lot of what is important in trying to level the playing",
    "start": "674040",
    "end": "680519"
  },
  {
    "text": "field is is um you know these interviews ask people very consistent questions and",
    "start": "680519",
    "end": "686399"
  },
  {
    "text": "that's something that's that's been done in hiring over the p several decades because you know hiring is very much",
    "start": "686399",
    "end": "692320"
  },
  {
    "text": "about gut feelings so we've improved it by trying to treat all candidates in a",
    "start": "692320",
    "end": "697399"
  },
  {
    "text": "consistent way but it's pretty much impossible for humans to actually do that humans have this implicit bias that",
    "start": "697399",
    "end": "703720"
  },
  {
    "text": "we don't even know we have so there's also a big culture recently of like this",
    "start": "703720",
    "end": "710160"
  },
  {
    "text": "concept of cultural fit which is very popular in companies say they want to hire someone who they like and that can",
    "start": "710160",
    "end": "717480"
  },
  {
    "text": "communicate well with them and work well with their team but this often results in like a similarity bias where I don't",
    "start": "717480",
    "end": "724000"
  },
  {
    "text": "know why I just like that person well you like them because they're a lot like you or they are a lot like your team",
    "start": "724000",
    "end": "729360"
  },
  {
    "text": "already so you get this homogeneity in your team so to some degree would it be",
    "start": "729360",
    "end": "735560"
  },
  {
    "text": "fair to say that when when a company is looking for cultural fit are they almost acknowledging their bias and saying",
    "start": "735560",
    "end": "741720"
  },
  {
    "text": "we're going to we're going to accept that as part of the process or or am I misreading that um I mean I think some",
    "start": "741720",
    "end": "747279"
  },
  {
    "text": "people have made that argument there's you know there's articles written about the the issues with cultural fit which",
    "start": "747279",
    "end": "753399"
  },
  {
    "text": "is just are you just opening the door for bias I wouldn't go that far to necessarily say that that's exactly",
    "start": "753399",
    "end": "759639"
  },
  {
    "text": "what's going on I mean I do understand the concept but it is it is very tricky and and you know humans are probably",
    "start": "759639",
    "end": "767639"
  },
  {
    "text": "going to be a part of the hiring process for a long time so it's something that we need to try to deal with so I'm kind",
    "start": "767639",
    "end": "773959"
  },
  {
    "text": "of thinking in my mind um right now in terms of like okay we know that humans are biased in terms of these ways that",
    "start": "773959",
    "end": "780320"
  },
  {
    "text": "we've mentioned we know that we can kind of subtly introduce bias into our",
    "start": "780320",
    "end": "786040"
  },
  {
    "text": "machine learning and AI models via uh representation in the data set and and other ways um I'm just wondering as kind",
    "start": "786040",
    "end": "793320"
  },
  {
    "text": "of human AI developers you know what chance do we have of of kind of fighting",
    "start": "793320",
    "end": "798800"
  },
  {
    "text": "this bias and and how can we have hope to actually do something better yeah I",
    "start": "798800",
    "end": "804600"
  },
  {
    "text": "think a big part of it is just becoming aware so as data scientist I I think",
    "start": "804600",
    "end": "809800"
  },
  {
    "text": "we've we spent a lot of time just trying to optimize the accuracy of our algorithms and kind of not thinking",
    "start": "809800",
    "end": "815720"
  },
  {
    "text": "about bias or fairness at all as I've studied algorithmic fairness more and",
    "start": "815720",
    "end": "821440"
  },
  {
    "text": "more I found that it it's a it's a more nuanced tricky topic than you might",
    "start": "821440",
    "end": "826519"
  },
  {
    "text": "assume so if you look up there's a recidivism model this is kind of a started a whole conversation that's",
    "start": "826519",
    "end": "832920"
  },
  {
    "text": "called compass and it was this recidivism model in Florida where they tried to predict the chance that someone",
    "start": "832920",
    "end": "839720"
  },
  {
    "text": "would reoffend after they were released from prison when you looked at the data actually blacks had a higher uh false",
    "start": "839720",
    "end": "846199"
  },
  {
    "text": "positive rate so they were marked as being at risk and they actually didn't",
    "start": "846199",
    "end": "851440"
  },
  {
    "text": "reoffend in the training data at at a higher rate than whites that algorithm was trained to optimize accuracy but",
    "start": "851440",
    "end": "857800"
  },
  {
    "text": "because of different base rates in the data this was a side effect so this this whole thing spurred a really interesting",
    "start": "857800",
    "end": "863880"
  },
  {
    "text": "conversation around fairness and how to define it and the upshot is that basically basically there's there's many",
    "start": "863880",
    "end": "870079"
  },
  {
    "text": "different Notions of what makes an algorithm fair and with most real world problems it's impossible to satisfy all",
    "start": "870079",
    "end": "876720"
  },
  {
    "text": "of them so it makes things tricky for data scientists and we actually need to consider what Notions of fairness matter",
    "start": "876720",
    "end": "884040"
  },
  {
    "text": "the most for our particular problem another example and I think marketing is a really interesting space because it it",
    "start": "884040",
    "end": "889959"
  },
  {
    "text": "relies a lot on demographics so an example of a situation to think about is if you're trying to predict who would",
    "start": "889959",
    "end": "896360"
  },
  {
    "text": "click on a data science job posting like an ad for a data science job the algorithm could look at a bunch of",
    "start": "896360",
    "end": "902720"
  },
  {
    "text": "browser data and say users who look at female type things online are less",
    "start": "902720",
    "end": "908480"
  },
  {
    "text": "likely to to click on that ad and end up making an algorithm that doesn't show it to any females it's a really strict",
    "start": "908480",
    "end": "915000"
  },
  {
    "text": "notion of fairness to say we need this to be shown to the same percentage of men and women that's obviously pretty",
    "start": "915000",
    "end": "921480"
  },
  {
    "text": "strict because there are more men that are interested in the ad and would click on the ad so so you the marketing",
    "start": "921480",
    "end": "928000"
  },
  {
    "text": "company would lose money but it's maybe realistic to aim for something else like we just want the same true positive rate",
    "start": "928000",
    "end": "934199"
  },
  {
    "text": "so out of the people that are interested same percentage of men and percentage of women saw the ad for example so those",
    "start": "934199",
    "end": "941199"
  },
  {
    "text": "are the kinds of things um and and there's a lot more detail beneath that but um those are the kinds of different",
    "start": "941199",
    "end": "946560"
  },
  {
    "text": "Notions of fairness that I think you need to take into consideration when you're building an algorithm so we've",
    "start": "946560",
    "end": "953160"
  },
  {
    "text": "kind of dived right into into doing it from the algorithm and and I guess I'd like to see if we can differ",
    "start": "953160",
    "end": "958959"
  },
  {
    "text": "differentiate a little bit between what a a traditional job assessment process looks like and how Highview is",
    "start": "958959",
    "end": "964759"
  },
  {
    "text": "approaching it algorithmically at this point and and what are the what are the things that might be the same uh for",
    "start": "964759",
    "end": "970720"
  },
  {
    "text": "companies uh going from one to the other and what are some of the things that might change for them and how do they prepare for that sure so yeah a lot of",
    "start": "970720",
    "end": "977759"
  },
  {
    "text": "people are familiar with this traditional job assessment which is often like multiple choice tests and",
    "start": "977759",
    "end": "983160"
  },
  {
    "text": "they've been around for a long time they're they are the result of trying to make the process more consistent some of",
    "start": "983160",
    "end": "989360"
  },
  {
    "text": "the drawbacks are that they are they're closed ended so you have maybe multiple choice but none of those choices",
    "start": "989360",
    "end": "995399"
  },
  {
    "text": "describe you and they also can be kind of a bad candidate experience so",
    "start": "995399",
    "end": "1001360"
  },
  {
    "text": "companies care a lot about that like they want people to come in and have a good experience even if they didn't get the job they don't want to damage their",
    "start": "1001360",
    "end": "1007839"
  },
  {
    "text": "brand by having this awful experience so those assessments can be long and make",
    "start": "1007839",
    "end": "1014120"
  },
  {
    "text": "that that experience negative and they also give results like personality traits and the connection between",
    "start": "1014120",
    "end": "1021839"
  },
  {
    "text": "personality traits and actual job performance is loose or it's maybe kind of made up by a person so assuming you",
    "start": "1021839",
    "end": "1030839"
  },
  {
    "text": "know we want a salesperson to have these exact personality traits is sometimes not validated in our process we actually",
    "start": "1030839",
    "end": "1038400"
  },
  {
    "text": "you know like I said we train straight to Performance like I mentioned before we try to get objective performance",
    "start": "1038400",
    "end": "1044120"
  },
  {
    "text": "metrics and that could depend on the job what that what exactly that means so",
    "start": "1044120",
    "end": "1049240"
  },
  {
    "text": "like in the example of the salesman that you talked about there's a stereotype that you know people have about what is",
    "start": "1049240",
    "end": "1054520"
  },
  {
    "text": "a Salesman you know what's that Natural Born salesperson you know look like personality wise and that usually has a",
    "start": "1054520",
    "end": "1060240"
  },
  {
    "text": "picture that you know is our The Stereotype in our head are you essentially trying to take those stereotypes out of the process by",
    "start": "1060240",
    "end": "1067039"
  },
  {
    "text": "validating uh which of the metrics are applicable for that job versus what we can see from the data is not yeah sure",
    "start": "1067039",
    "end": "1073919"
  },
  {
    "text": "and I think sometimes that does happen that humans have an assumption about what is going to make the perfect person",
    "start": "1073919",
    "end": "1079640"
  },
  {
    "text": "for this job versus what is actually in the data and so I think a lot of times those Notions are overturned by looking",
    "start": "1079640",
    "end": "1086520"
  },
  {
    "text": "at actual performance data and one thing that that I'm thinking about here is you know it might be like you already",
    "start": "1086520",
    "end": "1092880"
  },
  {
    "text": "mentioned the example where you only have the one example of a of a female software engineer who who went through",
    "start": "1092880",
    "end": "1099520"
  },
  {
    "text": "and maybe uh performed one way or the or or another is it is it hard for you to",
    "start": "1099520",
    "end": "1105840"
  },
  {
    "text": "as you're thinking about you know being objective in in these ways um I imagine",
    "start": "1105840",
    "end": "1110960"
  },
  {
    "text": "in some cases it might be hard for you to actually get the data that you need to to be objective like maybe you know",
    "start": "1110960",
    "end": "1118400"
  },
  {
    "text": "when you're first working with a company you don't you don't know the performance information of how the people that",
    "start": "1118400",
    "end": "1124120"
  },
  {
    "text": "they've hired in the past have performed in this objective way how do you go about kind of establishing that data",
    "start": "1124120",
    "end": "1130039"
  },
  {
    "text": "that you need as the as the foundation yeah a lot of times that's a process so a lot of companies don't have really",
    "start": "1130039",
    "end": "1137200"
  },
  {
    "text": "strong performance metrics and and so we have a team of IO psychologists or",
    "start": "1137200",
    "end": "1143159"
  },
  {
    "text": "industrial organization industrial organizational psychologists who go in",
    "start": "1143159",
    "end": "1148200"
  },
  {
    "text": "from the very beginning and help our customers kind of get set up if they're existing customers they might already",
    "start": "1148200",
    "end": "1153600"
  },
  {
    "text": "have their their own interview and and their own questions but ideally we kind of start with them from the beginning",
    "start": "1153600",
    "end": "1160400"
  },
  {
    "text": "what is important in this job we do a whole job analysis right so what what do you want to measure what are you looking",
    "start": "1160400",
    "end": "1167200"
  },
  {
    "text": "at and are ioy ologists have a lot of experience with knowing which questions to ask to actually tease out that",
    "start": "1167200",
    "end": "1175039"
  },
  {
    "text": "information so it's kind of interesting like there's questions like tell me about yourself which are good warm-up",
    "start": "1175039",
    "end": "1180760"
  },
  {
    "text": "questions that don't actually differentiate people very well at all whereas questions that are about a",
    "start": "1180760",
    "end": "1186360"
  },
  {
    "text": "situation like what would you do if this happened you have this difficult customer and you know some detailed",
    "start": "1186360",
    "end": "1192480"
  },
  {
    "text": "scenario how would you act in that situation those those questions tend to be better at differentiating top and",
    "start": "1192480",
    "end": "1199240"
  },
  {
    "text": "bottom performers so the hope is we go in from the beginning and kind of design",
    "start": "1199240",
    "end": "1204880"
  },
  {
    "text": "the interview we design the process of you know how we're going to collect performance data as you guys know",
    "start": "1204880",
    "end": "1210520"
  },
  {
    "text": "machine learning algorithms do rely on our training data being kind of Representative of who's coming in the",
    "start": "1210520",
    "end": "1216919"
  },
  {
    "text": "funnel so we want to see a distribution of people sometimes gathering enough data is a challenge though so we have",
    "start": "1216919",
    "end": "1224600"
  },
  {
    "text": "continuous monitoring of our algorithms I can say a little bit more about that after we release an algorithm we're",
    "start": "1224600",
    "end": "1231320"
  },
  {
    "text": "we're always watching for how it scores different groups of people and making sure that it's not treating different",
    "start": "1231320",
    "end": "1237919"
  },
  {
    "text": "groups of people in a statistically significantly different way that makes sense that that was something Chris I",
    "start": "1237919",
    "end": "1244159"
  },
  {
    "text": "know we we talked about in our last news updates thing is um you know Google recommending through their their AI uh",
    "start": "1244159",
    "end": "1251159"
  },
  {
    "text": "forget what they called it AI guidelines um to always be continuously monitoring for those uh those biases and everything",
    "start": "1251159",
    "end": "1258320"
  },
  {
    "text": "yep yeah so for us I mean I mentioned before you know when I when I've done research on fairness and Ai and bias and",
    "start": "1258320",
    "end": "1265360"
  },
  {
    "text": "AI there's a lot of problems that are really difficult to solve because the features that that you're looking at the",
    "start": "1265360",
    "end": "1270960"
  },
  {
    "text": "inputs to your model they actually do matter for the thing you're trying to predict have different base rates in the",
    "start": "1270960",
    "end": "1277320"
  },
  {
    "text": "data so an example would be like if you want to predict who should be given a loan or not you need to look at credit",
    "start": "1277320",
    "end": "1285080"
  },
  {
    "text": "score and income but credit score have different and income have different distributions among different age race",
    "start": "1285080",
    "end": "1292000"
  },
  {
    "text": "gender groups so it's really hard to get away from that coming into your model in",
    "start": "1292000",
    "end": "1298960"
  },
  {
    "text": "a way we're really lucky because we are only looking at this job interview we don't do any kind of facial recognition",
    "start": "1298960",
    "end": "1305600"
  },
  {
    "text": "we don't find out who this person is and try to like scrape the internet for more information about them we're not",
    "start": "1305600",
    "end": "1312240"
  },
  {
    "text": "throwing in a bunch of data that we don't understand we know exactly what we're dealing with and the way we take",
    "start": "1312240",
    "end": "1318919"
  },
  {
    "text": "our video interview data and structure it is intentionally made to kind of",
    "start": "1318919",
    "end": "1324919"
  },
  {
    "text": "obscure some of the things that we don't want to know like we don't want to know your age race gender attractiveness we",
    "start": "1324919",
    "end": "1331000"
  },
  {
    "text": "want to know the content of what you said how you said it like tone of voice pauses things like that and your facial",
    "start": "1331000",
    "end": "1338400"
  },
  {
    "text": "expressions so those are kind of the three types of features we pull out and structure so we're we're already kind of",
    "start": "1338400",
    "end": "1345520"
  },
  {
    "text": "blinding the algorithm to demographic trait but one thing to be aware of is that you",
    "start": "1345520",
    "end": "1351000"
  },
  {
    "text": "know if there's bias in the training data sometimes those traits can leak through somehow so for example maybe you",
    "start": "1351000",
    "end": "1357960"
  },
  {
    "text": "have an algorithm that was trained to be sexist and it will notice some little difference in how men and women speak in",
    "start": "1357960",
    "end": "1365240"
  },
  {
    "text": "the data set so if that's the case this this continuous monitoring is really important to see how the algorithm is",
    "start": "1365240",
    "end": "1372679"
  },
  {
    "text": "behaving in the wild and if it does have any issues like it's scoring men and women differently we can go back and say",
    "start": "1372679",
    "end": "1379640"
  },
  {
    "text": "what are the features that are even telling the algorithm who's a man and who's a woman and then remove some of",
    "start": "1379640",
    "end": "1384960"
  },
  {
    "text": "those features so we'll do a mitigation process we are in the situation where we have a lot of features so we can afford",
    "start": "1384960",
    "end": "1390559"
  },
  {
    "text": "to throw some out if they're contributing to bias we simply remove them in doing that we might lose a",
    "start": "1390559",
    "end": "1396320"
  },
  {
    "text": "little bit of predictive power but we mitigate that adverse impact we're also Lucky in the sense that our our rules",
    "start": "1396320",
    "end": "1403679"
  },
  {
    "text": "are very well defined by the EOC or the equal equal employment opportunity",
    "start": "1403679",
    "end": "1410039"
  },
  {
    "text": "commission so there's federal laws about how assessments can need to behave and",
    "start": "1410039",
    "end": "1415960"
  },
  {
    "text": "and so we we follow those very closely and basically uh the rules say that",
    "start": "1415960",
    "end": "1421360"
  },
  {
    "text": "whatever if you have some kind of a cut off like people who score Above This score continue on to the next steps and",
    "start": "1421360",
    "end": "1427279"
  },
  {
    "text": "if you score below you're out of the running at that cut off no group can be scoring less than 80% or 4 fths of the",
    "start": "1427279",
    "end": "1436000"
  },
  {
    "text": "top scoring group so we have to follow those those rules that's us law and",
    "start": "1436000",
    "end": "1442320"
  },
  {
    "text": "making sure that our algorithms are not treating people differently and if we ever see anything you know we can go through this mitigation",
    "start": "1442320",
    "end": "1448799"
  },
  {
    "text": "process okay so coming back out of break I have a question for you Lindsay what",
    "start": "1448799",
    "end": "1454400"
  },
  {
    "text": "types of things cannot be covered well uh algorithmically and you know uh",
    "start": "1454400",
    "end": "1460559"
  },
  {
    "text": "starting with that and then kind of where do where do humans fit into the equation you noted at the at the",
    "start": "1460559",
    "end": "1465799"
  },
  {
    "text": "beginning that you thought humans would be in the equation for a while to go for a long time potentially and I'd like to",
    "start": "1465799",
    "end": "1472279"
  },
  {
    "text": "understand kind of where they fit in and and how the human and the algorithm work together yeah so definitely we're not",
    "start": "1472279",
    "end": "1478679"
  },
  {
    "text": "taking humans out of the loop anytime soon I always kind of laugh when I try to talk to Siri and and she does a",
    "start": "1478679",
    "end": "1485880"
  },
  {
    "text": "terrible job of understanding what I'm saying and I think oh my God we're worried about these robots taking over",
    "start": "1485880",
    "end": "1493760"
  },
  {
    "text": "um there's still so many things that humans are a lot better at I think the important things that AI will be taking",
    "start": "1493760",
    "end": "1499840"
  },
  {
    "text": "over are the mundane boring things that AI can do well while humans still really",
    "start": "1499840",
    "end": "1505720"
  },
  {
    "text": "need to be a part of making personal connections making final decisions and and taking in other information that",
    "start": "1505720",
    "end": "1512919"
  },
  {
    "text": "might not be available to the AI for hiring that does you know on the other side of the coin mean that bias will",
    "start": "1512919",
    "end": "1520559"
  },
  {
    "text": "still be a part of hiring but we found that even removing bias from a chunk of",
    "start": "1520559",
    "end": "1525760"
  },
  {
    "text": "that hiring funnel can help people get through to later stages that they they might not have originally we've had you",
    "start": "1525760",
    "end": "1532600"
  },
  {
    "text": "know we've had um customers say they've increased their diversity by 16% or give",
    "start": "1532600",
    "end": "1538080"
  },
  {
    "text": "us these great metrics around you know kind of if this initial stage of the funnel is open to more people they tend",
    "start": "1538080",
    "end": "1544960"
  },
  {
    "text": "to get further along in the funnel so definitely for the slice that AI is taking over um we we hope to remove that",
    "start": "1544960",
    "end": "1553159"
  },
  {
    "text": "bias and one of the things you mentioned is kind of monitoring around fairness and I was wondering you know it seems",
    "start": "1553159",
    "end": "1559640"
  },
  {
    "text": "like you have to kind of develop a certain culture as data scientists and as a data science or AI team to really",
    "start": "1559640",
    "end": "1566640"
  },
  {
    "text": "make that like a core part of a goal on each one of your products to kind of",
    "start": "1566640",
    "end": "1572159"
  },
  {
    "text": "monitor for fairness and all of that I was wondering if you could kind of briefly talk about you know how how you",
    "start": "1572159",
    "end": "1578240"
  },
  {
    "text": "went about developing that culture on your team and you know maybe make some recommendations for those out there that",
    "start": "1578240",
    "end": "1584080"
  },
  {
    "text": "are kind of thinking about oh well this is something I'd really like to do on our team but maybe don't know where to",
    "start": "1584080",
    "end": "1589279"
  },
  {
    "text": "get started or or how to develop that culture yeah definitely I think for us a",
    "start": "1589279",
    "end": "1594679"
  },
  {
    "text": "lot of it came from our IO psychology team and being in the assessment space so starting from there we kind of had",
    "start": "1594679",
    "end": "1601159"
  },
  {
    "text": "you know like I said we have laws around what what our assessment how our assessment scores people our particular",
    "start": "1601159",
    "end": "1606760"
  },
  {
    "text": "assessment happens to include AI we were coming into this space that the job assessment space that had been around",
    "start": "1606760",
    "end": "1612960"
  },
  {
    "text": "for decades so we got a lot of those those ideas started there and then it's",
    "start": "1612960",
    "end": "1618679"
  },
  {
    "text": "kind of blossomed more and more as we've studied there's a lot of academic study going on around this and we and we",
    "start": "1618679",
    "end": "1625559"
  },
  {
    "text": "collaborate pretty closely with some researchers here at the University of Utah who study algorithmic fairness like",
    "start": "1625559",
    "end": "1631679"
  },
  {
    "text": "I said it's you know what constitutes fair is not well defined so it's usually something that needs to be discussed and",
    "start": "1631679",
    "end": "1637720"
  },
  {
    "text": "refined for every individual problem I would suggest a great place to start IBM",
    "start": "1637720",
    "end": "1643559"
  },
  {
    "text": "just released um it's called AI fairness 360 you can go on their website just play I I played with it a little bit",
    "start": "1643559",
    "end": "1650200"
  },
  {
    "text": "with just some kaggle data and they show you know a lot of a lot of these metrics",
    "start": "1650200",
    "end": "1655640"
  },
  {
    "text": "that I talked about you know these kind of definitions of fairness and you can kind of see how um those things are",
    "start": "1655640",
    "end": "1661120"
  },
  {
    "text": "related to each other and how you can possibly mitigate bias another recommendation I have just to kind of",
    "start": "1661120",
    "end": "1667880"
  },
  {
    "text": "illustrate the concept is uh Google did some research I think if you just if you",
    "start": "1667880",
    "end": "1673000"
  },
  {
    "text": "look for attacking discrimination with smarter machine learning there's an article with with an interactive portion",
    "start": "1673000",
    "end": "1680480"
  },
  {
    "text": "where you can play with this fake data where it's credit score and um you're trying to predict who would repay a loan",
    "start": "1680480",
    "end": "1687080"
  },
  {
    "text": "and this is something I mentioned earlier but it's a great thing to play with and kind of see how there's",
    "start": "1687080",
    "end": "1692559"
  },
  {
    "text": "trade-offs so there's in real world situations there's really not one way to",
    "start": "1692559",
    "end": "1698559"
  },
  {
    "text": "do things where you could satisfy all Notions of fairness so you're always dealing with these tradeoffs and I think",
    "start": "1698559",
    "end": "1704559"
  },
  {
    "text": "that's something that's good to look at and again this really varies from problem to problem depending on your",
    "start": "1704559",
    "end": "1709880"
  },
  {
    "text": "inputs and how different your base rates are and how much you rely on inputs with",
    "start": "1709880",
    "end": "1715000"
  },
  {
    "text": "different base rates to predict your outcome so you know keeping things practical because this is is practical",
    "start": "1715000",
    "end": "1721399"
  },
  {
    "text": "AI I'm finding all of this really really fascinating and I was wondering if you could just kind of walk through so do",
    "start": "1721399",
    "end": "1727279"
  },
  {
    "text": "you establish like maybe based on looking at some of this Google work or or IBM work kind of figure out some",
    "start": "1727279",
    "end": "1734960"
  },
  {
    "text": "metrics that at least make sense to track first and how are you tracking them so you're",
    "start": "1734960",
    "end": "1740000"
  },
  {
    "text": "you're making predictions with your your model and then are you are you running those metrics on the on the predictions",
    "start": "1740000",
    "end": "1746840"
  },
  {
    "text": "are you running them kind of on the the training data that you're uh that you're",
    "start": "1746840",
    "end": "1752320"
  },
  {
    "text": "feeding in what exactly are you you monitoring and what's kind of the process like you put the metrics in",
    "start": "1752320",
    "end": "1758080"
  },
  {
    "text": "place and then you kind of send notifications to people to to review them and who reviews them I'm kind of",
    "start": "1758080",
    "end": "1763880"
  },
  {
    "text": "interested in those sorts of details yeah so like I said the notion of fairness that we look at are tightly",
    "start": "1763880",
    "end": "1770080"
  },
  {
    "text": "tied to law like employment law but we also do we look at other things as well and we're always kind of interested in",
    "start": "1770080",
    "end": "1776080"
  },
  {
    "text": "being ahead of it I think it's kind of common that people assume data scientists don't care about this and we",
    "start": "1776080",
    "end": "1782200"
  },
  {
    "text": "really given it a lot of thought and we're always looking for different ways of looking at it and seeing how we can",
    "start": "1782200",
    "end": "1788159"
  },
  {
    "text": "improve certain Notions but again we kind of always come back to the",
    "start": "1788159",
    "end": "1793399"
  },
  {
    "text": "regulations um in the employment space as being kind of our most important um base to cover so I mentioned the 4 fths",
    "start": "1793399",
    "end": "1801120"
  },
  {
    "text": "rule or the 80% rule for us which is something we closely Monitor and you and like you did ask before about training",
    "start": "1801120",
    "end": "1808320"
  },
  {
    "text": "data versus kind of how the algorithm is behaving in the wild so we're always watching that like here's the customer's",
    "start": "1808320",
    "end": "1815240"
  },
  {
    "text": "cut off score they are watching job interviews for everyone who scored above this and maybe first or maybe they're",
    "start": "1815240",
    "end": "1822039"
  },
  {
    "text": "not watching the lower scorer the lower scorers at all so what what are those",
    "start": "1822039",
    "end": "1828039"
  },
  {
    "text": "ratios at that cut off you know um how are men scoring compared to women how are the different races scoring if we",
    "start": "1828039",
    "end": "1834679"
  },
  {
    "text": "ever have an issue there continuous monitoring is really important because we start off you know with a training",
    "start": "1834679",
    "end": "1840360"
  },
  {
    "text": "set of maybe hundreds and hundreds of interviews and there wasn't a lot of uh",
    "start": "1840360",
    "end": "1846240"
  },
  {
    "text": "diversity possibly there's there was groups that were small and it was kind of hard to see with all the noise how",
    "start": "1846240",
    "end": "1852519"
  },
  {
    "text": "the how the algorithm is treating those groups so watching how the algorithm actually behaves in the wild is very",
    "start": "1852519",
    "end": "1858039"
  },
  {
    "text": "important as well so we're we're always watching those numbers and being proactive about coming to our customers",
    "start": "1858039",
    "end": "1865360"
  },
  {
    "text": "and saying hey we need to mitigate your algorithm obviously we also mitigate at the beginning but if we ever see that",
    "start": "1865360",
    "end": "1871679"
  },
  {
    "text": "that we need to mitigate after the algorithm's been out in the wild for a while we will do that have you seen kind",
    "start": "1871679",
    "end": "1878120"
  },
  {
    "text": "of have have certain things surprised you as you've done this sort of monitoring like biases or things pop up",
    "start": "1878120",
    "end": "1884200"
  },
  {
    "text": "where you you thought you did a really good job preparing the algorithm but it turns out like you didn't in some way or",
    "start": "1884200",
    "end": "1890519"
  },
  {
    "text": "another yeah most of that probably just comes if if there's any bias that comes",
    "start": "1890519",
    "end": "1895679"
  },
  {
    "text": "in later on um a lot of that is because your training group just wasn't very",
    "start": "1895679",
    "end": "1902360"
  },
  {
    "text": "diverse so that is something that you know we see when we have uh maybe there",
    "start": "1902360",
    "end": "1907960"
  },
  {
    "text": "were very few people of color in this data set or maybe there are very few women so like I said it was really hard",
    "start": "1907960",
    "end": "1913639"
  },
  {
    "text": "to tell with just the training data that there was some some Fe te that was",
    "start": "1913639",
    "end": "1918880"
  },
  {
    "text": "allowing the the algorithm to mimic bias and the data but it becomes apparent",
    "start": "1918880",
    "end": "1924039"
  },
  {
    "text": "later on and and we have seen that usually usually not too badly I mean usually our we're pretty on top of our",
    "start": "1924039",
    "end": "1929720"
  },
  {
    "text": "monitoring we don't see anything too drastically different than we expected cool yeah so do you see I I'm thinking",
    "start": "1929720",
    "end": "1937720"
  },
  {
    "text": "you know maybe we can transition a little bit here to kind of the machine learning and AI community in general",
    "start": "1937720",
    "end": "1944760"
  },
  {
    "text": "maybe out outside of hiring are there things in like Trends in the community",
    "start": "1944760",
    "end": "1950919"
  },
  {
    "text": "around how we're developing AI that that concern you around like the the topic of",
    "start": "1950919",
    "end": "1956120"
  },
  {
    "text": "fairness and then are there maybe other things that are encouraging maybe these these uh these uh projects from IBM and",
    "start": "1956120",
    "end": "1963960"
  },
  {
    "text": "Google for example yeah I think the conversation like IBM's uh 360 toolkit",
    "start": "1963960",
    "end": "1971200"
  },
  {
    "text": "is an awesome example of how this is kind of coming into the conversation and people are talking about it for the last",
    "start": "1971200",
    "end": "1977440"
  },
  {
    "text": "few years years I've sometimes been frustrated by the alarmism that goes on in the media kind of calling out",
    "start": "1977440",
    "end": "1985000"
  },
  {
    "text": "situations where data scientists did behave really irresponsibly or just absolutely didn't think about",
    "start": "1985000",
    "end": "1991639"
  },
  {
    "text": "repercussions and it's hard as a as a data scientists who does care about this and works on it a lot to not get a",
    "start": "1991639",
    "end": "1997679"
  },
  {
    "text": "little defensive when you're stereotyped but I think there are some legitimate concerns um and there are a lot of books",
    "start": "1997679",
    "end": "2004200"
  },
  {
    "text": "and articles about algorithms gone wrong and kind of showcasing these kinds of examples I think it's good that that",
    "start": "2004200",
    "end": "2011240"
  },
  {
    "text": "conversation is out there in some ways it it scares people and they kind of make assumptions that all algorithms are",
    "start": "2011240",
    "end": "2018039"
  },
  {
    "text": "bad which can be frustrating from the hiring point of view you know I talked about how broken hiring is and and I",
    "start": "2018039",
    "end": "2025120"
  },
  {
    "text": "really feel like we've made huge improvements where with an algorithm we can actually look inside the algorithm",
    "start": "2025120",
    "end": "2031519"
  },
  {
    "text": "and say okay what features are causing this bias you know you really quantitatively see how the algorithm is",
    "start": "2031519",
    "end": "2037799"
  },
  {
    "text": "treating different people where it's a lot harder to do that with human beings human beings don't even know why they",
    "start": "2037799",
    "end": "2043600"
  },
  {
    "text": "made the decisions they made you can't open up their brain and figure out oh yeah you're a little racist and that's why you're doing that let's just tweak",
    "start": "2043600",
    "end": "2049760"
  },
  {
    "text": "your brain and and account for that so so we have like these tools that are",
    "start": "2049760",
    "end": "2054919"
  },
  {
    "text": "amazing but you know like any powerful tool they could be good or bad and so I",
    "start": "2054919",
    "end": "2060720"
  },
  {
    "text": "think it's um we're reaching a point where people are having these really important conversations about using them",
    "start": "2060720",
    "end": "2066240"
  },
  {
    "text": "responsibly talking about bias in these ways we we've had various conversations uh across different episodes with with",
    "start": "2066240",
    "end": "2072919"
  },
  {
    "text": "people doing all sorts of different types of work and and it's it really seems that you have a great process now",
    "start": "2072919",
    "end": "2079158"
  },
  {
    "text": "on how you're approaching it from with the monitoring and with the feature selection and trying to make sure your",
    "start": "2079159",
    "end": "2084358"
  },
  {
    "text": "data fairly represents where you want to go in a broader sense Beyond just the topic of hiring we have so many people",
    "start": "2084359",
    "end": "2090560"
  },
  {
    "text": "that listen that are faced with similar challenges do you have any any uh more generalized uh recommendations that you",
    "start": "2090560",
    "end": "2097400"
  },
  {
    "text": "would make to a data science team that is trying to get the bias out of their own situ out of their own circumstances",
    "start": "2097400",
    "end": "2104440"
  },
  {
    "text": "um or or something where rules of thumb that you utilize on that that is kind of broad-based and simple for them to",
    "start": "2104440",
    "end": "2110079"
  },
  {
    "text": "follow yeah I know I've seen like for example like checklists come out I don't know if those are useful or anything",
    "start": "2110079",
    "end": "2115960"
  },
  {
    "text": "around like you know your data and your process and all of that yeah I think like I said it's it's it's hard to",
    "start": "2115960",
    "end": "2122680"
  },
  {
    "text": "Define what fair is and and I think you have to kind of sit down and and have a conversation with a lot of input about",
    "start": "2122680",
    "end": "2130160"
  },
  {
    "text": "you know what you care about in this problem and and and being transparent about it you know are are we if if",
    "start": "2130160",
    "end": "2137920"
  },
  {
    "text": "you're not just trying to get a higher prediction accuracy be clear that we",
    "start": "2137920",
    "end": "2143160"
  },
  {
    "text": "care about these Notions of fairness and um and this is what we're doing um this is what we're measuring and this is what",
    "start": "2143160",
    "end": "2149240"
  },
  {
    "text": "we're doing to mitigate that's something that's just been really useful for us because we were doing this for a long time and not really talking that much",
    "start": "2149240",
    "end": "2155800"
  },
  {
    "text": "about it we were getting criticized ized and you know when people assumed that we",
    "start": "2155800",
    "end": "2161599"
  },
  {
    "text": "were being careless so I think now this conversation started and people are people are being really transparent to",
    "start": "2161599",
    "end": "2168079"
  },
  {
    "text": "be really open about it and say hey what you know what we're trying to do is difficult these are the Notions of",
    "start": "2168079",
    "end": "2173119"
  },
  {
    "text": "fairness that we care about and that we're trying to optimize and we're open to have conversations about that and",
    "start": "2173119",
    "end": "2178520"
  },
  {
    "text": "we're open to you know changing that I think everybody understands that you",
    "start": "2178520",
    "end": "2183880"
  },
  {
    "text": "know machine learning can be very powerful and if there isn't clear answers we want to have a conversation",
    "start": "2183880",
    "end": "2190079"
  },
  {
    "text": "uh about what we're trying to do with it one of the things that that we've noted before is you know we're still in the",
    "start": "2190079",
    "end": "2195280"
  },
  {
    "text": "very early days uh in data science you know especially if you compare it to to software engineering who has been",
    "start": "2195280",
    "end": "2201240"
  },
  {
    "text": "maturing for for decades now and I'm kind of talking about the AI space specifically but do you think that this",
    "start": "2201240",
    "end": "2207160"
  },
  {
    "text": "period right now where we're all grappling with bias is a kind of growing pains that we're going through or do you",
    "start": "2207160",
    "end": "2212760"
  },
  {
    "text": "think this is going to be inherent from now on is it always something that we're going to contend with or do you think",
    "start": "2212760",
    "end": "2217839"
  },
  {
    "text": "we'll have better tools going forward to tackle it I think kind of both I mean I do think it's a growing pain I think in",
    "start": "2217839",
    "end": "2225119"
  },
  {
    "text": "5 to 10 years way more data scientists will be well-versed in fairness and and",
    "start": "2225119",
    "end": "2231000"
  },
  {
    "text": "understand that it's a part of their job and it's it's something they need to think about but at the end of the day",
    "start": "2231000",
    "end": "2236119"
  },
  {
    "text": "it's like any complex topic there's always going to be different opinions so because there's not one clear answer I",
    "start": "2236119",
    "end": "2243319"
  },
  {
    "text": "think there will always be debate about what an algorithm should be doing and this is a great example with the compass",
    "start": "2243319",
    "end": "2249200"
  },
  {
    "text": "model the recidivism model that I mentioned at the end of the day there's no agreed upon way it should behave",
    "start": "2249200",
    "end": "2255680"
  },
  {
    "text": "because different Notions of fairness to satisfy them you sacrifice another and",
    "start": "2255680",
    "end": "2261480"
  },
  {
    "text": "there will always be people that have their opinions about what the most important Notions are so I think it it it will be something that's",
    "start": "2261480",
    "end": "2268040"
  },
  {
    "text": "controversial going forward uh I know that I have definitely appreciated your",
    "start": "2268040",
    "end": "2273800"
  },
  {
    "text": "perspective on this Lindsay it's been super enlightening to me so thank you you so much for being on the show are",
    "start": "2273800",
    "end": "2280200"
  },
  {
    "text": "there any uh uh places where you'd like to point to uh people to to to find you online or or certain resources or or",
    "start": "2280200",
    "end": "2287280"
  },
  {
    "text": "blog posts that you'd like to highlight sure I'm on mostly just on LinkedIn",
    "start": "2287280",
    "end": "2292400"
  },
  {
    "text": "Lindsay with an EU Zula z l o a g a that's where I'm probably the most",
    "start": "2292400",
    "end": "2297800"
  },
  {
    "text": "active awesome well thank you so much for uh for uh being on the show and I",
    "start": "2297800",
    "end": "2304079"
  },
  {
    "text": "know I'm really looking forward to seeing more of the the great content that you put out and and uh the great",
    "start": "2304079",
    "end": "2309560"
  },
  {
    "text": "work that that you and your team are doing so thank you so much thanks for having me thanks a",
    "start": "2309560",
    "end": "2315599"
  },
  {
    "text": "lot all right thank you for tuning into to this episode of practical AI if you enjoyed the show do us a favor go on",
    "start": "2315599",
    "end": "2321640"
  },
  {
    "text": "iTunes give us a rating go in your podcast app and favored it if you are on Twitter or social network share a link",
    "start": "2321640",
    "end": "2327240"
  },
  {
    "text": "with a friend whatever you got to do share the show with a friend if you enjoyed it and band with for change log is provided by fastly learn more at",
    "start": "2327240",
    "end": "2333839"
  },
  {
    "text": "fastly.com and we catch our ears before our users do hear change log because CU of robbar check them out at rar.com",
    "start": "2333839",
    "end": "2340079"
  },
  {
    "text": "changelog and we're hosted on Leno Cloud servers head to lin.com changelog check",
    "start": "2340079",
    "end": "2345720"
  },
  {
    "text": "them out support this show this episode is hosted by Daniel whack and Chris Benson editing is done by Tim Smith the",
    "start": "2345720",
    "end": "2352839"
  },
  {
    "text": "music is by breakmaster cylinder and you can find more shows just like this at changel law.com when you go there pop in",
    "start": "2352839",
    "end": "2359760"
  },
  {
    "text": "your email address get our weekly email keeping you up to date with the news and podcast for developers in your inbox",
    "start": "2359760",
    "end": "2366200"
  },
  {
    "text": "every single week thanks for tuning in we'll see you next [Music]",
    "start": "2366200",
    "end": "2373209"
  },
  {
    "text": "week I'm Nick ni this is kall and I'm Rachel white We're panelists on JS party",
    "start": "2374880",
    "end": "2380640"
  },
  {
    "text": "a community celebration of JavaScript and the web every Thursday at noon Central a few of us get together and",
    "start": "2380640",
    "end": "2385920"
  },
  {
    "text": "chat about JavaScript node and topics ranging from practical accessibility to weird web apis you can just eval the the",
    "start": "2385920",
    "end": "2393839"
  },
  {
    "text": "text that you're given and then and that's Bas I think that's basically what it's doing could go wrong yeah exactly",
    "start": "2393839",
    "end": "2399560"
  },
  {
    "text": "this is not uh legal advice to eval text as it comes in join us live on Thursdays",
    "start": "2399560",
    "end": "2405119"
  },
  {
    "text": "at noon Central listen and slack with us in real time or wait for the recording to hit new episodes come out each Friday",
    "start": "2405119",
    "end": "2411000"
  },
  {
    "text": "find the show at Chang log.com sljs party or wherever you listen to",
    "start": "2411000",
    "end": "2416470"
  },
  {
    "text": "[Music]",
    "start": "2416470",
    "end": "2423139"
  },
  {
    "text": "podcasts I'm Tim Smith and my show away from keyboard explores The Human Side of creative work you'll hear stories",
    "start": "2424200",
    "end": "2431119"
  },
  {
    "text": "sometimes deeply personal about the triumphs and struggles of doing what you love I got really depressed last year",
    "start": "2431119",
    "end": "2438200"
  },
  {
    "text": "and the reason it was so hard is because basically everything culminated at once all these things I'd been avoiding all",
    "start": "2438200",
    "end": "2445160"
  },
  {
    "text": "these things I'd swept under the rug they all came out at once new episodes Premiere every other Wednesday find the",
    "start": "2445160",
    "end": "2452160"
  },
  {
    "text": "show at changel log.com AFK or wherever you listen to podcasts",
    "start": "2452160",
    "end": "2458870"
  },
  {
    "text": "[Music] w",
    "start": "2458870",
    "end": "2465560"
  }
]
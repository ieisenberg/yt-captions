[
  {
    "text": "[Music]",
    "start": "330",
    "end": "4089"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspire to or are",
    "start": "7160",
    "end": "13759"
  },
  {
    "text": "curious how AI related Technologies are changing the world this is the show for you thank you to our partners at fastly",
    "start": "13759",
    "end": "21160"
  },
  {
    "text": "for shipping all of our pods super fast to wherever you listen check them out at",
    "start": "21160",
    "end": "26240"
  },
  {
    "text": "fast.com and to our friends at fly deploy your app and database close to",
    "start": "26240",
    "end": "31359"
  },
  {
    "text": "your users no Ops required learn more at",
    "start": "31359",
    "end": "37000"
  },
  {
    "text": "[Music]",
    "start": "37140",
    "end": "42440"
  },
  {
    "text": "fly.io welcome to another edition of the Practical AI podcast my name is Chris Benson I am your co-host today normally",
    "start": "42440",
    "end": "49520"
  },
  {
    "text": "we would have Daniel whack joining us uh but Daniel uh has just gotten off a plane he flew halfway around the world",
    "start": "49520",
    "end": "56280"
  },
  {
    "text": "and we decided to give him a break from today uh I would I would uh he was more Lucid than I would be under the same",
    "start": "56280",
    "end": "63199"
  },
  {
    "text": "situation today I wanted to uh to Dive Right In we have a super cool topic it",
    "start": "63199",
    "end": "69880"
  },
  {
    "text": "is not dissimilar from some of the other General things we've been talking about but I have two guests today I'd like to",
    "start": "69880",
    "end": "76280"
  },
  {
    "text": "introduce uh verun who is the CEO and co-founder of codium and anel who is the",
    "start": "76280",
    "end": "81840"
  },
  {
    "text": "lead of their Enterprise and partnership uh welcome to the show guys thanks for",
    "start": "81840",
    "end": "87040"
  },
  {
    "text": "having us thanks for having us Chris hey you're you're welcome um really interested in learning more about codium",
    "start": "87040",
    "end": "94799"
  },
  {
    "text": "when Daniel line you guys up he's like Chris you got to he's send me this thing saying you got to look at this this is really cool and everything and I'm like",
    "start": "94799",
    "end": "100640"
  },
  {
    "text": "get I'm on the show he's like I'm already doing that so uh so really glad to have you guys on um and he's going to",
    "start": "100640",
    "end": "106360"
  },
  {
    "text": "be bumming that he missed the conversation because he was pretty excited about it and so I guess I wanted to before we even dive uh into codium",
    "start": "106360",
    "end": "114159"
  },
  {
    "text": "and the problems it's trying to solve and such if you guys could each just tell me a little bit about how you found",
    "start": "114159",
    "end": "120880"
  },
  {
    "text": "yourself arriving at this moment kind of a little bit about your background how",
    "start": "120880",
    "end": "125920"
  },
  {
    "text": "you got into Ai and how uh how this became the thing verun if you want to kick off and then on show afterwards so",
    "start": "125920",
    "end": "133239"
  },
  {
    "text": "maybe I can get started um actually starts in 2017 I started working at this",
    "start": "133239",
    "end": "139519"
  },
  {
    "text": "company called nuro that does autonomous Goods delivery so it's an AV company",
    "start": "139519",
    "end": "144560"
  },
  {
    "text": "there I sort of worked on large scale offline deep learning workloads so as you can imagine in autonomous vehicle",
    "start": "144560",
    "end": "150599"
  },
  {
    "text": "company needs to run large scale simulation they need to basically be able to test their ml models at scale",
    "start": "150599",
    "end": "156959"
  },
  {
    "text": "before they can actually deploy them on a c and sort of in 2021 I left nuro and",
    "start": "156959",
    "end": "162560"
  },
  {
    "text": "started EXA function which is the company that is building out this product codium and exf function started",
    "start": "162560",
    "end": "168120"
  },
  {
    "text": "out building GPU virtualization software so you can imagine for these large scale deep learning applications one big",
    "start": "168120",
    "end": "175159"
  },
  {
    "text": "problem is gpus are scarce they're expensive and also hard to program and",
    "start": "175159",
    "end": "180400"
  },
  {
    "text": "sort of what XA function started building was Solutions and software to make it so that applications that ran on",
    "start": "180400",
    "end": "187239"
  },
  {
    "text": "gpus were more effectively using the GPU hardware and we realized that our software with aif function was best",
    "start": "187239",
    "end": "194760"
  },
  {
    "text": "applicable to gener of AI Tech and started building out codium around a year ago very cool and and uh before I",
    "start": "194760",
    "end": "201760"
  },
  {
    "text": "dive in because you I have several questions for you but I want to give anchel a chance to introduce himself here go ahead anchel surprisingly my",
    "start": "201760",
    "end": "208480"
  },
  {
    "text": "story is actually quite similar I was was also working at neuro um so ver and I used to work together uh back in the",
    "start": "208480",
    "end": "213879"
  },
  {
    "text": "day I was not actually working on you know the the ml infrastructure side of things I was something that you know run had hands on on but you know I decided",
    "start": "213879",
    "end": "221519"
  },
  {
    "text": "to kind of also join the team at XA function and I think yeah as as R mentioned about you know a year ago I",
    "start": "221519",
    "end": "227480"
  },
  {
    "text": "think we noticed there was like I think three things kind of happened at the same time that we noticed that led us to",
    "start": "227480",
    "end": "233040"
  },
  {
    "text": "codium right I think the first one is that you know we're Engineers all of us here are engineers and you know we had",
    "start": "233040",
    "end": "239079"
  },
  {
    "text": "all tried you know the GitHub co-pilots and all these like you know cool AI tools for code in their beta and we're",
    "start": "239079",
    "end": "245680"
  },
  {
    "text": "like wow this is like absolutely going to be the future of software development but at the same time you know it's like",
    "start": "245680",
    "end": "250720"
  },
  {
    "text": "still scratching the surface of potentially everything that we do as Engineers so I think like number one I",
    "start": "250720",
    "end": "256440"
  },
  {
    "text": "think that we realized then number two was you know talking to a lot of our friends at you know these like bigger",
    "start": "256440",
    "end": "262560"
  },
  {
    "text": "companies or anything like that a lot of them were just saying like oh yeah it's cool I've tried it for my personal",
    "start": "262560",
    "end": "267600"
  },
  {
    "text": "project but I can't use it at work right right my work's not allowing me to use that so was like the second thing we heard and the third thing was exactly",
    "start": "267600",
    "end": "274520"
  },
  {
    "text": "what ver alluded to we were building like ml infrastructure at scale for really large workloads like when this",
    "start": "274520",
    "end": "280919"
  },
  {
    "text": "entire generative AI wave started coming we're like wow we're actually kind of sitting on the perfect infrastructure for this so I think all those three",
    "start": "280919",
    "end": "287440"
  },
  {
    "text": "things kind of combined uh together for us to be like do you know what let's build out an application ourselves and",
    "start": "287440",
    "end": "292759"
  },
  {
    "text": "build an application that you know we as Engineers are customers ourselves right and that that end up becoming codium as",
    "start": "292759",
    "end": "299199"
  },
  {
    "text": "you were getting into doing GPU software what was in general some of the challenges that you were seeing you know",
    "start": "299199",
    "end": "305759"
  },
  {
    "text": "with Nvidia has their various software supporting things like that clearly you saw that there was a need for something",
    "start": "305759",
    "end": "312000"
  },
  {
    "text": "beyond that can you talk a little bit about just the layout that you saw in the you know in the environment before",
    "start": "312000",
    "end": "318199"
  },
  {
    "text": "you got to to all the generative stuff and the fact that you had infrastructure what what positioned you for that and",
    "start": "318199",
    "end": "324000"
  },
  {
    "text": "what was the thing that you decided that you needed to address maybe I can take it a step back of why the GP workloads",
    "start": "324000",
    "end": "330039"
  },
  {
    "text": "are just a little bit annoying compared to CPU workloads okay one of the really sort of unique things about gpus um is",
    "start": "330039",
    "end": "337479"
  },
  {
    "text": "that unlike CPUs it's kind of tricky to virtualize like one common thing that we",
    "start": "337479",
    "end": "342600"
  },
  {
    "text": "have with CPUs is you can put a bunch of containers on a single VM and then you can kind of make use of the CPU compute",
    "start": "342600",
    "end": "349199"
  },
  {
    "text": "like effectively right you can basically dump 10 applications onto a CPU and it's perfectly fine for GPU it's a little bit",
    "start": "349199",
    "end": "355840"
  },
  {
    "text": "more messy because the GPU doesn't have a ton of memory so you can't just blowed up infinitely many models on there like",
    "start": "355840",
    "end": "362080"
  },
  {
    "text": "let's imagine you have a GPU with 16 gigs of memory and each of these models takes like 10 gigs you can't really even",
    "start": "362080",
    "end": "368080"
  },
  {
    "text": "put two applications on there so then that already becomes a big issue and that's sort of what a lot of these large",
    "start": "368080",
    "end": "374360"
  },
  {
    "text": "deep learning workloads were struggling with so when I was at nuro one big problem we had was we had around like",
    "start": "374360",
    "end": "381280"
  },
  {
    "text": "tens of models but we had these workloads that needed hundreds of gpus some of them even thousands of gpus and",
    "start": "381280",
    "end": "387759"
  },
  {
    "text": "we struggled to basically make it so that we were even able to use the hardware properly and then you know you",
    "start": "387759",
    "end": "393800"
  },
  {
    "text": "could imagine the complexity then Stacks with now we're in a state where companies have the trouble even getting",
    "start": "393800",
    "end": "398919"
  },
  {
    "text": "access to 10 gpus because of Nvidia sort of scarcity issues and then also the cost of a GPU is like not like a CPU",
    "start": "398919",
    "end": "405360"
  },
  {
    "text": "it's like significantly more expensive like the cost of a single h100 you know chip is well over 30 grand so these",
    "start": "405360",
    "end": "412000"
  },
  {
    "text": "aren't like very cheap chips so there's like a big need at the time to figure out how do we leverage the hardware",
    "start": "412000",
    "end": "417759"
  },
  {
    "text": "properly and sort of that's what we had to build software for and just to clarify for me was that why you were still at neuro or was that after you",
    "start": "417759",
    "end": "424560"
  },
  {
    "text": "started EXA function yeah so while I was in neuro we sort of worked through or I sort of led a team that sort of built",
    "start": "424560",
    "end": "431000"
  },
  {
    "text": "software that kind of fixed these problems but aif function was focused on generically how do we make sure deep",
    "start": "431000",
    "end": "437520"
  },
  {
    "text": "learning based applications could best leverage gpus um that's sort of what we started out building actually and then",
    "start": "437520",
    "end": "444280"
  },
  {
    "text": "codium came out from that actually gotcha tell me a little bit about as you have been right in the middle middle of",
    "start": "444280",
    "end": "449960"
  },
  {
    "text": "this progression just to frame it for a second if you look at the last you know",
    "start": "449960",
    "end": "455199"
  },
  {
    "text": "couple of years in particular and the pace of change has been so much and so",
    "start": "455199",
    "end": "460759"
  },
  {
    "text": "you were right there starting at nuro and then creating XA function seeing some of the challenges could you talk a",
    "start": "460759",
    "end": "467080"
  },
  {
    "text": "little bit about how the industry was evolving and changing as you were seeing",
    "start": "467080",
    "end": "472639"
  },
  {
    "text": "it um so that we can get a sense of kind of how you moved toward codium you know to give a little bit of the history",
    "start": "472639",
    "end": "478400"
  },
  {
    "text": "instead of just starting from where that is can you talk a little bit about you know the itches that you were scratching",
    "start": "478400",
    "end": "484440"
  },
  {
    "text": "and why it led that direction what did this AI industry look like to you yeah",
    "start": "484440",
    "end": "489879"
  },
  {
    "text": "so when we started like you can just imagine everything was a lot more smaller scale right the hyperscalers so",
    "start": "489879",
    "end": "495479"
  },
  {
    "text": "the cloud providers just didn't have nearly as much gpus like if you ask them like what fraction of cloud spend is GPU",
    "start": "495479",
    "end": "501360"
  },
  {
    "text": "spend it's probably like very small single digit percentage points maybe even less than that at the time so this",
    "start": "501360",
    "end": "507120"
  },
  {
    "text": "is like a very small workload for them when we sort of started both me and arel started at nuro in like 2018 but then",
    "start": "507120",
    "end": "513360"
  },
  {
    "text": "over time this grew a ton like we could see it from the training workloads these were no longer like even single node",
    "start": "513360",
    "end": "519200"
  },
  {
    "text": "training workloads like back in the day a single GPU node that had maybe like eight v100s or something was like",
    "start": "519200",
    "end": "525120"
  },
  {
    "text": "considered a lot of compute and suddenly now we were able to witness the fact that this was slowly becoming 8 a100",
    "start": "525120",
    "end": "530800"
  },
  {
    "text": "nodes and then more than eight of these nodes were necessary then even to train these models and similarly to prove out",
    "start": "530800",
    "end": "537240"
  },
  {
    "text": "that these models were capable like in an actual production setting you needed to run offline testing at massive scales",
    "start": "537240",
    "end": "545000"
  },
  {
    "text": "like on the order of like 5,000 to 10,000 t4s scales which is like kind of incredible in terms of raw flops so we",
    "start": "545000",
    "end": "551920"
  },
  {
    "text": "were able to see this hockey stick happen in front of us and then that's sort of what made us want to start XA",
    "start": "551920",
    "end": "558200"
  },
  {
    "text": "function in the first place we realized that there were going to be large deep learning workloads one interesting fact",
    "start": "558200",
    "end": "563640"
  },
  {
    "text": "is for us like for just the exif function GPU virtualization software that we ended up selling to Enterprises",
    "start": "563640",
    "end": "569440"
  },
  {
    "text": "we ended up managing over 10,000 gpus on gcp in a single gcp region so we ended",
    "start": "569440",
    "end": "576120"
  },
  {
    "text": "up managing more than 20% and we realized that that hey this was only going to keep growing like when we",
    "start": "576120",
    "end": "581839"
  },
  {
    "text": "talked to the cloud providers they were only going to keep growing the number of gpus and we realized I guess the interesting thing was in the future",
    "start": "581839",
    "end": "588040"
  },
  {
    "text": "generative AI was going to be potentially the largest GPU workload though that was the big thing we realized was gbd3 came out which was I",
    "start": "588040",
    "end": "595079"
  },
  {
    "text": "guess in in 2021 now gotcha so but you had already at that point Point were you already into EXA function had it already",
    "start": "595079",
    "end": "601560"
  },
  {
    "text": "started at that point yeah it had already started and we were sort of selling GPU virtualization software to",
    "start": "601560",
    "end": "606880"
  },
  {
    "text": "large autonomous vehicle and Robotics companies gotcha and so basically if I'm",
    "start": "606880",
    "end": "612160"
  },
  {
    "text": "understanding correctly the whole generative tsunami just kind of landed on you when you were already sitting in",
    "start": "612160",
    "end": "618800"
  },
  {
    "text": "that space doing GPU virtualization already so you're it you just managed to",
    "start": "618800",
    "end": "624040"
  },
  {
    "text": "land right in front of the wave it sounds like yeah so we started working on codium like maybe four or five months",
    "start": "624040",
    "end": "630399"
  },
  {
    "text": "ago before Chad GPT it was interesting just because we realized that an application like GitHub co-pilot was",
    "start": "630399",
    "end": "635959"
  },
  {
    "text": "going to be one of the largest GPU workloads period like I don't know if you've you've probably tried the product",
    "start": "635959",
    "end": "641120"
  },
  {
    "text": "out it's like every time you do a key press you're going out to the cloud and doing trillions of computations right so",
    "start": "641120",
    "end": "646279"
  },
  {
    "text": "it's like a massive workload and we had like as unal said the perfect infrastructure to basically run this at",
    "start": "646279",
    "end": "651639"
  },
  {
    "text": "enormous scale not to mention we were in love with the product from day one like we were early users of the product the",
    "start": "651639",
    "end": "656880"
  },
  {
    "text": "moment it came out in in 2021 very cool and so as generative is starting to take",
    "start": "656880",
    "end": "663320"
  },
  {
    "text": "off kind of with chat GPT hitting the world and really changing things quite rapidly you know I think people are",
    "start": "663320",
    "end": "670079"
  },
  {
    "text": "still shocked at how fast things have moved you had started codium already what kind of cnergy were you starting to",
    "start": "670079",
    "end": "676480"
  },
  {
    "text": "see there in terms of knowing that you have one of presumably many many gpts",
    "start": "676480",
    "end": "682880"
  },
  {
    "text": "coming and other similar generative models you had just gotten into codium can you talk a little bit about what",
    "start": "682880",
    "end": "689040"
  },
  {
    "text": "that was and what how what were you putting together in your in your minds to recognize the opportunity that it was",
    "start": "689040",
    "end": "696200"
  },
  {
    "text": "yeah so I think like one of the you know great things about entire chat gbt wave is that you know everyone was using it",
    "start": "696200",
    "end": "703320"
  },
  {
    "text": "this is a thing where like literally every individual is using Ai and so it helped us in general right you know like",
    "start": "703320",
    "end": "708839"
  },
  {
    "text": "a big wave like raises All Ships kind of thing you know it really helped us we weren't really going out and as telling",
    "start": "708839",
    "end": "713959"
  },
  {
    "text": "people like hey a tool like codium can help productivity because that was kind of just now is resumed by everybody like",
    "start": "713959",
    "end": "721079"
  },
  {
    "text": "oh yeah if I do any kind of you know knowledge work then there's potential for AI to help right and I think so from",
    "start": "721079",
    "end": "727639"
  },
  {
    "text": "that sense when this enre like you know chat GPT wave really came about that overall kind of just like helped us in",
    "start": "727639",
    "end": "732959"
  },
  {
    "text": "terms of convincing people to even try the product the other thing that we we recognize is that we were positioning",
    "start": "732959",
    "end": "739199"
  },
  {
    "text": "ourselves very specifically from the beginning right when it comes to code code is like actually a very interesting",
    "start": "739199",
    "end": "744839"
  },
  {
    "text": "modality right it's not like your standard you know chat GPT where you have a you know long context that you",
    "start": "744839",
    "end": "751440"
  },
  {
    "text": "know user puts in and then it produces context coming out right code is interesting in the sense that you know",
    "start": "751440",
    "end": "757000"
  },
  {
    "text": "as we mentioned it's an autocomplete that's like a passive AI rather than like an AI that you're actually instructing you know the model to do",
    "start": "757000",
    "end": "763959"
  },
  {
    "text": "something it's happening every keystroke so it has to be a relatively smaller model right you can't you have this like",
    "start": "763959",
    "end": "769480"
  },
  {
    "text": "you know hundreds of billions of parameter models uh being used has be relatively low latency and then code",
    "start": "769480",
    "end": "775320"
  },
  {
    "text": "itself is interesting right if you have your cursor in the middle of a code block the context both before and after your cursor really matters right it's",
    "start": "775320",
    "end": "781959"
  },
  {
    "text": "not just what comes before so like there's all these interesting kind of like situational kind of constraints",
    "start": "781959",
    "end": "787320"
  },
  {
    "text": "about code that you put all these things together and we realize that okay you know all these chat chpi waves and",
    "start": "787320",
    "end": "793240"
  },
  {
    "text": "conversational AIS are happening that's great but we're still not going to be like you know rolled over by that",
    "start": "793240",
    "end": "798800"
  },
  {
    "text": "because we're kind of focusing on a very specific application and modality of of LMS that was pretty unique in many",
    "start": "798800",
    "end": "806090"
  },
  {
    "text": "[Music] ways",
    "start": "806090",
    "end": "811120"
  },
  {
    "text": "[Music] could you take a moment as we're diving",
    "start": "819890",
    "end": "827680"
  },
  {
    "text": "into codium and generative Ai and its unique you know capabilities there and",
    "start": "827680",
    "end": "832800"
  },
  {
    "text": "just differentiate a little bit about for those you know so many people have tried co-pilot and so it's kind of",
    "start": "832800",
    "end": "839160"
  },
  {
    "text": "inevitable that you're going to get that comparison to some degree can you talk a little bit about what co-pilot's not",
    "start": "839160",
    "end": "845800"
  },
  {
    "text": "doing uh for generative AI or how you're approaching it that allows you to show",
    "start": "845800",
    "end": "851800"
  },
  {
    "text": "people this as a Better Way Forward from your perspective I mean we have tons of respect for for the Copa team I just",
    "start": "851800",
    "end": "857639"
  },
  {
    "text": "want to start with that right I mean as ver said we were all early users of it definitely not putting you into conflict with them that just as a starting point",
    "start": "857639",
    "end": "864120"
  },
  {
    "text": "for people absolutely yeah I think but the way we kind of view this and I kind of like alluded this earlier is that you",
    "start": "864120",
    "end": "870079"
  },
  {
    "text": "know writing brand new code right with autocomplete is really just one small",
    "start": "870079",
    "end": "875680"
  },
  {
    "text": "task that we do as Engineers right we refactor code we ask for help we write",
    "start": "875680",
    "end": "880959"
  },
  {
    "text": "documentation we do PR reviews and so kind of our general approach has always been let's try to build an AI toolkit",
    "start": "880959",
    "end": "887320"
  },
  {
    "text": "rather than an AI autocomplete tool got it so we can get more into this into the weeds here but like autocomplete is just",
    "start": "887320",
    "end": "892480"
  },
  {
    "text": "one of our functionalities that we provide right we provide like an in ide chat so things like chat GPT except",
    "start": "892480",
    "end": "898079"
  },
  {
    "text": "integrated with the ID e natural language search over your code base using like embeddings and Vector stores",
    "start": "898079",
    "end": "903480"
  },
  {
    "text": "in the background so like we're really trying to expand like how can we address like the entire software development life cycle so I think that's probably",
    "start": "903480",
    "end": "909680"
  },
  {
    "text": "the you know the most obvious difference with a tool like co-pilot from like an individual developer point of view but",
    "start": "909680",
    "end": "915720"
  },
  {
    "text": "then the other thing which really kind of builds off of all the infrastructure that ver was mentioning earlier is that we were already deploying you know ml",
    "start": "915720",
    "end": "923120"
  },
  {
    "text": "infrastructure in our you know previous customers private clouds like we already",
    "start": "923120",
    "end": "928319"
  },
  {
    "text": "had all this expt Taste of how can we take actual ml in for a deployer for a customer in a way that you know they can",
    "start": "928319",
    "end": "934079"
  },
  {
    "text": "fully trust the solution because you know we're not getting any of their data and so another really big differentiator",
    "start": "934079",
    "end": "939480"
  },
  {
    "text": "for us was like okay I think this might actually be a tool that enterprises can use confidently and safely because we",
    "start": "939480",
    "end": "945959"
  },
  {
    "text": "have the infrastructure to do the deployment in a manner that they they would they would be open to using so I",
    "start": "945959",
    "end": "951480"
  },
  {
    "text": "think that was like the other differentiator when it came specifically to Enterprises but we can dive more into that later no no that sounds good I want",
    "start": "951480",
    "end": "957680"
  },
  {
    "text": "you to connect one more thing for going from uh being able to deploy the infrastructure and helping your",
    "start": "957680",
    "end": "964199"
  },
  {
    "text": "customers in that way to codium as a tool what's the leap there that got you from one to the other how did you get",
    "start": "964199",
    "end": "970920"
  },
  {
    "text": "from infra focused to codium focused oh yeah we I think we had to do like a full",
    "start": "970920",
    "end": "976199"
  },
  {
    "text": "like 180 when we started we like went from a full like infr Service Company to like let's like create a product for",
    "start": "976199",
    "end": "981920"
  },
  {
    "text": "consumers right like it was a full 180 in terms of product a pivot yeah full some degrees a pivot because we knew that you know eventually okay we'll",
    "start": "981920",
    "end": "988639"
  },
  {
    "text": "deploy employ to customers vpcs that sound great but like if we're going to ship something to a customer we had to",
    "start": "988639",
    "end": "993759"
  },
  {
    "text": "be like super confident that it was a product that would work well right because we're getting no feedback from",
    "start": "993759",
    "end": "998920"
  },
  {
    "text": "their developers and so we actually first focused for the first like six or so months of codium just building out",
    "start": "998920",
    "end": "1004720"
  },
  {
    "text": "like an individual tier right any developer can go try it we can see how",
    "start": "1004720",
    "end": "1010079"
  },
  {
    "text": "they like it right try our new capabilities get feedback from an actual Community do all these like community building things that we hadn't really",
    "start": "1010079",
    "end": "1016120"
  },
  {
    "text": "done as like you know INF as a service company but that that was like a really huge Focus for us and you know we've",
    "start": "1016120",
    "end": "1021959"
  },
  {
    "text": "grown our actual codium uh individual plan to like over 100,000 you know active developers using us for like you",
    "start": "1021959",
    "end": "1028120"
  },
  {
    "text": "know many hours a day because you code for that long if you're a developer you know that's like plenty of feedback to",
    "start": "1028120",
    "end": "1034400"
  },
  {
    "text": "us right plenty of people actually using the tool telling us like yeah this is good this isn't good like oh you tried pushing a new model that's worse like",
    "start": "1034400",
    "end": "1040480"
  },
  {
    "text": "all those things we actually learned so that we can you know get a product that's good so that was like the I guess the intermediate period right really",
    "start": "1040480",
    "end": "1046880"
  },
  {
    "text": "learning from actual Developers is what is a good product and and what is not and I think that's like that's always",
    "start": "1046880",
    "end": "1052559"
  },
  {
    "text": "going to be a key kind of part of our our development cycle you're you're coming into this with this Rich knowledge in infrastructure for",
    "start": "1052559",
    "end": "1059400"
  },
  {
    "text": "customers that's a huge area of expertise it's an area of expertise that",
    "start": "1059400",
    "end": "1064440"
  },
  {
    "text": "um even though you moving forward into the kind of the codium era if you will you my words that is a skill set and",
    "start": "1064440",
    "end": "1070919"
  },
  {
    "text": "level of expertise that very few organizations have deeply that you would have had there how did that inform you",
    "start": "1070919",
    "end": "1078400"
  },
  {
    "text": "in terms terms of codium and differentiation against whether it be co-pilot or other tools that are out",
    "start": "1078400",
    "end": "1084000"
  },
  {
    "text": "there or just you know developers uh you know throwing things into chat GPT what did that background give you that gave",
    "start": "1084000",
    "end": "1091919"
  },
  {
    "text": "you that differentiation in the marketplace yeah so I think when we started the thing we started with is like no one cares if we have better",
    "start": "1091919",
    "end": "1098280"
  },
  {
    "text": "infrastructure once you're a product like if we have better infrastructure that's great but if that makes a a product that's the same no one should",
    "start": "1098280",
    "end": "1104919"
  },
  {
    "text": "care they just assume that you should yeah so what we started with is we set a very high bar for ourselves codium is an",
    "start": "1104919",
    "end": "1111600"
  },
  {
    "text": "entirely free product so like for the individual User it's something that they can install and use immediately for free",
    "start": "1111600",
    "end": "1117880"
  },
  {
    "text": "there are unlimited there's like no limits at all so like when it comes to autocomplete you can use it as much as",
    "start": "1117880",
    "end": "1123080"
  },
  {
    "text": "you want and this is by the way forced us to do things where infrastructure is as efficient as possible just to give",
    "start": "1123080",
    "end": "1129480"
  },
  {
    "text": "you a sense of the numbers we're talking about here we process over 10 billion tokens of code a day that might sound",
    "start": "1129480",
    "end": "1136520"
  },
  {
    "text": "like a large number that's like over a billion of code a day that we process for our own developers we're forced to",
    "start": "1136520",
    "end": "1142039"
  },
  {
    "text": "do this entirely for free and then on top of that we probably have one of the world's largest chat applications also",
    "start": "1142039",
    "end": "1147120"
  },
  {
    "text": "because it's in ide as well and all of this put together has allowed us to build a very very scalable piece of",
    "start": "1147120",
    "end": "1153679"
  },
  {
    "text": "infrastructure such that we are the largest users of our own product we are the largest users of our own product we",
    "start": "1153679",
    "end": "1159520"
  },
  {
    "text": "learn the most from our users and we can then take those learnings and deploy in a very cost-effective very efficient and",
    "start": "1159520",
    "end": "1166400"
  },
  {
    "text": "optimized way to our own Enterprise users it's one of those things where we forced oursel to learn a lot from an",
    "start": "1166400",
    "end": "1172480"
  },
  {
    "text": "individual plan and then take all those learnings and actually bring them over to the Enterprise and a lot of the",
    "start": "1172480",
    "end": "1177640"
  },
  {
    "text": "learnings we were only able to make because we place like very I would say like annoying infrastructure constraints",
    "start": "1177640",
    "end": "1183039"
  },
  {
    "text": "on ourselves by saying hey you guys got to do this entirely for free basically and we're committed to building codium",
    "start": "1183039",
    "end": "1188799"
  },
  {
    "text": "is going to be a free product forever actually the individual plan will always be free and it's one of those things where our users are just always like how",
    "start": "1188799",
    "end": "1195039"
  },
  {
    "text": "are these guys even doing it like what are they even doing to make this happen and most of our users by the way are users that have turned off of co-pilot",
    "start": "1195039",
    "end": "1201840"
  },
  {
    "text": "we have spent very little if not anything on marketing so it's just one of those things where our users are like",
    "start": "1201840",
    "end": "1207120"
  },
  {
    "text": "how do we make this free we take the approach of we think some of the best products in the world are free like products at Google right they're",
    "start": "1207120",
    "end": "1213200"
  },
  {
    "text": "entirely free Google doesn't tell you all the time that they have the best infrastructure but they do have the best infrastructure it just so happens to be",
    "start": "1213200",
    "end": "1219240"
  },
  {
    "text": "the case that that shows itself off in the best product and we could talk a little bit more about how we take our sort of focus on infrastructure and make",
    "start": "1219240",
    "end": "1225600"
  },
  {
    "text": "a much better Enterprise product as well but like that's the way we sort of look at it it's like how do we deliver",
    "start": "1225600",
    "end": "1230679"
  },
  {
    "text": "materially better experiences with our infrastructure and our users shouldn't care that we actually did that you've",
    "start": "1230679",
    "end": "1235880"
  },
  {
    "text": "brought it up you got to go there now man go ahead and dive right into it I guess like one of the interesting things like just going to how we run one of the",
    "start": "1235880",
    "end": "1242799"
  },
  {
    "text": "world's largest LM applications what that sort of focus forced us to do is given a single piece of compute like",
    "start": "1242799",
    "end": "1249039"
  },
  {
    "text": "let's say a single node or a single box of gpus we could host the most number of users on there so like let's say a large",
    "start": "1249039",
    "end": "1254799"
  },
  {
    "text": "company comes to us they can be confident that whether they're on Prem or there in VPC we can give them a",
    "start": "1254799",
    "end": "1261280"
  },
  {
    "text": "solution where the cost of the hardware is not going to dominate the cost of the software itself because right now",
    "start": "1261280",
    "end": "1267159"
  },
  {
    "text": "there's kind of this misunderstanding that the gpus are really expensive which is true they are but the trade-off is",
    "start": "1267159",
    "end": "1273440"
  },
  {
    "text": "they have a lot of compute like modern gpus like A1 100s can do 300 Tera flops",
    "start": "1273440",
    "end": "1279080"
  },
  {
    "text": "of compute which is like some ungodly number right like that's a crazy number compared to what a modern CPU can do and",
    "start": "1279080",
    "end": "1284960"
  },
  {
    "text": "we can leverage that the best and we've sort of been forced to do that like you know if we didn't do that properly we'd",
    "start": "1284960",
    "end": "1290320"
  },
  {
    "text": "have outages with our service all the time because of that enterprises trust us to be like the best solution to run",
    "start": "1290320",
    "end": "1296880"
  },
  {
    "text": "in their own tenant in an air gapped way uh which is fantastic because for that's like the way that we can build the most",
    "start": "1296880",
    "end": "1302720"
  },
  {
    "text": "trust and deploy these pieces of technology to them the most effectively because they don't want to ship their code outside of the company Ono can talk",
    "start": "1302720",
    "end": "1308720"
  },
  {
    "text": "a little bit more about how we leverage things like fine-tuning as well that's like a purely infrastructure problem that's very unique to US versus like any",
    "start": "1308720",
    "end": "1315480"
  },
  {
    "text": "other company as well Al do you want to sort of take that I mean yes so I think you know as very said there's a lot of",
    "start": "1315480",
    "end": "1321400"
  },
  {
    "text": "things that we can do from like the individual infrastructure point of view so that we can do crazy things like make it all free for all of our IND",
    "start": "1321400",
    "end": "1326919"
  },
  {
    "text": "individual users but once we actually self host there's actually a lot of things that you can do that you know",
    "start": "1326919",
    "end": "1332799"
  },
  {
    "text": "just any other tool can't do without being self-hosted and one of the ones that ver just mentioned is the",
    "start": "1332799",
    "end": "1338480"
  },
  {
    "text": "personalization right if you're fully hosted in a company's you know tenant",
    "start": "1338480",
    "end": "1343799"
  },
  {
    "text": "you can use all of their knowledge bases to create a substantially better product right I think the way we generally think",
    "start": "1343799",
    "end": "1350240"
  },
  {
    "text": "about is that you have a generic model that's good it's learned from trillions of tokens of code on the in the public",
    "start": "1350240",
    "end": "1356480"
  },
  {
    "text": "Corpus but if you think about any like individual company they have themselves hundreds of millions of tokens of code",
    "start": "1356480",
    "end": "1363000"
  },
  {
    "text": "that has never seen the light of day and that's actually the code that's the most relevant for them if they want to write any new code think of like all the know",
    "start": "1363000",
    "end": "1370400"
  },
  {
    "text": "internal syntax semantics utility functions libraries dsls whatever it might be and a model like a co-pilot or",
    "start": "1370400",
    "end": "1376720"
  },
  {
    "text": "a codium by the nature of it having Bel low latency can only take about 150 or so lines of code AS context right so",
    "start": "1376720",
    "end": "1383840"
  },
  {
    "text": "this is not like one of those like you know chat gbts or gp4s where you're like putting in files and files of context",
    "start": "1383840",
    "end": "1389279"
  },
  {
    "text": "like it's really small what you can put in and so there's really no way for a single inference to have full context of",
    "start": "1389279",
    "end": "1395480"
  },
  {
    "text": "your code base without actually fine-tuning the base model that we shipped to them on all their local code",
    "start": "1395480",
    "end": "1403440"
  },
  {
    "text": "and so we've actually you know done a bunch of studies and we're like on how this actually massively reduces like huc",
    "start": "1403440",
    "end": "1408600"
  },
  {
    "text": "ations and all these other things that you know you always hear coming up with llms but you know things like this",
    "start": "1408600",
    "end": "1414440"
  },
  {
    "text": "things like providing more in-depth analytics all these things actually come up by being self-hosted and as R",
    "start": "1414440",
    "end": "1419880"
  },
  {
    "text": "mentioned these are all at the core to some degree an infra problem right how do you actually do fine tuning locally",
    "start": "1419880",
    "end": "1427360"
  },
  {
    "text": "in you know company's tenant that's actually info problem that you know we're happy to talk more about but maybe",
    "start": "1427360",
    "end": "1432840"
  },
  {
    "text": "I'll just I'll pass it back to you Chris I actually I'm about to ask a followup about that because you've got me really",
    "start": "1432840",
    "end": "1438240"
  },
  {
    "text": "think thinking um about some of the use cases in my own life on that and so with",
    "start": "1438240",
    "end": "1443400"
  },
  {
    "text": "the self-hosting model and you're able to now kind of like you know open AI I said you know with chat gb4 there's only",
    "start": "1443400",
    "end": "1449440"
  },
  {
    "text": "so far we're going to go because we've kind of we've used the public Corpus of knowledge out there on the internet you",
    "start": "1449440",
    "end": "1454919"
  },
  {
    "text": "know so there's only so much more vertical scaling you can do on on the model learning and so you know you're",
    "start": "1454919",
    "end": "1460640"
  },
  {
    "text": "touching on the fact that there's so much hidden IP in code uh hidden",
    "start": "1460640",
    "end": "1466360"
  },
  {
    "text": "information in code that is of huge value particularly to the company that it's in because it's representing their",
    "start": "1466360",
    "end": "1473360"
  },
  {
    "text": "business model and the way their business is evolved over time and so if I'm understanding you correctly you're",
    "start": "1473360",
    "end": "1479039"
  },
  {
    "text": "basically saying that your solution can take advantage of that on their behalf",
    "start": "1479039",
    "end": "1484120"
  },
  {
    "text": "um and really really hone against it what are some of the limits on privacy are they able to do that because that's",
    "start": "1484120",
    "end": "1490399"
  },
  {
    "text": "a big topic we've actually talked about it on the show before about you know in this generative AI age with IP concerns",
    "start": "1490399",
    "end": "1497080"
  },
  {
    "text": "and privacy concerns you know getting the lawyers involved are you able to do the training on their site and keep it",
    "start": "1497080",
    "end": "1504279"
  },
  {
    "text": "to the customer entirely or do they have to let their IP out and stuff how do you",
    "start": "1504279",
    "end": "1509480"
  },
  {
    "text": "approach that that problem yeah I mean so one of just the answer to any question of like does any IP leave",
    "start": "1509480",
    "end": "1515600"
  },
  {
    "text": "coding for Enterprises the answer is always no uh so in pretty much every like part of the system like you know",
    "start": "1515600",
    "end": "1521480"
  },
  {
    "text": "our guarantee is to actually be able to deploy this whole thing fully air gapped we've even deployed in places like you",
    "start": "1521480",
    "end": "1526799"
  },
  {
    "text": "know AWS CUV Cloud which like entirely you know doesn't even have connection to the internet kind of scenario so nothing",
    "start": "1526799",
    "end": "1532880"
  },
  {
    "text": "ever leaves there to address some of the points you you brought up there Chris like yeah I mean we're not like the only",
    "start": "1532880",
    "end": "1538360"
  },
  {
    "text": "ones who are like saying like oh no the data that a company has privately is like super important and it's",
    "start": "1538360",
    "end": "1544440"
  },
  {
    "text": "potentially even more important than the size of the model I think you know um a good example this is actually meta",
    "start": "1544440",
    "end": "1550039"
  },
  {
    "text": "instead of using like a GitHub co-pilot or any generic system they decided in you know I guess classic meta fashion to",
    "start": "1550039",
    "end": "1555600"
  },
  {
    "text": "like train their own autocomplete model internally using all of their code and",
    "start": "1555600",
    "end": "1560840"
  },
  {
    "text": "they actually you know published a paper I think a few weeks back and their model was like in terms of size I think 1.3",
    "start": "1560840",
    "end": "1567760"
  },
  {
    "text": "billion parameters like small in in in respect to the the llm world and it just massively outperformed GI co-pilot on",
    "start": "1567760",
    "end": "1574919"
  },
  {
    "text": "pretty much every task there's some like corroborating evidence to you know what we're saying about fine tuning that",
    "start": "1574919",
    "end": "1580440"
  },
  {
    "text": "doing this actually does lead to materially better performances for you know the user in question now does that",
    "start": "1580440",
    "end": "1586480"
  },
  {
    "text": "meta model going to be good for everyone else could probably not but that's also not the whole point right and in terms of like",
    "start": "1586480",
    "end": "1592799"
  },
  {
    "text": "being able to F tune locally um yeah we're able to you know do this completely local and again it comes down",
    "start": "1592799",
    "end": "1597880"
  },
  {
    "text": "to like you know scale of data our base model has been trained on trillions of tokens of code right that's a lot that's",
    "start": "1597880",
    "end": "1604720"
  },
  {
    "text": "why we need this like you know multi- node GPU setup to do all this training but an actual company you know if they",
    "start": "1604720",
    "end": "1611320"
  },
  {
    "text": "have like say like even 10 million lines of code that's about 100 million or so tokens there's like a huge order of",
    "start": "1611320",
    "end": "1616760"
  },
  {
    "text": "magnitude difference still between this pre-training and the fine tuning which is why we can do this kind of locally on",
    "start": "1616760",
    "end": "1623279"
  },
  {
    "text": "actually surprisingly whichever Hardware they choose to provision for serving their developers so again this comes to",
    "start": "1623279",
    "end": "1629640"
  },
  {
    "text": "some of our like ml infa background and all the stuff that we know how to do we actually can do fine tuning and",
    "start": "1629640",
    "end": "1635399"
  },
  {
    "text": "inferences on that same piece of Hardware so we don't actually ask you know companies to provision more",
    "start": "1635399",
    "end": "1640679"
  },
  {
    "text": "hardware and even more like critically we are able to do fine cheing during any",
    "start": "1640679",
    "end": "1646880"
  },
  {
    "text": "idle time of that GPU so whatever that GPU is not being used to perform an inference it's actually doing like you",
    "start": "1646880",
    "end": "1652159"
  },
  {
    "text": "know backrop steps to like continuously improve the model you know find two just one aspect of like a larger kind of",
    "start": "1652159",
    "end": "1657799"
  },
  {
    "text": "personalization system but you know we've instrumented all this on Hardware using our infar roots to actually create",
    "start": "1657799",
    "end": "1664600"
  },
  {
    "text": "a system that is relatively easy to manage it's not a crazy amount of overhead for any company to to manage or",
    "start": "1664600",
    "end": "1670799"
  },
  {
    "text": "use codium but still get like you know the maximum possible wins from from these AI tools okay so that is super",
    "start": "1670799",
    "end": "1677840"
  },
  {
    "text": "cool uh and you mentioned things like gov Cloud which I have actually worked in because of in my day job quite a bit",
    "start": "1677840",
    "end": "1684320"
  },
  {
    "text": "and I can think of a whole bunch of other use cases for me personally which begs the question about kind of going",
    "start": "1684320",
    "end": "1691120"
  },
  {
    "text": "back for a moment because we are practical AI uh and we like to always give some practical routes for people",
    "start": "1691120",
    "end": "1697360"
  },
  {
    "text": "into that so if we're going to go back toward the beginning of the conversation for a moment and we have some folks that",
    "start": "1697360",
    "end": "1703840"
  },
  {
    "text": "are listening to this right now and they've been using co-pilot for a while they're probably putting code into chat",
    "start": "1703840",
    "end": "1709919"
  },
  {
    "text": "gbt and and trying to accelerate there with with varying degrees of success they've been experimenting with Bard and",
    "start": "1709919",
    "end": "1717000"
  },
  {
    "text": "Bard's gotten better on code lately obviously and and so so many people that I talk to are still very frustrated with",
    "start": "1717000",
    "end": "1724320"
  },
  {
    "text": "kind of the workflow of the whole thing and recognizing that there are these you've outlined these differentiators",
    "start": "1724320",
    "end": "1730840"
  },
  {
    "text": "you know from co-pilot and other competition out there in a friendly competition kind of way talk a little",
    "start": "1730840",
    "end": "1736159"
  },
  {
    "text": "bit about some of the specific generative AI use cases that would be",
    "start": "1736159",
    "end": "1741240"
  },
  {
    "text": "good if someone was in that position where they're like yeah I'm using the stuff but I'm not real I'm a little bit frustrated with it I don't have it down",
    "start": "1741240",
    "end": "1748679"
  },
  {
    "text": "and if they were to give codium that chance and dive in on it can you give me",
    "start": "1748679",
    "end": "1753720"
  },
  {
    "text": "several kind of layout the use cases on what is what are they going to get when they move in from a very practical like",
    "start": "1753720",
    "end": "1760399"
  },
  {
    "text": "for me now as the coder perspective what do that look like what are they bonusing",
    "start": "1760399",
    "end": "1765840"
  },
  {
    "text": "and maybe give me a couple of different ones cuz I'm really I'm really curious and selfishly I'm probably going to go try each of these",
    "start": "1765840",
    "end": "1772480"
  },
  {
    "text": "that you're telling me so I'm I'm scratching my own itch by asking the question I think you pointed out like yeah workflows and the user experience",
    "start": "1772480",
    "end": "1779120"
  },
  {
    "text": "for a lot of AI tools like everyone's still kind of trying to figure it out right we're still in very early days of these AI applications and this is our",
    "start": "1779120",
    "end": "1785640"
  },
  {
    "text": "learnings of trying to become a product company we're actually taking like the U quite seriously right and this is actually what the individual plan is is",
    "start": "1785640",
    "end": "1791960"
  },
  {
    "text": "create to get feedback on I think very you know concretely I think a lot of people have that frustration of like",
    "start": "1791960",
    "end": "1797440"
  },
  {
    "text": "having to cop a code block over to chat GPT write out a full prompt and like you know remember the exact prompt that they",
    "start": "1797440",
    "end": "1804120"
  },
  {
    "text": "typed in before that gave them a good result and then copying answers back in and then making modifications like that",
    "start": "1804120",
    "end": "1810440"
  },
  {
    "text": "workflow is clearly kind of broken so when we actually built our chat functionality into the IDE we're like",
    "start": "1810440",
    "end": "1816519"
  },
  {
    "text": "okay what are all the parts here that can get totally streamlined right and so we actually did things like you know on top of every function block there's",
    "start": "1816519",
    "end": "1822960"
  },
  {
    "text": "little like code lenses that are just these small buttons that someone can like click like explain this function",
    "start": "1822960",
    "end": "1828679"
  },
  {
    "text": "and it'll automatically pull in all that relevant context open up in the window you're not copying anything over and",
    "start": "1828679",
    "end": "1834000"
  },
  {
    "text": "it's like writing you know hit out any human text or if you say like refactor a function or add doc strings right or",
    "start": "1834000",
    "end": "1839919"
  },
  {
    "text": "write a unit test do all just like small little buttons or you know preset prompts that you can just then click",
    "start": "1839919",
    "end": "1846000"
  },
  {
    "text": "it'll do this generation on the side and then we even have a way of clicking like apply diff and because we know where we pulled the context in we can apply diff",
    "start": "1846000",
    "end": "1853240"
  },
  {
    "text": "right back into the context right and so you're not copying things back and trying to like resolve mder conflicts",
    "start": "1853240",
    "end": "1858600"
  },
  {
    "text": "like all these things are are done kind of automatically so there's a lot of really cool things you can actually do when you start bringing these things",
    "start": "1858600",
    "end": "1864440"
  },
  {
    "text": "into the it where developers are um and we spent a lot of time really thinking as you said from a workflow point of",
    "start": "1864440",
    "end": "1870639"
  },
  {
    "text": "view how do you make this like super smooth Veron could you talk a little bit about maybe some specific tasks that",
    "start": "1870639",
    "end": "1877200"
  },
  {
    "text": "you're seeing people doing when we talk about generative and it's expanded and you know from llms and we're you know",
    "start": "1877200",
    "end": "1882960"
  },
  {
    "text": "we're doing things in video we're doing things in uh natural language all of the different different modalities are",
    "start": "1882960",
    "end": "1889480"
  },
  {
    "text": "gradually being addressed with these different models and different tools that are being built around it could you",
    "start": "1889480",
    "end": "1894880"
  },
  {
    "text": "talk a little bit about you know what are people trying to code right now what",
    "start": "1894880",
    "end": "1900159"
  },
  {
    "text": "specifically is codium helping them like what not just about codium but the actual use cases themselves so they go",
    "start": "1900159",
    "end": "1907279"
  },
  {
    "text": "ah I can see a path forward I can I can go do that I know how to generate this",
    "start": "1907279",
    "end": "1912519"
  },
  {
    "text": "or that or the other with generative AI in codium can you talk a little bit about those at something of a specific level",
    "start": "1912519",
    "end": "1918360"
  },
  {
    "text": "so interestingly just a little bit about multimodality I think we're maybe a little bit far from leveraging I guess",
    "start": "1918360",
    "end": "1925080"
  },
  {
    "text": "other modes Beyond text for code I think maybe that that'll happen but I I think there's not enough evidence right now",
    "start": "1925080",
    "end": "1931000"
  },
  {
    "text": "yet for autocomplete just to be open about the the sort of the functionality we have we have autocomplete we have",
    "start": "1931000",
    "end": "1936639"
  },
  {
    "text": "search and we have codebase aware chat right so for we recognize right now that all the usage autocomplete accounts for",
    "start": "1936639",
    "end": "1943840"
  },
  {
    "text": "more than 90 to 95% of the usage of the product it's because chatting is not something people do like even every day",
    "start": "1943840",
    "end": "1949799"
  },
  {
    "text": "potentially they might open it up once every couple days but autocomplete is something that's like always on very",
    "start": "1949799",
    "end": "1955000"
  },
  {
    "text": "passively helpful and people get the most value out of it um which is kind of counterintuitive I think people don't",
    "start": "1955000",
    "end": "1960440"
  },
  {
    "text": "recognize that immediately but when people are doing autocomplete we've recognize there's like two modalities",
    "start": "1960440",
    "end": "1966200"
  },
  {
    "text": "right of the way people type code there's a modality of accelerating the developer which is like hey I kind of",
    "start": "1966200",
    "end": "1971760"
  },
  {
    "text": "know what I'm going to type and I just want to tab complete the result and then there's also an exploration phase which",
    "start": "1971760",
    "end": "1977080"
  },
  {
    "text": "is like I don't even know what I'm trying to do based on that I write a comment this is like a classic thing where like my behavior writing code has",
    "start": "1977080",
    "end": "1983760"
  },
  {
    "text": "materially changed because of tools like codium where I'll write a comment and I kind of just hope and pray that it pulls",
    "start": "1983760",
    "end": "1989000"
  },
  {
    "text": "in the right context so that it gives me the best generation possible so in my mind for the acceleration case codium is",
    "start": "1989000",
    "end": "1995880"
  },
  {
    "text": "like very helpful right it can like autocomplete a bunch of code but to make the exploration case that's where the true magical moment comes in where I had",
    "start": "1995880",
    "end": "2002519"
  },
  {
    "text": "like no clue I like how I was going to use a bunch of these apis and that's sort of what we're focused on on trying",
    "start": "2002519",
    "end": "2008600"
  },
  {
    "text": "to make really better whether that be in chat as well as with autoc complate how do we make it so that we can build the",
    "start": "2008600",
    "end": "2014320"
  },
  {
    "text": "most knowledgeable AI that is maximally helpful and also minimally just like",
    "start": "2014320",
    "end": "2019519"
  },
  {
    "text": "annoying the interesting thing about codium as a product or these autocomplete products is they get a",
    "start": "2019519",
    "end": "2024720"
  },
  {
    "text": "little bit of getting used to but even despite the fact that they write wrong things it's not very annoying because",
    "start": "2024720",
    "end": "2030120"
  },
  {
    "text": "you can very easily just say I don't want this completion or it didn't like write an entire file out and you need to",
    "start": "2030120",
    "end": "2036480"
  },
  {
    "text": "go and correct a bunch of functions it was like a couple lines or maybe like 10 lines of code you can very easily",
    "start": "2036480",
    "end": "2041679"
  },
  {
    "text": "validate that it's correct right that comes back to then what unel was saying which is how do we make sure we can",
    "start": "2041679",
    "end": "2047159"
  },
  {
    "text": "provide always The maximally Helpful sort of AI agent the answer is have the",
    "start": "2047159",
    "end": "2052679"
  },
  {
    "text": "best context possible and a couple nitty-gritty details we do is currently our context and we'll write a blog post",
    "start": "2052679",
    "end": "2058280"
  },
  {
    "text": "about this is double what co-pilots is we allow double the amount of context for autocomplete than what they do the",
    "start": "2058280",
    "end": "2064440"
  },
  {
    "text": "second thing is we're able to pull context throughout the codebase and this is actually that same piece of",
    "start": "2064440",
    "end": "2070079"
  },
  {
    "text": "technology that is pulling context throughout the codebase through search and all these other functionalities is",
    "start": "2070079",
    "end": "2075118"
  },
  {
    "text": "getting used as part of chat for codebase aware chat which is something that copilot doesn't even have today yet",
    "start": "2075119",
    "end": "2080679"
  },
  {
    "text": "the third piece is finally for a large Enterprise is how do we make it so that these models actually semantically",
    "start": "2080679",
    "end": "2086440"
  },
  {
    "text": "understand your code which is where fine-tuning comes in it's like for us context gets us a lot of the way but it",
    "start": "2086440",
    "end": "2092079"
  },
  {
    "text": "doesn't get us all the way because you can just imagine even with double the context let's say we can pass in a thousand lines of code for a company",
    "start": "2092079",
    "end": "2098880"
  },
  {
    "text": "with 10 million lines of code we're scratching four orders of Mau less code than the company actually has so this is",
    "start": "2098880",
    "end": "2104800"
  },
  {
    "text": "where our vision is like we want to continually ramp up the amount of knowledge these models have and the ways",
    "start": "2104800",
    "end": "2111240"
  },
  {
    "text": "in which they can be helpful I don't know if that answered the question there it did actually your acceleration versus",
    "start": "2111240",
    "end": "2116920"
  },
  {
    "text": "exploration uh analogy that was for me personally different people get different things that really clarified",
    "start": "2116920",
    "end": "2123400"
  },
  {
    "text": "for me where I might be using co-pilot or where I would go and use codium on that because I do struggle on the",
    "start": "2123400",
    "end": "2129920"
  },
  {
    "text": "exploration side myself it's a lot easier on the acceleration yet into the line into the line you know and crank",
    "start": "2129920",
    "end": "2135560"
  },
  {
    "text": "through that fast uh which I've been able to do with these other tools but I have struggled on the exploration side",
    "start": "2135560",
    "end": "2141960"
  },
  {
    "text": "because I kind of want to do a thing and I'm kind of trying to figure it out and I'm just going to kind of see where my fingers lead on that and having that",
    "start": "2141960",
    "end": "2149040"
  },
  {
    "text": "ability to support that in the way you described that gave me a very clear",
    "start": "2149040",
    "end": "2154280"
  },
  {
    "text": "understanding from my standpoint so I'd like to ask each of you where this is",
    "start": "2154280",
    "end": "2159400"
  },
  {
    "text": "going both in the large and in your specific concern with codium you know",
    "start": "2159400",
    "end": "2164680"
  },
  {
    "text": "things have never move faster than they're moving right now in terms of how fast these Technologies are are",
    "start": "2164680",
    "end": "2170319"
  },
  {
    "text": "progressing and Daniel and I have a habit uh we were commenting on our last episode about this we have a habit of",
    "start": "2170319",
    "end": "2176480"
  },
  {
    "text": "saying yeah we recently mentioned this thing and that we'd get to it but then we turn around and we end up talking",
    "start": "2176480",
    "end": "2181720"
  },
  {
    "text": "about that we just got there way faster than we ever anticipated with the speed of generative AI and you know you're",
    "start": "2181720",
    "end": "2188480"
  },
  {
    "text": "already creating these amazing tools and stuff like that and you're having to stay out front where's your brain taking",
    "start": "2188480",
    "end": "2194000"
  },
  {
    "text": "you at night you know when you when you stop and you chill out and have a glass of wine or whatever you do and you're",
    "start": "2194000",
    "end": "2199319"
  },
  {
    "text": "kind of just pondering what does the future look like and I'd like to know both from your own specific personal",
    "start": "2199319",
    "end": "2205359"
  },
  {
    "text": "standpoints in terms of your product and that but just the generative AI World in",
    "start": "2205359",
    "end": "2210480"
  },
  {
    "text": "general how do you see it going forward I'd love your insights yeah I think um the classic question and then the grand",
    "start": "2210480",
    "end": "2216800"
  },
  {
    "text": "schem of things like oh my God is like gener AI just going to like totally get rid of my job or completely like",
    "start": "2216800",
    "end": "2222000"
  },
  {
    "text": "invalidate and I think for us we will'll be the first people to say that you know we we do think like AI will just be like",
    "start": "2222000",
    "end": "2228440"
  },
  {
    "text": "the next step in a series of at least in code where a series of tools that have had made like developers more productive",
    "start": "2228440",
    "end": "2234520"
  },
  {
    "text": "right that have led them to be able to focus on more kind of interesting parts of software development and you know be",
    "start": "2234520",
    "end": "2241920"
  },
  {
    "text": "an assistant right we all these tools are called AI assistant tools I think for a reason you know we're definitely not at a place place yet I I don't think",
    "start": "2241920",
    "end": "2249079"
  },
  {
    "text": "for a while where there isn't going to be like a human in the loop like in control uh you know guiding the AI and",
    "start": "2249079",
    "end": "2255560"
  },
  {
    "text": "and what to do so from that kind of respect like the Doomsday scenario I'm I don't want to speak for but I think",
    "start": "2255560",
    "end": "2261480"
  },
  {
    "text": "we're like pretty far from that mentality but we do think like I think you know we wouldn't have gotten into codium if we didn't genuinely think that",
    "start": "2261480",
    "end": "2268599"
  },
  {
    "text": "there was just so many things that we do as a day-to-day as Engineers that are just a little frustrating boring kind of",
    "start": "2268599",
    "end": "2274200"
  },
  {
    "text": "take us out of the Flow State you know slow us down those all seem like very Prime ripe things to like try to address",
    "start": "2274200",
    "end": "2281079"
  },
  {
    "text": "with AI right and I think that's kind of our general goal right I think there's a lot more capabilities to build right I",
    "start": "2281079",
    "end": "2286960"
  },
  {
    "text": "don't think search Chat these are going to be the last I guess like building blocks that we build we have more",
    "start": "2286960",
    "end": "2293200"
  },
  {
    "text": "capabilities coming up that we're super excited about but yeah it's also like you know going to be a thing where as",
    "start": "2293200",
    "end": "2298400"
  },
  {
    "text": "you said this is moving super quickly right like we have like research open source like applications all developing",
    "start": "2298400",
    "end": "2304079"
  },
  {
    "text": "at the same time at break Breck next speed and so I think part of what we're also looking forward to is like how can",
    "start": "2304079",
    "end": "2310359"
  },
  {
    "text": "we also just like educate like you know at least software developers on the best way to use AI tools how to like best",
    "start": "2310359",
    "end": "2316319"
  },
  {
    "text": "make the most use of it so that they are part of the wave right and that they also can get a lot of value well said",
    "start": "2316319",
    "end": "2322599"
  },
  {
    "text": "Veron yeah maybe if I was to just say like you were asking me what the big worry is for me the big worry is there's",
    "start": "2322599",
    "end": "2329000"
  },
  {
    "text": "going to be a lot of like exciting new demos that people end up building and obviously for us as a company we need to",
    "start": "2329000",
    "end": "2334960"
  },
  {
    "text": "make strategic bets on like hey this is a worth thing for us to invest in for instance I think a couple months ago",
    "start": "2334960",
    "end": "2340920"
  },
  {
    "text": "there was an entire craze on agents being able to write like entire pieces of of code for you and all these other",
    "start": "2340920",
    "end": "2346960"
  },
  {
    "text": "things for us though we had lots of Enterprise companies that were sort of using the product at the time and recognized that the technology just",
    "start": "2346960",
    "end": "2353560"
  },
  {
    "text": "wasn't there yet right like take a codebase that's like 100 million lenss of code or 10 million lenses of code it's going to be hard for you to write",
    "start": "2353560",
    "end": "2359680"
  },
  {
    "text": "C++ that's like five files that compiles perfectly and then also like uses all the other libraries when you have",
    "start": "2359680",
    "end": "2365440"
  },
  {
    "text": "context that's like you know 55 it's not going to be the easiest problem and I think that's maybe an example but",
    "start": "2365440",
    "end": "2372079"
  },
  {
    "text": "for us we've currently I would say just a pat on the back over the last eight months iterated like significantly",
    "start": "2372079",
    "end": "2377480"
  },
  {
    "text": "faster than every other company in the space just in terms of the functionality but we need to make strategic bets on",
    "start": "2377480",
    "end": "2383160"
  },
  {
    "text": "what the next thing to sort of work on is at any given point and we need to be very careful about like hey this is like",
    "start": "2383160",
    "end": "2389079"
  },
  {
    "text": "a very exciting area but is it like actually useful to our users right like is it actually useful in that hey like",
    "start": "2389079",
    "end": "2395680"
  },
  {
    "text": "maybe we could do something where a great example is given a PR we generate a summary and I think co-pilot has tried",
    "start": "2395680",
    "end": "2402760"
  },
  {
    "text": "building something like this and we tried using the product that copal had had and it was just wrong a lot of the",
    "start": "2402760",
    "end": "2408359"
  },
  {
    "text": "times and I think that would have been an interesting idea for us to pursue and keep trying to make work but then there",
    "start": "2408359",
    "end": "2414000"
  },
  {
    "text": "is like diminishing returns and I think onil and I have seen this very clearly in autonomous vehicles where we had a",
    "start": "2414000",
    "end": "2420319"
  },
  {
    "text": "piece of technology that was kind of just not there yet like it needs a couple more breakthroughs of machine learning to kind of get there and the",
    "start": "2420319",
    "end": "2426640"
  },
  {
    "text": "idea of building it 5 years in advance right you shouldn't be doing that you just 100% shouldn't be building a tool",
    "start": "2426640",
    "end": "2432440"
  },
  {
    "text": "when the technology just isn't there yet and that is something that keeps me up at night is like what are the next",
    "start": "2432440",
    "end": "2437960"
  },
  {
    "text": "things we need to build while keeping in mind of this is what the technological capability set is like today um if that",
    "start": "2437960",
    "end": "2444240"
  },
  {
    "text": "makes sense it does and it's a very practical uh AI perspective if you will so very fitting final words for the show",
    "start": "2444240",
    "end": "2451680"
  },
  {
    "text": "today well uh Veron and anchel thank you very very much for coming on the show uh",
    "start": "2451680",
    "end": "2456800"
  },
  {
    "text": "as fast fting I got a lot of insight a lot of uh new things to go explore from what you just taught me and I appreciate",
    "start": "2456800",
    "end": "2463440"
  },
  {
    "text": "your time thank you for coming on thanks for up us thanks L [Music]",
    "start": "2463440",
    "end": "2474319"
  },
  {
    "text": "Chris thank you for listening to practical AI your next step is to",
    "start": "2474319",
    "end": "2479640"
  },
  {
    "text": "subscribe now if you haven't already and if you're a longtime listener of the show help us reach more people by",
    "start": "2479640",
    "end": "2485960"
  },
  {
    "text": "sharing practical AI with your friends and colleagues thanks once again to fastly and fly for partnering with us to",
    "start": "2485960",
    "end": "2492040"
  },
  {
    "text": "bring you all Chang doog podcasts check out what they're up to at fastly.com and",
    "start": "2492040",
    "end": "2497440"
  },
  {
    "text": "fly.io and to our beat freaking residents breakmaster cylinder for continuously cranking out the best beats",
    "start": "2497440",
    "end": "2503200"
  },
  {
    "text": "in the viz that's all for now we'll talk to you again next [Music]",
    "start": "2503200",
    "end": "2516240"
  },
  {
    "text": "time k",
    "start": "2516240",
    "end": "2522079"
  }
]
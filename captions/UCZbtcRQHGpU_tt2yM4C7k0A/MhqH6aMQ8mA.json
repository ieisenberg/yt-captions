[
  {
    "text": "B with for Chang log is provided by fastly learn more at fastly.com we move",
    "start": "80",
    "end": "6040"
  },
  {
    "text": "fast and fix things here at changelog because of rbar check them out at rar.com and we're hosted on Leno servers",
    "start": "6040",
    "end": "12799"
  },
  {
    "text": "head to lin.com [Music]",
    "start": "12799",
    "end": "19809"
  },
  {
    "text": "changelog welcome to practical AI a weekly podcast about making artificial intelligence practical productive and",
    "start": "19840",
    "end": "27039"
  },
  {
    "text": "accessible to everyone this is where conversations around AI machine learning and data science happen join the",
    "start": "27039",
    "end": "33440"
  },
  {
    "text": "community and slack with us around various topics of the show at change.com Community follow us on Twitter we're at",
    "start": "33440",
    "end": "39120"
  },
  {
    "text": "practical aifm and now on to the [Music]",
    "start": "39120",
    "end": "45520"
  },
  {
    "text": "show well welcome to a fully connected episode of practical AI where Chris my",
    "start": "45520",
    "end": "52320"
  },
  {
    "text": "co-host and I will keep you fully connected with everything that's happening in the AI Community we'll take",
    "start": "52320",
    "end": "58879"
  },
  {
    "text": "some time to discuss some of the latest AI news and then we'll dig into some learning resources to to uh help you uh",
    "start": "58879",
    "end": "67000"
  },
  {
    "text": "and US level up our machine learning game so Chris how's it going going great how you doing Daniel doing well getting",
    "start": "67000",
    "end": "74159"
  },
  {
    "text": "ready for uh American Thanksgiving yep it's uh as we're recording this it is the day before Thanksgiving for us and",
    "start": "74159",
    "end": "81280"
  },
  {
    "text": "uh so looking forward to uh to over stuffing myself tomorrow and and then and then worrying about how I'm going to",
    "start": "81280",
    "end": "87320"
  },
  {
    "text": "lose the weight thereafter yeah looking forward to some to fky for sure exactly what have you been seeing in",
    "start": "87320",
    "end": "94399"
  },
  {
    "text": "terms of AI news recently Chris well actually I the first thing that caught my eye was something that you had uh had",
    "start": "94399",
    "end": "101280"
  },
  {
    "text": "shared with us the last time we were talking about this stuff and uh that is we were we were talking about uh artwork",
    "start": "101280",
    "end": "107960"
  },
  {
    "text": "in the world of AI and there was a uh a particular piece of art that you discussed and that was where a",
    "start": "107960",
    "end": "115000"
  },
  {
    "text": "generative adversarial Network had been used to generate uh this piece of kind",
    "start": "115000",
    "end": "120039"
  },
  {
    "text": "of period art I'm not an art person so I'm not going to do that yeah it looked like a portrait of a guy kind of yeah it",
    "start": "120039",
    "end": "125840"
  },
  {
    "text": "was called portrait of Edmund uh Bellamy if I'm saying that correctly and it was a it's a fictional person from a",
    "start": "125840",
    "end": "131640"
  },
  {
    "text": "fictional family when you were telling us about it last it hadn't gone to auction yet but Christies was going to",
    "start": "131640",
    "end": "137160"
  },
  {
    "text": "and they were expecting it to to raise somewhere between 7 and $10,000 us a few",
    "start": "137160",
    "end": "142840"
  },
  {
    "text": "days after our episode went live it actually went to auction and it ended up selling for $430",
    "start": "142840",
    "end": "151319"
  },
  {
    "text": "2,500 us boom boom that's crazy crazy so I mean and it really wait wasn't it yeah",
    "start": "151319",
    "end": "158160"
  },
  {
    "text": "so they were saying that it was going to sell for like 7 to 10 grand right something like that yeah it was like it",
    "start": "158160",
    "end": "164120"
  },
  {
    "text": "was 45 time multiple on what they thought and you know and so we we had been looking at it with interest you",
    "start": "164120",
    "end": "170000"
  },
  {
    "text": "know in the AI Community but I think the entire art World got rocked by that one because suddenly um suddenly yeah you're",
    "start": "170000",
    "end": "177760"
  },
  {
    "text": "major Contender from from the AI world in terms of you know high value art going so I think it's something that a",
    "start": "177760",
    "end": "184879"
  },
  {
    "text": "lot of people that are not traditionally thinking about AI are having to digest and realize that the world is changing",
    "start": "184879",
    "end": "191200"
  },
  {
    "text": "yeah I think people are going to have to start uh are going to stop going to uh Chicago Institute of Art and start going",
    "start": "191200",
    "end": "198599"
  },
  {
    "text": "to MIT or something to to go into art yeah it was kind of funny a few days after that I host a Meetup in Atlanta",
    "start": "198599",
    "end": "205640"
  },
  {
    "text": "called the Atlanta deep learning Meetup and I know I've mentioned it before but we actually had a a generative",
    "start": "205640",
    "end": "210680"
  },
  {
    "text": "adversarial Network tutorial last month uh where we had a an expert named RZA",
    "start": "210680",
    "end": "215879"
  },
  {
    "text": "katabi come and and show us and it was funny he came in he goes you know I had this uh I had this little project we can",
    "start": "215879",
    "end": "222120"
  },
  {
    "text": "all coded as we go along the way but I've changed my mind we're going to try to build some artwork in this session",
    "start": "222120",
    "end": "227640"
  },
  {
    "text": "and we'll split the proceeds if it makes enough money and so um it was it was just funny cuz you know sounds sounds",
    "start": "227640",
    "end": "233920"
  },
  {
    "text": "good yeah yeah that's great and there there's been some other uh some other big news not necessarily art related",
    "start": "233920",
    "end": "240959"
  },
  {
    "text": "what have you seen lately yeah so I don't know about you I'm on Twitter it's where I where I hear about a lot of",
    "start": "240959",
    "end": "247280"
  },
  {
    "text": "things and uh it seems like to me and I don't know if you've seen this thing same thing let me know if you have but",
    "start": "247280",
    "end": "252920"
  },
  {
    "text": "it seems like every other AI related tweet that I'm seeing at least in the",
    "start": "252920",
    "end": "258560"
  },
  {
    "text": "people that I follow is about natural language processing oh yeah so like over the past I would say like I don't know",
    "start": "258560",
    "end": "265560"
  },
  {
    "text": "like 3 weeks to a month it seems like there's just been a steady rise in all",
    "start": "265560",
    "end": "271520"
  },
  {
    "text": "things like neural Nets and natural language have you have you been seeing the same thing I sure have and I think",
    "start": "271520",
    "end": "276759"
  },
  {
    "text": "uh I think I know where you're going with that because there is a uh there was a particular thing announced that I'll let you I'll let you lead into that",
    "start": "276759",
    "end": "283800"
  },
  {
    "text": "has really caused a lot of interest in the last few weeks yeah you you guess where I'm going so uh there's this new",
    "start": "283800",
    "end": "290840"
  },
  {
    "text": "uh new model out uh so a pre-trained model called Bert from Google so that's",
    "start": "290840",
    "end": "296800"
  },
  {
    "text": "a new approach to pre-trained Natural language processing which we we can talk about here in a second but there there's",
    "start": "296800",
    "end": "303039"
  },
  {
    "text": "actually been like I've seen even yesterday I think it was yesterday this",
    "start": "303039",
    "end": "308080"
  },
  {
    "text": "HTML model from uh hugging face which is pretty incredible take a look at that if",
    "start": "308080",
    "end": "313680"
  },
  {
    "text": "you haven't seen it and by HTML it's not meaning the HTML of the web but like a",
    "start": "313680",
    "end": "319319"
  },
  {
    "text": "uh multitask learning model and uh or I'm sorry I and now I'm saying I I'm",
    "start": "319319",
    "end": "326639"
  },
  {
    "text": "getting confused even with the the acronym so it's hmtl right so hierarchical multitask learning not HTML",
    "start": "326639",
    "end": "334960"
  },
  {
    "text": "so there there's a confusion there you know you just you just disappointed an entire world of frontend developers who",
    "start": "334960",
    "end": "340280"
  },
  {
    "text": "thought they just now had their their way into machine learning their way into yeah no so hmtl so I saw that yesterday",
    "start": "340280",
    "end": "346120"
  },
  {
    "text": "there's also like I've seen Elmo which I think came from the Allen Institute and",
    "start": "346120",
    "end": "351600"
  },
  {
    "text": "also there was this challenge so one of the challenges at the now rebranded NPS",
    "start": "351600",
    "end": "357960"
  },
  {
    "text": "conference which was a much needed rebranding but now they had a competition that's actually it's kind of",
    "start": "357960",
    "end": "364440"
  },
  {
    "text": "in the schedule for the presentations phase I think now around uh around chat",
    "start": "364440",
    "end": "370360"
  },
  {
    "text": "Bots and dialogue systems and so it seems like at least from my perspective",
    "start": "370360",
    "end": "376520"
  },
  {
    "text": "all things with neural Nets these days are like with natural language yeah it's",
    "start": "376520",
    "end": "381759"
  },
  {
    "text": "kind of funny we've we we go through these waves you know for a long time everything seemed to be about computer",
    "start": "381759",
    "end": "387319"
  },
  {
    "text": "vision and and all the different convolutional variants that came out and capsule Nets and you're right there",
    "start": "387319",
    "end": "393360"
  },
  {
    "text": "hasn't been as much in the news lately but um with Bert being released the NLP world is just on fire right now yeah for",
    "start": "393360",
    "end": "399479"
  },
  {
    "text": "sure so let's uh actually I'd love to if you're willing to kind of dig in a little bit I'd love to dig into exactly",
    "start": "399479",
    "end": "406560"
  },
  {
    "text": "you know what Bert is I'm still learning about it so I'll confess you know as we get into this conversation please",
    "start": "406560",
    "end": "413080"
  },
  {
    "text": "connect with us on our slack team and our LinkedIn page uh of practical AI you",
    "start": "413080",
    "end": "419000"
  },
  {
    "text": "can go to changel log.com practical aai and uh join our our slack team but I",
    "start": "419000",
    "end": "424639"
  },
  {
    "text": "would love to hear if I say anything that's not right I'm kind of learning about these things as I as I go so we'd",
    "start": "424639",
    "end": "430120"
  },
  {
    "text": "love to hear your perspective on these things as well so keep us informed in that way but my understanding of what",
    "start": "430120",
    "end": "436759"
  },
  {
    "text": "Bert is is the goal is to create this kind of pre-trained NLP model or",
    "start": "436759",
    "end": "442919"
  },
  {
    "text": "pre-trained language model so some of this uh terminology is new to me like I",
    "start": "442919",
    "end": "448120"
  },
  {
    "text": "mentioned but in my understanding what they're trying to do here is create an encoder that will be pre-trained that",
    "start": "448120",
    "end": "455919"
  },
  {
    "text": "you could utilize for various natural language tasks so for example like",
    "start": "455919",
    "end": "462280"
  },
  {
    "text": "sentiment analysis or question answering or named entity recognition these are",
    "start": "462280",
    "end": "467879"
  },
  {
    "text": "all kind of natural language processing tasks and so their goal is to create",
    "start": "467879",
    "end": "473280"
  },
  {
    "text": "this pre-trained encoder that will essentially kind of be",
    "start": "473280",
    "end": "478319"
  },
  {
    "text": "a a uh act as a language model or a model that understands the kind of",
    "start": "478319",
    "end": "483680"
  },
  {
    "text": "structuring of words and the context of those that can be utilized as the first",
    "start": "483680",
    "end": "488960"
  },
  {
    "text": "bit of other models for these other sorts of tasks yeah is that kind of",
    "start": "488960",
    "end": "494639"
  },
  {
    "text": "Chris correct me if I'm wrong am I am I on the complete wrong track here no no I think you're right I think they have",
    "start": "494639",
    "end": "499800"
  },
  {
    "text": "some specific terminology they use I think they call that a Transformer and the Transformer is learning contextual",
    "start": "499800",
    "end": "506360"
  },
  {
    "text": "relation between words and text and then it has two separate pieces to it one is an encoder that's reading the text input",
    "start": "506360",
    "end": "513360"
  },
  {
    "text": "and then one's a decoder that is producing the prediction you know for whatever task you're applying it to so I",
    "start": "513360",
    "end": "518839"
  },
  {
    "text": "think the the when you combine the encoder and decoder they're calling that a Transformer yeah but you I think",
    "start": "518839",
    "end": "523959"
  },
  {
    "text": "everything you said was accurate yeah and I think what they're saying cuz this isn't the Transformer model I guess has",
    "start": "523959",
    "end": "530000"
  },
  {
    "text": "been around for a while and we'll link to the info about that in our notes but this so the Bert model which again has",
    "start": "530000",
    "end": "537000"
  },
  {
    "text": "come out of Google so it stands for bidirectional encoder representations from",
    "start": "537000",
    "end": "543200"
  },
  {
    "text": "Transformers so essentially this is like you just mentioned Chris this is based",
    "start": "543200",
    "end": "548440"
  },
  {
    "text": "on the Transformer model and it's kind of like like you mentioned in in the Transformer model there's an encoder and",
    "start": "548440",
    "end": "554640"
  },
  {
    "text": "a decoder level because they're trying to do a specific one or more specific tasks in this case they're kind of",
    "start": "554640",
    "end": "561839"
  },
  {
    "text": "basing this Bert model on the encoder piece of that Transformer thanks for the",
    "start": "561839",
    "end": "568000"
  },
  {
    "text": "clarification there yeah uh so it took me a second to get there because it is um it is confusing with the it's a lot",
    "start": "568000",
    "end": "574959"
  },
  {
    "text": "to digest there's a lot of information that's been pouring out and I know I know both of us have been going through",
    "start": "574959",
    "end": "580519"
  },
  {
    "text": "some of the different articles and stuff that kind of break it down so definitely a uh a learning task and process for us",
    "start": "580519",
    "end": "587640"
  },
  {
    "text": "yeah yeah for sure and my understanding is that it's based on this Transformer",
    "start": "587640",
    "end": "593279"
  },
  {
    "text": "encoder which is kind of unique amongst encoders because when you think about",
    "start": "593279",
    "end": "599480"
  },
  {
    "text": "about trying to understand language like the context of a word in a sentence you can think about it directionally like",
    "start": "599480",
    "end": "605320"
  },
  {
    "text": "moving forward in the sentence and based on the kind of forward Direction getting",
    "start": "605320",
    "end": "610399"
  },
  {
    "text": "the context of a word but actually the transformer in this case is well they",
    "start": "610399",
    "end": "616959"
  },
  {
    "text": "call it bidirectional but in my understanding it's really like nondirectional because it considers all",
    "start": "616959",
    "end": "622480"
  },
  {
    "text": "of the text surrounding a word at the you know as it's determining the context",
    "start": "622480",
    "end": "629040"
  },
  {
    "text": "of so it's not directional in the sense of like going forward through a sentence yeah that's my understanding is is i'",
    "start": "629040",
    "end": "635240"
  },
  {
    "text": "I've seen it described in in different people blogging about it as as uh either non-directional as you put it I've seen",
    "start": "635240",
    "end": "641279"
  },
  {
    "text": "it as directional in either way or or bidirectional I think you have a choice in how you're doing it and and the",
    "start": "641279",
    "end": "646519"
  },
  {
    "text": "masking of of the word that you're building the context around is is pretty key yeah yeah definitely you mentioned",
    "start": "646519",
    "end": "653200"
  },
  {
    "text": "the task I think that one of the also the key features here is that it's the",
    "start": "653200",
    "end": "658519"
  },
  {
    "text": "bidirectional encoder representation so they're creating this this kind of context for the for language but in",
    "start": "658519",
    "end": "666480"
  },
  {
    "text": "order to do that they have to kind of decide about what tasks will help them",
    "start": "666480",
    "end": "672880"
  },
  {
    "text": "or what tasks or predictions will help them get the best understanding of",
    "start": "672880",
    "end": "678079"
  },
  {
    "text": "language or create the best kind of encoder or language model like they're calling it and in this case they're",
    "start": "678079",
    "end": "684160"
  },
  {
    "text": "actually using multiple tasks to do that they're using one task like you mention",
    "start": "684160",
    "end": "689639"
  },
  {
    "text": "which is kind of like a masking of words like in a sentence they'll kind of remove certain words and have the Train",
    "start": "689639",
    "end": "696360"
  },
  {
    "text": "the model with the encoder to actually kind of fill in those words the other task that they're doing is next sentence",
    "start": "696360",
    "end": "704959"
  },
  {
    "text": "prediction which is like given two sentences can you tell if one of the sentence is actually the next sentence",
    "start": "704959",
    "end": "711399"
  },
  {
    "text": "that comes after the other sentence yep I agree one of the things that it occurred to me we probably should do is",
    "start": "711399",
    "end": "717760"
  },
  {
    "text": "is kind of talk about you know what encoding and decoding is encoding is where you're actually taking your input",
    "start": "717760",
    "end": "724480"
  },
  {
    "text": "and putting it into the sequencing and by the way I found this on quora for the audience Daniel and I are Googling this",
    "start": "724480",
    "end": "730519"
  },
  {
    "text": "stuff just like you are you know we're all learning as we go and and encoding and decoding is is obviously a common",
    "start": "730519",
    "end": "737040"
  },
  {
    "text": "task in a lot of neural network architectures but putting it into sequence and then decoding is where you're actually getting the output that",
    "start": "737040",
    "end": "743560"
  },
  {
    "text": "you're going to use on that also wanted to note that we've kind of uh not mentioned that there's really two stages",
    "start": "743560",
    "end": "748839"
  },
  {
    "text": "to and that's important because of they're for different purposes there's there's a pre-training stage and then",
    "start": "748839",
    "end": "755440"
  },
  {
    "text": "there's a fine-tuning stage and the pre-training stage is very expensive it takes a lot of resource I think in what",
    "start": "755440",
    "end": "761880"
  },
  {
    "text": "I'm looking at here they talk about it takes uh 4 days on a 4 to6 Cloud TPU",
    "start": "761880",
    "end": "768320"
  },
  {
    "text": "system just to get through yeah a lot of that's some crazy stuff lot of processing I'm have the thing pulled up",
    "start": "768320",
    "end": "774399"
  },
  {
    "text": "right now with uh gcps cost and that turns out to be around like well at",
    "start": "774399",
    "end": "780800"
  },
  {
    "text": "least with the number I'm seeing around 7K us so $7,000 in TPU cost um which of",
    "start": "780800",
    "end": "788480"
  },
  {
    "text": "course they're Google and I guess they don't spend that because it's their own cloud but significant effort my my wife",
    "start": "788480",
    "end": "794279"
  },
  {
    "text": "would not like it if I did that for a weekend project I would get in trouble for that spending that kind of money but",
    "start": "794279",
    "end": "799560"
  },
  {
    "text": "fortunately Google has put out a whole bunch of pre-trained models that you know recognizing the expense of that",
    "start": "799560",
    "end": "804680"
  },
  {
    "text": "they have uh they have helped us all those of us who are going to be trying to apply this technology they have a good starting point and really when",
    "start": "804680",
    "end": "811440"
  },
  {
    "text": "you're deploying it into your own application the fine-tuning which is an inexpensive thing doesn't require nearly",
    "start": "811440",
    "end": "817079"
  },
  {
    "text": "as much processing is really where you're going to be focusing so you'll be able to go and find a pre-trained model",
    "start": "817079",
    "end": "822120"
  },
  {
    "text": "hopefully maybe or maybe not even need to make tweaks to it they mentioned that there was very little adjustment needing to be made for different use cases and",
    "start": "822120",
    "end": "829360"
  },
  {
    "text": "then do the fine-tuning for your own specific which is inexpensive and something that I probably could do on",
    "start": "829360",
    "end": "834959"
  },
  {
    "text": "the weekend without getting in trouble nice yeah so correct me if I'm wrong Chris so I I'm trying to think",
    "start": "834959",
    "end": "841160"
  },
  {
    "text": "about like CU I actually have potentially a couple use cases that I I have in the back of my mind for this and",
    "start": "841160",
    "end": "847920"
  },
  {
    "text": "correct me if I'm wrong when I'm thinking about like how one would go about this but in my understanding a",
    "start": "847920",
    "end": "853800"
  },
  {
    "text": "best use case for me to use Bert is if I have some natural language processing",
    "start": "853800",
    "end": "859639"
  },
  {
    "text": "task let's say I'm trying to identify certain entities in text like named entity recognition what I could do is",
    "start": "859639",
    "end": "867959"
  },
  {
    "text": "take AE pre-trained Bert I don't know if that's the proper way to say that but",
    "start": "867959",
    "end": "873000"
  },
  {
    "text": "that's how I'm going to say pre-trained Bert sorry to any of you out there that are named Bert um and this is confusing",
    "start": "873000",
    "end": "878759"
  },
  {
    "text": "for but um I would take a pre-trained Bert which Google has spent much much",
    "start": "878759",
    "end": "884639"
  },
  {
    "text": "time training and many update steps and lots and lots of data and uh so they've",
    "start": "884639",
    "end": "890959"
  },
  {
    "text": "developed this Bert and what Bert's going to do is allow me to put in sequences of words and Bert will then",
    "start": "890959",
    "end": "898240"
  },
  {
    "text": "output sequences of vector representations of those words also give",
    "start": "898240",
    "end": "904360"
  },
  {
    "text": "kind of a context within the language model of birt and then I could kind of bolt onto that encoder layer some",
    "start": "904360",
    "end": "913839"
  },
  {
    "text": "classification task or some other sort of task in in my case maybe it would be",
    "start": "913839",
    "end": "919000"
  },
  {
    "text": "named entity recognition and because Bert is so good at understanding the",
    "start": "919000",
    "end": "925440"
  },
  {
    "text": "context of language actually the up for me to actually do one of these tasks",
    "start": "925440",
    "end": "930959"
  },
  {
    "text": "like named entity recognition or or uh question answering or something is like you said fairly inexpensive so I'm",
    "start": "930959",
    "end": "937240"
  },
  {
    "text": "utilizing all of the expertise that has been built into Google's model and just adding on the little piece that makes it",
    "start": "937240",
    "end": "944639"
  },
  {
    "text": "particular to my use case and so the first thing that's is pre-training the second thing is fine-tuning is that",
    "start": "944639",
    "end": "951079"
  },
  {
    "text": "right I I think that was a great explanation and that is consistent with my understanding of it it's you know Bert is really the way I'm reading it is",
    "start": "951079",
    "end": "958480"
  },
  {
    "text": "Bert is really to be uh embedded into a larger architecture to where you get this incredible capability for uh maybe",
    "start": "958480",
    "end": "966000"
  },
  {
    "text": "not for free but at low cost relative to having to to figure out how to do it yourself or use a lesser technology so",
    "start": "966000",
    "end": "973360"
  },
  {
    "text": "from my standpoint I think this is another great step where Google in this case is providing what would otherwise",
    "start": "973360",
    "end": "979120"
  },
  {
    "text": "be a very challenging specific task in a larger architecture and they're helping us do that almost like a a software",
    "start": "979120",
    "end": "985560"
  },
  {
    "text": "component in a larger Software System I think that there's kind of two threads that I see running through this that are",
    "start": "985560",
    "end": "991600"
  },
  {
    "text": "also kind of you know hugely impactful I think in the industry in general one one",
    "start": "991600",
    "end": "996639"
  },
  {
    "text": "of those is transfer learning what here we're calling maybe the the fine-tuning part where in transfer learning you're",
    "start": "996639",
    "end": "1003399"
  },
  {
    "text": "taking something that was trained for a certain task and then updating it or",
    "start": "1003399",
    "end": "1008720"
  },
  {
    "text": "fine-tuning it to another type of task and and as we've mentioned on the podcast before I think that's it's",
    "start": "1008720",
    "end": "1015360"
  },
  {
    "text": "hugely impactful and a huge benefit for actually people that are doing applied AI the other thing is this multitask",
    "start": "1015360",
    "end": "1023199"
  },
  {
    "text": "learning framework I see that this is done in Bert I also see it being done like I mentioned in the hmtl model and",
    "start": "1023199",
    "end": "1030959"
  },
  {
    "text": "other cases where this encoder layer is being trained based on being able to do",
    "start": "1030959",
    "end": "1037120"
  },
  {
    "text": "multiple tasks not just not just one task and I would highly recommend looking at that hmtl model as well",
    "start": "1037120",
    "end": "1043640"
  },
  {
    "text": "that's that's pretty impressive in that respect sounds good anything else uh well I was just to mention as you can",
    "start": "1043640",
    "end": "1049880"
  },
  {
    "text": "tell I've kind of been sucked down the rabbit hole of of Bert but I did want to mention to people again this is open",
    "start": "1049880",
    "end": "1056160"
  },
  {
    "text": "source you can read the article from from Google but also you can go to their GitHub and they have the pre-trained",
    "start": "1056160",
    "end": "1061320"
  },
  {
    "text": "models that you can go ahead and use but there's also actually already been an implementation in pytorch by hugging",
    "start": "1061320",
    "end": "1068200"
  },
  {
    "text": "face and it's not maintained by the Google team but but by someone else and I I just thought it was pretty cool and",
    "start": "1068200",
    "end": "1075080"
  },
  {
    "text": "useful to already see that implementation in pytorch so soon soon after seeing uh seeing the stuff count",
    "start": "1075080",
    "end": "1081919"
  },
  {
    "text": "come out of Google so keep that in mind whether you're working on pytorch or tensorflow not that those are the only two but I think that covers a lot of",
    "start": "1081919",
    "end": "1088640"
  },
  {
    "text": "people you'll be able to utilize this uh Tech so that's true and I think we end up talking about tensor flow and P TCH",
    "start": "1088640",
    "end": "1095080"
  },
  {
    "text": "right now because there's there's so much coming out in terms of advancements being made uh where people are really",
    "start": "1095080",
    "end": "1100600"
  },
  {
    "text": "centering around those two platforms but as you said there are tons of of great tools out there uh we're not trying to",
    "start": "1100600",
    "end": "1106600"
  },
  {
    "text": "exclude anyone on those and we would love to hear back if we are not talking about your favorite tool as much as",
    "start": "1106600",
    "end": "1112679"
  },
  {
    "text": "you'd like to hear uh join us in the slot Community tell us what you're doing in it because you know we we really go",
    "start": "1112679",
    "end": "1117799"
  },
  {
    "text": "out and see what people are writing and talking about and then we end up talking about that on the show so we we definitely would love feedback and and",
    "start": "1117799",
    "end": "1124760"
  },
  {
    "text": "we in whether it's that or other areas steer Us in directions you want to hear from yeah definitely so uh I noticed",
    "start": "1124760",
    "end": "1131400"
  },
  {
    "text": "that there was another release uh and this time it was from Facebook they open",
    "start": "1131400",
    "end": "1137120"
  },
  {
    "text": "sourced uh their applied enforcement learning platform it's called Horizon and with that I noticed that uh it's",
    "start": "1137120",
    "end": "1144280"
  },
  {
    "text": "pretty cool I think if you're not familiar uh with reinforcement learning that is an aspect to machine learning",
    "start": "1144280",
    "end": "1151080"
  },
  {
    "text": "where you are using a software agent uh to take actions that are in the",
    "start": "1151080",
    "end": "1156600"
  },
  {
    "text": "environment that you're operating in so if you have a a model that you're developing and actions are being taken",
    "start": "1156600",
    "end": "1162360"
  },
  {
    "text": "through those you are trying to reward uh when things are going the right way and you're trying to learn so your model",
    "start": "1162360",
    "end": "1169600"
  },
  {
    "text": "is converging in the right direction you reward it and and and you don't reward it when it doesn't and you see that in a",
    "start": "1169600",
    "end": "1176679"
  },
  {
    "text": "lot of different applications uh everything from different AI learning um how to play games you see it a lot in",
    "start": "1176679",
    "end": "1183960"
  },
  {
    "text": "robotics uh and so it's it's really great to see Facebook open sourcing how they're approaching that because they're",
    "start": "1183960",
    "end": "1190000"
  },
  {
    "text": "doing a lot of work on this so you had you seen that one Daniel yeah this definitely interesting to me um and I'll",
    "start": "1190000",
    "end": "1195559"
  },
  {
    "text": "note as well in a previous episode so episode 14 W Zera talked with us for a whole",
    "start": "1195559",
    "end": "1201559"
  },
  {
    "text": "episode about reinforcement learning it's an area that I definitely want to",
    "start": "1201559",
    "end": "1206720"
  },
  {
    "text": "get up to speed on so I did run across this it it was also one of the things that you know kind of crossed my path",
    "start": "1206720",
    "end": "1213200"
  },
  {
    "text": "multiple times over the past couple of weeks um one of the interesting things that that I thought was interesting",
    "start": "1213200",
    "end": "1219240"
  },
  {
    "text": "about this framework that they open source or really it's it's more of a platform right so this reinforcement",
    "start": "1219240",
    "end": "1225280"
  },
  {
    "text": "learning platform is that it's not kind of it's not just like a a specific library for pie torch or something it is",
    "start": "1225280",
    "end": "1231840"
  },
  {
    "text": "actually like a platform that utilizes multiple open source projects to do help",
    "start": "1231840",
    "end": "1237880"
  },
  {
    "text": "you do the task of of reinforcement learning so I see that spark is involved",
    "start": "1237880",
    "end": "1243360"
  },
  {
    "text": "here along with pytorch along with scipi along with open AI Gem and the Onyx",
    "start": "1243360",
    "end": "1249480"
  },
  {
    "text": "framework which I'm a big fan of and and excited about so you've got the kind of large scale data processing element",
    "start": "1249480",
    "end": "1256880"
  },
  {
    "text": "that's kind of coming from spark um you've got the scientific Computing and numerical machine learning pieces coming",
    "start": "1256880",
    "end": "1263120"
  },
  {
    "text": "from scipi and pytorch and then there's other things as well including model serialization and interoperability",
    "start": "1263120",
    "end": "1269480"
  },
  {
    "text": "that's coming with Onyx so it was really cool to see that this this kind of convergence of multiple different",
    "start": "1269480",
    "end": "1276600"
  },
  {
    "text": "projects to enable this you know what seems like a really great uh platform",
    "start": "1276600",
    "end": "1281960"
  },
  {
    "text": "for actually enabling reinforcement learning and production yeah I noticed uh I was looking across their GitHub",
    "start": "1281960",
    "end": "1288320"
  },
  {
    "text": "page thinking of it as a platform rather than just a library for for another platform you build it in Python uh using",
    "start": "1288320",
    "end": "1294640"
  },
  {
    "text": "pytorch uh for the modeling in the training and then you can serve models with Cafe 2 so it does have it does have",
    "start": "1294640",
    "end": "1302720"
  },
  {
    "text": "dependencies with other you know platforms specifically pytorch and Cafe 2 but it's it's a whole system unto",
    "start": "1302720",
    "end": "1308400"
  },
  {
    "text": "itself yeah yeah and I don't know this was actually pretty surprising to me and",
    "start": "1308400",
    "end": "1314120"
  },
  {
    "text": "maybe this is just my lack of following a lot of reinforcement learning things",
    "start": "1314120",
    "end": "1319480"
  },
  {
    "text": "but it it was kind of a shock to me for them to describe how they are using how Facebook is using reinforcement learning",
    "start": "1319480",
    "end": "1327559"
  },
  {
    "text": "in production so they mention on messenger on 360 video and more and that",
    "start": "1327559",
    "end": "1333480"
  },
  {
    "text": "was a shock to me if if someone was to ask me before I read this article you know who was using reinforcement",
    "start": "1333480",
    "end": "1339559"
  },
  {
    "text": "learning in production I would probably just kind of give them a a blurb about",
    "start": "1339559",
    "end": "1345559"
  },
  {
    "text": "how it's mostly a research thing right now and open a I and deep mine and other people are using it for robots and other",
    "start": "1345559",
    "end": "1351880"
  },
  {
    "text": "things but it's not really it hasn't really filtered into production usage in industry and clearly I'm wrong about",
    "start": "1351880",
    "end": "1358960"
  },
  {
    "text": "that because they're using this you know practical platform for reinforcement",
    "start": "1358960",
    "end": "1364559"
  },
  {
    "text": "learning in production at least on at least on a few things they they say you know Horizon has allowed us to improve",
    "start": "1364559",
    "end": "1371720"
  },
  {
    "text": "the image quality of 360° video optimizing bit rate parameters in real",
    "start": "1371720",
    "end": "1377159"
  },
  {
    "text": "time and and other things so this is actually like uh you know real usage of",
    "start": "1377159",
    "end": "1383120"
  },
  {
    "text": "reinforcement learning rather than just kind of like funny videos of robot arms and stuff yeah this was a pretty big",
    "start": "1383120",
    "end": "1389760"
  },
  {
    "text": "shock to me I have seen it used in industry but it was strictly in robotics uh when I was with a previous employer",
    "start": "1389760",
    "end": "1395600"
  },
  {
    "text": "and we had several teams uh doing some fairly Advanced robotics tasks my team was not we were very much focused on the",
    "start": "1395600",
    "end": "1401919"
  },
  {
    "text": "computer vision side of things with mascar CNN and other convolutional Technologies but yeah I I know another",
    "start": "1401919",
    "end": "1408080"
  },
  {
    "text": "team that we were working with was doing uh reinforcement learning and deep reinforcement learning where you're",
    "start": "1408080",
    "end": "1414440"
  },
  {
    "text": "combining reinforcement learning with with a a deep architecture as well to do that on the robotics side and that's",
    "start": "1414440",
    "end": "1420559"
  },
  {
    "text": "used a lot on kind of uh strategy for robotics movement and things uh so but",
    "start": "1420559",
    "end": "1426640"
  },
  {
    "text": "had been that my own personal experience have been very specific to to that use case yeah and I mean even so I'm looking",
    "start": "1426640",
    "end": "1433320"
  },
  {
    "text": "at their GitHub page for Horizon right now and it says a platform for applied",
    "start": "1433320",
    "end": "1438600"
  },
  {
    "text": "reinforcement learning or applied RL and of course that fits right in with what we're passionate about on this show",
    "start": "1438600",
    "end": "1444520"
  },
  {
    "text": "which is practicality and this has definitely changed my perception of reinforcement learning outside of kind",
    "start": "1444520",
    "end": "1451440"
  },
  {
    "text": "of the domain of robots like you were talking about which I have never worked in robots and so to me reinforcement",
    "start": "1451440",
    "end": "1458080"
  },
  {
    "text": "learning like didn't really come across as something that maybe I would apply",
    "start": "1458080",
    "end": "1463919"
  },
  {
    "text": "directly at least in the near future but um maybe I need to uh re evaluate my my",
    "start": "1463919",
    "end": "1469760"
  },
  {
    "text": "perceptions there and actually I'd love to just kind of go through and see I haven't been through the all of the",
    "start": "1469760",
    "end": "1476080"
  },
  {
    "text": "docks of horizon but it looks like that um you can install it with Docker so it would be fun to just kind of spin up",
    "start": "1476080",
    "end": "1482120"
  },
  {
    "text": "Horizon and say at least say I've done some reinforcement learning I feel like I could you know check that box off of",
    "start": "1482120",
    "end": "1489399"
  },
  {
    "text": "my bucket list at least absolutely I'm and I want to try to find a use case for both Bert and Horizon from a learning",
    "start": "1489399",
    "end": "1495080"
  },
  {
    "text": "standpoint uh to dive into them because you know it's kind of funny uh as we as",
    "start": "1495080",
    "end": "1500720"
  },
  {
    "text": "we talk about these different things in the uh that are are happening in the AI Community um on these fully connected",
    "start": "1500720",
    "end": "1507320"
  },
  {
    "text": "episodes it is uh you have to really pick and choose what you want to do but we're we're seeing so much advancement",
    "start": "1507320",
    "end": "1513120"
  },
  {
    "text": "right now in these areas um so I'm trying to find ways of uh since you don't get to do everything in whatever",
    "start": "1513120",
    "end": "1519039"
  },
  {
    "text": "job you're doing uh in the AI world I'm trying to find small projects where we can apply those so if anyone has ideas I",
    "start": "1519039",
    "end": "1524600"
  },
  {
    "text": "hope you'll share them in the uh slack Community or on LinkedIn LinkedIn group because that would be very welcome",
    "start": "1524600",
    "end": "1530440"
  },
  {
    "text": "things that are scaled that are affordable for people to dive in and have fun with yeah and we'll also uh",
    "start": "1530440",
    "end": "1536640"
  },
  {
    "text": "just so you guys know we always try to include a bunch of links to what we're talking about in our show notes so",
    "start": "1536640",
    "end": "1542240"
  },
  {
    "text": "there's actually I have a list here right now of all of the things about Bert like I said there's been a lot",
    "start": "1542240",
    "end": "1548320"
  },
  {
    "text": "there's been a Google article tensorflow uh GitHub there's been a paper on the archive the pytorch repo New York Times",
    "start": "1548320",
    "end": "1555640"
  },
  {
    "text": "article there's even like a collab note book it's like Jupiter notebook but kind",
    "start": "1555640",
    "end": "1560799"
  },
  {
    "text": "of Google doc style so there's one of those for you to try it out um of course like I mentioned Horizon has the docker",
    "start": "1560799",
    "end": "1567880"
  },
  {
    "text": "um install and all of that so barrier to spinning up a lot of this stuff is a lot",
    "start": "1567880",
    "end": "1573240"
  },
  {
    "text": "lower than it used to be which like you mentioned Chris in in some ways it's uh I mean in a lot of ways it's it's super",
    "start": "1573240",
    "end": "1579799"
  },
  {
    "text": "exciting but in other ways it's like there's too much to try so um I I probably need to to focus my attention a",
    "start": "1579799",
    "end": "1586679"
  },
  {
    "text": "little bit but um yeah so um I think that was pretty much the what we had to",
    "start": "1586679",
    "end": "1591760"
  },
  {
    "text": "say about Horizon I'm excited to dig in more um have you seen anything else uh in the in the news recently Chris that",
    "start": "1591760",
    "end": "1598279"
  },
  {
    "text": "you want to highlight yeah I I ran across a Blog article uh that's called does synthetic data hold the secret to",
    "start": "1598279",
    "end": "1604640"
  },
  {
    "text": "artificial intelligence and and it caught my eye kind of dives into just uh in general uh about synthetic data and",
    "start": "1604640",
    "end": "1611480"
  },
  {
    "text": "how it's used and in terms of generating enough data to operate on the reason it",
    "start": "1611480",
    "end": "1616520"
  },
  {
    "text": "really caught my eye is I had some personal experience expence um from my own work having to do with synthetic",
    "start": "1616520",
    "end": "1621559"
  },
  {
    "text": "data and I also was uh interviewed uh a short while back by Thompson Reuters on",
    "start": "1621559",
    "end": "1628120"
  },
  {
    "text": "a series of AI articles that they were posting on that and I've I've tweeted if anyone has an interest I've tweeted",
    "start": "1628120",
    "end": "1633799"
  },
  {
    "text": "about it and stuff and you can find the article but really talking about using synthetic data going forward to generate",
    "start": "1633799",
    "end": "1640360"
  },
  {
    "text": "larger data sets uh how it fits into unsupervised learning uh for the future and in my own experience I found a lot",
    "start": "1640360",
    "end": "1647799"
  },
  {
    "text": "of people tend to say yeah we'll just synthesize the data you know and there's a variety of techniques for that we",
    "start": "1647799",
    "end": "1653840"
  },
  {
    "text": "found it very hard to do that and I'm hoping that uh on on our on my own learning curve that me and the people uh",
    "start": "1653840",
    "end": "1660159"
  },
  {
    "text": "on the teams that I've worked with can can figure out better but that can be really challenging so the article caught",
    "start": "1660159",
    "end": "1665559"
  },
  {
    "text": "my eye because of the The Hope forward and I and as well as everybody does I would love to be able to say if I want",
    "start": "1665559",
    "end": "1671320"
  },
  {
    "text": "to hit a particular use case and don't have sufficient data we can go synthesize the data and train it when we",
    "start": "1671320",
    "end": "1676919"
  },
  {
    "text": "were doing that manually in terms of trying to generate through uh a number of automated things that a company I",
    "start": "1676919",
    "end": "1682960"
  },
  {
    "text": "used to work at we found that the the data set we had a small data set that represented the real life problem that",
    "start": "1682960",
    "end": "1689880"
  },
  {
    "text": "we were tackling uh and I'm not allowed to disclose what that was but we also we",
    "start": "1689880",
    "end": "1695640"
  },
  {
    "text": "didn't have nearly enough to address it and so uh I we we went and tried to synthesize it through a bunch of",
    "start": "1695640",
    "end": "1701120"
  },
  {
    "text": "different techniques and we found that the uh we really had a struggle with getting enough diversity into the data",
    "start": "1701120",
    "end": "1707320"
  },
  {
    "text": "we could generate the volume but it was very hard to synthesize the diversity that we needed to where our goal had",
    "start": "1707320",
    "end": "1713559"
  },
  {
    "text": "been if you take a synthetic data set and compare it side by side with the real much smaller data set that we",
    "start": "1713559",
    "end": "1719320"
  },
  {
    "text": "already had that it would be indistinguishable or close to that so I would love to hear back from listeners",
    "start": "1719320",
    "end": "1725279"
  },
  {
    "text": "and I would love to hear Daniel if you have any thoughts on that about how people are approaching synthetic data um",
    "start": "1725279",
    "end": "1731679"
  },
  {
    "text": "and and some of the different techniques and successes or failures that they've had yeah maybe just to kind of uh pause",
    "start": "1731679",
    "end": "1738640"
  },
  {
    "text": "a little bit because I I actually I don't have a lot of experience this whole idea of synthetic data but you",
    "start": "1738640",
    "end": "1744240"
  },
  {
    "text": "know what I'm thinking when I hear you talk about this is like you know hey Chris like what exactly do you mean by",
    "start": "1744240",
    "end": "1749600"
  },
  {
    "text": "synthetic data because uh isn't data just data I think you kind of got into that but maybe you could describe like",
    "start": "1749600",
    "end": "1756440"
  },
  {
    "text": "maybe a little bit more about why there is a need for synthetic data that's a great point so I'm kind of referencing",
    "start": "1756440",
    "end": "1762320"
  },
  {
    "text": "in my brain my own project but because of non-disclosure issues I can't address it directly so I'll I will try it is",
    "start": "1762320",
    "end": "1768760"
  },
  {
    "text": "often times the case in in industry in the real world when you're trying to tackle a business problem in the case",
    "start": "1768760",
    "end": "1775559"
  },
  {
    "text": "that we were in it was to enhance an existing product and you will say okay",
    "start": "1775559",
    "end": "1781519"
  },
  {
    "text": "this is what we need to go solve that problem for training purposes and but",
    "start": "1781519",
    "end": "1786720"
  },
  {
    "text": "when you look at the amount of data that you have you realize that you might need hundreds of thousands of Records or",
    "start": "1786720",
    "end": "1792640"
  },
  {
    "text": "millions of Records to train against and you might have you know uh 2,000 or",
    "start": "1792640",
    "end": "1798559"
  },
  {
    "text": "or less maybe a few hundred and that's and that might not be nearly enough to get a high quality model trained for",
    "start": "1798559",
    "end": "1803960"
  },
  {
    "text": "your purposes so one of the things that people will do is say are there ways that we can generate our own sense of",
    "start": "1803960",
    "end": "1811440"
  },
  {
    "text": "reality that looks very much like the real thing so you're generating more data that looks a whole lot like the",
    "start": "1811440",
    "end": "1816720"
  },
  {
    "text": "data that you already have but you need more volume and there's a number of different software packages that can",
    "start": "1816720",
    "end": "1822399"
  },
  {
    "text": "help you do that and we tried some different techniques in this project that we were working on the challenge",
    "start": "1822399",
    "end": "1827440"
  },
  {
    "text": "that we had there was was simply having uh enough variability enough diversity",
    "start": "1827440",
    "end": "1833600"
  },
  {
    "text": "in the synthesized data so that if you were to hold those two data sets up the synthesize versus the real life one the",
    "start": "1833600",
    "end": "1840000"
  },
  {
    "text": "real life one was messy it had all of the the little tweaks and diversity as you change things in real life and you",
    "start": "1840000",
    "end": "1846559"
  },
  {
    "text": "get noisy messy data to train off of that represents the real world that you're trying to to get a model to",
    "start": "1846559",
    "end": "1852200"
  },
  {
    "text": "represent that's what it is it's very hard to do uh at least in the stuff that we had done it was very hard to generate",
    "start": "1852200",
    "end": "1857639"
  },
  {
    "text": "syn ized data that didn't look synthesized that had so much diversity that you would never realize it was",
    "start": "1857639",
    "end": "1863840"
  },
  {
    "text": "gener the number of different options for various inputs that kind of thing as I go forward and I I'm sure this will",
    "start": "1863840",
    "end": "1869679"
  },
  {
    "text": "come up in the not too distant future where we have to take a synthetic data approach I'm looking forward to having",
    "start": "1869679",
    "end": "1874960"
  },
  {
    "text": "other people out there say hey this is what uh worked for me or what didn't work for me yeah I was just looking as",
    "start": "1874960",
    "end": "1880600"
  },
  {
    "text": "as you were talking um at you know models like we're talking about here which I'm I'm assuming like the models",
    "start": "1880600",
    "end": "1887480"
  },
  {
    "text": "that you were talking about in in your use case but other cases like robotics or natural language like the Bert model",
    "start": "1887480",
    "end": "1893919"
  },
  {
    "text": "says it has you know like you know hundreds of of millions of parameters right so to train that many parameters",
    "start": "1893919",
    "end": "1901159"
  },
  {
    "text": "to fit that many parameters takes an enormous amount of data usually which",
    "start": "1901159",
    "end": "1906200"
  },
  {
    "text": "sometimes you just don't have don't have access to I'm glad you brought up this point it's something that I definitely",
    "start": "1906200",
    "end": "1912039"
  },
  {
    "text": "feel like I need to learn a little bit more about and would be interested to hear from any of our listeners if they",
    "start": "1912039",
    "end": "1917120"
  },
  {
    "text": "have good resour ources or or pointers on on that front yeah I would note the use case that we were generating from",
    "start": "1917120",
    "end": "1923200"
  },
  {
    "text": "I'll say it was not a convolutional I've also done it on the convolutional side with more success because you can take",
    "start": "1923200",
    "end": "1929080"
  },
  {
    "text": "the images that you're using in your convolutional neural network and make adjustments you can change angles change",
    "start": "1929080",
    "end": "1934559"
  },
  {
    "text": "sizing flip them or some sort of stuff yeah there's a lot of image manipulation things you can do to generate more data",
    "start": "1934559",
    "end": "1941080"
  },
  {
    "text": "there so had great success there unfortunately the use case that I was kind of describing around was not that",
    "start": "1941080",
    "end": "1946880"
  },
  {
    "text": "so I just wanted to to to distinguish between the two I think it's I think it's easier with certain types of architectures than other yeah yeah well",
    "start": "1946880",
    "end": "1954279"
  },
  {
    "text": "on that note you know noting that we we all have a lot to learn about multiple",
    "start": "1954279",
    "end": "1959320"
  },
  {
    "text": "things let's go ahead and you know move into the part of fully connected where we where we highlight a couple of",
    "start": "1959320",
    "end": "1964919"
  },
  {
    "text": "learning resources that have been useful for us or look interesting the first one that I'm going to point out which is",
    "start": "1964919",
    "end": "1970960"
  },
  {
    "text": "something that I want to look into a little bit more and maybe order the physical copy of is um there's a new",
    "start": "1970960",
    "end": "1978360"
  },
  {
    "text": "or almost I don't know if it's actually out yet but um it's called grocking Deep learning and there's a physical an ebook",
    "start": "1978360",
    "end": "1987600"
  },
  {
    "text": "from Manning called grocking Deep learning but one of the things that I was looking at was that there's also a",
    "start": "1987600",
    "end": "1993679"
  },
  {
    "text": "kind of companion GitHub repository which itself is kind of helpful even",
    "start": "1993679",
    "end": "1999720"
  },
  {
    "text": "maybe even without the book because it goes through like from the beginning kind of from scratch how do we how do we",
    "start": "1999720",
    "end": "2006480"
  },
  {
    "text": "kind of understand and dig into deep learning so it goes through you know forward propagation and introduction to",
    "start": "2006480",
    "end": "2012679"
  },
  {
    "text": "neural networks gradient descent generalizing that back propagation regularization activation functions and",
    "start": "2012679",
    "end": "2019720"
  },
  {
    "text": "really kind of starts to pick apart like convolutional layers and word embeddings and other things more from a scratch",
    "start": "2019720",
    "end": "2026720"
  },
  {
    "text": "perspective and trying to get into those things so I think that this would be a great thing to go through if you're",
    "start": "2026720",
    "end": "2032840"
  },
  {
    "text": "wanting to really kind of understand deep learning and neural n works at a",
    "start": "2032840",
    "end": "2039159"
  },
  {
    "text": "more granular level I have the book and have read it and it is very good um",
    "start": "2039159",
    "end": "2044519"
  },
  {
    "text": "compared to a lot of books where where they don't give you a sufficient understanding the the grocking part of",
    "start": "2044519",
    "end": "2050398"
  },
  {
    "text": "the title I think is accurate and that they is that the author really tries to explain those and so having having the",
    "start": "2050399",
    "end": "2056440"
  },
  {
    "text": "examples in the GitHub which I had not looked at actually is really nice to have in the book so I I know I've read",
    "start": "2056440",
    "end": "2062679"
  },
  {
    "text": "that and enjoyed reading it and thought it was one of the better explanations out there so definitely concur with that well I'm glad that uh that I wasn't",
    "start": "2062679",
    "end": "2069720"
  },
  {
    "text": "making uh wrong assumptions there the I have one that's very specific and I've",
    "start": "2069720",
    "end": "2075240"
  },
  {
    "text": "done other uh I've I've talked about this in different articles but there on medium I found a uh medium post I",
    "start": "2075240",
    "end": "2082800"
  },
  {
    "text": "probably am going to butcher the name it's uh Natalie jeans J A ANS on medium",
    "start": "2082800",
    "end": "2088320"
  },
  {
    "text": "it looks like it's her only article that I see here but it's the back propagation algorithm demystified and it's another",
    "start": "2088320",
    "end": "2094839"
  },
  {
    "text": "really good explanation a lot of people is is were getting into the field you know this one of the the very first",
    "start": "2094839",
    "end": "2100720"
  },
  {
    "text": "things you learn and actually if you haven't been exposed to back propagation it can take a while to really understand",
    "start": "2100720",
    "end": "2106119"
  },
  {
    "text": "it and get it and so I thought this was one of those articles that if you're a newbie into the field and you're trying",
    "start": "2106119",
    "end": "2111800"
  },
  {
    "text": "to understand just how feed forward with B propagation works this is another good place to start she takes you kind of",
    "start": "2111800",
    "end": "2118200"
  },
  {
    "text": "through the initial Concepts about you know the the inputs to a node and what",
    "start": "2118200",
    "end": "2123400"
  },
  {
    "text": "it means to have an activation function and and what those are and kind of describes bat propagation at high level",
    "start": "2123400",
    "end": "2130040"
  },
  {
    "text": "and then she goes into gradient descent and there's that's a group of different related algorithms gradient descent that",
    "start": "2130040",
    "end": "2137560"
  },
  {
    "text": "allow you to minimize your error and she has some good visuals and some great explanation on that she talks about what",
    "start": "2137560",
    "end": "2144240"
  },
  {
    "text": "those different variants are and then kind of takes you through some examples uh using sigmoid which is not often used",
    "start": "2144240",
    "end": "2152119"
  },
  {
    "text": "in real life these days but is a is a good training tool that people will use uh and then actually goes to what people",
    "start": "2152119",
    "end": "2157359"
  },
  {
    "text": "do use in real life which is um back propagating rectified linear units or you might hear it as relu and so did a",
    "start": "2157359",
    "end": "2164520"
  },
  {
    "text": "good job of kind of giving you uh a good uh a good stab at understanding that is",
    "start": "2164520",
    "end": "2169599"
  },
  {
    "text": "so I I I hope people will go see it we'll put the link in the show notes and that's it for me this week you have anything else Daniel or you nope that's",
    "start": "2169599",
    "end": "2176599"
  },
  {
    "text": "it I think those are great and I think it's great that you brought up today how you know we just like everyone else even",
    "start": "2176599",
    "end": "2183319"
  },
  {
    "text": "though they don't always admit it are always searching through Kora always searching through stack Overflow and and",
    "start": "2183319",
    "end": "2189440"
  },
  {
    "text": "GitHub and papers and all of that if you if you run across any good ones that we haven't highlighted let us know on our",
    "start": "2189440",
    "end": "2195560"
  },
  {
    "text": "slack team and um and uh yeah it was it was great discussion today thanks for being patient uh with me Chris and uh",
    "start": "2195560",
    "end": "2203359"
  },
  {
    "text": "helping me dig through some of these things yeah I had I had a good time this was a slightly different type of show than anything we've done in terms of our",
    "start": "2203359",
    "end": "2210280"
  },
  {
    "text": "just you and me digging in ourselves and digging in not as uh experts but as many of our listeners just trying to to take",
    "start": "2210280",
    "end": "2216960"
  },
  {
    "text": "it so I I hope it made sense to our listeners and uh if we get good feedback I'm looking forward to uh to talking",
    "start": "2216960",
    "end": "2222839"
  },
  {
    "text": "about specific Technologies some more in the future awesome okay well I hope everybody has a great week and we will",
    "start": "2222839",
    "end": "2229319"
  },
  {
    "text": "talk to you sometime soon talk to you later Daniel all right see you Chris okay bye",
    "start": "2229319",
    "end": "2235200"
  },
  {
    "text": "bye all right thank you for tuning in to this episode of practical AI if you enjoyed the show do us a favor go on",
    "start": "2235480",
    "end": "2241480"
  },
  {
    "text": "iTunes give us a rating go in your podcast app and favorite it if you are on Twitter or social network share a",
    "start": "2241480",
    "end": "2246880"
  },
  {
    "text": "link with a friend whatever you got to do share the show with a friend if you enjoyed it and band with for change log is provided by fastly learn more at",
    "start": "2246880",
    "end": "2253640"
  },
  {
    "text": "fastly.com and we catch our erors before our users do here at changelog because of robar check them out at roar.com",
    "start": "2253640",
    "end": "2259920"
  },
  {
    "text": "changelog and we're hosted on lenoe cloud servers head to l.com changelog",
    "start": "2259920",
    "end": "2265400"
  },
  {
    "text": "check them out support this show this episode is hosted by Daniel whack and Chris Benson editing is done by Tim",
    "start": "2265400",
    "end": "2271839"
  },
  {
    "text": "Smith the music is by break master cylinder and you can find more shows just like this at Ang law.com when you",
    "start": "2271839",
    "end": "2278880"
  },
  {
    "text": "go there pop in your email address get our weekly email keeping you up to date with the news and podcast for developers",
    "start": "2278880",
    "end": "2285000"
  },
  {
    "text": "in your inbox every single week thanks for tuning in we'll see you next [Music]",
    "start": "2285000",
    "end": "2292669"
  },
  {
    "text": "week I'm Tim Smith and my show away from keyboard explores The Human Side of creative work you'll hear stories",
    "start": "2293839",
    "end": "2300760"
  },
  {
    "text": "sometimes deeply personal about the triumphs and struggles of doing what you love I ended up in hospital with out I",
    "start": "2300760",
    "end": "2308200"
  },
  {
    "text": "just kept ignoring the way that it was making me feel and just kept powering through it and then eventually my body",
    "start": "2308200",
    "end": "2313920"
  },
  {
    "text": "started to give me physical symptoms to say like hey you should stop and listen to me new episodes Premiere every other",
    "start": "2313920",
    "end": "2320720"
  },
  {
    "text": "Wednesday find the show at changel log.com AFK or wherever you listen to",
    "start": "2320720",
    "end": "2325970"
  },
  {
    "text": "[Music]",
    "start": "2325970",
    "end": "2332200"
  },
  {
    "text": "podcasts",
    "start": "2332200",
    "end": "2335200"
  }
]
[
  {
    "text": "[Music]",
    "start": "0",
    "end": "15730"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspire to or are",
    "start": "16600",
    "end": "23800"
  },
  {
    "text": "curious how AI related Tech is changing the world this is the show for you thank",
    "start": "23800",
    "end": "30320"
  },
  {
    "text": "you to our partners at fly.io the home of changel log.com learn more at",
    "start": "30320",
    "end": "37220"
  },
  {
    "text": "[Music]",
    "start": "37220",
    "end": "47360"
  },
  {
    "text": "fly.io well our friends over at Speak Easy have the complete platform for API",
    "start": "47360",
    "end": "52719"
  },
  {
    "text": "developer experience they can generate sdks terraform providers API testing",
    "start": "52719",
    "end": "58440"
  },
  {
    "text": "docks and more and and they just released a new version of their python SDK generation it's optimized for anyone",
    "start": "58440",
    "end": "66080"
  },
  {
    "text": "building an AI API every python SDK comes with pantic models for request and",
    "start": "66080",
    "end": "72320"
  },
  {
    "text": "response objects and httpx client for async and synchronous",
    "start": "72320",
    "end": "77920"
  },
  {
    "text": "method calls and support for Server sent events as well Speak Easy is everything",
    "start": "77920",
    "end": "84159"
  },
  {
    "text": "you need to give your python users an amazing experience integrating with your API learn more at at speak easy.com",
    "start": "84159",
    "end": "92079"
  },
  {
    "text": "python again speak easy.com [Music]",
    "start": "92079",
    "end": "102670"
  },
  {
    "text": "python welcome to another episode of practical AI this is Daniel whack I am",
    "start": "106360",
    "end": "113399"
  },
  {
    "text": "the founder and CEO at prediction guard and I would normally be recording with",
    "start": "113399",
    "end": "119960"
  },
  {
    "text": "with my co-host Chris uh but he has had to be out for for a couple weeks um and",
    "start": "119960",
    "end": "127000"
  },
  {
    "text": "I was thinking during this time I've been doing a bit of teaching at different conferences and I've kind of",
    "start": "127000",
    "end": "134200"
  },
  {
    "text": "honed in on a set of interesting learning materials that I thought would",
    "start": "134200",
    "end": "140120"
  },
  {
    "text": "be a great thing to share here we have these episodes normally called fully connected episodes and these are where",
    "start": "140120",
    "end": "147360"
  },
  {
    "text": "Chris and I keep you kind of connected to every that's happening in the AI news",
    "start": "147360",
    "end": "153040"
  },
  {
    "text": "and Trends but also try to provide some learning resources and what I found as",
    "start": "153040",
    "end": "158519"
  },
  {
    "text": "I've gone to different conferences and given workshops is that sometimes",
    "start": "158519",
    "end": "164400"
  },
  {
    "text": "there's a bit of confusion around two things one is that AI equals generative",
    "start": "164400",
    "end": "171680"
  },
  {
    "text": "Ai and that's you know not surprising because there's so much that we hear",
    "start": "171680",
    "end": "177959"
  },
  {
    "text": "about generative AI even on this podcast we've of course talked about it a lot that there's this Association that sort",
    "start": "177959",
    "end": "185200"
  },
  {
    "text": "of anything AI is generative AI but then there's another thing another notion",
    "start": "185200",
    "end": "192159"
  },
  {
    "text": "which is this idea of not knowing kind of how generative AI came about and it",
    "start": "192159",
    "end": "199640"
  },
  {
    "text": "kind of popped out of nowhere when in reality there was a sort of progression",
    "start": "199640",
    "end": "204760"
  },
  {
    "text": "towards generative Ai and it fits within a landscape of AI and machine learning",
    "start": "204760",
    "end": "210120"
  },
  {
    "text": "and data science that has been going on for some time so I thought it would be good in this particular fully connected",
    "start": "210120",
    "end": "217879"
  },
  {
    "text": "episode or this episode where it's actually just me so sorry to disappoint those out there that don't want to hear",
    "start": "217879",
    "end": "224879"
  },
  {
    "text": "more of my voice but it's just me today and I'm gonna go through some of this",
    "start": "224879",
    "end": "231159"
  },
  {
    "text": "kind of distilled set of learning resources that kind of set AI within the",
    "start": "231159",
    "end": "237280"
  },
  {
    "text": "context of a wider set of methodologies and a history of development and then",
    "start": "237280",
    "end": "244000"
  },
  {
    "text": "also maybe help us understand the landscape of AI methodologies Beyond",
    "start": "244000",
    "end": "250439"
  },
  {
    "text": "generative Ai and how those things are are still used quite a bit and might even be combined with generative AI in",
    "start": "250439",
    "end": "258199"
  },
  {
    "text": "very interesting ways so that's what we're going to embark on today is is a little bit of a tour of AI machine",
    "start": "258199",
    "end": "265199"
  },
  {
    "text": "learning history setting generative AI in that history and along the way we'll",
    "start": "265199",
    "end": "270800"
  },
  {
    "text": "talk about kind of the Practical things and the knowledge that you might want to go out and research more if you're",
    "start": "270800",
    "end": "276919"
  },
  {
    "text": "interested in any of these different kinds of techniques that are still used quite widely outside of generative AI so",
    "start": "276919",
    "end": "285840"
  },
  {
    "text": "let's go ahead and get going um there there's kind of a first generation or first phase in my mind of what I think",
    "start": "285840",
    "end": "293840"
  },
  {
    "text": "of with AI and machine learning and that's kind of 2017 and prior",
    "start": "293840",
    "end": "300320"
  },
  {
    "text": "or a lot of times what I think of since I've only been alive for a certain",
    "start": "300320",
    "end": "306080"
  },
  {
    "text": "period of time and been working professionally I kind of think of this as the 2010 to",
    "start": "306080",
    "end": "312039"
  },
  {
    "text": "2017 period that I would label kind of that data science statistical machine",
    "start": "312039",
    "end": "317400"
  },
  {
    "text": "learning period this is the time when I first started getting into data science",
    "start": "317400",
    "end": "323000"
  },
  {
    "text": "when I came out of Academia and this phase of data science machine learning",
    "start": "323000",
    "end": "329759"
  },
  {
    "text": "really focused on kind of smallscale model building and models that were",
    "start": "329759",
    "end": "335199"
  },
  {
    "text": "sometimes neural networks and sometimes they weren't neural networks they might be radiant boosted machines or decision",
    "start": "335199",
    "end": "342880"
  },
  {
    "text": "trees or other things like this and during this phase of data science AI",
    "start": "342880",
    "end": "348960"
  },
  {
    "text": "machine learning development the kind of primary role of those working in this",
    "start": "348960",
    "end": "355039"
  },
  {
    "text": "field was to curate a set of example input and kind of known outputs we",
    "start": "355039",
    "end": "362280"
  },
  {
    "text": "talked about this a little bit in a previous episode when we talked about it's all about the data but this would",
    "start": "362280",
    "end": "367599"
  },
  {
    "text": "be training data where we have example inputs and known outputs and then we",
    "start": "367599",
    "end": "372919"
  },
  {
    "text": "also have a software function which is parameterized and what I mean by",
    "start": "372919",
    "end": "379639"
  },
  {
    "text": "parameterized is think about what a software function does a software function is a data transformation I have",
    "start": "379639",
    "end": "386280"
  },
  {
    "text": "inputs to that software function and I have outputs of that software function and if you think about some software",
    "start": "386280",
    "end": "393160"
  },
  {
    "text": "functions they could be parameterized or they could have parameters so let's take",
    "start": "393160",
    "end": "398319"
  },
  {
    "text": "the example of object recognition right that the software function that executes",
    "start": "398319",
    "end": "405680"
  },
  {
    "text": "that data transformation of an image in and a set of labels out or maybe just a",
    "start": "405680",
    "end": "412000"
  },
  {
    "text": "set of binary out is there a cat or is there not a cat in this image that's a",
    "start": "412000",
    "end": "417199"
  },
  {
    "text": "data transformation from an image to a label and inside of that software function we",
    "start": "417199",
    "end": "423199"
  },
  {
    "text": "could think about a really dumb software function that could execute this so for example think about all of the pixel",
    "start": "423199",
    "end": "430599"
  },
  {
    "text": "values of that image I put that image in my software function I could just",
    "start": "430599",
    "end": "436240"
  },
  {
    "text": "calculate you know the percentage of red pixels in that image and if that",
    "start": "436240",
    "end": "442599"
  },
  {
    "text": "percentage is above a certain number greater than or equal to I could say it's a cat and if it's less than I could",
    "start": "442599",
    "end": "448720"
  },
  {
    "text": "say not not cat that's a really terrible function to do this data transformation",
    "start": "448720",
    "end": "453919"
  },
  {
    "text": "but it would operate in software right now me as as a developer I could choose",
    "start": "453919",
    "end": "462319"
  },
  {
    "text": "an appropriate percentage for that parameter the parameter that is the",
    "start": "462319",
    "end": "467560"
  },
  {
    "text": "percentage of red pixels and that might be an expert knowledge that I encode",
    "start": "467560",
    "end": "472680"
  },
  {
    "text": "into the system but I would hardcode it but maybe I don't know the exact value",
    "start": "472680",
    "end": "478720"
  },
  {
    "text": "for that parameter and so what am I to do well I could as a software engineer as a developer engineer I could actually",
    "start": "478720",
    "end": "486400"
  },
  {
    "text": "execute an a separate process that's iterative and actually try all the",
    "start": "486400",
    "end": "492560"
  },
  {
    "text": "parameters under the you know that are possible all of the values for percentages that are possible and",
    "start": "492560",
    "end": "499759"
  },
  {
    "text": "because I have a set of example inputs and example outputs I could try that set",
    "start": "499759",
    "end": "505440"
  },
  {
    "text": "of parameters for all of my example inputs and outputs and just choose the one that gives me the best results in",
    "start": "505440",
    "end": "512039"
  },
  {
    "text": "other words the most accurate results and then I would set that as an ideal parameter which was found or fitted or",
    "start": "512039",
    "end": "520479"
  },
  {
    "text": "trained and that's what's happening in a training process in this kind of 2010 to",
    "start": "520479",
    "end": "526200"
  },
  {
    "text": "2017 statistical machine learning supervised learning way of going about",
    "start": "526200",
    "end": "531399"
  },
  {
    "text": "things now I'm being a little bit General here obviously there's a whole variety of other methods that are maybe",
    "start": "531399",
    "end": "537800"
  },
  {
    "text": "unsupervised methods um if you're curious about those you could look up clustering um there's kind of",
    "start": "537800",
    "end": "543800"
  },
  {
    "text": "semisupervised methods and and other things you you can look at those and I'll talk about actually some of that",
    "start": "543800",
    "end": "550279"
  },
  {
    "text": "here in a second but generally that's how the process would go I would choose a function that would be",
    "start": "550279",
    "end": "557959"
  },
  {
    "text": "parameterized I would put in a set of example inputs and known outputs to a",
    "start": "557959",
    "end": "563680"
  },
  {
    "text": "training function that's iterative and I would find the ideal set of those",
    "start": "563680",
    "end": "568880"
  },
  {
    "text": "parameters and then once I found the ideal set of those parameters then I can use that",
    "start": "568880",
    "end": "574800"
  },
  {
    "text": "ideal set of parameters in my function to process new inputs which is called",
    "start": "574800",
    "end": "580680"
  },
  {
    "text": "inference or prediction now that function if you think about what what is the model in this case the quote unquote",
    "start": "580680",
    "end": "587720"
  },
  {
    "text": "model the machine learning the statistical model here the machine learning or statistical model here would",
    "start": "587720",
    "end": "594560"
  },
  {
    "text": "be the combination of the software function and the set of paramet that are",
    "start": "594560",
    "end": "599920"
  },
  {
    "text": "needed to execute that software function for inference or prediction those",
    "start": "599920",
    "end": "605079"
  },
  {
    "text": "together in my mind form the model you need both of them and that's why people",
    "start": "605079",
    "end": "610200"
  },
  {
    "text": "are maybe confused about how to license models because some people might use licenses for code some people might use",
    "start": "610200",
    "end": "617360"
  },
  {
    "text": "licenses for data and other people might make up their own because they don't know which one is right so this is kind",
    "start": "617360",
    "end": "624120"
  },
  {
    "text": "of that 2010 to 2017 era of data science machine learning and this is still used widely",
    "start": "624120",
    "end": "631160"
  },
  {
    "text": "if you're curious about this you might listen to the episode about broccoli ai ai that's good for you this was uh",
    "start": "631160",
    "end": "638480"
  },
  {
    "text": "bingson who uh created this sort of model an NLP classification model for a",
    "start": "638480",
    "end": "645079"
  },
  {
    "text": "real use case and um this fits a variety of use cases so time series forecasting",
    "start": "645079",
    "end": "652160"
  },
  {
    "text": "right where you have a Time series and then you're trying to predict future values or you have images like I said",
    "start": "652160",
    "end": "658480"
  },
  {
    "text": "and you're trying to predict labels or you have text input you're trying to classify that into spam or not spam it's",
    "start": "658480",
    "end": "666160"
  },
  {
    "text": "a whole variety of of things around classification which is that labeling",
    "start": "666160",
    "end": "671560"
  },
  {
    "text": "regression which is a prediction of a continuous value like a like a score",
    "start": "671560",
    "end": "677279"
  },
  {
    "text": "something like that and so there's there's a lot of these methods they're still used very widely if you want to",
    "start": "677279",
    "end": "683440"
  },
  {
    "text": "think practically about this most of these models especially the smaller",
    "start": "683440",
    "end": "688480"
  },
  {
    "text": "scale ones might not even need a GPU to train them or to execute the inference",
    "start": "688480",
    "end": "694360"
  },
  {
    "text": "at least at many different scales but as the model grows of course it's it's",
    "start": "694360",
    "end": "700800"
  },
  {
    "text": "harder to execute and in particular you know during this phase neural networks were trained and neural networks have",
    "start": "700800",
    "end": "707399"
  },
  {
    "text": "been around for a while and that's just a function that has a bunch of these",
    "start": "707399",
    "end": "712600"
  },
  {
    "text": "subf functions in it that take input again executing a data transformation",
    "start": "712600",
    "end": "718360"
  },
  {
    "text": "but the goal of this sort of neural network is to model more generally a complicated relationship from input to",
    "start": "718360",
    "end": "725560"
  },
  {
    "text": "Output without you sort of from the start you know using a lot of your",
    "start": "725560",
    "end": "730839"
  },
  {
    "text": "expert information to uh construct the architecture of that of that particular",
    "start": "730839",
    "end": "737040"
  },
  {
    "text": "function it's more generalizable maybe so this is this first phase um again",
    "start": "737040",
    "end": "744160"
  },
  {
    "text": "keeping things practical in this phase there is a practitioner that's often times curating data working with domain",
    "start": "744160",
    "end": "751600"
  },
  {
    "text": "experts they might be using an mlops platform like a weights and biases or",
    "start": "751600",
    "end": "757440"
  },
  {
    "text": "maybe a a larger platform like a data bricks or something like that to train models often update them often store",
    "start": "757440",
    "end": "764560"
  },
  {
    "text": "them in a repository monitor them and so there was a lot of kind of iterative model",
    "start": "764560",
    "end": "770360"
  },
  {
    "text": "training model monitoring all of those things that still goes on quite a bit in",
    "start": "770360",
    "end": "777320"
  },
  {
    "text": "in Industry so so that gets us to around the era of or the year 2017 now",
    "start": "777320",
    "end": "785639"
  },
  {
    "text": "2017 there's some interesting things that happen and that has to do with",
    "start": "785639",
    "end": "792240"
  },
  {
    "text": "Foundation models and transfer learning so in that first phase that I talked",
    "start": "792240",
    "end": "799160"
  },
  {
    "text": "about most of what I was talking about was training a model from scratch in",
    "start": "799160",
    "end": "804480"
  },
  {
    "text": "other words you have a software function with a set of PR parameters those",
    "start": "804480",
    "end": "810399"
  },
  {
    "text": "parameters need to be fit you use a training process to train those and",
    "start": "810399",
    "end": "815560"
  },
  {
    "text": "often times you might start those parameters out in that training process either in a random sort of way or maybe",
    "start": "815560",
    "end": "823240"
  },
  {
    "text": "according to a specific distribution But ultimately you're kind of starting from scratch you you don't have a great place",
    "start": "823240",
    "end": "829199"
  },
  {
    "text": "to start with those parameters in this Foundation model world or transfer learning um if you",
    "start": "829199",
    "end": "836199"
  },
  {
    "text": "remember around 2017 I think Google released uh Bert around this time and",
    "start": "836199",
    "end": "841759"
  },
  {
    "text": "others released other models and I think what people found was if you're doing",
    "start": "841759",
    "end": "847240"
  },
  {
    "text": "kind of these tasks generally with maybe text inputs or image inputs like with a",
    "start": "847240",
    "end": "853600"
  },
  {
    "text": "YOLO model or uh or text inputs like with a Bert based Model A lot of these",
    "start": "853600",
    "end": "861440"
  },
  {
    "text": "tasks were very similar one to another so if you think about doing object",
    "start": "861440",
    "end": "867759"
  },
  {
    "text": "recognition maybe you know Google trains a model that recognizes 10 different classes in",
    "start": "867759",
    "end": "875560"
  },
  {
    "text": "images an airplane and a car and a dog and a cat and Etc and you maybe want to",
    "start": "875560",
    "end": "882920"
  },
  {
    "text": "do something specific to your domain or your company maybe you're an agriculture company and you want to take pictures of",
    "start": "882920",
    "end": "889560"
  },
  {
    "text": "bugs on plants and classify those to keep track of what bugs are in your field or something like that well that's",
    "start": "889560",
    "end": "897079"
  },
  {
    "text": "that's a very similar task to the general object recognition task that",
    "start": "897079",
    "end": "903480"
  },
  {
    "text": "this model was already trained on and so the key piece or the kind of one of the",
    "start": "903480",
    "end": "908680"
  },
  {
    "text": "key shifts that we saw during this period of foundation models and transfer learning was that a large player like",
    "start": "908680",
    "end": "917800"
  },
  {
    "text": "Google or you know a big tech company or a set of academics actually might train",
    "start": "917800",
    "end": "924759"
  },
  {
    "text": "a very large scale model meaning they might have millions of example inputs and outputs and the model or the",
    "start": "924759",
    "end": "931319"
  },
  {
    "text": "function itself might have millions of parameters and they train on a huge",
    "start": "931319",
    "end": "936959"
  },
  {
    "text": "amount of data that model and output an ideal set of parameters that's a really",
    "start": "936959",
    "end": "942959"
  },
  {
    "text": "really good starting point for anyone that wants to Downstream carry on the fine-tuning OR",
    "start": "942959",
    "end": "950360"
  },
  {
    "text": "carry on the training of that in a process called fine-tuning to produce their own domain specific model now this",
    "start": "950360",
    "end": "959399"
  },
  {
    "text": "fine-tuning process that that we've been talking about you would need very a very",
    "start": "959399",
    "end": "965880"
  },
  {
    "text": "small scale of data to train or uh continue the training or fine-tune that",
    "start": "965880",
    "end": "971800"
  },
  {
    "text": "model as compared to the original data set that trained the model from scratch",
    "start": "971800",
    "end": "977199"
  },
  {
    "text": "and if you want to kind of get some intuition about this generally if you think about the size of the model like",
    "start": "977199",
    "end": "983440"
  },
  {
    "text": "one with millions of parameters or even tens of millions or hundreds of millions or billions of parameters",
    "start": "983440",
    "end": "989759"
  },
  {
    "text": "you need a lot of data to fit each of those billions of parameters you can think if you have billions of parameters",
    "start": "989759",
    "end": "996360"
  },
  {
    "text": "and 10 data points that's not very much data to train billions of parameters",
    "start": "996360",
    "end": "1001800"
  },
  {
    "text": "maybe not enough to train even a linear regression model you could do maybe a",
    "start": "1001800",
    "end": "1006920"
  },
  {
    "text": "better job there so you need a a lot of data to train this larger model which",
    "start": "1006920",
    "end": "1013399"
  },
  {
    "text": "could then Downstream be slightly adapted or slightly tweaked with a",
    "start": "1013399",
    "end": "1018920"
  },
  {
    "text": "smaller set of data for your domain to produce a domain specific model or a",
    "start": "1018920",
    "end": "1024240"
  },
  {
    "text": "model that's specific to your use case but the mechanics of this are not",
    "start": "1024240",
    "end": "1030160"
  },
  {
    "text": "dissimilar at runtime um you still have your new inputs come in to your adapted",
    "start": "1030160",
    "end": "1036760"
  },
  {
    "text": "model even though it's now a fine-tune model not a model you train from scratch and you process those new inputs through",
    "start": "1036760",
    "end": "1043319"
  },
  {
    "text": "the data transformation the outputs there is a very maybe a sign ific",
    "start": "1043319",
    "end": "1049360"
  },
  {
    "text": "difference here practically though because these models are meant to be more General and be applied to many",
    "start": "1049360",
    "end": "1056640"
  },
  {
    "text": "different use cases now those models are much bigger the software functions are",
    "start": "1056640",
    "end": "1062559"
  },
  {
    "text": "much bigger but mo more importantly the number of parameters that go into those",
    "start": "1062559",
    "end": "1068039"
  },
  {
    "text": "software functions is very large maybe even gigabytes large or more so when you",
    "start": "1068039",
    "end": "1074520"
  },
  {
    "text": "execute that many operations on that sort of input it's a lot of Matrix",
    "start": "1074520",
    "end": "1079919"
  },
  {
    "text": "multiplying it's a lot of processing and data transformation and so this is where",
    "start": "1079919",
    "end": "1085360"
  },
  {
    "text": "we really start to be stressed by this capacity and need for gpus or or other",
    "start": "1085360",
    "end": "1092679"
  },
  {
    "text": "specialized processors that would help us process these very many calculations",
    "start": "1092679",
    "end": "1098200"
  },
  {
    "text": "very fast because we want to recognize an image maybe in real time or close to real time not waiting seconds or even",
    "start": "1098200",
    "end": "1106280"
  },
  {
    "text": "minutes to process that image and so practically there's a need for a",
    "start": "1106280",
    "end": "1111520"
  },
  {
    "text": "different kind of generation or set of Hardware to run these larger models",
    "start": "1111520",
    "end": "1118080"
  },
  {
    "text": "which were kind of trained as larger models to handle a general set of use cases and Then followed on with transfer",
    "start": "1118080",
    "end": "1125280"
  },
  {
    "text": "learning after that and this is also still quite widely used so data",
    "start": "1125280",
    "end": "1130679"
  },
  {
    "text": "scientists and data analysts or machine learning Engineers or whatever they are",
    "start": "1130679",
    "end": "1136640"
  },
  {
    "text": "still use these models and still uh use models like this or do things",
    "start": "1136640",
    "end": "1141960"
  },
  {
    "text": "like this and practice fine-tuning you probably have heard of whether that's fine-tuning a large language model or",
    "start": "1141960",
    "end": "1148440"
  },
  {
    "text": "fine-tuning a non-generative type of model which we'll talk about here in a second this process of fine-tuning is",
    "start": "1148440",
    "end": "1155440"
  },
  {
    "text": "used very frequently because it requires you to maybe curate less specific",
    "start": "1155440",
    "end": "1161360"
  },
  {
    "text": "training data now I want to go maybe over a couple of a sides here that are important to note before we hop to the",
    "start": "1161360",
    "end": "1169200"
  },
  {
    "text": "latest generation of models and those couple of asides I think are are subtle",
    "start": "1169200",
    "end": "1174240"
  },
  {
    "text": "but important for kind of the general understanding of this flow and uh this",
    "start": "1174240",
    "end": "1180760"
  },
  {
    "text": "flow of thought and where things fit into the the major picture here the",
    "start": "1180760",
    "end": "1185799"
  },
  {
    "text": "first of these asides is let's think about maybe why this Foundation model or",
    "start": "1185799",
    "end": "1192240"
  },
  {
    "text": "transfer learning process actually works well as it turns out if you look at one",
    "start": "1192240",
    "end": "1199280"
  },
  {
    "text": "of these models like a Bert model or one of these other models like an object",
    "start": "1199280",
    "end": "1205520"
  },
  {
    "text": "recognition Model A lot of the processing of that software function you",
    "start": "1205520",
    "end": "1211000"
  },
  {
    "text": "can kind of think about it like a lot of the the heft of that function most all",
    "start": "1211000",
    "end": "1217480"
  },
  {
    "text": "of those parameters and those functions and subfunctions within within the model",
    "start": "1217480",
    "end": "1223919"
  },
  {
    "text": "are really dedicated to what's called either feature represent ation or",
    "start": "1223919",
    "end": "1230440"
  },
  {
    "text": "embedding or creating an internal representation however you want to put it it's about taking that data in",
    "start": "1230440",
    "end": "1238720"
  },
  {
    "text": "whatever mode that's in so an image or text or audio maybe and taking that in",
    "start": "1238720",
    "end": "1245760"
  },
  {
    "text": "and transforming that from its original format maybe a a set of pixel values or",
    "start": "1245760",
    "end": "1252640"
  },
  {
    "text": "a set of vocab indices or something like that in the case of text and actually",
    "start": "1252640",
    "end": "1258799"
  },
  {
    "text": "Translating that input into a really efficient and dense and good",
    "start": "1258799",
    "end": "1265039"
  },
  {
    "text": "representation that can be used for the downstream task so if you think about",
    "start": "1265039",
    "end": "1271480"
  },
  {
    "text": "kind of your model function as a big pipe you know 90% or more of the flow",
    "start": "1271480",
    "end": "1279840"
  },
  {
    "text": "through that pipe through that data transformation is dedicated to the translation of whatever that input is in",
    "start": "1279840",
    "end": "1286440"
  },
  {
    "text": "whatever format like an image or text into this internal representation sometimes called features or often times",
    "start": "1286440",
    "end": "1294159"
  },
  {
    "text": "called an embedding or a hidden a hidden representation then a very small amount",
    "start": "1294159",
    "end": "1300240"
  },
  {
    "text": "maybe 10% or less of that processing has to do with taking that representation",
    "start": "1300240",
    "end": "1307279"
  },
  {
    "text": "and then performing a downstream task like machine translation or speech synthesis or object recognition and so",
    "start": "1307279",
    "end": "1315400"
  },
  {
    "text": "because a lot of that has to do with representing the input that representation of the",
    "start": "1315400",
    "end": "1322520"
  },
  {
    "text": "input for text or images or audio is then transferable between different text",
    "start": "1322520",
    "end": "1329080"
  },
  {
    "text": "and image and audio tasks like I could have a model like Bert that embeds or",
    "start": "1329080",
    "end": "1336159"
  },
  {
    "text": "represents my text input and then I could kind of bolt on various heads onto",
    "start": "1336159",
    "end": "1342400"
  },
  {
    "text": "the front or onto the the end of that model or the end processing of that",
    "start": "1342400",
    "end": "1348080"
  },
  {
    "text": "software function and do things all sorts of things like machine translation or sentiment analysis or named entity",
    "start": "1348080",
    "end": "1356640"
  },
  {
    "text": "recognition or nli or or different things and so this is kind of one of the key pieces that makes this Foundation",
    "start": "1356640",
    "end": "1364000"
  },
  {
    "text": "model or transfer learning piece work so well now the second aside that I would",
    "start": "1364000",
    "end": "1371240"
  },
  {
    "text": "like to mention here is that one of the reasons why we were able to boost the",
    "start": "1371240",
    "end": "1378520"
  },
  {
    "text": "model size and kind of boost the generalizability of this was because one",
    "start": "1378520",
    "end": "1386080"
  },
  {
    "text": "we kind of were able to understand about how to make these models more",
    "start": "1386080",
    "end": "1391240"
  },
  {
    "text": "generalizable as I just mentioned with you know this feature representation but",
    "start": "1391240",
    "end": "1396799"
  },
  {
    "text": "also it requires a lot of data to train these and one of the things that was figured out you know quite interestingly",
    "start": "1396799",
    "end": "1404760"
  },
  {
    "text": "was that you could do things like have a huge set of images or videos or text or",
    "start": "1404760",
    "end": "1412480"
  },
  {
    "text": "pull for example scrape the whole internet and you could construct a task",
    "start": "1412480",
    "end": "1418520"
  },
  {
    "text": "in other words you could construct your example inputs and your example outputs your training data in an unsupervised",
    "start": "1418520",
    "end": "1425559"
  },
  {
    "text": "way from that large scrape of data and let me explain what I mean by that unsupervised I mean in kind of the old",
    "start": "1425559",
    "end": "1433679"
  },
  {
    "text": "days 2010 to 2017 we would hand curate you know this Tex text corresponds to",
    "start": "1433679",
    "end": "1440120"
  },
  {
    "text": "this output and we would manually create that label but in this new kind of",
    "start": "1440120",
    "end": "1446120"
  },
  {
    "text": "regime where we boosted the size of these models we would actually do this in an unsupervised way so we would",
    "start": "1446120",
    "end": "1452600"
  },
  {
    "text": "scrape the whole internet worth of Text data for example and then I can",
    "start": "1452600",
    "end": "1457919"
  },
  {
    "text": "construct a metat task quote unquote or or a set of example inputs and example",
    "start": "1457919",
    "end": "1464240"
  },
  {
    "text": "outputs by Just For example taking a sentence and removing the last word and",
    "start": "1464240",
    "end": "1469480"
  },
  {
    "text": "then having the last word be the prediction and that's an autocomplete task or I could take a sentence and",
    "start": "1469480",
    "end": "1475480"
  },
  {
    "text": "remove a word at the beginning or mask it and have the model try to fill that in I can construct that task",
    "start": "1475480",
    "end": "1481960"
  },
  {
    "text": "automatically I don't need to have a human do that I can actually do it programmatically as I scrape all of this",
    "start": "1481960",
    "end": "1488240"
  },
  {
    "text": "data and so you might be seeing where I'm going with this but tasks like this",
    "start": "1488240",
    "end": "1493640"
  },
  {
    "text": "autocomplete were tasks that were commonly used in the training of these",
    "start": "1493640",
    "end": "1498720"
  },
  {
    "text": "large Foundation or base models I think mostly with the original intent of",
    "start": "1498720",
    "end": "1504919"
  },
  {
    "text": "having these be transferable to a wide variety of Downstream tasks that would",
    "start": "1504919",
    "end": "1511520"
  },
  {
    "text": "be executed via this fine-tuning process okay so th those were the two",
    "start": "1511520",
    "end": "1518120"
  },
  {
    "text": "EXC asides about kind of these meta tasks why those are important and then",
    "start": "1518120",
    "end": "1524720"
  },
  {
    "text": "also this idea of feature representation or embedding and I'll kind of return to that embedding piece in a in a",
    "start": "1524720",
    "end": "1531159"
  },
  {
    "text": "bit to kind of set that in context but let's get to this final stage of quote",
    "start": "1531159",
    "end": "1536880"
  },
  {
    "text": "Ai and this is um you know 2022 plus this most recent time maybe people are",
    "start": "1536880",
    "end": "1543279"
  },
  {
    "text": "most familiar with and a lot of people hopped on the AI train during this time",
    "start": "1543279",
    "end": "1548600"
  },
  {
    "text": "period and we've already talked about this a little bit but a couple things that we haven't maybe talked about on",
    "start": "1548600",
    "end": "1554039"
  },
  {
    "text": "this podcast is in this generative AI phase people carried on kind of curating",
    "start": "1554039",
    "end": "1560640"
  },
  {
    "text": "more and more data increasing model size using these meta tasks like autocomplete",
    "start": "1560640",
    "end": "1566559"
  },
  {
    "text": "to train these generalizable large Foundation or base",
    "start": "1566559",
    "end": "1571919"
  },
  {
    "text": "models and as it turns out if you train a huge autocomplete model on whole",
    "start": "1571919",
    "end": "1578559"
  },
  {
    "text": "internet's worth of data obviously the internet contains blog posts about coding and tweets and movie scripts and",
    "start": "1578559",
    "end": "1587360"
  },
  {
    "text": "and all sorts of things right and so if I then have as input to that model a",
    "start": "1587360",
    "end": "1595279"
  },
  {
    "text": "blog post about practical AI is colon and ask the model to autocomplete that",
    "start": "1595279",
    "end": "1602360"
  },
  {
    "text": "the probabilities associated with that prediction of those next words would",
    "start": "1602360",
    "end": "1609080"
  },
  {
    "text": "actually predict maybe a quite relevant blog post and so now people start to",
    "start": "1609080",
    "end": "1615320"
  },
  {
    "text": "realize well wait a minute because of the scale of this training and the generalizability of this model maybe I",
    "start": "1615320",
    "end": "1623200"
  },
  {
    "text": "don't even have to execute this fine-tuning process maybe I actually",
    "start": "1623200",
    "end": "1629480"
  },
  {
    "text": "want to just create a large enough model that I can prompt or instruct and then",
    "start": "1629480",
    "end": "1637360"
  },
  {
    "text": "kind of hone in the the probabilities of the autocomplete to actually",
    "start": "1637360",
    "end": "1642559"
  },
  {
    "text": "autocomplete what I would autocomplete maybe as a human if I followed these instructions or if I generated this blog",
    "start": "1642559",
    "end": "1649320"
  },
  {
    "text": "post or if I translated this text into a different language and that's what",
    "start": "1649320",
    "end": "1654520"
  },
  {
    "text": "people started doing we've talked a little bit about this on the on the show before we've talked about how there's",
    "start": "1654520",
    "end": "1662480"
  },
  {
    "text": "one of these generative models is often uh starts as a pre-training which is",
    "start": "1662480",
    "end": "1668399"
  },
  {
    "text": "trained on these kind of meta tasks like autocomplete over a huge Corpus of data",
    "start": "1668399",
    "end": "1673640"
  },
  {
    "text": "which is not human curated and then there's a period also from the model",
    "start": "1673640",
    "end": "1678880"
  },
  {
    "text": "producers still not not us consumers but you know meta will do that pre-training",
    "start": "1678880",
    "end": "1684440"
  },
  {
    "text": "and then they'll use their own curated data set which is still large and very",
    "start": "1684440",
    "end": "1689480"
  },
  {
    "text": "expensive to create but their own kind of highquality curated data set of prompts which might include chat",
    "start": "1689480",
    "end": "1696679"
  },
  {
    "text": "examples and Tool usage and various tasks like question answering or machine",
    "start": "1696679",
    "end": "1702240"
  },
  {
    "text": "translation miscellaneous kind of instructions around around summarization and this fine tuning data set is then",
    "start": "1702240",
    "end": "1710240"
  },
  {
    "text": "used to further train the model and produce maybe uh an instruct model or a",
    "start": "1710240",
    "end": "1717200"
  },
  {
    "text": "chat model or a code completion model and then we if we want to consume that",
    "start": "1717200",
    "end": "1722880"
  },
  {
    "text": "model could use a chat type prompt or a certain instruction to use the model and",
    "start": "1722880",
    "end": "1728880"
  },
  {
    "text": "and execute accordingly so yeah this is kind of how this latest phase of of",
    "start": "1728880",
    "end": "1734600"
  },
  {
    "text": "models kind of fits into the history and now we're in a phase where primarily we consumers of these models we're not the",
    "start": "1734600",
    "end": "1743799"
  },
  {
    "text": "model trainers so practically speaking if we think about this whereas in",
    "start": "1743799",
    "end": "1748960"
  },
  {
    "text": "previous generations of model usage which again is still quite prevalent across industry we might need an mlops",
    "start": "1748960",
    "end": "1756360"
  },
  {
    "text": "system to curate uh or to train models and monitor models and calculate metrics",
    "start": "1756360",
    "end": "1762720"
  },
  {
    "text": "and we might need data annotation systems to label outputs and all of",
    "start": "1762720",
    "end": "1767760"
  },
  {
    "text": "those things here our primary the primary shift and maybe this makes more",
    "start": "1767760",
    "end": "1773440"
  },
  {
    "text": "sense now as you're hearing things but the creation of optimized prompts the",
    "start": "1773440",
    "end": "1779760"
  },
  {
    "text": "curation of those prompts getting domain experts to write and iterate on those",
    "start": "1779760",
    "end": "1785480"
  },
  {
    "text": "prompts um evaluating llm workflows these things are the things that people",
    "start": "1785480",
    "end": "1791080"
  },
  {
    "text": "are thinking about a lot now that they're not the ones training these models but they're sort of quote",
    "start": "1791080",
    "end": "1796600"
  },
  {
    "text": "programming them or executing reasoning over them just at the inference layer",
    "start": "1796600",
    "end": "1804399"
  },
  {
    "text": "now I mentioned a bit ago the this feature representation or embedding",
    "start": "1804399",
    "end": "1810159"
  },
  {
    "text": "piece of the puzzle and we set that in the context of foundation models and",
    "start": "1810159",
    "end": "1815840"
  },
  {
    "text": "transfer learning so I want to Circle back to that for just a second as a kind of uh afterthought here I guess which",
    "start": "1815840",
    "end": "1824679"
  },
  {
    "text": "hopefully now you have some context for where those come about but we of course",
    "start": "1824679",
    "end": "1829880"
  },
  {
    "text": "see those popping up as a very important piece of generative AI workflows because",
    "start": "1829880",
    "end": "1835760"
  },
  {
    "text": "these models as it turns out what kind of people learned and started actually",
    "start": "1835760",
    "end": "1842000"
  },
  {
    "text": "on purpose training these models to do um they found out that these internal",
    "start": "1842000",
    "end": "1847720"
  },
  {
    "text": "representations or these embeddings if I take text and represent it in a very",
    "start": "1847720",
    "end": "1852919"
  },
  {
    "text": "dense efficient way for use in these Downstream tasks actually text embedded",
    "start": "1852919",
    "end": "1859720"
  },
  {
    "text": "in that space could be used in a semantic search or retrieval fashion and",
    "start": "1859720",
    "end": "1866240"
  },
  {
    "text": "so if I take a sentence about eating Great Chicago deep dish pizza and I",
    "start": "1866240",
    "end": "1871960"
  },
  {
    "text": "embed that or represent it into this set of numbers of vector and then I take",
    "start": "1871960",
    "end": "1877159"
  },
  {
    "text": "another sentence about pizza and I do the same thing and I take another sentence about flying airplanes and do",
    "start": "1877159",
    "end": "1884120"
  },
  {
    "text": "the same thing the two sentences about pizza will be closer quote unquote in",
    "start": "1884120",
    "end": "1890600"
  },
  {
    "text": "that Vector space in that according to their vectors that were calculated or",
    "start": "1890600",
    "end": "1896080"
  },
  {
    "text": "their embeddings that were calculated they will be closer than the one about airplanes and so this now allows us to",
    "start": "1896080",
    "end": "1903360"
  },
  {
    "text": "semantically search over pieces of text and over other things connect those",
    "start": "1903360",
    "end": "1909639"
  },
  {
    "text": "things together and that has become a key piece as we've talked about in in",
    "start": "1909639",
    "end": "1914799"
  },
  {
    "text": "past episodes to things like retrieval augmented generation where we're pulling out information from knowledge bases and",
    "start": "1914799",
    "end": "1922240"
  },
  {
    "text": "and injecting that into models now taking a breath hopefully all",
    "start": "1922240",
    "end": "1928600"
  },
  {
    "text": "of that was interesting as we as we went through those different Generations I'd like to maybe emphasize a couple of",
    "start": "1928600",
    "end": "1935519"
  },
  {
    "text": "things in your mind so you can see that all of these modeling methods have their",
    "start": "1935519",
    "end": "1942840"
  },
  {
    "text": "place and they're still with us so it's still very efficient and effective",
    "start": "1942840",
    "end": "1948360"
  },
  {
    "text": "to utilize a Time series modeling method to do forecasts for example um that's in",
    "start": "1948360",
    "end": "1955240"
  },
  {
    "text": "that first generation of models the statistical machine learning models it's still quite relevant if you're you know",
    "start": "1955240",
    "end": "1961639"
  },
  {
    "text": "maybe training a new computer vision model for your factory and that's very specific it doesn't need to be General",
    "start": "1961639",
    "end": "1968039"
  },
  {
    "text": "at all it doesn't really make sense in many cases to maybe utilize a huge",
    "start": "1968039",
    "end": "1974799"
  },
  {
    "text": "heavyweight vision llm for example or an lvm a language Vision model to execute",
    "start": "1974799",
    "end": "1981679"
  },
  {
    "text": "at very high throughput on a machine or a manufacturing line to for a computer",
    "start": "1981679",
    "end": "1987320"
  },
  {
    "text": "vision model that is trying to find flaws and parts as they're coming off of a manufacturing line efficiency wise and",
    "start": "1987320",
    "end": "1995279"
  },
  {
    "text": "how that model would have to be deployed that would be a challenge to say the least and so maybe you want a very",
    "start": "1995279",
    "end": "2000720"
  },
  {
    "text": "specific model that is a little bit maybe smaller and more accessible but you also don't need to be training a",
    "start": "2000720",
    "end": "2007480"
  },
  {
    "text": "computer computer vision model from scratch often you would start with a foundation model and then finally of",
    "start": "2007480",
    "end": "2013360"
  },
  {
    "text": "course we're all familiar with a bunch of things that people are using generative AI models for so that's one",
    "start": "2013360",
    "end": "2019559"
  },
  {
    "text": "thing that I'd want to emphasize is all of these types of modeling are still with us and prevalent across industry",
    "start": "2019559",
    "end": "2025880"
  },
  {
    "text": "the second thing that I'd want to emphasize is an interesting thing that I've kind of noticed and even talked",
    "start": "2025880",
    "end": "2032200"
  },
  {
    "text": "with someone today about which is as you have advanced through these different generations of models",
    "start": "2032200",
    "end": "2038559"
  },
  {
    "text": "on the more machine learning statistical side often you had kind of role wise you",
    "start": "2038559",
    "end": "2044039"
  },
  {
    "text": "had software Engineers or infrastructure Engineers on one side you had business people or domain experts on the other",
    "start": "2044039",
    "end": "2050800"
  },
  {
    "text": "side and you had data scientists or data analysts or machine learning engineers in the middle that would often translate",
    "start": "2050800",
    "end": "2058320"
  },
  {
    "text": "domain specific problems into models that they would train which would be deployed by software engineers and",
    "start": "2058320",
    "end": "2064280"
  },
  {
    "text": "infrastructure people on the other end of the spectrum in this generative AI World often there's not this fine-tuning",
    "start": "2064280",
    "end": "2071520"
  },
  {
    "text": "or training that happens and so often domain experts or business um people",
    "start": "2071520",
    "end": "2077200"
  },
  {
    "text": "themselves are prompting these models to accomplish chains of reasoning and",
    "start": "2077200",
    "end": "2083679"
  },
  {
    "text": "there's not a data scientist or an analyst in the middle and so there's kind of this shrinking of the zone",
    "start": "2083679",
    "end": "2089960"
  },
  {
    "text": "between domain experts and business people and the direct infrastructure",
    "start": "2089960",
    "end": "2095679"
  },
  {
    "text": "that's running those models which is an interesting development I think finally",
    "start": "2095679",
    "end": "2101520"
  },
  {
    "text": "the thing that I'd like to emphasize is often in an actual business scenario the",
    "start": "2101520",
    "end": "2108079"
  },
  {
    "text": "very most intelligent or best or eventually kind of especially if you're creating a customized you know",
    "start": "2108079",
    "end": "2115640"
  },
  {
    "text": "proprietary or very domain specific approach to a problem or a workflow it",
    "start": "2115640",
    "end": "2121960"
  },
  {
    "text": "may involve all of these different types of models or some combination of them",
    "start": "2121960",
    "end": "2127480"
  },
  {
    "text": "and so you can imagine a system for example where a user would put in a",
    "start": "2127480",
    "end": "2133320"
  },
  {
    "text": "natural language query and say hey could you forecast out our revenue for two",
    "start": "2133320",
    "end": "2140400"
  },
  {
    "text": "years into the future and that may be processed by a generative model to",
    "start": "2140400",
    "end": "2146240"
  },
  {
    "text": "create a tool call that calls a function that uses a statistical or machine",
    "start": "2146240",
    "end": "2152480"
  },
  {
    "text": "learning model to make that forecast which Returns the answer which is is",
    "start": "2152480",
    "end": "2157800"
  },
  {
    "text": "then interpreted back into natural language by the generative model and so these types of workflows are I think",
    "start": "2157800",
    "end": "2163680"
  },
  {
    "text": "some of the most interesting ones I guess uh I said that was the last thing I was going to emphasize but I've",
    "start": "2163680",
    "end": "2169800"
  },
  {
    "text": "already emphasized this a lot in in different shows but just to remind people all of these things that we're",
    "start": "2169800",
    "end": "2175079"
  },
  {
    "text": "executing are software functions and not some sort of uh fairy dust or sentients",
    "start": "2175079",
    "end": "2181240"
  },
  {
    "text": "that comes about after you know you leave your laptop in the corner of a room for a while and so a lot of the",
    "start": "2181240",
    "end": "2188079"
  },
  {
    "text": "disillusionment that's happening in the AI space is because people think uh",
    "start": "2188079",
    "end": "2193440"
  },
  {
    "text": "doing AI or this AI transformation somehow just kind of happens once you quote have ai but the",
    "start": "2193440",
    "end": "2201480"
  },
  {
    "text": "reality is that these are all software functions parameterized software functions at different scales most",
    "start": "2201480",
    "end": "2207400"
  },
  {
    "text": "definitely but software functions that need infrastructure to operate and are",
    "start": "2207400",
    "end": "2212640"
  },
  {
    "text": "often integrated into other software systems to be made useful and so",
    "start": "2212640",
    "end": "2217760"
  },
  {
    "text": "engineering is still quite relevant of course you could argue some of these can write software now if you prompt them in",
    "start": "2217760",
    "end": "2224760"
  },
  {
    "text": "a specific way but still you sort of need to architect that system that does",
    "start": "2224760",
    "end": "2231160"
  },
  {
    "text": "all of that prompting and code generation and integration and execution so there's a lot of interesting things",
    "start": "2231160",
    "end": "2237119"
  },
  {
    "text": "related to that well I I it's been fun for me to kind of share this uh this",
    "start": "2237119",
    "end": "2242800"
  },
  {
    "text": "little talk or or Workshop material with you that that I've been talking with",
    "start": "2242800",
    "end": "2248240"
  },
  {
    "text": "people about there's a lot of things here of course that I that I haven't covered as part of this episode but",
    "start": "2248240",
    "end": "2255560"
  },
  {
    "text": "hopefully it gives you an overall sense I would definitely recommend people maybe on the generative AI side if you",
    "start": "2255560",
    "end": "2263839"
  },
  {
    "text": "have yet to kind of play around on the other side the statistical machine learning side if you're technical maybe",
    "start": "2263839",
    "end": "2271079"
  },
  {
    "text": "you want to just go to something like a scikit learn which is a Python program that even without GPU research es or",
    "start": "2271079",
    "end": "2278000"
  },
  {
    "text": "other things will help you learn about the different types of modeling that is available there there are great examples",
    "start": "2278000",
    "end": "2284280"
  },
  {
    "text": "and and um you can learn about that if you're coming from the more data science",
    "start": "2284280",
    "end": "2289319"
  },
  {
    "text": "machine learning side and and you're going to generative AI of course I would",
    "start": "2289319",
    "end": "2294480"
  },
  {
    "text": "encourage you to learn about that and think about maybe how um you can utilize the best parts of that alongside and",
    "start": "2294480",
    "end": "2301480"
  },
  {
    "text": "with your statistical machine learning workflows if you're non-technical in",
    "start": "2301480",
    "end": "2306839"
  },
  {
    "text": "either of these of course there's plenty of ways to to get Hands-On with generative models but on these other",
    "start": "2306839",
    "end": "2313079"
  },
  {
    "text": "cases there's still automl systems or or systems that would allow you to do",
    "start": "2313079",
    "end": "2318640"
  },
  {
    "text": "things in certain domains by uploading data and training models if you just search for kind of automl I know H2O had",
    "start": "2318640",
    "end": "2326160"
  },
  {
    "text": "a thing called driverless um AI for a while and and there's various systems like that that you can try and and look",
    "start": "2326160",
    "end": "2333680"
  },
  {
    "text": "at interesting results so thank you all for bearing with me on this one and I'm excited to have Chris back with me for",
    "start": "2333680",
    "end": "2341599"
  },
  {
    "text": "next week's episode which you'll you'll hear uh hopefully very soon hope you all have a a great week and thanks for",
    "start": "2341599",
    "end": "2349880"
  },
  {
    "text": "[Music]",
    "start": "2349880",
    "end": "2356079"
  },
  {
    "text": "joining all right that is practical AI for this week subscribe now if you",
    "start": "2356079",
    "end": "2362640"
  },
  {
    "text": "haven't already head to practical AI FM for all the ways and join our free slack",
    "start": "2362640",
    "end": "2369119"
  },
  {
    "text": "team where you can hang out with Daniel Chris and the entire change log Community sign up today at practical ai.",
    "start": "2369119",
    "end": "2377560"
  },
  {
    "text": "fm/ Community thanks again to our partners at fly.io to our beat freaking",
    "start": "2377560",
    "end": "2383560"
  },
  {
    "text": "residence breakmaster cylinder and to you for listening we appreciate you spending time with us that's all for now",
    "start": "2383560",
    "end": "2390560"
  },
  {
    "text": "we'll talk to you again next time",
    "start": "2390560",
    "end": "2394680"
  },
  {
    "text": "[Music]",
    "start": "2396530",
    "end": "2403679"
  }
]
[
  {
    "text": "we're researchers and we mostly communicate with the research Community but I mean there's stuff to be done everywhere thinking about you know",
    "start": "40",
    "end": "6359"
  },
  {
    "text": "thinking about efficiency you don't have to persuade anybody that if all the other things being equal if your uh tool",
    "start": "6359",
    "end": "11880"
  },
  {
    "text": "runs twice as fast or takes half the amount of memory everybody wins bandwidth for change log is",
    "start": "11880",
    "end": "19080"
  },
  {
    "text": "provided by fastly learn more at fastly.com our feature flags are power",
    "start": "19080",
    "end": "24160"
  },
  {
    "text": "by launch Darkly check them out at launch dark.com and we're hosted on looc cloud servers get $100 in hosting credit",
    "start": "24160",
    "end": "31039"
  },
  {
    "text": "at lin.com changelog we deserve a better internet and the brave team has the recipe for",
    "start": "31039",
    "end": "37960"
  },
  {
    "text": "bringing it to us start with Google Chrome keep the extensions the dev tools and the rendering engine that make",
    "start": "37960",
    "end": "43200"
  },
  {
    "text": "Chrome great rip out the Google bits we don't need them mix in ad and tracker blocking by default quick access to the",
    "start": "43200",
    "end": "49640"
  },
  {
    "text": "tour Network for True private browsing and an opt-in reward system so you can get paid to view privacy respecting ads",
    "start": "49640",
    "end": "56399"
  },
  {
    "text": "then turn around and use those rewards to support your favorite web creators like us Download Brave today using the",
    "start": "56399",
    "end": "61960"
  },
  {
    "text": "link in the show notes and give tipping a try on change.com",
    "start": "61960",
    "end": "66960"
  },
  {
    "text": "[Music]",
    "start": "67950",
    "end": "73450"
  },
  {
    "text": "welcome to practical AI a weekly podcast that makes artificial intelligence practical productive and accessible to",
    "start": "73880",
    "end": "81000"
  },
  {
    "text": "everyone this is where conversations around AI machine learning and data science happen join the community and",
    "start": "81000",
    "end": "87000"
  },
  {
    "text": "slack with us around various topics of the show at chain.com /c community and follow us on Twitter we're at practical",
    "start": "87000",
    "end": "95200"
  },
  {
    "text": "[Music] aifm welcome to another episode of",
    "start": "95270",
    "end": "102680"
  },
  {
    "text": "practical AI this is Daniel whack I am a data scientist at s International and",
    "start": "102680",
    "end": "109360"
  },
  {
    "text": "I'm joined as always by my co-host Chris Benson who is a principal emerging technology strategist at LED Martin how",
    "start": "109360",
    "end": "116680"
  },
  {
    "text": "you doing Chris I am doing very well how's it going Daniel going great it's warmer now in the US a lot of people",
    "start": "116680",
    "end": "122840"
  },
  {
    "text": "have been having some some issues particularly down in in Texas and other other areas so this is for those",
    "start": "122840",
    "end": "128759"
  },
  {
    "text": "listening later in the podcast this is February of 2021 a lot of uh snow and",
    "start": "128759",
    "end": "135040"
  },
  {
    "text": "cold weather in the US here so a couple of people on our team at work are in",
    "start": "135040",
    "end": "140120"
  },
  {
    "text": "Texas and we've been getting all the all the stories when they're able to connect and stuff so I think I think they're",
    "start": "140120",
    "end": "146640"
  },
  {
    "text": "they're getting through it finally thank goodness it was pretty pretty horrible but in the metime I enjoying my 70",
    "start": "146640",
    "end": "153280"
  },
  {
    "text": "something you know my 70Â° plus weather outside spring like and I'm kind of sticking my tongue out on them on Zoom",
    "start": "153280",
    "end": "159640"
  },
  {
    "text": "meetings yeah it's always interesting during these particular types of events because you kind of just assume that",
    "start": "159640",
    "end": "166920"
  },
  {
    "text": "people have all of this like redundant fault tolerant um like infrastructure going on for like their apis and other",
    "start": "166920",
    "end": "173920"
  },
  {
    "text": "things and these sorts of events really reveal like that is not the case like I know like one of the apis we we",
    "start": "173920",
    "end": "180400"
  },
  {
    "text": "frequently use like apparently on on Prem server in Dallas and they did not",
    "start": "180400",
    "end": "186840"
  },
  {
    "text": "have power and you know you you learn new and interesting things like that you",
    "start": "186840",
    "end": "192000"
  },
  {
    "text": "know what after the past year there's nothing that surprises me anymore not",
    "start": "192000",
    "end": "197080"
  },
  {
    "text": "now global pandemics all sorts of strife you name it I mean I'm just yeah nothing",
    "start": "197080",
    "end": "203440"
  },
  {
    "text": "nothing phases me now yeah I'm glad to hear you've you've built a lot of robustness into your personal life there",
    "start": "203440",
    "end": "210200"
  },
  {
    "text": "there we go I laugh a lot I Snicker a lot that's how I cope yeah well a few",
    "start": "210200",
    "end": "215439"
  },
  {
    "text": "months ago actually I think it was one of the researchers at s that I work with",
    "start": "215439",
    "end": "220640"
  },
  {
    "text": "called uh Gary Simons he's been a linguist and programmer computational",
    "start": "220640",
    "end": "226720"
  },
  {
    "text": "linguist uh translator type researcher for decades and um he sent me this link",
    "start": "226720",
    "end": "233799"
  },
  {
    "text": "in our Skype communication said hey this is a really cool article you should think about having this on your podcast",
    "start": "233799",
    "end": "239519"
  },
  {
    "text": "and there's an article called Green AI from Communications of the ACM and I'm",
    "start": "239519",
    "end": "245959"
  },
  {
    "text": "really happy today because we get to make materialize what uh what Gary saw",
    "start": "245959",
    "end": "251159"
  },
  {
    "text": "and what he recommended to me and we've got uh Roy Schwarz and uh Jesse Dodge",
    "start": "251159",
    "end": "256320"
  },
  {
    "text": "with us um Roy is a senior lecturer at Hebrew University of Jerusalem and Jesse",
    "start": "256320",
    "end": "261919"
  },
  {
    "text": "Dodge is a postto at the Allen Institute for AI and they were both authors on that article welcome guys thanks for",
    "start": "261919",
    "end": "268400"
  },
  {
    "text": "having us thank you yeah if both of you could just uh give us a little bit of a background about yourselves uh that'd be",
    "start": "268400",
    "end": "274880"
  },
  {
    "text": "great why don't we uh start with Jesse sure so I finished my PhD from Carnegie",
    "start": "274880",
    "end": "281360"
  },
  {
    "text": "melon uh in the language Technologies Institute last year in 2020 in the",
    "start": "281360",
    "end": "287080"
  },
  {
    "text": "pandemic although I spent most of my PhD at the University of Washington in Seattle and part of that time I spent um",
    "start": "287080",
    "end": "295479"
  },
  {
    "text": "working at the Allen Institute for AI where after I graduated now I'm back as a postto uh full-time so we wrote this",
    "start": "295479",
    "end": "304280"
  },
  {
    "text": "article I think back in we were thinking about this for quite a while and then um",
    "start": "304280",
    "end": "309720"
  },
  {
    "text": "wrote this back in 2019 and really got it out in 2020 so",
    "start": "309720",
    "end": "317479"
  },
  {
    "text": "yeah and now here even though uh the offices are closed I'm still here in",
    "start": "317479",
    "end": "322560"
  },
  {
    "text": "Seattle and I am on the Allan NL team once again awesome and what are you specifically working on so my research",
    "start": "322560",
    "end": "330840"
  },
  {
    "text": "sort of falls under two broad umbrellas the first is related to efficiency similar to this green AI idea that we'll",
    "start": "330840",
    "end": "338000"
  },
  {
    "text": "get into I work on um making models more",
    "start": "338000",
    "end": "343080"
  },
  {
    "text": "efficient along the number of Dimensions that they have in terms of the complexity in terms of inference",
    "start": "343080",
    "end": "350479"
  },
  {
    "text": "generally related to any way that you can measure like the total computational",
    "start": "350479",
    "end": "356520"
  },
  {
    "text": "cost of getting some kind of experimental result and then the second pillar of my",
    "start": "356520",
    "end": "361960"
  },
  {
    "text": "research relates to reproducibility where I created the natural language processing reproducibility checklist",
    "start": "361960",
    "end": "368319"
  },
  {
    "text": "that was used at uh I think four major NLP conferences now and I've published",
    "start": "368319",
    "end": "373919"
  },
  {
    "text": "some work on how we can make uh the science of machine learning and natural language processing more reproducible",
    "start": "373919",
    "end": "381280"
  },
  {
    "text": "yeah that's awesome well you're working on two things that are just like",
    "start": "381280",
    "end": "386639"
  },
  {
    "text": "desperately needed uh in terms of of Focus so yeah I commend you in terms of",
    "start": "386639",
    "end": "392160"
  },
  {
    "text": "that and yeah it's really great great to hear Roy what about yourself hi so I'm Roy Schwartz I'm a senior lecturer which",
    "start": "392160",
    "end": "399160"
  },
  {
    "text": "is an equivalent to assistant professor at the Hebrew University of Jerusalem I'm currently in Jerusalem I joined the",
    "start": "399160",
    "end": "405599"
  },
  {
    "text": "HEB University last summer and before that I spent four years in Seattle where I got to meet Jesse fortunately and uh I",
    "start": "405599",
    "end": "413240"
  },
  {
    "text": "was a postdoc and then a research scientist at the University of Washington and the Allen Institute for AI and these were for wonderful years",
    "start": "413240",
    "end": "421280"
  },
  {
    "text": "but now I'm back home similar to Jesse to some extent I also came from the University where I did my PhD and uh so",
    "start": "421280",
    "end": "429360"
  },
  {
    "text": "um and took a break and came back my research uh also spend two or maybe",
    "start": "429360",
    "end": "435199"
  },
  {
    "text": "three uh Dimensions one of them is uh similar to Jesse efficiency and trying",
    "start": "435199",
    "end": "441560"
  },
  {
    "text": "to think about ways to reduce the cost of AI and NLP in particular and the",
    "start": "441560",
    "end": "447560"
  },
  {
    "text": "other is trying to get better understanding of this technology now that we have models that are becoming so",
    "start": "447560",
    "end": "453000"
  },
  {
    "text": "big and so good at what you're doing but at the same time uh it's very hard to know why they're doing certain things",
    "start": "453000",
    "end": "459000"
  },
  {
    "text": "why things some things work and some don't uh why do models reach certain",
    "start": "459000",
    "end": "464759"
  },
  {
    "text": "decisions uh I'm particularly interested in the role of data in all of this how do our data sets look what do they",
    "start": "464759",
    "end": "471199"
  },
  {
    "text": "contain what kind of phenomena are encoded in them and I like to make connections between all of these goals",
    "start": "471199",
    "end": "477720"
  },
  {
    "text": "between understanding and between sing our data and between making things more efficient and these are some of the",
    "start": "477720",
    "end": "482800"
  },
  {
    "text": "things that I'm most excited about awesome before we move on what is your general impression about sort of",
    "start": "482800",
    "end": "488840"
  },
  {
    "text": "progress in this process of trying to make our models more interpretable and",
    "start": "488840",
    "end": "494440"
  },
  {
    "text": "and understand more about them obviously you're doing work in in the field so hopefully like you see progress in that",
    "start": "494440",
    "end": "500199"
  },
  {
    "text": "but as an industry as a whole where do you think we are on that Journey that's a great",
    "start": "500199",
    "end": "506599"
  },
  {
    "text": "question so as you said on on the one end we're making making tons of progress I mean lots of very smart people are",
    "start": "506599",
    "end": "513200"
  },
  {
    "text": "working towards developing method to probe models to kind of kind of poke",
    "start": "513200",
    "end": "518240"
  },
  {
    "text": "them and ask them I mean do you know syntax do you know World Knowledge do you know this you know that and we",
    "start": "518240",
    "end": "524320"
  },
  {
    "text": "developing methods that are more and more uh sophisticated to get this information at the same time the core",
    "start": "524320",
    "end": "531000"
  },
  {
    "text": "questions that I think will make a huge impact if we're able to solve them and I'm not sure if these questions are even",
    "start": "531000",
    "end": "536080"
  },
  {
    "text": "solvable to some extent and I'm happy to talk about it even though it's not that topic of today's talk is can how do we",
    "start": "536080",
    "end": "542000"
  },
  {
    "text": "get mod models to explain what they're doing to explain it in a reliable way in a way that's I mean I just say you one",
    "start": "542000",
    "end": "548959"
  },
  {
    "text": "thing I mean when you ask a person why did they do something like that that they did the explanations are often also",
    "start": "548959",
    "end": "555120"
  },
  {
    "text": "not I mean they might be a post-rational of things that and it's hard even for us",
    "start": "555120",
    "end": "561120"
  },
  {
    "text": "to say what we're why we're doing certain things and we're you know conscious creatures so machines are it's",
    "start": "561120",
    "end": "567600"
  },
  {
    "text": "much harder to get this but uh we're trying I appreciate that as we as we look at this we're talking I'm looking",
    "start": "567600",
    "end": "574279"
  },
  {
    "text": "at your green AI article here again and I'm just kind of curious you know what",
    "start": "574279",
    "end": "579560"
  },
  {
    "text": "was your motivation for putting this out and probably I should ask as part of",
    "start": "579560",
    "end": "584760"
  },
  {
    "text": "that uh you know what is green AI you know initially and how did you decide",
    "start": "584760",
    "end": "591200"
  },
  {
    "text": "that this was the thing that you needed to get out there to the world and because it's this is a topic that often",
    "start": "591200",
    "end": "597240"
  },
  {
    "text": "gets left out of AI ethics and such having worked in that field for a while we can go back to that in a little bit",
    "start": "597240",
    "end": "602959"
  },
  {
    "text": "I'm curious what your motivation was though yeah so I think part of it was some conversations that Roy and I had",
    "start": "602959",
    "end": "609320"
  },
  {
    "text": "again this was back in 2019 when we were both at the Allen Institute for AI and",
    "start": "609320",
    "end": "614839"
  },
  {
    "text": "we noticed that there was this increasing trend of in larger and larger computational budgets used for some of",
    "start": "614839",
    "end": "621959"
  },
  {
    "text": "the research papers that were published in NLP we looked around and found not",
    "start": "621959",
    "end": "628079"
  },
  {
    "text": "only did we notice this but but there were a couple other pieces of work that had also noticed this trend so back you",
    "start": "628079",
    "end": "634440"
  },
  {
    "text": "know when I started my PhD back in 2013 I could run my experiments often on",
    "start": "634440",
    "end": "641079"
  },
  {
    "text": "a a used laptop that I had purchased off of Amazon and it was kind of slow but I",
    "start": "641079",
    "end": "646279"
  },
  {
    "text": "would you know I could run most of my I could train my models in a few minutes or an hour maybe and it worked and that",
    "start": "646279",
    "end": "653200"
  },
  {
    "text": "was okay and then we noticed in you know in 2019 we were like wow a lot of these models don't even fit on a single GPU",
    "start": "653200",
    "end": "661639"
  },
  {
    "text": "and we have to like rent like Cloud instances to be able to actually use",
    "start": "661639",
    "end": "667040"
  },
  {
    "text": "some of these models Plus in some cases papers would do for example a tremendous",
    "start": "667040",
    "end": "673200"
  },
  {
    "text": "amount of hyperparameter optimization or they would train on a huge amount of data well beyond what we could do even",
    "start": "673200",
    "end": "680639"
  },
  {
    "text": "at you know a good institution like like the University of Washington or ai2 and",
    "start": "680639",
    "end": "686160"
  },
  {
    "text": "one interesting thing and this has really been followed up by some concrete research is that we do find uh",
    "start": "686160",
    "end": "693279"
  },
  {
    "text": "significant improvements in performance across a lot of tasks just by scaling up",
    "start": "693279",
    "end": "698440"
  },
  {
    "text": "these models so language modeling for example has been a pretty foundational",
    "start": "698440",
    "end": "704639"
  },
  {
    "text": "task in NLP what we found is that training models to do well at this task",
    "start": "704639",
    "end": "710639"
  },
  {
    "text": "of language modeling if you train a large enough model on enough language data then that",
    "start": "710639",
    "end": "717720"
  },
  {
    "text": "model can do some other tasks that we're interested in as well so it somehow",
    "start": "717720",
    "end": "722760"
  },
  {
    "text": "learns some kind of representation of language that's useful across a wide variety of tasks but to get there we saw",
    "start": "722760",
    "end": "730279"
  },
  {
    "text": "just huge computational budgets used for a number of of these papers and",
    "start": "730279",
    "end": "736199"
  },
  {
    "text": "interestingly I mean we wrote this a while ago but the trend has not slowed down so this is something like Roy and I",
    "start": "736199",
    "end": "742279"
  },
  {
    "text": "are still working on similar motivated pieces about how this is really driving",
    "start": "742279",
    "end": "749360"
  },
  {
    "text": "in a lot of research in our field like these these massive scaling laws for example are pushing stateoftheart and",
    "start": "749360",
    "end": "756120"
  },
  {
    "text": "also getting a lot of attention and having you know our field is interesting you can view our field through that lens",
    "start": "756120",
    "end": "762480"
  },
  {
    "text": "now and see um some interesting results yeah so I'm curious I have my own",
    "start": "762480",
    "end": "768839"
  },
  {
    "text": "thoughts about how I might answer this question but I also haven't done the",
    "start": "768839",
    "end": "774240"
  },
  {
    "text": "amount of thinking that that both of you have so I don't know um maybe Roy if you",
    "start": "774240",
    "end": "779480"
  },
  {
    "text": "want to comment on this or or kick it back to Jesse so that trend has been continuing and like we're seeing those",
    "start": "779480",
    "end": "786600"
  },
  {
    "text": "sort of improved results in some areas along that Trend like in language modeling so why is that a problem or",
    "start": "786600",
    "end": "794519"
  },
  {
    "text": "like what sorts of problems or red flags does that bring up I guess yeah I mean I",
    "start": "794519",
    "end": "799720"
  },
  {
    "text": "think there the it's interesting because Jesse and I bring complimentary motivations for tackling this problem so",
    "start": "799720",
    "end": "805680"
  },
  {
    "text": "I mean when I started thinking about these things I mean yes I was having having discussions with Jesse about this",
    "start": "805680",
    "end": "810920"
  },
  {
    "text": "but I'm I'm a person that cares about the environment and I try to make personal choices that you know I I ride",
    "start": "810920",
    "end": "816880"
  },
  {
    "text": "my bike to work because it's healthy but also because it allows me to not drive my car and I try to you know turn the",
    "start": "816880",
    "end": "823079"
  },
  {
    "text": "light off when I leave the room you know do the simple things that don't you know don't matter much as a global scale but",
    "start": "823079",
    "end": "828560"
  },
  {
    "text": "you know I make my personal choices and then I go to my office and I I don't know if you've ever seen a GPU but this",
    "start": "828560",
    "end": "835160"
  },
  {
    "text": "is a very loud machine very uh a machine that's emits a lot of",
    "start": "835160",
    "end": "840880"
  },
  {
    "text": "heat yeah and kind of we're running stuff you know like okay let's just push push a button and suddenly you know the",
    "start": "840880",
    "end": "847759"
  },
  {
    "text": "5 degrees or 10 degrees up in in your room maybe but not in your planet hopefully and kind of it's been",
    "start": "847759",
    "end": "854480"
  },
  {
    "text": "something i' I've been thinking about quite a bit I mean What's the total impact of our field and uh Jesse and",
    "start": "854480",
    "end": "861079"
  },
  {
    "text": "I've been talking about this and then thinking mid 2019 or early mid 2019 a",
    "start": "861079",
    "end": "866519"
  },
  {
    "text": "paper came out from University of Massachusetts uh led by Emma strubel and her colleagues that try to quantify the",
    "start": "866519",
    "end": "872800"
  },
  {
    "text": "CO2 impact of a large scale NLP experiments and she came to the she and",
    "start": "872800",
    "end": "878320"
  },
  {
    "text": "her colleagues came to the conclusion that one of the most expensive experiments that run the trainer model",
    "start": "878320",
    "end": "884320"
  },
  {
    "text": "in a process called the neural architecture search which basically means we're going to train a bunch of",
    "start": "884320",
    "end": "889600"
  },
  {
    "text": "models and select the best one uh but when I say a bunch I'm talking about thousands or tens of thousands of",
    "start": "889600",
    "end": "895880"
  },
  {
    "text": "experiments mhm and she computed uh using some rough estimations to to be",
    "start": "895880",
    "end": "901680"
  },
  {
    "text": "said that the amount of CO2 emitted by this process is equivalent to the amount",
    "start": "901680",
    "end": "908040"
  },
  {
    "text": "of the life term uh omission of five cars um or several flights or I don't I",
    "start": "908040",
    "end": "915880"
  },
  {
    "text": "don't remember the full detail but I mean something that's I think it was five part I remember this coming out and I was also shocked yeah I actually",
    "start": "915880",
    "end": "923399"
  },
  {
    "text": "talked about this in an episode way back when that came out I remember us just commenting on it yeah everybody was",
    "start": "923399",
    "end": "929160"
  },
  {
    "text": "about it and really hit me in a place that I this is something that I was thinking about and was really happy to I",
    "start": "929160",
    "end": "934319"
  },
  {
    "text": "mean I was sad to see that that my intuitions were right in some sense I was kind of hoping that maybe it's you",
    "start": "934319",
    "end": "940120"
  },
  {
    "text": "know it's not that bad but and and kind of then Jesse and I were having discussions along with other people at",
    "start": "940120",
    "end": "945759"
  },
  {
    "text": "AA too and kind of we were saying that you know this is something we need to do something or you know to make the",
    "start": "945759",
    "end": "952040"
  },
  {
    "text": "community more aware of it and we were thinking about I mean ai2 is an institution that our goal is I mean I'm",
    "start": "952040",
    "end": "958279"
  },
  {
    "text": "I'm no longer working there but at the time I was working there H to do AI for the common good and you know this feels",
    "start": "958279",
    "end": "963600"
  },
  {
    "text": "like a natural fit for the goals of the organizations and we got um oron the CEO",
    "start": "963600",
    "end": "970639"
  },
  {
    "text": "and nor Smith who who was my manager and Jess's adviser at the time um on board",
    "start": "970639",
    "end": "977120"
  },
  {
    "text": "and you know we work this piece and just hoping to get people um you know",
    "start": "977120",
    "end": "982800"
  },
  {
    "text": "thinking about this you know not NE thinking about this in terms of uh finding more accurate ways to quantify",
    "start": "982800",
    "end": "990160"
  },
  {
    "text": "uh how much energy and uh is omitted and how much are the costs of these",
    "start": "990160",
    "end": "995319"
  },
  {
    "text": "experiments and trying to encourage the community to work on more efficient solutions that would allow us to reduce",
    "start": "995319",
    "end": "1001319"
  },
  {
    "text": "these costs MH yeah that's and one way that Roy and I think like one thing that Roy just mentioned um is that we brought",
    "start": "1001319",
    "end": "1009079"
  },
  {
    "text": "different perspectives to this I completely agree with everything that Roy just said like that's super motivational I think that's you know",
    "start": "1009079",
    "end": "1015160"
  },
  {
    "text": "very important going forward that we keep track of CO2 estimates and we do great job at that there's another um",
    "start": "1015160",
    "end": "1021399"
  },
  {
    "text": "side to this also which we write about in our green AI paper uh where we talk",
    "start": "1021399",
    "end": "1026640"
  },
  {
    "text": "about the the sort of research inequality or inequality in the research Community where some of these uh",
    "start": "1026640",
    "end": "1033640"
  },
  {
    "text": "experiments really could only be done by sort of the 1% of the research Community",
    "start": "1033640",
    "end": "1039438"
  },
  {
    "text": "those that have access to tremendous numbers of gpus or just like lots of",
    "start": "1039439",
    "end": "1044640"
  },
  {
    "text": "machines so one question that we addressed in our paper is is this",
    "start": "1044640",
    "end": "1051000"
  },
  {
    "text": "valuable research that we should treat on the same level as like other types of research that can be done primarily",
    "start": "1051000",
    "end": "1057880"
  },
  {
    "text": "motivated by just a good idea rather than really expensive experiments and so",
    "start": "1057880",
    "end": "1064400"
  },
  {
    "text": "both of these are sort of negative consequences of this increasing Trend",
    "start": "1064400",
    "end": "1069559"
  },
  {
    "text": "that we observed and one interesting thing I think this is an interesting thing sort of back in",
    "start": "1069559",
    "end": "1074720"
  },
  {
    "text": "2019 going back to that strubel at all paper I found that through a number of",
    "start": "1074720",
    "end": "1081159"
  },
  {
    "text": "conversations that I had had and also just like the general information I saw online when before Emma uh and her",
    "start": "1081159",
    "end": "1089520"
  },
  {
    "text": "colleagues wrote that paper estimating the CO2 emissions there was an understanding of like how some work was",
    "start": "1089520",
    "end": "1096679"
  },
  {
    "text": "very expensive how some work was quote boiling the ocean for example just to get a 1% Improvement or half a percent",
    "start": "1096679",
    "end": "1104240"
  },
  {
    "text": "Improvement on some task and so when Emma wrote that paper I was surprised",
    "start": "1104240",
    "end": "1110640"
  },
  {
    "text": "but again I mean I felt similarly to Roy I I was surprised I wish I hadn't been",
    "start": "1110640",
    "end": "1115720"
  },
  {
    "text": "you know surprised by the results that I saw I wish they had claimed that people were emitting less CO2 but it really did",
    "start": "1115720",
    "end": "1123320"
  },
  {
    "text": "capture like her paper and then our paper as well I think these got so much traction partly because we were",
    "start": "1123320",
    "end": "1129440"
  },
  {
    "text": "outlining a trend that other people had also noticed and yeah like I said that Trend really does I think we focus on",
    "start": "1129440",
    "end": "1135400"
  },
  {
    "text": "two facets there are probably others but the CO2 emission and also the sort of This research inequality are both direct",
    "start": "1135400",
    "end": "1142880"
  },
  {
    "text": "consequences of that that increasing [Music]",
    "start": "1142880",
    "end": "1155440"
  },
  {
    "text": "Trend hey friends this episode of practical AI is brought to you by kodes a podcast from the team at Heroku that",
    "start": "1155440",
    "end": "1162600"
  },
  {
    "text": "exports code technology tools tips and developer life there's tons of great conversations on the cish podcast so I",
    "start": "1162600",
    "end": "1169240"
  },
  {
    "text": "would encourage you to check it out and subscribe but in particular I wanted to bring to your attention two episodes",
    "start": "1169240",
    "end": "1174880"
  },
  {
    "text": "episode 98 and 99 or julon duk explores the ethical and Technical sides of deep",
    "start": "1174880",
    "end": "1181039"
  },
  {
    "text": "fakes the rise of manipulated pictures and videos and other forms of computer generated media are able to cause",
    "start": "1181039",
    "end": "1187720"
  },
  {
    "text": "uncertainty and doubt what we see and hear online so how are we able to use these tools for good if at all here's a",
    "start": "1187720",
    "end": "1195159"
  },
  {
    "text": "sneak peek let's say we want to do a deep fake or for my voice and we train",
    "start": "1195159",
    "end": "1200799"
  },
  {
    "text": "the model and we have enough data and everything this will be also able to",
    "start": "1200799",
    "end": "1206840"
  },
  {
    "text": "imitate my accent for example like how I pronounce English and the strong pieces",
    "start": "1206840",
    "end": "1213880"
  },
  {
    "text": "of my accent or is not there yet it really depends if there would be a",
    "start": "1213880",
    "end": "1219280"
  },
  {
    "text": "person with similar Accent on the input then it would be fine but it's it's kind",
    "start": "1219280",
    "end": "1224799"
  },
  {
    "text": "of cheating you you you can think it's cheating because we're reusing accent of a different person that's similar to",
    "start": "1224799",
    "end": "1230240"
  },
  {
    "text": "your accent but if it would be like an an like an American native speaker or a British a person with a British accent",
    "start": "1230240",
    "end": "1238200"
  },
  {
    "text": "or like whatever diff whatever other other accent then um it will kind of be",
    "start": "1238200",
    "end": "1243720"
  },
  {
    "text": "a mixture on the output so we're not there yet in terms of converting accents",
    "start": "1243720",
    "end": "1249840"
  },
  {
    "text": "it's it's a little bit more difficult than we initially anticipated cuz like when we started the company with thought it would you know we'll kind of solve it",
    "start": "1249840",
    "end": "1257400"
  },
  {
    "text": "in a year or something but then it turned out oh no we're here for we're here for much",
    "start": "1257400",
    "end": "1263280"
  },
  {
    "text": "longer check these episodes out links are in the show us to both episodes or",
    "start": "1263280",
    "end": "1268600"
  },
  {
    "text": "head to Heroku com/ podcasts to listen And subscribe again check the shows for",
    "start": "1268600",
    "end": "1274080"
  },
  {
    "text": "links or go to Heroku [Music]",
    "start": "1274080",
    "end": "1287520"
  },
  {
    "text": "podcasts [Music] [Applause] so you brought up something that that",
    "start": "1287520",
    "end": "1294080"
  },
  {
    "text": "really kind of got my brain really going there for a minute and I was I was thinking about the fact that you know",
    "start": "1294080",
    "end": "1301120"
  },
  {
    "text": "this really can matter a lot even if not a lot of practitioner you know the the number of practitioners in AI relative",
    "start": "1301120",
    "end": "1307640"
  },
  {
    "text": "to all the people producing uh CO2 is quite small but you mentioned going",
    "start": "1307640",
    "end": "1314159"
  },
  {
    "text": "through all these models and when we're doing things like hyperparameter optimization and trying you know little",
    "start": "1314159",
    "end": "1319960"
  },
  {
    "text": "adjustments to architectures all the way through and then one practitioner doing work is essentially you know being",
    "start": "1319960",
    "end": "1327840"
  },
  {
    "text": "thousands of practitioners on a per model basis um as they're trying to hone in on that it really amplifies the",
    "start": "1327840",
    "end": "1334440"
  },
  {
    "text": "impact of what can happen I mean so so I guess you know it's not it's less of a",
    "start": "1334440",
    "end": "1340559"
  },
  {
    "text": "problem that a very few people are doing and more of a problem that that because of that amplification is is quite",
    "start": "1340559",
    "end": "1347760"
  },
  {
    "text": "outsized relative to the number of people doing it am I getting that right am I understanding the problem in the",
    "start": "1347760",
    "end": "1353039"
  },
  {
    "text": "way that you're thinking about it or or am I missing something there so I'm not 100% sure that I understood you so let",
    "start": "1353039",
    "end": "1359640"
  },
  {
    "text": "me try to sure to to say where I think this is uh going so I mean so I'm",
    "start": "1359640",
    "end": "1366400"
  },
  {
    "text": "assuming you're talking about the environmental uh yeah environmental because uh because the inequality aspect",
    "start": "1366400",
    "end": "1372640"
  },
  {
    "text": "I think is pretty clear that I mean a very small proportion of the community can afford to run these experiment",
    "start": "1372640",
    "end": "1379640"
  },
  {
    "text": "um and kind of when we're thinking about the environmental uh effect then some",
    "start": "1379640",
    "end": "1385039"
  },
  {
    "text": "people argue and and I'm am not sure I disagree even that it's not so bad",
    "start": "1385039",
    "end": "1390120"
  },
  {
    "text": "because these experiments are being run just a handful of time and I might agree on that I must say there are different",
    "start": "1390120",
    "end": "1396720"
  },
  {
    "text": "ways in which the AI Community is contributing so and so quote unquote to",
    "start": "1396720",
    "end": "1402000"
  },
  {
    "text": "the emission of CO2 to the atmosphere and probably the one that's easiest to",
    "start": "1402000",
    "end": "1407640"
  },
  {
    "text": "measure is the the most expensive experiments that's perhaps one dimension you can also think about I mean the",
    "start": "1407640",
    "end": "1413520"
  },
  {
    "text": "entire uh the amount of training being done by the entire community and probably most influential in this sense",
    "start": "1413520",
    "end": "1420320"
  },
  {
    "text": "is the the cost of inference of cost of taking a model that's been train and running it and this is one operation is",
    "start": "1420320",
    "end": "1428120"
  },
  {
    "text": "very cheap uh especially obviously compared to training a model but this is something that happens at scale uh if",
    "start": "1428120",
    "end": "1434640"
  },
  {
    "text": "you think about I don't know the amount of Google search queries that are being run per day or the translation or the",
    "start": "1434640",
    "end": "1440919"
  },
  {
    "text": "number of videos being edited or recommendations in in various websites",
    "start": "1440919",
    "end": "1446400"
  },
  {
    "text": "so there's different dimensions to these problems and I think what we're trying to promote is not so necessarily to say",
    "start": "1446400",
    "end": "1452520"
  },
  {
    "text": "uh look we're boiling the ocean as Jesse said quote unquote but I mean we don't know exactly what is it that we're doing",
    "start": "1452520",
    "end": "1460000"
  },
  {
    "text": "and let's be more honest about it let's do a better job at reporting and let's",
    "start": "1460000",
    "end": "1465039"
  },
  {
    "text": "try to reduce the these costs I mean and I mean it's hard to argue against uh I",
    "start": "1465039",
    "end": "1470200"
  },
  {
    "text": "mean who doesn't want cheaper models right it's obviously that uh other things are uh and you know if if cheaper",
    "start": "1470200",
    "end": "1478200"
  },
  {
    "text": "models perform slightly worse and maybe this slightly worse translates to slightly less Revenue then maybe cheaper",
    "start": "1478200",
    "end": "1484720"
  },
  {
    "text": "is there are different ways to Define cheap so I think what we're trying to promote is to get more people thinking",
    "start": "1484720",
    "end": "1490880"
  },
  {
    "text": "about it and not just improving another Epsilon on the accuracy level yeah",
    "start": "1490880",
    "end": "1496600"
  },
  {
    "text": "that's super helpful I think you know one of the things that's running through my mind is um uh I guess like talking",
    "start": "1496600",
    "end": "1506080"
  },
  {
    "text": "about you know what are the other options what does it mean to do green Ai",
    "start": "1506080",
    "end": "1511440"
  },
  {
    "text": "and I have this parallel in my mind so I come from a physics background and like if you're in high energy physics now",
    "start": "1511440",
    "end": "1517760"
  },
  {
    "text": "like there's just been a progression of larger and larger particle accelerators right and now if you want to do high",
    "start": "1517760",
    "end": "1524080"
  },
  {
    "text": "energy physics you're going to spend some time at CERN um in Switzerland or or whatever just because no one has",
    "start": "1524080",
    "end": "1529840"
  },
  {
    "text": "another CERN right like they're they're just not there so like is there another",
    "start": "1529840",
    "end": "1535320"
  },
  {
    "text": "option for and I'm thinking particularly Jesse of what you were highlighting in terms of the research inequality I think",
    "start": "1535320",
    "end": "1541679"
  },
  {
    "text": "that's a really great Point like what can we do in terms of reducing that",
    "start": "1541679",
    "end": "1547200"
  },
  {
    "text": "inequality and is there something more that we can say other than like tough luck go work at Google or somewhere that",
    "start": "1547200",
    "end": "1553960"
  },
  {
    "text": "has these like amazing resour you know in seemingly endless resources to do",
    "start": "1553960",
    "end": "1559120"
  },
  {
    "text": "these massive experiments yeah so that's a great question I think this is something that comes up a lot is sort of",
    "start": "1559120",
    "end": "1564399"
  },
  {
    "text": "the relationship when we talk about green AI sometimes somebody will say to us oh but in biology it costs so much to",
    "start": "1564399",
    "end": "1571679"
  },
  {
    "text": "do any experiment because you need a wet lab and because you need you know some equipment and you just can't do it",
    "start": "1571679",
    "end": "1577279"
  },
  {
    "text": "without that equipment so is it bad that some experiments in our field are",
    "start": "1577279",
    "end": "1582559"
  },
  {
    "text": "expensive and I think the answer here is really that in the computational sciences and in machine learning in NLP",
    "start": "1582559",
    "end": "1589120"
  },
  {
    "text": "in particular we really can there are a few things that we can do that make future comparisons against our work with",
    "start": "1589120",
    "end": "1596799"
  },
  {
    "text": "smaller budgets easier so one example of that might be sure I train a model on",
    "start": "1596799",
    "end": "1604039"
  },
  {
    "text": "all of the language data on the entire internet right but I can also uh",
    "start": "1604039",
    "end": "1609440"
  },
  {
    "text": "evaluate that same model after training on only a fraction of that data and if I",
    "start": "1609440",
    "end": "1614640"
  },
  {
    "text": "do this let's say I train and evaluate evaluation um in this case is typically pretty",
    "start": "1614640",
    "end": "1620720"
  },
  {
    "text": "inexpensive so your evaluation set your data set that you evaluate on is often",
    "start": "1620720",
    "end": "1626039"
  },
  {
    "text": "much smaller than it's like you know a tenth or uh even smaller of your training size so one thing that we can",
    "start": "1626039",
    "end": "1633440"
  },
  {
    "text": "do is just checkpoint our model or evaluate it regularly throughout",
    "start": "1633440",
    "end": "1638720"
  },
  {
    "text": "training and then a future researcher will be able to come up with a new idea",
    "start": "1638720",
    "end": "1644480"
  },
  {
    "text": "let's say they have a new model that they want to evaluate and can compare",
    "start": "1644480",
    "end": "1649559"
  },
  {
    "text": "against some of those sort of smaller budget evaluations so for us the point",
    "start": "1649559",
    "end": "1655399"
  },
  {
    "text": "here is that in our field we really do have a few ways that we can uh sort of build in these sort of lowbudget",
    "start": "1655399",
    "end": "1663039"
  },
  {
    "text": "comparison opportunities and that enables um not just future comparisons but that really",
    "start": "1663039",
    "end": "1669519"
  },
  {
    "text": "drives the sort of competitive nature of our field where instead of trying to",
    "start": "1669519",
    "end": "1674919"
  },
  {
    "text": "improve just the absolute best found performance somebody could try to find a better performance efficiency tradeoff",
    "start": "1674919",
    "end": "1682159"
  },
  {
    "text": "where at a low budget their new idea a low budget for you know the number of",
    "start": "1682159",
    "end": "1687799"
  },
  {
    "text": "parameters in your model or the total number of experiments of hyperparameter tuning or the amount of training data",
    "start": "1687799",
    "end": "1693840"
  },
  {
    "text": "you use along any of those Dimensions somebody else might come along and try to compare against your work",
    "start": "1693840",
    "end": "1701039"
  },
  {
    "text": "specifically in those sort of lowbudget regimes and so I think here that's a key",
    "start": "1701039",
    "end": "1706440"
  },
  {
    "text": "difference between our field and you know physics like you mention or we often hear biology and really if you",
    "start": "1706440",
    "end": "1712480"
  },
  {
    "text": "think about it if you're training a model and it costs you say a million dollars to train on all of the internet",
    "start": "1712480",
    "end": "1718519"
  },
  {
    "text": "spending an extra $10,000 on just evaluating that model spending an extra you know 10th of 1% or",
    "start": "1718519",
    "end": "1725360"
  },
  {
    "text": "some small fraction of your total budget so that other people in the future they",
    "start": "1725360",
    "end": "1731440"
  },
  {
    "text": "can have an opportunity they've got that hook to compare against that is what one",
    "start": "1731440",
    "end": "1737399"
  },
  {
    "text": "way that can help Drive the overall cost down by promoting that kind of",
    "start": "1737399",
    "end": "1743159"
  },
  {
    "text": "competition yeah I I totally agree with whaty said I think presenting another",
    "start": "1743159",
    "end": "1748799"
  },
  {
    "text": "angle of this so currently there are certain Norms in our community and kind of I mean there's certain ways of I mean",
    "start": "1748799",
    "end": "1756440"
  },
  {
    "text": "topics of research that get you know uh more visibility and more credit from the community while other aren't and I don't",
    "start": "1756440",
    "end": "1763760"
  },
  {
    "text": "want to say the the naive assumption is you know you know go work at Google as you said I mean but I mean the fact is",
    "start": "1763760",
    "end": "1770880"
  },
  {
    "text": "that when we were thinking about this paper a couple of years back we were doing a a short survey of papers in ACL",
    "start": "1770880",
    "end": "1777880"
  },
  {
    "text": "that's the top venue for our field and in other similar venues in other fields of AI and we found we had a very hard",
    "start": "1777880",
    "end": "1785519"
  },
  {
    "text": "time finding papers that focused on efficiency most of the papers we were looking at were trying to say okay we",
    "start": "1785519",
    "end": "1790600"
  },
  {
    "text": "did this and this and that and we got some better Improvement here and this and this and that and we got some you know T of 10 of a percent better on some",
    "start": "1790600",
    "end": "1798440"
  },
  {
    "text": "accuracy answering questions 10th of a percent uh better or translating um a",
    "start": "1798440",
    "end": "1804399"
  },
  {
    "text": "fraction of a percent better there and what we're trying to argue that this is not a good balance uh we want to see",
    "start": "1804399",
    "end": "1811480"
  },
  {
    "text": "it's good that people are working to make our models more accurate we're not arguing that this is not important and and similar we're not arguing that the",
    "start": "1811480",
    "end": "1818159"
  },
  {
    "text": "big models aren't important they're making huge contributions to our field but we think that a larger chunk of the",
    "start": "1818159",
    "end": "1824080"
  },
  {
    "text": "research effort should go towards trying to find a solution that are not uh",
    "start": "1824080",
    "end": "1829960"
  },
  {
    "text": "Epsilon better but are know twice as fast or take 10 10% of the memory or",
    "start": "1829960",
    "end": "1836159"
  },
  {
    "text": "what have you and we're trying to work with the research Community by uh",
    "start": "1836159",
    "end": "1841799"
  },
  {
    "text": "providing uh ways to publish this work for instance we've uh established tracks",
    "start": "1841799",
    "end": "1848120"
  },
  {
    "text": "in tracks are kind of like you can think of it as topics in major conferences where uh when we were work working on",
    "start": "1848120",
    "end": "1854919"
  },
  {
    "text": "some of our work that try to promote efficiency uh presented an efficient solution as I said that works five times",
    "start": "1854919",
    "end": "1862120"
  },
  {
    "text": "faster but doesn't improve the performance we had a hard time uh deciding where to send this paper to and",
    "start": "1862120",
    "end": "1868399"
  },
  {
    "text": "where would get the the the best audience uh to appreciate it and what",
    "start": "1868399",
    "end": "1875919"
  },
  {
    "text": "what we've were able to do in the past year is to set up a a green NLP track or an efficient NLP track in in our",
    "start": "1875919",
    "end": "1882639"
  },
  {
    "text": "conferences that allow uh works that focus on that to get published and to",
    "start": "1882639",
    "end": "1888240"
  },
  {
    "text": "get the visibility that they deserve yeah that's great and I think another thing to to build on what Ro just said",
    "start": "1888240",
    "end": "1894440"
  },
  {
    "text": "is our community like the I think one strength of the research Community is really that it's just a collection of",
    "start": "1894440",
    "end": "1901519"
  },
  {
    "text": "individuals all trying to do the best work that they can uh there is no",
    "start": "1901519",
    "end": "1907440"
  },
  {
    "text": "overall governing body so when we think about like how can we get our community to focus on more efficient",
    "start": "1907440",
    "end": "1914600"
  },
  {
    "text": "approaches it's kind of tricky you know we can't it's just not possible for us to say like some fraction of the work",
    "start": "1914600",
    "end": "1921039"
  },
  {
    "text": "should cover this this topic um so instead we thought a lot about the types of incentive structures that impact",
    "start": "1921039",
    "end": "1928519"
  },
  {
    "text": "people in our field and creating this track as Roy just mentioned is one of the ways that we can promote this and",
    "start": "1928519",
    "end": "1936000"
  },
  {
    "text": "provide an opportunity sort of lowering barriers for publishing work on work that promotes",
    "start": "1936000",
    "end": "1941920"
  },
  {
    "text": "[Music] efficiency",
    "start": "1941920",
    "end": "1948730"
  },
  {
    "text": "[Music]",
    "start": "1948730",
    "end": "1956589"
  },
  {
    "text": "have you heard about knowable it is an awesome new platform for learning from the world's best Minds anytime anywhere",
    "start": "1957399",
    "end": "1964279"
  },
  {
    "text": "at your own pace through audio learn about the performance benefits of a plant-based lifestyle from NBA All-Star",
    "start": "1964279",
    "end": "1971360"
  },
  {
    "text": "Chris Paul or how to launch a startup from Reddit co-founder Alexis Ohanian",
    "start": "1971360",
    "end": "1976399"
  },
  {
    "text": "there's even a 10 lesson course from Astronaut Scott Kelly here's a sneak",
    "start": "1976399",
    "end": "1981720"
  },
  {
    "text": "peek we learned a lot up there but what can you learn from a life in space the",
    "start": "1981720",
    "end": "1987320"
  },
  {
    "text": "answers might surprise you in this knowable course I want to share some of the things I've learned that you might",
    "start": "1987320",
    "end": "1993039"
  },
  {
    "text": "not expect lessons about leadership on a dark night on an aircraft carrier in the",
    "start": "1993039",
    "end": "1998480"
  },
  {
    "text": "middle of a churning sea lessons about the fear you feel with 7 million PBS of",
    "start": "1998480",
    "end": "2004039"
  },
  {
    "text": "thrust exploding underneath you and most of all there's an idea out",
    "start": "2004039",
    "end": "2009320"
  },
  {
    "text": "there that astronauts are always perfect failure is not an option right that's",
    "start": "2009320",
    "end": "2014720"
  },
  {
    "text": "why I want to take you through some of my life experiences to show you how that's just not true I believe everyday regular human",
    "start": "2014720",
    "end": "2022840"
  },
  {
    "text": "failure if we handle it right can be one of our greatest opportunities to learn grow and succeed knowable is accessible",
    "start": "2022840",
    "end": "2031320"
  },
  {
    "text": "on your phone and on the web and each audio course is broken out into individual lessons usually around 15",
    "start": "2031320",
    "end": "2037039"
  },
  {
    "text": "minutes long as a change log listener you can get an annual membership to Noble for 20% off get unlimited access",
    "start": "2037039",
    "end": "2044320"
  },
  {
    "text": "to every noble audio course right now just download the Noble app or visit noble. FYI and use code Chang log for",
    "start": "2044320",
    "end": "2052839"
  },
  {
    "text": "that 20% discount we put a link in your show notes for easy clickins check out knowable today and start learning from",
    "start": "2052839",
    "end": "2059960"
  },
  {
    "text": "hundreds of top experts from around the world once again that's knowable FYI code Chang",
    "start": "2059960",
    "end": "2066720"
  },
  {
    "text": "log [Music]",
    "start": "2066720",
    "end": "2074839"
  },
  {
    "text": "so this is really interesting to me and I'm as I'm listening to you I'm trying to think how I'm going to implement so",
    "start": "2074839",
    "end": "2082079"
  },
  {
    "text": "can you kind of describe some of the the good examples of how green ey green AI",
    "start": "2082079",
    "end": "2088118"
  },
  {
    "text": "has been implemented uh before and any kind of any kind of guidance so if I'm",
    "start": "2088119",
    "end": "2093560"
  },
  {
    "text": "if I'm a practitioner you know you you've hit on some of the the practice is but um either go through someone",
    "start": "2093560",
    "end": "2100000"
  },
  {
    "text": "else's example or something that you're that you've described to people CU I'm just trying to really make it to where",
    "start": "2100000",
    "end": "2105520"
  },
  {
    "text": "when I walk out of here I want to be able to go ahead and Implement that yeah so I guess I can I'll talk a little bit",
    "start": "2105520",
    "end": "2111680"
  },
  {
    "text": "about this so one thing that I mentioned already was performance efficiency tradeoffs and I think the the key idea",
    "start": "2111680",
    "end": "2118880"
  },
  {
    "text": "here and one thing that we found um when we did the survey that Roy mentioned of papers in our field is that most most",
    "start": "2118880",
    "end": "2126079"
  },
  {
    "text": "papers just don't report anything they don't report any efficiency uh related",
    "start": "2126079",
    "end": "2133200"
  },
  {
    "text": "metrics at all most papers in our field invent some new model or some new you",
    "start": "2133200",
    "end": "2139560"
  },
  {
    "text": "know loss function some new training scheme something like that and then claim in a table here is our better",
    "start": "2139560",
    "end": "2146160"
  },
  {
    "text": "performance we beat our baselines but they don't report for example training curves or you know some other measure",
    "start": "2146160",
    "end": "2154960"
  },
  {
    "text": "where you can trade off efficiency and performance maybe accuracy could be one measure of",
    "start": "2154960",
    "end": "2160599"
  },
  {
    "text": "performance so an example of this and and I guess the first thing that I would say here is what we hope everyone in the",
    "start": "2160599",
    "end": "2167560"
  },
  {
    "text": "research Community starts to do and we are seeing this uh happen now is just",
    "start": "2167560",
    "end": "2173000"
  },
  {
    "text": "report something report some measure of how um maybe it's going to be the",
    "start": "2173000",
    "end": "2178560"
  },
  {
    "text": "floating Point operations to run your model maybe it's going to be a training curve maybe it's going to be um the",
    "start": "2178560",
    "end": "2185599"
  },
  {
    "text": "results from your hyperparameter optim a search right so one example of this um I",
    "start": "2185599",
    "end": "2192680"
  },
  {
    "text": "can point to is a paper and I think this is I use this as a positive example of how somebody can report this kind of",
    "start": "2192680",
    "end": "2198280"
  },
  {
    "text": "information so Roy and I wrote a paper on that used early stopping so we",
    "start": "2198280",
    "end": "2205400"
  },
  {
    "text": "partway processed uh an example and then potentially had our model stop early so",
    "start": "2205400",
    "end": "2213160"
  },
  {
    "text": "instead of feeding the example all the way through our model and then coming up with a prediction at the end and we had",
    "start": "2213160",
    "end": "2218960"
  },
  {
    "text": "ways for our model to stop this computation early and make a decision quickly and this method allowed us to",
    "start": "2218960",
    "end": "2226520"
  },
  {
    "text": "show performance efficiency trade-offs these smooth curves which anyone can",
    "start": "2226520",
    "end": "2231960"
  },
  {
    "text": "then compare against at any point and what I would hope to see is other work come along and show a better curve",
    "start": "2231960",
    "end": "2238839"
  },
  {
    "text": "rather than just a single point on this uh performance efficiency trade-off they can report just here's how efficient my",
    "start": "2238839",
    "end": "2245720"
  },
  {
    "text": "model was and here's the performance potentially beating our entire curve or just a single point you know better",
    "start": "2245720",
    "end": "2253119"
  },
  {
    "text": "along one of those dimensions in this way like just reporting more information allows others to compete along either of",
    "start": "2253119",
    "end": "2261000"
  },
  {
    "text": "those Dimensions or potentially draw a better curve so I'm curious I think a lot of what we've talked about has been",
    "start": "2261000",
    "end": "2268480"
  },
  {
    "text": "focused on like what are ways in which we can still explore this regime of like",
    "start": "2268480",
    "end": "2274880"
  },
  {
    "text": "large models but potentially be responsible about how we're reporting the cost of it and or how we're allowing",
    "start": "2274880",
    "end": "2281599"
  },
  {
    "text": "others to build on top of what what we're building um I'm wondering how",
    "start": "2281599",
    "end": "2287119"
  },
  {
    "text": "maybe another side of this fits into this whole discussion which is just playing smaller and more and or more",
    "start": "2287119",
    "end": "2294640"
  },
  {
    "text": "efficient or different models so I'm thinking of things like uh recently I was U playing around with like quartz",
    "start": "2294640",
    "end": "2302520"
  },
  {
    "text": "net which is this um in to end speech recognition model from Nvidia which is",
    "start": "2302520",
    "end": "2308200"
  },
  {
    "text": "very compact based on uh these like 1D time separable convolutions and it's",
    "start": "2308200",
    "end": "2314480"
  },
  {
    "text": "like like the whole model like on dis is like 90 megabytes or or something like",
    "start": "2314480",
    "end": "2319520"
  },
  {
    "text": "that and like shows like really good performance almost like comparable or",
    "start": "2319520",
    "end": "2325000"
  },
  {
    "text": "comparable to like these really large speech recognition models so I'm curious",
    "start": "2325000",
    "end": "2330640"
  },
  {
    "text": "maybe that also has some advantages in terms of like some of the interpretability things Roy that you're",
    "start": "2330640",
    "end": "2336079"
  },
  {
    "text": "interested in where do you do you see that this whole regime of new and",
    "start": "2336079",
    "end": "2341359"
  },
  {
    "text": "different more efficient models fitting into this and do you see momentum in that area or or good examples in that",
    "start": "2341359",
    "end": "2347560"
  },
  {
    "text": "area as well yeah I think there's been a lot of I mean I think the thing that I",
    "start": "2347560",
    "end": "2352839"
  },
  {
    "text": "said the few minutes ago about seeing that we saw very little work that focuses on efficiency I think in the",
    "start": "2352839",
    "end": "2359520"
  },
  {
    "text": "last couple of years there's been more and more work that focuses on that and we're delighted to see that it's",
    "start": "2359520",
    "end": "2365720"
  },
  {
    "text": "probably has nothing to do with us it's probably something that would have happened anyway and I think the main ideas that",
    "start": "2365720",
    "end": "2371800"
  },
  {
    "text": "are being mostly explored are ways to make inference more efficient and this",
    "start": "2371800",
    "end": "2377000"
  },
  {
    "text": "makes sense at least in the environmental aspect but also you know just in terms of you want to put a",
    "start": "2377000",
    "end": "2383280"
  },
  {
    "text": "speech recognition or an image processing or text processing machine on",
    "start": "2383280",
    "end": "2388560"
  },
  {
    "text": "your phone and then you need for it to be you know small in terms of number of parameters or the amount of space it it",
    "start": "2388560",
    "end": "2395119"
  },
  {
    "text": "requires or you know doesn't require much energy so it doesn't drain your battery and so on so there has been a lot of",
    "start": "2395119",
    "end": "2402599"
  },
  {
    "text": "effort along these dimensions and I think the the main governing technology there is to train a big model you know",
    "start": "2402599",
    "end": "2409640"
  },
  {
    "text": "that train it as big as you can and then train another model to imitate this",
    "start": "2409640",
    "end": "2414680"
  },
  {
    "text": "model to some extent or to to take the the large model and get the same performance using fewer resources there",
    "start": "2414680",
    "end": "2421520"
  },
  {
    "text": "different techniques of doing that but that's probably the most common thing that we've seen what I think is very",
    "start": "2421520",
    "end": "2427319"
  },
  {
    "text": "interesting and people aren't putting that much effort into is to make the",
    "start": "2427319",
    "end": "2432480"
  },
  {
    "text": "other parts of the process more efficient namely training and what we call model selection basically",
    "start": "2432480",
    "end": "2437960"
  },
  {
    "text": "hyperparameter tuning or other ways of selecting your best model and I think",
    "start": "2437960",
    "end": "2443200"
  },
  {
    "text": "this is an exciting uh direction that relates to the motivation it's not like",
    "start": "2443200",
    "end": "2448240"
  },
  {
    "text": "I mean it's not like there's Jesse thing and my thing it's we're both excited about both of these uh motivations and I",
    "start": "2448240",
    "end": "2454319"
  },
  {
    "text": "think this is a really one way to improve the ability of the entire",
    "start": "2454319",
    "end": "2460160"
  },
  {
    "text": "Community to conduct Cutting Edge experiments by reducing the cost of these processes so in those other parts",
    "start": "2460160",
    "end": "2467480"
  },
  {
    "text": "of our process that you're talking about I can just imagine like there have been times and I will totally confess to this",
    "start": "2467480",
    "end": "2473720"
  },
  {
    "text": "that like it whether it be hyperparameter tuning or like model selection or something like the",
    "start": "2473720",
    "end": "2480079"
  },
  {
    "text": "logically the easiest way to go about that sometimes is just to say oh well I",
    "start": "2480079",
    "end": "2485119"
  },
  {
    "text": "can have this run for like the week and half and like go through all these things you know there may be a more like",
    "start": "2485119",
    "end": "2493599"
  },
  {
    "text": "a a smarter or better efficient way to to find the right Zone that I should be",
    "start": "2493599",
    "end": "2499240"
  },
  {
    "text": "in but I can just like get this running and like come back to it in a in a week and a half or or whatever do you also",
    "start": "2499240",
    "end": "2506000"
  },
  {
    "text": "find that to be sort of like a thing that you're talking to people about and a thing that you're running into is that",
    "start": "2506000",
    "end": "2511599"
  },
  {
    "text": "just sort of like I I don't want to call people lazy we're kind of spoiled in that way yeah that's that's what I was",
    "start": "2511599",
    "end": "2517720"
  },
  {
    "text": "thinking actually you know uh programmers and researchers are often lazy right they have like a machine",
    "start": "2517720",
    "end": "2524440"
  },
  {
    "text": "Let's just run it for a while yeah I think I mean the thing is this is super common like there absolutely is a",
    "start": "2524440",
    "end": "2530200"
  },
  {
    "text": "trade-off between how much time you put in as an engineer or as a researcher as any kind of practitioner",
    "start": "2530200",
    "end": "2537359"
  },
  {
    "text": "there's definitely a trade-off you could really carefully narrow down your hyperparameter",
    "start": "2537359",
    "end": "2542520"
  },
  {
    "text": "ranges and then spend less in GPU hours to find some good Optimum or you could",
    "start": "2542520",
    "end": "2551119"
  },
  {
    "text": "just set it up to be a super broad search let it run for a week and it'll you know it'll take you personally like",
    "start": "2551119",
    "end": "2557680"
  },
  {
    "text": "two days less time to run those experiments of your own hours right this",
    "start": "2557680",
    "end": "2563359"
  },
  {
    "text": "is the thing is this happens everyone does this there is some way to uh often",
    "start": "2563359",
    "end": "2570119"
  },
  {
    "text": "reduce the amount of time that you have to manually engineer something and you know another way this can happen is",
    "start": "2570119",
    "end": "2575200"
  },
  {
    "text": "you'll think of some algorithm to um say Implement to do inference in your",
    "start": "2575200",
    "end": "2580240"
  },
  {
    "text": "model and then later you'll be like oh you know what I could make that Faster by maybe 5% if I spent a full working",
    "start": "2580240",
    "end": "2587880"
  },
  {
    "text": "day rewriting all of that code sometimes like it's just not worth it the key idea",
    "start": "2587880",
    "end": "2594520"
  },
  {
    "text": "I think behind our green AI paper is that this happens all the time with people and often we just don't report",
    "start": "2594520",
    "end": "2602079"
  },
  {
    "text": "that so one analogy that I use is is that we in our field we don't keep lab",
    "start": "2602079",
    "end": "2607599"
  },
  {
    "text": "notebooks we just don't record a lot of the experiments that we run and we treat",
    "start": "2607599",
    "end": "2612880"
  },
  {
    "text": "those as like negative experiments experiments that don't show what we're looking for and then we only report the",
    "start": "2612880",
    "end": "2618960"
  },
  {
    "text": "positive experiments at the end right so we just report the single best performance that we found but with our",
    "start": "2618960",
    "end": "2625000"
  },
  {
    "text": "green AI paper what we argue is that we should be reporting even if it's not always like the most optimized the most",
    "start": "2625000",
    "end": "2632839"
  },
  {
    "text": "efficient approach the best thing that we can do right now is just report something you know it's a really good",
    "start": "2632839",
    "end": "2638839"
  },
  {
    "text": "point there and I want to ask Roy I wanted to bring you back into it for a moment the one of the things that you",
    "start": "2638839",
    "end": "2644880"
  },
  {
    "text": "say in your paper is you say finally we note that the the trend of releasing pre-trained models publicly is a green",
    "start": "2644880",
    "end": "2651000"
  },
  {
    "text": "success and we'd like to encourage organizations to continue to release their models in order to save others the",
    "start": "2651000",
    "end": "2656760"
  },
  {
    "text": "cost of retraining them so you know how far can you really get with pre-trained models do you feel that that will will",
    "start": "2656760",
    "end": "2663480"
  },
  {
    "text": "do that and is that kind of the way we should get people to start thinking about it because it seems like there's",
    "start": "2663480",
    "end": "2669400"
  },
  {
    "text": "certainly a uh uh a training component here in terms of driving people down the",
    "start": "2669400",
    "end": "2675119"
  },
  {
    "text": "right path yeah that that's a great point I mean so again this uh we",
    "start": "2675119",
    "end": "2680800"
  },
  {
    "text": "struggled a lot in the paper uh when we're writing it how to not you know I",
    "start": "2680800",
    "end": "2686119"
  },
  {
    "text": "mean what we call Red AI kind of there's a kind of the negative uh connotation",
    "start": "2686119",
    "end": "2692800"
  },
  {
    "text": "there but I mean basically I think there there's tons of value in uh these large",
    "start": "2692800",
    "end": "2698400"
  },
  {
    "text": "pre-train models and definitely uh I mean once you release them other people",
    "start": "2698400",
    "end": "2703440"
  },
  {
    "text": "can train models much more efficiently because if you build of models like I",
    "start": "2703440",
    "end": "2709079"
  },
  {
    "text": "don't know if no name is Bert or ber mean mean a lot to many of the listeners but I mean these are typical models that",
    "start": "2709079",
    "end": "2714960"
  },
  {
    "text": "are pre-trained I mean some company in this Cas Google or Facebook put a lot of efforts into training them and now they",
    "start": "2714960",
    "end": "2721200"
  },
  {
    "text": "release them and other people can take them and use them for their own task and the result will be much cheaper than if",
    "start": "2721200",
    "end": "2727319"
  },
  {
    "text": "people train their own model from scratch so this is definitely something that we encourage companies to do",
    "start": "2727319",
    "end": "2733559"
  },
  {
    "text": "company I say companies because the companies are basically the only entities that are can afford to to do",
    "start": "2733559",
    "end": "2740200"
  },
  {
    "text": "this and again kind of what our point is that these organization shouldn't stop training these huge models but we should",
    "start": "2740200",
    "end": "2747200"
  },
  {
    "text": "be thinking about the negative consequences and one way to mitigate the negative consequences is to make these",
    "start": "2747200",
    "end": "2752400"
  },
  {
    "text": "models public again to reduce the overall cost for everyone to run the",
    "start": "2752400",
    "end": "2757480"
  },
  {
    "text": "their experiments yeah so that has a huge benefit for those that are able to",
    "start": "2757480",
    "end": "2763240"
  },
  {
    "text": "use those pre-trained models and utilize model hubs and that sort of thing but of course there's like this element of of",
    "start": "2763240",
    "end": "2769960"
  },
  {
    "text": "companies where of course they're driven by by money companies make money and",
    "start": "2769960",
    "end": "2775680"
  },
  {
    "text": "they often want to keep their models proprietary or something like that but I think also like some of the things you",
    "start": "2775680",
    "end": "2782920"
  },
  {
    "text": "highlighted earlier is that they're you know in terms of like commercial benefit",
    "start": "2782920",
    "end": "2787960"
  },
  {
    "text": "and cost savings there's also a cost saving element to being able to",
    "start": "2787960",
    "end": "2793880"
  },
  {
    "text": "utilize uh something that's pre-trained and maybe fine-tune it uh and that's a huge saving in labor right um but also",
    "start": "2793880",
    "end": "2801640"
  },
  {
    "text": "in utilizing these more efficient or smaller models like maybe for inferencing like you you get less",
    "start": "2801640",
    "end": "2807760"
  },
  {
    "text": "latency you're you have less computational costs all of those things do you think there is that sort of",
    "start": "2807760",
    "end": "2815079"
  },
  {
    "text": "commercial or cost based um argument to be made to to companies I think so",
    "start": "2815079",
    "end": "2822240"
  },
  {
    "text": "there's um one thing that we saw recently there was a citation I think it was from Nvidia that claimed about 90%",
    "start": "2822240",
    "end": "2829480"
  },
  {
    "text": "of the cloud cost for machine learning was for inference and only 10 to 20% was",
    "start": "2829480",
    "end": "2835680"
  },
  {
    "text": "for training so if you can spend a bit extra during the training phase but end",
    "start": "2835680",
    "end": "2842400"
  },
  {
    "text": "up with a model that's a bit more computationally efficient for inference then potentially that could lead to",
    "start": "2842400",
    "end": "2848680"
  },
  {
    "text": "Savings in terms of like the amount of dollars spent renting instances in the cloud or GPU hours for inference for",
    "start": "2848680",
    "end": "2855880"
  },
  {
    "text": "example I think that a lot of our Focus has been on the research community so",
    "start": "2855880",
    "end": "2861280"
  },
  {
    "text": "you asked a question about like are companies motivated to keep their pre-trained models um",
    "start": "2861280",
    "end": "2867800"
  },
  {
    "text": "proprietary while that's true to some extent my guess is the it's hard to know",
    "start": "2867800",
    "end": "2874040"
  },
  {
    "text": "it's hard for me to know if a company has done that it's definitely possible it's almost surely happened",
    "start": "2874040",
    "end": "2879760"
  },
  {
    "text": "that some company has spent a lot of money training a model and then hasn't released it because it's part of their",
    "start": "2879760",
    "end": "2885119"
  },
  {
    "text": "business at the same time what we do know about is the research community and this has grown exponentially like not",
    "start": "2885119",
    "end": "2891760"
  },
  {
    "text": "just the size of our experiments has grown dramatically in recent years but this the number of people in our field",
    "start": "2891760",
    "end": "2897640"
  },
  {
    "text": "and also the number of papers that are written and the size of our conferences so across you know we are already seeing",
    "start": "2897640",
    "end": "2905359"
  },
  {
    "text": "such a tremendous growth there I think it's very worth it to focus on helping save computational costs across",
    "start": "2905359",
    "end": "2912000"
  },
  {
    "text": "inference training what have you yeah yeah I guess I think I'm the only person on the call working at a at a for-profit",
    "start": "2912000",
    "end": "2918960"
  },
  {
    "text": "you know commercial entity and certainly there are times when we aren't releasing that you know the way you would in the",
    "start": "2918960",
    "end": "2925240"
  },
  {
    "text": "research community so maybe I'm kind of curious you know would it make sense for",
    "start": "2925240",
    "end": "2931359"
  },
  {
    "text": "us to you yeah you still have a group of of people working in the organization that want to do the right thing always",
    "start": "2931359",
    "end": "2937359"
  },
  {
    "text": "you know so there you know they're they're no different in that way so maybe still having internal targets for",
    "start": "2937359",
    "end": "2943640"
  },
  {
    "text": "efficiency kind of like what you talked about earlier um and those internal metrics so that even if you aren't",
    "start": "2943640",
    "end": "2948880"
  },
  {
    "text": "publishing them you publishing them for competitive reasons or whatever it may be that you're you have a set of of",
    "start": "2948880",
    "end": "2955799"
  },
  {
    "text": "metrics that you're trying to to achieve and that might be that might be something they could spread through the",
    "start": "2955799",
    "end": "2961480"
  },
  {
    "text": "commercial space even when they're not willing to to do a full release does that sound like a reasonable you know",
    "start": "2961480",
    "end": "2967319"
  },
  {
    "text": "plan you know for those of us who who do want to strive toward that but maybe don't have the freedom to just release",
    "start": "2967319",
    "end": "2973480"
  },
  {
    "text": "yeah definitely I mean people have reached out to us from for for-profit companies and",
    "start": "2973480",
    "end": "2979000"
  },
  {
    "text": "with similar stories to what you're telling and they want to you know they work in a for-profit company so they",
    "start": "2979000",
    "end": "2984799"
  },
  {
    "text": "they're Limited in what they can do but they want to promote this they they uh sympathize with the motivation and they",
    "start": "2984799",
    "end": "2991319"
  },
  {
    "text": "want to do the right thing within the scope of their uh you know what they can do inside aany within commercial",
    "start": "2991319",
    "end": "2997720"
  },
  {
    "text": "constraints yeah exactly yeah I get it so yeah I mean you know as just said I mean most we're researchers we're not",
    "start": "2997720",
    "end": "3003880"
  },
  {
    "text": "part of I mean any company is different I guess with its own set of uh norms and rules uh but and we mostly uh",
    "start": "3003880",
    "end": "3011480"
  },
  {
    "text": "communicate with the research Community but I mean you know there there's stuff to be done everywhere you know thinking about you know thinking about efficiency",
    "start": "3011480",
    "end": "3018160"
  },
  {
    "text": "you don't have to persuade anybody that uh you know if if all all other things being equal if your uh tool runs twice",
    "start": "3018160",
    "end": "3025319"
  },
  {
    "text": "as fast or takes half the amount of memory then it's a u you know everybody wins great point it's harder when you",
    "start": "3025319",
    "end": "3032480"
  },
  {
    "text": "say okay I want to give up a fraction of percent or 1% or 10% and and get it to",
    "start": "3032480",
    "end": "3039079"
  },
  {
    "text": "run twice as fast and there you know it's it's hard to goes into you know questions of politics and regulations",
    "start": "3039079",
    "end": "3046040"
  },
  {
    "text": "and then what do these companies uh what is the price of for them to have expensive models running again more on",
    "start": "3046040",
    "end": "3053400"
  },
  {
    "text": "environmental side because this is not doesn't uh relate to the research Community because it's not open anyway",
    "start": "3053400",
    "end": "3059960"
  },
  {
    "text": "yeah I think another thing to build on that one thing that we're hoping with our uh for example the track that we",
    "start": "3059960",
    "end": "3065319"
  },
  {
    "text": "have at these upcoming conferences and the conferences that have happened is a place where you can look for uh research",
    "start": "3065319",
    "end": "3072720"
  },
  {
    "text": "that does directly aim to improve efficiency metrics so as Roy mentioned earlier distillation is one approach",
    "start": "3072720",
    "end": "3079960"
  },
  {
    "text": "that's pretty popular about taking a large model and making it uh smaller and",
    "start": "3079960",
    "end": "3085200"
  },
  {
    "text": "more efficient there are a ton of ways to do this so um model compression using",
    "start": "3085200",
    "end": "3090599"
  },
  {
    "text": "the lottery ticket hypothesis or like Roy and I had a a model compression paper there's a lot of ways that people",
    "start": "3090599",
    "end": "3097799"
  },
  {
    "text": "are taking existing work and making it more efficient and with this track at",
    "start": "3097799",
    "end": "3102839"
  },
  {
    "text": "these conferences or just in general you know promoting these ideas hopefully one thing that you can take away from this",
    "start": "3102839",
    "end": "3108480"
  },
  {
    "text": "is a snapshot of ways that you can improve efficiency that have a good",
    "start": "3108480",
    "end": "3115319"
  },
  {
    "text": "track record in the research Community awesome as we kind of close out here I'm",
    "start": "3115319",
    "end": "3120799"
  },
  {
    "text": "curious since you both have like a very close pulse on the research community in",
    "start": "3120799",
    "end": "3126640"
  },
  {
    "text": "particularly your your own areas of research but also sort of more generally I'm curious if we were to imagine in the",
    "start": "3126640",
    "end": "3133079"
  },
  {
    "text": "future and there's a world where like green AI is the thing that that",
    "start": "3133079",
    "end": "3138359"
  },
  {
    "text": "everyone's doing so some of we've reached some of those goals what else in",
    "start": "3138359",
    "end": "3143640"
  },
  {
    "text": "the uh AI research world world or maybe like things ways in which people are",
    "start": "3143640",
    "end": "3150240"
  },
  {
    "text": "applying AI um what gets you excited uh as as you look to the future of of the",
    "start": "3150240",
    "end": "3156760"
  },
  {
    "text": "industry that's a great question you know I something that uh keeps me busy",
    "start": "3156760",
    "end": "3162880"
  },
  {
    "text": "thinking about I mean you know thinking about the Horizon of where where I want to take my work and where would I like",
    "start": "3162880",
    "end": "3168920"
  },
  {
    "text": "to be in 10 20 30 years so I'm excited about a few things one I think I started",
    "start": "3168920",
    "end": "3175119"
  },
  {
    "text": "with and to you know taking this this amazing technology that does things that are far beyond our reach and and and we",
    "start": "3175119",
    "end": "3183119"
  },
  {
    "text": "we seriously I mean someone who's been around you know not not a a ton of time but I mean even five seven years back",
    "start": "3183119",
    "end": "3189680"
  },
  {
    "text": "nobody would even imagine it we be anywhere close to solving the task that we're currently solving very",
    "start": "3189680",
    "end": "3196040"
  },
  {
    "text": "successfully uh and the questions that remain open are how are we doing this I mean are we doing this because the",
    "start": "3196040",
    "end": "3202319"
  },
  {
    "text": "models are very good at memorizing and they're just learning everything and kind of are very good at retrieving the",
    "start": "3202319",
    "end": "3207520"
  },
  {
    "text": "information that they've learned are they really doing uh some sort of uh inference that requires some logic or",
    "start": "3207520",
    "end": "3214400"
  },
  {
    "text": "some uh you know I don't want to use the word thinking but you know something that requires some processing that",
    "start": "3214400",
    "end": "3220119"
  },
  {
    "text": "requires things that we as humans do and uh could we generate models that explain",
    "start": "3220119",
    "end": "3226680"
  },
  {
    "text": "why they reach a certain conclusion rather than others and could we trust I mean we obviously can do whatever we can",
    "start": "3226680",
    "end": "3232760"
  },
  {
    "text": "generate an explanation but is this explanation faithful and another thing that you know gets me excited is to use",
    "start": "3232760",
    "end": "3239400"
  },
  {
    "text": "this technology for all the good things that it can do and in particularly thinking about uh doctors now nowadays",
    "start": "3239400",
    "end": "3246920"
  },
  {
    "text": "that you know how can we take things off their plate allow them to do more of uh",
    "start": "3246920",
    "end": "3253240"
  },
  {
    "text": "what they're you know there's tons of applications of you know starting from",
    "start": "3253240",
    "end": "3258599"
  },
  {
    "text": "doing better analysis of uh x-rays for radiologist and to you know to",
    "start": "3258599",
    "end": "3264920"
  },
  {
    "text": "transcribe their uh patient summaries in a more efficient ways and to be able to extract",
    "start": "3264920",
    "end": "3270440"
  },
  {
    "text": "information from that there are tons of applications here that this technology can be used to make things better for uh",
    "start": "3270440",
    "end": "3277040"
  },
  {
    "text": "lots of people so that's uh things that I'm excited about awesome yeah us too I",
    "start": "3277040",
    "end": "3283079"
  },
  {
    "text": "know Chris and I both resonate with those points so what about yourself Jesse there's a lot of things I'm",
    "start": "3283079",
    "end": "3289319"
  },
  {
    "text": "excited about I think Roy I mean things Roy brought up I even just now I'm like those are all really cool I want to work",
    "start": "3289319",
    "end": "3294720"
  },
  {
    "text": "on that stuff too um I think for me you know continuing to work in these sort of two pillars of of uh my research so far",
    "start": "3294720",
    "end": "3301359"
  },
  {
    "text": "which has been reproducibility and efficiency these are pretty broad um categories so along the efficiency line",
    "start": "3301359",
    "end": "3309440"
  },
  {
    "text": "one thing that I have been continuing to think about is at least in NLP what we've seen is like larger and larger",
    "start": "3309440",
    "end": "3316240"
  },
  {
    "text": "language models which are pre-trained on tremendous amounts of data and then right now what we've been doing is",
    "start": "3316240",
    "end": "3322720"
  },
  {
    "text": "fine-tuning these models so updating all of the weights in the model so so that we can perform well on some Downstream",
    "start": "3322720",
    "end": "3329240"
  },
  {
    "text": "task um that could be you know sentiment analysis or some kind of other types of text classification or whatever my guess",
    "start": "3329240",
    "end": "3336799"
  },
  {
    "text": "is as these models become larger and larger there's probably going to be some other way that we can apply them to",
    "start": "3336799",
    "end": "3343960"
  },
  {
    "text": "problems that we're interested in an example of this that has recently been popular is adapters so that's like",
    "start": "3343960",
    "end": "3350319"
  },
  {
    "text": "adding a small number of parameters to one of these large pre-trained models and then only updating that small action",
    "start": "3350319",
    "end": "3356760"
  },
  {
    "text": "of the total number of parameters I think the high Lev motivation",
    "start": "3356760",
    "end": "3361920"
  },
  {
    "text": "here is that if these models are huge and we want to take a you know one",
    "start": "3361920",
    "end": "3368200"
  },
  {
    "text": "massive pre-trained model and adapt it to a 100 different tasks we don't want to have to have a hundred different",
    "start": "3368200",
    "end": "3373559"
  },
  {
    "text": "copies of this model we want to have some smaller fraction so I think that that is a a pretty motivational idea",
    "start": "3373559",
    "end": "3380520"
  },
  {
    "text": "exactly what the next big thing in NLP is going to be the next you know big",
    "start": "3380520",
    "end": "3386599"
  },
  {
    "text": "idea about how we take our pre-train models and apply them to many different tasks in a relatively efficient way um",
    "start": "3386599",
    "end": "3393920"
  },
  {
    "text": "I'm excited to see what that is I think one similar idea one one way that we",
    "start": "3393920",
    "end": "3399599"
  },
  {
    "text": "might do that is through um probing tasks so being able to probe our models without updating the weights in them to",
    "start": "3399599",
    "end": "3407520"
  },
  {
    "text": "understand the kinds of inferences that they can make I think that's a a particularly interesting topic that's",
    "start": "3407520",
    "end": "3414000"
  },
  {
    "text": "very active right now I've seen you know too many papers to read just in the last month and a half on um trying to probe",
    "start": "3414000",
    "end": "3420119"
  },
  {
    "text": "existing models and then on the reproducibility side you know we've had the reproducibility checklist now used",
    "start": "3420119",
    "end": "3427480"
  },
  {
    "text": "um for every submission at I think four conferences that's a huge success I'm",
    "start": "3427480",
    "end": "3433119"
  },
  {
    "text": "pretty happy with um the way that's worked out the reproducibility checklist I guess to give a little more information on that is a checklist",
    "start": "3433119",
    "end": "3440000"
  },
  {
    "text": "that's designed to remind authors of the kinds of information they should include to make their work reproducible so has",
    "start": "3440000",
    "end": "3446480"
  },
  {
    "text": "like did you include the number of parameters in your model and did you include the you know what the size of",
    "start": "3446480",
    "end": "3452920"
  },
  {
    "text": "your data sets for example I'm excited and thinking about what we can do next",
    "start": "3452920",
    "end": "3458480"
  },
  {
    "text": "with that information and also with the checklist so now conferences are adopting it on their own I've had to",
    "start": "3458480",
    "end": "3464880"
  },
  {
    "text": "advocate in the past you know reaching out to the conference chairs and saying hey I think we should do this now",
    "start": "3464880",
    "end": "3471520"
  },
  {
    "text": "conferences have picked it up on their own which is pretty exciting so you know I'm thinking a lot about",
    "start": "3471520",
    "end": "3477319"
  },
  {
    "text": "how we can continue to measure the sort of quality of the research that the",
    "start": "3477319",
    "end": "3482760"
  },
  {
    "text": "community produces at that CommunityWide level um and what we can do going",
    "start": "3482760",
    "end": "3488559"
  },
  {
    "text": "forward what's the next iteration of the checklist going to be for example so that's what I'm thinking about that's",
    "start": "3488559",
    "end": "3494520"
  },
  {
    "text": "awesome yeah and congrats on the uh the success with that and getting that out there and sort of self-propagating at",
    "start": "3494520",
    "end": "3501440"
  },
  {
    "text": "this point I also agree with you there's a lot of papers even you've mentioned in this conversation too many papers for",
    "start": "3501440",
    "end": "3507720"
  },
  {
    "text": "for me to read in a in a lifetime uh there there's so much exciting stuff going on but really appreciate both of",
    "start": "3507720",
    "end": "3514720"
  },
  {
    "text": "you taking time to join us and discuss this really important topic I hope um that people check out your your paper",
    "start": "3514720",
    "end": "3522119"
  },
  {
    "text": "which we'll uh Link in our show notes and um we'll link a bunch of the other things that Roy and Jesse uh talked",
    "start": "3522119",
    "end": "3528559"
  },
  {
    "text": "about so be sure to check those things out and um definitely uh spend some time",
    "start": "3528559",
    "end": "3533720"
  },
  {
    "text": "uh hope our listeners spend some time thinking about this topic and how it influences their workflow and and other",
    "start": "3533720",
    "end": "3540359"
  },
  {
    "text": "things so thank you both and um hope to uh talk to you again soon thank you so much it was so much fun thanks for",
    "start": "3540359",
    "end": "3546640"
  },
  {
    "text": "having us thanks for coming on the [Music] show thank you for listening to",
    "start": "3546640",
    "end": "3553440"
  },
  {
    "text": "practical AI if this is your first time make sure you subscribe so you don't miss a thing head to practical AI FM to",
    "start": "3553440",
    "end": "3561359"
  },
  {
    "text": "subscribe or find us in apple podcast Spotify or wherever you listen to",
    "start": "3561359",
    "end": "3566680"
  },
  {
    "text": "podcasts and if you get value from the show please do share it with a friend or a colleague we appreciate you spreading",
    "start": "3566680",
    "end": "3572799"
  },
  {
    "text": "the word practical AI is hosted by Daniel wh neck and Chris Benson it's produced by Jared Santo and our music is",
    "start": "3572799",
    "end": "3579559"
  },
  {
    "text": "provided by breakmaster cylinder we are brought to you by some awesome sponsors shout out to fley linode and laun",
    "start": "3579559",
    "end": "3586680"
  },
  {
    "text": "darkley that is our show we hope you enjoyed it and we'll talk to you again next",
    "start": "3586680",
    "end": "3593160"
  },
  {
    "text": "week [Music]",
    "start": "3595039",
    "end": "3609449"
  },
  {
    "text": "k",
    "start": "3611039",
    "end": "3614039"
  }
]
[
  {
    "text": "so now we have this new Nvidia dgx a100 maybe you'll get one I don't know if I'm",
    "start": "120",
    "end": "5960"
  },
  {
    "text": "GNA get one but we we'll see we'll see yeah yeah sadly I'm not in charge of of",
    "start": "5960",
    "end": "11960"
  },
  {
    "text": "procurement and I am certainly not in charge of procuring one for my own personal use that we'll see I'm guessing",
    "start": "11960",
    "end": "17720"
  },
  {
    "text": "that my nonprofit's not going to get one but if you happen to be getting your dgx a100 and you'd like me to run my",
    "start": "17720",
    "end": "24920"
  },
  {
    "text": "training on it I would be more than happy to do some benchmarking for you",
    "start": "24920",
    "end": "31679"
  },
  {
    "text": "bandwidth for change log is provided by fastly learn more at fastly.com we move",
    "start": "31679",
    "end": "37239"
  },
  {
    "text": "fast and fix things here at change law because of rbar check them out at rar.com and we're hosted on linode cloud",
    "start": "37239",
    "end": "43559"
  },
  {
    "text": "servers head the lin.com change log Leno makes cloud computing simple",
    "start": "43559",
    "end": "51039"
  },
  {
    "text": "affordable and accessible whether you're working on a personal project or managing your Enterprises infrastructure",
    "start": "51039",
    "end": "56520"
  },
  {
    "text": "lenoe has the pricing support and skill you need to take your ideas to the next level We Trust Leno because they keep it",
    "start": "56520",
    "end": "62399"
  },
  {
    "text": "fast and they keep it simple check them out at lin.com",
    "start": "62399",
    "end": "67519"
  },
  {
    "text": "[Music]",
    "start": "68410",
    "end": "73880"
  },
  {
    "text": "changelog welcome to practical AI a weekly podcast that makes artificial intelligence practical productive and",
    "start": "73880",
    "end": "80840"
  },
  {
    "text": "accessible to everyone this is where conversations around AI machine learning and data science happen join the",
    "start": "80840",
    "end": "86840"
  },
  {
    "text": "community and slack with us around various topics of the show at j.com community and follow us on Twitter we at",
    "start": "86840",
    "end": "93079"
  },
  {
    "text": "practical aifm okay take it away [Music]",
    "start": "93079",
    "end": "99159"
  },
  {
    "text": "guys welcome to another fully connected episode where Daniel and I keep you fully connected with everything that's",
    "start": "99159",
    "end": "105759"
  },
  {
    "text": "happening in the AI Community we'll take some time to discuss the latest AI news and we'll dig into learning resources to",
    "start": "105759",
    "end": "111840"
  },
  {
    "text": "help you level up your machine learning game so welcome to the Practical AI podcast my name is Chris Benson I'm",
    "start": "111840",
    "end": "118200"
  },
  {
    "text": "principal AI strategist at locky Martin and with me as always is Daniel whack data scientist at s International how's",
    "start": "118200",
    "end": "125119"
  },
  {
    "text": "it going Daniel it's going great it's a beautiful day outside hopefully I can take a walk after this and uh I've been",
    "start": "125119",
    "end": "133319"
  },
  {
    "text": "staring at my screen most of the day since like 700 a.m. so I'm I'm ready for a walk around the block or something",
    "start": "133319",
    "end": "140120"
  },
  {
    "text": "that sounds like a good idea I I am blury eyed from screen time as well so get outside and enjoy it especially now",
    "start": "140120",
    "end": "147080"
  },
  {
    "text": "that uh the at least where I'm at in Atlanta the worst of the pollen seems to be passed so that's good no more yellow",
    "start": "147080",
    "end": "154120"
  },
  {
    "text": "cars from pine pollen everywhere yeah that's rough we need like an AI model",
    "start": "154120",
    "end": "160159"
  },
  {
    "text": "that like takes in pictures of cars and people's driveways and like tells you whether it's safe to go outside yet",
    "start": "160159",
    "end": "166200"
  },
  {
    "text": "because of the the pollen levels or there you go I'm sure there's easier ways to do that but um that's right so",
    "start": "166200",
    "end": "172680"
  },
  {
    "text": "we'll have to prep people next year so we'll just ask everybody in the audience next year to uh to send us your images",
    "start": "172680",
    "end": "178840"
  },
  {
    "text": "of your cars covered and pine paen with a date a date time attached to it and we will have a great project to go on this",
    "start": "178840",
    "end": "185560"
  },
  {
    "text": "yeah exactly um so and and before we get going I know that you've been doing some training classes how have those been",
    "start": "185560",
    "end": "191120"
  },
  {
    "text": "going uh they went they went really good it was interesting CU nor teach by the way not not taking yeah so normally when",
    "start": "191120",
    "end": "199239"
  },
  {
    "text": "I do like AI trainings in industry or like at conferences or something obviously there's um you know normally",
    "start": "199239",
    "end": "205519"
  },
  {
    "text": "like a whiteboard there there's a lot of kind of uh changes as the class goes on",
    "start": "205519",
    "end": "211239"
  },
  {
    "text": "because there's a lot of easy kind of back and forth so it was interesting to figure out the virtual Dynamic with",
    "start": "211239",
    "end": "217840"
  },
  {
    "text": "everybody being at home I think actually it ended up having some benefits because",
    "start": "217840",
    "end": "224360"
  },
  {
    "text": "it sort of forced me like normally I kind of write things at the Whiteboard I'm able to like make changes as I go",
    "start": "224360",
    "end": "230560"
  },
  {
    "text": "but to be able to you or or to have to sit down and work things out in a strict",
    "start": "230560",
    "end": "237560"
  },
  {
    "text": "set of slides that I'm showing made me really think about like what is the",
    "start": "237560",
    "end": "242879"
  },
  {
    "text": "proper flow to explain this idea and like show certain things so in that",
    "start": "242879",
    "end": "248120"
  },
  {
    "text": "respect actually it was it was a learning experience for me a bit because it it helped clarify some of that logic",
    "start": "248120",
    "end": "255360"
  },
  {
    "text": "and even in my own mind so but it it went really well and the students um uh had some great questions and went you",
    "start": "255360",
    "end": "262360"
  },
  {
    "text": "know all the way from what is AI to convolutional layers and recurrent",
    "start": "262360",
    "end": "267600"
  },
  {
    "text": "layers and training cool things and so yeah it was a good time you know I've always found that no matter what the",
    "start": "267600",
    "end": "273479"
  },
  {
    "text": "topic you teach it forces you to assess everything that you think about because you got to explain it to other people",
    "start": "273479",
    "end": "278840"
  },
  {
    "text": "and answer all that and you always every time I've done that I've learned so much more about whatever it was I was going",
    "start": "278840",
    "end": "284240"
  },
  {
    "text": "to teach so for sure yeah and people ask questions that just never have come into",
    "start": "284240",
    "end": "290320"
  },
  {
    "text": "your mind not because they're bad questions it's just a different point of view so it forces you to like backtrack",
    "start": "290320",
    "end": "296280"
  },
  {
    "text": "yourself and kind of look at things from different directions yeah well that sounds interesting I guess uh you",
    "start": "296280",
    "end": "302960"
  },
  {
    "text": "probably looked out you got through your training classes right before Nvidia uh this year at their GPU technology",
    "start": "302960",
    "end": "310720"
  },
  {
    "text": "conference GTC made all their new hardware announcements uh and the things that go with that so and you know it's",
    "start": "310720",
    "end": "317440"
  },
  {
    "text": "interesting um I actually was spending the evening yesterday with my brother-in-laws who are living with us",
    "start": "317440",
    "end": "323520"
  },
  {
    "text": "so we aren't like social Gathering yet but but my brother-in-laws are living with us right now while they're back",
    "start": "323520",
    "end": "329360"
  },
  {
    "text": "from college and so they don't work in they're not like in computer science or or anything like that but they are",
    "start": "329360",
    "end": "335680"
  },
  {
    "text": "pretty heavy Gamers and uh they were both like we started talking about some",
    "start": "335680",
    "end": "340840"
  },
  {
    "text": "of this stuff and they had even seen the keynote from the Nvidia conference even",
    "start": "340840",
    "end": "345919"
  },
  {
    "text": "before I started talking about even though it was mostly AI related it it was like a you know already a sort of",
    "start": "345919",
    "end": "352680"
  },
  {
    "text": "General meme that like the Nvidia CEO was like presenting all of this cool GPU",
    "start": "352680",
    "end": "359240"
  },
  {
    "text": "stuff from his kitchen which was like you know you could see the spatulas in the background and some very interesting",
    "start": "359240",
    "end": "365600"
  },
  {
    "text": "like Fresco above his uh oven and and such so it was really interesting in",
    "start": "365600",
    "end": "371560"
  },
  {
    "text": "that sense that there was like a like people even people that aren't in the space like it made some impact on their",
    "start": "371560",
    "end": "379880"
  },
  {
    "text": "life which was really interesting well you know that's a great point it's worth talking about I mean",
    "start": "379880",
    "end": "385800"
  },
  {
    "text": "you know we talk about Nvidia and Google and other major players in this space",
    "start": "385800",
    "end": "391639"
  },
  {
    "text": "often uh because you can't really talk about AI in a lot of cases without talking about the biggest influencers",
    "start": "391639",
    "end": "398520"
  },
  {
    "text": "and and in nvidia's case they were this gaming company and gpus were originally",
    "start": "398520",
    "end": "404280"
  },
  {
    "text": "to promote graphics and you know computer Gamers you know were were constantly using it and now we're doing",
    "start": "404280",
    "end": "409840"
  },
  {
    "text": "this in the AI space you know so any thoughts on on how or insight into how that Evolution came about why we're",
    "start": "409840",
    "end": "416000"
  },
  {
    "text": "using gpus for all this stuff yeah and actually also demand from the the",
    "start": "416000",
    "end": "421280"
  },
  {
    "text": "Bitcoin mining that's true space as well so it's very interesting that like if",
    "start": "421280",
    "end": "426319"
  },
  {
    "text": "you look at nvidia's rise over time of course they existed for quite some time but it's",
    "start": "426319",
    "end": "432840"
  },
  {
    "text": "almost like so they existed for a reason and they were really good at this reason and then all of the sudden like the",
    "start": "432840",
    "end": "438919"
  },
  {
    "text": "things that they were good at became like the most important things in the world that's how kind of how it seems",
    "start": "438919",
    "end": "444720"
  },
  {
    "text": "and then they just like they were already there so it's like they just exploded so yeah you're you're right so",
    "start": "444720",
    "end": "451400"
  },
  {
    "text": "if you think about like video gaming and that sort of thing or like things you would want to do in video processing or",
    "start": "451400",
    "end": "457759"
  },
  {
    "text": "graphics for example like you might want to apply a filter to some image or frame",
    "start": "457759",
    "end": "464360"
  },
  {
    "text": "of a video right like to darken it or to apply a gradient of color or you know",
    "start": "464360",
    "end": "471440"
  },
  {
    "text": "something like this and so you're essentially applying some operation to the pixels of an image which are set up",
    "start": "471440",
    "end": "477560"
  },
  {
    "text": "in a matrix and have like even some depth because there's a color Dimension",
    "start": "477560",
    "end": "483400"
  },
  {
    "text": "right so you have like this Matrix of numbers and then you apply some operation on the elements of this Matrix",
    "start": "483400",
    "end": "491919"
  },
  {
    "text": "or really this volume this input volume in AI of course with convolutional layers like you are doing almost that",
    "start": "491919",
    "end": "499319"
  },
  {
    "text": "exact same thing because you're applying like a series of weights and and bias",
    "start": "499319",
    "end": "505319"
  },
  {
    "text": "and you know functions like activation functions to individual elements of a",
    "start": "505319",
    "end": "510599"
  },
  {
    "text": "matrix or an input volume but even in like recurrent layers or like fully connected neural networks and that sort",
    "start": "510599",
    "end": "517000"
  },
  {
    "text": "of thing the types of networks that might be relevant to other things like text or just like General classification",
    "start": "517000",
    "end": "524640"
  },
  {
    "text": "problem even those take some input vector or Matrix and just apply a series",
    "start": "524640",
    "end": "530680"
  },
  {
    "text": "of weights to those apply functions like activation functions like tangent and sigmoid and all of these in an element",
    "start": "530680",
    "end": "539040"
  },
  {
    "text": "yse way and so you're really doing the sort of Matrix operations that graphics",
    "start": "539040",
    "end": "546000"
  },
  {
    "text": "cards were always good at and so it turns out that it's really good to use",
    "start": "546000",
    "end": "551720"
  },
  {
    "text": "those sorts of graphics cards for those sorts of operations which are done in",
    "start": "551720",
    "end": "557000"
  },
  {
    "text": "specifically in AI training of course we're going to talk maybe about inference today too but I think it came",
    "start": "557000",
    "end": "562200"
  },
  {
    "text": "about because these are the sorts of things that happen iteratively thousands and thousands and millions of times when",
    "start": "562200",
    "end": "568600"
  },
  {
    "text": "you do training for an AI model you know that has to be the most accessible",
    "start": "568600",
    "end": "574720"
  },
  {
    "text": "explanation to that Evolution that I think I've heard anyone say I think I think you did it better than Nvidia",
    "start": "574720",
    "end": "581200"
  },
  {
    "text": "actually says it so that was well done well they can pay me if they like I mean or they could send me a graphics card if",
    "start": "581200",
    "end": "588399"
  },
  {
    "text": "that that would probably actually be better I would I Nvidia if you're listening hint hent um you know Titan",
    "start": "588399",
    "end": "595959"
  },
  {
    "text": "RTX I I won't even take the newest one no even give me like a a100 give them",
    "start": "595959",
    "end": "601279"
  },
  {
    "text": "the newest one I I don't just small potatoes yeah the that $55,000 or what I don't even",
    "start": "601279",
    "end": "608440"
  },
  {
    "text": "know how much it is uh Titan RTX well now that we have been pleading for free",
    "start": "608440",
    "end": "613720"
  },
  {
    "text": "stuff uh let's move on to some of the things that they announced which many",
    "start": "613720",
    "end": "619720"
  },
  {
    "text": "organizations uh around the world are going to be trying to evaluate and figure out how they're going to",
    "start": "619720",
    "end": "625920"
  },
  {
    "text": "incorporate buy into and basically utilize this new hardware and and the supporting software capabilities that go",
    "start": "625920",
    "end": "632360"
  },
  {
    "text": "with it yeah definitely so you know I guess one of the things to uh to talk",
    "start": "632360",
    "end": "637880"
  },
  {
    "text": "about here is uh even before we get to announcements are uh the types of gpus",
    "start": "637880",
    "end": "643240"
  },
  {
    "text": "that are currently available and what forums you know what kind of offbrand gpus are out there because Nvidia isn't",
    "start": "643240",
    "end": "648519"
  },
  {
    "text": "the only player in the space any insight into that yeah I mean it's probably",
    "start": "648519",
    "end": "654079"
  },
  {
    "text": "worth distinguishing a few things here I guess first is like accelerators that are out there and types of gpus that are",
    "start": "654079",
    "end": "660920"
  },
  {
    "text": "out there and also like access patterns to those whether that be like locally or",
    "start": "660920",
    "end": "666800"
  },
  {
    "text": "in the cloud or or whatever at least from my perspective and I'm I'm by no means an expert on this on the like",
    "start": "666800",
    "end": "674320"
  },
  {
    "text": "graphics card Front actually probably my my brother-in-laws could do a better job but um there has been a progression and",
    "start": "674320",
    "end": "681160"
  },
  {
    "text": "most of the time you'll see like graphics cards referred to by some series of numbers and acronyms so like",
    "start": "681160",
    "end": "688320"
  },
  {
    "text": "recent ones have been like something like 1080 RTX or Titan RTX or something so those are the",
    "start": "688320",
    "end": "695959"
  },
  {
    "text": "graphics processing unit that you would like buy and then you have to plug it",
    "start": "695959",
    "end": "702200"
  },
  {
    "text": "into like some computer right so PE some people say like okay I'm going to I'm",
    "start": "702200",
    "end": "708200"
  },
  {
    "text": "going to develop AI models and so I'm going to buy a like a computer like a",
    "start": "708200",
    "end": "713519"
  },
  {
    "text": "tower a desktop computer and then I'm going to buy a graphics uh GPU like a",
    "start": "713519",
    "end": "720040"
  },
  {
    "text": "one of these RTX gpus or something and I'm going to put it in like my PCI slot and my motherboard and then when I do AI",
    "start": "720040",
    "end": "727920"
  },
  {
    "text": "training then I'm going to like offload the training some of those training operations to the graphics card or GPU",
    "start": "727920",
    "end": "736000"
  },
  {
    "text": "that's input to my computer so that's sort of a one of the first ways you",
    "start": "736000",
    "end": "742399"
  },
  {
    "text": "might think about doing this is like I'm going to do AI development so I can buy a computer and then I'm going to buy a",
    "start": "742399",
    "end": "747760"
  },
  {
    "text": "graphics card and just put in there and a lot of those of course come from Nvidia they make a lot of those cards",
    "start": "747760",
    "end": "754480"
  },
  {
    "text": "but there's offbrand ones that kind of are similar to the",
    "start": "754480",
    "end": "761199"
  },
  {
    "text": "models that Nvidia has and then there's also like other brands that have their",
    "start": "761199",
    "end": "766920"
  },
  {
    "text": "own style of graphics card and that sort of thing have you ever built or thought about building this sort of like",
    "start": "766920",
    "end": "773320"
  },
  {
    "text": "workstation for your home to like sit by your desk or something I I think I'm way",
    "start": "773320",
    "end": "778680"
  },
  {
    "text": "too lazy to do that at this point I'd much rather go to to a cloud provider if I'm at home and uh and use what they've",
    "start": "778680",
    "end": "785680"
  },
  {
    "text": "built I've noticed that most of the people that had workstations specifically for their AI workflows seem",
    "start": "785680",
    "end": "791839"
  },
  {
    "text": "to have moved off those in recent years either in the cloud or if they're big enough into more of a a data center or",
    "start": "791839",
    "end": "797639"
  },
  {
    "text": "at least a you know like a workstation level you know B where they're buying a workstation versus buying individual",
    "start": "797639",
    "end": "803160"
  },
  {
    "text": "gpus it was one one of the things I was thinking as you were just talking about that was we had an one of our early",
    "start": "803160",
    "end": "809440"
  },
  {
    "text": "episodes which was episode 15 called artificial intelligence at Nvidia we had",
    "start": "809440",
    "end": "814639"
  },
  {
    "text": "nvidia's Chief scientist bill D on the show and he absolutely schooled us yeah",
    "start": "814639",
    "end": "820600"
  },
  {
    "text": "definitely in the hardware AR do you remember that he really schooled Us in the hardware much deeper than we'll go",
    "start": "820600",
    "end": "826320"
  },
  {
    "text": "on this episode so definitely take a look at that yeah yes if you're wning and we asked him to against other",
    "start": "826320",
    "end": "832920"
  },
  {
    "text": "architectures you know and he went there uh and described it so if if that aspect",
    "start": "832920",
    "end": "838240"
  },
  {
    "text": "of it not just the VI architectures but how they compare to other things uh I would encourage listeners to listen to",
    "start": "838240",
    "end": "843920"
  },
  {
    "text": "that episode and he will absolutely School you in in the fundamentals there yeah for sure cuz there's not only so",
    "start": "843920",
    "end": "850040"
  },
  {
    "text": "like I describe like the graphics card or GPU which is what a lot of times what people think of when they think of GPU",
    "start": "850040",
    "end": "857680"
  },
  {
    "text": "or or accelerator in the AI World they think of one of these gpus or a series",
    "start": "857680",
    "end": "863560"
  },
  {
    "text": "of them but there's other options too so there's like the TPU or tensor processing unit from is it tensor",
    "start": "863560",
    "end": "870480"
  },
  {
    "text": "Processing Unit or tensor flow process I don't know if they put the brand in there I think it's tensor Processing Unit I believe it is the TPU from uh",
    "start": "870480",
    "end": "878639"
  },
  {
    "text": "that that Google developed which um is another type of accelerator but there's even other architectures out there other",
    "start": "878639",
    "end": "885120"
  },
  {
    "text": "than CPU GPU TPU there's fpga and other things and yeah there's a lot of uh",
    "start": "885120",
    "end": "891959"
  },
  {
    "text": "options out there and like you said there's options also so I kind of describe like okay if you're developing",
    "start": "891959",
    "end": "898040"
  },
  {
    "text": "AI you could just like create just buy one of these computers to have at your desk but there's also just like how",
    "start": "898040",
    "end": "905480"
  },
  {
    "text": "other forms of compute have been commoditized via the cloud there's easy",
    "start": "905480",
    "end": "910639"
  },
  {
    "text": "access to Cloud resources for gpus too and in all the clouds and in even",
    "start": "910639",
    "end": "916759"
  },
  {
    "text": "special built GPU like cloud services like paper space",
    "start": "916759",
    "end": "922399"
  },
  {
    "text": "and others I I know when I was looking around a while back for a project I",
    "start": "922399",
    "end": "927440"
  },
  {
    "text": "don't know if it's still the case but I was trying to find like what is the cheapest way to use a GPU in the cloud",
    "start": "927440",
    "end": "933680"
  },
  {
    "text": "and uh I ended up going with paper space I don't know if it's the cheapest anymore I do use like Google collab as",
    "start": "933680",
    "end": "940199"
  },
  {
    "text": "I've mentioned a lot of times on the on the podcast and of course you can have access to a free GPU there there's",
    "start": "940199",
    "end": "945680"
  },
  {
    "text": "trade-offs because it's in a notebook and that sort of thing but anyway there's a lot of ways to access them",
    "start": "945680",
    "end": "950720"
  },
  {
    "text": "which aren't buying a computer and setting it on your desk that's true",
    "start": "950720",
    "end": "955920"
  },
  {
    "text": "that's definitely nice so why don't we dive into to uh some of the announcements that Nvidia made at GTC as",
    "start": "955920",
    "end": "963360"
  },
  {
    "text": "we're recording this I think it was about roughly a week ago that they made the announcement and uh it'll be another",
    "start": "963360",
    "end": "969199"
  },
  {
    "text": "week as it rolls out but uh uh I'll start us off with they started in I'm",
    "start": "969199",
    "end": "975279"
  },
  {
    "text": "I'm going to probably butcher the pronunciation the Nvidia emper architecture did they did I get that",
    "start": "975279",
    "end": "980839"
  },
  {
    "text": "right I've read it but I haven't watched the video to see there you go how he's pronouncing it so I think in reference",
    "start": "980839",
    "end": "986480"
  },
  {
    "text": "to like amp in electronics I think there you go I didn't get the connection there okay yeah so I don't know at least",
    "start": "986480",
    "end": "993680"
  },
  {
    "text": "that's how I was saying it so yeah I I know that that essentially this is what",
    "start": "993680",
    "end": "998759"
  },
  {
    "text": "they've used to replace um kind of the existing architecture and expand it they're really focusing on I think a",
    "start": "998759",
    "end": "1006120"
  },
  {
    "text": "more realistic in the sense of of kind of I say cloud but when I say cloud I don't necessarily strictly mean Cloud",
    "start": "1006120",
    "end": "1012519"
  },
  {
    "text": "providers I mean if you were putting together a data center with a whole bunch of gpus or GPU servers in it you",
    "start": "1012519",
    "end": "1019079"
  },
  {
    "text": "know they they're really focusing on not only the performance sides but the usability uh as I was reading through it",
    "start": "1019079",
    "end": "1024839"
  },
  {
    "text": "yeah and I think that what I was gathering also in talking with some other people about this is so the",
    "start": "1024839",
    "end": "1030959"
  },
  {
    "text": "generation before this latest one was focused more on the ray tracing Elements",
    "start": "1030959",
    "end": "1037120"
  },
  {
    "text": "which is the RTX in a lot of these cards which uh to be honest I'm I'm not a big expert on Ray tracing nor am I that has",
    "start": "1037120",
    "end": "1045079"
  },
  {
    "text": "um implications of course in graphics and that sort of thing but it wasn't like a huge advance in terms of like the",
    "start": "1045079",
    "end": "1051760"
  },
  {
    "text": "size and capabilities of the graphics processing unit itself it was more of this kind of generation of additional",
    "start": "1051760",
    "end": "1058080"
  },
  {
    "text": "rate tracing capabilities whereas this next architecture which they're releasing which they're calling the a100",
    "start": "1058080",
    "end": "1065400"
  },
  {
    "text": "or the Amper architecture which includes this a100 card uh or GPU that this this is a",
    "start": "1065400",
    "end": "1073679"
  },
  {
    "text": "fairly significant jump in the like size and capabilities of the graphics",
    "start": "1073679",
    "end": "1079000"
  },
  {
    "text": "processing unit itself I think part of that has to do with I guess the way that they've laid out the transistors and all",
    "start": "1079000",
    "end": "1086919"
  },
  {
    "text": "of that on the substrate that it's much more dense in my understanding yeah am I",
    "start": "1086919",
    "end": "1092720"
  },
  {
    "text": "recalling it was something like 20 times performance improvement over the V100",
    "start": "1092720",
    "end": "1098159"
  },
  {
    "text": "well yeah so it's 20 times greater flops which is like a measure of U actually",
    "start": "1098159",
    "end": "1104840"
  },
  {
    "text": "you you probably are better versed in the acronyms but um this is like a",
    "start": "1104840",
    "end": "1110000"
  },
  {
    "text": "common way to like measure the performance of like computers like supercomputers and that sort of thing so",
    "start": "1110000",
    "end": "1116280"
  },
  {
    "text": "20x greater flops for AI although they do give some benchmarks which is is",
    "start": "1116280",
    "end": "1123000"
  },
  {
    "text": "pretty nice um just for reference and what I was looking at they give some benchmarks for training Bert large scale",
    "start": "1123000",
    "end": "1130600"
  },
  {
    "text": "language models which we have an episode on Bert as well if you'd like to learn more about that yes we do we've",
    "start": "1130600",
    "end": "1137360"
  },
  {
    "text": "mentioned it in several actually yeah it's good that we ended up having that conversation but the um the Bert models",
    "start": "1137360",
    "end": "1144840"
  },
  {
    "text": "are these very large language uh related models NLP models that have just tons of",
    "start": "1144840",
    "end": "1152120"
  },
  {
    "text": "parameters um and actually these large language models have even billions of parameters now I forget how many Bert",
    "start": "1152120",
    "end": "1158240"
  },
  {
    "text": "has but they give some benchmarks both for the training and inference on speedups on training Bert mhm so on Bert",
    "start": "1158240",
    "end": "1168080"
  },
  {
    "text": "itself they're saying that above the V100 so the V100 if you go to like Google cloud",
    "start": "1168080",
    "end": "1175400"
  },
  {
    "text": "or if you go to paper space or one of these platforms at least right now I think the the best GPU that you can get",
    "start": "1175400",
    "end": "1182000"
  },
  {
    "text": "access to is is called a v00 which is a previous generation and it's it's pretty",
    "start": "1182000",
    "end": "1187200"
  },
  {
    "text": "wicked fast I mean I've I've used this in a in a couple of projects and um it's",
    "start": "1187200",
    "end": "1193440"
  },
  {
    "text": "quite astoundingly faster than the sort of entry level GPU yes",
    "start": "1193440",
    "end": "1199880"
  },
  {
    "text": "and it's the basis for the dgx line of Serv as well I think so or was prior to",
    "start": "1199880",
    "end": "1205320"
  },
  {
    "text": "this release prior to this yeah and um they're saying that there's a speed up",
    "start": "1205320",
    "end": "1210760"
  },
  {
    "text": "between three and six times in the training for the B large scale training",
    "start": "1210760",
    "end": "1217799"
  },
  {
    "text": "and the difference between the 3 to 6X has to do with the um Precision of the floating Point numbers that you're using",
    "start": "1217799",
    "end": "1224480"
  },
  {
    "text": "in the model so I'm stepping Way Beyond my bounds into like computer science land where I don't",
    "start": "1224480",
    "end": "1231720"
  },
  {
    "text": "deserve to step but but in the in the models obviously you have all these weights and",
    "start": "1231720",
    "end": "1238320"
  },
  {
    "text": "parameters and the matrices that you're transforming in these models and computers work with numbers and those",
    "start": "1238320",
    "end": "1244679"
  },
  {
    "text": "numbers have to be represented right in some form in some Precision you can't like if you have if you're representing",
    "start": "1244679",
    "end": "1251559"
  },
  {
    "text": "Pi you're not going to represent like all digits of pi in pi you're going to",
    "start": "1251559",
    "end": "1256840"
  },
  {
    "text": "have to cut it off somewhere right yeah this is having to do with that Precision of the numbers and you can actually if",
    "start": "1256840",
    "end": "1263600"
  },
  {
    "text": "you reduce the Precision of how you represent numbers you can sometimes",
    "start": "1263600",
    "end": "1268679"
  },
  {
    "text": "speed up your your performance and so that's what they're talking about there with that difference to 3 tox 3x to 3 to",
    "start": "1268679",
    "end": "1276200"
  },
  {
    "text": "6X yeah and I think uh I'm looking at their inference and I know they're they're saying it's a seven times speed",
    "start": "1276200",
    "end": "1282120"
  },
  {
    "text": "up on inference mhm so it's substantial in that case so they say like this card",
    "start": "1282120",
    "end": "1287919"
  },
  {
    "text": "this A1 100 accelerator they bring up this idea of what do they call it the I",
    "start": "1287919",
    "end": "1293520"
  },
  {
    "text": "don't know if they're if you say it Mig I'm thinking of like the fighter jet but the multi instance GPU which is a really",
    "start": "1293520",
    "end": "1301120"
  },
  {
    "text": "intriguing idea do do you work for us now in that way yeah they're saying it",
    "start": "1301120",
    "end": "1306520"
  },
  {
    "text": "it's multi-instance GPU which in my understand are they saying like you can basically treat the GPU as seven gpus is",
    "start": "1306520",
    "end": "1312960"
  },
  {
    "text": "that what they're saying so I was wondering that myself and so a big top",
    "start": "1312960",
    "end": "1318919"
  },
  {
    "text": "that I spend my time at work is is around multi-tenancy in your workflows",
    "start": "1318919",
    "end": "1325039"
  },
  {
    "text": "and you know the accessibility of compute in those and I was taking it in",
    "start": "1325039",
    "end": "1330080"
  },
  {
    "text": "that way but I'm not sure because they're a little bit ambiguous uh in the in the way they use some of the terms um",
    "start": "1330080",
    "end": "1337120"
  },
  {
    "text": "another one that I noticed is they they talked about the the need for no code changes I'm and I'm assuming that's Cuda",
    "start": "1337120",
    "end": "1343600"
  },
  {
    "text": "code changes uh in this case but they weren't always as specific as as they might have been in terms their",
    "start": "1343600",
    "end": "1348919"
  },
  {
    "text": "explanations here I was wondering about that as well of course there certainly are ways to make changes like this",
    "start": "1348919",
    "end": "1355360"
  },
  {
    "text": "transparent but there's a change somewhere right it's just maybe at the abstraction level you're working with in",
    "start": "1355360",
    "end": "1360440"
  },
  {
    "text": "tensor flow or something you don't have to make a change in tensor flow but in the underlying libraries it somewhere it",
    "start": "1360440",
    "end": "1366960"
  },
  {
    "text": "seems like there there's some type of change yeah it talks on the multi-instance GPU as I'm looking",
    "start": "1366960",
    "end": "1373240"
  },
  {
    "text": "through that it's talking about uh seven different isolated GPU instances running different applications",
    "start": "1373240",
    "end": "1378960"
  },
  {
    "text": "simultaneously yeah so it seems like when they say 7x speed up for ber large",
    "start": "1378960",
    "end": "1385799"
  },
  {
    "text": "inference and they have under their in parenthesis seven Mig or seven multi-",
    "start": "1385799",
    "end": "1392000"
  },
  {
    "text": "instant GPU they're using them all what I'm assuming that is meaning is they",
    "start": "1392000",
    "end": "1397039"
  },
  {
    "text": "basically are running seven inferences in parallel on the seven GPU which seems",
    "start": "1397039",
    "end": "1404840"
  },
  {
    "text": "to be the same performance that they're indicating for as the v00 so for",
    "start": "1404840",
    "end": "1411559"
  },
  {
    "text": "inference wise it seems like you know the change is that you're able to run",
    "start": "1411559",
    "end": "1419720"
  },
  {
    "text": "things in this parallel way whereas like on a v00 or something maybe you couldn't",
    "start": "1419720",
    "end": "1425640"
  },
  {
    "text": "do that and so there wasn't that that speed up um I'm making some assumptions here that's true I know for a fact that",
    "start": "1425640",
    "end": "1432480"
  },
  {
    "text": "there are folks in Nvidia that listen to the podcast so hopefully if we were getting this wrong they can yeah clear us up yeah they can clarify for us and",
    "start": "1432480",
    "end": "1439679"
  },
  {
    "text": "we'll come back at a later time on a later episode and say we were wrong we're happy to do that so we're we're",
    "start": "1439679",
    "end": "1445039"
  },
  {
    "text": "making the best of it we were wrong and if you send us a GPU then we'll we'll",
    "start": "1445039",
    "end": "1450559"
  },
  {
    "text": "prove that we were wrong on our own local system you're back to begging oh",
    "start": "1450559",
    "end": "1455919"
  },
  {
    "text": "oh but it seems pretty cool I I mean I I like the idea that if you've gone from a stage of training to",
    "start": "1455919",
    "end": "1462600"
  },
  {
    "text": "inference basically whereas before maybe you had this full like powerful GPU that",
    "start": "1462600",
    "end": "1469640"
  },
  {
    "text": "you were basically running inference on but not like soaking up all of the",
    "start": "1469640",
    "end": "1475480"
  },
  {
    "text": "goodness of the GPU and the the compute here they're basically saying okay well you can sort of uh parallelize the the",
    "start": "1475480",
    "end": "1483200"
  },
  {
    "text": "inference over that and still utilize this whole uh compute capability but now",
    "start": "1483200",
    "end": "1489200"
  },
  {
    "text": "you just have this ability to split it up in nice ways so I I definitely think",
    "start": "1489200",
    "end": "1494720"
  },
  {
    "text": "that's pretty cool and yeah it's interesting with the parallelization of",
    "start": "1494720",
    "end": "1500000"
  },
  {
    "text": "this there was a an image that I saw Nvidia had put out uh where they were kind of comparing the old architecture",
    "start": "1500000",
    "end": "1506360"
  },
  {
    "text": "with the new a100 architecture and they basically had you know one little server for the new that was the equivalent they",
    "start": "1506360",
    "end": "1512600"
  },
  {
    "text": "were showing you know rows of racks of servers in terms of its productivity but it it was definitely an impact it was uh",
    "start": "1512600",
    "end": "1519279"
  },
  {
    "text": "something that me and some folks I work with were passing around and so yeah gota gotta keep up with times I guess if",
    "start": "1519279",
    "end": "1525520"
  },
  {
    "text": "you're going to keep keep driving forward on compute anything else on the architecture at large before we talk",
    "start": "1525520",
    "end": "1531440"
  },
  {
    "text": "about uh DXs or dive into the processors themselves I think the the one thing",
    "start": "1531440",
    "end": "1536559"
  },
  {
    "text": "that you mentioned about like the speed up without code change I think they do introduce this new idea where as people",
    "start": "1536559",
    "end": "1543440"
  },
  {
    "text": "before had talked about floating Point 16 and 32 numbers yeah where again these are",
    "start": "1543440",
    "end": "1549760"
  },
  {
    "text": "having to do with the sort of uh Precision with which you're representing numbers they introduced this new idea of",
    "start": "1549760",
    "end": "1556840"
  },
  {
    "text": "like tensor float 30 2 I saw that which apparently with float 32 obviously if",
    "start": "1556840",
    "end": "1564159"
  },
  {
    "text": "you have more digits you can represent more numbers right there's like this kind of range but you know it's not as",
    "start": "1564159",
    "end": "1571240"
  },
  {
    "text": "fast as using floating Point 16 in some cases so what they're saying is they're trying to balance the two I I think in",
    "start": "1571240",
    "end": "1577960"
  },
  {
    "text": "that they have a wider range of numbers they can represent in this",
    "start": "1577960",
    "end": "1583000"
  },
  {
    "text": "representation but with lower Precision such that they can you know speed up",
    "start": "1583000",
    "end": "1588320"
  },
  {
    "text": "training so you know again hopefully I've represented that well in terms of how they're thinking about it there's an",
    "start": "1588320",
    "end": "1594000"
  },
  {
    "text": "image of this on a blog post that um we'll Link in our show notes if you want to kind of understand how the floating",
    "start": "1594000",
    "end": "1601840"
  },
  {
    "text": "Point 16 32 and tensor float 32 compare",
    "start": "1601840",
    "end": "1607279"
  },
  {
    "text": "but this is definitely a new representation on this chip that I don't think has happened on any other other",
    "start": "1607279",
    "end": "1614559"
  },
  {
    "text": "architecture yet um so that might be worth pointing out yeah totally another thing that we",
    "start": "1614559",
    "end": "1620399"
  },
  {
    "text": "probably should mention from the architecture is that they've they've gone to the new third generation for",
    "start": "1620399",
    "end": "1626200"
  },
  {
    "text": "Envy link and envy switch oh yeah and that manages the network scaling of how",
    "start": "1626200",
    "end": "1632159"
  },
  {
    "text": "you're moving you know your data around through the chips and stuff and I think that it's a something like a 10 times",
    "start": "1632159",
    "end": "1638399"
  },
  {
    "text": "bandwidth if I recall in terms of what it can do compared to or it may have been 10 times more than pcie Generation",
    "start": "1638399",
    "end": "1646159"
  },
  {
    "text": "4 if I I think that was what it was that I was Rec calling reading I'm going to get the number wrong but they said there",
    "start": "1646159",
    "end": "1651679"
  },
  {
    "text": "was like so many terabytes per some insanely small time so it's like a bunch",
    "start": "1651679",
    "end": "1657880"
  },
  {
    "text": "of data you could transfer back and forth very very quickly via these links",
    "start": "1657880",
    "end": "1663919"
  },
  {
    "text": "absolutely so the Envy link is that has to do with communication of data between",
    "start": "1663919",
    "end": "1671240"
  },
  {
    "text": "gpus is that the idea that's what I've always assumed I don't have the opportunity too often to run on like run",
    "start": "1671240",
    "end": "1678799"
  },
  {
    "text": "my training on like 32 gpus so this is where I'm kind of getting to the edge of my understanding but I did watch a",
    "start": "1678799",
    "end": "1685559"
  },
  {
    "text": "YouTube video and I think that's what they implied is that like staying at a",
    "start": "1685559",
    "end": "1691080"
  },
  {
    "text": "Holiday Express that yeah I've stayed at a holiday and express exactly yeah so um",
    "start": "1691080",
    "end": "1696480"
  },
  {
    "text": "I've watched the YouTube video and my understanding was like cuz people also build these Bitcoin mining rigs right",
    "start": "1696480",
    "end": "1703799"
  },
  {
    "text": "and they have all these gpus on top and they're running all the time and the way",
    "start": "1703799",
    "end": "1709039"
  },
  {
    "text": "they do that is they basically connect a bunch of them to PCI slots on a motherboard and to do that they have",
    "start": "1709039",
    "end": "1715519"
  },
  {
    "text": "these little adapters it's called risers that like come out of the motherboard but apparently those are very slow in",
    "start": "1715519",
    "end": "1721360"
  },
  {
    "text": "terms of communication between the gpus yeah and PCI is is slow in that way and",
    "start": "1721360",
    "end": "1727240"
  },
  {
    "text": "so I at least that's what they're implying that like in vlink and um some",
    "start": "1727240",
    "end": "1733200"
  },
  {
    "text": "of these other things from Nvidia help facilitate that communic of data and",
    "start": "1733200",
    "end": "1739000"
  },
  {
    "text": "like you're saying it helps scale out to like now if you have 32 gpus in your data center you know and you're trying",
    "start": "1739000",
    "end": "1745840"
  },
  {
    "text": "to run some computation across them you're going to need to have very quick communication yeah for like scientific",
    "start": "1745840",
    "end": "1753440"
  },
  {
    "text": "applications or AI applications that are not just Bitcoin mining which is just running operations there's actually",
    "start": "1753440",
    "end": "1760080"
  },
  {
    "text": "communication that's needed yeah if I recall correctly and it's been a while since I've I've delved into this was",
    "start": "1760080",
    "end": "1766279"
  },
  {
    "text": "back when they originally released the architecture I believe that uh Envy link connects GPU to GPU it gives you that",
    "start": "1766279",
    "end": "1773399"
  },
  {
    "text": "interconnect between the two and then that you know essentially that that mesh is something that Envy switch then",
    "start": "1773399",
    "end": "1779679"
  },
  {
    "text": "connects at a higher level uh combining the different Envy links too ah I see so",
    "start": "1779679",
    "end": "1784799"
  },
  {
    "text": "MV links GPU to GPU and mvy switch we'll call that now but if listeners if you",
    "start": "1784799",
    "end": "1790559"
  },
  {
    "text": "know we're wrong let us know and and we'll put a note in the show notes or something that's good to make that",
    "start": "1790559",
    "end": "1796000"
  },
  {
    "text": "connection okay yeah yeah and of course these because they're connectable and",
    "start": "1796000",
    "end": "1802399"
  },
  {
    "text": "scalable in this way it seems like this is their new way of replacing what they did have in the dgx which the DXs were",
    "start": "1802399",
    "end": "1811559"
  },
  {
    "text": "the sort of boxes that they put in data centers GPU data centers to like scale",
    "start": "1811559",
    "end": "1818000"
  },
  {
    "text": "up like a AI supercomputer of some type correct or a cluster of them okay which",
    "start": "1818000",
    "end": "1825000"
  },
  {
    "text": "is becoming more and more common in the earlier days you know people would get like when the original djx1 came out uh",
    "start": "1825000",
    "end": "1832080"
  },
  {
    "text": "and it had 8 gpus in it and people would get that and that that in itself people were calling a supercomputer and you",
    "start": "1832080",
    "end": "1838919"
  },
  {
    "text": "know we talked like that such a long time ago it's only been a couple of years but then they moved to dgx 2 and",
    "start": "1838919",
    "end": "1845360"
  },
  {
    "text": "then that was 16 and then they've actually scaled it back and in just a moment let's talk about",
    "start": "1845360",
    "end": "1851580"
  },
  {
    "text": "[Music] [Applause]",
    "start": "1851580",
    "end": "1856490"
  },
  {
    "text": "that the change log is deep discussions in and around the world of software and",
    "start": "1856919",
    "end": "1862440"
  },
  {
    "text": "it's been going for over a decade we interview hackers like Chris Anderson from 3D robotics at the time drones were",
    "start": "1862440",
    "end": "1869279"
  },
  {
    "text": "like predators and Global Hawks and military-industrial they were classified and super you know 10 billion do things",
    "start": "1869279",
    "end": "1876559"
  },
  {
    "text": "and we had just built a drone with Lego pieces around the dining room table programmed by a 9-year-old and it's like",
    "start": "1876559",
    "end": "1883639"
  },
  {
    "text": "okay that should not be possible you know it it when when a 9-year-old can do something that is classified that",
    "start": "1883639",
    "end": "1890320"
  },
  {
    "text": "literally export controlled as munition with Lego with toy pieces it know something important in this world has",
    "start": "1890320",
    "end": "1896519"
  },
  {
    "text": "changed leaders like Devon zugal from GitHub in the like 10 to 15 year range",
    "start": "1896519",
    "end": "1902519"
  },
  {
    "text": "or 20 year range what I would really like is for if you have like three 12-year-olds hanging out and one of",
    "start": "1902519",
    "end": "1908679"
  },
  {
    "text": "them's like I want to be a firefighter another one's like I want to be a lawyer I want one of them to say that I want to be an open source developer and",
    "start": "1908679",
    "end": "1915200"
  },
  {
    "text": "innovators like Amal Hussein I've yet to kind of see applications at scale that don't use multiple languages that don't",
    "start": "1915200",
    "end": "1921200"
  },
  {
    "text": "have just Arcane stories behind why this weirdo thing exists you know like all",
    "start": "1921200",
    "end": "1926799"
  },
  {
    "text": "right when you open this file you're going to have to turn around three times and tap your nose",
    "start": "1926799",
    "end": "1933240"
  },
  {
    "text": "once like it's just the most hilarious stories you know but applications are",
    "start": "1933240",
    "end": "1938679"
  },
  {
    "text": "living breathing they have crafted normal so I want to normalize",
    "start": "1938679",
    "end": "1944799"
  },
  {
    "text": "weirdness because that's just how application evolve over time welcome to",
    "start": "1944799",
    "end": "1950519"
  },
  {
    "text": "the change log please listen to an episode from our catalog that interests you and subscribe today we'd love to",
    "start": "1950519",
    "end": "1956679"
  },
  {
    "text": "have you with [Music]",
    "start": "1956679",
    "end": "1968559"
  },
  {
    "text": "us so now we have this new Nvidia dgx a100 which they've kind of broken the",
    "start": "1968559",
    "end": "1975720"
  },
  {
    "text": "Paradigm of their labeling so they went from DG gx1 originally to djx2 and now",
    "start": "1975720",
    "end": "1980760"
  },
  {
    "text": "they've gone to dgx a100 maybe you'll get one I don't know if I'm going to get one but we we'll see we'll see yeah yeah",
    "start": "1980760",
    "end": "1988760"
  },
  {
    "text": "sadly I'm not in charge of of procurement and I am certainly not in charge of procuring one for my own",
    "start": "1988760",
    "end": "1993919"
  },
  {
    "text": "personal use that we'll see I'm guessing that my nonprofit's not going to get one but if you happen to be getting your dgx",
    "start": "1993919",
    "end": "2001200"
  },
  {
    "text": "a100 and you'd like me to run my training on it I would be more than happy to do some benchmarking for you",
    "start": "2001200",
    "end": "2008399"
  },
  {
    "text": "gotcha I I'll I'll talk to my bosses bosses bosses boss and see see what's possible for I'm there for you my friend",
    "start": "2008399",
    "end": "2015559"
  },
  {
    "text": "I'm really into the mooching today yeah totally I got it I'm good we're there to support you I'm there for you but yeah I",
    "start": "2015559",
    "end": "2022279"
  },
  {
    "text": "mean with this new architecture it's much more performant but they've actually cut the number of gpus in the server back down to eight from 16 but it",
    "start": "2022279",
    "end": "2029720"
  },
  {
    "text": "has the the enhancements that we just talked about at the processor level architecturally so it's interesting that",
    "start": "2029720",
    "end": "2035720"
  },
  {
    "text": "they they kind of cut that down but they have this multi-instance GPU um",
    "start": "2035720",
    "end": "2041559"
  },
  {
    "text": "capability so actually they say you can run 56 applications GPU applications seven per",
    "start": "2041559",
    "end": "2050158"
  },
  {
    "text": "per GPU on the dgx yeah and like you were saying even though there's there's",
    "start": "2050159",
    "end": "2056320"
  },
  {
    "text": "fewer here because the size increase of a100 um they kind of showed this picture",
    "start": "2056320",
    "end": "2062720"
  },
  {
    "text": "in the in the keynote which people can watch but supposedly you can kind of reduce the size and footprint of your",
    "start": "2062720",
    "end": "2069878"
  },
  {
    "text": "data center because you're doing more computation per box per dgx than you",
    "start": "2069879",
    "end": "2075839"
  },
  {
    "text": "were before correct and this is interesting they were saying like you know each box let's say I I think the",
    "start": "2075839",
    "end": "2084358"
  },
  {
    "text": "price they said was like a million dollars right so this is not what I'm going to be putting on my desk but certainly within the range of uh like",
    "start": "2084359",
    "end": "2091280"
  },
  {
    "text": "compute budgets for some companies so like each one was that expensive but you",
    "start": "2091280",
    "end": "2097280"
  },
  {
    "text": "could do the same that you could if you spent previously like $1 million on your data center so like scaling wise you can",
    "start": "2097280",
    "end": "2105839"
  },
  {
    "text": "do more with less I think is the the idea yeah when I was originally looking",
    "start": "2105839",
    "end": "2111800"
  },
  {
    "text": "at these announcements as they came out I think one of the call outs here uh and this architecture does start to address",
    "start": "2111800",
    "end": "2118200"
  },
  {
    "text": "that but I think people in organizations that can't afford to get dgx systems and",
    "start": "2118200",
    "end": "2124079"
  },
  {
    "text": "they do choose to invest in those they underestimate what it takes takes to get productive with them and and so they",
    "start": "2124079",
    "end": "2131400"
  },
  {
    "text": "kind of just think ah I can go buy a dgx and just everything's going to work out after that and then all my training will",
    "start": "2131400",
    "end": "2137760"
  },
  {
    "text": "complete in three days and I'm done exactly nothing to it but I think the",
    "start": "2137760",
    "end": "2142800"
  },
  {
    "text": "challenge is when you're scaling up to one or more dgx systems then you are",
    "start": "2142800",
    "end": "2149319"
  },
  {
    "text": "talking about an overall I'm not just talking about a dgx architecture you're talking about an overall systems and",
    "start": "2149319",
    "end": "2155119"
  },
  {
    "text": "software architecture in your organization uh and and specifically data architecture that can support",
    "start": "2155119",
    "end": "2160440"
  },
  {
    "text": "moving a lot of data around through training in an organized way that flows in with your business processes and that",
    "start": "2160440",
    "end": "2167079"
  },
  {
    "text": "is a big Challenge and I think and being able to make all that work in your own",
    "start": "2167079",
    "end": "2172440"
  },
  {
    "text": "organization is where a lot of organizations are struggling and I know Nvidia works hard to throw them a bone",
    "start": "2172440",
    "end": "2178520"
  },
  {
    "text": "they work hard they recognize that and there are a lot of tools that they put out there to try to help you through",
    "start": "2178520",
    "end": "2183960"
  },
  {
    "text": "that process but I think this architecture has kind of accounted for some of those pain points of the past",
    "start": "2183960",
    "end": "2189960"
  },
  {
    "text": "and they're trying to make it easier to utilize you know in number of gpus across multiple DXs uh which is good",
    "start": "2189960",
    "end": "2197520"
  },
  {
    "text": "because there are cases there are very highly scaled cases where you might be doing a lot of experimentation with like",
    "start": "2197520",
    "end": "2205280"
  },
  {
    "text": "hyperparameter optimization and you want to try just an an insane number of",
    "start": "2205280",
    "end": "2211040"
  },
  {
    "text": "different possibilities yeah when you're doing your training and have the ability not just to train one time but to train",
    "start": "2211040",
    "end": "2217040"
  },
  {
    "text": "many many many times and you know thousands or Millions even and I think they've understood that and that this",
    "start": "2217040",
    "end": "2223240"
  },
  {
    "text": "architecture is starting to address that highly skilled use case yeah I think that gets to the point of sort of you",
    "start": "2223240",
    "end": "2230800"
  },
  {
    "text": "know maybe something that is on people's mind as they listen to this is like why not just the cloud and like use gpus in",
    "start": "2230800",
    "end": "2239920"
  },
  {
    "text": "the cloud which you you can certainly do so like you could you know if you wanted to run a thousand experiments to test",
    "start": "2239920",
    "end": "2245720"
  },
  {
    "text": "all your hyperparameters you could spin up a thousand GPU nodes in Google cloud",
    "start": "2245720",
    "end": "2251280"
  },
  {
    "text": "or Amazon or wherever but if you're doing that at any sort of frequency or",
    "start": "2251280",
    "end": "2256920"
  },
  {
    "text": "length that's going to the bills going to add up pretty crazy fast um on that",
    "start": "2256920",
    "end": "2263480"
  },
  {
    "text": "so if this is something that like a company actually wants to do and you know AI is Central to their strategy to",
    "start": "2263480",
    "end": "2271240"
  },
  {
    "text": "their products and they want to get that very best model and they want to do that",
    "start": "2271240",
    "end": "2277079"
  },
  {
    "text": "experiment ation over and over and over again if this sort of dgx system is",
    "start": "2277079",
    "end": "2282960"
  },
  {
    "text": "capable of supporting you know the usability side of things like you're talking about then",
    "start": "2282960",
    "end": "2288480"
  },
  {
    "text": "they could run those over and over again as much as they are able to useability",
    "start": "2288480",
    "end": "2294119"
  },
  {
    "text": "wise um and so I think that that that kind of gets to the point for some people like you know I keep joking that",
    "start": "2294119",
    "end": "2301040"
  },
  {
    "text": "I'd love to have access to this but I probably wouldn't you know just me myself since I'm the AI person doing a",
    "start": "2301040",
    "end": "2307800"
  },
  {
    "text": "lot of the AI things on my team and I don't have a team of 40 different people trying to run things all the time then",
    "start": "2307800",
    "end": "2314720"
  },
  {
    "text": "you know I'm pretty okay with using like a GPU instance in the cloud when I need",
    "start": "2314720",
    "end": "2321200"
  },
  {
    "text": "it because I might run a training for 48 hours or even four days or something but",
    "start": "2321200",
    "end": "2326400"
  },
  {
    "text": "I do that not very often and it's just me but if you got like a team of 40",
    "start": "2326400",
    "end": "2331599"
  },
  {
    "text": "people or you got multiple teams throughout your organization and they all need to run that stuff that adds up really really quick it does I have been",
    "start": "2331599",
    "end": "2339839"
  },
  {
    "text": "pleased it just in in general when you combine the advances in Envy link and switch when you combine that with the",
    "start": "2339839",
    "end": "2347280"
  },
  {
    "text": "multi-instance gpus that these A1 100s are at this point the scalability technology which without diving into it",
    "start": "2347280",
    "end": "2354160"
  },
  {
    "text": "is called uh melanox uh connect X-6 if I'm saying that right it's a nice blend",
    "start": "2354160",
    "end": "2359880"
  },
  {
    "text": "of architectural considerations to get you there and you know we haven't even talked yet about advancements on the",
    "start": "2359880",
    "end": "2366040"
  },
  {
    "text": "edge yeah and that is is a huge huge area at this point I'm glad you bring that up because it's probably even",
    "start": "2366040",
    "end": "2373160"
  },
  {
    "text": "though you know I may not get access to the sort of dgx system I am thinking",
    "start": "2373160",
    "end": "2378599"
  },
  {
    "text": "about various uh applications at the edge and in fact I had a conversation earlier today with another guy who's",
    "start": "2378599",
    "end": "2384760"
  },
  {
    "text": "working on totally different stuff in manufacturing but they they're not a large company but they do stuff at the",
    "start": "2384760",
    "end": "2391319"
  },
  {
    "text": "edge at in MA the manufacturing setting with low power devices already like",
    "start": "2391319",
    "end": "2397640"
  },
  {
    "text": "think like a Raspberry Pi and that sort of thing but if you could bring the power of like this sort of GPU to like",
    "start": "2397640",
    "end": "2404560"
  },
  {
    "text": "right to the edge to a machine where you're doing computer vision to detect like anomalies in your manufacturing",
    "start": "2404560",
    "end": "2411040"
  },
  {
    "text": "process or something like that that's a pretty major advantage and that brings that sort of capability to those sorts",
    "start": "2411040",
    "end": "2417960"
  },
  {
    "text": "of people that are working on smaller teams and have that specific use case for running AI at the edge they have the",
    "start": "2417960",
    "end": "2425720"
  },
  {
    "text": "Nvidia so along with the a100 they have the egx a100 which they're releasing",
    "start": "2425720",
    "end": "2431400"
  },
  {
    "text": "which seems to benefit from some of these things that we talked about with the a100 but they also talk a lot about",
    "start": "2431400",
    "end": "2436960"
  },
  {
    "text": "security um security and an endend an encryption of AI models encrypt all the",
    "start": "2436960",
    "end": "2442480"
  },
  {
    "text": "things and uh I have some ideas about why you know that may be important at at",
    "start": "2442480",
    "end": "2448000"
  },
  {
    "text": "the edge but you have any thoughts on that well we live in a time where you know we've we've had so many episodes",
    "start": "2448000",
    "end": "2453839"
  },
  {
    "text": "where we talk about malicious actors and they could be anywhere from you know state level all the way down to uh",
    "start": "2453839",
    "end": "2460480"
  },
  {
    "text": "teenagers that are Savvy and having some fun and we're in a world now where you just can't really uh assume that you can",
    "start": "2460480",
    "end": "2467599"
  },
  {
    "text": "put anything that's not secure out of the edge and that doesn't have to be in the defense world you know where I live that can be really anywhere any industry",
    "start": "2467599",
    "end": "2474200"
  },
  {
    "text": "at this point so they have had obviously their previous kind of edge oriented",
    "start": "2474200",
    "end": "2479520"
  },
  {
    "text": "offerings and we like to you know they you know there's there's the smaller scaled stuff that we' like to play with",
    "start": "2479520",
    "end": "2485079"
  },
  {
    "text": "you know they have the NX out now they've had Nan out the last couple of years and so like that but as industry",
    "start": "2485079",
    "end": "2490920"
  },
  {
    "text": "really gets serious about pushing uh inference out to the edge and and having it both widespread and pervasive having",
    "start": "2490920",
    "end": "2499560"
  },
  {
    "text": "kind of a comprehensive uh and sophisticated security model that they can deploy onto these platforms is is",
    "start": "2499560",
    "end": "2505880"
  },
  {
    "text": "pretty key and and I think that's really at this point it's no longer a specialty thing it's now something we're all",
    "start": "2505880",
    "end": "2511119"
  },
  {
    "text": "having to to acknowledge yeah and because like if you think about products",
    "start": "2511119",
    "end": "2516640"
  },
  {
    "text": "some products that have come out over the past years like if you think about a drone that's come out I think there's",
    "start": "2516640",
    "end": "2522880"
  },
  {
    "text": "multiple drones now that have come out that have some sort of AI model running on them that um you know does something",
    "start": "2522880",
    "end": "2529880"
  },
  {
    "text": "like it follows you around or like whatever the thing is uh it does some some operation object detection or",
    "start": "2529880",
    "end": "2536319"
  },
  {
    "text": "something if you're thinking about releasing a product that has like this",
    "start": "2536319",
    "end": "2542880"
  },
  {
    "text": "sort of edge GPU running inside of it whether that be in a manufact uring sense or like like the Drone or or robot",
    "start": "2542880",
    "end": "2550920"
  },
  {
    "text": "sense or something really the AI model that you're releasing with that as part of your IP right and you spent hundreds",
    "start": "2550920",
    "end": "2557960"
  },
  {
    "text": "of thousands of dollars into it so you got like the malicious actor side of thing but you've also got the fact that",
    "start": "2557960",
    "end": "2563040"
  },
  {
    "text": "like oh if I buy a cool thing to strap on my manufacturing machine that has one",
    "start": "2563040",
    "end": "2569559"
  },
  {
    "text": "of these gpus in it um and it's like doing something",
    "start": "2569559",
    "end": "2574880"
  },
  {
    "text": "sophisticated well if they're giving me the model in this product that I'm buying why don't I just like unscrew the",
    "start": "2574880",
    "end": "2581280"
  },
  {
    "text": "hatch and like plug plug my computer in and just take the model off of it and now I don't have to pay them for that",
    "start": "2581280",
    "end": "2587920"
  },
  {
    "text": "product anymore right so we've gotten to a point where the actual AI model is is",
    "start": "2587920",
    "end": "2593760"
  },
  {
    "text": "a piece of Ip and is and is extremely valuable so you wouldn't want like your",
    "start": "2593760",
    "end": "2601160"
  },
  {
    "text": "client or your you know competitor especially to just be able to buy one",
    "start": "2601160",
    "end": "2607119"
  },
  {
    "text": "one of your products unscrew the thing and like you know copy you know cpy",
    "start": "2607119",
    "end": "2613720"
  },
  {
    "text": "model. PB from the from the machine over to their machine and then they've rided",
    "start": "2613720",
    "end": "2619160"
  },
  {
    "text": "themselves of their need for buying your product right so um yeah I was just",
    "start": "2619160",
    "end": "2624200"
  },
  {
    "text": "going to say it's funny I've noticed this a lot lately and that when we talk about the fact that you're now seeing",
    "start": "2624200",
    "end": "2630599"
  },
  {
    "text": "models being deployed to the edge you know just in massively parallel deeply",
    "start": "2630599",
    "end": "2635720"
  },
  {
    "text": "pervasive in in whatever your business is you know as you know I have a daughter uh who's young we just went",
    "start": "2635720",
    "end": "2641280"
  },
  {
    "text": "through a birthday and the toys that you can buy these days are now incorporating",
    "start": "2641280",
    "end": "2646720"
  },
  {
    "text": "this stuff in it is you can actually buy toys that have convolutional neural networks in them you can buy them that",
    "start": "2646720",
    "end": "2652040"
  },
  {
    "text": "have n capability and I think that's the moment where I find myself surprised because we're so used to talking about",
    "start": "2652040",
    "end": "2657960"
  },
  {
    "text": "it in these kind of business orienting contexts but then you know that that's also someone else's business is to make",
    "start": "2657960",
    "end": "2663760"
  },
  {
    "text": "these toys and yeah and I you know I keep being surprised at these toys that she unwraps and they have these",
    "start": "2663760",
    "end": "2670359"
  },
  {
    "text": "capabilities of all people I should not be surprised I suppose but I am just to see it in that context yeah well and",
    "start": "2670359",
    "end": "2675800"
  },
  {
    "text": "especially in that case like at least depending on the age of the child you know it would be important for that AI",
    "start": "2675800",
    "end": "2683640"
  },
  {
    "text": "model to run offline on the device and like let's just keep that thing offline",
    "start": "2683640",
    "end": "2689839"
  },
  {
    "text": "and it's good if it acts as a toy but let's not connect it to the wild west of the internet just yet so yeah I",
    "start": "2689839",
    "end": "2696319"
  },
  {
    "text": "definitely see you you know you'd want to run that sort of model at the edge itself and upload it to the device I",
    "start": "2696319",
    "end": "2701480"
  },
  {
    "text": "think the other thing I wanted to mention is um so I was going you mentioned the Nano so if people are",
    "start": "2701480",
    "end": "2706920"
  },
  {
    "text": "thinking about like Raspberry Pi and this gets down maybe where it it does bring some accessibility to a lot of",
    "start": "2706920",
    "end": "2713839"
  },
  {
    "text": "people um so there's like Raspberry Pi devices which are like single board computer devices which have been of",
    "start": "2713839",
    "end": "2720440"
  },
  {
    "text": "course wildly popular but Nvidia released a um Jetson Nano which which is",
    "start": "2720440",
    "end": "2727520"
  },
  {
    "text": "like a single board computer with a little uh a little GPU on it um and I",
    "start": "2727520",
    "end": "2733160"
  },
  {
    "text": "was actually thinking about getting one of those but I don't know if it was in this series of releases or just very",
    "start": "2733160",
    "end": "2739119"
  },
  {
    "text": "recently they released this Xavier NX which is like a next greater version of",
    "start": "2739119",
    "end": "2745800"
  },
  {
    "text": "this they actually call it like a little AI super computer and it's it is a single board computer it's got like",
    "start": "2745800",
    "end": "2752559"
  },
  {
    "text": "something like a 10x compute or or something like that of the Nano and so",
    "start": "2752559",
    "end": "2758400"
  },
  {
    "text": "when I was going to get that one I just ended up getting the other cuz it seemed pretty awesome and I think that a couple",
    "start": "2758400",
    "end": "2763880"
  },
  {
    "text": "of things struck me about this one is I'm always trying to think of um you know like for example the the cases that",
    "start": "2763880",
    "end": "2771559"
  },
  {
    "text": "we work with and the people that work in our organization around the world of course work in a",
    "start": "2771559",
    "end": "2777000"
  },
  {
    "text": "disconnected uh setting a lot of times because they're out in the field and of course a lot of people around the world",
    "start": "2777000",
    "end": "2782960"
  },
  {
    "text": "don't have internet but then also you know we're not flowing with money so",
    "start": "2782960",
    "end": "2790280"
  },
  {
    "text": "like what is a way to like get things running at the edge in a reasonable way",
    "start": "2790280",
    "end": "2795319"
  },
  {
    "text": "in a disconnected offline way but also at a cost effective way and I find it",
    "start": "2795319",
    "end": "2801160"
  },
  {
    "text": "really interesting that some of these things are coming out that have sort of a GPU capability and the Xavier NX it's",
    "start": "2801160",
    "end": "2808720"
  },
  {
    "text": "interesting that it's it's got the GPU and you can run inference on it but you can actually update your models as well",
    "start": "2808720",
    "end": "2814920"
  },
  {
    "text": "so they talk about doing transfer learning which is like an update of a model so you're redoing some of the",
    "start": "2814920",
    "end": "2820400"
  },
  {
    "text": "training maybe you're training some of the layers or you're training additional layers that you add on to your model so",
    "start": "2820400",
    "end": "2826400"
  },
  {
    "text": "I'm really curious when this comes in I I actually it should be coming in today so I'm kind of watching up my window",
    "start": "2826400",
    "end": "2832480"
  },
  {
    "text": "right now yeah I'm going to reveal before we started the episode when when Daniel and I were talking he's waiting",
    "start": "2832480",
    "end": "2839520"
  },
  {
    "text": "he's watching out the window for UPS to show up station right by my front window we might possibly get a package opening",
    "start": "2839520",
    "end": "2846200"
  },
  {
    "text": "here on air as you know with that new NX fingers crossed yeah um so I'm curious to kind",
    "start": "2846200",
    "end": "2852839"
  },
  {
    "text": "of try I what I want to try actually is just to like start with a small model",
    "start": "2852839",
    "end": "2859440"
  },
  {
    "text": "and see like how the training compares to like in some like with a better GPU",
    "start": "2859440",
    "end": "2865520"
  },
  {
    "text": "and paper space or something and then like try it all the way up to like how far can I push the training on the on",
    "start": "2865520",
    "end": "2872079"
  },
  {
    "text": "the NX can I actually train like how big of a model can I train from scrap on it",
    "start": "2872079",
    "end": "2877520"
  },
  {
    "text": "and then like how big of a model can I do transfer learning on cuz yeah I find",
    "start": "2877520",
    "end": "2883000"
  },
  {
    "text": "that incredibly interesting the other thing that they talk about with the NX is cloud native things at the edge and I",
    "start": "2883000",
    "end": "2889400"
  },
  {
    "text": "know both you and I are really big fans of Docker so I find it interesting whereas before I didn't see them",
    "start": "2889400",
    "end": "2896000"
  },
  {
    "text": "emphasize a lot of things about using Docker at the edge to run like air",
    "start": "2896000",
    "end": "2901359"
  },
  {
    "text": "related workflows and now they're saying well this is how you should do it in this device I find that really",
    "start": "2901359",
    "end": "2906839"
  },
  {
    "text": "interesting yeah and not only Docker but kubernetes as well it's you know I mean",
    "start": "2906839",
    "end": "2912559"
  },
  {
    "text": "and we've talked I know we've talked about this on other episodes when we were hitting slightly different topics but we really this whole kind of AI",
    "start": "2912559",
    "end": "2920200"
  },
  {
    "text": "Revolution that's happened over the especially if you're looking at the last 3 to five years we really really",
    "start": "2920200",
    "end": "2927559"
  },
  {
    "text": "benefited from what had the revolution that had just swept through the software development World um and software",
    "start": "2927559",
    "end": "2934040"
  },
  {
    "text": "systems deployment world out there and that Docker and kubernetes became the",
    "start": "2934040",
    "end": "2939119"
  },
  {
    "text": "systems to build on and we landed on top of that and just took that over so it's really good to see all of the hardware",
    "start": "2939119",
    "end": "2947000"
  },
  {
    "text": "whether you're talking about you know the lower-end gpus such as you know the the Nano that you talked about uh all",
    "start": "2947000",
    "end": "2953359"
  },
  {
    "text": "the way up to you know the latest here this you know dgx a100 all using that",
    "start": "2953359",
    "end": "2959680"
  },
  {
    "text": "same architecture and so if you learn it one place you can use it from the most scaled down to the most scaled up",
    "start": "2959680",
    "end": "2965280"
  },
  {
    "text": "version and you can use it in the data center and you can use it in the edge and that is a wonderful wonderful thing",
    "start": "2965280",
    "end": "2970599"
  },
  {
    "text": "that we've inherited yeah I I totally agree I I've really enjoyed talking about all of these things I've got a lot",
    "start": "2970599",
    "end": "2975960"
  },
  {
    "text": "to learn on all of these fronts and I if you're thinking like oh all of this GPU stuff and like accelerated AI is very",
    "start": "2975960",
    "end": "2983160"
  },
  {
    "text": "new um don't be afraid I I there's still like I I didn't come from a sort of",
    "start": "2983160",
    "end": "2989640"
  },
  {
    "text": "Computer Science Background but there are there is tooling that's accessible for you to you know get into some of",
    "start": "2989640",
    "end": "2996319"
  },
  {
    "text": "these topics and uh one Learning Resource a lot of times in these fully connected episodes we like to mention",
    "start": "2996319",
    "end": "3002640"
  },
  {
    "text": "learning resources so actually envidia themselves um have uh what they call the",
    "start": "3002640",
    "end": "3009079"
  },
  {
    "text": "uh I think it's the Deep learning Institute um Nvidia deep learning Institute and they have a series of of",
    "start": "3009079",
    "end": "3016040"
  },
  {
    "text": "courses that talk about everything from like getting started with AI on the Jets and Nano that's that little single board",
    "start": "3016040",
    "end": "3022240"
  },
  {
    "text": "guy that we were talking about all the way to you know more advanced topics uh",
    "start": "3022240",
    "end": "3028000"
  },
  {
    "text": "with high performance Computing high performance Computing with containers they talk about various GPU accelerated",
    "start": "3028000",
    "end": "3033760"
  },
  {
    "text": "Frameworks like Rapids and AI in the data center and all all sorts of topics so if you're interested in this sort of",
    "start": "3033760",
    "end": "3040640"
  },
  {
    "text": "accelerated AI topic you know you might check that out we'll definitely link it in the um in the show notes as well I",
    "start": "3040640",
    "end": "3047680"
  },
  {
    "text": "know I have a lot to learn there myself so I I'm going to go slightly off topic",
    "start": "3047680",
    "end": "3053839"
  },
  {
    "text": "but I and I it just occurred to me as we were talking about this this for the Learning Resource I'm going to throw out",
    "start": "3053839",
    "end": "3058960"
  },
  {
    "text": "there um it's going to be one that a friend of mine mentioned just earlier today uh that he has utilized uh for",
    "start": "3058960",
    "end": "3066880"
  },
  {
    "text": "those of you who may be familiar with the learning site udy udemy.com um there",
    "start": "3066880",
    "end": "3072520"
  },
  {
    "text": "is a course on there called Docker and kubernetes the complete guide it's not",
    "start": "3072520",
    "end": "3078040"
  },
  {
    "text": "expensive especially there's a lot of coupons you can get it at a very low price like 10 12 $13 and so this person",
    "start": "3078040",
    "end": "3085920"
  },
  {
    "text": "had gone through through uh that course was like halfway 2third of the way through and just thought it was fantastic to ramp up on it so given that",
    "start": "3085920",
    "end": "3093640"
  },
  {
    "text": "recommendation I'm going to recommend that to everybody and we will put a link in the show notes because if you're going to be in the AI World it really",
    "start": "3093640",
    "end": "3100040"
  },
  {
    "text": "pays to understand Docker and kubernetes well awesome yeah well check check those",
    "start": "3100040",
    "end": "3105200"
  },
  {
    "text": "things out um reach out to us on our slack Channel or on LinkedIn or Twitter with any questions or thoughts that you",
    "start": "3105200",
    "end": "3111839"
  },
  {
    "text": "have and hope that this has been a fun episode it has for me it has been we will see you uh next week see you Chris",
    "start": "3111839",
    "end": "3119559"
  },
  {
    "text": "see you later and I apologize to the Nvidia people who are going oh my gosh those guys they they need to know more",
    "start": "3119559",
    "end": "3125040"
  },
  {
    "text": "about it before we accept feedback and and the show notes and everything is uh",
    "start": "3125040",
    "end": "3130160"
  },
  {
    "text": "is on GitHub so you can submit a PR so uh yeah okay feedback welcome see you",
    "start": "3130160",
    "end": "3136079"
  },
  {
    "text": "next time Daniel [Music] bye thank you for listening to practical",
    "start": "3136079",
    "end": "3143000"
  },
  {
    "text": "AI we appreciate your time and your attention word of mouth is the number one way people find new podcasts if",
    "start": "3143000",
    "end": "3150480"
  },
  {
    "text": "practical AI has helped you on your AI Journey please do tell a friend hey they thank you later special thanks to",
    "start": "3150480",
    "end": "3156760"
  },
  {
    "text": "breakmaster cylinder for the beats and to our awesome partners for their support shout out to fley linode and",
    "start": "3156760",
    "end": "3163319"
  },
  {
    "text": "rollbar if you and your organization would benefit by speaking directly to the AI Community you should sponsor",
    "start": "3163319",
    "end": "3170000"
  },
  {
    "text": "practical AI podcast advertising is highly effective and we would love to work with you head to changel log.com /s",
    "start": "3170000",
    "end": "3177000"
  },
  {
    "text": "sponsor to learn more that's all for now we'll talk to you again next",
    "start": "3177000",
    "end": "3183359"
  },
  {
    "text": "[Music]",
    "start": "3183780",
    "end": "3198000"
  },
  {
    "text": "week",
    "start": "3198000",
    "end": "3201000"
  }
]
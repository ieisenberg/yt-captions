[
  {
    "text": "bandwith for change log is provided by fastly learn more at fastly.com we move",
    "start": "40",
    "end": "5560"
  },
  {
    "text": "fast and fix things here at Chang log because of rbar check them out at rar.com and we're hosted on Leno Cloud",
    "start": "5560",
    "end": "11840"
  },
  {
    "text": "servers at the lin.com",
    "start": "11840",
    "end": "15559"
  },
  {
    "text": "changelog this episode is brought to you by digital ocean digital ocean provides worry-free database hosting with their",
    "start": "17119",
    "end": "23760"
  },
  {
    "text": "managed databases if you need to get data in and out of postgress MySQL or",
    "start": "23760",
    "end": "28920"
  },
  {
    "text": "reddis call on the worldclass support teams at digital ocean and stop wasting time on setup backup and maintenance get",
    "start": "28920",
    "end": "35879"
  },
  {
    "text": "simple predictable pricing get detailed documentation get up and running in minutes so you can get on with your",
    "start": "35879",
    "end": "42680"
  },
  {
    "text": "business what are you waiting for H to do. co/ changelog again that's do. co/",
    "start": "42680",
    "end": "49910"
  },
  {
    "text": "[Music]",
    "start": "49910",
    "end": "54000"
  },
  {
    "text": "changelog welcome to practical AI a weekly podcast",
    "start": "58920",
    "end": "66159"
  },
  {
    "text": "about making artificial intelligence practical productive and accessible to everyone this is where conversations",
    "start": "66159",
    "end": "72520"
  },
  {
    "text": "around AI machine learning and data science happen join the community and slack with us around various topics of",
    "start": "72520",
    "end": "77880"
  },
  {
    "text": "the show at change.com Community follow us on Twitter we at practical aifm and",
    "start": "77880",
    "end": "83360"
  },
  {
    "text": "now on to the [Music] show welcome to another fully connected",
    "start": "83360",
    "end": "90560"
  },
  {
    "text": "episode where Daniel and I keep you fully connected with everything that's happening in the AI Community we'll take",
    "start": "90560",
    "end": "96399"
  },
  {
    "text": "some time to discuss the latest AI news and we'll dig into learning resources to help you level up on your machine",
    "start": "96399",
    "end": "101759"
  },
  {
    "text": "learning game um my name is Chris Benson I am principal AI strategist at lock heed Martin and with me as always is",
    "start": "101759",
    "end": "108799"
  },
  {
    "text": "Daniel whack who is a data scientist at s International hey how's it going today Daniel it's going pretty good it's 2020",
    "start": "108799",
    "end": "115719"
  },
  {
    "text": "crazy man happy New Year man woo so we have uh we have just put to bed uh our",
    "start": "115719",
    "end": "122600"
  },
  {
    "text": "first full calendar year of podcast since we started mid 2018 um it's uh I",
    "start": "122600",
    "end": "129039"
  },
  {
    "text": "think if I do the math right this is episode 71 um unless we unless we switch",
    "start": "129039",
    "end": "134920"
  },
  {
    "text": "anything up but uh yeah so 70 plus um it's pretty pretty exciting I don't know",
    "start": "134920",
    "end": "140599"
  },
  {
    "text": "what we'll do when we hit 100 but um we'll we'll make sure and have something",
    "start": "140599",
    "end": "146319"
  },
  {
    "text": "exciting for listeners when we when we hit 100 for sure and if any of the listeners out there have any suggestions",
    "start": "146319",
    "end": "152360"
  },
  {
    "text": "for that let us know uh you know join us in our slack channel uh where we are on",
    "start": "152360",
    "end": "158319"
  },
  {
    "text": "all all the time every day talking to people uh or you can reach us on LinkedIn uh or Twitter um we are",
    "start": "158319",
    "end": "164840"
  },
  {
    "text": "definitely out there having conversations with you guys yeah definitely um and pretty soon uh just as",
    "start": "164840",
    "end": "171319"
  },
  {
    "text": "a as a final reminder for people I think um we might have Miss mentioned this on other episodes but um both of us will be",
    "start": "171319",
    "end": "178879"
  },
  {
    "text": "at the project voice conference um which I think as far as when this episode airs",
    "start": "178879",
    "end": "184440"
  },
  {
    "text": "will be the following week so January like 13th through the 16th so if you're around at project Voice come find us",
    "start": "184440",
    "end": "190920"
  },
  {
    "text": "we'll be recording some some episodes in the uh s International booth and uh as",
    "start": "190920",
    "end": "197200"
  },
  {
    "text": "well giving a keynote together uh both Chris and I so um it'll be fun to to be",
    "start": "197200",
    "end": "202640"
  },
  {
    "text": "there and think a little bit about speech and voice and Ai and what's going on in in that world absolutely that'll",
    "start": "202640",
    "end": "208720"
  },
  {
    "text": "be in Chattanooga tenness I think uh on the the week of the is it I think it's Monday the 13th if I'm if",
    "start": "208720",
    "end": "215200"
  },
  {
    "text": "I'm recalling correctly so you know today we're going to do the same thing we did about this time last year as we",
    "start": "215200",
    "end": "220760"
  },
  {
    "text": "got into 2019 we really wanted to kind of uh look back on a couple of notable",
    "start": "220760",
    "end": "226760"
  },
  {
    "text": "points uh in the AI World in 2019 talk about kind of why we think",
    "start": "226760",
    "end": "232319"
  },
  {
    "text": "they were notable and also kind of assess the current state of AI where we are right now and then look ahead to",
    "start": "232319",
    "end": "239079"
  },
  {
    "text": "2020 and and of course it would not be uh a start- of year show if we didn't try to make a few predictions each of us",
    "start": "239079",
    "end": "245840"
  },
  {
    "text": "on where things are going over the next year it is practical AI so I feel like we have to make predicting has to be a",
    "start": "245840",
    "end": "253200"
  },
  {
    "text": "part of it there you of course absolutely and the predictions will be likely wrong but maybe if after we do",
    "start": "253200",
    "end": "261000"
  },
  {
    "text": "this for like 20 years we can we we'll have a proper test set of predictions",
    "start": "261000",
    "end": "266160"
  },
  {
    "text": "that we can really determine what our what our accuracy was oh I'm not looking forward to that result I'm not sure",
    "start": "266160",
    "end": "271680"
  },
  {
    "text": "that's good and I'm not sure if we should call them predictions or inferences considering the field that we're in here maybe that would be better",
    "start": "271680",
    "end": "278400"
  },
  {
    "text": "one of the things um that we were talking about before we started recording is just kind of it's been an amazing ride so far and that is entirely",
    "start": "278400",
    "end": "286479"
  },
  {
    "text": "due to our listeners and our guests and as you pointed out you know we just would not be where we're at with the",
    "start": "286479",
    "end": "292680"
  },
  {
    "text": "with the the show being as popular and so many people expressing how helpful it's been for them to get into this",
    "start": "292680",
    "end": "299199"
  },
  {
    "text": "field understand the detail yeah thank you to our listeners and our guests um I mean the the guests for sure of course",
    "start": "299199",
    "end": "306960"
  },
  {
    "text": "are a lot of the great content comes directly from them Chris and I are mostly uh you know I feel like a lot of",
    "start": "306960",
    "end": "313600"
  },
  {
    "text": "times we're just kind of facilitators and they're to listen to the great content that is there so thank you to",
    "start": "313600",
    "end": "319160"
  },
  {
    "text": "our guests it has been great to get you know uh feedback on our slack Channel",
    "start": "319160",
    "end": "325319"
  },
  {
    "text": "talk to people on Twitter talk to people at conferences who are aware of the podcast and and are getting value out of",
    "start": "325319",
    "end": "332319"
  },
  {
    "text": "it and a lot of that is because we do get feedback we hear it would be awesome if you did a show on this or I'd love to",
    "start": "332319",
    "end": "337759"
  },
  {
    "text": "hear about this and and we definitely try to integrate those things in so thank you to being part of the community",
    "start": "337759",
    "end": "344400"
  },
  {
    "text": "I hope you feel welcome and are excited for 2020 like we are absolutely I think",
    "start": "344400",
    "end": "350319"
  },
  {
    "text": "a huge part of the show is the community aspect of it even more so than the the technical it gives people an ability to",
    "start": "350319",
    "end": "356800"
  },
  {
    "text": "connect so thank you all for constantly talking to us over this past year and a half and making sure that we stay on",
    "start": "356800",
    "end": "363039"
  },
  {
    "text": "track on how best to to meet your needs so I guess with that said I know that on a couple of things looking back we",
    "start": "363039",
    "end": "370120"
  },
  {
    "text": "definitely yeah top things of 2019 absolutely we definitely uh are in",
    "start": "370120",
    "end": "375240"
  },
  {
    "text": "agreement on quite a few of those you want to kind of one of those big topics is Transformers and you want to kind of",
    "start": "375240",
    "end": "381400"
  },
  {
    "text": "kind of jump into that and and set that up so when we were thinking about you know the top AI milestones or notable",
    "start": "381400",
    "end": "390479"
  },
  {
    "text": "things of of 2019 we both kind of Drew up our own list of things that that we",
    "start": "390479",
    "end": "396560"
  },
  {
    "text": "were interested in or or thought were notable there was a little bit of overlap but the big piece that was",
    "start": "396560",
    "end": "402000"
  },
  {
    "text": "overlap was Transformers and um we have an episode that talks about this in a",
    "start": "402000",
    "end": "407240"
  },
  {
    "text": "lot more detail specifically related to Bert and we referenced gpt2 a couple",
    "start": "407240",
    "end": "412400"
  },
  {
    "text": "times but if you aren't aware with of those episodes or haven't listened to them 2019 has kind of been the year of",
    "start": "412400",
    "end": "420000"
  },
  {
    "text": "the large language models the year of the Transformers so this kind of got kicked off with bird and and gpt2 and",
    "start": "420000",
    "end": "427240"
  },
  {
    "text": "other models that were really large scale language models that in essence",
    "start": "427240",
    "end": "433840"
  },
  {
    "text": "were able to learn a lot about language in general by being trained on many many",
    "start": "433840",
    "end": "441520"
  },
  {
    "text": "uh documents so lots of data scraped from the web or or other places and um",
    "start": "441520",
    "end": "447319"
  },
  {
    "text": "we're able to transfer to a lot of different NLP tasks so whether that's",
    "start": "447319",
    "end": "453960"
  },
  {
    "text": "machine translation or reading comprehension or named entity recognition all sorts of things text",
    "start": "453960",
    "end": "461680"
  },
  {
    "text": "classification these models have allowed us to sort of have a a zoo of really",
    "start": "461680",
    "end": "468720"
  },
  {
    "text": "large pre-trained models that know a lot about language and transfer those easily",
    "start": "468720",
    "end": "475199"
  },
  {
    "text": "to these various tasks and so we can kind of stand on the on the shoulders of science in a sense of open Ai and Google",
    "start": "475199",
    "end": "482240"
  },
  {
    "text": "and others who have trained these large models have a lot of data and then allow us to kind of just level up our own NLP",
    "start": "482240",
    "end": "490720"
  },
  {
    "text": "game by utilizing these these pre-trained models and that's that's been a huge boost to NLP this year in in",
    "start": "490720",
    "end": "498479"
  },
  {
    "text": "particular I think the thing that really struck me about it is you and I actually come at this from different perspectives",
    "start": "498479",
    "end": "504800"
  },
  {
    "text": "you are a true NLP expert anyone uh who has listened to our episodes very",
    "start": "504800",
    "end": "509960"
  },
  {
    "text": "when we talk about this we'll know that it's what you do all the time I observe it but it's not my specialty so I'm kind",
    "start": "509960",
    "end": "516120"
  },
  {
    "text": "of coming from an Outsiders perspective on that and the the thing that really struck me is these these new large",
    "start": "516120",
    "end": "522719"
  },
  {
    "text": "language models just impacted the entire world of deep learning and Industry at large whether or not you were neck deep",
    "start": "522719",
    "end": "529880"
  },
  {
    "text": "in it the way you are or whether you're really kind of watching this from outside and just being a user of these",
    "start": "529880",
    "end": "535519"
  },
  {
    "text": "externally the way I am and so it was like the big hits just kept on coming through 2019 as as we did this I know I",
    "start": "535519",
    "end": "543920"
  },
  {
    "text": "was absolutely as was probably most people blown away when open II uh did",
    "start": "543920",
    "end": "550040"
  },
  {
    "text": "their first blog post on gpt2 uh early in the year I think it was February if I'm recalling correctly and",
    "start": "550040",
    "end": "557600"
  },
  {
    "text": "even as they as they introduced it they noted you know a couple of things that it is a it as we have specified it's a",
    "start": "557600",
    "end": "563959"
  },
  {
    "text": "Transformer language model and it's used as a generative model of language where you can essentially give it a sentence",
    "start": "563959",
    "end": "571399"
  },
  {
    "text": "to start with and it will generate a great deal of text which in many cases is indistinguishable to the Casual",
    "start": "571399",
    "end": "578200"
  },
  {
    "text": "Observer you know on whether or not it came from a computer or from a human and it was pretty amazing when we saw that",
    "start": "578200",
    "end": "584240"
  },
  {
    "text": "and they did that initial release which was a scaled down version just to let the world try it and they had to they",
    "start": "584240",
    "end": "590240"
  },
  {
    "text": "were kind of recognizing there could be security uh implications on that they were slow to release and released in",
    "start": "590240",
    "end": "596880"
  },
  {
    "text": "stages But ultimately if I'm recalling the larger model they released later on",
    "start": "596880",
    "end": "602320"
  },
  {
    "text": "in the year was trained on on web text which contains over 8 million documents",
    "start": "602320",
    "end": "607519"
  },
  {
    "text": "for a total of 40 gab of text which from you know if that was images it wouldn't",
    "start": "607519",
    "end": "612680"
  },
  {
    "text": "be so much but for text that's enormous and they they pulled that from URLs on the internet in an unsupervised approach",
    "start": "612680",
    "end": "620399"
  },
  {
    "text": "that was from Reddit submissions in which case they had at least three up votes so they had a huge huge Corpus of",
    "start": "620399",
    "end": "626040"
  },
  {
    "text": "text to pull from and I just remember seeing those or those early examples of what was possible and thinking okay",
    "start": "626040",
    "end": "632600"
  },
  {
    "text": "we're we're in a new place on the NLP front at this point yeah definitely I've talked to many colleagues who have",
    "start": "632600",
    "end": "639040"
  },
  {
    "text": "expressed specifically with that blog post that you mentioned that prior to the blog post if you were to ask them",
    "start": "639040",
    "end": "646880"
  },
  {
    "text": "hey you know what's the best that an AI model could do in generating text",
    "start": "646880",
    "end": "652959"
  },
  {
    "text": "regardless of of architecture kind of everything that's been done in the past what's the best we could do they would",
    "start": "652959",
    "end": "658440"
  },
  {
    "text": "have guessed you know a much lower quality than what was published in that blog post yeah and",
    "start": "658440",
    "end": "664440"
  },
  {
    "text": "just kind of being blown away by that and then of course that fueled all sorts",
    "start": "664440",
    "end": "669800"
  },
  {
    "text": "of things throughout the year so I think these years kind of 2018 2019 have been",
    "start": "669800",
    "end": "676320"
  },
  {
    "text": "referred to as nlp's imag net moment so if you remember uh further back when",
    "start": "676320",
    "end": "683000"
  },
  {
    "text": "imet came out which is a was a challenge around object recognition um and computer vision uh",
    "start": "683000",
    "end": "691160"
  },
  {
    "text": "there was there was a huge boost in computer vision and Ai and um this I",
    "start": "691160",
    "end": "696839"
  },
  {
    "text": "think is kind of a parallel in in what's gone on and so there's just been an",
    "start": "696839",
    "end": "702240"
  },
  {
    "text": "explosion in all sorts of things that build on this technology so the technology itself you know these large",
    "start": "702240",
    "end": "708680"
  },
  {
    "text": "language models again they're not they're kind of building blocks in in a way um we we talked in uh the blog post",
    "start": "708680",
    "end": "715600"
  },
  {
    "text": "about Bert about how these are structured often into sort of uh encoding layers and and decoding layers",
    "start": "715600",
    "end": "722639"
  },
  {
    "text": "and how you can utilize Bert or these other models to create these sort of",
    "start": "722639",
    "end": "728839"
  },
  {
    "text": "word embeddings or representations of text that can be used for a variety of",
    "start": "728839",
    "end": "734040"
  },
  {
    "text": "tasks and so that's spurred not only innovation in sort of text generation",
    "start": "734040",
    "end": "739839"
  },
  {
    "text": "but innovation in all sorts of NLP tasks like I mentioned in and translation and and all sorts of things and I just saw",
    "start": "739839",
    "end": "746760"
  },
  {
    "text": "one of the big indications of this I think is I saw that Google search which",
    "start": "746760",
    "end": "751800"
  },
  {
    "text": "is arguably Google's uh kind of bread and butter right they just switched over",
    "start": "751800",
    "end": "757440"
  },
  {
    "text": "to actually integrating Bert which is one of these Transformer models large",
    "start": "757440",
    "end": "762680"
  },
  {
    "text": "language models directly into Google search in production you know live now",
    "start": "762680",
    "end": "768839"
  },
  {
    "text": "so I don't think Google would be taking that risk if they weren't convinced that this was a transformative technology so",
    "start": "768839",
    "end": "775680"
  },
  {
    "text": "that's pretty cool is almost a meta issue around this there was quite a bit",
    "start": "775680",
    "end": "780760"
  },
  {
    "text": "of controversy in how gp2 was released and you know we already talked about the",
    "start": "780760",
    "end": "786040"
  },
  {
    "text": "the stage release that they did in that original blog post they note under release strategy they say we're not",
    "start": "786040",
    "end": "792360"
  },
  {
    "text": "releasing the data set the training code or the gp2 model weights and they specify that we expect that Safety and",
    "start": "792360",
    "end": "798760"
  },
  {
    "text": "Security concerns will reduce our traditional publishing in the future while increasing the importance of",
    "start": "798760",
    "end": "804040"
  },
  {
    "text": "sharing safety policy and standards research um and that was really the first time that a major AI research",
    "start": "804040",
    "end": "812240"
  },
  {
    "text": "organization had done you know everybody up until that moment was just publishing as fast as they could as new stuff came",
    "start": "812240",
    "end": "819079"
  },
  {
    "text": "out and that was the moment where they suddenly said we have a greater concern and there was quite a lot of debate",
    "start": "819079",
    "end": "824760"
  },
  {
    "text": "about you know whether or not that was the right approach or or not I know we talked about it on the show a little bit",
    "start": "824760",
    "end": "830480"
  },
  {
    "text": "but it was just interesting to see how that policy uh debate shaked out over time yeah I would specifically you know",
    "start": "830480",
    "end": "838160"
  },
  {
    "text": "like to note and longtime listeners of the show will know that I I like to mention this group quite a bit because I",
    "start": "838160",
    "end": "844959"
  },
  {
    "text": "really um think that they're a big part of what's what's happening I specifically don't think that the",
    "start": "844959",
    "end": "852320"
  },
  {
    "text": "momentum that's built up this year around Transformers would have been quite as much without hugging fa's",
    "start": "852320",
    "end": "859000"
  },
  {
    "text": "contribution absolutely so we had Clen from hugging face on a while back we'll",
    "start": "859000",
    "end": "864560"
  },
  {
    "text": "reference that episode that was actually before a lot of the stuff I'm about to",
    "start": "864560",
    "end": "870399"
  },
  {
    "text": "talk about really built up but after that episode hugging face um they came",
    "start": "870399",
    "end": "875800"
  },
  {
    "text": "out with a few things one of those was this application called write with Transformers which is a really you know",
    "start": "875800",
    "end": "881839"
  },
  {
    "text": "for non-technical people you can just go to this app and choose any of these language models you want and just try to",
    "start": "881839",
    "end": "888720"
  },
  {
    "text": "generate some text with it and it's kind of like a Word document where you can kind of integrate these models and I",
    "start": "888720",
    "end": "895519"
  },
  {
    "text": "think that was just like a a huge eye opener for people cuz not a bunch of non-technical people could go in there",
    "start": "895519",
    "end": "901880"
  },
  {
    "text": "and do this it also forced hugging face to really deal with this well how how do",
    "start": "901880",
    "end": "908240"
  },
  {
    "text": "we productionize these models how do we integrate them practically which led them to release the Transformers Library",
    "start": "908240",
    "end": "915519"
  },
  {
    "text": "which is one of the widest used uh NLP AI libraries I think that's been",
    "start": "915519",
    "end": "921920"
  },
  {
    "text": "mentioned a lot this year top conferences even all the research conferences but industry conferences",
    "start": "921920",
    "end": "927759"
  },
  {
    "text": "even tensorflow Dev Summit even though uh hugging faces traditionally work with with pie torch I think so this is this",
    "start": "927759",
    "end": "934000"
  },
  {
    "text": "is really transformative I even in my car often I listen to NPR I do too I was",
    "start": "934000",
    "end": "941319"
  },
  {
    "text": "listening to NPR and uh there was someone on there I I forget the exact",
    "start": "941319",
    "end": "946680"
  },
  {
    "text": "topic I I don't remember the context but they were talking about Ai and they were like well I can use an AI model to",
    "start": "946680",
    "end": "953040"
  },
  {
    "text": "generate some new uh NPR show titles for this show and they used right with",
    "start": "953040",
    "end": "959360"
  },
  {
    "text": "Transformers the app from hugging face to do that uh sort of on the show which was which was pretty",
    "start": "959360",
    "end": "966040"
  },
  {
    "text": "cool so you know I'm looking over what they do and I you know they've done such a good job of integrating their",
    "start": "966040",
    "end": "972519"
  },
  {
    "text": "Transformers in with the existing tooling as you know tensor flow 2 uh you know was out this year and pytorch and",
    "start": "972519",
    "end": "979279"
  },
  {
    "text": "those two still probably uh I know there'll be some people disagreeing with me but probably the dominant to",
    "start": "979279",
    "end": "984959"
  },
  {
    "text": "Frameworks and and the tight integration they've really made in n LP not only",
    "start": "984959",
    "end": "990120"
  },
  {
    "text": "powerful but incredibly accessible to people in your view I know that you follow them very closely uh you know",
    "start": "990120",
    "end": "996040"
  },
  {
    "text": "even Beyond us having them on the episode what do you think hugging face has done so well uh and so right to you",
    "start": "996040",
    "end": "1003639"
  },
  {
    "text": "know they've kind of become to some degree it seems that kind of The Darlings of the NLP world uh this year",
    "start": "1003639",
    "end": "1009480"
  },
  {
    "text": "that's at least how that's my own feeling of it yeah for sure um I mean I think that a couple things that maybe",
    "start": "1009480",
    "end": "1015639"
  },
  {
    "text": "can be extracted from that and we can learn for our own work is that they have",
    "start": "1015639",
    "end": "1020959"
  },
  {
    "text": "focused on making things uh sort of giving people an immediate satisfaction",
    "start": "1020959",
    "end": "1027280"
  },
  {
    "text": "with using these tools so the right with Transformers thing you don't have to even go to GitHub or download any models",
    "start": "1027280",
    "end": "1033600"
  },
  {
    "text": "or anything you just go and you try it out right and so that that I think is one thing is is kind of that we could",
    "start": "1033600",
    "end": "1040640"
  },
  {
    "text": "extract from this is you know making AI consumable to all sorts of audiences is",
    "start": "1040640",
    "end": "1046600"
  },
  {
    "text": "something that is incredibly valuable but then also for developers prior to",
    "start": "1046600",
    "end": "1051679"
  },
  {
    "text": "the Transformers Library it was still rather difficult to integrate these",
    "start": "1051679",
    "end": "1057400"
  },
  {
    "text": "Large Scale Models into a normal workflow and Transformers really gave a",
    "start": "1057400",
    "end": "1063320"
  },
  {
    "text": "standardized API that people could use to pull in these models utilize them for various tasks or just utilize them for",
    "start": "1063320",
    "end": "1071720"
  },
  {
    "text": "uh generating embeddings and so uh I think that sort of standardization is",
    "start": "1071720",
    "end": "1076760"
  },
  {
    "text": "something that we also saw with spy so Spacey which we had on the show recently",
    "start": "1076760",
    "end": "1082240"
  },
  {
    "text": "that's true it has been and still is extremely popular in the space in the",
    "start": "1082240",
    "end": "1087280"
  },
  {
    "text": "NLP space and I think those are also characteristics that we've seen with",
    "start": "1087280",
    "end": "1092559"
  },
  {
    "text": "Spacey where they value good design they value a good user experience they have a",
    "start": "1092559",
    "end": "1099400"
  },
  {
    "text": "nice way to standardize the sort of workflow around NLP to these sorts of",
    "start": "1099400",
    "end": "1104840"
  },
  {
    "text": "pipelines so I think those are really key ideas that that we could take away way and just to give hugging face kind",
    "start": "1104840",
    "end": "1111000"
  },
  {
    "text": "of a final congrats they ended the year with an announcement of 15 million in in",
    "start": "1111000",
    "end": "1116159"
  },
  {
    "text": "funding to continue development of of Transformers and and what they're doing so I think it's worth taking time to",
    "start": "1116159",
    "end": "1122679"
  },
  {
    "text": "mention them and always happy to absolutely they've had such a profound impact on the industry this year it's uh",
    "start": "1122679",
    "end": "1129880"
  },
  {
    "text": "they just been very very impressed with them uh it was a great episode so if if anyone out there hasn't listened to that",
    "start": "1129880",
    "end": "1135360"
  },
  {
    "text": "episode you you definitely should",
    "start": "1135360",
    "end": "1140720"
  },
  {
    "text": "[Music]",
    "start": "1144850",
    "end": "1149890"
  },
  {
    "text": "if you like this show I bet you'd enjoy listening to brain science join clinical psychologists Muriel Reese and Adam",
    "start": "1151640",
    "end": "1157880"
  },
  {
    "text": "stovak as they explore the inner workings of the human brain to understand Behavior change habit",
    "start": "1157880",
    "end": "1163159"
  },
  {
    "text": "formation mental health and being human here's a quick taste of what you can expect is from episode 4 about coping",
    "start": "1163159",
    "end": "1169600"
  },
  {
    "text": "skills and strategies take a listen I often use This Acronym with",
    "start": "1169600",
    "end": "1175720"
  },
  {
    "text": "people when they're trying to copec and it's halt h a l t halt because if we are",
    "start": "1175720",
    "end": "1183159"
  },
  {
    "text": "hungry angry lonely or tired your coping",
    "start": "1183159",
    "end": "1188440"
  },
  {
    "text": "will invariably look different I don't care if you're 3 33 73 right if you are",
    "start": "1188440",
    "end": "1194280"
  },
  {
    "text": "hungry or hangry angry lonely or retired",
    "start": "1194280",
    "end": "1199799"
  },
  {
    "text": "you just have less to be able to navigate it brain science is a great",
    "start": "1199799",
    "end": "1205400"
  },
  {
    "text": "podcast check it out at changel log.com brain science or just search brain science in apple podcast Spotify or your",
    "start": "1205400",
    "end": "1212840"
  },
  {
    "text": "favorite podcast directory you'll find it while you're ated upgrade to our Master feed at change.com and let your",
    "start": "1212840",
    "end": "1219000"
  },
  {
    "text": "podcast app download all the shows we produce then you can pick and choose the ones you're interested in the most and skip the rest what have you got to lose",
    "start": "1219000",
    "end": "1225919"
  },
  {
    "text": "all right back to the show",
    "start": "1225919",
    "end": "1230640"
  },
  {
    "text": "[Music]",
    "start": "1231300",
    "end": "1238029"
  },
  {
    "text": "so there were a couple of things uh this past year I don't know that they were the the most important things",
    "start": "1239320",
    "end": "1245520"
  },
  {
    "text": "necessarily but they were certainly events that that really captured my imagination and we did have actually",
    "start": "1245520",
    "end": "1251080"
  },
  {
    "text": "episodes uh on on both of things I'm about to mention the first one people may recall a few months back open AI did",
    "start": "1251080",
    "end": "1258000"
  },
  {
    "text": "some work with uh robotic dexterity using a robotic hand that where the hand",
    "start": "1258000",
    "end": "1263600"
  },
  {
    "text": "was trying to solve a Rubik's Cube and just to specify and we had a whole episode talking about this it wasn't the",
    "start": "1263600",
    "end": "1270559"
  },
  {
    "text": "algorithm of the Rubik's Cube that the AI portions were solving because those are known Solutions out there so they",
    "start": "1270559",
    "end": "1276760"
  },
  {
    "text": "just implemented one of those but what they were doing was using reinforcement learning to really get the dexterity and",
    "start": "1276760",
    "end": "1283840"
  },
  {
    "text": "sensitivity of the robotic hand to really a whole new level that had been doing and they shared some videos out",
    "start": "1283840",
    "end": "1290480"
  },
  {
    "text": "there showing the robot manipulating the single robot hand manipulating the cube in all sorts of ways and it really",
    "start": "1290480",
    "end": "1297919"
  },
  {
    "text": "inspired me seeing that to see the delicateness of it the capability of",
    "start": "1297919",
    "end": "1303600"
  },
  {
    "text": "being able to to do very minute turns on the cube with with digits and fli it was",
    "start": "1303600",
    "end": "1310120"
  },
  {
    "text": "interesting it would make you hold your breath as you watch the video and at moments the Rubik's Cube would roll",
    "start": "1310120",
    "end": "1315320"
  },
  {
    "text": "right up onto the fingertips of the robot and it would stop balance and then spin and it just made me realize that we",
    "start": "1315320",
    "end": "1321400"
  },
  {
    "text": "were at the dawn of a new age for robotics in terms of what AI could do to really supercharge where Robotics are",
    "start": "1321400",
    "end": "1327559"
  },
  {
    "text": "right now not only in in more traditional movements and such but but",
    "start": "1327559",
    "end": "1332600"
  },
  {
    "text": "also in these tiny little dexterity things with with sensors that are able to capture delicate things and you could",
    "start": "1332600",
    "end": "1339320"
  },
  {
    "text": "after watching that video you could easily think of robots you know as we've",
    "start": "1339320",
    "end": "1344440"
  },
  {
    "text": "talked about medicine and things you know doing incredibly uh Dynamic and",
    "start": "1344440",
    "end": "1350039"
  },
  {
    "text": "precise forms of surgery you know on humans in that way that if you had all",
    "start": "1350039",
    "end": "1355080"
  },
  {
    "text": "of the right sensors and everything that you could take Ai and Robotics in medicine to a whole new level and that",
    "start": "1355080",
    "end": "1361960"
  },
  {
    "text": "really had a fairly profound for just one story it had a fairly profound impact on my perception of the",
    "start": "1361960",
    "end": "1367760"
  },
  {
    "text": "state-of-the-art how about yourself yeah um it was interesting and and this is a",
    "start": "1367760",
    "end": "1372919"
  },
  {
    "text": "space you're you're much more familiar with the space but I think the the things that stood out to me with that",
    "start": "1372919",
    "end": "1378679"
  },
  {
    "text": "was their focus on making the models robust against perturbations and and",
    "start": "1378679",
    "end": "1385600"
  },
  {
    "text": "sort of new scenarios so they developed these techniques around domain",
    "start": "1385600",
    "end": "1391320"
  },
  {
    "text": "randomization and increasing the randomization during during training um such that the the hand was able to deal",
    "start": "1391320",
    "end": "1399840"
  },
  {
    "text": "with all sorts of unexpected scenarios and I don't know if it's accurate maybe you can tell me but it it seems like",
    "start": "1399840",
    "end": "1406039"
  },
  {
    "text": "maybe one of the things that's that's held back um Ai and Robotics a bit is is this fact",
    "start": "1406039",
    "end": "1413039"
  },
  {
    "text": "of generalizing to all sorts of different scenarios like if you're saying with medicine and surgery you",
    "start": "1413039",
    "end": "1420000"
  },
  {
    "text": "know people are come in all sorts of different shapes and sizes and ages and",
    "start": "1420000",
    "end": "1425559"
  },
  {
    "text": "so having you know a hand that would perform certain procedures would need to",
    "start": "1425559",
    "end": "1431159"
  },
  {
    "text": "deal with all sorts of scenarios and you can't have all of those in your training set so how do you make sure that you're",
    "start": "1431159",
    "end": "1439039"
  },
  {
    "text": "your system is able to extend and generalize to different scenarios I",
    "start": "1439039",
    "end": "1444520"
  },
  {
    "text": "think that that focus in the project was was really interesting to me if that Focus continues it maybe there's a way",
    "start": "1444520",
    "end": "1451240"
  },
  {
    "text": "to to kind of push the boundary there yeah it it's really created a revolution",
    "start": "1451240",
    "end": "1456279"
  },
  {
    "text": "in robotics in terms of you know we've had robotics for decades you know deployed in various Industries uh",
    "start": "1456279",
    "end": "1462559"
  },
  {
    "text": "particularly industrial uses and for a long time everything about you know for instance an assembly line had to be very",
    "start": "1462559",
    "end": "1469240"
  },
  {
    "text": "precisely measured and there could not be variability substantial variability in those workflows and so we've really",
    "start": "1469240",
    "end": "1476520"
  },
  {
    "text": "seen over the past 2 or 3 years at the moment culminating in this robotic",
    "start": "1476520",
    "end": "1482000"
  },
  {
    "text": "dexterity demonstration that we saw is the ability to accommodate some variability and have the ability to make",
    "start": "1482000",
    "end": "1489720"
  },
  {
    "text": "change based on that variability dynamically and real time and so when we're looking forward and I know we're",
    "start": "1489720",
    "end": "1495399"
  },
  {
    "text": "going to talk about kind of the world ahead you know time ahead uh later on in this episode but it really starts",
    "start": "1495399",
    "end": "1502960"
  },
  {
    "text": "creating new possibilities in terms of using these in scenarios that it just wasn't practical and realistic before",
    "start": "1502960",
    "end": "1509919"
  },
  {
    "text": "and so it was a neat demo I don't think people should get too hung up on the Rubik's Cube aspect itself I just think",
    "start": "1509919",
    "end": "1515000"
  },
  {
    "text": "that was a a tool to show what they were getting to um but it was a it was a pretty cool moment the other thing that",
    "start": "1515000",
    "end": "1521320"
  },
  {
    "text": "had a very profound effect on me this last year and we had an episode on it kind of mid year I think it was in June",
    "start": "1521320",
    "end": "1527120"
  },
  {
    "text": "was on deep fakes and more specifically the very realistic types of deep fake videos where you're using a generative",
    "start": "1527120",
    "end": "1535200"
  },
  {
    "text": "adversarial Network again to generate those deep fake videos and I think the thing that became obvious not just to us",
    "start": "1535200",
    "end": "1543919"
  },
  {
    "text": "in this F but to the public at large you know we had Congressional hearings on it was the fact that you were now entering",
    "start": "1543919",
    "end": "1549799"
  },
  {
    "text": "a moment with this tool which could be used for both wonderful and nefarious purposes uh it's not all bad but you're",
    "start": "1549799",
    "end": "1556799"
  },
  {
    "text": "really blurring the lines of what is real and what is not uh with this capability and there can be fantastic",
    "start": "1556799",
    "end": "1562640"
  },
  {
    "text": "wonderful things you you go to an amusement park uh where they're able to implement deep fake you know in rides",
    "start": "1562640",
    "end": "1568279"
  },
  {
    "text": "and it could be a lot of fun you know where it personalizes the ride ways and you could do some pretty cool stuff or",
    "start": "1568279",
    "end": "1573520"
  },
  {
    "text": "obviously you could have you know things as bad as National Security concerns you know about elections the US elections in",
    "start": "1573520",
    "end": "1580279"
  },
  {
    "text": "2020 where we already have had the American FBI and the intelligence Community warn us about that it is",
    "start": "1580279",
    "end": "1587080"
  },
  {
    "text": "highly likely that we'll have ad necessaries and strategic competitors trying to interfere in the elections and then as I've heard some other people",
    "start": "1587080",
    "end": "1593960"
  },
  {
    "text": "talk about you know what happens you right now as we look at this technology and we have a little bit of time to",
    "start": "1593960",
    "end": "1599600"
  },
  {
    "text": "assess it in in some cases what happens when we get to a situation where there is no time to figure out what is real",
    "start": "1599600",
    "end": "1606039"
  },
  {
    "text": "and what is not if if you had a deep fake that showed the president of the United States describing that he had",
    "start": "1606039",
    "end": "1611440"
  },
  {
    "text": "just launched nuclear weapons you know and you're you're somebody out there who may be the target of that you know and that's not a real video how do you",
    "start": "1611440",
    "end": "1618559"
  },
  {
    "text": "assess in a responsible appropriate but expeditious manner to do that so we're in a a world that has changed in terms",
    "start": "1618559",
    "end": "1626200"
  },
  {
    "text": "of our ability to know what's real and know it in essentially real time any thoughts on that uh yeah I mean I think",
    "start": "1626200",
    "end": "1634200"
  },
  {
    "text": "you're definitely right and along with that we've seen an increase I think in Research into detecting fakes which is",
    "start": "1634200",
    "end": "1642080"
  },
  {
    "text": "encouraging and I I hope that continues and then also I know in a few uh of the",
    "start": "1642080",
    "end": "1648159"
  },
  {
    "text": "episodes after we talked about those sorts of things it's come up that there definitely are good uses of this",
    "start": "1648159",
    "end": "1654000"
  },
  {
    "text": "technology we've talked about you know generating medical imagery of tumors and",
    "start": "1654000",
    "end": "1659559"
  },
  {
    "text": "that sort of thing which is is very expensive to annotate and generate manually but uh you know we can kind of",
    "start": "1659559",
    "end": "1666360"
  },
  {
    "text": "simulate that data and create simulated data using these methods that can improve you know tumor detection",
    "start": "1666360",
    "end": "1673279"
  },
  {
    "text": "algorithms and that sort of thing so with any technology I think there's good",
    "start": "1673279",
    "end": "1678399"
  },
  {
    "text": "and bad sides uh that that you could draw from it I think this one the Deep fake things and the videos that came out",
    "start": "1678399",
    "end": "1685399"
  },
  {
    "text": "emphasize the bad ones first and so it'll be interesting to see as as Gans are uh become more and more practical",
    "start": "1685399",
    "end": "1692559"
  },
  {
    "text": "and integrated into different systems what the positives are and how we deal",
    "start": "1692559",
    "end": "1697880"
  },
  {
    "text": "with those those other negatives yeah there was one website I came across and it used the Deep fakes that were Gan",
    "start": "1697880",
    "end": "1704559"
  },
  {
    "text": "powerered to to animate the Mona Lisa so it took the you know what is the most famous painting in the world and the",
    "start": "1704559",
    "end": "1711799"
  },
  {
    "text": "Mona Lisa was was busy gesturing and talking and stuff like that so it was a cute thing and there's there I think",
    "start": "1711799",
    "end": "1717159"
  },
  {
    "text": "we're going to see many good uses yeah some of the uses are just uh kind of interesting in that sense there's",
    "start": "1717159",
    "end": "1723480"
  },
  {
    "text": "nothing uh I don't know who uses that sort of animated Mona Lisa for any sort",
    "start": "1723480",
    "end": "1728640"
  },
  {
    "text": "of practical purpose but it is still fun and it's pushing the boundaries one thing slight Downer not National",
    "start": "1728640",
    "end": "1735000"
  },
  {
    "text": "Security level Downer but I I think I've heard I've read some stuff that Tel calls you know that you get from",
    "start": "1735000",
    "end": "1740519"
  },
  {
    "text": "marketers and things like that um that that's supposed to be the next big wave is people scraping social media sites to",
    "start": "1740519",
    "end": "1747039"
  },
  {
    "text": "get images of you and people you know and then trying to mimic Voice or whatever on on those so um beware as we",
    "start": "1747039",
    "end": "1753640"
  },
  {
    "text": "go forward over the next year or two that that kind of thing could be at a very personal level it doesn't always have to be these giant end of the world",
    "start": "1753640",
    "end": "1759880"
  },
  {
    "text": "uh scenarios it can be something that is very immediate uh and known to you for sure what about you what are what are",
    "start": "1759880",
    "end": "1765840"
  },
  {
    "text": "some of the things that that you noticed in 20 19 that were awesome I think uh one thing that we definitely have to",
    "start": "1765840",
    "end": "1771880"
  },
  {
    "text": "note is uh tensorflow 2.0 so I think the the final official release of of",
    "start": "1771880",
    "end": "1778080"
  },
  {
    "text": "tensorflow 2.0 was November 9th if I if I searched that right I mean I use",
    "start": "1778080",
    "end": "1783120"
  },
  {
    "text": "Google search so if that's the wrong date then I guess they can blame themselves I was going to say if anyone",
    "start": "1783120",
    "end": "1788200"
  },
  {
    "text": "should know the date it should be them but yeah tensorflow 2.0 so for those that aren't aware uh with the release of",
    "start": "1788200",
    "end": "1795200"
  },
  {
    "text": "tensor flow 2.0 tensor flow made quite a few significant changes especially to",
    "start": "1795200",
    "end": "1801880"
  },
  {
    "text": "the yeah yeah I mean especially to the sort of default API to tensor flow which",
    "start": "1801880",
    "end": "1808120"
  },
  {
    "text": "is now Caris and also to the way in which computations happen instead of",
    "start": "1808120",
    "end": "1814600"
  },
  {
    "text": "always generating this static graph that has to be executed later um and so I think tensorflow 2.0 was just an amazing",
    "start": "1814600",
    "end": "1822799"
  },
  {
    "text": "demonstration that the tensorflow team this is coming I guess uh I should say",
    "start": "1822799",
    "end": "1828039"
  },
  {
    "text": "this is coming from a pie torch guy um i' I've used pie torch way more than I've used tensor flow and I really enjoy",
    "start": "1828039",
    "end": "1834600"
  },
  {
    "text": "pie torch and still really enjoy P torch and use it a lot but for me you know I",
    "start": "1834600",
    "end": "1839799"
  },
  {
    "text": "think it's a great demonstration that the tensor flow team saw that oh we have this really powerful technology but",
    "start": "1839799",
    "end": "1847399"
  },
  {
    "text": "we've gathered feedback that we need to kind of shift some focus in some areas and make it more usable um make it more",
    "start": "1847399",
    "end": "1854480"
  },
  {
    "text": "approachable and make it more practical and so I think the sort of usability and practicality of tensorflow 2.0 is just",
    "start": "1854480",
    "end": "1862000"
  },
  {
    "text": "amazing and I think that they should be given congratulations for for an amazing",
    "start": "1862000",
    "end": "1867120"
  },
  {
    "text": "release um and I can't can't wait to see more yeah as as someone who used both",
    "start": "1867120",
    "end": "1872240"
  },
  {
    "text": "the version one and version two now I much prefer version two and you can use it you can use the Caris interface for",
    "start": "1872240",
    "end": "1878880"
  },
  {
    "text": "the vast majority of use cases that most people are likely to see much more user friendly and it was funny this past year",
    "start": "1878880",
    "end": "1885840"
  },
  {
    "text": "a couple of conferences I tend to to keep my skills up I'll go to tensorflow classes and stuff and I remember it was",
    "start": "1885840",
    "end": "1892360"
  },
  {
    "text": "several months after the tensorflow 2 Beta had come out we weren't to final to be uh full disclosure you know and I so",
    "start": "1892360",
    "end": "1899320"
  },
  {
    "text": "I can understand but I remember going to a class it was tensorflow class the entire class on the beginning of that",
    "start": "1899320",
    "end": "1905279"
  },
  {
    "text": "first day was immensely disappointed that we weren't using the tensorflow 2 Beta in the class instead of tensorflow",
    "start": "1905279",
    "end": "1910600"
  },
  {
    "text": "one I felt sorry for the instructor I'm going to keep all the identities out of it but it made that big of a difference",
    "start": "1910600",
    "end": "1916760"
  },
  {
    "text": "uh in that community and so um kudos to the tensorflow team for listening to user feedback um and turning out a great",
    "start": "1916760",
    "end": "1923840"
  },
  {
    "text": "product that made great strides on the first one yeah I just tried this to see",
    "start": "1923840",
    "end": "1929360"
  },
  {
    "text": "how easy it was to find and I just searched for tensorflow to Cod laab notebooks because that's probably where",
    "start": "1929360",
    "end": "1935240"
  },
  {
    "text": "I would start if I was trying to find something or um you could probably also search tensorflow to quick start because",
    "start": "1935240",
    "end": "1941639"
  },
  {
    "text": "the the first two results are tensorflow 2 quick start for experts tensorflow 2 quick start for beginners and if you go",
    "start": "1941639",
    "end": "1948159"
  },
  {
    "text": "in there it walks you through the code itself but also they have nice collab notebooks that you can open and and try",
    "start": "1948159",
    "end": "1955080"
  },
  {
    "text": "things out without even running anything locally so um it's super easy to get into and would recommend people to to",
    "start": "1955080",
    "end": "1961720"
  },
  {
    "text": "take a look probably the last thing that that I want to mention I mean there was so much in in 2019 I'm sure we're so",
    "start": "1961720",
    "end": "1967840"
  },
  {
    "text": "sorry to all of you out there who are leaving leaving out your favorite thing from 2019 but the other thing that I",
    "start": "1967840",
    "end": "1974519"
  },
  {
    "text": "wanted to mention in 2019 is uh something that I detected throughout the year and that was a sort of um",
    "start": "1974519",
    "end": "1983760"
  },
  {
    "text": "realization which hadn't been there in 2018 that at least the way I felt it this year was that training AI models is",
    "start": "1983760",
    "end": "1992559"
  },
  {
    "text": "uh super compute intensive and this year I felt a little bit of pause from the",
    "start": "1992559",
    "end": "1998600"
  },
  {
    "text": "community in saying hey how much energy are we we expending to train these AI",
    "start": "1998600",
    "end": "2004279"
  },
  {
    "text": "models and what can we do to make that more efficient and more responsible in",
    "start": "2004279",
    "end": "2009679"
  },
  {
    "text": "terms of the environmental impact and all of that so an article was released in 2019 I think which caught a lot of",
    "start": "2009679",
    "end": "2016440"
  },
  {
    "text": "people's attention that you know training a single AI model one of these larger language models for example can",
    "start": "2016440",
    "end": "2024360"
  },
  {
    "text": "admit just training at once a single model can emit as much carbon as five",
    "start": "2024360",
    "end": "2030080"
  },
  {
    "text": "cars during their whole lifetime of use and which is pretty staggering and I personally felt like you know not",
    "start": "2030080",
    "end": "2037799"
  },
  {
    "text": "everybody took this seriously this year in in the community necessarily and it's",
    "start": "2037799",
    "end": "2042880"
  },
  {
    "text": "not like training large models has stopped but I do think there is beginning to be a sense that we need to",
    "start": "2042880",
    "end": "2050679"
  },
  {
    "text": "really pursue technologies that make AI more efficient and and responsible in",
    "start": "2050679",
    "end": "2057240"
  },
  {
    "text": "that sense yeah I remember us talking I don't remember which episode it was but I remember when it came out we talked a little bit about that and I know that",
    "start": "2057240",
    "end": "2064240"
  },
  {
    "text": "both of us are very environmentally focused in terms of being responsible and so I was very happy to see people",
    "start": "2064240",
    "end": "2071240"
  },
  {
    "text": "taking it seriously as well and I heard a lot of conversations through the year about the topic so um I think it's a",
    "start": "2071240",
    "end": "2078878"
  },
  {
    "text": "problem still to be solved I think you know when you have very large scale model training you have to do there are",
    "start": "2078879",
    "end": "2084560"
  },
  {
    "text": "currently not enough we we don't have enough Solutions out there yet in terms of having the compute capability and yet",
    "start": "2084560",
    "end": "2090599"
  },
  {
    "text": "still be able to to be responsible because you know this technology is is here to stay we're going to be Computing",
    "start": "2090599",
    "end": "2096919"
  },
  {
    "text": "more and more and so we need to be thinking about those those responsible Solutions just as we have other aspects",
    "start": "2096919",
    "end": "2102200"
  },
  {
    "text": "of AI that have come to pass that we'll be talking about in a few minutes yeah there's multiple facets to this so I",
    "start": "2102200",
    "end": "2108560"
  },
  {
    "text": "mean there's the side of things which is of course making data centers more efficient and also running those off of",
    "start": "2108560",
    "end": "2114760"
  },
  {
    "text": "sustainable energy sources and I think that's been going on prior to this year",
    "start": "2114760",
    "end": "2120200"
  },
  {
    "text": "and um there's been a good amount of effort put into that um but also I think",
    "start": "2120200",
    "end": "2126160"
  },
  {
    "text": "the the pieces that I've seen develop this year much more emphasis in sort of distilling and optimizing models to make",
    "start": "2126160",
    "end": "2133200"
  },
  {
    "text": "them more efficient make them run faster which is partly driven by just practicality right if you're using a",
    "start": "2133200",
    "end": "2139960"
  },
  {
    "text": "model in production and it's smaller or you're wanting to Port it to a mobile",
    "start": "2139960",
    "end": "2145040"
  },
  {
    "text": "device or something like that it needs to be smaller so some of those things factor in as well but also I I've seen",
    "start": "2145040",
    "end": "2153599"
  },
  {
    "text": "some efforts in sort of envisioning new more efficient architectures for for",
    "start": "2153599",
    "end": "2159200"
  },
  {
    "text": "modeling so not always relying on let's say the next larger Transformer model",
    "start": "2159200",
    "end": "2165720"
  },
  {
    "text": "but are there other architectures maybe just regular rnns that can do this task",
    "start": "2165720",
    "end": "2172599"
  },
  {
    "text": "just as well as using or almost as well as using you know the full large size",
    "start": "2172599",
    "end": "2179160"
  },
  {
    "text": "Bert model and are much smaller and can be trained in in much less time so I",
    "start": "2179160",
    "end": "2185240"
  },
  {
    "text": "think yeah we we need to approach this from very I angles but I think it's it's something that uh people started",
    "start": "2185240",
    "end": "2192160"
  },
  {
    "text": "hopefully taking seriously in in 2019 yeah I think we have the benefit of the fact that it doesn't require only a",
    "start": "2192160",
    "end": "2198520"
  },
  {
    "text": "mindset uh in terms of responsibility toward the environment but also just just sheer performance you know if",
    "start": "2198520",
    "end": "2204119"
  },
  {
    "text": "you're able to find these other approaches that are allowing us to actually get there sooner it's better",
    "start": "2204119",
    "end": "2209599"
  },
  {
    "text": "for all concerned so you know one of the things uh before we turn to what the future looks like is kind of uh let's",
    "start": "2209599",
    "end": "2216880"
  },
  {
    "text": "take a moment and kind of assess where we are right now you know we've just gotten to the end of 2019 uh we're at",
    "start": "2216880",
    "end": "2223599"
  },
  {
    "text": "the beginning of 2020 not only the beginning of a new year but the beginning of a whole new decade and so",
    "start": "2223599",
    "end": "2229720"
  },
  {
    "text": "what are your thoughts toward where we are now as we hit this point any Daniel yeah sure I think one super positive",
    "start": "2229720",
    "end": "2238680"
  },
  {
    "text": "point of where I think we are and will continue to be in 2020 is really an",
    "start": "2238680",
    "end": "2245800"
  },
  {
    "text": "amazing place in terms of the practical side of AI which is what we're concerned about a lot here on the Practical AI",
    "start": "2245800",
    "end": "2252680"
  },
  {
    "text": "podcast and I say that because you have these things like we already talked about like Transformers but other",
    "start": "2252680",
    "end": "2259400"
  },
  {
    "text": "libraries as well and other toolkits or just code on GitHub whatever it is",
    "start": "2259400",
    "end": "2265319"
  },
  {
    "text": "infrastructure pieces tooling I feel like as compared to where we were at the",
    "start": "2265319",
    "end": "2270480"
  },
  {
    "text": "end of 2018 there's just a lot more ways to be sort of robust and build system AI",
    "start": "2270480",
    "end": "2278280"
  },
  {
    "text": "systems with that have a lot of Integrity in a much shorter period of time than we used to be it kind of used",
    "start": "2278280",
    "end": "2285119"
  },
  {
    "text": "to be um very much the wild west and maybe we still are a little bit in the wild west but I think that a lot of the",
    "start": "2285119",
    "end": "2293640"
  },
  {
    "text": "principles from software engineering have kind of come into the AI world and",
    "start": "2293640",
    "end": "2298920"
  },
  {
    "text": "we a lot more focused on versioning things tracking things monitoring things",
    "start": "2298920",
    "end": "2305359"
  },
  {
    "text": "whether that be with tools like tensor board or other things or it's like uh",
    "start": "2305359",
    "end": "2310560"
  },
  {
    "text": "infrastructure pieces like padm and and things like that Cube flow we're just",
    "start": "2310560",
    "end": "2316440"
  },
  {
    "text": "thinking a lot more about the AI systems that we're building rather than just AI",
    "start": "2316440",
    "end": "2321480"
  },
  {
    "text": "models and I think that's really encouraging and it helps people that are actually trying to build products and be",
    "start": "2321480",
    "end": "2328000"
  },
  {
    "text": "practical and inte great AI I think there's so much opportunity there and there's so many choices available in",
    "start": "2328000",
    "end": "2335040"
  },
  {
    "text": "that regard agreed just seeing you called out something a moment ago that that really struck me and that is when",
    "start": "2335040",
    "end": "2341079"
  },
  {
    "text": "we talked about this a year ago now you know going back to that episode so much",
    "start": "2341079",
    "end": "2346920"
  },
  {
    "text": "has changed you know we used to when we first started this podcast we were always searching around for good",
    "start": "2346920",
    "end": "2353040"
  },
  {
    "text": "tutorials and examples and sometimes we would struggle a little bit to find them in just that that amount of time and",
    "start": "2353040",
    "end": "2359280"
  },
  {
    "text": "especially in the last year there's so much available out there the open source tools have really matured great",
    "start": "2359280",
    "end": "2365560"
  },
  {
    "text": "communities uh the tutorials enabling people to do that and and we're finally",
    "start": "2365560",
    "end": "2370720"
  },
  {
    "text": "seeing some of the surrounding infrastructure uh and tooling uh improving I think I think there's still",
    "start": "2370720",
    "end": "2376960"
  },
  {
    "text": "a struggle there as people really try to productize uh what how they get models",
    "start": "2376960",
    "end": "2382160"
  },
  {
    "text": "not only trained but deployed in the rest of their environment but I think that's that's definitely something that's that's working hard now you know",
    "start": "2382160",
    "end": "2389160"
  },
  {
    "text": "uh another thing that I've really noticed um I know at my job at loed",
    "start": "2389160",
    "end": "2394480"
  },
  {
    "text": "Martin I'm very very involved in our own AI ethics and responsibility initiatives",
    "start": "2394480",
    "end": "2399960"
  },
  {
    "text": "and so I spend a lot of time focusing on that and you know over the past year we've seen pretty much all the major",
    "start": "2399960",
    "end": "2406240"
  },
  {
    "text": "players out there whether they be Google or Microsoft or or and many others uh",
    "start": "2406240",
    "end": "2411280"
  },
  {
    "text": "releasing ethical Frameworks uh and and their principles and such and I think",
    "start": "2411280",
    "end": "2417440"
  },
  {
    "text": "it's really gotten called out the the difference between now and and last year at this time where people were starting",
    "start": "2417440",
    "end": "2423720"
  },
  {
    "text": "to talk about uh ethical AI but the the conversation has matured ured a great deal and the recognition that even with",
    "start": "2423720",
    "end": "2431079"
  },
  {
    "text": "some of the limitations of where we are right now in terms of what deep learning can accomplish that the dangers of abuse",
    "start": "2431079",
    "end": "2437880"
  },
  {
    "text": "are very real and we're seeing lots of the significant luminaries in our field kind of calling that out and expressing",
    "start": "2437880",
    "end": "2444599"
  },
  {
    "text": "a need for standardization as we go forward on that so that has been a fairly significant change in the last 12",
    "start": "2444599",
    "end": "2451880"
  },
  {
    "text": "months I think things like for example China's use of of facial recognition",
    "start": "2451880",
    "end": "2457400"
  },
  {
    "text": "which we've talked about on the show before and you know Russia's use of Behavioral modeling and that sort of",
    "start": "2457400",
    "end": "2464280"
  },
  {
    "text": "thing to influence uh for example elections those have hit everybody right",
    "start": "2464280",
    "end": "2469839"
  },
  {
    "text": "and have been just kind of widespread or have been acknowledged in a sort of",
    "start": "2469839",
    "end": "2476720"
  },
  {
    "text": "larger sense that AI isn't sort of something that is really cool and for",
    "start": "2476720",
    "end": "2483280"
  },
  {
    "text": "sci-fi but there's like real uses of it that are going on but not only real uses",
    "start": "2483280",
    "end": "2489520"
  },
  {
    "text": "but potentially really bad uses as well so yeah you know the and I know we've",
    "start": "2489520",
    "end": "2495720"
  },
  {
    "text": "also talked about it in previous episodes but the uh you know as an example of something that it depends on",
    "start": "2495720",
    "end": "2502359"
  },
  {
    "text": "on where you are in the world and your values but I know based on generalized Western values China has their social",
    "start": "2502359",
    "end": "2508359"
  },
  {
    "text": "credit system and as we have been looking at that and talking about that for some time now you know they're using",
    "start": "2508359",
    "end": "2514000"
  },
  {
    "text": "AI to not only surveil but um analyze and monitor their citizens and and",
    "start": "2514000",
    "end": "2520960"
  },
  {
    "text": "either reward or punish them accordingly and so you know that's such a profound effect upon that particular country and",
    "start": "2520960",
    "end": "2527480"
  },
  {
    "text": "the society that it's given us a lot to think about in terms of what do we want if you live in a democracy where you",
    "start": "2527480",
    "end": "2534359"
  },
  {
    "text": "have a say so and how things are implemented and you're one voice of many that can contribute to that voice I",
    "start": "2534359",
    "end": "2540240"
  },
  {
    "text": "certainly hope people are thinking about what is right for you and the community that you live in no matter where you are",
    "start": "2540240",
    "end": "2546319"
  },
  {
    "text": "and where does that make sense and I think so that that has become it's gone from being a fringe conversation to becoming a mainstream conversation in",
    "start": "2546319",
    "end": "2552880"
  },
  {
    "text": "this past year I'd say sure sure so one one thing that uh that I'll bring up in",
    "start": "2552880",
    "end": "2558440"
  },
  {
    "text": "terms of where we currently are in terms of the state of AI going into 2020 is I",
    "start": "2558440",
    "end": "2565920"
  },
  {
    "text": "think that as we move forward uh it's going to be more and more crucial that",
    "start": "2565920",
    "end": "2571640"
  },
  {
    "text": "if we're really serious about using AI to tackle large scale problems s like",
    "start": "2571640",
    "end": "2577839"
  },
  {
    "text": "climate change and the death of languages around the world access to Good Health Care around the world we're",
    "start": "2577839",
    "end": "2584839"
  },
  {
    "text": "going to have to better involve researchers and developers from all over",
    "start": "2584839",
    "end": "2590079"
  },
  {
    "text": "the world so we've had some really encouraging things this past year and and things going into next year around",
    "start": "2590079",
    "end": "2596839"
  },
  {
    "text": "that like uh you know various workshops being held around the world and in Southeast Asia and and uh Africa uh",
    "start": "2596839",
    "end": "2605040"
  },
  {
    "text": "there have been conferences that have been placed in in those areas uh there's",
    "start": "2605040",
    "end": "2610160"
  },
  {
    "text": "like the Deep learning in daa in uh in Africa that's going on and offices of of",
    "start": "2610160",
    "end": "2616200"
  },
  {
    "text": "Google and and others that are opening in those areas but we're definitely not",
    "start": "2616200",
    "end": "2621520"
  },
  {
    "text": "where we need to be for example you know nurs still this year there was a a huge",
    "start": "2621520",
    "end": "2627200"
  },
  {
    "text": "problem with researchers from around the world getting to nurs and having their their visas denied you know if you just",
    "start": "2627200",
    "end": "2633920"
  },
  {
    "text": "look at at publishing it we're still pretty driven by the US by by Europe um",
    "start": "2633920",
    "end": "2639640"
  },
  {
    "text": "in in certain areas and so if there's been one thing that's been clear to me as I've worked more with the NGO I'm a",
    "start": "2639640",
    "end": "2646760"
  },
  {
    "text": "part of and also other NOS is that if we really want to make an impact on these",
    "start": "2646760",
    "end": "2653319"
  },
  {
    "text": "sorts of problems we need to have representation from these local communities you know we can't just take",
    "start": "2653319",
    "end": "2660440"
  },
  {
    "text": "for example if we want to extend translation like Google Translate to all",
    "start": "2660440",
    "end": "2665680"
  },
  {
    "text": "sorts of languages we can't not involve these communities because there's you",
    "start": "2665680",
    "end": "2671760"
  },
  {
    "text": "know we can't just publish research papers that say we're studying low resource languages and we just under",
    "start": "2671760",
    "end": "2678040"
  },
  {
    "text": "sample English as our low resource language because that leaves out so much it leaves out unique scripts problems",
    "start": "2678040",
    "end": "2684680"
  },
  {
    "text": "and unique domain issues and cultural things and so I think there's a lot of Shifting that needs to happen in this",
    "start": "2684680",
    "end": "2691680"
  },
  {
    "text": "area and I and I certainly hope that that that continues to happen as we move into 2020",
    "start": "2691680",
    "end": "2697720"
  },
  {
    "text": "I think that's a really great point that you make there before we move on to predictions the the last thing I wanted",
    "start": "2697720",
    "end": "2703480"
  },
  {
    "text": "to mention just about state of where we are right now is I also think there's a general consensus developing in the",
    "start": "2703480",
    "end": "2709839"
  },
  {
    "text": "industry um we're seeing a lot of of top luminaries I know uh the the VP of AI at",
    "start": "2709839",
    "end": "2715680"
  },
  {
    "text": "Facebook uh recently said that we are very very far from Human intelligence and there were that was in an article I",
    "start": "2715680",
    "end": "2722480"
  },
  {
    "text": "believe that wired uh had and I think there was another article ironically that wired had where there were some",
    "start": "2722480",
    "end": "2728040"
  },
  {
    "text": "comments about the fact that with us hitting kind of uh some limitations on the types of problems that deep learning",
    "start": "2728040",
    "end": "2735359"
  },
  {
    "text": "is likely to be able to solve and given the fact that it is a technique that is very narrow in terms of you get highly",
    "start": "2735359",
    "end": "2742359"
  },
  {
    "text": "specialized results in a narrow scope that one of the things that at at nups that was talked about was the fact that",
    "start": "2742359",
    "end": "2749200"
  },
  {
    "text": "we really need to get to biological Roots uh of natural intelligence to understand what our next steps are going",
    "start": "2749200",
    "end": "2755400"
  },
  {
    "text": "to be uh in the AI space so what I think is that you may end up having people",
    "start": "2755400",
    "end": "2760760"
  },
  {
    "text": "trying to reassess as they enter this New Year about where they want to focus their research on and trying to to do",
    "start": "2760760",
    "end": "2766559"
  },
  {
    "text": "that and I guess um any thoughts on that before we move into predictions no I I think I think it's a great point and I",
    "start": "2766559",
    "end": "2773079"
  },
  {
    "text": "I've definitely seen uh I think we'll put some links into the show notes about various luminaries statements on this",
    "start": "2773079",
    "end": "2780240"
  },
  {
    "text": "sort of stuff I've seen those as well and I think that we can get into pattern that is is kind of of",
    "start": "2780240",
    "end": "2787160"
  },
  {
    "text": "natural but can be limiting in that like for example we we're all about Transformer models and we just do",
    "start": "2787160",
    "end": "2793480"
  },
  {
    "text": "Transformer models over and over and over and it breeds this sort of like NLP",
    "start": "2793480",
    "end": "2799280"
  },
  {
    "text": "is Transformers but actually you know there's a lot of things that have happened historically in AI that we",
    "start": "2799280",
    "end": "2805800"
  },
  {
    "text": "could pull from and there's new things that we could pull from maybe like you say that are rooted in other sorts of uh",
    "start": "2805800",
    "end": "2812960"
  },
  {
    "text": "in other sorts of ideas related to biology or um evolution algorithms or or",
    "start": "2812960",
    "end": "2818200"
  },
  {
    "text": "whatever it is so I think we need to keep uh keep our flexibility intact I",
    "start": "2818200",
    "end": "2824119"
  },
  {
    "text": "think maybe is it is a good way to put it I I would agree and I think the industry at large is would agree with those sentiments based on uh the the",
    "start": "2824119",
    "end": "2831440"
  },
  {
    "text": "sentiment we saw in hers and and that I think has been building over this past year in general let's look ahead to 2020",
    "start": "2831440",
    "end": "2837599"
  },
  {
    "text": "all right inference time inference time now figure out what we think uh what we think might happen I will start us off",
    "start": "2837599",
    "end": "2845119"
  },
  {
    "text": "with a couple of them and uh and then and then turn it over to you I think uh you know as we talked about kind of AI",
    "start": "2845119",
    "end": "2851880"
  },
  {
    "text": "ethics and responsibilities I think we're now at inflection point where we've had many organizations putting out",
    "start": "2851880",
    "end": "2858720"
  },
  {
    "text": "their principles on what they think should be but we don't have a very good way to execute on that so not everybody",
    "start": "2858720",
    "end": "2866040"
  },
  {
    "text": "is going to be an ethicist uh especially in the in the engineering field and so I",
    "start": "2866040",
    "end": "2871319"
  },
  {
    "text": "think that we're seeing a consensus that the next step now is to turn toward the creation of supporting tools or uh",
    "start": "2871319",
    "end": "2879040"
  },
  {
    "text": "retrofitting existing tooling that enables non-thesis to appropriately",
    "start": "2879040",
    "end": "2885400"
  },
  {
    "text": "Implement uh the various aspects of ethical AI everything from eliminating bias from data sets to being able to",
    "start": "2885400",
    "end": "2893000"
  },
  {
    "text": "think about where different types of AI should be applied to different types of solutioning and so I think we're going",
    "start": "2893000",
    "end": "2898839"
  },
  {
    "text": "to see uh I'm predicting that we're going to see a surge over the next year and Beyond in tooling to support ethical",
    "start": "2898839",
    "end": "2905920"
  },
  {
    "text": "AI uh any any comments on that I hope so you hope so yeah I'll be looking for it",
    "start": "2905920",
    "end": "2911680"
  },
  {
    "text": "that sounds good uh I think another thing that I think is um that is happening already at starting to I see a",
    "start": "2911680",
    "end": "2918359"
  },
  {
    "text": "lot of conversation I've been a part of a lot of conversations about this is the fact that we're getting to a point where",
    "start": "2918359",
    "end": "2924240"
  },
  {
    "text": "instead of being a separate you know neural deep learning and neural network development being a separate little shiny object with dedicated people that",
    "start": "2924240",
    "end": "2931079"
  },
  {
    "text": "only do the modeling you get to the problem of how do you implement this in real life and you can build a great",
    "start": "2931079",
    "end": "2936200"
  },
  {
    "text": "model but then people and organizations really struggle to get it deployed into",
    "start": "2936200",
    "end": "2941280"
  },
  {
    "text": "production and getting a kind of a devops uh and feedback loop associated",
    "start": "2941280",
    "end": "2946400"
  },
  {
    "text": "with what they're doing in those activities and so I think you're going to see a lot of effort into moving uh",
    "start": "2946400",
    "end": "2952240"
  },
  {
    "text": "neural network development into existing software development life cycle and workflows that organizations already",
    "start": "2952240",
    "end": "2958680"
  },
  {
    "text": "have in place and that they'll make adjustments to those workflows to accommodate these new technologies uh",
    "start": "2958680",
    "end": "2964640"
  },
  {
    "text": "and I think that's really important for them to see a good return on investment about about for their efforts in this",
    "start": "2964640",
    "end": "2970880"
  },
  {
    "text": "space yeah I'm thinking of we've talked about that a little bit maybe uh Joel Joel Gru's uh episode on um on",
    "start": "2970880",
    "end": "2978480"
  },
  {
    "text": "responsible uh AI development practices uh would would come into play here I'll link that in the show notes sounds good",
    "start": "2978480",
    "end": "2985040"
  },
  {
    "text": "um another thing I'm seeing and we actually already talked a little bit about it you know I think uh tensor flow 2 uh is an example of this is we're",
    "start": "2985040",
    "end": "2992160"
  },
  {
    "text": "seeing uh I think we're going to continue to see simplification uh of neural network tooling and trying to",
    "start": "2992160",
    "end": "2998680"
  },
  {
    "text": "make that learning curve more manageable and I think you'll you'll see different different users and developers uh within",
    "start": "2998680",
    "end": "3006480"
  },
  {
    "text": "this technology being able to buy into to tool sets that are suitable for them",
    "start": "3006480",
    "end": "3011559"
  },
  {
    "text": "and their own background so I think that you'll see more tooling that is specific to uh you know that that may cater to",
    "start": "3011559",
    "end": "3019119"
  },
  {
    "text": "certain types of data scientists versus certain types of software developers and you'll be able to kind of customize that",
    "start": "3019119",
    "end": "3024760"
  },
  {
    "text": "tooling to match your level of knowledge expertise and and your background as",
    "start": "3024760",
    "end": "3030400"
  },
  {
    "text": "well so that you can be productive quicker and then I guess my final prediction is that I think that kind of",
    "start": "3030400",
    "end": "3037480"
  },
  {
    "text": "given what we talked about this acknowledgment at large that's that's developing within the Deep learning",
    "start": "3037480",
    "end": "3043640"
  },
  {
    "text": "field that it's not well suited for certain problems that it is taking a lot more data to learn than maybe a a human",
    "start": "3043640",
    "end": "3051520"
  },
  {
    "text": "might use to learn something and is less flexible in stuff and and overly focused on a particular particular solution and",
    "start": "3051520",
    "end": "3057599"
  },
  {
    "text": "not able to move like by way of example from one game that you might have a deep",
    "start": "3057599",
    "end": "3063040"
  },
  {
    "text": "learning algorithm that has learned uh be able to move to another game and be able to to Leverage What it learned from",
    "start": "3063040",
    "end": "3069040"
  },
  {
    "text": "the first one so we've seen many examples of that and I think is is that",
    "start": "3069040",
    "end": "3074359"
  },
  {
    "text": "message really permeates through the field that we will see people reassessing and maybe and this is really",
    "start": "3074359",
    "end": "3080880"
  },
  {
    "text": "the first time I have said this ever uh in our podcast we will start looking at",
    "start": "3080880",
    "end": "3086319"
  },
  {
    "text": "a die in the future as moving into a post de learning world I tend to when",
    "start": "3086319",
    "end": "3092720"
  },
  {
    "text": "I'm talking about the present I tend to to tell people I think of AI personally",
    "start": "3092720",
    "end": "3097799"
  },
  {
    "text": "as equivalent to deep learning right now as we are at the beginning of 2020 but I think we also we may get to the end of",
    "start": "3097799",
    "end": "3104400"
  },
  {
    "text": "this year and and that may not be a true statement uh anymore and I may I may have a different answer so I I think",
    "start": "3104400",
    "end": "3109640"
  },
  {
    "text": "that is uh where we're going what what about you Daniel what are some of yours well I I decided to go the uh safe rout",
    "start": "3109640",
    "end": "3117280"
  },
  {
    "text": "and I'm going to say that uh I'm going to my my prediction is that uh at least",
    "start": "3117280",
    "end": "3124599"
  },
  {
    "text": "one of the following three things are going to uh be a a huge a huge player",
    "start": "3124599",
    "end": "3132079"
  },
  {
    "text": "and a huge emphasis in 2020 and we'll really pick up steam and maybe all of",
    "start": "3132079",
    "end": "3137920"
  },
  {
    "text": "them or maybe just two of them or one of them I'm I'm not sure um so I'm kind of covering my bases there that way um you",
    "start": "3137920",
    "end": "3144839"
  },
  {
    "text": "know my test scores are better when we look at things after uh time but um uh",
    "start": "3144839",
    "end": "3150640"
  },
  {
    "text": "the three things that that I was thinking of were First multimodal Learning then mobile AI or AI on mobile",
    "start": "3150640",
    "end": "3158920"
  },
  {
    "text": "devices and then Federated learning so multimodal learning is where for example",
    "start": "3158920",
    "end": "3165480"
  },
  {
    "text": "you you make inferences off of uh multiple modalities of of input data",
    "start": "3165480",
    "end": "3170839"
  },
  {
    "text": "maybe you have an image and text that are input to a model and then you you",
    "start": "3170839",
    "end": "3176079"
  },
  {
    "text": "make inference this was I I think already emphasized recently by our guest from Etsy in their sort of search",
    "start": "3176079",
    "end": "3184119"
  },
  {
    "text": "technology where they have titles for their products and descriptions but there's also more information in the",
    "start": "3184119",
    "end": "3191000"
  },
  {
    "text": "uploaded pictures of the products right and so you could take both of those",
    "start": "3191000",
    "end": "3196960"
  },
  {
    "text": "input signals and do much more than you could with just the text or just the",
    "start": "3196960",
    "end": "3202480"
  },
  {
    "text": "imagery alone right and I think that this is going to be really revolutionary",
    "start": "3202480",
    "end": "3207760"
  },
  {
    "text": "and pick up steam in terms of a lot of things whether it be chat Bots or",
    "start": "3207760",
    "end": "3212880"
  },
  {
    "text": "recommendation like in that in that Etsy case or or whatever it is I think we're going to see a lot more of that in fact",
    "start": "3212880",
    "end": "3218799"
  },
  {
    "text": "we saw that also with open AIS a robot hand Rubik's Cube thing where they were",
    "start": "3218799",
    "end": "3224040"
  },
  {
    "text": "taking signals off of the hand itself but also using uh the imagery from",
    "start": "3224040",
    "end": "3229559"
  },
  {
    "text": "cameras and and uh all of that I I think you're right I I know that uh at my own company multimodal learning is is a a",
    "start": "3229559",
    "end": "3236599"
  },
  {
    "text": "big deal um one kind of globally impacting use case uh that we're seeing",
    "start": "3236599",
    "end": "3241960"
  },
  {
    "text": "it is in humanitarian assistance and disaster relief and that is where you",
    "start": "3241960",
    "end": "3247359"
  },
  {
    "text": "have so you know as you're trying to get data sets for a a particular uh disaster",
    "start": "3247359",
    "end": "3252640"
  },
  {
    "text": "scenario maybe a wildfire if you can get data from lots of different uh imagery",
    "start": "3252640",
    "end": "3258960"
  },
  {
    "text": "the various types of radio calls that are occurring and all that then then you can create a model that is much more",
    "start": "3258960",
    "end": "3264799"
  },
  {
    "text": "robust and accurate uh and able to accommodate many more scenarios so I I I",
    "start": "3264799",
    "end": "3270200"
  },
  {
    "text": "totally think you're right on that on multimodal learning I think that is going to be huge going forward that was a good call good well hopefully at least",
    "start": "3270200",
    "end": "3276240"
  },
  {
    "text": "at least that one comes true I have faith in you man all right cool the other ones uh I think are uh",
    "start": "3276240",
    "end": "3284280"
  },
  {
    "text": "really driven out of my sense that the privacy of course is has been important",
    "start": "3284280",
    "end": "3289480"
  },
  {
    "text": "but is increasingly important and just the you know the scale of AI is",
    "start": "3289480",
    "end": "3294599"
  },
  {
    "text": "extending to all parts of the globe and so I think we're seeing a lot I think we",
    "start": "3294599",
    "end": "3300200"
  },
  {
    "text": "will see in 2020 a lot of deployments to mobile devices and a lot more tooling",
    "start": "3300200",
    "end": "3307440"
  },
  {
    "text": "around that um maybe along with deployment to things like browsers and that sort of thing where we're running",
    "start": "3307440",
    "end": "3313839"
  },
  {
    "text": "running uh models on user devices and fine-tuning them on user devices along",
    "start": "3313839",
    "end": "3319799"
  },
  {
    "text": "with that kind of goes Federated learning I think which is the the idea that we're not really centralizing data",
    "start": "3319799",
    "end": "3327799"
  },
  {
    "text": "from all sorts of users and then running a centralized training and then porting",
    "start": "3327799",
    "end": "3333000"
  },
  {
    "text": "the model back but there is this sort of Federated distributed training that's",
    "start": "3333000",
    "end": "3338720"
  },
  {
    "text": "happening where a lot of the data from user devices doesn't have to leave user devices and so there's advantages to",
    "start": "3338720",
    "end": "3345839"
  },
  {
    "text": "that of course because um because of privacy but also data transfer and and",
    "start": "3345839",
    "end": "3351440"
  },
  {
    "text": "all of that I've seen this talked about over the the last years but haven't really seen it you know really come come",
    "start": "3351440",
    "end": "3359000"
  },
  {
    "text": "about in a widespread way and um you know possibly this is this is the year I",
    "start": "3359000",
    "end": "3364920"
  },
  {
    "text": "I don't know I think you're right I think that's I think that's a you you have stuck with safe they're very good",
    "start": "3364920",
    "end": "3370039"
  },
  {
    "text": "bets but I think they're they're bet on all three of those actually so um yeah I",
    "start": "3370039",
    "end": "3375359"
  },
  {
    "text": "think you nailed it well I I probably then have to learn a little bit of uh I don't I don't know I need to learn a",
    "start": "3375359",
    "end": "3381319"
  },
  {
    "text": "little bit of mobile development or something maybe uh maybe we'll have have an episode where we have some learning",
    "start": "3381319",
    "end": "3387599"
  },
  {
    "text": "uh learning resources on that but um yeah I I've enjoyed this look back and",
    "start": "3387599",
    "end": "3392920"
  },
  {
    "text": "look ahead Chris um it'll be interesting to look back at this episode at the end",
    "start": "3392920",
    "end": "3398960"
  },
  {
    "text": "of 2020 and see um you know see what what uh what came true and what didn't",
    "start": "3398960",
    "end": "3405240"
  },
  {
    "text": "yeah so much has changed in the past year um as we've as we've called out and I suspect we'll have even more so this",
    "start": "3405240",
    "end": "3411400"
  },
  {
    "text": "coming year so uh it was a good conversation happy New Year again and looking forward to uh to seeing you in",
    "start": "3411400",
    "end": "3418640"
  },
  {
    "text": "Chattanooga uh at project voice and uh and doing all sorts of cool stuff in the year ahead awesome happy New",
    "start": "3418640",
    "end": "3427038"
  },
  {
    "text": "Year all right thank you for tuning in to this episode of practical AI if you enjoyed the show do us a favor go on",
    "start": "3427119",
    "end": "3433119"
  },
  {
    "text": "iTunes and give us a rating go in your podcast app and favored it if you are on Twitter or social network share a link",
    "start": "3433119",
    "end": "3438720"
  },
  {
    "text": "with a friend whatever you got to do share the show with a friend if you enjoyed it and band with for change log is provided by fastly learn more at",
    "start": "3438720",
    "end": "3445280"
  },
  {
    "text": "fastly.com and we catch our erors before our users do here at changelog because of robar check them out at roar.com",
    "start": "3445280",
    "end": "3451559"
  },
  {
    "text": "changelog and we're hosted on lenoe cloud servers head to l.com changelog",
    "start": "3451559",
    "end": "3457000"
  },
  {
    "text": "check them out support this show this episode is hosted by Daniel whack and Chris Benson the music is by breakmaster",
    "start": "3457000",
    "end": "3464119"
  },
  {
    "text": "cylinder and you can find more shows just like this at changel law.com when you go there pop in your email address",
    "start": "3464119",
    "end": "3470680"
  },
  {
    "text": "get our weekly email keeping you up to date with the news and podcast for developers in your inbox every single",
    "start": "3470680",
    "end": "3476520"
  },
  {
    "text": "week thanks for tuning in we'll see you next [Music]",
    "start": "3476520",
    "end": "3484039"
  },
  {
    "text": "week",
    "start": "3484039",
    "end": "3487039"
  }
]
[
  {
    "text": "I don't think deep learning evolves into AGI so AGI artificial general intelligence is not going to be reached",
    "start": "160",
    "end": "7080"
  },
  {
    "text": "by just having bigger deep learning networks and more data AGI and human intelligence require fundamental",
    "start": "7080",
    "end": "14519"
  },
  {
    "text": "capabilities that are just not present in deep learning technology as we currently understand it deep Learning",
    "start": "14519",
    "end": "19720"
  },
  {
    "text": "Systems don't know anything they can't reason they can't accumulate knowledge",
    "start": "19720",
    "end": "24880"
  },
  {
    "text": "they can't apply what they learned in one context to solve problems in another context etc etc right and these are just",
    "start": "24880",
    "end": "30960"
  },
  {
    "text": "Elementary things that humans do all the time band with for change log is",
    "start": "30960",
    "end": "37200"
  },
  {
    "text": "provided by fastly learn more at fastly.com we move fast and fix things",
    "start": "37200",
    "end": "42320"
  },
  {
    "text": "here at change law because of rollbar check them out at rar.com and we're hosted on linode cloud servers head to",
    "start": "42320",
    "end": "48640"
  },
  {
    "text": "lin.com changelog this episode is brought to you",
    "start": "48640",
    "end": "54879"
  },
  {
    "text": "by digital ocean digital Ocean's developer cloud makes it simple to launch in the cloud and SC up as you",
    "start": "54879",
    "end": "60600"
  },
  {
    "text": "grow they have an intuitive control panel predictable pricing team accounts worldwide availability with a 99.99",
    "start": "60600",
    "end": "67680"
  },
  {
    "text": "uptime SLA and 24/7 365 worldclass support to back that up digital ocean",
    "start": "67680",
    "end": "73439"
  },
  {
    "text": "makes it easy to deploy scale store secure and monitor your Cloud environments head to do. change law to",
    "start": "73439",
    "end": "80560"
  },
  {
    "text": "get started with a $100 credit again do. Cheese",
    "start": "80560",
    "end": "86400"
  },
  {
    "text": "Log [Music]",
    "start": "88920",
    "end": "94029"
  },
  {
    "text": "welcome to practical AI a weekly podcast that makes artificial intelligence practical productive and accessible to",
    "start": "95000",
    "end": "101479"
  },
  {
    "text": "everyone this is where conversations around AI machine learning and data science happen join the community and",
    "start": "101479",
    "end": "107479"
  },
  {
    "text": "slack with us around various topics of the show at change.com community and follow us on Twitter we at practical a",
    "start": "107479",
    "end": "114000"
  },
  {
    "text": "FM okay take it away Chris",
    "start": "114000",
    "end": "121280"
  },
  {
    "text": "welcome to another episode of the Practical AI podcast my name is Chris Benson I'm a principal AI strategist at",
    "start": "121280",
    "end": "127640"
  },
  {
    "text": "loed Martin normally listeners would know that Daniel whack my co-host would be with me he is unavailable today he's",
    "start": "127640",
    "end": "133720"
  },
  {
    "text": "out sick and so uh I have the pleasure of introducing Our Guest today who is uh",
    "start": "133720",
    "end": "140280"
  },
  {
    "text": "a legend in the AI field this with me today is Stuart Russell who is a",
    "start": "140280",
    "end": "146200"
  },
  {
    "text": "professor of computer science at University of California Berkeley and holder of the Smith is it Z chair if I'm",
    "start": "146200",
    "end": "154080"
  },
  {
    "text": "getting that correct Smith Zade Zade I apologize and also if the name sounds",
    "start": "154080",
    "end": "159519"
  },
  {
    "text": "familiar uh he is the author of The Standard book on artificial intelligence which most practitioners in the field",
    "start": "159519",
    "end": "165200"
  },
  {
    "text": "will be familiar with as well as uh a recent book for a general audience which",
    "start": "165200",
    "end": "170280"
  },
  {
    "text": "is called human compatible artificial intelligence and the problem of control steuart thank you very much for coming",
    "start": "170280",
    "end": "176920"
  },
  {
    "text": "on the show thank you I know I barely touched on it I know you have been in this field for decades if you could tell",
    "start": "176920",
    "end": "183040"
  },
  {
    "text": "us just a little bit more about your background before we get fully launching yes as you say it's been quite a long",
    "start": "183040",
    "end": "188840"
  },
  {
    "text": "time uh I first started doing AI when I was in high school because I I got a programmable calculator uh and I thought",
    "start": "188840",
    "end": "196319"
  },
  {
    "text": "I could make it really intelligent but it it turned out that it only allowed 36 keystrokes in the program so I didn't",
    "start": "196319",
    "end": "202840"
  },
  {
    "text": "get very far with that uh with that attempt but um and then I got to use uh",
    "start": "202840",
    "end": "208400"
  },
  {
    "text": "a giant computer at Imperial College so I wrote a chess program that was my first serious AI program I did my PhD at",
    "start": "208400",
    "end": "215319"
  },
  {
    "text": "Stanford I joined Berkeley in 86 so it's 34 years uh teaching in Berkeley and",
    "start": "215319",
    "end": "222000"
  },
  {
    "text": "it's been a pretty interesting time and it's you know most people would say now is maybe the most exciting time to be",
    "start": "222000",
    "end": "228720"
  },
  {
    "text": "doing AI because there's so much progress we've been able to solve or nearly solve some of the major open",
    "start": "228720",
    "end": "235480"
  },
  {
    "text": "problems of the field you know speech recognition machine translation certain part of computer Visions so particularly",
    "start": "235480",
    "end": "241200"
  },
  {
    "text": "recognizing objects and images all of those things now work pretty well so then then we can roll out all those",
    "start": "241200",
    "end": "247640"
  },
  {
    "text": "techniques into the real world and do cool things like driving cars and everything like that so it's lots of fun",
    "start": "247640",
    "end": "253000"
  },
  {
    "text": "and we're all very busy so I guess you know given that you have seen so much of the evolution of this field uh over time",
    "start": "253000",
    "end": "259880"
  },
  {
    "text": "could you talk a little bit about what the field was like when you came into it and what technologies were were",
    "start": "259880",
    "end": "266520"
  },
  {
    "text": "prevalent uh and tell us a bit about the evolution of the field over the years all the way into the current you know",
    "start": "266520",
    "end": "273160"
  },
  {
    "text": "what's certainly taken off these last few years sure yeah so in the early years so I guess I would say I started",
    "start": "273160",
    "end": "279520"
  },
  {
    "text": "probably 1975 the focus was almost exclusively on",
    "start": "279520",
    "end": "285759"
  },
  {
    "text": "problem solving game playing planning uh logical reasoning so everything was",
    "start": "285759",
    "end": "292720"
  },
  {
    "text": "deterministic so we assumed that we could give the computer perfect knowledge of the problem a perfectly",
    "start": "292720",
    "end": "298680"
  },
  {
    "text": "stated goal and it would come up with a guaranteed solution whether it was proving a theorem or you know finding a",
    "start": "298680",
    "end": "304880"
  },
  {
    "text": "Checkmate or thought you know coming up with a a plan to deliver a bunch of pels",
    "start": "304880",
    "end": "310280"
  },
  {
    "text": "to a bunch of recipients or whatever it might be and in the 80s we had the big",
    "start": "310280",
    "end": "315320"
  },
  {
    "text": "expert system boom so initially a logical rule based system so encoding",
    "start": "315320",
    "end": "321280"
  },
  {
    "text": "expertise in logical rules sometimes we now call it business rules or business intelligence that's a that's a phrase",
    "start": "321280",
    "end": "328039"
  },
  {
    "text": "that they use because the term expert system fell out of favor but in the 80s that was a really you know a big",
    "start": "328039",
    "end": "334840"
  },
  {
    "text": "exciting you know hype bubble just like today sure and the beginnings of",
    "start": "334840",
    "end": "340280"
  },
  {
    "text": "handling uncertainty because we wanted to to make expert systems that did things like medical diagnosis where",
    "start": "340280",
    "end": "346960"
  },
  {
    "text": "there are no hard and fast rules you you have to take the evidence and combine it in you know to get some kind of soft",
    "start": "346960",
    "end": "353360"
  },
  {
    "text": "prediction you might say but that technology largely failed in the real",
    "start": "353360",
    "end": "358919"
  },
  {
    "text": "world and complicated reasons for it but I think basically it was not doing uncertain reasoning correctly and so as",
    "start": "358919",
    "end": "366520"
  },
  {
    "text": "you tried to build bigger systems for real problems the whole thing would kind of fall apart every time you add a new",
    "start": "366520",
    "end": "372280"
  },
  {
    "text": "rule the other ones would start messing things up and you know the interactions would cause wrong answers to come out",
    "start": "372280",
    "end": "378960"
  },
  {
    "text": "and companies very quickly stopped investing in this and we had what we call the AI winter where you know I",
    "start": "378960",
    "end": "386440"
  },
  {
    "text": "think my AI course was down to about 25 students in 1990 it's up at about 900",
    "start": "386440",
    "end": "393520"
  },
  {
    "text": "right now I imagine it is and that's only because we're not you know the fire marshal won't let us have any more",
    "start": "393520",
    "end": "399720"
  },
  {
    "text": "people in the class uh would probably be you know 12500 if if let everyone in so",
    "start": "399720",
    "end": "406000"
  },
  {
    "text": "what happened next in AI actually was that rigorous parabis methods took over",
    "start": "406000",
    "end": "411840"
  },
  {
    "text": "within the field mainly from the work of of Udo Pearl starting in the mid 80s and",
    "start": "411840",
    "end": "417120"
  },
  {
    "text": "then machine learning had a Renaissance reinforcement learning had a Renaissance",
    "start": "417120",
    "end": "423280"
  },
  {
    "text": "and so from the late 80s until around 20 11 or so there was pretty solid",
    "start": "423280",
    "end": "432160"
  },
  {
    "text": "technical research progress using probability statistics connections to",
    "start": "432160",
    "end": "439080"
  },
  {
    "text": "operations research control theory became a very mathematical field some of the techniques worked pretty well you",
    "start": "439080",
    "end": "446039"
  },
  {
    "text": "know so speech recognition became reasonably practical and the first self-driving cars were",
    "start": "446039",
    "end": "452879"
  },
  {
    "text": "operating long before the present day and doing so reasonably successfully you",
    "start": "452879",
    "end": "458280"
  },
  {
    "text": "know there were big applications of planning there were uh lots of diagnostic systems and so on so it was",
    "start": "458280",
    "end": "464400"
  },
  {
    "text": "was relatively successful but it wasn't really until deep learning happened around 2011 2012 that it really hit the",
    "start": "464400",
    "end": "472919"
  },
  {
    "text": "big time in terms of media coverage and excitement uh and so on so it was deep",
    "start": "472919",
    "end": "478680"
  },
  {
    "text": "learning that enabled us to for example beat the human world champion at go uh combination of",
    "start": "478680",
    "end": "486360"
  },
  {
    "text": "deep learning with with reinforcement learning methods and game playing techniques that had been around for",
    "start": "486360",
    "end": "492319"
  },
  {
    "text": "decades and decades but deep learning was this extra ingredient that let the",
    "start": "492319",
    "end": "497680"
  },
  {
    "text": "system somehow recognize patn on the go board that allowed it to beat the human world champion so so now we're in a",
    "start": "497680",
    "end": "504280"
  },
  {
    "text": "position where uh you know as I mentioned thousands of students want to take AI courses there are thousands of",
    "start": "504280",
    "end": "510840"
  },
  {
    "text": "startup companies all the big companies uh have major AI divisions and",
    "start": "510840",
    "end": "516880"
  },
  {
    "text": "are using AI in hundreds of applications throughout their businesses so it's fun",
    "start": "516880",
    "end": "522279"
  },
  {
    "text": "it's exciting it maybe there's some hype going on too there might be a little bit so going through that it really begs the",
    "start": "522279",
    "end": "530120"
  },
  {
    "text": "question for me and I'm going to throw the question at you I I imagine we'll be like uh but you're looking at all these",
    "start": "530120",
    "end": "536360"
  },
  {
    "text": "different types of artificial intelligence different things that are being labeled as artificial intelligence",
    "start": "536360",
    "end": "542720"
  },
  {
    "text": "you know from the the symbolic logic days through expert systems all the way up through today's deep learning and",
    "start": "542720",
    "end": "549279"
  },
  {
    "text": "other Associated Technologies and there are obviously vastly different uh underpinnings in terms of what they can",
    "start": "549279",
    "end": "555200"
  },
  {
    "text": "do and how you arrive at them how do you define artificial intelligence what does the term mean to you as the person who",
    "start": "555200",
    "end": "562600"
  },
  {
    "text": "is literally written the textbook on the subject um and how has that changed and evolved over those years so that's a",
    "start": "562600",
    "end": "568800"
  },
  {
    "text": "good question I mean all of the above all the things you mentioned this is all artificial intelligence because it's all",
    "start": "568800",
    "end": "576040"
  },
  {
    "text": "in the service of creating machines that can act intelligently which means really",
    "start": "576040",
    "end": "583240"
  },
  {
    "text": "choosing actions that can be expected to achieve their objectives you know if you're a self-driving car the objective",
    "start": "583240",
    "end": "588880"
  },
  {
    "text": "is to get to the the airport safely legally comfortably and uh so in order",
    "start": "588880",
    "end": "595600"
  },
  {
    "text": "to do that you need perception but you also need symbolic planning to choose a route uh you need probabalistic",
    "start": "595600",
    "end": "602640"
  },
  {
    "text": "forecasting to deal with traffic delays and maybe have a backup route just in",
    "start": "602640",
    "end": "608040"
  },
  {
    "text": "case and you need speech recognition in order to interface with the passenger etc etc so you know if you want to build",
    "start": "608040",
    "end": "614600"
  },
  {
    "text": "a system that's going to help a mathematician you can't just throw a bunch of theorems and proofs into a deep",
    "start": "614600",
    "end": "620399"
  },
  {
    "text": "Learning System and say here you know learn how to do math uh you actually have to have symbolic reasoning capability theorem proven you know which",
    "start": "620399",
    "end": "628360"
  },
  {
    "text": "the underlying technology that is symbolic logic and not statistical learning so it all depends what you want",
    "start": "628360",
    "end": "635120"
  },
  {
    "text": "to do the overriding model which I think pervades not just AI but a lot of other",
    "start": "635120",
    "end": "641720"
  },
  {
    "text": "disciplines um control theory operations research economic statistics they all",
    "start": "641720",
    "end": "648480"
  },
  {
    "text": "have this model which is that we we specify an objective and then the machine finds some optimal solution or a",
    "start": "648480",
    "end": "657040"
  },
  {
    "text": "way of achieving the objective the best solution and so actually what the book is about the human compatible book is",
    "start": "657040",
    "end": "664079"
  },
  {
    "text": "basically saying that model is really a terrible model now unfortunately the first three",
    "start": "664079",
    "end": "671560"
  },
  {
    "text": "editions of my textbook actually kind of solidified that model and said okay here's how we",
    "start": "671560",
    "end": "678839"
  },
  {
    "text": "understand you know here's how we pull everything in AI together into a single conceptual framework and you can see all",
    "start": "678839",
    "end": "684800"
  },
  {
    "text": "of the different kinds of AI researches so different facets different ways of looking at that same underlying",
    "start": "684800",
    "end": "690760"
  },
  {
    "text": "conceptual framework and the reason I think it's a terrible model is not a new",
    "start": "690760",
    "end": "697360"
  },
  {
    "text": "thing right it's uh something we've known for thousands of years which is we",
    "start": "697360",
    "end": "702800"
  },
  {
    "text": "cannot specify our objectives completely incorrectly and you know if you look at the legend of King Midas he specifies",
    "start": "702800",
    "end": "709760"
  },
  {
    "text": "his objective I want everything I touch to turn to Gold you know the gods or you could say the AI system gives him the",
    "start": "709760",
    "end": "715760"
  },
  {
    "text": "objective uh exactly as he specifies and then of course his food and his drink and his family all turn to gold and he",
    "start": "715760",
    "end": "721800"
  },
  {
    "text": "dies misery starvation unexpected consequences right",
    "start": "721800",
    "end": "727519"
  },
  {
    "text": "you know that's the thing right it's always unanticipated consequences accidental side effects collateral",
    "start": "727519",
    "end": "733959"
  },
  {
    "text": "damage externalities is what the economists call it but it's a pervasive",
    "start": "733959",
    "end": "739120"
  },
  {
    "text": "problem we've known about it for a long time um you know that's why your third wish is always please undo the first two",
    "start": "739120",
    "end": "745519"
  },
  {
    "text": "wishes because I've ruined everything right so the human comptible book basically says okay we have to throw",
    "start": "745519",
    "end": "752760"
  },
  {
    "text": "away that model because you know up to now it hasn't been that bad because you know first of all most of our AI systems",
    "start": "752760",
    "end": "760120"
  },
  {
    "text": "were toys they were in the lab you know we were doing demos it wasn't out there in Industry at the level it's at now",
    "start": "760120",
    "end": "767040"
  },
  {
    "text": "until recently uh on a global scale but now it is right so now you know you've",
    "start": "767040",
    "end": "772440"
  },
  {
    "text": "got the content selection algorithms from all the different social media platforms and those algorithms are",
    "start": "772440",
    "end": "779680"
  },
  {
    "text": "their machine learning algorithms but they decide what billions of people",
    "start": "779680",
    "end": "785000"
  },
  {
    "text": "spend hours every day reading and watching right so in terms of their",
    "start": "785000",
    "end": "792160"
  },
  {
    "text": "actual Direct in terms of like you take the number of people times the amount of time they are more powerful than",
    "start": "792160",
    "end": "798560"
  },
  {
    "text": "anything that's ever existed in the history of the human race by",
    "start": "798560",
    "end": "803720"
  },
  {
    "text": "far by far right I mean you know you think Stalin was powerful but he got to",
    "start": "803720",
    "end": "808760"
  },
  {
    "text": "speak to to his people like you know maybe half an hour every month or something right yes these algorithms are",
    "start": "808760",
    "end": "814920"
  },
  {
    "text": "speaking to 50 times more people for hours every day a largely oblivious",
    "start": "814920",
    "end": "821519"
  },
  {
    "text": "audience for the most part that's acting on them yeah so the audience doesn't know what the algorithms are doing or",
    "start": "821519",
    "end": "826639"
  },
  {
    "text": "what they're trying to do the algorithms are trying to maximize their objective which is clickthrough or engagement or",
    "start": "826639",
    "end": "833079"
  },
  {
    "text": "something like that and in the course of doing that rather than just send you",
    "start": "833079",
    "end": "838399"
  },
  {
    "text": "what's interesting they actually modify you into someone who's more predictable",
    "start": "838399",
    "end": "844519"
  },
  {
    "text": "from their point of view because the more predictable you are the more money they can make off you and so whatever",
    "start": "844519",
    "end": "851360"
  },
  {
    "text": "you start out as they change you and mold you into a predictable clicker and",
    "start": "851360",
    "end": "856959"
  },
  {
    "text": "so that's what they've done and and I think you know most people would say that the results have been pretty",
    "start": "856959",
    "end": "862399"
  },
  {
    "text": "disastrous on the whole so I want to ask you there's a particular remark you make in the book that I want to ask you and I",
    "start": "862399",
    "end": "868240"
  },
  {
    "text": "think you're already kind of going down uh the path on this to some degree but you say uh we must plan for the",
    "start": "868240",
    "end": "875120"
  },
  {
    "text": "possibility that machines will far exceed the human capacity for decision-making in the real world and I",
    "start": "875120",
    "end": "881360"
  },
  {
    "text": "think that You' started to address some of the challenges could you give us a little bit more of a holistic perspective on what I mean that",
    "start": "881360",
    "end": "888160"
  },
  {
    "text": "statement has a lot in it right there can you talk a little bit about what the implications of that is so yeah Ian so",
    "start": "888160",
    "end": "895800"
  },
  {
    "text": "let's give an example right suppose that a few years or decades down the line",
    "start": "895800",
    "end": "901199"
  },
  {
    "text": "you're you know the CEO of an IT company or your solar power company or whatever",
    "start": "901199",
    "end": "906880"
  },
  {
    "text": "it might be and you want your company to be more successful so you you engage an",
    "start": "906880",
    "end": "912360"
  },
  {
    "text": "AI system and you give it the objective of let's say you know maximizing the",
    "start": "912360",
    "end": "917560"
  },
  {
    "text": "profits or the revenues of my Corporation and because that system is far more capable than humans are right",
    "start": "917560",
    "end": "925279"
  },
  {
    "text": "it devises plans that are more successful ful than the all the",
    "start": "925279",
    "end": "931440"
  },
  {
    "text": "competitors can be and so that coroporation in the interests of",
    "start": "931440",
    "end": "937000"
  },
  {
    "text": "maximizing revenues gradually takes over larger and larger portions of the world",
    "start": "937000",
    "end": "942440"
  },
  {
    "text": "economy you know and if it's not properly designed right if that was the",
    "start": "942440",
    "end": "947519"
  },
  {
    "text": "objective you know wherever it was feasible it might end up uh using slave",
    "start": "947519",
    "end": "952759"
  },
  {
    "text": "labor for example in order to maximize profits and so on and so forth right I mean you can imagine all the ways that",
    "start": "952759",
    "end": "959399"
  },
  {
    "text": "corporations have abused Humanity in the past and now we've got one that's much",
    "start": "959399",
    "end": "964600"
  },
  {
    "text": "more capable uh than human beings are you know some people actually argue that this is already happening um not from AI",
    "start": "964600",
    "end": "971920"
  },
  {
    "text": "but from corporations that optimize profit at the",
    "start": "971920",
    "end": "977480"
  },
  {
    "text": "expense of everything else so for example at the expense of the climate the fossil fuel industry has optimized",
    "start": "977480",
    "end": "984839"
  },
  {
    "text": "its profits by sort of multi-decade misinformation strategy that's actually",
    "start": "984839",
    "end": "991240"
  },
  {
    "text": "outwitted the human race right and so even though the vast",
    "start": "991240",
    "end": "996360"
  },
  {
    "text": "majority of experts and economists and scientists say oh you know we need to have a carbon tax we need to do this we",
    "start": "996360",
    "end": "1002600"
  },
  {
    "text": "need to do that we aren't doing any of it right we're just talking about it uh",
    "start": "1002600",
    "end": "1008279"
  },
  {
    "text": "and so effectively the fossil fuel industry has defeated the human race by",
    "start": "1008279",
    "end": "1013319"
  },
  {
    "text": "Superior pursuit of a fixed objective so it would get much worse than that when",
    "start": "1013319",
    "end": "1018560"
  },
  {
    "text": "AI systems are able to uh invent and carry out these kinds of strategies so",
    "start": "1018560",
    "end": "1023880"
  },
  {
    "text": "that's even you know within the realm of things that we currently understand",
    "start": "1023880",
    "end": "1030000"
  },
  {
    "text": "right that you could have corporate strategy you could enslave people you could do this you could do that but AI systems will come up with things we",
    "start": "1030000",
    "end": "1035199"
  },
  {
    "text": "don't understand sure and uh we you know the whole human race could be collateral",
    "start": "1035199",
    "end": "1040678"
  },
  {
    "text": "damage if we don't know how to control the systems that we create and so far",
    "start": "1040679",
    "end": "1047438"
  },
  {
    "text": "there's no examples of a dumb species controlling a more intelligent species",
    "start": "1047439",
    "end": "1052480"
  },
  {
    "text": "forever I totally agree with that so for my own employer I'm actually the person leading on AI ethics so AI ethics is a",
    "start": "1052480",
    "end": "1059799"
  },
  {
    "text": "huge passion of mine and obviously you've raised some pretty big concerns there and I'm taking a little bit of a",
    "start": "1059799",
    "end": "1065760"
  },
  {
    "text": "tangent I wasn't really expecting to go down this path but I am curious how you envision the role of AI Ethics in our",
    "start": "1065760",
    "end": "1074200"
  },
  {
    "text": "society in the World At Large given everything that you just said I mean it it clearly the potential for",
    "start": "1074200",
    "end": "1081159"
  },
  {
    "text": "consequences that we we did not Envision that we did not plan on uh is is fairly significant especially is as technology",
    "start": "1081159",
    "end": "1087600"
  },
  {
    "text": "evolves do you have any thought in a sense I wish it wasn't called AI ethics okay what what should it be called well",
    "start": "1087600",
    "end": "1093840"
  },
  {
    "text": "so I mean let's give you analogy right so the nuclear Engineers who make sure that nuclear power Stations don't",
    "start": "1093840",
    "end": "1100520"
  },
  {
    "text": "explode like Chernobyl are they ethicists would you say that's a you",
    "start": "1100520",
    "end": "1105640"
  },
  {
    "text": "know nuclear ethics issue uh no I mean it's just common sense that you don't",
    "start": "1105640",
    "end": "1110760"
  },
  {
    "text": "want your nuclear power station to explode it's common sense that you want your AI systems to remain under human",
    "start": "1110760",
    "end": "1116200"
  },
  {
    "text": "control sure but at the moment under the standard model they won't remain under",
    "start": "1116200",
    "end": "1123080"
  },
  {
    "text": "human control and would you talk us through what that implies when you say it won't and I'm going to set it up in",
    "start": "1123080",
    "end": "1128799"
  },
  {
    "text": "this way and that recognizing and it's funny how many people I talk to have",
    "start": "1128799",
    "end": "1134320"
  },
  {
    "text": "different perspectives from what I think you're about to go but given the Evolution that we've seen over over time",
    "start": "1134320",
    "end": "1141480"
  },
  {
    "text": "and the rapid Evolution we're seeing in deep learning and whatever follows coming up that potential for loss of human control where does that come from",
    "start": "1141480",
    "end": "1148440"
  },
  {
    "text": "why is it inevitable in your view I don't want to say inevitable if we persist with AI within the standard",
    "start": "1148440",
    "end": "1155640"
  },
  {
    "text": "model okay right where we fix an objective because when you when you fix an",
    "start": "1155640",
    "end": "1161039"
  },
  {
    "text": "objective you're basically telling the system whatever course of action optimizes that",
    "start": "1161039",
    "end": "1167480"
  },
  {
    "text": "objective is is the correct thing to do",
    "start": "1167480",
    "end": "1172640"
  },
  {
    "text": "and in particular for example anything that imperils the",
    "start": "1172640",
    "end": "1178360"
  },
  {
    "text": "success of the objective uh has to be prevented well",
    "start": "1178360",
    "end": "1184120"
  },
  {
    "text": "what might imperil the success of the objective while being switched off sure so by giving a system a fixed objective",
    "start": "1184120",
    "end": "1191280"
  },
  {
    "text": "you've now given it an incentive to protect itself from any attempt to",
    "start": "1191280",
    "end": "1196799"
  },
  {
    "text": "interfere with the objective any attempt to switch it off so as a a very typical",
    "start": "1196799",
    "end": "1202760"
  },
  {
    "text": "argument I hear people make if you kind of go back to like you know asimov's three rules for robotics you know in fun",
    "start": "1202760",
    "end": "1208480"
  },
  {
    "text": "in the idea that you can just in a nonprobabilistic way just definitively say you know you can't hurt people that",
    "start": "1208480",
    "end": "1214360"
  },
  {
    "text": "kind of thing as an underlying thing is given the fact that you have this ever increasing capability in the AI realm",
    "start": "1214360",
    "end": "1221760"
  },
  {
    "text": "would it be fair to say that's not a realistic perspective that the intelligence that AI would fundamentally",
    "start": "1221760",
    "end": "1228440"
  },
  {
    "text": "look to circumvent or how do you see that yeah so asimo's laws as you say",
    "start": "1228440",
    "end": "1234240"
  },
  {
    "text": "don't take into account the par perspective they they don't allow for uncertainty but of course in the real",
    "start": "1234240",
    "end": "1240679"
  },
  {
    "text": "world there are always risks so you know an asimovian self-driving car would simply stay in the garage it would say",
    "start": "1240679",
    "end": "1247400"
  },
  {
    "text": "I'm sorry you know the first law does not allow me to leave the garage because that would expose you to risk of of",
    "start": "1247400",
    "end": "1253280"
  },
  {
    "text": "injury or death so sorry we're not going anywhere I love that that's very funny actually it's true and if you were out",
    "start": "1253280",
    "end": "1260280"
  },
  {
    "text": "for a walk it would run around with an umbrella in case of photon from the Sun you know landed on your skin and maybe",
    "start": "1260280",
    "end": "1266280"
  },
  {
    "text": "initiated a little melanoma or something like right you know there's a chance that could happen so we have to protect",
    "start": "1266280",
    "end": "1271600"
  },
  {
    "text": "it so you know in any kind of real world situation there are tradeoffs but one of the things that Asos laws do is they",
    "start": "1271600",
    "end": "1278840"
  },
  {
    "text": "make a start on saying what it is that humans want right one of the things we",
    "start": "1278840",
    "end": "1284159"
  },
  {
    "text": "don't want to be harmed we don't want to be physically injured and that a start",
    "start": "1284159",
    "end": "1289320"
  },
  {
    "text": "because you know for example none of the self-driving cars that are out there right now know that people don't want to",
    "start": "1289320",
    "end": "1295480"
  },
  {
    "text": "be injured understood right they have built-in rules that say well if there's a pedestrian in front of you and you're",
    "start": "1295480",
    "end": "1301640"
  },
  {
    "text": "going forward stop right and if there's a if you're lucky they have another rule that says if there's a pedestrian behind",
    "start": "1301640",
    "end": "1307559"
  },
  {
    "text": "you and you're going backwards stop yeah right but they don't know why they don't know that if you run into a person you",
    "start": "1307559",
    "end": "1314400"
  },
  {
    "text": "can injure or kill them and they don't know that the person doesn't want to be injured or killed and it's that lack of",
    "start": "1314400",
    "end": "1319640"
  },
  {
    "text": "knowledge actually that makes them very brittle because when they get into situations they haven't been prepared",
    "start": "1319640",
    "end": "1325880"
  },
  {
    "text": "for they haven't the faintest idea what to do because they don't know which cause of action is good and which is bad",
    "start": "1325880",
    "end": "1333000"
  },
  {
    "text": "so the solution that the book proposes actually is to say look it doesn't",
    "start": "1333000",
    "end": "1338080"
  },
  {
    "text": "matter how much the human tells you that they want this or they don't want that there's always going to be residual",
    "start": "1338080",
    "end": "1346200"
  },
  {
    "text": "uncertainty about other preferences the human may have so if the human says I'd like a cup",
    "start": "1346200",
    "end": "1353279"
  },
  {
    "text": "of coffee that's not your life's mission right you know the robot could",
    "start": "1353279",
    "end": "1361240"
  },
  {
    "text": "say well you know the coffee in this hotel is 15 bucks a cup are you sure you want to cover coffee right because this",
    "start": "1361240",
    "end": "1368320"
  },
  {
    "text": "machine is uncertain about your trade-off between coffee and money right if you're miles from the nearest coffee",
    "start": "1368320",
    "end": "1375240"
  },
  {
    "text": "you know the robot might not be sure you know do you want to wait two hours for this coffeee is it okay if I like",
    "start": "1375240",
    "end": "1381480"
  },
  {
    "text": "trundle off across the desert to to the nearest Starbucks and come back two",
    "start": "1381480",
    "end": "1386640"
  },
  {
    "text": "hours later or two two weeks later with a cup of coffee you know so it would be reasonable again to ask permission and",
    "start": "1386640",
    "end": "1392720"
  },
  {
    "text": "you know if you give it a more important goal like restoring carbon dioxide levels to pre-industrial concentrations",
    "start": "1392720",
    "end": "1399919"
  },
  {
    "text": "if that was the only objective well you know one very straightforward solution is just to get rid of all the people",
    "start": "1399919",
    "end": "1405360"
  },
  {
    "text": "understood because they are the ones who are producing the carbon dioxide and and then you might say oh well I didn't I didn't mean that all right so wish",
    "start": "1405360",
    "end": "1411559"
  },
  {
    "text": "number two restore the carbon dioxide but don't kill anybody and then the system says fine",
    "start": "1411559",
    "end": "1419440"
  },
  {
    "text": "fine no problem we'll just have a multi-decade social media campaign to",
    "start": "1419440",
    "end": "1425360"
  },
  {
    "text": "convince people not to have children and then the human race will gradually die out and then carbon dioxide levels will",
    "start": "1425360",
    "end": "1432400"
  },
  {
    "text": "be restored and that's great so what I'm really proposing in in the book is",
    "start": "1432400",
    "end": "1437440"
  },
  {
    "text": "actually throw away the standal model or only use a standard model in very restricted circumstances but in general",
    "start": "1437440",
    "end": "1444840"
  },
  {
    "text": "have a new model where the objectives are in the human and the Machine knows",
    "start": "1444840",
    "end": "1453440"
  },
  {
    "text": "that it doesn't know what they are its job is to try to satisfy them but it knows that it doesn't know what they are",
    "start": "1453440",
    "end": "1460240"
  },
  {
    "text": "and when you design things that way and you actually solve that problem so you you can have an algorithm that for that",
    "start": "1460240",
    "end": "1468000"
  },
  {
    "text": "problem specification decides what the machine is going to do that algorithm produces behaviors",
    "start": "1468000",
    "end": "1475440"
  },
  {
    "text": "that seem to be what we want namely asking permission like you know is it okay if I turn the oceans into sulfuric",
    "start": "1475440",
    "end": "1481720"
  },
  {
    "text": "acid in order to restore carbon dioxide levels and you say no not so much we",
    "start": "1481720",
    "end": "1487279"
  },
  {
    "text": "like those little fishies don't don't turn the oceans into sulc acid right so we will ask permission you know it'll",
    "start": "1487279",
    "end": "1493399"
  },
  {
    "text": "even allow itself to be switched off so rather than try to protect itself and",
    "start": "1493399",
    "end": "1498559"
  },
  {
    "text": "take steps to prevent interference it actually welcomes interference because",
    "start": "1498559",
    "end": "1504399"
  },
  {
    "text": "interference by a human is a way of gaining [Music]",
    "start": "1504399",
    "end": "1509940"
  },
  {
    "text": "[Applause] [Music] information what up nerds I got some pretty awesome news to share with you",
    "start": "1509940",
    "end": "1516279"
  },
  {
    "text": "plural site is totally free for the entire month of April I'm not kidding",
    "start": "1516279",
    "end": "1521480"
  },
  {
    "text": "seriously had the pluralsight.com changelog and skill up while you stay at home for the entire month of April",
    "start": "1521480",
    "end": "1526600"
  },
  {
    "text": "you'll get access to over 7 th000 courses from experts in software development security cloud and data",
    "start": "1526600",
    "end": "1533159"
  },
  {
    "text": "there's never been a better time to skill up head to plal set.com changelog again pluralsight.com",
    "start": "1533159",
    "end": "1540320"
  },
  {
    "text": "[Music]",
    "start": "1544280",
    "end": "1547369"
  },
  {
    "text": "[Music] changelog so if you would take us a",
    "start": "1550700",
    "end": "1558640"
  },
  {
    "text": "little bit farther into your the the new model that you're proposing to replace the standard model and and maybe along",
    "start": "1558640",
    "end": "1565480"
  },
  {
    "text": "the way one of the things I I was wanting to ask as you were discussing that is if you could do that also in the",
    "start": "1565480",
    "end": "1571279"
  },
  {
    "text": "context of as we're looking at AI in the Deep learning context of today um",
    "start": "1571279",
    "end": "1577640"
  },
  {
    "text": "anticipating wherever we may be going in the future and and with the idea that people talk about about AGI which is",
    "start": "1577640",
    "end": "1584559"
  },
  {
    "text": "artificial general intelligence uh which presumably would change the nature of of",
    "start": "1584559",
    "end": "1589840"
  },
  {
    "text": "what AI is maybe and maybe distinguish how your new proposal would work kind of",
    "start": "1589840",
    "end": "1595960"
  },
  {
    "text": "in both worlds I mean if you were even today as we're looking at exceeding",
    "start": "1595960",
    "end": "1601520"
  },
  {
    "text": "human capability by uh if you have a complex set of tasks even now we can",
    "start": "1601520",
    "end": "1607279"
  },
  {
    "text": "take the models that we have and have many models each one addressing kind of a narrow scope and working together and",
    "start": "1607279",
    "end": "1613799"
  },
  {
    "text": "they can far outperform what humans could do in a similar complex task and with the idea also of having AGI where",
    "start": "1613799",
    "end": "1621159"
  },
  {
    "text": "we have models that are for lack of a better word more capable in themselves",
    "start": "1621159",
    "end": "1626200"
  },
  {
    "text": "maybe eventually aware I don't know um if you could kind of talk about what your proposal looks like in that",
    "start": "1626200",
    "end": "1632480"
  },
  {
    "text": "evolving World I'd love to know sure so first of all I should point out that I",
    "start": "1632480",
    "end": "1638279"
  },
  {
    "text": "don't think deep learning evolves into AGI okay right so AGI artificial general",
    "start": "1638279",
    "end": "1644120"
  },
  {
    "text": "intelligence is not going to be reached by just having bigger learning networks and more",
    "start": "1644120",
    "end": "1650360"
  },
  {
    "text": "data AGI and human intelligence require fundamental",
    "start": "1650360",
    "end": "1655640"
  },
  {
    "text": "capabilities that are just not present in deep learning technology as we currently understand it um so deep",
    "start": "1655640",
    "end": "1662200"
  },
  {
    "text": "Learning Systems don't know anything uh they can't reason and uh they can't accumulate",
    "start": "1662200",
    "end": "1669799"
  },
  {
    "text": "knowledge they can't apply what they've learned in one context to solve problems in another context etc etc right and",
    "start": "1669799",
    "end": "1677000"
  },
  {
    "text": "these are juste M things that humans do all the time a bit of a stepping stone",
    "start": "1677000",
    "end": "1682720"
  },
  {
    "text": "technology of the moment in a sense the Deep learning well I think deep learning is one of the pieces but you know so is",
    "start": "1682720",
    "end": "1688880"
  },
  {
    "text": "symbolic logic so is parabis reasoning so is uh sequential decision-making",
    "start": "1688880",
    "end": "1694399"
  },
  {
    "text": "techniques planning hierarchical reinforcement learning parab balistic programming Etc ET so there you know",
    "start": "1694399",
    "end": "1701640"
  },
  {
    "text": "there's lots of pieces of the puzzle some of which have been lying around for a long time deep learning is just the",
    "start": "1701640",
    "end": "1708200"
  },
  {
    "text": "newest shiniest one uh so everyone sort of oh look you know uh but you know in",
    "start": "1708200",
    "end": "1713480"
  },
  {
    "text": "in the 80s people were going oh look expert systems you know and similar claims are being made right that we just",
    "start": "1713480",
    "end": "1719360"
  },
  {
    "text": "you know if you just like scale up the number of Rules by by a factor of 500 you know and you had like learned people",
    "start": "1719360",
    "end": "1726559"
  },
  {
    "text": "you know making quantitative estim like yeah we would need about 500,000 rules",
    "start": "1726559",
    "end": "1732440"
  },
  {
    "text": "to to to manage your military campaign and like stuff like this like just complete Dil you know and there's a lot",
    "start": "1732440",
    "end": "1739039"
  },
  {
    "text": "of Dil being talked now about about deep learning but okay so within the context",
    "start": "1739039",
    "end": "1744760"
  },
  {
    "text": "of just straightforward supervised learning let's say for image classification okay",
    "start": "1744760",
    "end": "1750760"
  },
  {
    "text": "right so how does it work well we have training data and then we have deep",
    "start": "1750760",
    "end": "1757320"
  },
  {
    "text": "learning which is basically a giant tunable circuit with billions of tunable",
    "start": "1757320",
    "end": "1762519"
  },
  {
    "text": "connection strengths uh like little tiny volume controls and we just tweak all",
    "start": "1762519",
    "end": "1767600"
  },
  {
    "text": "those volume controls in this huge circuit until the thing that comes out the other end is the correct classification of an image so in in",
    "start": "1767600",
    "end": "1775120"
  },
  {
    "text": "statistical learning what you do is you you're supposed to specify the loss",
    "start": "1775120",
    "end": "1780799"
  },
  {
    "text": "function which says if you classify an object of type a as an object of type B",
    "start": "1780799",
    "end": "1786919"
  },
  {
    "text": "so let's say you class picture of a dog and you classify as a cat how bad is",
    "start": "1786919",
    "end": "1792240"
  },
  {
    "text": "that right so almost everybody in this business uses what we call call a",
    "start": "1792240",
    "end": "1798320"
  },
  {
    "text": "uniform loss function which means that they say every error is equally bad",
    "start": "1798320",
    "end": "1803519"
  },
  {
    "text": "because that's how the competitions work penalize you for the number of Errors you make not how bad the errors are",
    "start": "1803519",
    "end": "1811039"
  },
  {
    "text": "right so you know for example in in imag net there are two categories of dog one",
    "start": "1811039",
    "end": "1817159"
  },
  {
    "text": "well there's hund and something categories but two of them are the noric terer and the Norwich Terrier right and",
    "start": "1817159",
    "end": "1822519"
  },
  {
    "text": "these are practically identical in fact they weren't even recognized as separate breeds of dog until 19 1960 something um",
    "start": "1822519",
    "end": "1829840"
  },
  {
    "text": "you know and there's like slight difference in the shape of the ear and it's like okay who cares I'm sure the",
    "start": "1829840",
    "end": "1835200"
  },
  {
    "text": "nor Terriers are not gonna be that upset if you call them Norwich Terriers you I mean Norwich is he's in nor anyway",
    "start": "1835200",
    "end": "1841399"
  },
  {
    "text": "they'll lick your face either way right uh so clearly that kind of error is",
    "start": "1841399",
    "end": "1846840"
  },
  {
    "text": "relatively cheap whereas classifying a human as a gorilla as Google found out",
    "start": "1846840",
    "end": "1852720"
  },
  {
    "text": "is really expensive like in the billions of dollars of you know trashing your Goodwill of your corporation and and its",
    "start": "1852720",
    "end": "1859559"
  },
  {
    "text": "Global reputation for being fair and and idealistic and all the rest of it right",
    "start": "1859559",
    "end": "1864679"
  },
  {
    "text": "you know it was yeah I'm sure it was sort of an innocent error coming from just using a uniform loss function sure",
    "start": "1864679",
    "end": "1871519"
  },
  {
    "text": "and but if they had thought about it they would have said oh of course our loss function is not uniform oh then",
    "start": "1871519",
    "end": "1876960"
  },
  {
    "text": "what is it oh don't know we haven't thought about it and we're not sure and in fact you know if you've got typically",
    "start": "1876960",
    "end": "1883720"
  },
  {
    "text": "in imet there's like 20 something thousand different categories of object right so your loss function is a matrix",
    "start": "1883720",
    "end": "1890240"
  },
  {
    "text": "with 400 odd million entries and do you know what they are no no one knows what they are so you have an uncertain",
    "start": "1890240",
    "end": "1898320"
  },
  {
    "text": "objective you don't know what the objective is you're supposed to be optimizing and when you formulate the",
    "start": "1898320",
    "end": "1905120"
  },
  {
    "text": "problem that way right first of all you'd have to say Okay well how do we specify a probability distribution over",
    "start": "1905120",
    "end": "1911679"
  },
  {
    "text": "these 400 million entry matrices these giant tables and now I got to say okay",
    "start": "1911679",
    "end": "1917919"
  },
  {
    "text": "what's the probability of each possible table of 400 million numbers well that probability distribution is itself uh",
    "start": "1917919",
    "end": "1925399"
  },
  {
    "text": "massively complex object uh to specify and um no one has ever figured",
    "start": "1925399",
    "end": "1932840"
  },
  {
    "text": "out even how to write it down uh how to structure that probability distribution",
    "start": "1932840",
    "end": "1938440"
  },
  {
    "text": "because it clearly it has lots of structure right the the costs of misclassifying each breed of dog as a",
    "start": "1938440",
    "end": "1945080"
  },
  {
    "text": "cat is probably about the same I I think all dogs are equally upset to be called",
    "start": "1945080",
    "end": "1950159"
  },
  {
    "text": "cats but if you know if you classify a bus as an insect maybe that's a more",
    "start": "1950159",
    "end": "1956360"
  },
  {
    "text": "embarrassing mistake to make uh and so on so you could imagine that this there's lots of structure in this in",
    "start": "1956360",
    "end": "1961799"
  },
  {
    "text": "this Matrix and you know the structure partly reflects a taxonomic hierarchy of objects and how we arrange them into",
    "start": "1961799",
    "end": "1969080"
  },
  {
    "text": "categories so you could do a whole PhD thesis just on that part of the problem",
    "start": "1969080",
    "end": "1974919"
  },
  {
    "text": "and now there's also well what does the algorithm look like right right well if it doesn't know the loss function and it",
    "start": "1974919",
    "end": "1980760"
  },
  {
    "text": "has the opportunity to find out more for example by asking the user you know is",
    "start": "1980760",
    "end": "1986399"
  },
  {
    "text": "it worse to call a cat a dog or to call an apple an orange and sometimes the",
    "start": "1986399",
    "end": "1992039"
  },
  {
    "text": "algorithm would say I'm not going to classify that image right that's too dangerous so I'm just not going to make",
    "start": "1992039",
    "end": "1998120"
  },
  {
    "text": "a guess as to what it is so you immediately see that just the nature of supervised learning would change",
    "start": "1998120",
    "end": "2003480"
  },
  {
    "text": "considerably yes if you allow for uncertainty about the the underlying objective and then with",
    "start": "2003480",
    "end": "2009159"
  },
  {
    "text": "AGI we don't yet know exactly how to build AGI I mean there are a bunch of",
    "start": "2009159",
    "end": "2015080"
  },
  {
    "text": "Unsolved major conceptual problems that we have to figure out but I think the",
    "start": "2015080",
    "end": "2021480"
  },
  {
    "text": "basic answer is that if you formulate AGI within this new",
    "start": "2021480",
    "end": "2027120"
  },
  {
    "text": "model the key property of the new model is that the better the AI solves the",
    "start": "2027120",
    "end": "2032279"
  },
  {
    "text": "problem the better the outcome is for human beings because it means that the AI system system does a better job of",
    "start": "2032279",
    "end": "2039799"
  },
  {
    "text": "finding out what what it is you want and does a better job of achieving it and so you were talking a moment ago about kind",
    "start": "2039799",
    "end": "2047600"
  },
  {
    "text": "of applying control in the new model that that you're proposing uh as we move",
    "start": "2047600",
    "end": "2052760"
  },
  {
    "text": "into AGI would you pick that train of thought right up where you left it there yes so with AGI if we formulate it in",
    "start": "2052760",
    "end": "2059320"
  },
  {
    "text": "the new model the the the key property is that the the smarter the AI the",
    "start": "2059320",
    "end": "2064599"
  },
  {
    "text": "better the outcome for humans because the AI system will be able to better interpret our Behavior as",
    "start": "2064599",
    "end": "2072760"
  },
  {
    "text": "evidence of our underlying preferences so this this is the nature of information flow between the human and",
    "start": "2072760",
    "end": "2079280"
  },
  {
    "text": "the Machine about what the human's objectives and preferences are is that everything the human does reveals",
    "start": "2079280",
    "end": "2085200"
  },
  {
    "text": "evidence for our underlying preferences so the AI system observing us observing",
    "start": "2085200",
    "end": "2090919"
  },
  {
    "text": "our whole history observing everything we've ever written is able to infer from",
    "start": "2090919",
    "end": "2096960"
  },
  {
    "text": "that something about what we want as individuals as a species and so on and so the better the AI system the better",
    "start": "2096960",
    "end": "2103599"
  },
  {
    "text": "job it'll do of that and the better it'll be able to achieve those objectives when you say that just to",
    "start": "2103599",
    "end": "2108800"
  },
  {
    "text": "clarify it sounds like you're going into unsupervised learning where it just has kind of the wealth of human knowledge",
    "start": "2108800",
    "end": "2113920"
  },
  {
    "text": "and what humans have done or are you strictly leaving it for in this new approach are you leaving it for the",
    "start": "2113920",
    "end": "2120359"
  },
  {
    "text": "algorithm that you're training to figure that out are you specifying it as the",
    "start": "2120359",
    "end": "2126240"
  },
  {
    "text": "practitioner do you see this is kind of at some point maybe leaving kind of today's deep learning behind uh and and",
    "start": "2126240",
    "end": "2132880"
  },
  {
    "text": "taking a different approach mathematically how does that look going into the future if everyone adopts this",
    "start": "2132880",
    "end": "2137960"
  },
  {
    "text": "well yeah so you often see this claim that there's supervised learning unsupervised learning and then well that",
    "start": "2137960",
    "end": "2145720"
  },
  {
    "text": "I mean logically if those were correct then supervis and unsupervised would that constitutes a complete coverage of",
    "start": "2145720",
    "end": "2152640"
  },
  {
    "text": "all learning right you know a and not a but and then they say oh and there's reinforcement learning as well but actually there's not there's other kinds",
    "start": "2152640",
    "end": "2158920"
  },
  {
    "text": "of learning too and this is related to something we call inverse reinforcement learning and inverse reinforcement",
    "start": "2158920",
    "end": "2166119"
  },
  {
    "text": "learning is basically well so let me first say what reinforcement learning is Right reinforcement learning is the",
    "start": "2166119",
    "end": "2172599"
  },
  {
    "text": "human specifies the reward to the machine and then the",
    "start": "2172599",
    "end": "2177960"
  },
  {
    "text": "machine learns how to optimally produce reward right so the machine says okay",
    "start": "2177960",
    "end": "2184920"
  },
  {
    "text": "this is I'm going to give you one point when you the game and I going to view zero when you lose then the machine",
    "start": "2184920",
    "end": "2190280"
  },
  {
    "text": "learns to get one point more often than not so inverse reinforcement learning is the other way around the machine is",
    "start": "2190280",
    "end": "2196800"
  },
  {
    "text": "observing let's say the human and trying to figure out what is the reward function that this human is",
    "start": "2196800",
    "end": "2203520"
  },
  {
    "text": "optimizing right and we came up with it actually when I was uh collaborating",
    "start": "2203520",
    "end": "2210160"
  },
  {
    "text": "with some biologists and we were trying to figure out how could we apply reinforcement",
    "start": "2210160",
    "end": "2215800"
  },
  {
    "text": "learning to understand animal Locomotion so you know cockroaches and flies and",
    "start": "2215800",
    "end": "2222720"
  },
  {
    "text": "other you know creepy crawlies and so on and it struck me that actually we can't apply reinforcement learning to sort of",
    "start": "2222720",
    "end": "2229680"
  },
  {
    "text": "simulate animal you know to create a simulated insect or whatever because we don't know what the reward function is",
    "start": "2229680",
    "end": "2235800"
  },
  {
    "text": "right right so then I said oh well why don't we watch them walking and figure",
    "start": "2235800",
    "end": "2241599"
  },
  {
    "text": "out what reward function are they optimizing you know with their particular choice of how to locomote",
    "start": "2241599",
    "end": "2248240"
  },
  {
    "text": "right because I I don't know if you ever seen the montypython silly walk sketch yes I have your listeners may want to",
    "start": "2248240",
    "end": "2254400"
  },
  {
    "text": "check that out on the web right so John C demonstrates that there are many other ways you could walk besides the usual",
    "start": "2254400",
    "end": "2260880"
  },
  {
    "text": "one right so we choose the usual way of walking because it does something good",
    "start": "2260880",
    "end": "2266200"
  },
  {
    "text": "for us whether it's energy efficient or stable you know it avoids falling over whatever it might be it's optimizing",
    "start": "2266200",
    "end": "2272960"
  },
  {
    "text": "something and so the idea of inverse reinforcement learning is observe the behavior and figure figure out what is",
    "start": "2272960",
    "end": "2278280"
  },
  {
    "text": "being optimized by this Behavior okay and so this this approach the the new",
    "start": "2278280",
    "end": "2284280"
  },
  {
    "text": "model is sort of a generalization of that idea because it's it's generalized in the sense that the human is not just",
    "start": "2284280",
    "end": "2291839"
  },
  {
    "text": "being passively observed behave you know doing whatever human thing but the human",
    "start": "2291839",
    "end": "2297200"
  },
  {
    "text": "is sort of an active participant for example you know if they if the human solves their half of this problem they",
    "start": "2297200",
    "end": "2303000"
  },
  {
    "text": "will actively teach the robot about their preferences right including saying",
    "start": "2303000",
    "end": "2308319"
  },
  {
    "text": "things like I would like a cup of coffee right that's conveying preference",
    "start": "2308319",
    "end": "2313440"
  },
  {
    "text": "information to the robot it's not an order it's sort of just you know factual",
    "start": "2313440",
    "end": "2318760"
  },
  {
    "text": "evidence about my state of mind and the robot can interpret it as it wishes so",
    "start": "2318760",
    "end": "2324400"
  },
  {
    "text": "when you when you solve this this kind of problem it's what the economists call",
    "start": "2324400",
    "end": "2329520"
  },
  {
    "text": "a game which means a decision problem with more than one decision-making entity so you can imagine one human and",
    "start": "2329520",
    "end": "2335680"
  },
  {
    "text": "one machine or lots of humans lots of machine machines um so you can solve that problem mathematically and then you",
    "start": "2335680",
    "end": "2341040"
  },
  {
    "text": "just look at the behaviors that the machine and the human engage in when they solve this problem",
    "start": "2341040",
    "end": "2347680"
  },
  {
    "text": "and you know indeed the human teaches the machine and the Machine does things",
    "start": "2347680",
    "end": "2352720"
  },
  {
    "text": "it asks permission allows itself to be switched off and so on so you get very different behaviors than you do in in",
    "start": "2352720",
    "end": "2359839"
  },
  {
    "text": "the standard model of AI and so I think I'm reasonably optimistic that in fact",
    "start": "2359839",
    "end": "2364960"
  },
  {
    "text": "it shouldn't matter how intelligent the AI system is things will still go well and in the old model the more",
    "start": "2364960",
    "end": "2372040"
  },
  {
    "text": "intelligent the machine the worse the outcome for people because the machine",
    "start": "2372040",
    "end": "2377560"
  },
  {
    "text": "would find some way of messing with the world to achieve the objective that you",
    "start": "2377560",
    "end": "2382920"
  },
  {
    "text": "said and mess with the things you forgot to mention that you care about so I'm kind of curious as you take",
    "start": "2382920",
    "end": "2390599"
  },
  {
    "text": "this and you're looking we we've hit so many different areas and so I'm I'm trying to tie it together you look into",
    "start": "2390599",
    "end": "2396280"
  },
  {
    "text": "the future at this point having come as far through this field as it's evolved and changed over the years where do you",
    "start": "2396280",
    "end": "2402800"
  },
  {
    "text": "see it going especially with control in mind and and you know as you've talked about how the current standard model can",
    "start": "2402800",
    "end": "2410800"
  },
  {
    "text": "lead us arai then if you are a practitioner and you're out in industry and you're trying to do the things that",
    "start": "2410800",
    "end": "2416960"
  },
  {
    "text": "your organization wants you to do how do you apply your new model and as you look",
    "start": "2416960",
    "end": "2423720"
  },
  {
    "text": "out what do you think we're going to be doing uh in terms of what types of models what is AI kind of evolving into",
    "start": "2423720",
    "end": "2430640"
  },
  {
    "text": "if you're looking out 5 years or 10 years and we're learning these lessons that you're teaching Us in this capacity",
    "start": "2430640",
    "end": "2437040"
  },
  {
    "text": "what does the near Mid and a little bit F farther out look to you at this point interesting so first of all there's",
    "start": "2437040",
    "end": "2444040"
  },
  {
    "text": "going to be a little bit of um pushing and shoving right I would imagine the AI",
    "start": "2444040",
    "end": "2449920"
  },
  {
    "text": "Community that's grown up with the standard model and learned it from the textbook is going to keep pushing ahead",
    "start": "2449920",
    "end": "2456880"
  },
  {
    "text": "with their you know solving the technical problems that they're that they're solving within",
    "start": "2456880",
    "end": "2463000"
  },
  {
    "text": "the standard model and and and they have to be dragged Kicking and Screaming into this new way of doing things so so",
    "start": "2463000",
    "end": "2469319"
  },
  {
    "text": "partly means we you know on my research group there are you know maybe a dozen other research groups around the world",
    "start": "2469319",
    "end": "2474800"
  },
  {
    "text": "working in this new framework now we have to provide the Technical Solutions",
    "start": "2474800",
    "end": "2480000"
  },
  {
    "text": "we have to provide the new algorithms that uh behave according to the the the different principles and I think we can",
    "start": "2480000",
    "end": "2488599"
  },
  {
    "text": "do that if we can do that in Practical settings whether it's you know",
    "start": "2488599",
    "end": "2493880"
  },
  {
    "text": "recommendation systems content selection for social media intelligent personal",
    "start": "2493880",
    "end": "2498960"
  },
  {
    "text": "assistance then I think that will have a significant effect people will say oh now I get it in fact no they won't say",
    "start": "2498960",
    "end": "2506040"
  },
  {
    "text": "now I get it they'll say oh I always thought that way of course right so they W you know they won't be a sort of a you",
    "start": "2506040",
    "end": "2512520"
  },
  {
    "text": "know a moment of of capitulation there'll be just a gradual realization that of of course this is what they've",
    "start": "2512520",
    "end": "2518480"
  },
  {
    "text": "always thought and it makes sense right it does make sense do you think that as",
    "start": "2518480",
    "end": "2523520"
  },
  {
    "text": "they adopt this as I'm thinking about what you're saying here and and you already mentioned that the poorly named",
    "start": "2523520",
    "end": "2530640"
  },
  {
    "text": "idea of AI ethics you know in terms of how do we prevent those how does that",
    "start": "2530640",
    "end": "2535760"
  },
  {
    "text": "come together I mean because there's the algorithmic side there's the new algorithms and you know where you are going out into the future and you're",
    "start": "2535760",
    "end": "2542280"
  },
  {
    "text": "implementing inverse reinforcement learning and and and it's working for you technically and and you're also",
    "start": "2542280",
    "end": "2548440"
  },
  {
    "text": "trying to say we want to ensure that the outcomes are beneficial uh and certainly",
    "start": "2548440",
    "end": "2554800"
  },
  {
    "text": "to the human involved how does all that come together because right now you know",
    "start": "2554800",
    "end": "2559960"
  },
  {
    "text": "as I look at people there are people that are doing kind of the the outcome the ethical con you know concern there",
    "start": "2559960",
    "end": "2566000"
  },
  {
    "text": "there're people that are strictly algorithmically focused in terms of solving problems and yet if I'm",
    "start": "2566000",
    "end": "2571200"
  },
  {
    "text": "understanding you correctly you need to be able to to fuse all these together it sounds like so that that works yeah I",
    "start": "2571200",
    "end": "2577960"
  },
  {
    "text": "because I think the last thing you want and you've probably experienced this yourself is the AI ethics people leaning",
    "start": "2577960",
    "end": "2583760"
  },
  {
    "text": "over the shoulder of the AI practitioners and wagging their finger yeah and saying no no you're a bad person right doesn't work so what we",
    "start": "2583760",
    "end": "2592240"
  },
  {
    "text": "have to do actually is to get people to understand that this is just how you do",
    "start": "2592240",
    "end": "2597520"
  },
  {
    "text": "AI right you know when when civil engineers design Bridges there's not a",
    "start": "2597520",
    "end": "2603280"
  },
  {
    "text": "bunch of bridge designers and then a bunch of ethicists saying oh by the way you have to make sure it doesn't fall",
    "start": "2603280",
    "end": "2608400"
  },
  {
    "text": "over right it's just of course it of course it's it's not supposed to fall over it wouldn't be a bridge if it just",
    "start": "2608400",
    "end": "2614720"
  },
  {
    "text": "fell over right you know and similarly you know nuclear Engineers who",
    "start": "2614720",
    "end": "2620160"
  },
  {
    "text": "design nuclear power stations there isn't you know another discipline of people who care about safety and then",
    "start": "2620160",
    "end": "2626760"
  },
  {
    "text": "the nuclear Engineers don't care about safety and they just want to generate lots of energy right it doesn't work that way if we want to generate energy",
    "start": "2626760",
    "end": "2632559"
  },
  {
    "text": "we can just set off lots of bombs that's that's cheap and cheerful gets past was",
    "start": "2632559",
    "end": "2637599"
  },
  {
    "text": "red tape and all that crap so so I think there should be a strong incentive to just Design Systems this way because",
    "start": "2637599",
    "end": "2644520"
  },
  {
    "text": "they won't fall down right the you know the example I use in a lot of talks is",
    "start": "2644520",
    "end": "2649680"
  },
  {
    "text": "that you know your domestic robot if it's designed this way won't cook the",
    "start": "2649680",
    "end": "2654920"
  },
  {
    "text": "cat for dinner because there is you know because the fridge is empty because it would say well I mean it might realize",
    "start": "2654920",
    "end": "2660839"
  },
  {
    "text": "yeah cooking the cat for dinner solves the problem of lack of food but I'm",
    "start": "2660839",
    "end": "2666000"
  },
  {
    "text": "uncertain about perhaps the cat has sentimental value and so I shouldn't cook it right I should I should ask",
    "start": "2666000",
    "end": "2672040"
  },
  {
    "text": "permission before I cook it right so you get better Behavior out of your AI",
    "start": "2672040",
    "end": "2677400"
  },
  {
    "text": "systems and so they'll be economically more valuable they'll incur far less in",
    "start": "2677400",
    "end": "2682559"
  },
  {
    "text": "the way of liability insurance uh and so on so there's that but I also think that",
    "start": "2682559",
    "end": "2688359"
  },
  {
    "text": "we at some point will need regulation because there will always be just as there is with malware there's a",
    "start": "2688359",
    "end": "2695559"
  },
  {
    "text": "t you know temptation to just bypass uh safety and and all the rest",
    "start": "2695559",
    "end": "2701119"
  },
  {
    "text": "just in terms of immediate grasping and so as AI systens become more and more",
    "start": "2701119",
    "end": "2708720"
  },
  {
    "text": "capable and potentially powerful they need to be regulated more and more strictly just as we do with nuclear",
    "start": "2708720",
    "end": "2715359"
  },
  {
    "text": "power stations sure and I would imagine that's not just at a national level but they'll have to be a body of international law because you have",
    "start": "2715359",
    "end": "2721839"
  },
  {
    "text": "different you know parts of the world different countries have different values that they're bringing to play and some are going to care more about these",
    "start": "2721839",
    "end": "2727800"
  },
  {
    "text": "kind of outcomes than others I guess I wanted to to finish up with you know you have all these students looking to you",
    "start": "2727800",
    "end": "2734599"
  },
  {
    "text": "to and they're coming in and they are starting their careers out in this field",
    "start": "2734599",
    "end": "2739680"
  },
  {
    "text": "uh you have people like me who are a little bit older and we are we are trying to constantly retool and stay up",
    "start": "2739680",
    "end": "2745119"
  },
  {
    "text": "with the field and you've really you've kind of shifted you know in this conversation that we've just had you've",
    "start": "2745119",
    "end": "2751000"
  },
  {
    "text": "really shifted how I'm looking at the future and the things that need how does a practitioner uh or student that's",
    "start": "2751000",
    "end": "2757640"
  },
  {
    "text": "about to be a practitioner kind of tool themselves today Beyond just the current state of",
    "start": "2757640",
    "end": "2763960"
  },
  {
    "text": "deep learning because that's you know where all the focus is right now it's all about you know tensor flow or you",
    "start": "2763960",
    "end": "2769599"
  },
  {
    "text": "know pick whatever tool you want to use and we're we're building neural networks uh or adjacent Technologies and that's",
    "start": "2769599",
    "end": "2776160"
  },
  {
    "text": "where all the education is really focusing you know that's broadly available out there on the internet and",
    "start": "2776160",
    "end": "2781680"
  },
  {
    "text": "by service providers and and others how should someone like myself or a student coming in the field be thinking about",
    "start": "2781680",
    "end": "2788160"
  },
  {
    "text": "this and how should we focus on educating ourselves for the future to align ourselves with this Vision that",
    "start": "2788160",
    "end": "2793680"
  },
  {
    "text": "you just set out obviously there's your book there's human compatible I don't know if it's out yet the fourth edition",
    "start": "2793680",
    "end": "2799040"
  },
  {
    "text": "to your textbook yeah so the fourth edition is out next week we finished it a few weeks ago and I think it'll be in",
    "start": "2799040",
    "end": "2805520"
  },
  {
    "text": "the stores in a week's time perfect timing as they hear this I can go out and buy it yeah so you know it's an unfortunate situation because we",
    "start": "2805520",
    "end": "2812000"
  },
  {
    "text": "basically we've put the technical content from Human compatible into the new edition of the textbook you know so",
    "start": "2812000",
    "end": "2818559"
  },
  {
    "text": "the first two chapters saying okay well there's this old way of thinking about Ai and now there's this new way but we don't have all the chapters in the",
    "start": "2818559",
    "end": "2825800"
  },
  {
    "text": "middle telling you how to do the new way so we're going to tell you how to do the old way but keep in mind that you really",
    "start": "2825800",
    "end": "2831319"
  },
  {
    "text": "should be thinking about the new way so that'll have to be the fifth edition there an awkward timing yeah so the",
    "start": "2831319",
    "end": "2836359"
  },
  {
    "text": "fifth edition will hopefully have more stuff but the things to keep in mind are first of all is the objective that",
    "start": "2836359",
    "end": "2844119"
  },
  {
    "text": "you're designing your system to optimize and I think as I mentioned with the example of image classification and the",
    "start": "2844119",
    "end": "2850520"
  },
  {
    "text": "you know classifying the person as a gorilla most people are not even thinking about that the objective there",
    "start": "2850520",
    "end": "2858280"
  },
  {
    "text": "is typically implicit you know when you run tensorflow if you don't put in a loss function then you're putting in a",
    "start": "2858280",
    "end": "2864720"
  },
  {
    "text": "uniform loss function and if you put in a uniform loss function you're saying that classifying human in gorilla is",
    "start": "2864720",
    "end": "2870400"
  },
  {
    "text": "just as bad as classifying one kind of terer as another right and that's not true so don't do it right the second",
    "start": "2870400",
    "end": "2877760"
  },
  {
    "text": "thing to think about is what is the scope of action of your system so if",
    "start": "2877760",
    "end": "2885000"
  },
  {
    "text": "your system could learn any function that strings together actions that it",
    "start": "2885000",
    "end": "2891160"
  },
  {
    "text": "carries out you know what is the sort of transitive closure what's the the full",
    "start": "2891160",
    "end": "2896599"
  },
  {
    "text": "set of states that your system could take the world into when it runs in the real world right and if for example",
    "start": "2896599",
    "end": "2905240"
  },
  {
    "text": "you're just writing a go program you know and it's only moving pieces on a",
    "start": "2905240",
    "end": "2910760"
  },
  {
    "text": "simulated board you know within the memory of the computer uh and then displaying It's relatively safe all",
    "start": "2910760",
    "end": "2919240"
  },
  {
    "text": "right because no matter what sequence of moves it does it's still only changing",
    "start": "2919240",
    "end": "2924319"
  },
  {
    "text": "what appears on the screen when someone's playing go with it now",
    "start": "2924319",
    "end": "2929440"
  },
  {
    "text": "theoretically it's not perfectly safe because you know just as we have learned",
    "start": "2929440",
    "end": "2936400"
  },
  {
    "text": "the origins of our own universe and the physics of the world in which our bodies",
    "start": "2936400",
    "end": "2942000"
  },
  {
    "text": "run uh a sufficiently intelligent go program could actually do the same thing",
    "start": "2942000",
    "end": "2947480"
  },
  {
    "text": "and then figure out that there must be other entities outside of its computer and try to communicate with them through",
    "start": "2947480",
    "end": "2953839"
  },
  {
    "text": "the goboard uh and convince them to give it more CPU power or whatever right so",
    "start": "2953839",
    "end": "2959200"
  },
  {
    "text": "so it's not hermetically sealed even then but if your algorithm is in contact Direct contact with",
    "start": "2959200",
    "end": "2965720"
  },
  {
    "text": "humans right then you know here's one good way to remember this Hitler did it",
    "start": "2965720",
    "end": "2971200"
  },
  {
    "text": "with words right Hitler was not a thousand foot tall giant robot with laser beam",
    "start": "2971200",
    "end": "2977680"
  },
  {
    "text": "sweeping destruction everywhere it was just a little guy who spoke yeah that's",
    "start": "2977680",
    "end": "2982799"
  },
  {
    "text": "a great point and so if your AI system is in direct contact with humans it has",
    "start": "2982799",
    "end": "2988160"
  },
  {
    "text": "far more power than Hitler already because it can speak to billions of people all the time that may be the most",
    "start": "2988160",
    "end": "2995960"
  },
  {
    "text": "terrifying thing I've ever heard a person say right there that's a perspective right there yeah if you",
    "start": "2995960",
    "end": "3002359"
  },
  {
    "text": "think you know what is the closure right what is the transitive closure of all possible actions that system could do",
    "start": "3002359",
    "end": "3008079"
  },
  {
    "text": "there's really no limit to it yes right it could affect the world in any way so",
    "start": "3008079",
    "end": "3013200"
  },
  {
    "text": "those kinds of systems I think should absolutely be carefully regulated and I",
    "start": "3013200",
    "end": "3019440"
  },
  {
    "text": "think for example we talked earlier about how social media algorithms work I",
    "start": "3019440",
    "end": "3024839"
  },
  {
    "text": "think you can distinguish between reinforcement learning algorithms in that context and supervised learning",
    "start": "3024839",
    "end": "3031040"
  },
  {
    "text": "algorithms so a supervised learning algorithm roughly speaking will learn what people want whereas a reinforcement",
    "start": "3031040",
    "end": "3036640"
  },
  {
    "text": "learning Al will learn to manipulate people to change what they want so that the algorithm can make more money off",
    "start": "3036640",
    "end": "3043920"
  },
  {
    "text": "and so you know I really think that algorithms that are facing the general public in that way need to be regulated",
    "start": "3043920",
    "end": "3052000"
  },
  {
    "text": "not in exactly the same way but in some way analogous to the way we regulate Pharmaceuticals we don't just get to",
    "start": "3052000",
    "end": "3058680"
  },
  {
    "text": "spit out you know new Pharmaceuticals to billions of people whenever we feel like it right they have to be carefully",
    "start": "3058680",
    "end": "3066119"
  },
  {
    "text": "tested on you know on animals and then on you know control groups of humans because if it goes wrong it's really bad",
    "start": "3066119",
    "end": "3073720"
  },
  {
    "text": "and the same as we've learned is true with uh with these social media algorithms well I just wanted to say",
    "start": "3073720",
    "end": "3080680"
  },
  {
    "text": "thank you so much for coming on the show this has uh truly been one of the most fascinating conversations I've ever had",
    "start": "3080680",
    "end": "3087160"
  },
  {
    "text": "I think at this point I will be uh recommending that people read human compatible pretty much everywhere I go",
    "start": "3087160",
    "end": "3094160"
  },
  {
    "text": "well thank you you point out the danger of as we grow here if we don't start start taking that into account so thank",
    "start": "3094160",
    "end": "3100520"
  },
  {
    "text": "you so much for coming on the show you've really blown my mind so uh I don't normally finish the show stuttering like this so thank you very",
    "start": "3100520",
    "end": "3106720"
  },
  {
    "text": "much thank you Chris it's nice talking to [Music]",
    "start": "3106720",
    "end": "3112280"
  },
  {
    "text": "you thank you for listening to this episode of practical AI more like this",
    "start": "3112280",
    "end": "3117520"
  },
  {
    "text": "at Chang log.com practical aai there you'll find our latest as well as lists",
    "start": "3117520",
    "end": "3123200"
  },
  {
    "text": "of our most popular episodes and the ones we recommend if this show has helped you on your AI Journey please",
    "start": "3123200",
    "end": "3128359"
  },
  {
    "text": "leave us a five-star review on Apple podcasts heart us on Spotify star us on",
    "start": "3128359",
    "end": "3133400"
  },
  {
    "text": "overcast and tell a friend what they're missing out on practical AI is hosted by Daniel Whit neack and Chris Benson it's",
    "start": "3133400",
    "end": "3139079"
  },
  {
    "text": "produced by me Jared Santo and our music is brought to you by the beat freak breakmaster cylinder we have awesome",
    "start": "3139079",
    "end": "3144400"
  },
  {
    "text": "sponsors please support them they support us thanks again the fastly lenoe and rollbar that's all for now we'll",
    "start": "3144400",
    "end": "3150480"
  },
  {
    "text": "talk to you next [Music]",
    "start": "3150480",
    "end": "3170000"
  },
  {
    "text": "time",
    "start": "3170000",
    "end": "3173000"
  }
]
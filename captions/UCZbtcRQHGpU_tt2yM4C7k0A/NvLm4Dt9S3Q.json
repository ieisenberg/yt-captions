[
  {
    "text": "all natural data has a power law structure a fractal structure to it the way neural networks learn is they learn",
    "start": "80",
    "end": "7359"
  },
  {
    "text": "the multifractal nature of the data and that that's why they work so well on things like text and images and why they",
    "start": "7359",
    "end": "12840"
  },
  {
    "text": "don't work great on tabular data sets so they correlations in the data data is correlated you're trying to learn the",
    "start": "12840",
    "end": "18680"
  },
  {
    "text": "correlations and frequently you're trying to learn very subtle correlations you couldn't find in some other way you",
    "start": "18680",
    "end": "24760"
  },
  {
    "text": "know using some simple clustering algorithm or an SPM or something like that so what we're doing is we're measuring the fractal nature of the data",
    "start": "24760",
    "end": "31519"
  },
  {
    "text": "and every layer of a neural network gives you some measure of the fractal properties in that level of granularity",
    "start": "31519",
    "end": "38760"
  },
  {
    "text": "and so Alpha is like a measure of the fractal Dimension and what we know is that it measures the amount of",
    "start": "38760",
    "end": "44559"
  },
  {
    "text": "correlation in that [Music]",
    "start": "44559",
    "end": "55878"
  },
  {
    "text": "layer welcome to practical AI a weekly podcast cast making artificial",
    "start": "56120",
    "end": "61320"
  },
  {
    "text": "intelligence practical productive and accessible to everyone subscribe now if you haven't already head to practical AI",
    "start": "61320",
    "end": "68400"
  },
  {
    "text": "FM for all the ways special thanks to our partners at fastly for delivering our shows super fast to wherever you",
    "start": "68400",
    "end": "75200"
  },
  {
    "text": "listen check them out at fast.com and to our friends at fly.io we deploy our app",
    "start": "75200",
    "end": "81680"
  },
  {
    "text": "servers close to our users and you can too learn more at",
    "start": "81680",
    "end": "87200"
  },
  {
    "text": "[Music] fly.io",
    "start": "87200",
    "end": "91920"
  },
  {
    "text": "welcome to another episode of practical AI this is Daniel whack I'm a data",
    "start": "93040",
    "end": "98799"
  },
  {
    "text": "scientist with s International and I'm joined as always by my co-host Chris",
    "start": "98799",
    "end": "103960"
  },
  {
    "text": "Benson who is a tech strategist with locked Martin how you doing Chris I'm",
    "start": "103960",
    "end": "109200"
  },
  {
    "text": "doing very well Daniel how's it going today it's going well you know I've been uh training quite a few models recently",
    "start": "109200",
    "end": "115680"
  },
  {
    "text": "NLP models for question answering and other things and one thing always comes",
    "start": "115680",
    "end": "121039"
  },
  {
    "text": "up in that is you know how long do I train this thing am I overtraining it am",
    "start": "121039",
    "end": "126840"
  },
  {
    "text": "I under trining it how do I test it appropriately am I testing it right what",
    "start": "126840",
    "end": "132160"
  },
  {
    "text": "else should I be doing I'm all of these thoughts are running through my mind and I'm pretty excited because today we have",
    "start": "132160",
    "end": "138599"
  },
  {
    "text": "joining us Charles Martin who is an AI and data science consultant with calculation Consulting and uh this is",
    "start": "138599",
    "end": "146200"
  },
  {
    "text": "basically one of the things that that he thinks about a lot and builds tooling for so welcome Charles hey great thanks",
    "start": "146200",
    "end": "152440"
  },
  {
    "text": "for having me guys yeah well the main I think the thing that I saw of of your",
    "start": "152440",
    "end": "158280"
  },
  {
    "text": "work that really interested me was this Weight Watcher tool which is an open- Source diagnostic tool for analyzing",
    "start": "158280",
    "end": "166519"
  },
  {
    "text": "neural networks without the need for access to training or even test data",
    "start": "166519",
    "end": "171840"
  },
  {
    "text": "which is is super interesting and I want to get into all the details about that but maybe just describe for us kind of",
    "start": "171840",
    "end": "178120"
  },
  {
    "text": "pre-weight Watcher how what what led up to Weight Watcher what what were the sort of motivations that were going",
    "start": "178120",
    "end": "183400"
  },
  {
    "text": "through your mind and maybe the things that you were encountering in your own work that led you to think about this",
    "start": "183400",
    "end": "189159"
  },
  {
    "text": "this problem sure sure so I do Consulting in Ai and I had some clients",
    "start": "189159",
    "end": "194280"
  },
  {
    "text": "working with me to do uh text generation so this is years before GPT and all",
    "start": "194280",
    "end": "200879"
  },
  {
    "text": "these amazing diffusion models that existed and we were training lstms to",
    "start": "200879",
    "end": "206480"
  },
  {
    "text": "generate text things like you know weight loss articles and reviews on Amazon and stuff like that and I",
    "start": "206480",
    "end": "211640"
  },
  {
    "text": "realized that you know as I use these models I can't really evaluate them because if you're training like a",
    "start": "211640",
    "end": "217599"
  },
  {
    "text": "classifier like an old svm or XG boost you know you can look at the training accuracy but if you're trying to design",
    "start": "217599",
    "end": "223680"
  },
  {
    "text": "a model to generate text or some other natural language processing problem like say designing embedding vectors for",
    "start": "223680",
    "end": "229840"
  },
  {
    "text": "search relevance it's really hard to evaluate whether your model is converging or not and now I had studied",
    "start": "229840",
    "end": "236200"
  },
  {
    "text": "statistical physics of neural networks when I was a postto and theoretical phys physics so I knew that there are",
    "start": "236200",
    "end": "241799"
  },
  {
    "text": "techniques from physics that make it possible to analyze the performance of these models and to estimate how well",
    "start": "241799",
    "end": "247079"
  },
  {
    "text": "they're performing and what I realize is that nobody in the machine learning or AI Community really knows about this",
    "start": "247079",
    "end": "252400"
  },
  {
    "text": "stuff because it's like you know from the early 90s uh early to late 90s where a lot of This research was done and you",
    "start": "252400",
    "end": "260000"
  },
  {
    "text": "know the people doing Ai and machine learning are not theoretical physicists you know they're Computer Sciences they don't know about the works I said you",
    "start": "260000",
    "end": "265080"
  },
  {
    "text": "know I except for you and Daniel there got yes you know it's a very broad field",
    "start": "265080",
    "end": "270680"
  },
  {
    "text": "and there's so many people doing AI now that it's really fun because there's so many different backgrounds and I was at",
    "start": "270680",
    "end": "277520"
  },
  {
    "text": "a conference maybe 10 years ago maybe nine years ago and I met an old friend of mine Michael Mahoney who's a",
    "start": "277520",
    "end": "283840"
  },
  {
    "text": "professor at UC Berkeley it was at ml comp it was run by the guys at that time who were doing oh what was the name of",
    "start": "283840",
    "end": "290360"
  },
  {
    "text": "the company they they had a recommender system a recommender product they were T AI they eventually acquired by Apple and",
    "start": "290360",
    "end": "296000"
  },
  {
    "text": "I was I was talking to Michael I said you know there's a lot of theory around deep learning that is very similar to",
    "start": "296000",
    "end": "302320"
  },
  {
    "text": "what we see in protein folding and my adviser was actually the him and his student John jumper developed the first",
    "start": "302320",
    "end": "308039"
  },
  {
    "text": "version of alphafold so what happened was Google acquired Alpha fold uh excuse they they hired John jumper who was the",
    "start": "308039",
    "end": "313880"
  },
  {
    "text": "student from Chicago and basically souped up his thesis and that's where Alpha fold comes from this amazing",
    "start": "313880",
    "end": "319160"
  },
  {
    "text": "technology from Deep Mind that can predict protein folding so there was a lot of theoretical work I had done as a",
    "start": "319160",
    "end": "324240"
  },
  {
    "text": "postto and I was talking to my adviser about some of the stuff they were doing in protein folding way back before Alpha fold was released I thought you know I'm",
    "start": "324240",
    "end": "330479"
  },
  {
    "text": "I think I'd like to try my shot at doing research again and see if I can develop some theory that would allow me to",
    "start": "330479",
    "end": "338440"
  },
  {
    "text": "understand why deep learning works and that project you know it's been about seven years now of research and that's",
    "start": "338440",
    "end": "344840"
  },
  {
    "text": "led to the Weight Watcher tool cool so like it it's probably very typical for people to think about you know oh I'm",
    "start": "344840",
    "end": "351880"
  },
  {
    "text": "going to evaluate my model I have a test set but could you describe a little bit about two things one is like why from",
    "start": "351880",
    "end": "359680"
  },
  {
    "text": "your perspective at least in certain situations like a test set doesn't give",
    "start": "359680",
    "end": "364880"
  },
  {
    "text": "you the the indication of of behavior that that you're or behavior performance",
    "start": "364880",
    "end": "370800"
  },
  {
    "text": "of a model that that you're wanting and then how that connected to these things from from the physics world right so",
    "start": "370800",
    "end": "377680"
  },
  {
    "text": "let's say we're training a model to generate text there's no test set right you have to read the text and ask okay",
    "start": "377680",
    "end": "384039"
  },
  {
    "text": "does it look human or not and that's sort of where the first problem came is that there are many problems in",
    "start": "384039",
    "end": "390120"
  },
  {
    "text": "generating when you're generating things another would be let's say you're doing search relevance I'm trying to predict",
    "start": "390120",
    "end": "396800"
  },
  {
    "text": "what somebody wants to click on on I have clients like Walmart for example we build these systems for them it's very",
    "start": "396800",
    "end": "402520"
  },
  {
    "text": "expensive to run an AB test so you can test things in the lab and you can like make a model like an SPM model to",
    "start": "402520",
    "end": "408280"
  },
  {
    "text": "predict what people will click on but you don't really know how it's going to perform until you put in production and there are all sorts of biases that that",
    "start": "408280",
    "end": "415000"
  },
  {
    "text": "exist in the data because there's like presentation bias people tend to click on things that are in the element and",
    "start": "415000",
    "end": "420280"
  },
  {
    "text": "that screws the model up so there are many cases another good example is in quantitative Finance when you're trying",
    "start": "420280",
    "end": "426120"
  },
  {
    "text": "to predict the stock market and you have models where you would like to train some neural network to learn something",
    "start": "426120",
    "end": "431599"
  },
  {
    "text": "about how the news predicts the market but if you train it directly on the market you'll overfitted always and so",
    "start": "431599",
    "end": "437280"
  },
  {
    "text": "you have to have some way of evaluating whether your models are converging properly or not without just looking at",
    "start": "437280",
    "end": "444800"
  },
  {
    "text": "the out of sample you know test sample you don't a lot of data is out of sample or you don't you can't really evaluate",
    "start": "444800",
    "end": "451000"
  },
  {
    "text": "it without human judgments or it's very expensive would you would it kind of would infer that we're that we're",
    "start": "451000",
    "end": "456479"
  },
  {
    "text": "probably seeing a lot of practitioners running into these kinds of issues over time and you know in a lot of cases as",
    "start": "456479",
    "end": "464520"
  },
  {
    "text": "you know if you look over the last few years as everyone's kind of ramped up in the space and and been learning how to",
    "start": "464520",
    "end": "469800"
  },
  {
    "text": "do different types of deep learning training do you think that in terms of those accuracy issues that a lot of",
    "start": "469800",
    "end": "475960"
  },
  {
    "text": "practitioners are kind of missing it uh altogether uh or do you think they know that it's there and they just don't know",
    "start": "475960",
    "end": "481560"
  },
  {
    "text": "how to solve it or can you layer the land with it well let me give you an example let me give you an example there's a recent paper that came out of",
    "start": "481560",
    "end": "487120"
  },
  {
    "text": "Google Deep Mind on the the scaling properties of very large language models",
    "start": "487120",
    "end": "492360"
  },
  {
    "text": "and it showed that what we thought we knew about large language models from two years ago from open AI a paper that",
    "start": "492360",
    "end": "498039"
  },
  {
    "text": "they wrote was totally wrong they misunderstood how the scaling properties work and the question is things like",
    "start": "498039",
    "end": "505360"
  },
  {
    "text": "when you have a model and you're trying to train it should you be trying to optimize the hyper parameters or should you be adding more data you can think of",
    "start": "505360",
    "end": "512039"
  },
  {
    "text": "it like in that sort of very crude sense you know you're trying to train these models and essentially what was happening in open AIS are training these",
    "start": "512039",
    "end": "518680"
  },
  {
    "text": "large language models and they didn't realize that they should be adapting the learning rate to the data set size and",
    "start": "518680",
    "end": "524360"
  },
  {
    "text": "when you change the when you adapt the learning rate to the data set size you get very very different results than if",
    "start": "524360",
    "end": "529680"
  },
  {
    "text": "you don't and it looks like and we know that a lot of these large language models like Bert for example are just",
    "start": "529680",
    "end": "535320"
  },
  {
    "text": "not properly converged there are a large number of layers that are simply undertrained and I I think that",
    "start": "535320",
    "end": "542200"
  },
  {
    "text": "basically there's the theory that people are using there's no way to look at a model and ask how close do you are you",
    "start": "542200",
    "end": "548000"
  },
  {
    "text": "to conversions if you think about something like an spvm let's go back you know I'm an old guy let's go back 10 15",
    "start": "548000",
    "end": "553279"
  },
  {
    "text": "years ago we run spms there's something called The Duality Gap you can look at The Duality Gap in an SPM and you can",
    "start": "553279",
    "end": "559000"
  },
  {
    "text": "ask how close are you to the bottom of the of the you know you have it's a convex optimization problem and you can",
    "start": "559000",
    "end": "564120"
  },
  {
    "text": "tell how close is your solver to actually being at the optimal solution",
    "start": "564120",
    "end": "569440"
  },
  {
    "text": "you can tell that that's that's theoretically known so it's somewhat puzzling that you know now you have sort",
    "start": "569440",
    "end": "575240"
  },
  {
    "text": "of deep learning people understand that deep learning is sort of like a convex optimization or rugged convex",
    "start": "575240",
    "end": "581440"
  },
  {
    "text": "optimization because they know you don't have you don't have local Minima and there's an issue that there are lots of",
    "start": "581440",
    "end": "586680"
  },
  {
    "text": "Saddle points but no local Minima but yet there's no Theory which tells you whether you're converged or not and and",
    "start": "586680",
    "end": "592120"
  },
  {
    "text": "and so it's like what what what's going on so people are trying to solve this and I think this is where you know you",
    "start": "592120",
    "end": "597560"
  },
  {
    "text": "you you start training a model and you don't know have you have you trained it enough do you need to train it more let me give you a really practical example",
    "start": "597560",
    "end": "604200"
  },
  {
    "text": "which we have with we have a user who's using Weight Watcher to train semisupervised models to determine",
    "start": "604200",
    "end": "611640"
  },
  {
    "text": "whether the land you own is qualifies for carbon credits right so they're trying to can we use AI to help with",
    "start": "611640",
    "end": "618160"
  },
  {
    "text": "climate change and one of the biggest problems they have is how much data should we add to the model we have a",
    "start": "618160",
    "end": "623200"
  },
  {
    "text": "model we have data acquiring data acquiring good high quality labeled data",
    "start": "623200",
    "end": "629320"
  },
  {
    "text": "data is very very expensive you could easily spend millions of dollars on a data set maybe 10 million I know guys",
    "start": "629320",
    "end": "635839"
  },
  {
    "text": "self-driving car companies will spend easily $10 million on a data set so it would be nice to know given the model",
    "start": "635839",
    "end": "642320"
  },
  {
    "text": "that you have do you need to if you add more data to it will it help so we can answer that question with Weight Watcher",
    "start": "642320",
    "end": "648160"
  },
  {
    "text": "if you can kind of talk a little bit about some of the underlying because you're pointing out that there's a lot of opportunity for people to not be",
    "start": "648160",
    "end": "655120"
  },
  {
    "text": "optimal in their approaches and kind of miss some of the so it almost raises almost raises kind of a bigger issue",
    "start": "655120",
    "end": "661440"
  },
  {
    "text": "that we may have as a community if if if that's the case in terms of like how do we solve some of those problems in the",
    "start": "661440",
    "end": "667839"
  },
  {
    "text": "large uh aside from the specific tools you know what what what are your what are you thinking in terms of like how",
    "start": "667839",
    "end": "673760"
  },
  {
    "text": "should people approach these problems different well look I I think the first thing you have to ask is I'm beginning to train a model is my model big enough",
    "start": "673760",
    "end": "681399"
  },
  {
    "text": "is it small enough do I really want to spend millions of dollars doing Brute Force hyperparameter tuning you know",
    "start": "681399",
    "end": "687120"
  },
  {
    "text": "should I be tuning the like here's a basic question comes up with every client I have a model forget about deep",
    "start": "687120",
    "end": "692240"
  },
  {
    "text": "learning askm should I add more data or should I add more features let's say I have XD boost should add more data add",
    "start": "692240",
    "end": "698720"
  },
  {
    "text": "more features or do more hyperparameter tuning it's all expensive what direction do you go and you know there is a it's a",
    "start": "698720",
    "end": "706639"
  },
  {
    "text": "difficult these are difficult problems and if you add more data is the data the right quality is the data mislabeled are",
    "start": "706639",
    "end": "713760"
  },
  {
    "text": "there duplicates in the data is the data too similar to the data you've already added is it too different different from",
    "start": "713760",
    "end": "719519"
  },
  {
    "text": "the data you already added basic questions we just don't have mean very very basic broad level questions that we",
    "start": "719519",
    "end": "725120"
  },
  {
    "text": "have almost no answers to everything is Brute Force you know if you want to train a neural network you you go out",
    "start": "725120",
    "end": "730240"
  },
  {
    "text": "and you get weights and biases or you go to Google cloud and you just spend a fortune on hyperparameter tuning do you",
    "start": "730240",
    "end": "736560"
  },
  {
    "text": "really have to do that or isn't there something better you could do here here's another example when we started",
    "start": "736560",
    "end": "742120"
  },
  {
    "text": "this project there were maybe 50 open- Source pre-trained models right open source models right vgg the vgg resnet",
    "start": "742120",
    "end": "750000"
  },
  {
    "text": "things like that you go to hugging face now they're over 50,000 which one do you pick should you pick Bert or something",
    "start": "750000",
    "end": "756880"
  },
  {
    "text": "else everyone uses Bert Bert is highly under is highly under optimized if you compare Bert to Exel Nets EXL net is",
    "start": "756880",
    "end": "764519"
  },
  {
    "text": "much much better not only to the do the academic papers show that Excel net performs better on at least 20 different",
    "start": "764519",
    "end": "770000"
  },
  {
    "text": "metrics you can use Weight Watcher I have a blog post this you can see that it's just night and day between Exel net",
    "start": "770000",
    "end": "776160"
  },
  {
    "text": "and Bert but is it worth the money to spend the try to optimize EXL net why does everybody focus on Bert because it",
    "start": "776160",
    "end": "782000"
  },
  {
    "text": "has a cute name and it's made by Google I mean you know it's really hard to know which model to pick and it's hard these",
    "start": "782000",
    "end": "788480"
  },
  {
    "text": "models are very hard to improve if you're trying so there are a lot of just broad open questions like this which",
    "start": "788480",
    "end": "793839"
  },
  {
    "text": "model do I pick how much data should I add how do I evaluate the quality of my data do I really need to do Brute Force",
    "start": "793839",
    "end": "800920"
  },
  {
    "text": "searching on everything if I put something into production how do I know if the model doesn't it it breaks I",
    "start": "800920",
    "end": "807600"
  },
  {
    "text": "don't know if you guys worked in production environments I work in environments where things break every six weeks it's you know Thanksgiving",
    "start": "807600",
    "end": "813160"
  },
  {
    "text": "comes model's broken Christmas morning model's broken how do you monitor these things so I think I think we're in our I",
    "start": "813160",
    "end": "819279"
  },
  {
    "text": "think machine learning and certainly AI is in the infancy of engineering certainly compared to where we are in",
    "start": "819279",
    "end": "825360"
  },
  {
    "text": "software engineering 20 years behind we're software [Music]",
    "start": "825360",
    "end": "838040"
  },
  {
    "text": "engineering [Music]",
    "start": "838040",
    "end": "844130"
  },
  {
    "text": "[Music] so Charles I I definitely um uh it's",
    "start": "847260",
    "end": "854320"
  },
  {
    "text": "it's interesting kind of these I guess scenarios that you bring up because it's it's definitely something that happens I",
    "start": "854320",
    "end": "860440"
  },
  {
    "text": "mean sometimes uh in a in an actual real world setting like with my team it's",
    "start": "860440",
    "end": "865680"
  },
  {
    "text": "like we have what data we have what model is appropriate that fits that level of data right or maybe you have a",
    "start": "865680",
    "end": "872880"
  },
  {
    "text": "whole bunch of data and the question is do I need all of it for this you know model that I've already kind of decided",
    "start": "872880",
    "end": "878880"
  },
  {
    "text": "on or all all of these sorts of things and then you get to the to the training questions that you've that you brought",
    "start": "878880",
    "end": "884440"
  },
  {
    "text": "up I'm wondering if you could just give us a sort of highlevel overview of",
    "start": "884440",
    "end": "890199"
  },
  {
    "text": "because I think the main thing that that uh if I'm understanding right the main kind of tool that's come out of this",
    "start": "890199",
    "end": "895800"
  },
  {
    "text": "train of research that you've been working on is the Weight Watcher tool um could you just give us a kind of broad",
    "start": "895800",
    "end": "901199"
  },
  {
    "text": "overview of what the tool actually like functionally does and where it fits into",
    "start": "901199",
    "end": "908320"
  },
  {
    "text": "into a researcher or a developer or a data scientist workflow sure so the tool",
    "start": "908320",
    "end": "916079"
  },
  {
    "text": "can be used both when you're trying to train models AI models or you're trying to monitor them in production from a",
    "start": "916079",
    "end": "922279"
  },
  {
    "text": "training perspective it the tool gives you insights into whether your model has",
    "start": "922279",
    "end": "927959"
  },
  {
    "text": "converged and it does so on a layer by layer basis so I'm not aware of any",
    "start": "927959",
    "end": "933199"
  },
  {
    "text": "other technology that allows you to look at the layers of a neural network and ask has one layer converged and has",
    "start": "933199",
    "end": "939120"
  },
  {
    "text": "another layer not converged so there there are cues you can look at you can look at something called the alpha",
    "start": "939120",
    "end": "944440"
  },
  {
    "text": "metric which is the amount of correlation in the model and if the alpha usually if you have a computer vision model your Alpha should be down",
    "start": "944440",
    "end": "951519"
  },
  {
    "text": "around two in natural language processing Transformer models Alpha should be between three and four if your",
    "start": "951519",
    "end": "958440"
  },
  {
    "text": "Alphas are larger than that chances are the layer is not properly trained you can then visualize each layer and you",
    "start": "958440",
    "end": "965680"
  },
  {
    "text": "can look at the layer it's correlation structure and that correlation structure should be fairly smooth it should be",
    "start": "965680",
    "end": "972360"
  },
  {
    "text": "linear and smooth on a log log plot if it's choppy or has sort of a strange shape to it something's wrong if your",
    "start": "972360",
    "end": "979600"
  },
  {
    "text": "layers have lots of rank collapse so lots of zero ion values something's wrong we've identified something called",
    "start": "979600",
    "end": "985800"
  },
  {
    "text": "a correlation trap which is in deep learning language would be you have to",
    "start": "985800",
    "end": "991199"
  },
  {
    "text": "you didn't clip your weight matrices you didn't regularize the that layer correctly so you can use the the tool",
    "start": "991199",
    "end": "998120"
  },
  {
    "text": "during the training of a neural network to monitor the training you can find layers that are basically broken they're",
    "start": "998120",
    "end": "1004360"
  },
  {
    "text": "not trained correctly think of like you're building a you know you're building a house and there are you know cracks in the bricks you know you put a",
    "start": "1004360",
    "end": "1011240"
  },
  {
    "text": "brick in the CRA it's cracked you need to replace it you can adjust regularization up and down on the layer you can adjust learning rate up and down",
    "start": "1011240",
    "end": "1018000"
  },
  {
    "text": "on the layer you might find that when you're training a model some layers are beginning to they're well trained and",
    "start": "1018000",
    "end": "1024079"
  },
  {
    "text": "they begin to overfit so you might want to freeze them so you can freeze so as people talk about early stopping I talk",
    "start": "1024079",
    "end": "1029760"
  },
  {
    "text": "about early freezing so you might freeze some of the early layers and let the later layers converge so Weight Watcher",
    "start": "1029760",
    "end": "1035720"
  },
  {
    "text": "allows you to do all of this by as a mo you know it's it's very much a you have to do it by hand you have to go in and",
    "start": "1035720",
    "end": "1041760"
  },
  {
    "text": "visualize it and see what's going on but it allows you to inspect your models to determine whether they're trained correctly it also allows you to look at",
    "start": "1041760",
    "end": "1048600"
  },
  {
    "text": "model in production so if you're deploying AI models in production and you know maybe you're retraining your",
    "start": "1048600",
    "end": "1054400"
  },
  {
    "text": "models regularly you want it would allow you to gives you like a warning flag like a model alert system that would tell you hey you broke this layer we",
    "start": "1054400",
    "end": "1061280"
  },
  {
    "text": "have an example in our paper we have a paper in nature where we show that in one of the Intel systems they applied a",
    "start": "1061280",
    "end": "1068240"
  },
  {
    "text": "data compression algorithm to compress the model to go on the hardware and they screwed up one of the layers and you can",
    "start": "1068240",
    "end": "1073280"
  },
  {
    "text": "see this with Weight Watcher it will flag it for you so while you're so as you're deploying models in production it",
    "start": "1073280",
    "end": "1079280"
  },
  {
    "text": "can monitor them for you and remember it doesn't require any data so it's a very light very light touch you know very",
    "start": "1079280",
    "end": "1084480"
  },
  {
    "text": "simple integration to integrate into your M your Al Ops monitoring pipelines",
    "start": "1084480",
    "end": "1089760"
  },
  {
    "text": "I think of it's sort of like an AI uptime tool it allow it gives you like an early warning and you so this is how",
    "start": "1089760",
    "end": "1095559"
  },
  {
    "text": "you use the tool you can use it during training to make sure your models are converging well or they haven't",
    "start": "1095559",
    "end": "1100919"
  },
  {
    "text": "converged properly you go back and fix them or you can use them after training in production to monitor for problems so",
    "start": "1100919",
    "end": "1107440"
  },
  {
    "text": "I was kind of trying to think of analogies in my head while while you were talking and and you gave a good one",
    "start": "1107440",
    "end": "1112480"
  },
  {
    "text": "in terms of the the house and and and the cracks one of the things I was thinking about like you mentioned um you",
    "start": "1112480",
    "end": "1118240"
  },
  {
    "text": "mentioned Bert earlier which no doubt in in the sort of time when Bert came out it was quite an advancement and like",
    "start": "1118240",
    "end": "1125720"
  },
  {
    "text": "many people have built amazing things on on Bert but I was thinking about like",
    "start": "1125720",
    "end": "1131640"
  },
  {
    "text": "that and where we've come from there and and also thinking about uh my wife owns a manufacturing business and they've got",
    "start": "1131640",
    "end": "1137880"
  },
  {
    "text": "this principle in manufacturing about find the current biggest bottleneck in your process right address that as soon",
    "start": "1137880",
    "end": "1145120"
  },
  {
    "text": "as you address that there's going to be a next biggest bottleneck that you address next right and you kind of just",
    "start": "1145120",
    "end": "1150320"
  },
  {
    "text": "keep working your way through so I'm wondering like Bert obviously is a a good advance but then like you can",
    "start": "1150320",
    "end": "1156480"
  },
  {
    "text": "analyze that model and see maybe where the next biggest sort of offending area is and kind of address that and I was",
    "start": "1156480",
    "end": "1163600"
  },
  {
    "text": "also thinking about the tool that you were mentioning all the things you could do with it you could probably analyze",
    "start": "1163600",
    "end": "1169799"
  },
  {
    "text": "your model in development for years you know fixing all sorts of things and doing all sorts of things right but at",
    "start": "1169799",
    "end": "1176679"
  },
  {
    "text": "some point you have to ship your model right so maybe there's this process of and I'm wondering your thoughts on this",
    "start": "1176679",
    "end": "1182799"
  },
  {
    "text": "of like you using the tool to find sort of these like worst offending parts of your model addressing those and maybe",
    "start": "1182799",
    "end": "1190520"
  },
  {
    "text": "like at a certain point you get to a point of diminishing returns or something like that right yeah th this",
    "start": "1190520",
    "end": "1195840"
  },
  {
    "text": "is a corar grain tool it's not meant to go in and study epic by epic and try to",
    "start": "1195840",
    "end": "1200880"
  },
  {
    "text": "fine-tune exactly what's going on that that's exact I'm really glad you brought this up Daniel because you some you work",
    "start": "1200880",
    "end": "1206400"
  },
  {
    "text": "with the academics and they we want to use it as a regularizer you want to optimize the loss no no no that's not",
    "start": "1206400",
    "end": "1212400"
  },
  {
    "text": "that puts an engineering tool it's an engineering tool it's designed to go in and find out where the cracks are so if",
    "start": "1212400",
    "end": "1218240"
  },
  {
    "text": "you're I don't know if you guys in San Francisco you know about the Millennium Tower yeah so my little nephew he's he's",
    "start": "1218240",
    "end": "1223320"
  },
  {
    "text": "all into construction and he's always talking about they got to tear the Millennium Tower down tear it down junk",
    "start": "1223320",
    "end": "1228760"
  },
  {
    "text": "it cuz it has a they built this Tower and it's like the leaning tower of Bea it's tilting and if you go into the",
    "start": "1228760",
    "end": "1234400"
  },
  {
    "text": "basement of the Millennium Tower and this is like you know like condos like multi-million dollar condos you know I think probably like you know the Marissa",
    "start": "1234400",
    "end": "1241200"
  },
  {
    "text": "Meer May own a condo there I mean it's ridiculous and they built this thing and downstairs you look and there are cracks",
    "start": "1241200",
    "end": "1247080"
  },
  {
    "text": "in in the steel it's like guys the thing's gonna it's it's gonna fall down it's cracked and it's like this is what",
    "start": "1247080",
    "end": "1253280"
  },
  {
    "text": "Weight Watcher does you go into your models and ask are there gross problems that should not be there right right",
    "start": "1253280",
    "end": "1259320"
  },
  {
    "text": "this layer is overtrained this layer suggests that the data is mislabeled this layer has a correlation trap this",
    "start": "1259320",
    "end": "1266280"
  },
  {
    "text": "is what you're trying to do and and you know frequently in engineering you're under time constraint so you know you",
    "start": "1266280",
    "end": "1271600"
  },
  {
    "text": "got to get this thing out and into production you want to make sure it's it's not crazy and it allows you to",
    "start": "1271600",
    "end": "1276720"
  },
  {
    "text": "Weight Watcher allows you to detect problems that you canot detect in any other way and that's the key it allows",
    "start": "1276720",
    "end": "1283159"
  },
  {
    "text": "you to find a major problem so one of the things I was want to ask you uh because you you said something a moment ago and kind of circling back to that",
    "start": "1283159",
    "end": "1289880"
  },
  {
    "text": "that I'm I'm very curious about to bring me and other people in our audience along that may not be as familiar with",
    "start": "1289880",
    "end": "1295480"
  },
  {
    "text": "that I often rely on Daniel's expertise on this and I want to rely on yours on this you mentioned when we're talking",
    "start": "1295480",
    "end": "1301279"
  },
  {
    "text": "about you know kind of testing those layers as you did going back to the alpha and you specified you know for you",
    "start": "1301279",
    "end": "1307960"
  },
  {
    "text": "know ranges of of two uh for for the visual and the the three to four for like natural language models and stuff",
    "start": "1307960",
    "end": "1314080"
  },
  {
    "text": "I'm assuming that that's one of the mechanisms that you're using in the software can you talk a little bit about",
    "start": "1314080",
    "end": "1320400"
  },
  {
    "text": "what are the other mechanisms that are there along with that and maybe how alpha is used like what if somebody is",
    "start": "1320400",
    "end": "1325840"
  },
  {
    "text": "not familiar with that concept what is it about Alpha that's identifying that so that they understand that a",
    "start": "1325840",
    "end": "1332000"
  },
  {
    "text": "particular layer might be brittle in the sense if it's not fully converged you know how are you approaching that kind",
    "start": "1332000",
    "end": "1338120"
  },
  {
    "text": "of bring us along to try to catch us up with you on on how you're thinking about that on a like why does it work yeah why",
    "start": "1338120",
    "end": "1343960"
  },
  {
    "text": "does it work what is it what is it about Alpha and other things that you're using in the software that yield that level of",
    "start": "1343960",
    "end": "1349919"
  },
  {
    "text": "insight that you're describing so what we know from where does deep learning work deep learning works on Natural",
    "start": "1349919",
    "end": "1356000"
  },
  {
    "text": "Things natural images Voice Text things that are really part of the natural",
    "start": "1356000",
    "end": "1363320"
  },
  {
    "text": "world and the natural world exhibits a multif fractal structure you if you look at a tree you know if you remember like",
    "start": "1363320",
    "end": "1369080"
  },
  {
    "text": "the L systems from computer science or you know some of mandle BRS work most natural systems have or just think about",
    "start": "1369080",
    "end": "1375640"
  },
  {
    "text": "text you know zip flaws you know power law structure in text and documents all natural data has a power law structure a",
    "start": "1375640",
    "end": "1382960"
  },
  {
    "text": "fractal structure to it and when you the way neural networks learn is they learn the multifractal the multifractal nature",
    "start": "1382960",
    "end": "1390679"
  },
  {
    "text": "of the data and that that's why they work so well on things like text and images and why they don't work great on tabular data sets so what you're doing",
    "start": "1390679",
    "end": "1398400"
  },
  {
    "text": "is there are correlations in the data data's correlated you're trying to learn the correlations and frequently you're",
    "start": "1398400",
    "end": "1403559"
  },
  {
    "text": "trying to learn very subtle correlations you couldn't find in some other way you know using some simple clustering",
    "start": "1403559",
    "end": "1409679"
  },
  {
    "text": "algorithm or or or an svm or something like that so what we're doing is we're measuring the fractal nature of the data",
    "start": "1409679",
    "end": "1416400"
  },
  {
    "text": "and every layer of a neural network gives you some measure of the fractal properties in that level of granularity",
    "start": "1416400",
    "end": "1423679"
  },
  {
    "text": "and so Alpha is like a measure of the fractal Dimension and and what we know is that it measures the amount of",
    "start": "1423679",
    "end": "1429480"
  },
  {
    "text": "correlation in that layer in other words you're learning the data is obviously not random it can't be random you're",
    "start": "1429480",
    "end": "1435760"
  },
  {
    "text": "learning you're trying to learn patterns so what we've disc discovered empirically and we and there's some deep theoretical reasons for this but",
    "start": "1435760",
    "end": "1442200"
  },
  {
    "text": "qualitatively what's happening is you're you're learning the natural patterns in the data and those patterns you know",
    "start": "1442200",
    "end": "1448120"
  },
  {
    "text": "they have to be there so if you're looking at Text data and you start seeing Alphas around six or seven or eight the layer hasn't learn the",
    "start": "1448120",
    "end": "1454880"
  },
  {
    "text": "correlations it just didn't learn anything and it's just sort of there or it learned it the correlations are so",
    "start": "1454880",
    "end": "1460279"
  },
  {
    "text": "weak that's it's not really contributing to anything so you just B and we know that that many of these models are just have these extra layers they're way",
    "start": "1460279",
    "end": "1466399"
  },
  {
    "text": "overparameterized you know and they're you know so that that's that's what's happening and and if the correlations if",
    "start": "1466399",
    "end": "1472360"
  },
  {
    "text": "there are strange or spous correlations there are things that that cause Alpha to be small for spous reasons like you",
    "start": "1472360",
    "end": "1479720"
  },
  {
    "text": "know you didn't regularize your layer correctly and so there's a giant weight Matrix like you have you didn't clip the",
    "start": "1479720",
    "end": "1485120"
  },
  {
    "text": "weight Matrix elements so the regularizer failed so it can detect the difference between when there are",
    "start": "1485120",
    "end": "1490559"
  },
  {
    "text": "problems with the optimizer and when there's actual natural structure in the data and it allows you to distinguish",
    "start": "1490559",
    "end": "1496120"
  },
  {
    "text": "between these two that's what it's doing am I correct just just for uh for clarity sake in terms of when when we",
    "start": "1496120",
    "end": "1502760"
  },
  {
    "text": "say like it's doing this without the test data or the or the training data really you're doing these calculations",
    "start": "1502760",
    "end": "1509320"
  },
  {
    "text": "and you're detecting these these parameters these metrics based on the",
    "start": "1509320",
    "end": "1514760"
  },
  {
    "text": "weight matrices right is that correct yes only on the weight matrices we don't you don't need to look",
    "start": "1514760",
    "end": "1521520"
  },
  {
    "text": "at the data so in that case is it uh like the tool itself in terms of how",
    "start": "1521520",
    "end": "1527120"
  },
  {
    "text": "people would run it because it's doing these Matrix calculations is is it",
    "start": "1527120",
    "end": "1532279"
  },
  {
    "text": "necessary like could you speak to like the computational of it and like am I gon",
    "start": "1532279",
    "end": "1538520"
  },
  {
    "text": "spend am i g to spend five hours waiting for Weight Watcher to analyze my model or is it going to happen in 5 seconds",
    "start": "1538520",
    "end": "1544440"
  },
  {
    "text": "the current model right now it depends on the size it runs a singular value decomposition on each layer so that's a",
    "start": "1544440",
    "end": "1550399"
  },
  {
    "text": "g that's a high memory GPU CPU level it's a high memory",
    "start": "1550399",
    "end": "1555600"
  },
  {
    "text": "CPU intensive task it doesn't it's not optimized for gpus so you run a normal",
    "start": "1555600",
    "end": "1560679"
  },
  {
    "text": "CPU it does require some memory most layers aren't too large so it could take anywhere from a couple minutes to an",
    "start": "1560679",
    "end": "1566120"
  },
  {
    "text": "hour if you're trying to run on GPT and you have a thousand layers it's GNA take some time right if you just have a few",
    "start": "1566120",
    "end": "1572080"
  },
  {
    "text": "layers in your model and you're training like a small model it's it's it's very very fast you know generally you would",
    "start": "1572080",
    "end": "1577919"
  },
  {
    "text": "hope that it is faster than an Epoch in training but it it's not GPU optimized",
    "start": "1577919",
    "end": "1583559"
  },
  {
    "text": "so one of the things we're working on I'd like to if I commercialize the product is to make a version that's very very fast it's like it would like",
    "start": "1583559",
    "end": "1589399"
  },
  {
    "text": "distribute all the calculation on the nodes and come back to you so that's the kind of like it from so this is an open source tool but it it runs a simple SVD",
    "start": "1589399",
    "end": "1597200"
  },
  {
    "text": "calculation so it's a little computer intensive but again sort of my my theory on this is that if you're training small",
    "start": "1597200",
    "end": "1603640"
  },
  {
    "text": "models it's pretty fast if you're training really really big models well you're going to have the you you chances",
    "start": "1603640",
    "end": "1609320"
  },
  {
    "text": "are you have the compute resources anyway and you're not renting a GPU for it you don't need the GPU even though it can run it so that's that's sort of the",
    "start": "1609320",
    "end": "1617240"
  },
  {
    "text": "takeaway [Music]",
    "start": "1617240",
    "end": "1654039"
  },
  {
    "text": "well Charles I uh I mean when I first saw the the tool I was very interested in it and um I did take time to go ahead",
    "start": "1654039",
    "end": "1661880"
  },
  {
    "text": "and just pull pull it in one of my notebooks and and look at one of look at one of my own models uh because I wanted",
    "start": "1661880",
    "end": "1667399"
  },
  {
    "text": "I did want to get hands- on with it was a question answering model based on xlm",
    "start": "1667399",
    "end": "1673399"
  },
  {
    "text": "Berta and I analyzed it with Weight Watcher I did not do every single thing",
    "start": "1673399",
    "end": "1680200"
  },
  {
    "text": "that you describe on your on your repo CU I I'm still you know dipping dipping my toes right I I gu great I it ran it",
    "start": "1680200",
    "end": "1687600"
  },
  {
    "text": "actually it ran yeah and uh so it's a pie torch based model it ran I I didn't time it so I don't know exactly how long",
    "start": "1687600",
    "end": "1694360"
  },
  {
    "text": "but uh I did find out at least I found out according to Weight Watcher 10 10 of",
    "start": "1694360",
    "end": "1699799"
  },
  {
    "text": "my layers are undertrained so that could be yeah I I I at least found found that",
    "start": "1699799",
    "end": "1705080"
  },
  {
    "text": "out so could you speak a little bit about like the tool itself uh so you",
    "start": "1705080",
    "end": "1710880"
  },
  {
    "text": "mentioned like how people can integrate it in their workflows could you mention a little bit more about the open source",
    "start": "1710880",
    "end": "1716880"
  },
  {
    "text": "project and like how people like if I'm like I did and I want to do this on one",
    "start": "1716880",
    "end": "1722679"
  },
  {
    "text": "of my models how how would I go about doing it and how easy is it to to get it running on a Model well you know this is",
    "start": "1722679",
    "end": "1728880"
  },
  {
    "text": "just it's a tool I've been writing in my spare time based on my research there's no funding for any of this I published",
    "start": "1728880",
    "end": "1734039"
  },
  {
    "text": "with UC Berkeley but they're not funding any of this they're just sort of like I'm just they're just kind of helped me out a bit i' I've written it all myself",
    "start": "1734039",
    "end": "1740960"
  },
  {
    "text": "uh it's all open so I have one of my staff guys helped me out early on pep install Weight Watcher the way it's written now you probably need to have",
    "start": "1740960",
    "end": "1747039"
  },
  {
    "text": "both tensorflow and P torch installed in your in your environment if you want we can I can make a version that doesn't",
    "start": "1747039",
    "end": "1752919"
  },
  {
    "text": "require both of those I have no one's asked yet um one of the challenges I have with the tool is that I have 60,000",
    "start": "1752919",
    "end": "1758440"
  },
  {
    "text": "downloads I have no idea who's using it so if you're using the tool let me know so I can help you I don't know what",
    "start": "1758440",
    "end": "1764720"
  },
  {
    "text": "you're doing with it and I'm not going to SP you know I don't want to end up in feature creep where I design features in",
    "start": "1764720",
    "end": "1770360"
  },
  {
    "text": "the wild you know I need to know what you're doing so if you tell me I'll help you we have a slack Channel you can go",
    "start": "1770360",
    "end": "1775640"
  },
  {
    "text": "on slack and you can ask me and I'll help you but basically it's pep install Weight Watcher and you just give it a",
    "start": "1775640",
    "end": "1781399"
  },
  {
    "text": "model you say weight your Watcher equals Weight Watcher model equals my model and you say Watcher do analyze that's it and",
    "start": "1781399",
    "end": "1787799"
  },
  {
    "text": "it will return a data frame with quality metrics if you say Watcher do analyze plot equals true it will generate a",
    "start": "1787799",
    "end": "1793760"
  },
  {
    "text": "bunch of plots it will generate the plots it's meant to be I've been running it in jupyter notebook that's how I run",
    "start": "1793760",
    "end": "1799320"
  },
  {
    "text": "it in principle you could run it in a production environment um again it's",
    "start": "1799320",
    "end": "1804559"
  },
  {
    "text": "really a very it's not even an an alpha one tool yet it's still like 0.56 0.57",
    "start": "1804559",
    "end": "1810640"
  },
  {
    "text": "so you know if you do that reach out to me you know we can make a version that's more stable if you need to run it in a",
    "start": "1810640",
    "end": "1816080"
  },
  {
    "text": "production environment but I've mostly been using it in it runs in the jupyter notebook you get a data frame you analyze the data frame you run a Google",
    "start": "1816080",
    "end": "1823080"
  },
  {
    "text": "collab notebook you say plot equals true it gives you a bunch of plots if you had some other op it'll give you more plots",
    "start": "1823080",
    "end": "1829200"
  },
  {
    "text": "and then you analyze the plots so let me ask you a question as as kind of a followup to what you and Daniel were just talking about if you're looking at",
    "start": "1829200",
    "end": "1836039"
  },
  {
    "text": "the workflow like and you so you know Daniel said there were like what 10 layers that had not converged you know",
    "start": "1836039",
    "end": "1842440"
  },
  {
    "text": "to sufficiently how does that change the workflow for someone who hasn't done what Daniel's done and gotten his hands",
    "start": "1842440",
    "end": "1848080"
  },
  {
    "text": "on someone just listening talk a little bit about what they were doing before versus the workflow they're doing now",
    "start": "1848080",
    "end": "1854360"
  },
  {
    "text": "now that they have the insights that Weight Watcher is bringing to it what does that look like for the practitioner Well here here's the first thing this is",
    "start": "1854360",
    "end": "1860559"
  },
  {
    "text": "exactly what happened with one of Michael's posts and students go back and look at the regularization did you did you add enough Dropout on your layer are",
    "start": "1860559",
    "end": "1867880"
  },
  {
    "text": "the learning rights too large do you not have enough data is your model just too big are the early agers converging in",
    "start": "1867880",
    "end": "1874399"
  },
  {
    "text": "the later if the later layers are not maybe you should freeze some of the earlier layers and give the later layers",
    "start": "1874399",
    "end": "1879679"
  },
  {
    "text": "time to converge maybe you need to run it longer you need to run SGD longer maybe you know maybe need to adjust some",
    "start": "1879679",
    "end": "1884799"
  },
  {
    "text": "of your hyper parameters because you're not getting tuned you know try to adjust your hyper parameter so Alpha goes down not that it goes up those are the kind",
    "start": "1884799",
    "end": "1891519"
  },
  {
    "text": "of things you need to do during training yeah so if you were maybe you could also mention the workflow I find it very",
    "start": "1891519",
    "end": "1898600"
  },
  {
    "text": "interesting what you were saying about like the workflow of potentially using this like within the training Loops as",
    "start": "1898600",
    "end": "1905000"
  },
  {
    "text": "well like as as you're training the model right so one thing you could do is definitely run your model right like I",
    "start": "1905000",
    "end": "1910799"
  },
  {
    "text": "did and then look at it afterwards and see oh shees I you know I need to do",
    "start": "1910799",
    "end": "1916080"
  },
  {
    "text": "something about this or that and then of course like then probably is the the harder part of the problem is connecting",
    "start": "1916080",
    "end": "1922840"
  },
  {
    "text": "with like okay does that mean I do one of those things you just mentioned or another one of those things you just",
    "start": "1922840",
    "end": "1928679"
  },
  {
    "text": "mentioned but what about that workflow like in the training Loop how how might that work I know that uh you know maybe",
    "start": "1928679",
    "end": "1936000"
  },
  {
    "text": "some people have heard of certain things related to like optimizing either uh not",
    "start": "1936000",
    "end": "1943240"
  },
  {
    "text": "doing brute force uh hyperparameter tuning but doing some sort of some like",
    "start": "1943240",
    "end": "1948679"
  },
  {
    "text": "automl type of stuff or or something like PE people have thought about these things so like when you're pulling",
    "start": "1948679",
    "end": "1955080"
  },
  {
    "text": "Weight Watcher into the training run how would you think about that being used if",
    "start": "1955080",
    "end": "1960440"
  },
  {
    "text": "you want to give Google Cloud a million dollars to do automl and then have them own your models for you and feed them",
    "start": "1960440",
    "end": "1966639"
  },
  {
    "text": "back to you knock yourself out I I don't want to do that I don't want to be trapped you know that's what that's what",
    "start": "1966639",
    "end": "1971760"
  },
  {
    "text": "the automail offering is it's an offering to blow millions of dollars or if you want to get some tool like H2O",
    "start": "1971760",
    "end": "1978000"
  },
  {
    "text": "and auto tune a model and then find out it doesn't scale and then you have to redo it we've had clients with that problem right I think it's uh there's",
    "start": "1978000",
    "end": "1985559"
  },
  {
    "text": "this wider field though of of sort of I guess metal learning and kind of",
    "start": "1985559",
    "end": "1990799"
  },
  {
    "text": "learning on on on that and and I don't know if this would fit like the Weight Watcher stuff would fit into that larger",
    "start": "1990799",
    "end": "1997880"
  },
  {
    "text": "space of research I guess but look what what are you trying to do like what what does it mean to be optimal if being",
    "start": "1997880",
    "end": "2003960"
  },
  {
    "text": "optimal means that your Alphas are close to two or three then you should adjust your hyper parameters such that the",
    "start": "2003960",
    "end": "2009399"
  },
  {
    "text": "alphas go down that's what you do now doing that analytically typically in doing what are called analytic",
    "start": "2009399",
    "end": "2015240"
  },
  {
    "text": "derivatives meaning you try to compute the gradient from that that's somewhat difficult it could be done because you",
    "start": "2015240",
    "end": "2021360"
  },
  {
    "text": "have to compute the igen value spectrum and then you have to fit it and then you have to figure out the derivative and that's a very complex nonlinear",
    "start": "2021360",
    "end": "2027880"
  },
  {
    "text": "calculation it's very iterative it could be done numerically or could be done analytically with some work it's a lot",
    "start": "2027880",
    "end": "2033120"
  },
  {
    "text": "of work I would love to have VC funding like hugging face to do that but I don't it's just me me and you so you just try",
    "start": "2033120",
    "end": "2039240"
  },
  {
    "text": "to tune your parameters Alpha goes up go the other way you know if you turn your learning rate up and you find your Alphas are going up tune the learning",
    "start": "2039240",
    "end": "2045159"
  },
  {
    "text": "rate the other way and hopefully they'll go down obviously it's a complex optimization problem because you have you know you have 100 layers you have",
    "start": "2045159",
    "end": "2051720"
  },
  {
    "text": "100 alphas and so you're trying to tune different layers and optim you know trying to tune your your layer learning",
    "start": "2051720",
    "end": "2058118"
  },
  {
    "text": "rates and your amount of Dropout and the amount of momentum so in principle you could try to do that algorithmically in",
    "start": "2058119",
    "end": "2064040"
  },
  {
    "text": "a way using like a basian type approach where you try to get your Alphas to go go down on every layer I mean it is in",
    "start": "2064040",
    "end": "2069480"
  },
  {
    "text": "principle you could do that but it's a complex you know complex optimization problem but that that's what I would",
    "start": "2069480",
    "end": "2074599"
  },
  {
    "text": "recommend and and I think it's it's theoretically well grounded I mean the point is that you want to learn more",
    "start": "2074599",
    "end": "2079878"
  },
  {
    "text": "correlations typically what I found is that it's a good tool for newbies because you get into a model you start",
    "start": "2079879",
    "end": "2086158"
  },
  {
    "text": "doing something things are totally wrong and you can go in and fix some problems okay now we fixed it we found like what",
    "start": "2086159",
    "end": "2091240"
  },
  {
    "text": "did we not do like I didn't put the proper regularization on these layers let me add regularization and try again",
    "start": "2091240",
    "end": "2097720"
  },
  {
    "text": "you can see that okay that's much better so from a newbie perspective it's a very good tool because it helps you get",
    "start": "2097720",
    "end": "2102880"
  },
  {
    "text": "started now it does work keep in mind the tool works at the end of training not in the early stages of training",
    "start": "2102880",
    "end": "2108720"
  },
  {
    "text": "you've got to let the thing bake for a while you know you can't it doesn't once it's about halfway through training then",
    "start": "2108720",
    "end": "2114079"
  },
  {
    "text": "you can start looking at things it's got to have some some correlations but this is what it's for typically and this is",
    "start": "2114079",
    "end": "2121000"
  },
  {
    "text": "sort of you know trying to do large scale meta learning would just meaning you'd have to integrate the tool into some sort of process that allows you you",
    "start": "2121000",
    "end": "2127920"
  },
  {
    "text": "to look at the Alphas or look at more details in the layer the shape of the spectral density the number of spikes",
    "start": "2127920",
    "end": "2134720"
  },
  {
    "text": "the alphas the the volume of the spectral density and figure out how to tune from that I mean this could even be",
    "start": "2134720",
    "end": "2140000"
  },
  {
    "text": "used in a reinforcement learning situation where the reward instead of the reward being something that you know",
    "start": "2140000",
    "end": "2146680"
  },
  {
    "text": "the the act the agent takes the reward is oh I got smaller Alpha so I have rewards on every layer and I sum the",
    "start": "2146680",
    "end": "2151960"
  },
  {
    "text": "rewards in some average way to try to get the optimizer to work even in situations where I don't know what the reward is for a re enforcement warning",
    "start": "2151960",
    "end": "2158440"
  },
  {
    "text": "situation obviously that's would be nice in areas like you're trying to trade in the markets because you can't take",
    "start": "2158440",
    "end": "2165359"
  },
  {
    "text": "actions that trade you you can't trade on historical data and expect to learn from that so this gives you a way of",
    "start": "2165359",
    "end": "2171720"
  },
  {
    "text": "sort of doing things in a supervised or semisupervised way um that doesn't require peing at the test data to",
    "start": "2171720",
    "end": "2177640"
  },
  {
    "text": "optimize and that that's I hope that answers the question that's sort of the idea and there are lots of things people",
    "start": "2177640",
    "end": "2182839"
  },
  {
    "text": "I think want to try I I think it's great if you try them yeah I mean I definitely appreciate you being transparent about",
    "start": "2182839",
    "end": "2189280"
  },
  {
    "text": "where where where the tool is and all that and and really the the possibilities that might happen with the",
    "start": "2189280",
    "end": "2195280"
  },
  {
    "text": "tool and kind of the there's a lot of opportunities to explore usage and and",
    "start": "2195280",
    "end": "2200319"
  },
  {
    "text": "further development part of the why I want to do with the tool is build an open source Community I can't do everything myself and there's lots of",
    "start": "2200319",
    "end": "2207280"
  },
  {
    "text": "things to do and if people want to get involved in a community join the slack Channel we can build things right that's",
    "start": "2207280",
    "end": "2212400"
  },
  {
    "text": "what open source is and I think there a lot of people may have ideas and will be able to contribute in ways that you know",
    "start": "2212400",
    "end": "2218720"
  },
  {
    "text": "just expanded and I think that it's again right now to me the way you train neural networks now it's like you build",
    "start": "2218720",
    "end": "2224880"
  },
  {
    "text": "a bridge you drive a car over the bridge you see if the bridge falls down and you do it again and again and again how many",
    "start": "2224880",
    "end": "2230119"
  },
  {
    "text": "cars are you gonna crash into the ocean until you get the bridge right no people don't build Bridges like that you know you build Bridges by having engineering",
    "start": "2230119",
    "end": "2237359"
  },
  {
    "text": "principles you understand here are the engineering principles that go in and this is the load it can take and this is the wind shear and you know you you try",
    "start": "2237359",
    "end": "2244319"
  },
  {
    "text": "to build bridges that actually stay up and right now I think deep learning is so Brute Force it's like you just spend",
    "start": "2244319",
    "end": "2249760"
  },
  {
    "text": "as much money as you can do as much Brute Force as you can and if it doesn't work you try it again and there's no",
    "start": "2249760",
    "end": "2255839"
  },
  {
    "text": "principles behind what you're doing and we're trying to add some s you know and",
    "start": "2255839",
    "end": "2261400"
  },
  {
    "text": "principles that are based in deep Theory like they're empirical rules of thumb but there's also deep theoretical",
    "start": "2261400",
    "end": "2267079"
  },
  {
    "text": "reasons why they work just just like in any other field of optimization I'm curious I'm kind of going back to the",
    "start": "2267079",
    "end": "2272839"
  },
  {
    "text": "the engineering and the kind of you know talking about you know as this matures much you know and trailing the software",
    "start": "2272839",
    "end": "2279040"
  },
  {
    "text": "engineering world but one of the one of the decisions that we all make as we're as Engineers that we're doing is kind of",
    "start": "2279040",
    "end": "2285560"
  },
  {
    "text": "like as we're creating open source community and we're trying to provide the value for that community that you're",
    "start": "2285560",
    "end": "2290880"
  },
  {
    "text": "talking about do you see the future as being Community specifically built around Weight Watcher or or is there an",
    "start": "2290880",
    "end": "2298760"
  },
  {
    "text": "opportunity potentially to add the value that Weight Watcher is bringing and the new those insights that you described",
    "start": "2298760",
    "end": "2304880"
  },
  {
    "text": "and roll them into some of the other existing community do you have do you have any opinions or or or you know",
    "start": "2304880",
    "end": "2311240"
  },
  {
    "text": "thoughts about how you integrate this in for the value of the larger Community well look I I think I'd like to have is",
    "start": "2311240",
    "end": "2317480"
  },
  {
    "text": "a community of people who are training models and getting them to interact with each other a lot of the people like I said it's hard to get feedback people",
    "start": "2317480",
    "end": "2323720"
  },
  {
    "text": "are doing things in industry and because they are constrained by ndas they can't",
    "start": "2323720",
    "end": "2329079"
  },
  {
    "text": "really talk about what they're doing and I think it gives people an opportunity to really get into the space and learn",
    "start": "2329079",
    "end": "2334640"
  },
  {
    "text": "how training of neural networks Works without being constrained by your employer or your contract so you can",
    "start": "2334640",
    "end": "2340560"
  },
  {
    "text": "really do that's a lot of what this is I think there are other communities doing things like people building",
    "start": "2340560",
    "end": "2346280"
  },
  {
    "text": "hyperparameter optimization tools or people building reinforcement running tools we'd be happy to integrate the",
    "start": "2346280",
    "end": "2351800"
  },
  {
    "text": "tool in the challenge is always you know you want to make a tool that is self-contained you know if people Fork",
    "start": "2351800",
    "end": "2357680"
  },
  {
    "text": "the tool and begin changing it it ends up I don't know if you guys know the story of emx I was at champagne Nana",
    "start": "2357680",
    "end": "2363280"
  },
  {
    "text": "when this happened you know they wanted to port emac to basically x windows and stalman didn't want to do it and they",
    "start": "2363280",
    "end": "2369400"
  },
  {
    "text": "forked it you have XX you have emac it killed it you know forking emac killed it because you have the XX crowd and and",
    "start": "2369400",
    "end": "2375240"
  },
  {
    "text": "you know these guys went off and start Netscape and you know probably all retired now or they're sitting at the top of you know hang out with the roof",
    "start": "2375240",
    "end": "2381160"
  },
  {
    "text": "of Google festing or Netscape but this is the problem you want to make sure you have an open Force Community you don't want I mean I want people to contribute",
    "start": "2381160",
    "end": "2387599"
  },
  {
    "text": "and feel they can do things if we Fork it and it goes into other communities it kills it because now those contributions",
    "start": "2387599",
    "end": "2393319"
  },
  {
    "text": "don't come back you end up in these sort of weird battles and there's no value in that I mean what we want to do is help",
    "start": "2393319",
    "end": "2399240"
  },
  {
    "text": "people you know help people and and if it's necessary at this point you know commercialize the tool I would and turn",
    "start": "2399240",
    "end": "2405599"
  },
  {
    "text": "into something which we can support like hugging face I mean hugging face is a lot of Open Source but you know any sophisticated technology needs",
    "start": "2405599",
    "end": "2412560"
  },
  {
    "text": "maintenance if you buy a copier machine it's not open source because it needs maintenance you know so even a tool like",
    "start": "2412560",
    "end": "2418240"
  },
  {
    "text": "Weight Watcher needs maintenance so I would love to be able to work with people who would like to put in the",
    "start": "2418240",
    "end": "2424079"
  },
  {
    "text": "production as an open and and develop it and then at some point we realize look and we really need to put a service",
    "start": "2424079",
    "end": "2429680"
  },
  {
    "text": "contract around this so that we can maintain it and solve some of the harder problems for you be happy to do that uh",
    "start": "2429680",
    "end": "2435079"
  },
  {
    "text": "and I think that that's really the what we're trying to do because this is you know there's also a lot of opportunity for scientific research you know a",
    "start": "2435079",
    "end": "2441480"
  },
  {
    "text": "Weight Watcher has been a lot of it's come from doing research statistical mechanics and learning theory you know we have papers in jmlr nature icml kdd",
    "start": "2441480",
    "end": "2449440"
  },
  {
    "text": "there's a lot of opportunity for students to you know we have one student who is at a bank who just did his master's thesis on Weight Watcher and",
    "start": "2449440",
    "end": "2455800"
  },
  {
    "text": "and so there's a lot of that kind of opportun as well and I think there's a lot of room for improvement as we kind of get to the end here I was wondering",
    "start": "2455800",
    "end": "2462599"
  },
  {
    "text": "just quickly as we as we close out I I know you've spent a lot of really",
    "start": "2462599",
    "end": "2468319"
  },
  {
    "text": "valuable time in investing in the areas maybe that people aren't focusing on in",
    "start": "2468319",
    "end": "2473640"
  },
  {
    "text": "in the AI community in terms of the training side of things and and ways to help them in in those gaps as you look",
    "start": "2473640",
    "end": "2479720"
  },
  {
    "text": "forward to you know the the future of of where the AI Community is is going what",
    "start": "2479720",
    "end": "2485440"
  },
  {
    "text": "what encourages you about sort of the direction of things or or what excites you about what's exciting for you in in",
    "start": "2485440",
    "end": "2493119"
  },
  {
    "text": "the community right now you know for me I'm a physicist at heart I did theorical chemistry I did theorical physics you",
    "start": "2493119",
    "end": "2499200"
  },
  {
    "text": "know in subst I'm kind of the run of the litter like my one of my classmates you know a colleagues went often start Alpha",
    "start": "2499200",
    "end": "2504240"
  },
  {
    "text": "fold which solved the 50-year Grand Challenge I have another who has started a company who's going to label all the",
    "start": "2504240",
    "end": "2509400"
  },
  {
    "text": "world's translational medical data so I'm used to that for me this is an opportunity to really show that we can",
    "start": "2509400",
    "end": "2515839"
  },
  {
    "text": "use theoretical physics in a way that can have a broad impact you can use Theory to build sophisticated",
    "start": "2515839",
    "end": "2522240"
  },
  {
    "text": "engineering tools and a connection between a lot of the deep sort of Cold War education I have to build tools for",
    "start": "2522240",
    "end": "2528880"
  },
  {
    "text": "engineers there's there's a very famous uh statement by Carver me who's a very famous electrical engineer from Caltech",
    "start": "2528880",
    "end": "2535240"
  },
  {
    "text": "who said every useful experiment eventually becomes a tool everything you can measure eventually becomes a tool",
    "start": "2535240",
    "end": "2541880"
  },
  {
    "text": "you know that you give to an engineer and so I would just like people to realize look there's you can do deep Theory there's a lot of interest a lot",
    "start": "2541880",
    "end": "2548520"
  },
  {
    "text": "of fun and interesting stuff to do and we can turn Theory into tools that people can use and build a community and",
    "start": "2548520",
    "end": "2555359"
  },
  {
    "text": "and you know just have a broader impact I think that AI I mean I did AI in the 90s people thought we were crazy like",
    "start": "2555359",
    "end": "2561640"
  },
  {
    "text": "this stuff doesn't work nobody believed it right why are you doing neural network people think neural networks are invented by computer scientists but",
    "start": "2561640",
    "end": "2566880"
  },
  {
    "text": "there a whole group of theoretical physicists doing this stuff for years and you know understanding sort of who",
    "start": "2566880",
    "end": "2572160"
  },
  {
    "text": "we are how the brain works how we think what's actually going on up here and I think it's very exciting time and that",
    "start": "2572160",
    "end": "2578200"
  },
  {
    "text": "that's why I'm doing this I think there's a lot we can offer from the scientific Community there's a broad I think there are really deep broad",
    "start": "2578200",
    "end": "2584119"
  },
  {
    "text": "connections between General Science and what's going on in aii and that can connect back to um the engineering world",
    "start": "2584119",
    "end": "2590760"
  },
  {
    "text": "I and I think that there are big problems like like one of the things I'm really proudest of with Weight Watcher",
    "start": "2590760",
    "end": "2595920"
  },
  {
    "text": "is that there companies using it to help climate change W think is a huge problem if you can use it to find some way to",
    "start": "2595920",
    "end": "2602079"
  },
  {
    "text": "solve this massive problem we have I think that would be fantastic that's awesome well I I think that's a wonderful way to close out really really",
    "start": "2602079",
    "end": "2608319"
  },
  {
    "text": "appreciate your perspective there and yeah thank you so much for taking time to to join us Charles it's been a",
    "start": "2608319",
    "end": "2613720"
  },
  {
    "text": "pleasure hey I really appreciate it too I I'm glad we're able to set this up and I look forward to the podcast and I",
    "start": "2613720",
    "end": "2618960"
  },
  {
    "text": "really look forward to anyone who tries to use the tool wants to use it please reach out to me let me know how it's working complain to me if you don't like",
    "start": "2618960",
    "end": "2626000"
  },
  {
    "text": "it I'm not going to fix it if you don't tell me I don't know what's wrong with it I'm not gonna I can't fix what I don't know what is broken and I would",
    "start": "2626000",
    "end": "2632880"
  },
  {
    "text": "love that people join the community and uh build something great together awesome thanks so much right thanks guys",
    "start": "2632880",
    "end": "2639680"
  },
  {
    "text": "thank [Music]",
    "start": "2639680",
    "end": "2648000"
  },
  {
    "text": "you all right that is our show for this week if you dig it don't forget to",
    "start": "2648000",
    "end": "2653359"
  },
  {
    "text": "subscribe head to practical AI FM for all the ways and if practical AI has",
    "start": "2653359",
    "end": "2658720"
  },
  {
    "text": "benefited your life Pay It Forward by sharing the show with a friend or a colleague word of mouth is the number",
    "start": "2658720",
    "end": "2664400"
  },
  {
    "text": "one way people find shows like ours thanks again and too fastly for fronting our static assets to fly.io for backing",
    "start": "2664400",
    "end": "2671319"
  },
  {
    "text": "our Dynamic requests to break master cylinder for the beats and to you for listening we appreciate you that's all",
    "start": "2671319",
    "end": "2677200"
  },
  {
    "text": "for now we'll talk to you again on the next [Music]",
    "start": "2677200",
    "end": "2691960"
  },
  {
    "text": "one",
    "start": "2691960",
    "end": "2694960"
  }
]
[
  {
    "text": "[Music]",
    "start": "330",
    "end": "4090"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspire to or are",
    "start": "7160",
    "end": "13759"
  },
  {
    "text": "curious how AI related Technologies are changing the world this is the show for you thank you to our partners at fastly",
    "start": "13759",
    "end": "21160"
  },
  {
    "text": "for shipping all of our pods super fast to wherever you listen check them out at",
    "start": "21160",
    "end": "26240"
  },
  {
    "text": "fast.com and to our friends at fly deploy your app and database close to",
    "start": "26240",
    "end": "31359"
  },
  {
    "text": "your users no Ops required learn more at",
    "start": "31359",
    "end": "37000"
  },
  {
    "text": "[Music]",
    "start": "37140",
    "end": "42559"
  },
  {
    "text": "fly.io welcome to another fully connected episode of practical AI in",
    "start": "42559",
    "end": "48160"
  },
  {
    "text": "these episodes Chris and I keep you fully connected with everything that's happening in the AI Community we'll take",
    "start": "48160",
    "end": "54879"
  },
  {
    "text": "some time to discuss the latest news and also dig into some learning resources to help help you level up your machine",
    "start": "54879",
    "end": "61280"
  },
  {
    "text": "learning game I'm Daniel whack I'm a founder and data scientist at prediction guard and I'm joined as always by Chris",
    "start": "61280",
    "end": "67960"
  },
  {
    "text": "Benson who is a tech strategist at loed Martin how you doing Chris I'm doing very well Daniel it's uh more",
    "start": "67960",
    "end": "74280"
  },
  {
    "text": "interesting times ahead of us you know I'm thinking about changing jobs I'm thinking about uh like a job title",
    "start": "74280",
    "end": "81000"
  },
  {
    "text": "called something like I don't know generative juggler what do you think yeah cuz it sounds fun you know I",
    "start": "81000",
    "end": "88079"
  },
  {
    "text": "mean I can totally see llama Wrangler oh I love that that's perfect for me too I",
    "start": "88079",
    "end": "94479"
  },
  {
    "text": "I'm all over that okay of course our listeners know that you're a big animal Advocate what is an animal advocate's",
    "start": "94479",
    "end": "101520"
  },
  {
    "text": "perspective on the use of all of this llama camel all this sort of different",
    "start": "101520",
    "end": "106880"
  },
  {
    "text": "usage of animals do you find it fun and interesting of course we should all have",
    "start": "106880",
    "end": "112119"
  },
  {
    "text": "animals on the mind all the time I mean it makes us better people yes yeah I'm traveling my wife just sent",
    "start": "112119",
    "end": "119000"
  },
  {
    "text": "me a picture of our dog uh laying on the floor in a funny position looking out of the corner of his eye so I'm it made me",
    "start": "119000",
    "end": "126000"
  },
  {
    "text": "happy going into this recording so that's always good that sounds good you know the pet pictures are really",
    "start": "126000",
    "end": "131319"
  },
  {
    "text": "important when you're traveling my wife does that with me yeah uh she'll send a good moment so it you know in in the",
    "start": "131319",
    "end": "137000"
  },
  {
    "text": "face of all this technology change constantly uh coming at us it keeps our Humanity intact yeah yeah and it is a",
    "start": "137000",
    "end": "144959"
  },
  {
    "text": "crazy time in the AI Community um with so we we use these fully connected",
    "start": "144959",
    "end": "150840"
  },
  {
    "text": "episodes to update people on different news and that sort of thing and one of the things I was realizing this week as",
    "start": "150840",
    "end": "157440"
  },
  {
    "text": "we were prepping for this episode is I've even seen there's people and I think there's a website talking about",
    "start": "157440",
    "end": "164440"
  },
  {
    "text": "the Cambrian explosion of models or the proliferation of models so you know",
    "start": "164440",
    "end": "170760"
  },
  {
    "text": "there's just in the past couple weeks there's so many different ones that have",
    "start": "170760",
    "end": "176080"
  },
  {
    "text": "come out it is really a proliferation so um I thought it' be good to highlight a",
    "start": "176080",
    "end": "181200"
  },
  {
    "text": "few of those we can't get to all of them because there's just so many but um one",
    "start": "181200",
    "end": "186239"
  },
  {
    "text": "thing as a tip to people uh sometimes how I look at this is I'll go to hugging face and just go to the models Tab and",
    "start": "186239",
    "end": "194360"
  },
  {
    "text": "if you make sure that it's sorted by trending that's kind of an a cool way to see hey what's at the top and it you",
    "start": "194360",
    "end": "200519"
  },
  {
    "text": "know you can filter by different types of models but I found it kind of interesting to just look at what's trending overall because as of now on",
    "start": "200519",
    "end": "208560"
  },
  {
    "text": "the hugging face h it's a mix between kind of video Generation image generation language",
    "start": "208560",
    "end": "215120"
  },
  {
    "text": "generation models and over time you can see kind of which of those categories is",
    "start": "215120",
    "end": "220560"
  },
  {
    "text": "trending up or down I don't know there's probably an app that needs to be made to track that sort of thing but I'll let",
    "start": "220560",
    "end": "226200"
  },
  {
    "text": "someone else do that one of the ones that um I wanted to highlight was the",
    "start": "226200",
    "end": "231760"
  },
  {
    "text": "new stable diffusion XL 0.9 also these model names are getting a",
    "start": "231760",
    "end": "237959"
  },
  {
    "text": "little bit more complicated over time I found but uh stable diffusion XL 0.9 or",
    "start": "237959",
    "end": "245120"
  },
  {
    "text": "SD XL this is of course people probably remember stable diffusion this is an",
    "start": "245120",
    "end": "252000"
  },
  {
    "text": "image generation model so you put in a text prompt and then out comes an image",
    "start": "252000",
    "end": "258639"
  },
  {
    "text": "so something like astronaut riding horse on the moon photo realistic or something",
    "start": "258639",
    "end": "265199"
  },
  {
    "text": "like that and you get an image out this one is kind of interesting um I think it",
    "start": "265199",
    "end": "271560"
  },
  {
    "text": "was back in April they announced some kind of private access to this or beta access now the model is up on hugging",
    "start": "271560",
    "end": "279039"
  },
  {
    "text": "face it is available but under only a research only license but the images I",
    "start": "279039",
    "end": "285759"
  },
  {
    "text": "don't know if you've seen some of these Chris um I'm looking at them now while we're talking yeah you played with stable diffusion back you know when the",
    "start": "285759",
    "end": "293080"
  },
  {
    "text": "previous kind of iteration what is your thought in terms of the progression of this oh I mean it it's it was like I",
    "start": "293080",
    "end": "299720"
  },
  {
    "text": "remember when we were playing we were actually doing it on one of our episodes yeah and we were coming up raccoons all over the place I remember uh at the time",
    "start": "299720",
    "end": "306919"
  },
  {
    "text": "that were raccoons everywhere not just us there seem to be lots of raccoons coming out of staple diffusion regardless I was rather wondering about",
    "start": "306919",
    "end": "313520"
  },
  {
    "text": "that but no uh no I'm looking through some of the things and just like the imagery has come so far and the",
    "start": "313520",
    "end": "319240"
  },
  {
    "text": "capability and what you can do uh and that's just a few months since we were doing that so uh I'm in awe right now as",
    "start": "319240",
    "end": "325840"
  },
  {
    "text": "I look at these uh these shots as we're talking uh at least the last time I checked and this might be different now",
    "start": "325840",
    "end": "331080"
  },
  {
    "text": "that if you're listening to this episode it might be different but at the time today there was a blog post about the",
    "start": "331080",
    "end": "337199"
  },
  {
    "text": "release on from stability and they mentioned that there's going to be a follow-up more technical Deep dive I",
    "start": "337199",
    "end": "343840"
  },
  {
    "text": "don't know if it's a full paper or just a deep dive post but there are some general descriptions of how this is",
    "start": "343840",
    "end": "350680"
  },
  {
    "text": "working and uh you can dig into it a little bit so instead of there being sort of one step or a one model kind of",
    "start": "350680",
    "end": "359039"
  },
  {
    "text": "situation in this image generation apparently this model consists of a twep",
    "start": "359039",
    "end": "366039"
  },
  {
    "text": "pipeline it's still diffusion based but there's one model that generates um they",
    "start": "366039",
    "end": "371880"
  },
  {
    "text": "say latence of the desired output size in the second step is specialized to",
    "start": "371880",
    "end": "377360"
  },
  {
    "text": "generate this sort of high resolution image so it's like an imageo image model",
    "start": "377360",
    "end": "382680"
  },
  {
    "text": "they combine these and the second stage of the model then kind of adds finer details to the generated output so",
    "start": "382680",
    "end": "390280"
  },
  {
    "text": "that's one interesting thing which also is kind of interesting I I don't know if you've been following all of the",
    "start": "390280",
    "end": "395800"
  },
  {
    "text": "everyone talking about what's going on quote unquote in GPT 4 but I think there's a lot of speculation and",
    "start": "395800",
    "end": "403360"
  },
  {
    "text": "evidence that that also is a sort of mixture of experts multiple models",
    "start": "403360",
    "end": "409280"
  },
  {
    "text": "together not just a single model call so I find this trend kind of interesting do",
    "start": "409280",
    "end": "414800"
  },
  {
    "text": "you have any thoughts around like what is the virtue of having the kind of the multi-step multi approach and is that do",
    "start": "414800",
    "end": "421599"
  },
  {
    "text": "you think that that's likely to be kind of a a general architecture that we see continually overboard instead of just",
    "start": "421599",
    "end": "427919"
  },
  {
    "text": "having the model I mean even going back to the stable diffusion I noticed you the two models you mentioned and",
    "start": "427919",
    "end": "433479"
  },
  {
    "text": "interestingly the second model is basically twice the size of the first one in terms of parameters any thoughts",
    "start": "433479",
    "end": "438960"
  },
  {
    "text": "around the science or math around that or why why you would take that approach yeah as you scale up your data set and",
    "start": "438960",
    "end": "444960"
  },
  {
    "text": "you scale up your compute for a given model size you're going to get",
    "start": "444960",
    "end": "450720"
  },
  {
    "text": "diminishing returns on the performance of that model so in some ways given a certain amount of data in a model",
    "start": "450720",
    "end": "457520"
  },
  {
    "text": "architecture you know what are you going to improve more you could train for longer you could train on more data but",
    "start": "457520",
    "end": "463599"
  },
  {
    "text": "at the levels that some of these models are at now thinking particularly about open AI you know what more can they do",
    "start": "463599",
    "end": "471000"
  },
  {
    "text": "right now with respect to training longer different with the same model architecture more data so what's a",
    "start": "471000",
    "end": "477720"
  },
  {
    "text": "natural way to improve output but combining multiple models a pipeline",
    "start": "477720",
    "end": "482879"
  },
  {
    "text": "together now I think that you'll see probably advances in architectures so different model architectures will",
    "start": "482879",
    "end": "489960"
  },
  {
    "text": "continue to come out and maybe break some of that that Trend another way that",
    "start": "489960",
    "end": "495879"
  },
  {
    "text": "you see this kind of multiple models being applied is in things like the rhf",
    "start": "495879",
    "end": "501840"
  },
  {
    "text": "process which we talked about on the show The reinforcement learning from Human feedback which things like this",
    "start": "501840",
    "end": "508000"
  },
  {
    "text": "have been around for quite some time so Gans for example include two different models right a generative model and the",
    "start": "508000",
    "end": "514719"
  },
  {
    "text": "discriminator these sort of like multimodel workflows that produce a",
    "start": "514719",
    "end": "520479"
  },
  {
    "text": "instruction tuned or tuned model out the other end I think we'll continue to see a lot of that as well even if the model",
    "start": "520479",
    "end": "527640"
  },
  {
    "text": "that's produced or used for inference at the end is a single inference I got one other question before we dive into the",
    "start": "527640",
    "end": "533480"
  },
  {
    "text": "rest of the models to release you know one of the things that was notable was uh you know open AI kind of commented",
    "start": "533480",
    "end": "539440"
  },
  {
    "text": "you know after gbt 4 that there was there was only so much vertical growth you could have there you know given the",
    "start": "539440",
    "end": "545600"
  },
  {
    "text": "the data set you know basically I mean the whole internet you know in model so there's only you know you can't just",
    "start": "545600",
    "end": "551279"
  },
  {
    "text": "keep growing them like that here we find ourselves in this you know what we've kind of described as the proliferation",
    "start": "551279",
    "end": "556920"
  },
  {
    "text": "kind of episode talking about all these models coming out do you think part of what we're looking at today is generated",
    "start": "556920",
    "end": "563760"
  },
  {
    "text": "by the fact that when you lose the potential for further vertical growth because you basically used all the data",
    "start": "563760",
    "end": "568880"
  },
  {
    "text": "that's out there does that give all of these other model creators a chance to catch up to some",
    "start": "568880",
    "end": "573959"
  },
  {
    "text": "degree so that you kind of you had the surging of the leader but once they hit kind of a barrier there now you're",
    "start": "573959",
    "end": "579640"
  },
  {
    "text": "seeing many many catching up and comparing themselves to that is is that a fair assessment in terms of kind of",
    "start": "579640",
    "end": "585959"
  },
  {
    "text": "what we're looking at now yeah people probably have seen this post that went",
    "start": "585959",
    "end": "592079"
  },
  {
    "text": "sort of viral which is supposedly a leaked document from Google saying you know we have no mode and neither does Ai",
    "start": "592079",
    "end": "599959"
  },
  {
    "text": "and they they talk about how basically I think the phrase they use is open",
    "start": "599959",
    "end": "605320"
  },
  {
    "text": "sources eating our lunch like we're not positioned as major players to compete",
    "start": "605320",
    "end": "610519"
  },
  {
    "text": "necessarily so I think that that's where that sentiment is probably coming from wherever that document originated um",
    "start": "610519",
    "end": "618600"
  },
  {
    "text": "that would be the sentiment that's being expressed there so the ability to have a",
    "start": "618600",
    "end": "623640"
  },
  {
    "text": "foundation model is no longer this sort of moat that separates you because now",
    "start": "623640",
    "end": "630120"
  },
  {
    "text": "there's open source models there's really good open source models that maybe the base model let's say the base",
    "start": "630120",
    "end": "636800"
  },
  {
    "text": "model doesn't perform as good in a general purpose way as GPT 4 or",
    "start": "636800",
    "end": "642760"
  },
  {
    "text": "something like that well the reality is that like in your business environment",
    "start": "642760",
    "end": "648120"
  },
  {
    "text": "you don't need a general purpose model that's usually not what you need right",
    "start": "648120",
    "end": "653399"
  },
  {
    "text": "what you need is a model that performs really well for your task and so in that sense having a really good Open Access",
    "start": "653399",
    "end": "661920"
  },
  {
    "text": "whether it's a language model or an image generation model and then having the ability which we have now to adapt",
    "start": "661920",
    "end": "669160"
  },
  {
    "text": "or fine-tune that model with your own private data actually is kind of part of",
    "start": "669160",
    "end": "676120"
  },
  {
    "text": "what we're seeing with this proliferation I would say an example of this is the next model I was going to",
    "start": "676120",
    "end": "682480"
  },
  {
    "text": "highlight which I think is a really good example of this so I saw this in a tweet",
    "start": "682480",
    "end": "687680"
  },
  {
    "text": "um I don't know act the actual data was released but the Open chat models so if you just go to hugging face slopen chat",
    "start": "687680",
    "end": "695160"
  },
  {
    "text": "so there was a model that kind of outpaced chat GPT in some benchmarks so",
    "start": "695160",
    "end": "700519"
  },
  {
    "text": "there's a bakuna benchmark that model wasn't as open but these open chat",
    "start": "700519",
    "end": "705959"
  },
  {
    "text": "models are the first open models to outpace chat GPT with GPT 3.5 in this",
    "start": "705959",
    "end": "713680"
  },
  {
    "text": "Benchmark and what's interesting is this is another very much a trend that we're",
    "start": "713680",
    "end": "718720"
  },
  {
    "text": "seeing more and more and more of is actually using the closed",
    "start": "718720",
    "end": "724440"
  },
  {
    "text": "proprietary but really impressively performing models like gp4 to actually",
    "start": "724440",
    "end": "729880"
  },
  {
    "text": "create data for you to fine-tune an open model which then performs or maybe performs better than the closed models",
    "start": "729880",
    "end": "737519"
  },
  {
    "text": "at least in certain scenarios so that's what they did they used 6,000 conversations generated out of",
    "start": "737519",
    "end": "744480"
  },
  {
    "text": "gp4 to fine-tune this model which actually outperformed and is available",
    "start": "744480",
    "end": "750920"
  },
  {
    "text": "publicly and this we're seeing over and over so there's other models like people are generating this data for less than",
    "start": "750920",
    "end": "757040"
  },
  {
    "text": "a, right they're using the open AI API less than $1,000 to create these models",
    "start": "757040",
    "end": "763519"
  },
  {
    "text": "that are really impressive and how they perform now I think there's all sorts of",
    "start": "763519",
    "end": "769160"
  },
  {
    "text": "interesting implications of that and part of me wonders well how is open AI",
    "start": "769160",
    "end": "774760"
  },
  {
    "text": "going to shift its business model to make that sort of thing less or or other",
    "start": "774760",
    "end": "780160"
  },
  {
    "text": "providers of foundation models one result of this might be that we see providers like open AI try to prevent",
    "start": "780160",
    "end": "787399"
  },
  {
    "text": "usage like this where you're just using their API to generate data to create a",
    "start": "787399",
    "end": "792839"
  },
  {
    "text": "model that works better for you than using their API I don't know we'll see if you kind of back away for a second",
    "start": "792839",
    "end": "799279"
  },
  {
    "text": "and look at the history of this it's starting to look a lot like the way software development went open source",
    "start": "799279",
    "end": "805760"
  },
  {
    "text": "you know if you look back around you know 2000 or even down down into the '90s before that you saw all of these",
    "start": "805760",
    "end": "812079"
  },
  {
    "text": "proprietary programming languages you know you'd pay for them you had to pay for environments and stuff like that and",
    "start": "812079",
    "end": "817839"
  },
  {
    "text": "gradually open source overtook it and uh from my perspective it's feeling a lot of the same right now as we're making a",
    "start": "817839",
    "end": "824760"
  },
  {
    "text": "shift um I will leave it by saying I'm wondering uh if to that point about your unknown source document earlier whether",
    "start": "824760",
    "end": "831759"
  },
  {
    "text": "or not that's kind of an inevitable destination we're going",
    "start": "831759",
    "end": "836680"
  },
  {
    "text": "to this is a chang log news break can you",
    "start": "838040",
    "end": "843279"
  },
  {
    "text": "trust jat gpt's package recommendations m not so much the team at Vulcan have",
    "start": "843279",
    "end": "849480"
  },
  {
    "text": "published a new security Threat Vector they're calling AI package",
    "start": "849480",
    "end": "854959"
  },
  {
    "text": "hallucination that sounds good I'll have that it relies on the fact that chat GPT",
    "start": "854959",
    "end": "860959"
  },
  {
    "text": "sometimes answers questions with hallucinated sources links blogs and statistics it'll even generate",
    "start": "860959",
    "end": "867560"
  },
  {
    "text": "questionable fixes to cve and offer links to libraries that don't actually exist what about the RO Us's rodents of",
    "start": "867560",
    "end": "874920"
  },
  {
    "text": "unusual size I don't think they exist quote when the attacker finds a",
    "start": "874920",
    "end": "880320"
  },
  {
    "text": "recommendation for an unpublished package they can publish their own malicious package in its place the next",
    "start": "880320",
    "end": "885800"
  },
  {
    "text": "time a user asks a similar question they may receive a recommendation from chat gbt to use the now existing malicious",
    "start": "885800",
    "end": "892759"
  },
  {
    "text": "package end quote these AI tools like chat GPT are a real boost to developer",
    "start": "892759",
    "end": "898800"
  },
  {
    "text": "product it but be careful out there you just heard one of our five top stories",
    "start": "898800",
    "end": "904800"
  },
  {
    "text": "from Monday's Chang log news subscribe to the podcast to get all of the week's top stories and pop your email address",
    "start": "904800",
    "end": "911399"
  },
  {
    "text": "in at Chang blog.com newws to also receive our free companion email with even more the developer news worth your",
    "start": "911399",
    "end": "918920"
  },
  {
    "text": "attention once again that's changel log.com [Music]",
    "start": "918920",
    "end": "926560"
  },
  {
    "text": "newws we've been talking about open source models some things that we talked",
    "start": "926560",
    "end": "931639"
  },
  {
    "text": "about even like two months ago on this show like someday these things will happen I remember us talking about the",
    "start": "931639",
    "end": "938959"
  },
  {
    "text": "graph that I think CLM from hugging face posted on Twitter where you know you kind of got this linear progression of",
    "start": "938959",
    "end": "945440"
  },
  {
    "text": "these closed Source models and then eventually there's this kind of exponential increase of open models that",
    "start": "945440",
    "end": "952240"
  },
  {
    "text": "surpasses the performance of the closed models and I don't know if we're totally",
    "start": "952240",
    "end": "957279"
  },
  {
    "text": "in that place yet but it kind of seems like it's happening to some degree and maybe not in in",
    "start": "957279",
    "end": "965000"
  },
  {
    "text": "certain ways so I think still for like general purpose like this model can do whatever you ask it to do those sorts of",
    "start": "965000",
    "end": "972040"
  },
  {
    "text": "use cases still the closed models are winning I think but like I said how many",
    "start": "972040",
    "end": "978600"
  },
  {
    "text": "business use cases do you need a model that does that sort of thing the majority you don't need that so maybe",
    "start": "978600",
    "end": "985600"
  },
  {
    "text": "for the actual proliferation of these models in business use cases all that",
    "start": "985600",
    "end": "992480"
  },
  {
    "text": "really matters is that you can have open models that perform really well for all",
    "start": "992480",
    "end": "997880"
  },
  {
    "text": "those business use cases and that brings up of course a lot of other concerns and practical implications so",
    "start": "997880",
    "end": "1006160"
  },
  {
    "text": "open models are great if they perform better that's great but there is a lot of I mean it's not only that open AI or",
    "start": "1006160",
    "end": "1013440"
  },
  {
    "text": "cohere or anthropic or whoever who are running these models that the model is",
    "start": "1013440",
    "end": "1018639"
  },
  {
    "text": "good they also have a really nice and easy to use API that generally is up although I",
    "start": "1018639",
    "end": "1025079"
  },
  {
    "text": "think chat GPT was down the other night but uh yeah but yeah generally is good",
    "start": "1025079",
    "end": "1030558"
  },
  {
    "text": "and like wellmaintained and all that you don't get that with these open models you have to figure that bit out yourself",
    "start": "1030559",
    "end": "1036798"
  },
  {
    "text": "which has other sort of engineering implications and infrastructure implications and obviously uh you know",
    "start": "1036799",
    "end": "1043120"
  },
  {
    "text": "going back to uh someone I know here uh there are business opportunities available to help people",
    "start": "1043120",
    "end": "1049400"
  },
  {
    "text": "on board on those things so there's a lot it's so much happening right now as you said two months ago and now it's",
    "start": "1049400",
    "end": "1055480"
  },
  {
    "text": "already changing um and I think people need to get used to the new speed of of how fast this is happening at this point",
    "start": "1055480",
    "end": "1062039"
  },
  {
    "text": "um later on I'll come back to that but uh one other one that is trending at least this week on hugging face is",
    "start": "1062039",
    "end": "1069320"
  },
  {
    "text": "zeroscope XL version two is the one that I'm looking at but if you just search for zero scope you'll find it this is a",
    "start": "1069320",
    "end": "1076440"
  },
  {
    "text": "video generation model which is pretty cool so it's video generation it produces Watermark free videos and one",
    "start": "1076440",
    "end": "1085200"
  },
  {
    "text": "of the things I find interesting about so like this model the zeroscope model and also the stable diffusion model that",
    "start": "1085200",
    "end": "1092440"
  },
  {
    "text": "we mentioned a second ago is you can run these on some sort of commodity Hardware",
    "start": "1092440",
    "end": "1098520"
  },
  {
    "text": "maybe not the cheapest of commodity Hardware but this model supposably uses",
    "start": "1098520",
    "end": "1104400"
  },
  {
    "text": "15 a little over 15 gabt of GPU memory r ing 30 frames at 1024 by",
    "start": "1104400",
    "end": "1113559"
  },
  {
    "text": "576 so that sort of Hardware is definitely within reach for a lot of",
    "start": "1113559",
    "end": "1120600"
  },
  {
    "text": "people even in platforms where you can access some of that for free for at least sometime so yeah that's one of the",
    "start": "1120600",
    "end": "1127240"
  },
  {
    "text": "things that I find interesting about some of these models as well that's cool I we're seeing more and more video",
    "start": "1127240",
    "end": "1132559"
  },
  {
    "text": "generation recently it wasn't long ago it was earlier this year that we were talking about uh you know kind of moving",
    "start": "1132559",
    "end": "1139559"
  },
  {
    "text": "there uh as we were coming into 2023 and the fact that we were expecting it but",
    "start": "1139559",
    "end": "1144960"
  },
  {
    "text": "it hadn't really arrived yet and now it's already to your Cambrian uh point it is blown up and we're seeing multiple",
    "start": "1144960",
    "end": "1151559"
  },
  {
    "text": "opportunities uh in terms of these models already in in open source versions as well so how do you I'm kind",
    "start": "1151559",
    "end": "1157679"
  },
  {
    "text": "of curious Daniel how do you as a practitioner as you're looking at this explosion of these different options",
    "start": "1157679",
    "end": "1163440"
  },
  {
    "text": "coming at you how do you make an evaluation I've had people ask me that recently like so much is happening now I",
    "start": "1163440",
    "end": "1170400"
  },
  {
    "text": "don't even know how to evaluate one option versus another do you have any uh thoughts on framing that I think there's",
    "start": "1170400",
    "end": "1177039"
  },
  {
    "text": "a bunch of different axes that you could kind of narrow down your choices along",
    "start": "1177039",
    "end": "1182919"
  },
  {
    "text": "so let's say that you have a commercial use case right that alone is a filter by",
    "start": "1182919",
    "end": "1190679"
  },
  {
    "text": "which you can knock out a huge amount of models because just looking at the ones we've listed so far zeros scope released",
    "start": "1190679",
    "end": "1198080"
  },
  {
    "text": "under Creative Commons non-commercial can't use it open chat released under the Llama license can't use it for",
    "start": "1198080",
    "end": "1204559"
  },
  {
    "text": "commercial stable diffusion XL 0.9 available only for research can't use it",
    "start": "1204559",
    "end": "1210640"
  },
  {
    "text": "so not that you couldn't prototype with it or that it versions of this wouldn't be eventually released or you could",
    "start": "1210640",
    "end": "1216880"
  },
  {
    "text": "access them in other commercial products but that kind of does narrow down your",
    "start": "1216880",
    "end": "1222159"
  },
  {
    "text": "cases quite a bit whereas you look at certain models like the MPT family from",
    "start": "1222159",
    "end": "1227240"
  },
  {
    "text": "Mosaic release under licenses that allow you to use them for commercial purposes",
    "start": "1227240",
    "end": "1232880"
  },
  {
    "text": "Etc so that's an easy one what is your use case are you commercial well that knocks out a whole bunch then you have a",
    "start": "1232880",
    "end": "1239520"
  },
  {
    "text": "smaller set and then I think you need to do a second layer of filtering which is think about your practical use of this",
    "start": "1239520",
    "end": "1246760"
  },
  {
    "text": "model so for example let's say that I want to use an llm to extract a bunch of",
    "start": "1246760",
    "end": "1252159"
  },
  {
    "text": "information from a huge number of unstructured documents uh I've got maybe",
    "start": "1252159",
    "end": "1257960"
  },
  {
    "text": "millions of documents and I want to extract information from them okay well",
    "start": "1257960",
    "end": "1263080"
  },
  {
    "text": "if each inference is going to take 20 or 30 seconds for me and I would need to",
    "start": "1263080",
    "end": "1268880"
  },
  {
    "text": "extract a bunch of information then that's going to become a major problem",
    "start": "1268880",
    "end": "1274000"
  },
  {
    "text": "so then I need to think about like how am I going to use this and what are the constraints around like the inference",
    "start": "1274000",
    "end": "1280880"
  },
  {
    "text": "speed and the interaction with the model or the context link that I'm putting in in the case of large language models do",
    "start": "1280880",
    "end": "1286840"
  },
  {
    "text": "I need to put in a bunch of or a small amount and that narrows down to models",
    "start": "1286840",
    "end": "1292279"
  },
  {
    "text": "that are maybe smaller that can be run faster for inference or models that support larger inputs right so there's",
    "start": "1292279",
    "end": "1299480"
  },
  {
    "text": "those concerns and then finally once you get down to that let's say you found one that fits your use case and the",
    "start": "1299480",
    "end": "1305080"
  },
  {
    "text": "constraints that you're working under then I think it gets down to this sort of I guess we call it oldfashioned oh",
    "start": "1305080",
    "end": "1311320"
  },
  {
    "text": "it's not that oldfashioned create yourself a test set that's still the best way to do this right if you have",
    "start": "1311320",
    "end": "1317960"
  },
  {
    "text": "you know 100 200 examples that you've manually labeled as this is what I would like to",
    "start": "1317960",
    "end": "1324000"
  },
  {
    "text": "go in and this is what I would like to come out then you should just check the output and see you know what is the",
    "start": "1324000",
    "end": "1330640"
  },
  {
    "text": "accuracy or how does the output compare how would I rate these is failure or",
    "start": "1330640",
    "end": "1335880"
  },
  {
    "text": "what that's still the way to do it right so the last two minutes is my favorite part of this episode so far you just put",
    "start": "1335880",
    "end": "1342600"
  },
  {
    "text": "the Practical and practical AI uh in terms of how to go about actually doing this stuff in real life so so much",
    "start": "1342600",
    "end": "1349279"
  },
  {
    "text": "appreciated on that yeah of course yeah well one of those things that was mentioned what well two things the",
    "start": "1349279",
    "end": "1355960"
  },
  {
    "text": "licensing and the context link that we just talked about so for those that aren't aware um most of these generative",
    "start": "1355960",
    "end": "1362600"
  },
  {
    "text": "models accept a prompt that is some amount of text that is kind of autoc",
    "start": "1362600",
    "end": "1369039"
  },
  {
    "text": "completed the result is an autoc completion most of the large language models that we're dealing with are autoc",
    "start": "1369039",
    "end": "1374919"
  },
  {
    "text": "completion models so they predict next words the image generation one or the video generation when you kind of think",
    "start": "1374919",
    "end": "1380640"
  },
  {
    "text": "of the image or the video as the completion of a prompt as well because you're putting in text but these models",
    "start": "1380640",
    "end": "1386679"
  },
  {
    "text": "generally have a constraint around the amount of text that you can put in as",
    "start": "1386679",
    "end": "1391880"
  },
  {
    "text": "your prompt many of the open models are kind of around 2000ish tokens of input",
    "start": "1391880",
    "end": "1400600"
  },
  {
    "text": "so for example you couldn't put in maybe a whole chapter of a book or something that's not what you could put in there",
    "start": "1400600",
    "end": "1407120"
  },
  {
    "text": "there are some like trickeries that have been introduced that take like a model",
    "start": "1407120",
    "end": "1412240"
  },
  {
    "text": "that was trained on a smaller context length and kind of extend the context length but something we've seen in the",
    "start": "1412240",
    "end": "1418320"
  },
  {
    "text": "past couple weeks is some really seemingly very powerful models that are",
    "start": "1418320",
    "end": "1423520"
  },
  {
    "text": "open and are available for commercial usage under their licensing that support",
    "start": "1423520",
    "end": "1430200"
  },
  {
    "text": "a longer context length one of these being the Salesforce xgen model um so if",
    "start": "1430200",
    "end": "1436600"
  },
  {
    "text": "you go on hugging face just search for XG it's a 7 billion parameter model with",
    "start": "1436600",
    "end": "1442640"
  },
  {
    "text": "an 8,000 input sequence length uh which is obviously quite a bit more than that",
    "start": "1442640",
    "end": "1449440"
  },
  {
    "text": "2000 and one of the things I find interesting about this model as well kind of fitting with similar trends that",
    "start": "1449440",
    "end": "1455600"
  },
  {
    "text": "we saw in the other model the 7 billion parameter is kind of an important piece of it because 7 billion parameter once",
    "start": "1455600",
    "end": "1463200"
  },
  {
    "text": "you kind of go beyond that you lose some of your ability to deploy models on more",
    "start": "1463200",
    "end": "1470120"
  },
  {
    "text": "commodity hardware and so that 7 billion is a very strategic number and that's",
    "start": "1470120",
    "end": "1475840"
  },
  {
    "text": "why you see a lot of 7 billion 6.9 billion parameter models is it allows",
    "start": "1475840",
    "end": "1481200"
  },
  {
    "text": "you to kind of run these models on more reasonable Hardware single GPU cards",
    "start": "1481200",
    "end": "1486960"
  },
  {
    "text": "that sort of thing what is the technical distinction there when you exceed the 7 billion parameter is this something as",
    "start": "1486960",
    "end": "1492640"
  },
  {
    "text": "simple as you know kind of like the bus width of data bits going in or I mean it's really the model on fitting into",
    "start": "1492640",
    "end": "1500120"
  },
  {
    "text": "the GPU memory got it and not exceeding it so unless you want to quantize your",
    "start": "1500120",
    "end": "1505840"
  },
  {
    "text": "model which we had a whole episode with neural magic um so I'd recommend people listen to that that was really cool but",
    "start": "1505840",
    "end": "1511919"
  },
  {
    "text": "it was unless you're very careful so quantization means like each of these seven billion parameters of this model",
    "start": "1511919",
    "end": "1518880"
  },
  {
    "text": "are some sort of floating Point numbers right and most of them so if you load",
    "start": "1518880",
    "end": "1525799"
  },
  {
    "text": "them in are not used that much or you don't need sort of full float 32",
    "start": "1525799",
    "end": "1530880"
  },
  {
    "text": "Precision to get good output so one thing people do is they quantize those",
    "start": "1530880",
    "end": "1536320"
  },
  {
    "text": "down to float 16 or even N8 or 4 bit or whatever if you're not really careful",
    "start": "1536320",
    "end": "1542880"
  },
  {
    "text": "about how you do that or if you don't kind of retrain with that Precision often times you lose a lot of",
    "start": "1542880",
    "end": "1548240"
  },
  {
    "text": "performance so the thing here is like the 7 billion parameter model with these",
    "start": "1548240",
    "end": "1553279"
  },
  {
    "text": "larger cards now that you can get single cards even if it's an a100 or something",
    "start": "1553279",
    "end": "1558600"
  },
  {
    "text": "like that that's fairly expensive but it's a single card and it will fit and run one of these models fine but if you",
    "start": "1558600",
    "end": "1565320"
  },
  {
    "text": "go to like 40 billion parameters 60 billion parameters these larger models",
    "start": "1565320",
    "end": "1571799"
  },
  {
    "text": "now you're kind of getting into multi-gpu Zone which makes things much more difficult so there is a balance",
    "start": "1571799",
    "end": "1579320"
  },
  {
    "text": "here like you can quantize or optimize the larger models and run them on commodity Hardware but it's not always",
    "start": "1579320",
    "end": "1586200"
  },
  {
    "text": "straightforward how to do that gotcha so in general you want to get if you're just a practitioner out there and you're",
    "start": "1586200",
    "end": "1592000"
  },
  {
    "text": "in a small or mediumsized business you're kind of doing it on your own or with your companies stuff kind of",
    "start": "1592000",
    "end": "1597840"
  },
  {
    "text": "focusing in that five six seven billion parameter so that you can be productive",
    "start": "1597840",
    "end": "1603039"
  },
  {
    "text": "as opposed to and not escalate costs out of your control is that a fair way of looking at it yeah yeah I would say",
    "start": "1603039",
    "end": "1608399"
  },
  {
    "text": "basically if you try to work in that s billion or fewer Zone your life is much",
    "start": "1608399",
    "end": "1615000"
  },
  {
    "text": "easier infrastructure wise I would say and that's probably will also change",
    "start": "1615000",
    "end": "1620080"
  },
  {
    "text": "over time but I think it's the reality now and one in of the Salesforce thing I love it when people post this the they",
    "start": "1620080",
    "end": "1627480"
  },
  {
    "text": "posted that the training cost was around $150,000 USD on Google Cloud using tpus",
    "start": "1627480",
    "end": "1636039"
  },
  {
    "text": "and this model is released under Apache 2 which is cool for me the other one that I mentioned that was the 8K context",
    "start": "1636039",
    "end": "1643159"
  },
  {
    "text": "length was the mpt3 billion model which was released recently but also note",
    "start": "1643159",
    "end": "1649360"
  },
  {
    "text": "there the difference in parameter size right the xgen model from Salesforce supports that context leak that 7",
    "start": "1649360",
    "end": "1655279"
  },
  {
    "text": "billion parameters and for MPT you kind of have to go up to that 30 billion which the MPT models are really great I",
    "start": "1655279",
    "end": "1661679"
  },
  {
    "text": "love them I've been using them but that's just a differentiation like you can see why maybe Salesforce xgen is",
    "start": "1661679",
    "end": "1667720"
  },
  {
    "text": "trending because of uh their focus on this sort of thing it's more accessible",
    "start": "1667720",
    "end": "1675840"
  },
  {
    "text": "yeah",
    "start": "1677120",
    "end": "1680120"
  },
  {
    "text": "[Music]",
    "start": "1682420",
    "end": "1691140"
  },
  {
    "text": "well Chris uh I think that some of what we've talked about here with the open models is quite interesting because as",
    "start": "1692799",
    "end": "1700480"
  },
  {
    "text": "we already mentioned we were talking about this a couple months ago and thinking oh at some point these open",
    "start": "1700480",
    "end": "1706200"
  },
  {
    "text": "models are going to proliferate and kind of of take market share what whatever you want to say from the closed",
    "start": "1706200",
    "end": "1714120"
  },
  {
    "text": "proprietary models and I think we are seeing this trend one one of the evidences that I saw in the news this",
    "start": "1714120",
    "end": "1722559"
  },
  {
    "text": "yeah I forget if it was this week as we're recording this but was the acquisition of Mosaic ml so Mosaic is",
    "start": "1722559",
    "end": "1728640"
  },
  {
    "text": "the one that created the MPT family of models which again I've already said are really great choices if you're looking",
    "start": "1728640",
    "end": "1735880"
  },
  {
    "text": "for some llms to play with but Mosaic was acquired by data bricks or quote",
    "start": "1735880",
    "end": "1743640"
  },
  {
    "text": "agreed to join which I don't know the prices on these things are just astronomical you know in terms of it's",
    "start": "1743640",
    "end": "1750080"
  },
  {
    "text": "crazy yeah so I mean it's public information at least this one is public information so a total of 1.3 billion",
    "start": "1750080",
    "end": "1758600"
  },
  {
    "text": "yeah for Mosaic ml which has 62 employees so that's $21 million per",
    "start": "1758600",
    "end": "1765760"
  },
  {
    "text": "employee that's a valuable employer right there and I was talking to someone about this and I wasn't in the strategy",
    "start": "1765760",
    "end": "1773399"
  },
  {
    "text": "meetings with data bricks when they're talking about like why are we doing this and how does this position us but I mean",
    "start": "1773399",
    "end": "1780360"
  },
  {
    "text": "think about I remember data bricks and Spark and Hadoop back in the sort of Big",
    "start": "1780360",
    "end": "1786360"
  },
  {
    "text": "Data days leading into data science days and really focusing on this spark sort",
    "start": "1786360",
    "end": "1792000"
  },
  {
    "text": "of thing and think about that use case I gave earlier of the data extraction",
    "start": "1792000",
    "end": "1797480"
  },
  {
    "text": "right how are people going to do large scale data processing in the future or",
    "start": "1797480",
    "end": "1802679"
  },
  {
    "text": "large scale analytics in the future well there will likely always be data",
    "start": "1802679",
    "end": "1808080"
  },
  {
    "text": "warehouses and SQL queries and analytic systems but there's going to be a large",
    "start": "1808080",
    "end": "1813720"
  },
  {
    "text": "portion of what people are doing analytics wise or kind of Big Data analysis quote unquote Wise by",
    "start": "1813720",
    "end": "1821080"
  },
  {
    "text": "extracting information or doing reasoning with llms the problem with that is for an Enterprise you can't do",
    "start": "1821080",
    "end": "1827760"
  },
  {
    "text": "that with a proprietary closed API because you can't",
    "start": "1827760",
    "end": "1833440"
  },
  {
    "text": "leak your private data to that API and it's not cost effective to do it anyway",
    "start": "1833440",
    "end": "1839000"
  },
  {
    "text": "because those charge per token so how are you going to do that you're going to proliferate open models that are trained",
    "start": "1839000",
    "end": "1845360"
  },
  {
    "text": "on your own private data and make that easier and easier and that's what",
    "start": "1845360",
    "end": "1850440"
  },
  {
    "text": "mosaic's doing right so I think once you kind of think about that positioning I'm",
    "start": "1850440",
    "end": "1856600"
  },
  {
    "text": "not one to comment on business business strategy necessarily but that's that's how I've kind of thought about this is",
    "start": "1856600",
    "end": "1862480"
  },
  {
    "text": "yeah like that's the valuable trajectory of of where we're headed I think it's inevitable because you know you run in I",
    "start": "1862480",
    "end": "1869639"
  },
  {
    "text": "know in business I have seen many many cases where these closed models and the",
    "start": "1869639",
    "end": "1875039"
  },
  {
    "text": "licenses surrounding them and the concern about proprietary data it's a big challenge for people that are trying",
    "start": "1875039",
    "end": "1881360"
  },
  {
    "text": "to get into them as quickly as possible to navigate that through it throws a whole bunch of legal concern around it",
    "start": "1881360",
    "end": "1887480"
  },
  {
    "text": "and then you guard rails which slows it down so it makes perfect sense to go and",
    "start": "1887480",
    "end": "1892919"
  },
  {
    "text": "consume and participate in the open Community uh and I think just like software it's inevitable business will",
    "start": "1892919",
    "end": "1899200"
  },
  {
    "text": "force us into that direction so it's not it's not people doing it out of the goodness of their hearts it's people",
    "start": "1899200",
    "end": "1904240"
  },
  {
    "text": "doing it for the betterment of their businesses uh because it's the only sustainable viable option they have",
    "start": "1904240",
    "end": "1909639"
  },
  {
    "text": "right now the rug can't get yanked out from under you very quickly yeah so yeah I think we had no idea a couple of",
    "start": "1909639",
    "end": "1916880"
  },
  {
    "text": "months ago that we were going to have this conversation now though I think you and I probably expect things to happen",
    "start": "1916880",
    "end": "1922399"
  },
  {
    "text": "faster than most people out there because we're neck deep in stuff all the time but I don't even think we realize",
    "start": "1922399",
    "end": "1928039"
  },
  {
    "text": "just how fast that would happen I think it's going to I'm I'm trying to adjust my own brain for the fact that that will",
    "start": "1928039",
    "end": "1933600"
  },
  {
    "text": "keep happening and will probably accelerate so we're going to have a lot to talk about in the days ahead yeah the",
    "start": "1933600",
    "end": "1940159"
  },
  {
    "text": "trend that we're seeing is happening very quick that I thought would take much longer with these open models so if",
    "start": "1940159",
    "end": "1946360"
  },
  {
    "text": "you look back at these decisions that have been made around like funding new",
    "start": "1946360",
    "end": "1951960"
  },
  {
    "text": "GPU clusters for different startups trying to produce new Foundation models",
    "start": "1951960",
    "end": "1957080"
  },
  {
    "text": "so think about um like we saw funding $1.3 billion for inflection and the",
    "start": "1957080",
    "end": "1964639"
  },
  {
    "text": "Laten space guys in in their post on AI Engineers have highlighted some of these for mistol and other ones that there's",
    "start": "1964639",
    "end": "1972279"
  },
  {
    "text": "this sort of hoarding of gpus which is taking place but those strategy",
    "start": "1972279",
    "end": "1978120"
  },
  {
    "text": "decisions were made you know how long ago like two months and now is having",
    "start": "1978120",
    "end": "1985279"
  },
  {
    "text": "that sort of compute infrastructure is that the differentiator that is going to make the difference in the business",
    "start": "1985279",
    "end": "1991559"
  },
  {
    "text": "world I think you know I'm not saying it's not going to be good for those businesses I think probably they'll do",
    "start": "1991559",
    "end": "1998960"
  },
  {
    "text": "great things and be wonderful but you don't have to now have this sort of",
    "start": "1998960",
    "end": "2004320"
  },
  {
    "text": "large GPU cluster with thousands of gpus to be a player and create value in the",
    "start": "2004320",
    "end": "2012760"
  },
  {
    "text": "marketplace so yeah it's interesting to also see how the Dynamics of funding and",
    "start": "2012760",
    "end": "2018919"
  },
  {
    "text": "business strategy are kind of getting intermixed with this rapid proliferation and kind of individual developers small",
    "start": "2018919",
    "end": "2025360"
  },
  {
    "text": "groups of developers creating these models like open chat and other ones we're also seeing you know you know",
    "start": "2025360",
    "end": "2031159"
  },
  {
    "text": "going back to our conversation just a moment ago about you know 7 billion parameters being kind of an over under",
    "start": "2031159",
    "end": "2036279"
  },
  {
    "text": "decision point because it changed es how you're going to go Implement with that under 7 billion you're going to have",
    "start": "2036279",
    "end": "2042399"
  },
  {
    "text": "whole Industries focusing uh on things like that because they may be working out on the edge and now they're looking",
    "start": "2042399",
    "end": "2048480"
  },
  {
    "text": "at in the not so distant future you know we what whereas we might have said eventually it will blah blah blah now",
    "start": "2048480",
    "end": "2054240"
  },
  {
    "text": "we're like let's go do llms on the Edge Let's go uh you know I can have a GPU",
    "start": "2054240",
    "end": "2060599"
  },
  {
    "text": "that's a single board in whatever Edge device we're talking about and you're going to see whole Industries pop up",
    "start": "2060599",
    "end": "2067320"
  },
  {
    "text": "around the ability to do that because you're within that as you pointed out the the RAM available on the GPU so",
    "start": "2067320",
    "end": "2073679"
  },
  {
    "text": "that's going to create a whole bunch of new business cases I think one of the things in my mind uh right now is it's",
    "start": "2073679",
    "end": "2079919"
  },
  {
    "text": "such an explosive kind of wild west moment for us here is is always the case",
    "start": "2079919",
    "end": "2085118"
  },
  {
    "text": "all of the concerns that touch onto these uh issues such as cyber security",
    "start": "2085119",
    "end": "2090398"
  },
  {
    "text": "such as uh how it affects your Workforce your productivity how do you integrate the Tooling in what does it mean for",
    "start": "2090399",
    "end": "2096638"
  },
  {
    "text": "changing business stry and opportunities this is all trailing distantly behind",
    "start": "2096639",
    "end": "2102200"
  },
  {
    "text": "even things like AI ethics which we've covered quite a bit you know how do you uh legal Frameworks at different",
    "start": "2102200",
    "end": "2108800"
  },
  {
    "text": "countries and different municipalities and such how do you catch up all of",
    "start": "2108800",
    "end": "2114720"
  },
  {
    "text": "those things with the fact that we're having this amazing Cambrian explosion in terms of model availability",
    "start": "2114720",
    "end": "2121440"
  },
  {
    "text": "accessibility and fragmentation into many different use cases that were not thought of two months ago yeah you had",
    "start": "2121440",
    "end": "2128760"
  },
  {
    "text": "highlighted the security side of this I think it's a really good note because",
    "start": "2128760",
    "end": "2134320"
  },
  {
    "text": "one thing I've seen is you go to for example the hugging face llm leaderboard",
    "start": "2134320",
    "end": "2140520"
  },
  {
    "text": "right like let's say I'm a person I want to use the greatest open llm that I can find let's say that for one maybe a lot",
    "start": "2140520",
    "end": "2149160"
  },
  {
    "text": "of the licensing causes problems for me but let's say all the licensing problems are equal then I go to the leaderboard I",
    "start": "2149160",
    "end": "2156040"
  },
  {
    "text": "click on some of those that are high up on the leaderboard and the lack of",
    "start": "2156040",
    "end": "2161280"
  },
  {
    "text": "information around the data processing the training set the fine-tuning set the",
    "start": "2161280",
    "end": "2168240"
  },
  {
    "text": "testing and security vulnerabilities potentially like prompt injection",
    "start": "2168240",
    "end": "2173520"
  },
  {
    "text": "vulnerabilities all of these things similar to like you go to GitHub it's the same with open source code right you",
    "start": "2173520",
    "end": "2179440"
  },
  {
    "text": "can search for some tool and it might have a little bit of information in the readme and might say okay great import",
    "start": "2179440",
    "end": "2187079"
  },
  {
    "text": "solves my problem and move on but that's a recipe for introducing vulnerabilities",
    "start": "2187079",
    "end": "2193560"
  },
  {
    "text": "into your code it's why it it's why uh products like snake which I think is a",
    "start": "2193560",
    "end": "2198640"
  },
  {
    "text": "cool way that I found for developers to deal with that sort of issue on the code side is you know analyzing your",
    "start": "2198640",
    "end": "2204599"
  },
  {
    "text": "dependencies to look for known vulnerabilities in open- Source projects",
    "start": "2204599",
    "end": "2209760"
  },
  {
    "text": "but there's nothing like that for LMS right which of these llms has more",
    "start": "2209760",
    "end": "2215720"
  },
  {
    "text": "hallucinations than another one which of them has more toxicity than other ones",
    "start": "2215720",
    "end": "2220920"
  },
  {
    "text": "which of them are more prone to prompt injection type of things than other ones",
    "start": "2220920",
    "end": "2226240"
  },
  {
    "text": "all of that's not on the leaderboard right and one of the things to also note",
    "start": "2226240",
    "end": "2231599"
  },
  {
    "text": "here is we're kind of addressing all of the kind of the technical and I don't necessarily mean like code technical but",
    "start": "2231599",
    "end": "2238440"
  },
  {
    "text": "you know things like the legalities and documentation and how do you put in",
    "start": "2238440",
    "end": "2244520"
  },
  {
    "text": "compliance around it all these things but I've also o noticed uh and I'm just kind of mentioning it passing right now",
    "start": "2244520",
    "end": "2251079"
  },
  {
    "text": "because we can't delve into it there's a huge cultural thing that we're also trying to digest right now you know we've talked this year about how this",
    "start": "2251079",
    "end": "2257920"
  },
  {
    "text": "you know 2023 is really the year that it's been huge in the Public's Consciousness people are using the stuff",
    "start": "2257920",
    "end": "2264560"
  },
  {
    "text": "and they're aware they're using it uh in many parts of their lives things like the chat GPT app you know everyone's",
    "start": "2264560",
    "end": "2270240"
  },
  {
    "text": "using it on their phones and such these days I think I've had more conversations in the last three months around people",
    "start": "2270240",
    "end": "2276720"
  },
  {
    "text": "trying to figure out not just like the business aspect of how do I adopt but",
    "start": "2276720",
    "end": "2282119"
  },
  {
    "text": "also uh a lot of fear uh and a lot of concern about that and so I think that is becoming part of what we need to be",
    "start": "2282119",
    "end": "2289040"
  },
  {
    "text": "able to think about from a business strategy standpoint isn't just the cyber security and the compliance and all",
    "start": "2289040",
    "end": "2294720"
  },
  {
    "text": "these issues but also how do you bring the humans along for the ride yeah and get them integrated in as we're making",
    "start": "2294720",
    "end": "2301560"
  },
  {
    "text": "these massive leaps forward so don't forget your humans uh in the equation as",
    "start": "2301560",
    "end": "2307160"
  },
  {
    "text": "you as you try to take advantage of all this amazing llm goodness really good point",
    "start": "2307160",
    "end": "2312560"
  },
  {
    "text": "and I think some of the writing that I wanted to share as our learning resources at the end of this highlights",
    "start": "2312560",
    "end": "2318800"
  },
  {
    "text": "some aspects of those points that you just mentioned which is and I've been trying to tell people this recently that",
    "start": "2318800",
    "end": "2324960"
  },
  {
    "text": "the llm or the generative model the image generation model in some ways people are thinking about those things",
    "start": "2324960",
    "end": "2331839"
  },
  {
    "text": "like applications but really they're tools that are embedded in applications",
    "start": "2331839",
    "end": "2336920"
  },
  {
    "text": "so you're building an application for real people users that might make use of",
    "start": "2336920",
    "end": "2343480"
  },
  {
    "text": "a tool like an llm or an image generation model but application development is still part of it and",
    "start": "2343480",
    "end": "2350480"
  },
  {
    "text": "coding and Engineering is part of it and security is part of it and your UI ux",
    "start": "2350480",
    "end": "2356800"
  },
  {
    "text": "around how you interact with your customers is part of it so that sort of",
    "start": "2356800",
    "end": "2362440"
  },
  {
    "text": "thinking about these things as embedded tools within an application I think is important it's one thing that Jay Alamar",
    "start": "2362440",
    "end": "2369359"
  },
  {
    "text": "who was a previous guest on our show he has a really great article which I would recommend as a learning resource if",
    "start": "2369359",
    "end": "2375440"
  },
  {
    "text": "you're thinking about this sort of how to create competitive advantage or Moes with your AI applications he has an",
    "start": "2375440",
    "end": "2381839"
  },
  {
    "text": "article called AI is eating the world and he gives some really good analysis",
    "start": "2381839",
    "end": "2386920"
  },
  {
    "text": "of thinking about okay where are their competitive advantages and where aren't there and he has this really nice",
    "start": "2386920",
    "end": "2393520"
  },
  {
    "text": "diagram of like models are down here your application is here that's where you live right the application Level",
    "start": "2393520",
    "end": "2400560"
  },
  {
    "text": "above that maybe in the custom model like fine-tuning level and then above that there's all of these things that",
    "start": "2400560",
    "end": "2406599"
  },
  {
    "text": "are unrelated to the model or not unrelated but are more so like business concerns right how is it distributed you",
    "start": "2406599",
    "end": "2414079"
  },
  {
    "text": "know what sort of proprietary or sensitive data are you dealing with what sort of domain expertise do you have",
    "start": "2414079",
    "end": "2420000"
  },
  {
    "text": "that can be infused in your application etc etc those are the sorts of things",
    "start": "2420000",
    "end": "2425480"
  },
  {
    "text": "that can differentiate you and I found his writing on this very helpful in",
    "start": "2425480",
    "end": "2430720"
  },
  {
    "text": "framing my mind so I would recommend people look at that I like it in addition because it reminds us to stay",
    "start": "2430720",
    "end": "2436640"
  },
  {
    "text": "grounded and be practical and and and while the world is changing out from under us in so many ways kind of the",
    "start": "2436640",
    "end": "2442520"
  },
  {
    "text": "workflow of how you think about applications and getting uh productivity",
    "start": "2442520",
    "end": "2447599"
  },
  {
    "text": "out to people is still largely the same new tools and stuff like that but you the same concerns exist and so sometimes",
    "start": "2447599",
    "end": "2455160"
  },
  {
    "text": "maybe you take a deep breath and you go I know how to do this we've been doing this even before this moment good point",
    "start": "2455160",
    "end": "2461000"
  },
  {
    "text": "I think that's a good good statement to end with uh so thanks for journeying through the uh Cambrian explosion or",
    "start": "2461000",
    "end": "2467800"
  },
  {
    "text": "proliferation with me Chris this has been fun that's right it's a space warp here of models flying by us Good Times",
    "start": "2467800",
    "end": "2474920"
  },
  {
    "text": "Daniel uh thanks a lot all right talk to you [Music]",
    "start": "2474920",
    "end": "2484920"
  },
  {
    "text": "soon thank you for listening to practical AI your next step is to",
    "start": "2484920",
    "end": "2490240"
  },
  {
    "text": "subscribe now if you haven't already and if you're a longtime listener of the show help us reach more people by",
    "start": "2490240",
    "end": "2496560"
  },
  {
    "text": "sharing practical AI with your friends and colleagues thanks once again to fastly and fly for partnering with us to",
    "start": "2496560",
    "end": "2502640"
  },
  {
    "text": "bring you all Chang doog podcasts check out what they're up to at fastly.com and",
    "start": "2502640",
    "end": "2508000"
  },
  {
    "text": "fly.io and to our beat freaking residence breakmaster cylinder for continuously cranking out the best beats",
    "start": "2508000",
    "end": "2513800"
  },
  {
    "text": "in the biz that's all for now we'll talk to you again next time [Music]",
    "start": "2513800",
    "end": "2529520"
  },
  {
    "text": "k l",
    "start": "2529520",
    "end": "2532680"
  }
]
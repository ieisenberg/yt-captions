[
  {
    "text": "[Music]",
    "start": "0",
    "end": "7120"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspire to or are",
    "start": "7120",
    "end": "13719"
  },
  {
    "text": "curious how AI related Technologies are changing the world this is the show for you thank you to our partners at fastly",
    "start": "13719",
    "end": "21080"
  },
  {
    "text": "for shipping all of our pods super fast to wherever you listen check them out at",
    "start": "21080",
    "end": "26160"
  },
  {
    "text": "fast.com and to our friends that fly deploy your app server and database close to your users no Ops required",
    "start": "26160",
    "end": "33800"
  },
  {
    "text": "learn more at [Music]",
    "start": "33800",
    "end": "42270"
  },
  {
    "text": "fly.io welcome to another episode of practical AI this is Daniel whack I am",
    "start": "42640",
    "end": "49160"
  },
  {
    "text": "the founder and CEO at prediction guard and I'm joined as always by my co-host",
    "start": "49160",
    "end": "54320"
  },
  {
    "text": "Chris Benson who is a tech strategist at locked Martin how you doing Chris doing very well today Daniel how's it going oh",
    "start": "54320",
    "end": "61000"
  },
  {
    "text": "it's going great I I spent the afternoon in sort of a a brainstorming session with a couple of our our team members",
    "start": "61000",
    "end": "67600"
  },
  {
    "text": "here at prediction guard and it was it was a ton of fun so talking about a lot of prompt engineering things and how",
    "start": "67600",
    "end": "74880"
  },
  {
    "text": "different models perform and and that sort of thing so it was a good time I'm glad you're doing that cuz you know what",
    "start": "74880",
    "end": "80560"
  },
  {
    "text": "I just want things that just work you know I don't have to think about it I'm glad you're thinking about it uh I think",
    "start": "80560",
    "end": "86920"
  },
  {
    "text": "we might have someone else to talk to who knows how to make things that just work yeah yeah well a lot of the models that",
    "start": "86920",
    "end": "93240"
  },
  {
    "text": "we're running um sort of just work for us in terms of inference because we're",
    "start": "93240",
    "end": "98439"
  },
  {
    "text": "we're hosting um some of our models in base 10 and we've got Tuan uh joining us",
    "start": "98439",
    "end": "104119"
  },
  {
    "text": "from base 10 today how you doing Tuan hi Dan hi Chris nice nice to see you guys again um thanks for the kind words Dan",
    "start": "104119",
    "end": "111119"
  },
  {
    "text": "yeah yeah for sure well it's exciting to have you actually back on the show because it was I believe I looked it up",
    "start": "111119",
    "end": "119079"
  },
  {
    "text": "it was like May May June 2021 when we recorded and released the",
    "start": "119079",
    "end": "124719"
  },
  {
    "text": "last episode with you so how you doing what's what's new and how is base 10",
    "start": "124719",
    "end": "130679"
  },
  {
    "text": "how's the ride been yeah it's it's been crazy um I feel like the um lost I think it was like May",
    "start": "130679",
    "end": "137680"
  },
  {
    "text": "2021 um that's like a millennium in AI time you know oh my God it h if it",
    "start": "137680",
    "end": "142800"
  },
  {
    "text": "actually does feel like it was a different Jobo yes it feels like the job before the last",
    "start": "142800",
    "end": "148840"
  },
  {
    "text": "job if that makes sense no I think um being crazy I think the last two years for",
    "start": "148840",
    "end": "154599"
  },
  {
    "text": "everyone here have probably been a bit of a warwind and you guys are pretty on top of current things in machine",
    "start": "154599",
    "end": "160480"
  },
  {
    "text": "learning in Ai and I think H I imagine just like for you guys it's hard to keep",
    "start": "160480",
    "end": "165640"
  },
  {
    "text": "up at times with you know what's going on I think you know lot we only do one show a week and you know it's getting we",
    "start": "165640",
    "end": "171879"
  },
  {
    "text": "almost need a Daily Show there's so much content now it's not enough yeah don't give our listeners ideas cuz I don't",
    "start": "171879",
    "end": "178000"
  },
  {
    "text": "know I don't know if I can do a daily show but uh it is a lot and I think so",
    "start": "178000",
    "end": "183879"
  },
  {
    "text": "I'm looking back previous at our at our episode and last time we talked about sort of the easiest way to create ml",
    "start": "183879",
    "end": "191720"
  },
  {
    "text": "apps that was kind of part of how the conversation was framed and I know just from working with you and and talking",
    "start": "191720",
    "end": "199680"
  },
  {
    "text": "with you as friends that a lot has changed and you've seen some things",
    "start": "199680",
    "end": "205560"
  },
  {
    "text": "within how people are deploying machine learning AI systems that now base 10 is",
    "start": "205560",
    "end": "212480"
  },
  {
    "text": "really focused on could you give us kind of like the high level view of base 10",
    "start": "212480",
    "end": "218480"
  },
  {
    "text": "and the type of problem the type of solution that you're offering yeah yeah yeah um I think I think it's just worth",
    "start": "218480",
    "end": "224159"
  },
  {
    "text": "probably like pointing out you know before I go into base 10 specific things like what are like the key things that",
    "start": "224159",
    "end": "229519"
  },
  {
    "text": "changed since we last talked I think you know sure if you think of like the year of like 2012 to 2020 um you know data",
    "start": "229519",
    "end": "236239"
  },
  {
    "text": "scientists were the ones doing a l machine learning I think you know that's changed for a number of reasons um I",
    "start": "236239",
    "end": "241920"
  },
  {
    "text": "have a lot of thoughts on that but probably the bigger changes are you know the are the emergence of good open source models and I know you do a lot of",
    "start": "241920",
    "end": "248439"
  },
  {
    "text": "work with that and you know like we've seen hugging faces a community evolve into like really really vibrant place",
    "start": "248439",
    "end": "254400"
  },
  {
    "text": "where if you want to get a sense of how fast things are moving doesn't take long to you know take screenshots of hugging",
    "start": "254400",
    "end": "261519"
  },
  {
    "text": "face every Monday morning and see how the trending is changing and you'll see that you things are pretty different",
    "start": "261519",
    "end": "267000"
  },
  {
    "text": "every week I don't know if it was Daniel that said this or another friend of mine but um the analogy was that you know",
    "start": "267000",
    "end": "272199"
  },
  {
    "text": "hugging face has become to AI kind of what GitHub has always been for software developers over the last decade or so um",
    "start": "272199",
    "end": "279039"
  },
  {
    "text": "it's just you know it's the place to go to find it anyway I didn't mean to interrupt you there yeah and the good about it but also the confusing too it's",
    "start": "279039",
    "end": "286560"
  },
  {
    "text": "like you know you have like random person clones model or copies model and",
    "start": "286560",
    "end": "294520"
  },
  {
    "text": "uploads random Mo version of that model that like maybe works",
    "start": "294520",
    "end": "300520"
  },
  {
    "text": "yeah 100% I feel like the game you have to play with hugging face it's like but doesn't run you does the model but does",
    "start": "300520",
    "end": "306680"
  },
  {
    "text": "the model run U but you know I think open source emerged and I I think like",
    "start": "306680",
    "end": "311720"
  },
  {
    "text": "stuff like whisper showing up and you know some of these OCR type replacement",
    "start": "311720",
    "end": "317320"
  },
  {
    "text": "models showing up you know they're probably the more more interesting ones to me not because what they do but",
    "start": "317320",
    "end": "323199"
  },
  {
    "text": "because they end up just solving a lot of open problems yeah you know if you think about transcription as a problem",
    "start": "323199",
    "end": "330280"
  },
  {
    "text": "of think about nuance and like how long they were working for that yeah like literally 20 or 30 years of of work just",
    "start": "330280",
    "end": "336520"
  },
  {
    "text": "kind of all right that's solve problem now let's move on oh we we've actually solved multil language with the same",
    "start": "336520",
    "end": "342520"
  },
  {
    "text": "model too business models come and go don't they yeah yeah it's wild and I think like the last piece is just around",
    "start": "342520",
    "end": "349520"
  },
  {
    "text": "you know like the chat gbt moment for AI interesting for a number of reasons I",
    "start": "349520",
    "end": "355000"
  },
  {
    "text": "personally think it's someone who build infrastructure that it's most interesting because if you want to call",
    "start": "355000",
    "end": "360520"
  },
  {
    "text": "that the iPhone moment of AI I think it's a bit different to that because it's so early in the journey it's like",
    "start": "360520",
    "end": "366800"
  },
  {
    "text": "if the iPhone showed up when we were all using 5110 from Nokia the world would be very very different I think because",
    "start": "366800",
    "end": "374039"
  },
  {
    "text": "consumers and developers their first taste of machine learning in AI was through chat gbt and gbt apis the stakes",
    "start": "374039",
    "end": "382360"
  },
  {
    "text": "are just you know it's just harder to build something good like you know people don't want to use a model that",
    "start": "382360",
    "end": "388199"
  },
  {
    "text": "takes 12 seconds to run mhm you know like highspeed production inference is",
    "start": "388199",
    "end": "393639"
  },
  {
    "text": "you know taken for granted when you're using um this model and then when you kind of combine that with okay open",
    "start": "393639",
    "end": "399160"
  },
  {
    "text": "source models need to be run somewhere we we personally think that's like okay well there's a massive infrastructure opportunity there um or",
    "start": "399160",
    "end": "406479"
  },
  {
    "text": "maybe not even opportunity that just a a fact that a whole new stack will be built to support um models to be able to",
    "start": "406479",
    "end": "414720"
  },
  {
    "text": "power these end user experiences and I think like that's kind of the core in sight kind of going into base 10 and",
    "start": "414720",
    "end": "422000"
  },
  {
    "text": "talking a bit about base 10 around like what's changed is that you know we we kind of two years ago when we were",
    "start": "422000",
    "end": "428280"
  },
  {
    "text": "talking about data Sciences we weren't talking about engineers I think that's pretty key to our story which is that I",
    "start": "428280",
    "end": "434520"
  },
  {
    "text": "think we came to the realization that every engineer needs to Grapple with machine learning now as opposed to maybe",
    "start": "434520",
    "end": "440360"
  },
  {
    "text": "a smaller Market data scientist I think going from smaller models that run in memory to larger models is another big",
    "start": "440360",
    "end": "448759"
  },
  {
    "text": "you know Focus ch we've had I think there's a bunch of language stuff and nltk stuff and you know you were doing",
    "start": "448759",
    "end": "454720"
  },
  {
    "text": "all that work Daniel but for the most part everyone was using you know psychic learn and that and psychic learn models",
    "start": "454720",
    "end": "460000"
  },
  {
    "text": "for the most part run in memory on CPUs on CPUs yeah if you think just in that",
    "start": "460000",
    "end": "466000"
  },
  {
    "text": "time period the the amount of maturation you know that's occurred in this industry it still bought you said",
    "start": "466000",
    "end": "471520"
  },
  {
    "text": "something a second ago which I kind of hit me and that is most people out there in the general public you know are",
    "start": "471520",
    "end": "477080"
  },
  {
    "text": "really just getting into this you know with chat GPT stuff and we've come a long road already but I just I'm",
    "start": "477080",
    "end": "482800"
  },
  {
    "text": "listening to you and it's amazing how far we've come in such a short time yeah it's insane 100% And I think that you",
    "start": "482800",
    "end": "489680"
  },
  {
    "text": "know going from small models to large models as well it's just like that change kind of happened pretty quickly",
    "start": "489680",
    "end": "495360"
  },
  {
    "text": "you know as someone who did a bunch of work with small models like they have their time in place but they just aren't that fun",
    "start": "495360",
    "end": "501400"
  },
  {
    "text": "anymore like something that runs in memory just doesn't give you the same feeling as and then I think the last one",
    "start": "501400",
    "end": "507560"
  },
  {
    "text": "is just so much of the stuff that was happening with machine learning outside of fang I'd say was like Fang had some",
    "start": "507560",
    "end": "514760"
  },
  {
    "text": "production use cases around like ad serving and search and and whatnot but outside of that it was mostly just",
    "start": "514760",
    "end": "520039"
  },
  {
    "text": "internal workflows you go and work on fraud and content moderation and recommendation systems and I think you",
    "start": "520039",
    "end": "526320"
  },
  {
    "text": "know going from hey every product is going to have some sort of machine learning in it and every existing",
    "start": "526320",
    "end": "532240"
  },
  {
    "text": "product what will definitely and 90% of new products will be built with the with a new pillar that is machine learning in",
    "start": "532240",
    "end": "539040"
  },
  {
    "text": "AI which which wasn't the case I think two years ago which is just crazy to think about yeah it's completely changed",
    "start": "539040",
    "end": "544880"
  },
  {
    "text": "in that time I think one thing that was brought into Focus for me while you were talking was that as soon as you make",
    "start": "544880",
    "end": "552440"
  },
  {
    "text": "this leap to kind of larger models and you make the leap from some closed API",
    "start": "552440",
    "end": "561440"
  },
  {
    "text": "that's very fast to maybe running your own model there's two things that become like immediately clear one is the",
    "start": "561440",
    "end": "568480"
  },
  {
    "text": "infrastructure chall around that which I think is the workflow around that and the model hosting you know base 10 of",
    "start": "568480",
    "end": "575240"
  },
  {
    "text": "course is an expert in that and the other side of that is like the product sort of concerns around running these",
    "start": "575240",
    "end": "583000"
  },
  {
    "text": "things which I feel like you know we always have great conversations to and because like you're on the one side of",
    "start": "583000",
    "end": "589320"
  },
  {
    "text": "that and I'm probably on the other side because yeah like when you're using chat GPT or even the open AI API they have",
    "start": "589320",
    "end": "596040"
  },
  {
    "text": "layers of you know protections on the prom s and like on the output they have",
    "start": "596040",
    "end": "601720"
  },
  {
    "text": "you know filters to make sure they're not responding in certain ways and there's all these product concerns that",
    "start": "601720",
    "end": "606760"
  },
  {
    "text": "people don't think about and then they take like a llama 2 model or something they run it and then there's like oh",
    "start": "606760",
    "end": "613320"
  },
  {
    "text": "this doesn't respond like this is not a product right and so like the infrastructure is a piece of that the",
    "start": "613320",
    "end": "619680"
  },
  {
    "text": "ability to iterate very quickly with models of a variety of types I think is",
    "start": "619680",
    "end": "624959"
  },
  {
    "text": "part of that infrastructure challenge how do you see that infrastructure piece of this kind of playing out yeah maybe",
    "start": "624959",
    "end": "631079"
  },
  {
    "text": "just before I say go into that when you were saying that it reminded me of like I bought a drone in",
    "start": "631079",
    "end": "636320"
  },
  {
    "text": "2014 um and I was so EXC like DJI Phantom 3 I was so pumped and you know I",
    "start": "636320",
    "end": "641880"
  },
  {
    "text": "FLW it around a bit and they had bit had autopilot mode where you didn't have to do anything um like it kind of",
    "start": "641880",
    "end": "647160"
  },
  {
    "text": "stabilized itself and then there was this button that said manual mode and had like all sorts of warnings and I",
    "start": "647160",
    "end": "652639"
  },
  {
    "text": "remember saying like being like Oh how hard can it be right oh I really like",
    "start": "652639",
    "end": "657920"
  },
  {
    "text": "jokeing like I was in space but I put it into manual mode while I was up in the",
    "start": "657920",
    "end": "662959"
  },
  {
    "text": "air and it just fell to the ground very very fast I don't know Chris do you have some experience with this football well",
    "start": "662959",
    "end": "669160"
  },
  {
    "text": "I'm I'm in Aerospace uh professionally so I know a little bit about that and yes Chris weren't you like the TV host",
    "start": "669160",
    "end": "676959"
  },
  {
    "text": "of the Drone racing competition or something like this yeah a few years ago uh yeah I was",
    "start": "676959",
    "end": "683760"
  },
  {
    "text": "I was one of the hosts uh of the first drone Racing League they had a championship series and they were using",
    "start": "683760",
    "end": "691160"
  },
  {
    "text": "instead of you as a human they were navigating obstacle courses and stuff like that and what I learned through that experience is when you have how",
    "start": "691160",
    "end": "698920"
  },
  {
    "text": "much autonomy is required to make even Small Things fly well yeah and yeah so I",
    "start": "698920",
    "end": "705480"
  },
  {
    "text": "I sympathize with you for going on manual there oh no don't do it don't do it and the analogy I think holds here",
    "start": "705480",
    "end": "711040"
  },
  {
    "text": "it's like the Clos the closed API is seems so great and then you you see something like a latu or mistro and",
    "start": "711040",
    "end": "716760"
  },
  {
    "text": "you're like okay I'll just rip and replace this it's like nope that's not going to work um for a number of reasons and I think that's how we how we see",
    "start": "716760",
    "end": "723839"
  },
  {
    "text": "about think about infrastructure based sandwich is that running models in production is very very difficult it's",
    "start": "723839",
    "end": "729839"
  },
  {
    "text": "difficult for a number of reasons so I can get start like from like a user requirements perspective like latency",
    "start": "729839",
    "end": "736040"
  },
  {
    "text": "and throughput Paramount um costs of what something you want to optimize data",
    "start": "736040",
    "end": "741360"
  },
  {
    "text": "privacy is you know a whole another Beast um security comes into play then",
    "start": "741360",
    "end": "746600"
  },
  {
    "text": "orchestrating this across a bunch of different Hardware um orchestrating this across clouds becomes a problem",
    "start": "746600",
    "end": "752760"
  },
  {
    "text": "benchmarking these things isn't easy and that's even before you go into all the evals and the you know the kind of like",
    "start": "752760",
    "end": "758959"
  },
  {
    "text": "the guard rails you want to put around this thing to get it running and I know that's some of the stuff that you think a lot about Dan so just as an extension",
    "start": "758959",
    "end": "766000"
  },
  {
    "text": "of what you're saying and Daniel you mentioned it at first but if you could also talk a little bit about what the difference is about just host like like",
    "start": "766000",
    "end": "773000"
  },
  {
    "text": "just having the model hosted and kind of the idea around what you have to put around it as a to make it a product I",
    "start": "773000",
    "end": "779360"
  },
  {
    "text": "don't think most people talk about I don't hear a lot of conversations about that and it's a big set of gotas on what",
    "start": "779360",
    "end": "785279"
  },
  {
    "text": "to do you know and kind of what's involved in that what's your thinking around that when when people are looking at doing that I can talk well about the",
    "start": "785279",
    "end": "791839"
  },
  {
    "text": "first one and I have thoughts about the second Dan's going to be the Exeter on the ladder piece of that but to get a",
    "start": "791839",
    "end": "797199"
  },
  {
    "text": "model running in production there's actually a ton of work you need to do from an infrastructure perspective but and this is before we talk about the",
    "start": "797199",
    "end": "802639"
  },
  {
    "text": "workflow stuff you know you need to figure out how to containerize this thing and get this image running like you know as we alluded to to earlier",
    "start": "802639",
    "end": "809639"
  },
  {
    "text": "like just taking your model parking face and expecting it to run is not a thing you know there's a bunch of requirements",
    "start": "809639",
    "end": "815440"
  },
  {
    "text": "that these models have there's quantization um inside the code there is um different base images that they might",
    "start": "815440",
    "end": "822079"
  },
  {
    "text": "need based on Torch and Pie torch and um python versions um and then you know you",
    "start": "822079",
    "end": "827959"
  },
  {
    "text": "can really find yourself in a bit of a pickle just trying to dockerize a model so the first thing is you need to figure",
    "start": "827959",
    "end": "833279"
  },
  {
    "text": "out how to get this in some sort of containerized form so you can run it elsewhere once you have that the truth",
    "start": "833279",
    "end": "838800"
  },
  {
    "text": "is that you need to spit up some sort of servers that can deal with variable traffic um and the reason why that is is that traffic you know these things tend",
    "start": "838800",
    "end": "845199"
  },
  {
    "text": "to be expensive they tend to be bound by compute so if you get smashed with a bunch of requests it's not like you can",
    "start": "845199",
    "end": "852519"
  },
  {
    "text": "just have one model it will que out they will time out the whole thing will slow down your product won't work so you need to figure out how to scale up and down",
    "start": "852519",
    "end": "859240"
  },
  {
    "text": "with traffic and then you need to figure out all the security Concepts that come with all that that's just on the serving",
    "start": "859240",
    "end": "864920"
  },
  {
    "text": "layer now you need to start think about the workflow layer that sits on top of that and I think you know version management is you a non-existent for",
    "start": "864920",
    "end": "871120"
  },
  {
    "text": "hooking up into cicd it to really treat this like a a service or a micros service that has putting your model by",
    "start": "871120",
    "end": "877560"
  },
  {
    "text": "an API you need observability um and logging another whole um set of features",
    "start": "877560",
    "end": "883000"
  },
  {
    "text": "and what you realize is that taking a model and getting it working in production behind a reliable secure",
    "start": "883000",
    "end": "890839"
  },
  {
    "text": "performant API and maybe cost efficient as someone has done this myself um and",
    "start": "890839",
    "end": "895920"
  },
  {
    "text": "someone has built a company to try to abstract this way it it is easily for",
    "start": "895920",
    "end": "900959"
  },
  {
    "text": "one model couple of people have had counts work for a couple quarters if you're lucky at scale and I think that",
    "start": "900959",
    "end": "907000"
  },
  {
    "text": "is the most efficient organizations that can hire people with kubernetes u",
    "start": "907000",
    "end": "912839"
  },
  {
    "text": "kubernetes experience to be able to do this and so that's type of things that we try to abstract away from our users",
    "start": "912839",
    "end": "919519"
  },
  {
    "text": "where it's like you know you figure out the python code we'll figure out everything else and we'll give this model this first class treatment um so",
    "start": "919519",
    "end": "927079"
  },
  {
    "text": "that you conversion around there you can log around that you can observe it um and you can call it but you don't need",
    "start": "927079",
    "end": "932240"
  },
  {
    "text": "to think so much about that you get that free that's now to the point where you have something behind an API and ready",
    "start": "932240",
    "end": "939079"
  },
  {
    "text": "to consume now there's a bunch of stuff that needs to happen to make sure that you know it doesn't start saying random",
    "start": "939079",
    "end": "944959"
  },
  {
    "text": "Stu that you protect against hallucinations it's not just ingesting pii all the time Dan can probably just",
    "start": "944959",
    "end": "951480"
  },
  {
    "text": "talk really quickly about that as well I'm sure yeah I think part of the reason why I'm always excited to talk to to and",
    "start": "951480",
    "end": "958600"
  },
  {
    "text": "and is team at base 10 is because they are experts in this all of those layers that we just talked about I was actually",
    "start": "958600",
    "end": "965519"
  },
  {
    "text": "on a call uh with someone the other day and we were talking about like spinning",
    "start": "965519",
    "end": "972360"
  },
  {
    "text": "up some microservices or something and I think my comment was like I just really don't want to care about kubernetes",
    "start": "972360",
    "end": "978079"
  },
  {
    "text": "because I don't want to like wake up lying in a ditch crying in the fetal position like that's how I view that",
    "start": "978079",
    "end": "985000"
  },
  {
    "text": "like whole world so uh props to you and your team for dealing with that side of things I think that's what's allowed us",
    "start": "985000",
    "end": "991560"
  },
  {
    "text": "then on like the prediction guard side in a lot of ways to like bring up a model quickly and then have the time to",
    "start": "991560",
    "end": "1000480"
  },
  {
    "text": "think about some of these other things to and I I don't know if you can comment",
    "start": "1000480",
    "end": "1006959"
  },
  {
    "text": "on like I have my own perspective from trying to run models for for my company",
    "start": "1006959",
    "end": "1014079"
  },
  {
    "text": "but it would be interesting to hear the perspective of different pers as that",
    "start": "1014079",
    "end": "1019399"
  },
  {
    "text": "are coming into base 10 like are they people that are sort of",
    "start": "1019399",
    "end": "1026678"
  },
  {
    "text": "application developers that are you know not infrastructure people are they like",
    "start": "1026679",
    "end": "1032000"
  },
  {
    "text": "data scientists like what are the what are the types of people that are coming to base 10 and I maybe along with that",
    "start": "1032000",
    "end": "1038839"
  },
  {
    "text": "like as you mentioned closed apis are getting used a lot but still people are",
    "start": "1038839",
    "end": "1046079"
  },
  {
    "text": "coming over to think about like hosting their own model one question would be like why like who",
    "start": "1046079",
    "end": "1051840"
  },
  {
    "text": "are these people and why totally um I'll answer the second one first um no I",
    "start": "1051840",
    "end": "1056919"
  },
  {
    "text": "think I add some together is that it is more or more just Engineers um I'd say",
    "start": "1056919",
    "end": "1062280"
  },
  {
    "text": "like I I don't know if there's any there's any distinction now between like I say it's less and less data scientists",
    "start": "1062280",
    "end": "1068840"
  },
  {
    "text": "your traditional data scientists it's more and more people with some ml exposure product Engineers",
    "start": "1068840",
    "end": "1074080"
  },
  {
    "text": "infrastructure Engineers who have tried to build it themselves and have really felt the pain I think from a product",
    "start": "1074080",
    "end": "1079960"
  },
  {
    "text": "engineering perspective like why want people want to use open source apis I think cost is one big thing is that open",
    "start": "1079960",
    "end": "1086400"
  },
  {
    "text": "a has stack up over time I think or anthropic um I think the other one is",
    "start": "1086400",
    "end": "1092400"
  },
  {
    "text": "data privacy and security is that you don't want to just be piping over all your data to open AI today um and",
    "start": "1092400",
    "end": "1098799"
  },
  {
    "text": "especially when you start to talk with B2B use cases and Enterprises and I think there's like probably the more",
    "start": "1098799",
    "end": "1104080"
  },
  {
    "text": "interesting one is that there were just like a long tale of people working on weird models people are fine tuning",
    "start": "1104080",
    "end": "1109640"
  },
  {
    "text": "models um fine tuning open AI models is you know not great um you get a bit more control with that manual mode with open",
    "start": "1109640",
    "end": "1117960"
  },
  {
    "text": "source models and so it's kind of like the longtail of use cases I'd say are coming more and more and these can be",
    "start": "1117960",
    "end": "1123960"
  },
  {
    "text": "Engineers they can be machine learning Engineers they can be honestly like a lot of Audio models like different modalities that you know there's not",
    "start": "1123960",
    "end": "1130799"
  },
  {
    "text": "that much exposure to with closed API and a lot of custom stuff as well you mentioned you know like shipping data",
    "start": "1130799",
    "end": "1136840"
  },
  {
    "text": "over to to open Ai and I have talked to gazillions of people who have that as a",
    "start": "1136840",
    "end": "1142159"
  },
  {
    "text": "constraint in their businesses you know because the the attorneys for the business are like nope you don't want to",
    "start": "1142159",
    "end": "1147480"
  },
  {
    "text": "send you know your proprietary information and stuff over that I guess you would not have that issue at all",
    "start": "1147480",
    "end": "1153720"
  },
  {
    "text": "with base 10 would would you I mean that's that kind of goes away altogether when you're hosting in that way right",
    "start": "1153720",
    "end": "1159840"
  },
  {
    "text": "yeah um you have ownership of your data we don't log any of that data you're treating the model as just like a like a",
    "start": "1159840",
    "end": "1165960"
  },
  {
    "text": "map of input the outputs and nothing else yeah that would really solve a lot of people's problems by taking an",
    "start": "1165960",
    "end": "1171440"
  },
  {
    "text": "approach like that yeah and I think the second piece there is that once you adopt the Bas approach you can then start to think about like self hosting",
    "start": "1171440",
    "end": "1177760"
  },
  {
    "text": "deploying it within your own bpc like you know we have customers that deploy base 10 within their own AWS accounts",
    "start": "1177760",
    "end": "1184880"
  },
  {
    "text": "and data never leaves kind of their boundaries or their accepted boundaries",
    "start": "1184880",
    "end": "1190360"
  },
  {
    "text": "yeah and we've kind of I think you've framed the concerns that you're looking",
    "start": "1190360",
    "end": "1196000"
  },
  {
    "text": "at with base 10 very well they sort of infrastructure scaling concerns of",
    "start": "1196000",
    "end": "1201320"
  },
  {
    "text": "Hosting your own model could you maybe take a step back and just describe like",
    "start": "1201320",
    "end": "1207159"
  },
  {
    "text": "if I go into base 10 like how have you architected the approach like to I'm an",
    "start": "1207159",
    "end": "1212880"
  },
  {
    "text": "application developer I want to run you know some random fine tune of llama 2",
    "start": "1212880",
    "end": "1219280"
  },
  {
    "text": "that I've created somehow what is it like for me what what does that look like with the way that you've structured",
    "start": "1219280",
    "end": "1226280"
  },
  {
    "text": "this and what's some of the thinking behind that in terms of the workflow and and how you want it to be for people so",
    "start": "1226280",
    "end": "1232919"
  },
  {
    "text": "that they can treat I guess that model as a first class thing that is a first",
    "start": "1232919",
    "end": "1238679"
  },
  {
    "text": "class asset in terms of what they're monitoring and logging that sort of thing yeah for sure I'll go just to make",
    "start": "1238679",
    "end": "1244520"
  },
  {
    "text": "it EAS and you know try to take away of as much of the complexity but you know",
    "start": "1244520",
    "end": "1250240"
  },
  {
    "text": "maybe more importantly is to allow you to have a bit of control you know I think base 10 is like a on line to Theo",
    "start": "1250240",
    "end": "1256400"
  },
  {
    "text": "you model like you know we don't believe that anymore you know that we think that you know actually having a little bit of structure around it gives you actually",
    "start": "1256400",
    "end": "1263120"
  },
  {
    "text": "um bit of structure up front gives you a lot more flexibility a bit down the line so we have a open source Library C trust",
    "start": "1263120",
    "end": "1270640"
  },
  {
    "text": "which is basically a it's abstraction that if you write your model in you get kind of everything free and so basically",
    "start": "1270640",
    "end": "1277960"
  },
  {
    "text": "you need to write two things you need to write one python class with a load function and a predict function and this",
    "start": "1277960",
    "end": "1283480"
  },
  {
    "text": "is vanilla python code it can sit within your mon repo you can specify",
    "start": "1283480",
    "end": "1288559"
  },
  {
    "text": "requirement as you want there's nothing base 10 about these files you know you can run them outside of a base 10 I",
    "start": "1288559",
    "end": "1294240"
  },
  {
    "text": "think that's very important well but once you write that load and predict function it does two things one it tells",
    "start": "1294240",
    "end": "1299960"
  },
  {
    "text": "us hey what are you trying to do here and you know we can load that up and when we deploy a model we load that function when we infer We Run The",
    "start": "1299960",
    "end": "1307159"
  },
  {
    "text": "predict function but more importantly within those functions we allow you to compile yourself down we allow you to",
    "start": "1307159",
    "end": "1312880"
  },
  {
    "text": "can do the tricks that you need to do so that you know you still have that control and you know within that you can",
    "start": "1312880",
    "end": "1319279"
  },
  {
    "text": "write pre-processing and postprocessing functions that allow you to you know maybe like strip out some data log",
    "start": "1319279",
    "end": "1325520"
  },
  {
    "text": "something monitor something but really it's still giving you that control of the product and application Level while",
    "start": "1325520",
    "end": "1330720"
  },
  {
    "text": "still abstracting out the thing we want with trust one to have a trust developed and you can go to trust b.co and and",
    "start": "1330720",
    "end": "1338080"
  },
  {
    "text": "check out a bunch of these um it's a pretty simple abstraction and you can just push that up and we kind of give",
    "start": "1338080",
    "end": "1343559"
  },
  {
    "text": "you all the workb version management around that deploy trust yeah could you you speak then to like that's like the",
    "start": "1343559",
    "end": "1351400"
  },
  {
    "text": "prep kind of that goes into oh I've got my weird model I'm writing this python",
    "start": "1351400",
    "end": "1357880"
  },
  {
    "text": "class I'm going to deploy it on uh somewhere and I know that like one thing",
    "start": "1357880",
    "end": "1363400"
  },
  {
    "text": "that I think is really cool how you've made base 10 trust is like you mentioned it is open source and so you can run",
    "start": "1363400",
    "end": "1370840"
  },
  {
    "text": "trust things and deploy in a variety of ways one of those being like base 10's",
    "start": "1370840",
    "end": "1376240"
  },
  {
    "text": "hosted infrastructure which is of course easy but it's also like generally a",
    "start": "1376240",
    "end": "1381799"
  },
  {
    "text": "great great sort of framework to package your models but let's say that you do kind of go the base 10 route you deploy",
    "start": "1381799",
    "end": "1389799"
  },
  {
    "text": "this through the base 10 client to base 10 could you kind of compare and",
    "start": "1389799",
    "end": "1395720"
  },
  {
    "text": "contrast like let's say I just tried to run my model in a fast API API in a ec2",
    "start": "1395720",
    "end": "1404520"
  },
  {
    "text": "instance or ECS or like whatever that is in my cloud what is going to be different about what",
    "start": "1404520",
    "end": "1411320"
  },
  {
    "text": "I look at when I kind of look at my model in base 10 versus running this API",
    "start": "1411320",
    "end": "1417200"
  },
  {
    "text": "somewhere else and how does that make a meaningful difference or what are you trying to do in terms of making a",
    "start": "1417200",
    "end": "1423279"
  },
  {
    "text": "meaningful difference for the day-to-day for people yeah well I think what you're doing is that so besides you know you",
    "start": "1423279",
    "end": "1429320"
  },
  {
    "text": "can run that model in P API great you got this model you give it an input it gives you an output fantastic let's",
    "start": "1429320",
    "end": "1435159"
  },
  {
    "text": "carry on but it's like the depth of features and the creation of work flow which are really important here and so",
    "start": "1435159",
    "end": "1440320"
  },
  {
    "text": "like the depth of features is that hey if you can do that with fast API great you're still going to have to set up all scaling you're still going to have to",
    "start": "1440320",
    "end": "1446120"
  },
  {
    "text": "set up observability you're going to have to set up logging and whatnot Hardware management but I think the",
    "start": "1446120",
    "end": "1451799"
  },
  {
    "text": "workflow is probably more important to be honest which is like you we're creating a defined way for you to",
    "start": "1451799",
    "end": "1457440"
  },
  {
    "text": "publish new versions of this if you want to AB test two models you can have two models running at the same time you know",
    "start": "1457440",
    "end": "1463440"
  },
  {
    "text": "it's really that the removal of boilerplate and the addition of some workflow so that you know when you",
    "start": "1463440",
    "end": "1470600"
  },
  {
    "text": "deploying this in production and you need to roll back a version you don't need to go and scramble to find that fast API file without you using we've",
    "start": "1470600",
    "end": "1477799"
  },
  {
    "text": "all been there before and so it's that creation of workflow is probably I think what a lot of our customers probably use",
    "start": "1477799",
    "end": "1484600"
  },
  {
    "text": "us for besides you know I think the production grade inference is a given",
    "start": "1484600",
    "end": "1490760"
  },
  {
    "text": "but a lot of the differentiation comes from that webflow just to totally boil it down you're saving them a lot of work",
    "start": "1490760",
    "end": "1497440"
  },
  {
    "text": "right there yeah 100% yeah there's a lot of kind of grunge work uh it reminds me of Dan liking to do his data massaging",
    "start": "1497440",
    "end": "1505360"
  },
  {
    "text": "that I'm always teasing him about but joking aside you're basically saving us all sorts of work so we can get into",
    "start": "1505360",
    "end": "1511360"
  },
  {
    "text": "production faster get it up and running and and know that it's production grade all the way through with a minimal",
    "start": "1511360",
    "end": "1517440"
  },
  {
    "text": "amount of effort and know that it's just there 100% like we're working with this customer right now this is worth noting",
    "start": "1517440",
    "end": "1523120"
  },
  {
    "text": "that they were a this is a pretty late stage startup ra hundreds of millions of dollars",
    "start": "1523120",
    "end": "1529200"
  },
  {
    "text": "AI native product they've got a team of four AI infra people to manage this and",
    "start": "1529200",
    "end": "1535600"
  },
  {
    "text": "they've been working on this for about two years you know we were able to replicate and get a more performing API up and running in two days wow I think",
    "start": "1535600",
    "end": "1543679"
  },
  {
    "text": "that is kind of what we are trying to it's the performance the workflow it's the maintainability but it's also just",
    "start": "1543679",
    "end": "1549600"
  },
  {
    "text": "the speed to prod I don't know how many of your users do this but the fact that",
    "start": "1549600",
    "end": "1556679"
  },
  {
    "text": "this might be sort of reveal about me as a person um and also reveal some utility",
    "start": "1556679",
    "end": "1562520"
  },
  {
    "text": "of base 10 but like I can literally like last night I'm sitting on my couch and I can log in to base 10 on my phone and",
    "start": "1562520",
    "end": "1569799"
  },
  {
    "text": "then just Chang the auto scaling from like two replicas to like five Max",
    "start": "1569799",
    "end": "1575919"
  },
  {
    "text": "replicas and the timeout and like all those things of like the auto scaling of",
    "start": "1575919",
    "end": "1581520"
  },
  {
    "text": "my llama 2 fine tune from my couch like in between Halo games so that was that",
    "start": "1581520",
    "end": "1588080"
  },
  {
    "text": "was terrifying I don't know what that reveals about me as a person but",
    "start": "1588080",
    "end": "1594279"
  },
  {
    "text": "certainly like that ease of use I think is really interesting it it's like that uh that proverb when you like try to",
    "start": "1594279",
    "end": "1601919"
  },
  {
    "text": "solve a problem and then you're like I'll I'll solve this with Rex and then you just have another problem to solve",
    "start": "1601919",
    "end": "1608360"
  },
  {
    "text": "it's like kind of like that it's like you want to deploy your model and then you want to deploy it with kubernetes",
    "start": "1608360",
    "end": "1614640"
  },
  {
    "text": "and then you have like a whole another problem to to solve and like solve the auto scaling stuff and and all that and",
    "start": "1614640",
    "end": "1621840"
  },
  {
    "text": "then like I think on top of that just all the SR work that you have to do that stuff it's like you know what happens when it goes down you know what happens",
    "start": "1621840",
    "end": "1628840"
  },
  {
    "text": "when you need to migrate something over U what happens when there's a new GPU you want to use there's just so much I",
    "start": "1628840",
    "end": "1635559"
  },
  {
    "text": "feel like we've really turned the corner and I think stuff like Ai and ml um really has helped here because people",
    "start": "1635559",
    "end": "1642000"
  },
  {
    "text": "want to move fast is like I feel we put the build versus biod debate a little bit to rest for a bit where where we",
    "start": "1642000",
    "end": "1648760"
  },
  {
    "text": "just don't hear it as much it's like hey we we want to build it ourselves like people are just like we want managed",
    "start": "1648760",
    "end": "1654480"
  },
  {
    "text": "Solutions yeah you got to go fast these days because if you don't somebody else is going to get there first and and",
    "start": "1654480",
    "end": "1660480"
  },
  {
    "text": "you're not going to have a business and the market is remarkably Talent contrain like yeah you know again like Dan you're",
    "start": "1660480",
    "end": "1665880"
  },
  {
    "text": "saying this and this makes me happy because like just like so you know like Dan's background is in data pop and de",
    "start": "1665880",
    "end": "1672559"
  },
  {
    "text": "and dealing with a all of these things you know like it is I've cried myself to sleep in fatal position",
    "start": "1672559",
    "end": "1680039"
  },
  {
    "text": "and so really it's just a e of use and like it's e of use and the ability to scale with you like and that's probably",
    "start": "1680039",
    "end": "1685919"
  },
  {
    "text": "like the two things which we try to bring to our our customers and I think just even outside of base 10 is probably",
    "start": "1685919",
    "end": "1691960"
  },
  {
    "text": "the the biggest opportunity I'd say in machine learning infrastructure right now is think of all the user stories",
    "start": "1691960",
    "end": "1698640"
  },
  {
    "text": "that are important now that weren't important 12 months ago and maybe just take a long a slightly longer term view",
    "start": "1698640",
    "end": "1705000"
  },
  {
    "text": "than what can I build around open AI API which is like stopped a lot of attention these are all places where Bas s is",
    "start": "1705000",
    "end": "1711080"
  },
  {
    "text": "thinking about going you like you know we we will partner with people are doing if you think about people the emails like think about people with the",
    "start": "1711080",
    "end": "1717039"
  },
  {
    "text": "fine-tuning layer you think of people at the training layer at the observability layer the logging layer it's like the",
    "start": "1717039",
    "end": "1722880"
  },
  {
    "text": "entire new stack here to be built and that's a massive opportunity m is a really interesting company to look at to",
    "start": "1722880",
    "end": "1728399"
  },
  {
    "text": "be honest because you they were training their models they helping people train mod they were Mobly early but like the",
    "start": "1728399",
    "end": "1733799"
  },
  {
    "text": "value was very very clear to a pretty sophisticated buyer um in dat bricks and so to any folks building tools around",
    "start": "1733799",
    "end": "1741000"
  },
  {
    "text": "here like so much value to be at it it's Green Field I have another question to",
    "start": "1741000",
    "end": "1747120"
  },
  {
    "text": "ask you because you are living in kind of that world of model deployments and the various ways that people are doing",
    "start": "1747120",
    "end": "1754120"
  },
  {
    "text": "this people are fine-tuning their own models or just using open models I'm",
    "start": "1754120",
    "end": "1759960"
  },
  {
    "text": "wondering how you see the trends going so you've already talked a little bit about open models being available small",
    "start": "1759960",
    "end": "1767679"
  },
  {
    "text": "to big models and how people are hosting them there's tons of people that are",
    "start": "1767679",
    "end": "1772919"
  },
  {
    "text": "also exploring this area around running models kind of at the edge or in various",
    "start": "1772919",
    "end": "1781200"
  },
  {
    "text": "environments or on laptops and also people that are exploring kind of you already mentioned quantization and",
    "start": "1781200",
    "end": "1787919"
  },
  {
    "text": "running models on CPUs potentially instead of gpus I'm curious for as like",
    "start": "1787919",
    "end": "1794960"
  },
  {
    "text": "someone who hosts like a lot of models in the world world like what are you",
    "start": "1794960",
    "end": "1800159"
  },
  {
    "text": "seeing in terms of this trend like cuz you hear about these topics but I don't really have a good sense of like",
    "start": "1800159",
    "end": "1807200"
  },
  {
    "text": "obviously people are exploring those things but are those people just like extra loud on the Internet or like",
    "start": "1807200",
    "end": "1816000"
  },
  {
    "text": "certainly there's use cases Chris knows them well for running certain things at at the edge but for many people out",
    "start": "1816000",
    "end": "1823080"
  },
  {
    "text": "there that are like maybe building a SAS platform or something you know that's less relevant although maybe the costing",
    "start": "1823080",
    "end": "1830440"
  },
  {
    "text": "you you mentioned cost optimization as well around like that sort of thing so yeah how are you seeing as someone I",
    "start": "1830440",
    "end": "1836480"
  },
  {
    "text": "guess my question is is someone who hosts a lot of models for a lot of people what what are you seeing as",
    "start": "1836480",
    "end": "1842240"
  },
  {
    "text": "people's concerns both in terms of that costing optimizing models and like",
    "start": "1842240",
    "end": "1848799"
  },
  {
    "text": "deployment targets I guess totally I think what we're saying is is remarkably",
    "start": "1848799",
    "end": "1854080"
  },
  {
    "text": "early to be honest like there are opport like people are deploy up on edge but I think there's not enough of them today",
    "start": "1854080",
    "end": "1861559"
  },
  {
    "text": "just kind of think about like a generalized opportunity there and so I think you know there's a company called",
    "start": "1861559",
    "end": "1867360"
  },
  {
    "text": "octoml that started with Edge deployment and then think they were just like let's Mo because that's where the opportunity",
    "start": "1867360",
    "end": "1873480"
  },
  {
    "text": "today is I think all the stuff that's happening around running these models on less and less Hardware or optimizing in",
    "start": "1873480",
    "end": "1880360"
  },
  {
    "text": "xway or Y way it's remarkably intriguing right is it's pretty crazy that we can get a model that we can barely run on",
    "start": "1880360",
    "end": "1887000"
  },
  {
    "text": "you know the biggest CBU we can find and suppos have figured out how to compile it down or ritten it with C plus kernels",
    "start": "1887000",
    "end": "1893880"
  },
  {
    "text": "and all of a sudden it runs anywhere that's pretty fantastic but I I do think that you know we're still in the",
    "start": "1893880",
    "end": "1899519"
  },
  {
    "text": "research phase there we're in the experimental research phase and like you know we've seen a lot of people deploy",
    "start": "1899519",
    "end": "1905519"
  },
  {
    "text": "those models yes we've seen a lot of people play with those models we've seen a lot of interest in those models but I",
    "start": "1905519",
    "end": "1910679"
  },
  {
    "text": "can't really think of too many examples of people running those models in production just yet but it seems",
    "start": "1910679",
    "end": "1916000"
  },
  {
    "text": "inevitable that over time oh it will happen that is the AR that we are on yeah these models are getting smaller",
    "start": "1916000",
    "end": "1921679"
  },
  {
    "text": "and smaller yeah when I'm not on the podcast I'm in a world where it's all about things moving around in time and",
    "start": "1921679",
    "end": "1926720"
  },
  {
    "text": "space and a lot of those things uh will have ai uh capability uh on board going",
    "start": "1926720",
    "end": "1932799"
  },
  {
    "text": "forward so that's I agree with you there's a lot of research going on and no one it's not a solved problem in one",
    "start": "1932799",
    "end": "1939799"
  },
  {
    "text": "you know there's not a set of best practices yet yeah if you will but it's an area that is majorly ripe I'll be",
    "start": "1939799",
    "end": "1946440"
  },
  {
    "text": "really curious to see if if you guys or another company is able to leverage all",
    "start": "1946440",
    "end": "1951480"
  },
  {
    "text": "the expertise you've built up uh and experience youve built up in the cloud and kind of move out into those areas",
    "start": "1951480",
    "end": "1957200"
  },
  {
    "text": "pretty device yeah yeah there's millions of devices out there just waiting for you yeah I say like the the challenge",
    "start": "1957200",
    "end": "1963600"
  },
  {
    "text": "there is just around you know how I'm guessing loy's devices are are a bit of",
    "start": "1963600",
    "end": "1968760"
  },
  {
    "text": "a snowflake and you know we can't you know you can't build for one type of device and just go and apply that to the",
    "start": "1968760",
    "end": "1975880"
  },
  {
    "text": "next device there and I feel like there probably some generalization that needs to happen at the OS layer before we can",
    "start": "1975880",
    "end": "1982120"
  },
  {
    "text": "do that but I am also completely uneducated on edge self so you probably have a lot more to say that than I do",
    "start": "1982120",
    "end": "1988720"
  },
  {
    "text": "well and it's interesting too I sort of ask this in a leading way because one of",
    "start": "1988720",
    "end": "1994320"
  },
  {
    "text": "the people that we're talking to I'll kind of genericize this but they run some equipment at the edge in",
    "start": "1994320",
    "end": "2001120"
  },
  {
    "text": "manufacturing and they have like a hub at the edge which is air gaap which doesn't talk to the internet but their",
    "start": "2001120",
    "end": "2007840"
  },
  {
    "text": "whole like next generation of things is going to be internet connected and when",
    "start": "2007840",
    "end": "2014559"
  },
  {
    "text": "I was talking them about like doing some things with large language models in that environment you know essentially",
    "start": "2014559",
    "end": "2021399"
  },
  {
    "text": "where we got was hey well it's going to be more hassle for you to figure out",
    "start": "2021399",
    "end": "2026760"
  },
  {
    "text": "some of these like model optimization things and all of that than to just like set up an API in base 10 or something",
    "start": "2026760",
    "end": "2033440"
  },
  {
    "text": "like that and and just connect it out if that's where you're headed anyway and it's not like a military security",
    "start": "2033440",
    "end": "2040559"
  },
  {
    "text": "concern like so one of these situations so yeah I think we're probably see both",
    "start": "2040559",
    "end": "2046039"
  },
  {
    "text": "and but for a lot of people it's like kind of how I've categorized these things in my mind is yeah some people",
    "start": "2046039",
    "end": "2052800"
  },
  {
    "text": "will want to run kubernetes in their own infrastructure and they have the expertise to do that and if that's you",
    "start": "2052800",
    "end": "2059560"
  },
  {
    "text": "then like great you're one of maybe a few people on the planet I don't know good on you good good on you and",
    "start": "2059560",
    "end": "2066560"
  },
  {
    "text": "similarly like with if you're running a lot of models on the edge which I know uh certain people are",
    "start": "2066560",
    "end": "2072040"
  },
  {
    "text": "and in certain industries it's really important that's great and that expertise will be there but I think for",
    "start": "2072040",
    "end": "2077158"
  },
  {
    "text": "the M I don't know my sense is that for a lot of majority of people like separating out that infrastructure",
    "start": "2077159",
    "end": "2083158"
  },
  {
    "text": "concern of model hosting is really really a useful way to think about things so I don't know we'll see I'm I'm",
    "start": "2083159",
    "end": "2090240"
  },
  {
    "text": "always bad at predicting the future but we talked to this one customer they was saying that for some reason the CEO",
    "start": "2090240",
    "end": "2097400"
  },
  {
    "text": "bought a bunch of gpus and they literally have machines in the office they're like oh well we're going to do",
    "start": "2097400",
    "end": "2104359"
  },
  {
    "text": "the I think it's Amazon has like the kubernetes anywhere or something where you can basically uh like a hybrid sort",
    "start": "2104359",
    "end": "2110560"
  },
  {
    "text": "of thing yeah yeah you know we run away from that opportunity as um suffices to",
    "start": "2110560",
    "end": "2116320"
  },
  {
    "text": "say but you know there are I think these people are thinking about these problems I don't know if there is a a solution",
    "start": "2116320",
    "end": "2123240"
  },
  {
    "text": "here just yet yeah well as you kind of think about out so obviously and I know",
    "start": "2123240",
    "end": "2131040"
  },
  {
    "text": "just from our discussions like you're helping a lot of people and really significant use cases in the space with",
    "start": "2131040",
    "end": "2138000"
  },
  {
    "text": "already with what you're doing with the infrastructure side of model hosting but as you look to kind of the next I can't",
    "start": "2138000",
    "end": "2146200"
  },
  {
    "text": "even say like the next years because things move so quickly but as you look",
    "start": "2146200",
    "end": "2151440"
  },
  {
    "text": "towards the future and like what is not yet solved on the infrastructure side",
    "start": "2151440",
    "end": "2157440"
  },
  {
    "text": "with model hosting and what are like you and base 10 really excited to dig into",
    "start": "2157440",
    "end": "2163359"
  },
  {
    "text": "what comes to mind and what are you thinking about yeah I think um within the containers like that layer is gets",
    "start": "2163359",
    "end": "2169200"
  },
  {
    "text": "very interesting I think you know VM which I'm sure you've played around with um TGI which you know they both great I",
    "start": "2169200",
    "end": "2177160"
  },
  {
    "text": "still I you I think they still fall from ready for prime time just yet um VM TGI",
    "start": "2177160",
    "end": "2183400"
  },
  {
    "text": "and um T LM the Nvidia just put out I think this it's going to be more and more of these Frameworks and supporting",
    "start": "2183400",
    "end": "2189839"
  },
  {
    "text": "these Frameworks I think is going to be very very key for us and what we're really excited about so we're going deeper at that layer so you can kind of",
    "start": "2189839",
    "end": "2196800"
  },
  {
    "text": "bring your own framework on your container and really benefit from that so you know we're going to have first",
    "start": "2196800",
    "end": "2202040"
  },
  {
    "text": "class support for trt llm pretty soon and we already do it for TGI and BLM and",
    "start": "2202040",
    "end": "2207480"
  },
  {
    "text": "I think that side's pretty interesting I think you know we have a big launch coming up I'm happy to talk about right",
    "start": "2207480",
    "end": "2212880"
  },
  {
    "text": "now actually but around um multicluster so that's basically being able to one",
    "start": "2212880",
    "end": "2218720"
  },
  {
    "text": "use your own compute to bring your compute to base 10 so the the control",
    "start": "2218720",
    "end": "2224040"
  },
  {
    "text": "plane sits on base 10 and the workload plane considering gcp aure AWS or some",
    "start": "2224040",
    "end": "2229880"
  },
  {
    "text": "combination of the three and then we'll keep adding clouds to that and so I think that's very very exciting",
    "start": "2229880",
    "end": "2236200"
  },
  {
    "text": "especially in the Enterprise that because you know people want self-hosted that's huge it is it's really nice",
    "start": "2236200",
    "end": "2242880"
  },
  {
    "text": "that's going be big and then kind of just beyond serving and I think with really decid like you know we've already",
    "start": "2242880",
    "end": "2248480"
  },
  {
    "text": "had one for8 and we learned a lot and you know we we we end up retiring but we're going to get into fine tuning at",
    "start": "2248480",
    "end": "2254280"
  },
  {
    "text": "some point I think like that's we keep seeing like just like I said about kind of like the edge device stuff and the",
    "start": "2254280",
    "end": "2260119"
  },
  {
    "text": "compilation stuff is that my tuning is still an not I'm a little bearish on like API that say give me your data I'll",
    "start": "2260119",
    "end": "2266280"
  },
  {
    "text": "give you a model like I think you need more controls as someone who built an API that said give us your data we'll",
    "start": "2266280",
    "end": "2272079"
  },
  {
    "text": "give you a model U with blueprint you know I think you need more control you need control over your base model you",
    "start": "2272079",
    "end": "2277760"
  },
  {
    "text": "need more control over even the fine-tuning scripts to customize that model we'll start to think about that",
    "start": "2277760",
    "end": "2284599"
  },
  {
    "text": "very soon you know we're already doing a bunch of work with customers to make sure that we're marching the right direction so I'm very excited about that",
    "start": "2284599",
    "end": "2291040"
  },
  {
    "text": "which is that you know over time base 10 becomes this place where you can run your models great but then you can also",
    "start": "2291040",
    "end": "2297040"
  },
  {
    "text": "start to collect data sets around your model just imagine if you could just give your model to base 10 and then you",
    "start": "2297040",
    "end": "2302880"
  },
  {
    "text": "know you either opt in and we basically write all your input and output data to S3 that's beautiful yeah like",
    "start": "2302880",
    "end": "2309000"
  },
  {
    "text": "essentially a level of uh caching for model inputs outputs yeah exactly yeah",
    "start": "2309000",
    "end": "2314280"
  },
  {
    "text": "that the multic cloud thing really will be big for Enterprise by the way just to that point because I think most",
    "start": "2314280",
    "end": "2320160"
  },
  {
    "text": "Enterprises across many Industries are recognizing that their future is a multicloud world it's no longer tied to",
    "start": "2320160",
    "end": "2326920"
  },
  {
    "text": "one and if you have base 10 able to do that hosting and run a control plane and you can deploy into any of the cloud",
    "start": "2326920",
    "end": "2333800"
  },
  {
    "text": "clusters that you happen to be and maybe different parts of the company emphasize one or the other then that takes a lot",
    "start": "2333800",
    "end": "2339400"
  },
  {
    "text": "of challenge uh that they're currently facing out of that so it's pretty sweet I mean also opens up opportunities right",
    "start": "2339400",
    "end": "2344880"
  },
  {
    "text": "especially in the GPU can train world yeah you can get them from wherever you want and then you know I think once you",
    "start": "2344880",
    "end": "2350079"
  },
  {
    "text": "have data sets as well then fine tuning just becomes obvious which it's like okay now I can I find this and you or",
    "start": "2350079",
    "end": "2355760"
  },
  {
    "text": "maybe it's even like hey hook up your open AI end point using base 10 so we can collect that data set and then we",
    "start": "2355760",
    "end": "2361920"
  },
  {
    "text": "can create that 5 tune misal or llama to to keep you the more you want I think there's a lot of interesting things",
    "start": "2361920",
    "end": "2368319"
  },
  {
    "text": "along that whole and as I said to you guys earlier there's so much opportunity here for people building in the tooling",
    "start": "2368319",
    "end": "2374240"
  },
  {
    "text": "layer and Ai and and ml it's very exciting overall yeah well we appreciate",
    "start": "2374240",
    "end": "2380640"
  },
  {
    "text": "uh you taking time out of doing great work in that layer to talk to us and share with our listeners um this is a a",
    "start": "2380640",
    "end": "2387880"
  },
  {
    "text": "great conversation and hopefully we have you on the show in less than 3 years",
    "start": "2387880",
    "end": "2395000"
  },
  {
    "text": "from now but um if not at least three years from now hopefully sooner so thank",
    "start": "2395000",
    "end": "2400880"
  },
  {
    "text": "you for joining us again and giving us an update and some insights around this and uh really appreciate what you all",
    "start": "2400880",
    "end": "2406480"
  },
  {
    "text": "are doing and and appreciate you taking time of course um thank you thank you so much for spending time on the show I",
    "start": "2406480",
    "end": "2413000"
  },
  {
    "text": "thought it's not to be [Music]",
    "start": "2413000",
    "end": "2421720"
  },
  {
    "text": "Hest thank you for listening to practical AI your next step is to",
    "start": "2421720",
    "end": "2426960"
  },
  {
    "text": "subscribe subribe now if you haven't already and if you're a longtime listener of the show help us reach more",
    "start": "2426960",
    "end": "2432800"
  },
  {
    "text": "people by sharing practical AI with your friends and colleagues thanks once again to fastly and fly for partnering with us",
    "start": "2432800",
    "end": "2439319"
  },
  {
    "text": "to bring you all change talk podcasts check out what they're up to at fastly.com and",
    "start": "2439319",
    "end": "2444839"
  },
  {
    "text": "fly.io and to our beat freaking residents breakmaster cylinder for continuously cranking out the best beats",
    "start": "2444839",
    "end": "2450599"
  },
  {
    "text": "in the biz that's all for now we'll talk to you again next [Music]",
    "start": "2450599",
    "end": "2456240"
  },
  {
    "text": "time [Music]",
    "start": "2456240",
    "end": "2468109"
  }
]
[
  {
    "text": "[Music]",
    "start": "330",
    "end": "4030"
  },
  {
    "text": "welcome to practical AI if you work in artificial intelligence aspire to or are",
    "start": "5359",
    "end": "12200"
  },
  {
    "text": "curious how AI related Tech is changing the world this is the show for you thank",
    "start": "12200",
    "end": "18359"
  },
  {
    "text": "you to our partners at fly.io fly transforms containers into microv VMS",
    "start": "18359",
    "end": "24000"
  },
  {
    "text": "that run on their Hardware in 30 plus regions on six continents so you can launch your app near your users learn",
    "start": "24000",
    "end": "31400"
  },
  {
    "text": "more at",
    "start": "31400",
    "end": "34279"
  },
  {
    "text": "Y.O if you're listening you know softwares build from thousands of small technical choices and some of these",
    "start": "37040",
    "end": "43239"
  },
  {
    "text": "seemingly inconsequential choices can have a profound impact on the economics of Internet services who gets to",
    "start": "43239",
    "end": "50120"
  },
  {
    "text": "participate in them build them and profit from them this is especially true for artificial intelligence where the",
    "start": "50120",
    "end": "56680"
  },
  {
    "text": "decisions we make today can determine who can have access to world changing Technologies and who can decide their",
    "start": "56680",
    "end": "62199"
  },
  {
    "text": "future read write own building the next era of the internet is a new book from",
    "start": "62199",
    "end": "67600"
  },
  {
    "text": "startup investor Chris Dixon that explores the decisions that took us from open networks governed by communities to",
    "start": "67600",
    "end": "73759"
  },
  {
    "text": "massive social networks run by internet Giants this book read right own is a call to action for building a new era of",
    "start": "73759",
    "end": "81479"
  },
  {
    "text": "the internet that puts people in charge from Ani projects that compensate creators for their work to protocols",
    "start": "81479",
    "end": "88280"
  },
  {
    "text": "that fund open source contribution utions this is our chance to build the internet we want not the one we",
    "start": "88280",
    "end": "94520"
  },
  {
    "text": "inherited order your copy of read write own today or go to readwrite own.com to",
    "start": "94520",
    "end": "101240"
  },
  {
    "text": "learn [Music]",
    "start": "101240",
    "end": "114720"
  },
  {
    "text": "more welcome to a very special Fireside ch um which corresponds uh with the ongoing",
    "start": "115640",
    "end": "124880"
  },
  {
    "text": "Advent of gen AI hackathon um that will also be reposted on the Practical AI",
    "start": "124880",
    "end": "132360"
  },
  {
    "text": "podcast I'm uh very pleased to have been uh participating in this hackathon as",
    "start": "132360",
    "end": "139080"
  },
  {
    "text": "one of the organizers but I'm also joined here in the fireside chat by an",
    "start": "139080",
    "end": "144760"
  },
  {
    "text": "amazing team from Intel's liftoff program for startups who helped organize",
    "start": "144760",
    "end": "151640"
  },
  {
    "text": "this hackathon that we'll be talking about throughout the day so uh I'd like",
    "start": "151640",
    "end": "156959"
  },
  {
    "text": "to kick it over maybe to Rahul to um describe a little bit about what Intel",
    "start": "156959",
    "end": "162840"
  },
  {
    "text": "liftoff is hey hey all thank you Dan um this has been an incredible experience",
    "start": "162840",
    "end": "168239"
  },
  {
    "text": "let me before that even talk about the Advent of ji two sentences is uh this was probably the biggest uh generative",
    "start": "168239",
    "end": "175080"
  },
  {
    "text": "hackathon that we our team has organized and the submissions uh all all the",
    "start": "175080",
    "end": "180120"
  },
  {
    "text": "different chats and things that we have seen uh this has been really awesome we",
    "start": "180120",
    "end": "186239"
  },
  {
    "text": "got a lot of positive feedback and a lot of things that we need to improve for the next time so thank you for participating for the hackathon and we",
    "start": "186239",
    "end": "192560"
  },
  {
    "text": "would be announcing the winners of the final the pro product development uh in",
    "start": "192560",
    "end": "197720"
  },
  {
    "text": "couple of hours before that let me talk about LOF right um so LOF is an",
    "start": "197720",
    "end": "203120"
  },
  {
    "text": "accelerator program uh specifically a technical accelerator program for early State startups so if you have an idea",
    "start": "203120",
    "end": "209959"
  },
  {
    "text": "you're a SE startup or till series P you are want to scale you want to build some",
    "start": "209959",
    "end": "215120"
  },
  {
    "text": "cool things in AI or machine learning please join the program it's free I would categorize benefits basically into",
    "start": "215120",
    "end": "221879"
  },
  {
    "text": "three different pillars uh world class technical support um and Technical expertise that's uh me and Ryan here we",
    "start": "221879",
    "end": "228720"
  },
  {
    "text": "lead the engineering side of things and we have an incredible engineering uh scale team some of the folks are here",
    "start": "228720",
    "end": "235480"
  },
  {
    "text": "like chus and marad then you get access to technology both Intel software and",
    "start": "235480",
    "end": "240599"
  },
  {
    "text": "Intel developer Cloud Intel developer cloud is a production read Cloud specifically designed for AI workloads",
    "start": "240599",
    "end": "247480"
  },
  {
    "text": "prodution guard is uh one of our uh the startups that came to our program",
    "start": "247480",
    "end": "252560"
  },
  {
    "text": "earlier this year and they are running on Intel developer Cloud now uh using a go2 accelerator and I'm sure that many",
    "start": "252560",
    "end": "258840"
  },
  {
    "text": "of you folks who have participated in the hack would have used uh prediction guards llm apis the third one uh is co",
    "start": "258840",
    "end": "266160"
  },
  {
    "text": "marketing and bringing your once you built that product and deployed it uh the next thing is to make some money",
    "start": "266160",
    "end": "272280"
  },
  {
    "text": "right so we uh co-market your um startup your idea through all of Intel channels",
    "start": "272280",
    "end": "278360"
  },
  {
    "text": "and also our we have a network of accelerators and network of folks that's beyond Intel that we take the product",
    "start": "278360",
    "end": "285080"
  },
  {
    "text": "you have buil the company I buil uh and basically Market uh it all over the world we also connect you with um our",
    "start": "285080",
    "end": "291680"
  },
  {
    "text": "sales teams to see if there's a um potential for selling the things that will built through Intel channels uh it",
    "start": "291680",
    "end": "298960"
  },
  {
    "text": "could be a service an IDC or it could be separate that one of our customers of Intel is looking for I would urge anyone",
    "start": "298960",
    "end": "306759"
  },
  {
    "text": "who is looking to really bootstrap and accelerate your startup journey to join Intel lipof yeah that's great that's",
    "start": "306759",
    "end": "313960"
  },
  {
    "text": "great Rahul um could you describe a little bit so I remember um initial",
    "start": "313960",
    "end": "320360"
  },
  {
    "text": "discussions between a few of us you had this idea for the Advent of gen AI",
    "start": "320360",
    "end": "327080"
  },
  {
    "text": "hackathon now a lot of people in the audience out there might be familiar with like Advent of code so where like",
    "start": "327080",
    "end": "335840"
  },
  {
    "text": "how did you start thinking about this Advent of gen Ai hackathon and like what",
    "start": "335840",
    "end": "340919"
  },
  {
    "text": "was your initial vision for it uh a lot of the Geeks uh in the call which most",
    "start": "340919",
    "end": "346160"
  },
  {
    "text": "of us are would know Advent of code uh it's a set of programming challenges you can take any sort of um program language",
    "start": "346160",
    "end": "353560"
  },
  {
    "text": "you want to learn or to attempt to solve these algorithmic questions uh I've been doing that for many years and uh I",
    "start": "353560",
    "end": "360759"
  },
  {
    "text": "thought you know gen is something that's new and something a lot of people are talking about but there are no fun set",
    "start": "360759",
    "end": "367639"
  },
  {
    "text": "of exercises uh or that you can use to learn and also build cool things with",
    "start": "367639",
    "end": "372919"
  },
  {
    "text": "the technology that's that's existing today so I I was thinking why not just create something you know set of",
    "start": "372919",
    "end": "378599"
  },
  {
    "text": "challenges uh that's tailored from a person who might not know how to code but have seen prompt engineering and",
    "start": "378599",
    "end": "385199"
  },
  {
    "text": "creating cool prompts to create images all the way to uh people building with uh llm apis so we designed a set of",
    "start": "385199",
    "end": "392720"
  },
  {
    "text": "challenges to bring in as much as audience as possible to introduce them to gen and also learn through that",
    "start": "392720",
    "end": "397919"
  },
  {
    "text": "process many folks I've seen in in the chats where um they came with just prompt engineering knowledge and have",
    "start": "397919",
    "end": "404759"
  },
  {
    "text": "built really cool things uh graduating from one challenge to other uh and there has been a really good community help",
    "start": "404759",
    "end": "411080"
  },
  {
    "text": "also like people talking to each other and trying to help out uh how to run how to build these things this has been a",
    "start": "411080",
    "end": "417840"
  },
  {
    "text": "really really good exercise even some of the challenges when I was building it I was like oh W I would like to do that",
    "start": "417840",
    "end": "423879"
  },
  {
    "text": "because it's we always wanted to add a fun element to it so uh no",
    "start": "423879",
    "end": "429360"
  },
  {
    "text": "challenges drive just an algorithmic question but there is something fun element to that that's where the whole",
    "start": "429360",
    "end": "434599"
  },
  {
    "text": "Advent of gen came about and we want to do this yearly uh so we next year it",
    "start": "434599",
    "end": "439960"
  },
  {
    "text": "might be a new technology it could be multimodality uh hackathon some other things we already saw uh some cool",
    "start": "439960",
    "end": "446080"
  },
  {
    "text": "engineering stuff folks are bu this challenge but uh it would be something but I'd like to do in December Advent or",
    "start": "446080",
    "end": "452400"
  },
  {
    "text": "something else that lift up uses for the community yeah that's awesome so if you're listening to this uh after the",
    "start": "452400",
    "end": "460120"
  },
  {
    "text": "holiday season or as this will be coming out on the podcast later you didn't miss",
    "start": "460120",
    "end": "466080"
  },
  {
    "text": "out on partici well you missed out on participating in 2023 but there's going to be more opportunities to participate",
    "start": "466080",
    "end": "472840"
  },
  {
    "text": "in things like this that Intel is going to put on later on so I definitely recommend people keep an eye out on the",
    "start": "472840",
    "end": "479680"
  },
  {
    "text": "liftoff program and social media uh to hear about things could you speak a little bit to the response to this first",
    "start": "479680",
    "end": "488599"
  },
  {
    "text": "Advent of gen and like the participation that happened um I think we were all a",
    "start": "488599",
    "end": "495080"
  },
  {
    "text": "bit surprised at how many people joined in to this so could you speak to that a",
    "start": "495080",
    "end": "500240"
  },
  {
    "text": "little bit and anyone else from the liftoff program kind of any of your observations for um the type of people",
    "start": "500240",
    "end": "508599"
  },
  {
    "text": "that joined in and the range of experiences and and all of that this has been uh fantastic uh we had grad",
    "start": "508599",
    "end": "516159"
  },
  {
    "text": "students we had even students who are in school who uh have taken prompt engineering courses who just wanted to",
    "start": "516159",
    "end": "522599"
  },
  {
    "text": "have fun working on some of the earlier challenges uh there has been experts also some of experts in llm and gen I",
    "start": "522599",
    "end": "530120"
  },
  {
    "text": "worked on it and some of the products that they have built right Al some of the challenge solution is it's like an",
    "start": "530120",
    "end": "536120"
  },
  {
    "text": "MVP a startup will build we have many startups who are building a similar solution who are taking like 6 months to",
    "start": "536120",
    "end": "541399"
  },
  {
    "text": "an year to build a full solid solution but uh some of the Challenge answers especially using the rag example and and",
    "start": "541399",
    "end": "548040"
  },
  {
    "text": "or the the python code explainer things like that are uh difficult and they have even gone further where when we asked",
    "start": "548040",
    "end": "555160"
  },
  {
    "text": "about how to can you create a story teller chatboard people have created a story Plus image uh chatboard a",
    "start": "555160",
    "end": "561320"
  },
  {
    "text": "multimodality chatboard so these are um many levels of experience and that's even some of the folks from Intel",
    "start": "561320",
    "end": "567560"
  },
  {
    "text": "participated that's also a very positive thing where we see you can you know in a Level Playing Field work with folks from",
    "start": "567560",
    "end": "575079"
  },
  {
    "text": "Intel um and solve the challenges together we had uh folks from Berkeley",
    "start": "575079",
    "end": "581240"
  },
  {
    "text": "uh folks from many different Enterprises uh participating so this has been a mix",
    "start": "581240",
    "end": "587240"
  },
  {
    "text": "and I was amazed uh at the level of participation I didn't expect these many people would participate and we had to",
    "start": "587240",
    "end": "593399"
  },
  {
    "text": "stop registrations after 2,000 people registering for the event and uh this",
    "start": "593399",
    "end": "598440"
  },
  {
    "text": "has been just great Ryan do you want to add something yeah I just remember this is R's idea when he first called me was",
    "start": "598440",
    "end": "606040"
  },
  {
    "text": "like cleaning up after Thanksgiving in my basement or something he's like you know Advent a code yeah of course of",
    "start": "606040",
    "end": "611920"
  },
  {
    "text": "course I want to do Advent of gen like all right what do you want to do we worked it out and it was like set the",
    "start": "611920",
    "end": "617360"
  },
  {
    "text": "goal like let's get like it's like yeah we could get big like you know couple hundred people at least would would be a",
    "start": "617360",
    "end": "624079"
  },
  {
    "text": "success but like stretch it like hey I mean we could get maybe a thousand even and do the biggest event of the year",
    "start": "624079",
    "end": "631000"
  },
  {
    "text": "weend end up cutting it off at twice that at twice the stretch goal so then of course the entire time we're like oh",
    "start": "631000",
    "end": "637600"
  },
  {
    "text": "man did we do a good job are people going to like this are we going to get submissions every time knock it out of",
    "start": "637600",
    "end": "642920"
  },
  {
    "text": "the park way more submissions than we were hoping for and the quality was excellent and the amount of people we",
    "start": "642920",
    "end": "648839"
  },
  {
    "text": "saw in the chat helping each other it's like somebody you know we're all trying it's 24 hours a day so we're you know",
    "start": "648839",
    "end": "654440"
  },
  {
    "text": "our team is trying to stay in and answer questions as much as possible we set that as a goal but what we saw like from",
    "start": "654440",
    "end": "660680"
  },
  {
    "text": "go like from when it started was when people would ask questions other people would jump in and like link them to the",
    "start": "660680",
    "end": "665760"
  },
  {
    "text": "explanation or the documentation or whatever these were all the dreams for the event so it's been incredible and I",
    "start": "665760",
    "end": "671000"
  },
  {
    "text": "want to thank every single person who was involved yeah and maybe it would be good for those maybe some people jumped",
    "start": "671000",
    "end": "677680"
  },
  {
    "text": "into certain challenges and not other challenges or they might be hopping in at at one point or the other or they're",
    "start": "677680",
    "end": "683920"
  },
  {
    "text": "learning about Advent of J AI as they're listening to this so what were some of the challenges that were presented to",
    "start": "683920",
    "end": "692079"
  },
  {
    "text": "the participants and how would you consider them in terms of like",
    "start": "692079",
    "end": "697639"
  },
  {
    "text": "relative challenge level or skill required to complete them we designed",
    "start": "697639",
    "end": "703000"
  },
  {
    "text": "this challenge um in a progressing level of I wouldn't say difficulty but I mean",
    "start": "703000",
    "end": "708959"
  },
  {
    "text": "the ability to code uh I would say it's uh it's not difficulty exactly and creativity also because a lot of geni",
    "start": "708959",
    "end": "715560"
  },
  {
    "text": "it's um what we see at least in lifttop is that AI has become truly commoditized",
    "start": "715560",
    "end": "720880"
  },
  {
    "text": "and you don't really need to know go through um Masters or a couple of courses on neuron networks to build an",
    "start": "720880",
    "end": "728040"
  },
  {
    "text": "application right now you have the amazing Transformer ecosystem it's really easy to integrate uh some of",
    "start": "728040",
    "end": "733760"
  },
  {
    "text": "these things the AI applications to AI superpowers to the applications you build I would take the first challenge",
    "start": "733760",
    "end": "740880"
  },
  {
    "text": "for example the first challenge was to create a narrative based set of images and uh if you look at the challenge the",
    "start": "740880",
    "end": "747399"
  },
  {
    "text": "first time it's it looks like it's very easy you just create couple of images using stable diffusion it's all about",
    "start": "747399",
    "end": "753320"
  },
  {
    "text": "prompt engineering you don't need to know a single line of code all the notebooks and the models everything is",
    "start": "753320",
    "end": "758519"
  },
  {
    "text": "available on Intel developer Cloud you just create a standard account log in there get Jupiter Hub open and just play",
    "start": "758519",
    "end": "764839"
  },
  {
    "text": "with it but the thing is creating an transition from one image to another and creating a whole story with set of five",
    "start": "764839",
    "end": "771360"
  },
  {
    "text": "images it's not easy it's really difficult and we even saw some folks creating a comic book generator using",
    "start": "771360",
    "end": "777680"
  },
  {
    "text": "this challenge that sort of um Imagination right that's that's what I really wanted people to do but I didn't",
    "start": "777680",
    "end": "782839"
  },
  {
    "text": "want to say that okay please create a comic book generator as a challenge because it's it's really difficult some",
    "start": "782839",
    "end": "788000"
  },
  {
    "text": "of the folks even without knowing that uh built it you take the the final challenge right that was python code",
    "start": "788000",
    "end": "793800"
  },
  {
    "text": "explainer where you giv a python code you use llm model to understand the code",
    "start": "793800",
    "end": "799160"
  },
  {
    "text": "and give an explanation of it we had additional challenge additional subchallenge there show the source of uh",
    "start": "799160",
    "end": "805399"
  },
  {
    "text": "documentation or stack Overflow questions where I can go into and learn about it more these kind of additions",
    "start": "805399",
    "end": "812519"
  },
  {
    "text": "makes it very interesting and a little bit more complicated where you have to use a vector database you have to use uh",
    "start": "812519",
    "end": "818800"
  },
  {
    "text": "prediction guts llm apis to get the right model and uh you had to design a UI for it all in the constraints of a",
    "start": "818800",
    "end": "825079"
  },
  {
    "text": "jupyter notebook so I would say there was a progression of difficult difficulty say is very relative word but",
    "start": "825079",
    "end": "830639"
  },
  {
    "text": "yeah there a progression of difficulty if you're just coming to gen and the whole idea is said it's a single package",
    "start": "830639",
    "end": "836880"
  },
  {
    "text": "so even if you're you not participated in of J right we have released all the resources that we have built for this",
    "start": "836880",
    "end": "843759"
  },
  {
    "text": "you can take this to basically get your an idea of what gen can actually help",
    "start": "843759",
    "end": "848839"
  },
  {
    "text": "you to build and Infuse to your applications and you can just go through the different challenges or if you're an",
    "start": "848839",
    "end": "854279"
  },
  {
    "text": "expert in um uh llm rag based application go to that particular Challenge and take a look at it so it's",
    "start": "854279",
    "end": "860199"
  },
  {
    "text": "now become a Learning Resource also not just a a hack if I could just add on to that real quick it did on purpose go up",
    "start": "860199",
    "end": "868560"
  },
  {
    "text": "and difficulty like the level of each challenge was supposed to get harder and more advanced let's say in terms of",
    "start": "868560",
    "end": "873800"
  },
  {
    "text": "coding ability as we went on but the real Focus was about skills and understanding the tools um that are",
    "start": "873800",
    "end": "880440"
  },
  {
    "text": "being used within the industry there's been a huge focus on creating new levels of abstraction to make neural networks",
    "start": "880440",
    "end": "887320"
  },
  {
    "text": "easier to use and build with used to be very challenging now not I mean not nearly as much you don't even need to",
    "start": "887320",
    "end": "893519"
  },
  {
    "text": "stand up your own neural network anymore right you can grab an API so if you look at the challenges each one is kind of",
    "start": "893519",
    "end": "900360"
  },
  {
    "text": "focused on a different skill and if you go through all five you cover prompting",
    "start": "900360",
    "end": "907639"
  },
  {
    "text": "specifically for images text image cover using an llm API and the different",
    "start": "907639",
    "end": "913079"
  },
  {
    "text": "things you can do with it cover uh image to image so image editing with AI in the",
    "start": "913079",
    "end": "918639"
  },
  {
    "text": "third one and then uh rag based applications with L LM apis and finally",
    "start": "918639",
    "end": "924240"
  },
  {
    "text": "we thought you know the fifth was the most advanced like the code explainer one that's you know there companies that",
    "start": "924240",
    "end": "929560"
  },
  {
    "text": "are basically that are big companies that are working on that exact problem that are betting that you know it's",
    "start": "929560",
    "end": "935759"
  },
  {
    "text": "going to a lot that a good solution for code explanation Improvement and generation is going to lock many",
    "start": "935759",
    "end": "941880"
  },
  {
    "text": "billions of dollars of value so all these things are focused on these different skills and Our Hope was that",
    "start": "941880",
    "end": "948079"
  },
  {
    "text": "for people who are maybe software Engineers looking to move over to AI or to students like whatever anybody who's",
    "start": "948079",
    "end": "954040"
  },
  {
    "text": "interested in learning AI skills that by through the ones they chose to or all of them but by the end of them they'd have",
    "start": "954040",
    "end": "960000"
  },
  {
    "text": "kind of a portfolio of knowledge in their head about the different skills both on understanding how to use them",
    "start": "960000",
    "end": "965560"
  },
  {
    "text": "and how to do a good job like with prompting but also by going through the code and understanding all of the code",
    "start": "965560",
    "end": "971800"
  },
  {
    "text": "and all the notebooks and idea of what else they could build outside of the narrow set of applications that we asked",
    "start": "971800",
    "end": "977399"
  },
  {
    "text": "for over the course of five days I think one thing that impressed me about the set of challenges that you all came up",
    "start": "977399",
    "end": "984000"
  },
  {
    "text": "with was that it focused really around image generation coherent image",
    "start": "984000",
    "end": "990680"
  },
  {
    "text": "generation and on the llm side sort of retrieval based methods along with chat",
    "start": "990680",
    "end": "996680"
  },
  {
    "text": "so I think all of these things are the things that people are finding most utility out of when they're first",
    "start": "996680",
    "end": "1003880"
  },
  {
    "text": "implementing AI Solutions within their actual Enterprise or industry or startup",
    "start": "1003880",
    "end": "1010399"
  },
  {
    "text": "or whatever environment they're working in in particular retrieval based methods and rag systems at least for our clients",
    "start": "1010399",
    "end": "1017600"
  },
  {
    "text": "we're seeing that's like the first thing that everybody is building right you have your own company set of data in the",
    "start": "1017600",
    "end": "1024640"
  },
  {
    "text": "case of the challenges that you all put together maybe that's external python documentation for the code explainer or",
    "start": "1024640",
    "end": "1031880"
  },
  {
    "text": "maybe that's just some external PDFs or YouTube videos or whatever it is um for",
    "start": "1031880",
    "end": "1037400"
  },
  {
    "text": "the rag based solution but lots of companies have this data that has this sort of unlocked potential and is",
    "start": "1037400",
    "end": "1044558"
  },
  {
    "text": "unlocked via these retrieval based methods which is a lot of time what people are building first when they",
    "start": "1044559",
    "end": "1051440"
  },
  {
    "text": "adopt this technology so I think it was great that you all tied that together",
    "start": "1051440",
    "end": "1056640"
  },
  {
    "text": "with the participants to give them practical skills in that area and kind of help them learn you know what is a",
    "start": "1056640",
    "end": "1062880"
  },
  {
    "text": "vector database what is a rag system how do you implement this with custom data rather than kind of immediately hopping",
    "start": "1062880",
    "end": "1069640"
  },
  {
    "text": "to fine-tune a model which I know of course you can do more easily than ever as well but there's a lot you can do",
    "start": "1069640",
    "end": "1075880"
  },
  {
    "text": "even just by integrating your own data with retrieval or other sorts of methods",
    "start": "1075880",
    "end": "1082440"
  },
  {
    "text": "I do want to ask here in a second some of the solutions that you saw and what stood out to you just to highlight some",
    "start": "1082440",
    "end": "1089360"
  },
  {
    "text": "of those really cool things that we saw but before we do that so you can have that in the back of your mind and and",
    "start": "1089360",
    "end": "1094880"
  },
  {
    "text": "think through some things you'd want to highlight I'm wondering if you all could speak to the Intel developer Cloud",
    "start": "1094880",
    "end": "1100960"
  },
  {
    "text": "specifically which is is something of course I've found utility out of but it",
    "start": "1100960",
    "end": "1106039"
  },
  {
    "text": "was something that was kind of unique about this hackathon and it might be something that the participants here are",
    "start": "1106039",
    "end": "1112880"
  },
  {
    "text": "a little bit like this was their first time using it but also there's a whole",
    "start": "1112880",
    "end": "1118000"
  },
  {
    "text": "lot available there in terms of different ways to run AI models that are maybe maybe some people are less",
    "start": "1118000",
    "end": "1124919"
  },
  {
    "text": "familiar with so could you describe a little bit the Intel developer cloud and maybe also highlight some of those like",
    "start": "1124919",
    "end": "1131280"
  },
  {
    "text": "different unique ways that people were running AI models outside of just like",
    "start": "1131280",
    "end": "1137120"
  },
  {
    "text": "throwing it on a GPU they're some interesting kind of other either tooling",
    "start": "1137120",
    "end": "1142919"
  },
  {
    "text": "or Hardware software available for people could you highlight a little bit of that and the unique ways that people",
    "start": "1142919",
    "end": "1148880"
  },
  {
    "text": "were specifically running AI models throughout the hackathon sure um so",
    "start": "1148880",
    "end": "1154080"
  },
  {
    "text": "Intel developer cloud is Intel's production ready Cloud specifically for AI and machine learning workloads uh and",
    "start": "1154080",
    "end": "1161080"
  },
  {
    "text": "of course when we say Ai and machine learning it's Matrix math so many other Compu heavy workloads can run really",
    "start": "1161080",
    "end": "1167080"
  },
  {
    "text": "well on IDC so uh for this particular hack um we provided um anyone logging in",
    "start": "1167080",
    "end": "1174640"
  },
  {
    "text": "Intel developer Cloud registering on IDC as a standard or free tier user you get a shared uh Jupiter Hub instance uh",
    "start": "1174640",
    "end": "1182240"
  },
  {
    "text": "where you get access to Intel's data center gpus Intel zon processors and I",
    "start": "1182240",
    "end": "1187559"
  },
  {
    "text": "would say this system I for a free tier user I don't think any other service",
    "start": "1187559",
    "end": "1193120"
  },
  {
    "text": "provide I mean there are many services with the Jupiter Hub front end uh but the amount of compute and amount of",
    "start": "1193120",
    "end": "1199400"
  },
  {
    "text": "memory and and RAM and even file storage that you get in the systems I haven't seen a single cloud service provider uh",
    "start": "1199400",
    "end": "1205679"
  },
  {
    "text": "providing that and we' have seen lot of people really using it and giving us",
    "start": "1205679",
    "end": "1210760"
  },
  {
    "text": "feedback on how we could even improve it today on IDC we have a lot of models or",
    "start": "1210760",
    "end": "1216400"
  },
  {
    "text": "llms already there are tens of even hundreds of local models that we are planning to add further to boost this",
    "start": "1216400",
    "end": "1223240"
  },
  {
    "text": "there are stable diffusion models llm models and things like that beyond that for productionizing the workload right",
    "start": "1223240",
    "end": "1229559"
  },
  {
    "text": "uh Dan in your case uh you are using the gudi 2 accelerators those are",
    "start": "1229559",
    "end": "1234840"
  },
  {
    "text": "specifically designed for for workloads that that request high bandwidth uh like llm and gen workloads and I like",
    "start": "1234840",
    "end": "1242559"
  },
  {
    "text": "this this this I lost my TR out thought but yeah we have G2 accelerators which we are",
    "start": "1242559",
    "end": "1249520"
  },
  {
    "text": "seeing incredibly competitive and sometimes outclassing the best uh out there uh for your particular workloads",
    "start": "1249520",
    "end": "1256039"
  },
  {
    "text": "along with Gaudi accelerators um uh those are specifically designed for Gen and AI workloads we have general purpose",
    "start": "1256039",
    "end": "1262200"
  },
  {
    "text": "gpus the data center Max gpus both with 48 gigs and uh 128 gig uh versions um so",
    "start": "1262200",
    "end": "1270720"
  },
  {
    "text": "the folks in the hackathon they actually used uh both of our fourth generation Zeon that is the latest Zeon uh that we",
    "start": "1270720",
    "end": "1277880"
  },
  {
    "text": "have which what it particularly does is that it accelerates your machine learning workloads we have dedicated",
    "start": "1277880",
    "end": "1283039"
  },
  {
    "text": "instructions in this CPU to sometimes even take your workload to 2x the performance you got and ear generation",
    "start": "1283039",
    "end": "1289840"
  },
  {
    "text": "uh it's all about making the CPUs how we see it is that uh making it as efficient",
    "start": "1289840",
    "end": "1295320"
  },
  {
    "text": "as possible and making it as fast as possible just still maintaining the general purpose utility of a CPU then",
    "start": "1295320",
    "end": "1303120"
  },
  {
    "text": "like I said the data center Max series gpus a little bit more generic solution where you can run your a workloud HPC",
    "start": "1303120",
    "end": "1310159"
  },
  {
    "text": "workloads um each of these machines when you're uh productionizing you get a VM",
    "start": "1310159",
    "end": "1316200"
  },
  {
    "text": "you get an eight node uh eight card system system um there are also clustered systems available then comes",
    "start": "1316200",
    "end": "1321960"
  },
  {
    "text": "the Gaudi accelerators both there are single node machines and uh also clustered machines if you want to do pre-training or or big fine tuning all",
    "start": "1321960",
    "end": "1329520"
  },
  {
    "text": "those cool things and soon we'll have kubernetes service uh Object Store file store all those things uh coming up uh",
    "start": "1329520",
    "end": "1336600"
  },
  {
    "text": "so it's going to be great what I see is that if you're building a startup it would be very difficult to find a",
    "start": "1336600",
    "end": "1342840"
  },
  {
    "text": "performing and accelerator cloud like IDC out there I'm sure that there are different different hypers scale",
    "start": "1342840",
    "end": "1349200"
  },
  {
    "text": "but this uniquely for startups from my personal experience is is a really really awesome solution uh I'd like to",
    "start": "1349200",
    "end": "1355320"
  },
  {
    "text": "know more from you Dan like you you are one of the first customers of of IDC right like what are the things that you",
    "start": "1355320",
    "end": "1361279"
  },
  {
    "text": "thought uh that really uh you know made you decide to choose choose IDC from the performance and also the team side also",
    "start": "1361279",
    "end": "1368559"
  },
  {
    "text": "right appreciate that and appreciate the support that you all have given I think it's interesting maybe for people out",
    "start": "1368559",
    "end": "1374279"
  },
  {
    "text": "there that are less familiar with the various options for model deployment to",
    "start": "1374279",
    "end": "1380520"
  },
  {
    "text": "understand that there is really good tooling um like you say whether it's optimizing a model and deploying it on a",
    "start": "1380520",
    "end": "1387200"
  },
  {
    "text": "CPU or an edge environment or um just a cheaper inference solution or it's like",
    "start": "1387200",
    "end": "1395559"
  },
  {
    "text": "all the way to these gouty 2 processors that we've been experimenting with I think there's a lot of interesting and",
    "start": "1395559",
    "end": "1402240"
  },
  {
    "text": "approachable tooling for that so I first came across some of the tooling around G",
    "start": "1402240",
    "end": "1408720"
  },
  {
    "text": "2 by actually seeing blogs on the hugging face blog about gouty 2 and I",
    "start": "1408720",
    "end": "1414159"
  },
  {
    "text": "think at the time like the Bloom model which is a very large model and running it on either a single accelerator or",
    "start": "1414159",
    "end": "1422480"
  },
  {
    "text": "spread across eight accelerators with really high throughput on the inference side and doing that with tools like",
    "start": "1422480",
    "end": "1429159"
  },
  {
    "text": "Optimum Habana so for those of you that are out there and wanting to explore things actually if you look up the",
    "start": "1429159",
    "end": "1435000"
  },
  {
    "text": "hugging face Optimum Library um there's a lot of great tools that you can play around with there even not for for gudy",
    "start": "1435000",
    "end": "1442039"
  },
  {
    "text": "but for other processors too so whether that be CPUs gpus the gouty 2 hpus the",
    "start": "1442039",
    "end": "1450039"
  },
  {
    "text": "data center Max gpus Optimum kind of provides you a way um if some of you can",
    "start": "1450039",
    "end": "1455440"
  },
  {
    "text": "visualize maybe you're uh writing in your code and you're importing a model from hugging face it's just like Auto",
    "start": "1455440",
    "end": "1463360"
  },
  {
    "text": "tokenizer or Auto uh caal LM or whatever it is with Optimum a lot of times either",
    "start": "1463360",
    "end": "1470320"
  },
  {
    "text": "you can just do like a one a couple line replacement and just replace that with the optimum version of those classes or",
    "start": "1470320",
    "end": "1478960"
  },
  {
    "text": "do some uh wrapping of the various models um with optimizers and this",
    "start": "1478960",
    "end": "1484000"
  },
  {
    "text": "allows you to run run your your model very fast on on a wide range of",
    "start": "1484000",
    "end": "1489399"
  },
  {
    "text": "architectures so I think to your point uh rul I think one of the things that we found really useful is the actual the",
    "start": "1489399",
    "end": "1497440"
  },
  {
    "text": "ease of use and coming in and saying okay well we have this stuff running on",
    "start": "1497440",
    "end": "1502559"
  },
  {
    "text": "a GPU um let's try it on this various other architectures I remember even like",
    "start": "1502559",
    "end": "1508080"
  },
  {
    "text": "maybe two or three years ago trying to do some of this model optimization things for Edge deployments is very very",
    "start": "1508080",
    "end": "1514679"
  },
  {
    "text": "challenging so like uh a lot of times I would try to optimize a model at the time working on like speech models and",
    "start": "1514679",
    "end": "1521039"
  },
  {
    "text": "other things and it just wouldn't work because operations wouldn't be supported or or something like that but this",
    "start": "1521039",
    "end": "1527559"
  },
  {
    "text": "tooling which is cool because you know Intel's working directly with hugging face on this tooling and uh of course",
    "start": "1527559",
    "end": "1535600"
  },
  {
    "text": "the ease of use has just been ramped up drastically and and we've been applying that with really good results",
    "start": "1535600",
    "end": "1541840"
  },
  {
    "text": "particularly for inference for llms so that's been a key feature to that that change happen that's really awesome to",
    "start": "1541840",
    "end": "1549000"
  },
  {
    "text": "hear D and and particularly the what also the thing you mentioned right so so you think of Intel in in two ways uh",
    "start": "1549000",
    "end": "1556080"
  },
  {
    "text": "probably the biggest uh semiconductor manufact are the cooler tips uh the other is intell and open source software",
    "start": "1556080",
    "end": "1562840"
  },
  {
    "text": "company also we are uh contributing to almost all all big opensource projects U",
    "start": "1562840",
    "end": "1568880"
  },
  {
    "text": "Linux Kel almost all things if you see we would we would be anywhere in the top three BYO strength of flow uh hugging P",
    "start": "1568880",
    "end": "1575919"
  },
  {
    "text": "any any sort of um open source Solutions out there we work really hard uh across",
    "start": "1575919",
    "end": "1582039"
  },
  {
    "text": "to make sure that your adoption of a technology is as easy as possible and try to Upstream as much is possible to",
    "start": "1582039",
    "end": "1589640"
  },
  {
    "text": "uh the core pyto library or tens library and and things like that in cases where we uh we feel that there are further",
    "start": "1589640",
    "end": "1595880"
  },
  {
    "text": "optimizations that could be done and these things canot be upstreamed in couple of months to the mainline",
    "start": "1595880",
    "end": "1601880"
  },
  {
    "text": "repositories we release extensions also so for example uh if you take the outter",
    "start": "1601880",
    "end": "1606960"
  },
  {
    "text": "box spy Tor and and run it on a CPU you already get a lot of performance because of um Intel's new network accelerator",
    "start": "1606960",
    "end": "1613399"
  },
  {
    "text": "Library 1 DN and that's powering a lot of these operations uh when you're running on a uh machine like an Intel",
    "start": "1613399",
    "end": "1619799"
  },
  {
    "text": "xon for example but if you want to go a little bit further right we we have things like Intel extensions for pyos",
    "start": "1619799",
    "end": "1625679"
  },
  {
    "text": "that with one line of code um essentially it's uh int extensive pyto",
    "start": "1625679",
    "end": "1630880"
  },
  {
    "text": "as ipex and ipex do optimize and pass in the model we add further optimizations",
    "start": "1630880",
    "end": "1636039"
  },
  {
    "text": "uh to run it as fast as possible we are also working on even upst streaming",
    "start": "1636039",
    "end": "1641080"
  },
  {
    "text": "whatever possible uh to pyto main line so uh that thing you mentioned right",
    "start": "1641080",
    "end": "1646360"
  },
  {
    "text": "it's very important to work with the community and enable the software that the community uses um rather than having",
    "start": "1646360",
    "end": "1653000"
  },
  {
    "text": "a completely different architecture um and something that's sometimes is close source and working on it um that's not",
    "start": "1653000",
    "end": "1660360"
  },
  {
    "text": "the way Intel things even the whole concept of one API um heterogenous programming everything open about it",
    "start": "1660360",
    "end": "1667080"
  },
  {
    "text": "where other vendors can come in and add their accelerators to the 1 API and use a 1 API standard where um if you're",
    "start": "1667080",
    "end": "1674279"
  },
  {
    "text": "writing code for a CPU there should be minimal to no change that's required to run that on another accelerator uh",
    "start": "1674279",
    "end": "1681159"
  },
  {
    "text": "that's the philosophy that we are we are working with overall in the 1 AP architecture that works underneath all",
    "start": "1681159",
    "end": "1686840"
  },
  {
    "text": "these acceleration libraries uh optimo Habana it's yeah we've been working very closely with hpce Team almost all llm",
    "start": "1686840",
    "end": "1693840"
  },
  {
    "text": "models work out of the box um there are models that we have tested in Benchmark that's available on GitHub and things",
    "start": "1693840",
    "end": "1700159"
  },
  {
    "text": "like BLM right uh our info support all those things are enabled through int libraries for example bigdl and things",
    "start": "1700159",
    "end": "1707279"
  },
  {
    "text": "like that giving a higher level abstraction Beyond pyo because when we talk to startups these days we feel that",
    "start": "1707279",
    "end": "1713120"
  },
  {
    "text": "pyo is considered as a lowlevel library right now and that's uh a little bit funny for folks uh who have worked in",
    "start": "1713120",
    "end": "1720000"
  },
  {
    "text": "tianao or or uh you know even beyond that uh in in 2016 and 17 uh and coming",
    "start": "1720000",
    "end": "1726880"
  },
  {
    "text": "from the early days of tens oflow to see fighter being going low level uh and",
    "start": "1726880",
    "end": "1732399"
  },
  {
    "text": "there this higher abstraction libraries uh to work on top of that it's really an exciting time to be in and work with you",
    "start": "1732399",
    "end": "1738399"
  },
  {
    "text": "all yeah for sure and I also want to highlight in addition to like open source code it's been cool to see until",
    "start": "1738399",
    "end": "1745159"
  },
  {
    "text": "recently uh release nurl chat which was a fine tune on the mistol model um which",
    "start": "1745159",
    "end": "1752480"
  },
  {
    "text": "is openly accessible on hugging face and permissively licensed so we've been",
    "start": "1752480",
    "end": "1757799"
  },
  {
    "text": "we've been experimenting with that and we saw usage of that in the hackathon so it's cool to see people like like a",
    "start": "1757799",
    "end": "1763559"
  },
  {
    "text": "couple of these models narrow chat which is a fine tune of mistl came out like I",
    "start": "1763559",
    "end": "1768600"
  },
  {
    "text": "don't know maybe a week before the hack and notice um which is another fine tune",
    "start": "1768600",
    "end": "1775200"
  },
  {
    "text": "on mistol came out like a few days before the hack and both of those were being used in in the hackathon which I",
    "start": "1775200",
    "end": "1781279"
  },
  {
    "text": "think demonstrates the ability to kind of rapidly adopt this new stuff that's coming",
    "start": "1781279",
    "end": "1788240"
  },
  {
    "text": "[Music]",
    "start": "1790220",
    "end": "1797039"
  },
  {
    "text": "out [Music]",
    "start": "1797039",
    "end": "1802559"
  },
  {
    "text": "this is a change log news break van. AI is a python rag framework for accurate",
    "start": "1802559",
    "end": "1810279"
  },
  {
    "text": "text to SQL generation it lets you chat with any relational database by",
    "start": "1810279",
    "end": "1815640"
  },
  {
    "text": "accurately generating SQL queries trained via rag which stands for",
    "start": "1815640",
    "end": "1821080"
  },
  {
    "text": "retrieval augmented generation to use with any llm that you want you load up",
    "start": "1821080",
    "end": "1827440"
  },
  {
    "text": "your data definitions your documentation and any raw SQL queries you have laying",
    "start": "1827440",
    "end": "1832720"
  },
  {
    "text": "around into Vana and then you're off to the races Vanna boasts high accuracy on",
    "start": "1832720",
    "end": "1838559"
  },
  {
    "text": "complex data sets excellent security and privacy because your database contents are never sent to the llm or a vector DB",
    "start": "1838559",
    "end": "1846919"
  },
  {
    "text": "it boasts the ability to self-learn by choosing to Auto Train on successful",
    "start": "1846919",
    "end": "1852080"
  },
  {
    "text": "queries and a choose your own front-end approach with front ends provided for",
    "start": "1852080",
    "end": "1857240"
  },
  {
    "text": "jupyter Notebook streamlit flask and slack you just heard",
    "start": "1857240",
    "end": "1862840"
  },
  {
    "text": "one of our five top stories from Monday's changelog news subscribe to the",
    "start": "1862840",
    "end": "1867919"
  },
  {
    "text": "podcast to get all of the week's top stories and pop your email address in at",
    "start": "1867919",
    "end": "1874159"
  },
  {
    "text": "[Music]",
    "start": "1883640",
    "end": "1901880"
  },
  {
    "text": "well I do want to make sure that we have time uh to highlight a couple of cool things so what were a couple of the",
    "start": "1901880",
    "end": "1908720"
  },
  {
    "text": "highlights for you all in terms of solutions that you saw or methodologies that you saw or just like cool things",
    "start": "1908720",
    "end": "1915639"
  },
  {
    "text": "you didn't expect what stands out in your mind I'll start quickly and I'll I'll let uh Ryan talk about this so we",
    "start": "1915639",
    "end": "1922760"
  },
  {
    "text": "so we both have been spending I mean Dan you were also there where like every day going through these uh submissions and",
    "start": "1922760",
    "end": "1929440"
  },
  {
    "text": "like it was very difficult to figure out who is the best submission because each time we we think that this is the best",
    "start": "1929440",
    "end": "1934519"
  },
  {
    "text": "and look at the other one we like oh my God like this is incredible even the first submission right the quality of",
    "start": "1934519",
    "end": "1940760"
  },
  {
    "text": "image creation um that was I was surprised that how can you even create",
    "start": "1940760",
    "end": "1946679"
  },
  {
    "text": "this kind of images at the model that was there the time that was spent in prompt engineering and even using custom",
    "start": "1946679",
    "end": "1953639"
  },
  {
    "text": "models uh to combine these sort of images and create these Solutions other thing um uh there are a few really",
    "start": "1953639",
    "end": "1960919"
  },
  {
    "text": "interesting rag examples taking YouTube videos passing the audio figuring out a YouTube search that was something that",
    "start": "1960919",
    "end": "1967039"
  },
  {
    "text": "stood out to me and for the python code explainer there was a a submission that came maybe uh I think in 3 hours uh the",
    "start": "1967039",
    "end": "1974720"
  },
  {
    "text": "first iteration of the of the submission for the by this person where there was",
    "start": "1974720",
    "end": "1979919"
  },
  {
    "text": "uh you could do uh that that solution can do python explanation but also give uh references to where exactly that the",
    "start": "1979919",
    "end": "1987399"
  },
  {
    "text": "model got this information from a really really good use of rag and and llms um",
    "start": "1987399",
    "end": "1993159"
  },
  {
    "text": "Ryan what are the things that that stood out for you on submissions what always stands out is when somebody the the",
    "start": "1993159",
    "end": "1999760"
  },
  {
    "text": "Jupiter notebooks which rul had put together I think are really well designed for as learning activities and",
    "start": "1999760",
    "end": "2006159"
  },
  {
    "text": "to like get something done that's cool just by going through them um and so people use those to do a lot of amazing",
    "start": "2006159",
    "end": "2013279"
  },
  {
    "text": "work and I was stunned by the quality but what always stands out to me is when somebody like takes the concept takes",
    "start": "2013279",
    "end": "2018559"
  },
  {
    "text": "what's in there and then runs with it and like we saw people setting up AI agents for some of these challenges like",
    "start": "2018559",
    "end": "2025799"
  },
  {
    "text": "the comic book generator you know in the code explanator in the the fifth challenge of where where code",
    "start": "2025799",
    "end": "2031919"
  },
  {
    "text": "explanation comes in it's like oh explainability like listen we're going to do things like we're going to do the",
    "start": "2031919",
    "end": "2038360"
  },
  {
    "text": "explanation the the model will then cite the sources it's using right um which",
    "start": "2038360",
    "end": "2043639"
  },
  {
    "text": "made me think you know we used to in Years Gone by people were very concerned with explainable AI and what they always",
    "start": "2043639",
    "end": "2049720"
  },
  {
    "text": "meant is like well if the model is making a recommendation or classifying something in such a way we should be",
    "start": "2049720",
    "end": "2055520"
  },
  {
    "text": "able to figure out exactly why and so there are all these like discussions of how best to do that like oh you can use",
    "start": "2055520",
    "end": "2060839"
  },
  {
    "text": "shap values you know or whatever and I think what it turns out is like well now that we have gen you know and we have",
    "start": "2060839",
    "end": "2067679"
  },
  {
    "text": "tral based methods it's like just ask what are you so okay this is your explanation like where did that come",
    "start": "2067679",
    "end": "2073398"
  },
  {
    "text": "from and you know we we see like the setting of sources so that creativity not just in application which was",
    "start": "2073399",
    "end": "2080079"
  },
  {
    "text": "astounding but then also in people bringing in methods Cutting Edge methods from outside of like what we even",
    "start": "2080079",
    "end": "2087158"
  },
  {
    "text": "included in the notebooks that always blew me away and there were some people that just always ended up um in the top",
    "start": "2087159",
    "end": "2093280"
  },
  {
    "text": "five like toas Bari I don't know if I'm pronouncing that correctly who I actually reached out to it was like what do you do for a living like this is your",
    "start": "2093280",
    "end": "2100119"
  },
  {
    "text": "work is incredible um becauseas uh there are so many Simon's team um Prav yeah I",
    "start": "2100119",
    "end": "2108560"
  },
  {
    "text": "haven't sat down to a compile a list uh you know who you are because you can go back each to each winners post that rul",
    "start": "2108560",
    "end": "2115079"
  },
  {
    "text": "made and find those names and that's something that we'll follow up probably with a Blog about and you know U maybe",
    "start": "2115079",
    "end": "2121359"
  },
  {
    "text": "reaching out to somebody you to be on a podcast or to talk to us or whatever I would also like to highlight that uh our",
    "start": "2121359",
    "end": "2127720"
  },
  {
    "text": "youngest participant I think uh might be on this yeah I see his name Arian who is",
    "start": "2127720",
    "end": "2133400"
  },
  {
    "text": "a middle school student who owned us every day like at around the time when we were supposed to be posting a video",
    "start": "2133400",
    "end": "2139680"
  },
  {
    "text": "or whatever with the same like skeleton like waiting tapping his fingers you know like patiently waiting for this",
    "start": "2139680",
    "end": "2145320"
  },
  {
    "text": "video that was supposed to be here five minutes ago that was a wonderful part of that for me yeah even the the thing",
    "start": "2145320",
    "end": "2153359"
  },
  {
    "text": "right like you were mentioning the the python explaining uh I mean there were there were submissions were okay now you",
    "start": "2153359",
    "end": "2159800"
  },
  {
    "text": "have explained the code now click this button to optimize the code I'll give you an optimized version of the solution",
    "start": "2159800",
    "end": "2166359"
  },
  {
    "text": "taking the challenge in spirit and not just in words and going beyond that like",
    "start": "2166359",
    "end": "2172200"
  },
  {
    "text": "incredible work um it's truly I really feel generative Ai and the commoditization ofi I've really really",
    "start": "2172200",
    "end": "2179599"
  },
  {
    "text": "helped a lot more folks who might not have been here to do this AI kind of work really democratizing the solution",
    "start": "2179599",
    "end": "2186560"
  },
  {
    "text": "all the toolings the the API based approach for example from prediction guard the hugging face ecosystem making",
    "start": "2186560",
    "end": "2192520"
  },
  {
    "text": "it as easy to use it and and one thing and when Dan was mentioning that people",
    "start": "2192520",
    "end": "2198480"
  },
  {
    "text": "were using neural chat uh for llm apis that was because of Dan's incredible team uh adding these models and scaling",
    "start": "2198480",
    "end": "2205839"
  },
  {
    "text": "it in like in matter of hours so it's still a challenge to deploy and and scale this uh you you have an incredible",
    "start": "2205839",
    "end": "2213319"
  },
  {
    "text": "team down there who was also participating in the conversation thanks",
    "start": "2213319",
    "end": "2218599"
  },
  {
    "text": "well I definitely think so appreciate that and and speaking of um where people can find out more about some of the",
    "start": "2218599",
    "end": "2226079"
  },
  {
    "text": "specific submissions even seeing some screenshots some code that people generated um Eugene do you want to",
    "start": "2226079",
    "end": "2232319"
  },
  {
    "text": "comment you created some amazing blog posts already and I think there's more in the works so um do you want to just",
    "start": "2232319",
    "end": "2239119"
  },
  {
    "text": "describe to those listening where they can find out more about some of the solutions and maybe also where they can",
    "start": "2239119",
    "end": "2246599"
  },
  {
    "text": "keep tabs on future events and and things coming through the liftoff team",
    "start": "2246599",
    "end": "2252720"
  },
  {
    "text": "thank you de um Danielle so we um we posted uh already three blog articles um",
    "start": "2252720",
    "end": "2260520"
  },
  {
    "text": "uh at our landing page developer. intel.com liftoff and uh I just want to",
    "start": "2260520",
    "end": "2265839"
  },
  {
    "text": "also give you insights um as I reviewed always the top submissions um and uh",
    "start": "2265839",
    "end": "2271480"
  },
  {
    "text": "other like uh honorable mentions I had a look at the profiles uh of um uh",
    "start": "2271480",
    "end": "2277720"
  },
  {
    "text": "developers and it was really like exciting mix across regions and um as",
    "start": "2277720",
    "end": "2283960"
  },
  {
    "text": "already said like we have students we have uh individual developers we have Founders here we have here software",
    "start": "2283960",
    "end": "2291119"
  },
  {
    "text": "Engineers from a big uh companies uh but also uh I saw um very active uh software",
    "start": "2291119",
    "end": "2300680"
  },
  {
    "text": "developers from Intel this is very interesting that um I mean indeed like Intel lifto um is more um targeting um",
    "start": "2300680",
    "end": "2310520"
  },
  {
    "text": "startups but it was very diverse portfolio of developers uh and from across region so it's really like",
    "start": "2310520",
    "end": "2316839"
  },
  {
    "text": "amazing because in our slack channel uh we for hackaton we see really like",
    "start": "2316839",
    "end": "2322640"
  },
  {
    "text": "always like uh from like 24 hours um messages there with submissions with",
    "start": "2322640",
    "end": "2330200"
  },
  {
    "text": "questions uh because of this diversity this is really like a global hackaton at",
    "start": "2330200",
    "end": "2335520"
  },
  {
    "text": "the end of the year we're very proud about it and uh we will spot spot um",
    "start": "2335520",
    "end": "2340920"
  },
  {
    "text": "post really like um articles about each challenges and also about the last um",
    "start": "2340920",
    "end": "2349440"
  },
  {
    "text": "challenge with uh two days uh development Sprint now you can read uh",
    "start": "2349440",
    "end": "2355720"
  },
  {
    "text": "three uh articles uh not only like it is not only announcement um of winners but",
    "start": "2355720",
    "end": "2362960"
  },
  {
    "text": "also their own comments and uh results of Works what you can find in this blog",
    "start": "2362960",
    "end": "2368599"
  },
  {
    "text": "articles awesome thank you so much for your work on those it was cool to see like the traffic coming in basically all",
    "start": "2368599",
    "end": "2375920"
  },
  {
    "text": "day and night which was awesome and um like it's hard to sleep while all of",
    "start": "2375920",
    "end": "2381079"
  },
  {
    "text": "this cool stuff is going on um so as we draw close to an end here I want to kick",
    "start": "2381079",
    "end": "2386880"
  },
  {
    "text": "it over to uh Ralph who leads up the liftoff program and just get any sort of",
    "start": "2386880",
    "end": "2393000"
  },
  {
    "text": "final thoughts um like what did you think of this whole process what were you encouraged to see and what are you",
    "start": "2393000",
    "end": "2400520"
  },
  {
    "text": "looking forward to in the New Year in terms of uh things related to generative",
    "start": "2400520",
    "end": "2405839"
  },
  {
    "text": "Ai and liftoff hello everyone it's me RAV I'm sorry for the noise here that's",
    "start": "2405839",
    "end": "2411599"
  },
  {
    "text": "why I was on mute for the all the time because there is some at the office there's some kind of um year end party",
    "start": "2411599",
    "end": "2419000"
  },
  {
    "text": "going on um so yeah I was completely Amazed by what happened during this",
    "start": "2419000",
    "end": "2424920"
  },
  {
    "text": "aaton and I'm very grateful to the team starting with Rahul the Rockstar",
    "start": "2424920",
    "end": "2431800"
  },
  {
    "text": "developer of this aaton and also thank you very much to you Dan for supporting",
    "start": "2431800",
    "end": "2438839"
  },
  {
    "text": "this for really running this with us and then Ryan who is the second Rockstar",
    "start": "2438839",
    "end": "2444920"
  },
  {
    "text": "developer here and of course Eugene who made it all happen and so I really look",
    "start": "2444920",
    "end": "2450800"
  },
  {
    "text": "forward to uh the impact we can make in the developer ecosystem in the AI uh",
    "start": "2450800",
    "end": "2456760"
  },
  {
    "text": "developer ecosystem really look forward what's going to happen next year and we want to have a share of uh what the",
    "start": "2456760",
    "end": "2464480"
  },
  {
    "text": "future might bring to us and I can tell you the Intel LIF off team is ready for",
    "start": "2464480",
    "end": "2470720"
  },
  {
    "text": "whatever comes in the startup world and uh yeah so see you next time and uh",
    "start": "2470720",
    "end": "2478560"
  },
  {
    "text": "great to have you all here thanks R awesome um I mean we co-created this",
    "start": "2478560",
    "end": "2483920"
  },
  {
    "text": "together with prediction gr and day one like we had meetings on how to do this and what are the things that we need to",
    "start": "2483920",
    "end": "2489760"
  },
  {
    "text": "do on this do you want to say uh for the folks who don't know about prediction guard you know to introduce prediction",
    "start": "2489760",
    "end": "2495280"
  },
  {
    "text": "guard also to what was your experience bre uh working on this hackathon with us",
    "start": "2495280",
    "end": "2500839"
  },
  {
    "text": "um and what are things that we need to do next uh I'm sure there are we need to do it big 2,000 is now sort of our",
    "start": "2500839",
    "end": "2508000"
  },
  {
    "text": "Baseline so next time we do maybe it's 4,000 people it's pretty big so let's yeah uh what's your take on it then I",
    "start": "2508000",
    "end": "2515640"
  },
  {
    "text": "think one takeway is like when you do a hackathon with Intel liftoff you better be ready to scale your servers um so um",
    "start": "2515640",
    "end": "2523880"
  },
  {
    "text": "we'll we'll take that takeway uh for next year when it's 10,000 people uh",
    "start": "2523880",
    "end": "2528960"
  },
  {
    "text": "participating I'm sure but yeah it's been great I one of the things like I say is um we really appreciated actually",
    "start": "2528960",
    "end": "2536400"
  },
  {
    "text": "interacting with people creating practical Solutions with llms that's what we're about at prediction guard and",
    "start": "2536400",
    "end": "2542720"
  },
  {
    "text": "seeing people actually apply some of the latest models like the neural chat notice Zephyr ye wizard coder seeing",
    "start": "2542720",
    "end": "2551480"
  },
  {
    "text": "them actually access these things and even like combine them together in unique agents I think that gave us like",
    "start": "2551480",
    "end": "2558760"
  },
  {
    "text": "such encouragement to see people actually kind of fulfilling this Vision that we have which is providing these",
    "start": "2558760",
    "end": "2565440"
  },
  {
    "text": "open privacy conserving hosted models to people and them combining them in unique",
    "start": "2565440",
    "end": "2571800"
  },
  {
    "text": "ways to create real Enterprise Value that's what we're excited to see and do it in a way that is actually trustworthy",
    "start": "2571800",
    "end": "2579119"
  },
  {
    "text": "Intel of course has a great history with security and and privacy confidential Computing but to be able to sort of be",
    "start": "2579119",
    "end": "2586599"
  },
  {
    "text": "partnered together and see people creating um really both trustworthy privacy conserving and scalable",
    "start": "2586599",
    "end": "2593280"
  },
  {
    "text": "Solutions with llms in this environment is really encouraging I think for the future of AI because as we've seen even",
    "start": "2593280",
    "end": "2600040"
  },
  {
    "text": "over the past week with mixol being released and striped hyena and all these",
    "start": "2600040",
    "end": "2605720"
  },
  {
    "text": "models the open model are just getting better and better and um you know",
    "start": "2605720",
    "end": "2611440"
  },
  {
    "text": "providing ways for people to access those in a scalable way and build real solutions yeah it's really exciting to",
    "start": "2611440",
    "end": "2618559"
  },
  {
    "text": "see that happen in in the industry so thank you for hosting this and making it",
    "start": "2618559",
    "end": "2624160"
  },
  {
    "text": "happen um it was a great experience you and thank you to the entire team like uh",
    "start": "2624160",
    "end": "2629319"
  },
  {
    "text": "Scott Ral um the team that I I uh talk to uh daily Ryan like we practically we",
    "start": "2629319",
    "end": "2637240"
  },
  {
    "text": "talk every hour Eugene uh and and the whole of engineering team at int lifto",
    "start": "2637240",
    "end": "2642760"
  },
  {
    "text": "um jois vat uh basanta Raj like you guys are incredible and all the teams uh Dan",
    "start": "2642760",
    "end": "2650000"
  },
  {
    "text": "side also like being in the slack Channel and um answering questions uh",
    "start": "2650000",
    "end": "2655319"
  },
  {
    "text": "there was all of us had reservations but we kept that to ourselves uh we didn't know how it's going to go but everyone",
    "start": "2655319",
    "end": "2661240"
  },
  {
    "text": "pitched in with really cool ideas and with mindset to help and that really shows even the community all the",
    "start": "2661240",
    "end": "2667119"
  },
  {
    "text": "messages we get we had messages where folks were saying now I can take this thing to my boss and tell like you know",
    "start": "2667119",
    "end": "2672920"
  },
  {
    "text": "I need to implement these sort of things in our day-to-day work and this is really really gratifying to see that and",
    "start": "2672920",
    "end": "2678960"
  },
  {
    "text": "next time we come in uh we'll fix all the shortcomings we'll do an internal review carefully if there were any",
    "start": "2678960",
    "end": "2685319"
  },
  {
    "text": "shortcomings I'm sure there are uh to to fix them bigger better more scalable",
    "start": "2685319",
    "end": "2690599"
  },
  {
    "text": "more cooler challenges we want to continue this and and grow this community so any sort of feedback eug",
    "start": "2690599",
    "end": "2696359"
  },
  {
    "text": "would be I'm I'm sure be sending a a surve um I know it's very difficult to answer any sort of surveys uh it's",
    "start": "2696359",
    "end": "2703000"
  },
  {
    "text": "easier to delete that email but we would really appreciate I personally would really appreciate your feedback on what",
    "start": "2703000",
    "end": "2708480"
  },
  {
    "text": "we can improve what are the things that we could add more and make it more more a Community Driven effort we we don't",
    "start": "2708480",
    "end": "2715359"
  },
  {
    "text": "really like in lift of the top down top approach we really want your uh feedback",
    "start": "2715359",
    "end": "2720559"
  },
  {
    "text": "and and the things that you want to see and build around it so thank you uh once again yeah thank you all um closing out",
    "start": "2720559",
    "end": "2728200"
  },
  {
    "text": "here I just want to encourage you also to not only keep tab for hackathons but all of you who are building amazing",
    "start": "2728200",
    "end": "2734079"
  },
  {
    "text": "startups and I know many of you are who are part of the hackathon they maybe are too humble uh uh to say it but this",
    "start": "2734079",
    "end": "2741359"
  },
  {
    "text": "liftoff team is doing amazing things and as a startup that's participating in it your startup should join liftoff and and",
    "start": "2741359",
    "end": "2748440"
  },
  {
    "text": "reach out to them because you will find amazing uh amazing benefit and scale and access to expertise and Hardware so uh",
    "start": "2748440",
    "end": "2756200"
  },
  {
    "text": "reach out to the team they truly are rock stars like Ralph said so reach out",
    "start": "2756200",
    "end": "2761319"
  },
  {
    "text": "and get involved in program and um the the community with that we'll we'll close this uh Advent of gen AI out uh",
    "start": "2761319",
    "end": "2769839"
  },
  {
    "text": "we'll give you the last word uh Rahul all right yeah I forgot to mention one person Kelly uh I don't know I don't",
    "start": "2769839",
    "end": "2776079"
  },
  {
    "text": "know how I forgot she has been incredible starting from the website uh",
    "start": "2776079",
    "end": "2781319"
  },
  {
    "text": "creating the content editing the video I mean she was sick while she was doing it",
    "start": "2781319",
    "end": "2787079"
  },
  {
    "text": "but uh she had some a few hours that she she had to take off but she has been incredible in the pace at which uh she",
    "start": "2787079",
    "end": "2794520"
  },
  {
    "text": "was able to help us and and thank you Kelly for doing that I'm sure that we' be doing many more of these things uh",
    "start": "2794520",
    "end": "2800839"
  },
  {
    "text": "again the entire team if I miss missed anyone I'm really sorry but this was",
    "start": "2800839",
    "end": "2805880"
  },
  {
    "text": "truly a team event everyone contributed and um without in a small contribution",
    "start": "2805880",
    "end": "2811280"
  },
  {
    "text": "this would have just been an idea so thank you all for doing that thanks everybody",
    "start": "2811280",
    "end": "2818839"
  },
  {
    "text": "[Music] all right that is practical AI for this",
    "start": "2820260",
    "end": "2826640"
  },
  {
    "text": "week subscribe now if you haven't already head to practical a.m for all",
    "start": "2826640",
    "end": "2833240"
  },
  {
    "text": "the ways and join our free slack team where you can hang out with Daniel Chris",
    "start": "2833240",
    "end": "2838319"
  },
  {
    "text": "and the entire change log Community sign up today at practical ai. fm/ Community",
    "start": "2838319",
    "end": "2846240"
  },
  {
    "text": "thanks again to our partners at fly.io to our beat freaking residence breakmaster cylinder and to you for",
    "start": "2846240",
    "end": "2852760"
  },
  {
    "text": "listening we appreciate you spending time with us that's all for now we'll talk to you again next",
    "start": "2852760",
    "end": "2859070"
  },
  {
    "text": "[Music]",
    "start": "2859070",
    "end": "2868720"
  },
  {
    "text": "time",
    "start": "2868720",
    "end": "2871720"
  }
]
[
  {
    "text": "[Music]",
    "start": "3320",
    "end": "8769"
  },
  {
    "text": "thank thank you Sid uh it's a real pleasure to be with you all today at cucon uh to share that the world is",
    "start": "12880",
    "end": "20680"
  },
  {
    "text": "becoming more transactional uh from servers to serverless in per second billing uh you",
    "start": "20680",
    "end": "26640"
  },
  {
    "text": "used to buy a server every 3 years or rent dedicated by the month then an instance by the hour now every second",
    "start": "26640",
    "end": "33120"
  },
  {
    "text": "there's a serous transaction and in the same way from coal to clean energy our energy sources are changing to be more",
    "start": "33120",
    "end": "39840"
  },
  {
    "text": "transactional so you have Smart Meters around the world that now transact energy every 30 minutes instead of once",
    "start": "39840",
    "end": "46360"
  },
  {
    "text": "a month so it's an increase of 1,440 times uh and then there's the",
    "start": "46360",
    "end": "51399"
  },
  {
    "text": "tsunami of instant payments for example India's UPI processed 10 billion real-time transactions in",
    "start": "51399",
    "end": "58359"
  },
  {
    "text": "2019 and this year in the month of August alone uh UPI processed 10 billion",
    "start": "58359",
    "end": "65600"
  },
  {
    "text": "transactions uh so India went from 10 billion a year to 10 billion a month and will triple over the next three years if",
    "start": "65600",
    "end": "71960"
  },
  {
    "text": "India is leading then other countries are not far behind for example Brazil 3 billion a month growing 200% a year and",
    "start": "71960",
    "end": "79640"
  },
  {
    "text": "this is spreading for example to the US with the introduction of fed now so the world is becoming more transactional the",
    "start": "79640",
    "end": "86079"
  },
  {
    "text": "volume of online transactional processing or oltp across several sectors has grown by",
    "start": "86079",
    "end": "92439"
  },
  {
    "text": "three orders of magnitude and yet the three most popular oltp databases today",
    "start": "92439",
    "end": "98799"
  },
  {
    "text": "post MySQL and sqlite are 20 to 30 years old designed for a different world and a",
    "start": "98799",
    "end": "104399"
  },
  {
    "text": "different scale which I think is a testament uh to the people that designed",
    "start": "104399",
    "end": "109600"
  },
  {
    "text": "these databases uh that they still power everything today and at the same time um",
    "start": "109600",
    "end": "115719"
  },
  {
    "text": "in in the same 30 years we've seen advances in hardware and research uh so there are hints of the need to redesign",
    "start": "115719",
    "end": "123200"
  },
  {
    "text": "oltp for new order of magnitude starts with a creeping dependence on caching escalates to deployments that have 64",
    "start": "123200",
    "end": "130399"
  },
  {
    "text": "shards of postgres Maria DB and capitulates to the extreme of replacing",
    "start": "130399",
    "end": "136120"
  },
  {
    "text": "the oltp database entirely for example the switch that powers India's UPI runs",
    "start": "136120",
    "end": "141280"
  },
  {
    "text": "on open source but not OP Source oltp instead they append transactions to CFA",
    "start": "141280",
    "end": "147720"
  },
  {
    "text": "then they've Rewritten the transactions processing logic and Java Services above reddis so they're doing around 10,000",
    "start": "147720",
    "end": "154120"
  },
  {
    "text": "logical payments per second at Peak and 10 times that many physical database queries so 100,000 transactions a second",
    "start": "154120",
    "end": "162159"
  },
  {
    "text": "in terms of database transactions is the peak ltp load yet even a 10th of this a th000 TPS for systems a fraction of the",
    "start": "162159",
    "end": "168920"
  },
  {
    "text": "size of UPI is still not easy to do so the other problem is that open source ltp databases are not online if you",
    "start": "168920",
    "end": "176720"
  },
  {
    "text": "interpret online in the mission critical sense so there are single node out of the out of the box you get synchronous",
    "start": "176720",
    "end": "182239"
  },
  {
    "text": "replication yes but there's no consensus algorithm backed in no raft or paof so",
    "start": "182239",
    "end": "187799"
  },
  {
    "text": "failover is manual and you risk data loss and I think this is why at the on the other end of the spectrum you see",
    "start": "187799",
    "end": "193879"
  },
  {
    "text": "Mission critical systems start to abandon open source entirely uh they move to proprietary Cloud databases to",
    "start": "193879",
    "end": "200400"
  },
  {
    "text": "trust the cloud provider with the problems of scale availability and cost",
    "start": "200400",
    "end": "206000"
  },
  {
    "text": "efficiency how can we do better uh can we redesign OTP by three orders of magnitude I hope that by the end of our",
    "start": "206000",
    "end": "212400"
  },
  {
    "text": "time together we'll see not only that it's possible but that it's exciting and needs to be done especially if we change",
    "start": "212400",
    "end": "218560"
  },
  {
    "text": "the way we think about scalability so I love this paper by Frank mcer uh because",
    "start": "218560",
    "end": "225040"
  },
  {
    "text": "it shows I think you know perhaps we focused too much on the scalability of our systems and we've lost sight of the",
    "start": "225040",
    "end": "232159"
  },
  {
    "text": "need to optimize our unit of scale so it's common in software distributed",
    "start": "232159",
    "end": "237879"
  },
  {
    "text": "systems to Define scalability as more with more you handle orders of magnitude more workload with orders of magnitude",
    "start": "237879",
    "end": "244439"
  },
  {
    "text": "more machines uh the trouble is that Opex gets out of hand firstly operating expenditure so you pay for more machines",
    "start": "244439",
    "end": "251239"
  },
  {
    "text": "and secondly operating experience one thing you know manage a single node server it's another to manage a thousand",
    "start": "251239",
    "end": "258000"
  },
  {
    "text": "so I prefer the definition of scalability from industrial engineering do more with less um so you handle",
    "start": "258000",
    "end": "265120"
  },
  {
    "text": "orders of magnitude more lowed with the same machine uh so so you start to ask",
    "start": "265120",
    "end": "270400"
  },
  {
    "text": "the question how can we take our unit of scale a single machine and redesign the",
    "start": "270400",
    "end": "276000"
  },
  {
    "text": "design so that we can go from a thousand real world transactions a second to a million transactions a second uh and",
    "start": "276000",
    "end": "283160"
  },
  {
    "text": "thinking in terms of the exponent like this you know tweaking that exponent it's a challenge a fun challenge um",
    "start": "283160",
    "end": "289800"
  },
  {
    "text": "because there are only so many microsc in a second you know to process a million transactions your budget is one",
    "start": "289800",
    "end": "296360"
  },
  {
    "text": "microsc per transaction it's not very long uh uh but to make it no less easy",
    "start": "296360",
    "end": "302160"
  },
  {
    "text": "we're also not going to take shortcuts uh so no magic tricks no eventual consistency no no weak durability here",
    "start": "302160",
    "end": "308759"
  },
  {
    "text": "uh we're going to have to work hard together um if we want to handle orders of more scale with the same machine and",
    "start": "308759",
    "end": "314120"
  },
  {
    "text": "in fact better guarantees uh because the default isolation level for example in",
    "start": "314120",
    "end": "319199"
  },
  {
    "text": "postgis is actually read committed uh which is not so safe uh you know you might query an account balance see that",
    "start": "319199",
    "end": "325280"
  },
  {
    "text": "there's enough to transact uh but then query again and see that another database transac has withdrawn the",
    "start": "325280",
    "end": "331240"
  },
  {
    "text": "balance you thought you had so we need to offer the highest level of isolation and storability and to do this I I think",
    "start": "331240",
    "end": "338360"
  },
  {
    "text": "we need to think from first principes so to ask the question how can we optimize our unit of scale um how can we take the",
    "start": "338360",
    "end": "345199"
  },
  {
    "text": "four primary colors of computer science network storage memory compute and blend them into a more optimal Design This was",
    "start": "345199",
    "end": "352199"
  },
  {
    "text": "the question we asked in July 20120 as we began to create tigerle uh at the time we were working on an open-source P",
    "start": "352199",
    "end": "359360"
  },
  {
    "text": "payment switch uh we wanted a drop in open source olp database to power this",
    "start": "359360",
    "end": "365479"
  },
  {
    "text": "switch more cost efficiently so we wanted to tweak the exponents and nail",
    "start": "365479",
    "end": "371039"
  },
  {
    "text": "the scale uh with a distributed Financial transactions database optimized for oltp uh our goals were to",
    "start": "371039",
    "end": "377560"
  },
  {
    "text": "improve performance by three orders using the same or less hardware and for the design to be significantly safer and",
    "start": "377560",
    "end": "384880"
  },
  {
    "text": "easier to operate uh so tiger beetles license under pasy 2 my favorite open source license uh and we're approaching",
    "start": "384880",
    "end": "392080"
  },
  {
    "text": "our first production release uh the dream is to run oltp at any scale in any environment and indeed the beetle we",
    "start": "392080",
    "end": "399080"
  },
  {
    "text": "named tiger beet after thrives in all kinds of environments also one of the fastest creatures in the world uh",
    "start": "399080",
    "end": "404840"
  },
  {
    "text": "sprinting at 5.6 mph 125 body lengths per second scaled for size the tiger",
    "start": "404840",
    "end": "411319"
  },
  {
    "text": "beetle is the fastest insect and land animal on Earth and doesn't it look it",
    "start": "411319",
    "end": "416360"
  },
  {
    "text": "uh so tiger beetle is meant to be fast and small but what is oltp what do we",
    "start": "416360",
    "end": "421479"
  },
  {
    "text": "mean by transactions database transactions or are database transactions named after another kind of",
    "start": "421479",
    "end": "428319"
  },
  {
    "text": "transaction the everyday transactions every you know everyday business in every sector the who what when where why",
    "start": "428319",
    "end": "435080"
  },
  {
    "text": "and how much um of business so I find it fascinating that the first popular LP",
    "start": "435080",
    "end": "440960"
  },
  {
    "text": "Benchmark was literally called debit credit and this wasn't just",
    "start": "440960",
    "end": "447599"
  },
  {
    "text": "any Benchmark either so I love the the an nonl anonymous but in fact there were 24 etls",
    "start": "447599",
    "end": "455039"
  },
  {
    "text": "24 co-authors collaborating with Jim Gray the transactions processing Guru uh",
    "start": "455039",
    "end": "460759"
  },
  {
    "text": "who was a tandem at the time also coined the term acid also gave us the five minute rule uh Jim's debit credit",
    "start": "460759",
    "end": "467400"
  },
  {
    "text": "Benchmark inspired so many Benchmark Wars uh that soon the transaction processing performance Council formed to",
    "start": "467400",
    "end": "474080"
  },
  {
    "text": "standardize ltp benchmarks and then again you know the history historical context of transactions was all",
    "start": "474080",
    "end": "480720"
  },
  {
    "text": "financial banking banking Warehouse brokerage uh and Once Upon a Time OTP",
    "start": "480720",
    "end": "487159"
  },
  {
    "text": "actually included analytics in there somewhere um you didn't have the term olap um and general purpose is also",
    "start": "487159",
    "end": "494039"
  },
  {
    "text": "somewhere in between so until 1993 Edgar Cod coined the term olap as",
    "start": "494039",
    "end": "499400"
  },
  {
    "text": "online analytical processing and olap spun out of oltp so where olp is",
    "start": "499400",
    "end": "505520"
  },
  {
    "text": "interested in the who what when where why and how much olap is more interested in the why and what if uh so where oltp",
    "start": "505520",
    "end": "512839"
  },
  {
    "text": "is Right heavy with a high volume of simple queries olap is read heavy with",
    "start": "512839",
    "end": "518279"
  },
  {
    "text": "less volume and complex query so OTP is actually not really a query execution engine you know that's all the olap",
    "start": "518279",
    "end": "524360"
  },
  {
    "text": "stuff olp is just how do we get stuff in the front door and olap is like okay now how do we query uh so after olap spun",
    "start": "524360",
    "end": "531360"
  },
  {
    "text": "out of ltp object storage quickly followed suit and we no longer store blobs in our ltp database we use the",
    "start": "531360",
    "end": "537640"
  },
  {
    "text": "database as a queue uh so that today we use oltp for business",
    "start": "537640",
    "end": "542880"
  },
  {
    "text": "transactions um and and anything general purpose uh which means that the oltp",
    "start": "542880",
    "end": "548640"
  },
  {
    "text": "database is forced to generalize and there's no separation of concerns so I think you see where I'm going with this",
    "start": "548640",
    "end": "554680"
  },
  {
    "text": "you know just as duck DB is better at olap than sqlite this free sqlite to focus on general purpose workloads I",
    "start": "554680",
    "end": "562000"
  },
  {
    "text": "think we can unlock scale if we separate our general purpose processing from",
    "start": "562000",
    "end": "567480"
  },
  {
    "text": "olp so if we take all the metadata relating to business transactions we",
    "start": "567480",
    "end": "572600"
  },
  {
    "text": "move it out of the data plane into the control plane for olp to continue to",
    "start": "572600",
    "end": "578680"
  },
  {
    "text": "carry the mixed read write control plan workloads that have less volume than the data plan which remains olp so if we",
    "start": "578680",
    "end": "586079"
  },
  {
    "text": "apply separation of concerns to the lgp control plane and ltp data plane like this then I think we can start to reach",
    "start": "586079",
    "end": "593200"
  },
  {
    "text": "three orders in three design decisions across storage engine consensus and",
    "start": "593200",
    "end": "598399"
  },
  {
    "text": "Network um here with respect to the network we find that scale increases aerodynamic",
    "start": "598399",
    "end": "604959"
  },
  {
    "text": "drag as you go through three orders of magnetude the pressure on everything increases uh anything that's not",
    "start": "604959",
    "end": "611800"
  },
  {
    "text": "isomorphic burns up so you suddenly see an impedance mismatch where there wasn't one before and that's because while the",
    "start": "611800",
    "end": "618880"
  },
  {
    "text": "language of database transactions is SQL the language of business transactions in",
    "start": "618880",
    "end": "624760"
  },
  {
    "text": "the real world is doubl entry accounting so I I would",
    "start": "624760",
    "end": "631760"
  },
  {
    "text": "never want to replace SQL for analytics it's great you know send one query in get a lot of analysis out um but there's",
    "start": "631760",
    "end": "638639"
  },
  {
    "text": "also a lot going for double entry you know if your workload is oltp and you want to track business transactions you",
    "start": "638639",
    "end": "645480"
  },
  {
    "text": "know the gym grade debit credit then Double Entry is really the perfect schema which means you see this tension",
    "start": "645480",
    "end": "651079"
  },
  {
    "text": "in query amplification so here here it is a switch wants to execute the debit credit Logic for One financial",
    "start": "651079",
    "end": "657440"
  },
  {
    "text": "transaction but this knes on the order of 10 redite database queries so you can",
    "start": "657440",
    "end": "663160"
  },
  {
    "text": "use stor procedures to get this amplification down to one but then a million transactions a second is still a",
    "start": "663160",
    "end": "668800"
  },
  {
    "text": "million Network requests a second you know more with more so it's not more with less so what if we could invert",
    "start": "668800",
    "end": "675000"
  },
  {
    "text": "query amplification to our advantage what if in one database transaction we",
    "start": "675000",
    "end": "680360"
  },
  {
    "text": "could process 10 business transactions a thousand business transactions even",
    "start": "680360",
    "end": "685480"
  },
  {
    "text": "10,000 you know this would give not three orders but four orders more scale in one network request one network",
    "start": "685480",
    "end": "692720"
  },
  {
    "text": "request and we're doing 10,000 um so it's just one request 10,000 one request",
    "start": "692720",
    "end": "698279"
  },
  {
    "text": "10,000 um that's that's a lot more with less um and then we can spend the extra order on safety so the advantage of",
    "start": "698279",
    "end": "705440"
  },
  {
    "text": "Double Entry as simple flexible business schema is not only that it can handle",
    "start": "705440",
    "end": "711120"
  },
  {
    "text": "any kind of oltp business transaction the who what when where why and how much but that it's standardized so you can",
    "start": "711120",
    "end": "717800"
  },
  {
    "text": "pack a double entry transaction in a fixed size struct put 10,000 of these in a single you know Network request um",
    "start": "717800",
    "end": "724920"
  },
  {
    "text": "you've got a uu ID for distributed in a potency debit and credit account ID to describe the who the amount or the how",
    "start": "724920",
    "end": "731440"
  },
  {
    "text": "much um this amount can be any unit of value not only financial and then the transaction Tim stamp obviously is the",
    "start": "731440",
    "end": "738279"
  },
  {
    "text": "win finally the transaction metadata which links back up to your lgp control plan and you've got your user data to",
    "start": "738279",
    "end": "744839"
  },
  {
    "text": "record the why what and where so this is really what these systems need to do this is what they all do you know so if",
    "start": "744839",
    "end": "751160"
  },
  {
    "text": "you have an O CHP database again in your control plan then your data plan can operate on thousands of these 128 by",
    "start": "751160",
    "end": "758360"
  },
  {
    "text": "transactions or two CPU cash lines so in a single one me query you can process",
    "start": "758360",
    "end": "763600"
  },
  {
    "text": "8,000 transactions and with low latency as well uh because if you have a single transaction that you need to do you just",
    "start": "763600",
    "end": "769680"
  },
  {
    "text": "send it right away you don't batch but then as your load increases your you know your requests fill up and you get",
    "start": "769680",
    "end": "775160"
  },
  {
    "text": "more and more transactions per query so this gives not only the best throughput but intuitively also a sweet spot for",
    "start": "775160",
    "end": "781399"
  },
  {
    "text": "latency because your system now has more capacity more mechanical sympathy so for example in your server uh with a single",
    "start": "781399",
    "end": "788920"
  },
  {
    "text": "receive sore um you can receive 8,000 transactions from a client and if we",
    "start": "788920",
    "end": "794519"
  },
  {
    "text": "then reuse this wire schema for the dis schema we can write this one meeg request as is to the writerhead log plus",
    "start": "794519",
    "end": "801560"
  },
  {
    "text": "replicate the same in parallel to a backup machine so this gives crash consistency amortizes if sync very",
    "start": "801560",
    "end": "807480"
  },
  {
    "text": "nicely and gives you the best best performance when you use direct IO to do direct memory access to the dis so",
    "start": "807480",
    "end": "814519"
  },
  {
    "text": "direct IO is yes it's actually faster than Buffett IO when you do it right uh",
    "start": "814519",
    "end": "819800"
  },
  {
    "text": "and it's becoming more and more important also when you think about where network storage memory bandwidth",
    "start": "819800",
    "end": "825040"
  },
  {
    "text": "are going so this graph by Roland dryer I always had this feeling but I came across it recently uh it shows how",
    "start": "825040",
    "end": "831480"
  },
  {
    "text": "network storage and memory bandwidth have increased even just the last 3 years but what's interesting is not that",
    "start": "831480",
    "end": "838079"
  },
  {
    "text": "everything got faster everything did get faster network storage memory baners everything got faster but look at that",
    "start": "838079",
    "end": "844320"
  },
  {
    "text": "little flip um the relative ratio is completely flipped so just three years ago network was the bottleneck then",
    "start": "844320",
    "end": "851079"
  },
  {
    "text": "storage then memory so you burned memory bandwidth to make the most of your network and storage bandwidth you know",
    "start": "851079",
    "end": "856720"
  },
  {
    "text": "you had Bloom filters um today everything has inverted the bottleneck is now memory bandwidth uh so it's like",
    "start": "856720",
    "end": "863920"
  },
  {
    "text": "drinking from a firear but through a straw uh so this is an incredible time",
    "start": "863920",
    "end": "869399"
  },
  {
    "text": "in the history of database design I I haven't figured this out you know it's like gravity just inverted uh and this",
    "start": "869399",
    "end": "876480"
  },
  {
    "text": "is why we put so much effort into tiger beetle you know into how we work with memory so fixed size cach line Align",
    "start": "876480",
    "end": "882639"
  },
  {
    "text": "data structures little Indian is everywhere these days so we no longer wanted to burn memory bandwidth on",
    "start": "882639",
    "end": "888800"
  },
  {
    "text": "distalization on memory copies and this in turn avoids threshing the CPU cach uh",
    "start": "888800",
    "end": "894000"
  },
  {
    "text": "but most of all we wanted to invest in static memory allocation not the CCH technique but the principle of zero",
    "start": "894000",
    "end": "901279"
  },
  {
    "text": "memory allocations after startup so at startup we allocate everything we know that we need then at runtime as you run",
    "start": "901279",
    "end": "908040"
  },
  {
    "text": "tiger beetle there's no more maloc or free like no maloc no free it's not it's foren doesn't happen uh and the",
    "start": "908040",
    "end": "914759"
  },
  {
    "text": "motivation for this is really the second order effect that this brings so your memory layout is now handcrafted for",
    "start": "914759",
    "end": "921639"
  },
  {
    "text": "efficiency and locality of access uh so there's no waste no hidden runtime allocation latency no risk of global",
    "start": "921639",
    "end": "928480"
  },
  {
    "text": "allocation Panic if you push tle to the Limit and no risk of fragmentation uh",
    "start": "928480",
    "end": "934040"
  },
  {
    "text": "and because memory bandwidth is so important for where we felt systems programming was going if it was a choice",
    "start": "934040",
    "end": "939880"
  },
  {
    "text": "between C or rest and Zig you know between the last 30 years of systems",
    "start": "939880",
    "end": "945040"
  },
  {
    "text": "programming or investing in the next 30 Years you know then memory efficiency was really why we decided to invest in",
    "start": "945040",
    "end": "952800"
  },
  {
    "text": "Zig highly readable explicit language great for writing a database uh where",
    "start": "952800",
    "end": "958279"
  },
  {
    "text": "memory back bandwidth is more and more the bottleneck so after appending to the log with a minimum of memory bandwidth",
    "start": "958279",
    "end": "965160"
  },
  {
    "text": "uh the next step is to execute the transactions uh to apply them to our existing state using the architecture of",
    "start": "965160",
    "end": "971920"
  },
  {
    "text": "a replicated State machine uh so we take the same inputs we replay them in the",
    "start": "971920",
    "end": "976959"
  },
  {
    "text": "same order uh through the state machine on every machine uh to get the same state across the cluster it's a such a",
    "start": "976959",
    "end": "983240"
  },
  {
    "text": "very simple technique you've got a distributed log all your machines process it in the same order same",
    "start": "983240",
    "end": "989120"
  },
  {
    "text": "business logic same state uh finally we send a small reply back to the client this is kind of an interesting trick in",
    "start": "989120",
    "end": "995079"
  },
  {
    "text": "Tiger Bel because we assume success so that we only have to return error codes for the transactions that actually",
    "start": "995079",
    "end": "1000720"
  },
  {
    "text": "failed so you save 8 kilobytes on The Wire um and this is how tiger be processes 8,000 transactions in a single",
    "start": "1000720",
    "end": "1007759"
  },
  {
    "text": "query one database query um with four CIS calls four M copies and three",
    "start": "1007759",
    "end": "1012959"
  },
  {
    "text": "Network requests so do more with less uh however the biggest win with this",
    "start": "1012959",
    "end": "1018079"
  },
  {
    "text": "network protocol I mean these are really massive wins you know it could be 30,000 cisor or something like that but the",
    "start": "1018079",
    "end": "1023920"
  },
  {
    "text": "biggest win with this network protocol is that it eliminates the need to take 16,000 rollocks on accounts you know for",
    "start": "1023920",
    "end": "1031038"
  },
  {
    "text": "every transaction there's two accounts so if we understand that the oltp workload is business transactions then",
    "start": "1031039",
    "end": "1038400"
  },
  {
    "text": "we can see why a transactional workload can mean contention because if your",
    "start": "1038400",
    "end": "1043520"
  },
  {
    "text": "debit or credit is against a cold account then the contra account is almost always a hot account so I'm going",
    "start": "1043520",
    "end": "1049720"
  },
  {
    "text": "to explain this you know again um but just bear in mind you know in a in a general purpose o GP database like post",
    "start": "1049720",
    "end": "1057039"
  },
  {
    "text": "sqlite my SQL this would force rocks uh so for example you have a million",
    "start": "1057039",
    "end": "1062080"
  },
  {
    "text": "customers you can spread your updates across a million rows you can horizontally Shar no problem but all",
    "start": "1062080",
    "end": "1068080"
  },
  {
    "text": "your rights still need to be serialized through your bank account and you only have one or you have four um so the",
    "start": "1068080",
    "end": "1074480"
  },
  {
    "text": "effect of Roo then is is worse when you go horizontally distributed because when you Shard across machines um now",
    "start": "1074480",
    "end": "1081240"
  },
  {
    "text": "transactions have to talk across the network but they still bottleneck on the bank account which is on one Shard um",
    "start": "1081240",
    "end": "1088039"
  },
  {
    "text": "but you get this effect also in lgp databases you know as a single note but this compounds especially you know when",
    "start": "1088039",
    "end": "1093880"
  },
  {
    "text": "you consider how compute advances relative to network latency so there's a",
    "start": "1093880",
    "end": "1098919"
  },
  {
    "text": "law about Mo's law that the number of people predicting the death of M law",
    "start": "1098919",
    "end": "1104799"
  },
  {
    "text": "doubles every two years and I say this because if you look back 10 years ago",
    "start": "1104799",
    "end": "1110159"
  },
  {
    "text": "you know if you thought that Mo's law was slowing and I I think I I thought so too you know um you know you can",
    "start": "1110159",
    "end": "1117480"
  },
  {
    "text": "understand why someone might have wanted to scale compute horizontally you know however 10 years later Mo law is still",
    "start": "1117480",
    "end": "1124080"
  },
  {
    "text": "on track um I think this year or next we're going to get to um the M3 from",
    "start": "1124080",
    "end": "1129880"
  },
  {
    "text": "Apple with 3 nanometer process 100 billion transistors we're on track um and yeah a single core has advanced you",
    "start": "1129880",
    "end": "1137440"
  },
  {
    "text": "know since 2015 which is after all the cloud databases after all the horizontal SC you know",
    "start": "1137440",
    "end": "1143200"
  },
  {
    "text": "scalability strategies um it's single core is now an order of magnitude more",
    "start": "1143200",
    "end": "1149080"
  },
  {
    "text": "powerful but all this time the speed of light in fiber has remained constant you",
    "start": "1149080",
    "end": "1154520"
  },
  {
    "text": "know so if you bet on that if you bet on horizontal for compute compute is an exponential resource um but if your if",
    "start": "1154520",
    "end": "1162080"
  },
  {
    "text": "your CPU has to wait on a network request to A Shard to complete a transaction this is going to appear",
    "start": "1162080",
    "end": "1168080"
  },
  {
    "text": "slower and slower you know every two years as most law progresses so you don't want to make the CPU weight on the",
    "start": "1168080",
    "end": "1174480"
  },
  {
    "text": "network if you do if you if you make that decision it's going to be twice as costly in two years uh so what tiger",
    "start": "1174480",
    "end": "1180520"
  },
  {
    "text": "beetle does then is to keep the hot contentious transactional data local to every CPU core in the cluster so we",
    "start": "1180520",
    "end": "1187559"
  },
  {
    "text": "replicate it across all machines you can it's small um the principle again is separation of concerns because comput",
    "start": "1187559",
    "end": "1193919"
  },
  {
    "text": "and storage scale differently instead of coupling comput and storage scaling vertically or only horizontally you can",
    "start": "1193919",
    "end": "1201120"
  },
  {
    "text": "blend these techniques to scale diagonally so you go vertical with compute and with the hot storage",
    "start": "1201120",
    "end": "1206480"
  },
  {
    "text": "replicated across the cluster and then you go horizontal to colder remote storage object storage you know tearing",
    "start": "1206480",
    "end": "1213320"
  },
  {
    "text": "if necessary but we haven't needed to do this yet with tiger beetle so I'm going to speak to the first two um now that",
    "start": "1213320",
    "end": "1219480"
  },
  {
    "text": "we've looked at the network how to use it and when not to uh I want to look at tiger beetle storage engine so when",
    "start": "1219480",
    "end": "1225799"
  },
  {
    "text": "transactions execute through the state machine um the results of this execution go into the storage engine so you",
    "start": "1225799",
    "end": "1232960"
  },
  {
    "text": "transactions come off the wire execute the logic into the storage engine um into the inmemory component and then",
    "start": "1232960",
    "end": "1239760"
  },
  {
    "text": "they spill out the dis but this execution is interesting uh because as we execute um there's no IO going on",
    "start": "1239760",
    "end": "1247919"
  },
  {
    "text": "again where's law so the CPU levitates doesn't touch disk or network instead before execution we preach all data",
    "start": "1247919",
    "end": "1255320"
  },
  {
    "text": "dependencies um into memory from dis so they're already in memory when execution happens and then we",
    "start": "1255320",
    "end": "1260880"
  },
  {
    "text": "execute the transaction serially and it's all debit credit objects they're all monomorphic so the instruction cache",
    "start": "1260880",
    "end": "1267640"
  },
  {
    "text": "is hot and there are zero rocks um so the CPU becomes an Olympic sprinter that",
    "start": "1267640",
    "end": "1273279"
  },
  {
    "text": "you let loose on the 100 meters uh from here they insert spill out to dis and for this you have two main choices B",
    "start": "1273279",
    "end": "1279200"
  },
  {
    "text": "tree LSM tree uh B trees optimize for read heavy workloads at the expense of",
    "start": "1279200",
    "end": "1284320"
  },
  {
    "text": "random rights LSM trees optimize for write heavy workloads at the expense multiple reads to find an object but you",
    "start": "1284320",
    "end": "1292039"
  },
  {
    "text": "can always use caching you know to optimize those reads uh so the original Alm Tre paper was published by Neil 1996",
    "start": "1292039",
    "end": "1299960"
  },
  {
    "text": "uh and then a month later postris was born you know and so the three most popular oltp or ol GP databases they're",
    "start": "1299960",
    "end": "1308159"
  },
  {
    "text": "actually optimized more for read write o GP or read intensive olap they don't",
    "start": "1308159",
    "end": "1313679"
  },
  {
    "text": "actually have the right optimized lemetry engine which is what you want for ltp so this makes it difference for",
    "start": "1313679",
    "end": "1319200"
  },
  {
    "text": "example meter took um my SQL they swapped the engine for rock steb and",
    "start": "1319200",
    "end": "1324520"
  },
  {
    "text": "alry and they found that mice my rocks you know was 10 times more right efficient that's their phrase you know",
    "start": "1324520",
    "end": "1330600"
  },
  {
    "text": "from you know from that blog post 10 times more right efficient but even Rock TV is now you know more than 10 years",
    "start": "1330600",
    "end": "1337000"
  },
  {
    "text": "old so and most of the LSM research is since then it's recent so today you can leap frog and that's why if the best",
    "start": "1337000",
    "end": "1344480"
  },
  {
    "text": "time to plant an lism tree was 20 years ago I think the second best time is now so I want to show you a few LSM",
    "start": "1344480",
    "end": "1350600"
  },
  {
    "text": "techniques we've developed at tiger beetle uh for predictable performance when we talk with LSM reach researchers",
    "start": "1350600",
    "end": "1357000"
  },
  {
    "text": "for example at fourth in Creet uh they tell us um they routinely see you know",
    "start": "1357000",
    "end": "1362200"
  },
  {
    "text": "in their words 1 to 10c right stalls in existing alism trees so a client is",
    "start": "1362200",
    "end": "1367559"
  },
  {
    "text": "trying to make a request something goes wrong in the tree and it's a 1 to 10 second user Vis you know p100 uh so the",
    "start": "1367559",
    "end": "1375440"
  },
  {
    "text": "problem is that there's no endtoend control Loop between the client coming in and the background compaction work",
    "start": "1375440",
    "end": "1381159"
  },
  {
    "text": "that needs to keep up uh so if the engine can't keep up uh then it blocks client requests um so there's been a lot",
    "start": "1381159",
    "end": "1388039"
  },
  {
    "text": "of work in Rox TB to improve this but it's not a guarantee it's not a solv problem uh and that's because to fix it",
    "start": "1388039",
    "end": "1394480"
  },
  {
    "text": "compaction really needs to be able to predict how much work the next client",
    "start": "1394480",
    "end": "1399559"
  },
  {
    "text": "request will generate predict the future uh Without Limits you can't you can't predict the future so we wanted to",
    "start": "1399559",
    "end": "1405640"
  },
  {
    "text": "eliminate these right stalls we wanted to have a hard guarantee but because tiger beetle does have",
    "start": "1405640",
    "end": "1410880"
  },
  {
    "text": "limits on all work coming into the system uh we could design compaction to be just in time so compaction does just",
    "start": "1410880",
    "end": "1419320"
  },
  {
    "text": "enough work to be able to absorb the next client request and no more so it's choreographed you don't worry you just",
    "start": "1419320",
    "end": "1426320"
  },
  {
    "text": "need to get the big picture here of you know um something being choreographed uh",
    "start": "1426320",
    "end": "1431679"
  },
  {
    "text": "and I'll tell you what this is so we divide time into bars bars into beats and then each request and the",
    "start": "1431679",
    "end": "1436720"
  },
  {
    "text": "corresponding compaction in terms of CPU dis and memory it's spread out incrementally across these beats uh so",
    "start": "1436720",
    "end": "1443440"
  },
  {
    "text": "we think of this like GC you know and this is how you can move from stop the world to paste Jitter free compaction um",
    "start": "1443440",
    "end": "1451200"
  },
  {
    "text": "another technique is how to deal with the problem of using one tree for all your data uh if you store different",
    "start": "1451200",
    "end": "1457000"
  },
  {
    "text": "types and sizes of data in the same lism tree then you get this tug of war uh you know how you optimize the engine as",
    "start": "1457000",
    "end": "1463640"
  },
  {
    "text": "described in the r rum conjecture um by aanus idus Kahan and other",
    "start": "1463640",
    "end": "1469000"
  },
  {
    "text": "so the rum conjecture is that you can optimize for reads and wres but you pay",
    "start": "1469000",
    "end": "1474120"
  },
  {
    "text": "for it with more memory or space on disk pick any two of three formula U but I",
    "start": "1474120",
    "end": "1480000"
  },
  {
    "text": "think the context for the rum conjecture is you're storing everything in one tree trying to optimize the tree for all",
    "start": "1480000",
    "end": "1486200"
  },
  {
    "text": "workloads one tree and now you try to optimize for all workloads but what if this is not always the case could we",
    "start": "1486200",
    "end": "1492480"
  },
  {
    "text": "then push past the rum conjecture what if we broaden the model uh to assume",
    "start": "1492480",
    "end": "1497559"
  },
  {
    "text": "many trees instead of one and then we have each tree adapt to its individual workload to have workload awareness so",
    "start": "1497559",
    "end": "1505039"
  },
  {
    "text": "we go from rum to rumber like this um can we then find a more efficient pero Frontier so we found that if you store",
    "start": "1505039",
    "end": "1512480"
  },
  {
    "text": "different key value sizes in the same tree then you need to have length prefixes but writing these length",
    "start": "1512480",
    "end": "1518080"
  },
  {
    "text": "prefixes to disk it increases you know um right and space simplification you're burning more right bandwidth using more",
    "start": "1518080",
    "end": "1524559"
  },
  {
    "text": "space for example if you have many secondary indexes with values of 8 to 32 bytes um then a 32-bit length prefix",
    "start": "1524559",
    "end": "1532360"
  },
  {
    "text": "consumes 10 to 30% of right bandwidth and space overhead that's the 30% is a",
    "start": "1532360",
    "end": "1538120"
  },
  {
    "text": "lot you know however the worst part of putting all your data in one tree is that different key values have different",
    "start": "1538120",
    "end": "1544120"
  },
  {
    "text": "workload so half your data for example transactions might be immutable it's double entry but if you store these in",
    "start": "1544120",
    "end": "1550159"
  },
  {
    "text": "the same tree as your secondary indexes or your account balances you know you're compacting and churning your immutable",
    "start": "1550159",
    "end": "1555880"
  },
  {
    "text": "data again and again and again for no reason so when you mix your date it also becomes harder to find because you're",
    "start": "1555880",
    "end": "1561720"
  },
  {
    "text": "looking for a needle in a Hast stack of wood brick and straw what if we just had a a wood stack and a brick stack and a a",
    "start": "1561720",
    "end": "1568200"
  },
  {
    "text": "straw stack a hair stack um so the Insight then is not to miss the forest for the trees but to go from um an LSM",
    "start": "1568200",
    "end": "1574799"
  },
  {
    "text": "tree to an LSM Forest if you store disjoint data in in disjoint trees you",
    "start": "1574799",
    "end": "1579880"
  },
  {
    "text": "can optimize wres reads and memory you can auto tune according to kind if you have a tree for every type uh so for",
    "start": "1579880",
    "end": "1586880"
  },
  {
    "text": "example tiger beetles Forest is around 20 trees um this reduces read WR and space amp improves cach locality as well",
    "start": "1586880",
    "end": "1594120"
  },
  {
    "text": "because now you have everything tuned according to your access pattern so this is the second technique in tiger beetle",
    "start": "1594120",
    "end": "1601000"
  },
  {
    "text": "storage engine um the third derives from the fact that more scale demands",
    "start": "1601000",
    "end": "1608960"
  },
  {
    "text": "more durability so in a study with net app bover syndrome W medicine found that",
    "start": "1608960",
    "end": "1615960"
  },
  {
    "text": "commodity discs have a half a percent chance of of corruption or silent bet rot in a 2-year window at scale this",
    "start": "1615960",
    "end": "1622960"
  },
  {
    "text": "kind of thing becomes common so probability Theory you go from one dis to 100 start to expect a 50% chance of",
    "start": "1622960",
    "end": "1630080"
  },
  {
    "text": "running into compaction somewhere in your Fleet so W medison under Remy Andrea P so um they've done wonderful",
    "start": "1630080",
    "end": "1637360"
  },
  {
    "text": "storage fault research like this over the last 10 years um however SQL light",
    "start": "1637360",
    "end": "1642520"
  },
  {
    "text": "you know which was first released in 2000 before most of this work does not",
    "start": "1642520",
    "end": "1647960"
  },
  {
    "text": "add any redundancy to the database file for the purpose of detecting corruption or IO errors sqlite assumes that the",
    "start": "1647960",
    "end": "1654720"
  },
  {
    "text": "data it reads is exactly the same data that it previously wrote and postris and",
    "start": "1654720",
    "end": "1660640"
  },
  {
    "text": "MySQL have a similar crash consistency model that's what you call it crash consistency model so they aim to be",
    "start": "1660640",
    "end": "1666480"
  },
  {
    "text": "consistent in the event of power loss but they're not actually designed to recover from or even detect storage",
    "start": "1666480",
    "end": "1674320"
  },
  {
    "text": "faults and you can understand this uh you know because again much of the research destroy faults was done only",
    "start": "1674320",
    "end": "1680600"
  },
  {
    "text": "after these databases were designed but this can and does lead to data loss so 2018 um this became known as fsync get",
    "start": "1680600",
    "end": "1688840"
  },
  {
    "text": "but users found that post's handling of surprising fsync behavior in the Linux kernel the way that postris handled that",
    "start": "1688840",
    "end": "1696760"
  },
  {
    "text": "could actually accelerate what was an otherwise routine recoverable just a storage fault but it could accelerate",
    "start": "1696760",
    "end": "1704000"
  },
  {
    "text": "that into Data loss so just a temporary sector error and that could lead to dead loss um so post and my SQL were patched",
    "start": "1704000",
    "end": "1711720"
  },
  {
    "text": "for this uh to to panic rather and then recover from the log at startup but then",
    "start": "1711720",
    "end": "1716799"
  },
  {
    "text": "in 2020 W medison looked into it and they found that the fix was not enough",
    "start": "1716799",
    "end": "1721960"
  },
  {
    "text": "and this is very this is not well known uh so you know at startup when post",
    "start": "1721960",
    "end": "1727279"
  },
  {
    "text": "recovers the log it actually reads from the kernel page cach in memory it it doesn't read what was durably synced to",
    "start": "1727279",
    "end": "1734399"
  },
  {
    "text": "dis so it doesn't really know what's durable or not when it commits transactions um so the risk of data loss is",
    "start": "1734399",
    "end": "1740200"
  },
  {
    "text": "unfortunately still there um this is going to be fixed when post finishes adding support for direct a and that's",
    "start": "1740200",
    "end": "1747159"
  },
  {
    "text": "there's a lot of movement there coming into post even this year um so the third",
    "start": "1747159",
    "end": "1752960"
  },
  {
    "text": "storage technique in tigerle then is to move Beyond a crash consistency model",
    "start": "1752960",
    "end": "1758399"
  },
  {
    "text": "and to actually design for an explicit storage fault model to assume that that",
    "start": "1758399",
    "end": "1763919"
  },
  {
    "text": "storage faults do happen so you can expect Laten sector errors coruption or",
    "start": "1763919",
    "end": "1769240"
  },
  {
    "text": "even you know where the firmware or whatever file system will send your resal rights to the wrong sector or just",
    "start": "1769240",
    "end": "1775080"
  },
  {
    "text": "not even do iio at all so there are a myriad of detection and Recovery techniques that tigerle uses to solve",
    "start": "1775080",
    "end": "1782279"
  },
  {
    "text": "this model um for example to checkpoint the log ring buffer every time it wraps",
    "start": "1782279",
    "end": "1787679"
  },
  {
    "text": "um we do special read write quorums we treat the dis like a distributed system you know and we check for Quorum overlap",
    "start": "1787679",
    "end": "1794679"
  },
  {
    "text": "we use right and then we verify the rights we read it back again right verify techniques we store check sums",
    "start": "1794679",
    "end": "1800960"
  },
  {
    "text": "out of band so the parent knows the check sum of the child in case the the io to read the child is misdirected it's",
    "start": "1800960",
    "end": "1807200"
  },
  {
    "text": "a ZFS technique um and then we also have a small uh a second small writerhead log",
    "start": "1807200",
    "end": "1813159"
  },
  {
    "text": "so we have two righte head logs in tigerle the the small one is for metadata to enable tigerle to determine",
    "start": "1813159",
    "end": "1819240"
  },
  {
    "text": "you know whether the log is corrupt in the middle of the log because of corruption or if it's torn at the tail",
    "start": "1819240",
    "end": "1825519"
  },
  {
    "text": "because of power loss so as another example this is actual tiger beetle code it's a comment in the source it shows",
    "start": "1825519",
    "end": "1832720"
  },
  {
    "text": "how we enumerate all these kinds of of faults under the model um to see how",
    "start": "1832720",
    "end": "1837880"
  },
  {
    "text": "they influence our recovery at startup um and because it's a matrix the recovery actions can be generated",
    "start": "1837880",
    "end": "1843760"
  },
  {
    "text": "dynamically tested to be sure that that you know every case is handled so as you start to accept you know that disk",
    "start": "1843760",
    "end": "1849960"
  },
  {
    "text": "sectors do fail you also start to see another problem with existing engines and that's because the data file they",
    "start": "1849960",
    "end": "1856799"
  },
  {
    "text": "produce is it's not deterministic um what they produce on disk you know if a single dis sector fails on one machine",
    "start": "1856799",
    "end": "1864159"
  },
  {
    "text": "the data files in other machines are all different so you have to recover the whole data file from from another",
    "start": "1864159",
    "end": "1869880"
  },
  {
    "text": "machine and this can take hours or days you know gigabytes terabytes so to solve this tiger beetles just in time",
    "start": "1869880",
    "end": "1876480"
  },
  {
    "text": "compaction um is also deterministic so that the same log always produces the",
    "start": "1876480",
    "end": "1882600"
  },
  {
    "text": "exact same data file across every machine in the cluster um so the storage engine is determined istic what it",
    "start": "1882600",
    "end": "1888679"
  },
  {
    "text": "produces on dis um which is very unique you know but so now if you see that a 64",
    "start": "1888679",
    "end": "1895320"
  },
  {
    "text": "KOB block is corrupt that's all you need to transfer over the network um so at",
    "start": "1895320",
    "end": "1900480"
  },
  {
    "text": "this point I'm sure you're wondering okay you're on why not raid uh why not just put post on raid or sqlite on raid",
    "start": "1900480",
    "end": "1907559"
  },
  {
    "text": "and of course the answer is that if you're already replicating your data across three machines you know for a three time storage overhead then extra",
    "start": "1907559",
    "end": "1914880"
  },
  {
    "text": "local raid redundancy triples this now you 9x storage overhead but you also don't need to because you have Global",
    "start": "1914880",
    "end": "1921440"
  },
  {
    "text": "you know redundancy that you can tap into so it's more efficient to take your",
    "start": "1921440",
    "end": "1927039"
  },
  {
    "text": "storage engine and integrate it with your consensus protocol um then you can recover from local faults using your",
    "start": "1927039",
    "end": "1932919"
  },
  {
    "text": "Global redundancy you share and you can also share one log between the storage engine and consensus in a lot of systems",
    "start": "1932919",
    "end": "1939799"
  },
  {
    "text": "there's actually two logs so you you Haring your right bandwidth um if you can share the log you double your right",
    "start": "1939799",
    "end": "1946120"
  },
  {
    "text": "efficiency so these are all Techni in tiger beetle storage engine to solve right stalls push the limits of",
    "start": "1946120",
    "end": "1951720"
  },
  {
    "text": "performance past rum increase durability optimize recovery and these are all",
    "start": "1951720",
    "end": "1956919"
  },
  {
    "text": "integrated with the con consensus protocol so we've already looked at how we optimize the network um to process",
    "start": "1956919",
    "end": "1964200"
  },
  {
    "text": "8,000 transactions in one query we use the same technique to make consensus",
    "start": "1964200",
    "end": "1969240"
  },
  {
    "text": "just as cheap uh so instead of replicating transactions one by one through the consensus log a single entry",
    "start": "1969240",
    "end": "1975639"
  },
  {
    "text": "in the consensus log replicates 8,000 transactions one consensus commit 8,000",
    "start": "1975639",
    "end": "1982039"
  },
  {
    "text": "it's the same idea it's very powerful um and this is only one again one round trip to a backup to replicate optimal",
    "start": "1982039",
    "end": "1989320"
  },
  {
    "text": "because you need data on more than one machine for durability anyway so where consensus comes in is when you want to",
    "start": "1989320",
    "end": "1995639"
  },
  {
    "text": "use this redundancy not only for durability but also for high availability for automated failover when",
    "start": "1995639",
    "end": "2002639"
  },
  {
    "text": "your primary machine fails so it's not enough to have synchronous replication you also want automated failover and we",
    "start": "2002639",
    "end": "2008200"
  },
  {
    "text": "do this using um the pioneering replication and consensus protocol view stamp replication by Brian Oki Barber",
    "start": "2008200",
    "end": "2015279"
  },
  {
    "text": "lisov Jam caring uh so it was actually published a year before paas and revised",
    "start": "2015279",
    "end": "2020320"
  },
  {
    "text": "again two years before raft raft is almost exactly the same protocol as VSR names are changed but it missed out on",
    "start": "2020320",
    "end": "2027440"
  },
  {
    "text": "optimizations that lisov and Carling introduced in their 2012 vssr paper so if you haven't read it yet I think this",
    "start": "2027440",
    "end": "2034440"
  },
  {
    "text": "is the most intuitive of the consensus papers also more optimal which I'm going to we're going to go",
    "start": "2034440",
    "end": "2039519"
  },
  {
    "text": "into now so for example in raft you don't know ahead of time who the next primary will be if the primary current",
    "start": "2039519",
    "end": "2045760"
  },
  {
    "text": "leader crashes who's the next leader you don't know um whereas in VSR you do have a pretty good idea um because the",
    "start": "2045760",
    "end": "2052638"
  },
  {
    "text": "election of the new Primary in VSR is actually round robin uh each machine has what is called a view number um they",
    "start": "2052639",
    "end": "2059320"
  },
  {
    "text": "bump this number when a quorum of the cluster confirms that the old primary is down and then a simple modular tells you",
    "start": "2059320",
    "end": "2065960"
  },
  {
    "text": "who the new primary is that's conent ensus like I've just explained it to you thanks thanks to Brian Baris James cing",
    "start": "2065960",
    "end": "2072079"
  },
  {
    "text": "so simple but even more powerful because you've got more information encoded in the protocol so there's also no protocol",
    "start": "2072079",
    "end": "2079638"
  },
  {
    "text": "in raft actually to repair the log of what otherwise might be a perfect",
    "start": "2079639",
    "end": "2084679"
  },
  {
    "text": "candidate so raft can sometimes get stuck for example you have three machines replica zero on the left is",
    "start": "2084679",
    "end": "2091079"
  },
  {
    "text": "primary and then you've got two backups so leader and two followers but the classical terminology is always primary",
    "start": "2091079",
    "end": "2097000"
  },
  {
    "text": "and backup which is what we use so replica zero as the primary has three entries in the log um replica one has",
    "start": "2097000",
    "end": "2104040"
  },
  {
    "text": "three replica 2 only has two it hasn't got the latest um log entry and then",
    "start": "2104040",
    "end": "2109560"
  },
  {
    "text": "replica two crashes so raft here would have to elect replica 1 as primary and",
    "start": "2109560",
    "end": "2115760"
  },
  {
    "text": "this makes sense because replica 1 has a longer log than replica 2 it has more data however what if replica one has a",
    "start": "2115760",
    "end": "2122480"
  },
  {
    "text": "sector fault in the first entry of its log so in this scenario your rth clusters is actually stuck it has to",
    "start": "2122480",
    "end": "2129200"
  },
  {
    "text": "wait until replica zero recovers um whereas VSR is able to elect either",
    "start": "2129200",
    "end": "2134800"
  },
  {
    "text": "replica 1 or replica 2 and then transfer you know the missing log entries across",
    "start": "2134800",
    "end": "2141200"
  },
  {
    "text": "so in other words by limiting who can be primary raft doesn't fully utilize the global redundancy that you're paying for",
    "start": "2141200",
    "end": "2147359"
  },
  {
    "text": "as it could and at scale this matters you know um so rft's formal proof also",
    "start": "2147359",
    "end": "2152560"
  },
  {
    "text": "assumes stable storage but that the stable storage disc is perfect so there's no idea of storage faults um",
    "start": "2152560",
    "end": "2159520"
  },
  {
    "text": "whereas vssr can run only in memory so it's a very nice protocol for prototyping if if you're afraid of",
    "start": "2159520",
    "end": "2165440"
  },
  {
    "text": "working with the dis um vssr can also run with stable storage like raft which",
    "start": "2165440",
    "end": "2170800"
  },
  {
    "text": "is what we do with tiger beetle except the storage engine that we have can detect dis faults and cooperate with",
    "start": "2170800",
    "end": "2177160"
  },
  {
    "text": "vssr to recover so one of the ways we do this is by extending the consensus log",
    "start": "2177160",
    "end": "2182880"
  },
  {
    "text": "with a cryptographic hash chain of the check sums of our Ops that are going through consens so this means we can go",
    "start": "2182880",
    "end": "2189200"
  },
  {
    "text": "beyond draft to handle situations even where all machines have a corrupt log",
    "start": "2189200",
    "end": "2194800"
  },
  {
    "text": "but in different places so here we've got Ops one two and three corrupt across different machines raft you would the",
    "start": "2194800",
    "end": "2201440"
  },
  {
    "text": "cluster is lost there's no way to recover in terms of the ra protocol what",
    "start": "2201440",
    "end": "2206560"
  },
  {
    "text": "we do is we've got a check on from C back to B and then from B back to A's check on so tiger beetle can actually",
    "start": "2206560",
    "end": "2213640"
  },
  {
    "text": "Stitch this log back together and keep going um the hash chain also means that the primary doesn't need to have an op",
    "start": "2213640",
    "end": "2220280"
  },
  {
    "text": "on its own disc before it commits usually you know you append your disc replicate then you commit but you got to",
    "start": "2220280",
    "end": "2226319"
  },
  {
    "text": "wait for your disc what if the disc is slow this technique you don't have to wait for your disc um you can just go as",
    "start": "2226319",
    "end": "2232200"
  },
  {
    "text": "fast as the fastest two of three discs in your cluster um and then backups can also receive Ops out of order they don't",
    "start": "2232200",
    "end": "2239640"
  },
  {
    "text": "have to try and first catch up they can take the op from the primary say yes I",
    "start": "2239640",
    "end": "2244920"
  },
  {
    "text": "got this and then they'll catch up in the background whereas in raft normally they have to block the primary say wait",
    "start": "2244920",
    "end": "2250720"
  },
  {
    "text": "wait I've got a gap let me go and repair first and then I'll tell you it's okay keeps the client waiting so this",
    "start": "2250720",
    "end": "2256280"
  },
  {
    "text": "technique can also optimize backups that they give you know very fast a to the primary um so far I've only shown you",
    "start": "2256280",
    "end": "2262800"
  },
  {
    "text": "cases where raft can get stuck uh and that's only because it wasn't designed for storage faults um that's fine it",
    "start": "2262800",
    "end": "2269640"
  },
  {
    "text": "doesn't have a storage fault model um but again new research since raft was designed protocol aware recovery for",
    "start": "2269640",
    "end": "2276240"
  },
  {
    "text": "consensus based storage if you're runting a consensus protocol how do you do storage this is really the paper you",
    "start": "2276240",
    "end": "2281640"
  },
  {
    "text": "want to look at um alapan ganison ew medicine one best paper fast 2018 again",
    "start": "2281640",
    "end": "2288160"
  },
  {
    "text": "it's so so recent you know so we just didn't know this when when graft was designed uh but this shows how with raft",
    "start": "2288160",
    "end": "2294800"
  },
  {
    "text": "and paxos a single sector fault on one machine can actually just ruin your",
    "start": "2294800",
    "end": "2300280"
  },
  {
    "text": "whole cluster and cause global you know cluster data loss um it can propagate through the protocol for example if the",
    "start": "2300280",
    "end": "2307520"
  },
  {
    "text": "first op on replica one is corrupt we've seen this example um then its checkm",
    "start": "2307520",
    "end": "2312839"
  },
  {
    "text": "isn't going to validate and what typically happens at startup replica one will see oh this check some didn't",
    "start": "2312839",
    "end": "2318359"
  },
  {
    "text": "validate I must have been writing this and then the power went off again the crash consistency model and then replica",
    "start": "2318359",
    "end": "2324440"
  },
  {
    "text": "one will truncate its log all the way back to zero so you lose you lose all those committed transactions uh and",
    "start": "2324440",
    "end": "2330920"
  },
  {
    "text": "that's really because it's conflating the checkm error with the torn right after crash but actually that was just",
    "start": "2330920",
    "end": "2336599"
  },
  {
    "text": "corruption on dis which is a half% chance you know every two years um so this will erase",
    "start": "2336599",
    "end": "2343440"
  },
  {
    "text": "committed operations and you get split brain and and everything is messed up so in tarle we Implement protocol away",
    "start": "2343440",
    "end": "2349560"
  },
  {
    "text": "recovery and we ask the cluster to figure out well what is the correct action to take to recover from the",
    "start": "2349560",
    "end": "2355000"
  },
  {
    "text": "storage Vault um so I want to show you one more trick um that we're working on still everything I've shown you here you",
    "start": "2355000",
    "end": "2361359"
  },
  {
    "text": "know is in um we find tuning Our compaction pacing but everything is in",
    "start": "2361359",
    "end": "2366560"
  },
  {
    "text": "but I want to show you one more trick um and this is the Insight with consensus right normally you want to replicate an",
    "start": "2366560",
    "end": "2373400"
  },
  {
    "text": "OP across your cluster you wait for a quorum then you execute so you always replicate get Quorum execute but the",
    "start": "2373400",
    "end": "2380440"
  },
  {
    "text": "Insight is that 99% of the time your Ops are always going to get the Quorum it's",
    "start": "2380440",
    "end": "2386599"
  },
  {
    "text": "only if like the primary is down or some machines are down that you don't get the Quorum so 99% of the time why not just",
    "start": "2386599",
    "end": "2393760"
  },
  {
    "text": "execute let's let's aen to our Dis Let's replicate and let's execute through the state machine in parallel um we can",
    "start": "2393760",
    "end": "2401319"
  },
  {
    "text": "remove that right barrier um then we just wait we've executed we cach that",
    "start": "2401319",
    "end": "2407839"
  },
  {
    "text": "result and when we do get the Corum then we apply it so basically you're getting a head start on your state machine",
    "start": "2407839",
    "end": "2413720"
  },
  {
    "text": "execution um and then you only throw the execution away if the op actually doesn't receive Quorum so you get like a",
    "start": "2413720",
    "end": "2420839"
  },
  {
    "text": "a round trip time of Head Start but this is really powerful because this is basically saying consensus is now 100%",
    "start": "2420839",
    "end": "2427880"
  },
  {
    "text": "free like there you know whether you're doing single node or cluster doesn't matter because that round trip we're",
    "start": "2427880",
    "end": "2434000"
  },
  {
    "text": "we're using it to execute CPU so M's law this you know today it's 15% win two",
    "start": "2434000",
    "end": "2440720"
  },
  {
    "text": "years time it's a 30% win four years time you know eight years time it then",
    "start": "2440720",
    "end": "2446280"
  },
  {
    "text": "your your CPU is even free um so our you know it's been three years since the start of tiger beetle production release",
    "start": "2446280",
    "end": "2452760"
  },
  {
    "text": "around the corner um with the design decisions I've showed you tiger beetle",
    "start": "2452760",
    "end": "2457880"
  },
  {
    "text": "is able to do today a 988 th000 transactions per second we're going for",
    "start": "2457880",
    "end": "2463119"
  },
  {
    "text": "a million we should get there we've got some more techniques to come um and that's on nvme with primary indexes",
    "start": "2463119",
    "end": "2470040"
  },
  {
    "text": "everything you need to do data change data capture um a million a second um if we then index all columns in tiger",
    "start": "2470040",
    "end": "2476839"
  },
  {
    "text": "beetle you know so we can do very predictable multi-attribute queries with zigzag merge join which is fantastic I",
    "start": "2476839",
    "end": "2483599"
  },
  {
    "text": "actually think post and myql don't have zigzag merge joins so it's something something that's newer again but it's a",
    "start": "2483599",
    "end": "2490040"
  },
  {
    "text": "great way to do multi-attribute queries um also in the works but if we add 20",
    "start": "2490040",
    "end": "2495119"
  },
  {
    "text": "secondary indexes so we add a lot of indexes now um then tigerle is still able to do 200 to 500,000 transactions",
    "start": "2495119",
    "end": "2502920"
  },
  {
    "text": "per second business transactions uh and that's again 20 secondary indexes for",
    "start": "2502920",
    "end": "2507960"
  },
  {
    "text": "nice multi-attribute scans and the P99 is under 100 milliseconds um more important than",
    "start": "2507960",
    "end": "2515400"
  },
  {
    "text": "performance is safety um how can we hope to be safer than things that were you know 30 years tried and tested have to",
    "start": "2515400",
    "end": "2522240"
  },
  {
    "text": "be a guru to get this right and I know a guru or two we're certainly not so instead we adopted NASA's power of 10",
    "start": "2522240",
    "end": "2529079"
  },
  {
    "text": "rules for safety critical code uh it's not a standard you see very often um but",
    "start": "2529079",
    "end": "2534400"
  },
  {
    "text": "it means that there's 4,000 assertions in Tiger be as it runs it's checking itself uh there limits also on all the",
    "start": "2534400",
    "end": "2541200"
  },
  {
    "text": "resources memory like I've showed you but even concurrency even our our while Loops we put a counter on so everything",
    "start": "2541200",
    "end": "2548920"
  },
  {
    "text": "is worked out we know how much resource any algorithm will use in terms of memory especially um so you get a piece",
    "start": "2548920",
    "end": "2555160"
  },
  {
    "text": "of software that has it's like Rock Solid it's got a well-defined shape you can depend on the shape it's not going",
    "start": "2555160",
    "end": "2560920"
  },
  {
    "text": "to change and all these limits are known statically at compile time zig's got amazing compile time obviously um but",
    "start": "2560920",
    "end": "2568280"
  },
  {
    "text": "finally we designed tiger not only as a distributed database but as a deterministic distributor database so",
    "start": "2568280",
    "end": "2575400"
  },
  {
    "text": "this means then you can take this whole database cluster you can run it in a simulated world that's deterministic you",
    "start": "2575400",
    "end": "2583280"
  },
  {
    "text": "can simulate different latencies of network storage different bandwidths you can inject all kinds of faults very high",
    "start": "2583280",
    "end": "2590319"
  },
  {
    "text": "levels of storage faults we we do that um and then you can verify correctness",
    "start": "2590319",
    "end": "2596319"
  },
  {
    "text": "and liveness of the consensus protocol of the storage engine up to the theoretical limits so you can say look",
    "start": "2596319",
    "end": "2601680"
  },
  {
    "text": "I'm going to corre corrupt every log on every replica in different places can you Stitch that log together can you",
    "start": "2601680",
    "end": "2608000"
  },
  {
    "text": "keep going or do you shut down prematurely um and because this testing is also uh completely deterministic you",
    "start": "2608000",
    "end": "2614839"
  },
  {
    "text": "can replay bugs from a single seed um and then you get this incredible rapid debug velocity um but the most valuable",
    "start": "2614839",
    "end": "2622680"
  },
  {
    "text": "thing with simulation testing and obviously this is inspired by Foundation DB who've really pioneered this Our",
    "start": "2622680",
    "end": "2628760"
  },
  {
    "text": "Heroes um the most valuable thing with this is that you can actually speed up time time itself is simulated so you",
    "start": "2628760",
    "end": "2636280"
  },
  {
    "text": "just speed it up a while true Loop tick that secondhand while true um you know in the simulated world so for example if",
    "start": "2636280",
    "end": "2643079"
  },
  {
    "text": "you run the tiger beetle simulator on your in your terminal just for 3.3 seconds you've got the equivalent of 39",
    "start": "2643079",
    "end": "2649319"
  },
  {
    "text": "minutes of of you know real test time on average you run for two days you get two years of test time and we run 10 of",
    "start": "2649319",
    "end": "2656359"
  },
  {
    "text": "these simulators 24/7 just burning CPU um to put years on the clock you know",
    "start": "2656359",
    "end": "2662359"
  },
  {
    "text": "and this is actually verifying the consensus the actual code the ual",
    "start": "2662359",
    "end": "2667400"
  },
  {
    "text": "implementation is verified like this and it's all virtual so you're running you know a whole cluster of real tigy Beetle",
    "start": "2667400",
    "end": "2674240"
  },
  {
    "text": "code um in your terminal all the io the time is all simulated but what if you know this also",
    "start": "2674240",
    "end": "2681079"
  },
  {
    "text": "means this is a whole simulated world what if we can transplant this world what if you know we could if we wanted",
    "start": "2681079",
    "end": "2687400"
  },
  {
    "text": "to you know you could do something fun like you know you could compile this to WM and you could run this whole",
    "start": "2687400",
    "end": "2693079"
  },
  {
    "text": "simulation in your browser also or um and of course this this is what we went and did um so I want to this is what I",
    "start": "2693079",
    "end": "2700319"
  },
  {
    "text": "want to leave with you now um you're welcome to go go to this yourself later sim. tiger.com",
    "start": "2700319",
    "end": "2707640"
  },
  {
    "text": "and um I was walking on Golden Gate yesterday I thought well we've got this",
    "start": "2707640",
    "end": "2713960"
  },
  {
    "text": "simulated world what if we can take this cluster of tiger beetles running a real tiger beetle code and just like teleport",
    "start": "2713960",
    "end": "2719760"
  },
  {
    "text": "them onto Golden Gate Bridge uh so we of course this is what we went and did as a",
    "start": "2719760",
    "end": "2725079"
  },
  {
    "text": "team um let's see if we get some sound so now we're going to see no Faults at",
    "start": "2725079",
    "end": "2731000"
  },
  {
    "text": "all no processes crash rep you know networks's perfect storage perfect Golden Gate",
    "start": "2731000",
    "end": "2737000"
  },
  {
    "text": "Bridge traffic has stopped the tiger beetles descend you can see who the Captain America is the",
    "start": "2737000",
    "end": "2744400"
  },
  {
    "text": "leader and the client request at the top they're sending the the requests",
    "start": "2744400",
    "end": "2750240"
  },
  {
    "text": "in cluster started this is all real tiger beetle code The Beatles don't even",
    "start": "2750240",
    "end": "2756319"
  },
  {
    "text": "know that there at cuon on Golden Gate Bridge this is like real Target code all VSR",
    "start": "2756319",
    "end": "2763200"
  },
  {
    "text": "consensus and you can see the replication happening and the A and the replies going back to",
    "start": "2763200",
    "end": "2769920"
  },
  {
    "text": "clients all the faults on the left everything is",
    "start": "2769920",
    "end": "2775280"
  },
  {
    "text": "perfect and I think we should stop there because this is a live demo lower demos let's let's just leave it at that oh",
    "start": "2776200",
    "end": "2782280"
  },
  {
    "text": "we're out of time okay uh shall we stop anyone want",
    "start": "2782280",
    "end": "2787520"
  },
  {
    "text": "to go further Next Level okay so this is now red desert",
    "start": "2787520",
    "end": "2793839"
  },
  {
    "text": "Andy Pavlo is in the bath doing his bath lecture that was famous uh here we've got Network faults so we're going to",
    "start": "2793839",
    "end": "2799599"
  },
  {
    "text": "mess with the network drop Network packets on the ground partition the beetles in that mission impossible five",
    "start": "2799599",
    "end": "2806200"
  },
  {
    "text": "glass box um and you can see the cluster is now starting to do you know leader",
    "start": "2806200",
    "end": "2811839"
  },
  {
    "text": "elections the primary is you also if you look at the primary you can see it's going round robin cuz it's F on Robin so",
    "start": "2811839",
    "end": "2819319"
  },
  {
    "text": "it's moving clockwise around the circle if and you can see the one that holds the helmet when it's orange is the",
    "start": "2819319",
    "end": "2826400"
  },
  {
    "text": "next primary um and if you want uh let me see",
    "start": "2826400",
    "end": "2834520"
  },
  {
    "text": "we added a few fun tools here so let's find the primary which",
    "start": "2834520",
    "end": "2840520"
  },
  {
    "text": "will be this one it's this is quite a hard game to play okay cuz they changed they automatically fell over so fast uh",
    "start": "2840520",
    "end": "2848599"
  },
  {
    "text": "let's okay there's our primary wait we will we will",
    "start": "2848599",
    "end": "2854680"
  },
  {
    "text": "succeed there we go okay and you can crash it and then watch watch it recover",
    "start": "2854680",
    "end": "2862880"
  },
  {
    "text": "um let's move on because this is radioactive so how does",
    "start": "2863079",
    "end": "2869960"
  },
  {
    "text": "your database do if you just corrupt the disc you know 8% of reads you corrupt them you every machine is writing to dis",
    "start": "2869960",
    "end": "2876319"
  },
  {
    "text": "and you corrupt 9% of the time let's just do that because it's a simulation see what happens um and we found so many",
    "start": "2876319",
    "end": "2885160"
  },
  {
    "text": "bugs in our Cod like this um so now we're actually exercising the whole storage fault",
    "start": "2885160",
    "end": "2891359"
  },
  {
    "text": "model and we zap the tiger beetles with cosmic",
    "start": "2891359",
    "end": "2896400"
  },
  {
    "text": "rays and let's see what happens",
    "start": "2901680",
    "end": "2908760"
  },
  {
    "text": "and the simulator is testing you know strict cability just like Jepson would but it does it in real time not after",
    "start": "2919720",
    "end": "2925160"
  },
  {
    "text": "the fact uh and you can see we've got different latencies simulator different pack loss um different read and right",
    "start": "2925160",
    "end": "2932480"
  },
  {
    "text": "corruption 8 % um and everything is working otherwise the simulator would crash uh uh so let's",
    "start": "2932480",
    "end": "2940839"
  },
  {
    "text": "do now if you're a fan of duck DB there's a little Easter egg if you click that",
    "start": "2940839",
    "end": "2947760"
  },
  {
    "text": "duck uh you can engage duck mode and see if",
    "start": "2947760",
    "end": "2952920"
  },
  {
    "text": "oltp can survive olap which it's not easy to do but Tagle",
    "start": "2952920",
    "end": "2961720"
  },
  {
    "text": "can do it uh we put this in there just for our friends there dub um but you can",
    "start": "2961720",
    "end": "2968599"
  },
  {
    "text": "also do a bit of lightning uh is very violent yeah but",
    "start": "2968599",
    "end": "2975280"
  },
  {
    "text": "yeah tiger beetle survives and this is just thanks to Foundation DB what you can do you know if you simulate",
    "start": "2975280",
    "end": "2981640"
  },
  {
    "text": "everything deterministically put all your faults in um and that's that folks again so",
    "start": "2981640",
    "end": "2988200"
  },
  {
    "text": "nice to be with you here today and um yeah looking forward to to that production release of",
    "start": "2988200",
    "end": "2995640"
  },
  {
    "text": "tar",
    "start": "2995640",
    "end": "2998640"
  },
  {
    "text": "[Music]",
    "start": "3005050",
    "end": "3010499"
  }
]
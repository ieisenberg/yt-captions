[
  {
    "start": "0",
    "end": "75000"
  },
  {
    "text": "[Music]",
    "start": "680",
    "end": "8549"
  },
  {
    "text": "hello everybody um so this morning we had a really great talk on differentiable programming",
    "start": "15040",
    "end": "22640"
  },
  {
    "text": "and since everybody loves ml and ai i thought we should probably",
    "start": "22640",
    "end": "28560"
  },
  {
    "text": "look at what other research topics or what what's differentiable programming and what other research topics are out",
    "start": "28640",
    "end": "34000"
  },
  {
    "text": "there that will improve ml and ai and for this purpose i've invited this",
    "start": "34000",
    "end": "40320"
  },
  {
    "text": "really illustrious panel here um maybe we'll kick things off by uh and",
    "start": "40320",
    "end": "45920"
  },
  {
    "text": "should do maybe you can introduce yourselves and what you're why you're here uh what your connection",
    "start": "45920",
    "end": "51360"
  },
  {
    "text": "to ml is so on the screen i read you the one on the left so maybe you can start off",
    "start": "51360",
    "end": "57360"
  },
  {
    "text": "all right hi everyone i'm irene gee um i gave this talk i gave the talk this morning on",
    "start": "57360",
    "end": "62559"
  },
  {
    "text": "differentiable programming in kotlin um it's about the framework that we're building",
    "start": "62559",
    "end": "67760"
  },
  {
    "text": "at facebook and specifically specifically on the team i work on the static shape checker",
    "start": "67760",
    "end": "75680"
  },
  {
    "start": "75000",
    "end": "130000"
  },
  {
    "text": "cool uh kendrick yeah i'm jendrick i'm cto of nuxit and we're deploying a lot",
    "start": "75840",
    "end": "82640"
  },
  {
    "text": "of machine learning into production so i originally started in data science now",
    "start": "82640",
    "end": "88080"
  },
  {
    "text": "i'm going more and more into the ops part so you'll as well have the opportunity to join us next week for a",
    "start": "88080",
    "end": "95520"
  },
  {
    "text": "really mlop's heavy ml track well we'll see each other hopefully",
    "start": "95520",
    "end": "102240"
  },
  {
    "text": "cool and alana hi i'm alana um i work with irene",
    "start": "102240",
    "end": "107520"
  },
  {
    "text": "actually on differential programming um i'm specifically focused on",
    "start": "107520",
    "end": "114399"
  },
  {
    "text": "the performance of our uh of our tool so making sure we can train goals quickly",
    "start": "114399",
    "end": "120560"
  },
  {
    "text": "and uh prior to that i worked on a compiler team at a",
    "start": "120560",
    "end": "125680"
  },
  {
    "text": "hardware startup for ai exciting um",
    "start": "125680",
    "end": "131280"
  },
  {
    "start": "130000",
    "end": "195000"
  },
  {
    "text": "maybe for i don't know if people have seen the talk yet",
    "start": "131280",
    "end": "136319"
  },
  {
    "text": "that's the case why not but maybe irene maybe we can just give a quick elevator pitch of what",
    "start": "136319",
    "end": "142720"
  },
  {
    "text": "differential programming is and why why it's different than other approaches",
    "start": "142720",
    "end": "148480"
  },
  {
    "text": "right so i would say with our framework we're trying to um well",
    "start": "148480",
    "end": "154160"
  },
  {
    "text": "so to back up a lot of the popular frameworks out there that many of you might have heard of jax tensorflow pi",
    "start": "154160",
    "end": "160239"
  },
  {
    "text": "board those are um those are really great for traditional",
    "start": "160239",
    "end": "166160"
  },
  {
    "text": "machine learning model use cases but once you sort of step out of those boundaries um you don't really do so",
    "start": "166160",
    "end": "173200"
  },
  {
    "text": "well in terms of performance and usability so what we're trying to do with differentiable programming in",
    "start": "173200",
    "end": "178560"
  },
  {
    "text": "kotlin is we're trying to do um we're taking a compiler-aware approach",
    "start": "178560",
    "end": "184480"
  },
  {
    "text": "to this problem and we're trying to support these other use cases that aren't so that are outside of the traditional",
    "start": "184480",
    "end": "191519"
  },
  {
    "text": "machine learning realm cool",
    "start": "191519",
    "end": "197040"
  },
  {
    "start": "195000",
    "end": "276000"
  },
  {
    "text": "alana what's your you mentioned you work on performance yeah so um",
    "start": "197040",
    "end": "204080"
  },
  {
    "text": "i guess um we're so actually",
    "start": "204080",
    "end": "210080"
  },
  {
    "text": "it's really interesting i won't go to and do it but um so",
    "start": "210080",
    "end": "215200"
  },
  {
    "text": "we'll give us we're just in college give us details so we're using kotlin which is which",
    "start": "215200",
    "end": "220239"
  },
  {
    "text": "runs on it so it can it can compile to a number of different backgrounds but its primary backend is the jvm",
    "start": "220239",
    "end": "226400"
  },
  {
    "text": "um which i don't think i guess there's other projects that have worked on uh machine",
    "start": "226400",
    "end": "232640"
  },
  {
    "text": "learning on the jvm um but and of course there's um",
    "start": "232640",
    "end": "237680"
  },
  {
    "text": "there's spark but machine learning on the jvm in the sense",
    "start": "237680",
    "end": "243760"
  },
  {
    "text": "of like training resnet is kind of not really a",
    "start": "243760",
    "end": "249120"
  },
  {
    "text": "a big thing that people do i think a lot of people stick to python sequels plus and and that stack so um",
    "start": "249120",
    "end": "257040"
  },
  {
    "text": "so the the interesting stuff that i get to work on is like okay how do i work with garbage collection and memory",
    "start": "257040",
    "end": "264080"
  },
  {
    "text": "management in the jvm and how do i make that work with these c plus libraries that are",
    "start": "264080",
    "end": "269919"
  },
  {
    "text": "especially the intel ones and then also cuda that that are super optimized for running things like convolutions",
    "start": "269919",
    "end": "276639"
  },
  {
    "start": "276000",
    "end": "345000"
  },
  {
    "text": "so it's mainly is it getting the data across to the native code or is it sort of taming the garbage collector or stuff",
    "start": "276639",
    "end": "283120"
  },
  {
    "text": "like that it's a combination so um so in in",
    "start": "283120",
    "end": "289199"
  },
  {
    "text": "for one thing in the jvm you can't get a big array of uninitialized data",
    "start": "289199",
    "end": "295120"
  },
  {
    "text": "you have to zero out that you know because the jvm is like we're memory safe we're not going to give you uninitialized data because we're and",
    "start": "295120",
    "end": "301360"
  },
  {
    "text": "that's that's a really great thing about the jvm but when you get into the performance of some of these ops you're like no i just just give me the array",
    "start": "301360",
    "end": "308320"
  },
  {
    "text": "like i i don't have time to zero it and i don't need a zero",
    "start": "308320",
    "end": "313759"
  },
  {
    "text": "things like that interesting yeah all the memory saved in the jvm is sort of fighting you there i",
    "start": "313919",
    "end": "319520"
  },
  {
    "text": "guess it's it's it's it's good and bad so it's something to work with but it's",
    "start": "319520",
    "end": "325520"
  },
  {
    "text": "something that like is obviously super useful to our users because if users had to write it had to do the",
    "start": "325520",
    "end": "332080"
  },
  {
    "text": "level of control that um you know one has to deal with in c plus it it just gets in the way of of",
    "start": "332080",
    "end": "338800"
  },
  {
    "text": "training the model of doing what you're trying to do right right um",
    "start": "338800",
    "end": "345440"
  },
  {
    "start": "345000",
    "end": "420000"
  },
  {
    "text": "i guess the question is so um so all the training and",
    "start": "346080",
    "end": "351280"
  },
  {
    "text": "is it it's it's mainly used for training right not for interference uh differentiable programming or your calling library",
    "start": "351280",
    "end": "359919"
  },
  {
    "text": "um i've mostly been focused on performance of training as a whole right now i think",
    "start": "359919",
    "end": "366160"
  },
  {
    "text": "inference is kind of a what's the right way to say it",
    "start": "366160",
    "end": "372880"
  },
  {
    "text": "i think there are tools that are yeah yeah it's something to itself and i think there are other tools that are",
    "start": "372880",
    "end": "378319"
  },
  {
    "text": "actually pretty good at it um for example um like if if you're",
    "start": "378319",
    "end": "384639"
  },
  {
    "text": "if you have in so training is more of like a i want to iterate quickly um like",
    "start": "384639",
    "end": "389680"
  },
  {
    "text": "i want to make a change and i want to um and i want to see if my model if my loss decreases",
    "start": "389680",
    "end": "394960"
  },
  {
    "text": "versus if you're doing inference you maybe have more time to just sort of uh like",
    "start": "394960",
    "end": "401280"
  },
  {
    "text": "take what you've trained and and feed it to an optimizer and let that run for like five hours",
    "start": "401280",
    "end": "407120"
  },
  {
    "text": "before you before you put that in production um and so um",
    "start": "407120",
    "end": "412639"
  },
  {
    "text": "while we might be interested in that later i haven't i haven't i haven't personally looked at that yet",
    "start": "412639",
    "end": "419599"
  },
  {
    "text": "so again drake um i think you're you were not familiar with uh differentiable programming",
    "start": "419759",
    "end": "425759"
  },
  {
    "start": "420000",
    "end": "448000"
  },
  {
    "text": "before what are you using now is it did you use like stoneage tools uh to build ml or",
    "start": "425759",
    "end": "433440"
  },
  {
    "text": "yeah i use pen and paper and then i started",
    "start": "433840",
    "end": "438240"
  },
  {
    "text": "like an iteration takes me around 10 years um depending on that size",
    "start": "439680",
    "end": "445120"
  },
  {
    "text": "um i started with tensorflow um and then",
    "start": "445120",
    "end": "451039"
  },
  {
    "text": "pytorch came out which is i think already five or six years ago it's it's",
    "start": "451039",
    "end": "456319"
  },
  {
    "text": "a long time ago um but that was already like a humongous",
    "start": "456319",
    "end": "461840"
  },
  {
    "text": "jump in tech because it gave you a lot of reusability which i really liked",
    "start": "461840",
    "end": "467039"
  },
  {
    "text": "because you started having the modules and if someone wrote a module",
    "start": "467039",
    "end": "472400"
  },
  {
    "text": "on your network and you wanted to reuse it well you just added the class or the object instantiated the class edit it to",
    "start": "472400",
    "end": "480160"
  },
  {
    "text": "your object and you were like well okay i can just reuse the network and was so easy well under tensorflow you yeah i",
    "start": "480160",
    "end": "487680"
  },
  {
    "text": "mean basically you started searching the index for the weights of the convolutional layer out of this",
    "start": "487680",
    "end": "493599"
  },
  {
    "text": "humongous weight file and you were like um not really happy about",
    "start": "493599",
    "end": "499039"
  },
  {
    "text": "doing that all the time um i really stuck with pytorch since then i",
    "start": "499039",
    "end": "505039"
  },
  {
    "text": "always wanted to try tensorflow 2. i never had the time for it and never had the urge to do it because it was just",
    "start": "505039",
    "end": "512159"
  },
  {
    "text": "like yeah i really like the integration between python and pytorch",
    "start": "512159",
    "end": "517518"
  },
  {
    "text": "i definitely want to try kotlin at one point because it makes my life easier when arguing",
    "start": "517519",
    "end": "523599"
  },
  {
    "text": "with my co-founder about all the cloud builds because python is definitely not so",
    "start": "523599",
    "end": "529839"
  },
  {
    "text": "efficient when it comes to comes to resource usage um but yeah in the end you always have this",
    "start": "529839",
    "end": "537519"
  },
  {
    "text": "trade-off between like time it takes me to write it in kotlin and time to write it in python and then the cloud bill and",
    "start": "537519",
    "end": "544640"
  },
  {
    "text": "most of the time at least in small companies you end up with saying well my time is more valuable than the money i",
    "start": "544640",
    "end": "550080"
  },
  {
    "text": "throw at the cloud provider for giving me one more note while i think at facebook that's a",
    "start": "550080",
    "end": "555680"
  },
  {
    "text": "different story if you have the number of data scientists that facebook has or the number of models you",
    "start": "555680",
    "end": "562240"
  },
  {
    "text": "try to train but yeah not pen and paper anymore",
    "start": "562240",
    "end": "567600"
  },
  {
    "text": "so you also mentioned that you are really focusing on bringing models to production are you also using pie torch",
    "start": "568320",
    "end": "574800"
  },
  {
    "text": "for that um yes um so currently i still use pie torch for that",
    "start": "574800",
    "end": "581680"
  },
  {
    "start": "575000",
    "end": "648000"
  },
  {
    "text": "i mean you can get it a lot faster but just go to going to 16 bit floating points",
    "start": "581680",
    "end": "588880"
  },
  {
    "text": "and most our models are so small that that is okay from the response time i",
    "start": "588880",
    "end": "594880"
  },
  {
    "text": "mean given all the requests catching i mean you get a http request and normally",
    "start": "594880",
    "end": "600240"
  },
  {
    "text": "the time from the person asking you the question until it reaches your server is already so long that they don't really",
    "start": "600240",
    "end": "606800"
  },
  {
    "text": "realize that your model takes 10 milliseconds more um but yeah if you go to bigger models i",
    "start": "606800",
    "end": "613760"
  },
  {
    "text": "mean you can do quantization or some other things to get it um run faster or",
    "start": "613760",
    "end": "619680"
  },
  {
    "text": "use tensor rt which i tried two years ago and never touched again because it was such a pain to build everything in c",
    "start": "619680",
    "end": "626880"
  },
  {
    "text": "plus plus um but and that's that's why i meant is its whole own story because each",
    "start": "626880",
    "end": "633920"
  },
  {
    "text": "model you can just like i mean you can start doing pruning and then well you",
    "start": "633920",
    "end": "638959"
  },
  {
    "text": "can make a doctor thesis out of optimizing this one model [Laughter]",
    "start": "638959",
    "end": "647459"
  },
  {
    "start": "648000",
    "end": "688000"
  },
  {
    "text": "uh you have a question here uh maybe i'll just work some off here um",
    "start": "648800",
    "end": "655360"
  },
  {
    "text": "a few questions [Music] i guess the choice of kotlin is is one",
    "start": "655519",
    "end": "662160"
  },
  {
    "text": "question and i think you aren't uh i really answered that in your talk that it's because of the compiler infrastructure",
    "start": "662160",
    "end": "668720"
  },
  {
    "text": "and stuff like that i think that's that's the reason right yeah yeah so i mean one big reason is is",
    "start": "668720",
    "end": "674959"
  },
  {
    "text": "also just the performance and kotlin being a jbm language and um another big",
    "start": "674959",
    "end": "680720"
  },
  {
    "text": "one is the compiler the static compilation aspect and also the static typing",
    "start": "680720",
    "end": "688920"
  },
  {
    "start": "688000",
    "end": "715000"
  },
  {
    "text": "yeah it's interesting i think that was also um one of the big arguments for swift for",
    "start": "689120",
    "end": "694959"
  },
  {
    "text": "tensorflow the the static typing in in swift compared to python and static",
    "start": "694959",
    "end": "701760"
  },
  {
    "text": "compilation rather than having to carry around the python interpreter and stuff like that",
    "start": "701760",
    "end": "708240"
  },
  {
    "text": "let's see it's another question uh i think there's a question",
    "start": "711279",
    "end": "717040"
  },
  {
    "text": "maybe from for atlanta um in regards to the ml and jvm performance if you consider it off heap",
    "start": "717040",
    "end": "723440"
  },
  {
    "text": "memory which heap off of the jvm heap c plus plus",
    "start": "723440",
    "end": "731360"
  },
  {
    "text": "uh well i guess off heap in the sense of not on the object heap of the object but like use i guess unsafe or",
    "start": "731360",
    "end": "738240"
  },
  {
    "text": "something like that to allocate a big buffer um",
    "start": "738240",
    "end": "744760"
  },
  {
    "text": "that yes i haven't that has been on the to-do list actually for a little while",
    "start": "747519",
    "end": "753040"
  },
  {
    "text": "oh okay um that's that's what's happening for uh the prototype gpu support that i have",
    "start": "753040",
    "end": "759360"
  },
  {
    "text": "right now um you know it has the memory has to live on the gpu so um we are",
    "start": "759360",
    "end": "764639"
  },
  {
    "text": "doing that but um yeah also like i i i'm guessing what",
    "start": "764639",
    "end": "770320"
  },
  {
    "text": "is meant is sort of is wrapping in uh float buffers to expose to java i haven't",
    "start": "770320",
    "end": "776000"
  },
  {
    "text": "tried that um that is another thing to try",
    "start": "776000",
    "end": "781760"
  },
  {
    "start": "780000",
    "end": "868000"
  },
  {
    "text": "um maybe you can actually um talking about the gpus what's the story with um",
    "start": "781760",
    "end": "788079"
  },
  {
    "text": "hardware if you write your code in kotlin",
    "start": "788079",
    "end": "793360"
  },
  {
    "text": "how much can you offload to fancy pens hardware",
    "start": "793360",
    "end": "797839"
  },
  {
    "text": "well so it depends on the software available",
    "start": "798560",
    "end": "803600"
  },
  {
    "text": "libraries available for the hardware so i mean gpu like basically anything we",
    "start": "803600",
    "end": "808959"
  },
  {
    "text": "can uh connect to from cpus plus we can we can sort of send down through kotlin",
    "start": "808959",
    "end": "814480"
  },
  {
    "text": "um the challenge becomes when um so with with cootie and n cuda um on",
    "start": "814480",
    "end": "820800"
  },
  {
    "text": "gpus it's relatively straightforward because you can you can run sort of an op at a time",
    "start": "820800",
    "end": "826560"
  },
  {
    "text": "on the gpu um the part where it gets challenging is the world of accelerators where um",
    "start": "826560",
    "end": "834720"
  },
  {
    "text": "if if accelerators sort of aren't expecting the same offset or if the or if the cost to offload the",
    "start": "834720",
    "end": "841120"
  },
  {
    "text": "accelerators high then you're going to need to send down a group of operations at once um and that's sort of a",
    "start": "841120",
    "end": "848160"
  },
  {
    "text": "that's something that we plan to hopefully plan to support in the future we'll see i would like to support that in the future um can't",
    "start": "848160",
    "end": "854959"
  },
  {
    "text": "speak for everybody but um so yeah we'll we'll have to see how that",
    "start": "854959",
    "end": "861120"
  },
  {
    "text": "goes interesting um",
    "start": "861120",
    "end": "867199"
  },
  {
    "start": "868000",
    "end": "972000"
  },
  {
    "text": "i literally have a question oh go ahead i actually have one is is the kotlin um",
    "start": "869120",
    "end": "876480"
  },
  {
    "text": "um implementation actually already onyx compliant because it's like what i think",
    "start": "876480",
    "end": "882720"
  },
  {
    "text": "two three years ago onyx started and it was like well okay we can finally start moving our ai models from a to b to c",
    "start": "882720",
    "end": "890240"
  },
  {
    "text": "and nobody had to worry and then it just disappeared and nobody ever talked again about it",
    "start": "890240",
    "end": "898079"
  },
  {
    "text": "yeah yeah i think there was i think at one point i played with with onyx but",
    "start": "898079",
    "end": "903360"
  },
  {
    "text": "i'm not sure what yeah i haven't seen much activity around it recently",
    "start": "903360",
    "end": "910839"
  },
  {
    "text": "so it's nice that others have the same experience because it wasn't",
    "start": "910839",
    "end": "916240"
  },
  {
    "text": "that's how it felt as well i think the onyx stuff was really big",
    "start": "916240",
    "end": "922959"
  },
  {
    "text": "when we're doing a lot of exploratory stuff with our project and then yeah it same experience where it just kind of",
    "start": "922959",
    "end": "928639"
  },
  {
    "text": "disappeared and i think um yeah and people were i don't know",
    "start": "928639",
    "end": "933680"
  },
  {
    "text": "no one talked about it ever again so onyx is the",
    "start": "933680",
    "end": "938880"
  },
  {
    "text": "uh sort of inter change um standard for models i think is it or",
    "start": "938880",
    "end": "944800"
  },
  {
    "text": "yeah yeah it tried to be an ir for models so that you could you know take something",
    "start": "944800",
    "end": "951040"
  },
  {
    "text": "in tensorflow then like have it you know spit out something in",
    "start": "951040",
    "end": "956160"
  },
  {
    "text": "high torque or something like that or test or rt",
    "start": "956160",
    "end": "962879"
  },
  {
    "text": "you can you can get in such trouble again sorry",
    "start": "965120",
    "end": "970639"
  },
  {
    "text": "um actually talking about the native code or jbm",
    "start": "971279",
    "end": "976880"
  },
  {
    "start": "972000",
    "end": "1026000"
  },
  {
    "text": "currently kotlin also has native compilation support do you do you run on",
    "start": "976880",
    "end": "982800"
  },
  {
    "text": "on all of those or is it just the jvm",
    "start": "982800",
    "end": "987120"
  },
  {
    "text": "um so right now we are we're i think we're focusing mostly on the jbm",
    "start": "988720",
    "end": "994399"
  },
  {
    "text": "it's true that kotlin can also target javascript and native which is you know",
    "start": "994399",
    "end": "999440"
  },
  {
    "text": "great because that means they can go they can really be heavily supported on both mobile",
    "start": "999440",
    "end": "1005199"
  },
  {
    "text": "platforms and also web programming but currently i i think the main use case of",
    "start": "1005199",
    "end": "1010399"
  },
  {
    "text": "kotlin native is really to have the different types of mobile support so",
    "start": "1010399",
    "end": "1016320"
  },
  {
    "text": "i don't know i don't think the the purpose of kotlin native is",
    "start": "1016320",
    "end": "1021360"
  },
  {
    "text": "necessarily for performance at the moment and we haven't really looked into that",
    "start": "1021360",
    "end": "1027199"
  },
  {
    "start": "1026000",
    "end": "1054000"
  },
  {
    "text": "yeah i guess it's uh because ios and stuff like that needs you need to make they compile it actually how does",
    "start": "1027360",
    "end": "1034240"
  },
  {
    "text": "and uh how does kotlin work on android because it's because it's compiled to delve or",
    "start": "1034240",
    "end": "1040400"
  },
  {
    "text": "oh okay yeah yeah um just similar yeah so",
    "start": "1040400",
    "end": "1046160"
  },
  {
    "text": "it is the it uses the bbm back end to um be used on android",
    "start": "1046160",
    "end": "1053840"
  },
  {
    "start": "1054000",
    "end": "1165000"
  },
  {
    "text": "um another question came in kotlin pros and cons i think we just talked about",
    "start": "1055120",
    "end": "1061039"
  },
  {
    "text": "different backends and stuff like that uh i see knowing smiles uh",
    "start": "1061039",
    "end": "1067520"
  },
  {
    "text": "i feel that's a story who wants to i actually love using kotlin",
    "start": "1067520",
    "end": "1075280"
  },
  {
    "text": "yeah i wanna go for it talk about",
    "start": "1075280",
    "end": "1081320"
  },
  {
    "text": "it's i i so i used i came from the python people's",
    "start": "1081679",
    "end": "1087360"
  },
  {
    "text": "plus world and i was a big fan of both i was afraid of jbm",
    "start": "1087360",
    "end": "1092720"
  },
  {
    "text": "um but the experience of writing kotlin is very nice in in my opinion and um",
    "start": "1092720",
    "end": "1098320"
  },
  {
    "text": "i like having the type system but it's it's not a not a particularly restrictive type system um in the sense",
    "start": "1098320",
    "end": "1105600"
  },
  {
    "text": "of like um it has you don't have to declare a type on a variable you just have to declare",
    "start": "1105600",
    "end": "1111360"
  },
  {
    "text": "it on a function um which which python is getting towards too with it with its type hints um",
    "start": "1111360",
    "end": "1117679"
  },
  {
    "text": "so i think i don't know i it's personally a really awesome",
    "start": "1117679",
    "end": "1122960"
  },
  {
    "text": "experience i like it i think um python can be faster for sort of quick stuff for me when i'm um",
    "start": "1122960",
    "end": "1131760"
  },
  {
    "text": "when i don't care about what i know when i can keep in my mind all of the",
    "start": "1131760",
    "end": "1137360"
  },
  {
    "text": "uh argument and return types to to all the functions in my code then like python is",
    "start": "1137360",
    "end": "1143039"
  },
  {
    "text": "perfect and i think it is faster for me but the documentation um that i get from",
    "start": "1143039",
    "end": "1148720"
  },
  {
    "text": "uh from the types and especially from the tensor typing that irene has prototyped um i'm her biggest fan of",
    "start": "1148720",
    "end": "1155919"
  },
  {
    "text": "that um uh it it's it's it's a pretty awesome experience in my opinion",
    "start": "1155919",
    "end": "1161760"
  },
  {
    "text": "someone else can speak to it i think there's some cons but i mean we're we're very hairy on the",
    "start": "1161760",
    "end": "1168720"
  },
  {
    "start": "1165000",
    "end": "1205000"
  },
  {
    "text": "python stack um i mean one reason is of course the the echo system for mlai is simply",
    "start": "1168720",
    "end": "1174559"
  },
  {
    "text": "so humongous in python um and we we indeed use um all the thai pins in",
    "start": "1174559",
    "end": "1181039"
  },
  {
    "text": "python and i totally agree that if possible use that because i think it's",
    "start": "1181039",
    "end": "1186480"
  },
  {
    "text": "it's nicer when they're first past citizen but it makes it easier for people to get into a language if you",
    "start": "1186480",
    "end": "1193679"
  },
  {
    "text": "if you don't have to start with typing and then later explain them by the way there is a thing you can use to",
    "start": "1193679",
    "end": "1200000"
  },
  {
    "text": "basically check a lot of things which will otherwise lead to bugs um i actually did like i went from",
    "start": "1200000",
    "end": "1208000"
  },
  {
    "start": "1205000",
    "end": "1529000"
  },
  {
    "text": "python to java to python and not to kotlin yet because i i just stuck",
    "start": "1208000",
    "end": "1214720"
  },
  {
    "text": "in the titan world um because i'm always thinking well i have docker what do i need a jvm for it's like it's all",
    "start": "1214720",
    "end": "1220640"
  },
  {
    "text": "virtual anyhow but i mean that's maybe very particular to to",
    "start": "1220640",
    "end": "1226240"
  },
  {
    "text": "us developing our services um and i mean we use lots of golang for microservices as",
    "start": "1226240",
    "end": "1231919"
  },
  {
    "text": "well paula we see your comments um because it's simply super fast for small",
    "start": "1231919",
    "end": "1236960"
  },
  {
    "text": "micro services um but for everything that's mla i related",
    "start": "1236960",
    "end": "1242240"
  },
  {
    "text": "we're yeah i mean we're basically going we're faster in developing python and that's basically our pro for for using",
    "start": "1242240",
    "end": "1249679"
  },
  {
    "text": "python and i think if you're used to right in kotlin and someone has an amazing carbon library for ml definitely",
    "start": "1249679",
    "end": "1255919"
  },
  {
    "text": "go for that i mean in the beginning go with whatever is most comfortable for you to start with",
    "start": "1255919",
    "end": "1263840"
  },
  {
    "text": "yeah definitely i i would really say though that as someone who's come from",
    "start": "1263919",
    "end": "1268960"
  },
  {
    "text": "also like a lot of python i i do think kotlin is actually like a great starting language and i wouldn't even say that",
    "start": "1268960",
    "end": "1275200"
  },
  {
    "text": "it's it's much heavier than python um it's definitely much lighter than",
    "start": "1275200",
    "end": "1280799"
  },
  {
    "text": "java and i think it's the way that like there's an interpreter as well so",
    "start": "1280799",
    "end": "1286480"
  },
  {
    "text": "you can script stuff pretty quickly and i can't well python without types i cannot",
    "start": "1286480",
    "end": "1292559"
  },
  {
    "text": "handle anymore like without types i have no idea what's going on",
    "start": "1292559",
    "end": "1298559"
  },
  {
    "text": "and to that point also like when i look at model code in python that",
    "start": "1298559",
    "end": "1303600"
  },
  {
    "text": "doesn't have that doesn't have any comments about the shapes and that that drives me nuts like",
    "start": "1303600",
    "end": "1309679"
  },
  {
    "text": "i have no idea what's going on um if you go on stack overflow which i've done",
    "start": "1309679",
    "end": "1315600"
  },
  {
    "text": "many times and look up something like you know tensor shape mismatch like you will see so many errors from people who",
    "start": "1315600",
    "end": "1322799"
  },
  {
    "text": "are just trying to use like the the like basic tutorial like com con 2d like two",
    "start": "1322799",
    "end": "1329840"
  },
  {
    "text": "just a few layers like thing on like a new data set and they just have like all",
    "start": "1329840",
    "end": "1334960"
  },
  {
    "text": "these issues because they're they're using it on a new data set and maybe two of their dimensions are like flipped and",
    "start": "1334960",
    "end": "1340640"
  },
  {
    "text": "that's it and but there they run into all these issues and they have no idea what's going on so i feel like from that",
    "start": "1340640",
    "end": "1346960"
  },
  {
    "text": "perspective that's where that's where like types and like static shape checking",
    "start": "1346960",
    "end": "1352799"
  },
  {
    "text": "are really beneficial and then also i think i think as people are like writing bigger ml programs i i feel like",
    "start": "1352799",
    "end": "1360960"
  },
  {
    "text": "doing little scripty stuff in python is great but when people are writing bigger things i think that's where",
    "start": "1360960",
    "end": "1367440"
  },
  {
    "text": "you know having a static statically typed language with static shape information and uh great",
    "start": "1367440",
    "end": "1375600"
  },
  {
    "text": "ide support is gonna be really crucial especially like like when you're collaborating with people and you're",
    "start": "1375600",
    "end": "1381600"
  },
  {
    "text": "like sharing code you know i think that's that's where it gets really important",
    "start": "1381600",
    "end": "1387039"
  },
  {
    "text": "i totally forgot about the ide um yeah i wanted i want to jump on that um",
    "start": "1387039",
    "end": "1392159"
  },
  {
    "text": "the so kotlin comes from jetbrains probably probably",
    "start": "1392159",
    "end": "1398400"
  },
  {
    "text": "people know this already but um jetbrains makes ides so kotlin is designed to be awesome in the ide and it",
    "start": "1398400",
    "end": "1405760"
  },
  {
    "text": "is it's like when you start writing code in kotlin it in in intellij it gives you all these",
    "start": "1405760",
    "end": "1412159"
  },
  {
    "text": "suggestions it tells you how to write canonical code and i came from like a world of python",
    "start": "1412159",
    "end": "1419520"
  },
  {
    "text": "with not that many suggestions and you just sort of learn you learn your pepe you learn your rules and um it's",
    "start": "1419520",
    "end": "1425200"
  },
  {
    "text": "actually really nice to just sort of have that um have",
    "start": "1425200",
    "end": "1430480"
  },
  {
    "text": "be taught as you're learning uh what to do there um and then also if i can",
    "start": "1430480",
    "end": "1437679"
  },
  {
    "text": "no go ahead go ahead no i'm just gonna add to the ide point i think also also because the ide is also",
    "start": "1437679",
    "end": "1445440"
  },
  {
    "text": "hackable like you can also add suggestions that um have to do with",
    "start": "1445440",
    "end": "1452240"
  },
  {
    "text": "you know are more domain specific um so we you know have ide support for like",
    "start": "1452240",
    "end": "1459279"
  },
  {
    "text": "static shape checking and we can add ide support for other other things as well",
    "start": "1459279",
    "end": "1466159"
  },
  {
    "text": "so again drake you look increasingly jealous no i mean i have vs code set up with",
    "start": "1466400",
    "end": "1472480"
  },
  {
    "text": "order formatting using the black formatter have my pi type checking and",
    "start": "1472480",
    "end": "1477679"
  },
  {
    "text": "automatic like eight testing so i'm super fine with staying with python",
    "start": "1477679",
    "end": "1482799"
  },
  {
    "text": "especially since i mean that the advantage of this code what i prefer over the jetbrains one is that you can",
    "start": "1482799",
    "end": "1488640"
  },
  {
    "text": "have multiple languages in one um",
    "start": "1488640",
    "end": "1493520"
  },
  {
    "text": "which is i mean there's always this fight if you're a person writing one language you prefer the you just have",
    "start": "1494080",
    "end": "1499919"
  },
  {
    "text": "one language but if you write go python helm charts then terraform code you're just like i just want all of that in my",
    "start": "1499919",
    "end": "1506880"
  },
  {
    "text": "ide and don't bother me and if it loads for 10 seconds that's fine but then it works um",
    "start": "1506880",
    "end": "1512720"
  },
  {
    "text": "but yeah if you if you're focused on the on the one language i i totally agree there's nothing nothing nicer than a um",
    "start": "1512720",
    "end": "1519200"
  },
  {
    "text": "than a nicely set up ide then you don't have to share your settings file with half your company which which is what",
    "start": "1519200",
    "end": "1525760"
  },
  {
    "text": "i'm currently doing um actually i had one question regarding the the static",
    "start": "1525760",
    "end": "1531919"
  },
  {
    "start": "1529000",
    "end": "1579000"
  },
  {
    "text": "shape checking um how does it handle if you have i mean",
    "start": "1531919",
    "end": "1537679"
  },
  {
    "text": "especially for semantic segmentation you can somewhat reuse um the network for",
    "start": "1537679",
    "end": "1543679"
  },
  {
    "text": "different um image sizes does that currently work or is it um very um",
    "start": "1543679",
    "end": "1551440"
  },
  {
    "text": "very static yeah yeah so",
    "start": "1551440",
    "end": "1557360"
  },
  {
    "text": "yeah we have quality organism or you know we're supporting we do support polymorphism with with tapes so you can",
    "start": "1557360",
    "end": "1564480"
  },
  {
    "text": "you can have um so you could say maybe your inputs is n and your outputs is m",
    "start": "1564480",
    "end": "1569919"
  },
  {
    "text": "and then you know n m get assigned at the call site when you actually use it",
    "start": "1569919",
    "end": "1575360"
  },
  {
    "text": "i don't need okay",
    "start": "1575360",
    "end": "1578559"
  },
  {
    "start": "1579000",
    "end": "1757000"
  },
  {
    "text": "uh it's because it keeps coming up uh go for ml uh yandra you mentioned",
    "start": "1580480",
    "end": "1586320"
  },
  {
    "text": "do you use go for actual ml workloads or for other stuff no we use it for for",
    "start": "1586320",
    "end": "1592760"
  },
  {
    "text": "microservices um especially for stuff that needs to get super small i mean the memory footprint",
    "start": "1592760",
    "end": "1598960"
  },
  {
    "text": "of go is amazing if i especially if you if you run in the cloud you can just put",
    "start": "1598960",
    "end": "1605039"
  },
  {
    "text": "a hundred docker or 100 go containers on one node while having two python nodes",
    "start": "1605039",
    "end": "1610880"
  },
  {
    "text": "just explodes it um but we we don't use it for for ml um",
    "start": "1610880",
    "end": "1618320"
  },
  {
    "text": "yeah i mean simply because the python echo system is there and i think in go you would need to rebuild a lot of it um",
    "start": "1618320",
    "end": "1626320"
  },
  {
    "text": "and yeah i mean that's that's why we simply use python and i mean that's i think generally one of those advantages",
    "start": "1626320",
    "end": "1632240"
  },
  {
    "text": "of microservices it's like i will definitely try the the kotlin ml",
    "start": "1632240",
    "end": "1637679"
  },
  {
    "text": "stuff at one point and i'll be like well okay i just put it alongside the python stuff and along the side the go",
    "start": "1637679",
    "end": "1642720"
  },
  {
    "text": "microservices um so yeah i'm generally interested to see how many languages will support and all",
    "start": "1642720",
    "end": "1650000"
  },
  {
    "text": "because it makes sense if you have monolithic applications um where you basically have to stay in your language",
    "start": "1650000",
    "end": "1656320"
  },
  {
    "text": "but i mean with kotlin you can basically integrate c plus plus with python you can integrate everything the question is",
    "start": "1656320",
    "end": "1662640"
  },
  {
    "text": "just how long it takes to call during runtime so uh yeah i'll just be interested to",
    "start": "1662640",
    "end": "1669840"
  },
  {
    "text": "see how many different languages will support it and actually where onyx goes because i think it was a",
    "start": "1669840",
    "end": "1676159"
  },
  {
    "text": "great idea to basically if we have all the frameworks we basically want to move models from a to b to c um",
    "start": "1676159",
    "end": "1683120"
  },
  {
    "text": "it's like this this cross language support will be i think very very interesting as well but",
    "start": "1683120",
    "end": "1688480"
  },
  {
    "text": "we're not using go for for ml currently at least let's see what comes in the future",
    "start": "1688480",
    "end": "1695679"
  },
  {
    "text": "regarding your your comment about onyx it'll be also interesting to see how",
    "start": "1698399",
    "end": "1703760"
  },
  {
    "text": "models will evolve um so a model that that we've sort of talked about um",
    "start": "1703760",
    "end": "1709679"
  },
  {
    "text": "on our end which which we think is pretty cool uh or i think is pretty cool i guess is",
    "start": "1709679",
    "end": "1715039"
  },
  {
    "text": "um is the slide model which uses these um uses hash tables and a smart hashing",
    "start": "1715039",
    "end": "1722000"
  },
  {
    "text": "scheme to drastically sparsify a densely connected network um",
    "start": "1722000",
    "end": "1729520"
  },
  {
    "text": "and i don't think on x is gonna be able to rip that at any time soon or maybe it will um",
    "start": "1729520",
    "end": "1735200"
  },
  {
    "text": "but um it seems like uh ml respect there's there's a direction of ml research",
    "start": "1735200",
    "end": "1741120"
  },
  {
    "text": "that's just sort of um like exploding in the kinds of things you can do with architectures um so it'll be really",
    "start": "1741120",
    "end": "1747440"
  },
  {
    "text": "interesting to see what what happens there and and i guess that's sort of what differentiable programming is",
    "start": "1747440",
    "end": "1752960"
  },
  {
    "text": "excited about but it's another question i had to i wanted",
    "start": "1752960",
    "end": "1759440"
  },
  {
    "start": "1757000",
    "end": "1899000"
  },
  {
    "text": "to ask um actually it's a good point so with onyx you mentioned that there's things you",
    "start": "1759440",
    "end": "1765279"
  },
  {
    "text": "can't really represent in onyx so does the interchange model even make",
    "start": "1765279",
    "end": "1770320"
  },
  {
    "text": "sense so would it have to wait for another iteration of research to know what it have what have to",
    "start": "1770320",
    "end": "1776640"
  },
  {
    "text": "have to support i think generally it's it's a question",
    "start": "1776640",
    "end": "1782480"
  },
  {
    "text": "how much i mean i think it's simply not so needed by the community right now because basically i think you need to",
    "start": "1782480",
    "end": "1788320"
  },
  {
    "text": "convert every layer in every language to the respective layer in every other language and that's i think simply a",
    "start": "1788320",
    "end": "1795440"
  },
  {
    "text": "humongous amount of effort but um i mean that's that's what is limiting it",
    "start": "1795440",
    "end": "1801760"
  },
  {
    "text": "i think for dense layers it has no problems convolutions are not problems but if you start doing i i mean the",
    "start": "1801760",
    "end": "1809200"
  },
  {
    "text": "first thing is already i think striding is like where do you start counting the stride is different between tensorflow",
    "start": "1809200",
    "end": "1814960"
  },
  {
    "text": "and pytorch um they start shuffling around the dimensions so uh",
    "start": "1814960",
    "end": "1821760"
  },
  {
    "text": "what was the direction i think pytorch prefers batch uh second when it comes to time series",
    "start": "1821760",
    "end": "1828080"
  },
  {
    "text": "while tensorflow likes batch first um which makes sense because i think",
    "start": "1828080",
    "end": "1834640"
  },
  {
    "text": "pytorch is more tailored to cuda which likes it batch second i don't know it's like it",
    "start": "1834640",
    "end": "1841520"
  },
  {
    "text": "i mean that's where where's that where shape checking actually helps you because then you know which",
    "start": "1841520",
    "end": "1846799"
  },
  {
    "text": "dimensions you run around to come back to that topic but",
    "start": "1846799",
    "end": "1852320"
  },
  {
    "text": "i think it's simply the it's it's not that needed yet but",
    "start": "1852320",
    "end": "1857679"
  },
  {
    "text": "um i mean especially if if we see models appearing in more like especially new",
    "start": "1857679",
    "end": "1863440"
  },
  {
    "text": "research papers seeing appearing in other languages then python it will get really relevant because",
    "start": "1863440",
    "end": "1870080"
  },
  {
    "text": "then if you basically want to reproduce the paper um you somewhat need a way to transport",
    "start": "1870080",
    "end": "1875760"
  },
  {
    "text": "the model around right and especially if you want to then start iterating on it so",
    "start": "1875760",
    "end": "1881919"
  },
  {
    "text": "i i hope it it will get yeah it will reappear but",
    "start": "1881919",
    "end": "1887679"
  },
  {
    "text": "it's it's a humongous effort i think so that's right probably died down a bit because then people realized how complex",
    "start": "1887679",
    "end": "1894080"
  },
  {
    "text": "it will be",
    "start": "1894080",
    "end": "1896559"
  },
  {
    "start": "1899000",
    "end": "1987000"
  },
  {
    "text": "cool uh i think there's one question i'm not sure if we can have an answer",
    "start": "1899519",
    "end": "1905200"
  },
  {
    "text": "wondering if kotlin is fit for web application or m or ml or mobile all of",
    "start": "1905200",
    "end": "1911200"
  },
  {
    "text": "these i guess it's always as we mentioned it's for androids",
    "start": "1911200",
    "end": "1917039"
  },
  {
    "text": "so i guess people are using it there uh web application i don't know if kotlin for javascript that's mature",
    "start": "1917039",
    "end": "1924240"
  },
  {
    "text": "enough or not any comments from you um i've i've tried it actually it's",
    "start": "1924240",
    "end": "1932080"
  },
  {
    "text": "pretty good i mean i haven't tried it for ml specifically but you know java",
    "start": "1932080",
    "end": "1937760"
  },
  {
    "text": "javascript or kotlin for javascript is is actually quite easy to use and i",
    "start": "1937760",
    "end": "1943120"
  },
  {
    "text": "originally wrote this program maybe like 700 lines um",
    "start": "1943120",
    "end": "1948960"
  },
  {
    "text": "in in kotlin for jbm and just flipped the switch for javascript wrote like a",
    "start": "1948960",
    "end": "1954799"
  },
  {
    "text": "little thing to displ to actually display stuff on web and it worked like",
    "start": "1954799",
    "end": "1959840"
  },
  {
    "text": "i didn't have to change any of the meat of the code so it it's pretty good um",
    "start": "1959840",
    "end": "1966799"
  },
  {
    "text": "in terms of speed i'm not sure if it was like very performant so",
    "start": "1966799",
    "end": "1973519"
  },
  {
    "text": "but yeah i really i mean i think it's it's great that i was able to use the same code and i think that's that's one",
    "start": "1973519",
    "end": "1979600"
  },
  {
    "text": "of their main goals is code reuse for having these different back ends",
    "start": "1979600",
    "end": "1985760"
  },
  {
    "start": "1987000",
    "end": "2089000"
  },
  {
    "text": "cool um so we're kind of we have seven minutes left um",
    "start": "1987919",
    "end": "1993919"
  },
  {
    "text": "so just before we started the panel i threw out the word probabilistic programming",
    "start": "1993919",
    "end": "2000000"
  },
  {
    "text": "uh because we all like to introduce new paradigms",
    "start": "2000000",
    "end": "2004960"
  },
  {
    "text": "who would like to do an elevator pitch or elevator explanation for probabilistic programming",
    "start": "2005120",
    "end": "2012158"
  },
  {
    "text": "um yeah i i can kind of explain it um again i'm not i'm not a",
    "start": "2012240",
    "end": "2018720"
  },
  {
    "text": "probabilistic programming expert but this is my my attempt but um probabilistic programming basically",
    "start": "2018720",
    "end": "2025840"
  },
  {
    "text": "um aims to allow people to add a level of uncertainty to their models and to",
    "start": "2025840",
    "end": "2030880"
  },
  {
    "text": "show uncertain statistical relationships so for example what you do with",
    "start": "2030880",
    "end": "2036240"
  },
  {
    "text": "probabilistic programming is you generally first give some assumption about your world um in the form of you know you",
    "start": "2036240",
    "end": "2043679"
  },
  {
    "text": "might have like some distributions um and then you provide a set of",
    "start": "2043679",
    "end": "2048960"
  },
  {
    "text": "observations so you have you know this is how i think the world functions and then you have this is what i see",
    "start": "2048960",
    "end": "2055280"
  },
  {
    "text": "happening in this world and then what comes out of it is a prediction of",
    "start": "2055280",
    "end": "2061919"
  },
  {
    "text": "how your world actually is given those assumptions and your observations",
    "start": "2061919",
    "end": "2068000"
  },
  {
    "text": "so that that's my my high level overview and it's it's a great way to",
    "start": "2068000",
    "end": "2073919"
  },
  {
    "text": "add uncertainty because i mean the world is just full of uncertainty right and you have these underlying relationships",
    "start": "2073919",
    "end": "2079679"
  },
  {
    "text": "um these underlying effects and causes to the data that you actually see",
    "start": "2079679",
    "end": "2084720"
  },
  {
    "text": "um so that's where or that's why it's important",
    "start": "2084720",
    "end": "2089839"
  },
  {
    "start": "2089000",
    "end": "2159000"
  },
  {
    "text": "so is this an in dml space is this an alternative to sort of",
    "start": "2090000",
    "end": "2096720"
  },
  {
    "text": "the various networks and models or is it in addition to those",
    "start": "2096960",
    "end": "2103200"
  },
  {
    "text": "um i i think it's i think it's kind of like separate i",
    "start": "2103200",
    "end": "2108880"
  },
  {
    "text": "think i feel like it's it's an added it's like an added",
    "start": "2108880",
    "end": "2114320"
  },
  {
    "text": "information to your models yeah because it requires that",
    "start": "2114320",
    "end": "2120880"
  },
  {
    "text": "oh go ahead go go go ahead i was just gonna say because it requires the addition of the assumptions um and",
    "start": "2120880",
    "end": "2128000"
  },
  {
    "text": "like if you're if you're just working on your machine learning model then you just have your data and you're just gonna throw it at you know what which",
    "start": "2128000",
    "end": "2134079"
  },
  {
    "text": "which architecture you've picked or or a couple of them uh versus um the like",
    "start": "2134079",
    "end": "2139760"
  },
  {
    "text": "programming in the assumptions is kind of the kind of a big input",
    "start": "2139760",
    "end": "2146320"
  },
  {
    "text": "because you're you're sort of you're in in a way you're sort of restricting the model uh is my understanding that this",
    "start": "2146320",
    "end": "2152560"
  },
  {
    "text": "might be a little off but um you're sort of restricting the model in a way based on what you think the world looks like",
    "start": "2152560",
    "end": "2159359"
  },
  {
    "start": "2159000",
    "end": "2250000"
  },
  {
    "text": "yeah i mean we i i think where you can actually edit together is basically when you make probabilistic predictions so we",
    "start": "2159359",
    "end": "2167359"
  },
  {
    "text": "for example use that when we we did um power predictions when i worked at the",
    "start": "2167359",
    "end": "2172480"
  },
  {
    "text": "company we basically wanted to predict how much power we consume to basically then go to the stock market and buy the",
    "start": "2172480",
    "end": "2177520"
  },
  {
    "text": "amount we need um and we i mean what you want to know is not only the answer it's like you will",
    "start": "2177520",
    "end": "2184079"
  },
  {
    "text": "use 50 megawatts but you will you want to know is it like well is it within plus and minus 10",
    "start": "2184079",
    "end": "2190400"
  },
  {
    "text": "megawatts or are you uncertain from 100 to zero because that's that's the",
    "start": "2190400",
    "end": "2195839"
  },
  {
    "text": "difference to what you will actually buy um and the nice thing you can then as well see",
    "start": "2195839",
    "end": "2201599"
  },
  {
    "text": "is if your if your input data goes out of the training distribution you can",
    "start": "2201599",
    "end": "2206720"
  },
  {
    "text": "basically as well see how your outputs increases in uncertainty um we we actually modeled that with power",
    "start": "2206720",
    "end": "2214400"
  },
  {
    "text": "outages we had so basically you could see in advance that some sensory data went crazy and then you could just see",
    "start": "2214400",
    "end": "2221200"
  },
  {
    "text": "that the model got more and more uncertain um how much power we will actually use and",
    "start": "2221200",
    "end": "2227359"
  },
  {
    "text": "it's helpful for that it's basically nice to know in advance if or how",
    "start": "2227359",
    "end": "2232560"
  },
  {
    "text": "certain your model is itself about the prediction it does um so so for that it's pretty pretty",
    "start": "2232560",
    "end": "2239440"
  },
  {
    "text": "handy i think cool",
    "start": "2239440",
    "end": "2246000"
  },
  {
    "text": "cool so we have um we have a quick question about um",
    "start": "2246720",
    "end": "2255920"
  },
  {
    "start": "2250000",
    "end": "2378000"
  },
  {
    "text": "i mean using rust i think for interference um does the language in that sense make that much of a",
    "start": "2258560",
    "end": "2264400"
  },
  {
    "text": "difference for interference i mean",
    "start": "2264400",
    "end": "2269440"
  },
  {
    "text": "different languages make a difference for inference i think basically all um models developed in in",
    "start": "2269440",
    "end": "2277359"
  },
  {
    "text": "uh python based frameworks are exported to c plus for inference so",
    "start": "2277359",
    "end": "2282880"
  },
  {
    "text": "um certainly potential for for uh for a difference there i'm not sure i'm",
    "start": "2282880",
    "end": "2289440"
  },
  {
    "text": "not i'm not sure how big the difference would be but certainly potential it it is reasonably big so um at least",
    "start": "2289440",
    "end": "2297680"
  },
  {
    "text": "going from python to c plus plus accelerates stuff but normally the first things you do going",
    "start": "2297680",
    "end": "2303280"
  },
  {
    "text": "to float 16 or quantize your your model because i mean going from float 32 to",
    "start": "2303280",
    "end": "2310320"
  },
  {
    "text": "integer 8 uh stuff actually gives you like at least a four time increase maybe",
    "start": "2310320",
    "end": "2315520"
  },
  {
    "text": "even more depending on how optimized your your hardware is um",
    "start": "2315520",
    "end": "2321280"
  },
  {
    "text": "so at least for me that was like the gain i needed and then i didn't bother writing it in rust um",
    "start": "2321280",
    "end": "2328640"
  },
  {
    "text": "but probably you can get go even faster i mean that depends a bit on how good your compilers as well for the language",
    "start": "2329119",
    "end": "2335920"
  },
  {
    "text": "i assume not really a compiler person but um i think their difference in how well",
    "start": "2335920",
    "end": "2342400"
  },
  {
    "text": "they optimize so i'm being told by the monitors that we are",
    "start": "2342400",
    "end": "2349440"
  },
  {
    "text": "basically out of time uh that was a really excellent discussion",
    "start": "2349440",
    "end": "2354560"
  },
  {
    "text": "i think everybody here has some homework to do not not you you folks but the audience",
    "start": "2354560",
    "end": "2360079"
  },
  {
    "text": "lots of stuff to look and thank you irene yandrick and alana",
    "start": "2360079",
    "end": "2367880"
  },
  {
    "text": "[Music]",
    "start": "2367880",
    "end": "2375750"
  },
  {
    "text": "you",
    "start": "2378000",
    "end": "2380079"
  }
]
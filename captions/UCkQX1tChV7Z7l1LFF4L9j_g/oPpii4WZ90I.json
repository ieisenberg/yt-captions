[
  {
    "start": "0",
    "end": "122000"
  },
  {
    "text": "[Music]",
    "start": "2009",
    "end": "14789"
  },
  {
    "text": "okay thank you Good evening My name is Michael Malava and I'm from his data",
    "start": "15280",
    "end": "20480"
  },
  {
    "text": "Thank you for invitation from uh Sri and I would like to speak about how to make",
    "start": "20480",
    "end": "27439"
  },
  {
    "text": "a better prediction and with help of Scala So the first the first part of the",
    "start": "27439",
    "end": "34480"
  },
  {
    "text": "talk will be about our Scala API which is still in the progress and we are trying to make better better and better",
    "start": "34480",
    "end": "42079"
  },
  {
    "text": "and then Cliff will explain some uh technical details how to how to tune JVM",
    "start": "42079",
    "end": "51440"
  },
  {
    "text": "to its limits So why are we focused on better",
    "start": "51440",
    "end": "57360"
  },
  {
    "text": "predictions You know there are a lot of there is big hype uh about big data A",
    "start": "57360",
    "end": "64080"
  },
  {
    "text": "lot of people are interested in that A lot of companies collecting big lot of data So we are trying to participate in",
    "start": "64080",
    "end": "70640"
  },
  {
    "text": "this world and make them better and make them better Made them better",
    "start": "70640",
    "end": "77000"
  },
  {
    "text": "by framework which is called H2O H2O Yeah It's open source framework",
    "start": "77000",
    "end": "84240"
  },
  {
    "text": "which in fact provide uh provides inmemory computation and prediction engine and I",
    "start": "84240",
    "end": "94240"
  },
  {
    "text": "was asked to play a short video which will",
    "start": "94240",
    "end": "99720"
  },
  {
    "text": "introduce which will introduce uh where is",
    "start": "99720",
    "end": "105240"
  },
  {
    "text": "it which will introduce H2O Ah here is it So I will refresh the",
    "start": "105240",
    "end": "113360"
  },
  {
    "text": "page and it's just one minute video explaining all the",
    "start": "113360",
    "end": "119680"
  },
  {
    "text": "aspects of H2O So your business has massive amounts of customer data stored in Hadoop that",
    "start": "119680",
    "end": "126399"
  },
  {
    "text": "you need to analyze The more data you analyze the better you can predict how to serve your customers But organizing",
    "start": "126399",
    "end": "132080"
  },
  {
    "text": "and analyzing this data requires complicated math And modeling this data to come up with better predictions",
    "start": "132080",
    "end": "137440"
  },
  {
    "text": "usually takes days to weeks and is often errorprone So what's the best solution",
    "start": "137440",
    "end": "142720"
  },
  {
    "text": "Quite frankly it's H2O from Ox Data the industry's first open-source prediction",
    "start": "142720",
    "end": "148480"
  },
  {
    "text": "and math engine that will enable you to make better predictions and build accurate models faster And as makers of",
    "start": "148480",
    "end": "154560"
  },
  {
    "text": "the parallelized modeling and scoring engine of Hadoop we got you covered Here's a real world example Let's say",
    "start": "154560",
    "end": "160720"
  },
  {
    "text": "your business is trying to understand the best product placement for optimal customer engagement So you want to model",
    "start": "160720",
    "end": "165840"
  },
  {
    "text": "the interactions of your customers on your website to make better predictions on what they want to do next Well H2O",
    "start": "165840",
    "end": "172080"
  },
  {
    "text": "allows you to model all of your data with better algorithms using many machines This way you won't have to",
    "start": "172080",
    "end": "177440"
  },
  {
    "text": "sample a smaller data set for performance reasons H2O then allows you to score hundreds of models in",
    "start": "177440",
    "end": "183040"
  },
  {
    "text": "nanoseconds and deliver better predictions to your business The reality is data is messy and so many hours of",
    "start": "183040",
    "end": "190000"
  },
  {
    "text": "data science go into moving big files and munching missing features And that's why we designed H2O's data console to",
    "start": "190000",
    "end": "196560"
  },
  {
    "text": "make those tasks a piece of cake within a familiar interface Simply put H2O makes big data science well simple So",
    "start": "196560",
    "end": "205200"
  },
  {
    "text": "when you're ready to mine the true gold hidden within your big data you're ready for",
    "start": "205200",
    "end": "211360"
  },
  {
    "text": "H2O Okay So so that was a short marketing video about H2O I like the",
    "start": "212599",
    "end": "219200"
  },
  {
    "start": "213000",
    "end": "281000"
  },
  {
    "text": "video because it's really cool with a lot of presentation a lot of animation",
    "start": "219200",
    "end": "225599"
  },
  {
    "text": "and so on Okay can you see that Okay so I will go back to the slides",
    "start": "225599",
    "end": "232360"
  },
  {
    "text": "and make some uh technical details about H2O It's in fact Java platform So we are",
    "start": "232360",
    "end": "239280"
  },
  {
    "text": "running on JVM and we are doing inmemory computation We are not like Hadoop We",
    "start": "239280",
    "end": "245120"
  },
  {
    "text": "are not storing any temporary data to HDFS or some some distributed storage",
    "start": "245120",
    "end": "251280"
  },
  {
    "text": "but we are loading data to the memory and then make quick fast computation",
    "start": "251280",
    "end": "258880"
  },
  {
    "text": "over the data with lot of performance tuning This in fact supports different",
    "start": "258880",
    "end": "265040"
  },
  {
    "text": "styles of programming but you know a lot of people for this kind of computation",
    "start": "265040",
    "end": "270960"
  },
  {
    "text": "are using mapu style So it's also our paradigm which we use but internally we",
    "start": "270960",
    "end": "278320"
  },
  {
    "text": "use fortune framework from Dougli and uh the whole platform is",
    "start": "278320",
    "end": "285120"
  },
  {
    "start": "281000",
    "end": "320000"
  },
  {
    "text": "accessible via uh v via different clients one client it's used for testing",
    "start": "285120",
    "end": "291840"
  },
  {
    "text": "is the python client which access h2 rest api for doing the operation and",
    "start": "291840",
    "end": "298560"
  },
  {
    "text": "then we have also our clients our client which use the same way how to",
    "start": "298560",
    "end": "306240"
  },
  {
    "text": "access uh all functionality of H2O",
    "start": "306240",
    "end": "313080"
  },
  {
    "text": "but you know there are some limitation of rest API which we cannot uh cross So",
    "start": "313080",
    "end": "320479"
  },
  {
    "start": "320000",
    "end": "386000"
  },
  {
    "text": "we also provide Java API which is little bit lower level API how to how to",
    "start": "320479",
    "end": "329440"
  },
  {
    "text": "compute over the data and that's was the reason why we also want to introduce the",
    "start": "329440",
    "end": "336080"
  },
  {
    "text": "Scala some Scala access to this API because if you look at the example of our internal API",
    "start": "336080",
    "end": "343759"
  },
  {
    "text": "it was designed or it is designed to be performant",
    "start": "343759",
    "end": "348840"
  },
  {
    "text": "and really allows you to access whole data distributed in across the cloud in",
    "start": "348840",
    "end": "354720"
  },
  {
    "text": "low-level way So lot of user are confused by this API You can see there",
    "start": "354720",
    "end": "360240"
  },
  {
    "text": "are a lot of uh weird word like chunk or uh set zero at zero and so on",
    "start": "360240",
    "end": "368039"
  },
  {
    "text": "So we would like to cross this low-level API and provide something high higher",
    "start": "368039",
    "end": "375360"
  },
  {
    "text": "level and the higher level should be Scala API which should which should",
    "start": "375360",
    "end": "381600"
  },
  {
    "text": "encapsulate this low-level API to nice domain specific language which we called",
    "start": "381600",
    "end": "387720"
  },
  {
    "start": "386000",
    "end": "469000"
  },
  {
    "text": "Shala according to some restaurant in Mountain View which serves uh soup So",
    "start": "387720",
    "end": "399720"
  },
  {
    "text": "yeah it's favorite restaurant there So it was nice nice idea how to how to call",
    "start": "401440",
    "end": "409199"
  },
  {
    "text": "the language So in fact Shala is Scala DSL or internal DSL based on Scala",
    "start": "409199",
    "end": "416560"
  },
  {
    "text": "language which uh make abstraction over our low-level computation",
    "start": "416560",
    "end": "424360"
  },
  {
    "text": "API and the goal of this API is just to",
    "start": "424360",
    "end": "429560"
  },
  {
    "text": "make writing map reduce or computation task easier and also manipulate with",
    "start": "429560",
    "end": "436319"
  },
  {
    "text": "data in easy way But still we want to stay in JVM We don't we don't want to",
    "start": "436319",
    "end": "443440"
  },
  {
    "text": "publish the operation via via rest API because we have already have this API We",
    "start": "443440",
    "end": "449039"
  },
  {
    "text": "would like to stay in JVM and make the best of",
    "start": "449039",
    "end": "454840"
  },
  {
    "text": "JVM And then there is also uh nice you know integration of ripple into our",
    "start": "454840",
    "end": "463479"
  },
  {
    "text": "H2O which you which provides a way how to play with this",
    "start": "463479",
    "end": "469160"
  },
  {
    "text": "shala So what are the basic concept of this shala DSL",
    "start": "469160",
    "end": "475680"
  },
  {
    "text": "We play with table tabular data with frames and if you are familiar with R",
    "start": "475680",
    "end": "483039"
  },
  {
    "text": "you can uh you perhaps know that frame is abstraction of data which cons uh",
    "start": "483039",
    "end": "490800"
  },
  {
    "text": "which uh consists of uh vectors or columns",
    "start": "490800",
    "end": "496319"
  },
  {
    "text": "Each columns has a name and uh data type and uh obtain the data So we uh took the",
    "start": "496319",
    "end": "505280"
  },
  {
    "text": "same approach how to represent data inshallah and and",
    "start": "505280",
    "end": "513479"
  },
  {
    "text": "uh uh we call that distributed frame and in fact the data in the frame are",
    "start": "513479",
    "end": "520159"
  },
  {
    "text": "distributed across your cloud I will speak about that later and perhaps Cliff",
    "start": "520159",
    "end": "525200"
  },
  {
    "text": "will clarify this in his technical talk Then this is uh this uh frame",
    "start": "525200",
    "end": "532720"
  },
  {
    "text": "distributive frame is the first class entity which we need to operate over and",
    "start": "532720",
    "end": "538320"
  },
  {
    "text": "then we need to provide expressions how to operate with the with the frames How",
    "start": "538320",
    "end": "543440"
  },
  {
    "text": "to access the columns how to access the data how to make the basic operation",
    "start": "543440",
    "end": "548640"
  },
  {
    "text": "over data and how to make uh operation with the frames and also the language",
    "start": "548640",
    "end": "557760"
  },
  {
    "text": "should provide easy access to our low-level API So if there is some",
    "start": "557760",
    "end": "564399"
  },
  {
    "text": "functionality which you cannot solve with shala you can still switch to",
    "start": "564399",
    "end": "570000"
  },
  {
    "text": "low-level H2O API and just uh implement your functionality via Java",
    "start": "570000",
    "end": "578839"
  },
  {
    "text": "API So for frame operations I will just summarize several of several of them and",
    "start": "578839",
    "end": "586480"
  },
  {
    "text": "then show uh more of them dur during the demo",
    "start": "586480",
    "end": "591560"
  },
  {
    "text": "But they are divided into uh obvious steps You need to load data parse data",
    "start": "591560",
    "end": "598560"
  },
  {
    "text": "Then you need to select uh columns or manipulate with the",
    "start": "598560",
    "end": "606680"
  },
  {
    "text": "columns Then you need to store data into our internal store H2O is using",
    "start": "606680",
    "end": "614959"
  },
  {
    "text": "internally uh DKV store which is distributed over the cloud So uh DSL also provides the",
    "start": "614959",
    "end": "624079"
  },
  {
    "text": "functions how to access this decay store and so there are simple operations and",
    "start": "624079",
    "end": "631760"
  },
  {
    "text": "in this case we are uh motivated by R because lot of data scientists knows R",
    "start": "631760",
    "end": "640160"
  },
  {
    "text": "and they can develop simple or",
    "start": "640160",
    "end": "645600"
  },
  {
    "text": "simple they can develop uh not only simple analysis is in R So we would like",
    "start": "645959",
    "end": "652480"
  },
  {
    "text": "to uh provise the similar commands in our uh Scala DSL that if data analyst come",
    "start": "652480",
    "end": "660480"
  },
  {
    "text": "look at the program in shala it can read the program and decide what is the",
    "start": "660480",
    "end": "666880"
  },
  {
    "text": "program what the program is doing and then we have of course some distributed",
    "start": "666880",
    "end": "672480"
  },
  {
    "start": "670000",
    "end": "761000"
  },
  {
    "text": "uh operation so we provide uh currently just three of them you can still switch",
    "start": "672480",
    "end": "678240"
  },
  {
    "text": "to our low-level API but currently We provide a map just for mapping uh one",
    "start": "678240",
    "end": "685519"
  },
  {
    "text": "given operation given user method over the m uh over the data filtering and",
    "start": "685519",
    "end": "691959"
  },
  {
    "text": "collecting and you can see that the API is still little bit ugly I will speak",
    "start": "691959",
    "end": "697920"
  },
  {
    "text": "about that later that there are some limitations which we need still",
    "start": "697920",
    "end": "704920"
  },
  {
    "text": "cross but we are still working on that",
    "start": "704920",
    "end": "710320"
  },
  {
    "text": "So how it uh how it is implemented internally it's",
    "start": "710320",
    "end": "715519"
  },
  {
    "text": "small magic more about the magic uh will be in the in the uh talk of cliff but I",
    "start": "715519",
    "end": "723839"
  },
  {
    "text": "will just clarify what the scala DSLR is",
    "start": "723839",
    "end": "729120"
  },
  {
    "text": "doing In fact the basic thing is that in",
    "start": "729240",
    "end": "734399"
  },
  {
    "text": "H2O we are using our own class loader which is responsible for a lot of things",
    "start": "734399",
    "end": "740079"
  },
  {
    "text": "for optimization data structures or generation parts of data structure which we pass around the cloud and",
    "start": "740079",
    "end": "749200"
  },
  {
    "text": "uh for some uh typing things So we need to preserve this semantics of class",
    "start": "749200",
    "end": "756480"
  },
  {
    "text": "order in cooperation with Scala So it's one one thing then we need to translate",
    "start": "756480",
    "end": "763760"
  },
  {
    "start": "761000",
    "end": "828000"
  },
  {
    "text": "the Scala Scala uh code or the DSL code",
    "start": "763760",
    "end": "770000"
  },
  {
    "text": "which user types we need to translate to our internal JAPI So this is uh quite",
    "start": "770000",
    "end": "778800"
  },
  {
    "text": "easy task but still we need to live in the world of HTO which say there are",
    "start": "778800",
    "end": "785360"
  },
  {
    "text": "some limitations regarding what you can pass around the cloud and what you can",
    "start": "785360",
    "end": "790560"
  },
  {
    "text": "do but still it's it can be done quite easily and",
    "start": "790560",
    "end": "797320"
  },
  {
    "text": "also in our low-level J API we really focus on preserving primitive types and",
    "start": "797320",
    "end": "804720"
  },
  {
    "text": "computation with primitive styles everywhere just to avoid unboxing boxing",
    "start": "804720",
    "end": "812760"
  },
  {
    "text": "So all the translation from Scala part to",
    "start": "812760",
    "end": "818440"
  },
  {
    "text": "uh Java Java partad has to has to uh",
    "start": "818440",
    "end": "825320"
  },
  {
    "text": "preserve print types So one example how uh filter operation is",
    "start": "825320",
    "end": "833839"
  },
  {
    "start": "828000",
    "end": "977000"
  },
  {
    "text": "implemented I will go to the slide and filter operation takes uh in fact",
    "start": "834920",
    "end": "843839"
  },
  {
    "text": "functor which is map over all the values in the frame It's one kind it's one kind",
    "start": "843839",
    "end": "850560"
  },
  {
    "text": "of the filter operation which we provides and you can see it's little bit ugly Normally you would expect here uh",
    "start": "850560",
    "end": "859680"
  },
  {
    "text": "some kind of closure but currently we uh",
    "start": "859680",
    "end": "864880"
  },
  {
    "text": "have to be nice uh to our class order So currently this",
    "start": "864880",
    "end": "871600"
  },
  {
    "text": "closure is en encapsulated in our uh data structure and the code is",
    "start": "871600",
    "end": "878240"
  },
  {
    "text": "translated to low-level uh H2O API I wrote this example in Scala",
    "start": "878240",
    "end": "885360"
  },
  {
    "text": "just to see uh what is uh what we are doing internally",
    "start": "885360",
    "end": "891800"
  },
  {
    "text": "but the same version is you can find in jar code So in fact we are we have",
    "start": "891800",
    "end": "899800"
  },
  {
    "text": "marriage task which runs around the cloud look at the data and run given",
    "start": "899800",
    "end": "907040"
  },
  {
    "text": "operation The marri task as you know it's marri so",
    "start": "907040",
    "end": "912560"
  },
  {
    "text": "it has two operation map reduce we are taking uh classical uh map reduce",
    "start": "912560",
    "end": "922000"
  },
  {
    "text": "approach So mapping over the values the values is a chunk and chunk in fact is",
    "start": "922000",
    "end": "928000"
  },
  {
    "text": "part of data which is distributed over the cloud and it contains the rows from",
    "start": "928000",
    "end": "933680"
  },
  {
    "text": "the data set and on the data you can over this data you can do a lot of",
    "start": "933680",
    "end": "939680"
  },
  {
    "text": "operations and then for example here there there is no reduce stage because you don't need to reduce data you just",
    "start": "939680",
    "end": "946320"
  },
  {
    "text": "need to compute something in this case we are filtering uh the values So we are",
    "start": "946320",
    "end": "954880"
  },
  {
    "text": "just appending to a new vector the values which satisfies the uh predicate",
    "start": "954880",
    "end": "961759"
  },
  {
    "text": "and then there is some technical magic that you have to uh preserve uh the",
    "start": "961759",
    "end": "967120"
  },
  {
    "text": "naming of the vectors in resulting frame the types the domains of the vectors and",
    "start": "967120",
    "end": "972639"
  },
  {
    "text": "so on more about that I think will be in the talk of the of",
    "start": "972639",
    "end": "979079"
  },
  {
    "start": "977000",
    "end": "1230000"
  },
  {
    "text": "cliff and I think it's Time for demo So I will try",
    "start": "979079",
    "end": "987160"
  },
  {
    "text": "just this So what I did I launch one instance",
    "start": "987160",
    "end": "993680"
  },
  {
    "text": "of H2 uh H2 So I launch virtual machine with",
    "start": "993680",
    "end": "1002480"
  },
  {
    "text": "some flags and by default H2O expose",
    "start": "1002480",
    "end": "1008959"
  },
  {
    "text": "uh rest API and we have uh some web UI to access the web API So I will",
    "start": "1008959",
    "end": "1018120"
  },
  {
    "text": "go to browser and show you that I'm not lying that there is something running",
    "start": "1018120",
    "end": "1025120"
  },
  {
    "text": "and it's one one way how to access",
    "start": "1025120",
    "end": "1030760"
  },
  {
    "text": "H2O and I can look to the store which is what is inside and there is nothing",
    "start": "1030760",
    "end": "1037839"
  },
  {
    "text": "nothing is running and I can look to the cloud",
    "start": "1037839",
    "end": "1042880"
  },
  {
    "text": "status So I have I run I'm running the cloud of only one machine here on this",
    "start": "1042880",
    "end": "1053080"
  },
  {
    "text": "machine So I will go back to the console and I will try to",
    "start": "1053080",
    "end": "1063440"
  },
  {
    "text": "parse some date some",
    "start": "1063720",
    "end": "1069440"
  },
  {
    "text": "data Uh",
    "start": "1070039",
    "end": "1073519"
  },
  {
    "text": "sorry So I uh I par a simple data set",
    "start": "1079240",
    "end": "1084720"
  },
  {
    "text": "which is one of the favorite data set uh designed for",
    "start": "1084720",
    "end": "1091400"
  },
  {
    "text": "prediction and uh in fact the data set",
    "start": "1091400",
    "end": "1096880"
  },
  {
    "text": "contains eight columns",
    "start": "1097640",
    "end": "1103760"
  },
  {
    "text": "and 46 rows And you",
    "start": "1104039",
    "end": "1109080"
  },
  {
    "text": "can just to believe that I load something I will",
    "start": "1109080",
    "end": "1115120"
  },
  {
    "text": "go to uh web UI and show you that there is",
    "start": "1115120",
    "end": "1122160"
  },
  {
    "text": "something some data",
    "start": "1122160",
    "end": "1125440"
  },
  {
    "text": "loaded and it contains eight columns and",
    "start": "1128840",
    "end": "1134080"
  },
  {
    "text": "lot of rows So now I can start to play with data So I can look at the first",
    "start": "1134080",
    "end": "1142039"
  },
  {
    "text": "column So it contains the name of the data uh of the of the car In fact the",
    "start": "1142039",
    "end": "1148320"
  },
  {
    "text": "data set contains uh different types of cars with their",
    "start": "1148320",
    "end": "1154919"
  },
  {
    "text": "properties like uh year of of creation weight uh power",
    "start": "1154919",
    "end": "1162720"
  },
  {
    "text": "number of cylinders economy and so on So I will try just show you several",
    "start": "1162720",
    "end": "1169240"
  },
  {
    "text": "operations over the data set I can look for example",
    "start": "1169240",
    "end": "1174559"
  },
  {
    "text": "of number of cylinders or I prefer I prepared several",
    "start": "1174559",
    "end": "1180160"
  },
  {
    "text": "examples here I",
    "start": "1180160",
    "end": "1185559"
  },
  {
    "text": "can make look at the last column which is",
    "start": "1185559",
    "end": "1190880"
  },
  {
    "text": "year You can see that the year is just a small number and I would like to uh",
    "start": "1190880",
    "end": "1197360"
  },
  {
    "text": "would like to transform this column to a new column which will contains the full",
    "start": "1197360",
    "end": "1202760"
  },
  {
    "text": "year dated from uh year zero So I make transformation",
    "start": "1202760",
    "end": "1209600"
  },
  {
    "text": "and uh in ripple we are just showing uh 10",
    "start": "1209600",
    "end": "1217200"
  },
  {
    "text": "lines of the data set but",
    "start": "1217200",
    "end": "1222000"
  },
  {
    "text": "just show you more lines We can look at all the lines of",
    "start": "1222919",
    "end": "1228480"
  },
  {
    "text": "the vector which we created There is uh important point that at this at this",
    "start": "1228480",
    "end": "1235400"
  },
  {
    "start": "1230000",
    "end": "1400000"
  },
  {
    "text": "uh stage we are not creating any frames So if we are go if we go back to the",
    "start": "1235400",
    "end": "1244480"
  },
  {
    "text": "inspect or store view you will still see that there is only one frame one data",
    "start": "1244480",
    "end": "1252799"
  },
  {
    "text": "frame which was created and I also can access this view",
    "start": "1252799",
    "end": "1258640"
  },
  {
    "text": "from the console So I can look at the number of the keys So there is only one",
    "start": "1258640",
    "end": "1264240"
  },
  {
    "text": "key which is representing one data frame which I loaded but I can also look at",
    "start": "1264240",
    "end": "1271679"
  },
  {
    "text": "our internal data structure So access our our internal Java API So I will say",
    "start": "1271679",
    "end": "1279840"
  },
  {
    "text": "show me all the keys which are created in the KV store",
    "start": "1279840",
    "end": "1287000"
  },
  {
    "text": "So you can see that there are lot of technical or internal keys",
    "start": "1289520",
    "end": "1295440"
  },
  {
    "text": "which are in fact representing the parts of the data which are normally",
    "start": "1295440",
    "end": "1300880"
  },
  {
    "text": "distributed Now they are just stored in one GVM and also the parts of data which",
    "start": "1300880",
    "end": "1308919"
  },
  {
    "text": "uh represent uh the vector which I created in ripple",
    "start": "1308919",
    "end": "1317400"
  },
  {
    "text": "I can also make a boolean vector",
    "start": "1319840",
    "end": "1326559"
  },
  {
    "text": "from filtering all the cars or uh",
    "start": "1326679",
    "end": "1331760"
  },
  {
    "text": "accessing one vector and making a boolean vector saying this car has more than four cylinders or",
    "start": "1331760",
    "end": "1338760"
  },
  {
    "text": "less And",
    "start": "1338760",
    "end": "1342159"
  },
  {
    "text": "internally it's in fact simple map operation taking initial frame and",
    "start": "1345080",
    "end": "1352919"
  },
  {
    "text": "saying accessing the second column and asking the second column if it contains",
    "start": "1352919",
    "end": "1359520"
  },
  {
    "text": "more than four cylinders or not And the result is a new vector containing",
    "start": "1359520",
    "end": "1367240"
  },
  {
    "text": "containing uh containing",
    "start": "1370840",
    "end": "1376520"
  },
  {
    "text": "uh the boo values and I can in fact",
    "start": "1376520",
    "end": "1383600"
  },
  {
    "text": "compare both columns both created vectors and just",
    "start": "1383799",
    "end": "1392080"
  },
  {
    "text": "uh make",
    "start": "1392080",
    "end": "1395880"
  },
  {
    "text": "Just look at the difference between the vectors and you can see that I'm not lying that both vectors are the same and",
    "start": "1399840",
    "end": "1405760"
  },
  {
    "start": "1400000",
    "end": "1415000"
  },
  {
    "text": "in fact internally uh the operation of booting predicate is implemented in the",
    "start": "1405760",
    "end": "1413840"
  },
  {
    "text": "simple map call and the same for also for filtering",
    "start": "1413840",
    "end": "1419840"
  },
  {
    "start": "1415000",
    "end": "1690000"
  },
  {
    "text": "So if I would like to filter all the cars I can use the same the same call",
    "start": "1419840",
    "end": "1427840"
  },
  {
    "text": "just using the filter operation and the filter filter operation will go through",
    "start": "1427840",
    "end": "1434400"
  },
  {
    "text": "whole data set and look at each row and apply the predate at each row and decide",
    "start": "1434400",
    "end": "1442320"
  },
  {
    "text": "this row should be included in the resulting data set or not So if I",
    "start": "1442320",
    "end": "1448200"
  },
  {
    "text": "compute number of row of this filter operation",
    "start": "1448200",
    "end": "1455159"
  },
  {
    "text": "uh okay it's variable f6 So you can see that",
    "start": "1455320",
    "end": "1462720"
  },
  {
    "text": "there is 195 cars which has which have",
    "start": "1462720",
    "end": "1467840"
  },
  {
    "text": "more than four cylinders So this is uh one way how to manipulate with data",
    "start": "1467840",
    "end": "1476240"
  },
  {
    "text": "but we H2O also provides different kind of analysis I am personally involved on",
    "start": "1476240",
    "end": "1484520"
  },
  {
    "text": "u DRF which is distributed random forest implementation algorithm which",
    "start": "1484520",
    "end": "1494000"
  },
  {
    "text": "uh which we provide So I will try to run that run that over",
    "start": "1494000",
    "end": "1502400"
  },
  {
    "text": "the car data and make a prediction about the number of uh",
    "start": "1502400",
    "end": "1510080"
  },
  {
    "text": "cylinders So I will create some small data structures So I will in uh I will",
    "start": "1510120",
    "end": "1518240"
  },
  {
    "text": "create a new frame which is called source which will contain uh only",
    "start": "1518240",
    "end": "1523279"
  },
  {
    "text": "selected columns So I will skip the first column with the name because it has no practive",
    "start": "1523279",
    "end": "1530520"
  },
  {
    "text": "power and I will skip uh the column uh",
    "start": "1530520",
    "end": "1536159"
  },
  {
    "text": "with cylinders because this is my response which I will be practing later",
    "start": "1536159",
    "end": "1543120"
  },
  {
    "text": "and then I will include all the columns So I created a new frame",
    "start": "1543120",
    "end": "1551760"
  },
  {
    "text": "In fact I can save this FRA frame to DKV if I want So let's call the frame",
    "start": "1551760",
    "end": "1561159"
  },
  {
    "text": "source.hex This hex means that it's our internal data",
    "start": "1561159",
    "end": "1566919"
  },
  {
    "text": "format And by this call I just save the created",
    "start": "1566919",
    "end": "1574720"
  },
  {
    "text": "frame to DKV So let's look here And you",
    "start": "1574720",
    "end": "1580080"
  },
  {
    "text": "can see okay there is some source.hex frame which contains only",
    "start": "1580080",
    "end": "1585919"
  },
  {
    "text": "selected uh columns and all the",
    "start": "1585919",
    "end": "1594320"
  },
  {
    "text": "rows Then I will take the second column with the",
    "start": "1597480",
    "end": "1603880"
  },
  {
    "text": "cylinders and create a DRF",
    "start": "1603880",
    "end": "1611159"
  },
  {
    "text": "model based on this data set By this call I'm saying",
    "start": "1611159",
    "end": "1618640"
  },
  {
    "text": "take the source build uh runoff forest model over",
    "start": "1618640",
    "end": "1625120"
  },
  {
    "text": "the source and the response column which is uh which is an objective of the",
    "start": "1625120",
    "end": "1632559"
  },
  {
    "text": "prediction uh is the second parameter of the call and the last parameter is the number of",
    "start": "1632559",
    "end": "1640440"
  },
  {
    "text": "uh number of uh trees which will which will be generated it in the resulting",
    "start": "1640440",
    "end": "1648000"
  },
  {
    "text": "random forest Uh I switch on uh the",
    "start": "1648000",
    "end": "1653200"
  },
  {
    "text": "logging So you will see that it's something the engine is doing something",
    "start": "1653200",
    "end": "1659760"
  },
  {
    "text": "So I will launch it and you can see there are severals several log messages",
    "start": "1659760",
    "end": "1666559"
  },
  {
    "text": "saying okay I'm we are starting DRF computation with these parameters and",
    "start": "1666559",
    "end": "1672320"
  },
  {
    "text": "then we are building uh collection",
    "start": "1672320",
    "end": "1677720"
  },
  {
    "text": "of decision trees and computing the some errors over the tree and some properties",
    "start": "1677720",
    "end": "1684960"
  },
  {
    "text": "and the result of this code is DRF model and It contains all the data which you",
    "start": "1684960",
    "end": "1691279"
  },
  {
    "start": "1690000",
    "end": "2020000"
  },
  {
    "text": "need to store for this kind of models I was doing regression",
    "start": "1691279",
    "end": "1700679"
  },
  {
    "text": "So I can take the model and ask the model",
    "start": "1700679",
    "end": "1707000"
  },
  {
    "text": "what he thinks about the given data And I will be lying a little bit",
    "start": "1707000",
    "end": "1714000"
  },
  {
    "text": "here because I will use the same data as I was using for training So it will give",
    "start": "1714000",
    "end": "1720240"
  },
  {
    "text": "it or the model should give good really good prediction So I will",
    "start": "1720240",
    "end": "1728000"
  },
  {
    "text": "launch scoring part of the",
    "start": "1728600",
    "end": "1733919"
  },
  {
    "text": "model and I will I will use the source data",
    "start": "1735399",
    "end": "1741279"
  },
  {
    "text": "for the scoring And there is one point which I have to stress that the source",
    "start": "1741279",
    "end": "1747120"
  },
  {
    "text": "it does not contain the response column So really model has to take has to look",
    "start": "1747120",
    "end": "1752720"
  },
  {
    "text": "at the at the uh data and ask all the trees what uh the",
    "start": "1752720",
    "end": "1759760"
  },
  {
    "text": "trees thinks about about the data and in this case I'm accessing our Java API So",
    "start": "1759760",
    "end": "1766240"
  },
  {
    "text": "the model is uh the object published by H2O and the",
    "start": "1766240",
    "end": "1773760"
  },
  {
    "text": "score method it's not it's not a wrapper from Scala but it's really uh j method",
    "start": "1773760",
    "end": "1781520"
  },
  {
    "text": "taking uh taking uh a frame as a parameter So I",
    "start": "1781520",
    "end": "1788159"
  },
  {
    "text": "generated a fraction I was and the result operation is the",
    "start": "1788159",
    "end": "1793640"
  },
  {
    "text": "frame but here I leaked the internal frame",
    "start": "1793640",
    "end": "1800679"
  },
  {
    "text": "So I",
    "start": "1800679",
    "end": "1804080"
  },
  {
    "text": "will I will create this distributed",
    "start": "1807000",
    "end": "1812760"
  },
  {
    "text": "frame and you can see the result of the prediction So we say uh the model thinks",
    "start": "1812760",
    "end": "1819279"
  },
  {
    "text": "about the first row of the data So let's look at the first row of the",
    "start": "1819279",
    "end": "1826158"
  },
  {
    "text": "data The model thinks that am some car with name AMC ambassador has eight",
    "start": "1829080",
    "end": "1837039"
  },
  {
    "text": "columns and in fact it has eight columns So I would like to see uh what is the",
    "start": "1837039",
    "end": "1842960"
  },
  {
    "text": "general error for this prediction So I will compute uh the squared error for each row",
    "start": "1842960",
    "end": "1852520"
  },
  {
    "text": "So I will just take one vector containing the",
    "start": "1852520",
    "end": "1858279"
  },
  {
    "text": "response and the predated",
    "start": "1858279",
    "end": "1862640"
  },
  {
    "text": "vector I forgot [Music] this",
    "start": "1863320",
    "end": "1871039"
  },
  {
    "text": "response So I compute for each row I",
    "start": "1877240",
    "end": "1882640"
  },
  {
    "text": "computed in fact square error and now I'm interested in the sum of all these",
    "start": "1885320",
    "end": "1891760"
  },
  {
    "text": "square errors So I will launch map reduce operation overall data and",
    "start": "1891760",
    "end": "1898480"
  },
  {
    "text": "compute the sum of that For this I have",
    "start": "1898480",
    "end": "1907200"
  },
  {
    "text": "simple operation prepared here and what I'm doing I'm collecting",
    "start": "1910200",
    "end": "1918679"
  },
  {
    "text": "uh data over the cloud in this case I'm collecting single double and single",
    "start": "1920120",
    "end": "1926559"
  },
  {
    "text": "double is computed for each row in the in the uh in the given data set in the",
    "start": "1926559",
    "end": "1933519"
  },
  {
    "text": "given frame and it should produce the sum of all all",
    "start": "1933519",
    "end": "1939960"
  },
  {
    "text": "the all the uh all the rows You can see here that I'm using reduce operation",
    "start": "1939960",
    "end": "1948840"
  },
  {
    "text": "which in I can avoid in the future just by using nice types which will implement",
    "start": "1948840",
    "end": "1957120"
  },
  {
    "text": "the plus operation by default So that",
    "start": "1957120",
    "end": "1963159"
  },
  {
    "text": "was a demo of the DSL and if I go back to the view",
    "start": "1963159",
    "end": "1971919"
  },
  {
    "text": "web view you can look that there is some entity which is called",
    "start": "1971919",
    "end": "1979240"
  },
  {
    "text": "DRF big string and this is not a frame this is",
    "start": "1979240",
    "end": "1985200"
  },
  {
    "text": "not a vector this is a model which we generated it by",
    "start": "1985200",
    "end": "1990519"
  },
  {
    "text": "calling DRF API and in fact the here is",
    "start": "1990519",
    "end": "1995919"
  },
  {
    "text": "simple view of the model which contains all the information and also we can access the code of the model So we can",
    "start": "1995919",
    "end": "2003519"
  },
  {
    "text": "look in fact at generated code of the model which can be used",
    "start": "2003519",
    "end": "2009720"
  },
  {
    "text": "later for some correction",
    "start": "2009720",
    "end": "2014278"
  },
  {
    "text": "So I will go back to the presentation and just",
    "start": "2018039",
    "end": "2025039"
  },
  {
    "start": "2020000",
    "end": "2120000"
  },
  {
    "text": "just tell you something tell you something more about future plans In fact the goal is to uh",
    "start": "2025159",
    "end": "2034559"
  },
  {
    "text": "have the API which is similar to scalding API but we we are still battling with some limitation introduced",
    "start": "2034559",
    "end": "2041600"
  },
  {
    "text": "by H2O As I mentioned this class loader and generator generating of byte code",
    "start": "2041600",
    "end": "2048158"
  },
  {
    "text": "and we would like to support more uh distributed operations more highle distributed",
    "start": "2048159",
    "end": "2054638"
  },
  {
    "text": "operation you can still go to our low-level API and general ideas is to",
    "start": "2054639",
    "end": "2061280"
  },
  {
    "text": "introduce algebraic operation as was as they are introduced in al",
    "start": "2061280",
    "end": "2068358"
  },
  {
    "text": "algebra So if you are interested in participation you can simply get clone",
    "start": "2068359",
    "end": "2074398"
  },
  {
    "text": "our repository because it's open source You can switch to the H2 Scala branch",
    "start": "2074399",
    "end": "2080000"
  },
  {
    "text": "and just play with that or really simply simply contribute or there is also uh",
    "start": "2080000",
    "end": "2087118"
  },
  {
    "text": "release which is a small link at the bottom of the of the of the uh slide",
    "start": "2087119",
    "end": "2094398"
  },
  {
    "text": "which you can download and just try H2O Scala ripple and try try to play with",
    "start": "2094399",
    "end": "2100880"
  },
  {
    "text": "that So that's uh all from me and Cliff is waiting for his talk",
    "start": "2100880",
    "end": "2107200"
  },
  {
    "text": "Thank you [Applause]",
    "start": "2107200",
    "end": "2113599"
  },
  {
    "text": "It's getting late so I will go quick and then we'll go time for Q&A Um and so I",
    "start": "2113599",
    "end": "2120480"
  },
  {
    "start": "2120000",
    "end": "2145000"
  },
  {
    "text": "will skip through a bunch of stuff that's sort of boilerplate here Um I hope it's not auto forwarding Okay",
    "start": "2120480",
    "end": "2127599"
  },
  {
    "text": "yes it's auto forwarding Okay so I don't know what you did Let's back up a little bit here Okay so this is sort of obvious",
    "start": "2127599",
    "end": "2133440"
  },
  {
    "text": "Um we're open source You can find us on the Git There's a git uh the GitHub and also um xeroxdata.com right on our front",
    "start": "2133440",
    "end": "2140640"
  },
  {
    "text": "of our web page and you already know we're a platform for doing math Um so let's just roll along So I'm going to",
    "start": "2140640",
    "end": "2147200"
  },
  {
    "start": "2145000",
    "end": "2205000"
  },
  {
    "text": "dive into some details on the insides of the Java implementation And the reason for diving down there is to show you why",
    "start": "2147200",
    "end": "2155760"
  },
  {
    "text": "we're getting speed So when I say speed I I mean that most of our math operations are completely memory",
    "start": "2155760",
    "end": "2162320"
  },
  {
    "text": "bandwidth bound um on the data which means it's it's milliseconds per gigabyte As you do more math per row",
    "start": "2162320",
    "end": "2169599"
  },
  {
    "text": "that moment about balance might change Might be doing more FP versus memory but typically we're like really really fast",
    "start": "2169599",
    "end": "2177440"
  },
  {
    "text": "So when other people say \"Yeah we do big really fast.\" We're usually 10x 100x I mean we're we're fast So the basic",
    "start": "2177440",
    "end": "2184960"
  },
  {
    "text": "notion that Muel was showing you was that we have a notion of a vector It's like it's an array um but it's a big",
    "start": "2184960",
    "end": "2191119"
  },
  {
    "text": "array and it could be much much bigger than a Java int That's why the length is listed as a long and it supports fast",
    "start": "2191119",
    "end": "2197359"
  },
  {
    "text": "random access from any node to any piece of data But we're geared to running to um linear access pass over the entire",
    "start": "2197359",
    "end": "2205119"
  },
  {
    "start": "2205000",
    "end": "2448000"
  },
  {
    "text": "data That's where you're going to get your your most speed out So a taxonomy there's a big vector It could be a very",
    "start": "2205119",
    "end": "2211200"
  },
  {
    "text": "large vector Conceptually it's a Java primitive or double but actually it's",
    "start": "2211200",
    "end": "2216800"
  },
  {
    "text": "compressed internally The compression schemes are quite aggressive and I'll talk about that in a minute because that's part of our speed Um and so we're",
    "start": "2216800",
    "end": "2223920"
  },
  {
    "text": "often seeing two to fourx better than gzip on disk So better than gzip on disk in memory while getting speed out of",
    "start": "2223920",
    "end": "2231320"
  },
  {
    "text": "it The vector is distributed across the cluster and it's kept in the Java heap",
    "start": "2231320",
    "end": "2237119"
  },
  {
    "text": "not off heap And that gets us really fast access to it from Java which makes for very convenient programming Um but",
    "start": "2237119",
    "end": "2243599"
  },
  {
    "text": "it means you have to watch out for GC and we've done that We've taken our care that we can uh spill the disk as needed",
    "start": "2243599",
    "end": "2250079"
  },
  {
    "text": "Um and because we keep the data in very large arrays of primitives Typical GC",
    "start": "2250079",
    "end": "2256400"
  },
  {
    "text": "costs are very modest for a 32 gig heap Um a full GC cycle is usually under a",
    "start": "2256400",
    "end": "2262000"
  },
  {
    "text": "second and they come around from time to time but under a second I don't care Um whereas new gen collections are and",
    "start": "2262000",
    "end": "2268560"
  },
  {
    "text": "they're they're blazingly fast A 200 gig heap will have full GCs on there over a",
    "start": "2268560",
    "end": "2273680"
  },
  {
    "text": "couple seconds Within the the same heap will",
    "start": "2273680",
    "end": "2280079"
  },
  {
    "text": "have a collection of vectors um what was uh typically called a a frame And the",
    "start": "2280079",
    "end": "2286960"
  },
  {
    "text": "key notion here is that we are aligning the rows within the JVM across this way",
    "start": "2286960",
    "end": "2292480"
  },
  {
    "text": "So that if you're talking about all the elements of that car data set what year how many cylinders that car have what's",
    "start": "2292480",
    "end": "2298800"
  },
  {
    "text": "its weight and displacement all that data is local on one JVM and you can do some math on it at you know memory",
    "start": "2298800",
    "end": "2303920"
  },
  {
    "text": "bandwidth speed So yeah so it's a frame and and essentially you can think of this as this a tabular data or it's a a",
    "start": "2303920",
    "end": "2311040"
  },
  {
    "text": "strruct of arrays instead of array of strrus That's the conceptual view of it",
    "start": "2311040",
    "end": "2316560"
  },
  {
    "text": "within that big old pile of data we breaking up the vectors into chunks",
    "start": "2316560",
    "end": "2322000"
  },
  {
    "text": "where a chunk is a thousand to a million elements depending it's stored compressed and the compression strategy",
    "start": "2322000",
    "end": "2327760"
  },
  {
    "text": "is sort of key to speed in a lot of ways Um basically more compression is good because we get more data per cache miss",
    "start": "2327760",
    "end": "2334400"
  },
  {
    "text": "and it it's how long it takes to drag the data in from memory that sort of matters on things",
    "start": "2334400",
    "end": "2339839"
  },
  {
    "text": "They're all aligned going across as I mentioned before And so you can essentially think you're looking at a strct that you can read and write and",
    "start": "2339839",
    "end": "2346160"
  },
  {
    "text": "toy with directly like it's a strct in Java You can write to it as well as read from it And we'll follow the Java memory",
    "start": "2346160",
    "end": "2353359"
  },
  {
    "text": "model rules down the line all the way Um that chunk is also the unit of uh",
    "start": "2353359",
    "end": "2361119"
  },
  {
    "text": "execution So one CPU will grab a chunk of rows and do whatever math you're",
    "start": "2361119",
    "end": "2366480"
  },
  {
    "text": "asking for all across all those rows all in one set And that means that it's also single threaded on those rows And so",
    "start": "2366480",
    "end": "2373200"
  },
  {
    "text": "there's no synchronization games being played in the code that you're looking at it You're guaranteed single threaded",
    "start": "2373200",
    "end": "2379040"
  },
  {
    "text": "access to the rows that you're you know handed to that granularity is big enough",
    "start": "2379040",
    "end": "2384560"
  },
  {
    "text": "to cover all our control overheads all the management costs of launching a thread to deal with a pile of data and",
    "start": "2384560",
    "end": "2390480"
  },
  {
    "text": "small enough to get good fine grain data parallelism out of it",
    "start": "2390480",
    "end": "2395960"
  },
  {
    "text": "um because that's one one CPU does that chunk all the other CPUs will be",
    "start": "2397040",
    "end": "2402800"
  },
  {
    "text": "grabbing their own independent chunks and will typically light up all the cores across all the machines in the",
    "start": "2402800",
    "end": "2408079"
  },
  {
    "text": "cluster and it'll do the math in one big pass of the data and be done Um the within this kind of taxonomy um Ho is",
    "start": "2408079",
    "end": "2416000"
  },
  {
    "text": "handling all the communications and data management It's handling all the communication between the nodes as you do uh reduces you have to roll things up",
    "start": "2416000",
    "end": "2422560"
  },
  {
    "text": "across the cluster and so on within a single node We're using Douglasley's fork join to do the chunk by chunk",
    "start": "2422560",
    "end": "2429640"
  },
  {
    "text": "execution where you're typically expecting few thousands of chunks uh more or less depending on this volume of",
    "start": "2429640",
    "end": "2436000"
  },
  {
    "text": "the data uh and that's going to be roundroin however fork join does it across however many you know 4 8 16 CPUs",
    "start": "2436000",
    "end": "2442640"
  },
  {
    "text": "you have we typically see we get really good behavior out of fork join except",
    "start": "2442640",
    "end": "2448560"
  },
  {
    "start": "2448000",
    "end": "2492000"
  },
  {
    "text": "for the cases I'll talk in a minute so there's a taxonomy um there's a frame it's a 2D table where the cross is",
    "start": "2448560",
    "end": "2456079"
  },
  {
    "text": "columns typically hundreds can be thousands can be hundreds of thousands but the rows will run onto the millions",
    "start": "2456079",
    "end": "2461920"
  },
  {
    "text": "and billions so however much fits in all the RAM in your cluster within that",
    "start": "2461920",
    "end": "2467280"
  },
  {
    "text": "collection a column we call a ve internally it's a column of data it's a big array that's broken up to chunks",
    "start": "2467280",
    "end": "2473760"
  },
  {
    "text": "thousand to a million at a pop a chunk is a collection of elements elements conceptually a Java double how it's",
    "start": "2473760",
    "end": "2479359"
  },
  {
    "text": "actually stored in memory varies according to the compression strategy of the moment um but you can ask score for",
    "start": "2479359",
    "end": "2484880"
  },
  {
    "text": "back as a double value or as an int Uh and we also support like the notion of missing elements is really crucial for a",
    "start": "2484880",
    "end": "2490240"
  },
  {
    "text": "lot of the data science stuff So that said the the platform as a whole can be considered at a couple",
    "start": "2490240",
    "end": "2496720"
  },
  {
    "start": "2492000",
    "end": "2558000"
  },
  {
    "text": "different layers Um there's this layer where you use the rest and JSON that male talked about earlier Um that's the",
    "start": "2496720",
    "end": "2502880"
  },
  {
    "text": "layer where you treat the box as a big box for doing the cluster as a big box",
    "start": "2502880",
    "end": "2507920"
  },
  {
    "text": "for doing math load this data run a logistic regression run a random forest get some results cycle back around add",
    "start": "2507920",
    "end": "2514640"
  },
  {
    "text": "columns drop columns manufacture features run another model score it go again Um you might be driving that from",
    "start": "2514640",
    "end": "2521599"
  },
  {
    "text": "the internal H2O console you could be driving it from Scala but you might be driving it from R or Python or",
    "start": "2521599",
    "end": "2527839"
  },
  {
    "text": "Mathematica or whatever Um here I'm going to talk about uh a",
    "start": "2527839",
    "end": "2534000"
  },
  {
    "text": "little bit more on the inards of the system the data parallel coding layer And this would be for people who are implementing stuff at the Java level And",
    "start": "2534000",
    "end": "2540160"
  },
  {
    "text": "so male's doing Scola to Java and we have other engineers doing R to Java and",
    "start": "2540160",
    "end": "2545200"
  },
  {
    "text": "I'm implementing well other people implementing new math algorithms So whether it's K means or u you know",
    "start": "2545200",
    "end": "2551040"
  },
  {
    "text": "gradient boosting or whatever that's the layer that you would talk to the system at and then there's more complicated stuff you can do if you want to get sort",
    "start": "2551040",
    "end": "2557200"
  },
  {
    "text": "of heads down in the system So I'm going to give one or two examples of the Java but this is a Scola group So I'm going",
    "start": "2557200",
    "end": "2563359"
  },
  {
    "start": "2558000",
    "end": "2622000"
  },
  {
    "text": "to leave it at that and then I'm going to go dive into uh some of the guts of the system and and why things go fast",
    "start": "2563359",
    "end": "2569760"
  },
  {
    "text": "And then I'll stop and this will be like a whirlwind tour of things really quick because it's getting late and we'll just take a Q&A after that So here's a here's",
    "start": "2569760",
    "end": "2576800"
  },
  {
    "text": "sort of the simplest map reduce task that does something interesting And this is an example from linear regression and I'm just going to accumulate the sums of",
    "start": "2576800",
    "end": "2583280"
  },
  {
    "text": "squares of a particular vector And so I'm going to make a map reduce task has a map and a reduce Map is a function",
    "start": "2583280",
    "end": "2590560"
  },
  {
    "text": "which takes a thing of type A and produces a thing of type B In this case type A is a double Type B is also a",
    "start": "2590560",
    "end": "2597680"
  },
  {
    "text": "double but it doesn't have to be And the next slide will change it up a little bit And reduce takes two things of type",
    "start": "2597680",
    "end": "2603040"
  },
  {
    "text": "B and makes one thing out of it And that's uh it collaps it reduces your data Right So this is a a piece of code",
    "start": "2603040",
    "end": "2610640"
  },
  {
    "text": "that will run at the memory bandwidth speeds across a cluster in like five six",
    "start": "2610640",
    "end": "2615760"
  },
  {
    "text": "lines and compute sums of squares across the cluster you know sort of just like that",
    "start": "2615760",
    "end": "2622640"
  },
  {
    "start": "2622000",
    "end": "2759000"
  },
  {
    "text": "I can have a more complicated example In particular I can have state Um here I've",
    "start": "2622640",
    "end": "2628319"
  },
  {
    "text": "got my type A is a pair of doubles and my type B is uh this Java object called",
    "start": "2628319",
    "end": "2634400"
  },
  {
    "text": "an LR pass one which has three internal fields And the map call is go do",
    "start": "2634400",
    "end": "2640079"
  },
  {
    "text": "something with all the fields It's go scribble on them And the reduce is take a this and a that So that this is",
    "start": "2640079",
    "end": "2645200"
  },
  {
    "text": "implicit and that that's the other side of it And it will redo the reduction and that will run across your",
    "start": "2645200",
    "end": "2652319"
  },
  {
    "text": "cluster doing all the right things So within a node the reductions obviously taking two Java objects and squishing",
    "start": "2652319",
    "end": "2658480"
  },
  {
    "text": "them together but across the cluster one of the Java objects got serialized and shipped over the wire and then they got",
    "start": "2658480",
    "end": "2663920"
  },
  {
    "text": "reduced on the other side Um I'll touch this a little bit and then",
    "start": "2663920",
    "end": "2670400"
  },
  {
    "text": "we'll move on Um for efficiency we do a lot of uh we do batching So a whole",
    "start": "2670400",
    "end": "2676000"
  },
  {
    "text": "chunk is passed into a map call at once And we typically write at this layer but you can write this one line and it'll",
    "start": "2676000",
    "end": "2682079"
  },
  {
    "text": "work But at this layer you can see that there's a loop over a chunk which is a thousand to a million elements And the",
    "start": "2682079",
    "end": "2688000"
  },
  {
    "text": "the app calls here are doing the decompression strategy which might vary from chunk to chunk to chunk to chunk",
    "start": "2688000",
    "end": "2694079"
  },
  {
    "text": "right But this is typically a few clock cycles to decompress and pull data out Then you do your math and you go on The",
    "start": "2694079",
    "end": "2699200"
  },
  {
    "text": "rest of the code was same as the last slide So that's sort of it",
    "start": "2699200",
    "end": "2704680"
  },
  {
    "text": "for the whirlwind Java side of things and now I was going to dive into some",
    "start": "2704680",
    "end": "2710480"
  },
  {
    "text": "technical concerns So these are all slides I wrote in the last half an hour So pardon me if they're a little brief",
    "start": "2710480",
    "end": "2716640"
  },
  {
    "text": "or a little raw Um so so we're concerned with big and whenever we're concerned",
    "start": "2716640",
    "end": "2723280"
  },
  {
    "text": "with big you're concerned with speed Um because typically the problem is big got slow So how fast is fast",
    "start": "2723280",
    "end": "2731280"
  },
  {
    "text": "Typically we have to see all the data and it's big and we also typically have",
    "start": "2731280",
    "end": "2736720"
  },
  {
    "text": "you know less math than the memory bandwidth it takes to drag the data in So if you're doing a logistic regression",
    "start": "2736720",
    "end": "2742800"
  },
  {
    "text": "you're doing a what's called a gram matrix It's a bunch of floatingoint ops for every row that comes in If you don't",
    "start": "2742800",
    "end": "2747839"
  },
  {
    "text": "have very many columns it's not that many floatingoint ops And the cache miss time from x86 to memory it far exceeds",
    "start": "2747839",
    "end": "2754560"
  },
  {
    "text": "the cost of doing a few floatingoint ops So you can decompress in the shadow of the memory",
    "start": "2754560",
    "end": "2760359"
  },
  {
    "start": "2759000",
    "end": "2811000"
  },
  {
    "text": "bandwidth right And more decompression is better or more compression is better because that means you got more data in",
    "start": "2760359",
    "end": "2766880"
  },
  {
    "text": "one cache miss So currently we have about 15 different compression schemes and we can drop another lin in half a",
    "start": "2766880",
    "end": "2772880"
  },
  {
    "text": "day or so Um and they vary all over the map Their obvious ones are just take the data without compression but then you",
    "start": "2772880",
    "end": "2779359"
  },
  {
    "text": "might do a bias and a scale off of a thing or you might say it's oh it's boolean only so it's a bit set or it's",
    "start": "2779359",
    "end": "2785280"
  },
  {
    "text": "very sparse data so there's a run length encoding going on There's a bunch of different compression strategies and uh the they're picked per",
    "start": "2785280",
    "end": "2792560"
  },
  {
    "text": "chunk We inspect all the data at the time we load it and decide on the best compression strategy for this few thousand rows and we keep varying them",
    "start": "2792560",
    "end": "2799040"
  },
  {
    "text": "as we go The only thing that's key there is all the decompression schemes take a couple clock cycles to go decompress the",
    "start": "2799040",
    "end": "2805839"
  },
  {
    "text": "data and then you can go do lots of time to do your math on it after that Um",
    "start": "2805839",
    "end": "2813160"
  },
  {
    "start": "2811000",
    "end": "2895000"
  },
  {
    "text": "serialization So serialization is this funny thing You might think with big data that serialization is a key issue",
    "start": "2813160",
    "end": "2820560"
  },
  {
    "text": "when you're dealing with a cluster and it is but for not for the obvious reason You can't send the big data across the",
    "start": "2820560",
    "end": "2826720"
  },
  {
    "text": "cluster or you're just going to drown an individual node in the data The assumption the guiding assumption you have to start out with is there's just",
    "start": "2826720",
    "end": "2832560"
  },
  {
    "text": "more data that's going to fit on your one machine So you just can't ask for it all in one machine and you don't want to pass it through the one machine either",
    "start": "2832560",
    "end": "2838079"
  },
  {
    "text": "You want to keep it in memory So you're not passing around the big data But you are passing around tons and tons of",
    "start": "2838079",
    "end": "2843839"
  },
  {
    "text": "small data things that are plain old Java objects that are part of doing your math They're accumulating histograms and",
    "start": "2843839",
    "end": "2849920"
  },
  {
    "text": "sums and variances they're building a gram matrix or they're building uh you know partial dependency graphs or whatever they're building they're doing",
    "start": "2849920",
    "end": "2855680"
  },
  {
    "text": "something with the math and that's getting passed around the cluster So we have to have a fast way to send POJO",
    "start": "2855680",
    "end": "2861200"
  },
  {
    "text": "around the cluster Since we already had a bite code weaver in place for a variety of reasons we went ahead and",
    "start": "2861200",
    "end": "2866720"
  },
  {
    "text": "threw in serialization in the bode weaver and it does sort of the fastest possible thing you can imagine It writes",
    "start": "2866720",
    "end": "2872240"
  },
  {
    "text": "the fields via unsafe directly into direct bite buffers um there's one two byte token at the start of any send of a",
    "start": "2872240",
    "end": "2879280"
  },
  {
    "text": "nested Java object that defines the entire layout of the whole thing and after that it's just the data and then",
    "start": "2879280",
    "end": "2884800"
  },
  {
    "text": "we compress that as well because typically we have more CPU than network bandwidth and so it's faster to compress",
    "start": "2884800",
    "end": "2890800"
  },
  {
    "text": "and send compression than it is to send the raw data The the direct bite buffer access",
    "start": "2890800",
    "end": "2897680"
  },
  {
    "start": "2895000",
    "end": "2985000"
  },
  {
    "text": "is all just uh loads and stores and nothing else There's no smarts in there at all It's literally take this field",
    "start": "2897680",
    "end": "2902960"
  },
  {
    "text": "and lift and store it um with compression as you went We write into streaming",
    "start": "2902960",
    "end": "2908839"
  },
  {
    "text": "asynchronous buffers There's multiple shared TCP channels Uh full app level",
    "start": "2908839",
    "end": "2914319"
  },
  {
    "text": "recovery retry You can pull a cable on a cluster and add it back back in five minutes later and things will just",
    "start": "2914319",
    "end": "2919839"
  },
  {
    "text": "recover Um we do make a decision to send small stuff via UDP and big stuff via",
    "start": "2919839",
    "end": "2926200"
  },
  {
    "text": "TCP and that's because there's a lot of small stuff and UDP is usually very very",
    "start": "2926200",
    "end": "2931280"
  },
  {
    "text": "reliable and it's much faster than TCP in that zone And it turns out that TCP",
    "start": "2931280",
    "end": "2936640"
  },
  {
    "text": "well everyone knows UDP is unreliable That's what the U is So we have to have a reliability layer for that Turns out",
    "start": "2936640",
    "end": "2942800"
  },
  {
    "text": "TCP is unreliable as well And in a couple minutes uh in my labs or EC2 or I",
    "start": "2942800",
    "end": "2949760"
  },
  {
    "text": "can cause TCP to fail And when I say fail I mean silently the sender will",
    "start": "2949760",
    "end": "2955599"
  },
  {
    "text": "open a socket write some data and close a socket and the receiver will get no data and no arrows will be thrown in either side The data will just go into",
    "start": "2955599",
    "end": "2961920"
  },
  {
    "text": "the bit bucket and be gone So you think of TCP as a reliable communication channel In fact it is not And that only",
    "start": "2961920",
    "end": "2968240"
  },
  {
    "text": "happens under heavy heavy load But I can drive that system to the maximum possible load you can get And under that",
    "start": "2968240",
    "end": "2974160"
  },
  {
    "text": "kind of scenarios TCP channels drop silently So I have a reliability layer built in for UDP and for TCP It's the",
    "start": "2974160",
    "end": "2981599"
  },
  {
    "text": "same layer Um a little bit more on map reduce",
    "start": "2981599",
    "end": "2989040"
  },
  {
    "start": "2985000",
    "end": "3102000"
  },
  {
    "text": "Uh a map call is made once per chunk Um typically they have a couple thousand per node You know more or less amount of",
    "start": "2989040",
    "end": "2995599"
  },
  {
    "text": "data you've loaded but if you've piled on a lot of data you'll have thousands Uh maybe millions and not millions",
    "start": "2995599",
    "end": "3001040"
  },
  {
    "text": "unless you got really big boxes Um and we're using fork join for the fine grain parallelism Um more on that in a minute",
    "start": "3001040",
    "end": "3007760"
  },
  {
    "text": "as well The reduction is a little different than the usual Hadoop reduction people think about Instead of",
    "start": "3007760",
    "end": "3013839"
  },
  {
    "text": "us running all our maps at up front and then saving the data to disk and then the shuffle and pull it all back and do",
    "start": "3013839",
    "end": "3019200"
  },
  {
    "text": "the reductions we don't ever go to disk So we reduce early and we reduce often",
    "start": "3019200",
    "end": "3026000"
  },
  {
    "text": "Every pair of maps when they're done immediately the reduction happens If another pair of maps are run and they",
    "start": "3026000",
    "end": "3031359"
  },
  {
    "text": "reduce when those two reduces are done they reduce again immediately So the reductions happen sort of incrementally",
    "start": "3031359",
    "end": "3037520"
  },
  {
    "text": "uh on the fly as the data is as the math is worked So you always keep the data size of your final result crunched down",
    "start": "3037520",
    "end": "3044000"
  },
  {
    "text": "to the smallest you can fit in memory uh you know subject to the constraints of running as much in parallel as you can",
    "start": "3044000",
    "end": "3050559"
  },
  {
    "text": "Once you're done doing all the reductions on a node it'll go of course over the wire and you get a log tree roll up People know what a log tree",
    "start": "3050559",
    "end": "3057040"
  },
  {
    "text": "rollup is every pair of nodes in the cluster uh consider themselves buddies",
    "start": "3057040",
    "end": "3063119"
  },
  {
    "text": "and and one of them is the parent of a tree and the two tree parents are buddies and go up again you get another",
    "start": "3063119",
    "end": "3069119"
  },
  {
    "text": "layer standard binary tree thing So that the time it takes to do a fast math pass",
    "start": "3069119",
    "end": "3076000"
  },
  {
    "text": "will be a log tree walk across the cluster then everyone does their math and a log tree walk back over and you'll",
    "start": "3076000",
    "end": "3082559"
  },
  {
    "text": "be network latency bound sort of the limiting and that's one of the reasons I went to UDP packets for small data if",
    "start": "3082559",
    "end": "3088880"
  },
  {
    "text": "you're doing a small roll up a small result like you're computing the averages and standard deviations or",
    "start": "3088880",
    "end": "3093920"
  },
  {
    "text": "linear regression kind of thing you're going to have a small result it's all going to run in UDP packets and that is your memory that is your latency on",
    "start": "3093920",
    "end": "3100079"
  },
  {
    "text": "getting that job Fork join experience",
    "start": "3100079",
    "end": "3106040"
  },
  {
    "start": "3102000",
    "end": "3157000"
  },
  {
    "text": "Um I had some some hard thoughts on this one Uh this is kind of fun stuff Fork",
    "start": "3106040",
    "end": "3113040"
  },
  {
    "text": "join sort of a new framework in Java 8 Um but it's been around for a long time and Doug Lee's been working on it for a",
    "start": "3113040",
    "end": "3119599"
  },
  {
    "text": "long time and I have a lot of respect for Doug and he's done some really great stuff and I think fork join really is",
    "start": "3119599",
    "end": "3124720"
  },
  {
    "text": "good but has some interesting gotchas to it Um the good stuff first So there's a",
    "start": "3124720",
    "end": "3130160"
  },
  {
    "text": "learning curve and once you're over it it's actually easy enough to write and use We use it all the time There must be",
    "start": "3130160",
    "end": "3136240"
  },
  {
    "text": "hundreds maybe a thousand or more uses of fork joins scattered throughout the code Um so it's fullfeatured it's",
    "start": "3136240",
    "end": "3142400"
  },
  {
    "text": "flexible it keeps you know all the CPUs busy I can have huge piles of tiny tiny",
    "start": "3142400",
    "end": "3147520"
  },
  {
    "text": "jobs running around or handfuls of big jobs It all seems to work really well So in that sense Fourth Joint's",
    "start": "3147520",
    "end": "3153720"
  },
  {
    "text": "good Some hard experience comes out of that um blocking threads while you're",
    "start": "3153720",
    "end": "3159440"
  },
  {
    "start": "3157000",
    "end": "3347000"
  },
  {
    "text": "running on fork join is hard on it because he has to realize a thread has been stolen for blocking usually in an",
    "start": "3159440",
    "end": "3166079"
  },
  {
    "text": "IO call and start another thread And so sometimes you get thread starvation issues and working around that somewhat",
    "start": "3166079",
    "end": "3172520"
  },
  {
    "text": "painful The recommended thing is to rewrite your code in a style uh that",
    "start": "3172520",
    "end": "3178079"
  },
  {
    "text": "uses what's called counted completers and now you're doing continuation passing styles How many people here know what continuation passing style is H oh",
    "start": "3178079",
    "end": "3185599"
  },
  {
    "text": "pretty good Okay Okay so third half um basically I'm writing continuation passing style in Java if I don't want to",
    "start": "3185599",
    "end": "3191440"
  },
  {
    "text": "have thread blocking issues and that's kind of painful to do Um you'll find that buried throughout the code that",
    "start": "3191440",
    "end": "3197040"
  },
  {
    "text": "happens in various key algorithms because it was just too hard to get it right and too painful to leave it",
    "start": "3197040",
    "end": "3202400"
  },
  {
    "text": "sitting the way it is Um there's no priority cues There's this one big fat happy queue in fork join But you have to",
    "start": "3202400",
    "end": "3209280"
  },
  {
    "text": "have thread priorities for a variety of reasons In particular if you got a web server and the web pages don't have any priority they can't service a page You",
    "start": "3209280",
    "end": "3216640"
  },
  {
    "text": "can't even get a status update you know a polling bar moving across your browser because you all CPUs are swamped doing",
    "start": "3216640",
    "end": "3222000"
  },
  {
    "text": "work The web server can't get a you know kind of clock in edge wise right So we built priority cues into the system Um",
    "start": "3222000",
    "end": "3229040"
  },
  {
    "text": "built over the fork join layer and that's also crucial in making the key value store go fast Um kind of buried",
    "start": "3229040",
    "end": "3236640"
  },
  {
    "text": "under the hood I think I think uh male mentioned it We have a key value store Uh I'll claim it's one of the fastest",
    "start": "3236640",
    "end": "3242880"
  },
  {
    "text": "ones on the planet I'd love to go measure that But a a cash hitting put or cash hitting get or 150 nanos basically",
    "start": "3242880",
    "end": "3250319"
  },
  {
    "text": "hasht lookup But a cash miss is uh going over the wire and back And to keep that",
    "start": "3250319",
    "end": "3256400"
  },
  {
    "text": "from causing a circular chain of cash missing asking for somebody else to do something around the cluster there's",
    "start": "3256400",
    "end": "3261520"
  },
  {
    "text": "priority cues built into the system for the key value store In exchange for that the KV store even when you cash miss is",
    "start": "3261520",
    "end": "3268720"
  },
  {
    "text": "uh nothing more than the direct NIO UDP socket back and forth round trip to kind",
    "start": "3268720",
    "end": "3274720"
  },
  {
    "text": "of get stuff done Um a few of the things I think uh",
    "start": "3274720",
    "end": "3282160"
  },
  {
    "text": "you got to pay attention to by default in fork join exceptions are silently",
    "start": "3282160",
    "end": "3287200"
  },
  {
    "text": "dropped the thread that takes an exception doing a piece of your work just like goes back to the idle queue",
    "start": "3287200",
    "end": "3293440"
  },
  {
    "text": "and like waits for the next job to show up And that usual symptom of that is he doesn't complete his job because he",
    "start": "3293440",
    "end": "3299520"
  },
  {
    "text": "threw an exception He doesn't tell anyone he didn't complete it because he just silently dropped it And and in the",
    "start": "3299520",
    "end": "3305599"
  },
  {
    "text": "end what happens is that all your threads suddenly go idle and the job's not done and we're all waiting for some last guy to complete something but he's",
    "start": "3305599",
    "end": "3311920"
  },
  {
    "text": "never going to It went away So you it's just a maintenance disaster you just have to catch and track and log all",
    "start": "3311920",
    "end": "3317359"
  },
  {
    "text": "exceptions and and so that when the scene hangs you can go back and look and see well who threw an exception So we",
    "start": "3317359",
    "end": "3323040"
  },
  {
    "text": "went a step further after that and said okay we're going to take all the logged exceptions and pass them around the cluster and roll them back up So they",
    "start": "3323040",
    "end": "3328960"
  },
  {
    "text": "get rethrown at the call site of the original map reduceuced task So somebody says new map reduce taskd doall of a",
    "start": "3328960",
    "end": "3334880"
  },
  {
    "text": "vector big math whatever fine that'll throw an exception at you that'll come back and say hey node yada yada yada",
    "start": "3334880",
    "end": "3340400"
  },
  {
    "text": "over there through this exception and here's his stack trace and it's it's just like a huge help in debugging",
    "start": "3340400",
    "end": "3345720"
  },
  {
    "text": "things Um try completes one of the key things to count right it's part of the",
    "start": "3345720",
    "end": "3350880"
  },
  {
    "start": "3347000",
    "end": "3412000"
  },
  {
    "text": "learning curve once you figure out how it works it's not so bad Um but in the beginning you'll blow the counts on try",
    "start": "3350880",
    "end": "3356319"
  },
  {
    "text": "completes too many or too few and jobs will complete out of order early or late or not at all so on so forth Um early on",
    "start": "3356319",
    "end": "3363280"
  },
  {
    "text": "when using fork join we did a lot of fork bombings of ourselves including the point where the CPU the the box was",
    "start": "3363280",
    "end": "3369119"
  },
  {
    "text": "unusable We had to reboot it Um so you just have to watch that Cap all your thread pools Uh and maybe throw warnings",
    "start": "3369119",
    "end": "3375359"
  },
  {
    "text": "out saying \"Hey hey somehow I'm asking to launch the thousandth thread Is this a good idea?\" Right And when you cap",
    "start": "3375359",
    "end": "3382400"
  },
  {
    "text": "thread pools you then can get into deadlock issues because all threads are actually blocked waiting for some other",
    "start": "3382400",
    "end": "3388640"
  },
  {
    "text": "event which is on another node whose all threads are blocked waiting event happening on your node And so in that situation uh you either have have to",
    "start": "3388640",
    "end": "3395440"
  },
  {
    "text": "have priority cues which fixes some of them or go to the CPS style to fix it again So anyhow despite all that I would",
    "start": "3395440",
    "end": "3402720"
  },
  {
    "text": "use fork join again um it it when it works it works really really well and",
    "start": "3402720",
    "end": "3407839"
  },
  {
    "text": "they're just these edge cases you got to know about to figure out how to to work around it Okay and that's actually the",
    "start": "3407839",
    "end": "3413680"
  },
  {
    "start": "3412000",
    "end": "3487000"
  },
  {
    "text": "end of my quick past few things I have some more Java examples which I can step through and I have some summary slides",
    "start": "3413680",
    "end": "3421119"
  },
  {
    "text": "So let's summaries real quick and then we'll go Q&A and I'll pull up other slides if people want them Um you know",
    "start": "3421119",
    "end": "3427119"
  },
  {
    "text": "the real summary here is that most simple Java just works in those map produced calls it it runs at memory",
    "start": "3427119",
    "end": "3433119"
  },
  {
    "text": "bandwidth speeds Um parallel distributed reads and writes and pins all just go",
    "start": "3433119",
    "end": "3438720"
  },
  {
    "text": "You can do conflicting writes Um and we'll follow the Java memory model which is pretty loosey goosey Uh so you might",
    "start": "3438720",
    "end": "3445119"
  },
  {
    "text": "not get what you want but it will be you know honestly the JMM um and we're writing big data analytics",
    "start": "3445119",
    "end": "3452559"
  },
  {
    "text": "state-of-the-art algorithms uh running distributed And this slide's now old I'd say that we're solid solidly working at",
    "start": "3452559",
    "end": "3459280"
  },
  {
    "text": "200 gig data sets and we have definitely tested uh terabyte size data sets before",
    "start": "3459280",
    "end": "3465280"
  },
  {
    "text": "So you know it's it's the big data and we're doing big math on the big data at",
    "start": "3465280",
    "end": "3471760"
  },
  {
    "text": "fast speeds and that's it [Applause]",
    "start": "3471760",
    "end": "3482909"
  }
]
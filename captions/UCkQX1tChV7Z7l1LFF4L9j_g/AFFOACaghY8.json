[
  {
    "text": "i'm very excited to share about some of the ways we're leveraging generative AI for productivity at well simple and the",
    "start": "10480",
    "end": "18560"
  },
  {
    "text": "journey that got us to this place uh so my talk's going to be roughly structured",
    "start": "18560",
    "end": "24320"
  },
  {
    "text": "and broken into four sections i'll start by sharing some context about what we do",
    "start": "24320",
    "end": "29920"
  },
  {
    "text": "uh we'll dive deeply into our LLM journey i'll talk also about the",
    "start": "29920",
    "end": "35040"
  },
  {
    "text": "learnings that came out of it and then we I'll end with sharing a quick snapshot overview of generative AI",
    "start": "35040",
    "end": "43079"
  },
  {
    "text": "today uh so let's get started so well simple is a Canadian",
    "start": "43079",
    "end": "49600"
  },
  {
    "text": "fintech company our mission is to help Canadians achieve their version of",
    "start": "49600",
    "end": "54800"
  },
  {
    "text": "financial independence and we do this through our unified app where uh",
    "start": "54800",
    "end": "60160"
  },
  {
    "text": "investing saving and spending comes together as one at Wells simple our generative AI",
    "start": "60160",
    "end": "67920"
  },
  {
    "text": "efforts are primarily organized into three streams the first is employee productivity this was the original",
    "start": "67920",
    "end": "75439"
  },
  {
    "text": "thesis of how we envision LLMs to add value and continues to be an area of",
    "start": "75439",
    "end": "81280"
  },
  {
    "text": "investment today as we started building up the foundations the tools the guard",
    "start": "81280",
    "end": "87200"
  },
  {
    "text": "rails for employee productivity this also gave us the confidence to start",
    "start": "87200",
    "end": "92640"
  },
  {
    "text": "extending the same technologies for our clients to actually optimize operations which becomes our second stream of",
    "start": "92640",
    "end": "100759"
  },
  {
    "text": "focus in oper in optimizing these operations our goal is to provide to use",
    "start": "100759",
    "end": "106159"
  },
  {
    "text": "LMS and generative AI to provide a more delightful experience for our clients",
    "start": "106159",
    "end": "111439"
  },
  {
    "text": "and third but certainly not least there's the underlying LLM platform which powers both employee productivity",
    "start": "111439",
    "end": "119200"
  },
  {
    "text": "and optimizing operations through the investments in our platform we have a few wins to share",
    "start": "119200",
    "end": "126000"
  },
  {
    "text": "in the past 1.5 years um since we've embarked on our LLM journey I'll go",
    "start": "126000",
    "end": "131200"
  },
  {
    "text": "through these really quickly but we'll dive deeper into them later on as well so we developed and open source our LLM",
    "start": "131200",
    "end": "138000"
  },
  {
    "text": "gateway which internally is used by over half the company um we developed and",
    "start": "138000",
    "end": "143120"
  },
  {
    "text": "shipped our in-house PI redaction model we made it really simple to self-host",
    "start": "143120",
    "end": "148560"
  },
  {
    "text": "open-source LLMs within our own cloud environments and we've provided the platform support for fine-tuning and",
    "start": "148560",
    "end": "155280"
  },
  {
    "text": "model training with hardware accelerations and we have LMS in production optimizing operations",
    "start": "155280",
    "end": "163280"
  },
  {
    "text": "so how did we get here i'm sure most of you in this room will remember but",
    "start": "163280",
    "end": "168959"
  },
  {
    "text": "almost two years ago on November 30th 2022 OpenAI released",
    "start": "168959",
    "end": "174280"
  },
  {
    "text": "ChatgBT and that changed the way the world understood and consumed generative",
    "start": "174280",
    "end": "179560"
  },
  {
    "text": "AI it took what used to be a niche and hard to understand technology and made",
    "start": "179560",
    "end": "186000"
  },
  {
    "text": "accessible by virtually anyone this democratization of AI led to",
    "start": "186000",
    "end": "191879"
  },
  {
    "text": "unprecedented improvements in both innovation and productivity and we were just one of the",
    "start": "191879",
    "end": "198159"
  },
  {
    "text": "many companies swept up in this hype and in the potential of what generative AI could do for",
    "start": "198159",
    "end": "204040"
  },
  {
    "text": "us the first thing that we did in 2023 was launching our LM gateway um when",
    "start": "204040",
    "end": "211760"
  },
  {
    "text": "chat GPT first became popularized the security awareness of from the general",
    "start": "211760",
    "end": "216799"
  },
  {
    "text": "public for fourth and thirdparty data sharing was not as mature as it was today there were cases where companies",
    "start": "216799",
    "end": "223680"
  },
  {
    "text": "were inadvertently oversharing information with open AAI and this information was then being used to train",
    "start": "223680",
    "end": "229360"
  },
  {
    "text": "new models that would become publicly available uh so as a result a lot of companies out there Samsung being one of",
    "start": "229360",
    "end": "235680"
  },
  {
    "text": "them had to actually ban chat GPT among employees um to prevent this information from getting out um and this this wasn't",
    "start": "235680",
    "end": "245680"
  },
  {
    "text": "uncommon especially within the financial services industry um but at well simple we really did see Genai for its",
    "start": "245680",
    "end": "252319"
  },
  {
    "text": "potential so we want so we quickly got to work building a gateway that would address these concerns while also",
    "start": "252319",
    "end": "257680"
  },
  {
    "text": "providing the freedom to explore uh so our gateway this is a screenshot",
    "start": "257680",
    "end": "264000"
  },
  {
    "text": "of what it used to look like in in the earlier days in the first version of our",
    "start": "264000",
    "end": "269040"
  },
  {
    "text": "gateway all it did was maintain an audit trail it would track what data was being sent externally where was it being sent",
    "start": "269040",
    "end": "276199"
  },
  {
    "text": "externally and who sent it and our gateway was a tool that we made",
    "start": "276199",
    "end": "281759"
  },
  {
    "text": "available for all employees behind VPN gated by octa um and it would proxy the information",
    "start": "281759",
    "end": "290720"
  },
  {
    "text": "from the conversations send it to various open to various LM providers such as OpenAI and track this",
    "start": "290720",
    "end": "298360"
  },
  {
    "text": "information uh users can leverage any of the a drop-own selection of the",
    "start": "298360",
    "end": "303759"
  },
  {
    "text": "different models um to initiate conversations our production systems",
    "start": "303759",
    "end": "309199"
  },
  {
    "text": "could also interact with these models programmatically through an API endpoint from our LLM service which also handles",
    "start": "309199",
    "end": "315840"
  },
  {
    "text": "retry and fallback mechanisms and another feature that we",
    "start": "315840",
    "end": "320880"
  },
  {
    "text": "added fairly early on in our gateway was the ability to export and import",
    "start": "320880",
    "end": "326039"
  },
  {
    "text": "conversations so conversations can be exported to any of the other platforms we work with and they can be imported as",
    "start": "326039",
    "end": "332960"
  },
  {
    "text": "checkpoints to create a blended experience across different models",
    "start": "332960",
    "end": "338960"
  },
  {
    "text": "so after we built the gateway we ran into another problem which was adoption",
    "start": "339919",
    "end": "346320"
  },
  {
    "text": "a lot of people saw our gateway as a bootleg version of chat GBT and there wasn't that much incentive to use it um",
    "start": "346320",
    "end": "353360"
  },
  {
    "text": "one of our philosophies at Walth Simple um is whenever it comes to new",
    "start": "353360",
    "end": "358960"
  },
  {
    "text": "technologies or new tools we want to make the right way the simple way or the",
    "start": "358960",
    "end": "365360"
  },
  {
    "text": "the right way the path of least resistance and we wanted to do something similar with our gateway as well we",
    "start": "365360",
    "end": "371840"
  },
  {
    "text": "wanted people to actually want to use it and we wanted to make it really really easy for people to use it so we",
    "start": "371840",
    "end": "379840"
  },
  {
    "text": "emphasized and amplified a series of sticks and carrots to kind of guide them towards that d direction um there was a",
    "start": "379840",
    "end": "388000"
  },
  {
    "text": "lot of emphasis on the carrots and we let a lot of the user feedback drive future iterations of our gateway um some",
    "start": "388000",
    "end": "395919"
  },
  {
    "text": "of the benefits of our gateway is that one it's free to use we pay for all of",
    "start": "395919",
    "end": "401280"
  },
  {
    "text": "the cost um second we want to provide optionality we wanted to pro provide the",
    "start": "401280",
    "end": "407840"
  },
  {
    "text": "centralized place to interact with all of the LLMs all of the different LLM providers",
    "start": "407840",
    "end": "414160"
  },
  {
    "text": "at the beginning it was just open AI and cohhere so not much to choose from but this list also expanded as time went on",
    "start": "414160",
    "end": "421759"
  },
  {
    "text": "we also wanted to make it a lot easier for developers in the early days of interacting with OpenAI their servers",
    "start": "421759",
    "end": "428000"
  },
  {
    "text": "were not the most reliable so we increased reliability availability through a series of retry and fallback",
    "start": "428000",
    "end": "434639"
  },
  {
    "text": "mechanisms and we actually worked with OpenAI to increase our rate limits as well and additionally we provided an",
    "start": "434639",
    "end": "441520"
  },
  {
    "text": "integrated API with both our staging and production environments so that anyone can explore the interactions between our",
    "start": "441520",
    "end": "448560"
  },
  {
    "text": "gateway and other business processes alongside those carrots we",
    "start": "448560",
    "end": "454160"
  },
  {
    "text": "also had some very soft sticks to nudge people into the right direction the first is what we called these nudge",
    "start": "454160",
    "end": "460360"
  },
  {
    "text": "mechanisms so whenever anyone visited chat GBT or another LM provider directly",
    "start": "460360",
    "end": "466400"
  },
  {
    "text": "they would get a gentle nudge on Slack saying \"Hey have you heard about our LM gateway you should be using that",
    "start": "466400",
    "end": "473800"
  },
  {
    "text": "instead.\" And alongside that we provided guidelines on a on an appropriate LLM",
    "start": "473800",
    "end": "480319"
  },
  {
    "text": "use which directed people to leverage the gateway for all workrelated purposes",
    "start": "480319",
    "end": "487319"
  },
  {
    "text": "although the first iteration of our LM gateway um although it had a really great paper trail u it offered very",
    "start": "488720",
    "end": "496479"
  },
  {
    "text": "little guard rails and mechanisms to actually prevent data from being shared",
    "start": "496479",
    "end": "501960"
  },
  {
    "text": "externally um but we had a vision that we were working towards and that that",
    "start": "501960",
    "end": "509759"
  },
  {
    "text": "drove a lot of the future roadmap and the improvements for our gateway um our",
    "start": "509759",
    "end": "515360"
  },
  {
    "text": "vision was centered around security reliability and optionality uh we wanted",
    "start": "515360",
    "end": "521440"
  },
  {
    "text": "our vision for the gateway was was to provide to make the secure path the easy",
    "start": "521440",
    "end": "526480"
  },
  {
    "text": "path by prevent um with the gu appropriate guardrails to prevent sharing sensitive information with",
    "start": "526480",
    "end": "531600"
  },
  {
    "text": "thirdparty LLM providers we wanted to make it highly available and then again",
    "start": "531600",
    "end": "536800"
  },
  {
    "text": "provide the options of multiple LLM providers to choose from and in building off of those",
    "start": "536800",
    "end": "543519"
  },
  {
    "text": "enablement philosophies the very next thing we shipped in June of 2023 was our",
    "start": "543519",
    "end": "548880"
  },
  {
    "text": "own PI redaction model so we leveraged Microsoft procedurals framework along",
    "start": "548880",
    "end": "555519"
  },
  {
    "text": "with an NE model we we developed internally to detect and redact any",
    "start": "555519",
    "end": "560959"
  },
  {
    "text": "potentially sensitive information prior to sending to OpenAI or any external LM",
    "start": "560959",
    "end": "566399"
  },
  {
    "text": "providers so here's a screenshot of our uh PI reduction model in in action so I",
    "start": "566399",
    "end": "573680"
  },
  {
    "text": "I asked um so I provide this dummy phone number i would like you to give me a",
    "start": "573680",
    "end": "578880"
  },
  {
    "text": "call at this number and this number is recognized by our PII reduction model as",
    "start": "578880",
    "end": "584959"
  },
  {
    "text": "being potentially sensitive PII so it actually gets redacted prior to being sent to the external provider",
    "start": "584959",
    "end": "593959"
  },
  {
    "text": "what was interesting is that with the PI redaction model while we closed a gap in",
    "start": "595200",
    "end": "601320"
  },
  {
    "text": "security we actually introduced a different gap in the user",
    "start": "601320",
    "end": "607160"
  },
  {
    "text": "experience one of the feedback that we heard from a lot of people is that one",
    "start": "607160",
    "end": "612480"
  },
  {
    "text": "the PI reduction model is not always accurate so a lot of the times it interfered with the accuracy or the",
    "start": "612480",
    "end": "618480"
  },
  {
    "text": "relevancies of the answers provided and two for them to act to to effectively",
    "start": "618480",
    "end": "624640"
  },
  {
    "text": "leverage LLM in their day-to-day work it needs to be able to accept some degree",
    "start": "624640",
    "end": "630320"
  },
  {
    "text": "of PII because that fundamentally was the data that they worked with and for us in going back to our",
    "start": "630320",
    "end": "638240"
  },
  {
    "text": "philosophy of making the right way the easy way uh we started to look into",
    "start": "638240",
    "end": "643399"
  },
  {
    "text": "self-hosted into self-hosting open-source LMS the idea was that by uh",
    "start": "643399",
    "end": "649200"
  },
  {
    "text": "hosting these LLMs within our own VPCs we didn't have to run the PI redaction",
    "start": "649200",
    "end": "654880"
  },
  {
    "text": "model we could encourage people to send any information to these models because the data would stay within our cloud",
    "start": "654880",
    "end": "661720"
  },
  {
    "text": "environments so we spent the next month building a simple framework using Llama",
    "start": "661720",
    "end": "667600"
  },
  {
    "text": "CPP a quantized framework for uh host for self-hosting open source LLMs the",
    "start": "667600",
    "end": "674160"
  },
  {
    "text": "first three models that we started self-hosting was Llama it was Llama 2 at the time um the Mistro models and also",
    "start": "674160",
    "end": "681760"
  },
  {
    "text": "Whisper which OpenAI had open source so I know technically Whisper is not an LLM",
    "start": "681760",
    "end": "686880"
  },
  {
    "text": "um it's the voice transcription model but for uh but like for simplicity we",
    "start": "686880",
    "end": "693040"
  },
  {
    "text": "included in the umbrella of our LLM",
    "start": "693040",
    "end": "697040"
  },
  {
    "text": "platform after introducing these self-hosted LMS we made a fast follow by",
    "start": "698680",
    "end": "705200"
  },
  {
    "text": "introducing retrieval augmented generation as an API which also included a very deliberate choice of our vector",
    "start": "705200",
    "end": "712240"
  },
  {
    "text": "database we heard from a lot of the feedback and",
    "start": "712240",
    "end": "717600"
  },
  {
    "text": "we saw in a lot both industry trends and the use cases that the most powerful use",
    "start": "717600",
    "end": "722720"
  },
  {
    "text": "the power most powerful use cases of LLMs involved grounding it against",
    "start": "722720",
    "end": "728480"
  },
  {
    "text": "context that was relevant to the company so in making these in similar",
    "start": "728480",
    "end": "735360"
  },
  {
    "text": "investments within our LLM platform we first introduced elastic search as our vector database",
    "start": "735360",
    "end": "742240"
  },
  {
    "text": "uh we built um pipelines and DEGs and Airflow our orchestration framework to",
    "start": "742240",
    "end": "749079"
  },
  {
    "text": "update and index our common knowledge bases and we offered a very simple",
    "start": "749079",
    "end": "754560"
  },
  {
    "text": "semantic search as an AP as a as our first rag API",
    "start": "754560",
    "end": "760399"
  },
  {
    "text": "we encouraged our we encouraged our developers we encouraged our end users to build upon these APIs and building",
    "start": "760399",
    "end": "767360"
  },
  {
    "text": "blocks that we provided in order to leverage LLM's grounded against our",
    "start": "767360",
    "end": "772480"
  },
  {
    "text": "company context what we found very interesting was that",
    "start": "772480",
    "end": "779839"
  },
  {
    "text": "even though h grounding was one of the things that a lot of our end users asked for even though intuitively it made",
    "start": "779839",
    "end": "786639"
  },
  {
    "text": "sense as a useful building block within our platform the engagement adoption was",
    "start": "786639",
    "end": "792079"
  },
  {
    "text": "actually very low people were not expanding um our knowledge bases as we",
    "start": "792079",
    "end": "797839"
  },
  {
    "text": "thought they would they were not extending their APIs there was very little exploration to be done and we",
    "start": "797839",
    "end": "803120"
  },
  {
    "text": "realized that we probably didn't make this easy enough we there was still a gap when it came to experimentation",
    "start": "803120",
    "end": "810399"
  },
  {
    "text": "there was still a gap when it came to exploration and it was hard for people to get feedback on the LLM and Genai",
    "start": "810399",
    "end": "817360"
  },
  {
    "text": "products that they were building and in um and in recognizing that one of the",
    "start": "817360",
    "end": "824639"
  },
  {
    "text": "next things that we invested in was what we called our data applications platform",
    "start": "824639",
    "end": "830079"
  },
  {
    "text": "so we built an internal service um it runs on Python and Streamlit we chose",
    "start": "830079",
    "end": "835920"
  },
  {
    "text": "that stack because it's easy to use um and it's something a lot of our data scientists were familiar with and once",
    "start": "835920",
    "end": "842959"
  },
  {
    "text": "again we made this um we put this behind OctaB made it available um behind our VPNs and created what was essentially a",
    "start": "842959",
    "end": "850560"
  },
  {
    "text": "platform that was very easy to build new applications and iterate on those applications",
    "start": "850560",
    "end": "857040"
  },
  {
    "text": "uh the idea was that data scientists and developers or really anyone who who",
    "start": "857040",
    "end": "863120"
  },
  {
    "text": "could who was interested and willing to get a little bit technical um they were able to build and their own applications",
    "start": "863120",
    "end": "870560"
  },
  {
    "text": "have it run on our data applications platform and create this very fast feedback loop for to share with",
    "start": "870560",
    "end": "877120"
  },
  {
    "text": "stakeholders get feedback and in a lot of the cases these proof of concept applications expanded into something",
    "start": "877120",
    "end": "883839"
  },
  {
    "text": "much bigger within just the first two weeks of launching our data application",
    "start": "883839",
    "end": "889600"
  },
  {
    "text": "platform we had over seven applications running on it and of those seven two of",
    "start": "889600",
    "end": "895040"
  },
  {
    "text": "them eventually made it into production where they're adding value and in optimizing operations and creating a",
    "start": "895040",
    "end": "902160"
  },
  {
    "text": "more delightful client experience so with the introduction of",
    "start": "902160",
    "end": "909680"
  },
  {
    "text": "our data applications platform our LLM platform was also starting to come",
    "start": "909680",
    "end": "914959"
  },
  {
    "text": "together so this is a very highlevel diagram of what it looks like in the",
    "start": "914959",
    "end": "920880"
  },
  {
    "text": "first role we have a lot of our contextual data our knowledge bases is being ingested through our airflow des",
    "start": "920880",
    "end": "927600"
  },
  {
    "text": "um to our embedding models and then update and index in elastic search uh we've also chose lang chain um as to",
    "start": "927600",
    "end": "935600"
  },
  {
    "text": "orchestrate our data applications which sits very closely with both our data applications platform and our LLM",
    "start": "935600",
    "end": "942560"
  },
  {
    "text": "service and then we have the API for our LM gateway through our LM service",
    "start": "942560",
    "end": "948240"
  },
  {
    "text": "tightly integrated within our production",
    "start": "948240",
    "end": "952639"
  },
  {
    "text": "environments as our LM platform came together uh we started also building",
    "start": "954199",
    "end": "961600"
  },
  {
    "text": "tools uh internal tools that we thought would be very powerful for employee productivity",
    "start": "961600",
    "end": "968040"
  },
  {
    "text": "uh the at the end of 2023 we built a tool we call booster pack which kind of",
    "start": "968040",
    "end": "974639"
  },
  {
    "text": "com which combines a lot of the reusable building blocks that I mentioned earlier and the idea of booster pack is we",
    "start": "974639",
    "end": "981839"
  },
  {
    "text": "wanted to provide a personal assistant grounded against well simple context for",
    "start": "981839",
    "end": "987120"
  },
  {
    "text": "all of our employees we want to run this on our cloud infrastructure with three different types of knowledge bases uh",
    "start": "987120",
    "end": "994240"
  },
  {
    "text": "the first being public knowledge bases which was accessessible to everyone at the company with source code help",
    "start": "994240",
    "end": "1000000"
  },
  {
    "text": "articles and financial newsletters uh the second would be a private knowledge base for each employee where they can",
    "start": "1000000",
    "end": "1006160"
  },
  {
    "text": "store and query their own personal documents and the third is a limited knowledge base that can be shared with a",
    "start": "1006160",
    "end": "1012079"
  },
  {
    "text": "limited set of co-workers delineated by role and projects and this is what we call the wells simple booster pack i",
    "start": "1012079",
    "end": "1019839"
  },
  {
    "text": "have a short video of what it looks like",
    "start": "1019839",
    "end": "1025399"
  },
  {
    "text": "so once so the the uh so booster pack was one of the applications we actually built on top of our data applications",
    "start": "1026240",
    "end": "1033199"
  },
  {
    "text": "platform and in this recording I'm uploading a file a study of the economic",
    "start": "1033199",
    "end": "1038720"
  },
  {
    "text": "um benefits and productivity through AI adding this to a private knowledge base",
    "start": "1038720",
    "end": "1043839"
  },
  {
    "text": "for myself and once this knowledge base is created I can leverage the chat functionality to ask ask questions about",
    "start": "1043839",
    "end": "1052960"
  },
  {
    "text": "This video is slightly sped",
    "start": "1062240",
    "end": "1065679"
  },
  {
    "text": "up and alongside the um question like answering um functionalities we also",
    "start": "1072039",
    "end": "1078960"
  },
  {
    "text": "provided a source and this was really um effective especially when it came to know like documents as a part of our",
    "start": "1078960",
    "end": "1085760"
  },
  {
    "text": "knowledge bases um you could actually see where the answer was sourced from and the link would take you there so if",
    "start": "1085760",
    "end": "1092000"
  },
  {
    "text": "you wanted to do any factchecking or further",
    "start": "1092000",
    "end": "1096159"
  },
  {
    "text": "reading so 2023 ended oh sorry to this video is playing",
    "start": "1098200",
    "end": "1108000"
  },
  {
    "text": "again so 2023 ended with a lot of excitement you know we rounded the year",
    "start": "1110919",
    "end": "1116720"
  },
  {
    "text": "off um by introducing our LLM gateway introducing self-hosted models um providing in rag API and building a data",
    "start": "1116720",
    "end": "1124240"
  },
  {
    "text": "applications platform and we ended the year off by building what we thought would be like one of our coolest",
    "start": "1124240",
    "end": "1130000"
  },
  {
    "text": "internal tools ever um and we were in a bit of a shock when it came to 2024 so",
    "start": "1130000",
    "end": "1137200"
  },
  {
    "text": "this graph this is this is uh Gartner's hype cycle which maps out the ch",
    "start": "1137200",
    "end": "1143120"
  },
  {
    "text": "evolution of expectations um and changes when it comes to emerging",
    "start": "1143120",
    "end": "1148559"
  },
  {
    "text": "technologies so this is very relevant especially for generative AI which in",
    "start": "1148559",
    "end": "1154080"
  },
  {
    "text": "2023 for most of us we were entering this peak of inflated expectations we were so excited about",
    "start": "1154080",
    "end": "1161360"
  },
  {
    "text": "what LLMs could do for us we weren't exactly sure um in concrete ways or like",
    "start": "1161360",
    "end": "1167280"
  },
  {
    "text": "or how we could where the business alignment came from but we had the",
    "start": "1167280",
    "end": "1172559"
  },
  {
    "text": "confidence we wanted to make big bets in this space on the other hand as we were",
    "start": "1172559",
    "end": "1177760"
  },
  {
    "text": "entering 2024 it was kind of sobering for us as a company and for the industry as a whole too uh we realized that not",
    "start": "1177760",
    "end": "1185760"
  },
  {
    "text": "all of our bets had paid off that in some cases we may have indexed a little bit too much into investments for",
    "start": "1185760",
    "end": "1193039"
  },
  {
    "text": "generative AI or building tools for Gen AI and what this meant for us for wealth",
    "start": "1193039",
    "end": "1199440"
  },
  {
    "text": "simple in particular was we our strategy evolved to be a lot more deliberate we",
    "start": "1199440",
    "end": "1205919"
  },
  {
    "text": "started focusing a lot more on the business alignment and on how we can get business alignment with our generative",
    "start": "1205919",
    "end": "1212880"
  },
  {
    "text": "AI applications there was less appetite for bets there were less appetite for",
    "start": "1212880",
    "end": "1219360"
  },
  {
    "text": "let's see what happens if we swap this out for one of the best performing models and we became a lot more",
    "start": "1219360",
    "end": "1226400"
  },
  {
    "text": "deliberate and nuance in our strategy as a whole",
    "start": "1226400",
    "end": "1232159"
  },
  {
    "text": "so in 2024 we actually spent a big chunk of time at the beginning of the year",
    "start": "1232159",
    "end": "1237400"
  },
  {
    "text": "just going back to our strategy talking to end users and thinking really deeply",
    "start": "1237400",
    "end": "1243039"
  },
  {
    "text": "about the intersection between generative AI and the values our business cared about",
    "start": "1243039",
    "end": "1250440"
  },
  {
    "text": "so we were a bit So the first thing we actually did as a part of our LM journey concretely in 2024 was we unshipped",
    "start": "1251520",
    "end": "1258799"
  },
  {
    "text": "something we built in 2023 so when we first launched our LM",
    "start": "1258799",
    "end": "1264400"
  },
  {
    "text": "gateway we introduced the nudge mechanisms which were the gentle slack reminders for anyone not using our",
    "start": "1264400",
    "end": "1270919"
  },
  {
    "text": "gateway um long story short it wasn't working we found very little evidence",
    "start": "1270919",
    "end": "1277440"
  },
  {
    "text": "that the nudges were affecting and changing behavior um people who were",
    "start": "1277440",
    "end": "1282799"
  },
  {
    "text": "getting nudged it was the same people getting nudged over and over again and they were became conditioned to ignore",
    "start": "1282799",
    "end": "1288559"
  },
  {
    "text": "it instead what we found was that improvements to the platform itself um",
    "start": "1288559",
    "end": "1294400"
  },
  {
    "text": "was a much stronger indicator for behavioral changes so we got rid of these mechanisms because they weren't",
    "start": "1294400",
    "end": "1300559"
  },
  {
    "text": "working and they were just causing noise",
    "start": "1300559",
    "end": "1304840"
  },
  {
    "text": "following that um in in May in in May of this year we",
    "start": "1306799",
    "end": "1313280"
  },
  {
    "text": "started looking into ways uh we started expanding the LM providers that we wanted to offer um this the catalyst for",
    "start": "1313280",
    "end": "1320799"
  },
  {
    "text": "this was Gemini so around that time Gemini had uh launched had launched",
    "start": "1320799",
    "end": "1327039"
  },
  {
    "text": "their 1 million uh token context window models and this was later replaced by",
    "start": "1327039",
    "end": "1332159"
  },
  {
    "text": "the two plus million ones and we were really interested to see what this could do for us and how it could circumvent a",
    "start": "1332159",
    "end": "1339520"
  },
  {
    "text": "lot of our previous challenges with the context window limitations uh so we spend some a lot of time thinking",
    "start": "1339520",
    "end": "1347320"
  },
  {
    "text": "about our the providers we the providers we wanted to offer and building the",
    "start": "1347320",
    "end": "1353200"
  },
  {
    "text": "foundations and building blocks to first introduce Gemini but eventually other providers as",
    "start": "1353200",
    "end": "1360399"
  },
  {
    "text": "well a big part of 2024 has also been about keeping up with the latest trends",
    "start": "1360840",
    "end": "1366960"
  },
  {
    "text": "in the industry um in 2023 a lot of our time and energy were spent on making",
    "start": "1366960",
    "end": "1373440"
  },
  {
    "text": "sure we had this best state-of-the-art model available on our platform but we",
    "start": "1373440",
    "end": "1379760"
  },
  {
    "text": "realized that this was quickly a losing battle because the state-of-the-art models were evolving they were changing",
    "start": "1379760",
    "end": "1385440"
  },
  {
    "text": "every week or every few weeks so that strategy shifted in 2024 where",
    "start": "1385440",
    "end": "1391120"
  },
  {
    "text": "instead of focusing on the models itself we took a step back and focused higher",
    "start": "1391120",
    "end": "1396960"
  },
  {
    "text": "level on the trends and one of the emerging trends that come out this year was multimodal inputs like who knew you",
    "start": "1396960",
    "end": "1405039"
  },
  {
    "text": "could have even less frictionful mediums of interacting with generative AI forget",
    "start": "1405039",
    "end": "1410880"
  },
  {
    "text": "about text now we can send a file or a picture and this was something that",
    "start": "1410880",
    "end": "1416559"
  },
  {
    "text": "caught on really quickly within our company so le this we started out by le",
    "start": "1416559",
    "end": "1424240"
  },
  {
    "text": "leveraging Gemini's multimmoto fe uh capabilities uh we added a feature",
    "start": "1424240",
    "end": "1429360"
  },
  {
    "text": "within our gateway where people where our end users could upload either an image or a PDF and the LN would be able",
    "start": "1429360",
    "end": "1437039"
  },
  {
    "text": "to drive the conversation with um understanding what was being",
    "start": "1437039",
    "end": "1443320"
  },
  {
    "text": "sent and over within the first few weeks um",
    "start": "1443320",
    "end": "1450320"
  },
  {
    "text": "within the first few weeks of launching this close to a third of all of our end users started leveraging",
    "start": "1450320",
    "end": "1457520"
  },
  {
    "text": "uh started leveraging our multimodal feature at least once a week and one of",
    "start": "1457520",
    "end": "1462559"
  },
  {
    "text": "the most common use cases we found was um when people were running into issues with our internal tools um when they",
    "start": "1462559",
    "end": "1469600"
  },
  {
    "text": "were running into programming um program errors or even like errors working with",
    "start": "1469600",
    "end": "1475039"
  },
  {
    "text": "our BI tool um so as humans we find it like if some if",
    "start": "1475039",
    "end": "1482880"
  },
  {
    "text": "if you're a developer and someone sends you a screenshot of their stack trace",
    "start": "1482880",
    "end": "1488240"
  },
  {
    "text": "like that's an anti pattern we would want to get the text copy of it and",
    "start": "1488240",
    "end": "1493600"
  },
  {
    "text": "where humans offered very little patience for that of thing that sort of things LLMs embraced it and pretty soon",
    "start": "1493600",
    "end": "1501279"
  },
  {
    "text": "we were actually seeing behavioral changes in the way people communicate because LLM's multimodal inputs made it",
    "start": "1501279",
    "end": "1508000"
  },
  {
    "text": "so easy to just throw a screenshot throw a message um a lot of people were doing",
    "start": "1508000",
    "end": "1513440"
  },
  {
    "text": "it fairly often this may not necessarily be one of the good things to come out of it but the silver lining is we did",
    "start": "1513440",
    "end": "1520480"
  },
  {
    "text": "provide a very simple way for people to get the help they needed in the medium they needed so here is an example of an",
    "start": "1520480",
    "end": "1527679"
  },
  {
    "text": "error someone encountered in like when working with our BI tool and this is a fairly simple error um if you ask our",
    "start": "1527679",
    "end": "1535200"
  },
  {
    "text": "gateway hey I keep running into this error message while refreshing my SQL dashboard what does this mean it",
    "start": "1535200",
    "end": "1541520"
  },
  {
    "text": "actually provides a fairly detailed list of how to diagnose the problem now of",
    "start": "1541520",
    "end": "1547120"
  },
  {
    "text": "course you could get the same results by just copying and pasting it um but for a lot of our less technical users it's a",
    "start": "1547120",
    "end": "1554400"
  },
  {
    "text": "little bit hard sometimes to distinguish the actual mer error message from the full full result",
    "start": "1554400",
    "end": "1562360"
  },
  {
    "text": "so after launching um multimodto after supporting multimodto inputs the next",
    "start": "1565120",
    "end": "1571840"
  },
  {
    "text": "thing we actually added to our platform was bedrock and bedrock was a very",
    "start": "1571840",
    "end": "1577440"
  },
  {
    "text": "interesting addition because this marked a shift in our build versus buy strategy",
    "start": "1577440",
    "end": "1583600"
  },
  {
    "text": "so bedrock is AWS's managed service for interacting um with foundational large",
    "start": "1583600",
    "end": "1590480"
  },
  {
    "text": "language models and it also in provides the ability to deploy and fine-tune",
    "start": "1590480",
    "end": "1595840"
  },
  {
    "text": "these models at scale so there was a very there was a very big overlap between everything we've been building",
    "start": "1595840",
    "end": "1602080"
  },
  {
    "text": "internally and what Bedrock had to offer",
    "start": "1602080",
    "end": "1606919"
  },
  {
    "text": "we had actually considered Bedrock back in 2023 but um said no but said no to it in",
    "start": "1608000",
    "end": "1615679"
  },
  {
    "text": "favor of building up a lot of these capabilities ourselves our motivation at that time was so that we could build up",
    "start": "1615679",
    "end": "1622799"
  },
  {
    "text": "the confidence the knowhow internally to deploy these technologies at scale",
    "start": "1622799",
    "end": "1629120"
  },
  {
    "text": "but with 2024 being a very different year uh this was al this was also a good",
    "start": "1629120",
    "end": "1634480"
  },
  {
    "text": "inflection point for us as we shifted and re-evaluated our build versus buy",
    "start": "1634480",
    "end": "1639880"
  },
  {
    "text": "strategy so these the three points I have here on the slides are top",
    "start": "1639880",
    "end": "1645600"
  },
  {
    "text": "considerations when it comes to build versus buy the first is that we have a baseline requirement for security and",
    "start": "1645600",
    "end": "1652080"
  },
  {
    "text": "privacy if we wanted to buy something they need to be meet that the second is the",
    "start": "1652080",
    "end": "1660640"
  },
  {
    "text": "consideration of time to market and cost and then third this was something",
    "start": "1660640",
    "end": "1666720"
  },
  {
    "text": "that changed a lot between 2023 and 2024 was in considering and evaluating our",
    "start": "1666720",
    "end": "1672720"
  },
  {
    "text": "unique points of leverage otherwise known as the opportunity cost of building something as opposed to buying",
    "start": "1672720",
    "end": "1679360"
  },
  {
    "text": "it there were a lot of trends that drove",
    "start": "1679360",
    "end": "1685360"
  },
  {
    "text": "the evolution of these strategies and these thinking the first was that",
    "start": "1685360",
    "end": "1690799"
  },
  {
    "text": "vendors and LM providers their security awareness got a lot better over time you",
    "start": "1690799",
    "end": "1697200"
  },
  {
    "text": "know LM providers were offering u mechanisms for zero day data integr uh",
    "start": "1697200",
    "end": "1702320"
  },
  {
    "text": "retention they were becoming a lot more integrated with like cloud providers um",
    "start": "1702320",
    "end": "1708240"
  },
  {
    "text": "and they and they had learned a lot from the risks and the pitfalls of the",
    "start": "1708240",
    "end": "1713600"
  },
  {
    "text": "previous year to know that consumers cared about these things",
    "start": "1713600",
    "end": "1720000"
  },
  {
    "text": "the second trend that we've seen um and this was something that affected us more a lot more internally is that as we got",
    "start": "1720000",
    "end": "1727279"
  },
  {
    "text": "a better understanding of generative AI it also meant we had a better understanding of how to apply it in ways",
    "start": "1727279",
    "end": "1733279"
  },
  {
    "text": "to add value to increase business alignment and oftent",
    "start": "1733279",
    "end": "1738360"
  },
  {
    "text": "times getting the most value out of our work is not by building genai tools that",
    "start": "1738360",
    "end": "1744320"
  },
  {
    "text": "exist on the marketplace it's by looking deeply into what we need as a business",
    "start": "1744320",
    "end": "1750640"
  },
  {
    "text": "and understanding and evaluating the intersections with generative AI",
    "start": "1750640",
    "end": "1756200"
  },
  {
    "text": "there so both of these points actually shifted our strategy to to what was",
    "start": "1756200",
    "end": "1763840"
  },
  {
    "text": "initially very build for focused to being a lot more buy focused",
    "start": "1763840",
    "end": "1770960"
  },
  {
    "text": "um the last point I'll mention which makes this whole thing a lot more nuanced is that you know over the past",
    "start": "1770960",
    "end": "1778399"
  },
  {
    "text": "year year to two years a lot more vendors both existing and new are offering genai",
    "start": "1778399",
    "end": "1786520"
  },
  {
    "text": "integrations for almost every almost almost every single SAS product has like a AI add-on now and they all cost money",
    "start": "1786520",
    "end": "1794799"
  },
  {
    "text": "and one analogy we like to use internally is this is really similar to the streaming versus cable paradigm time",
    "start": "1794799",
    "end": "1801120"
  },
  {
    "text": "where once upon a time you know getting Netflix or getting um getting Netflix",
    "start": "1801120",
    "end": "1807279"
  },
  {
    "text": "was very econ was a very economical decision when contrasted against the cost of cable but today with all of the",
    "start": "1807279",
    "end": "1813760"
  },
  {
    "text": "streaming services you can easily be paying a lot more for that than what you had initially been paying for cable and",
    "start": "1813760",
    "end": "1821360"
  },
  {
    "text": "we found ourselves running into a similar predicament when evaluating all of these additional Genai offerings",
    "start": "1821360",
    "end": "1828320"
  },
  {
    "text": "provided by our vendors so all that is to say is the decision for build versus",
    "start": "1828320",
    "end": "1834320"
  },
  {
    "text": "buy has gone a lot more nuanced today than it was even a year ago um we're",
    "start": "1834320",
    "end": "1839360"
  },
  {
    "text": "certainly more open to buying but there are a lot of considerations on making sure we're buying the right tools that",
    "start": "1839360",
    "end": "1845440"
  },
  {
    "text": "add value and not just providing duplicate value",
    "start": "1845440",
    "end": "1850760"
  },
  {
    "text": "so after adopting Bedrock um we turned our attentions to the internal uh to the",
    "start": "1853600",
    "end": "1861279"
  },
  {
    "text": "API that we offered for interacting with our LM gateway when we first put",
    "start": "1861279",
    "end": "1867919"
  },
  {
    "text": "together our gateway when when we first shipped our gateway when we first offered this API uh we didn't think too",
    "start": "1867919",
    "end": "1875360"
  },
  {
    "text": "deeply about what the structure would look like and this ended up being a decision that we would",
    "start": "1875360",
    "end": "1880760"
  },
  {
    "text": "regret as OpenAI's API specs become became the gold standard we ran into a",
    "start": "1880760",
    "end": "1887760"
  },
  {
    "text": "lot of headaches with integrations we had to monkey patch and rewrite a lot of",
    "start": "1887760",
    "end": "1894159"
  },
  {
    "text": "code from Langchain and other libraries and frameworks because we didn't offer a",
    "start": "1894159",
    "end": "1899360"
  },
  {
    "text": "compatible API structure so we took some time in September of this year to ship",
    "start": "1899360",
    "end": "1906000"
  },
  {
    "text": "V2 of our API which did mirror the OpenAI's API specs and the lesson we",
    "start": "1906000",
    "end": "1912880"
  },
  {
    "text": "learned here was that um it's important to think about as this industry as the",
    "start": "1912880",
    "end": "1919440"
  },
  {
    "text": "tools and frameworks within Genai with geni",
    "start": "1919440",
    "end": "1924679"
  },
  {
    "text": "matures how those providers were think how those providers were thinking about",
    "start": "1924679",
    "end": "1930159"
  },
  {
    "text": "like what is the right standard and the right integrations",
    "start": "1930159",
    "end": "1935240"
  },
  {
    "text": "so this brings us a lot closer to where we are today and over the past few years although our platform although our tools",
    "start": "1937039",
    "end": "1943840"
  },
  {
    "text": "although these landscapes have changed a lot we've also had a lot of learnings along the way um alongside these",
    "start": "1943840",
    "end": "1950880"
  },
  {
    "text": "learnings we also gain a better understanding of how people use these tools and what they use them to do so I",
    "start": "1950880",
    "end": "1957200"
  },
  {
    "text": "wanted to share some statistics that we've gathered internally on these use on on these usage so the first is that",
    "start": "1957200",
    "end": "1965039"
  },
  {
    "text": "there is at least within well simple a very strong intersection between generative AI and",
    "start": "1965039",
    "end": "1971320"
  },
  {
    "text": "productivity in the surveys and the client interviews we did almost everyone",
    "start": "1971320",
    "end": "1976480"
  },
  {
    "text": "who used LLMs found it to significantly increase or improve their productivity",
    "start": "1976480",
    "end": "1981760"
  },
  {
    "text": "so this is more of a qualitative measure we also found that LM gateway",
    "start": "1981760",
    "end": "1988399"
  },
  {
    "text": "adoption is uniform across tenure and level were fairly uniform and it's a",
    "start": "1988399",
    "end": "1994240"
  },
  {
    "text": "fairly even split between individual contributors and people leaders and this was great affirmation for us because you",
    "start": "1994240",
    "end": "2001360"
  },
  {
    "text": "know we had spent a lot of time in building a tool and a platform that was very much bottoms up driven and this was",
    "start": "2001360",
    "end": "2008640"
  },
  {
    "text": "good affirmation that we were building that we were offering like these tools which were delightful that",
    "start": "2008640",
    "end": "2015600"
  },
  {
    "text": "were genuinely delightful and frictionless for our end users",
    "start": "2015600",
    "end": "2021080"
  },
  {
    "text": "in terms of how we were leveraging LMS internally um so this data is a few",
    "start": "2021760",
    "end": "2027360"
  },
  {
    "text": "months um outdated but we actually spent some time annotating a lot of the use cases uh the top use case the top usage",
    "start": "2027360",
    "end": "2036000"
  },
  {
    "text": "was for programming support so almost half of all of the usage was some variation of debugging code generation",
    "start": "2036000",
    "end": "2045120"
  },
  {
    "text": "um or just general programming support the second was content generation/",
    "start": "2045120",
    "end": "2051000"
  },
  {
    "text": "augmentation so help me write something uh change the style of this message",
    "start": "2051000",
    "end": "2057440"
  },
  {
    "text": "complete what I had written and then the third category was information retrieval so a lot of this",
    "start": "2057440",
    "end": "2064079"
  },
  {
    "text": "was focused around research or um parsing documents and what's interesting is that",
    "start": "2064079",
    "end": "2071118"
  },
  {
    "text": "almost everything all the use cases we saw basically fell within these top these three buckets there was very",
    "start": "2071119",
    "end": "2076960"
  },
  {
    "text": "little use case",
    "start": "2076960",
    "end": "2079838"
  },
  {
    "text": "outside uh we also saw that found that about 80% of our LM usage came through",
    "start": "2082440",
    "end": "2090000"
  },
  {
    "text": "our LM gateway so this is not going to be like a perfectly accurate measure because we don't have a comprehensive",
    "start": "2090000",
    "end": "2096079"
  },
  {
    "text": "list of all of the direct LM accesses out there um but about only about 20% of",
    "start": "2096079",
    "end": "2103280"
  },
  {
    "text": "our our LM traffic hit the providers directly and most of it came through the gateway and we thought this was pretty",
    "start": "2103280",
    "end": "2111320"
  },
  {
    "text": "cool we also learned a lot of lessons in behavior uh one of our biggest takeaways",
    "start": "2111320",
    "end": "2118160"
  },
  {
    "text": "this year was that as our LLM tooling became more mature we learned that",
    "start": "2118160",
    "end": "2123520"
  },
  {
    "text": "they're really only they're our tools are the most valuable when injected in the places we do work and that the",
    "start": "2123520",
    "end": "2130160"
  },
  {
    "text": "movement of information between platforms is a huge detractor we wanted to create a",
    "start": "2130160",
    "end": "2136000"
  },
  {
    "text": "centralized place for people to do their work any pattern to this would be if they needed seven different tabs open",
    "start": "2136000",
    "end": "2142480"
  },
  {
    "text": "for all of their LLM or Genai needs so having to visit multiple places",
    "start": "2142480",
    "end": "2148720"
  },
  {
    "text": "for generative AI is a confusing experience and we learned that even as",
    "start": "2148720",
    "end": "2154000"
  },
  {
    "text": "the number of tools grew most people stuck to using a single tool so we",
    "start": "2154000",
    "end": "2160400"
  },
  {
    "text": "wrapped up 2023 thinking that booster pack was going to fundamentally change the way people leverage this",
    "start": "2160400",
    "end": "2167800"
  },
  {
    "text": "technology that didn't really happen i mean we had some good bursts in adoption",
    "start": "2167800",
    "end": "2173520"
  },
  {
    "text": "there were some good use cases but at the end of the day we actually bifurcated our tools and created two",
    "start": "2173520",
    "end": "2180160"
  },
  {
    "text": "different places for people to get their to get their Genai needs and that was",
    "start": "2180160",
    "end": "2186000"
  },
  {
    "text": "not and that was detrimental for both adoption and productivity so the",
    "start": "2186000",
    "end": "2191119"
  },
  {
    "text": "learning from here is that we need to be a lot more deliberate about the tools we build and we need to put investments",
    "start": "2191119",
    "end": "2198400"
  },
  {
    "text": "into centralizing a lot of these toolings um because even though this is",
    "start": "2198400",
    "end": "2203520"
  },
  {
    "text": "what people said they wanted even though this intuitively made sense you know behavior is a tr user behavior for these",
    "start": "2203520",
    "end": "2210320"
  },
  {
    "text": "tools is a tricky thing and that will often surprise us",
    "start": "2210320",
    "end": "2215760"
  },
  {
    "text": "so taking all of these learnings um we're I wanted to share a little bit",
    "start": "2217599",
    "end": "2224079"
  },
  {
    "text": "more about how generative AI today at well simple how we're using it and how",
    "start": "2224079",
    "end": "2229119"
  },
  {
    "text": "we're thinking about it going into 2025 so the first is that you know in",
    "start": "2229119",
    "end": "2234720"
  },
  {
    "text": "spite of the pitfalls we've made overall well simple really loves LMS across all",
    "start": "2234720",
    "end": "2241680"
  },
  {
    "text": "the different tools we offer over 2200 messages gets sent",
    "start": "2241680",
    "end": "2246839"
  },
  {
    "text": "daily uh close to a third of the entire company are weekly active users and",
    "start": "2246839",
    "end": "2253839"
  },
  {
    "text": "slightly over half of the company are monthly active users so adoption engagement for these tools is really",
    "start": "2253839",
    "end": "2260560"
  },
  {
    "text": "great and at the same time the feedback that we're hearing is that it is helping",
    "start": "2260560",
    "end": "2266320"
  },
  {
    "text": "it is helping them be more productive we've also learned all of the",
    "start": "2266320",
    "end": "2272560"
  },
  {
    "text": "lessons all of the foundations and the guard rails that we learned and developed for employee productivity also",
    "start": "2272560",
    "end": "2279119"
  },
  {
    "text": "paves the way to providing a more delightful client experience these building blocks um so",
    "start": "2279119",
    "end": "2286079"
  },
  {
    "text": "these internal tools establish the building blocks to build and develop Genaii at scale and they're giving us",
    "start": "2286079",
    "end": "2292240"
  },
  {
    "text": "the confidence to find opportunities to optimize operations for our",
    "start": "2292240",
    "end": "2298320"
  },
  {
    "text": "clients and by providing the freedom for anyone",
    "start": "2298520",
    "end": "2303920"
  },
  {
    "text": "at the company to freely freely and securely explore this technology we had",
    "start": "2303920",
    "end": "2309119"
  },
  {
    "text": "a lot of organic extensions and additions that involved generative AI a",
    "start": "2309119",
    "end": "2314480"
  },
  {
    "text": "lot of which we had never thought of before so as of today we actually do have a lot of use cases both in",
    "start": "2314480",
    "end": "2321520"
  },
  {
    "text": "development and um in production that are optimizing",
    "start": "2321520",
    "end": "2327240"
  },
  {
    "text": "operations so I wanted to share very quickly one of them so this is uh what our client experience",
    "start": "2327240",
    "end": "2336560"
  },
  {
    "text": "triaging workflow used to look like um every single day we get a lot of tickets",
    "start": "2336560",
    "end": "2344079"
  },
  {
    "text": "uh both like through text and through phone calls from our clients and a few",
    "start": "2344079",
    "end": "2349599"
  },
  {
    "text": "years ago we actually had a team dedicated to reading all of these tickets and triaging them which team",
    "start": "2349599",
    "end": "2356720"
  },
  {
    "text": "should these tickets be sent to so that they can get their the clients can get their issue resolved and pretty quickly",
    "start": "2356720",
    "end": "2363040"
  },
  {
    "text": "we realized this is not a very effective um workflow and the people on this team were they didn't enjoy what they were",
    "start": "2363040",
    "end": "2369760"
  },
  {
    "text": "doing so we developed uh a transformer-based model to help with this triage so this is what we're",
    "start": "2369760",
    "end": "2376640"
  },
  {
    "text": "calling our original client experience triaging workflow so this model would",
    "start": "2376640",
    "end": "2381920"
  },
  {
    "text": "only work for emails it would take the ticket um and then map it to a topic and",
    "start": "2381920",
    "end": "2388960"
  },
  {
    "text": "subtopic and this classification would determine where this ticket gets sent to",
    "start": "2388960",
    "end": "2394880"
  },
  {
    "text": "so this was one of the areas which very organically extended into generative AI because the team working on it had",
    "start": "2394880",
    "end": "2400800"
  },
  {
    "text": "experimented with the techn with the tools that we offered uh with our LM platform there were two",
    "start": "2400800",
    "end": "2408320"
  },
  {
    "text": "improvements that were made so the first is that by leveraging whisper we could extend triaging to all tickets not just",
    "start": "2408320",
    "end": "2416359"
  },
  {
    "text": "emails um whisper would transcribe like any phone calls into text first and then",
    "start": "2416359",
    "end": "2422240"
  },
  {
    "text": "the text would be passed into the downstream system and generations from our",
    "start": "2422240",
    "end": "2428400"
  },
  {
    "text": "self-hosted LMS were used to enrich the classification so we were actually able to get huge performance boosts um which",
    "start": "2428400",
    "end": "2436240"
  },
  {
    "text": "translated into so many hours saved by both our client experience agents and our client and and our clients directly",
    "start": "2436240",
    "end": "2443160"
  },
  {
    "text": "themselves through these improvements in in performance in",
    "start": "2443160",
    "end": "2448920"
  },
  {
    "text": "performance so going back to this hype chart um 2023 we were climbing up that",
    "start": "2448920",
    "end": "2456000"
  },
  {
    "text": "peak of inflated expectations 2024 was a little bit sobering as we made our way",
    "start": "2456000",
    "end": "2461319"
  },
  {
    "text": "down um but towards the end of this year and as we're headed into next year I think we're on a very good trajectory to",
    "start": "2461319",
    "end": "2468640"
  },
  {
    "text": "send that slope of enlightenment so even with the ups and downs over the past two years um there's still a lot of optimism",
    "start": "2468640",
    "end": "2476720"
  },
  {
    "text": "and there's still a lot of excitement for what next year could hold and this",
    "start": "2476720",
    "end": "2481839"
  },
  {
    "text": "marks the end of my presentation as well so thank you everyone for listening thank you Manny all",
    "start": "2481839",
    "end": "2489599"
  },
  {
    "text": "right that was a very fascinating journey lots of ups and downs hard to keep up with all advancements i love how",
    "start": "2491440",
    "end": "2498319"
  },
  {
    "text": "your strategies also evolve rapidly as well we have about five minutes for questions so if you have you want to",
    "start": "2498319",
    "end": "2505040"
  },
  {
    "text": "raise your hand we'll run the mic to you uh back",
    "start": "2505040",
    "end": "2510200"
  },
  {
    "text": "there all right back there hi uh Dylan Fox from XRaxis uh thanks for the",
    "start": "2510200",
    "end": "2517800"
  },
  {
    "text": "presentation i'm really curious when it comes to um helping people realize that",
    "start": "2517800",
    "end": "2524480"
  },
  {
    "text": "putting lots of personal information into an LLM um is not necessarily a safe",
    "start": "2524480",
    "end": "2530240"
  },
  {
    "text": "thing to do uh how did you help ensure",
    "start": "2530240",
    "end": "2535440"
  },
  {
    "text": "that people weren't sharing those you know compromising data from a user",
    "start": "2535440",
    "end": "2542160"
  },
  {
    "text": "education standpoint that's a good question so from",
    "start": "2542160",
    "end": "2547640"
  },
  {
    "text": "um so I think there's there's two parts to this one is that we found over the",
    "start": "2547640",
    "end": "2554480"
  },
  {
    "text": "years um of introducing new tools that good intentions are not necessarily",
    "start": "2554480",
    "end": "2560480"
  },
  {
    "text": "enough that we couldn't just trust people that we couldn't just focus on education that we actually needed the",
    "start": "2560480",
    "end": "2567040"
  },
  {
    "text": "guardrails and the mechanisms within our system to guide them towards making the right to ensure they make the right",
    "start": "2567040",
    "end": "2572480"
  },
  {
    "text": "decision other like outside of just informing them about what to do um so that was like one part to our philosophy",
    "start": "2572480",
    "end": "2578640"
  },
  {
    "text": "but I I think to your point like definitely leveling up that understanding of the security risk was",
    "start": "2578640",
    "end": "2583680"
  },
  {
    "text": "very important um being a financial services company we work with very sensitive information for our clients so",
    "start": "2583680",
    "end": "2590880"
  },
  {
    "text": "as a part of our routine training there's a lot of education already about like what is acceptable to share and",
    "start": "2590880",
    "end": "2596319"
  },
  {
    "text": "what is not acceptable to share the part that was very hard for people to wrap their heads around is what happens when",
    "start": "2596319",
    "end": "2603040"
  },
  {
    "text": "this information is being shared um directly with open AAI for instance where in a lot of cases like fourth",
    "start": "2603040",
    "end": "2609200"
  },
  {
    "text": "party data sharing so for instance um you know slack has their AI integration notion has their AI integration what",
    "start": "2609200",
    "end": "2616640"
  },
  {
    "text": "does that mean like to an extent it does mean all of this information will get",
    "start": "2616640",
    "end": "2622640"
  },
  {
    "text": "sent to the providers directly and that was the part that was really hard for people to wrap their heads around i",
    "start": "2622640",
    "end": "2629119"
  },
  {
    "text": "wouldn't necessarily say this is well this is definitely not a problem that we've solved but um some of the ways",
    "start": "2629119",
    "end": "2634319"
  },
  {
    "text": "that we've been trying to raise that awareness is one through onboarding so we've actually added a component for all",
    "start": "2634319",
    "end": "2641280"
  },
  {
    "text": "employee onboarding that includes like guidelines for proper AI usage and we've",
    "start": "2641280",
    "end": "2647599"
  },
  {
    "text": "added a lot more education um for u like leaders and individuals in the company",
    "start": "2647599",
    "end": "2653520"
  },
  {
    "text": "who may be involved in the procurement process for new vendors and what that AI like and and the implications that may",
    "start": "2653520",
    "end": "2660400"
  },
  {
    "text": "have from a security point of view cool thank you we have a question over here yeah thanks for the presentation uh",
    "start": "2660400",
    "end": "2668640"
  },
  {
    "text": "I had a question on uh data platform i was uh wondering uh could you elaborate",
    "start": "2668640",
    "end": "2674400"
  },
  {
    "text": "on uh what consisted of this data platform and uh how it was useful for the LL solution",
    "start": "2674400",
    "end": "2682560"
  },
  {
    "text": "uh sorry so you are you asking about the intersections between like our data",
    "start": "2682560",
    "end": "2688400"
  },
  {
    "text": "engineering platform and LMS in particular or Yeah what consisted of the",
    "start": "2688400",
    "end": "2693839"
  },
  {
    "text": "data platform and uh how did you use that uh in your solution",
    "start": "2693839",
    "end": "2700480"
  },
  {
    "text": "yeah um so there's definitely a very close intersection between our data platform and our machine learning",
    "start": "2700480",
    "end": "2706160"
  },
  {
    "text": "platform so for instance um one of the bread and butters to our data platform",
    "start": "2706160",
    "end": "2711359"
  },
  {
    "text": "is our orchestration framework through airflow and that was something we use to",
    "start": "2711359",
    "end": "2716720"
  },
  {
    "text": "update the embeddings within our vector database um and make sure it was up to date with our knowledge bases um outside",
    "start": "2716720",
    "end": "2723680"
  },
  {
    "text": "of that the there's also when it comes to exploration and especially for our",
    "start": "2723680",
    "end": "2729119"
  },
  {
    "text": "data scientists as they're building new um LLM and ML products there's a very",
    "start": "2729119",
    "end": "2734160"
  },
  {
    "text": "close intersection between the data we have available in our data warehouse and the downstream use cases so I would call",
    "start": "2734160",
    "end": "2741839"
  },
  {
    "text": "those two out as the biggest intersections um I hope that answers your question makes sense we have one",
    "start": "2741839",
    "end": "2748319"
  },
  {
    "text": "more questions over there yes hi um this is Glenn i love this uh",
    "start": "2748319",
    "end": "2753920"
  },
  {
    "text": "presentation thank you so much for uh uh participating and and providing it uh",
    "start": "2753920",
    "end": "2760240"
  },
  {
    "text": "early in the conversation you talked about elastic search as your vector database capability for similarity",
    "start": "2760240",
    "end": "2766880"
  },
  {
    "text": "search for rag purposes later you talked about transitioning to bedrock did you",
    "start": "2766880",
    "end": "2772160"
  },
  {
    "text": "keep elastic search or did you get off of that when you transitioned to bedrock",
    "start": "2772160",
    "end": "2777200"
  },
  {
    "text": "um great question we didn't get off of that uh I think so at the time we chose",
    "start": "2777200",
    "end": "2782800"
  },
  {
    "text": "it was actually we're using open search which is AWS's managed version of elastic search at the time we chose open",
    "start": "2782800",
    "end": "2790240"
  },
  {
    "text": "search/ elastic search because it was already part of our stack so it was easy",
    "start": "2790240",
    "end": "2795520"
  },
  {
    "text": "to make that choice um we didn't go into it thinking that this would be our permanent choice and we understand this",
    "start": "2795520",
    "end": "2802160"
  },
  {
    "text": "is a space that evolves a lot right now bedrock is still fairly new to us we're",
    "start": "2802160",
    "end": "2807599"
  },
  {
    "text": "primarily using it to extend our LM provider offerings specifically for anthropic models um we haven't dug or",
    "start": "2807599",
    "end": "2815680"
  },
  {
    "text": "evaluated as deeply uh like their vector database or like their fine-tuning or",
    "start": "2815680",
    "end": "2821280"
  },
  {
    "text": "their other capabilities i think that's definitely one of the things we want to deep digger want to dig deeper into for",
    "start": "2821280",
    "end": "2829000"
  },
  {
    "text": "2025 as we're looking into what an evolution the next iteration of our platform would look like",
    "start": "2829000",
    "end": "2835920"
  },
  {
    "text": "cool are you happy with the the similarity results that you're getting with open search",
    "start": "2835920",
    "end": "2843680"
  },
  {
    "text": "i think we are um I mean I think studies have shown that this is not usually not",
    "start": "2843680",
    "end": "2849440"
  },
  {
    "text": "the most effective way of doing things um from a performance and relevancy",
    "start": "2849440",
    "end": "2854560"
  },
  {
    "text": "perspective at least but where where we're really happy with it is like one it's easy to scale latency is really",
    "start": "2854560",
    "end": "2861440"
  },
  {
    "text": "good and it's just overall simple to use i think depending on the use cases like maybe using a reranker or like",
    "start": "2861440",
    "end": "2868319"
  },
  {
    "text": "leveraging a different technique may may be better suited depending very depending on the use case",
    "start": "2868319",
    "end": "2874400"
  },
  {
    "text": "all right thank you all for attending we are time so let's skip many one more time",
    "start": "2874400",
    "end": "2881079"
  }
]
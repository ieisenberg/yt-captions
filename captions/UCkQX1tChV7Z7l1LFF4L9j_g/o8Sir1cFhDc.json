[
  {
    "text": "welcome to my talk about maximizing performance with growl VM I'm Thomas",
    "start": "4250",
    "end": "10730"
  },
  {
    "text": "I'm working as a researcher at or collapse I'm a compiler constructor I did a lot of compiler work during my",
    "start": "10730",
    "end": "16910"
  },
  {
    "text": "career both on hot spot the magazine research VM but also on we ate",
    "start": "16910",
    "end": "22090"
  },
  {
    "text": "JavaScript engine at Google and since about seven eight years I'm working as",
    "start": "22090",
    "end": "28070"
  },
  {
    "text": "the project lead for gravia which is a new virtual machine that is trying to execute many languages faster and so",
    "start": "28070",
    "end": "36949"
  },
  {
    "text": "what I'm saying in this talk today it comes from the perspective of the compiler constructor I'm not a GC expert",
    "start": "36949",
    "end": "42859"
  },
  {
    "text": "or like a runtime expert but I'm trying to convey kind of from the perspective",
    "start": "42859",
    "end": "48109"
  },
  {
    "text": "of a compiler guy what is possible and how do you maximize performance there so",
    "start": "48109",
    "end": "57460"
  },
  {
    "text": "when we talk about performance there's many different ways we can talk about it",
    "start": "57460",
    "end": "62809"
  },
  {
    "text": "and many different ways to measure performance and when the main thing usually people think about when they",
    "start": "62809",
    "end": "68780"
  },
  {
    "text": "talk about performance is Peaks throughput this means when your system reaches a steady state how many",
    "start": "68780",
    "end": "75350"
  },
  {
    "text": "operations per seconds will it be able to serve this is one of the dimensions",
    "start": "75350",
    "end": "81320"
  },
  {
    "text": "that you can optimize for but there's many more other dimensions a second one is the startup time it's basically how",
    "start": "81320",
    "end": "90920"
  },
  {
    "text": "fasting in your application reach a certain amount of requests per second or",
    "start": "90920",
    "end": "96050"
  },
  {
    "text": "how fast is your application in the first two seconds maybe first few minutes before it reaches that steady",
    "start": "96050",
    "end": "101390"
  },
  {
    "text": "state and as this diagram here suggests",
    "start": "101390",
    "end": "106550"
  },
  {
    "text": "this is already a little bit of a trade-off you can have more startup time or more peak performance depending on",
    "start": "106550",
    "end": "111800"
  },
  {
    "text": "what you care more about but that's not everything there is also memory footprint it's becoming more important",
    "start": "111800",
    "end": "118400"
  },
  {
    "text": "over time because if you look at your cloud provider for example the main thing they are charging for is the",
    "start": "118400",
    "end": "124130"
  },
  {
    "text": "memory using half as much memory usually gives you half the price on any cloud",
    "start": "124130",
    "end": "129140"
  },
  {
    "text": "provider so in some applications specific applications that are scaling",
    "start": "129140",
    "end": "134690"
  },
  {
    "text": "very well maybe you don't care about your peak throughput but you care about your peak throughput per memory meaning how much throughput",
    "start": "134690",
    "end": "143510"
  },
  {
    "text": "can you achieve is a certain amount of memory available and this is again a consideration you need to be thinking of",
    "start": "143510",
    "end": "151550"
  },
  {
    "text": "when it comes to what you actually mean by performance and there's more there's",
    "start": "151550",
    "end": "157550"
  },
  {
    "text": "there's other more secondary characteristics people care about one is max latency this is a very hard",
    "start": "157550",
    "end": "164570"
  },
  {
    "text": "characteristics in garbage collection where you care about your maximum",
    "start": "164570",
    "end": "171050"
  },
  {
    "text": "latency for certain requests and your choice of garbage collectors that there are heavily influences whether you care",
    "start": "171050",
    "end": "178010"
  },
  {
    "text": "more about peak performance versus max latency and finally another second",
    "start": "178010",
    "end": "183770"
  },
  {
    "text": "rather secondary item is packaging size how much do you care about the size of",
    "start": "183770",
    "end": "190160"
  },
  {
    "text": "the package you're distributing to your users or to your servers on the server",
    "start": "190160",
    "end": "195680"
  },
  {
    "text": "side application that's usually not that important it's a big consideration on mobile phone applications for example",
    "start": "195680",
    "end": "202660"
  },
  {
    "text": "because if you download size of your iOS app is half of what it was before a lot",
    "start": "202660",
    "end": "210020"
  },
  {
    "text": "more people will download it and use your app so this is another dimension you need to think about and this talk is",
    "start": "210020",
    "end": "217640"
  },
  {
    "text": "about how can you trade off these things and how can you and how can you",
    "start": "217640",
    "end": "224239"
  },
  {
    "text": "basically maximize the items you want and it's not like you can only pick one",
    "start": "224239",
    "end": "229880"
  },
  {
    "text": "it's usually you can pick one two three out of those five and get them to optimal values so when it comes to",
    "start": "229880",
    "end": "241880"
  },
  {
    "text": "gravia core RVM itself as I said is a virtual machine that can run any",
    "start": "241880",
    "end": "247130"
  },
  {
    "text": "language it can run specifically any Java based language and it can run on top of open JDK here but it cannot just",
    "start": "247130",
    "end": "254420"
  },
  {
    "text": "run Java and Scala and coughlin and groovy and Giambi's languages it has the capability to run also other languages",
    "start": "254420",
    "end": "262340"
  },
  {
    "text": "like Ruby Python or JavaScript these are",
    "start": "262340",
    "end": "267500"
  },
  {
    "text": "all scripting languages to chromium supports in addition to the gem languages and we also support running",
    "start": "267500",
    "end": "273900"
  },
  {
    "text": "see rust C++ type of applications",
    "start": "273900",
    "end": "279380"
  },
  {
    "text": "usually we would run these applications on top of open JDK which gives you a",
    "start": "279380",
    "end": "284400"
  },
  {
    "text": "familiar set up with a java virtual machine but we also have other",
    "start": "284400",
    "end": "290250"
  },
  {
    "text": "environments that we can grab run gravia because corrodium is very embeddable is embeddable in multiple environments we",
    "start": "290250",
    "end": "296940"
  },
  {
    "text": "can embed it in the note chess platform this means you can run all the Guardium languages also when you run a node.js",
    "start": "296940",
    "end": "303780"
  },
  {
    "text": "application we can embed it in the Oracle database obviously there you can",
    "start": "303780",
    "end": "311550"
  },
  {
    "text": "run it as a store procedures the final thing you can run Robi invoice is",
    "start": "311550",
    "end": "317970"
  },
  {
    "text": "standalone ahead of time compiled and this is where we create a small package",
    "start": "317970",
    "end": "325260"
  },
  {
    "text": "binary for a certain application",
    "start": "325260",
    "end": "329060"
  },
  {
    "text": "chromium comes in two editions there's a Community Edition as an Enterprise Edition Community Edition is free for",
    "start": "330530",
    "end": "336599"
  },
  {
    "text": "production years it's a we maintain about a couple million lines of open source around krabi among github and",
    "start": "336599",
    "end": "342889"
  },
  {
    "text": "Enterprise Edition is acquiring a license so I said chromium can run this",
    "start": "342889",
    "end": "351479"
  },
  {
    "text": "languages Java Scala Ruby Kotlin on top of open JDK in your usual way you download the Grove",
    "start": "351479",
    "end": "357840"
  },
  {
    "text": "installation you run java my main gloss and you run with chromium",
    "start": "357840",
    "end": "363169"
  },
  {
    "text": "the main difference was as a normal open JDK installation is that it runs with the grog EMT just-in-time compiler which",
    "start": "363169",
    "end": "370860"
  },
  {
    "text": "is a new just-in-time compiler that's written in Java and that replaces - C - just-in-time compiler that is usually",
    "start": "370860",
    "end": "377010"
  },
  {
    "text": "run when you run on top of the hotspot virtual machine so this is a very",
    "start": "377010",
    "end": "382620"
  },
  {
    "text": "familiar set up for every Java developer nowadays the chromium has a second way",
    "start": "382620",
    "end": "388590"
  },
  {
    "text": "to run things it can run things ahead of time compile there you take your main",
    "start": "388590",
    "end": "395430"
  },
  {
    "text": "glass of your application there's a native image command that takes that main glass as an argument and it",
    "start": "395430",
    "end": "403050"
  },
  {
    "text": "produces a new executable binary and that binary is all you need to further run your application so this binary",
    "start": "403050",
    "end": "409590"
  },
  {
    "text": "includes all of the runtime includes all of every all of the code pre-compile etc",
    "start": "409590",
    "end": "416150"
  },
  {
    "text": "these are the main two modes you can run chromium verse you can run Gras VM in the chick mode I can run it in the eot",
    "start": "416150",
    "end": "422940"
  },
  {
    "text": "mode and there are trade-offs between this to the chit mode and the ERT mode",
    "start": "422940",
    "end": "428250"
  },
  {
    "text": "and in this talk I will talk more about when to use which mode and what are the",
    "start": "428250",
    "end": "433260"
  },
  {
    "text": "specifics of these trade-offs this Yorty",
    "start": "433260",
    "end": "438389"
  },
  {
    "text": "mode is something that only gravy and provides and the cheat mode is something you can get with other with other open",
    "start": "438389",
    "end": "446279"
  },
  {
    "text": "JDK distributions as well this ahead of time compiled mode is a wave every",
    "start": "446279",
    "end": "454169"
  },
  {
    "text": "package and compile the whole java application down into a single executable so how do we do that what we",
    "start": "454169",
    "end": "462990"
  },
  {
    "text": "do is we take everything that is consumed by the java application meaning the libraries the GDK libraries also",
    "start": "462990",
    "end": "471300"
  },
  {
    "text": "resources and what we do is we do a close to old analysis it's an analysis",
    "start": "471300",
    "end": "477810"
  },
  {
    "text": "of what is reachable from the main class of the application because one problem is that when you create this package",
    "start": "477810",
    "end": "486240"
  },
  {
    "text": "binary you don't want to include every JDK class there is you don't want to include every library class there is you",
    "start": "486240",
    "end": "494250"
  },
  {
    "text": "want to package exactly what is only used by your application so we do a flow",
    "start": "494250",
    "end": "499860"
  },
  {
    "text": "sensitive analysis of what is reachable from the entry point of the application",
    "start": "499860",
    "end": "505190"
  },
  {
    "text": "we run some of the static initializers specifically the one that we can brew us",
    "start": "505190",
    "end": "510599"
  },
  {
    "text": "as correct to be running at image generation time and then we snapshot the",
    "start": "510599",
    "end": "517198"
  },
  {
    "text": "current heap of the java application as is and put everything together in a single binary so we put all of the code",
    "start": "517199",
    "end": "526709"
  },
  {
    "text": "ahead of time compiled into the code section and we also write down a snapshot of the java application as it",
    "start": "526709",
    "end": "533550"
  },
  {
    "text": "was as initialized into the image heat this allows you to",
    "start": "533550",
    "end": "538750"
  },
  {
    "text": "also pre initialize certain values or configuration parameters of your",
    "start": "538750",
    "end": "544840"
  },
  {
    "text": "application and you don't need to load them again when you start this binary",
    "start": "544840",
    "end": "550840"
  },
  {
    "text": "again so what's what's the benefit of",
    "start": "550840",
    "end": "556300"
  },
  {
    "text": "this what's the benefit of IOT so the problem is a JIT compiler in the chit configuration there's a lot of work",
    "start": "556300",
    "end": "563380"
  },
  {
    "text": "going on when you start the application so first of all while the TVM executable",
    "start": "563380",
    "end": "570010"
  },
  {
    "text": "starts starts executing okay you load the classes that your byte codes from",
    "start": "570010",
    "end": "575410"
  },
  {
    "text": "your disk then you have to verify the byte codes then you start interpreting",
    "start": "575410",
    "end": "581980"
  },
  {
    "text": "your byte code which is usually about 50 times slower than your final machine code would be so this interpretation of",
    "start": "581980",
    "end": "588880"
  },
  {
    "text": "byte codes and starting initializes as it starts up is about 50 times slower you're under static initializers usually",
    "start": "588880",
    "end": "596260"
  },
  {
    "text": "an interpreted mode and then what you do on the Java hotspot virtual machine is that you create a first-tier compilation",
    "start": "596260",
    "end": "602080"
  },
  {
    "text": "so use a fast compiler which is c1 the client compiler of hotspot to create",
    "start": "602080",
    "end": "608110"
  },
  {
    "text": "your first exit your first machine code you do that because you want to speed up",
    "start": "608110",
    "end": "613810"
  },
  {
    "text": "your application as fast as possible you don't want to wait for the final machine code to arrive because there's such a",
    "start": "613810",
    "end": "619510"
  },
  {
    "text": "big difference between the interpreter speed and the final machine code speed",
    "start": "619510",
    "end": "624640"
  },
  {
    "text": "that you kind of want an intermediate solution this intermediate solution is provided by the C one client compiler",
    "start": "624640",
    "end": "630910"
  },
  {
    "text": "and this intermediate solution specifically has something in there that gathers profiling feedback the goddess",
    "start": "630910",
    "end": "637090"
  },
  {
    "text": "that gathers information about how the application is running the code",
    "start": "637090",
    "end": "642780"
  },
  {
    "text": "profiling feedback includes loop counts it includes for every pranced it",
    "start": "642780",
    "end": "649330"
  },
  {
    "text": "includes the counts how often did the branch go right or left it includes",
    "start": "649330",
    "end": "654850"
  },
  {
    "text": "information about actual concrete classes that occur at certain places",
    "start": "654850",
    "end": "660630"
  },
  {
    "text": "meaning at instance off or add virtual calls",
    "start": "660630",
    "end": "665950"
  },
  {
    "text": "and it includes some other minor information about the execution so this profit covering this profiling",
    "start": "665950",
    "end": "673150"
  },
  {
    "text": "feedback is again not free it slows down your code because while you start up you need to do this extra bookkeeping of the",
    "start": "673150",
    "end": "679780"
  },
  {
    "text": "profiling department then when a method gets really hot meaning you you you've",
    "start": "679780",
    "end": "686140"
  },
  {
    "text": "had the first compile you got at some profile then the method is scheduled for the second compiler and this is when the",
    "start": "686140",
    "end": "693430"
  },
  {
    "text": "heavyweight compiler it's either the c2 compiler or the grahyam compiler comes in and uses all",
    "start": "693430",
    "end": "700780"
  },
  {
    "text": "the information gathered during the startup sequence of the application to create the final hopefully very good",
    "start": "700780",
    "end": "706930"
  },
  {
    "text": "machine code and then you execute it fast but as you can say there's a long",
    "start": "706930",
    "end": "712180"
  },
  {
    "text": "sequence here and this is the main reason why an application that is running on the Java Virtual Machine is",
    "start": "712180",
    "end": "719290"
  },
  {
    "text": "starting up slowly so when we do the add of time compilation obviously we don't",
    "start": "719290",
    "end": "726940"
  },
  {
    "text": "need to do a lot of these things because we did the compilation to machine code during the head of time compilation step",
    "start": "726940",
    "end": "733840"
  },
  {
    "text": "and then when you start the app everything is ready so you do not need",
    "start": "733840",
    "end": "740680"
  },
  {
    "text": "to interpret you do not need to get a profiling feedback nothing of that sort you immediately start with the best",
    "start": "740680",
    "end": "745810"
  },
  {
    "text": "machine code plus if you had snapshot some configuration files you might even not avoid loading configuration files",
    "start": "745810",
    "end": "752800"
  },
  {
    "text": "that the otherwise would load at runtime so startup time is probably the area where the head of time compilation is",
    "start": "752800",
    "end": "759280"
  },
  {
    "text": "beating the JIT compilation by the largest margin and we can see that in",
    "start": "759280",
    "end": "765400"
  },
  {
    "text": "the numbers we have here measured a couple of popular web frameworks and we",
    "start": "765400",
    "end": "770710"
  },
  {
    "text": "measured the gravy m cheat configuration versus the gravy immunity configuration in startup time sort of time here is",
    "start": "770710",
    "end": "778800"
  },
  {
    "text": "effectively from the start of the application to the until the first request can be served on that web server",
    "start": "778800",
    "end": "786030"
  },
  {
    "text": "so the games here are huge they're about 50 X on average and it's not surprising",
    "start": "786030",
    "end": "791620"
  },
  {
    "text": "because it just showed it before how much is going on on the one hand which is how little is going on on the other",
    "start": "791620",
    "end": "797990"
  },
  {
    "text": "so this is really opening a new white you can run a Java based web server and",
    "start": "797990",
    "end": "803840"
  },
  {
    "text": "suddenly changes a little bit the equation about well if I can start up in",
    "start": "803840",
    "end": "808860"
  },
  {
    "text": "this 16 milliseconds I don't need to keep the process around all the time",
    "start": "808860",
    "end": "813920"
  },
  {
    "text": "so when the web application is idle you just shut down the process you can almost start a new process per request",
    "start": "813920",
    "end": "819720"
  },
  {
    "text": "if you want with this type of speed so",
    "start": "819720",
    "end": "827090"
  },
  {
    "text": "whether the compilation time is relevant for application or not you can actually",
    "start": "827090",
    "end": "832530"
  },
  {
    "text": "find out with the profiling tool called Java flight recorder who of you has been using Java flight",
    "start": "832530",
    "end": "838710"
  },
  {
    "text": "recorder were you couple about doesn't and so who of you has ever looked at the",
    "start": "838710",
    "end": "847500"
  },
  {
    "text": "compilation times with Java flight recorder one awesome yes I also didn't",
    "start": "847500",
    "end": "857130"
  },
  {
    "text": "know how awesome these features of Java flight recorder but I want to present it to you here in Java particular mode when",
    "start": "857130",
    "end": "863760"
  },
  {
    "text": "you go to the java application to java application you look up you look up how",
    "start": "863760",
    "end": "870830"
  },
  {
    "text": "how the threads are doing you can actually select the compiler threads in",
    "start": "870830",
    "end": "877230"
  },
  {
    "text": "the ground case these are called GBMC i native threat there is in the c 2 normal",
    "start": "877230",
    "end": "883230"
  },
  {
    "text": "open JDK sir they are called C 2 threads and when you select one of these threads",
    "start": "883230",
    "end": "888960"
  },
  {
    "text": "you will see here a little diagram purse red and yellow here means that you have",
    "start": "888960",
    "end": "896100"
  },
  {
    "text": "a compilation running so the compiler is doing something so this is an",
    "start": "896100",
    "end": "901740"
  },
  {
    "text": "interesting workload this is compiling Apache spark why are the Scala compiler",
    "start": "901740",
    "end": "908340"
  },
  {
    "text": "on the JVM it runs for about three minutes and what we can see is we have",
    "start": "908340",
    "end": "914070"
  },
  {
    "text": "three compiler threats here that are all busy all the time and after these three",
    "start": "914070",
    "end": "920820"
  },
  {
    "text": "minutes and done compiling my Apache spark and at the same time obtuse tons of machine code",
    "start": "920820",
    "end": "925830"
  },
  {
    "text": "it will be useless now because because you know I'm done after three minutes",
    "start": "925830",
    "end": "930860"
  },
  {
    "text": "so this is a typical workload where the compilation speed of the cheat compiler",
    "start": "930860",
    "end": "936120"
  },
  {
    "text": "is very important so you can figure out whether the compilation speed of your",
    "start": "936120",
    "end": "941400"
  },
  {
    "text": "typical files are important or not by selecting the compiler threads here and see if they are green which means they",
    "start": "941400",
    "end": "946980"
  },
  {
    "text": "are not doing anything or if they are yellow which means they are compiling you can even go down to individual",
    "start": "946980",
    "end": "952260"
  },
  {
    "text": "compiles a selected here is single compiled that took here 700 milliseconds of a certain weird-looking Java Scala",
    "start": "952260",
    "end": "960990"
  },
  {
    "text": "method and you can actually go down to individual compiles and see how long they took and to see whether there is a",
    "start": "960990",
    "end": "969030"
  },
  {
    "text": "problem is a specific one but it is just to show you here one of the things you can do with Java mission control that is",
    "start": "969030",
    "end": "975360"
  },
  {
    "text": "less well-known and then it worked like this getting a faster compiler might",
    "start": "975360",
    "end": "980880"
  },
  {
    "text": "speed up the whole thing are doing ahead of time compilation might give you even more so second area of ahead of time",
    "start": "980880",
    "end": "991860"
  },
  {
    "text": "versus JIT compiler where ahead of time compile has an advantage is on memory footprint and the reason is that in the",
    "start": "991860",
    "end": "1000230"
  },
  {
    "text": "JIT compilation mode of gravimon hotspot you need to load a lot keep a lot of",
    "start": "1000230",
    "end": "1006080"
  },
  {
    "text": "things in memory well obviously well you need to load parts of TGV i'm executable you get the application data",
    "start": "1006080",
    "end": "1011660"
  },
  {
    "text": "ok that's clear but then there's a lot of additional data that is hanging around one is of course 2 loaded clip ID",
    "start": "1011660",
    "end": "1018530"
  },
  {
    "text": "codes and class files then you have reflection metadata because they need to",
    "start": "1018530",
    "end": "1023870"
  },
  {
    "text": "be always ready to do a certain reflection call or do a debug session on",
    "start": "1023870",
    "end": "1029750"
  },
  {
    "text": "your JVM for example you get the code cache this is where you install the",
    "start": "1029750",
    "end": "1035630"
  },
  {
    "text": "just-in-time compiled code that is created on the fly and as I shown on the previous workload this can be a lot of",
    "start": "1035630",
    "end": "1042500"
  },
  {
    "text": "code that is generated actually here on this workload you can also see the",
    "start": "1042500",
    "end": "1048710"
  },
  {
    "text": "compiled code size down here it's 32 5 kilobyte down until on the second loss",
    "start": "1048710",
    "end": "1053930"
  },
  {
    "text": "line at 35 kilobytes on the matter then you have here profiling data you",
    "start": "1053930",
    "end": "1062850"
  },
  {
    "text": "need to keep the data in memory that was used to feed the JIT compiler and then finally this cheat compiled itself which",
    "start": "1062850",
    "end": "1069809"
  },
  {
    "text": "hopefully when the application reaches the steady state will be no longer",
    "start": "1069809",
    "end": "1075179"
  },
  {
    "text": "relevant because hopefully no compilations are going on anymore when your application runs for a long time but during this startup and during the",
    "start": "1075179",
    "end": "1082890"
  },
  {
    "text": "warmup period there will be a lot of compilations that also take memory so in",
    "start": "1082890",
    "end": "1088530"
  },
  {
    "text": "the head of time compiled case again this is much less available that it is",
    "start": "1088530",
    "end": "1093990"
  },
  {
    "text": "much less that needs to be kept in memory you basically load the application executable and you load the",
    "start": "1093990",
    "end": "1100320"
  },
  {
    "text": "application data so the savings you get here depend on how much payload data the",
    "start": "1100320",
    "end": "1108210"
  },
  {
    "text": "application has because the application payload data is the same on both configurations so if your application",
    "start": "1108210",
    "end": "1114090"
  },
  {
    "text": "payload data is 32 gigabyte you won't save anything if your application",
    "start": "1114090",
    "end": "1120210"
  },
  {
    "text": "payload data is 500 megabyte you might save a lot so the typical lambda",
    "start": "1120210",
    "end": "1126360"
  },
  {
    "text": "configurations on on on cloud providers is like 500 megabyte for your whole",
    "start": "1126360",
    "end": "1131640"
  },
  {
    "text": "application these are scenarios where the metadata matters a lot so you can go",
    "start": "1131640",
    "end": "1138240"
  },
  {
    "text": "to a lower configuration on your cloud provider if you go with out of time compilation and then it depends on how",
    "start": "1138240",
    "end": "1147240"
  },
  {
    "text": "much application code is executed meaning you have an application it's very complex loads loads a lot of katar",
    "start": "1147240",
    "end": "1152970"
  },
  {
    "text": "files has a lot of hot code or do you have a simple application via game have",
    "start": "1152970",
    "end": "1160530"
  },
  {
    "text": "some numbers here on ahead of time versus cheat a memory footprint with various web frameworks hello Don McLean",
    "start": "1160530",
    "end": "1167070"
  },
  {
    "text": "out and Coker's and the gains are still substantial this is again to serve a",
    "start": "1167070",
    "end": "1173340"
  },
  {
    "text": "single request and the gains are about yeah 3 X 5 X but as I said it depends on",
    "start": "1173340",
    "end": "1180030"
  },
  {
    "text": "how much application payload you have versus how much classes you load or code",
    "start": "1180030",
    "end": "1187200"
  },
  {
    "text": "you execute it's an interesting tool by the way to",
    "start": "1187200",
    "end": "1192850"
  },
  {
    "text": "measure performance specifically memory footprint is P as record PS record",
    "start": "1192850",
    "end": "1198250"
  },
  {
    "text": "measures CPU consumption and resident set size over time this is important",
    "start": "1198250",
    "end": "1205270"
  },
  {
    "text": "because a lot of java virtual machine memory tools only show you the heap the",
    "start": "1205270",
    "end": "1211360"
  },
  {
    "text": "Java heap and they basically say well this is your Java heap consumption and this is how many how many bytes you",
    "start": "1211360",
    "end": "1218140"
  },
  {
    "text": "using the Java heap but that's not everything that's relevant all of the metadata structures compiler JIT",
    "start": "1218140",
    "end": "1223810"
  },
  {
    "text": "compiler data structures etc are not included in the measurement so it's",
    "start": "1223810",
    "end": "1230260"
  },
  {
    "text": "usually better to measure the memory consumption of a process by looking at the resident set size one thing about",
    "start": "1230260",
    "end": "1237190"
  },
  {
    "text": "the resident set size is that it's highly variable because it depends on your operating system heuristics as your",
    "start": "1237190",
    "end": "1243280"
  },
  {
    "text": "operating system is swapping pages in and out and many many other factors this is why I would not recommend to master",
    "start": "1243280",
    "end": "1250960"
  },
  {
    "text": "the resident set size at a specific point but measure it over time and then look at the overall graph because if you",
    "start": "1250960",
    "end": "1259060"
  },
  {
    "text": "measure that the specific point images get lucky or unlucky you get a lot of variability in the measurements so this",
    "start": "1259060",
    "end": "1264070"
  },
  {
    "text": "is here running dravyam in sheet configuration to the first request and what we see as well it takes a lot of",
    "start": "1264070",
    "end": "1270850"
  },
  {
    "text": "real memory here on the operating system about 350 megabytes but also to see at the beginning is during the wall of the",
    "start": "1270850",
    "end": "1277450"
  },
  {
    "text": "application we use a lot of CPU time because this is where the cheat compilation happens so you see the all",
    "start": "1277450",
    "end": "1283660"
  },
  {
    "text": "this red box there so then compared to a crawl in ahead of",
    "start": "1283660",
    "end": "1288910"
  },
  {
    "text": "time compiled mode it is looking very different first the real memory usage",
    "start": "1288910",
    "end": "1295180"
  },
  {
    "text": "here is only 12 megabytes that's about 30 times less but also the CPU usage as",
    "start": "1295180",
    "end": "1304000"
  },
  {
    "text": "a lot less even during startup it's a lot less doing this bottom it's just a",
    "start": "1304000",
    "end": "1309190"
  },
  {
    "text": "small peak nothing else and then as you like here I'm doing 2 requests I'm",
    "start": "1309190",
    "end": "1315910"
  },
  {
    "text": "sending two requests to this server and it's just a small a small little spike",
    "start": "1315910",
    "end": "1322480"
  },
  {
    "text": "but then it's immediately or worse on the right side this cheat compilation a request could trigger",
    "start": "1322480",
    "end": "1327580"
  },
  {
    "text": "additional compilations and suddenly you have a lot of cpu for this one request of course as you progress if you run",
    "start": "1327580",
    "end": "1336070"
  },
  {
    "text": "into your application for hours and millions of requests your cheat compiler hopefully will not matter anymore and",
    "start": "1336070",
    "end": "1341350"
  },
  {
    "text": "things will look differently but in your first couple minutes for the first couple hundred thousand requests there's",
    "start": "1341350",
    "end": "1348220"
  },
  {
    "text": "a big differences so this is here using Pierce record to plot the CPU",
    "start": "1348220",
    "end": "1355180"
  },
  {
    "text": "consumption and the memory usage over time so when it comes to throughput and",
    "start": "1355180",
    "end": "1361720"
  },
  {
    "text": "and and cheat compilation i've looked with for you I have here three ways to",
    "start": "1361720",
    "end": "1367510"
  },
  {
    "text": "implement the negation of value and negate one is return - I negate - is",
    "start": "1367510",
    "end": "1375220"
  },
  {
    "text": "adding a local variable doing some computation and negate three is yes it's",
    "start": "1375220",
    "end": "1381730"
  },
  {
    "text": "using the full the full power of of the Java object model to get there and I",
    "start": "1381730",
    "end": "1388990"
  },
  {
    "text": "will little quiz for you which of these versions is fastest all of them",
    "start": "1388990",
    "end": "1397660"
  },
  {
    "text": "excellent correct yes specifically if you use a modern compiler like C - or gravia all of these three will compile",
    "start": "1397660",
    "end": "1404650"
  },
  {
    "text": "to the exact same machine code and in the second scenario of course it's the usual canonicalization C compiler does",
    "start": "1404650",
    "end": "1411059"
  },
  {
    "text": "and in the third scenario is boxing animation that the compiler would do and my problem is specifically good at all",
    "start": "1411059",
    "end": "1418120"
  },
  {
    "text": "of these three the compiler can prove and kind of understand what the program does and reason about it in a way to",
    "start": "1418120",
    "end": "1424900"
  },
  {
    "text": "produce the same machine code now you would say like why why would that ever matter I'm not writing this type of code",
    "start": "1424900",
    "end": "1430570"
  },
  {
    "text": "right so yes hopefully you're not writing this type of code but on the other hand if you use very good",
    "start": "1430570",
    "end": "1436360"
  },
  {
    "text": "abstractions with inlining and utility methods these type of patterns often",
    "start": "1436360",
    "end": "1442900"
  },
  {
    "text": "occur when the compiler system because all of this might be hidden in a couple utility methods that you use at the",
    "start": "1442900",
    "end": "1449320"
  },
  {
    "text": "higher level abstraction and then the compiler can fold them all right so so these things actually occur quite often",
    "start": "1449320",
    "end": "1454870"
  },
  {
    "text": "in our JIT compiler code in in the JIT compiler itself like the chick compiler has literally a thousand",
    "start": "1454870",
    "end": "1461039"
  },
  {
    "text": "different optimizations I seeing a lot of talks about well and comparing this JIT compiler versus the other cheat",
    "start": "1461039",
    "end": "1466650"
  },
  {
    "text": "compiler it's a race between C compilers etcetera right the truth is JIT compilers literally",
    "start": "1466650",
    "end": "1472890"
  },
  {
    "text": "have a thousand different canonicalization optimizations in them and it's very hard to compare them",
    "start": "1472890",
    "end": "1478620"
  },
  {
    "text": "specifically if you only look at one tiny one because where it matters most is on a big on a big graph ring on a big",
    "start": "1478620",
    "end": "1487409"
  },
  {
    "text": "complex graph of methods and graphs this is where it actually matters most",
    "start": "1487409",
    "end": "1492840"
  },
  {
    "text": "whether the cheat compiler is optimizing this little kind of tiny micro over there might not be that relevant it's",
    "start": "1492840",
    "end": "1499830"
  },
  {
    "text": "also interesting it's interesting to look at and can be relevant if this is kind of the hottest loop in your application a lot of real-world",
    "start": "1499830",
    "end": "1506640"
  },
  {
    "text": "application however have like like literally hundred thousands of lines of",
    "start": "1506640",
    "end": "1511830"
  },
  {
    "text": "hot code and the cheat compiler will get the performance only by optimizing everything together and it's harder to",
    "start": "1511830",
    "end": "1518850"
  },
  {
    "text": "kind of do these comparisons so actually the third version here will run slower",
    "start": "1518850",
    "end": "1524640"
  },
  {
    "text": "if you run with the client compiler only in hotspot because the client compiler this C one faster compiler does not do",
    "start": "1524640",
    "end": "1532200"
  },
  {
    "text": "the same escape analysis so it will run that slower so you might be tempted to speed it up and write this type of",
    "start": "1532200",
    "end": "1540240"
  },
  {
    "text": "function here let's just you know let's just catch",
    "start": "1540240",
    "end": "1545370"
  },
  {
    "text": "something right because cache is a good right so the fun thing is this sudoc",
    "start": "1545370",
    "end": "1550470"
  },
  {
    "text": "some of this force example here will run faster on the client compiler but it",
    "start": "1550470",
    "end": "1555809"
  },
  {
    "text": "will run a lot slower on the C to compiler and the chromium compiler because suddenly for us as a compiler",
    "start": "1555809",
    "end": "1562799"
  },
  {
    "text": "like this is like what we call a value escapes right this is what the compiler",
    "start": "1562799",
    "end": "1567840"
  },
  {
    "text": "really hates as a compiler construction hurts me because because this is like",
    "start": "1567840",
    "end": "1573140"
  },
  {
    "text": "yeah like somebody writes the value to somewhere where I no longer can prove around it I can no longer reason about it right",
    "start": "1573140",
    "end": "1579630"
  },
  {
    "text": "and and so this is really something there suddenly we can no longer remove the object allocations because",
    "start": "1579630",
    "end": "1586380"
  },
  {
    "text": "another thread could see that and you would need a lot more clever kind of interest rate analysis to figure",
    "start": "1586380",
    "end": "1593370"
  },
  {
    "text": "out maybe that no other thread can see the value so in ahead of time compiled mode maybe we'll also be able to",
    "start": "1593370",
    "end": "1598950"
  },
  {
    "text": "optimize the last one at some point but the last one is kind of not recommended and this is a general rule of thumb in",
    "start": "1598950",
    "end": "1605700"
  },
  {
    "text": "terms of getting maximum throughput is keep everything local local data structures are practically free as long",
    "start": "1605700",
    "end": "1613110"
  },
  {
    "text": "as the compiler can prove there's read local and be very very careful about",
    "start": "1613110",
    "end": "1618330"
  },
  {
    "text": "what data you write globally that can be seen by other threads because a just-in-time compiler will always try to",
    "start": "1618330",
    "end": "1625230"
  },
  {
    "text": "optimize in a way where if you can prove only the one thread sees the value it can do much better yeah performance is",
    "start": "1625230",
    "end": "1635040"
  },
  {
    "text": "hard to measure this is actually from a from our screenshot from my internal",
    "start": "1635040",
    "end": "1640230"
  },
  {
    "text": "performance tool on an on a certain benchmark on a certain scarlet benchmark I noticed this is like running the",
    "start": "1640230",
    "end": "1646470"
  },
  {
    "text": "benchmark to peak performance so this is not warm-up this is peak performance of that benchmark run and we see that yeah",
    "start": "1646470",
    "end": "1653970"
  },
  {
    "text": "like this seems to vary a lot but it's not like every check in this one running",
    "start": "1653970",
    "end": "1659280"
  },
  {
    "text": "on every checking of the compiler I get like you know thousands of check-ins but but it is it is still like showing a lot",
    "start": "1659280",
    "end": "1667890"
  },
  {
    "text": "of our ability so the problem is that there's a lot of variability in the",
    "start": "1667890",
    "end": "1673770"
  },
  {
    "text": "voyage it compiler would create its performance because the profiling feedback that it has as an input is",
    "start": "1673770",
    "end": "1680000"
  },
  {
    "text": "actually like gathered in a not thread safe way and has a lot of variability in",
    "start": "1680000",
    "end": "1687030"
  },
  {
    "text": "it and then when the JIT compiler gets a good profile maybe it gets lucky and",
    "start": "1687030",
    "end": "1692340"
  },
  {
    "text": "produces a better version of the machine code will be better or maybe it gets unlucky and then you're a lot worse we",
    "start": "1692340",
    "end": "1699960"
  },
  {
    "text": "see quite a few benchmarks in our internal system where you have basically two states and you're alternating",
    "start": "1699960",
    "end": "1705060"
  },
  {
    "text": "between you're either fast or you slow but when you slow you keep being slow",
    "start": "1705060",
    "end": "1710610"
  },
  {
    "text": "and you're forced to keeping focus right so it's not like it's not like a variability between individual iterations of the benchmarks it's really",
    "start": "1710610",
    "end": "1716070"
  },
  {
    "text": "like the peak performance the final that is the peak performance it reaches the benchmark rank and it's very hard for us this is not",
    "start": "1716070",
    "end": "1722970"
  },
  {
    "text": "zoomed out over one and a half years in that benchmark so this is kind of the the work we do to improve things and",
    "start": "1722970",
    "end": "1729360"
  },
  {
    "text": "yeah over time we seem to be getting better here that's good news but but it",
    "start": "1729360",
    "end": "1734940"
  },
  {
    "text": "is is something that's still very hard for us to it's very hard for us to make improvements that are in the Platinum in",
    "start": "1734940",
    "end": "1741630"
  },
  {
    "text": "there like just 1% improvement for example because it's hard for us even to measure by to be actually improved",
    "start": "1741630",
    "end": "1747150"
  },
  {
    "text": "something and that's a pretty big problem because well you know if you improve 1% every week you will you will",
    "start": "1747150",
    "end": "1753570"
  },
  {
    "text": "double your performance or going to one and a half years so for us it's a big",
    "start": "1753570",
    "end": "1759090"
  },
  {
    "text": "challenge to get good measurements on this time and this is also for you when",
    "start": "1759090",
    "end": "1765960"
  },
  {
    "text": "you measure performance you need to be careful about basically repeating your",
    "start": "1765960",
    "end": "1771960"
  },
  {
    "text": "experiments getting error bars etc etc because one run might not see anything",
    "start": "1771960",
    "end": "1777030"
  },
  {
    "text": "like you got a really bad run here summer six six weeks ago six months ago I had a bad check-in or the machine was",
    "start": "1777030",
    "end": "1784049"
  },
  {
    "text": "doing something else I don't know but like and we got a couple of really good runs here so you should analyze all that",
    "start": "1784049",
    "end": "1790740"
  },
  {
    "text": "was but but generally like when you measure performance make sure it's repeatable you measure a couple times",
    "start": "1790740",
    "end": "1796770"
  },
  {
    "text": "etcetera because it's there's so much variability in the system so on you know T versus chip throughput this is gravity",
    "start": "1796770",
    "end": "1804870"
  },
  {
    "text": "mode and the top is Grahame on chip mode",
    "start": "1804870",
    "end": "1810059"
  },
  {
    "text": "at the blue one right and this is running a web server again and what we",
    "start": "1810059",
    "end": "1816299"
  },
  {
    "text": "see is the cheat compiler produces in the end two better machine code however",
    "start": "1816299",
    "end": "1823110"
  },
  {
    "text": "as you can see here this only pays off at about a hundred thousand requests up to about a hundred thousand requests the",
    "start": "1823110",
    "end": "1830340"
  },
  {
    "text": "end of time compiler is still faster but then sort of the cheat compiler takes over",
    "start": "1830340",
    "end": "1835520"
  },
  {
    "text": "so the JIT compiler does better because it has knowledge about how the application functions it has the",
    "start": "1835520",
    "end": "1841710"
  },
  {
    "text": "profiling feedback and it can be more aggressive about that but one of the",
    "start": "1841710",
    "end": "1847320"
  },
  {
    "text": "things you can do with your of time compilation is you can do profile guided optimizations as well in ahead of time",
    "start": "1847320",
    "end": "1852780"
  },
  {
    "text": "compiled mode it's a little bit harder to set up so from a manageability perspective it's",
    "start": "1852780",
    "end": "1857820"
  },
  {
    "text": "harder but what you can do is also this problem you can run native image with -",
    "start": "1857820",
    "end": "1862890"
  },
  {
    "text": "- pgo instrument it gives you an instrumented binary you run that on a",
    "start": "1862890",
    "end": "1868080"
  },
  {
    "text": "couple example workloads and this gives you a profiling data you feed that",
    "start": "1868080",
    "end": "1874530"
  },
  {
    "text": "profiling data into another run of native image and then you get your final fully profile fully up optimized execute",
    "start": "1874530",
    "end": "1881850"
  },
  {
    "text": "demo so so this is this of course",
    "start": "1881850",
    "end": "1887130"
  },
  {
    "text": "depends on whether your vocals are relevant or not right how could your final performance will be but the good",
    "start": "1887130",
    "end": "1893250"
  },
  {
    "text": "news is the profile doesn't need to be 100% accurate it's okay to be approximately ok-ish yeah you laugh but",
    "start": "1893250",
    "end": "1902880"
  },
  {
    "text": "that's it's kind of that's kind of important actually for us because even you and when we are running JIT",
    "start": "1902880",
    "end": "1909270"
  },
  {
    "text": "compilation mode it's important for us to not a hundred percent trusted profiles because the profiles are just",
    "start": "1909270",
    "end": "1914580"
  },
  {
    "text": "an approximation so if you would go handy percent on the profiles you would see even more random weirdness in",
    "start": "1914580",
    "end": "1920310"
  },
  {
    "text": "performance right so we actually as a JIT compilers need to be like yeah that maybe that's like a recommendation but",
    "start": "1920310",
    "end": "1926670"
  },
  {
    "text": "yeah we need to be relatively careful not to base too much on the profiles but",
    "start": "1926670",
    "end": "1931830"
  },
  {
    "text": "on on the ahead of time compiled version of this it makes the throughput a lot better with gravy Ameer T and it",
    "start": "1931830",
    "end": "1939900"
  },
  {
    "text": "basically moves to the point where hotspot chit with chromium overtakes",
    "start": "1939900",
    "end": "1946740"
  },
  {
    "text": "crabby Meo T to about a half a million requests we then go a little bit down",
    "start": "1946740",
    "end": "1954960"
  },
  {
    "text": "that has to do that our AO t RT compiler has not rit binary doesn't have such a",
    "start": "1954960",
    "end": "1960840"
  },
  {
    "text": "good garbage collector and then a later stages of the application the performance of the garbage collector is is it's getting a problem in the NT mode",
    "start": "1960840",
    "end": "1969870"
  },
  {
    "text": "but generally with PG o you can get relatively close to your cheat code so",
    "start": "1969870",
    "end": "1975690"
  },
  {
    "text": "to compare here unity versus chittim click performance the cheat has an advantage because this profiling is at",
    "start": "1975690",
    "end": "1981270"
  },
  {
    "text": "startup and it can make the other thing you can do is it can make optimistic assumptions so it can",
    "start": "1981270",
    "end": "1988170"
  },
  {
    "text": "it can make the assumption that for example a certain past is not taken and that later bail out of it this is what's",
    "start": "1988170",
    "end": "1995940"
  },
  {
    "text": "called deoptimization in hotspot when you optimize but I need to optimize if it turns out that your optimization was",
    "start": "1995940",
    "end": "2004040"
  },
  {
    "text": "just not accurate this is something the chit compiler can do because it can recompile the head of time compiler",
    "start": "2004040",
    "end": "2010400"
  },
  {
    "text": "cannot do that it needs to kind of needs to handle all cases except for of course",
    "start": "2010400",
    "end": "2017000"
  },
  {
    "text": "when it can brew statically that something would not occur but needs to be ready for all theoretically possible",
    "start": "2017000",
    "end": "2022670"
  },
  {
    "text": "cases the cheat compiler can be much more aggressive and on T yeah we need to",
    "start": "2022670",
    "end": "2027710"
  },
  {
    "text": "handle all cases profile guided optimizations help us a little bit because because we can then also",
    "start": "2027710",
    "end": "2035180"
  },
  {
    "text": "optimize better the advantage dude he has here and this is a pretty",
    "start": "2035180",
    "end": "2040450"
  },
  {
    "text": "significant one is that your performance is more predictable because one of the",
    "start": "2040450",
    "end": "2046820"
  },
  {
    "text": "downsides of the cheat is it is trying to figure like it is your profile it takes is from your startup your",
    "start": "2046820",
    "end": "2052730"
  },
  {
    "text": "application this means and it tries to optimize for that for the common case it",
    "start": "2052730",
    "end": "2059060"
  },
  {
    "text": "always tries to optimize for the common case but what if I care about the exceptional case let's say I have a",
    "start": "2059060",
    "end": "2065510"
  },
  {
    "text": "trading application and the common case is nothing happens nothing happens and then suddenly boom the market crashes",
    "start": "2065510",
    "end": "2071658"
  },
  {
    "text": "right then in this scenario the exceptional case happens my code is not optimized for that I might run go back",
    "start": "2071659",
    "end": "2078950"
  },
  {
    "text": "to your interpreter and it might be specifically slow in that exceptional case so in a scenario where you want to",
    "start": "2078950",
    "end": "2085970"
  },
  {
    "text": "optimize for the exceptional case the eot base profile added optimizations is",
    "start": "2085970",
    "end": "2091460"
  },
  {
    "text": "actually significantly better because you can train on your exceptional case get the profile and then compile with",
    "start": "2091460",
    "end": "2099590"
  },
  {
    "text": "that profile instead of like training just for the common case so generally I",
    "start": "2099590",
    "end": "2108560"
  },
  {
    "text": "like benchmarks and I think you should have more so the main reason for that is",
    "start": "2108560",
    "end": "2116860"
  },
  {
    "text": "optimizing a compiler for a small number of benchmarks is the equivalent of",
    "start": "2116860",
    "end": "2121970"
  },
  {
    "text": "doing overfitting in a machine learning algorithm it's like your pen your compiler will be really good on the",
    "start": "2121970",
    "end": "2127910"
  },
  {
    "text": "benchmarks that you trained him is like four years decades but then you give him",
    "start": "2127910",
    "end": "2133430"
  },
  {
    "text": "a little bit of a different program and suddenly boom like the heuristics no longer work etc etc so we really need to",
    "start": "2133430",
    "end": "2140240"
  },
  {
    "text": "be careful as compiler constructors to avoid overfitting I mean ideally you would have maybe we can learn here from",
    "start": "2140240",
    "end": "2146450"
  },
  {
    "text": "the machine learning community and have like tests at validation set and height height sort of the validation set from",
    "start": "2146450",
    "end": "2152930"
  },
  {
    "text": "from from the compiler optimizer train but like this is quite important and",
    "start": "2152930",
    "end": "2158630"
  },
  {
    "text": "this is why we actually started a little project with some academic collaborators that is trying to create more benchmarks",
    "start": "2158630",
    "end": "2165290"
  },
  {
    "text": "specifically for more than Java workloads we call it Renaissance benchmark suite and my personal opinion",
    "start": "2165290",
    "end": "2171020"
  },
  {
    "text": "is that all benchmark data is useful careful with the conclusions of course as always because first of all you might",
    "start": "2171020",
    "end": "2176720"
  },
  {
    "text": "not matter what you think you measure and second it might not mean what you think it means so but still I'm not",
    "start": "2176720",
    "end": "2184160"
  },
  {
    "text": "saying like it's important to get the data right and and and get as much data as possible even if conclusions might",
    "start": "2184160",
    "end": "2191810"
  },
  {
    "text": "not be that definitive as you might want them to be so if you're in this constant def I don't go into details on this you",
    "start": "2191810",
    "end": "2198470"
  },
  {
    "text": "can look up the website we are this is a benchmark suite that has quite some Scala code in it",
    "start": "2198470",
    "end": "2204530"
  },
  {
    "text": "Kafka SPARC workloads and umbrellas that are typically underrepresented in traditional benchmarks like spec TM 2008",
    "start": "2204530",
    "end": "2212180"
  },
  {
    "text": "or spec GV 2015 all right yo T versus",
    "start": "2212180",
    "end": "2218089"
  },
  {
    "text": "chit max latency the max latency is more a garbage collection domain usually that's why I don't talk about it in that",
    "start": "2218089",
    "end": "2223190"
  },
  {
    "text": "much detail and so for latency usually you go to garbage collector first because that's often your biggest",
    "start": "2223190",
    "end": "2230210"
  },
  {
    "text": "introduce doctor of latency problems there's a couple low latency options in",
    "start": "2230210",
    "end": "2235880"
  },
  {
    "text": "hotspot g1 CMS set GCE shenandoah and in our UT",
    "start": "2235880",
    "end": "2242060"
  },
  {
    "text": "compiled code at the moment you only have a regular stop and copy collector this works well if your heap is very",
    "start": "2242060",
    "end": "2247579"
  },
  {
    "text": "small so if you like in a hundred megabyte to a new megabyte heap configurations for your web server for your lambda functions it doesn't work",
    "start": "2247579",
    "end": "2254180"
  },
  {
    "text": "well when the heap is big because you get a lot of latency one one thing here of course is because your",
    "start": "2254180",
    "end": "2260300"
  },
  {
    "text": "startup is the forest you can actually use this to shut down your process instead of doing as you see if you for",
    "start": "2260300",
    "end": "2267290"
  },
  {
    "text": "example if your configuration but you have a load balancer where you can immediately just start a new process and give the the worker a new process so",
    "start": "2267290",
    "end": "2274790"
  },
  {
    "text": "it's not clear that in all setups that you see is that important here and the",
    "start": "2274790",
    "end": "2280160"
  },
  {
    "text": "other thing here is that like with native image you don't need to add a lot",
    "start": "2280160",
    "end": "2285829"
  },
  {
    "text": "of applications onto the same application server but you can have one native image per app which which reduces",
    "start": "2285829",
    "end": "2292609"
  },
  {
    "text": "the the influence the apps have on each other so latency has sometimes",
    "start": "2292609",
    "end": "2298089"
  },
  {
    "text": "trade-offs versus peak performance one is loop save points so when you have a loop we are usually removing the save",
    "start": "2298089",
    "end": "2305480"
  },
  {
    "text": "point in the loop that would allow a threat to stop for garbage collection this gives us better pick the former's",
    "start": "2305480",
    "end": "2312260"
  },
  {
    "text": "and we do that if the loop is counted we kind of proved that that you can you will at some point exit the loop so this",
    "start": "2312260",
    "end": "2320180"
  },
  {
    "text": "is an optimization that helps peak performance but can introduce more latency because of because the threads",
    "start": "2320180",
    "end": "2326540"
  },
  {
    "text": "take longer until the garbage collection can finally happen and they're parallel",
    "start": "2326540",
    "end": "2332150"
  },
  {
    "text": "stop debris OCC is usually the best for peak throughput so all you care about is the final answer and you don't care",
    "start": "2332150",
    "end": "2337280"
  },
  {
    "text": "about latency parallel stop the world GC is probably best one thing and latency is yes GC is",
    "start": "2337280",
    "end": "2343730"
  },
  {
    "text": "important but if you have a low latency garbage collector then suddenly your compiled code performance will also have",
    "start": "2343730",
    "end": "2349790"
  },
  {
    "text": "meta again because because like it doesn't help me if I don't stop for",
    "start": "2349790",
    "end": "2355670"
  },
  {
    "text": "garbage collection but my requests just take a hundred milliseconds longer right it doesn't help me it both of these need",
    "start": "2355670",
    "end": "2361700"
  },
  {
    "text": "to be optimized in the end finally your",
    "start": "2361700",
    "end": "2367640"
  },
  {
    "text": "T versus chip packaging size on the chit site you can use in new activity case",
    "start": "2367640",
    "end": "2374210"
  },
  {
    "text": "there is a awesome tool called che link for smaller packaging that allows you to package your java applications and you",
    "start": "2374210",
    "end": "2381740"
  },
  {
    "text": "can run the cheat compiler on a lightweight docker image but in the chit mode you have a big",
    "start": "2381740",
    "end": "2387660"
  },
  {
    "text": "constant overhead for packaging because you need to include class libraries you",
    "start": "2387660",
    "end": "2392760"
  },
  {
    "text": "need to form the GDK you need to include the binaries for hot spot etc on the OT",
    "start": "2392760",
    "end": "2398790"
  },
  {
    "text": "side you can have everything in a single binary and you can run it on a bare metal docker image so you can actually",
    "start": "2398790",
    "end": "2406770"
  },
  {
    "text": "run it on a very very slim docker image we get like docker image size of four",
    "start": "2406770",
    "end": "2412860"
  },
  {
    "text": "smaller web servers total of like seven megabytes or something like that",
    "start": "2412860",
    "end": "2417950"
  },
  {
    "text": "so the the constant of at is smaller but again here if your application is super complex the yotie mode is starting to",
    "start": "2417950",
    "end": "2427170"
  },
  {
    "text": "look a little worse so if you have like hundreds of megabytes of char files let's say then the final machine code",
    "start": "2427170",
    "end": "2434430"
  },
  {
    "text": "might be also quite big because the machine code of course is depending on your optimizations larger than the buy",
    "start": "2434430",
    "end": "2440340"
  },
  {
    "text": "codes but it depends on on many factors here also how how long your class names",
    "start": "2440340",
    "end": "2446670"
  },
  {
    "text": "are etcetera so on P courses packaging",
    "start": "2446670",
    "end": "2452070"
  },
  {
    "text": "trade-offs when we create a native image we can actually ask the compiler to",
    "start": "2452070",
    "end": "2457350"
  },
  {
    "text": "produce a bigger binary size for better performance or smaller banner size for",
    "start": "2457350",
    "end": "2463500"
  },
  {
    "text": "less performance and that is because many compiler optimizations in the end boiled down to duplicating code this is",
    "start": "2463500",
    "end": "2471810"
  },
  {
    "text": "kind of the the mother of all optimizations is duplicating code and optimizing it for a specific context or path right and so in this P vs.",
    "start": "2471810",
    "end": "2480930"
  },
  {
    "text": "packaging trade-offs we can have inline in code duplication which help us we speak but but increase the size of your",
    "start": "2480930",
    "end": "2487380"
  },
  {
    "text": "packaging or in the cheat mode in to increase the amount of memory occupied",
    "start": "2487380",
    "end": "2492420"
  },
  {
    "text": "by a just-in-time compiled code in the code cache so this is not a one of these trade-offs of in",
    "start": "2492420",
    "end": "2499200"
  },
  {
    "text": "the chip mode this is actually a Tweetup of memory footprint versus peak in the OT mode this is a trade-off of packaging",
    "start": "2499200",
    "end": "2505830"
  },
  {
    "text": "size versus peak alright to summarize and conclude Guardium chick versus",
    "start": "2505830",
    "end": "2512640"
  },
  {
    "text": "gravia man out of time chromium cheat at the moment you use chromium shitman you are interested in Peaks report",
    "start": "2512640",
    "end": "2519410"
  },
  {
    "text": "specifically the crowd compiler and Enterprise Edition is totally optimized cowards like achieving the best possible",
    "start": "2519410",
    "end": "2525480"
  },
  {
    "text": "machine code at the cost of some compilation times growling max",
    "start": "2525480",
    "end": "2531180"
  },
  {
    "text": "latency if you interested in that they use gradient cheat because you can use the garbage collectors from hotspot and",
    "start": "2531180",
    "end": "2537690"
  },
  {
    "text": "you don't need any configuration because one of the things is of course that in our ahead of time compared mode you",
    "start": "2537690",
    "end": "2542880"
  },
  {
    "text": "currently need depending on your reflection users of your application you might need some configuration to create",
    "start": "2542880",
    "end": "2549119"
  },
  {
    "text": "the ahead of time compiled image that is because in the other find compiled mode we need to guide the closed world",
    "start": "2549119",
    "end": "2555239"
  },
  {
    "text": "analysis cowards cowards are being able to produce the final packaging in gravia",
    "start": "2555239",
    "end": "2561269"
  },
  {
    "text": "mio t use that if you care about startup time memory footprint so for example also maybe we are like 20% slower in",
    "start": "2561269",
    "end": "2567630"
  },
  {
    "text": "throughput but on throughput per memory we might be a lot better and depending",
    "start": "2567630",
    "end": "2572910"
  },
  {
    "text": "on your deployment this might be actually what you care about and packaging size is usually smaller so",
    "start": "2572910",
    "end": "2580200"
  },
  {
    "text": "this is all about trade-offs right but yeah and the question is can you get ot better and there's a couple of things",
    "start": "2580200",
    "end": "2586559"
  },
  {
    "text": "you're currently exploring to get you t better on the areas of attitude compiler currently is better one is the profile",
    "start": "2586559",
    "end": "2594239"
  },
  {
    "text": "guided optimizations we collect the profiles up front another one is we're working on a low latency GC option also for the native",
    "start": "2594239",
    "end": "2600839"
  },
  {
    "text": "images so this puts at least on max latency that two versions at the same",
    "start": "2600839",
    "end": "2608430"
  },
  {
    "text": "level and then we are continuously working to improve the boy you can",
    "start": "2608430",
    "end": "2613950"
  },
  {
    "text": "create native images by having for example a tracing agent that will automatically create your configuration",
    "start": "2613950",
    "end": "2620420"
  },
  {
    "text": "but currently if I want to use native images the best bet is to use one of the",
    "start": "2620420",
    "end": "2625680"
  },
  {
    "text": "frameworks that has support for it meaning high lead on Mac ranaut or quotas because those frameworks help you",
    "start": "2625680",
    "end": "2632609"
  },
  {
    "text": "with some of the configurations you need to create that small thing alright gray Liam can do much more like this was the",
    "start": "2632609",
    "end": "2639420"
  },
  {
    "text": "talk about about just chit versus your tea but crime itself can do much more",
    "start": "2639420",
    "end": "2644849"
  },
  {
    "text": "than that it can run many languages this is a node.js application using Java and",
    "start": "2644849",
    "end": "2649950"
  },
  {
    "text": "R to plot something if you're interested in any interesting things I recommend the top 10 things to",
    "start": "2649950",
    "end": "2656940"
  },
  {
    "text": "do with Guardian blog post on our medium site that has sort of all the variations we can do it's a big project it's a",
    "start": "2656940",
    "end": "2664230"
  },
  {
    "text": "research project but now we are also in production so you're also not an actual product but you can still a little bit",
    "start": "2664230",
    "end": "2670230"
  },
  {
    "text": "field as a research project because there's many additional areas we are still continued to explore this chromium",
    "start": "2670230",
    "end": "2677870"
  },
  {
    "text": "chromium is an ecosystem with a multiplicative value add you can run many languages you can have language",
    "start": "2677870",
    "end": "2684540"
  },
  {
    "text": "independent tooling into ability optimizations and you can run them in the hot spot iam nodejs standalone UT",
    "start": "2684540",
    "end": "2691670"
  },
  {
    "text": "etc and we absolutely welcome anyone to add your own language or add your own",
    "start": "2691670",
    "end": "2697230"
  },
  {
    "text": "embedding and or otherwise make use of choir VM it's a big community it is it",
    "start": "2697230",
    "end": "2707460"
  },
  {
    "text": "is in chromium that org you find documentation downloads etc we are on github is a git up repository our main",
    "start": "2707460",
    "end": "2714990"
  },
  {
    "text": "repository that has all the optimizations in there you see like many",
    "start": "2714990",
    "end": "2720180"
  },
  {
    "text": "commits here from our core team and we welcome anybody to to join us here in",
    "start": "2720180",
    "end": "2725670"
  },
  {
    "text": "that community on Twitter github or on the website with that I'm at the end of",
    "start": "2725670",
    "end": "2732060"
  },
  {
    "text": "the talk I hope I could I could give you some insights or or some interesting infos",
    "start": "2732060",
    "end": "2737370"
  },
  {
    "text": "I'd like to thank very much for your attention thank you so much and I am ready to answer your questions",
    "start": "2737370",
    "end": "2742810"
  },
  {
    "text": "[Applause]",
    "start": "2742810",
    "end": "2751610"
  },
  {
    "text": "have you considered using epsilon in the benchmarking and I guess the other",
    "start": "2759660",
    "end": "2766140"
  },
  {
    "text": "question when it comes to carbs question is like for t why would you not use a parallel collector and because the other",
    "start": "2766140",
    "end": "2772530"
  },
  {
    "text": "options are for those size heaps are much more expensive in my experience",
    "start": "2772530",
    "end": "2779900"
  },
  {
    "text": "right thank you thanks Kay so the question was have you considered to use epsilon or also the parallels you see we",
    "start": "2779900",
    "end": "2788640"
  },
  {
    "text": "have not yet done epsilon but I think it's an excellent suggestion I think epsilon would totally make sense",
    "start": "2788640",
    "end": "2794160"
  },
  {
    "text": "absolutely is the garbage collector that doesn't do any garbage collection at all and it can absolutely make sense if",
    "start": "2794160",
    "end": "2801000"
  },
  {
    "text": "because the start up is a good you shut down the process so I think we should certainly add the epsilon option on the",
    "start": "2801000",
    "end": "2807840"
  },
  {
    "text": "problem sheet see like for max through Kurt yes but like I'm not sure whether",
    "start": "2807840",
    "end": "2813690"
  },
  {
    "text": "in a typical native image it would make that much of a difference we are more",
    "start": "2813690",
    "end": "2819210"
  },
  {
    "text": "like we're currently more exploring to get a cheap one style garbage collector into native image oh you don't like that",
    "start": "2819210",
    "end": "2828140"
  },
  {
    "text": "the thing is if you're going to put a concurrent garbage collector in you're gonna take a throughput hit on the",
    "start": "2828170",
    "end": "2833880"
  },
  {
    "text": "allocators right which would you don't take with the parallel collector and",
    "start": "2833880",
    "end": "2839760"
  },
  {
    "text": "with small heaps you don't take the pause time hit that you do with large heaps and so with the g1 you're gonna",
    "start": "2839760",
    "end": "2846750"
  },
  {
    "text": "get a boat the same pause time characteristic but you're gonna get about a 10 to 15% hit in throughput",
    "start": "2846750",
    "end": "2853220"
  },
  {
    "text": "meaning that you're gonna take a throughput hit not really benefit in terms of the positive characteristics of",
    "start": "2853220",
    "end": "2859530"
  },
  {
    "text": "the whole thing and you're gonna have to run extra threads to do things like our set refinements and things like that so which means you get a yet another power",
    "start": "2859530",
    "end": "2867750"
  },
  {
    "text": "hit in terms of processor right yeah right yeah so for a heap that small we",
    "start": "2867750",
    "end": "2875610"
  },
  {
    "text": "still highly recommend people use a parallel collector over anything else right right yes that's good to touch",
    "start": "2875610",
    "end": "2882300"
  },
  {
    "text": "some because if the heap is small enough the parallel collector even if you stop everything it will not introduce too",
    "start": "2882300",
    "end": "2888840"
  },
  {
    "text": "much additional light and say yeah that's a good point",
    "start": "2888840",
    "end": "2893180"
  },
  {
    "text": "so cut so kind of on the the same topic is the are we basically saying like",
    "start": "2896060",
    "end": "2903660"
  },
  {
    "text": "ahead of time compilation might not make sense for large heaps or do we think",
    "start": "2903660",
    "end": "2908730"
  },
  {
    "text": "that we could also find a place for a large heaps with a yes so so that's my",
    "start": "2908730",
    "end": "2913740"
  },
  {
    "text": "ahead of time compilation sense for Lordships or not so I think you can you",
    "start": "2913740",
    "end": "2918960"
  },
  {
    "text": "can at least make sure that for large heaps you don't have a disadvantage with the cheat compilation the thing of",
    "start": "2918960",
    "end": "2925260"
  },
  {
    "text": "course is the question is large hips and typically for use by job applications that are running for a very long time",
    "start": "2925260",
    "end": "2931410"
  },
  {
    "text": "and when you have a large heap your application payload data is so big that",
    "start": "2931410",
    "end": "2937890"
  },
  {
    "text": "the savings and memory from the cheat code from the out of time compilation all is not that big so on your typical",
    "start": "2937890",
    "end": "2943410"
  },
  {
    "text": "application that uses a huge heap and it runs for long I don't think there's a",
    "start": "2943410",
    "end": "2948480"
  },
  {
    "text": "lot of reason to ahead of time compile and and therefore we can make it that",
    "start": "2948480",
    "end": "2954720"
  },
  {
    "text": "it's practically gives the same characteristics but it also doesn't give you the benefits that's good thank you",
    "start": "2954720",
    "end": "2967560"
  },
  {
    "text": "so much [Applause]",
    "start": "2967560",
    "end": "2972369"
  }
]
[
  {
    "text": "[Music]",
    "start": "760",
    "end": "22530"
  },
  {
    "text": "so we're going to talk about scaling it's available uh on GitHub um you can follow it on Twitter uh",
    "start": "25320",
    "end": "32960"
  },
  {
    "text": "and wanted to thank stackmob and also Mirana for hosting this schola meet",
    "start": "32960",
    "end": "38879"
  },
  {
    "text": "up okay so the the talk is going to be pretty straight forward we're going to talk about scalding we're actually uh",
    "start": "38879",
    "end": "45320"
  },
  {
    "text": "going to tell you how we use it at Twitter when I go into how it's implemented the extra special sauce that you get this time that you didn't get",
    "start": "45320",
    "end": "51680"
  },
  {
    "text": "last time if you've seen any previous talks is the in detail algorithm on how to deal with heavy data skew in your in",
    "start": "51680",
    "end": "58600"
  },
  {
    "text": "your data sets that's pretty big deal I kind of alluded to it in the past I talked about it how do you walk the",
    "start": "58600",
    "end": "64119"
  },
  {
    "text": "graph the Twitter graph given that like you know one in 10 people follow Lady Gaga and like one in 10 people follow",
    "start": "64119",
    "end": "70159"
  },
  {
    "text": "Justin Bieber right you're gonna like something naive you're gonna hash Lady Gaga to one machine and then like you're",
    "start": "70159",
    "end": "76439"
  },
  {
    "text": "going to send 10% of your edges to that machine it's going to be a big disaster and then our Gus only like you know one",
    "start": "76439",
    "end": "81799"
  },
  {
    "text": "in 15 people follow him and so that that machine won't be like loaded at all so",
    "start": "81799",
    "end": "86840"
  },
  {
    "text": "like how do you deal with that and last we're going to talk a little bit about like what's coming up next for scaling",
    "start": "86840",
    "end": "92240"
  },
  {
    "text": "and the cool thing is like people guilt guilt us into like doing one thing or another and you could do that and the next time we give a talk maybe your",
    "start": "92240",
    "end": "98320"
  },
  {
    "text": "awesome feature will be the next thing in because like now it's like totally new stuff so okay so",
    "start": "98320",
    "end": "105360"
  },
  {
    "text": "um this is what scalding looks like so what's scalding all about so scalding um so uh scalding came about because uh",
    "start": "105360",
    "end": "113479"
  },
  {
    "text": "really Avi Bryant who um is now moving to Etsy and will be bringing scalding there they uh Ed uh Scala sorry uh Ruby",
    "start": "113479",
    "end": "122439"
  },
  {
    "text": "and cascading now they don't use um SC scalding yet as far as I know but um he",
    "start": "122439",
    "end": "128679"
  },
  {
    "text": "didn't really want to write Pig anymore so if you're like really into Pig and like Pig's awesome and you want everything to be SQL like scalding is",
    "start": "128679",
    "end": "134959"
  },
  {
    "text": "probably not going to be for you and that like that's cool like everybody can do their own thing there's a lot of different uh projects what what scalding",
    "start": "134959",
    "end": "140920"
  },
  {
    "text": "is all about is trying to make the Scala collections API somewhat close to like a",
    "start": "140920",
    "end": "147800"
  },
  {
    "text": "table model of computation that you would see in a database or in a spreadsheet there are some people who",
    "start": "147800",
    "end": "154319"
  },
  {
    "text": "are kind of like on either end of this picture so they're like I'm I'm going to try to make Hadoop look like a like a",
    "start": "154319",
    "end": "159640"
  },
  {
    "text": "database for you that's not what what scalding is trying to do some people are on the other end of the picture where they're trying to make like Hadoop look",
    "start": "159640",
    "end": "166400"
  },
  {
    "text": "like just exactly like Computing on collections so they're going to give you a list and you're going to do like",
    "start": "166400",
    "end": "172120"
  },
  {
    "text": "reduces on this list you're and and and scalding is not exactly doing that either right now so instead that we have",
    "start": "172120",
    "end": "178280"
  },
  {
    "text": "this picture so the idea idea here is that we have all your your famili so uh just to get an idea how many of you like",
    "start": "178280",
    "end": "183840"
  },
  {
    "text": "are all like crazy into Scala already and like you know everything you do is a moad and like you know everything's",
    "start": "183840",
    "end": "189640"
  },
  {
    "text": "awesome like you know Life's good okay how many of you like I heard Scola like might be cool and I know basically",
    "start": "189640",
    "end": "195879"
  },
  {
    "text": "nothing about it and it's sort of like Java and I maybe in the future want to do that so that's kind of more okay",
    "start": "195879",
    "end": "201840"
  },
  {
    "text": "we're dealing with a mix there so the the functions that you see here",
    "start": "201840",
    "end": "209000"
  },
  {
    "text": "have functions of the same name in The Scholar collection's API so flatmap is one of these things that freaks people",
    "start": "209000",
    "end": "215280"
  },
  {
    "text": "out if they're if they've never heard of it but it's a like a really and shockingly useful concept that it's like",
    "start": "215280",
    "end": "221000"
  },
  {
    "text": "I want to go through a list and rather than mapping each item in in that list",
    "start": "221000",
    "end": "226120"
  },
  {
    "text": "onto something I want to map each item in that list onto a set of things and",
    "start": "226120",
    "end": "232159"
  },
  {
    "text": "then glue them all together and why is this so cool like if I gave you just one function map or flat map you'd be fool",
    "start": "232159",
    "end": "240000"
  },
  {
    "text": "to take flat map because I could just take sorry I'm a Fool apparently you'd",
    "start": "240000",
    "end": "245200"
  },
  {
    "text": "be a fool to take map why because you could just map each element in flat map",
    "start": "245200",
    "end": "250239"
  },
  {
    "text": "to a list of one thing right so I can simulate your your map function with my",
    "start": "250239",
    "end": "255840"
  },
  {
    "text": "flat map no problem but also I could do a filter if I only want to keep half the elements I could map the ones I don't",
    "start": "255840",
    "end": "262720"
  },
  {
    "text": "want to keep onto a list of zero items right so flat map is like is like the",
    "start": "262720",
    "end": "268000"
  },
  {
    "text": "canonical map in map produce that you see in Hadoop so with just flat map",
    "start": "268000",
    "end": "273840"
  },
  {
    "text": "you're basically good to go if you just Implement that and get it right you're fine okay so this appears here so for",
    "start": "273840",
    "end": "282440"
  },
  {
    "text": "some ridiculous reason it must I I imagine someone wrote the first word count example for uh map reduce",
    "start": "282440",
    "end": "288479"
  },
  {
    "text": "programming everyone has everyone does this and because we're un I'm unimaginative really it's my fault um so",
    "start": "288479",
    "end": "295759"
  },
  {
    "text": "this is the implementation and scaling so we take a text line it might be like you know all the web pages in the world",
    "start": "295759",
    "end": "303520"
  },
  {
    "text": "and like we're going to look at these line by line and the parallelism comes because",
    "start": "303520",
    "end": "309800"
  },
  {
    "text": "this map is fundamentally parallelizable and in Hadoop you'll have a bunch of nodes 100 maybe a thousand because hudo",
    "start": "309800",
    "end": "316440"
  },
  {
    "text": "kind of sucks it's not like a million nodes but like you know a lot of nodes um and you're going to go through and",
    "start": "316440",
    "end": "322039"
  },
  {
    "text": "process all of those in parallel because the way the algorithm is structured you know that it must be you know there's there's nothing that can interfere",
    "start": "322039",
    "end": "328639"
  },
  {
    "text": "there's no concurrency that are going to show up so you map each line onto in this case all the words in that line so",
    "start": "328639",
    "end": "336479"
  },
  {
    "text": "you can do this in scalding because you can just inline functions right there if you're familiar with something like pig",
    "start": "336479",
    "end": "342440"
  },
  {
    "text": "or your you know um I don't know like SQL you can't very easily just Jam your",
    "start": "342440",
    "end": "347759"
  },
  {
    "text": "own functions in here we're taking this function tokenize which we Define here and it's a really simple function it it",
    "start": "347759",
    "end": "354680"
  },
  {
    "text": "I don't know um it replaces anything it's not all these characters with empty",
    "start": "354680",
    "end": "360800"
  },
  {
    "text": "space and then it splits on Spaces using a regular expression just normal Java uh",
    "start": "360800",
    "end": "366840"
  },
  {
    "text": "functions there are all there in the Java STL Java standard library on te on",
    "start": "366840",
    "end": "372599"
  },
  {
    "text": "strings so once you've done this you've taken each each line and mapped it onto",
    "start": "372599",
    "end": "378479"
  },
  {
    "text": "a list of words so if it was like hello how are you that one line becomes now a",
    "start": "378479",
    "end": "383599"
  },
  {
    "text": "list of hello how are you right and then you go on to the next line and you keep",
    "start": "383599",
    "end": "390080"
  },
  {
    "text": "doing that so you've glued all these words together into you this giant like very simple list of single words and now",
    "start": "390080",
    "end": "397400"
  },
  {
    "text": "there's a function called groupby this works a little bit different in scaling than it does in Scala and Scala it takes a function and it says I'm G to I'm",
    "start": "397400",
    "end": "403840"
  },
  {
    "text": "going to look at this thing in your list and I'm going to map it onto a key and so like a simple way to think about this",
    "start": "403840",
    "end": "410080"
  },
  {
    "text": "might be that I'm going to map like you know we want to sort all the men and women in this room and the Sorting",
    "start": "410080",
    "end": "416199"
  },
  {
    "text": "function will return either M or F right and that's your group by function and",
    "start": "416199",
    "end": "421479"
  },
  {
    "text": "then you're going to get a mapping that takes M and then the list of all the men",
    "start": "421479",
    "end": "427479"
  },
  {
    "text": "and then F and a list of all the women right that's how Map ruce works it",
    "start": "427479",
    "end": "432960"
  },
  {
    "text": "basically it's those two things you have the map this is where you do the shuffling you do this group and then you",
    "start": "432960",
    "end": "438599"
  },
  {
    "text": "do some reduction on it okay so in this case what we're grouping on is the word",
    "start": "438599",
    "end": "444199"
  },
  {
    "text": "itself so each word will be sent to a different list so we'll have you you",
    "start": "444199",
    "end": "449599"
  },
  {
    "text": "know hello all the hellos will be in one word all the hows will be in one word all the 's will sorry all the hell will",
    "start": "449599",
    "end": "456120"
  },
  {
    "text": "be in one list all the hows will be in one list all the 's will be in one list and so on down the line right and now",
    "start": "456120",
    "end": "463039"
  },
  {
    "text": "we're going to do a really trivial calculation on that list which is let me get the size of that list so now you've changed",
    "start": "463039",
    "end": "471039"
  },
  {
    "text": "these all these sentences into this map of word how long was the list but the",
    "start": "471039",
    "end": "478360"
  },
  {
    "text": "length of the list was just how how many times that word appeared that's word count right how appeared five times you",
    "start": "478360",
    "end": "485240"
  },
  {
    "text": "appeared two times Etc and now you've got that now you've got this now You' got two columns now you've got the word",
    "start": "485240",
    "end": "492479"
  },
  {
    "text": "column and the size column and you can keep doing reductions",
    "start": "492479",
    "end": "497680"
  },
  {
    "text": "in scalling you could keep going you could say um uh we could say give me the",
    "start": "497680",
    "end": "502840"
  },
  {
    "text": "first character in each word and like you know I don't know treat them as numbers and add them all up you can keep",
    "start": "502840",
    "end": "508319"
  },
  {
    "text": "adding more and more reduction and those would all happen in that same reduced phase on on Hadoop so this is",
    "start": "508319",
    "end": "515159"
  },
  {
    "text": "like awesome if you don't know much about Hadoop or Scola it's like you know welcome to being lost but uh because",
    "start": "515159",
    "end": "521399"
  },
  {
    "text": "it's like it's like it's like how much can one person introduce one in one talk but so finally when we've got that we",
    "start": "521399",
    "end": "527920"
  },
  {
    "text": "just write it out and boom that's it that's it that's like the the prototypical word count everyone a lot",
    "start": "527920",
    "end": "534000"
  },
  {
    "text": "of people start with that that's that yes yeah so let me repeat the question the question was what is um so",
    "start": "534000",
    "end": "541600"
  },
  {
    "text": "what are the what are let's talk about the types here so if you're in Scola you're into types you want like a strongly typed thing and so a lot of",
    "start": "541600",
    "end": "548079"
  },
  {
    "text": "this is is is well typed so let me answer that question but then we can move on in a second and talk about some",
    "start": "548079",
    "end": "553640"
  },
  {
    "text": "of the bad news uh like elsewhere the the type of of this object is uh a",
    "start": "553640",
    "end": "559800"
  },
  {
    "text": "source that represents like where data is re you read or write on Hadoop right",
    "start": "559800",
    "end": "565640"
  },
  {
    "text": "so that's pretty straightforward but in between scalding is a uh a scolar",
    "start": "565640",
    "end": "570880"
  },
  {
    "text": "library it's a DSL for cascading it's a Java library that you can use in a lot of different ways and that Java Library",
    "start": "570880",
    "end": "576600"
  },
  {
    "text": "uses it represents these computations as pipes basically things flowing around you can think of these pipes as like",
    "start": "576600",
    "end": "582800"
  },
  {
    "text": "lists like I think of them more like lists when I operate on them and all these objects here are now these",
    "start": "582800",
    "end": "589040"
  },
  {
    "text": "pipes now the deeper question is what was going on here so Group by if you're",
    "start": "589040",
    "end": "594640"
  },
  {
    "text": "if you're new to schola this group by took a function and this function did",
    "start": "594640",
    "end": "599839"
  },
  {
    "text": "something and it's a little bit I mean it's like it's a slight it almost look a slight of hand if you if you look at it",
    "start": "599839",
    "end": "605320"
  },
  {
    "text": "but what group ey does is it hands you a thing that's we it's it's like a builder",
    "start": "605320",
    "end": "611200"
  },
  {
    "text": "pattern it hands you this object which you will describe the calculation you're going to build up on the reduction",
    "start": "611200",
    "end": "616920"
  },
  {
    "text": "because in Hadoop we don't want to go through the data more than once we want to only go we want to go through it as few times as possible once is almost",
    "start": "616920",
    "end": "623839"
  },
  {
    "text": "already too many so if you want to take the average of a bunch of numbers and the sum of a bunch of numbers and you",
    "start": "623839",
    "end": "629079"
  },
  {
    "text": "want look at the I element in the tupal and like take the max of those numbers you don't want to go through that over",
    "start": "629079",
    "end": "634880"
  },
  {
    "text": "and over again in the Scola standard library to do that you would be forced",
    "start": "634880",
    "end": "640639"
  },
  {
    "text": "like there's not a really good composition story there you you could go through it over and over again or you",
    "start": "640639",
    "end": "645839"
  },
  {
    "text": "could write some function that like goes through this giant Tuple and does all these different calculations on it",
    "start": "645839",
    "end": "651320"
  },
  {
    "text": "there's actually a really nice story around it here is that we're taking this group Builder",
    "start": "651320",
    "end": "657600"
  },
  {
    "text": "thing that has a bun all the reduction methods we'll see it later and we can do all these different reductions one",
    "start": "657600",
    "end": "662920"
  },
  {
    "text": "reduction is to get the size size will return the group Builder so you could keep going we could also say let me get",
    "start": "662920",
    "end": "668760"
  },
  {
    "text": "the max and you can keep going whenever you stop you're done building up this",
    "start": "668760",
    "end": "673880"
  },
  {
    "text": "giant calculation that will run in the reducer it's not really running here this is like code you can compile and",
    "start": "673880",
    "end": "680440"
  },
  {
    "text": "you would run it and nothing actually happens it's this it's code that returns a",
    "start": "680440",
    "end": "686560"
  },
  {
    "text": "calculation so it's it's code that's like it's the output of this code is a",
    "start": "686560",
    "end": "693800"
  },
  {
    "text": "calculation",
    "start": "693800",
    "end": "696800"
  },
  {
    "text": "yes yeah that's exactly right yeah so so",
    "start": "700200",
    "end": "707839"
  },
  {
    "text": "this will all get compiled into Java B code um behind the scenes the things that it passes through this will get",
    "start": "707839",
    "end": "713320"
  },
  {
    "text": "serialized using Java serialization it'll get shipped over to all the mappers and and the reducers in in",
    "start": "713320",
    "end": "719279"
  },
  {
    "text": "Hadoop and then they're going to put it through the the appropriate parts of this code it's exactly what will",
    "start": "719279",
    "end": "727240"
  },
  {
    "text": "happen uh Hadoop and cascading handle that portion of it yeah yeah so it's all",
    "start": "729200",
    "end": "736560"
  },
  {
    "text": "ready to go and by the way I didn't jump up and down about this any other time I've talked about it but I probably should there's this really cool Library",
    "start": "736560",
    "end": "742199"
  },
  {
    "text": "called cryo I don't know if you're familiar with it but you should really look into it if you're not it's it's about as fast as protuff which is a lot",
    "start": "742199",
    "end": "750360"
  },
  {
    "text": "faster than Thrift it is as compact as protuff or Thrift and you don't have to",
    "start": "750360",
    "end": "755720"
  },
  {
    "text": "write uh a definition for your uh class that you want to serialize in most cases",
    "start": "755720",
    "end": "761279"
  },
  {
    "text": "if you try to do something crazy like serializing a open socket or something it's obviously not going to work but for most of the value types that we have in",
    "start": "761279",
    "end": "767480"
  },
  {
    "text": "Scala it just works it's just so you can jam anything into these things and send them around you could have case classes",
    "start": "767480",
    "end": "773519"
  },
  {
    "text": "you could do you know a scholar list you could pass anything around and they're just magically G to almost magically",
    "start": "773519",
    "end": "780040"
  },
  {
    "text": "going to work",
    "start": "780040",
    "end": "782680"
  },
  {
    "text": "yeah yeah I only did this in this case actually just to show that you could put a Anonymous function up there if you",
    "start": "788480",
    "end": "794199"
  },
  {
    "text": "wanted to or you can call any other function that you like yeah oh yeah yeah I mean that's",
    "start": "794199",
    "end": "800079"
  },
  {
    "text": "just like it could just be like Bob's your uncle and like that could have been it too it was just to show you that like there's no constraints on what you do",
    "start": "800079",
    "end": "806279"
  },
  {
    "text": "you can send any any code around you",
    "start": "806279",
    "end": "811120"
  },
  {
    "text": "yeah k r yo cryo it's awesome also um so",
    "start": "812399",
    "end": "819279"
  },
  {
    "text": "so it's also used in spark if you're interested in Scala and like uh in memory map ruce style uh it's also used",
    "start": "819279",
    "end": "825480"
  },
  {
    "text": "in CasCal log which U those those guys work with us at Twitter um for our closure version of all of this uh and",
    "start": "825480",
    "end": "833079"
  },
  {
    "text": "also storm uses it so it's it's and I've heard some people at Yahoo use it so it's not it's not like just some crazy",
    "start": "833079",
    "end": "838480"
  },
  {
    "text": "dudes using it well in addition to Crazy dudes using it so I think we've kind of",
    "start": "838480",
    "end": "844000"
  },
  {
    "text": "gone through all this you can call these functions uh you can Define them in line or you can call any function that you",
    "start": "844000",
    "end": "849480"
  },
  {
    "text": "already wrote so we're all set to go so this is pretty awesome so now the data model as I",
    "start": "849480",
    "end": "856639"
  },
  {
    "text": "mentioned is that you have a stream of name tupal like you can picture this as you're always calculating with like a",
    "start": "856639",
    "end": "862040"
  },
  {
    "text": "spreadsheet and you've got this code that like tells you how to modify the spreadsheet okay so you have column A1",
    "start": "862040",
    "end": "869240"
  },
  {
    "text": "and now I'm going to map on to column A2 and things like this and it's a nice model um but it's that's where you're",
    "start": "869240",
    "end": "875920"
  },
  {
    "text": "going to see the difference between um scalding and like the standard Scola collections",
    "start": "875920",
    "end": "881519"
  },
  {
    "text": "API so uh we can actually run this and I'll run this in a second and later we'll go through more examples but we",
    "start": "881519",
    "end": "887680"
  },
  {
    "text": "have this like little uh driver script that allows you to take your jobs that you write this scholet job it'll in the",
    "start": "887680",
    "end": "893279"
  },
  {
    "text": "background run the compiler ship it over to our cluster run it if we want if you want to run it locally can do D- local",
    "start": "893279",
    "end": "899959"
  },
  {
    "text": "and it will run it locally as well and um pretty soon now real soon now um Edwin Chen or somebody or maybe you guys",
    "start": "899959",
    "end": "907440"
  },
  {
    "text": "well add EMR support it's like relatively easy to do that there's some cascading support for that already people have done that that would be",
    "start": "907440",
    "end": "913360"
  },
  {
    "text": "awesome if someone else did it we don't use EMR so it's not like going to be like top on our list it'll",
    "start": "913360",
    "end": "919000"
  },
  {
    "text": "be so easy and so awesome and like these demos would be so much better if we could do that so you guys should someone get on that but let's give it a try",
    "start": "919000",
    "end": "927639"
  },
  {
    "text": "so how dides how does word count actually run so deploying some code going",
    "start": "927639",
    "end": "937079"
  },
  {
    "text": "into so",
    "start": "937680",
    "end": "941319"
  },
  {
    "text": "actually and here is word count it's the",
    "start": "945399",
    "end": "951319"
  },
  {
    "text": "exact same code that we did before right so nothing up my sleeve and",
    "start": "951319",
    "end": "957560"
  },
  {
    "text": "then we uh I downloaded Alison Wonderland so we have Alison Wonderland",
    "start": "957560",
    "end": "965000"
  },
  {
    "text": "and I'm sure everyone wants to know what the top words in Alison Wonderland are",
    "start": "965000",
    "end": "970639"
  },
  {
    "text": "down the rabbit hole something like this so we have scald this is this little driver script that we",
    "start": "970639",
    "end": "975920"
  },
  {
    "text": "wrote and I want to run it in local mode and I want to run word count and I want to have I've have",
    "start": "975920",
    "end": "983279"
  },
  {
    "text": "so that job had two so it had some ARG parsing that we built into",
    "start": "983279",
    "end": "989600"
  },
  {
    "text": "and uh it just we take the input AR and then we eventually write to the output AR and the way that that kind of can",
    "start": "989600",
    "end": "996279"
  },
  {
    "text": "canonically works is just with uh Dash dashes so we just uh we run it",
    "start": "996279",
    "end": "1005199"
  },
  {
    "text": "so now uh it's it's compiling the job it's linking in some various Hadoop",
    "start": "1023199",
    "end": "1029280"
  },
  {
    "text": "libraries which may or may not be on your system and we hacked it up so it magically uh downloads up from Maven um",
    "start": "1029280",
    "end": "1036360"
  },
  {
    "text": "The Scholar compiler is like super blindingly fast it's just my laptop that's slow if anyone ever tells you the",
    "start": "1036360",
    "end": "1041918"
  },
  {
    "text": "scholar compiler is slow they're L it's only my laptop um that's a joke for people who",
    "start": "1041919",
    "end": "1048400"
  },
  {
    "text": "actually know the schar compiler is crazy insanely slow um and now let's take a little",
    "start": "1048400",
    "end": "1054640"
  },
  {
    "text": "check at the words here we go so uh there they are uh",
    "start": "1054640",
    "end": "1061960"
  },
  {
    "text": "I think if we search for Alice it'll be one of the top",
    "start": "1061960",
    "end": "1069120"
  },
  {
    "text": "words there we go uh nope that's not the right one that's Alice exclamation",
    "start": "1069120",
    "end": "1075640"
  },
  {
    "text": "point uh yeah I thought we did too but apparently uh maybe someone can spot the code the error in our",
    "start": "1077559",
    "end": "1084039"
  },
  {
    "text": "code let's see anyone want to engage in some real",
    "start": "1084039",
    "end": "1090000"
  },
  {
    "text": "time debugging let's see so anything that is",
    "start": "1090000",
    "end": "1094158"
  },
  {
    "text": "not it's not totally obvious to",
    "start": "1097320",
    "end": "1101440"
  },
  {
    "text": "me yeah we did two lower as well",
    "start": "1104159",
    "end": "1109520"
  },
  {
    "text": "anything think it's not yeah I don't know we can open up the reple and play",
    "start": "1112640",
    "end": "1118320"
  },
  {
    "text": "around yeah we're only splitting on Spaces but we're uh replacing everything",
    "start": "1118320",
    "end": "1123760"
  },
  {
    "text": "in that set with space right it's not in that space right it's because it's",
    "start": "1123760",
    "end": "1130840"
  },
  {
    "text": "not so it should anyways there we go",
    "start": "1130840",
    "end": "1139760"
  },
  {
    "text": "see I mean if we can't get this right I would be very suspect that this whole thing is not going to blow up on you when you try it but uh",
    "start": "1139760",
    "end": "1146600"
  },
  {
    "text": "apparently it works somewhat okay",
    "start": "1146600",
    "end": "1153400"
  },
  {
    "text": "okay so that's where we are with that so um so what's scalding all about so",
    "start": "1153400",
    "end": "1159520"
  },
  {
    "text": "scalding has like three sets of functions and it's these are really like the mapper use kind of Primitives yeah",
    "start": "1159520",
    "end": "1166639"
  },
  {
    "text": "that's a good question for that like that's so the question was can you run the the jobs from the repple and the answer is right now you cannot and like",
    "start": "1169840",
    "end": "1177200"
  },
  {
    "text": "so why is that it would seem like it would be nice and easy to do things from the repple but the way that the scolar repple works is that every line",
    "start": "1177200",
    "end": "1184200"
  },
  {
    "text": "basically I haven't delv too deeply into it but they get put into as a the body",
    "start": "1184200",
    "end": "1190159"
  },
  {
    "text": "of a main method in some Anonymous object that gets created at that moment in time and that model breaks like the",
    "start": "1190159",
    "end": "1198880"
  },
  {
    "text": "way that we're threading behind the scenes this cascading flow that we build up and get and then submit to the the",
    "start": "1198880",
    "end": "1205559"
  },
  {
    "text": "Hadoop cluster in principle it is surmountable but it probably involves writing our own repol like spark has",
    "start": "1205559",
    "end": "1212039"
  },
  {
    "text": "done and that's just something that we haven't done yet um it would be really nice because that we have a lot of we",
    "start": "1212039",
    "end": "1217480"
  },
  {
    "text": "have a you know we have several implicits which are a Scala feature that that are very useful at free people out",
    "start": "1217480",
    "end": "1223480"
  },
  {
    "text": "um that that enable a lot of the DSL and if we had our if we do Implement our own reppel we can make all those implicits",
    "start": "1223480",
    "end": "1229520"
  },
  {
    "text": "are imported by default and that would make it a little bit cleaner and you could like probably replace it would be nicer to replace this called that R arus",
    "start": "1229520",
    "end": "1236360"
  },
  {
    "text": "is threaten to do this so you can nag him about it he he might actually do this so so there's three sets of",
    "start": "1236360",
    "end": "1241840"
  },
  {
    "text": "functions that you have there's really two that really matter and the last one is built on top of the other one and you have the map functions so if you're just",
    "start": "1241840",
    "end": "1249200"
  },
  {
    "text": "used to like like the idea of map produce from like maybe you saw in python or you saw it in list there's this map phase that's totally",
    "start": "1249200",
    "end": "1255760"
  },
  {
    "text": "parallelized and then you reduce it down to one thing you go through a big list and you get one value so how does that",
    "start": "1255760",
    "end": "1262000"
  },
  {
    "text": "picture if you're not familiar with hop go in Hadoop so the idea in Hadoop is that usually you can Shard the reducing",
    "start": "1262000",
    "end": "1268840"
  },
  {
    "text": "by something else and you don't want to reduce down to one value you might reduce it down like I want to do a bunch of mapping and then Group by a bunch of",
    "start": "1268840",
    "end": "1275360"
  },
  {
    "text": "days and for each day I want to reduce things down or I want to have a bunch of products and over each of those say 100",
    "start": "1275360",
    "end": "1281880"
  },
  {
    "text": "or thousand or million products I want to reduce some things down so in Hadoop",
    "start": "1281880",
    "end": "1287200"
  },
  {
    "text": "that's the picture you do the map you you define some kind of grouping and then on the grouping you're going to do",
    "start": "1287200",
    "end": "1293200"
  },
  {
    "text": "some kind of reduction and that's where you see all the standard you're going to see the standard you know sum you know",
    "start": "1293200",
    "end": "1298600"
  },
  {
    "text": "average take head sort whatever that you probably know from um your your normal",
    "start": "1298600",
    "end": "1304320"
  },
  {
    "text": "functional programming there's a pretty decent API on the GitHub page I'm not going to go",
    "start": "1304320",
    "end": "1309440"
  },
  {
    "text": "through all of it but we'll see some of it here um but so each of the functions you see the groups you see represented",
    "start": "1309440",
    "end": "1315240"
  },
  {
    "text": "up there like the map like functions the grouping functions and the joint oper ation so as I've said about 20 times uh",
    "start": "1315240",
    "end": "1323559"
  },
  {
    "text": "usually if you're familiar with the collections API and you can imagine how you would structure your calculation",
    "start": "1323559",
    "end": "1328720"
  },
  {
    "text": "using scholar collections you could usually just like say okay how would I take that over to scalding and look up",
    "start": "1328720",
    "end": "1334320"
  },
  {
    "text": "and like oh there's that function there's this function there's scan there's take there's fold there's reduce",
    "start": "1334320",
    "end": "1339760"
  },
  {
    "text": "all the things that like if you're used to functional programming they'll all be there the only thing that is different",
    "start": "1339760",
    "end": "1345559"
  },
  {
    "text": "is the notion of named Fields so rather than just having a map you're",
    "start": "1345559",
    "end": "1351440"
  },
  {
    "text": "operating on this GI I have this giant tle that's sitting in the background and you when you say I want a map you say I",
    "start": "1351440",
    "end": "1357520"
  },
  {
    "text": "you ask you tell me which Fields do you want to map on and then I'll take some subset of them and give them to you and",
    "start": "1357520",
    "end": "1363880"
  },
  {
    "text": "then you're going to map and then you're going to give some back to me and I'm going to change that Tuple around so",
    "start": "1363880",
    "end": "1369039"
  },
  {
    "text": "that's the whole picture so here you see an example where we can use by",
    "start": "1369039",
    "end": "1374480"
  },
  {
    "text": "index let me get the the first three elements out of the tall and then I'm going to map them on to",
    "start": "1374480",
    "end": "1381279"
  },
  {
    "text": "tuple's name these three things Source zero destination blah blah",
    "start": "1381279",
    "end": "1386520"
  },
  {
    "text": "blah so there's two contexts we in which so you can kind of read that Arrow as",
    "start": "1386520",
    "end": "1391960"
  },
  {
    "text": "we're mapping this onto that thing there the other way that we use the arrow is with the joining operations and a join",
    "start": "1391960",
    "end": "1398880"
  },
  {
    "text": "is again it's lifted from a noce like databases you don't see this in the Scola API but I think you should we should have a co-group um there's Group",
    "start": "1398880",
    "end": "1406120"
  },
  {
    "text": "by there should be co-group right why not Co group if there was Co group",
    "start": "1406120",
    "end": "1412039"
  },
  {
    "text": "in the the API everybody would have a much easier time writing um map ruce jobs but a join if you're not familiar",
    "start": "1412039",
    "end": "1419279"
  },
  {
    "text": "with it um it's weird to who knows how much everyone's familiar with but you're just saying on this list I've got a",
    "start": "1419279",
    "end": "1425320"
  },
  {
    "text": "bunch of keys and on this list some of those keys appear also and everywhere",
    "start": "1425320",
    "end": "1430360"
  },
  {
    "text": "where the keys appear in both list I want to make a cross product and it just I mean it's a pretty",
    "start": "1430360",
    "end": "1436679"
  },
  {
    "text": "simple mathematical operation but it's very common in databases and so if you're simulating something like a database or database calculation in",
    "start": "1436679",
    "end": "1442799"
  },
  {
    "text": "Hadoop it's very useful and so this syntax here means The Source on the left",
    "start": "1442799",
    "end": "1448159"
  },
  {
    "text": "hand side I want to Source zero I want to everywhere",
    "start": "1448159",
    "end": "1453480"
  },
  {
    "text": "on the right hand side PR which is some other thing that kind of comes in I'm going to map I want to join those two",
    "start": "1453480",
    "end": "1460559"
  },
  {
    "text": "together and then output two poles that form this cross product it's pretty straightforward I",
    "start": "1460559",
    "end": "1465760"
  },
  {
    "text": "mean it's it's same thing you've seen in SQL uh it's uh co- group in pig uh it's",
    "start": "1465760",
    "end": "1471720"
  },
  {
    "text": "co- group in um cascading there we go so that's how it",
    "start": "1471720",
    "end": "1477159"
  },
  {
    "text": "works boom so I've mentioned cascading a couple times so what's what's up with",
    "start": "1477159",
    "end": "1483240"
  },
  {
    "text": "cascading what is this relationship with scalding so the cool thing about cascading um so there's like three big",
    "start": "1483240",
    "end": "1488559"
  },
  {
    "text": "scalding dsls for Hadoop there's like like like I heard like oh we're Twitter",
    "start": "1488559",
    "end": "1494000"
  },
  {
    "text": "so we're the the big one so which doesn't seem like but apparently we're the big one if going to use one it's",
    "start": "1494000",
    "end": "1499039"
  },
  {
    "text": "scalding apparently we've won but if you don't use scalding there's another one called uh Scooby which they have their",
    "start": "1499039",
    "end": "1504520"
  },
  {
    "text": "own flow planner their own mapping of Scala to hadu Primitives uh there's also",
    "start": "1504520",
    "end": "1509760"
  },
  {
    "text": "one called scrunch from the guys at cladera and they have a a project called Crunch and scrunch is like after I uh",
    "start": "1509760",
    "end": "1517039"
  },
  {
    "text": "told Josh Wills how awesome schola would be for his scrunch Library he got religion and wrote scrunch and so it's",
    "start": "1517039",
    "end": "1523360"
  },
  {
    "text": "it's awesome too the difference is cascading has had years of use I mean like people have been banging on it for",
    "start": "1523360",
    "end": "1529520"
  },
  {
    "text": "years and many many people are using it it's an active Community is really well tested the 1.2 branch is like really",
    "start": "1529520",
    "end": "1535799"
  },
  {
    "text": "rock solid it's a little bit hard to find problems with it major problems at least you you'll know it it feel it's",
    "start": "1535799",
    "end": "1541720"
  },
  {
    "text": "very safe Library it's going through we're in about to release 2.0 we still see a couple bugs here and there but",
    "start": "1541720",
    "end": "1547320"
  },
  {
    "text": "it's a great Library it's really well tested it's super optimized it's high performance so scaling is based on that",
    "start": "1547320",
    "end": "1553679"
  },
  {
    "text": "you're not like you know when you're using it you're not using like some crazy guys flow planner who cooked it up",
    "start": "1553679",
    "end": "1558760"
  },
  {
    "text": "last week and it'll be awesome real soon now it like it it works it's in it's very fast um it's got a fast local mode",
    "start": "1558760",
    "end": "1566640"
  },
  {
    "text": "which I just showed you that was not using Hadoop at all so you can use cascad you can use scalding or cascading",
    "start": "1566640",
    "end": "1573440"
  },
  {
    "text": "on your cluster you can then write the same job and run it locally and that's really handy to be able to use the same",
    "start": "1573440",
    "end": "1579480"
  },
  {
    "text": "Concepts and how you um deal with data for the cluster and locally it's a real pain if you work with some other systems",
    "start": "1579480",
    "end": "1586480"
  },
  {
    "text": "you might use something on your your cluster and then bring it into map uh sorry r or maybe you know XL in some",
    "start": "1586480",
    "end": "1593480"
  },
  {
    "text": "cases locally that's like it's like this impedance mismatch it's no fun um one cool thing is it has a flow planner",
    "start": "1593480",
    "end": "1599600"
  },
  {
    "text": "that's portable especially now so there's two flow planners now the Hadoop flow planner and there's a local flow planner but you can easily write a spark",
    "start": "1599600",
    "end": "1606559"
  },
  {
    "text": "flow planner which I I I really want to push um Chris quinol at at um concurrent",
    "start": "1606559",
    "end": "1611799"
  },
  {
    "text": "to do or we've also talked about doing a real-time flow Planner on top of storm so you could have streaming like like uh",
    "start": "1611799",
    "end": "1619279"
  },
  {
    "text": "batch operations there's in transactional mode in storm if you're familiar with it it's a kind of a streaming like Hadoop like a real-time",
    "start": "1619279",
    "end": "1625760"
  },
  {
    "text": "Hadoop Nathan calls it and it would be possible to bring cascading to that and then you could use your exact same jobs",
    "start": "1625760",
    "end": "1632200"
  },
  {
    "text": "in all these different cases that would be awesome the bad part is if you're really into like functional programming",
    "start": "1632200",
    "end": "1638200"
  },
  {
    "text": "and you're into type safety and all that um cascading tupal model is basically an array of",
    "start": "1638200",
    "end": "1643919"
  },
  {
    "text": "objects and so even though scalding cares about types it takes your work for it like when you say that this is like a",
    "start": "1643919",
    "end": "1650760"
  },
  {
    "text": "function that takes a double to string to something really it's saying okay I'm going to go get a double and a string",
    "start": "1650760",
    "end": "1656360"
  },
  {
    "text": "out of this cascading Tuple but that cascading Tuple it can't tell the compiler what it's got inside so that's",
    "start": "1656360",
    "end": "1662440"
  },
  {
    "text": "an unfortunate part about it that's one thing I don't like about it um the other thing uh that is like a",
    "start": "1662440",
    "end": "1669279"
  },
  {
    "text": "little bit of a downside relative to some of the other systems is that cascading field model as I mentioned before like it it just doesn't mesh well",
    "start": "1669279",
    "end": "1677000"
  },
  {
    "text": "it's like a record model an untyped record model that doesn't match well with a strongly typed like",
    "start": "1677000",
    "end": "1682159"
  },
  {
    "text": "collections API like schols collection API or like what you might see in hll or",
    "start": "1682159",
    "end": "1688200"
  },
  {
    "text": "something that having been said it's like it's really productive like so we have a lot of people who use it every",
    "start": "1688200",
    "end": "1694080"
  },
  {
    "text": "day we have a relatively large team they're using it day in and day out they don't like lose a lot of sleep because",
    "start": "1694080",
    "end": "1699279"
  },
  {
    "text": "like it doesn't have like like a lot of strong functional Purity to it and it like it basically works for them this",
    "start": "1699279",
    "end": "1705000"
  },
  {
    "text": "model of like tupal and naming columns and everything it like meshes well with how people think so I haven't been that",
    "start": "1705000",
    "end": "1710799"
  },
  {
    "text": "like motivated to like do that much about it so this is just a grap through one of",
    "start": "1710799",
    "end": "1717279"
  },
  {
    "text": "the repos uh just to count but we've got like more than 60 in production jobs and those are jobs that like if they don't",
    "start": "1717279",
    "end": "1722840"
  },
  {
    "text": "run we get alerts and like bad things happen that are running on the system we've got more than 200 just like ad hoc",
    "start": "1722840",
    "end": "1728240"
  },
  {
    "text": "jobs someone's just like hey you know how many times did Justin Bieber say I'm going to you know have a beer in the",
    "start": "1728240",
    "end": "1734240"
  },
  {
    "text": "last three days I don't know probably didn't say that actually this is going on the web like it's going to make me",
    "start": "1734240",
    "end": "1739919"
  },
  {
    "text": "I'm going get in trouble for that one all right no we don't do that kind",
    "start": "1739919",
    "end": "1745399"
  },
  {
    "text": "of stuff but I mean like it's public data anyways I mean anyone can see how many times Justin Viber said that anyways but like that's not what the 200",
    "start": "1745399",
    "end": "1752919"
  },
  {
    "text": "jobs are but like you get ask a question you need to answer the question so like and they work so uh the one thing I don't I want to",
    "start": "1752919",
    "end": "1760320"
  },
  {
    "text": "give you the impression though is that somehow it's our only tool at Twitter I don't want to misrepresent we've got a lot of people on analytics who I I know",
    "start": "1760320",
    "end": "1765799"
  },
  {
    "text": "and love and they love Pig so uh we have a lot of uh tools there uh the CasCal guys I mentioned before they're using cascading",
    "start": "1765799",
    "end": "1773039"
  },
  {
    "text": "there's another python DSL inside of Twitter being developed called P cascading but so we're using a lot of cascading but we also use pig and a",
    "start": "1773039",
    "end": "1779760"
  },
  {
    "text": "little bit of Hive so um I want to talk a little bit about the",
    "start": "1779760",
    "end": "1786559"
  },
  {
    "text": "implementation issues uh in a minute we're going to switch over and do the Hands-On I think I'm going to hand it off to araras um at that stage but",
    "start": "1786559",
    "end": "1794200"
  },
  {
    "text": "before I do that we're going to talk a little bit about like uh actually I might even like throw it back to the",
    "start": "1794200",
    "end": "1800159"
  },
  {
    "text": "audience it looked like a lot of people were new uh to Scala and if I go in",
    "start": "1800159",
    "end": "1805720"
  },
  {
    "text": "detail on like how like the implicits work which is like a weird Scala feature",
    "start": "1805720",
    "end": "1812120"
  },
  {
    "text": "weird to most people who don't know Scala yet I think we might just like like not get the most use out of our",
    "start": "1812120",
    "end": "1817200"
  },
  {
    "text": "time so I think I might skip that unless people are really interested in like how does the how do you implement a DSL in",
    "start": "1817200",
    "end": "1824919"
  },
  {
    "text": "in Scala to like match with like a Java API is that like something like is there",
    "start": "1824919",
    "end": "1831039"
  },
  {
    "text": "like some serious interest in that or should we go to the",
    "start": "1831039",
    "end": "1835120"
  },
  {
    "text": "handson handson okay so anyways these slides will be available so someone can",
    "start": "1836320",
    "end": "1841720"
  },
  {
    "text": "see this this implicit stuff so there we go um so before yes so",
    "start": "1841720",
    "end": "1848679"
  },
  {
    "text": "here's what we're going to do we're going to talk a little bit about the the group builder stuff how the reductions work and then we'll go to the Hands-On",
    "start": "1848679",
    "end": "1854960"
  },
  {
    "text": "so this is what we're going to see so this question came up earlier what is the type that this grouping operates on",
    "start": "1854960",
    "end": "1862440"
  },
  {
    "text": "and the the type that it operates on is this group Builder okay and that keeps happening",
    "start": "1862440",
    "end": "1868360"
  },
  {
    "text": "that's kind of fun if it weren't annoying okay so",
    "start": "1868360",
    "end": "1875200"
  },
  {
    "text": "uh in this case we're going to take some a bunch of numbers we're going to group them up by this value X but after we do",
    "start": "1875200",
    "end": "1882720"
  },
  {
    "text": "that we're going to do a series of calculations on them the first one is this function",
    "start": "1882720",
    "end": "1888679"
  },
  {
    "text": "it looks lame you wouldn't do this on locally because you just it looks makes your code look muddy but if you're going",
    "start": "1888679",
    "end": "1894279"
  },
  {
    "text": "to do go through the list once you don't want to have to go through and calculate like go through the list five times to calculate all the moments you care about",
    "start": "1894279",
    "end": "1901080"
  },
  {
    "text": "so we have this function size average and standard deviation okay so what this thing is GNA do is it's going to take",
    "start": "1901080",
    "end": "1907639"
  },
  {
    "text": "grouping grouping the numbers by X let's take Y and then let me add on three more",
    "start": "1907639",
    "end": "1912840"
  },
  {
    "text": "Fields into my Tuple how many values for y I saw the",
    "start": "1912840",
    "end": "1918480"
  },
  {
    "text": "average value for y and the standard deviation for y so now we've grown the Tuple out from one element it had X in",
    "start": "1918480",
    "end": "1924360"
  },
  {
    "text": "it now it has four elements X the number of Y values for that X the average",
    "start": "1924360",
    "end": "1929600"
  },
  {
    "text": "number of the average value of y for that value of x and the standard deviation of Y for that value of x and",
    "start": "1929600",
    "end": "1935320"
  },
  {
    "text": "then we can do it as much as much as you want I I apologize for the cut and paste code that this was this from a unit test",
    "start": "1935320",
    "end": "1941120"
  },
  {
    "text": "so um but you can do it as much as you want after this we've got four now we got five six seven columns and now we",
    "start": "1941120",
    "end": "1946919"
  },
  {
    "text": "add one more we've got eight at the end I say actually I only want these five and then they get written out in those",
    "start": "1946919",
    "end": "1953200"
  },
  {
    "text": "five columns so there you go so we can do all these parallel",
    "start": "1953200",
    "end": "1958279"
  },
  {
    "text": "reductions at the same time so you might have like this one object you might ask a bunch of questions about it you can",
    "start": "1958279",
    "end": "1964000"
  },
  {
    "text": "keep doing these by adding more and more elements to the tupal inside that grouping so one function that we have",
    "start": "1964000",
    "end": "1970600"
  },
  {
    "text": "like the main function that we have in cascading A Primitive that it offers you",
    "start": "1970600",
    "end": "1975840"
  },
  {
    "text": "to do this kind of parallel reduction it can be rep can be thought of as a map reduce and Then followed by a map so",
    "start": "1975840",
    "end": "1983159"
  },
  {
    "text": "what's going on here is once You' set up the grouping you might first do some kind of Preparatory",
    "start": "1983159",
    "end": "1989279"
  },
  {
    "text": "phase and then you do a standard reduce on them so you're combining a bunch of things together but then when you're",
    "start": "1989279",
    "end": "1995120"
  },
  {
    "text": "done you might want to clean up so that's the map the reduce in the map so what's an example of that so the",
    "start": "1995120",
    "end": "2002240"
  },
  {
    "text": "one I just put up size average standard deviation I want to take the average of Y I want to get all all the moments let",
    "start": "2002240",
    "end": "2007880"
  },
  {
    "text": "me I can take like the first 10 moments how do I prepare the first step is I take Y and I splat it out to all the",
    "start": "2007880",
    "end": "2014399"
  },
  {
    "text": "five moments of yre in this case it was three moments the zeroth power that's one the first Power that's y the third",
    "start": "2014399",
    "end": "2021360"
  },
  {
    "text": "the second power that's y^2 now I do the normal reduce which would just like sum",
    "start": "2021360",
    "end": "2026600"
  },
  {
    "text": "them all up and then how do I finish up well once I finish up I take one I get",
    "start": "2026600",
    "end": "2033279"
  },
  {
    "text": "now I've got the count I've got the sum of all the Y's and I've got the sum of all of them squared and I'm I'm sure at",
    "start": "2033279",
    "end": "2038840"
  },
  {
    "text": "least 95% of you if I gave you those three numbers could compute the mean and",
    "start": "2038840",
    "end": "2044080"
  },
  {
    "text": "the standard deviation the mean is easy you just divide the sum of y's by the count standard deviation slightly more",
    "start": "2044080",
    "end": "2050079"
  },
  {
    "text": "complicated but not much and I'm sure you figure it out so that idea that you want to first set up then do the reduce",
    "start": "2050079",
    "end": "2056919"
  },
  {
    "text": "then clean up very powerful how powerful almost everything we have is implemented this way if you want to count something",
    "start": "2056919",
    "end": "2063480"
  },
  {
    "text": "that satisfies a predicate what's the setup phase well if it satisf if I the predicate map it to one if it doesn't",
    "start": "2063480",
    "end": "2070118"
  },
  {
    "text": "map it to zero What's the reduce phase the reduce phase is obvious you add you do just sum sum is a very common reduce",
    "start": "2070119",
    "end": "2077240"
  },
  {
    "text": "function um what's the last phase well that's kind of common a lot of times you don't have to clean up so we have uh an",
    "start": "2077240",
    "end": "2083878"
  },
  {
    "text": "identity function is the man that is super annoying if I were just like eight feet",
    "start": "2083879",
    "end": "2089560"
  },
  {
    "text": "tall it would be more convenient but so at the end there is a uh identity fun",
    "start": "2089560",
    "end": "2097720"
  },
  {
    "text": "function so same thing with for all are all these predicates true for these",
    "start": "2097720",
    "end": "2104119"
  },
  {
    "text": "things how do I say well I take the function is it true for each of them that's the map reduce and all the way",
    "start": "2104119",
    "end": "2111480"
  },
  {
    "text": "through what's the clean up no clean up average here's like a very complicated",
    "start": "2111480",
    "end": "2116720"
  },
  {
    "text": "uh algorithm that is a streaming average that's more stable for giant lists so if",
    "start": "2116720",
    "end": "2122760"
  },
  {
    "text": "if you add giant numbers to small numbers and you want to avoid roundoff errors this is a slightly better algorithm for it this one actually has",
    "start": "2122760",
    "end": "2129119"
  },
  {
    "text": "non-trivial steps on all of them you first set up by mapping X to one and X you do this reduction which is",
    "start": "2129119",
    "end": "2136560"
  },
  {
    "text": "associative and commutative and then finally the cleanup is non-trivial you take the second element of the Tuple out",
    "start": "2136560",
    "end": "2143119"
  },
  {
    "text": "almost everything that we have is is is implemented this way why do we do it this way it can be pushed to the mappers in many cases it's more efficient if",
    "start": "2143119",
    "end": "2149599"
  },
  {
    "text": "you're all into combiners and Ma ruce and all that sort of thing you can just grip through the code it's like almost",
    "start": "2149599",
    "end": "2155920"
  },
  {
    "text": "everything's written in terms of that function so it turns out to be a really valuable function so now I'm going to head over to our he's going to do the",
    "start": "2155920",
    "end": "2161880"
  },
  {
    "text": "handson all right so let's take a look if you actually download scolding from",
    "start": "2161880",
    "end": "2167240"
  },
  {
    "text": "GitHub we have a tutorials uh directory that uh contains a bunch of introductory",
    "start": "2167240",
    "end": "2173440"
  },
  {
    "text": "material that you can use to get a little bit more familiar with the code we're just going to walk through a couple of those just so that you can uh",
    "start": "2173440",
    "end": "2180000"
  },
  {
    "text": "take a look at like the the anatomy of a scolding job and how it's actually uh how you can actually write your own too",
    "start": "2180000",
    "end": "2189000"
  },
  {
    "text": "all right so um how does a how do you",
    "start": "2189720",
    "end": "2195119"
  },
  {
    "text": "actually write a uh scolding job yourself um basically all the jobs look something",
    "start": "2195119",
    "end": "2201960"
  },
  {
    "text": "like this you set up some input source one or more you set up an output source that you want to write to uh you do some",
    "start": "2201960",
    "end": "2208040"
  },
  {
    "text": "basic processing on the tles that are contained within that source and then you just write the output out um in this",
    "start": "2208040",
    "end": "2214240"
  },
  {
    "text": "particular case we're not doing anything interesting at all we're just reading uh an input file from uh like a little",
    "start": "2214240",
    "end": "2220880"
  },
  {
    "text": "data file that we have in here uh and we're writing it back out without doing anything um the main thing to look at is",
    "start": "2220880",
    "end": "2227079"
  },
  {
    "text": "this text line um definition here this is one of the standard types of sources",
    "start": "2227079",
    "end": "2232359"
  },
  {
    "text": "that is supported in scolding natively the only two types that we support uh out of the books right now are text line",
    "start": "2232359",
    "end": "2238760"
  },
  {
    "text": "and tsv uh text line just basically reads Dex one line at a time and gives you two Fields one field is the line",
    "start": "2238760",
    "end": "2245359"
  },
  {
    "text": "number the other field is the line um and uh tsv is basically a source that",
    "start": "2245359",
    "end": "2252440"
  },
  {
    "text": "gives you a set of fields one per uh tab separated column inside the file that you're reading um we also have um",
    "start": "2252440",
    "end": "2261400"
  },
  {
    "text": "additional types of data that we support uh there's another repo that you can",
    "start": "2261400",
    "end": "2267119"
  },
  {
    "text": "download from GitHub called elephant bird um and what that allows you to do is allows you to read data which is",
    "start": "2267119",
    "end": "2273720"
  },
  {
    "text": "saved in hdfs in protuff or Thrift format so if you guys are basically using U protobot for Thrift you can use",
    "start": "2273720",
    "end": "2280520"
  },
  {
    "text": "that there's schemes cascading schemes that allow you to read data in that format too um and",
    "start": "2280520",
    "end": "2289839"
  },
  {
    "text": "um the main thing to realize about a source is that there's basically two components that",
    "start": "2289839",
    "end": "2296920"
  },
  {
    "text": "um damn",
    "start": "2296920",
    "end": "2300920"
  },
  {
    "text": "yeah there's basically two components in the source and that has to do a lot with how cascading works one component is the",
    "start": "2313560",
    "end": "2319640"
  },
  {
    "text": "type of the data that is stored in hdfs and the other component is the path",
    "start": "2319640",
    "end": "2325200"
  },
  {
    "text": "structure inside hdfs what does that mean um a lot of the data that we have is processed daily so",
    "start": "2325200",
    "end": "2332480"
  },
  {
    "text": "for example we um we have a root directory in htfs that contains let's say say for example the Tweet um and",
    "start": "2332480",
    "end": "2339400"
  },
  {
    "text": "then we have a time stamp let's say by hour or by day or depending on what your",
    "start": "2339400",
    "end": "2344520"
  },
  {
    "text": "schema you're using that saves the data for that particular hour day or so on um scolding contains a relatively easy way",
    "start": "2344520",
    "end": "2352560"
  },
  {
    "text": "to manipulate dates uh which is actually a library that we're probably going to spin off eventually in its own uh in its",
    "start": "2352560",
    "end": "2359040"
  },
  {
    "text": "own repo um that lets you pass command line Arguments for like in start times",
    "start": "2359040",
    "end": "2366160"
  },
  {
    "text": "and end times and you can limit the amount of data that you're looking at for that particular time Regent you want to look uh so we have this notion of a",
    "start": "2366160",
    "end": "2373880"
  },
  {
    "text": "Time path source and we have a notion of a fixed path Source fixed path Source just means read everything in this hdfs",
    "start": "2373880",
    "end": "2379680"
  },
  {
    "text": "directory time path Source means read everything uh in all the directories",
    "start": "2379680",
    "end": "2384839"
  },
  {
    "text": "that are within this time range um in this case text line is just a fixed path Source it's just basically what we're",
    "start": "2384839",
    "end": "2391040"
  },
  {
    "text": "telling scolding here is go and read the data that is Con contained inside tutorial hello. XT and whatever",
    "start": "2391040",
    "end": "2398920"
  },
  {
    "text": "processing you do just write it in tutorial /data output 0.txt um is this",
    "start": "2398920",
    "end": "2405240"
  },
  {
    "text": "clear okay um now because this",
    "start": "2405240",
    "end": "2410280"
  },
  {
    "text": "particular example doesn't do anything interesting we're just going to go and read read the second one which is a",
    "start": "2410280",
    "end": "2415560"
  },
  {
    "text": "little bit more",
    "start": "2415560",
    "end": "2418079"
  },
  {
    "text": "interesting all right so",
    "start": "2424480",
    "end": "2429319"
  },
  {
    "text": "in this case we'll look at like the first sort of um you know non-trivial",
    "start": "2430400",
    "end": "2435440"
  },
  {
    "text": "example of doing something um keep in mind that these types of text line are",
    "start": "2435440",
    "end": "2441000"
  },
  {
    "text": "of type source source is like one of the main objects that you deal with in in",
    "start": "2441000",
    "end": "2446160"
  },
  {
    "text": "scolding the other main object that you deal with sculping is this notion of a pipe uh a pipe is the object that has",
    "start": "2446160",
    "end": "2452880"
  },
  {
    "text": "all the methods that Oscar was talking about like map and Flat map and filter and so on um the way to transform a source into a",
    "start": "2452880",
    "end": "2460440"
  },
  {
    "text": "pipe is by reading it so when you call do read on a given Source what we doing is you're basically taking the data that",
    "start": "2460440",
    "end": "2466680"
  },
  {
    "text": "is contained in that uh source and converting it into the subject that you can call all the different map map and",
    "start": "2466680",
    "end": "2472400"
  },
  {
    "text": "reduce method zone for example here the only thing we're doing is we're taking this text line we're reading it this",
    "start": "2472400",
    "end": "2477839"
  },
  {
    "text": "will give us a pipe which will contain the line number and the line itself and then we're saying all I want to do is I",
    "start": "2477839",
    "end": "2484440"
  },
  {
    "text": "want to get the line so only the text that is contain contained inside that line and write it out as an",
    "start": "2484440",
    "end": "2490720"
  },
  {
    "text": "output",
    "start": "2490720",
    "end": "2493720"
  },
  {
    "text": "um here we're doing something a little bit more complicated we just want to take every line and reverse it what this",
    "start": "2503400",
    "end": "2510359"
  },
  {
    "text": "will actually do is it will um it will replace the field called line which is",
    "start": "2510359",
    "end": "2516200"
  },
  {
    "text": "the input field in this map mapping operation with this fuel called reversed which is the output of this inline",
    "start": "2516200",
    "end": "2521760"
  },
  {
    "text": "method which all it does takes the line reverses it and replaces it in that",
    "start": "2521760",
    "end": "2527680"
  },
  {
    "text": "pipe so again like the difference of this m of this map with like the kind of",
    "start": "2528400",
    "end": "2534920"
  },
  {
    "text": "map that you would call in a Scala collection is that you basically pass it two arguments the first argument is um",
    "start": "2534920",
    "end": "2541760"
  },
  {
    "text": "um this this tle two that basically tells it what the input field is and what the output field is and the second",
    "start": "2541760",
    "end": "2546800"
  },
  {
    "text": "argument is the inline function that tells it what operation perform on the subset of tles generated from this does",
    "start": "2546800",
    "end": "2553440"
  },
  {
    "text": "does this make",
    "start": "2553440",
    "end": "2555880"
  },
  {
    "text": "sense all right so a lot of times when you're",
    "start": "2560359",
    "end": "2565800"
  },
  {
    "text": "writing your jobs you might want to actually pass input arguments um and the",
    "start": "2565800",
    "end": "2571599"
  },
  {
    "text": "way that we do that is we have our own little Arc paring Library uh which is",
    "start": "2571599",
    "end": "2577760"
  },
  {
    "text": "uh which is shown in this ARX object uh so the way that this is done is you can",
    "start": "2577760",
    "end": "2584920"
  },
  {
    "text": "basically treat this args object as a map and when you are trying like for example in this line where I'm picking",
    "start": "2584920",
    "end": "2591200"
  },
  {
    "text": "up the input in line 47 I'm not using a fixed name for the input um for the",
    "start": "2591200",
    "end": "2597520"
  },
  {
    "text": "input file location but I'm passing it in through the ARs object the moment I I call the key input on the ARX object I",
    "start": "2597520",
    "end": "2605680"
  },
  {
    "text": "am telling the flow planner that when you call when you invoke basically this job you have to pass a dash dash input",
    "start": "2605680",
    "end": "2612240"
  },
  {
    "text": "parameter otherwise the compiler is going to freak out and it's not going to work um for the output I'm still writing",
    "start": "2612240",
    "end": "2618960"
  },
  {
    "text": "in the same place like just in tutorial data output three um and this happens",
    "start": "2618960",
    "end": "2625880"
  },
  {
    "text": "for for this particular implementation of job like I I just you know I can I can add more arguments if I want to and",
    "start": "2625880",
    "end": "2632359"
  },
  {
    "text": "that's the way that I deal with input arguments there are other subclasses of job that",
    "start": "2632359",
    "end": "2638160"
  },
  {
    "text": "will constrain you to also have to pass let's say a date as a command line argument",
    "start": "2638160",
    "end": "2643960"
  },
  {
    "text": "and this args U object basically gives you the flexibility to either require",
    "start": "2643960",
    "end": "2649400"
  },
  {
    "text": "something or optionally set it to n to none if it's not there um so I don't",
    "start": "2649400",
    "end": "2654920"
  },
  {
    "text": "know if that makes sense",
    "start": "2654920",
    "end": "2658520"
  },
  {
    "text": "all right here's a little bit uh here's basically an example that shows you how a group by works um so in the first",
    "start": "2667160",
    "end": "2674400"
  },
  {
    "text": "three lines of this job um I'm just splitting the string by word so this would be like the first step to a to a",
    "start": "2674400",
    "end": "2680960"
  },
  {
    "text": "word count let's say um and here is the grouping that Oscar was talking about um",
    "start": "2680960",
    "end": "2688359"
  },
  {
    "text": "when Oscar writes his jobs he generally likes to use the underscore notation for the for the anonymous function that you",
    "start": "2688359",
    "end": "2694240"
  },
  {
    "text": "pass to the grouping here we're making it more explicit that you know this is a group Builder object that you're passing",
    "start": "2694240",
    "end": "2699520"
  },
  {
    "text": "around and all we're doing is we're doing a size um and again in the output I'm not even",
    "start": "2699520",
    "end": "2707480"
  },
  {
    "text": "though I'm reading from a text line here I'm writing to a tsv so this is the tsv that has two columns one column being uh",
    "start": "2707480",
    "end": "2714880"
  },
  {
    "text": "the the word and the second one being the count so here's an example that shows you how you can actually join uh",
    "start": "2714880",
    "end": "2720160"
  },
  {
    "text": "in this case we're actually picking up the the native uh dictionary file that",
    "start": "2720160",
    "end": "2726520"
  },
  {
    "text": "exists in all Macs well I guess in all Linux distributions right um too so all",
    "start": "2726520",
    "end": "2732800"
  },
  {
    "text": "we're doing is we're reading this up as um as a number on a score no actually",
    "start": "2732800",
    "end": "2739079"
  },
  {
    "text": "sorry we're we're so here's what we're doing here this is a file we can actually look it",
    "start": "2739079",
    "end": "2745680"
  },
  {
    "text": "up yeah so this is just a file that has",
    "start": "2754720",
    "end": "2760000"
  },
  {
    "text": "words and um and scores I don't see the scores",
    "start": "2760000",
    "end": "2765520"
  },
  {
    "text": "though oh the scores are the line numbers okay that's cool and what we're doing here is we're",
    "start": "2765520",
    "end": "2771920"
  },
  {
    "text": "taking the the the field num which is just a line number and converting it into a score I mean this is a very",
    "start": "2771920",
    "end": "2778160"
  },
  {
    "text": "contrived example um but what we're doing at the end of this",
    "start": "2778160",
    "end": "2784880"
  },
  {
    "text": "operation is we just have a score and a word and this is our first pipe the scores pipe uh then we're getting",
    "start": "2784880",
    "end": "2791599"
  },
  {
    "text": "against the input and we're flatting it out to like to a word and this step here is the one that",
    "start": "2791599",
    "end": "2798880"
  },
  {
    "text": "is actually doing the work what this does is it joins one pipe the scores",
    "start": "2798880",
    "end": "2804000"
  },
  {
    "text": "pipe with another pipe the the the one that we got from the from the text line which is the one that we call the join",
    "start": "2804000",
    "end": "2809359"
  },
  {
    "text": "with largeron and um and the join key is actually the word itself um and finally",
    "start": "2809359",
    "end": "2816599"
  },
  {
    "text": "we're grouping by uh the the line itself and just getting for every line the sum",
    "start": "2816599",
    "end": "2823920"
  },
  {
    "text": "of all the scores of all the words that appear in this line um you can imagine doing like more",
    "start": "2823920",
    "end": "2831319"
  },
  {
    "text": "complicated things here anyway any",
    "start": "2831319",
    "end": "2837040"
  },
  {
    "text": "questions sorry what are the two inputs the first input was the the dictionary file in uh",
    "start": "2837839",
    "end": "2845720"
  },
  {
    "text": "in user share dick words and the second one is actually userdefined you could",
    "start": "2845720",
    "end": "2851240"
  },
  {
    "text": "pass anything in there um any more questions so the question is",
    "start": "2851240",
    "end": "2857440"
  },
  {
    "text": "what the development process is for this um it depends I think what Oscar ends up",
    "start": "2857440",
    "end": "2863000"
  },
  {
    "text": "doing a lot is we and actually I I follow too is we subsample our data sets",
    "start": "2863000",
    "end": "2868240"
  },
  {
    "text": "into small chunks that we can actually fit in our laptops and we run a lot of these jobs in local mode and so you have",
    "start": "2868240",
    "end": "2873520"
  },
  {
    "text": "a small subset of the data that you're going to run over you first run it on local mode on your machine see that",
    "start": "2873520",
    "end": "2878599"
  },
  {
    "text": "everything works and then you um and then you ship it over and try to run it on your cluster uh the good thing about",
    "start": "2878599",
    "end": "2884960"
  },
  {
    "text": "this and I don't know if it became very clear when we gave the talk or like throughout this talk is that because of",
    "start": "2884960",
    "end": "2892040"
  },
  {
    "text": "the way that cascading works you essentially have three stages to your job the first one is compilation the",
    "start": "2892040",
    "end": "2897079"
  },
  {
    "text": "second one is flow planning and the last one is actually when like the the running phase uh so in the compilation",
    "start": "2897079",
    "end": "2902720"
  },
  {
    "text": "phase you can like you know catch like stupid errors or whatever like stupid when it your job doesn't compile in the",
    "start": "2902720",
    "end": "2909440"
  },
  {
    "text": "flow planning stage what the what the flow planner will actually do is will see that all the fields of all the",
    "start": "2909440",
    "end": "2915200"
  },
  {
    "text": "tuples that you're defining create a flow that makes sense if that doesn't happen at that point no job will be",
    "start": "2915200",
    "end": "2920640"
  },
  {
    "text": "scheduled and it will fail at that stage um you can also get failures in the in",
    "start": "2920640",
    "end": "2925880"
  },
  {
    "text": "the let's say in the running stage if you have like something like a null pointer exception or some other or bug",
    "start": "2925880",
    "end": "2931079"
  },
  {
    "text": "that we have in code or something like that um but the good news is that most of the errors will be picked up in",
    "start": "2931079",
    "end": "2937839"
  },
  {
    "text": "either in the compilation page or the flow planning stage so that helps a lot like that helps you save a lot of time",
    "start": "2937839",
    "end": "2943440"
  },
  {
    "text": "um yes so flatmap takes two arguments the first argument is a topple two of",
    "start": "2943440",
    "end": "2950680"
  },
  {
    "text": "from fields to two fields and the second argument is an anonymous function that",
    "start": "2950680",
    "end": "2956559"
  },
  {
    "text": "uh goes from um a topple of the same size as your um as your input field with",
    "start": "2956559",
    "end": "2964960"
  },
  {
    "text": "the exception being when you have a field like just one input field um with the exception being when",
    "start": "2964960",
    "end": "2972359"
  },
  {
    "text": "you have only one input field in which case instead of a toule just going to be one field and the output of that",
    "start": "2972359",
    "end": "2978720"
  },
  {
    "text": "Anonymous function has to be un iterable um so what flap map will do is it will",
    "start": "2978720",
    "end": "2986200"
  },
  {
    "text": "create a topple which will be created by the subset of the fields that you define",
    "start": "2986200",
    "end": "2991760"
  },
  {
    "text": "in your from fields and populate the two Fields with uh with the",
    "start": "2991760",
    "end": "2997240"
  },
  {
    "text": "with the output of your Anonymous method does this make sense so the question is does flat map create the number the same",
    "start": "2997240",
    "end": "3003480"
  },
  {
    "text": "number of rows the answer is it doesn't um yeah the the answer is it doesn't uh",
    "start": "3003480",
    "end": "3009599"
  },
  {
    "text": "it creates so for every row that is processed it creates as many rows as the",
    "start": "3009599",
    "end": "3015119"
  },
  {
    "text": "output of the anonymous function creates so so if your Anonymous function creates",
    "start": "3015119",
    "end": "3020319"
  },
  {
    "text": "gives back and none it's going to create zero rows I want to so the question is is the is the pipe gone does the what",
    "start": "3020319",
    "end": "3026720"
  },
  {
    "text": "happens when you operate on it the pipes are always immutable so you can kind of think of them as Frozen in time they're never going to change so when you take",
    "start": "3026720",
    "end": "3033400"
  },
  {
    "text": "this pipe and then you flat map over here you're creating a new pipe that is going to be larger or smaller who knows",
    "start": "3033400",
    "end": "3039920"
  },
  {
    "text": "because the flat map can shrink or grow the number of elements what I was just typing while argeris was was talking",
    "start": "3039920",
    "end": "3045960"
  },
  {
    "text": "about flatmap was an example in the scholar repo where I took a a list of two things you can think of that as a",
    "start": "3045960",
    "end": "3051240"
  },
  {
    "text": "pipe that has two things that has two strings uh you all everybody and is a lyric from Lost",
    "start": "3051240",
    "end": "3057319"
  },
  {
    "text": "and what I did was I did this the normal uh the the word count flat map that we keep seeing up there I did the exact",
    "start": "3057319",
    "end": "3062359"
  },
  {
    "text": "same one and you see that it returns a list that says you all everybody is a",
    "start": "3062359",
    "end": "3068160"
  },
  {
    "text": "lyric from Lost if you count that if I do do size on it you see there's eight things now so we started with two lines",
    "start": "3068160",
    "end": "3075240"
  },
  {
    "text": "we flat mapped it out wound up with eight",
    "start": "3075240",
    "end": "3079160"
  },
  {
    "text": "lines yeah to the analogy of this we could we could also do this with with a",
    "start": "3084280",
    "end": "3089599"
  },
  {
    "text": "I could have done so here's um oh",
    "start": "3089599",
    "end": "3096640"
  },
  {
    "text": "man so I can capture this as on top of all the stuff that this",
    "start": "3096640",
    "end": "3102680"
  },
  {
    "text": "awesome high-tech computer is doing it's also playing some fonus Monk in the background that no one's listening to but um there we go so there's this it's",
    "start": "3102680",
    "end": "3109079"
  },
  {
    "text": "not really a pipe it's a list but now we do the flat map on it flat map you know",
    "start": "3109079",
    "end": "3114440"
  },
  {
    "text": "line to line. split same kind of code that we've done and",
    "start": "3114440",
    "end": "3120880"
  },
  {
    "text": "now let me capture this in a new pipe Val new pipe this would be the kind of",
    "start": "3120880",
    "end": "3126400"
  },
  {
    "text": "code that we would write in sculling all the time now newpipe when you take a look that's the one that has a size of",
    "start": "3126400",
    "end": "3132760"
  },
  {
    "text": "eight and if I group you know you can do a group by in in schola as well I can",
    "start": "3132760",
    "end": "3137799"
  },
  {
    "text": "Group by I don't know like uh take the the word and and get the zeroth element",
    "start": "3137799",
    "end": "3143880"
  },
  {
    "text": "out of that oops",
    "start": "3143880",
    "end": "3148078"
  },
  {
    "text": "and that makes some big mapping whatever but uh all that's there but now notice pipe is still untouched pipe still looks",
    "start": "3149559",
    "end": "3155839"
  },
  {
    "text": "the same and that semantic those semantics still work the same in scaling as well so that did I I could also do",
    "start": "3155839",
    "end": "3162599"
  },
  {
    "text": "something like pipe do um make string and glue this all together into one big",
    "start": "3162599",
    "end": "3168400"
  },
  {
    "text": "line and that didn't change the like actually that was a bad example because that you get the same result whether you",
    "start": "3168400",
    "end": "3174680"
  },
  {
    "text": "did it on the first or second pipe but whatever yeah all right let's see if this works",
    "start": "3174680",
    "end": "3182720"
  },
  {
    "text": "so um wait a",
    "start": "3182720",
    "end": "3188880"
  },
  {
    "text": "minute okay so let's try to run this example as we said like the first uh",
    "start": "3188880",
    "end": "3194040"
  },
  {
    "text": "input that we're passing is this dictionary file um and the second one",
    "start": "3194040",
    "end": "3199599"
  },
  {
    "text": "that we're passing is you're right it did finish compiling is um",
    "start": "3199599",
    "end": "3208200"
  },
  {
    "text": "this one this hello.txt file let's take a look at",
    "start": "3208200",
    "end": "3212760"
  },
  {
    "text": "this it just has four words so it's not necessarily that",
    "start": "3215520",
    "end": "3221160"
  },
  {
    "text": "interesting but let's run it",
    "start": "3221960",
    "end": "3225640"
  },
  {
    "text": "anyways so one mode that we're doing here is we",
    "start": "3228640",
    "end": "3234720"
  },
  {
    "text": "um we don't need to compile the whole world every time we want to run a job um",
    "start": "3234720",
    "end": "3241440"
  },
  {
    "text": "something that we do to make everything a little bit faster is uh we keep around like an assembly jar that we've built",
    "start": "3241440",
    "end": "3247160"
  },
  {
    "text": "with all the necessary sources that we need and every time you run like the driver script sc. RB what it does is it",
    "start": "3247160",
    "end": "3254480"
  },
  {
    "text": "compiles a thin jar for this particular Scala file for your job um adding that",
    "start": "3254480",
    "end": "3260240"
  },
  {
    "text": "into the class path like your big assembly jar into the class path so that makes compilation time much faster for your little job that you want to run and",
    "start": "3260240",
    "end": "3266480"
  },
  {
    "text": "you want to run a little bit quickly um so yeah so that means that yeah so that",
    "start": "3266480",
    "end": "3273640"
  },
  {
    "text": "basically makes things a little bit better anyway so um so this is the",
    "start": "3273640",
    "end": "3279480"
  },
  {
    "text": "output the line Goodbye World if we sum the scores for goodbye in World we'll get 2300 20 20 232,000 sorry guys I",
    "start": "3279480",
    "end": "3290359"
  },
  {
    "text": "can't speak and uh for hello world we'll just get 35,9 75 so yeah that's the",
    "start": "3290359",
    "end": "3297119"
  },
  {
    "text": "output um any more",
    "start": "3297119",
    "end": "3301039"
  },
  {
    "text": "questions oh that's a very good question what's the scaling gen script about um",
    "start": "3304480",
    "end": "3309880"
  },
  {
    "text": "so as Oscar explained one of the things that we're doing is we are converting",
    "start": "3309880",
    "end": "3315160"
  },
  {
    "text": "cascading tles into Scala tles just make to make the whole DSL feel much more Scala likee um and that actually",
    "start": "3315160",
    "end": "3321960"
  },
  {
    "text": "requires doing a bunch of implicits for each one of the topples from 1 to 22 so there were two ways to do this either",
    "start": "3321960",
    "end": "3328839"
  },
  {
    "text": "we would take the same code and copy paste it 22 times or we write a little script that generates a code um so",
    "start": "3328839",
    "end": "3337039"
  },
  {
    "text": "that's what it does and in fact one of the um like more let's say experimental",
    "start": "3337039",
    "end": "3342400"
  },
  {
    "text": "features that we are about to release is this whole notion of an abstract algebra um this is something that Oscar worked",
    "start": "3342400",
    "end": "3348640"
  },
  {
    "text": "on a lot the idea being that if you define the the notion of a of a of a",
    "start": "3348640",
    "end": "3354720"
  },
  {
    "text": "monoid and the notion of a group and the notion of a ring uh then the operations that you need for each one of those is",
    "start": "3354720",
    "end": "3360240"
  },
  {
    "text": "like you know a zero and a plus and a and then you need like a a times and a one and all these things so you could",
    "start": "3360240",
    "end": "3366240"
  },
  {
    "text": "for example Define a plus operator for two tles right I just sum all the all the different fields inside each one of",
    "start": "3366240",
    "end": "3372799"
  },
  {
    "text": "the tles together and that's it right I just called Plus on each one of those and you can have like nested monoids and so on and so forth so this would be very",
    "start": "3372799",
    "end": "3379400"
  },
  {
    "text": "useful for doing things like reductions on multiple fields at the same time uh so but in order to do that again you",
    "start": "3379400",
    "end": "3385920"
  },
  {
    "text": "need to do all the monoid implicit conversions for each one of the tles from tle one to tle 22 we had to",
    "start": "3385920",
    "end": "3391640"
  },
  {
    "text": "generate a bunch of code for that too so because like you know our scripting",
    "start": "3391640",
    "end": "3396880"
  },
  {
    "text": "language of choice is Ruby the Gen scripts are Ruby scripts",
    "start": "3396880",
    "end": "3402200"
  },
  {
    "text": "um does that answer a question Cool",
    "start": "3402200",
    "end": "3407760"
  },
  {
    "text": "please so it's not really like so the question is if there's any best practice in terms of the number of joints that",
    "start": "3407760",
    "end": "3413799"
  },
  {
    "text": "you do within a job um actually what ends up being a little bit",
    "start": "3413799",
    "end": "3419280"
  },
  {
    "text": "more critical is how much data skew there is in a given joint that you want to do um the thing is if those joints",
    "start": "3419280",
    "end": "3426640"
  },
  {
    "text": "are different joints that are happening the cascading flow planner is going to be smart enough to break those up into a a very like a different number of map",
    "start": "3426640",
    "end": "3433640"
  },
  {
    "text": "redu steps uh so if you're doing too many what will end up happening is the whole flow will take like a lot of time",
    "start": "3433640",
    "end": "3440319"
  },
  {
    "text": "to run but nothing bad will happen um also keep in mind that none of the like",
    "start": "3440319",
    "end": "3446799"
  },
  {
    "text": "if you actually want to access any of the data um and actually read it and do stuff based on it like you want to have",
    "start": "3446799",
    "end": "3453039"
  },
  {
    "text": "some logic or you want to run a loop where a job will will rerun if like some",
    "start": "3453039",
    "end": "3458760"
  },
  {
    "text": "for example you're running something like page rank for example um then you can't do that at the flow planning stage",
    "start": "3458760",
    "end": "3465119"
  },
  {
    "text": "you have to wait for your flow to complete and then access the data read it and decide whether you want to keep",
    "start": "3465119",
    "end": "3470559"
  },
  {
    "text": "going so that could be a limiting factor um now if you have issues with data skew",
    "start": "3470559",
    "end": "3477319"
  },
  {
    "text": "we're actually in the process of implementing um a skew join um we have",
    "start": "3477319",
    "end": "3482799"
  },
  {
    "text": "this notion of what we call a block join that yeah that that I could talk about if you want to but um what that",
    "start": "3482799",
    "end": "3491119"
  },
  {
    "text": "basically does is it helps you do joints of of pipes that where like some of the",
    "start": "3491119",
    "end": "3496480"
  },
  {
    "text": "keys would hash into the same reducer and like that would cause a lot of the data to go to the same reducer and",
    "start": "3496480",
    "end": "3501799"
  },
  {
    "text": "everything would take forever to run um oh um so how does scolding know if an",
    "start": "3501799",
    "end": "3507760"
  },
  {
    "text": "operation is not associative um well the only like we have a couple of operations",
    "start": "3507760",
    "end": "3514319"
  },
  {
    "text": "that are not so if you actually look at the group Builder code we Implement Logic for um how to do a particular",
    "start": "3514319",
    "end": "3521480"
  },
  {
    "text": "operation in a way that would be associative or in a way that would do everything at the reducer and the moment",
    "start": "3521480",
    "end": "3527559"
  },
  {
    "text": "you add an operation in the group Builder that is not associative at that point we cancel any Maps side aggregation and we push everything at",
    "start": "3527559",
    "end": "3533839"
  },
  {
    "text": "the reducer so we keep track of that and the moment you try to do something that would break the associativity would just",
    "start": "3533839",
    "end": "3541119"
  },
  {
    "text": "give up and say okay that means we need to push everything to the reducer an example of that would be something like a fold LIF that would need to go through",
    "start": "3541119",
    "end": "3548160"
  },
  {
    "text": "every um element inside your group you can't do that from a from a map side",
    "start": "3548160",
    "end": "3554799"
  },
  {
    "text": "right the def like let's say the the main um like functions such as sum or",
    "start": "3554799",
    "end": "3561079"
  },
  {
    "text": "average or average some average standard deviation or map reduce map those retain associativity so as long as you're using",
    "start": "3561079",
    "end": "3566880"
  },
  {
    "text": "those you're good um there are other methods like fold left or scan left or",
    "start": "3566880",
    "end": "3572920"
  },
  {
    "text": "sort which other ones do we have they're fix in the library yeah no you",
    "start": "3572920",
    "end": "3581078"
  },
  {
    "text": "can't yeah and there's another list of functions that are not associative and the moment you use any of those you just",
    "start": "3583160",
    "end": "3588400"
  },
  {
    "text": "broken associativity so yeah that's a really",
    "start": "3588400",
    "end": "3593680"
  },
  {
    "text": "good example um actually we rare rarely and maybe never deal with data that is",
    "start": "3593680",
    "end": "3599599"
  },
  {
    "text": "text in Twitter like almost all of the data we deal with is either Thrift or protuff um the thing is that we haven't",
    "start": "3599599",
    "end": "3606119"
  },
  {
    "text": "pulled that as a dependency inside the scolding project itself because we didn't want to make it too heavy uh but",
    "start": "3606119",
    "end": "3611839"
  },
  {
    "text": "there is another project called elephant bird and it's quite easy to to pull in",
    "start": "3611839",
    "end": "3617359"
  },
  {
    "text": "that and and and use that to to be able to read uh and write to to let's say for",
    "start": "3617359",
    "end": "3623760"
  },
  {
    "text": "example LZ compressed uh through on protuff just to answer your question the",
    "start": "3623760",
    "end": "3628960"
  },
  {
    "text": "the code looks exactly the same like nothing changes you just make a few definitions about your source and then",
    "start": "3628960",
    "end": "3634720"
  },
  {
    "text": "the rest of the job looks exactly the",
    "start": "3634720",
    "end": "3638119"
  },
  {
    "text": "same yeah it's it's basically a different implementation of a of of a source yeah that's all it",
    "start": "3640119",
    "end": "3645640"
  },
  {
    "text": "is um yes",
    "start": "3645640",
    "end": "3650440"
  },
  {
    "text": "uh yeah so yeah you can take that and Sam is gonna love this so Sam",
    "start": "3656640",
    "end": "3662359"
  },
  {
    "text": "Richie is uh one of the guys from calog and he works at Twitter also and we're always like you know trying you know Sam",
    "start": "3662359",
    "end": "3670000"
  },
  {
    "text": "sitting there trying to convert you over to using calog which is like a closure version of like cascading and then we're",
    "start": "3670000",
    "end": "3675280"
  },
  {
    "text": "over here or maybe me more than arus isn't the the Zealot that I am maybe but um trying to preach the gospel of",
    "start": "3675280",
    "end": "3681559"
  },
  {
    "text": "scalding and but we've agreed to collaborate on some subset of things so Meat Locker cascading cryo we have like",
    "start": "3681559",
    "end": "3688119"
  },
  {
    "text": "a whole like GitHub cascading is a bunch of projects and a lot of those are just like Sam and us and Chris win from",
    "start": "3688119",
    "end": "3694960"
  },
  {
    "text": "concurrent and so uh Sam's some like uh you know former Olympic rower like",
    "start": "3694960",
    "end": "3700640"
  },
  {
    "text": "CrossFit crazy dude and we were joking about something some about putting cryo stuff in the freezer and we were we have",
    "start": "3700640",
    "end": "3707000"
  },
  {
    "text": "to give things names and people hate code names and it became meat locker and it's so awesome that meat locker gets",
    "start": "3707000",
    "end": "3712799"
  },
  {
    "text": "brought up it's like a big question this is awesome it's Twitter's Secret strategy to destroy Facebook that's really the",
    "start": "3712799",
    "end": "3719920"
  },
  {
    "text": "answer he didn't just say that anyway um yeah so yeah does that answer your",
    "start": "3719920",
    "end": "3727480"
  },
  {
    "text": "question it's so what we're doing is we're basically breaking off pieces that are common to projects that use",
    "start": "3727480",
    "end": "3733839"
  },
  {
    "text": "cascading but are written in different languages and we're just trying to use these around so that's that's the part",
    "start": "3733839",
    "end": "3740440"
  },
  {
    "text": "of serialization that Sam pulled out into its own project",
    "start": "3740440",
    "end": "3746960"
  },
  {
    "text": "and what I was trying to bring up here was an example of how would you go about like doing thrift like um and so here so",
    "start": "3747720",
    "end": "3756000"
  },
  {
    "text": "we have these this is this is code that's not been released yet there's no reason why it shouldn't be or couldn't be but it's just not yet and so if you",
    "start": "3756000",
    "end": "3762880"
  },
  {
    "text": "wanted to implement this yourself you can see it's like five lines of code and you basically say you wanted to define a new uh like in this case we make a trait",
    "start": "3762880",
    "end": "3770279"
  },
  {
    "text": "for lzo compressed protuff and we say that the H there's a scheme this is a notion from cascading is the lzo protuff",
    "start": "3770279",
    "end": "3777440"
  },
  {
    "text": "schemes and these guys are defined uh somewhere up here those uh these are",
    "start": "3777440",
    "end": "3782520"
  },
  {
    "text": "defined in the elephant bur project that is open source so you can download that that's another Twitter project and it's",
    "start": "3782520",
    "end": "3787880"
  },
  {
    "text": "like five lines of code to adapt it to being so the the schemes are cascading schemes but it's like like I said I mean",
    "start": "3787880",
    "end": "3793160"
  },
  {
    "text": "that's literally five lines of code to make it a scalding source and then you're good to go so we we could release this file or whatever but um and this is",
    "start": "3793160",
    "end": "3800440"
  },
  {
    "text": "just like arus was mentioning if we want to deal with dates we've got some some logic around that but it's pretty straightforward",
    "start": "3800440",
    "end": "3806960"
  },
  {
    "text": "that's actually so the question is is there a way to define a mapping from let's say Thrift or Proto Fields into",
    "start": "3806960",
    "end": "3812760"
  },
  {
    "text": "into cascading Fields awesome question the answer is yes you can do that in one line of code uh we have a methods called",
    "start": "3812760",
    "end": "3819799"
  },
  {
    "text": "pack and unpack what unpack does is it's a little bit dirty but it works so I like it um what it does is it uses",
    "start": "3819799",
    "end": "3827599"
  },
  {
    "text": "reflection on the field name to call the right getter on on the protuff object or",
    "start": "3827599",
    "end": "3833000"
  },
  {
    "text": "the thrift object and takes it out and puts it into the field with that name um the the good news is that it doesn't do",
    "start": "3833000",
    "end": "3839640"
  },
  {
    "text": "that at runtime it does that at flow uh at at flow um scheduling time so it will",
    "start": "3839640",
    "end": "3846440"
  },
  {
    "text": "check whether those Getters and Setters exist in your in your object and if they don't it will fail without scheduling",
    "start": "3846440",
    "end": "3852920"
  },
  {
    "text": "any job so it's dirty but it's not as dirty as it sounds so um that's what unpack does it gets out the the field",
    "start": "3852920",
    "end": "3859799"
  },
  {
    "text": "and pack will do the opposite like if you've named your Fields the right way it will actually use the cascading it's",
    "start": "3859799",
    "end": "3865720"
  },
  {
    "text": "sorry the thrift or protuff Setters to set them into the object so you don't need to write a bunch of boilerplate",
    "start": "3865720",
    "end": "3870839"
  },
  {
    "text": "code to instantiate the object put everything in and put it out you just do it like that so but by the way you don't",
    "start": "3870839",
    "end": "3875960"
  },
  {
    "text": "have to operate that way you can these objects can just pass along the whole Thrift object to you the Tuple the",
    "start": "3875960",
    "end": "3882039"
  },
  {
    "text": "fields can contain a whole object so like our like you know log entries might have like a hundred like they might be a",
    "start": "3882039",
    "end": "3888279"
  },
  {
    "text": "thrift object with like a 100 Fields inside they don't have to be flattened out into tups they can you know you can",
    "start": "3888279",
    "end": "3894240"
  },
  {
    "text": "pass those objects around three pipes so it's not like pig or something that only has primitive elements in the tupal you",
    "start": "3894240",
    "end": "3900000"
  },
  {
    "text": "can also have your Thrift object right in the tupal so the packing our pack is there when you want to flatten it out",
    "start": "3900000",
    "end": "3906359"
  },
  {
    "text": "but often is the case that you want to just compute directly on the object itself",
    "start": "3906359",
    "end": "3913559"
  },
  {
    "text": "cool thanks guys",
    "start": "3913559",
    "end": "3917920"
  },
  {
    "text": "[Music]",
    "start": "3919600",
    "end": "3930050"
  }
]
[
  {
    "start": "0",
    "end": "41000"
  },
  {
    "text": "so mine is Richard I'm sorry and we're here to talk about continuous profiling",
    "start": "4080",
    "end": "9629"
  },
  {
    "text": "in production what wine how so what does that mean well we're gonna talk a little bit about why performance tools matter",
    "start": "9629",
    "end": "17970"
  },
  {
    "text": "why you might need tools to understand performance problems in your application stack I want talk about the differences",
    "start": "17970",
    "end": "23160"
  },
  {
    "text": "between like a development environment and a production environment and why just looking at things in development",
    "start": "23160",
    "end": "29190"
  },
  {
    "text": "might not be the right way to understand performance problems and then look at a few different kind of approaches at the",
    "start": "29190",
    "end": "34620"
  },
  {
    "text": "high level as to how we can solve these things so firstly at a very high level like why do performance tools matter",
    "start": "34620",
    "end": "42329"
  },
  {
    "start": "41000",
    "end": "190000"
  },
  {
    "text": "well firstly when you think about software development problems I think there's kind of three kind of broad",
    "start": "42329",
    "end": "49230"
  },
  {
    "text": "categories of things that you get and this applies to performance problems and",
    "start": "49230",
    "end": "54480"
  },
  {
    "text": "performance aspects of your software as as much as others the first ones no known so these are kind of like the",
    "start": "54480",
    "end": "59690"
  },
  {
    "text": "theoretically the easy aspects of your software right so you know that reading",
    "start": "59690",
    "end": "66689"
  },
  {
    "text": "data out of your main memory is gonna be faster than reading data off a hard disk",
    "start": "66689",
    "end": "71939"
  },
  {
    "text": "you you can have that in your mental model that's something that you can confidently bank on then you've got your",
    "start": "71939",
    "end": "80009"
  },
  {
    "text": "known unknowns okay so these are things aspects of your software system where",
    "start": "80009",
    "end": "86069"
  },
  {
    "text": "you know that there could be a potential for a performance problem there but you don't know how big of an issue it is for",
    "start": "86069",
    "end": "94170"
  },
  {
    "text": "example every time you've got an unbounded size of queue in a production system you don't know whether it'll be a",
    "start": "94170",
    "end": "101639"
  },
  {
    "text": "performance problem but you know it could be a an issue there you know that there's this main memory disk speed",
    "start": "101639",
    "end": "109020"
  },
  {
    "text": "ratio difference but you don't know how big it is until you actually look at it in some particular system so these are",
    "start": "109020",
    "end": "116669"
  },
  {
    "text": "things that you you may not know all the details on but you can plan ahead for okay you can mentally model you can",
    "start": "116669",
    "end": "123389"
  },
  {
    "text": "think through and then there are the unknown unknowns the real kind of spanner in the works problems these",
    "start": "123389",
    "end": "130619"
  },
  {
    "text": "don't necessarily have to be hard or complicated but they could be something like you spent months building of beauty",
    "start": "130619",
    "end": "137330"
  },
  {
    "text": "full well-thought-through scalable parallel algorithm and then you've got a sequential logger in the middle of this",
    "start": "137330",
    "end": "143960"
  },
  {
    "text": "system that's slowing everything down to the speed of one thread and you didn't think about that you wouldn't you would",
    "start": "143960",
    "end": "150020"
  },
  {
    "text": "necessarily think about those kind of issues ahead of time until you hit them in production until they're real",
    "start": "150020",
    "end": "156710"
  },
  {
    "text": "problems for your system that the things that you maybe with hindsight you would think oh yeah I'd get that next time but",
    "start": "156710",
    "end": "163310"
  },
  {
    "text": "until you hit it it's an unknown unknown and a lot of the other aspects of",
    "start": "163310",
    "end": "169910"
  },
  {
    "text": "software performance can be planned ahead you can architect and design for known owns and for known unknowns but",
    "start": "169910",
    "end": "177170"
  },
  {
    "text": "unknown unknowns you're gonna need to have something that measures how that",
    "start": "177170",
    "end": "182420"
  },
  {
    "text": "system actually works to understand how those perform how you can solve those",
    "start": "182420",
    "end": "188330"
  },
  {
    "text": "performance problems okay now initially when we look at a lot of aspects of",
    "start": "188330",
    "end": "195740"
  },
  {
    "start": "190000",
    "end": "232000"
  },
  {
    "text": "software correctness for example test and we look at running automated tests in the development environment so Siddiq",
    "start": "195740",
    "end": "203120"
  },
  {
    "text": "if we do testing in development for the correctness of our programs why can't we",
    "start": "203120",
    "end": "208940"
  },
  {
    "text": "just do that for performance problems as well why can't why can we just do that for everything right well over the next",
    "start": "208940",
    "end": "215269"
  },
  {
    "text": "few slides we are going to go through why from a performance point of view",
    "start": "215269",
    "end": "220540"
  },
  {
    "text": "testing in development is not representative of production and we",
    "start": "220540",
    "end": "225620"
  },
  {
    "text": "should take a step back just for we start this our goal for performance testing is to remove bottlenecks from",
    "start": "225620",
    "end": "232190"
  },
  {
    "text": "production right we do this performance work to make production go quicker or produce less waste if our goal was to",
    "start": "232190",
    "end": "239989"
  },
  {
    "text": "make development go quicker well then we could do in a different way but if we're trying to make production go quicker then we need to actually do our",
    "start": "239989",
    "end": "249080"
  },
  {
    "text": "performance testing in production as a problem because actually performance testing and development is easier the",
    "start": "249080",
    "end": "255110"
  },
  {
    "text": "the tools that we're used to using are desktop tools the desktop profile is",
    "start": "255110",
    "end": "260479"
  },
  {
    "text": "your visual leo JJ profile of visual VM what have you you may not have access to",
    "start": "260479",
    "end": "266060"
  },
  {
    "text": "production there are many organizations I've worked in I'm sure many of you here where there are strict",
    "start": "266060",
    "end": "271440"
  },
  {
    "text": "rolls around who has access to production might be organizational might be regulatory reasons but as we're gonna",
    "start": "271440",
    "end": "278220"
  },
  {
    "text": "see over next few slides as easy as it is doing performance testing development it is not representative of production",
    "start": "278220",
    "end": "284640"
  },
  {
    "text": "and our goal here is to actually understand the performance of production",
    "start": "284640",
    "end": "290090"
  },
  {
    "start": "290000",
    "end": "428000"
  },
  {
    "text": "so the first problem we've got is unrepresentative hardware who here",
    "start": "290090",
    "end": "295380"
  },
  {
    "text": "develops on exactly the same kind of hardware they actually deploy to in production one person who about one with",
    "start": "295380",
    "end": "304410"
  },
  {
    "text": "a really big bid and so you you might",
    "start": "304410",
    "end": "311010"
  },
  {
    "text": "you might develop on a on a two or if you're lucky four core laptop that's",
    "start": "311010",
    "end": "316740"
  },
  {
    "text": "optimized for power consumption they try and make that battery last as long as possible whereas when you deploy to production",
    "start": "316740",
    "end": "322170"
  },
  {
    "text": "you might be on 24 core 32 call multiple socket machines that have very different",
    "start": "322170",
    "end": "327480"
  },
  {
    "text": "memory topologies you city doesn't that just mean though your production servers",
    "start": "327480",
    "end": "332850"
  },
  {
    "text": "are a bit faster so if you can find the bottleneck on your laptop and you can fix on your laptop it's gonna run better",
    "start": "332850",
    "end": "339000"
  },
  {
    "text": "in production right it's bigger hardware it's faster bigger is not always better so from the point of view of a",
    "start": "339000",
    "end": "345200"
  },
  {
    "text": "production if you imagine that you have say a to core processor in your laptop and you have a 24 core processor in your",
    "start": "345200",
    "end": "352860"
  },
  {
    "text": "server what you're gonna see is a shift in the kind of bottlenecks that turn up so if you've got a 24 core if your story",
    "start": "352860",
    "end": "359610"
  },
  {
    "text": "you've got a 2 core processor in your laptop you may may just not see a lock",
    "start": "359610",
    "end": "364890"
  },
  {
    "text": "contention issue that actually is a big problem in production when you now have many many cause so just because the",
    "start": "364890",
    "end": "372210"
  },
  {
    "text": "system is bigger doesn't necessarily mean it's it's it's anyway better representative and you're gonna see the",
    "start": "372210",
    "end": "377610"
  },
  {
    "text": "same problem where say IO subsystems so on your server class Hardware you're",
    "start": "377610",
    "end": "384060"
  },
  {
    "text": "likely to have very high performance very throughput latency optimized IO nvme scuzzy and nvme SSDs and suchlike",
    "start": "384060",
    "end": "392160"
  },
  {
    "text": "whereas on your laptop you have things that are generally generally tuned for",
    "start": "392160",
    "end": "397230"
  },
  {
    "text": "power and that means the bottlenecks will shift what might be a io bottleneck",
    "start": "397230",
    "end": "402390"
  },
  {
    "text": "on your laptop will probably turn into an or CPU bottleneck on a server where you're no longer sat there waiting on",
    "start": "402390",
    "end": "408879"
  },
  {
    "text": "the disks all the time and that's before we get to modern cloud environments where the hard way you get is often very",
    "start": "408879",
    "end": "416289"
  },
  {
    "text": "opaque and sometimes you know basically a mechanical potato is what some of those servers are running very very much",
    "start": "416289",
    "end": "422889"
  },
  {
    "text": "slower than modern laptops and desktops for a lot of cases the next thing is",
    "start": "422889",
    "end": "429309"
  },
  {
    "start": "428000",
    "end": "503000"
  },
  {
    "text": "unrepresentative software so that's the show hands again who is running exactly the same software on their development",
    "start": "429309",
    "end": "435009"
  },
  {
    "text": "environment as they do in production okay just normal people I mean in",
    "start": "435009",
    "end": "441279"
  },
  {
    "text": "organizations I've worked in the last few years development hasn't actually even happened on the same operating system as",
    "start": "441279",
    "end": "447719"
  },
  {
    "text": "production you know I often you've got Mac laptops and you have Linux running in in production but even if you're",
    "start": "447719",
    "end": "454360"
  },
  {
    "text": "running the same operating system the actual version of the operating system is that you run makes a big difference",
    "start": "454360",
    "end": "461680"
  },
  {
    "text": "and we saw that we saw that in a big way with the specter and meltdown issues the",
    "start": "461680",
    "end": "467169"
  },
  {
    "text": "last few years where different Linux versions the way that they actually implement these these mitigations the",
    "start": "467169",
    "end": "473439"
  },
  {
    "text": "different kernel versions actually had dramatically different performance characteristics around them so even small variations in the software that",
    "start": "473439",
    "end": "480789"
  },
  {
    "text": "you run between your development environment and production can have a big difference of where your bottlenecks lie one of the patch hues they updates",
    "start": "480789",
    "end": "488289"
  },
  {
    "text": "for Windows 10 back at the end of last May I think it was dropped UDP",
    "start": "488289",
    "end": "494139"
  },
  {
    "text": "throughput by 40 percent which is an absolute stonking regression in",
    "start": "494139",
    "end": "499509"
  },
  {
    "text": "performance and that was just a security patch the next thing is I'm",
    "start": "499509",
    "end": "504759"
  },
  {
    "start": "503000",
    "end": "580000"
  },
  {
    "text": "representative workloads so assuming we were going to test in development what we need some way of exercising our",
    "start": "504759",
    "end": "510669"
  },
  {
    "text": "environment and actually that that can be very difficult especially if if we're trying to look for these unknown",
    "start": "510669",
    "end": "516969"
  },
  {
    "text": "unknowns the things that we don't actually know about before that it's very easy to say okay what what is the",
    "start": "516969",
    "end": "523180"
  },
  {
    "text": "distribution of requests our cost my different endpoints most people probably have that information then you start to",
    "start": "523180",
    "end": "528910"
  },
  {
    "text": "say well alright well what is the for a given end point what's the distribution of requests between caught a hold and",
    "start": "528910",
    "end": "536100"
  },
  {
    "text": "hot and cold data well a bit more complicated to answer and then it's things like how what's the",
    "start": "536100",
    "end": "541900"
  },
  {
    "text": "interdependence between requests to my different end points and that's a much more complicated question to answer I",
    "start": "541900",
    "end": "547090"
  },
  {
    "text": "once worked with a company where we had a misbehaving SDK in the wild that would do through three parallel requests to",
    "start": "547090",
    "end": "555160"
  },
  {
    "text": "three of our different endpoints but that those endpoints actually ended up and you taking the same data you can imagine that you'd find all kinds of",
    "start": "555160",
    "end": "561550"
  },
  {
    "text": "weird and wonderful contention issues there that you wouldn't have thought to actually encode in in a workload test",
    "start": "561550",
    "end": "569680"
  },
  {
    "text": "that you're running against your development environment so it's very difficult to actually create a worker",
    "start": "569680",
    "end": "574840"
  },
  {
    "text": "that is representative of how production is being exercised and of course the",
    "start": "574840",
    "end": "581560"
  },
  {
    "start": "580000",
    "end": "615000"
  },
  {
    "text": "last wild card we have is the JVM so using hotspot it has a JIT it does",
    "start": "581560",
    "end": "586810"
  },
  {
    "text": "adaptive optimization it adapts its optimization to how the code is actually being used so if you can't exercise the",
    "start": "586810",
    "end": "594940"
  },
  {
    "text": "environment you're testing in exactly the same way as production that there's no guarantee that actually it's been",
    "start": "594940",
    "end": "600070"
  },
  {
    "text": "optimized in the same way in production so you might actually be looking at something that performs again differently to your production",
    "start": "600070",
    "end": "605830"
  },
  {
    "text": "environment so in summary don't be the dog who's kind of cool but you don't",
    "start": "605830",
    "end": "612040"
  },
  {
    "text": "really want be the dog cool so having said we need to understand how systems",
    "start": "612040",
    "end": "618040"
  },
  {
    "start": "615000",
    "end": "621000"
  },
  {
    "text": "work in a realistic production environment with a real load what kind of information can we gather from that",
    "start": "618040",
    "end": "624010"
  },
  {
    "start": "621000",
    "end": "696000"
  },
  {
    "text": "production system to understand it well firstly people look at metrics so by",
    "start": "624010",
    "end": "629920"
  },
  {
    "text": "metrics I mean some pre-configured numerical measure on a regular time",
    "start": "629920",
    "end": "635770"
  },
  {
    "text": "interval you pull some data of that system suffering things like what's your CPU time usage what are your page load",
    "start": "635770",
    "end": "643120"
  },
  {
    "text": "times for individual requests some kind of time-series metric data metrics are",
    "start": "643120",
    "end": "648430"
  },
  {
    "text": "often incredibly useful they can narrow down problems incredibly rapidly and",
    "start": "648430",
    "end": "655120"
  },
  {
    "text": "tell you whether you get bottlenecks and different components in your system well within your system some of those",
    "start": "655120",
    "end": "660130"
  },
  {
    "text": "problems can lie they're also incredibly cheap to collect so when I say cheap to",
    "start": "660130",
    "end": "666100"
  },
  {
    "text": "collect I don't mean how much actual cash you necessarily directly spend on",
    "start": "666100",
    "end": "671440"
  },
  {
    "text": "these things I'm what's the performance overhead for gathering these things these things are often very cheap to collect and often",
    "start": "671440",
    "end": "677740"
  },
  {
    "text": "very cheap to aggregate query and store over and lots of open-source tooling around system metrics so very useful but",
    "start": "677740",
    "end": "685180"
  },
  {
    "text": "system metrics aren't necessarily a solution in and of themselves they're quite bad at telling you where inside",
    "start": "685180",
    "end": "692290"
  },
  {
    "text": "your codebase a problem specifically lies looking at system metrics",
    "start": "692290",
    "end": "699340"
  },
  {
    "start": "696000",
    "end": "743000"
  },
  {
    "text": "extensively can often lead to these kind of murder-mystery style debugging situations now that sounds like it's a",
    "start": "699340",
    "end": "706660"
  },
  {
    "text": "really exciting oq para roleplay situation but unfortunately the reality",
    "start": "706660",
    "end": "712210"
  },
  {
    "text": "can be a little bit different people go around start systematically looking through these metrics and often people",
    "start": "712210",
    "end": "717910"
  },
  {
    "text": "are encouraged to collect as many metrics as their system can store which can often be a lot so you have a lot of",
    "start": "717910",
    "end": "724570"
  },
  {
    "text": "different possible causes of a problem and people start looking for anomalies and going a euler metric that caused",
    "start": "724570",
    "end": "730300"
  },
  {
    "text": "this problem au the metric that caused this problem are you the metric that causes from before eventually finding",
    "start": "730300",
    "end": "735760"
  },
  {
    "text": "something that's unusual or problematic if it's kind of systemic guess working",
    "start": "735760",
    "end": "742180"
  },
  {
    "text": "way logging is another way you can extract useful information from",
    "start": "742180",
    "end": "748000"
  },
  {
    "start": "743000",
    "end": "789000"
  },
  {
    "text": "production systems so sometimes people have manual logging that they've",
    "start": "748000",
    "end": "753700"
  },
  {
    "text": "instrumented their code base with which can often be incredibly useful incredibly detailed information about",
    "start": "753700",
    "end": "760000"
  },
  {
    "text": "the system but a that's manual work that you need to do yourself be logging in",
    "start": "760000",
    "end": "765880"
  },
  {
    "text": "detail can rapidly become a big bottleneck or a big overhead and often",
    "start": "765880",
    "end": "771580"
  },
  {
    "text": "the cause of a lot of performance problems in itself GC logging is another",
    "start": "771580",
    "end": "777070"
  },
  {
    "text": "case where the performance information to be useful often much much lower overhead and very useful but again",
    "start": "777070",
    "end": "783130"
  },
  {
    "text": "that's only for a specific sub system and often GC logs are quite hard to interpret anyway a lot of modern",
    "start": "783130",
    "end": "791380"
  },
  {
    "start": "789000",
    "end": "874000"
  },
  {
    "text": "application performance monitoring APM tools use a different approach they use a very coarse-grained instrumentation",
    "start": "791380",
    "end": "798310"
  },
  {
    "text": "approach so what they do is they have some agent that sits within your software system they weave in some information into your",
    "start": "798310",
    "end": "805980"
  },
  {
    "text": "byte code that's very fancy doesn't it weave it in there and take timings for a",
    "start": "805980",
    "end": "812640"
  },
  {
    "text": "certain operation so measure the time of the beginning of the operation measure time at the end of the operation did",
    "start": "812640",
    "end": "818070"
  },
  {
    "text": "with subtraction pull out the time that you can get for an operation and then you know how how long it is",
    "start": "818070",
    "end": "825080"
  },
  {
    "text": "instrumentation can be a very very useful way to see into your application",
    "start": "825080",
    "end": "832020"
  },
  {
    "text": "in a way that metrics won't give you visibility into a black box but",
    "start": "832020",
    "end": "837230"
  },
  {
    "text": "instrumentation itself has a couple of big problems okay the first problem that",
    "start": "837230",
    "end": "845610"
  },
  {
    "text": "it has is potentially the more detailed your instrumentation is the more instrumentation code you have to add",
    "start": "845610",
    "end": "852690"
  },
  {
    "text": "into your application software itself and the more code you add the slower your system becomes and the second thing",
    "start": "852690",
    "end": "859020"
  },
  {
    "text": "is in practice because people just look at very coarse-grained pictures it has to be things that they've thought of a",
    "start": "859020",
    "end": "865380"
  },
  {
    "text": "priori before their system goes into production in order to understand where",
    "start": "865380",
    "end": "871500"
  },
  {
    "text": "that instrumentation should lie within the stack then that's production profiling so what is profiling profiling",
    "start": "871500",
    "end": "878670"
  },
  {
    "start": "874000",
    "end": "930000"
  },
  {
    "text": "is attributed some resource usage from the system to a component within your software stack so what methods are using",
    "start": "878670",
    "end": "886140"
  },
  {
    "text": "up CPU time what lines of code are allocating objects it could be where your CPU cache misses are coming from it",
    "start": "886140",
    "end": "892350"
  },
  {
    "text": "could be you could profile for almost anything now profiling has some nice wins here so firstly it can be automatic",
    "start": "892350",
    "end": "900450"
  },
  {
    "text": "so that's to say once you've got a profiler that works for a JVM",
    "start": "900450",
    "end": "905610"
  },
  {
    "text": "application you don't necessarily need to customize your application to add any specific aspect of it production",
    "start": "905610",
    "end": "913530"
  },
  {
    "text": "profiling can also be done very cheaply we'll look later on this talk about some of the technical approaches to make it",
    "start": "913530",
    "end": "919650"
  },
  {
    "text": "really cheap in practice profilers are often not very cheap if you try and hook",
    "start": "919650",
    "end": "925170"
  },
  {
    "text": "up JVG or VM production you are in for a world of hurt so I said earlier that",
    "start": "925170",
    "end": "932750"
  },
  {
    "start": "930000",
    "end": "1018000"
  },
  {
    "text": "instrumentation can be a little bit blind in a lot of real worlds situation so let's look at our kind of",
    "start": "932750",
    "end": "938430"
  },
  {
    "text": "real example of that that we had from a customer of ours they had a problem",
    "start": "938430",
    "end": "944279"
  },
  {
    "text": "where they had a slow HTTP endpoint periodically like every five seconds the",
    "start": "944279",
    "end": "949680"
  },
  {
    "text": "endpoint would be really slow they were using an APM tool so that was",
    "start": "949680",
    "end": "956130"
  },
  {
    "text": "instrumenting all their HTTP requests loads and the graph on that was beautiful green you never got a bad",
    "start": "956130",
    "end": "963660"
  },
  {
    "text": "request if you just look at that graph everything's fantastic if you talk to the customers they're really annoyed",
    "start": "963660",
    "end": "968880"
  },
  {
    "text": "that they can't log into their system periodically so what was the root cause",
    "start": "968880",
    "end": "974550"
  },
  {
    "text": "of that system a problem well a root cause was tomcat it has like a cache for",
    "start": "974550",
    "end": "980279"
  },
  {
    "text": "the resources that you HTTP resources and it expires that cache periodically",
    "start": "980279",
    "end": "986850"
  },
  {
    "text": "when it tries to reload those resources they go and do a load of classpath scanning so the whole system grinds to a",
    "start": "986850",
    "end": "993959"
  },
  {
    "text": "halt for two seconds whilst this happens and that's something that an",
    "start": "993959",
    "end": "999000"
  },
  {
    "text": "instrumentation based system didn't pick up because they are putting their instrumentation on the servlet request",
    "start": "999000",
    "end": "1004820"
  },
  {
    "text": "itself rather than looking at what the underlying system was so they made this",
    "start": "1004820",
    "end": "1010850"
  },
  {
    "text": "kind of ahead of time assumption about where problems were but didn't really follow through in the real world and the",
    "start": "1010850",
    "end": "1019190"
  },
  {
    "start": "1018000",
    "end": "1051000"
  },
  {
    "text": "other aspect of this is the overhead I mean these are tools that are meant to be helping you solve performance",
    "start": "1019190",
    "end": "1025308"
  },
  {
    "text": "problems so the more overhead the tools adds the worse the problem becomes they",
    "start": "1025309",
    "end": "1031339"
  },
  {
    "text": "can rapidly become the problem rather than help you solve problems and that's",
    "start": "1031339",
    "end": "1036350"
  },
  {
    "text": "the case with instrumentation if you have a tional notation based approaches which are very fine-grained and very",
    "start": "1036350",
    "end": "1041660"
  },
  {
    "text": "detailed they rapidly add so much overhead that you have to get a lot of",
    "start": "1041660",
    "end": "1046880"
  },
  {
    "text": "you have to get a lot of gains in order to win back that overhead from them so",
    "start": "1046880",
    "end": "1052730"
  },
  {
    "start": "1051000",
    "end": "1075000"
  },
  {
    "text": "surely there's a better way right not just looking at metrics but we want actionable insights you want something",
    "start": "1052730",
    "end": "1059480"
  },
  {
    "text": "that we can look at and say we're in our code base to me to fix a problem so what",
    "start": "1059480",
    "end": "1067370"
  },
  {
    "text": "about thinking about profile in production so that's what we call",
    "start": "1067370",
    "end": "1073760"
  },
  {
    "text": "continuous profiling so how would we consider using continuous profilers in",
    "start": "1073760",
    "end": "1079790"
  },
  {
    "start": "1075000",
    "end": "1118000"
  },
  {
    "text": "terms of your interaction with them I suppose you get a problem that you need to investigate narrowing it down to a",
    "start": "1079790",
    "end": "1086600"
  },
  {
    "text": "specific time period or some machines which are exhibiting this problem looking at a type of profile the mo on a",
    "start": "1086600",
    "end": "1093380"
  },
  {
    "text": "gather will see the difference between CPU time and wall clock time in a sec",
    "start": "1093380",
    "end": "1098530"
  },
  {
    "text": "looking at where the dominant consumer the resources are wearing your code base what's really using up that time and",
    "start": "1098530",
    "end": "1105890"
  },
  {
    "text": "then fixing that bottleneck and deploying and iterating so that's how this kind of stuff fits into the application developer approach like very",
    "start": "1105890",
    "end": "1114020"
  },
  {
    "text": "kind of agile or iterative approach well",
    "start": "1114020",
    "end": "1119390"
  },
  {
    "start": "1118000",
    "end": "1242000"
  },
  {
    "text": "that's it you can think about different kinds of time in terms of what your profiler can extract from your system so",
    "start": "1119390",
    "end": "1125480"
  },
  {
    "text": "CPU time a walk time I would say the two biggest forms of time that you can think",
    "start": "1125480",
    "end": "1131840"
  },
  {
    "text": "about so CPU time is time that you actually spend on CPU actually executing code",
    "start": "1131840",
    "end": "1138429"
  },
  {
    "text": "it's wall clock time it's the time between the beginning and end of the whole operation that you're trying to",
    "start": "1138429",
    "end": "1145610"
  },
  {
    "text": "measure so I like to think of this a bit like in a coffee metaphor maybe that's",
    "start": "1145610",
    "end": "1151220"
  },
  {
    "text": "because I drink too much coffee but yeah if you go to any good coffee shop or",
    "start": "1151220",
    "end": "1157580"
  },
  {
    "text": "even a Starbucks at lunchtime you'll find that there's a big queue at the beginning of that system so your CPU",
    "start": "1157580",
    "end": "1164570"
  },
  {
    "text": "time is a bit like the time it takes the actual barista to make the coffee for you and the wall clock time is a bit",
    "start": "1164570",
    "end": "1170510"
  },
  {
    "text": "like the whole process time waiting for someone to prepare that coffee waiting",
    "start": "1170510",
    "end": "1177140"
  },
  {
    "text": "to be served on the other side the whole operation time begin to end now in order",
    "start": "1177140",
    "end": "1184460"
  },
  {
    "text": "to understand problems you need to understand both the information offer by CPU time and also wall clock time so CPU",
    "start": "1184460",
    "end": "1192860"
  },
  {
    "text": "time is very good because it allows you to diagnose computational hot spots see what's actually using up the CPU see",
    "start": "1192860",
    "end": "1199250"
  },
  {
    "text": "where the actual inefficiency in your algorithm CPU time is also really good if you're",
    "start": "1199250",
    "end": "1204529"
  },
  {
    "text": "looking at a production system because one of the things that production systems do which systems in development",
    "start": "1204529",
    "end": "1211760"
  },
  {
    "text": "under a load test don't do is they spend most of their time idle and CPU time will already tell you the actual things",
    "start": "1211760",
    "end": "1219230"
  },
  {
    "text": "which are executing rather than your waiting around a lot wall clock time is",
    "start": "1219230",
    "end": "1224510"
  },
  {
    "text": "very very useful because it helps you diagnose problems that are about not",
    "start": "1224510",
    "end": "1229789"
  },
  {
    "text": "using your CPU time you spend waiting on disk i/o time you spend waiting on lock contention issues things like that so",
    "start": "1229789",
    "end": "1236929"
  },
  {
    "text": "it's really helpful in order to understand the full range of problems to look at both there's a few different",
    "start": "1236929",
    "end": "1244640"
  },
  {
    "start": "1242000",
    "end": "1279000"
  },
  {
    "text": "kind of visualizations you have a profiling data so hotspot type profiling",
    "start": "1244640",
    "end": "1251360"
  },
  {
    "text": "I would say is the simplest kind of visualization for that data so there's just a list of methods in your system",
    "start": "1251360",
    "end": "1258320"
  },
  {
    "text": "sorted by the amount of time that they're using and I think the so some",
    "start": "1258320",
    "end": "1263929"
  },
  {
    "text": "hotspots visualizations show you also for example where within a method time",
    "start": "1263929",
    "end": "1269090"
  },
  {
    "text": "is being spent like line number information or for example you can get a hotspot view with like with a bottom up",
    "start": "1269090",
    "end": "1275210"
  },
  {
    "text": "of stack traces that tells you what's the context for that another common profiler visualization is",
    "start": "1275210",
    "end": "1283460"
  },
  {
    "start": "1279000",
    "end": "1304000"
  },
  {
    "text": "a tree view based visualization so the tree view based visualization basically",
    "start": "1283460",
    "end": "1288679"
  },
  {
    "text": "arranges all the methods in your profiling data in a big tree within the tree what is the parent is calling the",
    "start": "1288679",
    "end": "1296090"
  },
  {
    "text": "child relationship so for example in Java you might see java.lang thread at the top of the tree and then child",
    "start": "1296090",
    "end": "1301730"
  },
  {
    "text": "methods coming down off that flame graphs are a newer visualization for",
    "start": "1301730",
    "end": "1308870"
  },
  {
    "start": "1304000",
    "end": "1373000"
  },
  {
    "text": "profiling data so is anyone familiar with flame graphs or use flame graphs ok cool product quite a few people that's",
    "start": "1308870",
    "end": "1314899"
  },
  {
    "text": "that's good to see yeah so you're not familiar with flame graphs where flame grass work is each",
    "start": "1314899",
    "end": "1320630"
  },
  {
    "text": "box within the flame graph represents a method and you can see flame graphs either the more flame your way going up",
    "start": "1320630",
    "end": "1327110"
  },
  {
    "text": "this is top-down approach of flame graph which some people call icicles",
    "start": "1327110",
    "end": "1333460"
  },
  {
    "text": "so in a top-down view the methods which are calling their children are placed in",
    "start": "1333460",
    "end": "1339040"
  },
  {
    "text": "boxes above and then boxes that go down are the children and then the width of",
    "start": "1339040",
    "end": "1344350"
  },
  {
    "text": "the box indicates the total time within that method so if you have a method that's wide and then has a very narrow",
    "start": "1344350",
    "end": "1350770"
  },
  {
    "text": "child that can often indicate a lot of self time within that method and it",
    "start": "1350770",
    "end": "1356919"
  },
  {
    "text": "shows you still what the the width the box indicates how much that method and it's children by using that's what I",
    "start": "1356919",
    "end": "1362440"
  },
  {
    "text": "mean by total time okay so we talked about production profiling what",
    "start": "1362440",
    "end": "1368169"
  },
  {
    "text": "information we can get out of profiles but how do they work under the hood all",
    "start": "1368169",
    "end": "1374320"
  },
  {
    "start": "1373000",
    "end": "1483000"
  },
  {
    "text": "right so we're gonna cover some of the we're gonna come and basically how profiling works in Java and we'll start",
    "start": "1374320",
    "end": "1381790"
  },
  {
    "text": "with the earliest type of profiler and we'll go through some of the reasons why maybe people were resistant to putting profilers into production and then we'll",
    "start": "1381790",
    "end": "1389169"
  },
  {
    "text": "see why that's become less of an issue with the modern techniques for creating a production safe profilers so the",
    "start": "1389169",
    "end": "1396790"
  },
  {
    "text": "earliest type of profiler is what's got an instrumenting profiler now intereting profilers add",
    "start": "1396790",
    "end": "1402120"
  },
  {
    "text": "instrumentation to the code that's being tested in order to measure the consumption of whatever resource of",
    "start": "1402120",
    "end": "1408490"
  },
  {
    "text": "interest were interested so if we were interested in say walk lock time we",
    "start": "1408490",
    "end": "1416049"
  },
  {
    "text": "could add instrumentation that would measure the time at the start and at the end of a method so without instructions",
    "start": "1416049",
    "end": "1422260"
  },
  {
    "text": "there and then using that when the program runs we can actually get information for how long it took to",
    "start": "1422260",
    "end": "1427299"
  },
  {
    "text": "execute the individual methods now the problem of the instrumenting profiler is that in adding instructions to the to",
    "start": "1427299",
    "end": "1435010"
  },
  {
    "text": "the actual program for testing it modifies the behavior of that program and it modifies the behavior in a way that's not uniform across all programs",
    "start": "1435010",
    "end": "1442390"
  },
  {
    "text": "so let's take the example that we're just talking about about a way of instrumenting method entry and exit if",
    "start": "1442390",
    "end": "1449110"
  },
  {
    "text": "you imagine a a lovely well refactored code base full of shorts of short methods and then imagine a horrendous",
    "start": "1449110",
    "end": "1456900"
  },
  {
    "text": "code base that basically has only a half-dozen methods at like tens of thousands of lines long clearly the",
    "start": "1456900",
    "end": "1462640"
  },
  {
    "text": "impact of instrumentation is going to be different between those two codebases that the size of your methods",
    "start": "1462640",
    "end": "1468930"
  },
  {
    "text": "dictates how much of overheads and invitations have had so the the overhead varies by the type of program we're",
    "start": "1468930",
    "end": "1475270"
  },
  {
    "text": "actually testing which means the results you get actually very inaccurate and add to that is actually very slow so can we",
    "start": "1475270",
    "end": "1481960"
  },
  {
    "text": "do any better well instead of instead of",
    "start": "1481960",
    "end": "1487200"
  },
  {
    "start": "1483000",
    "end": "1572000"
  },
  {
    "text": "instrumenting the program under test what we can do is we can do statistical or sampling profiling our sampling",
    "start": "1487200",
    "end": "1494020"
  },
  {
    "text": "profiling works by taking the program under test stopping it periodically and then measuring the consumption of",
    "start": "1494020",
    "end": "1501250"
  },
  {
    "text": "whatever resource were interested in so if we were interested in war clock time we could take a program we could stop it",
    "start": "1501250",
    "end": "1507400"
  },
  {
    "text": "every say hundred milliseconds and we could say what are you doing and then we can record that sample and then over",
    "start": "1507400",
    "end": "1512770"
  },
  {
    "text": "time we can aggravate all those samples together and we can build up a statistical picture of the performance of the program so here we have a diagram",
    "start": "1512770",
    "end": "1522280"
  },
  {
    "text": "which shows how we would go about profiling this particular program here so this is web server thread run it",
    "start": "1522280",
    "end": "1529030"
  },
  {
    "text": "cause controller do some things controller which cause repo dot read person which then constructs a new",
    "start": "1529030",
    "end": "1534790"
  },
  {
    "text": "person and the green line is the point where we basically interrupt the program and we grab a sample so the first sample",
    "start": "1534790",
    "end": "1540370"
  },
  {
    "text": "we grab would be web server thread run and then the next one we'd grab is in the new person constructor then we can",
    "start": "1540370",
    "end": "1547120"
  },
  {
    "text": "aggregate all this together we can produce say a flame graph or a tree of your hotspot whatever kind of profiling report you'd like that's all nice in",
    "start": "1547120",
    "end": "1554770"
  },
  {
    "text": "theory but there's a problem in Java there is a way of getting the the state",
    "start": "1554770",
    "end": "1562030"
  },
  {
    "text": "of the threats in the in java application threads and that's a call",
    "start": "1562030",
    "end": "1567100"
  },
  {
    "text": "call get all stack traces before we discuss why general stack traces is like problematic we need to take a little",
    "start": "1567100",
    "end": "1573670"
  },
  {
    "start": "1572000",
    "end": "1658000"
  },
  {
    "text": "detour via safe points how many people are aware of safe points what they are",
    "start": "1573670",
    "end": "1579540"
  },
  {
    "text": "okay just to show of hands okay so safe points are a mechanism by which the JVM",
    "start": "1579540",
    "end": "1586000"
  },
  {
    "text": "can bring java application threads to a halt normally do some kind of work right",
    "start": "1586000",
    "end": "1591520"
  },
  {
    "text": "some kind of work that would be difficult to do or problematic to do while the application was still running",
    "start": "1591520",
    "end": "1596950"
  },
  {
    "text": "so things with bias locks and GC operations and safe",
    "start": "1596950",
    "end": "1602480"
  },
  {
    "text": "points are as the name says they're safe points to do this work and the way safe points are implemented and the",
    "start": "1602480",
    "end": "1609110"
  },
  {
    "text": "interpreter there's there are safe points after every instruction with the JIT hotspot safe point will call safe",
    "start": "1609110",
    "end": "1618110"
  },
  {
    "text": "point polls are added to compiled code so what is a pole the pole is simply a read from a known",
    "start": "1618110",
    "end": "1625130"
  },
  {
    "text": "memory location and these instructions are added at the beginning and at the end of compiled methods and also inside",
    "start": "1625130",
    "end": "1631850"
  },
  {
    "text": "certain types of loops and all that happens is these these simple tests they read from a known memory location and",
    "start": "1631850",
    "end": "1638510"
  },
  {
    "text": "then when the JVM wants to bring the application to a halt it can unwrap or it can protect that memory location and",
    "start": "1638510",
    "end": "1644630"
  },
  {
    "text": "all these threads trigger a segmentation fault and the segmentation fault handler just kind of stops them and gets on with",
    "start": "1644630",
    "end": "1650690"
  },
  {
    "text": "whatever else needs to be done so that's how safe points work now the problem",
    "start": "1650690",
    "end": "1656750"
  },
  {
    "text": "with get all stack traces which is the JVM TIR JVM method for getting the stack",
    "start": "1656750",
    "end": "1663679"
  },
  {
    "start": "1658000",
    "end": "1728000"
  },
  {
    "text": "traces of the threads in the system is that it requires a safe point it requires being at a safe point to get",
    "start": "1663679",
    "end": "1669830"
  },
  {
    "text": "that information that's the point where it can safely say what the actual threads are doing so we said at the",
    "start": "1669830",
    "end": "1675650"
  },
  {
    "text": "beginning and at the end of a method and insight types of loops so before we had",
    "start": "1675650",
    "end": "1681290"
  },
  {
    "text": "our idealized sampling now we have our sampling using the naive method which",
    "start": "1681290",
    "end": "1687200"
  },
  {
    "text": "requires being at a safe point and you can see now that instead of actually sampling that so the Green Arrow's which",
    "start": "1687200",
    "end": "1695870"
  },
  {
    "text": "should have been our samples actually what we're seeing you've seen these red points those are",
    "start": "1695870",
    "end": "1701150"
  },
  {
    "text": "the actual samples we'd end up taking because that's the nearest safe point right so you can see that actually using",
    "start": "1701150",
    "end": "1707809"
  },
  {
    "text": "the naive implementation you actually end up with bias samples you end up",
    "start": "1707809",
    "end": "1713299"
  },
  {
    "text": "seeing actually the safe points that are nearest to your actual whatever you're",
    "start": "1713299",
    "end": "1719120"
  },
  {
    "text": "trying to measure and that's problematic because it means the results you're getting a not right and then there's us",
    "start": "1719120",
    "end": "1725150"
  },
  {
    "text": "there's a second problem that makes us even worse so one of the one of the",
    "start": "1725150",
    "end": "1731179"
  },
  {
    "start": "1728000",
    "end": "1840000"
  },
  {
    "text": "optimizations that  does that's actually very effective is that it it does inlining very",
    "start": "1731179",
    "end": "1736910"
  },
  {
    "text": "aggressive in lining so when it actually compiles code if you've got a method and it calls another small method and it",
    "start": "1736910",
    "end": "1743300"
  },
  {
    "text": "passed a certain tests instead of that being actually done as a method call the",
    "start": "1743300",
    "end": "1748790"
  },
  {
    "text": "contents of the method being called are actually inlined into the caller and in doing that you can you can optimize",
    "start": "1748790",
    "end": "1754970"
  },
  {
    "text": "certain things away one of which is the safe point but other things like having to park having to store arguments and",
    "start": "1754970",
    "end": "1761360"
  },
  {
    "text": "register isn't such like but there's a big performance win from doing it especially some like Java where say for example you might have lots of getters",
    "start": "1761360",
    "end": "1767390"
  },
  {
    "text": "and setters and such like which do well from being in line now in lining remove",
    "start": "1767390",
    "end": "1772580"
  },
  {
    "text": "safe points and this complicates our problem even more so if we if we look again now we've lost the safe points",
    "start": "1772580",
    "end": "1779000"
  },
  {
    "text": "actually in these purple methods which have been inlined into their caller so",
    "start": "1779000",
    "end": "1784610"
  },
  {
    "text": "now actually we're seeing an even more distorted picture we're not even just seeing the method necessary that was actually causing the problem we",
    "start": "1784610",
    "end": "1791480"
  },
  {
    "text": "potentially have attributed that to a caller or a parent and that's that's problematic and another thing that can",
    "start": "1791480",
    "end": "1799760"
  },
  {
    "text": "also cause this kind of problem where you don't have safe points with a regularity that you would expect is",
    "start": "1799760",
    "end": "1806870"
  },
  {
    "text": "loops regular loops have safe point polls within their loop header and when",
    "start": "1806870",
    "end": "1813800"
  },
  {
    "text": "you have a counted loop so something looks like for int I equals 0 I less than n where n some compile time known",
    "start": "1813800",
    "end": "1821060"
  },
  {
    "text": "constant I plus plus then you have the sake point poll on that loop removed as",
    "start": "1821060",
    "end": "1828440"
  },
  {
    "text": "an optimization worth compiler and this can result in longer periods of time growing past without a safe point poll",
    "start": "1828440",
    "end": "1834500"
  },
  {
    "text": "and again causing a bias between some threads and other threads the other",
    "start": "1834500",
    "end": "1840590"
  },
  {
    "start": "1840000",
    "end": "1943000"
  },
  {
    "text": "problem we've got is that not only are the results that we're getting biased but in getting that that information",
    "start": "1840590",
    "end": "1848660"
  },
  {
    "text": "making that call we are triggering a safe point now as we said safe points bring application threads to a halt and",
    "start": "1848660",
    "end": "1855410"
  },
  {
    "text": "they're at the beginning and they're in certain types of loops and at the end of methods and as Richard pointed out",
    "start": "1855410",
    "end": "1860960"
  },
  {
    "text": "sometimes you might actually go for quite a while in very nice well optimized code you might you go for",
    "start": "1860960",
    "end": "1866300"
  },
  {
    "text": "amount of time without seeing a safe point now the problem with that is that if you have so this is a diagram that",
    "start": "1866300",
    "end": "1872570"
  },
  {
    "text": "represents the system you've got four threads in there we've triggered a safe point the first thread hits a safe point",
    "start": "1872570",
    "end": "1878870"
  },
  {
    "text": "very quickly as the second thread and the third thread joins them a little while afterwards but the fourth thread",
    "start": "1878870",
    "end": "1883970"
  },
  {
    "text": "actually it goes for quite a while before hitting a safe point when it finally does at a safe point then it to",
    "start": "1883970",
    "end": "1889130"
  },
  {
    "text": "his part and the VM can get on with this whatever operation it wants to now that time there between the first one the",
    "start": "1889130",
    "end": "1894980"
  },
  {
    "text": "last one that's wasted time in the system all this area that these threads are not running is is extra latency",
    "start": "1894980",
    "end": "1900530"
  },
  {
    "text": "that's in your system actually wasted time so by and why why we going through this well it means that that actually",
    "start": "1900530",
    "end": "1906830"
  },
  {
    "text": "limits the rate even if you even if you are happy with the biasing in the naive",
    "start": "1906830",
    "end": "1912050"
  },
  {
    "text": "method of actually getting profiling information out of the JVM that doing it",
    "start": "1912050",
    "end": "1918830"
  },
  {
    "text": "at the the fact that you have to park these application threads limits the",
    "start": "1918830",
    "end": "1924020"
  },
  {
    "text": "frequency of which you could do it so the data you're getting is biased and actually the frequency with which you can do it is relatively low without",
    "start": "1924020",
    "end": "1930200"
  },
  {
    "text": "impact and the performance of the application and that's why you can't take a lot of the desktop profilers expect to hook them up to production and",
    "start": "1930200",
    "end": "1936470"
  },
  {
    "text": "see that they actually give you they don't actually ruin productions performance so what can we do about it",
    "start": "1936470",
    "end": "1943870"
  },
  {
    "start": "1943000",
    "end": "1965000"
  },
  {
    "text": "so we've said we've said why get all stacktrace is expensive to do frequently it's inaccurate also Tony gives us wall",
    "start": "1943870",
    "end": "1950840"
  },
  {
    "text": "clock time it's very hard to get CPU time out of that what do we do about that well as we said with something",
    "start": "1950840",
    "end": "1957260"
  },
  {
    "text": "profiling we need to two things we need to interrupt the application and then we need to sample the resource of interest",
    "start": "1957260",
    "end": "1962960"
  },
  {
    "text": "and turns out there's another way you can do this we can rely on interrupting",
    "start": "1962960",
    "end": "1969770"
  },
  {
    "start": "1965000",
    "end": "2091000"
  },
  {
    "text": "the application we can rely on what are called operating system signals how many people are aware of operating system signals okay you smell hands as well so",
    "start": "1969770",
    "end": "1977930"
  },
  {
    "text": "signals are a way of the opera system asynchronously delivering a message to a process so if you've ever kind of killed",
    "start": "1977930",
    "end": "1984650"
  },
  {
    "text": "a process you're sending a signal to a processes sake terrible secret one of",
    "start": "1984650",
    "end": "1990350"
  },
  {
    "text": "them now so you can use OS signals to deliver a message to a process and the kernel will",
    "start": "1990350",
    "end": "1998270"
  },
  {
    "text": "actually make sure that message is - one of the threads in that process it's a very lightweight method it's used",
    "start": "1998270",
    "end": "2004300"
  },
  {
    "text": "it's used a lot it has some particular quirky kind of performance",
    "start": "2004300",
    "end": "2009520"
  },
  {
    "text": "characteristics in terms of you have to be very careful because a signal can be",
    "start": "2009520",
    "end": "2014590"
  },
  {
    "text": "delivered to a to a process to a thread at any point you have to be very very careful what you do inside the code that",
    "start": "2014590",
    "end": "2021130"
  },
  {
    "text": "actually handles that signal because that signal handler which is triggered when the thread receives a signal that",
    "start": "2021130",
    "end": "2026440"
  },
  {
    "text": "could be called inside a memory allocation you could be called inside holding up mutex you could be in any",
    "start": "2026440",
    "end": "2032440"
  },
  {
    "text": "kind of state you can't really make money you can't really reason much about where you are so you have to be very",
    "start": "2032440",
    "end": "2037660"
  },
  {
    "text": "careful about what you do inside of that Sigma hat but within those constraints it's possible to actually sample",
    "start": "2037660",
    "end": "2043920"
  },
  {
    "text": "resources of interests that are actually useful and one one of those is made possible by a call inside the JVM that's",
    "start": "2043920",
    "end": "2051010"
  },
  {
    "text": "actually not an official one but it's it's async get call trace what that does is actually say I'd like the current",
    "start": "2051010",
    "end": "2058810"
  },
  {
    "text": "call stack for the thread that I'm on right and it's designed to run inside of",
    "start": "2058810",
    "end": "2064179"
  },
  {
    "text": "signal handlers that's what the async means it means it is safe to be called inside of a signal handler it's not",
    "start": "2064179",
    "end": "2070120"
  },
  {
    "text": "reallocating memory it's not going to be holding any locks or anything that might deadlock the application so we can",
    "start": "2070120",
    "end": "2075398"
  },
  {
    "text": "actually we can actually grab the current state there's an we can grab the the stack and then we can also if we're",
    "start": "2075399",
    "end": "2081878"
  },
  {
    "text": "careful we can reach inside the JVM and do other things at that point in time but we have to be very careful what we",
    "start": "2081879",
    "end": "2086980"
  },
  {
    "text": "do because we can't rely on the state being consistent but with those two we",
    "start": "2086980",
    "end": "2092888"
  },
  {
    "start": "2091000",
    "end": "2128000"
  },
  {
    "text": "can actually we can actually sample from a java application without a safe point",
    "start": "2092889",
    "end": "2098860"
  },
  {
    "text": "bias and we can do it at reasonable sampling rates with very very low",
    "start": "2098860",
    "end": "2105010"
  },
  {
    "text": "overhead we're not when it's when a signal is live it to a thread only that thread has run the signal handler the rest of system carries on running",
    "start": "2105010",
    "end": "2111040"
  },
  {
    "text": "there's no safe point there's no waiting around it's not an approach used by any of the existing desktop kind of",
    "start": "2111040",
    "end": "2117640"
  },
  {
    "text": "profilers but there are actually and we'll come on to further slides and",
    "start": "2117640",
    "end": "2123250"
  },
  {
    "text": "there's some good open source profilers that do actually do that so we have a",
    "start": "2123250",
    "end": "2129100"
  },
  {
    "start": "2128000",
    "end": "2160000"
  },
  {
    "text": "way of profiling a very low overhead in a way that's it's usable in a production environment",
    "start": "2129100",
    "end": "2134980"
  },
  {
    "text": "by choosing us are something right we could basically make up overhead as",
    "start": "2134980",
    "end": "2141250"
  },
  {
    "text": "little as we like so why don't people actually do that well our experience over the last few years has been that",
    "start": "2141250",
    "end": "2149079"
  },
  {
    "text": "people have put off by practical issues as much as they are technical ones so",
    "start": "2149079",
    "end": "2154359"
  },
  {
    "text": "what are the practical issues around using some of these advanced profilers in a production environment well the",
    "start": "2154359",
    "end": "2161589"
  },
  {
    "start": "2160000",
    "end": "2235000"
  },
  {
    "text": "first thing is the general require access to production you haven't to go to your ops people and say hi I'd like you to add this this agent here to our",
    "start": "2161589",
    "end": "2168420"
  },
  {
    "text": "Java flags so you've actually got to have access to production well you've got to get somebody to do something into",
    "start": "2168420",
    "end": "2174609"
  },
  {
    "text": "production and in many organizations that doesn't happen the developers don't",
    "start": "2174609",
    "end": "2179799"
  },
  {
    "text": "have access to a production and also even if you do have access to production the the downsides of actually messing",
    "start": "2179799",
    "end": "2185380"
  },
  {
    "text": "with a production environment normally end up being pretty catastrophic for you so people tend to shy away from doing",
    "start": "2185380",
    "end": "2191230"
  },
  {
    "text": "that in some organizations there might even be legal barriers Chinese rules between people who can write software",
    "start": "2191230",
    "end": "2196480"
  },
  {
    "text": "that runs their in operations people as well sure and then the process also involves manual work so if you're doing",
    "start": "2196480",
    "end": "2202329"
  },
  {
    "text": "ad hoc production profiling you're saying I've got a problem I want to hook up a profiler get some information",
    "start": "2202329",
    "end": "2208079"
  },
  {
    "text": "analyze it that normally actually requires running that on the server collecting the information copying it",
    "start": "2208079",
    "end": "2213549"
  },
  {
    "text": "locally run your analysis then actually making your fix and then repeating the whole process right so there's a lot of",
    "start": "2213549",
    "end": "2219039"
  },
  {
    "text": "manual work involved and the other problem is is that the actual profilers that can be done can do this in",
    "start": "2219039",
    "end": "2224740"
  },
  {
    "text": "production tend to be the open tend to be open source without commercial support and that's that from any",
    "start": "2224740",
    "end": "2230200"
  },
  {
    "text": "organization that can also be a problem running that in a production environment so how could we work around this well I",
    "start": "2230200",
    "end": "2238150"
  },
  {
    "start": "2235000",
    "end": "2258000"
  },
  {
    "text": "got us thinking as in what if we instead of just profiled in response to a",
    "start": "2238150",
    "end": "2243309"
  },
  {
    "text": "problem if the overhead is low enough why don't we just profile all the time right it removes some of the problems",
    "start": "2243309",
    "end": "2250809"
  },
  {
    "text": "that we have we don't have to have access to production each time we want to do an ad hoc profiling session because we can just do it all the time",
    "start": "2250809",
    "end": "2258359"
  },
  {
    "start": "2258000",
    "end": "2308000"
  },
  {
    "text": "and also if we were profiling all the time does it actually open up any new capabilities for us well it does for one",
    "start": "2258359",
    "end": "2265690"
  },
  {
    "text": "if we're profiling all the time if your CPUs decide to pay at three",
    "start": "2265690",
    "end": "2271120"
  },
  {
    "text": "o'clock in the morning and the next day are doing a post-mortem you can go back and say well we have a historical profiling data what happened what was",
    "start": "2271120",
    "end": "2277720"
  },
  {
    "text": "actually running at that point in time and if you're only doing ad hoc profiling you can't do that the other",
    "start": "2277720",
    "end": "2283150"
  },
  {
    "text": "problem of doing ad hoc profiling in response to a problem is that you get this profiling information but how do",
    "start": "2283150",
    "end": "2288670"
  },
  {
    "text": "you know what normal looks like because you're by definition looking an abnormal system with your historical data you can",
    "start": "2288670",
    "end": "2295330"
  },
  {
    "text": "go back and look at what normal look like and compare the two so opens up some new capabilities you",
    "start": "2295330",
    "end": "2301330"
  },
  {
    "text": "could say highway new version of application performs poorly how does that compare to our profiling information from the previous version",
    "start": "2301330",
    "end": "2307000"
  },
  {
    "text": "and then also lets you start putting your samples in context we talked about version but you could start attaching",
    "start": "2307000",
    "end": "2313600"
  },
  {
    "start": "2308000",
    "end": "2332000"
  },
  {
    "text": "environmental parameters I've got Amazon AWS c3s how do they",
    "start": "2313600",
    "end": "2318970"
  },
  {
    "text": "compare to the see force I'm running this version the JVM how does it compare this other version of JVM so we can",
    "start": "2318970",
    "end": "2325510"
  },
  {
    "text": "start attach that information to our profiling data and that's something that you can't get with just ad-hoc profiling",
    "start": "2325510",
    "end": "2332580"
  },
  {
    "start": "2332000",
    "end": "2368000"
  },
  {
    "text": "so how can we actually implement continuous profiling well there's a there's a great paper from Google called",
    "start": "2332580",
    "end": "2339610"
  },
  {
    "text": "Google web profiling continuous profiling infrastructure for data centers it's up there on their website there's a PDF up there and it basically",
    "start": "2339610",
    "end": "2346570"
  },
  {
    "text": "details how their system works they have collectors that take this data from their production environments they have",
    "start": "2346570",
    "end": "2352450"
  },
  {
    "text": "another system a collection the binary isn't doing symbolization what have you that's then stored in databases which",
    "start": "2352450",
    "end": "2357520"
  },
  {
    "text": "their users can then run queries against you can actually generate these profiling reports the kind of reports",
    "start": "2357520",
    "end": "2362620"
  },
  {
    "text": "that we looked at earlier and they have a system for doing this and it's been running in google for years but what if",
    "start": "2362620",
    "end": "2368950"
  },
  {
    "start": "2368000",
    "end": "2414000"
  },
  {
    "text": "you wanted to build it yourself well we talked about some open source profilers these these are open source profilers",
    "start": "2368950",
    "end": "2376270"
  },
  {
    "text": "that use the method we looked at before that has no overhead or something very",
    "start": "2376270",
    "end": "2381610"
  },
  {
    "text": "similar as a sink profiler as honest profile which was written by Richard here there's also a Java's flight",
    "start": "2381610",
    "end": "2387370"
  },
  {
    "text": "recorder as well and these are safe for hooking up to production but it's worth pointing out they are they are profilers",
    "start": "2387370",
    "end": "2393700"
  },
  {
    "text": "that that hook up Russian for ad hoc profiling you still need then some method to actually collect and store",
    "start": "2393700",
    "end": "2399880"
  },
  {
    "text": "that information there reported in some way and I know in some way relations I've worked in the past",
    "start": "2399880",
    "end": "2405359"
  },
  {
    "text": "that we've we've come up with ways of doing that storing that information and then be able to get it if we need it for",
    "start": "2405359",
    "end": "2410970"
  },
  {
    "text": "a analysis alternatively that's what we do an op seein we have a continuous",
    "start": "2410970",
    "end": "2417300"
  },
  {
    "start": "2414000",
    "end": "2442000"
  },
  {
    "text": "profiling platform which basically implements this so you hook up the profiling agent to your JVMs",
    "start": "2417300",
    "end": "2424190"
  },
  {
    "text": "it runs in JVMs they send their profiling data over to indexing and",
    "start": "2424190",
    "end": "2430170"
  },
  {
    "text": "aggregation service which basically aggregates all that and then makes it available for reporting via a",
    "start": "2430170",
    "end": "2436079"
  },
  {
    "text": "browser-based interface and basically implements that they can it's the same current system we saw the last few slides so in summary it's possible to",
    "start": "2436079",
    "end": "2445140"
  },
  {
    "start": "2442000",
    "end": "2465000"
  },
  {
    "text": "profile production would look it with low overhead you can do it in production overhead to overcome some the practical",
    "start": "2445140",
    "end": "2451619"
  },
  {
    "text": "issues around doing it you should profile all the time and it makes life a lot easier and by profiling all the time",
    "start": "2451619",
    "end": "2458880"
  },
  {
    "text": "and not only solves your practical issues from before but actually opens up a whole bunch of new capabilities as well cool so in conclusion the talk we",
    "start": "2458880",
    "end": "2468150"
  },
  {
    "start": "2465000",
    "end": "2516000"
  },
  {
    "text": "talked about why performance mattered why we needed tooling to understand both the known unknowns but especially the",
    "start": "2468150",
    "end": "2474690"
  },
  {
    "text": "unknown unknowns with regards to our our system things that we couldn't necessarily think of in advance we",
    "start": "2474690",
    "end": "2480690"
  },
  {
    "text": "talked about how developments and production environments often differ so much that you can have very different root causes to performance problems that",
    "start": "2480690",
    "end": "2487290"
  },
  {
    "text": "you can have very different low tests and you can find it hard to replicate those problems we talked about how",
    "start": "2487290",
    "end": "2492300"
  },
  {
    "text": "things like metrics are incredibly useful for gathering from production system understanding of a problem but",
    "start": "2492300",
    "end": "2498210"
  },
  {
    "text": "aren't necessarily going to give you the root cause analysis aren't and give you the vector into your system",
    "start": "2498210",
    "end": "2504560"
  },
  {
    "text": "instrumentation was an approach that could give you that I have very high overhead if you wanted to do it at a",
    "start": "2504560",
    "end": "2509760"
  },
  {
    "text": "fine grain level and at a coarse grain level had less useful information and continuous profiling could provide a lot",
    "start": "2509760",
    "end": "2516300"
  },
  {
    "start": "2516000",
    "end": "2521000"
  },
  {
    "text": "of insight so we think we need a bit of an attitude shift on profiling and monitoring we want profiling to be done",
    "start": "2516300",
    "end": "2523920"
  },
  {
    "start": "2521000",
    "end": "2550000"
  },
  {
    "text": "in a systematic way not an ad hoc way so that means keeping it done continuously",
    "start": "2523920",
    "end": "2529530"
  },
  {
    "text": "all the time on your system and not having to do things like hook up tooling when there's a problem or a",
    "start": "2529530",
    "end": "2537410"
  },
  {
    "text": "one-off event that you need to resolve being proactive about these things",
    "start": "2537410",
    "end": "2542960"
  },
  {
    "text": "rather than reactive having things in place to understand and resolve these",
    "start": "2542960",
    "end": "2548750"
  },
  {
    "text": "issues in other words please do production profiling all the time that's",
    "start": "2548750",
    "end": "2554630"
  },
  {
    "start": "2550000",
    "end": "2574000"
  },
  {
    "text": "what we'd love you to do if you use our tool them that's great but even if you don't that's also great just please do",
    "start": "2554630",
    "end": "2560089"
  },
  {
    "text": "it it's really useful and I'm sure you will find it it's very helpful to your your systems as well thank you very much",
    "start": "2560089",
    "end": "2568630"
  },
  {
    "text": "[Applause]",
    "start": "2568630",
    "end": "2575559"
  },
  {
    "start": "2574000",
    "end": "2992000"
  },
  {
    "text": "so I don't know if anyone has any questions we have five minutes or so for",
    "start": "2575559",
    "end": "2581450"
  },
  {
    "text": "questions right the front row",
    "start": "2581450",
    "end": "2587740"
  },
  {
    "text": "if understood correctly you provide a solution where we can inject some agent",
    "start": "2588819",
    "end": "2595880"
  },
  {
    "text": "into our application and you will collect this matrix and we can access them we some web-based interface but the",
    "start": "2595880",
    "end": "2605569"
  },
  {
    "text": "question is possible to install some house in implementation of this so can",
    "start": "2605569",
    "end": "2613670"
  },
  {
    "text": "it be their own version yes yes so it doesn't have to be because you know",
    "start": "2613670",
    "end": "2620089"
  },
  {
    "text": "sometimes it's just from perspective folks yes yeah it doesn't have to isn't that the aggregation can happen and",
    "start": "2620089",
    "end": "2626180"
  },
  {
    "text": "storage happen inside your premises or in the cloud okay",
    "start": "2626180",
    "end": "2632200"
  },
  {
    "text": "were there any other questions",
    "start": "2632680",
    "end": "2636338"
  },
  {
    "text": "and have you ever considered using the output of your profiling in any form of",
    "start": "2639660",
    "end": "2645610"
  },
  {
    "text": "automated testing to try and highlight code change problems and within",
    "start": "2645610",
    "end": "2651400"
  },
  {
    "text": "algorithms so we were having an interesting discussion early it's a rigor question we were having an",
    "start": "2651400",
    "end": "2657640"
  },
  {
    "text": "interesting discussion earlier today about could we use the information to",
    "start": "2657640",
    "end": "2662920"
  },
  {
    "text": "say identify where in very large code bases hey you're actually using this particular method and that's only",
    "start": "2662920",
    "end": "2669640"
  },
  {
    "text": "available in a really old version of the appliques library you're using and it see if you use this newer method it",
    "start": "2669640",
    "end": "2675310"
  },
  {
    "text": "would be a lot quicker so yeah there are there are possibilities for that there's possibilities for say security where you",
    "start": "2675310",
    "end": "2681880"
  },
  {
    "text": "know you're actually using this method and and actually that's deprecated because it's got a vulnerability issue in it kind of thing so yes you could use",
    "start": "2681880",
    "end": "2689530"
  },
  {
    "text": "the data you get out of a profiling system for that kind of stuff but I think it was also maybe I interpreted a",
    "start": "2689530",
    "end": "2695710"
  },
  {
    "text": "different way which was could you have like JIT like J unit tests you mean can you profile J unit tests is that the",
    "start": "2695710",
    "end": "2701470"
  },
  {
    "text": "question you're asking no okay great cool any other questions",
    "start": "2701470",
    "end": "2707290"
  },
  {
    "text": "oh there's fear the back never grabs all over there",
    "start": "2707290",
    "end": "2711510"
  },
  {
    "text": "and his ops is obscene just gathering statistics and presenting them or does it include its own profiler it built on",
    "start": "2715340",
    "end": "2724220"
  },
  {
    "text": "somebody else's profile it includes its include its own profile so it's it's we",
    "start": "2724220",
    "end": "2729800"
  },
  {
    "text": "basically did a lot of development work on top of Richards honest profiler which has a kind of long history of kind of",
    "start": "2729800",
    "end": "2735680"
  },
  {
    "text": "being used in production so yeah",
    "start": "2735680",
    "end": "2740589"
  },
  {
    "text": "thanks Great Auk have you any experience of aggregating these kind of profiling",
    "start": "2743960",
    "end": "2751100"
  },
  {
    "text": "in distributed computing like spark jobs Hadoop and stuff like that so we do yeah",
    "start": "2751100",
    "end": "2759380"
  },
  {
    "text": "so we do in terms of aggregating jobs that are similar a lot of them are a lot",
    "start": "2759380",
    "end": "2766070"
  },
  {
    "text": "a lot of what we've seen are more people like web request response oriented workloads rather than something like",
    "start": "2766070",
    "end": "2772010"
  },
  {
    "text": "spark but in general when you're looking at things like profile and data and where the bottlenecks are often you can",
    "start": "2772010",
    "end": "2779900"
  },
  {
    "text": "quite nicely aggregate over different machines things like knowing what an",
    "start": "2779900",
    "end": "2785120"
  },
  {
    "text": "individual threads ID that had a specific problem or something like that don't come up so well but if you're",
    "start": "2785120",
    "end": "2792080"
  },
  {
    "text": "looking for bigger code efficiency problems it works yeah when we've looked at spark things like spark before if",
    "start": "2792080",
    "end": "2797930"
  },
  {
    "text": "your problem is a CPU problem so you're converting stuff inside a particular",
    "start": "2797930",
    "end": "2803180"
  },
  {
    "text": "part your job then it's pretty obvious if your problem is deep within spark of",
    "start": "2803180",
    "end": "2808250"
  },
  {
    "text": "how it's transferring the data it's a bit more problematic because of the async nature of the whole thing yeah so",
    "start": "2808250",
    "end": "2814280"
  },
  {
    "text": "breed depends your bottleneck any other questions run down right down the front Oh",
    "start": "2814280",
    "end": "2821890"
  },
  {
    "text": "do you risk with in front and continuous profiling shifting something to the",
    "start": "2825710",
    "end": "2831500"
  },
  {
    "text": "right so why me but I is we often want things to be caught we want to shift",
    "start": "2831500",
    "end": "2836900"
  },
  {
    "text": "things to the left want people to consider profiling and performance early and testing do you risk people going",
    "start": "2836900",
    "end": "2843470"
  },
  {
    "text": "I've got continuous profiling production I'm I'm not gonna bother I'm just gonna wait and see how it works in production and the people come become complacent",
    "start": "2843470",
    "end": "2851119"
  },
  {
    "text": "with continuous profiling that's kind of it that's a really good question I don't really have any like nice head",
    "start": "2851119",
    "end": "2858559"
  },
  {
    "text": "to head that were blind scientific survey on that kind of thing but my general experience on these things is that people basically do that anyway and",
    "start": "2858559",
    "end": "2865700"
  },
  {
    "text": "then when things hit production they're blind and even when they do have performance testing ahead of time that",
    "start": "2865700",
    "end": "2872960"
  },
  {
    "text": "can hit help them identify and solve certain problems but there's often things that they miss anyway so I think",
    "start": "2872960",
    "end": "2880490"
  },
  {
    "text": "there's a risk of complacency with either approach and that's probably more like cultural team honesty reflection",
    "start": "2880490",
    "end": "2890150"
  },
  {
    "text": "type value type issue rather than the technology solution tool type issue in",
    "start": "2890150",
    "end": "2895940"
  },
  {
    "text": "my opinion at least the question is about you know profiler do provide some",
    "start": "2895940",
    "end": "2901849"
  },
  {
    "text": "information some detailed information about rest which are not currently doing some Java stuff I mean native libraries",
    "start": "2901849",
    "end": "2908990"
  },
  {
    "text": "scan on calls and so on as it's done in icing profile so I said so that's walk",
    "start": "2908990",
    "end": "2915290"
  },
  {
    "text": "lock in terms of when threads are actually actively doing work they just belonged on something yeah but you want",
    "start": "2915290",
    "end": "2921950"
  },
  {
    "text": "to know well because if you will just look at stack trace in Java you will see that it does something so so you think",
    "start": "2921950",
    "end": "2931309"
  },
  {
    "text": "the actual lock itself that's blocked out or I mean some more deep information what's where this is spending time",
    "start": "2931309",
    "end": "2940190"
  },
  {
    "text": "inside can afford oh inside the kernel right no so you as you say things like",
    "start": "2940190",
    "end": "2946339"
  },
  {
    "text": "async profiling you can go into the kernel further we don't with our product",
    "start": "2946339",
    "end": "2952339"
  },
  {
    "text": "mainly because actually for one there are security issues around once you",
    "start": "2952339",
    "end": "2957740"
  },
  {
    "text": "getting into that and it starts to get bit more problematic saying to people hey it's on your production service on",
    "start": "2957740",
    "end": "2962960"
  },
  {
    "text": "by the way needs to be route kind of thing or it needs to have certainly elevated privileges but the other other",
    "start": "2962960",
    "end": "2968480"
  },
  {
    "text": "issues performance as well so we want to make sure that you stay if you can what we found it we if you can get yourself",
    "start": "2968480",
    "end": "2974960"
  },
  {
    "text": "within a small enough envelope that basically there isn't a criticism of a she's going to slow down production then it's it's a much easier process of",
    "start": "2974960",
    "end": "2981470"
  },
  {
    "text": "getting us into production in Austria question I think we're pretty much out of time but thank you very much it's",
    "start": "2981470",
    "end": "2987560"
  },
  {
    "text": "been a pleasure to speak to you [Applause]",
    "start": "2987560",
    "end": "2993469"
  }
]
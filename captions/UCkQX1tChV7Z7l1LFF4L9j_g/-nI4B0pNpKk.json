[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "okay so I'll give you somewhat of an idea of what we're going to cover first",
    "start": "4000",
    "end": "11530"
  },
  {
    "text": "just to set some kind of what we're trying to do why we're",
    "start": "11530",
    "end": "17220"
  },
  {
    "text": "trying to do it some tools to help you in your quest for performance my own",
    "start": "17220",
    "end": "25680"
  },
  {
    "text": "experience working on open l depth problems that we ran into or discovered along the way and the solutions we use",
    "start": "25680",
    "end": "32400"
  },
  {
    "text": "to fix them and one of the things you find as you improve a codebase is once",
    "start": "32400",
    "end": "40080"
  },
  {
    "text": "you fix one problem several more become apparent so you see",
    "start": "40080",
    "end": "45300"
  },
  {
    "text": "more problems you need more tools and while you're refining and improving",
    "start": "45300",
    "end": "52699"
  },
  {
    "text": "sometimes you'll also find that incremental changes aren't good enough to get you where you want to be and so",
    "start": "52699",
    "end": "59460"
  },
  {
    "text": "sometimes you need more drastic measures [Applause]",
    "start": "59460",
    "end": "65600"
  },
  {
    "text": "so you know this is experience working",
    "start": "66229",
    "end": "71310"
  },
  {
    "text": "on the open l that project for the class lasts almost twenty years and from the",
    "start": "71310",
    "end": "78539"
  },
  {
    "text": "very first version of the code to the version that we're running today it has accelerated by over a factor of 100 now",
    "start": "78539",
    "end": "86909"
  },
  {
    "text": "you know we're not quite programming right on the metal I'm not using assembly language anywhere this is all",
    "start": "86909",
    "end": "94280"
  },
  {
    "text": "portable C language stuff so this chart",
    "start": "94280",
    "end": "101880"
  },
  {
    "start": "99000",
    "end": "99000"
  },
  {
    "text": "shows you where search performance was on the very left at the very first version of open LDAP and on the very",
    "start": "101880",
    "end": "108179"
  },
  {
    "text": "right the current version and so as I",
    "start": "108179",
    "end": "113640"
  },
  {
    "text": "mentioned up here from 60 milliseconds for a single operation 2.6 milliseconds",
    "start": "113640",
    "end": "120380"
  },
  {
    "text": "0.6 milliseconds also happens to be the ping time on that network so we're",
    "start": "120380",
    "end": "127770"
  },
  {
    "text": "running at network speed",
    "start": "127770",
    "end": "130819"
  },
  {
    "text": "it's interesting if you look at what you know other famous computer scientists",
    "start": "134320",
    "end": "139910"
  },
  {
    "text": "have written about performance and their perspectives over time so you know",
    "start": "139910",
    "end": "146270"
  },
  {
    "text": "Donald Knuth wrote this in 1967 which happens to be the year I was born and",
    "start": "146270",
    "end": "152480"
  },
  {
    "text": "the idea then was you know you needed to understand something about the machines",
    "start": "152480",
    "end": "157550"
  },
  {
    "text": "you're working with right and then a few",
    "start": "157550",
    "end": "163400"
  },
  {
    "text": "years later it's almost like he changed his perspective he said we're focusing",
    "start": "163400",
    "end": "168530"
  },
  {
    "text": "too much on optimization and maybe we should back off of that a little bit now",
    "start": "168530",
    "end": "174760"
  },
  {
    "text": "this quote has probably circulated through all of your consciousnesses you",
    "start": "174760",
    "end": "179870"
  },
  {
    "text": "know optimization is the root of all evil well that's the misquote that gets handed out a lot of times and you have",
    "start": "179870",
    "end": "187520"
  },
  {
    "text": "to take it really in its full context of premature optimization is root of all evil and take those numbers with a huge",
    "start": "187520",
    "end": "198230"
  },
  {
    "text": "grain of salt right you know his perspective there is 97% of",
    "start": "198230",
    "end": "203690"
  },
  {
    "text": "the time you don't need to worry about optimization and I think in the decades",
    "start": "203690",
    "end": "210080"
  },
  {
    "text": "from 1974 into the 1990s everybody took",
    "start": "210080",
    "end": "215420"
  },
  {
    "text": "that a little too much to heart because you shouldn't be able to get a 100 to",
    "start": "215420",
    "end": "221600"
  },
  {
    "text": "one performance boost on a well-written piece of code you know you shouldn't be",
    "start": "221600",
    "end": "226910"
  },
  {
    "text": "able to do that but I believe people have tried a little too far away from",
    "start": "226910",
    "end": "234019"
  },
  {
    "text": "thinking about optimization and so we need to kind of bring this back into",
    "start": "234019",
    "end": "239060"
  },
  {
    "text": "focus and think about you know what's good what makes a code run efficiently",
    "start": "239060",
    "end": "245030"
  },
  {
    "text": "on a machine and be a little more aware",
    "start": "245030",
    "end": "249910"
  },
  {
    "start": "250000",
    "end": "250000"
  },
  {
    "text": "of course you know the the choices you make in writing your code can differ",
    "start": "251990",
    "end": "258170"
  },
  {
    "text": "quite a but quite a bit depending on if you're starting a new project from scratch or if you're refactoring",
    "start": "258170",
    "end": "264980"
  },
  {
    "text": "existing code how many of you have been faced with optimizing an existing",
    "start": "264980",
    "end": "271040"
  },
  {
    "text": "project yeah pretty much everybody all right and how many of you have started a brand new project from scratch",
    "start": "271040",
    "end": "278150"
  },
  {
    "text": "and thought about optimization in your",
    "start": "278150",
    "end": "283460"
  },
  {
    "text": "design process all right very healthy so",
    "start": "283460",
    "end": "290660"
  },
  {
    "text": "one of the things about the phrase premature optimization is kind of tricky",
    "start": "290660",
    "end": "296270"
  },
  {
    "text": "too there there's context to that all right some things are so well established in the literature already",
    "start": "296270",
    "end": "303230"
  },
  {
    "text": "not to think about them at the beginning of the project still isn't premature right if you're writing a project today",
    "start": "303230",
    "end": "309320"
  },
  {
    "text": "you don't use bubble sort you know that's that that's just an easy one okay",
    "start": "309320",
    "end": "315770"
  },
  {
    "text": "so there are some things that you can think about even at the very beginning of a project that would not be premature",
    "start": "315770",
    "end": "325300"
  },
  {
    "text": "of course you know as you go along you know if you're doing very well eventually you hit a limit and the you",
    "start": "328690",
    "end": "337940"
  },
  {
    "text": "get to diminishing returns and every decision you make where you gain something you also lose something else",
    "start": "337940",
    "end": "344570"
  },
  {
    "text": "the trade-offs start to add up but I think if you look across the industry most of the code is nowhere near that",
    "start": "344570",
    "end": "350750"
  },
  {
    "text": "limit most of code that you see you know can easily slash a huge amount of what it's doing without affecting any losses",
    "start": "350750",
    "end": "359650"
  },
  {
    "text": "also sometimes it's really clear that the solution in front of you is the best",
    "start": "359650",
    "end": "367220"
  },
  {
    "text": "it's gonna get and there is no need to do any more work on it for example if",
    "start": "367220",
    "end": "372530"
  },
  {
    "text": "you just want to add up the values of all these numbers in an array the",
    "start": "372530",
    "end": "379300"
  },
  {
    "text": "simplest and most straightforward solution it's probably the best one yeah you got three of eight elements okay",
    "start": "379300",
    "end": "386350"
  },
  {
    "text": "let's just do a simple for loop through it and you're done that's great you",
    "start": "386350",
    "end": "392020"
  },
  {
    "text": "don't need fancy algorithms you don't need divide-and-conquer or anything else like that in fact if you try to do a",
    "start": "392020",
    "end": "398919"
  },
  {
    "text": "fancy algorithm here all you're doing is making your code more complicated and while the basic number of operations",
    "start": "398919",
    "end": "408039"
  },
  {
    "text": "involved here is the same you've added a whole bunch of extraneous overhead in",
    "start": "408039",
    "end": "414340"
  },
  {
    "text": "your more complex algorithm so one of the guiding principles should be",
    "start": "414340",
    "end": "420810"
  },
  {
    "text": "simplicity is better okay so a couple of",
    "start": "420810",
    "end": "432159"
  },
  {
    "text": "the speakers mentioned this earlier today your code has to be correct first",
    "start": "432159",
    "end": "437199"
  },
  {
    "text": "always right and when you have correct code it's fairly easy to make it faster",
    "start": "437199",
    "end": "444159"
  },
  {
    "text": "and it's a lot faster than the opposite where you have fast broken code and trying to fix it and make it do the",
    "start": "444159",
    "end": "450789"
  },
  {
    "text": "right thing so yeah you always have to get correct code first optimization is",
    "start": "450789",
    "end": "456310"
  },
  {
    "text": "kind of a secondary consideration but the other thing you really do want to",
    "start": "456310",
    "end": "461440"
  },
  {
    "text": "try as as much as you can to get everything right the first time around because you know if if you look at this",
    "start": "461440",
    "end": "468550"
  },
  {
    "text": "and say well I don't have time to think about this that hard I can't get it right the first time now if you don't",
    "start": "468550",
    "end": "473650"
  },
  {
    "text": "have time when are you gonna have time to come back and fix it you know it's not going to happen and then a final",
    "start": "473650",
    "end": "481060"
  },
  {
    "text": "consideration which I always inject in here computers are supposed to be fast you know these things processes running",
    "start": "481060",
    "end": "487300"
  },
  {
    "text": "three gigahertz or whatever so if your code is correct even if it gives you the right answer if it gives it to you too",
    "start": "487300",
    "end": "493780"
  },
  {
    "text": "late that code is broken at least in my perspective",
    "start": "493780",
    "end": "498870"
  },
  {
    "text": "okay so how do you even know that you have a problem I think if you've been",
    "start": "501370",
    "end": "506830"
  },
  {
    "text": "following the performance track today you know this answer is fairly obvious now you got to profile your code you you",
    "start": "506830",
    "end": "512409"
  },
  {
    "text": "have to measure what it's doing to see if there's a problem and where the problems are now there are a bunch of",
    "start": "512409",
    "end": "521169"
  },
  {
    "text": "different approaches to your profiling and they each have different strengths and weaknesses today we can use Linux",
    "start": "521169",
    "end": "531070"
  },
  {
    "text": "perf which is a pretty wonderful tool right it can tell you all kinds of things very easily very non invasively",
    "start": "531070",
    "end": "537610"
  },
  {
    "text": "all right it used to be called a profile that's when I was using it first it uses",
    "start": "537610",
    "end": "544600"
  },
  {
    "text": "two - statistical sampling like what's mentioned in previous talk Richards talk",
    "start": "544600",
    "end": "550740"
  },
  {
    "text": "and because it uses a very low overhead sampling and you can run it on a live",
    "start": "550740",
    "end": "557320"
  },
  {
    "text": "system fairly little impact but one of the things that I notice about it is it",
    "start": "557320",
    "end": "563950"
  },
  {
    "text": "can still miss details all right and the call graphs that you get out of it can",
    "start": "563950",
    "end": "569920"
  },
  {
    "text": "be missing entire hierarchies of the call tree so you can't solely rely on",
    "start": "569920",
    "end": "576400"
  },
  {
    "text": "that right other tools that I've also used one of these is called function",
    "start": "576400",
    "end": "582400"
  },
  {
    "text": "check and it uses the GCC compilers instrument functions feature all right",
    "start": "582400",
    "end": "588760"
  },
  {
    "text": "so if you compile a project with the flag F instrument functions then GCC",
    "start": "588760",
    "end": "595029"
  },
  {
    "text": "will emit custom profiling calls at the",
    "start": "595029",
    "end": "600220"
  },
  {
    "text": "beginning and exit of every function right so then if you provide your own shared library that fills in the stubs",
    "start": "600220",
    "end": "607390"
  },
  {
    "text": "that GCC expects you can do whatever you want in the prologues and epilogues of",
    "start": "607390",
    "end": "612520"
  },
  {
    "text": "every function in your code so function check takes advantage of this and lets",
    "start": "612520",
    "end": "618070"
  },
  {
    "text": "you measure the time and also as a side benefit it tracks memory allocations now",
    "start": "618070",
    "end": "625740"
  },
  {
    "text": "it's not the easiest thing to use this because you need a specially compiled binary and also anything",
    "start": "625740",
    "end": "634620"
  },
  {
    "text": "that you link to that hasn't also been compiled with instrumentation isn't going to give you any information all",
    "start": "634620",
    "end": "642090"
  },
  {
    "text": "right so you get a fairly coarse profile it only tells you how much time was",
    "start": "642090",
    "end": "649050"
  },
  {
    "text": "spent in a function but it doesn't tell you where in that function okay but the advantage of it is the call graphs are",
    "start": "649050",
    "end": "655950"
  },
  {
    "text": "always accurate right there's no there's no elements missing in the call tree and",
    "start": "655950",
    "end": "662570"
  },
  {
    "text": "then the other option that there is is one of the sub tools of mal grind called",
    "start": "662570",
    "end": "668610"
  },
  {
    "text": "call grind actually and this is really pretty complete it can give you",
    "start": "668610",
    "end": "676490"
  },
  {
    "text": "instruction level profiling all right complete call graphs the only problem is",
    "start": "676490",
    "end": "681750"
  },
  {
    "text": "you know it's running it through an emulated machine so it's at least a hundred times slower than running in",
    "start": "681750",
    "end": "686790"
  },
  {
    "text": "real time how many of you have used Val grind all right yeah if you haven't used",
    "start": "686790",
    "end": "692460"
  },
  {
    "text": "you should definitely check it out because it's got a lot of cool features again the only big problem with it is it",
    "start": "692460",
    "end": "698640"
  },
  {
    "text": "runs so much more slowly so you don't always get an accurate view of the",
    "start": "698640",
    "end": "704850"
  },
  {
    "text": "overall overall allocation of time and one of the other tricks I've learned with this is if you're using a sampling",
    "start": "704850",
    "end": "711960"
  },
  {
    "text": "profiler like perf run it on the slowest CPU you can because it makes all of the",
    "start": "711960",
    "end": "718530"
  },
  {
    "text": "time samples a lot easier to capture you know I used to run it on a Pentium M laptop that it would set down to the",
    "start": "718530",
    "end": "725100"
  },
  {
    "text": "battery safe mode so it would run at 600 megahertz and I would get the best profiles that way",
    "start": "725100",
    "end": "731540"
  },
  {
    "start": "733000",
    "end": "733000"
  },
  {
    "text": "so purpose so easier to use this should always be your first go-to tool right",
    "start": "734930",
    "end": "741449"
  },
  {
    "text": "and the results can be fairly obviously",
    "start": "741449",
    "end": "746639"
  },
  {
    "text": "you know in the very first version of open LDAP which was inherited for years University of Michigan we found 95% of",
    "start": "746639",
    "end": "756930"
  },
  {
    "text": "our execution time was in the C library and basically only 5% of the time was",
    "start": "756930",
    "end": "762740"
  },
  {
    "text": "executing LDAP protocol all right so this this code was pretty horrible to",
    "start": "762740",
    "end": "768899"
  },
  {
    "text": "begin with and I would say it was representative of code written in the",
    "start": "768899",
    "end": "774839"
  },
  {
    "text": "mid-1990s you know this was people who did not think about memory allocation",
    "start": "774839",
    "end": "780120"
  },
  {
    "text": "because they weren't taught to think about it I think they were taught not to think about it all right",
    "start": "780120",
    "end": "785209"
  },
  {
    "text": "and they used the standard C string library because that's what every C",
    "start": "785209",
    "end": "791790"
  },
  {
    "text": "programmer does even though it's really not that great so first of all you never",
    "start": "791790",
    "end": "798899"
  },
  {
    "text": "actually know how bad things are until you look alright so you always have to",
    "start": "798899",
    "end": "804000"
  },
  {
    "text": "take at least that first look of course",
    "start": "804000",
    "end": "811439"
  },
  {
    "text": "you can miss some details with perf with the sampler so it's it's always a good",
    "start": "811439",
    "end": "817290"
  },
  {
    "text": "idea to use more than one tool",
    "start": "817290",
    "end": "821240"
  },
  {
    "text": "how many of you have seen you know dr why don't repeat yourself okay normally",
    "start": "825459",
    "end": "832189"
  },
  {
    "text": "it's applied to writing a source code right you don't want to copy and paste functions or whatever you try and",
    "start": "832189",
    "end": "839750"
  },
  {
    "text": "minimize repetition in your source base I would say also don't repeat yourself",
    "start": "839750",
    "end": "846410"
  },
  {
    "text": "at execution time all right so you don't want to compute the same information",
    "start": "846410",
    "end": "853550"
  },
  {
    "text": "over and over again and throw it away each time if you're going to use it a lot all right and and on the opposite",
    "start": "853550",
    "end": "862300"
  },
  {
    "text": "you don't want to cache information if you don't use it that often or if it's",
    "start": "862300",
    "end": "868129"
  },
  {
    "text": "very easy to retrieve it again so you",
    "start": "868129",
    "end": "875089"
  },
  {
    "start": "873000",
    "end": "873000"
  },
  {
    "text": "know looking into our problem you know 40 40 % of execution time in the string",
    "start": "875089",
    "end": "881120"
  },
  {
    "text": "library we find that 25% of our time is just on sterlin counting the lengths of",
    "start": "881120",
    "end": "887180"
  },
  {
    "text": "strings length of strings that we received over the network which were",
    "start": "887180",
    "end": "892550"
  },
  {
    "text": "transmitted in a binary protocol that always sends us the length okay so this",
    "start": "892550",
    "end": "901430"
  },
  {
    "text": "was completely unnecessary work and we",
    "start": "901430",
    "end": "906559"
  },
  {
    "text": "found a way to fix this which is well already the the code base uses",
    "start": "906559",
    "end": "911809"
  },
  {
    "text": "structured strings which is a string pointer with an explicit length variable",
    "start": "911809",
    "end": "917180"
  },
  {
    "text": "right this is already in the code base why aren't they taking an advantage of it well now we are all right so after",
    "start": "917180",
    "end": "924559"
  },
  {
    "text": "addressing this we could get string length completely removed from the",
    "start": "924559",
    "end": "929809"
  },
  {
    "text": "runtime profile so right away we gained 25 percent runtime performance",
    "start": "929809",
    "end": "938319"
  },
  {
    "text": "the next thing it's doing is dissecting these strings that are coming in tearing",
    "start": "940499",
    "end": "946869"
  },
  {
    "text": "them apart and then putting them back together again using a string cap which is you know what see string library does",
    "start": "946869",
    "end": "954100"
  },
  {
    "text": "it gives you how many you have seen Emile the painter problem okay so the",
    "start": "954100",
    "end": "962949"
  },
  {
    "text": "idea here is you've got a meal he his",
    "start": "962949",
    "end": "968980"
  },
  {
    "text": "job is to paint the lines down a roadway okay and every day",
    "start": "968980",
    "end": "975699"
  },
  {
    "text": "he paints some lines and the following day he gets less done and every day he",
    "start": "975699",
    "end": "983050"
  },
  {
    "text": "gets less and less work done and someone asks well what's going on with me why are you slowing down so much he says well every day I have to walk back",
    "start": "983050",
    "end": "990639"
  },
  {
    "text": "further to the Paint Bucket all right so the hill the painter problem with stir",
    "start": "990639",
    "end": "997689"
  },
  {
    "text": "cat is it always starts at the beginning of the string and so as you keep concatenating strings to it it gets",
    "start": "997689",
    "end": "1003300"
  },
  {
    "text": "longer and longer and longer and slower and slower and slower right so stir cat",
    "start": "1003300",
    "end": "1009720"
  },
  {
    "text": "is a horrible function we you know we",
    "start": "1009720",
    "end": "1014910"
  },
  {
    "text": "fixed this an open L that just by you know instead of having a copy function",
    "start": "1014910",
    "end": "1019920"
  },
  {
    "text": "that always returns the pointer of the destination we always return a pointer",
    "start": "1019920",
    "end": "1025260"
  },
  {
    "text": "to the tail of the copy so since you have the tail of the copy you can just keep adding to it immediately from where",
    "start": "1025260",
    "end": "1032308"
  },
  {
    "text": "you are so now you know this was 2001 so",
    "start": "1032309",
    "end": "1039750"
  },
  {
    "text": "this was a custom function of ours now you can find exactly this feature in a modern sea library it's called",
    "start": "1039750",
    "end": "1045750"
  },
  {
    "text": "STP copy but here's something that still",
    "start": "1045750",
    "end": "1051659"
  },
  {
    "text": "isn't in modern sea libraries that really needs to be all right this is a",
    "start": "1051659",
    "end": "1058440"
  },
  {
    "text": "string copy function that will never overflow its buffer right and it's a lot",
    "start": "1058440",
    "end": "1064620"
  },
  {
    "text": "easier to use than stirol' copy or stir copy yes or whatever because you don't have to recompute the remaining space on",
    "start": "1064620",
    "end": "1071279"
  },
  {
    "text": "the buffer whenever you use it all you do as you say here's the end of the buffer I don't care how much I put into",
    "start": "1071279",
    "end": "1077590"
  },
  {
    "text": "it I don't have to compute any lengths at all just keep stuffing into it until you can't stuff any else in and it also",
    "start": "1077590",
    "end": "1085030"
  },
  {
    "text": "has the same feature where it returns pointer to the end of what it copied so",
    "start": "1085030",
    "end": "1090640"
  },
  {
    "text": "again you can just easily concatenate stuff together very quickly and",
    "start": "1090640",
    "end": "1095970"
  },
  {
    "text": "completely safely the standard C string",
    "start": "1095970",
    "end": "1106780"
  },
  {
    "text": "library is is kind of horrible you know so you there are so it's so easy to do a",
    "start": "1106780",
    "end": "1113260"
  },
  {
    "text": "better job of what it does and when you have the opportunity to fix problems",
    "start": "1113260",
    "end": "1119530"
  },
  {
    "text": "like this you should do it every chance you get okay so if you've got an",
    "start": "1119530",
    "end": "1128590"
  },
  {
    "text": "application that does a lot of string handling and you've been using the",
    "start": "1128590",
    "end": "1133860"
  },
  {
    "text": "standard C string library you can probably do a much better job and if you",
    "start": "1133860",
    "end": "1140110"
  },
  {
    "text": "need to punch strings around you probably need to use something like the",
    "start": "1140110",
    "end": "1145390"
  },
  {
    "text": "struct or Val where you keep an explicit length it will save you a lot of work",
    "start": "1145390",
    "end": "1152100"
  },
  {
    "start": "1153000",
    "end": "1153000"
  },
  {
    "text": "okay so Malik was 50 some percent of our profile is again it was horrible and",
    "start": "1155260",
    "end": "1161830"
  },
  {
    "text": "these days we have super high performance Malik libraries that we can",
    "start": "1161830",
    "end": "1166880"
  },
  {
    "text": "use you know JD Malik or Google's TC Malik this should not be your first",
    "start": "1166880",
    "end": "1171890"
  },
  {
    "text": "reaction you know you should not just say oh let me put a better Malik library in there if you don't fix anything else",
    "start": "1171890",
    "end": "1179060"
  },
  {
    "text": "the most you're going to get out of them is maybe 10% all right so you really",
    "start": "1179060",
    "end": "1184280"
  },
  {
    "text": "want to examine where your memory allocations are occurring and see if they really are doing something that's",
    "start": "1184280",
    "end": "1191720"
  },
  {
    "text": "necessary so the most common occurrence",
    "start": "1191720",
    "end": "1197180"
  },
  {
    "text": "that we found was in functions that return an object to the caller or the",
    "start": "1197180",
    "end": "1203000"
  },
  {
    "text": "object is filled with certain bits of data all right and I think this is a",
    "start": "1203000",
    "end": "1209050"
  },
  {
    "text": "horrible pattern but it's one that C++ uses all the time that you get constructors that say here here's an",
    "start": "1209050",
    "end": "1215750"
  },
  {
    "text": "object for you and and it's so easy to fix this you just say hey pass in the",
    "start": "1215750",
    "end": "1223160"
  },
  {
    "text": "container most the time the container can be a local variable in the caller can be on the stack and so you go from",
    "start": "1223160",
    "end": "1230560"
  },
  {
    "text": "stupid Malik's that are going to be immediately freed as soon as you've consumed the data to know Malik's all",
    "start": "1230560",
    "end": "1237950"
  },
  {
    "text": "right so C++ is horrible don't do things",
    "start": "1237950",
    "end": "1245990"
  },
  {
    "text": "the way C++ does them right so these",
    "start": "1245990",
    "end": "1253160"
  },
  {
    "text": "these were very easy wins all right that again got us another 25% boost in",
    "start": "1253160",
    "end": "1258800"
  },
  {
    "text": "performance at least so the next few",
    "start": "1258800",
    "end": "1264740"
  },
  {
    "text": "bits will be a little bit more involved",
    "start": "1264740",
    "end": "1269500"
  },
  {
    "text": "another frequent issue is okay we've parsed some data we're gonna build a structure out of it and we're going to",
    "start": "1274160",
    "end": "1282260"
  },
  {
    "text": "start with an own size and just keep reality as we add elements to it and again this is horrible it's it gets",
    "start": "1282260",
    "end": "1289560"
  },
  {
    "text": "slower the more you use it so if you do things like this the the smart thing to",
    "start": "1289560",
    "end": "1296280"
  },
  {
    "text": "do is iterate through all the elements you think you're going to add in count up their sizes do a single malloc for",
    "start": "1296280",
    "end": "1303690"
  },
  {
    "text": "the right size and and then set the fields in so instead of doing a series",
    "start": "1303690",
    "end": "1312180"
  },
  {
    "text": "of malloc realloc realloc realloc you're just doing one aleck that'll save quite a bit of time and then if we're talking",
    "start": "1312180",
    "end": "1324870"
  },
  {
    "text": "about a network service that takes incoming requests over the wire parses them up does something to process them",
    "start": "1324870",
    "end": "1331230"
  },
  {
    "text": "and then spits a reply back now you know again we're talking about a binary",
    "start": "1331230",
    "end": "1337260"
  },
  {
    "text": "protocol where every message has its length already encoded in it so we know the size of what we're dealing with",
    "start": "1337260",
    "end": "1344660"
  },
  {
    "text": "we've got a buffer that's big enough to hold it and then we parse it into",
    "start": "1344660",
    "end": "1349760"
  },
  {
    "text": "individual fields the old code would malloc a new copy for every element of",
    "start": "1349760",
    "end": "1358740"
  },
  {
    "text": "the field that it was parsing out and so again this is a whole bunch of Malick's",
    "start": "1358740",
    "end": "1364770"
  },
  {
    "text": "that are happening really for no good reason right because the original network",
    "start": "1364770",
    "end": "1370620"
  },
  {
    "text": "buffer is still there right so we change this to wherever we parse a value we just set a pointer into the original",
    "start": "1370620",
    "end": "1377040"
  },
  {
    "text": "network buffer right so instead of having lots of Malick's and then copies we now have zero mend copies",
    "start": "1377040",
    "end": "1385400"
  },
  {
    "text": "this should be a simpler one if everything you're doing is you know",
    "start": "1389740",
    "end": "1395720"
  },
  {
    "text": "request based if you have individual requests that don't affect anything else",
    "start": "1395720",
    "end": "1400970"
  },
  {
    "text": "that don't leave any global state then you know it's really effective to have an arena that's associated with",
    "start": "1400970",
    "end": "1408620"
  },
  {
    "text": "individual requests and you can just allocate a whole bunch of stuff as you need to process that request but once",
    "start": "1408620",
    "end": "1414620"
  },
  {
    "text": "the request is done you can throw the entire thing away you can just reset it back to its virgin state without having",
    "start": "1414620",
    "end": "1421519"
  },
  {
    "text": "to go through the trouble of freeing one element at a time the funny thing about",
    "start": "1421519",
    "end": "1427429"
  },
  {
    "text": "this is you know this is the dynamic memory model that Pascal used back in the 1980s it's really simple and it's",
    "start": "1427429",
    "end": "1435440"
  },
  {
    "text": "really fast",
    "start": "1435440",
    "end": "1437919"
  },
  {
    "text": "some of the other more obvious techniques you know if you know you're gonna need a bunch of request structures",
    "start": "1442440",
    "end": "1448990"
  },
  {
    "text": "pre-allocate a whole bunch of them at startup time and it's also a good idea",
    "start": "1448990",
    "end": "1455080"
  },
  {
    "text": "to keep like a small number of them reserved alright so for example if your",
    "start": "1455080",
    "end": "1461470"
  },
  {
    "text": "server gets overloaded you always have a couple of requests structures available that you can use to send replies back",
    "start": "1461470",
    "end": "1469150"
  },
  {
    "text": "and say hey too busy or something so you never get an unresponsive server so with",
    "start": "1469150",
    "end": "1480220"
  },
  {
    "text": "these techniques you know mallet doesn't even show up in our runtime profiles anymore it doesn't show up at least in",
    "start": "1480220",
    "end": "1485920"
  },
  {
    "text": "the top 100 just another note if you",
    "start": "1485920",
    "end": "1494800"
  },
  {
    "text": "make some mistakes along the way it happens you might discover you've got some memory leaks in your code I",
    "start": "1494800",
    "end": "1501700"
  },
  {
    "text": "encourage you to check out this project on github which I wrote which is at",
    "start": "1501700",
    "end": "1508270"
  },
  {
    "text": "least eight times faster than the malloc tracer in TC malloc it's six times",
    "start": "1508270",
    "end": "1514000"
  },
  {
    "text": "faster than one energy Lipsy so it'll save you a lot of time it won't heavily",
    "start": "1514000",
    "end": "1519370"
  },
  {
    "text": "impact your runtime performance okay",
    "start": "1519370",
    "end": "1528990"
  },
  {
    "text": "so after you've tackled all the big hot spots on your call profile you might see",
    "start": "1529210",
    "end": "1536570"
  },
  {
    "text": "that everything's kind of flat and there's no longer any big obstacles that are apparent and if the performance is",
    "start": "1536570",
    "end": "1545059"
  },
  {
    "text": "where you want it to be then that's cool you're done if you still need more",
    "start": "1545059",
    "end": "1551440"
  },
  {
    "text": "performance out of it you might have some problems you you've got some harder thinking to do also there are a lot of",
    "start": "1551440",
    "end": "1561190"
  },
  {
    "text": "interesting overheads that won't show up in like a source level call graph",
    "start": "1561190",
    "end": "1566539"
  },
  {
    "text": "alright for example if you spawn a lot",
    "start": "1566539",
    "end": "1572659"
  },
  {
    "start": "1569000",
    "end": "1569000"
  },
  {
    "text": "of threads which are supposed to be cheap supposed to be easy to spawn them",
    "start": "1572659",
    "end": "1578899"
  },
  {
    "text": "and throw them away as much as you want you know the reality is there is a cost",
    "start": "1578899",
    "end": "1584330"
  },
  {
    "text": "to starting up a thread and shutting down a thread okay and if you're gonna do a lot of thread work over and over",
    "start": "1584330",
    "end": "1590779"
  },
  {
    "text": "again you really don't want to incur that cost repeatedly so again don't repeat yourself don't do the same",
    "start": "1590779",
    "end": "1596960"
  },
  {
    "text": "processing steps more than necessary so",
    "start": "1596960",
    "end": "1604159"
  },
  {
    "text": "I would say if you're using threads and you're just spawning them on demand you really need to switch to a thread pool",
    "start": "1604159",
    "end": "1610909"
  },
  {
    "text": "or you just keep reusing the same threads over and over again",
    "start": "1610909",
    "end": "1615789"
  },
  {
    "text": "I don't know if this is something you",
    "start": "1620120",
    "end": "1627980"
  },
  {
    "start": "1621000",
    "end": "1621000"
  },
  {
    "text": "think about very often but you know do you typically have debug or log functions scattered throughout your code",
    "start": "1627980",
    "end": "1635380"
  },
  {
    "text": "yes no all right in open LDAP you know this",
    "start": "1635380",
    "end": "1641150"
  },
  {
    "text": "is litter dollar at the code base and the basic idea is you know you say",
    "start": "1641150",
    "end": "1646220"
  },
  {
    "text": "here's a message out put it if the log level is selected to be this value all right",
    "start": "1646220",
    "end": "1651500"
  },
  {
    "text": "and so the debug function always has this check is the provided value matched",
    "start": "1651500",
    "end": "1657529"
  },
  {
    "text": "with the current system debug level and if it is then we'll do the message processing if it's not we just return",
    "start": "1657529",
    "end": "1664130"
  },
  {
    "text": "and do nothing okay it turns out if you have this scattered through your code quite a bit that just the overhead of",
    "start": "1664130",
    "end": "1671419"
  },
  {
    "text": "calling into a function and returning again immediately is a significant impact on your throughput it kills here",
    "start": "1671419",
    "end": "1678409"
  },
  {
    "text": "well on a modern CPU it kills your branch target buffer call it kills your return cache there there's a few things",
    "start": "1678409",
    "end": "1686450"
  },
  {
    "text": "that it's just no good so the simple thing to do here is you use a macro to",
    "start": "1686450",
    "end": "1691970"
  },
  {
    "text": "invoke your debug function in the macro you put the if statements that checks your debug level and then then you're",
    "start": "1691970",
    "end": "1699830"
  },
  {
    "text": "golden so you know in situations like",
    "start": "1699830",
    "end": "1705080"
  },
  {
    "text": "this it's cheaper just to do a single if than it is to do a function call to a no op function you know try to avoid that",
    "start": "1705080",
    "end": "1714429"
  },
  {
    "text": "here's another that is probably more common in languages like C++ all right",
    "start": "1717349",
    "end": "1726169"
  },
  {
    "text": "the LDAP search operation has something like 12 parameters you know base scope",
    "start": "1726889",
    "end": "1732690"
  },
  {
    "text": "filter attributes only values only and so you know we parse the singing from",
    "start": "1732690",
    "end": "1739019"
  },
  {
    "text": "the network and then we pass this from the front end into the back end and we do syntax checking in all these things",
    "start": "1739019",
    "end": "1744690"
  },
  {
    "text": "and at every function that we pass this off to we got to send all 12 parameters",
    "start": "1744690",
    "end": "1749999"
  },
  {
    "text": "across it was kind of horrible and you",
    "start": "1749999",
    "end": "1755309"
  },
  {
    "text": "know as Alan Perlis says you know having a large number of parameters to a function tends to mean you've done",
    "start": "1755309",
    "end": "1761849"
  },
  {
    "text": "something wrong but more than you know",
    "start": "1761849",
    "end": "1767789"
  },
  {
    "text": "even if you've got it correct every single time you're wasting time because",
    "start": "1767789",
    "end": "1775289"
  },
  {
    "text": "every one of those parameters has get pushed onto the stack and then they get popped off the stack by the Kali and the",
    "start": "1775289",
    "end": "1781080"
  },
  {
    "text": "Kali does what it wants to do and they call something else and has to push them back onto the stack all right it's kind",
    "start": "1781080",
    "end": "1787589"
  },
  {
    "text": "of horrible so in in our code we replaced all of that with a single",
    "start": "1787589",
    "end": "1794309"
  },
  {
    "text": "structure all right structure still has 12 fields or whatever it is right but when you're passing it around it's only costing us",
    "start": "1794309",
    "end": "1800879"
  },
  {
    "text": "one pointer in the parameter list and surprisingly you know this can be up to",
    "start": "1800879",
    "end": "1806940"
  },
  {
    "text": "8% of your execution time and this doesn't show up in a source level",
    "start": "1806940",
    "end": "1812070"
  },
  {
    "text": "profile you can't see that",
    "start": "1812070",
    "end": "1816440"
  },
  {
    "text": "it's alright if you were in nits ins talked earlier",
    "start": "1819789",
    "end": "1827040"
  },
  {
    "start": "1820000",
    "end": "1820000"
  },
  {
    "text": "today you might have caught caught as mention of false sharing you know so",
    "start": "1827040",
    "end": "1832830"
  },
  {
    "text": "basically if you have shared data that's accessed from multiple CPUs at the same",
    "start": "1832830",
    "end": "1838860"
  },
  {
    "text": "time and if the fields of your data straddle a CPU cache line then every CPU",
    "start": "1838860",
    "end": "1846300"
  },
  {
    "text": "that accesses it is causing caching a validation on every other CPU that accesses it it's kind of horrible it's",
    "start": "1846300",
    "end": "1854370"
  },
  {
    "text": "not a problem that occurs on a single processor machine but it's it's",
    "start": "1854370",
    "end": "1859710"
  },
  {
    "text": "something that you run into more and more especially these days we got sixteen thirty-two for whatever boxes so",
    "start": "1859710",
    "end": "1866120"
  },
  {
    "text": "it's something you have to be more aware of now",
    "start": "1866120",
    "end": "1871880"
  },
  {
    "text": "the advice here about ordering elements",
    "start": "1878890",
    "end": "1884870"
  },
  {
    "text": "within a structure this is actually something that I was taught in the 1980s",
    "start": "1884870",
    "end": "1889970"
  },
  {
    "text": "when I was learning Fortran right but it still applies today you don't you know",
    "start": "1889970",
    "end": "1897110"
  },
  {
    "text": "if you can avoid it you don't really want hidden padding in your structures alright and if you've got data",
    "start": "1897110",
    "end": "1906320"
  },
  {
    "text": "structures that are going to be shared between threads you do want them to be CPU cache line aligned and if you you",
    "start": "1906320",
    "end": "1915080"
  },
  {
    "text": "know if you can't just declare them that way the portable portable methods would be to use POSIX memo line or M map or V",
    "start": "1915080",
    "end": "1923960"
  },
  {
    "text": "malloc whatever whatever is available to you and if you want to see the impact of",
    "start": "1923960",
    "end": "1930800"
  },
  {
    "text": "what's going on again the Linux perf command can show this to you because it can show you a",
    "start": "1930800",
    "end": "1936440"
  },
  {
    "text": "cache hit and miss ratios and cache timing delays",
    "start": "1936440",
    "end": "1943150"
  },
  {
    "text": "another thing that tends not to show up in the source level call graph now by",
    "start": "1949700",
    "end": "1958080"
  },
  {
    "text": "default these profilers show you CPU time used all right and when you're",
    "start": "1958080",
    "end": "1963510"
  },
  {
    "text": "sitting in a lock you're using a zero CPU time so mutex is typically don't",
    "start": "1963510",
    "end": "1970050"
  },
  {
    "text": "show up in a normal call trace so there is this cool little tool called new",
    "start": "1970050",
    "end": "1976950"
  },
  {
    "text": "trace whose only job used to measure in new text times well it shows me Texas and condition variables so we found for",
    "start": "1976950",
    "end": "1986580"
  },
  {
    "text": "example in open LDAP we had high contention on a single mutex for our",
    "start": "1986580",
    "end": "1992400"
  },
  {
    "text": "thread pool work queue right kind of make senses there's only one of them the",
    "start": "1992400",
    "end": "1999390"
  },
  {
    "text": "interesting thing is ok so testing on a quad core box if we split this up into",
    "start": "1999390",
    "end": "2004820"
  },
  {
    "text": "four cues we actually get a better than 4x performance boost if it's it's",
    "start": "2004820",
    "end": "2010960"
  },
  {
    "text": "nonlinear so this is again something to",
    "start": "2010960",
    "end": "2016790"
  },
  {
    "text": "be aware of it won't show up in a normal call trace you have to go explicitly looking for it",
    "start": "2016790",
    "end": "2023830"
  },
  {
    "start": "2025000",
    "end": "2025000"
  },
  {
    "text": "okay so you discover over the course of time I mean I'm talking about a",
    "start": "2029530",
    "end": "2035200"
  },
  {
    "text": "development process where we discovered these things you know over intervals of months you eliminate one problem and",
    "start": "2035200",
    "end": "2042910"
  },
  {
    "text": "something else pops up and sometimes it's amazing to use like how did this",
    "start": "2042910",
    "end": "2048730"
  },
  {
    "text": "big problem hide from us so long but it's just a matter of changing the",
    "start": "2048730",
    "end": "2054190"
  },
  {
    "text": "dynamic of your program as you fix certain problems other timing relationships change and so certain",
    "start": "2054190",
    "end": "2060370"
  },
  {
    "text": "things that weren't a problem before become more of one the way to survive",
    "start": "2060370",
    "end": "2066970"
  },
  {
    "text": "this from a morale standpoint is to keep good notes and just to show that you",
    "start": "2066970",
    "end": "2074378"
  },
  {
    "text": "have been making progress over time and those notes have to be you know test",
    "start": "2074379",
    "end": "2079628"
  },
  {
    "text": "parameters profile results all of these things that you can use to give yourself documentation says oh yeah we changed",
    "start": "2079629",
    "end": "2087460"
  },
  {
    "text": "this function we've we've eliminated this bottleneck so this is something new",
    "start": "2087460",
    "end": "2093419"
  },
  {
    "start": "2094000",
    "end": "2094000"
  },
  {
    "text": "[Music] okay and then at the end of all of this",
    "start": "2094580",
    "end": "2100420"
  },
  {
    "text": "you know refinement iteration whatever you may still discover it's it's not",
    "start": "2100420",
    "end": "2107800"
  },
  {
    "text": "where it needs to be all right and then the only solution is to start over",
    "start": "2107800",
    "end": "2117300"
  },
  {
    "text": "how many of you have used Berkeley DB in your projects all right well what's your experience with a plot positive okay",
    "start": "2120420",
    "end": "2130540"
  },
  {
    "text": "yeah open LDAP we've used it for quite a long time and it always was a massive source of",
    "start": "2130540",
    "end": "2140470"
  },
  {
    "text": "complexity for us all right because Berkeley DB itself is too slow for the",
    "start": "2140470",
    "end": "2145570"
  },
  {
    "text": "request rates we want to process so we have our own layer of caching on top of",
    "start": "2145570",
    "end": "2151060"
  },
  {
    "text": "it all right and this turns out to be massive overhead because that means data",
    "start": "2151060",
    "end": "2158260"
  },
  {
    "text": "can appear in three places at once you know it can be in the file system cache it's almost always on the file system",
    "start": "2158260",
    "end": "2163840"
  },
  {
    "text": "cache anyway it can be in Berkeley DB zone cache and then it's in our entry",
    "start": "2163840",
    "end": "2170950"
  },
  {
    "text": "cache data cache so the techniques we",
    "start": "2170950",
    "end": "2176020"
  },
  {
    "text": "used here to make Berkeley's performance acceptable were hugely wasteful just in",
    "start": "2176020",
    "end": "2181930"
  },
  {
    "text": "terms of memory use the other thing too is you know Berkeley has its own transaction management system and it's a",
    "start": "2181930",
    "end": "2188320"
  },
  {
    "text": "locking system if you use it properly",
    "start": "2188320",
    "end": "2194010"
  },
  {
    "text": "you still get dead locks you know in all of the operations you're giving okay so even when it's being used",
    "start": "2194010",
    "end": "2200710"
  },
  {
    "text": "correctly you have to detect deadlocks and abort and back off and retry so it's",
    "start": "2200710",
    "end": "2207400"
  },
  {
    "text": "pretty poor for throughput and then the other thing is you know you have to coordinate its",
    "start": "2207400",
    "end": "2213190"
  },
  {
    "text": "locking system with the locks we had to use to protect our own cache so we're now talking about two levels of locks",
    "start": "2213190",
    "end": "2220000"
  },
  {
    "text": "and three levels of caches and it was pretty much horrible over the course of",
    "start": "2220000",
    "end": "2226240"
  },
  {
    "text": "years it was always the cause of new bug reports and so you know sometimes you",
    "start": "2226240",
    "end": "2235090"
  },
  {
    "text": "have to think and say gosh we keep on having problems with this thing is this",
    "start": "2235090",
    "end": "2241510"
  },
  {
    "text": "particular thing what we should be doing is like if Berkeley DB is this slow that",
    "start": "2241510",
    "end": "2247660"
  },
  {
    "text": "we have to build all these band-aids around it you know why are we using it",
    "start": "2247660",
    "end": "2254190"
  },
  {
    "text": "well it took us nine years to realize maybe that's not the thing to do so you",
    "start": "2256020",
    "end": "2267100"
  },
  {
    "text": "know with with Ellen DB we looked at all the things that we hated about Berkeley a lock management cash management",
    "start": "2267100",
    "end": "2273850"
  },
  {
    "text": "I always said you know get rid of all those things now in order to have the",
    "start": "2273850",
    "end": "2279520"
  },
  {
    "text": "flexibility to make such a large change as this making you know the entire local data store toss it out and put in a new",
    "start": "2279520",
    "end": "2286960"
  },
  {
    "text": "one you know we were kind of lucky that we already had a modular back-end interface",
    "start": "2286960",
    "end": "2292090"
  },
  {
    "text": "so actually plugging in new data stores isn't too traumatic for us but it could",
    "start": "2292090",
    "end": "2299860"
  },
  {
    "text": "be a much larger problem and you could get lost in the muck along the way to it",
    "start": "2299860",
    "end": "2306310"
  },
  {
    "text": "so you have to make sure that you have the original design goals well in mind and make sure that you're actually",
    "start": "2306310",
    "end": "2312160"
  },
  {
    "text": "solving them with a new solution that you bring in so it turns out you know",
    "start": "2312160",
    "end": "2320080"
  },
  {
    "text": "with LM DB since we're using MVC C we can actually do reads without any locks",
    "start": "2320080",
    "end": "2325720"
  },
  {
    "text": "at all and because we use a read-only",
    "start": "2325720",
    "end": "2331810"
  },
  {
    "text": "memory map we can actually you know return pointers to database data without",
    "start": "2331810",
    "end": "2337300"
  },
  {
    "text": "doing any mem copies or Malick's so in fact when you run open LDAP today with",
    "start": "2337300",
    "end": "2345340"
  },
  {
    "text": "back m DB and do a pure read search load on it the read threads actually do no",
    "start": "2345340",
    "end": "2353490"
  },
  {
    "text": "blocking calls at all the only system calls that they invoke are the ones to",
    "start": "2353490",
    "end": "2358750"
  },
  {
    "text": "write packets back to the client also",
    "start": "2358750",
    "end": "2365410"
  },
  {
    "text": "because of the way we implemented MVCC and the read-only memory map the database structure is actually",
    "start": "2365410",
    "end": "2371230"
  },
  {
    "text": "completely immune to system crash corruption you can check the data kick the disk drives you can pull out the",
    "start": "2371230",
    "end": "2377440"
  },
  {
    "text": "power plug whatever the database will come up instantly perfectly every",
    "start": "2377440",
    "end": "2383880"
  },
  {
    "start": "2385000",
    "end": "2385000"
  },
  {
    "text": "all right so just recap you do always",
    "start": "2387960",
    "end": "2395200"
  },
  {
    "text": "have to aim for correctness first so yeah you can tolerate slow code at the very beginning of the project but at",
    "start": "2395200",
    "end": "2404200"
  },
  {
    "text": "least in my perspective getting the right answer too late is still wrong",
    "start": "2404200",
    "end": "2409890"
  },
  {
    "text": "fixing these kind of problems is an iterative process you're always going to discover a new bottleneck after you fix",
    "start": "2410520",
    "end": "2417940"
  },
  {
    "text": "the last one there's lots of tools out there that can help you with this",
    "start": "2417940",
    "end": "2423190"
  },
  {
    "text": "process and you probably need to use several of them because the more perspective you get into the problem the",
    "start": "2423190",
    "end": "2431440"
  },
  {
    "text": "more clear the solution becomes and you know sometimes after all this iteration",
    "start": "2431440",
    "end": "2436930"
  },
  {
    "text": "you might just have to throw things out and start over the ultimate goal is to",
    "start": "2436930",
    "end": "2447550"
  },
  {
    "text": "just do what's necessary right an efficient program just does what it needs to do to get your work done",
    "start": "2447550",
    "end": "2453580"
  },
  {
    "text": "and then gets out of the way and and that's that's really what you want to do",
    "start": "2453580",
    "end": "2458940"
  },
  {
    "text": "okay [Applause]",
    "start": "2461310",
    "end": "2469050"
  }
]
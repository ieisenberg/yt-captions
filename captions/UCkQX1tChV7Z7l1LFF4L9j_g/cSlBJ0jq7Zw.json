[
  {
    "text": "hello fellow developers this is Ed ovic your chair for the upcoming infoq Dev in",
    "start": "160",
    "end": "6279"
  },
  {
    "text": "Boston if you're looking to stay ahead all the critical topics like generative AI security modern web applications and",
    "start": "6279",
    "end": "13639"
  },
  {
    "text": "more learn directly for over 20 senior software practitioners navigating this",
    "start": "13639",
    "end": "18920"
  },
  {
    "text": "challenge as they share their experience and practical sites you can apply immediately plus there's a plenty of",
    "start": "18920",
    "end": "25359"
  },
  {
    "text": "time for you to connect with peers and speakers at your social events if q that",
    "start": "25359",
    "end": "30400"
  },
  {
    "text": "sum is brought to you by the team behind EQ and the Keyon International software developer conference find out more at De",
    "start": "30400",
    "end": "38760"
  },
  {
    "text": "summit. EOC qq.com I'm looking forward to connected to you in Boston this June",
    "start": "38760",
    "end": "44440"
  },
  {
    "text": "see you",
    "start": "44440",
    "end": "46878"
  },
  {
    "text": "there hi everyone my name is reini picala I am the lead editor for AIML and",
    "start": "49760",
    "end": "56239"
  },
  {
    "text": "data engineering community at infoq website and a podcast host in today's",
    "start": "56239",
    "end": "61960"
  },
  {
    "text": "episode I will be speaking with miam arik co-founder and the CEO of Titan ml",
    "start": "61960",
    "end": "67759"
  },
  {
    "text": "the company behind generative AI solutions for regulated Industries we will discuss the current state of large",
    "start": "67759",
    "end": "74240"
  },
  {
    "text": "language models or llms and how to deploy and support those llms in",
    "start": "74240",
    "end": "79400"
  },
  {
    "text": "production which is very important in successfully adopting generative AI or gen AI Technologies in any organization",
    "start": "79400",
    "end": "87000"
  },
  {
    "text": "hi miam thank you for joining me today first can you introduce yourself and tell our listeners about your career",
    "start": "87000",
    "end": "93840"
  },
  {
    "text": "your focus areas and what you've been working on recently of course thank you",
    "start": "93840",
    "end": "98920"
  },
  {
    "text": "so much for having me so I'm Mary marrick I'm the co-founder and CEO of Titan ML and what we do is we build",
    "start": "98920",
    "end": "106159"
  },
  {
    "text": "infrastructure to help regulated Industries deploy generative AI within their own environments so instead of",
    "start": "106159",
    "end": "111719"
  },
  {
    "text": "sending their data to C GPT or anthropic we help them deploy within their own on Prem or VPC infrastructure in terms of",
    "start": "111719",
    "end": "119000"
  },
  {
    "text": "my background so I actually quite a varied background I've always been very",
    "start": "119000",
    "end": "124159"
  },
  {
    "text": "techy I guess my degree was in theoretical physics and philosophy and that's actually where I met my",
    "start": "124159",
    "end": "129879"
  },
  {
    "text": "co-founders all three of us are are physicists I then went off into the",
    "start": "129879",
    "end": "135640"
  },
  {
    "text": "world of Enterprise and my co-founder stayed in the world of research but we stayed very very close friends and we",
    "start": "135640",
    "end": "142120"
  },
  {
    "text": "started the business a couple years ago because their research was all about",
    "start": "142120",
    "end": "147560"
  },
  {
    "text": "efficient inference optimization and and impression and I was sitting in in the",
    "start": "147560",
    "end": "153160"
  },
  {
    "text": "Enterprise world and what we could see is that there was this really big gap between what was possible in the research literature and what Enterprises",
    "start": "153160",
    "end": "159200"
  },
  {
    "text": "were actually able to achieve and we saw that there was going to be a very big infrastructural gap when AI really came",
    "start": "159200",
    "end": "166159"
  },
  {
    "text": "around and that's what we looked at solving thank you it seems like generative Ai and llm Technologies are",
    "start": "166159",
    "end": "173040"
  },
  {
    "text": "in full swing lately recently at Google IO conference Google announced several",
    "start": "173040",
    "end": "178440"
  },
  {
    "text": "new developments including Google Gemini updates and what they call generative AI",
    "start": "178440",
    "end": "185159"
  },
  {
    "text": "in search which is probably going to change the suchar functionality on Google and uh open AI released GPT 40",
    "start": "185159",
    "end": "194360"
  },
  {
    "text": "the Omni model that can work with audio vision and text in real time and also",
    "start": "194360",
    "end": "200680"
  },
  {
    "text": "recently Lama 3 was released so looks like you know there's a lot of innovation happening and it seems like",
    "start": "200680",
    "end": "207319"
  },
  {
    "text": "this space is accelerating faster and faster than ever where do you see gen Ai and llms are at this point which is only",
    "start": "207319",
    "end": "214760"
  },
  {
    "text": "few years since Char GPD came came out and how do you see it innovating in rest",
    "start": "214760",
    "end": "220680"
  },
  {
    "text": "of this year and next year it's been a pretty crazy couple weeks so for context",
    "start": "220680",
    "end": "226120"
  },
  {
    "text": "for The Listener we're talking I think two days after the Google IO conference and three days after the open AI",
    "start": "226120",
    "end": "233120"
  },
  {
    "text": "conference and then I think about three weeks from from llama 3 we got started in the industry before",
    "start": "233120",
    "end": "240360"
  },
  {
    "text": "it was called llms we got started back when it was called NLP and it's been the",
    "start": "240360",
    "end": "245720"
  },
  {
    "text": "most phenomenal astronomical growth and technological advancement since we first started the company so back then we were",
    "start": "245720",
    "end": "253599"
  },
  {
    "text": "working with gpt2 models right and we thought they were really impressive because they could write a poem that",
    "start": "253599",
    "end": "259000"
  },
  {
    "text": "sounded like Shakespeare and now we're at a stage where I can have a language",
    "start": "259000",
    "end": "264560"
  },
  {
    "text": "model that can constantly see my screen and give me suggestions about how I'm working and give me real-time audio",
    "start": "264560",
    "end": "270479"
  },
  {
    "text": "feedback like that is just completely night and day so the rate of progression",
    "start": "270479",
    "end": "276720"
  },
  {
    "text": "is just enormous and it really feels like we've cracked some kind of",
    "start": "276720",
    "end": "281759"
  },
  {
    "text": "understanding where all of the players in the field are building these same kind of capability models but I think",
    "start": "281759",
    "end": "288120"
  },
  {
    "text": "it's important to not get too hung up on",
    "start": "288120",
    "end": "293160"
  },
  {
    "text": "how much the models are improving by every release it's been said a couple times",
    "start": "293160",
    "end": "298840"
  },
  {
    "text": "and releasing Matt Turk said it in a tweet that he wrote which is that even if we stop llm",
    "start": "298840",
    "end": "305400"
  },
  {
    "text": "Innovation we probably have around a decade of Enterprise Innovation that we can unlock with the technologies that we",
    "start": "305400",
    "end": "311479"
  },
  {
    "text": "have so we're already at the stage of enormous potential even if we stand",
    "start": "311479",
    "end": "317600"
  },
  {
    "text": "still and we're not standing still so it's incredibly exciting time to be in the space yeah we're not standing still",
    "start": "317600",
    "end": "323800"
  },
  {
    "text": "we're not even moving linearly you know it's almost like a innovating in a logarithm skill right exactly something",
    "start": "323800",
    "end": "330120"
  },
  {
    "text": "that I'm really excited that I think will come up in the next year because I think you you asked me about in previous",
    "start": "330120",
    "end": "335240"
  },
  {
    "text": "question which is the first thing is that I think we're going to see",
    "start": "335240",
    "end": "340680"
  },
  {
    "text": "increasingly impressive capabilities from surprisingly small models so I can give an example of this the Llama 38",
    "start": "340680",
    "end": "348639"
  },
  {
    "text": "billion was as performant as gbt 3.5 and if we all think back to when GPT 3.5 was",
    "start": "348639",
    "end": "355680"
  },
  {
    "text": "released we thought it was some kind of magic right and now we're able to get that through actually a relatively small",
    "start": "355680",
    "end": "361199"
  },
  {
    "text": "8 billion parameter model and I think we're going to increasingly see these smaller size models providing better and",
    "start": "361199",
    "end": "367880"
  },
  {
    "text": "better outputs and I think that's just because the quality and and number of tokens that we're training them on so",
    "start": "367880",
    "end": "373000"
  },
  {
    "text": "that's on the one end which will really help the Enterprise scale specifically on the other end of the spectrum we're",
    "start": "373000",
    "end": "378400"
  },
  {
    "text": "starting to see emergent technology and phenomena so the GPT 40 model it looks",
    "start": "378400",
    "end": "384759"
  },
  {
    "text": "like it's been trained to be natively multimodal it looks like it can do audio to audio conversation rather than having",
    "start": "384759",
    "end": "391160"
  },
  {
    "text": "to go through text as a as a middle layer and that's incredibly exciting and I think we'll start seeing some very",
    "start": "391160",
    "end": "397120"
  },
  {
    "text": "impressive Technologies from those proper Frontier level models especially playing with multimodality as well so",
    "start": "397120",
    "end": "403319"
  },
  {
    "text": "that's what I think we're going to see over the next year more Enterprise friendly scale models and then also these huge models with amazing",
    "start": "403319",
    "end": "409960"
  },
  {
    "text": "multimodal abilities yeah definitely I would like to talk about the Enterprise adoption",
    "start": "409960",
    "end": "415479"
  },
  {
    "text": "little bit later in the podcast you know in terms of rag the retrieval augmented generation techniques but let's start",
    "start": "415479",
    "end": "421479"
  },
  {
    "text": "with couple of other questions to catch up on the llm space right so can you talk about some important use cases for",
    "start": "421479",
    "end": "427000"
  },
  {
    "text": "using llms for our listeners who are who may be new to this especially I know",
    "start": "427000",
    "end": "432039"
  },
  {
    "text": "your focus is regulated Industries yeah so how do you kind of see llms kind of helping in terms of security privacy",
    "start": "432039",
    "end": "438680"
  },
  {
    "text": "compliance and other other areas yeah so it can be quite difficult for people to",
    "start": "438680",
    "end": "443960"
  },
  {
    "text": "imagine what llms are able to do because it's quite different from any other form of technology that we've we've had",
    "start": "443960",
    "end": "449759"
  },
  {
    "text": "before the way that I get my clients to think about it is I ask them to think of",
    "start": "449759",
    "end": "457199"
  },
  {
    "text": "these llms almost like having an intern and what would you do if you got given",
    "start": "457199",
    "end": "464479"
  },
  {
    "text": "access to essentially unlimited free interns and",
    "start": "464479",
    "end": "470000"
  },
  {
    "text": "that's kind of what I think you can do with Gen so if there are tasks in your",
    "start": "470000",
    "end": "475400"
  },
  {
    "text": "organization that you feel could be done if an intern had super Vision that's the",
    "start": "475400",
    "end": "480520"
  },
  {
    "text": "kind of thing that you can do with these kinds of models so I don't think we're at the stage yet where we're replacing",
    "start": "480520",
    "end": "486960"
  },
  {
    "text": "senior level jobs but there's a huge number of tasks that happen in every single industry that can be delegated",
    "start": "486960",
    "end": "494240"
  },
  {
    "text": "and that can be broken up into smaller tasks one of the most common use cases",
    "start": "494240",
    "end": "499720"
  },
  {
    "text": "that we see as like a 101 for Enterprise and I think we'll talk about this when later when we talk about rag is",
    "start": "499720",
    "end": "506639"
  },
  {
    "text": "essentially acting as a research assistant or or some kind of Knowledge Management System it's incredibly good",
    "start": "506639",
    "end": "513839"
  },
  {
    "text": "at searching through large large large suaves of documents and then and then summarizing and and and using that as a",
    "start": "513839",
    "end": "521320"
  },
  {
    "text": "research piece so that's kind of the early uses that we're seeing but I think we're going to see increasingly creative",
    "start": "521320",
    "end": "527240"
  },
  {
    "text": "and also Niche use cases that people really investigate the workflows they have in their business and what they",
    "start": "527240",
    "end": "533160"
  },
  {
    "text": "could automate if they had access to for example these recent graduates yeah definitely you're right I don't think",
    "start": "533160",
    "end": "538880"
  },
  {
    "text": "llms will completely replace human efforts but they can definitely augment a lot of things we do right also like in",
    "start": "538880",
    "end": "545839"
  },
  {
    "text": "terms of LL models you know there are these base models and open source and propriety models you know how do you see",
    "start": "545839",
    "end": "551959"
  },
  {
    "text": "this space kind of you know I know they're like the Llama models and then um there lava for vision and of course",
    "start": "551959",
    "end": "558680"
  },
  {
    "text": "the GPT you know 234 40 now uh and then Google has B and CLA and all those other",
    "start": "558680",
    "end": "566120"
  },
  {
    "text": "models so can you talk more about these I know like I there are so many models you like how to even go about these base",
    "start": "566120",
    "end": "572760"
  },
  {
    "text": "models and like what should the developers consider when they're looking to leverage llms in their applications",
    "start": "572760",
    "end": "579320"
  },
  {
    "text": "so I think what's important to realize for your listeners that might not be familiar with base models and these",
    "start": "579320",
    "end": "584640"
  },
  {
    "text": "Foundation models is that they come pre-trained so it's not like in Old School I say old school only a couple",
    "start": "584640",
    "end": "591079"
  },
  {
    "text": "years ago data science machine learning where you would have to spend a lot of time and effort into training these",
    "start": "591079",
    "end": "596200"
  },
  {
    "text": "models come pre-trained and for the modality that you're looking at will already have a really good base level of",
    "start": "596200",
    "end": "602640"
  },
  {
    "text": "understanding that you can then kind of work on top of when you look at the different Foundation models and you",
    "start": "602640",
    "end": "608680"
  },
  {
    "text": "already pointed out a number of them so for example on the open source side we have you know llama models we have the",
    "start": "608680",
    "end": "616320"
  },
  {
    "text": "lava models for vision we have whisper we have all the proprietary API based",
    "start": "616320",
    "end": "621360"
  },
  {
    "text": "models there's a huge number to choose from so it can be very very difficult to know which one's right for your",
    "start": "621360",
    "end": "627079"
  },
  {
    "text": "particular application so I'll give a couple heuristics which might be helpful",
    "start": "627079",
    "end": "632839"
  },
  {
    "text": "the first heuristic I'll give is figuring out what modality you cared about so if you are just doing text",
    "start": "632839",
    "end": "640160"
  },
  {
    "text": "processing then you don't need an image model you don't need an audio model and you need a text model if you are doing",
    "start": "640160",
    "end": "646519"
  },
  {
    "text": "table passing or image passing or audio then you need something that works with",
    "start": "646519",
    "end": "651800"
  },
  {
    "text": "that particular modality so the modality is the first one that you should worry about the second decision that you'll",
    "start": "651800",
    "end": "657560"
  },
  {
    "text": "typically have is okay I know my modality then you'll have this big choice between API based models and",
    "start": "657560",
    "end": "664519"
  },
  {
    "text": "self-hosted models and this is probably one of the biggest choices you have when you're kind of comparing different",
    "start": "664519",
    "end": "669560"
  },
  {
    "text": "models because once you're in the various regime it's easy to just go for the best of the best of each one so if",
    "start": "669560",
    "end": "676959"
  },
  {
    "text": "you are experimenting or if you don't have particularly strict compliance or",
    "start": "676959",
    "end": "683360"
  },
  {
    "text": "data residency regulations and you're not going to deploy at a huge scale it really makes sense to to start with",
    "start": "683360",
    "end": "689720"
  },
  {
    "text": "these API based models things like open Ai and anthropic they're really good places to start if however you are",
    "start": "689720",
    "end": "697839"
  },
  {
    "text": "looking to go to mass scale production or you really care about data residency",
    "start": "697839",
    "end": "704040"
  },
  {
    "text": "and you really care about that privacy aspects or maybe you're really cost",
    "start": "704040",
    "end": "709279"
  },
  {
    "text": "sensitive then it makes sense to start looking at those self-hosted models that's a key decision you have to make",
    "start": "709279",
    "end": "715040"
  },
  {
    "text": "so firstly the modality secondly open source versus self-hosted and then the Third decision I would give is around",
    "start": "715040",
    "end": "721920"
  },
  {
    "text": "essentially that cost to accuracy tradeoff that you need to make almost all of the API providers and it's also",
    "start": "721920",
    "end": "727959"
  },
  {
    "text": "available in open source have different sized models that perform differently",
    "start": "727959",
    "end": "733240"
  },
  {
    "text": "but have different cost ratios so if you're asking it's a very easy task you might ask it to use a very small model",
    "start": "733240",
    "end": "739040"
  },
  {
    "text": "if it's a very complex task you might use very big and very expensive model so",
    "start": "739040",
    "end": "744519"
  },
  {
    "text": "they're kind of the three highlights and then the final thing I would say is if you are working in something domain",
    "start": "744519",
    "end": "751079"
  },
  {
    "text": "specific or maybe in a language that isn't very well supported you might also want to start looking at fine tuned",
    "start": "751079",
    "end": "757600"
  },
  {
    "text": "variants of all of these so just to summarize because that's actually quite a lot of information number one what",
    "start": "757600",
    "end": "763920"
  },
  {
    "text": "modality is it that you careabout number two do you want to go API based or self-hosted number three what is the",
    "start": "763920",
    "end": "772399"
  },
  {
    "text": "size performance cost tradeoff you're willing to make and then number four if it's something very Niche you're doing",
    "start": "772399",
    "end": "778639"
  },
  {
    "text": "or in a for language you might want to do something fine change I know you've been focusing on the selfhosted El",
    "start": "778639",
    "end": "784160"
  },
  {
    "text": "deployments how to help the companies you know not to use this API based which kind of come with its own data privacy",
    "start": "784160",
    "end": "791240"
  },
  {
    "text": "and latency type of challenges so on the selfhosted models I know there are the",
    "start": "791240",
    "end": "796320"
  },
  {
    "text": "AMA is one of the examples so can you talk about what are the pros and cons I know there are some advantages for self",
    "start": "796320",
    "end": "802000"
  },
  {
    "text": "hosting but also I mean I'm sure it comes with some constraints right so what should the teams keep in mind you",
    "start": "802000",
    "end": "808079"
  },
  {
    "text": "know selfhosted is not all all you see right so there are some challenges as well yeah exactly there's",
    "start": "808079",
    "end": "814560"
  },
  {
    "text": "definitely challenges with self hosting and if you just want to go for the raw easiest option API based is the easiest",
    "start": "814560",
    "end": "821199"
  },
  {
    "text": "so there's broadly three challenges or reasons you might not want to self host and they're",
    "start": "821199",
    "end": "828040"
  },
  {
    "text": "changing day by day so I'll kind of tell you the challenges and I'll also describe how I think they're changing",
    "start": "828040",
    "end": "833880"
  },
  {
    "text": "the first one is around the quality of the model this is especially something that we saw last year the",
    "start": "833880",
    "end": "839120"
  },
  {
    "text": "state-of-the-art models in the API based regime so for example like open AI were",
    "start": "839120",
    "end": "844639"
  },
  {
    "text": "so much better than what we had in open source that in terms of just raw quality",
    "start": "844639",
    "end": "850279"
  },
  {
    "text": "you just weren't able to get the same kind of quality that you needed so that",
    "start": "850279",
    "end": "855639"
  },
  {
    "text": "was a challenge that a lot of people had last year if they needed to self host is it was very difficult to get the quality of models they needed this has changed",
    "start": "855639",
    "end": "862880"
  },
  {
    "text": "dramatically and llama 3 was a really big turning point it was the first time that we've seen open source models",
    "start": "862880",
    "end": "869560"
  },
  {
    "text": "essentially perform as well as API based models for a better cost tradeoff so that quality of model thing is going",
    "start": "869560",
    "end": "876000"
  },
  {
    "text": "away but that's something you need to evaluate the second reason why people",
    "start": "876000",
    "end": "881240"
  },
  {
    "text": "might find self-hosting challenging is there's a lot more infrastructure that you're responsible for when you're",
    "start": "881240",
    "end": "887120"
  },
  {
    "text": "self-hosting compared to when you're using an API so when you're using an API based model you take for granted a huge",
    "start": "887120",
    "end": "894959"
  },
  {
    "text": "amount of infrastructure that they've built behind the scenes so everything from the batching server the model",
    "start": "894959",
    "end": "901279"
  },
  {
    "text": "optimization that they've done they've enabled function calling this is all stuff that if you're self-hosting and",
    "start": "901279",
    "end": "907880"
  },
  {
    "text": "you care about you need to now build yourself I mean that's the whole reason that we exist as a company is we provide",
    "start": "907880",
    "end": "914519"
  },
  {
    "text": "that infrastructure that you take for granted in the API regime but provide it for the self-hosted",
    "start": "914519",
    "end": "920240"
  },
  {
    "text": "regime and then the final challenge around self hosting is essentially",
    "start": "920240",
    "end": "925680"
  },
  {
    "text": "getting access to gpus this is still something that team struggle with even though the GPU crunch is eased since",
    "start": "925680",
    "end": "932360"
  },
  {
    "text": "last year it's not necessarily easy to be able to get the gpus that you require",
    "start": "932360",
    "end": "938000"
  },
  {
    "text": "and also unless you're deploying at an Enterprise scale then it might not be",
    "start": "938000",
    "end": "943920"
  },
  {
    "text": "cost effective for you to rent those gpus as well so that's the quality thing",
    "start": "943920",
    "end": "949160"
  },
  {
    "text": "which I think is going away pretty quickly the ease of use which we're trying to get rid of but it's always",
    "start": "949160",
    "end": "954720"
  },
  {
    "text": "going to be there because it's more work and then finally whether you canuse use those gpus efficiently and effectively",
    "start": "954720",
    "end": "961839"
  },
  {
    "text": "right so assuming that you know all of these kind of the check mark all of these and you know self hosting is the way to go how do you see these space",
    "start": "961839",
    "end": "969240"
  },
  {
    "text": "working right you know is do you see like large companies going with the self hosting model because they can afford to",
    "start": "969240",
    "end": "975240"
  },
  {
    "text": "host on Prem or do you also see smaller companies doing this because they have more control on the overall process so",
    "start": "975240",
    "end": "982959"
  },
  {
    "text": "like what size companies can benefit from this so I actually am surprised to",
    "start": "982959",
    "end": "988040"
  },
  {
    "text": "say that it not just big companies I would have thought that it would just be",
    "start": "988040",
    "end": "993120"
  },
  {
    "text": "something that really big companies with very big data centers would be investing in but actually that's not what we've",
    "start": "993120",
    "end": "998199"
  },
  {
    "text": "seen necessarily from our client base that's not to say we see very small startups doing this but for example like",
    "start": "998199",
    "end": "1005160"
  },
  {
    "text": "midmarket businesses and scale-ups are really investing in these self-hosted",
    "start": "1005160",
    "end": "1010240"
  },
  {
    "text": "capabilities for the big big companies it's typically because of privacy concerns and and um data residency",
    "start": "1010240",
    "end": "1018040"
  },
  {
    "text": "concerns but for the smaller companies and this is potentially counterintuitive it's actually very",
    "start": "1018040",
    "end": "1025160"
  },
  {
    "text": "often because of the performance you can get and now that's both latency and",
    "start": "1025160",
    "end": "1030760"
  },
  {
    "text": "throughput performance that you can get by using self-hosted you can get much faster responses for instance also when",
    "start": "1030760",
    "end": "1037400"
  },
  {
    "text": "you're self-hosting models you get access to a much bigger choice of models that you can use so actually if you're",
    "start": "1037400",
    "end": "1044720"
  },
  {
    "text": "building a state-of-the-art rag app you might think okay the best model for everything is open AI well that's not",
    "start": "1044720",
    "end": "1050120"
  },
  {
    "text": "actually true if you're building a state-of-the-art rag app the best generative model you can use is open AI",
    "start": "1050120",
    "end": "1057320"
  },
  {
    "text": "but the best embedding model the best ranker model the best table passer the best image passer they're all open",
    "start": "1057320",
    "end": "1063000"
  },
  {
    "text": "source so you might have if you're a smaller company some kind of hybrid solution where you can get better",
    "start": "1063000",
    "end": "1069000"
  },
  {
    "text": "performance by using some open source and self-hosted components yeah definitely I was",
    "start": "1069000",
    "end": "1075360"
  },
  {
    "text": "recently exploring AMA the framework and I was able to download Lama 3 mistal and",
    "start": "1075360",
    "end": "1081360"
  },
  {
    "text": "lava so I was not constrained by any of these models right I would have been if I chose open AI or you know meta or some",
    "start": "1081360",
    "end": "1088960"
  },
  {
    "text": "other proprietary hosting model right so we can talk about rag a little bit I know you mentioned about res stance",
    "start": "1088960",
    "end": "1095600"
  },
  {
    "text": "Knowledge Management examples and you just mentioned the state-ofthe-art rag app let's kind of jump into that so how",
    "start": "1095600",
    "end": "1102840"
  },
  {
    "text": "do you define the characteristics of a state-of-the-art rag app you know what",
    "start": "1102840",
    "end": "1108799"
  },
  {
    "text": "should have you know to be really effective and efficient and valuable to the teams yeah so rag or retrieval",
    "start": "1108799",
    "end": "1115960"
  },
  {
    "text": "augmented generation is a technique that I would actually say the majority of",
    "start": "1115960",
    "end": "1121919"
  },
  {
    "text": "production scale AI applications are using and what it does is it enables",
    "start": "1121919",
    "end": "1128799"
  },
  {
    "text": "your llm your generative llm to call on data right so that's data that you might",
    "start": "1128799",
    "end": "1134960"
  },
  {
    "text": "have stored in your business so there are a couple key parts of the r g app",
    "start": "1134960",
    "end": "1140960"
  },
  {
    "text": "that I think are really important to get right and there are two parts which get talked about a lot that I actually think",
    "start": "1140960",
    "end": "1147320"
  },
  {
    "text": "are not very important the first one is the vector database I don't think the vector database of choice is that",
    "start": "1147320",
    "end": "1152480"
  },
  {
    "text": "important they're pretty commoditized most of them are fairly similar so I don't spend a lot of time thinking about",
    "start": "1152480",
    "end": "1157840"
  },
  {
    "text": "that choice the second thing that I don't think you should necessarily spend a lot of time thinking about which is",
    "start": "1157840",
    "end": "1163840"
  },
  {
    "text": "counterintuitive is which generative model you should use people are like should I use mix or llama 3 or whatever",
    "start": "1163840",
    "end": "1170919"
  },
  {
    "text": "it actually typically doesn't matter and the reason why it doesn't matter is because the most important things are",
    "start": "1170919",
    "end": "1177640"
  },
  {
    "text": "your data pipelines and your embedding search and it's the whole thing of garbage in garbage out if you feed the",
    "start": "1177640",
    "end": "1185240"
  },
  {
    "text": "best model in the world really bad search results then you're going to get a really really bad output and if you",
    "start": "1185240",
    "end": "1190880"
  },
  {
    "text": "feed in really amazing search results into a not very good model you'll probably still get a good output so the",
    "start": "1190880",
    "end": "1196480"
  },
  {
    "text": "two things that I think are really important the first one is that document",
    "start": "1196480",
    "end": "1202159"
  },
  {
    "text": "processing or data processing pipeline for example how do you chunk your text",
    "start": "1202159",
    "end": "1207520"
  },
  {
    "text": "if you have images or tables how do you pass those images and tables so that they can be searched on efficiently this",
    "start": "1207520",
    "end": "1214760"
  },
  {
    "text": "is incredibly important to get right and that's actually why we recently released support for improved table passes and",
    "start": "1214760",
    "end": "1222000"
  },
  {
    "text": "improved image passs as well within our server and then the second thing you need to get right is actually non-er as",
    "start": "1222000",
    "end": "1229159"
  },
  {
    "text": "well but it's essentially the semantic search part of of that application the best way by far that we",
    "start": "1229159",
    "end": "1236400"
  },
  {
    "text": "have found to do that semantic search is essentially a two-stage process you can",
    "start": "1236400",
    "end": "1241679"
  },
  {
    "text": "make it more complicated but the highest level two-stage the first one is the embedding search and then the second one",
    "start": "1241679",
    "end": "1247559"
  },
  {
    "text": "is the ranker search so the embedder search is very very good for searching over vast documents and then kind of",
    "start": "1247559",
    "end": "1254200"
  },
  {
    "text": "picking out the ones that it thinks are most relevant and the ranker search is a more expensive search se but it's a way",
    "start": "1254200",
    "end": "1260120"
  },
  {
    "text": "that given you have a kind of short list to be able to say which ones are the most relevant so a combination of an",
    "start": "1260120",
    "end": "1265919"
  },
  {
    "text": "embedder and ranker are fantastic for that rag application if I think about",
    "start": "1265919",
    "end": "1272400"
  },
  {
    "text": "the actual models that I need to deploy or self-host the llm is one of them and that could be either API or self-hosted",
    "start": "1272400",
    "end": "1279279"
  },
  {
    "text": "whatever but the others are I need a table passer I need probably an image passer I need a embeding model and I",
    "start": "1279279",
    "end": "1286159"
  },
  {
    "text": "need a ranker model and that's a lot that you need to deploy and optimize and",
    "start": "1286159",
    "end": "1292960"
  },
  {
    "text": "orchestrate so we've built into our container so that you can deploy it all in one so you can hit a single end point",
    "start": "1292960",
    "end": "1298880"
  },
  {
    "text": "but that's the kind of number of models you need for a really really good rag application yeah before I I'm definitely",
    "start": "1298880",
    "end": "1304720"
  },
  {
    "text": "um very interested in learning about uh the Titan ml inference stack architecture before we delve into that",
    "start": "1304720",
    "end": "1311640"
  },
  {
    "text": "let me talk about the the recent presentation that you gave at cucon London can you highlight some of the",
    "start": "1311640",
    "end": "1318080"
  },
  {
    "text": "tips I you talked about uh the llm deployment techniques can you highlight kind of few of those techniques and have",
    "start": "1318080",
    "end": "1324360"
  },
  {
    "text": "you any other additional observations you know since the conference yes the talk that I gave was my tips and tricks",
    "start": "1324360",
    "end": "1330600"
  },
  {
    "text": "for llm deployment it was essentially a combination of tips that I've learn over the last couple years working with our",
    "start": "1330600",
    "end": "1336480"
  },
  {
    "text": "clients that we end up saying over and over again and I've written that talk up into a Blog which will be released some",
    "start": "1336480",
    "end": "1342720"
  },
  {
    "text": "point on the on the infoq website and I'm also going to be doing a revised version of that talk in San Francisco go",
    "start": "1342720",
    "end": "1348760"
  },
  {
    "text": "in November or December so you'll be able to see how much of the landscape has changed between those two talks I",
    "start": "1348760",
    "end": "1354880"
  },
  {
    "text": "gave seven tips overall maybe I'll pick out one or two that I think are interesting to highlight the first one",
    "start": "1354880",
    "end": "1361720"
  },
  {
    "text": "that I'll highlight is that people don't spend enough time",
    "start": "1361720",
    "end": "1367360"
  },
  {
    "text": "thinking about their deployment requirements and their deployment boundaries and they will often kind of",
    "start": "1367360",
    "end": "1374400"
  },
  {
    "text": "be left to scramble when they get to deploying but what we find is really helpful is when you start designing your",
    "start": "1374400",
    "end": "1382640"
  },
  {
    "text": "application if you have very hard and fast deployment requirements like it",
    "start": "1382640",
    "end": "1388000"
  },
  {
    "text": "needs to be real time or it can be batched or it has to be deployed on this GPU or it has to have this kind of cost",
    "start": "1388000",
    "end": "1394159"
  },
  {
    "text": "profile these are all things that you should know upfront because it will radically change the way you architect",
    "start": "1394159",
    "end": "1399880"
  },
  {
    "text": "your system so knowing your deployment requirements is crucial another tip that",
    "start": "1399880",
    "end": "1405480"
  },
  {
    "text": "I gave is that I recommended that unless you have have pretty much unlimited",
    "start": "1405480",
    "end": "1410679"
  },
  {
    "text": "resource you should almost always quantize your model using fit forbit quantization specifically and the reason",
    "start": "1410679",
    "end": "1418159"
  },
  {
    "text": "why is that given you have a fixed resource requirement the",
    "start": "1418159",
    "end": "1423480"
  },
  {
    "text": "performance for a larger model that's been quantized down to that size versus a model natively of that size will be",
    "start": "1423480",
    "end": "1430840"
  },
  {
    "text": "far better so you'll retain a lot of that performance and accuracy and that's from a Tim de's paper a couple years ago",
    "start": "1430840",
    "end": "1436520"
  },
  {
    "text": "called 4bit scaling laws or forit Precision scaling laws or something like that so we almost always recommend using",
    "start": "1436520",
    "end": "1443039"
  },
  {
    "text": "a bigger model that's quantized down rather than using a natively small model and I can give one more tip which is",
    "start": "1443039",
    "end": "1452760"
  },
  {
    "text": "that even though gpc4 is the best model although now it be gpc4 o or Claude or",
    "start": "1452760",
    "end": "1458600"
  },
  {
    "text": "whatever it is that doesn't necessarily mean you need to use it for everything and that quite often smaller models",
    "start": "1458600",
    "end": "1465159"
  },
  {
    "text": "which are cheaper and easier to deploy are just as performant and you're not really getting any benefit from using",
    "start": "1465159",
    "end": "1470320"
  },
  {
    "text": "those bigger models so think about how hard your task is before you Dole out",
    "start": "1470320",
    "end": "1475360"
  },
  {
    "text": "for the biggest inv best model there's just three of them but if you want to read all seven you can read it in the",
    "start": "1475360",
    "end": "1480480"
  },
  {
    "text": "blog yeah definitely we will make sure that we link that the article you know in this uh podcast transcript so let's",
    "start": "1480480",
    "end": "1487960"
  },
  {
    "text": "jump into the big topic right the architecture framework that you company offers Titan takeoff inference stack I'm",
    "start": "1487960",
    "end": "1496840"
  },
  {
    "text": "definitely curious about this this is an inference software to make self-hosting",
    "start": "1496840",
    "end": "1502279"
  },
  {
    "text": "of AI apps simple and scalable and secure can you discuss more about this architecture stack you know what",
    "start": "1502279",
    "end": "1507600"
  },
  {
    "text": "technologies Does it include and how can our listeners kind of get started is there like a tutorial",
    "start": "1507600",
    "end": "1514200"
  },
  {
    "text": "or anything they can use to kind of learn more about it for sure so you mentioned olama before which is a way of",
    "start": "1514200",
    "end": "1520960"
  },
  {
    "text": "really easily running a language model we are a similar kind of framework but",
    "start": "1520960",
    "end": "1526480"
  },
  {
    "text": "for designed for scale and designed for the Enterprise so we are essentially a",
    "start": "1526480",
    "end": "1531880"
  },
  {
    "text": "way that you can run language model applications really efficiently on your own private hardware and the stack",
    "start": "1531880",
    "end": "1538399"
  },
  {
    "text": "comprises of a couple things so I think what I'll do first is look at the zoomed out like what does it actually look like",
    "start": "1538399",
    "end": "1544159"
  },
  {
    "text": "well it's just a Docker container it's a Docker container that when you pass a model through exposes an API that you",
    "start": "1544159",
    "end": "1550440"
  },
  {
    "text": "can then interact with exposes that llm API that you can interact with and you can deploy that Docker container on",
    "start": "1550440",
    "end": "1557200"
  },
  {
    "text": "whatever Hardware that you carry about and we fully integrate with things like kubernetes so it's a containerized and",
    "start": "1557200",
    "end": "1563880"
  },
  {
    "text": "kubernetes Native product within that server we've made the very unique choice",
    "start": "1563880",
    "end": "1569760"
  },
  {
    "text": "I think we're one of only a handful teams worldwide that's ever done this which is we rolled out absolutely",
    "start": "1569760",
    "end": "1574960"
  },
  {
    "text": "everything from scratch ourselves pretty much so the inference server the server",
    "start": "1574960",
    "end": "1581039"
  },
  {
    "text": "part is written all in Rust so it's a multi-threaded rust server and then the",
    "start": "1581039",
    "end": "1586799"
  },
  {
    "text": "inference engine so this is the engine that makes the model run faster so run than just deploying a hugg and face",
    "start": "1586799",
    "end": "1592600"
  },
  {
    "text": "model onto a GPU we do a lot of smart things with things like quantization and caching and inference optimization on",
    "start": "1592600",
    "end": "1599320"
  },
  {
    "text": "that level that's written in a combination of python and then also the open ai's Triton the Triton language and",
    "start": "1599320",
    "end": "1607440"
  },
  {
    "text": "the reason we made those technical decisions of writing it in Triton rather than writing in Cuda is it means that we",
    "start": "1607440",
    "end": "1613480"
  },
  {
    "text": "can be Hardware agnostic because Triton will compile not just to Nvidia but also to AMD and Intel as well so we don't",
    "start": "1613480",
    "end": "1621320"
  },
  {
    "text": "have to be tied to that Cuda stack so there are like a couple of decisions that we've made so the entire stack is",
    "start": "1621320",
    "end": "1627279"
  },
  {
    "text": "written in Docker rust Python and then um the Trion programming language so how",
    "start": "1627279",
    "end": "1634399"
  },
  {
    "text": "much of the overall process does this stack you know going to automate or help the developers and teams who are going",
    "start": "1634399",
    "end": "1639480"
  },
  {
    "text": "to use it what the stack does is it allows you to turn just a GPU so raw",
    "start": "1639480",
    "end": "1645679"
  },
  {
    "text": "Hardware plus a model into a very scalable endpoint that you can then build on top of and things that make our",
    "start": "1645679",
    "end": "1653760"
  },
  {
    "text": "platform in particular very unique is we're not just saying okay you now have",
    "start": "1653760",
    "end": "1659080"
  },
  {
    "text": "a llama 3 endpoint but we support not just generative models but embedding models re rank models image to text",
    "start": "1659080",
    "end": "1665919"
  },
  {
    "text": "models all kinds of modalities and what's really interesting is you can deploy them in one container and you can",
    "start": "1665919",
    "end": "1672480"
  },
  {
    "text": "deploy that container over multiple gpus so it automates all of the multi-gpu set up it allows you hit a single container",
    "start": "1672480",
    "end": "1679320"
  },
  {
    "text": "for an entire rag application all through a declarative interface which if you were trying to",
    "start": "1679320",
    "end": "1686200"
  },
  {
    "text": "build this kind of natively you would have to worry about how I'm going to do my multi-gpu inference I would have to",
    "start": "1686200",
    "end": "1693000"
  },
  {
    "text": "be playing around with things like tensor R tlm to make it run faster and from our clients we Benchmark that this",
    "start": "1693000",
    "end": "1699559"
  },
  {
    "text": "typically saves about two to three months per project by using our stack",
    "start": "1699559",
    "end": "1704720"
  },
  {
    "text": "and then using our stack for both experimentation so you can easily swap models in and out but then also using it",
    "start": "1704720",
    "end": "1709960"
  },
  {
    "text": "for production and knowing that it's going to scale properly and you know isn't going to come across horrible",
    "start": "1709960",
    "end": "1715080"
  },
  {
    "text": "throughput rates as well so it's a really significant time save and it means that the developers can focus just",
    "start": "1715080",
    "end": "1722240"
  },
  {
    "text": "on building the application which is actually the thing that brings them value because they're working from an API that they know is stable that they",
    "start": "1722240",
    "end": "1728640"
  },
  {
    "text": "know will support when the new model comes out they can just swap it in and out and they can just focus on building that better",
    "start": "1728640",
    "end": "1734600"
  },
  {
    "text": "application so let's jump back to the regulation side of the discussion little bit medium so I was reading this",
    "start": "1734600",
    "end": "1740440"
  },
  {
    "text": "Stanford University's AI index report for this year so one of their predictions is the number of AI",
    "start": "1740440",
    "end": "1747840"
  },
  {
    "text": "regulations in the United States will sharply increase can you talk about the",
    "start": "1747840",
    "end": "1753640"
  },
  {
    "text": "AI regulations in general and uh any specific Regulatory Compliance standards",
    "start": "1753640",
    "end": "1759600"
  },
  {
    "text": "in the US UK and the European countries and and how do you see like you know regulation is always trying to catch up",
    "start": "1759600",
    "end": "1764919"
  },
  {
    "text": "with Innovation so what is the balance between having some kind of good control on",
    "start": "1764919",
    "end": "1770960"
  },
  {
    "text": "these Technologies without disrupting or interrupting the Innovation what is like responsible llm or gen AI type of you",
    "start": "1770960",
    "end": "1778200"
  },
  {
    "text": "know look like right so well it's it's difficult for me so I double majored in theoretical physics and philosophy so I",
    "start": "1778200",
    "end": "1784960"
  },
  {
    "text": "do have this philosophical Street to me where I I I do enjoy thinking about these things but it's actually something",
    "start": "1784960",
    "end": "1790039"
  },
  {
    "text": "that I find incredibly difficult to think about what I'm not worried about is some",
    "start": "1790039",
    "end": "1796200"
  },
  {
    "text": "kind of Terminator the style risk what I am incredibly worried about is the",
    "start": "1796200",
    "end": "1805880"
  },
  {
    "text": "societal impact of the technology that we've already built this is impact all",
    "start": "1805880",
    "end": "1811720"
  },
  {
    "text": "the way from dis and misinformation to really Mass underemployment but I don't think those",
    "start": "1811720",
    "end": "1819440"
  },
  {
    "text": "particular things are things that you can stop through regulation because I think they're things that already exist",
    "start": "1819440",
    "end": "1825240"
  },
  {
    "text": "in the technology that we have so that's something that that I'm very cautious of that I don't really",
    "start": "1825240",
    "end": "1831159"
  },
  {
    "text": "know what the the right or correct answer is I also have this additional",
    "start": "1831159",
    "end": "1836519"
  },
  {
    "text": "question that I think about of would it be safer if we lived in a closed Source",
    "start": "1836519",
    "end": "1843559"
  },
  {
    "text": "AI world or an open source AI world and both of them can be very scary the close",
    "start": "1843559",
    "end": "1851679"
  },
  {
    "text": "sourc AI world I think in particular scares me more this idea of you have incredibly",
    "start": "1851679",
    "end": "1858240"
  },
  {
    "text": "huge concentrated power potentially like Humanity changing power in the hands of",
    "start": "1858240",
    "end": "1863720"
  },
  {
    "text": "a very very small number of people something that really scares me and those companies become more powerful",
    "start": "1863720",
    "end": "1869039"
  },
  {
    "text": "than even governments but on the other hand if you have an open source regime which I actually tend to lean towards",
    "start": "1869039",
    "end": "1876000"
  },
  {
    "text": "you do end up with models that can be harmful in the hands of Bad actors and we already have that right now there are",
    "start": "1876000",
    "end": "1882519"
  },
  {
    "text": "already websites where you can create deep fakes in pornography of of children like that is something from a technology",
    "start": "1882519",
    "end": "1889080"
  },
  {
    "text": "that exists right now that has been empowered by open source so the answer",
    "start": "1889080",
    "end": "1894519"
  },
  {
    "text": "is I don't really know what the regulation should look like but what I do think we should have is we should",
    "start": "1894519",
    "end": "1901720"
  },
  {
    "text": "have governments that are incredibly concerned about this and are very very thoughtful about this in a way that I",
    "start": "1901720",
    "end": "1908320"
  },
  {
    "text": "don't necessarily think they are I think they're concerned but I don't necessarily think they're thoughtful and I also think that we need",
    "start": "1908320",
    "end": "1915799"
  },
  {
    "text": "to be really striving towards regulatory alignment between the major Powers so",
    "start": "1915799",
    "end": "1921840"
  },
  {
    "text": "the EU Britain the US Asia should all be aligned on how we're regulating and",
    "start": "1921840",
    "end": "1927279"
  },
  {
    "text": "currently it feels like there's a lot of misalignment which is incredibly confusing for all of the players in the",
    "start": "1927279",
    "end": "1932559"
  },
  {
    "text": "field so that's my broad answer which is it's something that I'm incredibly concerned about and it's something that",
    "start": "1932559",
    "end": "1939000"
  },
  {
    "text": "I think government should think about very carefully and I also think alignment is really what I would be arguing for whatever the regulations end",
    "start": "1939000",
    "end": "1946360"
  },
  {
    "text": "up being that's a great point because some of these regulations don't have to be enforced by the governments they can",
    "start": "1946360",
    "end": "1953240"
  },
  {
    "text": "be self-regulated right so like you said you know what would be the human involvement you know post AI world right",
    "start": "1953240",
    "end": "1961559"
  },
  {
    "text": "so maybe that's where it is you know like you know maybe we can use humans to make sure that any content that is not",
    "start": "1961559",
    "end": "1968519"
  },
  {
    "text": "appropriate will not get out right so other those you know control those yeah there's a huge amount of self-regulation",
    "start": "1968519",
    "end": "1975320"
  },
  {
    "text": "and I think unfortunately that self regulation has to happen from the big platforms it's not like there's one",
    "start": "1975320",
    "end": "1981760"
  },
  {
    "text": "central place where we can say okay this is allowed and this isn't allowed it's what's allowed on Facebook what's allowed on Twitter what's allowed on all",
    "start": "1981760",
    "end": "1988480"
  },
  {
    "text": "of these things and that actually was already a concentration of power and it's something as that I experienced",
    "start": "1988480",
    "end": "1996159"
  },
  {
    "text": "because I was a teenager when social media first came out and we've already experienced this problem of what are we",
    "start": "1996159",
    "end": "2002440"
  },
  {
    "text": "allowed to put on and consume on these platforms and in the past we've actually not been very good",
    "start": "2002440",
    "end": "2008440"
  },
  {
    "text": "at putting things that don't harm people on these platforms so I'm hoping that we've learned our lessons from like my",
    "start": "2008440",
    "end": "2015919"
  },
  {
    "text": "generation and for the next AI generation will'll be a bit more careful though yes makes sense Switching gears a",
    "start": "2015919",
    "end": "2023120"
  },
  {
    "text": "little bit right so one of the predictions at a recent Microsoft conference they said in no more than 3",
    "start": "2023120",
    "end": "2028679"
  },
  {
    "text": "years anything that is not connected to AI will be considered broken or",
    "start": "2028679",
    "end": "2033760"
  },
  {
    "text": "invisible so that kind of tells us how big a part A is playing right so so how do you see AI playing a larger role in",
    "start": "2033760",
    "end": "2041120"
  },
  {
    "text": "our work and daily lives in the future and do you have any interesting use cases where you see AI can help it's an",
    "start": "2041120",
    "end": "2048358"
  },
  {
    "text": "interesting quote and I do genuinely think we will see AI very very deeply embedded in everything we do three is is",
    "start": "2048359",
    "end": "2055919"
  },
  {
    "text": "quite ambitious though I don't think they know this pace at which Enterprise tends to move I don't think Enterprise",
    "start": "2055919",
    "end": "2061398"
  },
  {
    "text": "do very much in in three years what are use cases that I'm really excited about",
    "start": "2061399",
    "end": "2066599"
  },
  {
    "text": "well the use case I'm really excited by are actually the ones that are potentially the most boring it's those",
    "start": "2066599",
    "end": "2073118"
  },
  {
    "text": "really micro improvements that we'll see in every single workflow that if we can",
    "start": "2073119",
    "end": "2078919"
  },
  {
    "text": "in every single workflow make it 10% more efficient and keep doing that over and over and over again I think we get",
    "start": "2078919",
    "end": "2084800"
  },
  {
    "text": "to like very real transformation I think what people often do is they're like",
    "start": "2084800",
    "end": "2090200"
  },
  {
    "text": "we're going to automate all of this role or all of this department and I think",
    "start": "2090200",
    "end": "2095520"
  },
  {
    "text": "that is a mistake I think the things that I'm very excited by are the things where we see very very",
    "start": "2095520",
    "end": "2102520"
  },
  {
    "text": "meaningful and practical improvements to workflows that already exist and that's",
    "start": "2102520",
    "end": "2107599"
  },
  {
    "text": "what I think we'll see a lot of in the Enterprise yeah definitely I agree you know I I kind of see the real power will",
    "start": "2107599",
    "end": "2112920"
  },
  {
    "text": "be not only automating the parts of the organization but automating the whole organization right so can we bring in",
    "start": "2112920",
    "end": "2119839"
  },
  {
    "text": "this AI you know power of AI into the system level where we can really start to see the synergic effect and benefits",
    "start": "2119839",
    "end": "2127119"
  },
  {
    "text": "right so there are entire industries that are propping up that I'm really excited by and one of them is Tech",
    "start": "2127119",
    "end": "2133280"
  },
  {
    "text": "enabled services companies so for example law firms they build by the hour",
    "start": "2133280",
    "end": "2138800"
  },
  {
    "text": "right like the the pure services and I'm incredibly excited by these new law firms that are popping up that are Tech",
    "start": "2138800",
    "end": "2145560"
  },
  {
    "text": "first and AI first and are fundamentally transforming the way that Services businesses run I think that'll be really",
    "start": "2145560",
    "end": "2151720"
  },
  {
    "text": "exciting to kind of start wrapping up this discussion do you have any recommendations or resource online that",
    "start": "2151720",
    "end": "2158720"
  },
  {
    "text": "our listeners can check out you know to learn about llms in general or any specific Technologies yes well obviously",
    "start": "2158720",
    "end": "2166359"
  },
  {
    "text": "you should listen to this podcast you should listen to more of this podcast we write a lot of blogs on our website and",
    "start": "2166359",
    "end": "2171960"
  },
  {
    "text": "if you are interested in quantization which is something that I mentioned we have an entire repo of free quantitized",
    "start": "2171960",
    "end": "2177640"
  },
  {
    "text": "models that are what we would call like Titan certified so these are the best Enterprise appropriate models that you",
    "start": "2177640",
    "end": "2183160"
  },
  {
    "text": "can use and go on our hugging face page huggingface Tian ml or something like that",
    "start": "2183160",
    "end": "2188280"
  },
  {
    "text": "and then also for courses of like starting to learn with llms there are a bunch of really good courses the hugging",
    "start": "2188280",
    "end": "2195359"
  },
  {
    "text": "face course in particular I think is quite good sounds good do you have any additional comments before we wrap up",
    "start": "2195359",
    "end": "2200920"
  },
  {
    "text": "today's discussion no it's been absolutely fantastic chatting to you and I'm really looking forward to listening",
    "start": "2200920",
    "end": "2206839"
  },
  {
    "text": "to your future podcast as well thanks Miriam thank you very much for joining this podcast it's been great to discuss",
    "start": "2206839",
    "end": "2212440"
  },
  {
    "text": "one of the very important topics in the AI space the self-hosted models and and",
    "start": "2212440",
    "end": "2218000"
  },
  {
    "text": "deployment of those models into production as we all know any software solution will require more rigor and",
    "start": "2218000",
    "end": "2225839"
  },
  {
    "text": "discipline after it goes into production right not just development phase but actually post production and post",
    "start": "2225839",
    "end": "2231480"
  },
  {
    "text": "deployment efforts are more more significant so thanks for uh sharing your thoughts on that and thank you for",
    "start": "2231480",
    "end": "2237040"
  },
  {
    "text": "listening to this podcast if you would like to learn more about AIML topics",
    "start": "2237040",
    "end": "2242160"
  },
  {
    "text": "check out the AIML and data engineering community page on info.com website I",
    "start": "2242160",
    "end": "2248160"
  },
  {
    "text": "encourage you to listen to the recent podcast and also check out the Articles and news items on the website thank you",
    "start": "2248160",
    "end": "2256920"
  },
  {
    "text": "[Music]",
    "start": "2259680",
    "end": "2275680"
  }
]
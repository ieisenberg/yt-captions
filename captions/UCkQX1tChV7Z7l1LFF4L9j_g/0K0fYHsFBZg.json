[
  {
    "start": "0",
    "end": "53000"
  },
  {
    "text": "hey everyone so I'm joy I'm a senior software engineer at a we pay if you",
    "start": "3950",
    "end": "9590"
  },
  {
    "text": "haven't heard about we pay we provide payment solutions for platform",
    "start": "9590",
    "end": "14840"
  },
  {
    "text": "businesses through our API so for this talk I'm going to be talking about database streaming we live in a world",
    "start": "14840",
    "end": "22580"
  },
  {
    "text": "where we expect kind of everything to be streamed right like our music is streamed our TV shows are streamed so I",
    "start": "22580",
    "end": "29900"
  },
  {
    "text": "want to argue that the data in our data warehouses should not be considered as second-class citizen we should allow",
    "start": "29900",
    "end": "36290"
  },
  {
    "text": "everything to be streamed in real time so that we can access these data as soon",
    "start": "36290",
    "end": "41629"
  },
  {
    "text": "as they arrive into the database so this talk is about our journey at we pay going from an ETL data pipeline into a",
    "start": "41629",
    "end": "48769"
  },
  {
    "text": "streaming based real-time pipeline the talk is going to be broken down into",
    "start": "48769",
    "end": "55670"
  },
  {
    "start": "53000",
    "end": "100000"
  },
  {
    "text": "three sections we're first going to kind of go over what our current the ETL prop",
    "start": "55670",
    "end": "61580"
  },
  {
    "text": "Remus ETL process look like and what are some of the pain points that we're going through we're also going to introduce",
    "start": "61580",
    "end": "68689"
  },
  {
    "text": "changes or capture which is how the mechanism that we use to stream data",
    "start": "68689",
    "end": "74149"
  },
  {
    "text": "from our database next we're going to take a look at a real world example which is how we're actually streaming",
    "start": "74149",
    "end": "81259"
  },
  {
    "text": "data from my sequel into our data warehouse and finally we're going to",
    "start": "81259",
    "end": "87079"
  },
  {
    "text": "kind of go a little experimental and take a look some of the ongoing work we're doing with streaming Cassandra",
    "start": "87079",
    "end": "92780"
  },
  {
    "text": "into bigquery which is our data warehouse as I mentioned let's get",
    "start": "92780",
    "end": "98240"
  },
  {
    "text": "started so ed we've hey we use the quarry for those of you who are in the",
    "start": "98240",
    "end": "104509"
  },
  {
    "start": "100000",
    "end": "167000"
  },
  {
    "text": "AWS eslint this is the equivalent of redshift so it's basically the Google",
    "start": "104509",
    "end": "110390"
  },
  {
    "text": "cloud data warehouse it uses NC compliant Seco as this query language",
    "start": "110390",
    "end": "116960"
  },
  {
    "text": "which makes it really easy for our developers and engineers to take up it supports nested and repeated data",
    "start": "116960",
    "end": "126049"
  },
  {
    "text": "structures for things like lists and or structs and even geospatial data types",
    "start": "126049",
    "end": "131750"
  },
  {
    "text": "which is actually something very useful for CDC as you will see later on and it has a material sorry a virtual",
    "start": "131750",
    "end": "140480"
  },
  {
    "text": "view feature which you can create meals on top of the base tables and because these views are not materialized when",
    "start": "140480",
    "end": "147470"
  },
  {
    "text": "you're occurring the view you're essentially querying the underlying table and this will allow you to access the data in real time sorry access",
    "start": "147470",
    "end": "154549"
  },
  {
    "text": "real-time data even through views and that's another feature that we're leveraging very heavily at we pay for",
    "start": "154549",
    "end": "161810"
  },
  {
    "text": "our streaming pipeline which we'll also go into later on so at we pay we use a",
    "start": "161810",
    "end": "169310"
  },
  {
    "start": "167000",
    "end": "629000"
  },
  {
    "text": "micro service architecture most of our micro services are stateful and the",
    "start": "169310",
    "end": "175310"
  },
  {
    "text": "states are typically stored into a my sequel database and we use air flow as a",
    "start": "175310",
    "end": "180890"
  },
  {
    "text": "tool to orchestrate our data pipelines for anyone who hasn't heard about air",
    "start": "180890",
    "end": "185900"
  },
  {
    "text": "flow you can kind of think of it as cron on steroids that's designed for data",
    "start": "185900",
    "end": "190910"
  },
  {
    "text": "pipelines and complex workflow and the way we're using air flow is basically by",
    "start": "190910",
    "end": "196160"
  },
  {
    "text": "periodically pulling the my Seco database for change the way we did we",
    "start": "196160",
    "end": "202819"
  },
  {
    "text": "detect these changes by looking at the modify time column in each table and if",
    "start": "202819",
    "end": "208700"
  },
  {
    "text": "the modify time has model has been changing the most recent interval we upload that information into bigquery",
    "start": "208700",
    "end": "214730"
  },
  {
    "text": "it's pretty standard with this approach though we're starting to hit a lot of",
    "start": "214730",
    "end": "219829"
  },
  {
    "text": "limitations and operational overhead so the first problem which ties back to the",
    "start": "219829",
    "end": "226790"
  },
  {
    "text": "talk from from the introduction is that it has very low latency or sorry very",
    "start": "226790",
    "end": "231950"
  },
  {
    "text": "high latency the data won't actually arrive into bigquery until much later some of our jobs we try to push the",
    "start": "231950",
    "end": "239810"
  },
  {
    "text": "limit to once every 15 minute so the job runs in 15 minute interval but then we",
    "start": "239810",
    "end": "247069"
  },
  {
    "text": "get into this inconsistency where analysts may be trying to do a join in bigquery and one of the table is being",
    "start": "247069",
    "end": "253819"
  },
  {
    "text": "uploaded on an hourly or daily basis and another table is being uploaded every 15 minutes and then the data becomes",
    "start": "253819",
    "end": "260150"
  },
  {
    "text": "inconsistency so it's like why is it not in this other table but it's here the second problem is that because the way",
    "start": "260150",
    "end": "266599"
  },
  {
    "text": "we use air flow you we're creating one job for every single",
    "start": "266599",
    "end": "272490"
  },
  {
    "text": "table an airflow a job is called a day or directed acyclic graph so we have",
    "start": "272490",
    "end": "279180"
  },
  {
    "text": "basically hundreds of decks each of them is responsible for a table and this is a",
    "start": "279180",
    "end": "285090"
  },
  {
    "text": "whole lot of operational or configurations as well as overhead when it comes to monitoring so it's not quite",
    "start": "285090",
    "end": "291300"
  },
  {
    "text": "ideal another problem is hard deletes we can't allow hard deletes in our database because when you're pulling a",
    "start": "291300",
    "end": "297750"
  },
  {
    "text": "database you're running these flat queries it's not going to generate which data has been deleted it's only going to",
    "start": "297750",
    "end": "303720"
  },
  {
    "text": "show you what's in the database so we basically have to tower micro-service owners about hey just don't delete",
    "start": "303720",
    "end": "310230"
  },
  {
    "text": "anything in these tables which is pretty error-prone and that's leads to the first point is that it is very",
    "start": "310230",
    "end": "315690"
  },
  {
    "text": "error-prone we are relying on our micro-service owners to be doing the",
    "start": "315690",
    "end": "320880"
  },
  {
    "text": "right thing not only do the must say not delete rows from this table which they",
    "start": "320880",
    "end": "326160"
  },
  {
    "text": "must be able to guarantee that they're always updating the modify time step every time because otherwise we'll still",
    "start": "326160",
    "end": "331680"
  },
  {
    "text": "get into data inconsistency issue because we won't be able to detect those changes finally the schema management is",
    "start": "331680",
    "end": "339630"
  },
  {
    "text": "actually manual because if it Evi decides to go into the database and they",
    "start": "339630",
    "end": "345210"
  },
  {
    "text": "want to say add a column to a table air flow doesn't know about it so now we",
    "start": "345210",
    "end": "350580"
  },
  {
    "text": "have to go into air flow and we have to manage every single one of those tables or pop whichever table that needs to be",
    "start": "350580",
    "end": "356880"
  },
  {
    "text": "modified and we have to update the schema so that it propagates the big query and so on on top of all these",
    "start": "356880",
    "end": "363960"
  },
  {
    "text": "problems where our data ecosystem is constantly evolving we are adding new",
    "start": "363960",
    "end": "370560"
  },
  {
    "text": "tools that are optimized for different jobs we may introduce a Redis that optimizes for key value cache we may",
    "start": "370560",
    "end": "377580"
  },
  {
    "text": "introduce elastic search to do full-text search we may want to add a graph database for fraud detection or we may",
    "start": "377580",
    "end": "384060"
  },
  {
    "text": "want to add some live dashboards and alert the monitoring system that helped us understand how our business is doing",
    "start": "384060",
    "end": "391290"
  },
  {
    "text": "right now and airflow being a batch oriented tool it's not meant for",
    "start": "391290",
    "end": "396930"
  },
  {
    "text": "streaming so we needed a better tool for this job and as many of you probably already guessed it",
    "start": "396930",
    "end": "402750"
  },
  {
    "text": "or if you already read the summary in the to talk we use Kafka with calf canal",
    "start": "402750",
    "end": "409320"
  },
  {
    "text": "every single downstream derived application can now just listen to the",
    "start": "409320",
    "end": "414480"
  },
  {
    "text": "Kafka log and apply the changes at their own pace which is really nice and because Kafka is designed for streaming",
    "start": "414480",
    "end": "421500"
  },
  {
    "text": "to solve the streaming problem the next question is we know that we're going to be using Kafka the question is how are",
    "start": "421500",
    "end": "428340"
  },
  {
    "text": "we getting the data from these databases into Kafka there's a couple options",
    "start": "428340",
    "end": "433640"
  },
  {
    "text": "first one we can just double right about system right every time we're updating the database we make sure we're also",
    "start": "433640",
    "end": "439110"
  },
  {
    "text": "sending a message to Kafka then the question is should we do this synchronously or asynchronously if we",
    "start": "439110",
    "end": "446580"
  },
  {
    "text": "update asynchronously we'll again getting to data inconsistent issues because we don't know whether the data",
    "start": "446580",
    "end": "453480"
  },
  {
    "text": "has been successfully written into Kafka when we're doing the updating to the database if we do this synchronously",
    "start": "453480",
    "end": "459600"
  },
  {
    "text": "which means that every time we successfully sends to Kafka we commit the change every time we fail to send to",
    "start": "459600",
    "end": "467100"
  },
  {
    "text": "Kafka we abort the change but we're talking about distributed systems here and errors are our friends the problem",
    "start": "467100",
    "end": "474480"
  },
  {
    "text": "is timeouts timeouts is something that we don't quite know whether the change",
    "start": "474480",
    "end": "480330"
  },
  {
    "text": "it could be a network glitch that I essentially cost a timeout and the data could have been successfully running to",
    "start": "480330",
    "end": "485400"
  },
  {
    "text": "Kafka or it could have not so we wouldn't know what to do and to solve that properly that required distributed",
    "start": "485400",
    "end": "491850"
  },
  {
    "text": "transaction which means something like two-phase commit and two-phase commit is",
    "start": "491850",
    "end": "497400"
  },
  {
    "text": "not trivial to implement and get right it requires a set of interfaces or so I",
    "start": "497400",
    "end": "502470"
  },
  {
    "text": "set up two interfaces and tools to actually implement it and the vanilla Kafka doesn't support it and not to",
    "start": "502470",
    "end": "508560"
  },
  {
    "text": "mention that with two-phase commit it means it requires multiple round-trip to do a consensus in order to have each",
    "start": "508560",
    "end": "515729"
  },
  {
    "text": "right to commit it and that's going to take a lot of time and a lot of production database cannot allow that",
    "start": "515729",
    "end": "520979"
  },
  {
    "text": "kind of latency there's the second option this is a cool kid on the club",
    "start": "520979",
    "end": "526290"
  },
  {
    "text": "event sourcing right which means we're using Kafka is a source of truth every time we write it we only write the data",
    "start": "526290",
    "end": "533130"
  },
  {
    "text": "into Kafka we're going to treat the database just like any other derived system the",
    "start": "533130",
    "end": "538530"
  },
  {
    "text": "database is just going to be pulling changes from this kafka log and it's going to apply them into the database",
    "start": "538530",
    "end": "544800"
  },
  {
    "text": "one by one this looked much cleaner and it will solve a lot of headaches however",
    "start": "544800",
    "end": "550410"
  },
  {
    "text": "there is one problem with this for some use cases and it's called its rape your",
    "start": "550410",
    "end": "556530"
  },
  {
    "text": "read your right consistency reach your right consistency is idea that when",
    "start": "556530",
    "end": "561930"
  },
  {
    "text": "you're updating some data and you're trying to read from what you've just updated you're expected to get what you",
    "start": "561930",
    "end": "567720"
  },
  {
    "text": "just wrote but with this setup we're actually may potentially be reading",
    "start": "567720",
    "end": "572730"
  },
  {
    "text": "stale data because say if we have a traffic spike and we have a bunch of data that are being sent into Kafka and",
    "start": "572730",
    "end": "579600"
  },
  {
    "text": "then the database is slow at catching up so at that point if we're trying to do a read we're going to be reading stale",
    "start": "579600",
    "end": "585420"
  },
  {
    "text": "data so that's really bad when you're building an application like an account",
    "start": "585420",
    "end": "592200"
  },
  {
    "text": "balance where you need to guarantee that your users are not withdrawing money to go into negative balance and that's this",
    "start": "592200",
    "end": "598950"
  },
  {
    "text": "is problematic for that then there is the third option which is change you to",
    "start": "598950",
    "end": "605220"
  },
  {
    "text": "capture using the right head log so change the capture is a design pattern in databases that basically says every",
    "start": "605220",
    "end": "613200"
  },
  {
    "text": "single page that basically captures every single database changes into a stream of change events and then anyone",
    "start": "613200",
    "end": "619740"
  },
  {
    "text": "that is interested in these change events can listen to the change and up and react accordingly and we mentioned",
    "start": "619740",
    "end": "626580"
  },
  {
    "text": "we're going to do this with the right head log so red head log is pretty much implemented in every single database out",
    "start": "626580",
    "end": "633570"
  },
  {
    "start": "629000",
    "end": "749000"
  },
  {
    "text": "there it's kind of an implementation detail of each database rather than an",
    "start": "633570",
    "end": "638610"
  },
  {
    "text": "API and the idea of the right head log is that before we update the data into",
    "start": "638610",
    "end": "644250"
  },
  {
    "text": "the storage file we're first going to update them into the right ahead log just like the name sounds and there are",
    "start": "644250",
    "end": "651390"
  },
  {
    "text": "some benefits to this approach the first is crash recovery now if we if the",
    "start": "651390",
    "end": "656880"
  },
  {
    "text": "database crashes halfway while writing the data into the storage file the data",
    "start": "656880",
    "end": "662010"
  },
  {
    "text": "base upon restart can look at the commit log replay the change restore the",
    "start": "662010",
    "end": "667230"
  },
  {
    "text": "corrupted data so that's great the second benefit is in improving write performance in certain",
    "start": "667230",
    "end": "672520"
  },
  {
    "text": "scenario this is the case where you have a single transaction but you're updating a lot of database a lot of tables and",
    "start": "672520",
    "end": "679330"
  },
  {
    "text": "these table probably reside on different storage files so instead of trying to",
    "start": "679330",
    "end": "684899"
  },
  {
    "text": "update on each of those table individually its first going to sequentially write all of those changing",
    "start": "684899",
    "end": "690580"
  },
  {
    "text": "to this log that's only a single sync versus of syncing on each of those individual storage log so it's much",
    "start": "690580",
    "end": "698200"
  },
  {
    "text": "faster the third benefit is streaming replication a lot of database already",
    "start": "698200",
    "end": "703630"
  },
  {
    "text": "applies is like my sequel where all the replicas are just looking at the commit log and tail and telling the commit log",
    "start": "703630",
    "end": "709810"
  },
  {
    "text": "applying the change and then updating these replicas asynchronously one other",
    "start": "709810",
    "end": "717100"
  },
  {
    "text": "detail that's worth mentioning about the right head log is specifically for my",
    "start": "717100",
    "end": "722620"
  },
  {
    "text": "sequel is that it gives you two options you can either lock statement you can",
    "start": "722620",
    "end": "727660"
  },
  {
    "text": "either do statement based logging or you can do row based logging statement based logging means you're logging the",
    "start": "727660",
    "end": "733420"
  },
  {
    "text": "quarries and row based doggy means you're actually logging the data after the change has been applied and in terms",
    "start": "733420",
    "end": "739420"
  },
  {
    "text": "of changes the capture row based logging is very useful since now you know you have the data for the entire row not",
    "start": "739420",
    "end": "745810"
  },
  {
    "text": "just a column you've updated so by using",
    "start": "745810",
    "end": "751149"
  },
  {
    "start": "749000",
    "end": "789000"
  },
  {
    "text": "changes to capture with the right head lock we get the best of all the worlds we don't have to worry about",
    "start": "751149",
    "end": "756250"
  },
  {
    "text": "implementing distributed transaction but we get all of the transactional guarantees and because we're",
    "start": "756250",
    "end": "762610"
  },
  {
    "text": "asynchronously tailing this commit log or sorry not commit like this my secret my sequel bin log or some kind of right",
    "start": "762610",
    "end": "769839"
  },
  {
    "text": "head log we don't have to worry about impacting the performance when we're",
    "start": "769839",
    "end": "775089"
  },
  {
    "text": "writing the data into the database because it's asynchronous now let's take",
    "start": "775089",
    "end": "781600"
  },
  {
    "text": "a look at how exactly we are using CDC for add we pay to stream database from",
    "start": "781600",
    "end": "787779"
  },
  {
    "text": "IC go into bigquery so we use under the hood we use caf-co connect framework or",
    "start": "787779",
    "end": "794529"
  },
  {
    "start": "789000",
    "end": "841000"
  },
  {
    "text": "we leverage cough connect framework for this job the source connector is responsible for getting",
    "start": "794529",
    "end": "801410"
  },
  {
    "text": "from external sources and publishing them into Kafka the sink connector is responsible for reading from Kafka and",
    "start": "801410",
    "end": "808240"
  },
  {
    "text": "storing them into external sinks applied at we pay our source our source data is",
    "start": "808240",
    "end": "815600"
  },
  {
    "text": "my sequel our data sink is bigquery our source connector is the bzm which is an",
    "start": "815600",
    "end": "822680"
  },
  {
    "text": "open source project and our data sink is KC BQ which stands for Kafka connect big quarry it's something we named ourselves",
    "start": "822680",
    "end": "829310"
  },
  {
    "text": "because we wrote it and we're going to break this up into two sections and talk about each part of them separately so",
    "start": "829310",
    "end": "836980"
  },
  {
    "text": "first my sequel into Kafka and we have to definitely talk about the bzm before",
    "start": "836980",
    "end": "843949"
  },
  {
    "start": "841000",
    "end": "888000"
  },
  {
    "text": "going to any details so the BGM is an open source project it's basically meant for CDC on top and",
    "start": "843949",
    "end": "852889"
  },
  {
    "text": "it's built on top of a cough connect framework and the way it does this is by basically just like CDC readings right",
    "start": "852889",
    "end": "860449"
  },
  {
    "text": "headlock and converting them into individual changes and record them on the rollable basis a division guarantees",
    "start": "860449",
    "end": "868910"
  },
  {
    "text": "at least one semantics which is the same guarantee as Kafka and this means we",
    "start": "868910",
    "end": "874850"
  },
  {
    "text": "don't have to worry about whatever loose data but we may potentially get duplicates and finally the medium",
    "start": "874850",
    "end": "881120"
  },
  {
    "text": "currently already supports my sequel MongoDB Postgres Oracle and sequel",
    "start": "881120",
    "end": "886430"
  },
  {
    "text": "server so how does the medium look like in action before we started the BGM",
    "start": "886430",
    "end": "894439"
  },
  {
    "start": "888000",
    "end": "971000"
  },
  {
    "text": "connector we probably already have some database running in production it's priority replicating to some replicas so",
    "start": "894439",
    "end": "900259"
  },
  {
    "text": "when we first start the connector it's going to ask the database to give it the",
    "start": "900259",
    "end": "905689"
  },
  {
    "text": "possess the file name and the position of the most recent write and it's going",
    "start": "905689",
    "end": "911059"
  },
  {
    "text": "to record that information next it's going to run a select star from table",
    "start": "911059",
    "end": "919040"
  },
  {
    "text": "every single table from the database and it's going to convert the result set into individual create event and publish",
    "start": "919040",
    "end": "927559"
  },
  {
    "text": "these events into Kafka and because some tables are huge this could potentially",
    "start": "927559",
    "end": "932630"
  },
  {
    "text": "take a couple hours and during this time the database may be right maybe having additional rights and",
    "start": "932630",
    "end": "940250"
  },
  {
    "text": "that maybe replicating to the database to the replica and my sequel sorry and the museum is just going to temporarily",
    "start": "940250",
    "end": "946220"
  },
  {
    "text": "ignore that once the snapshotting is complete the medium is going to start to catch up and",
    "start": "946220",
    "end": "952730"
  },
  {
    "text": "it knows where to catch out because they recorded the filename and the position of the most recent right and then once",
    "start": "952730",
    "end": "959450"
  },
  {
    "text": "it's finally caught up it will start streaming the data in real time just like any other replica except instead of",
    "start": "959450",
    "end": "965990"
  },
  {
    "text": "storing the information it's sending that information to Kafka so let's take",
    "start": "965990",
    "end": "973280"
  },
  {
    "start": "971000",
    "end": "1028000"
  },
  {
    "text": "a look at what a DBZ event looks like the before section is what the data",
    "start": "973280",
    "end": "978470"
  },
  {
    "text": "looks like before the change after section is what the data looks like after the change the source section",
    "start": "978470",
    "end": "984800"
  },
  {
    "text": "provides a bunch of metadata about the data source so like the server ID and",
    "start": "984800",
    "end": "991190"
  },
  {
    "text": "the file name and positions as well as the database and the table that's coming from and if you're familiar with my",
    "start": "991190",
    "end": "998000"
  },
  {
    "text": "sequel since 5.6 it introduced GT ID so this is actually able to support GT ID",
    "start": "998000",
    "end": "1003970"
  },
  {
    "text": "as well instead of using the file name and position the OP section represents",
    "start": "1003970",
    "end": "1010510"
  },
  {
    "text": "the type of operation used for updates these four create and these four delete and the timestamp is the timestamp of",
    "start": "1010510",
    "end": "1017620"
  },
  {
    "text": "when this event was created in the BGM if it's a create event before what we",
    "start": "1017620",
    "end": "1023680"
  },
  {
    "text": "know if it's a delete event after would be now so this original pipeline I",
    "start": "1023680",
    "end": "1032560"
  },
  {
    "start": "1028000",
    "end": "1169000"
  },
  {
    "text": "showed you at the very start it's pretty different from we're actually running in production it's a little bit more",
    "start": "1032560",
    "end": "1039069"
  },
  {
    "text": "complicated than this let's take a look at why so for we're not going to",
    "start": "1039070",
    "end": "1044620"
  },
  {
    "text": "basically directly reading from the my sequel in production sorry the production the master of the my sequel",
    "start": "1044620",
    "end": "1051760"
  },
  {
    "text": "instance because we can potentially have snapshot that could take hours we don't",
    "start": "1051760",
    "end": "1057190"
  },
  {
    "text": "want to impact the performance so we set up a my sequel replica and we disturb",
    "start": "1057190",
    "end": "1062500"
  },
  {
    "text": "replica is dedicated for the medium and we're just going to be tailing from the the replica but having just one replica",
    "start": "1062500",
    "end": "1070480"
  },
  {
    "text": "is not enough because what if it goes down so we set up a secondary replicas and this is responsible to in case the",
    "start": "1070480",
    "end": "1078010"
  },
  {
    "text": "primary is down in order to handle failover we add a proxy in front of it so that if the primary is down we read",
    "start": "1078010",
    "end": "1086139"
  },
  {
    "text": "from the secondary instead but of course we don't just have a single micro service we have many micro services and",
    "start": "1086139",
    "end": "1093610"
  },
  {
    "text": "each one of them will be replicating to the same primary and secondary my sequel",
    "start": "1093610",
    "end": "1098889"
  },
  {
    "text": "replicas and the reason that we're doing we're using just a single cluster of",
    "start": "1098889",
    "end": "1104049"
  },
  {
    "text": "primary and secondary replicas for the BDM is for operational cost we we know",
    "start": "1104049",
    "end": "1110559"
  },
  {
    "text": "that as we add more micro services this could potentially become problematic and",
    "start": "1110559",
    "end": "1115659"
  },
  {
    "text": "we may potentially add additional cluster as well but for now this is sufficient for us because we're a",
    "start": "1115659",
    "end": "1121360"
  },
  {
    "text": "start-up but even though we only have a",
    "start": "1121360",
    "end": "1126429"
  },
  {
    "text": "single the BDM dedicated my sequel rep cluster we do have a individual the BDM",
    "start": "1126429",
    "end": "1134049"
  },
  {
    "text": "connector for that corresponds to every single one of those micro service and this is important because it allow us to",
    "start": "1134049",
    "end": "1140559"
  },
  {
    "text": "configure each micro service the medium connector based on what works for that",
    "start": "1140559",
    "end": "1146289"
  },
  {
    "text": "particular connector and it also allow us to bring up and down a specific connector in the case we're doing any",
    "start": "1146289",
    "end": "1153370"
  },
  {
    "text": "kind of troubleshooting without affecting the rest of what the entire streaming pipeline basically and we run",
    "start": "1153370",
    "end": "1160570"
  },
  {
    "text": "these connectors in distributed mode forethought tolerance so this is what it actually looks like in production just a",
    "start": "1160570",
    "end": "1166779"
  },
  {
    "text": "little bit more complicated now that we got our data into Kafka the next",
    "start": "1166779",
    "end": "1172240"
  },
  {
    "text": "question is how are we getting the data from Kafka into bigquery as the reason",
    "start": "1172240",
    "end": "1178120"
  },
  {
    "text": "we built kcb queue is because at the time there was no existing bigquery caf-co to bigquery connector we have",
    "start": "1178120",
    "end": "1186460"
  },
  {
    "start": "1186000",
    "end": "1298000"
  },
  {
    "text": "open sources so if you're interested it's there on the web hey github there's a couple nice features about this",
    "start": "1186460",
    "end": "1192399"
  },
  {
    "text": "connector first of all it has a conservative configurable rich high logic which means that",
    "start": "1192399",
    "end": "1199450"
  },
  {
    "text": "Vickery will sometimes give you these three tribal transient errors and the",
    "start": "1199450",
    "end": "1204909"
  },
  {
    "text": "connector is intelligent enough to know about it and it's going to retry in order to not drop any messages but",
    "start": "1204909",
    "end": "1212169"
  },
  {
    "text": "because sometimes this error could last for a while we've implemented the retry logic with exponential back-off so that",
    "start": "1212169",
    "end": "1218379"
  },
  {
    "text": "it won't have to hit the API too frequently in the case it's down for a long time",
    "start": "1218379",
    "end": "1224589"
  },
  {
    "text": "secondly this case ebq is capable of lazily updating the schema for our",
    "start": "1224589",
    "end": "1231489"
  },
  {
    "text": "tables what the lazily means here is that the beta meets table is actually",
    "start": "1231489",
    "end": "1237249"
  },
  {
    "text": "going to cache the schema for every single table as for every single table",
    "start": "1237249",
    "end": "1242589"
  },
  {
    "text": "and when the new message arrived is going to leverage the the data in that",
    "start": "1242589",
    "end": "1247809"
  },
  {
    "text": "cache and it's going to try to send a message to bigquery with the version in cache in a case where it gets the schema",
    "start": "1247809",
    "end": "1255789"
  },
  {
    "text": "error back and knows that the schema is outdated it will then go fetch the latest schema from the schema registry",
    "start": "1255789",
    "end": "1262599"
  },
  {
    "text": "and it will retry again with that latest schema so that helped us deal with automatic schema evolution and finally",
    "start": "1262599",
    "end": "1271169"
  },
  {
    "text": "KC PQ supports both batch and streaming based uploading or it basically uses bit",
    "start": "1271169",
    "end": "1279309"
  },
  {
    "text": "queries batch API and the queries streaming insertion API the benefit of",
    "start": "1279309",
    "end": "1284469"
  },
  {
    "text": "the batch API is when you're doing snapshotting it's the more faster option and when the snapshot is complete you",
    "start": "1284469",
    "end": "1289869"
  },
  {
    "text": "can then basically flip the switch to use the streaming based API which allow",
    "start": "1289869",
    "end": "1294909"
  },
  {
    "text": "you to access data in real time there is one additional information that we had",
    "start": "1294909",
    "end": "1301509"
  },
  {
    "start": "1298000",
    "end": "1316000"
  },
  {
    "text": "to add to the KC BQE event and that's the Kafka offset I'll explain why in a",
    "start": "1301509",
    "end": "1306729"
  },
  {
    "text": "second but the Kafka offset if you're not familiar with it it's essentially the position of this offset of this",
    "start": "1306729",
    "end": "1313209"
  },
  {
    "text": "record in Kafka so here is what a table",
    "start": "1313209",
    "end": "1319209"
  },
  {
    "start": "1316000",
    "end": "1413000"
  },
  {
    "text": "an example table looks like when we're querying for all the field in this table and I've also include Kafka officer",
    "start": "1319209",
    "end": "1326919"
  },
  {
    "text": "offset there as well notice that this is actually not very useful we're getting every single",
    "start": "1326919",
    "end": "1333040"
  },
  {
    "text": "record every single change event what we really want is just the final change so",
    "start": "1333040",
    "end": "1340540"
  },
  {
    "text": "we leveraged Kafka offsets to to do deduplication and compression and",
    "start": "1340540",
    "end": "1346030"
  },
  {
    "text": "determine what is that we actually need to show to the user the reason we can trust the Kafka offset is because the",
    "start": "1346030",
    "end": "1353140"
  },
  {
    "text": "data are partitioned by primary key so an in Kafka anything in a partition is",
    "start": "1353140",
    "end": "1360520"
  },
  {
    "text": "guaranteed to be ordered so now we know that any data was a larger offset arrived at a later time so is the calf",
    "start": "1360520",
    "end": "1368530"
  },
  {
    "text": "offset we can now do per data by primary key and we now have a version that",
    "start": "1368530",
    "end": "1374440"
  },
  {
    "text": "mirrors what's in bigquery an additional benefit of using bigquery view is that",
    "start": "1374440",
    "end": "1381660"
  },
  {
    "text": "we can actually mask any of columns that we don't want to see because for example",
    "start": "1381660",
    "end": "1387730"
  },
  {
    "text": "email is PII sensitive data and we don't want certain most the user to see this",
    "start": "1387730",
    "end": "1393790"
  },
  {
    "text": "information we create another view on top of our the view I showed you guys",
    "start": "1393790",
    "end": "1398860"
  },
  {
    "text": "earlier and this view does not have the email information and because bigquery",
    "start": "1398860",
    "end": "1404860"
  },
  {
    "text": "has access control configuration so we can give different user different permissions to different tables there is",
    "start": "1404860",
    "end": "1414070"
  },
  {
    "start": "1413000",
    "end": "1477000"
  },
  {
    "text": "one final piece in this pipeline that I briefly mentioned but in really getting to and that's the schema registry so at",
    "start": "1414070",
    "end": "1420700"
  },
  {
    "text": "we pay we use the confluence schema registry and this is basically a registry that store a version history of",
    "start": "1420700",
    "end": "1427390"
  },
  {
    "text": "all of the data schemas what's really cool about the confluence schema registry is that a dog foods on Kafka",
    "start": "1427390",
    "end": "1434560"
  },
  {
    "text": "what that means is that it uses Kafka as its underlying storage for all of the",
    "start": "1434560",
    "end": "1439570"
  },
  {
    "text": "schemas so you don't have to spin up a new storage engine or database of some sort to handle schema and schema",
    "start": "1439570",
    "end": "1447250"
  },
  {
    "text": "registry supports Apache Avro as it's the serialization format which",
    "start": "1447250",
    "end": "1452320"
  },
  {
    "text": "guarantees both forward and backward compatibility which is always a good thing and finally we don't want our",
    "start": "1452320",
    "end": "1458620"
  },
  {
    "text": "schema registry to become our single point of failure because that defeats the whole purpose of a resilient",
    "start": "1458620",
    "end": "1464230"
  },
  {
    "text": "pipeline and the schema registry is the designed to be post distributed a single master a laboratory zookeeper to to do",
    "start": "1464230",
    "end": "1472360"
  },
  {
    "text": "any kind of failover but essentially it is resilient to failure to put it all",
    "start": "1472360",
    "end": "1478210"
  },
  {
    "start": "1477000",
    "end": "1546000"
  },
  {
    "text": "together here is what schema evolution looks like we have also before that one thing worth",
    "start": "1478210",
    "end": "1485140"
  },
  {
    "text": "mentioning is that implemented my sequel bin log doesn't just store the data change it also stores every single",
    "start": "1485140",
    "end": "1491560"
  },
  {
    "text": "schema change this is really useful because now the B's iam a pound receiving a schema change it's going to",
    "start": "1491560",
    "end": "1498460"
  },
  {
    "text": "cache this schema change and it's going to update this information to schema",
    "start": "1498460",
    "end": "1504250"
  },
  {
    "text": "registry any following information that are any following data change events it",
    "start": "1504250",
    "end": "1509650"
  },
  {
    "text": "receives it can now use this new cached version of the schema instead and so by",
    "start": "1509650",
    "end": "1516700"
  },
  {
    "text": "the time the data gets into case ebq case speaker doesn't know about the schema change yet so it's just going to",
    "start": "1516700",
    "end": "1523270"
  },
  {
    "text": "send the data with its oder cached version but bigquery is gonna give us an error saying the schema is wrong and",
    "start": "1523270",
    "end": "1530170"
  },
  {
    "text": "case speak you can now fetch the latest schema from the schema registry and then send this in for send the data to",
    "start": "1530170",
    "end": "1537100"
  },
  {
    "text": "bigquery using this new schema so that completes this automatic schema",
    "start": "1537100",
    "end": "1543070"
  },
  {
    "text": "evolution which is really useful okay so as I mentioned this final part is going",
    "start": "1543070",
    "end": "1550270"
  },
  {
    "start": "1546000",
    "end": "1561000"
  },
  {
    "text": "to be a little bit experimental as it's something we're currently working on but it's interesting enough and relevant",
    "start": "1550270",
    "end": "1556150"
  },
  {
    "text": "relevant enough to CDC and I'm really excited to share it with you guys so we",
    "start": "1556150",
    "end": "1562150"
  },
  {
    "text": "pay as her company guru we began to see a need for a no sequel database that's",
    "start": "1562150",
    "end": "1568060"
  },
  {
    "text": "optimized for high right throughput for horizontal scalability and for high availability and Kafka became the",
    "start": "1568060",
    "end": "1575680"
  },
  {
    "text": "obvious top contender by introducing Kafka to our stack though we also need",
    "start": "1575680",
    "end": "1581350"
  },
  {
    "text": "to figure out how we want to do CDC for Kafka at first we thought we figured this out for my sequel how hard could it",
    "start": "1581350",
    "end": "1587890"
  },
  {
    "text": "be it turns out that it's a little bit more complicated and for because this",
    "start": "1587890",
    "end": "1594370"
  },
  {
    "text": "talk is not a Cassandra focused talk it's going to be I'm going to be skipping over",
    "start": "1594370",
    "end": "1600050"
  },
  {
    "text": "a lot of details on Cassandra I'm only going to talk about the Cassandra stuff that are directly related to CDC so the",
    "start": "1600050",
    "end": "1607730"
  },
  {
    "start": "1606000",
    "end": "1689000"
  },
  {
    "text": "thing that makes Cassandra really difficult for change data capture is its",
    "start": "1607730",
    "end": "1613370"
  },
  {
    "text": "replication model unlike my sequel which uses primary replicas replication model",
    "start": "1613370",
    "end": "1620320"
  },
  {
    "text": "Cassandra uses a peer-to-peer replication model this means that all the nodes are equal it also means that",
    "start": "1620320",
    "end": "1627020"
  },
  {
    "text": "every single node is able to handle both reads and writes and this also means",
    "start": "1627020",
    "end": "1632360"
  },
  {
    "text": "that if we look at the data in a single node it only contains a subset of the",
    "start": "1632360",
    "end": "1637610"
  },
  {
    "text": "entire cluster of nodes and which makes sense right because that's how you do",
    "start": "1637610",
    "end": "1643220"
  },
  {
    "text": "horizontal scale scalability you don't want a note to contain all the data so",
    "start": "1643220",
    "end": "1650990"
  },
  {
    "text": "the next question is how exactly then this Cassandra determine where each data",
    "start": "1650990",
    "end": "1656180"
  },
  {
    "text": "which notice each data go into so the",
    "start": "1656180",
    "end": "1661880"
  },
  {
    "text": "way Cassandra handles this is that it divides the data into a cluster of nodes",
    "start": "1661880",
    "end": "1667400"
  },
  {
    "text": "it's typically visualized as a ring and each of the node in this ring is",
    "start": "1667400",
    "end": "1672920"
  },
  {
    "text": "responsible for a subset of all the data and it's called the token range so in",
    "start": "1672920",
    "end": "1679580"
  },
  {
    "text": "this night naive example we have a total possible token values from 0 to 19 and",
    "start": "1679580",
    "end": "1685250"
  },
  {
    "text": "each node is responsible for a quarter of them so when a request comes in it's",
    "start": "1685250",
    "end": "1692990"
  },
  {
    "start": "1689000",
    "end": "1749000"
  },
  {
    "text": "going to have a primary key or partition key value the reason there is always going to be a partition key is because",
    "start": "1692990",
    "end": "1699170"
  },
  {
    "text": "because cassandra tables sorry Cassandra schemas require you to specify a partition key for every single table so",
    "start": "1699170",
    "end": "1706670"
  },
  {
    "text": "in this case the part the partition key is foo and one of the node is going to",
    "start": "1706670",
    "end": "1713330"
  },
  {
    "text": "be picked at the coordinator node the job of the coordinator node is to hash this partition key converted into a",
    "start": "1713330",
    "end": "1721190"
  },
  {
    "text": "token value and depending on what this token value is the coordinator is going",
    "start": "1721190",
    "end": "1727040"
  },
  {
    "text": "to forward this information this request to the node that is responsible for writing this",
    "start": "1727040",
    "end": "1733210"
  },
  {
    "text": "but what if this note si dies then this is no longer thought tolerant so the way",
    "start": "1733210",
    "end": "1741940"
  },
  {
    "text": "Cassandra's softest is by increasing the replication factor this example here has",
    "start": "1741940",
    "end": "1747160"
  },
  {
    "text": "a replication factor of 1 in reality we it typically has a reputation factor of",
    "start": "1747160",
    "end": "1753610"
  },
  {
    "start": "1749000",
    "end": "1791000"
  },
  {
    "text": "3 with the replication factor of 3 the way the cassandra' distributed this this",
    "start": "1753610",
    "end": "1759130"
  },
  {
    "text": "token range is by walking along this token ring and then basically replicate",
    "start": "1759130",
    "end": "1766840"
  },
  {
    "text": "this range to its neighbors until the replication factor has reached there are more sophisticated of distribution but",
    "start": "1766840",
    "end": "1772720"
  },
  {
    "text": "this is just a naive example and with this approach now this when the",
    "start": "1772720",
    "end": "1779050"
  },
  {
    "text": "coordinator is forwarding the data stream of these 4 nodes are actually going to all store this data so now we",
    "start": "1779050",
    "end": "1785200"
  },
  {
    "text": "don't have to worry about not being able to write when one of the node is down",
    "start": "1785200",
    "end": "1791040"
  },
  {
    "start": "1791000",
    "end": "1812000"
  },
  {
    "text": "how does this relate to CDC well there is actually also a right ahead login",
    "start": "1791040",
    "end": "1796480"
  },
  {
    "text": "every single one of these node in the cluster and this is called a commit log",
    "start": "1796480",
    "end": "1802120"
  },
  {
    "text": "in Cassandra this commit log will only record the data the rights that are",
    "start": "1802120",
    "end": "1808330"
  },
  {
    "text": "specific to that note and then the way",
    "start": "1808330",
    "end": "1813820"
  },
  {
    "start": "1812000",
    "end": "1829000"
  },
  {
    "text": "we can actually handle CDC is that we can put one agent a CDC agent in each of",
    "start": "1813820",
    "end": "1820420"
  },
  {
    "text": "these node and this agent is going to be responsible for reading the data from",
    "start": "1820420",
    "end": "1825850"
  },
  {
    "text": "this commit log and sending them off into Kafka in fact since cassandra is",
    "start": "1825850",
    "end": "1831610"
  },
  {
    "start": "1829000",
    "end": "1862000"
  },
  {
    "text": "3.0 they actually introduced a feature a CDC feature and this feature provides us with a file reader and the file read",
    "start": "1831610",
    "end": "1838810"
  },
  {
    "text": "Handler and the handler is already deserialized this information from the",
    "start": "1838810",
    "end": "1844420"
  },
  {
    "text": "commit log so we thought all we have to do then is to take this mutation which would is what the color change of event",
    "start": "1844420",
    "end": "1850930"
  },
  {
    "text": "extract the data that we care about converting to a bro package it and then",
    "start": "1850930",
    "end": "1856210"
  },
  {
    "text": "send it off to Kafka but as you're probably already thinking there are a couple problem with this approach first",
    "start": "1856210",
    "end": "1864340"
  },
  {
    "start": "1862000",
    "end": "1993000"
  },
  {
    "text": "of all we get duplicated change of event because we have a replication factor of",
    "start": "1864340",
    "end": "1870230"
  },
  {
    "text": "three when we're reading from all these locks we're going to get three copies of all the data so somewhere down in our",
    "start": "1870230",
    "end": "1876559"
  },
  {
    "text": "pipeline we need to figure out how to do the deduplication second problem is out",
    "start": "1876559",
    "end": "1881659"
  },
  {
    "text": "of order events this Y is a little bit more subtle because we're dealing with distributed system here it is possible",
    "start": "1881659",
    "end": "1888769"
  },
  {
    "text": "that when two different clients are writing to the same row at the same time but to do two different values in this",
    "start": "1888769",
    "end": "1895700"
  },
  {
    "text": "case maybe one client is changing the first name to N and the other clients changing the first name to Alice and not",
    "start": "1895700",
    "end": "1902690"
  },
  {
    "text": "want to note to receive Alice first and then end while notes three receives and first and then Alice now these three",
    "start": "1902690",
    "end": "1909590"
  },
  {
    "text": "different notes actually have a different understanding of what's the most recent data the way cassandra",
    "start": "1909590",
    "end": "1915080"
  },
  {
    "text": "cleverly hen doses is using the concept of last right wing so when a client is",
    "start": "1915080",
    "end": "1921309"
  },
  {
    "text": "sending a request they actually generate a client-side timestamp and this time",
    "start": "1921309",
    "end": "1926869"
  },
  {
    "text": "stem gets propagated into every single column of these of this row of the data",
    "start": "1926869",
    "end": "1933309"
  },
  {
    "text": "so this way when the client is reading the data from these nodes if it sees the",
    "start": "1933309",
    "end": "1938809"
  },
  {
    "text": "discrepancy between two or more notes it's going to always take the latest the",
    "start": "1938809",
    "end": "1945080"
  },
  {
    "text": "row is the latest timestamp but because our CDC pipe line is outside of the read",
    "start": "1945080",
    "end": "1951440"
  },
  {
    "text": "path of Cassandra we have to basically figure out how to do this ourselves third problem is incomplete change of",
    "start": "1951440",
    "end": "1959389"
  },
  {
    "text": "event Cassandra is optimized for write so unlike my sequel where it's going to",
    "start": "1959389",
    "end": "1964580"
  },
  {
    "text": "do a read before every single right Cassandra is just going to blindly write the data into the database and because",
    "start": "1964580",
    "end": "1970879"
  },
  {
    "text": "of this we're only going to know the columns that have changed we're not going to know all the rest of the rest",
    "start": "1970879",
    "end": "1977059"
  },
  {
    "text": "of that a rest of the columns of that row and because of this are our mutate",
    "start": "1977059",
    "end": "1983629"
  },
  {
    "text": "or sorry not aging our change of events is incomplete and we need to somehow figure out how to piece together this",
    "start": "1983629",
    "end": "1989570"
  },
  {
    "text": "information in our pipeline and a first problem is unlocked schema change so",
    "start": "1989570",
    "end": "1998730"
  },
  {
    "start": "1993000",
    "end": "2025000"
  },
  {
    "text": "Kassandra um does have you can modify your schema in Cassandra however it used",
    "start": "1998730",
    "end": "2005059"
  },
  {
    "text": "a completely different readwrite paths from a data change event it uses gossip",
    "start": "2005059",
    "end": "2010669"
  },
  {
    "text": "protocol to handle or propagate a schema change this means that this data is never going to be recorded into the",
    "start": "2010669",
    "end": "2017840"
  },
  {
    "text": "commit log so if we're only listening to the commit log we're not going to be to know about any schema change our current",
    "start": "2017840",
    "end": "2026929"
  },
  {
    "start": "2025000",
    "end": "2058000"
  },
  {
    "text": "solution that we're working on we call it a bridging the gap' solution is that we're going to ignore all the problems",
    "start": "2026929",
    "end": "2033169"
  },
  {
    "text": "at least at least until the data get into bigquery so basically the agents",
    "start": "2033169",
    "end": "2040070"
  },
  {
    "text": "just going to parse all of these data send it off to Kafka Kafka is gonna send all of these data into bigquery",
    "start": "2040070",
    "end": "2045190"
  },
  {
    "text": "everything in bigquery is unordered is duplicated and it's incomplete but then",
    "start": "2045190",
    "end": "2051710"
  },
  {
    "text": "we're going to heavily leveraged bigquery revealed view to handle all of this in order for bigquery to know how",
    "start": "2051710",
    "end": "2057980"
  },
  {
    "text": "to do this it needs a little bit more information it's not only going to store the value of every single column it's",
    "start": "2057980",
    "end": "2066108"
  },
  {
    "start": "2058000",
    "end": "2154000"
  },
  {
    "text": "also going to record the timestamp which is when the data is updated it's going to record at lesion timestamp in the",
    "start": "2066109",
    "end": "2073190"
  },
  {
    "text": "case the data is deleted and it's also going to create a boolean field or record a boolean field which is the east",
    "start": "2073190",
    "end": "2079760"
  },
  {
    "text": "primary boolean that just represents whether this column is a primary field or not so let's take a look at the data",
    "start": "2079760",
    "end": "2088010"
  },
  {
    "text": "now that we have stored them into bigquery this query specifically looks at the",
    "start": "2088010",
    "end": "2094070"
  },
  {
    "text": "first name column and if we want to also",
    "start": "2094070",
    "end": "2099230"
  },
  {
    "text": "query for the last name column we are getting notice that the second row is",
    "start": "2099230",
    "end": "2104570"
  },
  {
    "text": "now and that's because the second event is just an update so we only updated first-name this is not quite useful",
    "start": "2104570",
    "end": "2112880"
  },
  {
    "text": "because what we actually want is the second event for a first name but the",
    "start": "2112880",
    "end": "2118720"
  },
  {
    "text": "but the first event for last name so the way we can handle this is basically by",
    "start": "2118720",
    "end": "2125090"
  },
  {
    "text": "looking at the timestamp field compare them and find the one with the latest time them and then we can return the user or",
    "start": "2125090",
    "end": "2132980"
  },
  {
    "text": "recreate a view that returns the user with the data that's been deduplicated it's being ordered and it's complete and",
    "start": "2132980",
    "end": "2140560"
  },
  {
    "text": "in order to do this we have two heavily leveraged Vickery including its UDF's as",
    "start": "2140560",
    "end": "2146390"
  },
  {
    "text": "well as a lot of like like what I'm thinking",
    "start": "2146390",
    "end": "2151910"
  },
  {
    "text": "group I and so on there are some advantage to this approach the first",
    "start": "2151910",
    "end": "2157820"
  },
  {
    "start": "2154000",
    "end": "2269000"
  },
  {
    "text": "advantage is quick iteration because we basically didn't change any senior pipeline and we're doing all the heavy",
    "start": "2157820",
    "end": "2163820"
  },
  {
    "text": "lifting bigquery and bigquery view is very cheap to create to modify to delete so then we can as we experiment with",
    "start": "2163820",
    "end": "2170900"
  },
  {
    "text": "Cassandra we can basically modify the view as necessary the second benefit is",
    "start": "2170900",
    "end": "2177710"
  },
  {
    "text": "that there's very few operational overhead notice aside from the Cassandra CDC agent we didn't introduce anything",
    "start": "2177710",
    "end": "2183740"
  },
  {
    "text": "new so this way as we're solving this problem we don't want to be thinking about the the uptime of other services",
    "start": "2183740",
    "end": "2190700"
  },
  {
    "text": "or other application that help out students for this pipeline and finally",
    "start": "2190700",
    "end": "2198470"
  },
  {
    "text": "because we're leveraging off the base table in bigquery we're not going to impact Cassandra production because we",
    "start": "2198470",
    "end": "2204890"
  },
  {
    "text": "don't have to basically on every write read back into Cassandra to get the full row because all of our data are already",
    "start": "2204890",
    "end": "2210980"
  },
  {
    "text": "in bigquery but of course it comes at a cost the most the biggest the first cost",
    "start": "2210980",
    "end": "2216860"
  },
  {
    "text": "is it's very expensive because this means every time a user is querying for",
    "start": "2216860",
    "end": "2222140"
  },
  {
    "text": "this view we have to do all of this piecing the data together and it's it's",
    "start": "2222140",
    "end": "2227330"
  },
  {
    "text": "going to get very expensive on top of this we're recording a replication factor of three which means that it's",
    "start": "2227330",
    "end": "2233990"
  },
  {
    "text": "going to amplify and the table is going to get really big really fast so we'd",
    "start": "2233990",
    "end": "2239030"
  },
  {
    "text": "have to do some maintenance work in order to minimize this view and the way to do compaction is by just",
    "start": "2239030",
    "end": "2246490"
  },
  {
    "text": "materializing this view periodically but it is going to be an opera another overhead and finally notice we've only",
    "start": "2246490",
    "end": "2254360"
  },
  {
    "text": "solved this problem for bigquery which means that if any other downstream",
    "start": "2254360",
    "end": "2259760"
  },
  {
    "text": "derived system is trying to read from this data they're out of luck the base have to re-implement all of this",
    "start": "2259760",
    "end": "2265510"
  },
  {
    "text": "themselves and that's not quite ideal so for a sake of completion I've included a",
    "start": "2265510",
    "end": "2272190"
  },
  {
    "start": "2269000",
    "end": "2357000"
  },
  {
    "text": "potential future solution that's that we're considering it's a little bit more",
    "start": "2272190",
    "end": "2277930"
  },
  {
    "text": "complicated because now it introduces stream processing engine introduces a cache a database and a second Kafka so",
    "start": "2277930",
    "end": "2286750"
  },
  {
    "text": "let's go through how this would work the message are still going to arrive into Kafka duplicated and out of order the",
    "start": "2286750",
    "end": "2293950"
  },
  {
    "text": "first thing the stream processing engine is going to do is by checking against the cache to see whether this data has",
    "start": "2293950",
    "end": "2299830"
  },
  {
    "text": "been processed or not if it has been been processed then we will process this otherwise we can drop the message next",
    "start": "2299830",
    "end": "2306850"
  },
  {
    "text": "is the stream processing engine is going to check against the database it's going to notice whether the timestamp or it's",
    "start": "2306850",
    "end": "2315220"
  },
  {
    "text": "going to compare whether the timestamp of what's in the database against the timestamp of this event and in the case",
    "start": "2315220",
    "end": "2321970"
  },
  {
    "text": "where we have an oder timestamp in our event we can drop it as well and finally",
    "start": "2321970",
    "end": "2327520"
  },
  {
    "text": "because we've done a read on this database we now get both the before and the after of every single event so we",
    "start": "2327520",
    "end": "2335260"
  },
  {
    "text": "can send this complete information into our second Kafka now when Kafka's can can then send this",
    "start": "2335260",
    "end": "2341680"
  },
  {
    "text": "information into kcb queue which then can propagate into bigquery and the benefit here is that if we have any",
    "start": "2341680",
    "end": "2348430"
  },
  {
    "text": "other derived system that are reading from Kafka they now have a much nicer",
    "start": "2348430",
    "end": "2354690"
  },
  {
    "text": "outcome so in summary there's three things I'm",
    "start": "2354690",
    "end": "2362230"
  },
  {
    "start": "2357000",
    "end": "2428000"
  },
  {
    "text": "trying to I guess get through to for this talk the first thing is that database as a stream of change event is",
    "start": "2362230",
    "end": "2370000"
  },
  {
    "text": "a really natural and useful concept it would make a lot of sense for every single database out there to be able to",
    "start": "2370000",
    "end": "2377740"
  },
  {
    "text": "provide a city's sip interface for the data to to be sent into other derived",
    "start": "2377740",
    "end": "2383890"
  },
  {
    "text": "systems because otherwise we're talking about a very closed system where the database expects that this is going to",
    "start": "2383890",
    "end": "2390040"
  },
  {
    "text": "be the final destination and the data is not going to go anywhere else and that's kind of selfish the second the second point is that lock",
    "start": "2390040",
    "end": "2398160"
  },
  {
    "text": "centric architecture is at the heart of streaming data pipelines it helped us solve a lot of problems when it comes to",
    "start": "2398160",
    "end": "2404700"
  },
  {
    "text": "distributed transactions and it's and it's very simple to implement and",
    "start": "2404700",
    "end": "2410010"
  },
  {
    "text": "understand and finally CDC for peer-to-peer databases is not trivial as you've",
    "start": "2410010",
    "end": "2416880"
  },
  {
    "text": "probably already noticed however we're hoping as the tools gets better and as our understanding of these databases",
    "start": "2416880",
    "end": "2423090"
  },
  {
    "text": "gets better it will become easier over time some additional information if",
    "start": "2423090",
    "end": "2429990"
  },
  {
    "start": "2428000",
    "end": "2484000"
  },
  {
    "text": "you're interesting our my sequel to bigquery pipeline there is a blog post",
    "start": "2429990",
    "end": "2435330"
  },
  {
    "text": "on our website that basically explains it in a little bit more details I've",
    "start": "2435330",
    "end": "2441240"
  },
  {
    "text": "also included the case ebq github link in case you're interested in using that and finally the last piece is actually a",
    "start": "2441240",
    "end": "2449160"
  },
  {
    "text": "blog post that my colleague has wrote this morning it talks about schema",
    "start": "2449160",
    "end": "2454650"
  },
  {
    "text": "evolution in this in the case where it breaks backwards compatibility because",
    "start": "2454650",
    "end": "2460770"
  },
  {
    "text": "arrows we can use arrows for an a backward compatibility to deal with schemas that do that are compatible but",
    "start": "2460770",
    "end": "2469140"
  },
  {
    "text": "what happens if you have you have data that are not if you made a change that is not compatible in the database so the",
    "start": "2469140",
    "end": "2476430"
  },
  {
    "text": "last point kind of talks goes a little bit more into that and I think it's super interesting and relevant for CDC",
    "start": "2476430",
    "end": "2483740"
  },
  {
    "text": "and that's end of my talk thank you guys",
    "start": "2483740",
    "end": "2488450"
  },
  {
    "start": "2484000",
    "end": "2506000"
  },
  {
    "text": "okay thank you very much but this is an awesome talk I have a question can I",
    "start": "2493780",
    "end": "2498890"
  },
  {
    "text": "start with a question so for the future work you have a day to be sitting on the",
    "start": "2498890",
    "end": "2505970"
  },
  {
    "text": "side I have two questions one is so you could hydrate by just reading directly from one of the source databases yes so",
    "start": "2505970",
    "end": "2513680"
  },
  {
    "start": "2506000",
    "end": "2648000"
  },
  {
    "text": "so the reason we don't want to read directly from the source is because we don't want to impact the production of",
    "start": "2513680",
    "end": "2519590"
  },
  {
    "text": "the source database it is possible to create a second cluster a Cassandra cluster that is made specifically for",
    "start": "2519590",
    "end": "2526210"
  },
  {
    "text": "the CDC purpose but which is kind of what this could potentially be as well",
    "start": "2526210",
    "end": "2531260"
  },
  {
    "text": "so but you have to keep it in sync with the sources right oh so it's okay if",
    "start": "2531260",
    "end": "2537140"
  },
  {
    "text": "it's asynchronous because we are for every single table it's essentially serialized so then we know that it's",
    "start": "2537140",
    "end": "2543650"
  },
  {
    "text": "going to be in order okay well what do",
    "start": "2543650",
    "end": "2552470"
  },
  {
    "text": "you think about writing the event from the application itself because we've implemented the future solution that you",
    "start": "2552470",
    "end": "2559609"
  },
  {
    "text": "showed here yeah using events in the application right - Cassandra right -",
    "start": "2559609",
    "end": "2565430"
  },
  {
    "text": "Kafka and then we omit two events before and after into Kafka and then we use the stream processing engine within doing do",
    "start": "2565430",
    "end": "2573020"
  },
  {
    "text": "you hand a lot of partners and then distribute the updates to multiple databases yeah I think yes so the one of",
    "start": "2573020",
    "end": "2580040"
  },
  {
    "text": "the problem that we're seeing is like well there is the distributed transaction problem so you guys have",
    "start": "2580040",
    "end": "2585140"
  },
  {
    "text": "potentially stopped that then that's great but the the other problem is that we do want to be able to get the before",
    "start": "2585140",
    "end": "2593240"
  },
  {
    "text": "and after anything the my sequel case if we were to use if we were to use this",
    "start": "2593240",
    "end": "2599420"
  },
  {
    "text": "event sourcing approach then we only get the column that have changed so that was something we're trying to avoid but in",
    "start": "2599420",
    "end": "2605330"
  },
  {
    "text": "this case with Cassandra it's simply not possible because the database itself doesn't do read before right so that's",
    "start": "2605330",
    "end": "2611510"
  },
  {
    "text": "also why we're kind of this is kind of an event sourcing approach okay so now I kind of understand we're saying so",
    "start": "2611510",
    "end": "2617630"
  },
  {
    "text": "you're talking about why not just to update Kafka first and then and then basically works with Cassandra",
    "start": "2617630",
    "end": "2626080"
  },
  {
    "text": "you're not you don't have to worry about multiple copies and stuff before you",
    "start": "2626080",
    "end": "2638500"
  },
  {
    "text": "write - Cassandra you write into them - Kafka and then once it's successfully write another event after and another",
    "start": "2638500",
    "end": "2648460"
  },
  {
    "start": "2648000",
    "end": "2694000"
  },
  {
    "text": "thing is if you are using Cassandra for for any kind of like transactional",
    "start": "2648460",
    "end": "2655090"
  },
  {
    "text": "things where you care about read your own right consistency that could potentially become a problem I think",
    "start": "2655090",
    "end": "2660780"
  },
  {
    "text": "where you need to guarantee that every time you're reading from the database it's as it's the latest thing it's",
    "start": "2660780",
    "end": "2666760"
  },
  {
    "text": "something it has what you've written already",
    "start": "2666760",
    "end": "2670140"
  },
  {
    "text": "what's the yeah we can take it all by after what's the motivation for going to",
    "start": "2680360",
    "end": "2687240"
  },
  {
    "text": "Cassandra given that it sounds like this is quite an effort to go to it is bigquery not sufficient or what's the",
    "start": "2687240",
    "end": "2692880"
  },
  {
    "text": "limitation there so we want to use the Cassandra more in the sense of a production database big queries a star",
    "start": "2692880",
    "end": "2699540"
  },
  {
    "text": "in the sense of like yeah like OLTP database whereas bigquery is more so for",
    "start": "2699540",
    "end": "2705540"
  },
  {
    "text": "analytical database ola p so we want to optimize for right and cassandra is our",
    "start": "2705540",
    "end": "2712050"
  },
  {
    "text": "best contender for that so I had a quick",
    "start": "2712050",
    "end": "2719070"
  },
  {
    "text": "question about the caching that essentially materializes the view of the",
    "start": "2719070",
    "end": "2724260"
  },
  {
    "text": "row within the cache right so how long do you know how do you know how long to keep that cash yeah so the cache is kind",
    "start": "2724260",
    "end": "2732360"
  },
  {
    "start": "2731000",
    "end": "2781000"
  },
  {
    "text": "of going to be like an optimization but it's not going to be like a source of truth because it is possible say you've",
    "start": "2732360",
    "end": "2739350"
  },
  {
    "text": "set your TTL to 30 minutes but for whatever reason some one of the note is down for a longer amount of time then",
    "start": "2739350",
    "end": "2746010"
  },
  {
    "text": "you can get the data later but the database can then catch those problems by the time of day to get there so",
    "start": "2746010",
    "end": "2754160"
  },
  {
    "text": "hi just a quick question could you not so it's just listening through the",
    "start": "2761250",
    "end": "2766299"
  },
  {
    "text": "future solution for Cassandra when you will get three copies of the data and out of order as well at times could you",
    "start": "2766299",
    "end": "2772930"
  },
  {
    "text": "not just use one of the replicas as master and you could use zookeeper for keeping that state and just have that",
    "start": "2772930",
    "end": "2779799"
  },
  {
    "text": "one like a push it out so that's actually something we considered where we would actually coordinate the",
    "start": "2779799",
    "end": "2785829"
  },
  {
    "text": "different agents so that only one of them is sending the message the problem is that Cassandra is meant to be a",
    "start": "2785829",
    "end": "2791619"
  },
  {
    "text": "peer-to-peer database and it's meant where all the notes should be equal if we're started to introduce zookeeper",
    "start": "2791619",
    "end": "2798190"
  },
  {
    "text": "into the picture it's a little bit against Cassandra's philosophy which is that any note can be taken up or down",
    "start": "2798190",
    "end": "2804400"
  },
  {
    "text": "because now we're basically setting one of the notes to be the master and it's",
    "start": "2804400",
    "end": "2809829"
  },
  {
    "text": "not definitely possible but the reason we're not considering is because we kind of want to follow what cassandra is known for which is the this whole like",
    "start": "2809829",
    "end": "2817710"
  },
  {
    "text": "peer to peer everyone is thinking do you do write three write equals three and all right right now we do yeah",
    "start": "2817710",
    "end": "2826349"
  },
  {
    "text": "just curious thanks to the great talk just curious if you think there'll be any one people to build downstream",
    "start": "2838809",
    "end": "2844369"
  },
  {
    "text": "applications off some of these streams or if it all goes to analytics I've seen some interesting use cases of using this",
    "start": "2844369",
    "end": "2850430"
  },
  {
    "text": "to actually generate other applications yeah I think it's definitely possible which is why we want to have this future",
    "start": "2850430",
    "end": "2858049"
  },
  {
    "text": "solution that allows the other system to be able to read from Kafka if the only thing we care about with analytics then",
    "start": "2858049",
    "end": "2863930"
  },
  {
    "text": "our existing pipeline could kind of work for a while so yeah cool any others sure",
    "start": "2863930",
    "end": "2876760"
  },
  {
    "text": "um I'm curious if you ever end up missing events due to like a network failure talking to Kafka or something",
    "start": "2879490",
    "end": "2886609"
  },
  {
    "text": "like that and if so how do you deal with that so that's a good question a lot of things we're dealing right now are all",
    "start": "2886609",
    "end": "2892910"
  },
  {
    "text": "in PLC's so we haven't had like the the spend a lot of time and effort in terms",
    "start": "2892910",
    "end": "2898279"
  },
  {
    "text": "of guaranteeing that our messages are not lost and whatnot I think it's potentially possible as I've heard about",
    "start": "2898279",
    "end": "2904819"
  },
  {
    "text": "similar scenario in other pipelines before with Kafka so but it will",
    "start": "2904819",
    "end": "2910250"
  },
  {
    "text": "probably get a clearer answer as we experiment more with this pipeline Thanks thank you if any others okay",
    "start": "2910250",
    "end": "2922270"
  },
  {
    "text": "yeah so my question is you're paying lost a lot of the data duplication with",
    "start": "2925789",
    "end": "2931709"
  },
  {
    "text": "a view on bigquery how how much of a performance penalty are you incurring by",
    "start": "2931709",
    "end": "2937739"
  },
  {
    "text": "like lazily evaluating the data this way it's it's so that's something that's",
    "start": "2937739",
    "end": "2943920"
  },
  {
    "start": "2941000",
    "end": "3028000"
  },
  {
    "text": "just going to get worse over time we are kerning a process building this so I don't have a good lot of numbers",
    "start": "2943920",
    "end": "2950579"
  },
  {
    "text": "for you but it is definitely pretty expensive the query is great because it's able to do a parallel execution but",
    "start": "2950579",
    "end": "2958799"
  },
  {
    "text": "even with sad we are it is the concern that it would put we could potentially take way too",
    "start": "2958799",
    "end": "2964170"
  },
  {
    "text": "long for single query to do which is why we're hoping compaction could help us down the road but yeah thank you I can't",
    "start": "2964170",
    "end": "2972690"
  },
  {
    "text": "I don't have a good business trade-off you think like whether or not to throw away the outdated expense right it's",
    "start": "2972690",
    "end": "2980279"
  },
  {
    "text": "going the query cost is based off execution so this is going to get expensive",
    "start": "2980279",
    "end": "2985789"
  },
  {
    "text": "yeah thank you so one question is if you",
    "start": "2985789",
    "end": "2991380"
  },
  {
    "text": "do in this metaphor model but like if you are cash and use the windowing and stream processor you could probably do",
    "start": "2991380",
    "end": "2997559"
  },
  {
    "text": "there at least for a time window data right yeah Cassandra itself actually has a TTL feature so if we actually want to",
    "start": "2997559",
    "end": "3004549"
  },
  {
    "text": "use Cassandra as this intermediate data base it's possible as well",
    "start": "3004549",
    "end": "3010089"
  },
  {
    "text": "this is in more in line with someone who had asked a question before if data consistency is such a big",
    "start": "3015349",
    "end": "3021240"
  },
  {
    "text": "requirement or on here what is the rationale for using an eventual thing like Cassandra yeah that's that's a",
    "start": "3021240",
    "end": "3029160"
  },
  {
    "start": "3028000",
    "end": "3087000"
  },
  {
    "text": "really good question I think like we are because we're building a data pipeline we want to optimize for different use",
    "start": "3029160",
    "end": "3035040"
  },
  {
    "text": "cases so maybe for one user their goal is to use CAF to use Cassandra for write",
    "start": "3035040",
    "end": "3041280"
  },
  {
    "text": "only and another might be using Cassandra for something that's a little bit more consistent which are we're",
    "start": "3041280",
    "end": "3047910"
  },
  {
    "text": "trying to make a more generic solution essentially that covers all these cases but it's it's true though yeah so you",
    "start": "3047910",
    "end": "3055230"
  },
  {
    "text": "are in you're in this picture you are envisioning heterogeneous sources like",
    "start": "3055230",
    "end": "3061859"
  },
  {
    "text": "Cassandra and other my sequel and things like that oh no so this pipeline is",
    "start": "3061859",
    "end": "3067079"
  },
  {
    "text": "specifically for Cassandra only great",
    "start": "3067079",
    "end": "3073859"
  },
  {
    "text": "questions maybe one more anyone has one ok great",
    "start": "3073859",
    "end": "3082800"
  },
  {
    "text": "thank you very much thank you [Applause]",
    "start": "3082800",
    "end": "3088659"
  }
]
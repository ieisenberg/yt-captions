[
  {
    "start": "0",
    "end": "60000"
  },
  {
    "text": "[Music]",
    "start": "3370",
    "end": "6549"
  },
  {
    "text": "at netflix",
    "start": "9840",
    "end": "10719"
  },
  {
    "text": "we have microservices using different",
    "start": "10719",
    "end": "12639"
  },
  {
    "text": "kinds of databases",
    "start": "12639",
    "end": "13759"
  },
  {
    "text": "based on the capabilities of each",
    "start": "13759",
    "end": "15360"
  },
  {
    "text": "database when a new movie",
    "start": "15360",
    "end": "17760"
  },
  {
    "text": "is added we have the information written",
    "start": "17760",
    "end": "20640"
  },
  {
    "text": "into a cassandra database",
    "start": "20640",
    "end": "22320"
  },
  {
    "text": "which would then be required by",
    "start": "22320",
    "end": "26000"
  },
  {
    "text": "the ui but needs to be accessed through",
    "start": "26000",
    "end": "28880"
  },
  {
    "text": "elasticsearch",
    "start": "28880",
    "end": "30080"
  },
  {
    "text": "or we might need this information for",
    "start": "30080",
    "end": "32398"
  },
  {
    "text": "analytics",
    "start": "32399",
    "end": "33440"
  },
  {
    "text": "and we would need to use a database like",
    "start": "33440",
    "end": "36880"
  },
  {
    "text": "iceberg which is a data warehouse",
    "start": "36880",
    "end": "38320"
  },
  {
    "text": "solution",
    "start": "38320",
    "end": "40160"
  },
  {
    "text": "in this talk we'll focus on the",
    "start": "40160",
    "end": "42719"
  },
  {
    "text": "challenges involved in keeping the data",
    "start": "42719",
    "end": "44960"
  },
  {
    "text": "synced",
    "start": "44960",
    "end": "45440"
  },
  {
    "text": "from cassandra which is a distributed",
    "start": "45440",
    "end": "47920"
  },
  {
    "text": "nosql database",
    "start": "47920",
    "end": "49200"
  },
  {
    "text": "to other databases using change data",
    "start": "49200",
    "end": "51680"
  },
  {
    "text": "capture",
    "start": "51680",
    "end": "52800"
  },
  {
    "text": "hi i'm raghu and i'm a software engineer",
    "start": "52800",
    "end": "56239"
  },
  {
    "text": "at netflix",
    "start": "56239",
    "end": "57199"
  },
  {
    "text": "working on our data integrations",
    "start": "57199",
    "end": "58879"
  },
  {
    "text": "platform",
    "start": "58879",
    "end": "60960"
  },
  {
    "start": "60000",
    "end": "115000"
  },
  {
    "text": "the data sync problem which we saw just",
    "start": "60960",
    "end": "63840"
  },
  {
    "text": "now",
    "start": "63840",
    "end": "64559"
  },
  {
    "text": "is not specific to netflix applications",
    "start": "64559",
    "end": "67840"
  },
  {
    "text": "end up requiring varying kinds of access",
    "start": "67840",
    "end": "70720"
  },
  {
    "text": "patterns",
    "start": "70720",
    "end": "71439"
  },
  {
    "text": "for the use cases they support due to",
    "start": "71439",
    "end": "74400"
  },
  {
    "text": "this",
    "start": "74400",
    "end": "75200"
  },
  {
    "text": "we have different databases with",
    "start": "75200",
    "end": "77439"
  },
  {
    "text": "trade-offs resulting from their",
    "start": "77439",
    "end": "78799"
  },
  {
    "text": "architectures",
    "start": "78799",
    "end": "80960"
  },
  {
    "text": "what are some of the access patterns for",
    "start": "80960",
    "end": "83759"
  },
  {
    "text": "example",
    "start": "83759",
    "end": "84479"
  },
  {
    "text": "you could use apache cassandra which is",
    "start": "84479",
    "end": "86960"
  },
  {
    "text": "known for having high availability and",
    "start": "86960",
    "end": "88960"
  },
  {
    "text": "high rate throughput workloads because",
    "start": "88960",
    "end": "91040"
  },
  {
    "text": "it uses mam tables and commit logs",
    "start": "91040",
    "end": "93280"
  },
  {
    "text": "while providing eventual consistency but",
    "start": "93280",
    "end": "96079"
  },
  {
    "text": "doesn't provide apis",
    "start": "96079",
    "end": "97520"
  },
  {
    "text": "for say search",
    "start": "97520",
    "end": "100720"
  },
  {
    "text": "but for that you could use elasticsearch",
    "start": "100720",
    "end": "103280"
  },
  {
    "text": "which can provide which can provide",
    "start": "103280",
    "end": "104720"
  },
  {
    "text": "those query patterns",
    "start": "104720",
    "end": "106399"
  },
  {
    "text": "but cannot handle analytical queries",
    "start": "106399",
    "end": "109439"
  },
  {
    "text": "and we would need a data warehouse",
    "start": "109439",
    "end": "110960"
  },
  {
    "text": "solution like hive or iceberg",
    "start": "110960",
    "end": "114560"
  },
  {
    "text": "what are some solutions to these",
    "start": "114560",
    "end": "116079"
  },
  {
    "start": "115000",
    "end": "162000"
  },
  {
    "text": "problems we could have the rights",
    "start": "116079",
    "end": "118719"
  },
  {
    "text": "go to multiple databases for every right",
    "start": "118719",
    "end": "122079"
  },
  {
    "text": "or perform every right as a distributed",
    "start": "122079",
    "end": "124479"
  },
  {
    "text": "transaction",
    "start": "124479",
    "end": "125840"
  },
  {
    "text": "with dual rights some issues will be",
    "start": "125840",
    "end": "128720"
  },
  {
    "text": "with regarding to",
    "start": "128720",
    "end": "130560"
  },
  {
    "text": "reconciling only one of the rights",
    "start": "130560",
    "end": "132400"
  },
  {
    "text": "succeeding",
    "start": "132400",
    "end": "133760"
  },
  {
    "text": "distributed transactions need management",
    "start": "133760",
    "end": "136160"
  },
  {
    "text": "outside of the database",
    "start": "136160",
    "end": "137680"
  },
  {
    "text": "and that is a hard problem to tackle we",
    "start": "137680",
    "end": "140640"
  },
  {
    "text": "could have a separate process which",
    "start": "140640",
    "end": "142720"
  },
  {
    "text": "takes care of just",
    "start": "142720",
    "end": "144080"
  },
  {
    "text": "extracting the data from the source",
    "start": "144080",
    "end": "146080"
  },
  {
    "text": "optionally transforming it",
    "start": "146080",
    "end": "147599"
  },
  {
    "text": "and then loading it into a sync database",
    "start": "147599",
    "end": "150080"
  },
  {
    "text": "but",
    "start": "150080",
    "end": "150720"
  },
  {
    "text": "these processes would need to have",
    "start": "150720",
    "end": "152400"
  },
  {
    "text": "verifiers to make sure that there are no",
    "start": "152400",
    "end": "154480"
  },
  {
    "text": "bugs in the systems and",
    "start": "154480",
    "end": "156319"
  },
  {
    "text": "that the source and same database always",
    "start": "156319",
    "end": "158400"
  },
  {
    "text": "have the same information",
    "start": "158400",
    "end": "161599"
  },
  {
    "text": "where can cdc come into the picture with",
    "start": "162239",
    "end": "164480"
  },
  {
    "text": "this",
    "start": "164480",
    "end": "165840"
  },
  {
    "text": "we can look at this as a solution for",
    "start": "165840",
    "end": "168080"
  },
  {
    "text": "this problem",
    "start": "168080",
    "end": "170160"
  },
  {
    "text": "and we'll see how that is the case in",
    "start": "170160",
    "end": "172720"
  },
  {
    "text": "this",
    "start": "172720",
    "end": "173599"
  },
  {
    "text": "talk",
    "start": "173599",
    "end": "175840"
  },
  {
    "text": "for a particular database you could be",
    "start": "176800",
    "end": "178560"
  },
  {
    "text": "writing to it from a shell client",
    "start": "178560",
    "end": "180720"
  },
  {
    "text": "or from an application so",
    "start": "180720",
    "end": "183760"
  },
  {
    "text": "the changes to a database could be",
    "start": "183760",
    "end": "186239"
  },
  {
    "text": "coming in from different",
    "start": "186239",
    "end": "187840"
  },
  {
    "text": "systems we're mainly concerned about",
    "start": "187840",
    "end": "190959"
  },
  {
    "text": "inserts updates and deletes which we'll",
    "start": "190959",
    "end": "194000"
  },
  {
    "text": "term as mutations",
    "start": "194000",
    "end": "195440"
  },
  {
    "text": "for the rest of the stock when we",
    "start": "195440",
    "end": "198800"
  },
  {
    "text": "convert these changes",
    "start": "198800",
    "end": "200480"
  },
  {
    "text": "at a database to a stream of events we",
    "start": "200480",
    "end": "203519"
  },
  {
    "text": "have changed data capture or cdc for",
    "start": "203519",
    "end": "205760"
  },
  {
    "text": "short",
    "start": "205760",
    "end": "206879"
  },
  {
    "text": "cdc involves capturing data which gets",
    "start": "206879",
    "end": "209920"
  },
  {
    "text": "written to a database",
    "start": "209920",
    "end": "211040"
  },
  {
    "text": "and sending it to downstream consumers",
    "start": "211040",
    "end": "213360"
  },
  {
    "text": "as a stream of events",
    "start": "213360",
    "end": "216319"
  },
  {
    "text": "why would we need this let's take a look",
    "start": "216319",
    "end": "218799"
  },
  {
    "text": "at the previous example which we talked",
    "start": "218799",
    "end": "220480"
  },
  {
    "text": "about",
    "start": "220480",
    "end": "221280"
  },
  {
    "text": "here we have an application which has a",
    "start": "221280",
    "end": "223760"
  },
  {
    "text": "backend service with a ui",
    "start": "223760",
    "end": "226319"
  },
  {
    "text": "the backend service has business logic",
    "start": "226319",
    "end": "228080"
  },
  {
    "text": "and maintain state in a robust database",
    "start": "228080",
    "end": "229840"
  },
  {
    "text": "like cassandra",
    "start": "229840",
    "end": "231280"
  },
  {
    "text": "but the ui needs a more flexible",
    "start": "231280",
    "end": "234080"
  },
  {
    "text": "database like elasticsearch",
    "start": "234080",
    "end": "235599"
  },
  {
    "text": "to perform text search and have search",
    "start": "235599",
    "end": "238640"
  },
  {
    "text": "indices",
    "start": "238640",
    "end": "239439"
  },
  {
    "text": "based on different fields to support",
    "start": "239439",
    "end": "242239"
  },
  {
    "text": "user requests",
    "start": "242239",
    "end": "244080"
  },
  {
    "text": "we can solve the data sync problem",
    "start": "244080",
    "end": "246480"
  },
  {
    "text": "between these two databases",
    "start": "246480",
    "end": "248159"
  },
  {
    "text": "using cdc here we see another example",
    "start": "248159",
    "end": "252799"
  },
  {
    "text": "where we need the data in cassandra and",
    "start": "252799",
    "end": "254879"
  },
  {
    "text": "an analytics oriented data warehouse",
    "start": "254879",
    "end": "256639"
  },
  {
    "text": "solution",
    "start": "256639",
    "end": "257280"
  },
  {
    "text": "like iceberg or hive by having a change",
    "start": "257280",
    "end": "260639"
  },
  {
    "text": "data capture stream",
    "start": "260639",
    "end": "262079"
  },
  {
    "text": "from cassandra being written into",
    "start": "262079",
    "end": "265440"
  },
  {
    "text": "the data warehouse solution we simplify",
    "start": "265440",
    "end": "268479"
  },
  {
    "text": "the problem let's look at how",
    "start": "268479",
    "end": "271680"
  },
  {
    "text": "cdc operates within cassandra",
    "start": "271680",
    "end": "274880"
  },
  {
    "text": "cassandra provides high availability",
    "start": "274880",
    "end": "276800"
  },
  {
    "text": "guarantees by having three copies of",
    "start": "276800",
    "end": "278960"
  },
  {
    "text": "data",
    "start": "278960",
    "end": "279600"
  },
  {
    "text": "on different nodes in a cluster since",
    "start": "279600",
    "end": "282240"
  },
  {
    "text": "rights to mem tables and commit clocks",
    "start": "282240",
    "end": "284000"
  },
  {
    "text": "are extremely",
    "start": "284000",
    "end": "285040"
  },
  {
    "text": "fast we can have good performance",
    "start": "285040",
    "end": "288560"
  },
  {
    "text": "by the database despite the replication",
    "start": "288560",
    "end": "292320"
  },
  {
    "text": "what are the challenges in such a system",
    "start": "292320",
    "end": "295360"
  },
  {
    "text": "the data is partitioned so multiple",
    "start": "295360",
    "end": "298560"
  },
  {
    "text": "nodes",
    "start": "298560",
    "end": "299280"
  },
  {
    "text": "have to emit the change stream data is",
    "start": "299280",
    "end": "302479"
  },
  {
    "text": "replicated which means the same change",
    "start": "302479",
    "end": "305120"
  },
  {
    "text": "will be",
    "start": "305120",
    "end": "305520"
  },
  {
    "text": "emitted by multiple modes the system is",
    "start": "305520",
    "end": "309120"
  },
  {
    "text": "active active which is to say that there",
    "start": "309120",
    "end": "311280"
  },
  {
    "text": "is no",
    "start": "311280",
    "end": "312479"
  },
  {
    "text": "single authoritative node to get the",
    "start": "312479",
    "end": "315199"
  },
  {
    "text": "change stream",
    "start": "315199",
    "end": "316000"
  },
  {
    "text": "unlike databases like mysql or postgres",
    "start": "316000",
    "end": "321039"
  },
  {
    "text": "when multiple replicas are emitting this",
    "start": "321039",
    "end": "322960"
  },
  {
    "text": "change stream there is no ordering",
    "start": "322960",
    "end": "324960"
  },
  {
    "text": "guarantee",
    "start": "324960",
    "end": "326160"
  },
  {
    "text": "in the resultant stream and",
    "start": "326160",
    "end": "330800"
  },
  {
    "text": "the stream is also unfiltered",
    "start": "330800",
    "end": "333840"
  },
  {
    "text": "which is to say that all changes",
    "start": "333840",
    "end": "335680"
  },
  {
    "text": "happening in the cluster are part of the",
    "start": "335680",
    "end": "337280"
  },
  {
    "text": "stream irrespective of",
    "start": "337280",
    "end": "338880"
  },
  {
    "text": "which column family they might belong to",
    "start": "338880",
    "end": "340960"
  },
  {
    "text": "or what the columns",
    "start": "340960",
    "end": "342320"
  },
  {
    "text": "would be which are changing cassandra",
    "start": "342320",
    "end": "344880"
  },
  {
    "text": "also",
    "start": "344880",
    "end": "345360"
  },
  {
    "text": "only provides partial changes",
    "start": "345360",
    "end": "348560"
  },
  {
    "text": "which is to say that updates and deletes",
    "start": "348560",
    "end": "351360"
  },
  {
    "text": "contain",
    "start": "351360",
    "end": "352160"
  },
  {
    "text": "only affected columns and keys but not",
    "start": "352160",
    "end": "354960"
  },
  {
    "text": "details about the full impact",
    "start": "354960",
    "end": "357440"
  },
  {
    "text": "a change stream with these properties",
    "start": "357440",
    "end": "360400"
  },
  {
    "text": "ends up requiring",
    "start": "360400",
    "end": "361600"
  },
  {
    "text": "downstream systems which consume this",
    "start": "361600",
    "end": "365199"
  },
  {
    "text": "to make sure that they are",
    "start": "365199",
    "end": "369440"
  },
  {
    "text": "deduplicated and have ordering somehow",
    "start": "369440",
    "end": "373280"
  },
  {
    "text": "and filter them according to their",
    "start": "373280",
    "end": "374800"
  },
  {
    "text": "requirements",
    "start": "374800",
    "end": "377360"
  },
  {
    "text": "this is an issue with the open source",
    "start": "378000",
    "end": "380800"
  },
  {
    "text": "debesium cassandra connector also",
    "start": "380800",
    "end": "384160"
  },
  {
    "text": "and we'll see how we can address these",
    "start": "384160",
    "end": "386560"
  },
  {
    "text": "problems",
    "start": "386560",
    "end": "388800"
  },
  {
    "start": "388000",
    "end": "438000"
  },
  {
    "text": "what are the ideal properties of a chain",
    "start": "388800",
    "end": "390960"
  },
  {
    "text": "stream",
    "start": "390960",
    "end": "392479"
  },
  {
    "text": "you would mainly want it to be unique",
    "start": "392479",
    "end": "396639"
  },
  {
    "text": "so there are no duplicate changes",
    "start": "396639",
    "end": "399600"
  },
  {
    "text": "ordered",
    "start": "399600",
    "end": "400639"
  },
  {
    "text": "the changes that are emitted they are",
    "start": "400639",
    "end": "402720"
  },
  {
    "text": "emitted in the order that they got",
    "start": "402720",
    "end": "404400"
  },
  {
    "text": "committed",
    "start": "404400",
    "end": "404960"
  },
  {
    "text": "in the source database we have full row",
    "start": "404960",
    "end": "408080"
  },
  {
    "text": "images",
    "start": "408080",
    "end": "409280"
  },
  {
    "text": "all columns including pre and post",
    "start": "409280",
    "end": "411599"
  },
  {
    "text": "images of a row",
    "start": "411599",
    "end": "412880"
  },
  {
    "text": "are emitted in the screen",
    "start": "412880",
    "end": "416000"
  },
  {
    "text": "it should be filtered so that there is a",
    "start": "416000",
    "end": "418639"
  },
  {
    "text": "change stream",
    "start": "418639",
    "end": "419360"
  },
  {
    "text": "per database per table and specific",
    "start": "419360",
    "end": "421840"
  },
  {
    "text": "columns",
    "start": "421840",
    "end": "423039"
  },
  {
    "text": "might need to be filtered out for",
    "start": "423039",
    "end": "424720"
  },
  {
    "text": "security requirements",
    "start": "424720",
    "end": "426080"
  },
  {
    "text": "where the columns could contain",
    "start": "426080",
    "end": "428319"
  },
  {
    "text": "personally identifiable information",
    "start": "428319",
    "end": "430960"
  },
  {
    "text": "which should not be leaving the",
    "start": "430960",
    "end": "433039"
  },
  {
    "text": "boundaries of",
    "start": "433039",
    "end": "434080"
  },
  {
    "text": "the database cluster",
    "start": "434080",
    "end": "437840"
  },
  {
    "start": "438000",
    "end": "603000"
  },
  {
    "text": "what are some possible solutions which",
    "start": "438240",
    "end": "440160"
  },
  {
    "text": "we can",
    "start": "440160",
    "end": "441680"
  },
  {
    "text": "look at for this particular problem",
    "start": "441680",
    "end": "445120"
  },
  {
    "text": "the cassandra clusters at netflix have",
    "start": "445120",
    "end": "447520"
  },
  {
    "text": "incremental backups",
    "start": "447520",
    "end": "448960"
  },
  {
    "text": "where ss tables from the cluster are",
    "start": "448960",
    "end": "452160"
  },
  {
    "text": "written to s3 at regular intervals",
    "start": "452160",
    "end": "456160"
  },
  {
    "text": "the backup system is robust but",
    "start": "456160",
    "end": "459360"
  },
  {
    "text": "this approach could take minutes to",
    "start": "459360",
    "end": "461199"
  },
  {
    "text": "hours to emit changes",
    "start": "461199",
    "end": "462800"
  },
  {
    "text": "so it's not near real time which is one",
    "start": "462800",
    "end": "465120"
  },
  {
    "text": "of our requirements",
    "start": "465120",
    "end": "467039"
  },
  {
    "text": "we could use audit loggers or full query",
    "start": "467039",
    "end": "469680"
  },
  {
    "text": "loggers",
    "start": "469680",
    "end": "470560"
  },
  {
    "text": "which would end up severely",
    "start": "470560",
    "end": "474080"
  },
  {
    "text": "degrading the cluster performance and",
    "start": "474080",
    "end": "476400"
  },
  {
    "text": "require changes to cassandra",
    "start": "476400",
    "end": "478879"
  },
  {
    "text": "we also need to recreate ordering",
    "start": "478879",
    "end": "480479"
  },
  {
    "text": "outside of cassandra",
    "start": "480479",
    "end": "482800"
  },
  {
    "text": "we could perform cdc in the coordinator",
    "start": "482800",
    "end": "485440"
  },
  {
    "text": "only",
    "start": "485440",
    "end": "486479"
  },
  {
    "text": "but this has issues with having",
    "start": "486479",
    "end": "489280"
  },
  {
    "text": "availability",
    "start": "489280",
    "end": "490160"
  },
  {
    "text": "and continuation of the change stream",
    "start": "490160",
    "end": "492160"
  },
  {
    "text": "when the coordinator goes down and",
    "start": "492160",
    "end": "494160"
  },
  {
    "text": "there's a",
    "start": "494160",
    "end": "495680"
  },
  {
    "text": "newly elected node which becomes the",
    "start": "495680",
    "end": "497680"
  },
  {
    "text": "coordinator",
    "start": "497680",
    "end": "500160"
  },
  {
    "text": "cdc could be performed in an additional",
    "start": "500160",
    "end": "502960"
  },
  {
    "text": "copy",
    "start": "502960",
    "end": "503680"
  },
  {
    "text": "where basically we are saying if the",
    "start": "503680",
    "end": "506639"
  },
  {
    "text": "replication factor is three we have a",
    "start": "506639",
    "end": "508560"
  },
  {
    "text": "fourth copy",
    "start": "508560",
    "end": "509919"
  },
  {
    "text": "which would be in the asynchronous right",
    "start": "509919",
    "end": "512560"
  },
  {
    "text": "path",
    "start": "512560",
    "end": "513120"
  },
  {
    "text": "and not on the read path for the",
    "start": "513120",
    "end": "515680"
  },
  {
    "text": "cassandra cluster",
    "start": "515680",
    "end": "517120"
  },
  {
    "text": "this would make sure that this change",
    "start": "517120",
    "end": "519440"
  },
  {
    "text": "stream has",
    "start": "519440",
    "end": "520959"
  },
  {
    "text": "all of the previous properties which we",
    "start": "520959",
    "end": "523200"
  },
  {
    "text": "want but",
    "start": "523200",
    "end": "524800"
  },
  {
    "text": "the complexity of this implementation",
    "start": "524800",
    "end": "527360"
  },
  {
    "text": "would require major changes",
    "start": "527360",
    "end": "528959"
  },
  {
    "text": "into cassandra our solution",
    "start": "528959",
    "end": "532160"
  },
  {
    "text": "entails instead an intermediate system",
    "start": "532160",
    "end": "534959"
  },
  {
    "text": "which is used to hold information about",
    "start": "534959",
    "end": "536959"
  },
  {
    "text": "the data",
    "start": "536959",
    "end": "538080"
  },
  {
    "text": "so that we can solve these challenges",
    "start": "538080",
    "end": "540720"
  },
  {
    "text": "our solution",
    "start": "540720",
    "end": "541680"
  },
  {
    "text": "also improves upon the solution for this",
    "start": "541680",
    "end": "543760"
  },
  {
    "text": "which is developed by yelp",
    "start": "543760",
    "end": "545279"
  },
  {
    "text": "where they talk about streaming",
    "start": "545279",
    "end": "546800"
  },
  {
    "text": "cassandra into kafka",
    "start": "546800",
    "end": "549839"
  },
  {
    "text": "here we can see what the internal",
    "start": "549839",
    "end": "551519"
  },
  {
    "text": "architecture of our connector would look",
    "start": "551519",
    "end": "553120"
  },
  {
    "text": "like",
    "start": "553120",
    "end": "554480"
  },
  {
    "text": "the mutations are read from the commit",
    "start": "554480",
    "end": "556880"
  },
  {
    "text": "log of cassandra",
    "start": "556880",
    "end": "558640"
  },
  {
    "text": "and written to a kafka topic it's",
    "start": "558640",
    "end": "561200"
  },
  {
    "text": "important to know",
    "start": "561200",
    "end": "562000"
  },
  {
    "text": "that the flink application and the",
    "start": "562000",
    "end": "563760"
  },
  {
    "text": "cassandra cluster need to have the same",
    "start": "563760",
    "end": "566080"
  },
  {
    "text": "versions of the cassandra storage engine",
    "start": "566080",
    "end": "568560"
  },
  {
    "text": "to be able to read objects correctly",
    "start": "568560",
    "end": "570959"
  },
  {
    "text": "since we make use of this",
    "start": "570959",
    "end": "572399"
  },
  {
    "text": "to generate the correct full row image",
    "start": "572399",
    "end": "577680"
  },
  {
    "text": "we will see how we can use a",
    "start": "577680",
    "end": "581040"
  },
  {
    "text": "key value store within flink to store",
    "start": "581040",
    "end": "583360"
  },
  {
    "text": "data",
    "start": "583360",
    "end": "584560"
  },
  {
    "text": "and make sure that the",
    "start": "584560",
    "end": "588160"
  },
  {
    "text": "cassandra output which is unordered has",
    "start": "588160",
    "end": "590560"
  },
  {
    "text": "duplicates",
    "start": "590560",
    "end": "592000"
  },
  {
    "text": "has only partial updates and is",
    "start": "592000",
    "end": "593839"
  },
  {
    "text": "unfiltered can be converted to one which",
    "start": "593839",
    "end": "596080"
  },
  {
    "text": "is",
    "start": "596080",
    "end": "596320"
  },
  {
    "text": "ordered deduped has full row images",
    "start": "596320",
    "end": "600720"
  },
  {
    "text": "and is filtered",
    "start": "600720",
    "end": "603760"
  },
  {
    "text": "what are some of the properties of the",
    "start": "603760",
    "end": "605680"
  },
  {
    "text": "system which make it ideal",
    "start": "605680",
    "end": "607600"
  },
  {
    "text": "for us the output of the cassandra",
    "start": "607600",
    "end": "611200"
  },
  {
    "text": "cluster",
    "start": "611200",
    "end": "612560"
  },
  {
    "text": "ends up being a kafka topic with n",
    "start": "612560",
    "end": "615120"
  },
  {
    "text": "partitions",
    "start": "615120",
    "end": "616320"
  },
  {
    "text": "we then have workers which process",
    "start": "616320",
    "end": "618320"
  },
  {
    "text": "events on each partition",
    "start": "618320",
    "end": "620079"
  },
  {
    "text": "having this intermediary kafka topic",
    "start": "620079",
    "end": "622720"
  },
  {
    "text": "decouples the availability of the",
    "start": "622720",
    "end": "624399"
  },
  {
    "text": "consuming system",
    "start": "624399",
    "end": "626000"
  },
  {
    "text": "this also ensures that the cdc solution",
    "start": "626000",
    "end": "629360"
  },
  {
    "text": "has minimal impact on the cassandra",
    "start": "629360",
    "end": "632480"
  },
  {
    "text": "cluster's performance we",
    "start": "632480",
    "end": "635600"
  },
  {
    "text": "have a linearizable data store to",
    "start": "635600",
    "end": "638240"
  },
  {
    "text": "retrieve the most",
    "start": "638240",
    "end": "639440"
  },
  {
    "text": "recent information which is",
    "start": "639440",
    "end": "642720"
  },
  {
    "text": "stored for a particular partition key if",
    "start": "642720",
    "end": "644880"
  },
  {
    "text": "present",
    "start": "644880",
    "end": "645839"
  },
  {
    "text": "apply the incoming change and write that",
    "start": "645839",
    "end": "647760"
  },
  {
    "text": "back into the data store",
    "start": "647760",
    "end": "649519"
  },
  {
    "text": "this helps us achieve the same ordering",
    "start": "649519",
    "end": "652160"
  },
  {
    "text": "which is given by cassandra to its",
    "start": "652160",
    "end": "653839"
  },
  {
    "text": "clients",
    "start": "653839",
    "end": "655279"
  },
  {
    "text": "we can also scale the system",
    "start": "655279",
    "end": "658320"
  },
  {
    "text": "independently from the cassandra cluster",
    "start": "658320",
    "end": "660320"
  },
  {
    "text": "to account for changes",
    "start": "660320",
    "end": "661440"
  },
  {
    "text": "in the stream rate",
    "start": "661440",
    "end": "664240"
  },
  {
    "text": "we would like it if the system could be",
    "start": "664480",
    "end": "666320"
  },
  {
    "text": "open sourced easily also",
    "start": "666320",
    "end": "669680"
  },
  {
    "text": "apache flink is a streaming system which",
    "start": "669839",
    "end": "672560"
  },
  {
    "text": "acts",
    "start": "672560",
    "end": "672959"
  },
  {
    "text": "as a data plane in our solution the",
    "start": "672959",
    "end": "675200"
  },
  {
    "text": "major components",
    "start": "675200",
    "end": "676560"
  },
  {
    "text": "here include the input kafka topic",
    "start": "676560",
    "end": "680240"
  },
  {
    "text": "the flink application which reads from",
    "start": "680240",
    "end": "682720"
  },
  {
    "text": "this",
    "start": "682720",
    "end": "683440"
  },
  {
    "text": "the application itself maintains state",
    "start": "683440",
    "end": "686399"
  },
  {
    "text": "which in our case is rox tb",
    "start": "686399",
    "end": "688399"
  },
  {
    "text": "which is a ephemeral in-memory data",
    "start": "688399",
    "end": "692000"
  },
  {
    "text": "store",
    "start": "692000",
    "end": "693440"
  },
  {
    "text": "we can process incoming data from the",
    "start": "693440",
    "end": "696640"
  },
  {
    "text": "kafka input",
    "start": "696640",
    "end": "698000"
  },
  {
    "text": "and emit it to an output stream here",
    "start": "698000",
    "end": "701680"
  },
  {
    "text": "the flink application is able to process",
    "start": "701680",
    "end": "704320"
  },
  {
    "text": "the stream of data and recover from",
    "start": "704320",
    "end": "706000"
  },
  {
    "text": "failures",
    "start": "706000",
    "end": "706959"
  },
  {
    "text": "by having the stored application state",
    "start": "706959",
    "end": "708880"
  },
  {
    "text": "and kafka offsets",
    "start": "708880",
    "end": "710880"
  },
  {
    "text": "checkpointed at regular intervals we can",
    "start": "710880",
    "end": "713680"
  },
  {
    "text": "also scale this link application",
    "start": "713680",
    "end": "715920"
  },
  {
    "text": "independently of the cassandra cluster",
    "start": "715920",
    "end": "718639"
  },
  {
    "text": "we will see how this intermediary state",
    "start": "718639",
    "end": "720959"
  },
  {
    "text": "is leveraged to provide a cdc solution",
    "start": "720959",
    "end": "722720"
  },
  {
    "text": "for cassandra",
    "start": "722720",
    "end": "725360"
  },
  {
    "text": "let's look at this with an example so",
    "start": "725360",
    "end": "728639"
  },
  {
    "text": "let us say there is a new movie being",
    "start": "728639",
    "end": "731200"
  },
  {
    "text": "written into the database",
    "start": "731200",
    "end": "732880"
  },
  {
    "text": "with the movie id 842",
    "start": "732880",
    "end": "736160"
  },
  {
    "text": "for fargo and the status is private",
    "start": "736160",
    "end": "739680"
  },
  {
    "text": "the sidecar would read this mutation",
    "start": "739680",
    "end": "742959"
  },
  {
    "text": "and write it to the cdc kafka topic",
    "start": "742959",
    "end": "746320"
  },
  {
    "text": "this would then end up",
    "start": "746320",
    "end": "749440"
  },
  {
    "text": "being read by the flink application and",
    "start": "749440",
    "end": "753360"
  },
  {
    "text": "written into the rocks tv store",
    "start": "753360",
    "end": "756720"
  },
  {
    "text": "with the partition key and the mutation",
    "start": "756720",
    "end": "759680"
  },
  {
    "text": "information",
    "start": "759680",
    "end": "761120"
  },
  {
    "text": "as this is a fresh row it would have all",
    "start": "761120",
    "end": "763680"
  },
  {
    "text": "of the information",
    "start": "763680",
    "end": "764639"
  },
  {
    "text": "for that particular row and the second",
    "start": "764639",
    "end": "767279"
  },
  {
    "text": "kafka topic then gets a record",
    "start": "767279",
    "end": "769360"
  },
  {
    "text": "for that row with the create operation",
    "start": "769360",
    "end": "773360"
  },
  {
    "text": "as you can see here we maintain a fourth",
    "start": "773360",
    "end": "775839"
  },
  {
    "text": "copy of the data",
    "start": "775839",
    "end": "777120"
  },
  {
    "text": "outside of cassandra let's see why",
    "start": "777120",
    "end": "780399"
  },
  {
    "text": "this would be required",
    "start": "780399",
    "end": "783600"
  },
  {
    "text": "now let's update that row to have",
    "start": "784399",
    "end": "787040"
  },
  {
    "text": "different information",
    "start": "787040",
    "end": "788240"
  },
  {
    "text": "in the columns we want to change",
    "start": "788240",
    "end": "792480"
  },
  {
    "text": "the status of fargo from private to",
    "start": "792480",
    "end": "795120"
  },
  {
    "text": "public",
    "start": "795120",
    "end": "796880"
  },
  {
    "text": "now when we make that update in",
    "start": "796880",
    "end": "798839"
  },
  {
    "text": "cassandra",
    "start": "798839",
    "end": "800079"
  },
  {
    "text": "the sidecar emits that change to",
    "start": "800079",
    "end": "803440"
  },
  {
    "text": "the cdc kafka topic it is",
    "start": "803440",
    "end": "806800"
  },
  {
    "text": "important to note that the change",
    "start": "806800",
    "end": "809920"
  },
  {
    "text": "in the kafka topic only has the changed",
    "start": "809920",
    "end": "812959"
  },
  {
    "text": "columns but not",
    "start": "812959",
    "end": "814000"
  },
  {
    "text": "all of the row information specifically",
    "start": "814000",
    "end": "817360"
  },
  {
    "text": "we are missing the information that",
    "start": "817360",
    "end": "820560"
  },
  {
    "text": "fargo is part of this row",
    "start": "820560",
    "end": "824320"
  },
  {
    "text": "but when this is sent",
    "start": "824320",
    "end": "827600"
  },
  {
    "text": "to the flink application we have",
    "start": "827600",
    "end": "830720"
  },
  {
    "text": "the previous mutation which came for",
    "start": "830720",
    "end": "833440"
  },
  {
    "text": "this particular partition key",
    "start": "833440",
    "end": "835120"
  },
  {
    "text": "and we can reconcile that with the",
    "start": "835120",
    "end": "838079"
  },
  {
    "text": "incoming",
    "start": "838079",
    "end": "840079"
  },
  {
    "text": "event and make sure that we have a full",
    "start": "840079",
    "end": "843600"
  },
  {
    "text": "row image",
    "start": "843600",
    "end": "844560"
  },
  {
    "text": "generated in this data store this is",
    "start": "844560",
    "end": "847199"
  },
  {
    "text": "then emitted as an update",
    "start": "847199",
    "end": "849040"
  },
  {
    "text": "for that particular row into the source",
    "start": "849040",
    "end": "851279"
  },
  {
    "text": "connected kafka",
    "start": "851279",
    "end": "853839"
  },
  {
    "text": "now let's look at how a delete would",
    "start": "853839",
    "end": "856639"
  },
  {
    "text": "happen",
    "start": "856639",
    "end": "857600"
  },
  {
    "text": "if we end up deleting that same row from",
    "start": "857600",
    "end": "860800"
  },
  {
    "text": "cassandra we store a delete",
    "start": "860800",
    "end": "864320"
  },
  {
    "text": "for that particular partition key",
    "start": "864320",
    "end": "869040"
  },
  {
    "text": "in cassandra as a tombstone now",
    "start": "869040",
    "end": "871920"
  },
  {
    "text": "cassandra would end up",
    "start": "871920",
    "end": "873360"
  },
  {
    "text": "removing this tombstone after gc3",
    "start": "873360",
    "end": "875440"
  },
  {
    "text": "seconds",
    "start": "875440",
    "end": "876800"
  },
  {
    "text": "so the sidecar would serialize this",
    "start": "876800",
    "end": "880079"
  },
  {
    "text": "mutation and we would store",
    "start": "880079",
    "end": "883120"
  },
  {
    "text": "that particular delete within",
    "start": "883120",
    "end": "886480"
  },
  {
    "text": "the data store here",
    "start": "886480",
    "end": "889920"
  },
  {
    "text": "and emit the delete information",
    "start": "890480",
    "end": "893680"
  },
  {
    "text": "to the source connector kafka we also",
    "start": "893680",
    "end": "897360"
  },
  {
    "text": "at the same time store a timer within",
    "start": "897360",
    "end": "900720"
  },
  {
    "text": "flink state to make sure that we remove",
    "start": "900720",
    "end": "903760"
  },
  {
    "text": "this partition key",
    "start": "903760",
    "end": "905440"
  },
  {
    "text": "from the map if there are no",
    "start": "905440",
    "end": "908639"
  },
  {
    "text": "future updates which come for this",
    "start": "908639",
    "end": "911920"
  },
  {
    "text": "particular partition key",
    "start": "911920",
    "end": "913279"
  },
  {
    "text": "with a higher timestamp",
    "start": "913279",
    "end": "916399"
  },
  {
    "text": "this way we can make sure that the data",
    "start": "916720",
    "end": "920000"
  },
  {
    "text": "grows and shrinks correctly according to",
    "start": "920000",
    "end": "922480"
  },
  {
    "text": "whatever is happening",
    "start": "922480",
    "end": "923519"
  },
  {
    "text": "on cassandra now how do we make sure",
    "start": "923519",
    "end": "928000"
  },
  {
    "text": "we can guarantee uniqueness and or and",
    "start": "928000",
    "end": "930480"
  },
  {
    "text": "ordering",
    "start": "930480",
    "end": "931120"
  },
  {
    "text": "in our output stream unique mutations",
    "start": "931120",
    "end": "934639"
  },
  {
    "text": "in the source connector kafka stream can",
    "start": "934639",
    "end": "937759"
  },
  {
    "text": "be",
    "start": "937759",
    "end": "938720"
  },
  {
    "text": "achieved by checking",
    "start": "938720",
    "end": "941920"
  },
  {
    "text": "that we",
    "start": "941920",
    "end": "944959"
  },
  {
    "text": "have already processed this particular",
    "start": "945120",
    "end": "947600"
  },
  {
    "text": "information",
    "start": "947600",
    "end": "948720"
  },
  {
    "text": "from a previous replica so when the",
    "start": "948720",
    "end": "951360"
  },
  {
    "text": "second replica",
    "start": "951360",
    "end": "952320"
  },
  {
    "text": "ends up emitting this same information",
    "start": "952320",
    "end": "956079"
  },
  {
    "text": "we do not send the",
    "start": "956079",
    "end": "959120"
  },
  {
    "text": "row update to the source connector kafka",
    "start": "959120",
    "end": "964399"
  },
  {
    "text": "ordering is guaranteed by making the cdc",
    "start": "964639",
    "end": "967759"
  },
  {
    "text": "kafka topic",
    "start": "967759",
    "end": "968800"
  },
  {
    "text": "a key topic where the key is",
    "start": "968800",
    "end": "972399"
  },
  {
    "text": "the partition key of the change this way",
    "start": "972399",
    "end": "975199"
  },
  {
    "text": "all changes",
    "start": "975199",
    "end": "976399"
  },
  {
    "text": "for a particular partition key arrive at",
    "start": "976399",
    "end": "979199"
  },
  {
    "text": "the same",
    "start": "979199",
    "end": "979839"
  },
  {
    "text": "consumer influence and because we have",
    "start": "979839",
    "end": "983040"
  },
  {
    "text": "the same storage",
    "start": "983040",
    "end": "984079"
  },
  {
    "text": "engine we can recreate order for these",
    "start": "984079",
    "end": "987360"
  },
  {
    "text": "changes",
    "start": "987360",
    "end": "988079"
  },
  {
    "text": "correctly there is a cost to be paid for",
    "start": "988079",
    "end": "991680"
  },
  {
    "text": "the ordering",
    "start": "991680",
    "end": "992560"
  },
  {
    "text": "we would need to deserialize the",
    "start": "992560",
    "end": "994079"
  },
  {
    "text": "mutation to know which partitioning key",
    "start": "994079",
    "end": "996560"
  },
  {
    "text": "to use and serialize it back before",
    "start": "996560",
    "end": "998480"
  },
  {
    "text": "writing it into the power series of the",
    "start": "998480",
    "end": "1000240"
  },
  {
    "text": "bucket",
    "start": "1000240",
    "end": "1002560"
  },
  {
    "text": "what happens when the schema of a column",
    "start": "1003199",
    "end": "1005680"
  },
  {
    "text": "family changes",
    "start": "1005680",
    "end": "1006959"
  },
  {
    "text": "the cassandra storage engine in flink",
    "start": "1006959",
    "end": "1009120"
  },
  {
    "text": "needs to have the right schema",
    "start": "1009120",
    "end": "1010399"
  },
  {
    "text": "information",
    "start": "1010399",
    "end": "1012160"
  },
  {
    "text": "in order to deserialize mutation",
    "start": "1012160",
    "end": "1013920"
  },
  {
    "text": "correctly for this",
    "start": "1013920",
    "end": "1015600"
  },
  {
    "text": "we listen for schema changes by",
    "start": "1015600",
    "end": "1017199"
  },
  {
    "text": "registering with the cassandra cluster",
    "start": "1017199",
    "end": "1019600"
  },
  {
    "text": "to make sure we have this up-to-date",
    "start": "1019600",
    "end": "1022839"
  },
  {
    "text": "information",
    "start": "1022839",
    "end": "1025839"
  },
  {
    "start": "1026000",
    "end": "1057000"
  },
  {
    "text": "how do we make sure we have filtering",
    "start": "1026000",
    "end": "1029760"
  },
  {
    "text": "of the output change data capture stream",
    "start": "1029760",
    "end": "1035839"
  },
  {
    "text": "this is required because the original",
    "start": "1036240",
    "end": "1038480"
  },
  {
    "text": "cdc stream from cassandra will have",
    "start": "1038480",
    "end": "1040319"
  },
  {
    "text": "changes from",
    "start": "1040319",
    "end": "1041038"
  },
  {
    "text": "all of the column families or tables for",
    "start": "1041039",
    "end": "1043360"
  },
  {
    "text": "that particular cluster",
    "start": "1043360",
    "end": "1044959"
  },
  {
    "text": "we would normally want this as separate",
    "start": "1044959",
    "end": "1046720"
  },
  {
    "text": "streams and with specific fields",
    "start": "1046720",
    "end": "1048799"
  },
  {
    "text": "we can perform this filtering at the",
    "start": "1048799",
    "end": "1050320"
  },
  {
    "text": "flink application and generate",
    "start": "1050320",
    "end": "1052640"
  },
  {
    "text": "messages to multiple kafka topics one",
    "start": "1052640",
    "end": "1055039"
  },
  {
    "text": "per column",
    "start": "1055039",
    "end": "1057440"
  },
  {
    "start": "1057000",
    "end": "1185000"
  },
  {
    "text": "what are some challenges with this",
    "start": "1057440",
    "end": "1059760"
  },
  {
    "text": "solution",
    "start": "1059760",
    "end": "1061600"
  },
  {
    "text": "we obviously need to keep an additional",
    "start": "1061600",
    "end": "1063520"
  },
  {
    "text": "copy of the data",
    "start": "1063520",
    "end": "1064640"
  },
  {
    "text": "so if your replication factor is already",
    "start": "1064640",
    "end": "1067039"
  },
  {
    "text": "three",
    "start": "1067039",
    "end": "1067919"
  },
  {
    "text": "for cassandra resiliency then you have",
    "start": "1067919",
    "end": "1070240"
  },
  {
    "text": "four copies",
    "start": "1070240",
    "end": "1071600"
  },
  {
    "text": "this added cost is on both",
    "start": "1071600",
    "end": "1073600"
  },
  {
    "text": "infrastructure and maintenance",
    "start": "1073600",
    "end": "1076320"
  },
  {
    "text": "what happens when the right throughput",
    "start": "1076320",
    "end": "1079120"
  },
  {
    "text": "on cassandra",
    "start": "1079120",
    "end": "1080160"
  },
  {
    "text": "is higher than what kafka can safely",
    "start": "1080160",
    "end": "1082640"
  },
  {
    "text": "handle",
    "start": "1082640",
    "end": "1083919"
  },
  {
    "text": "we could drop the stream to keep",
    "start": "1083919",
    "end": "1086320"
  },
  {
    "text": "cassandra available",
    "start": "1086320",
    "end": "1088000"
  },
  {
    "text": "but this would mean we need to backfill",
    "start": "1088000",
    "end": "1091520"
  },
  {
    "text": "from",
    "start": "1091520",
    "end": "1091840"
  },
  {
    "text": "ss tables at scale we would also need to",
    "start": "1091840",
    "end": "1095840"
  },
  {
    "text": "make sure",
    "start": "1095840",
    "end": "1096640"
  },
  {
    "text": "that the flink system and cassandra",
    "start": "1096640",
    "end": "1099280"
  },
  {
    "text": "cluster which is emitting changes",
    "start": "1099280",
    "end": "1100960"
  },
  {
    "text": "at the same version of the storage",
    "start": "1100960",
    "end": "1103200"
  },
  {
    "text": "engine",
    "start": "1103200",
    "end": "1104240"
  },
  {
    "text": "which is also an operational overhead",
    "start": "1104240",
    "end": "1109840"
  },
  {
    "text": "here we've seen how we can get an",
    "start": "1109840",
    "end": "1111600"
  },
  {
    "text": "eventually consistent",
    "start": "1111600",
    "end": "1112880"
  },
  {
    "text": "change stream from an active active",
    "start": "1112880",
    "end": "1114960"
  },
  {
    "text": "setup database",
    "start": "1114960",
    "end": "1116000"
  },
  {
    "text": "like cassandra we have a stream which is",
    "start": "1116000",
    "end": "1118480"
  },
  {
    "text": "unique",
    "start": "1118480",
    "end": "1119120"
  },
  {
    "text": "ordered full rose and filter",
    "start": "1119120",
    "end": "1122400"
  },
  {
    "text": "our solution could be extended to",
    "start": "1122400",
    "end": "1124320"
  },
  {
    "text": "support other databases",
    "start": "1124320",
    "end": "1126080"
  },
  {
    "text": "which have architectures similar to",
    "start": "1126080",
    "end": "1128080"
  },
  {
    "text": "cassandra",
    "start": "1128080",
    "end": "1129679"
  },
  {
    "text": "where cdc is not supported out of the",
    "start": "1129679",
    "end": "1131360"
  },
  {
    "text": "box",
    "start": "1131360",
    "end": "1132799"
  },
  {
    "text": "there are still a lot of questions",
    "start": "1132799",
    "end": "1136000"
  },
  {
    "text": "left with some solutions in the horizon",
    "start": "1136000",
    "end": "1138480"
  },
  {
    "text": "for example",
    "start": "1138480",
    "end": "1139360"
  },
  {
    "text": "how can we make sure we have a schema",
    "start": "1139360",
    "end": "1141280"
  },
  {
    "text": "attached to the output stream",
    "start": "1141280",
    "end": "1142960"
  },
  {
    "text": "and make schema evolution possible",
    "start": "1142960",
    "end": "1146480"
  },
  {
    "text": "how do we scale this to handle data at",
    "start": "1146480",
    "end": "1149280"
  },
  {
    "text": "the scale at which netflix systems",
    "start": "1149280",
    "end": "1150880"
  },
  {
    "text": "operate",
    "start": "1150880",
    "end": "1152160"
  },
  {
    "text": "how does this operating fraud what are",
    "start": "1152160",
    "end": "1154559"
  },
  {
    "text": "some operational challenges",
    "start": "1154559",
    "end": "1156400"
  },
  {
    "text": "for managing this infrastructure at",
    "start": "1156400",
    "end": "1158400"
  },
  {
    "text": "scale",
    "start": "1158400",
    "end": "1159679"
  },
  {
    "text": "stay tuned for answers to all these",
    "start": "1159679",
    "end": "1161360"
  },
  {
    "text": "questions and more",
    "start": "1161360",
    "end": "1163520"
  },
  {
    "text": "in a future blog post",
    "start": "1163520",
    "end": "1166880"
  },
  {
    "text": "this work would not have been possible",
    "start": "1166880",
    "end": "1168480"
  },
  {
    "text": "without the help of many others",
    "start": "1168480",
    "end": "1170080"
  },
  {
    "text": "at netflix i'd like to especially thank",
    "start": "1170080",
    "end": "1172960"
  },
  {
    "text": "taranga and samantha",
    "start": "1172960",
    "end": "1174400"
  },
  {
    "text": "for their contributions",
    "start": "1174400",
    "end": "1178080"
  },
  {
    "text": "thank you here's my contact information",
    "start": "1178080",
    "end": "1180240"
  },
  {
    "text": "please feel free to reach out if you",
    "start": "1180240",
    "end": "1181679"
  },
  {
    "text": "have",
    "start": "1181679",
    "end": "1182000"
  },
  {
    "text": "any further questions on this topic",
    "start": "1182000",
    "end": "1187679"
  }
]
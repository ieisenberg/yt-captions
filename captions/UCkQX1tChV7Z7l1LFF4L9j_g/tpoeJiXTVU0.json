[
  {
    "text": "foreign [Music]",
    "start": "1380",
    "end": "14249"
  },
  {
    "text": "Tuesday Morning a developer sits down at their desk",
    "start": "15360",
    "end": "21420"
  },
  {
    "text": "opens up their laptop they look at some dashboards Maybe",
    "start": "21420",
    "end": "28320"
  },
  {
    "text": "oh hey is this blip in the error rate could that possibly be related to the change I",
    "start": "28320",
    "end": "35340"
  },
  {
    "text": "pushed yesterday hmm they open up their log aggregator and they they type in a query",
    "start": "35340",
    "end": "43879"
  },
  {
    "text": "take a sip of coffee might as well go get another cup",
    "start": "44100",
    "end": "52218"
  },
  {
    "text": "that's it that's the whole story they never get back to that question maybe maybe the kid walked in and",
    "start": "54539",
    "end": "61860"
  },
  {
    "text": "distracted them maybe they got an email who knows their attention's gone",
    "start": "61860",
    "end": "67580"
  },
  {
    "text": "I'm Jessica care jessitron I'm happy to be here today to talk to you about how",
    "start": "68460",
    "end": "73920"
  },
  {
    "text": "at honeycomb we use serverless functions to speed up our database servers",
    "start": "73920",
    "end": "79200"
  },
  {
    "text": "I want to give credit to Ian Wilkes who told me this story initially because he's our primary database engineer and",
    "start": "79200",
    "end": "85920"
  },
  {
    "text": "Liz Fong Jones she's responsible for a lot of this story too",
    "start": "85920",
    "end": "91140"
  },
  {
    "text": "I'm going to talk about how serverless is useful to us at honeycomb not for",
    "start": "91140",
    "end": "96600"
  },
  {
    "text": "answering web requests but for on-demand compute and then I'll talk about some of the",
    "start": "96600",
    "end": "101939"
  },
  {
    "text": "ways that it was tricky some of the obstacles that we overcame to get this working smoothly and finally how you",
    "start": "101939",
    "end": "109500"
  },
  {
    "text": "might use serverless some things to watch out for what kind of workloads you might use this for",
    "start": "109500",
    "end": "116899"
  },
  {
    "text": "let's go first I need to tell you why we use serverless at all so we use Lambda functions on AWS Lambda",
    "start": "117000",
    "end": "124979"
  },
  {
    "text": "to supplement our custom data store whose name is retriever now your first",
    "start": "124979",
    "end": "131280"
  },
  {
    "text": "question there should definitely be why do you have a custom data store because the answer to let's write our own",
    "start": "131280",
    "end": "137819"
  },
  {
    "text": "database is no but in our case our Founders tried that",
    "start": "137819",
    "end": "143580"
  },
  {
    "text": "and it turned out that we are really specialized retriever",
    "start": "143580",
    "end": "149700"
  },
  {
    "text": "is a special purpose data store for real-time event aggregation for interactive querying over traces over",
    "start": "149700",
    "end": "157080"
  },
  {
    "text": "Telemetry data for observability oh now why would we want to do that",
    "start": "157080",
    "end": "162120"
  },
  {
    "text": "because honeycomb's vision of observability is highly Interactive",
    "start": "162120",
    "end": "168660"
  },
  {
    "text": "people should be able to find out what's going on in their Software System when",
    "start": "168660",
    "end": "173940"
  },
  {
    "text": "they need to know not just learn that something's wrong but be able to ask what's wrong how is this different",
    "start": "173940",
    "end": "182340"
  },
  {
    "text": "what does normal look like a repeated question structure always get",
    "start": "182340",
    "end": "187980"
  },
  {
    "text": "to New questions so the difference for us between monitoring and observability is in",
    "start": "187980",
    "end": "193860"
  },
  {
    "text": "monitoring you decided up front what you want to watch for you maybe watch for",
    "start": "193860",
    "end": "199200"
  },
  {
    "text": "everything that has been a problem in the past Maybe and then when you want to graph over",
    "start": "199200",
    "end": "204900"
  },
  {
    "text": "that you can graph that over any period of time and it's really fast because you've stored it in a Time series",
    "start": "204900",
    "end": "210540"
  },
  {
    "text": "database you've done all the aggregating already in a honeycomb like you don't yet know",
    "start": "210540",
    "end": "219000"
  },
  {
    "text": "what you are going to need to ask about production data so dump it all into",
    "start": "219000",
    "end": "224040"
  },
  {
    "text": "events we'll put it in a retriever and then we'll make every graph then",
    "start": "224040",
    "end": "230400"
  },
  {
    "text": "we'll make every graph fast so each different field that you might",
    "start": "230400",
    "end": "237120"
  },
  {
    "text": "want to group by or aggregate over each different aggregation you might want to do from a simple count to a p50 or a P90",
    "start": "237120",
    "end": "245099"
  },
  {
    "text": "or a P99 or a heat map over the whole distribution our goal is to make all of these graphs",
    "start": "245099",
    "end": "251700"
  },
  {
    "text": "fast so that you can get the information you need and immediately start querying",
    "start": "251700",
    "end": "256859"
  },
  {
    "text": "it for more more information it goes kind of like this so say I want to know",
    "start": "256859",
    "end": "263400"
  },
  {
    "text": "how long are Lambda functions take to execute what's the average execution",
    "start": "263400",
    "end": "268979"
  },
  {
    "text": "time it's not always the most useful useful metric but we can use it today okay so I",
    "start": "268979",
    "end": "274080"
  },
  {
    "text": "know I need to look in retrievers data set for something in Lambda but I don't",
    "start": "274080",
    "end": "279840"
  },
  {
    "text": "remember the name of the spans I'm looking for so I'll just ask it for a",
    "start": "279840",
    "end": "284880"
  },
  {
    "text": "group by name give me all the different names of this bands ah I recognize this",
    "start": "284880",
    "end": "290280"
  },
  {
    "text": "one invoke I'm looking for invoke so next question run this query but show me",
    "start": "290280",
    "end": "295860"
  },
  {
    "text": "only the invoke spans uh oh okay God that's back next query",
    "start": "295860",
    "end": "301020"
  },
  {
    "text": "show me the average of their durations all right I can scroll down and I can",
    "start": "301020",
    "end": "306120"
  },
  {
    "text": "see what that is and then I get curious this is important I'm like why is this",
    "start": "306120",
    "end": "311340"
  },
  {
    "text": "so spiky what is going on over here where it's like super jumpy and the the",
    "start": "311340",
    "end": "316919"
  },
  {
    "text": "count is way higher and the the average duration is bouncy and I'm like wow look",
    "start": "316919",
    "end": "322259"
  },
  {
    "text": "at this look at that spike in in the p50 of the duration median duration",
    "start": "322259",
    "end": "327960"
  },
  {
    "text": "um down there let me let's see I'll heat map over that it doesn't look like they're particularly",
    "start": "327960",
    "end": "334620"
  },
  {
    "text": "slower in the distribution but let's say okay what is different about",
    "start": "334620",
    "end": "339660"
  },
  {
    "text": "these spans compared to everything else in the graph and honeycomb does a",
    "start": "339660",
    "end": "345539"
  },
  {
    "text": "statistical analysis of what's going on and then we can scroll down and we can",
    "start": "345539",
    "end": "350940"
  },
  {
    "text": "see what's different okay it looks like for the spans in this box I drew they're",
    "start": "350940",
    "end": "357479"
  },
  {
    "text": "mostly from queries okay and they have a single trace ID so they're from this particular query okay so now next",
    "start": "357479",
    "end": "365340"
  },
  {
    "text": "aggregation give me only the spans inside this Trace so now I'm seeing all",
    "start": "365340",
    "end": "370560"
  },
  {
    "text": "the invocations in this one query okay but now I want to know like what query were they running that like",
    "start": "370560",
    "end": "378300"
  },
  {
    "text": "made it take so long all right so instead of looking for the invocations let's look through this Trace but let's",
    "start": "378300",
    "end": "383759"
  },
  {
    "text": "find something with like a query spec in it and now I'm gonna get back probably just",
    "start": "383759",
    "end": "389940"
  },
  {
    "text": "one span oh a couple spans okay a retriever client fetch I recognize that",
    "start": "389940",
    "end": "395580"
  },
  {
    "text": "name that's the one that's gonna tell me what uh what this particular customer is",
    "start": "395580",
    "end": "401580"
  },
  {
    "text": "trying to do if I flip over to Raw data then I can see all of the fields that we sent in retrieve a client fetch oh oh",
    "start": "401580",
    "end": "408360"
  },
  {
    "text": "look there's the query spec right there yeah yeah I'm not sure exactly what that is",
    "start": "408360",
    "end": "413759"
  },
  {
    "text": "but it looks hard some queries the customer's friend are definitely harder than others",
    "start": "413759",
    "end": "421759"
  },
  {
    "text": "but the point is to get this interactive feel this back and forth this dialogue",
    "start": "422100",
    "end": "428039"
  },
  {
    "text": "going with your production data so that you can continue to ask new questions over and over and for that it has to be",
    "start": "428039",
    "end": "436020"
  },
  {
    "text": "fast it has to be really fast like if if I hit run query and then I take a sip of",
    "start": "436020",
    "end": "441660"
  },
  {
    "text": "coffee okay now I should have my answer if I",
    "start": "441660",
    "end": "447240"
  },
  {
    "text": "have to go get another cup complete failure we've lost we've lost the",
    "start": "447240",
    "end": "452699"
  },
  {
    "text": "developer or that SRE um and that's not good enough",
    "start": "452699",
    "end": "458819"
  },
  {
    "text": "so the emphasis on this is on the interactivity here 10 seconds is a little slow one second",
    "start": "458819",
    "end": "465419"
  },
  {
    "text": "is great uh but a minute write out how do we do this okay architecture of",
    "start": "465419",
    "end": "472800"
  },
  {
    "text": "retriever um customers send us events we put them in the database",
    "start": "472800",
    "end": "479660"
  },
  {
    "text": "and then developers and sres and product and whoever runs the queries from our",
    "start": "479660",
    "end": "486479"
  },
  {
    "text": "our web app of course at the events coming in Kafka which makes that this is not weird and",
    "start": "486479",
    "end": "494039"
  },
  {
    "text": "naturally we partition them so retriever is a distributed data store and there's",
    "start": "494039",
    "end": "500099"
  },
  {
    "text": "a retriever to read off of each topic actually there's I didn't draw two but there's two retrievers to read off of each topic so that we have redundancy",
    "start": "500099",
    "end": "507479"
  },
  {
    "text": "there and it reads all the events and then it writes them to Local disk because local disk is fast in memory is",
    "start": "507479",
    "end": "515459"
  },
  {
    "text": "too expensive anywhere else is slower so it writes all these things to local disk and um",
    "start": "515459",
    "end": "522240"
  },
  {
    "text": "that's quick so the more retrievers we have the more local disks we have then when a query comes in it comes into",
    "start": "522240",
    "end": "529080"
  },
  {
    "text": "one Retriever and that retriever says oh okay this data set has data in these",
    "start": "529080",
    "end": "535320"
  },
  {
    "text": "this many other partitions sends off um inner queries to all of those retrievers",
    "start": "535320",
    "end": "542760"
  },
  {
    "text": "so that they can access their local disks and then there's a big mapreduce operation going on it comes back to the",
    "start": "542760",
    "end": "549300"
  },
  {
    "text": "retriever you asked and it responds to the UI okay so that's the the distributed part",
    "start": "549300",
    "end": "555360"
  },
  {
    "text": "the next trick to making this really fast is that retriever is a column store",
    "start": "555360",
    "end": "561000"
  },
  {
    "text": "and it's been a column store since before these were super cool but it's still super cool",
    "start": "561000",
    "end": "567240"
  },
  {
    "text": "um so every field that comes in with an event goes in a separate file",
    "start": "567240",
    "end": "573600"
  },
  {
    "text": "uh that's that's fine this is how we scale with quantity of fields on the event",
    "start": "573600",
    "end": "579660"
  },
  {
    "text": "because at honeycomb we want you to send all kinds of fields and they can have",
    "start": "579660",
    "end": "585240"
  },
  {
    "text": "all different values we don't care because we're only going to access the ones we need",
    "start": "585240",
    "end": "591120"
  },
  {
    "text": "so when a query comes in the if we're looking for service name equals Lambda",
    "start": "591120",
    "end": "597779"
  },
  {
    "text": "and name of the span is invoke and we're",
    "start": "597779",
    "end": "603140"
  },
  {
    "text": "aggregating over the duration all retrievers going to look at is the",
    "start": "603140",
    "end": "608160"
  },
  {
    "text": "service name the name and the duration columns and the timestamp there's always a time stamp associated with every query",
    "start": "608160",
    "end": "615240"
  },
  {
    "text": "so that's the next trick is in order to segment this data we use timestamp at",
    "start": "615240",
    "end": "621000"
  },
  {
    "text": "honeycomb I like to say we don't index on anything but that's not quite true we index on timestamp",
    "start": "621000",
    "end": "627019"
  },
  {
    "text": "so the data is broken into segments based on like I think at most 12 hours",
    "start": "627019",
    "end": "633480"
  },
  {
    "text": "or a million events or a certain number of megabytes in a in a file and then",
    "start": "633480",
    "end": "639959"
  },
  {
    "text": "we'll roll over to the next segment um and then we record like what time",
    "start": "639959",
    "end": "645540"
  },
  {
    "text": "stamps are the earliest and latest in each segment and that way when a query comes in we're like okay the query has",
    "start": "645540",
    "end": "652380"
  },
  {
    "text": "this time range we're going to get all the segments that overlap that time range and we're going to look through uh",
    "start": "652380",
    "end": "660060"
  },
  {
    "text": "the timestamp file to find out which events qualify and that's how retriever",
    "start": "660060",
    "end": "665820"
  },
  {
    "text": "achieves Dynamic aggregation of any Fields across any time range at that interactive query speed",
    "start": "665820",
    "end": "672420"
  },
  {
    "text": "okay but then we have the problem of success and we've got bigger customers with more data coming",
    "start": "672420",
    "end": "679740"
  },
  {
    "text": "in and data sets are getting bigger and the thing is our strategy used to be whenever we run out of space for a",
    "start": "679740",
    "end": "687959"
  },
  {
    "text": "particular data set new segment starts older segments get get deleted and that",
    "start": "687959",
    "end": "693000"
  },
  {
    "text": "was fine when the oldest segment was like a week old the point is your current production",
    "start": "693000",
    "end": "698160"
  },
  {
    "text": "data is what's most important right but we got data sets that were big enough",
    "start": "698160",
    "end": "703320"
  },
  {
    "text": "that it are like maximum allocation for a data set we were throwing away data",
    "start": "703320",
    "end": "708420"
  },
  {
    "text": "from like 10 minutes ago that's not okay you need more than 10",
    "start": "708420",
    "end": "714240"
  },
  {
    "text": "minutes window into your production system so well we did what everybody does when",
    "start": "714240",
    "end": "721440"
  },
  {
    "text": "there's too much data we started putting it in S3 so this time instead of deleting the",
    "start": "721440",
    "end": "728220"
  },
  {
    "text": "oldest segment we're shipping it up to S3 and each retriever still takes responsibility for all of the segments",
    "start": "728220",
    "end": "735120"
  },
  {
    "text": "in its partition it's just that now we're not limited in storage so we can",
    "start": "735120",
    "end": "741000"
  },
  {
    "text": "store it up to 60 days and that's that's a much much better",
    "start": "741000",
    "end": "746240"
  },
  {
    "text": "time window than until we run out of space much more predictable",
    "start": "746240",
    "end": "752459"
  },
  {
    "text": "uh and then those queries are going to be slower they're not as fast as local disk but it's that it's that uh",
    "start": "752459",
    "end": "759720"
  },
  {
    "text": "the most recent stuff that you query the most often and that's what you want to be really",
    "start": "759720",
    "end": "764760"
  },
  {
    "text": "fast it's also the stuff that's the most urgent so we're like okay so each retriever will just um",
    "start": "764760",
    "end": "770339"
  },
  {
    "text": "when it needs some data that's older it'll go download those files from S3 and include those in the query and it",
    "start": "770339",
    "end": "776339"
  },
  {
    "text": "won't be quite as fast but uh but it it'll be a lot more flexible because you have more data right that's",
    "start": "776339",
    "end": "781920"
  },
  {
    "text": "good now people can run queries over 60 days worth of data hooray",
    "start": "781920",
    "end": "789079"
  },
  {
    "text": "oh no no wait a minute wait a minute 60 days is a lot how much longer is that gonna",
    "start": "789120",
    "end": "795660"
  },
  {
    "text": "take and now we start to get um when",
    "start": "795660",
    "end": "801060"
  },
  {
    "text": "when you're reading from local disk it's really fast but as soon as you hit S3 the query time grows at least linearly",
    "start": "801060",
    "end": "808980"
  },
  {
    "text": "with the number of segments that it has to download and query and so if you if",
    "start": "808980",
    "end": "815220"
  },
  {
    "text": "you query for the last few minutes yeah you can take a sip of coffee but if you query for the last few days",
    "start": "815220",
    "end": "822480"
  },
  {
    "text": "you might have to take a couple sips and 60 days it was",
    "start": "822480",
    "end": "827660"
  },
  {
    "text": "we we had to change our maximum query timeout to an hour",
    "start": "827760",
    "end": "833700"
  },
  {
    "text": "oh my gosh that's Way Beyond a cup of coffee that's like roast the Beans and Brew the pot I hear you can roast beans",
    "start": "833700",
    "end": "840420"
  },
  {
    "text": "it doesn't take that long but this took too long so that was not okay what are we gonna",
    "start": "840420",
    "end": "846000"
  },
  {
    "text": "do retriever is like I need more compute the network wasn't the uh the bottleneck",
    "start": "846000",
    "end": "853200"
  },
  {
    "text": "here it was actually the compute because we're doing um all those those reads and the",
    "start": "853200",
    "end": "859860"
  },
  {
    "text": "aggregations and uh group buys and filters and all that stuff in memory",
    "start": "859860",
    "end": "865800"
  },
  {
    "text": "um at query time compute was on limitation all right uh so so we could just like",
    "start": "865800",
    "end": "872760"
  },
  {
    "text": "spin up more retrievers we could get more ec2 instances I mean you can buy compute right except we really don't",
    "start": "872760",
    "end": "879540"
  },
  {
    "text": "need it all the time the retriever dog doesn't always want to play uh so this is like when we need to",
    "start": "879540",
    "end": "887519"
  },
  {
    "text": "compute this is uh the concurrency of how many lambdas are we running at any one time and it's it's super spiky often",
    "start": "887519",
    "end": "895560"
  },
  {
    "text": "pretty much none sometimes we need thousands",
    "start": "895560",
    "end": "902820"
  },
  {
    "text": "um and uh this is very different from the compute profile of ec2 because we",
    "start": "902820",
    "end": "908339"
  },
  {
    "text": "don't need it 30 seconds from now after you use I mean even if an instance spun",
    "start": "908339",
    "end": "914220"
  },
  {
    "text": "up that fast which they don't all um that's too long we need",
    "start": "914220",
    "end": "920459"
  },
  {
    "text": "sudden access to compute while you're lifting your cup and that is exactly what serverless",
    "start": "920459",
    "end": "926519"
  },
  {
    "text": "provides also lambdas are like right next door to S3 right",
    "start": "926519",
    "end": "932220"
  },
  {
    "text": "so okay so okay retriever you get some minions and now",
    "start": "932220",
    "end": "938100"
  },
  {
    "text": "um when a retriever needs to access its segments in S3 it spins up a Lambda for",
    "start": "938100",
    "end": "943440"
  },
  {
    "text": "each eight or so segments and that Lambda reads the data from S3 decrypts",
    "start": "943440",
    "end": "949740"
  },
  {
    "text": "it looks at the the files just that it needs to does the aggregations sense the",
    "start": "949740",
    "end": "955019"
  },
  {
    "text": "intermediate results Retriever and the mapreduce operation flows upward",
    "start": "955019",
    "end": "961560"
  },
  {
    "text": "this is much better see our query time I mean it still goes up with the number of segments queried",
    "start": "961560",
    "end": "967680"
  },
  {
    "text": "that's not weird but it's very sublinear and if you're running a 60-day query and",
    "start": "967680",
    "end": "974639"
  },
  {
    "text": "it's a hard one you might get more than one sip in but you're not gonna have to go get another cup",
    "start": "974639",
    "end": "981480"
  },
  {
    "text": "when turns out that buy and compute in used",
    "start": "981480",
    "end": "986699"
  },
  {
    "text": "to be 100 milliseconds now it's one millisecond increments you can do it and uh this is like us",
    "start": "986699",
    "end": "994380"
  },
  {
    "text": "scaling the compute so that the time of the query doesn't scale with how much it's doing so we're kind of throwing",
    "start": "994380",
    "end": "1000920"
  },
  {
    "text": "money at the problem but very precisely like only when we need to",
    "start": "1000920",
    "end": "1007480"
  },
  {
    "text": "so we use Lambda to scale up compute in our database and we found that it's fast enough I mean our median start time is",
    "start": "1007759",
    "end": "1014899"
  },
  {
    "text": "like 50 milliseconds that's my cup doesn't get very far in in that amount of time it's okay we don't see much of a",
    "start": "1014899",
    "end": "1021620"
  },
  {
    "text": "difference between hot and cold startups more on that in a bit they tend to return within two and a",
    "start": "1021620",
    "end": "1027438"
  },
  {
    "text": "half seconds which is acceptable and they are you know three or four",
    "start": "1027439",
    "end": "1033199"
  },
  {
    "text": "times more expensive but we run them a hundred times less at least than we would an ec2 instance",
    "start": "1033199",
    "end": "1040160"
  },
  {
    "text": "for the same amount of compute so this works out and there are caveats to all of these",
    "start": "1040160",
    "end": "1047178"
  },
  {
    "text": "or at least caveats that we overcame so watch out we started doing this a",
    "start": "1047179",
    "end": "1054080"
  },
  {
    "text": "year ago um and a little over a year ago and uh",
    "start": "1054080",
    "end": "1060100"
  },
  {
    "text": "AWS was I mean this was kind of a new use case at the time for serverless",
    "start": "1060100",
    "end": "1065299"
  },
  {
    "text": "because they designed it for web apps they designed it as like a back end on demand",
    "start": "1065299",
    "end": "1071620"
  },
  {
    "text": "um so the scaling isn't exactly what we expected like that the scaling",
    "start": "1071660",
    "end": "1078200"
  },
  {
    "text": "for Lambda is it'll go up to what is called the burst limit which in in U.S",
    "start": "1078200",
    "end": "1083419"
  },
  {
    "text": "east one is 500 in US West to I think",
    "start": "1083419",
    "end": "1089720"
  },
  {
    "text": "it's 3 000 so it varies by region uh but that burst limit is like 500 lambdas and",
    "start": "1089720",
    "end": "1095179"
  },
  {
    "text": "then they stop scaling and there's then it was just like oh oh but if you have continuous load then",
    "start": "1095179",
    "end": "1101480"
  },
  {
    "text": "over the next minute they will scale up I think it might be linearly I've drawn",
    "start": "1101480",
    "end": "1106640"
  },
  {
    "text": "it as steps to the concurrency limit which is like a thousand",
    "start": "1106640",
    "end": "1112100"
  },
  {
    "text": "um and the rest of them will get a 429 response which is throttled free try",
    "start": "1112100",
    "end": "1117260"
  },
  {
    "text": "so uh so so we hit this and uh spending a",
    "start": "1117260",
    "end": "1123200"
  },
  {
    "text": "minute scaling up by 500 more lambdas is not helpful because our usage pattern",
    "start": "1123200",
    "end": "1129020"
  },
  {
    "text": "looks like this we don't have a minute of sustained load that doesn't help us at all so we really",
    "start": "1129020",
    "end": "1134840"
  },
  {
    "text": "needed our burst Limit raised and so we talked to AWS and they raised our burst Limit",
    "start": "1134840",
    "end": "1141500"
  },
  {
    "text": "um you can you can talk to your rep and you can get your first limit raised into the tens of thousands now that helps or",
    "start": "1141500",
    "end": "1148700"
  },
  {
    "text": "at least your concurrency limit both really um the trick is to to not",
    "start": "1148700",
    "end": "1155240"
  },
  {
    "text": "um not surprise your cloud provider so uh we were able to measure",
    "start": "1155240",
    "end": "1161539"
  },
  {
    "text": "uh how many lambdas we needed to run at a given time or are running out in fact we added this concurrency operator",
    "start": "1161539",
    "end": "1168860"
  },
  {
    "text": "um to count how many of a thing at once uh just for this purpose",
    "start": "1168860",
    "end": "1174440"
  },
  {
    "text": "and now that's available to everyone so right start up",
    "start": "1174440",
    "end": "1180559"
  },
  {
    "text": "we need this to be fast people talk about cold starts warm starts is that a problem for us it hasn't been I mean",
    "start": "1180559",
    "end": "1187580"
  },
  {
    "text": "there's when you spin up or when you invoke a Lambda function AWS may or may not have",
    "start": "1187580",
    "end": "1194900"
  },
  {
    "text": "some already ready of these processes already started up in ready and if not",
    "start": "1194900",
    "end": "1200600"
  },
  {
    "text": "it'll start up a new one and then invoke it and then that one will hang out a",
    "start": "1200600",
    "end": "1205820"
  },
  {
    "text": "little while waiting to see if it gets some more invocations and you only get charged for while it's",
    "start": "1205820",
    "end": "1211220"
  },
  {
    "text": "running the code um yeah so you can see the difference",
    "start": "1211220",
    "end": "1216799"
  },
  {
    "text": "between these in fact uh this is fun this is fun we can make a trace and we",
    "start": "1216799",
    "end": "1221840"
  },
  {
    "text": "do uh we make a trace not only of our invocations but of that wider Lambda",
    "start": "1221840",
    "end": "1227240"
  },
  {
    "text": "process because we emit a span when it wakes up and we admit a span all right before uh",
    "start": "1227240",
    "end": "1233720"
  },
  {
    "text": "the function goes to sleep and so we can see run sleep run sleep run sleep you",
    "start": "1233720",
    "end": "1239120"
  },
  {
    "text": "can actually follow what's going on in that process even though during those sleeps it is not actively doing anything",
    "start": "1239120",
    "end": "1246380"
  },
  {
    "text": "I I think that's fun but generally our startup within yeah 50",
    "start": "1246380",
    "end": "1251900"
  },
  {
    "text": "milliseconds like you saw this isn't go so that helps oh look here it goes here's the here's the the Lambda",
    "start": "1251900",
    "end": "1259220"
  },
  {
    "text": "function process you can see that this one hung out for a while and we can count the number currently",
    "start": "1259220",
    "end": "1265820"
  },
  {
    "text": "running and we can use concurrency to count the number currently sleeping and you can see that those are wider that's",
    "start": "1265820",
    "end": "1271880"
  },
  {
    "text": "just kind of neat what matters is that when we invoke them",
    "start": "1271880",
    "end": "1278720"
  },
  {
    "text": "they start up quickly they do their processing um and they return within two and a half",
    "start": "1278720",
    "end": "1285440"
  },
  {
    "text": "seconds most of the time ninety percent of the time but definitely not 100 you can see uh",
    "start": "1285440",
    "end": "1293000"
  },
  {
    "text": "the 30 000 millisecond to the 32nd um line in the middle of this graph",
    "start": "1293000",
    "end": "1298760"
  },
  {
    "text": "there's kind of a cluster that's S3 timeout so Lambda may be right next door",
    "start": "1298760",
    "end": "1304100"
  },
  {
    "text": "to S3 but S3 does not always answer its knock uh and the I mean the trick to this is",
    "start": "1304100",
    "end": "1310460"
  },
  {
    "text": "just don't wait that long start up another one with the same parameters and",
    "start": "1310460",
    "end": "1315679"
  },
  {
    "text": "I hope you get a little luckier on the timing this time and S3 does respond",
    "start": "1315679",
    "end": "1320960"
  },
  {
    "text": "watch out because the default uh timeout in the Lambda SDK is like 30 seconds or",
    "start": "1320960",
    "end": "1328760"
  },
  {
    "text": "longer it's way too long you do not want to use the default timeout make sure you give up uh before the data becomes",
    "start": "1328760",
    "end": "1336500"
  },
  {
    "text": "irrelevant okay we did also find a peculiar restriction that like the functions",
    "start": "1336500",
    "end": "1342740"
  },
  {
    "text": "can't return more than like six megabytes of data so okay put the return value in S3 and",
    "start": "1342740",
    "end": "1349280"
  },
  {
    "text": "send respond with a link okay um it's just Amazon has the limit for",
    "start": "1349280",
    "end": "1354860"
  },
  {
    "text": "everything that's healthy they have boundaries they will surprise you you will find",
    "start": "1354860",
    "end": "1361039"
  },
  {
    "text": "them also when we try to send the function's data we would like to send them a binary",
    "start": "1361039",
    "end": "1369559"
  },
  {
    "text": "data but they they only want Json and there's weird stuff Json is not that",
    "start": "1369559",
    "end": "1374900"
  },
  {
    "text": "efficient and it's not exactly Json it's whatever AWS is Lambda Json cop has",
    "start": "1374900",
    "end": "1381740"
  },
  {
    "text": "decided is Json don't deal with it put the input in S3 and send a link",
    "start": "1381740",
    "end": "1388580"
  },
  {
    "text": "this is fine finally everyone knows that serverless",
    "start": "1388580",
    "end": "1394760"
  },
  {
    "text": "is expensive per CPU second it costs like three to four times what an ec2",
    "start": "1394760",
    "end": "1401480"
  },
  {
    "text": "instance would cost I mean given",
    "start": "1401480",
    "end": "1406940"
  },
  {
    "text": "that it we're running it less than a hundredth of the time as much that seems like a win but what can we do to keep",
    "start": "1406940",
    "end": "1414200"
  },
  {
    "text": "that down well first of all what really worries me about Lambda cost",
    "start": "1414200",
    "end": "1419720"
  },
  {
    "text": "is that you don't know what they're going to be because how many of these are you going is your software going to invoke and",
    "start": "1419720",
    "end": "1425840"
  },
  {
    "text": "suddenly spin up and what are the costs associated with that and are you going to get surprised by a bill that's like a",
    "start": "1425840",
    "end": "1432260"
  },
  {
    "text": "quarter if you're AWS Bill sometimes this is where observability is also",
    "start": "1432260",
    "end": "1438860"
  },
  {
    "text": "really important so because uh we have spans that measure",
    "start": "1438860",
    "end": "1444620"
  },
  {
    "text": "that implication time we can multiply that duration by how much we pay per second of Lambda invocation and",
    "start": "1444620",
    "end": "1453140"
  },
  {
    "text": "um we can we can count that up by customer",
    "start": "1453140",
    "end": "1458179"
  },
  {
    "text": "because all of our spans include customer ID as a dimension and then we",
    "start": "1458179",
    "end": "1463880"
  },
  {
    "text": "can get notified and we do whenever a particular customer uses more than like",
    "start": "1463880",
    "end": "1469880"
  },
  {
    "text": "a thousand dollars of Lambda in a day or an hour I forget which one it is",
    "start": "1469880",
    "end": "1475520"
  },
  {
    "text": "and then sometimes we get the account reps to reach out and talk to that customer and be like what are you doing",
    "start": "1475520",
    "end": "1483620"
  },
  {
    "text": "here's a more effective way to accomplish what you're looking for",
    "start": "1483620",
    "end": "1489260"
  },
  {
    "text": "um and we as we throttle our API and stuff like that but really the best you can do is find",
    "start": "1489260",
    "end": "1496340"
  },
  {
    "text": "out quickly if you're going to get a big Bill also we do a ton of optimization we do",
    "start": "1496340",
    "end": "1504500"
  },
  {
    "text": "so much optimization of our Lambda execution really all of our our major",
    "start": "1504500",
    "end": "1509600"
  },
  {
    "text": "database processes um to get that speed um one way that we optimize is that",
    "start": "1509600",
    "end": "1515720"
  },
  {
    "text": "we've moved from x86 to arm processors to the graviton 2 processors uh both",
    "start": "1515720",
    "end": "1521360"
  },
  {
    "text": "both for our retrievers and our ingest and most of our other",
    "start": "1521360",
    "end": "1526760"
  },
  {
    "text": "um servers but also for our lambdas so Liz",
    "start": "1526760",
    "end": "1533000"
  },
  {
    "text": "Fong Jones who's our field CTO now has written several articles about",
    "start": "1533000",
    "end": "1539620"
  },
  {
    "text": "the arm processors are both faster in the sense that it's going",
    "start": "1539620",
    "end": "1546320"
  },
  {
    "text": "to take less CPU to run them and those CPU seconds are cheaper",
    "start": "1546320",
    "end": "1552260"
  },
  {
    "text": "so we get lower costs in two different ways and we can measure that",
    "start": "1552260",
    "end": "1557960"
  },
  {
    "text": "so we we started building our Lambda functions there and go for both x86 and",
    "start": "1557960",
    "end": "1565159"
  },
  {
    "text": "arm and we the first time we tried a 50 50 split and we ran into some okay how is maybe",
    "start": "1565159",
    "end": "1573740"
  },
  {
    "text": "this maybe not uh the uh initially the arm 64 processors",
    "start": "1573740",
    "end": "1580700"
  },
  {
    "text": "um were up about the same average but a lot more varied in their performance",
    "start": "1580700",
    "end": "1586039"
  },
  {
    "text": "um and overall slower okay take it back they were not the same average they're",
    "start": "1586039",
    "end": "1592760"
  },
  {
    "text": "more varied in their performance and overall slower so we're like okay let's change that",
    "start": "1592760",
    "end": "1599659"
  },
  {
    "text": "feature flag and we'll roll this back so we're running one percent on arm processors and 99 on x86",
    "start": "1599659",
    "end": "1608620"
  },
  {
    "text": "and we did that and um yeah so now you can see our arm percentage you can barely see the orange line at the end",
    "start": "1608659",
    "end": "1615140"
  },
  {
    "text": "after the the feature flag was deployed and then we started investigating why",
    "start": "1615140",
    "end": "1620720"
  },
  {
    "text": "why was it so slow well one one was capacity uh even though we had our",
    "start": "1620720",
    "end": "1626059"
  },
  {
    "text": "Lambda executions limits raised there were only so many arm processors",
    "start": "1626059",
    "end": "1631580"
  },
  {
    "text": "available to run them the the total capacity in AWS for these is still lower than for x86 lambdas",
    "start": "1631580",
    "end": "1639799"
  },
  {
    "text": "as we had to work with AWS directly and created a capacity plan for when we",
    "start": "1639799",
    "end": "1647360"
  },
  {
    "text": "would be able to spin up more and more of them to arm more on that later",
    "start": "1647360",
    "end": "1653419"
  },
  {
    "text": "the next thing we noticed was that these were running slower because uh",
    "start": "1653419",
    "end": "1660440"
  },
  {
    "text": "okay so at the time the current going was 117 and 117 had a particular",
    "start": "1660440",
    "end": "1669100"
  },
  {
    "text": "optimization of um putting parameters in registers instead",
    "start": "1669100",
    "end": "1675080"
  },
  {
    "text": "of having to put them in memory for function calls that made calling functions faster",
    "start": "1675080",
    "end": "1681320"
  },
  {
    "text": "on x86 and because we're doing all these super complicated queries and which filter are we doing and which group buy",
    "start": "1681320",
    "end": "1687620"
  },
  {
    "text": "are we doing and there's a lot a lot of branching in what our aggregators are",
    "start": "1687620",
    "end": "1693140"
  },
  {
    "text": "doing there are a lot of function calls and so a little bit of overhead on a function call went a long way",
    "start": "1693140",
    "end": "1699919"
  },
  {
    "text": "now go 1.18 also has this optimization on arm so we",
    "start": "1699919",
    "end": "1706279"
  },
  {
    "text": "started using 118 a little bit early just for our lambdas and that made a difference now goes 119 it's fine but at",
    "start": "1706279",
    "end": "1714380"
  },
  {
    "text": "the time that was a significant discovery so we figured that out with profiling",
    "start": "1714380",
    "end": "1720279"
  },
  {
    "text": "and also through profiling we noticed that the compression was taking a lot",
    "start": "1720279",
    "end": "1726260"
  },
  {
    "text": "longer on uh arm than on x86 and it turned out that the lz4 compression",
    "start": "1726260",
    "end": "1733340"
  },
  {
    "text": "Library had a native implementation on x86 but had not been released yet",
    "start": "1733340",
    "end": "1741260"
  },
  {
    "text": "natively in assembly for arm 64. it's a Liz spent a couple afternoons porting",
    "start": "1741260",
    "end": "1747620"
  },
  {
    "text": "the arm32 assembly version of the lz4 compression",
    "start": "1747620",
    "end": "1753080"
  },
  {
    "text": "library to arm 64. got that out and brought the performance more in line",
    "start": "1753080",
    "end": "1760580"
  },
  {
    "text": "so so these three considerations fixed the performance problems that we",
    "start": "1760580",
    "end": "1766279"
  },
  {
    "text": "saw at the time although the capacity ones that's a that's a gradual fix over time",
    "start": "1766279",
    "end": "1771679"
  },
  {
    "text": "so since then since a year ago we've been able to bump it up to 30",
    "start": "1771679",
    "end": "1776899"
  },
  {
    "text": "percent arm and then AWS called and said hey uh",
    "start": "1776899",
    "end": "1782720"
  },
  {
    "text": "try go for it and we bumped it up to like 99 but then there were some regressions and so we dropped it down to",
    "start": "1782720",
    "end": "1789380"
  },
  {
    "text": "50 and that was okay and then we got those fixed and then uh bumped it up to",
    "start": "1789380",
    "end": "1794600"
  },
  {
    "text": "90 or gradually worked it up to 99 and now we're there",
    "start": "1794600",
    "end": "1799640"
  },
  {
    "text": "uh we keep one percent on x86 just so we don't break it without noticing",
    "start": "1799640",
    "end": "1806860"
  },
  {
    "text": "and the performance is good um there's a little more variation in the purple x86 lines here than in but",
    "start": "1807620",
    "end": "1815480"
  },
  {
    "text": "that's just because they're one percent and the orange lines are arm and yeah the performance is the same oh and we",
    "start": "1815480",
    "end": "1822500"
  },
  {
    "text": "figured out um also through profiling and observability uh that on arm we with the",
    "start": "1822500",
    "end": "1830779"
  },
  {
    "text": "same CPU size is x86 it was fat sufficiently fast enough that",
    "start": "1830779",
    "end": "1836419"
  },
  {
    "text": "we'd actually hit Network limitations um so we we scaled back the CPU by 20",
    "start": "1836419",
    "end": "1842960"
  },
  {
    "text": "percent um so on fewer CPUs we're getting the same performance and also those CPUs are",
    "start": "1842960",
    "end": "1849500"
  },
  {
    "text": "20 cheaper yay this kind of continued optimization is",
    "start": "1849500",
    "end": "1856220"
  },
  {
    "text": "how we manage to spend money very strategically on our database CPU",
    "start": "1856220",
    "end": "1862760"
  },
  {
    "text": "so that people can get that interactive query timing even over 60 days",
    "start": "1862760",
    "end": "1870519"
  },
  {
    "text": "all right so we scaled up our compute with Lambda should you",
    "start": "1870559",
    "end": "1875679"
  },
  {
    "text": "I mean think about it think about it if you do be sure to study your limits",
    "start": "1875679",
    "end": "1881720"
  },
  {
    "text": "be sure to change the SDK retry parameters don't wait 30 seconds for it to come back",
    "start": "1881720",
    "end": "1887299"
  },
  {
    "text": "deployment is its own thing I haven't talked about that and testing it is uh",
    "start": "1887299",
    "end": "1893779"
  },
  {
    "text": "yeah we stepped that out for automated tests and hey the only real test is production",
    "start": "1893779",
    "end": "1899480"
  },
  {
    "text": "so also test in production with you with good observability",
    "start": "1899480",
    "end": "1904659"
  },
  {
    "text": "observability is also really important for knowing how much you're spending because you can really only find that",
    "start": "1904659",
    "end": "1910279"
  },
  {
    "text": "out again in production from minute to minute and always always talk to your cloud",
    "start": "1910279",
    "end": "1916940"
  },
  {
    "text": "provider don't surprise them work this out with them talk about your capacity limits a lot of them are adjustable but",
    "start": "1916940",
    "end": "1923899"
  },
  {
    "text": "not without warning but the question is what should you do",
    "start": "1923899",
    "end": "1929960"
  },
  {
    "text": "um on serverless and what should you not so uh real-time bulk workloads that's",
    "start": "1929960",
    "end": "1937220"
  },
  {
    "text": "what we're doing we're doing a lot of work while someone is waiting in our database",
    "start": "1937220",
    "end": "1942559"
  },
  {
    "text": "so um it needs to be a lot of work or don't",
    "start": "1942559",
    "end": "1948140"
  },
  {
    "text": "bother just run it on whatever computer you're already on and it needs to be urgent like a human is waiting for it or",
    "start": "1948140",
    "end": "1955460"
  },
  {
    "text": "else there's no point spending the two to four times extra on serverless",
    "start": "1955460",
    "end": "1960919"
  },
  {
    "text": "I mean unless you just really want to look cool or something no Apprentice is a kubernetes job run it on",
    "start": "1960919",
    "end": "1967220"
  },
  {
    "text": "ec2 something like that if it's not urgent so once you've got someone waiting on a whole lot of work",
    "start": "1967220",
    "end": "1973640"
  },
  {
    "text": "then what you're going to need to do is move the input to object storage you've got",
    "start": "1973640",
    "end": "1979580"
  },
  {
    "text": "to get all of the input that these functions need off of local disk and somewhere in the cloud where they can",
    "start": "1979580",
    "end": "1985340"
  },
  {
    "text": "access it if they have to call back to retriever to get the data that wouldn't help",
    "start": "1985340",
    "end": "1991580"
  },
  {
    "text": "and then you've got to Shard it you've got to divide that up into work that can be done in parallel so it takes a lot of",
    "start": "1991580",
    "end": "1998840"
  },
  {
    "text": "parallelism the mapreduce algorithms that are our lambdas are using have this",
    "start": "1998840",
    "end": "2004899"
  },
  {
    "text": "and then you'll want to bring that data together you could do this in Lambda",
    "start": "2004899",
    "end": "2010360"
  },
  {
    "text": "but but this also can be a bottleneck and we we choose to do that outside of Lambda",
    "start": "2010360",
    "end": "2016480"
  },
  {
    "text": "on our persistent retriever instances which are also running on arm",
    "start": "2016480",
    "end": "2023260"
  },
  {
    "text": "for added savings and then you're gonna have to do a lot of work",
    "start": "2023260",
    "end": "2028960"
  },
  {
    "text": "I mean t you're spending money on the serverless compute use it carefully",
    "start": "2028960",
    "end": "2034659"
  },
  {
    "text": "you're going to need to tune uh the parameters like how many segments per",
    "start": "2034659",
    "end": "2040840"
  },
  {
    "text": "invocation what's the right amount of work for the right Lambda execution how many CPUs do you need on Lambda at a",
    "start": "2040840",
    "end": "2047919"
  },
  {
    "text": "time and I think memory is connected to that but watch out for things like when you're blocked on network nothing no",
    "start": "2047919",
    "end": "2054398"
  },
  {
    "text": "more CPU is going to help you um you'll need to optimize properly and that means I mean performance optimizing",
    "start": "2054399",
    "end": "2061720"
  },
  {
    "text": "your code where it's needed you'll need profiling",
    "start": "2061720",
    "end": "2067060"
  },
  {
    "text": "um you definitely need observability and there's an open Telemetry layer and it",
    "start": "2067060",
    "end": "2073060"
  },
  {
    "text": "will wrap around your function and and create the spans at the start and end",
    "start": "2073060",
    "end": "2078878"
  },
  {
    "text": "um and it's important to use a layer for this your function can't send anything after it returns nothing as soon as it",
    "start": "2078879",
    "end": "2086260"
  },
  {
    "text": "returns it's in sleep mode until it starts up again so you need",
    "start": "2086260",
    "end": "2092138"
  },
  {
    "text": "um the Lambda layer allows something to happen to report on the return of your",
    "start": "2092139",
    "end": "2097839"
  },
  {
    "text": "function and be sure to measure it really carefully",
    "start": "2097839",
    "end": "2102880"
  },
  {
    "text": "because that's how you're going to find out how much you're spending",
    "start": "2102880",
    "end": "2107460"
  },
  {
    "text": "in the end technology doesn't matter it's not about using the latest hotness",
    "start": "2108040",
    "end": "2116220"
  },
  {
    "text": "and the architecture doesn't matter it's not about how cool a distributed column store is",
    "start": "2116560",
    "end": "2122619"
  },
  {
    "text": "what matters is that this gives something valuable to the people who use",
    "start": "2122619",
    "end": "2127960"
  },
  {
    "text": "honeycomb so we spend a ton of thought",
    "start": "2127960",
    "end": "2133560"
  },
  {
    "text": "a ton of development effort a ton of optimization a ton of observability we",
    "start": "2133560",
    "end": "2141520"
  },
  {
    "text": "put all of our brain power and a lot of money into our our serverless functions",
    "start": "2141520",
    "end": "2149380"
  },
  {
    "text": "all to preserve that one most precious resource developer attention",
    "start": "2149380",
    "end": "2156599"
  },
  {
    "text": "thank you for listening I look forward to taking your questions and if you want to learn more",
    "start": "2159339",
    "end": "2166599"
  },
  {
    "text": "you can find me at honeycomb.io office Dash hours or on Twitter is justatron or",
    "start": "2166599",
    "end": "2173920"
  },
  {
    "text": "you can like read our book so Liz and George and charity all from honeycomb have written about uh how we do this",
    "start": "2173920",
    "end": "2182560"
  },
  {
    "text": "how we do observability and how we make it fast in the observability engineering book so you can learn a lot more about",
    "start": "2182560",
    "end": "2188079"
  },
  {
    "text": "retriever in there the end",
    "start": "2188079",
    "end": "2193740"
  },
  {
    "text": "thank you for a wonderful talk I I love watching it um is excellent super in-depth that I",
    "start": "2196540",
    "end": "2202780"
  },
  {
    "text": "think you already have quite a few questions um one one person asked great talk Jessica",
    "start": "2202780",
    "end": "2209079"
  },
  {
    "text": "I was wondering how much data we're talking about let me say 60 days for large clients",
    "start": "2209079",
    "end": "2216480"
  },
  {
    "text": "I mean I don't know I think it's in terabytes but like tens of terabytes",
    "start": "2217000",
    "end": "2223359"
  },
  {
    "text": "not Pi terabytes pretty awesome okay um I actually sort of had a",
    "start": "2223359",
    "end": "2229240"
  },
  {
    "text": "question just like a very basic question like what's the normal workflow for your customer using the retriever function",
    "start": "2229240",
    "end": "2234579"
  },
  {
    "text": "like what's their normal method like let's say you have a customer they build a dashboard with charts do they",
    "start": "2234579",
    "end": "2240339"
  },
  {
    "text": "basically say okay this chart I want to be faster or more real time like what's the how do they move no no uh we just",
    "start": "2240339",
    "end": "2248380"
  },
  {
    "text": "work to make everything fast there's okay you don't pick custom indexes",
    "start": "2248380",
    "end": "2255280"
  },
  {
    "text": "um and you don't like pick which graphs to make fast we aim to make all of them fast",
    "start": "2255280",
    "end": "2260859"
  },
  {
    "text": "because we don't want you to be stuck with your dashboards I mean yeah you can build a dashboard that is a",
    "start": "2260859",
    "end": "2266260"
  },
  {
    "text": "functionality that honeycomb has um but it's not what we're optimizing for we're really optimizing for the",
    "start": "2266260",
    "end": "2272440"
  },
  {
    "text": "interactive experience you might start at a dashboard but then we expect you to click on the graph maybe change the time",
    "start": "2272440",
    "end": "2279280"
  },
  {
    "text": "range maybe compared to last week more likely Group by a field or several fields",
    "start": "2279280",
    "end": "2286960"
  },
  {
    "text": "um and get little tables of the results as well as the um as well as many lines on the graph",
    "start": "2286960",
    "end": "2293220"
  },
  {
    "text": "and then maybe click on make a heat map or click on it and say",
    "start": "2293220",
    "end": "2298780"
  },
  {
    "text": "what's different about these and we're gonna go run a series of queries to tell you that",
    "start": "2298780",
    "end": "2304420"
  },
  {
    "text": "also it's completely done on demand in like real time as the user is doing his",
    "start": "2304420",
    "end": "2310359"
  },
  {
    "text": "or her analysis it's not about optimizing the speed of a chart in a dashboard it's all about the interactive",
    "start": "2310359",
    "end": "2316420"
  },
  {
    "text": "part oh that's very interesting okay yeah yeah we don't know what I mean could go look in the database what you",
    "start": "2316420",
    "end": "2322300"
  },
  {
    "text": "have in your dashboards but your dashboard queries are not any different from a live query",
    "start": "2322300",
    "end": "2327880"
  },
  {
    "text": "and do you also speed those up with receiver the the sort of the can set of",
    "start": "2327880",
    "end": "2333520"
  },
  {
    "text": "charts that people have um yes okay like if you make a dashboard",
    "start": "2333520",
    "end": "2338920"
  },
  {
    "text": "for a long period period um and access it a lot we're probably going",
    "start": "2338920",
    "end": "2344500"
  },
  {
    "text": "to notice and maybe talk to you uh because we don't want if you like updating that every 30 seconds",
    "start": "2344500",
    "end": "2352000"
  },
  {
    "text": "we're gonna cash it for you because those are expensive queries oh but I think Tristan asked about when",
    "start": "2352000",
    "end": "2358599"
  },
  {
    "text": "to use Lambda functions and when not to uh is whether the data is in S3",
    "start": "2358599",
    "end": "2363820"
  },
  {
    "text": "if it's an S3 it's we're going to use a Lambda if it's on local disk then we're not and that's entirely determined by a",
    "start": "2363820",
    "end": "2372220"
  },
  {
    "text": "Time the time isn't the same for every data set though if you have a smaller data",
    "start": "2372220",
    "end": "2378579"
  },
  {
    "text": "set maybe all of the data is on local disk and then as it gets bigger more a larger",
    "start": "2378579",
    "end": "2384160"
  },
  {
    "text": "percentage of that data is in S3 okay uh is it circuit yeah and",
    "start": "2384160",
    "end": "2392619"
  },
  {
    "text": "oh I see so it's it's based on the data set size and and then do you move the data to S3",
    "start": "2392619",
    "end": "2398320"
  },
  {
    "text": "like behind the scenes retriever does retriever okay yeah oh so like retriever uh depending on how",
    "start": "2398320",
    "end": "2405820"
  },
  {
    "text": "so is it a you get to decide how much data you hold like if I want do I get to decide if I want six months of data",
    "start": "2405820",
    "end": "2412720"
  },
  {
    "text": "um you can negotiate that a little bit with your contract like okay I think we have",
    "start": "2412720",
    "end": "2418599"
  },
  {
    "text": "a few exceptions where customers keep more than 60 days of data in particular data sets",
    "start": "2418599",
    "end": "2425619"
  },
  {
    "text": "um but honeycomb I mean wait we kind of it's pretty simple pretty much everybody had 60 days of",
    "start": "2425619",
    "end": "2432460"
  },
  {
    "text": "data and how much of that is in local disk is like a fixed amount per data set",
    "start": "2432460",
    "end": "2438460"
  },
  {
    "text": "roughly um some data sets have more partitions than others and so they'd have",
    "start": "2438460",
    "end": "2446380"
  },
  {
    "text": "um correspondingly more data on local disk but it's all invisible to the customer you don't know when",
    "start": "2446380",
    "end": "2452320"
  },
  {
    "text": "we're using Lambda okay and then someone asked Jacob asked can you elaborate on what makes lambdas",
    "start": "2452320",
    "end": "2457660"
  },
  {
    "text": "hard to test oh um so you can test",
    "start": "2457660",
    "end": "2463240"
  },
  {
    "text": "inside the Lambda you can you can use that as just fine but actually testing whether it works",
    "start": "2463240",
    "end": "2470500"
  },
  {
    "text": "um once it's uploaded to AWS like integration integration testing lambdas",
    "start": "2470500",
    "end": "2476740"
  },
  {
    "text": "is really hard you can't do that locally you can't do that in a test environment I mean you can do that in a test version",
    "start": "2476740",
    "end": "2482800"
  },
  {
    "text": "that you uploaded to AWS uh but that's slow it's really slow",
    "start": "2482800",
    "end": "2489579"
  },
  {
    "text": "um so yeah I mean honeycomb is all about test and",
    "start": "2489579",
    "end": "2495099"
  },
  {
    "text": "production not that we only test in production but that we also test in production and we",
    "start": "2495099",
    "end": "2501220"
  },
  {
    "text": "notice when things break um and then we roll back quickly the other thing we do is we upload or we",
    "start": "2501220",
    "end": "2509680"
  },
  {
    "text": "don't we deploy to our internal environment first our internal environment is not a it's not test it's",
    "start": "2509680",
    "end": "2516460"
  },
  {
    "text": "not staging it's a completely separate environment of honeycomb",
    "start": "2516460",
    "end": "2521920"
  },
  {
    "text": "that we're the only customer of so there's there's production honeycomb that monitors everybody else's stuff",
    "start": "2521920",
    "end": "2528160"
  },
  {
    "text": "that all of our customers observability data and then there's our version of",
    "start": "2528160",
    "end": "2533920"
  },
  {
    "text": "honeycomb that just receives data from production honeycomb we call it dog food",
    "start": "2533920",
    "end": "2539140"
  },
  {
    "text": "because we use it to eat our own dog food um so the dog food honeycomb we deploy",
    "start": "2539140",
    "end": "2544540"
  },
  {
    "text": "to that first technically there's another one that monitors dog food but close enough",
    "start": "2544540",
    "end": "2550660"
  },
  {
    "text": "um and so if we broke the interface uh",
    "start": "2550660",
    "end": "2555940"
  },
  {
    "text": "between retriever in ec2 actually I think we just moved to kubernetes but still",
    "start": "2555940",
    "end": "2562180"
  },
  {
    "text": "that's under that's on ec2 eventually uh between retriever on ec2 and then the",
    "start": "2562180",
    "end": "2567400"
  },
  {
    "text": "lambdas um or anything else about the lambdas that we couldn't unit test if we broke",
    "start": "2567400",
    "end": "2573400"
  },
  {
    "text": "that we'll notice it very quickly we even have like",
    "start": "2573400",
    "end": "2578619"
  },
  {
    "text": "a deployment Gates that normally uh the deployment to production would just happen 20 minutes later",
    "start": "2578619",
    "end": "2584680"
  },
  {
    "text": "but if um if ours if our slos don't match if we get too many errors in",
    "start": "2584680",
    "end": "2591700"
  },
  {
    "text": "dog food we'll automatically stop the deploy to production uh so we test in prod where it's a",
    "start": "2591700",
    "end": "2599440"
  },
  {
    "text": "smaller version of prod right it's not um all of prod it's a limited rollout I guess got it",
    "start": "2599440",
    "end": "2607839"
  },
  {
    "text": "um great um someone asked uh there are a few questions here one is how do you compare lambdas to K native have you",
    "start": "2607839",
    "end": "2613839"
  },
  {
    "text": "well personally I don't I've never buy we do use kubernetes in any column",
    "start": "2613839",
    "end": "2621900"
  },
  {
    "text": "I don't think they're using EPS kubernetes over ecans",
    "start": "2621900",
    "end": "2628319"
  },
  {
    "text": "got it for the control plane um someone asked uh this other question which is does it sometimes make sense to",
    "start": "2628319",
    "end": "2634599"
  },
  {
    "text": "use a platform agnostic language like Java that may help avoid issues with sub-optimal libraries that are not yet",
    "start": "2634599",
    "end": "2640480"
  },
  {
    "text": "ported to Native CPU architecture sometimes absolutely it depends on your business case",
    "start": "2640480",
    "end": "2646000"
  },
  {
    "text": "uh I mean we're doing something really specialized in this custom database I mean in general don't write your own",
    "start": "2646000",
    "end": "2651400"
  },
  {
    "text": "database and in general don't optimize your code this much or like business software",
    "start": "2651400",
    "end": "2659020"
  },
  {
    "text": "but this is like the secret sauce that makes honeycomb special this is what makes it possible for you to not have to",
    "start": "2659020",
    "end": "2664720"
  },
  {
    "text": "decide which queries you want fast they're just all fast and we don't even this is dynamically generated schema we",
    "start": "2664720",
    "end": "2670660"
  },
  {
    "text": "don't even know what Fields you're going to send us just that it's going to be fast um",
    "start": "2670660",
    "end": "2676359"
  },
  {
    "text": "so it's super specialized and at the scale that we do these particular",
    "start": "2676359",
    "end": "2682000"
  },
  {
    "text": "operations that it's expensive um and that's where a significant portion of our costs are in AWS in a",
    "start": "2682000",
    "end": "2690880"
  },
  {
    "text": "significant chunk of that is Lambda so we're constantly optimizing to run",
    "start": "2690880",
    "end": "2696160"
  },
  {
    "text": "really lean in AWS and we watch that closely Liz Fong Jones is um",
    "start": "2696160",
    "end": "2703839"
  },
  {
    "text": "is always noticing something that uh that could be faster and could save us",
    "start": "2703839",
    "end": "2709240"
  },
  {
    "text": "um thousands or tens of thousands of dollars a month which is significant in",
    "start": "2709240",
    "end": "2714579"
  },
  {
    "text": "our our size are you is your entire platform written in go",
    "start": "2714579",
    "end": "2719800"
  },
  {
    "text": "um pretty much I mean the front ends typescript okay that's really awesome uh great questions",
    "start": "2719800",
    "end": "2726220"
  },
  {
    "text": "from everyone um let's see let's see if there are any others",
    "start": "2726220",
    "end": "2732359"
  },
  {
    "text": "um this was a very detailed talk I I took",
    "start": "2734619",
    "end": "2740440"
  },
  {
    "text": "so many notes during this I actually we also and we do real-time streaming and",
    "start": "2740440",
    "end": "2748240"
  },
  {
    "text": "I mean I I'm going to go and check to see if we've seen we did a comparison with x86 before moving over to see if it",
    "start": "2748240",
    "end": "2755140"
  },
  {
    "text": "affected our latency oh I had a question so um is there ever a time do you see a",
    "start": "2755140",
    "end": "2761680"
  },
  {
    "text": "case where uh like what are your timers so user types in a query in you know in the in the UI uh how long will they wait",
    "start": "2761680",
    "end": "2770260"
  },
  {
    "text": "will they wait as long as it takes to get a result but you try to be as fast as possible I mean it'll time out after",
    "start": "2770260",
    "end": "2775839"
  },
  {
    "text": "five minutes okay uh but if if it takes that long there's a bug well more likely something",
    "start": "2775839",
    "end": "2782380"
  },
  {
    "text": "went down um uh yeah that they the user Waits until",
    "start": "2782380",
    "end": "2788140"
  },
  {
    "text": "there's a little spinny thing um and I think yeah and then the query",
    "start": "2788140",
    "end": "2793780"
  },
  {
    "text": "will populate all the queries will populate all at once when the when the results have",
    "start": "2793780",
    "end": "2799300"
  },
  {
    "text": "been aggregated and sent back and usually it's it's like five seconds on a long one",
    "start": "2799300",
    "end": "2806560"
  },
  {
    "text": "um and like two seconds on typical query",
    "start": "2806560",
    "end": "2813599"
  },
  {
    "text": "um I was also going to ask I mean this is the Holy Grail like call cancellation someone close to the window",
    "start": "2813640",
    "end": "2818980"
  },
  {
    "text": "you you have to schedule the workload I mean everyone wants to it never gets around",
    "start": "2818980",
    "end": "2824680"
  },
  {
    "text": "to it yeah I mean a little finish what it's doing there's no really stopping it because it's doing everything at once",
    "start": "2824680",
    "end": "2830260"
  },
  {
    "text": "already yeah um that now uh we will cache the results if somebody runs that exact query with",
    "start": "2830260",
    "end": "2837160"
  },
  {
    "text": "that exact time span again um those results are actually stored in S3 this works for this makes permalinks",
    "start": "2837160",
    "end": "2844359"
  },
  {
    "text": "work um so those results are actually stored forever so that your your queries that",
    "start": "2844359",
    "end": "2849880"
  },
  {
    "text": "you've already run that you've like put into your your incident review notes",
    "start": "2849880",
    "end": "2855819"
  },
  {
    "text": "um those will always work you just won't be able to drill further in once the data is timed out",
    "start": "2855819",
    "end": "2861040"
  },
  {
    "text": "what's the time granularity of your buckets is it like your titles you can",
    "start": "2861040",
    "end": "2867099"
  },
  {
    "text": "set that on the graph with within a range um so it'll usually start at a second",
    "start": "2867099",
    "end": "2872980"
  },
  {
    "text": "but you can make it 30 minutes you can make it uh five milliseconds depending on depending on your time",
    "start": "2872980",
    "end": "2879819"
  },
  {
    "text": "range you're not going to do five milliseconds for a 60-day query that no but appropriately but you could Group by",
    "start": "2879819",
    "end": "2886720"
  },
  {
    "text": "a second you support group by is where they have one second buckets oh uh that's that's just bucketing for like",
    "start": "2886720",
    "end": "2893079"
  },
  {
    "text": "the heat Maps yeah Group by is more like a SQL Group by where you can Group by account ID you could hurt by region you",
    "start": "2893079",
    "end": "2900640"
  },
  {
    "text": "can any of the attributes and they'll divide those out separately and show you a heat",
    "start": "2900640",
    "end": "2906400"
  },
  {
    "text": "map that you can like cover and I mean create a free honeycomb account and try it okay thank you wow definitely will",
    "start": "2906400",
    "end": "2913480"
  },
  {
    "text": "this is really awesome I think we're at a time um and I don't see any more questions",
    "start": "2913480",
    "end": "2918640"
  },
  {
    "text": "coming in but if anyone does have any questions how would they reach you uh jessitron on Twitter is easiest",
    "start": "2918640",
    "end": "2926560"
  },
  {
    "text": "um just trying to hackyderm dot io on Mastodon I agree I am in the slack but I don't",
    "start": "2926560",
    "end": "2932079"
  },
  {
    "text": "promise to check it again after like five minutes from now you're a busy person you're already at another you're at multiple conferences so uh yeah and",
    "start": "2932079",
    "end": "2940359"
  },
  {
    "text": "everyone wants to reach out to her justotron on Twitter thank you very much for your time",
    "start": "2940359",
    "end": "2945579"
  },
  {
    "text": "thank you foreign [Music]",
    "start": "2945579",
    "end": "2955290"
  }
]
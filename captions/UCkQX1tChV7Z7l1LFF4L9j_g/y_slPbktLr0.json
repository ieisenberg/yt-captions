[
  {
    "start": "0",
    "end": "100000"
  },
  {
    "text": "well thank you Seth I'm I'm going to try without the mic probably going to be a",
    "start": "3080",
    "end": "10559"
  },
  {
    "text": "bit easier for me it's it's great to be here and I'm really glad to be here",
    "start": "10559",
    "end": "16619"
  },
  {
    "text": "and of course I'm particularly honored to be opening up this great event for you guys with this talk on akka HTTP",
    "start": "16619",
    "end": "24080"
  },
  {
    "text": "it's always nice for me to come back to Boston first because I've studied in",
    "start": "24080",
    "end": "29099"
  },
  {
    "text": "Massachusetts a long time ago and second because it was actually in Boston at any Scala 2012 that I did the very first",
    "start": "29099",
    "end": "37079"
  },
  {
    "text": "public talk on spray a lot of stuff has",
    "start": "37079",
    "end": "42090"
  },
  {
    "text": "happened since then of course we've moved a lot longer a lot forward and it",
    "start": "42090",
    "end": "47280"
  },
  {
    "text": "was quite a ride actually but this talk is is still on YouTube and you can also",
    "start": "47280",
    "end": "53550"
  },
  {
    "text": "find it find the link from on the sprite web site and even if you haven't seen it yet",
    "start": "53550",
    "end": "59039"
  },
  {
    "text": "if you haven't seen it yet then I would totally recommend you keep it that way because the talk isn't very good so we",
    "start": "59039",
    "end": "69960"
  },
  {
    "text": "were actually quite surprised about the amount of uptake and and an interest in",
    "start": "69960",
    "end": "76590"
  },
  {
    "text": "this HTTP library that we've developed and we weren't really quite ruined initially where all this is coming from",
    "start": "76590",
    "end": "83790"
  },
  {
    "text": "like where does all the interest come from why does everyone really always ask us about you know presenting and and you",
    "start": "83790",
    "end": "90420"
  },
  {
    "text": "know talking to conferences and so on and but when you think about it you realize well there's a good reason why we all need a proper HTTP stack and the",
    "start": "90420",
    "end": "99150"
  },
  {
    "text": "the reason the ultimate driver for that is is the same as it's probably for a",
    "start": "99150",
    "end": "105030"
  },
  {
    "start": "100000",
    "end": "170000"
  },
  {
    "text": "lot of the talks that we're going to see in the next two days the world has changed significantly as you all know we",
    "start": "105030",
    "end": "111240"
  },
  {
    "text": "now live in a multi everything world multi threaded multi cord multi machined",
    "start": "111240",
    "end": "116610"
  },
  {
    "text": "multi data center which has the effect that all our applications are now",
    "start": "116610",
    "end": "122520"
  },
  {
    "text": "distributed they are and that this is the core driver for a lot of the developments also in the scholar world",
    "start": "122520",
    "end": "129890"
  },
  {
    "text": "there are they really are distributed even if they are just distributed across",
    "start": "129890",
    "end": "135390"
  },
  {
    "text": "threads and cores and and it makes sense sometimes to even at that level think about your application as being a",
    "start": "135390",
    "end": "141270"
  },
  {
    "text": "distributed application but it's not just across threads on cores it's across machines and data centers across",
    "start": "141270",
    "end": "147030"
  },
  {
    "text": "organizations and essentially across the world right if we build an application today we certainly don't live on an",
    "start": "147030",
    "end": "153180"
  },
  {
    "text": "island anymore we are going to talk to the world in one shape or form and that",
    "start": "153180",
    "end": "158510"
  },
  {
    "text": "distribution is the core and since it's a naka talk let's look at what the akka",
    "start": "158510",
    "end": "163680"
  },
  {
    "text": "toolkit promises when you go to a kayo you'll see the promise that akka put up",
    "start": "163680",
    "end": "169110"
  },
  {
    "text": "and let's to make easier to build concurrent powerful concurrent and distributed applications that's what",
    "start": "169110",
    "end": "175290"
  },
  {
    "start": "170000",
    "end": "277000"
  },
  {
    "text": "akka wants to do right and because distribution is the core of everything we do now it's important there are two",
    "start": "175290",
    "end": "183750"
  },
  {
    "text": "two big things concurrency and distribution and when you think about distribution then this always implies",
    "start": "183750",
    "end": "190170"
  },
  {
    "text": "integration right if I distribute stuff I need to integrate the stuff that I've just distributed and since akka is the",
    "start": "190170",
    "end": "197910"
  },
  {
    "text": "toolkit there is distribution for example within one machine just across threads and course and akka gives you a",
    "start": "197910",
    "end": "204690"
  },
  {
    "text": "tool to work with that it's not the only one you cannot you know actors akka",
    "start": "204690",
    "end": "209910"
  },
  {
    "text": "actors are one possible way to deal with the challenges of programming concurrently there are many other tools",
    "start": "209910",
    "end": "216090"
  },
  {
    "text": "but akka gives you one if you are outside of one machine between your own subsystems that you controlled and akka",
    "start": "216090",
    "end": "222930"
  },
  {
    "text": "gives you things like akka remoting an aqua cluster to integrate the different parts of your whole application and of",
    "start": "222930",
    "end": "230700"
  },
  {
    "text": "course when you talk to other external systems that you don't control that's where akka HTTP comes in that's where it",
    "start": "230700",
    "end": "236700"
  },
  {
    "text": "makes sense for akka to take on an HTTP module because integration with the rest of the world probably is going to happen",
    "start": "236700",
    "end": "244200"
  },
  {
    "text": "through HTTP it is the most successful integration protocol up to now it's not",
    "start": "244200",
    "end": "249240"
  },
  {
    "text": "perfect it has all kinds of warts and and there are many good reasons to critique HTTP but it's still it's the",
    "start": "249240",
    "end": "255120"
  },
  {
    "text": "standard it's what everyone needs to talk and so our systems need HTTP in",
    "start": "255120",
    "end": "261269"
  },
  {
    "text": "order to be able to integrate with the rest of the world all right so when we look at akka HTTP there are",
    "start": "261270",
    "end": "268310"
  },
  {
    "text": "certain things that make it cool right why why is it cool the design goals that",
    "start": "268310",
    "end": "274639"
  },
  {
    "text": "have flown into this is they come from the learnings of the last year of the",
    "start": "274639",
    "end": "279680"
  },
  {
    "start": "277000",
    "end": "447000"
  },
  {
    "text": "last year's and of course we want to achieve maximum throughput with acceptable latency right that's that's",
    "start": "279680",
    "end": "286400"
  },
  {
    "text": "what you're looking for you want performance we want to be able to properly scale across all our cores",
    "start": "286400",
    "end": "291770"
  },
  {
    "text": "crank up the machine really use it properly and basically give you an unlimited number of connections",
    "start": "291770",
    "end": "297979"
  },
  {
    "text": "unlimited in the sense that you're limited by your memory by your or by your operating system but not by the",
    "start": "297979",
    "end": "304520"
  },
  {
    "text": "library the HTTP stack that you use one important thing is that we always had in",
    "start": "304520",
    "end": "310100"
  },
  {
    "text": "spray in an HTTP server and client side support at the same time because integration with other systems means you",
    "start": "310100",
    "end": "317660"
  },
  {
    "text": "need to consume as well as provide services right and it's not enough to just focus on one side then of course",
    "start": "317660",
    "end": "325550"
  },
  {
    "text": "what you expect from a modern library is open composable api's you want to be able to easily integrate it into your",
    "start": "325550",
    "end": "333160"
  },
  {
    "text": "stack into whatever you choose it shouldn't be hard to work with it should nicely allow you to factor out things",
    "start": "333160",
    "end": "339410"
  },
  {
    "text": "and so on so that's important and commonly as is on VOC is it's not a",
    "start": "339410",
    "end": "346430"
  },
  {
    "text": "framework style right you you probably have heard that before and I'll focus with this layer is integration as I said",
    "start": "346430",
    "end": "353720"
  },
  {
    "text": "it's integration is not necessarily building web applications there are certain differences you can use it to",
    "start": "353720",
    "end": "359210"
  },
  {
    "text": "build web applications if you really want to or if your application needs are simple but if you know it's that the",
    "start": "359210",
    "end": "366229"
  },
  {
    "text": "core of your application is the interaction with the browser then things like play might be better suited alright",
    "start": "366229",
    "end": "373520"
  },
  {
    "text": "so if that are the goals they have certain consequences for the implementation and it means if we want",
    "start": "373520",
    "end": "378800"
  },
  {
    "text": "to scale if we want to really get high performance we need to be fully asynchronous and non-blocking",
    "start": "378800",
    "end": "384169"
  },
  {
    "text": "right there's no way around around that otherwise we won't scale and since we're",
    "start": "384169",
    "end": "389479"
  },
  {
    "text": "an akka it needs to be somehow act or friendly even though akka HTTP is now moved a bit away from the pure actor",
    "start": "389479",
    "end": "396200"
  },
  {
    "text": "basis it's actually it's implemented on top of actors but that might change and you don't need to worry",
    "start": "396200",
    "end": "402819"
  },
  {
    "text": "about that and the current API is actually not actor api's anymore of",
    "start": "402819",
    "end": "409059"
  },
  {
    "text": "course it needs to be lightweight modular testable everything that you expect and it's fully well is that even",
    "start": "409059",
    "end": "416469"
  },
  {
    "text": "a word i I kind of I'm not sure this this thing you can decouple it from the",
    "start": "416469",
    "end": "422979"
  },
  {
    "text": "underlying TCP interface we're going to see what that what that means and as you know it's based on spray i/o so we built",
    "start": "422979",
    "end": "430689"
  },
  {
    "text": "on top of the experience they're reuse where whatever was possible from the",
    "start": "430689",
    "end": "435939"
  },
  {
    "text": "code base but also wrote a lot of code completely from scratch so what what is",
    "start": "435939",
    "end": "442659"
  },
  {
    "text": "actually coming in from spray as heritage so to speak oh there is a pretty good immutable case class-based",
    "start": "442659",
    "end": "450069"
  },
  {
    "text": "HTTP model that many people have grown to like and that didn't need a lot of adaptation we have a very efficient",
    "start": "450069",
    "end": "457479"
  },
  {
    "text": "parsing and rendering logic for HTTP which is the reason of one core reason of why spray has been so fast and then",
    "start": "457479",
    "end": "465069"
  },
  {
    "text": "many people might know spray mainly as its as its surface layer which is the the routing DSL on the server side but",
    "start": "465069",
    "end": "472029"
  },
  {
    "text": "it's only one part and that part is going to be moving or is moving into akka HTTP with small tweaks but no major",
    "start": "472029",
    "end": "480069"
  },
  {
    "text": "changes and there's the test kit which is basically the same of course we've",
    "start": "480069",
    "end": "485199"
  },
  {
    "text": "learned over the last years a few things that weren't as great in spray and they",
    "start": "485199",
    "end": "493539"
  },
  {
    "text": "are centered around the common theme which is mostly a lack of having the",
    "start": "493539",
    "end": "498999"
  },
  {
    "text": "right just having the right abstraction we didn't have the right abstraction to tackle a few of those guy a few of those",
    "start": "498999",
    "end": "504699"
  },
  {
    "text": "weaknesses if you've worked with spray then you might know that handling chunked messages requests and responses",
    "start": "504699",
    "end": "510039"
  },
  {
    "text": "can be a bit clunky it's it's not as easy as it should be dealing with large",
    "start": "510039",
    "end": "515169"
  },
  {
    "text": "messages kind of similar it's sometimes hard and we're going to see a little bit later what exactly can be the problem",
    "start": "515169",
    "end": "521258"
  },
  {
    "text": "there then the routing DSL has its own kind of small traps that you can fall into if you are kind of new to scala",
    "start": "521259",
    "end": "527410"
  },
  {
    "text": "especially and there's there are things that we can improve and of course if you",
    "start": "527410",
    "end": "532720"
  },
  {
    "text": "come into scala then you sometimes have trouble with implicit debugging and these kind of things and missing",
    "start": "532720",
    "end": "538029"
  },
  {
    "text": "features are always a thing as always a weakness will always have missing features one common one is WebSockets",
    "start": "538029",
    "end": "543910"
  },
  {
    "text": "support for spray so there's one example that I want to go into a bit deeper",
    "start": "543910",
    "end": "549490"
  },
  {
    "start": "546000",
    "end": "670000"
  },
  {
    "text": "because we have the ability to work on the client as well as on the server-side",
    "start": "549490",
    "end": "554970"
  },
  {
    "text": "proxying request is actually quite easy because you usually work with the same kind of data models on the on the one",
    "start": "554970",
    "end": "563199"
  },
  {
    "text": "and on the other side so this is a scenario that has come up quite a few times over the last years where someone",
    "start": "563199",
    "end": "569920"
  },
  {
    "text": "said wow cool we have this new back-end written completely in scala we use spray for it it's it's all great but small",
    "start": "569920",
    "end": "576009"
  },
  {
    "text": "parts of our application they still need to run we just keep it running on the",
    "start": "576009",
    "end": "581439"
  },
  {
    "text": "legacy machine on the same line it runs whatever jungle whatever and for certain",
    "start": "581439",
    "end": "586779"
  },
  {
    "text": "types of requests we need to proxy the requests over to the legacy back-end and there's just final funnel the response",
    "start": "586779",
    "end": "593259"
  },
  {
    "text": "back to the client so that's what it usually looks like you have a client that requests something we proxy the request over to the legacy back end the",
    "start": "593259",
    "end": "599559"
  },
  {
    "text": "legacy back-end answers proxies the response back to the client done you can build that easy now you can see where",
    "start": "599559",
    "end": "607209"
  },
  {
    "text": "the problem comes in if the response is really really large because you have a disparen see the disparity in in in data",
    "start": "607209",
    "end": "614230"
  },
  {
    "text": "rate right the lan is fast and the client might be new zealand really really slow and you can see where",
    "start": "614230",
    "end": "620079"
  },
  {
    "text": "the problem is it's it's there right you have a risk of getting squeezed there because the legacy packet might just",
    "start": "620079",
    "end": "625389"
  },
  {
    "text": "dump the eight gigabytes across a ten gigabit connection unto you at but you",
    "start": "625389",
    "end": "630879"
  },
  {
    "text": "actually need to spoon-feed it to the client right so how do you how do you",
    "start": "630879",
    "end": "636100"
  },
  {
    "text": "solve that what we need is is push back we need to somehow slow down the legacy back-end in sending stuff to us now tcp",
    "start": "636100",
    "end": "643990"
  },
  {
    "text": "the underlying transport can do that but your your your stack in spray your HTTP",
    "start": "643990",
    "end": "652480"
  },
  {
    "text": "stack needs to handle that properly and this is tougher than necessary with",
    "start": "652480",
    "end": "658720"
  },
  {
    "text": "spray is actually it's possible but it's brittle it's not really robust and it doesn't work",
    "start": "658720",
    "end": "663939"
  },
  {
    "text": "in a composable way and that that sucks that's one of the main problems that we needed to solve so akka HDPE is",
    "start": "663939",
    "end": "672189"
  },
  {
    "start": "670000",
    "end": "864000"
  },
  {
    "text": "something like spray - oh we address the weaknesses we do across the board publishing we add java api is for",
    "start": "672189",
    "end": "678729"
  },
  {
    "text": "everything which is something that we've tried to avoid all the time and spray now we can't avoid it anymore everything in akka has a Java API so",
    "start": "678729",
    "end": "685209"
  },
  {
    "text": "akka HTTP needs needs to have one as well we simply have simplified the module structure a bit but there's one core",
    "start": "685209",
    "end": "691269"
  },
  {
    "text": "improvement and that's the that's that we moved a lot of the core code on to",
    "start": "691269",
    "end": "697379"
  },
  {
    "text": "reactive streams now the act reactive streams is is basically the basis of",
    "start": "697379",
    "end": "703329"
  },
  {
    "text": "everything underneath akka HTTP in the new Akai oh I don't really have the time to go into reactive streams too much",
    "start": "703329",
    "end": "710529"
  },
  {
    "text": "today here in this session but I'm going to be offering a session on reactor streams tomorrow I have a lot of",
    "start": "710529",
    "end": "716349"
  },
  {
    "text": "material that have been presenting several times across Europe in the last month so if anyone's interested tomorrow",
    "start": "716349",
    "end": "722619"
  },
  {
    "text": "we can have a deep dive in into into reactive streams so today just one chart reactive streams all you need to",
    "start": "722619",
    "end": "728859"
  },
  {
    "text": "understand at a very high level in order to be following the rest of the talk reactive streams are basically a new",
    "start": "728859",
    "end": "734589"
  },
  {
    "text": "abstraction for asynchronous and non blocking pipeline processing if you do",
    "start": "734589",
    "end": "739659"
  },
  {
    "text": "pipeline processing in a synchronous way then you always can resort to blocking",
    "start": "739659",
    "end": "745149"
  },
  {
    "text": "and that kind of solves the back pressure problem but if your asynchronous and you don't block then",
    "start": "745149",
    "end": "751439"
  },
  {
    "text": "handling back pressure in a similar way that have just shown slowing down the source of the data that you are",
    "start": "751439",
    "end": "757599"
  },
  {
    "text": "digesting is tougher than then you might initially think and reactive streams is",
    "start": "757599",
    "end": "764499"
  },
  {
    "text": "one attempt to do that properly it's the core improvement over prior works like re grx java is that the back pressure is",
    "start": "764499",
    "end": "771489"
  },
  {
    "text": "built in and handled properly across everything and tomorrow we're going to look at that tomorrow if it really",
    "start": "771489",
    "end": "778689"
  },
  {
    "text": "in-depth if you are interested director streams project itself defines not much",
    "start": "778689",
    "end": "786669"
  },
  {
    "text": "more than just an API that different implementations can implement and the core goal is to have all the different",
    "start": "786669",
    "end": "793059"
  },
  {
    "text": "implementations of reactive streams be interoperable so the Twitter can have their implementation talk to the one from Netflix talk to the",
    "start": "793059",
    "end": "799600"
  },
  {
    "text": "one from typesafe and so on so that's that's great there are many many use cases for reactive streams and as I said",
    "start": "799600",
    "end": "807190"
  },
  {
    "text": "it's a joint effort from Big Shot guys from important companies so back to akka",
    "start": "807190",
    "end": "813760"
  },
  {
    "text": "HTTP where do we have streams there are quite a few places where streams are important in akka HTTP of course you can",
    "start": "813760",
    "end": "819670"
  },
  {
    "text": "think about the requests that come across one connection as a stream it's a stream of requests that come comes out",
    "start": "819670",
    "end": "826720"
  },
  {
    "text": "and on the other way what is going out is a stream of responses going out",
    "start": "826720",
    "end": "831760"
  },
  {
    "text": "across the same connection if you have a request then the entity so the content",
    "start": "831760",
    "end": "838870"
  },
  {
    "text": "of the request can be chunks a stream of chunks and if you model that as a proper",
    "start": "838870",
    "end": "844990"
  },
  {
    "text": "stream then it's the same abstraction again just one nested level in and the bytes if it's not chunked if it's just a",
    "start": "844990",
    "end": "851260"
  },
  {
    "text": "raw request and even the bytes of this request or response can be a pure can be",
    "start": "851260",
    "end": "856810"
  },
  {
    "text": "looked at as a pure stream so these are the four major points where we have",
    "start": "856810",
    "end": "862060"
  },
  {
    "text": "streams in akka HTTP now this picture is actually this is important this if you take away one thing from this talk and",
    "start": "862060",
    "end": "868510"
  },
  {
    "start": "864000",
    "end": "1131000"
  },
  {
    "text": "it's this picture this is what akka HTTP gives you let's let's look at what this",
    "start": "868510",
    "end": "874300"
  },
  {
    "text": "means the yellow stuff here is your application right on the client or on",
    "start": "874300",
    "end": "880209"
  },
  {
    "text": "the server side on both sides and the stuff in the middle is what our KH TP gives you now let's look at the client",
    "start": "880209",
    "end": "886420"
  },
  {
    "text": "side first you basically have some kind of processing pipeline where you implement",
    "start": "886420",
    "end": "892660"
  },
  {
    "text": "your business logic that does certain things to whatever data you are dealing with and what akka HTTP gives you on the",
    "start": "892660",
    "end": "898930"
  },
  {
    "text": "client side is an element that you can plug into your stream logic that",
    "start": "898930",
    "end": "905380"
  },
  {
    "text": "transforms requests into responses because that's essentially what HTTP",
    "start": "905380",
    "end": "910720"
  },
  {
    "text": "client does right it's an it's a function essentially asynchronous non-blocking properly modeled function",
    "start": "910720",
    "end": "916959"
  },
  {
    "text": "that you stuff in requests and you'll get out responses that's it that's a client and on the server side it's",
    "start": "916959",
    "end": "923589"
  },
  {
    "text": "exactly the opposite what you provide as a server is a function more or less that",
    "start": "923589",
    "end": "929410"
  },
  {
    "text": "turns requests into responses that's what you build and if you stay",
    "start": "929410",
    "end": "934779"
  },
  {
    "text": "within the stream abstraction then on the server side you provide a piece of",
    "start": "934779",
    "end": "940509"
  },
  {
    "text": "pipeline that properly connects onto those sockets and that transforms",
    "start": "940509",
    "end": "945699"
  },
  {
    "text": "requests into responses and on the client side you need a piece of pipeline from the library that transform requests",
    "start": "945699",
    "end": "952449"
  },
  {
    "text": "into responses but this was all streaming fied it's all streams now the",
    "start": "952449",
    "end": "957670"
  },
  {
    "text": "benefit is for example let's look at what this means suppose here the client pipeline has some slow stages something",
    "start": "957670",
    "end": "964720"
  },
  {
    "text": "that takes a long time to process because you're doing expensive CRC checking of the content of the response",
    "start": "964720",
    "end": "971470"
  },
  {
    "text": "or something so if this is slow then this stream abstraction makes is possible that this this back pressure",
    "start": "971470",
    "end": "977680"
  },
  {
    "text": "that is building up so that's the slow down signal gets carried across this",
    "start": "977680",
    "end": "983050"
  },
  {
    "text": "part of the TCP connection and TCP does have flow control so we can use that all the way here it slows down the server in",
    "start": "983050",
    "end": "990129"
  },
  {
    "text": "producing responses now if the server is built properly with akka HTTP on this side then this back pressure will",
    "start": "990129",
    "end": "996579"
  },
  {
    "text": "actually carry over to this side go across here and slow down the client in",
    "start": "996579",
    "end": "1002279"
  },
  {
    "text": "sending requests so the client can because this stage is slow maybe this",
    "start": "1002279",
    "end": "1008370"
  },
  {
    "text": "stage is being slowed down right and that's important because you need to stay if you if you rip up this the the",
    "start": "1008370",
    "end": "1014639"
  },
  {
    "text": "pipeline somewhere then you're going to have data loss or you can have out of memory errors or whatever so if you stay",
    "start": "1014639",
    "end": "1019980"
  },
  {
    "text": "within this tight stream pipeline then the back pressure will properly carry over all the way to wherever the data",
    "start": "1019980",
    "end": "1027089"
  },
  {
    "text": "are coming from and that's really nice and that solves the problem that we sing in the beginning by just automatically",
    "start": "1027089",
    "end": "1033538"
  },
  {
    "text": "slowing down whoever is signing the data so if we do a double-click on on this",
    "start": "1033539",
    "end": "1041399"
  },
  {
    "text": "thing I've shown it as just one element but it's of course several elements so",
    "start": "1041399",
    "end": "1046409"
  },
  {
    "text": "this is the stack of of what it is you have underneath obviously the the operating system then you have the niño",
    "start": "1046409",
    "end": "1053450"
  },
  {
    "text": "JDK currently as our basis layer and then you have two or three layers on top",
    "start": "1053450",
    "end": "1060390"
  },
  {
    "text": "there's a curio which is a module that has been in for a year or two I think that",
    "start": "1060390",
    "end": "1067350"
  },
  {
    "text": "implements the translation between the raw and i/o interfaces in a proper actor",
    "start": "1067350",
    "end": "1074429"
  },
  {
    "text": "eyes message based TCP UDP interface or a proper streaming fied TCP interface",
    "start": "1074429",
    "end": "1079799"
  },
  {
    "text": "right so you get stream interfaces for TCP on top we have akka ITT Pecor which",
    "start": "1079799",
    "end": "1085110"
  },
  {
    "text": "does just the translation between TCP and HTTP right that's it that's all it",
    "start": "1085110",
    "end": "1090299"
  },
  {
    "text": "does and your application can choose to sit directly on the core layer and not use the this part which is the higher",
    "start": "1090299",
    "end": "1098549"
  },
  {
    "text": "level stuff like the routing DSL and marshaling compression all these kind of",
    "start": "1098549",
    "end": "1103980"
  },
  {
    "text": "things annika stream which is also in the new occur module kind of sits on the side",
    "start": "1103980",
    "end": "1109139"
  },
  {
    "text": "because it's an it's an it's a help of technology that is used across all stacks it provides the stream",
    "start": "1109139",
    "end": "1115590"
  },
  {
    "text": "infrastructure that is needed here and here and here and potentially also at the application level you can use to you",
    "start": "1115590",
    "end": "1122519"
  },
  {
    "text": "can choose to build your application with akka stream if you want to you don't have to but if so then you'll be",
    "start": "1122519",
    "end": "1129120"
  },
  {
    "text": "using that as well so now I have a few charts that just do explain what I just",
    "start": "1129120",
    "end": "1135929"
  },
  {
    "start": "1131000",
    "end": "1259000"
  },
  {
    "text": "explained as well so that's ok i/o i KH t peak or what i just said and the",
    "start": "1135929",
    "end": "1143159"
  },
  {
    "text": "responsibilities of the akka HTTP layer so there's one before we dive into the",
    "start": "1143159",
    "end": "1148799"
  },
  {
    "text": "code finally there are a few basic concepts that we need to understand in",
    "start": "1148799",
    "end": "1155429"
  },
  {
    "text": "order to be able to understand the the code is coming and tomorrow we're going to dig into that deeper if you're",
    "start": "1155429",
    "end": "1160470"
  },
  {
    "text": "interested so there are a few things that are important a source in akka stream is the open end of a pipeline so",
    "start": "1160470",
    "end": "1168029"
  },
  {
    "text": "you have a stream pipeline that you know can produce T's if you ask it to produce",
    "start": "1168029",
    "end": "1173789"
  },
  {
    "text": "T's and that's a source of T and the sink is just the opposite now you have a",
    "start": "1173789",
    "end": "1179490"
  },
  {
    "text": "piece of pipeline that you can stuff T's in if it requests them from you and a",
    "start": "1179490",
    "end": "1186029"
  },
  {
    "text": "flow is basically just a piece of pipeline with two open ends so with a flow you can take a source plug in a",
    "start": "1186029",
    "end": "1193110"
  },
  {
    "text": "flow and then you have a new source here right you can put in another flow and and you have a new source at this end",
    "start": "1193110",
    "end": "1199110"
  },
  {
    "text": "and in the end you need to somehow connect it to a sink and once you have connected to a sink the whole thing is",
    "start": "1199110",
    "end": "1204570"
  },
  {
    "text": "done and you can push the button and say go right that's roughly the logic of how",
    "start": "1204570",
    "end": "1210030"
  },
  {
    "text": "this works and there's one important thing generally naka stream sources and sinks and flows are reusable meaning if",
    "start": "1210030",
    "end": "1219059"
  },
  {
    "text": "I have a piece of flow for example I can take one source plug it in start it",
    "start": "1219059",
    "end": "1225059"
  },
  {
    "text": "connected to the sink started and then take the same flow instance that is that I still have plug it into another source",
    "start": "1225059",
    "end": "1230970"
  },
  {
    "text": "and another thing and then crank it again so so you can materialize a stream",
    "start": "1230970",
    "end": "1236880"
  },
  {
    "text": "several times that's the proper the concept of materialization it's important to understand that concept",
    "start": "1236880",
    "end": "1242059"
  },
  {
    "text": "before we can understand the code so materialization is take the template a",
    "start": "1242059",
    "end": "1247890"
  },
  {
    "text": "source a flow a sink put it together and then when you push the button that's materialization you can push it several",
    "start": "1247890",
    "end": "1254669"
  },
  {
    "text": "times and you get several materializations incarnations of the same stream okay so let's look at the",
    "start": "1254669",
    "end": "1260909"
  },
  {
    "start": "1259000",
    "end": "1348000"
  },
  {
    "text": "server API what does it look like right now so it gives you a ket P gives you a bind method and the bind method takes an",
    "start": "1260909",
    "end": "1269280"
  },
  {
    "text": "endpoint and a bunch of settings doesn't matter and it immediately gives you back",
    "start": "1269280",
    "end": "1275490"
  },
  {
    "text": "a server binding a server binding instance so there is no future here and nothing really happens at that point you",
    "start": "1275490",
    "end": "1282150"
  },
  {
    "text": "just get a binding right so you have a binding but what can you do with the binding a binding gives you a source of",
    "start": "1282150",
    "end": "1288450"
  },
  {
    "text": "connections because in the end you can look at it at a server as a TCP server",
    "start": "1288450",
    "end": "1293700"
  },
  {
    "text": "or HTTP server as something that produces connections right so you and they are modeled as a source as well so",
    "start": "1293700",
    "end": "1300390"
  },
  {
    "text": "it's a stream of incoming connection and when you materialize this source this",
    "start": "1300390",
    "end": "1307140"
  },
  {
    "text": "source that's when the binding happens right up until that point the binding doesn't happen now you can take the same",
    "start": "1307140",
    "end": "1313559"
  },
  {
    "text": "binding and actually bind several times materialize several times if you want to now if you have a concrete port that",
    "start": "1313559",
    "end": "1320730"
  },
  {
    "text": "won't work the second time you try to bind the port port that won't work but if you bind to port 0 for example the",
    "start": "1320730",
    "end": "1326669"
  },
  {
    "text": "operating system is going to assign the port the free port and you can actually bind ten times hundred times if you want to for the",
    "start": "1326669",
    "end": "1333059"
  },
  {
    "text": "same server binding so let's let's just skip across the rest there's a bit of",
    "start": "1333059",
    "end": "1340769"
  },
  {
    "text": "sugar here but that's the basic idea now let's look at what is what do I get out of this source once I've materialized it",
    "start": "1340769",
    "end": "1346740"
  },
  {
    "text": "what is an incoming connection an incoming connection is this guy it has at the time you see it at the time you",
    "start": "1346740",
    "end": "1354269"
  },
  {
    "start": "1348000",
    "end": "1427000"
  },
  {
    "text": "have an instance in your hand the connection has been accepted so you have a local address and the remote address",
    "start": "1354269",
    "end": "1359669"
  },
  {
    "text": "right there and what you then do we're on the server side you can call handle",
    "start": "1359669",
    "end": "1365700"
  },
  {
    "text": "with with a handler and a flow so what you supply as we seen is the piece of",
    "start": "1365700",
    "end": "1372210"
  },
  {
    "text": "pipeline that translates requests into responses and if you give that to the incoming connection then the connection",
    "start": "1372210",
    "end": "1377850"
  },
  {
    "text": "will take that attach it to the socket and have it run right that's it and you",
    "start": "1377850",
    "end": "1384299"
  },
  {
    "text": "can take the same flow instance for another connection and just have it materialize there right so that's the",
    "start": "1384299",
    "end": "1390149"
  },
  {
    "text": "that's why it's important that you can reuse flows because you can supply a flow once and then it can be materialized for every connection again",
    "start": "1390149",
    "end": "1397379"
  },
  {
    "text": "and again and again and there's a bit of sugar here that we're going to see tomorrow how that is implemented is just",
    "start": "1397379",
    "end": "1404340"
  },
  {
    "text": "one line it just helps you to if you don't want to stay within the flow and you already have a true function a",
    "start": "1404340",
    "end": "1409499"
  },
  {
    "text": "synchronous function that translates requests into responses you can just use that or if you have an asynchronous",
    "start": "1409499",
    "end": "1415440"
  },
  {
    "text": "function that produces a future on a response you can just use that obviously streams and futures they interoperate",
    "start": "1415440",
    "end": "1421799"
  },
  {
    "text": "nicely and there is there's all kinds of things that make it easy for you so",
    "start": "1421799",
    "end": "1426860"
  },
  {
    "text": "there's one more interesting bit which is there's a function that allows you to",
    "start": "1426860",
    "end": "1435590"
  },
  {
    "start": "1427000",
    "end": "1534000"
  },
  {
    "text": "use the HTTP layer all by itself and what it does is you'll give it the flow",
    "start": "1435590",
    "end": "1442499"
  },
  {
    "text": "the server flow that translates request into responses and what you get back is another flow that you can use on the",
    "start": "1442499",
    "end": "1450090"
  },
  {
    "text": "underlying TCP layer so because I oh the IO IO layer is you essentially exactly",
    "start": "1450090",
    "end": "1456480"
  },
  {
    "text": "the same api's not from request to response but from bite string to bite string because that's what TCP is right",
    "start": "1456480",
    "end": "1462570"
  },
  {
    "text": "so and if you if you use that that basically just translates or encapsulate everything",
    "start": "1462570",
    "end": "1468480"
  },
  {
    "text": "that the HDP layer does which is parsing requests and rendering responses all by",
    "start": "1468480",
    "end": "1474090"
  },
  {
    "text": "itself and then the nice benefit is you now have a flow that you can plug into",
    "start": "1474090",
    "end": "1479159"
  },
  {
    "text": "the TCP layer if you want to but you could also just materialize it in your",
    "start": "1479159",
    "end": "1484440"
  },
  {
    "text": "tests just for yourself and and you know just use your own bite strings and just",
    "start": "1484440",
    "end": "1489570"
  },
  {
    "text": "run the tittie at the HTTP layer detached from everything else and that's really nice it's completely decoupled",
    "start": "1489570",
    "end": "1495029"
  },
  {
    "text": "and it allows you to just work with this in a much nicer way than it's been",
    "start": "1495029",
    "end": "1500519"
  },
  {
    "text": "possible with spray or with other libraries or frameworks okay this is a",
    "start": "1500519",
    "end": "1507809"
  },
  {
    "text": "very simple example it just uses the what would look like to have a small ping-pong server so you have a binding",
    "start": "1507809",
    "end": "1514019"
  },
  {
    "text": "and then you just call this sugar method which does this and you can probably all",
    "start": "1514019",
    "end": "1519570"
  },
  {
    "text": "understand what this does so that's that's of course it's bit of a bit of cheating because we we just put all the",
    "start": "1519570",
    "end": "1526080"
  },
  {
    "text": "hard stuff in there but this is just one line so and tomorrow we'll see how that",
    "start": "1526080",
    "end": "1531539"
  },
  {
    "text": "will how that looks like underneath so on the client side let's move over to the client side on the client side you",
    "start": "1531539",
    "end": "1538200"
  },
  {
    "text": "call outgoing connection to an endpoint and you get back an outgoing connection instance again no connection is actually",
    "start": "1538200",
    "end": "1546659"
  },
  {
    "text": "being established nothing happens at that point you immediately and synchronously get back an outgoing connection and only when you take the",
    "start": "1546659",
    "end": "1554730"
  },
  {
    "text": "flow that is part of this plug it into your stream setup and then materialize",
    "start": "1554730",
    "end": "1559769"
  },
  {
    "text": "that then the connection is established and that can happen several times you",
    "start": "1559769",
    "end": "1565109"
  },
  {
    "text": "can take take this this out actually the name we should improve the name is if you take this instance here and you",
    "start": "1565109",
    "end": "1572429"
  },
  {
    "text": "materialize it ten times ten new connections to the to the host will be opened right because you can just open",
    "start": "1572429",
    "end": "1579149"
  },
  {
    "text": "several connections and on the client side as well there is this the ability",
    "start": "1579149",
    "end": "1585690"
  },
  {
    "start": "1582000",
    "end": "1609000"
  },
  {
    "text": "to separate it the HTTP layer from everything else and it's just the other way around so you give it a transport on",
    "start": "1585690",
    "end": "1592830"
  },
  {
    "text": "the TCP layer level and what you get is the upgraded flow the up",
    "start": "1592830",
    "end": "1598620"
  },
  {
    "text": "created piece of pipeline that includes the request rendering and the response parsing on the client-side again this is",
    "start": "1598620",
    "end": "1606090"
  },
  {
    "text": "great for testing okay so the HTTP model",
    "start": "1606090",
    "end": "1611190"
  },
  {
    "start": "1609000",
    "end": "1644000"
  },
  {
    "text": "is very similar to what we have in spray so if you use spray who view has used as",
    "start": "1611190",
    "end": "1616830"
  },
  {
    "text": "you spray actually so far many of you okay great then this will all be very",
    "start": "1616830",
    "end": "1621930"
  },
  {
    "text": "familiar that's model is the same there was no reason to change a lot of the things because we already got it kind of",
    "start": "1621930",
    "end": "1627240"
  },
  {
    "text": "right the first time it's high level abstractions for most things that you work with it's immutable little logic",
    "start": "1627240",
    "end": "1633480"
  },
  {
    "text": "there and it just gives you gives users the core types and Singleton's and",
    "start": "1633480",
    "end": "1640890"
  },
  {
    "text": "definitions that you need and open for extension this is the request in akka",
    "start": "1640890",
    "end": "1647190"
  },
  {
    "start": "1644000",
    "end": "1670000"
  },
  {
    "text": "HTTP it looks very much the same as in as in spray so it's properly typed as",
    "start": "1647190",
    "end": "1652590"
  },
  {
    "text": "you would expect in scala so the method is not a string its importance of proper type and the URI is a proper type and so there's no string",
    "start": "1652590",
    "end": "1659160"
  },
  {
    "text": "Li typing here the HTTP headers there's one difference to spray is that now the entity here is a request entity we're",
    "start": "1659160",
    "end": "1666809"
  },
  {
    "text": "going to see that in a second what that means on the response side we have a",
    "start": "1666809",
    "end": "1671970"
  },
  {
    "text": "status code which is not an integer it's a proper type and so on the same kind of headers and here we have a response",
    "start": "1671970",
    "end": "1678150"
  },
  {
    "text": "entity right the entity of an HTTP response and this is just to show that",
    "start": "1678150",
    "end": "1685080"
  },
  {
    "start": "1683000",
    "end": "1704000"
  },
  {
    "text": "even the URI is another time properly typed so we have proper types for the",
    "start": "1685080",
    "end": "1690510"
  },
  {
    "text": "Authority for the path for the query so so there's there's a lot of deep model",
    "start": "1690510",
    "end": "1697440"
  },
  {
    "text": "here that gives you safety when working with your eyes and and just everything in HTTP which is which is great so the",
    "start": "1697440",
    "end": "1704520"
  },
  {
    "start": "1704000",
    "end": "1786000"
  },
  {
    "text": "entity is interesting because that's where a big change over spray has happened so let's let's understand this",
    "start": "1704520",
    "end": "1711059"
  },
  {
    "text": "so there's a super type HTTP entity and then we have a response entity which you",
    "start": "1711059",
    "end": "1716700"
  },
  {
    "text": "can use on responses then we have a request entity that is used for requests and what is interesting of what trips",
    "start": "1716700",
    "end": "1722550"
  },
  {
    "text": "people up is request entity it extends response entity now what does that mean",
    "start": "1722550",
    "end": "1727830"
  },
  {
    "text": "does it make sense it does make sense because what it means is that everything that comes in in a",
    "start": "1727830",
    "end": "1734909"
  },
  {
    "text": "request you can also use on the response side so if I see a request I can take the entity and put it in a response and",
    "start": "1734909",
    "end": "1741029"
  },
  {
    "text": "it's all fine but it's not the case the other way around we're going to see why so anything I can use that I can use for",
    "start": "1741029",
    "end": "1749279"
  },
  {
    "text": "any type of message is a message entity and it's it's just an alias for for this guy and then HTTP what an important",
    "start": "1749279",
    "end": "1757260"
  },
  {
    "text": "feature that is used very often is a multi-part messages where several smaller content pieces are chunked",
    "start": "1757260",
    "end": "1765990"
  },
  {
    "text": "together into one big request or response commonly for example for forms or for file upload that's the type that",
    "start": "1765990",
    "end": "1772799"
  },
  {
    "text": "you would use and there's entities again inside of those parts of a multi-part",
    "start": "1772799",
    "end": "1777990"
  },
  {
    "text": "message and that's body part entity I mean Universal entity you can use anywhere right because it's it's just",
    "start": "1777990",
    "end": "1784139"
  },
  {
    "text": "standard so let's see there are five different incarnations of these guys the",
    "start": "1784139",
    "end": "1790139"
  },
  {
    "start": "1786000",
    "end": "1970000"
  },
  {
    "text": "first one is a strict entity which is a universal entity you can use it anywhere it has a content type and it has a byte",
    "start": "1790139",
    "end": "1798269"
  },
  {
    "text": "string so if I already have the data in memory if I already have the string there's no point in creating a",
    "start": "1798269",
    "end": "1803909"
  },
  {
    "text": "complicated stream abstraction around it I want to be able to use it just like that so many times you just use a strict",
    "start": "1803909",
    "end": "1809279"
  },
  {
    "text": "entity but it's not the most general one the most general one is this one it has",
    "start": "1809279",
    "end": "1816000"
  },
  {
    "text": "a content type it has a content length because you need up need to know a priori what is the length of the whole",
    "start": "1816000",
    "end": "1821909"
  },
  {
    "text": "of the whole guy and then you have a source of byte string so a stream that",
    "start": "1821909",
    "end": "1827970"
  },
  {
    "text": "you can instantiate also materialized where you can pull out the data but you",
    "start": "1827970",
    "end": "1833130"
  },
  {
    "text": "don't need to if you don't want to read it then it's going to stay where it is if you don't open up this data source",
    "start": "1833130",
    "end": "1838950"
  },
  {
    "text": "then the stack will actually not read the stuff from the socket and the client",
    "start": "1838950",
    "end": "1845490"
  },
  {
    "text": "or whoever is on the other side will not be able to send the data because you're not reading it right that's where the backpressure comes in but you can",
    "start": "1845490",
    "end": "1852210"
  },
  {
    "text": "already look at the rest of the request or at the response for example the headers or the the URI even before the",
    "start": "1852210",
    "end": "1859320"
  },
  {
    "text": "entity has been read of the network that's a big improvement over what we haven't sprayed so a chunked entity",
    "start": "1859320",
    "end": "1865080"
  },
  {
    "text": "models the age the chunked transfer encoding in HTTP it has a content type no content length",
    "start": "1865080",
    "end": "1870929"
  },
  {
    "text": "because chunk messages don't have a content length header and it has a source of chunks right I'm not showing",
    "start": "1870929",
    "end": "1877710"
  },
  {
    "text": "the chunk stream part it's basically just chunks with the exception that the last chunk in HTTP can have additional",
    "start": "1877710",
    "end": "1883259"
  },
  {
    "text": "data like a trailer additional headers and funky stuff that really is used so",
    "start": "1883259",
    "end": "1888990"
  },
  {
    "text": "and all this is a message entity meaning that you can use it in requests and responses but not in body parts because",
    "start": "1888990",
    "end": "1896039"
  },
  {
    "text": "in body parts doesn't make sense to have chunked in in there that's clear now",
    "start": "1896039",
    "end": "1901200"
  },
  {
    "text": "this guy is strange because this guy is a response entity you can only use it on responses not on requests and it has a",
    "start": "1901200",
    "end": "1909330"
  },
  {
    "text": "content type no content length and a source of byte string what this is is",
    "start": "1909330",
    "end": "1915000"
  },
  {
    "text": "the exception that we have inherited from HTTP 1 0 which allowed an implicit",
    "start": "1915000",
    "end": "1921539"
  },
  {
    "text": "ending of a response by just terminating the connection so HTTP HTTP 1 0 allows",
    "start": "1921539",
    "end": "1926940"
  },
  {
    "text": "the server to send the response and then at the end just terminate the connection which isn't a great idea because the",
    "start": "1926940",
    "end": "1933059"
  },
  {
    "text": "connection might have been you know closed for whatever reasons not necessarily for the right reason and you",
    "start": "1933059",
    "end": "1938159"
  },
  {
    "text": "don't have a way as a client to figure out was this a mistake an error or is that the proper ending of the response so that's discouraged in HTTP 1 1 but",
    "start": "1938159",
    "end": "1945090"
  },
  {
    "text": "it's still around and tons of clients and servers rely on that so we need to model it and obviously you can only use",
    "start": "1945090",
    "end": "1951419"
  },
  {
    "text": "it for responses because closing the connection at the end of the request kind of defeats the purpose you can't",
    "start": "1951419",
    "end": "1957269"
  },
  {
    "text": "read the response then so that's why why there is a difference between what is allowed on the request and what is on",
    "start": "1957269",
    "end": "1963179"
  },
  {
    "text": "the response side and then in the end we have something similar just for body parts ok so a few headers just to show",
    "start": "1963179",
    "end": "1972419"
  },
  {
    "start": "1970000",
    "end": "2030000"
  },
  {
    "text": "you the model how it works if you know spray that's exactly the same we we use the funky backtick notation in spray and",
    "start": "1972419",
    "end": "1980759"
  },
  {
    "text": "Anaka HTTP quite a lot because it makes it easy to understand or to think about what is the type for this header right",
    "start": "1980759",
    "end": "1986399"
  },
  {
    "text": "if you if I look at the setcookie header I need the type of the header then I know what the type is without having to",
    "start": "1986399",
    "end": "1993210"
  },
  {
    "text": "apply a certain transformation of what do I do with the - is it camel cased or is it an underscore or whatever which",
    "start": "1993210",
    "end": "1999630"
  },
  {
    "text": "use the same string and it makes it really easy of course this is a problem for the Java API right how do we well",
    "start": "1999630",
    "end": "2007460"
  },
  {
    "text": "there are tons of problems with Java API and of course we have a row handler become model everything so there are",
    "start": "2007460",
    "end": "2013700"
  },
  {
    "text": "tons of headers that we don't know about that you make up yourself and you can still use the escape hatch of just",
    "start": "2013700",
    "end": "2018740"
  },
  {
    "text": "having a string string thing this is basically all that play does right play",
    "start": "2018740",
    "end": "2024470"
  },
  {
    "text": "doesn't have a strong deep header model it gives you string string headers so",
    "start": "2024470",
    "end": "2031100"
  },
  {
    "start": "2030000",
    "end": "2098000"
  },
  {
    "text": "the benefits over the spray design we have a deeper and more properly typed",
    "start": "2031100",
    "end": "2036860"
  },
  {
    "text": "model for requests responses and the entities inside them in in spray this was all kind of compressed onto the same",
    "start": "2036860",
    "end": "2043220"
  },
  {
    "text": "level you had chunks and and which are actually a part of a request on the same",
    "start": "2043220",
    "end": "2048590"
  },
  {
    "text": "message level as the requests themselves which made it really tough to to separate the two entities can now have",
    "start": "2048590",
    "end": "2057080"
  },
  {
    "text": "arbitrary size properly we're not reading them from the network unless you request them that means we can deal with arbitrarily long messages in bounded",
    "start": "2057080",
    "end": "2064340"
  },
  {
    "text": "memory and that's great and as I said now a nice benefit is that",
    "start": "2064340",
    "end": "2070220"
  },
  {
    "text": "you can see the request or response as soon as the header has been read the header part the rest of the of the",
    "start": "2070220",
    "end": "2077419"
  },
  {
    "text": "response can still you know be in flight somewhere or sit in some buffer and you don't care you can already decide do I",
    "start": "2077419",
    "end": "2084169"
  },
  {
    "text": "take it do I read it to a reject the request because there's no authorization and I don't have to read the upload that is",
    "start": "2084169",
    "end": "2090560"
  },
  {
    "text": "you know the 10 gigabyte upload that the client is trying to push onto us so that's it's much cleaner much nicer",
    "start": "2090560",
    "end": "2096200"
  },
  {
    "text": "to be stream based here so there's more of course I could be talking about the",
    "start": "2096200",
    "end": "2101990"
  },
  {
    "start": "2098000",
    "end": "2117000"
  },
  {
    "text": "server side routing DSL it looks very similar to what you have in sprays or no big changes there there's testing I",
    "start": "2101990",
    "end": "2108530"
  },
  {
    "text": "could talk about and client-side API is I haven't really shown and the Jason Jason is always a big question yeah so",
    "start": "2108530",
    "end": "2117020"
  },
  {
    "start": "2117000",
    "end": "2216000"
  },
  {
    "text": "I'm not going to talk about that there's the the roadmap for us is since we are",
    "start": "2117020",
    "end": "2123560"
  },
  {
    "text": "on top of akka stream and akka stream depends on reactive streams on the reactor streams API we're kind of this",
    "start": "2123560",
    "end": "2129560"
  },
  {
    "text": "is our our upstream in terms of dependencies and this reactor streams di is almost completely specified",
    "start": "2129560",
    "end": "2136040"
  },
  {
    "text": "there's an RC out and we're going to c10 very soon which means that we have a stable specification for what reactor",
    "start": "2136040",
    "end": "2143270"
  },
  {
    "text": "streams are like and all the implementations can properly program against that and then it'll be even more",
    "start": "2143270",
    "end": "2149210"
  },
  {
    "text": "stable and we are very close on finishing up the first one zero release",
    "start": "2149210",
    "end": "2154880"
  },
  {
    "text": "of the new akka modules which is like a stream a chi-chi TP core naka HTTP you can see where we're almost done on the",
    "start": "2154880",
    "end": "2161360"
  },
  {
    "text": "client and server side the bottom layer is almost done one thing that where we're not really we haven't really had",
    "start": "2161360",
    "end": "2167210"
  },
  {
    "text": "time for right now is the high level client side so there's no high level client side right now so if you need if you're on the client side you need to",
    "start": "2167210",
    "end": "2173000"
  },
  {
    "text": "drop down to the connection level right now but that's going to change of course the most requested feature of spray",
    "start": "2173000",
    "end": "2179030"
  },
  {
    "text": "WebSocket support there like one hundred and eighty five different plus ones on that ticket on github so if you want to",
    "start": "2179030",
    "end": "2184520"
  },
  {
    "text": "you can put your own on to it as well but we're going to add it we have been kind of pushing out WebSocket support",
    "start": "2184520",
    "end": "2189890"
  },
  {
    "text": "because we knew that we were going to change large parts of the underlying infrastructure and if we had implemented",
    "start": "2189890",
    "end": "2197210"
  },
  {
    "text": "that in the spray world we would have to re-implement everything now on top of streams that's what we kind of pushed it out but now since we have the new",
    "start": "2197210",
    "end": "2203450"
  },
  {
    "text": "infrastructure underneath it's easy to just well of course it's just going to ninety percent done you know always the",
    "start": "2203450",
    "end": "2211190"
  },
  {
    "text": "case now we haven't really started yet and but it shouldn't take long maybe a few weeks we'll see and then of course",
    "start": "2211190",
    "end": "2217760"
  },
  {
    "text": "in the end the goal is that play we'll move on to this new shiny stack and move off nettie which they are successfully",
    "start": "2217760",
    "end": "2224180"
  },
  {
    "text": "using so far and Nettie is a good project but Nettie is a different world right it's it's not Scala it uses its",
    "start": "2224180",
    "end": "2230210"
  },
  {
    "text": "own thread pools it's configured in a completely different way it's can it's logging in a completely different way so it's its own world and there's a benefit",
    "start": "2230210",
    "end": "2237500"
  },
  {
    "text": "to just unifying everything on the same kind of clean stack and that's where play actually wants to end up so the",
    "start": "2237500",
    "end": "2244070"
  },
  {
    "text": "goal is to build a new kind of driver for play that sits on top of our HTTP",
    "start": "2244070",
    "end": "2251090"
  },
  {
    "text": "put it on the side and let you configure which driver you want to use the old proven natty one or the new shiny akka",
    "start": "2251090",
    "end": "2258860"
  },
  {
    "text": "HTTP one on top you shouldn't feel any difference except that the akka HTTP one",
    "start": "2258860",
    "end": "2264320"
  },
  {
    "text": "will be a lot slower right now because it's has been it hasn't been any optimization so far we've been focusing on many",
    "start": "2264320",
    "end": "2269819"
  },
  {
    "text": "different things but not on performance so far so if you look at our Chi HDPE right now it's it's dark slow but the",
    "start": "2269819",
    "end": "2276329"
  },
  {
    "text": "cool thing is that the architecture is is very nice and there's no reason why",
    "start": "2276329",
    "end": "2281880"
  },
  {
    "text": "in the end we shouldn't even be faster than spray because we are now we have all kinds of optimization options that",
    "start": "2281880",
    "end": "2288269"
  },
  {
    "text": "we can pull we haven't pulled yet so don't look at performance in the end we will have something that's that's really",
    "start": "2288269",
    "end": "2294180"
  },
  {
    "text": "really really fast so and then obviously after we've matured this new driver",
    "start": "2294180",
    "end": "2299510"
  },
  {
    "start": "2296000",
    "end": "2347000"
  },
  {
    "text": "underneath play for some time then we can deprecated the Neddie one and then move into the new shiny world of having",
    "start": "2299510",
    "end": "2306900"
  },
  {
    "text": "everything from akka HTTP and then of course in the end we want to have the nice new model which is much nicer than",
    "start": "2306900",
    "end": "2313980"
  },
  {
    "text": "the model that we have currently in play we want to have that on the surface so that you can actually use all those types right as long as we as play has to",
    "start": "2313980",
    "end": "2322130"
  },
  {
    "text": "keep the api's stable we can't surface this nice nice stuff so what is",
    "start": "2322130",
    "end": "2327240"
  },
  {
    "text": "happening if you play moves on to akka HTTP just like that then we'll have a nice passing layer underneath build a",
    "start": "2327240",
    "end": "2333000"
  },
  {
    "text": "really shiny proper model and then we'll call to string on all those types to you know give them funnel them through the",
    "start": "2333000",
    "end": "2339180"
  },
  {
    "text": "play API switch is kind of its it pains me to just think about it but so we want",
    "start": "2339180",
    "end": "2345089"
  },
  {
    "text": "to change that in the future of course so these are the resources we have a few minutes left thank",
    "start": "2345089",
    "end": "2352400"
  },
  {
    "start": "2347000",
    "end": "2569000"
  },
  {
    "text": "questions yes timeframe well I always",
    "start": "2358630",
    "end": "2365059"
  },
  {
    "text": "dodge that question I might as well just do it now um I can't really talk about it too much is it it's always tough because initially we",
    "start": "2365059",
    "end": "2372469"
  },
  {
    "text": "thought this is not going to take a long time right just streams are well understood let's",
    "start": "2372469",
    "end": "2378019"
  },
  {
    "text": "just go out three months we're done right now it's a year after we've had that talk and things creep up especially",
    "start": "2378019",
    "end": "2385940"
  },
  {
    "text": "in this new reactive streams world because there is a lot of stuff that we have not really understood yet there's a",
    "start": "2385940",
    "end": "2391969"
  },
  {
    "text": "lot of research really happening in a certain way how do you properly plug together those streams that have a back",
    "start": "2391969",
    "end": "2397369"
  },
  {
    "text": "pressure channel and tomorrow we're going to see exactly where all the complication comes from so I'm I'm I'm",
    "start": "2397369",
    "end": "2405680"
  },
  {
    "text": "not going to give you any date the goal is of course ASAP everyone wants it play",
    "start": "2405680",
    "end": "2411229"
  },
  {
    "text": "wants it everyone wants HTTP out and we're working on it as much as we can the goal is to have one zero out the",
    "start": "2411229",
    "end": "2419059"
  },
  {
    "text": "akka HT p10 thing currently at the end of q1 this year so there's not a lot of",
    "start": "2419059",
    "end": "2424880"
  },
  {
    "text": "time left two months or something so we're currently kind of digging through tickets what are we still doing what are we what what can't we do it stuff yeah",
    "start": "2424880",
    "end": "2434229"
  },
  {
    "text": "well the good thing is an akai oh we completely owned the stack all the way through so if there are any issues and",
    "start": "2435910",
    "end": "2443150"
  },
  {
    "text": "you're right that Nettie has certainly had much more time to mature over time and really address small tickets and",
    "start": "2443150",
    "end": "2448430"
  },
  {
    "text": "bugs and here and there if we are aware of any bugs on the i/o layer we'll try to address them as quickly as possible",
    "start": "2448430",
    "end": "2454099"
  },
  {
    "text": "because it's the base layer of everything currently I don't think we have any known issues there but it",
    "start": "2454099",
    "end": "2460190"
  },
  {
    "text": "doesn't mean that we don't have them I'm sure that that he has more kind of special casing of Windows on a certain",
    "start": "2460190",
    "end": "2466940"
  },
  {
    "text": "word version where you have a certain bug there has been a few things there have been a few things that have crept",
    "start": "2466940",
    "end": "2472160"
  },
  {
    "text": "up over the last two years that we have a kayo now but you're of course you're",
    "start": "2472160",
    "end": "2477469"
  },
  {
    "text": "right we're not as mature yet just because we didn't have that time but the goal is not to leave you alone with that but to give you give us the chance to",
    "start": "2477469",
    "end": "2483769"
  },
  {
    "text": "react quickly to the bugs that you find rather than trying to fix something in nettie and work with them even though",
    "start": "2483769",
    "end": "2489319"
  },
  {
    "text": "the cooperation with the nettie folks has been has been very nice but it's still one level away of course right so that's",
    "start": "2489319",
    "end": "2494750"
  },
  {
    "text": "that's the goal yeah well you need that",
    "start": "2494750",
    "end": "2501160"
  },
  {
    "text": "we have for example if you implement an HTTP proxy that's basically what it is you just fold it up and then you have a",
    "start": "2501160",
    "end": "2507770"
  },
  {
    "text": "client you have a proxy which is taking in the requests and sends it across another connection and does the same",
    "start": "2507770",
    "end": "2513560"
  },
  {
    "text": "thing on the on the other side and then you need to if the server is slow you need to slow down the client because you",
    "start": "2513560",
    "end": "2518930"
  },
  {
    "text": "want to be a transparent proxy in the middle right so there needs to be a way to trance transport back back pressure",
    "start": "2518930",
    "end": "2524210"
  },
  {
    "text": "across your own stack all the way into another connection and if you have several proxies which might well be the",
    "start": "2524210",
    "end": "2530750"
  },
  {
    "text": "case then it needs to go across machines right and you can do it if you just connect TCP and all the stacks are",
    "start": "2530750",
    "end": "2536990"
  },
  {
    "text": "properly kind of closed within the within the streams world then this will",
    "start": "2536990",
    "end": "2542330"
  },
  {
    "text": "work and we're going to see there's a chart on that tomorrow in tomorrow's session that deals exactly with that",
    "start": "2542330",
    "end": "2548090"
  },
  {
    "text": "because it's very cool yeah one more question okay maybe we're out of time",
    "start": "2548090",
    "end": "2553820"
  },
  {
    "text": "maybe we can take it outside thank you",
    "start": "2553820",
    "end": "2558250"
  },
  {
    "text": "you",
    "start": "2561240",
    "end": "2563300"
  }
]
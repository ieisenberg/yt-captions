[
  {
    "start": "0",
    "end": "132000"
  },
  {
    "text": "a couple of weeks ago I read an article they talked about how recent IPL cricket",
    "start": "4060",
    "end": "10420"
  },
  {
    "text": "auctions were life-changing for several cricket players that list of players included Ben Stokes who's one of my",
    "start": "10420",
    "end": "18279"
  },
  {
    "text": "favorite British cricketer and he was quoted in the article saying I was following it on Twitter I didn't",
    "start": "18279",
    "end": "24970"
  },
  {
    "text": "actually see it life I kept on refreshing my notifications I thought people were tweeting and then I realized",
    "start": "24970",
    "end": "31240"
  },
  {
    "text": "that Pune had got me why am i sharing this anecdote with you all well for one",
    "start": "31240",
    "end": "37360"
  },
  {
    "text": "I can talk about cricket in this country without having to explain myself and as",
    "start": "37360",
    "end": "42490"
  },
  {
    "text": "you can tell I love talking about cricket but more importantly it ties very closely to our jobs to be done",
    "start": "42490",
    "end": "47980"
  },
  {
    "text": "framework and we want to keep our users informed about the world the other thing",
    "start": "47980",
    "end": "55600"
  },
  {
    "text": "is it also showcases one of the prime use cases of Twitter where people come",
    "start": "55600",
    "end": "61270"
  },
  {
    "text": "to Twitter to follow a live event and to hear the real-world commentary around it and for both of these use cases my team",
    "start": "61270",
    "end": "67900"
  },
  {
    "text": "plays a very central role and we we enable these use cases by notifying",
    "start": "67900",
    "end": "73149"
  },
  {
    "text": "users about what's happening in their world in real time the key to highlight",
    "start": "73149",
    "end": "80049"
  },
  {
    "text": "here is their world and real-time and during the talk today we will focus on",
    "start": "80049",
    "end": "87909"
  },
  {
    "text": "why these two are important my name is Saul Apothic I manage notifications team",
    "start": "87909",
    "end": "94749"
  },
  {
    "text": "at Twitter I'm here today with Gary lamb who's the lead engineer in my team today",
    "start": "94749",
    "end": "101350"
  },
  {
    "text": "we will be giving a high-level overview of notifications then we will talk about",
    "start": "101350",
    "end": "107319"
  },
  {
    "text": "some of the main challenges we face scaling it and then we'll go over how",
    "start": "107319",
    "end": "113200"
  },
  {
    "text": "our infrastructure solves them after that we will go over the evolution of",
    "start": "113200",
    "end": "119310"
  },
  {
    "text": "notifications and broadly there are three categories that we will cover today we will start with triggered",
    "start": "119310",
    "end": "126009"
  },
  {
    "text": "notifications and then we will talk about personalized sign out and recommendations so that's not before",
    "start": "126009",
    "end": "134730"
  },
  {
    "start": "132000",
    "end": "228000"
  },
  {
    "text": "before we start let's do a quick show of hands raise your hands if you have used student notifications in the past it's",
    "start": "134730",
    "end": "142600"
  },
  {
    "text": "awesome but for those who did not raise your hands I'll have to find you and start sending you notifications but for your",
    "start": "142600",
    "end": "151420"
  },
  {
    "text": "benefit I will give a quick recap of the recap of the four main channels we use to notify our users the the first one is",
    "start": "151420",
    "end": "160990"
  },
  {
    "text": "notification timeline this is an in-app experience you go to your timeline to",
    "start": "160990",
    "end": "167170"
  },
  {
    "text": "see a reverse chronological history of all your notifications it acts as a pivot for the product then there's push",
    "start": "167170",
    "end": "175480"
  },
  {
    "text": "it's a heavenly use channel it ties very closely to the core of Twitter which is",
    "start": "175480",
    "end": "180580"
  },
  {
    "text": "students live and these notifications are real-time one of the most common",
    "start": "180580",
    "end": "185890"
  },
  {
    "text": "force notification is account notification through account",
    "start": "185890",
    "end": "191530"
  },
  {
    "text": "notification you can opt in to be notified every time someone tweets and that's that comprises of a huge volume",
    "start": "191530",
    "end": "198310"
  },
  {
    "text": "for push and then there is our G channel",
    "start": "198310",
    "end": "203860"
  },
  {
    "text": "some of you might not be aware but Twitter actually started as a group send SMS service and so SMS is still relevant",
    "start": "203860",
    "end": "211420"
  },
  {
    "text": "for us apart from some product cases we use it for sending login codes and 2",
    "start": "211420",
    "end": "217930"
  },
  {
    "text": "factor authorization and whatnot and then finally email it's the oldest",
    "start": "217930",
    "end": "222940"
  },
  {
    "text": "messaging channel channel on internet and it's still pretty relevant for us",
    "start": "222940",
    "end": "228660"
  },
  {
    "start": "228000",
    "end": "512000"
  },
  {
    "text": "now let's switch gears and talk about some of the main challenges that we face",
    "start": "228660",
    "end": "235989"
  },
  {
    "text": "and they have a bearing on how our architecture has evolved over time the",
    "start": "235989",
    "end": "243970"
  },
  {
    "text": "first one I want to highlight is notifications our bimodal what I mean",
    "start": "243970",
    "end": "250330"
  },
  {
    "text": "there is if you were to plot the number of notifications received by users for",
    "start": "250330",
    "end": "257260"
  },
  {
    "text": "all of your users you see a power law like distribution where there are two",
    "start": "257260",
    "end": "262870"
  },
  {
    "text": "major category of users there are users like me who get a handful of notifications on a given day and then",
    "start": "262870",
    "end": "270220"
  },
  {
    "text": "there are these have users they receive a ton of engagement these tend to be your",
    "start": "270220",
    "end": "275469"
  },
  {
    "text": "celebrities your politicians news reporters and people who have gone viral so as a product this creates challenges",
    "start": "275469",
    "end": "283770"
  },
  {
    "text": "that have bearing on the infrastructure so for instance for these heavy users they they get ton of engagement so they",
    "start": "283770",
    "end": "291639"
  },
  {
    "text": "get kind of notifications and you want to make sure we deliver those to them in real times on the other extreme people",
    "start": "291639",
    "end": "298419"
  },
  {
    "text": "who do not get a lot of notifications are the ones who do not tweet a lot they",
    "start": "298419",
    "end": "305349"
  },
  {
    "text": "are the consumers and for them the challenge is to figure out the right content that or right notifications that",
    "start": "305349",
    "end": "313779"
  },
  {
    "text": "will bring value to their Twitter experience as all of you are aware",
    "start": "313779",
    "end": "319539"
  },
  {
    "text": "Twitter is a very spiky product here's a good example of that and this is from",
    "start": "319539",
    "end": "325509"
  },
  {
    "text": "2013 so it's slightly dated but this was from in Japan they were he broadcasting",
    "start": "325509",
    "end": "333490"
  },
  {
    "text": "in an anime called castle in the sky and something must have happened during that where suddenly all the Japanese users",
    "start": "333490",
    "end": "340449"
  },
  {
    "text": "took to Twitter and started tweeting it and it created a tweets per second record for us back then",
    "start": "340449",
    "end": "346719"
  },
  {
    "text": "and then we started receiving hundreds of thousands of notifications or tweets",
    "start": "346719",
    "end": "352089"
  },
  {
    "text": "per second and as you can imagine every time there's a tweet spike there is a corresponding notification spike related",
    "start": "352089",
    "end": "360759"
  },
  {
    "text": "to that footer is highly asymmetric unlike some other social networks you",
    "start": "360759",
    "end": "366310"
  },
  {
    "text": "have cases where people like Elon Musk who have millions of followers so every",
    "start": "366310",
    "end": "371710"
  },
  {
    "text": "time Milan must tweets we have to send out his free to all of his followers and",
    "start": "371710",
    "end": "377979"
  },
  {
    "text": "just like to expand out there's notifications pan out so every time we tweets we have to find out all the users",
    "start": "377979",
    "end": "387279"
  },
  {
    "text": "who we need to notify and then deliver that notification to them in real time",
    "start": "387279",
    "end": "393150"
  },
  {
    "text": "so to round off an overview of our challenges how I'll",
    "start": "393150",
    "end": "398770"
  },
  {
    "text": "briefly mention the four main challenges that we face and by no means this is an",
    "start": "398770",
    "end": "404870"
  },
  {
    "text": "exhaustive list there are lot more both from product and infrastructure point of view but I want to highlight them today",
    "start": "404870",
    "end": "410360"
  },
  {
    "text": "because we will also talk about how we solve or how we address some of these challenges latency is the most obvious",
    "start": "410360",
    "end": "416600"
  },
  {
    "text": "one Twitter is life we want to make sure that from the time someone tweets to the",
    "start": "416600",
    "end": "423380"
  },
  {
    "text": "time you get notified is minimal we don't want to introduce much latency otherwise it takes away from the",
    "start": "423380",
    "end": "430400"
  },
  {
    "text": "experience I spoke about notification spikes and find out again we have to",
    "start": "430400",
    "end": "435800"
  },
  {
    "text": "make sure that we not only scale up to handle billions of notifications every day but we can also handle these sudden",
    "start": "435800",
    "end": "441530"
  },
  {
    "text": "spikes heterogeneity is something that's there for a lot of distributed systems",
    "start": "441530",
    "end": "448970"
  },
  {
    "text": "and it's the case for notifications and what I mean there is if you look at all",
    "start": "448970",
    "end": "454550"
  },
  {
    "text": "the calls that our services make notification services make you can split them into two major categories there are",
    "start": "454550",
    "end": "460400"
  },
  {
    "text": "there are calls that are serviced via cash or a fast data sort which tend to",
    "start": "460400",
    "end": "466160"
  },
  {
    "text": "be anywhere from few milliseconds to let's say tens of milliseconds and then there are external calls that we make to",
    "start": "466160",
    "end": "472160"
  },
  {
    "text": "Google and iOS which can take anywhere from half a second to a second and when",
    "start": "472160",
    "end": "478340"
  },
  {
    "text": "you have these two sets of calls it's not as simple as just horizontally",
    "start": "478340",
    "end": "484490"
  },
  {
    "text": "scaling up you have to be cognizant of how you are coupling or actually not coupling them and then finally for any",
    "start": "484490",
    "end": "491570"
  },
  {
    "text": "app like Twitter we need to make sure that we are resilient and for that we",
    "start": "491570",
    "end": "498020"
  },
  {
    "text": "need to make sure that our users can get",
    "start": "498020",
    "end": "503870"
  },
  {
    "text": "their notifications even if we were to failover and in general we need to make sure that we can handle multiple data",
    "start": "503870",
    "end": "509930"
  },
  {
    "text": "centers so let's talk about how our",
    "start": "509930",
    "end": "516500"
  },
  {
    "start": "512000",
    "end": "706000"
  },
  {
    "text": "infrastructure addresses some of these challenges and now for the sake of time",
    "start": "516500",
    "end": "522349"
  },
  {
    "text": "I will be very I will give you a very high-level overview each of this topic is something I can talk for the entire",
    "start": "522349",
    "end": "527900"
  },
  {
    "text": "duration but that's give a quick overview so this is our push architecture which is used to send",
    "start": "527900",
    "end": "535070"
  },
  {
    "text": "push SMS and email notifications and at a very high level we see notifications",
    "start": "535070",
    "end": "542150"
  },
  {
    "text": "and then there is some business business logic that we apply things like make sure your settings are being honored we",
    "start": "542150",
    "end": "548839"
  },
  {
    "text": "check for spam abuse whatnot and so a bunch of business rules are applied and then once a notification passes all of",
    "start": "548839",
    "end": "556400"
  },
  {
    "text": "them it's then sent out for delivery and then it eventually gets to your devices",
    "start": "556400",
    "end": "561820"
  },
  {
    "text": "so for this architecture the the three main challenges are of course we want to",
    "start": "561820",
    "end": "567410"
  },
  {
    "text": "keep latency low because push as I said is a live use case live channel we have",
    "start": "567410",
    "end": "575420"
  },
  {
    "text": "to be able to deal with spikes which happen all the time and the problem the spikes is you cannot fit it when they",
    "start": "575420",
    "end": "580940"
  },
  {
    "text": "happen so I used to work at Netflix and there they could rely on predictive auto",
    "start": "580940",
    "end": "587270"
  },
  {
    "text": "scaling but we cannot do that because you have no idea when the next spike is going to come and then I mentioned the",
    "start": "587270",
    "end": "595400"
  },
  {
    "text": "heterogeneity so how do we deal with latency and spikes well we rely on horizontal scaling but",
    "start": "595400",
    "end": "604490"
  },
  {
    "text": "that's not enough we need to make sure that when we scale up or when we have a",
    "start": "604490",
    "end": "612080"
  },
  {
    "text": "sudden a surge of a spike or notifications traffic we don't bring our",
    "start": "612080",
    "end": "617780"
  },
  {
    "text": "upstream services down because as I said notifications are asymmetric and so it's",
    "start": "617780",
    "end": "623510"
  },
  {
    "text": "very common for us so we have millions of events in our queue that are all",
    "start": "623510",
    "end": "629630"
  },
  {
    "text": "referring to the same user and if each of these processes start calling for the same user that services we will be down",
    "start": "629630",
    "end": "635900"
  },
  {
    "text": "so we is lie on lots of short-lived caches usually when you have you put",
    "start": "635900",
    "end": "643640"
  },
  {
    "text": "caching in place you optimize for cache hit rate for us it's totally fine to have cache misses in the beginning and",
    "start": "643640",
    "end": "650110"
  },
  {
    "text": "given that these spikes are short-lived short-lived Cassius Cassius totally",
    "start": "650110",
    "end": "655250"
  },
  {
    "text": "suffice our use cases in terms of heterogeneity there are two main ways we",
    "start": "655250",
    "end": "662720"
  },
  {
    "text": "to them so as I said we have different",
    "start": "662720",
    "end": "669670"
  },
  {
    "text": "types of notifications and different types of calls and we have we rely",
    "start": "669670",
    "end": "675139"
  },
  {
    "text": "heavily on priority queues to make sure that for instance your login codes are",
    "start": "675139",
    "end": "680149"
  },
  {
    "text": "not being delayed because there's a backlog because Katy Perry just tweeted so we need to decouple them and we do",
    "start": "680149",
    "end": "686750"
  },
  {
    "text": "that via priority queues and then the second thing is we make sure that cause",
    "start": "686750",
    "end": "692209"
  },
  {
    "text": "that take that have similar latency profile are queued separately so if",
    "start": "692209",
    "end": "697970"
  },
  {
    "text": "there is a delay due to a Google outage or slow down we are not delaying other",
    "start": "697970",
    "end": "703129"
  },
  {
    "text": "notifications so that was the push architecture for notifications timeline",
    "start": "703129",
    "end": "709790"
  },
  {
    "text": "we use a pull architecture and at a very high level same thing notifications are",
    "start": "709790",
    "end": "717189"
  },
  {
    "text": "received via by our right path they're typically received asynchronously but we have some synchronous use cases we apply",
    "start": "717189",
    "end": "725029"
  },
  {
    "text": "a set of business rules and again in this case instead of pushing them out for delivery we stole them in a backing",
    "start": "725029",
    "end": "732319"
  },
  {
    "text": "data store and they are cached and these sketches are long-lived caches and the",
    "start": "732319",
    "end": "737779"
  },
  {
    "text": "idea there is every time you visit your notifications timeline it should be",
    "start": "737779",
    "end": "742790"
  },
  {
    "text": "served out of cache it's very rare that it's not served out of cache because it's a very costly operation to generate",
    "start": "742790",
    "end": "750170"
  },
  {
    "text": "your timeline on the fly so that the two main challenges here are again latency",
    "start": "750170",
    "end": "757269"
  },
  {
    "text": "which is obvious we want to make sure that we are not taking forever to load up your notifications timeline because",
    "start": "757269",
    "end": "763250"
  },
  {
    "text": "otherwise you'll switch to something else and the other thing is multi DC we",
    "start": "763250",
    "end": "769040"
  },
  {
    "text": "need to make sure that in the event of fail failover or what not we can deliver your notification timeline to you and in",
    "start": "769040",
    "end": "775790"
  },
  {
    "text": "a timely manner so from a latency point of view we use a custom implementation",
    "start": "775790",
    "end": "785480"
  },
  {
    "text": "of Redis and I'm not sure if you guys attended Yao's talk on Monday she talked",
    "start": "785480",
    "end": "792529"
  },
  {
    "text": "about our caching architecture very good talk if you check it out as I said these we rely on long live",
    "start": "792529",
    "end": "798910"
  },
  {
    "text": "caches and we also store all of our notifications in Manhattan which is our",
    "start": "798910",
    "end": "805360"
  },
  {
    "text": "real-time distributed backing store and it's built for availability because",
    "start": "805360",
    "end": "812200"
  },
  {
    "text": "that's the most important thing for us from a multi DC point of view we of",
    "start": "812200",
    "end": "821350"
  },
  {
    "text": "course to cross the seer application but that's not enough we need to make sure that if you you were to move from one",
    "start": "821350",
    "end": "828070"
  },
  {
    "text": "data center to the other your notifications stay the same otherwise it will be a very jarring experience and so",
    "start": "828070",
    "end": "834280"
  },
  {
    "text": "for that we have we siphon off a small volume of notifications and it's off in",
    "start": "834280",
    "end": "842140"
  },
  {
    "text": "a separate of a synchronous queue we make sure that we compare notifications across data centers and make sure that",
    "start": "842140",
    "end": "848470"
  },
  {
    "text": "they are the same and if they are not saying we need to figure out what's going on we also have maintenance job to",
    "start": "848470",
    "end": "854890"
  },
  {
    "text": "make sure that our caches are not growing out of bounds and just doing housecleaning which we don't do not need",
    "start": "854890",
    "end": "861910"
  },
  {
    "text": "to do while we are handling real-time events if you are building a",
    "start": "861910",
    "end": "870430"
  },
  {
    "text": "notification infrastructure there these two things I want to highlight which you should think about building in one is",
    "start": "870430",
    "end": "877780"
  },
  {
    "text": "you want to make sure that it's very straightforward to add any notifications otherwise your experiment velocity will",
    "start": "877780",
    "end": "884590"
  },
  {
    "text": "be very slow so most of our new notifications are pretty much self serve or templated the second thing is we you",
    "start": "884590",
    "end": "893350"
  },
  {
    "text": "want to ensure that your notifications and your experiments are driven purely",
    "start": "893350",
    "end": "899860"
  },
  {
    "text": "on the backend side and the reason I mentioned this is as you can imagine footer is on all all possible apps and",
    "start": "899860",
    "end": "906160"
  },
  {
    "text": "if I have to add a new notification and if I have to chase down iOS theme and an Android team and make sure that I figure",
    "start": "906160",
    "end": "913900"
  },
  {
    "text": "out when is their next release and they are never aligned and before before you",
    "start": "913900",
    "end": "919300"
  },
  {
    "text": "know you have wasted months trying to add a new experiment and so we do not have we used to live in that world a",
    "start": "919300",
    "end": "925240"
  },
  {
    "text": "long time ago and we have moved away from that and most of our new experiments are now server-side and it is responsible for our high",
    "start": "925240",
    "end": "932120"
  },
  {
    "text": "experiment velocity so from an infrastructure point of view before we",
    "start": "932120",
    "end": "938959"
  },
  {
    "text": "wrap wrap it up I want to mention these three key takeaways again there was a",
    "start": "938959",
    "end": "946430"
  },
  {
    "text": "talk on Monday where this really good talk where we talked about sink what is a sink and that's a trade-off we make",
    "start": "946430",
    "end": "953089"
  },
  {
    "text": "all the time and for distributed systems we should always rely on asynchronously",
    "start": "953089",
    "end": "959810"
  },
  {
    "text": "a synchronicity is your friend try to make sure that you have as minimal synchronous operations as possible",
    "start": "959810",
    "end": "965060"
  },
  {
    "text": "because it's very hard to scale things up so in our notifications infrastructure",
    "start": "965060",
    "end": "972440"
  },
  {
    "text": "we rely on very few synchronous operations and wherever possible we try to move away from them similarly we make",
    "start": "972440",
    "end": "979399"
  },
  {
    "text": "trade-offs between write and read path and the idea there is you need to be cognizant of what you are doing at right",
    "start": "979399",
    "end": "986720"
  },
  {
    "text": "time there are certain things you can do in right time but you shouldn't for",
    "start": "986720",
    "end": "991730"
  },
  {
    "text": "instance when we cache stuff we only cache our IDs we do not cache data for",
    "start": "991730",
    "end": "997550"
  },
  {
    "text": "them because we want to do that at the real time so that we give you the most up-to-date information similarly on the",
    "start": "997550",
    "end": "1004209"
  },
  {
    "text": "flip side when we show you an aggregated time line most of the aggregation happens at read time there is no point",
    "start": "1004209",
    "end": "1010959"
  },
  {
    "text": "doing it at write time and then we talked about multi DC but and this stain",
    "start": "1010959",
    "end": "1017920"
  },
  {
    "text": "is you need to be very even if you starting off of an app with just one",
    "start": "1017920",
    "end": "1023199"
  },
  {
    "text": "data center make sure that you are aware of how you would scale it up to or how you would evolve it to have multiple",
    "start": "1023199",
    "end": "1028510"
  },
  {
    "text": "data centers now let's go over the",
    "start": "1028510",
    "end": "1035500"
  },
  {
    "start": "1030000",
    "end": "1112000"
  },
  {
    "text": "evolution of Twitter notifications so we started off with this category of",
    "start": "1035500",
    "end": "1041168"
  },
  {
    "text": "notifications which are by far the highest volume they're called triggered notifications as you can imagine they",
    "start": "1041169",
    "end": "1046449"
  },
  {
    "text": "are triggered by an interaction on Twitter so for instance if I were to",
    "start": "1046449",
    "end": "1051820"
  },
  {
    "text": "tweet and if you were to reply or like it will generate a like notification or",
    "start": "1051820",
    "end": "1056980"
  },
  {
    "text": "reply notification so again these are the highest volume notifications by far as I mentioned we generate",
    "start": "1056980",
    "end": "1063400"
  },
  {
    "text": "billions of them every day we need to make sure that not only we do that but",
    "start": "1063400",
    "end": "1068920"
  },
  {
    "text": "we can handle spikes and I thought about by modality in the beginning but trigger",
    "start": "1068920",
    "end": "1075940"
  },
  {
    "text": "notifications are highly bimodal a small minority of user receive majority of",
    "start": "1075940",
    "end": "1082210"
  },
  {
    "text": "these notifications a quick example of",
    "start": "1082210",
    "end": "1088420"
  },
  {
    "text": "how they flow in our system someone tweets goes through a right pass and",
    "start": "1088420",
    "end": "1094690"
  },
  {
    "text": "then there we apply all our business rules and logic and then once it passes",
    "start": "1094690",
    "end": "1100090"
  },
  {
    "text": "that it sport document onto two different paths one path is real-time it leads to your device with a push and",
    "start": "1100090",
    "end": "1107470"
  },
  {
    "text": "other path is where it's stored and then served out of cache so why why do we",
    "start": "1107470",
    "end": "1115809"
  },
  {
    "text": "need personalization why I triggered notification is not enough the reason",
    "start": "1115809",
    "end": "1121300"
  },
  {
    "text": "they are not enough is there is a lot more happening on Twitter both outside",
    "start": "1121300",
    "end": "1126610"
  },
  {
    "text": "your graphs and within your graph that triggered notifications do not cover they cover a subset of those use cases",
    "start": "1126610",
    "end": "1131890"
  },
  {
    "text": "but they are not enough for instance if I'm a left-hander warriors fan and I",
    "start": "1131890",
    "end": "1137140"
  },
  {
    "text": "follow follow warriors account and then there is some controversy during a game",
    "start": "1137140",
    "end": "1142270"
  },
  {
    "text": "and if warriors account doesn't tweet it I would never know about it but if",
    "start": "1142270",
    "end": "1147610"
  },
  {
    "text": "couldn't knows that I'm interested in Valle yes they could notify me in real time with a upcoming trend and whatnot",
    "start": "1147610",
    "end": "1154380"
  },
  {
    "text": "as I mentioned in the beginning we notify users about what's happening in their world in real time we cover",
    "start": "1154380",
    "end": "1160380"
  },
  {
    "text": "trigger notifications cover the real time part of it but there's lot more",
    "start": "1160380",
    "end": "1166929"
  },
  {
    "text": "that we do with personalization that Gary will talk about so I'll hand it over to him Thank You syrup so this is",
    "start": "1166929",
    "end": "1179440"
  },
  {
    "text": "where I'm going to talk about personalization personalization comes down to notifying our users about their",
    "start": "1179440",
    "end": "1185710"
  },
  {
    "text": "interest you only want to hear about things you're interested in and there's",
    "start": "1185710",
    "end": "1191140"
  },
  {
    "text": "two ways we do personalization at Twitter the first we call personalized Vento previously we",
    "start": "1191140",
    "end": "1199520"
  },
  {
    "text": "talked about fan-out when Elon Musk's tweets we have to send it to all the followers that have subscribed to them",
    "start": "1199520",
    "end": "1204820"
  },
  {
    "text": "but Elon Musk tweets about space because he's the CEO of SpaceX and also tweets",
    "start": "1204820",
    "end": "1210080"
  },
  {
    "text": "about electric cars because he's CEO of Tesla you might not be interested in",
    "start": "1210080",
    "end": "1215090"
  },
  {
    "text": "space but you might be interested in that your cars so we only want to notify you when Neil almost tweets about",
    "start": "1215090",
    "end": "1220250"
  },
  {
    "text": "electric cars and this is what personalized spinel does I'm going to",
    "start": "1220250",
    "end": "1226549"
  },
  {
    "text": "walk you through the personalized fan-out algorithm so we mentioned we to",
    "start": "1226549",
    "end": "1231650"
  },
  {
    "text": "keep track of a user's interest we all want to notify you about your interest so we keep track of your recent",
    "start": "1231650",
    "end": "1237290"
  },
  {
    "text": "engagements on entities let's break this down engagements are like tweet replies",
    "start": "1237290",
    "end": "1243679"
  },
  {
    "text": "when you tweet about a particular topic we call that an engagement or where you like somebody else's tweet we we bunched",
    "start": "1243679",
    "end": "1251210"
  },
  {
    "text": "this up into something we call engagements entities these are hashtags",
    "start": "1251210",
    "end": "1256880"
  },
  {
    "text": "accounts or can be something more abstract like a particular topic it could be movie sports so we keep track",
    "start": "1256880",
    "end": "1264020"
  },
  {
    "text": "of your engagement on these things we call entities to make this more concrete for me for example I'm currently in",
    "start": "1264020",
    "end": "1271910"
  },
  {
    "text": "London so I've tweeted about hashtag London and this is being Q Khan I want to keep up",
    "start": "1271910",
    "end": "1277490"
  },
  {
    "text": "with everybody's great talks as in favoriting and liking and retweeting all of your tweets about Q Khan so I have",
    "start": "1277490",
    "end": "1283280"
  },
  {
    "text": "recently engaged with London and Q Khan so those are my recent engagements so we",
    "start": "1283280",
    "end": "1291500"
  },
  {
    "text": "keep track of these engagements as a proxy to what your interests are and we only keep track of your recent",
    "start": "1291500",
    "end": "1296750"
  },
  {
    "text": "engagements because Twitter is constantly changing the data on Twitter what people are talking about on Twitter",
    "start": "1296750",
    "end": "1302270"
  },
  {
    "text": "are constantly changing as well as your interest you maybe haven't been interested in the Super Bowl or the",
    "start": "1302270",
    "end": "1308090"
  },
  {
    "text": "Oscars a month or two months ago you're not so interested in that right now so when we keep track of your most recent",
    "start": "1308090",
    "end": "1314210"
  },
  {
    "text": "engagements the second part to",
    "start": "1314210",
    "end": "1319460"
  },
  {
    "text": "personalize find out is your followings so when we mean followings my followings",
    "start": "1319460",
    "end": "1325640"
  },
  {
    "text": "are the users I follow you follow a lot of people on Twitter",
    "start": "1325640",
    "end": "1331820"
  },
  {
    "text": "but not every single person you follow means the same to you there are some",
    "start": "1331820",
    "end": "1337290"
  },
  {
    "text": "people that you really want to hear from and there are others that you might not want to hear from them so much so for",
    "start": "1337290",
    "end": "1344490"
  },
  {
    "text": "every user we want to keep track of who are the very very top followings who are the people that they really really want",
    "start": "1344490",
    "end": "1350850"
  },
  {
    "text": "to hear hear about so for me for example I'm a Twitter employee so Twitter is one",
    "start": "1350850",
    "end": "1357000"
  },
  {
    "text": "of my top followings and to come London I want to hear about everybody's talks York on London tweets a lot about it so",
    "start": "1357000",
    "end": "1364080"
  },
  {
    "text": "I follow maybe hundreds of people on Twitter but in personal i span out we would only use the top view in this case",
    "start": "1364080",
    "end": "1370500"
  },
  {
    "text": "would take top two in the simplified example so to recap we have your recent",
    "start": "1370500",
    "end": "1376830"
  },
  {
    "text": "engagements on entities and we also have the top followings and I want to walk through an example of what happens when",
    "start": "1376830",
    "end": "1383490"
  },
  {
    "text": "Q columns and tweets and when personalised inal decides whether they want to send it to me or not so first",
    "start": "1383490",
    "end": "1391620"
  },
  {
    "text": "thing when you come London tweets we extract out the entities from the tweet in this case we're looking at hashtags",
    "start": "1391620",
    "end": "1397830"
  },
  {
    "text": "so hashtag London is the entity would then look whether I have recently",
    "start": "1397830",
    "end": "1403470"
  },
  {
    "text": "engaged on hashtag London which I have because I'm at UConn in London and then",
    "start": "1403470",
    "end": "1410340"
  },
  {
    "text": "we look at the author of the tweet and whether the author is in my top end followings so then we decide hey we'll",
    "start": "1410340",
    "end": "1417450"
  },
  {
    "text": "send this to Khan tweet to lamb Gary and the reason this is the hard problem like",
    "start": "1417450",
    "end": "1424830"
  },
  {
    "text": "a lot of problems that Twitter is because there's asymmetric if you look at Katy Perry she has millions millions",
    "start": "1424830",
    "end": "1430200"
  },
  {
    "text": "of followers to make it clear what we're not doing is looking at Katy Perry and sending it to her top 20 followers",
    "start": "1430200",
    "end": "1436140"
  },
  {
    "text": "because then there will be a huge fight to become the top 20 years of 2025 okay Perry and we upset a lot of people what",
    "start": "1436140",
    "end": "1443280"
  },
  {
    "text": "we're doing is we're taking everybody that follows Katy Perry and seeing if Katy Perry is in one of the top",
    "start": "1443280",
    "end": "1449040"
  },
  {
    "text": "followings so you compare Katy Perry to someone slightly less popular like me I",
    "start": "1449040",
    "end": "1454650"
  },
  {
    "text": "might only have one or two people who are in my talk who want to hear from me",
    "start": "1454650",
    "end": "1462740"
  },
  {
    "text": "so how do we solve this so we solve this by colocation and no network lookups",
    "start": "1464640",
    "end": "1471010"
  },
  {
    "text": "okay what does let's deep dive into this what we do is we shard by every user so each",
    "start": "1471010",
    "end": "1477970"
  },
  {
    "text": "user belongs to a particular shard I would be longing to say chars one star would be long into short too and on each",
    "start": "1477970",
    "end": "1486100"
  },
  {
    "text": "one of these charts for every user we keep track of the top engage their recent engagement and the top followings",
    "start": "1486100",
    "end": "1493000"
  },
  {
    "text": "and they're all on the same chart what this means is when we want run the personalized standout algorithm we don't",
    "start": "1493000",
    "end": "1499390"
  },
  {
    "text": "have to do Network lookups to other services everything's done locally so we don't incur any latency by hitting other",
    "start": "1499390",
    "end": "1505780"
  },
  {
    "text": "external services they also scales well because we've charted the recent",
    "start": "1505780",
    "end": "1511840"
  },
  {
    "text": "engagements and charted your followings so we can scale horizontally that way and Pokeno here is all of these charts",
    "start": "1511840",
    "end": "1519970"
  },
  {
    "text": "listen to the same copy of the firehose so each one of these are running their personalized final algorithm on the",
    "start": "1519970",
    "end": "1526390"
  },
  {
    "text": "users that belong to that shard so let's walk through an example of what",
    "start": "1526390",
    "end": "1533230"
  },
  {
    "text": "happens when Katy Perry actually tweets so Katy Perry three skitty here I lost the bet for best picture I wanted",
    "start": "1533230",
    "end": "1538570"
  },
  {
    "text": "glowing light so this was tweeted during the Oscars if a lot of you might know",
    "start": "1538570",
    "end": "1543940"
  },
  {
    "text": "during the Oscars they announced that la-la-land won best picture and then they kind of they made a mistake there and then they",
    "start": "1543940",
    "end": "1550240"
  },
  {
    "text": "announced that moonlight 1 so this Katy Perry tweeted this out before the fix the mistake but back to this problem",
    "start": "1550240",
    "end": "1557020"
  },
  {
    "text": "what we have supposing you live in a world where you have two sharks you have sharp one and you have shark tooth and",
    "start": "1557020",
    "end": "1562770"
  },
  {
    "text": "we're going to look at two of Katy Perry's followers Buller a and follower be so far where a is not short one and",
    "start": "1562770",
    "end": "1569620"
  },
  {
    "text": "on short one we keep track of follower a engagements in this case spoiler a has",
    "start": "1569620",
    "end": "1574900"
  },
  {
    "text": "engaged with a lowland and Katy Perry is one of the top followings on shore to",
    "start": "1574900",
    "end": "1580510"
  },
  {
    "text": "follower B is a fan of moonlight and they've also follow Katy Perry's lemon cell followings so what happens in",
    "start": "1580510",
    "end": "1588040"
  },
  {
    "text": "personalized fan out is again the first thing we do extract those entities from the tweet",
    "start": "1588040",
    "end": "1593110"
  },
  {
    "text": "in this case the entity is moonlights a movie we then send that tweet to every single personalized standout chart so",
    "start": "1593110",
    "end": "1599560"
  },
  {
    "text": "all of these charts get it and they run the algorithm and as I mentioned before",
    "start": "1599560",
    "end": "1604750"
  },
  {
    "text": "we look at the engagement only follower B has engaged buffoon like so we'd only send this the follower be and not",
    "start": "1604750",
    "end": "1611050"
  },
  {
    "text": "follower a so in this way we're able to notify you about people you care about",
    "start": "1611050",
    "end": "1617470"
  },
  {
    "text": "and only about the interest that you care about so we talked about why we",
    "start": "1617470",
    "end": "1627850"
  },
  {
    "start": "1624000",
    "end": "1987000"
  },
  {
    "text": "need to co-locate our data I'm going to deep that now more into how we make this efficient and the key is data",
    "start": "1627850",
    "end": "1634120"
  },
  {
    "text": "pre-processing I'm going to go a bit backwards on this slide I'm going to go",
    "start": "1634120",
    "end": "1639520"
  },
  {
    "text": "from your right down to the left so first off the recent agents are entities",
    "start": "1639520",
    "end": "1645160"
  },
  {
    "text": "we store that in memory the reason we store in memory is your recent agents are short-lived as I mentioned before we",
    "start": "1645160",
    "end": "1652090"
  },
  {
    "text": "keep you're not interested in something from two months ago so we keep maybe a",
    "start": "1652090",
    "end": "1657760"
  },
  {
    "text": "couple of hours up to a day's worth of your recent engagements in memory which",
    "start": "1657760",
    "end": "1662800"
  },
  {
    "text": "is good we don't persist it as any for anywhere else because it's not useful anymore after day or two this data isn't really",
    "start": "1662800",
    "end": "1669370"
  },
  {
    "text": "going to be useful but the problem comes when your shard goes down we work out of",
    "start": "1669370",
    "end": "1676660"
  },
  {
    "text": "a data center there's maintenance jobs things go down all the time all of you are probably aware of this and when you",
    "start": "1676660",
    "end": "1683320"
  },
  {
    "text": "go down then you lose your in memory recent engagements at this point we can't just go oh sorry we're not going",
    "start": "1683320",
    "end": "1688480"
  },
  {
    "text": "to send you notifications right because all the Katy Perry fans will get really angry so what we do is we need to make",
    "start": "1688480",
    "end": "1694930"
  },
  {
    "text": "sure these personalized Dino shards come up very very quickly and the way we do",
    "start": "1694930",
    "end": "1700030"
  },
  {
    "text": "it is we read from a Q this Q has the last say 24 hours of recent engagements",
    "start": "1700030",
    "end": "1706720"
  },
  {
    "text": "and on startup we've consumed from this Q very quickly to rebuild this in-memory engagement graph and there are two",
    "start": "1706720",
    "end": "1715900"
  },
  {
    "text": "things that we do to make this efficient the first is batching by batching your engagements together you reduce the",
    "start": "1715900",
    "end": "1722740"
  },
  {
    "text": "message overhead and this typically gives us a huge speed-up the second thing we do is if you ever",
    "start": "1722740",
    "end": "1728630"
  },
  {
    "text": "use the fire hose and you looked at the Twitter JSON data it contains a lot of metadata so it has things like what",
    "start": "1728630",
    "end": "1734600"
  },
  {
    "text": "clients the user used what the iOS is Android which countries perhaps they",
    "start": "1734600",
    "end": "1739850"
  },
  {
    "text": "tweeted from what time of day the actual tweet pecks there's all this metadata in there that aren't relevant for personal",
    "start": "1739850",
    "end": "1746960"
  },
  {
    "text": "life I know so we extract only the key pieces of metadata for example maybe just a user",
    "start": "1746960",
    "end": "1752270"
  },
  {
    "text": "ID and the tweet ID that they've engaged with so with that's why we call it a slim firehose and its batched so in this",
    "start": "1752270",
    "end": "1759289"
  },
  {
    "text": "way we're able to launch personalized I know shards in a matter of minutes if they ever go down and the other good",
    "start": "1759289",
    "end": "1767210"
  },
  {
    "text": "thing about this is the entity extraction so figuring out on the tweet which movies or hashtags",
    "start": "1767210",
    "end": "1772640"
  },
  {
    "text": "it is sometimes can be quite an expensive process and we do this into the slim engagement service what this",
    "start": "1772640",
    "end": "1779570"
  },
  {
    "text": "means is we do the entity extraction once and then we send that result to all the personal personal life span out",
    "start": "1779570",
    "end": "1786350"
  },
  {
    "text": "shards which means we save on that computation and you can put some more expensive computations in the entity",
    "start": "1786350",
    "end": "1792020"
  },
  {
    "text": "extraction so this is recent engagements the next is how do we preset process the",
    "start": "1792020",
    "end": "1799820"
  },
  {
    "text": "top followings so to find the top followings for every user we run an",
    "start": "1799820",
    "end": "1805250"
  },
  {
    "text": "offline machine learning algorithm and this is based off your historical interaction between the two users for",
    "start": "1805250",
    "end": "1811970"
  },
  {
    "text": "example whether you're likely to like that person's tweet whether you have similar friends follow similar people on",
    "start": "1811970",
    "end": "1817640"
  },
  {
    "text": "Twitter we calculates this offline because you're your friends and your top",
    "start": "1817640",
    "end": "1824240"
  },
  {
    "text": "followings don't change that often friendships are built over months and years even in this modern age so running",
    "start": "1824240",
    "end": "1832159"
  },
  {
    "text": "an offline allows us to make it reliable and scale correctly and after we've",
    "start": "1832159",
    "end": "1837980"
  },
  {
    "text": "calculated the top end followings for every single user we partition it and we partition it in the same way that we",
    "start": "1837980",
    "end": "1844309"
  },
  {
    "text": "partition our production record service charts so if we have n rec service",
    "start": "1844309",
    "end": "1850070"
  },
  {
    "text": "shards rent personalised I know shards sorry that service is what we call it internally personalized final shards",
    "start": "1850070",
    "end": "1857730"
  },
  {
    "text": "we would have n partitions on HDFS and we pre pre partition this so when we",
    "start": "1857730",
    "end": "1863440"
  },
  {
    "text": "bring up a shard supposing we bring up char three it just copies that piece of data from H DSS on to its local disk and",
    "start": "1863440",
    "end": "1872040"
  },
  {
    "text": "after we've copied it to local disk we don't actually load it into memory immediately this is because your",
    "start": "1872040",
    "end": "1878290"
  },
  {
    "text": "followings graph is typically pretty large you don't want to waste all that memory on something that is so large so",
    "start": "1878290",
    "end": "1884590"
  },
  {
    "text": "what we do is we lazily load it into memory as its required so in this way the recent engagements as we bring up",
    "start": "1884590",
    "end": "1891520"
  },
  {
    "text": "the shard we process back from akhil built it up very quickly the top end falling we simply copy from HDFS on to",
    "start": "1891520",
    "end": "1898560"
  },
  {
    "text": "the local disk of that shard so the key",
    "start": "1898560",
    "end": "1906310"
  },
  {
    "text": "takeaways for personalized fan-out is co-locate your data once you've co-located your data you no longer have",
    "start": "1906310",
    "end": "1911560"
  },
  {
    "text": "external Network lookups you can scale horizontally that way but in order to do this efficiently you really need to rely",
    "start": "1911560",
    "end": "1918280"
  },
  {
    "text": "on data pre-processing preprocessor engagements make sure that sufficient to process your followings graph so you",
    "start": "1918280",
    "end": "1923740"
  },
  {
    "text": "partition your correctly but the third key takeaway here is real-time",
    "start": "1923740",
    "end": "1929350"
  },
  {
    "text": "personalization is actually very expensive we have to do a lot of pre-processing to make sure this all",
    "start": "1929350",
    "end": "1935470"
  },
  {
    "text": "works efficiently this impacts our iteration speed if someone has a new",
    "start": "1935470",
    "end": "1941080"
  },
  {
    "text": "idea they have to write the group they have to write a preprocessor pipeline pre process this data before they can",
    "start": "1941080",
    "end": "1947020"
  },
  {
    "text": "experiment with that and the other thing that makes real-time personalization",
    "start": "1947020",
    "end": "1953290"
  },
  {
    "text": "so expensive is we're listening to the firehose things are spiky on Twitter we've talked about that a lot if you",
    "start": "1953290",
    "end": "1959470"
  },
  {
    "text": "look at Hillary Clinton her when she got nominated for dozen product as a Democratic nominee her mentions and",
    "start": "1959470",
    "end": "1966580"
  },
  {
    "text": "people were interested in it spiked many many different times many times the average volume so in order for",
    "start": "1966580",
    "end": "1973480"
  },
  {
    "text": "personalized fan-out to scale to this volume we need to over allocate on capacity to make sure we handle this and",
    "start": "1973480",
    "end": "1979980"
  },
  {
    "text": "because this is very unpredictable we waste a lot of resources by having to over allocate",
    "start": "1979980",
    "end": "1987720"
  },
  {
    "start": "1987000",
    "end": "2424000"
  },
  {
    "text": "so this brings us to our second way of doing personalization which is",
    "start": "1991710",
    "end": "1997210"
  },
  {
    "text": "recommendations in personalized I know",
    "start": "1997210",
    "end": "2002640"
  },
  {
    "text": "what we saw was we send you the best content from the people you follow but sorry I've mentioned earlier your",
    "start": "2002640",
    "end": "2009450"
  },
  {
    "text": "there's content on Twitter that you don't explicitly follow that will be interesting to you there are a few examples on that slide on that slide",
    "start": "2009450",
    "end": "2016260"
  },
  {
    "text": "over there but what we're trying to do is look at your interest look at your",
    "start": "2016260",
    "end": "2022410"
  },
  {
    "text": "followers and friends look at what they're interested in and try to recommend you good content for example",
    "start": "2022410",
    "end": "2027420"
  },
  {
    "text": "if I didn't know about Q Khan but three or four of my colleagues came to Q Khan tweeted a lot about it",
    "start": "2027420",
    "end": "2033180"
  },
  {
    "text": "maybe you're interested in Q Khan too so the goal here is to find content you love even though you don't especially",
    "start": "2033180",
    "end": "2039120"
  },
  {
    "text": "follow it and the reason why we have a",
    "start": "2039120",
    "end": "2046230"
  },
  {
    "text": "second way of doing personalization is because it's scaled a lot better and in this recommendations world what we're",
    "start": "2046230",
    "end": "2052050"
  },
  {
    "text": "going to do is relax the real-time constraint what we're going to do is not read from the firehose but instead",
    "start": "2052050",
    "end": "2057750"
  },
  {
    "text": "control the own load by ourself what does this mean so we have a very tight",
    "start": "2057750",
    "end": "2068010"
  },
  {
    "text": "loop and in this loop we actually go go over every single user on Twitter the",
    "start": "2068010",
    "end": "2074730"
  },
  {
    "text": "number of users on Twitter is much more predictable than the number of events or tweets so in this way we're able to",
    "start": "2074730",
    "end": "2080730"
  },
  {
    "text": "predict our capacity much better and by controlling the load ourselves this allows us to scale and be much more",
    "start": "2080730",
    "end": "2086669"
  },
  {
    "text": "efficient with our resources but again as identified what we're sacrificing is latency as you've been tapping our",
    "start": "2086670",
    "end": "2093120"
  },
  {
    "text": "Twitter no longer are we sending out to you in a matter of seconds but there might be a delay of a couple of minutes",
    "start": "2093120",
    "end": "2099540"
  },
  {
    "text": "because we're looping over every single user at Twitter and what loop service",
    "start": "2099540",
    "end": "2105120"
  },
  {
    "text": "does is it triggers another component called fatigue fetch and rank so fatigue veteran rank is another service that I'm",
    "start": "2105120",
    "end": "2111720"
  },
  {
    "text": "going to walk everyone through right now first off fatigue in this stage we're",
    "start": "2111720",
    "end": "2118140"
  },
  {
    "text": "able to figure out where the user lives on that bimodal distribution that we talked about are there someone that receives a lot of",
    "start": "2118140",
    "end": "2124530"
  },
  {
    "text": "notifications in which case we don't want to send them anymore nor are they someone that who could do with more",
    "start": "2124530",
    "end": "2130440"
  },
  {
    "text": "recommendations to help them get the most value out of Twitter and we have what we call a history store we keep",
    "start": "2130440",
    "end": "2136950"
  },
  {
    "text": "track of your historical open rate for notifications whether you like these notifications whether you engage with",
    "start": "2136950",
    "end": "2142530"
  },
  {
    "text": "them so we we know whether you want notifications or not and this works well for both the user because they don't get",
    "start": "2142530",
    "end": "2149250"
  },
  {
    "text": "notified if they don't like notifications and it's also good for us because we don't waste computation capacity calculating and doing things",
    "start": "2149250",
    "end": "2156300"
  },
  {
    "text": "for users who aren't going to see it in the end once we pass the fatigue stage",
    "start": "2156300",
    "end": "2163380"
  },
  {
    "text": "we know at this point we're likely wanting to send a notification to the user in this fetch stage what we do is",
    "start": "2163380",
    "end": "2170250"
  },
  {
    "text": "we look up many many different candidate sources so a candidate source is the",
    "start": "2170250",
    "end": "2175740"
  },
  {
    "text": "interface that we defined and it's very simple that the user ID is as a key and the value that returns from it is just a",
    "start": "2175740",
    "end": "2182700"
  },
  {
    "text": "list of possible notifications that may be relevant to that user so in this batch stage we fetch from",
    "start": "2182700",
    "end": "2190109"
  },
  {
    "text": "many different content sources so we're more likely to find something that's relevant to the user we would have a",
    "start": "2190109",
    "end": "2196380"
  },
  {
    "text": "separate content source for each type of content we would recommend for example we would have one for hashtags we would",
    "start": "2196380",
    "end": "2202380"
  },
  {
    "text": "have one for photos we would have one for follower recommendations and at the other good",
    "start": "2202380",
    "end": "2211680"
  },
  {
    "text": "thing about this is if a person has a new idea and wants to experiment with the new candidate source for example",
    "start": "2211680",
    "end": "2217710"
  },
  {
    "text": "maybe they just want to recommend good technical presentations they could create a new candidate source for that",
    "start": "2217710",
    "end": "2223440"
  },
  {
    "text": "and plug it into a pipeline very seamlessly no longer do they have to do a lot of pre-processing and all of this",
    "start": "2223440",
    "end": "2229460"
  },
  {
    "text": "data group logic that's inflexible like we saw in personalized I know and",
    "start": "2229460",
    "end": "2235970"
  },
  {
    "text": "typically these candidate sources can be backed by other services a typical one we use that Twitter is grass yet so",
    "start": "2235970",
    "end": "2242700"
  },
  {
    "text": "grass yet is a real-time graph processing library that we've open-sourced a Twitter check it out on",
    "start": "2242700",
    "end": "2248400"
  },
  {
    "text": "github is that essentially what it does it looks at your followers and look the tweets of your followers and is of",
    "start": "2248400",
    "end": "2254450"
  },
  {
    "text": "the random walk across these to find the best content for you not only can we",
    "start": "2254450",
    "end": "2260810"
  },
  {
    "text": "back canada sources with other services they can also be generated offline so we have scouting which is our offline",
    "start": "2260810",
    "end": "2267980"
  },
  {
    "text": "MapReduce pipeline framework that we use our Twitter to generate this data and we can store that in Manhattan and we can",
    "start": "2267980",
    "end": "2274640"
  },
  {
    "text": "then load that out from a data set so these candidate source is super flexible and they're easy to plug in into the",
    "start": "2274640",
    "end": "2280910"
  },
  {
    "text": "fetch stage once we fetch all the candidates we're going to rank them with",
    "start": "2280910",
    "end": "2287540"
  },
  {
    "text": "a machine learn model if we have 100 candidates we're not going to send all hundred to the user that would be",
    "start": "2287540",
    "end": "2292550"
  },
  {
    "text": "impractical and the user will just be overwhelmed so we choose the best one to send to it and we bait do this based off",
    "start": "2292550",
    "end": "2299810"
  },
  {
    "text": "your historical engagement whether you like photos more whether you're like hashtags more and we also look at the",
    "start": "2299810",
    "end": "2305210"
  },
  {
    "text": "social proof for example if six of your friends have liked a particular photo versus another photo that only two of",
    "start": "2305210",
    "end": "2310400"
  },
  {
    "text": "your friends have liked we're more likely to recommend the one with six that six of your friends have liked and",
    "start": "2310400",
    "end": "2317500"
  },
  {
    "text": "once we figured out the best notifications to send we send this out to our throw notification infrastructure",
    "start": "2317500",
    "end": "2323240"
  },
  {
    "text": "so this is what's our talked about where we do the notification timeline and then push notification I want to go one level",
    "start": "2323240",
    "end": "2332630"
  },
  {
    "text": "deeper we mentioned our machine learning model Twitter is a data and experimentation driven company so we",
    "start": "2332630",
    "end": "2338000"
  },
  {
    "text": "need to collect data and data is really what drives our machine learning models so each one of our services we log our",
    "start": "2338000",
    "end": "2344570"
  },
  {
    "text": "information back to HDFS for example in defects in the rank stage we would log",
    "start": "2344570",
    "end": "2350540"
  },
  {
    "text": "perhaps the score that the machine learning model gave all the candidates and say that HDFS",
    "start": "2350540",
    "end": "2355630"
  },
  {
    "text": "we also instrument all of our clients so when you open the new location or",
    "start": "2355630",
    "end": "2360710"
  },
  {
    "text": "whether you give us an explicit signal that you don't like notifications we have this information on HDFS as well",
    "start": "2360710",
    "end": "2367030"
  },
  {
    "text": "what we do we turn these into machine learning features and labels they feed in not only to notifications but",
    "start": "2367030",
    "end": "2373040"
  },
  {
    "text": "potentially into your rank timeline your ranking timeline as well and then we generate a new machine learning model",
    "start": "2373040",
    "end": "2379220"
  },
  {
    "text": "off of this new collected data so in this aspect as Twitter is constantly changing we're adapting our models",
    "start": "2379220",
    "end": "2386540"
  },
  {
    "text": "to reflect that so buy this in the in this way we're able to deliver you relevant recommendations so to sum up",
    "start": "2386540",
    "end": "2396140"
  },
  {
    "text": "the recommendation section we relaxed our real time constraint and we took control of our load we can predict our",
    "start": "2396140",
    "end": "2402050"
  },
  {
    "text": "load because we're not subject to the spiky nature of the firehose anymore this is really more personalized because",
    "start": "2402050",
    "end": "2408920"
  },
  {
    "text": "we have a diverse set of content sources we're looking at many different content sources compared to personalise panel so",
    "start": "2408920",
    "end": "2414620"
  },
  {
    "text": "you're more likely to find something that relevant to the user we run that through a machine learn model and to",
    "start": "2414620",
    "end": "2420140"
  },
  {
    "text": "parity you really need data I want to",
    "start": "2420140",
    "end": "2426680"
  },
  {
    "start": "2424000",
    "end": "2510000"
  },
  {
    "text": "bring everything together we talked about today so at the beginning we",
    "start": "2426680",
    "end": "2432470"
  },
  {
    "text": "talked about our notifications infrastructure this was our scalable infrastructure that powers the notifications timeline and allows us to",
    "start": "2432470",
    "end": "2438800"
  },
  {
    "text": "send push email and SMS to our users and then what we walk you through is",
    "start": "2438800",
    "end": "2444290"
  },
  {
    "text": "actually a sliding scale of three systems from the real-time to the personalized so in the real-time world",
    "start": "2444290",
    "end": "2452390"
  },
  {
    "text": "we showed you trigger notifications these are based off your interaction where users have an expectation of",
    "start": "2452390",
    "end": "2457910"
  },
  {
    "text": "delivery and we send these out in real time then we talked about personalized I",
    "start": "2457910",
    "end": "2463610"
  },
  {
    "text": "know you might not want to you want to be notified with all your interest from people you follow we saw here we're able",
    "start": "2463610",
    "end": "2470840"
  },
  {
    "text": "to do real-time personalization but it comes on the cost of in flexibility and very expensive capacity and then we move",
    "start": "2470840",
    "end": "2480140"
  },
  {
    "text": "to a world where we're in recommendations where we're extremely personalized where we can deliver extremely relevant notifications to the",
    "start": "2480140",
    "end": "2486110"
  },
  {
    "text": "user but we have to sacrifice on the latency so the key takeaway I want",
    "start": "2486110",
    "end": "2492200"
  },
  {
    "text": "everyone to walk away with today as you're building out the new architecture think about where your product or where",
    "start": "2492200",
    "end": "2498080"
  },
  {
    "text": "your use case lies from the real time for the personalised world you have to use it there's a trade-off between all",
    "start": "2498080",
    "end": "2503960"
  },
  {
    "text": "of them and hopefully what we show you today will you to make a better better informed decision about that so thank",
    "start": "2503960",
    "end": "2511610"
  },
  {
    "start": "2510000",
    "end": "2991000"
  },
  {
    "text": "you very much for listening follow up on Twitter and I guess we'll open up for",
    "start": "2511610",
    "end": "2516920"
  },
  {
    "text": "Q&A right now [Applause]",
    "start": "2516920",
    "end": "2527949"
  },
  {
    "text": "- Cindy hi thanks for the talk what",
    "start": "2528400",
    "end": "2539930"
  },
  {
    "text": "programming languages you use for this stuff so we are predominantly a SCADA",
    "start": "2539930",
    "end": "2545900"
  },
  {
    "text": "household of the back end and financials in the u.s. color yeah thank you for the",
    "start": "2545900",
    "end": "2555290"
  },
  {
    "text": "presentation and I actually work on a news recommendation infrastructure and I",
    "start": "2555290",
    "end": "2560600"
  },
  {
    "text": "was interested in terms of the candidate sources to say you have a candidate",
    "start": "2560600",
    "end": "2565730"
  },
  {
    "text": "source that does collaborative filtering for you and then you have your we ranking step where you integrate all the",
    "start": "2565730",
    "end": "2572300"
  },
  {
    "text": "sources yeah so do you pass along and features from your candidate sources so",
    "start": "2572300",
    "end": "2579350"
  },
  {
    "text": "you make sure that maybe you have a very interesting answers but it's being run very low because you don't have proper",
    "start": "2579350",
    "end": "2587240"
  },
  {
    "text": "representation for that your revenge instead yeah so typically we don't do",
    "start": "2587240",
    "end": "2592700"
  },
  {
    "text": "that because your candidate your features that belong to your candid sources are very specific to that candidate source and you're trying to",
    "start": "2592700",
    "end": "2598940"
  },
  {
    "text": "rank across multiple candidate sources those features won't be that helpful so you really want teachers that are common",
    "start": "2598940",
    "end": "2605480"
  },
  {
    "text": "to all of your candidate sources all",
    "start": "2605480",
    "end": "2611990"
  },
  {
    "text": "right thanks for the great talk and you mention that do you rely on the data",
    "start": "2611990",
    "end": "2617930"
  },
  {
    "text": "processor of your entities right so how hard is to do it and how hard is to define or to find your entity or not",
    "start": "2617930",
    "end": "2624680"
  },
  {
    "text": "wait sorry can you repeat that your question how hard is for you guys to define what is an entity and precise",
    "start": "2624680",
    "end": "2633110"
  },
  {
    "text": "that in order to have the right automation yeah is that so",
    "start": "2633110",
    "end": "2638270"
  },
  {
    "text": "entity is like hashtags and authors are pretty easy to expect but you can imagine nothing to an interest it's a",
    "start": "2638270",
    "end": "2644150"
  },
  {
    "text": "pretty hard problem and sort of there's a lot of people working on that Twitter the Torah is full of entities I mean",
    "start": "2644150",
    "end": "2651410"
  },
  {
    "text": "everything a user as an entity so an entity could be following another entity or hashtag is an entity or image could",
    "start": "2651410",
    "end": "2658790"
  },
  {
    "text": "be an entity or interest could be an entity so we have a taxonomy of interest",
    "start": "2658790",
    "end": "2666290"
  },
  {
    "text": "we have all of that predefined and if you were to add something it's I mean",
    "start": "2666290",
    "end": "2672230"
  },
  {
    "text": "some of these things are they don't change on a day to day to day basis like you might have different hashtags but",
    "start": "2672230",
    "end": "2677570"
  },
  {
    "text": "they're still a hash tag in a great talk a couple questions",
    "start": "2677570",
    "end": "2683090"
  },
  {
    "text": "one was see you pick a candidate source you mention hash tag for those accounts",
    "start": "2683090",
    "end": "2688730"
  },
  {
    "text": "to follow right yeah and then you pick one and then you rank the results for those and you mentioned that you don't",
    "start": "2688730",
    "end": "2695000"
  },
  {
    "text": "have features across because they're all sort of different entities and they're going to be normalized differently right",
    "start": "2695000",
    "end": "2700640"
  },
  {
    "text": "but some you know in search for example they usually just slot in and you say slot once locked in slot three and then",
    "start": "2700640",
    "end": "2707600"
  },
  {
    "text": "they pick three three three or something and they rank individually and the main so why don't you guys try slotting so",
    "start": "2707600",
    "end": "2715870"
  },
  {
    "text": "notifications tend to be more focused on the chronology so like the value you get out",
    "start": "2715870",
    "end": "2722840"
  },
  {
    "text": "of it is more about chronologically sorted reverse chronological sorted once so we don't want to just artificially",
    "start": "2722840",
    "end": "2729380"
  },
  {
    "text": "inject diversity for the sake of slotting but if something is highly relevant to you",
    "start": "2729380",
    "end": "2735170"
  },
  {
    "text": "then it'll be injected in I mean so you give up blending so for example I can't",
    "start": "2735170",
    "end": "2741200"
  },
  {
    "text": "get a blended photo plus hash tag because you're you're afraid that it's",
    "start": "2741200",
    "end": "2748490"
  },
  {
    "text": "going to mess up your ranking so blending happens in real time because if you blended it you'd have this problem",
    "start": "2748490",
    "end": "2754370"
  },
  {
    "text": "of you would go like photo hash person for the hash person but then there have",
    "start": "2754370",
    "end": "2761180"
  },
  {
    "text": "different ranking normalization so that would mess it up so that's why people do slotting right they'd say here's all the",
    "start": "2761180",
    "end": "2766340"
  },
  {
    "text": "photos and you'd have the top three photos you here's the people top three people here's the hash tag top these",
    "start": "2766340",
    "end": "2771980"
  },
  {
    "text": "hash tag and they're using different ranking algorithms and so but so we try to be that kind of way",
    "start": "2771980",
    "end": "2778100"
  },
  {
    "text": "to avoid non-normalized no absolutely that's a good point and I think we try to do a lot of personalization so we",
    "start": "2778100",
    "end": "2784339"
  },
  {
    "text": "see that if someone is not engaging with let's say people recommendations we stop sending those to them altogether so we",
    "start": "2784339",
    "end": "2790609"
  },
  {
    "text": "don't have it predefined but we do some of what you are saying but it's highly personalized since we collect all that",
    "start": "2790609",
    "end": "2797930"
  },
  {
    "text": "slightly so essentially you will try to first show them a people recognition then you get the feedback they're not doing",
    "start": "2797930",
    "end": "2803750"
  },
  {
    "text": "anything every so often you need to keep reintroducing the rights if they get interested in yep so you are sort of",
    "start": "2803750",
    "end": "2809930"
  },
  {
    "text": "doing that startup doing that but not in a fixed order yeah and we don't like notifications is",
    "start": "2809930",
    "end": "2815720"
  },
  {
    "text": "special because you don't get you can't display a full search page of notifications right you get very few",
    "start": "2815720",
    "end": "2821569"
  },
  {
    "text": "chances to send it so you do want to send the best one at that particular",
    "start": "2821569",
    "end": "2826579"
  },
  {
    "text": "point in time thank you hello here so there are like two pubs",
    "start": "2826579",
    "end": "2834829"
  },
  {
    "text": "completely different ones the whole path and one one is the push pop do you in any way somehow cooperate those two",
    "start": "2834829",
    "end": "2841730"
  },
  {
    "text": "paths because or do I care about situation when you push a notification and it isn't",
    "start": "2841730",
    "end": "2847730"
  },
  {
    "text": "yes visible on the timeline that can happen because they are completely",
    "start": "2847730",
    "end": "2854390"
  },
  {
    "text": "independent paths so you might keep it but do you even care about it we do care",
    "start": "2854390",
    "end": "2861619"
  },
  {
    "text": "about it we want to make sure that every time you get pushed and you go back to your timeline you see it in your timeline so that's the ideal experience",
    "start": "2861619",
    "end": "2868069"
  },
  {
    "text": "and that's what we strive towards but there are cases when they can be out of things but it's very rare okay but do",
    "start": "2868069",
    "end": "2874730"
  },
  {
    "text": "you somehow coordinate those two things yes yes we do so the notification right",
    "start": "2874730",
    "end": "2881359"
  },
  {
    "text": "path that we mentioned earlier it falls off on two different paths so it basically makes sure that when we send",
    "start": "2881359",
    "end": "2889069"
  },
  {
    "text": "something out for push delivery it's also stored in the cache at the time so it kind of is the gatekeeper for that",
    "start": "2889069",
    "end": "2895990"
  },
  {
    "text": "okay",
    "start": "2895990",
    "end": "2898990"
  },
  {
    "text": "hi there you mentioned multi DC can you quickly talk about some of this stuff",
    "start": "2906650",
    "end": "2912270"
  },
  {
    "text": "running in parallel and multiple DC's and these all your own infrastructure or",
    "start": "2912270",
    "end": "2917580"
  },
  {
    "text": "some of the public life as well I can take you that so on Twitter we run our",
    "start": "2917580",
    "end": "2922800"
  },
  {
    "text": "own data centers so everything is internal to Twitter and we do have to",
    "start": "2922800",
    "end": "2927900"
  },
  {
    "text": "run things in parallel because users can switch between DC's yeah so every you",
    "start": "2927900",
    "end": "2932940"
  },
  {
    "text": "have to have Mead onion you have to be able to serve from that serve your notification town I out from different DC's is everything where you the whole",
    "start": "2932940",
    "end": "2944160"
  },
  {
    "text": "population of Twitter are you running that all in parallel and every DC or are you sharted across BC similar we would",
    "start": "2944160",
    "end": "2951570"
  },
  {
    "text": "you would have to have enough redundancy to make sure that you are resilient enough yeah so your event might arrive",
    "start": "2951570",
    "end": "2960450"
  },
  {
    "text": "in one vc but then get replicated on to the other one but we do have the duplication",
    "start": "2960450",
    "end": "2966740"
  },
  {
    "text": "you're talking about the labeled data other if you can go back but so as",
    "start": "2975290",
    "end": "2980460"
  },
  {
    "text": "people interact with your phone you're getting sort of feedback so you can determine so so that feedback is - we",
    "start": "2980460",
    "end": "2987840"
  },
  {
    "text": "want is to determine if they're interacting with a candidate source what else how else are using it and they're",
    "start": "2987840",
    "end": "2993780"
  },
  {
    "start": "2991000",
    "end": "3056000"
  },
  {
    "text": "using a building global model so let's say a bunch of people click on the move like thing now that should increase the",
    "start": "2993780",
    "end": "3000230"
  },
  {
    "text": "relevance globally right are you using that to feed a global model that will",
    "start": "3000230",
    "end": "3006980"
  },
  {
    "text": "feed into the personalised models for anybody so I mean there's many models running at the same time like we have a",
    "start": "3006980",
    "end": "3012950"
  },
  {
    "text": "model for the top-end followings that would use some of these features the rank for this specific slide on the rank",
    "start": "3012950",
    "end": "3019730"
  },
  {
    "text": "it's a global ranking across different candidate sources so we usually for candidate source ranking yeah so we",
    "start": "3019730",
    "end": "3026090"
  },
  {
    "text": "gather all the candidates so if you have a hundred candidates some of them might be hashed as some of the might be photos and you kind of need to decide what we",
    "start": "3026090",
    "end": "3033320"
  },
  {
    "text": "want a hashtag or a photo recommendation okay okay",
    "start": "3033320",
    "end": "3039700"
  },
  {
    "text": "thanks everyone thank you we'll have to end this here as we continue this track",
    "start": "3041560",
    "end": "3046940"
  },
  {
    "text": "in this room 11:50 and if you have any questions feel free to ping us and we can talk offline",
    "start": "3046940",
    "end": "3053630"
  },
  {
    "text": "[Applause]",
    "start": "3053630",
    "end": "3057748"
  }
]
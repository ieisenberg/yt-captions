[
  {
    "text": "[Music]",
    "start": "3270",
    "end": "8730"
  },
  {
    "text": "thank you no no pressure to be cool and exciting when in internally at data bicks I call myself the governness of",
    "start": "12080",
    "end": "17920"
  },
  {
    "text": "data um yeah exactly but you know the topics I end up covering are thing like things",
    "start": "17920",
    "end": "23680"
  },
  {
    "text": "like responsibility and like capability maturity and stuff like that like it sounds like I'm everyone's nanny",
    "start": "23680",
    "end": "29840"
  },
  {
    "text": "hopefully more of the like Mary Poppins style than the ones that get taken away on umbrellas um cool so I'll talk a",
    "start": "29840",
    "end": "38000"
  },
  {
    "text": "little bit about responsible AI some of the things that we're seeing now and how organizations are approaching that uh a",
    "start": "38000",
    "end": "43760"
  },
  {
    "text": "little bit of a regulation update obviously there's quite a lot going on in the space and in particular um for",
    "start": "43760",
    "end": "49760"
  },
  {
    "text": "fintech there are some specific things in there as well uh and then the response that we're seeing in the",
    "start": "49760",
    "end": "55199"
  },
  {
    "text": "industry and and how that's being approached uh so hopefully that jives i will say I uh again in the fact that I'm",
    "start": "55199",
    "end": "62399"
  },
  {
    "text": "talking about responsibility and ethics and so forth I did read the rules about creating presentations for this it said",
    "start": "62399",
    "end": "68240"
  },
  {
    "text": "to use like 32 point font so there are very few very large words and for those in the back you're welcome um for",
    "start": "68240",
    "end": "74080"
  },
  {
    "text": "everyone else I apologize for the lack of words on the screen just means that I have to say more over them all right",
    "start": "74080",
    "end": "81600"
  },
  {
    "text": "right so I'm going to start with responsible AI um and I I like to kind of lay the groundwork of what we're",
    "start": "81600",
    "end": "87040"
  },
  {
    "text": "talking about um so one of the things to think about just just to kind of level set 80% of companies are planning to",
    "start": "87040",
    "end": "95439"
  },
  {
    "text": "increase their investment in responsible AI um over the last few years especially we've seen a a tremendous increase of",
    "start": "95439",
    "end": "102960"
  },
  {
    "text": "course in the desire to use AI um and a a parallel increase in the need to think",
    "start": "102960",
    "end": "109200"
  },
  {
    "text": "about what that means from a risk perspective um how do you get the value of AI and the and the capabilities that",
    "start": "109200",
    "end": "114960"
  },
  {
    "text": "it will drive for your organization and unlock that value without creating a massive reputational uh risk for your",
    "start": "114960",
    "end": "122000"
  },
  {
    "text": "company or potentially business and financial risks um so when we think about responsible AI",
    "start": "122000",
    "end": "129039"
  },
  {
    "text": "um at we kind of think of in in multiple levels right so a lot of people talk about the ethics right that's where I",
    "start": "129039",
    "end": "134879"
  },
  {
    "text": "started actually so I was in data science ethics I had a podcast for it for several years um as a data scientist",
    "start": "134879",
    "end": "143120"
  },
  {
    "text": "who kind of came into the the industry when things weren't quite such a buzz um",
    "start": "143120",
    "end": "148239"
  },
  {
    "text": "it was still important to see where could it go um but you know there's there's sort of multiple levels at the",
    "start": "148239",
    "end": "154160"
  },
  {
    "text": "very bottom is where we regulatory compliance right we have to follow the guidelines that are set in place to be",
    "start": "154160",
    "end": "160720"
  },
  {
    "text": "uh compliant with regulation right otherwise we're going to be out of business that's how it works um in the",
    "start": "160720",
    "end": "167519"
  },
  {
    "text": "ethics space this is like what should we do if we could could make AI act the way",
    "start": "167519",
    "end": "173760"
  },
  {
    "text": "we would act and have the same values that we have what should we do um now getting there as we may have seen in the",
    "start": "173760",
    "end": "180560"
  },
  {
    "text": "last year and a half is very challenging um and so really where we end up is what can we do um what are the things that we",
    "start": "180560",
    "end": "188159"
  },
  {
    "text": "can put in place to be responsible with AI and and put in place guard rails that we actually can enforce um knowing that",
    "start": "188159",
    "end": "195920"
  },
  {
    "text": "the aspiration is to get to ethics um but the real uh realistic intention and",
    "start": "195920",
    "end": "201200"
  },
  {
    "text": "goal is to be responsible um so that's that's kind of where we're at um and that 80% of companies are looking to say",
    "start": "201200",
    "end": "208640"
  },
  {
    "text": "okay yeah I have to be compliant that I've already invested in what else can I do right this is that next",
    "start": "208640",
    "end": "215560"
  },
  {
    "text": "step um so I break this down into kind of four levels right if you think about",
    "start": "215560",
    "end": "221040"
  },
  {
    "text": "kind of coming from the top down at the top you have the program that's really",
    "start": "221040",
    "end": "226080"
  },
  {
    "text": "the if we could do anything if we could be the the most ethical people that we",
    "start": "226080",
    "end": "232000"
  },
  {
    "text": "intend to be what does that look like for our company right it's setting the stage on the the ethical principles and",
    "start": "232000",
    "end": "238239"
  },
  {
    "text": "the vision of what our organization wants to achieve and and intends to be",
    "start": "238239",
    "end": "244000"
  },
  {
    "text": "um so this is where at those top level you you typically see somewhere between like four and six ethical principles in",
    "start": "244000",
    "end": "249920"
  },
  {
    "text": "a given company um and somebody some group of people probably in the seauite maybe the board are setting out some",
    "start": "249920",
    "end": "257040"
  },
  {
    "text": "some highlevel principles like we want to be fair and unbiased we want to be",
    "start": "257040",
    "end": "262199"
  },
  {
    "text": "transparent we want to be human centric um these kinds of very big vague floaty",
    "start": "262199",
    "end": "268240"
  },
  {
    "text": "ideas um and then at some point you have to translate that down right you say \"Okay that's that's great and all and",
    "start": "268240",
    "end": "274720"
  },
  {
    "text": "what the heck does that mean to those of us who are actually in the organization what is it we have to do to be whatever",
    "start": "274720",
    "end": "281360"
  },
  {
    "text": "vague concept you've just thrown out there and that's where you see policies right so this is that translation down",
    "start": "281360",
    "end": "287759"
  },
  {
    "text": "one level to say what are the frameworks what are the the rules of the road um are there specific things that that",
    "start": "287759",
    "end": "294080"
  },
  {
    "text": "means we can or can't do as an organization um do we have to say you",
    "start": "294080",
    "end": "299199"
  },
  {
    "text": "know every time we're going to create an AI uh we need to evaluate it against this policy and say is this allowed",
    "start": "299199",
    "end": "306240"
  },
  {
    "text": "right is this Okay for us in our organization and every organization is going to handle this a little differently um be beneath that the next",
    "start": "306240",
    "end": "315440"
  },
  {
    "text": "level of translation is then okay how do we create processes to enforce the",
    "start": "315440",
    "end": "322759"
  },
  {
    "text": "policy what does it look like to start enacting that on a daily basis so do we",
    "start": "322759",
    "end": "329039"
  },
  {
    "text": "have an AI review board that looks at this and says does a given application of AI conform with the policy conform",
    "start": "329039",
    "end": "337360"
  },
  {
    "text": "with therefore the principles uh do we have auditing over time how does this",
    "start": "337360",
    "end": "342560"
  },
  {
    "text": "change other processes in our organization like procurement uh or like cyber security for example and so this",
    "start": "342560",
    "end": "350320"
  },
  {
    "text": "is where you have kind of the process of all the different processes that the organization is going to operate under",
    "start": "350320",
    "end": "357120"
  },
  {
    "text": "um and then at the bottom you've got the practice the actual hands to keyboard building these things what is the way",
    "start": "357120",
    "end": "364479"
  },
  {
    "text": "that we're going to actually implement responsible AI what are the tools and the templates and the techniques that",
    "start": "364479",
    "end": "370560"
  },
  {
    "text": "we're going to use to evaluate AI as we start to build it into our",
    "start": "370560",
    "end": "375639"
  },
  {
    "text": "organization and so what you find is that this middle section is what ends up being called AI",
    "start": "375639",
    "end": "381000"
  },
  {
    "text": "governance right and it's governing the practice right right it's governing to",
    "start": "381000",
    "end": "387840"
  },
  {
    "text": "make sure that these tools templates and techniques abide by the processes and",
    "start": "387840",
    "end": "393199"
  },
  {
    "text": "follow that process that is then aligned to the policy that then hopefully gets",
    "start": "393199",
    "end": "398400"
  },
  {
    "text": "you closer to your principles right so this is the the kind of stack of responsible",
    "start": "398400",
    "end": "403960"
  },
  {
    "text": "AI in terms of principles these are I I've kind of summarized from a lot of",
    "start": "403960",
    "end": "409360"
  },
  {
    "text": "different frameworks these that end up being roughly what you find it's usually",
    "start": "409360",
    "end": "415440"
  },
  {
    "text": "some subset of these um and basically this is sort of the pick list that ends",
    "start": "415440",
    "end": "422400"
  },
  {
    "text": "up happening at the highest levels of which of these do we think is most important um we've seen a lot more",
    "start": "422400",
    "end": "428000"
  },
  {
    "text": "emphasis for example on security lately because there's a lot of concern about",
    "start": "428000",
    "end": "434639"
  },
  {
    "text": "how do we make sure that IP is not infringed that our information is not",
    "start": "434639",
    "end": "440000"
  },
  {
    "text": "getting put out there that our customers information is not going to be exposed right so this safety and security ends",
    "start": "440000",
    "end": "447280"
  },
  {
    "text": "up being a big part of that of course we've also seen that in privacy as well right um and now with additional",
    "start": "447280",
    "end": "453919"
  },
  {
    "text": "regulation compliance is taking on more meaning has more aspects to it but other",
    "start": "453919",
    "end": "459520"
  },
  {
    "text": "things that we find for example is efficiency typically uh in building AI",
    "start": "459520",
    "end": "466800"
  },
  {
    "text": "takes a lot of power takes a lot of processing um takes a lot of money not",
    "start": "466800",
    "end": "472240"
  },
  {
    "text": "the thing that you know most organizations especially fintex want to spend to do this if they can get the",
    "start": "472240",
    "end": "477680"
  },
  {
    "text": "capability less expensive they want to but efficiency is something that's been talked about more because the energy",
    "start": "477680",
    "end": "483879"
  },
  {
    "text": "costs of creating and maintaining and doing inference with AI especially large language models is becoming a bigger",
    "start": "483879",
    "end": "490240"
  },
  {
    "text": "concern how do we power these things so if efficiency becomes one of your",
    "start": "490240",
    "end": "495759"
  },
  {
    "text": "principles then you look at how you minimize that to still get the same outputs while not impacting the",
    "start": "495759",
    "end": "501680"
  },
  {
    "text": "environment and also not impacting your budget so I won't go into all of them",
    "start": "501680",
    "end": "506800"
  },
  {
    "text": "but they're there if you'd like them all right quick update on regulation first off let me caveat i am not a lawyer i am",
    "start": "506800",
    "end": "514399"
  },
  {
    "text": "a data scientist who went into strategy so uh while I talked to the lawyers I I",
    "start": "514399",
    "end": "519518"
  },
  {
    "text": "have to say I'm not a lawyer um again 77% of companies see regulatory",
    "start": "519519",
    "end": "526560"
  },
  {
    "text": "compliance and regulation as a priority for AI of course with the EU AI act",
    "start": "526560",
    "end": "531839"
  },
  {
    "text": "that's increasing anyone who does business with or near or on EU citizens",
    "start": "531839",
    "end": "537680"
  },
  {
    "text": "this is going to be a concern for with the EUAI act coming in we've also seen new regulation elsewhere and I'll I'll",
    "start": "537680",
    "end": "544560"
  },
  {
    "text": "do a little bit of a mapping on that but of course in that ladder right the first step is can we be compliant with",
    "start": "544560",
    "end": "551120"
  },
  {
    "text": "regulation changing what it means to be compliant is changing so of course companies are saying yeah we should",
    "start": "551120",
    "end": "556640"
  },
  {
    "text": "probably still also be compliant with whatever happens all right",
    "start": "556640",
    "end": "562399"
  },
  {
    "text": "this is probably not up to date it changes literally daily um but we're seeing regulation all over the place",
    "start": "562399",
    "end": "568640"
  },
  {
    "text": "right and the the patterns that it takes is different so in the states what we've",
    "start": "568640",
    "end": "574320"
  },
  {
    "text": "seen up to this point is more u an indication that existing laws need to be",
    "start": "574320",
    "end": "580720"
  },
  {
    "text": "abided even if you're using AI to do the thing um in Europe they're taking a",
    "start": "580720",
    "end": "585839"
  },
  {
    "text": "different approach and saying we're going to have this you know riskbased hierarchical uh view of how AI can and",
    "start": "585839",
    "end": "592720"
  },
  {
    "text": "should be applied in China they're saying uh you can do AI as long as it is uh in accord with our uh our our",
    "start": "592720",
    "end": "602120"
  },
  {
    "text": "uh party you know the the the party aspirations and kind of how they think",
    "start": "602120",
    "end": "607440"
  },
  {
    "text": "about the way they want their society to run and in fairness that's how responsible AI and regulation works",
    "start": "607440",
    "end": "613600"
  },
  {
    "text": "right everybody has their view of what does it mean to be responsible what values should we be enforcing um not",
    "start": "613600",
    "end": "621279"
  },
  {
    "text": "universal which makes it again very difficult if you're operating in a multinational environment um we're also",
    "start": "621279",
    "end": "627600"
  },
  {
    "text": "starting to see additional regulations coming in in Japan in India in Brazil um",
    "start": "627600",
    "end": "634160"
  },
  {
    "text": "lots of different approaches in Australia of course tons of different ways that this actually ends up",
    "start": "634160",
    "end": "639360"
  },
  {
    "text": "implemented and the things that you need to comply with will be different by jurisdiction um so I'll go through a",
    "start": "639360",
    "end": "645279"
  },
  {
    "text": "couple um please understand that for a lot of them pre-existing laws do still",
    "start": "645279",
    "end": "650480"
  },
  {
    "text": "apply right so in the states this is what I was talking about like in the states if you look at the way they're handling it they basically say if",
    "start": "650480",
    "end": "657120"
  },
  {
    "text": "something was illegal before when a human was doing it it's still illegal if an AI does it right you're not allowed",
    "start": "657120",
    "end": "662320"
  },
  {
    "text": "to discriminate based on protected classes if you're a human you're not allowed to discriminate algorithmically",
    "start": "662320",
    "end": "667360"
  },
  {
    "text": "if you're using AI that's kind of how that goes data and consumer protection still apply so you don't get to just",
    "start": "667360",
    "end": "673600"
  },
  {
    "text": "blast people's information out there because the AI accidentally whoops did it um which we've seen intellectual",
    "start": "673600",
    "end": "680800"
  },
  {
    "text": "property still applies so all the copyright disputes and infringe IP infringements that have been uh spinning",
    "start": "680800",
    "end": "686959"
  },
  {
    "text": "up in litigation still applies and AI",
    "start": "686959",
    "end": "692040"
  },
  {
    "text": "anti-discrimination anything criminal so um for example there's a lot of of worry",
    "start": "692040",
    "end": "697200"
  },
  {
    "text": "about could AI tell someone how to do something terrible that would constitute criminal behavior um and so there's a",
    "start": "697200",
    "end": "704320"
  },
  {
    "text": "lot of concern around how do you guard against your AI saying something it shouldn't that it probably knows about",
    "start": "704320",
    "end": "710399"
  },
  {
    "text": "but you don't want anyone to know it knows about um just based on how it was trained so there's there's a lot of kind",
    "start": "710399",
    "end": "715680"
  },
  {
    "text": "of filtering that goes on for that um and then antitrust and unfair competition which is a whole other topic",
    "start": "715680",
    "end": "721920"
  },
  {
    "text": "at some point if you're if we have time at the end maybe we can touch on this um but you know basically with antitrust",
    "start": "721920",
    "end": "728880"
  },
  {
    "text": "it's saying you know you you can't use AI to create a non-competitive environment um despite the fact that the",
    "start": "728880",
    "end": "736079"
  },
  {
    "text": "AI itself might be doing that but we'll go to that later all right euai Act um four categories of",
    "start": "736079",
    "end": "743680"
  },
  {
    "text": "risk you've probably heard about this how many people have like looked up the EU AI",
    "start": "743680",
    "end": "749160"
  },
  {
    "text": "act okay a few not as many as I thought all right cool yay so it's new to some",
    "start": "749160",
    "end": "755760"
  },
  {
    "text": "people and this is also the one with the smallest font you're welcome it has content um so four categorizations in",
    "start": "755760",
    "end": "764160"
  },
  {
    "text": "the the the top left over there unacceptable risk is um stuff that like",
    "start": "764160",
    "end": "770240"
  },
  {
    "text": "it's just disallowed flatout disallowed it's things like um",
    "start": "770240",
    "end": "775320"
  },
  {
    "text": "behavioral uh profiling and and all kinds of stuff with like biometrics and",
    "start": "775320",
    "end": "780720"
  },
  {
    "text": "stuff like that um and the idea is that if you're materially distorting behavior",
    "start": "780720",
    "end": "787440"
  },
  {
    "text": "or you're doing things that are like really privacy invading those are prohibited just can't do um unless",
    "start": "787440",
    "end": "794639"
  },
  {
    "text": "you're the government or the military or a bunch of other things it's big just asterisks all over this slide just",
    "start": "794639",
    "end": "800240"
  },
  {
    "text": "imagine asterisks everywhere like it's snowing um snowing caveats so in that",
    "start": "800240",
    "end": "808160"
  },
  {
    "text": "category you know hopefully in your organization you're not dealing with any of those things if you are probably",
    "start": "808160",
    "end": "813920"
  },
  {
    "text": "think about ways to take them out now because this is going to happen this is going to come into effect in a year or",
    "start": "813920",
    "end": "819839"
  },
  {
    "text": "so year and a half um high risk so in high risk what it's basically saying is",
    "start": "819839",
    "end": "826399"
  },
  {
    "text": "if it's if there's the potential for this to influence someone's like means of earning a living means of living um",
    "start": "826399",
    "end": "834560"
  },
  {
    "text": "health safety access to critical infrastructure those kinds of things you have to go through a very rigorous",
    "start": "834560",
    "end": "840399"
  },
  {
    "text": "documentation process called the conformity assessment um this is where a",
    "start": "840399",
    "end": "846639"
  },
  {
    "text": "fair bit of of fintech organizations are going to end up having something to do",
    "start": "846639",
    "end": "851680"
  },
  {
    "text": "um and probably in the limited risk which I'll get to in a sec the conformity assessment is a lot um that",
    "start": "851680",
    "end": "858320"
  },
  {
    "text": "said finance has been doing impact assessments and compliance documentation",
    "start": "858320",
    "end": "863440"
  },
  {
    "text": "for decades i've been there it sucks but you do it you put out reams of",
    "start": "863440",
    "end": "868920"
  },
  {
    "text": "documentation about how you got to the conclusion you got to why this model was the best one of all the things you",
    "start": "868920",
    "end": "874320"
  },
  {
    "text": "tested why these features were selected what their relative importance is how you've tested for disparate impact all",
    "start": "874320",
    "end": "880079"
  },
  {
    "text": "that good stuff it it's that plus a bunch of other things that go into the conformity assessment so the",
    "start": "880079",
    "end": "885839"
  },
  {
    "text": "documentation that you've done so far drop in the bucket um my hope personally is that we can",
    "start": "885839",
    "end": "893120"
  },
  {
    "text": "then train an LLM to help generate the documentation and then we can figure out",
    "start": "893120",
    "end": "899440"
  },
  {
    "text": "which bucket that falls into i'm I'm thinking minimal um so in any case um so that's",
    "start": "899440",
    "end": "908639"
  },
  {
    "text": "the high-risk group um and there are some some caveats on that as well because like I said it's snowing caveats",
    "start": "908639",
    "end": "914480"
  },
  {
    "text": "today um limited risk basically if it's not one of the other two but it interacts with a person you have to tell the",
    "start": "914480",
    "end": "920959"
  },
  {
    "text": "person you're interacting with an AI the fun one I think about here is a few years ago Google did a demonstration of",
    "start": "920959",
    "end": "927600"
  },
  {
    "text": "what was a Duo or something like that where they had an AI application that called and made a booking at a",
    "start": "927600",
    "end": "933600"
  },
  {
    "text": "restaurant or something like that yeah if if that were the case under the EU AI act the phone call would sound like \"Hi",
    "start": "933600",
    "end": "940320"
  },
  {
    "text": "this is Google Duo calling this is an AI i would like to book a reservation for this particular person on this date and",
    "start": "940320",
    "end": "946079"
  },
  {
    "text": "time right because you have to tell them um and this is true then for all the",
    "start": "946079",
    "end": "951199"
  },
  {
    "text": "chat bots that are being created and all the these kind of use cases that are coming in now where there's an",
    "start": "951199",
    "end": "956560"
  },
  {
    "text": "interaction with a person similarly it would work for internal so even if",
    "start": "956560",
    "end": "961680"
  },
  {
    "text": "you're not necessarily displacing uh customer service for example if you're augmenting your customer service staff",
    "start": "961680",
    "end": "968000"
  },
  {
    "text": "you have to tell your customer service staff this is an AI chatbot that's giving you a script right this is not a",
    "start": "968000",
    "end": "973519"
  },
  {
    "text": "pre-programmed rules you know defined rules engine this is an AI just so",
    "start": "973519",
    "end": "979120"
  },
  {
    "text": "they're aware um and then everything else is minimal risk so um for example",
    "start": "979120",
    "end": "984399"
  },
  {
    "text": "things like fraud detection fall into minimal risk according to the way that the current structure has been laid out",
    "start": "984399",
    "end": "991160"
  },
  {
    "text": "now these are very vague there are examples in the act if you want to read through the 200 and some odd pages of it",
    "start": "991160",
    "end": "998000"
  },
  {
    "text": "um I don't recommend it unless you have insomnia in which case have at um but",
    "start": "998000",
    "end": "1005120"
  },
  {
    "text": "the majority of what this will do I think my own again not a lawyer my own",
    "start": "1005120",
    "end": "1010639"
  },
  {
    "text": "interpretation is a lot of how this is going to come together will happen in litigation so as new applications come",
    "start": "1010639",
    "end": "1018320"
  },
  {
    "text": "online once this is enforced we will probably see a lot of the rules get a",
    "start": "1018320",
    "end": "1024959"
  },
  {
    "text": "little bit more clear as to what they consider high risk unacceptable risk",
    "start": "1024959",
    "end": "1030079"
  },
  {
    "text": "lower risk and so forth uh because right now there's sort of some vague understandings of what we think people",
    "start": "1030079",
    "end": "1036480"
  },
  {
    "text": "are going to try and do with AI but it's not specific yet um in the act there are",
    "start": "1036480",
    "end": "1042640"
  },
  {
    "text": "also specific rules around general purpose AI and foundation models if you're training a general purpose or",
    "start": "1042640",
    "end": "1049360"
  },
  {
    "text": "foundation model on your own uh first of all I would like your budget secondly um",
    "start": "1049360",
    "end": "1056400"
  },
  {
    "text": "there are specific rules around how you have to be transparent and how much how many flops you have you can have and all",
    "start": "1056400",
    "end": "1062720"
  },
  {
    "text": "kinds of crazy stuff there's that's for like the the few that want to actually build a model which at data bricks we",
    "start": "1062720",
    "end": "1069520"
  },
  {
    "text": "did so we had to actually look at that stuff all right the other one I wanted to talk",
    "start": "1069520",
    "end": "1075679"
  },
  {
    "text": "about specific to FinTech is consumer duty so this came in I think last year um and it has some interesting",
    "start": "1075679",
    "end": "1082400"
  },
  {
    "text": "implications for responsible AI because first of all it says design for good",
    "start": "1082400",
    "end": "1087600"
  },
  {
    "text": "customer outcomes well how do you define a good customer outcome how do you know that that customer outcome avoids",
    "start": "1087600",
    "end": "1093840"
  },
  {
    "text": "foreseeable harm right so this is sort of going back to that conformity assessment disparate impact assessment",
    "start": "1093840",
    "end": "1100640"
  },
  {
    "text": "all these things that you have to prove are doing the right thing for your customers um and the next part is demonstrating",
    "start": "1100640",
    "end": "1108559"
  },
  {
    "text": "your supply chain with AI the supply chain gets a little nebulous um so you have to think about",
    "start": "1108559",
    "end": "1116640"
  },
  {
    "text": "what is your procurement process how do you track what data is coming in being",
    "start": "1116640",
    "end": "1122799"
  },
  {
    "text": "used in your AI how it's being labeled how it's being featurized how it's being vectorized or chunked or whatever you're",
    "start": "1122799",
    "end": "1128160"
  },
  {
    "text": "using to be able to actually put it into an AI application",
    "start": "1128160",
    "end": "1133520"
  },
  {
    "text": "so for fintech there's this kind of extra bit again I think it's probably mostly there for most financial services",
    "start": "1133520",
    "end": "1140480"
  },
  {
    "text": "companies including fintech because again we've been subject to this stuff for a long time but things to think",
    "start": "1140480",
    "end": "1147440"
  },
  {
    "text": "about with our new technologies is how is this actually going to play out over",
    "start": "1147440",
    "end": "1153720"
  },
  {
    "text": "time all right it does bring us into the response though from fintech so more",
    "start": "1153720",
    "end": "1160000"
  },
  {
    "text": "stats because I'm a numbers nerd so according to a survey of fintex 10 uh",
    "start": "1160000",
    "end": "1166000"
  },
  {
    "text": "they expect a 10 to 30% revenue boost in the next three years most leaders in in fintech",
    "start": "1166000",
    "end": "1172480"
  },
  {
    "text": "um based on the use of generative AI specifically this is not uncommon um",
    "start": "1172480",
    "end": "1178000"
  },
  {
    "text": "I've heard this 30% thing bandied about I think McKenzie had another one that was like oh 30% efficiency from doing uh",
    "start": "1178000",
    "end": "1185039"
  },
  {
    "text": "you using generative AI you're going to save 30% of whatever costs and and all",
    "start": "1185039",
    "end": "1190080"
  },
  {
    "text": "this stuff maybe um but the reputation of fintech is kind of two things right it's there's the",
    "start": "1190080",
    "end": "1197120"
  },
  {
    "text": "disruption angle right and from a technology perspective or digital native perspective it's it's also open source",
    "start": "1197120",
    "end": "1204000"
  },
  {
    "text": "so when you think about how you're going to achieve this 10 to 30%",
    "start": "1204000",
    "end": "1209679"
  },
  {
    "text": "um in a way that others aren't right so you want to be disruptive you don't want to be the next you know JP Morgan who's",
    "start": "1209679",
    "end": "1216400"
  },
  {
    "text": "saying okay yes we can incrementally improve our efficiency by 10% fintech saying \"No no no we want to do something",
    "start": "1216400",
    "end": "1222480"
  },
  {
    "text": "massively different like completely different from what the big guys are doing disrupt it.\" Um and often",
    "start": "1222480",
    "end": "1229679"
  },
  {
    "text": "especially in in early stage right you want to go for something that you can build and control well it's actually an",
    "start": "1229679",
    "end": "1234880"
  },
  {
    "text": "advantage now because when you talk about knowing and and ensuring your supply chain for AI being able to have",
    "start": "1234880",
    "end": "1241960"
  },
  {
    "text": "transparency driving towards responsibility the more you use open source and can see the code and can see",
    "start": "1241960",
    "end": "1248880"
  },
  {
    "text": "the data and can see the weights and can show all of that the better you are able to take that use it to your advantage",
    "start": "1248880",
    "end": "1255440"
  },
  {
    "text": "prove the supply chain go through the conformity assessments and disrupt so that you're not the one",
    "start": "1255440",
    "end": "1261120"
  },
  {
    "text": "sitting there going \"Yes I will incrementally improve my efficiency and I might get a 5% decrease in in some",
    "start": "1261120",
    "end": "1267039"
  },
  {
    "text": "sort of cost right so we're seeing in fintech a lot of interest in the open",
    "start": "1267039",
    "end": "1272640"
  },
  {
    "text": "source models a lot of interest in being able to build and fine-tune uh especially for for",
    "start": "1272640",
    "end": "1278360"
  },
  {
    "text": "LLMs uh and of course that's always been there for for machine learning and data",
    "start": "1278360",
    "end": "1283520"
  },
  {
    "text": "science and so forth so I I've not yet met a fintech using SAS which I'm very grateful for",
    "start": "1283520",
    "end": "1289480"
  },
  {
    "text": "um but just you know taking advantage of what's",
    "start": "1289480",
    "end": "1294679"
  },
  {
    "text": "available now that said as a disruptor there's nothing holding you",
    "start": "1294679",
    "end": "1299760"
  },
  {
    "text": "back from saying well you know we think there's a 20% reduction in workforce that we could actually achieve and",
    "start": "1299760",
    "end": "1305840"
  },
  {
    "text": "what's interesting here is that it's sort of the unspoken bit in other industries but in fintech it's actually",
    "start": "1305840",
    "end": "1314159"
  },
  {
    "text": "moving in that direction there's there's a lot of of uh noise about it right so going from processes that had been",
    "start": "1314159",
    "end": "1321400"
  },
  {
    "text": "manual through to kind of augmenting people and then eventually automating",
    "start": "1321400",
    "end": "1326880"
  },
  {
    "text": "those capabilities and a great example of that was Clara so a couple months ago Clara's",
    "start": "1326880",
    "end": "1334240"
  },
  {
    "text": "CEO it was actually on their own website on their blog um said \"We have a chatbot",
    "start": "1334240",
    "end": "1340320"
  },
  {
    "text": "that's been handling twothirds of our customer service requests over the last couple of months it's gotten better",
    "start": "1340320",
    "end": "1346240"
  },
  {
    "text": "quality there have been le uh fewer issues where people had to come back and talk to somebody again so you know we're",
    "start": "1346240",
    "end": "1352000"
  },
  {
    "text": "looking at that um and we're seeing that it could it could replace 700 workers",
    "start": "1352000",
    "end": "1359600"
  },
  {
    "text": "they were public about this right why because fintech most digital natives are",
    "start": "1359600",
    "end": "1366320"
  },
  {
    "text": "known for disrupting they rely on technology right it's that",
    "start": "1366320",
    "end": "1371559"
  },
  {
    "text": "technosolutionism of being able to say \"Yes we want to do this.\" Now thinking back to those principles does that make",
    "start": "1371559",
    "end": "1378880"
  },
  {
    "text": "you human centric or not like these are the decisions that end up having",
    "start": "1378880",
    "end": "1384159"
  },
  {
    "text": "ramifications for what you do with AI if you're saying well we're customer",
    "start": "1384159",
    "end": "1390120"
  },
  {
    "text": "centric we want to make sure that the humans that we're serving are our customers but that means potentially not",
    "start": "1390120",
    "end": "1396559"
  },
  {
    "text": "serving our employees in the same way not ensuring their continued uh work in",
    "start": "1396559",
    "end": "1401840"
  },
  {
    "text": "in this company although frankly what he said was those were all outsourced people so they don't count as our employees",
    "start": "1401840",
    "end": "1408280"
  },
  {
    "text": "which ethically vague there's a reason I always wear gray when I give talks about",
    "start": "1408280",
    "end": "1413520"
  },
  {
    "text": "responsible AI everything's gray um but this is something that that's",
    "start": "1413520",
    "end": "1419039"
  },
  {
    "text": "very much happening now um and I can tell you that they're not the only company saying we think there's a",
    "start": "1419039",
    "end": "1425440"
  },
  {
    "text": "workforce reduction and I spoke with another very large organization not long ago that said \"We have 2,000 analysts",
    "start": "1425440",
    "end": "1432880"
  },
  {
    "text": "but we think if we put in place the right tooling we put in place the right AI we could drop that to about",
    "start": "1432880",
    "end": "1439159"
  },
  {
    "text": "200.\" They're not saying it publicly they're not telling their analysts \"By the way your job is on the line but it's",
    "start": "1439159",
    "end": "1446640"
  },
  {
    "text": "still there right it's happening now.\" Um",
    "start": "1446640",
    "end": "1453400"
  },
  {
    "text": "so how do we kind of move through this pattern together um from a responsibility",
    "start": "1453400",
    "end": "1459760"
  },
  {
    "text": "perspective first thing establish your principles right and that includes how much transparency are you going to give",
    "start": "1459760",
    "end": "1466720"
  },
  {
    "text": "to whom in what right these are the policies internally you need to set up um for organizations that have risk",
    "start": "1466720",
    "end": "1474400"
  },
  {
    "text": "management which fintech should extend your risk management framework to include AI right that's happening now",
    "start": "1474400",
    "end": "1480240"
  },
  {
    "text": "they're evaluating what are the risks that we're taking on when we put AI into place",
    "start": "1480240",
    "end": "1486320"
  },
  {
    "text": "um identify what I call no-fly zones so there are some organizations that are saying you know we're probably not in",
    "start": "1486320",
    "end": "1492880"
  },
  {
    "text": "the high-risk camp most of the time and we don't really want to go through this conformity assessment stuff so if we",
    "start": "1492880",
    "end": "1498720"
  },
  {
    "text": "could just never use AI in anything to do with HR that'd be great because the moment it touches something like",
    "start": "1498720",
    "end": "1504799"
  },
  {
    "text": "employment status or pay or performance conformity assessment is required um so",
    "start": "1504799",
    "end": "1511760"
  },
  {
    "text": "sometimes there's just it's just not worth it right um crossf",
    "start": "1511760",
    "end": "1517480"
  },
  {
    "text": "functionally implementing responsible AI there's a lot in that one",
    "start": "1517480",
    "end": "1523640"
  },
  {
    "text": "bullet this is something that again at the start we're seeing a lot more security getting involved so we're",
    "start": "1523640",
    "end": "1528720"
  },
  {
    "text": "seeing CISOs legal teams compliance AI governance all coming together to figure",
    "start": "1528720",
    "end": "1535440"
  },
  {
    "text": "out what the heck do we do um how do we safeguard the organization how do we look at risk",
    "start": "1535440",
    "end": "1541760"
  },
  {
    "text": "management differently do we bring in the risk officers in conjunction with all these other groups right build your",
    "start": "1541760",
    "end": "1548480"
  },
  {
    "text": "AI review board including all these crossf functional folks so that you can establish a holistic",
    "start": "1548480",
    "end": "1555159"
  },
  {
    "text": "approach um and then set up practical processes so saying well we're just going to do a conformity assessment for",
    "start": "1555159",
    "end": "1561440"
  },
  {
    "text": "every single AI that we ever ever have just in case probably not practical may or may not need to do it again unless",
    "start": "1561440",
    "end": "1568000"
  },
  {
    "text": "the magic LLM that happens someday is able to do all that documentation for you which here's hoping",
    "start": "1568000",
    "end": "1575159"
  },
  {
    "text": "um but try to to kind of think about what are all the teams that actually need to come together to help you solve",
    "start": "1575159",
    "end": "1581760"
  },
  {
    "text": "for responsible AI um and especially in fintech a lot of this already exists",
    "start": "1581760",
    "end": "1586880"
  },
  {
    "text": "right you've got risk management frameworks you've got a model risk management uh capability you've probably",
    "start": "1586880",
    "end": "1592720"
  },
  {
    "text": "done some amount of documentation of this stuff before um and you've got a lot of the the",
    "start": "1592720",
    "end": "1598720"
  },
  {
    "text": "components all the people in different teams that could be part of this um it's",
    "start": "1598720",
    "end": "1604400"
  },
  {
    "text": "all I had officially with a lot of time left um so",
    "start": "1604400",
    "end": "1609840"
  },
  {
    "text": "happy to take questions [Applause]",
    "start": "1609840",
    "end": "1621140"
  },
  {
    "text": "so we have time for questions and we want to encourage lots of questions just one quickly um you said 20% of or 80% of",
    "start": "1623279",
    "end": "1630960"
  },
  {
    "text": "companies are investing in ethical responsible AI does that mean 20% are investing in irresponsible AI um I I",
    "start": "1630960",
    "end": "1639200"
  },
  {
    "text": "would pro I would say 20% probably have the hubris to think that they've already invested enough",
    "start": "1639200",
    "end": "1645360"
  },
  {
    "text": "okay that's cool um a question on AI dealing with AI when you talked about um",
    "start": "1645360",
    "end": "1651679"
  },
  {
    "text": "limited risk in informing and then sort of what are you seeing with AI dealing",
    "start": "1651679",
    "end": "1657279"
  },
  {
    "text": "with AI because you talked about like AI dealing with humans a lot um will you will you see a stage where AIs have to",
    "start": "1657279",
    "end": "1663200"
  },
  {
    "text": "inform each AI that they're dealing with an AI and how does that all work or or what are you seeing with regulations",
    "start": "1663200",
    "end": "1668480"
  },
  {
    "text": "around AI dealing with AIS um I haven't seen a tremendous amount of of regulation around that area what I have",
    "start": "1668480",
    "end": "1675360"
  },
  {
    "text": "seen is more that AI will govern AI um so it's it's kind of that um adversarial",
    "start": "1675360",
    "end": "1682960"
  },
  {
    "text": "approach of like having an AI that says okay explain to me why you said this as a second",
    "start": "1682960",
    "end": "1691200"
  },
  {
    "text": "buffer because a human can't be there all the time to to indicate yes this is",
    "start": "1691200",
    "end": "1696559"
  },
  {
    "text": "a good response or no it's a bad response in a generative nature so when you're doing things like uh governing",
    "start": "1696559",
    "end": "1702559"
  },
  {
    "text": "and checking and evaluating the responses after somebody's prompted and saying is this a a response that we",
    "start": "1702559",
    "end": "1708480"
  },
  {
    "text": "would want um it's actually more scalable and effective to have another AI in place as the governor of that um",
    "start": "1708480",
    "end": "1716320"
  },
  {
    "text": "so that's something I am seeing that's that's come up quite a bit and so it's things like um algorithmic red teaming",
    "start": "1716320",
    "end": "1722720"
  },
  {
    "text": "right so like yes you could have someone try and sit there and type but humans are constrained as to how quickly we can",
    "start": "1722720",
    "end": "1728240"
  },
  {
    "text": "type and think up the next use case and the next thing we want to try and trick it to do uh AIs can do that a lot faster",
    "start": "1728240",
    "end": "1734720"
  },
  {
    "text": "so if if we say to one AI trick that one into saying this it will find ways and",
    "start": "1734720",
    "end": "1741200"
  },
  {
    "text": "it'll do it quick cool any questions from the audience sure there must be",
    "start": "1741200",
    "end": "1747600"
  },
  {
    "text": "someone out there is thinking about something devious yes there's one",
    "start": "1747600",
    "end": "1753720"
  },
  {
    "text": "of the policy organization oh thank you uh we started thinking",
    "start": "1755360",
    "end": "1762480"
  },
  {
    "text": "about like um um enforcing the policy of uh adding more and more use cases using",
    "start": "1762480",
    "end": "1768720"
  },
  {
    "text": "generative AI so we came to an conclusion that we have created a committee to improve every and every use",
    "start": "1768720",
    "end": "1774000"
  },
  {
    "text": "case so I was kind of wondering what your takeaway about like creating that type of commitment committee yeah yeah",
    "start": "1774000",
    "end": "1780320"
  },
  {
    "text": "absolutely so that's kind of the AI review board idea um a couple of things that that that body would do one is set",
    "start": "1780320",
    "end": "1787760"
  },
  {
    "text": "up the policies so making sure that you have uh kind of that framework at at the start also looking at the processes",
    "start": "1787760",
    "end": "1794480"
  },
  {
    "text": "right so what at what point do different um business areas need to come to the",
    "start": "1794480",
    "end": "1800960"
  },
  {
    "text": "board and say we have this idea for a new AI application uh maybe if they've",
    "start": "1800960",
    "end": "1806159"
  },
  {
    "text": "already chatted with somebody who's from the AI team data science machine learning whatever it might be to say we",
    "start": "1806159",
    "end": "1811840"
  },
  {
    "text": "think we want to solve it this way um so that the AI review board can then say",
    "start": "1811840",
    "end": "1816880"
  },
  {
    "text": "does this you know realistically conform with the policies and processes and so",
    "start": "1816880",
    "end": "1821919"
  },
  {
    "text": "forth so it becomes that kind of touch point um it does so there there kind of",
    "start": "1821919",
    "end": "1827520"
  },
  {
    "text": "two issues with that though one is I you know if you don't have a solid",
    "start": "1827520",
    "end": "1833440"
  },
  {
    "text": "set of information on how you're going to manage and mitigate risks that can cause a lot of looping um the other is",
    "start": "1833440",
    "end": "1840559"
  },
  {
    "text": "if they don't meet often um that can cause a a bit of a time suck um so and",
    "start": "1840559",
    "end": "1846720"
  },
  {
    "text": "the two of those compound right so you want to make sure that this is something where there's enough of a framework",
    "start": "1846720",
    "end": "1852720"
  },
  {
    "text": "there and and this comes back to kind of the the riskmanagement framework right",
    "start": "1852720",
    "end": "1858080"
  },
  {
    "text": "understanding categorizing and quantifying the risks that you're taking and understanding what can be done to",
    "start": "1858080",
    "end": "1863120"
  },
  {
    "text": "mitigate them um and having enough information when you first go to that AI",
    "start": "1863120",
    "end": "1868240"
  },
  {
    "text": "review board to say \"Here's the stuff that you're going to need as inputs to risk management here are the mitigations",
    "start": "1868240",
    "end": "1874000"
  },
  {
    "text": "we're planning here's what we're kind of looking at.\" So that they can say \"Yeah go ahead.\" And then also just making",
    "start": "1874000",
    "end": "1879840"
  },
  {
    "text": "sure they meet pretty frequently",
    "start": "1879840",
    "end": "1884039"
  },
  {
    "text": "question there yeah hello i had a question regarding uh",
    "start": "1884880",
    "end": "1892559"
  },
  {
    "text": "chat bots um do you think we will see a lot of chatbots giving financial advices in the",
    "start": "1892559",
    "end": "1900559"
  },
  {
    "text": "future and what are the regulations uh in that uh area yeah yeah there's a lot",
    "start": "1900559",
    "end": "1906880"
  },
  {
    "text": "of discussion around um AI giving financial advice um there are",
    "start": "1906880",
    "end": "1912559"
  },
  {
    "text": "regulations already in place about robo advising um it's been out there i mean robo advising has been out for for some",
    "start": "1912559",
    "end": "1918640"
  },
  {
    "text": "time even without you know generative AI um I think the the regulation will still",
    "start": "1918640",
    "end": "1925760"
  },
  {
    "text": "apply that said there's enough information for us to see that yes it's something that if the regulation allows",
    "start": "1925760",
    "end": "1932960"
  },
  {
    "text": "in the jurisdiction companies will absolutely be approaching it um I think the question there becomes one of how",
    "start": "1932960",
    "end": "1941519"
  },
  {
    "text": "how many permutations of advice do you really want to offer how customized does",
    "start": "1941519",
    "end": "1946880"
  },
  {
    "text": "that become um and what other information do you give access to that chatbot right so for robo advising",
    "start": "1946880",
    "end": "1955120"
  },
  {
    "text": "really any of that you'd want to have sufficient I won't say real time but very you know but upto-date information",
    "start": "1955120",
    "end": "1962159"
  },
  {
    "text": "so that it's not giving advice on for example you know stock performances from six months ago it's looking at what's",
    "start": "1962159",
    "end": "1968159"
  },
  {
    "text": "happening now so you want to make sure it's constantly getting information how many different places",
    "start": "1968159",
    "end": "1973519"
  },
  {
    "text": "and how much information are you going to feed it on an ongoing basis because there's a cost to that right so it's",
    "start": "1973519",
    "end": "1979039"
  },
  {
    "text": "thinking about what is that going to get you how much do you want to do Or do you set you kind of set it as almost like a",
    "start": "1979039",
    "end": "1984720"
  },
  {
    "text": "rules-based engine the way that a lot of robo advisors do anyways which is instead of saying well these specific",
    "start": "1984720",
    "end": "1990880"
  },
  {
    "text": "things would constitute a good portfolio for you you say you're in this risk category you know risk appetite category",
    "start": "1990880",
    "end": "1997600"
  },
  {
    "text": "so we recommend this kind of fund or whatever and it's kind of a pick list so I think it'll depend you know on the on",
    "start": "1997600",
    "end": "2003279"
  },
  {
    "text": "the regulation like I said earlier there's different approaches in every jurisdiction um but it's certainly a use",
    "start": "2003279",
    "end": "2008880"
  },
  {
    "text": "case that comes up quite a bit question about bias um two seems to be",
    "start": "2008880",
    "end": "2015919"
  },
  {
    "text": "two schools of thought around bias you either eliminate from the data set beforehand or you you you work through",
    "start": "2015919",
    "end": "2022240"
  },
  {
    "text": "and let it be eliminated afterwards what's your thought on that neither is",
    "start": "2022240",
    "end": "2027440"
  },
  {
    "text": "possible okay um so bias is something that we try to mitigate um but I will",
    "start": "2027440",
    "end": "2035360"
  },
  {
    "text": "tell you that it's uh it's very very challenging because the biases that you're trying to take out mean that",
    "start": "2035360",
    "end": "2042480"
  },
  {
    "text": "you're putting in other biases so like good luck um yeah it's it's sort of a",
    "start": "2042480",
    "end": "2048320"
  },
  {
    "text": "vicious cycle right this is bias is something that everyone has you know we various cognitive biases you know",
    "start": "2048320",
    "end": "2054000"
  },
  {
    "text": "contextual biases and so forth and so you the more we try and and do something",
    "start": "2054000",
    "end": "2059200"
  },
  {
    "text": "about it the more it's just changing what bias is represented um it's not to say don't do it or don't try to mitigate",
    "start": "2059200",
    "end": "2066638"
  },
  {
    "text": "it but just be aware that there will be biases certain of them are illegal in",
    "start": "2066639",
    "end": "2072320"
  },
  {
    "text": "various countries and those are the ones you definitely want to mitigate that's really what it comes down to yeah when we get past the uh AI coming for the job",
    "start": "2072320",
    "end": "2079760"
  },
  {
    "text": "of the person operating a phone to the person who's doing financial trading and moving up the stack how do we avoid the",
    "start": "2079760",
    "end": "2085679"
  },
  {
    "text": "financial war game scenario where the bots just trade away all the money",
    "start": "2085679",
    "end": "2091158"
  },
  {
    "text": "um so I think it depends so a generative AI is not necessarily going to be doing the trading immediately it's you know",
    "start": "2091159",
    "end": "2098880"
  },
  {
    "text": "that's something that is a little bit different you're talking about different styles of agents at that point i I get",
    "start": "2098880",
    "end": "2104240"
  },
  {
    "text": "your point um you know I think there's it is helpful to think about",
    "start": "2104240",
    "end": "2111119"
  },
  {
    "text": "what limits you put on these systems right so those no-fly zones do you allow AI to trade certain types of you know at",
    "start": "2111119",
    "end": "2119040"
  },
  {
    "text": "certain levels so for example if I go back to here how much do you automate how much",
    "start": "2119040",
    "end": "2125680"
  },
  {
    "text": "do you augment a human or do you have a human in the loop where the AI says I think it'd be prudent to do X Y and Z",
    "start": "2125680",
    "end": "2132560"
  },
  {
    "text": "but somebody has to approve it and do the regulations prevent someone from making the bad decision that says I'm",
    "start": "2132560",
    "end": "2138880"
  },
  {
    "text": "going to try and go fully automated on this when the responsible thing is keep a human in the loop um so some of it",
    "start": "2138880",
    "end": "2145760"
  },
  {
    "text": "does right so to the point earlier around um you know robo advising or financial advice um certain",
    "start": "2145760",
    "end": "2152160"
  },
  {
    "text": "jurisdictions say you're not allowed to give financial advice in a chatbot for example at that point okay great so",
    "start": "2152160",
    "end": "2160000"
  },
  {
    "text": "you're not automating you might be augmenting so instead of a chatbot saying it directly to the person you've",
    "start": "2160000",
    "end": "2166160"
  },
  {
    "text": "got a financial advisor who types something in and the chatbot says to them \"Here's what I'd recommend for this",
    "start": "2166160",
    "end": "2172000"
  },
  {
    "text": "client.\" And then they get to say yay or nay um so sometimes you depending on the jurisdiction that's what you'd end up",
    "start": "2172000",
    "end": "2178079"
  },
  {
    "text": "seeing",
    "start": "2178079",
    "end": "2181079"
  },
  {
    "text": "oh one over here yeah on the front over the front they're They're coming",
    "start": "2184880",
    "end": "2193440"
  },
  {
    "text": "hi um so yeah really enjoyed your talk um do you do you see that with LLMs",
    "start": "2194560",
    "end": "2201920"
  },
  {
    "text": "being adopted quite you know quite widely um do you see that the onus being on being compliant running against those",
    "start": "2201920",
    "end": "2211200"
  },
  {
    "text": "companies that are building these LLM so they have kind of like you know I don't know like ISO or some sort of a",
    "start": "2211200",
    "end": "2217200"
  },
  {
    "text": "certification that embeds that confidence of you know that they're compliant to a certain level or am I",
    "start": "2217200",
    "end": "2224720"
  },
  {
    "text": "just um so compliance is an interesting one on this because compliance is on a per application level at this point",
    "start": "2224720",
    "end": "2231359"
  },
  {
    "text": "right you don't you don't get certified as a company that you are compliant with the AI regulation you have to have every",
    "start": "2231359",
    "end": "2237359"
  },
  {
    "text": "single AI certified if that if you're part of the conformity assessment right every one of them has to go through that",
    "start": "2237359",
    "end": "2244000"
  },
  {
    "text": "um so you don't get like a blanket statement saying \"Yep stamp you're good.\" Um I think",
    "start": "2244000",
    "end": "2251079"
  },
  {
    "text": "with with respect to LLMs um you know the the probability of of things going",
    "start": "2251079",
    "end": "2258480"
  },
  {
    "text": "more arai than in classical machine learning and and data science is higher um and so I think there's a a higher",
    "start": "2258480",
    "end": "2266000"
  },
  {
    "text": "burden of proof to to say that we've done what we can to try and limit um and",
    "start": "2266000",
    "end": "2271680"
  },
  {
    "text": "to try to be responsible with it and so I think that's something that you know we it's certainly acknowledged in all",
    "start": "2271680",
    "end": "2276720"
  },
  {
    "text": "the regulations um but it's going to be harder and frankly when you look at who's on the hook right the the actual",
    "start": "2276720",
    "end": "2283760"
  },
  {
    "text": "you know liability of what happens it's still people um a lot of the the",
    "start": "2283760",
    "end": "2289280"
  },
  {
    "text": "regulation has actually been quite clear that it's still a um a person or people",
    "start": "2289280",
    "end": "2294800"
  },
  {
    "text": "who are responsible for the actions of the AI a good example of that was the whole debacle with Air Canada and the",
    "start": "2294800",
    "end": "2301359"
  },
  {
    "text": "bereavement policy that the AI said \"Oh yeah you know just go ahead and claim that it's bereavement you can say within",
    "start": "2301359",
    "end": "2306960"
  },
  {
    "text": "90 days and we'll refund your money.\" And and they're like \"Your AI said",
    "start": "2306960",
    "end": "2312200"
  },
  {
    "text": "it go on you got to honor it.\" Um so you know I think there's there's more of",
    "start": "2312200",
    "end": "2317680"
  },
  {
    "text": "that and the regulation has been clearer especially with um some of the newer regulation coming out saying it has to",
    "start": "2317680",
    "end": "2322880"
  },
  {
    "text": "be a natural person um that's responsible when it comes to financial services here at least as I understand",
    "start": "2322880",
    "end": "2329040"
  },
  {
    "text": "it it's the MDs who who carry that which is uh a lot of risk when you look at it at scale",
    "start": "2329040",
    "end": "2336720"
  },
  {
    "text": "you want to touch on mentioned antitrust close that out we could close that so antitrust the",
    "start": "2336720",
    "end": "2344320"
  },
  {
    "text": "So it's sort of an interesting one that I think about from not from the perspective of those implementing AI and",
    "start": "2344320",
    "end": "2350400"
  },
  {
    "text": "trying to com you know create anti-competitive environments for their their potential competition but more so",
    "start": "2350400",
    "end": "2355920"
  },
  {
    "text": "for the accessibility of AI um as a competitive advantage uh that a lot of",
    "start": "2355920",
    "end": "2362160"
  },
  {
    "text": "the organizations that we're seeing that are startup or fintech or you know digital native and whatnot they're going",
    "start": "2362160",
    "end": "2367200"
  },
  {
    "text": "towards open source partly because you have the ability to use it without",
    "start": "2367200",
    "end": "2372240"
  },
  {
    "text": "having to spend millions upon millions of dollars to do it um and so it creates",
    "start": "2372240",
    "end": "2377440"
  },
  {
    "text": "actually a more competitive environment to have open-source models and to be able to leverage some of these",
    "start": "2377440",
    "end": "2383280"
  },
  {
    "text": "capabilities um so that if somebody does have a new disruptive idea that would take you know it would require the use",
    "start": "2383280",
    "end": "2389760"
  },
  {
    "text": "of AI and require the use of LLM there's a means of entry into that market um so",
    "start": "2389760",
    "end": "2395119"
  },
  {
    "text": "you know my own soap box since I'm standing on the podium I get to say it um you know I I personally think that",
    "start": "2395119",
    "end": "2402000"
  },
  {
    "text": "it's a it's a helpful tool to have these kind of open source models to get new entrance into the market so that it's",
    "start": "2402000",
    "end": "2408640"
  },
  {
    "text": "not relying on this token-based economy of having to pay for a a proprietary application for AI",
    "start": "2408640",
    "end": "2417000"
  },
  {
    "text": "[Music]",
    "start": "2418550",
    "end": "2424010"
  }
]
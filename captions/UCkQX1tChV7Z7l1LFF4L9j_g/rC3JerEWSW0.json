[
  {
    "start": "0",
    "end": "25000"
  },
  {
    "text": "so before we get too far I'll first want to see is there anybody that's going to admit to not knowing anything about",
    "start": "24390",
    "end": "29920"
  },
  {
    "start": "25000",
    "end": "50000"
  },
  {
    "text": "spark yeah it's going to get good news bad news kind of thing bad news is that",
    "start": "29920",
    "end": "36850"
  },
  {
    "text": "i'm not going to be able to spend a lot of time explaining really what spark is all about because i really want to talk",
    "start": "36850",
    "end": "42489"
  },
  {
    "text": "about some of the pieces that start to go beyond spark the good news is I've got a larger audience for my look now",
    "start": "42489",
    "end": "50100"
  },
  {
    "start": "50000",
    "end": "234000"
  },
  {
    "text": "but so we will start with a quick review of where the whole spark ecosystem is to",
    "start": "50100",
    "end": "56890"
  },
  {
    "text": "date and you can start off by thinking",
    "start": "56890",
    "end": "62470"
  },
  {
    "text": "of spark is similar to Hadoop and actually after alex's talk you can actually think of it even more",
    "start": "62470",
    "end": "68650"
  },
  {
    "text": "accurately as being similar to Scooby in that it's a data analysis big data and",
    "start": "68650",
    "end": "76510"
  },
  {
    "text": "that was just a framework that runs across a cluster for to add it has a scholar API to it and actually the skull",
    "start": "76510",
    "end": "83050"
  },
  {
    "text": "API for spark is almost identical to what the Scooby API is I mean you can",
    "start": "83050",
    "end": "88930"
  },
  {
    "text": "literally change a d-list to an RDD here and there a couple other keywords change and you can pretty much run the exact",
    "start": "88930",
    "end": "95800"
  },
  {
    "text": "same MapReduce job that you would run in scooby over on to spark spark actually",
    "start": "95800",
    "end": "101920"
  },
  {
    "text": "actually to do some things you can't do with Scooby so there's we can actually go further and run more generalized eggs",
    "start": "101920",
    "end": "107980"
  },
  {
    "text": "and actually will disagree what that looks a little bit later about the",
    "start": "107980",
    "end": "113350"
  },
  {
    "text": "viability of running machine learning jobs and such because right so we get to",
    "start": "113350",
    "end": "120370"
  },
  {
    "text": "more generalized graphs of MapReduce operations because one of the problems",
    "start": "120370",
    "end": "125410"
  },
  {
    "text": "that Alex talk to you a bit about was that with Hadoop being very much based",
    "start": "125410",
    "end": "131950"
  },
  {
    "text": "on HDFS on the reading things all from disk running one pass through your",
    "start": "131950",
    "end": "137200"
  },
  {
    "text": "MapReduce operation writing the results back out into disk that really limits you when you try and do interactive or",
    "start": "137200",
    "end": "144360"
  },
  {
    "text": "iterative kind of algorithms but one of the big differences with",
    "start": "144360",
    "end": "152110"
  },
  {
    "text": "spark is that instead of keeping your working data set back and forth off from",
    "start": "152110",
    "end": "159230"
  },
  {
    "text": "disk we actually stored in the ram the aggregate ram across the cluster which",
    "start": "159230",
    "end": "164930"
  },
  {
    "text": "means that once you've got your data set resonating Ram there you can actually iterate through it multiple times or you run an interactive query against it and",
    "start": "164930",
    "end": "171860"
  },
  {
    "text": "not have to spend the time waiting for to read off disc all the time so what",
    "start": "171860",
    "end": "177620"
  },
  {
    "text": "that amounts to is that we end up with much lower latency on these jobs to do I",
    "start": "177620",
    "end": "182989"
  },
  {
    "text": "mean this is 100 milliseconds is basically for a null job a job does nothing you're going to get the response",
    "start": "182989",
    "end": "190040"
  },
  {
    "text": "back 100 milliseconds where it doesn't sound all that great except when you look at what doing the equivalent in",
    "start": "190040",
    "end": "195980"
  },
  {
    "text": "Hadoop it would take you probably on the order of at least 30 seconds just to spin up to JVMs across the cluster and",
    "start": "195980",
    "end": "202040"
  },
  {
    "text": "still you're doing nothing so if you start to look at interactive kind of jobs something more like a traditional",
    "start": "202040",
    "end": "209150"
  },
  {
    "text": "database query where you want to issue an interactive query at a console and get a response back you really want to",
    "start": "209150",
    "end": "215030"
  },
  {
    "text": "see something that's kind of in some second or at worst a couple of seconds a response time and you're just not going",
    "start": "215030",
    "end": "221389"
  },
  {
    "text": "to get that with a Hadoop based clustering whereas we can do that over with bark and like I said before we can",
    "start": "221389",
    "end": "227690"
  },
  {
    "text": "actually start to run more iterative kinds of jobs as well and start to get into machine learning so spark was kind",
    "start": "227690",
    "end": "236810"
  },
  {
    "start": "234000",
    "end": "371000"
  },
  {
    "text": "of the first step along the path all these things are getting developed at the amp lab over at Berkeley it's a",
    "start": "236810",
    "end": "243489"
  },
  {
    "text": "group of graduate students and faculty over there it's actually starting to expand as well but so spark was well",
    "start": "243489",
    "end": "251030"
  },
  {
    "text": "actually more like the second major piece came out of there the earlier piece was on the gold mesos which we'll",
    "start": "251030",
    "end": "256130"
  },
  {
    "text": "see in just a little bit but after spark now we get to shark which if you think",
    "start": "256130",
    "end": "262370"
  },
  {
    "text": "of spark as being similar to do shark is similar to hive and what hive and sharp",
    "start": "262370",
    "end": "268729"
  },
  {
    "text": "what you do is such the issue SQL queries against your Hadoop cluster or",
    "start": "268729",
    "end": "274789"
  },
  {
    "text": "against your spark cluster so that opens up a whole it opens up being able to write jobs",
    "start": "274789",
    "end": "281910"
  },
  {
    "text": "against your clusters people that only no sequel or even equally important",
    "start": "281910",
    "end": "287130"
  },
  {
    "text": "there's a whole sets of tools and applications out there that know how to write read & write sequel and they can",
    "start": "287130",
    "end": "294090"
  },
  {
    "text": "actually interact with yours in spark cluster as well through sharp so",
    "start": "294090",
    "end": "299400"
  },
  {
    "text": "actually shark barrows directly from the hive libraries we take over the hive",
    "start": "299400",
    "end": "304949"
  },
  {
    "text": "metadata store the actual high ql query language which is like i said it's a",
    "start": "304949",
    "end": "311070"
  },
  {
    "text": "subset of sequel then we also use the hive parser and used hive to the hive",
    "start": "311070",
    "end": "317880"
  },
  {
    "text": "leverage to generate the logical plan but one actually gets submitted to the spark closer now we're running a",
    "start": "317880",
    "end": "323699"
  },
  {
    "text": "physical plant instead of the Hadoop physical plant so we start to get the",
    "start": "323699",
    "end": "329160"
  },
  {
    "text": "same kinds of speed of sweet because again we're using a memory sharing on this data set so what you end up doing",
    "start": "329160",
    "end": "335270"
  },
  {
    "text": "is issuing your gear sharp query",
    "start": "335270",
    "end": "340310"
  },
  {
    "text": "generating a result set from that that results that you cash across the memory",
    "start": "340310",
    "end": "346680"
  },
  {
    "text": "of the entire cluster and then you can run further interactive queries or more",
    "start": "346680",
    "end": "352020"
  },
  {
    "text": "quick short queries against it also when you we bring the stuff over into the",
    "start": "352020",
    "end": "357270"
  },
  {
    "text": "memory of the cluster we also converted over to a kilometer store format which then allows for a lot of compression",
    "start": "357270",
    "end": "364229"
  },
  {
    "text": "other speed ups as well and again so that maintains the low latency then the",
    "start": "364229",
    "end": "372690"
  },
  {
    "start": "371000",
    "end": "601000"
  },
  {
    "text": "next step beyond sharp was something called spark streaming which you can think of it as being somewhat similar to storm trident where we're taking sliding",
    "start": "372690",
    "end": "384000"
  },
  {
    "text": "windows over real time streaming events so we group up these events that are",
    "start": "384000",
    "end": "390449"
  },
  {
    "text": "streaming into your system and you have essentially running lots of small spark batch jobs against those windows of",
    "start": "390449",
    "end": "397860"
  },
  {
    "text": "events and if you can process those quickly enough which of course you couldn't do if you were doing it in at a",
    "start": "397860",
    "end": "404190"
  },
  {
    "text": "dupe based system but we can do with bark then you can keep up with your",
    "start": "404190",
    "end": "409530"
  },
  {
    "text": "stream of events and actually do real-time stream processing you know across your whole entire cluster so this",
    "start": "409530",
    "end": "417270"
  },
  {
    "text": "is what the Berkeley data analytics tech ends up looking like if you look at the",
    "start": "417270",
    "end": "423060"
  },
  {
    "text": "stuff in white that's all the existing open source stuff I mean you got your HDFS filesystem from badoo you got a",
    "start": "423060",
    "end": "430200"
  },
  {
    "text": "dupe itself I pig and there's other things that can use the HDFS things like",
    "start": "430200",
    "end": "437430"
  },
  {
    "text": "storm and mpi currents processing those kinds of things can stay within the",
    "start": "437430",
    "end": "442950"
  },
  {
    "text": "Berkeley data analytic stick because I mean HDFS kind of ends up being the",
    "start": "442950",
    "end": "448620"
  },
  {
    "text": "common denominator can the beneath all of these the bottom level there may so",
    "start": "448620",
    "end": "453840"
  },
  {
    "text": "that's a resource management framework if you familiar with yarn to cloud arrow",
    "start": "453840",
    "end": "461070"
  },
  {
    "text": "that's something similar with if you want to run so like if you want to run",
    "start": "461070",
    "end": "466740"
  },
  {
    "text": "MPI jobs or a storm cluster or a Hadoop cluster in a spark cluster at the same",
    "start": "466740",
    "end": "473219"
  },
  {
    "text": "time or multiple Hadoop clusters are multiple spark clusters that gets be",
    "start": "473219",
    "end": "478860"
  },
  {
    "text": "pretty much impossible unless you've got some sort of resource manager underneath allow you to share different resources",
    "start": "478860",
    "end": "484770"
  },
  {
    "text": "CPU and memory and such across the clusters that's what mais les allows you do like I say that was kind of the first",
    "start": "484770",
    "end": "490680"
  },
  {
    "text": "piece that came out of the amp web and has since been picked up by Twitter and",
    "start": "490680",
    "end": "496380"
  },
  {
    "text": "some others actually most the further development work isn't really done at Berkeley anymore basis so we've already",
    "start": "496380",
    "end": "505860"
  },
  {
    "text": "talked about the spark and shark and sparks trading pieces and so for the",
    "start": "505860",
    "end": "512550"
  },
  {
    "text": "five pieces don't even talking about tonight are then tachyon which was just",
    "start": "512550",
    "end": "518070"
  },
  {
    "text": "released a couple of weeks ago and then the next things that will probably I",
    "start": "518070",
    "end": "524970"
  },
  {
    "text": "mean let's say it's the most likely future for the whole spark ecosystem because these next pieces aren't",
    "start": "524970",
    "end": "530730"
  },
  {
    "text": "released yet they may change some before they actually do get released some of them are still kind of more research projects",
    "start": "530730",
    "end": "536190"
  },
  {
    "text": "so this is kind of the way things look now and there were things worth thinking about learning something about but",
    "start": "536190",
    "end": "542280"
  },
  {
    "text": "they've made up I'm not going to get into like trying to show you code or anything from these it's going to be kind of a high-level motivational kind",
    "start": "542280",
    "end": "549480"
  },
  {
    "text": "of discussion of these kinds of things yeah ah that's a good question because",
    "start": "549480",
    "end": "559950"
  },
  {
    "text": "the question is which parts will the book cover and spark and sharp and",
    "start": "559950",
    "end": "565920"
  },
  {
    "text": "streaming will definitely be there tachyon is an important enough piece that they'll probably parts of it that",
    "start": "565920",
    "end": "572490"
  },
  {
    "text": "are in there but tackling is also very new so it won't be an awful lot about it there graphics may get mentioned some an",
    "start": "572490",
    "end": "582830"
  },
  {
    "text": "FML basin blank dvd-r probably far enough in the future that they won't make it into this edition so so the",
    "start": "582830",
    "end": "592530"
  },
  {
    "text": "first thing we need to talk about is tachyon which gives us a reliable file-sharing had memory speed across the",
    "start": "592530",
    "end": "598560"
  },
  {
    "text": "cluster frameworks and ok yeah like I",
    "start": "598560",
    "end": "604770"
  },
  {
    "start": "601000",
    "end": "675000"
  },
  {
    "text": "said there was a recent spark user group meetup on this and thanks to stony the",
    "start": "604770",
    "end": "611700"
  },
  {
    "text": "video for that is available and that's really where you want to go if you want to try and find out more about what",
    "start": "611700",
    "end": "617580"
  },
  {
    "text": "tacky I was all about because like I say I'll be able to go through kind of the high-level motivational points about",
    "start": "617580",
    "end": "623850"
  },
  {
    "text": "tachyon but won't really be going into the details of it and ok one of do are",
    "start": "623850",
    "end": "630600"
  },
  {
    "text": "continuing to do our comparisons here you can think of it as similar to HDFS it's a distributed file system that's",
    "start": "630600",
    "end": "636180"
  },
  {
    "text": "easily used from MapReduce jobs Hadoop jobs or from spark in fact the spark and",
    "start": "636180",
    "end": "642420"
  },
  {
    "text": "shark API for reading and writing to you tagging out is essentially identical to what it is to write in HDFS so you can",
    "start": "642420",
    "end": "649350"
  },
  {
    "text": "literally write a job now that's going to read and write from HDFS change just a couple of lines and you're going to be",
    "start": "649350",
    "end": "655500"
  },
  {
    "text": "reading and writing from tachyon now why would you want to be doing that and",
    "start": "655500",
    "end": "662429"
  },
  {
    "text": "it what it mostly comes down to is that you want to be able to share data sets",
    "start": "662429",
    "end": "670160"
  },
  {
    "text": "among us Park and shark jobs right so if",
    "start": "670160",
    "end": "680009"
  },
  {
    "text": "we write to we look here we see tech and",
    "start": "680009",
    "end": "686730"
  },
  {
    "text": "is essentially working as a caching layer on top of some sort of existing underlying file system and in most cases",
    "start": "686730",
    "end": "694049"
  },
  {
    "text": "is going to be HDFS and so that you'll be reading and writing to you tachyon",
    "start": "694049",
    "end": "700230"
  },
  {
    "text": "and more than one Supporter MapReduce program can then see the same data set",
    "start": "700230",
    "end": "706649"
  },
  {
    "text": "within tech yeah you'd be able to do the same thing when HDFS made if you thought",
    "start": "706649",
    "end": "712170"
  },
  {
    "text": "about writing running one Hadoop job take the results of that write it out to HDFS then another job could pick up that",
    "start": "712170",
    "end": "718649"
  },
  {
    "text": "result set and start working further with it then that kind of thing was difficult to do before before we have",
    "start": "718649",
    "end": "726629"
  },
  {
    "text": "tachyon in spark or shark actually stealing a set of slides here from a",
    "start": "726629",
    "end": "731819"
  },
  {
    "text": "rental t key developer on shark and these are all mention shark but they pretty much applied to spark as well",
    "start": "731819",
    "end": "739489"
  },
  {
    "text": "because this is a situation we have I just running one shark job against the",
    "start": "739489",
    "end": "747449"
  },
  {
    "text": "cluster you end up taking blocks of data off from your HDFS filesystem reading",
    "start": "747449",
    "end": "753689"
  },
  {
    "text": "them into the memory of the shark system and then you can run I instead of",
    "start": "753689",
    "end": "759989"
  },
  {
    "text": "interactive jobs across that but that's really limited to this one sharp context",
    "start": "759989",
    "end": "767129"
  },
  {
    "text": "that has access to that memory your problem then is if you have more than",
    "start": "767129",
    "end": "772410"
  },
  {
    "text": "one user or you have more than one job that wants to access this same set of data that's no resident in memory it's",
    "start": "772410",
    "end": "779759"
  },
  {
    "text": "not really a good way to do that what you end up having to do r is there's",
    "start": "779759",
    "end": "786269"
  },
  {
    "text": "actually something called the Sharks server which essentially adds a server layer on top of this that instead of one",
    "start": "786269",
    "end": "793319"
  },
  {
    "text": "user one job directly interacting with a sharp and context he goes through a server layer that's going to then",
    "start": "793319",
    "end": "798780"
  },
  {
    "text": "aggregate multiple jobs and share this out one shark context and I could skip",
    "start": "798780",
    "end": "808170"
  },
  {
    "text": "the slide oh okay and that's fine as far as it goes but you've actually there's",
    "start": "808170",
    "end": "817740"
  },
  {
    "text": "two tight and coupling between the actual the job that's between the",
    "start": "817740",
    "end": "823710"
  },
  {
    "text": "execution part of the job and the storage layer part of the job because what ends up happening is that if that",
    "start": "823710",
    "end": "828960"
  },
  {
    "text": "shark server ends up crashing on you well it usually doesn't end up stopping",
    "start": "828960",
    "end": "834690"
  },
  {
    "text": "there what happens next is that you lose the entire storage layer as well so now",
    "start": "834690",
    "end": "840660"
  },
  {
    "text": "you've a grenade at multiple jobs into this one and shower context and now everybody's job is dead and it's not",
    "start": "840660",
    "end": "847500"
  },
  {
    "text": "only that there's not really a good way to recover you've got to go all the way back not to you HDFS and restart that",
    "start": "847500",
    "end": "853340"
  },
  {
    "text": "and you can try and compensate for that some by running multiple spark spark or",
    "start": "853340",
    "end": "859710"
  },
  {
    "text": "shower context but now the problem is that we end up even want to protect",
    "start": "859710",
    "end": "866040"
  },
  {
    "text": "against losing a set of data we end up having to duplicated across multiple of",
    "start": "866040",
    "end": "872970"
  },
  {
    "text": "sparkle share context and so we're duplicating the amount of memory that we're using across the cluster and what",
    "start": "872970",
    "end": "882000"
  },
  {
    "text": "we really want this to you added a separate layer in there to kind of separate out the execution from the",
    "start": "882000",
    "end": "887850"
  },
  {
    "text": "storage layer because what ends up happening now is that you've what's",
    "start": "887850",
    "end": "895980"
  },
  {
    "text": "going on here hello something now it's working",
    "start": "895980",
    "end": "906279"
  },
  {
    "text": "correctly here yeah but what is we're supposed to be showing that if say this",
    "start": "906279",
    "end": "911529"
  },
  {
    "text": "cluster crashes with tachyon system the",
    "start": "911529",
    "end": "917589"
  },
  {
    "text": "other guy will still be able to access the data sets that it'd still be a resident attacking the tech aunt won't",
    "start": "917589",
    "end": "924430"
  },
  {
    "text": "crash just because the execution engine crashed now and because of some of the",
    "start": "924430",
    "end": "930520"
  },
  {
    "text": "details of the way tacking on is it is implemented that I won't be able to go",
    "start": "930520",
    "end": "935770"
  },
  {
    "text": "into it actually stores a lineage of how a data set was correct how I data set",
    "start": "935770",
    "end": "943420"
  },
  {
    "text": "was constructed and so if we do end up losing a piece out of a piece of",
    "start": "943420",
    "end": "951850"
  },
  {
    "text": "attacking our data that was stored one of the nodes in the cluster if that note goes down it said we're actually able to",
    "start": "951850",
    "end": "958240"
  },
  {
    "text": "or quickly recover that and so we do get a instantaneous recovery with into",
    "start": "958240",
    "end": "966130"
  },
  {
    "start": "963000",
    "end": "1078000"
  },
  {
    "text": "account your release yet to develop a release so it's not really production",
    "start": "966130",
    "end": "971350"
  },
  {
    "text": "ready yet and we do do our db's are kind of equivalent to these d lists that Alex",
    "start": "971350",
    "end": "977320"
  },
  {
    "text": "talked about before it's kind of the fundamental abstraction of what a piece of data is our DD is a resilient",
    "start": "977320",
    "end": "983830"
  },
  {
    "text": "distributed data sets of these these distributed collections across the cluster memory and some support for",
    "start": "983830",
    "end": "991330"
  },
  {
    "text": "those sharing and cashing those is in the current developer release there's an",
    "start": "991330",
    "end": "996339"
  },
  {
    "text": "HDFS API to it so you can actually you're right Hadoop MapReduce jobs using",
    "start": "996339",
    "end": "1001709"
  },
  {
    "text": "tachyon but things like being able to",
    "start": "1001709",
    "end": "1006900"
  },
  {
    "text": "directly put these column-oriented storage that I talked about from shark before you can't eventually we'll be",
    "start": "1006900",
    "end": "1013410"
  },
  {
    "text": "able to take those and write those directly into tachyon as well so if you thought about it before you write you",
    "start": "1013410",
    "end": "1020250"
  },
  {
    "text": "would read your shark data off from HDFS and change it over two kilometers storage in RAM and then have to write it",
    "start": "1020250",
    "end": "1027300"
  },
  {
    "text": "back out to the non kilometer and storage format bacon back in hdfs eventually with attacking",
    "start": "1027300",
    "end": "1033640"
  },
  {
    "text": "out you'll be able to take that converted kilometer store and put it directly as a raw table into tachyon and",
    "start": "1033640",
    "end": "1040808"
  },
  {
    "text": "not pay that kind of reorganization cost multiple times and then the next release",
    "start": "1040809",
    "end": "1047260"
  },
  {
    "text": "also introduced full tolerance for there is a master node in tacky and currently",
    "start": "1047260",
    "end": "1053530"
  },
  {
    "text": "that's kind of similar to the Hadoop name node and that's a single point of failure right now it will take to be",
    "start": "1053530",
    "end": "1060280"
  },
  {
    "text": "taking care of that and then next release and there actually is potential",
    "start": "1060280",
    "end": "1065380"
  },
  {
    "text": "for further releases you start to support that kind of directly writing beautiful changes to your data set again",
    "start": "1065380",
    "end": "1072460"
  },
  {
    "text": "attacking on itself so those are all things that will be coming down the road but are really there yet so graphics",
    "start": "1072460",
    "end": "1082030"
  },
  {
    "start": "1078000",
    "end": "1092000"
  },
  {
    "text": "okay we're back to you a hard diagram here so graphics is something that's built on top of spark and but we're",
    "start": "1082030",
    "end": "1091000"
  },
  {
    "text": "looking at graph processing now yes so so there's what kind of trying not these",
    "start": "1091000",
    "end": "1100510"
  },
  {
    "start": "1092000",
    "end": "1590000"
  },
  {
    "text": "didn't talk too much about graphics tonight because the Berkeley guys haven't really talked about it yet that's really just kind of one paper out",
    "start": "1100510",
    "end": "1106600"
  },
  {
    "text": "there now and this is a very nice short paper it's like a six page paper you take a look at it you can learn an awful",
    "start": "1106600",
    "end": "1113290"
  },
  {
    "text": "lot more about more about how it's actually implemented so I'm just going to give you the high level again what",
    "start": "1113290",
    "end": "1120280"
  },
  {
    "text": "this is all about so graph data structures and algorithms are quite important now if you want to look at the",
    "start": "1120280",
    "end": "1126610"
  },
  {
    "text": "data I'm sure a lot of you are familiar with like social network graphs and stuff that are out there now and that's",
    "start": "1126610",
    "end": "1134620"
  },
  {
    "text": "kind of a familiar one to a lot of us but there are a lot of other kind of data sets out there they're kind of fundamentally graph warranted in nature",
    "start": "1134620",
    "end": "1141250"
  },
  {
    "text": "and then there's certain algorithms that are most easily expressed as graph",
    "start": "1141250",
    "end": "1146799"
  },
  {
    "text": "algorithms as well about nodes communicating messages to other nodes so",
    "start": "1146799",
    "end": "1152740"
  },
  {
    "text": "if you look at how PageRank algorithm it's all about well in the context of",
    "start": "1152740",
    "end": "1158080"
  },
  {
    "text": "websites is about which websites are connected to other websites and so there's a natural graph",
    "start": "1158080",
    "end": "1164450"
  },
  {
    "text": "kind of orientation there and so if you actually try and write page rank and",
    "start": "1164450",
    "end": "1169790"
  },
  {
    "text": "Hadoop with its data parallelism orientation it's got a difficult to do it and you much rather have a set of",
    "start": "1169790",
    "end": "1176510"
  },
  {
    "text": "graph primitives that allow you to say these are nodes these are edges between the nose these are messages that are",
    "start": "1176510",
    "end": "1181850"
  },
  {
    "text": "getting past this is what you do when you get a message and that sort of thing and so that's what graphics and other",
    "start": "1181850",
    "end": "1188120"
  },
  {
    "text": "graph processing frameworks and start to allow you to do so the aim of the graph",
    "start": "1188120",
    "end": "1195290"
  },
  {
    "text": "parallelism is to reduce the communication and computation by exploiting the graph structure itself so",
    "start": "1195290",
    "end": "1201650"
  },
  {
    "text": "like I said if you try to write these algorithms using kind of the normal Hadoop primitives you have doing a lot",
    "start": "1201650",
    "end": "1208520"
  },
  {
    "text": "of extra computation and communication across all these nodes because do",
    "start": "1208520",
    "end": "1213740"
  },
  {
    "text": "fundamentally wants to scan through the entire set of data and do something to",
    "start": "1213740",
    "end": "1219650"
  },
  {
    "text": "it instead of being able to work with reduced set okay so yeah the first",
    "start": "1219650",
    "end": "1226430"
  },
  {
    "text": "problem we have in trying to do any kind of graph processing is that the data that we get typically needs to be munge",
    "start": "1226430",
    "end": "1233930"
  },
  {
    "text": "door mangled into some sort of graph of appropriate format I mean data sets you",
    "start": "1233930",
    "end": "1239870"
  },
  {
    "text": "get out there aren't already set up to be used directly in their expressed as nodes and edges you have to kind of",
    "start": "1239870",
    "end": "1246770"
  },
  {
    "text": "manipulate the existing data North turn it into a usable graph and then once",
    "start": "1246770",
    "end": "1254870"
  },
  {
    "text": "you've actually got and then expressed as a graph your graph algorithms like I've said before don't typically want to",
    "start": "1254870",
    "end": "1260510"
  },
  {
    "text": "run efficiently or then they're not easily expressed a framework like",
    "start": "1260510",
    "end": "1266870"
  },
  {
    "text": "mapreduce so these solutions to these are you need to do you you typically end",
    "start": "1266870",
    "end": "1274640"
  },
  {
    "text": "up needing to do your data munging or data wrangling with a separate tool from your actual graph processing framework",
    "start": "1274640",
    "end": "1281810"
  },
  {
    "text": "so oftentimes actually MapReduce similarly or two parameters can actually",
    "start": "1281810",
    "end": "1287030"
  },
  {
    "text": "do that quite well so you there may be",
    "start": "1287030",
    "end": "1291880"
  },
  {
    "text": "yes so there are there are existing graph parallel tools and frameworks out",
    "start": "1292060",
    "end": "1297680"
  },
  {
    "text": "there things like right so these are all working with passing messages between be",
    "start": "1297680",
    "end": "1304790"
  },
  {
    "text": "aa graph nodes and so there are things out there like prego which is a batch of",
    "start": "1304790",
    "end": "1313190"
  },
  {
    "text": "synchronous parallel processing what amounts to said these work it kind of as",
    "start": "1313190",
    "end": "1319600"
  },
  {
    "text": "synchronous and super steps so you may have this whole class set of nodes and",
    "start": "1319600",
    "end": "1325700"
  },
  {
    "text": "connections they know the messages they want to send and so you get it gets step through in a synchronous fashion that",
    "start": "1325700",
    "end": "1331940"
  },
  {
    "text": "all the nodes are going to generate a message all of them are going to send to the next nodes in this step of this",
    "start": "1331940",
    "end": "1337310"
  },
  {
    "text": "super loop in this super step and then we're all going to coordinate and",
    "start": "1337310",
    "end": "1342590"
  },
  {
    "text": "generate the next message when we're on the next super step and so the process indeed you process in this kind of",
    "start": "1342590",
    "end": "1347660"
  },
  {
    "text": "synchronous fashion and there are other things out there like GraphLab and it's powered graph set of algorithms it",
    "start": "1347660",
    "end": "1355580"
  },
  {
    "text": "actually can work asynchronously which can actually end up providing you a lot",
    "start": "1355580",
    "end": "1360610"
  },
  {
    "text": "better speed up but in both of these cases like i said before you typically",
    "start": "1360610",
    "end": "1367100"
  },
  {
    "text": "end up needing to do a data wrangling step before that so you have kind of in a two-phase kind of operation wear first",
    "start": "1367100",
    "end": "1373970"
  },
  {
    "text": "we're going to manipulate the whatever raw format of the data we got into a graph format and then we're going to run",
    "start": "1373970",
    "end": "1380090"
  },
  {
    "text": "these graph processing tools against it so graphics replaces the earlier bagel",
    "start": "1380090",
    "end": "1389330"
  },
  {
    "text": "library which is used to be well it still actually is in the spark code and",
    "start": "1389330",
    "end": "1395150"
  },
  {
    "text": "bagel is kind of an implementation of prego but using a spark instead of",
    "start": "1395150",
    "end": "1400970"
  },
  {
    "text": "Hadoop that graphics just to borrow ideas from GraphLab one of which is",
    "start": "1400970",
    "end": "1408860"
  },
  {
    "text": "vertex cut algorithms and some of these details like I said you can find in that paper or referenced earlier it's tightly",
    "start": "1408860",
    "end": "1416930"
  },
  {
    "text": "integrated with spark so yeah so we adding a new data abstraction called a",
    "start": "1416930",
    "end": "1424340"
  },
  {
    "text": "resilient distributed graph again those details are in the paper and we're not going to get into too much tonight",
    "start": "1424340",
    "end": "1430730"
  },
  {
    "text": "and yet it's getting kind of interesting that these new frameworks get",
    "start": "1430730",
    "end": "1438140"
  },
  {
    "text": "implemented on top of spark and get implemented in an astonishing small amount of code I kind of expect that",
    "start": "1438140",
    "end": "1444950"
  },
  {
    "text": "Reynold will be presenting our graphics in the not-too-distant future and he'll get into a lot of these into a lot of",
    "start": "1444950",
    "end": "1452030"
  },
  {
    "text": "these know details that are also in that paper and you'll find that the framework",
    "start": "1452030",
    "end": "1459830"
  },
  {
    "text": "itself is a small amount of code then actual jobs expressed using the",
    "start": "1459830",
    "end": "1465950"
  },
  {
    "text": "framework or very tiny amounts of code I mean the entire PageRank algorithm can be implemented just a handful of lines",
    "start": "1465950",
    "end": "1472880"
  },
  {
    "text": "of code okay so then when we look at",
    "start": "1472880",
    "end": "1478970"
  },
  {
    "text": "performance of graphics so I talked before about prego which is kind of this",
    "start": "1478970",
    "end": "1485120"
  },
  {
    "text": "Hadoop oriented that synchronous processing our kind of way of doing",
    "start": "1485120",
    "end": "1490340"
  },
  {
    "text": "things and then there's also graph lab which is asynchronous way of doing things and so if you implement the same",
    "start": "1490340",
    "end": "1497299"
  },
  {
    "text": "page rank algorithm on both of those you'll find that graphics runs roughly",
    "start": "1497299",
    "end": "1503690"
  },
  {
    "text": "an order of magnitude faster then Fragel does but it runs an order of magnitude slower than what GraphLab does so it's",
    "start": "1503690",
    "end": "1511040"
  },
  {
    "text": "kind of fitting in between what that amounts to in a practical sense is it",
    "start": "1511040",
    "end": "1517669"
  },
  {
    "text": "the graphics will probably never be equal in performance to the specialized",
    "start": "1517669",
    "end": "1522950"
  },
  {
    "text": "tools that are out there like GraphLab",
    "start": "1522950",
    "end": "1526929"
  },
  {
    "text": "but it's because of the nature of spark",
    "start": "1530110",
    "end": "1535520"
  },
  {
    "text": "and it's low latency will actually be able to interactively or iteratively change the graph structure that we're",
    "start": "1535520",
    "end": "1542540"
  },
  {
    "text": "working with which is something you can't do in that two-phase process I was talking about before because your data",
    "start": "1542540",
    "end": "1549470"
  },
  {
    "text": "ranking Wrangler data munging step using Hadoop MapReduce that's going to take you it's an all-day batch kind of job so",
    "start": "1549470",
    "end": "1556400"
  },
  {
    "text": "much what else was talking about before whereas if we can keep that all within those two steps all both within the same",
    "start": "1556400",
    "end": "1563900"
  },
  {
    "text": "Berkeley data analytics tack and then we can do interactive or updates of the",
    "start": "1563900",
    "end": "1569870"
  },
  {
    "text": "actual graph itself so even though the final graph processing algorithms may",
    "start": "1569870",
    "end": "1575900"
  },
  {
    "text": "not run as quickly as what what a more specialized tool like GraphLab can do it with there may be enough advantages that",
    "start": "1575900",
    "end": "1582530"
  },
  {
    "text": "this kind of intermediate performance will still be an overall win in the end",
    "start": "1582530",
    "end": "1589090"
  },
  {
    "start": "1590000",
    "end": "2024000"
  },
  {
    "text": "okay so let's move on to the next piece and this is ml base so again we're back",
    "start": "1590169",
    "end": "1598400"
  },
  {
    "text": "to another piece that's built on top of spark and yea though ba the San",
    "start": "1598400",
    "end": "1607970"
  },
  {
    "text": "Francisco Bay Area machine learning meetup is a week from tonight and that's will actually be presenting on mo base",
    "start": "1607970",
    "end": "1613480"
  },
  {
    "text": "for the first time and where is it yelp",
    "start": "1613480",
    "end": "1621169"
  },
  {
    "text": "I think and I checked a couple of hours",
    "start": "1621169",
    "end": "1626780"
  },
  {
    "text": "ago and there's still a few slots available there so if you get enough interested in saw I'm actually going to",
    "start": "1626780",
    "end": "1633200"
  },
  {
    "text": "try and do this all with a single slide here so what we need to do first is kind",
    "start": "1633200",
    "end": "1638570"
  },
  {
    "text": "of ignored the ml machine learning kind of tags that are applied to this and",
    "start": "1638570",
    "end": "1644840"
  },
  {
    "text": "think of this as just a typical relational database kind of model so in",
    "start": "1644840",
    "end": "1651049"
  },
  {
    "text": "your normal our DBMS you come in with a year end user is kind of this guy in",
    "start": "1651049",
    "end": "1658490"
  },
  {
    "text": "orange of the top and he doesn't really know all the details of a relational database is implemented",
    "start": "1658490",
    "end": "1664919"
  },
  {
    "text": "doesn't know really anything much about about past joins or loop joins they're",
    "start": "1664919",
    "end": "1673739"
  },
  {
    "text": "all the different possibilities of how things are actually implemented within the database what he's giving you as an SQL query which is a pretty high level",
    "start": "1673739",
    "end": "1681679"
  },
  {
    "text": "description of what the kind of results he wants not how the job is actually done and the system will take that and",
    "start": "1681679",
    "end": "1690169"
  },
  {
    "text": "parse it or run a query planner against it run an optimizer against it generates",
    "start": "1690169",
    "end": "1695969"
  },
  {
    "text": "some sort of physical plant against that and then that will eventually get from run against the database and you're",
    "start": "1695969",
    "end": "1704519"
  },
  {
    "text": "smart guy over there he's the one that ends up having to write all those low-level database details about how",
    "start": "1704519",
    "end": "1711239"
  },
  {
    "text": "things actually get implemented and how they optimizer itself runs and that sort of thing so what ml bases are attempting",
    "start": "1711239",
    "end": "1720359"
  },
  {
    "text": "to do is something a similar sort of model but instead of issuing sequel",
    "start": "1720359",
    "end": "1727679"
  },
  {
    "text": "queries against the database what we want to be able to do is our issue machine learning-based queries so you",
    "start": "1727679",
    "end": "1734609"
  },
  {
    "text": "may say instead of select these rows from a database you may end up setting against this database I want you to",
    "start": "1734609",
    "end": "1741509"
  },
  {
    "text": "cluster it for me and so then that high-level description of what you want",
    "start": "1741509",
    "end": "1747659"
  },
  {
    "text": "will get passed into a inquiry planner and optimizer and similar to what the",
    "start": "1747659",
    "end": "1755279"
  },
  {
    "text": "sequel way of doing things is and that will turn into sort of run time jobs",
    "start": "1755279",
    "end": "1761279"
  },
  {
    "text": "against a spark cluster which will ya",
    "start": "1761279",
    "end": "1766320"
  },
  {
    "text": "again I don't want to go too much into the details because these are be stepping on the toes of the guys",
    "start": "1766320",
    "end": "1771509"
  },
  {
    "text": "presenting in a week here but that should be I hope sufficient to get you",
    "start": "1771509",
    "end": "1781019"
  },
  {
    "text": "answers in the idea of being able to I mean one of the big problems we faced",
    "start": "1781019",
    "end": "1786629"
  },
  {
    "text": "with in with in machine learning or data",
    "start": "1786629",
    "end": "1791999"
  },
  {
    "text": "analysis right now is there's just not enough of these smart guys they know how to actually run all the",
    "start": "1791999",
    "end": "1797570"
  },
  {
    "text": "tools at all of the at the level of detail that the frameworks require so if",
    "start": "1797570",
    "end": "1802670"
  },
  {
    "text": "you have a a system like this then allows you to express a query at a much higher level and be able to handle the",
    "start": "1802670",
    "end": "1811400"
  },
  {
    "text": "creation of the plans the running of those the evaluating at the results of those and presenting those at all at a",
    "start": "1811400",
    "end": "1816440"
  },
  {
    "text": "higher level to the ID user is something that's very valuable that actually like",
    "start": "1816440",
    "end": "1821600"
  },
  {
    "text": "look like they are this diagram shows I mean that kind of high level stuff will",
    "start": "1821600",
    "end": "1828950"
  },
  {
    "text": "only be in phase 2 of ML base the first phase of it will be really implementing",
    "start": "1828950",
    "end": "1834470"
  },
  {
    "text": "kind of more than low-level libraries yeah it's doing yeah so those kind of",
    "start": "1834470",
    "end": "1844700"
  },
  {
    "text": "things I mean exactly how all the details of this are going to work out is still yet to be seen but yeah when so",
    "start": "1844700",
    "end": "1851060"
  },
  {
    "text": "when you ask for something to be clustered the planet can end up generating may end up I mean when you've",
    "start": "1851060",
    "end": "1857570"
  },
  {
    "text": "asked for clustering you haven't told it which clustering a laburar to use I",
    "start": "1857570",
    "end": "1862690"
  },
  {
    "text": "can't really speak to the details too much but I mean my understanding is this would be part of mean both yeah right",
    "start": "1865690",
    "end": "1881320"
  },
  {
    "text": "yeah again these are probably questions at a better reserved for the guys next week but the over idea is that you'll be",
    "start": "1882870",
    "end": "1890440"
  },
  {
    "text": "able to express your desire at a high level that will actually end up can be",
    "start": "1890440",
    "end": "1895990"
  },
  {
    "text": "implemented as a plan that's going to execute potentially multiple clustering algorithms or multiple other machine",
    "start": "1895990",
    "end": "1902320"
  },
  {
    "text": "learning algorithms and then be able to present to you some results of those that are expressing how well each of the",
    "start": "1902320",
    "end": "1909730"
  },
  {
    "text": "different clustering algorithms worked and there's a least one paper out there",
    "start": "1909730",
    "end": "1916750"
  },
  {
    "text": "i believe i'd have to look of it in the",
    "start": "1916750",
    "end": "1922390"
  },
  {
    "text": "details exactly he was working on it for you it's up there I believe there's",
    "start": "1922390",
    "end": "1929669"
  },
  {
    "text": "from which",
    "start": "1936940",
    "end": "1940090"
  },
  {
    "text": "yeah I don't know if there's a paper specific to what you're asking about but I think there is at least one paper out",
    "start": "1948720",
    "end": "1954539"
  },
  {
    "text": "there on mo base there should be a believe this an ml based web page is accessible off from the main app 11 page",
    "start": "1954539",
    "end": "1961830"
  },
  {
    "text": "as well yes sometimes these papers are a",
    "start": "1961830",
    "end": "1970350"
  },
  {
    "text": "little bit in a tricky to find but I'm sure the guys next week will be giving you an awful lot more of pointers as to",
    "start": "1970350",
    "end": "1975990"
  },
  {
    "text": "what's up yeah and some of this stuff",
    "start": "1975990",
    "end": "1981090"
  },
  {
    "text": "has actually introduced it on amp Lev retreat in just over this past couple of days and not all those details have been",
    "start": "1981090",
    "end": "1988320"
  },
  {
    "text": "public released either anyway you should hopefully at least from that you can get the basic idea of being able to express",
    "start": "1988320",
    "end": "1995580"
  },
  {
    "text": "machine learning queries in kind of the same fashion as what you express sequel",
    "start": "1995580",
    "end": "2000799"
  },
  {
    "text": "queries and so these low-level libraries that will be in the first phase of development that was actually end up",
    "start": "2000799",
    "end": "2006380"
  },
  {
    "text": "being conceptually somewhat similar to like mahout or other machine learning",
    "start": "2006380",
    "end": "2011539"
  },
  {
    "text": "libraries that are out there that are Hadoop specific but these will be the spark specific and then able to be",
    "start": "2011539",
    "end": "2018500"
  },
  {
    "text": "optimized for the way spark can handle things in memory and such so now we're",
    "start": "2018500",
    "end": "2025700"
  },
  {
    "start": "2024000",
    "end": "2059000"
  },
  {
    "text": "starting to get off in kind of really into the research fringe with something called blink DB and this is all relies",
    "start": "2025700",
    "end": "2034850"
  },
  {
    "text": "heavily upon using approximate answers to your queries which becomes important",
    "start": "2034850",
    "end": "2040400"
  },
  {
    "text": "Aleksei yeah it's a research effort now you're not going to see a lot in the way of really anywhere close to production",
    "start": "2040400",
    "end": "2046669"
  },
  {
    "text": "rutted code for a while and this post of yarn Stojko up at the amp web is thomas",
    "start": "2046669",
    "end": "2055460"
  },
  {
    "text": "pretty much when i'm covering tonight but in more detail it's kind of a it's a",
    "start": "2055460",
    "end": "2060618"
  },
  {
    "start": "2059000",
    "end": "2099000"
  },
  {
    "text": "good motivational paper but we're still not seeing anything in the way of details about how things are actually implemented so the problem that we're",
    "start": "2060619",
    "end": "2067128"
  },
  {
    "text": "facing right now is that the rate of growth in the available computational",
    "start": "2067129",
    "end": "2072408"
  },
  {
    "text": "resources it pretty well understood me that's going by Moore's law essentially you have a pretty good idea of how much",
    "start": "2072409",
    "end": "2078589"
  },
  {
    "text": "more computing power you're going to have two years from now right now but we're also starting to see",
    "start": "2078589",
    "end": "2084700"
  },
  {
    "text": "that the rate of growth of data is actually exceeding Moore's law and I mean at first you think that well we're",
    "start": "2084700",
    "end": "2093608"
  },
  {
    "text": "doomed at mean we're just going to get overwhelmed by the amount of data that's out there is no way we're going to be able to keep up with it but if you start",
    "start": "2093609",
    "end": "2101080"
  },
  {
    "start": "2099000",
    "end": "2354000"
  },
  {
    "text": "to look at the key insight this problem is that right now we're generally computing exact answers to things we go",
    "start": "2101080",
    "end": "2108730"
  },
  {
    "text": "through all of our entire data set and run a clustering against it or something or do some sort of machine learning",
    "start": "2108730",
    "end": "2115300"
  },
  {
    "text": "algorithm against the entire data set and that gets us as good an answer who",
    "start": "2115300",
    "end": "2120700"
  },
  {
    "text": "could possibly get but I put the exact in quotes because it's still really not",
    "start": "2120700",
    "end": "2126010"
  },
  {
    "text": "a perfect answer because our data sets aren't perfect there's a certain amount of error present in the data so what's",
    "start": "2126010",
    "end": "2132190"
  },
  {
    "text": "the point of computing this exact answer when statistically there's still going to be error present of whatever you",
    "start": "2132190",
    "end": "2137530"
  },
  {
    "text": "compute and so most the time approximate answers are good enough if we can define",
    "start": "2137530",
    "end": "2144160"
  },
  {
    "text": "to know that we're going to have our error bounded by a certain amount it's usually actually maybe that's what we",
    "start": "2144160",
    "end": "2151390"
  },
  {
    "text": "got with our exact answer before we just were kind of hiding the fact that there was error involved and to create",
    "start": "2151390",
    "end": "2160000"
  },
  {
    "text": "approximate answers you don't need to be looking at the entire data set you're going to be looking at just a sample and",
    "start": "2160000",
    "end": "2167220"
  },
  {
    "text": "what's really important is that the growth in the sample size is needed to",
    "start": "2167220",
    "end": "2174250"
  },
  {
    "text": "maintain a certain error bound actually occur is much slower you know what",
    "start": "2174250",
    "end": "2179260"
  },
  {
    "text": "Moore's law it says so if you're if you get twice as much data two years from",
    "start": "2179260",
    "end": "2186339"
  },
  {
    "text": "now you won't the size of the sample that you will need to create the same error that you did before will not be",
    "start": "2186339",
    "end": "2192609"
  },
  {
    "text": "twice as great and so Moore's law can actually more than keep up with a rate",
    "start": "2192609",
    "end": "2199089"
  },
  {
    "text": "of sample size growth even given the higher rate of overall data growth that",
    "start": "2199089",
    "end": "2205570"
  },
  {
    "text": "we're seeing so what actually ends up happening is that we're not doomed we're",
    "start": "2205570",
    "end": "2210760"
  },
  {
    "text": "actually better than saved because because we're more giving us is increasing faster than what",
    "start": "2210760",
    "end": "2217880"
  },
  {
    "text": "the required sample size is we can actually improve the accuracy of our",
    "start": "2217880",
    "end": "2224180"
  },
  {
    "text": "results over time that's one option and that's kind of what this graph at the bottom is showing you Moore's Law is",
    "start": "2224180",
    "end": "2230390"
  },
  {
    "text": "going in the gray there which is probably hard to see data is going up with a green line but the actual size of",
    "start": "2230390",
    "end": "2237200"
  },
  {
    "text": "your error is actually decreasing over time the other option you can take is to",
    "start": "2237200",
    "end": "2244130"
  },
  {
    "text": "get the same level of accuracy just faster or you can start to run",
    "start": "2244130",
    "end": "2251210"
  },
  {
    "text": "additional tests additional queries against the same data and so that will",
    "start": "2251210",
    "end": "2256790"
  },
  {
    "text": "hopefully give you much richer insights so the whole point of all this is that if you can architect your system be",
    "start": "2256790",
    "end": "2264200"
  },
  {
    "text": "using samples and approximate answers actually your future is looking pretty",
    "start": "2264200",
    "end": "2269359"
  },
  {
    "text": "good even though the amount of data is increasing at this seemingly",
    "start": "2269359",
    "end": "2275890"
  },
  {
    "text": "insurmountable rate I mean it's really not a problem as long as you can handle approximate answers and samples so right",
    "start": "2276220",
    "end": "2289400"
  },
  {
    "text": "so when we're going back to this look at blink TB is now implemented kind of above shark and hive so the idea is that",
    "start": "2289400",
    "end": "2296329"
  },
  {
    "text": "it's going to be another SQL kind of base query so you're going to have sequel queries that will then be",
    "start": "2296329",
    "end": "2303109"
  },
  {
    "text": "expressed with an error bound and a time in which you want to get an approximate error as her back and like I say that's",
    "start": "2303109",
    "end": "2311240"
  },
  {
    "text": "just one kind of research effort that's out there but it's worth really keeping an eye on me this is a pretty key idea",
    "start": "2311240",
    "end": "2318619"
  },
  {
    "text": "going forward so it's not just blink DB that you need to be looking at but how other systems are going to be answering",
    "start": "2318619",
    "end": "2324470"
  },
  {
    "text": "this approximation and sample size sample size kind of problem in the future so now we're actually up to you",
    "start": "2324470",
    "end": "2333200"
  },
  {
    "text": "those are the four pieces that are coming out of the amp web and now i'm actually going off into the piece that",
    "start": "2333200",
    "end": "2339140"
  },
  {
    "text": "I'm more directly involved with so that's outside of the amp web",
    "start": "2339140",
    "end": "2344740"
  },
  {
    "text": "and the problem we're facing right now is that we need to be able to improve",
    "start": "2345790",
    "end": "2351470"
  },
  {
    "text": "the code bases out there but we're starting to step on each other's toes and try to do so so sparking related",
    "start": "2351470",
    "end": "2359690"
  },
  {
    "text": "khodam and things like shark and spark streaming tachyon it's like I said before it's actually a surprisingly",
    "start": "2359690",
    "end": "2364700"
  },
  {
    "text": "small code base so that means it's pretty easy to understand it comprehend it and the development community around",
    "start": "2364700",
    "end": "2373250"
  },
  {
    "text": "it is pretty open and friendly so it's pretty easy to get started using it and",
    "start": "2373250",
    "end": "2378460"
  },
  {
    "text": "there actually are a quickly growing number of contributors to the code base",
    "start": "2378460",
    "end": "2383620"
  },
  {
    "text": "but the smallness of the code is actually a problem for us as well",
    "start": "2383620",
    "end": "2388750"
  },
  {
    "text": "because everybody's crammed into this one small piece of code and so we're starting to bump into each other more",
    "start": "2388750",
    "end": "2394940"
  },
  {
    "text": "and more and so who is this we that we're talking about they're running",
    "start": "2394940",
    "end": "2400520"
  },
  {
    "text": "these problems well a couple of years ago it was just grad students and",
    "start": "2400520",
    "end": "2406520"
  },
  {
    "text": "faculty over at the amp web but that's starting to expand now that the amp lab",
    "start": "2406520",
    "end": "2411830"
  },
  {
    "text": "itself has hired on a group of staff developers they're headed up a guy named",
    "start": "2411830",
    "end": "2417740"
  },
  {
    "text": "Matt Massey so if you're an Android developer wanting to use the Berkeley",
    "start": "2417740",
    "end": "2422990"
  },
  {
    "text": "data analytics stack that's a good guy to know and his group was kind of test",
    "start": "2422990",
    "end": "2429080"
  },
  {
    "text": "with turning this amp web code into production production ready distribution",
    "start": "2429080",
    "end": "2435040"
  },
  {
    "text": "so being able to easily deploy the code make sure it runs 24 7 all those kinds",
    "start": "2435040",
    "end": "2440780"
  },
  {
    "text": "of good things that are typically associated with research projects out of academics but the apple app is starting",
    "start": "2440780",
    "end": "2447590"
  },
  {
    "text": "to try and push it more in that direction and the that groups also has",
    "start": "2447590",
    "end": "2453380"
  },
  {
    "text": "the task of maintaining developer relations with outside developers then",
    "start": "2453380",
    "end": "2459730"
  },
  {
    "text": "there's also academics outside of the amp lab there's some of them other",
    "start": "2459730",
    "end": "2464780"
  },
  {
    "text": "groups at Berkeley at are using it and this actually been a few papers that have been contributed they can't",
    "start": "2464780",
    "end": "2472640"
  },
  {
    "text": "remember where the guys from is a very interesting paper out there God sparkler that was contributed from a group",
    "start": "2472640",
    "end": "2479150"
  },
  {
    "text": "outside of berkeley and matei sahara",
    "start": "2479150",
    "end": "2485119"
  },
  {
    "text": "himself who was the lead developer on house park he's finishing up his PhD in",
    "start": "2485119",
    "end": "2491119"
  },
  {
    "text": "the next month basically and has announced yet precisely where he's going but he's sticking in academics so he'll",
    "start": "2491119",
    "end": "2498049"
  },
  {
    "text": "be another academic that's outside Berkeley so those folks need to be coordinated more into the development",
    "start": "2498049",
    "end": "2505009"
  },
  {
    "text": "effort and then there's a whole set of industry developers like myself who are contributing code directly back into",
    "start": "2505009",
    "end": "2511910"
  },
  {
    "text": "these open source projects so this we is",
    "start": "2511910",
    "end": "2516980"
  },
  {
    "start": "2513000",
    "end": "2603000"
  },
  {
    "text": "now starting to get organized we need some sort of road road map to enumerate",
    "start": "2516980",
    "end": "2522049"
  },
  {
    "text": "and prioritize all of our development efforts and we started to recently see",
    "start": "2522049",
    "end": "2529220"
  },
  {
    "text": "more communication of what the amp labs roadmap is if you look at that video of",
    "start": "2529220",
    "end": "2534440"
  },
  {
    "text": "the attack I made up Randall actually went through and give you a pretty good",
    "start": "2534440",
    "end": "2540470"
  },
  {
    "text": "idea of what's coming next in coordinated shark and sparking tachyon",
    "start": "2540470",
    "end": "2545690"
  },
  {
    "text": "development so we're starting to get more information directly from the amp web on that and that's really not",
    "start": "2545690",
    "end": "2554660"
  },
  {
    "text": "sufficient because we are certainly getting more and more people contributing code from outside the eff",
    "start": "2554660",
    "end": "2560269"
  },
  {
    "text": "blab to the point where there actually are more non ample app developers contributing code to spark and related",
    "start": "2560269",
    "end": "2566739"
  },
  {
    "text": "projects and what there are actual developers at the amp web and yet the",
    "start": "2566739",
    "end": "2574460"
  },
  {
    "text": "needs of us outside developers our needs and priorities they're not always the same as what the amp labs are now it's",
    "start": "2574460",
    "end": "2580700"
  },
  {
    "text": "been pretty good so far we haven't found any real conflicts but we still need to have some way being able to express the",
    "start": "2580700",
    "end": "2587359"
  },
  {
    "text": "coordinates the needs of Industry as distinct from the amp web so what we",
    "start": "2587359",
    "end": "2593779"
  },
  {
    "text": "need is a wider roadmap something wider than just the amp labs ideas of what should take place next and that's going",
    "start": "2593779",
    "end": "2600650"
  },
  {
    "text": "to include all these community efforts and contributions so that's actually",
    "start": "2600650",
    "end": "2607819"
  },
  {
    "start": "2603000",
    "end": "2865000"
  },
  {
    "text": "something I've been involved with over the pet a couple of months is organizing organizing and coordinating kind of a",
    "start": "2607819",
    "end": "2613820"
  },
  {
    "text": "steering group now that's in quotes because we haven't really decided",
    "start": "2613820",
    "end": "2619700"
  },
  {
    "text": "exactly what to call ourselves yet but gives you an idea we're trying to",
    "start": "2619700",
    "end": "2625300"
  },
  {
    "text": "present some sort of coordinated",
    "start": "2625300",
    "end": "2630470"
  },
  {
    "text": "roadmaps so the steering group is kind of composed of was people from the amp lab but it's also a collection of",
    "start": "2630470",
    "end": "2638630"
  },
  {
    "text": "industry developers some companies that have been contributing heavily to the spark and shark code so we first met up",
    "start": "2638630",
    "end": "2648619"
  },
  {
    "text": "almost a month ago now to try and put together our first job was to try and",
    "start": "2648619",
    "end": "2654050"
  },
  {
    "text": "put together this kind of community roadmap so these are some selected items",
    "start": "2654050",
    "end": "2659270"
  },
  {
    "text": "off from that roadmap things that we added kind of to the amp labs list of",
    "start": "2659270",
    "end": "2664880"
  },
  {
    "text": "the things that we want to see next one of which is a job progress indication right now if you kick off a job into",
    "start": "2664880",
    "end": "2672680"
  },
  {
    "text": "your spark cluster you basically get no feedback as to how far the job is progressing you don't really know",
    "start": "2672680",
    "end": "2678380"
  },
  {
    "text": "whether it's crashed or whether it's making good progress or just what's going on another piece that we want to",
    "start": "2678380",
    "end": "2683750"
  },
  {
    "text": "see soon is more general cluster monitoring them about the health of your entire cluster which knows are up which",
    "start": "2683750",
    "end": "2690109"
  },
  {
    "text": "nodes are down how much of their CPU is being used and all that sort of thing",
    "start": "2690109",
    "end": "2695380"
  },
  {
    "text": "getting T I mean I was kind of envying I all she was talking about being able to you with just a couple of lines being",
    "start": "2695619",
    "end": "2702500"
  },
  {
    "text": "able to deploy a new Hadoop installation for them we'd like to be able to get the",
    "start": "2702500",
    "end": "2708440"
  },
  {
    "text": "same sorts of things working within spark and shark and related stuff and to",
    "start": "2708440",
    "end": "2713510"
  },
  {
    "text": "do that we are looking at using a chef or puppet scripts making those available yes don't so the first phase this was",
    "start": "2713510",
    "end": "2724460"
  },
  {
    "text": "just kind of all of us agreeing on which things need to be done and which kind of",
    "start": "2724460",
    "end": "2729670"
  },
  {
    "text": "somewhat a rough idea of the priority of the priority of them and then it's so",
    "start": "2729670",
    "end": "2736130"
  },
  {
    "text": "we're kind of working next well not quite working on it yet but the next step will be figuring out who was going",
    "start": "2736130",
    "end": "2742250"
  },
  {
    "text": "to be working on each one of these different jobs so it's more just at the stage of what jobs need to be done at the moment and the next step",
    "start": "2742250",
    "end": "2748300"
  },
  {
    "text": "will be who is going to be actually doing them some of them people have started to do pieces of them but like I",
    "start": "2748300",
    "end": "2755200"
  },
  {
    "text": "say the problem of us stepping on each other's toes is present that's there can",
    "start": "2755200",
    "end": "2760210"
  },
  {
    "text": "actually multiple groups and starting to work on the same piece and now we've got to kind of back up a little bit and every coordinate those yet another",
    "start": "2760210",
    "end": "2768070"
  },
  {
    "text": "possibilities to work on the it's",
    "start": "2768070",
    "end": "2774010"
  },
  {
    "text": "possible to run spark is a standalone cluster now so it doesn't use that may",
    "start": "2774010",
    "end": "2780670"
  },
  {
    "text": "associate other kind of resource sharing a framework underneath it just takes over the entire cluster which is really",
    "start": "2780670",
    "end": "2786700"
  },
  {
    "text": "nice on kind of development or testing kind of modes where you're not really worried about sharing an entire cluster",
    "start": "2786700",
    "end": "2792640"
  },
  {
    "text": "in production use you just want to be able to implement something fairly small",
    "start": "2792640",
    "end": "2797800"
  },
  {
    "text": "against me maybe even against virtual machines on a single laptop or something",
    "start": "2797800",
    "end": "2802840"
  },
  {
    "text": "like that or against a small test cluster but there are actually it's in",
    "start": "2802840",
    "end": "2808540"
  },
  {
    "text": "certain situations I mean if you want to run in production and you don't have any",
    "start": "2808540",
    "end": "2814270"
  },
  {
    "text": "need to run another head tube or MPI job or some of these other things if it's",
    "start": "2814270",
    "end": "2819550"
  },
  {
    "text": "perfectly fine with you taking over the entire cluster there's really no reason why you shouldn't be able to use this",
    "start": "2819550",
    "end": "2825580"
  },
  {
    "text": "spark standalone cluster in your production environment as well the problem is is that that's not really a",
    "start": "2825580",
    "end": "2831700"
  },
  {
    "text": "high availability environment right now if you lose a master node you've lost the entire cluster so one of the guys",
    "start": "2831700",
    "end": "2840730"
  },
  {
    "text": "it's in part of this the steering group has actually done a fair amount of work already with acha clustering and so he's",
    "start": "2840730",
    "end": "2847869"
  },
  {
    "text": "looking at starting to implement high availability within the spark standalone cluster mode then yeah how your data set",
    "start": "2847869",
    "end": "2857380"
  },
  {
    "text": "gets partitioned across your cluster is there's room for improvement there and",
    "start": "2857380",
    "end": "2862990"
  },
  {
    "text": "yeah there's other things upcoming as well but this we this steering group is",
    "start": "2862990",
    "end": "2868300"
  },
  {
    "start": "2865000",
    "end": "3049000"
  },
  {
    "text": "really not meant to exclude any of the rest of you we",
    "start": "2868300",
    "end": "2874080"
  },
  {
    "text": "we think that a small group like this is useful in order to be able to conduct",
    "start": "2874080",
    "end": "2880230"
  },
  {
    "text": "discussions where I mean we're intending to continue meeting kind of on a monthly basis and be able to make some rapid",
    "start": "2880230",
    "end": "2886710"
  },
  {
    "text": "progress within a small group but yeah",
    "start": "2886710",
    "end": "2891810"
  },
  {
    "text": "so the first step is if you actually are have been contributing code or think you",
    "start": "2891810",
    "end": "2897390"
  },
  {
    "text": "will be contributing code in the near future and you think that you should be part of this group go ahead and get in",
    "start": "2897390",
    "end": "2902910"
  },
  {
    "text": "contact with me we haven't formalized procedures for admitting people to the group or even worse kicking them out of",
    "start": "2902910",
    "end": "2909210"
  },
  {
    "text": "the group but so now actually is a",
    "start": "2909210",
    "end": "2915120"
  },
  {
    "text": "pretty good time to try and get involved with it if you think that's where you want to be but this small group is not",
    "start": "2915120",
    "end": "2922800"
  },
  {
    "text": "meant to be some sort of secret society that's going to be making all the decisions for spark and shark and we're",
    "start": "2922800",
    "end": "2928560"
  },
  {
    "text": "going to say what's going to happen and the rest of you just have to live with it that's not at all what we have in mind so your contributions are still",
    "start": "2928560",
    "end": "2936450"
  },
  {
    "text": "prized and we're going to be trying to make it easier for you to productively contribute to the code and still",
    "start": "2936450",
    "end": "2942750"
  },
  {
    "text": "function in this coordinated manner so that your stuff doesn't get rejected because it's conflicting with somebody",
    "start": "2942750",
    "end": "2948960"
  },
  {
    "text": "else's or whatever so as part of that the amp lab is going to start to use",
    "start": "2948960",
    "end": "2954450"
  },
  {
    "text": "make much wider use of their juro system which up until now has been mostly just",
    "start": "2954450",
    "end": "2960690"
  },
  {
    "text": "a bug reporting system but we're also going to start to see more larger or design kind of oriented issues being",
    "start": "2960690",
    "end": "2967110"
  },
  {
    "text": "posted to JIRA and be discussions of them there and yeah so there's the URL",
    "start": "2967110",
    "end": "2973770"
  },
  {
    "text": "for that and like I said we had this first meeting of this smaller group a",
    "start": "2973770",
    "end": "2980910"
  },
  {
    "text": "month ago we generated some raw and documentation out of that that we're",
    "start": "2980910",
    "end": "2987060"
  },
  {
    "text": "actually we're supposed to have it available for you already by this point to kind of flesh out more some of those",
    "start": "2987060",
    "end": "2993450"
  },
  {
    "text": "bullet points that gave you some of our ideas of what needs to be done and then so it get fully descriptions of the",
    "start": "2993450",
    "end": "2999450"
  },
  {
    "text": "problem sets we want to work on I get zero issues for those opened and be able to carry out more of the community its",
    "start": "2999450",
    "end": "3006200"
  },
  {
    "text": "discussion of though we're not quite at that point yet but the intent and very much is for the",
    "start": "3006200",
    "end": "3012289"
  },
  {
    "text": "results of these monthly small group discussions to within a couple of weeks be available to the wider community and",
    "start": "3012289",
    "end": "3018619"
  },
  {
    "text": "get a larger discussion going as well so yes all that stuff will be coming out in",
    "start": "3018619",
    "end": "3025940"
  },
  {
    "text": "a wiki that would be hosted over at the apple app as well and I think that's",
    "start": "3025940",
    "end": "3031789"
  },
  {
    "text": "about where we end up with except of course that clear story is also hiring",
    "start": "3031789",
    "end": "3038890"
  }
]
[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "[Music]",
    "start": "680",
    "end": "8549"
  },
  {
    "text": "hi everyone my name is irene d and today i'll be giving a talk on the new differentiable programming framework",
    "start": "15120",
    "end": "22000"
  },
  {
    "text": "we're developing at facebook i'm giving this talk today on behalf of",
    "start": "22000",
    "end": "28160"
  },
  {
    "text": "my wonderful team so here is everyone's smiling faces",
    "start": "28160",
    "end": "34480"
  },
  {
    "start": "35000",
    "end": "93000"
  },
  {
    "text": "alright so what is differentiable programming well differentiable programming brings",
    "start": "36079",
    "end": "42239"
  },
  {
    "text": "gradient based optimization techniques from machine learning into general programming",
    "start": "42239",
    "end": "48239"
  },
  {
    "text": "with machine learning many algorithms are now being learned instead of explicitly written by programmers",
    "start": "48239",
    "end": "56320"
  },
  {
    "text": "and in the words of yon lacoon it's really very much like a regular",
    "start": "57600",
    "end": "62640"
  },
  {
    "text": "program except it's parameterized automatically differentiated and trainable or optimizable",
    "start": "62640",
    "end": "71159"
  },
  {
    "text": "of course there are many popular frameworks that do provide differentiation such as pytorch",
    "start": "72080",
    "end": "77280"
  },
  {
    "text": "tensorflow and jacks however these frameworks are heavily geared towards traditional machine",
    "start": "77280",
    "end": "83119"
  },
  {
    "text": "learning models and there are many use cases that are not well supported such as computer graphics physics simulations",
    "start": "83119",
    "end": "90000"
  },
  {
    "text": "and probabilistic programming so let's take a look at what we need to",
    "start": "90000",
    "end": "97119"
  },
  {
    "start": "93000",
    "end": "141000"
  },
  {
    "text": "cover these other use cases first we'll need a fast language to write computationally intensive code",
    "start": "97119",
    "end": "103680"
  },
  {
    "text": "wherever it is needed so most popular frameworks today use python as a service language which makes",
    "start": "103680",
    "end": "110000"
  },
  {
    "text": "it inefficient to write custom logic and of course we'll need automatic differentiation so users can obtain the",
    "start": "110000",
    "end": "117200"
  },
  {
    "text": "gradients of their computations automatically next we'll need memory safety as it can",
    "start": "117200",
    "end": "122719"
  },
  {
    "text": "be difficult and frustrating to track down memory issues when you have other goals in mind",
    "start": "122719",
    "end": "128399"
  },
  {
    "text": "type safety can also be very helpful especially when writing large programs",
    "start": "128399",
    "end": "133599"
  },
  {
    "text": "and finally static compilation enables many useful optimizations before runtime",
    "start": "133599",
    "end": "141120"
  },
  {
    "start": "141000",
    "end": "192000"
  },
  {
    "text": "[Music] so with that in mind in the end it all comes down to performance usability and",
    "start": "141120",
    "end": "147840"
  },
  {
    "text": "flexibility it's important that users are able to write performant code that can be",
    "start": "147840",
    "end": "152879"
  },
  {
    "text": "productionized easily and works well with mixed workload applications",
    "start": "152879",
    "end": "158000"
  },
  {
    "text": "on the usability side users should be able to effectively develop and iterate",
    "start": "158000",
    "end": "163040"
  },
  {
    "text": "on new models debugability for example is a huge necessity",
    "start": "163040",
    "end": "168400"
  },
  {
    "text": "bugs should be quickly surfaced and easily understood with regards to flexibility our",
    "start": "168400",
    "end": "174560"
  },
  {
    "text": "framework can be applied to a wide range of use cases most frameworks work",
    "start": "174560",
    "end": "179920"
  },
  {
    "text": "exceptionally well on certain use cases like traditional machine learning models but once you step outside those",
    "start": "179920",
    "end": "185599"
  },
  {
    "text": "boundaries and are writing custom code you quickly lose out on usability and performance",
    "start": "185599",
    "end": "192800"
  },
  {
    "start": "192000",
    "end": "215000"
  },
  {
    "text": "to address these three major needs we have taken a compiler aware approach we",
    "start": "193120",
    "end": "198480"
  },
  {
    "text": "provide a customizable extensible api that serves as the base toolkit for",
    "start": "198480",
    "end": "203519"
  },
  {
    "text": "differentiability and building ml models on top of that we provide compile time",
    "start": "203519",
    "end": "209200"
  },
  {
    "text": "optimizations and compile time shape checking enabled through compiler plug-ins",
    "start": "209200",
    "end": "215920"
  },
  {
    "start": "215000",
    "end": "329000"
  },
  {
    "text": "so why kotlin well we decided on kotlin because it's it's easy to use it's memory safe it's",
    "start": "216640",
    "end": "223280"
  },
  {
    "text": "type safe and they're functional constructs uh it's extensible via compiler plug-ins",
    "start": "223280",
    "end": "228959"
  },
  {
    "text": "and it's performant kotlin is a jvm language which means that it can be anywhere from half the",
    "start": "228959",
    "end": "235360"
  },
  {
    "text": "speed of c plus plus to sometimes faster than c plus plus and of course orders of",
    "start": "235360",
    "end": "240879"
  },
  {
    "text": "magnitude faster than python kotlin is developed by jetbrains who is also the creator of the popular ide",
    "start": "240879",
    "end": "248480"
  },
  {
    "text": "intellij as a result kotlin has excellent seamless ide support which is crucial",
    "start": "248480",
    "end": "254400"
  },
  {
    "text": "for developers and so you might be wondering why are we using an android language",
    "start": "254400",
    "end": "261680"
  },
  {
    "text": "well actually there is a talk today happening uh called kotlin is way more than just",
    "start": "261680",
    "end": "267840"
  },
  {
    "text": "android kotlin well it is the official android language can be used for a wide variety",
    "start": "267840",
    "end": "273759"
  },
  {
    "text": "of other applications like server-side applications writing dsls jetbrains even",
    "start": "273759",
    "end": "279520"
  },
  {
    "text": "has a dedicated team of developers that are working on kotlin for data science for example they're working on notebook",
    "start": "279520",
    "end": "286240"
  },
  {
    "text": "support furthermore kotlin's interoperability with java gives it access to the entire",
    "start": "286240",
    "end": "292720"
  },
  {
    "text": "java ecosystem which includes numerous popular libraries",
    "start": "292720",
    "end": "298560"
  },
  {
    "text": "in addition to the jvm kotlin can also target native llvm or javascript",
    "start": "298560",
    "end": "304880"
  },
  {
    "text": "with these other two backends kotlin can be used not only just for android",
    "start": "304880",
    "end": "310479"
  },
  {
    "text": "and of course all the other applications as we discussed but also for ios and web programming",
    "start": "310479",
    "end": "316880"
  },
  {
    "text": "kotlin is a well-loved language with an active developer community and millions of users and we firmly believe that",
    "start": "316880",
    "end": "323919"
  },
  {
    "text": "colin is the perfect language for compiler aware differentiability",
    "start": "323919",
    "end": "329759"
  },
  {
    "start": "329000",
    "end": "429000"
  },
  {
    "text": "so now let's take a look at our api our api is pure and functional",
    "start": "331360",
    "end": "336960"
  },
  {
    "text": "which means that that the values we work with are immutable this gives us performance and usability",
    "start": "336960",
    "end": "342800"
  },
  {
    "text": "advantages our api supports both scalar and tensor math for example in this slide we have a",
    "start": "342800",
    "end": "349520"
  },
  {
    "text": "function f that's equivalent to sine to compute the first derivative you pass the value at which you're evaluating the",
    "start": "349520",
    "end": "356240"
  },
  {
    "text": "derivative x and a reference to the function you are taking the derivative of",
    "start": "356240",
    "end": "361919"
  },
  {
    "text": "in this example the function f p which is the derivative of f is approximately",
    "start": "361919",
    "end": "366960"
  },
  {
    "text": "equal to cosine we can support both forward and reverse",
    "start": "366960",
    "end": "373520"
  },
  {
    "text": "differentiation and we can see here that by nesting we can also compute higher order derivatives",
    "start": "373520",
    "end": "379759"
  },
  {
    "text": "we also support the derivatives of multivariate functions functions taking or returning user-defined types",
    "start": "379759",
    "end": "386800"
  },
  {
    "text": "or tensor functions so that's like computing the jacobian or the hessian",
    "start": "386800",
    "end": "393720"
  },
  {
    "text": "we also support many other components practically needed for ai applications notably our api provides the necessary",
    "start": "394720",
    "end": "401680"
  },
  {
    "text": "tools to tackle traditional ml problems such as layers and optimizers",
    "start": "401680",
    "end": "408360"
  },
  {
    "text": "in addition the api is designed to be customizable and extensible",
    "start": "408800",
    "end": "414000"
  },
  {
    "text": "for example you can differentiate with inputs or outputs being user-defined types you can also add user-defined",
    "start": "414000",
    "end": "420720"
  },
  {
    "text": "trainable layers and components finally our api is designed to be optimizable by a compiler plugin",
    "start": "420720",
    "end": "429198"
  },
  {
    "start": "429000",
    "end": "476000"
  },
  {
    "text": "so now that we've covered the efficient the different pieces of the api let's talk about performance",
    "start": "430400",
    "end": "437840"
  },
  {
    "text": "we've talked previously about how kotlin is performant this is exciting because it allows differentiability to be used",
    "start": "438160",
    "end": "444960"
  },
  {
    "text": "in mixed workload applications so if you're writing a performance critical application you can add pieces of",
    "start": "444960",
    "end": "452319"
  },
  {
    "text": "differentiation without the cost of having to write logic in python as you would in other frameworks",
    "start": "452319",
    "end": "459360"
  },
  {
    "text": "for more traditional mlu use cases we've hooked into mkl dnn the go-to",
    "start": "459360",
    "end": "465759"
  },
  {
    "text": "library for machine learning ops on cpu and continue to work on c plus speed ups",
    "start": "465759",
    "end": "471360"
  },
  {
    "text": "we have demonstrated performance on par with other popular frameworks",
    "start": "471360",
    "end": "477120"
  },
  {
    "start": "476000",
    "end": "505000"
  },
  {
    "text": "we also support sparse tensors sparse information is everywhere for example",
    "start": "477759",
    "end": "483520"
  },
  {
    "text": "social network companies like facebook have a lot of graph type problems so they have a lot of sparse data many",
    "start": "483520",
    "end": "490319"
  },
  {
    "text": "frameworks support some sparse tensor operations but have little to no support for the gradients which prevents",
    "start": "490319",
    "end": "496720"
  },
  {
    "text": "learning on sparse weights so far we have seen an order of magnitude performance increase with our",
    "start": "496720",
    "end": "502879"
  },
  {
    "text": "sparse tensors we are also developing a couple of",
    "start": "502879",
    "end": "508720"
  },
  {
    "text": "compile time optimizations that work with our library as mentioned previously",
    "start": "508720",
    "end": "513760"
  },
  {
    "text": "our api is specifically designed for this purpose",
    "start": "513760",
    "end": "519880"
  },
  {
    "start": "519000",
    "end": "559000"
  },
  {
    "text": "so now that we've covered our api let's take a look at some of the cool compiler optimizations that we're developing",
    "start": "520560",
    "end": "527519"
  },
  {
    "text": "let's take a look at the first optimization ad optimize",
    "start": "527519",
    "end": "532880"
  },
  {
    "text": "our ad implementation produces a compute tree for evaluating the derivative which is built at runtime with a node created",
    "start": "532880",
    "end": "539920"
  },
  {
    "text": "for each operation this approach comes at the cost of extra allocations and function calls",
    "start": "539920",
    "end": "546959"
  },
  {
    "text": "this is a common problem in automatic differentiation frameworks our ad optimized plugin addresses this",
    "start": "546959",
    "end": "553200"
  },
  {
    "text": "cost by inlining differentiable computations and unboxing scalars",
    "start": "553200",
    "end": "559279"
  },
  {
    "start": "559000",
    "end": "635000"
  },
  {
    "text": "now let's take a look at an example so here you can see we have a function foo",
    "start": "561040",
    "end": "566399"
  },
  {
    "text": "that computes the geometric series with r is equal to one-half we can see here that y is the sum and in",
    "start": "566399",
    "end": "574080"
  },
  {
    "text": "this loop we are accumulating a divided by 2 to the power of i",
    "start": "574080",
    "end": "580480"
  },
  {
    "text": "to compute the derivative we create a compute tree here is what the compute tree looks like",
    "start": "580560",
    "end": "586800"
  },
  {
    "text": "for three iterations each operation that we do produces a node in our compute tree",
    "start": "586800",
    "end": "593120"
  },
  {
    "text": "the loop and foo is actually running a thousand times so and in each iteration we have a couple",
    "start": "593120",
    "end": "599600"
  },
  {
    "text": "of operations add and divide so we're actually creating approximately",
    "start": "599600",
    "end": "604720"
  },
  {
    "text": "a couple thousand node objects here at runtime in order to compute the derivative so how can we do better",
    "start": "604720",
    "end": "613120"
  },
  {
    "text": "well with the ad optimized plugin we can unbox scalars and inline derivative values in order to drastically reduce",
    "start": "614160",
    "end": "620959"
  },
  {
    "text": "the number of objects that we create for this example this results in the",
    "start": "620959",
    "end": "626240"
  },
  {
    "text": "creation of just one single object for the derivative computation",
    "start": "626240",
    "end": "632279"
  },
  {
    "text": "but we can do even more so let's take a look at the next",
    "start": "632320",
    "end": "638079"
  },
  {
    "start": "635000",
    "end": "860000"
  },
  {
    "text": "optimization course name course thing is a novel optimization technique that we have developed",
    "start": "638079",
    "end": "644560"
  },
  {
    "text": "there are two main ways to do differentiations there's algorithmic differentiation and there's symbolic differentiation",
    "start": "644560",
    "end": "652320"
  },
  {
    "text": "algorithmic differentiation differentiates every operation at runtime it has the finest granularity of",
    "start": "652320",
    "end": "658720"
  },
  {
    "text": "operation symbolic differentiation applies calculus on the entire computation and",
    "start": "658720",
    "end": "664320"
  },
  {
    "text": "has the largest granularity of operation coursing introduces a new way to do ad",
    "start": "664320",
    "end": "670320"
  },
  {
    "text": "by striking a balance between two existing methods and getting the best of both worlds",
    "start": "670320",
    "end": "677200"
  },
  {
    "text": "with coarsening the ad optimizer takes the primal code as input identifies",
    "start": "679120",
    "end": "684240"
  },
  {
    "text": "segments of interest through a reuse aware algorithm raises them to the symbolic level and conducts symbolic",
    "start": "684240",
    "end": "690800"
  },
  {
    "text": "differentiation and generates the optimized code with mixed algorithmic symbolic",
    "start": "690800",
    "end": "696880"
  },
  {
    "text": "differentiation so the key point here is that coarsening has a larger view than our standard",
    "start": "696880",
    "end": "702880"
  },
  {
    "text": "differentiation which allows for more optimizations",
    "start": "702880",
    "end": "708000"
  },
  {
    "text": "now let's revisit the geometric series function with coarsening we're able to consider",
    "start": "709279",
    "end": "714480"
  },
  {
    "text": "the entire function's computation and recognize certain patterns coursing can",
    "start": "714480",
    "end": "719519"
  },
  {
    "text": "transform form loops into summations and even simplify summations further",
    "start": "719519",
    "end": "725839"
  },
  {
    "text": "here we can use this property of geometric series to simplify the foo function",
    "start": "725839",
    "end": "732160"
  },
  {
    "text": "we can then take the derivative of this simplified function",
    "start": "732160",
    "end": "736959"
  },
  {
    "text": "so here are the functions generated by our coursing optimization here is the primal computation and over",
    "start": "738959",
    "end": "746160"
  },
  {
    "text": "here is the gradient computation we have arrived at the primal",
    "start": "746160",
    "end": "751519"
  },
  {
    "text": "computation through this property here the one that looks like a screenshot from a textbook",
    "start": "751519",
    "end": "757600"
  },
  {
    "text": "and the gradient was computed symbolically from this we've effectively reduced our function",
    "start": "757600",
    "end": "763680"
  },
  {
    "text": "foo to a simple short expression with no loops and same for the gradient",
    "start": "763680",
    "end": "769200"
  },
  {
    "text": "also notice that when we obtain the derivative now we only call foo grad",
    "start": "769200",
    "end": "774320"
  },
  {
    "text": "previously the ad system would actually call the primal function foo behind the scenes",
    "start": "774320",
    "end": "780000"
  },
  {
    "text": "now we don't have any calls to foo at all and we can just call foo directly",
    "start": "780000",
    "end": "786519"
  },
  {
    "text": "so now let's take a look at a more complex example this slide shows the performance of hokian spring a physics",
    "start": "789040",
    "end": "795519"
  },
  {
    "text": "simulation program it simulates mass spring systems",
    "start": "795519",
    "end": "801639"
  },
  {
    "text": "the three configurations correspond to three sizes of the spring system in terms of the number of spring vertices",
    "start": "802399",
    "end": "809600"
  },
  {
    "text": "so here we have 10 vertices 20 vertices and 40 vertices",
    "start": "809600",
    "end": "817120"
  },
  {
    "text": "coursing is able to do symbolic differentiation on the entire computation of the gradient as a result",
    "start": "817120",
    "end": "822720"
  },
  {
    "text": "the primal computation which computes the system energy can be completely removed so you can see here that the",
    "start": "822720",
    "end": "829279"
  },
  {
    "text": "primal time is actually reduced to zero and so this is similar to what we saw on the previous example where we had to",
    "start": "829279",
    "end": "836160"
  },
  {
    "text": "only call or where we only had to call fugrad to get the derivative the speedups here that we've observed",
    "start": "836160",
    "end": "842800"
  },
  {
    "text": "are 4 to 11x the program even runs faster than the original primal computation alone",
    "start": "842800",
    "end": "850880"
  },
  {
    "text": "we've also evaluated coarsening on other examples and have observed speedups of one to two orders of magnitude",
    "start": "852320",
    "end": "860480"
  },
  {
    "start": "860000",
    "end": "955000"
  },
  {
    "text": "so now that we've gone over compiler optimizations for performance let's see how we're using compiler plugins to",
    "start": "862399",
    "end": "868880"
  },
  {
    "text": "enhance usability tensors are often fed through many different operations each operation",
    "start": "868880",
    "end": "876000"
  },
  {
    "text": "often has different shape requirements and produces a new tensor with a possibly different shape the combination of shape",
    "start": "876000",
    "end": "882959"
  },
  {
    "text": "requirements and new output shapes makes it incredibly easy to hit runtime shape errors with popular frameworks which",
    "start": "882959",
    "end": "889760"
  },
  {
    "text": "offer no static shape checking or information debugging runtime shape errors is hard",
    "start": "889760",
    "end": "896560"
  },
  {
    "text": "and a lot of users rely heavily on printing their shapes at runtime to debug errors or even to just understand",
    "start": "896560",
    "end": "903279"
  },
  {
    "text": "what their code is doing to address this issue we're developing a",
    "start": "903279",
    "end": "908320"
  },
  {
    "text": "compiler plugin for static shape checking with this plugin users will get not only",
    "start": "908320",
    "end": "914399"
  },
  {
    "text": "compile time shape inference and shape checking but also real time feedback in intellij",
    "start": "914399",
    "end": "921199"
  },
  {
    "text": "such as error messaging and redlining with intellij users can also inspect the shapes of their tensors as they develop",
    "start": "921199",
    "end": "928399"
  },
  {
    "text": "so before they even build or run their code",
    "start": "928399",
    "end": "933199"
  },
  {
    "text": "the plugin is integrated with our api which means that you can get static shape checking out of the box for",
    "start": "934480",
    "end": "940079"
  },
  {
    "text": "numerous tensor operations and lastly the plugin functionality is extensible",
    "start": "940079",
    "end": "946160"
  },
  {
    "text": "there are a lot of tensor operations that have complex shape transformations so it's important that users can define",
    "start": "946160",
    "end": "952720"
  },
  {
    "text": "their own shape functions so here's an example of how you can",
    "start": "952720",
    "end": "958560"
  },
  {
    "text": "provide static shape checking for the matte mole function which implements a matrix multiply",
    "start": "958560",
    "end": "964560"
  },
  {
    "text": "for those who are unfamiliar mammal takes two two dimensional tensors and requires that the inner two dimensions",
    "start": "964560",
    "end": "970800"
  },
  {
    "text": "match so here we can see that the second dimension of x is the parameter b and",
    "start": "970800",
    "end": "976320"
  },
  {
    "text": "the first dimension of y is the parameter b",
    "start": "976320",
    "end": "982040"
  },
  {
    "start": "981000",
    "end": "1008000"
  },
  {
    "text": "now let's take a look at matt mole in action the shape of a is inferred to be 1 2 and the shape of b is inferred to be",
    "start": "982800",
    "end": "990399"
  },
  {
    "text": "2 3 the value res is obtained from a correct usage of matte mole that produces a tensor of shape 1 3.",
    "start": "990399",
    "end": "999600"
  },
  {
    "text": "now bad res shows an incorrect usage of matt mole this will result in a compile-time error as the inner",
    "start": "999600",
    "end": "1006000"
  },
  {
    "text": "dimensions do not match here we have a couple of examples",
    "start": "1006000",
    "end": "1011440"
  },
  {
    "text": "showing what the plugin looks like intellij up top here we have shape inspection and over here on the bottom",
    "start": "1011440",
    "end": "1018399"
  },
  {
    "text": "we have an error message and remember this is all happening during development and this means that users can inspect",
    "start": "1018399",
    "end": "1025280"
  },
  {
    "text": "their code and see errors immediately as they're typing",
    "start": "1025280",
    "end": "1030240"
  },
  {
    "start": "1029000",
    "end": "1077000"
  },
  {
    "text": "now let's take a look at an example of more complex shape checking the shape of the matmal function was",
    "start": "1030799",
    "end": "1037280"
  },
  {
    "text": "quite simple and could be done using positional matching however broadcast is an example of a shape transformation",
    "start": "1037280",
    "end": "1043918"
  },
  {
    "text": "that is not so easily expressed broadcast is a very dynamic shape transformation that lets users add",
    "start": "1043919",
    "end": "1049679"
  },
  {
    "text": "tensors of different shapes up top we have the broadcast shape function",
    "start": "1049679",
    "end": "1055360"
  },
  {
    "text": "users can write this code imperatively and even call other functions on the bottom we have the definition of",
    "start": "1055360",
    "end": "1061600"
  },
  {
    "text": "add notice that the return shape is a call to the shape function broadcasts on a and b",
    "start": "1061600",
    "end": "1068559"
  },
  {
    "text": "this type of extensibility allows users to find custom shape checking logic for new tensor operations",
    "start": "1068559",
    "end": "1076879"
  },
  {
    "start": "1077000",
    "end": "1131000"
  },
  {
    "text": "now that we've gone over all the major components of our framework let's take a look at an interesting use case",
    "start": "1079200",
    "end": "1086720"
  },
  {
    "text": "b machine is a probabilistic programming system for bayesian models as being developed at facebook",
    "start": "1087520",
    "end": "1093520"
  },
  {
    "text": "traditional differentiation and machine learning frameworks were not a good fit for them",
    "start": "1093520",
    "end": "1099039"
  },
  {
    "text": "in particular traditional frameworks generally lack higher order differentiation performance scalar",
    "start": "1099039",
    "end": "1104400"
  },
  {
    "text": "support sparse tensor support and fast execution of native language for example newtonian monte carlo is a",
    "start": "1104400",
    "end": "1111679"
  },
  {
    "text": "probabilistic inference algorithm algorithm that uses second order differentiation and is well suited for",
    "start": "1111679",
    "end": "1117840"
  },
  {
    "text": "scalars and so with our framework we're able to provide support for these use cases and",
    "start": "1117840",
    "end": "1123840"
  },
  {
    "text": "we're collaborating with bean machine to provide the differentiability infrastructure that they need",
    "start": "1123840",
    "end": "1130399"
  },
  {
    "start": "1131000",
    "end": "1175000"
  },
  {
    "text": "so i started this talk saying that what we're doing really comes down to performance usability and flexibility",
    "start": "1132400",
    "end": "1139679"
  },
  {
    "text": "here's how all the pieces we've discussed fit into that idea so for performance we saw the benefits",
    "start": "1139679",
    "end": "1146000"
  },
  {
    "text": "from sparse tensors mkl dnn being in kotlin and our optimization plugins",
    "start": "1146000",
    "end": "1152320"
  },
  {
    "text": "with regards to usability we talked about our functional api and our static shape checking plug-in for flexibility",
    "start": "1152320",
    "end": "1159679"
  },
  {
    "text": "we saw that our api was extensible and customizable and we saw how shape checking the shape checking plug-in was",
    "start": "1159679",
    "end": "1166320"
  },
  {
    "text": "extensible as well we also touched on our collaboration with b machine a probabilistic",
    "start": "1166320",
    "end": "1172799"
  },
  {
    "text": "programming system alright so what do we have planned for",
    "start": "1172799",
    "end": "1177919"
  },
  {
    "start": "1175000",
    "end": "1225000"
  },
  {
    "text": "the future well on the optimization side we want to develop new optimizations enabled by",
    "start": "1177919",
    "end": "1183679"
  },
  {
    "text": "compiler plugins for example there might be room for more domain specific optimizations and",
    "start": "1183679",
    "end": "1189120"
  },
  {
    "text": "because these are all plugins users can pick and choose which ones to apply depending on what their goals are",
    "start": "1189120",
    "end": "1196640"
  },
  {
    "text": "so on the usability front you can imagine that there is a lot of other metadata out there besides tensor shapes",
    "start": "1196640",
    "end": "1202720"
  },
  {
    "text": "that could be used to help users detect bugs early and ergonomically",
    "start": "1202720",
    "end": "1207919"
  },
  {
    "text": "lastly we're excited to see users utilize our framework for their innovative purposes and we're looking",
    "start": "1207919",
    "end": "1213120"
  },
  {
    "text": "forward to getting their feedback and working with them alright so that's all for this talk",
    "start": "1213120",
    "end": "1220559"
  },
  {
    "text": "thank you for listening",
    "start": "1220559",
    "end": "1223679"
  },
  {
    "start": "1225000",
    "end": "1602000"
  },
  {
    "text": "excellent talk irene it's always good to learn about all the new research going on in this area",
    "start": "1225760",
    "end": "1233280"
  },
  {
    "text": "it definitely gave me some flashbacks to calculus clause which is this outside but you know it's it's useful",
    "start": "1233360",
    "end": "1240559"
  },
  {
    "text": "um so i'm wondering so this is a library in kotlin uh how do",
    "start": "1240559",
    "end": "1248240"
  },
  {
    "text": "you achieve uh the analysis of the code is it like you were talking about compiler plugins",
    "start": "1248240",
    "end": "1253600"
  },
  {
    "text": "is it like analyzing and interfacing uh itself into the compiler build chain",
    "start": "1253600",
    "end": "1259919"
  },
  {
    "text": "is that how it works yeah exactly so um so yeah we have",
    "start": "1259919",
    "end": "1265760"
  },
  {
    "text": "uh compiler plugins and they run at different levels in the plugin so for example the static",
    "start": "1265760",
    "end": "1271280"
  },
  {
    "text": "shape checking plugin it it runs in the front end and one of the things",
    "start": "1271280",
    "end": "1277120"
  },
  {
    "text": "that we're intercepting is call resolution so that is a big thing right because we have to check the",
    "start": "1277120",
    "end": "1282400"
  },
  {
    "text": "different each call and we have to make sure that each call produces the right shape",
    "start": "1282400",
    "end": "1288400"
  },
  {
    "text": "and then for things like the ad optimize plug-in which is generating code that actually",
    "start": "1288400",
    "end": "1294159"
  },
  {
    "text": "runs further down the compiler pipeline so that one will run on the kotlin ir",
    "start": "1294159",
    "end": "1301039"
  },
  {
    "text": "which is right before it gets translated to either uh jbm bytecode or native or",
    "start": "1301039",
    "end": "1308159"
  },
  {
    "text": "javascript so that's a stat that's basically a feature of kotlin right you're not doing",
    "start": "1308159",
    "end": "1313520"
  },
  {
    "text": "anything special here it's just you plug in here compiler generates new builds",
    "start": "1313520",
    "end": "1319440"
  },
  {
    "text": "yeah so we are using the uh yeah we're just using the general kotlin",
    "start": "1319440",
    "end": "1324799"
  },
  {
    "text": "plug-in framework so how many",
    "start": "1324799",
    "end": "1329919"
  },
  {
    "text": "language features do you support can i use everything in kotlin can everything be differentiated",
    "start": "1329919",
    "end": "1336400"
  },
  {
    "text": "uh yeah so it kind of it so it depends i would say",
    "start": "1336400",
    "end": "1342000"
  },
  {
    "text": "that it not everything can be differentiated but",
    "start": "1342000",
    "end": "1347039"
  },
  {
    "text": "we provide support in our api to for users to add their own custom different",
    "start": "1347039",
    "end": "1354080"
  },
  {
    "text": "differentiable objects you would have to extend an interface and fit onto our api",
    "start": "1354080",
    "end": "1360480"
  },
  {
    "text": "if you want your custom object to be differentiated in terms of things like control flow we",
    "start": "1360480",
    "end": "1365840"
  },
  {
    "text": "are planning to handle that uh with with compiler plugins as well",
    "start": "1365840",
    "end": "1371919"
  },
  {
    "text": "and so that's all built that's easy for users to do they don't have to write they don't have to write their own plugins",
    "start": "1371919",
    "end": "1378880"
  },
  {
    "text": "no yeah we we're planning to provide the general features of kotlin um",
    "start": "1378880",
    "end": "1384000"
  },
  {
    "text": "for users and so they can differentiate through gen generally through most",
    "start": "1384000",
    "end": "1389760"
  },
  {
    "text": "features um yeah and that includes control flow as well",
    "start": "1389760",
    "end": "1396480"
  },
  {
    "text": "so maybe this is a weird question but what does it mean to differentiate over control flow",
    "start": "1396480",
    "end": "1402640"
  },
  {
    "text": "maybe explain that yeah so to differentiate over control flow well",
    "start": "1402640",
    "end": "1409039"
  },
  {
    "text": "so generally it it is so let's i guess like to back up if you are in a",
    "start": "1409039",
    "end": "1416000"
  },
  {
    "text": "framework let's say like pie torch and you're different and you have a p like an if statement or you",
    "start": "1416000",
    "end": "1424159"
  },
  {
    "text": "know a for loop you're actually just tracing through the for loop um and so",
    "start": "1424159",
    "end": "1429520"
  },
  {
    "text": "remember in the talk we talked about building a compute tree um and so what's happening is every",
    "start": "1429520",
    "end": "1436480"
  },
  {
    "text": "operation that you do in the for loop gets unrolled into this compute tree and so that's what's happening in in a",
    "start": "1436480",
    "end": "1443120"
  },
  {
    "text": "framework like pie torch um for us that is also happening but what people",
    "start": "1443120",
    "end": "1449840"
  },
  {
    "text": "actually prefer is to have the control flow preserved so that people",
    "start": "1449840",
    "end": "1455919"
  },
  {
    "text": "so the dynamism is actually preserved uh later on in our models so it's just",
    "start": "1455919",
    "end": "1461919"
  },
  {
    "text": "so yeah and in other frameworks it just gets unrolled completely but you lose",
    "start": "1461919",
    "end": "1467360"
  },
  {
    "text": "that the sense that you have control flow and you also are not able to",
    "start": "1467360",
    "end": "1472559"
  },
  {
    "text": "do optimizations on it because you lose that and i guess you also if you optimize the",
    "start": "1472559",
    "end": "1478240"
  },
  {
    "text": "control flow away you can debug into it as a pros yeah yeah exactly",
    "start": "1478240",
    "end": "1485360"
  },
  {
    "text": "um just see some questions in the chat maybe we should step back and say",
    "start": "1485360",
    "end": "1490400"
  },
  {
    "text": "so what do you use this for is this work is it for writing general ml",
    "start": "1490400",
    "end": "1497200"
  },
  {
    "text": "models just in a more language-based way is that it",
    "start": "1497200",
    "end": "1502240"
  },
  {
    "text": "yeah so i would i would say um i would say like the the other popular",
    "start": "1502240",
    "end": "1507440"
  },
  {
    "text": "frameworks are more suited towards that use case as as we saw the presentation",
    "start": "1507440",
    "end": "1512640"
  },
  {
    "text": "so the use cases that we're that we're looking at more are outside",
    "start": "1512640",
    "end": "1518159"
  },
  {
    "text": "of that box so for example we did talk about probabilistic programming and one thing that people tend to use",
    "start": "1518159",
    "end": "1525200"
  },
  {
    "text": "probabilistic programming for um is things like uh",
    "start": "1525200",
    "end": "1530320"
  },
  {
    "text": "like climate models there's um uh like",
    "start": "1530320",
    "end": "1536559"
  },
  {
    "text": "there's like a probabilistic programming model that's used to like make sure gamers are",
    "start": "1536559",
    "end": "1542559"
  },
  {
    "text": "the same they find gamers at the same level when they pit them against each other so",
    "start": "1542559",
    "end": "1547919"
  },
  {
    "text": "that that's an example another example that you might see differentiable programming used is things like uh like",
    "start": "1547919",
    "end": "1554640"
  },
  {
    "text": "a ray tracer has and so physics simulations things in that area as well",
    "start": "1554640",
    "end": "1562240"
  },
  {
    "text": "and it for that it's for the ray tracering example it's used to to optimize the ray tracer or the to",
    "start": "1562240",
    "end": "1569120"
  },
  {
    "text": "learn anything about it yeah so i think for the ray tracing",
    "start": "1569120",
    "end": "1574880"
  },
  {
    "text": "ray tracing example i think i think it's generally used as an optimization",
    "start": "1574880",
    "end": "1581039"
  },
  {
    "text": "um but it's also used i think it's something like you learn",
    "start": "1581039",
    "end": "1586559"
  },
  {
    "text": "uh you learn with respect to the different um",
    "start": "1586559",
    "end": "1591919"
  },
  {
    "text": "like you know your objects might have like a property to them and that you might have a position and so you're",
    "start": "1591919",
    "end": "1597520"
  },
  {
    "text": "learning with respect to those things okay",
    "start": "1597520",
    "end": "1603039"
  },
  {
    "start": "1602000",
    "end": "1702000"
  },
  {
    "text": "um you brought up the word probabilistic programming uh is it too much to ask is it a bigger",
    "start": "1603039",
    "end": "1609679"
  },
  {
    "text": "explanation to give an overview of what that is yeah i can i can attempt to give an",
    "start": "1609679",
    "end": "1614799"
  },
  {
    "text": "overview i'm not just an elevator pitch maybe yeah yeah so probabilistic programming",
    "start": "1614799",
    "end": "1620400"
  },
  {
    "text": "is um basically basically a way to",
    "start": "1620400",
    "end": "1625520"
  },
  {
    "text": "encode uncertainty into your models so",
    "start": "1625520",
    "end": "1630559"
  },
  {
    "text": "if you can think um you actually so",
    "start": "1630559",
    "end": "1636640"
  },
  {
    "text": "what happens in probabilistic programming is you provide some sort of assumption about your world",
    "start": "1636640",
    "end": "1642960"
  },
  {
    "text": "and that might be in the form of distributions so you provide some sort",
    "start": "1642960",
    "end": "1648640"
  },
  {
    "text": "of statistical assumptions and then you provide some observations on top of that",
    "start": "1648640",
    "end": "1654559"
  },
  {
    "text": "and so you're you're basically saying here's what i think the world how the world is acting and then you say well",
    "start": "1654559",
    "end": "1660240"
  },
  {
    "text": "this is what i'm seeing and then you and then what comes out is",
    "start": "1660240",
    "end": "1665440"
  },
  {
    "text": "a distribution that says this is what might actually be happening given those",
    "start": "1665440",
    "end": "1671919"
  },
  {
    "text": "two things the observations and your assumptions so it allows people to add a level of uncertainty but also some",
    "start": "1671919",
    "end": "1678000"
  },
  {
    "text": "domain knowledge into their models",
    "start": "1678000",
    "end": "1683279"
  },
  {
    "text": "and i think facebook does a lot of research into that i think we had a q con talk two years ago from your",
    "start": "1683279",
    "end": "1688559"
  },
  {
    "text": "colleague yeah michael oh yeah yeah yeah",
    "start": "1688559",
    "end": "1693600"
  },
  {
    "text": "so if the audience would like to look at that more just look for info cube probabilistic programming there's a talk",
    "start": "1693600",
    "end": "1699919"
  },
  {
    "text": "online let's see there's a question here how would kotlin deal with",
    "start": "1699919",
    "end": "1706080"
  },
  {
    "text": "continuous functions and stochastic calculus that's obvious to me but uh maybe help everyone else i'm kidding",
    "start": "1706080",
    "end": "1712320"
  },
  {
    "text": "this is not obvious to me like you cannot correct me yeah um well",
    "start": "1712320",
    "end": "1718159"
  },
  {
    "text": "i guess i'm not sure if i quite understand the question here because we would need to have continuous functions",
    "start": "1718159",
    "end": "1724720"
  },
  {
    "text": "in order to take the derivative of them um so um",
    "start": "1724720",
    "end": "1729840"
  },
  {
    "text": "yeah if you if you are writing something that you're taking the derivative with resp uh the derivative",
    "start": "1729840",
    "end": "1736000"
  },
  {
    "text": "of it would need to be a continuous function",
    "start": "1736000",
    "end": "1739840"
  },
  {
    "start": "1740000",
    "end": "1789000"
  },
  {
    "text": "when you so the differentiation um so you get the example of differentiating um",
    "start": "1742399",
    "end": "1747919"
  },
  {
    "text": "the sine function the sin function so how much uh how fancy can i get with",
    "start": "1747919",
    "end": "1754240"
  },
  {
    "text": "the functions in there how much do you support if i have like i don't know i can't think of any fancy functions",
    "start": "1754240",
    "end": "1760399"
  },
  {
    "text": "bernoulli that's not the right that's the right thing but something like that uh yeah i mean you you can get pretty",
    "start": "1760399",
    "end": "1767360"
  },
  {
    "text": "pretty fancy um so we we do have like a suite of examples and also generally you can do",
    "start": "1767360",
    "end": "1774240"
  },
  {
    "text": "any you we do support anything traditional machine learning supports as well so",
    "start": "1774240",
    "end": "1781440"
  },
  {
    "text": "and those those models do get i i guess pretty fancy too",
    "start": "1781440",
    "end": "1787760"
  },
  {
    "text": "okay uh i think we also had the question of so is this open source is this online are",
    "start": "1787760",
    "end": "1793679"
  },
  {
    "start": "1789000",
    "end": "1816000"
  },
  {
    "text": "you going to open source it can people play around this with this somewhere right that that's a great question so we",
    "start": "1793679",
    "end": "1799919"
  },
  {
    "text": "are working on open sourcing our framework and that is the plan um right now we're currently",
    "start": "1799919",
    "end": "1807039"
  },
  {
    "text": "getting feedback internally and we have some internal users but we have we don't have any concrete plans to open",
    "start": "1807039",
    "end": "1814399"
  },
  {
    "text": "source soon okay i think do you work with eric meyer",
    "start": "1814399",
    "end": "1819760"
  },
  {
    "start": "1816000",
    "end": "1990000"
  },
  {
    "text": "directly yeah so eric meyer actually started this team and he was yeah and so",
    "start": "1819760",
    "end": "1828480"
  },
  {
    "text": "we worked together in the beginning i saw some tweets over the last year or two of him doing stuff with math and",
    "start": "1828480",
    "end": "1835039"
  },
  {
    "text": "kotlin what's he up to how many how many monets how many moments does he force you to use",
    "start": "1835039",
    "end": "1842000"
  },
  {
    "text": "how many what how many monacs well i mean working yeah working with",
    "start": "1842000",
    "end": "1849360"
  },
  {
    "text": "eric is is quite interesting it is also quite interesting to um",
    "start": "1849360",
    "end": "1854640"
  },
  {
    "text": "definitely work in the intersection of machine learning and pls because i think there is",
    "start": "1854640",
    "end": "1859679"
  },
  {
    "text": "there is so much overlap there um and there is so much unexplored overlap there so for example i think",
    "start": "1859679",
    "end": "1866799"
  },
  {
    "text": "um with the with the static shape checking i think that there's a lot of",
    "start": "1866799",
    "end": "1872320"
  },
  {
    "text": "um i think there's a lot of interesting overlap with the pls pls world there because originally we",
    "start": "1872320",
    "end": "1878399"
  },
  {
    "text": "actually intended um for that to be in the type checker um",
    "start": "1878399",
    "end": "1884159"
  },
  {
    "text": "but there's we can't extend kotlin in in that direction we actually ended up we",
    "start": "1884159",
    "end": "1890960"
  },
  {
    "text": "actually started hacking the compiler at first um and our first prototype was actually",
    "start": "1890960",
    "end": "1896640"
  },
  {
    "text": "just in the shape or in the type checker so i i would say like",
    "start": "1896640",
    "end": "1902080"
  },
  {
    "text": "so it's kind of interesting just to see how pls and",
    "start": "1902080",
    "end": "1907279"
  },
  {
    "text": "pl and ml fit together here especially with that specific feature",
    "start": "1907279",
    "end": "1914399"
  },
  {
    "text": "yeah it's i guess it's a trade-off of having the needs of clean compiler plug-ins versus having your own",
    "start": "1914960",
    "end": "1921440"
  },
  {
    "text": "branch of kotlin which makes it harder to use yeah yeah i would say we we kind of went in",
    "start": "1921440",
    "end": "1927200"
  },
  {
    "text": "that direction because it was hard to maintain and make sure that everything was up to date with",
    "start": "1927200",
    "end": "1932640"
  },
  {
    "text": "upstream as well um but yeah but the compiler plugins are really nice as well",
    "start": "1932640",
    "end": "1938799"
  },
  {
    "text": "and we're working with jetbrains on the usability okay",
    "start": "1938799",
    "end": "1943919"
  },
  {
    "text": "so can you um maybe put your work in context of the",
    "start": "1943919",
    "end": "1948960"
  },
  {
    "text": "wider research uh uh industry um ecosystem i think there's",
    "start": "1948960",
    "end": "1954480"
  },
  {
    "text": "there was a there was unfortunately a project called swift for tensorflow which i think is related to what you're",
    "start": "1954480",
    "end": "1960399"
  },
  {
    "text": "doing in a way but for the swift language are there others that we might want to watch while we wait for you to",
    "start": "1960399",
    "end": "1966480"
  },
  {
    "text": "open-source this yeah um there's other there's other ones um of course there's",
    "start": "1966480",
    "end": "1972799"
  },
  {
    "text": "pi torch tensorflow and jacks which are very popular um other than that there's also julia which has zygote",
    "start": "1972799",
    "end": "1980480"
  },
  {
    "text": "and i'm not sure if they have what the other name was but they have uh",
    "start": "1980480",
    "end": "1985679"
  },
  {
    "text": "differentiation with in julia as well in is is julia as extensible as kotlin i",
    "start": "1985679",
    "end": "1993840"
  },
  {
    "start": "1990000",
    "end": "2060000"
  },
  {
    "text": "can't remember do they use macros or something yeah i'm not sure i know",
    "start": "1993840",
    "end": "1999440"
  },
  {
    "text": "that it's not statically compiled it's actually",
    "start": "1999440",
    "end": "2004559"
  },
  {
    "text": "i guess kind of between well in terms of types it's kind of between static and dynamic typing",
    "start": "2004559",
    "end": "2010880"
  },
  {
    "text": "but um it's not statically compiled so there isn't",
    "start": "2010880",
    "end": "2016159"
  },
  {
    "text": "there wouldn't be like compiler plug-in infrastructure",
    "start": "2016159",
    "end": "2022080"
  },
  {
    "text": "and so if you're looking at something like uh pipe torch or i think keras are those kind of the same",
    "start": "2022399",
    "end": "2030000"
  },
  {
    "text": "way where you can write models in a language and then to figure out the graphs is that right or is it a",
    "start": "2030000",
    "end": "2036640"
  },
  {
    "text": "different thing yeah yeah so keras is a um",
    "start": "2036640",
    "end": "2042320"
  },
  {
    "text": "so uh yeah keras is a um layer or a machine learning library on top of",
    "start": "2042320",
    "end": "2049358"
  },
  {
    "text": "tensorflow so it's a high-level library and so that that is a little bit different from pie",
    "start": "2049359",
    "end": "2055440"
  },
  {
    "text": "torch um but keras sorry what was your question",
    "start": "2055440",
    "end": "2061118"
  },
  {
    "start": "2060000",
    "end": "2127000"
  },
  {
    "text": "i was just wondering if there's other tools that are uh similar to to the work that you're",
    "start": "2061119",
    "end": "2067118"
  },
  {
    "text": "doing with allowing people to write models in a language rather than plugging graphs together",
    "start": "2067119",
    "end": "2073679"
  },
  {
    "text": "yeah yeah um yeah i would say julia is probably the the most similar one i",
    "start": "2073679",
    "end": "2079118"
  },
  {
    "text": "would say pie torch pie torches pie torch is really easy to use because it's",
    "start": "2079119",
    "end": "2086158"
  },
  {
    "text": "um because you're not meta programming",
    "start": "2086159",
    "end": "2091200"
  },
  {
    "text": "whereas in tensorflow you are meta programming and you kind of have to think about how the actual graphs that",
    "start": "2091200",
    "end": "2096800"
  },
  {
    "text": "you are building so for example instead of just having like a variable you would have a variable",
    "start": "2096800",
    "end": "2103520"
  },
  {
    "text": "node that you're updating um so it you there's this level of separation with",
    "start": "2103520",
    "end": "2108960"
  },
  {
    "text": "tensorflow um but i think yeah and keras is a is a",
    "start": "2108960",
    "end": "2114240"
  },
  {
    "text": "library on top of that and so there's also this",
    "start": "2114240",
    "end": "2119920"
  },
  {
    "text": "there's also like a degree of separation too because it's a high level library on top of tensorflow",
    "start": "2119920",
    "end": "2127599"
  },
  {
    "text": "what used to be in the olden days you had to literally plug together a graph which was kind of",
    "start": "2127920",
    "end": "2133119"
  },
  {
    "text": "if you read the old tensorflow examples it was like jesus i have to do 20 pages of code just",
    "start": "2133119",
    "end": "2139040"
  },
  {
    "text": "to have one network and something so i think these language-based approaches are just neater",
    "start": "2139040",
    "end": "2145359"
  },
  {
    "text": "but cleaner yeah so i'm just quickly we're running out of",
    "start": "2145359",
    "end": "2152400"
  },
  {
    "start": "2149000",
    "end": "2172000"
  },
  {
    "text": "time i think we've covered most things there's a question about is someone",
    "start": "2152400",
    "end": "2158480"
  },
  {
    "text": "going to do a version of his talk oriented to math educators um i don't think we can answer that",
    "start": "2158480",
    "end": "2166400"
  },
  {
    "text": "no nothing planned maybe one day",
    "start": "2166400",
    "end": "2172280"
  },
  {
    "start": "2172000",
    "end": "2220000"
  },
  {
    "text": "cool uh so um sort of wrapping up um thank you irene",
    "start": "2172720",
    "end": "2177760"
  },
  {
    "text": "again for your talk uh everyone uh i think irene if you have time could you join the q a right sorry the hangout",
    "start": "2177760",
    "end": "2185599"
  },
  {
    "text": "right after this sure yeah i'll be there cool if people have questions um don't",
    "start": "2185599",
    "end": "2192160"
  },
  {
    "text": "be shy um come along and ask some questions right there um the link is i think right under",
    "start": "2192160",
    "end": "2199040"
  },
  {
    "text": "this talk it's called hangouts you join right there and with that i think we can end and",
    "start": "2199040",
    "end": "2205760"
  },
  {
    "text": "thank you irene all right thanks so much [Music]",
    "start": "2205760",
    "end": "2218520"
  },
  {
    "text": "you",
    "start": "2220800",
    "end": "2222880"
  }
]
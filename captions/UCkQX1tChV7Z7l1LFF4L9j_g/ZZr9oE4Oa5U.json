[
  {
    "start": "0",
    "end": "273000"
  },
  {
    "text": "today I'm going to be talking about the future of data engineering which is sort of a highfalutin fancy title so in",
    "start": "3889",
    "end": "11840"
  },
  {
    "text": "actuality what I want to cover is I want to give you a little bit of my context about me and I want to present some",
    "start": "11840",
    "end": "20810"
  },
  {
    "text": "various stages of data pipeline maturity I'm gonna kind of twist the blog post",
    "start": "20810",
    "end": "26630"
  },
  {
    "text": "that that Gwen alluded to a bit so that if you've already read it you'll still",
    "start": "26630",
    "end": "32238"
  },
  {
    "text": "get something new if you haven't read it you'll also be getting something new so lastly what I want to do is build out",
    "start": "32239",
    "end": "38200"
  },
  {
    "text": "kind of an architecture as we progress along through the stages so that we land on something that it might be you is",
    "start": "38200",
    "end": "43460"
  },
  {
    "text": "kind of a modern data architecture data pipeline and also maybe a little bit a",
    "start": "43460",
    "end": "48829"
  },
  {
    "text": "hint of where I think we're going in the next couple years so I'll get started with context the reason I want to cover",
    "start": "48829",
    "end": "55760"
  },
  {
    "text": "this in a little more detail than I might otherwise is because I think when I'm doing things like predicting the",
    "start": "55760",
    "end": "61399"
  },
  {
    "text": "future or telling you what how I think things are going to be it's important to know where I'm coming from so that you",
    "start": "61399",
    "end": "67490"
  },
  {
    "text": "all can get a sense for a little bit about my perspective and kind of couch",
    "start": "67490",
    "end": "72740"
  },
  {
    "text": "that with your own perspectives and sort of act accordingly I also want to give you a little context about what I mean by data engineering",
    "start": "72740",
    "end": "78890"
  },
  {
    "text": "because as it turns out that can mean a lot of different things and lastly I",
    "start": "78890",
    "end": "84110"
  },
  {
    "text": "want to do a really brief overview of just why I'm giving this talk and what led to the blog post that Gwen had been",
    "start": "84110",
    "end": "90680"
  },
  {
    "text": "talking about so my name is Chris I work",
    "start": "90680",
    "end": "95869"
  },
  {
    "text": "right now at we pay which is payment processing company were actually part of",
    "start": "95869",
    "end": "101450"
  },
  {
    "text": "JP Morgan Chase at this point we got acquired a few years ago I work on data infrastructure there and data",
    "start": "101450",
    "end": "106729"
  },
  {
    "text": "engineering our stack is airflow Kafka and bigquery for the most part airflow",
    "start": "106729",
    "end": "113540"
  },
  {
    "text": "is of course a job scheduler that kicks off jobs and does workflow kind of things bigquery is a data warehouse",
    "start": "113540",
    "end": "119930"
  },
  {
    "text": "hosted by Google cloud now you'll get a hint of this I make a lot of maybe not a lot but I make some references to Google",
    "start": "119930",
    "end": "126140"
  },
  {
    "text": "cloud in here you can definitely swap them out with corresponding AWS or a0 services for the most part I think they",
    "start": "126140",
    "end": "132830"
  },
  {
    "text": "can be drop in in the context of this talk and lastly Kafka Kafka is a big one we work we use",
    "start": "132830",
    "end": "139340"
  },
  {
    "text": "it a lot at we pay and that kind of leads into my previous history at LinkedIn where I spent about seven years",
    "start": "139340",
    "end": "146050"
  },
  {
    "text": "LinkedIn and was the birthplace of Kafka which is for those of you that might not",
    "start": "146050",
    "end": "151100"
  },
  {
    "text": "be aware a pub/sub sort of right ahead log that's at this point it's a sort of",
    "start": "151100",
    "end": "156680"
  },
  {
    "text": "the backbone of a distributed infrastructure around logging and while I was at LinkedIn I spent a bunch of",
    "start": "156680",
    "end": "162080"
  },
  {
    "text": "time doing everything from data science service infrastructure and so on I also wrote Apache sansa which is a stream",
    "start": "162080",
    "end": "168770"
  },
  {
    "text": "processing system so I'm very interested to hear about the the Netflix stateful stream processing talk that's on this",
    "start": "168770",
    "end": "174230"
  },
  {
    "text": "track I spent some time with Hadoop more job schedulers and more data warehouses",
    "start": "174230",
    "end": "179660"
  },
  {
    "text": "at PayPal so that's me when it comes to data engineering there's all kinds of",
    "start": "179660",
    "end": "186500"
  },
  {
    "text": "different definitions I've seen people using it when they're talking about business analytics I've seen people talk about it in the context of data science",
    "start": "186500",
    "end": "193120"
  },
  {
    "text": "so I I'm gonna throw it out my definition I haven't gonna claim that a data",
    "start": "193120",
    "end": "199430"
  },
  {
    "text": "engineers job is to help an organization move and process data right so on the",
    "start": "199430",
    "end": "205250"
  },
  {
    "text": "movement front we're talking about either streaming pipelines or data pipelines on the processing front we're",
    "start": "205250",
    "end": "210470"
  },
  {
    "text": "talking about data warehouses stream processing usually we're focused a synchronous sort of batch or streaming",
    "start": "210470",
    "end": "217250"
  },
  {
    "text": "based stuff as opposed to synchronous real-time kind of things and I want to call it a keyword help here because I",
    "start": "217250",
    "end": "224390"
  },
  {
    "text": "think I'll tie this in at the end of the talks it just bookmark that that we're not actually in my view supposed to be",
    "start": "224390",
    "end": "230269"
  },
  {
    "text": "moving and processing the data ourselves we're supposed to be helping the organization do that so that was the",
    "start": "230269",
    "end": "236870"
  },
  {
    "text": "what this is a little bit of that how Maxine motioned mean for those of you that don't know is sort of a prolific",
    "start": "236870",
    "end": "244100"
  },
  {
    "text": "engineer he started out I think a yahoo Facebook Airbnb lyft and over the course",
    "start": "244100",
    "end": "250489"
  },
  {
    "text": "of his adventures wrote air flow which is the job scheduler that we use as well as a bunch of other companies and he",
    "start": "250489",
    "end": "256820"
  },
  {
    "text": "also wrote super set and in this blog posts on the rise of the day to engineer that he published a few years ago he",
    "start": "256820",
    "end": "263000"
  },
  {
    "text": "said that data engineers build tools infrastructure frameworks and services right so this is sort of the how how we",
    "start": "263000",
    "end": "269479"
  },
  {
    "text": "go about moving processing the data so why am i giving",
    "start": "269479",
    "end": "274530"
  },
  {
    "start": "273000",
    "end": "546000"
  },
  {
    "text": "this talk the reason that I kind of got down this path was I came across this",
    "start": "274530",
    "end": "280530"
  },
  {
    "text": "blog post it's from a company called Ada and it's a really nice blog post where they talk about their their journey",
    "start": "280530",
    "end": "289050"
  },
  {
    "text": "trying to set up a data warehouse they were a company I think they do virtual assistants I actually don't know that",
    "start": "289050",
    "end": "294090"
  },
  {
    "text": "much about the company but they had a MongoDB database and they were starting to run up against the limits of it when",
    "start": "294090",
    "end": "299550"
  },
  {
    "text": "it came to reporting and some ad hoc query things so eventually they did some",
    "start": "299550",
    "end": "306599"
  },
  {
    "text": "exploration and landed on using Apache airflow and redshift which is of course AWS is data warehousing solution the",
    "start": "306599",
    "end": "315419"
  },
  {
    "text": "thing that struck me about this post was how much it looked like this post the",
    "start": "315419",
    "end": "321360"
  },
  {
    "text": "this is a post that I wrote about three years ago when I landed it at WePay they",
    "start": "321360",
    "end": "327539"
  },
  {
    "text": "didn't have much of a data warehouse and so we got one up and running and we went through almost the exact same exercise",
    "start": "327539",
    "end": "332969"
  },
  {
    "text": "that ADA did we did some evaluation and eventually landed on airflow and",
    "start": "332969",
    "end": "338550"
  },
  {
    "text": "bigquery which is Google clouds version of redshift the striking thing about the",
    "start": "338550",
    "end": "344490"
  },
  {
    "text": "post is that they're there so verbatim that the images showing the architectures are almost identical and",
    "start": "344490",
    "end": "350129"
  },
  {
    "text": "even the structure of the post themselves like what sections are in the post are identical so I thought this was this was kind of interesting because",
    "start": "350129",
    "end": "355860"
  },
  {
    "text": "from my perspective this was something we had done a few years ago and so I kind of threw down the gauntlet that I I",
    "start": "355860",
    "end": "362669"
  },
  {
    "text": "make the claim that I know if they are successful and want to continue building out their data warehouse where they",
    "start": "362669",
    "end": "368069"
  },
  {
    "text": "might end up and so I thought it might be useful to share some of those thoughts and so I kind of made the claim",
    "start": "368069",
    "end": "375479"
  },
  {
    "text": "that one step would be going real time going from batch to real time and the next step might be going to a fully",
    "start": "375479",
    "end": "381389"
  },
  {
    "text": "self-serve or automated pipeline and I want to be clear I'm not trying to pick on that particular blog post or anything",
    "start": "381389",
    "end": "387300"
  },
  {
    "text": "I think it's a perfectly perfectly reasonable solution it just so happens that I think that there's a sort of a",
    "start": "387300",
    "end": "392819"
  },
  {
    "text": "natural progression about the evolution of a data pipeline in a data warehouse and sort of the modern data ecosystem",
    "start": "392819",
    "end": "398399"
  },
  {
    "text": "and that's really what I want to cover in the talk today so I refined this a",
    "start": "398399",
    "end": "403709"
  },
  {
    "text": "little bit I kind of got cute with it and tried to do a land expand on the man kind of thing I was talking with like past",
    "start": "403709",
    "end": "409500"
  },
  {
    "text": "present future but trying to figure out how to categorize this this stuff and these thoughts in a way that really",
    "start": "409500",
    "end": "415620"
  },
  {
    "text": "resonated and made sense so the initial idea was well initially you land you've got nothing so you need",
    "start": "415620",
    "end": "421440"
  },
  {
    "text": "to set up a data warehouse quickly then you expand you start doing more integrations maybe you go to real time",
    "start": "421440",
    "end": "426960"
  },
  {
    "text": "because you've got Kafka in your ecosystem and then finally you you do an expansion where you sorry you do an",
    "start": "426960",
    "end": "432600"
  },
  {
    "text": "automation where you start doing on-demand stuff that eventually led to this post where where I talked about",
    "start": "432600",
    "end": "440160"
  },
  {
    "text": "three trends or sorry four trends that I see coming down the road the first one",
    "start": "440160",
    "end": "446460"
  },
  {
    "text": "is timeliness where I see us going from this batch based periodic architecture",
    "start": "446460",
    "end": "452790"
  },
  {
    "text": "to a more real-time architecture and the second one is connectivity where once",
    "start": "452790",
    "end": "458730"
  },
  {
    "text": "you go down the timeliness route you start doing more integration with other systems and then the last two I think",
    "start": "458730",
    "end": "465960"
  },
  {
    "text": "kind of tied together automation and decentralization on the automation front I think we need to start thinking about",
    "start": "465960",
    "end": "473640"
  },
  {
    "text": "operating not just our operations but our data management and I'll go into that today and then decentralizing the",
    "start": "473640",
    "end": "478890"
  },
  {
    "text": "data warehouse as a total so what I didn't do in that talk in that post and",
    "start": "478890",
    "end": "484620"
  },
  {
    "text": "what I want to do today is kind of put a hierarchy up in front of it",
    "start": "484620",
    "end": "490380"
  },
  {
    "text": "and I'm kind of gonna walk through these stages sequentially and as I mentioned",
    "start": "490380",
    "end": "495390"
  },
  {
    "text": "earlier build out a little bit bit of an architectural diagram so we can see where we end up the reason I wanted to",
    "start": "495390",
    "end": "501720"
  },
  {
    "text": "go down this path is I found as I was thinking about future it was occurring to me everyone's future is different because you're all at a different point",
    "start": "501720",
    "end": "507870"
  },
  {
    "text": "in your life cycle you know if you're ADA your future looks very different than somebody like WePay wherever may be farther along on some dimensions and",
    "start": "507870",
    "end": "514380"
  },
  {
    "text": "then there are companies that are even farther along than us so I think this kind of lets you choose your own",
    "start": "514380",
    "end": "519750"
  },
  {
    "text": "adventure and build out a little bit of a roadmap for yourself so I'm gonna start with the none stage",
    "start": "519750",
    "end": "526860"
  },
  {
    "text": "I wouldn't sure what to call this I couldn't think of anything clever but you're probably at this stage if you",
    "start": "526860",
    "end": "533040"
  },
  {
    "text": "have no data warehouse you've probably got a monolithic architecture or maybe a smaller company",
    "start": "533040",
    "end": "538470"
  },
  {
    "text": "and you need a warehouse up and running like now you probably also don't have too many data engineers and so you're",
    "start": "538470",
    "end": "545070"
  },
  {
    "text": "kind of doing this on the side it looks like this we're all familiar with our lovely monolith in our database and and",
    "start": "545070",
    "end": "551279"
  },
  {
    "start": "546000",
    "end": "672000"
  },
  {
    "text": "this is where you take a user and you attach it to this and this kind of sounds crazy to people that have been in",
    "start": "551279",
    "end": "556620"
  },
  {
    "text": "the data warehouse world for a while but it's actually a pretty viable solution when you need to get things up and",
    "start": "556620",
    "end": "562529"
  },
  {
    "text": "running the latency of the data that the users are looking at is basically real-time because you're clearing the",
    "start": "562529",
    "end": "567810"
  },
  {
    "text": "database and it's pretty easy and cheap and this is this is actually where I",
    "start": "567810",
    "end": "572820"
  },
  {
    "text": "landed it we when I landed it we pay where they were at so about 2014 when I joined we had a PHP monolith and then",
    "start": "572820",
    "end": "579720"
  },
  {
    "text": "basically a monolithic my sequel database the users I had though weren't quite as happy and noticed there's more",
    "start": "579720",
    "end": "586769"
  },
  {
    "text": "than one of them there so things were starting to tip over a little bit we had",
    "start": "586769",
    "end": "593519"
  },
  {
    "text": "queries timing out we had users impacting each other most OLTP systems that you're going to be using are not",
    "start": "593519",
    "end": "599850"
  },
  {
    "text": "going to be fairly strong on the isolation front so users can really get",
    "start": "599850",
    "end": "604890"
  },
  {
    "text": "in each other's way because we were using my sequel it was missing some of the more fancy analytic sequel stuff",
    "start": "604890",
    "end": "610470"
  },
  {
    "text": "that our data science and business analytics people wanted and report generation was starting to tip over",
    "start": "610470",
    "end": "616140"
  },
  {
    "text": "right so a pretty pretty normal story there we go and so we started to go down",
    "start": "616140",
    "end": "623910"
  },
  {
    "text": "the batch path and this is where the ADA Post comes in and that earlier post I mentioned also comes in so on this path",
    "start": "623910",
    "end": "630540"
  },
  {
    "text": "right you have a monolithic architecture probably you might be starting to trend",
    "start": "630540",
    "end": "635699"
  },
  {
    "text": "away from that a little bit but usually it works best when you have relatively few sources data engineering is now",
    "start": "635699",
    "end": "642209"
  },
  {
    "text": "probably your part-time job you've got queries as I mentioned as we were suffering from that are timing out",
    "start": "642209",
    "end": "647699"
  },
  {
    "text": "you're exceeding the database capacity so whether it's space memory or CPU",
    "start": "647699",
    "end": "652740"
  },
  {
    "text": "you're starting to see queries just not come back I mentioned the complex analytics equal",
    "start": "652740",
    "end": "658740"
  },
  {
    "text": "stuff and reports are becoming more and more of an issue for your organization and those could be customer facing",
    "start": "658740",
    "end": "664350"
  },
  {
    "text": "reports or internal reports and people are starting to ask for things like charts and business intelligence and all",
    "start": "664350",
    "end": "669930"
  },
  {
    "text": "that kind of fun stuff and that's where the classic you know batch based approach that I think most people are",
    "start": "669930",
    "end": "677459"
  },
  {
    "start": "672000",
    "end": "901000"
  },
  {
    "text": "familiar with comes in in between the database and the user use stuff data warehouse that can accomplish a lot more",
    "start": "677459",
    "end": "684720"
  },
  {
    "text": "of the more OLAP and you know analysis kind of needs analytic needs and to get",
    "start": "684720",
    "end": "690180"
  },
  {
    "text": "data from the database into that data warehouse you have a scheduler that will periodically wake up and suck the data",
    "start": "690180",
    "end": "695430"
  },
  {
    "text": "in so that's where we were at maybe about 2016 this is probably about a year",
    "start": "695430",
    "end": "700980"
  },
  {
    "text": "after I joined and this this architecture is actually pretty fantastic in terms of trade-offs you can",
    "start": "700980",
    "end": "708209"
  },
  {
    "text": "get the pipeline up pretty quickly these days at the time I did it in 2016 it",
    "start": "708209",
    "end": "713850"
  },
  {
    "text": "took like a couple weeks the data latency we had was about 15 minutes so we were doing incremental partition",
    "start": "713850",
    "end": "719819"
  },
  {
    "text": "loads where we would take little chunks of data and load them in and we could handle we were running I think a few",
    "start": "719819",
    "end": "725190"
  },
  {
    "text": "hundred tables and this actually in if you think back to that land expand on-demand kind of hierarchy that I was",
    "start": "725190",
    "end": "731490"
  },
  {
    "text": "attempting to impose if you're just trying to get something up and running this is a really nice place to start off",
    "start": "731490",
    "end": "737010"
  },
  {
    "text": "with but of course you outgrow it so at",
    "start": "737010",
    "end": "742350"
  },
  {
    "text": "some point the number of airflow workflows that we had you know went from",
    "start": "742350",
    "end": "747360"
  },
  {
    "text": "a few hundred to a few thousand we started running tens or hundreds of thousands of tasks per day so that the",
    "start": "747360",
    "end": "754949"
  },
  {
    "text": "likelihood that all those are going to work starts to not be that probable so that became a bit of an operational",
    "start": "754949",
    "end": "760920"
  },
  {
    "text": "issue we also discovered and this is a little less intuitive the people that haven't actually run complex data",
    "start": "760920",
    "end": "766890"
  },
  {
    "text": "pipelines but you in an incremental or batch based approach you start having to impose dependencies on the schemas or",
    "start": "766890",
    "end": "774120"
  },
  {
    "text": "requirements on the schemas of the data that you're loading so we had issues with create times and modify times and",
    "start": "774120",
    "end": "779579"
  },
  {
    "text": "RMS doing things in different ways and and it got a little complicated for us DBAs were impacting our workload so if",
    "start": "779579",
    "end": "786750"
  },
  {
    "text": "they do something that that kind of hurts our replicas that we were reading off of it can cause latency issues which",
    "start": "786750",
    "end": "792300"
  },
  {
    "text": "can in turn cause us to miss data hard deletes weren't being propagated and",
    "start": "792300",
    "end": "797490"
  },
  {
    "text": "this is a big one if you have people that delete data from your database this is you know something I think most",
    "start": "797490",
    "end": "804400"
  },
  {
    "text": "people don't want to do but most people do do whether it's removing in a row or",
    "start": "804400",
    "end": "809470"
  },
  {
    "text": "a table or whatever it is that can cause problems with batch loads as well because you just don't know when the data disappears latency I mentioned and",
    "start": "809470",
    "end": "816970"
  },
  {
    "text": "of course more time outs this time the timeouts are happening on your workflow though now this is where real time kicks",
    "start": "816970",
    "end": "826090"
  },
  {
    "text": "off and this is where I'm gonna maybe go a little more in depth than I have over the first two stages because I think now",
    "start": "826090",
    "end": "831190"
  },
  {
    "text": "we're approaching sort of what I would consider the cusp or the modern era of real-time data architecture so you might",
    "start": "831190",
    "end": "838960"
  },
  {
    "text": "be ready for this if your load times are taking too long you've got pipelines that are no longer",
    "start": "838960",
    "end": "845230"
  },
  {
    "text": "stable whether that's workflows being failing or my sequel or whatever your",
    "start": "845230",
    "end": "850330"
  },
  {
    "text": "are DBMS is having issues serving the data you've got complicated workflows",
    "start": "850330",
    "end": "856170"
  },
  {
    "text": "data latency is is becoming a bigger problem and what I mean here is essentially you know maybe the 15-minute",
    "start": "856170",
    "end": "862420"
  },
  {
    "text": "jobs you started off with in 2014 or 2016 are now taking an hour or a day and",
    "start": "862420",
    "end": "868410"
  },
  {
    "text": "people that are using it aren't as happy about it data engineering now is probably your",
    "start": "868410",
    "end": "873730"
  },
  {
    "text": "full-time job right and lastly you look around the ecosystem you are not-- you",
    "start": "873730",
    "end": "880600"
  },
  {
    "text": "might have something like apache Kafka in your back pocket maybe the operations folks have spun it up to do log",
    "start": "880600",
    "end": "885730"
  },
  {
    "text": "aggregation and and run some operational metrics over it maybe some web services are communicating via Kafka to do some",
    "start": "885730",
    "end": "893620"
  },
  {
    "text": "queuing or asynchronous processing it's probably you know floating around in your ecosystem at this point so from a",
    "start": "893620",
    "end": "900670"
  },
  {
    "text": "data pipeline perspective what we're gonna do is is get rid of that batch processor for ETL purposes and replace",
    "start": "900670",
    "end": "908440"
  },
  {
    "start": "901000",
    "end": "927000"
  },
  {
    "text": "it with a streaming platform right and so that's what we did we wrote up a post",
    "start": "908440",
    "end": "913630"
  },
  {
    "text": "where we we got rid of well I shouldn't say we got rid of air flow but we changed our ETL pipeline from air flow",
    "start": "913630",
    "end": "921220"
  },
  {
    "text": "to debbie's ium and a few other systems so it started to look a little bit like",
    "start": "921220",
    "end": "926260"
  },
  {
    "text": "this and so this is where we were in about 2017 we introduced so you can see",
    "start": "926260",
    "end": "933160"
  },
  {
    "start": "927000",
    "end": "987000"
  },
  {
    "text": "the earth the little air flow box now has one two three four five boxes in it and we're talking about many",
    "start": "933160",
    "end": "939820"
  },
  {
    "text": "machines so the operational complexity has gone up but in exchange for that we've got a real-time pipeline now so",
    "start": "939820",
    "end": "945520"
  },
  {
    "text": "we've got Kafka and I'm not going to go into too much detail about what that is I will do a very brief overview which is",
    "start": "945520",
    "end": "953800"
  },
  {
    "text": "that it is a right ahead log that you can use to either produce messages to they get appended to the end of the log",
    "start": "953800",
    "end": "959770"
  },
  {
    "text": "and you can have consumers that are reading from various locations in that log so it's a sequential read and sequential write kind of a thing we use",
    "start": "959770",
    "end": "968350"
  },
  {
    "text": "it with these connectors so it has this ecosystem and this framework called",
    "start": "968350",
    "end": "973510"
  },
  {
    "text": "Kafka connect one of the connectors where heavy user of is the B's IAM so this is a change data capture connector",
    "start": "973510",
    "end": "980110"
  },
  {
    "text": "that reads data from my sequel in real time and funnels it into Kafka also in",
    "start": "980110",
    "end": "985180"
  },
  {
    "text": "real time and I said a magic word there that actually may not be familiar to",
    "start": "985180",
    "end": "990190"
  },
  {
    "start": "987000",
    "end": "1081000"
  },
  {
    "text": "many people here but change data capture is essentially a way to replicate data",
    "start": "990190",
    "end": "996520"
  },
  {
    "text": "from one data source to others wikis wikipedia has got this nice little write-up where they're talking about the",
    "start": "996520",
    "end": "1002250"
  },
  {
    "text": "identification capture and delivery of changes made to the enterprise data sources sounds very fancy but to give",
    "start": "1002250",
    "end": "1008790"
  },
  {
    "text": "you a concrete example what something like the museum will do is if I have a in our case on my sequel database and I",
    "start": "1008790",
    "end": "1014970"
  },
  {
    "text": "insert a row and then maybe I update that row and at some future time I delete it the CDC feed change data capture feed",
    "start": "1014970",
    "end": "1021959"
  },
  {
    "text": "will give me three different events and insert the update and the delete and in some cases it will actually give me the",
    "start": "1021959",
    "end": "1027839"
  },
  {
    "text": "before in the after so if an update occurs it will show what it was like before and then what it was like what the row looked like after so you can",
    "start": "1027839",
    "end": "1035160"
  },
  {
    "text": "imagine this can be kind of useful if you're building out a data warehouse right so DBZ ins got a bunch of sources",
    "start": "1035160",
    "end": "1041370"
  },
  {
    "text": "we use my sequel as I mentioned now again if you think back to that ADA Post I referenced at the beginning of this",
    "start": "1041370",
    "end": "1046770"
  },
  {
    "text": "talk one of the things about that post that caught my eye was the fact that they were using MongoDB and sure enough",
    "start": "1046770",
    "end": "1051950"
  },
  {
    "text": "the museum has a MongoDB connector I should also call out Cassandra is",
    "start": "1051950",
    "end": "1057240"
  },
  {
    "text": "something that I'll be talking a little bit about in the later portions of this talk it's a connector that we contributed to the museum just a couple",
    "start": "1057240",
    "end": "1063900"
  },
  {
    "text": "months ago it's incubating and we're still getting up off the ground with it ourselves but that's something that we're going to be",
    "start": "1063900",
    "end": "1070020"
  },
  {
    "text": "using pretty heavily and your future lastly quick shout out for the data track this is ganar right up here in the front",
    "start": "1070020",
    "end": "1075850"
  },
  {
    "text": "row he's going to be talking later today so if you guys are interested in the museum more you should definitely come to his talk ok back to our pipeline last",
    "start": "1075850",
    "end": "1083950"
  },
  {
    "start": "1081000",
    "end": "1332000"
  },
  {
    "text": "but not least we have KC BQ which stands for Kafka Connect bigquery I do not name",
    "start": "1083950",
    "end": "1089440"
  },
  {
    "text": "things creatively so this is just a connector that takes data from Kafka and loads it into bigquery the cool thing",
    "start": "1089440",
    "end": "1096490"
  },
  {
    "text": "about this though is that it leverages big queries real-time streaming insert",
    "start": "1096490",
    "end": "1101679"
  },
  {
    "text": "API so when you think about most data warehouses they tend to be more batch load because they're just assuming that",
    "start": "1101679",
    "end": "1107110"
  },
  {
    "text": "you're going to be doing batch batch loads so going to that back to my LinkedIn days HDFS at the time was all",
    "start": "1107110",
    "end": "1112809"
  },
  {
    "text": "batch based we had actually MapReduce tasks that would spin up read from Kafka",
    "start": "1112809",
    "end": "1117850"
  },
  {
    "text": "since the last time they ran and then load them into HDFS and then shut down again and they would do this periodically even though the Kafka feed",
    "start": "1117850",
    "end": "1123730"
  },
  {
    "text": "was real-time HDFS was just not set up for it at that time one of the cool things about bigquery is it has",
    "start": "1123730",
    "end": "1128769"
  },
  {
    "text": "basically a restful api you can use to post data into the data warehouse in",
    "start": "1128769",
    "end": "1134289"
  },
  {
    "text": "real time and it's visible almost immediately so what that gives us is a",
    "start": "1134289",
    "end": "1139779"
  },
  {
    "text": "data warehouse where the latency from our production database to our data warehouse is about 5 seconds give or",
    "start": "1139779",
    "end": "1146710"
  },
  {
    "text": "take it's actually a little less usually more like a couple seconds and and this pattern really opens up a lot of use",
    "start": "1146710",
    "end": "1152529"
  },
  {
    "text": "cases so first off it lets you do real-time metrics and business intelligence off of your data warehouse",
    "start": "1152529",
    "end": "1159059"
  },
  {
    "text": "it also allows you to do debugging which is something that's not immediately obvious but if your engineers need to",
    "start": "1159059",
    "end": "1166750"
  },
  {
    "text": "see the state of their database in production right now being able to go the to the data warehouse to do that is",
    "start": "1166750",
    "end": "1172720"
  },
  {
    "text": "actually a pretty nice way to expose that state to them so that they can figure out what's going on with their",
    "start": "1172720",
    "end": "1178269"
  },
  {
    "text": "system and the fact that they're seeing a real-time you know within 5 second view of that world is pretty handy and",
    "start": "1178269",
    "end": "1185500"
  },
  {
    "text": "lastly you can do some kind of fancy monitoring stuff with it you can start to impose sort of assertions about what",
    "start": "1185500",
    "end": "1192159"
  },
  {
    "text": "the shape of the data should look like in the database so that not only do you know that the data warehouse is healthy",
    "start": "1192159",
    "end": "1197260"
  },
  {
    "text": "but that the underlying web service itself might be healthy and there are of",
    "start": "1197260",
    "end": "1202690"
  },
  {
    "text": "course some problems with this not all of our connectors at that point in time when we first did the migration",
    "start": "1202690",
    "end": "1207940"
  },
  {
    "text": "were on this pipeline so we're now sort of in this world where we have the new cool stuff and the the old older painful",
    "start": "1207940",
    "end": "1213429"
  },
  {
    "text": "stuff datastore is a Google cloud system that we were using that was still air flow based Cassandra as I mentioned",
    "start": "1213429",
    "end": "1218980"
  },
  {
    "text": "didn't have a connector really and BigTable which is a Google cloud hosted",
    "start": "1218980",
    "end": "1224230"
  },
  {
    "text": "version I hate to say version but of each table or HBase so we use all these",
    "start": "1224230",
    "end": "1229750"
  },
  {
    "text": "systems as well right in addition to that we've got big query but bigquery needed more than just our primary OLTP",
    "start": "1229750",
    "end": "1236080"
  },
  {
    "text": "data it needed logging and metrics we had elasticsearch in the mix now and we've got this fancy graph database that",
    "start": "1236080",
    "end": "1242320"
  },
  {
    "text": "we're going to be open sourcing soon that needs data as well so the ecosystem starts looking more complicated right so",
    "start": "1242320",
    "end": "1249280"
  },
  {
    "text": "we're no longer talking about this little monolithic database a huge hat tip to confluent for for the image here",
    "start": "1249280",
    "end": "1256270"
  },
  {
    "text": "I think it's pretty accurate so this is tough we have to start figuring out how",
    "start": "1256270",
    "end": "1264190"
  },
  {
    "text": "to managing some of this operational pain and one of the first things you can do is start to do some integration so",
    "start": "1264190",
    "end": "1270520"
  },
  {
    "text": "that you have fewer systems to deal with here and for us we leveraged Kafka for",
    "start": "1270520",
    "end": "1275559"
  },
  {
    "text": "that so you might be ready for data integration and really this is if you",
    "start": "1275559",
    "end": "1281500"
  },
  {
    "text": "think back 20 years to sort of like enterprise service bus architectures that's really all this is in a nutshell",
    "start": "1281500",
    "end": "1287169"
  },
  {
    "text": "the only difference is that platforms in streaming platforms like Kafka along with sort of the evolution and stream",
    "start": "1287169",
    "end": "1295330"
  },
  {
    "text": "processing that's happened over the last 10 years or so has made this really viable so you might be ready if you've",
    "start": "1295330",
    "end": "1301600"
  },
  {
    "text": "got a lot of micro services you've got a diverse set of data bases as I showed in that last picture you've got some",
    "start": "1301600",
    "end": "1308230"
  },
  {
    "text": "specialized Drive data systems so I mentioned graph databases but you may have special caches you might have a",
    "start": "1308230",
    "end": "1313809"
  },
  {
    "text": "real-time OLAP system and you've got maybe a team of data engineers now enough people that are responsible that",
    "start": "1313809",
    "end": "1320530"
  },
  {
    "text": "they can start to manage some of this complex workload and lastly hopefully you've got a really happy mature sre",
    "start": "1320530",
    "end": "1327280"
  },
  {
    "text": "organization that's more than willing to take on all these connectors for you so",
    "start": "1327280",
    "end": "1333760"
  },
  {
    "start": "1332000",
    "end": "1425000"
  },
  {
    "text": "this is what it looks like you'll see we've still got sort of the base data pipeline that we've had so far we've got a service with a DB",
    "start": "1333760",
    "end": "1340270"
  },
  {
    "text": "we've got our streaming platform and we've got our data warehouse but now we've got the Web Services maybe we've",
    "start": "1340270",
    "end": "1345370"
  },
  {
    "text": "got a no sequel thing or we've got this new sequel thing we've got a graph database there and then I've also got",
    "start": "1345370",
    "end": "1351790"
  },
  {
    "text": "some some search diagram there to plug it in this is an example in our case a",
    "start": "1351790",
    "end": "1358000"
  },
  {
    "text": "concrete instance of this would be around where we were at the beginning of the year right so things are getting even more complicated now now we've",
    "start": "1358000",
    "end": "1364330"
  },
  {
    "text": "gotten a bzm connected not only to my sequel but we've got it connected to Cassandra as well highlight that and",
    "start": "1364330",
    "end": "1372700"
  },
  {
    "text": "this is as I mentioned previously the connector that we've been working with with ganar and company on to try and get",
    "start": "1372700",
    "end": "1378220"
  },
  {
    "text": "it off the ground you'll see down in the bottom there we've also got kcw which is a stands for",
    "start": "1378220",
    "end": "1385480"
  },
  {
    "text": "Kafka connect waltz so waltzes is a sort of ledger that we've built in-house that's kind of Kafka ish in some ways",
    "start": "1385480",
    "end": "1393070"
  },
  {
    "text": "and kind of more like a database in subways but it services our our ledger",
    "start": "1393070",
    "end": "1398320"
  },
  {
    "text": "use cases and our ledger needs because we are a payment processing system we",
    "start": "1398320",
    "end": "1403360"
  },
  {
    "text": "care a lot about data transactionality and multi-region availability and so it's sort of a quorum based right ahead",
    "start": "1403360",
    "end": "1408370"
  },
  {
    "text": "log that handles serializable transactions and on the downstream side",
    "start": "1408370",
    "end": "1413980"
  },
  {
    "text": "as I mentioned we've got a bunch of this stuff going on right so so why why are we incurring all this pain why are there",
    "start": "1413980",
    "end": "1420550"
  },
  {
    "text": "so many boxes this is getting more and more complicated right the answer has to",
    "start": "1420550",
    "end": "1426070"
  },
  {
    "start": "1425000",
    "end": "1461000"
  },
  {
    "text": "do with Metcalfe's law for those of you that don't know I'm going to paraphrase",
    "start": "1426070",
    "end": "1431250"
  },
  {
    "text": "and probably corrupt it quite a bit but essentially what it is is a statement that the value of a network increases",
    "start": "1431250",
    "end": "1437920"
  },
  {
    "text": "the more nodes and connections you add to it it's usually used in the context of social networking where people are",
    "start": "1437920",
    "end": "1444610"
  },
  {
    "text": "always talking about adding more nodes and edges but it was initially actually intended to be used for communication",
    "start": "1444610",
    "end": "1451390"
  },
  {
    "text": "devices so adding more peripherals to an Ethernet network is what the Wikipedia page said so this is what we're talking",
    "start": "1451390",
    "end": "1457780"
  },
  {
    "text": "about we're talking about getting to a network effect in our data ecosystem this leads me to a post yet another",
    "start": "1457780",
    "end": "1463570"
  },
  {
    "start": "1461000",
    "end": "1600000"
  },
  {
    "text": "positions like plugging all my blog post there's another post that I wrote earlier in the year where I kind of",
    "start": "1463570",
    "end": "1468730"
  },
  {
    "text": "thought through the implications of Kafka as your escape hatch so when you leverage this kind of network",
    "start": "1468730",
    "end": "1474340"
  },
  {
    "text": "effect in the data ecosystem what your what you're doing is adding more and more systems to the kafka bus that are",
    "start": "1474340",
    "end": "1481330"
  },
  {
    "text": "now able to load their data in and expose it to other systems and slurp up the data of those systems so we've found",
    "start": "1481330",
    "end": "1487179"
  },
  {
    "text": "this to be a pretty powerful architecture because your data becomes really portable and so it leads to some",
    "start": "1487179",
    "end": "1493210"
  },
  {
    "text": "advantages first off I'm not gonna say it lets you avoid vendor lock-in but at least ameliorate some of those concerns",
    "start": "1493210",
    "end": "1499119"
  },
  {
    "text": "because if your data is portable usually that's kind of the harder part to deal",
    "start": "1499119",
    "end": "1504879"
  },
  {
    "text": "with when you're moving between systems and so the idea that you could say if you're on Splunk plug-in elasticsearch",
    "start": "1504879",
    "end": "1511389"
  },
  {
    "text": "alongside it to test it out suddenly becomes theoretically possible the the",
    "start": "1511389",
    "end": "1517899"
  },
  {
    "text": "cost to do so certainly gets lowered it also helps with multi cloud strategy so",
    "start": "1517899",
    "end": "1522909"
  },
  {
    "text": "if you you know need to run on multiple clouds because you need really high availability or want you know again want",
    "start": "1522909",
    "end": "1529299"
  },
  {
    "text": "to just be able to pick the cloud vendors against each other to save money you can do that and you can move use",
    "start": "1529299",
    "end": "1535749"
  },
  {
    "text": "Kafka and the Kafka bus as a way to move the data around and lastly I think it",
    "start": "1535749",
    "end": "1541509"
  },
  {
    "text": "leads to infrastructure agility and I kind of alluded to this with my elasticsearch example but if you come",
    "start": "1541509",
    "end": "1547149"
  },
  {
    "text": "across some new you know hot real-time OLAP system that you want to check out or you know some new cache that you want",
    "start": "1547149",
    "end": "1552729"
  },
  {
    "text": "to plug in the fact that your data is already in your streaming platform your Kafka means that all you really need to",
    "start": "1552729",
    "end": "1559389"
  },
  {
    "text": "do is turn on the new system and plug in a sync for it to load the data and you can at least start to get a feel for how",
    "start": "1559389",
    "end": "1565989"
  },
  {
    "text": "the system is going to behave and how the pipeline might behave so so it drastically lowers the cost of testing",
    "start": "1565989",
    "end": "1571089"
  },
  {
    "text": "the water with new things and supporting specialized infrastructure so these are things that maybe do one or two things",
    "start": "1571089",
    "end": "1578049"
  },
  {
    "text": "really well that normally you might have to kind of decide on a trade-off between operationally do we want to support the",
    "start": "1578049",
    "end": "1584649"
  },
  {
    "text": "specialized piece of infrastructure like a graph database or do we want to use an RD BMS which just so happens to have",
    "start": "1584649",
    "end": "1590019"
  },
  {
    "text": "joins and so it by reducing the cost you can start to get a little bit of a more",
    "start": "1590019",
    "end": "1595179"
  },
  {
    "text": "granular set of infrastructure to handle your queries now the problems here look",
    "start": "1595179",
    "end": "1602169"
  },
  {
    "start": "1600000",
    "end": "1703000"
  },
  {
    "text": "a little different right what we found ourselves doing when we",
    "start": "1602169",
    "end": "1608789"
  },
  {
    "text": "moved to this architecture and sort of bought in and did a bunch of the integration was we were spending a lot",
    "start": "1608789",
    "end": "1615990"
  },
  {
    "text": "of time doing fairly manual stuff so adding channels for my sequel DB's",
    "start": "1615990",
    "end": "1621240"
  },
  {
    "text": "adding you know topics for Kafka setting up the museum connectors creating datasets you know you can read though",
    "start": "1621240",
    "end": "1627029"
  },
  {
    "text": "the whole list here right and you know in short we were spending a lot of time",
    "start": "1627029",
    "end": "1632519"
  },
  {
    "text": "administering the the data says the the systems around the streaming platform so",
    "start": "1632519",
    "end": "1638250"
  },
  {
    "text": "a lot of the connectors the upstream databases the downstream data warehouses and our ticket load started to go",
    "start": "1638250",
    "end": "1643769"
  },
  {
    "text": "something like this so these are there's a screen shot for those of you that are huge fans of JIRA you might recognize",
    "start": "1643769",
    "end": "1648809"
  },
  {
    "text": "this this is a screenshot of our support load in JIRA over the past 300 days or",
    "start": "1648809",
    "end": "1654720"
  },
  {
    "text": "so and you can see it's like kind of happy at the beginning of the year it's relatively low and then like around May",
    "start": "1654720",
    "end": "1660419"
  },
  {
    "text": "or March it's kind of skyrockets and it hasn't ever really fully recovered although there's a nice trend over the",
    "start": "1660419",
    "end": "1667169"
  },
  {
    "text": "last couple months that I'll get into right now we started investing in",
    "start": "1667169",
    "end": "1672809"
  },
  {
    "text": "automation right and this is something you've got to do when you're when your system gets so big it's kind of a Noda",
    "start": "1672809",
    "end": "1678389"
  },
  {
    "text": "thing I think most people would say well yeah you should have been automating all along right that's that's like table",
    "start": "1678389",
    "end": "1684330"
  },
  {
    "text": "stakes so you might be ready for this",
    "start": "1684330",
    "end": "1689460"
  },
  {
    "text": "step if you're sres can't keep up you're spending a lot of time on manual toil and I'll get into what I mean by toil a",
    "start": "1689460",
    "end": "1696240"
  },
  {
    "text": "little bit and you don't have time for",
    "start": "1696240",
    "end": "1701279"
  },
  {
    "text": "the fun stuff so I want to add two new",
    "start": "1701279",
    "end": "1707190"
  },
  {
    "start": "1703000",
    "end": "1831000"
  },
  {
    "text": "layers here the first one as I mentioned is the automation of operations and this is something like I said that most",
    "start": "1707190",
    "end": "1713220"
  },
  {
    "text": "people are gonna not be too surprised about you know whether it's just the devops stuff has been going on for a",
    "start": "1713220",
    "end": "1719100"
  },
  {
    "text": "long time I think a lot of people are very familiar with it but there's a second layer in here that I don't think is quite as obvious and that is the data",
    "start": "1719100",
    "end": "1727289"
  },
  {
    "text": "management automation layer so I'm gonna go into both of these now so first off",
    "start": "1727289",
    "end": "1732960"
  },
  {
    "text": "we'll cover automation for operations I'll do that relatively quickly because I don't think there a ton of new ground to cover here but",
    "start": "1732960",
    "end": "1739610"
  },
  {
    "text": "there's a great quote from Google s re handbook where I think the chapter is",
    "start": "1739610",
    "end": "1745770"
  },
  {
    "text": "actually on toil and they defined toil as like manual repeatable automatable",
    "start": "1745770",
    "end": "1752640"
  },
  {
    "text": "stuff it's usually interrupt ribbons you're getting slacks or tickets or people are showing up at your desk asking you to do things and they're",
    "start": "1752640",
    "end": "1759210"
  },
  {
    "text": "saying if a human operator needs to touch your system during normal operations you have a bug right that is",
    "start": "1759210",
    "end": "1764970"
  },
  {
    "text": "not what you want to be doing and so what are normal operations for data engineering well it's all the stuff we were spending our time on right it's all",
    "start": "1764970",
    "end": "1772290"
  },
  {
    "text": "this like anytime you're adding managing a pipeline you're gonna be adding new topics and adding new datasets and shutting up views and granting access",
    "start": "1772290",
    "end": "1778260"
  },
  {
    "text": "this stuff needs to get automated so great news there's a bunch of solutions",
    "start": "1778260",
    "end": "1784350"
  },
  {
    "text": "for this right terraform ansible on and on I saw there was a good talk on",
    "start": "1784350",
    "end": "1789540"
  },
  {
    "text": "terraform yesterday from one of my old co-workers but anyhow I we we pay use",
    "start": "1789540",
    "end": "1797730"
  },
  {
    "text": "terraform and ansible but like I said you can substitute any one of these out",
    "start": "1797730",
    "end": "1802920"
  },
  {
    "text": "if you want to and it doesn't look terribly surprising you can use it to manage your topics right here's an",
    "start": "1802920",
    "end": "1808380"
  },
  {
    "text": "example where you've got some system D log thing where you're logging some stuff and you're using compaction which",
    "start": "1808380",
    "end": "1814620"
  },
  {
    "text": "is kind of an exciting policy to use with your system D logs but I'll digress and you can also manage your Kafka",
    "start": "1814620",
    "end": "1822210"
  },
  {
    "text": "connect connectors these are like the Debbie's iums and the kcv queues and the KC double use of the world so not",
    "start": "1822210",
    "end": "1829410"
  },
  {
    "text": "terribly surprising we should be doing this but we we kind of are doing this right so we have terraform we've had",
    "start": "1829410",
    "end": "1835830"
  },
  {
    "start": "1831000",
    "end": "1901000"
  },
  {
    "text": "ansible for a long time we're moving now to terraform and packable and more packer and more immutable deploys but",
    "start": "1835830",
    "end": "1842100"
  },
  {
    "text": "long story short we've got a bunch of operational tooling we're fancy and we're on the cloud and we have a bunch",
    "start": "1842100",
    "end": "1850470"
  },
  {
    "text": "of scripts that we use to manage bigquery and automate a lot of our are what I would call toil things like",
    "start": "1850470",
    "end": "1856830"
  },
  {
    "text": "creating views and bigquery creating datasets and so on so why why are we still having such a high ticket load and",
    "start": "1856830",
    "end": "1863370"
  },
  {
    "text": "the answer is we are spending a lot of time on or we were spending a lot of time on data management so we're",
    "start": "1863370",
    "end": "1870240"
  },
  {
    "text": "answering questions like well who's gonna get access to this data once I load it you know how long how",
    "start": "1870240",
    "end": "1875490"
  },
  {
    "text": "long am I allowed to keep this data hey security is it okay to to persist this data indefinitely or do we need to have a three year truncation policy is the",
    "start": "1875490",
    "end": "1883020"
  },
  {
    "text": "data allowed in the system even you know again we pay is sort of a payment",
    "start": "1883020",
    "end": "1889350"
  },
  {
    "text": "processor so we deal with some pretty sensitive information you know what geography can it be in and",
    "start": "1889350",
    "end": "1895169"
  },
  {
    "text": "you know should there be certain columns that gets tripped out redacted you know",
    "start": "1895169",
    "end": "1900600"
  },
  {
    "text": "stuff like that so as I mentioned I think we pay I won't say we're on the forefront of this but we certainly deal",
    "start": "1900600",
    "end": "1906809"
  },
  {
    "start": "1901000",
    "end": "1962000"
  },
  {
    "text": "not necessarily with regulation but with policy and compliance stuff we have a fairly robust compliance arm that's part",
    "start": "1906809",
    "end": "1913260"
  },
  {
    "text": "of JPMorgan Chase in addition to that because we deal with credit cards we have PCI audits and we deal with you",
    "start": "1913260",
    "end": "1919980"
  },
  {
    "text": "know credit card data so we really need to think about this and I don't think we're alone and I think this is going to",
    "start": "1919980",
    "end": "1926159"
  },
  {
    "text": "become just more and more of a theme so get used to it like we're gonna have to start doing a lot of this stuff and I just that's the the reality of situation",
    "start": "1926159",
    "end": "1933150"
  },
  {
    "text": "I think you know if you're in Europe you're talking about GDP are CCPA is for",
    "start": "1933150",
    "end": "1940260"
  },
  {
    "text": "California we have PCI if you've got credit card data HIPAA for Health Sox is if your public shield is one I didn't",
    "start": "1940260",
    "end": "1945840"
  },
  {
    "text": "even know about but apparently that's in New York on and on and on right so so we're gonna have to really start getting",
    "start": "1945840",
    "end": "1952860"
  },
  {
    "text": "better at automating this stuff or else are our lives as data engineers is mostly just going to be spent chasing",
    "start": "1952860",
    "end": "1958559"
  },
  {
    "text": "people around trying to make sure this stuff is compliant so I want to talk a",
    "start": "1958559",
    "end": "1965250"
  },
  {
    "start": "1962000",
    "end": "2178000"
  },
  {
    "text": "little bit about what I think that might look like and now I'm kind of getting into the more futuristic stuff and so things might get a little more vague or",
    "start": "1965250",
    "end": "1971340"
  },
  {
    "text": "hand-wavy but I'm trying to keep it as concrete as I can first thing you want",
    "start": "1971340",
    "end": "1976860"
  },
  {
    "text": "to do is probably set up a data catalog this is something that over the past year - I've seen a lot of activity in a",
    "start": "1976860",
    "end": "1983299"
  },
  {
    "text": "data catalog and I should mention you probably want to centralized ie you want to have one with with I met all the",
    "start": "1983299",
    "end": "1989640"
  },
  {
    "text": "metadata it's gonna have the locations of your data what kind of schemas the data has who owns the data lineage which is",
    "start": "1989640",
    "end": "1996630"
  },
  {
    "text": "essentially where the data came from so in my you know initial examples it would be like it came from my sequel it went",
    "start": "1996630",
    "end": "2002270"
  },
  {
    "text": "to Kafka and then it got loaded into bigquery knowing that pipeline maybe even encryption or",
    "start": "2002270",
    "end": "2007580"
  },
  {
    "text": "versioning so you know what things are masked or encrypted or and what things are versioned as as the scheme has",
    "start": "2007580",
    "end": "2013460"
  },
  {
    "text": "evolved so I'm gonna do a big shout-out to a munson which is a data catalog from",
    "start": "2013460",
    "end": "2019100"
  },
  {
    "text": "lyft but I should be clear there's like a bunch of these it's activity this is a bunch of activity in this area it's kind",
    "start": "2019100",
    "end": "2024860"
  },
  {
    "text": "of getting very hot I think over the last year so you have Apache Atlas you have data hub which is recently kind of",
    "start": "2024860",
    "end": "2031039"
  },
  {
    "text": "open sourced as a patch that's from LinkedIn we work has a system called marques google has a product called",
    "start": "2031039",
    "end": "2037700"
  },
  {
    "text": "data catalog and and I know I'm missing you know at least two or three more from",
    "start": "2037700",
    "end": "2043460"
  },
  {
    "text": "this list now what these things do they'd only do a lot and they generally do more than one thing but I wanted to",
    "start": "2043460",
    "end": "2050118"
  },
  {
    "text": "show an example just to kind of make it concrete so we've got an example here with some fake data that I yanked from",
    "start": "2050119",
    "end": "2056658"
  },
  {
    "text": "the Munson blog where they they've got their schema you know the field types the data type so everything they've got",
    "start": "2056659",
    "end": "2063230"
  },
  {
    "text": "who owns the data right and notice that add button there I want to get back to",
    "start": "2063230",
    "end": "2068929"
  },
  {
    "text": "that in a moment but just keep that in the back your mind we've got the source so this is kind of get starting to get",
    "start": "2068929",
    "end": "2075230"
  },
  {
    "text": "into a little bit of the lineage so it's telling you what source code generated it what system generated in this case",
    "start": "2075230",
    "end": "2081560"
  },
  {
    "text": "it's air flow that's what that little pinwheel is and you know some lineage about where the data came from and",
    "start": "2081560",
    "end": "2087470"
  },
  {
    "text": "they've even got a little preview it's pretty nice UI and underneath it of course is a repository and you think you",
    "start": "2087470",
    "end": "2093378"
  },
  {
    "text": "can even use Apache Atlas to power it or neo4j if I'm not mistaken that actually",
    "start": "2093379",
    "end": "2099650"
  },
  {
    "text": "houses all this information and that's that's really useful because you need to get all your systems to be talking to",
    "start": "2099650",
    "end": "2105290"
  },
  {
    "text": "this this catalog right so that little plus thing that I mentioned on the the owner part you don't as a data engineer",
    "start": "2105290",
    "end": "2111050"
  },
  {
    "text": "want to be entering that data in yourself that is not where you want to be that's sort of back in land of manual",
    "start": "2111050",
    "end": "2116390"
  },
  {
    "text": "data steward data management instead what you want to be doing is hooking up",
    "start": "2116390",
    "end": "2121940"
  },
  {
    "text": "all these systems to your data catalog so that they're automatically reporting stuff you know about the schema about",
    "start": "2121940",
    "end": "2128150"
  },
  {
    "text": "the evolution of the schema about the ownership when the data is loaded from one to the next so you know first off",
    "start": "2128150",
    "end": "2134570"
  },
  {
    "text": "you need your systems like air flow and bigquery your data warehouses and stuff to talk to data catalog I think there's quite a",
    "start": "2134570",
    "end": "2141600"
  },
  {
    "text": "bit of movement there you then need your data pipeline streaming platforms to talk to your data catalog I think that",
    "start": "2141600",
    "end": "2147690"
  },
  {
    "text": "there's I haven't seen as much yet from that area although maybe maybe there's",
    "start": "2147690",
    "end": "2153960"
  },
  {
    "text": "stuff coming out that will integrate better but right now I think that's kind of something got to do on your own and",
    "start": "2153960",
    "end": "2159720"
  },
  {
    "text": "then something that I don't think we've done a really good job of bridging the gap with is on that service side you",
    "start": "2159720",
    "end": "2164940"
  },
  {
    "text": "actually I will claim want to have your service stuff in the data catalog as well so this would be like G RPC",
    "start": "2164940",
    "end": "2170730"
  },
  {
    "text": "protobufs it would be JSON schemas and even the the D B's of those databases",
    "start": "2170730",
    "end": "2176070"
  },
  {
    "text": "right so once you've got your you know where all your data is the next step is",
    "start": "2176070",
    "end": "2182790"
  },
  {
    "start": "2178000",
    "end": "2275000"
  },
  {
    "text": "you got to configure your access to it and right now like I said if you have an automated this stuff what you're",
    "start": "2182790",
    "end": "2188460"
  },
  {
    "text": "probably doing is is going to security or your compliance or whoever the policy maker is and being like scan so-and-so",
    "start": "2188460",
    "end": "2194490"
  },
  {
    "text": "see this data whenever they make a access request and that's not where you want to be you want to be able to automate the access request management",
    "start": "2194490",
    "end": "2201090"
  },
  {
    "text": "so that you don't have to you can be as hands-off with it as possible this is kind of alphabet soup what we're really",
    "start": "2201090",
    "end": "2206490"
  },
  {
    "text": "talking about here is our back role based access controls identity access management access control list just a",
    "start": "2206490",
    "end": "2212760"
  },
  {
    "text": "bunch of fancy words for a bunch of different features for managing groups user access and so on",
    "start": "2212760",
    "end": "2220020"
  },
  {
    "text": "do you kind of need three things to do this the first thing is you need your systems to support it the second thing",
    "start": "2220020",
    "end": "2225540"
  },
  {
    "text": "is you need to provide some tooling to security and compliance to configure the policies appropriately and the third",
    "start": "2225540",
    "end": "2231720"
  },
  {
    "text": "thing is you need to automate the management of the policies once they've been defined by your security and compliance folks so I'm gonna start with",
    "start": "2231720",
    "end": "2241500"
  },
  {
    "text": "some good news and that is that I think there's been a fair amount of work done",
    "start": "2241500",
    "end": "2247260"
  },
  {
    "text": "on a lot of the system supporting it aspect of this airflow has our back",
    "start": "2247260",
    "end": "2252570"
  },
  {
    "text": "which is a role based access control it was a patch we submitted last year from we pay I think Kafka has had and I",
    "start": "2252570",
    "end": "2260550"
  },
  {
    "text": "should mention airflow has had a lot more work done on it since then they now have dag level access control and they've really taken it pretty seriously",
    "start": "2260550",
    "end": "2267600"
  },
  {
    "text": "Kafka also has ACLs and has had that for quite a while and here's an example of managing it",
    "start": "2267600",
    "end": "2273160"
  },
  {
    "text": "with terraform so you can use those kind",
    "start": "2273160",
    "end": "2278290"
  },
  {
    "start": "2275000",
    "end": "2330000"
  },
  {
    "text": "of tools to start to automate some of this stuff so we want to be automating when a new user is added to the system",
    "start": "2278290",
    "end": "2285190"
  },
  {
    "text": "their access automatically gets configured when a new user when a new piece of data is added in the system their access controls automatically get",
    "start": "2285190",
    "end": "2292210"
  },
  {
    "text": "configured we want to start automating service account access so as new web services are coming online and the last",
    "start": "2292210",
    "end": "2298960"
  },
  {
    "text": "two are less obvious there's occasionally need for someone to get temporary access to something and you",
    "start": "2298960",
    "end": "2304720"
  },
  {
    "text": "don't want to be in a position where you're setting a calendar reminder three years three weeks in the future to say hey please remember to revoke the access",
    "start": "2304720",
    "end": "2311410"
  },
  {
    "text": "for this user you want that all to be automated and the same deal with unused",
    "start": "2311410",
    "end": "2317020"
  },
  {
    "text": "access you want to know when users aren't using all the permissions that they're granted so that you can start to strip them away to kind of limit the",
    "start": "2317020",
    "end": "2324030"
  },
  {
    "text": "security vulnerability space so once",
    "start": "2324030",
    "end": "2332800"
  },
  {
    "start": "2330000",
    "end": "2429000"
  },
  {
    "text": "we've got we know where all our data is and we know we've got the policies set",
    "start": "2332800",
    "end": "2338170"
  },
  {
    "text": "up we need to detect violations and this this area of my talk is a little thin I mostly want to talk about data loss",
    "start": "2338170",
    "end": "2344500"
  },
  {
    "text": "prevention but there's also auditing as well which is you know keeping track of logs and making sure that the activities",
    "start": "2344500",
    "end": "2349690"
  },
  {
    "text": "and the systems are conforming to the required policies so we need to monitor",
    "start": "2349690",
    "end": "2358330"
  },
  {
    "text": "and verify that the policies aren't being violated so I'm gonna pick out because I'm in Google cloud and I have",
    "start": "2358330",
    "end": "2364900"
  },
  {
    "text": "some experience with this piece of software the data loss solution from GCP there's a corresponding one from AWS",
    "start": "2364900",
    "end": "2371410"
  },
  {
    "text": "called macey there's also an open source project called Ranger which has Apache Ranger which has a little bit of an",
    "start": "2371410",
    "end": "2378190"
  },
  {
    "text": "enforcement and monitoring mechanism built into it it's more focused on the Hadoop ecosystem the theme with all these things though is that you can you",
    "start": "2378190",
    "end": "2385540"
  },
  {
    "text": "can use them to detect sensitive data where it shouldn't be so this is an example where you know we've got a piece",
    "start": "2385540",
    "end": "2392290"
  },
  {
    "text": "of text that says my phone number is blah blah blah and you get a result back saying it defect",
    "start": "2392290",
    "end": "2397990"
  },
  {
    "text": "detected an info type of phone number and the likelihood is very likely so you can use this kind of stuff to start to",
    "start": "2397990",
    "end": "2405130"
  },
  {
    "text": "monitor the policies that you set forth so for example if you have say a data set that is supposed to be cleaned",
    "start": "2405130",
    "end": "2411670"
  },
  {
    "text": "ie not have any sensitive information in it you can run DLP checks on that clean",
    "start": "2411670",
    "end": "2416980"
  },
  {
    "text": "data set and if anything pops up like a phone number or social security number or credit card you can be alerted you",
    "start": "2416980",
    "end": "2422350"
  },
  {
    "text": "know immediately that there's a violation in place okay so we have a",
    "start": "2422350",
    "end": "2432010"
  },
  {
    "start": "2429000",
    "end": "2487000"
  },
  {
    "text": "little bit of progress here right users can find the data that they need they can use their data catalog we have some",
    "start": "2432010",
    "end": "2437050"
  },
  {
    "text": "automation in place maybe we're using terraform to manage ACLs for Kafka maybe we're using terraform to manage our back",
    "start": "2437050",
    "end": "2442900"
  },
  {
    "text": "controls and air flow but there's still a problem here the problem is data",
    "start": "2442900",
    "end": "2449560"
  },
  {
    "text": "engineering is probably still the one managing that configuration in those deployments and the reason for that is",
    "start": "2449560",
    "end": "2455130"
  },
  {
    "text": "mostly due to the interface right so we're still in the land at this point of get pull requests terraform DSL yeah mal",
    "start": "2455130",
    "end": "2462250"
  },
  {
    "text": "jasin you know kubernetes it's it sort of nitty-gritty so even going to some security teams",
    "start": "2462250",
    "end": "2469300"
  },
  {
    "text": "might be a tall order and asking them to to make changes of that going to your compliance wing is an even taller order",
    "start": "2469300",
    "end": "2475119"
  },
  {
    "text": "and going beyond compliance is basically like there's no way so this this leads",
    "start": "2475119",
    "end": "2480280"
  },
  {
    "text": "to the last theme or stage that I want to talk about and that is decentralization so you're probably",
    "start": "2480280",
    "end": "2488350"
  },
  {
    "start": "2487000",
    "end": "2531000"
  },
  {
    "text": "ready to decentralize your your data pipeline in your data warehouses if you have a fully automated real-time data",
    "start": "2488350",
    "end": "2494680"
  },
  {
    "text": "pipeline but people are still coming to you asking to get data loaded that's a hint that you probably have you're",
    "start": "2494680",
    "end": "2501340"
  },
  {
    "text": "probably ready for this step so right the question is if everything's automated why do we need a single team",
    "start": "2501340",
    "end": "2506890"
  },
  {
    "text": "to manage all this stuff I of course don't think you do I think the place",
    "start": "2506890",
    "end": "2514030"
  },
  {
    "text": "where we're going to see this first and are we're already seeing this in some ways is a decentralization at the data warehouse so I think we're moving",
    "start": "2514030",
    "end": "2521560"
  },
  {
    "text": "towards a world where people are going to be empowered to spin up multiple data",
    "start": "2521560",
    "end": "2527050"
  },
  {
    "text": "warehouses and sort Minister and manage their own so the way",
    "start": "2527050",
    "end": "2533170"
  },
  {
    "text": "I kind of framed this this line of thought is really around our migration from monolith to micro-services that",
    "start": "2533170",
    "end": "2538750"
  },
  {
    "text": "we've had going on you know in the past decade or two and part of the motivation",
    "start": "2538750",
    "end": "2544630"
  },
  {
    "text": "there was really to sort of break up large complex things increase agility increase efficiency let people move at",
    "start": "2544630",
    "end": "2550690"
  },
  {
    "text": "their own pace a lot of that stuff kind of sounds like your data warehouse it's like monolithic it's not that agile",
    "start": "2550690",
    "end": "2557260"
  },
  {
    "text": "you're having to go to your data engineering team to ask to do things maybe don't want it maybe you're not able to do things at your own pace so I",
    "start": "2557260",
    "end": "2563770"
  },
  {
    "text": "think we're going to want to do the same kind of thing and we're gonna want to get towards a more decentralized approach quick shout out I'm not alone",
    "start": "2563770",
    "end": "2570340"
  },
  {
    "text": "in this there's a really great blog post this was just like when I read this post I was like yes this is exactly what I've",
    "start": "2570340",
    "end": "2575890"
  },
  {
    "text": "been thinking about and this is like just such a great description of it and it turns out that that the author of",
    "start": "2575890",
    "end": "2581710"
  },
  {
    "text": "this blog posts I'm probably gonna mispronounce her name but jhamak Joginder Gani she is the next speaker in",
    "start": "2581710",
    "end": "2588640"
  },
  {
    "text": "this track right after me so I'm very excited to hear what she has to say but in the post she kind of talks about you",
    "start": "2588640",
    "end": "2595210"
  },
  {
    "text": "know the the shift from this monolithic view to a more fragmented or decentralized view and she even talks",
    "start": "2595210",
    "end": "2600700"
  },
  {
    "text": "about policy automation and a lot of the same stuff that I'm thinking about so I think this this shift towards",
    "start": "2600700",
    "end": "2606490"
  },
  {
    "text": "decentralization will take place in two phases if you've got this set of raw tools you've got your get and your yeah Mille and your JSON and you're like this",
    "start": "2606490",
    "end": "2613510"
  },
  {
    "text": "beaten down data engineering team that's just getting requests left and right and you know you're just running strips all",
    "start": "2613510",
    "end": "2618850"
  },
  {
    "text": "the time if you're just trying to escape that the first step is simply to expose that raw set of tools to your other engineers they're comfortable with this",
    "start": "2618850",
    "end": "2625540"
  },
  {
    "text": "stuff they know get they know pull requests they know yamo and json and all that kind of thing so you can at least",
    "start": "2625540",
    "end": "2630640"
  },
  {
    "text": "start exposing that the automated tooling and pipelines to those teams so that they can begin to manage their own",
    "start": "2630640",
    "end": "2636850"
  },
  {
    "text": "data warehouses so an example of this would be maybe you've got a team that",
    "start": "2636850",
    "end": "2642520"
  },
  {
    "text": "does a lot of reporting or reconciliation and you need to they need",
    "start": "2642520",
    "end": "2648250"
  },
  {
    "text": "a data warehouse that they can manage you might just give them you know keys to the castle and they can go about it maybe there's a team that's attached to",
    "start": "2648250",
    "end": "2654790"
  },
  {
    "text": "your sales organization that's a business analytics team and they need to have a data warehouse they can they can do it as well but this is",
    "start": "2654790",
    "end": "2662060"
  },
  {
    "text": "not I think the end goal the end goal is full decentralization and for that I think what we really need to see here is",
    "start": "2662060",
    "end": "2667340"
  },
  {
    "text": "a lot of development and evolution in the tooling that we're providing beyond just sort of the gits and the Hamill's",
    "start": "2667340",
    "end": "2673580"
  },
  {
    "text": "and the RTFM attitude that we kind of throw around sometimes so I'm talking here more about you is something that's",
    "start": "2673580",
    "end": "2680000"
  },
  {
    "text": "polished something that you can give not just to an engineer with ten years under their belt you know writing code but to",
    "start": "2680000",
    "end": "2686720"
  },
  {
    "text": "people outside of that in your organization so if we can get to that point I think we will have a fully",
    "start": "2686720",
    "end": "2693560"
  },
  {
    "text": "decentralized warehouse and data pipeline where security and compliance can manage access controls data",
    "start": "2693560",
    "end": "2700160"
  },
  {
    "text": "engineering can manage the tooling and the infrastructure if you think all the way back to the beginning of this talk",
    "start": "2700160",
    "end": "2705170"
  },
  {
    "text": "was really what Maxine was was talking about and everyone else can manage their own data pipelines and their own data",
    "start": "2705170",
    "end": "2710420"
  },
  {
    "text": "warehouses and we can help them do that which is that that key phrase that I wanted to call out at the beginning of this talk so with that this is sort of",
    "start": "2710420",
    "end": "2718790"
  },
  {
    "text": "where I landed on my view of a modern data architecture we got real-time data integration streaming platform we've got",
    "start": "2718790",
    "end": "2725030"
  },
  {
    "text": "automated data management we have automated operations decentralized data warehouses and pipelines and happy",
    "start": "2725030",
    "end": "2731780"
  },
  {
    "text": "engineers sres and users oh okay so when I started when sakuni's like 97",
    "start": "2731780",
    "end": "2740420"
  },
  {
    "start": "2736000",
    "end": "3098000"
  },
  {
    "text": "slides that's ambitious so I made it thank you all for attending the talk I really appreciate you giving me your",
    "start": "2740420",
    "end": "2746510"
  },
  {
    "text": "attention and I'm happy to answer any questions you you all might have and of course we're hiring as well so if you want to come work on this stuff let me",
    "start": "2746510",
    "end": "2752690"
  },
  {
    "text": "know [Applause]",
    "start": "2752690",
    "end": "2764389"
  },
  {
    "text": "hi with here here hey with all the",
    "start": "2766849",
    "end": "2775380"
  },
  {
    "text": "loading and I'm new to this space so if this is like the elementary question sorry but with all the loading of like",
    "start": "2775380",
    "end": "2781710"
  },
  {
    "text": "low level data that's in these like online transnationals or some databases are you concerned about coupling to that",
    "start": "2781710",
    "end": "2787470"
  },
  {
    "text": "data all at all and do you think any of our reporting and analytics should move to the api's of these services that they",
    "start": "2787470",
    "end": "2794369"
  },
  {
    "text": "exposed to other consumers do that is such a fantastic question I'm gonna call",
    "start": "2794369",
    "end": "2801570"
  },
  {
    "text": "out another blog post that I have there there's a blog post that I wrote earlier in the year called changed you to",
    "start": "2801570",
    "end": "2807930"
  },
  {
    "text": "capture breaks database encapsulation or micro service encapsulation and it is exactly what you're talking about",
    "start": "2807930",
    "end": "2813780"
  },
  {
    "text": "that is a problem in the post I kind of enumerated the various strategies that you can employ and they can vary from",
    "start": "2813780",
    "end": "2821339"
  },
  {
    "text": "the draconian like banning backwards and forwards compatibility changes on the microservice database do more flexible",
    "start": "2821339",
    "end": "2827640"
  },
  {
    "text": "things where you might put a streaming shim in between that's that's allowing the team that owns the micro service to",
    "start": "2827640",
    "end": "2834030"
  },
  {
    "text": "munge their data before it gets exposed to the public I think gunner also has a really good post on an out box pattern",
    "start": "2834030",
    "end": "2839970"
  },
  {
    "text": "that he talks about with DBZ 'm so yes absolutely a problem something you've got to deal with I think we're headed",
    "start": "2839970",
    "end": "2847470"
  },
  {
    "text": "towards a world where we are going to provide a data API much like the public facing API that the micro services",
    "start": "2847470",
    "end": "2853500"
  },
  {
    "text": "expose and I think we're gonna have to handle I mean these problems exist for the micro service API is as well you're",
    "start": "2853500",
    "end": "2859349"
  },
  {
    "text": "talking about versioning you're talking about migrating the users from one version to another and so on the tooling",
    "start": "2859349",
    "end": "2864540"
  },
  {
    "text": "is a little more nascent but it is there like that the rudimentary parts whether it's stream processing or schema",
    "start": "2864540",
    "end": "2869849"
  },
  {
    "text": "management detection like that stuff is there but it it's a little more painful oh can you elaborate a little bit but on",
    "start": "2869849",
    "end": "2881300"
  },
  {
    "text": "how you handle historical data in case",
    "start": "2881300",
    "end": "2886500"
  },
  {
    "text": "for example when you have you have you found out that",
    "start": "2886500",
    "end": "2891599"
  },
  {
    "text": "there is some defect that seeped into the data warehouse the year years worth",
    "start": "2891599",
    "end": "2897059"
  },
  {
    "text": "of data and you have to recalculate yes question yep so that is a also an excellent",
    "start": "2897059",
    "end": "2902880"
  },
  {
    "text": "question the way that we handle that right now there are a couple ways so one",
    "start": "2902880",
    "end": "2909089"
  },
  {
    "text": "is sort of a manual like we will just in the data warehouse go and munge the thing to make it look like the upstream",
    "start": "2909089",
    "end": "2914670"
  },
  {
    "text": "thing and that's that's painful and you know not really rigorous in a sense that you may you may make a mistake the other",
    "start": "2914670",
    "end": "2921359"
  },
  {
    "text": "way is more more lazy and a little bit slower usually but is more accurate and that is we will what we call reboot",
    "start": "2921359",
    "end": "2927509"
  },
  {
    "text": "strap or recent app shot the data so specifically for us with deniz IAM when",
    "start": "2927509",
    "end": "2934109"
  },
  {
    "text": "you first start the connector up obviously there's no data and coffee yet but that table might have existed for two years so the museum will do sort of",
    "start": "2934109",
    "end": "2941789"
  },
  {
    "text": "a consistent snapshot where it will select all the data out and then load it into Kafka if you decide that something",
    "start": "2941789",
    "end": "2948449"
  },
  {
    "text": "went wrong you can essentially re trigger and recent app shot the thing again and I'm getting a stop sign here I",
    "start": "2948449",
    "end": "2957449"
  },
  {
    "text": "can talk more with you later but we usually read snapshot yeah I'm not sure",
    "start": "2957449",
    "end": "2964709"
  },
  {
    "text": "am I supposed to stuff excellent talk thank you for providing",
    "start": "2964709",
    "end": "2972610"
  },
  {
    "text": "this amazing framework to understand you know the challenges in data engineering I think it's kind of good talk is that",
    "start": "2972610",
    "end": "2978040"
  },
  {
    "text": "it launches a lot of conversations and I'm sure you get a lot of questions for people here I have many but I'll ask one",
    "start": "2978040",
    "end": "2985090"
  },
  {
    "text": "or two you the one has to do with data quality and data ownership I think",
    "start": "2985090",
    "end": "2991480"
  },
  {
    "text": "there's always this question of publishers of data subscribers of data who owns the data yep how do you tackle",
    "start": "2991480",
    "end": "2998650"
  },
  {
    "text": "them yeah so we so I'm a firm believer that the publisher should own it and",
    "start": "2998650",
    "end": "3005010"
  },
  {
    "text": "that's coming from a data engineer so we pay we take the stance that we are",
    "start": "3005010",
    "end": "3010500"
  },
  {
    "text": "responsible for taking the data from the upstream database and making it look identical in the data pipeline and so if",
    "start": "3010500",
    "end": "3016980"
  },
  {
    "text": "it looks identical we've done our job I think as we decentralized the ownership is going to have to shift to",
    "start": "3016980",
    "end": "3022710"
  },
  {
    "text": "either the engineering teams or whomever and so then it becomes about detection right when things aren't matching up",
    "start": "3022710",
    "end": "3028980"
  },
  {
    "text": "alerting the proper people so we have",
    "start": "3028980",
    "end": "3034800"
  },
  {
    "text": "some systems that we employ that do data quality checking it we pay right now all those alerts come to us and then we have",
    "start": "3034800",
    "end": "3039930"
  },
  {
    "text": "to suss out the problem we have is and I think this is true of a lot of data engineering is they don't necessarily have as much context around like the",
    "start": "3039930",
    "end": "3047609"
  },
  {
    "text": "business case like what the data is they're just kind of moving the data around so we usually end up having to chase people down so my opinion is if we",
    "start": "3047609",
    "end": "3055950"
  },
  {
    "text": "go with like the micro service example that if the pipeline is accurately",
    "start": "3055950",
    "end": "3061740"
  },
  {
    "text": "moving the data and reflecting what is in the source database then data engineering is doing its job usually the",
    "start": "3061740",
    "end": "3068609"
  },
  {
    "text": "problem is not in that pipeline it's like there's a confusion about the semantics meeting of a column or there",
    "start": "3068609",
    "end": "3074609"
  },
  {
    "text": "was a schema change upstream that affected the downstream users in a way",
    "start": "3074609",
    "end": "3079740"
  },
  {
    "text": "that they're not happy about or they're stuffing JSON into a string and they've stopped at it using a field that they were using and that stuff we just push",
    "start": "3079740",
    "end": "3085290"
  },
  {
    "text": "it's that's that's on the individual engineering teams to own okay you were",
    "start": "3085290",
    "end": "3090510"
  },
  {
    "text": "kind of out of time yeah yeah thank you very much Chris and you're welcome to stay here",
    "start": "3090510",
    "end": "3096000"
  },
  {
    "text": "you're not gonna stop",
    "start": "3096000",
    "end": "3099230"
  }
]
[
  {
    "start": "0",
    "end": "33000"
  },
  {
    "text": "okay so topic is our socket which is a",
    "start": "3899",
    "end": "9719"
  },
  {
    "text": "new application level networking protocol well not new it's been around for a while but new in terms of concept",
    "start": "9719",
    "end": "16200"
  },
  {
    "text": "just a show of hands how many people have heard of our socket before alright",
    "start": "16200",
    "end": "22649"
  },
  {
    "text": "and how many have actually used it alright well we're hoping to change some",
    "start": "22649",
    "end": "29610"
  },
  {
    "text": "of this today hopefully after today so just very quickly I'm most lung Aslam",
    "start": "29610",
    "end": "38940"
  },
  {
    "text": "Farooq I am the CEO at notify I am a bit",
    "start": "38940",
    "end": "45510"
  },
  {
    "text": "of a you know serial entrepreneur as well as I grew up at Oracle so lots of history dealing with enterprise class",
    "start": "45510",
    "end": "52350"
  },
  {
    "text": "deployments and infrastructures with me today is Robert he's our chief",
    "start": "52350",
    "end": "58499"
  },
  {
    "text": "innovation officer which is you know just kind of a big word for the smartest guy in the company so we're gonna be",
    "start": "58499",
    "end": "67440"
  },
  {
    "text": "talking about it I'll just very quickly just introduce the project and then we'll let Robert talk about things that",
    "start": "67440",
    "end": "74610"
  },
  {
    "text": "you guys are more interested in so we're notifying and our socket is an open",
    "start": "74610",
    "end": "83070"
  },
  {
    "start": "76000",
    "end": "212000"
  },
  {
    "text": "source protocol that was basically germinated some time back inside Netflix",
    "start": "83070",
    "end": "89490"
  },
  {
    "text": "and other places and right now we're working with Facebook Alibaba pivotal and other partners who are onboard and",
    "start": "89490",
    "end": "97200"
  },
  {
    "text": "we are sort of using and promoting our socket and we're hoping that you know us",
    "start": "97200",
    "end": "105420"
  },
  {
    "text": "together and with other incoming partners will be able to change the fact",
    "start": "105420",
    "end": "110580"
  },
  {
    "text": "that you know few people have heard of our socket hopefully more will have and will will use I should mention that",
    "start": "110580",
    "end": "117620"
  },
  {
    "text": "Facebook pivot pivotal and Alibaba they're all using our socket internally",
    "start": "117620",
    "end": "123080"
  },
  {
    "text": "pivot holes for you Java developers the Spring Framework 5.2 is coming up next",
    "start": "123080",
    "end": "129479"
  },
  {
    "text": "month and that has our socket built in so if you if you'd like to use spring you'll be able to get on our socket immediately",
    "start": "129479",
    "end": "136400"
  },
  {
    "text": "what it is is basically it's it's an application level layer five six loosely",
    "start": "136400",
    "end": "142200"
  },
  {
    "text": "speaking I call it layer seven but I know I'm wrong it's got built-in",
    "start": "142200",
    "end": "147359"
  },
  {
    "text": "reactives semantics so backpressure composable flow control all of that stuff is built into the protocol you",
    "start": "147359",
    "end": "154439"
  },
  {
    "text": "should be thinking compare that to HTTP or other rest type protocols you've heard and we'll see how",
    "start": "154439",
    "end": "160109"
  },
  {
    "text": "that works in a minute it does have flow control built in which basically means that you don't have to",
    "start": "160109",
    "end": "166560"
  },
  {
    "text": "worry about things like retries and other things that you have to write in your blue logic when you write your",
    "start": "166560",
    "end": "172349"
  },
  {
    "text": "applications the network and the protocol will take care of it for you for those of us who are old enough and",
    "start": "172349",
    "end": "177659"
  },
  {
    "text": "remember tcp/ip at a lower level that had flow control built in and that's why",
    "start": "177659",
    "end": "184170"
  },
  {
    "text": "we never have to write a lot of the glue code that that we have right at application level so going to our socket",
    "start": "184170",
    "end": "190349"
  },
  {
    "text": "will change that binary encoded and it's message passing based which Robert will talk about why that's important and",
    "start": "190349",
    "end": "197969"
  },
  {
    "text": "allows you to do you know to get a synchrony in your applications very very quickly so let's you know I think that's that's",
    "start": "197969",
    "end": "204870"
  },
  {
    "text": "kind of enough for me and I'll hand it over to Robert your mics working hello yeah all right so I want to talk",
    "start": "204870",
    "end": "214290"
  },
  {
    "start": "212000",
    "end": "279000"
  },
  {
    "text": "about what's needed for high-performance micro service networking so when I thought about this talk I came up a",
    "start": "214290",
    "end": "220379"
  },
  {
    "text": "little list of things that I think are important for building and performant applications so firstly we need temporal",
    "start": "220379",
    "end": "228540"
  },
  {
    "text": "and spatial decoupling next you should actually be sending binary across the network you shouldn't be sending text",
    "start": "228540",
    "end": "234389"
  },
  {
    "text": "encoding and then finally you need application flow control because you want to consist in application an",
    "start": "234389",
    "end": "240269"
  },
  {
    "text": "application that isn't consistent that has bad tail latency in a distributed system is actually very slow so let's",
    "start": "240269",
    "end": "249269"
  },
  {
    "text": "look at loose coupling so when I think about loose coupling I think about spatial and temporal decoupling and so",
    "start": "249269",
    "end": "255809"
  },
  {
    "text": "what spatial decoupling is is a message sender should not directly call a destination",
    "start": "255809",
    "end": "261539"
  },
  {
    "text": "instead it should pass a message to somebody else through a stream or a channel and then temporal coupling is that when",
    "start": "261539",
    "end": "268830"
  },
  {
    "text": "you call something the thing that you call should not block the execution so you can think that is like non-blocking",
    "start": "268830",
    "end": "274500"
  },
  {
    "text": "code and this will let you more efficiently use your resources our",
    "start": "274500",
    "end": "280409"
  },
  {
    "start": "279000",
    "end": "328000"
  },
  {
    "text": "socket is loosely coupled because it uses asynchronous message passing and when we talk about message passing",
    "start": "280409",
    "end": "286830"
  },
  {
    "text": "something that comes up a lot is what's the difference between an event-driven architecture and a message driven or",
    "start": "286830",
    "end": "292889"
  },
  {
    "text": "message passing architecture so I created a quick list of things here but",
    "start": "292889",
    "end": "299220"
  },
  {
    "text": "the really big thing to take away from this is that in a message driven architecture you send messages to a",
    "start": "299220",
    "end": "306120"
  },
  {
    "text": "destination and an event-driven architecture what you do is you actually listen to events emitted from an entity",
    "start": "306120",
    "end": "311729"
  },
  {
    "text": "and so one way to think about this is message passing would be your boss tells",
    "start": "311729",
    "end": "317639"
  },
  {
    "text": "you to go fill your timesheet out right but an event-driven architecture would be more like your boss actually sends an",
    "start": "317639",
    "end": "324030"
  },
  {
    "text": "email to everybody and says hey fill out your timesheet so this is let's take a",
    "start": "324030",
    "end": "329880"
  },
  {
    "text": "look what that looks like so on one side you have something that emits events in",
    "start": "329880",
    "end": "335370"
  },
  {
    "text": "the middle you have some kind of queue usually and on the other side you have things that are listening for events",
    "start": "335370",
    "end": "341069"
  },
  {
    "text": "right and so it's all good you begin to emit events things go in the queue many people are familiar with this and you",
    "start": "341069",
    "end": "347099"
  },
  {
    "text": "begin to just pull stuff off the process it right and the messages that are sent or sorry the events that are sent aren't",
    "start": "347099",
    "end": "353069"
  },
  {
    "text": "actually correlated to anybody so anyone can go ahead and just pulled it off and you can't actually tell you know where",
    "start": "353069",
    "end": "359009"
  },
  {
    "text": "the message originated and where it came from right they just go into the queue and people go ahead and process this and",
    "start": "359009",
    "end": "364620"
  },
  {
    "text": "this is generally okay except it ends up leading to a few problems and some of",
    "start": "364620",
    "end": "370650"
  },
  {
    "text": "those problems are how do you actually send a response back to just someone or send a message back to a particular",
    "start": "370650",
    "end": "376130"
  },
  {
    "text": "person in midian events it's very difficult to do this right you can't do this because you generally don't",
    "start": "376130",
    "end": "382199"
  },
  {
    "text": "actually know where the van came from right and besides just sending an event",
    "start": "382199",
    "end": "387560"
  },
  {
    "text": "you might actually want to send an exception right so what could happen is you might have a device that's emitting",
    "start": "387560",
    "end": "393810"
  },
  {
    "text": "a bunch of exceptions right sorry omitting payloads that are causing exceptions so those",
    "start": "393810",
    "end": "399420"
  },
  {
    "text": "payloads go into the queue and you can't actually tell which device is doing that because there's no correlation between",
    "start": "399420",
    "end": "405060"
  },
  {
    "text": "the thing emitting the payloads and the processing costing the exception right",
    "start": "405060",
    "end": "410330"
  },
  {
    "text": "and then finally back pressure is a lot harder to deal with in this kind of",
    "start": "410330",
    "end": "416580"
  },
  {
    "text": "environment so you can only really do back pressure around a queue right now right so you can't actually tell one of",
    "start": "416580",
    "end": "422970"
  },
  {
    "text": "these things admitting events to slow down and stop sending new events right because there's no signal you can't actually say hey you're sending things",
    "start": "422970",
    "end": "429570"
  },
  {
    "text": "too fast for me to process right and so what can happen is you can have one bad device or one bad deployment that",
    "start": "429570",
    "end": "435420"
  },
  {
    "text": "actually goes ahead and blows up your queue for everybody else right because you can't say hey stop sending me stuff",
    "start": "435420",
    "end": "441330"
  },
  {
    "text": "actually this is kind of funny at Nike when I worked on the fuel band we call this the mark parker problem",
    "start": "441330",
    "end": "446820"
  },
  {
    "text": "so mark Parker is the CEO of of Nike and every time we gave him a fuel band inevitably he would have a bug and then",
    "start": "446820",
    "end": "453510"
  },
  {
    "text": "like buried halfway through the queue or his device he'd end up actually breaking the fuel band so he died like you know",
    "start": "453510",
    "end": "459030"
  },
  {
    "text": "executive tech support come to fix it so I'm very familiar with this thing and it ends up causing a lot of issues so let's",
    "start": "459030",
    "end": "467520"
  },
  {
    "text": "take a look at how this would work with message passing so a message passing instead you have different destinations",
    "start": "467520",
    "end": "472740"
  },
  {
    "text": "right and what the destinations do is they begin to send messages to each",
    "start": "472740",
    "end": "479160"
  },
  {
    "text": "other over you know distinct streams right so destination six sends a message",
    "start": "479160",
    "end": "484260"
  },
  {
    "text": "of destination one right and then conceptually unlike event-driven",
    "start": "484260",
    "end": "491220"
  },
  {
    "text": "architectures something that receives a message can go ahead and pass it on to somebody else right so in this case you",
    "start": "491220",
    "end": "498060"
  },
  {
    "text": "know destination three gets a message you can send it off to another place right and then more importantly you can",
    "start": "498060",
    "end": "503850"
  },
  {
    "text": "actually go ahead and send messages back and forth between different destinations right and so you can use this for",
    "start": "503850",
    "end": "509670"
  },
  {
    "text": "request reply or you can also begin to use this for other things signal maybe you need to slow down or send an",
    "start": "509670",
    "end": "515460"
  },
  {
    "text": "exception for someone to handle right let's take a look at the way that our socket uses message passing and the",
    "start": "515460",
    "end": "522240"
  },
  {
    "text": "protocol so our socket has a bunch of different interaction models and there's some",
    "start": "522240",
    "end": "527550"
  },
  {
    "text": "really great talks about it I won't go over that but one of the interaction models that has is the ability to create a bi-directional channel between two",
    "start": "527550",
    "end": "535920"
  },
  {
    "text": "different destinations and the way that it starts doing that is it goes ahead and sends a message over from you know",
    "start": "535920",
    "end": "542160"
  },
  {
    "text": "destination two to one says hey I want to do a bi-directional channel right and then our socket has this built in idea",
    "start": "542160",
    "end": "550350"
  },
  {
    "text": "of back pressure so even though destination two sent a message over nothing will be emitted until the person",
    "start": "550350",
    "end": "558029"
  },
  {
    "text": "goes ahead and asked for it so what happens is it sends a message and says hey go ahead and send me three different",
    "start": "558029",
    "end": "563940"
  },
  {
    "text": "payloads right and so it begins to go emit the different payloads at the rate",
    "start": "563940",
    "end": "568950"
  },
  {
    "text": "it cares about and then importantly - it doesn't actually have to admit them any set rate so it can choose not to emit it",
    "start": "568950",
    "end": "574950"
  },
  {
    "text": "or well so if it ends up showing up too much resources it can just stop anyway",
    "start": "574950",
    "end": "580529"
  },
  {
    "text": "it emits these payloads and the one that gets to the third payload it stops than anything else right so if you if I",
    "start": "580529",
    "end": "587490"
  },
  {
    "text": "talked about the previous example in an event-driven architecture where you go ahead and have this rogue program that",
    "start": "587490",
    "end": "593820"
  },
  {
    "text": "submitting data it can actually happen in this because it will happen is you'll MIT the three pieces of data and then it",
    "start": "593820",
    "end": "598890"
  },
  {
    "text": "will just stop it won't send any more data and you won't actually have that",
    "start": "598890",
    "end": "604910"
  },
  {
    "text": "situation where one bad actor can go ahead and just take up all your system resources and then because this is a",
    "start": "604910",
    "end": "612270"
  },
  {
    "text": "bi-directional channel destination one can go ahead and say hey go ahead and send me data back as well but two",
    "start": "612270",
    "end": "619290"
  },
  {
    "text": "doesn't have to do that instead it can go ahead and send other messages which is like go ahead and complete this",
    "start": "619290",
    "end": "624450"
  },
  {
    "text": "transaction I want to stop doing it and then the thing that's actually the most useful in this architecture is let's say",
    "start": "624450",
    "end": "631589"
  },
  {
    "text": "the third payload is actually causing you issues right well when destination",
    "start": "631589",
    "end": "636660"
  },
  {
    "text": "two gets the third payload in an event-driven architecture there's no way to actually go ahead and really correlate that back to the area where",
    "start": "636660",
    "end": "645660"
  },
  {
    "text": "it's admitted but in our socket when it gets it it goes ahead and basically sends an exception frame back to the",
    "start": "645660",
    "end": "652320"
  },
  {
    "text": "caller so that you can very easily see that like oh I sent this message this guy and then the message comes back so this is how our socket is",
    "start": "652320",
    "end": "661290"
  },
  {
    "text": "loosely coupled so it is spatially decoupled because it sends binary messages over a dedicated stream and it",
    "start": "661290",
    "end": "670170"
  },
  {
    "text": "is temporally decoupled because all of its api's are non blocking so what kind",
    "start": "670170",
    "end": "676709"
  },
  {
    "start": "675000",
    "end": "711000"
  },
  {
    "text": "of messages does our sockets send between the different destinations well our socket sends binary payloads",
    "start": "676709",
    "end": "684620"
  },
  {
    "text": "between the different destinations and it accesses those payloads and processes",
    "start": "684620",
    "end": "689730"
  },
  {
    "text": "am using a flyweight pattern which is very efficient basically doesn't have to allocate objects to do this and it",
    "start": "689730",
    "end": "695520"
  },
  {
    "text": "allows you to do things like zero copy in a very efficient manner and it does this across languages so the different",
    "start": "695520",
    "end": "701520"
  },
  {
    "text": "implementations that are socket whether it's in JavaScript Java C++ all use this",
    "start": "701520",
    "end": "707339"
  },
  {
    "text": "same pattern so they don't create extra garbage let's take a look at how our",
    "start": "707339",
    "end": "712620"
  },
  {
    "start": "711000",
    "end": "983000"
  },
  {
    "text": "socket actually does is processing and this is something like when you move to threaded code and multi-threaded",
    "start": "712620",
    "end": "721230"
  },
  {
    "text": "applications that you can get wrong really easily and actually create a situation where it looks like you might",
    "start": "721230",
    "end": "726810"
  },
  {
    "text": "be CPU bound but you're actually not so I have a really simple application",
    "start": "726810",
    "end": "732950"
  },
  {
    "text": "that's just doing some work basically pretty easy to see basics gonna go ahead and count and what this you know",
    "start": "732950",
    "end": "740220"
  },
  {
    "text": "conceptually looks like is there's one thread going ahead calling this simple little program and running it right and",
    "start": "740220",
    "end": "746720"
  },
  {
    "text": "it turns out this is incredibly fast like on my laptop this took less than a",
    "start": "746720",
    "end": "751920"
  },
  {
    "text": "microsecond to run right like basically in a microsecond you can count to 2 billion on a laptop right but of course",
    "start": "751920",
    "end": "760620"
  },
  {
    "text": "we need to like make this faster and everyone knows the best way to do that is to just go ahead and add as many threads as possible we get like 128 core",
    "start": "760620",
    "end": "767790"
  },
  {
    "text": "box we're gonna just add like 128 threads this guy and we're gonna we're",
    "start": "767790",
    "end": "773220"
  },
  {
    "text": "gonna totally blow this out of the water right and not only that we're gonna use Atomics and just you know make the best",
    "start": "773220",
    "end": "779820"
  },
  {
    "text": "program ever and so like how long do you guys think this took to run does anyone have a guess anyone know",
    "start": "779820",
    "end": "787150"
  },
  {
    "text": "no clue so this is kind of what it looks like everyone's helping you out counting",
    "start": "787150",
    "end": "792890"
  },
  {
    "text": "right everyone's gonna lend a hand and add to this but when I ran this guess what happened I didn't wait for it to",
    "start": "792890",
    "end": "799340"
  },
  {
    "text": "finish it let it run for like ten minutes on my laptop and it never completed in fact I wanted to I didn't",
    "start": "799340",
    "end": "807320"
  },
  {
    "text": "actually think it was working so I changed the target of you know two billion to like two thousand it still",
    "start": "807320",
    "end": "812630"
  },
  {
    "text": "took 30 milliseconds 40 milliseconds to actually run right and so basically",
    "start": "812630",
    "end": "818600"
  },
  {
    "text": "what's happening is is you're causing contention in the CPU right so not only are you not on your CPU cache it's a",
    "start": "818600",
    "end": "825140"
  },
  {
    "text": "very fast you're actually in slow main memory right and then you have all these",
    "start": "825140",
    "end": "831920"
  },
  {
    "text": "people like going in at once trying to like go a help at it and like the way I like to think about it is imagine you",
    "start": "831920",
    "end": "837140"
  },
  {
    "text": "have like a eight-lane highway right and then at the end of the hate lane highway it all goes down into one road and",
    "start": "837140",
    "end": "842480"
  },
  {
    "text": "you're just trying to jam as much stuff through and when you run this you run something this you can actually go look",
    "start": "842480",
    "end": "848330"
  },
  {
    "text": "at your task manager and it looks like you're running at you know you know eight hundred percent CPU on my laptop",
    "start": "848330",
    "end": "853880"
  },
  {
    "text": "it looks like it's just churning through stuff and I'm like oh I must be totally CPU bound right but you're not because",
    "start": "853880",
    "end": "859520"
  },
  {
    "text": "you saw the last application in a like taking less than a microsecond right so",
    "start": "859520",
    "end": "865630"
  },
  {
    "text": "what can we do well this is something that happens a lot behind the scenes in",
    "start": "865630",
    "end": "870680"
  },
  {
    "text": "our sock and other reactive libraries and what we want to do is you basically want to take our application and turn it",
    "start": "870680",
    "end": "878120"
  },
  {
    "text": "into a bunch of single threaded applications for you right and so what",
    "start": "878120",
    "end": "883520"
  },
  {
    "text": "we end up doing is we end up controlling threads accessing the work we want to do",
    "start": "883520",
    "end": "889220"
  },
  {
    "text": "with a shared variable and then locally we go ahead and cache it right so we end",
    "start": "889220",
    "end": "894290"
  },
  {
    "text": "up doing the work so it's all on the same CPU so it's very fast and then when we're done we go ahead and we you know",
    "start": "894290",
    "end": "899840"
  },
  {
    "text": "make it available to everybody right and so what this kind of ends up looking like is this you basically have a bunch",
    "start": "899840",
    "end": "906890"
  },
  {
    "text": "of little single threaded programs that run right and there's way less contention so when you go ahead and run this it also ends up being pretty quick",
    "start": "906890",
    "end": "914420"
  },
  {
    "text": "it takes less than a millisecond to go through and churn through all this right and a nice side effect of this is the",
    "start": "914420",
    "end": "922260"
  },
  {
    "text": "threads that are actually doing the work are free to go do other stuff right so they're like oh I wanted to count II",
    "start": "922260",
    "end": "927300"
  },
  {
    "text": "know I can't count so they might go do some other application and the way this actually ties back into message passing",
    "start": "927300",
    "end": "933810"
  },
  {
    "text": "is you know replaces a silly little counter what's say like a message queue or something right so everyone's pulling",
    "start": "933810",
    "end": "938820"
  },
  {
    "text": "the message queue one person wins they get to drain the queue the other people are free to go off and do other stuff but no one actually wants to program",
    "start": "938820",
    "end": "947279"
  },
  {
    "text": "like that all the time and I can tell you it's pretty awful to deal with it gets way more complicated but thankfully",
    "start": "947279",
    "end": "953070"
  },
  {
    "text": "we have libraries available that abstract this away for you and end up",
    "start": "953070",
    "end": "958410"
  },
  {
    "text": "actually basically doing the same thing under the scenes right so they end up",
    "start": "958410",
    "end": "964139"
  },
  {
    "text": "going ahead and doing all that complicated work so you end up getting you end up getting the same same result",
    "start": "964139",
    "end": "970529"
  },
  {
    "text": "that happens as if you did this by hand you get these basically little single thread applications and when you run",
    "start": "970529",
    "end": "976470"
  },
  {
    "text": "that application it ends up taking less than a millisecond as well right so to",
    "start": "976470",
    "end": "983940"
  },
  {
    "start": "983000",
    "end": "1172000"
  },
  {
    "text": "circle back to our socket how this connects together so reactive streams",
    "start": "983940",
    "end": "989760"
  },
  {
    "text": "abstracts the way message passing for you right and the interesting thing about message passing is there's no",
    "start": "989760",
    "end": "996630"
  },
  {
    "text": "difference in message passing between something that's on box or off box right like for the caller so if I call",
    "start": "996630",
    "end": "1003139"
  },
  {
    "text": "something I don't necessarily have to have it be on the same box as I'm on",
    "start": "1003139",
    "end": "1008209"
  },
  {
    "text": "right and what our socket end up doing is taking that abstraction and then",
    "start": "1008209",
    "end": "1013310"
  },
  {
    "text": "creating a protocol that makes that work across a network right and the end result is you can basically take this",
    "start": "1013310",
    "end": "1018620"
  },
  {
    "text": "reactive code that was there earlier and swap in our socket without actually changing in any of the calling code",
    "start": "1018620",
    "end": "1024168"
  },
  {
    "text": "right as far as the person making the calls concerned it's as if it's on box right or just you know some answer Kunis",
    "start": "1024169",
    "end": "1031520"
  },
  {
    "text": "code that's running so if we go back and look at the last little snippet of code",
    "start": "1031520",
    "end": "1039380"
  },
  {
    "text": "we have here is the piece that goes off and does the counting is actually encapsulated in a reactive streams",
    "start": "1039380",
    "end": "1045620"
  },
  {
    "text": "context and we can go ahead and switch it with a really simple little request reply peace",
    "start": "1045620",
    "end": "1051820"
  },
  {
    "text": "and then if you go look the person that's actually doing the calling isn't changed at all right as far as they're",
    "start": "1051820",
    "end": "1057760"
  },
  {
    "text": "concerned this could just be you know some threaded code and so you can begin to go ahead and use this to build out",
    "start": "1057760",
    "end": "1063600"
  },
  {
    "text": "more complicated applications that could either run on box run off box you can",
    "start": "1063600",
    "end": "1069100"
  },
  {
    "text": "combine them together and as far as the person calling it there's no difference to you and then conceptually you end up",
    "start": "1069100",
    "end": "1075850"
  },
  {
    "text": "with this you end up with a bunch of applications with the work paralyzed out where you don't have to go ahead and",
    "start": "1075850",
    "end": "1081010"
  },
  {
    "text": "worry about it so to go ahead and review",
    "start": "1081010",
    "end": "1089080"
  },
  {
    "text": "it we talked at the top we need something like temporal and spatial decoupling so we want to make sure that",
    "start": "1089080",
    "end": "1094950"
  },
  {
    "text": "we pass messages through a stream or channel to to a to a caller we need",
    "start": "1094950",
    "end": "1101620"
  },
  {
    "text": "spatial decoupling screw goes up so we need spatially coupling which is sending",
    "start": "1101620",
    "end": "1106780"
  },
  {
    "text": "a message through a channel or a stream we need temporal decoupling which of course is like non-blocking api's we",
    "start": "1106780",
    "end": "1113620"
  },
  {
    "text": "want that what we're sending across the network to actually be encoded in binary so it's efficient and actually I should",
    "start": "1113620",
    "end": "1120070"
  },
  {
    "text": "mention like how much more efficient the binary is so the encoding our socket the frame encoding in binary can do about 10",
    "start": "1120070",
    "end": "1127810"
  },
  {
    "text": "to 20 million recode x' a second versus you know like some of the faster you",
    "start": "1127810",
    "end": "1134260"
  },
  {
    "text": "stuff like json you can do like 30,000 a second so it's not an insignificant difference when you switch to stuff like",
    "start": "1134260",
    "end": "1140320"
  },
  {
    "text": "that and then finally you need some kind of application flow control right so the",
    "start": "1140320",
    "end": "1146380"
  },
  {
    "text": "reason you want application flow control is when you move to a distributed system as you begin to make network calls your",
    "start": "1146380",
    "end": "1153220"
  },
  {
    "text": "tail latency actually dominates the entire request so the slowest request that you make ends up actually slowing",
    "start": "1153220",
    "end": "1158230"
  },
  {
    "text": "down your whole application and so using something like flow control it actually evens out your latency and controls your",
    "start": "1158230",
    "end": "1164290"
  },
  {
    "text": "tail latency which actually makes your entire application faster and that's the stuff that our Saga provides you for",
    "start": "1164290",
    "end": "1170110"
  },
  {
    "text": "free basically using it and then our salon is going to go ahead and go over what this actually works or looks like",
    "start": "1170110",
    "end": "1177070"
  },
  {
    "start": "1172000",
    "end": "1492000"
  },
  {
    "text": "in the real world right so it works in concept so the question we",
    "start": "1177070",
    "end": "1183850"
  },
  {
    "text": "asked ourselves was you know we can we can build small test programs and show",
    "start": "1183850",
    "end": "1190420"
  },
  {
    "text": "ourselves that were millions of times faster than other things but what happens if you build a real-world",
    "start": "1190420",
    "end": "1195850"
  },
  {
    "text": "example you know what does that look like and so what we did was we applied",
    "start": "1195850",
    "end": "1202960"
  },
  {
    "text": "it to the microservices problem because you know it's the it's a distributed computing flavored Azure and so what",
    "start": "1202960",
    "end": "1210340"
  },
  {
    "text": "we're going to do is let's use a test",
    "start": "1210340",
    "end": "1215620"
  },
  {
    "text": "that's out there some of you may have heard of it it's called Acme it's a it's a bit of a test and test harness that",
    "start": "1215620",
    "end": "1222130"
  },
  {
    "text": "that was built to test real-world simulate real-world networked",
    "start": "1222130",
    "end": "1228960"
  },
  {
    "text": "micro-services infrastructures good news is IBM actually publishes tests and",
    "start": "1228960",
    "end": "1238210"
  },
  {
    "text": "publishes the test results on a on a specific system that's listed here on a",
    "start": "1238210",
    "end": "1244420"
  },
  {
    "text": "regular basis so what we said was you know that's a good benchmark of course",
    "start": "1244420",
    "end": "1250660"
  },
  {
    "text": "IBM inventors of sto how many people have heard of this to you okay so this",
    "start": "1250660",
    "end": "1257620"
  },
  {
    "text": "is a you know what what what these days is known as a service mesh sto linker D",
    "start": "1257620",
    "end": "1263590"
  },
  {
    "text": "a couple of others and it's a rest-based proxy base networking scheme that that",
    "start": "1263590",
    "end": "1271210"
  },
  {
    "text": "people are trying to use for building their highly granular distributed microservices applications so good so we",
    "start": "1271210",
    "end": "1279010"
  },
  {
    "text": "have this test that's published and I'd like to point out a couple of things in this test now this these are not our numbers these numbers are available",
    "start": "1279010",
    "end": "1284620"
  },
  {
    "text": "online published by IBM so they ran the test and the first thing I'd like to point",
    "start": "1284620",
    "end": "1290740"
  },
  {
    "text": "out is they got up to around 60 users and if you look at the throughput you see that it's starting to level out",
    "start": "1290740",
    "end": "1299310"
  },
  {
    "text": "right a throughput chart there on the in the middle which is telling us that we're reaching some sort of our capacity",
    "start": "1299310",
    "end": "1306810"
  },
  {
    "text": "constraint there so they were able to ramp it up to 60 users and did a pretty",
    "start": "1306810",
    "end": "1312160"
  },
  {
    "text": "good job they created a through power of around 4 point 4 K requests per",
    "start": "1312160",
    "end": "1320640"
  },
  {
    "text": "minute and then basically delivered the response time profile of 12 milliseconds",
    "start": "1321240",
    "end": "1327040"
  },
  {
    "text": "of 4 point 4 K for 60 concurrent user simulated users in a real application at",
    "start": "1327040",
    "end": "1333490"
  },
  {
    "text": "12 milliseconds performance delivered and that's where they started tapping out in this and they run this regularly",
    "start": "1333490",
    "end": "1340540"
  },
  {
    "text": "so you can go and get the updated results anytime you want so we said okay well that's working on HTTP rests all",
    "start": "1340540",
    "end": "1347080"
  },
  {
    "text": "the good stuff let's run this entire thing based on our socket and so we did",
    "start": "1347080",
    "end": "1353470"
  },
  {
    "text": "oops so stared that for a second same",
    "start": "1353470",
    "end": "1359980"
  },
  {
    "text": "test same machine same everything we got to 60 users delivered a throughput that",
    "start": "1359980",
    "end": "1366970"
  },
  {
    "text": "was four times greater at a response time of a third of what they had and not",
    "start": "1366970",
    "end": "1376120"
  },
  {
    "text": "only that we are still ramping in the throughput chart so there's capacity available so 4x the throughput in a real",
    "start": "1376120",
    "end": "1384610"
  },
  {
    "text": "world system at 1/3 the latency just by using a socket so we got excited very",
    "start": "1384610",
    "end": "1394030"
  },
  {
    "text": "excited and what we did and by the way there's a blog post that lays out all of this it's listed there so we said ok",
    "start": "1394030",
    "end": "1401740"
  },
  {
    "text": "well how far can we go same system since we had more capacity so we went to 300",
    "start": "1401740",
    "end": "1408370"
  },
  {
    "text": "users got to 27 close to 30 K and look",
    "start": "1408370",
    "end": "1414250"
  },
  {
    "text": "at their response time and compare that to the 60 years of response time and",
    "start": "1414250",
    "end": "1420600"
  },
  {
    "text": "then we just got crazy we said let's just go all the way we turn it up to 11 got to a thousand users on the same",
    "start": "1420600",
    "end": "1427960"
  },
  {
    "text": "system concurrent users and the system kept churning kept delivering more",
    "start": "1427960",
    "end": "1433120"
  },
  {
    "text": "throughput 37.8 k and you see this this",
    "start": "1433120",
    "end": "1438430"
  },
  {
    "text": "the response time starting to spike so where the the our socket with all of the the flow control built in etc all these",
    "start": "1438430",
    "end": "1444970"
  },
  {
    "text": "things are acting together to start yielding a little bit on this one time but still creating generating",
    "start": "1444970",
    "end": "1451159"
  },
  {
    "text": "more throughput in the system and all we did was did the same test except we did",
    "start": "1451159",
    "end": "1456860"
  },
  {
    "text": "it on our socket so this was the moment and we this was when we realized that",
    "start": "1456860",
    "end": "1462740"
  },
  {
    "text": "you know all the stuff that that Robert just talked about when applied in a",
    "start": "1462740",
    "end": "1468499"
  },
  {
    "text": "realistic sense can be you know at least we think pretty game-changing so we",
    "start": "1468499",
    "end": "1476029"
  },
  {
    "text": "invite you to sort of look at this take a look at the the blog post you'll see what our methodology was and also if",
    "start": "1476029",
    "end": "1483200"
  },
  {
    "text": "you're interested you know we've got some good good quick starts so you guys can get started if you're not familiar with with with our socket on our website",
    "start": "1483200",
    "end": "1491299"
  },
  {
    "text": "and that's pretty much it I just wanted to I wanted to basically frame this in a",
    "start": "1491299",
    "end": "1498860"
  },
  {
    "text": "real-world scenario because sometimes it's hard to see what the the basic",
    "start": "1498860",
    "end": "1503899"
  },
  {
    "text": "theory is going to get you and at this point I think we're ready for questions Robert you want to come up here so take questions",
    "start": "1503899",
    "end": "1510700"
  },
  {
    "text": "so so there are different components when you're making service to service",
    "start": "1516780",
    "end": "1522000"
  },
  {
    "start": "1517000",
    "end": "1667000"
  },
  {
    "text": "calls right so how about service discovery and serialization and deserialization is that something part",
    "start": "1522000",
    "end": "1528510"
  },
  {
    "text": "of the our circuit or yeah so there's",
    "start": "1528510",
    "end": "1533520"
  },
  {
    "text": "our socket protocol and then on top of that we have like a routing and forwarding protocol that builds on top",
    "start": "1533520",
    "end": "1538620"
  },
  {
    "text": "what our socket offers but with it you basically don't need separate service discovery load balancing we have you",
    "start": "1538620",
    "end": "1547380"
  },
  {
    "text": "know built-in serialization and then coming in like the spring framework this is on the Java side there's built-in integration with serialization stuff",
    "start": "1547380",
    "end": "1553830"
  },
  {
    "text": "into there and then other languages as well have civilization built in so basically what you do is you just set up the application they point each other",
    "start": "1553830",
    "end": "1560340"
  },
  {
    "text": "and then all the everything is taken care of I have a follow-up question on",
    "start": "1560340",
    "end": "1565470"
  },
  {
    "text": "Soji IPC I think gr piece has two components the server side and and then",
    "start": "1565470",
    "end": "1571920"
  },
  {
    "text": "peer-to-peer communication also so if G RPC pair two pair is that similar to our",
    "start": "1571920",
    "end": "1579150"
  },
  {
    "text": "stream or how does it compare so one thing I didn't talk about and there's",
    "start": "1579150",
    "end": "1584970"
  },
  {
    "text": "other talks that talk about this in our socket once you make a connection both sides are co-equal right so there",
    "start": "1584970",
    "end": "1592740"
  },
  {
    "text": "isn't really like a client and a server in our socket there's the person that made the connection that's that's it so",
    "start": "1592740",
    "end": "1597990"
  },
  {
    "text": "I can connect to you and then actually act like a server and so and and in both",
    "start": "1597990",
    "end": "1603240"
  },
  {
    "text": "directions right so on either side you can actually set up clients and servers and exchange messages and we have a",
    "start": "1603240",
    "end": "1609500"
  },
  {
    "text": "protobuf serialization if that's what you like we're looking at graph QL and then there's more of the standard kind",
    "start": "1609500",
    "end": "1615960"
  },
  {
    "text": "of more straight up message passing kind of stuff where you just send messages back and forth so it's kind of like this",
    "start": "1615960",
    "end": "1621260"
  },
  {
    "text": "nice layer with pluggable transports which I also didn't talk about so you can say hey I want this one WebSocket so",
    "start": "1621260",
    "end": "1626940"
  },
  {
    "text": "it works in a browser I want to use TCP I have a shared memory driver based on some stuff Todd did and then you can go",
    "start": "1626940",
    "end": "1633300"
  },
  {
    "text": "ahead and like plug that stuff in and pick what you want and then pick the API that you want to use to talk in your",
    "start": "1633300",
    "end": "1639120"
  },
  {
    "text": "application so I mean just to summarize there's no server or client distinction",
    "start": "1639120",
    "end": "1644670"
  },
  {
    "text": "because it's a completely symmetric scheme and so you don't have to worry about I mean",
    "start": "1644670",
    "end": "1650389"
  },
  {
    "text": "we have some demos where we show an entire service class you know demo",
    "start": "1650389",
    "end": "1655429"
  },
  {
    "text": "running inside a browser and JavaScript that is being accessed by other browsers those kind of things",
    "start": "1655429",
    "end": "1662769"
  },
  {
    "start": "1667000",
    "end": "1763000"
  },
  {
    "text": "performance or in features we have a blog it was real quick like we could do",
    "start": "1667029",
    "end": "1672889"
  },
  {
    "text": "with 92 Meg's of RAM we could do like 800,000 RPS and they died so usually",
    "start": "1672889",
    "end": "1679100"
  },
  {
    "text": "about two yeah similar deltas and we can point you to I mean if you visit a blog",
    "start": "1679100",
    "end": "1684789"
  },
  {
    "text": "similar deltas to this in fact the better look any cases talk about after Azure someone has a question",
    "start": "1684789",
    "end": "1690409"
  },
  {
    "text": "thanks guys it was very interesting and I'm sorry if this is a bit of a stupid question but when you had the graph up",
    "start": "1690409",
    "end": "1697100"
  },
  {
    "text": "with destination one and two and destination requests in CSI you know you can send me three PACU or three or",
    "start": "1697100",
    "end": "1702980"
  },
  {
    "text": "Swann's packages but of a two-part question is destination one dependent on",
    "start": "1702980",
    "end": "1709549"
  },
  {
    "text": "getting all three packages and what kind of retry methodology or mechanics the",
    "start": "1709549",
    "end": "1714860"
  },
  {
    "text": "event it's a good question so first off it's the kindest request and semantics",
    "start": "1714860",
    "end": "1722929"
  },
  {
    "text": "from reactive streams so I send you three right that means you can send me three messages you don't actually have to send them I could even say hey send",
    "start": "1722929",
    "end": "1729740"
  },
  {
    "text": "me eight and that's kind of like these tokens you can use that once you use it up then the rules say you can't send",
    "start": "1729740",
    "end": "1734870"
  },
  {
    "text": "anything else as far as retry semantics go once the stream receives a terminal",
    "start": "1734870",
    "end": "1742549"
  },
  {
    "text": "event like an exception the stream is torn down right but because this message passing what you can do is you can intercept the exception and then not",
    "start": "1742549",
    "end": "1749809"
  },
  {
    "text": "hand it back and then just do a retry if that makes sense and that's kind of built into the frameworks around it so",
    "start": "1749809",
    "end": "1756080"
  },
  {
    "text": "it's not something you do yourself you just basically dot retry",
    "start": "1756080",
    "end": "1760299"
  },
  {
    "text": "um thank you this seems somewhat reminiscent of Nats dot IO and I'm wondering if you're familiar with that",
    "start": "1762830",
    "end": "1768210"
  },
  {
    "start": "1763000",
    "end": "1918000"
  },
  {
    "text": "and could sort of maybe draw some distinctions so because I'm more familiar with that yeah so",
    "start": "1768210",
    "end": "1777330"
  },
  {
    "text": "Nath's is probably more like a message broker like a protocol for a message broker and one thing they did they did",
    "start": "1777330",
    "end": "1785609"
  },
  {
    "text": "that some people like that maybe I don't like as much as that it was its dreamed string based so it's a it's a text it's",
    "start": "1785609",
    "end": "1794099"
  },
  {
    "text": "a very simple text protocol so it's easy to understand and maybe debug but then you get this trade-off with having",
    "start": "1794099",
    "end": "1801299"
  },
  {
    "text": "things encoded and string and it's actually really significant to do that like you can end up basically making all",
    "start": "1801299",
    "end": "1809639"
  },
  {
    "text": "your work like JSON and text set a joke with a guy at work would be like if you just stopped any box randomly at Amazon",
    "start": "1809639",
    "end": "1816389"
  },
  {
    "text": "it's like 99 times out of a hundred and you go look at it you they will be parsing text right and so I mean is",
    "start": "1816389",
    "end": "1823259"
  },
  {
    "text": "you're basically like burning money the other thing I said if you care about the environment you shouldn't use text so that's like a huge difference because",
    "start": "1823259",
    "end": "1829710"
  },
  {
    "text": "basically it's I mean I can't it's very inefficient to to do that and that's one",
    "start": "1829710",
    "end": "1835440"
  },
  {
    "text": "of the big things and then the different interaction models and the final thing is the pluggable transports oh when we",
    "start": "1835440",
    "end": "1842369"
  },
  {
    "text": "built our stock what we wanted to make it so that you could like pick up a transport that was appropriate for your use case right so sometimes this",
    "start": "1842369",
    "end": "1849239"
  },
  {
    "text": "WebSockets sometimes that shared memory sometimes it's TCP we wanted a future-proof it so something like quick",
    "start": "1849239",
    "end": "1854460"
  },
  {
    "text": "comes out you don't actually ought to change your API is you just say hey I'm gonna use quick and that's it so robot",
    "start": "1854460",
    "end": "1861179"
  },
  {
    "text": "briefly mentioned the various interaction patterns that you can have",
    "start": "1861179",
    "end": "1866279"
  },
  {
    "text": "so we have in our socket well if you just look at rest and HTTP you've got a",
    "start": "1866279",
    "end": "1871830"
  },
  {
    "text": "request response right that's that's that's it in our socket first-class interaction",
    "start": "1871830",
    "end": "1877979"
  },
  {
    "text": "can be request response far and forget channel or a bi-directional channel so",
    "start": "1877979",
    "end": "1884279"
  },
  {
    "text": "right stream ijen so these are all first-class primitives of the of the protocol so a lot of the work that",
    "start": "1884279",
    "end": "1890309"
  },
  {
    "text": "people do with buffering and and you know Q's etc are",
    "start": "1890309",
    "end": "1895730"
  },
  {
    "text": "actually handled straightaway inside the the network protocol itself so that's something we didn't get to spend time on",
    "start": "1895730",
    "end": "1901460"
  },
  {
    "text": "but if you're interested you should probably take a look at it you'll find that very interesting was there a",
    "start": "1901460",
    "end": "1907430"
  },
  {
    "text": "question on that side here",
    "start": "1907430",
    "end": "1912790"
  },
  {
    "text": "that's it my connections with know about too much okay yeah so when you connect",
    "start": "1917890",
    "end": "1923500"
  },
  {
    "start": "1918000",
    "end": "2071000"
  },
  {
    "text": "you get an AR socket object right and then what we do is we actually collect those are sock good objects together and",
    "start": "1923500",
    "end": "1929830"
  },
  {
    "text": "well I mean frankly just load balance across the connections right so you have like these like 12 different are you",
    "start": "1929830",
    "end": "1935980"
  },
  {
    "text": "talking my like application load balancing are women to go ahead and like load balance and we like qui us and move them between got three pods that I'll do",
    "start": "1935980",
    "end": "1946059"
  },
  {
    "text": "the same thing and they're communicating with you so if you have one pot that",
    "start": "1946059",
    "end": "1953080"
  },
  {
    "text": "goes down and is replaced okay how do you not overload the one this is",
    "start": "1953080",
    "end": "1960130"
  },
  {
    "text": "actually something to do that is pretty cool because there's back pressure and this availability metric we can actually",
    "start": "1960130",
    "end": "1966910"
  },
  {
    "text": "look and see like how much load you can handle we also take a look at the latency that the that you have and then",
    "start": "1966910",
    "end": "1975460"
  },
  {
    "text": "we actually predict the latency so if you're not within a window we can slow you down speed you up so we get this bucket of Converse istic connections",
    "start": "1975460",
    "end": "1981309"
  },
  {
    "text": "come in we actually use a flyweight for the load balancer put it over the bucket",
    "start": "1981309",
    "end": "1986320"
  },
  {
    "text": "of things you want to talk to and then pull two at random and then actually go ahead and find the best candidate and",
    "start": "1986320",
    "end": "1991390"
  },
  {
    "text": "send it so if one of them goes down very quickly it like moves them off and goes",
    "start": "1991390",
    "end": "1996490"
  },
  {
    "text": "ahead and sends it to somebody else and here's the other cool thing because there's this idea of back pressure if someone's down they're not actually",
    "start": "1996490",
    "end": "2001980"
  },
  {
    "text": "sending you like a request and to send you more data so you'll you'll actually just you know stop getting you know",
    "start": "2001980",
    "end": "2008429"
  },
  {
    "text": "having traffic sent to them to do then also do take over so so if you did have",
    "start": "2008429",
    "end": "2015750"
  },
  {
    "text": "one node that did go down but was actively trying to communicate a process on",
    "start": "2015750",
    "end": "2021180"
  },
  {
    "text": "sort of work with another service yeah so there's this concept in the protocol",
    "start": "2021180",
    "end": "2027120"
  },
  {
    "text": "called resumption so if you have a flappy connection something goes down what it does it actually makes it seem like a stable persistent connection so",
    "start": "2027120",
    "end": "2035490"
  },
  {
    "text": "connection flaps kind of buffer stuff on either side some will pick it up and fill in where you left often so that's",
    "start": "2035490",
    "end": "2041550"
  },
  {
    "text": "how you would do something like that and resume ability can be both warm and cold so you know mobile use cases unreliable",
    "start": "2041550",
    "end": "2050100"
  },
  {
    "text": "networks connections it's a natural to use our sonnet any other questions",
    "start": "2050100",
    "end": "2061429"
  },
  {
    "start": "2071000",
    "end": "2297000"
  },
  {
    "text": "thank you like I mean like some of the things they require even thing right",
    "start": "2071550",
    "end": "2077850"
  },
  {
    "text": "like how does our circuit have anything support to support even thing or it's",
    "start": "2077850",
    "end": "2084720"
  },
  {
    "text": "completely different do you mean like events or scenery yeah I've been asked",
    "start": "2084720",
    "end": "2090898"
  },
  {
    "text": "this before we haven't built anything right now but it would be very natural so another thing we didn't talk about is this connection-oriented so when I",
    "start": "2090899",
    "end": "2098940"
  },
  {
    "text": "connect to you right all the streams that I have come on that same channel so you could begin to go ahead and save",
    "start": "2098940",
    "end": "2104970"
  },
  {
    "text": "them and you could maybe make the case that resumption could be kind of a form",
    "start": "2104970",
    "end": "2110970"
  },
  {
    "text": "of event sourcing too so you might not need to use it quite the same way so you could probably use resumption as a",
    "start": "2110970",
    "end": "2117320"
  },
  {
    "text": "fill-in for event sourcing in some use cases I think because and it's important",
    "start": "2117320",
    "end": "2123060"
  },
  {
    "text": "to understand that we're not advocating for death to all event queues we're not",
    "start": "2123060",
    "end": "2128670"
  },
  {
    "text": "we're not saying that I mean there's a natural use case for events you may be",
    "start": "2128670",
    "end": "2133710"
  },
  {
    "text": "your application requires a cube then use the cube it's there we're also not advocating that you throw out all of",
    "start": "2133710",
    "end": "2140280"
  },
  {
    "text": "your mq and your Kafka's because now you can actually do the where our socket",
    "start": "2140280",
    "end": "2145650"
  },
  {
    "text": "becomes very useful is when you are using those mechanisms you may be using",
    "start": "2145650",
    "end": "2152670"
  },
  {
    "text": "you know rabbit or you mean you may be using Kafka because you have a bi-directional streaming interaction and",
    "start": "2152670",
    "end": "2158720"
  },
  {
    "text": "there's no such facility in rest or or HTTP so you basically use something that",
    "start": "2158720",
    "end": "2166530"
  },
  {
    "text": "was designed to you know ingest today and consume tomorrow as a you know to do",
    "start": "2166530",
    "end": "2173850"
  },
  {
    "text": "your bi-directional streaming so it's those cases that tend to introduce a lot",
    "start": "2173850",
    "end": "2179550"
  },
  {
    "text": "of infrastructure in your applications so there's a place for queues there's a place for you know Kafka's of the world",
    "start": "2179550",
    "end": "2186869"
  },
  {
    "text": "and the rabbits of the world and and even HTTP I mean unit was designed to schlep documents it's great but the",
    "start": "2186869",
    "end": "2194460"
  },
  {
    "text": "important thing is that oftentimes you end up being forced in a place where",
    "start": "2194460",
    "end": "2199859"
  },
  {
    "text": "you're using some of these these these architectural elements these infrastructure elements unnaturally",
    "start": "2199859",
    "end": "2206449"
  },
  {
    "text": "because you have no other options and that's where a massive amount of",
    "start": "2206449",
    "end": "2211920"
  },
  {
    "text": "performance degradation etc comes in so for example if you just take the example of these service mesh thinking that's",
    "start": "2211920",
    "end": "2218489"
  },
  {
    "text": "going on these days what is the service mesh what is the problem is trying to solve and how is it solving it a service",
    "start": "2218489",
    "end": "2224039"
  },
  {
    "text": "mesh is basically a response to the fact that I have two services sitting apart",
    "start": "2224039",
    "end": "2229529"
  },
  {
    "text": "from each other and they need to be able to talk to each other in a secure controlled fashion right so the response",
    "start": "2229529",
    "end": "2234719"
  },
  {
    "text": "is let's put a site car there which is a reverse proxy let's put more proxies there let's introduce service",
    "start": "2234719",
    "end": "2240769"
  },
  {
    "text": "infrastructure let's Discovery infrastructure all of that stuff with all this apparatus of layers upon layers",
    "start": "2240769",
    "end": "2247819"
  },
  {
    "text": "so that service a can talk to service B well we have a model for this it's",
    "start": "2247819",
    "end": "2254729"
  },
  {
    "text": "called networking that's how you talk one service talks to another service not proxy upon proxy upon proxy so it's now",
    "start": "2254729",
    "end": "2262349"
  },
  {
    "text": "that is that saying that that you can't ever use rest or you should never use an service description no no that's all",
    "start": "2262349",
    "end": "2267779"
  },
  {
    "text": "were saying but but the question is when you're trying to build a performant simple to deploy and use system do you",
    "start": "2267779",
    "end": "2277140"
  },
  {
    "text": "have options other than building those big you know scaffolding around your",
    "start": "2277140",
    "end": "2282569"
  },
  {
    "text": "services and that's one of the ways you use this hopefully that gets to the heart of what you're saying thank you",
    "start": "2282569",
    "end": "2289729"
  },
  {
    "text": "more questions",
    "start": "2290239",
    "end": "2293449"
  },
  {
    "start": "2297000",
    "end": "2356000"
  },
  {
    "text": "how does the contract between two different services look like do you do cogeneration or do you use approximant",
    "start": "2297099",
    "end": "2304449"
  },
  {
    "text": "the IDL RPC as well as the messaging yeah there's two ways you can do like I",
    "start": "2304449",
    "end": "2310029"
  },
  {
    "text": "said a message passing between both of them which is more akin to rest you just send it like so Spring has like this",
    "start": "2310029",
    "end": "2316660"
  },
  {
    "text": "concept they're building in or buildings to other stuff like a named a named stream you can do IDL's so protobuf",
    "start": "2316660",
    "end": "2325259"
  },
  {
    "text": "graph QL stuff like that so again like I said you can bring your own API so you can pick what is appropriate for the use",
    "start": "2325259",
    "end": "2332289"
  },
  {
    "text": "case that you're doing and strong contracts are always good if your application can can can have a product",
    "start": "2332289",
    "end": "2338799"
  },
  {
    "text": "so so we do provide the the RPC attraction idea distraction all right",
    "start": "2338799",
    "end": "2347859"
  },
  {
    "text": "any other questions guess we're done all right thank you very much yeah thank you",
    "start": "2347859",
    "end": "2353890"
  },
  {
    "text": "[Applause]",
    "start": "2353890",
    "end": "2358420"
  }
]
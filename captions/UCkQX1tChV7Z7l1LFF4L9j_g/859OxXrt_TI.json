[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": "I'm Cory I'm a software engineer at data bricks and today I'll be talking about ml flow a platform for the complete",
    "start": "3990",
    "end": "11370"
  },
  {
    "text": "machine learning lifecycle ml flow is an open source project that originally got",
    "start": "11370",
    "end": "16529"
  },
  {
    "text": "its start at data bricks and it's developing a large contributor community",
    "start": "16529",
    "end": "21829"
  },
  {
    "text": "to start off let me provide an outline of the topics that I'll be covering over",
    "start": "21829",
    "end": "27329"
  },
  {
    "start": "22000",
    "end": "22000"
  },
  {
    "text": "the next 40 minutes I'll begin with an overview of some of the critical challenges associated with developing",
    "start": "27329",
    "end": "34350"
  },
  {
    "text": "machine learning applications after that I'll introduce ml flow specifically",
    "start": "34350",
    "end": "40079"
  },
  {
    "text": "addressing how ml flow is designed to tackle each of these challenges you'll",
    "start": "40079",
    "end": "45449"
  },
  {
    "text": "get an overview of the three critical components of ml flow tracking projects",
    "start": "45449",
    "end": "51420"
  },
  {
    "text": "and models as well as a compelling demo for each component finally you'll learn",
    "start": "51420",
    "end": "57480"
  },
  {
    "text": "about the ongoing roadmap for ml flow as well as how to get started with the project so let's dive right into the",
    "start": "57480",
    "end": "65100"
  },
  {
    "text": "challenges associated with machine learning application development as many of you are probably painfully aware",
    "start": "65100",
    "end": "71270"
  },
  {
    "text": "developing machine learning applications is complex and to expand on that a bit",
    "start": "71270",
    "end": "76759"
  },
  {
    "start": "76000",
    "end": "76000"
  },
  {
    "text": "let's take a look at the typical machine learning lifecycle it's a four-step",
    "start": "76759",
    "end": "81840"
  },
  {
    "text": "process that all begins with the collection of raw data once data has",
    "start": "81840",
    "end": "86909"
  },
  {
    "text": "been collected it is cleaned and processed and ultimately this processed data is used to fit or train a model",
    "start": "86909",
    "end": "94969"
  },
  {
    "text": "finally this model is deployed to a production environment to satisfy either",
    "start": "94969",
    "end": "100469"
  },
  {
    "text": "a business or production research use case oftentimes these production applications receive new data that was",
    "start": "100469",
    "end": "107430"
  },
  {
    "text": "not part of the original training dataset kick-starting the next iteration of this life cycle so at face value this",
    "start": "107430",
    "end": "115109"
  },
  {
    "text": "may sound somewhat straightforward we have a four-step process but there are several layers of difficulty and",
    "start": "115109",
    "end": "120840"
  },
  {
    "text": "complexity and implementation that actually make this a very daunting task for many organizations let's take a look",
    "start": "120840",
    "end": "127829"
  },
  {
    "text": "at the first one if I were to sit down and try to implement any particular phase of this life cycle the first thing",
    "start": "127829",
    "end": "134700"
  },
  {
    "text": "I notice is that there are a large number of tools of for anyone stage but there is no single",
    "start": "134700",
    "end": "140819"
  },
  {
    "text": "tool that implements all four which means that practically as a developer I'm stitching together code for data",
    "start": "140819",
    "end": "146879"
  },
  {
    "text": "ingest and preparation like Kafka with model training frameworks like tensor flow with deployment environments like",
    "start": "146879",
    "end": "153569"
  },
  {
    "text": "kubernetes and then repeating the process each time I add a new tool for example running the same funnel through",
    "start": "153569",
    "end": "158970"
  },
  {
    "text": "scikit-learn and deploying the Amazon Sage Maker oftentimes this problem lends itself to",
    "start": "158970",
    "end": "164849"
  },
  {
    "text": "the development of brittle pipeline code that is prone to failure as API evolve",
    "start": "164849",
    "end": "170129"
  },
  {
    "text": "and as organizations scale now provided your organization is able to",
    "start": "170129",
    "end": "175680"
  },
  {
    "text": "successfully craft pipelines to stitch together various tools the work is still not complete we also observe that hyper",
    "start": "175680",
    "end": "182609"
  },
  {
    "text": "parameter tuning is a major elements of the machine learning lifecycle and must be supported models are highly sensitive",
    "start": "182609",
    "end": "190079"
  },
  {
    "text": "to configuration parameters referred to as hyper parameters that dramatically impact their performance selecting the",
    "start": "190079",
    "end": "197700"
  },
  {
    "text": "appropriate set of parameters can produce a model that will revolutionize a production news case but failure to",
    "start": "197700",
    "end": "203519"
  },
  {
    "text": "select reasonable parameters may produce a result that's no better or even worse than guesswork so it's paramount that",
    "start": "203519",
    "end": "210060"
  },
  {
    "text": "when you're developing a platform that implements this lifecycle that you allow data scientists to adequately explore",
    "start": "210060",
    "end": "216810"
  },
  {
    "text": "this parameter space additionally we note that scale becomes a problem when",
    "start": "216810",
    "end": "222630"
  },
  {
    "text": "implementing a solution to this life cycle while pipeline code may work for a small handful of developers we often see",
    "start": "222630",
    "end": "230489"
  },
  {
    "text": "that this pipeline code fails to scale properly to large organizations and this is becoming increasingly problematic as",
    "start": "230489",
    "end": "237150"
  },
  {
    "text": "the number of machine learning practitioners increases finally and very",
    "start": "237150",
    "end": "243329"
  },
  {
    "text": "importantly we note that model exchange and governance is a major problem implicated by the machine learning",
    "start": "243329",
    "end": "249810"
  },
  {
    "text": "lifecycle you see it's not sufficient to train a model once in a black box deploy",
    "start": "249810",
    "end": "255120"
  },
  {
    "text": "it and forget where it came from for every model within your organization there needs to be a complete lineage or",
    "start": "255120",
    "end": "261539"
  },
  {
    "text": "track record of the hyper parameters that were used to train that model as",
    "start": "261539",
    "end": "266820"
  },
  {
    "text": "well as source code performance metrics and information about who trained the model and when that model was trained and this is",
    "start": "266820",
    "end": "273270"
  },
  {
    "text": "particularly important for organizations that are beginning to leverage machine learning in high scrutiny environments",
    "start": "273270",
    "end": "278729"
  },
  {
    "text": "such as the financial sector so now that we've expanded on the set of difficulties associated with its life",
    "start": "278729",
    "end": "284759"
  },
  {
    "text": "cycle it's clear that we don't have a simple four-step process but rather a daunting platform development challenge",
    "start": "284759",
    "end": "290789"
  },
  {
    "text": "that is challenging many organizations that are attempting to leverage machine",
    "start": "290789",
    "end": "295949"
  },
  {
    "text": "learning today so you may be asking are there any platform solutions right now",
    "start": "295949",
    "end": "301199"
  },
  {
    "start": "298000",
    "end": "298000"
  },
  {
    "text": "that standardized this life cycle and the answer is sort of we've identified that several platforms from large",
    "start": "301199",
    "end": "308039"
  },
  {
    "text": "established organizations such as Facebook's FB Lerner ubers Michelangelo and Google's tf-x attempt to standardize",
    "start": "308039",
    "end": "315900"
  },
  {
    "text": "the machine learning lifecycle however there are several drawbacks associated with these platforms and the biggest one",
    "start": "315900",
    "end": "322740"
  },
  {
    "text": "that I'll mentioned first is that they're not entirely open-source and are often tied to a particular company's",
    "start": "322740",
    "end": "328650"
  },
  {
    "text": "infrastructure so what that means is unless you're a data scientist or machine learning developer who's lucky",
    "start": "328650",
    "end": "333930"
  },
  {
    "text": "enough to work at one of these companies you often can't leverage the full benefits of their standardized life",
    "start": "333930",
    "end": "339210"
  },
  {
    "text": "cycle the second aspect is that even internally these platforms limit the set",
    "start": "339210",
    "end": "345090"
  },
  {
    "text": "of tools programming languages and algorithms that data scientists can leverage when building their models for",
    "start": "345090",
    "end": "351780"
  },
  {
    "text": "example while tf-x may be an excellent platform for writing tensor flow models for example it is less prone or less",
    "start": "351780",
    "end": "359580"
  },
  {
    "text": "apps in the face of our developers or users who want to write classical models",
    "start": "359580",
    "end": "365039"
  },
  {
    "text": "and frameworks like scikit-learn which leads us to a motivating question can we",
    "start": "365039",
    "end": "370979"
  },
  {
    "text": "provide the benefits of a standardized life cycle in a similar vein to these platforms but do so in an open manner",
    "start": "370979",
    "end": "377789"
  },
  {
    "text": "allowing data scientists to bring the set of tools and languages and algorithms that they require on a daily",
    "start": "377789",
    "end": "384120"
  },
  {
    "text": "basis introducing ml flow an open source platform for the machine learning",
    "start": "384120",
    "end": "389639"
  },
  {
    "start": "386000",
    "end": "386000"
  },
  {
    "text": "lifecycle ml flow is built on an open interface philosophy defining",
    "start": "389639",
    "end": "395190"
  },
  {
    "text": "several key abstractions that allow existing infrastructure and machine learning algorithms to be integrated",
    "start": "395190",
    "end": "401400"
  },
  {
    "text": "with the system easily meaning that if you're a developer who wants to m/l flow and you're using a particular",
    "start": "401400",
    "end": "407820"
  },
  {
    "text": "framework that's currently unsupported the open interface design makes it extremely easy to integrate that",
    "start": "407820",
    "end": "413009"
  },
  {
    "text": "framework and start working with the platform effectively this means that ml flow is designed in principle to work",
    "start": "413009",
    "end": "419100"
  },
  {
    "text": "with any machine learning library or any language further ml flow facilitates",
    "start": "419100",
    "end": "424289"
  },
  {
    "text": "reproducibility meaning that the same training or production machine learning code is designed to execute with the",
    "start": "424289",
    "end": "431070"
  },
  {
    "text": "same results regardless of environments whether in the cloud on a local machine or in a notebook",
    "start": "431070",
    "end": "436669"
  },
  {
    "text": "finally ml flow is designed with scalability in mind meaning it is just",
    "start": "436669",
    "end": "442620"
  },
  {
    "text": "as useful for a small team of data scientists as it is for a large organization consisting of potentially",
    "start": "442620",
    "end": "448440"
  },
  {
    "text": "thousands of machine learning practitioners so now that I've provided a high-level overview of the motivation",
    "start": "448440",
    "end": "455190"
  },
  {
    "start": "452000",
    "end": "452000"
  },
  {
    "text": "for ml flow I'm going to walk through each of ml flows three components tracking projects and models tracking is",
    "start": "455190",
    "end": "463830"
  },
  {
    "text": "a centralized repository for metadata about training sessions within an",
    "start": "463830",
    "end": "468960"
  },
  {
    "text": "organization projects is a reproducible self-contained packaging format for",
    "start": "468960",
    "end": "475080"
  },
  {
    "text": "modeled training code ensuring that that training code runs the same way regardless of the execution environments",
    "start": "475080",
    "end": "481080"
  },
  {
    "text": "and models is a general-purpose model format enabling any model produced with",
    "start": "481080",
    "end": "487409"
  },
  {
    "text": "ml flow to be deployed to a variety of production environments I'm going to",
    "start": "487409",
    "end": "492810"
  },
  {
    "text": "begin by diving into ml flow tracking there are several key concepts",
    "start": "492810",
    "end": "498150"
  },
  {
    "start": "496000",
    "end": "496000"
  },
  {
    "text": "associated with a centralized training metadata tracking repository that ml",
    "start": "498150",
    "end": "503669"
  },
  {
    "text": "flow enables collection of the first concepts is that set of important hyper",
    "start": "503669",
    "end": "508979"
  },
  {
    "text": "parameters or configuration knobs that impact model performance these can all be saved using ml flows api's and",
    "start": "508979",
    "end": "515849"
  },
  {
    "text": "centralized tracking service additionally users can log performance metrics that provide insights into the",
    "start": "515849",
    "end": "522328"
  },
  {
    "text": "effectiveness of their machine learning models additionally for reproducibility ml flow enables users to log the",
    "start": "522329",
    "end": "529500"
  },
  {
    "text": "particular source code that was used to produce a model as well as its version by integrating tightly with get to map",
    "start": "529500",
    "end": "536310"
  },
  {
    "text": "every model to a particular commit hat further and perhaps most importantly for",
    "start": "536310",
    "end": "542220"
  },
  {
    "text": "reproducibility ml flow can also be used to log artifacts which are any arbitrary",
    "start": "542220",
    "end": "548370"
  },
  {
    "text": "files including training test data and models themselves which means that if",
    "start": "548370",
    "end": "553410"
  },
  {
    "text": "I'm a developer who just trained a model I can persist it to the centralized tracking service and one of my",
    "start": "553410",
    "end": "559020"
  },
  {
    "text": "colleagues can load that model sometime later and either continue to train in experiment or productionize that model",
    "start": "559020",
    "end": "565440"
  },
  {
    "text": "to satisfy a particular need finally for any concepts that's not",
    "start": "565440",
    "end": "570480"
  },
  {
    "text": "supported as a first-class entity in the tracking ecosystem ml flow provides supports for flexible tags and notes",
    "start": "570480",
    "end": "578300"
  },
  {
    "text": "associated with a training session for example a notes might be a good place to drop some information about the business",
    "start": "578300",
    "end": "584880"
  },
  {
    "text": "use case for which a model is being developed now that we're familiar with",
    "start": "584880",
    "end": "590310"
  },
  {
    "text": "the set of concepts that ml flow tracking is designed to manage let's take a look at how that ml flow tracking",
    "start": "590310",
    "end": "597630"
  },
  {
    "text": "Service integrates with the existing training ecosystem we observe the",
    "start": "597630",
    "end": "603120"
  },
  {
    "text": "developers and machine learning practitioners train their models in a variety of locations some prefer to use",
    "start": "603120",
    "end": "608970"
  },
  {
    "text": "cloud hosted notebook services like jupiter lab or data bricks others run",
    "start": "608970",
    "end": "614010"
  },
  {
    "text": "model training jobs on Prem or on their local machines a third group uses remote task execution services in the cloud and",
    "start": "614010",
    "end": "621030"
  },
  {
    "text": "there are many others regardless of environment the goal for emma flow tracking is to allow users to capture",
    "start": "621030",
    "end": "627450"
  },
  {
    "text": "all of this important metadata and the way that users are unable to do so is by ml flow tracking ap is written in Python",
    "start": "627450",
    "end": "635610"
  },
  {
    "text": "Java R and also available restfully that allow users to easily instrument that",
    "start": "635610",
    "end": "641910"
  },
  {
    "text": "code and retrieve all of that content regardless of where the codes being executed once this information has been",
    "start": "641910",
    "end": "648570"
  },
  {
    "text": "collected it is aggregated by a centralized tracking server that is pluggable and designed to run on a",
    "start": "648570",
    "end": "655560"
  },
  {
    "text": "variety of popular infrastructure that you may be using today further this",
    "start": "655560",
    "end": "661440"
  },
  {
    "text": "tracking server exposes a view of all this training information both through a high-performance illuminating user",
    "start": "661440",
    "end": "668160"
  },
  {
    "text": "interface as well as a set of programmatic API s so the developers can interact directly with",
    "start": "668160",
    "end": "674100"
  },
  {
    "text": "the data and perform analytics about the models that are being trained within their organization let's take a look at",
    "start": "674100",
    "end": "682079"
  },
  {
    "text": "an example of the ml flow tracking API in Python in this case we're gonna walk",
    "start": "682079",
    "end": "687420"
  },
  {
    "text": "through a very simple example whereby a user hypothetically trains a machine learning model and logs the associated",
    "start": "687420",
    "end": "694139"
  },
  {
    "text": "metadata that I just talked about in the previous slide it all starts with the creation of a new run using the ml flow",
    "start": "694139",
    "end": "701130"
  },
  {
    "text": "that start run directive a run as a term for a training session once a training",
    "start": "701130",
    "end": "706649"
  },
  {
    "text": "session has been initialized ml flows log per am directive can be used to log",
    "start": "706649",
    "end": "712050"
  },
  {
    "text": "hyper parameter information for example the number of layers in a neural network or the Alpha parameter associated with a",
    "start": "712050",
    "end": "719220"
  },
  {
    "text": "logistic regression algorithm after this point users can simply inject any",
    "start": "719220",
    "end": "724829"
  },
  {
    "text": "training code that they may already be executing ml flow is not at all prescriptive or restrictive about the",
    "start": "724829",
    "end": "731880"
  },
  {
    "text": "type of code that can run within a model training session after the model has been fit performance metrics are",
    "start": "731880",
    "end": "738540"
  },
  {
    "text": "obtained and these are logged using the ml flow log metric directive we",
    "start": "738540",
    "end": "743639"
  },
  {
    "text": "oftentimes observe that research groups and businesses produced visualizations of model performance using sophisticated",
    "start": "743639",
    "end": "750660"
  },
  {
    "text": "plotting tools and these visualizations can be directly logged using the ml float log artifact directive for any",
    "start": "750660",
    "end": "758279"
  },
  {
    "text": "arbitrary file it's also worth noting that the ml flow UI provides its own visualizations as well finally the most",
    "start": "758279",
    "end": "766170"
  },
  {
    "text": "important part for reproducibility comes from an ml flow model specific",
    "start": "766170",
    "end": "771690"
  },
  {
    "text": "integration for persisting the model artifact itself for example you see here",
    "start": "771690",
    "end": "777389"
  },
  {
    "text": "the ml flow tensor flow log model directive which will take your tensor flow graph persist it in an ml flow",
    "start": "777389",
    "end": "784589"
  },
  {
    "text": "model format that you'll learn more about later and upload it to the centralized repository so that colleagues can download and begin using",
    "start": "784589",
    "end": "790949"
  },
  {
    "text": "that model later on now that we're familiar with the overview of the",
    "start": "790949",
    "end": "796620"
  },
  {
    "start": "794000",
    "end": "794000"
  },
  {
    "text": "tracking component we're going to walk through the first part of our demo and I realize this is a training data set that",
    "start": "796620",
    "end": "802740"
  },
  {
    "text": "you're likely all familiar with we're going to be talking about digit classification with feminists and the reason I'm doing so is",
    "start": "802740",
    "end": "808350"
  },
  {
    "text": "because M nest provides a very self-contained training data set and",
    "start": "808350",
    "end": "813390"
  },
  {
    "text": "problem that emphasizes how easy it is to integrate ml flow with your existing",
    "start": "813390",
    "end": "819180"
  },
  {
    "text": "training code so the first thing that we're going to do is take a Karass feed-forward neural network training",
    "start": "819180",
    "end": "825270"
  },
  {
    "text": "script that I've written and we're gonna instrument it using those Python tracking api's and see just how easy it",
    "start": "825270",
    "end": "831000"
  },
  {
    "text": "is to collect all of this metadata the first thing I'll do is hop over to my terminal and can everybody see this",
    "start": "831000",
    "end": "839010"
  },
  {
    "text": "alright or should i zoom in a little bit more okay do one more I'm going to take",
    "start": "839010",
    "end": "844620"
  },
  {
    "text": "a look at this caris train python script and walk through the overall structure",
    "start": "844620",
    "end": "850460"
  },
  {
    "text": "initially we see that this training script defines a set of arguments a set of hyper parameters that are gonna",
    "start": "850460",
    "end": "856650"
  },
  {
    "text": "impact model performance such as the number of epochs the learning rates and the batch size after that the scripts",
    "start": "856650",
    "end": "863910"
  },
  {
    "text": "loads the M missed digit classification data set using a Karass API and then it",
    "start": "863910",
    "end": "870270"
  },
  {
    "text": "defines a feed-forward neural network using the Charis sequential API after",
    "start": "870270",
    "end": "876420"
  },
  {
    "text": "this it simply fits the model on the training data set that we loaded previously and after the model has been",
    "start": "876420",
    "end": "883410"
  },
  {
    "text": "trained it ultimately evaluates it on test data and produces test metrics so",
    "start": "883410",
    "end": "889140"
  },
  {
    "text": "now what we're going to do is instrument this code with ml flow the first thing that I'll do is import the ml flow",
    "start": "889140",
    "end": "896100"
  },
  {
    "text": "library as well as the Karis specific ml flow module that's going to be used to",
    "start": "896100",
    "end": "902160"
  },
  {
    "text": "persist that model to the centralized tracking repository now after we've",
    "start": "902160",
    "end": "907980"
  },
  {
    "text": "identified the training parameters and hyper parameters for our model we're gonna log those as well",
    "start": "907980",
    "end": "913380"
  },
  {
    "text": "in this case we leverage the log per am directed that we saw on the previous slide to log the batch size the epics",
    "start": "913380",
    "end": "919950"
  },
  {
    "text": "and the learning rates the next thing that we'll do is define a Karass callback that is going to log some",
    "start": "919950",
    "end": "926850"
  },
  {
    "text": "metrics associated with the model after each training epoch and we're going to",
    "start": "926850",
    "end": "933330"
  },
  {
    "text": "go ahead and pass this callback into the models fit function so that our metric logging executes after each",
    "start": "933330",
    "end": "940200"
  },
  {
    "text": "training epic this is going to instruments the process of training the",
    "start": "940200",
    "end": "947399"
  },
  {
    "text": "next thing that we're going to do is obtain those evaluation metrics and we're going to log the test loss and",
    "start": "947399",
    "end": "953220"
  },
  {
    "text": "test accuracy at the end using the same log metric directive finally the most",
    "start": "953220",
    "end": "959820"
  },
  {
    "text": "important part for reproducibility again we're going to go ahead and use the ml float Karis module to log the model",
    "start": "959820",
    "end": "966329"
  },
  {
    "text": "itself to the centralized tracking repository so I'll go ahead and save this file and will note that we didn't",
    "start": "966329",
    "end": "973050"
  },
  {
    "text": "add any more than 20 lines of code here to fully instrument our existing training strips so ml flows Python api's",
    "start": "973050",
    "end": "978690"
  },
  {
    "text": "are super lightweight and powerful the next thing that I'll note is I've defined this ml flow tracking URI",
    "start": "978690",
    "end": "985949"
  },
  {
    "text": "environment variable in my terminal and this environment variable refers to a",
    "start": "985949",
    "end": "991199"
  },
  {
    "text": "particular instance of the ml flow tracking server running on ec2 so when I",
    "start": "991199",
    "end": "997320"
  },
  {
    "text": "run this training script ml flow is gonna pick up this environment variable and forward all of the data to this centralized tracking repository I'm",
    "start": "997320",
    "end": "1004610"
  },
  {
    "text": "gonna go ahead and run this and I'll specify that we're gonna use two training epics which hopefully doesn't",
    "start": "1004610",
    "end": "1010100"
  },
  {
    "text": "take too long while this runs I'll hop over to the ml flow UI and provide an overview of how",
    "start": "1010100",
    "end": "1015709"
  },
  {
    "text": "training sessions are visualized I'll zoom in on this just a bit everybody see",
    "start": "1015709",
    "end": "1020810"
  },
  {
    "text": "this okay great we see that we have a list of training sessions under a particular experiments",
    "start": "1020810",
    "end": "1028280"
  },
  {
    "text": "and experiments is a simply just a collection of training sessions that are aggregated around a particular use case",
    "start": "1028280",
    "end": "1034850"
  },
  {
    "text": "we see that important metadata such as the user who produced the model is recorded here as well as source code",
    "start": "1034850",
    "end": "1042230"
  },
  {
    "text": "that was used to train that model the set of hyper parameters those batch sizes dropouts learning rate for example",
    "start": "1042230",
    "end": "1050240"
  },
  {
    "text": "and then metrics so if I go ahead and refresh you should see a new model",
    "start": "1050240",
    "end": "1055640"
  },
  {
    "text": "training session corresponding to the run that we just created we'll see that we have a new session from about a",
    "start": "1055640",
    "end": "1062419"
  },
  {
    "text": "minute ago see that I trained it and we get the name of the exact source script",
    "start": "1062419",
    "end": "1067549"
  },
  {
    "text": "that Karis underscore train PI we see that we train with two epics and if we",
    "start": "1067549",
    "end": "1072770"
  },
  {
    "text": "go ahead and click we can hone in on some more tabular information about the model training",
    "start": "1072770",
    "end": "1078710"
  },
  {
    "text": "session and visualize the set of produced artifacts we'll come back to this specific view of these of this",
    "start": "1078710",
    "end": "1086060"
  },
  {
    "text": "training session later on in the demo now I'm going to hop back into the presentation and talk a little bit about",
    "start": "1086060",
    "end": "1093350"
  },
  {
    "start": "1093000",
    "end": "1093000"
  },
  {
    "text": "how you can get started with ml flow tracking within your organization the ml",
    "start": "1093350",
    "end": "1098540"
  },
  {
    "text": "flow tracking service back ends is divided into two components the first is an entity or metadata store that's",
    "start": "1098540",
    "end": "1105830"
  },
  {
    "text": "designed to collect and aggregate all of the lightweight metadata associated with",
    "start": "1105830",
    "end": "1111800"
  },
  {
    "text": "a training session this is for your metrics your parameters and source inversion for example the",
    "start": "1111800",
    "end": "1119090"
  },
  {
    "text": "metadata store is designed to work with any UNIX or Windows file system it's",
    "start": "1119090",
    "end": "1124190"
  },
  {
    "text": "also compatible with a wide variety of sequel databases via sequel alchemy these include Postgres my sequel as well",
    "start": "1124190",
    "end": "1132470"
  },
  {
    "text": "as sequel light finally for organizations that wish to bring their own infrastructure the metadata store",
    "start": "1132470",
    "end": "1139640"
  },
  {
    "text": "provides a restful abstraction allowing your organization to plug in any",
    "start": "1139640",
    "end": "1145250"
  },
  {
    "text": "particular infrastructure restfully and implement the metadata store abstraction",
    "start": "1145250",
    "end": "1151960"
  },
  {
    "text": "the second aspect of the ml flow backend is for heavier-weight artifacts such as those training data",
    "start": "1151960",
    "end": "1157940"
  },
  {
    "text": "files and models the artifacts store is also designed to run on top of a variety",
    "start": "1157940",
    "end": "1163970"
  },
  {
    "text": "of existing production infrastructure such as Amazon s3 Azure blob storage",
    "start": "1163970",
    "end": "1169480"
  },
  {
    "text": "HDFS Google Cloud Storage the data bricks file system FTP and SFTP so there",
    "start": "1169480",
    "end": "1177110"
  },
  {
    "text": "are a large number of options that likely fit your organization's use case for getting started with ml flow",
    "start": "1177110",
    "end": "1182780"
  },
  {
    "text": "tracking now that we've seen an overview of the tracking components I'm going to",
    "start": "1182780",
    "end": "1188150"
  },
  {
    "text": "talk about ml flow projects a reproducible packaging format for model",
    "start": "1188150",
    "end": "1193310"
  },
  {
    "text": "training sessions regardless of execution context and to start with motivation we observe that businesses",
    "start": "1193310",
    "end": "1200540"
  },
  {
    "start": "1198000",
    "end": "1198000"
  },
  {
    "text": "are leveraging a diverse set of machine learning training tools but they're also running these training tools in a",
    "start": "1200540",
    "end": "1205610"
  },
  {
    "text": "diverse set of environments as we saw in one of the previous slides for example they may be running their training code in the cloud they may be",
    "start": "1205610",
    "end": "1211669"
  },
  {
    "text": "running on a local machine they may be running in a notebook which leads to this challenge which is that machine",
    "start": "1211669",
    "end": "1217730"
  },
  {
    "text": "learning results are difficult to reproduce oftentimes the same exact training code doesn't run the same way",
    "start": "1217730",
    "end": "1223549"
  },
  {
    "text": "or produce the same result in two different places an ml flows solution to",
    "start": "1223549",
    "end": "1228799"
  },
  {
    "text": "this is a self-contained training code projects specification that bundles all",
    "start": "1228799",
    "end": "1235580"
  },
  {
    "text": "of the machine learning training code along with its versioned library dependencies its configuration and its",
    "start": "1235580",
    "end": "1242539"
  },
  {
    "text": "training and test data by fully specifying the complete set of dependencies for a machine learning",
    "start": "1242539",
    "end": "1249200"
  },
  {
    "text": "training tasks ml flow enforces reproducibility across execution",
    "start": "1249200",
    "end": "1254779"
  },
  {
    "text": "environments and it does this by installing all those libraries and achieving the exact same system state",
    "start": "1254779",
    "end": "1260779"
  },
  {
    "text": "wherever the code is running so what does an emma flow project look like at its core and emma flow project is simply",
    "start": "1260779",
    "end": "1268519"
  },
  {
    "text": "a directory it's a directory with this optional configuration file and it contains the",
    "start": "1268519",
    "end": "1274669"
  },
  {
    "text": "training code the library dependency specification and other data required by the training session these library",
    "start": "1274669",
    "end": "1281990"
  },
  {
    "text": "dependencies are specified in multiple ways for example users can include a",
    "start": "1281990",
    "end": "1287330"
  },
  {
    "text": "yama formatted anaconda environment specification to enumerate their training codes library dependencies they",
    "start": "1287330",
    "end": "1294169"
  },
  {
    "text": "can also include a docker container and ml flow will execute that training code within the specified container finally",
    "start": "1294169",
    "end": "1300889"
  },
  {
    "text": "ml flow provides a CLI for executing these projects as well as API is in",
    "start": "1300889",
    "end": "1307429"
  },
  {
    "text": "python r and Java and these projects can be executed both on the user's local machine as well as several remote",
    "start": "1307429",
    "end": "1314090"
  },
  {
    "text": "environments including the data bricks job scheduler as well as kubernetes so",
    "start": "1314090",
    "end": "1320840"
  },
  {
    "start": "1320000",
    "end": "1320000"
  },
  {
    "text": "what does an example ml flow project actually look like on the left we see that we have a simple directory",
    "start": "1320840",
    "end": "1327350"
  },
  {
    "text": "structure as alluded to before at the top level there's this ml project configuration file which we'll come back",
    "start": "1327350",
    "end": "1333950"
  },
  {
    "text": "to in a minute and we also have a Conda yamo file specifying the collection of",
    "start": "1333950",
    "end": "1339200"
  },
  {
    "text": "library dependency finally we have some training scripts mein debt pie and model dot pie and this",
    "start": "1339200",
    "end": "1344870"
  },
  {
    "text": "would also be the place to bundle in training and test data or hooks to that information honing in on the ml project",
    "start": "1344870",
    "end": "1351860"
  },
  {
    "text": "configuration file we see that the configuration references that library dependencies condo file if I were using",
    "start": "1351860",
    "end": "1359150"
  },
  {
    "text": "a dr container i would define a docker and variable instead with a fully",
    "start": "1359150",
    "end": "1364190"
  },
  {
    "text": "qualified uri to my specific container additionally and more interestingly the",
    "start": "1364190",
    "end": "1370190"
  },
  {
    "text": "configuration file specifies a set of entry points which consists of a command and then the user configurable",
    "start": "1370190",
    "end": "1376850"
  },
  {
    "text": "parameters to pass to that command at runtime ml flow does not restrict the",
    "start": "1376850",
    "end": "1382280"
  },
  {
    "text": "types of commands that can exist within a configuration file as long as it'll run in a bash shell or a windows shell",
    "start": "1382280",
    "end": "1388430"
  },
  {
    "text": "it's a valid ml flow project command and in this case we'll see that we have a couple of parameters the first is",
    "start": "1388430",
    "end": "1395090"
  },
  {
    "text": "training data and this is a special type called path so the training data can",
    "start": "1395090",
    "end": "1400790"
  },
  {
    "text": "actually reference external artifacts that exist on a variety of storage solutions the local file system s3 and",
    "start": "1400790",
    "end": "1406730"
  },
  {
    "text": "other repositories we also have a simple float parameter lambda with a default value of 0.1 honing out on the bottom",
    "start": "1406730",
    "end": "1414380"
  },
  {
    "text": "right hand of the screen we see an example of how the ml flow runs CLI can",
    "start": "1414380",
    "end": "1419390"
  },
  {
    "text": "be used to execute a project what I'd like to call out here is that ml flow run is directly compatible with projects",
    "start": "1419390",
    "end": "1426290"
  },
  {
    "text": "that exist on github ml flow will automatically clone that repository check out the required git commits and",
    "start": "1426290",
    "end": "1432710"
  },
  {
    "text": "then begin executing the code so let's continue our demo and see how ml",
    "start": "1432710",
    "end": "1438650"
  },
  {
    "text": "projects make it easy to package reproducible machine learning code I'm",
    "start": "1438650",
    "end": "1445130"
  },
  {
    "text": "gonna hop back over to Google Chrome and we're gonna take a look at an example github hosted ml flow project you'll see",
    "start": "1445130",
    "end": "1453740"
  },
  {
    "text": "that in this directory structure we have the ml project configuration file we have a condo ml file specifying a set of",
    "start": "1453740",
    "end": "1461120"
  },
  {
    "text": "dependencies and these include Kerris a GPU installation of tensorflow as well",
    "start": "1461120",
    "end": "1467510"
  },
  {
    "text": "as a specific version of the ml flow library going back we also see that we have our training script",
    "start": "1467510",
    "end": "1473480"
  },
  {
    "text": "and if we hone in on the ml project file will see that we reference our Conda",
    "start": "1473480",
    "end": "1478490"
  },
  {
    "text": "environment and we define an entry points with a set of parameters that are familiar from the training script in the",
    "start": "1478490",
    "end": "1484580"
  },
  {
    "text": "tracking section of the demo we have the batch size we have the epics and we have the learning rates it's worth calling",
    "start": "1484580",
    "end": "1490220"
  },
  {
    "text": "out that when you run an ml flow project with parameters all of these parameters are automatically logged to the tracking",
    "start": "1490220",
    "end": "1496909"
  },
  {
    "text": "service which means that you don't have to instrument project code with that log per am directed all of this is",
    "start": "1496909",
    "end": "1503149"
  },
  {
    "text": "automatically recorded so what I'm going to do here is copy the URL of that git",
    "start": "1503149",
    "end": "1508399"
  },
  {
    "text": "repository and hop back over to our terminal what I'll do now is ssh into a",
    "start": "1508399",
    "end": "1514730"
  },
  {
    "text": "remote GPU based instance and i'm going to go ahead and set that same ml flow",
    "start": "1514730",
    "end": "1521419"
  },
  {
    "text": "tracking URI environment variable to communicate with that same centralized tracking repository now I'll go ahead",
    "start": "1521419",
    "end": "1527570"
  },
  {
    "text": "and leverage the ml flow run CLI to execute that github hosted ml flow",
    "start": "1527570",
    "end": "1533389"
  },
  {
    "text": "project I'll pass in a larger number of epochs and I'll go ahead and hit enter",
    "start": "1533389",
    "end": "1538820"
  },
  {
    "text": "ml flow is going to clone that git repository activate its associated Khanda environment and begin training",
    "start": "1538820",
    "end": "1545179"
  },
  {
    "text": "and we'll see that because we're running on a GPU the training happens a lot more quickly and we ultimately produce a",
    "start": "1545179",
    "end": "1550730"
  },
  {
    "text": "model with better performance so if we hop back over to our tracking UI and go",
    "start": "1550730",
    "end": "1555980"
  },
  {
    "text": "ahead and refresh we'll see that we have a new training session corresponding to",
    "start": "1555980",
    "end": "1561289"
  },
  {
    "text": "that remote ml flow project run we can go ahead and click on the source file and it takes us right back to that same",
    "start": "1561289",
    "end": "1568580"
  },
  {
    "text": "github repository providing a complete lineage of exactly how this model was produced additionally we can go ahead",
    "start": "1568580",
    "end": "1575149"
  },
  {
    "text": "and compare the performance of this model to the performance of the locally trained model we'll go ahead and select",
    "start": "1575149",
    "end": "1581090"
  },
  {
    "text": "these two tick boxes and hit compare in this case we have a tabular view that",
    "start": "1581090",
    "end": "1587169"
  },
  {
    "text": "demonstrates the set of parameters associated with each training session as well as its metrics and if you want to",
    "start": "1587169",
    "end": "1593000"
  },
  {
    "text": "get a more visual take on the performance trade-offs we can go ahead and hone in on a metric like training",
    "start": "1593000",
    "end": "1598250"
  },
  {
    "text": "accuracy and we'll see that it's plotted both relative to Walt wall clock time as",
    "start": "1598250",
    "end": "1603379"
  },
  {
    "text": "well as to the number of training epochs in this case we can see that after a training to epochs for",
    "start": "1603379",
    "end": "1610610"
  },
  {
    "text": "example that locally trained model did pretty well but my training for additional epochs we ended up getting",
    "start": "1610610",
    "end": "1616520"
  },
  {
    "text": "better accuracy that concludes the ml",
    "start": "1616520",
    "end": "1621800"
  },
  {
    "text": "flow projects components of the demo and we'll return to that same project run when attempting to deploy the model for",
    "start": "1621800",
    "end": "1629120"
  },
  {
    "text": "serving later on in the demo but first I'd like to talk about ml flow models a",
    "start": "1629120",
    "end": "1634809"
  },
  {
    "text": "general purpose model format supporting a diverse variety of production ization",
    "start": "1634809",
    "end": "1640910"
  },
  {
    "text": "environments now the motivation for ml flow models is very similar to the motivation for",
    "start": "1640910",
    "end": "1647540"
  },
  {
    "start": "1643000",
    "end": "1643000"
  },
  {
    "text": "projects we again observe that models can be written using a wide variety of tools but they can also be production",
    "start": "1647540",
    "end": "1654350"
  },
  {
    "text": "eyes or deployed in a wide variety of environments as is distinct from training environments these environments",
    "start": "1654350",
    "end": "1661280"
  },
  {
    "text": "include real-time serving tools such as kubernetes or Amazon sage maker as well",
    "start": "1661280",
    "end": "1666620"
  },
  {
    "text": "as tools for streaming and batch scoring like spark additionally some organizations may wish",
    "start": "1666620",
    "end": "1672110"
  },
  {
    "text": "to stand up models as a restful web service running on a pre-configured cloud instance now it's tempting as an",
    "start": "1672110",
    "end": "1678650"
  },
  {
    "text": "organization that wants to deploy to real-time and to batch and is using several machine learning tools to write",
    "start": "1678650",
    "end": "1684679"
  },
  {
    "text": "these deployment pipelines from a particular tool to a particular environment for example a business might",
    "start": "1684679",
    "end": "1691160"
  },
  {
    "text": "stitch together tensorflow with kubernetes a research organization may stitch together scikit-learn models",
    "start": "1691160",
    "end": "1697190"
  },
  {
    "text": "with the batch scoring feature in SPARC for example but what we find is that as",
    "start": "1697190",
    "end": "1703160"
  },
  {
    "text": "the number of tools that organizations are using scales and as they begin to production eyes in new ways we end up",
    "start": "1703160",
    "end": "1710090"
  },
  {
    "text": "with this kind of one-to-one rat's nest mapping that becomes hard to maintain over time and the solution to this",
    "start": "1710090",
    "end": "1716780"
  },
  {
    "text": "problem of mapping M frameworks to n different deployment environments is a",
    "start": "1716780",
    "end": "1722059"
  },
  {
    "start": "1722000",
    "end": "1722000"
  },
  {
    "text": "unified model abstraction called an ml flow model that can be produced using a",
    "start": "1722059",
    "end": "1728330"
  },
  {
    "text": "variety of common ml tools and then deployed to a variety of machine learning environments providing this",
    "start": "1728330",
    "end": "1734540"
  },
  {
    "text": "intermediate layer and avoiding the one-to-one mapping problem so what does",
    "start": "1734540",
    "end": "1739910"
  },
  {
    "text": "an ml flow model look like similarly to a project an Emma phone model is also a directory structure it",
    "start": "1739910",
    "end": "1746290"
  },
  {
    "text": "contains a configuration file and instead of containing training code this time it contains a serialized model",
    "start": "1746290",
    "end": "1753200"
  },
  {
    "text": "artifact it also contains as a project the set of dependencies for reproducibility this",
    "start": "1753200",
    "end": "1760130"
  },
  {
    "text": "time we're talking about evaluation dependencies in the form of a Conda environment",
    "start": "1760130",
    "end": "1765190"
  },
  {
    "text": "additionally Emma flow provides model creation utilities for serializing",
    "start": "1765190",
    "end": "1770360"
  },
  {
    "text": "models from a variety of popular frameworks in ml flow formats finally ml",
    "start": "1770360",
    "end": "1777230"
  },
  {
    "text": "flow introduces deployment api's for production izing and deploying any ml",
    "start": "1777230",
    "end": "1782270"
  },
  {
    "text": "flow model to a variety of services and these api's are available in Python Java",
    "start": "1782270",
    "end": "1787580"
  },
  {
    "text": "R and bio CLI format so let's take a",
    "start": "1787580",
    "end": "1792740"
  },
  {
    "start": "1792000",
    "end": "1792000"
  },
  {
    "text": "look at an example ml flow model that could be produced using the convenience utility ml flow tensorflow",
    "start": "1792740",
    "end": "1799580"
  },
  {
    "text": "dot log model by calling this function we obtain a directory structure similar",
    "start": "1799580",
    "end": "1806480"
  },
  {
    "text": "in nature to a project at the top layer we have the ml model configuration file we also have in this case a serialized",
    "start": "1806480",
    "end": "1813860"
  },
  {
    "text": "tensorflow estimator containing a graph and a collection of variables focusing",
    "start": "1813860",
    "end": "1820400"
  },
  {
    "text": "in on that configuration file we'll see that this time it contains some important metadata about the specific",
    "start": "1820400",
    "end": "1827030"
  },
  {
    "text": "model in this case the run ID which is a unique identifier for the training",
    "start": "1827030",
    "end": "1832640"
  },
  {
    "text": "session that produced it as well as the time that it was created at additionally",
    "start": "1832640",
    "end": "1838070"
  },
  {
    "text": "this configuration file contains an important field called flavors a flavor",
    "start": "1838070",
    "end": "1844190"
  },
  {
    "text": "is a language and tool specific representation of an ml flow model in",
    "start": "1844190",
    "end": "1849830"
  },
  {
    "text": "this example we have two flavors that have been bundled with the model we have the tensorflow flavor and we have the",
    "start": "1849830",
    "end": "1856880"
  },
  {
    "text": "Python function flavor with the tensorflow flavor the ml flow model can",
    "start": "1856880",
    "end": "1862580"
  },
  {
    "text": "be loaded as a native tensorflow object for example a TF dot estimator instance or a TF graph and this makes it usable",
    "start": "1862580",
    "end": "1870200"
  },
  {
    "text": "with any tensorflow api for evaluation or continued training",
    "start": "1870200",
    "end": "1875649"
  },
  {
    "text": "with the Python function flavor ml flow introduces an additional layer of",
    "start": "1875649",
    "end": "1880820"
  },
  {
    "text": "abstraction for loading and evaluating this model via Python function an ml",
    "start": "1880820",
    "end": "1886700"
  },
  {
    "text": "flow model can be represented as a vanilla Python function accepting a panda's data frame meaning that in order",
    "start": "1886700",
    "end": "1893599"
  },
  {
    "text": "to load and evaluate this model I no longer have to reason about the internals of the tensorflow library and",
    "start": "1893599",
    "end": "1900129"
  },
  {
    "text": "to expand on model flavors a bit let's walk through a hyper a hypothetical example where the user trains a model",
    "start": "1900129",
    "end": "1907669"
  },
  {
    "start": "1901000",
    "end": "1901000"
  },
  {
    "text": "logs it to the tracking service and then sometime later loads it and evaluates it",
    "start": "1907669",
    "end": "1913029"
  },
  {
    "text": "the first step would be to train a model doing so using a framework like Kerris which we've been doing in the demos the",
    "start": "1913029",
    "end": "1920749"
  },
  {
    "text": "next step is to persist it using the ml flow caris dot log model directive this",
    "start": "1920749",
    "end": "1926899"
  },
  {
    "text": "produces an ml flow model format with two flavors the first is that Python",
    "start": "1926899",
    "end": "1932119"
  },
  {
    "text": "function flavor abbreviated PI func that you saw previously and the second is a",
    "start": "1932119",
    "end": "1937369"
  },
  {
    "text": "carry specific flavor so if I were to try to load and evaluates the PI func",
    "start": "1937369",
    "end": "1942830"
  },
  {
    "text": "representation of an ml flow model we see that the evaluation code is very simple by invoking ml flow - load PI",
    "start": "1942830",
    "end": "1951710"
  },
  {
    "text": "func I represent this model as a vanilla Python function and then to evaluate it",
    "start": "1951710",
    "end": "1957259"
  },
  {
    "text": "I simply pass in a formatted pandas dataframe and return a panda's data frame output it's two lines of very",
    "start": "1957259",
    "end": "1964220"
  },
  {
    "text": "simple code that completely abstracts away the details and guts of Karass",
    "start": "1964220",
    "end": "1970029"
  },
  {
    "text": "optionally users can also load the carry specific flavor to obtain a native",
    "start": "1970029",
    "end": "1975049"
  },
  {
    "text": "carries object in this case ml flow caris dot load model yields a Karass",
    "start": "1975049",
    "end": "1981169"
  },
  {
    "text": "model object which can be evaluated using the Charis specific model dot predict api passing in yet another",
    "start": "1981169",
    "end": "1988279"
  },
  {
    "text": "carries specific option so this highlights how ml flows flavors allow users to interact with their models at",
    "start": "1988279",
    "end": "1995090"
  },
  {
    "text": "differing levels of abstraction to meet their particular use case i would like",
    "start": "1995090",
    "end": "2000519"
  },
  {
    "text": "to highlight that the PI func abstraction is extremely useful when we consider the number of model creation",
    "start": "2000519",
    "end": "2006489"
  },
  {
    "text": "utilities that ml flow supports for example models trained in Karis tensorflow spark scikit-learn PI torch",
    "start": "2006489",
    "end": "2014710"
  },
  {
    "text": "and several other frameworks are all automatically serialized with this Python function representation meaning",
    "start": "2014710",
    "end": "2021550"
  },
  {
    "text": "that those same two lines of code that I use to load and evaluate that Karis model are compatible with any model in",
    "start": "2021550",
    "end": "2028720"
  },
  {
    "text": "the ML flow ecosystem that contains this Python function format which means that for deployment engineers it's super easy",
    "start": "2028720",
    "end": "2034660"
  },
  {
    "text": "to write thin evaluation layers that are compatible with the wide set of models",
    "start": "2034660",
    "end": "2039910"
  },
  {
    "text": "that are being developed within my organization now I'd like to return to our demo and see how we can deploy an ml",
    "start": "2039910",
    "end": "2047020"
  },
  {
    "text": "flow model locally for real-time serving the first thing that I'm going to do is",
    "start": "2047020",
    "end": "2052389"
  },
  {
    "text": "hop back into google chrome and pan over to this simple web app for a hand-drawn",
    "start": "2052390",
    "end": "2058360"
  },
  {
    "text": "digit classification the goal here is to be able to draw a digit such as five and forward predictions to a hosted model",
    "start": "2058360",
    "end": "2064750"
  },
  {
    "text": "now you'll notice this doesn't quite work yet because we haven't actually hooked up a model to that web app so the",
    "start": "2064750",
    "end": "2070480"
  },
  {
    "text": "first thing that we're gonna do is go back into ml flow and open up the",
    "start": "2070480",
    "end": "2075850"
  },
  {
    "text": "training session corresponding to our previous remote project run this",
    "start": "2075850",
    "end": "2081040"
  },
  {
    "text": "training session has a unique identifier or run ID that will copy for later reference if we scroll down we also see",
    "start": "2081040",
    "end": "2089200"
  },
  {
    "text": "that there are some artifacts associated with our training session we particularly call out this Kerris - CREP",
    "start": "2089200",
    "end": "2096010"
  },
  {
    "text": "resent ation of our model which we're going to use to load and serve in real time this Python function representation",
    "start": "2096010",
    "end": "2103230"
  },
  {
    "text": "specifies the Conda environment that will be activated when running that model as well as the model configuration",
    "start": "2103230",
    "end": "2110350"
  },
  {
    "text": "file with those important attributes such as the set of flavors the run ID and the time created so if I head back",
    "start": "2110350",
    "end": "2118870"
  },
  {
    "text": "to my terminal I can go ahead and exit my GPU instance go ahead and make sure",
    "start": "2118870",
    "end": "2124720"
  },
  {
    "text": "that my ml flow tracking URI is still set and now I'll leverage the ml flow",
    "start": "2124720",
    "end": "2129910"
  },
  {
    "text": "models CLI to serve the model as a local restful web service so I can type ml",
    "start": "2129910",
    "end": "2136840"
  },
  {
    "text": "flow models serve pass in a unique reference to that model artifact",
    "start": "2136840",
    "end": "2142780"
  },
  {
    "text": "in this case I will paste in the run ID I will also type in the name of that",
    "start": "2142780",
    "end": "2148450"
  },
  {
    "text": "Python function representation and I'll hit enter now the download may take a moment so let me explain what ml flow is",
    "start": "2148450",
    "end": "2155260"
  },
  {
    "text": "doing behind the scenes ml flow will fetch the serialized carest model that ml flow formatted",
    "start": "2155260",
    "end": "2161320"
  },
  {
    "text": "model from the tracking server it will then activate its Conda environments once the environment has been activated",
    "start": "2161320",
    "end": "2167260"
  },
  {
    "text": "it will start a flask server running in Python and this flask server will then load the generic Python function",
    "start": "2167260",
    "end": "2174250"
  },
  {
    "text": "representation of the model such that when a request is received its transformed to a panda's data frame",
    "start": "2174250",
    "end": "2179560"
  },
  {
    "text": "passed to the Python function and then the output data frame is returned as JSON so it looks like this loaded",
    "start": "2179560",
    "end": "2185800"
  },
  {
    "text": "successfully I'll go ahead and return to our web app and see if we can draw a",
    "start": "2185800",
    "end": "2191380"
  },
  {
    "text": "digit successfully this time looks like if we draw a five we get a five we can",
    "start": "2191380",
    "end": "2196990"
  },
  {
    "text": "try a different digit it's a poorly drawn - but it seems to pick that one up and I know this model has some problem",
    "start": "2196990",
    "end": "2204550"
  },
  {
    "text": "with sevens so this facilitates the idea that ml flow is an ongoing",
    "start": "2204550",
    "end": "2209830"
  },
  {
    "text": "experimentation tool by which users can continue to iterate and develop on their models without changing particular",
    "start": "2209830",
    "end": "2216310"
  },
  {
    "text": "evaluation code so that concludes the",
    "start": "2216310",
    "end": "2221380"
  },
  {
    "text": "overview of the collection of components associated with ml flow now I'd like to",
    "start": "2221380",
    "end": "2226900"
  },
  {
    "start": "2222000",
    "end": "2222000"
  },
  {
    "text": "talk a little bit about a little bit about the current state of the project as well as the ongoing development",
    "start": "2226900",
    "end": "2232420"
  },
  {
    "text": "roadmap and tell you guys how to get started ml flow recently released stable",
    "start": "2232420",
    "end": "2237700"
  },
  {
    "text": "version 1.0 and there are several important features to call out the first is a new metrics UI which you saw",
    "start": "2237700",
    "end": "2244450"
  },
  {
    "text": "briefly during the project's component where runs can be visually compared against one another on multiple axes",
    "start": "2244450",
    "end": "2251490"
  },
  {
    "text": "additionally to call it out specifically you can now associate metrics with",
    "start": "2251490",
    "end": "2256780"
  },
  {
    "text": "particulate training epics or iterations via a generic step parameter to that log",
    "start": "2256780",
    "end": "2261850"
  },
  {
    "text": "metric call additionally in ml flow 1.0 search has been greatly improved",
    "start": "2261850",
    "end": "2267580"
  },
  {
    "text": "you can search model training sessions based on attributes such as parameter values metric values a runs start time",
    "start": "2267580",
    "end": "2274750"
  },
  {
    "text": "or user for exam additionally Wando supports packaging",
    "start": "2274750",
    "end": "2280540"
  },
  {
    "text": "Emma flow models as dr. containers for deployment to platforms like kubernetes and finally the last feature I'd like to",
    "start": "2280540",
    "end": "2287349"
  },
  {
    "text": "call out which is actually a community contribution is support for the onyx framework in ml flow via an ml flow",
    "start": "2287349",
    "end": "2294040"
  },
  {
    "text": "flavor additionally I'll provide a high-level overview of ml flows ongoing",
    "start": "2294040",
    "end": "2300250"
  },
  {
    "start": "2296000",
    "end": "2296000"
  },
  {
    "text": "development roadmap we're actively working on this new component which is a model registry for model management's",
    "start": "2300250",
    "end": "2306430"
  },
  {
    "text": "this will allow users to version models as well as keep track of where they're deployed and eventually this model",
    "start": "2306430",
    "end": "2313150"
  },
  {
    "text": "registry will integrate with several monitoring and telemetry tools to provide insight into production model",
    "start": "2313150",
    "end": "2318280"
  },
  {
    "text": "performance additionally we're working on support for multi-step project workflows which allow one ml flow",
    "start": "2318280",
    "end": "2324640"
  },
  {
    "text": "project to call another creating a training execution pipeline we're also",
    "start": "2324640",
    "end": "2329890"
  },
  {
    "text": "working on introducing improved tracking api's for Scala and Java these api's currently exist we're just making them",
    "start": "2329890",
    "end": "2336250"
  },
  {
    "text": "easier to use we'd also like to package projects with bailed steps so this is in",
    "start": "2336250",
    "end": "2341500"
  },
  {
    "text": "the works as well as provide in improvements on the input and output schema associated with that Python",
    "start": "2341500",
    "end": "2347920"
  },
  {
    "text": "function representation extending it to tools like numpy for example to provide",
    "start": "2347920",
    "end": "2353349"
  },
  {
    "text": "enhanced flexibility now getting started with ml flow is really easy it's available on pip via pip install ml flow",
    "start": "2353349",
    "end": "2360910"
  },
  {
    "text": "you can find Doc's and examples at ml flow org and if you'd like to make a",
    "start": "2360910",
    "end": "2366369"
  },
  {
    "text": "contribution to the project you can get us on github at github comm / ml flow or",
    "start": "2366369",
    "end": "2371589"
  },
  {
    "text": "slack us on tinyurl.com / ml flow slack thank you so much for listening and I",
    "start": "2371589",
    "end": "2377980"
  },
  {
    "text": "hope you took some insights out of the open structure of the ml flow platform and learned a lot about its components",
    "start": "2377980",
    "end": "2382990"
  },
  {
    "text": "looking forward to any questions",
    "start": "2382990",
    "end": "2386369"
  },
  {
    "text": "awesome so thanks Cory for the great details on AML flow so we have quite a",
    "start": "2389650",
    "end": "2396440"
  },
  {
    "text": "bit of time for about 10-12 minutes for questions I wanna have a first question",
    "start": "2396440",
    "end": "2402320"
  },
  {
    "text": "for you yeah Mona you have at the end now it's pretty cool is that something I can download is that on your laptop only",
    "start": "2402320",
    "end": "2408620"
  },
  {
    "text": "what you draw and then it I go ahead and send you the source I'm for two different open-source github project and",
    "start": "2408620",
    "end": "2414890"
  },
  {
    "text": "modified it to communicate with that model it's a good question though I'll send it to you I call questions",
    "start": "2414890",
    "end": "2422800"
  },
  {
    "text": "thank you so I have a question about where to get started I know there's a",
    "start": "2431000",
    "end": "2436320"
  },
  {
    "text": "lot of tools I'm really new to machine learning as a software developer so what",
    "start": "2436320",
    "end": "2442170"
  },
  {
    "start": "2437000",
    "end": "2437000"
  },
  {
    "text": "so maybe the first question is who are competitors of ml flow cuz I know they're for every tool there's gonna be",
    "start": "2442170",
    "end": "2448170"
  },
  {
    "text": "competitors and also with the really the",
    "start": "2448170",
    "end": "2455700"
  },
  {
    "text": "active development with all these libraries which are the libraries that I constantly have to keep on track of like",
    "start": "2455700",
    "end": "2463260"
  },
  {
    "text": "I know that there's wonderful features that coming out that blows my mind so like some waters yeah so my first",
    "start": "2463260",
    "end": "2470550"
  },
  {
    "text": "question is who are the competitors and second what are the libraries that I have to constantly keep keep on top of",
    "start": "2470550",
    "end": "2478140"
  },
  {
    "text": "in the ecosystem that's a wonderful question everybody was able to hear that all right by the microphone awesome so",
    "start": "2478140",
    "end": "2484349"
  },
  {
    "text": "to start off by addressing what the competitive situation looks like previously on the talk I sort of",
    "start": "2484349",
    "end": "2490170"
  },
  {
    "text": "highlighted some major machine learning platforms that standardized this machine learning lifecycle so tools like",
    "start": "2490170",
    "end": "2496890"
  },
  {
    "text": "Google's tf-x and tensorflow do provide competing implementations for model",
    "start": "2496890",
    "end": "2502440"
  },
  {
    "text": "metadata tracking as well as deployments using tools like tensor flow serving however as I previously stated these are",
    "start": "2502440",
    "end": "2508890"
  },
  {
    "text": "often constrained to particular model types there are a number of other paid",
    "start": "2508890",
    "end": "2513960"
  },
  {
    "text": "services for example such as weights and biases that will try to sell this functionality as well and provide metric",
    "start": "2513960",
    "end": "2520980"
  },
  {
    "text": "logging for example we often find that they aren't quite as feature completes and they aren't as extensible by virtue",
    "start": "2520980",
    "end": "2526859"
  },
  {
    "text": "of being paid services so in terms of the complete management of model",
    "start": "2526859",
    "end": "2532800"
  },
  {
    "text": "training deployments and introducing these remote execution abstractions ml flow is pretty unique in its open source",
    "start": "2532800",
    "end": "2539250"
  },
  {
    "text": "structure in that sense there's another platform I think DVC for handling model",
    "start": "2539250",
    "end": "2545970"
  },
  {
    "text": "training data management and EMA flow is actively working to move more into training data collection and ingest and",
    "start": "2545970",
    "end": "2552960"
  },
  {
    "text": "sort of handle those portions the life cycle as well so you can expect to see that on the ongoing roadmap I hope that",
    "start": "2552960",
    "end": "2558000"
  },
  {
    "text": "provided a pretty good overview of of competing products just the big takeaway here is that ml flow is really the big",
    "start": "2558000",
    "end": "2563910"
  },
  {
    "text": "open source extensible one additionally to answer your other question about which libraries need to be on top of ml flow",
    "start": "2563910",
    "end": "2571230"
  },
  {
    "text": "provides these Conda environments associated with the projects and the models components and the whole goal for",
    "start": "2571230",
    "end": "2578160"
  },
  {
    "text": "providing these Conda environments and doctor containers is to simplify library management so when you train a model",
    "start": "2578160",
    "end": "2584490"
  },
  {
    "text": "with ml flow oftentimes this set of library dependencies is automatically produced which means that as soon as you",
    "start": "2584490",
    "end": "2591390"
  },
  {
    "text": "try to go ahead and serve and continue to load and train that model all the library management is baked into the ml",
    "start": "2591390",
    "end": "2597030"
  },
  {
    "text": "flow platform meaning that the easiest thing you can do is just pip install ml flow and get started and as soon as you",
    "start": "2597030",
    "end": "2603150"
  },
  {
    "text": "save your model all of those required libraries are going to be available thanks thank you any other questions",
    "start": "2603150",
    "end": "2613100"
  },
  {
    "text": "it's a mail flow written in Python or Java or what language is being used it's",
    "start": "2613100",
    "end": "2618510"
  },
  {
    "text": "a great question so the bulk of Emma flow is written in Python we provide tracking API implementations as well as",
    "start": "2618510",
    "end": "2625170"
  },
  {
    "text": "model API implementations in Java and R and you can interact with various components such as deployment pieces the",
    "start": "2625170",
    "end": "2632430"
  },
  {
    "text": "remote project execution for example via a command-line interface and we're actively working to enhance the support",
    "start": "2632430",
    "end": "2639630"
  },
  {
    "text": "for languages like our Java and Scala and if there's a particular language you'd like us to support please reach",
    "start": "2639630",
    "end": "2645030"
  },
  {
    "text": "out on the slack or file a github issue and we'd love to talk about collaborating on introducing support for",
    "start": "2645030",
    "end": "2650100"
  },
  {
    "text": "additional languages I saw when you were doing the training",
    "start": "2650100",
    "end": "2657260"
  },
  {
    "text": "data I had to connect that remote server is there an offline mode if you didn't have a network connection yeah that's an awesome question so when",
    "start": "2657260",
    "end": "2664370"
  },
  {
    "text": "I was talking about the metadata the entity store that's ml flow the AMF low",
    "start": "2664370",
    "end": "2669470"
  },
  {
    "text": "back end is implemented on one of those options was a file system so the I was",
    "start": "2669470",
    "end": "2674960"
  },
  {
    "text": "it was a very minor detail but the point is that ml flows tracking components can run on top of any UNIX or Windows file",
    "start": "2674960",
    "end": "2680600"
  },
  {
    "text": "system this also extends to artifacts meaning that the easiest way to get started is by running and testing",
    "start": "2680600",
    "end": "2686240"
  },
  {
    "text": "locally on your machine and you can do that without calling out any particular tracking URI it'll just start using the",
    "start": "2686240",
    "end": "2692450"
  },
  {
    "text": "local directory associated with your training script unless otherwise specified any other questions I think",
    "start": "2692450",
    "end": "2702650"
  },
  {
    "text": "this is pretty awesome open source projects to get involved with if you're looking for one to contribute all right",
    "start": "2702650",
    "end": "2711800"
  },
  {
    "text": "if not let's give Cori now two hands for an awesome presentation [Applause]",
    "start": "2711800",
    "end": "2719860"
  }
]
[
  {
    "text": "foreign [Music]",
    "start": "1380",
    "end": "16920"
  },
  {
    "text": "I am super excited to be here today and to talk to you about Edge caching",
    "start": "16920",
    "end": "23000"
  },
  {
    "text": "graphql apis my name is Max steuber I am in a",
    "start": "23000",
    "end": "29640"
  },
  {
    "text": "beautiful Vienna Austria here unfortunately I can't be there in person this time but I am really excited to be",
    "start": "29640",
    "end": "36780"
  },
  {
    "text": "here and if you want to follow me practically anywhere on the internet I am at mxstvr",
    "start": "36780",
    "end": "43800"
  },
  {
    "text": "basically everywhere I am the co-founder of graph CDN which",
    "start": "43800",
    "end": "50219"
  },
  {
    "text": "is the graphql CDN if you are in the react community in the",
    "start": "50219",
    "end": "56640"
  },
  {
    "text": "reactivist community or in the JavaScript Community more generally you might have used some of the open source",
    "start": "56640",
    "end": "61980"
  },
  {
    "text": "projects that I helped build like styled components or react boilerplates or microanalytics or a whole bunch of",
    "start": "61980",
    "end": "69360"
  },
  {
    "text": "others I'm really active in that scene and so if you're there you might have used some of those projects as well",
    "start": "69360",
    "end": "78680"
  },
  {
    "text": "the story of a graph CDN and how we got there",
    "start": "78680",
    "end": "83700"
  },
  {
    "text": "started in 2018. at the time I was the CTO of another startup called Spectrum",
    "start": "83700",
    "end": "90540"
  },
  {
    "text": "and at Spectrum we were building a modern take on the classic Community",
    "start": "90540",
    "end": "96900"
  },
  {
    "text": "Forum so essentially we were trying to combine the best of what PHP BBB gave us",
    "start": "96900",
    "end": "104220"
  },
  {
    "text": "20 years ago with the best of what Discord and slack give us nowadays that",
    "start": "104220",
    "end": "109920"
  },
  {
    "text": "was essentially the idea it was a public forum but all of the comments on any",
    "start": "109920",
    "end": "115439"
  },
  {
    "text": "posts Were Real Time chat so we tried to take these two worlds that were that are",
    "start": "115439",
    "end": "121860"
  },
  {
    "text": "currently very separate where communities in slack and Discord write lots of messages but none of them are findable and make them public and a",
    "start": "121860",
    "end": "129599"
  },
  {
    "text": "little bit more organized so that you could find them afterwards on Google or elsewhere and try to combine those two",
    "start": "129599",
    "end": "136140"
  },
  {
    "text": "worlds together now that actually worked out",
    "start": "136140",
    "end": "142400"
  },
  {
    "text": "surprisingly well which led to quite a bit of user growth as you can imagine with all of this user generated content",
    "start": "142400",
    "end": "148739"
  },
  {
    "text": "lots of people found us on Google and elsewhere and started visiting Spectrum",
    "start": "148739",
    "end": "154020"
  },
  {
    "text": "quite regularly that meant we had quite a bit of growth",
    "start": "154020",
    "end": "159060"
  },
  {
    "text": "now unfortunately I had chosen a database that wasn't very well supported",
    "start": "159060",
    "end": "164519"
  },
  {
    "text": "I chose to rethink DB which nowadays doesn't even exist anymore the company behind it shut down after a while",
    "start": "164519",
    "end": "170959"
  },
  {
    "text": "and I chosen that database originally because they advertised themselves as the real-time database and their key",
    "start": "170959",
    "end": "178560"
  },
  {
    "text": "feature or there the the thing they praised externally was that you could",
    "start": "178560",
    "end": "183780"
  },
  {
    "text": "put this changes key at the end of any database query and it would give stream",
    "start": "183780",
    "end": "189120"
  },
  {
    "text": "real-time updates to that database query to you and so you could listen to changes to practically any data changes",
    "start": "189120",
    "end": "196080"
  },
  {
    "text": "which felt like a fantastic fit for what we were trying to do",
    "start": "196080",
    "end": "202500"
  },
  {
    "text": "because obviously almost anything in Spectrum was real time right the post popped in in real time the chat was real",
    "start": "202500",
    "end": "207959"
  },
  {
    "text": "time of course we had direct messages which had to be real time so this felt like a great fit for what we were trying",
    "start": "207959",
    "end": "214080"
  },
  {
    "text": "to do lesson learned in hindsight rely on the databases that everybody",
    "start": "214080",
    "end": "219659"
  },
  {
    "text": "uses there's a reason everybody uses postgres and MySQL in now there's a reason those databases are as",
    "start": "219659",
    "end": "226440"
  },
  {
    "text": "prevalent as they are is because they work I didn't I'm I'm a lot wiser now I",
    "start": "226440",
    "end": "232500"
  },
  {
    "text": "wasn't that wise back then and so it very quickly turned out that racing to",
    "start": "232500",
    "end": "237780"
  },
  {
    "text": "be the real-time nature of it didn't scale at all we had hundreds of thousands of users every single month",
    "start": "237780",
    "end": "245220"
  },
  {
    "text": "but recently B couldn't even handle a hundred concurrent change listeners",
    "start": "245220",
    "end": "251879"
  },
  {
    "text": "now as you can imagine every person that visits the website starts many different change listeners right we're listening",
    "start": "251879",
    "end": "256979"
  },
  {
    "text": "to changes of the specific post that they're looking at we're listening to changes of the community that the post has posted in we're listening to new",
    "start": "256979",
    "end": "263460"
  },
  {
    "text": "notifications we had a bunch of listening is per user and essentially",
    "start": "263460",
    "end": "268500"
  },
  {
    "text": "our database servers were on fire literally on fire well thankfully not",
    "start": "268500",
    "end": "274560"
  },
  {
    "text": "literally but they were crashing quite frequently I Googled servers on fire and found this amazing stock photo of",
    "start": "274560",
    "end": "281540"
  },
  {
    "text": "servers on fire which if your data center looks like this you have some",
    "start": "281540",
    "end": "286740"
  },
  {
    "text": "really serious problems hours weren't quite as bad but they were still pretty bad",
    "start": "286740",
    "end": "293699"
  },
  {
    "text": "so we had this database that didn't scale and we had essentially we had to work around that limitation we wanted to",
    "start": "293699",
    "end": "300960"
  },
  {
    "text": "switch to a more well-supported database however that's a lot of work",
    "start": "300960",
    "end": "307680"
  },
  {
    "text": "um rewriting the hundreds of database queries we'd written and optimized up to that point migrating all that data",
    "start": "307680",
    "end": "313259"
  },
  {
    "text": "without any downtime that was the whole project and we wanted to get there eventually but we needed a solution for",
    "start": "313259",
    "end": "319560"
  },
  {
    "text": "us crashing literally every day right at this moment",
    "start": "319560",
    "end": "325080"
  },
  {
    "text": "as I was thinking about this of course I realized that caching we had an ideal use case for caching because our API was",
    "start": "325080",
    "end": "333180"
  },
  {
    "text": "really read heavy of course it's public data lots of people read it but not as many people write to it and so actually",
    "start": "333180",
    "end": "338580"
  },
  {
    "text": "we had an ideal use case for caching we'd originally chosen graphql for our API because we had a lot of relational",
    "start": "338580",
    "end": "345419"
  },
  {
    "text": "data we were fetching a community all the posts within that Community the authors of every post the number of",
    "start": "345419",
    "end": "351419"
  },
  {
    "text": "comments a bunch of relational data and graphql was a fantastic fit for that use case it worked out extremely well for us",
    "start": "351419",
    "end": "358620"
  },
  {
    "text": "and we really enjoyed our experience of building our API with graphql the one big downside that we ran into",
    "start": "358620",
    "end": "365100"
  },
  {
    "text": "was that there weren't any pre-built solutions for caching graphql at the",
    "start": "365100",
    "end": "370620"
  },
  {
    "text": "edge which is what we wanted to do now we wanted to essentially run code in many many data centers all around the",
    "start": "370620",
    "end": "377820"
  },
  {
    "text": "world and we wanted to Route our users to the nearest Data Center and cache",
    "start": "377820",
    "end": "382860"
  },
  {
    "text": "their data very close to them for a very fast response time but also so that we could reduce the load on our servers",
    "start": "382860",
    "end": "390600"
  },
  {
    "text": "now if you've ever used graphql then you know that that is essentially what",
    "start": "390600",
    "end": "395880"
  },
  {
    "text": "graphql clients do in the browser if you've heard of Apollo client relay Urkel all of these graphql clients what",
    "start": "395880",
    "end": "402900"
  },
  {
    "text": "they are is essentially an A A fetching mechanism for graphql queries that very",
    "start": "402900",
    "end": "408600"
  },
  {
    "text": "intelligently caches them in the browser for a better user experience so in my head basically the question I wanted to",
    "start": "408600",
    "end": "414960"
  },
  {
    "text": "answer was can't I just run a graphql client at the edge",
    "start": "414960",
    "end": "420360"
  },
  {
    "text": "graphql clients do this in the browser why can't I just take this graphical client that's running on my local",
    "start": "420360",
    "end": "426600"
  },
  {
    "text": "browser put it on a server somewhere and have that same caching logic but at the itch",
    "start": "426600",
    "end": "433080"
  },
  {
    "text": "to answer the question I want to dive a little bit into how graphql clients cache if we look at this example of a",
    "start": "433080",
    "end": "440160"
  },
  {
    "text": "graphql query which fetches a blog post by a slug and it fetches its ID title",
    "start": "440160",
    "end": "445800"
  },
  {
    "text": "and the author and of the author it fetches the ID name and Avatar and there",
    "start": "445800",
    "end": "451380"
  },
  {
    "text": "is one magic trick that makes graphql caching really great and that is the",
    "start": "451380",
    "end": "458400"
  },
  {
    "text": "underscore underscore type name meta field you can add that to any graphql object any in your query you can add",
    "start": "458400",
    "end": "465240"
  },
  {
    "text": "that to any object type and you will get back the name of the type of the response so for example with this query",
    "start": "465240",
    "end": "471780"
  },
  {
    "text": "we would add type name in these two places for the post and also for the",
    "start": "471780",
    "end": "476880"
  },
  {
    "text": "author when the origin responds with the data the response will look something like this with the important piece being",
    "start": "476880",
    "end": "483780"
  },
  {
    "text": "that now we have the post data and we know that the type that was returned there was a post and the same thing for",
    "start": "483780",
    "end": "490080"
  },
  {
    "text": "the author we got the author data and we also know that the author is a user",
    "start": "490080",
    "end": "495120"
  },
  {
    "text": "and when we take this response and we store it in our cache locally in the browser we can now associate that cached",
    "start": "495120",
    "end": "503340"
  },
  {
    "text": "query response with those two objects we can tag it with post with the id5 and",
    "start": "503340",
    "end": "508919"
  },
  {
    "text": "user with the id1 okay that's fine so we've just taken this query response we've put it in the",
    "start": "508919",
    "end": "516240"
  },
  {
    "text": "cache we key that by the query that we saw so by the get post query and anytime",
    "start": "516240",
    "end": "521700"
  },
  {
    "text": "we see the same query we return that same data why are these tags relevant why do I",
    "start": "521700",
    "end": "527279"
  },
  {
    "text": "care that this contains the post with the id5 and the user with the id1 well this is where the magic comes in graphql",
    "start": "527279",
    "end": "534000"
  },
  {
    "text": "also has something called mutations which are essentially just actions anything that changes data needs to be a",
    "start": "534000",
    "end": "539820"
  },
  {
    "text": "mutation for example if we had a mutation that was called edit post which edits a post in this case we're",
    "start": "539820",
    "end": "547080"
  },
  {
    "text": "editing the post with your D5 and changing its title any mutation also has to fetch whatever",
    "start": "547080",
    "end": "553320"
  },
  {
    "text": "it changed so in this case we're getting back the post and again we can do the same thing we did for the query and add",
    "start": "553320",
    "end": "559620"
  },
  {
    "text": "the underscore underscore type name fields to the response now when that response comes back from the origin to",
    "start": "559620",
    "end": "566160"
  },
  {
    "text": "our client the client can look at this response and go oh look we just sent a mutation to the origin that mutation has",
    "start": "566160",
    "end": "573540"
  },
  {
    "text": "come back from the origin and the data that was returned was the post with the id5 huh",
    "start": "573540",
    "end": "581040"
  },
  {
    "text": "I actually have a cached query response that contains that post with the id5 and",
    "start": "581040",
    "end": "587880"
  },
  {
    "text": "I can now automatically invalidate that cash query result that contains the stale data of this post that's amazing",
    "start": "587880",
    "end": "594899"
  },
  {
    "text": "right and this is what graphql clients do under the hood they do this Magic invalidation based on the underscore",
    "start": "594899",
    "end": "600720"
  },
  {
    "text": "underscore type name field and the ID field and then they combine them to invalidate any scale data that has been",
    "start": "600720",
    "end": "606180"
  },
  {
    "text": "changed at the origin there's one slight Edge case here where",
    "start": "606180",
    "end": "611459"
  },
  {
    "text": "the magic kind of ends which is list invalidation if you imagine a query that fetches a list of blog posts in this",
    "start": "611459",
    "end": "618060"
  },
  {
    "text": "case just their ID and title when we look at the response to to this query it's an array that just contains the one",
    "start": "618060",
    "end": "624660"
  },
  {
    "text": "blog post that we have right now the post with your D5 how to Edge cache graphql apis",
    "start": "624660",
    "end": "630180"
  },
  {
    "text": "now a mutation that creates a new post now poses an interesting problem because",
    "start": "630180",
    "end": "636660"
  },
  {
    "text": "of course the response to this create post mutation will look something like this it will return an object of a post",
    "start": "636660",
    "end": "643640"
  },
  {
    "text": "with the id6 but of course our Quest create our",
    "start": "643640",
    "end": "650220"
  },
  {
    "text": "cached query results for the Post list doesn't contain the post with the id6",
    "start": "650220",
    "end": "657060"
  },
  {
    "text": "and that's really annoying because that means that graphql clients can't automatically invalidate when lists when",
    "start": "657060",
    "end": "663779"
  },
  {
    "text": "new items are created kind of frustrating now thankfully they",
    "start": "663779",
    "end": "669779"
  },
  {
    "text": "found a good workaround for this which is manual invitation essentially graphql clients give you different apis to",
    "start": "669779",
    "end": "676980"
  },
  {
    "text": "manually influence the cache and change it depending on which things pass through it so for example with",
    "start": "676980",
    "end": "683700"
  },
  {
    "text": "Urkel which is uh the third biggest graphql client this would look this would look a little bit like this you",
    "start": "683700",
    "end": "689160"
  },
  {
    "text": "could tell Oracle that when the create post mutation passes through the graphql client invalidate any query cached query",
    "start": "689160",
    "end": "696899"
  },
  {
    "text": "result that contains the posts query that contains the list of posts and so",
    "start": "696899",
    "end": "701940"
  },
  {
    "text": "that way we can automatically invalidate that no problem and whenever a post is created our graphql client will",
    "start": "701940",
    "end": "707700"
  },
  {
    "text": "automatically refetch the fresh data from the origin Graphica clients actually go one step",
    "start": "707700",
    "end": "714360"
  },
  {
    "text": "further and they do something called normalized caching if we go back to our",
    "start": "714360",
    "end": "719399"
  },
  {
    "text": "original query of fetching a single blog post it's a d title and it's author then",
    "start": "719399",
    "end": "725820"
  },
  {
    "text": "rather than taking the entire response of the post with the D5 and the user with your D1 and putting that entire",
    "start": "725820",
    "end": "731940"
  },
  {
    "text": "thing keyed by the query into the cache they actually take each object within",
    "start": "731940",
    "end": "737100"
  },
  {
    "text": "the query response individually and store that individually so inside of",
    "start": "737100",
    "end": "742860"
  },
  {
    "text": "Urkel's cache this looks a little bit like this where we essentially in the",
    "start": "742860",
    "end": "748260"
  },
  {
    "text": "Cache Store okay the post with the id5 corresponds to this data and the user with the id1 corresponds to this other",
    "start": "748260",
    "end": "755339"
  },
  {
    "text": "data why do we care to do this because now if if a query comes in that for",
    "start": "755339",
    "end": "760980"
  },
  {
    "text": "example fetches the user with the id1 then the Cache can go oh hold on you're",
    "start": "760980",
    "end": "766740"
  },
  {
    "text": "fetching the user with the id1 although we haven't seen the specific query before we do actually have that specific",
    "start": "766740",
    "end": "773040"
  },
  {
    "text": "data in our cache and we can just serve you that on the client without you having to go to the origin to fetch that",
    "start": "773040",
    "end": "779040"
  },
  {
    "text": "data again because we've already fetched it it was just deeply nested in some other query but we've normalized that",
    "start": "779040",
    "end": "784320"
  },
  {
    "text": "for you and can now give you the user data for the user with the id1 no problem just like that which is very",
    "start": "784320",
    "end": "790620"
  },
  {
    "text": "nice and actually makes for Less Network traffic and a much nicer user experience because things will resolve much much",
    "start": "790620",
    "end": "796019"
  },
  {
    "text": "faster since they're already on the client and loaded very nice you essentially only ever fetch every object",
    "start": "796019",
    "end": "802200"
  },
  {
    "text": "once which is fantastic as people particularly if people navigate around your app quite frequently",
    "start": "802200",
    "end": "808019"
  },
  {
    "text": "now the one thing that's missing here that you might have noticed is the post dot author we",
    "start": "808019",
    "end": "815040"
  },
  {
    "text": "have the post with the D5 data and the user with the id1 later but how do we know that the post author is the user",
    "start": "815040",
    "end": "822120"
  },
  {
    "text": "with the id1 well Urkel stores that in a separate data structure that looks like this which essentially just talks about",
    "start": "822120",
    "end": "828839"
  },
  {
    "text": "the relations or the links between things so here we're essentially saying hey if you're fetching the post with",
    "start": "828839",
    "end": "834839"
  },
  {
    "text": "this specific slug that corresponds to the post with the id5 if you're fetching the post with your d5's author then that",
    "start": "834839",
    "end": "842279"
  },
  {
    "text": "corresponds to the user with your D1 and then the user with the id1 doesn't have any further relations or links that you",
    "start": "842279",
    "end": "847920"
  },
  {
    "text": "can go into now what I really want you to take away from this section is that graphql is",
    "start": "847920",
    "end": "855779"
  },
  {
    "text": "actually awesome for caching it's actually really really good for caching because of its introspectability it",
    "start": "855779",
    "end": "862019"
  },
  {
    "text": "tells you what data you're returning and this introspectability combined with the",
    "start": "862019",
    "end": "867060"
  },
  {
    "text": "strict schema where you have to return something that matches that schema means it's actually really good for caching",
    "start": "867060",
    "end": "874019"
  },
  {
    "text": "and that's also a lot of the reason why so much great tooling has",
    "start": "874019",
    "end": "879899"
  },
  {
    "text": "spun up around graphql it's gotten such wide Community adoption that if one person builds tooling tooling for it",
    "start": "879899",
    "end": "886199"
  },
  {
    "text": "because it's always the same graphql spec that it that it has to follow everybody else gets to benefit from that",
    "start": "886199",
    "end": "892620"
  },
  {
    "text": "tooling and that's incredibly powerful now to get back to my original question",
    "start": "892620",
    "end": "898320"
  },
  {
    "text": "that I posed way back in 2018 can't I just run a graphical client at the edge",
    "start": "898320",
    "end": "904199"
  },
  {
    "text": "can't I just take this logic that Apollo client relay and Eric will have internally anyway",
    "start": "904199",
    "end": "909720"
  },
  {
    "text": "take that same code and just put it on a bunch of servers around the world at the",
    "start": "909720",
    "end": "914940"
  },
  {
    "text": "edge so that everybody that uses Spectrum everywhere gets super fast response times and we get to reduce the",
    "start": "914940",
    "end": "922740"
  },
  {
    "text": "load our server has to handle massively well the key to the answer of this question",
    "start": "922740",
    "end": "930980"
  },
  {
    "text": "lies in the last part The Edge because as it turns out graphql clients are",
    "start": "930980",
    "end": "937019"
  },
  {
    "text": "designed with very specific constraints that div that differ ever so slightly",
    "start": "937019",
    "end": "943019"
  },
  {
    "text": "from the constraints we would have to work with at the edge one of the main ones that we have to",
    "start": "943019",
    "end": "949500"
  },
  {
    "text": "deal with if we were to deploy caching logic to the edge is authorization because of course if a graphql client",
    "start": "949500",
    "end": "956639"
  },
  {
    "text": "runs in the browser it knows that if something is in the cache whoever's requesting this again can",
    "start": "956639",
    "end": "963600"
  },
  {
    "text": "access it because it's the same person right if I'm using spectrum and I'm querying for the post with the id5 the",
    "start": "963600",
    "end": "971100"
  },
  {
    "text": "and the graphical client puts that in the cache then the graphql client doesn't have to worry about authorization it doesn't even have to",
    "start": "971100",
    "end": "976500"
  },
  {
    "text": "know anything about authorization because I am allowed to access the post",
    "start": "976500",
    "end": "981779"
  },
  {
    "text": "with your D5 so if I request the same post again the client can just give that to me from the cache right and go yeah",
    "start": "981779",
    "end": "988019"
  },
  {
    "text": "of course right no problem at the age that's slightly differently right if we have one server setting that",
    "start": "988019",
    "end": "994500"
  },
  {
    "text": "a lot of users are requesting data from some of those might be allowed to access",
    "start": "994500",
    "end": "999959"
  },
  {
    "text": "the post with your D5 but others maybe aren't right or maybe even more specifically if you think about user",
    "start": "999959",
    "end": "1005720"
  },
  {
    "text": "data right maybe somebody's allowed to access their own email but nobody else's and so we can't just take a query and",
    "start": "1005720",
    "end": "1013579"
  },
  {
    "text": "put that result in the cache because that would mean everyone gets served the same data so if somebody creates some",
    "start": "1013579",
    "end": "1019519"
  },
  {
    "text": "data that's sensitive that's specific to that user suddenly that will be served to everyone that will be a nightmare",
    "start": "1019519",
    "end": "1024798"
  },
  {
    "text": "right that we can see terrible security Nightmare and a really bad experience because we would essentially just be",
    "start": "1024799",
    "end": "1029839"
  },
  {
    "text": "leaking data very bad idea so at the edge what we have to do is rather than",
    "start": "1029839",
    "end": "1035000"
  },
  {
    "text": "just making the cash key a hash of the query so essentially we take the query text that we have and the variables and",
    "start": "1035000",
    "end": "1040640"
  },
  {
    "text": "we use that as a cache key rather than doing just that we also have to take the author authorization token into account",
    "start": "1040640",
    "end": "1046760"
  },
  {
    "text": "whether that's sent via the authorization header or whether that is a cool cookie we have to just add that",
    "start": "1046760",
    "end": "1052220"
  },
  {
    "text": "to the cache key so that if somebody else sends the same query they don't get the same response",
    "start": "1052220",
    "end": "1058100"
  },
  {
    "text": "it's as simple as that just put the authorization token in the cat excuse me in the cache key and",
    "start": "1058100",
    "end": "1064039"
  },
  {
    "text": "everything will be fine the other part that's a little bit different is Cash purging because",
    "start": "1064039",
    "end": "1071240"
  },
  {
    "text": "not only do we have to do automatic cash purging and support manual invalidation",
    "start": "1071240",
    "end": "1076400"
  },
  {
    "text": "for list invalidation we also have to do it globally right if you're running at the age and all of these data centers",
    "start": "1076400",
    "end": "1081919"
  },
  {
    "text": "globally then you have to invalidate that data globally right if the post with their D5 changes and the user sends",
    "start": "1081919",
    "end": "1087799"
  },
  {
    "text": "a mutation to edit that or the server says hey look this has changed and once manually invalidated then you have to do",
    "start": "1087799",
    "end": "1095059"
  },
  {
    "text": "it globally you can't just do it in one data center that would be a terrible experience because the stale data would",
    "start": "1095059",
    "end": "1100760"
  },
  {
    "text": "stick around in every other data center you have to do it globally and so as we were thinking about these problems for",
    "start": "1100760",
    "end": "1106940"
  },
  {
    "text": "craft City and as we were building out this graphql Edge cache solution we came to the conclusion that we that",
    "start": "1106940",
    "end": "1114440"
  },
  {
    "text": "we're going to use fastly's compute at Edge product now we are huge fans of fastly here and the reason we chose",
    "start": "1114440",
    "end": "1120620"
  },
  {
    "text": "fastly is because like their name suggests they are super fast ly has about 60 and ever increasing data",
    "start": "1120620",
    "end": "1129140"
  },
  {
    "text": "centers worldwide spread across the entire Globe now here is a crazy fact",
    "start": "1129140",
    "end": "1135500"
  },
  {
    "text": "fastly's invalidation logic right if you take a query response and you put it into fast lease cache and you tag it",
    "start": "1135500",
    "end": "1142280"
  },
  {
    "text": "with the post with your D5 if you then send an API request to fastly to",
    "start": "1142280",
    "end": "1147500"
  },
  {
    "text": "invalidate any cash query result that contains the post with your D5 they can invalidate stale data within",
    "start": "1147500",
    "end": "1155260"
  },
  {
    "text": "150 milliseconds globally 150 milliseconds globally that is",
    "start": "1155260",
    "end": "1161900"
  },
  {
    "text": "probably faster than you can blink right in the time that it takes me to do this fastly is already invalidated the data",
    "start": "1161900",
    "end": "1168200"
  },
  {
    "text": "globally that is absolutely mind-blowing to me right and I actually looked up a",
    "start": "1168200",
    "end": "1173600"
  },
  {
    "text": "while ago I was like wait hold on how fast even is the speed of light right surely that takes a while to go around",
    "start": "1173600",
    "end": "1180200"
  },
  {
    "text": "the globe once and so I looked it up and actually light does take 133 milliseconds if I remember correctly",
    "start": "1180200",
    "end": "1186559"
  },
  {
    "text": "to get across the entire globe so how can fasting validate within 150",
    "start": "1186559",
    "end": "1193039"
  },
  {
    "text": "milliseconds that is super fast well the answer is of course that they're that they don't have to go around the",
    "start": "1193039",
    "end": "1199340"
  },
  {
    "text": "entire Globe because they're going bi-directional they're going both ways at the same time so they only have to go",
    "start": "1199340",
    "end": "1204440"
  },
  {
    "text": "around half the globe which cuts the time in half and then of course they also do they have a really",
    "start": "1204440",
    "end": "1210799"
  },
  {
    "text": "fancy gossiping algorithm which you can Google they've wrote they've written some great articles about it and I bow",
    "start": "1210799",
    "end": "1217160"
  },
  {
    "text": "down in front of their Engineers because it's absolutely genius and it is so fast that it enables our customers now to",
    "start": "1217160",
    "end": "1224480"
  },
  {
    "text": "Cache a lot more data right if you can invalidate stale data within 150 milliseconds globally imagine how much",
    "start": "1224480",
    "end": "1231500"
  },
  {
    "text": "more data you can cache because it will never be sale right when the data changes send an API request and 150",
    "start": "1231500",
    "end": "1238880"
  },
  {
    "text": "milliseconds later everybody globally has the fresh data imagine how much more data you can cache if you have the super",
    "start": "1238880",
    "end": "1245840"
  },
  {
    "text": "fast and validation and that's the reason we use fastly they're super fast and we're super happy with them so",
    "start": "1245840",
    "end": "1251419"
  },
  {
    "text": "that's essentially what graph CDN is we rebuilt this caching logic to run at the",
    "start": "1251419",
    "end": "1258260"
  },
  {
    "text": "edge to take authorization into account and to have this global cash purging and we deploy it to fast this computed age",
    "start": "1258260",
    "end": "1263720"
  },
  {
    "text": "60 worldwide data centers to a allow our customers to Cache their graphql queries",
    "start": "1263720",
    "end": "1269480"
  },
  {
    "text": "in their graphical responses at the age",
    "start": "1269480",
    "end": "1275539"
  },
  {
    "text": "I wish this would have existed back in 2018 when we had our scaling problems",
    "start": "1275539",
    "end": "1280820"
  },
  {
    "text": "with Spectrum at the time I just built a terrible in-memory caching solution that reduced the load slightly until we",
    "start": "1280820",
    "end": "1287059"
  },
  {
    "text": "eventually got acquired by GitHub and I just if we had had gravity and we would",
    "start": "1287059",
    "end": "1292280"
  },
  {
    "text": "have been able to scale so much more smoothly we would have saved so much money because of course running something at the edge is much cheaper",
    "start": "1292280",
    "end": "1298340"
  },
  {
    "text": "than running the request through our entire infrastructure and it would have been a much better experience for all of",
    "start": "1298340",
    "end": "1304100"
  },
  {
    "text": "our Global user base because everybody would have had super fast response times from their local data center",
    "start": "1304100",
    "end": "1311600"
  },
  {
    "text": "all right I hope you learned about graphical caching today the main thing I",
    "start": "1311600",
    "end": "1316880"
  },
  {
    "text": "want you to take away is graphql is amazing for caching that's really the takeaway I want to hone in on graphql",
    "start": "1316880",
    "end": "1325240"
  },
  {
    "text": "absolutely fantastic for caching the introspectability the strict schema shave kiss just absolutely fantastic and",
    "start": "1325240",
    "end": "1333620"
  },
  {
    "text": "if you have a graphql API I'd love to meet you I'd love to hear what else we can do for you in the future even if you",
    "start": "1333620",
    "end": "1338960"
  },
  {
    "text": "don't need caching thank you for having me if you have any questions feel free to",
    "start": "1338960",
    "end": "1345200"
  },
  {
    "text": "hit me up anytime I am at mxsdpr practically everywhere on the internet and I look forward to hearing from you",
    "start": "1345200",
    "end": "1353740"
  },
  {
    "text": "thanks a lot for uh preparing the presentation for this track definitely uh excited to hear about the technology",
    "start": "1355940",
    "end": "1362600"
  },
  {
    "text": "and ability to see in Cache the graphql apis I also love the energy of the presentation it's just like the result",
    "start": "1362600",
    "end": "1369080"
  },
  {
    "text": "of Drive behind you uh behind your talk uh and hopefully you are we have saved a",
    "start": "1369080",
    "end": "1374480"
  },
  {
    "text": "little bit for the live q a uh I know it's uh it's getting late uh in Austria but yeah let's uh let's plan the the",
    "start": "1374480",
    "end": "1381620"
  },
  {
    "text": "next 24 uh the next 20 minutes uh chatting about like some of the more uh",
    "start": "1381620",
    "end": "1387440"
  },
  {
    "text": "nuances about your uh you talk about your technology and uh for the audience I encourage you to ask your questions in",
    "start": "1387440",
    "end": "1394520"
  },
  {
    "text": "the chat uh and uh Max uh will uh we'll do his best to answer them",
    "start": "1394520",
    "end": "1400700"
  },
  {
    "text": "thank you for having me I just wanted to mention that and uh I'm I hope the the energy level matched my excitement of",
    "start": "1400700",
    "end": "1406460"
  },
  {
    "text": "being at qcon today I am I am pumped to be here thank you so much for having me oh my pleasure Max",
    "start": "1406460",
    "end": "1412580"
  },
  {
    "text": "uh so yeah let's um you mentioned if you were interesting",
    "start": "1412580",
    "end": "1418340"
  },
  {
    "text": "um technical details uh but before we go into those um can you share some of the success",
    "start": "1418340",
    "end": "1425480"
  },
  {
    "text": "stories some of the real world numbers of uh from an actual apis in production that you you currently manage and help",
    "start": "1425480",
    "end": "1431960"
  },
  {
    "text": "to Cache what are the real world numbers and if you can share any specific examples in what domains those numbers",
    "start": "1431960",
    "end": "1437900"
  },
  {
    "text": "are from oh of course um actually in fact I'm going to look up to make sure that I say the exact correct numbers",
    "start": "1437900",
    "end": "1445100"
  },
  {
    "text": "um one of our customers one of our recent customers is italic.com which is an e-commerce retailer and they Pride",
    "start": "1445100",
    "end": "1451880"
  },
  {
    "text": "themselves on selling really high quality stuff that is completely unbranded so there's no italic logo on",
    "start": "1451880",
    "end": "1457100"
  },
  {
    "text": "anything it's all completely unbranded and they do it in the same um factories and at the same",
    "start": "1457100",
    "end": "1462620"
  },
  {
    "text": "manufacturers that other big brands are working on so you can buy like a Prada bag without the product logo for much",
    "start": "1462620",
    "end": "1469039"
  },
  {
    "text": "cheaper it's sort of the the point of italic and they're really worried about Black Friday coming up they had huge",
    "start": "1469039",
    "end": "1474919"
  },
  {
    "text": "traffic they had a huge traffic Spike last year and they really couldn't scale their server was apparently crashed",
    "start": "1474919",
    "end": "1480860"
  },
  {
    "text": "every few hours and so about a month or two ago they started thinking ahead again okay Black Friday is coming up how",
    "start": "1480860",
    "end": "1486740"
  },
  {
    "text": "can we solve this problem this year around and the other grass the end of the stack in front of their graphql API",
    "start": "1486740",
    "end": "1492500"
  },
  {
    "text": "and I'm reading this out because I want to make sure that I get the numbers right it reduced their overall server load by 61 database load by two orders",
    "start": "1492500",
    "end": "1500419"
  },
  {
    "text": "of magnitude and Page load Times by over one second and that's just one of the most recent",
    "start": "1500419",
    "end": "1505640"
  },
  {
    "text": "ones that uh that I know of the top of my head who've been really really successful with gravity and then we're",
    "start": "1505640",
    "end": "1510799"
  },
  {
    "text": "actually seeing um a lot more e-commerce companies signing up and putting us in",
    "start": "1510799",
    "end": "1516620"
  },
  {
    "text": "front of their graphical apis because for them one of them actually told us this was an italic but another customer",
    "start": "1516620",
    "end": "1522380"
  },
  {
    "text": "they said in a customer called milliseconds mean money right and for for e-commerce while they're not latency",
    "start": "1522380",
    "end": "1529520"
  },
  {
    "text": "critical they're very light latency sensitive right and the faster they can render their web pages the faster their",
    "start": "1529520",
    "end": "1534740"
  },
  {
    "text": "apis are the more money they will make that's a very strong correlation there and so to them our product really helps",
    "start": "1534740",
    "end": "1541400"
  },
  {
    "text": "scale but also make more money ultimately because we can really reduce the page load times across the globe",
    "start": "1541400",
    "end": "1547100"
  },
  {
    "text": "yeah actually I think it was Amazon back in 2009 ethical correctly who did the",
    "start": "1547100",
    "end": "1552500"
  },
  {
    "text": "first one of the first studies and mentioned the some of the impressive numbers of uh matching the milliseconds",
    "start": "1552500",
    "end": "1558200"
  },
  {
    "text": "delay on the e-commerce side to the revenue that they would generate in uh yeah or for shopping so definitely not",
    "start": "1558200",
    "end": "1565520"
  },
  {
    "text": "surprised the more e-commerce retailers jumping on on board there's a few studies like that Walmart",
    "start": "1565520",
    "end": "1572000"
  },
  {
    "text": "has done famously some Staples I think has done some Nike has done some um and practically everywhere the",
    "start": "1572000",
    "end": "1577880"
  },
  {
    "text": "outcome is the faster your website is the more money you make right and there's like a there's like a spike I",
    "start": "1577880",
    "end": "1583100"
  },
  {
    "text": "was recently talking with one of our other customers and and there's there's like a spike right like if you if you get faster from like 20 seconds to 10",
    "start": "1583100",
    "end": "1589340"
  },
  {
    "text": "seconds it's not gonna matter that much right like you're still so slow that dude your conversion Dropbox will just be massive but if you if you can get",
    "start": "1589340",
    "end": "1595640"
  },
  {
    "text": "from 10 or even five seconds down to three to one seconds right that's a huge difference",
    "start": "1595640",
    "end": "1600919"
  },
  {
    "text": "um and we really enable our customers to get to speeds even faster than that globally everywhere around the world",
    "start": "1600919",
    "end": "1606200"
  },
  {
    "text": "even though they usually only have their data centers in Virginia most of the time right a single Data Center used",
    "start": "1606200",
    "end": "1611480"
  },
  {
    "text": "East is sort of the standard setup that we see there and so that's really exciting for us because ultimately they",
    "start": "1611480",
    "end": "1616520"
  },
  {
    "text": "enable us and hopefully they make a lot more money than they would ever have to pay us awful yeah of the performance",
    "start": "1616520",
    "end": "1621679"
  },
  {
    "text": "improvements which is definitely makes sense so yeah let's dive a little bit more into the technical details uh so",
    "start": "1621679",
    "end": "1627200"
  },
  {
    "text": "you mentioned that um Authentication uh uh is generally challenged when you put the data from a",
    "start": "1627200",
    "end": "1634820"
  },
  {
    "text": "client to the shared infrastructure like a city and Edge um and the probably two questions like",
    "start": "1634820",
    "end": "1640279"
  },
  {
    "text": "first is uh how do you generally Define and what the recommendations you provide to the API authors like to categorize",
    "start": "1640279",
    "end": "1647179"
  },
  {
    "text": "the apis as authorized or generically shared uh and uh can you generally share",
    "start": "1647179",
    "end": "1654200"
  },
  {
    "text": "any more details uh into the internals of how it works absolutely so",
    "start": "1654200",
    "end": "1661039"
  },
  {
    "text": "what's interesting about graphql apis is that certain types or Fields might be authenticated but others really aren't",
    "start": "1661039",
    "end": "1666559"
  },
  {
    "text": "right maybe a blog post type is publicly available and every if the data is the same for everyone but then you might",
    "start": "1666559",
    "end": "1673100"
  },
  {
    "text": "have a current user query that fetches the currently authenticated user and that obviously has to be specific to the",
    "start": "1673100",
    "end": "1678620"
  },
  {
    "text": "authentication token that is present in the request um and essentially we as grad student",
    "start": "1678620",
    "end": "1683779"
  },
  {
    "text": "but I think every solution should do this allows you to specify okay the current user for example that's an authenticated query if that's in the",
    "start": "1683779",
    "end": "1689600"
  },
  {
    "text": "query then please cache this entire result that you've just gotten from the origin and cache it for every user",
    "start": "1689600",
    "end": "1695480"
  },
  {
    "text": "separately so that we don't share that data and then corollarially if only a blog post is in",
    "start": "1695480",
    "end": "1701720"
  },
  {
    "text": "the query then please cache it publicly right please make sure that if only the blog post is in there just cache it the",
    "start": "1701720",
    "end": "1707179"
  },
  {
    "text": "same for everyone no matter if they're authenticated or not now that actually that configuration aspect",
    "start": "1707179",
    "end": "1712940"
  },
  {
    "text": "of it of saying okay which fields and which types are specific to a user versus public actually has interesting",
    "start": "1712940",
    "end": "1718760"
  },
  {
    "text": "implications down the line because you with graphql you can query for many of these fields at the same time right you",
    "start": "1718760",
    "end": "1724640"
  },
  {
    "text": "can query for a blog post and the current user at the same time and so actually a lot of what our customers end",
    "start": "1724640",
    "end": "1730520"
  },
  {
    "text": "up doing right now is they manually end up sending two requests to increase their cash hit rate because otherwise if",
    "start": "1730520",
    "end": "1737179"
  },
  {
    "text": "you send both of these queries in the same HTTP request then you'll end up with a",
    "start": "1737179",
    "end": "1743120"
  },
  {
    "text": "very low cachet rate in the blog post and unnecessarily so because it you could have almost probably a 100 cash",
    "start": "1743120",
    "end": "1748880"
  },
  {
    "text": "rate on that right because suddenly every cash response has to be scoped to the user because it also contains the",
    "start": "1748880",
    "end": "1754700"
  },
  {
    "text": "current user so at the moment our customers manually end up splitting these usually into two HTTP requests and",
    "start": "1754700",
    "end": "1761539"
  },
  {
    "text": "sending authenticated requests separately from public requests however that's also something really interesting that we're thinking about because we at",
    "start": "1761539",
    "end": "1767840"
  },
  {
    "text": "the edge we can we can we can look at your configuration and we can go hold on the current user is specific to the user",
    "start": "1767840",
    "end": "1773120"
  },
  {
    "text": "right and the blog post is public so why don't we just split them automatically right like we can just go in and say hey",
    "start": "1773120",
    "end": "1779659"
  },
  {
    "text": "look we know that this part of the graphical tree is specific to the current user this part is public we're just going to split them at the agent to",
    "start": "1779659",
    "end": "1785779"
  },
  {
    "text": "two HTTP requests so you don't even have to worry about it and it's sort of an under the hood optimization from us to",
    "start": "1785779",
    "end": "1791179"
  },
  {
    "text": "make sure that you're getting the highest cash rate possible um so that's something we're thinking about we've so far been very",
    "start": "1791179",
    "end": "1797419"
  },
  {
    "text": "conservative in basically with people's graphql queries because that's what a danger lies so far we try to stay as",
    "start": "1797419",
    "end": "1804320"
  },
  {
    "text": "dumb as possible right we just take the entire query we cache the tech query no magic nothing can go wrong right like it",
    "start": "1804320",
    "end": "1810140"
  },
  {
    "text": "just works and now we're with the feedback from our customers we're starting to figure out okay where are",
    "start": "1810140",
    "end": "1815360"
  },
  {
    "text": "the areas and what are sort of the features that we can provide now that we have this sort of safe way of doing",
    "start": "1815360",
    "end": "1820399"
  },
  {
    "text": "things and where can we make it slightly less safe but maybe get you a much higher cash rate in return and that is definitely one of the areas that we're",
    "start": "1820399",
    "end": "1826760"
  },
  {
    "text": "very much thinking about yeah but one question so you mentioned that uh you were asked the users to specify which is",
    "start": "1826760",
    "end": "1833419"
  },
  {
    "text": "the public and which is a private API uh how is it declared uh what sort of uh",
    "start": "1833419",
    "end": "1838880"
  },
  {
    "text": "information that uh that it is a standard uh or is it something that's specific to a product or is it something",
    "start": "1838880",
    "end": "1845059"
  },
  {
    "text": "that could become like the part of the garage kills back so there's two different ways you can",
    "start": "1845059",
    "end": "1850399"
  },
  {
    "text": "specify this um the default ways that we have sort of a concept of rules which is very similar",
    "start": "1850399",
    "end": "1856880"
  },
  {
    "text": "to if you know cloudflare page rules I think Sergey just so I get back I'm back",
    "start": "1856880",
    "end": "1861919"
  },
  {
    "text": "sorry I had a hardware issue yeah you're all good you're all good I was just saying we have the concept of rules",
    "start": "1861919",
    "end": "1867740"
  },
  {
    "text": "which is very similar to if you use cloudflare before they have page rules um where essentially you can Define",
    "start": "1867740",
    "end": "1872899"
  },
  {
    "text": "rules and say if the query contains this type of field then set the cache configuration to that right",
    "start": "1872899",
    "end": "1879559"
  },
  {
    "text": "um and so you can create as many rules as you want and you can be like okay if it contains the current User it's authenticated if it contains the blog",
    "start": "1879559",
    "end": "1885020"
  },
  {
    "text": "post it's public and cache it for a year or whatever right like you can set any kind of configuration that way the so",
    "start": "1885020",
    "end": "1890480"
  },
  {
    "text": "that's specific to our product the other way you can do it is that we have um we respect the origin cache control",
    "start": "1890480",
    "end": "1897320"
  },
  {
    "text": "header and that's a setting you can enable or disable as well but many particularly in the node.js ecosystem",
    "start": "1897320",
    "end": "1903200"
  },
  {
    "text": "many graphql servers come with the ability to add annotations for caching",
    "start": "1903200",
    "end": "1909260"
  },
  {
    "text": "uh for for for cache control two types and Fields in your graphql schema so in",
    "start": "1909260",
    "end": "1914659"
  },
  {
    "text": "your graphql schema you can add things like the add cache control directive and say add cache control Max h900",
    "start": "1914659",
    "end": "1920659"
  },
  {
    "text": "and the graphical server then goes through the query figures out what are all the directors that are in there in the schema for all the types and Fields",
    "start": "1920659",
    "end": "1927020"
  },
  {
    "text": "in that query and computes the cache control header out of that and sends that back through to the response and",
    "start": "1927020",
    "end": "1932179"
  },
  {
    "text": "now we as grassly and we can look at that ahead and we can go okay you told us we should cache this for 100 seconds so we're going to Cache it for 900",
    "start": "1932179",
    "end": "1938000"
  },
  {
    "text": "seconds um so we also support that as a sort of enhancement now depending on your",
    "start": "1938000",
    "end": "1944299"
  },
  {
    "text": "graphql server implementation that doesn't quite have the same flexibility as our rule structure hence why we added the rule structure because we were like",
    "start": "1944299",
    "end": "1950059"
  },
  {
    "text": "okay some people are going to need more power than this but we also support essentially just a standard cache",
    "start": "1950059",
    "end": "1955220"
  },
  {
    "text": "control header syntax from your origin depending on uh what the query contains or doesn't contain",
    "start": "1955220",
    "end": "1960380"
  },
  {
    "text": "all right yeah sounds good yeah thanks for the detailed answer um yeah and uh another question about",
    "start": "1960380",
    "end": "1966799"
  },
  {
    "text": "the internals uh because you you mentioned how you invalidate the data and you talked about relationships between objects uh how do you invalidate",
    "start": "1966799",
    "end": "1974480"
  },
  {
    "text": "the relationships is it the does it work similarly or there are there any nuances that's actually a great question so what",
    "start": "1974480",
    "end": "1981020"
  },
  {
    "text": "we do is we essentially walk through the entire response right so we take whatever you send back from the origin",
    "start": "1981020",
    "end": "1987380"
  },
  {
    "text": "that contains the blog post the author maybe all of the comments and their authors and we figure out which objects",
    "start": "1987380",
    "end": "1993019"
  },
  {
    "text": "are in this response right so that might be a blog post a user that is the author a comment and then the author of the",
    "start": "1993019",
    "end": "1999320"
  },
  {
    "text": "comment might be another user and we tag the cache response with every single one of the objects that we see in the data",
    "start": "1999320",
    "end": "2005440"
  },
  {
    "text": "and then you can essentially ping this and say hey look the user with the id5 has changed and we can go through and we",
    "start": "2005440",
    "end": "2011320"
  },
  {
    "text": "can invalidate any cash query result that contains that specific object that specific user if that makes sense and so",
    "start": "2011320",
    "end": "2017620"
  },
  {
    "text": "that's how we don't even really have to be aware of relations right those are still defined in your graphql schema and",
    "start": "2017620",
    "end": "2023260"
  },
  {
    "text": "with your graphql queries but we can still invalidate them because you have to send them back through the response",
    "start": "2023260",
    "end": "2029500"
  },
  {
    "text": "okay yeah makes sense thanks a lot uh and yeah we have another question from the audience uh what kind of",
    "start": "2029500",
    "end": "2035679"
  },
  {
    "text": "observability tools uh I needed uh for the edge caching and uh What uh what",
    "start": "2035679",
    "end": "2041559"
  },
  {
    "text": "were your findings and learnings that you integrated into your product that is actually a really interesting question because that is another thing we're very",
    "start": "2041559",
    "end": "2047980"
  },
  {
    "text": "much thinking about right now we started out we realized very early on that now people are passing off the graphql",
    "start": "2047980",
    "end": "2053138"
  },
  {
    "text": "request through us we can provide analytics for people right and so we added graphical analytics to our system",
    "start": "2053139",
    "end": "2058780"
  },
  {
    "text": "where you can essentially see how many requests are you getting what is your cachet rates per time frame which",
    "start": "2058780",
    "end": "2064480"
  },
  {
    "text": "queries are you seeing which mutations are you seeing what are their individual performance metrics p50 P95 P99 what are",
    "start": "2064480",
    "end": "2070658"
  },
  {
    "text": "the individual cachet rates et cetera Etc right then we realized okay we have all of this data on your course but we",
    "start": "2070659",
    "end": "2076000"
  },
  {
    "text": "also have a lot of data on your errors because we're in front of your infrastructure we essentially see every single error that is sent back from your",
    "start": "2076000",
    "end": "2082000"
  },
  {
    "text": "API and so we added error tracking to our system right so we have performance monitoring and we have error tracking where we essentially you can very finely",
    "start": "2082000",
    "end": "2088960"
  },
  {
    "text": "click your alert right very similar to what you might be used to from a Sentry or a data dog or whatever and you can",
    "start": "2088960",
    "end": "2094000"
  },
  {
    "text": "say hey look if I see more than 50 graphical errors in a minute if I have a huge Spike probably something's going",
    "start": "2094000",
    "end": "2099520"
  },
  {
    "text": "wrong right I I I should probably be aware of that and so we can then send you an email it's like message of pager",
    "start": "2099520",
    "end": "2104560"
  },
  {
    "text": "2D triggered incident whatever you want and the same thing is true for graphql and HTTP errors",
    "start": "2104560",
    "end": "2111220"
  },
  {
    "text": "um so that's sort of the the analytics we provide now as we talk with more and more companies",
    "start": "2111220",
    "end": "2116740"
  },
  {
    "text": "that are using graphics and production we realized very quickly that caching is pretty scary right adding caching to",
    "start": "2116740",
    "end": "2122560"
  },
  {
    "text": "your stack comes with a lot of inherent risk of maybe the data isn't fresh anymore right how do you know what is",
    "start": "2122560",
    "end": "2128140"
  },
  {
    "text": "even in the cache right like how do you know that all the stuff is fresh um and so that's something we're very much thinking about right there we do",
    "start": "2128140",
    "end": "2134200"
  },
  {
    "text": "solve a big problem for a lot of people and so people are already using us but there's a lot of risk associated with",
    "start": "2134200",
    "end": "2139540"
  },
  {
    "text": "implementing caching and thus there's also a lot of hesitancy with implementing caching and we've been thinking about ways we could get rid of",
    "start": "2139540",
    "end": "2145720"
  },
  {
    "text": "that so stay tuned for that but we have plans to to work on more caching insights and give you a little bit more",
    "start": "2145720",
    "end": "2152020"
  },
  {
    "text": "um I don't know how to phrase this security I guess uh with your caching",
    "start": "2152020",
    "end": "2157540"
  },
  {
    "text": "that's good uh and yeah probably the uh the last question for for today uh what",
    "start": "2157540",
    "end": "2164020"
  },
  {
    "text": "are the cases when seeing Edge caching might not be a good idea you mentioned that uh",
    "start": "2164020",
    "end": "2169599"
  },
  {
    "text": "authentication is already one uh headwind uh but uh a special thinking",
    "start": "2169599",
    "end": "2175660"
  },
  {
    "text": "about uh invalidation and the hunger field 50 milliseconds delay which on one",
    "start": "2175660",
    "end": "2180820"
  },
  {
    "text": "side sounds fast but on the other side for use case like transactions that might not be that fast like are there",
    "start": "2180820",
    "end": "2187060"
  },
  {
    "text": "any more details and like what's your adrenal thinking guidance on this it definitely boils down to latency",
    "start": "2187060",
    "end": "2193660"
  },
  {
    "text": "critical things where we're talking about milliseconds or something you can't you can't catch those at the cdnh",
    "start": "2193660",
    "end": "2199359"
  },
  {
    "text": "that doesn't make any sense um and then it also only makes sense for very read heavy apis I have good friends",
    "start": "2199359",
    "end": "2205240"
  },
  {
    "text": "that work at Sentry right the error tracking service and they obviously they get billions of of Errors sent to them",
    "start": "2205240",
    "end": "2211480"
  },
  {
    "text": "but only a small percentage of them are ever looked at and so for them caching doesn't make any sense because their data would change way more frequently",
    "start": "2211480",
    "end": "2217780"
  },
  {
    "text": "than the cache it would ever be you know what I mean they would probably have a zero percent cash fit rate and so if you",
    "start": "2217780",
    "end": "2223300"
  },
  {
    "text": "have a very very write heavy API caching is probably not for you on the other hand if you have a very read heavy API",
    "start": "2223300",
    "end": "2228940"
  },
  {
    "text": "that is latency sensitive but maybe not latency critical I think that's really where craft City in comes in or age",
    "start": "2228940",
    "end": "2234220"
  },
  {
    "text": "caching generally comes in and this can be a very powerful tool to help you scale but also make your stack way more",
    "start": "2234220",
    "end": "2240400"
  },
  {
    "text": "performance across the globe yeah okay thank you Max",
    "start": "2240400",
    "end": "2246339"
  },
  {
    "text": "um yeah thanks again for the presentation I also want to quickly I mention that Max will also join us for",
    "start": "2246339",
    "end": "2251859"
  },
  {
    "text": "the discussion panel uh later today um and yeah thanks a lot Max for uh",
    "start": "2251859",
    "end": "2258040"
  },
  {
    "text": "going with us through the Q a uh we're going to have another a chance to have more informal discussion with Max uh in",
    "start": "2258040",
    "end": "2265300"
  },
  {
    "text": "the zoom hangout uh so you can see the link in the chat how to join",
    "start": "2265300",
    "end": "2271780"
  },
  {
    "text": "um uh how to uh uh uh how how to join the discussion there",
    "start": "2271780",
    "end": "2277900"
  },
  {
    "text": "are also links from the schedule page uh and I see there is one more question we won't be able to take it right now but",
    "start": "2277900",
    "end": "2283000"
  },
  {
    "text": "the hangout is actually a very good opportunity to talk more about it right Mark thank you again and uh thank",
    "start": "2283000",
    "end": "2289060"
  },
  {
    "text": "you for having Hangouts and see you later at the discussion panel",
    "start": "2289060",
    "end": "2294240"
  },
  {
    "text": "[Music]",
    "start": "2296650",
    "end": "2302939"
  }
]
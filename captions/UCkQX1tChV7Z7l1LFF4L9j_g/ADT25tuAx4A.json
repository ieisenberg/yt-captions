[
  {
    "start": "0",
    "end": "34000"
  },
  {
    "text": "thank you very much so as cover you said hello my name is David",
    "start": "3960",
    "end": "10219"
  },
  {
    "text": "I'm a software developer I live in Sydney Australia I'm also a bit of a fan",
    "start": "10219",
    "end": "16890"
  },
  {
    "text": "of go I've been privileged to be able to call go my full-time job for the last",
    "start": "16890",
    "end": "22890"
  },
  {
    "text": "six years also help organise go for con every year I've been involved in the",
    "start": "22890",
    "end": "28259"
  },
  {
    "text": "local Sydney Meetup and I travel a bit to talk and teach about go so this is going to be a",
    "start": "28259",
    "end": "37260"
  },
  {
    "start": "34000",
    "end": "74000"
  },
  {
    "text": "practical session it's going to be lots of live coding and demos so there's ample opportunity for things to go terribly terribly wrong so if you can't",
    "start": "37260",
    "end": "44520"
  },
  {
    "text": "see the screen you might want to move forward just to see my mistakes and today we're going to talk about the",
    "start": "44520",
    "end": "50490"
  },
  {
    "text": "techniques for writing high performance go we're going to focus on three areas",
    "start": "50490",
    "end": "55610"
  },
  {
    "text": "just start my timer three years in its presentation benchmarking performance",
    "start": "55610",
    "end": "60930"
  },
  {
    "text": "measurement and profiling and a little bit about memory management and the garbage collector and really the goal is",
    "start": "60930",
    "end": "67439"
  },
  {
    "text": "for you to take away tools and techniques that you can use to improve your own go programs alright let's jump",
    "start": "67439",
    "end": "75510"
  },
  {
    "start": "74000",
    "end": "111000"
  },
  {
    "text": "straight in so before you can begin to tune your application you need to",
    "start": "75510",
    "end": "81180"
  },
  {
    "text": "establish a reliable baseline to measure the impacts of your changes you need to know if you're making things better or",
    "start": "81180",
    "end": "88110"
  },
  {
    "text": "worse so in this section we're going to focus on how to construct some useful benchmarks using the go testing",
    "start": "88110",
    "end": "95310"
  },
  {
    "text": "framework and we're going to give a few practical tips for kind of like traps for young players along the way and",
    "start": "95310",
    "end": "102260"
  },
  {
    "text": "benchmarking and profiling are closely related so there will be a little bit of overlap but we'll talk more about",
    "start": "102260",
    "end": "107430"
  },
  {
    "text": "profiling in the following section there are a few ground rules for benchmarking",
    "start": "107430",
    "end": "113690"
  },
  {
    "text": "and they're mainly about getting a stable repeatable bent baseline first of",
    "start": "113690",
    "end": "120390"
  },
  {
    "text": "all the machines got to be idle this this seems obvious so that means profiling on shared Hardware may be",
    "start": "120390",
    "end": "126060"
  },
  {
    "text": "unlike the staging or dev server it's probably not a good idea if other people are using it similarly you know like",
    "start": "126060",
    "end": "133049"
  },
  {
    "text": "don't start a benchmark and then like watch YouTube in another browser in a browser tab or something like that as much as the hardware manufacturers",
    "start": "133049",
    "end": "139820"
  },
  {
    "text": "would like you to believe that cause independent isolated the reality is less true for that so really if you're",
    "start": "139820",
    "end": "146570"
  },
  {
    "text": "running your benchmark don't touch your laptop more importantly is power saving",
    "start": "146570",
    "end": "152210"
  },
  {
    "text": "and thermal scaling this is the this is the other side of intel's turbo boost and things like that while to abuse",
    "start": "152210",
    "end": "160460"
  },
  {
    "text": "basically takes advantage of thermal headroom in the processor and ramps up the clock speed Thermal scaling is the",
    "start": "160460",
    "end": "166820"
  },
  {
    "text": "opposite once the processor gets too hot not just the fan has got to come on but the actual clock rate goes down and you",
    "start": "166820",
    "end": "173720"
  },
  {
    "text": "can see that in your benchmarks initially the same code will start to run faster for a little bit until your",
    "start": "173720",
    "end": "179810"
  },
  {
    "text": "laptop gets really hot and then it'll get cold it will get slower probably below the original baseline and avoid",
    "start": "179810",
    "end": "186800"
  },
  {
    "text": "virtual machines and cloud hosting for the same RIP for the the same reasons",
    "start": "186800",
    "end": "192260"
  },
  {
    "text": "there they're usually too noisy to get consistent repeatable results if you can",
    "start": "192260",
    "end": "198380"
  },
  {
    "text": "afford it at several companies we've bought dedicated performance test hardware we've stuck it in a rack we've",
    "start": "198380",
    "end": "204560"
  },
  {
    "text": "turned off as much of the power management as we can and we set the thermal scaling to some kind of minimal baseline and we never update the",
    "start": "204560",
    "end": "212090"
  },
  {
    "text": "software in those machines now this is terrible advice from a security point of view but probably reasonable advice from",
    "start": "212090",
    "end": "217970"
  },
  {
    "text": "a performance point of view because if you update the software if you update the kernel you're no longer comparing",
    "start": "217970",
    "end": "224330"
  },
  {
    "text": "apples to apples and fundamentally for everybody have a before and after sample",
    "start": "224330",
    "end": "232010"
  },
  {
    "text": "and that generally means running them multiple times so I should have asked at",
    "start": "232010",
    "end": "238519"
  },
  {
    "text": "the beginning of this presentation who here has has used go I can't show hands excellent so keep them up if",
    "start": "238519",
    "end": "244910"
  },
  {
    "text": "you've written a test good keep them up if you've written a benchmark okay a few",
    "start": "244910",
    "end": "251090"
  },
  {
    "text": "few less than a written test writing a benchmark and writing a test are very similar in a test you're passing a",
    "start": "251090",
    "end": "257690"
  },
  {
    "text": "testing dot T in a benchmark you pass in a testing B and this little this little",
    "start": "257690",
    "end": "264410"
  },
  {
    "text": "benchmark function this loop runs you function in this case fib of 20",
    "start": "264410",
    "end": "269680"
  },
  {
    "text": "B dot n times what's the value of b dot n starts at 1 and if that benchmark",
    "start": "269680",
    "end": "278139"
  },
  {
    "text": "function completes in less than a second then the benchmark framework starts to ramp up the size of size of B dot in",
    "start": "278139",
    "end": "284350"
  },
  {
    "text": "follows a roughly you know 1 2 3 5 10 type progression but if but it can it",
    "start": "284350",
    "end": "291789"
  },
  {
    "text": "can skip some so as an example let's have a look how's that for size no and",
    "start": "291789",
    "end": "300190"
  },
  {
    "text": "see that a little bit bigger so on this",
    "start": "300190",
    "end": "305949"
  },
  {
    "text": "laptop on this day and this temperature at this altitude it takes a it's not a",
    "start": "305949",
    "end": "311410"
  },
  {
    "text": "joke um my benchmarks run significantly faster it's the coming into the summer in Australia and when I do this",
    "start": "311410",
    "end": "317050"
  },
  {
    "text": "presentation about six months ago I get about fourteen anisette forty microseconds now in the summer we're",
    "start": "317050",
    "end": "323139"
  },
  {
    "text": "getting fifty five milliseconds that's the difference of thermal scaling makes",
    "start": "323139",
    "end": "328319"
  },
  {
    "text": "so for this example we did thirty thousand iterations and average time of fifty four microseconds so a few other",
    "start": "330000",
    "end": "342099"
  },
  {
    "start": "340000",
    "end": "417000"
  },
  {
    "text": "kind of tips about about writing benchmarks when you get down below below",
    "start": "342099",
    "end": "348159"
  },
  {
    "text": "the microsecond mark like when you're down in the nanoseconds you're going to see some instability mainly because of",
    "start": "348159",
    "end": "354550"
  },
  {
    "text": "the relativistic effects of instruction reordering like good tree what your processor was doing before it got to",
    "start": "354550",
    "end": "359710"
  },
  {
    "text": "your code is going to affect the the observe runtime of that code and also",
    "start": "359710",
    "end": "365680"
  },
  {
    "text": "things like code alignment like littering recompiling your program may change the runtime only you know when",
    "start": "365680",
    "end": "372280"
  },
  {
    "text": "we're talking in nanoseconds so these are these are relatively small amounts of time at the other at the other end if",
    "start": "372280",
    "end": "379960"
  },
  {
    "text": "you have a benchmark that instead of taking microseconds or milliseconds you know it takes takes more than a second",
    "start": "379960",
    "end": "387550"
  },
  {
    "text": "or something like that you might want to run your benchmark for longer say 10 seconds just to get more sample so you",
    "start": "387550",
    "end": "393070"
  },
  {
    "text": "have a more reliable average and as a takeaway you shouldn't if you need to do",
    "start": "393070",
    "end": "400330"
  },
  {
    "text": "things like this you shouldn't let them be tribal knowledge like communicated like communicated in slack or like hidden in some wiki you should",
    "start": "400330",
    "end": "406930"
  },
  {
    "text": "codify them in a in a make file or whatever tool of your choice so that you",
    "start": "406930",
    "end": "412000"
  },
  {
    "text": "have I could make a bench target and everybody uses invokes the benchmarks in the same way so as I said for repeatable",
    "start": "412000",
    "end": "420880"
  },
  {
    "start": "417000",
    "end": "465000"
  },
  {
    "text": "results you should probably run your benchmark multiple times and it's very easy to do that with the count flag",
    "start": "420880",
    "end": "426730"
  },
  {
    "text": "let's do that example now so I'm just",
    "start": "426730",
    "end": "432910"
  },
  {
    "text": "going to run it ten times pipe the result into a text file which will become obvious in a second you can see",
    "start": "432910",
    "end": "439630"
  },
  {
    "text": "even now the numbers are changing slightly in in a wider workshops right I",
    "start": "439630",
    "end": "448930"
  },
  {
    "text": "talked about this more I can afford I have the time to run it longer and you can actually see the thermal cycle is",
    "start": "448930",
    "end": "454810"
  },
  {
    "text": "the process that heats up and then slows down so now we have our before sample we",
    "start": "454810",
    "end": "460750"
  },
  {
    "text": "have ten invocations of fib of twenty let's improve fib and try to do a",
    "start": "460750",
    "end": "469270"
  },
  {
    "start": "465000",
    "end": "537000"
  },
  {
    "text": "comparison",
    "start": "469270",
    "end": "471660"
  },
  {
    "text": "so at the moment we memorize the zero Fibonacci number",
    "start": "477910",
    "end": "484010"
  },
  {
    "text": "the first Fibonacci number we could improve this code just simply by just memorizing the second Fibonacci number",
    "start": "484010",
    "end": "490010"
  },
  {
    "text": "which is just someone yelled out the",
    "start": "490010",
    "end": "494440"
  },
  {
    "text": "second Fibonacci is to one if I have",
    "start": "495550",
    "end": "503900"
  },
  {
    "text": "more time there's actually a test we can talk we can talk about that but so I",
    "start": "503900",
    "end": "512229"
  },
  {
    "text": "pick on Fibonacci because it's a it's an easy recursive algorithm you can demonstrate significant significant",
    "start": "512230",
    "end": "517669"
  },
  {
    "text": "improvements so here just by memorizing the second second Fibonacci number we've",
    "start": "517670",
    "end": "523219"
  },
  {
    "text": "improved the performance how much we'll find out in a little bit so this is the",
    "start": "523220",
    "end": "529640"
  },
  {
    "text": "process you should be going through with all your benchmarking grab a nice solid before of a full result and I sort of",
    "start": "529640",
    "end": "535160"
  },
  {
    "text": "after result and then you can use a tool like Russ Russ Cox's bench stat which",
    "start": "535160",
    "end": "540590"
  },
  {
    "start": "537000",
    "end": "607000"
  },
  {
    "text": "does some nice statistical analysis on it",
    "start": "540590",
    "end": "544540"
  },
  {
    "text": "let me just okay and that is a pretty good run so",
    "start": "550460",
    "end": "559720"
  },
  {
    "text": "that the before sample has a variance of about one percent that's excellent the after sample variance about four",
    "start": "559720",
    "end": "565480"
  },
  {
    "text": "percent that's tolerable and we can see we've improved this this run time by about thirty seven percent it's got a",
    "start": "565480",
    "end": "573460"
  },
  {
    "text": "really good confidence value like P is virtually zero and all the samples both",
    "start": "573460",
    "end": "578800"
  },
  {
    "text": "the before and after that's their N equals 10 plus 10 would in that range because generally with you know",
    "start": "578800",
    "end": "586510"
  },
  {
    "text": "collocations and things like that one of the one of the very first runs of your benchmark will probably be well outside",
    "start": "586510",
    "end": "591970"
  },
  {
    "text": "that range and so it's not uncommon to see like comparing nine to ten so the benchmark framework takes care of just",
    "start": "591970",
    "end": "598300"
  },
  {
    "text": "removing those completely irrelevant outliers so that's the basic mechanics",
    "start": "598300",
    "end": "603430"
  },
  {
    "text": "of writing and analyzing benchmark there are a few other things that you might",
    "start": "603430",
    "end": "609880"
  },
  {
    "start": "607000",
    "end": "675000"
  },
  {
    "text": "want to do when writing a benchmark and one of them is you probably have a bunch",
    "start": "609880",
    "end": "615460"
  },
  {
    "text": "of setup you need to do like load some data off disk compute some tables a bunch of kind of setup which is",
    "start": "615460",
    "end": "621220"
  },
  {
    "text": "necessary to execute the function under test but you don't want that time to count against a sexual runtime so you",
    "start": "621220",
    "end": "628630"
  },
  {
    "text": "can use this reset timer function which basically just resets the clock back and then we go straight into the loop",
    "start": "628630",
    "end": "635850"
  },
  {
    "text": "similarly if you have some expensive set up logic to do per loop iteration which",
    "start": "635850",
    "end": "643030"
  },
  {
    "text": "might be a sign that your benchmark you're trying to benchmark something that it's too large like if it has too",
    "start": "643030",
    "end": "648190"
  },
  {
    "text": "many moving parts they all need to be reset on every iteration then you might",
    "start": "648190",
    "end": "654100"
  },
  {
    "text": "need to think about refactoring your benchmark but with that said there's quite a few cases where we do this",
    "start": "654100",
    "end": "659680"
  },
  {
    "text": "inside the standard library so it's by no means extraordinary and easiest way",
    "start": "659680",
    "end": "665380"
  },
  {
    "text": "is to you can use stop timer and then later on start timer to effectively pause the clock why you reset some reset",
    "start": "665380",
    "end": "673000"
  },
  {
    "text": "some data structures now there's been a lot of talk about garbage collection and",
    "start": "673000",
    "end": "679840"
  },
  {
    "start": "675000",
    "end": "714000"
  },
  {
    "text": "allocations and it's absolutely true that allocation count and the size are",
    "start": "679840",
    "end": "685030"
  },
  {
    "text": "strongly correlated with benchmark time like allocation cost time obviously the easiest so you want to",
    "start": "685030",
    "end": "692240"
  },
  {
    "text": "kind of you don't want to know just how fast your function runs you want to get an idea for how many allocations it's",
    "start": "692240",
    "end": "697640"
  },
  {
    "text": "making because that may be a clue to how you can improve its performance the testing framework gives us a mechanism",
    "start": "697640",
    "end": "703760"
  },
  {
    "text": "to do this using B dot report Aleks which basically records the number and",
    "start": "703760",
    "end": "709790"
  },
  {
    "text": "average size of the allocations for the function and so to look at that let's",
    "start": "709790",
    "end": "716690"
  },
  {
    "text": "try an example this is a kind of contrived maybe you think of like logging some some kind of logging",
    "start": "716690",
    "end": "723950"
  },
  {
    "text": "example we have a request ID the client address is a string and the current time",
    "start": "723950",
    "end": "729350"
  },
  {
    "text": "is a string what it actually does is not really important for this example and here are effectively four different ways",
    "start": "729350",
    "end": "736250"
  },
  {
    "text": "of constructing the string the first one just use good old string concatenation the second one we make a bytes buffer",
    "start": "736250",
    "end": "743540"
  },
  {
    "text": "and we use the F printf version in the font package to write into it and then",
    "start": "743540",
    "end": "749000"
  },
  {
    "text": "we turn that buffer back into a string this third example we use s printf which",
    "start": "749000",
    "end": "755440"
  },
  {
    "text": "externally you might think why it's kind of basically the same thing s printf is just doing what the example above is",
    "start": "755440",
    "end": "761630"
  },
  {
    "text": "doing for you and the last one is kind of like the the loop unrolled version we",
    "start": "761630",
    "end": "767390"
  },
  {
    "text": "make a buffer we know is the right size because we can control the size of request ID we know the time of you know",
    "start": "767390",
    "end": "774410"
  },
  {
    "text": "the size will form at a time we know the client IP address is fixed to a certain size so we can make a buffer of exactly",
    "start": "774410",
    "end": "781220"
  },
  {
    "text": "the right size we append the bytes of the request ID space the bytes of the",
    "start": "781220",
    "end": "787700"
  },
  {
    "text": "client address string another space and we really kind of push the boat out with the append format from the time package",
    "start": "787700",
    "end": "795980"
  },
  {
    "text": "which rather than returning time as a string it will write it into this pre-prepare buffer that you give it and",
    "start": "795980",
    "end": "803410"
  },
  {
    "text": "then finally we confer convert that buffer back to a string and what is somewhat off the end of the slide is a",
    "start": "803410",
    "end": "809750"
  },
  {
    "text": "benchmark for this now I would ask for a show of hands who thinks it's going to",
    "start": "809750",
    "end": "815450"
  },
  {
    "text": "who thinks which is going to be faster but in the interest of time let's just find out",
    "start": "815450",
    "end": "821320"
  },
  {
    "text": "so as I can catenate benchmark and we just make sure that fits on the screen F",
    "start": "822319",
    "end": "828060"
  },
  {
    "text": "printf s printf and lastly string conversion which is the kind of unrolled",
    "start": "828060",
    "end": "834689"
  },
  {
    "text": "version and not surprisingly the unrolled string converge version is both",
    "start": "834689",
    "end": "840959"
  },
  {
    "text": "the fastest in terms of both the time and the allocations you can see it only",
    "start": "840959",
    "end": "845999"
  },
  {
    "text": "has five allocations what's a little bit surprising is that there can the dumb",
    "start": "845999",
    "end": "851579"
  },
  {
    "text": "old string concatenation version which if you come from Java in the world of string builders you're told never ever ever do turns out not only to be the",
    "start": "851579",
    "end": "859379"
  },
  {
    "text": "second fastest but has the second fewest allocations so this kind of goes back to",
    "start": "859379",
    "end": "864559"
  },
  {
    "text": "one of my opening points which is you know maybe don't guess measure so that's",
    "start": "864559",
    "end": "872999"
  },
  {
    "text": "an example of benchmarking allocations as well as just wall time now this is",
    "start": "872999",
    "end": "880019"
  },
  {
    "start": "877000",
    "end": "959000"
  },
  {
    "text": "one of my favorite examples this came from an issue which was raised you know",
    "start": "880019",
    "end": "885420"
  },
  {
    "text": "18 months two years ago when we bought the GNU Compiler back-end online which",
    "start": "885420",
    "end": "890670"
  },
  {
    "text": "is much a much better code generator this is a population count function for",
    "start": "890670",
    "end": "896430"
  },
  {
    "text": "those who haven't used such a thing it basically returns the number of bits that are won in this UN 64 so the",
    "start": "896430",
    "end": "903959"
  },
  {
    "text": "population of one bits in this bit set and the bug was that",
    "start": "903959",
    "end": "909720"
  },
  {
    "text": "why sure I won't tell what the book is I'll show will run the benchmark and you figure out what the bug is yourself so",
    "start": "909720",
    "end": "915480"
  },
  {
    "text": "it's just got a regular benchmark for N equals o for each B dot n we're going to",
    "start": "915480",
    "end": "921329"
  },
  {
    "text": "run pop count just of n it doesn't really matter what the input is because we don't care what the output is so",
    "start": "921329",
    "end": "928170"
  },
  {
    "text": "let's run it screaming okay so it says that pop count",
    "start": "928170",
    "end": "939610"
  },
  {
    "text": "function can run in point three five a nanosecond this is a two point something",
    "start": "939610",
    "end": "945340"
  },
  {
    "text": "gigahertz CPU so that's kind of telling me that that instruction takes one clock",
    "start": "945340",
    "end": "952410"
  },
  {
    "text": "now I know it's fast but I don't I don't believe that number I think that that's kind of too fast so what actually",
    "start": "952410",
    "end": "960700"
  },
  {
    "start": "959000",
    "end": "1169000"
  },
  {
    "text": "happened pop count is what we call and go a leaf function which means it has no",
    "start": "960700",
    "end": "967360"
  },
  {
    "text": "it doesn't call anything else it is the it is the leaf on a call tree and",
    "start": "967360",
    "end": "972450"
  },
  {
    "text": "because of that it makes it a really good candidate to be inlined and by inlining it now the compiler can",
    "start": "972450",
    "end": "979210"
  },
  {
    "text": "see that bench pop count and pop count itself have no side effects",
    "start": "979210",
    "end": "986080"
  },
  {
    "text": "they make no change to their arguments passed in and they affect no global state so effectively it can be",
    "start": "986080",
    "end": "993279"
  },
  {
    "text": "eliminated you can't prove that I didn't do that work so I'm not going to do it because you can't prove it and this is",
    "start": "993279",
    "end": "1000330"
  },
  {
    "text": "effectively what the compiler sees and",
    "start": "1000330",
    "end": "1005390"
  },
  {
    "text": "Intel CPUs are really good at optimizing empty loops so that's effective what we've timed which about about one cycle",
    "start": "1005420",
    "end": "1013350"
  },
  {
    "text": "to do go around this loop doing nothing and the the reason I like this example",
    "start": "1013350",
    "end": "1019560"
  },
  {
    "text": "is that the same optimizations that we want to make our code fast the dead code",
    "start": "1019560",
    "end": "1025980"
  },
  {
    "text": "elimination constant folding loop hoisting all of these things which take",
    "start": "1025980",
    "end": "1031050"
  },
  {
    "text": "regular easy to read bog-standard code on the page and finally find the",
    "start": "1031050",
    "end": "1036510"
  },
  {
    "text": "inefficiencies and eliminate them are exactly the same optimizations that remove the extraneous bits of this",
    "start": "1036510",
    "end": "1042540"
  },
  {
    "text": "benchmark and made it run ridiculously fast so I put it to you that this is",
    "start": "1042540",
    "end": "1047970"
  },
  {
    "text": "actually a feature not a bug but having said that this benchmark is",
    "start": "1047970",
    "end": "1054830"
  },
  {
    "text": "useless so let's talk about how to fix it so",
    "start": "1054830",
    "end": "1064400"
  },
  {
    "text": "fundamentally the problem is that this benchmark and I'm sorry I think that's a little bit cut off from that screen this",
    "start": "1064400",
    "end": "1069710"
  },
  {
    "text": "benchmark has no observable behavior we don't use its return value so the first",
    "start": "1069710",
    "end": "1076280"
  },
  {
    "text": "thing is probably to do something like this so at least capture the result of",
    "start": "1076280",
    "end": "1089240"
  },
  {
    "text": "pop count just as a show of hands who thinks this is sufficient to make the",
    "start": "1089240",
    "end": "1095030"
  },
  {
    "text": "compiler happy not one single hand that's excellent because this is not sufficient because",
    "start": "1095030",
    "end": "1101650"
  },
  {
    "text": "our is still local to this call frame it still is not global state it you you",
    "start": "1101650",
    "end": "1107690"
  },
  {
    "text": "can't prove that you ran it because our ceases to exist when this function returns so we need to put the result",
    "start": "1107690",
    "end": "1114920"
  },
  {
    "text": "somewhere that the compiler cannot prove that somebody else can't see it and the",
    "start": "1114920",
    "end": "1120080"
  },
  {
    "text": "easiest place for that the best way to fix your benchmarks if you hit this situation is something like this we",
    "start": "1120080",
    "end": "1130160"
  },
  {
    "text": "don't need to store into capital our result every time around the loop just doing it at the end is sufficient but",
    "start": "1130160",
    "end": "1135860"
  },
  {
    "text": "because this is a public packaged variable there's no way for the compiler or any kind of code analysis to prove",
    "start": "1135860",
    "end": "1142880"
  },
  {
    "text": "that there isn't another package in this program which is observing that variable so we can no longer just eliminate this",
    "start": "1142880",
    "end": "1148580"
  },
  {
    "text": "as dead code because it's not it's actually changing some global state and",
    "start": "1148580",
    "end": "1153680"
  },
  {
    "text": "just to prove that for you we run it yeah it takes about 2 nanoseconds which",
    "start": "1153680",
    "end": "1159830"
  },
  {
    "text": "is still pretty fast because it's a pretty decent implementation but that's more what I would expect that's eight that's eight to ten clocks a lot of them",
    "start": "1159830",
    "end": "1167240"
  },
  {
    "text": "overlapped all right dunno can time",
    "start": "1167240",
    "end": "1174309"
  },
  {
    "text": "so testing be is useful for writing micro benchmarks micro benchmarks are",
    "start": "1174309",
    "end": "1182109"
  },
  {
    "text": "useful for tuning the performance of like a single hot piece of code we use them a lot through the standard library",
    "start": "1182109",
    "end": "1188919"
  },
  {
    "text": "because the standard libraries which is the code which everything else is built on so we want that to be efficient but",
    "start": "1188919",
    "end": "1194619"
  },
  {
    "text": "it's impractical and more importantly probably unreliable to construct a testing dot B for like your main domain",
    "start": "1194619",
    "end": "1201070"
  },
  {
    "text": "like like you can't you can't reliably do a micro benchmark for your entire application it just would just be too",
    "start": "1201070",
    "end": "1206950"
  },
  {
    "text": "variable so we should talk about other ways to profile whole programs rather",
    "start": "1206950",
    "end": "1212830"
  },
  {
    "text": "than just little pieces of them and in this section we're going to explore two",
    "start": "1212830",
    "end": "1218469"
  },
  {
    "text": "profiling tools built into the go runtime the first tool we'll talk about",
    "start": "1218469",
    "end": "1224589"
  },
  {
    "text": "is people off has anybody used people off here good good excellent paper off",
    "start": "1224589",
    "end": "1231039"
  },
  {
    "text": "has been in go since the Year dot since it since it came out and it consists of",
    "start": "1231039",
    "end": "1236379"
  },
  {
    "text": "two parts a piece in the runtime which is like the kind of runtime support and a piece run outside which is what we",
    "start": "1236379",
    "end": "1245289"
  },
  {
    "text": "called go tool paper off which is for analyzing the results that the runtime bit produces it talked a little bit",
    "start": "1245289",
    "end": "1253479"
  },
  {
    "start": "1251000",
    "end": "1292000"
  },
  {
    "text": "about the different types of profiling we have available the most commonly used one and what one that people probably",
    "start": "1253479",
    "end": "1259539"
  },
  {
    "text": "think of the most is CPU profiling when you turn on CPU profiling the runtime",
    "start": "1259539",
    "end": "1265359"
  },
  {
    "text": "itself will set up with the operating system a timer interrupt and every time that interrupts fires it just writes",
    "start": "1265359",
    "end": "1271149"
  },
  {
    "text": "down into into the profile the stack trace of all the currently running go routines",
    "start": "1271149",
    "end": "1277479"
  },
  {
    "text": "when the profile is complete it's pretty straightforward to just count up the number of times a particular stack trace",
    "start": "1277479",
    "end": "1283570"
  },
  {
    "text": "appears and then therefore that that stack trace that appears the most in the profile is the one that was using the",
    "start": "1283570",
    "end": "1289539"
  },
  {
    "text": "most CPU memory profiling records a",
    "start": "1289539",
    "end": "1295299"
  },
  {
    "start": "1292000",
    "end": "1360000"
  },
  {
    "text": "stack trace whenever a heap allocation is made so that is it records the stack",
    "start": "1295299",
    "end": "1300729"
  },
  {
    "text": "trace that led up to an allocation in this model stack allocations are",
    "start": "1300729",
    "end": "1306730"
  },
  {
    "text": "basically assumed to be free and they are not tracked in the memory profile now memory profiling kind of like CPU",
    "start": "1306730",
    "end": "1313690"
  },
  {
    "text": "profiling is sample based by default we sample every one out of every thousand",
    "start": "1313690",
    "end": "1318790"
  },
  {
    "text": "allocation when you turn this on you can if you like reduce that reduce that rate down to one out of every one a location",
    "start": "1318790",
    "end": "1326070"
  },
  {
    "text": "and something that I put here as a note is that because it's sample based and",
    "start": "1326070",
    "end": "1332350"
  },
  {
    "text": "because it tracks the allocation not the lifetime of of its use memory profiling",
    "start": "1332350",
    "end": "1339850"
  },
  {
    "text": "is not really gos equivalent of like a heap dump it I",
    "start": "1339850",
    "end": "1345480"
  },
  {
    "text": "we have many cases where people reach from every profiling like I have some memory issue in my program I don't know",
    "start": "1345480",
    "end": "1351280"
  },
  {
    "text": "why it's using so much memory fortunately the memory profile is not going to give you that information or",
    "start": "1351280",
    "end": "1356500"
  },
  {
    "text": "not directly in the same way that heap profile was would just quickly some",
    "start": "1356500",
    "end": "1361780"
  },
  {
    "start": "1360000",
    "end": "1455000"
  },
  {
    "text": "other supported profiles these are the more esoteric ones block profiling is similar to CPU profiling but it records",
    "start": "1361780",
    "end": "1368800"
  },
  {
    "text": "the amount of time a guru teen spends waiting to run not running so it can",
    "start": "1368800",
    "end": "1375220"
  },
  {
    "text": "show you where a large number of goroutines could make progress but were blocked for some resource and they show",
    "start": "1375220",
    "end": "1381100"
  },
  {
    "text": "you the resources they'll blocked on resources like that could be sending on",
    "start": "1381100",
    "end": "1386380"
  },
  {
    "text": "receiving on an unbuffered channel so if the if you're trying to send and the receivers not ready you have to you have",
    "start": "1386380",
    "end": "1391960"
  },
  {
    "text": "to block if the channel is full or if you're receiving from empty one similar situation and trying to lock something",
    "start": "1391960",
    "end": "1399580"
  },
  {
    "text": "like a sink mutex which is already locked by somebody else talking about",
    "start": "1399580",
    "end": "1404890"
  },
  {
    "text": "meu Texas we have a profile specifically for recording the stack traces of the holders of contended mutexes so you can",
    "start": "1404890",
    "end": "1412660"
  },
  {
    "text": "find the Cole path to a hot lock its recreation profile records the stack",
    "start": "1412660",
    "end": "1419290"
  },
  {
    "text": "traces that resulted in the creation of a new OS thread it's pretty much common",
    "start": "1419290",
    "end": "1425290"
  },
  {
    "text": "knowledge that go multiplexers many guru teens onto a small number of threads but there are instances where you need to",
    "start": "1425290",
    "end": "1431320"
  },
  {
    "text": "need to either take or create a thread to do some long blocking operation at syscall some sis calls",
    "start": "1431320",
    "end": "1437480"
  },
  {
    "text": "Sego things like that and so if you have a problem all of a sudden the number of threads in your application spikes this",
    "start": "1437480",
    "end": "1444140"
  },
  {
    "text": "is the profile for you really the takeaway is that on this slide these are quite specialized tools you shouldn't",
    "start": "1444140",
    "end": "1450470"
  },
  {
    "text": "reach for them straight away you should start with CPU memory usage speaking of",
    "start": "1450470",
    "end": "1456679"
  },
  {
    "start": "1455000",
    "end": "1494000"
  },
  {
    "text": "that profiling is not free it has a moderate but measurable impact on your",
    "start": "1456679",
    "end": "1462559"
  },
  {
    "text": "programs performance and especially when you do things like if you increase the the memory profile sample rate will",
    "start": "1462559",
    "end": "1469429"
  },
  {
    "text": "basically grind your application to a halt if you enable multiple profiles at",
    "start": "1469429",
    "end": "1474440"
  },
  {
    "text": "a time and this is kind of like a trap a trap for new players you say I have a problem with my application just give me all that I turn them all on I want to",
    "start": "1474440",
    "end": "1480890"
  },
  {
    "text": "have all the data and I will figure it out what you'll end up with is just a bunch of profiles that report the other",
    "start": "1480890",
    "end": "1486530"
  },
  {
    "text": "profiles that were running so the the simple answer is don't turn on more than",
    "start": "1486530",
    "end": "1491780"
  },
  {
    "text": "one at a time so the runtime the",
    "start": "1491780",
    "end": "1498500"
  },
  {
    "start": "1494000",
    "end": "1552000"
  },
  {
    "text": "interface to turning on to working with profiles is inside the runtime paper off",
    "start": "1498500",
    "end": "1503840"
  },
  {
    "text": "package it's quite low level and for various historical reasons the",
    "start": "1503840",
    "end": "1509360"
  },
  {
    "text": "interfaces between the different kinds of profiles that I talked about are not uniform a few years ago I got kind of",
    "start": "1509360",
    "end": "1516169"
  },
  {
    "text": "frustrated with this and I wrote as any engineer would a little wrapper that kind of solves this and this makes it",
    "start": "1516169",
    "end": "1524299"
  },
  {
    "text": "easier to profile your application it's just easy as just adding one line either",
    "start": "1524299",
    "end": "1531049"
  },
  {
    "text": "unconditionally at the top of Maine or maybe you want to put it behind a flag or something like that and then importing the package it also takes care",
    "start": "1531049",
    "end": "1538520"
  },
  {
    "text": "of things like capturing ctrl C so that profiles written out cleanly if you quit your application and also the kind of",
    "start": "1538520",
    "end": "1546110"
  },
  {
    "text": "API won't let you turn on more than one profile you turn one off the first one will be turn one on the first one will",
    "start": "1546110",
    "end": "1551270"
  },
  {
    "text": "be turned off so as a demo let's pick on everyone's favorite program go doc and",
    "start": "1551270",
    "end": "1557530"
  },
  {
    "start": "1552000",
    "end": "1633000"
  },
  {
    "text": "profile that",
    "start": "1557530",
    "end": "1560710"
  },
  {
    "text": "if your vim user everyone should be using fattier sans",
    "start": "1582970",
    "end": "1588570"
  },
  {
    "text": "vim go package you get going ports for free you get quit on compiled unsaved",
    "start": "1588570",
    "end": "1594430"
  },
  {
    "text": "for free all that stuff so now we've added a profile in it go doc literally",
    "start": "1594430",
    "end": "1601600"
  },
  {
    "text": "one line we know how a version go doc which records a CPU profile anytime we run it so that's it now go doc is doing",
    "start": "1601600",
    "end": "1618670"
  },
  {
    "text": "it standard HTTP thing if we cancel it there's a little handling and handler in",
    "start": "1618670",
    "end": "1623950"
  },
  {
    "text": "there that caches and writes out the profile before it quits and how do we",
    "start": "1623950",
    "end": "1629410"
  },
  {
    "text": "look at a profile have a look at profile fantastic it's on the next slide now",
    "start": "1629410",
    "end": "1634630"
  },
  {
    "start": "1633000",
    "end": "1783000"
  },
  {
    "text": "we've talked about it what it can measure let's look at the results we get one of the really nice things that have",
    "start": "1634630",
    "end": "1642100"
  },
  {
    "text": "been waiting for for a long time in go 1.9 you no longer need the binary and the profile as long as you have the",
    "start": "1642100",
    "end": "1648190"
  },
  {
    "text": "profile that is all you need this is going to make such a difference in in SRA and operations that you no longer",
    "start": "1648190",
    "end": "1654220"
  },
  {
    "text": "need to have the matching binary to a profile that was produced by a program if using 1.8 or earlier unfortunately",
    "start": "1654220",
    "end": "1661270"
  },
  {
    "text": "both just upgrade to 1.9 save yourself a lot of trouble so",
    "start": "1661270",
    "end": "1667590"
  },
  {
    "text": "use go tool paper off and pass to the profile and let's find out what the top",
    "start": "1670710",
    "end": "1676110"
  },
  {
    "text": "talkers are what are the top things that go doc was doing um all I see is run",
    "start": "1676110",
    "end": "1682860"
  },
  {
    "text": "time stuff so like some syscall a bunch of stuff which seems to be about the",
    "start": "1682860",
    "end": "1688320"
  },
  {
    "text": "garbage collector like there's no go dog code in here what is what is going on and when I talk to talk to programmers",
    "start": "1688320",
    "end": "1696060"
  },
  {
    "text": "and try and talk about profiling it seems quite that natural of people to use this interface but I find the",
    "start": "1696060",
    "end": "1702320"
  },
  {
    "text": "graphical interface to be much easier to interpret so this is the same profile",
    "start": "1702320",
    "end": "1708000"
  },
  {
    "text": "but as a graph now I'll try and make it larger for the screen here and this is",
    "start": "1708000",
    "end": "1714750"
  },
  {
    "text": "it's just called dot Cisco yep it absolutely is the top talker but Cisco doesn't call itself it's being called",
    "start": "1714750",
    "end": "1721080"
  },
  {
    "text": "from other stuff so let's trace back up Elster there's some reading directories",
    "start": "1721080",
    "end": "1726570"
  },
  {
    "text": "okay so now there's some stuff about reading directories and yeah we're still",
    "start": "1726570",
    "end": "1733740"
  },
  {
    "text": "reading looks like we're walking through directories now this gives you a little",
    "start": "1733740",
    "end": "1740040"
  },
  {
    "text": "bit of clue about what go doc is doing and let's not forget that this is the",
    "start": "1740040",
    "end": "1747690"
  },
  {
    "text": "Godot um the this is the version go dog",
    "start": "1747690",
    "end": "1753570"
  },
  {
    "text": "that you run on your laptop so you have your documentation so the first thing it does when it starts up is walk through your go path read all the files and you",
    "start": "1753570",
    "end": "1760410"
  },
  {
    "text": "know built build tables and stuff and this is exactly what we see here all of the time in the first couple of seconds",
    "start": "1760410",
    "end": "1766350"
  },
  {
    "text": "so the first you know nine or ten seconds is built walking the directory",
    "start": "1766350",
    "end": "1772530"
  },
  {
    "text": "and building building this file tree so",
    "start": "1772530",
    "end": "1777810"
  },
  {
    "text": "we talked about this is the graphic",
    "start": "1777810",
    "end": "1782870"
  },
  {
    "text": "so what we saw in people OFF kind of matches what we know it does",
    "start": "1784010",
    "end": "1790000"
  },
  {
    "text": "you can also very easily if you structure your benchmarks as testing be",
    "start": "1790000",
    "end": "1795890"
  },
  {
    "text": "benchmarks you can get profiling from them for free just past CPU profile and",
    "start": "1795890",
    "end": "1801980"
  },
  {
    "text": "profile block profile or all those ones so in this example here we're just",
    "start": "1801980",
    "end": "1808190"
  },
  {
    "text": "running the tests for the bytes package and capturing the CPU profile on the way out the the the tip here is the CPU",
    "start": "1808190",
    "end": "1819080"
  },
  {
    "text": "profile is going to run for the whole of that testing binary but we don't really want to like actually get profile data",
    "start": "1819080",
    "end": "1825200"
  },
  {
    "text": "for the tests we just want the benchmarks so hopefully everyone knows that run and bench reg X's so xxx",
    "start": "1825200",
    "end": "1834440"
  },
  {
    "text": "matches nothing in the bytes package and dot matches all the benchmarks so that basically says don't running the tests",
    "start": "1834440",
    "end": "1840590"
  },
  {
    "text": "just run the benchmark functions that match this reg X so that's the easy way",
    "start": "1840590",
    "end": "1845870"
  },
  {
    "text": "to get a sleepier profile for some or all of the benchmarks in your in your package alright pretty good ok the",
    "start": "1845870",
    "end": "1858350"
  },
  {
    "start": "1852000",
    "end": "1908000"
  },
  {
    "text": "second profiling tool I want to talk about is the execution tracer this was added in go 1.5 and remained under",
    "start": "1858350",
    "end": "1866049"
  },
  {
    "text": "documented for a little bit until it's there have been a lot of good presentations recently over the last",
    "start": "1866049",
    "end": "1871820"
  },
  {
    "text": "year 18 months an unlike sample-based profiling which we looked at before because the execution tracer is",
    "start": "1871820",
    "end": "1878720"
  },
  {
    "text": "integrated into the go runtime it doesn't just know what the program was doing like any sample-based profiling can do that it knows why it gets",
    "start": "1878720",
    "end": "1887179"
  },
  {
    "text": "nanosecond precision for go routine creation start/stop why they started",
    "start": "1887179",
    "end": "1892640"
  },
  {
    "text": "what started them what stopped them blocking and block unblocking events it's integrated into the network polar",
    "start": "1892640",
    "end": "1898790"
  },
  {
    "text": "so it knows when goroutines start and stop and interact with the network syscalls obviously and a lot of detail",
    "start": "1898790",
    "end": "1905990"
  },
  {
    "text": "about the garbage collector there are a few few Cabot's when using the trace",
    "start": "1905990",
    "end": "1913549"
  },
  {
    "start": "1908000",
    "end": "2322000"
  },
  {
    "text": "tool the visualization tool that we're going to see in the next slide actually reuses a lot of mechanisms",
    "start": "1913549",
    "end": "1919050"
  },
  {
    "text": "built into chrome it's actually part of the chrome Java JavaScript debugging stuff so unfortunately it's not going to",
    "start": "1919050",
    "end": "1925770"
  },
  {
    "text": "work on Firefox Safari ie sorry about that my life was significantly improved",
    "start": "1925770",
    "end": "1932190"
  },
  {
    "text": "using this tool when someone told me it supports WASD to move around you do not need to use the mouse and especially",
    "start": "1932190",
    "end": "1937980"
  },
  {
    "text": "because it's JavaScript there's no right right mouse click support anyway so WASD super important to know and question",
    "start": "1937980",
    "end": "1945810"
  },
  {
    "text": "mark just like all Google products will give you the list of hotkeys and the last one is that viewing traces can take",
    "start": "1945810",
    "end": "1952860"
  },
  {
    "text": "a lot of memory like seriously for gig is not going to cut it aching is probably the minimum and if you're",
    "start": "1952860",
    "end": "1959250"
  },
  {
    "text": "analyzing some very large traces because I don't forget it's going to load all this crap into your browser via JavaScript you you need a lot of memory",
    "start": "1959250",
    "end": "1967200"
  },
  {
    "text": "that's one of the downsides at the moment so let's do a demo let's pick on",
    "start": "1967200",
    "end": "1973140"
  },
  {
    "text": "go dock again and instead of doing a CPU profile we'll grab it we'll grab a trace profile",
    "start": "1973140",
    "end": "1979880"
  },
  {
    "text": "and we'll just run go doc you know that about the same amount of time so we want to want to see what it looks like we saw",
    "start": "1998509",
    "end": "2006200"
  },
  {
    "text": "a paper off type profile let's have a look an execution trace - now we have",
    "start": "2006200",
    "end": "2013490"
  },
  {
    "text": "the trace we use a slightly different tool go to trace and the profile and",
    "start": "2013490",
    "end": "2021620"
  },
  {
    "text": "because this is reusing kind of JavaScript stuff built into Chrome what's actually happening in the background is this slide is running a",
    "start": "2021620",
    "end": "2028519"
  },
  {
    "text": "little server - like a spoon feed data into into Chrome so what we see here is",
    "start": "2028519",
    "end": "2033769"
  },
  {
    "text": "that the trace has been split into two sections like there has its roughly a",
    "start": "2033769",
    "end": "2038899"
  },
  {
    "text": "limit on the number of events so the larger the longer your trace transform",
    "start": "2038899",
    "end": "2044149"
  },
  {
    "text": "the number of the more events that are in it is really the size of the splitting let let's pick this one that's",
    "start": "2044149",
    "end": "2053569"
  },
  {
    "text": "not very interesting at all well it is but for not reasons that are",
    "start": "2053569",
    "end": "2058720"
  },
  {
    "text": "worth going into now let's pick this so",
    "start": "2058720",
    "end": "2066158"
  },
  {
    "text": "we're going to be looking at the same visualization that we saw here but rather than looking at in terms of in",
    "start": "2066159",
    "end": "2072429"
  },
  {
    "text": "terms of course tax we're going to be looking at it as a function over time",
    "start": "2072429",
    "end": "2078460"
  },
  {
    "text": "just kind of make this big enough so",
    "start": "2078460",
    "end": "2086889"
  },
  {
    "text": "from the top to the bottom we have a list of a list of go routines and so at",
    "start": "2086890",
    "end": "2094330"
  },
  {
    "text": "this point this point in the execution we had for running go routines which matches the four processes here we had",
    "start": "2094330",
    "end": "2101140"
  },
  {
    "text": "about 54 that were runnable but hadn't been scheduled yet so quickly at a",
    "start": "2101140",
    "end": "2106540"
  },
  {
    "text": "glance you can see how many great things are running in this program the heap is the next one and it follows that",
    "start": "2106540",
    "end": "2112420"
  },
  {
    "text": "traditional stair step garbage collector pattern threads also show you the number",
    "start": "2112420",
    "end": "2119860"
  },
  {
    "text": "of operating system threads actually in use in your go program interestingly out in this error here we can see it kind of",
    "start": "2119860",
    "end": "2129520"
  },
  {
    "text": "like a sometimes the depending on when I run it sometimes the spike is much larger but this is this is spike in",
    "start": "2129520",
    "end": "2136600"
  },
  {
    "text": "running threads that are not actually in the go runtime they're off actually",
    "start": "2136600",
    "end": "2141640"
  },
  {
    "text": "doing thread stuff now you can see",
    "start": "2141640",
    "end": "2146860"
  },
  {
    "text": "highlighted here this next row is talking about garbage collection stuff that's when the garbage collector is actually running rather than being in",
    "start": "2146860",
    "end": "2152950"
  },
  {
    "text": "the background and the the these last",
    "start": "2152950",
    "end": "2159490"
  },
  {
    "text": "four columns represent the four processes or the props or the pieces you might think about them and there's",
    "start": "2159490",
    "end": "2164860"
  },
  {
    "text": "really two parts to this there's the kind of top part which is your code and",
    "start": "2164860",
    "end": "2170800"
  },
  {
    "text": "this is the bottom path which is usually runtime related stuff garbage collector",
    "start": "2170800",
    "end": "2176590"
  },
  {
    "text": "stuff perhaps even though like it's just call or something like that and we can",
    "start": "2176590",
    "end": "2182590"
  },
  {
    "text": "just keep zooming in here like that is 5 micro seconds between",
    "start": "2182590",
    "end": "2194040"
  },
  {
    "text": "that you cannot get that resolution with sample-based profiling you can click on",
    "start": "2194040",
    "end": "2199320"
  },
  {
    "text": "any one of the anyway these little boxes which represent a goroutine running and",
    "start": "2199320",
    "end": "2204570"
  },
  {
    "text": "stopping running and find out stuff about what it was doing so for example this this little piece of sweep here was",
    "start": "2204570",
    "end": "2212460"
  },
  {
    "text": "a bit of background work that the garbage collector asked the Goa team to do the garbage collector is not doesn't",
    "start": "2212460",
    "end": "2219900"
  },
  {
    "text": "have this kind of finite offer on state the more allocations run ahead of the",
    "start": "2219900",
    "end": "2225150"
  },
  {
    "text": "garbage collector the more work the allocator has to do and so we can see here this started with something to do",
    "start": "2225150",
    "end": "2230970"
  },
  {
    "text": "with building a directory tree we're doing some strings join in the runtime and because that went because that",
    "start": "2230970",
    "end": "2238740"
  },
  {
    "text": "touched the allocator the the garbage collector is in a mode where says we have to do a little bit of",
    "start": "2238740",
    "end": "2244770"
  },
  {
    "text": "work for me before you can go back to doing your own work and we can see all",
    "start": "2244770",
    "end": "2250320"
  },
  {
    "text": "this level of detail this is this is",
    "start": "2250320",
    "end": "2255870"
  },
  {
    "text": "invaluable so",
    "start": "2255870",
    "end": "2259580"
  },
  {
    "text": "so we just looked at we just looked at two ways of tracing kind of like a running program from start to finish but",
    "start": "2261190",
    "end": "2269240"
  },
  {
    "text": "this may not be this is useful but this may not be how you run your application for example you saw how much data was",
    "start": "2269240",
    "end": "2275180"
  },
  {
    "text": "generated you could you can imagine this would be infeasible to have this running in production from start running for",
    "start": "2275180",
    "end": "2281330"
  },
  {
    "text": "weeks until you do your next deploy so be really useful if we had a way of just",
    "start": "2281330",
    "end": "2286940"
  },
  {
    "text": "jumping in turning it on for 5 10 seconds grabbing a trace leaving turning it off and this is exactly what the net",
    "start": "2286940",
    "end": "2294320"
  },
  {
    "text": "HTTP people OFF package provides you this line here how many people have seen",
    "start": "2294320",
    "end": "2301220"
  },
  {
    "text": "have seen will used this line in their code yep good so when you import this",
    "start": "2301220",
    "end": "2306860"
  },
  {
    "text": "this is a somewhat questionable use of a side-effect import but it registers a few debugging handlers on the default",
    "start": "2306860",
    "end": "2313430"
  },
  {
    "text": "serve marks so basically just by importing this you get a little kind of debugging end point in your application",
    "start": "2313430",
    "end": "2321160"
  },
  {
    "start": "2322000",
    "end": "2682000"
  },
  {
    "text": "so to show this and to give another demonstration of the trace tool given",
    "start": "2322510",
    "end": "2328910"
  },
  {
    "text": "I'm in San Francisco I offer you Mandelbrot's as a micro service so let's",
    "start": "2328910",
    "end": "2337100"
  },
  {
    "text": "have a before we run it let's have a look at this program",
    "start": "2337100",
    "end": "2341020"
  },
  {
    "text": "so attribution definitely is well this is Franciscan boys matter brought",
    "start": "2344480",
    "end": "2350760"
  },
  {
    "text": "package which we collaborate on doing various demos with because it is a wonderful tool to demo with we can see",
    "start": "2350760",
    "end": "2356220"
  },
  {
    "text": "here we have the net h @ PP prof we're also going to register a handle func on",
    "start": "2356220",
    "end": "2362670"
  },
  {
    "text": "the amount abroad endpoint and then wrap that in something just to log the request just so it's useful to see the",
    "start": "2362670",
    "end": "2371100"
  },
  {
    "text": "man who brought endpoint itself we make a 512 by 512 image we create a weight",
    "start": "2371100",
    "end": "2378090"
  },
  {
    "text": "group with 512 entries in it and so we spawn a goroutine for each row in this",
    "start": "2378090",
    "end": "2384810"
  },
  {
    "text": "mount abroad we run them all together and then when they're all done we then",
    "start": "2384810",
    "end": "2390660"
  },
  {
    "text": "write it out as a PNG so when we get a request we're going to dedicate I'm just going to throw 512 goroutines at this at",
    "start": "2390660",
    "end": "2398430"
  },
  {
    "text": "this problem do it as quick as we can send the result back that's running when",
    "start": "2398430",
    "end": "2408330"
  },
  {
    "text": "you when you hit it just get this matter brought the size 512 512 was deliberately chosen because it takes a",
    "start": "2408330",
    "end": "2414830"
  },
  {
    "text": "moderate amount of time on this laptop about about 200 milliseconds so what we",
    "start": "2414830",
    "end": "2422130"
  },
  {
    "text": "want to do is you want to trace this program while it's running now because I would need three hands and two screens",
    "start": "2422130",
    "end": "2428310"
  },
  {
    "text": "rather than trying to like alt tab and stuff like that I'm just gonna run a",
    "start": "2428310",
    "end": "2434120"
  },
  {
    "text": "kind of a B style HTTP tester this was written by Jana Birju Dogen it's called",
    "start": "2434120",
    "end": "2441390"
  },
  {
    "text": "Hey and the reason I choose it is that it supports this mode where you can say send one per second don't just send one",
    "start": "2441390",
    "end": "2447360"
  },
  {
    "text": "at a time but send one per second kind of QPS so if we've run that see now it's",
    "start": "2447360",
    "end": "2455610"
  },
  {
    "text": "just issuing so now great now the application is doing some stuff we can grab a trace and",
    "start": "2455610",
    "end": "2462030"
  },
  {
    "text": "actually catch it doing stuff how do we grab a trace",
    "start": "2462030",
    "end": "2468250"
  },
  {
    "text": "just good old Co now cuz we've said",
    "start": "2468250",
    "end": "2473890"
  },
  {
    "text": "seconds equals five this is going to pause for five seconds and see that request an end point there anyway so now",
    "start": "2473890",
    "end": "2486160"
  },
  {
    "text": "now so now we have a trace of a running application let's have a look at it it's",
    "start": "2486160",
    "end": "2495220"
  },
  {
    "text": "obviously a bit smaller so there's only one one trace there it's not split over multiple ones and when we look at it we",
    "start": "2495220",
    "end": "2502930"
  },
  {
    "text": "can kind of see that these these kind of clusters of activity line up with what we expected like like we're issuing one",
    "start": "2502930",
    "end": "2508600"
  },
  {
    "text": "requests per second it takes about 200 milli so one second two seconds three",
    "start": "2508600",
    "end": "2514090"
  },
  {
    "text": "seconds and these are probably in the range of 372 that's about that's about",
    "start": "2514090",
    "end": "2521110"
  },
  {
    "text": "what we expect I don't have a version of this where I push the server into overload and we kind of look at the",
    "start": "2521110",
    "end": "2527050"
  },
  {
    "text": "behavior of that but this is a really good way of analyzing some of the results that we see so just before the",
    "start": "2527050",
    "end": "2534610"
  },
  {
    "text": "request comes in there nothing no go routines running it's as soon as the",
    "start": "2534610",
    "end": "2540040"
  },
  {
    "text": "request comes in we see it spiked up to like four hundred sixty-five hundred so that's obviously creating all those go routines and then you can see the CPU",
    "start": "2540040",
    "end": "2547120"
  },
  {
    "text": "getting very busy we just go routines running the Mandelbrot function as it",
    "start": "2547120",
    "end": "2552940"
  },
  {
    "text": "slowly chews through them all and then the program moves into the second phase where it seems to be allocating more",
    "start": "2552940",
    "end": "2558910"
  },
  {
    "text": "memory because the the heap is going up and that corresponds with the that",
    "start": "2558910",
    "end": "2564700"
  },
  {
    "text": "corresponds very closely with the writing out of the PNG and we can tell that because you can click on it we can",
    "start": "2564700",
    "end": "2572110"
  },
  {
    "text": "see down here handle function matter brought in code so definitely this bit which is allocating memory is running",
    "start": "2572110",
    "end": "2581410"
  },
  {
    "text": "the PNG compressor now one other thing",
    "start": "2581410",
    "end": "2587560"
  },
  {
    "text": "if I can just find it I'm looking for there it is there it is looking for this",
    "start": "2587560",
    "end": "2595110"
  },
  {
    "text": "this is on the network line this is the record of the packet coming in the HTTP requests coming in",
    "start": "2595110",
    "end": "2601420"
  },
  {
    "text": "and not only can we identify that but we can say what did you do afterwards so if",
    "start": "2601420",
    "end": "2606940"
  },
  {
    "text": "we click on unblock it will create this little arrow here sorry for jumping",
    "start": "2606940",
    "end": "2612700"
  },
  {
    "text": "around but we can see here that this network request directly resulted in this go routine waking up and this girl",
    "start": "2612700",
    "end": "2619780"
  },
  {
    "text": "routine is I'll see the surf HTTP server HTTP our Mandelbrot one so then as we go",
    "start": "2619780",
    "end": "2627700"
  },
  {
    "text": "across here all of these go routines their incoming flow is this go statement",
    "start": "2627700",
    "end": "2635770"
  },
  {
    "text": "so you can trace the you can trace a request both in time and also how it",
    "start": "2635770",
    "end": "2643090"
  },
  {
    "text": "interacts so this is obviously our all",
    "start": "2643090",
    "end": "2648820"
  },
  {
    "text": "these errors here are all the ghost statements firing off these go routines as we see there their number starts to",
    "start": "2648820",
    "end": "2655180"
  },
  {
    "text": "shoot up and then that's just slowly processing them working its way down and if we go to the other end we're now back",
    "start": "2655180",
    "end": "2663370"
  },
  {
    "text": "in they should be serving we can say what unblocked you what made you wake up and what made it wake up was the wait",
    "start": "2663370",
    "end": "2670870"
  },
  {
    "text": "group being done so there's a tremendous amount of menace amount of detail that I really have no more time to go into",
    "start": "2670870",
    "end": "2678480"
  },
  {
    "text": "available in the trace tool I think it is just amazing here are a whole bunch",
    "start": "2678480",
    "end": "2684070"
  },
  {
    "start": "2682000",
    "end": "2693000"
  },
  {
    "text": "of links this will be online straight away so you don't write them down now of more talks about the execution tracer it",
    "start": "2684070",
    "end": "2691000"
  },
  {
    "text": "is a wonderful tool so with the time that I don't have left I want to spend a",
    "start": "2691000",
    "end": "2697030"
  },
  {
    "start": "2693000",
    "end": "2803000"
  },
  {
    "text": "little I want to talk a little bit about memory management and garbage collection goers unashamedly a garbage collected",
    "start": "2697030",
    "end": "2704740"
  },
  {
    "text": "language this is a design principle it's not something that's going to change at this point and because it's a garbage",
    "start": "2704740",
    "end": "2711220"
  },
  {
    "text": "collected language the performance of your program is often determined by your interaction with the garbage collector",
    "start": "2711220",
    "end": "2717000"
  },
  {
    "text": "um from the worldview of garbage collector",
    "start": "2717000",
    "end": "2723080"
  },
  {
    "text": "designers and authors their worldview is that they want to present to the program",
    "start": "2723080",
    "end": "2728100"
  },
  {
    "text": "of this illusion of an infinite amount of memory they want to free you from having to think about freeing memory by",
    "start": "2728100",
    "end": "2734400"
  },
  {
    "text": "by promising you this world that you can allocate an infinite amount of memory",
    "start": "2734400",
    "end": "2739430"
  },
  {
    "text": "because they because behind the scenes when you lose track of that memory they",
    "start": "2739430",
    "end": "2744480"
  },
  {
    "text": "can clear it up and you can't prove that they did that so you might disagree with this statement but it's important to",
    "start": "2744480",
    "end": "2751110"
  },
  {
    "text": "understand it from the the way that this is how the garbage collector designers think about it and more importantly from",
    "start": "2751110",
    "end": "2757350"
  },
  {
    "text": "Google's experience with running their production systems has come and talked",
    "start": "2757350",
    "end": "2763500"
  },
  {
    "text": "about this morning the GC favours lower latency over maximum throughput it",
    "start": "2763500",
    "end": "2769230"
  },
  {
    "text": "really targets driving the latency figures down and their results over the last four or five releases ago I've just",
    "start": "2769230",
    "end": "2775620"
  },
  {
    "text": "been to drive that latency down drive through the pores outliers down into the into the microseconds range because",
    "start": "2775620",
    "end": "2783300"
  },
  {
    "text": "fundamentally an application which has stopped stopped because we're GBC pores is no different to an applications",
    "start": "2783300",
    "end": "2790140"
  },
  {
    "text": "crashed from the point of view of suddenly trying to send it work so if you can reduce that if you can reduce",
    "start": "2790140",
    "end": "2795360"
  },
  {
    "text": "the latency you increase that the total amount of capacity you have to process things now I want to give you the super",
    "start": "2795360",
    "end": "2806250"
  },
  {
    "text": "simple way to measure the activity of the garbage collector and that is this",
    "start": "2806250",
    "end": "2811730"
  },
  {
    "text": "GC trace equals one flag this turns these statistics are always being collected but they're normally",
    "start": "2811730",
    "end": "2818040"
  },
  {
    "text": "suppressed so it costs you nothing to turn on this this profiling so again we",
    "start": "2818040",
    "end": "2823980"
  },
  {
    "text": "pick on go doc we run it with this this",
    "start": "2823980",
    "end": "2829110"
  },
  {
    "text": "flag enabled so now it's going to print out every time we do a garbage collection and this matches what we expected before we saw it does a lot of",
    "start": "2829110",
    "end": "2835200"
  },
  {
    "text": "work reading reading and building tables and things like that and then into this mode were just quiets down and waits for",
    "start": "2835200",
    "end": "2840870"
  },
  {
    "text": "requests and now obviously everyone's application",
    "start": "2840870",
    "end": "2847800"
  },
  {
    "text": "is going to be different but that this is like like the when I arrive at a",
    "start": "2847800",
    "end": "2853950"
  },
  {
    "text": "performance problem I just turn on turn on this flag and I get an instant thing like here's this program bound on",
    "start": "2853950",
    "end": "2860160"
  },
  {
    "text": "allocations or is a bound on something else if this is just spewing off the screen without end it's pretty pretty",
    "start": "2860160",
    "end": "2866820"
  },
  {
    "text": "clear they haven't got a handle on their allocations okay the garbage collector",
    "start": "2866820",
    "end": "2875460"
  },
  {
    "text": "provides you exactly one variable to tune its operation which is effectively the size of how much should the heap",
    "start": "2875460",
    "end": "2881490"
  },
  {
    "text": "grow the default value is 100 which means it will double every time it if it",
    "start": "2881490",
    "end": "2886620"
  },
  {
    "text": "needs to grow it will double your double itself if you set that value higher than 100 it will grow larger every time it",
    "start": "2886620",
    "end": "2893040"
  },
  {
    "text": "needs to with with the view that hopefully this will reduce the number of times you have to grow we set that value",
    "start": "2893040",
    "end": "2898950"
  },
  {
    "text": "smaller it will cause the garbage collector to run more frequently maybe",
    "start": "2898950",
    "end": "2905130"
  },
  {
    "text": "keep the heap the heap under control and maybe use less memory there's no real I",
    "start": "2905130",
    "end": "2910560"
  },
  {
    "text": "mean 100 is the default but really it's up to you to profile and choose the best",
    "start": "2910560",
    "end": "2915720"
  },
  {
    "text": "value for your application I think I'll",
    "start": "2915720",
    "end": "2921150"
  },
  {
    "start": "2919000",
    "end": "2995000"
  },
  {
    "text": "move to some conclusions so I have a little bit of time for questions of this",
    "start": "2921150",
    "end": "2926220"
  },
  {
    "text": "possible and I want to end with some concluding remarks which is start with",
    "start": "2926220",
    "end": "2931590"
  },
  {
    "text": "the simplest possible code I measure profile your code to identify",
    "start": "2931590",
    "end": "2937260"
  },
  {
    "text": "bottlenecks like maybe maybe it's fine maybe there are no bollocks but don't guess don't don't say right I've written",
    "start": "2937260",
    "end": "2943860"
  },
  {
    "text": "some code now I need to find now I need to find all the performance problems with it so yeah if the performance is",
    "start": "2943860",
    "end": "2949230"
  },
  {
    "text": "good stop you don't need to do anything you don't need to optimize everything you should have both a upper response",
    "start": "2949230",
    "end": "2956490"
  },
  {
    "text": "time and a lower response time like this probably little value going below 100 milliseconds or 50 milliseconds to a",
    "start": "2956490",
    "end": "2962340"
  },
  {
    "text": "webstar request humans can't really see that see lower than that and importantly",
    "start": "2962340",
    "end": "2967920"
  },
  {
    "text": "as your application grows your traffic profile is going to evolve people are going to use your application in",
    "start": "2967920",
    "end": "2973920"
  },
  {
    "text": "different ways as new features are added as new kind of social circumstances change that make the music so your performance hotspots are going",
    "start": "2973920",
    "end": "2980519"
  },
  {
    "text": "to move and when they do don't leave that complex hyper optimized code there",
    "start": "2980519",
    "end": "2986729"
  },
  {
    "text": "this is an opportunity this is no longer a need to spend complexity debt in this place rewrite it to something simpler",
    "start": "2986729",
    "end": "2995119"
  },
  {
    "text": "and speaking about simple try and always write the simplest code that you can we",
    "start": "2995119",
    "end": "3000410"
  },
  {
    "text": "saw in the example with the string concatenation in contrary to perhaps what some of you some of you may have",
    "start": "3000410",
    "end": "3006710"
  },
  {
    "text": "thought and certainly I thought when I first did this example um it didn't turn out to be that bad so write the simplest",
    "start": "3006710",
    "end": "3013579"
  },
  {
    "text": "code you can the go compiler is optimized for I said normal here mainly",
    "start": "3013579",
    "end": "3018890"
  },
  {
    "text": "because I don't like the word idiomatic I think that we kind of use that as this your belief shorter code is faster code",
    "start": "3018890",
    "end": "3025989"
  },
  {
    "text": "like fundamentally less less code code will less code on the page will optimize",
    "start": "3025989",
    "end": "3031460"
  },
  {
    "text": "to a smaller program which will probably run faster go isn't C++ it's not designed to unroll all those complex",
    "start": "3031460",
    "end": "3038119"
  },
  {
    "text": "templated abstractions um and yet finally pay attentions to allocations",
    "start": "3038119",
    "end": "3044390"
  },
  {
    "text": "and try to try to avoid them where necessary because allocations are really",
    "start": "3044390",
    "end": "3050079"
  },
  {
    "text": "going to in terms of their pressure on the garbage collector go to determine probably the scalability of your",
    "start": "3050079",
    "end": "3055700"
  },
  {
    "text": "application and I want to I want to close with two quotes the first one by",
    "start": "3055700",
    "end": "3062599"
  },
  {
    "text": "Russ codes is I can make things very fast if they don't have to be correct and robbers always reliable readable",
    "start": "3062599",
    "end": "3071059"
  },
  {
    "text": "means reliable and I mentioned these because I've talked all about performance and nothing about any other",
    "start": "3071059",
    "end": "3077269"
  },
  {
    "text": "aspects of coding in this talk but performance and reliability are equally important I see little value in making a",
    "start": "3077269",
    "end": "3084680"
  },
  {
    "text": "really fast server that is touchy and unreliable and panics and deadlocks and out of memories on a regular basis like",
    "start": "3084680",
    "end": "3091579"
  },
  {
    "text": "I don't think anyone here is building f1 cars they have to race for you know 100",
    "start": "3091579",
    "end": "3098210"
  },
  {
    "text": "laps and it doesn't matter if you have to completely rebuild the engine you're writing production software that has to be reliable over the long term so please",
    "start": "3098210",
    "end": "3105619"
  },
  {
    "text": "don't trade performance for reliability thank you very much",
    "start": "3105619",
    "end": "3110660"
  },
  {
    "text": "[Applause]",
    "start": "3110660",
    "end": "3114940"
  }
]
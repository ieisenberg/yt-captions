[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "so good morning welcome to my talk my name is Alan Wayne and I'm with the",
    "start": "4300",
    "end": "9400"
  },
  {
    "text": "Netflix real-time data infrastructure team so today my talk will be focusing",
    "start": "9400",
    "end": "15490"
  },
  {
    "text": "on external monitoring and the tracing system that we have developed in Netflix",
    "start": "15490",
    "end": "22470"
  },
  {
    "text": "to improve our production readiness for our streaming data infrastructure so",
    "start": "22470",
    "end": "31419"
  },
  {
    "start": "30000",
    "end": "30000"
  },
  {
    "text": "today when I look back one thing strikes me is that the tools that we have",
    "start": "31419",
    "end": "38019"
  },
  {
    "text": "developed share one common theme and that is we provide powerful observations",
    "start": "38019",
    "end": "45809"
  },
  {
    "text": "made from outside of our core system so you may be wondering what's so special",
    "start": "45809",
    "end": "53230"
  },
  {
    "text": "about observing from outside well let me",
    "start": "53230",
    "end": "58539"
  },
  {
    "text": "first talk about a situation then they sound familiar to many of you so you",
    "start": "58539",
    "end": "64420"
  },
  {
    "text": "wake up at night due to a peter duty call and you realize that the reason",
    "start": "64420",
    "end": "70630"
  },
  {
    "text": "that you are waking up it's just because of the latency spike on one of your dependency service so you",
    "start": "70630",
    "end": "80230"
  },
  {
    "text": "keep wondering why the guys who are responsible for that service are not the first one to wake up so that they can",
    "start": "80230",
    "end": "87220"
  },
  {
    "text": "fix their issue and I can have a good night of sleep well the truth is they",
    "start": "87220",
    "end": "94240"
  },
  {
    "text": "may not have the same insight as you do their dashboard may looks perfectly",
    "start": "94240",
    "end": "101950"
  },
  {
    "text": "normal but it doesn't matter right in a distributed system the lightness of the",
    "start": "101950",
    "end": "109870"
  },
  {
    "text": "service totally depends on the observations made from outside so here's",
    "start": "109870",
    "end": "117580"
  },
  {
    "start": "116000",
    "end": "116000"
  },
  {
    "text": "another example so this is how the first",
    "start": "117580",
    "end": "122860"
  },
  {
    "text": "finding of blackhole was confirmed so black hole as named Stan's is",
    "start": "122860",
    "end": "130950"
  },
  {
    "text": "invisible so in order for scientists to find a black hole they have to",
    "start": "130950",
    "end": "136690"
  },
  {
    "text": "observe objects around it so in this case scientists found a star called",
    "start": "136690",
    "end": "145180"
  },
  {
    "text": "Cygnus x1 and there's one interesting fact about this star so it changes color",
    "start": "145180",
    "end": "152590"
  },
  {
    "text": "from red to blue and blue to red periodically so if used to remember",
    "start": "152590",
    "end": "160240"
  },
  {
    "text": "physics that actually matches the description of Doppler effect so when",
    "start": "160240",
    "end": "166270"
  },
  {
    "text": "the Conte when the object comes towards you and the object move away from you",
    "start": "166270",
    "end": "171400"
  },
  {
    "text": "its wavelength will change so this star",
    "start": "171400",
    "end": "180420"
  },
  {
    "text": "Cygnus x1 must be moving towards Earth and moving away from the earth",
    "start": "180420",
    "end": "186570"
  },
  {
    "text": "periodically a natural explanation of",
    "start": "186570",
    "end": "191800"
  },
  {
    "text": "that behavior is that is to actually circle in something right so what is the",
    "start": "191800",
    "end": "199270"
  },
  {
    "text": "circling it is something invisible and scientists was able to calculate the",
    "start": "199270",
    "end": "205989"
  },
  {
    "text": "mass of this invisible object given the location of the star and the math and",
    "start": "205989",
    "end": "213340"
  },
  {
    "text": "the mass actually matches the criteria of a black hole so this is how the",
    "start": "213340",
    "end": "220930"
  },
  {
    "text": "conclusion was made that this invisible object was probably a black hole so this",
    "start": "220930",
    "end": "228880"
  },
  {
    "text": "story tells us how powerful external observations is and I will argue that",
    "start": "228880",
    "end": "235150"
  },
  {
    "text": "this might be the only way for you to find something invisible in your system",
    "start": "235150",
    "end": "242459"
  },
  {
    "start": "242000",
    "end": "242000"
  },
  {
    "text": "and next I will share our vision to production readiness so our vision maps",
    "start": "242459",
    "end": "251140"
  },
  {
    "text": "into four levels of satisfactions so you start with the basics and once you",
    "start": "251140",
    "end": "258040"
  },
  {
    "text": "satisfy your basic needs you start to go up and for more advanced needs so at the",
    "start": "258040",
    "end": "266050"
  },
  {
    "text": "bottom we have observability so you should have clear insights to",
    "start": "266050",
    "end": "272139"
  },
  {
    "text": "your product and you should share your insights with your customers to earn",
    "start": "272139",
    "end": "277180"
  },
  {
    "text": "their trust without observe it here nothing works",
    "start": "277180",
    "end": "282749"
  },
  {
    "text": "and if you feel that you are short of ideas of how to improve your product",
    "start": "282749",
    "end": "289180"
  },
  {
    "text": "ranges I definitely recommend to start with observability so once you have",
    "start": "289180",
    "end": "296169"
  },
  {
    "text": "achieved observability the next step will be availability so that means you",
    "start": "296169",
    "end": "302800"
  },
  {
    "text": "want your product to be available and reliable to your users most of the time",
    "start": "302800",
    "end": "309400"
  },
  {
    "text": "so for our streaming data infrastructure that means we should make sure that the",
    "start": "309400",
    "end": "315129"
  },
  {
    "text": "data keeps flowing end to end in our system without interruption so once you",
    "start": "315129",
    "end": "324580"
  },
  {
    "text": "have achieved availability you should look into operability having a great",
    "start": "324580",
    "end": "330279"
  },
  {
    "text": "product doesn't mean that you have to be burned out for operations so for no sub",
    "start": "330279",
    "end": "335860"
  },
  {
    "text": "issues you should have simple and repeatable processes to deal with them and most of the operations should be",
    "start": "335860",
    "end": "343089"
  },
  {
    "text": "automated so in Netflix our streaming data infrastructure handles about",
    "start": "343089",
    "end": "349509"
  },
  {
    "text": "thousand streams and data pipelines so without operability things will be",
    "start": "349509",
    "end": "356229"
  },
  {
    "text": "totally untenable so once you have",
    "start": "356229",
    "end": "362319"
  },
  {
    "text": "satisfied with operability availability and observability here comes the crown",
    "start": "362319",
    "end": "368499"
  },
  {
    "text": "jewel data quality so here you want to establish some key indicators for your",
    "start": "368499",
    "end": "375789"
  },
  {
    "text": "data quality and maybe some also enforceable hollows and for this talk",
    "start": "375789",
    "end": "383770"
  },
  {
    "text": "I'll be focusing on data transport quality and specifically data loss rate",
    "start": "383770",
    "end": "389219"
  },
  {
    "text": "duplicate rate and end-to-end latency",
    "start": "389219",
    "end": "394259"
  },
  {
    "start": "394000",
    "end": "394000"
  },
  {
    "text": "to make sense of my talk I like to share the architecture of our streaming data",
    "start": "395940",
    "end": "401530"
  },
  {
    "text": "infrastructure and Netflix so on the left side we have event producers and",
    "start": "401530",
    "end": "407909"
  },
  {
    "text": "they send events to a set of pop rock clusters we which we call fronting cop",
    "start": "407909",
    "end": "414699"
  },
  {
    "text": "rock clusters and as you can see on this",
    "start": "414699",
    "end": "419740"
  },
  {
    "text": "picture we Youthlink for stream processing so once the data get into a fronting khakha cluster they",
    "start": "419740",
    "end": "426099"
  },
  {
    "text": "are consumed by a set of stream processing jobs which operate on the",
    "start": "426099",
    "end": "431470"
  },
  {
    "text": "infrastructure level and those stream processing jobs are also called routers",
    "start": "431470",
    "end": "437830"
  },
  {
    "text": "in our infrastructure and they do some simple ETL like projection and filtering",
    "start": "437830",
    "end": "445050"
  },
  {
    "text": "and once the data is processed they'll be sent to downstream sinks",
    "start": "445050",
    "end": "450090"
  },
  {
    "text": "including s3 erratically search and another set of Kakaako Hofstra which we",
    "start": "450090",
    "end": "455500"
  },
  {
    "text": "call consumer carpark rosters and their data will be consumed by our customers",
    "start": "455500",
    "end": "462880"
  },
  {
    "text": "streaming processing job and other copper consumers so now that we have",
    "start": "462880",
    "end": "471669"
  },
  {
    "text": "covered our vision our principle of external observation and our",
    "start": "471669",
    "end": "477130"
  },
  {
    "text": "architecture let's start with the basics how we have improved of observability",
    "start": "477130",
    "end": "483490"
  },
  {
    "text": "with our kafka broker and consumer monitoring so as you can see on the",
    "start": "483490",
    "end": "492159"
  },
  {
    "start": "490000",
    "end": "490000"
  },
  {
    "text": "previous a architectural chart top top",
    "start": "492159",
    "end": "498430"
  },
  {
    "text": "plays a vital role in our infrastructure so it is very important to make sure the kafka is operational is healthy so let's",
    "start": "498430",
    "end": "508539"
  },
  {
    "text": "say you create a cop car cluster and all the internal metrics looks normal to you are you confident enough to put to put",
    "start": "508539",
    "end": "516490"
  },
  {
    "text": "production traffic on it well the ikata cluster is not on operational until you",
    "start": "516490",
    "end": "524198"
  },
  {
    "text": "can produce message to it and consume consume message from it",
    "start": "524199",
    "end": "530010"
  },
  {
    "text": "so we come up with a simple idea of creating an external service that",
    "start": "530010",
    "end": "537010"
  },
  {
    "text": "constantly send heart beating messages to the carpark history--and at the same time and assume those messages and we do",
    "start": "537010",
    "end": "546250"
  },
  {
    "text": "a little bit of analytical work here also we will will make sure that the",
    "start": "546250",
    "end": "553810"
  },
  {
    "text": "messages that it produce matches the messages it has consumed so by doing",
    "start": "553810",
    "end": "561190"
  },
  {
    "text": "that we have we can gain confidence that the Kaka Koster is truly operational",
    "start": "561190",
    "end": "568769"
  },
  {
    "text": "another important functionality we do in this external monitoring service is to",
    "start": "568950",
    "end": "574990"
  },
  {
    "text": "monitor the Capcom meta data and we do this in two ways we watch the zookeeper",
    "start": "574990",
    "end": "581980"
  },
  {
    "text": "nodes and look for its metadata and we",
    "start": "581980",
    "end": "587200"
  },
  {
    "text": "monitor the IRS our state in zookeeper as well at the same time this actor is",
    "start": "587200",
    "end": "595750"
  },
  {
    "text": "external monitoring service we will also talk to blockers to get the meta data directly and we try to match the",
    "start": "595750",
    "end": "603190"
  },
  {
    "text": "metadata we get from brokers versus the metadata we get from the zookeeper to make sure they match and if there's a",
    "start": "603190",
    "end": "610390"
  },
  {
    "text": "mismatch usually it's an indication that some kind of network partitioning has",
    "start": "610390",
    "end": "615610"
  },
  {
    "text": "happened so either the broker cannot talk to the zookeeper or the broker",
    "start": "615610",
    "end": "620710"
  },
  {
    "text": "cannot who cannot connect to the rest of the the capacitors so at that time you",
    "start": "620710",
    "end": "627910"
  },
  {
    "text": "need to enable some automated actions for example you should maybe restart the",
    "start": "627910",
    "end": "632920"
  },
  {
    "text": "JBN of your taka broker or just completely replace that broker another",
    "start": "632920",
    "end": "640690"
  },
  {
    "start": "639000",
    "end": "639000"
  },
  {
    "text": "important functionality that we do in this modern service is to monitor the",
    "start": "640690",
    "end": "645760"
  },
  {
    "text": "consumer and stream jobs so Coppa consumers we appeared audit",
    "start": "645760",
    "end": "653420"
  },
  {
    "text": "committe is offset to the cop car cluster so the committee the consumer",
    "start": "653420",
    "end": "658580"
  },
  {
    "text": "offset becomes a vital sign to tell if the consumer is healthy so from",
    "start": "658580",
    "end": "667580"
  },
  {
    "text": "monitoring the committee to offset we can derive the consumer lag as well as",
    "start": "667580",
    "end": "672680"
  },
  {
    "text": "to get a signal of whether the consumer has been completely stuck so what we do",
    "start": "672680",
    "end": "678530"
  },
  {
    "text": "here is we fetch the LOC and offsets from the car cluster and we also fetch",
    "start": "678530",
    "end": "684680"
  },
  {
    "text": "the committed consumer cell offsets from the cop car cluster and we do a little",
    "start": "684680",
    "end": "690140"
  },
  {
    "text": "you know simple calculation to note the consumer lag which is the log and",
    "start": "690140",
    "end": "696560"
  },
  {
    "text": "offsets minus the community offsets for any topic partition another signal that",
    "start": "696560",
    "end": "705500"
  },
  {
    "text": "we try to derive is whether the consumer is completely stocked so why we we do",
    "start": "705500",
    "end": "712460"
  },
  {
    "text": "this by observing the continued stillness of the community confused",
    "start": "712460",
    "end": "718520"
  },
  {
    "text": "consumer offset in a given window so let's say we said this window to be three minutes as I shown in this example",
    "start": "718520",
    "end": "726340"
  },
  {
    "text": "in the first three minutes the committed consumer said the consumer offset has not been changed it has been",
    "start": "726340",
    "end": "734000"
  },
  {
    "text": "you know all three while the log and offset has been making some progress so",
    "start": "734000",
    "end": "740800"
  },
  {
    "text": "at the fourth minute upon observing you know the consumer offset is still",
    "start": "740800",
    "end": "746120"
  },
  {
    "text": "unchanged we'll declare this consumer to be stocked and at the fifth minute we",
    "start": "746120",
    "end": "755000"
  },
  {
    "text": "noticed an advancement of the community the consumer offset so we will just",
    "start": "755000",
    "end": "760670"
  },
  {
    "text": "clear their stock signal and we do",
    "start": "760670",
    "end": "765800"
  },
  {
    "start": "765000",
    "end": "765000"
  },
  {
    "text": "provide rest endpoints for this marketing service and we expose the",
    "start": "765800",
    "end": "771140"
  },
  {
    "text": "consumer lacking information as well as the broker mandated information so by",
    "start": "771140",
    "end": "776840"
  },
  {
    "text": "doing this we can build a lot of the useful automations on top of those",
    "start": "776840",
    "end": "782860"
  },
  {
    "text": "so if you are familiar with the kaepa you may notice that cops already provide",
    "start": "783640",
    "end": "788870"
  },
  {
    "text": "internal metrics for ConsumerLab so you mean you may be asking you know",
    "start": "788870",
    "end": "794390"
  },
  {
    "text": "why bother creating your own service to monitor the consumer lag well these",
    "start": "794390",
    "end": "799850"
  },
  {
    "text": "internal metrics works well until the consumer stops polling or completely",
    "start": "799850",
    "end": "805310"
  },
  {
    "text": "crash and at that time this magic leak may become completely stale or be",
    "start": "805310",
    "end": "812000"
  },
  {
    "text": "dropped from the metric system and at that point it will be very confusing and",
    "start": "812000",
    "end": "817490"
  },
  {
    "text": "misleading and the second reason that we want to have this service is that we can",
    "start": "817490",
    "end": "823220"
  },
  {
    "text": "easily derive the stock signal because purely relying on because internal",
    "start": "823220",
    "end": "830750"
  },
  {
    "text": "metric there's no way that you can get that stock signal raise your hand if you",
    "start": "830750",
    "end": "840410"
  },
  {
    "start": "837000",
    "end": "837000"
  },
  {
    "text": "know this song Oh only what I can't believe it",
    "start": "840410",
    "end": "847660"
  },
  {
    "text": "yeah this this sounds you know kind of rosy and I when I when I wrote my slice",
    "start": "848530",
    "end": "855800"
  },
  {
    "text": "but it's kind of stuck in my head because it actually reflects the feeling",
    "start": "855800",
    "end": "861890"
  },
  {
    "text": "that we have towards our stock consumer alert and it's always the mix of love",
    "start": "861890",
    "end": "867740"
  },
  {
    "text": "and hate and now explain why so first a",
    "start": "867740",
    "end": "873200"
  },
  {
    "text": "love well getting this stock consumer alert can help us we catch all kinds of",
    "start": "873200",
    "end": "878570"
  },
  {
    "text": "issues whether its internal or external to our system and it dramatically",
    "start": "878570",
    "end": "884960"
  },
  {
    "text": "improves our service equality so if you have a streaming data service the last",
    "start": "884960",
    "end": "891320"
  },
  {
    "text": "thing that you won't have is your customer comes to you to complain about their job getting stock and you have no",
    "start": "891320",
    "end": "898190"
  },
  {
    "text": "idea about it so this stock consumer alert helped us",
    "start": "898190",
    "end": "903260"
  },
  {
    "text": "to avoid this kind of embarrassment and it also helped us to earn the customers",
    "start": "903260",
    "end": "909470"
  },
  {
    "text": "trust so why the hate well it is truly online their first",
    "start": "909470",
    "end": "915560"
  },
  {
    "text": "so since the creation of this alert it immediately becomes number one wake-up",
    "start": "915560",
    "end": "920759"
  },
  {
    "text": "calls from pager duty and it's actually very difficult to debug and there are so",
    "start": "920759",
    "end": "927690"
  },
  {
    "text": "many possibilities they that can cause a consumer getting stuck so here I listed",
    "start": "927690",
    "end": "936089"
  },
  {
    "start": "934000",
    "end": "934000"
  },
  {
    "text": "some of the possible causes to get on this consumer stock alert and you can",
    "start": "936089",
    "end": "941310"
  },
  {
    "text": "see it ranges from source infrastructure sync and processors and it may be even",
    "start": "941310",
    "end": "949709"
  },
  {
    "text": "caused by problems in committing offset so imagine that you wake up at night and",
    "start": "949709",
    "end": "957420"
  },
  {
    "text": "you are facing so many possibilities to deal with so to help us to truly",
    "start": "957420",
    "end": "965459"
  },
  {
    "text": "identify the cause of consumer getting stuck we need to further look into debugging logs and possibly try to find",
    "start": "965459",
    "end": "972360"
  },
  {
    "text": "some metrics and in some cases after we identify some pattern or some failure",
    "start": "972360",
    "end": "980130"
  },
  {
    "text": "modes we will create additional logging or additional metrics so that next time",
    "start": "980130",
    "end": "985350"
  },
  {
    "text": "we know where to look for but the biggest help comes from auto",
    "start": "985350",
    "end": "990930"
  },
  {
    "text": "remediations so in the next section I'm going to talk about how Auto mediations",
    "start": "990930",
    "end": "997380"
  },
  {
    "text": "help us to improve the operability and availability in our data infrastructure",
    "start": "997380",
    "end": "1004360"
  },
  {
    "text": "so the first first thing that we have noticed is that for a staleys streaming",
    "start": "1004360",
    "end": "1010250"
  },
  {
    "text": "job simply in relaunching a job upon getting the stock consumer alert having",
    "start": "1010250",
    "end": "1016519"
  },
  {
    "text": "a good chance to actually getting that consumer out of the stock state so we",
    "start": "1016519",
    "end": "1023660"
  },
  {
    "text": "create this tool called first responder so as the name implies it will",
    "start": "1023660",
    "end": "1029418"
  },
  {
    "text": "automatically relaunch a status job upon getting the first consumer stock alert",
    "start": "1029419",
    "end": "1036880"
  },
  {
    "text": "and of course we will still go investigate the root cause afterwards",
    "start": "1037240",
    "end": "1042319"
  },
  {
    "text": "but and also when",
    "start": "1042319",
    "end": "1048150"
  },
  {
    "text": "the fakes relaunch does not fix the problem the further relaunch will be suppressed",
    "start": "1048150",
    "end": "1053300"
  },
  {
    "text": "and here is the screenshot of the first responder in action so as you can see it",
    "start": "1053300",
    "end": "1061410"
  },
  {
    "start": "1054000",
    "end": "1054000"
  },
  {
    "text": "indeed say the night for a couple of times for us and the second use for",
    "start": "1061410",
    "end": "1068220"
  },
  {
    "start": "1066000",
    "end": "1066000"
  },
  {
    "text": "automations that we derive from our consumer lag monitoring is streaming jobs Auto skating so as you can see for",
    "start": "1068220",
    "end": "1075870"
  },
  {
    "text": "most of our streams their traffic fluctuate on a database so it is very",
    "start": "1075870",
    "end": "1082740"
  },
  {
    "text": "inefficient to use a fixed capacity for all streaming jobs but without auto",
    "start": "1082740",
    "end": "1089640"
  },
  {
    "text": "scaling all we can do initially is to pin our capacity high the evening that",
    "start": "1089640",
    "end": "1096570"
  },
  {
    "start": "1096000",
    "end": "1096000"
  },
  {
    "text": "we pin our capacity high sometimes it is still not sufficient because the traffic",
    "start": "1096570",
    "end": "1102060"
  },
  {
    "text": "can grow organically so on this graph the green area designates the traffic",
    "start": "1102060",
    "end": "1109230"
  },
  {
    "text": "volume and the red line designating the consumer lag so you can see after the",
    "start": "1109230",
    "end": "1115740"
  },
  {
    "text": "traffic increase through a exist a certain threshold the consumer lag will",
    "start": "1115740",
    "end": "1120960"
  },
  {
    "text": "increase dramatically and only after this peak hour is over then the lag can",
    "start": "1120960",
    "end": "1126570"
  },
  {
    "text": "disappear and the job can finally catch up so the direct impact of this is that",
    "start": "1126570",
    "end": "1133170"
  },
  {
    "text": "the customer will see increased latency at peak hours so in order to get rid of",
    "start": "1133170",
    "end": "1140910"
  },
  {
    "start": "1139000",
    "end": "1139000"
  },
  {
    "text": "this catch-up game we want to do Auto skating and the ideas are the ceiling is",
    "start": "1140910",
    "end": "1148860"
  },
  {
    "text": "is this for example you noticed a lack",
    "start": "1148860",
    "end": "1154440"
  },
  {
    "text": "for your streaming job and you won't get rid of it in 15 minutes so you need to",
    "start": "1154440",
    "end": "1160320"
  },
  {
    "text": "calculate the new capacity needed for the job so once you you calculate so",
    "start": "1160320",
    "end": "1167040"
  },
  {
    "text": "once you calculate the new capacity you need to relaunch the job and then the job relaunch will take about two minutes",
    "start": "1167040",
    "end": "1174440"
  },
  {
    "text": "so you have 30 minutes left to do the actual ketchup so your first",
    "start": "1174440",
    "end": "1180840"
  },
  {
    "text": "thing you need to figure out is the expected incoming events in the 15 minutes timeframe so these are the new",
    "start": "1180840",
    "end": "1187619"
  },
  {
    "text": "events coming into the pipeline and you also need to know the consumer lag you",
    "start": "1187619",
    "end": "1193979"
  },
  {
    "text": "add them together to get the number of total events that you'll be processing",
    "start": "1193979",
    "end": "1199590"
  },
  {
    "text": "in this 15 minutes and you divide that total events by the catch-up time you'll",
    "start": "1199590",
    "end": "1205229"
  },
  {
    "text": "get the target rate once you know the target rate it's very easy to figure out",
    "start": "1205229",
    "end": "1210239"
  },
  {
    "text": "the new expected capacity for your job and one thing we need to get in order to",
    "start": "1210239",
    "end": "1219929"
  },
  {
    "start": "1215000",
    "end": "1215000"
  },
  {
    "text": "make this work is to predicting the future workload so what we do here is",
    "start": "1219929",
    "end": "1225419"
  },
  {
    "text": "why what we try is we try to fit the quadratic regression on our traffic",
    "start": "1225419",
    "end": "1231239"
  },
  {
    "text": "curve and if it turns out that this error is too large we'll just go back to",
    "start": "1231239",
    "end": "1238499"
  },
  {
    "text": "linear regression and of course this sounds like overly simplified and in",
    "start": "1238499",
    "end": "1244679"
  },
  {
    "text": "practice we do find that this calculation does not cover all cases and",
    "start": "1244679",
    "end": "1250220"
  },
  {
    "text": "there's a lot of room for improvement but at least it gave us a head start for",
    "start": "1250220",
    "end": "1255720"
  },
  {
    "text": "us to do auto scaling so that we can say the cost and reduce the operational",
    "start": "1255720",
    "end": "1260789"
  },
  {
    "text": "burdens so this is a screenshot showing",
    "start": "1260789",
    "end": "1266429"
  },
  {
    "start": "1264000",
    "end": "1264000"
  },
  {
    "text": "the stringing jobs auto scaling in action so on the upper part of the graph you can see their traffic volume but on",
    "start": "1266429",
    "end": "1274679"
  },
  {
    "text": "the lower part that's the the number containers needed for the extreme in",
    "start": "1274679",
    "end": "1280379"
  },
  {
    "text": "jobs and basically that translate to translates to the resource and the capacity of the job as you can see the",
    "start": "1280379",
    "end": "1288059"
  },
  {
    "text": "number of containers actually scale up and down quite nicely according to the",
    "start": "1288059",
    "end": "1294509"
  },
  {
    "text": "traffic pattern so finally we you know covered the",
    "start": "1294509",
    "end": "1303320"
  },
  {
    "start": "1298000",
    "end": "1298000"
  },
  {
    "text": "operability availability and the ability and then we can get into discussion of",
    "start": "1303320",
    "end": "1309830"
  },
  {
    "text": "data quality and here I want to talk about how we used lost detection to be",
    "start": "1309830",
    "end": "1316850"
  },
  {
    "text": "able to find the lost messages and even auto recover those messages to improve",
    "start": "1316850",
    "end": "1323420"
  },
  {
    "text": "our data quality and as I mentioned in",
    "start": "1323420",
    "end": "1328940"
  },
  {
    "text": "the beginning of a talk I'll be focusing on the data transport trend a trend",
    "start": "1328940",
    "end": "1334970"
  },
  {
    "text": "protocol D here which is the loss loss rate duplicate rate and Antron latency",
    "start": "1334970",
    "end": "1344169"
  },
  {
    "start": "1348000",
    "end": "1348000"
  },
  {
    "text": "so let's look into their loss detection in details I have seen in several places",
    "start": "1349150",
    "end": "1354710"
  },
  {
    "text": "where people relying on count to detect loss and the idea is simple so you first",
    "start": "1354710",
    "end": "1362120"
  },
  {
    "text": "count the number of messages sent by your producer in a time frame and you",
    "start": "1362120",
    "end": "1368510"
  },
  {
    "text": "also count the number of messages are received by your consumer in the same",
    "start": "1368510",
    "end": "1373580"
  },
  {
    "text": "time frame and you try to compare your received count and the send count but",
    "start": "1373580",
    "end": "1380720"
  },
  {
    "text": "the question is that say if your received count is always greater than the send count are you confident that",
    "start": "1380720",
    "end": "1387740"
  },
  {
    "text": "you deal with you deliver every message well the answer is no because in the",
    "start": "1387740",
    "end": "1397220"
  },
  {
    "start": "1393000",
    "end": "1393000"
  },
  {
    "text": "receive account there's a problem some duplicates and the duplicates can be caused by producer doing retries under",
    "start": "1397220",
    "end": "1404990"
  },
  {
    "text": "the hood which you cannot account for or the consumer we have sometimes we status",
    "start": "1404990",
    "end": "1411170"
  },
  {
    "text": "offset to an earlier position and another problem with the count is that",
    "start": "1411170",
    "end": "1417470"
  },
  {
    "text": "the aggregation is tricky are we talking about event time or processing time and",
    "start": "1417470",
    "end": "1423130"
  },
  {
    "text": "how do we handle the late arrivals of the message and the third reason that I",
    "start": "1423130",
    "end": "1429800"
  },
  {
    "text": "don't like using count is that the identity a tional the messages is lost in aggregation so even if you can't eat at",
    "start": "1429800",
    "end": "1438200"
  },
  {
    "text": "account there's no way that you can recover your loss so we decided to turn",
    "start": "1438200",
    "end": "1445430"
  },
  {
    "text": "to a widely accepted concepts in micro service world which is tracing so the",
    "start": "1445430",
    "end": "1453410"
  },
  {
    "text": "basic idea is we want to trace the data as they move along in the pipeline and we will also generate traces as point up",
    "start": "1453410",
    "end": "1461210"
  },
  {
    "text": "interests so at a data ingestion point we want to determine if we want to trace",
    "start": "1461210",
    "end": "1467870"
  },
  {
    "text": "a peripheral message by random sampling and this sampling rate is configurable",
    "start": "1467870",
    "end": "1473200"
  },
  {
    "text": "so if you configure sampling rate to be 100 percent that just means you want to trace every single message and once we",
    "start": "1473200",
    "end": "1481460"
  },
  {
    "text": "gather those traces we want to analyze I want we want to analyze the traces externally but we are also doing quite",
    "start": "1481460",
    "end": "1490070"
  },
  {
    "start": "1487000",
    "end": "1487000"
  },
  {
    "text": "differently from the tracing in micro service the world our emphasis here is",
    "start": "1490070",
    "end": "1495590"
  },
  {
    "text": "on data loss they lost detection we want to identify lost messages and be able to",
    "start": "1495590",
    "end": "1502040"
  },
  {
    "text": "automatically recover those lost messages it is not about creating the",
    "start": "1502040",
    "end": "1507590"
  },
  {
    "text": "call graph because we already have the data DD of the information from our control planning or our management",
    "start": "1507590",
    "end": "1515120"
  },
  {
    "text": "service so instead we want to leverage the data lineage information to derive",
    "start": "1515120",
    "end": "1522230"
  },
  {
    "text": "the data loss information so in other words we know the claw graph but we want",
    "start": "1522230",
    "end": "1529040"
  },
  {
    "text": "to figure out who doesn't make that call so we created our tracing system called",
    "start": "1529040",
    "end": "1537200"
  },
  {
    "start": "1534000",
    "end": "1534000"
  },
  {
    "text": "Inca and Inca is a famous trail a mountain trail in South America it is",
    "start": "1537200",
    "end": "1546410"
  },
  {
    "text": "worth noting that we typically use mountain names in our for our so we",
    "start": "1546410",
    "end": "1551870"
  },
  {
    "text": "typically use mono names for our services in our streaming data infrastructure and Inca is a clear",
    "start": "1551870",
    "end": "1558830"
  },
  {
    "text": "exception from that naming convention but you can figure out that we want to",
    "start": "1558830",
    "end": "1563990"
  },
  {
    "text": "rely on Inca to reach higher ground so this is how we",
    "start": "1563990",
    "end": "1571010"
  },
  {
    "start": "1570000",
    "end": "1570000"
  },
  {
    "text": "do tracing assuming you have a typical date pipeline where you have your event producer produce messages to a cop",
    "start": "1571010",
    "end": "1578630"
  },
  {
    "text": "across your a and the message is consumed by your stream processing job",
    "start": "1578630",
    "end": "1584620"
  },
  {
    "text": "and let's assume it would do some simple enrichment to n keep the same identity",
    "start": "1584620",
    "end": "1591230"
  },
  {
    "text": "of the message and then the final message will be produced to a cluster B",
    "start": "1591230",
    "end": "1598750"
  },
  {
    "text": "so we want to keep using Kafka for our tracing and we create a dedicated Kafka",
    "start": "1598750",
    "end": "1604760"
  },
  {
    "text": "cluster to hold all the trees messages so when the producer sent a message with",
    "start": "1604760",
    "end": "1611390"
  },
  {
    "text": "ID 0 0 0 1 2 Kaka cluster a it way at the same time standard trace message to",
    "start": "1611390",
    "end": "1618050"
  },
  {
    "text": "the tracing cluster and the trees message we have the message ID which is the same as the original message ID and",
    "start": "1618050",
    "end": "1624670"
  },
  {
    "text": "you have the type of sent and remote location being a and the offset of that",
    "start": "1624670",
    "end": "1631520"
  },
  {
    "text": "message and same as the streaming",
    "start": "1631520",
    "end": "1637010"
  },
  {
    "text": "processing jobs upon receiving the message of ID 0 0 0 1 it will send a",
    "start": "1637010",
    "end": "1643220"
  },
  {
    "text": "trace to the kata-kata to the tracing kafka cluster with the same ID and with",
    "start": "1643220",
    "end": "1650120"
  },
  {
    "text": "the type being received and remote location ba once the processing is done",
    "start": "1650120",
    "end": "1655550"
  },
  {
    "text": "and the final message is produced to the Kafka cluster B another trace message",
    "start": "1655550",
    "end": "1662780"
  },
  {
    "text": "will be generated and this time it had the same ID and the type of being sent",
    "start": "1662780",
    "end": "1668210"
  },
  {
    "text": "and the remote location being B so now",
    "start": "1668210",
    "end": "1673640"
  },
  {
    "start": "1672000",
    "end": "1672000"
  },
  {
    "text": "we gather all our trees messages in our Kafka cluster and we want to do stream stream processing for those messages to",
    "start": "1673640",
    "end": "1680210"
  },
  {
    "text": "get real-time results because we don't want to wait for hours or days to detect",
    "start": "1680210",
    "end": "1687350"
  },
  {
    "text": "a loss we want to detect loss immediately within minutes so the first",
    "start": "1687350",
    "end": "1693200"
  },
  {
    "text": "thing that the job does is do a key by the trees ID orders or the same as message",
    "start": "1693200",
    "end": "1699289"
  },
  {
    "text": "so by doing this you can imagine that a lot of messages are being shuffled you",
    "start": "1699289",
    "end": "1704330"
  },
  {
    "text": "know to different places and the traces of or the same message will be shuffled",
    "start": "1704330",
    "end": "1711620"
  },
  {
    "text": "to the same task so now that we have access to all the trees in the trees",
    "start": "1711620",
    "end": "1716809"
  },
  {
    "text": "messages for the for all the traces of the same message in one place and that",
    "start": "1716809",
    "end": "1722629"
  },
  {
    "text": "can actually give us tremendous insights to see what's going on there so if if we",
    "start": "1722629",
    "end": "1729889"
  },
  {
    "text": "find that let's say one trace is missing for a given location and a given action",
    "start": "1729889",
    "end": "1735440"
  },
  {
    "text": "type we can claim that the message should last there and if we received",
    "start": "1735440",
    "end": "1741259"
  },
  {
    "text": "more than one traces for a certain location and certainly action type we",
    "start": "1741259",
    "end": "1747049"
  },
  {
    "text": "can claim duplicates and same as latency we can easily calculate the calculate",
    "start": "1747049",
    "end": "1753259"
  },
  {
    "text": "the latency for any data hub using the timestamp in the traces but we",
    "start": "1753259",
    "end": "1760190"
  },
  {
    "start": "1759000",
    "end": "1759000"
  },
  {
    "text": "immediately face a challenge so in the streaming processing job how long we should be waiting for the trace to",
    "start": "1760190",
    "end": "1766279"
  },
  {
    "text": "arrive because trace arrival time is unpredictable in our system it is not",
    "start": "1766279",
    "end": "1774259"
  },
  {
    "text": "unusual because it actually matches the behavior of messages flowing in our data system while most of the messages are",
    "start": "1774259",
    "end": "1782779"
  },
  {
    "text": "delivered and to end within a few seconds there are messages that can take",
    "start": "1782779",
    "end": "1789350"
  },
  {
    "text": "hours to be delivered and this is just",
    "start": "1789350",
    "end": "1795769"
  },
  {
    "text": "caused by you know the streaming jog is is severely lagging behind so as I",
    "start": "1795769",
    "end": "1802549"
  },
  {
    "text": "mentioned before we use Frink for stream processing but in flank is very hard to find a built a built-in",
    "start": "1802549",
    "end": "1810830"
  },
  {
    "text": "window function that can efficiently deal with this kind of long tail so we",
    "start": "1810830",
    "end": "1816230"
  },
  {
    "text": "decided to use Frank's cousin trigger with a global window what it is",
    "start": "1816230",
    "end": "1821480"
  },
  {
    "text": "essentially translates to is that we want to take converted control of Holland wait and what actions through",
    "start": "1821480",
    "end": "1828259"
  },
  {
    "text": "when what actions would take after the wait is over but we still face the challenge of you",
    "start": "1828259",
    "end": "1835679"
  },
  {
    "text": "know how long to wait if you wait too long but the message is already lost",
    "start": "1835679",
    "end": "1841049"
  },
  {
    "text": "then we are just wasting resources and the job will become unscalable if your",
    "start": "1841049",
    "end": "1847740"
  },
  {
    "text": "wait too short the system major with a lot of force alarms because if we if we",
    "start": "1847740",
    "end": "1858830"
  },
  {
    "text": "prematurely know declare a message laws",
    "start": "1858830",
    "end": "1863870"
  },
  {
    "text": "the Fossum will jet will definitely arrive because the actual message has",
    "start": "1863870",
    "end": "1870929"
  },
  {
    "text": "not been arrived yet and we just declare loss at that time so it's like you know",
    "start": "1870929",
    "end": "1879630"
  },
  {
    "text": "waiting a train that's not always sticking to the schedule when you rush",
    "start": "1879630",
    "end": "1885270"
  },
  {
    "text": "to the platform and you found the trains not there you will face dilemma of whether to wait",
    "start": "1885270",
    "end": "1890850"
  },
  {
    "text": "or not and if you choose to wait you might be keep wondering if you are",
    "start": "1890850",
    "end": "1896100"
  },
  {
    "text": "waiting for a train that will never arrive so to solve that problem we need",
    "start": "1896100",
    "end": "1902669"
  },
  {
    "start": "1900000",
    "end": "1900000"
  },
  {
    "text": "to some external inputs and we decided to turn to our old friends committee the",
    "start": "1902669",
    "end": "1908760"
  },
  {
    "text": "consumer offset so recall that in our trace messages we actually record the",
    "start": "1908760",
    "end": "1914490"
  },
  {
    "text": "actual offset of the message so what we can do here is we can compare the",
    "start": "1914490",
    "end": "1920970"
  },
  {
    "text": "committed offset versus the message offset so if the committee offset is greater than the message offset but we",
    "start": "1920970",
    "end": "1928320"
  },
  {
    "text": "don't have the trace that means the message is probably lost so here I'm",
    "start": "1928320",
    "end": "1935399"
  },
  {
    "text": "showing you the simply simplify the logic of our stream processing job and it always start with some kind of event",
    "start": "1935399",
    "end": "1942899"
  },
  {
    "text": "so the event can being the trace is received or a timer has been triggered",
    "start": "1942899",
    "end": "1948960"
  },
  {
    "text": "and at that time we'll check if all expected traces has been received for",
    "start": "1948960",
    "end": "1956190"
  },
  {
    "text": "that message and if it's if we do receive all the traces we will be poor",
    "start": "1956190",
    "end": "1962460"
  },
  {
    "text": "good and if not we'll compare the committee offset versus the message offset if the",
    "start": "1962460",
    "end": "1970230"
  },
  {
    "text": "committee offset is greater than the message offset will report loss as I",
    "start": "1970230",
    "end": "1977100"
  },
  {
    "text": "plain as I explained in the previous slide and if not that just means the",
    "start": "1977100",
    "end": "1983580"
  },
  {
    "text": "consumer is still trying to catch on and at that time we'll just set a new timer",
    "start": "1983580",
    "end": "1988920"
  },
  {
    "text": "and keep waiting so here is the completed picture for our tracing system",
    "start": "1988920",
    "end": "1995610"
  },
  {
    "start": "1991000",
    "end": "1991000"
  },
  {
    "text": "inca so the data producers and processes",
    "start": "1995610",
    "end": "2001100"
  },
  {
    "text": "will constantly send us all kinds of trace messages to our dedicated car capacitor for tracing and we have our",
    "start": "2001100",
    "end": "2009770"
  },
  {
    "text": "event we have our stream processing jobs that consume from those trees messages",
    "start": "2009770",
    "end": "2015800"
  },
  {
    "text": "from Kafka cluster and it will also get external input from our control plane",
    "start": "2015800",
    "end": "2021830"
  },
  {
    "text": "and Kafka clusters it will get the data energy information from our control",
    "start": "2021830",
    "end": "2028280"
  },
  {
    "text": "plane so that we can figure out what are the expected traces for any message and",
    "start": "2028280",
    "end": "2033830"
  },
  {
    "text": "it will get the kabillion offset from the cop car cluster so we will know how long to wait for the trace messages and",
    "start": "2033830",
    "end": "2041620"
  },
  {
    "text": "after the processing is done it will produce its final outputs to two",
    "start": "2041620",
    "end": "2047000"
  },
  {
    "text": "locations so it will produce the last rate duplicate rate and latency metrics",
    "start": "2047000",
    "end": "2053240"
  },
  {
    "text": "to our calamity system called Atlas and most importantly it will published",
    "start": "2053240",
    "end": "2060080"
  },
  {
    "text": "identity of the last messages to a Kafka topic so that's where our consumer or",
    "start": "2060080",
    "end": "2066800"
  },
  {
    "text": "our customer can subscribe to that last message clock on topic and apply their",
    "start": "2066800",
    "end": "2072830"
  },
  {
    "text": "own auto recovery so you might be asking",
    "start": "2072830",
    "end": "2079250"
  },
  {
    "text": "you know those trees messages are also Kalka messages and can be lost right the",
    "start": "2079250",
    "end": "2085250"
  },
  {
    "text": "answer is definitely yes and we understand that a last trace can lead to",
    "start": "2085250",
    "end": "2091250"
  },
  {
    "text": "a false alarms or some inaccuracy in our analysis but I also want to argue the",
    "start": "2091250",
    "end": "2097770"
  },
  {
    "text": "to validate your streaming data there's no perfect solution that can give you",
    "start": "2097770",
    "end": "2104790"
  },
  {
    "text": "you know 100% confidence or 100% accuracy you you'll probably end up",
    "start": "2104790",
    "end": "2113250"
  },
  {
    "text": "having to have multiple data validation solutions are together to give you you",
    "start": "2113250",
    "end": "2120450"
  },
  {
    "text": "know the best confidence that you can have and tracing is just one of those data validation solutions that being",
    "start": "2120450",
    "end": "2128790"
  },
  {
    "text": "said we do maximize the delivery guarantee for our traces for example we",
    "start": "2128790",
    "end": "2135960"
  },
  {
    "text": "have a dedicated treating cough dog pasture and it uses a very durable a SS",
    "start": "2135960",
    "end": "2142680"
  },
  {
    "text": "EBS and finally let's say a force alarm",
    "start": "2142680",
    "end": "2151020"
  },
  {
    "text": "is generated due to a lost race it is zero okay so one solution for getting",
    "start": "2151020",
    "end": "2158550"
  },
  {
    "text": "this kind of force alarms due to lost a lost race is that you apply your auto",
    "start": "2158550",
    "end": "2164250"
  },
  {
    "text": "recovery anyway because for at least one's delivery this may introduce a",
    "start": "2164250",
    "end": "2171830"
  },
  {
    "text": "little bit of duplicates but given the at least one semantics",
    "start": "2171830",
    "end": "2177270"
  },
  {
    "text": "this is totally acceptable given that our loss rate for the traces is very",
    "start": "2177270",
    "end": "2182339"
  },
  {
    "text": "very low now you might be wondering now",
    "start": "2182339",
    "end": "2187470"
  },
  {
    "text": "you have this you know wonderful tracing system what kind of problem have you detected well we have detected three",
    "start": "2187470",
    "end": "2194760"
  },
  {
    "text": "major categories of data loss so the first one the first category is caused",
    "start": "2194760",
    "end": "2201930"
  },
  {
    "text": "by less durable configurations and this",
    "start": "2201930",
    "end": "2207750"
  },
  {
    "text": "is understandable because when we initially create our caca cluster and create our and configure our streams we",
    "start": "2207750",
    "end": "2215010"
  },
  {
    "text": "have taken to account of cost availability and durability and balance",
    "start": "2215010",
    "end": "2220349"
  },
  {
    "text": "the amount so we may end up choosing unless you know durable configuration for saving cost for example if you have",
    "start": "2220349",
    "end": "2229560"
  },
  {
    "text": "a calf topic with replication factor of two and producer ax equals one naturally this",
    "start": "2229560",
    "end": "2237180"
  },
  {
    "text": "might leads to you know a tiny bit of message losses it can happen you know at",
    "start": "2237180",
    "end": "2243210"
  },
  {
    "text": "some extreme cases at due to you know it",
    "start": "2243210",
    "end": "2249119"
  },
  {
    "text": "can't happen it has some edge cases at replication especially when there's a",
    "start": "2249119",
    "end": "2254760"
  },
  {
    "text": "change of leader in a partition and the",
    "start": "2254760",
    "end": "2260250"
  },
  {
    "text": "second major category that we found for de laws is some extreme situations let's say you have a Kaka topic with",
    "start": "2260250",
    "end": "2267319"
  },
  {
    "text": "replication factor of nine but you just happen to lose online of your replicas",
    "start": "2267319",
    "end": "2273470"
  },
  {
    "text": "that's very unfortunate but it can happen but in one interesting case we",
    "start": "2273470",
    "end": "2279390"
  },
  {
    "text": "found that a partition leader has a significant clock drift and that leads",
    "start": "2279390",
    "end": "2285630"
  },
  {
    "text": "to unexpected log truncation happening at unexpected time and luckily we have",
    "start": "2285630",
    "end": "2293550"
  },
  {
    "text": "the tracing in place that time and we were able to detect the message loss caused by this art that inspected a log",
    "start": "2293550",
    "end": "2300270"
  },
  {
    "text": "truncation and the third major category for the day laws is actually human",
    "start": "2300270",
    "end": "2307170"
  },
  {
    "text": "factors so these are human errors code errors or operation errors so I can give",
    "start": "2307170",
    "end": "2316319"
  },
  {
    "text": "you one example in our deployment two we have a design flaw where in some rare",
    "start": "2316319",
    "end": "2323970"
  },
  {
    "text": "cases it can assign the same consumer ID to two different string processing jobs",
    "start": "2323970",
    "end": "2330200"
  },
  {
    "text": "so those two stream processing jobs can step on each other's toll when they",
    "start": "2330200",
    "end": "2335369"
  },
  {
    "text": "restart so what happens is when one job shuts down it will commit its last of",
    "start": "2335369",
    "end": "2342599"
  },
  {
    "text": "last offset to the Kaka cluster and when it comes back again is try to fetch the",
    "start": "2342599",
    "end": "2349380"
  },
  {
    "text": "last committed offset but what it gets is somebody else committed offset so it",
    "start": "2349380",
    "end": "2355470"
  },
  {
    "text": "or naturally leads to message loss",
    "start": "2355470",
    "end": "2359270"
  },
  {
    "text": "and I want to point out that for the second and third category it can happen",
    "start": "2360560",
    "end": "2366320"
  },
  {
    "text": "regardless how durable your 'kappa configuration is and I would even argue",
    "start": "2366320",
    "end": "2371480"
  },
  {
    "text": "that it can happen for any system regardless how strong their delivery",
    "start": "2371480",
    "end": "2377180"
  },
  {
    "text": "guarantees so that leads me to think",
    "start": "2377180",
    "end": "2383240"
  },
  {
    "text": "that detecting message loss is not that different from finding a black hole so",
    "start": "2383240",
    "end": "2389960"
  },
  {
    "text": "as you'll recall in my the beginning of my talk to find a black hole you have to observe objects around it so in this",
    "start": "2389960",
    "end": "2398060"
  },
  {
    "text": "case the black hole is the kafka broker with a bad hardware that eats our",
    "start": "2398060",
    "end": "2405320"
  },
  {
    "text": "messages and what are the objects around it the producers and consumers so if you",
    "start": "2405320",
    "end": "2413810"
  },
  {
    "text": "just look at your Kafka broker there's no way that you can find that elusive message but if you look at the",
    "start": "2413810",
    "end": "2421760"
  },
  {
    "text": "producer and consumer and the tree sees that they generate it's very easy to",
    "start": "2421760",
    "end": "2427520"
  },
  {
    "text": "figure out that some message has been lost so this is a takeaway of my talk we",
    "start": "2427520",
    "end": "2435260"
  },
  {
    "start": "2432000",
    "end": "2432000"
  },
  {
    "text": "start we started with observability where we used Kafka program and consumer",
    "start": "2435260",
    "end": "2440600"
  },
  {
    "text": "morning to to improve hours of ability and on top of that we created Auto",
    "start": "2440600",
    "end": "2447340"
  },
  {
    "text": "remediations to help you improve our operability and availability and",
    "start": "2447340",
    "end": "2452680"
  },
  {
    "text": "specifically we use a first responder to automatically relaunch our stateís jobs",
    "start": "2452680",
    "end": "2458230"
  },
  {
    "text": "once once it gets the stock state and also we use auto scaling to help us to",
    "start": "2458230",
    "end": "2467240"
  },
  {
    "text": "efficiently use our resources while keeping the consumer lag and minimal",
    "start": "2467240",
    "end": "2472340"
  },
  {
    "text": "level and finally we use message tracing to help us detect master loss and auto",
    "start": "2472340",
    "end": "2478880"
  },
  {
    "text": "recover them to improve our data quality and again I liked everybody to remember",
    "start": "2478880",
    "end": "2485810"
  },
  {
    "text": "the power of external observation and I hope someday you can use that to find",
    "start": "2485810",
    "end": "2492920"
  },
  {
    "text": "your own black hole so by the way I have a completed blog",
    "start": "2492920",
    "end": "2499760"
  },
  {
    "text": "post for our master trading system in Netflix tech blog so check it out if you",
    "start": "2499760",
    "end": "2505670"
  },
  {
    "text": "are interested and if you are interested",
    "start": "2505670",
    "end": "2511490"
  },
  {
    "text": "to tackle with problems in the real-time infrastructure we are hiring and welcome to join us",
    "start": "2511490",
    "end": "2520569"
  },
  {
    "text": "thank you [Applause]",
    "start": "2520569",
    "end": "2526520"
  }
]
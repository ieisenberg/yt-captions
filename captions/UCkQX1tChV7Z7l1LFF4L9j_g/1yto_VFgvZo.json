[
  {
    "start": "0",
    "end": "47000"
  },
  {
    "text": "good morning everyone my name is yang and I'm engineer at a company called the space safe games where I make mobile",
    "start": "4270",
    "end": "10059"
  },
  {
    "text": "games for a living as you can see I've got ryokan shaft in here today yeah don't worry it's a 24 hour blood",
    "start": "10059",
    "end": "15580"
  },
  {
    "text": "pressure monitoring system but in about two minutes it's gonna beep there's no",
    "start": "15580",
    "end": "21400"
  },
  {
    "text": "need to worry no need to evacuate the room or anything I'm not gonna crash on the floor either it's just gonna have to",
    "start": "21400",
    "end": "27489"
  },
  {
    "text": "stand very still and anything my blood pressure otherwise it's gonna keep retrying because clearly they haven't",
    "start": "27489",
    "end": "32529"
  },
  {
    "text": "learned to use circuit breakers yet so we Ted I would have been a quite long",
    "start": "32529",
    "end": "39699"
  },
  {
    "text": "time use of aw so it's coming to almost ten years now since I first started using services or it into an s3 and so",
    "start": "39699",
    "end": "46359"
  },
  {
    "text": "on and the last two years have worked quite extensively with Vader's lambda in production including working on some",
    "start": "46359",
    "end": "53199"
  },
  {
    "start": "47000",
    "end": "75000"
  },
  {
    "text": "non-trivial service architectures in one of my previous jobs working for a social network star in London and since then",
    "start": "53199",
    "end": "60519"
  },
  {
    "text": "I've been really active in writing about ensuring my experiences as well as many lessons I've learned while I was working",
    "start": "60519",
    "end": "67300"
  },
  {
    "text": "with established technologies and some of that's been picked up by the service well architect the white paper published",
    "start": "67300",
    "end": "73720"
  },
  {
    "text": "by AWS and I'm here today to talk to you about observability which often has definitely enter into the mainstream",
    "start": "73720",
    "end": "79990"
  },
  {
    "text": "thinking in 2017 to the point that we now have a full-on I was of ability track at a massive conference like UConn",
    "start": "79990",
    "end": "86950"
  },
  {
    "text": "and I think that is in part thanks to the excellent writings by people such as charity majors as well as industry",
    "start": "86950",
    "end": "93159"
  },
  {
    "text": "heroine and in her post Cindy talked about how the first mention of the mobility came from a post by Twitter",
    "start": "93159",
    "end": "100329"
  },
  {
    "text": "maybe going back even a few more years where they were discussing the challenges and problems that I run into",
    "start": "100329",
    "end": "106479"
  },
  {
    "text": "in terms of debugging and monitoring and troubleshooting this massively complex disability system that they have built",
    "start": "106479",
    "end": "114270"
  },
  {
    "text": "which begs the question at least for me of what exactly is observability and how",
    "start": "114270",
    "end": "120039"
  },
  {
    "text": "is it any different from just plain old monitoring and the best way I can think of the explain the difference is that",
    "start": "120039",
    "end": "126270"
  },
  {
    "text": "monitoring is like having a guard tower where you're looking now for those known system failure modes like someone",
    "start": "126270",
    "end": "133090"
  },
  {
    "text": "climbing over the fence or trying to Russia gates or in our case would be maybe spike since if you usage or never IO or memories",
    "start": "133090",
    "end": "140620"
  },
  {
    "text": "memory usage and it's a sort of thing that really well-suited for being displayed on dashboard and cluttered all",
    "start": "140620",
    "end": "146799"
  },
  {
    "text": "over the Sawyer or all of your office where the observability is maybe closer to what say intelligence officer",
    "start": "146799",
    "end": "154209"
  },
  {
    "text": "agencies are doing in terms of monitoring your data about you and me and to help you understand this",
    "start": "154209",
    "end": "160299"
  },
  {
    "text": "massively complicated system of human interactions by only observing from the outside hence the name of observability",
    "start": "160299",
    "end": "167980"
  },
  {
    "text": "and in her interview with daniel over there for info q child he talks about",
    "start": "167980",
    "end": "174549"
  },
  {
    "text": "how when you have four complex disabilities term the health of individual services now become less",
    "start": "174549",
    "end": "180549"
  },
  {
    "text": "important because they no longer tell the full story by the way is happening right now you're witnessing live blood",
    "start": "180549",
    "end": "186939"
  },
  {
    "text": "pressure taking so you're going to stand very still and talk so when you go",
    "start": "186939",
    "end": "192219"
  },
  {
    "text": "complete this video system the individual health of a salon service can not only tell you the full story of",
    "start": "192219",
    "end": "197769"
  },
  {
    "text": "what's happening it's hard to tell the whole - link between the help of one service to the level user experience",
    "start": "197769",
    "end": "203799"
  },
  {
    "text": "that your users get when they interact with your system so instead we should",
    "start": "203799",
    "end": "208989"
  },
  {
    "text": "focus on those using user actions instead and try to improve our ability to debug and troubleshoot those complex",
    "start": "208989",
    "end": "216099"
  },
  {
    "text": "interactions that are happening inside the system and that means we'll collect",
    "start": "216099",
    "end": "223090"
  },
  {
    "text": "data from different dimensions and telemetry data that we collect for monitoring is just one of those",
    "start": "223090",
    "end": "229000"
  },
  {
    "text": "dimensions and unlike monitoring observability is also very useful outside of incidents and altitudes and",
    "start": "229000",
    "end": "235930"
  },
  {
    "text": "quite frankly when dealing with a really complex system you can need a very good observability just we understand what",
    "start": "235930",
    "end": "242680"
  },
  {
    "text": "the hell is going on and to be able to operate his system in production and of",
    "start": "242680",
    "end": "248469"
  },
  {
    "start": "247000",
    "end": "290000"
  },
  {
    "text": "course as people start building more and more complex disabilities terms they also created tools that help them gain a",
    "start": "248469",
    "end": "253989"
  },
  {
    "text": "visibility in both the open source space with two slides if keen and open tracing a source commercial offerings as well",
    "start": "253989",
    "end": "261630"
  },
  {
    "text": "unfortunately all of these tools and practices that's been building up in the last couple years they also evolve the previous",
    "start": "261630",
    "end": "268360"
  },
  {
    "text": "generations or paradigms of how we build and ship we're to run inside ec2 instances or",
    "start": "268360",
    "end": "274660"
  },
  {
    "text": "inside containers and of course when Amazon announced the ADA was lambda and then we got this new paradigm of service",
    "start": "274660",
    "end": "281770"
  },
  {
    "text": "computing it's institute a number of interesting challenges to this existing set of tools and practices that we have",
    "start": "281770",
    "end": "288250"
  },
  {
    "text": "built up for starters we now no longer",
    "start": "288250",
    "end": "293319"
  },
  {
    "start": "290000",
    "end": "325000"
  },
  {
    "text": "have access to the underlying infrastructure that runs our code which means we can't install monitoring agents",
    "start": "293319",
    "end": "299319"
  },
  {
    "text": "and daemons that for very long time has been really quietly going about their job outside of the critical path where",
    "start": "299319",
    "end": "306099"
  },
  {
    "text": "we really were really concern about minimizing user facing latency so all",
    "start": "306099",
    "end": "312130"
  },
  {
    "text": "these ages and demons they were patched they were collected logs and metrics from your system and you patch them up",
    "start": "312130",
    "end": "317380"
  },
  {
    "text": "and send them asynchronously in the background but we've technologies are lambda you now lose the ability to do",
    "start": "317380",
    "end": "323229"
  },
  {
    "text": "background processing another interesting thing that has change we have the service paradigm is that",
    "start": "323229",
    "end": "329560"
  },
  {
    "start": "325000",
    "end": "431000"
  },
  {
    "text": "whereas before the level concurrency is largely managed can controlled by our own code but with lambda that content",
    "start": "329560",
    "end": "337300"
  },
  {
    "text": "management of concurrency has been lifted up into the platform which on the face of it is great news for us because",
    "start": "337300",
    "end": "343690"
  },
  {
    "text": "it means our code has now become drastically simpler on the other hand we",
    "start": "343690",
    "end": "349330"
  },
  {
    "text": "also lose a certain economic scale because we as before those logs and metrics to be collected and passed up at",
    "start": "349330",
    "end": "355930"
  },
  {
    "text": "the instance or container level whereas now they have to be a best patched up at",
    "start": "355930",
    "end": "362139"
  },
  {
    "text": "a per concurrent execution of your function which means in terms of the",
    "start": "362139",
    "end": "367180"
  },
  {
    "text": "concurrence that we project onto the downstream system that we use for collecting and monitoring our system is",
    "start": "367180",
    "end": "372520"
  },
  {
    "text": "now the level concurrency is now far far greater than before you might say sure",
    "start": "372520",
    "end": "379380"
  },
  {
    "text": "there's a simple solution for that they just use a bigger batch size unfortunately that's not quite when to",
    "start": "379380",
    "end": "385659"
  },
  {
    "text": "cut it either because imagine when there's a high level of traffic hitting your system and Amazon is now creating",
    "start": "385659",
    "end": "393039"
  },
  {
    "text": "new containers to run your code in response which is great because your system is also scaling without you even",
    "start": "393039",
    "end": "398680"
  },
  {
    "text": "have to think about it it just happens magically what happens then if you are patching and collecting those",
    "start": "398680",
    "end": "405409"
  },
  {
    "text": "metrics and logs data in between locations and not sending them eagerly and what happens when that traffic goes",
    "start": "405409",
    "end": "411589"
  },
  {
    "text": "down some of those containers are no longer necessary they become idle and eventually the garbage collected by the",
    "start": "411589",
    "end": "418039"
  },
  {
    "text": "platform along with any data that you've collected I have not yet sent to the monitoring system yet so if you're",
    "start": "418039",
    "end": "424849"
  },
  {
    "text": "patching and sending your data then there's a very high chance for data loss as a result whenever those garbage",
    "start": "424849",
    "end": "429949"
  },
  {
    "text": "collection happens so you might say sure in that case that we just send those",
    "start": "429949",
    "end": "435649"
  },
  {
    "start": "431000",
    "end": "548000"
  },
  {
    "text": "metrics were not equally at the end of every invocation problem solved",
    "start": "435649",
    "end": "440709"
  },
  {
    "text": "unfortunately remember there's no more background processing which means now you can't do those as part of your",
    "start": "440709",
    "end": "446899"
  },
  {
    "text": "functions invocation so that as to the duration for your function invocation",
    "start": "446899",
    "end": "451999"
  },
  {
    "text": "and when talking about api's with a Pik way it doesn't respond until your function as you finish executing and the",
    "start": "451999",
    "end": "459229"
  },
  {
    "text": "meantime your customer is still waiting for something to happen because your app is doing for your function to finish",
    "start": "459229",
    "end": "465050"
  },
  {
    "text": "executing so get caught in this catch-22 situation where on one hand if you are",
    "start": "465050",
    "end": "471379"
  },
  {
    "text": "patching and sending metrics data then you have data loss on the other hand if you are sending them equally then you're",
    "start": "471379",
    "end": "477709"
  },
  {
    "text": "adding to your user facing latency which as we know can impact revenue as well",
    "start": "477709",
    "end": "483339"
  },
  {
    "text": "another thing that the like to mention is that with service technologies event-driven architectures has become",
    "start": "483339",
    "end": "489769"
  },
  {
    "text": "much more commonplace and this is the toast part when listed in the C for random mode by event-driven architecture",
    "start": "489769",
    "end": "495529"
  },
  {
    "text": "go talk to Randy afterwards and I think in general we seen that the rise of event-driven architecture with service",
    "start": "495529",
    "end": "502039"
  },
  {
    "text": "adoption I think in part because it's just become easier to implement them with technologies our lambda and",
    "start": "502039",
    "end": "507769"
  },
  {
    "text": "Canisius to create an event-driven architecture it's actually really simple and in general we're also seeing a lot",
    "start": "507769",
    "end": "513888"
  },
  {
    "text": "of functions being chained together by a singular event sources such as as an S",
    "start": "513889",
    "end": "519078"
  },
  {
    "text": "messages or Canisius streams or even dynamodb streams or s3 events whenever",
    "start": "519079",
    "end": "524930"
  },
  {
    "text": "you drop a file into s3 bucket that can trigger a lambda function so as so in",
    "start": "524930",
    "end": "530899"
  },
  {
    "text": "order to trace those asynchronous events invocations is actually quite difficult at least compared to those synchrony",
    "start": "530899",
    "end": "537529"
  },
  {
    "text": "locations like API call so that's just some of the challenges that this new service paradigm has",
    "start": "537529",
    "end": "544250"
  },
  {
    "text": "introduced to the practices and tools that we have for observability and so",
    "start": "544250",
    "end": "550250"
  },
  {
    "start": "548000",
    "end": "574000"
  },
  {
    "text": "let's talk about some of the tools that we do have available today there's of course in terms of the four pillars that",
    "start": "550250",
    "end": "555530"
  },
  {
    "text": "seem identified by the treaty engineers in terms of monitoring alerting and visualization it is really tracing and the log",
    "start": "555530",
    "end": "562580"
  },
  {
    "text": "aggregation and of course there are more tools than the UK there's more tools and",
    "start": "562580",
    "end": "567710"
  },
  {
    "text": "vendors in this space and you can that you can count so I'm just gonna focus on the tools that comes with the platform",
    "start": "567710",
    "end": "572810"
  },
  {
    "text": "with AWS whenever your function rise to send out that message gets captured by",
    "start": "572810",
    "end": "579680"
  },
  {
    "text": "the lander service and ship asynchronously to cloud which locks and this is one of the few background",
    "start": "579680",
    "end": "586340"
  },
  {
    "text": "hosting you do get because it's provided by the platform in addition to your log message you also get a UTC times them as",
    "start": "586340",
    "end": "593600"
  },
  {
    "text": "well as a unique request ID as well and the way locks are organized inside cloud watch is such therefore every lambda",
    "start": "593600",
    "end": "600020"
  },
  {
    "text": "function you get a matching CloudWatch unlock group and inside the lock group you have a one lock stream for every",
    "start": "600020",
    "end": "605870"
  },
  {
    "text": "container that's running your code the problem of cloud which locks is that it",
    "start": "605870",
    "end": "610940"
  },
  {
    "start": "608000",
    "end": "800000"
  },
  {
    "text": "doesn't make searching easy especially if you need to search across all of your functions so what people will tend to do",
    "start": "610940",
    "end": "617540"
  },
  {
    "text": "in in practice is that they would go to your cloud which locks on so select a rock group action and then say you're",
    "start": "617540",
    "end": "624470"
  },
  {
    "text": "going to stream all of my log events to Amazon's the home manage the elastic search service if I'm using that or more",
    "start": "624470",
    "end": "630590"
  },
  {
    "text": "commonly to stream them through a lambda function which you can then shift your logs to whatever other log aggregation",
    "start": "630590",
    "end": "637040"
  },
  {
    "text": "service you're using which could be locally it could be sprung if you can afford it because this is really",
    "start": "637040",
    "end": "642290"
  },
  {
    "text": "expensive want me to keep in mind is that will for every time you create a",
    "start": "642290",
    "end": "647720"
  },
  {
    "text": "new lambda function the system also creates a new corresponding lock grouping cloud which locks as well and",
    "start": "647720",
    "end": "653090"
  },
  {
    "text": "we don't want to have is a manual process for someone to go in there to have to manually configure the",
    "start": "653090",
    "end": "658640"
  },
  {
    "text": "functional lock loop to then stream it to your locking function and what you can do in this space is to enable cloud",
    "start": "658640",
    "end": "664670"
  },
  {
    "text": "share on the account which then allows you to create an event pattern against the create Law Group API call that",
    "start": "664670",
    "end": "670670"
  },
  {
    "text": "system makes so that every time a new log has been created you can trigger another lambda function I can't really see you",
    "start": "670670",
    "end": "677300"
  },
  {
    "text": "can check in under lambda function whose job is to subscribe this new law group to your log shipping function and this",
    "start": "677300",
    "end": "683900"
  },
  {
    "text": "is something that you have to do once per environment so that you get that as a platform as a capability for your",
    "start": "683900",
    "end": "689570"
  },
  {
    "text": "platform by even using the service framework you can also choose to put this into your function definition as",
    "start": "689570",
    "end": "694910"
  },
  {
    "text": "well in your server so llamo so every time you deploy a function this project to your environment you also get that as",
    "start": "694910",
    "end": "701540"
  },
  {
    "text": "a capability another thing to keep in mind is that whenever pi before the list",
    "start": "701540",
    "end": "707390"
  },
  {
    "text": "whenever new law group has been created is set to never expire and if you're going to be shipping your logs to",
    "start": "707390",
    "end": "713120"
  },
  {
    "text": "somewhere else already then it really doesn't make any sense for you to keep all those logs in cloud wash logs forever especially as you're also paying",
    "start": "713120",
    "end": "720560"
  },
  {
    "text": "for data data storage with cloud wash logs as well so again apply the same",
    "start": "720560",
    "end": "725780"
  },
  {
    "text": "technique used car enable cultural set up the event pattern for create lock up",
    "start": "725780",
    "end": "731180"
  },
  {
    "text": "API and then invoke another function whose job is sent to set the retention policy to serve a more reasonable like",
    "start": "731180",
    "end": "738080"
  },
  {
    "text": "seven days and by default you get a bunch of basic telemetry by your",
    "start": "738080",
    "end": "743810"
  },
  {
    "text": "functions from cloud watch including function invocation count duration error counts total count and so on and",
    "start": "743810",
    "end": "750670"
  },
  {
    "text": "oftentimes you want to record application level custom metrics as well but remember no background processing so",
    "start": "750670",
    "end": "758720"
  },
  {
    "text": "again you've got to do it as part of your function invocation which makes your API slower and put in okay you may",
    "start": "758720",
    "end": "764810"
  },
  {
    "text": "say that's only 10 20 milliseconds but when you've got micro-services those 10 20 milliseconds can start a compound",
    "start": "764810",
    "end": "771230"
  },
  {
    "text": "when you have a user action that requires several API to complete so those 10 20 milliseconds per API call",
    "start": "771230",
    "end": "778520"
  },
  {
    "text": "you adding can easily add 100 or 200 milliseconds overall to the latency that your user experience and a few years ago",
    "start": "778520",
    "end": "785750"
  },
  {
    "text": "even Amazon found that every hundred milliseconds you add to their latency will reduce the number of sales by 1% so",
    "start": "785750",
    "end": "793310"
  },
  {
    "text": "those additional milliseconds you're spending to send custom metrics can actually end up coming back to haunt you",
    "start": "793310",
    "end": "798680"
  },
  {
    "text": "and hurt your revenue so one of the workarounds available in this space is",
    "start": "798680",
    "end": "804200"
  },
  {
    "text": "that you can piggyback off one of the back processing you to get on a platform by sending metrics a sickness II by first",
    "start": "804200",
    "end": "811320"
  },
  {
    "text": "writing them as especially formatted log messages in cloud watch logs so that gets captured by the service sent to",
    "start": "811320",
    "end": "817830"
  },
  {
    "text": "cloud which locks asynchronously and then your function that ships logs can then pick us up and send them as metrics",
    "start": "817830",
    "end": "824160"
  },
  {
    "text": "through your monitoring system instead of logs and this might sound like a really strange thing to do but actually",
    "start": "824160",
    "end": "829920"
  },
  {
    "text": "a lot of tools that are designed with service in mind are doing that already by default so a standard which is a new",
    "start": "829920",
    "end": "835950"
  },
  {
    "text": "monitoring tool from optionee they do this by default and dashboard for those who are familiar with the",
    "start": "835950",
    "end": "841470"
  },
  {
    "text": "service space they also build a monitoring system for service architects applications they do the same as well",
    "start": "841470",
    "end": "846960"
  },
  {
    "text": "another company that's really do some really interesting stuff around server security pure site they also do these to",
    "start": "846960",
    "end": "852870"
  },
  {
    "text": "record the security related information so that they can display and filter them on their platform as well in terms of",
    "start": "852870",
    "end": "860400"
  },
  {
    "start": "858000",
    "end": "941000"
  },
  {
    "text": "approach well this approach is going to add latency to when you see those metrics in your dashboards and it's also",
    "start": "860400",
    "end": "865920"
  },
  {
    "text": "going to add cost with the use of cloud which logs as well as lambda invocations and one more thing to consider is that",
    "start": "865920",
    "end": "871920"
  },
  {
    "text": "with lambda there's a regional limit of by default of 1,000 concurrent executions and in one region and what",
    "start": "871920",
    "end": "879840"
  },
  {
    "text": "you don't want to do is when you have so many things that you're locking so many things that this log should be",
    "start": "879840",
    "end": "885060"
  },
  {
    "text": "functional event are invoking are invoked constantly because it's an asynchronous events source that you end",
    "start": "885060",
    "end": "891030"
  },
  {
    "text": "up meeting up your quota for your regional limit and cause first top priority functions such as those",
    "start": "891030",
    "end": "898070"
  },
  {
    "text": "services API so then get strata instead so you want to use the new available the",
    "start": "898070",
    "end": "903360"
  },
  {
    "text": "new ability we have to control concurrency for individual functions and make sure that this guy doesn't run wild",
    "start": "903360",
    "end": "908790"
  },
  {
    "text": "in return you're not going to add any latency to your function location for",
    "start": "908790",
    "end": "913830"
  },
  {
    "text": "tracking custom metrics and so on which i think is a pretty good trade-off but it's definitely not the right thing to do for every situation what I would",
    "start": "913830",
    "end": "921750"
  },
  {
    "text": "say is that when you've got ap is where you're really concerned about user facing latency maybe consider this approach to send metrics asynchronously",
    "start": "921750",
    "end": "928800"
  },
  {
    "text": "but for everything else where you're doing background processing with communities or SNS just send them custom",
    "start": "928800",
    "end": "934440"
  },
  {
    "text": "metrics as part of function invocation because you'll those additional agencies are not impacting you",
    "start": "934440",
    "end": "939769"
  },
  {
    "text": "experience and once you have all of your metrics in carwash or whatever",
    "start": "939769",
    "end": "944989"
  },
  {
    "start": "941000",
    "end": "1014000"
  },
  {
    "text": "monitoring system you're using create dashboards set up alarms hook them up with your ops Genie or whatever usual",
    "start": "944989",
    "end": "950929"
  },
  {
    "text": "things that you would do already and in terms of systole tracing Amazon also offers the xray service which allows you",
    "start": "950929",
    "end": "957709"
  },
  {
    "text": "to see what goes on in signing location for a particular function especially if you're taking the time to instrument",
    "start": "957709",
    "end": "963499"
  },
  {
    "text": "your code and you get a very fine grained breakdown of what was happening sorry for your function and where those",
    "start": "963499",
    "end": "969379"
  },
  {
    "text": "milliseconds are going and interestingly if you call another function from that first function via lambdas API then you",
    "start": "969379",
    "end": "976610"
  },
  {
    "text": "also get a breakdown for that second function as well except it doesn't work when you call a second API lambda",
    "start": "976610",
    "end": "983629"
  },
  {
    "text": "function via API gateway because as of now x-ray this is the port API gateway natively but it's being worked on by",
    "start": "983629",
    "end": "990199"
  },
  {
    "text": "Amazon still though for my experience the use of x-ray is largely focused on",
    "start": "990199",
    "end": "995329"
  },
  {
    "text": "what happens inside one function so it's good when you want a homing on to some performance issues that you know about",
    "start": "995329",
    "end": "1001959"
  },
  {
    "text": "the particular problematic function but it doesn't do enough for you to help you gain intuition and understanding about",
    "start": "1001959",
    "end": "1007990"
  },
  {
    "text": "how your system is is connected together the composition of your service",
    "start": "1007990",
    "end": "1013299"
  },
  {
    "text": "architecture and again coming back to the same interview with tiny between",
    "start": "1013299",
    "end": "1018699"
  },
  {
    "start": "1014000",
    "end": "1047000"
  },
  {
    "text": "Daniel and charity with the individual how the health of individual services",
    "start": "1018699",
    "end": "1023829"
  },
  {
    "text": "are now less important in this world when you're dealing with a complex disability system instead in here at the",
    "start": "1023829",
    "end": "1030220"
  },
  {
    "text": "for the data as the enter into the edge of my architecture as a user request and then just flows through various part of",
    "start": "1030220",
    "end": "1037120"
  },
  {
    "text": "my system via both synchronous invocations like our API gateway as well as asynchronous locations via Canisius",
    "start": "1037120",
    "end": "1044350"
  },
  {
    "text": "or SNS or as three events and so on x-ray of course offers a service map",
    "start": "1044350",
    "end": "1050289"
  },
  {
    "start": "1047000",
    "end": "1095000"
  },
  {
    "text": "view for the traces that you collect but just as the traces themselves don't spend over a synchronous event sources",
    "start": "1050289",
    "end": "1056679"
  },
  {
    "text": "the traces that the service map itself doesn't review those either so it may be good for you to get a quick overview of",
    "start": "1056679",
    "end": "1063010"
  },
  {
    "text": "what how your function is connected to the various components and har over again solid overview of their current",
    "start": "1063010",
    "end": "1070029"
  },
  {
    "text": "health it doesn't do very much for you to call those the entire culture and of course being an address service",
    "start": "1070029",
    "end": "1076059"
  },
  {
    "text": "it doesn't really help you when it comes to chasing resources outside of a diverse ecosystem so if you're using of",
    "start": "1076059",
    "end": "1082600"
  },
  {
    "text": "zero or you're using as your functions as part of your architecture because you want to use the API services available",
    "start": "1082600",
    "end": "1090159"
  },
  {
    "text": "now sure rather than once in AWS x-ray isn't going to help you trace those invocations and finally I know I've got",
    "start": "1090159",
    "end": "1098529"
  },
  {
    "start": "1095000",
    "end": "1137000"
  },
  {
    "text": "the option to just go to the dashboard keep pressing the refresh button to see new traces they come in but that's feels",
    "start": "1098529",
    "end": "1104230"
  },
  {
    "text": "like a very static view for a system that liveing things that constantly happening why am I sitting there no it's",
    "start": "1104230",
    "end": "1109870"
  },
  {
    "text": "looking at us true and it's constant clicking the refresh button it just silly and we talk more about this later but",
    "start": "1109870",
    "end": "1115600"
  },
  {
    "text": "for now it's we want to conclude this session by saying that I think our tools right now they're very focused on",
    "start": "1115600",
    "end": "1120700"
  },
  {
    "text": "helping you understand what happens inside your function we're suffering in the future they need to shift their",
    "start": "1120700",
    "end": "1125980"
  },
  {
    "text": "focus slightly to then focus more on the interactions of your functions and what happens inside your whole system by",
    "start": "1125980",
    "end": "1132129"
  },
  {
    "text": "looking at those user actions that had a tendency to cut across multiple part of your architecture and this is one of the",
    "start": "1132129",
    "end": "1140379"
  },
  {
    "start": "1137000",
    "end": "1177000"
  },
  {
    "text": "architecture that will turn my previous company where we appeal we are migrated Amman at the backing system for a social",
    "start": "1140379",
    "end": "1146529"
  },
  {
    "text": "network to run on servers and one simple user actions could be I create a new post if she get distributed to all my",
    "start": "1146529",
    "end": "1153970"
  },
  {
    "text": "followers feeds so that the next time they come into the app they will see my new post on their timeline exactly like",
    "start": "1153970",
    "end": "1160179"
  },
  {
    "text": "how treat the timeline works and for very simple user action like this you can see a number of function have to",
    "start": "1160179",
    "end": "1165970"
  },
  {
    "text": "work together to make this feature work and they have the work together via both synchronous invocation events such as",
    "start": "1165970",
    "end": "1172269"
  },
  {
    "text": "API gateway as well as asynchronous sources such as SNS and Kinesis and as",
    "start": "1172269",
    "end": "1179169"
  },
  {
    "text": "people build more and more complex systems using service technologies and pretty sure that this is the area where",
    "start": "1179169",
    "end": "1184809"
  },
  {
    "text": "we're going to need the most help from our tools and that brings us to what the",
    "start": "1184809",
    "end": "1189879"
  },
  {
    "start": "1187000",
    "end": "1201000"
  },
  {
    "text": "future of service observability could be based on some of the things i've seen in people actually working on new tools or",
    "start": "1189879",
    "end": "1196690"
  },
  {
    "text": "new features for existing tools but also some of the ideas that I have myself as well starting with dashboards as",
    "start": "1196690",
    "end": "1203820"
  },
  {
    "start": "1201000",
    "end": "1367000"
  },
  {
    "text": "engineer who's done a lot of on core and operational in my career I have used a lot of",
    "start": "1203820",
    "end": "1209730"
  },
  {
    "text": "different dashboards from different vendors and by and large I dislike most of them for the simple reason that for",
    "start": "1209730",
    "end": "1216300"
  },
  {
    "text": "every useful bit of signal I have the filter are myself a lot of noise and I",
    "start": "1216300",
    "end": "1222059"
  },
  {
    "text": "also get this mental dissonance where by most my tools focus on what happens",
    "start": "1222059",
    "end": "1227220"
  },
  {
    "text": "inside one component and yet when I want to ask the question of is this component",
    "start": "1227220",
    "end": "1232530"
  },
  {
    "text": "healthy the different dimension of data and in to look at our splattered all over the place",
    "start": "1232530",
    "end": "1237540"
  },
  {
    "text": "semi that corner summer at the top and I can't even work how no where am I gonna find my one service in this mess here",
    "start": "1237540",
    "end": "1245150"
  },
  {
    "text": "which is fine of all the dashboards I've used so far the one I enjoyed the most is the one that you get from a History X",
    "start": "1245150",
    "end": "1251880"
  },
  {
    "text": "library from Netflix whereby all the high level useful and relevant information about one component is",
    "start": "1251880",
    "end": "1258450"
  },
  {
    "text": "nicely in one place and the most important piece of information around the volume of traffic and overall health",
    "start": "1258450",
    "end": "1265110"
  },
  {
    "text": "of a survey or component is also the most prominent and visually striking part of the dashboard as well",
    "start": "1265110",
    "end": "1271160"
  },
  {
    "text": "unfortunately in terms of data points that you get from history is just not fit for service because the information",
    "start": "1271160",
    "end": "1278850"
  },
  {
    "text": "we don't care about like the number of hosts for example base also missing data points that we do care about such as",
    "start": "1278850",
    "end": "1284670"
  },
  {
    "text": "number of co-stars or the number of concurrent executions and so on so way",
    "start": "1284670",
    "end": "1289980"
  },
  {
    "text": "if we are able to apply little makeover to the History X dashboard and we keep the import import information up there",
    "start": "1289980",
    "end": "1295650"
  },
  {
    "text": "around the volume of traffic and health of the service as the most striking and visually prominent part of the dashboard",
    "start": "1295650",
    "end": "1303120"
  },
  {
    "text": "but then we were substituting the number of co-stars both in absolute terms as",
    "start": "1303120",
    "end": "1308160"
  },
  {
    "text": "well as percentage of the number invocations say in the last two or five minutes and also since we know how much",
    "start": "1308160",
    "end": "1315690"
  },
  {
    "text": "one invocations going to cost you Amazon even reports how much is going to cost you in the car which locks messages",
    "start": "1315690",
    "end": "1321840"
  },
  {
    "text": "based on thus the function invocation duration as well as the the size of your",
    "start": "1321840",
    "end": "1327960"
  },
  {
    "text": "function in terms of the memory setting we can actually give you an estimate on how much this function is costing you",
    "start": "1327960",
    "end": "1333690"
  },
  {
    "text": "say per second or per minute rate also we can tell you the current could",
    "start": "1333690",
    "end": "1338790"
  },
  {
    "text": "concurrent currency that you have for this affirmation as well and as well as any",
    "start": "1338790",
    "end": "1344140"
  },
  {
    "text": "number the number of throttled or error invocations alongside with all the other",
    "start": "1344140",
    "end": "1350520"
  },
  {
    "text": "Terra latency numbers that we are monitoring as well and so one good having all this information so",
    "start": "1350520",
    "end": "1356320"
  },
  {
    "text": "information in a dashboard so it shows that the health of individual functions is citizen tell us how the my system is",
    "start": "1356320",
    "end": "1363550"
  },
  {
    "text": "composed together by the different functions and different event sources and the way they like to visualize my",
    "start": "1363550",
    "end": "1370210"
  },
  {
    "start": "1367000",
    "end": "1396000"
  },
  {
    "text": "system is as if it's a brain where you've got neurons and you've got the snap sister connector so there are loud",
    "start": "1370210",
    "end": "1376840"
  },
  {
    "text": "stated chance to flow through the brain and when you want to see how the brain reacts to external stimuli you press",
    "start": "1376840",
    "end": "1383980"
  },
  {
    "text": "enter into MRI machine and your watch in real-time as different parts of the brain lights up as you inject those",
    "start": "1383980",
    "end": "1390430"
  },
  {
    "text": "external stimuli by I don't know pinch the arm or tickle them or take their blood pressure so if you apply the same",
    "start": "1390430",
    "end": "1398920"
  },
  {
    "start": "1396000",
    "end": "1426000"
  },
  {
    "text": "design thinking to dashboards maybe end up with something like Netflix is Withrow to where you can actually watch",
    "start": "1398920",
    "end": "1404590"
  },
  {
    "text": "as traffic flows through your system imagine all those little dots could be lambda functions or could be event",
    "start": "1404590",
    "end": "1410650"
  },
  {
    "text": "sources or maybe how traffic is being diverted when one of the address regions",
    "start": "1410650",
    "end": "1416500"
  },
  {
    "text": "is having an outage so having a live dashboard rather than a static one it's going to give you a lot of bird's-eye",
    "start": "1416500",
    "end": "1422710"
  },
  {
    "text": "view into your system as it breathes and acid leaves and maybe occasionally you",
    "start": "1422710",
    "end": "1428710"
  },
  {
    "start": "1426000",
    "end": "1450000"
  },
  {
    "text": "want to take a pause on watching the little dots move around across the screen and you want to just pick out one of the current execution threads and",
    "start": "1428710",
    "end": "1435280"
  },
  {
    "text": "really dive into it and here we're going to need to be able to trace those",
    "start": "1435280",
    "end": "1440560"
  },
  {
    "text": "asynchronous even six or a sacred invocations and also with the trace over",
    "start": "1440560",
    "end": "1445620"
  },
  {
    "text": "services that were using they are not part of the a diverse ecosystem and also",
    "start": "1445620",
    "end": "1452170"
  },
  {
    "start": "1450000",
    "end": "1484000"
  },
  {
    "text": "instead of how is a forcing me to jump between different tools to see different views of the same trace I should have",
    "start": "1452170",
    "end": "1457420"
  },
  {
    "text": "all the logs rate all other logs relevant to this particular set of execution right there",
    "start": "1457420",
    "end": "1462790"
  },
  {
    "text": "in my fingertip and should have the usual treatment for new acts in terms of being the click on the column to saw the",
    "start": "1462790",
    "end": "1468580"
  },
  {
    "text": "different to soar by different columns or click on a row to expand it to see other attributes and collect",
    "start": "1468580",
    "end": "1474670"
  },
  {
    "text": "with my lock messages and if I click on one of the functions is she also just filter out everything else to show me",
    "start": "1474670",
    "end": "1481000"
  },
  {
    "text": "only the logs created by that particular function and since the tool also notes",
    "start": "1481000",
    "end": "1486850"
  },
  {
    "text": "that I've click on a function maybe you show me the tooltip so that can very quickly pop open the cloud9 IDE to look",
    "start": "1486850",
    "end": "1492910"
  },
  {
    "text": "at the code so that I can easy collate between the lock messages I'm seeing just now we have the code that's",
    "start": "1492910",
    "end": "1498640"
  },
  {
    "text": "generating those log messages and I also want to see the input and output for my lambda functions when I'm looking at",
    "start": "1498640",
    "end": "1504250"
  },
  {
    "text": "them so that should also be right there available where I need it as well and as",
    "start": "1504250",
    "end": "1509620"
  },
  {
    "text": "to navigate to another function you should show me the differ the new log messages as well as a new input and output for that particular function and",
    "start": "1509620",
    "end": "1516280"
  },
  {
    "text": "if one malfunctions errored i also want to see the error message as was a stack trace if one is available and finally",
    "start": "1516280",
    "end": "1524530"
  },
  {
    "text": "the two should make those a function that didn't complete successfully very visually prominent so there are no",
    "start": "1524530",
    "end": "1530200"
  },
  {
    "text": "straightaway there hey that's the function i should investigate so that's",
    "start": "1530200",
    "end": "1535810"
  },
  {
    "start": "1533000",
    "end": "1587000"
  },
  {
    "text": "all well and good but we're still missing some information around the performance tracing so we probably going",
    "start": "1535810",
    "end": "1541420"
  },
  {
    "text": "to care about how long the entire workflow took as well as the the different breakdown for the different parts of that that code chain and if I",
    "start": "1541420",
    "end": "1549190"
  },
  {
    "text": "click on one of the functions maybe you should just filter out the noise so that it shows me how nicely the trace is",
    "start": "1549190",
    "end": "1555700"
  },
  {
    "text": "relevant to a particular function invocation and if I took the time to in some of my code and also get more",
    "start": "1555700",
    "end": "1561550"
  },
  {
    "text": "fine-grained breakdown as well so the idea here is that the two I should have",
    "start": "1561550",
    "end": "1567640"
  },
  {
    "text": "a tool where I can I can satisfy all of my tracing needs rather than having multiple tools that shows me different",
    "start": "1567640",
    "end": "1573400"
  },
  {
    "text": "views of the same trace and then only then mentally build up a pack complete picture of what's going on in that trace",
    "start": "1573400",
    "end": "1579880"
  },
  {
    "text": "in my head the two she just showed me the picture run and give me clues to what's happened and then forced me to",
    "start": "1579880",
    "end": "1585790"
  },
  {
    "text": "piece everything together another thing that strikes me when I look at a dashboard like this is that is",
    "start": "1585790",
    "end": "1592510"
  },
  {
    "start": "1587000",
    "end": "1629000"
  },
  {
    "text": "actually a graph as saying you've got nodes and you got vertices that connect them so what if we are able to store",
    "start": "1592510",
    "end": "1600340"
  },
  {
    "text": "those traces data as a graph data and spill to query them as a graph as you",
    "start": "1600340",
    "end": "1605680"
  },
  {
    "text": "would do in a graph database like near 40 or Amazon's new hotness natural database",
    "start": "1605680",
    "end": "1611490"
  },
  {
    "text": "so that wouldn't that allow us to then build a query the query based on the",
    "start": "1611490",
    "end": "1617170"
  },
  {
    "text": "relationship between the different components that we're observing as opposed to just about say some",
    "start": "1617170",
    "end": "1622450"
  },
  {
    "text": "characteristics about that components like average latency or error count or so on you may ask the why is that useful and I",
    "start": "1622450",
    "end": "1630250"
  },
  {
    "text": "think it's useful because whenever you're doing a root cause analysis as the name suggests you're looking for",
    "start": "1630250",
    "end": "1635350"
  },
  {
    "text": "that causality that helps you understand what caused some of know behavior that you're able to observe or be what's been",
    "start": "1635350",
    "end": "1643000"
  },
  {
    "text": "reported by your users and oftentimes when you start to investigate these of know behaviors you start by looking for",
    "start": "1643000",
    "end": "1649330"
  },
  {
    "text": "other abnormal abnormality in your system as a whole just blindly looking",
    "start": "1649330",
    "end": "1654460"
  },
  {
    "text": "only for temporal correlation but those temporal correlation doesn't necessary",
    "start": "1654460",
    "end": "1659620"
  },
  {
    "text": "mean causality oftentimes it really hard to tell the cause from the symptom because things will happen around the",
    "start": "1659620",
    "end": "1665470"
  },
  {
    "text": "same time and they show up on your gravity for at different scales and I",
    "start": "1665470",
    "end": "1670690"
  },
  {
    "text": "think for me the reason dyes difficult is because the relationship between the different components whose metrics we're",
    "start": "1670690",
    "end": "1676570"
  },
  {
    "text": "looking at are not always obvious to us and that's why you often have to fall back to the experts of a system keep",
    "start": "1676570",
    "end": "1682809"
  },
  {
    "text": "with a builder system because chances are those relationships only exist in their mental model for the system and",
    "start": "1682809",
    "end": "1689440"
  },
  {
    "text": "not record it anywhere else maybe in the documentation but documentation go out of there as well so what if then imagine",
    "start": "1689440",
    "end": "1697540"
  },
  {
    "text": "the world where but those relationships can be captured explicitly and also queried upon so instead of blindly",
    "start": "1697540",
    "end": "1703870"
  },
  {
    "text": "looking for temporal correlation across the entire system I can only look I only look for temporal correlations in the",
    "start": "1703870",
    "end": "1709900"
  },
  {
    "text": "things that this particular say the payment service depends on either directly or indirectly then maybe I can",
    "start": "1709900",
    "end": "1717160"
  },
  {
    "text": "much quickly identify that the root cause here is that we have seen an elevated number of stroke executions in",
    "start": "1717160",
    "end": "1724210"
  },
  {
    "text": "one of the Dharma TV tables and since being used by the user service which",
    "start": "1724210",
    "end": "1729400"
  },
  {
    "text": "then caused user service to be slower and but maybe not so much that it triggers our alarms and alerts but where",
    "start": "1729400",
    "end": "1735940"
  },
  {
    "text": "we are seeing a symptom is actually in the payment system so now that we have identified a place of interest we can",
    "start": "1735940",
    "end": "1741590"
  },
  {
    "text": "also expand this urgency what are other things that depend on the this particular table either directly or",
    "start": "1741590",
    "end": "1748070"
  },
  {
    "text": "indirectly so that we can find other components that could have been impacted but not to such a severe degree that it",
    "start": "1748070",
    "end": "1755390"
  },
  {
    "text": "shapes our alerting and monitoring systems so I think they'll be really useful actually dimension to or lease",
    "start": "1755390",
    "end": "1762679"
  },
  {
    "text": "tutor to add to our tool belt when it comes to monitoring and operating our systems in the last couple years we've",
    "start": "1762679",
    "end": "1768830"
  },
  {
    "start": "1766000",
    "end": "1817000"
  },
  {
    "text": "also heard an awful lot about big data about machine learning about deep learning and I think as industry because",
    "start": "1768830",
    "end": "1774649"
  },
  {
    "text": "I'm very good at using those technologies and those techniques to help improve the products and services",
    "start": "1774649",
    "end": "1779899"
  },
  {
    "text": "that we offer what if we then turn around and say can we apply the same ideas and same techniques to improve the",
    "start": "1779899",
    "end": "1786140"
  },
  {
    "text": "way that we operate our software maybe we can use machine learning to help us Auto detect erroneous and suspicious",
    "start": "1786140",
    "end": "1792380"
  },
  {
    "text": "behavior in our system or maybe to suggest potential improvement that we can make in fact if we look at what's",
    "start": "1792380",
    "end": "1798289"
  },
  {
    "text": "happening in the cloud providers Amazon's already doing this with services like guard duty and macey and",
    "start": "1798289",
    "end": "1803990"
  },
  {
    "text": "the fingers U is also doing this as well with the cloud sequel offering where they can such offer suggestions on maybe",
    "start": "1803990",
    "end": "1810559"
  },
  {
    "text": "she turned on this index because had you done that you would have improved that query speed by X percentage so imagine",
    "start": "1810559",
    "end": "1819500"
  },
  {
    "start": "1817000",
    "end": "1860000"
  },
  {
    "text": "now we have a system in the background as constant learning about how our system is operating and maybe they tell",
    "start": "1819500",
    "end": "1825140"
  },
  {
    "text": "us that hey you're one of your functions just starting writing to a tournament DB table that it's never done before is",
    "start": "1825140",
    "end": "1831260"
  },
  {
    "text": "that right is that just feels a bit suspicious and if you're in the dashboard maybe surely to pop up so that",
    "start": "1831260",
    "end": "1837350"
  },
  {
    "text": "you can quickly react to it or if you're not a dashboard at a moment in time then maybe send you an email as well with a",
    "start": "1837350",
    "end": "1844220"
  },
  {
    "text": "few more links you can say oh yeah it's fine it's a new feature we know about this that don't worry about it or maybe",
    "start": "1844220",
    "end": "1850370"
  },
  {
    "text": "something's fishy so you can tell the tool to automatically update the IE and permission for that function to put a",
    "start": "1850370",
    "end": "1856429"
  },
  {
    "text": "stop to whatever is happening until you've had a chance to investigate further and nothing you make me to do is",
    "start": "1856429",
    "end": "1863240"
  },
  {
    "start": "1860000",
    "end": "1900000"
  },
  {
    "text": "well we seize that last time you did a deployment yesterday and now your functions running on average 30% slower",
    "start": "1863240",
    "end": "1870200"
  },
  {
    "text": "than before the deployment so maybe if you're free to do some performance issues and he maybe want to look into it or",
    "start": "1870200",
    "end": "1877100"
  },
  {
    "text": "that your function is averaging 102 milliseconds and since the Amazon lambda",
    "start": "1877100",
    "end": "1882799"
  },
  {
    "text": "P was your function invocation for in 100 millisecond blocks so you actually can charge for 200 milliseconds so maybe",
    "start": "1882799",
    "end": "1889820"
  },
  {
    "text": "you want to increase the memory setting for the function so that you bring down the average execution time to under",
    "start": "1889820",
    "end": "1895669"
  },
  {
    "text": "hundred millisecond and therefore is faster and you also pay less money overall as well so that's just some an",
    "start": "1895669",
    "end": "1902570"
  },
  {
    "text": "idea that I've had for where we could be heading in the future for the service that was ability of course I don't have",
    "start": "1902570",
    "end": "1909289"
  },
  {
    "text": "a crystal ball so I can't tell you exactly what's gonna happen but this is just my wishes and based on things I've",
    "start": "1909289",
    "end": "1914779"
  },
  {
    "text": "seen so far and Simon soire who is a noted advocate for service technologies he will also",
    "start": "1914779",
    "end": "1921710"
  },
  {
    "text": "talk about how businesses need to develop a sense of situational awareness and they need to do that they can only",
    "start": "1921710",
    "end": "1927950"
  },
  {
    "text": "do that by using tools that show them the context and movement of a space that are operating in and equally as",
    "start": "1927950",
    "end": "1935210"
  },
  {
    "start": "1933000",
    "end": "1954000"
  },
  {
    "text": "engineers who are building complex systems where we care about those user actions that tend to cut across multiple",
    "start": "1935210",
    "end": "1941090"
  },
  {
    "text": "parts of our system we also need to use tools that show us the movement and",
    "start": "1941090",
    "end": "1946519"
  },
  {
    "text": "context of data so that we can build the situational awareness we need in order to operate our service architectures and",
    "start": "1946519",
    "end": "1954580"
  },
  {
    "start": "1954000",
    "end": "1978000"
  },
  {
    "text": "as Alan Kay will say the best way to predict the future is to invent it and I",
    "start": "1954580",
    "end": "1960590"
  },
  {
    "text": "guess I'll follow that by saying the best way to invent the future is to inception someone else to do it for you",
    "start": "1960590",
    "end": "1966549"
  },
  {
    "text": "which has been the entire purpose of this hook and I guess also like to thank",
    "start": "1966549",
    "end": "1972350"
  },
  {
    "text": "a few people who are definitely inventing the future of service a possibility for showing me the stuff",
    "start": "1972350",
    "end": "1977360"
  },
  {
    "text": "that they are working on and as I mentioned already is Sandra the optional",
    "start": "1977360",
    "end": "1982580"
  },
  {
    "text": "guys are pretty new to that's just right now focus on the Java Runtime",
    "start": "1982580",
    "end": "1988519"
  },
  {
    "text": "but the local users to support other one x as well and also I looked at some the",
    "start": "1988519",
    "end": "1993529"
  },
  {
    "text": "things that our pipes guys are working on in the pipeline and it's definitely definitely very very interesting but the",
    "start": "1993529",
    "end": "1999019"
  },
  {
    "text": "ones who that's pretty guarded most excited over the last couple of weeks or months as I prepare for this talk is this guys called epsilon there are",
    "start": "1999019",
    "end": "2005950"
  },
  {
    "text": "Starbase in the Israel and as you can see from the the prototype of like a demo for that tool I've taken a",
    "start": "2005950",
    "end": "2012280"
  },
  {
    "text": "lot of ideas in terms of visually for what you could do in terms of how you",
    "start": "2012280",
    "end": "2017560"
  },
  {
    "text": "want to monitor and trace your function invocations across both synchronous and asynchronous events sources as was in",
    "start": "2017560",
    "end": "2024520"
  },
  {
    "text": "and out of Amazon's ecosystem I think those guys are going to open Peter pretty soon so check them out when you",
    "start": "2024520",
    "end": "2031000"
  },
  {
    "start": "2026000",
    "end": "2031000"
  },
  {
    "text": "have a chance and even I learn more about acai in general or just observability in general as well here's",
    "start": "2031000",
    "end": "2037510"
  },
  {
    "text": "a quite a few people that you follow on Twitter and with that oh okay yes so far",
    "start": "2037510",
    "end": "2043300"
  },
  {
    "text": "as shameless the cell clock I'm also working on a course with Manning to produce to share some right except the",
    "start": "2043300",
    "end": "2049060"
  },
  {
    "text": "experiences with running eight of slam during production so do check it out as well that's supportive thank you Slifer I",
    "start": "2049060",
    "end": "2055840"
  },
  {
    "text": "guess I don't have that anymore thank you [Applause]",
    "start": "2055840",
    "end": "2062960"
  }
]
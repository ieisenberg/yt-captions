[
  {
    "start": "0",
    "end": "53000"
  },
  {
    "text": "so hi everybody my name's Kevin Kemper thanks for coming",
    "start": "8870",
    "end": "14099"
  },
  {
    "text": "today's or this time slot anyway I'll be doing a talk on post grass backup and",
    "start": "14099",
    "end": "20820"
  },
  {
    "text": "recovery methods just a side note if you guys have any questions during the talk",
    "start": "20820",
    "end": "26430"
  },
  {
    "text": "feel free to just throw up your hand or or holler out and we can do questions on",
    "start": "26430",
    "end": "33000"
  },
  {
    "text": "the way and also have some time for questions at the end so we'll do a little bit of an overview we'll talk",
    "start": "33000",
    "end": "39540"
  },
  {
    "text": "about the various backup options and restore options primarily using PG dump",
    "start": "39540",
    "end": "45329"
  },
  {
    "text": "and PG dump all and then we'll look at a little bit in depth of the different",
    "start": "45329",
    "end": "51510"
  },
  {
    "text": "ways that you can do a recovery and then also we'll go into a point in time recovery talk about how how you do the",
    "start": "51510",
    "end": "57989"
  },
  {
    "start": "53000",
    "end": "53000"
  },
  {
    "text": "backups and walk through a step-by-step in terms of a true point in time",
    "start": "57989",
    "end": "63329"
  },
  {
    "text": "recovery so the the main sort of snapshot style dump tools that the",
    "start": "63329",
    "end": "70500"
  },
  {
    "text": "Postgres offers are PG dump and PG dump all PG dump is a tool that is designed",
    "start": "70500",
    "end": "77310"
  },
  {
    "start": "73000",
    "end": "73000"
  },
  {
    "text": "to back up with a variety of options a single database and PG dump all again",
    "start": "77310",
    "end": "84090"
  },
  {
    "text": "with a number of options will dump the entire cluster so PG dump is a dump",
    "start": "84090",
    "end": "90900"
  },
  {
    "text": "utility that creates consistent backups even if the databases in use it's non-blocking although it's not non",
    "start": "90900",
    "end": "99689"
  },
  {
    "text": "resource intensive if you will so even though it's not blocking if you've got a significantly large database and you",
    "start": "99689",
    "end": "107280"
  },
  {
    "text": "kick off a PG dump at you know two o'clock in the afternoon on your busiest",
    "start": "107280",
    "end": "112409"
  },
  {
    "text": "day you're going to see an impact however it's not going to be an impact because tables are block actually it",
    "start": "112409",
    "end": "119130"
  },
  {
    "text": "would be the other way it is possible that the database would have tables blocked long enough that PG dump will",
    "start": "119130",
    "end": "125969"
  },
  {
    "text": "actually timeout and say I can't I can't do the dump at this time again there's a",
    "start": "125969",
    "end": "131459"
  },
  {
    "text": "number of output file up floormats there's a number of options in",
    "start": "131459",
    "end": "136590"
  },
  {
    "text": "terms of what you want to dump and what format you want to dump it and so on and so forth the syntax for PG dump is obviously PG",
    "start": "136590",
    "end": "145650"
  },
  {
    "text": "dump and we pass it connection options which are optional and then we also",
    "start": "145650",
    "end": "152400"
  },
  {
    "text": "compasseth a number of flags would tell it how we want it to operate the connection options are the standard psql",
    "start": "152400",
    "end": "160230"
  },
  {
    "text": "connection options - h4 host - p4 port user and you can",
    "start": "160230",
    "end": "166560"
  },
  {
    "text": "tell - I want you to prompt me for a password with the - W likewise PG dump",
    "start": "166560",
    "end": "171810"
  },
  {
    "text": "and PG dump all will both respect the standard environment variables PG",
    "start": "171810",
    "end": "177150"
  },
  {
    "text": "database PG host PG port and PG user so if those are set that is the variables",
    "start": "177150",
    "end": "185069"
  },
  {
    "text": "that will be used for the connection that PG dump makes to your to your cluster some of the common options these",
    "start": "185069",
    "end": "193769"
  },
  {
    "text": "aren't all the options but some of the more common options for PG dump is the -",
    "start": "193769",
    "end": "198959"
  },
  {
    "text": "a flag says only dump data the - capital",
    "start": "198959",
    "end": "204120"
  },
  {
    "text": "C or the - cache clean version of it effectively puts a drop database command",
    "start": "204120",
    "end": "210930"
  },
  {
    "text": "in the output file and likewise a create database command I'm sorry the clean",
    "start": "210930",
    "end": "217709"
  },
  {
    "text": "just does the drop the - C and the - capital C create will give you a create database command - D will give you",
    "start": "217709",
    "end": "225359"
  },
  {
    "text": "singleton inserts by default PG dump will give you copy statements you can",
    "start": "225359",
    "end": "231750"
  },
  {
    "text": "exclude schemas we can dump only a particular schema the excluded schema is",
    "start": "231750",
    "end": "237840"
  },
  {
    "text": "actually pretty useful if you're running slow nee so slow nee creates its own",
    "start": "237840",
    "end": "243090"
  },
  {
    "text": "schema or schemas depending on how many databases you're replicating and if you do a PG dump of a database that has a",
    "start": "243090",
    "end": "250079"
  },
  {
    "text": "slow niece kima and then try to restore it on another box where slow knees not installed it'll actually fail because",
    "start": "250079",
    "end": "256919"
  },
  {
    "text": "the functions it tries to restore require that the Salone libraries exist so the nice workaround for that is just",
    "start": "256919",
    "end": "264419"
  },
  {
    "text": "don't dump the Salone schema likewise the the schema only flag says",
    "start": "264419",
    "end": "271449"
  },
  {
    "text": "just dump the DDL give me the create table statements and create index and so forth but but I don't want the data you",
    "start": "271449",
    "end": "279490"
  },
  {
    "text": "can specify individual tables or a list of tables so you could say - tea table",
    "start": "279490",
    "end": "285039"
  },
  {
    "text": "name or you could say - tea like part of a table name star you can and that works",
    "start": "285039",
    "end": "292569"
  },
  {
    "text": "or you can give it a comma separated list of tables we can exclude tables in",
    "start": "292569",
    "end": "298449"
  },
  {
    "text": "the same way the verbose flag just gives you some debugging info the format is",
    "start": "298449",
    "end": "304479"
  },
  {
    "text": "pretty important meaning the default format is just to dump you a standard",
    "start": "304479",
    "end": "309520"
  },
  {
    "text": "clear text SQL file and of course the way to restore that is just with P SQL however you can you can give it formats",
    "start": "309520",
    "end": "317169"
  },
  {
    "text": "like there's a custom format and a tar format and tar format is obviously a tar",
    "start": "317169",
    "end": "323199"
  },
  {
    "text": "compressed file and a custom format is a custom compressed binary format and both",
    "start": "323199",
    "end": "329529"
  },
  {
    "text": "the tar in the custom format give you the option of restoring via utility",
    "start": "329529",
    "end": "334539"
  },
  {
    "text": "called PG restore we'll get into that in a few slides but it does open up a world of options",
    "start": "334539",
    "end": "340120"
  },
  {
    "text": "for you in terms of recoverability and in particular flexibility in terms of",
    "start": "340120",
    "end": "346000"
  },
  {
    "text": "what what objects what data structures what data sets you might or might not want to restore it is maintained so all",
    "start": "346000",
    "end": "354490"
  },
  {
    "text": "of the alt all of your referential integrity are pushed to the end of the dump pile so it'll restore the tables",
    "start": "354490",
    "end": "361719"
  },
  {
    "text": "and the primary keys and then it will restore the data and then it restores all the referential integrity likewise",
    "start": "361719",
    "end": "371199"
  },
  {
    "text": "there's a locked time-out wait there is a default I think it's 30 seconds don't quote me on that however that's the",
    "start": "371199",
    "end": "378819"
  },
  {
    "text": "amount of time it's going to wait if Postgres has a lock on a table due to",
    "start": "378819",
    "end": "383949"
  },
  {
    "text": "what an application is doing given that PG dump is non-blocking it's it's going",
    "start": "383949",
    "end": "389139"
  },
  {
    "text": "to wait and if it waits the locked amount amount of time it'll actually exit and say sorry I can't I can't move",
    "start": "389139",
    "end": "395529"
  },
  {
    "text": "forward if the default isn't working for you you could set this to you know something higher like two",
    "start": "395529",
    "end": "402170"
  },
  {
    "text": "minutes or five minutes or whatever to try to get PG dumped more of an opportunity to get itself in the queue",
    "start": "402170",
    "end": "409250"
  },
  {
    "text": "if you l to to grab a dump of that particular table in terms of the file",
    "start": "409250",
    "end": "415940"
  },
  {
    "text": "format options we talked a little bit about this but the default is do a plane to do a plane format so if you don't",
    "start": "415940",
    "end": "422810"
  },
  {
    "text": "specify the - a flag at all you'll get again like I mentioned just a flat clear",
    "start": "422810",
    "end": "428720"
  },
  {
    "text": "text SQL file if you specify the - see that's the custom it's a custom binary",
    "start": "428720",
    "end": "434360"
  },
  {
    "text": "format and likewise the - T is a tar format you can also specify a",
    "start": "434360",
    "end": "439910"
  },
  {
    "text": "compression level with a - Z so when you do either the C or the the T if you",
    "start": "439910",
    "end": "446570"
  },
  {
    "text": "specify compression level you can give it a 0 to 9 of course the trade-off is the higher the compression level the",
    "start": "446570",
    "end": "453980"
  },
  {
    "text": "longer it's going to take to to do your Tom but the more disk disk savings you",
    "start": "453980",
    "end": "460640"
  },
  {
    "text": "get here's a couple of examples so in this top example we're dumping insert",
    "start": "460640",
    "end": "467570"
  },
  {
    "start": "463000",
    "end": "463000"
  },
  {
    "text": "only statements including a create database statement so the - capital C of",
    "start": "467570",
    "end": "473120"
  },
  {
    "text": "course gives us the create the - - inserts gives us insert statements we're",
    "start": "473120",
    "end": "478340"
  },
  {
    "text": "dumping a database called prod one underscore DB and redirecting it to straight SQL file in the second example",
    "start": "478340",
    "end": "485690"
  },
  {
    "text": "we're dumping a table called customer and we're only dumping the data in a",
    "start": "485690",
    "end": "491810"
  },
  {
    "text": "custom format again from the prod 1 DB database and likewise we're redirecting",
    "start": "491810",
    "end": "497870"
  },
  {
    "text": "that to a file called problem D because dot FCM the next example we're dumping",
    "start": "497870",
    "end": "506660"
  },
  {
    "text": "only the DDL of the prod 1 DB database and we're redirecting that to a straight",
    "start": "506660",
    "end": "513440"
  },
  {
    "text": "SQL file and the last example we have here we're dumping the gold schema and",
    "start": "513440",
    "end": "520130"
  },
  {
    "text": "we're doing a tar format of the prod 1 DB database and redirecting that to to a",
    "start": "520130",
    "end": "526160"
  },
  {
    "text": "dump pile questions so far that's just something I made up so it's",
    "start": "526160",
    "end": "532690"
  },
  {
    "text": "just whatever schema we happen to want to dump PG dump all very similar utility",
    "start": "532690",
    "end": "539740"
  },
  {
    "text": "the difference is PG dump all dumps the entire cluster whereas PG dump you",
    "start": "539740",
    "end": "545379"
  },
  {
    "text": "specify a database there are a couple of key components to PG dump all that are",
    "start": "545379",
    "end": "550899"
  },
  {
    "text": "worth noting the connection options are exactly the same a lot of the common",
    "start": "550899",
    "end": "557050"
  },
  {
    "text": "options are the same so the data only and the clean you can do inserts got",
    "start": "557050",
    "end": "563199"
  },
  {
    "text": "Yatta Yatta a couple of key differences here is the - G flag the Global's only",
    "start": "563199",
    "end": "570610"
  },
  {
    "text": "and the - are flag the roles only are pretty pretty useful in scenarios for",
    "start": "570610",
    "end": "576009"
  },
  {
    "text": "example if you're setting up Sloan E and you need to set up your database on the slave you can use PG dump and get all",
    "start": "576009",
    "end": "583329"
  },
  {
    "text": "the DDL and push it across for a particular database and likewise you could use for example the - R to get",
    "start": "583329",
    "end": "589480"
  },
  {
    "text": "just the roles from the master database and push it to the slave or you could do",
    "start": "589480",
    "end": "594519"
  },
  {
    "text": "- G and get all the Global's meaning you get the roles and the tablespaces and all the global structures however just",
    "start": "594519",
    "end": "603430"
  },
  {
    "text": "be aware that if you dump the tablespaces all of course those same paths need to exist on your slave as",
    "start": "603430",
    "end": "609699"
  },
  {
    "text": "well likewise you can tell it I don't want you to put ownership in the file",
    "start": "609699",
    "end": "616350"
  },
  {
    "text": "and I think everything else is mostly the same maybe the superuser is",
    "start": "616350",
    "end": "621430"
  },
  {
    "text": "different so you could specify a different super user that you want to be specified as the owner when you do a",
    "start": "621430",
    "end": "629230"
  },
  {
    "text": "dump all a couple of dump all examples this top one we're doing an entire",
    "start": "629230",
    "end": "634839"
  },
  {
    "text": "cluster dump containing only the global structure so we're doing the - G the",
    "start": "634839",
    "end": "641199"
  },
  {
    "start": "639000",
    "end": "639000"
  },
  {
    "text": "next one we're dumping the only the tablespaces and likewise the third",
    "start": "641199",
    "end": "646540"
  },
  {
    "text": "example we're dumping a dump of the cluster without any tablespace references on the final example we're",
    "start": "646540",
    "end": "653350"
  },
  {
    "text": "dumping the cluster and we're talented use the superuser gold user and we're",
    "start": "653350",
    "end": "659319"
  },
  {
    "text": "giving it a lock wait timeout of 30 seconds so if we wait more than thirty seconds on a lock it well abort",
    "start": "659319",
    "end": "667110"
  },
  {
    "text": "any questions yes jump to a tape so PG dump and PG dump",
    "start": "667110",
    "end": "674350"
  },
  {
    "text": "all inherently the question was is there any media manager support that allows us",
    "start": "674350",
    "end": "679540"
  },
  {
    "text": "to dump two tape and the short answer is no PG dump and PG dump all don't support",
    "start": "679540",
    "end": "685980"
  },
  {
    "text": "the media protocols within the tool itself however we have done some work",
    "start": "685980",
    "end": "692880"
  },
  {
    "text": "where we did go to tape and basically it's a two-step process so we we either",
    "start": "692880",
    "end": "698860"
  },
  {
    "text": "go to disk and then from disk we have a command script that pushes that to tape",
    "start": "698860",
    "end": "705280"
  },
  {
    "text": "or in what we did is in one scenario is we did the PG dump and we'll pipe that",
    "start": "705280",
    "end": "712420"
  },
  {
    "text": "to the tape commands and it sends it straight on to the tape however it's you have to go to the UNIX command line and",
    "start": "712420",
    "end": "718870"
  },
  {
    "text": "and write your own if you will so restore options that obviously when",
    "start": "718870",
    "end": "724720"
  },
  {
    "text": "we're doing PG dump and PG dump all our restore options are psql",
    "start": "724720",
    "end": "730120"
  },
  {
    "text": "for the flat SQL files or we can use PG restore and it has a number of options and it gives us a fair amount of",
    "start": "730120",
    "end": "736900"
  },
  {
    "start": "731000",
    "end": "731000"
  },
  {
    "text": "flexibility in terms of how we want to restore what we want to restore with",
    "start": "736900",
    "end": "742810"
  },
  {
    "text": "psql of course if we've got just a flat straight SQL file we can do here's a",
    "start": "742810",
    "end": "748540"
  },
  {
    "start": "747000",
    "end": "747000"
  },
  {
    "text": "couple examples psql - EF of the SQL file and in this case the first example",
    "start": "748540",
    "end": "755920"
  },
  {
    "text": "we're just redirecting the output to a log file and in this case we also didn't",
    "start": "755920",
    "end": "763150"
  },
  {
    "text": "give it a database name so the assumption is that we're we're connecting to the default database which",
    "start": "763150",
    "end": "768370"
  },
  {
    "text": "is going to be set by the PG database environment variable likewise were",
    "start": "768370",
    "end": "773860"
  },
  {
    "text": "here's an example where we did a PG dump and we dumped the prod 1 DB database and",
    "start": "773860",
    "end": "779830"
  },
  {
    "text": "we're simply piping that to P SQL - H and redirecting that to our QA server in",
    "start": "779830",
    "end": "786760"
  },
  {
    "text": "this case there's another PG dump all we're dumping only the Global's and",
    "start": "786760",
    "end": "791950"
  },
  {
    "text": "we're passing that to a psql - H of our dev server and we're given it a different port and",
    "start": "791950",
    "end": "798000"
  },
  {
    "text": "we're logging it this is pretty similar to what we would do with Sloane II is you know we would do the PG dumb Paul -",
    "start": "798000",
    "end": "805230"
  },
  {
    "text": "T on the master and pipe it to psql - H for the slave that we're setting up and",
    "start": "805230",
    "end": "811530"
  },
  {
    "text": "then we'd come back and do the DDL likewise the last example we're doing a PG dump of the prod one database and",
    "start": "811530",
    "end": "818610"
  },
  {
    "text": "piping that to psql on the test database and then we're we're logging it so pretty pretty",
    "start": "818610",
    "end": "824820"
  },
  {
    "text": "standard stuff in terms of restoring from P SQL files or dot SQL files PG",
    "start": "824820",
    "end": "832080"
  },
  {
    "text": "restore is utility that gives us enormous amount of flexibility the",
    "start": "832080",
    "end": "837990"
  },
  {
    "text": "connection options are the same it respects the same environment variables just like PG dump and PG dump all do",
    "start": "837990",
    "end": "844530"
  },
  {
    "text": "some of the common options / PG restore are number one we've always got to give",
    "start": "844530",
    "end": "850110"
  },
  {
    "text": "it a database name so we give a - D or - - database or I'm sorry - - DB name and",
    "start": "850110",
    "end": "857040"
  },
  {
    "text": "we give it the database name we can tell it for example I could do a PG dump and",
    "start": "857040",
    "end": "863670"
  },
  {
    "text": "pipe that or set it to a custom pile or a tar file and I could take that tar",
    "start": "863670",
    "end": "868680"
  },
  {
    "text": "file even though it's a full dump of the database so all the DDL indexes data",
    "start": "868680",
    "end": "874290"
  },
  {
    "text": "everything and on with PG restore I can give it a - a and say I only want you to",
    "start": "874290",
    "end": "879540"
  },
  {
    "text": "restore the data because I've you know I've already installed the DDL and so on and so forth like guys we can do the",
    "start": "879540",
    "end": "887790"
  },
  {
    "text": "clean and the create just like I'm on the way out if you well with PG dump we",
    "start": "887790",
    "end": "894420"
  },
  {
    "text": "can specify individual indexes so if we just wanted to restore a couple of",
    "start": "894420",
    "end": "899700"
  },
  {
    "text": "indexes from a dump file we could do that we can restore only the DDL we can",
    "start": "899700",
    "end": "906630"
  },
  {
    "text": "restore individual schemas we can tell it to disable the triggers when we do the restore so on and so forth a lot of",
    "start": "906630",
    "end": "915450"
  },
  {
    "text": "the a lot of the the flags are the same but it provides I think an extra amount",
    "start": "915450",
    "end": "922380"
  },
  {
    "text": "if you will of flexibility when you go to recover so it doesn't mean that you have to recover it's not all or nothing",
    "start": "922380",
    "end": "930760"
  },
  {
    "text": "likewise we can specify individual tables individual triggers and you do",
    "start": "930760",
    "end": "937490"
  },
  {
    "text": "have to specify the - F and tell it is this a custom file or is it a tar",
    "start": "937490",
    "end": "942620"
  },
  {
    "text": "formatted file no it won't the other",
    "start": "942620",
    "end": "950270"
  },
  {
    "text": "thing if you notice the last couple of items here the - Al and the - capital L",
    "start": "950270",
    "end": "955690"
  },
  {
    "text": "this gives you a really powerful way to create an enormous amount of flexibility",
    "start": "955690",
    "end": "961130"
  },
  {
    "text": "in terms of what you might want to recover and we'll get to that here momentarily so here's a couple of",
    "start": "961130",
    "end": "966589"
  },
  {
    "text": "restore examples this first one restores the data only from a custom formatted file and we're",
    "start": "966589",
    "end": "973610"
  },
  {
    "start": "967000",
    "end": "967000"
  },
  {
    "text": "restoring it into a database called prod to underscore dB so we're given it the PG restore the - a",
    "start": "973610",
    "end": "980330"
  },
  {
    "text": "to say only restore the data we're counted it's a custom formatted file we're specifying the database name",
    "start": "980330",
    "end": "988040"
  },
  {
    "text": "and then we're given at the dump pile likewise the second one does it clean so",
    "start": "988040",
    "end": "993980"
  },
  {
    "text": "it removes the data and the structures first and then it restores only the gold",
    "start": "993980",
    "end": "999020"
  },
  {
    "text": "partner's schema from at our formatted file and the final example we're",
    "start": "999020",
    "end": "1004570"
  },
  {
    "text": "restoring only the DDL ie the schema only into the QA one underscore DB file",
    "start": "1004570",
    "end": "1012839"
  },
  {
    "text": "from a custom formatted dump file and the dash J did we have it on this slide",
    "start": "1012839",
    "end": "1021329"
  },
  {
    "text": "the jobs that's actually a parallel restore feature so if I've got a",
    "start": "1021329",
    "end": "1028230"
  },
  {
    "text": "database and let's say just for simplicity I've got a thousand tables if",
    "start": "1028230",
    "end": "1033428"
  },
  {
    "text": "I specify - J and give it ten it'll actually create ten parallel jobs and it",
    "start": "1033429",
    "end": "1039640"
  },
  {
    "text": "will split those thousands tables up you know a hundred per job and it will run",
    "start": "1039640",
    "end": "1045819"
  },
  {
    "text": "all ten jobs in parallel so what used to take in previous versions of Postgres",
    "start": "1045819",
    "end": "1051490"
  },
  {
    "text": "eight hours to restore we could potentially restore in two hours or thirty minutes or so depending on",
    "start": "1051490",
    "end": "1060970"
  },
  {
    "text": "how much parallelism your machine can handle so the next big feature with the",
    "start": "1060970",
    "end": "1067480"
  },
  {
    "text": "PG restore is using table of table of contents files and that's the - L and",
    "start": "1067480",
    "end": "1073960"
  },
  {
    "text": "the - capital L that I mentioned earlier so if we have a dump and we've dumped it",
    "start": "1073960",
    "end": "1079120"
  },
  {
    "start": "1075000",
    "end": "1075000"
  },
  {
    "text": "to either a tar or a custom formatted file you can run a PG restore on it and",
    "start": "1079120",
    "end": "1085390"
  },
  {
    "text": "you can in this case if you look at the second example here we're doing a first",
    "start": "1085390",
    "end": "1091210"
  },
  {
    "text": "we do a PG dump and we're doing at our formatted file and then we run PG restore and we give it a - L on that",
    "start": "1091210",
    "end": "1098100"
  },
  {
    "text": "dump file and then we're redirecting that to an output file what's going to get redirected into that output file is",
    "start": "1098100",
    "end": "1104590"
  },
  {
    "text": "a table of contents of what's in that dump and here's sort of an example of",
    "start": "1104590",
    "end": "1111429"
  },
  {
    "start": "1111000",
    "end": "1111000"
  },
  {
    "text": "what you would see in that file so the semicolons or comments so you get a",
    "start": "1111429",
    "end": "1116530"
  },
  {
    "text": "header that talks about how many entries are in this file and when was it created and so on and so forth and then likewise",
    "start": "1116530",
    "end": "1124030"
  },
  {
    "text": "you'll get an entry for every object in that file so if we look at this example",
    "start": "1124030",
    "end": "1131309"
  },
  {
    "text": "there's a crease effectively a crate schema there's a comment on the schema",
    "start": "1131309",
    "end": "1138970"
  },
  {
    "text": "there's a access control setting the permissions to be owned by Postgres",
    "start": "1138970",
    "end": "1144000"
  },
  {
    "text": "there's a public DB mon thresh table that's owned by Postgres and so on and",
    "start": "1144000",
    "end": "1150940"
  },
  {
    "text": "so forth a little further down there's some set commands and there's a couple of data commands they're specifying",
    "start": "1150940",
    "end": "1156909"
  },
  {
    "text": "these are the actual data restores as opposed to the table that ETL restore and there will be index entries in here",
    "start": "1156909",
    "end": "1164169"
  },
  {
    "text": "and and referential foreign key entries and so on and so forth so the way to",
    "start": "1164169",
    "end": "1170799"
  },
  {
    "text": "deal with a table of contents file is you could effectively go into that file and comment out anything you don't want",
    "start": "1170799",
    "end": "1177520"
  },
  {
    "text": "to restore and create a very custom restore if you out so you could restore",
    "start": "1177520",
    "end": "1182830"
  },
  {
    "text": "in a set of specific tables and only restore data on some of those tables and",
    "start": "1182830",
    "end": "1188350"
  },
  {
    "text": "and restore indexes on all of them but not the foreign keys on some of and so on and so forth and then when you",
    "start": "1188350",
    "end": "1194530"
  },
  {
    "text": "run the PG dump using the table of contents file you get a very customized restore scenario what I used to do with",
    "start": "1194530",
    "end": "1204160"
  },
  {
    "text": "this before we had parallel restore is I would take the table of contents file and split it up into multiple files and",
    "start": "1204160",
    "end": "1212110"
  },
  {
    "text": "create my own parallel restore which we don't need anymore but now it's kind of a cool feature as well here's a couple",
    "start": "1212110",
    "end": "1220030"
  },
  {
    "text": "of examples so we do a PG dump to a tar formatted file and then we run the PG",
    "start": "1220030",
    "end": "1226480"
  },
  {
    "start": "1221000",
    "end": "1221000"
  },
  {
    "text": "restore on that creating the list file and then we create this queue adb 3",
    "start": "1226480",
    "end": "1231880"
  },
  {
    "text": "database we added the less file according to what we want to restore and",
    "start": "1231880",
    "end": "1237130"
  },
  {
    "text": "then we run the PG restore with a - capital L and give it the name of the",
    "start": "1237130",
    "end": "1242140"
  },
  {
    "text": "list file and then give it the rest of the parameters as normal and it will restore only the the data structures and",
    "start": "1242140",
    "end": "1251380"
  },
  {
    "text": "the objects that are referenced in the list file any questions on the question",
    "start": "1251380",
    "end": "1258280"
  },
  {
    "text": "was are all these features available and generic Postgres vs. et B's Advanced",
    "start": "1258280",
    "end": "1263800"
  },
  {
    "text": "Server the answer is yes this is generic Postgres any other questions",
    "start": "1263800",
    "end": "1269380"
  },
  {
    "text": "so the question what are the advantages of the custom file number one it's",
    "start": "1269380",
    "end": "1275740"
  },
  {
    "text": "compressed and number two it's a binary file so it's a more efficient restore because it's binary and then of course",
    "start": "1275740",
    "end": "1282190"
  },
  {
    "text": "just the compression so next we'll talk about point in time recovery so Postgres",
    "start": "1282190",
    "end": "1289860"
  },
  {
    "text": "doesn't necessarily have a way of saying by the way just turn point in time",
    "start": "1289860",
    "end": "1297220"
  },
  {
    "text": "recovery on and let me deal with it later however it does have all the",
    "start": "1297220",
    "end": "1302320"
  },
  {
    "text": "building blocks to let us put point in time recovery in place and leverage a",
    "start": "1302320",
    "end": "1307780"
  },
  {
    "text": "fair amount of flexibility in terms of how we want to recover recovery time so the basic things we need to do for a",
    "start": "1307780",
    "end": "1316240"
  },
  {
    "text": "point in time recovery is number one we need to do point in time recovery based backups which would effectively be the",
    "start": "1316240",
    "end": "1324070"
  },
  {
    "text": "equivalent of say a level zero back up and then likewise you need to tell the the database server or your cluster",
    "start": "1324070",
    "end": "1331700"
  },
  {
    "text": "to archive the wall segments meaning every time one of your transaction logs gets full we need an archived copy of",
    "start": "1331700",
    "end": "1338540"
  },
  {
    "text": "that transaction log the combination of those two items that the effectively",
    "start": "1338540",
    "end": "1343910"
  },
  {
    "text": "level 0 backup and some number of archived transaction logs allows us to",
    "start": "1343910",
    "end": "1349550"
  },
  {
    "text": "recover to any point in time we define likewise for a point in time recovery",
    "start": "1349550",
    "end": "1356410"
  },
  {
    "text": "basically restore the lathe the latest base backup or the latest base backup",
    "start": "1356410",
    "end": "1362900"
  },
  {
    "text": "that we want to leverage for our recovery you have to do a little bit of preparation in the system data directory",
    "start": "1362900",
    "end": "1369370"
  },
  {
    "text": "and one of those things is we create a file called recovery comp and basically",
    "start": "1369370",
    "end": "1376220"
  },
  {
    "text": "after we've identified how we want to recover basically you need to tell the recovery comp file where do where do I",
    "start": "1376220",
    "end": "1383630"
  },
  {
    "text": "find the wall segments the archived transaction logs and to what point in time in its most simple terms",
    "start": "1383630",
    "end": "1390650"
  },
  {
    "text": "do I want to recover two and then you start the postmaster the postmaster will",
    "start": "1390650",
    "end": "1395780"
  },
  {
    "text": "find the recovery comp file it'll automatically roll into recovery mode and once it's finished it'll rename the",
    "start": "1395780",
    "end": "1403340"
  },
  {
    "text": "recovery file to recovery got done and he'll come online it's a fairly",
    "start": "1403340",
    "end": "1409420"
  },
  {
    "text": "straightforward process it's pretty simple to be honest so in order to do",
    "start": "1409420",
    "end": "1417590"
  },
  {
    "start": "1414000",
    "end": "1414000"
  },
  {
    "text": "the backups here's sort of a walkthrough so in this case we go into our",
    "start": "1417590",
    "end": "1423320"
  },
  {
    "text": "PostgreSQL comp file and there's a couple of key parameters we need to change so one is we need to turn archive",
    "start": "1423320",
    "end": "1430280"
  },
  {
    "text": "mode to on by default archive mode is off and changing archive mode requires",
    "start": "1430280",
    "end": "1436670"
  },
  {
    "text": "that we restart the database server likewise we need to give it an archive command the archive command can be any",
    "start": "1436670",
    "end": "1447140"
  },
  {
    "text": "valid shell script or I'm sorry any valid OS command so if you're running on",
    "start": "1447140",
    "end": "1452630"
  },
  {
    "text": "Linux it can be a copy statement like we have here it could be in our sink it",
    "start": "1452630",
    "end": "1457790"
  },
  {
    "text": "could be an SCP it you could reference a shell script any valid OS command can go in there",
    "start": "1457790",
    "end": "1463940"
  },
  {
    "text": "effectively what we're trying to tell the database is I'm going to reference",
    "start": "1463940",
    "end": "1469400"
  },
  {
    "text": "via the percent P variable which means that's the full path to the actual",
    "start": "1469400",
    "end": "1475360"
  },
  {
    "text": "source wall segment meaning the transaction log and the percent F is the name of the file that it's going to give",
    "start": "1475360",
    "end": "1481760"
  },
  {
    "text": "to the wall segment so by using those two variables we effectively try to tell the database engine I want you to move",
    "start": "1481760",
    "end": "1488390"
  },
  {
    "text": "the percent P file to some other location and that location can be whatever you want in this case we're",
    "start": "1488390",
    "end": "1495620"
  },
  {
    "text": "doing a simple copy and we're copying it to a directory called slash stage slash wall in a lot of cases I've seen in fact",
    "start": "1495620",
    "end": "1504680"
  },
  {
    "text": "even with our shop we've done SCPs or we've done our sinks which effectively",
    "start": "1504680",
    "end": "1510230"
  },
  {
    "text": "move the wall the wall segments the archived transaction logs off of the main database server onto a backup",
    "start": "1510230",
    "end": "1517970"
  },
  {
    "text": "server somewhere and that way in case of a disaster if the disaster were",
    "start": "1517970",
    "end": "1523420"
  },
  {
    "text": "significant enough that the discs were irrecoverable we haven't lost all of our",
    "start": "1523420",
    "end": "1529670"
  },
  {
    "text": "wall segments with the crash likewise there's a there's a variable called",
    "start": "1529670",
    "end": "1535160"
  },
  {
    "text": "archive timeout in most cases we leave this to zero however if you tweak it",
    "start": "1535160",
    "end": "1540440"
  },
  {
    "text": "what it'll do is let's say you set it to 30 seconds what that will do is every 30",
    "start": "1540440",
    "end": "1545930"
  },
  {
    "text": "seconds it will make sure that if it hasn't already in the last 30 seconds it will archive the current transaction log",
    "start": "1545930",
    "end": "1553430"
  },
  {
    "text": "where this is useful as if you've got a database server that the traffic is",
    "start": "1553430",
    "end": "1558800"
  },
  {
    "text": "light enough that you only rotate transaction logs like once a week and",
    "start": "1558800",
    "end": "1564770"
  },
  {
    "text": "you don't want you know half a week's worth of transactions even though it's not all that many you don't want those",
    "start": "1564770",
    "end": "1570950"
  },
  {
    "text": "transactions sitting in the transaction log for that amount of time on archived",
    "start": "1570950",
    "end": "1576320"
  },
  {
    "text": "in the case of a disaster there is a way to if you can still get back to your",
    "start": "1576320",
    "end": "1583190"
  },
  {
    "text": "original directory tree where your database lived in a crash scenario where",
    "start": "1583190",
    "end": "1588260"
  },
  {
    "text": "you could recover those but it's not a guarantee so that's a that's an nice feature if you have a light traffic",
    "start": "1588260",
    "end": "1594590"
  },
  {
    "text": "machine the archived command and the archived timeout values can both be",
    "start": "1594590",
    "end": "1599600"
  },
  {
    "text": "changed by doing a reload as opposed to a restart of the database server so for",
    "start": "1599600",
    "end": "1609680"
  },
  {
    "text": "an example we would do a make der on the stage wall directory we would make sure",
    "start": "1609680",
    "end": "1616490"
  },
  {
    "text": "that that directory is owned by Postgres and assuming we had already made the",
    "start": "1616490",
    "end": "1621800"
  },
  {
    "text": "these three changes we would go ahead and restart the server once that's done",
    "start": "1621800",
    "end": "1627710"
  },
  {
    "text": "if we were in a let's test this scenario we would want to create some transactions generate some volume at",
    "start": "1627710",
    "end": "1634280"
  },
  {
    "text": "that point we should start to see files show up in the stage wall directory and they they have a long name but they're",
    "start": "1634280",
    "end": "1640760"
  },
  {
    "text": "effectively archived version of your transaction logs the transaction logs",
    "start": "1640760",
    "end": "1646550"
  },
  {
    "text": "are copied when one of two events takes place either your I'm sorry the wall",
    "start": "1646550",
    "end": "1652460"
  },
  {
    "text": "segments are copied when either the transaction log is full and it gets ready to rotate to the next log or when",
    "start": "1652460",
    "end": "1659870"
  },
  {
    "text": "the number of seconds specified in our archived timeout has passed so the next",
    "start": "1659870",
    "end": "1666410"
  },
  {
    "text": "step would be we're archiving the transaction logs or database servers back online now we need",
    "start": "1666410",
    "end": "1672800"
  },
  {
    "text": "to do our base backup or our level 0 backup so what you would do is connect",
    "start": "1672800",
    "end": "1677870"
  },
  {
    "text": "to Postgres and execute the function PG start back up PG start back up requires",
    "start": "1677870",
    "end": "1683750"
  },
  {
    "text": "a single parameter which is a tag and it doesn't matter what you put in that tag generally when I do this I'll put in the",
    "start": "1683750",
    "end": "1690920"
  },
  {
    "text": "date as a string however you can put whatever you want in that tag and there is some value in terms of having a",
    "start": "1690920",
    "end": "1700600"
  },
  {
    "text": "formal naming convention for that tag in extremely rare scenarios you get into a",
    "start": "1700600",
    "end": "1706610"
  },
  {
    "text": "place where you might not be able to recover based on a normal time line or",
    "start": "1706610",
    "end": "1712700"
  },
  {
    "text": "the actual time line that took place and you have to go back to previous baseline",
    "start": "1712700",
    "end": "1718610"
  },
  {
    "text": "backups and in those cases you get into a scenario where it's important to understand what tag you gave it",
    "start": "1718610",
    "end": "1725510"
  },
  {
    "text": "in most cases you'll never deal with it but it is important to stick with a",
    "start": "1725510",
    "end": "1730820"
  },
  {
    "text": "naming convention in case you ever get backed into a corner in a recovery scenario likewise so we run the just",
    "start": "1730820",
    "end": "1740330"
  },
  {
    "text": "like any function we run select PG start back up and then once that comes back we",
    "start": "1740330",
    "end": "1745730"
  },
  {
    "text": "go ahead and we archive all of the directories that are associated with the database so if you have your database",
    "start": "1745730",
    "end": "1753740"
  },
  {
    "text": "for example installed in VAR live PG SQL data you would effectively backup the",
    "start": "1753740",
    "end": "1759980"
  },
  {
    "text": "dative directory also if you have external table spaces let's say you have a file system called /pg data and in",
    "start": "1759980",
    "end": "1769730"
  },
  {
    "text": "there you've created several external table spaces you also need to back that up so any any parts of the file system",
    "start": "1769730",
    "end": "1776330"
  },
  {
    "text": "where you have Postgres data installed is what you want to backup you can back",
    "start": "1776330",
    "end": "1782419"
  },
  {
    "text": "it up with tar you could R sync it to another box you could SCP it it really doesn't matter just back it up once",
    "start": "1782419",
    "end": "1790429"
  },
  {
    "text": "you're finished with the backup then you connect to the database server again and you execute the function PG stop backup",
    "start": "1790429",
    "end": "1797210"
  },
  {
    "text": "PG stop backup doesn't take any parameters and effectively what you're",
    "start": "1797210",
    "end": "1802580"
  },
  {
    "text": "telling the database is this is the point in time where I started and when I finish doing the actual file system copy",
    "start": "1802580",
    "end": "1808820"
  },
  {
    "text": "for my base backup then of course if we were testing this we would want to",
    "start": "1808820",
    "end": "1815450"
  },
  {
    "text": "generate some more transactions make sure that we had transaction logs that were archived on both sides of the",
    "start": "1815450",
    "end": "1821690"
  },
  {
    "text": "backup just to make sure we're fully testing the scenario and then we roll",
    "start": "1821690",
    "end": "1827779"
  },
  {
    "text": "into recovery so let's say our database crashes or we want to create another instance on take a cue a box or what",
    "start": "1827779",
    "end": "1834950"
  },
  {
    "text": "have you the first thing you want to do in the case of a crash is if you're able",
    "start": "1834950",
    "end": "1840830"
  },
  {
    "text": "to still get to the original data directory you want to get in there and copy the PGX log directory and save it",
    "start": "1840830",
    "end": "1847580"
  },
  {
    "text": "off somewhere if if you can get to it what that will buy us is any",
    "start": "1847580",
    "end": "1852950"
  },
  {
    "text": "transactions that were in that last transaction log that didn't have a chance to get archived",
    "start": "1852950",
    "end": "1858250"
  },
  {
    "text": "we'll have an opportunity to restore those transactions and in that case if we were doing a full recovery of",
    "start": "1858250",
    "end": "1864970"
  },
  {
    "text": "everything we weren't specifying a time stamp we would recover anything that had been committed and we would only lose",
    "start": "1864970",
    "end": "1871630"
  },
  {
    "text": "uncommitted transactions if however your disk is just unusable you can't get to",
    "start": "1871630",
    "end": "1878650"
  },
  {
    "text": "it at all then you're going to lose not only uncommitted transactions but any transactions that were in that last",
    "start": "1878650",
    "end": "1884919"
  },
  {
    "text": "transaction log number two here ensure",
    "start": "1884919",
    "end": "1890500"
  },
  {
    "text": "that the postmaster is not running that's key if you are able to get back to disk and you had some catastrophe",
    "start": "1890500",
    "end": "1897070"
  },
  {
    "text": "take place but you're rebuilding the database server back onto the same box",
    "start": "1897070",
    "end": "1902250"
  },
  {
    "text": "in most cases you're going to it's likely that you will have rebooted that",
    "start": "1902250",
    "end": "1907570"
  },
  {
    "text": "box in between but that's not a guarantee either so make sure that the there are no orphaned or in some other",
    "start": "1907570",
    "end": "1915669"
  },
  {
    "text": "way non-responsive postmaster processes running on the box likewise if if we were able to copy the",
    "start": "1915669",
    "end": "1924340"
  },
  {
    "text": "original data directory I'm sorry if we can copy the original data directory we",
    "start": "1924340",
    "end": "1930909"
  },
  {
    "text": "want to copy that however what we're doing is oh I'm sorry I covered that",
    "start": "1930909",
    "end": "1936490"
  },
  {
    "text": "we're just going after the the PGX log directory so if you look at the documentation it talks about copying the",
    "start": "1936490",
    "end": "1943360"
  },
  {
    "start": "1938000",
    "end": "1938000"
  },
  {
    "text": "data directory the original one but in reality all you need is the PGX log directory nothing else is going to be a",
    "start": "1943360",
    "end": "1949900"
  },
  {
    "text": "benefit to you in that directory at this point if we were doing in our sync then",
    "start": "1949900",
    "end": "1957010"
  },
  {
    "text": "we can skip these next two steps however if we for example say we tarred up when",
    "start": "1957010",
    "end": "1962500"
  },
  {
    "text": "we did our base backup the directories and then move that tar file to another box obviously we want to remove the data",
    "start": "1962500",
    "end": "1970750"
  },
  {
    "text": "directory in any tablespace directories and that would be if we're covering back to the same box and then we want to",
    "start": "1970750",
    "end": "1977470"
  },
  {
    "text": "restore our last system backup effectively what we're looking to do here is take our base backup and lay it",
    "start": "1977470",
    "end": "1984429"
  },
  {
    "text": "down on disk in the same way that it looked like on the server that crashed so whether that's not back onto the same",
    "start": "1984429",
    "end": "1991700"
  },
  {
    "text": "physical box or not it doesn't matter but you want to lay things down in the same fashion so if you backed up",
    "start": "1991700",
    "end": "1998750"
  },
  {
    "text": "everything from a data directory you say it's invar live data you it's it's to",
    "start": "1998750",
    "end": "2005470"
  },
  {
    "text": "your best advantage to keep it simple to lay that back into a directory VAR live data it's not required there are some",
    "start": "2005470",
    "end": "2012639"
  },
  {
    "text": "tweaks you can do to to make it come up in a different directory path configuration but in some cases it",
    "start": "2012639",
    "end": "2019360"
  },
  {
    "text": "requires you to go in and and tweak some things so anyway you uncompress your",
    "start": "2019360",
    "end": "2026889"
  },
  {
    "text": "backup or whatever you need to do to restore your base backup and key things",
    "start": "2026889",
    "end": "2033429"
  },
  {
    "text": "or you want to make sure that your permissions are retained and you want to make sure that if you've created external tablespaces that the symbolic",
    "start": "2033429",
    "end": "2040000"
  },
  {
    "text": "links in the PG tablespace directory which is in the Postgres cluster data",
    "start": "2040000",
    "end": "2046000"
  },
  {
    "text": "directory make sure that those are still appropriate so for example if you had table spaces on the original box and",
    "start": "2046000",
    "end": "2052888"
  },
  {
    "text": "they were mounted let's say on a sand and your mount point on that box with /pg data but when you set up your",
    "start": "2052889",
    "end": "2061358"
  },
  {
    "text": "recovery box the SAS gave you a mount that says /pg data - that's ok but you",
    "start": "2061359",
    "end": "2068589"
  },
  {
    "text": "need to go into your PG tablespace directory and reset those table tablespace links they're just soft links",
    "start": "2068589",
    "end": "2076569"
  },
  {
    "text": "in the directory they're not hard to figure out but you need to make sure that those are appropriate next thing",
    "start": "2076569",
    "end": "2084550"
  },
  {
    "text": "you want to do is in the data directory that you just recovered you restored your tarp file or what have you go into",
    "start": "2084550",
    "end": "2091148"
  },
  {
    "text": "the PGX log directory and we need to get rid of everything with the exception of there's a directory within that",
    "start": "2091149",
    "end": "2097839"
  },
  {
    "text": "directory the only thing you want to leave is the PGX log directory itself and the PGX log slash archive status",
    "start": "2097839",
    "end": "2106660"
  },
  {
    "text": "directory the reason is you took that base backup let's say two weeks ago that",
    "start": "2106660",
    "end": "2113740"
  },
  {
    "text": "PGX log directory is in the state of when you took that backup so to leave",
    "start": "2113740",
    "end": "2119829"
  },
  {
    "text": "those uncommitted or I'm sorry unarchive transactions in the same state as the",
    "start": "2119829",
    "end": "2125079"
  },
  {
    "text": "point time you took the backup will just confuse the issue so get rid of everything in there the next thing you",
    "start": "2125079",
    "end": "2131140"
  },
  {
    "text": "do is if you are able to save your original PGX log directory you would effectively copy that straight into",
    "start": "2131140",
    "end": "2137609"
  },
  {
    "text": "what's now your new PGX log directory that's what's going to allow you to recover any transactions that have been",
    "start": "2137609",
    "end": "2144640"
  },
  {
    "text": "committed but not yet archived next thing we do is we create a file in the",
    "start": "2144640",
    "end": "2152109"
  },
  {
    "text": "data directory called recovery comm and we'll go over the options for that in a",
    "start": "2152109",
    "end": "2157119"
  },
  {
    "text": "couple slides as an option and I always do this I will modify the PG hbo.com to",
    "start": "2157119",
    "end": "2163990"
  },
  {
    "text": "lock everybody out that I possibly can so I'll lock everyone out except for the",
    "start": "2163990",
    "end": "2170140"
  },
  {
    "text": "Postgres user for local connections so unfortunately if the there's",
    "start": "2170140",
    "end": "2175650"
  },
  {
    "text": "applications or jobs on the local server that run as Postgres and connect locally",
    "start": "2175650",
    "end": "2181480"
  },
  {
    "text": "they're still going to try to connect the only downside it's not a big deal but the only downside to that is every",
    "start": "2181480",
    "end": "2187960"
  },
  {
    "text": "time someone tries to connect when you're running a recovery the application gets an error back and you",
    "start": "2187960",
    "end": "2193960"
  },
  {
    "text": "get some entries in the logs for these errors so if there's a lot of connections trying to pain the database",
    "start": "2193960",
    "end": "2199869"
  },
  {
    "text": "server while you're trying to monitor progress you start to have to filter through all these error messages which",
    "start": "2199869",
    "end": "2205540"
  },
  {
    "text": "just becomes a pain it's not a problem per se it's just not helpful then you",
    "start": "2205540",
    "end": "2212619"
  },
  {
    "text": "start the server the server will find the recovery I'll it'll roll into recovery mode if you tail the Postgres",
    "start": "2212619",
    "end": "2220390"
  },
  {
    "text": "log or if you're going to syslog if you tell the VAR log messages or wherever you're pushing your Postgres logs you",
    "start": "2220390",
    "end": "2228280"
  },
  {
    "text": "will see the recovery in action and once it's finished it'll rename the recovery comp to recovery not done and",
    "start": "2228280",
    "end": "2234550"
  },
  {
    "text": "it will come online you'd want to poke around as DBA and just make sure that",
    "start": "2234550",
    "end": "2241450"
  },
  {
    "text": "the data looks good that maybe do some counts make sure that everything looks kosher and then if you did option 8 here",
    "start": "2241450",
    "end": "2250510"
  },
  {
    "text": "you'd want to go ahead and restore the hbo.com file to its original state and",
    "start": "2250510",
    "end": "2256510"
  },
  {
    "text": "at that point everybody's good to go one should be able to connect and your",
    "start": "2256510",
    "end": "2261520"
  },
  {
    "text": "data should be as you specified in the recovery comp file in the recovery not",
    "start": "2261520",
    "end": "2267270"
  },
  {
    "text": "file there's a couple of key parameters we need to specify one of them is the",
    "start": "2267270",
    "end": "2273849"
  },
  {
    "text": "actual restore command so in our case we when we archive our wall segments we",
    "start": "2273849",
    "end": "2280540"
  },
  {
    "text": "were copying from the internal Postgres data directory to a directory called slash stage / wall so the assumption is",
    "start": "2280540",
    "end": "2288310"
  },
  {
    "text": "that we still have a slash stage / wall on this box or we've mounted it so it's",
    "start": "2288310",
    "end": "2294130"
  },
  {
    "text": "still that same name so in this case the the first restore command you see here",
    "start": "2294130",
    "end": "2299770"
  },
  {
    "text": "is just a simple copy / stage / wall / % F which is the wall segment file name",
    "start": "2299770",
    "end": "2306970"
  },
  {
    "text": "and we're copying it to % P which is the internal transaction log location",
    "start": "2306970",
    "end": "2313530"
  },
  {
    "text": "inclusive of its full path likewise the restore command could be a shell script",
    "start": "2313530",
    "end": "2318880"
  },
  {
    "text": "and you could do some additional checking before you actually pass that",
    "start": "2318880",
    "end": "2324640"
  },
  {
    "text": "or move that file to its right location it could be an SCP command it really",
    "start": "2324640",
    "end": "2331630"
  },
  {
    "text": "doesn't matter just like with archiving the wall segments this can be any valid OS command that well at the end of it",
    "start": "2331630",
    "end": "2338609"
  },
  {
    "text": "actually moved the wall segment into the transaction log directory Postgres will",
    "start": "2338609",
    "end": "2344619"
  },
  {
    "text": "actually call this command for every file that it knows it needs and it will",
    "start": "2344619",
    "end": "2350680"
  },
  {
    "text": "pass in the appropriate values for the % F than the % P each time there's also a",
    "start": "2350680",
    "end": "2358589"
  },
  {
    "text": "variable you can specify a recovery target time if you leave this out the",
    "start": "2358589",
    "end": "2364450"
  },
  {
    "text": "default is to recover everything it can find however if you put a timestamp in",
    "start": "2364450",
    "end": "2369700"
  },
  {
    "text": "here it will recover up to inclusive of any transactions that were committed on",
    "start": "2369700",
    "end": "2376540"
  },
  {
    "text": "or before that timestamp likewise",
    "start": "2376540",
    "end": "2381609"
  },
  {
    "text": "there's a couple of other parameters that you less likely to use one of them",
    "start": "2381609",
    "end": "2388390"
  },
  {
    "text": "is the recovery target transaction ID and you can specify an individual transaction ID and say I",
    "start": "2388390",
    "end": "2395559"
  },
  {
    "text": "want to recover up through this transaction ID one thing to note is that",
    "start": "2395559",
    "end": "2400989"
  },
  {
    "text": "when transaction IDs are generated they're generated sequentially but they're not necessarily committed",
    "start": "2400989",
    "end": "2407439"
  },
  {
    "text": "sequentially so if you it's feasible that you could generate transaction ID",
    "start": "2407439",
    "end": "2413699"
  },
  {
    "text": "105 by doing a begin statement and before you do your commit 87 other",
    "start": "2413699",
    "end": "2420489"
  },
  {
    "text": "transactions have not only begun but also committed then you're out of",
    "start": "2420489",
    "end": "2425679"
  },
  {
    "text": "sequence at that point so just an FYI be careful when you specify a transaction",
    "start": "2425679",
    "end": "2431259"
  },
  {
    "text": "ID if you have that kind of visibility into your system I haven't had any",
    "start": "2431259",
    "end": "2437349"
  },
  {
    "text": "experience with doing the transaction ID recoveries or to be honest with the",
    "start": "2437349",
    "end": "2443489"
  },
  {
    "text": "recovery target timeline which is another one if you have to specify a",
    "start": "2443489",
    "end": "2449709"
  },
  {
    "text": "recovery target timeline it means that you're in a world of hurt as a DBA",
    "start": "2449709",
    "end": "2455099"
  },
  {
    "text": "it means that something's gone really really wrong and you physically can't",
    "start": "2455099",
    "end": "2460959"
  },
  {
    "text": "recover the base back up and the set of all segments you have based on the",
    "start": "2460959",
    "end": "2466479"
  },
  {
    "text": "timeline that actually occurred as they were backed up so you can specify effectively an alternate timeline and at",
    "start": "2466479",
    "end": "2474400"
  },
  {
    "text": "least get the database to come online and then you can go to your boss and say well we're back but but at least you get",
    "start": "2474400",
    "end": "2481869"
  },
  {
    "text": "to say we're back so there is a lot of documentation on this one it's it gives",
    "start": "2481869",
    "end": "2487329"
  },
  {
    "text": "really complicated really fast and you need to have some real visibility into",
    "start": "2487329",
    "end": "2492869"
  },
  {
    "text": "how the transactions occurred in terms of being able to try to construction an",
    "start": "2492869",
    "end": "2499390"
  },
  {
    "text": "alternate timeline hopefully you never have to go there but it's available if you do there is also a parameter called",
    "start": "2499390",
    "end": "2506499"
  },
  {
    "text": "log restart points it's a boolean it doesn't do anything in terms of the",
    "start": "2506499",
    "end": "2511929"
  },
  {
    "text": "recovery itself all it does is basically set up verbose flag if you will in terms",
    "start": "2511929",
    "end": "2517719"
  },
  {
    "text": "of what it logs as it's doing the recovery so if you have some particularly long-running transaction",
    "start": "2517719",
    "end": "2525020"
  },
  {
    "text": "and you turn this on it actually gives you the ability to see things progress",
    "start": "2525020",
    "end": "2531530"
  },
  {
    "text": "so you don't have to sit and stare at the keyboard for an hour and a half before you see that it's actually doing",
    "start": "2531530",
    "end": "2537410"
  },
  {
    "text": "something nothing more than logging for that scenario and at that point you",
    "start": "2537410",
    "end": "2543530"
  },
  {
    "text": "should have a running server back online and hopefully all your data is intact",
    "start": "2543530",
    "end": "2550250"
  },
  {
    "text": "I've done point in time recovery untold number of times and never had a single",
    "start": "2550250",
    "end": "2556070"
  },
  {
    "text": "issue I've done it both with full recovery not specifying a timestamp just",
    "start": "2556070",
    "end": "2561710"
  },
  {
    "text": "recover everything and I've also done it by specifying a timestamp and in general",
    "start": "2561710",
    "end": "2567200"
  },
  {
    "text": "it's been flawless oh and thanks everybody we're a little over but don't worry",
    "start": "2567200",
    "end": "2575980"
  }
]
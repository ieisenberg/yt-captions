[
  {
    "text": "let me start with the the discussion monica talked about the customer",
    "start": "4640",
    "end": "10080"
  },
  {
    "text": "there were definitely three issues one was related to what are the licensing",
    "start": "10080",
    "end": "15679"
  },
  {
    "text": "terms so i think there is a talk and discussion later which i'm not that involved in the",
    "start": "15679",
    "end": "21279"
  },
  {
    "text": "licensing but there are other experts second one was the monitoring and observability",
    "start": "21279",
    "end": "26880"
  },
  {
    "text": "that have not been great in seven or eight and there have been significant improvement and i've seen there are",
    "start": "26880",
    "end": "33280"
  },
  {
    "text": "other talks talking about the monitoring part so this track also does not cover the monitoring",
    "start": "33280",
    "end": "39200"
  },
  {
    "text": "my expertise comes from more from the benchmarking area and be able to performance and",
    "start": "39200",
    "end": "45520"
  },
  {
    "text": "responsiveness and that is where when i got this email",
    "start": "45520",
    "end": "50800"
  },
  {
    "text": "from that was just one and a half month ago or so that hey we are evaluating this intel latest platform",
    "start": "50800",
    "end": "57039"
  },
  {
    "text": "and i'm doing this runs and i'm getting a variability of almost 40 50 60 percent",
    "start": "57039",
    "end": "65119"
  },
  {
    "text": "from run to run and i'm like no i have not seen such things so you",
    "start": "65119",
    "end": "70720"
  },
  {
    "text": "can see the two metric he was talking about one is full capacity matrix when system",
    "start": "70720",
    "end": "76799"
  },
  {
    "text": "is fully utilized he said that is just only when in case of everything else fail and only few",
    "start": "76799",
    "end": "82720"
  },
  {
    "text": "system carrying the load then performance is very repeatable but where my",
    "start": "82720",
    "end": "87759"
  },
  {
    "text": "production range is with regard to 30 to 40 operational then i see this 60 to 70",
    "start": "87759",
    "end": "94400"
  },
  {
    "text": "variability from run to run and that start gave me some idea okay what",
    "start": "94400",
    "end": "99840"
  },
  {
    "text": "is going on here because we don't see such things that lead to me asking the very first",
    "start": "99840",
    "end": "106079"
  },
  {
    "text": "question to the person that what are you running and when you look at this is a pretty large company they said",
    "start": "106079",
    "end": "114079"
  },
  {
    "text": "i have around 3000 to 4000 applications some of them are very small footprint",
    "start": "114079",
    "end": "119920"
  },
  {
    "text": "these are microservices which talk to each other and some of them are very small like 2",
    "start": "119920",
    "end": "125680"
  },
  {
    "text": "gig we run them usually two giga three gig heap very few of them are very large",
    "start": "125680",
    "end": "131039"
  },
  {
    "text": "we go up to 100 gig heap and the problem is he said i cannot take anything from",
    "start": "131039",
    "end": "136560"
  },
  {
    "text": "my production environment and have the confidence of repeatability running on the systems",
    "start": "136560",
    "end": "142720"
  },
  {
    "text": "so then what i go i go run for traditional benchmark etc we find and one of the benchmark he was using",
    "start": "142720",
    "end": "150640"
  },
  {
    "text": "we'll talk about later that he was using a benchmark which he said we have matched it to our we run our",
    "start": "150640",
    "end": "158720"
  },
  {
    "text": "system in production so we know the behavior and we have done the benchmark part and they pretty much with regard to",
    "start": "158720",
    "end": "164560"
  },
  {
    "text": "whether it is gc or dcp utilization or network io in most of the situations so we have",
    "start": "164560",
    "end": "171040"
  },
  {
    "text": "created this proxy where that's what we are running so we okay so that's even help us",
    "start": "171040",
    "end": "177360"
  },
  {
    "text": "because we can run similar proxy and when we ended up running on our",
    "start": "177360",
    "end": "182720"
  },
  {
    "text": "environment so let me see some of the component i could figure it out",
    "start": "182720",
    "end": "188080"
  },
  {
    "text": "so the traditional environment could be your app and jdm it could be running in",
    "start": "188080",
    "end": "193760"
  },
  {
    "text": "a container and from that container it when you launch a process you could have number",
    "start": "193760",
    "end": "200239"
  },
  {
    "text": "one case you launch the process it goes to the one of the socket this is the two socket system",
    "start": "200239",
    "end": "206000"
  },
  {
    "text": "it will the process will start on let's say the other end of the socket and it will",
    "start": "206000",
    "end": "211040"
  },
  {
    "text": "get the local memory the memory so number one you're running on a socket is getting the local memory in number two you start your",
    "start": "211040",
    "end": "219120"
  },
  {
    "text": "process it starts on other socket and then it get it does not get its own local memory",
    "start": "219120",
    "end": "225040"
  },
  {
    "text": "it get the memory from the other socket these are the traditional two socket system in third case what happens that",
    "start": "225040",
    "end": "232400"
  },
  {
    "text": "you launch the process again and you in the second socket and it gets local",
    "start": "232400",
    "end": "237519"
  },
  {
    "text": "memory so now let me ask the question that are you going to see the best",
    "start": "237519",
    "end": "245200"
  },
  {
    "text": "performance between one and two which is going to be better performance",
    "start": "245200",
    "end": "250319"
  },
  {
    "text": "one because the local memory and that part could cause significant variation in",
    "start": "250319",
    "end": "256239"
  },
  {
    "text": "certain cases it will not result in based on application on the total throughput",
    "start": "256239",
    "end": "261440"
  },
  {
    "text": "because we are talking memory latency of 100 nanosecond to 140 nanosecond",
    "start": "261440",
    "end": "266560"
  },
  {
    "text": "but it can make a big difference on your response time the latency so anytime you are sensitive to latency",
    "start": "266560",
    "end": "273199"
  },
  {
    "text": "that path can make a big difference so that is one variation for the",
    "start": "273199",
    "end": "278639"
  },
  {
    "text": "responsiveness of why the responsiveness could be different but not the total throughput second part",
    "start": "278639",
    "end": "285600"
  },
  {
    "text": "which is not covered just on that picture are many of you are maybe using the",
    "start": "285600",
    "end": "291680"
  },
  {
    "text": "containers or the virtual machines and when you're setting the thread pool within your application",
    "start": "291680",
    "end": "299199"
  },
  {
    "text": "it depends on how many cpu thread that api call gets it and that answer to",
    "start": "299199",
    "end": "306160"
  },
  {
    "text": "it if you're running on a large system would be all the core for example this system was 112 threads it could be",
    "start": "306160",
    "end": "312800"
  },
  {
    "text": "112 thread or if you're running within a vm and that vm only gives you",
    "start": "312800",
    "end": "318080"
  },
  {
    "text": "16 thread or so answer would be 16. so in one case you would be setting your thread pool based on 112",
    "start": "318080",
    "end": "324560"
  },
  {
    "text": "another just on 8 or 16 and as a app writer you don't have the control",
    "start": "324560",
    "end": "329680"
  },
  {
    "text": "it's in the deployment scenario you have to see and we have seen on the thread pool if you based on fork joint or now the",
    "start": "329680",
    "end": "337039"
  },
  {
    "text": "parallel stream i will talk a little bit later that how do you do the settings",
    "start": "337039",
    "end": "342479"
  },
  {
    "text": "it could have a effect on the context switch etc and resulting in variability",
    "start": "342479",
    "end": "348240"
  },
  {
    "text": "the another part is also your guest towards policies like some of them docker etc they allow pinning other vms",
    "start": "348240",
    "end": "355600"
  },
  {
    "text": "don't allow painting and your performance thread moving from one memory one socket to other could have significant",
    "start": "355600",
    "end": "362319"
  },
  {
    "text": "impact and the last part is on the heap memory that was the surprising one from",
    "start": "362319",
    "end": "367600"
  },
  {
    "text": "the experiment working with that person what is happening that there was around 256 gig of memory on",
    "start": "367600",
    "end": "374880"
  },
  {
    "text": "that system but traditionally a system will be keep using for almost two days three days",
    "start": "374880",
    "end": "380160"
  },
  {
    "text": "four days not rebooted so over time the memory fragmentation happens so even though you are requesting a 20",
    "start": "380160",
    "end": "387280"
  },
  {
    "text": "gig of heap you may not get 20 gigafeet why what we notice on it sometimes you are getting 18 gig another",
    "start": "387280",
    "end": "393919"
  },
  {
    "text": "time you were getting only eight gig and i'll show some data later so even though you give the parameter",
    "start": "393919",
    "end": "399919"
  },
  {
    "text": "of like give me this much heap based on how much fragmentation have been and if particularly the transparent",
    "start": "399919",
    "end": "406639"
  },
  {
    "text": "large pages which by default nowadays are enabled that requires a chunk contiguous if it",
    "start": "406639",
    "end": "412160"
  },
  {
    "text": "is not the large pages then it could actually give you much more easily those memory and then but there is a performance",
    "start": "412160",
    "end": "418639"
  },
  {
    "text": "benefit of large page of 10 to 15 percent and that can make a difference of the on the responsiveness also",
    "start": "418639",
    "end": "425120"
  },
  {
    "text": "as well as throughput so somehow earlier it used to be you have to request the large pages now the large page in these cases are",
    "start": "425120",
    "end": "432639"
  },
  {
    "text": "all by by default in the transparent you don't know so these were the interesting",
    "start": "432639",
    "end": "439440"
  },
  {
    "text": "things so some of the things i did not mean the talk today to go about these detail how the process",
    "start": "439440",
    "end": "445360"
  },
  {
    "text": "launched etc the interest was can the jdk 8 to 11 are any of the benefits which",
    "start": "445360",
    "end": "452639"
  },
  {
    "text": "are changing does it help in reducing the variability because these parts are out of your control as a programmer as",
    "start": "452639",
    "end": "459440"
  },
  {
    "text": "your developer you are not thinking where it is deploying what are the policies because their policy",
    "start": "459440",
    "end": "464960"
  },
  {
    "text": "could change the deployment might be misos here tomorrow docker or some other things",
    "start": "464960",
    "end": "471440"
  },
  {
    "text": "so what we wanted to see is the jdk doing anything and could be done certain",
    "start": "471440",
    "end": "476639"
  },
  {
    "text": "changes which help so that is where one of the thought was coming",
    "start": "476639",
    "end": "481919"
  },
  {
    "text": "so the couple of things we want to talk about with regard to some idea first we wanted to give you something",
    "start": "481919",
    "end": "487680"
  },
  {
    "text": "about what are the big changes from 8 to 11 and this talk is not about those changes",
    "start": "487680",
    "end": "493759"
  },
  {
    "text": "i think you are very well aware and there are other talks which talks about those feature of the api changes",
    "start": "493759",
    "end": "499840"
  },
  {
    "text": "or some thread pool changes and some data coming on them what we wanted to show that in the if",
    "start": "499840",
    "end": "506720"
  },
  {
    "text": "you really run certain benchmarks and workload how the different",
    "start": "506720",
    "end": "511919"
  },
  {
    "text": "parameters by default are changing that's one of the sharing part another part we wanted to",
    "start": "511919",
    "end": "517760"
  },
  {
    "text": "show you the data for again we talked about throughput we talked about the responsiveness we",
    "start": "517760",
    "end": "522800"
  },
  {
    "text": "talked about the variability and some startup so that data we want to share",
    "start": "522800",
    "end": "528880"
  },
  {
    "text": "and when we look at there are a lot of variation in those parts so monica looked at some of the",
    "start": "528880",
    "end": "534480"
  },
  {
    "text": "explanations that why it is going that way so it will help you to understand",
    "start": "534480",
    "end": "540399"
  },
  {
    "text": "so let's start with the new use cases if you look so there have been changes with regard",
    "start": "540399",
    "end": "545600"
  },
  {
    "text": "to monitoring code observability we are not covering it on that part there are new users of the",
    "start": "545600",
    "end": "551360"
  },
  {
    "text": "containers microservices or function as service or polygon we will cover the function as",
    "start": "551360",
    "end": "557760"
  },
  {
    "text": "services slightly that what you could see the impact from the",
    "start": "557760",
    "end": "562880"
  },
  {
    "text": "jdk 11 and then we for the concurrency part we are not covering the project",
    "start": "562880",
    "end": "568399"
  },
  {
    "text": "loom on the value type or not there but we would definitely one of the benchmark has the fork joint and what is that impact on the thread",
    "start": "568399",
    "end": "575040"
  },
  {
    "text": "pool will have and the networking part is all the benchmark using",
    "start": "575040",
    "end": "580480"
  },
  {
    "text": "an io using grizzly but not the neti but the impact is very similar but we are not",
    "start": "580480",
    "end": "586080"
  },
  {
    "text": "going in detail of that part so most of the data you would see from the benchmark which are throughput",
    "start": "586080",
    "end": "591360"
  },
  {
    "text": "or responsiveness or variability or the startup type",
    "start": "591360",
    "end": "597839"
  },
  {
    "text": "so let's start with why did we pick the jds jdk8 not seven not six or so and the one of the reason was",
    "start": "599360",
    "end": "605920"
  },
  {
    "text": "this is from one of the survey that almost uh significant amount of deployments currently are at eight that's what",
    "start": "605920",
    "end": "612160"
  },
  {
    "text": "they're evaluating and they are thinking to move to 11 that's what",
    "start": "612160",
    "end": "619839"
  },
  {
    "text": "another part is which workload did we avoid because we did pick certain workloads and what we are finding the jmh particularly",
    "start": "620079",
    "end": "627680"
  },
  {
    "text": "which comes with the jdk kit has a lot of variability almost 50 percent and some of them even bigger",
    "start": "627680",
    "end": "634160"
  },
  {
    "text": "so we are not using the gmh component even though they come with open jdk and many times you might just look at",
    "start": "634160",
    "end": "640640"
  },
  {
    "text": "the data coming from open jdk so that is a lot of variability and we had to remove that part out",
    "start": "640640",
    "end": "647600"
  },
  {
    "text": "the next one i talked about a bit heap that in that process even if you give a",
    "start": "647600",
    "end": "653519"
  },
  {
    "text": "certain amount of heap you're not guaranteed so you should always put your gc print output into",
    "start": "653519",
    "end": "659440"
  },
  {
    "text": "checking environment when deploying what how much heap are you really getting and the data shown here is really for a",
    "start": "659440",
    "end": "666959"
  },
  {
    "text": "spec jvm 2008 which is compute and memory bound different components and what we wanted",
    "start": "666959",
    "end": "672959"
  },
  {
    "text": "to show just look at the 20 gig to 60 gig part some of them of course there won't be a",
    "start": "672959",
    "end": "678079"
  },
  {
    "text": "difference if they are not allocating heavily and not getting impacted by that but there are many component in your environment also",
    "start": "678079",
    "end": "685120"
  },
  {
    "text": "which can have a significant com impact just how much heat did you get from run to run",
    "start": "685120",
    "end": "691920"
  },
  {
    "text": "so that data was just to showcase that even on your cases when you have wide variety of them you would have a big difference",
    "start": "691920",
    "end": "698000"
  },
  {
    "text": "now let's look at the throughput and performance so spec jvm 2008 it has almost 13 or 14",
    "start": "698000",
    "end": "705040"
  },
  {
    "text": "components and we look at at least for jdk 8 to 11",
    "start": "705040",
    "end": "711040"
  },
  {
    "text": "and even up to 13 there is almost no case where the",
    "start": "711040",
    "end": "716160"
  },
  {
    "text": "performance goes down and it's on improvement only so by default if you just move from",
    "start": "716160",
    "end": "721200"
  },
  {
    "text": "8 to 11 to 12 or 13 then other than very rare cases you should",
    "start": "721200",
    "end": "727519"
  },
  {
    "text": "see improvement just by default",
    "start": "727519",
    "end": "731839"
  },
  {
    "text": "that just the parameter i put for the slides now let's talk about a little bit more perform performance response and variability",
    "start": "734000",
    "end": "740639"
  },
  {
    "text": "because you can find many benchmark which is a throughput you run them there are so many of them for",
    "start": "740639",
    "end": "747760"
  },
  {
    "text": "performance and variability the one of the benchmark which at spec monika was also part",
    "start": "747760",
    "end": "752959"
  },
  {
    "text": "monica and i work in the same committee we created this benchmark for this purpose that you can have all three",
    "start": "752959",
    "end": "759360"
  },
  {
    "text": "components so the very first one here when the benchmark runs um is speculate 2015. in the beginning",
    "start": "759360",
    "end": "766880"
  },
  {
    "text": "phase it actually doing a binary search that means it is loading the system",
    "start": "766880",
    "end": "772480"
  },
  {
    "text": "crazily some low value high value low value high value so very similar to production environment where you might see the",
    "start": "772480",
    "end": "779279"
  },
  {
    "text": "surges in throughput or the load coming in and at that time it determines what is your satellite load values",
    "start": "779279",
    "end": "786000"
  },
  {
    "text": "so it try to give you a rough approximation what kind of load you handle when the request comes in very variable",
    "start": "786000",
    "end": "793839"
  },
  {
    "text": "or bursts the second part is we call response throughput curve where",
    "start": "793839",
    "end": "799920"
  },
  {
    "text": "it slowly increases the throughput and it keeps increasing and it keeps measuring your response time",
    "start": "799920",
    "end": "805200"
  },
  {
    "text": "and it is a 99 percentile response time and from that it keep loading the system",
    "start": "805200",
    "end": "810240"
  },
  {
    "text": "and you get two metrics one is the max job which is the full system capacity what will happen if your system is the",
    "start": "810240",
    "end": "816240"
  },
  {
    "text": "failover mode i need to handle and the second one is the critical jobs which has a sla that",
    "start": "816240",
    "end": "822399"
  },
  {
    "text": "which is a geometric mean of 5 sl 10 millisecond 25 millisecond 50 millisecond",
    "start": "822399",
    "end": "828160"
  },
  {
    "text": "75 millisecond and 100 milliseconds so it try to check what is your throughput when you have",
    "start": "828160",
    "end": "834000"
  },
  {
    "text": "those slas and that is called critical jobs that is more responsiveness and we have seen for different scenarios",
    "start": "834000",
    "end": "840880"
  },
  {
    "text": "it is in the range of 30 to 50 percent of the system utilization and that is where most of the products",
    "start": "840880",
    "end": "847680"
  },
  {
    "text": "and environment system also operate so these are the three metric from this",
    "start": "847680",
    "end": "853120"
  },
  {
    "text": "benchmark we get so now let us look at the sum of the data we got",
    "start": "853120",
    "end": "859760"
  },
  {
    "text": "so this data is for the jdk 8 to 11 and it is full system capacity and",
    "start": "860560",
    "end": "866560"
  },
  {
    "text": "responsiveness what you will see between 8 and 11 that",
    "start": "866560",
    "end": "871680"
  },
  {
    "text": "full system capacity almost no difference and you may be surprised in one of them",
    "start": "871680",
    "end": "877680"
  },
  {
    "text": "why and what we have seen i talked to the person in the team who works several of the jet related changes even",
    "start": "877680",
    "end": "884959"
  },
  {
    "text": "for 11 and 12 they have been back ported to jdk8 so if you pick the latest jdk 8 several",
    "start": "884959",
    "end": "891199"
  },
  {
    "text": "of the jit related changes are back ported so throughput wise you would see the very",
    "start": "891199",
    "end": "896480"
  },
  {
    "text": "similar performance for many situations that that's the reason",
    "start": "896480",
    "end": "901759"
  },
  {
    "text": "the responsiveness the critical jobs what we were talking that got impacted by your response time the the for each",
    "start": "901920",
    "end": "908959"
  },
  {
    "text": "transaction because that is what for sla is measuring and that is where we see almost a 35 percent improvement from jdk",
    "start": "908959",
    "end": "917040"
  },
  {
    "text": "11 and the reason being it is that 11 when we look into detail it's mostly the g1 gc",
    "start": "917040",
    "end": "925600"
  },
  {
    "text": "because your jdk8 by default has the parallel stop the world gc and anytime",
    "start": "925600",
    "end": "932320"
  },
  {
    "text": "you are doing a gc it will ended up stopping to anywhere from 50 millisecond to almost",
    "start": "932320",
    "end": "939759"
  },
  {
    "text": "300 400 milliseconds based on what kind of gc happen on the other hand g1 gc takes a hit on",
    "start": "939759",
    "end": "946480"
  },
  {
    "text": "the full system capacity that is why both are matching kind of but it gives you much better",
    "start": "946480",
    "end": "952480"
  },
  {
    "text": "critical jobs the rest where the response time is never more than 20 30 milliseconds",
    "start": "952480",
    "end": "958240"
  },
  {
    "text": "and monica will cover later more detail why and how that happens but that is the part of the reason that",
    "start": "958240",
    "end": "964880"
  },
  {
    "text": "responsiveness is much better on jdk 11 not due to any other component but on",
    "start": "964880",
    "end": "970160"
  },
  {
    "text": "the g 1 gc by default let's look at the variability part how",
    "start": "970160",
    "end": "976880"
  },
  {
    "text": "we are defining variability it is more that we are doing 10 runs or more and then",
    "start": "976880",
    "end": "982480"
  },
  {
    "text": "we look at how the total maximum throughput or the critical jobs we were measuring",
    "start": "982480",
    "end": "988480"
  },
  {
    "text": "under sla changing that is run to run variation that is very similar to you take your test case",
    "start": "988480",
    "end": "994160"
  },
  {
    "text": "and launch it 10 20 or 30 time on the same system that's what we did also here that we do",
    "start": "994160",
    "end": "1001120"
  },
  {
    "text": "some other work in between and then launch this system do other work and launch the system and what we are finding that from the",
    "start": "1001120",
    "end": "1007839"
  },
  {
    "text": "varia variability prospective jdk 8 on the throughput standard deviation",
    "start": "1007839",
    "end": "1013759"
  },
  {
    "text": "is around 2 2 but standard deviation for the critical jobs which is the",
    "start": "1013759",
    "end": "1019839"
  },
  {
    "text": "responsiveness is almost 10 very high and really bad on the other hand jdk",
    "start": "1019839",
    "end": "1025600"
  },
  {
    "text": "11 which we talked about due to g1 gc much more i say",
    "start": "1025600",
    "end": "1032079"
  },
  {
    "text": "the response time which is predictable on the other hand the parallel gc stop is are not predictable",
    "start": "1032079",
    "end": "1038240"
  },
  {
    "text": "they can be from very small to very large and that's what causes the variability part",
    "start": "1038240",
    "end": "1043678"
  },
  {
    "text": "again the variability is also related to g1 gc improvements so that is the main",
    "start": "1043679",
    "end": "1049039"
  },
  {
    "text": "component we are finding in addition to of course the the api other thing you get by default",
    "start": "1049039",
    "end": "1055280"
  },
  {
    "text": "uh it's mostly variability and responses are coming from the g1gc part",
    "start": "1055280",
    "end": "1062400"
  },
  {
    "text": "now let's talk about a bit more startup type thing i was talking about because when we are going function as",
    "start": "1062640",
    "end": "1068720"
  },
  {
    "text": "service then we are all talking about something coming out for",
    "start": "1068720",
    "end": "1073840"
  },
  {
    "text": "almost few milliseconds to say one or two minutes",
    "start": "1073840",
    "end": "1080799"
  },
  {
    "text": "so far any workload we were talking we were talking at least 10 minutes six to eight minutes to",
    "start": "1080799",
    "end": "1086640"
  },
  {
    "text": "almost two hours running like spec jv 2015 runs two hours",
    "start": "1086640",
    "end": "1091840"
  },
  {
    "text": "spec jvm 2008 each iteration runs for six minute overall runs for two to three",
    "start": "1091840",
    "end": "1097200"
  },
  {
    "text": "hours but the copper benchmark we just picked they have improved the repeatability i really don't like abit their",
    "start": "1097200",
    "end": "1103360"
  },
  {
    "text": "repeatability so we are doing several runs but what what it is that you can see on",
    "start": "1103360",
    "end": "1108640"
  },
  {
    "text": "the top graph several components are barely 500 millisecond 500 millisecond",
    "start": "1108640",
    "end": "1114480"
  },
  {
    "text": "each iteration so small which would be very similar if tomorrow you start writing function",
    "start": "1114480",
    "end": "1119600"
  },
  {
    "text": "as service a service need to make a call get the work done and be out then what we are finding that",
    "start": "1119600",
    "end": "1126640"
  },
  {
    "text": "in that case between 8 and 11 i was surprised that so far we were seeing jdk",
    "start": "1126640",
    "end": "1132240"
  },
  {
    "text": "11 is better in everything compared to eight better similar throughput of adder and",
    "start": "1132240",
    "end": "1138559"
  },
  {
    "text": "much better variability and much better response now but here i was surprised to see that uh in",
    "start": "1138559",
    "end": "1145120"
  },
  {
    "text": "several of the components jdk 11 is actually first i looked oh the higher is",
    "start": "1145120",
    "end": "1150559"
  },
  {
    "text": "higher is not better it's lower because i'm dividing jdk 11 execution time by the jdk execution time so lower is",
    "start": "1150559",
    "end": "1157919"
  },
  {
    "text": "better and this one again i discussed with monica and then she looked into the logs",
    "start": "1157919",
    "end": "1164080"
  },
  {
    "text": "it happens to be this time g1 gc is not doing good and she would have explanation y in",
    "start": "1164080",
    "end": "1170240"
  },
  {
    "text": "particular for these kind of instances so there are situations where g1 gc for",
    "start": "1170240",
    "end": "1176559"
  },
  {
    "text": "this short startup or functional service type scenario and we plan to investigate more",
    "start": "1176559",
    "end": "1182000"
  },
  {
    "text": "and give feedback to open jdk that's the part we plan to do so i think that's the part i wanted to",
    "start": "1182000",
    "end": "1188559"
  },
  {
    "text": "share the database and i work with monica and she had the explanation for several",
    "start": "1188559",
    "end": "1193600"
  },
  {
    "text": "of these things we worked on cool thank you anil",
    "start": "1193600",
    "end": "1201200"
  },
  {
    "text": "so um so yeah so all the good fun stuff that was covered by anil so what i'm",
    "start": "1201440",
    "end": "1207840"
  },
  {
    "text": "going to do here is provide a little bit of groundwork on garbage collections",
    "start": "1207840",
    "end": "1213440"
  },
  {
    "text": "and certain observations that anil had i'm going to provide uh",
    "start": "1213440",
    "end": "1220960"
  },
  {
    "text": "explanations for those as well",
    "start": "1220960",
    "end": "1224720"
  },
  {
    "text": "so um very basic stuff with respect to a heap layout so usually we talk about heap as",
    "start": "1226799",
    "end": "1233840"
  },
  {
    "text": "a contiguous chunk like that uh with the newer garbage collectors",
    "start": "1233840",
    "end": "1239039"
  },
  {
    "text": "uh you would also see something called regions so that's a regionalized heap basically",
    "start": "1239039",
    "end": "1244640"
  },
  {
    "text": "where they have um so these are all uh virtual space right and then um",
    "start": "1244640",
    "end": "1252240"
  },
  {
    "text": "there's also the concept of generations so you have the young generation and all generation so in",
    "start": "1252240",
    "end": "1259679"
  },
  {
    "text": "for example g1 gc's case you will have the generations as well as the regions",
    "start": "1259679",
    "end": "1264880"
  },
  {
    "text": "and that's typical configuration of the heap uh when we are trying to explain the",
    "start": "1264880",
    "end": "1270720"
  },
  {
    "text": "basic heap layout so for now zgc and shenandoah are not generational",
    "start": "1270720",
    "end": "1278640"
  },
  {
    "text": "and g1gc is generational um as well as it's got regionalized heap so",
    "start": "1278640",
    "end": "1285120"
  },
  {
    "text": "i have also in in some of the because we're comparing judy gate and jdk 11 or 13",
    "start": "1285120",
    "end": "1291440"
  },
  {
    "text": "i've also provided numbers for parallel gc and parallel gc used to be the default",
    "start": "1291440",
    "end": "1297919"
  },
  {
    "text": "for jdk8 and starting 9 the new default gc is g1",
    "start": "1297919",
    "end": "1304480"
  },
  {
    "text": "so that's why i wanted to provide comparative numbers so parallel gc is not regionalized",
    "start": "1304480",
    "end": "1312559"
  },
  {
    "text": "i will go into details of this later when we talk about the couple but something to realize is",
    "start": "1313200",
    "end": "1318720"
  },
  {
    "text": "that when we talk about generational heap uh eden and survivor",
    "start": "1318720",
    "end": "1325679"
  },
  {
    "text": "regions will form the young generation and old regions as well as humongous will be",
    "start": "1325679",
    "end": "1332880"
  },
  {
    "text": "from the old generation so this is very important to know and i'll i'll go into details why okay",
    "start": "1332880",
    "end": "1340960"
  },
  {
    "text": "so the same uh for for for a user or for or even a gc person",
    "start": "1340960",
    "end": "1347679"
  },
  {
    "text": "uh it all boils down to occupied and free regions so basically if you are generational",
    "start": "1347679",
    "end": "1353919"
  },
  {
    "text": "basically your young generation gets filled and then you either promote or you try to age them in",
    "start": "1353919",
    "end": "1359440"
  },
  {
    "text": "the survivors and eventually you will have just a bunch of",
    "start": "1359440",
    "end": "1365520"
  },
  {
    "text": "occupied so basically long-lived objects or whatever so again it's just all the free regions",
    "start": "1365520",
    "end": "1373600"
  },
  {
    "text": "are maintained in a list and uh any of those occupied regions",
    "start": "1373600",
    "end": "1378880"
  },
  {
    "text": "could be like i mentioned young or old or humongous which is allocated out of the old region",
    "start": "1378880",
    "end": "1387120"
  },
  {
    "text": "um i want to quickly compare different garbage collectors and the reason i wanted to talk about",
    "start": "1387600",
    "end": "1393520"
  },
  {
    "text": "um the other two like shenandoah and zgc is because that's the future that's",
    "start": "1393520",
    "end": "1398799"
  },
  {
    "text": "where we are headed so you'll see this trend which i'll cover here soon and um",
    "start": "1398799",
    "end": "1404320"
  },
  {
    "text": "so basically the the entire um thing boils down to",
    "start": "1404320",
    "end": "1412400"
  },
  {
    "text": "copying okay so i'm going to emphasize that here so we also know that as compacting",
    "start": "1412400",
    "end": "1418880"
  },
  {
    "text": "collector or we call it evacuation as well so it's kind of similar everything is similar",
    "start": "1418880",
    "end": "1424559"
  },
  {
    "text": "uh your heap has a from space and a tooth and",
    "start": "1424559",
    "end": "1431440"
  },
  {
    "text": "as you start filling up the from space",
    "start": "1431440",
    "end": "1436000"
  },
  {
    "text": "and it gets filled now is the time for you to do marking okay and to do marking you go",
    "start": "1437679",
    "end": "1444640"
  },
  {
    "text": "find out the gc routes which could be a static variables that stack any references",
    "start": "1444640",
    "end": "1450080"
  },
  {
    "text": "jnr references and then you identify them uh on the in in your from space area and",
    "start": "1450080",
    "end": "1458000"
  },
  {
    "text": "then you start doing the live object graph and and eventually you move the live objects",
    "start": "1458000",
    "end": "1465200"
  },
  {
    "text": "to the to space and then you reclaim the front space and",
    "start": "1465200",
    "end": "1471760"
  },
  {
    "text": "eventually the two space turns into from space and you start allocating um",
    "start": "1471760",
    "end": "1479039"
  },
  {
    "text": "into the from space so it just goes back and forth right so this simple concept the way it gets a",
    "start": "1479039",
    "end": "1487200"
  },
  {
    "text": "little more complicated when you have generational gc it gets complicated when you are",
    "start": "1487200",
    "end": "1492240"
  },
  {
    "text": "doing concurrent compaction or concurrent marking and stuff like that i will not have time to",
    "start": "1492240",
    "end": "1498640"
  },
  {
    "text": "to go into details but i wanted to sorry about the formatting but i wanted to quickly",
    "start": "1498640",
    "end": "1503760"
  },
  {
    "text": "highlight um the differences so as i mentioned",
    "start": "1503760",
    "end": "1508960"
  },
  {
    "text": "parallel gc is not regionalized right but it is generational",
    "start": "1508960",
    "end": "1514400"
  },
  {
    "text": "just like g1gc compaction does happen uh in parallel and g1 uh",
    "start": "1514400",
    "end": "1521360"
  },
  {
    "text": "and they just use the forwarding address in the header and because parallel gc is throughput",
    "start": "1521360",
    "end": "1527840"
  },
  {
    "text": "driven so that's the goal it's like to have higher throughput and there's no past time target per se as long as we",
    "start": "1527840",
    "end": "1535360"
  },
  {
    "text": "keep on uh putting the throughput to the max so it's everything is stopped the world in parallel gc",
    "start": "1535360",
    "end": "1542000"
  },
  {
    "text": "uh g1 gc does have a target pass-time goal and um it it's so",
    "start": "1542000",
    "end": "1548960"
  },
  {
    "text": "i'm not going to go into details but basically it tries it's like i hope i can achieve this goal and",
    "start": "1548960",
    "end": "1557200"
  },
  {
    "text": "then the adaptive resizing of regions uh or collection set in the regions uh",
    "start": "1557200",
    "end": "1564720"
  },
  {
    "text": "will will be what will be changed as well as you'll find out how much expensive a",
    "start": "1564720",
    "end": "1571679"
  },
  {
    "text": "particular region gets during a collection parallel gc does not have any concurrent",
    "start": "1571679",
    "end": "1579120"
  },
  {
    "text": "marking at all it does everything is stopped the world like i mentioned but g1 gc does",
    "start": "1579120",
    "end": "1584240"
  },
  {
    "text": "and they are both g1 and shenandoah are a snapshot at the beginning",
    "start": "1584240",
    "end": "1590320"
  },
  {
    "text": "algorithm and zgc does striping which i'm not going to go into details here",
    "start": "1590320",
    "end": "1596960"
  },
  {
    "text": "there's also the concept of colored pointers in g cgc and their target pause times are",
    "start": "1596960",
    "end": "1604159"
  },
  {
    "text": "slightly uh smaller actually uh than g1 gc because they",
    "start": "1604159",
    "end": "1609520"
  },
  {
    "text": "both shenandoah and zgc are targeting the low pass time market",
    "start": "1609520",
    "end": "1617278"
  },
  {
    "text": "and so i quickly ran",
    "start": "1617600",
    "end": "1623039"
  },
  {
    "text": "jbb with about 28 gigs and um",
    "start": "1623039",
    "end": "1631600"
  },
  {
    "text": "and what we saw so this was explained by anil earlier max throughput is basically",
    "start": "1631600",
    "end": "1639520"
  },
  {
    "text": "the entire system you know when when you just look fully loaded and that's the system",
    "start": "1639520",
    "end": "1645520"
  },
  {
    "text": "capacity uh there is the responsive the response and",
    "start": "1645520",
    "end": "1651039"
  },
  {
    "text": "throughput curve that arnel was talking about that's the one that i'm talking about that's the max j ops metric and then the responsiveness",
    "start": "1651039",
    "end": "1658799"
  },
  {
    "text": "is what he mentioned as critical jobs metric uh everything is normalized to",
    "start": "1658799",
    "end": "1664000"
  },
  {
    "text": "shenandoah's max throughput so",
    "start": "1664000",
    "end": "1669600"
  },
  {
    "text": "the things i want to i want you to take away from here are that parallel gc is everything is",
    "start": "1669600",
    "end": "1676399"
  },
  {
    "text": "stopped the world so of course it gives you the maximum throughput that's the the way gc is designed generational",
    "start": "1676399",
    "end": "1682880"
  },
  {
    "text": "stop the world so it gives you the maximum throughput but as you go down to g1gc and basically",
    "start": "1682880",
    "end": "1690320"
  },
  {
    "text": "what i've done is like made some adjustments to the past time goals and kind of relaxed it a bit",
    "start": "1690320",
    "end": "1696000"
  },
  {
    "text": "so that's why you see that your throughput kind of gets better but your critical",
    "start": "1696000",
    "end": "1702399"
  },
  {
    "text": "jobs is pretty consistent so the last three are basically your g1 gc so you see how it's so that's",
    "start": "1702399",
    "end": "1709679"
  },
  {
    "text": "where the repeatability uh metric that um that you were talking about anil",
    "start": "1709679",
    "end": "1715039"
  },
  {
    "text": "comes into play um as you change certain things with respect to so that",
    "start": "1715039",
    "end": "1720159"
  },
  {
    "text": "the the third and the fourth are parallel gc a slight change in nursery produces a",
    "start": "1720159",
    "end": "1727279"
  },
  {
    "text": "lot of variation in parallel gc's output with respect to throughput or responsiveness as well",
    "start": "1727279",
    "end": "1734960"
  },
  {
    "text": "shenandoah and zgc kind of have an issue here because they are not generational yet",
    "start": "1734960",
    "end": "1741520"
  },
  {
    "text": "right and they they achieve uh uh copying compaction while concurrently",
    "start": "1741520",
    "end": "1747760"
  },
  {
    "text": "moving objects from the from space to the two space right so that those are basically trying to",
    "start": "1747760",
    "end": "1754080"
  },
  {
    "text": "achieve higher uh critical response time which is what you see with zgc so it's kind of uh it's",
    "start": "1754080",
    "end": "1762399"
  },
  {
    "text": "56 at 56 right and whereas any anything and everything that uh g1",
    "start": "1762399",
    "end": "1767760"
  },
  {
    "text": "gc could achieve was about 49 to 50 right so that's the target that's the goal",
    "start": "1767760",
    "end": "1772799"
  },
  {
    "text": "that's a design of these gcs they're headed towards providing you much better responsiveness okay it's kind of like a",
    "start": "1772799",
    "end": "1780880"
  },
  {
    "text": "lot of information there but the the the the trend that i'm trying to",
    "start": "1780880",
    "end": "1786240"
  },
  {
    "text": "show here is that there's more uh effort put into uh getting better responsiveness going",
    "start": "1786240",
    "end": "1792960"
  },
  {
    "text": "from jdk 8 to 11 to 13. okay",
    "start": "1792960",
    "end": "1798640"
  },
  {
    "text": "now going back to the decapo case i wanted to quickly talk about gntc and",
    "start": "1800000",
    "end": "1806640"
  },
  {
    "text": "and humongous objects so um gngc has of course it's regionalized it",
    "start": "1806640",
    "end": "1812640"
  },
  {
    "text": "has a concept of region each region uh uh kind of gets allocated a size at jvm start",
    "start": "1812640",
    "end": "1820799"
  },
  {
    "text": "in in decouple's case it was four megs okay so if as and when you have objects",
    "start": "1820799",
    "end": "1827600"
  },
  {
    "text": "getting allocated um they would end up in eden",
    "start": "1827600",
    "end": "1832640"
  },
  {
    "text": "if they fill if they meet certain criteria and if it's a humongous object they will go",
    "start": "1832640",
    "end": "1838880"
  },
  {
    "text": "and get allocated out of the old generation okay so the threshold is basically",
    "start": "1838880",
    "end": "1845360"
  },
  {
    "text": "the size of the object so if the object is greater than or equal to fifty",
    "start": "1845360",
    "end": "1850480"
  },
  {
    "text": "percent of the region size so in in the couple's case if the object is two megs or high or",
    "start": "1850480",
    "end": "1857200"
  },
  {
    "text": "larger then it will be considered a humongous object",
    "start": "1857200",
    "end": "1862480"
  },
  {
    "text": "so less than 50 it will be allocated out of eden greater than or equal to 50 then it",
    "start": "1863519",
    "end": "1870159"
  },
  {
    "text": "would be out of the old generation and anything that's greater than region size would",
    "start": "1870159",
    "end": "1875760"
  },
  {
    "text": "have humongous regions so basically that would be a contiguous space right there",
    "start": "1875760",
    "end": "1881840"
  },
  {
    "text": "so again same information but not but like dif expressed differently here",
    "start": "1881840",
    "end": "1888720"
  },
  {
    "text": "anything less than half the region size is not humongous everything else is humongous if you need",
    "start": "1888720",
    "end": "1893919"
  },
  {
    "text": "more than one region then it's called a contiguous region and it's",
    "start": "1893919",
    "end": "1899360"
  },
  {
    "text": "also humongous so with with the capo one of the things it does",
    "start": "1899360",
    "end": "1905919"
  },
  {
    "text": "is does these system gc's to between every um i guess it's different",
    "start": "1905919",
    "end": "1912480"
  },
  {
    "text": "benchmarks that start and then so but it's setting up the object so the objects are long lived",
    "start": "1912480",
    "end": "1918480"
  },
  {
    "text": "and and because of the four meg space anything that's two megs or above cons",
    "start": "1918480",
    "end": "1925039"
  },
  {
    "text": "uh becomes a humongous object so when the capo is um allocating these objects",
    "start": "1925039",
    "end": "1931279"
  },
  {
    "text": "which is which is hoping were regular sized because of the lower heap region uh size",
    "start": "1931279",
    "end": "1937919"
  },
  {
    "text": "that we have these are all humongous objects and when you're doing system gc uh what's happening is you're trying to",
    "start": "1937919",
    "end": "1944240"
  },
  {
    "text": "move these humongous regions remember that that we're trying to uh have contiguous regions",
    "start": "1944240",
    "end": "1950159"
  },
  {
    "text": "you're trying to move it from the from space because they're live and into the two space and and trying to",
    "start": "1950159",
    "end": "1957039"
  },
  {
    "text": "find uh if you keep on doing it over time trying to find contiguous regions is it gets difficult because of",
    "start": "1957039",
    "end": "1965200"
  },
  {
    "text": "fragmentation issues so that's why the g1gc",
    "start": "1965200",
    "end": "1971039"
  },
  {
    "text": "showed you reduced performance okay",
    "start": "1971039",
    "end": "1977840"
  },
  {
    "text": "i wanted to talk about aot because that's something that's um that's a direction again where we're",
    "start": "1978080",
    "end": "1984559"
  },
  {
    "text": "headed is more responsiveness and so there's we're going to have a",
    "start": "1984559",
    "end": "1990000"
  },
  {
    "text": "talk later today about um you know more compilation directions in future by mark",
    "start": "1990000",
    "end": "1997120"
  },
  {
    "text": "but um this is something that is available since jdk 910 and it's gotten better",
    "start": "1997120",
    "end": "2004559"
  },
  {
    "text": "over time and one of my colleagues has a very good article so i'm going to reference the article",
    "start": "2004559",
    "end": "2010399"
  },
  {
    "text": "um here okay so prior to tiered compilations around",
    "start": "2010399",
    "end": "2016320"
  },
  {
    "text": "before jdk 7 ish you would have the first execution",
    "start": "2016320",
    "end": "2021840"
  },
  {
    "text": "it would end up in the interpreter and then eventually you will have adaptive jitting and based on",
    "start": "2021840",
    "end": "2030080"
  },
  {
    "text": "the profiles of critical hotspots so basically it's like you have thresholds thresholds are crossed uh some things",
    "start": "2030080",
    "end": "2036240"
  },
  {
    "text": "get jitted and there was a concept of server and client compiler which is also known as c2 and c1 and",
    "start": "2036240",
    "end": "2044080"
  },
  {
    "text": "then and then tiered compilation happened so you tweet compilation was fully",
    "start": "2044080",
    "end": "2050800"
  },
  {
    "text": "supported in jdk8 i think and before that it was experimental",
    "start": "2050800",
    "end": "2058720"
  },
  {
    "text": "with tiered compilation again the c1 ct concepts are still there but there's the profiling concept is",
    "start": "2058720",
    "end": "2066079"
  },
  {
    "text": "different so you have limited profiling as and opposed to full profiling there's",
    "start": "2066079",
    "end": "2071760"
  },
  {
    "text": "a good explanation like i said mentioned in that link over there so all you have to think about is",
    "start": "2071760",
    "end": "2077760"
  },
  {
    "text": "basically from interpreter to c1 or c2 based on the profiling and the different thresholds",
    "start": "2077760",
    "end": "2083919"
  },
  {
    "text": "and then of course there's a de-optimization path as well",
    "start": "2083919",
    "end": "2089280"
  },
  {
    "text": "with aot what happens is we do not go after the first execution we do not go",
    "start": "2089280",
    "end": "2095118"
  },
  {
    "text": "to interpreter we actually go to aot code and we can do c1 and c2 based on",
    "start": "2095119",
    "end": "2101200"
  },
  {
    "text": "full profile so when you have c1 with full profile you could do go to c2 and any de-optimization goes back to",
    "start": "2101200",
    "end": "2107680"
  },
  {
    "text": "interpreter to go into details please go ahead and read the article",
    "start": "2107680",
    "end": "2113440"
  },
  {
    "text": "and actually many are many great articles out there on aot um as well",
    "start": "2113440",
    "end": "2121040"
  },
  {
    "text": "so what i ended up doing is um using huh interesting so sorry about the um",
    "start": "2121040",
    "end": "2128800"
  },
  {
    "text": "the labels got getting cut off uh so what we i did is i took the jvm 2008",
    "start": "2128800",
    "end": "2136320"
  },
  {
    "text": "startup component and i tried to run it with so without aot then with aot",
    "start": "2136320",
    "end": "2144079"
  },
  {
    "text": "and with aot with tiered the difference between aot and aot with tiered is that when you create the dynamic library",
    "start": "2144079",
    "end": "2151040"
  },
  {
    "text": "you could say that i would like it to be able to use the tiered compilation path",
    "start": "2151040",
    "end": "2157599"
  },
  {
    "text": "or you could say nope i don't need the tiered compilation path so as you can see higher is better so",
    "start": "2157599",
    "end": "2165359"
  },
  {
    "text": "most of the time you'll see aot just giving you a straight up win for most of the startup workloads that i have",
    "start": "2165359",
    "end": "2171200"
  },
  {
    "text": "covered here and apologize again for the label uh getting cut out like that uh",
    "start": "2171200",
    "end": "2177280"
  },
  {
    "text": "but what was interesting is if you look at the last three here to your to your right",
    "start": "2177280",
    "end": "2183520"
  },
  {
    "text": "uh uh that to the left the the blue one is without aot and after that the",
    "start": "2183520",
    "end": "2189599"
  },
  {
    "text": "performance drops so that was my um so i was going to use i was using the same workload as",
    "start": "2189599",
    "end": "2194960"
  },
  {
    "text": "the the one previous there right you saw aot and aot with tiered actually giving you a benefit so these two workloads are",
    "start": "2194960",
    "end": "2201599"
  },
  {
    "text": "the same but the runtime is is different so that is just measured at startup and",
    "start": "2201599",
    "end": "2208000"
  },
  {
    "text": "this one is measured after it's warmed up and now it's trying to achieve steady state and",
    "start": "2208000",
    "end": "2214160"
  },
  {
    "text": "the reason that actually you the tiered with aot material gives you the worst performance",
    "start": "2214160",
    "end": "2219599"
  },
  {
    "text": "is that it hasn't crossed the threshold so when you think about these different",
    "start": "2219599",
    "end": "2226839"
  },
  {
    "text": "compilation uh improvements the thresholds change as well so for",
    "start": "2226839",
    "end": "2233200"
  },
  {
    "text": "example tier three invocation threshold for aot with tiered",
    "start": "2233200",
    "end": "2239280"
  },
  {
    "text": "is more than 10x or 100x uh different than without tiered and",
    "start": "2239280",
    "end": "2245839"
  },
  {
    "text": "stuff like that so the thresholds totally change so for for this one for the last one here",
    "start": "2245839",
    "end": "2250880"
  },
  {
    "text": "to achieve similar runs it'll actually have i'll have to run it more times so basically if i would have run it more",
    "start": "2250880",
    "end": "2256960"
  },
  {
    "text": "times it would have crossed that threshold and you would have seen a better optimized code so it would have gone to tier four",
    "start": "2256960",
    "end": "2263040"
  },
  {
    "text": "so it's like that's one of the reasons why we have that reduced performance there",
    "start": "2263040",
    "end": "2270960"
  },
  {
    "text": "i think um i would like anil to come back on stage because most of his work is amazing and",
    "start": "2270960",
    "end": "2277040"
  },
  {
    "text": "i'd like you to summarize please okay thank you so i think the main summary we want to take away from the",
    "start": "2277040",
    "end": "2283599"
  },
  {
    "text": "jdk 8 to 11 or even up to 13 was if you are running long steady state",
    "start": "2283599",
    "end": "2290320"
  },
  {
    "text": "mostly throughput bound you may not see much difference between 8 11 12 13 4. there could be some cases",
    "start": "2290320",
    "end": "2297359"
  },
  {
    "text": "where you are better but usually when we did not find across this benchmark a big difference",
    "start": "2297359",
    "end": "2302960"
  },
  {
    "text": "but if you're talking about workload with responsiveness where you have the slas you are looking at those low pass time etc you would see",
    "start": "2302960",
    "end": "2310480"
  },
  {
    "text": "significant improvement in your responsiveness and you would also see significant improvement in your variability",
    "start": "2310480",
    "end": "2317040"
  },
  {
    "text": "and the thing we came found to relate to it's mostly the changes from the parallel gc to g1 gc",
    "start": "2317040",
    "end": "2323280"
  },
  {
    "text": "because those pause time etc are giving you more consistency and better response time the end to end response time that's what",
    "start": "2323280",
    "end": "2330320"
  },
  {
    "text": "we so if that is your goal on different applicant then it is worth moving or evaluating up to",
    "start": "2330320",
    "end": "2336400"
  },
  {
    "text": "11 or even higher for latest is coming in the",
    "start": "2336400",
    "end": "2341839"
  },
  {
    "text": "last one is the when you have the short running workloads as we saw with the cup also you you may want to check there because",
    "start": "2341839",
    "end": "2348720"
  },
  {
    "text": "there could be some issue with g1gc and we do plan to give this feedback to openjdk to see if they can be addressed",
    "start": "2348720",
    "end": "2355119"
  },
  {
    "text": "as monica just pointing with the humongous object sizes causing the issue and you are seeing worst performance in",
    "start": "2355119",
    "end": "2361839"
  },
  {
    "text": "that case and we we know that current trend the last one was containers",
    "start": "2361839",
    "end": "2367520"
  },
  {
    "text": "are being used very heavily almost 40 50 percent and the next one on the growth is the function as service",
    "start": "2367520",
    "end": "2372960"
  },
  {
    "text": "in many areas so i think that scenario will happen so it would be good i think to have that",
    "start": "2372960",
    "end": "2378640"
  },
  {
    "text": "part but definitely right now you need to watch for g1gc with regard to short",
    "start": "2378640",
    "end": "2383760"
  },
  {
    "text": "startup timings related workload and situations and as for aot",
    "start": "2383760",
    "end": "2389119"
  },
  {
    "text": "monika was just talking about you have to be there also just watch if it is long term then you",
    "start": "2389119",
    "end": "2394960"
  },
  {
    "text": "might be better off without and but if it is short function and service type thing then aod definitely giving",
    "start": "2394960",
    "end": "2400640"
  },
  {
    "text": "you faster response times so i think with that we definitely want to know more",
    "start": "2400640",
    "end": "2406240"
  },
  {
    "text": "because we are also in in the spec committee working on making changes as you saw like earlier the",
    "start": "2406240",
    "end": "2412400"
  },
  {
    "text": "workloads were all like spec gbm 2008 more just throughput you do something",
    "start": "2412400",
    "end": "2417680"
  },
  {
    "text": "compute memory and throughput then we change into respect just on 15 we change it into more response time where",
    "start": "2417680",
    "end": "2424400"
  },
  {
    "text": "you can see the difference on response time and repeatability so similar changes we planning next and",
    "start": "2424400",
    "end": "2430400"
  },
  {
    "text": "we do we are looking into parallels these parallel streams and the other changes coming in but if you have the use case",
    "start": "2430400",
    "end": "2437040"
  },
  {
    "text": "from your area here these are my problem points these are the use cases we definitely want to reflect them",
    "start": "2437040",
    "end": "2442720"
  },
  {
    "text": "into the benchmarks that is one of our goal so they can be used to evaluation as you saw that even to at least three",
    "start": "2442720",
    "end": "2450000"
  },
  {
    "text": "or four large customers i have talked about they have 4000 applications but they can't use them for testing or evaluating",
    "start": "2450000",
    "end": "2457520"
  },
  {
    "text": "so your collaboration and be very open to such collaboration you have",
    "start": "2457520",
    "end": "2462560"
  },
  {
    "text": "my email and things there monica so that would be great and any questions or so",
    "start": "2462560",
    "end": "2471440"
  },
  {
    "text": "[Applause] so we'll take questions",
    "start": "2472580",
    "end": "2481838"
  },
  {
    "text": "um we use g1 gc with jdk8 itself is it recommended",
    "start": "2486960",
    "end": "2493359"
  },
  {
    "text": "yes so then why should we move to jdk 13 then so i think you should go to",
    "start": "2493359",
    "end": "2501040"
  },
  {
    "text": "guild stock and um that would be helpful there is definitely",
    "start": "2501040",
    "end": "2507119"
  },
  {
    "text": "in this tract today we did not have a exhaustive list but there are",
    "start": "2507119",
    "end": "2513440"
  },
  {
    "text": "lots of improvements that that moving to 11 lts would bring and",
    "start": "2513440",
    "end": "2521280"
  },
  {
    "text": "even after that probably the mts uh as gil would um we'll talk about um",
    "start": "2521280",
    "end": "2530000"
  },
  {
    "text": "that that question so one of the things that we're doing right now at microsoft we have a lot of",
    "start": "2531359",
    "end": "2536560"
  },
  {
    "text": "internal customers who are still at jdk8 so we're trying to help them to move to 11 update",
    "start": "2536560",
    "end": "2542880"
  },
  {
    "text": "and we made a list of pros and cons and how it can affect them like",
    "start": "2542880",
    "end": "2549280"
  },
  {
    "text": "multi-release jars and other things that may be helpful to them so",
    "start": "2549280",
    "end": "2554560"
  },
  {
    "text": "it's a very case specific",
    "start": "2554560",
    "end": "2559040"
  },
  {
    "text": "analysis that we have to do i can just mention all the features that you are",
    "start": "2559680",
    "end": "2565119"
  },
  {
    "text": "the benefits you can get but do they apply to your use case probably not not all of them",
    "start": "2565119",
    "end": "2570960"
  },
  {
    "text": "so you have to do evaluation of our cost benefit analysis for moving to",
    "start": "2570960",
    "end": "2577680"
  },
  {
    "text": "11. um but remember any of these kind of low latency garbage collection or even",
    "start": "2577680",
    "end": "2584560"
  },
  {
    "text": "aot for that matter those benefits you will only get when you move to",
    "start": "2584560",
    "end": "2589920"
  },
  {
    "text": "this side of nine you know okay i'll come to you first and then you",
    "start": "2589920",
    "end": "2598079"
  },
  {
    "text": "uh you're talking about how a lot of the newer garbage collectors divide the memory into regions",
    "start": "2599040",
    "end": "2604720"
  },
  {
    "text": "i was just wondering is that something that's configurable that we should be thinking about like",
    "start": "2604720",
    "end": "2609760"
  },
  {
    "text": "what size region should we use or is that something that's just handled by the gc itself",
    "start": "2609760",
    "end": "2616720"
  },
  {
    "text": "so it should it should be handled by the gc the way zgc does it is that it is adaptive",
    "start": "2616720",
    "end": "2623599"
  },
  {
    "text": "i think on the fly and um so it should not be a problem",
    "start": "2623599",
    "end": "2630400"
  },
  {
    "text": "unfortunately right now it is and that's what i was showing you with respect to decapo um we definitely want to change that so",
    "start": "2630400",
    "end": "2637839"
  },
  {
    "text": "it shouldn't be something that you should worry about that was just a bad choice when we started doing g1",
    "start": "2637839",
    "end": "2643520"
  },
  {
    "text": "so so we'll work on changing that but yeah you shouldn't worry about those things",
    "start": "2643520",
    "end": "2650400"
  },
  {
    "text": "jdk8 uh not zgc but uh i like that you say zgc",
    "start": "2653520",
    "end": "2661200"
  },
  {
    "text": "so but that's a different thing so everybody that i talk to always say z but i go back to z so anyway that's a",
    "start": "2661200",
    "end": "2667200"
  },
  {
    "text": "different thing uh but shenandoah yes i think there is uh you do get shenandoah with",
    "start": "2667200",
    "end": "2675680"
  },
  {
    "text": "jdk8 i'm not sure the status of that right now if anybody else knows please",
    "start": "2675680",
    "end": "2684079"
  },
  {
    "text": "only the red hat one okay so there is if you go to the uh there's a page maintained by alex",
    "start": "2685760",
    "end": "2692800"
  },
  {
    "text": "alexei um they would you could probably go check it out but you'll have to use their uh bits for",
    "start": "2692800",
    "end": "2700079"
  },
  {
    "text": "jdk yes yes",
    "start": "2700079",
    "end": "2706400"
  },
  {
    "text": "ah thanks for the excellent metrics it was very useful i do have like two questions out of this talk one is um i was also in a talk with",
    "start": "2706400",
    "end": "2713200"
  },
  {
    "text": "growl vm yesterday when they were talking about the jedi aot with crawl bm and i do see an aot function with java",
    "start": "2713200",
    "end": "2720000"
  },
  {
    "text": "that starts with jdk9 and grab um they also talked about being used in oracle with oracle cloud",
    "start": "2720000",
    "end": "2726560"
  },
  {
    "text": "can you help us to decide on like when do you really use the gral vm eot versus this eot",
    "start": "2726560",
    "end": "2732000"
  },
  {
    "text": "or do we even start to look into grapheme or not",
    "start": "2732000",
    "end": "2736400"
  },
  {
    "text": "so i'm not the best person to talk about that um if anybody else here would like to chime",
    "start": "2737760",
    "end": "2743200"
  },
  {
    "text": "in i would appreciate that i'm looking at you michael mikhail sorry um but um when do you did you say when",
    "start": "2743200",
    "end": "2751680"
  },
  {
    "text": "do you want to evaluate girl yeah is there a difference between the aod of uh",
    "start": "2751680",
    "end": "2757040"
  },
  {
    "text": "native that aorta natively comes with java towards what graphium is offering so this is so the jaotc",
    "start": "2757040",
    "end": "2765359"
  },
  {
    "text": "tool that i use to generate the dynamic library it is uh from the girl j so you're",
    "start": "2765359",
    "end": "2772720"
  },
  {
    "text": "talking about vm level differences but this is more of a jet level",
    "start": "2772720",
    "end": "2777760"
  },
  {
    "text": "thing growl jit is supposedly the future",
    "start": "2777760",
    "end": "2783200"
  },
  {
    "text": "okay which means that eventually c2 will be replaced by girl",
    "start": "2783200",
    "end": "2788240"
  },
  {
    "text": "girl jet not the vm so i think",
    "start": "2788240",
    "end": "2795920"
  },
  {
    "text": "this is a very big question for me to to be able to answer because i did not really i'm not the",
    "start": "2795920",
    "end": "2802079"
  },
  {
    "text": "right person to talk about growth because i don't want to provide any knowledge that may not be helpful",
    "start": "2802079",
    "end": "2807839"
  },
  {
    "text": "but yeah so jit is different though just i just want to clarify that so when you when people talk about growl vm",
    "start": "2807839",
    "end": "2814000"
  },
  {
    "text": "sometimes we because of the unfortunate it's similarly named uh but vm has a diff",
    "start": "2814000",
    "end": "2820319"
  },
  {
    "text": "a lot of different benefits so with um jdk9 i think there was a jvm ci which is the",
    "start": "2820319",
    "end": "2826960"
  },
  {
    "text": "compiler interface that was introduced and that took advantage of the growl jit and that's how we get aot so it's from",
    "start": "2826960",
    "end": "2834160"
  },
  {
    "text": "the same uh source i would say but i have not done any performance analysis on",
    "start": "2834160",
    "end": "2839520"
  },
  {
    "text": "coral jet uh aot with that oh you know it of course mark i'll talk",
    "start": "2839520",
    "end": "2845599"
  },
  {
    "text": "a little bit about that later today sorry i'll i'll be talking a",
    "start": "2845599",
    "end": "2851760"
  },
  {
    "text": "little bit about that point in my talk later today that talk isn't specifically about growl",
    "start": "2851760",
    "end": "2856800"
  },
  {
    "text": "i'm not from the girl team i don't represent them but but my talk is about some of the trade-offs in",
    "start": "2856800",
    "end": "2861839"
  },
  {
    "text": "how do you choose whether to use jet or to use aot or to use any of the other technology so i'll i'll touch on it a",
    "start": "2861839",
    "end": "2867599"
  },
  {
    "text": "little bit so i encourage you to attend",
    "start": "2867599",
    "end": "2872078"
  },
  {
    "text": "i think i did mention that i don't know if you were here uh so you will talk about the the future the directions so that",
    "start": "2876240",
    "end": "2882720"
  },
  {
    "text": "would be a good talk for you to attend to kind of understand uh aot is just the",
    "start": "2882720",
    "end": "2887920"
  },
  {
    "text": "start right so there's more so another reason for somebody to move to um the lady asked us why",
    "start": "2887920",
    "end": "2894880"
  },
  {
    "text": "should i move right that's another reason to move uh is because of the all the improvements that will happen",
    "start": "2894880",
    "end": "2900640"
  },
  {
    "text": "and it will be on the jdk8 uh code base mostly jdk9 sorry",
    "start": "2900640",
    "end": "2906880"
  },
  {
    "text": "and the other part would be on the same on why to move we have seen in like spec 2015 the fork joint it's not easy",
    "start": "2906880",
    "end": "2913760"
  },
  {
    "text": "to use the the different thing we had to do but parallel stream have been done much uh",
    "start": "2913760",
    "end": "2919680"
  },
  {
    "text": "much better improvement and one of the thing you may want to find anytime you have the thread pool and you the within micro service or",
    "start": "2919680",
    "end": "2927040"
  },
  {
    "text": "other situations you want to the auto balancing it really requires some very well thought so which is",
    "start": "2927040",
    "end": "2932960"
  },
  {
    "text": "with parallel stream in nine or higher you might have better job if you do need the load balancing",
    "start": "2932960",
    "end": "2939200"
  },
  {
    "text": "through thread pool and it is a tricky issue now because you have the j if you are within a vm you might have",
    "start": "2939200",
    "end": "2945280"
  },
  {
    "text": "only eight core or your whole system you might have 256 core and you don't know how your application",
    "start": "2945280",
    "end": "2951599"
  },
  {
    "text": "will behave on those two extremes so there may be some some consideration but there is no",
    "start": "2951599",
    "end": "2957280"
  },
  {
    "text": "perfect answer to this you have to try how it is behaving",
    "start": "2957280",
    "end": "2962160"
  },
  {
    "text": "okay we're at time so we can take questions later but thank you all for being here thank",
    "start": "2962400",
    "end": "2967599"
  },
  {
    "text": "you thank you",
    "start": "2967599",
    "end": "2971839"
  }
]
[
  {
    "start": "0",
    "end": "74000"
  },
  {
    "text": "so today we're going to be talking about machine learning on mobile and edge devices specifically with a tensorflow",
    "start": "3870",
    "end": "10410"
  },
  {
    "text": "light flavor and I'll talk a little bit about what that is in a moment so my",
    "start": "10410",
    "end": "16619"
  },
  {
    "text": "name is Daniel satanica I work at Google I'm a developer advocate for tensorflow light which means I'm an engineer who",
    "start": "16619",
    "end": "23610"
  },
  {
    "text": "works on the tensorflow light team but helps the tensorflow light team understand and integrate with our",
    "start": "23610",
    "end": "29220"
  },
  {
    "text": "community so I do stuff like building our examples and working on bugs that we",
    "start": "29220",
    "end": "35309"
  },
  {
    "text": "find from our community I'm also the co-author of this book which is coming out in mid-december called tiny ml and",
    "start": "35309",
    "end": "42449"
  },
  {
    "text": "it's the first book about machine learning specifically deep learning on devices that are really small so this is",
    "start": "42449",
    "end": "48719"
  },
  {
    "text": "the kind of models Wes mentioned that are like 15 20 kilobytes but can do things like speech recognition or",
    "start": "48719",
    "end": "55050"
  },
  {
    "text": "gesture detection so tensorflow light which is what I work on at Google is a",
    "start": "55050",
    "end": "62010"
  },
  {
    "text": "production framework for deploying ml on all sorts of different devices so that's",
    "start": "62010",
    "end": "67080"
  },
  {
    "text": "everything from mobile devices on down I'll talk a little bit about some of those categories of devices as we get",
    "start": "67080",
    "end": "73530"
  },
  {
    "text": "further along and but in our goals today I want to kind of inspire you to let you",
    "start": "73530",
    "end": "79890"
  },
  {
    "start": "74000",
    "end": "161000"
  },
  {
    "text": "know what is possible with machine learning on device at the edge of the network I also want to make sure we all",
    "start": "79890",
    "end": "87240"
  },
  {
    "text": "have the same level of understanding of what machine learning is and the kinds of things it can do and how we do that",
    "start": "87240",
    "end": "93990"
  },
  {
    "text": "stuff and finally I want to give some actionable next steps so if you're interested in this space like how do you",
    "start": "93990",
    "end": "100230"
  },
  {
    "text": "get involved where can you learn more how can you get started and I kind of wanted to see right at the beginning who",
    "start": "100230",
    "end": "106170"
  },
  {
    "text": "has a background in machine learning if you give raise your hand awesome so we've got a few people and",
    "start": "106170",
    "end": "112550"
  },
  {
    "text": "who's heard of tensorflow ok awesome most people and then who has worked on",
    "start": "112550",
    "end": "120960"
  },
  {
    "text": "edge devices so maybe you're a mobile developer or even mobile web or embedded",
    "start": "120960",
    "end": "127369"
  },
  {
    "text": "ok so that's a little more than half so that's really awesome so I'm going to be",
    "start": "127369",
    "end": "132510"
  },
  {
    "text": "able to give a kind of intro to ml presumably evil herd of ML to some degree but I'll kind",
    "start": "132510",
    "end": "139770"
  },
  {
    "text": "of cover the basics of what it is then we'll talk a little bit about ml on device and why that makes sense and then",
    "start": "139770",
    "end": "146790"
  },
  {
    "text": "I'll go into some specifics of tensor flow but there's some of the hairy stuff I'll skip over really quickly because it",
    "start": "146790",
    "end": "154320"
  },
  {
    "text": "might not be relevant if you haven't used tensor flow a lot already but we can always talk at the end about that",
    "start": "154320",
    "end": "159780"
  },
  {
    "text": "too so first of all I want to talk about what is machine learning and so the",
    "start": "159780",
    "end": "166709"
  },
  {
    "start": "161000",
    "end": "362000"
  },
  {
    "text": "easiest ways to talk about this is talk about like what is not machine learning and the standard way that we build",
    "start": "166709",
    "end": "172709"
  },
  {
    "text": "programs obviously is not machine learning so if I'm going to build a program generally I am writing some",
    "start": "172709",
    "end": "179520"
  },
  {
    "text": "rules that apply to some data so I might write a function here so here we're",
    "start": "179520",
    "end": "186020"
  },
  {
    "text": "doing a calculation based on some data and that happens through rules that we",
    "start": "186020",
    "end": "192030"
  },
  {
    "text": "express in code and when that function runs we get some answers back and so the",
    "start": "192030",
    "end": "198420"
  },
  {
    "text": "computation happens in that one place where we're taking taking the data running it through some rules and",
    "start": "198420",
    "end": "204299"
  },
  {
    "text": "getting some answers similarly a video game works in the same way so there's",
    "start": "204299",
    "end": "209820"
  },
  {
    "text": "some stuff going on in a kind of virtual environment and there are some rules which apply whenever stuff happens and",
    "start": "209820",
    "end": "217470"
  },
  {
    "text": "so all these types of things that we're familiar with as engineers in the past generally used this type of programming",
    "start": "217470",
    "end": "225120"
  },
  {
    "text": "we're coming up with rule sets that handle stuff that happens in an environment so pretty much what is going",
    "start": "225120",
    "end": "231690"
  },
  {
    "text": "on is we create some rules and we create some data and we feed them into this box",
    "start": "231690",
    "end": "237360"
  },
  {
    "text": "and out of the box we get answers so machine learning kind of screws this up",
    "start": "237360",
    "end": "243810"
  },
  {
    "text": "a little bit so instead of feeding in rules and data we feed in answers and",
    "start": "243810",
    "end": "249120"
  },
  {
    "text": "data and in our box actually figures out how to return some rules which we can",
    "start": "249120",
    "end": "254760"
  },
  {
    "text": "then apply in the future so I'll talk to you what that means so imagine we're doing the classical",
    "start": "254760",
    "end": "260910"
  },
  {
    "text": "style of building an application to determine what kind of activity people are performing so in this case we can",
    "start": "260910",
    "end": "268200"
  },
  {
    "text": "look at the person's speed so imagine someone is walking if they're going less than 4 miles per hour maybe",
    "start": "268200",
    "end": "274710"
  },
  {
    "text": "we can say that they are walking so maybe if they're going greater than 4",
    "start": "274710",
    "end": "280740"
  },
  {
    "text": "miles per hour or 4 miles per hour and above their status can be running and",
    "start": "280740",
    "end": "286040"
  },
  {
    "text": "then maybe we can come up with a rule that says hey like if this person is going even faster faster than a human",
    "start": "286040",
    "end": "292320"
  },
  {
    "text": "can run they're probably cycling but then what do we do if they're doing something",
    "start": "292320",
    "end": "297810"
  },
  {
    "text": "completely different our rules just don't work for this they break down the simple heuristic that we've chosen doesn't make sense anymore",
    "start": "297810",
    "end": "305960"
  },
  {
    "text": "so this is how the traditional programming model works let's have a look at how this might work in a machine",
    "start": "305960",
    "end": "312090"
  },
  {
    "text": "learning application so in this case we have maybe a sensor that's attached to a",
    "start": "312090",
    "end": "318510"
  },
  {
    "text": "smart device that the person is wearing and we're taking raw data from that sensor and we're going to train a",
    "start": "318510",
    "end": "324690"
  },
  {
    "text": "machine learning algorithm to understand that so in the case that the person is",
    "start": "324690",
    "end": "330270"
  },
  {
    "text": "walking we feed in the data for that and we feed in a label that they are what that says they are walking into our",
    "start": "330270",
    "end": "336510"
  },
  {
    "text": "model and we do the same for running the same for biking and the same for golfing",
    "start": "336510",
    "end": "341700"
  },
  {
    "text": "so we have basically fed all of these things into this model that we're training we've said here is what the",
    "start": "341700",
    "end": "348090"
  },
  {
    "text": "data looks like for walking here's what the data looks like for running and so on and our model can learn to",
    "start": "348090",
    "end": "353670"
  },
  {
    "text": "distinguish between these categories without us knowing the exact rules and the exact heuristics that indicate those",
    "start": "353670",
    "end": "360240"
  },
  {
    "text": "that the model figures that out for us so I want to give a quick demo of this",
    "start": "360240",
    "end": "365280"
  },
  {
    "start": "362000",
    "end": "581000"
  },
  {
    "text": "in action it's a live demo so I apologize in advance if it doesn't work but I'm going to use a tool that we have",
    "start": "365280",
    "end": "373280"
  },
  {
    "text": "released originally at Google called teachable machine so you can try this yourself it's totally free teachable",
    "start": "373280",
    "end": "380010"
  },
  {
    "text": "machine is basically a studio for training your own machine learning models very easily for prototyping",
    "start": "380010",
    "end": "386120"
  },
  {
    "text": "experiences super fast so I'm going to get started here I'm going to do an",
    "start": "386120",
    "end": "391800"
  },
  {
    "text": "image based project and what I'm going to do is do rock-paper-scissors recognition model so each of the",
    "start": "391800",
    "end": "399690"
  },
  {
    "text": "activities that I'm trying to classify is like either rock paper or scissors is",
    "start": "399690",
    "end": "404850"
  },
  {
    "text": "represented here so I'm going to make those so I got rock paper and scissors",
    "start": "404850",
    "end": "412940"
  },
  {
    "text": "okay and then I'm gonna capture some camera data of myself doing the rock",
    "start": "412940",
    "end": "418110"
  },
  {
    "text": "paper and scissors sighs does everybody know what Rock Paper Scissors is okay awesome so I'll do that via the webcam",
    "start": "418110",
    "end": "426570"
  },
  {
    "text": "and so I just need to capture a bunch of photos of myself doing this like rock",
    "start": "426570",
    "end": "432330"
  },
  {
    "text": "side so I'm gonna try that now so hopefully my image appears there we go",
    "start": "432330",
    "end": "438240"
  },
  {
    "text": "so here's my rock so I'm turning it all around so you can see it from a bunch of",
    "start": "438240",
    "end": "443550"
  },
  {
    "text": "different angles so it understands not just one image of a hand but the",
    "start": "443550",
    "end": "450540"
  },
  {
    "text": "generally a hand rotated all around can still represent rock so I'm going to do",
    "start": "450540",
    "end": "455640"
  },
  {
    "text": "the same for paper okay so I don't",
    "start": "455640",
    "end": "464190"
  },
  {
    "text": "really need that much data here and let's do the same for scissors now",
    "start": "464190",
    "end": "469668"
  },
  {
    "text": "all right so I've got sort of less than a hundred samples for some of them the rock has a few more because as talking",
    "start": "473729",
    "end": "480270"
  },
  {
    "text": "was to hang it but it doesn't really matter so what we're going to do now is train a model that uses these images and",
    "start": "480270",
    "end": "488639"
  },
  {
    "text": "the labels to understand what is meant by rock paper and scissors gesture so",
    "start": "488639",
    "end": "494879"
  },
  {
    "text": "what happens during training is very complicated I'm not going to go into it now but there's a lot of literature and",
    "start": "494879",
    "end": "501330"
  },
  {
    "text": "a lot of interesting stuff online that you can read about how this works and but essentially what we're doing here is",
    "start": "501330",
    "end": "506610"
  },
  {
    "text": "we're taking a model that was already trained on vision so it understands how to break apart a visual scene into lots",
    "start": "506610",
    "end": "514050"
  },
  {
    "text": "of different shapes colors and objects and things and then we take that pre",
    "start": "514050",
    "end": "519990"
  },
  {
    "text": "train model and we can customize it a little bit so it specifically understands what the rock paper and",
    "start": "519990",
    "end": "525810"
  },
  {
    "text": "scissors just just made so right now I'm not doing anything so it's oscillating wildly between the three but let's see",
    "start": "525810",
    "end": "531660"
  },
  {
    "text": "if I can do rock we got really high confidence there if I did paper also",
    "start": "531660",
    "end": "537420"
  },
  {
    "text": "works and then scissors so this is a little bit harder to discern from paper",
    "start": "537420",
    "end": "542550"
  },
  {
    "text": "but yeah there we go it's working pretty well and so you can see like this is how much team learning works you capture",
    "start": "542550",
    "end": "548819"
  },
  {
    "text": "data label it feed it into a model during training but the model gets",
    "start": "548819",
    "end": "554490"
  },
  {
    "text": "adjusted so that it can do this stuff in the future and then you get something pretty robust potentially pretty quickly",
    "start": "554490",
    "end": "559910"
  },
  {
    "text": "the technology to do this the the basic concepts have been around awhile but to be able to do this reliably and",
    "start": "559910",
    "end": "567060"
  },
  {
    "text": "so easily and so quickly this stuff's only been figured out in the last five years or so so it's pretty",
    "start": "567060",
    "end": "572760"
  },
  {
    "text": "exciting so let me pause that for now and we'll go back to our presentation so before we",
    "start": "572760",
    "end": "584160"
  },
  {
    "start": "581000",
    "end": "702000"
  },
  {
    "text": "go on I want to cover some key terms just so that we're able to talk about this stuff fluently so the first thing",
    "start": "584160",
    "end": "591420"
  },
  {
    "text": "that I'll define is a data set so a data set is the data that we're going to be feeding into the model during training",
    "start": "591420",
    "end": "598440"
  },
  {
    "text": "and that includes in the case I just showed the photos of meeting the gesture",
    "start": "598440",
    "end": "603449"
  },
  {
    "text": "and also the label training is the process of taking a",
    "start": "603449",
    "end": "609760"
  },
  {
    "text": "model so a model is basically a bunch of",
    "start": "609760",
    "end": "614800"
  },
  {
    "text": "data structures that are woven together in a certain way and gradually adjusting",
    "start": "614800",
    "end": "620080"
  },
  {
    "text": "that model so that it is able to make predictions based on that data set the",
    "start": "620080",
    "end": "626740"
  },
  {
    "text": "model itself at the end of training can be represented either as arrays in",
    "start": "626740",
    "end": "632170"
  },
  {
    "text": "memory or as data on disk so it's essentially you can think of it as a file like a package of information that",
    "start": "632170",
    "end": "639670"
  },
  {
    "text": "contains a represented representation of how to make the predictions that we train the model for so that's kind of",
    "start": "639670",
    "end": "646210"
  },
  {
    "text": "portable you can like take it from device to device and run it in different places and the process of running the",
    "start": "646210",
    "end": "653710"
  },
  {
    "text": "model is called inference so when you take a thing the model hasn't seen",
    "start": "653710",
    "end": "659260"
  },
  {
    "text": "before and you run it through the model and get a prediction that process is called inference so that's separate from",
    "start": "659260",
    "end": "665800"
  },
  {
    "text": "training which is where you take some labelled data and teach the model how to understand it so those are the two main",
    "start": "665800",
    "end": "672160"
  },
  {
    "text": "parts of machine learning training and inference and what I'm going to talk about today mostly falls into the bucket",
    "start": "672160",
    "end": "678160"
  },
  {
    "text": "of inference because inference is the thing is most useful to do on edge devices training usually takes quite a",
    "start": "678160",
    "end": "685150"
  },
  {
    "text": "lot of power quite a lot of memory and quite a lot of time and those are generally three things that edge devices",
    "start": "685150",
    "end": "691600"
  },
  {
    "text": "don't have so we're really mostly talking about inference here but there are some cool technologies for doing",
    "start": "691600",
    "end": "697000"
  },
  {
    "text": "training on edge devices and we'll talk about those later if anyone has any questions so what inference looks like",
    "start": "697000",
    "end": "705190"
  },
  {
    "start": "702000",
    "end": "824000"
  },
  {
    "text": "in an application is this so first of all we have our model and we load it",
    "start": "705190",
    "end": "710440"
  },
  {
    "text": "into memory we then take our input data and we transform it into a way that fits",
    "start": "710440",
    "end": "717580"
  },
  {
    "text": "the model so every model has different sort of input parameters for example the model we just train here the model would",
    "start": "717580",
    "end": "725200"
  },
  {
    "text": "have had a fixed input size so it takes an image with a certain number of pixels so if we've got data from a camera that",
    "start": "725200",
    "end": "732580"
  },
  {
    "text": "has a different resolution we want to transform that so it fits the size of the model",
    "start": "732580",
    "end": "738220"
  },
  {
    "text": "we have to do that generally - we then run inference which is done by an interpreter which takes the model takes",
    "start": "738220",
    "end": "745270"
  },
  {
    "text": "the data runs the data through the model and gives us the results and then we figure out how to use the resulting",
    "start": "745270",
    "end": "751150"
  },
  {
    "text": "output so sometimes that's very easy it's just some like category scores in an array sometimes it's something that's",
    "start": "751150",
    "end": "757810"
  },
  {
    "text": "a little bit more complicated and we need to write some application code to make it clear what's going on so to show",
    "start": "757810",
    "end": "765430"
  },
  {
    "text": "you all the parts of this application just sort of a typical ml application first of all we have our input data that",
    "start": "765430",
    "end": "772240"
  },
  {
    "text": "could be captured from a sensor or a device or it could be just data that exists in memory somewhere we then do",
    "start": "772240",
    "end": "780340"
  },
  {
    "text": "some pre-processing so we're getting it ready to feed into the model and every model has a different format that it",
    "start": "780340",
    "end": "786190"
  },
  {
    "text": "expects and that's just defined by whoever created the model we then load",
    "start": "786190",
    "end": "792100"
  },
  {
    "text": "the model and use an interpreter to run inference using the model and then we do",
    "start": "792100",
    "end": "798340"
  },
  {
    "text": "some post-processing that interprets the model's output and helps us make sense of it in context of our application and",
    "start": "798340",
    "end": "805360"
  },
  {
    "text": "then we can use that to do something cool for the user so tensorflow light",
    "start": "805360",
    "end": "810970"
  },
  {
    "text": "has to link to do all of this stuff so it has components that cover every",
    "start": "810970",
    "end": "816190"
  },
  {
    "text": "aspect of this process and that you can use to kind of easily build mobile and embedded applications that use machine",
    "start": "816190",
    "end": "823390"
  },
  {
    "text": "learning so in our kind of exploration of TF light we're going to go through an",
    "start": "823390",
    "end": "829300"
  },
  {
    "start": "824000",
    "end": "923000"
  },
  {
    "text": "intro we'll talk about how to get started with tensorflow lights how to make the most of it once you start using",
    "start": "829300",
    "end": "836050"
  },
  {
    "text": "it seriously and then we're also going to talk about running tensorflow light on microcontrollers or m/c use which are",
    "start": "836050",
    "end": "842080"
  },
  {
    "text": "the tiny devices that power all of our gadgets read that is smaller than a mobile phone or embedded Linux device so",
    "start": "842080",
    "end": "850840"
  },
  {
    "text": "the thing driving like doing ml on edge devices is threefold so first of all if",
    "start": "850840",
    "end": "860170"
  },
  {
    "text": "you do ml on a device you have lower latency like the original model the kind",
    "start": "860170",
    "end": "865780"
  },
  {
    "text": "of like from a couple years ago model of ml is that you have some big crazy ml model running on a big",
    "start": "865780",
    "end": "871600"
  },
  {
    "text": "powerful service somewhere and if you want to do machine learning inference no matter what it's for you send your data",
    "start": "871600",
    "end": "877089"
  },
  {
    "text": "up to that server and the server does some computation and sends you the result back so that results in pretty",
    "start": "877089",
    "end": "882970"
  },
  {
    "text": "high latency so you're not going to be able to do nice like real-time video or audio stuff in that case and all your",
    "start": "882970",
    "end": "889360"
  },
  {
    "text": "interactions are gonna have some latency and you're gonna have to worry about things like bandwidth so network",
    "start": "889360",
    "end": "896380"
  },
  {
    "text": "connectivity is kind of an issue if you're you're trying to do inference and it's not on device and this comes down",
    "start": "896380",
    "end": "902620"
  },
  {
    "text": "to bandwidth and latency like I mentioned the other thing is if we're able to do ml on device then none of the",
    "start": "902620",
    "end": "910060"
  },
  {
    "text": "data needs to go to the cloud and that's much better for the user and it's much better for you as a developer because",
    "start": "910060",
    "end": "915279"
  },
  {
    "text": "you don't have to deal with a hairy issues surrounding user data so I'm going to talk about these sort of",
    "start": "915279",
    "end": "921370"
  },
  {
    "text": "continually through the talk so if you can do away with some of these problems",
    "start": "921370",
    "end": "927399"
  },
  {
    "start": "923000",
    "end": "1060000"
  },
  {
    "text": "you're able to build a whole generation of new products that just weren't possible before if we're thinking about",
    "start": "927399",
    "end": "933430"
  },
  {
    "text": "medical devices that can operate without interesting loads of user data or devices that are doing video",
    "start": "933430",
    "end": "940800"
  },
  {
    "text": "modification in real time and we'll show some of that in a second so this is an example of something which you really",
    "start": "940800",
    "end": "947199"
  },
  {
    "text": "struggle to do with server-side ml so on the device here we have a model that's",
    "start": "947199",
    "end": "952689"
  },
  {
    "text": "doing facial landmark detection so it can pick out where your eyes ears mouth and nose are and that's allowing the app",
    "start": "952689",
    "end": "959800"
  },
  {
    "text": "developer to add some animations and add some features onto a photo so if we're trying to do this over a network",
    "start": "959800",
    "end": "965589"
  },
  {
    "text": "connection it would be really laggy and slow and you just wouldn't have that great and experience whereas here",
    "start": "965589",
    "end": "970810"
  },
  {
    "text": "running on a phone it works really nicely another example of this is we're",
    "start": "970810",
    "end": "976480"
  },
  {
    "text": "doing pose estimation so this is a type of ML model that takes an image of a",
    "start": "976480",
    "end": "982240"
  },
  {
    "text": "person as an input and it's able to figure out what their different limbs and body parts are and give you",
    "start": "982240",
    "end": "988360"
  },
  {
    "text": "coordinates for those so in this case the kids able to get a reward in the app",
    "start": "988360",
    "end": "993819"
  },
  {
    "text": "for having their are dancing matched up with the dancing in the little video this inset and this is another kind of",
    "start": "993819",
    "end": "1000000"
  },
  {
    "text": "thing where you need super low latency happen on device and also you probably if you have built a game or a toy don't",
    "start": "1000000",
    "end": "1006980"
  },
  {
    "text": "want to be streaming loads of data it's bad from a privacy perspective and it also means you have to spend a lot on",
    "start": "1006980",
    "end": "1012500"
  },
  {
    "text": "bandwidth so in this case is super suited to edge ml and here's another use",
    "start": "1012500",
    "end": "1019459"
  },
  {
    "text": "case imagine you're on vacation somewhere or you're reading a book in a",
    "start": "1019459",
    "end": "1026089"
  },
  {
    "text": "foreign language and you want to look at definitions for words and you maybe don't have good connectivity so this is",
    "start": "1026089",
    "end": "1032720"
  },
  {
    "text": "a really good example of another place where an edge model makes sense because you can do all sorts of stuff on device",
    "start": "1032720",
    "end": "1041329"
  },
  {
    "text": "that maybe you won't be able to do if you didn't have an internet connection so there are thousands and thousands of",
    "start": "1041329",
    "end": "1048319"
  },
  {
    "text": "apps using ml and using tensorflow light for edge ml at the moment google uses it",
    "start": "1048319",
    "end": "1053480"
  },
  {
    "text": "across pretty much all of its experiences and then there are a bunch of big international companies that are also doing really cool stuff there are",
    "start": "1053480",
    "end": "1061820"
  },
  {
    "start": "1060000",
    "end": "1184000"
  },
  {
    "text": "three billion plus mobile devices globally that are running tensorflow",
    "start": "1061820",
    "end": "1067280"
  },
  {
    "text": "light in production so this is a really good platform a really good tool to learn if you're interested in doing this",
    "start": "1067280",
    "end": "1072980"
  },
  {
    "text": "type of thing because it's it already out there there are a bunch of guides and a bunch of examples of how to use",
    "start": "1072980",
    "end": "1078620"
  },
  {
    "text": "things and it's battle tested by some of the biggest companies but beyond mobile",
    "start": "1078620",
    "end": "1084650"
  },
  {
    "text": "devices tensorflow light works in a bunch of different places so Android and iOS obviously big targets another place",
    "start": "1084650",
    "end": "1092179"
  },
  {
    "text": "is embedded Linux so if you're building stuff on things like raspberry pi and similar platforms you can use tensorflow",
    "start": "1092179",
    "end": "1098630"
  },
  {
    "text": "Lite to run inference on device in maybe an industrial setting or we've seen",
    "start": "1098630",
    "end": "1103670"
  },
  {
    "text": "people doing things on wildlife monitoring stations that are set up in the jungle somewhere or places that are",
    "start": "1103670",
    "end": "1110929"
  },
  {
    "text": "disconnected from a network but you want to have some degree of intelligence we also have support for hardware",
    "start": "1110929",
    "end": "1117230"
  },
  {
    "text": "acceleration so this category of devices that are basically small embedded Linux",
    "start": "1117230",
    "end": "1122660"
  },
  {
    "text": "ports with a chip on board that is dedicated to running ml inference really",
    "start": "1122660",
    "end": "1128780"
  },
  {
    "text": "fast so there are chips from Google we have the single the edge TPU which lets",
    "start": "1128780",
    "end": "1134270"
  },
  {
    "text": "you run Excel inference on these kind of devices I'm NVIDIA has some similar products and",
    "start": "1134270",
    "end": "1139600"
  },
  {
    "text": "they're a ton of them that are on the way and our final target are micro controllers so micro controllers are a",
    "start": "1139600",
    "end": "1146710"
  },
  {
    "text": "little bit in a class of their own here because they have such smaller access to",
    "start": "1146710",
    "end": "1152560"
  },
  {
    "text": "resources so in terms of memory and processing power they're vastly smaller they might have a a couple hundred K of",
    "start": "1152560",
    "end": "1159010"
  },
  {
    "text": "RAM maybe a 48 megahertz processor they're designed for very low power",
    "start": "1159010",
    "end": "1165070"
  },
  {
    "text": "consumption and we're able to run tensorflow light on those we can only run much smaller models but you can do",
    "start": "1165070",
    "end": "1171010"
  },
  {
    "text": "some really exciting stuff still so we're pretty much running the gamut from really powerful little supercomputers",
    "start": "1171010",
    "end": "1177850"
  },
  {
    "text": "like mobile phones all the way down to tiny little microcontrollers that cost a couple of cents each so I want to talk a",
    "start": "1177850",
    "end": "1186760"
  },
  {
    "start": "1184000",
    "end": "1312000"
  },
  {
    "text": "little bit more about on device ml so the previous model is that we have an",
    "start": "1186760",
    "end": "1191800"
  },
  {
    "text": "internet connection to a big server that's powerful and running ml and the",
    "start": "1191800",
    "end": "1198970"
  },
  {
    "text": "device is located in an environment where it's collecting data and in order to run inference on that data and do",
    "start": "1198970",
    "end": "1205000"
  },
  {
    "text": "anything intelligent it has to send that data back so with ml on the edge the",
    "start": "1205000",
    "end": "1211090"
  },
  {
    "text": "only part of this system that exists is just the connection between the environment and the device you don't",
    "start": "1211090",
    "end": "1216250"
  },
  {
    "text": "have to worry about other connectivity so that helps you with bandwidth so you're not sending a lots of data",
    "start": "1216250",
    "end": "1221740"
  },
  {
    "text": "everywhere it helps you with latency so things like music or video you can actually build",
    "start": "1221740",
    "end": "1227710"
  },
  {
    "text": "applications that work that have lower latency that humans are able to humans are able to perceive it's much better",
    "start": "1227710",
    "end": "1235000"
  },
  {
    "text": "from a privacy and security perspective because you're not sending people's data anywhere and it rules out a load of",
    "start": "1235000",
    "end": "1242080"
  },
  {
    "text": "complexity so you don't have to maintain this back-end ml infrastructure that you might not have any experience with and",
    "start": "1242080",
    "end": "1248680"
  },
  {
    "text": "instead you can just do everything on device so there are some challenges that",
    "start": "1248680",
    "end": "1254530"
  },
  {
    "text": "come with this so one of them I mentioned a few times are you might not have access to much compute power so the",
    "start": "1254530",
    "end": "1261010"
  },
  {
    "text": "extreme cases these tiny little microcontrollers with very little memory and processing ability but even a mobile",
    "start": "1261010",
    "end": "1267220"
  },
  {
    "text": "phone you have think about how much computation you want to do in order to preserve battery life and things like that you might not",
    "start": "1267220",
    "end": "1275610"
  },
  {
    "text": "have met a lot of memory no matter where this thing is running and battery is always really important so whether it's",
    "start": "1275610",
    "end": "1282480"
  },
  {
    "text": "on a SmartWatch or an embedded device you're always going to think about power so tensorflow light is designed to make",
    "start": "1282480",
    "end": "1289620"
  },
  {
    "text": "it easier to address some of these issues and the other big thing it allows you to do is take an existing ml model",
    "start": "1289620",
    "end": "1297510"
  },
  {
    "text": "convert it for use with ten surfer lights and then deploy that same model to any kind of platform so whether you",
    "start": "1297510",
    "end": "1303900"
  },
  {
    "text": "want to be running on iOS or Android or on an embedded Linux device the same model bit will be supported in multiple",
    "start": "1303900",
    "end": "1310680"
  },
  {
    "text": "places so I want to talk a little bit about how to actually use tensorflow",
    "start": "1310680",
    "end": "1315870"
  },
  {
    "start": "1312000",
    "end": "1451000"
  },
  {
    "text": "Lite I'll probably go through this like a fairly high level there's a lot of",
    "start": "1315870",
    "end": "1321300"
  },
  {
    "text": "documentation available but I just want to give you a taste of like the level of complexity here for an application",
    "start": "1321300",
    "end": "1326700"
  },
  {
    "text": "developer but the first thing I want to do is show you an example of TF Lite in action in a kind of bigger experience so",
    "start": "1326700",
    "end": "1334260"
  },
  {
    "text": "this year for Google i/o we built an app called dance-like and basically it's a",
    "start": "1334260",
    "end": "1339720"
  },
  {
    "text": "kind of fun experience built on tensorflow Lite that uses a bunch of chained together ml models to help you learn to be a",
    "start": "1339720",
    "end": "1346980"
  },
  {
    "text": "better dancer and so I will show you a quick video about how it works",
    "start": "1346980",
    "end": "1353630"
  },
  {
    "text": "do we have audio here",
    "start": "1355340",
    "end": "1359210"
  },
  {
    "text": "oh here we go dance like night was you to learn how to dance on the mobile",
    "start": "1379510",
    "end": "1386140"
  },
  {
    "text": "phone since our flow can take our smartphone camera and turn it into a powerful tool",
    "start": "1386140",
    "end": "1392470"
  },
  {
    "text": "for analyzing body posts we have team at Google that have developed an advanced model for doing post segmentation so we",
    "start": "1392470",
    "end": "1399520"
  },
  {
    "text": "were able to take their implementation convert it into tensorflow light once we had it there we could use it directly to",
    "start": "1399520",
    "end": "1406390"
  },
  {
    "text": "run all the AI and machine learning models to detect body parts it's a very",
    "start": "1406390",
    "end": "1411940"
  },
  {
    "text": "computationally expensive process where we need to use the on device GPUs tensor",
    "start": "1411940",
    "end": "1417640"
  },
  {
    "text": "library made it possible so that we can leverage all these resources to compute on the device and give a great user",
    "start": "1417640",
    "end": "1425260"
  },
  {
    "text": "experience teaching people to dance is just the tip of the iceberg anything that involves movement would be a great",
    "start": "1425260",
    "end": "1431590"
  },
  {
    "text": "candidate so that means people who have skills can teach other people those",
    "start": "1431590",
    "end": "1436660"
  },
  {
    "text": "skills and you know AI is just this layer that really just interfaces between the two things when you empower",
    "start": "1436660",
    "end": "1443170"
  },
  {
    "text": "people to teach people I think that's really when you have something that you know is damn changing",
    "start": "1443170",
    "end": "1449970"
  },
  {
    "start": "1451000",
    "end": "1561000"
  },
  {
    "text": "all right so to give you a sense of what this looks like in action the way it works is that you dance",
    "start": "1451700",
    "end": "1457710"
  },
  {
    "text": "alongside a professional dancer who's",
    "start": "1457710",
    "end": "1462960"
  },
  {
    "text": "dancing at full speed you dance at half speed and then we use machine learning",
    "start": "1462960",
    "end": "1468450"
  },
  {
    "text": "to take your video and speed it up and beat match you with the dancers actual movements and give you a score for how",
    "start": "1468450",
    "end": "1475380"
  },
  {
    "text": "well you did so it looks like we're having some Wi-Fi issues there but you",
    "start": "1475380",
    "end": "1483810"
  },
  {
    "text": "get the idea so the whole idea of tensorflow light is to try and make it",
    "start": "1483810",
    "end": "1491040"
  },
  {
    "text": "easier to deploy these types of applications so you can focus on building an amazing user experience",
    "start": "1491040",
    "end": "1496770"
  },
  {
    "text": "without having to focus with on all of the crazy detail of managing m/l models and designing of runtime to run them so",
    "start": "1496770",
    "end": "1504950"
  },
  {
    "text": "there are four parts to sensor flow like one part is that we offer a whole bunch",
    "start": "1504950",
    "end": "1510600"
  },
  {
    "text": "of models that you can pick up and use or customize to your own end so some of",
    "start": "1510600",
    "end": "1516210"
  },
  {
    "text": "the models we've seen already like the pose detection model they're available you can just grab them and drop them",
    "start": "1516210",
    "end": "1521910"
  },
  {
    "text": "into your app and start using them right away we also let you convert models so you",
    "start": "1521910",
    "end": "1526980"
  },
  {
    "text": "can take a model that you found somewhere else online or that your company's data science team has",
    "start": "1526980",
    "end": "1532560"
  },
  {
    "text": "developed or that you created personally in your own work with ml and basically",
    "start": "1532560",
    "end": "1538860"
  },
  {
    "text": "translate that into a form that works better on mobile you then have the",
    "start": "1538860",
    "end": "1543930"
  },
  {
    "text": "ability to take that file deploy its and mobile devices we have a bunch of different language bindings and support",
    "start": "1543930",
    "end": "1549660"
  },
  {
    "text": "for a bunch of different types of devices and we also have tools for optimizing models so you can actually do",
    "start": "1549660",
    "end": "1555750"
  },
  {
    "text": "stuff to them that makes them run faster and take up less space on device so the",
    "start": "1555750",
    "end": "1562230"
  },
  {
    "start": "1561000",
    "end": "1741000"
  },
  {
    "text": "workflow for doing this is pretty simple first you get a model secondly you",
    "start": "1562230",
    "end": "1567840"
  },
  {
    "text": "deploy it and run it on devices there's not much more to it than that and I'm gonna show how that works so first of",
    "start": "1567840",
    "end": "1574260"
  },
  {
    "text": "all you don't have a model you don't even know what one really is you can still get started really easily so on",
    "start": "1574260",
    "end": "1579720"
  },
  {
    "text": "our site we have this index of model types you can go in learn about each one learn",
    "start": "1579720",
    "end": "1584970"
  },
  {
    "text": "about how it might solve the problems that you're trying to solve and we have example apps for each of those so that you can actually see them in iOS and",
    "start": "1584970",
    "end": "1592710"
  },
  {
    "text": "Android apps running so that covers everything from image classification where you're figuring out where it was",
    "start": "1592710",
    "end": "1598619"
  },
  {
    "text": "in an image all the way through to text classification using birds so an example",
    "start": "1598619",
    "end": "1605220"
  },
  {
    "text": "of image segmentation here that's when you're able to cut the foreground and background over an image or you can",
    "start": "1605220",
    "end": "1611159"
  },
  {
    "text": "basically figure out which pixels in an image belong to which objects so in this",
    "start": "1611159",
    "end": "1616470"
  },
  {
    "text": "case we're figuring out some parts belong to a person so in the left hand part we're figuring out what the",
    "start": "1616470",
    "end": "1623220"
  },
  {
    "text": "background isn't blurring it so it looks like a pro photo and then the second one we're letting the user replace the",
    "start": "1623220",
    "end": "1629249"
  },
  {
    "text": "background entirely so they just look cool the second model we already saw an",
    "start": "1629249",
    "end": "1634710"
  },
  {
    "text": "example of this but this is a pose net model for figuring out where your limbs",
    "start": "1634710",
    "end": "1640019"
  },
  {
    "text": "are and so you can use that data as a developer to do those are stuff maybe you're drawing stuff onto it onto the",
    "start": "1640019",
    "end": "1646230"
  },
  {
    "text": "screen on top of people's body but you could also take this data as input to another deep learning network that you",
    "start": "1646230",
    "end": "1653609"
  },
  {
    "text": "develop that is able to figure out what gestures they're doing and like maybe what kind of dance they're doing or what",
    "start": "1653609",
    "end": "1659909"
  },
  {
    "text": "kind of moves in a fighting game or something a really cool thing that we",
    "start": "1659909",
    "end": "1666539"
  },
  {
    "text": "just launched is mobile Bert so this is a really small version of Bert which has almost as good accuracy and works on",
    "start": "1666539",
    "end": "1673830"
  },
  {
    "text": "mobile devices Bert is like a cutting edge model for doing various different classes of text understanding problems",
    "start": "1673830",
    "end": "1682169"
  },
  {
    "text": "so in this case we can put a corpus of text so you can see there's a paragraph",
    "start": "1682169",
    "end": "1687330"
  },
  {
    "text": "of text here about tensorflow and the user can ask questions about it and the model picks out parts of the text that",
    "start": "1687330",
    "end": "1694200"
  },
  {
    "text": "answer the question so you can paste in any text you want so it could be a fake use for a product it could be a story it",
    "start": "1694200",
    "end": "1703649"
  },
  {
    "text": "could be a biography and the model is able to answer questions based on it so you can just weave that into your",
    "start": "1703649",
    "end": "1710850"
  },
  {
    "text": "application for whatever thing you want to do with it so beyond the kinds of models that we're",
    "start": "1710850",
    "end": "1716620"
  },
  {
    "text": "giving away and we're actually adding more and more all the time so we have a whole team devoted to just doing that we",
    "start": "1716620",
    "end": "1724180"
  },
  {
    "text": "also support all sorts of different types of models that you can run through the tensorflow light converter and use",
    "start": "1724180",
    "end": "1730210"
  },
  {
    "text": "on your mobile device so see these are some of the ones that we've identified as the most exciting from mobile",
    "start": "1730210",
    "end": "1735820"
  },
  {
    "text": "application developers perspective but you can you can convert pretty much any kind of model so we'll talk a little bit",
    "start": "1735820",
    "end": "1743230"
  },
  {
    "start": "1741000",
    "end": "1769000"
  },
  {
    "text": "about how that works so imagine you've built a model with tensorflow if you've never used it before basically",
    "start": "1743230",
    "end": "1749410"
  },
  {
    "text": "there's some high-level api's that let you join layers of computation together",
    "start": "1749410",
    "end": "1754870"
  },
  {
    "text": "to build a machine learning model and then train it and it's actually pretty easy to use and you can get up and",
    "start": "1754870",
    "end": "1760360"
  },
  {
    "text": "running really quickly there's some really good guides online and once you've done that you can just convert",
    "start": "1760360",
    "end": "1765370"
  },
  {
    "text": "your model to run on mobile with a couple lines of Python so once you've",
    "start": "1765370",
    "end": "1770590"
  },
  {
    "start": "1769000",
    "end": "1792000"
  },
  {
    "text": "got your model ready we want to run it and running it is also super easy so in this example first of all we're loading",
    "start": "1770590",
    "end": "1778210"
  },
  {
    "text": "a model file and instantiating an interpreter with that model and we're",
    "start": "1778210",
    "end": "1784480"
  },
  {
    "text": "then processing our input to get ready to feed into the model and then we run the interpreter with that pre-processed",
    "start": "1784480",
    "end": "1790990"
  },
  {
    "text": "input so pretty simple and we also have this support library which actually can",
    "start": "1790990",
    "end": "1796480"
  },
  {
    "start": "1792000",
    "end": "1849000"
  },
  {
    "text": "provide you with high level api's and eventually auto-generated code to be",
    "start": "1796480",
    "end": "1802600"
  },
  {
    "text": "able to pre-process your data and feed it into whatever type of model that you want so you'll be able to find a model",
    "start": "1802600",
    "end": "1808900"
  },
  {
    "text": "online and run it through the support library the support library will generate some classes for you that you",
    "start": "1808900",
    "end": "1814720"
  },
  {
    "text": "can drop into your application that will do all of this kind of pre processing work for you so you really just think of",
    "start": "1814720",
    "end": "1821050"
  },
  {
    "text": "it as an API to get the results of the inference so in example here this is",
    "start": "1821050",
    "end": "1826480"
  },
  {
    "text": "what the pre-processing code kind of looks like without using the support library for transforming an image into",
    "start": "1826480",
    "end": "1833350"
  },
  {
    "text": "the form that it needs to be for the model to understand and with the support library it turns into a few lines of",
    "start": "1833350",
    "end": "1839470"
  },
  {
    "text": "code so this is pretty awesome it makes it a lot easier to use random models that you've found without having to",
    "start": "1839470",
    "end": "1845770"
  },
  {
    "text": "really deeply understand the input format that they require so we talked about the",
    "start": "1845770",
    "end": "1851799"
  },
  {
    "start": "1849000",
    "end": "1885000"
  },
  {
    "text": "converter and the interpreter and these make use of another couple of high-level things called op kernels and delegates",
    "start": "1851799",
    "end": "1859210"
  },
  {
    "text": "so we'll talk about those a little bit more later we have language bindings for",
    "start": "1859210",
    "end": "1864220"
  },
  {
    "text": "a ton of different targets so you might be working on iOS or Android or an embedded Linux we've got you covered so",
    "start": "1864220",
    "end": "1871270"
  },
  {
    "text": "we have swift objective-c C and C sharp rust go flutter and you basically either",
    "start": "1871270",
    "end": "1880659"
  },
  {
    "text": "have library supported by us or by the community for pretty much anything you can think of so I want to also talk",
    "start": "1880659",
    "end": "1888520"
  },
  {
    "start": "1885000",
    "end": "2027000"
  },
  {
    "text": "about microcontrollers but a little bit separately because this we have two interpreters there's an interpreter that",
    "start": "1888520",
    "end": "1894820"
  },
  {
    "text": "runs on mobile devices and then there's a super-efficient super handcrafted",
    "start": "1894820",
    "end": "1899950"
  },
  {
    "text": "interpreter that runs on microcontrollers because they need such efficient code so just as a recap my con",
    "start": "1899950",
    "end": "1907679"
  },
  {
    "text": "microcontrollers are these tiny computers that are on a single piece of silicon they don't have an OS they have",
    "start": "1907679",
    "end": "1914919"
  },
  {
    "text": "very little ram they have very little code space as well for storing your program so you can't put really big",
    "start": "1914919",
    "end": "1921580"
  },
  {
    "text": "models on there and you can't do loads of computationally intensive stuff quickly but they are built into",
    "start": "1921580",
    "end": "1928990"
  },
  {
    "text": "everything they've really cheap and they're actually I think three billion microcontrollers produced every year in",
    "start": "1928990",
    "end": "1936340"
  },
  {
    "text": "all sorts of types of devices and so by being able to add deep learning based",
    "start": "1936340",
    "end": "1941860"
  },
  {
    "text": "intelligence to all sorts of things like we're talking about having stuff like microwave ovens and kitchen appliances",
    "start": "1941860",
    "end": "1948940"
  },
  {
    "text": "and components inside of vehicles and even smart sensors that can just take an",
    "start": "1948940",
    "end": "1954580"
  },
  {
    "text": "arbitrary input and give you a very simple output that you can then build into other products so an example of how",
    "start": "1954580",
    "end": "1961600"
  },
  {
    "text": "you might use microcontrollers for inference is maybe you've got a product",
    "start": "1961600",
    "end": "1967299"
  },
  {
    "text": "that is figuring out what a person is saying so imagine you're building a smart home device that can understand",
    "start": "1967299",
    "end": "1974169"
  },
  {
    "text": "speech so you want it to use as little power as possible and so you I have a deep learning network running",
    "start": "1974169",
    "end": "1980980"
  },
  {
    "text": "on a microcontroller that first of all figures out if there's any sound that sounds like it's it's worth listening to",
    "start": "1980980",
    "end": "1987850"
  },
  {
    "text": "and when that sound happens the output of that model is used to wake up a",
    "start": "1987850",
    "end": "1994539"
  },
  {
    "text": "secondary model which is actually looking to figure out whether the sound is human speech or not so that's",
    "start": "1994539",
    "end": "2000749"
  },
  {
    "text": "something that would be difficult to do without deep learning but once you've figured out that yes this is human",
    "start": "2000749",
    "end": "2006809"
  },
  {
    "text": "speech we're hearing you can wake up the application processor that actually has a deeper network that does speech",
    "start": "2006809",
    "end": "2012990"
  },
  {
    "text": "recognition so by cascading models in this manner we're able to make sure",
    "start": "2012990",
    "end": "2017999"
  },
  {
    "text": "we're saving energy by not waking up the application processor for every little noise that happens so this is a really",
    "start": "2017999",
    "end": "2024929"
  },
  {
    "text": "common use case for this type of technology so as I mentioned tensorflow",
    "start": "2024929",
    "end": "2030389"
  },
  {
    "start": "2027000",
    "end": "2124000"
  },
  {
    "text": "light for microcontrollers you use the same model but there's a different interpreter and the interpreter is",
    "start": "2030389",
    "end": "2036690"
  },
  {
    "text": "optimized very heavily for these tiny devices so here's an example it's kind of amazing this is a tiny little",
    "start": "2036690",
    "end": "2043200"
  },
  {
    "text": "microcontroller using very little power the whole cost of the the actual microcontroller itself would be a couple",
    "start": "2043200",
    "end": "2050190"
  },
  {
    "text": "of dollars the camera is also very low-power and cheap and it's able to detect whether a person is in the frame",
    "start": "2050190",
    "end": "2058050"
  },
  {
    "text": "or not so the way we've got this set up there's a display but this can actually",
    "start": "2058050",
    "end": "2064710"
  },
  {
    "text": "be boiled down into a tiny device that's like the size of your fingernail which",
    "start": "2064710",
    "end": "2070349"
  },
  {
    "text": "you could put in any product and it can give you a boolean output of if there's",
    "start": "2070349",
    "end": "2076050"
  },
  {
    "text": "a person visible near the device it gives you a 1 and if there's no person visible it gives you a zero and it uses",
    "start": "2076050",
    "end": "2083550"
  },
  {
    "text": "barely any power and you don't have to know anything about machine learnings to be able to use this thing you just put",
    "start": "2083550",
    "end": "2089669"
  },
  {
    "text": "that in your hardware product so you can have a TV that shuts off when no one's watching it automatically for the cost",
    "start": "2089669",
    "end": "2095638"
  },
  {
    "text": "of a couple of extra dollars of the manufacturing cost so these kind of",
    "start": "2095639",
    "end": "2101099"
  },
  {
    "text": "smart sensors are going to absolutely transform the world around us this type of technology has only existed for a",
    "start": "2101099",
    "end": "2106800"
  },
  {
    "text": "matter of months tends to feel light for microcontrollers was announced in February of this year",
    "start": "2106800",
    "end": "2112190"
  },
  {
    "text": "so we've not even remotely started to see the kind of applications people are developing if you have any interested in",
    "start": "2112190",
    "end": "2119150"
  },
  {
    "text": "embedded development you should definitely start playing with this stuff because it's really fun and surprisingly easy so here is a another video from our",
    "start": "2119150",
    "end": "2128660"
  },
  {
    "start": "2124000",
    "end": "2256000"
  },
  {
    "text": "partners at Arduino so we're able to run ten to four light four microcontrollers",
    "start": "2128660",
    "end": "2133849"
  },
  {
    "text": "on the most recent Arduino devices and they've got some tutorials for doing all sorts of cool stuff like recognizing",
    "start": "2133849",
    "end": "2140210"
  },
  {
    "text": "gestures or recognizing objects from the sensors on device you can actually just grab the examples for Arduino from",
    "start": "2140210",
    "end": "2147470"
  },
  {
    "text": "within the Arduino IDE because we've published a library that's really easy to use so on an MCU we can do everything",
    "start": "2147470",
    "end": "2154970"
  },
  {
    "text": "from speech recognition through to interpreting camera data we can do gesture recognition using accelerometers",
    "start": "2154970",
    "end": "2161030"
  },
  {
    "text": "and we can do stuff for predictive maintenance where you're looking at like the vibration of an industrial component",
    "start": "2161030",
    "end": "2167210"
  },
  {
    "text": "to figure out when it's gonna break so that your whole factory doesn't explode so this is all stuff that is really",
    "start": "2167210",
    "end": "2174290"
  },
  {
    "text": "exciting because you can push intelligence down close to these sensors and do this type of inference really",
    "start": "2174290",
    "end": "2180109"
  },
  {
    "text": "cheaply so speech recognition we have an example for there's a 20 kilobyte model",
    "start": "2180109",
    "end": "2185990"
  },
  {
    "text": "that can discern between the words yes and no and we also have scripts you can use to retrain it for other stuff so",
    "start": "2185990",
    "end": "2192410"
  },
  {
    "text": "this is really exciting to just play with personal detection is my favorite",
    "start": "2192410",
    "end": "2198559"
  },
  {
    "text": "really because it's just so mind-blowing you have a tiny little camera the model is 250 kilobytes so it won't fit on",
    "start": "2198559",
    "end": "2205250"
  },
  {
    "text": "every embedded device but it will fit on some tiny devices and you can run scripts to retrain this easily to",
    "start": "2205250",
    "end": "2212150"
  },
  {
    "text": "recognize other objects so if you want to build a smart sensor that like maybe on your bicycle will tell you when",
    "start": "2212150",
    "end": "2218780"
  },
  {
    "text": "there's a car coming up close behind you you could do that super easy gesture",
    "start": "2218780",
    "end": "2224210"
  },
  {
    "text": "detection so we have an example where you have a device with an accelerometer and you can use it as a magic one so you",
    "start": "2224210",
    "end": "2231020"
  },
  {
    "text": "can do different gestures and cast different spells and we built a game that lets you do that but obviously",
    "start": "2231020",
    "end": "2236960"
  },
  {
    "text": "there are some practical implications for this too in things like activity trackers the model for that's also",
    "start": "2236960",
    "end": "2243119"
  },
  {
    "text": "really small 20 kilobytes and is trained with data captured from five people it probably took like an hour to capture",
    "start": "2243119",
    "end": "2249690"
  },
  {
    "text": "all the training data so it's super easy to really be able to build something",
    "start": "2249690",
    "end": "2254910"
  },
  {
    "text": "powerful so beyond microcontrollers and across all of this edge ml stuff you have to",
    "start": "2254910",
    "end": "2262290"
  },
  {
    "start": "2256000",
    "end": "2301000"
  },
  {
    "text": "think about how do you make models that perform well on tiny devices and we have",
    "start": "2262290",
    "end": "2267450"
  },
  {
    "text": "all the tooling to do that too so the big the big thing for tensile blow lysis",
    "start": "2267450",
    "end": "2272640"
  },
  {
    "text": "is performance across different types of devices we've got really good",
    "start": "2272640",
    "end": "2278520"
  },
  {
    "text": "performance across a bunch of different types of accelerators so if you were just running on CPU we're pretty quick",
    "start": "2278520",
    "end": "2284250"
  },
  {
    "text": "but if your device like most mobile phones has access to a GPU you can run",
    "start": "2284250",
    "end": "2289950"
  },
  {
    "text": "model super fast because they involve the kind of calculations that are highly parallelizable and if you have a",
    "start": "2289950",
    "end": "2295950"
  },
  {
    "text": "hardware accelerator like the edge CPU you can run inference ridiculously fast",
    "start": "2295950",
    "end": "2302030"
  },
  {
    "start": "2301000",
    "end": "2374000"
  },
  {
    "text": "they're also a bunch of techniques you can use to improve the performance of your model so the tensorflow light",
    "start": "2302030",
    "end": "2309030"
  },
  {
    "text": "converter can help with all of these and it can do things that make your model smaller and make it run better on",
    "start": "2309030",
    "end": "2314310"
  },
  {
    "text": "different types of devices so if you're on CPU you can do something called quantization which basically involves",
    "start": "2314310",
    "end": "2320760"
  },
  {
    "text": "reducing the precision of the numbers in the model while taking that into account",
    "start": "2320760",
    "end": "2326550"
  },
  {
    "text": "during inference so by default the numbers in a tensor phone knob model",
    "start": "2326550",
    "end": "2331859"
  },
  {
    "text": "have represented it's 32 bit floating points but if we reduce them down to 8-bit integers we can make the model 1/4",
    "start": "2331859",
    "end": "2339240"
  },
  {
    "text": "the size but still keep most of the same performance pruning is another really",
    "start": "2339240",
    "end": "2344700"
  },
  {
    "text": "cool technique so you're able to identify the models basically a network of neurons some of the connections",
    "start": "2344700",
    "end": "2350940"
  },
  {
    "text": "between the neurons are very important and other ones are not so important so if you figure out which ones are not",
    "start": "2350940",
    "end": "2356970"
  },
  {
    "text": "that important and cut them and just ignore them you don't have to represent that data anywhere and you don't have to",
    "start": "2356970",
    "end": "2362609"
  },
  {
    "text": "do that computation so we have the tooling that lets you do that so that the model can basically run more",
    "start": "2362609",
    "end": "2369540"
  },
  {
    "text": "effectively without more efficiently without any reduction in a key see so we have a bunch of really",
    "start": "2369540",
    "end": "2378160"
  },
  {
    "start": "2374000",
    "end": "2412000"
  },
  {
    "text": "low-level stuff that you can get into the weeds around to figure out how to do this stuff more efficiently I won't go",
    "start": "2378160",
    "end": "2384460"
  },
  {
    "text": "into a lot of detail here and but we have mechanisms for making use of the types of accelerators that are in all",
    "start": "2384460",
    "end": "2390490"
  },
  {
    "text": "sorts of devices from mobile phones through to these specialized accelerators so GPU delegation is one of",
    "start": "2390490",
    "end": "2397960"
  },
  {
    "text": "those like I mentioned you can run model on the GPU of your device you can also",
    "start": "2397960",
    "end": "2404530"
  },
  {
    "text": "make use of DSPs which is purpose-built chips that are inside of a lot of devices that allow you to do really fast",
    "start": "2404530",
    "end": "2410680"
  },
  {
    "text": "calculations on this type of stuff and we make use of androids Ani and also",
    "start": "2410680",
    "end": "2416770"
  },
  {
    "start": "2412000",
    "end": "2462000"
  },
  {
    "text": "metal on iOS so it's really easy to do this you can just add an option to your",
    "start": "2416770",
    "end": "2422410"
  },
  {
    "text": "interpreter to tell it to use acceleration so here's an example of how",
    "start": "2422410",
    "end": "2429100"
  },
  {
    "text": "you can basically optimize models for different types of uses so inception by",
    "start": "2429100",
    "end": "2438100"
  },
  {
    "text": "itself is a 95 megabyte model for image classification Google developed mobile",
    "start": "2438100",
    "end": "2444100"
  },
  {
    "text": "net which is a model that does exactly the same thing almost this almost as good accuracy but much much faster so",
    "start": "2444100",
    "end": "2451330"
  },
  {
    "text": "when you're thinking about deploying models to your device there are often mobile optimized versions of different",
    "start": "2451330",
    "end": "2457240"
  },
  {
    "text": "types of popular models so you should look for those and use them if available so we have tools for profiling how long",
    "start": "2457240",
    "end": "2465190"
  },
  {
    "start": "2462000",
    "end": "2486000"
  },
  {
    "text": "it takes to do various stuff and you can even do that down to the operator level and so ml models are built out of these",
    "start": "2465190",
    "end": "2472450"
  },
  {
    "text": "different operations and you can identify which ones are taking the longest so if you're trying to run a model on a device you can figure out",
    "start": "2472450",
    "end": "2479080"
  },
  {
    "text": "which parts of the model are not running fast and you can work with your ml engineers to optimize that so there are",
    "start": "2479080",
    "end": "2487480"
  },
  {
    "text": "also ways to use models that are not fully supported by TF lights so you can",
    "start": "2487480",
    "end": "2492910"
  },
  {
    "text": "use ops tensorflow light has I think a thousand or so or a few hundred ops",
    "start": "2492910",
    "end": "2498430"
  },
  {
    "text": "tensorflow has a thousand or so ops that you can use you can import those up some tensor for to use in your mobile applications you",
    "start": "2498430",
    "end": "2507060"
  },
  {
    "start": "2506000",
    "end": "2520000"
  },
  {
    "text": "can also that's super easy you can also selectively modify the",
    "start": "2507060",
    "end": "2512220"
  },
  {
    "text": "tensorflow light runtime so it only uses the ops that your model uses so this is just another way to get your binary size",
    "start": "2512220",
    "end": "2518850"
  },
  {
    "text": "as small as possible so that's super easy as well you can set some stuff up",
    "start": "2518850",
    "end": "2525090"
  },
  {
    "start": "2520000",
    "end": "2531000"
  },
  {
    "text": "in your code and then use stuff like the Android build tools to tell it to only grab the stuff it needs so hopefully",
    "start": "2525090",
    "end": "2532680"
  },
  {
    "start": "2531000",
    "end": "2578000"
  },
  {
    "text": "I've covered some like very high-level ml stuff I've talked a little bit about on device ml and why it's cool and why",
    "start": "2532680",
    "end": "2539370"
  },
  {
    "text": "it should exist and and how it's gonna make a big difference in the future and also give you an idea of what you will",
    "start": "2539370",
    "end": "2546750"
  },
  {
    "text": "start to think about when you start working in this stuff as an engineer but now let's point to some resources that",
    "start": "2546750",
    "end": "2553200"
  },
  {
    "text": "you can use to get started so we actually just launched a course with Udacity that covers tensorflow Lite",
    "start": "2553200",
    "end": "2559800"
  },
  {
    "text": "end-to-end so if you're interested in getting started with TF lite are definitely search for this and check it",
    "start": "2559800",
    "end": "2565920"
  },
  {
    "text": "out and we cover inference on Android iOS and raspberry pi so if one of those",
    "start": "2565920",
    "end": "2571500"
  },
  {
    "text": "platforms interests you can just ignore the other stuff and you can just pick and choose what you want to learn so if",
    "start": "2571500",
    "end": "2579090"
  },
  {
    "start": "2578000",
    "end": "2616000"
  },
  {
    "text": "you're interested in the microcontroller site I just co-authored this book with Pete worden who's the guy on our team who",
    "start": "2579090",
    "end": "2586230"
  },
  {
    "text": "pretty much helped invent this space this books going to be available in",
    "start": "2586230",
    "end": "2591450"
  },
  {
    "text": "mid-december if you're an O'Reilly subscriber you can read the early release version already so we basically",
    "start": "2591450",
    "end": "2598680"
  },
  {
    "text": "give you an introduction to how embedded ml works and how you can use the",
    "start": "2598680",
    "end": "2605760"
  },
  {
    "text": "tensorflow Lite to work with that and it's written so that if even if you're not an embedded developer or if you're",
    "start": "2605760",
    "end": "2611730"
  },
  {
    "text": "not an ml developer you can still build all the projects in the book so if",
    "start": "2611730",
    "end": "2617310"
  },
  {
    "start": "2616000",
    "end": "2651000"
  },
  {
    "text": "you're especially interested in this embedded stuff we run monthly meetups on",
    "start": "2617310",
    "end": "2622560"
  },
  {
    "text": "embedded ml so there are two right now one of them since Santa Clara and one of",
    "start": "2622560",
    "end": "2627750"
  },
  {
    "text": "them is in Austin and we're actually launching more and more all the time so",
    "start": "2627750",
    "end": "2632880"
  },
  {
    "text": "we we get like an inbound request from someone whose interest did in stuffing up a group every couple",
    "start": "2632880",
    "end": "2639030"
  },
  {
    "text": "weeks so there are going to be these all over the world and so if there isn't one in your local community now there will",
    "start": "2639030",
    "end": "2644610"
  },
  {
    "text": "be soon and it's really cool to go and meet people and see presentations from people who are doing cool stuff in this",
    "start": "2644610",
    "end": "2650160"
  },
  {
    "text": "space but the main place to go for info on tensorflow light and all the stuff we",
    "start": "2650160",
    "end": "2655440"
  },
  {
    "start": "2651000",
    "end": "2680000"
  },
  {
    "text": "talked about is our tensorflow light-dark site so we've got information on everything that i've talked about",
    "start": "2655440",
    "end": "2662010"
  },
  {
    "text": "today and we're actually going to be revamping the docks over the next month or so just so that they're even more",
    "start": "2662010",
    "end": "2668190"
  },
  {
    "text": "inclusive of all the information that you need and so I hope this has been useful and informative and I'd love to",
    "start": "2668190",
    "end": "2674760"
  },
  {
    "text": "answer any questions you might have",
    "start": "2674760",
    "end": "2677930"
  }
]
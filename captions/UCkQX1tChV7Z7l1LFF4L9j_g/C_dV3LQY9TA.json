[
  {
    "start": "0",
    "end": "130000"
  },
  {
    "text": "my name is mark stood Lee I'm the project lead for an open source java virtual machine project called eclipse",
    "start": "4050",
    "end": "10559"
  },
  {
    "text": "open j9 and I work at IBM in Canada and",
    "start": "10559",
    "end": "15780"
  },
  {
    "text": "I'm really happy to be here not just because we've had lots of great talks and lots of great speakers to listen to",
    "start": "15780",
    "end": "20970"
  },
  {
    "text": "at this conference but because I left be home behind at home 6 inches of snow on",
    "start": "20970",
    "end": "26040"
  },
  {
    "text": "my driveway and a traffic nightmare my wife who's now in charge of shuttling my",
    "start": "26040",
    "end": "33210"
  },
  {
    "text": "daughter around to school is not quite so happy about this situation and so",
    "start": "33210",
    "end": "38280"
  },
  {
    "text": "that's an example of two people applying a very different trade off to the exact same situation and coming to a different",
    "start": "38280",
    "end": "44429"
  },
  {
    "text": "conclusion about what's good and what's not so good so in this talk I'm actually",
    "start": "44429",
    "end": "51539"
  },
  {
    "text": "going to talk about that same subject I'm gonna try to teach you about the trade-offs that are involved in using different types of compilers for your",
    "start": "51539",
    "end": "59010"
  },
  {
    "text": "java applications and try to explain why the trade-offs are what they are and what you should expect when you try to do them what use",
    "start": "59010",
    "end": "65309"
  },
  {
    "text": "different ones and the subtitle is from a ot2 JIT and beyond so at the end of this talk I'm gonna be transitioning",
    "start": "65309",
    "end": "72540"
  },
  {
    "text": "into an explanation of how we're at open j9 starting to put different types of technologies together in order to",
    "start": "72540",
    "end": "78690"
  },
  {
    "text": "address all kinds of different needs and do some pretty cool stuff so I wanted to",
    "start": "78690",
    "end": "84690"
  },
  {
    "text": "start off by just saying like the Java ecosystem is this amazing place to work on compilers there's been a tremendous",
    "start": "84690",
    "end": "91890"
  },
  {
    "text": "investment over the years Orgel more than twenty years in the Java ecosystem",
    "start": "91890",
    "end": "96900"
  },
  {
    "text": "looking at JIT compilers looking at a ot compilers looking at JIT compilers that can cache their code and load it later",
    "start": "96900",
    "end": "103490"
  },
  {
    "text": "I've listed a whole bunch of different projects here not all of these are still with us but these are kind of a lot of",
    "start": "103490",
    "end": "109980"
  },
  {
    "text": "the major projects that have been looking at compilation over the years and these are only really the things that have been happening in industry and",
    "start": "109980",
    "end": "116070"
  },
  {
    "text": "sort of very popular open-source projects there's a whole ton of work that's happened in academia hundreds of",
    "start": "116070",
    "end": "121290"
  },
  {
    "text": "graduate students have gotten degrees looking at compilation in the Java ecosystem it's this amazing place but",
    "start": "121290",
    "end": "126960"
  },
  {
    "text": "it's created a lot of stuff to think about if we fast forward to today that",
    "start": "126960",
    "end": "132300"
  },
  {
    "start": "130000",
    "end": "130000"
  },
  {
    "text": "long list of things is kind of crystallized into kind of four projects there that are kind of live at them at",
    "start": "132300",
    "end": "138410"
  },
  {
    "text": "the moment so everyone's probably heard of this thing called hot spot it's it's pretty popular in the Java ecosystem it",
    "start": "138410",
    "end": "144170"
  },
  {
    "text": "has two JIT compilers in it c1 and c2 and they're they're basically the default pretty much everybody is using",
    "start": "144170",
    "end": "150110"
  },
  {
    "text": "these things I work on a project called Eclipse open j9 which is a java virtual",
    "start": "150110",
    "end": "155240"
  },
  {
    "text": "machine that was originally contributed by are built by and contributed by IBM to the Eclipse Foundation and it's now",
    "start": "155240",
    "end": "161000"
  },
  {
    "text": "available for everyone to use it has a JIT compiler in it that's very adaptive and has optimization levels that use",
    "start": "161000",
    "end": "166820"
  },
  {
    "text": "temperature as a metaphor so we have cold warm hot very hot scorching compiles which is kind of cool and",
    "start": "166820",
    "end": "174070"
  },
  {
    "text": "historically it's been invested in a OT compilation from an embedded and real-time system space so we come at the",
    "start": "174070",
    "end": "181070"
  },
  {
    "text": "the the problem of compiling for Java from a very different direction Azul has a Falcon JIT which is based on",
    "start": "181070",
    "end": "187880"
  },
  {
    "text": "the LLVM project you've probably heard of this provides an alternative high opt compiler to - C - and it also has the",
    "start": "187880",
    "end": "194840"
  },
  {
    "text": "ability to kind of stash compiles on disk and reload in subsequent runs which I should have mentioned that open j9",
    "start": "194840",
    "end": "200930"
  },
  {
    "text": "does - when I was talking about my own project and finally there's this project",
    "start": "200930",
    "end": "207320"
  },
  {
    "text": "or coracles crawl compiler which has the distinction on this list of being the only one that's actually written in Java",
    "start": "207320",
    "end": "213290"
  },
  {
    "text": "and compiles for Java which is kind of neat and since Java 9 it's been available as an experimental äôt",
    "start": "213290",
    "end": "218989"
  },
  {
    "text": "compiler and this tool called J a OTC I'll talk a little bit more about that in the next few slides and since Java 10",
    "start": "218989",
    "end": "225110"
  },
  {
    "text": "that's also been available as an experimental alternative to the C 2 JIT compiler so you can use it as a JIT",
    "start": "225110",
    "end": "230260"
  },
  {
    "text": "there's also this creating native images option that they have available using",
    "start": "230260",
    "end": "236690"
  },
  {
    "text": "their substrate vm project which takes a closed world assumption basically it says I'm not going to load anything",
    "start": "236690",
    "end": "241940"
  },
  {
    "text": "other than this set of classes and try to compile a small and native image as you possibly can that's a very",
    "start": "241940",
    "end": "249860"
  },
  {
    "text": "interesting project I'm not going to be focusing on that primarily in this talk that's almost as much as I'll say about",
    "start": "249860",
    "end": "255769"
  },
  {
    "text": "it in this talk there was another talk yesterday where you could learn a lot more about Grall and how it works so the",
    "start": "255769",
    "end": "262340"
  },
  {
    "start": "261000",
    "end": "261000"
  },
  {
    "text": "outline of my talk is I'm going to start off by just kind of comparing some of these JIT and äôt and caching kit say",
    "start": "262340",
    "end": "268340"
  },
  {
    "text": "what I mean about these things and talk about some of the trade-offs and using them and then I'm gonna talk a little bit about how we take jets to the",
    "start": "268340",
    "end": "274750"
  },
  {
    "text": "cloud and I'll wrap up so as I as I've talked about before Jets Stanford just",
    "start": "274750",
    "end": "281800"
  },
  {
    "text": "in time if you haven't heard the term before basically this JIT compiler is active at the same time that your program is",
    "start": "281800",
    "end": "288040"
  },
  {
    "text": "running and so it can adapt to all of the all the things that are happening in the program as it runs it can collect",
    "start": "288040",
    "end": "294160"
  },
  {
    "text": "profile data it can watch classes getting loaded unloaded etc it can adapt even to the platform that you're running",
    "start": "294160",
    "end": "300430"
  },
  {
    "text": "on so you ship around a set of class files you can run those on x86 you can run those on arm you can run those on any",
    "start": "300430",
    "end": "307540"
  },
  {
    "text": "kind of platform and it doesn't matter because the JIT compiler which is the thing that's going to convert it to",
    "start": "307540",
    "end": "312580"
  },
  {
    "text": "native code runs at the same time the program runs so you can defer the decision about what how you compiled",
    "start": "312580",
    "end": "317590"
  },
  {
    "text": "code with it yet after more than two decades of sustained effort jits are",
    "start": "317590",
    "end": "323140"
  },
  {
    "text": "really the leader in java application performance right we've proven this time and time again as despite multiple",
    "start": "323140",
    "end": "328930"
  },
  {
    "text": "significant parallel efforts aimed at äôt performance the Java because of its dynamic language nature just lends",
    "start": "328930",
    "end": "336940"
  },
  {
    "text": "itself very well to JIT compilation why is that well there are a couple reasons which if you squint at them they're",
    "start": "336940",
    "end": "343570"
  },
  {
    "text": "actually really the same reason but the first one is the Jets Jets aggressively speculate on class hierarchy so in the",
    "start": "343570",
    "end": "351280"
  },
  {
    "text": "Java ecosystem or the java language calls our virtual by specification that means they can be overridden by other",
    "start": "351280",
    "end": "357040"
  },
  {
    "text": "classes and so when you're making a call to one of these functions you don't really know what the target is it could",
    "start": "357040",
    "end": "363700"
  },
  {
    "text": "be anything it could be a class that hasn't even been loaded yet and but many of these calls as we know because we've",
    "start": "363700",
    "end": "370750"
  },
  {
    "text": "studied many many many many many many many java applications over many years many calls really only do have a single",
    "start": "370750",
    "end": "376810"
  },
  {
    "text": "target at runtime and so the JIT can see that because it's watching the program run it knows which calls have only a",
    "start": "376810",
    "end": "383440"
  },
  {
    "text": "single target and it can optimize for that they can speculate that this one target that it seen is only going to be",
    "start": "383440",
    "end": "389169"
  },
  {
    "text": "this is only going to be the target and so it can aggressively optimize that it can inline the target of the call into",
    "start": "389169",
    "end": "394210"
  },
  {
    "text": "the code around it and then it can optimize that code and make it much faster alright inlining is one of the",
    "start": "394210",
    "end": "401349"
  },
  {
    "text": "great enablers in compilers right it allows you to see more scope of more operations combined things with the",
    "start": "401349",
    "end": "407770"
  },
  {
    "text": "context out of call with the code that's inside the call and so on and that expands greatly by being able to inline",
    "start": "407770",
    "end": "413980"
  },
  {
    "text": "you can expand the scope of optimization you can generate really great code but because of this dynamic nature of Java",
    "start": "413980",
    "end": "421780"
  },
  {
    "text": "if you compile too early you can actually fool the compiler into speculating on something that's not",
    "start": "421780",
    "end": "427000"
  },
  {
    "text": "really only that doesn't only have one target and so you'll end up generating code that's right for a while but then",
    "start": "427000",
    "end": "433720"
  },
  {
    "text": "in the real world you have multiple targets and it's not right and so the JIT has to generate backup paths that it",
    "start": "433720",
    "end": "439840"
  },
  {
    "text": "can deal so I can deal with that situation when it happens and that ends up having not great code not great",
    "start": "439840",
    "end": "445600"
  },
  {
    "text": "performance until you've recompiled it just also use profile data as the",
    "start": "445600",
    "end": "451090"
  },
  {
    "start": "448000",
    "end": "448000"
  },
  {
    "text": "program is running so it might not surprise you to learn that not all code",
    "start": "451090",
    "end": "456130"
  },
  {
    "text": "paths in your application execute equally frequently some code paths execute a lot more frequently than",
    "start": "456130",
    "end": "462160"
  },
  {
    "text": "others and so the profile data that the compiler can collect while the program is running tells it which paths to focus",
    "start": "462160",
    "end": "468640"
  },
  {
    "text": "on the simplest example here is that you don't have to compile every method in the program if it if a method never gets",
    "start": "468640",
    "end": "474640"
  },
  {
    "text": "called and only rarely executes in a particular run of your application there's no reason to compile it spend",
    "start": "474640",
    "end": "480310"
  },
  {
    "text": "the time compiling it if it's only gonna run a few times you can run that in the interpreter and you can afford to do",
    "start": "480310",
    "end": "485620"
  },
  {
    "text": "that because it's not gonna run for very much it's not gonna consume very much of your profile but something that's running and being called all the time",
    "start": "485620",
    "end": "491740"
  },
  {
    "text": "you want to compile that because you get a big benefit from compiling it to native code not all calls have a single",
    "start": "491740",
    "end": "499240"
  },
  {
    "text": "possible target there are mega morphic calls they do exist but profile data can",
    "start": "499240",
    "end": "504310"
  },
  {
    "text": "help you prioritize which one of those targets you might inline and then optimize the code around with it so profile data can",
    "start": "504310",
    "end": "511810"
  },
  {
    "text": "help you do inlining even for those calls that that aren't monomorphic and",
    "start": "511810",
    "end": "516930"
  },
  {
    "text": "the third point is kind of it's it's a it's a very efficient substitute in the JIT to profile data again you can",
    "start": "516930",
    "end": "523180"
  },
  {
    "text": "actually identify a constants via profiling not by having to do extreme",
    "start": "523180",
    "end": "528510"
  },
  {
    "text": "analyses of lots of code you can imagine if somebody creates a constant and then passes it through a long call chain for",
    "start": "528510",
    "end": "535630"
  },
  {
    "text": "a compiler to realize that that's a con it has to see that entire chain of calls has to look at all of that code and make",
    "start": "535630",
    "end": "541300"
  },
  {
    "text": "sure that the constants really propagating all the way down to the uses but if I'm profiling the use and I see",
    "start": "541300",
    "end": "547210"
  },
  {
    "text": "that only one value ever gets there I can be pretty sure that it's likely to be a constant I might not be a hundred",
    "start": "547210",
    "end": "552490"
  },
  {
    "text": "percent sure but I can still generate better code assuming that it is a constant and so JIT compilers work",
    "start": "552490",
    "end": "558970"
  },
  {
    "text": "really really very well if the profile data is high-quality we've spent two decades making sure that that's true and",
    "start": "558970",
    "end": "564400"
  },
  {
    "text": "that's that's why Jets get such great performance but this advantage doesn't come for free obviously collecting",
    "start": "564400",
    "end": "571660"
  },
  {
    "text": "profile data is an overhead for one right you just you have to spend time to do it and that cost is usually paid",
    "start": "571660",
    "end": "578440"
  },
  {
    "text": "while the codes being interpreted which means that's gonna slow down your startup and ramp up right which is",
    "start": "578440",
    "end": "584530"
  },
  {
    "text": "something that people don't always like and if you need high quality data that",
    "start": "584530",
    "end": "591190"
  },
  {
    "text": "means that you have to profile for awhile before you actually pull the trigger to decide to compile something you have to wait until you've collected",
    "start": "591190",
    "end": "597520"
  },
  {
    "text": "enough profile data to do a really good job compiling in which also slows down",
    "start": "597520",
    "end": "602530"
  },
  {
    "text": "rip up and startup so a second part of",
    "start": "602530",
    "end": "608170"
  },
  {
    "text": "this performance advantage that it's not free is that they're resource resources being consumed by the JIT compiler itself CPU cycles in memory right it",
    "start": "608170",
    "end": "615550"
  },
  {
    "text": "takes you know milliseconds to seconds to do a JIT compilation for one method and it's going to consume potentially",
    "start": "615550",
    "end": "623260"
  },
  {
    "text": "hundreds of megabytes of memory transiently you're not going to see it for very long because it compels tend to be short but it's there it's measurable",
    "start": "623260",
    "end": "630270"
  },
  {
    "text": "and that cost is paid while you're compiling and mostly you're compiling",
    "start": "630270",
    "end": "635440"
  },
  {
    "text": "during startup and during ramp up so all of these overheads are kind of coming to",
    "start": "635440",
    "end": "641860"
  },
  {
    "text": "roost in exactly the place where people have problems will start up in footprint our startup and ramp up which is where",
    "start": "641860",
    "end": "647410"
  },
  {
    "text": "you really want to get compiled code performance factor or they're interfering with the ability to get",
    "start": "647410",
    "end": "653560"
  },
  {
    "text": "compiled code performance faster there's also some persistent resource allocation you know you have to store profile data",
    "start": "653560",
    "end": "659590"
  },
  {
    "text": "somewhere I have to store metadata about classes somewhere but for the most part it's the transient stuff that really",
    "start": "659590",
    "end": "664690"
  },
  {
    "text": "gets in the way all right so if I were to kind of collect that together in a kind of a scorecard",
    "start": "664690",
    "end": "671399"
  },
  {
    "start": "666000",
    "end": "666000"
  },
  {
    "text": "and and I'll assign a score for you know steady-state code performance it's",
    "start": "671399",
    "end": "676949"
  },
  {
    "text": "really great Forge it so that's green for it can adapt to changes at runtime that's great",
    "start": "676949",
    "end": "682049"
  },
  {
    "text": "it's really easy to use does anybody know the command-line option to disable the JIT no hands alright that's easy to",
    "start": "682049",
    "end": "692609"
  },
  {
    "text": "use right nobody even cares how to get rid of it you have platform neutral deployment so",
    "start": "692609",
    "end": "699919"
  },
  {
    "text": "you can because you're compiling when the programs running not when you're actually building however as we've",
    "start": "699919",
    "end": "706470"
  },
  {
    "text": "noticed there's some issues with startup performance and with ramp up performance I haven't defined those yet sorry startup performance I call the time",
    "start": "706470",
    "end": "713879"
  },
  {
    "text": "until an application is ready to handle load right so you spend a lot of time initializing data structures getting stuff ready and eventually you're kind",
    "start": "713879",
    "end": "721109"
  },
  {
    "text": "of ready to start accepting load or start solving the problem that you're trying to solve ramp up is the time",
    "start": "721109",
    "end": "726899"
  },
  {
    "text": "after that until you hit your steady-state performance so you may not be able to immediately do things as fast",
    "start": "726899",
    "end": "732600"
  },
  {
    "text": "as you'd like to but eventually you'll get there and that's when you'll hit steady-state and we also mentioned that",
    "start": "732600",
    "end": "738209"
  },
  {
    "text": "they'll there's these runtime impacts the CPU in memory so we'll give a read score for those things and so I don't",
    "start": "738209",
    "end": "745589"
  },
  {
    "text": "know how many people have come to talk to me about these things when they point they realize these things and I say hey can't a OT help with these read things",
    "start": "745589",
    "end": "753419"
  },
  {
    "text": "here we really don't like these read things we want to startup fast we want to ramp up fast and we don't want to pay",
    "start": "753419",
    "end": "759059"
  },
  {
    "text": "all this extra stuff so let's talk about ahead of time compiled compilers so the",
    "start": "759059",
    "end": "765899"
  },
  {
    "text": "the basic idea here which you probably are already already know is you introduce an extra step here at your",
    "start": "765899",
    "end": "771329"
  },
  {
    "text": "build time to generate native code before you deploy the application to wherever it's going to be run in the",
    "start": "771329",
    "end": "777539"
  },
  {
    "text": "open JDK ecosystem there's this tool called J a OTC which is used to convert a set of class files to a platform",
    "start": "777539",
    "end": "783449"
  },
  {
    "text": "specific shared object it's very akin to the approach that's taken with less dynamic languages like C",
    "start": "783449",
    "end": "789660"
  },
  {
    "text": "or C++ a rust or go or swift etc it's currently still in the experimental it",
    "start": "789660",
    "end": "796139"
  },
  {
    "text": "has the experimental tag associated with it since JDK 9 and right now it's x86 64 platforms only as far as I know there",
    "start": "796139",
    "end": "803100"
  },
  {
    "text": "are a couple of deployment options so these are things you have to decide at Build time before you deploy your app and that's whether",
    "start": "803100",
    "end": "808410"
  },
  {
    "text": "or not you want a JIT to be able to top up your performance on top of what the äôt code is able to give you so you can",
    "start": "808410",
    "end": "815070"
  },
  {
    "text": "have no JIT at runtime which means you get you know statically compiled code and nothing else anything else runs in",
    "start": "815070",
    "end": "820890"
  },
  {
    "text": "the interpreter absolutely or you can run it with the JIT at runtime in which",
    "start": "820890",
    "end": "827310"
  },
  {
    "text": "case there's mechanisms in place built into the code so that it can trigger JIT compilations using c1 or c2 in order to",
    "start": "827310",
    "end": "835530"
  },
  {
    "text": "upgrade the performance and get closer to what the JIT is capable of doing so you get faster performance plus you get",
    "start": "835530",
    "end": "841590"
  },
  {
    "text": "the ability to get higher runtime performance now äôt has some runtime advantages over",
    "start": "841590",
    "end": "847410"
  },
  {
    "text": "over at JIT compiler you get that compiled code performance immediately there's no try to figure out you'll",
    "start": "847410",
    "end": "854220"
  },
  {
    "text": "watch the program wait to figure out what methods they're running a lot put them in a queue wait till they get to",
    "start": "854220",
    "end": "859620"
  },
  {
    "text": "the head of the queue run a compiler to compile it generate native code inject it into the running system and wait for",
    "start": "859620",
    "end": "865140"
  },
  {
    "text": "the next time for it to get invoked skip all of that stuff right you loaded in your process boom you've got native code",
    "start": "865140",
    "end": "870750"
  },
  {
    "text": "it runs everything's great startup performance here can typically be 20 to 50 percent better especially if you're",
    "start": "870750",
    "end": "877290"
  },
  {
    "text": "combining it with technologies like Apps EDS and it's gonna reduce the CPU and memory impact of the JIT compiler",
    "start": "877290",
    "end": "883560"
  },
  {
    "text": "particular if you use that first deployment option where there is no JIT",
    "start": "883560",
    "end": "889250"
  },
  {
    "text": "but there's there's quite a few big butts actually you're no longer platform",
    "start": "889250",
    "end": "896730"
  },
  {
    "start": "890000",
    "end": "890000"
  },
  {
    "text": "neutral you have to decide which platform you're gonna target when you're building it and that means you because",
    "start": "896730",
    "end": "904380"
  },
  {
    "text": "you need different äôt code for different platforms right and particularly you need to package it differently right the way you package a shared object or or code on Linux Mac",
    "start": "904380",
    "end": "911790"
  },
  {
    "text": "and Windows they're different even if you're just talking about x86 if you brought other platforms into the mix it would be an even stranger mix of things",
    "start": "911790",
    "end": "918450"
  },
  {
    "text": "that you'd have to decide up front ahead of time and you have to pick which processor you're gonna generate code for",
    "start": "918450",
    "end": "923940"
  },
  {
    "text": "- you can't necessarily say target the latest and greatest skylake processor if your code might run on something that's",
    "start": "923940",
    "end": "930870"
  },
  {
    "text": "not a skylake you know at worst that might you might have some performance",
    "start": "930870",
    "end": "935970"
  },
  {
    "text": "impact to that but if you choose to use and actions that are only available on that CPU then your host if you try to run it",
    "start": "935970",
    "end": "942060"
  },
  {
    "text": "somewhere else you're gonna abort cause all kinds of unhappiness and there are a",
    "start": "942060",
    "end": "947370"
  },
  {
    "text": "few other usability kinds of issues too some of which are getting better as the ecosystem with forward but you know",
    "start": "947370",
    "end": "953370"
  },
  {
    "text": "basically there's there's deployment options you have to decide on build time and you're kind of locked in to them because those options to change how you",
    "start": "953370",
    "end": "961080"
  },
  {
    "text": "generate code so different GC policies require different kinds of rate barriers and sometimes read barriers and so you",
    "start": "961080",
    "end": "968550"
  },
  {
    "text": "can't just arbitrarily say okay I want to use g1 now or I just want to use Z",
    "start": "968550",
    "end": "974459"
  },
  {
    "text": "one said one sorry I'm Canadian I should really do better at that Canadian here",
    "start": "974459",
    "end": "982290"
  },
  {
    "text": "are they though as I mentioned the",
    "start": "982290",
    "end": "989459"
  },
  {
    "text": "ability if you want to be able to reach it or not you have to decide that on different platforms you're generating",
    "start": "989459",
    "end": "994920"
  },
  {
    "text": "even different sets of classes and methods so one of the other things that you have to do when you're generating you know Tico is you have to tell it",
    "start": "994920",
    "end": "1000410"
  },
  {
    "text": "which classes and methods you want it to compile and so on different platforms",
    "start": "1000410",
    "end": "1005779"
  },
  {
    "text": "that might be a different list because there are classes that only get loaded on Mac when you're running on Mac and",
    "start": "1005779",
    "end": "1011600"
  },
  {
    "text": "some that only get loaded on Linux when you're running on Linux stain that repeatedly but anyway you get the point",
    "start": "1011600",
    "end": "1017950"
  },
  {
    "text": "and now those lists are things that you have to curate and maintain it's all",
    "start": "1017950",
    "end": "1022970"
  },
  {
    "text": "well and good to write a you know do one study and try a OT and it works great fantastic but my application is a",
    "start": "1022970",
    "end": "1030170"
  },
  {
    "text": "changing thing if I have a lot of applications then I have a lot of things that continue to change and so those",
    "start": "1030170",
    "end": "1036050"
  },
  {
    "text": "lists of classes and methods are things that have to be curated you have to maintain them you have to keep track of",
    "start": "1036050",
    "end": "1041780"
  },
  {
    "text": "them as your applications evolving new code paths are being created new cloud pads are being activated you have to",
    "start": "1041780",
    "end": "1047300"
  },
  {
    "text": "remember to add those to the list and keep them there and if there are things that are no longer used you probably",
    "start": "1047300",
    "end": "1052550"
  },
  {
    "text": "want to take those out of the list because they're not worth while being there anymore and then of course there's",
    "start": "1052550",
    "end": "1057860"
  },
  {
    "text": "always the question about what classes what about classes that aren't there until the run starts you can't you know T compile it if you don't have it so so",
    "start": "1057860",
    "end": "1066110"
  },
  {
    "text": "there are some things that are kind of troublesome from a usability standpoint with a ot code and you know let's look back at all",
    "start": "1066110",
    "end": "1072380"
  },
  {
    "text": "those those two reasons that we had for JIT compilers to deliver excellent performance speculating on class",
    "start": "1072380",
    "end": "1077630"
  },
  {
    "text": "hierarchy and profile data and I don't have any of those I can't do those because I don't know what classes have",
    "start": "1077630",
    "end": "1083630"
  },
  {
    "text": "been loaded because it's not yet so äôt compilers in their very pure form have",
    "start": "1083630",
    "end": "1089990"
  },
  {
    "text": "to like they're not being combined with chits have to really reason about things that are happening at runtime because they're not at runtime so let's take a",
    "start": "1089990",
    "end": "1096980"
  },
  {
    "text": "bit of a sidetrack into side bar into that discussion and let's look at the",
    "start": "1096980",
    "end": "1102350"
  },
  {
    "start": "1097000",
    "end": "1097000"
  },
  {
    "text": "lifetime of some generic hopefully matches at least somebody's job application in the room so things start",
    "start": "1102350",
    "end": "1109610"
  },
  {
    "text": "off you're on Java and you have that big bang that Java process has been created poof that didn't exist before and now it",
    "start": "1109610",
    "end": "1116480"
  },
  {
    "text": "exists you have a process a little while after that the JVM gets loaded and initialized and and you're a book to",
    "start": "1116480",
    "end": "1122840"
  },
  {
    "text": "load the first class and about to run main about by the time you get to the",
    "start": "1122840",
    "end": "1128990"
  },
  {
    "text": "point where you can actually run me about 750 classes have been loaded and",
    "start": "1128990",
    "end": "1134140"
  },
  {
    "text": "there's a hat a handful of class loader objects that are alive and and and they're responsible for doing the",
    "start": "1134140",
    "end": "1140360"
  },
  {
    "text": "remaining class loading that's going on and now in this diagram I'm starting to show a bit of an envelope there's these",
    "start": "1140360",
    "end": "1146330"
  },
  {
    "text": "two blue lines here which hopefully you can see my pointer down here which you",
    "start": "1146330",
    "end": "1152390"
  },
  {
    "text": "know the more apart they are the more classes there are and the more complex that those are relationships between those classes or excuse me",
    "start": "1152390",
    "end": "1160030"
  },
  {
    "text": "so during this application class loading",
    "start": "1160030",
    "end": "1165560"
  },
  {
    "text": "and initialization phase up to hundreds of active class loaders can be loaded and tens of thousands of classes can be",
    "start": "1165560",
    "end": "1173500"
  },
  {
    "text": "implemented loaded so the if you're running a big Jakarta EE app say you can",
    "start": "1173500",
    "end": "1180740"
  },
  {
    "text": "have lots and lots and lots of stuff flying around all at the same time so you can get very large numbers of",
    "start": "1180740",
    "end": "1187850"
  },
  {
    "text": "classes and a very complex class hierarchy that you have to be looking at and finally your application gets to the",
    "start": "1187850",
    "end": "1194960"
  },
  {
    "text": "point where it's ready to do work right this is the end of the phase I called startup right you're now starting to",
    "start": "1194960",
    "end": "1200510"
  },
  {
    "text": "exercise the actual code paths that are going to be commonly used at runtime and you'll probably end up loading a lot",
    "start": "1200510",
    "end": "1207040"
  },
  {
    "text": "more class a lot more classes now which if you did too much compilation during startup you're gonna start invalidating",
    "start": "1207040",
    "end": "1212530"
  },
  {
    "text": "some of the assumptions that you were making at that point but eventually your code path stabilized and your profile",
    "start": "1212530",
    "end": "1218290"
  },
  {
    "text": "stabilizes and everything gets everything's fantastic right and ramp up ends and you're you're in the world of",
    "start": "1218290",
    "end": "1225340"
  },
  {
    "text": "normality now real applications will go through phases and they'll go idle and they'll do all sorts of other complicated nasty things I'm not trying",
    "start": "1225340",
    "end": "1232660"
  },
  {
    "text": "to show that with this diagram that now that the JIT compiler getting back to",
    "start": "1232660",
    "end": "1238600"
  },
  {
    "text": "the topic of compilers the JIT compiler is basically inside this process the whole time and at any point in time it",
    "start": "1238600",
    "end": "1245290"
  },
  {
    "text": "knows exactly which classes have been loaded where they've been loaded how they relate to all the other classes in the system regardless of which class",
    "start": "1245290",
    "end": "1252100"
  },
  {
    "text": "loader loaded them etc it can see all of that complexity it's right in front of it but the äôt compiler has to view it",
    "start": "1252100",
    "end": "1259900"
  },
  {
    "text": "all through the Big Bang of the Java process being created it's outside of",
    "start": "1259900",
    "end": "1265180"
  },
  {
    "text": "this whole process and what that means is that äôt really has to predict all of",
    "start": "1265180",
    "end": "1271960"
  },
  {
    "text": "that all of that complexity that I just described those hundreds of class loaders potentially and tens of",
    "start": "1271960",
    "end": "1277690"
  },
  {
    "text": "thousands of classes how are those things all going to relate it has to predict all of that and that's really",
    "start": "1277690",
    "end": "1282820"
  },
  {
    "text": "hard all right so what great story let's",
    "start": "1282820",
    "end": "1288430"
  },
  {
    "text": "go through an example so imagine two very simple classes here B and C where C",
    "start": "1288430",
    "end": "1294550"
  },
  {
    "text": "dot foo calls B dot bar right this looks like a very simple opportunity to inline",
    "start": "1294550",
    "end": "1299890"
  },
  {
    "text": "the car call to beat up all right bar just returns five so I can take five and just replace the call to be a bar with",
    "start": "1299890",
    "end": "1305830"
  },
  {
    "text": "five and optimize it with the code around it right cool that would be great",
    "start": "1305830",
    "end": "1312220"
  },
  {
    "text": "but how did that actually happen how did how did this connection between C and B get formed well classes C and B got",
    "start": "1312220",
    "end": "1319090"
  },
  {
    "text": "loaded by a class loader let's call it CL 1 and when foo is running it needs to",
    "start": "1319090",
    "end": "1325780"
  },
  {
    "text": "figure out which B it is that I'm really talking about if you look at the class file format for C B is a string it's not",
    "start": "1325780",
    "end": "1334420"
  },
  {
    "text": "a class it's not an identity it's not which water be superclass's it's not anything but it's a string and if the class",
    "start": "1334420",
    "end": "1342480"
  },
  {
    "text": "loaders responsibility to take that string and say ah that's this class over here class B that's this guy and so if",
    "start": "1342480",
    "end": "1350970"
  },
  {
    "text": "you're compiling sifu and you've resolved the constant pool entry for B it will point to this class B and then",
    "start": "1350970",
    "end": "1356850"
  },
  {
    "text": "you'll be able to hook up bar and find out that it returns five and do this magical optimization that we all really really really hope happens these class",
    "start": "1356850",
    "end": "1365790"
  },
  {
    "text": "loader objects they don't really exist anywhere but in the Java heap they're",
    "start": "1365790",
    "end": "1370950"
  },
  {
    "text": "just objects there's no concept of a class loader really outside of the JVM",
    "start": "1370950",
    "end": "1378960"
  },
  {
    "text": "process and so in particular you can have other class loader objects which can equally load Class C and look up",
    "start": "1378960",
    "end": "1386370"
  },
  {
    "start": "1381000",
    "end": "1381000"
  },
  {
    "text": "some different class be from that string that's sitting in B's and C's class constant pool and that might look up",
    "start": "1386370",
    "end": "1393390"
  },
  {
    "text": "some other B that returns minus five and in that case well we probably better not",
    "start": "1393390",
    "end": "1398760"
  },
  {
    "text": "in line five we'd better do the right thing which is just call B dot bar right",
    "start": "1398760",
    "end": "1405210"
  },
  {
    "text": "and in fact you might not even know what B is until you run C dot foo right that",
    "start": "1405210",
    "end": "1411150"
  },
  {
    "text": "line of code there B B equals get a B that might be the first time of B object",
    "start": "1411150",
    "end": "1417000"
  },
  {
    "text": "got allocated in the whole program so how's äôt supposed to figure all of",
    "start": "1417000",
    "end": "1422880"
  },
  {
    "text": "this stuff out without actually constructing any of this it's hard and so a OT probably has to hedge in this",
    "start": "1422880",
    "end": "1432180"
  },
  {
    "text": "case because maybe only class load or one exists or maybe only class load or two exists or maybe both of them right",
    "start": "1432180",
    "end": "1437970"
  },
  {
    "text": "it doesn't know what the scenario is and so it probably has to hedge now you might be saying that seems like a pretty",
    "start": "1437970",
    "end": "1444180"
  },
  {
    "start": "1442000",
    "end": "1442000"
  },
  {
    "text": "contrived example I don't know that it's actually modeled on how OSGi modules are",
    "start": "1444180",
    "end": "1449280"
  },
  {
    "text": "modules work right enabling two different versions of the same library to be loaded at the same time which you",
    "start": "1449280",
    "end": "1455700"
  },
  {
    "text": "know we have a great name to our file hell for that we don't like it nobody likes it but it is a reality and there's",
    "start": "1455700",
    "end": "1461580"
  },
  {
    "text": "nothing in the Java specification that says it can't happen so you have to ask yourself what prevents this scenario if",
    "start": "1461580",
    "end": "1467730"
  },
  {
    "text": "classes can be loaded dynamically even created on the fly you just No and that because a OT has to",
    "start": "1467730",
    "end": "1474240"
  },
  {
    "text": "completely understand what's going on it means it's probably going to have to hedge at these kinds of inlining opportunities it makes it really hard",
    "start": "1474240",
    "end": "1480450"
  },
  {
    "text": "for a OT to in line and in lining like I said is a great enabler for performance",
    "start": "1480450",
    "end": "1485730"
  },
  {
    "text": "now the jet it's acting at runtime it can look at exactly what's happening it's only class load or one great all in",
    "start": "1485730",
    "end": "1492090"
  },
  {
    "text": "line five it's only class load or two great all in line - five you got both of them fantastic I've got to seize and",
    "start": "1492090",
    "end": "1498240"
  },
  {
    "text": "into each see of each of those seedot foods I'll compile them independently and put 5 and 1 and minus 5 in the other",
    "start": "1498240",
    "end": "1503460"
  },
  {
    "text": "that JIT really has the advantage here and so these hedges that the OT compiler",
    "start": "1503460",
    "end": "1509520"
  },
  {
    "text": "has to do really increase a gap the potential gap between the a ot and JIT performance levels and here we're",
    "start": "1509520",
    "end": "1515790"
  },
  {
    "text": "talking about steady-state performance levels now you might be thinking quick a profile directed feedback sometimes it's",
    "start": "1515790",
    "end": "1522300"
  },
  {
    "start": "1518000",
    "end": "1518000"
  },
  {
    "text": "called profile guided optimization PG oh maybe that'll help well yes maybe but",
    "start": "1522300",
    "end": "1529410"
  },
  {
    "text": "but a ot code has to run all possible user executions right the JIT gets the",
    "start": "1529410",
    "end": "1535020"
  },
  {
    "text": "advantage of knowing the profile data in this run and if you do a different run where it does something completely different it will still get that profile",
    "start": "1535020",
    "end": "1542070"
  },
  {
    "text": "data for that run and it will be able to optimize for it but with äôt you have to handle everything right because you've",
    "start": "1542070",
    "end": "1547860"
  },
  {
    "text": "only built it once you can't you don't have the option to rebuild it for each runtime each each runtime instance and",
    "start": "1547860",
    "end": "1557270"
  },
  {
    "text": "what that means is that it's really important to use representative input data that crosses all of the possible",
    "start": "1557270",
    "end": "1564210"
  },
  {
    "text": "user data that you might have when you're dealing with a OT and the risk is that it can be very misleading if you",
    "start": "1564210",
    "end": "1570870"
  },
  {
    "text": "use only a few input sets which you know a ot compiler is going to specialize just like the JIT would if it only had",
    "start": "1570870",
    "end": "1577410"
  },
  {
    "text": "that profile data it's going to specialize for the for the input sets that you give it and if you give it",
    "start": "1577410",
    "end": "1582630"
  },
  {
    "text": "something else then you're gonna have lower performance that that profile",
    "start": "1582630",
    "end": "1587850"
  },
  {
    "text": "directed feedback approach can really lead the compiler astray if it's not representative enough and you know you",
    "start": "1587850",
    "end": "1593850"
  },
  {
    "text": "know we talked about monotonic calls where the call only has one target and",
    "start": "1593850",
    "end": "1598860"
  },
  {
    "text": "that we've done lots of studies saying that calls are generally monotonic well those studies were done",
    "start": "1598860",
    "end": "1604630"
  },
  {
    "text": "20 years ago a lot of them on a bench mark called spec 98 which was really",
    "start": "1604630",
    "end": "1611170"
  },
  {
    "text": "just a bunch of C programs that got converted to Java you know it's it's been borne out by lots of applications",
    "start": "1611170",
    "end": "1616900"
  },
  {
    "text": "when you look at it inside the run but when you look at it across all the possible input datasets I'm not sure I'm",
    "start": "1616900",
    "end": "1624040"
  },
  {
    "text": "this confident that it's always going to be monotonic across all user instances",
    "start": "1624040",
    "end": "1629520"
  },
  {
    "text": "that also means we have to be very careful with benchmark results when we're looking at a OT because benchmarks",
    "start": "1629520",
    "end": "1635800"
  },
  {
    "text": "might not use a lot of different inputs it data sets right so they might not you know they might not properly reflect",
    "start": "1635800",
    "end": "1643270"
  },
  {
    "text": "what you would really get using a OT and so cross-training here is really you know critically important it's very important in machine learning it's very",
    "start": "1643270",
    "end": "1649840"
  },
  {
    "text": "important for IOT compiling right you want to train you want to use PDF with one data set and try to measure it on",
    "start": "1649840",
    "end": "1655810"
  },
  {
    "text": "other data sets to see just how good it's doing and these input data sets are just like those lists of classes and",
    "start": "1655810",
    "end": "1662110"
  },
  {
    "text": "methods that I talked about before if they need to be curated you need to maintain them as your application evolves and as your users involve",
    "start": "1662110",
    "end": "1669700"
  },
  {
    "text": "because they're because the input data might change right and all of that's really on the application provider right",
    "start": "1669700",
    "end": "1676060"
  },
  {
    "text": "it's on the person who's going to do the IOT compile and then distribute it to all of the different people who might",
    "start": "1676060",
    "end": "1681970"
  },
  {
    "text": "use that at a OT code and I'll make one observation that PDF has not really been",
    "start": "1681970",
    "end": "1688240"
  },
  {
    "text": "a huge success for static languages there are cases where it's been used and to great advantage but as a general rule",
    "start": "1688240",
    "end": "1694300"
  },
  {
    "text": "not everybody is using PDF for static for statically compiled languages for a",
    "start": "1694300",
    "end": "1699310"
  },
  {
    "text": "lot of these same reasons and so you might think I'm pretty down on the OT here and as a pure technology I kind of am so",
    "start": "1699310",
    "end": "1707470"
  },
  {
    "text": "you know I'll be I'll be clear about that right if I put them back up on my my scorecard it's true that I turned all",
    "start": "1707470",
    "end": "1715240"
  },
  {
    "text": "my red boxes green by using a OT but at the same time I changed all my green",
    "start": "1715240",
    "end": "1720400"
  },
  {
    "text": "boxes red so that really didn't help me very much I would call that kind of one",
    "start": "1720400",
    "end": "1726460"
  },
  {
    "text": "step forward and one step back but you know if I if I were to combine a ot and",
    "start": "1726460",
    "end": "1732760"
  },
  {
    "text": " like use a ot to generate an initial set of code and then recompile things with the JIT in order to",
    "start": "1732760",
    "end": "1738190"
  },
  {
    "text": "better performance I can start to do a better job here all right so I still",
    "start": "1738190",
    "end": "1743529"
  },
  {
    "text": "have a JIT I mean it so I I I have a JIT running so I can get good steady-state performance eventually I have a JIT running so I can",
    "start": "1743529",
    "end": "1751330"
  },
  {
    "text": "adapt to runtime changes and what's going on so I get a green box there a ot",
    "start": "1751330",
    "end": "1756940"
  },
  {
    "text": "has all of the issues with curating lists of methods and classes and profile data that I mentioned so I took off",
    "start": "1756940",
    "end": "1762519"
  },
  {
    "text": "ease-of-use for that one it's not platform neutral because I have to generate this a ot code and decide which",
    "start": "1762519",
    "end": "1768399"
  },
  {
    "text": "platform precisely that I'm going to or excuse me what class of platforms I'm going to target but I get good start up",
    "start": "1768399",
    "end": "1775690"
  },
  {
    "text": "and I get pretty good ramp up because ramp up you really need the JIT take you all the way and but I have a JIT at",
    "start": "1775690",
    "end": "1785679"
  },
  {
    "text": "runtime now so I still have CPU and memory problems all right so as good as",
    "start": "1785679",
    "end": "1791350"
  },
  {
    "text": "it gets well not quite I still have other tricks in my bag so what I'm describing right",
    "start": "1791350",
    "end": "1797139"
  },
  {
    "text": "now is pretty much the state of open j9 before it was open sourced in about 2007",
    "start": "1797139",
    "end": "1803700"
  },
  {
    "text": "so the solution that we put out to accelerate we use a OT code basically we",
    "start": "1803700",
    "end": "1809470"
  },
  {
    "text": "generated by the JIT we store it in a cache and we get we get basically the",
    "start": "1809470",
    "end": "1815470"
  },
  {
    "start": "1814000",
    "end": "1814000"
  },
  {
    "text": "the kind of scorecard that I showed before but caching jets have gone further we've gotten better at doing",
    "start": "1815470",
    "end": "1821409"
  },
  {
    "text": "this so the basic idea here with a caching kit is you have a trick compiler running why not just take the code that",
    "start": "1821409",
    "end": "1828970"
  },
  {
    "text": "generated and store it someplace and then in another run let's take that code I don't have to compile it again how",
    "start": "1828970",
    "end": "1834970"
  },
  {
    "text": "many times do I have to compile string dot equals really and so this is kind of",
    "start": "1834970",
    "end": "1843429"
  },
  {
    "text": "like a chit and a ot mix here right so is it really different than you know tea well no and yes right from the second",
    "start": "1843429",
    "end": "1850600"
  },
  {
    "text": "JVM looks kind of like a ot right on the loading code that's something else generated I'm not compiling it I'm not",
    "start": "1850600",
    "end": "1856960"
  },
  {
    "text": "doing anything at runtime to use it so I'm just gonna load it and use it so that looks like a ot to me but the first",
    "start": "1856960",
    "end": "1862779"
  },
  {
    "text": "JVM that poor sucker has to go through that whole process of compiling everything and generating the",
    "start": "1862779",
    "end": "1868549"
  },
  {
    "text": "code and storing it in the cache and on top of that I have to generate a bunch of metadata to make sure that I don't",
    "start": "1868549",
    "end": "1874130"
  },
  {
    "text": "screw things up in that second run if some different class gets loaded or some different path becomes hot and and used",
    "start": "1874130",
    "end": "1880490"
  },
  {
    "text": "or if classes don't get loaded with exactly the same relationship that I relied on in the JIT and optimized the",
    "start": "1880490",
    "end": "1886070"
  },
  {
    "text": "code on in that first run in that code that I stored away I have to be able to catch that because you know that would",
    "start": "1886070",
    "end": "1891320"
  },
  {
    "text": "be bad if I took a code that was optimized for a scenario that's not true in the current JVM and used it why would",
    "start": "1891320",
    "end": "1897799"
  },
  {
    "text": "you guys be unhappy with me so we have to be very careful and that that has a",
    "start": "1897799",
    "end": "1904490"
  },
  {
    "text": "bit of an impact on making sure that all this works very well but we do get to return to platform neutrality because",
    "start": "1904490",
    "end": "1909940"
  },
  {
    "text": "even that first run where I'm generating that code it's the JIT compiler it's running in the process it sees at least",
    "start": "1909940",
    "end": "1917240"
  },
  {
    "text": "the profile of the user running that code I don't I don't have to generalize across all user all possible scenarios I",
    "start": "1917240",
    "end": "1924919"
  },
  {
    "text": "can focus on one and that usually is enough to get to get good because not",
    "start": "1924919",
    "end": "1932179"
  },
  {
    "text": "too many people like having different apps operating very differently all the time right that's just a not a very nice",
    "start": "1932179",
    "end": "1938630"
  },
  {
    "text": "system to work with right but different users are using different caches and so",
    "start": "1938630",
    "end": "1944840"
  },
  {
    "text": "they get the benefit of the code being tailored for their environment and it's happening at run time so it's tailored",
    "start": "1944840",
    "end": "1950210"
  },
  {
    "text": "for the processor so I can compile it on skylake if I want to compile it on skylake all right there are two basic",
    "start": "1950210",
    "end": "1957410"
  },
  {
    "start": "1956000",
    "end": "1956000"
  },
  {
    "text": "implementations of this that are available out there in the wild one is technology it Clips open j9 the the JVM",
    "start": "1957410",
    "end": "1964580"
  },
  {
    "text": "that I work on we call it dynamic äôt no one will ever accuse us of being good at",
    "start": "1964580",
    "end": "1970640"
  },
  {
    "text": "naming things in fact that comes up again and again in this talk poorly named stuff but anyway that's fine",
    "start": "1970640",
    "end": "1977059"
  },
  {
    "text": "missus originally introduced a long long time ago in the IBM SDK for Java Java 6",
    "start": "1977059",
    "end": "1983059"
  },
  {
    "text": "in fact and at this point we've got it to the point where there's about a 5 to",
    "start": "1983059",
    "end": "1989900"
  },
  {
    "text": "10 percent possible hit to be JIT performance and we're getting better all",
    "start": "1989900",
    "end": "1995450"
  },
  {
    "text": "the time like that and it's resilient to application changes Azul also has a technology which they",
    "start": "1995450",
    "end": "2000730"
  },
  {
    "text": "call compiled stashing maybe we should just use their name because Gil's usually a lot better at naming stuff",
    "start": "2000730",
    "end": "2006250"
  },
  {
    "text": "than I am however nonetheless so as ool's Falcon JIT has this compiled",
    "start": "2006250",
    "end": "2011679"
  },
  {
    "text": "stashing ability based on LEM was introduced I don't know if it's 20 18 or",
    "start": "2011679",
    "end": "2017049"
  },
  {
    "text": "19 I'm not 100% sure on when it actually got produced but it's kind of the same",
    "start": "2017049",
    "end": "2023140"
  },
  {
    "text": "idea you can store compiled code to disk you can load it on in a in a subsequent run there are some issues trying to make",
    "start": "2023140",
    "end": "2028840"
  },
  {
    "text": "sure that this run completely matches the scenario that you were that you had in the previous run so it's not a",
    "start": "2028840",
    "end": "2034150"
  },
  {
    "text": "hundred percent perfect but they do recompilation to get everything up to up to scratch so it's it works really well to also resilient to application changes",
    "start": "2034150",
    "end": "2041650"
  },
  {
    "text": "so these things are all very Java compliant right they run any java application and get it right in open g9",
    "start": "2041650",
    "end": "2050050"
  },
  {
    "start": "2048000",
    "end": "2048000"
  },
  {
    "text": "we really use cash to get code to accelerate startup that's been our primary use case for it we have an",
    "start": "2050050",
    "end": "2056740"
  },
  {
    "text": "option called - check share classes if you turn on that option you will share",
    "start": "2056740",
    "end": "2062108"
  },
  {
    "text": "the memory for classes you will save time trying to initialize those classes at load time you will store a ot code",
    "start": "2062109",
    "end": "2069760"
  },
  {
    "text": "into that cache that's been compiled by the JIT you will store profile data you will store hints to the JIT on what it",
    "start": "2069760",
    "end": "2076570"
  },
  {
    "text": "should do going forward and that population of the cache happens naturally and transparently at runtime",
    "start": "2076570",
    "end": "2081700"
  },
  {
    "text": "there's nothing else you have to do in order to make that work and you can name caches you can put them in different",
    "start": "2081700",
    "end": "2088000"
  },
  {
    "text": "caches etc there's all kinds of cool stuff that you can do with it right now very recently actually in one of our",
    "start": "2088000",
    "end": "2094868"
  },
  {
    "text": "recent releases we turned it on for boot class bootstrap classes by default which is",
    "start": "2094869",
    "end": "2100690"
  },
  {
    "text": "comparable to hotspot sharing classes in the in the in the bootstrap classes by default as well there's also an option -",
    "start": "2100690",
    "end": "2107920"
  },
  {
    "text": "axe to virtualized which will use cache cheat code even more aggressively it will even use it to accelerate ramp up",
    "start": "2107920",
    "end": "2114310"
  },
  {
    "text": "not just startup but there may be a slight performance drop that you'll see by doing that it can top it up but but",
    "start": "2114310",
    "end": "2121420"
  },
  {
    "text": "you might still see there so the graph on the right here shows Tomcat starting up with open j9 on the left side if you",
    "start": "2121420",
    "end": "2129070"
  },
  {
    "text": "completely disable all sharing you get that's are sort of the normalized 100% number",
    "start": "2129070",
    "end": "2135160"
  },
  {
    "text": "if you are using hotspot it's doing some class sharing by default so you get a 19",
    "start": "2135160",
    "end": "2142060"
  },
  {
    "text": "percent boost using hotspot to do that however with the new change that we've made to the default share class cache",
    "start": "2142060",
    "end": "2148570"
  },
  {
    "text": "there's actually a 28 percent boost that you get from using open g9 by default you don't have to turn on anything and",
    "start": "2148570",
    "end": "2154510"
  },
  {
    "text": "then if you do take that extra step into a - act share classes you actually get a 43 percent",
    "start": "2154510",
    "end": "2160000"
  },
  {
    "text": "performance boost in terms of startup performance for the Tomcat server so it",
    "start": "2160000",
    "end": "2165550"
  },
  {
    "text": "works pretty well now if we add that to our scorecard so",
    "start": "2165550",
    "end": "2170609"
  },
  {
    "text": "we almost have great steady-state performance we can adapt to runtime changes it's very easy to use it's",
    "start": "2170609",
    "end": "2177790"
  },
  {
    "text": "platform neutral startup is great except for that poor first run the ramp up is",
    "start": "2177790",
    "end": "2184570"
  },
  {
    "text": "great except for that poor first run and in the second run we get pretty good you",
    "start": "2184570",
    "end": "2191920"
  },
  {
    "text": "know CPU in memory because we're not doing as many JIT compiles in that second run but that first run still",
    "start": "2191920",
    "end": "2198339"
  },
  {
    "text": "getting hit so you know that's kind of the downside there okay there's still",
    "start": "2198339",
    "end": "2204609"
  },
  {
    "text": "some boxes there that are not green that's kind of unfortunate right even for caching jets well I'm gonna talk now",
    "start": "2204609",
    "end": "2212619"
  },
  {
    "text": "about some of the technology that were in the process of building at open j9 and we're actually very close to having",
    "start": "2212619",
    "end": "2219400"
  },
  {
    "text": "this ready for people to try out and use actually it is ready for people to try out and use it's just not in our builds by default quite yet so the basic",
    "start": "2219400",
    "end": "2227470"
  },
  {
    "start": "2226000",
    "end": "2226000"
  },
  {
    "text": "question is what if the JIT became a JIT server right we're trying to get rid of those transient",
    "start": "2227470",
    "end": "2232570"
  },
  {
    "text": "resource requirements that are imposed by the JIT on the JVM client when you run your application because they're",
    "start": "2232570",
    "end": "2239920"
  },
  {
    "text": "actually really hard to predict right who knows how much memory a JIT compiler is going to take in their java",
    "start": "2239920",
    "end": "2246250"
  },
  {
    "text": "application any idea no idea right again because the JIT is so lovely and",
    "start": "2246250",
    "end": "2252099"
  },
  {
    "text": "transparent you have no idea how to predict what it's doing all right we got your back so let's",
    "start": "2252099",
    "end": "2261339"
  },
  {
    "text": "let's dodge the problem and take this unpredictable random transparent thing that we all love and move it somewhere",
    "start": "2261339",
    "end": "2267280"
  },
  {
    "text": "else so that it can be random and transparent and somewhere else that we don't have to care about as much right let our applications run nice and clean",
    "start": "2267280",
    "end": "2274180"
  },
  {
    "text": "and and you can probably have more chance of predicting what the memory requirements are for the job",
    "start": "2274180",
    "end": "2279730"
  },
  {
    "text": "applications that we write then for this JIT compiler that somebody else wrote and activates randomly and random times",
    "start": "2279730",
    "end": "2287309"
  },
  {
    "text": "all right so the basic idea here is the JVM is going to be doing some profiling and worked it to identify what paths",
    "start": "2287309",
    "end": "2292869"
  },
  {
    "text": "need to get compiled but the actual work of compiling those methods gets shifted off to a remote server well and then you",
    "start": "2292869",
    "end": "2300640"
  },
  {
    "text": "have some wonderful Orchestrator in the middle of it handles load balancing and affinity and scaling reliability and all",
    "start": "2300640",
    "end": "2306490"
  },
  {
    "text": "that stuff gee if only there were things that could do that for us hmm all right well eventually they'll come",
    "start": "2306490",
    "end": "2312069"
  },
  {
    "text": "along I'm sure all right",
    "start": "2312069",
    "end": "2317920"
  },
  {
    "text": "use do lots of good things all right so one of the benefits well we can get all",
    "start": "2317920",
    "end": "2323230"
  },
  {
    "text": "of these you know random hard to predict induced CPU spikes and memory spikes out",
    "start": "2323230",
    "end": "2328359"
  },
  {
    "text": "of the client and and get the performance more along the lines of what",
    "start": "2328359",
    "end": "2333760"
  },
  {
    "text": "what you're familiar with in the applications that you're running we can get that JIT server can connect to the",
    "start": "2333760",
    "end": "2339640"
  },
  {
    "text": "client JVM at runtime same time that the applications running so theoretically there's no loss in performance we can",
    "start": "2339640",
    "end": "2345730"
  },
  {
    "text": "use the same profile data we can get the same class hierarchy information of that running process it's still adaptable to",
    "start": "2345730",
    "end": "2352660"
  },
  {
    "text": "changing conditions so that's great and the JVM client is still platform neutral in fact the JIT server doesn't even have",
    "start": "2352660",
    "end": "2360220"
  },
  {
    "text": "to run on the same kind of machine as the client anymore in principle there's some reasons why",
    "start": "2360220",
    "end": "2366819"
  },
  {
    "text": "it's usually still quite similar but but in principle you could do cross compiles all right could it really work well yes",
    "start": "2366819",
    "end": "2376270"
  },
  {
    "text": "that wouldn't be here from telling you about it if it didn't work right that's a less interesting talk all right so",
    "start": "2376270",
    "end": "2382990"
  },
  {
    "text": "here's a chart that talks about a Java EE benchmark called Acme err it's",
    "start": "2382990",
    "end": "2388580"
  },
  {
    "text": "modeling a flight reservation system that's not super important but it's using digit server technology that we've",
    "start": "2388580",
    "end": "2395360"
  },
  {
    "text": "been building at open j9 and in combination with - check share classes so I'm showing the cold run on the left",
    "start": "2395360",
    "end": "2403670"
  },
  {
    "text": "and the warm run on the right and you can see the blue line is open j9 using a",
    "start": "2403670",
    "end": "2410030"
  },
  {
    "text": "local JIT and the orange line is open j9 using a JIT server to do its JIT",
    "start": "2410030",
    "end": "2416060"
  },
  {
    "text": "compilations and the JVM client here I've backed into a little bit of a",
    "start": "2416060",
    "end": "2421460"
  },
  {
    "text": "corner I'm only letting it it's running in a container and I'm only giving it one CPU and 150 Meg's of memory which is",
    "start": "2421460",
    "end": "2428270"
  },
  {
    "text": "pretty tight for this particular application right and you can see even in the cold run by taking the compiled",
    "start": "2428270",
    "end": "2436130"
  },
  {
    "text": "workload and moving it to a different system and don't call me a cheater yet taking taking this cpu load to do",
    "start": "2436130",
    "end": "2444770"
  },
  {
    "text": "compilations out of the JVM client and to the server helps the JVM client startup faster even in that cold run",
    "start": "2444770",
    "end": "2451640"
  },
  {
    "text": "where you know that poor victimised guy who has to do all the work for everybody else and you know it doesn't get the",
    "start": "2451640",
    "end": "2457040"
  },
  {
    "text": "limelight even this cold run gets to do a better job it ramps up faster it starts up faster and actually quite a",
    "start": "2457040",
    "end": "2462470"
  },
  {
    "text": "bit faster right on the right-hand side the warm run well okay it's not exactly",
    "start": "2462470",
    "end": "2469220"
  },
  {
    "text": "a lot better using the JIT server but it's as good and in fact you do hit peak performance",
    "start": "2469220",
    "end": "2476960"
  },
  {
    "text": "faster and there's an interesting reason why the when you're doing a cold runs",
    "start": "2476960",
    "end": "2484100"
  },
  {
    "text": "with a local JIT the the JIT can't compile methods very quickly which means",
    "start": "2484100",
    "end": "2489350"
  },
  {
    "text": "it's queue of methods gets very long and we have a heuristic that says when the queue is long start downgrading äôt",
    "start": "2489350",
    "end": "2495890"
  },
  {
    "text": "compilations and doing them at lower op level so I can chew through more of them and get compiled code performance faster",
    "start": "2495890",
    "end": "2501350"
  },
  {
    "text": "which is great except that when I lower the off level I don't get as good performance which means I have to",
    "start": "2501350",
    "end": "2507470"
  },
  {
    "text": "recompile a bunch of stuff so if you can see there's kind of this drawn-out process here it kind of gets to a point",
    "start": "2507470",
    "end": "2514970"
  },
  {
    "text": "and then it has to do some other stuff to get all the way up to peak performance right it has this delay in",
    "start": "2514970",
    "end": "2520670"
  },
  {
    "text": "here I'm looking at the wrong one sorry here sorry so you you get here faster because",
    "start": "2520670",
    "end": "2528720"
  },
  {
    "text": "you've compiled a lot of äôt codes and your EOD methods in your cold run but",
    "start": "2528720",
    "end": "2533790"
  },
  {
    "text": "then you have to do more sort of high up compiles to get you all the way up and those compiles end up happening in the",
    "start": "2533790",
    "end": "2540210"
  },
  {
    "text": "process in the warm run to get you there when you're doing a server work those JIT compiler somewhere else so the cue",
    "start": "2540210",
    "end": "2547020"
  },
  {
    "text": "doesn't get long so we don't downgrade as many things and so we end up actually being able to compile all of the methods",
    "start": "2547020",
    "end": "2552150"
  },
  {
    "text": "that are going to be used and start up and ramp up at warm at our normal and so",
    "start": "2552150",
    "end": "2557520"
  },
  {
    "text": "that means we get this nice straight line boom all the way up to peak performance much earlier than what the",
    "start": "2557520",
    "end": "2563250"
  },
  {
    "text": "in process yet is able to achieve so that's kind of cool now I have to be fair these things are running on two",
    "start": "2563250",
    "end": "2570240"
  },
  {
    "text": "different machines but with a direct cable connection so kind of like the best offer I could have put them on the",
    "start": "2570240",
    "end": "2575550"
  },
  {
    "text": "same machine but but best option in terms of latency connecting these two things and I do want to make the point",
    "start": "2575550",
    "end": "2582660"
  },
  {
    "text": "that hotspot takes about twice as long as open j9 with a local JIT to start up this application and to ramp up to peak",
    "start": "2582660",
    "end": "2588750"
  },
  {
    "text": "performance so so so open tree lines",
    "start": "2588750",
    "end": "2593790"
  },
  {
    "text": "already great and this makes it even better all right now another example I'm",
    "start": "2593790",
    "end": "2601080"
  },
  {
    "start": "2600000",
    "end": "2600000"
  },
  {
    "text": "gonna show here is running a different application called day trader 7 now this is a bit beefier Java EE benchmark which",
    "start": "2601080",
    "end": "2609540"
  },
  {
    "text": "is simulating day trading stock trading and here I've shown three scenarios where I'm I'm backing this client",
    "start": "2609540",
    "end": "2618000"
  },
  {
    "text": "application into an increasingly difficult corner right the left hand graph shows one CPU and 300 Meg's and",
    "start": "2618000",
    "end": "2624420"
  },
  {
    "text": "you can see that that it that's really not very not a very tight corner right",
    "start": "2624420",
    "end": "2629910"
  },
  {
    "text": "even the local JIT is able to kind of make enough progress on here we get about the same ramp up and about the same performance in the middle graph",
    "start": "2629910",
    "end": "2636540"
  },
  {
    "text": "I've reduced the memory to 256 Meg's so and the the local JIT is now starting to",
    "start": "2636540",
    "end": "2642480"
  },
  {
    "text": "have trouble managing the workload of compiling at the same time that the the",
    "start": "2642480",
    "end": "2648350"
  },
  {
    "text": "application is trying to do work and what that means is with the JIT compiler",
    "start": "2648350",
    "end": "2653430"
  },
  {
    "text": "runs out of memory it does throw em and take down the whole JVM that would be stupid what we do instead",
    "start": "2653430",
    "end": "2660060"
  },
  {
    "text": "is just bail on the compile right we can't do that compile at that optimization level and so we'll back off",
    "start": "2660060",
    "end": "2665130"
  },
  {
    "text": "to a lower optimization level but that means lower performance and so as you can see the local JIT is starting to",
    "start": "2665130",
    "end": "2671490"
  },
  {
    "text": "have a bit of a performance impact whereas the JIT server because it's still sending its compiles over there",
    "start": "2671490",
    "end": "2676650"
  },
  {
    "text": "it's it's still able to manage things quite well now on the right hand side",
    "start": "2676650",
    "end": "2681810"
  },
  {
    "text": "I've down reduced it even further to 200 Meg's and now you can really see that",
    "start": "2681810",
    "end": "2687630"
  },
  {
    "text": "the local JIT is struggling right it's having real trouble being able to compile methods and so the the",
    "start": "2687630",
    "end": "2693480"
  },
  {
    "text": "throughput performance the results that it can manage to achieve it doesn't fall over it doesn't die but it's not doing",
    "start": "2693480",
    "end": "2700140"
  },
  {
    "text": "as as well as it was in the other scenarios JIT server is doing just fine",
    "start": "2700140",
    "end": "2707360"
  },
  {
    "text": "why is it a little lower I'm not a hundred percent sure of that something I'll have to look at so what this means",
    "start": "2707360",
    "end": "2715590"
  },
  {
    "text": "is is that you can start to be a lot more aggressive about how you size your",
    "start": "2715590",
    "end": "2720690"
  },
  {
    "text": "containers once the JIT compiler has been taken out of the process now you still have to obviously allocate space",
    "start": "2720690",
    "end": "2726960"
  },
  {
    "text": "and memory and CPU resources for the JIT server but but this simplifies the task",
    "start": "2726960",
    "end": "2734070"
  },
  {
    "text": "of managing your containers for your applications all right now I know what you're thinking all of that's been",
    "start": "2734070",
    "end": "2739980"
  },
  {
    "text": "dedicated machines with network cables and who knows but what about network latency not gonna hurt startup and ramp",
    "start": "2739980",
    "end": "2746580"
  },
  {
    "text": "up and all that compile stuffs happening and will it really be practical in the cloud right the title of the topic was",
    "start": "2746580",
    "end": "2752280"
  },
  {
    "text": "jigging for the cloud taking jets to the cloud all right well so we tried it on Amazon and it worked pretty well right",
    "start": "2752280",
    "end": "2760740"
  },
  {
    "text": "so on the Left shows the blue line is again the open j9 client with a local",
    "start": "2760740",
    "end": "2766920"
  },
  {
    "text": "JIT and you can see that it has massive spikes in footprint on the left in order",
    "start": "2766920",
    "end": "2772830"
  },
  {
    "text": "to do JIT compilers to get to its peak performance steady state it's it's quite",
    "start": "2772830",
    "end": "2778590"
  },
  {
    "text": "regular but the JIT server has managed to move all of that workload off onto a jet server just fine and we get this",
    "start": "2778590",
    "end": "2785460"
  },
  {
    "text": "nice clean memory footprint curve very predictable very easy to deal with",
    "start": "2785460",
    "end": "2790520"
  },
  {
    "text": "in terms of performance which is the graph on the right you can see okay it's",
    "start": "2790520",
    "end": "2795530"
  },
  {
    "text": "not quite as perfect as the other graphs that I showed but it's not all that far out of whack and we're still working on",
    "start": "2795530",
    "end": "2801470"
  },
  {
    "text": "this so we think there's still improvements that can get made now why is this the case well it's because we",
    "start": "2801470",
    "end": "2807350"
  },
  {
    "text": "can trade bandwidth for latency right yes it's true that compiles take a lot",
    "start": "2807350",
    "end": "2813380"
  },
  {
    "text": "longer to happen when they're happening across a network but we can afford to do more of them at a time because they're",
    "start": "2813380",
    "end": "2819200"
  },
  {
    "text": "kind of lower utilization even on the server and we can afford to put more resources on the server if it's doing a",
    "start": "2819200",
    "end": "2824780"
  },
  {
    "text": "lot of compiles and it can do compiles across multiple applications it doesn't you don't have to have one server for",
    "start": "2824780",
    "end": "2829940"
  },
  {
    "text": "one application anymore it's not a one-to-one relationship you can have one server feeding a whole bunch of clients",
    "start": "2829940",
    "end": "2835610"
  },
  {
    "text": "if you want all right so if we put that one up I've got almost all of my boxes",
    "start": "2835610",
    "end": "2841520"
  },
  {
    "text": "green almost all so everything's great from a performance side everything it's",
    "start": "2841520",
    "end": "2846770"
  },
  {
    "text": "platform neutral it's easy to use we've got two stars now because it's the first run across a cluster of applications",
    "start": "2846770",
    "end": "2853010"
  },
  {
    "text": "that are talking to the server the first time you try to compile this code but you can send it you know to any number",
    "start": "2853010",
    "end": "2859250"
  },
  {
    "text": "of clients if they want it in principle the only reason why I didn't do the",
    "start": "2859250",
    "end": "2864980"
  },
  {
    "text": "runtime CPU and memory a full green bar here is because there's actually still some CPU that gets consumed at the",
    "start": "2864980",
    "end": "2871760"
  },
  {
    "text": "client in order to satisfy these JIT compiler requests it turns out it's actually takes quite a lot of CPU cycles",
    "start": "2871760",
    "end": "2879230"
  },
  {
    "text": "to send memory that's in network traffic as a compiler guy this shocked me",
    "start": "2879230",
    "end": "2886310"
  },
  {
    "text": "because I thought compilers have to be like one of the most computationally demanding things that you could possibly do right well it turns out that sending",
    "start": "2886310",
    "end": "2893660"
  },
  {
    "text": "Network messages is actually even more intensive which I'm still unhappy about",
    "start": "2893660",
    "end": "2899510"
  },
  {
    "text": "but that's the way it is if wishes were so current status here is the code is",
    "start": "2899510",
    "end": "2907610"
  },
  {
    "start": "2904000",
    "end": "2904000"
  },
  {
    "text": "fully open source at Eclipse open j9 and the project that it builds from open Eclipse will more it's now been merged",
    "start": "2907610",
    "end": "2914090"
  },
  {
    "text": "into our master branch so that's new for this iteration of the presentation that hasn't been true before all the code is",
    "start": "2914090",
    "end": "2919940"
  },
  {
    "text": "in our master branch but we're not holding it in by default to the binary said adopt openjdk quite yet we've",
    "start": "2919940",
    "end": "2927900"
  },
  {
    "text": "introduced some simple options which lend really well to any kind of Java workload deployment right so if you want",
    "start": "2927900",
    "end": "2934500"
  },
  {
    "text": "to start the server or the client you're still running Java there's an option start as JIT server which causes the JVM",
    "start": "2934500",
    "end": "2942060"
  },
  {
    "text": "to start up as a JIT server predictably and you tell it which port to listen on and it listens on that port and it",
    "start": "2942060",
    "end": "2947670"
  },
  {
    "text": "happens like that very quickly if you're running a client application you use the",
    "start": "2947670",
    "end": "2952860"
  },
  {
    "text": "option to use JIT server give it the port send it the address and whatever command-line options you like",
    "start": "2952860",
    "end": "2958950"
  },
  {
    "text": "to run your java application with and that's it will do all of its compiles I was gonna do a demo but am a little bit",
    "start": "2958950",
    "end": "2966270"
  },
  {
    "text": "late on time and B I spilled water on myself in the panel I walked into that",
    "start": "2966270",
    "end": "2973320"
  },
  {
    "text": "TV trying to leave the room earlier so I figured not my day to do demos so I'm",
    "start": "2973320",
    "end": "2981000"
  },
  {
    "text": "gonna rest easy sorry you pay the price for that our current focus right now is",
    "start": "2981000",
    "end": "2989250"
  },
  {
    "text": "just on ensuring the stability of code base so that we can turn it on by default in our build for open j9 and we're hoping that that's going to happen",
    "start": "2989250",
    "end": "2995280"
  },
  {
    "text": "in our very next release which is in early 2020 that will be all the 0.18 release and because open j9 as a JVM",
    "start": "2995280",
    "end": "3004160"
  },
  {
    "text": "gets built into the same code base gets built into every JDK release that means that you'll be able to run JIT servers",
    "start": "3004160",
    "end": "3009950"
  },
  {
    "text": "with JDK 8 JDK 11 and JDK 13 at that point and actually one JIT server can",
    "start": "3009950",
    "end": "3016190"
  },
  {
    "text": "handle all three of those and I'm now being told to stop but I'm not quite done so I'll ask you to bear with me for",
    "start": "3016190",
    "end": "3025730"
  },
  {
    "text": "a couple minutes longer we're really just at the beginning of this process with jibt servers I think there's some",
    "start": "3025730",
    "end": "3031220"
  },
  {
    "text": "really cool stuff that can happen here our primary focus right now has been just on implementing up Kanaks to move",
    "start": "3031220",
    "end": "3036650"
  },
  {
    "text": "this compiled workload into a separate process once it's there there's actually",
    "start": "3036650",
    "end": "3042080"
  },
  {
    "text": "a lot of very interesting things you can do right you can figure out how to do that work more efficiently right so that you can use one server to serve a whole",
    "start": "3042080",
    "end": "3048590"
  },
  {
    "text": "bunch of different applications and not have to spend if you have NJ VMs you",
    "start": "3048590",
    "end": "3054410"
  },
  {
    "text": "should have to do n times that compile workload of one JVM you should be able to do that more efficiently right again it's kind",
    "start": "3054410",
    "end": "3060380"
  },
  {
    "text": "of that how many times do I have to compile string done equals question and",
    "start": "3060380",
    "end": "3066710"
  },
  {
    "text": "and that's obviously a very good fit for you know current trends towards micro-services where you've got lots of",
    "start": "3066710",
    "end": "3072020"
  },
  {
    "text": "JVMs and lots of je viens that you want to run in small footprints so it's a really good fit for taking the JIT out",
    "start": "3072020",
    "end": "3077780"
  },
  {
    "text": "of all of those things and compiling across them we can start using classification algorithms to try and",
    "start": "3077780",
    "end": "3084110"
  },
  {
    "text": "categorize those JVMs automatically so you don't have to do very much there's no user experience in trying to figure",
    "start": "3084110",
    "end": "3089780"
  },
  {
    "text": "this out we can make it just work the same wage it's work right where nobody knows how to disable it because it's so",
    "start": "3089780",
    "end": "3095690"
  },
  {
    "text": "weak a bit good isn't great we can even optimize groups of micro-services together right and you",
    "start": "3095690",
    "end": "3101570"
  },
  {
    "text": "know you can I think there's some really exciting opportunities to use this in say you know CI ACD pipelines right you",
    "start": "3101570",
    "end": "3107240"
  },
  {
    "text": "could imagine where even your sort of development experience is tied to I know",
    "start": "3107240",
    "end": "3112580"
  },
  {
    "text": "which methods changed in this pull request so communicate that to the JIT server so it knows exactly which ones",
    "start": "3112580",
    "end": "3118820"
  },
  {
    "text": "not to send to the thing and then you know it can even start compiling those ones while you're waiting to run your",
    "start": "3118820",
    "end": "3124700"
  },
  {
    "text": "tests and then you just get your your whole pipeline gets accelerated by this JIT server sitting on the side that's",
    "start": "3124700",
    "end": "3129980"
  },
  {
    "text": "communicating back and forth and it's even a good place where you can collect information like imagine all the profile",
    "start": "3129980",
    "end": "3135440"
  },
  {
    "text": "data all the class information everything that's inside the JVM it's now sitting someplace that I can",
    "start": "3135440",
    "end": "3141050"
  },
  {
    "text": "independently query I could find a way to present that data in the IDE maybe even right start feeding back some of",
    "start": "3141050",
    "end": "3148280"
  },
  {
    "text": "that information about how applications are running in your IDE because that",
    "start": "3148280",
    "end": "3153470"
  },
  {
    "text": "server can live longer than your application does it doesn't have to be there then all right",
    "start": "3153470",
    "end": "3158510"
  },
  {
    "text": "I'm wrapping up I promise to thumbs up",
    "start": "3158510",
    "end": "3164140"
  },
  {
    "text": "so yes quickly wrapping up so Jets continue to provide the best peak",
    "start": "3164290",
    "end": "3170510"
  },
  {
    "text": "performance here but there are some really good opportunities to do even cooler things äôt compilers as we talked",
    "start": "3170510",
    "end": "3177020"
  },
  {
    "text": "about they're very interesting technology they're starting there they can improve start-up performance dramatically but there are some",
    "start": "3177020",
    "end": "3183290"
  },
  {
    "text": "steady-state performance issues with them and some serious usability issues if you were to just use a",
    "start": "3183290",
    "end": "3188600"
  },
  {
    "text": "by itself and that's why in open j9 we don't just use a OT by itself we use a OT in combination with and now with",
    "start": "3188600",
    "end": "3196370"
  },
  {
    "text": "cashing argit compiles and and starting to now go to jet servers right you can",
    "start": "3196370",
    "end": "3202790"
  },
  {
    "text": "get to within five to ten percent with cashing jet of with excellent start up and ramp up even for very large to car",
    "start": "3202790",
    "end": "3209210"
  },
  {
    "text": "to EE applications right and I think there's still room here to improve both throughput and startup and footprint",
    "start": "3209210",
    "end": "3215690"
  },
  {
    "text": "without sacrificing and compliance without having to go to a closed world model excuse me it'd be very interesting to see if we",
    "start": "3215690",
    "end": "3222770"
  },
  {
    "text": "can go if there are any intermediate steps there between you know full Java compliance and definitely not Java",
    "start": "3222770",
    "end": "3229370"
  },
  {
    "text": "compliant there's there's there's a spectrum in between there I think it'd be interesting to see what solutions we",
    "start": "3229370",
    "end": "3235130"
  },
  {
    "text": "can build in that space without having to sacrifice completely on on Java",
    "start": "3235130",
    "end": "3240260"
  },
  {
    "text": "compliance and JIT servers are coming hopefully built into opt open JDK in",
    "start": "3240260",
    "end": "3245780"
  },
  {
    "text": "early 2020 if you haven't tried eclipse open j9 yet I don't know what you're waiting for",
    "start": "3245780",
    "end": "3250850"
  },
  {
    "text": "but go to a site docked open JDK net you'll get presented with a thing like that a page like that make sure you pick",
    "start": "3250850",
    "end": "3257840"
  },
  {
    "text": "open j9 on the right hand side here and try it out and let us know how it goes thank you",
    "start": "3257840",
    "end": "3263640"
  },
  {
    "text": "[Applause]",
    "start": "3263640",
    "end": "3267449"
  }
]
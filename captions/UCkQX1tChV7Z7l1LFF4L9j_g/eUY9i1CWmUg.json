[
  {
    "text": "[Music]",
    "start": "3270",
    "end": "8730"
  },
  {
    "text": "it is a delight to be here uh with you all sharing um some ideas about what I",
    "start": "10000",
    "end": "16480"
  },
  {
    "text": "find to be one of the most fascinating topics in maybe all of Technology",
    "start": "16480",
    "end": "22359"
  },
  {
    "text": "um what a time for what we call AI or language AI it's been",
    "start": "22359",
    "end": "30279"
  },
  {
    "text": "a roller coaster ride if you've been paying attention uh the last few years",
    "start": "30279",
    "end": "35440"
  },
  {
    "text": "and this is a a pattern that you can see just in Computing in general every 10 15 years we have this sort of new paradigm",
    "start": "35440",
    "end": "43000"
  },
  {
    "text": "that opens up new ways of doing things so the rise of the personal computers",
    "start": "43000",
    "end": "48600"
  },
  {
    "text": "the creation of the web browser the smartphones every one of these just creates new ways where people can",
    "start": "48600",
    "end": "55960"
  },
  {
    "text": "communicate with uh with computers and ways they can use them that also changes",
    "start": "55960",
    "end": "61199"
  },
  {
    "text": "definitions of jobs entire Industries as well and now we stand at this era or",
    "start": "61199",
    "end": "69600"
  },
  {
    "text": "time where this generative AI or AI in general or possibly generative chat are",
    "start": "69600",
    "end": "76320"
  },
  {
    "text": "this um new mode that is probably going to be as big as these these previous",
    "start": "76320",
    "end": "82320"
  },
  {
    "text": "technological shifts but I even sometimes like to take a a further step back and say if you look at the human",
    "start": "82320",
    "end": "88880"
  },
  {
    "text": "species in general jumps in language technology can be",
    "start": "88880",
    "end": "94880"
  },
  {
    "text": "milestones for the species as a whole and you can point at the invention of writing which is just this jump in in",
    "start": "94880",
    "end": "102360"
  },
  {
    "text": "human language technology and that's technically what we call the beginning",
    "start": "102360",
    "end": "107600"
  },
  {
    "text": "of history is this one sort of jump that we use language in a in in a specific way and then that's what we call history",
    "start": "107600",
    "end": "116079"
  },
  {
    "text": "and then about four or 500 years ago the printing press the device sort of made it possible for people for so many",
    "start": "116079",
    "end": "123759"
  },
  {
    "text": "people to have books before this invention if you wanted a copy of a book you needed to go and copy it yourself or",
    "start": "123759",
    "end": "130200"
  },
  {
    "text": "pay somebody to copy it by hand so once this way of automating books came around",
    "start": "130200",
    "end": "136280"
  },
  {
    "text": "people were you didn't need to be rich anymore to be able to own a book and then that",
    "start": "136280",
    "end": "142160"
  },
  {
    "text": "sort of opens the door for the next technological Revolution uh the Renaissance and pretty soon we're just",
    "start": "142160",
    "end": "148840"
  },
  {
    "text": "launching Tesla into space within the span of a couple of hundred years so I have talks from two years ago",
    "start": "148840",
    "end": "156160"
  },
  {
    "text": "where I say this jump is it going to be as as as big as the as these two we",
    "start": "156160",
    "end": "163920"
  },
  {
    "text": "don't really know uh there's a lot of hype and I would like to cut through the hype but two years ago I would say we",
    "start": "163920",
    "end": "170959"
  },
  {
    "text": "have a less than maybe 20% chance it's possible that this is going to be as big uh now I put it at less than 40% chance",
    "start": "170959",
    "end": "177959"
  },
  {
    "text": "so it's definitely going to change so many different things but we'll see if it sort of lives up to to these two so",
    "start": "177959",
    "end": "184319"
  },
  {
    "text": "my name is Jay and I I I blog U on for about the last nine or 10 years uh about",
    "start": "184319",
    "end": "191239"
  },
  {
    "text": "machine learning uh and language processing and large language models uh the most read article is the illustated",
    "start": "191239",
    "end": "198599"
  },
  {
    "text": "Transformer that explains this uh neural network architecture that sort of launched this this explosion in AI",
    "start": "198599",
    "end": "205920"
  },
  {
    "text": "capability over the last uh few years it has about 3 million page views or so um",
    "start": "205920",
    "end": "212319"
  },
  {
    "text": "I'm the author of this upcoming O'Reilly book uh called uh handson large language",
    "start": "212319",
    "end": "217840"
  },
  {
    "text": "models so this is we're targeting releasing it in August uh it's already",
    "start": "217840",
    "end": "223760"
  },
  {
    "text": "you can find the first five or six chapters on the oral platform um and I",
    "start": "223760",
    "end": "229360"
  },
  {
    "text": "work at coher and coher is a large language model company it's one of the earliest large L model companies they've",
    "start": "229360",
    "end": "235879"
  },
  {
    "text": "been training these models for about four years and it was started by one of the authors of the Transformer paper",
    "start": "235879",
    "end": "242079"
  },
  {
    "text": "Aiden GES and so I joined because I was absolutely fascinated about this",
    "start": "242079",
    "end": "247360"
  },
  {
    "text": "technology and I wanted to see how this cool machine learning trick would make",
    "start": "247360",
    "end": "253040"
  },
  {
    "text": "its way into industry how will it become products how will it become features and",
    "start": "253040",
    "end": "258440"
  },
  {
    "text": "that's what we're going to be sharing here some of the things that I learned sort of from what we see in um incoh",
    "start": "258440",
    "end": "264759"
  },
  {
    "text": "here and sort of how people sort of adopt these um these products and so you're definitely in the right room in",
    "start": "264759",
    "end": "270880"
  },
  {
    "text": "the right place this is the right time to start to think about uh how to build",
    "start": "270880",
    "end": "276400"
  },
  {
    "text": "the intelligence systems of the future using Technologies like these now when I",
    "start": "276400",
    "end": "281479"
  },
  {
    "text": "used to go and give talks two years ago uh I had to introduce to people what a l large language model is that was not a",
    "start": "281479",
    "end": "289080"
  },
  {
    "text": "common piece of of of software knowledge but now everywhere I go developers or non-developers everybody has interacted",
    "start": "289080",
    "end": "296440"
  },
  {
    "text": "or had have some sense of what is a chatk model what is a chat GPT what is a",
    "start": "296440",
    "end": "302280"
  },
  {
    "text": "large language model that you sort of can can talk to and so how we talk about them is is a little bit different so now",
    "start": "302280",
    "end": "308919"
  },
  {
    "text": "what we try to do is to try to raise the awareness that okay you've interacted with a generative chat Model A large",
    "start": "308919",
    "end": "314960"
  },
  {
    "text": "language model we suggest that you don't think of it as a black box we suggest that you",
    "start": "314960",
    "end": "320880"
  },
  {
    "text": "don't think of it as a digital brain regardless of how coherent and",
    "start": "320880",
    "end": "325960"
  },
  {
    "text": "how the the how well written it might",
    "start": "325960",
    "end": "331160"
  },
  {
    "text": "uh the useful perspective we advise everybody and developers specifically is",
    "start": "331160",
    "end": "336639"
  },
  {
    "text": "is to think about it in terms of what can you build with this what kinds of capabilities did this sort of uh give",
    "start": "336639",
    "end": "342360"
  },
  {
    "text": "you uh or adds to your toolbox as a as a developer and so how can you think about",
    "start": "342360",
    "end": "347960"
  },
  {
    "text": "it more than just this box that you sent some text in and you get some text out",
    "start": "347960",
    "end": "353319"
  },
  {
    "text": "and that's what we're going to be talking about and so when we talk about the language uh side of it you can talk talk",
    "start": "353319",
    "end": "359840"
  },
  {
    "text": "about two major families of capabilities that these models bring to you and these",
    "start": "359840",
    "end": "365039"
  },
  {
    "text": "can be language understanding capabilities that's the first group of capabilities that language models",
    "start": "365039",
    "end": "370960"
  },
  {
    "text": "provide to you and it can also be language generation capabilities that's let's say the other group and even if",
    "start": "370960",
    "end": "378199"
  },
  {
    "text": "you're not dealing specifically with uh text generation uh who in here has saw",
    "start": "378199",
    "end": "383639"
  },
  {
    "text": "mid Journey or Sora for like image generation or stable diffusion for video",
    "start": "383639",
    "end": "388759"
  },
  {
    "text": "generation so all of these models even though they are generating things other",
    "start": "388759",
    "end": "393960"
  },
  {
    "text": "than text they have a language model embedded in them in the beginning of that flow because you're giving them a",
    "start": "393960",
    "end": "400400"
  },
  {
    "text": "prompt and that understanding of a prompt is the use of a language model for understanding not not necessarily",
    "start": "400400",
    "end": "407479"
  },
  {
    "text": "for for generation and so for your toolbox I",
    "start": "407479",
    "end": "412800"
  },
  {
    "text": "want to break this down further so generative chat is only one of multiple things that you can do with generation",
    "start": "412800",
    "end": "419599"
  },
  {
    "text": "so text generation can be summarization so taking a large article and providing",
    "start": "419599",
    "end": "425720"
  },
  {
    "text": "a two or three minute a three sentence summary is a generative uh task um",
    "start": "425720",
    "end": "432479"
  },
  {
    "text": "copyrighting if you tell the model to you know write me an email that says this or write me variations of this type",
    "start": "432479",
    "end": "439560"
  },
  {
    "text": "of text or that's another sort of generation text and these are you know",
    "start": "439560",
    "end": "445560"
  },
  {
    "text": "in addition to generative chat so one of the the one of the main messages here is",
    "start": "445560",
    "end": "451120"
  },
  {
    "text": "don't be limited to chat only like everything you can do with generation can go into a lot of different uh",
    "start": "451120",
    "end": "458400"
  },
  {
    "text": "generation tasks and a lot of them should probably be offline you shouldn't always sort of lock yourself into I'm",
    "start": "458400",
    "end": "463960"
  },
  {
    "text": "going to be always thinking about online chat right this very minute and then",
    "start": "463960",
    "end": "469120"
  },
  {
    "text": "even when you think about these other non- chat generative um capabilities you're only thinking about one of the",
    "start": "469120",
    "end": "475400"
  },
  {
    "text": "things that that AI can do in fact some of the most dramatic I and most reliable",
    "start": "475400",
    "end": "481039"
  },
  {
    "text": "use cases that AI has right now that has even progressed the last few years are things like search or text",
    "start": "481039",
    "end": "488000"
  },
  {
    "text": "classification or categorizations and and large language models or language models in general small and large uh are",
    "start": "488000",
    "end": "494639"
  },
  {
    "text": "some of the best tools that we have for that and so think Beyond just generating text I think it's a little bit",
    "start": "494639",
    "end": "499919"
  },
  {
    "text": "unfortunate that this wave is being called generative AI because some of the most robust applications are really more",
    "start": "499919",
    "end": "505720"
  },
  {
    "text": "on the understanding the representation the search systems and we we'll talk about and sort of where their capabilities lie",
    "start": "505720",
    "end": "513360"
  },
  {
    "text": "and so this idea of search by meaning or using a language model for search is is one of the most reliable uh applications",
    "start": "513360",
    "end": "520240"
  },
  {
    "text": "of of large language models and if you've tried to build with large language models reliability becomes something that you sort of um care about",
    "start": "520240",
    "end": "527120"
  },
  {
    "text": "a little bit because there's so many chicked examples that you come across in social media but if you try to build",
    "start": "527120",
    "end": "532640"
  },
  {
    "text": "that into a product they you know you realize that you know that works six out",
    "start": "532640",
    "end": "538360"
  },
  {
    "text": "of 10 times or three out of 10 times depending on on on that use case and so reliability is is important when you",
    "start": "538360",
    "end": "543839"
  },
  {
    "text": "think about sort of robustness so when you think about search don't think about only about building the next Google",
    "start": "543839",
    "end": "550000"
  },
  {
    "text": "search search is this major feature of every application that you interact with every company needs to search their own",
    "start": "550000",
    "end": "556640"
  },
  {
    "text": "internal documents and a lot of search systems are broken they need to be sort of improved you can almost never find um",
    "start": "556640",
    "end": "564519"
  },
  {
    "text": "what you want then how language models can can can help here is this with this idea of Mantic search so let's take a",
    "start": "564519",
    "end": "571360"
  },
  {
    "text": "query for example so you want to search for Brazil to USA travel so before",
    "start": "571360",
    "end": "577440"
  },
  {
    "text": "language models most search was based on keyword uh relevance so it will break it",
    "start": "577440",
    "end": "582920"
  },
  {
    "text": "down and compare the keywords in the query to keywords in in in the document and you know if a a system is not very",
    "start": "582920",
    "end": "590320"
  },
  {
    "text": "well tuned it might give you this article which has all the same keywords but the order of the two countries is",
    "start": "590320",
    "end": "596760"
  },
  {
    "text": "flipped and so that document really does not become a a relevant document for that search but if you use language",
    "start": "596760",
    "end": "603839"
  },
  {
    "text": "models for that search they have a better ability to sort of catch the intention and the context that you're",
    "start": "603839",
    "end": "609760"
  },
  {
    "text": "using these words for and so that's the idea of using uh language models for uh",
    "start": "609760",
    "end": "615560"
  },
  {
    "text": "for search two main Concepts to think about for semantic search or using",
    "start": "615560",
    "end": "620680"
  },
  {
    "text": "language models for um search one is called dense retrieval who's here who",
    "start": "620680",
    "end": "626720"
  },
  {
    "text": "has built anything with embedding search like a Vector search database or pine cone okay so we have a good number I",
    "start": "626720",
    "end": "632880"
  },
  {
    "text": "think maybe 30 40% so that is what's called dense retrieval and then the",
    "start": "632880",
    "end": "638000"
  },
  {
    "text": "other one is called rewriting let's let's take a look a quick look at how those are so you have a query you send",
    "start": "638000",
    "end": "643639"
  },
  {
    "text": "it to a a search system in this case a vector database uh or it can be a",
    "start": "643639",
    "end": "649040"
  },
  {
    "text": "database with Vector uh search capabilities so there are features of postgress for example that can do um",
    "start": "649040",
    "end": "656120"
  },
  {
    "text": "something like that and that Vector database has access to a archive and then it produces a number of of search",
    "start": "656120",
    "end": "662639"
  },
  {
    "text": "results so this is the search formula basically uh behind the scenes how dense",
    "start": "662639",
    "end": "668600"
  },
  {
    "text": "retrieval sort of works is that it takes the query it sends it to a language model that provides something called an",
    "start": "668600",
    "end": "674800"
  },
  {
    "text": "embedding so language models you can have have them generate text but you can also have them generate another thing",
    "start": "674800",
    "end": "681680"
  },
  {
    "text": "which is a list of numbers that capture the meaning of that text uh and that's",
    "start": "681680",
    "end": "687120"
  },
  {
    "text": "what's called an embedding vector and and so here you have the query you send it to the model the model gives you",
    "start": "687120",
    "end": "692519"
  },
  {
    "text": "maybe 300 numbers like a vector size that is a numeric representation that is useful for Downstream software",
    "start": "692519",
    "end": "699800"
  },
  {
    "text": "applications and then you send you simply send that Vector to this Vector database and it finds the the nearest",
    "start": "699800",
    "end": "705760"
  },
  {
    "text": "neighbors to that to that point and those will tend to be the best search",
    "start": "705760",
    "end": "711040"
  },
  {
    "text": "results for for for that for that query and this model sort of has to be tuned for search specifically you can't just",
    "start": "711040",
    "end": "717279"
  },
  {
    "text": "get any embedding models uh an betting model used for search has to be tuned in a specific way for for",
    "start": "717279",
    "end": "724800"
  },
  {
    "text": "solu there's a step before that of chunking the text and embedding the the",
    "start": "725839",
    "end": "731079"
  },
  {
    "text": "archive beforehand so that that is Step Zero uh if you'd like to play around with embeddings we've open source we've",
    "start": "731079",
    "end": "738560"
  },
  {
    "text": "launched uh released the embeddings of all of Wikipedia these are 250",
    "start": "738560",
    "end": "745279"
  },
  {
    "text": "million embedding vectors of Wikipedia in 300 languages so it's the English but",
    "start": "745279",
    "end": "751000"
  },
  {
    "text": "also every other Wikipedia out there you can it's on hugging face you can download it and sort of play around with it uh it's you can build incredible",
    "start": "751000",
    "end": "758920"
  },
  {
    "text": "things with with it and so that is dense retrieval the other idea is called",
    "start": "758920",
    "end": "764440"
  },
  {
    "text": "reranking and and reranking is really the fastest way to inject the intelligence of a language model into a",
    "start": "764440",
    "end": "769959"
  },
  {
    "text": "existing search system and it work basically in this two uh step Factor",
    "start": "769959",
    "end": "775199"
  },
  {
    "text": "twostep let's say pipeline so you don't have to remove your existing search system so if you're using elastic or any",
    "start": "775199",
    "end": "782399"
  },
  {
    "text": "other sort of search system that can be your first step of of your your search Pipeline and that is the system that",
    "start": "782399",
    "end": "789440"
  },
  {
    "text": "queries or searches your million or a billion documents and gets you the top",
    "start": "789440",
    "end": "794839"
  },
  {
    "text": "100 results and then those 100 results we pass to a language model and it just",
    "start": "794839",
    "end": "799920"
  },
  {
    "text": "changes the order it outputs the same 100 but it says hm this article that you told me is number 33 is actually the",
    "start": "799920",
    "end": "807199"
  },
  {
    "text": "most relevant to this query so I'm going to make it number one and so this is only one call at the end of that of that",
    "start": "807199",
    "end": "813760"
  },
  {
    "text": "search pipeline that tends to dramatically improve the search system regardless whether you're using elastic",
    "start": "813760",
    "end": "819760"
  },
  {
    "text": "whether you're using embedding search whether you're using hybrid search of the two just reranking just gives you",
    "start": "819760",
    "end": "824920"
  },
  {
    "text": "that that that uplift sort of very quickly the way that it works is this is",
    "start": "824920",
    "end": "830040"
  },
  {
    "text": "a a language model um that works in what's called a cross encoder fashion so",
    "start": "830040",
    "end": "835519"
  },
  {
    "text": "to to the language model we present the query and the document and just outputs a a score of relevance and even if",
    "start": "835519",
    "end": "843560"
  },
  {
    "text": "you're familiar with embeddings this works better than embeddings because the language model at the time of scoring",
    "start": "843560",
    "end": "850920"
  },
  {
    "text": "has access to all of the text of the query and of the um of the document and",
    "start": "850920",
    "end": "856639"
  },
  {
    "text": "so it's able to give a better result because of that information that it has while embeddings actually work on this",
    "start": "856639",
    "end": "862880"
  },
  {
    "text": "very compressed spaces of the of the two vectors that you know can't encode all the information in the text so that's R",
    "start": "862880",
    "end": "869399"
  },
  {
    "text": "ranking tends to work better than than embeddings but it happens to be a second stage because it can't operate on on a",
    "start": "869399",
    "end": "876680"
  },
  {
    "text": "million documents so you want you need a funnel uh to choose the top 10 or 100",
    "start": "876680",
    "end": "882240"
  },
  {
    "text": "results to to to give to it and here you get to see the uplift that you can get the light these are three different data",
    "start": "882240",
    "end": "888680"
  },
  {
    "text": "sets the light one is keyword search so that's elastic or bm25 the one next to",
    "start": "888680",
    "end": "894959"
  },
  {
    "text": "it is kind of like this one is this is search by embeddings and this this is",
    "start": "894959",
    "end": "900079"
  },
  {
    "text": "elastic plus reranking so whe whether you're using keyword search or embedding",
    "start": "900079",
    "end": "905120"
  },
  {
    "text": "search a ranker sort of is one of these fastest ways to to improve the the the",
    "start": "905120",
    "end": "911199"
  },
  {
    "text": "search system that you that you're building with now the y- axis here is accuracy who here is familiar enough",
    "start": "911199",
    "end": "918959"
  },
  {
    "text": "with what that means what is search accuracy okay that is very good because",
    "start": "918959",
    "end": "925000"
  },
  {
    "text": "we have I have a couple of slides on what that means but uh because coming into this we I saw lot of people wave",
    "start": "925000",
    "end": "932839"
  },
  {
    "text": "hands about search accuracy but you know I wanted a clear definition but we we'll get to that and so these are two kinds",
    "start": "932839",
    "end": "939199"
  },
  {
    "text": "of language models so these are not generative language models but these are ways of using language models for search",
    "start": "939199",
    "end": "945480"
  },
  {
    "text": "uh embeddings and reranking are these two ways and so even if you're interested in in generation specifically",
    "start": "945480",
    "end": "951800"
  },
  {
    "text": "search is one of the most important things for the future of generation models and this is an example that",
    "start": "951800",
    "end": "958560"
  },
  {
    "text": "showcas is um why that is so let's say you have two questions um you have a question where you send a a question to",
    "start": "958560",
    "end": "965079"
  },
  {
    "text": "a language model and then you have another scenario where you send it the same question but you actually give it some sort of context you maybe give it",
    "start": "965079",
    "end": "972240"
  },
  {
    "text": "the answer before you gave it you give it the question and question number two",
    "start": "972240",
    "end": "978079"
  },
  {
    "text": "like models would tend to answer number two better than than number one uh so regardless of the question like if you",
    "start": "978079",
    "end": "983959"
  },
  {
    "text": "give the the model the answer plus the question it will probably have a better answer um for for you and this is one of",
    "start": "983959",
    "end": "989759"
  },
  {
    "text": "the first things that people sort of first realized when these models came out uh they called them you know search",
    "start": "989759",
    "end": "997759"
  },
  {
    "text": "killers and people were rely asking these models questions and relying on how factual their their information are",
    "start": "997759",
    "end": "1004880"
  },
  {
    "text": "and a lot of people got into trouble for trusting how coherent those model models are um and ascribing authority to to",
    "start": "1004880",
    "end": "1012440"
  },
  {
    "text": "their information sort of retrieval um but then that turned out to be a mistake",
    "start": "1012440",
    "end": "1017560"
  },
  {
    "text": "and everybody now knows about the problem called hallucinations models will tend to give you an answer maybe",
    "start": "1017560",
    "end": "1023360"
  },
  {
    "text": "they might be a little bit too confident about it but you should not rely on a language model specifically only a",
    "start": "1023360",
    "end": "1029959"
  },
  {
    "text": "language model for factual retrieval you need better tools you need to to augment it somehow and that is the the the",
    "start": "1029959",
    "end": "1037120"
  },
  {
    "text": "method here so when you're relying on the model for information you're relying",
    "start": "1037120",
    "end": "1042199"
  },
  {
    "text": "on information that is stored within the parameters of of of the model and so you're always going to be using larger",
    "start": "1042199",
    "end": "1048160"
  },
  {
    "text": "and larger models uh the information is always going to be outdated because how can you inject new",
    "start": "1048160",
    "end": "1053840"
  },
  {
    "text": "information into the model do you have to train it for another 9 months while in this other Paradigm you",
    "start": "1053840",
    "end": "1060840"
  },
  {
    "text": "actually augment the model with an external data source where you can inject the the information at question",
    "start": "1060840",
    "end": "1067240"
  },
  {
    "text": "time whenever sort of somebody asks you the model is able to retrieve the the information that is needed and then that",
    "start": "1067240",
    "end": "1073039"
  },
  {
    "text": "informs it and you get so many different benefits from this so you get much smaller models because you're not",
    "start": "1073039",
    "end": "1078320"
  },
  {
    "text": "storing ing ridiculous amounts of information in this inefficient um storage mechanism and",
    "start": "1078320",
    "end": "1085679"
  },
  {
    "text": "loading them to GPU memory all the time uh you can have upto-date information you can change it by the hour um you can",
    "start": "1085679",
    "end": "1093840"
  },
  {
    "text": "give different users the ability to access different data sources so even it gives you more freedom of how what",
    "start": "1093840",
    "end": "1100760"
  },
  {
    "text": "systems uh you can build with with a with a system like this but it also gives you explainable sources so which",
    "start": "1100760",
    "end": "1108760"
  },
  {
    "text": "doents did the model look at before it answered this question that gives you a little bit more transparency into the",
    "start": "1108760",
    "end": "1114000"
  },
  {
    "text": "behavior of the model and then that can also help you debug did the problem come from the search step or from the from",
    "start": "1114000",
    "end": "1119960"
  },
  {
    "text": "the generation step and so this is what retrieval augmented generation is it is this",
    "start": "1119960",
    "end": "1125120"
  },
  {
    "text": "intersection of search uh and and generation and it's by far the highest",
    "start": "1125120",
    "end": "1132320"
  },
  {
    "text": "uh in demand uh use case that we see in in in industry and Enterprises that that",
    "start": "1132320",
    "end": "1138799"
  },
  {
    "text": "we talk with and one way to look at it is kind of like this command is is the llm we use at go here and it just you're",
    "start": "1138799",
    "end": "1146320"
  },
  {
    "text": "tying your llm with a with a data source that is able to access and sort of retrieve information from so this is one",
    "start": "1146320",
    "end": "1151919"
  },
  {
    "text": "way of of thinking that the conversation is not just with the model itself but it's with a model that is connected that",
    "start": "1151919",
    "end": "1158880"
  },
  {
    "text": "is grounded in a a data source that is able to access that information and so now you have these",
    "start": "1158880",
    "end": "1165640"
  },
  {
    "text": "two steps so before the questions answered it goes through a retrieval or",
    "start": "1165640",
    "end": "1170960"
  },
  {
    "text": "a search step and then you go through a generation step so that is these are the two sort of basic steps of of a",
    "start": "1170960",
    "end": "1178000"
  },
  {
    "text": "retrieval pipeline um and then another way of of seeing it more clearly is you do a",
    "start": "1178000",
    "end": "1183600"
  },
  {
    "text": "search step and then you get the top three documents for example or 10 documents you put those in the prompt",
    "start": "1183600",
    "end": "1190520"
  },
  {
    "text": "with the question you present that to the language model and then that's sort of how how how it's it's answered this",
    "start": "1190520",
    "end": "1196320"
  },
  {
    "text": "is also another sort of the most basic formulas of uh of frag or retrieval",
    "start": "1196320",
    "end": "1201960"
  },
  {
    "text": "augmented generation and then you get even better results if you have a a ranker in this step because if if if you're only giving 10 documents and the",
    "start": "1201960",
    "end": "1209240"
  },
  {
    "text": "11th document is really the one that has the uh the right information but it's beyond that cut offline the model is not",
    "start": "1209240",
    "end": "1215559"
  },
  {
    "text": "going to be able to generate the right answer and so any Improvement the most uh the area where",
    "start": "1215559",
    "end": "1222200"
  },
  {
    "text": "so many failures in rag happen tends to be more in the retrieval side as the generation side and so now you have these two",
    "start": "1222200",
    "end": "1229760"
  },
  {
    "text": "language models in the retrieval step in addition to the generation model in the",
    "start": "1229760",
    "end": "1235039"
  },
  {
    "text": "in in the generation step and so that's one of the first ways that you can sort of build build a right",
    "start": "1235039",
    "end": "1241400"
  },
  {
    "text": "system now one challenge is after you build a system like this and because you",
    "start": "1241400",
    "end": "1247000"
  },
  {
    "text": "have in mind that people will ask direct questions that can be answered with one piece of information you roll this into",
    "start": "1247000",
    "end": "1253159"
  },
  {
    "text": "production and then you find people really ask questions kind of like this they say we have an essay do tomorrow we",
    "start": "1253159",
    "end": "1259200"
  },
  {
    "text": "have to write about some animal I love penguins I could write about them but I could also write about dolphins are they",
    "start": "1259200",
    "end": "1264520"
  },
  {
    "text": "animals maybe let's do dolphins where do they live for example now as a software",
    "start": "1264520",
    "end": "1271240"
  },
  {
    "text": "engineer is it fair for you to take this and throw it at elastic and say deal",
    "start": "1271240",
    "end": "1276960"
  },
  {
    "text": "with this uh it really is is is not and this is one area one of the first ways to",
    "start": "1276960",
    "end": "1283279"
  },
  {
    "text": "improve sort of initial rag systems which is to go through this step called query rewriting",
    "start": "1283279",
    "end": "1289720"
  },
  {
    "text": "and this is an example of how that works so when a language model gets a question like this you can write a query using a",
    "start": "1289720",
    "end": "1296200"
  },
  {
    "text": "language Model A generative language model that says to answer this question this is the query that I need to search",
    "start": "1296200",
    "end": "1301799"
  },
  {
    "text": "for and so to answer this it says okay where do dolphins live it's just extracted that that piece of information",
    "start": "1301799",
    "end": "1307600"
  },
  {
    "text": "and then that is what is relevant for that component which is the search system so now you have you have query",
    "start": "1307600",
    "end": "1314799"
  },
  {
    "text": "rewriting uh as as this step with with a a generation model you can do it with a",
    "start": "1314799",
    "end": "1320760"
  },
  {
    "text": "language model with a prompt but the in the API that we sort of build we have a",
    "start": "1320760",
    "end": "1326000"
  },
  {
    "text": "specific let's say parameter for it that that that we optimize it but you can use it sort of in different ways but this is",
    "start": "1326000",
    "end": "1331440"
  },
  {
    "text": "how it kind of works it outputs the search query and then you can throw it at your search system so now you have a",
    "start": "1331440",
    "end": "1338559"
  },
  {
    "text": "text generation llm in your retrieval step doing that sort of initial rewriting query rewriting set and we'll",
    "start": "1338559",
    "end": "1346760"
  },
  {
    "text": "take it a few steps further because even the the talks later in this uh in this track will you'll see some of the most",
    "start": "1346760",
    "end": "1353760"
  },
  {
    "text": "advanced uses of of llms and we're we're building up to those um step by step now",
    "start": "1353760",
    "end": "1359360"
  },
  {
    "text": "what about a question like this if somebody says can compare the financial results of Nvidia in 2020 versus",
    "start": "1359360",
    "end": "1365039"
  },
  {
    "text": "2023 now you might get this query and",
    "start": "1365039",
    "end": "1370159"
  },
  {
    "text": "you might be able to find a document that already has the information about",
    "start": "1370159",
    "end": "1375480"
  },
  {
    "text": "nvidia's results in 2020 and 2023 but 's a a very good chance that you will not find one single document that does this",
    "start": "1375480",
    "end": "1382799"
  },
  {
    "text": "and so one way to improve that is to say actually to answer this I need two queries I need to search for NVIDIA",
    "start": "1382799",
    "end": "1389760"
  },
  {
    "text": "results 2022 2020 and then 2023 and these are two separate results you get",
    "start": "1389760",
    "end": "1395240"
  },
  {
    "text": "two separate sets of of um results and documents back and then you sort of synthesize them and present them to the",
    "start": "1395240",
    "end": "1401640"
  },
  {
    "text": "model and then that and this is what's called multi-query",
    "start": "1401640",
    "end": "1406600"
  },
  {
    "text": "R another way looking at it is kind of like this so you have the question you send it to the the language model and",
    "start": "1407000",
    "end": "1413400"
  },
  {
    "text": "then the language model says okay I'm going to hit this data source where this data source can be whatever you want it",
    "start": "1413400",
    "end": "1419880"
  },
  {
    "text": "can be the web it can be your notion it can be slack it can be whatever is is sort of relevant for you um and then the",
    "start": "1419880",
    "end": "1425760"
  },
  {
    "text": "information is retrieved and then you have this answering phase where or what's called a grounded generation so",
    "start": "1425760",
    "end": "1432400"
  },
  {
    "text": "this is where you present the model with the document in the context and it's able to sort of answer",
    "start": "1432400",
    "end": "1439640"
  },
  {
    "text": "another optimization for search is what if you build this search system and somebody says hi or hello do you need to",
    "start": "1440880",
    "end": "1448400"
  },
  {
    "text": "really search your database for the model to answer hi or hello or something like that you you really don't and so",
    "start": "1448400",
    "end": "1455159"
  },
  {
    "text": "when you're doing this query rewriting you can build that um awareness in the",
    "start": "1455159",
    "end": "1461039"
  },
  {
    "text": "language model to say I need to search for this or I need to search for these two queries or I do not make I do not",
    "start": "1461039",
    "end": "1467880"
  },
  {
    "text": "need to make search to answer this question and so here you're starting to see the model become a switch or",
    "start": "1467880",
    "end": "1475480"
  },
  {
    "text": "statement or an if else where the model sort of is start starting to be um you know controlling the flow a little bit",
    "start": "1475480",
    "end": "1482159"
  },
  {
    "text": "of how to deal with this uh and so it has a couple of options so it can either search or it can generate directly",
    "start": "1482159",
    "end": "1488279"
  },
  {
    "text": "without without without search as you get more greedy and and",
    "start": "1488279",
    "end": "1494919"
  },
  {
    "text": "comfortable with these with these sort of New Primitives of of using language models you start to say hm okay if I can",
    "start": "1494919",
    "end": "1502720"
  },
  {
    "text": "search One Source why can I not search multiple sources why can't I give the",
    "start": "1502720",
    "end": "1508320"
  },
  {
    "text": "model the ability to search my notion but also you know my Erp or my CRM and",
    "start": "1508320",
    "end": "1515120"
  },
  {
    "text": "later and later model sort of models start to build in these these these",
    "start": "1515120",
    "end": "1520159"
  },
  {
    "text": "capabilities where you can the model can can route it's not necessarily tied to one uh one data",
    "start": "1520159",
    "end": "1527120"
  },
  {
    "text": "source and and this should give you a sense of you know this is a kind of a new way of doing software like it's",
    "start": "1527120",
    "end": "1535000"
  },
  {
    "text": "really different uh when you think about about these things and uh you can take",
    "start": "1535000",
    "end": "1541039"
  },
  {
    "text": "it even in a it can get a little bit more more um complex um let's you have a",
    "start": "1541039",
    "end": "1546720"
  },
  {
    "text": "question like this where you can say you know who are the largest car manufacturers in 2023 do they each make",
    "start": "1546720",
    "end": "1552799"
  },
  {
    "text": "EVS or not you know there probably are not one document uh on the web or anywhere that",
    "start": "1552799",
    "end": "1559320"
  },
  {
    "text": "can answer this question so one thing the llm can do is to say Okay first I",
    "start": "1559320",
    "end": "1564440"
  },
  {
    "text": "will search the web for the largest car manufacturers in 2023 so I need a one",
    "start": "1564440",
    "end": "1569600"
  },
  {
    "text": "piece of information first and then after it gets that piece of information it says ahuh okay now I need to search",
    "start": "1569600",
    "end": "1575919"
  },
  {
    "text": "Toyota electric vehicles Volkswagen electric vehicles Hyundai electric",
    "start": "1575919",
    "end": "1581080"
  },
  {
    "text": "vehicles so the model is now sort of continuing to control the flow of asking",
    "start": "1581080",
    "end": "1586480"
  },
  {
    "text": "follow-up questions and making follow-up searches by itself before outputting the final result and this is what's called",
    "start": "1586480",
    "end": "1593279"
  },
  {
    "text": "multihop rag uh where the model can make multiple jumps and sort of it's",
    "start": "1593279",
    "end": "1598320"
  },
  {
    "text": "determining uh is this enough information or should I sort of go and do something else um",
    "start": "1598320",
    "end": "1605520"
  },
  {
    "text": "to to Pro to produce this this Final Answer let's take one last uh mental",
    "start": "1605520",
    "end": "1613080"
  },
  {
    "text": "jump and to say you know when you search the web or when you search",
    "start": "1613080",
    "end": "1618880"
  },
  {
    "text": "um notion you are kind of invoking a function like this you're saying okay I needed to search notion so call search",
    "start": "1618880",
    "end": "1626960"
  },
  {
    "text": "notion this function and give it these these parameters what now if you have models that are capable enough in doing",
    "start": "1626960",
    "end": "1633760"
  },
  {
    "text": "something like this reliably and accurately enough what is to prevent you from saying okay not only do you search",
    "start": "1633760",
    "end": "1641600"
  },
  {
    "text": "or retrieve information from notion how about you post this to notion so the models are now able to just call apis to",
    "start": "1641600",
    "end": "1649760"
  },
  {
    "text": "actually do things to inject information to interact with with the other systems and make these sort of",
    "start": "1649760",
    "end": "1656640"
  },
  {
    "text": "um interactions and now here you're starting to see this new thing emerge now we're beyond what llms are this is a",
    "start": "1656640",
    "end": "1664320"
  },
  {
    "text": "new thing this is the llm backed agent um and these are some of the most futuristic um things that you can see or",
    "start": "1664320",
    "end": "1671919"
  },
  {
    "text": "think about in llms right now there's a talk in this track about about agents uh",
    "start": "1671919",
    "end": "1677120"
  },
  {
    "text": "it's never too early they will continue to get better um but then now you're",
    "start": "1677120",
    "end": "1682840"
  },
  {
    "text": "having llms as the heart of a piece of software that is able to read and write",
    "start": "1682840",
    "end": "1688760"
  },
  {
    "text": "from multiple sources that is able to use tools so it can use the the the",
    "start": "1688760",
    "end": "1693840"
  },
  {
    "text": "python CLI it can use calculators it can use email it can use other things and so now you have this piece of software that",
    "start": "1693840",
    "end": "1700360"
  },
  {
    "text": "is a little bit more intelligent it sort of is can be connected to different sort of sources um and you're starting to see",
    "start": "1700360",
    "end": "1706799"
  },
  {
    "text": "more and more of what's it what it's able to do and it's it's a important",
    "start": "1706799",
    "end": "1712840"
  },
  {
    "text": "piece of uh place to invest in where things will will go in the future and",
    "start": "1712840",
    "end": "1718080"
  },
  {
    "text": "some of the or a lot of the agents that you see right now are maybe toys or just",
    "start": "1718080",
    "end": "1724480"
  },
  {
    "text": "they show you the potential but it this will take a few a few months or years to sort of",
    "start": "1724480",
    "end": "1730600"
  },
  {
    "text": "um come through but you can already seeing it sort of um showing its potential and solving sort of problems",
    "start": "1730600",
    "end": "1737640"
  },
  {
    "text": "and it's just this extension of if you made the jump from llms to Rag and then",
    "start": "1737640",
    "end": "1743080"
  },
  {
    "text": "from rag to multi uh multi-step in multihop right tool use is the next sort",
    "start": "1743080",
    "end": "1748760"
  },
  {
    "text": "of abstraction because you're using the same thing instead of the the search engine being your tool it's another system where another API or another of",
    "start": "1748760",
    "end": "1756519"
  },
  {
    "text": "software and then we also always advocate for citations so if you can have a system that sort of provides the",
    "start": "1756519",
    "end": "1763559"
  },
  {
    "text": "citations for why it which spans in the text referred to documents uh we need to",
    "start": "1763559",
    "end": "1770320"
  },
  {
    "text": "give our users the ability to verify the model's output not completely trust it um and so citations",
    "start": "1770320",
    "end": "1777760"
  },
  {
    "text": "is as a feature is is highly um recommended let's say in building these",
    "start": "1777760",
    "end": "1783960"
  },
  {
    "text": "systems on the coher side we've built this series of models command R and",
    "start": "1783960",
    "end": "1789159"
  },
  {
    "text": "command R plus we've released the weights you can download them you can run them on your laptop um and they're",
    "start": "1789159",
    "end": "1795559"
  },
  {
    "text": "super optimized for Rag and for all of these use cas cases that we sort of uh talked about they're on hugging face if",
    "start": "1795559",
    "end": "1802000"
  },
  {
    "text": "you have the gpus you can probably run them on CPUs as well but you need a little bit of memory you can download the quantized models um but if you can",
    "start": "1802000",
    "end": "1808880"
  },
  {
    "text": "search Co here on on hugging face you can download these models and sort of start playing with all of these ideas of",
    "start": "1808880",
    "end": "1814640"
  },
  {
    "text": "rag multi-step multihop and the final uh one tool",
    "start": "1814640",
    "end": "1820360"
  },
  {
    "text": "use developers love it so yeah let us know if you interact with it and uh if you have any experiences with it and so",
    "start": "1820360",
    "end": "1827799"
  },
  {
    "text": "now now you have a shape like this where you have retrieval that has three language models in it there's an",
    "start": "1827799",
    "end": "1833559"
  },
  {
    "text": "embedding language model there a ranking language model and there's a generation language model and you know why that",
    "start": "1833559",
    "end": "1839679"
  },
  {
    "text": "generation model is in the search step and then you have this generation uh step that does this grounded generation",
    "start": "1839679",
    "end": "1846559"
  },
  {
    "text": "hopefully with citations that will be useful last note on evaluation so we talked about accuracy so this is from",
    "start": "1846559",
    "end": "1853679"
  },
  {
    "text": "one of the chapters of of of the upcoming book so let's talk about this accuracy metric of of search so you have",
    "start": "1853679",
    "end": "1861080"
  },
  {
    "text": "one query you have two systems that you want to compare the the quality of and from each one you will get three results",
    "start": "1861080",
    "end": "1868720"
  },
  {
    "text": "let's say you have this query and then search system one gives you these results where number one is relevant two",
    "start": "1868720",
    "end": "1874799"
  },
  {
    "text": "is not relevant and three is relevant so two out of three and search system number two gives you two non-relevant uh",
    "start": "1874799",
    "end": "1882279"
  },
  {
    "text": "and results and one relevant who says that search system one is better",
    "start": "1882279",
    "end": "1889360"
  },
  {
    "text": "we have one two three four who says that system two is",
    "start": "1890440",
    "end": "1895799"
  },
  {
    "text": "better have one yeah okay it's maybe five to three so search system one got",
    "start": "1895799",
    "end": "1903279"
  },
  {
    "text": "two out of three correct so that's maybe a two out of three accuracy for this query while one got one out of three",
    "start": "1903279",
    "end": "1909840"
  },
  {
    "text": "accuracy so search system one is is actually better so that's one metric of evaluating search which is accuracy and",
    "start": "1909840",
    "end": "1917960"
  },
  {
    "text": "another one is kind of like this what about both of them got you one but one out of the three as relevant but the",
    "start": "1917960",
    "end": "1924320"
  },
  {
    "text": "first system says placed it right at the top said this is number one and the the",
    "start": "1924320",
    "end": "1929440"
  },
  {
    "text": "second system said this is number three who says system one is better and who says system two is better",
    "start": "1929440",
    "end": "1937679"
  },
  {
    "text": "okay I have a lot more for system one and system one is is is is better because the relevance score the relevant",
    "start": "1937679",
    "end": "1944399"
  },
  {
    "text": "response is is higher rated and so that is there's a another sort of span of of metrics that sort of U and so what this",
    "start": "1944399",
    "end": "1952919"
  },
  {
    "text": "assumes is that you have this that you have a test suite for your data uh and so if you're thinking about building rag",
    "start": "1952919",
    "end": "1959240"
  },
  {
    "text": "systems or evaluating search um systems for for your use case it's good for you to develop something like this",
    "start": "1959240",
    "end": "1965519"
  },
  {
    "text": "internally which is you have your documents and let's say you have a set of queries that are relevant for them",
    "start": "1965519",
    "end": "1972039"
  },
  {
    "text": "and then you have these relevance judgments of is this document relevant for this query or not not uh for for all",
    "start": "1972039",
    "end": "1979600"
  },
  {
    "text": "of them so this is how you would tend to evaluate at least the retrieval step for",
    "start": "1979600",
    "end": "1984720"
  },
  {
    "text": "end to end rag there are other sort of methods but this is what say one way and you can use language models to actually",
    "start": "1984720",
    "end": "1990840"
  },
  {
    "text": "generate the queries for that so um and I hope by now you can think about them",
    "start": "1990840",
    "end": "1996559"
  },
  {
    "text": "as just these multi-pro solving tools um and this builds up to this metric uh",
    "start": "1996559",
    "end": "2002000"
  },
  {
    "text": "called mean average Precision which is one of the metrics that you can use for uh for search that thinks about the",
    "start": "2002000",
    "end": "2008279"
  },
  {
    "text": "scores and and the ranking so in summary if I want you to",
    "start": "2008279",
    "end": "2013440"
  },
  {
    "text": "take away two things out of this I would say one large language models are not this black box of text in text out they",
    "start": "2013440",
    "end": "2020919"
  },
  {
    "text": "are a a collection of tools in your grasp we talked about so many of these",
    "start": "2020919",
    "end": "2027399"
  },
  {
    "text": "ways to make them useful for embedding for search for classification for retrieval for generation for query",
    "start": "2027399",
    "end": "2034440"
  },
  {
    "text": "rewriting and so think of them as just this new class of software that you're able to build with and then this idea of",
    "start": "2034440",
    "end": "2041320"
  },
  {
    "text": "this new form that they're taking this new also class of software which is the the llm backed agent that is able to",
    "start": "2041320",
    "end": "2048720"
  },
  {
    "text": "communicate with external data sources and um tools and use them a little bit",
    "start": "2048720",
    "end": "2054118"
  },
  {
    "text": "more successive successfully and in successive",
    "start": "2054119",
    "end": "2060240"
  },
  {
    "text": "steps uh we have a guide on how to build something that build plugs all of these",
    "start": "2060240",
    "end": "2065638"
  },
  {
    "text": "uh tools together you can just search rag chatbot on on on on the blog we have",
    "start": "2065639",
    "end": "2071520"
  },
  {
    "text": "a resource called lm. University it's uh you I saw people missed that the",
    "start": "2071520",
    "end": "2078358"
  },
  {
    "text": "previous one that wanted to take a photo but this is the the rag um",
    "start": "2078359",
    "end": "2084679"
  },
  {
    "text": "chatbot we have a resource called lm. University uh where we have about seven",
    "start": "2084679",
    "end": "2090240"
  },
  {
    "text": "or eight modules uh about lessons very highly accessible uh very visual with",
    "start": "2090240",
    "end": "2096480"
  },
  {
    "text": "videos and a lot of them it's completely free you don't need to sign up uh just go to lm. university and start browsing",
    "start": "2096480",
    "end": "2102800"
  },
  {
    "text": "and let us know if you have any questions or if we can make it sort of any more useful for you that is the end",
    "start": "2102800",
    "end": "2108240"
  },
  {
    "text": "of my talk thank you so much please vote and [Applause]",
    "start": "2108240",
    "end": "2118760"
  },
  {
    "text": "feedback thank you Jay um we have about 10 minutes for Q&A so think about your",
    "start": "2118760",
    "end": "2124680"
  },
  {
    "text": "questions there's some Volunteers in the back's going to raise your hand and then they'll or mik will get to you shortly",
    "start": "2124680",
    "end": "2131520"
  },
  {
    "text": "but I'm going to start question for Jay and then we'll go from there uh given your experience in all these areas and",
    "start": "2131520",
    "end": "2138920"
  },
  {
    "text": "uh working with RS and such it's it's not an easy it's not easy to build R based systems in an Enterprise grade",
    "start": "2138920",
    "end": "2146480"
  },
  {
    "text": "level what have you seen as some of like best practices and pitps that that companies or folks have run into yeah so",
    "start": "2146480",
    "end": "2154960"
  },
  {
    "text": "the earlier you invest the better because there is definitely a lot of learning that goes into into into",
    "start": "2154960",
    "end": "2160000"
  },
  {
    "text": "building these systems and so having the people uh who experiment with these internally and sort of realize very",
    "start": "2160000",
    "end": "2166280"
  },
  {
    "text": "quickly or very early their failure points uh is is important to sort of to",
    "start": "2166280",
    "end": "2171800"
  },
  {
    "text": "sort of build continually a few concrete things are yes embeddings are great but",
    "start": "2171800",
    "end": "2178680"
  },
  {
    "text": "it's probably even better to have a hybrid search system where you're doing both keyword and embeddings at the same time uh so you shouldn't just rely on",
    "start": "2178680",
    "end": "2185880"
  },
  {
    "text": "one of these methods uh and then with all s systems you can also inject other signals into that that that that would",
    "start": "2185880",
    "end": "2191359"
  },
  {
    "text": "be sort of relevant um having I really love software testing and let's say unit",
    "start": "2191359",
    "end": "2198640"
  },
  {
    "text": "tests I think we should do a lot more of that in in in machine learning and so if you have some of that as a cache of",
    "start": "2198640",
    "end": "2205319"
  },
  {
    "text": "tests that are relevant for you as as behaviors because even when you're using um you know managed language models",
    "start": "2205319",
    "end": "2212319"
  },
  {
    "text": "their behavior might change with the next version and the next version and so you need to bring these these solid",
    "start": "2212319",
    "end": "2219000"
  },
  {
    "text": "software um methodologies of doing you know can you can you catch a regression",
    "start": "2219000",
    "end": "2224400"
  },
  {
    "text": "in one Behavior or or another and so building those those solid software",
    "start": "2224400",
    "end": "2229839"
  },
  {
    "text": "engineering practices into machine learning is something that people in AI should should be doing a lot",
    "start": "2229839",
    "end": "2236440"
  },
  {
    "text": "more yeah makes a lot of sense so yeah if you have a question raise your hand I Know M will come to you which SL",
    "start": "2236440",
    "end": "2243920"
  },
  {
    "text": "to uh thanks you for your talk was incredible um the the multi rag hop do",
    "start": "2246319",
    "end": "2253760"
  },
  {
    "text": "you think that it's relevant to incorporate that into the first classification uh call that you talked",
    "start": "2253760",
    "end": "2259880"
  },
  {
    "text": "about you know the rewrite plus the the skip or because it sounds very beefy to",
    "start": "2259880",
    "end": "2266400"
  },
  {
    "text": "to for the model to understand it's actually a flow is needed so would you separate that out or how how would you",
    "start": "2266400",
    "end": "2272200"
  },
  {
    "text": "tackle that so in like in machine learning most answers are it depends",
    "start": "2272200",
    "end": "2278599"
  },
  {
    "text": "for if you're doing a highly latent latency sensitive system",
    "start": "2278599",
    "end": "2285280"
  },
  {
    "text": "the query rewriting needs to be sort of the fastest that you can be and so if if that is I think you should just measure",
    "start": "2285280",
    "end": "2292800"
  },
  {
    "text": "how latent latency sensitive the use case is and then go on that and if it's highly latency sensitive you might go",
    "start": "2292800",
    "end": "2299839"
  },
  {
    "text": "with a smaller model for the first sort of step and then for the",
    "start": "2299839",
    "end": "2305119"
  },
  {
    "text": "U the multi-step like you call it when when you need it so but the entire ethos",
    "start": "2305119",
    "end": "2311119"
  },
  {
    "text": "of this is to use the best tool for each each thing and not throw everything at a massive model that can do everything but",
    "start": "2311119",
    "end": "2318200"
  },
  {
    "text": "can do it very expensively it will need so many gpus so yes always advocating",
    "start": "2318200",
    "end": "2323800"
  },
  {
    "text": "let's say using the smallest types of model that is capable to to to solve the",
    "start": "2323800",
    "end": "2328920"
  },
  {
    "text": "test",
    "start": "2328920",
    "end": "2331920"
  },
  {
    "text": "thanks again it's great talk um what's your favorite framework because there's quite a few Frameworks out there at the",
    "start": "2337839",
    "end": "2343720"
  },
  {
    "text": "moment and I'm going from one to the other to the other making qus everywh",
    "start": "2343720",
    "end": "2348839"
  },
  {
    "text": "yes um I'm in the same uh I'm always trying different sort of uh Frameworks I",
    "start": "2348839",
    "end": "2355319"
  },
  {
    "text": "cannot necessarily recommend anyone right now like we're working a little bit with Lang chain because Lang chain",
    "start": "2355319",
    "end": "2361640"
  },
  {
    "text": "started soon and just makes it convenient for people to get started with it but I also would like to do a",
    "start": "2361640",
    "end": "2367440"
  },
  {
    "text": "lot of my work in just you know python strings and just call the apis and sort of build those things so the the",
    "start": "2367440",
    "end": "2373680"
  },
  {
    "text": "Frameworks might just make it easier for you to download a template play around with it see where it breaks but don't",
    "start": "2373680",
    "end": "2379119"
  },
  {
    "text": "always think that it will take you all the way to to production because it will not always do that but as long as it",
    "start": "2379119",
    "end": "2384599"
  },
  {
    "text": "helped you sort of get your hands uh dirty and sort of play with the with their convenient to to learn with but",
    "start": "2384599",
    "end": "2391839"
  },
  {
    "text": "it's a still very volatile there's so much development very quickly that is happening in I wouldn't say there's a",
    "start": "2391839",
    "end": "2398640"
  },
  {
    "text": "sort of major dominant ones you know Lang chain has made made its name but there continues to be newer and newer",
    "start": "2398640",
    "end": "2405640"
  },
  {
    "text": "let's say models that uh Frameworks that specialize in the different use cases I would say",
    "start": "2405640",
    "end": "2412560"
  },
  {
    "text": "that question gentlemen here as well oh here yeah hi so I have a question of",
    "start": "2412560",
    "end": "2419440"
  },
  {
    "text": "definitions uh one year ago when I learned about language models it was quite mentally easy for me to picture",
    "start": "2419440",
    "end": "2425119"
  },
  {
    "text": "that they were taught with text masses and and were able to answer questions and so on nowadays there's these agents",
    "start": "2425119",
    "end": "2432119"
  },
  {
    "text": "and and all that control logic that you were also talking about about splitting questions and so on so what's your",
    "start": "2432119",
    "end": "2437760"
  },
  {
    "text": "definition of a language model Does it include all that control logic and stuff like that what what do you think yeah",
    "start": "2437760",
    "end": "2445079"
  },
  {
    "text": "yeah know that is a a great thing because even before large language models became language model is is a",
    "start": "2445079",
    "end": "2450760"
  },
  {
    "text": "very well defined let's say system in in statistics which is a system that is able to predict the next word",
    "start": "2450760",
    "end": "2456680"
  },
  {
    "text": "successfully that is the language modeling objective of even how these models are created in the first first",
    "start": "2456680",
    "end": "2461920"
  },
  {
    "text": "step but what we found out recently is that if you train a large enough language model and a large enough and",
    "start": "2461920",
    "end": "2468680"
  },
  {
    "text": "clean enough data set it captures behaviors that really surprise you and so if you've trained it on a data set",
    "start": "2468680",
    "end": "2474359"
  },
  {
    "text": "that has a lot of factual information the model will not only pick up language it will pick up facts if you train it on",
    "start": "2474359",
    "end": "2480839"
  },
  {
    "text": "a lot of code and give it the right tokenization it's going to be able to generate code and so it becomes this the",
    "start": "2480839",
    "end": "2487319"
  },
  {
    "text": "these new sort of capabilities based on how you you train it and how you clean the data and how you sort of you",
    "start": "2487319",
    "end": "2492440"
  },
  {
    "text": "optimize for it it becomes a general problemsolving piece of software that is sort of able to to stretch the",
    "start": "2492440",
    "end": "2499200"
  },
  {
    "text": "imagination and uh do more things than just generate coherent language or text",
    "start": "2499200",
    "end": "2506119"
  },
  {
    "text": "so yeah the nature of of language mods is is",
    "start": "2506119",
    "end": "2510400"
  },
  {
    "text": "fascinating thanks for the thanks for the talk um",
    "start": "2513359",
    "end": "2518960"
  },
  {
    "text": "it is now there we go thanks for the talk Jay um you mentioned pitfalls especially when people are initially",
    "start": "2518960",
    "end": "2525280"
  },
  {
    "text": "playing with these kind of systems um what's one that you think you would call out that people could keep eyes open",
    "start": "2525280",
    "end": "2530640"
  },
  {
    "text": "before they play What's the one that you see as most common to people Pitfall or limitation that it would be nice to know",
    "start": "2530640",
    "end": "2536680"
  },
  {
    "text": "about beforehand yeah look over overly trusting the the model and this is you know a punishment that we get by making",
    "start": "2536680",
    "end": "2543280"
  },
  {
    "text": "models that are so good once models became let's say not gibberish uh",
    "start": "2543280",
    "end": "2549200"
  },
  {
    "text": "creators people started to give them more Authority than than they should and so that nature um of it is is is a",
    "start": "2549200",
    "end": "2557040"
  },
  {
    "text": "little different and that trust in companies or in in people who are new in let's say making applications for it can",
    "start": "2557040",
    "end": "2563559"
  },
  {
    "text": "say okay I can interact with this system on this website let me take that same",
    "start": "2563559",
    "end": "2569319"
  },
  {
    "text": "system and make it a chatbot on myb public website to sort of talk with the world and you know some companies have",
    "start": "2569319",
    "end": "2574880"
  },
  {
    "text": "have you know fallen into into uh and so over trusting in in in you know these",
    "start": "2574880",
    "end": "2581160"
  },
  {
    "text": "probabilistic systems without guard rails without sort of the domain knowledge of uh so yeah just",
    "start": "2581160",
    "end": "2587240"
  },
  {
    "text": "being cyber security gives you a lot of paranoia because you need to think about the the different ways where your system",
    "start": "2587240",
    "end": "2593839"
  },
  {
    "text": "can be broken I think we need a lot more of that in in deployment",
    "start": "2593839",
    "end": "2599319"
  },
  {
    "text": "of yeah thanks um and to follow up on that question Jay these models are probabilistic they're not deterministic",
    "start": "2601680",
    "end": "2608440"
  },
  {
    "text": "right so if that's the cas would you ever put them closer to your systems of record with that diagram you showed of",
    "start": "2608440",
    "end": "2614480"
  },
  {
    "text": "them interacting with the world and more more uh apis and plugins would you ever",
    "start": "2614480",
    "end": "2619599"
  },
  {
    "text": "put them closer to systems of record and how long before you think that's possible or feasible yeah I mean it depends on the use case really uh there",
    "start": "2619599",
    "end": "2625839"
  },
  {
    "text": "are a lot of use cases where they are ready now so if you're doing things that are for example recommendations to an",
    "start": "2625839",
    "end": "2632559"
  },
  {
    "text": "expert that can sort of spot the failure modes or if you have the correct guard",
    "start": "2632559",
    "end": "2637800"
  },
  {
    "text": "rails you know it's supposed to Output to Json you know can you check is it valid Json or not so the more let's say",
    "start": "2637800",
    "end": "2645760"
  },
  {
    "text": "you build these actual practices of of of that domain yes they can solve a lot of problems right now but then the more",
    "start": "2645760",
    "end": "2653319"
  },
  {
    "text": "high risk the the use case is the more care and attention that needs to be there the more we need to think about",
    "start": "2653319",
    "end": "2658720"
  },
  {
    "text": "humans in the loop and sort of safe deployment uh options and so yeah it",
    "start": "2658720",
    "end": "2664640"
  },
  {
    "text": "depends really on on on the use case and we know a lot of tools that increase the probability of of of success um there",
    "start": "2664640",
    "end": "2671839"
  },
  {
    "text": "are things like majority voting for example you have a model up with a you know the response three or five times",
    "start": "2671839",
    "end": "2679119"
  },
  {
    "text": "and seeing do they agree with each other or not um so there are tools of",
    "start": "2679119",
    "end": "2684599"
  },
  {
    "text": "improving that but you as the Creator have the responsibility of setting that threshold and having enough let's say of",
    "start": "2684599",
    "end": "2691599"
  },
  {
    "text": "guard rails to to make sure that you get the the the response and the result and the behavior that that your system some",
    "start": "2691599",
    "end": "2699000"
  },
  {
    "text": "Ms with that we out of time so thanks for attending and let's give Jay an awesome",
    "start": "2699000",
    "end": "2706079"
  },
  {
    "text": "[Music]",
    "start": "2707880",
    "end": "2713328"
  }
]
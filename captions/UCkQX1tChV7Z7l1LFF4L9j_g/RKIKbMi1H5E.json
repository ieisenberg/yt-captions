[
  {
    "start": "0",
    "end": "137000"
  },
  {
    "text": "so thank you all for coming um how many of you here actually are doing any kind of stream processing in your in your",
    "start": "4480",
    "end": "10120"
  },
  {
    "text": "company oh that's great anyone using Flink",
    "start": "10120",
    "end": "15720"
  },
  {
    "text": "spark any of the other famous popular favorite engines oh a few hands okay um",
    "start": "15720",
    "end": "24359"
  },
  {
    "text": "so I think as any domain matures over time uh patterns emerge and we all know",
    "start": "24359",
    "end": "30400"
  },
  {
    "text": "how useful patterns are uh and I think with stream processing it's the same thing uh the domain has been maturing uh",
    "start": "30400",
    "end": "37719"
  },
  {
    "text": "we've been building different applications and patterns have come out of it and internally at Netflix we've been using these names for these",
    "start": "37719",
    "end": "44079"
  },
  {
    "text": "patterns for some of them and uh for the others uh I'm trying to give them names",
    "start": "44079",
    "end": "50360"
  },
  {
    "text": "and naming is really hard so if you don't like them I may not be able to appease everyone with the names but I",
    "start": "50360",
    "end": "56120"
  },
  {
    "text": "have to start somewhere so um in this session I want to kind of begin that conversation with the community to uh",
    "start": "56120",
    "end": "63120"
  },
  {
    "text": "discuss these patterns uh so that we can have a meaningful conversation about it so I've been uh building stream",
    "start": "63120",
    "end": "71759"
  },
  {
    "text": "processing applications in the platform for past four years on Netflix and I've",
    "start": "71759",
    "end": "76799"
  },
  {
    "text": "helped Drive the technical Vision road map and the implementation of it and uh today I'm going to distill my experience",
    "start": "76799",
    "end": "83560"
  },
  {
    "text": "over the four years to kind of uh talk to you about uh eight patterns why do we",
    "start": "83560",
    "end": "89320"
  },
  {
    "text": "think stream processing is useful for us and I'll provide some background material so that if you're new to the",
    "start": "89320",
    "end": "95079"
  },
  {
    "text": "space uh some of the patterns and things that we discuss actually um tie things",
    "start": "95079",
    "end": "100360"
  },
  {
    "text": "together and you have enough context for it so in the spirit of any movie that's",
    "start": "100360",
    "end": "106479"
  },
  {
    "text": "based on or documentary that's based on true events the stock is inspired by true events have to provide a disclaimer",
    "start": "106479",
    "end": "113280"
  },
  {
    "text": "um unfortunately I don't have a baritone Voice or I don't work for an ad company that sells pharmaceutical drugs so I",
    "start": "113280",
    "end": "120039"
  },
  {
    "text": "don't have a really cool audio for you but imagine there's one right uh so I did change some code around so I some",
    "start": "120039",
    "end": "127159"
  },
  {
    "text": "identifying information uh so that I can uh avoid the Privacy issue of People",
    "start": "127159",
    "end": "134280"
  },
  {
    "text": "code and applications involved so um what is stream processing",
    "start": "134280",
    "end": "140640"
  },
  {
    "start": "137000",
    "end": "369000"
  },
  {
    "text": "right the very essence of it is you just processing events as they arrive or as",
    "start": "140640",
    "end": "146720"
  },
  {
    "text": "they're produced so basically it's nothing but processing data in motion",
    "start": "146720",
    "end": "152040"
  },
  {
    "text": "right so let's take a u real world",
    "start": "152040",
    "end": "157080"
  },
  {
    "text": "example so this is a homepage you might have visited on Netflix and um the user",
    "start": "157080",
    "end": "163519"
  },
  {
    "text": "kind of browses around and then picks a movie right to watch uh a whole bunch of events were generated behind the scenes",
    "start": "163519",
    "end": "170040"
  },
  {
    "text": "that you didn't know about so that we can provide users a really rich uh personalized experience and we have over",
    "start": "170040",
    "end": "176640"
  },
  {
    "text": "130 million members so we want to provide every one of them a unique experience when they come to the site",
    "start": "176640",
    "end": "182440"
  },
  {
    "text": "and if you look at uh one of the homepages you'll see this row called trending row now this provides",
    "start": "182440",
    "end": "190480"
  },
  {
    "text": "you member specific personalization of what's happening right now in Netflix so",
    "start": "190480",
    "end": "196080"
  },
  {
    "text": "it's not just a most recent across all members it's most recent across all members specific to your account and",
    "start": "196080",
    "end": "203480"
  },
  {
    "text": "profile right if you have a Netflix account you'd know that you you can have up to five different profiles so each",
    "start": "203480",
    "end": "209400"
  },
  {
    "text": "profile is personalized and this row is personalized for each user so getting lower latency uh",
    "start": "209400",
    "end": "217959"
  },
  {
    "text": "analytics and metrics is useful and that's where uh one of the applications of stream processing is the next one is",
    "start": "217959",
    "end": "225200"
  },
  {
    "text": "if you're trying to uh understand user sessions maybe they're searching or uh",
    "start": "225200",
    "end": "230760"
  },
  {
    "text": "maybe they're creating uh certain experiences and you want to know what happens in in the",
    "start": "230760",
    "end": "237280"
  },
  {
    "text": "batch world you usually have fixed batches and you try of identify sessions that happen during those batches and a",
    "start": "237280",
    "end": "244280"
  },
  {
    "text": "problem with that is you might identify a session that was close enough and have those two events as two separate",
    "start": "244280",
    "end": "250480"
  },
  {
    "text": "sessions and you may say well I can fix this I can go in and kind of scan the next batch and see uh figure out where",
    "start": "250480",
    "end": "257120"
  },
  {
    "text": "the session joins in but it's a lot of cumbersome work and the tools kind of out of the box don't really support it",
    "start": "257120",
    "end": "262479"
  },
  {
    "text": "really nicely uh and what exactly actually you want is you want these two",
    "start": "262479",
    "end": "268080"
  },
  {
    "text": "events to be part of the same session so with stream processing something happened to the",
    "start": "268080",
    "end": "274520"
  },
  {
    "text": "slide but let's see if I can fix it there we go so um in stream processing as we are",
    "start": "274520",
    "end": "281479"
  },
  {
    "text": "processing events we are able to aggregate them into sessions right and so when you're processing unbounded",
    "start": "281479",
    "end": "288800"
  },
  {
    "text": "streams and trying to suiz them stream processing kind of is the more natural",
    "start": "288800",
    "end": "294479"
  },
  {
    "text": "intuitive model to do and Stitch these sessions together so a couple more things why",
    "start": "294479",
    "end": "300720"
  },
  {
    "text": "stream processing at a high level is as the data arrives uh from the website from the devices that you're playing",
    "start": "300720",
    "end": "306960"
  },
  {
    "text": "there's tons of metrics that are being generated events that are being generated we want to clean the data we may want to enhance it and then we want",
    "start": "306960",
    "end": "313479"
  },
  {
    "text": "to send this data to elastic search high or other stream processing applications Downstream so we want to eal the data as",
    "start": "313479",
    "end": "320160"
  },
  {
    "text": "it arrives so that we don't have to drop it read it again and then massage it and clean it up again uh the other area",
    "start": "320160",
    "end": "326440"
  },
  {
    "text": "where you can leverage stream processing is not just for adoc anal itics you can actually use it for building event",
    "start": "326440",
    "end": "333000"
  },
  {
    "text": "driven applications because at the core of it if you think about it both of them are actually processing events and we'll",
    "start": "333000",
    "end": "339120"
  },
  {
    "text": "look at a uh actual example of where we have actually used it for event driven applications as well uh the other",
    "start": "339120",
    "end": "346639"
  },
  {
    "text": "interesting thing about stream processing is actually turns the database Paradigm reversed so in the",
    "start": "346639",
    "end": "352840"
  },
  {
    "text": "database world you take all your data you shove it in and then you run queries and other analysis on it right and",
    "start": "352840",
    "end": "358639"
  },
  {
    "text": "stream processing you the queries as the data is flowing in and then you generate meaningful results and you store it in",
    "start": "358639",
    "end": "364319"
  },
  {
    "text": "the database so it kind of slightly reverses what's happening in a",
    "start": "364319",
    "end": "369560"
  },
  {
    "start": "369000",
    "end": "432000"
  },
  {
    "text": "database so uh now I'm going to provide some background and set the stage uh so",
    "start": "369560",
    "end": "376759"
  },
  {
    "text": "that we have enough information uh to uh support the discussion on patterns and",
    "start": "376759",
    "end": "382000"
  },
  {
    "text": "streaming applications so we'll look at the high level architecture of what most streaming application looks like right",
    "start": "382000",
    "end": "388199"
  },
  {
    "text": "it's it's pretty simple then ,000 foot view you have a source you do some meaningful processing and you shove the",
    "start": "388199",
    "end": "393759"
  },
  {
    "text": "data uh to the sync a little more interesting you may have multiple sources that you're joining across and",
    "start": "393759",
    "end": "399639"
  },
  {
    "text": "you may be Fanning out to multiple syns in addition as the events are flowing through you may be enriching them with",
    "start": "399639",
    "end": "405880"
  },
  {
    "text": "data from other services or other lookup data so for example if you get a click",
    "start": "405880",
    "end": "411039"
  },
  {
    "text": "event you may want to find out which GE region this was clicked in maybe there's a service you call into you want to find",
    "start": "411039",
    "end": "417120"
  },
  {
    "text": "out what additional movie metadata was there so that you can denormalize the event and then send it to your data warehouse so that you have a event",
    "start": "417120",
    "end": "424280"
  },
  {
    "text": "that's prepared and ready for analysis so we'll look at an example also and a pattern that's related to side inputs",
    "start": "424280",
    "end": "430759"
  },
  {
    "text": "and what it entails so um why did we actually uh",
    "start": "430759",
    "end": "436120"
  },
  {
    "start": "432000",
    "end": "503000"
  },
  {
    "text": "choose fling for our stream processing engine uh so we'll this section will kind of give you a high level overview",
    "start": "436120",
    "end": "442400"
  },
  {
    "text": "and if you're new to Flink also a primer of how things work so let's start with code right",
    "start": "442400",
    "end": "449560"
  },
  {
    "text": "right I mean it's pretty straightforward when we look at the architecture we can map the different areas here so if you",
    "start": "449560",
    "end": "455120"
  },
  {
    "text": "look here we have the source and here's the code on the line for the source",
    "start": "455120",
    "end": "461039"
  },
  {
    "text": "right and then we have a couple of Transformations on the bottom of it",
    "start": "461039",
    "end": "466599"
  },
  {
    "text": "and if you look here we just cleaning the line up parsing the line and then we",
    "start": "466599",
    "end": "472159"
  },
  {
    "text": "do three simple operations it's kind of like doing a group buy and we're doing window that's we grouping into buckets",
    "start": "472159",
    "end": "478879"
  },
  {
    "text": "because we want do some meaningful metrics on it analytics on it like zcore",
    "start": "478879",
    "end": "484400"
  },
  {
    "text": "or deviation or as simple as a count and then we want to send those results to some sync right to be useful so there's",
    "start": "484400",
    "end": "491680"
  },
  {
    "text": "a source there's a transformation and there's a sync so in effect it's streaming data flows it's streams and a",
    "start": "491680",
    "end": "497520"
  },
  {
    "text": "bunch of operators transformation operators combin together to uh process these",
    "start": "497520",
    "end": "503720"
  },
  {
    "start": "503000",
    "end": "911000"
  },
  {
    "text": "data and um if you're new to window it's nothing but just grouping or batching",
    "start": "503720",
    "end": "510080"
  },
  {
    "text": "group of events so that you can run meaningful um metrics on it or comp computation on",
    "start": "510080",
    "end": "517159"
  },
  {
    "text": "it so that code what Flink does is it takes that code and splits it up into",
    "start": "517159",
    "end": "523159"
  },
  {
    "text": "these operators and it creates a dag out of it um now it does support some kind of iterations and Cycles but we'll not",
    "start": "523159",
    "end": "529160"
  },
  {
    "text": "get into it for now let's just assume it's a AC click graph of operators so in this case we have a source we have a map",
    "start": "529160",
    "end": "535600"
  },
  {
    "text": "where we took the line and parsed the line and then we did a bunch of operators operations like Key by window",
    "start": "535600",
    "end": "542399"
  },
  {
    "text": "and apply now if you look at the Key by window and apply they're efficiently grouped together and they run as uh one",
    "start": "542399",
    "end": "549800"
  },
  {
    "text": "execution unit in a um single process the reason Flink does that is it tries",
    "start": "549800",
    "end": "554959"
  },
  {
    "text": "to avoid Network hops when it knows that operations can be chained together so it's doing some smart chaining here for",
    "start": "554959",
    "end": "561760"
  },
  {
    "text": "us uh without us having to tell it and then uh the way this get actually",
    "start": "561760",
    "end": "567079"
  },
  {
    "text": "deployed on a set of processes is uh Flink has a very similar model to spark",
    "start": "567079",
    "end": "572360"
  },
  {
    "text": "streaming where you have a coordinator process and you have a bunch of Slayer processes the coordinator process",
    "start": "572360",
    "end": "577959"
  },
  {
    "text": "decides what task is running on what it's responsible for fall tolerance and",
    "start": "577959",
    "end": "583000"
  },
  {
    "text": "making sure when a task manager goes when a replacement comes it becomes part of the whole job again and here if you",
    "start": "583000",
    "end": "590240"
  },
  {
    "text": "look at the the task manager process we have the source and map operators and",
    "start": "590240",
    "end": "597600"
  },
  {
    "text": "then we have a keyby and a sync each task Lots think about it host a operator that needs to be run and it's a single",
    "start": "597600",
    "end": "604079"
  },
  {
    "text": "thread uh each task slot so Flink gives you this outof the boox mechanism of",
    "start": "604079",
    "end": "609600"
  },
  {
    "text": "taking a very simple code getting making a graph of operators out of it deploying",
    "start": "609600",
    "end": "616279"
  },
  {
    "text": "it onto a um set of processes and then giving you a fault or and processing",
    "start": "616279",
    "end": "622360"
  },
  {
    "text": "mechanism out of the box so in this case we have a sync parallelism of one you'll only see one sync operator with the",
    "start": "622360",
    "end": "629000"
  },
  {
    "text": "other operators we said we want a parallelism of two so there'll be two instances of each running so it also lets you control the parallelism and and",
    "start": "629000",
    "end": "636760"
  },
  {
    "text": "the concurrency of different tasks that are running and all it takes is a couple lines of code to tweak that if you need",
    "start": "636760",
    "end": "643399"
  },
  {
    "text": "to so you can take this set of processes and it's agnostic so you could deploy it",
    "start": "643399",
    "end": "649200"
  },
  {
    "text": "on bare metal uh we do development on our laptops we take the same thing build a Docker container out of it and then we",
    "start": "649200",
    "end": "655480"
  },
  {
    "text": "deploy it onto a runtime we could do the same thing and deploy it onto ec2 to deploy it onto VMS and so there's a very",
    "start": "655480",
    "end": "662200"
  },
  {
    "text": "flexible model out of the box to deploy onto different uh Target run",
    "start": "662200",
    "end": "668279"
  },
  {
    "text": "times uh the other notion within uh Flink is the support for stateful and stateless processing now when we talk",
    "start": "668279",
    "end": "675399"
  },
  {
    "text": "about stateless processing what we are saying is as those events flow through the system uh the application is just",
    "start": "675399",
    "end": "682120"
  },
  {
    "text": "processing one event at a time and then it's not storing any um State between",
    "start": "682120",
    "end": "689440"
  },
  {
    "text": "events right so for example if you're just taking an event and either you're enriching it or cleaning it and then",
    "start": "689440",
    "end": "696880"
  },
  {
    "text": "moving it forward now stateful is very",
    "start": "696880",
    "end": "702120"
  },
  {
    "text": "interesting uh let's take a look at a quick animation to see what's happening and then I'll add a little more color to",
    "start": "702120",
    "end": "707200"
  },
  {
    "text": "it so on the left we have these um Source producers or producers that actually produce events right and then",
    "start": "707200",
    "end": "713720"
  },
  {
    "text": "they end up going into a Kafka topic the reason we use Kafka is we want a person",
    "start": "713720",
    "end": "719240"
  },
  {
    "text": "assistant buffer for a short period of time so that if our services are down or if our stream processing jobs are down",
    "start": "719240",
    "end": "726000"
  },
  {
    "text": "we have uh availability of the messages and we can process it so that we can at",
    "start": "726000",
    "end": "731040"
  },
  {
    "text": "least guarantee processing this messages at least once that is we try our best effort that every event that we get",
    "start": "731040",
    "end": "736920"
  },
  {
    "text": "we're going to process it at least once and so Kafka kind of helps us do that and then we have a stream uh streaming",
    "start": "736920",
    "end": "744480"
  },
  {
    "text": "application which is the three processes I showed you it could be many more slaves and then we'll look at what's happening to State as the events get",
    "start": "744480",
    "end": "751560"
  },
  {
    "text": "processed so we have an event that comes gets into Kafka and then it's pulled into the task manager and one of the",
    "start": "751560",
    "end": "758760"
  },
  {
    "text": "slots there processed the event made some transformations of it and then it automatically got stored into local",
    "start": "758760",
    "end": "764920"
  },
  {
    "text": "state uh so Flink out of the box provides mechanism to store State locally and that's what is being uh used",
    "start": "764920",
    "end": "772920"
  },
  {
    "text": "here and then this state is either available in memory you can configure it to do so or you can have it backed by",
    "start": "772920",
    "end": "780839"
  },
  {
    "text": "local disc which uses Rox DB uh back storage mechanism uh so it gives you a",
    "start": "780839",
    "end": "786920"
  },
  {
    "text": "flexibility of how you want to actually store the state and it's just a configuration option you don't have to",
    "start": "786920",
    "end": "792079"
  },
  {
    "text": "worry about it now Flink also gives you something called checkpointing so",
    "start": "792079",
    "end": "797240"
  },
  {
    "text": "periodically it takes asynchronous checkpoints uh so that it can save the state of the application itself so you",
    "start": "797240",
    "end": "805240"
  },
  {
    "text": "can say every 10 seconds capture my state back it off to a secondary storage we actually store it on S3 by default",
    "start": "805240",
    "end": "811959"
  },
  {
    "text": "and then that storage is supported hdfs is supported and so when there's a failure it'll actually rewind the state",
    "start": "811959",
    "end": "818959"
  },
  {
    "text": "back to the last non good checkpoint and because with the checkpoint it also saves the offset in Kafka so offset is",
    "start": "818959",
    "end": "825399"
  },
  {
    "text": "nothing but a pointer in Kafka which tells you which was the last message you read you can actually resurrect your job",
    "start": "825399",
    "end": "831120"
  },
  {
    "text": "to begin the state where left off and so this is pretty powerful because now this lets you uh provide exactly one",
    "start": "831120",
    "end": "837600"
  },
  {
    "text": "semantics within the streaming application so for example if you're doing counts and you're have four",
    "start": "837600",
    "end": "842839"
  },
  {
    "text": "messages and all of one is adding two and then you're adding two again you're adding two again and then you're adding",
    "start": "842839",
    "end": "848000"
  },
  {
    "text": "five right you'd expect the answer to be 11 regardless of failures within the realm of the application so that's what",
    "start": "848000",
    "end": "854399"
  },
  {
    "text": "fling kind of guarantees you'll actually get 11 regardless of how many failures you have because a checkpoint State um",
    "start": "854399",
    "end": "861320"
  },
  {
    "text": "another cool feature is you can actually explicitly take save points so this is a",
    "start": "861320",
    "end": "866519"
  },
  {
    "text": "consistent snapshot of the state and you can take the state and then run another version of your application on it as",
    "start": "866519",
    "end": "872720"
  },
  {
    "text": "long as it's compatible with the state dag that was built or the job dag that was",
    "start": "872720",
    "end": "878600"
  },
  {
    "text": "built and uh this lets you do some really cool things uh the closest thing",
    "start": "878600",
    "end": "884399"
  },
  {
    "text": "you can think about is think about good branches right when you Branch off you can do something with that state your",
    "start": "884399",
    "end": "889800"
  },
  {
    "text": "original state is safe so save points lets you do a lot of that it also lets you take a save point and scale up your",
    "start": "889800",
    "end": "896360"
  },
  {
    "text": "job so that you can scale it up to a much larger state or you can do AB testing on it or you can try out a new",
    "start": "896360",
    "end": "902040"
  },
  {
    "text": "algorithm on the state and see how it's going to behave before you deploy it and run canaries on it so there's a lot of",
    "start": "902040",
    "end": "907399"
  },
  {
    "text": "possibilities the way you can use save points and leverage them um at the API from the API",
    "start": "907399",
    "end": "915320"
  },
  {
    "text": "perspective Flink offers different levels of um uh abstraction uh at the",
    "start": "915320",
    "end": "921000"
  },
  {
    "text": "most easiest level on the top they have SQL um the SQL is streaming SQL and it's",
    "start": "921000",
    "end": "928279"
  },
  {
    "text": "built on top of Apache calite the challenges on SQL side is actually productionizing right if a user",
    "start": "928279",
    "end": "934759"
  },
  {
    "text": "gives a SQL and we are operating a p platform that lets them run this how do we determine how many resources it's",
    "start": "934759",
    "end": "940800"
  },
  {
    "text": "going to take is it going to misbehave what kind of joints it's going to do uh so it's a great mechanism but there's",
    "start": "940800",
    "end": "946600"
  },
  {
    "text": "lots of um challenges around offering that as a platform and then there are low-level apis we took a look at the",
    "start": "946600",
    "end": "952959"
  },
  {
    "text": "data stream API uh today and then if you go even lower level you can actually control how the states being Rec Ro DB",
    "start": "952959",
    "end": "959519"
  },
  {
    "text": "their SPI provider interfaces and so on so it gives you a gamut of options to uh run through things so uh let's jump into",
    "start": "959519",
    "end": "968040"
  },
  {
    "text": "patterns now and uh the way I'm going to describe it is I'm going to take a use case the real use case that we",
    "start": "968040",
    "end": "973199"
  },
  {
    "text": "encountered uh how we solved it and how an pattern emerged out of it I'll show you a small code snippet um and then how",
    "start": "973199",
    "end": "980759"
  },
  {
    "text": "that code snippet actually gets deployed and I'll mention any related patterns if so any so they're divided into",
    "start": "980759",
    "end": "987319"
  },
  {
    "start": "985000",
    "end": "1237000"
  },
  {
    "text": "functional and nonfunctional patter patterns so we'll start with the functional ones and the first one is called the configurable",
    "start": "987319",
    "end": "994920"
  },
  {
    "text": "router so back to our popular screen again so when the user clicks on this as",
    "start": "994920",
    "end": "1000880"
  },
  {
    "text": "I was mentioning there's a whole bunch of traffic that gets generated on the back end uh so these are the mesh of",
    "start": "1000880",
    "end": "1007519"
  },
  {
    "text": "microservices that actually front what you're seeing on the UI and generate tons of events these could be user click",
    "start": "1007519",
    "end": "1015000"
  },
  {
    "text": "Impressions playbacks health of the client did you download a movie offline",
    "start": "1015000",
    "end": "1020759"
  },
  {
    "text": "status of that and and lot of other such cool things and even internally within the system the microservices generate",
    "start": "1020759",
    "end": "1027959"
  },
  {
    "text": "tracing events they generate error log events uh and other system events there are a lot of uh interest to us now these",
    "start": "1027959",
    "end": "1035079"
  },
  {
    "text": "are in addition to our whole um operating metric system which is called Atlas which is different so this",
    "start": "1035079",
    "end": "1041520"
  },
  {
    "text": "generates a whole ton of um events back into our system now we",
    "start": "1041520",
    "end": "1048199"
  },
  {
    "text": "want to take the these events and uh you know clean them up prep them and get them either to the data warehouse and",
    "start": "1048199",
    "end": "1054440"
  },
  {
    "text": "get them to elastic search or other interesting things right so what we actually want to do is we want to create",
    "start": "1054440",
    "end": "1060880"
  },
  {
    "text": "allow the users to create in just pipelines because I could have multiple",
    "start": "1060880",
    "end": "1066480"
  },
  {
    "text": "streams of events I may be interested in only generating events for my application and I want that to be",
    "start": "1066480",
    "end": "1072120"
  },
  {
    "text": "separate from other another user so maybe I want to create a personal injust Pipeline and then specify which things",
    "start": "1072120",
    "end": "1078400"
  },
  {
    "text": "it's going to go to and we want to do it with at least one semantics right and",
    "start": "1078400",
    "end": "1083840"
  },
  {
    "text": "users want to do some kind of basic filtering and projection and we'll look at what those are so u in essence what",
    "start": "1083840",
    "end": "1091080"
  },
  {
    "text": "they want what we wanted was a serverless product that's ready to use out of the box um and the user does not",
    "start": "1091080",
    "end": "1098240"
  },
  {
    "text": "have to write any code they don't have to manage it they don't have to operate it they just come to the UI and then",
    "start": "1098240",
    "end": "1103960"
  },
  {
    "text": "they say I want a new stream right and I want to take that stream and I want to",
    "start": "1103960",
    "end": "1109720"
  },
  {
    "text": "on One path I want to filter it and then send it to Hive and then I want to just send the raw events to elastic such as",
    "start": "1109720",
    "end": "1116360"
  },
  {
    "text": "they are and I also want to send them to a Kafka topic and uh the filter that we looked",
    "start": "1116360",
    "end": "1124039"
  },
  {
    "text": "at before is right here on the top and the user",
    "start": "1124039",
    "end": "1129559"
  },
  {
    "text": "specifies declarative syntax right here right and think about filtering as um",
    "start": "1129559",
    "end": "1136880"
  },
  {
    "text": "filtering out grows in a database when you're SQL it's kind of like the rare Clause right it filters out certain rows",
    "start": "1136880",
    "end": "1143039"
  },
  {
    "text": "the projection on the other hand is like selecting columns right of a SQL query",
    "start": "1143039",
    "end": "1148520"
  },
  {
    "text": "when you're running it against a database so the user goes to the UI and just specifies these two things and on",
    "start": "1148520",
    "end": "1154880"
  },
  {
    "text": "the back end we actually create in provision a",
    "start": "1154880",
    "end": "1160720"
  },
  {
    "text": "topic and then we run a stream we create and run a stream processing job and why",
    "start": "1160720",
    "end": "1167080"
  },
  {
    "text": "we call it the configurable router job job is because this is a streaming application code that's written once and",
    "start": "1167080",
    "end": "1173039"
  },
  {
    "text": "then each time on deployment time we can configure what filter it's going to run what projection it's going to run and",
    "start": "1173039",
    "end": "1178280"
  },
  {
    "text": "what connectors is going to use um so in this scenario where the user had",
    "start": "1178280",
    "end": "1183640"
  },
  {
    "text": "specified three different paths we ended up creating three different jobs but the interesting thing to look at is it it's",
    "start": "1183640",
    "end": "1189960"
  },
  {
    "text": "all reading from the same Kafka topic right so it's a fan out of three so the",
    "start": "1189960",
    "end": "1195559"
  },
  {
    "text": "same topic is being read twice you may wonder why when know why do we do that why do we um use up so many resources",
    "start": "1195559",
    "end": "1202600"
  },
  {
    "text": "and do the fan out uh the reason is isolation right if Hive is down then you",
    "start": "1202600",
    "end": "1207840"
  },
  {
    "text": "don't want the other two paths to be impacted or if elastic searches down you don't want the other two um sources to",
    "start": "1207840",
    "end": "1214120"
  },
  {
    "text": "be impacted and U the arrows kind of den denote the offsets so that if there's a",
    "start": "1214120",
    "end": "1220640"
  },
  {
    "text": "failure we can rewind back and start off where we left off so it provides us at least once guarantee of uh processing",
    "start": "1220640",
    "end": "1227440"
  },
  {
    "text": "these events so we'll be using the r hence forth to kind of refer to this routing job as we",
    "start": "1227440",
    "end": "1234200"
  },
  {
    "text": "use it in other patterns so this whole Keystone Pipeline",
    "start": "1234200",
    "end": "1239600"
  },
  {
    "start": "1237000",
    "end": "1286000"
  },
  {
    "text": "currently is processing uh you know up to a trillion new events every day and",
    "start": "1239600",
    "end": "1245559"
  },
  {
    "text": "uh it ends up in about four pedabytes of data being moved around in the system and there are 2,000 routing jobs we",
    "start": "1245559",
    "end": "1251640"
  },
  {
    "text": "looked at three there are 2,000 of those uh and it runs on 10,000 different containers it's a massive scale pipeline",
    "start": "1251640",
    "end": "1258679"
  },
  {
    "text": "and so this pattern has been wetted at scale for a couple years so this is what it ends up being uh the derived pattern",
    "start": "1258679",
    "end": "1266480"
  },
  {
    "text": "is you have a producer you put it into a uh system like Kafka that is a",
    "start": "1266480",
    "end": "1272880"
  },
  {
    "text": "temporary persistent log buffer and then you pass it through a routing job which",
    "start": "1272880",
    "end": "1279159"
  },
  {
    "text": "allows you to specify declarative processing like filtering and uh transformation and vo you get something",
    "start": "1279159",
    "end": "1285000"
  },
  {
    "text": "interesting into your sync so this is the code snippet uh pretty",
    "start": "1285000",
    "end": "1291240"
  },
  {
    "start": "1286000",
    "end": "1423000"
  },
  {
    "text": "straightforward we have the source on the top right here and",
    "start": "1291240",
    "end": "1296480"
  },
  {
    "text": "then we build a sync and if you see here the syns are configurable so depending on deployment time it'll pick one of",
    "start": "1296480",
    "end": "1302440"
  },
  {
    "text": "those syncs and then this filter function and projection function actually use the configuration that was",
    "start": "1302440",
    "end": "1308520"
  },
  {
    "text": "passed in the declarative xat syntax or the projection syntax and the user did",
    "start": "1308520",
    "end": "1314440"
  },
  {
    "text": "not have to write any code we didn't have to write any code for every new pipeline that was uh deployed it was",
    "start": "1314440",
    "end": "1321039"
  },
  {
    "text": "automatically deployed by our automation we generate uh metrics dashboards logs",
    "start": "1321039",
    "end": "1326120"
  },
  {
    "text": "everything for us to um automate and operate this so to the user it's servoless and 247 running uh system and",
    "start": "1326120",
    "end": "1333320"
  },
  {
    "text": "they don't actually have to ever worry about it we take care of that for them",
    "start": "1333320",
    "end": "1339240"
  },
  {
    "text": "so the next variation of the configurable router pattern is",
    "start": "1339240",
    "end": "1344360"
  },
  {
    "text": "um is driven by the fact that we have a high fan fan out Factor right so you might have a really popular stream like",
    "start": "1344360",
    "end": "1351159"
  },
  {
    "text": "we have our click event stream is really popular has a very high fan out Factor so that means we have to keep scaling up",
    "start": "1351159",
    "end": "1356720"
  },
  {
    "text": "our Kafka cluster so that it can handle the fan outload and after a while it becomes very expensive it's prone to",
    "start": "1356720",
    "end": "1362400"
  },
  {
    "text": "failures and you cannot scale a single cka cluster Beyond a certain limit right so what do we do for that uh so A",
    "start": "1362400",
    "end": "1369440"
  },
  {
    "text": "variation on that is like in this scenario this just tells",
    "start": "1369440",
    "end": "1374840"
  },
  {
    "text": "us that there are two routing paths that are going to the same cluster but they're of different topics so we",
    "start": "1374840",
    "end": "1382000"
  },
  {
    "text": "leverage this fact because now they are in the same fault domain right it's the same cluster if something goes wrong in",
    "start": "1382000",
    "end": "1388400"
  },
  {
    "text": "the whole cluster it's okay and so we do that tradeoff of isolation to efficent",
    "start": "1388400",
    "end": "1394679"
  },
  {
    "text": "efficiency but we only do it in the domain of one cluster so what we do is",
    "start": "1394679",
    "end": "1399760"
  },
  {
    "text": "we merge the processing that was happening across two routers into one right and it's still configurable you",
    "start": "1399760",
    "end": "1406000"
  },
  {
    "text": "can still specify what filters and projection it needs to do but now the same job has reduced the fan out factor",
    "start": "1406000",
    "end": "1413080"
  },
  {
    "text": "from 3 to two right so it's a efficiency optimization pattern uh that leverages",
    "start": "1413080",
    "end": "1420320"
  },
  {
    "text": "what the router pattern starts off with uh so this code snippet is pretty",
    "start": "1420320",
    "end": "1426000"
  },
  {
    "start": "1423000",
    "end": "1453000"
  },
  {
    "text": "straightforward to that one all we do is Flink allows you to take a stream and then do parallel mapping on it right so",
    "start": "1426000",
    "end": "1433400"
  },
  {
    "text": "it just splits out and it does the processing for you so it's pretty straightforward we have to do much to",
    "start": "1433400",
    "end": "1439679"
  },
  {
    "text": "come up with this pattern and implement it again no user code needs to be deployed for this it's again",
    "start": "1439679",
    "end": "1446320"
  },
  {
    "text": "configurable um and based on the syns that you've configured it'll merge the",
    "start": "1446320",
    "end": "1452240"
  },
  {
    "text": "topics together so the next pattern is uh UDF",
    "start": "1452240",
    "end": "1458440"
  },
  {
    "text": "what if the configurable louder for projection and filtering is not enough",
    "start": "1458440",
    "end": "1464120"
  },
  {
    "text": "you want to do something a little bit more right but you still don't the user still does not want to manage the code and deployed so then they can uh plug in",
    "start": "1464120",
    "end": "1473000"
  },
  {
    "text": "their business logic using uh a scripting engine right so one of them",
    "start": "1473000",
    "end": "1478159"
  },
  {
    "text": "was like nashon so users can provide a JavaScript uh snippet to",
    "start": "1478159",
    "end": "1484080"
  },
  {
    "text": "run and so the pattern that emerges out of it is we created this re we it's",
    "start": "1484080",
    "end": "1489760"
  },
  {
    "text": "actually this is in PC mode it's not fully out yet but it's a reusable component that you can um let a",
    "start": "1489760",
    "end": "1497120"
  },
  {
    "text": "scripting uh script run right and the script could be downloaded automatically from your Dynamic runtime configuration",
    "start": "1497120",
    "end": "1503520"
  },
  {
    "text": "system so that you might process 100 events you change your script 100 first event will use the next new script to",
    "start": "1503520",
    "end": "1509120"
  },
  {
    "text": "run so um comparing this to the udfs in SQL the udfs in SQL need to be written",
    "start": "1509120",
    "end": "1516039"
  },
  {
    "text": "in Java and flank and or Scala and you have to package the library uh and so there's a little bit of ceremony for the",
    "start": "1516039",
    "end": "1522360"
  },
  {
    "text": "user to go through and manage the code uh so this is actually complimentary to CDs because you can actually dropped",
    "start": "1522360",
    "end": "1528799"
  },
  {
    "text": "this component as one of the udfs in SQL so now you have scripting engine support the downside is all the cons of using",
    "start": "1528799",
    "end": "1535559"
  },
  {
    "text": "scripting engine right you're going to introduce latencies people can write any code so you need to have the right kind",
    "start": "1535559",
    "end": "1541080"
  },
  {
    "text": "of isolation on it and because we run in containers and every job is its own it",
    "start": "1541080",
    "end": "1546279"
  },
  {
    "text": "kind of provides some degree of isolation there so this is the code snippet again",
    "start": "1546279",
    "end": "1552559"
  },
  {
    "text": "straightforward it's just a map function in the map function we use a scripting engine and this is the uh scripting",
    "start": "1552559",
    "end": "1559159"
  },
  {
    "text": "engine um functionality that the jdk provides out of the box and it's using the nashon jdk on the right and on the",
    "start": "1559159",
    "end": "1566600"
  },
  {
    "text": "left it's just using that engine to run the script so the next one is the",
    "start": "1566600",
    "end": "1573679"
  },
  {
    "start": "1571000",
    "end": "1607000"
  },
  {
    "text": "enricher um all the patterns that we looked so far didn't require any deployment right the next three patterns",
    "start": "1573679",
    "end": "1580760"
  },
  {
    "text": "that we going to look at are patterns based on code that the user needs to write so that means they need to deploy",
    "start": "1580760",
    "end": "1586440"
  },
  {
    "text": "it so we have this tooling build that lets them uh deploy their job and it",
    "start": "1586440",
    "end": "1592000"
  },
  {
    "text": "also automatically syncs the configuration changes in the code they might have made and make it very easy to override here so that they can take the",
    "start": "1592000",
    "end": "1598880"
  },
  {
    "text": "same code through test and production and we also generate some metrics dashboard for them automatically",
    "start": "1598880",
    "end": "1604399"
  },
  {
    "text": "searchable application logs for them and some Nic cities but that's the deployment model we're going to use so",
    "start": "1604399",
    "end": "1611520"
  },
  {
    "start": "1607000",
    "end": "1690000"
  },
  {
    "text": "um this third use case was where we wanted to generate interesting plays that were happening on the user and",
    "start": "1611520",
    "end": "1617840"
  },
  {
    "text": "identif ify them so that we can provide better personalization and uh what this job",
    "start": "1617840",
    "end": "1624559"
  },
  {
    "text": "ended up doing was it's using a stream from Keystone pipelines it's using one of the router streams here and",
    "start": "1624559",
    "end": "1631640"
  },
  {
    "text": "it looks up additional information about this event from the playback history so",
    "start": "1631640",
    "end": "1637559"
  },
  {
    "text": "you made a play you want to look at additional information about it we enriched the event and then we also look",
    "start": "1637559",
    "end": "1643399"
  },
  {
    "text": "up the data from the video metadata now there's a rate limiter built in because you don't want to bombard the service",
    "start": "1643399",
    "end": "1649960"
  },
  {
    "text": "there are different ways of uh rate limiting you know that itself is a is a big topic so I won't get into that but",
    "start": "1649960",
    "end": "1656039"
  },
  {
    "text": "here we limiting the rate by very dumb way of just launching less resource on the streaming job site so the pattern",
    "start": "1656039",
    "end": "1663360"
  },
  {
    "text": "that emerges out of uh this is the enricher pattern right and what it says",
    "start": "1663360",
    "end": "1668399"
  },
  {
    "text": "is uh you can connect to a side input and the side input could be a service call it could be a lookup from a data",
    "start": "1668399",
    "end": "1674840"
  },
  {
    "text": "store or it could be data from a data store that's cashed locally but refreshed frequently uh and periodically",
    "start": "1674840",
    "end": "1682960"
  },
  {
    "text": "and so the data can be either pulled or pushed or gathered say in a sync or in a",
    "start": "1682960",
    "end": "1688399"
  },
  {
    "text": "sync fashion so the code looks pretty similar again uh the Magic's happening in the",
    "start": "1688399",
    "end": "1695960"
  },
  {
    "start": "1690000",
    "end": "1707000"
  },
  {
    "text": "map function uh where it's using the client libraries to get this data and",
    "start": "1695960",
    "end": "1701039"
  },
  {
    "text": "it's using another library to locally gache the data that's refreshed on a 30 second interval",
    "start": "1701039",
    "end": "1708279"
  },
  {
    "start": "1707000",
    "end": "1980000"
  },
  {
    "text": "so this is one of the kind of the more complex use cases that we have that we're recently working on and it's",
    "start": "1708279",
    "end": "1714519"
  },
  {
    "text": "called the co-process Joiner so when you are on the website uh you're browsing it",
    "start": "1714519",
    "end": "1720279"
  },
  {
    "text": "up and down then you're clicking it every time you browse you're generating Impressions right and then when you",
    "start": "1720279",
    "end": "1726159"
  },
  {
    "text": "click on something you're generating a play so we want to be able to understand what the conversion rate is or what the",
    "start": "1726159",
    "end": "1732799"
  },
  {
    "text": "take rate is we want to understand how many number of Impressions before user play happened um and we want to find out",
    "start": "1732799",
    "end": "1741200"
  },
  {
    "text": "um additional attributes around it so there are about 10 billion Impressions that get generated and 2.5 billion play",
    "start": "1741200",
    "end": "1748640"
  },
  {
    "text": "events and um what you realized is to build this actual job we'll have to keep at any point in time two terabytes of",
    "start": "1748640",
    "end": "1755120"
  },
  {
    "text": "state so we looked at how stateful processing Works in Flink so the state that was held across that job it ends up",
    "start": "1755120",
    "end": "1762600"
  },
  {
    "text": "being approximately 2 terab and so here's a quick animation to",
    "start": "1762600",
    "end": "1769519"
  },
  {
    "text": "show you actually what the problem is so we have two different topics where we're getting events from impressions in place",
    "start": "1769519",
    "end": "1776559"
  },
  {
    "text": "and we are interested in joining these events together to make some meaningful conversion rate analytics on top of it",
    "start": "1776559",
    "end": "1783159"
  },
  {
    "text": "right so we get an event from Impressions uh we get another event and",
    "start": "1783159",
    "end": "1789000"
  },
  {
    "text": "then we get one more event and we get another event right if you notice the events in a single stream are",
    "start": "1789000",
    "end": "1796440"
  },
  {
    "text": "coming out of order it's completely completely natural because you may be offline on your device when you come",
    "start": "1796440",
    "end": "1801799"
  },
  {
    "text": "back online you might send it and take different paths through our services and through the networks right so we need to",
    "start": "1801799",
    "end": "1807080"
  },
  {
    "text": "be able to handle this out of order this and the next thing you have to do",
    "start": "1807080",
    "end": "1812760"
  },
  {
    "text": "is we want to actually process this by event time what I mean by event time is when the event was actually generated so",
    "start": "1812760",
    "end": "1820240"
  },
  {
    "text": "if I am on my device mobile device and I watch a movie and I get on a plane and then when I come back online again it's",
    "start": "1820240",
    "end": "1826440"
  },
  {
    "text": "going to send an event I want to know when that play actually happened not when I received it because when I",
    "start": "1826440",
    "end": "1831760"
  },
  {
    "text": "received it it's the wrong signal right so you want to do it based on the event time so to quickly understand event time",
    "start": "1831760",
    "end": "1838000"
  },
  {
    "text": "here's a quick graphic so um imagine an event that came between",
    "start": "1838000",
    "end": "1845240"
  },
  {
    "text": "12 12:00 and 1:00 right here right but",
    "start": "1845600",
    "end": "1851000"
  },
  {
    "text": "it actually was created at somewhere between 11 and 12 so when you're processing based on event time you'd",
    "start": "1851000",
    "end": "1857200"
  },
  {
    "text": "actually put it in the right bucket if you're doing it in processing time you'd only put it you'd put it in the 12 to",
    "start": "1857200",
    "end": "1863200"
  },
  {
    "text": "three uh 1:00 bucket because that's what when you receive it right so this kind",
    "start": "1863200",
    "end": "1868360"
  },
  {
    "text": "of little graphic helps you understand what processing by event time actually",
    "start": "1868360",
    "end": "1873399"
  },
  {
    "text": "means and so this again there's another animation that shows you exactly what happens so we have an event that comes",
    "start": "1873399",
    "end": "1881480"
  },
  {
    "text": "through the system um there's a group bu there's some processing on it and then we save it and this is Kei by a key",
    "start": "1881480",
    "end": "1888760"
  },
  {
    "text": "called K you can see it on top of the i1 event and then we get another event and",
    "start": "1888760",
    "end": "1895159"
  },
  {
    "text": "now these events are um we can coist these events because they are uh we can",
    "start": "1895159",
    "end": "1901519"
  },
  {
    "text": "we are able to do it so it's a kind of a reduction we had multiple events of the same key we can actually start reducing",
    "start": "1901519",
    "end": "1906880"
  },
  {
    "text": "them so it reduced those two events into one event and then now we got an event from uh the place right and now they",
    "start": "1906880",
    "end": "1914039"
  },
  {
    "text": "actually match because they are the same key and we found a match across the states and then uh it merges those two events",
    "start": "1914039",
    "end": "1921919"
  },
  {
    "text": "and then emits an interesting result right so what it's doing here is within the same process it actually has access",
    "start": "1921919",
    "end": "1928840"
  },
  {
    "text": "to the both state that's accumulating across both events and so we keep in",
    "start": "1928840",
    "end": "1934799"
  },
  {
    "text": "memory as much as we can we start reducing and then after a while when we have a join we actually join the events",
    "start": "1934799",
    "end": "1941120"
  },
  {
    "text": "and send it through so this coprocess mechanism comes out of the box with fling right so we don't have to write",
    "start": "1941120",
    "end": "1946519"
  },
  {
    "text": "anything the states managed it's fully fall tolerant you don't have to worry about concurrency um all that's taken",
    "start": "1946519",
    "end": "1953080"
  },
  {
    "text": "care of and so this is kind of the pattern that emerges out of it right we process",
    "start": "1953080",
    "end": "1959440"
  },
  {
    "text": "and call as events for each stream Group by the key and then we join if there's a match and we then we emit the results",
    "start": "1959440",
    "end": "1966039"
  },
  {
    "text": "and then we uh based on a timer we evict U the state from these states so the",
    "start": "1966039",
    "end": "1973200"
  },
  {
    "text": "timers is another functionality that fling provides out of the box where you can register timers will fire after a",
    "start": "1973200",
    "end": "1979000"
  },
  {
    "text": "certain period of time and so the code looks pretty simple here if you look at it we are setting up",
    "start": "1979000",
    "end": "1985000"
  },
  {
    "start": "1980000",
    "end": "2038000"
  },
  {
    "text": "the sources we are saying use the same key and do the processing by event time and then um we took the event time",
    "start": "1985000",
    "end": "1994720"
  },
  {
    "text": "what you see grade out here is something called watermarking right if you have a wall clock you know the clock is",
    "start": "1994720",
    "end": "2000159"
  },
  {
    "text": "sticking but if you basing it on an event time how do you Pro proceed the wall clock on it right you could",
    "start": "2000159",
    "end": "2006440"
  },
  {
    "text": "say there events from 9:00 10:00 11:00 but what's my current clock so",
    "start": "2006440",
    "end": "2011919"
  },
  {
    "text": "watermarking is the concept that's used to show the time tick when you're using event time which says how much time has",
    "start": "2011919",
    "end": "2019159"
  },
  {
    "text": "passed when I'm processing my event right so Flink offers very out of the",
    "start": "2019159",
    "end": "2024679"
  },
  {
    "text": "box mechanism all we are saying is whatever the latest event is let's say my event came at 9:00 then my Watermark",
    "start": "2024679",
    "end": "2032360"
  },
  {
    "text": "or the time talk was at 8:50 just 10 seconds behind right",
    "start": "2032360",
    "end": "2039399"
  },
  {
    "text": "and then we just use this connect function that fling provides out the box to do everything that we needed to do",
    "start": "2039399",
    "end": "2046080"
  },
  {
    "text": "and the joints actually happening in the co-process function and the co-process function is just simple there are two",
    "start": "2046080",
    "end": "2052200"
  },
  {
    "text": "apis process element one and liement two corresponding to each streams independently for each streams you",
    "start": "2052200",
    "end": "2058398"
  },
  {
    "text": "update and reduce the state and then you look in the other state if it's available you join it and clean it out",
    "start": "2058399",
    "end": "2063919"
  },
  {
    "text": "uh so this whole complex pattern was made made very simple uh with the functionality that's",
    "start": "2063919",
    "end": "2070440"
  },
  {
    "start": "2070000",
    "end": "2246000"
  },
  {
    "text": "available so the next pattern is called the event sourced materialized view",
    "start": "2070440",
    "end": "2075480"
  },
  {
    "text": "right uh and this is where we are leveraging fling for an event driven application not to do adoc",
    "start": "2075480",
    "end": "2082919"
  },
  {
    "text": "analytics so as a user when you go to a site uh you present it with all these",
    "start": "2082919",
    "end": "2088240"
  },
  {
    "text": "nice videos but they need to be uh attached or link to actual files so that",
    "start": "2088240",
    "end": "2093280"
  },
  {
    "text": "you can watch the videos and so these assets or file assets uh we need the links to those file assets so they came",
    "start": "2093280",
    "end": "2100560"
  },
  {
    "text": "they come from a service which is backed by a a cache which is our cache called",
    "start": "2100560",
    "end": "2106079"
  },
  {
    "text": "evach which is mcash based and how does this cache actually gets this data it",
    "start": "2106079",
    "end": "2111880"
  },
  {
    "text": "comes through the stream processing uh application so when we upload all our",
    "start": "2111880",
    "end": "2117839"
  },
  {
    "text": "assets to our CDN um Everybody familiar with content delivery Network Okay cool",
    "start": "2117839",
    "end": "2123480"
  },
  {
    "text": "so we upload all these assets to our content uh Ed servers which are much closer to the users and ISP so we can",
    "start": "2123480",
    "end": "2130480"
  },
  {
    "text": "serve the bits faster and as soon as the asset gets uploaded it generates an event to a service on our back end which",
    "start": "2130480",
    "end": "2137359"
  },
  {
    "text": "says either the asset was added or asset was deleted or moved and these events get generated into Kafka and then we put",
    "start": "2137359",
    "end": "2144119"
  },
  {
    "text": "a streaming job there the streaming job accumulates the state changes into a materialized view in the state it's",
    "start": "2144119",
    "end": "2150200"
  },
  {
    "text": "again using flinx uh stateful processing functionality and it creates this map",
    "start": "2150200",
    "end": "2155560"
  },
  {
    "text": "saying asset one is on uh Edge devices one and two and then asset 2 is on edge",
    "start": "2155560",
    "end": "2163599"
  },
  {
    "text": "devices one and three right and then it publishes that information to EVC on a batched basis so every ex number of",
    "start": "2163599",
    "end": "2170599"
  },
  {
    "text": "seconds it batches these updates and then flushes out the new Delta changes occasionally we want to publish the",
    "start": "2170599",
    "end": "2176640"
  },
  {
    "text": "whole snapshot that's in memory uh right to make sure no updates were lost and we get a more fresher view so what we do is",
    "start": "2176640",
    "end": "2184119"
  },
  {
    "text": "we have this pseudo source which generates trigger events into this uh streaming job and it tells",
    "start": "2184119",
    "end": "2190560"
  },
  {
    "text": "it to just flush out all the uh IDs that it's giving it so it's just saying you have a map of 10 assets here's asset one",
    "start": "2190560",
    "end": "2198440"
  },
  {
    "text": "2 3 four just goes through all of them and just sends a marker event and the streaming job actually dumps all those",
    "start": "2198440",
    "end": "2204839"
  },
  {
    "text": "events into evach so we get a consistent snapshot view of it uh so that's the materialized view uh",
    "start": "2204839",
    "end": "2212040"
  },
  {
    "text": "in the pattern that we're talking about so this is what um uh ends up",
    "start": "2212040",
    "end": "2217960"
  },
  {
    "text": "happening uh in the pattern wise so you have an event publisher publishing",
    "start": "2217960",
    "end": "2223960"
  },
  {
    "text": "events it's like event sourcing you're aggregating those events into a view and",
    "start": "2223960",
    "end": "2229040"
  },
  {
    "text": "then you're flushing it out to a SN um on a buffer basis or immediately and then optionally you can inject markers",
    "start": "2229040",
    "end": "2236520"
  },
  {
    "text": "so that you can force it to flush and this optional trigger could be based on your Dynamic configuration or curl poke",
    "start": "2236520",
    "end": "2243520"
  },
  {
    "text": "you do however you want to configure it and and uh this is the code we set up",
    "start": "2243520",
    "end": "2250079"
  },
  {
    "start": "2246000",
    "end": "2283000"
  },
  {
    "text": "the source the trigger Source we say parallelism one because we only want one",
    "start": "2250079",
    "end": "2255119"
  },
  {
    "text": "instance of the source to trigger everything we don't want multiples of it so you're saying create only one source",
    "start": "2255119",
    "end": "2260839"
  },
  {
    "text": "for the trigger and then create another source that actually reads the events coming from the CDN servers and then we",
    "start": "2260839",
    "end": "2267640"
  },
  {
    "text": "do the union of the two sources and then we do the regular functionality we do a keyby we process the event and then we",
    "start": "2267640",
    "end": "2274760"
  },
  {
    "text": "update the inmemory state here and then after that we publish a TV",
    "start": "2274760",
    "end": "2282880"
  },
  {
    "start": "2283000",
    "end": "2403000"
  },
  {
    "text": "cache so uh that ends our functional patterns now we have three more",
    "start": "2283200",
    "end": "2288760"
  },
  {
    "text": "non-functional patterns uh the first one is the development interfaces when",
    "start": "2288760",
    "end": "2295040"
  },
  {
    "text": "you're building a platform and uh stream processing functionality what we've observed is it's useful to have uh a",
    "start": "2295040",
    "end": "2301920"
  },
  {
    "text": "flexible set of apis right and this is what we have found based on ease of use",
    "start": "2301920",
    "end": "2307119"
  },
  {
    "text": "going from Top well bottom to top and capabilities increase as you go from top to bottom so we looked at the point and",
    "start": "2307119",
    "end": "2313960"
  },
  {
    "text": "click uh UI and the udf's extremely easy to for anybody to use right takes 5 minutes to use it and get all the",
    "start": "2313960",
    "end": "2320119"
  },
  {
    "text": "benefits but it's limited in what the user can do with it next would be SQL with their own udfs provides a little",
    "start": "2320119",
    "end": "2326560"
  },
  {
    "text": "more functionality uh but then the onus is on the users to maintain the scale of",
    "start": "2326560",
    "end": "2331599"
  },
  {
    "text": "it and uh there's a little bit of operational overhead on it though we don't have that functionality yet we have some PC's for the SQL stuff running",
    "start": "2331599",
    "end": "2338400"
  },
  {
    "text": "just because of the operational complexity and challenges with it uh the next one is um using annotation based",
    "start": "2338400",
    "end": "2345960"
  },
  {
    "text": "apis right so we have a use case internally that's using uh certain",
    "start": "2345960",
    "end": "2351079"
  },
  {
    "text": "application specific annotations and when a user uses an interface specifies those application specific DSL",
    "start": "2351079",
    "end": "2357760"
  },
  {
    "text": "annotations they take that and then they generate code uh uh using javao and a",
    "start": "2357760",
    "end": "2364480"
  },
  {
    "text": "few other libraries and they generate Flint code and they actually use our automation deployment that I showed you",
    "start": "2364480",
    "end": "2370520"
  },
  {
    "text": "that has an API for it to deploy um and then at the lowest level we looked at",
    "start": "2370520",
    "end": "2375640"
  },
  {
    "text": "all the code for the patterns that we looked at the data stream apis that's what we have right and we mix that with",
    "start": "2375640",
    "end": "2381960"
  },
  {
    "text": "reusable components like the script UDF uh we have data hygiene component that we can uh use rules that are got from a",
    "start": "2381960",
    "end": "2388680"
  },
  {
    "text": "different service and uh we looked at the script Transformer engine so that's",
    "start": "2388680",
    "end": "2394240"
  },
  {
    "text": "kind of the four um variations of apis you can have based on E of use",
    "start": "2394240",
    "end": "2400359"
  },
  {
    "text": "capability and flexibility of the platform uh so as we've been building",
    "start": "2400359",
    "end": "2406319"
  },
  {
    "start": "2403000",
    "end": "2549000"
  },
  {
    "text": "this stream processing platform in Netflix this itself has become a pattern within Netflix so when you say we",
    "start": "2406319",
    "end": "2412359"
  },
  {
    "text": "provide a stream processing as a service platform or spaz people expect this out of it right so what it actually is is",
    "start": "2412359",
    "end": "2420720"
  },
  {
    "text": "our whole platform actually runs on Amazon ec2 then on top of that we have a",
    "start": "2420720",
    "end": "2426200"
  },
  {
    "text": "container runtime that on other team managers and then we have our stream processing platform so it's the",
    "start": "2426200",
    "end": "2432160"
  },
  {
    "text": "streaming engine plus a whole bunch of config management um integration into",
    "start": "2432160",
    "end": "2437240"
  },
  {
    "text": "Netflix ecosystem for metrics and monitoring and for service Discovery right and on top of that we lay reusable",
    "start": "2437240",
    "end": "2443720"
  },
  {
    "text": "components like sources and syns uh different kind of connectors that you looked at when it writes to Hive S3",
    "start": "2443720",
    "end": "2449680"
  },
  {
    "text": "elastic search Kafka and so we provide that out of the box uh and then on top of that we built",
    "start": "2449680",
    "end": "2456640"
  },
  {
    "text": "the routers the whole Keystone pipelines built on that and then at the same level people can write custom streaming jobs",
    "start": "2456640",
    "end": "2462760"
  },
  {
    "text": "using Code deployments now vertically functionality that's leveraged across the whole stack is the Management",
    "start": "2462760",
    "end": "2468880"
  },
  {
    "text": "Service and UI which you take a look at and then we have functionality for",
    "start": "2468880",
    "end": "2473920"
  },
  {
    "text": "making it extremely easy for users to create brand new jobs right you may be familiar with mavan archetype so what we",
    "start": "2473920",
    "end": "2480880"
  },
  {
    "text": "do is out of the box uh it takes users five minutes to",
    "start": "2480880",
    "end": "2488680"
  },
  {
    "text": "take a concept and create a stream processing job out of it so like archetype you have a command line tool",
    "start": "2488720",
    "end": "2494520"
  },
  {
    "text": "that creates a git repo creates a Jenkins job and then also creates u",
    "start": "2494520",
    "end": "2500680"
  },
  {
    "text": "local in AJ idea file so you can actually run it locally and then it also",
    "start": "2500680",
    "end": "2505800"
  },
  {
    "text": "sends your configuration to our deployment tool so that when you're ready to deploy uh the containers are",
    "start": "2505800",
    "end": "2511680"
  },
  {
    "text": "available and you can have the configuration and override it right so all this functionality is to take about more than a week to kind of build now it",
    "start": "2511680",
    "end": "2518200"
  },
  {
    "text": "takes 5 minutes for anybody to get started off with and then we provide some metrics and monitoring for these",
    "start": "2518200",
    "end": "2523760"
  },
  {
    "text": "jobs out of the box and we send all the logs from these uh streaming jobs uh and",
    "start": "2523760",
    "end": "2529000"
  },
  {
    "text": "index them so that they're searchable uh across the board so it's like a full package solution for anybody who wants",
    "start": "2529000",
    "end": "2535640"
  },
  {
    "text": "to do stream processing in Netflix so internally when we talk about it say",
    "start": "2535640",
    "end": "2541000"
  },
  {
    "text": "pass actually people know what we what they mean so I thought including this would be useful as a pattern because",
    "start": "2541000",
    "end": "2546280"
  },
  {
    "text": "it's emerging as one internally um the last pattern for the day is uh rewind and restatement now",
    "start": "2546280",
    "end": "2554280"
  },
  {
    "start": "2549000",
    "end": "2669000"
  },
  {
    "text": "what happens when there are bugs in the code or you want to reprocess some data right on batch you go reprocess the",
    "start": "2554280",
    "end": "2560400"
  },
  {
    "text": "whole batch the batch fails you start from again for the eight hours and then you process the batch again but in",
    "start": "2560400",
    "end": "2565839"
  },
  {
    "text": "streaming you've been streaming the data and you've been processing it right how do we do it so let's say at point x now x + 1 we",
    "start": "2565839",
    "end": "2575040"
  },
  {
    "text": "we figure out that there was actually an outage because if there was a bug in our code or there was something wrong and there were some corrupted uh events that",
    "start": "2575040",
    "end": "2581760"
  },
  {
    "text": "happened to enter our system but if you recall we've been taking consistent checkpoints right and we've taken three",
    "start": "2581760",
    "end": "2588359"
  },
  {
    "text": "checkpoints so far so what we do is we actually roll back our",
    "start": "2588359",
    "end": "2595319"
  },
  {
    "text": "state and um the processing",
    "start": "2595319",
    "end": "2600680"
  },
  {
    "text": "so basically Kafka if you look at this here",
    "start": "2600680",
    "end": "2607319"
  },
  {
    "text": "gafka was at second message and if you look at the next one it went back to",
    "start": "2607319",
    "end": "2614760"
  },
  {
    "text": "this message because when the checkpoint was taken at this point in time it was processing this message and the state",
    "start": "2614760",
    "end": "2621000"
  },
  {
    "text": "got rolled back to so we roll back the state we rolled back the pointer and Kafka and we went back to a well-known",
    "start": "2621000",
    "end": "2627160"
  },
  {
    "text": "good checkpoint and now you can actually go and deploy a new code you want and you can start off exactly at this point",
    "start": "2627160",
    "end": "2633160"
  },
  {
    "text": "and then you can fix it going forward um the whole space of restatement and Rewind and being able to",
    "start": "2633160",
    "end": "2641079"
  },
  {
    "text": "correct data of stream processing jobs it's quite complex there are lots of other variations we working on and so as",
    "start": "2641079",
    "end": "2646680"
  },
  {
    "text": "we work on more more uh patterns will more J of it uh so here's a quick summary of the eight um patterns we",
    "start": "2646680",
    "end": "2653559"
  },
  {
    "text": "looked at the configurable router the script component the enricher the co-process Joiner The Event Source",
    "start": "2653559",
    "end": "2660000"
  },
  {
    "text": "materialized view um the elastic interface and the stream processing",
    "start": "2660000",
    "end": "2665319"
  },
  {
    "text": "platform and the reind uh restatement so um if you liked what you",
    "start": "2665319",
    "end": "2671559"
  },
  {
    "start": "2669000",
    "end": "2854000"
  },
  {
    "text": "saw or you have your patterns of your own or you didn't like something you have better names uh feel free to reach",
    "start": "2671559",
    "end": "2677000"
  },
  {
    "text": "out uh I'd be happy to have uh chat or discussions with you so this is just the",
    "start": "2677000",
    "end": "2682160"
  },
  {
    "text": "beginning of cataloging uh the different patterns that are occurring uh so a",
    "start": "2682160",
    "end": "2687559"
  },
  {
    "text": "conversation is welcome thank you [Applause]",
    "start": "2687559",
    "end": "2697520"
  },
  {
    "text": "yeah I think we have time for three questions",
    "start": "2697520",
    "end": "2702920"
  },
  {
    "text": "okay oh thank you very much for your talk I wanted to ask how do you scale jobs do you have any functionality to",
    "start": "2703400",
    "end": "2709359"
  },
  {
    "text": "identify the bursts of your in your source and maybe Auto scale somehow or",
    "start": "2709359",
    "end": "2714520"
  },
  {
    "text": "do you just redeploy the whole fling job no that's a great question so Auto scaling is not",
    "start": "2714520",
    "end": "2720680"
  },
  {
    "text": "um proactive Auto scaling is not built in yet there's a proposal out in the Flink Community to add uh Autos scaling",
    "start": "2720680",
    "end": "2727960"
  },
  {
    "text": "that we're working on what we do internally is uh we have external",
    "start": "2727960",
    "end": "2733359"
  },
  {
    "text": "processes that monitor uh and we have metrics that uh report lag in the system",
    "start": "2733359",
    "end": "2739040"
  },
  {
    "text": "so when there's a lag in the system we have some automation that will boost the capacity and it'll redeploy that job",
    "start": "2739040",
    "end": "2745960"
  },
  {
    "text": "because the state is uh fa to and we can stop the job increase the capacity and",
    "start": "2745960",
    "end": "2751760"
  },
  {
    "text": "then relaunch it and it's running on containers which come up really fast so the downtime pretty small so at this",
    "start": "2751760",
    "end": "2758760"
  },
  {
    "text": "point in time that's how we kind of scale until we get through Auto scaling in it thank",
    "start": "2758760",
    "end": "2765078"
  },
  {
    "text": "you okay maybe one more question no okay uh oh here we",
    "start": "2765240",
    "end": "2774599"
  },
  {
    "text": "go hey thanks monel this is fantastic uh quick question so you talking about um",
    "start": "2774599",
    "end": "2780440"
  },
  {
    "text": "joining multiple stream processes using a single uh to kind of create the the",
    "start": "2780440",
    "end": "2785480"
  },
  {
    "text": "batch before you commit uh to a a destination how do you know when when",
    "start": "2785480",
    "end": "2791160"
  },
  {
    "text": "the events are finished for a given uh join kind of thing okay so uh when do we know when",
    "start": "2791160",
    "end": "2798800"
  },
  {
    "text": "the events are joined so this there are few uh possibilities when you know it's",
    "start": "2798800",
    "end": "2804760"
  },
  {
    "text": "finished uh one is uh depending on the domain so for our use case where we had Impressions and uh plays we know that",
    "start": "2804760",
    "end": "2813400"
  },
  {
    "text": "the Impressions that are showed the page that shows you after X number of that becomes invalid so we know that after X",
    "start": "2813400",
    "end": "2821160"
  },
  {
    "text": "number of hours we not going to get impressions for that factor so whatever plays are left over we can either put",
    "start": "2821160",
    "end": "2827800"
  },
  {
    "text": "them out to a different output channel for analysis later as to why we didn't find the match or we can just uh capture",
    "start": "2827800",
    "end": "2833800"
  },
  {
    "text": "a account metric and just drop it um in other scenarios uh you know because you",
    "start": "2833800",
    "end": "2839000"
  },
  {
    "text": "found a joint so for example you're just looking for one join and then you're done then you know so it's either",
    "start": "2839000",
    "end": "2844359"
  },
  {
    "text": "application logic specific or it's a timeout specific or it's a resource",
    "start": "2844359",
    "end": "2849960"
  },
  {
    "text": "specific okay thanks",
    "start": "2849960",
    "end": "2855078"
  }
]
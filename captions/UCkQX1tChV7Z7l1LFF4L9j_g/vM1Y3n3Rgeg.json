[
  {
    "start": "0",
    "end": "29000"
  },
  {
    "text": "so I want to get a better sense for the background for the scouts are clearly in the machine learning 2.0 tracks I presume you're interested in machine",
    "start": "3939",
    "end": "10179"
  },
  {
    "text": "learning but how many folks I have known about deep learning or are using deep learning and practice but just by show",
    "start": "10179",
    "end": "15760"
  },
  {
    "text": "of hands alright cool and I guess how many folks know about convolutional neural networks",
    "start": "15760",
    "end": "21099"
  },
  {
    "text": "by show of hands alright great got it all right so I I guess it was advice to me by by John",
    "start": "21099",
    "end": "27399"
  },
  {
    "text": "Langford that I start slow and walk you through some of the basics of deep learning and cognition near let's so",
    "start": "27399",
    "end": "34750"
  },
  {
    "start": "29000",
    "end": "29000"
  },
  {
    "text": "we'll start there so I'm gonna just briefly talk about the history of deep learning why it's important commercial",
    "start": "34750",
    "end": "39850"
  },
  {
    "text": "applications at this point in time and then convolutional neural nets and then we will get to the meat of the talk",
    "start": "39850",
    "end": "45520"
  },
  {
    "text": "which is about climate science why we care about this problem and then how we represent climate patterns using",
    "start": "45520",
    "end": "52090"
  },
  {
    "text": "supervised and semi-supervised architectures and then I'll get to scaling D planning on our supercomputer",
    "start": "52090",
    "end": "58170"
  },
  {
    "text": "all right so let's start with what deep learning so for those of you who are",
    "start": "58170",
    "end": "64239"
  },
  {
    "text": "tracking the field you may know that this is not the first time that neural nets have been you know in in why well",
    "start": "64239",
    "end": "70929"
  },
  {
    "text": "have been popular so they started off in 1960s and at that point in time people",
    "start": "70929",
    "end": "76749"
  },
  {
    "text": "were essentially fiddling with mapping input layer to an output layer by using one hidden layer",
    "start": "76749",
    "end": "82719"
  },
  {
    "text": "so essentially what what researchers used to do was to take the input multiplied by a linear rate and then",
    "start": "82719",
    "end": "89560"
  },
  {
    "text": "apply some non-linearity and hope that you'll get an output so they they",
    "start": "89560",
    "end": "94600"
  },
  {
    "text": "experimented with this for a while and and essentially unfortunately early on it was discovered that such networks",
    "start": "94600",
    "end": "101200"
  },
  {
    "text": "could not even solve something called the saw problem and exclusive-or problem and unfortunately that result was widely",
    "start": "101200",
    "end": "109060"
  },
  {
    "text": "publicized and a lot of people were disappointed that that these neural nets would not do anything complicated in the",
    "start": "109060",
    "end": "115990"
  },
  {
    "start": "115000",
    "end": "115000"
  },
  {
    "text": "mid-1980s a bunch of researchers kept at it so they they started looking at",
    "start": "115990",
    "end": "122049"
  },
  {
    "text": "multi-layer networks so not just having one hidden layer but a cascade of several hidden layers the idea is still",
    "start": "122049",
    "end": "128770"
  },
  {
    "text": "being the same so you take an input you apply a linear rate you apply a non-linearity and then the output of",
    "start": "128770",
    "end": "135430"
  },
  {
    "text": "that first hidden layer would get processed by the second hidden layer and so on they also worked out how to do",
    "start": "135430",
    "end": "141760"
  },
  {
    "text": "back propagation so how do you take if you're making any mistakes at the output layer how do you move the error or the",
    "start": "141760",
    "end": "149290"
  },
  {
    "text": "correction rather to the weights through the network and update the weights to get a more accurate answer so that",
    "start": "149290",
    "end": "155110"
  },
  {
    "text": "seemed to hold some promise now unfortunately for the the neural net crowd support vector machines and random",
    "start": "155110",
    "end": "161260"
  },
  {
    "text": "forests were in vogue and that's what dominated the field for the next two decades or so till present day so this",
    "start": "161260",
    "end": "168520"
  },
  {
    "text": "we are right now in the midst of I guess the third wave of neural networks and one might ask the question of what's",
    "start": "168520",
    "end": "174730"
  },
  {
    "text": "different this time around there are two important things that have changed between the nine mid-1980s to to present",
    "start": "174730",
    "end": "180880"
  },
  {
    "text": "day one is that we definitely have big data and we have a lot of it it's complex but perhaps more importantly",
    "start": "180880",
    "end": "188080"
  },
  {
    "text": "there are a lot of labeled data sets that are now available so the computer vision community which for the first",
    "start": "188080",
    "end": "193450"
  },
  {
    "text": "time demonstrated that deep learning is extremely powerful had access to millions of label images and once you have that then it's been found that",
    "start": "193450",
    "end": "200739"
  },
  {
    "text": "these systems can be really powerful the other change is big compute so certainly",
    "start": "200739",
    "end": "207000"
  },
  {
    "text": "Moore's Law has been alive and around for for several decades now so certainly",
    "start": "207000",
    "end": "212680"
  },
  {
    "text": "on your laptop you can have a powerful GPU or you can have a many core CPU and",
    "start": "212680",
    "end": "218050"
  },
  {
    "text": "get access to teraflop classed computing so with these two trends a lot of label",
    "start": "218050",
    "end": "223540"
  },
  {
    "text": "data and a lot of compute has power essentially people started exploring",
    "start": "223540",
    "end": "228730"
  },
  {
    "text": "what if we start adding more and more layers to the network so here is an input and right at the end as the",
    "start": "228730",
    "end": "234880"
  },
  {
    "text": "outputs but you'll note that we no longer have two layers but you in fact have dozens of layers and essentially I",
    "start": "234880",
    "end": "241030"
  },
  {
    "text": "think what the field empirically found was that if you can do that if you can have a very deep network than these these networks are extremely powerful in",
    "start": "241030",
    "end": "248440"
  },
  {
    "text": "terms of capturing patterns in your data set and they've applied it now successfully to a range of applications",
    "start": "248440",
    "end": "253870"
  },
  {
    "text": "I'm going to just walk you through some commercial I guess some bleeding edge",
    "start": "253870",
    "end": "259239"
  },
  {
    "text": "research so the deep wine startup was acquired by Google and immediately they",
    "start": "259239",
    "end": "265690"
  },
  {
    "text": "de put it to use to defeat the human world expert in the game of Go Sogo is a game that's supposed to be",
    "start": "265690",
    "end": "271990"
  },
  {
    "text": "exponentially harder than chess and using a formalism called reinforcement learning",
    "start": "271990",
    "end": "277180"
  },
  {
    "text": "we now have beaten the korean grandmaster and now the Chinese Grandmaster self-driving cars are no",
    "start": "277180",
    "end": "283990"
  },
  {
    "start": "282000",
    "end": "282000"
  },
  {
    "text": "longer friction in in California at least these cars are you know routinely",
    "start": "283990",
    "end": "290409"
  },
  {
    "text": "on the highways so certainly there are a range of sensors that the cars have so",
    "start": "290409",
    "end": "295900"
  },
  {
    "text": "there might be computer vision sensors or or depth sensors so processing all of",
    "start": "295900",
    "end": "302529"
  },
  {
    "text": "that data and fusing it is done by deep learning to some extent but also the control strategy for the car should I turn my wheel to the left or to the",
    "start": "302529",
    "end": "308949"
  },
  {
    "text": "right should I press the accelerator or the brake that's that's determined by deep learning system as well deep",
    "start": "308949",
    "end": "317080"
  },
  {
    "start": "316000",
    "end": "316000"
  },
  {
    "text": "learning has certainly become quite transparent so these days if you just pick up your cell phone and you talk to it chances are high that there is a deep",
    "start": "317080",
    "end": "325360"
  },
  {
    "text": "learning system either on your cell phone or somewhere in the cloud and it's going to be essentially trying to",
    "start": "325360",
    "end": "332259"
  },
  {
    "text": "understand the speech signal and figuring out what question you have in mind so so this is you know fully",
    "start": "332259",
    "end": "337629"
  },
  {
    "text": "transparent at this point in time but really the the the key event that",
    "start": "337629",
    "end": "343080"
  },
  {
    "start": "339000",
    "end": "339000"
  },
  {
    "text": "revolutionized I would say deep learning and made it successful was computer",
    "start": "343080",
    "end": "348250"
  },
  {
    "text": "vision so in the computer vision community there's something called the image net competition and the competition is as follows we're going to",
    "start": "348250",
    "end": "355089"
  },
  {
    "text": "give you a bunch of images so these are all natural real world images and you the computer system will need to come up",
    "start": "355089",
    "end": "361060"
  },
  {
    "text": "with well you need to tell me exactly what objects are there in that image so given this image on the top left the",
    "start": "361060",
    "end": "368469"
  },
  {
    "text": "the deep learning system needs to draw a box around a bird and a box around a frog and so on and so forth now before",
    "start": "368469",
    "end": "376419"
  },
  {
    "text": "2011 the entire computer vision community had been at it for for several",
    "start": "376419",
    "end": "382180"
  },
  {
    "text": "decades and every year the error rate in this particular competition would drop by maybe a half a percent or one percent",
    "start": "382180",
    "end": "388270"
  },
  {
    "text": "or so so it was really a slow incremental field till geoff hinton",
    "start": "388270",
    "end": "393699"
  },
  {
    "text": "and and his colleagues in toronto applied convolutional architectures to",
    "start": "393699",
    "end": "399519"
  },
  {
    "text": "dramatically drop the error rate in 2012 by you deep learning by about 15% and",
    "start": "399519",
    "end": "405270"
  },
  {
    "text": "subsequently the entire field is almost entirely shifted over to deep learning",
    "start": "405270",
    "end": "410290"
  },
  {
    "text": "and they have beaten up on this problem to the extent now that the the error",
    "start": "410290",
    "end": "416320"
  },
  {
    "text": "rate that's reported by these convolutional architectures is below that of human performance so essentially",
    "start": "416320",
    "end": "422620"
  },
  {
    "text": "a machine can do a better job in identifying objects and images than even",
    "start": "422620",
    "end": "428200"
  },
  {
    "text": "humans so I'll just walk you through so I guess some of the basics of how how",
    "start": "428200",
    "end": "433990"
  },
  {
    "text": "this works in practice so typically what what happens is that you start off with an image that's all the way off to the",
    "start": "433990",
    "end": "441100"
  },
  {
    "text": "left here and that might be say 224 by 224 pixel image and there might be say three channels typically when you're",
    "start": "441100",
    "end": "447670"
  },
  {
    "text": "looking at commercial applications you have RGB chance and its 8-bit and what you want the network to do at the end is",
    "start": "447670",
    "end": "453790"
  },
  {
    "text": "to produce its estimate or what it thinks there is in the object so perhaps there is a a vector with 100 classes and",
    "start": "453790",
    "end": "462220"
  },
  {
    "text": "it's going to give you a probabilistic estimate of what class it feels most confident about so the way you set this",
    "start": "462220",
    "end": "471250"
  },
  {
    "text": "up is you know the very first thing you do is to identify training data and the more of it you have the better the",
    "start": "471250",
    "end": "476350"
  },
  {
    "text": "chance that you're gonna converge something interesting so training data means that you need a lot of images",
    "start": "476350",
    "end": "482650"
  },
  {
    "text": "preferably hundreds of thousands if not millions and you'll need labels on what exactly is in the image to begin with",
    "start": "482650",
    "end": "489180"
  },
  {
    "text": "somehow you need to decide on what architecture makes sense for this problem and that's where some of the",
    "start": "489180",
    "end": "494230"
  },
  {
    "text": "magic certainly is but let's say that you have some heuristics or some other people in the field have already filled",
    "start": "494230",
    "end": "499720"
  },
  {
    "text": "with similar data and you have a reasonable starting point so so you essentially determine what architecture",
    "start": "499720",
    "end": "506350"
  },
  {
    "text": "makes sense for this problem now once the architecture is set what you'll do is and typically the",
    "start": "506350",
    "end": "513190"
  },
  {
    "text": "architecture consists of different layers we're filtering and pooling happens so I'm just gonna visually I",
    "start": "513190",
    "end": "518830"
  },
  {
    "start": "518000",
    "end": "518000"
  },
  {
    "text": "mean these are standard image processing terms but essentially what you do is say",
    "start": "518830",
    "end": "524050"
  },
  {
    "text": "you have an input image with three channels you're going to define some filters they might be say five by five",
    "start": "524050",
    "end": "529120"
  },
  {
    "text": "and you're going to slide those filters across the image till it produces some feature map output",
    "start": "529120",
    "end": "535360"
  },
  {
    "text": "so that's standard convolution and then there are some nonlinear nonlinearities such as pooling so you take an image of",
    "start": "535360",
    "end": "543369"
  },
  {
    "text": "affair and then in this case we're going to apply something called a max pooling operation so I apply a max pooling",
    "start": "543369",
    "end": "550839"
  },
  {
    "text": "operation to these two by two pixels the max value is nine and so on and so forth so generally speaking those are the two",
    "start": "550839",
    "end": "556869"
  },
  {
    "text": "kinds of operations which are applied in these convolutional architectures so essentially you you design a cascade",
    "start": "556869",
    "end": "563230"
  },
  {
    "text": "so you have convolutions and then max pooling convolutions max pooling all the",
    "start": "563230",
    "end": "568269"
  },
  {
    "text": "way till the end when you have a fully connected layer now you are the key",
    "start": "568269",
    "end": "574749"
  },
  {
    "text": "thing here is that you are not going to be designing these filters by hand and this is a big big difference between",
    "start": "574749",
    "end": "582339"
  },
  {
    "text": "what the computer vision community did for thirty four three decades compared to what the deep learning crowd tells",
    "start": "582339",
    "end": "587379"
  },
  {
    "text": "you the computer vision community thought that it could by hand design the world's best pedestrian detector and the",
    "start": "587379",
    "end": "594549"
  },
  {
    "text": "world's best you know tree detector or card detector and so on what the deep learning folks said no we're not going",
    "start": "594549",
    "end": "599889"
  },
  {
    "text": "to do that we are not going to be in the business of designing filters we're just going to initialize these weights",
    "start": "599889",
    "end": "605410"
  },
  {
    "text": "randomly and then we will take our training image we will pass it through",
    "start": "605410",
    "end": "612339"
  },
  {
    "text": "this entire network and we will get an output now chances of course are high that well if you start off with the",
    "start": "612339",
    "end": "618009"
  },
  {
    "text": "random weight you'll you'll get junk so you will make an error write it right at the end but because you know what the",
    "start": "618009",
    "end": "623799"
  },
  {
    "text": "truth is because you know what the label is you can compute what the error is and then you can map back propagate you can",
    "start": "623799",
    "end": "629769"
  },
  {
    "text": "figure out the gradient of the error with respect to the layer and then you",
    "start": "629769",
    "end": "634929"
  },
  {
    "text": "can back propagate that gradient through the network and adjust the weights so",
    "start": "634929",
    "end": "639999"
  },
  {
    "text": "that hopefully will do a better job next time around and then you do this millions of times as many images as you",
    "start": "639999",
    "end": "645309"
  },
  {
    "text": "have and you hope that you know you can version on on a reasonable architecture so near so we start off with random",
    "start": "645309",
    "end": "652410"
  },
  {
    "text": "initialization we do a forward pass filtering images and making the prediction we compute the error because",
    "start": "652410",
    "end": "658209"
  },
  {
    "text": "we know the truth and then we do the backward pass we compute the gradients and update parameters now what got",
    "start": "658209",
    "end": "664779"
  },
  {
    "text": "people really interested I would say I think intellectually was that if you apply this technique at",
    "start": "664779",
    "end": "670949"
  },
  {
    "start": "665000",
    "end": "665000"
  },
  {
    "text": "this procedure to real-world images you get filters that are really interesting",
    "start": "670949",
    "end": "676050"
  },
  {
    "text": "and they make a lot of sense so right at the very first condition layer essentially what the network learns are",
    "start": "676050",
    "end": "682620"
  },
  {
    "text": "low level Gabor filters and neuroscientists believe that this is what our visual system does so these are",
    "start": "682620",
    "end": "689759"
  },
  {
    "text": "all oriented edges at different scales a little bit further the completion in in",
    "start": "689759",
    "end": "696689"
  },
  {
    "text": "the conditional layer essentially what what the network learns are compositions of these low-level features so simple",
    "start": "696689",
    "end": "702569"
  },
  {
    "text": "texture patterns move further along in the architecture the network seems to",
    "start": "702569",
    "end": "708629"
  },
  {
    "text": "pick out object parts so it'll take these relatively simple texture patterns and then learn how to compose them to",
    "start": "708629",
    "end": "714720"
  },
  {
    "text": "make parts so you learn the representation of a clock or the wheel of a car or the face of a dog and so on",
    "start": "714720",
    "end": "720509"
  },
  {
    "text": "and right at the end the network essentially learns the notion of an object so perhaps there is a ship or an",
    "start": "720509",
    "end": "728970"
  },
  {
    "text": "animal or what have you an internetwork now this was really interesting because this is not prescribed in any way unlike what the",
    "start": "728970",
    "end": "735810"
  },
  {
    "text": "computer vision community had done for three decades there was no notion of a prescription of this is these are the filters you need to have in order to",
    "start": "735810",
    "end": "742500"
  },
  {
    "text": "become you know in order to design the world's best car detector all right so",
    "start": "742500",
    "end": "748199"
  },
  {
    "text": "so hopefully I think that gives you a sense for just the basics of these architectures what's involved so I'm",
    "start": "748199",
    "end": "754529"
  },
  {
    "text": "gonna now transition to you know from commercial applications to climate science so I'm as Supes mentioned Simon",
    "start": "754529",
    "end": "763949"
  },
  {
    "text": "I'm at Berkeley Lab and you know we're really not in the business of making money we care about basic science and",
    "start": "763949",
    "end": "770430"
  },
  {
    "text": "and fundamental questions the the science question in this case is we know",
    "start": "770430",
    "end": "777480"
  },
  {
    "text": "that the climate is changing you know politically it may be convenient or not is a different question but but the climate is changing",
    "start": "777480",
    "end": "783750"
  },
  {
    "text": "and instead of talking about maybe a a simplistic quantity like the change in",
    "start": "783750",
    "end": "790470"
  },
  {
    "text": "temperature by a degree or two degrees or a change in sea level the question that we want to ask here is how is",
    "start": "790470",
    "end": "796889"
  },
  {
    "text": "extreme weather going to be changing in the future so what do we mean by extreme weather",
    "start": "796889",
    "end": "802860"
  },
  {
    "text": "so for this city at least I guess some of you might still recall hurricane sandy and and what happened when sandy",
    "start": "802860",
    "end": "809370"
  },
  {
    "text": "made landfall so this was a storm system that started off in the tropics and it",
    "start": "809370",
    "end": "814470"
  },
  {
    "text": "started propagating towards the Northeast now unfortunately there was another storm system to the right of",
    "start": "814470",
    "end": "819779"
  },
  {
    "text": "this figure which prevented this storm from typically veering off to the top right which is what it would have done",
    "start": "819779",
    "end": "825000"
  },
  {
    "text": "normally but instead it it made landfall with catastrophic effects so certainly",
    "start": "825000",
    "end": "830790"
  },
  {
    "text": "people on the coastline individual homeowners on support' were negatively impacted certainly also impacted a",
    "start": "830790",
    "end": "838800"
  },
  {
    "text": "number of landmarks I guess in in the area but you know city like Manhattan",
    "start": "838800",
    "end": "845390"
  },
  {
    "text": "was was at a standstill for for several days now a city like New York again is",
    "start": "845390",
    "end": "852899"
  },
  {
    "text": "very resilient the economy's really strong so it can always bounce back but you know hurricanes do not discriminate",
    "start": "852899",
    "end": "859580"
  },
  {
    "text": "I guess I almost a decade back now Hurricane Katrina made landfall in in",
    "start": "859580",
    "end": "865410"
  },
  {
    "text": "New Orleans which is perhaps economically not as strong a city and it",
    "start": "865410",
    "end": "871079"
  },
  {
    "text": "almost I think I would say it took a decade for the the city to recover now both of these events sandy and and",
    "start": "871079",
    "end": "876870"
  },
  {
    "text": "Katrina are order a ten billion dollar of events I mean that's the amount of damage they caused but really it's not",
    "start": "876870",
    "end": "882029"
  },
  {
    "text": "just about the cost the dollar amount of the damage it's really the inconvenience",
    "start": "882029",
    "end": "887040"
  },
  {
    "text": "that it causes to humans and fortunately lives are lost and a number of people displaced from from their homes so I",
    "start": "887040",
    "end": "894000"
  },
  {
    "text": "think this is the Houston Astrodome and a number of people who are moved there and in the aftermath of Hurricane Katrina so so the question here is you",
    "start": "894000",
    "end": "902459"
  },
  {
    "start": "900000",
    "end": "900000"
  },
  {
    "text": "know we know that these events are extremely expensive and extremely I mean there's a negative impact on humanity",
    "start": "902459",
    "end": "908600"
  },
  {
    "text": "what can we say about such events in the future as the climate change so we're not going to be talking about course",
    "start": "908600",
    "end": "915089"
  },
  {
    "text": "quantity like degree or two Celsius increase or sea level rise I mean those are important things to keep in mind but",
    "start": "915089",
    "end": "921000"
  },
  {
    "text": "the question we can ask is are category four and category 5 storms going to be",
    "start": "921000",
    "end": "926220"
  },
  {
    "text": "more frequent in the future are they gonna start making landfall more often in the future when they make landfall",
    "start": "926220",
    "end": "932040"
  },
  {
    "text": "are they going to be more intense or less intense so those are questions we don't ask so how do we go",
    "start": "932040",
    "end": "937560"
  },
  {
    "text": "about answering that question well as we often do in Earth Sciences you know we",
    "start": "937560",
    "end": "944430"
  },
  {
    "text": "are our lives are relatively short I mean the the recorded time period for Humanities is relatively small Earth is",
    "start": "944430",
    "end": "951180"
  },
  {
    "text": "is several billion years old so one of the things that we can do is to look back in time and look at paleo climate records and see if such events have",
    "start": "951180",
    "end": "958440"
  },
  {
    "text": "happened now those are hard to come by and you can only dig for for these kinds of records",
    "start": "958440",
    "end": "965940"
  },
  {
    "text": "in very few places in the world but now because we have powerful computers one",
    "start": "965940",
    "end": "971130"
  },
  {
    "text": "of the things that we can do is to simulate the Earth's going forward so we can have climate simulations and we can",
    "start": "971130",
    "end": "976380"
  },
  {
    "text": "plug in a range of effects so we can talk about what the external force",
    "start": "976380",
    "end": "982050"
  },
  {
    "text": "things are for the climate system so solar activity and volcanic eruptions we can talk about anthropogenic influence",
    "start": "982050",
    "end": "988020"
  },
  {
    "text": "so how say the GDP of China and u.s. and India are going to grow how much co2 the emissions are going to make and then we",
    "start": "988020",
    "end": "994830"
  },
  {
    "text": "have a lot of physics equations that we plug in and those take into account the",
    "start": "994830",
    "end": "999900"
  },
  {
    "text": "internal climate system variability so you plug all of that in and then you run the climate simulation out for the next",
    "start": "999900",
    "end": "1004940"
  },
  {
    "text": "hundred years so essentially what you're going to do is once you do that you end up with the last dataset and we will",
    "start": "1004940",
    "end": "1011570"
  },
  {
    "text": "need to do some pattern detection on that dataset so I wanted to give you a favor I understand that most of you may",
    "start": "1011570",
    "end": "1016640"
  },
  {
    "text": "not have a background in climate science so I wanted to give you a flavor for what the day set looks like and the question you should be asking yourself",
    "start": "1016640",
    "end": "1022610"
  },
  {
    "text": "as you see this movie is if I have a hundred years of this movie running in front of me will I be able to find",
    "start": "1022610",
    "end": "1028819"
  },
  {
    "text": "patterns in this data set by hand or by eye so there is a certain field called",
    "start": "1028820",
    "end": "1036770"
  },
  {
    "start": "1033000",
    "end": "1033000"
  },
  {
    "text": "water vapour humidity or specific humidity that we are trying to visualize this is a model that our production work",
    "start": "1036770",
    "end": "1043610"
  },
  {
    "text": "house model in the do-e and we run this at 25 kilometer resolution and essentially you're seeing the atmosphere",
    "start": "1043610",
    "end": "1049700"
  },
  {
    "text": "you're seeing how water vapor in the atmosphere is getting transported some of you may know that there are",
    "start": "1049700",
    "end": "1055010"
  },
  {
    "text": "hurricanes that are forming and they you know some of them fizzle out here but others develop and grow and you know",
    "start": "1055010",
    "end": "1063020"
  },
  {
    "text": "make landfall the movie that we played was just over three months in a specific year but now",
    "start": "1063020",
    "end": "1069800"
  },
  {
    "text": "in a movie that runs for 100 years so you have a lot of data to process now if",
    "start": "1069800",
    "end": "1075140"
  },
  {
    "start": "1074000",
    "end": "1074000"
  },
  {
    "text": "you look at any specific patch in this in this frame from the movie you're not gonna have 8 bit RGB information you",
    "start": "1075140",
    "end": "1082580"
  },
  {
    "text": "will actually have a lot of variables of off interest and these are all going to be single or double precision floating",
    "start": "1082580",
    "end": "1088010"
  },
  {
    "text": "point so you might have specific humidity but then you might also have Bend and pressure and temperature and so",
    "start": "1088010",
    "end": "1094010"
  },
  {
    "text": "on and so forth so essentially this is what the machine learning or the deep learning system is going to see and based on that",
    "start": "1094010",
    "end": "1100070"
  },
  {
    "text": "information it'll need to decide whether there is an extreme weather event here or not so the task is going to be I will",
    "start": "1100070",
    "end": "1108050"
  },
  {
    "text": "give the deep learning system these fields and then the deep learning system",
    "start": "1108050",
    "end": "1113120"
  },
  {
    "text": "will need to say you know draw me the task I'm gonna ask it to do is to say",
    "start": "1113120",
    "end": "1118370"
  },
  {
    "text": "draw me yellow bounding boxes around hurricanes and draw me green boxes around X tropical cyclones and draw me",
    "start": "1118370",
    "end": "1124940"
  },
  {
    "text": "red boxes around atmospheric rivers these are all different kinds of examples of extreme weather events of interest all right so there is an",
    "start": "1124940",
    "end": "1133160"
  },
  {
    "start": "1131000",
    "end": "1131000"
  },
  {
    "text": "analogy here in the task that we have in climate which is to find these patterns",
    "start": "1133160",
    "end": "1138530"
  },
  {
    "text": "in computer vision when I showed you the image net challenge it was roughly the same problem I had RGB images and I had",
    "start": "1138530",
    "end": "1144230"
  },
  {
    "text": "to pull out you know pictures of cats and dogs and so on so there it's a it's a pattern classification task but there",
    "start": "1144230",
    "end": "1151700"
  },
  {
    "text": "is also this key step of feature learning you know I the climate community has not spent three decades in",
    "start": "1151700",
    "end": "1156710"
  },
  {
    "text": "hand tuning you know features for different types of events they have",
    "start": "1156710",
    "end": "1162830"
  },
  {
    "text": "actually spent three decades in designing features for one event but but not others so relieve automate this I",
    "start": "1162830",
    "end": "1168500"
  },
  {
    "text": "really want to get pattern classification and feature learning working at scale now so there is an",
    "start": "1168500",
    "end": "1173660"
  },
  {
    "text": "analogy but then there are some differences and as I mentioned there is the attributes of climate data are",
    "start": "1173660",
    "end": "1178940"
  },
  {
    "text": "different so we have many channels so we have dozens of channels they're all double precision floating point and then",
    "start": "1178940",
    "end": "1185930"
  },
  {
    "text": "probably the last bullet point is most interesting which is that the underlying statistics or patterns are likely",
    "start": "1185930",
    "end": "1191120"
  },
  {
    "text": "different so if you think about taking a camera and clicking images in the real world perhaps your camera has a thousand by",
    "start": "1191120",
    "end": "1197270"
  },
  {
    "text": "thousand pixels pixels so you take an image so that's one point in a million",
    "start": "1197270",
    "end": "1202640"
  },
  {
    "text": "dimensional space now I go around taking a lot of pixels so I'm slowly filling in points in this",
    "start": "1202640",
    "end": "1207919"
  },
  {
    "text": "high dimension space and essentially what the deep learning system does is it tries to figure out how can I separate",
    "start": "1207919",
    "end": "1213320"
  },
  {
    "text": "clusters in this high dimensional space non-climate roughly is the same story so",
    "start": "1213320",
    "end": "1218539"
  },
  {
    "text": "maybe we have thousand by thousand pixels and now I'm going to be looking for patterns in this data set",
    "start": "1218539",
    "end": "1223879"
  },
  {
    "text": "there is really no guarantee a priori that patterns in this high dimension",
    "start": "1223879",
    "end": "1228979"
  },
  {
    "text": "space corresponding to a fluid flow system will be the same as what you find in the national natural so the",
    "start": "1228979",
    "end": "1234229"
  },
  {
    "text": "underlying statistics are most likely different and the question really is can a deep learning systems be successful at",
    "start": "1234229",
    "end": "1239779"
  },
  {
    "text": "separating out patterns in this in this space alright so that leads us to",
    "start": "1239779",
    "end": "1246729"
  },
  {
    "text": "representational challenges I mean given this problem set up how do we go about",
    "start": "1246729",
    "end": "1252529"
  },
  {
    "text": "solving it so so we're gonna use two approaches first because this is a this",
    "start": "1252529",
    "end": "1260119"
  },
  {
    "text": "is the first application of deep learning to a climate science data set I needed to convince myself that",
    "start": "1260119",
    "end": "1265960"
  },
  {
    "text": "convolutional architectures would work at all so we're going to start slow we can start simple and say let's try",
    "start": "1265960",
    "end": "1271639"
  },
  {
    "text": "supervised convolution architectures and then once that works then we'll try semi-supervised architectures so let's",
    "start": "1271639",
    "end": "1278419"
  },
  {
    "text": "start with supervised learning so again supervised learning is the paradigm wherein you have a lot of data",
    "start": "1278419",
    "end": "1284960"
  },
  {
    "text": "and you have labels for for for that dataset so our training input is going to be nicely cropped nicely centered",
    "start": "1284960",
    "end": "1292639"
  },
  {
    "text": "patches that have labels so so I mentioned that the climate science",
    "start": "1292639",
    "end": "1298309"
  },
  {
    "text": "community has spent a bunch of time say trying to better understand tropical cyclones so we have some heuristics that",
    "start": "1298309",
    "end": "1304669"
  },
  {
    "text": "the community seems to have converged on which we caught up and that's what we use for producing labels similarly",
    "start": "1304669",
    "end": "1312289"
  },
  {
    "text": "people by hand in some cases have manually annotated and said oh I know that there is a certain event that",
    "start": "1312289",
    "end": "1317599"
  },
  {
    "text": "happened on a certain date that hit California and so on there are very few examples of these but they do exist now",
    "start": "1317599",
    "end": "1323749"
  },
  {
    "text": "this list is not exhaustive we actually have dozens of extreme events that we on a track and one of the goals here is",
    "start": "1323749",
    "end": "1329720"
  },
  {
    "text": "going to be to get at the other classes of events but we got to start here because we need to be able to operate on",
    "start": "1329720",
    "end": "1335570"
  },
  {
    "text": "a fluid flow simulation output and see we can find patterns alright so for simplicity how about we just focus on",
    "start": "1335570",
    "end": "1340909"
  },
  {
    "text": "tropical cyclones so I have nice cropped centered patches of the assimilation",
    "start": "1340909",
    "end": "1346399"
  },
  {
    "text": "dataset so I give it labels I say this patch contains a tropical cyclone and",
    "start": "1346399",
    "end": "1351620"
  },
  {
    "text": "this patch does not contain a tropical cyclone so this is a classic binary classification test that's all that the",
    "start": "1351620",
    "end": "1357830"
  },
  {
    "text": "network needs to do so once the network has trained itself on say 10,000 positive and 10,000 negative examples",
    "start": "1357830",
    "end": "1364360"
  },
  {
    "text": "I'm gonna give it some held out data some hello test data and then I'm gonna ask this question well you know how well",
    "start": "1364360",
    "end": "1370639"
  },
  {
    "text": "do you think that this new patch has a tropical cyclone in it yes or no so that's going to be the boundary",
    "start": "1370639",
    "end": "1375889"
  },
  {
    "text": "classification task alright so some details on the image path size the",
    "start": "1375889",
    "end": "1381950"
  },
  {
    "text": "variables the channels that that went into this and then how many examples we",
    "start": "1381950",
    "end": "1387080"
  },
  {
    "text": "were able to provide now you'll note that we do not have a hundred thousand or a million examples so that's always",
    "start": "1387080",
    "end": "1393710"
  },
  {
    "text": "going to be a constraint to keep in mind perhaps this constraint applies to some of the applications commercial",
    "start": "1393710",
    "end": "1398840"
  },
  {
    "text": "applications that you care about now what we ended up doing again by by some",
    "start": "1398840",
    "end": "1404870"
  },
  {
    "text": "experimentation we figured out so given that we don't have a lot of data what",
    "start": "1404870",
    "end": "1409970"
  },
  {
    "text": "sort of a relatively shallow architecture could actually solve this problem so for tropical cyclones we",
    "start": "1409970",
    "end": "1416330"
  },
  {
    "text": "figured out that to convolution layers interspersed with two max pooling layers",
    "start": "1416330",
    "end": "1422809"
  },
  {
    "text": "and then a fully connected layer right at the end seems to be sufficient for solving the problem and it does not over",
    "start": "1422809",
    "end": "1429710"
  },
  {
    "text": "train or all fit the data that we have and the similar a similar story holds",
    "start": "1429710",
    "end": "1435379"
  },
  {
    "text": "true for the other two patterns that we care about now here are some results so",
    "start": "1435379",
    "end": "1440720"
  },
  {
    "start": "1438000",
    "end": "1438000"
  },
  {
    "text": "so this table essentially lists accuracy so for the test data that was held out",
    "start": "1440720",
    "end": "1448370"
  },
  {
    "text": "for the binary classification task you know what percentage of the time was was",
    "start": "1448370",
    "end": "1454250"
  },
  {
    "text": "the deep learning conventional architecture able to correctly classify tropical cyclones so the convolutional",
    "start": "1454250",
    "end": "1461179"
  },
  {
    "text": "results are all the way to the right and then we you know for due diligence we",
    "start": "1461179",
    "end": "1466519"
  },
  {
    "text": "did implement random forests and support vector machines and k-nearest neighbors and logistic regression and generally I would say",
    "start": "1466519",
    "end": "1474110"
  },
  {
    "text": "that in indeed convolutional nets do get the best performance but I guess the",
    "start": "1474110",
    "end": "1481730"
  },
  {
    "text": "fact that was not appreciated by me till I lie coded up the other methods was that this is it turns out that this is a",
    "start": "1481730",
    "end": "1487910"
  },
  {
    "text": "hard problem most of the numbers here are above 85% to begin with so I think",
    "start": "1487910",
    "end": "1492920"
  },
  {
    "text": "this is a really important lesson learned which is you know one should not use the most powerful hammer there is",
    "start": "1492920",
    "end": "1499220"
  },
  {
    "text": "right now which is deep learning on any single data set you could probably start slow start with something that's",
    "start": "1499220",
    "end": "1505220"
  },
  {
    "text": "interpretable like logistic regression or SVM's or K nearest neighbors get a",
    "start": "1505220",
    "end": "1510350"
  },
  {
    "text": "sense for how hard the problem really is and then you know move out to deep learning if you really need that extra",
    "start": "1510350",
    "end": "1515600"
  },
  {
    "text": "accuracy I'll note that all of these methods have some free parameters that",
    "start": "1515600",
    "end": "1521630"
  },
  {
    "text": "you need to tweak so for K K nearest neighbors you know perhaps there is the choice of K that you need to somehow decide upon",
    "start": "1521630",
    "end": "1527380"
  },
  {
    "text": "for support vector machines you need to decide on the form of a form of the kernel function for example random",
    "start": "1527380",
    "end": "1534080"
  },
  {
    "text": "forest you need to decide on how many trees you want to have and how much what the depth of the trees should be and so",
    "start": "1534080",
    "end": "1540560"
  },
  {
    "text": "on and so forth convolutional architectures of course there are many more parameters you need to decide upon so there is a tool called Spearman that",
    "start": "1540560",
    "end": "1546800"
  },
  {
    "text": "we've been using to with some success at dusk so for all of these methods we use",
    "start": "1546800",
    "end": "1553070"
  },
  {
    "text": "pavement and we figure out what the best choice of parameter might be and then we go with a choice and then proceed with",
    "start": "1553070",
    "end": "1559190"
  },
  {
    "text": "with the training all right so anyway so I think so far things are promising I",
    "start": "1559190",
    "end": "1564280"
  },
  {
    "text": "think I convinced myself that supervised convolution architectures could work on",
    "start": "1564280",
    "end": "1569810"
  },
  {
    "text": "on the output of a climate data set so let's take it another take it up to",
    "start": "1569810",
    "end": "1575660"
  },
  {
    "start": "1573000",
    "end": "1573000"
  },
  {
    "text": "another level so far semi-supervised learning what I would really like to do is instead of having three different",
    "start": "1575660",
    "end": "1582260"
  },
  {
    "text": "networks that do a great job at finding three separate patterns I would like to have one unified architecture a single",
    "start": "1582260",
    "end": "1588560"
  },
  {
    "text": "network that can find all weather patterns I would like that network do",
    "start": "1588560",
    "end": "1593960"
  },
  {
    "text": "not just do binary classification but I would like it to predict where the bounding box is so I need to find out",
    "start": "1593960",
    "end": "1599810"
  },
  {
    "text": "where the center of the pattern is and then the space extent of the storm and then this last",
    "start": "1599810",
    "end": "1605549"
  },
  {
    "text": "point I mean this is sort of the Holy Grail which is I know going in that I'm going to be able to provide only labels",
    "start": "1605549",
    "end": "1611940"
  },
  {
    "text": "for say three kinds of events but I know that there are many other types of events for which I don't have labels so",
    "start": "1611940",
    "end": "1617940"
  },
  {
    "text": "I would like to build in into this architecture the capability for it to discover new patterns so this is the the",
    "start": "1617940",
    "end": "1626970"
  },
  {
    "start": "1625000",
    "end": "1625000"
  },
  {
    "text": "convolutional architecture that we ended up with so on the on the left here is is",
    "start": "1626970",
    "end": "1633480"
  },
  {
    "text": "the encoder so this is the classic picture the image net picture or the supervised picture that I showed you",
    "start": "1633480",
    "end": "1639659"
  },
  {
    "text": "earlier a bunch of convolution and pooling layers and so on and so forth till you reach a certain compact",
    "start": "1639659",
    "end": "1646049"
  },
  {
    "text": "representation of the weights now we'll just stop here for a moment ignore the the piece on the right but",
    "start": "1646049",
    "end": "1652740"
  },
  {
    "text": "just if you look at the the green piece on the bottom we're going to be operating on this this compact",
    "start": "1652740",
    "end": "1659909"
  },
  {
    "text": "representation which is called the bottleneck layer and we will ask the bottleneck layer to predict bounding",
    "start": "1659909",
    "end": "1665760"
  },
  {
    "text": "boxes so that's a regression task and then also predict labels that's a classification task so that's what we're",
    "start": "1665760",
    "end": "1671010"
  },
  {
    "text": "gonna do so from left to the bottleneck layer to the bottom the the green box this is a classic supervised problem",
    "start": "1671010",
    "end": "1677520"
  },
  {
    "text": "nothing new there the peas that's new is is the part on the right the the decoder peas so essentially what what the",
    "start": "1677520",
    "end": "1685320"
  },
  {
    "text": "decoder piece does is it operates on this bottleneck layer and then it's going to progressively in some sense I",
    "start": "1685320",
    "end": "1691919"
  },
  {
    "text": "guess up sample the the features which are learnt here till it gets an image",
    "start": "1691919",
    "end": "1697080"
  },
  {
    "text": "which is of the same dimensions as the input image and the objective that it",
    "start": "1697080",
    "end": "1702360"
  },
  {
    "text": "has the objective of the decoder piece is to make sure that it can minimize the reconstruction error between the input",
    "start": "1702360",
    "end": "1708179"
  },
  {
    "text": "and the output so this network is essentially trying to do two things at the same time one from left to right so",
    "start": "1708179",
    "end": "1714960"
  },
  {
    "text": "this is called an auto encoder it will take the input filter it down filter it",
    "start": "1714960",
    "end": "1720450"
  },
  {
    "text": "up and try to minimize the reconstruction quality between the input and the output and the second thing is",
    "start": "1720450",
    "end": "1725700"
  },
  {
    "text": "going to simultaneously try to do is to for the given patterns for which it has labels and bounding boxes it will try to",
    "start": "1725700",
    "end": "1732149"
  },
  {
    "text": "do the supervised classification and supervised regression task all right so we recorded this up and in",
    "start": "1732149",
    "end": "1740400"
  },
  {
    "start": "1739000",
    "end": "1739000"
  },
  {
    "text": "general the results look look reasonable I mean this is pretty much work in progress on the left or sixteen images",
    "start": "1740400",
    "end": "1746910"
  },
  {
    "text": "which are the which is just a snapshot of a certain time instant in the climate",
    "start": "1746910",
    "end": "1753480"
  },
  {
    "text": "data set so these are all different fields and on the right the panel of four by four are the reconstructed",
    "start": "1753480",
    "end": "1759390"
  },
  {
    "text": "variants as the output of the auto encoder on the right so in general I would say that the spatial patterns are",
    "start": "1759390",
    "end": "1764760"
  },
  {
    "text": "being captured quite well now how about the the classification and regression",
    "start": "1764760",
    "end": "1770820"
  },
  {
    "start": "1767000",
    "end": "1767000"
  },
  {
    "text": "task so in this case ground truth is in green so all the green boxes here with",
    "start": "1770820",
    "end": "1777180"
  },
  {
    "text": "the TC label means that there is a we know that the ground truth is",
    "start": "1777180",
    "end": "1782250"
  },
  {
    "text": "essentially a tropical cyclone at that location of a certain bounding box sighs there's a green bounding box here for an",
    "start": "1782250",
    "end": "1788010"
  },
  {
    "text": "ATC there is a green bounding box here for an atmospheric River and the network again the single network is now trying",
    "start": "1788010",
    "end": "1794790"
  },
  {
    "text": "to predict these three classes so in this case you know it's predicted an extra pikal cyclone here which seems to",
    "start": "1794790",
    "end": "1801780"
  },
  {
    "text": "line up pretty well it predicts an atmospheric River here the the bounding box is not quite size right but at least",
    "start": "1801780",
    "end": "1807360"
  },
  {
    "text": "the the position is fine and it does maybe a reasonable job in in these locations as well so there's this work",
    "start": "1807360",
    "end": "1813900"
  },
  {
    "text": "to do but it seems to be getting the the patterns right now how about pattern",
    "start": "1813900",
    "end": "1819570"
  },
  {
    "text": "discovery again this is this is sort of the the hard one so I talked about this",
    "start": "1819570",
    "end": "1824610"
  },
  {
    "text": "bottleneck layer and again to the extent that this network is doing the right thing we should be able to cluster the",
    "start": "1824610",
    "end": "1831210"
  },
  {
    "text": "the features that the bottleneck layer has learnt look at the clustering structure and see how well the clusters",
    "start": "1831210",
    "end": "1837000"
  },
  {
    "text": "corresponding to known events are separated so in this case you know blues",
    "start": "1837000",
    "end": "1842940"
  },
  {
    "text": "might be extra pickle cyclones and red might be tropical cyclones and greens might be at mystic rivers and I",
    "start": "1842940",
    "end": "1848870"
  },
  {
    "text": "apologize for the quality of the display here but the grey dots are different other other feature vectors the colored",
    "start": "1848870",
    "end": "1856470"
  },
  {
    "text": "ones are features that we know correspond to label data so what I was",
    "start": "1856470",
    "end": "1862020"
  },
  {
    "text": "hoping and to some extent I think is true the blue stuff is interspersed throughout but definitely the green",
    "start": "1862020",
    "end": "1867390"
  },
  {
    "text": "stuff is it's slightly separated and and some of these these areas so so",
    "start": "1867390",
    "end": "1874300"
  },
  {
    "text": "this this chunk here definitely corresponds to tropical systems that are",
    "start": "1874300",
    "end": "1879490"
  },
  {
    "text": "evolving and and these this chunk here corresponds to weaker systems so I I",
    "start": "1879490",
    "end": "1885280"
  },
  {
    "text": "know that this is not perfect but eventually I think our hope is that if",
    "start": "1885280",
    "end": "1890559"
  },
  {
    "text": "you can get a good separation of clusters in this low dimension space then the question then becomes you know",
    "start": "1890559",
    "end": "1895750"
  },
  {
    "text": "if we find a tight cluster which is separate from these known labels can be",
    "start": "1895750",
    "end": "1900820"
  },
  {
    "text": "associated new semantic label semantic type to that cluster so that's that's our hope for discovering new patterns",
    "start": "1900820",
    "end": "1908580"
  },
  {
    "text": "all right so so I think hopefully you have a sense for you know that we made",
    "start": "1908580",
    "end": "1916240"
  },
  {
    "text": "some progress along by using supervised convolutional architectures also semi-supervised architectures now the",
    "start": "1916240",
    "end": "1921700"
  },
  {
    "text": "problem is is scaling how do we get these things to run fast so again for those of you who have some experience with deep learning you may know that it",
    "start": "1921700",
    "end": "1928929"
  },
  {
    "text": "takes a long time for these networks to converge so in our experience I think when we apply it to scientific data sets",
    "start": "1928929",
    "end": "1935170"
  },
  {
    "start": "1929000",
    "end": "1929000"
  },
  {
    "text": "if you want to process say tens of gigabytes of data it can easily take several days for the network's to train",
    "start": "1935170",
    "end": "1941860"
  },
  {
    "text": "and we at this point in time we easily have tens of terabytes I mean III the",
    "start": "1941860",
    "end": "1947200"
  },
  {
    "text": "climate data set that I'm showing you is 30 terabytes in size and there's there's more waiting to be processed so if it's",
    "start": "1947200",
    "end": "1954309"
  },
  {
    "text": "going to take you weeks and maybe months to train your network then you're really",
    "start": "1954309",
    "end": "1960100"
  },
  {
    "text": "not gonna be able to experiment at all so I mentioned this hyper parameter tuning problem which is you have to come",
    "start": "1960100",
    "end": "1965740"
  },
  {
    "text": "up with the right architecture to begin with and the hypervisor choices might",
    "start": "1965740",
    "end": "1970809"
  },
  {
    "text": "comprise of how many layers do we have how many filters do we use the size of the filter is something called striding",
    "start": "1970809",
    "end": "1976960"
  },
  {
    "text": "the kind of non-linearity you want to apply in the pooling or the learning",
    "start": "1976960",
    "end": "1982030"
  },
  {
    "text": "rate that you want might wanna apply sometimes people change the learning rate as the training proceeds",
    "start": "1982030",
    "end": "1987309"
  },
  {
    "text": "choice of different optimizer so on and so forth so this is a seven to eight dimension space that does need to be",
    "start": "1987309",
    "end": "1992440"
  },
  {
    "text": "explored somehow but if each run is going to take a week or a month this is",
    "start": "1992440",
    "end": "1997660"
  },
  {
    "text": "just not happening senia so performance so single node performance and more",
    "start": "1997660",
    "end": "2003610"
  },
  {
    "text": "you know scaling is absolutely key going forward so I guess I just won't share",
    "start": "2003610",
    "end": "2010030"
  },
  {
    "start": "2007000",
    "end": "2007000"
  },
  {
    "text": "you know the the stack that exists the deep learning stack that that's there in practice right now so as a practitioner",
    "start": "2010030",
    "end": "2017320"
  },
  {
    "text": "there are a number of frameworks that you can use and tensorflow and cafe and tiana are the ones that we use at the",
    "start": "2017320",
    "end": "2023170"
  },
  {
    "text": "lab but there are high-level frameworks where it's much easier for you to set up",
    "start": "2023170",
    "end": "2028260"
  },
  {
    "text": "set up a network easily like Harrison lasagna now as you think about scaling actually",
    "start": "2028260",
    "end": "2034600"
  },
  {
    "text": "much of the magic is underneath the deep learning framework so there are multi node libraries that you have to keep in mind so perhaps you can use MPI or gr PC",
    "start": "2034600",
    "end": "2041940"
  },
  {
    "text": "as the library Intel has now developed a new library called ml SL now single node",
    "start": "2041940",
    "end": "2048908"
  },
  {
    "text": "performance is absolutely key so if you are using a GPU then ku DNN does a really good job at getting you that",
    "start": "2048909",
    "end": "2054100"
  },
  {
    "text": "performance but on a CPU you will probably need to turn to M care and hardware of course so we use Knights",
    "start": "2054100",
    "end": "2061780"
  },
  {
    "text": "landing there are other flavors of multi-core CPUs coming up shortly and GPUs are of course a very competitive",
    "start": "2061780",
    "end": "2068320"
  },
  {
    "text": "option at this point in time so for all the scaling results that I'm going to talk about next the stack for us is",
    "start": "2068320",
    "end": "2076810"
  },
  {
    "text": "going to be cafe and in particular Intel cafe we used ml SL for as as the multi",
    "start": "2076810",
    "end": "2082780"
  },
  {
    "text": "node library we used mkl for single node performance and then knights landing is",
    "start": "2082780",
    "end": "2088000"
  },
  {
    "text": "the is the chip that we used so a few words I guess on the target hardware",
    "start": "2088000",
    "end": "2093429"
  },
  {
    "start": "2090000",
    "end": "2090000"
  },
  {
    "text": "platform so I I work at the nernst supercomputing Center and the machine that we ended up using for these tests",
    "start": "2093429",
    "end": "2099730"
  },
  {
    "text": "was the the quarry Cray XE 40 supercomputer and this machine has 9600 Knights landing nodes",
    "start": "2099730",
    "end": "2106420"
  },
  {
    "text": "so in theory it's capable of 30 para flop class performance hundreds of",
    "start": "2106420",
    "end": "2111820"
  },
  {
    "text": "terabytes of memory IO is a challenge for deep learning so we ended up staging",
    "start": "2111820",
    "end": "2116830"
  },
  {
    "text": "a lot of our data not on a lustre or a gpfs filesystem because those typically don't keep up but we ended up using a",
    "start": "2116830",
    "end": "2124390"
  },
  {
    "text": "big SSD pool called called the data Bob which is 1.5 petabytes its size and it",
    "start": "2124390",
    "end": "2131619"
  },
  {
    "text": "can support io rate of one-and-a-half terabytes second so a little more specifics on the input",
    "start": "2131619",
    "end": "2139200"
  },
  {
    "start": "2137000",
    "end": "2137000"
  },
  {
    "text": "data set that we ended up using for the for this study so the input images are 768 by 768 in size they have 16 channels",
    "start": "2139200",
    "end": "2147210"
  },
  {
    "text": "overall the data set as is in in aggregate is 15 terabytes and it's",
    "start": "2147210",
    "end": "2152610"
  },
  {
    "text": "comprised of 400,000 images and the architecture that we ended up using has 9 convolution layers and 5 decomposition",
    "start": "2152610",
    "end": "2159660"
  },
  {
    "text": "layers and the parameters all of the filters that the weights are about 300",
    "start": "2159660",
    "end": "2164850"
  },
  {
    "text": "megabytes in size all right so on the single node side of things I mentioned",
    "start": "2164850",
    "end": "2172200"
  },
  {
    "start": "2167000",
    "end": "2167000"
  },
  {
    "text": "the xeon phi the knights landing ship we used Intel Cafe with the mkl 2017 library we did have to optimize various",
    "start": "2172200",
    "end": "2181890"
  },
  {
    "text": "layers the deconvolution layer in particular was not yet optimized for K&L so that's something that we ended up",
    "start": "2181890",
    "end": "2187590"
  },
  {
    "text": "doing and this is the performance that we get for our architecture so a couple",
    "start": "2187590",
    "end": "2193110"
  },
  {
    "start": "2189000",
    "end": "2189000"
  },
  {
    "text": "of I guess two things are being plotted here in red is the amount of time that's",
    "start": "2193110",
    "end": "2198750"
  },
  {
    "text": "been taken up by different layers so there are a bunch of deconvolution layers in the backward pass and",
    "start": "2198750",
    "end": "2204570"
  },
  {
    "text": "convolution layers in the forward pass and so on so red indicates how much time is being spent in various layers and in",
    "start": "2204570",
    "end": "2212310"
  },
  {
    "text": "black the the vertical plots or what the performance level is in terms of the teraflop rate that we are able to",
    "start": "2212310",
    "end": "2218790"
  },
  {
    "text": "achieve so in general we are able to get anywhere from 1 to 4 teraflop on a",
    "start": "2218790",
    "end": "2225180"
  },
  {
    "text": "single KL node after we did the octave 8/8 the optimization which is not not",
    "start": "2225180",
    "end": "2230880"
  },
  {
    "text": "bad in there's there's only so much room that you have on on a K&L chip and I'll",
    "start": "2230880",
    "end": "2236940"
  },
  {
    "text": "note that some GPUs of course can do more on a single node basis but one to four times lops is is not bad at all for",
    "start": "2236940",
    "end": "2243330"
  },
  {
    "text": "4 K and L so the real piece here is is in the multi node strategy so now that",
    "start": "2243330",
    "end": "2250440"
  },
  {
    "start": "2246000",
    "end": "2246000"
  },
  {
    "text": "we know you can get one to four teraflops on a single node how far can you really push it out across this",
    "start": "2250440",
    "end": "2255770"
  },
  {
    "text": "$9,600 supercomputer that we have now a few options one is to use data",
    "start": "2255770",
    "end": "2261600"
  },
  {
    "text": "parallelism where and you take this 400,000 images and then you're going to just break it up into pieces and each",
    "start": "2261600",
    "end": "2267810"
  },
  {
    "text": "node is going to be processing a small fraction of the image a small fraction of the dataset so that's the",
    "start": "2267810",
    "end": "2273900"
  },
  {
    "text": "typical data parallelism strategy that's used and that's what we're gonna be using for this for this exercise now",
    "start": "2273900",
    "end": "2281700"
  },
  {
    "text": "some some uses some researchers also use model parallelism which is we're going",
    "start": "2281700",
    "end": "2287430"
  },
  {
    "text": "to take a big network we will actually break up the network into pieces and perhaps have the same data set on different nodes and we will figure out a",
    "start": "2287430",
    "end": "2296670"
  },
  {
    "text": "way to get the the networks to synchronize with each other all right so a bunch of optimizations here I'm going",
    "start": "2296670",
    "end": "2302760"
  },
  {
    "text": "to walk you through some visuals for for these optimizations but it was really important to get to develop a hybrid",
    "start": "2302760",
    "end": "2308250"
  },
  {
    "text": "strategy for for synchronizing parameters we had to do some topology",
    "start": "2308250",
    "end": "2314940"
  },
  {
    "text": "aware placement and in putting the parameter servers and then we had to dedicate some nodes purely to do to play",
    "start": "2314940",
    "end": "2321720"
  },
  {
    "text": "the role of a parameter server I'll note that just like we use cafe for the single node stuff and mkl 20:17 in this",
    "start": "2321720",
    "end": "2329070"
  },
  {
    "text": "case we use the new MLS cell library which gets much better performance compared to baseline MPI in terms of",
    "start": "2329070",
    "end": "2335670"
  },
  {
    "text": "bandwidth utilization on our on our network all right so just on visuals so",
    "start": "2335670",
    "end": "2341990"
  },
  {
    "start": "2338000",
    "end": "2338000"
  },
  {
    "text": "I guess there are two options two extremes perhaps four for converging on",
    "start": "2341990",
    "end": "2349410"
  },
  {
    "text": "parameters as as different nodes see data sets so some conventions here so a worker node will see a small fraction of",
    "start": "2349410",
    "end": "2356460"
  },
  {
    "text": "the data set it will try to update its weight because it knows what the error is it's going to compute gradients is",
    "start": "2356460",
    "end": "2362760"
  },
  {
    "text": "going to do the backdrop and they'll compute the updated weights so one",
    "start": "2362760",
    "end": "2367859"
  },
  {
    "text": "option is that all the workers work in lockstep so as everyone sees its group",
    "start": "2367859",
    "end": "2372869"
  },
  {
    "text": "of ten images they update the weights and then they do an all reduce everyone gets the latest and the latest estimate",
    "start": "2372869",
    "end": "2379320"
  },
  {
    "text": "for what the entire networks weights are so that's the synchronous model of",
    "start": "2379320",
    "end": "2384930"
  },
  {
    "text": "execution the other extreme is to do it asynchronously so everyone has ten",
    "start": "2384930",
    "end": "2390180"
  },
  {
    "text": "images say they go ahead and they process their ten images as soon as they",
    "start": "2390180",
    "end": "2396119"
  },
  {
    "text": "they are done with the with the backdrop then they're gonna just broadcast",
    "start": "2396119",
    "end": "2401700"
  },
  {
    "text": "there updates to an asynchronous parameter server and then will be the job of that parameter server to",
    "start": "2401700",
    "end": "2407130"
  },
  {
    "text": "reconcile differences and send the updates out to the other nodes so some trade-offs here again these are two",
    "start": "2407130",
    "end": "2413370"
  },
  {
    "text": "extremes for synchronous scaling where everyone is moving in lockstep compared",
    "start": "2413370",
    "end": "2419100"
  },
  {
    "text": "to a serial implementations if you were to do the same task on a serial on a single node you will likely have the",
    "start": "2419100",
    "end": "2425400"
  },
  {
    "text": "same number of iterations for convergence the the negatives the downsides here are that if any one of",
    "start": "2425400",
    "end": "2431820"
  },
  {
    "text": "your nodes fails for whatever reason or lags behind that will essentially slow",
    "start": "2431820",
    "end": "2437730"
  },
  {
    "text": "everyone down now on the asynchronous side you can move faster again people",
    "start": "2437730",
    "end": "2444390"
  },
  {
    "text": "are not constrained to block and and communicate so you can certainly move faster there is more robustness to node",
    "start": "2444390",
    "end": "2451320"
  },
  {
    "text": "failure so if one of the nodes goes down it's not the end of the world but",
    "start": "2451320",
    "end": "2457080"
  },
  {
    "text": "chances are high that you will need many many more iterations to converge compared to the serial implementation",
    "start": "2457080",
    "end": "2463610"
  },
  {
    "text": "alright so clearly we don't have to choose extremes so you don't have to I mean this is a spectrum you don't have",
    "start": "2463610",
    "end": "2469080"
  },
  {
    "start": "2464000",
    "end": "2464000"
  },
  {
    "text": "to be fully synchronous or fully asynchronous so you can be hybrid and essentially that's the strategy that we ended up going with so we break up our",
    "start": "2469080",
    "end": "2476510"
  },
  {
    "text": "our supercomputer into groups which are going to be executing synchronously one",
    "start": "2476510",
    "end": "2483630"
  },
  {
    "text": "of the nodes in that group will be responsible for communicating its",
    "start": "2483630",
    "end": "2488850"
  },
  {
    "text": "updates which reflect the the latest updates for the compute group 1 2 and",
    "start": "2488850",
    "end": "2494730"
  },
  {
    "text": "asynchronous parameter server and you know we'll see where that takes us so we can change by by changing the number of",
    "start": "2494730",
    "end": "2501660"
  },
  {
    "text": "synchronous compute groups we can essentially move along the spectrum the",
    "start": "2501660",
    "end": "2508020"
  },
  {
    "text": "other thing that we ended up doing apart from this hybrid strategy is to dedicate parameter servers for every layer of the",
    "start": "2508020",
    "end": "2513810"
  },
  {
    "text": "network so for example here in this schematic there are 4 layers in the network so we dedicate one parameter",
    "start": "2513810",
    "end": "2521010"
  },
  {
    "text": "server to handle the traffic coming in from all of the different groups another",
    "start": "2521010",
    "end": "2526860"
  },
  {
    "text": "node for the second layer so on and so forth there are some more advanced",
    "start": "2526860",
    "end": "2532680"
  },
  {
    "start": "2531000",
    "end": "2531000"
  },
  {
    "text": "topology where placement so exactly you want to make sure that if you are within a synchronous group then you",
    "start": "2532680",
    "end": "2537840"
  },
  {
    "text": "don't really span racks on on a supercomputer certainly so we just make sure that when the run time comes up",
    "start": "2537840",
    "end": "2544230"
  },
  {
    "text": "that we take the topology of the network into account and try to minimize extra hops all right so here are some some",
    "start": "2544230",
    "end": "2551520"
  },
  {
    "start": "2550000",
    "end": "2550000"
  },
  {
    "text": "results so there are two configurations here one is a strong scaling configuration wherein we fix the overall",
    "start": "2551520",
    "end": "2558150"
  },
  {
    "text": "data set size and all we're going to be doing is to throw more and more nodes at",
    "start": "2558150",
    "end": "2563310"
  },
  {
    "text": "the problem so you would hope that things run faster and faster at least at the time to completion in terms of",
    "start": "2563310",
    "end": "2569040"
  },
  {
    "text": "processing the data set is faster so sure enough the the synchronous approach",
    "start": "2569040",
    "end": "2575369"
  },
  {
    "text": "stops scaling after some point so as we go from say 256 to 512 nodes the",
    "start": "2575369",
    "end": "2582150"
  },
  {
    "text": "synchronous approach stops scaling after that and and sort of flattens out tilde tilde 20 1024 node mark but the hybrid",
    "start": "2582150",
    "end": "2589980"
  },
  {
    "text": "strategy where and we played with having two groups so two synchronous groups that would communicate with each other",
    "start": "2589980",
    "end": "2595290"
  },
  {
    "text": "through an async through a parameter server or four groups that seems to scale better now a slide so this is most",
    "start": "2595290",
    "end": "2603510"
  },
  {
    "text": "likely the the configuration that you will likely have in your in your in your work you'll have a certain dataset size",
    "start": "2603510",
    "end": "2609390"
  },
  {
    "text": "and you want to maybe throw more more nodes at the problem if you are at a I",
    "start": "2609390",
    "end": "2615000"
  },
  {
    "text": "guess in a situation where you can come up with a weak scaling configuration where in each node will always have the",
    "start": "2615000",
    "end": "2621570"
  },
  {
    "text": "same amount of data to process but as I add more nodes I can add more data so",
    "start": "2621570",
    "end": "2627330"
  },
  {
    "text": "that's the the weak scaling configuration things seem to hold up fine for for our implementation so",
    "start": "2627330",
    "end": "2634340"
  },
  {
    "text": "synchronous is is in blue and the hybrid strategy seems to be scaling better than",
    "start": "2634340",
    "end": "2639570"
  },
  {
    "text": "when this then the single strategy Sony so things seem to be holding up reasonably well John I guess had a",
    "start": "2639570",
    "end": "2647220"
  },
  {
    "start": "2644000",
    "end": "2644000"
  },
  {
    "text": "pointed question for me earlier on well I mean does this converge at all so you might be processing the same amount of",
    "start": "2647220",
    "end": "2655020"
  },
  {
    "text": "data but is your network converging so for for climate we do see the loss",
    "start": "2655020",
    "end": "2661109"
  },
  {
    "text": "dropping and it seems to be leveling off so the hybrid strategy seems to be to be",
    "start": "2661109",
    "end": "2668580"
  },
  {
    "text": "building of now there is a slightly different problem where we applied",
    "start": "2668580",
    "end": "2674190"
  },
  {
    "text": "exactly the same architecture so the topology of a placement the hybrid tuning strategy so on and so forth",
    "start": "2674190",
    "end": "2680880"
  },
  {
    "text": "I could not create the same plot for for climate but there is a different signs from in in high energy physics and",
    "start": "2680880",
    "end": "2687180"
  },
  {
    "text": "essentially I think it does a nice job of visually representing what the difference might be between a",
    "start": "2687180",
    "end": "2692940"
  },
  {
    "text": "synchronous run and a hybrid run with with regards to conversions so so the",
    "start": "2692940",
    "end": "2700620"
  },
  {
    "text": "the dotted blue lines are the worst case scenario for for synchronous execution",
    "start": "2700620",
    "end": "2706470"
  },
  {
    "text": "so so that's this case again loss is plotted on the x axis and and number of",
    "start": "2706470",
    "end": "2712020"
  },
  {
    "text": "epochs or iterations is on the is on the x axis losses on the y axis solid blue",
    "start": "2712020",
    "end": "2717840"
  },
  {
    "text": "lines is the best case for synchronous so again when you run on 9000 nodes not",
    "start": "2717840",
    "end": "2725370"
  },
  {
    "text": "every run is going to be identical so they're going to be stragglers and and they're gonna be node failures and so on so forth",
    "start": "2725370",
    "end": "2730920"
  },
  {
    "text": "so the solid blue line is is is best synchronous run the dotted blue line is",
    "start": "2730920",
    "end": "2736380"
  },
  {
    "text": "the worst synchronous run and then we have hybrid in various flavors so with two groups with four groups with eight",
    "start": "2736380",
    "end": "2741960"
  },
  {
    "text": "groups and I guess if you look at the orange line for example and let's say",
    "start": "2741960",
    "end": "2748140"
  },
  {
    "text": "that we care about this particular loss level we want to get the loss to a certain certain level of acceptable",
    "start": "2748140",
    "end": "2753480"
  },
  {
    "text": "performance the orange line definitely gets to that loss level faster than the",
    "start": "2753480",
    "end": "2758700"
  },
  {
    "text": "blue line and you know there might be a gap of one point six six axes in the",
    "start": "2758700",
    "end": "2764700"
  },
  {
    "text": "number of iterations that it took for the synchronous to eventually catch up now the async which would be you know all nine thousand nodes doing their own",
    "start": "2764700",
    "end": "2770580"
  },
  {
    "text": "thing that will likely not not converge certainly in this time frame so nice so there is a benefit to do the hybrid",
    "start": "2770580",
    "end": "2777270"
  },
  {
    "text": "model all right so just to recap overall performance so on a single KNL Lord we",
    "start": "2777270",
    "end": "2783540"
  },
  {
    "start": "2779000",
    "end": "2779000"
  },
  {
    "text": "can get several teraflops for the 9600 node run which ran on six hundred",
    "start": "2783540",
    "end": "2790380"
  },
  {
    "text": "thousand-plus course we were able to achieve fifty fifteen pair flop per",
    "start": "2790380",
    "end": "2796050"
  },
  {
    "text": "second peak and then on a sustained basis we were able to get 13 pair of lobster so",
    "start": "2796050",
    "end": "2801740"
  },
  {
    "text": "so just to conclude I think I'm slowly getting out of time so just to recap I think you know",
    "start": "2801740",
    "end": "2808970"
  },
  {
    "start": "2802000",
    "end": "2802000"
  },
  {
    "text": "there's there's a lot of fighting genuine excitement in the field of AI and deep learning a lot of breakthroughs",
    "start": "2808970",
    "end": "2815390"
  },
  {
    "text": "in computer vision and speech and control systems in this presentation I",
    "start": "2815390",
    "end": "2820880"
  },
  {
    "text": "think I wanted to communicate that we can get the same success in scientific data as well so so deep learning has now",
    "start": "2820880",
    "end": "2828050"
  },
  {
    "text": "been established to be a viable tool for finding patterns in in climate data set and this can certainly help us in able",
    "start": "2828050",
    "end": "2833810"
  },
  {
    "text": "to characterize better what climate change will do in the future there was",
    "start": "2833810",
    "end": "2838820"
  },
  {
    "text": "representation challenges in in getting this to work so I think we proved that supervisor architectures can do a good",
    "start": "2838820",
    "end": "2845300"
  },
  {
    "text": "job in terms of detecting known patterns and then semi-supervised architectures",
    "start": "2845300",
    "end": "2850790"
  },
  {
    "text": "can potentially discover new patterns in in diffusion in terms of computation challenges I think we're certainly",
    "start": "2850790",
    "end": "2857540"
  },
  {
    "text": "getting reasonable performance on a single K&L node but then also I believe this is the largest multi node scaling",
    "start": "2857540",
    "end": "2864500"
  },
  {
    "text": "experiment that's been done with deep learning so far I want to thank a number of researchers from from Intel from",
    "start": "2864500",
    "end": "2870560"
  },
  {
    "text": "Stanford from Montreal and and of course bugzilla all right thanks very much I'm happy to take questions",
    "start": "2870560",
    "end": "2878230"
  },
  {
    "text": "Thanks provide I had one question so so when do we start saying the application",
    "start": "2882510",
    "end": "2888100"
  },
  {
    "text": "of your models towards predicting actual you know extreme weather events and I'm",
    "start": "2888100",
    "end": "2893890"
  },
  {
    "text": "sure you also waiting for that so that you can actually test in your models in the real world yes I think you know the",
    "start": "2893890",
    "end": "2900760"
  },
  {
    "text": "word prediction is unfortunately overloaded in the climate context so in this case we are not really doing",
    "start": "2900760",
    "end": "2906640"
  },
  {
    "text": "prediction we've already run the simulation out and all we want to do is to find patterns in that simulation so",
    "start": "2906640",
    "end": "2911680"
  },
  {
    "text": "in some sense the dataset is fixed that haven't been said there are people who are trying to look at deep learning so",
    "start": "2911680",
    "end": "2919000"
  },
  {
    "text": "variants of convolutional and lsdm architectures for predicting the entire state of the system for the next few",
    "start": "2919000",
    "end": "2924820"
  },
  {
    "text": "time steps so that work is also in progress and you know I think the",
    "start": "2924820",
    "end": "2929920"
  },
  {
    "text": "results are promising I mean there are limits to the predictability of the climate system and that's the property of the the system itself so it's a",
    "start": "2929920",
    "end": "2936720"
  },
  {
    "text": "nonlinear chaotic system so we know that we cannot predict the the state of the",
    "start": "2936720",
    "end": "2941860"
  },
  {
    "text": "system beyond two weeks but to what extent these convolutional STM",
    "start": "2941860",
    "end": "2947890"
  },
  {
    "text": "architectures can do a good job better than the climate models that remains to",
    "start": "2947890",
    "end": "2953080"
  },
  {
    "text": "be seen",
    "start": "2953080",
    "end": "2955320"
  },
  {
    "text": "curiously if you saw you know in your kind of training in your encoder and",
    "start": "2961160",
    "end": "2966270"
  },
  {
    "text": "auto encoder and decoder any insights about the fundamental dimensionality of the data set right so you have this I'm",
    "start": "2966270",
    "end": "2973710"
  },
  {
    "text": "sorry what was the question about any insights on the fundamental dimensionality of the data set right so",
    "start": "2973710",
    "end": "2979710"
  },
  {
    "text": "like what's the minimum number of nodes that it can be brought down to yeah so",
    "start": "2979710",
    "end": "2988430"
  },
  {
    "text": "you know in many ways we do not want to artificially constrain the data set size",
    "start": "2988430",
    "end": "2993780"
  },
  {
    "text": "right so the 768 by 768 image patch that's that's the that's the native",
    "start": "2993780",
    "end": "3000170"
  },
  {
    "text": "spatial resolution of the data set one could course on it I guess but we",
    "start": "3000170",
    "end": "3005780"
  },
  {
    "text": "found that we were able to get autoencoders to work at that resolution reasonably well and in terms of channels",
    "start": "3005780",
    "end": "3012050"
  },
  {
    "text": "again we we sort of stuck to the 16 channels that we had it is I know that",
    "start": "3012050",
    "end": "3020000"
  },
  {
    "text": "you know if you if one wanted to train say 1k by 1k patches or higher chances",
    "start": "3020000",
    "end": "3025400"
  },
  {
    "text": "are that you'll have a hard time to get autoencoders to work if time for one",
    "start": "3025400",
    "end": "3034880"
  },
  {
    "text": "more question",
    "start": "3034880",
    "end": "3037150"
  },
  {
    "text": "so I'm curious the original input is actually an output of simulation so is",
    "start": "3042970",
    "end": "3050360"
  },
  {
    "text": "just a visual representation why did you choose a visual representation or are",
    "start": "3050360",
    "end": "3055790"
  },
  {
    "text": "there other representations you could have used so the input is the simulation data so the simulation produces grids",
    "start": "3055790",
    "end": "3064880"
  },
  {
    "text": "and the grids have 768 by 768 points and then again each each point has 16 chance",
    "start": "3064880",
    "end": "3070520"
  },
  {
    "text": "on it so you know Allah is doing in the movies is just creating a visual representation by map by mapping one",
    "start": "3070520",
    "end": "3076490"
  },
  {
    "text": "field to an RGB image but we actually do not create RGB images we work on the raw double precision floating point eight",
    "start": "3076490",
    "end": "3082670"
  },
  {
    "text": "asses so let's thank prophet once again",
    "start": "3082670",
    "end": "3087890"
  },
  {
    "text": "go and probably would be hanging out here during the break for more questions",
    "start": "3087890",
    "end": "3092440"
  }
]
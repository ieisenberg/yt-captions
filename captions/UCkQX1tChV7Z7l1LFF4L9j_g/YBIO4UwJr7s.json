[
  {
    "text": "[Music]",
    "start": "1100",
    "end": "12390"
  },
  {
    "text": "thank you thank you very much for coming this morning second day a lot of content but I appreciate that you chose my",
    "start": "14679",
    "end": "21320"
  },
  {
    "text": "session so let's get started so imagine you have built this",
    "start": "21320",
    "end": "26960"
  },
  {
    "text": "simple servess architecture in the cloud you pick the pieces you want to use you connected them together and everything",
    "start": "26960",
    "end": "33680"
  },
  {
    "text": "just works like magic because well that's what Serv is right so much so",
    "start": "33680",
    "end": "39360"
  },
  {
    "text": "that you decide to go to production with it and of course all of a sudden Hell Breaks Loose and everything just starts",
    "start": "39360",
    "end": "46239"
  },
  {
    "text": "to fail in all possible shapes and forms and there's nothing that you have done",
    "start": "46239",
    "end": "52000"
  },
  {
    "text": "wrong at least that's what you think except for maybe not reading all the extensive documentation about all the",
    "start": "52000",
    "end": "58399"
  },
  {
    "text": "services and all the library that you are using but come on who does that nowadays anyway right so what's the next",
    "start": "58399",
    "end": "65760"
  },
  {
    "text": "logical step maybe you just swear of using the architecture or services in",
    "start": "65760",
    "end": "71520"
  },
  {
    "text": "question never and again because well they just don't work do they what's wrong with the cloud anyway",
    "start": "71520",
    "end": "77880"
  },
  {
    "text": "why doesn't it work maybe we just should go on Prem and build good old monoliths",
    "start": "77880",
    "end": "83360"
  },
  {
    "text": "anyone no good but purely statistically speaking we might consider that the",
    "start": "83360",
    "end": "89439"
  },
  {
    "text": "problem is not necessarily the cloud or the cloud provider maybe not even the",
    "start": "89439",
    "end": "94880"
  },
  {
    "text": "services or the architecture that you have built so what is it",
    "start": "94880",
    "end": "101159"
  },
  {
    "text": "then as Murphy's law says anything that can go wrong will go wrong now I",
    "start": "101159",
    "end": "107360"
  },
  {
    "text": "personally prefer the more extended version of it that says anything that can go wrong will go wrong and at the",
    "start": "107360",
    "end": "112799"
  },
  {
    "text": "worst possible time my name is Anahit I'm A leite Cloud",
    "start": "112799",
    "end": "118520"
  },
  {
    "text": "software engineer at the company call Solita and I'm personally based in Finland and I'm also an AWS data hero",
    "start": "118520",
    "end": "125159"
  },
  {
    "text": "and there was this funny thing that I noticed after becoming an AWS hero for some reason people just started to come",
    "start": "125159",
    "end": "131200"
  },
  {
    "text": "to me with this smirk on their faces saying so tell us now what's wrong with the cloud why doesn't it just work so",
    "start": "131200",
    "end": "138760"
  },
  {
    "text": "I'm finally here to answer that question or maybe not exactly that question but I",
    "start": "138760",
    "end": "145040"
  },
  {
    "text": "want us to look together at something that we as humans usually don't feel too comfort looking at",
    "start": "145040",
    "end": "152760"
  },
  {
    "text": "failures and I hope that this talk helps you to become a little bit more aware",
    "start": "152760",
    "end": "158200"
  },
  {
    "text": "and curious maybe to spot patterns that others don't necessarily see and also to",
    "start": "158200",
    "end": "163959"
  },
  {
    "text": "have the tools to ask questions and make conscious critical and informed decisions rather than believing in Magic",
    "start": "163959",
    "end": "170840"
  },
  {
    "text": "taking control into your own hands and finally become a little bit paranoid but",
    "start": "170840",
    "end": "177000"
  },
  {
    "text": "in a good way because to borrow words of Martin Gman in distributed system suspicion pessimism and paranoia",
    "start": "177000",
    "end": "184920"
  },
  {
    "text": "payoff but before we go any deeper into talking about distributed systems and all the failures let's briefly get back",
    "start": "184920",
    "end": "191480"
  },
  {
    "text": "to our story with Cirus architecture that was failing it actually had a prequel to it so once upon a time you",
    "start": "191480",
    "end": "199680"
  },
  {
    "text": "were a developer that started developing software that was supposed to run on a single machine probably somewhere in a",
    "start": "199680",
    "end": "205640"
  },
  {
    "text": "nonrem Data Center and everything you need to care about at that point where your so-called functional requirements",
    "start": "205640",
    "end": "212239"
  },
  {
    "text": "so that your code works and it does exactly what it's supposed to and it has as little bugs as",
    "start": "212239",
    "end": "218319"
  },
  {
    "text": "possible that was your definition of reliability excuse me of course there",
    "start": "218319",
    "end": "224439"
  },
  {
    "text": "could have been some occasional Hardware failures oops that was one but you",
    "start": "224439",
    "end": "229640"
  },
  {
    "text": "didn't really care much about them because things were mostly deterministic they everything either worked or it",
    "start": "229640",
    "end": "236599"
  },
  {
    "text": "didn't so next thing you know you find yourself from the cloud and maybe",
    "start": "236599",
    "end": "242480"
  },
  {
    "text": "building software uh that is supposed to run on Virtual machines in the cloud and all of a sudden you start developing",
    "start": "242480",
    "end": "248720"
  },
  {
    "text": "software that requires you to think about the so-called non-functional requirements so certain levels of",
    "start": "248720",
    "end": "255040"
  },
  {
    "text": "availability scalability also reliability and resilience get a whole new meaning and you still have all your",
    "start": "255040",
    "end": "262400"
  },
  {
    "text": "functional requirements you still need to make sure that your code works and has as little box as possible but the",
    "start": "262400",
    "end": "268040"
  },
  {
    "text": "complexity just went up not and uh you need to worry about so much more",
    "start": "268040",
    "end": "274840"
  },
  {
    "text": "now and also failures start to be somewhat more pronounced and somewhat",
    "start": "274840",
    "end": "279960"
  },
  {
    "text": "less deterministic welcome to the dark side wonderful world of distributed systems",
    "start": "279960",
    "end": "286759"
  },
  {
    "text": "where with great power comes great responsibility but things don't stop",
    "start": "286759",
    "end": "292080"
  },
  {
    "text": "there and before you know it you jump over to the serverless world where things just seem so easy again right you",
    "start": "292080",
    "end": "297759"
  },
  {
    "text": "just pick the services you connect them together pure magic of course Cloud providers take",
    "start": "297759",
    "end": "305280"
  },
  {
    "text": "care of these most important ilities for you things like reliability availability scalability and you're once again back",
    "start": "305280",
    "end": "312919"
  },
  {
    "text": "to caring about your own code and the fact that it works and has as little box as humanly possible you are not looking",
    "start": "312919",
    "end": "320039"
  },
  {
    "text": "for any machines around moreover the word servoless suggests that there are no machines that you need to be looking",
    "start": "320039",
    "end": "325840"
  },
  {
    "text": "around and things are just easy and nice and wonderful right though we know that",
    "start": "325840",
    "end": "332039"
  },
  {
    "text": "that's not exactly how the story goes because anything that can go wrong will go wrong so what is it that can go",
    "start": "332039",
    "end": "340880"
  },
  {
    "text": "wrong exactly so to set the stage let's talk a little bit about seress Cloud",
    "start": "340880",
    "end": "348199"
  },
  {
    "text": "distributed systems in really simplified terms and if the things I'm going to be talking about for next five minutes are",
    "start": "348199",
    "end": "354479"
  },
  {
    "text": "completely obvious to you try to bear with me for just a little while so this",
    "start": "354479",
    "end": "360400"
  },
  {
    "text": "system just a bunch of machines connected with a network and while it provides a lot of new and excited ways",
    "start": "360400",
    "end": "366919"
  },
  {
    "text": "to build Solutions and solve problems it also comes with a lot of new and exciting ways for things to go",
    "start": "366919",
    "end": "372599"
  },
  {
    "text": "wrong because resources we are using are not limited to a single machine anymore",
    "start": "372599",
    "end": "377880"
  },
  {
    "text": "they are distributed across multiple servers server racks data centers maybe even",
    "start": "377880",
    "end": "383280"
  },
  {
    "text": "geolocations and failure can happen in many different machines now instead of just one and those failures can of",
    "start": "383280",
    "end": "390520"
  },
  {
    "text": "course happen on many different levels it can be software failures or Hardware failures so things like operating system",
    "start": "390520",
    "end": "396240"
  },
  {
    "text": "hard drive network adapters anything can fail and all of those failures can happen in completely independently of",
    "start": "396240",
    "end": "402759"
  },
  {
    "text": "each other and in the most non-deterministic way possible but the worst thing here is",
    "start": "402759",
    "end": "407840"
  },
  {
    "text": "that all of those machines are talking to each other over a network and network is known for one thing in particular",
    "start": "407840",
    "end": "414880"
  },
  {
    "text": "Whenever there is any communication happening over the network it will eventually f",
    "start": "414880",
    "end": "421520"
  },
  {
    "text": "now any cloud is built on top of such distributed systems that's where their superpowers come from and the cloud",
    "start": "422639",
    "end": "428919"
  },
  {
    "text": "provider takes care of the most difficult part of managing the underlying distributed infrastructure",
    "start": "428919",
    "end": "434400"
  },
  {
    "text": "obstructing it away from us and giving us us access to this really huge pool of",
    "start": "434400",
    "end": "440400"
  },
  {
    "text": "shared resources that we can use like compute storage Network and they do that at a really massive scale that no",
    "start": "440400",
    "end": "447000"
  },
  {
    "text": "individual user could ever achieve but especially at the big scale if something",
    "start": "447000",
    "end": "452039"
  },
  {
    "text": "has a tiny little chance of happening it most certainly will and seress and fully managed",
    "start": "452039",
    "end": "459120"
  },
  {
    "text": "services are just a step up in this obstruction ladder they make the underlying",
    "start": "459120",
    "end": "464560"
  },
  {
    "text": "infrastructure seem almost invisible almost magical so much so that we",
    "start": "464560",
    "end": "470000"
  },
  {
    "text": "sometimes forget that it's there but by using those Ser Services we didn't just magically teleport to a different",
    "start": "470000",
    "end": "476280"
  },
  {
    "text": "reality we are still living in the very same massive physical world still using the very same underlying infrastructure",
    "start": "476280",
    "end": "483319"
  },
  {
    "text": "with all its complexity and of course this higher level of obstruction does make a lot of things easier just like a",
    "start": "483319",
    "end": "490039"
  },
  {
    "text": "higher level programming language would but it also comes with certain danger",
    "start": "490039",
    "end": "495759"
  },
  {
    "text": "being seemingly simple to use it might also give you this false sense of",
    "start": "495759",
    "end": "500840"
  },
  {
    "text": "security which might make spotting potential failures that much harder because they're also obstructed away",
    "start": "500840",
    "end": "506280"
  },
  {
    "text": "from you but the reality is failures didn't really they go anywhere they are still there embedded in the very same",
    "start": "506280",
    "end": "512640"
  },
  {
    "text": "distributed system that you are using waiting to show up as Le Leslie Lampert said in already in",
    "start": "512640",
    "end": "518360"
  },
  {
    "text": "1987 a distributed system is one in which the failure of a computer you didn't even know existed can render your",
    "start": "518360",
    "end": "524880"
  },
  {
    "text": "own computer unusable and we could rephrase this for seress architectures so in seress",
    "start": "524880",
    "end": "532120"
  },
  {
    "text": "architecture a seress architecture is one in which a failure of a computer you didn't even know or cared existed can",
    "start": "532120",
    "end": "538519"
  },
  {
    "text": "render your entire architecture unusable but of course failures with dist with servess are a bit different than",
    "start": "538519",
    "end": "545839"
  },
  {
    "text": "failures with you know distributed systems the you don't see them as let's",
    "start": "545839",
    "end": "551839"
  },
  {
    "text": "say blue screens or failures of the hardware they manifest in a bit different",
    "start": "551839",
    "end": "558480"
  },
  {
    "text": "way so let's take one last step in this obstruction ladder so we started with distributed system then we had the cloud",
    "start": "559480",
    "end": "566399"
  },
  {
    "text": "then we had servoless and now we are building distributed apption on top of serverless and distributed",
    "start": "566399",
    "end": "573040"
  },
  {
    "text": "systems so in essence what we do is we just split the problem at hand in smaller pieces we pick resources or",
    "start": "573040",
    "end": "579040"
  },
  {
    "text": "services for each piece we connect them together with things like messages or HTTP requests or",
    "start": "579040",
    "end": "585560"
  },
  {
    "text": "events and just like that we build ourselves a distributed application but all of those things are using network in",
    "start": "585560",
    "end": "592120"
  },
  {
    "text": "some shape or form so you might have noticed that in essence we are mirroring the underlying",
    "start": "592120",
    "end": "598480"
  },
  {
    "text": "distributed applic uh architecture that we are having of course distributed applications also give you this great",
    "start": "598480",
    "end": "604880"
  },
  {
    "text": "power of building applications in completely different way but just like the underlying distributed architecture",
    "start": "604880",
    "end": "611519"
  },
  {
    "text": "they come with certain complexity and certain trade-offs so architectures that",
    "start": "611519",
    "end": "616680"
  },
  {
    "text": "you are going to build are likely going to be complex every piece can fail at any given moment in the most non",
    "start": "616680",
    "end": "623240"
  },
  {
    "text": "deterministic way possible and whenever there is any communication happening over Network it it will eventually",
    "start": "623240",
    "end": "632160"
  },
  {
    "text": "fail and our special case of these kind of distributed architectures are the so-called data architectur of data",
    "start": "632160",
    "end": "638000"
  },
  {
    "text": "applications and with data applications we deal with collecting storing processing large amounts of data and the",
    "start": "638000",
    "end": "644399"
  },
  {
    "text": "data can be anything I mean log data maybe you have uh website clickstreams or iot data whatever data you have as",
    "start": "644399",
    "end": "651040"
  },
  {
    "text": "long as the volumes are large and on one hand that large volumes make spotting",
    "start": "651040",
    "end": "656120"
  },
  {
    "text": "potential issues somewhat easier because if something has a tiny chance of happening at a bigger scale it will but",
    "start": "656120",
    "end": "662200"
  },
  {
    "text": "also with data applications maybe failures are not as obvious as with let's say client facing applications and",
    "start": "662200",
    "end": "668639"
  },
  {
    "text": "if there was a failure while processing the incoming data nobody is going to resend you that data once the data is",
    "start": "668639",
    "end": "674480"
  },
  {
    "text": "gone it's gone and we'll see an example of such a",
    "start": "674480",
    "end": "679560"
  },
  {
    "text": "data architecture just in in a second so how do we make our distributed",
    "start": "679560",
    "end": "685000"
  },
  {
    "text": "architectures more resilient in the face of all those impending failures",
    "start": "685000",
    "end": "690279"
  },
  {
    "text": "while we are mirroring the underlying distributed system let's take a look at how Cloud providers are dealing with all",
    "start": "690279",
    "end": "695959"
  },
  {
    "text": "those failures they do have quite some experience with that right and of course there's a lot of complex algorithms and",
    "start": "695959",
    "end": "702240"
  },
  {
    "text": "mechanics at play I'm not going to go into them today but surprisingly two of the most effective tools for making",
    "start": "702240",
    "end": "709480"
  },
  {
    "text": "distributed architectures or distributed systems more resilient are also surprisingly simple or at least",
    "start": "709480",
    "end": "715600"
  },
  {
    "text": "seemingly simple they are timeouts and retries and those are the things that we",
    "start": "715600",
    "end": "722920"
  },
  {
    "text": "absolutely need to be aware of when we are building our distributed applications I call them these",
    "start": "722920",
    "end": "728600"
  },
  {
    "text": "superpowers because just like superpowers they can be extremely powerful but we need to be very Mindful",
    "start": "728600",
    "end": "734639"
  },
  {
    "text": "and careful about how we use them not to do more harm so you might have noticed that so",
    "start": "734639",
    "end": "741279"
  },
  {
    "text": "far I haven't mentioned any Cloud providers any Services nothing because all of those things are pretty much",
    "start": "741279",
    "end": "746639"
  },
  {
    "text": "Universal to any of them but now it's finally time to move on from our",
    "start": "746639",
    "end": "751920"
  },
  {
    "text": "fictional story and also time for me to confess that it probably wasn't as fictional as I wanted you to believe in",
    "start": "751920",
    "end": "758160"
  },
  {
    "text": "fact it's something that happened to me to some degree so I was working with a customer where we're building this",
    "start": "758160",
    "end": "765160"
  },
  {
    "text": "simple servess distributed architecture for near realtime data streaming at a pretty big scale I would say on a quiet",
    "start": "765160",
    "end": "771680"
  },
  {
    "text": "day we would have over half a terabyte of data coming in and we wanted to",
    "start": "771680",
    "end": "776760"
  },
  {
    "text": "collect and process and store that data and for that we had producer application that received the data we connected it",
    "start": "776760",
    "end": "782040"
  },
  {
    "text": "to Kinesis data stream and on the other end we connected an AWS Lambda to it and",
    "start": "782040",
    "end": "787519"
  },
  {
    "text": "just like that we built ourselves a magical data processing Pipeline and",
    "start": "787519",
    "end": "792760"
  },
  {
    "text": "things were just wonderful we're very happy until one day we realized we were actually losing data in many different",
    "start": "792760",
    "end": "799800"
  },
  {
    "text": "places and we had no idea it was happening thank you higher level of abstraction I guess so what exactly was",
    "start": "799800",
    "end": "807240"
  },
  {
    "text": "going on there let's look at it step by step and there were several places where that was",
    "start": "807240",
    "end": "813560"
  },
  {
    "text": "happening okay so first what is kineses data streams it's a fully managed massively scalable service in AWS where",
    "start": "813839",
    "end": "820920"
  },
  {
    "text": "for streaming data so after you write the data to the stream it appears in the Stream within milliseconds and it's",
    "start": "820920",
    "end": "826800"
  },
  {
    "text": "stored in that stream for at least 24 hours or up to a year if you configure it to be so and during that entire time",
    "start": "826800",
    "end": "833800"
  },
  {
    "text": "you can process and reprocess read that data in any way that you want as many times as you want",
    "start": "833800",
    "end": "839639"
  },
  {
    "text": "but you cannot delete the data from the stream once it gets to the stream it stays there for at least 24",
    "start": "839639",
    "end": "845600"
  },
  {
    "text": "hours and Kinesis is an extremely powerful tool it's mostly used for data applications but also for event driven",
    "start": "845600",
    "end": "852800"
  },
  {
    "text": "architectures and the the power comes from the fact that well you don't need to manage any servers or any clusters",
    "start": "852800",
    "end": "859279"
  },
  {
    "text": "and also it scales pretty much massively and to achieve that massive scalability kesis uses a concept of a chart which I",
    "start": "859279",
    "end": "865920"
  },
  {
    "text": "believe is familiar for many of you in this particular context Shard just means an ordered queue within the stream and",
    "start": "865920",
    "end": "872000"
  },
  {
    "text": "stream being composed of multiple such cues and each Shard will come with capacity limitation of how much data you",
    "start": "872000",
    "end": "878720"
  },
  {
    "text": "can write to it so one megabyte or 1,000 records of incoming data per second um",
    "start": "878720",
    "end": "885600"
  },
  {
    "text": "but you the amount of shards you can have in the Stream are pretty much unlimited so you can have as many shards",
    "start": "885600",
    "end": "891560"
  },
  {
    "text": "as you want to stream as much data as you need and when you write the data to the stream it will end up in one of the",
    "start": "891560",
    "end": "897839"
  },
  {
    "text": "shards in your stream So speaking about writing the data there's actually two ways in which you",
    "start": "897839",
    "end": "904279"
  },
  {
    "text": "can write the data to the Stream So in essence you have to choose between two API calls you either write individual",
    "start": "904279",
    "end": "910160"
  },
  {
    "text": "records or you can batch up to 500 records in a single API call and bashing",
    "start": "910160",
    "end": "917279"
  },
  {
    "text": "is usually a most more effective and less resource intensive way to make API",
    "start": "917279",
    "end": "922839"
  },
  {
    "text": "calls especially in data intensive applications where the amount of individual calls can get really really",
    "start": "922839",
    "end": "928160"
  },
  {
    "text": "high really quickly but once again when something sounds too good there's usually some things we need",
    "start": "928160",
    "end": "934279"
  },
  {
    "text": "to consider and we'll get back to that in a second all right so we have established",
    "start": "934279",
    "end": "940160"
  },
  {
    "text": "by now that the failures will happen right there's no way around that but how do those failur manifest with this",
    "start": "940160",
    "end": "946680"
  },
  {
    "text": "higher level of obstruction with servoless services with services like Kinesis for example well it's actually",
    "start": "946680",
    "end": "952199"
  },
  {
    "text": "pretty straightforward because when we interact with Services let's say from our code we are using API calls and",
    "start": "952199",
    "end": "958319"
  },
  {
    "text": "naturally any of those API calls can fail now the good news is that if you",
    "start": "958319",
    "end": "964120"
  },
  {
    "text": "are using AWS SDK to make those API calls from your code it handles most of those failures",
    "start": "964120",
    "end": "970839"
  },
  {
    "text": "for you after all AWS does know that the failures will happen so they have built",
    "start": "970839",
    "end": "975959"
  },
  {
    "text": "into the SDK one of those essential tools for better resilience or a superpower as we know it the rich",
    "start": "975959",
    "end": "984000"
  },
  {
    "text": "rise now the trouble with the r rise is that now we have a potential of turning",
    "start": "984000",
    "end": "990920"
  },
  {
    "text": "a small intermittent problem let's say a network glitch into a really massive one",
    "start": "990920",
    "end": "996240"
  },
  {
    "text": "because retries can have really unexpected blast radius they can spread this ripple effect of cascading failures",
    "start": "996240",
    "end": "1003240"
  },
  {
    "text": "through your entire system and ultimately bring the entire system down because retri are ultimately",
    "start": "1003240",
    "end": "1013199"
  },
  {
    "text": "selfish just like when you're hitting the refresh button in a browser right we all know we shouldn't do it but we do it",
    "start": "1013360",
    "end": "1019639"
  },
  {
    "text": "anyway because retrying implies that our request is more important and more",
    "start": "1019639",
    "end": "1024880"
  },
  {
    "text": "valuable than anybody else's and we are ready to spend more resources we are ready to add load to add potential cost",
    "start": "1024880",
    "end": "1031880"
  },
  {
    "text": "on the downstream system just to make sure that our retri or our request goes through no matter what but the reality",
    "start": "1031880",
    "end": "1038918"
  },
  {
    "text": "is that retress are not always effective neither are they safe first and foremost",
    "start": "1038919",
    "end": "1045000"
  },
  {
    "text": "which failures do we even retry let's say the failure is caused by by the downstream system such as database or",
    "start": "1045000",
    "end": "1051600"
  },
  {
    "text": "API being under a really heavy load when then if you're retrying you are probably",
    "start": "1051600",
    "end": "1057480"
  },
  {
    "text": "making the weather the matter worse or let's say the request failed",
    "start": "1057480",
    "end": "1062679"
  },
  {
    "text": "because it took too much time and it timed out but then retrying will take more time that you're actually prepared",
    "start": "1062679",
    "end": "1068760"
  },
  {
    "text": "to wait let's say you have your own SLA requirements and then that basically means that retrying is just selfishly",
    "start": "1068760",
    "end": "1075240"
  },
  {
    "text": "using the resources that you don't really need it's just like pressing the refresh button and just closing the",
    "start": "1075240",
    "end": "1081360"
  },
  {
    "text": "browser and what if the underlying system also have their own retries implemented and let's say they also have",
    "start": "1081360",
    "end": "1087120"
  },
  {
    "text": "a distributed application they have different components each of them has retries on a certain level so in that",
    "start": "1087120",
    "end": "1093480"
  },
  {
    "text": "case our retries will just be multiplied and they will just amplify all the potential bad things that can happen and",
    "start": "1093480",
    "end": "1099440"
  },
  {
    "text": "this is the place where the this ripple effect of cascading failures can happen really really easily especially if we",
    "start": "1099440",
    "end": "1105600"
  },
  {
    "text": "start retrying without giving the underlying system a chance to",
    "start": "1105600",
    "end": "1110679"
  },
  {
    "text": "recover and let's say what if the operation that you're actually retrying has side effects let's say you updating",
    "start": "1110679",
    "end": "1116760"
  },
  {
    "text": "a database then r r can actually have unexpected results so the bottom line is you need",
    "start": "1116760",
    "end": "1123960"
  },
  {
    "text": "to be extremely careful about how we use the superpower we don't want to bring down the system that we are trying to",
    "start": "1123960",
    "end": "1131360"
  },
  {
    "text": "fix now luckily in case of AWS SDK it already or retries already come with",
    "start": "1131360",
    "end": "1136799"
  },
  {
    "text": "this built-in safety measures so if a request to a service such as Kinesis",
    "start": "1136799",
    "end": "1142240"
  },
  {
    "text": "fails AWS SDK will only handle the so-called retriable errors so things",
    "start": "1142240",
    "end": "1147919"
  },
  {
    "text": "like uh service unavailable other 500 errors or timeouts and for those",
    "start": "1147919",
    "end": "1153000"
  },
  {
    "text": "retriable errors it will retry them on your behalf behind the scenes but it will stop after a certain amount of",
    "start": "1153000",
    "end": "1159760"
  },
  {
    "text": "attempts and between those retry attempts it will use so-called exponential backoff which means that",
    "start": "1159760",
    "end": "1165240"
  },
  {
    "text": "delays between retry attempts will be increasing exponentially now these things might seem very simple",
    "start": "1165240",
    "end": "1172840"
  },
  {
    "text": "but they are actually crucial details that can either Make It or Break It they can turn retries from being a very",
    "start": "1172840",
    "end": "1178840"
  },
  {
    "text": "powerful tool for better resilience into the main cause of a system outage because we only want to be retrying if",
    "start": "1178840",
    "end": "1186080"
  },
  {
    "text": "it actually helps the situation so only retryable failures and when we do retry",
    "start": "1186080",
    "end": "1191159"
  },
  {
    "text": "we do want to stop if it doesn't help the situation anymore to avoid that ripple effect of cascading failures as",
    "start": "1191159",
    "end": "1197480"
  },
  {
    "text": "much as possible and also we want to spread the retry attempt as uniformly as",
    "start": "1197480",
    "end": "1202679"
  },
  {
    "text": "possible instead of just sending this burst of retries to A system that is already under a heavy load so to give",
    "start": "1202679",
    "end": "1209559"
  },
  {
    "text": "the system a chance to recover and with AWS SDK you are given",
    "start": "1209559",
    "end": "1215200"
  },
  {
    "text": "these safety measures but you are also given the possibility to configure some of those retry parameters and here's an",
    "start": "1215200",
    "end": "1221480"
  },
  {
    "text": "example how you would do this with JavaScript as decay and every language will have their own ways to configure them and their own default values but",
    "start": "1221480",
    "end": "1228880"
  },
  {
    "text": "all of them will give you a possibility to configure some of those values and uh the same way they will",
    "start": "1228880",
    "end": "1234679"
  },
  {
    "text": "give you the possibility to configure the second superpower that we have the timeout related values now if timeouts",
    "start": "1234679",
    "end": "1242760"
  },
  {
    "text": "don't sound like too much of a superow to you I have a news for you timeouts",
    "start": "1242760",
    "end": "1248400"
  },
  {
    "text": "are pretty much a given and distributed systems and we absolutely need to be aware of them so once again in simplified terms",
    "start": "1248400",
    "end": "1256280"
  },
  {
    "text": "let's talk about timeouts so when we are interacting with Services No Matter are they serverless or not we are us using",
    "start": "1256280",
    "end": "1262960"
  },
  {
    "text": "API calls right and usually those API calls are abstracted away as SDK method",
    "start": "1262960",
    "end": "1268039"
  },
  {
    "text": "calls and those look exactly the same as any local method invocation right but let's not let that fool us because we",
    "start": "1268039",
    "end": "1274159"
  },
  {
    "text": "know already network is still there it's just abstracted away from us and any request sent over Network",
    "start": "1274159",
    "end": "1282240"
  },
  {
    "text": "like an API call to canas for example can fail in many different stages",
    "start": "1282240",
    "end": "1287559"
  },
  {
    "text": "moreover it's almost possible to tell if the request actually failed or it didn't because that failure can happen on many",
    "start": "1287559",
    "end": "1293720"
  },
  {
    "text": "levels so maybe sending the request actually failed or maybe the processing of the request failed or maybe your",
    "start": "1293720",
    "end": "1299960"
  },
  {
    "text": "request in wait is waiting in the queue because the downstream system is overwhelmed or maybe the request was",
    "start": "1299960",
    "end": "1306400"
  },
  {
    "text": "processed but you just never got the response back and you just don't know about so there are plenty of options but",
    "start": "1306400",
    "end": "1313360"
  },
  {
    "text": "end result is always the same you are stuck waiting for something that might never happen",
    "start": "1313360",
    "end": "1319159"
  },
  {
    "text": "and this can happen to any service it can happen to Kinesis as well and not to wait forever AWS has built into the SDK",
    "start": "1319159",
    "end": "1326760"
  },
  {
    "text": "this other two for better resilience this other superpower the timeouts now the ability to configure",
    "start": "1326760",
    "end": "1333039"
  },
  {
    "text": "those timeouts for the API calls is our superpower that we can use but again",
    "start": "1333039",
    "end": "1338520"
  },
  {
    "text": "just like with retries we need to be extremely careful how we use it because picking the right timeout",
    "start": "1338520",
    "end": "1345279"
  },
  {
    "text": "value is not an easy task at all and just like any any decision in your architecture it will come with certain",
    "start": "1345279",
    "end": "1351159"
  },
  {
    "text": "trade-offs so let's say you pick a too long time out then it's likely going to be in effective and it can consume",
    "start": "1351159",
    "end": "1357360"
  },
  {
    "text": "resources increase latencies Too Short Time Out might mean that you will be retrying too early and not giving the",
    "start": "1357360",
    "end": "1364520"
  },
  {
    "text": "original request a chance to finish and this will inevitably mean that you will add load to the underlying system and",
    "start": "1364520",
    "end": "1372120"
  },
  {
    "text": "this as we know will cause this cascading failures and eventually we can bring the entire system down",
    "start": "1372120",
    "end": "1379000"
  },
  {
    "text": "and on top of all that the appropriate timeout value will be different depending on the service you are using",
    "start": "1379000",
    "end": "1384760"
  },
  {
    "text": "or operation that you are performing now for the longest time I've been scaring people saying that for all",
    "start": "1384760",
    "end": "1391880"
  },
  {
    "text": "the services and all the requests AWS SDK JavaScript SDK has this default",
    "start": "1391880",
    "end": "1397880"
  },
  {
    "text": "timeout that it uses and it's 2 minutes so just to think about it we are",
    "start": "1397880",
    "end": "1404720"
  },
  {
    "text": "probably dealing with some low latency systems with services like in this case or Dynamo DB usually we are really aware",
    "start": "1404720",
    "end": "1412200"
  },
  {
    "text": "of every millisecond that we spend right but here we are just stuck for 2 minutes",
    "start": "1412200",
    "end": "1418799"
  },
  {
    "text": "waiting for SDK to decide that yeah there was a timeout sorry well since then things have",
    "start": "1418799",
    "end": "1425360"
  },
  {
    "text": "changed things have evolved JavaScript has Decay saw a change of version from two to three and also timeout values",
    "start": "1425360",
    "end": "1432600"
  },
  {
    "text": "default timeout values have changed so now the default timeout value is infinite",
    "start": "1432600",
    "end": "1439559"
  },
  {
    "text": "great right so basically this means that if you don't configure those timeouts you are just stuck there just like you",
    "start": "1439559",
    "end": "1447559"
  },
  {
    "text": "know I mean who knows what happens right so bottom line here is that very",
    "start": "1447559",
    "end": "1453559"
  },
  {
    "text": "powerful but very dangerous and finally we get to the first reason",
    "start": "1453559",
    "end": "1459000"
  },
  {
    "text": "for losing data in our story so having two long timeouts can actually exhaust",
    "start": "1459000",
    "end": "1465440"
  },
  {
    "text": "resources of your producer application and not make it possible for it to consume new incoming requests and that's",
    "start": "1465440",
    "end": "1472960"
  },
  {
    "text": "exactly what we saw in our architecture and it was still in the two-minute timeout era but still even then without",
    "start": "1472960",
    "end": "1478960"
  },
  {
    "text": "configuring timeouts we got our producer to be stuck and waiting for something that will never happen because of likely",
    "start": "1478960",
    "end": "1485640"
  },
  {
    "text": "a small intermittent problem and we got this entire system outage instead of",
    "start": "1485640",
    "end": "1492919"
  },
  {
    "text": "kind of masking and recovering from Individual failures because well that's what a resilient system should do so",
    "start": "1492919",
    "end": "1498480"
  },
  {
    "text": "instead we just kind of gave up and and start to losing data now this obviously doesn't sound",
    "start": "1498480",
    "end": "1505159"
  },
  {
    "text": "too great but if you think the solution is to have short timeouts I kind of have a bad news for you as well because in my",
    "start": "1505159",
    "end": "1512320"
  },
  {
    "text": "experience two short timeouts can be even more dangerous especially if they are combined with the",
    "start": "1512320",
    "end": "1518679"
  },
  {
    "text": "retries because again retrying requests too early not giving the original request a chance to to complete means",
    "start": "1518679",
    "end": "1524640"
  },
  {
    "text": "that you are adding the load on the underlying system and kind of pushing it over the age and you start to see all of",
    "start": "1524640",
    "end": "1530080"
  },
  {
    "text": "the fun things it's not as obvious when you see it you just start to see failures you start to see latencies you",
    "start": "1530080",
    "end": "1535799"
  },
  {
    "text": "start to see cost going up and we will get this ripple effect of",
    "start": "1535799",
    "end": "1541480"
  },
  {
    "text": "cascading failures in in the end and again ultimately bring the entire system",
    "start": "1541480",
    "end": "1546559"
  },
  {
    "text": "down so again if if our goal is to build a resilient system we should mask and",
    "start": "1546559",
    "end": "1552080"
  },
  {
    "text": "recover from Individual failures we should in uh make sure that our system works as a whole even if there were some",
    "start": "1552080",
    "end": "1559360"
  },
  {
    "text": "individual failures and here is where the timeouts and or wrly wrongly configured timeouts and r r can really",
    "start": "1559360",
    "end": "1565279"
  },
  {
    "text": "become a matchmate in hell so once again even though retries",
    "start": "1565279",
    "end": "1571399"
  },
  {
    "text": "and timeouts can be extremely powerful we need to be very mindful how we use it",
    "start": "1571399",
    "end": "1576799"
  },
  {
    "text": "we should never ever go with the defaults defaults are really dangerous so next time you see your own code or",
    "start": "1576799",
    "end": "1583559"
  },
  {
    "text": "your own architecture please go check all the libraries and all the places that you make any calls over the network",
    "start": "1583559",
    "end": "1589240"
  },
  {
    "text": "let's say SDK or maybe you have external apis that you are calling please make sure that you know what the default",
    "start": "1589240",
    "end": "1595200"
  },
  {
    "text": "timeouts are because they usually are in default timeout make sure that you are comfortable with that value it's not too",
    "start": "1595200",
    "end": "1601480"
  },
  {
    "text": "small it's not too big that you have control over that value and especially if those timeouts",
    "start": "1601480",
    "end": "1608600"
  },
  {
    "text": "are combined with the retries okay so so far I've been talking",
    "start": "1608600",
    "end": "1614159"
  },
  {
    "text": "about these failures that are inevitable in distributed systems but there's actually one more type of failures and",
    "start": "1614159",
    "end": "1621039"
  },
  {
    "text": "those failures are caused by the cloud providers on purpose those are failures related to service limits and",
    "start": "1621039",
    "end": "1629759"
  },
  {
    "text": "throttling and this can be extremely confusing especially in the serverless world because we are promised",
    "start": "1631640",
    "end": "1637200"
  },
  {
    "text": "scalability right but somehow we are very easily assuming infinite scalability and of course if something",
    "start": "1637200",
    "end": "1644399"
  },
  {
    "text": "sounds too good to be true there's probably a catch and sooner or later we",
    "start": "1644399",
    "end": "1649600"
  },
  {
    "text": "better face the reality and reality is of course the cloud is not infinite and moreover we are sharing the underlying",
    "start": "1649600",
    "end": "1655760"
  },
  {
    "text": "Resources with everybody else we don't have the entire Cloud at our disposal right and sharing all those resources",
    "start": "1655760",
    "end": "1662640"
  },
  {
    "text": "comes with trade-offs of course on one hand we do have this huge amount of resources that we can share that we",
    "start": "1662640",
    "end": "1668080"
  },
  {
    "text": "wouldn't have otherwise but on the other hand it also allows individual users on",
    "start": "1668080",
    "end": "1673559"
  },
  {
    "text": "purpose or by accident to monopolize certain resources and while resour are",
    "start": "1673559",
    "end": "1678640"
  },
  {
    "text": "not infinite it will inevitably cause theg gradation of service to all the other users so service limits are there",
    "start": "1678640",
    "end": "1685000"
  },
  {
    "text": "to ensure that that doesn't happen and throttling is just a tool to enforce those service limits for example in case",
    "start": "1685000",
    "end": "1691559"
  },
  {
    "text": "of Kinesis we had The Shard level limit of how much data we can write to a shark and once we reach that limit all our",
    "start": "1691559",
    "end": "1698840"
  },
  {
    "text": "requests will be throttled they will fail now we get to the next reason of",
    "start": "1698840",
    "end": "1705799"
  },
  {
    "text": "losing data in our story so I said at some point that if you're using AWS SDK",
    "start": "1705799",
    "end": "1711840"
  },
  {
    "text": "you're lucky but it handles most of the failures for you right so the catch here",
    "start": "1711840",
    "end": "1717960"
  },
  {
    "text": "is that in case of batch operations like we have put records here instead of just",
    "start": "1717960",
    "end": "1723399"
  },
  {
    "text": "handling the failure of anti request we should also handle the so-called partial",
    "start": "1723399",
    "end": "1728600"
  },
  {
    "text": "failures now the thing here is that those batch operations they are not automic they are not either all request",
    "start": "1728600",
    "end": "1733919"
  },
  {
    "text": "all record succeeded or all record failed it might happen so that part of",
    "start": "1733919",
    "end": "1738960"
  },
  {
    "text": "your batch goes through successfully while the other part fails and you still get a success response back and it's",
    "start": "1738960",
    "end": "1745039"
  },
  {
    "text": "your responsibility to detect those partial failures and to handle them moreover every single record in a batch",
    "start": "1745039",
    "end": "1752000"
  },
  {
    "text": "can fail every single one of them and you will still get a success response back so it's very important to handle",
    "start": "1752000",
    "end": "1758399"
  },
  {
    "text": "those partial failures and the main reason for the partial failures in this case is actually throttling or exceeding",
    "start": "1758399",
    "end": "1764399"
  },
  {
    "text": "uh um occasionally is uh exceeding service limit so having spikes in",
    "start": "1764399",
    "end": "1771158"
  },
  {
    "text": "traffic luckily we already know that there is this fantastic tool that can help us when we are dealing with",
    "start": "1772440",
    "end": "1778679"
  },
  {
    "text": "transient errors and in case of occasional Spice in traffic we are dealing with something temporary that",
    "start": "1778679",
    "end": "1784640"
  },
  {
    "text": "will probably pass and this wonderful tool is of course R rise so when",
    "start": "1784640",
    "end": "1789919"
  },
  {
    "text": "implementing the r rise there are key three key things that we need to keep in mind and let's go through them one more",
    "start": "1789919",
    "end": "1796080"
  },
  {
    "text": "time so we only want to retry the retryable failures and we want to set",
    "start": "1796080",
    "end": "1801320"
  },
  {
    "text": "upper limits for our retries not to retry forever and stop retrying when it doesn't help and we want to spread the",
    "start": "1801320",
    "end": "1808159"
  },
  {
    "text": "retry attempts um as uniformly as possible and have a proper back off and",
    "start": "1808159",
    "end": "1813440"
  },
  {
    "text": "for that an exponential back off a Jeter is an extremely powerful tool so I",
    "start": "1813440",
    "end": "1818760"
  },
  {
    "text": "actually lied a little bit SDK uses exponential back off and jiter I just didn't me mention Jeter in the previous",
    "start": "1818760",
    "end": "1824840"
  },
  {
    "text": "slide so Jeter basically just means adding some randomization to your delay",
    "start": "1824840",
    "end": "1830880"
  },
  {
    "text": "and surprisingly or maybe not so surprisingly by just this small little change to how you handle the delays or",
    "start": "1830880",
    "end": "1837799"
  },
  {
    "text": "the backoffs between your retry attempts you can actually dramatically improve your chances of getting your request",
    "start": "1837799",
    "end": "1843799"
  },
  {
    "text": "through it actually reduces the amount of retry attempts that you need and increases the chance of the overall",
    "start": "1843799",
    "end": "1850279"
  },
  {
    "text": "request to succeed pretty pretty drastically so very small and simple tool but also extremely powerful and I",
    "start": "1850279",
    "end": "1857639"
  },
  {
    "text": "always say that if you remember anything from my talks Let It Be partial failures",
    "start": "1857639",
    "end": "1863200"
  },
  {
    "text": "of batch operations timeouts and retries with exponential back off and jiter because",
    "start": "1863200",
    "end": "1869880"
  },
  {
    "text": "those things will save you tons of headache in many many situations when you are dealing with distributed",
    "start": "1869880",
    "end": "1875919"
  },
  {
    "text": "applications they are not related to any particular service they are just things that you absolutely need to be aware",
    "start": "1875919",
    "end": "1883200"
  },
  {
    "text": "of and to borrow words of Gregor hoe rri have brought more distributed system",
    "start": "1883200",
    "end": "1888279"
  },
  {
    "text": "down that all the other causes together of course this doesn't mean that we shouldn't retrive but we know by now we",
    "start": "1888279",
    "end": "1894440"
  },
  {
    "text": "need to be very very Mindful and very very careful we don't want to kill the system that we are trying to",
    "start": "1894440",
    "end": "1901519"
  },
  {
    "text": "fix speaking of which there were even more failures coming in our story so",
    "start": "1902880",
    "end": "1908840"
  },
  {
    "text": "let's see now what else can happen if we let the error handling slide and not",
    "start": "1908840",
    "end": "1914120"
  },
  {
    "text": "really do anything and just go with the defaults and this time we are speaking about the other end of our architecture",
    "start": "1914120",
    "end": "1919519"
  },
  {
    "text": "where we had a Lambda function reading from our Kinesis Stream So Lambda itself is actually a",
    "start": "1919519",
    "end": "1926720"
  },
  {
    "text": "prime representative of distributed applications because it's composed of many different components that work",
    "start": "1926720",
    "end": "1933720"
  },
  {
    "text": "together behind the scenes to make it one powerful service and one of those components that I personally love and",
    "start": "1933720",
    "end": "1940840"
  },
  {
    "text": "adore is the Event Source mapping so it's probably unfamiliar to you even if",
    "start": "1940840",
    "end": "1946720"
  },
  {
    "text": "you are using Lambda because it's very well obstructed underneath the Lambda obstruction layer but it's very",
    "start": "1946720",
    "end": "1953480"
  },
  {
    "text": "important component when you are dealing with different event sources in this case Kinesis for example uh because when",
    "start": "1953480",
    "end": "1959760"
  },
  {
    "text": "you're reading data with your Lambda from a Kinesis data stream you are in fact attaching an Event Source mapping to that stream and it pulls record from",
    "start": "1959760",
    "end": "1967080"
  },
  {
    "text": "the stream and it batches them and it invokes your Lambda function code for you and it will pick those records from",
    "start": "1967080",
    "end": "1973960"
  },
  {
    "text": "the stream uh from all the shards in the Stream in parallel and you can have up to 10 lambdas reading from each shart in",
    "start": "1973960",
    "end": "1981639"
  },
  {
    "text": "your stream that's once again something that the Event Source mapping provides you and it's um just a feature called",
    "start": "1981639",
    "end": "1987440"
  },
  {
    "text": "paraliz Factor so you can set it to have up to 10 lambdas reading from each chart instead of just one and here is where we",
    "start": "1987440",
    "end": "1995399"
  },
  {
    "text": "see the true power of concurrent processing Keening because now we can actually parallelize that record",
    "start": "1995399",
    "end": "2000760"
  },
  {
    "text": "processing we can speed things up if we need to we have 10 lambdas reading from each r instead of just one Lambda but of",
    "start": "2000760",
    "end": "2008200"
  },
  {
    "text": "course there's always a catch behind every fantastic thing that you hear and in this case it's extremely help uh",
    "start": "2008200",
    "end": "2015760"
  },
  {
    "text": "extremely easy to hit one of service limits so every service has a limit even",
    "start": "2015760",
    "end": "2021320"
  },
  {
    "text": "Lambda and one of those limits are very important I always bring it up it's the Lambda concurrency",
    "start": "2021320",
    "end": "2028080"
  },
  {
    "text": "limit so this one basically just means that you can have a li a limited number",
    "start": "2028080",
    "end": "2033919"
  },
  {
    "text": "of concurrent Lambda invocations in the same account in the same region so the number of Lambda instances running in",
    "start": "2033919",
    "end": "2040200"
  },
  {
    "text": "your account in your region at the same time is always limited to a number usually that number is 1,000 uh it's a",
    "start": "2040200",
    "end": "2047039"
  },
  {
    "text": "soft limit nowadays I've heard that you only get 100 lambdas haven't seen that just heard the rumors but anyhow it's a",
    "start": "2047039",
    "end": "2054040"
  },
  {
    "text": "soft limit you can increase it by creating um a ticket to the support but",
    "start": "2054040",
    "end": "2060358"
  },
  {
    "text": "there still is going to be a limit and once you reach that limit all the new",
    "start": "2060359",
    "end": "2065960"
  },
  {
    "text": "Lambda invocations in that account in your in that region will be throttled they will fail so let's say you have",
    "start": "2065960",
    "end": "2073398"
  },
  {
    "text": "your kin stream with 100 charts and let's say you set paralyzation factor to 10 because you want to speed things up",
    "start": "2073399",
    "end": "2078800"
  },
  {
    "text": "and because why not and now all of a sudden you have 1,000 lambdas so 100 *",
    "start": "2078800",
    "end": "2083960"
  },
  {
    "text": "10 reading from your stream and things are probably going to be okay but then",
    "start": "2083960",
    "end": "2090320"
  },
  {
    "text": "there is another very important Lambda somewhere in your ACC somewhere in your region that does something completely",
    "start": "2090320",
    "end": "2096079"
  },
  {
    "text": "irrelevant from your stream but that Lambda starts to fail and the reason is",
    "start": "2096079",
    "end": "2101280"
  },
  {
    "text": "you have consumed the entire Lambda concurrency limit with your stream consumer pun not intended so this is the",
    "start": "2101280",
    "end": "2109520"
  },
  {
    "text": "limit that can have a really big blast radius and it can spread this familiar",
    "start": "2109520",
    "end": "2114720"
  },
  {
    "text": "ripple effect of cascading failures well outside of your own architecture you can",
    "start": "2114720",
    "end": "2119880"
  },
  {
    "text": "actually have failures in systems that have nothing to do with your architecture so that's why I always bring it up and that's why it's a very",
    "start": "2119880",
    "end": "2126400"
  },
  {
    "text": "important limit to be aware of and to monitor all the time okay so now let's get back to",
    "start": "2126400",
    "end": "2132040"
  },
  {
    "text": "actually reading data from our stream so what happens if there's a failure let's",
    "start": "2132040",
    "end": "2138119"
  },
  {
    "text": "say okay let's get to it in a second so if there is a failure again there's a",
    "start": "2138119",
    "end": "2144160"
  },
  {
    "text": "good news bad news situation and the good news is that the Event Source mapping that I've been talking about actually comes with a lot of extensive",
    "start": "2144160",
    "end": "2151240"
  },
  {
    "text": "air handling capabilities but to use them you actually need to know that they are",
    "start": "2151240",
    "end": "2156839"
  },
  {
    "text": "there and if you don't know that the entire ventor mapping exists the chances are high you don't know and well the bad",
    "start": "2156839",
    "end": "2163359"
  },
  {
    "text": "news is that if you don't know you are likely just to go with the defaults and",
    "start": "2163359",
    "end": "2168440"
  },
  {
    "text": "we should know by now that defaults can be really really really dangerous so what happens by default if",
    "start": "2168440",
    "end": "2174720"
  },
  {
    "text": "there is a failure in processing a batch of Records let's say there was a bad record with some corrupt data and your",
    "start": "2174720",
    "end": "2181119"
  },
  {
    "text": "Lambda couldn't process it you didn't Implement proper error handling because well nothing bad can ever happen right",
    "start": "2181119",
    "end": "2186880"
  },
  {
    "text": "so your entire Lambda now fails as a result of it so what happens next so by",
    "start": "2186880",
    "end": "2192160"
  },
  {
    "text": "default even though no amount of retries can help in this situation we just have some bad data there right but by default",
    "start": "2192160",
    "end": "2199400"
  },
  {
    "text": "Lambda will be retrying that one batch of Records over and over and over and over again until it either succeeds",
    "start": "2199400",
    "end": "2206119"
  },
  {
    "text": "which well it never will or until the data in the batch expires and in case of Kinesis I remind",
    "start": "2206119",
    "end": "2212880"
  },
  {
    "text": "you data stays in the Stream for at least 24 hours so this effectively means an",
    "start": "2212880",
    "end": "2219200"
  },
  {
    "text": "entire day of useless lambay invocations that will be retrying that batch of records and they don't come for free you",
    "start": "2219200",
    "end": "2226599"
  },
  {
    "text": "are going to pay for them so those all those useless Lum",
    "start": "2226599",
    "end": "2231960"
  },
  {
    "text": "vacations have a lot of fun side effects and one of them is that you're likely reprocessing the same data over and over",
    "start": "2231960",
    "end": "2238680"
  },
  {
    "text": "again because you see from the perspective of the Event Source mapping either your entire batch succeeded or",
    "start": "2238680",
    "end": "2244400"
  },
  {
    "text": "your entire batch failed so whenever Lambda encounter there's a record that fails it fails the entire batch so in",
    "start": "2244400",
    "end": "2251839"
  },
  {
    "text": "this example record 1 two and three went successfully record four failed but your entire batch will be retried so records",
    "start": "2251839",
    "end": "2258800"
  },
  {
    "text": "one two and three will be reprocessed over and over and over again and here we come to item potency which Leo was",
    "start": "2258800",
    "end": "2265839"
  },
  {
    "text": "telling us about yesterday extremely important but the bad things don't",
    "start": "2265839",
    "end": "2271680"
  },
  {
    "text": "really stop there because while all this madness at least it looks like Madness to us is",
    "start": "2271680",
    "end": "2277960"
  },
  {
    "text": "happening no other records are being picked from that shart so other shards",
    "start": "2277960",
    "end": "2283200"
  },
  {
    "text": "in your stream they go on with their lives and data is being processed and everything is good but that one shart is",
    "start": "2283200",
    "end": "2288760"
  },
  {
    "text": "stuck it's waiting for that one bad batch of record to well to be processed",
    "start": "2288760",
    "end": "2295160"
  },
  {
    "text": "and that's why it's often referred to as a poison peel record because there was just one bad record but a lot of bad",
    "start": "2295160",
    "end": "2301480"
  },
  {
    "text": "things happen and one of those bad things is that especially in data",
    "start": "2301480",
    "end": "2306720"
  },
  {
    "text": "applications data loses its value pretty quickly so the chances are really high",
    "start": "2306720",
    "end": "2312240"
  },
  {
    "text": "that 24hour long or old data is pretty much useless to you so we lose data on",
    "start": "2312240",
    "end": "2318800"
  },
  {
    "text": "many different levels when we don't process it right away and speaking of losing data so",
    "start": "2318800",
    "end": "2325319"
  },
  {
    "text": "let's say finally in 24 hours the data finally expires your entire batch finally leaves the stream Lambda can",
    "start": "2325319",
    "end": "2331920"
  },
  {
    "text": "stop retrying of course part of that batch was unprocessed but okay that's life what will you do at least your",
    "start": "2331920",
    "end": "2337119"
  },
  {
    "text": "Lambda can kind of catch up and start picking new records from the chart right and well bad things happen it's okay but",
    "start": "2337119",
    "end": "2344640"
  },
  {
    "text": "the problem here is that your Shard is potentially filled with records that were written around the same time that",
    "start": "2344640",
    "end": "2350800"
  },
  {
    "text": "they already expired one so this means that it will only also expire around the same time that they already expired once",
    "start": "2350800",
    "end": "2357480"
  },
  {
    "text": "so this might lead to a situation where y Lambda will not even have a chance to process all those records the records",
    "start": "2357480",
    "end": "2363480"
  },
  {
    "text": "will just keep expiring and expiring and being deleted from The Shard without you having a chance to process them and I",
    "start": "2363480",
    "end": "2369760"
  },
  {
    "text": "bring up this overflowing sink analogy because you just don't have enough time to drain that sink water just keeps",
    "start": "2369760",
    "end": "2375359"
  },
  {
    "text": "flowing and flowing so oops sorry we started with just one bad record right and we ended",
    "start": "2375359",
    "end": "2382720"
  },
  {
    "text": "up losing a lot of valid and valuable data again something opposite from what",
    "start": "2382720",
    "end": "2387960"
  },
  {
    "text": "a resilient system should be like and yes this is exactly what we",
    "start": "2387960",
    "end": "2394079"
  },
  {
    "text": "were seeing in our story so just because of some random bad records we would see",
    "start": "2394079",
    "end": "2400000"
  },
  {
    "text": "that we would lose a lot of data we would have a lot of reprocessing we will have a lot of duplicates we will have a",
    "start": "2400000",
    "end": "2405520"
  },
  {
    "text": "lot of delays we would consume a lot of Resources pay a lot of money for something that will never",
    "start": "2405520",
    "end": "2412040"
  },
  {
    "text": "happen so now the clicker yes and all of those",
    "start": "2412040",
    "end": "2419520"
  },
  {
    "text": "happen things happened because we just didn't know better and just went with the good old defaults when it comes to",
    "start": "2419520",
    "end": "2426079"
  },
  {
    "text": "handling failures and we know by now that that's exactly the opposite from what we should do and",
    "start": "2426079",
    "end": "2433040"
  },
  {
    "text": "I need to bring up the quote by Gregor because it just so great uh like like luckily there are",
    "start": "2433040",
    "end": "2439599"
  },
  {
    "text": "many easy ways in which we can be more Mindful and smarter about r r when it comes to Lambda because as I said Event",
    "start": "2439599",
    "end": "2446000"
  },
  {
    "text": "Source mapping comes with extensive set of air handling capabilities and we know by now that probably the most important",
    "start": "2446000",
    "end": "2452079"
  },
  {
    "text": "things that we should set are timeout values and limits for the r rise now we",
    "start": "2452079",
    "end": "2457400"
  },
  {
    "text": "can do both of them with Event Source mapping but both of them are set to minus one by default so no limits and",
    "start": "2457400",
    "end": "2465880"
  },
  {
    "text": "that's exactly what we were seeing and it's not like AWS wants to be bad and",
    "start": "2465880",
    "end": "2471040"
  },
  {
    "text": "evil to us actually it makes sense because Kinesis promises us an order of",
    "start": "2471040",
    "end": "2477400"
  },
  {
    "text": "shards um of Records sorry so if you remember I said that A Shard is an ordered Q so records that come in the",
    "start": "2477400",
    "end": "2483440"
  },
  {
    "text": "shart they should be ordered which means that Lambda needs to process them in order so if there is a failure it can't",
    "start": "2483440",
    "end": "2490000"
  },
  {
    "text": "just jump over and kind of maybe process the failures in the background and because we will miss or mess up the",
    "start": "2490000",
    "end": "2496920"
  },
  {
    "text": "entire order right so this is done with the best intentions but uh the end",
    "start": "2496920",
    "end": "2502200"
  },
  {
    "text": "result is still not not pretty so we need to configure those values and there",
    "start": "2502200",
    "end": "2507640"
  },
  {
    "text": "are also a lot of other very useful things that you can do to improve ER handling with Event Source mapping I'm",
    "start": "2507640",
    "end": "2513000"
  },
  {
    "text": "not going to go through them I I will give you a link in a second and we can use all of those uh options",
    "start": "2513000",
    "end": "2520200"
  },
  {
    "text": "in any combination that we want just most important things please please do",
    "start": "2520200",
    "end": "2526000"
  },
  {
    "text": "not go with the defaults and as I said I I can't go",
    "start": "2526000",
    "end": "2531160"
  },
  {
    "text": "through all of the all of the details here but if you interested at all I have written these two huge I would say user",
    "start": "2531160",
    "end": "2536960"
  },
  {
    "text": "manuals I call them lovingly blog posts about Kinesis and Lambda and how they",
    "start": "2536960",
    "end": "2542319"
  },
  {
    "text": "work together and separately so there's a lot of details about Lambda in devour",
    "start": "2542319",
    "end": "2547559"
  },
  {
    "text": "there as well so please go go ahead and read them if you feel so",
    "start": "2547559",
    "end": "2553160"
  },
  {
    "text": "inclined okay so we have seen today that we can actually cause more trouble while",
    "start": "2559240",
    "end": "2564680"
  },
  {
    "text": "trying to fix problems right and this is especially true if we don't make conscious critical informed decisions",
    "start": "2564680",
    "end": "2571880"
  },
  {
    "text": "about aor handling so things like uh brid rise and timeouts can be very",
    "start": "2571880",
    "end": "2577960"
  },
  {
    "text": "useful and very powerful but we need to make conscious decisions about them and we we need to take control rather than",
    "start": "2577960",
    "end": "2584760"
  },
  {
    "text": "just letting the meas slide because if we let the meas slide things can backfire and instead of making our",
    "start": "2584760",
    "end": "2589800"
  },
  {
    "text": "architecture more resilient we can actually achieve the exact opposite so next time you are building a",
    "start": "2589800",
    "end": "2596760"
  },
  {
    "text": "distributed architecture I encourage you to be brave to face the messy reality of",
    "start": "2596760",
    "end": "2602400"
  },
  {
    "text": "the real world to take control into your own hands rather than believing in magic because there's no magic and that's a",
    "start": "2602400",
    "end": "2608960"
  },
  {
    "text": "good thing it means that we have control so let's use that control and distributed systems and",
    "start": "2608960",
    "end": "2615800"
  },
  {
    "text": "architectures can be extremely powerful but they are also complex which doesn't make them neither inherently good nor",
    "start": "2615800",
    "end": "2622359"
  },
  {
    "text": "bad and the cloud and servus especially abstracts away a lot of that complexity from us but that doesn't mean that",
    "start": "2622359",
    "end": "2628960"
  },
  {
    "text": "complexity doesn't exist anymore and again not inherently good nor",
    "start": "2628960",
    "end": "2634319"
  },
  {
    "text": "bad and we really don't need to know or we can't even know every single detail",
    "start": "2634319",
    "end": "2640440"
  },
  {
    "text": "about every single service that you we are using it's borderline impossible but there are these fundamental things that",
    "start": "2640440",
    "end": "2647160"
  },
  {
    "text": "are inherent to distributed systems and the cloud in general so things like service limits timeouts partial failures",
    "start": "2647160",
    "end": "2655480"
  },
  {
    "text": "retries back offs and all of those things are really fundamental if we are",
    "start": "2655480",
    "end": "2660880"
  },
  {
    "text": "building distributed applications we absolutely need to understand them otherwise we are just moving in the dark",
    "start": "2660880",
    "end": "2666640"
  },
  {
    "text": "with our eyes closed and hoping that everything will be fine and finally on a more philosophical",
    "start": "2666640",
    "end": "2672960"
  },
  {
    "text": "note distributed systems and architectures are hard but they can also teach us a very useful lesson to embrace",
    "start": "2672960",
    "end": "2681440"
  },
  {
    "text": "the chaos of the real world because every failure is an opportunity to make our architectures",
    "start": "2681440",
    "end": "2688280"
  },
  {
    "text": "better more resilient and while it's borderline impossible to build something that never fails but there's one thing",
    "start": "2688280",
    "end": "2695280"
  },
  {
    "text": "that we can do we can learn and grow from each individual failure and as Dr ver wles likes to say",
    "start": "2695280",
    "end": "2702319"
  },
  {
    "text": "everything fails all the time that's just the reality of things so either in life in general or with AWS services in",
    "start": "2702319",
    "end": "2709000"
  },
  {
    "text": "particular I'd argue that the best thing that we can actually do is be prepared and stay calm when those failures happen",
    "start": "2709000",
    "end": "2715400"
  },
  {
    "text": "because they will and that's it for me for today thank you all so very much for listening",
    "start": "2715400",
    "end": "2721559"
  },
  {
    "text": "and please please please go and trade the session in the app thank you",
    "start": "2721559",
    "end": "2728760"
  },
  {
    "text": "[Applause] uh we have time for a question or two does anybody have any",
    "start": "2731260",
    "end": "2738920"
  },
  {
    "text": "questions hello I would like to know how do you set those limits and for",
    "start": "2743280",
    "end": "2749040"
  },
  {
    "text": "throttling for timeout ET so let's say that you know that you will have certain",
    "start": "2749040",
    "end": "2754200"
  },
  {
    "text": "lot and you want to do certain performance test or validate your",
    "start": "2754200",
    "end": "2759240"
  },
  {
    "text": "hypothesis do you have a tool in or framewor for that and also how do you manage the unexpected spikes on those",
    "start": "2759240",
    "end": "2767640"
  },
  {
    "text": "systems I don't I'm not sure I got the second part can you repeat it let's say that you have a system that you are",
    "start": "2767640",
    "end": "2773000"
  },
  {
    "text": "expecting to have I don't know 25k records per seconds and suddenly you have triple this because happen in the",
    "start": "2773000",
    "end": "2781800"
  },
  {
    "text": "cloud and how do you manage this scenario on on this uh system",
    "start": "2781800",
    "end": "2787800"
  },
  {
    "text": "okay so first with the how do you set the timeouts and retries that's actually a very good question as I probably",
    "start": "2787800",
    "end": "2794520"
  },
  {
    "text": "mentioned it's not easy I'm not saying it's they do sound very simple but you need to do a lot of load testing you",
    "start": "2794520",
    "end": "2801680"
  },
  {
    "text": "need to see how your system responds under heavy load to actually know what",
    "start": "2801680",
    "end": "2806760"
  },
  {
    "text": "the appropriate numbers for you are going to be and like for timeout for example one practice is to try to",
    "start": "2806760",
    "end": "2814319"
  },
  {
    "text": "estimate what's the let's say P9 9 latency of the downstream system is that",
    "start": "2814319",
    "end": "2819599"
  },
  {
    "text": "you are calling and then based on that try to maybe add some padding to that P99 number and then set it as your",
    "start": "2819599",
    "end": "2826400"
  },
  {
    "text": "timeout then you probably are kind of safe um because it's not easy I mean I",
    "start": "2826400",
    "end": "2832040"
  },
  {
    "text": "have seen this problem just couple of weeks back though I know exactly what's going to happen but then things just",
    "start": "2832040",
    "end": "2837800"
  },
  {
    "text": "happen that you don't predict like there are libraries that have defaults that you haven't accounted for and then all",
    "start": "2837800",
    "end": "2843680"
  },
  {
    "text": "of a sudden you just hit a brick wall because latencies increase on the um on",
    "start": "2843680",
    "end": "2849200"
  },
  {
    "text": "the downstream system and then you start retrying and then things just escalate and get worse and and then basically the",
    "start": "2849200",
    "end": "2854960"
  },
  {
    "text": "system shuts down so my point is it's not easy you need to do load test and I think you mentioned load test I we don't",
    "start": "2854960",
    "end": "2861480"
  },
  {
    "text": "have any specific tool Ling per say we have um certain scripts that would just send a heavy load to our systems and and",
    "start": "2861480",
    "end": "2868400"
  },
  {
    "text": "that's that's the way how we usually try to figure what the appropriate numbers are but it's always a trade-off so when",
    "start": "2868400",
    "end": "2874680"
  },
  {
    "text": "it comes to spikes in traffic again really complex issue and usually using",
    "start": "2874680",
    "end": "2880359"
  },
  {
    "text": "servoless actually is um easier way around it like with Lambda being able to",
    "start": "2880359",
    "end": "2886119"
  },
  {
    "text": "to scale for example pretty instantaneously it's it's a big thing or it's very helpful in case of Kinesis um",
    "start": "2886119",
    "end": "2893960"
  },
  {
    "text": "if we speak about specific Services actually the best thing you can do is just over provision that's the harsh",
    "start": "2893960",
    "end": "2899920"
  },
  {
    "text": "reality of it so if you think that you are going to have certain spikes and you want to be absolutely sure especially if",
    "start": "2899920",
    "end": "2907559"
  },
  {
    "text": "those spice are unpredictable and you want to be absolutely sure that you don't lose data you don't really have",
    "start": "2907559",
    "end": "2913400"
  },
  {
    "text": "much option than than op there's in case of Kinesis there is a this on demand Kinesis uh option where you don't manage",
    "start": "2913400",
    "end": "2920559"
  },
  {
    "text": "the shards and you let AWS manage the shards and you pay a bit differently",
    "start": "2920559",
    "end": "2925960"
  },
  {
    "text": "much more to be honest but what it does in the background it actually over Provisions your shart you or your stream",
    "start": "2925960",
    "end": "2931839"
  },
  {
    "text": "you just don't see it so that's that's that's the truth of it at the moment",
    "start": "2931839",
    "end": "2938720"
  },
  {
    "text": "um all right uh one more question thank you very much for the",
    "start": "2939040",
    "end": "2944880"
  },
  {
    "text": "talk um I was wondering whether it could be helpful to not fail the Lambda in case of a batch with data that cannot be",
    "start": "2944880",
    "end": "2951480"
  },
  {
    "text": "written instead use metric and logs to just track that and then potentially retry on your own separately but uh that",
    "start": "2951480",
    "end": "2958200"
  },
  {
    "text": "way basically do not come in this kind of stuck situation what do you think about that yeah so I didn't hear it too well",
    "start": "2958200",
    "end": "2964599"
  },
  {
    "text": "but from from what I heard I try to answer the question so yeah first of all of course you need",
    "start": "2964599",
    "end": "2970240"
  },
  {
    "text": "to have proper observability and monitoring especially in um distributed",
    "start": "2970240",
    "end": "2975480"
  },
  {
    "text": "applications and Serv as it becomes extremely important to know what's happening in your system so definitely",
    "start": "2975480",
    "end": "2981359"
  },
  {
    "text": "you need to have logging and stuff um also there are certain metrics nowadays that will tell you that in some of those",
    "start": "2981359",
    "end": "2987760"
  },
  {
    "text": "scenarios that there is something going on but you you need to know that they exist before you because there's like",
    "start": "2987760",
    "end": "2992960"
  },
  {
    "text": "tons of metrics you usually don't know what to look up at um but uh what comes to re Riz in Lambda as I said there is a",
    "start": "2992960",
    "end": "2999640"
  },
  {
    "text": "lot of options that you can use and one of them is sending the failed request to a so-called failure destinations so",
    "start": "2999640",
    "end": "3006079"
  },
  {
    "text": "basically to a queue or a topic and then you come can come back and reprocess those requests so I hope that was",
    "start": "3006079",
    "end": "3012680"
  },
  {
    "text": "somewhat aligned with your question I'm sorry I didn't hear it too well yes thanks okay uh thank you very much as an",
    "start": "3012680",
    "end": "3020079"
  },
  {
    "text": "said please do uh rate this session and leave written feedback uh you can also read leave written feedback for any",
    "start": "3020079",
    "end": "3025319"
  },
  {
    "text": "sessions that you see yesterday thank you very much and another uh Round of Applause for an thank",
    "start": "3025319",
    "end": "3031680"
  },
  {
    "text": "you thank you [Music]",
    "start": "3031680",
    "end": "3046959"
  }
]
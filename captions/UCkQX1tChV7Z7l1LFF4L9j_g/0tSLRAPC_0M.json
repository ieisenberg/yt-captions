[
  {
    "text": "[Music]",
    "start": "3270",
    "end": "8730"
  },
  {
    "text": "um so my talk is about um what I'm calling the performance complexity curve",
    "start": "10080",
    "end": "16118"
  },
  {
    "text": "uh excuse me so what is the performance uh complexity curve um well it it comes",
    "start": "16119",
    "end": "23039"
  },
  {
    "text": "from uh the performance um uh the performance work phase diagram by Alexi",
    "start": "23039",
    "end": "28160"
  },
  {
    "text": "Shipv who who needs no introduction uh and it's an observation um he made uh on",
    "start": "28160",
    "end": "34320"
  },
  {
    "text": "on on how uh performance and complexity change as we engage in performance work",
    "start": "34320",
    "end": "39440"
  },
  {
    "text": "so it's quite common before we do any kind of performance work um that we",
    "start": "39440",
    "end": "44480"
  },
  {
    "text": "actually have a low performance and high complexity system uh this often comes from the mantra make it work make it",
    "start": "44480",
    "end": "50559"
  },
  {
    "text": "right make it fast in that order and so what we do is we uh in a lot of systems at the application layer we'll uh we'll",
    "start": "50559",
    "end": "57199"
  },
  {
    "text": "incur technical debt uh to meet deadlines maybe to get an MVP out and then later people will start using the",
    "start": "57199",
    "end": "63359"
  },
  {
    "text": "app and uh we'll need to improve the performance of it but the characteristic of this um this phase the first phase of",
    "start": "63359",
    "end": "70560"
  },
  {
    "text": "the performance um performance tuning is is is actually usually bug fixing and",
    "start": "70560",
    "end": "76159"
  },
  {
    "text": "these are simplifying changes um but later on if we if we still need to tune the system more we might actually have",
    "start": "76159",
    "end": "81920"
  },
  {
    "text": "to trade some complexity for performance and this is uh this is something that's always",
    "start": "81920",
    "end": "87040"
  },
  {
    "text": "really resonated with me uh because it's how I've seen uh things play out many",
    "start": "87040",
    "end": "92159"
  },
  {
    "text": "times um so what we can see is in the different phases as we get to the most",
    "start": "92159",
    "end": "98159"
  },
  {
    "text": "simple possible point um we get these really big gains at the beginning and if you hear about 10x gains in performance",
    "start": "98159",
    "end": "104880"
  },
  {
    "text": "is probably that um nobody's tried to optimize the system before and later on it gets much harder and we have to incur",
    "start": "104880",
    "end": "112720"
  },
  {
    "text": "a complexity for diminishing returns as we as we improve uh performance i split",
    "start": "112720",
    "end": "118560"
  },
  {
    "text": "this into three main phases so we have the lowhanging fruit which is um from",
    "start": "118560",
    "end": "124240"
  },
  {
    "text": "the initial state to the simplest possible point we we can get to and we",
    "start": "124240",
    "end": "129759"
  },
  {
    "text": "make lots of performance gains in this stage um after that we might get into tuning uh and after that there's this",
    "start": "129759",
    "end": "136239"
  },
  {
    "text": "competit competitive advantage stage which is um a stage we shouldn't really",
    "start": "136239",
    "end": "143680"
  },
  {
    "text": "go into unless there some kind of um unless we're in real-time competition or",
    "start": "143680",
    "end": "148879"
  },
  {
    "text": "we want to reduce cost to to improve margins uh because at that point we're taking on a lot of complexity for for",
    "start": "148879",
    "end": "155040"
  },
  {
    "text": "marginal gains um and we can use it as a framework for thinking to compare",
    "start": "155040",
    "end": "160400"
  },
  {
    "text": "problems so if we can um produce the same um if we can uh if we have a",
    "start": "160400",
    "end": "165800"
  },
  {
    "text": "problem which uh gives us more performance for the same level of complexity then that's a nicer problem",
    "start": "165800",
    "end": "170879"
  },
  {
    "text": "and if we can simplify it further then we've got an even nicer problem because we should usually prefer simplicity in",
    "start": "170879",
    "end": "176879"
  },
  {
    "text": "the application layer um and it also informs",
    "start": "176879",
    "end": "182360"
  },
  {
    "text": "the the tools we might use so early on when we're when we're doing performance",
    "start": "182360",
    "end": "188080"
  },
  {
    "text": "optimization um we might want to use metrics uh and uh something I work on",
    "start": "188080",
    "end": "193440"
  },
  {
    "text": "which is continuous profiling can help you find um bottlenecks and later on we",
    "start": "193440",
    "end": "198959"
  },
  {
    "text": "might change tac and uh move into uh microbenchmarks uh perf counters",
    "start": "198959",
    "end": "204080"
  },
  {
    "text": "instruction profiles as we try to improve um improve the code so who am I",
    "start": "204080",
    "end": "210080"
  },
  {
    "text": "uh my name is Richard Startin i'm a software engineer at uh data dog i work on continuous profiling i will talk",
    "start": "210080",
    "end": "216239"
  },
  {
    "text": "about continuous profiling here but we're we're not the only um we're not the only vendor and I it's it's not a",
    "start": "216239",
    "end": "221760"
  },
  {
    "text": "sales pitch um and I'm splitting the rest of the talk into three phases uh",
    "start": "221760",
    "end": "226959"
  },
  {
    "text": "based on the the um the lowhanging fruit the uh the tuning and the competitive",
    "start": "226959",
    "end": "233840"
  },
  {
    "text": "advantage stage that I've shown you before so we'll start in the green zone where we'll look at um how we might",
    "start": "233840",
    "end": "240799"
  },
  {
    "text": "start a performance uh how we might start a performance tuning exercise uh and some of the kinds of lowhanging",
    "start": "240799",
    "end": "247519"
  },
  {
    "text": "fruit that we we might encounter um so",
    "start": "247519",
    "end": "252720"
  },
  {
    "text": "before before you do anything uh if if you want to optimize you need you need an objective um so you need to really",
    "start": "252720",
    "end": "259840"
  },
  {
    "text": "know what you're trying to do it could be reduce latency or increase throughput or maybe reduce cost and these are",
    "start": "259840",
    "end": "266240"
  },
  {
    "text": "activities which which um might actually trade off against each other so you can imagine to improve",
    "start": "266240",
    "end": "274080"
  },
  {
    "text": "latency you might um take some processing off the critical path onto a background thread uh but that might cost",
    "start": "274080",
    "end": "280960"
  },
  {
    "text": "you some throughput if you have more context switches and you have the concurrency control that you need to",
    "start": "280960",
    "end": "286000"
  },
  {
    "text": "take care of and it may even increase cost so um you really need to know what",
    "start": "286000",
    "end": "291759"
  },
  {
    "text": "what you're going for and what your objective is um so uh most of the focus of this talk",
    "start": "291759",
    "end": "300240"
  },
  {
    "text": "will be will be in terms of cost reduction because that that's quite uh generic um and the the the ultimate aim is to",
    "start": "300240",
    "end": "308080"
  },
  {
    "text": "reduce hardware uh so we can um we want to focus on what's using memory or CPU",
    "start": "308080",
    "end": "313840"
  },
  {
    "text": "so we can use less of it um so for the sake of simplicity of the",
    "start": "313840",
    "end": "319680"
  },
  {
    "text": "talk um I'm focusing on CPU bottlenecks because um this is a fairly ubiquitous",
    "start": "319680",
    "end": "325440"
  },
  {
    "text": "problem uh and it uh applies nicely to you know whatever your objective is um",
    "start": "325440",
    "end": "332880"
  },
  {
    "text": "and the main point here is uh uh I'm going to talk about continuous profiling later but it's it's a good idea to start",
    "start": "332880",
    "end": "338320"
  },
  {
    "text": "with metrics uh so you actually know that you have a CPU uh consumption pro you have a CPU",
    "start": "338320",
    "end": "343919"
  },
  {
    "text": "utilization problem before you start looking at uh profiles otherwise going bottom up it can be too much information",
    "start": "343919",
    "end": "349759"
  },
  {
    "text": "you're not even sure you're going to get anywhere useful um so something dear to",
    "start": "349759",
    "end": "355440"
  },
  {
    "text": "my heart is continuous profiling so um it's really useful if you're always",
    "start": "355440",
    "end": "361600"
  },
  {
    "text": "running a profiler whether you know that you have a problem to analyze or not because when an unexpected problem comes",
    "start": "361600",
    "end": "368080"
  },
  {
    "text": "about then you you have the profiles you can just go and look at them and you'll get a breakdown of of what's using the",
    "start": "368080",
    "end": "373680"
  },
  {
    "text": "resource that you could you're concerned with um this is only actually possible because sampling CPU profile is a very",
    "start": "373680",
    "end": "380000"
  },
  {
    "text": "very low overhead um so what they do is they continuously sample threads",
    "start": "380000",
    "end": "385880"
  },
  {
    "text": "um in proportion to CPU time so the Linux kernel has um has has tools which",
    "start": "385880",
    "end": "392960"
  },
  {
    "text": "allow you to uh generate a signal um every you know whenever 10 milliseconds",
    "start": "392960",
    "end": "398400"
  },
  {
    "text": "of CPU time or a period of CPU time has has passed and then take a sample so if",
    "start": "398400",
    "end": "404240"
  },
  {
    "text": "you take a sample every 10 milliseconds of CPU time and it takes less than 100 microsconds to record a sample then",
    "start": "404240",
    "end": "410240"
  },
  {
    "text": "you're staying under 1% CPU overhead so it's possible for a lot of applications to actually just profile or at least do",
    "start": "410240",
    "end": "416560"
  },
  {
    "text": "CPU profiling continuously in production once you've um profiled your",
    "start": "416560",
    "end": "422080"
  },
  {
    "text": "entire fleet um you can aggregate all of the profiles together and you can look at uh fleet",
    "start": "422080",
    "end": "427840"
  },
  {
    "text": "level bottlenecks um so there are numerous technical options um there's two that I know more about through my",
    "start": "427840",
    "end": "434639"
  },
  {
    "text": "work which is JFR and async profiler these are JVM profilers which which run in process um and they each have their",
    "start": "434639",
    "end": "442160"
  },
  {
    "text": "merits and their drawbacks um so JFR for example it doesn't",
    "start": "442160",
    "end": "447440"
  },
  {
    "text": "actually have a true CPU profiler so it's got execution sample events they're scheduled they're not scheduled in in",
    "start": "447440",
    "end": "453440"
  },
  {
    "text": "response to CPU time and it doesn't actually report any of its errors and when you're taking profile samples uh",
    "start": "453440",
    "end": "460240"
  },
  {
    "text": "there can be a lot of error cases and it's important not to um destroy the statistics of the of the data set by uh",
    "start": "460240",
    "end": "468479"
  },
  {
    "text": "misreporting errors um async profiler which is um written by Andrew Pangan at",
    "start": "468479",
    "end": "473599"
  },
  {
    "text": "AWS uh solves an awful lot of problems so it's got two true CPU profilers um it",
    "start": "473599",
    "end": "478960"
  },
  {
    "text": "uses Perf events and it has a a a timer based solution and it has very rigorous",
    "start": "478960",
    "end": "484960"
  },
  {
    "text": "error reporting uh so on the downside it's using undocumented JVM internals um",
    "start": "484960",
    "end": "491599"
  },
  {
    "text": "unsupported APIs which in principle could be taken away at some point in the future um and those are the only two",
    "start": "491599",
    "end": "498080"
  },
  {
    "text": "inprocess JVM profilers which have low enough overhead to use in production um",
    "start": "498080",
    "end": "503840"
  },
  {
    "text": "there's um there's ebpf and and and and Perf which have their um their their own",
    "start": "503840",
    "end": "511599"
  },
  {
    "text": "uh pros and cons but I I don't want to get into those now because that that's kind of",
    "start": "511599",
    "end": "516719"
  },
  {
    "text": "outside my area of expertise um so in this first phase of",
    "start": "516719",
    "end": "522240"
  },
  {
    "text": "optimization once we've got a profiling tool that can show us where problems are",
    "start": "522240",
    "end": "527600"
  },
  {
    "text": "uh we want to focus on low hanging fruit these are these are generally problems that",
    "start": "527600",
    "end": "533399"
  },
  {
    "text": "um are essentially bugs and I'm going to start with something that I call non-functional bugs this is code which",
    "start": "533399",
    "end": "538959"
  },
  {
    "text": "produces the correct result um but goes about it in the wrong way",
    "start": "538959",
    "end": "545200"
  },
  {
    "text": "and in such a way so the the the error can only be detected by performance",
    "start": "545200",
    "end": "550600"
  },
  {
    "text": "measurement and so I'm I'm an Apache Pino committer which is a distributed OLAP database that originated at",
    "start": "550600",
    "end": "556880"
  },
  {
    "text": "LinkedIn i I used to work on Pino when I was working at Star Tree um and at some point I wanted to speed",
    "start": "556880",
    "end": "564080"
  },
  {
    "text": "up our test suite because it took quite a long time so I profiled it so I I I I profile the test suite rather than",
    "start": "564080",
    "end": "569120"
  },
  {
    "text": "rather than Pino in production uh and I noticed that the profile was dominated",
    "start": "569120",
    "end": "574720"
  },
  {
    "text": "by this library called Apache Helix which is used by Pino's controller to uh",
    "start": "574720",
    "end": "579839"
  },
  {
    "text": "schedule um schedule work to other participants in the Pino cluster so here",
    "start": "579839",
    "end": "585519"
  },
  {
    "text": "we can see uh the scheduleuling of um of jobs to something called the minions",
    "start": "585519",
    "end": "590560"
  },
  {
    "text": "which are basically workers uh which um uh do work on behalf of the rest of",
    "start": "590560",
    "end": "596720"
  },
  {
    "text": "the cluster and the profile shows that most of these controller CPU time is is generuling this job list which seems a",
    "start": "596720",
    "end": "603120"
  },
  {
    "text": "bit unusual um so the problem here is quite a common one in libraries so it's",
    "start": "603120",
    "end": "608880"
  },
  {
    "text": "an expectations mismatch on either side of the module boundaries so on we can see at the top um this is on the pen",
    "start": "608880",
    "end": "615680"
  },
  {
    "text": "side and it's basically saying it's setting it's setting a parallelism level and it's saying give me all you've got",
    "start": "615680",
    "end": "621360"
  },
  {
    "text": "because it sets integer max value you can't have more than that on the other side it's assuming that there will be",
    "start": "621360",
    "end": "626560"
  },
  {
    "text": "many more jobs in the level of parallelism so the loop termination condition um only checks for the level",
    "start": "626560",
    "end": "632880"
  },
  {
    "text": "of parallelism and it will just keep on looping round until",
    "start": "632880",
    "end": "639000"
  },
  {
    "text": "um until uh it gets to integer max value that can easily take 20 seconds of a",
    "start": "639000",
    "end": "644880"
  },
  {
    "text": "busy spin on CPU and it's not a very difficult problem to fix because all you have to do is check that all of the jobs",
    "start": "644880",
    "end": "650240"
  },
  {
    "text": "have been consumed um LinkedIn upgraded the Helix library after this after this",
    "start": "650240",
    "end": "655360"
  },
  {
    "text": "fix had been uh made and uh they actually published a blog post about it which is really great because you can",
    "start": "655360",
    "end": "661760"
  },
  {
    "text": "really dig into the details of and the the outcomes of what happened here so this led to a massive reduction in",
    "start": "661760",
    "end": "668920"
  },
  {
    "text": "um reduction in processing latency for for for jobs uh by you know 7x and you",
    "start": "668920",
    "end": "676560"
  },
  {
    "text": "can get away you can figure out whether um you can figure out whether you have a",
    "start": "676560",
    "end": "682480"
  },
  {
    "text": "performance problem with with things like um you know back of the envelope calculations where you can figure out what's reasonable uh for for a uh for a",
    "start": "682480",
    "end": "690480"
  },
  {
    "text": "task to take how h how much resources should it take uh with back of the envelope calcul calculations but it's",
    "start": "690480",
    "end": "695519"
  },
  {
    "text": "very difficult when you have the abstraction of libraries in the way uh if you if the libraries are doing things for you that you um you you don't know",
    "start": "695519",
    "end": "704079"
  },
  {
    "text": "how to do it you you you don't understand the problem so um abstraction can make it hard whereas a profiler will",
    "start": "704079",
    "end": "711360"
  },
  {
    "text": "just show you that there's a problem and you can go and fix it it's it's normally quite easy um there's also poor",
    "start": "711360",
    "end": "717839"
  },
  {
    "text": "programming practices i I'll try and skip over this one quite quickly um I think most people have seen stuff like this so this is something that I dug out",
    "start": "717839",
    "end": "725040"
  },
  {
    "text": "of um a profile at some point um and it's basically programmed by exception",
    "start": "725040",
    "end": "731040"
  },
  {
    "text": "so um to convert um a a double to a long if the if it's uh you know if the",
    "start": "731040",
    "end": "738560"
  },
  {
    "text": "mantisa is zero if it if it's an integral value then construct a big decimal which is expensive and then get",
    "start": "738560",
    "end": "744079"
  },
  {
    "text": "the exact long value and uh th which will throw an exception if it if the input was a double and then catch the",
    "start": "744079",
    "end": "750639"
  },
  {
    "text": "exception and return that so it's obvious that you know this this can be done better by doing some arithmetic and",
    "start": "750639",
    "end": "756720"
  },
  {
    "text": "if you compare this as like a 150x improvement u and these are just the",
    "start": "756720",
    "end": "761760"
  },
  {
    "text": "kinds of problems that like work their way into application code um when you're",
    "start": "761760",
    "end": "766880"
  },
  {
    "text": "in the um you you're kind of bootstrapping a product um also",
    "start": "766880",
    "end": "772240"
  },
  {
    "text": "algorithmic issues I mean this is an interesting one from um from data dog um",
    "start": "772240",
    "end": "777760"
  },
  {
    "text": "we can get algorithmicities for a number of reasons mostly because of abstraction uh so you can you can get accidentally",
    "start": "777760",
    "end": "784000"
  },
  {
    "text": "too high um complexity algorithmic complexity uh because of composition uh",
    "start": "784000",
    "end": "789519"
  },
  {
    "text": "in ways that wasn't expected or you can have uh rare cases that you didn't",
    "start": "789519",
    "end": "795519"
  },
  {
    "text": "expect to be rare in fact you might have a comment saying this never happens but this is a fallback and you don't put too much effort into implementing the most",
    "start": "795519",
    "end": "802000"
  },
  {
    "text": "optimal fallback and then it turns out in production that um that that fallback",
    "start": "802000",
    "end": "807360"
  },
  {
    "text": "is is is um is not so rare um so this actually came up at data dog in in one",
    "start": "807360",
    "end": "812560"
  },
  {
    "text": "of our backend processes which um processes JFR files from our customers and so we use a JMC JFR paraser to pass",
    "start": "812560",
    "end": "820639"
  },
  {
    "text": "the JFR files and all of a sudden it started timing out but only for one customer so fortunately we we profile",
    "start": "820639",
    "end": "828000"
  },
  {
    "text": "that that um that service which is doing the passing so it's kind of like profiling inception um and we quickly",
    "start": "828000",
    "end": "834800"
  },
  {
    "text": "identified that um all of the time was being spent in this this method disjoint builder add and what this just just as a",
    "start": "834800",
    "end": "843519"
  },
  {
    "text": "quick overview so we we can understand the problem um this is trying to turn events which have a start and uh an end",
    "start": "843519",
    "end": "850480"
  },
  {
    "text": "an end time stamp um into disjoint into lanes uh so that",
    "start": "850480",
    "end": "856320"
  },
  {
    "text": "the events the the intervals are disjoint in a lane so if none of the events overlap then we only have one",
    "start": "856320",
    "end": "862560"
  },
  {
    "text": "lane and that was expected to be the common case and if all of the events overlap then we have lots of lanes so",
    "start": "862560",
    "end": "868079"
  },
  {
    "text": "what the code was doing to maintain this it was basically saying I don't expect it ever to have more than one lane so uh",
    "start": "868079",
    "end": "874480"
  },
  {
    "text": "if that ever happens to maintain an invariant of sort order I'll just sort the entire set of lanes over and over",
    "start": "874480",
    "end": "880320"
  },
  {
    "text": "again um because of a bug in um because of a bug in the JDK actually um where",
    "start": "880320",
    "end": "888160"
  },
  {
    "text": "file writer some tracing around file write events was recording the uh the end time stamp rather than the duration",
    "start": "888160",
    "end": "894959"
  },
  {
    "text": "as the duration so we would always get um events which don't overlap um if",
    "start": "894959",
    "end": "900639"
  },
  {
    "text": "you're using that kind of file API and so we'd be process um taking these these",
    "start": "900639",
    "end": "906880"
  },
  {
    "text": "um these events in and uh the assumption would would be quite",
    "start": "906880",
    "end": "913920"
  },
  {
    "text": "catastrophic and we'd end up with a cubic time algorithm it's very easy to fix this just by finding the insertion point we still don't get a really",
    "start": "913920",
    "end": "920480"
  },
  {
    "text": "optimal solution but it would be very difficult to change everything else but this was enough to fix the problem here",
    "start": "920480",
    "end": "925839"
  },
  {
    "text": "so just like something unexpected has happened in production basically um",
    "start": "925839",
    "end": "931760"
  },
  {
    "text": "there's also going against a grain so there lots of existing optimizations in frameworks which target",
    "start": "931760",
    "end": "938800"
  },
  {
    "text": "idiomatic code so if you don't write idiomatic code then you won't profit from these optimizations a common one is",
    "start": "938800",
    "end": "944880"
  },
  {
    "text": "like composite lookup so you have a hashmap uh with two two or more values you could concatenate the values",
    "start": "944880",
    "end": "951279"
  },
  {
    "text": "together and look them up in the map or you could you know construct a record and if we compare the performance here",
    "start": "951279",
    "end": "957360"
  },
  {
    "text": "there's basically like a 3 to 4x performance difference and I call this I call the stringly typed and type safe",
    "start": "957360",
    "end": "964399"
  },
  {
    "text": "because there are like prefix and suffix overlap bugs in the string version which",
    "start": "964399",
    "end": "969680"
  },
  {
    "text": "you just don't need to think about with type safe so you're getting better performance but you're also um you",
    "start": "969680",
    "end": "975839"
  },
  {
    "text": "you're avoiding bugs and um ultimately um you're just writing objectively",
    "start": "975839",
    "end": "982079"
  },
  {
    "text": "better code um so why not just find all",
    "start": "982079",
    "end": "987680"
  },
  {
    "text": "of the bad code in your codebase with static analysis well there might be quite a lot of it some of it might never",
    "start": "987680",
    "end": "993360"
  },
  {
    "text": "run uh some of it might not run very much the benefit of having a profiler is that um you know it's worth fixing if",
    "start": "993360",
    "end": "999839"
  },
  {
    "text": "you see it in the profile uh because it it definitely happened that way um and people might have different thresholds",
    "start": "999839",
    "end": "1005920"
  },
  {
    "text": "on when to act here but um normally these kinds of optimizations they're",
    "start": "1005920",
    "end": "1012160"
  },
  {
    "text": "just win-win um all of this assumes that um the",
    "start": "1012160",
    "end": "1018000"
  },
  {
    "text": "profiling data is is accurate enough to act on um and profiling is it's quite",
    "start": "1018000",
    "end": "1024480"
  },
  {
    "text": "surprising that profiling is um you think that you're just you know interrupting the thread and collecting a",
    "start": "1024480",
    "end": "1030640"
  },
  {
    "text": "stack trace and that should be quite simple um it's actually not because there are so many different kinds of code running on a on a JVM uh stack so",
    "start": "1030640",
    "end": "1039120"
  },
  {
    "text": "we have uh code running in the interpreter uh which hasn't been compiled yet then it gets jit compiled",
    "start": "1039120",
    "end": "1044160"
  },
  {
    "text": "if it gets hot we have generated native code which is basically uh you know C++",
    "start": "1044160",
    "end": "1049520"
  },
  {
    "text": "code which is generated at runtime based on the platform capabilities which is slightly different to JIT compiled code",
    "start": "1049520",
    "end": "1055039"
  },
  {
    "text": "it's it's it's not come from um bite code in the first place and then finally",
    "start": "1055039",
    "end": "1060240"
  },
  {
    "text": "we have native code that we might call from uh from JNI and that's kind of dangerous as well so and it's there are",
    "start": "1060240",
    "end": "1067840"
  },
  {
    "text": "you know problems um complications that I won't go into now uh in unwinding Java stacks outside",
    "start": "1067840",
    "end": "1074080"
  },
  {
    "text": "of a safe point because some of the code in the JVM to do this just never expected to be called outside of a safe",
    "start": "1074080",
    "end": "1080240"
  },
  {
    "text": "point so it's not always you know safe or possible to get a sample um and this",
    "start": "1080240",
    "end": "1085679"
  },
  {
    "text": "can lead to errors so let's compare the uh the stringly type lookup profiles taken by JFR where we get these figures",
    "start": "1085679",
    "end": "1092880"
  },
  {
    "text": "um notably 27% in string hash code and just 31% um 8% of samples in string get",
    "start": "1092880",
    "end": "1099440"
  },
  {
    "text": "bytes and then async profiler reports something completely different so it it",
    "start": "1099440",
    "end": "1104480"
  },
  {
    "text": "reports much more time in uh string get bytes and a little less time in the hash",
    "start": "1104480",
    "end": "1110720"
  },
  {
    "text": "code method um this is because of this red frame",
    "start": "1110720",
    "end": "1116080"
  },
  {
    "text": "here which is um which is a runtime stub um so jbyte disjoint array copy is a",
    "start": "1116080",
    "end": "1122559"
  },
  {
    "text": "runtime stub um this is code which is generated at at at runtime and uh JFR can't unwind these",
    "start": "1122559",
    "end": "1130919"
  },
  {
    "text": "because the unwinding code never expected to encounter them because they they can't be encountered outside of a",
    "start": "1130919",
    "end": "1136240"
  },
  {
    "text": "safe point um whereas async profiling knows about them it manually um unwinds",
    "start": "1136240",
    "end": "1142480"
  },
  {
    "text": "it pops this frame and then it gets into the Java code where it can unwind from um so yeah if you if you have two",
    "start": "1142480",
    "end": "1149440"
  },
  {
    "text": "profilers you're not really sure what your bottlenecks are because they report completely different things but they do agree on the on the type on the type",
    "start": "1149440",
    "end": "1155760"
  },
  {
    "text": "safe lookup so uh we get some benefits here we're not constructing a new string we're not concatenating strings and also",
    "start": "1155760",
    "end": "1162799"
  },
  {
    "text": "interestingly there's next to no time in string hash code and JFR does agree so it's not like JFR is uh like a hopeless",
    "start": "1162799",
    "end": "1168799"
  },
  {
    "text": "case um it's it's there are specific cases where it goes wrong and it doesn't",
    "start": "1168799",
    "end": "1173840"
  },
  {
    "text": "tell you that it's gone wrong but it can agree with async profiler um and this is important for the rest of the talk",
    "start": "1173840",
    "end": "1179760"
  },
  {
    "text": "because we're going to change tac as we get into the different phases of the curve um the important thing here is",
    "start": "1179760",
    "end": "1185280"
  },
  {
    "text": "that uh a string caches its hash code and so if you write code which does",
    "start": "1185280",
    "end": "1192080"
  },
  {
    "text": "things with strings where you have to hash the strings in such a way that you um you work with the caching of this",
    "start": "1192080",
    "end": "1199039"
  },
  {
    "text": "hash code you don't need to compute the hash code but if you don't then we'll get into um we'll be we'll be computing",
    "start": "1199039",
    "end": "1205520"
  },
  {
    "text": "the hash code and that might get to be expensive so we're kind of moving into the next zone in the talk now so this is the amber zone this is kind of tuning um",
    "start": "1205520",
    "end": "1212320"
  },
  {
    "text": "some of the stuff I'll talk about here I don't ne necessarily suggest that that people try um uh it's not necessarily",
    "start": "1212320",
    "end": "1219200"
  },
  {
    "text": "helpful um but uh it in in in some cases it it it it'll make a difference um so",
    "start": "1219200",
    "end": "1226480"
  },
  {
    "text": "what do we do at data dog we we ingest a lot of observability data um a lot of our backend is written in Go",
    "start": "1226480",
    "end": "1233600"
  },
  {
    "text": "but we also have a lot of Java services and they're large enough to be worth optimizing uh for the sake of cost also",
    "start": "1233600",
    "end": "1240640"
  },
  {
    "text": "meeting SLAs's um so when you've got when you've got u when you profile your",
    "start": "1240640",
    "end": "1247200"
  },
  {
    "text": "entire fleet you can do things like uh take all of the data aggregate the data together convert it into cores and then",
    "start": "1247200",
    "end": "1254400"
  },
  {
    "text": "u multiply the number of cores in a unit time by the cost from your cloud provider um in that in that unit of time",
    "start": "1254400",
    "end": "1263200"
  },
  {
    "text": "and um uh and you can basically compute the",
    "start": "1263200",
    "end": "1268880"
  },
  {
    "text": "cost that different methods um uh you how much you're paying for different methods so it turns out that actually at",
    "start": "1268880",
    "end": "1275280"
  },
  {
    "text": "data dog for some reason we spend an awful lot of time um in string hash code and so what we could do uh so this",
    "start": "1275280",
    "end": "1281440"
  },
  {
    "text": "turned out to be the most expensive method what we could do is we could find all of the uses of it and optimize them individually but it's death by a",
    "start": "1281440",
    "end": "1287280"
  },
  {
    "text": "thousand cuts uh and if we went and found them all and we we optimized them",
    "start": "1287280",
    "end": "1292400"
  },
  {
    "text": "away to do something different there'd be more of them in two weeks time um so what can you actually do so we we",
    "start": "1292400",
    "end": "1299200"
  },
  {
    "text": "actually have to optimize this method and we so we found this hot method like what can we actually do um so we can",
    "start": "1299200",
    "end": "1305360"
  },
  {
    "text": "stare really hard at the code but it's the problem's not actually jumping out at me just looking at this if if if any",
    "start": "1305360",
    "end": "1311360"
  },
  {
    "text": "of you have any ideas um let me know um or we could what we could do is we could relax the requirements in the context of",
    "start": "1311360",
    "end": "1318799"
  },
  {
    "text": "um string hash code we might want to compute a compute the hash code in a a",
    "start": "1318799",
    "end": "1325120"
  },
  {
    "text": "completely different algorithm a different way produce a different result um and this is like moving to uh to have",
    "start": "1325120",
    "end": "1332720"
  },
  {
    "text": "a nicer problem and this is going to have a dual effect because a lot of people in the Java community know that",
    "start": "1332720",
    "end": "1337840"
  },
  {
    "text": "strings hash code is not particularly good in terms of randomness and why are we computing hash codes in the first",
    "start": "1337840",
    "end": "1344640"
  },
  {
    "text": "place it's because we're using hashmaps and so we don't want collisions in the hashmaps and so if we had a better algorithm which produced a more random",
    "start": "1344640",
    "end": "1351520"
  },
  {
    "text": "result then we could uh we could solve two problems uh so we'd have a faster",
    "start": "1351520",
    "end": "1357520"
  },
  {
    "text": "algorithm to to to to compute and we'd have fewer fewer collisions in the hashmaps which would have secondary",
    "start": "1357520",
    "end": "1363320"
  },
  {
    "text": "benefits um so the problem with changing the algorithm is it's specified in the JLS",
    "start": "1363320",
    "end": "1369520"
  },
  {
    "text": "but it's kind of hard to believe that this is really an immovable obstacle uh because it was originally specified",
    "start": "1369520",
    "end": "1374640"
  },
  {
    "text": "incorrectly in the '90s so the specification was reverse engineered from the implementation uh but it was",
    "start": "1374640",
    "end": "1380159"
  },
  {
    "text": "reverse engineered incorrectly so they changed the specification to make it correct and then it was noticed because",
    "start": "1380159",
    "end": "1387120"
  },
  {
    "text": "the hashcode algorithm the original one it only depended on the first 16 characters the first 16 characters of",
    "start": "1387120",
    "end": "1393760"
  },
  {
    "text": "the string which trivially produced a lot of collisions and so for the sake of reducing the number of collisions the",
    "start": "1393760",
    "end": "1399440"
  },
  {
    "text": "algorithm was changed um so that that was I I think this was",
    "start": "1399440",
    "end": "1404880"
  },
  {
    "text": "resolved in 1999 so a long time ago now um so the real problem that this can't",
    "start": "1404880",
    "end": "1411039"
  },
  {
    "text": "be changed is that Java 7 introduced switch statements on strings so this is a switch expression uh which is",
    "start": "1411039",
    "end": "1420000"
  },
  {
    "text": "um a more modern uh a more modern way to write Java code but um it's it's",
    "start": "1420120",
    "end": "1425840"
  },
  {
    "text": "fundamentally very similar to a switch statement which happened back in Java 7 and if we actually look at the the bite",
    "start": "1425840",
    "end": "1431919"
  },
  {
    "text": "code for how this is compiled we'll see that it in the invoke virtual up there is on the string hash code and then we",
    "start": "1431919",
    "end": "1437600"
  },
  {
    "text": "basically have a lookup switch on the the hash code values so the output of the function is now as of Java 17 is",
    "start": "1437600",
    "end": "1445760"
  },
  {
    "text": "hardcoded into class files and then we don't know how many of those there could be in the last you know uh 13 years or",
    "start": "1445760",
    "end": "1451840"
  },
  {
    "text": "whatever it's been since Java 7 uh so to maintain backward compatibility we just can't change the algorithm so that kind",
    "start": "1451840",
    "end": "1457600"
  },
  {
    "text": "of um we can't avoid solving this problem um so we kind of have to change tac um",
    "start": "1457600",
    "end": "1465400"
  },
  {
    "text": "the we can't really stare at the code the line number information we might get from a profiler isn't going to be very",
    "start": "1465400",
    "end": "1470720"
  },
  {
    "text": "revealing because the code is so simple so we can produce a a microbenchmark with um with JH and what this",
    "start": "1470720",
    "end": "1477440"
  },
  {
    "text": "microbenchmark here is doing is creating random bite arrays uh of parameterize",
    "start": "1477440",
    "end": "1483840"
  },
  {
    "text": "range of sizes try not to uh choose multiples of eight um because that's",
    "start": "1483840",
    "end": "1490000"
  },
  {
    "text": "that's going to give the the hardware an easy time so try to choose um something",
    "start": "1490000",
    "end": "1498279"
  },
  {
    "text": "uh you know like uh seven um and uh so it's constructing a new string to make",
    "start": "1498279",
    "end": "1505039"
  },
  {
    "text": "sure that the hash code doesn't get cached uh so if we compare this to anything to have a fair test we're going",
    "start": "1505039",
    "end": "1511200"
  },
  {
    "text": "to have to um also do these same operations so we have the same the same baseline cost uh and JMH gives you all",
    "start": "1511200",
    "end": "1519760"
  },
  {
    "text": "of these micro profilers and all of this was written by Alexi Shipv um very useful tooling uh to help you explain um",
    "start": "1519760",
    "end": "1529360"
  },
  {
    "text": "what the um to help you explain the benchmark results so you're not just saying A is",
    "start": "1529360",
    "end": "1534960"
  },
  {
    "text": "faster than B you you you you you have uh things like Perf counters from the Perf norm profiler which basically",
    "start": "1534960",
    "end": "1540640"
  },
  {
    "text": "normalizes the Perf counters to the benchmark invocations and then um it",
    "start": "1540640",
    "end": "1546799"
  },
  {
    "text": "will give you um it'll give you something like IPC which is instructions per cycle and this is this is a good",
    "start": "1546799",
    "end": "1553279"
  },
  {
    "text": "measure of how efficient the code is um it's it's uh essentially dividing the number of instructions during the",
    "start": "1553279",
    "end": "1559600"
  },
  {
    "text": "benchmark run by the number of cycles per invocation and so we can see we're starting at four and we're uh as the",
    "start": "1559600",
    "end": "1565760"
  },
  {
    "text": "string gets longer we're going down under two which is which is not particularly good um there's another",
    "start": "1565760",
    "end": "1571520"
  },
  {
    "text": "profiler for explaining explain your benchmark results in a different way which is the",
    "start": "1571520",
    "end": "1577919"
  },
  {
    "text": "Perth ASM profiler and that works by um loading um HSIS which is a hotspot",
    "start": "1577919",
    "end": "1584720"
  },
  {
    "text": "disassembler uh putting that in a location where the JVM can load it and then that will allow um the JVM to",
    "start": "1584720",
    "end": "1592080"
  },
  {
    "text": "decompile code blobs wherever wherever they land um and you can build that with um ben uut tools or capstone or whatever",
    "start": "1592080",
    "end": "1598799"
  },
  {
    "text": "disassembly you like and uh then it does it goes more it goes further than that",
    "start": "1598799",
    "end": "1603840"
  },
  {
    "text": "and it links the program counters which is what perf samples with the jet compile code blobs so it can produce",
    "start": "1603840",
    "end": "1612640"
  },
  {
    "text": "um a histogram like this which is uh very useful because you can check whether what you think should be running",
    "start": "1612640",
    "end": "1619120"
  },
  {
    "text": "is running um and here we can see that 80% is in the benchmark stub um a total",
    "start": "1619120",
    "end": "1625919"
  },
  {
    "text": "of 8% is in code that we constructing strings and the and and copying the",
    "start": "1625919",
    "end": "1631440"
  },
  {
    "text": "strings which we know is um coming from the benchmark stub and then there's",
    "start": "1631440",
    "end": "1637520"
  },
  {
    "text": "there's another interesting thing which is in in my system I haven't set up debug symbols for the kernel so it's",
    "start": "1637520",
    "end": "1642880"
  },
  {
    "text": "saying that 9% of the time is is is spent in the kernel and we don't know where so that's a really important thing",
    "start": "1642880",
    "end": "1648000"
  },
  {
    "text": "to to to check before you interpret the the the the uh data you get from here and it produces this kind of um this",
    "start": "1648000",
    "end": "1654880"
  },
  {
    "text": "output it's worth getting to understand this um before going any further because it's important for understanding the",
    "start": "1654880",
    "end": "1660400"
  },
  {
    "text": "rest of the talk so on the left hand side you have percentages and those are computed from how and the the scary",
    "start": "1660400",
    "end": "1668080"
  },
  {
    "text": "looking addresses in the middle are program counters so the percentages are how many times of all of the program",
    "start": "1668080",
    "end": "1673840"
  },
  {
    "text": "counter samples um that program counter was sampled by Perf and then we have the instructions on the right hand side so",
    "start": "1673840",
    "end": "1681600"
  },
  {
    "text": "we kind of have an instruction profile um it's very hard to interpret the percentages on the left hand side",
    "start": "1681600",
    "end": "1687600"
  },
  {
    "text": "because there are lots of confounding factors so there are things like skid where the an instruction a few",
    "start": "1687600",
    "end": "1693200"
  },
  {
    "text": "instructions late gets blamed um so you have the wrong the wrong suspect and we have things like pipelining but there's",
    "start": "1693200",
    "end": "1699760"
  },
  {
    "text": "only one instruction pointer so if you have multiple instructions in flight which one do you blame",
    "start": "1699760",
    "end": "1705559"
  },
  {
    "text": "um but it does give you very useful output which can help you to understand problems the first thing we can notice",
    "start": "1705559",
    "end": "1712240"
  },
  {
    "text": "so this is this is the this is the output for the string hash code uh which should have a lot of multiplications in",
    "start": "1712240",
    "end": "1719559"
  },
  {
    "text": "it but we don't see any so you have um if you don't read x86 assembly you can",
    "start": "1719559",
    "end": "1724799"
  },
  {
    "text": "see there's an add move shift left sub but there's there's no",
    "start": "1724799",
    "end": "1730120"
  },
  {
    "text": "multiplication um and this is actually in intentional um so compilers do",
    "start": "1730120",
    "end": "1736240"
  },
  {
    "text": "something called a strength reduction which is an optimization a compiler can apply uh when it has information about",
    "start": "1736240",
    "end": "1741760"
  },
  {
    "text": "constants and in this particular case we know that a multiple by 31 is a difference of a multiple by 32 and the",
    "start": "1741760",
    "end": "1748960"
  },
  {
    "text": "value subtracted from that multiple and multiplying by 32 is nice because the compiler can replace that multiplication",
    "start": "1748960",
    "end": "1754880"
  },
  {
    "text": "with a with a left shift and this was actually ch the value of 31 was chosen",
    "start": "1754880",
    "end": "1762559"
  },
  {
    "text": "back in the 90s to enable this optimization um but if we look at the structure of",
    "start": "1762559",
    "end": "1769760"
  },
  {
    "text": "the code we can see that this code has been has been unrolled uh so we can see the same code over and over again and in",
    "start": "1769760",
    "end": "1776480"
  },
  {
    "text": "between each of these blocks we don't have any control flow so we're not checking the loop conditions uh so",
    "start": "1776480",
    "end": "1781760"
  },
  {
    "text": "that's good that's saving some overhead per bite each of these blocks is processing one",
    "start": "1781760",
    "end": "1787159"
  },
  {
    "text": "bite um but unfortunately we have what's known as a dependency chain um so first",
    "start": "1787159",
    "end": "1793840"
  },
  {
    "text": "we start by um bumping the um the loop",
    "start": "1793840",
    "end": "1798960"
  },
  {
    "text": "induction variable then we load a load of data four at a time these these um instructions don't block each other and",
    "start": "1798960",
    "end": "1804880"
  },
  {
    "text": "in principle they can happen at the same time and then we have this long sorry um",
    "start": "1804880",
    "end": "1810320"
  },
  {
    "text": "chain of uh instructions which can only happen one at a time and that makes us",
    "start": "1810320",
    "end": "1815640"
  },
  {
    "text": "sad um but it may or may not seem like a problem to you because the program is sequential um the execution is also",
    "start": "1815640",
    "end": "1822960"
  },
  {
    "text": "sequential so where were we expecting to get parallelism from and the instruction latencies are very low so it's worth",
    "start": "1822960",
    "end": "1828799"
  },
  {
    "text": "looking at how instructions are actually executed so first of all in the front end they're decoding these things called",
    "start": "1828799",
    "end": "1834799"
  },
  {
    "text": "microlops or u ops u for mu um by the front end the u ops are then executed",
    "start": "1834799",
    "end": "1841679"
  },
  {
    "text": "out of order and scheduled across a number of uh ports um and instructions",
    "start": "1841679",
    "end": "1847360"
  },
  {
    "text": "have affinity reports so certain instructions can only execute on certain ports uh so the execution engine is",
    "start": "1847360",
    "end": "1853840"
  },
  {
    "text": "designed to exploit um any nonsequential you know out of order",
    "start": "1853840",
    "end": "1860760"
  },
  {
    "text": "um it is it's designed to exploit um any non-sequentialism in in in in the",
    "start": "1860760",
    "end": "1867039"
  },
  {
    "text": "program and so it can do things out of order and it's designed to um it's it's",
    "start": "1867039",
    "end": "1872559"
  },
  {
    "text": "designed to execute out of order so long as um and and and this works so long as you don't have a data dependency so we",
    "start": "1872559",
    "end": "1879120"
  },
  {
    "text": "can think of um IPC which I showed you earlier as almost like a utilization metric for the execution engine so if we",
    "start": "1879120",
    "end": "1884640"
  },
  {
    "text": "get a lot of instruction level parallelism IPC is high that means that we're executing lots of instructions over the execution ports there's a great",
    "start": "1884640",
    "end": "1892000"
  },
  {
    "text": "simulator where you can just load some assembly code on um uops.info which shows you basically like",
    "start": "1892000",
    "end": "1898480"
  },
  {
    "text": "a gant chart waterfall for for how the code is actually executing and basically",
    "start": "1898480",
    "end": "1903919"
  },
  {
    "text": "um we can see this long diagonal um waterfall of um of of green retired",
    "start": "1903919",
    "end": "1910679"
  },
  {
    "text": "blocks uh and that's something that we'd like to avoid um so the next thing to do to to",
    "start": "1910679",
    "end": "1919279"
  },
  {
    "text": "think about how to improve the performance of the hash code is to look at the uh the chain latency these",
    "start": "1919279",
    "end": "1924880"
  },
  {
    "text": "instructions for each bite so and go back to pentium when the",
    "start": "1924880",
    "end": "1931360"
  },
  {
    "text": "optimization like choosing 31 as the multiple was uh was applied so back in",
    "start": "1931360",
    "end": "1936480"
  },
  {
    "text": "those days um multiplying integers was really expensive it cost nine cycles",
    "start": "1936480",
    "end": "1941519"
  },
  {
    "text": "whereas uh the add move shift left sub uh routine that we that we've seen in",
    "start": "1941519",
    "end": "1946640"
  },
  {
    "text": "the disassembly only cost four so this was actually a pretty decent optimization back in the day but",
    "start": "1946640",
    "end": "1951919"
  },
  {
    "text": "nowadays multiplication is much faster uh and and there's",
    "start": "1951919",
    "end": "1957240"
  },
  {
    "text": "there's there's there's nothing there's nothing between them i",
    "start": "1957240",
    "end": "1962720"
  },
  {
    "text": "got these numbers from Agna Fog's instruction tables which are really useful i don't actually have a Pentium to measure this on um so that that",
    "start": "1962720",
    "end": "1969679"
  },
  {
    "text": "that's that's where I got those numbers from um so if we want to optimize this then we kind of need to replace uh total",
    "start": "1969679",
    "end": "1976159"
  },
  {
    "text": "order with partial order and the approach we'll take is to",
    "start": "1976159",
    "end": "1981279"
  },
  {
    "text": "um set up a recurrence relation and we're going to um substitute the last value into the into the next iteration",
    "start": "1981279",
    "end": "1988000"
  },
  {
    "text": "for each for each iteration so we're substituting this in and then keeping",
    "start": "1988000",
    "end": "1993600"
  },
  {
    "text": "track of these multiples of 32 and the subtractions gets really unwieldy and so if we just cave in and we just multiply",
    "start": "1993600",
    "end": "1999760"
  },
  {
    "text": "by 31 instead we start to get this polomial expression uh and it gets very simple and if we go all the way down to",
    "start": "1999760",
    "end": "2005519"
  },
  {
    "text": "the base case we can see this is just a polomial so it's quite easy to deal with and this leads to this possible I call",
    "start": "2005519",
    "end": "2011919"
  },
  {
    "text": "it crazy unroll and this code looks pretty ugly um but uh there there's",
    "start": "2011919",
    "end": "2018720"
  },
  {
    "text": "there's something to it um I don't suggest people do this but people tend to assume in high level languages that",
    "start": "2018720",
    "end": "2024720"
  },
  {
    "text": "it's not possible to outdo legit compiler so if you have two programs which um which produce the same output",
    "start": "2024720",
    "end": "2031679"
  },
  {
    "text": "that the compiler will somehow magically optimize them both the same way um you can by understanding the gaps in the jet",
    "start": "2031679",
    "end": "2038159"
  },
  {
    "text": "compiler you can you can find ways to beat it um I wouldn't bother most of the time but this this was uh a case where",
    "start": "2038159",
    "end": "2046000"
  },
  {
    "text": "we could do this so what's going to happen here is so first of all we need to deal with the the remainder and then",
    "start": "2046000",
    "end": "2052720"
  },
  {
    "text": "we have this big unrolled loop which does all of these multiplications and but it's basically looking ahead in the loop uh to premp compute some of the",
    "start": "2052720",
    "end": "2059118"
  },
  {
    "text": "multiplications we're not doing lots of extra multiplications because we have constant folding and so we can see that the uh those multip those um powers of",
    "start": "2059119",
    "end": "2067760"
  },
  {
    "text": "31 are are precomputed by and loaded into the bite code so we don't need to worry about that and if we actually",
    "start": "2067760",
    "end": "2074000"
  },
  {
    "text": "measure the performance of this we've improved IPC so we know that we're making better use of the execution",
    "start": "2074000",
    "end": "2079200"
  },
  {
    "text": "engine with this code and we we managed to outsmart the JIT compiler",
    "start": "2079200",
    "end": "2085040"
  },
  {
    "text": "um so if we actually inspect the JIT compile code uh we can see why this is",
    "start": "2085240",
    "end": "2090480"
  },
  {
    "text": "uh so here we are we're in principle we can load all of the data you know eight",
    "start": "2090480",
    "end": "2096000"
  },
  {
    "text": "eight bytes at a time uh in parallel they're not going to block each other and then we can do these at the same",
    "start": "2096000",
    "end": "2101440"
  },
  {
    "text": "time in principle and so on uh and that gives us uh a faster",
    "start": "2101440",
    "end": "2108720"
  },
  {
    "text": "implementation by about 2x why is that it shouldn't be faster really because",
    "start": "2108720",
    "end": "2114200"
  },
  {
    "text": "the strength reduction sequence of instructions has the same latency but if you look at the reciprocal throughput of",
    "start": "2114200",
    "end": "2120320"
  },
  {
    "text": "the instructions um reciprocal throughput of one means that once you've",
    "start": "2120320",
    "end": "2126079"
  },
  {
    "text": "uh once you've um issued one instruction you can wait one cycle to issue another",
    "start": "2126079",
    "end": "2131800"
  },
  {
    "text": "um and if uh you have a reciprocal throughput of 0.25 you can you can issue",
    "start": "2131800",
    "end": "2137280"
  },
  {
    "text": "um four per cycle and you you you don't need to wait um you don't need to wait",
    "start": "2137280",
    "end": "2143040"
  },
  {
    "text": "uh for for the first instruction to complete so we have a kind of a gant chart like",
    "start": "2143040",
    "end": "2149040"
  },
  {
    "text": "this and we can see that after six cycles um we have all of these um we we've actually processed three",
    "start": "2149040",
    "end": "2156240"
  },
  {
    "text": "bytes which gives us two cycles per bite versus four cycles per bite so that's twice as fast and that explains why",
    "start": "2156240",
    "end": "2162320"
  },
  {
    "text": "we're you know twice as fast to compute the result and we can also um put the",
    "start": "2162320",
    "end": "2168480"
  },
  {
    "text": "disassembly into the the the UP the instructionuling uh simulator and we can see it's much more parallel if we put",
    "start": "2168480",
    "end": "2174720"
  },
  {
    "text": "them side by side we used to have this diagonal waterfall and um now we have",
    "start": "2174720",
    "end": "2180560"
  },
  {
    "text": "something which is much deeper um we do have a problem though because we have this data dependency again on this ECX",
    "start": "2180560",
    "end": "2186720"
  },
  {
    "text": "register we can see all of these add instructions are trying to add to the same register which creates a data",
    "start": "2186720",
    "end": "2191920"
  },
  {
    "text": "dependency and that is because we're loading the hash at the start of each loop iteration then we have to add all",
    "start": "2191920",
    "end": "2197359"
  },
  {
    "text": "of these numbers together into the hash so we're basically um forking and merging back we'd be",
    "start": "2197359",
    "end": "2204560"
  },
  {
    "text": "doing this computation effectively in parallel and then merging back into the intermediate result for each iteration",
    "start": "2204560",
    "end": "2210880"
  },
  {
    "text": "and that's basically limiting the amount of parallelism we can get um so you know I'd say this arguably",
    "start": "2210880",
    "end": "2217119"
  },
  {
    "text": "an optimization because it's twice as fast it's pure Java um it's pretty easy to understand even",
    "start": "2217119",
    "end": "2223119"
  },
  {
    "text": "if it's ugly um it does increase the bite code size which is a bit of a problem if we want to get this into open",
    "start": "2223119",
    "end": "2229599"
  },
  {
    "text": "JDK and it may you know it may penalize um smaller shorter strings um if um we",
    "start": "2229599",
    "end": "2237920"
  },
  {
    "text": "no longer get inlining because the bite code size is too large so this was actually submitted uh as a proposal to",
    "start": "2237920",
    "end": "2244640"
  },
  {
    "text": "open JDK um to you know kind of solve our our",
    "start": "2244640",
    "end": "2250560"
  },
  {
    "text": "cost problem because we'd identified that the hash code was costing us so much money to to to compute and we kind",
    "start": "2250560",
    "end": "2257200"
  },
  {
    "text": "of get into the red zone now um because straight away you rightly open JDK kind",
    "start": "2257200",
    "end": "2262960"
  },
  {
    "text": "of came back to us and said don't do it this way do it another way can you implement a vectorized intrinsic um",
    "start": "2262960",
    "end": "2269280"
  },
  {
    "text": "here's an idea Uh so what is vectorization um so what we're trying to do is uh it's synonymous",
    "start": "2269280",
    "end": "2275760"
  },
  {
    "text": "with SIMD which is single instruction multiple data and so we're trying to um",
    "start": "2275760",
    "end": "2281760"
  },
  {
    "text": "process more data per instruction so this can be really useful um for increasing the throughput and reducing",
    "start": "2281760",
    "end": "2288320"
  },
  {
    "text": "the number of instructions that we need to apply per bite uh by operating in chunks um so we're basically applying",
    "start": "2288320",
    "end": "2296480"
  },
  {
    "text": "the same operation to a vector of values simultaneously in one go and so it's a bit like instruction level parallelism",
    "start": "2296480",
    "end": "2302720"
  },
  {
    "text": "but it's kind of there are explicit execution units um special instructions",
    "start": "2302720",
    "end": "2308359"
  },
  {
    "text": "uh and pipelining applies to vectorization too um so schematically",
    "start": "2308359",
    "end": "2314320"
  },
  {
    "text": "what we're doing is we're basically we no longer we would no longer have this reduction bottleneck um we could we",
    "start": "2314320",
    "end": "2320000"
  },
  {
    "text": "could keep um all of the data in separate lanes and then reduce horizontally at the end",
    "start": "2320000",
    "end": "2326280"
  },
  {
    "text": "um so why can't so there's there's auto vectorization applied by the J compiler",
    "start": "2326280",
    "end": "2331440"
  },
  {
    "text": "in open JDK so why can't it do anything with this um we've already seen the disassembly for the improved version and",
    "start": "2331440",
    "end": "2338079"
  },
  {
    "text": "so we know that the disassembly um we know that the disassembly uh uh",
    "start": "2338079",
    "end": "2343760"
  },
  {
    "text": "doesn't have any vectorized instructions uh because uh we we've seen it um but",
    "start": "2343760",
    "end": "2349119"
  },
  {
    "text": "the problem with the the um the problem with the the the",
    "start": "2349119",
    "end": "2354240"
  },
  {
    "text": "optimized uh solution that we've that we've um we've shown is basically we've unrolled the loop uh JIT compilers um",
    "start": "2354240",
    "end": "2361760"
  },
  {
    "text": "the C2 has to uh the JIT compiler basically competes with the application for um CPU cycles so it's limited in the",
    "start": "2361760",
    "end": "2371040"
  },
  {
    "text": "analysis it can really do so it's not going to look for similarity in blocks of instructions so if we do manual",
    "start": "2371040",
    "end": "2376160"
  },
  {
    "text": "unrolling we're basically switching off vectorization because unrolling is actually the trigger for vectorization",
    "start": "2376160",
    "end": "2381240"
  },
  {
    "text": "analysis so why don't we just try and make it easier by premputing the coefficients and then we'll evaluate the",
    "start": "2381240",
    "end": "2387760"
  },
  {
    "text": "polomial as a as as a as a dot product um which should be pretty simple to optimize unfortunately we don't get any",
    "start": "2387760",
    "end": "2394800"
  },
  {
    "text": "sim we get these register spills where um register spills are where um there's",
    "start": "2394800",
    "end": "2401359"
  },
  {
    "text": "there's too much um register pressure and uh integer values are saved into floatingoint registers and we still have",
    "start": "2401359",
    "end": "2407839"
  },
  {
    "text": "this uh this per iteration reduction anyways so it's not really a very um attractive solution what we could do I wrote a blog",
    "start": "2407839",
    "end": "2415119"
  },
  {
    "text": "post about this in 2018 is premputee enough powers of 31 so that we can just keep on generating the next uh set of",
    "start": "2415119",
    "end": "2421920"
  },
  {
    "text": "powers in a loop and we'll multiply the vector ve of um we'll multiply the vector values by the powers of 31 and",
    "start": "2421920",
    "end": "2429599"
  },
  {
    "text": "compute a dotproduct one vector of a time and then we'll finally we'll reduce the vector at the horizontally at the",
    "start": "2429599",
    "end": "2434640"
  },
  {
    "text": "end so there's a blog post here about how to do that and that code looks like this using the vector API which still",
    "start": "2434640",
    "end": "2440480"
  },
  {
    "text": "still hasn't been released and this this code won't compile anymore but um this had very very um this had very",
    "start": "2440480",
    "end": "2448400"
  },
  {
    "text": "attractive uh performance back in 2018 using a prototype with the vector API",
    "start": "2448400",
    "end": "2454160"
  },
  {
    "text": "and so here's a diagram of how how this algorithm is actually working uh so we're going to load the data backwards",
    "start": "2454160",
    "end": "2460079"
  },
  {
    "text": "we're going to load that into a small register then we're going to have to sign extend so we're going to put a load",
    "start": "2460079",
    "end": "2465119"
  },
  {
    "text": "of zeros next to next to the data um then we'll multiply that data as an",
    "start": "2465119",
    "end": "2470400"
  },
  {
    "text": "integer with the powers of 31 we're going to add that to the accumulator and then we're going to",
    "start": "2470400",
    "end": "2476160"
  },
  {
    "text": "update the coefficient so we have the next powers of 31 and then finally we're going to go and uh because we're going",
    "start": "2476160",
    "end": "2483200"
  },
  {
    "text": "backwards we're going to go and load the next vector and we'll keep on going backwards until we've got nothing more and finally uh in the in the end we'll",
    "start": "2483200",
    "end": "2491440"
  },
  {
    "text": "reduce the accumulator horizontally so this works pretty well because we're processing so much data",
    "start": "2491440",
    "end": "2497040"
  },
  {
    "text": "per per instruction we're uh processing um",
    "start": "2497040",
    "end": "2502280"
  },
  {
    "text": "um it takes 20 adding up the latencies of these instructions uh we have 24",
    "start": "2502280",
    "end": "2507960"
  },
  {
    "text": "cycles but we're doing eight values per per chain so we've basically got three",
    "start": "2507960",
    "end": "2514000"
  },
  {
    "text": "instructions uh so we got three cycles per bite um which isn't that much better",
    "start": "2514000",
    "end": "2519359"
  },
  {
    "text": "than we had before so we should probably find out why um if we have wider vectors so we have AVX 512 and so we can process",
    "start": "2519359",
    "end": "2526640"
  },
  {
    "text": "16 then we're down to 1.5 um cycles per bite which is quite a big improvement um",
    "start": "2526640",
    "end": "2533119"
  },
  {
    "text": "but what's going on here is that we we have um so vector multiplications are quite slow they have a latency of 10 so um the",
    "start": "2533119",
    "end": "2542640"
  },
  {
    "text": "the nice thing is in AVX2 um we uh the the multiplication has a throughput of",
    "start": "2542640",
    "end": "2548720"
  },
  {
    "text": "one so we only need to wait uh one cycle until we can have another one so if we",
    "start": "2548720",
    "end": "2553920"
  },
  {
    "text": "just wait uh 27 cycles by doing four of these uh I'm rolling this four ways um",
    "start": "2553920",
    "end": "2560960"
  },
  {
    "text": "in 27 cycles we can process um four times more data so three cycles actually",
    "start": "2560960",
    "end": "2566480"
  },
  {
    "text": "we get four times more data processed and say finally we get under one cycle per bite with",
    "start": "2566480",
    "end": "2573160"
  },
  {
    "text": "um with this unrolled approach so this introduc so L Ludvic Henry um",
    "start": "2573160",
    "end": "2582160"
  },
  {
    "text": "who used to work at data dog uh went off and implemented this and then he left data dog um before",
    "start": "2582160",
    "end": "2589599"
  },
  {
    "text": "it could get finished but we were really lucky because um um Oracle and Intel saw",
    "start": "2589599",
    "end": "2595680"
  },
  {
    "text": "a lot of value in this approach because it massively improved the performance of such a common JDK method that they they",
    "start": "2595680",
    "end": "2602160"
  },
  {
    "text": "came in they helped and they productionized it and it went into JDK21 and so it's it's if you're running JDK",
    "start": "2602160",
    "end": "2609200"
  },
  {
    "text": "21 now on x64 then you're you're benefiting from this from this optimization and here here's the we can",
    "start": "2609200",
    "end": "2615599"
  },
  {
    "text": "we can see here's a kernel of the loop now we can see that um we have a we have a vectorzed loop and the instruction",
    "start": "2615599",
    "end": "2622720"
  },
  {
    "text": "simulation is um we can see it's much more vertical so that's a nice",
    "start": "2622720",
    "end": "2627920"
  },
  {
    "text": "comparison with with what we started off with we have much more parallelism is is",
    "start": "2627920",
    "end": "2633200"
  },
  {
    "text": "uh the interpretation of these two charts and we can see that we have um",
    "start": "2633200",
    "end": "2638400"
  },
  {
    "text": "you know crazy unroll was somewhere in the middle um but with you know JDK21",
    "start": "2638400",
    "end": "2643520"
  },
  {
    "text": "for a range of lengths of of string um computing hash codes is much",
    "start": "2643520",
    "end": "2649720"
  },
  {
    "text": "faster so what kind of impact does this actually have well it's a shame that it's had limited impact at data dog um",
    "start": "2649720",
    "end": "2656319"
  },
  {
    "text": "because um this hasn't been implemented for ARM and uh it took about 18 months",
    "start": "2656319",
    "end": "2662160"
  },
  {
    "text": "for this change to get into open JDK uh and in the meantime we actually moved u",
    "start": "2662160",
    "end": "2667839"
  },
  {
    "text": "most of our um uh backend processing to to ARM uh so we need a new intrinsic now",
    "start": "2667839",
    "end": "2674079"
  },
  {
    "text": "so it's going to be a little while more to to to to finally profit from this although we have profited a lot from",
    "start": "2674079",
    "end": "2679920"
  },
  {
    "text": "that very simple migration of of um to a different micro architecture um but potentially it's got a huge impact",
    "start": "2679920",
    "end": "2685920"
  },
  {
    "text": "outside of data dog if you're running um Java on x64 uh you're running Java 21",
    "start": "2685920",
    "end": "2691040"
  },
  {
    "text": "that is um so that's the state of things now so",
    "start": "2691040",
    "end": "2696880"
  },
  {
    "text": "I think the key takeaways the key takeaways are you know early on in performance",
    "start": "2696880",
    "end": "2702800"
  },
  {
    "text": "work we have uh these simplifying optimizations which",
    "start": "2702800",
    "end": "2707880"
  },
  {
    "text": "um which you know they're they're objective improvements they",
    "start": "2707880",
    "end": "2713440"
  },
  {
    "text": "uh it's hard to argue with them because you're probably like improving your code quality at the same time and 10x really",
    "start": "2713440",
    "end": "2719280"
  },
  {
    "text": "sounds amazing but it's probably uh it probably means that um the system hasn't",
    "start": "2719280",
    "end": "2724880"
  },
  {
    "text": "been optimized before and you were just the first one to get there and you know don't be too disappointed with 10% later",
    "start": "2724880",
    "end": "2730160"
  },
  {
    "text": "on um I think that continuous profiling is a great tool for finding low hanging",
    "start": "2730160",
    "end": "2735839"
  },
  {
    "text": "fruit um but um it's not so useful uh for uh",
    "start": "2735839",
    "end": "2743040"
  },
  {
    "text": "fine-tuning uh of the kind of work that data dog did with um with with the string hash code another interesting",
    "start": "2743040",
    "end": "2750880"
  },
  {
    "text": "thing I mean to Thomas is um hosting the tracker thomas said at QCon last year that um uh all software is optimized for",
    "start": "2750880",
    "end": "2759920"
  },
  {
    "text": "um for outof-date hardware and that's an interesting example of this here because",
    "start": "2759920",
    "end": "2765680"
  },
  {
    "text": "string hash code was optimized for the Pentium in 90s the algorithm was was chosen for the Pentium uh to to be more",
    "start": "2765680",
    "end": "2772160"
  },
  {
    "text": "efficient and over time that optimization became less and less relevant and uh specifying that",
    "start": "2772160",
    "end": "2778880"
  },
  {
    "text": "algorithm and relying on it um put open JDK in a difficult place uh because it",
    "start": "2778880",
    "end": "2784640"
  },
  {
    "text": "couldn't be changed when hardware changed uh so that that's the conclusion",
    "start": "2784640",
    "end": "2789839"
  },
  {
    "text": "of the talk um are there any questions",
    "start": "2789839",
    "end": "2794480"
  },
  {
    "text": "thomas",
    "start": "2800000",
    "end": "2803000"
  },
  {
    "text": "I'm not I'm not sure about that",
    "start": "2805040",
    "end": "2809079"
  },
  {
    "text": "uh so actually implementing the solution is quite quick um obviously open JDK has",
    "start": "2817520",
    "end": "2823440"
  },
  {
    "text": "a massive impact so if you break something like the string hash code um it can really affect a lot of a lot of",
    "start": "2823440",
    "end": "2830319"
  },
  {
    "text": "um users uh so open JDK is a very uh cautious project so actually getting it",
    "start": "2830319",
    "end": "2835839"
  },
  {
    "text": "merged and released took more like 18 months um but implementing the solution was was was relatively quick uh we Yep",
    "start": "2835839",
    "end": "2846880"
  },
  {
    "text": "hello i've got a mic um you said earlier that um some of",
    "start": "2846880",
    "end": "2853599"
  },
  {
    "text": "your that profilers will often uh report different things um does this mean that we should be using different profilers",
    "start": "2853599",
    "end": "2860800"
  },
  {
    "text": "in different circumstances or is there a way for us to know when a profiler is best suited for a certain problem",
    "start": "2860800",
    "end": "2868119"
  },
  {
    "text": "um I think I think it's worth having more than one obser you know observability tool uh to to test the",
    "start": "2868119",
    "end": "2875200"
  },
  {
    "text": "observability um but um I think in general for Java anything based on async",
    "start": "2875200",
    "end": "2881599"
  },
  {
    "text": "profiler is is a really accurate profile and it's more that um JFR has",
    "start": "2881599",
    "end": "2889160"
  },
  {
    "text": "um JFR has some gaps we'd like to actually fix those gaps uh to make it better that's something we're working on",
    "start": "2889160",
    "end": "2895119"
  },
  {
    "text": "at Data Dog now um so I wouldn't I wouldn't suggest running two in",
    "start": "2895119",
    "end": "2900640"
  },
  {
    "text": "production i would uh because it's going to increase the",
    "start": "2900640",
    "end": "2906960"
  },
  {
    "text": "overhead and profilers especially if they use signals they don't play too nicely but I think it's I think it's",
    "start": "2906960",
    "end": "2912400"
  },
  {
    "text": "definitely worth not trusting your tools and testing them against each",
    "start": "2912400",
    "end": "2916960"
  },
  {
    "text": "a little bit risk averse um to add a little bit more to it you mentioned it's below 1% are there cases where this",
    "start": "2934400",
    "end": "2940160"
  },
  {
    "text": "isn't the case or stuff you need to watch out for yeah so um anything that applies tracing",
    "start": "2940160",
    "end": "2947280"
  },
  {
    "text": "um is difficult to to reason about because when you apply tracing you don't know all of the programs that the",
    "start": "2947280",
    "end": "2952720"
  },
  {
    "text": "instrumentation will be applied to so the overhead can it depends on what's",
    "start": "2952720",
    "end": "2957760"
  },
  {
    "text": "being traced the overhead depends on what's being traced but with C CPU sampling I mean it's by construction uh",
    "start": "2957760",
    "end": "2963680"
  },
  {
    "text": "if you set the sampling frequency low enough um you can't have more than a a",
    "start": "2963680",
    "end": "2969599"
  },
  {
    "text": "certain level of overhead um allocation profiling on the other hand that can be quite high overhead it's more like uh it",
    "start": "2969599",
    "end": "2975520"
  },
  {
    "text": "can be more like 5% uh depending on the workload so be careful with allocation profiling if you want to enable that in",
    "start": "2975520",
    "end": "2982240"
  },
  {
    "text": "production often it's lower than that but um it it can be higher depending on the",
    "start": "2982240",
    "end": "2988799"
  },
  {
    "text": "workload thank you [Applause]",
    "start": "2990520",
    "end": "2997119"
  },
  {
    "text": "[Music]",
    "start": "2997570",
    "end": "3003020"
  }
]
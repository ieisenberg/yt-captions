[
  {
    "text": "hello everyone so yeah as Roland said I",
    "start": "3899",
    "end": "7500"
  },
  {
    "text": "will give an introduction to Piper",
    "start": "7500",
    "end": "9450"
  },
  {
    "text": "today probably the thing you all want to",
    "start": "9450",
    "end": "12690"
  },
  {
    "text": "know is what is pi toys but let me ask",
    "start": "12690",
    "end": "16230"
  },
  {
    "text": "you a question first like whom is using",
    "start": "16230",
    "end": "18300"
  },
  {
    "text": "Python in this room justly and to use",
    "start": "18300",
    "end": "21689"
  },
  {
    "text": "numpy and who would like to numpy to run",
    "start": "21689",
    "end": "26340"
  },
  {
    "text": "30 times faster ok then pi touch is",
    "start": "26340",
    "end": "30419"
  },
  {
    "text": "something for you because pi torch is",
    "start": "30419",
    "end": "33719"
  },
  {
    "text": "basically an ndre library with GPU",
    "start": "33719",
    "end": "36120"
  },
  {
    "text": "support and if you run stuff on the GPU",
    "start": "36120",
    "end": "38519"
  },
  {
    "text": "it goes faster if you can paralyze it",
    "start": "38519",
    "end": "40679"
  },
  {
    "text": "which is most of the time the case with",
    "start": "40679",
    "end": "42780"
  },
  {
    "text": "arrays but instead of going through like",
    "start": "42780",
    "end": "45899"
  },
  {
    "text": "what pi/2 it can actually do and how",
    "start": "45899",
    "end": "48030"
  },
  {
    "text": "awesome it is let me just show you code",
    "start": "48030",
    "end": "50820"
  },
  {
    "text": "that's always better so similar to numpy",
    "start": "50820",
    "end": "55199"
  },
  {
    "text": "you always have to import torch check ok",
    "start": "55199",
    "end": "59190"
  },
  {
    "text": "that was boring nothing happened you can",
    "start": "59190",
    "end": "63960"
  },
  {
    "text": "build tensors with PI torch just by",
    "start": "63960",
    "end": "67200"
  },
  {
    "text": "saying I want to have a tensor it size 5",
    "start": "67200",
    "end": "70830"
  },
  {
    "text": "pi/3 can you read it in the back row",
    "start": "70830",
    "end": "72780"
  },
  {
    "text": "otherwise I will make okay awesome",
    "start": "72780",
    "end": "75300"
  },
  {
    "text": "the really cool thing about PI torch is",
    "start": "75300",
    "end": "77460"
  },
  {
    "text": "that you can actually print the tensor",
    "start": "77460",
    "end": "79350"
  },
  {
    "text": "and you get values on the console",
    "start": "79350",
    "end": "82260"
  },
  {
    "text": "because if you use tensorflow",
    "start": "82260",
    "end": "83940"
  },
  {
    "text": "or Karis it will tell you like oh yeah",
    "start": "83940",
    "end": "86160"
  },
  {
    "text": "this is a tensor somewhere in the graph",
    "start": "86160",
    "end": "89090"
  },
  {
    "text": "but you never really see the values",
    "start": "89090",
    "end": "91830"
  },
  {
    "text": "which are in this tensor which is super",
    "start": "91830",
    "end": "94170"
  },
  {
    "text": "annoying for debugging because that's",
    "start": "94170",
    "end": "95670"
  },
  {
    "text": "like the most awesome debugging tool to",
    "start": "95670",
    "end": "97350"
  },
  {
    "text": "print you can see there are like really",
    "start": "97350",
    "end": "102030"
  },
  {
    "text": "weird values in there everything from 10",
    "start": "102030",
    "end": "104490"
  },
  {
    "text": "to the power of minus 41 to 10 to the",
    "start": "104490",
    "end": "107040"
  },
  {
    "text": "power of 21 or even higher this is",
    "start": "107040",
    "end": "111510"
  },
  {
    "text": "simply because if you just say I want to",
    "start": "111510",
    "end": "113010"
  },
  {
    "text": "have a tensor it just tells you ok",
    "start": "113010",
    "end": "114900"
  },
  {
    "text": "here's your data and it's just whatever",
    "start": "114900",
    "end": "117270"
  },
  {
    "text": "was in the memory before so normally you",
    "start": "117270",
    "end": "121110"
  },
  {
    "text": "want to go with something like this you",
    "start": "121110",
    "end": "122640"
  },
  {
    "text": "for example want to randomly initialize",
    "start": "122640",
    "end": "125250"
  },
  {
    "text": "the array which gives you an error which",
    "start": "125250",
    "end": "127830"
  },
  {
    "text": "is basically containing values between 0",
    "start": "127830",
    "end": "130170"
  },
  {
    "text": "and 1 randomly you can as well always",
    "start": "130170",
    "end": "134010"
  },
  {
    "text": "ask pie-chart ok what is the size of the",
    "start": "134010",
    "end": "136109"
  },
  {
    "text": "tensor it will tell you 5 by 3",
    "start": "136109",
    "end": "137790"
  },
  {
    "text": "you can again print the values but of",
    "start": "137790",
    "end": "141239"
  },
  {
    "text": "course you normally especially in deep",
    "start": "141239",
    "end": "143099"
  },
  {
    "text": "learning you don't really want to see",
    "start": "143099",
    "end": "144750"
  },
  {
    "text": "the whole tensor because it's simply",
    "start": "144750",
    "end": "147090"
  },
  {
    "text": "huge the cool thing of Pi torch is you",
    "start": "147090",
    "end": "150599"
  },
  {
    "text": "can as well slice like you used to do in",
    "start": "150599",
    "end": "152879"
  },
  {
    "text": "numpy so you can just say okay I want to",
    "start": "152879",
    "end": "154739"
  },
  {
    "text": "have basically in this case the first",
    "start": "154739",
    "end": "157829"
  },
  {
    "text": "column and the second column and it",
    "start": "157829",
    "end": "159959"
  },
  {
    "text": "gives you the second column so since",
    "start": "159959",
    "end": "162989"
  },
  {
    "text": "it's so similar to numpy there's of",
    "start": "162989",
    "end": "165629"
  },
  {
    "text": "course a bridge to numpy because that's",
    "start": "165629",
    "end": "167639"
  },
  {
    "text": "what everyone uses in python nowadays",
    "start": "167639",
    "end": "170280"
  },
  {
    "text": "when they have areas like the first",
    "start": "170280",
    "end": "171780"
  },
  {
    "text": "thing they do is okay I read it into",
    "start": "171780",
    "end": "173639"
  },
  {
    "text": "numpy area and then I figure out what I",
    "start": "173639",
    "end": "175319"
  },
  {
    "text": "do the really cool thing is so we built",
    "start": "175319",
    "end": "180000"
  },
  {
    "text": "this tensor X and want to have the numpy",
    "start": "180000",
    "end": "182250"
  },
  {
    "text": "version we just say okay dot mam PI and",
    "start": "182250",
    "end": "184829"
  },
  {
    "text": "we print it and it prints an umpire E",
    "start": "184829",
    "end": "187200"
  },
  {
    "text": "but the really cool thing is it does",
    "start": "187200",
    "end": "189870"
  },
  {
    "text": "that without any overhead so none PI and",
    "start": "189870",
    "end": "193980"
  },
  {
    "text": "PI torch are pointing to the exact same",
    "start": "193980",
    "end": "196500"
  },
  {
    "text": "data so it's basically just telling like",
    "start": "196500",
    "end": "198629"
  },
  {
    "text": "okay one outputs you the PI torch",
    "start": "198629",
    "end": "201209"
  },
  {
    "text": "version of it the other than PI but if I",
    "start": "201209",
    "end": "203849"
  },
  {
    "text": "for example now at one to the PI touch",
    "start": "203849",
    "end": "206760"
  },
  {
    "text": "tensor it adds it as well to the",
    "start": "206760",
    "end": "209069"
  },
  {
    "text": "number-10 so simply we have because we",
    "start": "209069",
    "end": "211019"
  },
  {
    "text": "have the same reference and that simply",
    "start": "211019",
    "end": "213030"
  },
  {
    "text": "makes the conversion between an PI and",
    "start": "213030",
    "end": "214919"
  },
  {
    "text": "PI George super fast because basically",
    "start": "214919",
    "end": "217560"
  },
  {
    "text": "just tells you like okay now interpreted",
    "start": "217560",
    "end": "219150"
  },
  {
    "text": "as pipe towards data and don't copy it",
    "start": "219150",
    "end": "221220"
  },
  {
    "text": "at all the same thing holds for the",
    "start": "221220",
    "end": "226049"
  },
  {
    "text": "other way so if you have numpy data like",
    "start": "226049",
    "end": "229139"
  },
  {
    "text": "in this case an area of once you can",
    "start": "229139",
    "end": "231209"
  },
  {
    "text": "just call torture from numpy and it",
    "start": "231209",
    "end": "233909"
  },
  {
    "text": "makes a torch tensor out of it and again",
    "start": "233909",
    "end": "236819"
  },
  {
    "text": "if you add something to the numpy data",
    "start": "236819",
    "end": "238889"
  },
  {
    "text": "it will be added to the PI torch data so",
    "start": "238889",
    "end": "241799"
  },
  {
    "text": "that's really nice to replace numpy but",
    "start": "241799",
    "end": "245549"
  },
  {
    "text": "that's not why most of you are here on",
    "start": "245549",
    "end": "247979"
  },
  {
    "text": "the conference so numpy offers other PI",
    "start": "247979",
    "end": "252209"
  },
  {
    "text": "torch office other things as well it has",
    "start": "252209",
    "end": "257070"
  },
  {
    "text": "an automatic differentiation engine",
    "start": "257070",
    "end": "259530"
  },
  {
    "text": "meaning that it can every variable knows",
    "start": "259530",
    "end": "262800"
  },
  {
    "text": "how it was calculated and can calculate",
    "start": "262800",
    "end": "265620"
  },
  {
    "text": "the gradients with respect to every",
    "start": "265620",
    "end": "267360"
  },
  {
    "text": "variable in the system which simply",
    "start": "267360",
    "end": "269099"
  },
  {
    "text": "allows you to do",
    "start": "269099",
    "end": "270210"
  },
  {
    "text": "keep learning on this with this",
    "start": "270210",
    "end": "272370"
  },
  {
    "text": "framework or reinforcement learning on",
    "start": "272370",
    "end": "277169"
  },
  {
    "text": "top of that you have some gradient based",
    "start": "277169",
    "end": "278940"
  },
  {
    "text": "optimization packages like simply",
    "start": "278940",
    "end": "282120"
  },
  {
    "text": "gradient descent optimizer or atom",
    "start": "282120",
    "end": "284550"
  },
  {
    "text": "optimizer or you name it okay you not",
    "start": "284550",
    "end": "287910"
  },
  {
    "text": "name it because it's one year old so",
    "start": "287910",
    "end": "289560"
  },
  {
    "text": "they are still implementing some of them",
    "start": "289560",
    "end": "291120"
  },
  {
    "text": "but they already have sick or the 6m7",
    "start": "291120",
    "end": "294840"
  },
  {
    "text": "most common ones implemented and you",
    "start": "294840",
    "end": "298050"
  },
  {
    "text": "have utility so there are futilities to",
    "start": "298050",
    "end": "300449"
  },
  {
    "text": "load data they provide by default some",
    "start": "300449",
    "end": "304020"
  },
  {
    "text": "standard data sets with their API so of",
    "start": "304020",
    "end": "307500"
  },
  {
    "text": "course m-miss but as well see fartin and",
    "start": "307500",
    "end": "310889"
  },
  {
    "text": "some other ones so the way this is",
    "start": "310889",
    "end": "313919"
  },
  {
    "text": "working and now it's getting a bit",
    "start": "313919",
    "end": "316020"
  },
  {
    "text": "uglier is basically from the autograph",
    "start": "316020",
    "end": "321509"
  },
  {
    "text": "package from Nampa from torch you import",
    "start": "321509",
    "end": "324030"
  },
  {
    "text": "a variable the variable is wrapping the",
    "start": "324030",
    "end": "326310"
  },
  {
    "text": "tensor so it can remember how it was",
    "start": "326310",
    "end": "328650"
  },
  {
    "text": "calculated and how the gradients flow",
    "start": "328650",
    "end": "331050"
  },
  {
    "text": "through the system the functional you'll",
    "start": "331050",
    "end": "334800"
  },
  {
    "text": "see later is just a convenient library",
    "start": "334800",
    "end": "337320"
  },
  {
    "text": "where you can find function notes so",
    "start": "337320",
    "end": "339509"
  },
  {
    "text": "that you just have to import and then",
    "start": "339509",
    "end": "343620"
  },
  {
    "text": "for example let's build the four",
    "start": "343620",
    "end": "346949"
  },
  {
    "text": "different variables like in this case X",
    "start": "346949",
    "end": "349320"
  },
  {
    "text": "previous age two weights and then we",
    "start": "349320",
    "end": "353969"
  },
  {
    "text": "calculate I to H and H to H we sum them",
    "start": "353969",
    "end": "359699"
  },
  {
    "text": "up and we put an activation function on",
    "start": "359699",
    "end": "363000"
  },
  {
    "text": "it so basically building a really simple",
    "start": "363000",
    "end": "365310"
  },
  {
    "text": "neuron so in this case it calculates now",
    "start": "365310",
    "end": "370560"
  },
  {
    "text": "next H so you can actually already see",
    "start": "370560",
    "end": "373199"
  },
  {
    "text": "what is in next H if you have given an x",
    "start": "373199",
    "end": "375810"
  },
  {
    "text": "and y which is different competitor",
    "start": "375810",
    "end": "378060"
  },
  {
    "text": "tensorflow because there you build a",
    "start": "378060",
    "end": "379650"
  },
  {
    "text": "graph then you put data in and when you",
    "start": "379650",
    "end": "381990"
  },
  {
    "text": "run it you actually get the result with",
    "start": "381990",
    "end": "383669"
  },
  {
    "text": "patriots you get the result immediately",
    "start": "383669",
    "end": "386030"
  },
  {
    "text": "but now if you want to have the",
    "start": "386030",
    "end": "388860"
  },
  {
    "text": "gradients with respect to a variable you",
    "start": "388860",
    "end": "391110"
  },
  {
    "text": "just called dot backward with a given",
    "start": "391110",
    "end": "396449"
  },
  {
    "text": "variable so in this case I just put once",
    "start": "396449",
    "end": "398370"
  },
  {
    "text": "in there to show how it works and then",
    "start": "398370",
    "end": "401430"
  },
  {
    "text": "I'll just add a cell you can",
    "start": "401430",
    "end": "404440"
  },
  {
    "text": "just for every variable print the",
    "start": "404440",
    "end": "412330"
  },
  {
    "text": "gradients given this output for this",
    "start": "412330",
    "end": "415180"
  },
  {
    "text": "input so if you have as well as some",
    "start": "415180",
    "end": "418630"
  },
  {
    "text": "problem where you have an input and you",
    "start": "418630",
    "end": "420850"
  },
  {
    "text": "know the output and you want to",
    "start": "420850",
    "end": "422860"
  },
  {
    "text": "calculate the error gradients you can",
    "start": "422860",
    "end": "424780"
  },
  {
    "text": "just print them easily to the console",
    "start": "424780",
    "end": "426580"
  },
  {
    "text": "compared to tensor flow where you would",
    "start": "426580",
    "end": "428260"
  },
  {
    "text": "again need to build an output node to",
    "start": "428260",
    "end": "431350"
  },
  {
    "text": "then catch the data to then export them",
    "start": "431350",
    "end": "433780"
  },
  {
    "text": "to the CPU to them and print them which",
    "start": "433780",
    "end": "435880"
  },
  {
    "text": "is a bit cumbersome if you have to debug",
    "start": "435880",
    "end": "438040"
  },
  {
    "text": "it so let's see how this actually works",
    "start": "438040",
    "end": "443440"
  },
  {
    "text": "on your network so with torch you can",
    "start": "443440",
    "end": "446410"
  },
  {
    "text": "install torch vision which is simply",
    "start": "446410",
    "end": "448420"
  },
  {
    "text": "this utility package in this case we",
    "start": "448420",
    "end": "451390"
  },
  {
    "text": "will um use m-miss because everyone uses",
    "start": "451390",
    "end": "453700"
  },
  {
    "text": "em mist because it's good to show some",
    "start": "453700",
    "end": "456580"
  },
  {
    "text": "cases so I hope it's still downloaded so",
    "start": "456580",
    "end": "463990"
  },
  {
    "text": "what it does is it's downloading the",
    "start": "463990",
    "end": "466750"
  },
  {
    "text": "data in the background and just provides",
    "start": "466750",
    "end": "468940"
  },
  {
    "text": "you with the training the test set and",
    "start": "468940",
    "end": "470790"
  },
  {
    "text": "related loaders to actually train your",
    "start": "470790",
    "end": "473530"
  },
  {
    "text": "newer network so for example in this",
    "start": "473530",
    "end": "477850"
  },
  {
    "text": "case it just go and have a look at the",
    "start": "477850",
    "end": "480630"
  },
  {
    "text": "training data and at the training label",
    "start": "480630",
    "end": "483820"
  },
  {
    "text": "so you can see it's a 5 and it kind of",
    "start": "483820",
    "end": "486940"
  },
  {
    "text": "looks like a 5 as well sorry for the",
    "start": "486940",
    "end": "489160"
  },
  {
    "text": "heat plot I just do heat plots all the",
    "start": "489160",
    "end": "491290"
  },
  {
    "text": "time",
    "start": "491290",
    "end": "491680"
  },
  {
    "text": "they look fancier than greyscale so we",
    "start": "491680",
    "end": "497560"
  },
  {
    "text": "of course now want to build a neural",
    "start": "497560",
    "end": "499150"
  },
  {
    "text": "network which can actually figure out",
    "start": "499150",
    "end": "500860"
  },
  {
    "text": "how a mist works the way this is done in",
    "start": "500860",
    "end": "503890"
  },
  {
    "text": "pi torch is that every newer network",
    "start": "503890",
    "end": "506620"
  },
  {
    "text": "inherits the n + dot module class which",
    "start": "506620",
    "end": "511360"
  },
  {
    "text": "simply does most of the parameter",
    "start": "511360",
    "end": "514180"
  },
  {
    "text": "handling in the background and you have",
    "start": "514180",
    "end": "516039"
  },
  {
    "text": "it all and capsulated like you're used",
    "start": "516039",
    "end": "518110"
  },
  {
    "text": "to an object-oriented programming it's",
    "start": "518110",
    "end": "520180"
  },
  {
    "text": "like everything you need for the newer",
    "start": "520180",
    "end": "521950"
  },
  {
    "text": "network is part of this newer network",
    "start": "521950",
    "end": "524560"
  },
  {
    "text": "class which is quite handy",
    "start": "524560",
    "end": "527500"
  },
  {
    "text": "compared to tensorflow or Kerris where",
    "start": "527500",
    "end": "529870"
  },
  {
    "text": "you have to figure or you have to find",
    "start": "529870",
    "end": "532420"
  },
  {
    "text": "the parameters if you actually want to",
    "start": "532420",
    "end": "533890"
  },
  {
    "text": "change them you have to find the",
    "start": "533890",
    "end": "535420"
  },
  {
    "text": "variables in the GPU memory",
    "start": "535420",
    "end": "537230"
  },
  {
    "text": "until you just go through the parameters",
    "start": "537230",
    "end": "540070"
  },
  {
    "text": "of this object and you have basically",
    "start": "540070",
    "end": "542750"
  },
  {
    "text": "everything which is related to the",
    "start": "542750",
    "end": "544460"
  },
  {
    "text": "neural network in there so in this case",
    "start": "544460",
    "end": "547820"
  },
  {
    "text": "I just use a really simple model module",
    "start": "547820",
    "end": "550490"
  },
  {
    "text": "model neural network with two",
    "start": "550490",
    "end": "554000"
  },
  {
    "text": "convolutions and three linear layers and",
    "start": "554000",
    "end": "556550"
  },
  {
    "text": "a bit of dropout in between",
    "start": "556550",
    "end": "559190"
  },
  {
    "text": "I choose a criterion for optimization in",
    "start": "559190",
    "end": "563330"
  },
  {
    "text": "this case with classification simply",
    "start": "563330",
    "end": "566330"
  },
  {
    "text": "cross-entropy",
    "start": "566330",
    "end": "567460"
  },
  {
    "text": "and an optimizer so I just choose the",
    "start": "567460",
    "end": "570710"
  },
  {
    "text": "item optimizer because I like it the",
    "start": "570710",
    "end": "572240"
  },
  {
    "text": "most it's like it's a bit of dark magic",
    "start": "572240",
    "end": "574130"
  },
  {
    "text": "and everyone likes to take his own",
    "start": "574130",
    "end": "576320"
  },
  {
    "text": "optimizer you will get a preference",
    "start": "576320",
    "end": "579670"
  },
  {
    "text": "throughout you're working with deep",
    "start": "579670",
    "end": "582140"
  },
  {
    "text": "learning and I have to hurry you then do",
    "start": "582140",
    "end": "587450"
  },
  {
    "text": "a forward pass which is basically then",
    "start": "587450",
    "end": "590210"
  },
  {
    "text": "replacing calling the object so every",
    "start": "590210",
    "end": "592850"
  },
  {
    "text": "time you call net and put an input there",
    "start": "592850",
    "end": "595700"
  },
  {
    "text": "it will call the forward function and to",
    "start": "595700",
    "end": "599690"
  },
  {
    "text": "train the neural network you zero the",
    "start": "599690",
    "end": "601760"
  },
  {
    "text": "optimizer that you just have to do",
    "start": "601760",
    "end": "603500"
  },
  {
    "text": "because the buffers gradients you",
    "start": "603500",
    "end": "605080"
  },
  {
    "text": "calculate the output you calculate the",
    "start": "605080",
    "end": "607820"
  },
  {
    "text": "loss you do backward propagation with",
    "start": "607820",
    "end": "610010"
  },
  {
    "text": "the loss and then you step the optimizer",
    "start": "610010",
    "end": "612490"
  },
  {
    "text": "and that's how you call it it's",
    "start": "612490",
    "end": "615530"
  },
  {
    "text": "basically you build the model you built",
    "start": "615530",
    "end": "618620"
  },
  {
    "text": "an input variable in this case I just",
    "start": "618620",
    "end": "620330"
  },
  {
    "text": "start with random stuff and this is how",
    "start": "620330",
    "end": "622610"
  },
  {
    "text": "you calculate the output you just call",
    "start": "622610",
    "end": "624800"
  },
  {
    "text": "the object cool thing is if you want to",
    "start": "624800",
    "end": "629180"
  },
  {
    "text": "do it on your GPU you just call once dot",
    "start": "629180",
    "end": "632120"
  },
  {
    "text": "CUDA it puts all the data into the GPU",
    "start": "632120",
    "end": "635380"
  },
  {
    "text": "does the calculation and if you then",
    "start": "635380",
    "end": "638360"
  },
  {
    "text": "need to get the data back you call dot",
    "start": "638360",
    "end": "640670"
  },
  {
    "text": "CPU it puts it back into the CPU and you",
    "start": "640670",
    "end": "643790"
  },
  {
    "text": "can just print it to the console and",
    "start": "643790",
    "end": "646150"
  },
  {
    "text": "it's all really nicely embedded into",
    "start": "646150",
    "end": "649550"
  },
  {
    "text": "Python so I could like go way more into",
    "start": "649550",
    "end": "655190"
  },
  {
    "text": "this but I was told I have to stop",
    "start": "655190",
    "end": "657140"
  },
  {
    "text": "[Laughter]",
    "start": "657140",
    "end": "659350"
  },
  {
    "text": "strictly doing ten minutes with Python",
    "start": "659350",
    "end": "662170"
  },
  {
    "text": "but I hope you all took something from",
    "start": "662170",
    "end": "665180"
  },
  {
    "text": "it and you at least saw how it",
    "start": "665180",
    "end": "666710"
  },
  {
    "text": "integrates",
    "start": "666710",
    "end": "669040"
  },
  {
    "text": "[Applause]",
    "start": "669440",
    "end": "673679"
  }
]
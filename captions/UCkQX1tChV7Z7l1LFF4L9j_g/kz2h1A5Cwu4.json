[
  {
    "start": "0",
    "end": "161000"
  },
  {
    "text": "foreign [Music]",
    "start": "0",
    "end": "14249"
  },
  {
    "text": "hi my name's Liz rice I'm the chief open source officer at isovalent I'm also an",
    "start": "15299",
    "end": "22740"
  },
  {
    "text": "ambassador and board member for open UK and until recently I was chair of the",
    "start": "22740",
    "end": "28920"
  },
  {
    "text": "technical oversight committee at the cloud native Computing Foundation",
    "start": "28920",
    "end": "34079"
  },
  {
    "text": "I joined i7 just over a year ago because that team has so much expertise in ebpf",
    "start": "34079",
    "end": "42600"
  },
  {
    "text": "which is the technology that I'm talking about today I've been excited about ebtf for a few",
    "start": "42600",
    "end": "48719"
  },
  {
    "text": "years now from my cncf work I've seen some of the really incredible range of",
    "start": "48719",
    "end": "55079"
  },
  {
    "text": "things that ebpf can enable and today I want to share some of the reasons why I'm so excited about it and",
    "start": "55079",
    "end": "62820"
  },
  {
    "text": "specifically talk about the ways that evpf can help us build more resilient",
    "start": "62820",
    "end": "68159"
  },
  {
    "text": "deployments but before we get to that let's talk about what evpf is",
    "start": "68159",
    "end": "74520"
  },
  {
    "text": "the acronym stands for extended Berkeley packet filter",
    "start": "74520",
    "end": "79680"
  },
  {
    "text": "I don't think that's terribly helpful what you really need to know is that ebpf allows you to run custom code in",
    "start": "79680",
    "end": "88200"
  },
  {
    "text": "the kernel it makes the kernel programmable let's just pause for a moment and make",
    "start": "88200",
    "end": "93900"
  },
  {
    "text": "sure we're all on the same page about what the kernel is so kernel is a core",
    "start": "93900",
    "end": "99240"
  },
  {
    "text": "part of your operating system which is divided into user space and the kernel",
    "start": "99240",
    "end": "105900"
  },
  {
    "text": "we typically write applications that run in user space but whenever those applications want to",
    "start": "105900",
    "end": "113340"
  },
  {
    "text": "interface with Hardware in any way whether they want to read or write to a",
    "start": "113340",
    "end": "118740"
  },
  {
    "text": "file um send or receive Network packets accessing memory all these things",
    "start": "118740",
    "end": "125640"
  },
  {
    "text": "require privileged access that only the kernel has so user space",
    "start": "125640",
    "end": "132900"
  },
  {
    "text": "applications have to make requests of the kernel whenever they want to do any",
    "start": "132900",
    "end": "137940"
  },
  {
    "text": "of those things the candle's also looking after things like scheduling those different",
    "start": "137940",
    "end": "143640"
  },
  {
    "text": "applications making sure that uh multiple processes can run at once",
    "start": "143640",
    "end": "149660"
  },
  {
    "text": "so normally normally we're writing applications that run in user space",
    "start": "150120",
    "end": "155520"
  },
  {
    "text": "ebpf is allowing us to write kernels that run within the kernel",
    "start": "155520",
    "end": "161220"
  },
  {
    "start": "161000",
    "end": "161000"
  },
  {
    "text": "and we load the eppf program into the kernel and we attach it to an event",
    "start": "161220",
    "end": "169200"
  },
  {
    "text": "so whenever that event happens it's going to trigger the ebpf program to run",
    "start": "169200",
    "end": "175440"
  },
  {
    "text": "events can be all sorts of different things it could be the arrival of a network packet it could be a function",
    "start": "175440",
    "end": "183540"
  },
  {
    "text": "call being made in the kernel or in user space it could be a trace point it could",
    "start": "183540",
    "end": "189900"
  },
  {
    "text": "be um a perf event there are lots of different places where we can attach",
    "start": "189900",
    "end": "195379"
  },
  {
    "text": "ebpf programs so to make this a bit more concrete I'm",
    "start": "195379",
    "end": "201420"
  },
  {
    "text": "going to show an example here so this is going to be the hello world of ebpf",
    "start": "201420",
    "end": "208280"
  },
  {
    "text": "and let's just bring the right screen across so here is my",
    "start": "208280",
    "end": "215280"
  },
  {
    "text": "um here's my ebpf program the actual evpf program are these few lines here they've",
    "start": "215280",
    "end": "222000"
  },
  {
    "text": "written in C the rest of my program is uh in Python",
    "start": "222000",
    "end": "228480"
  },
  {
    "text": "so my python code here is going to actually compile my C",
    "start": "228480",
    "end": "235739"
  },
  {
    "text": "program into BPF format so all my ebpf program is going to do is",
    "start": "235739",
    "end": "243840"
  },
  {
    "text": "write out some tracing here it's going to say hello qcon and I'm going to attach that to the",
    "start": "243840",
    "end": "250200"
  },
  {
    "text": "event of uh the exec ve system call being made now exact fee is used to run",
    "start": "250200",
    "end": "259680"
  },
  {
    "text": "a new executable whenever a new executable runs exactly is what causes it to run",
    "start": "259680",
    "end": "265860"
  },
  {
    "text": "so every time a new executable started on my virtual machine that's going to cause",
    "start": "265860",
    "end": "272880"
  },
  {
    "text": "my tracing to be printed out so if I run this program",
    "start": "272880",
    "end": "280740"
  },
  {
    "text": "first of all we should see we're not allowed to load BPF unless we are",
    "start": "280740",
    "end": "286860"
  },
  {
    "text": "um well unless we have a privilege called cat BPF which is typically only it's reserved for route",
    "start": "286860",
    "end": "294360"
  },
  {
    "text": "so we need to see the user privileges to run so let's try that with sudo",
    "start": "294360",
    "end": "301880"
  },
  {
    "text": "and we start seeing a lot of these Trace events being written out",
    "start": "303000",
    "end": "308040"
  },
  {
    "text": "now I'm using a cloud VM I'm using vs",
    "start": "308040",
    "end": "313320"
  },
  {
    "text": "code remote to access it and that it turns out is running quite a lot of",
    "start": "313320",
    "end": "318780"
  },
  {
    "text": "um executables in a different Shell let's run something",
    "start": "318780",
    "end": "323820"
  },
  {
    "text": "let's run PS and we can see the process ID",
    "start": "323820",
    "end": "329900"
  },
  {
    "text": "1063059 and here is the trace line that was triggered by me running that PS",
    "start": "329900",
    "end": "336479"
  },
  {
    "text": "executable foreign output we don't just get the text we're",
    "start": "336479",
    "end": "344699"
  },
  {
    "text": "also getting some contextual information about the event that triggered that",
    "start": "344699",
    "end": "350699"
  },
  {
    "text": "program to run and I think that's an important part of what bbpf is giving us we get this",
    "start": "350699",
    "end": "358100"
  },
  {
    "text": "contextual information that could be used to generate observability data",
    "start": "358100",
    "end": "364500"
  },
  {
    "text": "about the events that we're attached to",
    "start": "364500",
    "end": "368840"
  },
  {
    "text": "when we load an ebps program into the kernel it is crucial that it's safe to",
    "start": "371220",
    "end": "377340"
  },
  {
    "text": "run if it crashes that would bring down the whole machine",
    "start": "377340",
    "end": "382620"
  },
  {
    "text": "and in order to make sure that it is safe there's a process called verification as",
    "start": "382620",
    "end": "389520"
  },
  {
    "text": "we load the program into the kernel the ebpf verifier checks that the program",
    "start": "389520",
    "end": "396479"
  },
  {
    "text": "will run to completion that it um never dereferences a null pointer",
    "start": "396479",
    "end": "401880"
  },
  {
    "text": "that all the memory accessing that it will do is safe and correct",
    "start": "401880",
    "end": "408979"
  },
  {
    "text": "so that ensures that the ebpf programs were running won't bring down our",
    "start": "409080",
    "end": "415620"
  },
  {
    "text": "machine and that they're um that they're accessing memory correctly",
    "start": "415620",
    "end": "420960"
  },
  {
    "text": "and because of this verification process sometimes ebpf is described as being a",
    "start": "420960",
    "end": "426120"
  },
  {
    "text": "Sandbox but I do want to be clear that this is a different kind of sandboxing from containerization for example",
    "start": "426120",
    "end": "435620"
  },
  {
    "text": "it is run custom programs inside the kernel and by doing so we're changing the way that the",
    "start": "439919",
    "end": "446819"
  },
  {
    "text": "kernel behaves now this is a real game changer in the",
    "start": "446819",
    "end": "452099"
  },
  {
    "text": "past if you wanted to change the Linux kernel well it takes a long time it it",
    "start": "452099",
    "end": "458479"
  },
  {
    "text": "requires expertise in kernel programming the kernel if you make a change to the",
    "start": "458479",
    "end": "465120"
  },
  {
    "text": "kernel it then typically takes several years to get from the kernel into the",
    "start": "465120",
    "end": "472259"
  },
  {
    "text": "different Linux distributions that we all use in production",
    "start": "472259",
    "end": "477360"
  },
  {
    "text": "so it can be quite often five years between a new feature in the kernel",
    "start": "477360",
    "end": "482940"
  },
  {
    "text": "arriving in your production deployments now this is why ebtf has suddenly become",
    "start": "482940",
    "end": "490740"
  },
  {
    "text": "such a a kind of prevalent technology as of you know the last year or so",
    "start": "490740",
    "end": "497180"
  },
  {
    "text": "almost all production environments are running Linux kernels that are new",
    "start": "497180",
    "end": "502259"
  },
  {
    "text": "enough to have ebpf capabilities in them",
    "start": "502259",
    "end": "507479"
  },
  {
    "text": "so that means pretty much everyone can now take advantage of ebpf and that's",
    "start": "507479",
    "end": "512520"
  },
  {
    "text": "why you've suddenly seen so many more tools using it",
    "start": "512520",
    "end": "517740"
  },
  {
    "text": "and of course with ebpf we don't have to wait for the Linux kernel to be rolled",
    "start": "517740",
    "end": "522899"
  },
  {
    "text": "out if we can create a new kernel capability in an ebpf program",
    "start": "522899",
    "end": "529500"
  },
  {
    "text": "we can just load it into the machine we don't have to reboot the machine we can",
    "start": "529500",
    "end": "535680"
  },
  {
    "text": "just dynamically change the way that that machine behaves we don't even have",
    "start": "535680",
    "end": "540959"
  },
  {
    "text": "to stop and restart the applications that are running the changes affect the",
    "start": "540959",
    "end": "546720"
  },
  {
    "text": "kernel immediately and we can use this for a number of",
    "start": "546720",
    "end": "554040"
  },
  {
    "text": "different purposes one of which is for dynamically patching uh vulnerabilities",
    "start": "554040",
    "end": "561300"
  },
  {
    "text": "so we can use ebpf to make ourselves more resilient to exploits",
    "start": "561300",
    "end": "566820"
  },
  {
    "text": "one example that I like of this kind of dynamic vulnerability patching is being",
    "start": "566820",
    "end": "574380"
  },
  {
    "start": "573000",
    "end": "573000"
  },
  {
    "text": "resilient to packets of death so a packet of death is a",
    "start": "574380",
    "end": "580380"
  },
  {
    "text": "well it's a packet that takes advantage of a kernel vulnerability there have been a few of these over time where the",
    "start": "580380",
    "end": "587940"
  },
  {
    "text": "kernel doesn't handle a packet correctly for example maybe there's a if if you put a",
    "start": "587940",
    "end": "595019"
  },
  {
    "text": "length field into that Network packet that's incorrect maybe the panel doesn't handle it correctly and",
    "start": "595019",
    "end": "601019"
  },
  {
    "text": "um perhaps it crashes or bad things happen now this is pretty easy to mitigate with",
    "start": "601019",
    "end": "609839"
  },
  {
    "text": "with bbpf because we can attach an ebpf",
    "start": "609839",
    "end": "615660"
  },
  {
    "text": "program to the event that is the arrival of a network packet we can look at the",
    "start": "615660",
    "end": "621120"
  },
  {
    "text": "packet see if it is formed in the way that would um exploit this vulnerability the packet",
    "start": "621120",
    "end": "627839"
  },
  {
    "text": "of debt is it a packet of death and if it is we can just discard that packet",
    "start": "627839",
    "end": "635220"
  },
  {
    "text": "so as an example of of how easy this is I'm just going to show a another example",
    "start": "635220",
    "end": "641580"
  },
  {
    "start": "636000",
    "end": "636000"
  },
  {
    "text": "of a program that will drop pbpf sorry double drop Network packets",
    "start": "641580",
    "end": "646680"
  },
  {
    "text": "of a particular form in this example I'm going to look for Ping packets that's the protocol icmp",
    "start": "646680",
    "end": "655100"
  },
  {
    "text": "and I can drop them so let's find my window for that here's",
    "start": "655100",
    "end": "662040"
  },
  {
    "text": "my program don't worry too much about the details here I'm uh essentially just looking at the",
    "start": "662040",
    "end": "668760"
  },
  {
    "text": "structure of the network packet and here is a",
    "start": "668760",
    "end": "674279"
  },
  {
    "text": "looking I'm identifying that I've found a ping packet and for now I'm just going to allow them",
    "start": "674279",
    "end": "681420"
  },
  {
    "text": "to carry on XDP pass means just carry on doing whatever you would have done with",
    "start": "681420",
    "end": "686640"
  },
  {
    "text": "this packet I'm going to trace out uh whatever's",
    "start": "686640",
    "end": "693480"
  },
  {
    "text": "loaded into that actually let me stop that other program that's still running okay",
    "start": "693480",
    "end": "699120"
  },
  {
    "text": "so that has been merely tracing out hello qcon for the last five minutes",
    "start": "699120",
    "end": "706019"
  },
  {
    "text": "okay so that should emit whatever tracing you get and I'm going to start pinging",
    "start": "706019",
    "end": "713459"
  },
  {
    "text": "uh the this is actually a container called ping box so I'm gonna just start",
    "start": "713459",
    "end": "719160"
  },
  {
    "text": "sending pings to that address and they're being responded to we can",
    "start": "719160",
    "end": "725040"
  },
  {
    "text": "see the sequence number here ticking up nicely at the moment my ebtf program is not",
    "start": "725040",
    "end": "731220"
  },
  {
    "text": "loaded and I'm gonna run a make file that will compile my program",
    "start": "731220",
    "end": "738120"
  },
  {
    "text": "um clean up any previous uh programs attached to this network interface and",
    "start": "738120",
    "end": "743160"
  },
  {
    "text": "then load my program so there's make running the compile and",
    "start": "743160",
    "end": "748620"
  },
  {
    "text": "then attaching to the network interface F0 here",
    "start": "748620",
    "end": "754019"
  },
  {
    "text": "and you see immediately it started tracing out got icmp packet",
    "start": "754019",
    "end": "760860"
  },
  {
    "text": "okay so that hasn't affected the behavior and my sequence numbers are still just ticking up as before",
    "start": "760860",
    "end": "768120"
  },
  {
    "text": "let's change this to say drop",
    "start": "768120",
    "end": "773459"
  },
  {
    "text": "and we'll just make that and what we should see is",
    "start": "776220",
    "end": "783300"
  },
  {
    "text": "the tracing here is still being generated so it's continuing to",
    "start": "783300",
    "end": "788519"
  },
  {
    "text": "receive those ping packets but those packets have been dropped so",
    "start": "788519",
    "end": "794100"
  },
  {
    "text": "they never get responded to and on this side here the sequence",
    "start": "794100",
    "end": "799320"
  },
  {
    "text": "numbers have stopped going up because we're not getting the response back so let's just change it back to pass",
    "start": "799320",
    "end": "809420"
  },
  {
    "text": "make it again and we should see yeah oops there's my secrets numbers that you know",
    "start": "812519",
    "end": "819480"
  },
  {
    "text": "there were 40 or so packets that were missed out but now it's working again",
    "start": "819480",
    "end": "825480"
  },
  {
    "text": "so what I hope that illustrates is well first of all how we can attach to a",
    "start": "825480",
    "end": "830519"
  },
  {
    "text": "network interface and do things with network packets but also that we can",
    "start": "830519",
    "end": "836519"
  },
  {
    "text": "dynamically change that behavior we didn't have to stop and start paying we didn't have to stop and start anything",
    "start": "836519",
    "end": "842600"
  },
  {
    "text": "uh all we were doing was changing the behavior of the kernel live",
    "start": "842600",
    "end": "850260"
  },
  {
    "text": "so I was illustrating that as um a kind of an illustration of how",
    "start": "850500",
    "end": "856920"
  },
  {
    "text": "handling packet of death scenarios um would work",
    "start": "856920",
    "end": "862860"
  },
  {
    "text": "we can be resilient to a number of other different exploits using BPF Linux",
    "start": "862860",
    "end": "869220"
  },
  {
    "text": "security modules so you may have come across Linux security modules uh such as app armor or",
    "start": "869220",
    "end": "877500"
  },
  {
    "text": "SC Linux and there's a Linux security module API",
    "start": "877500",
    "end": "882839"
  },
  {
    "text": "in the kernel which gives us a number of different events that",
    "start": "882839",
    "end": "888360"
  },
  {
    "text": "something like app armor can look at and decide whether or not that event is in",
    "start": "888360",
    "end": "895079"
  },
  {
    "text": "or out of policy and either allow or disallow that particular Behavior to to",
    "start": "895079",
    "end": "901380"
  },
  {
    "text": "go ahead so for example allowing or disallowing file access",
    "start": "901380",
    "end": "907160"
  },
  {
    "text": "we can write BPF programs that attach to that same LSM API and that gives us a",
    "start": "907160",
    "end": "915959"
  },
  {
    "text": "lot more flexibility a lot more Dynamic security policies",
    "start": "915959",
    "end": "921420"
  },
  {
    "text": "um and as an example of that there's a an application called Tracy that's",
    "start": "921420",
    "end": "927060"
  },
  {
    "text": "written by my former colleagues at Aqua which will attach to LSM events and",
    "start": "927060",
    "end": "933180"
  },
  {
    "text": "decide whether they are in or out of policy",
    "start": "933180",
    "end": "937759"
  },
  {
    "text": "bbpf to help us be resilient to exploits",
    "start": "939660",
    "end": "944940"
  },
  {
    "text": "what other kinds of resiliency can we enable with ebpf",
    "start": "944940",
    "end": "951120"
  },
  {
    "text": "well one other example is load balancing and load balancing can be used to scale",
    "start": "951120",
    "end": "958560"
  },
  {
    "text": "requests across a number of different um back-end instances",
    "start": "958560",
    "end": "965639"
  },
  {
    "text": "but we often do it not just for scaling but also to allow for resilience to",
    "start": "965699",
    "end": "971940"
  },
  {
    "text": "failure High availability we might have multiple instances so that if one of",
    "start": "971940",
    "end": "977579"
  },
  {
    "text": "those instances fails in some way we still have enough other instances to",
    "start": "977579",
    "end": "982920"
  },
  {
    "text": "carry on handling that traffic so",
    "start": "982920",
    "end": "988380"
  },
  {
    "start": "988000",
    "end": "988000"
  },
  {
    "text": "in that previous example I showed you ebpf program attached to a network",
    "start": "988380",
    "end": "994980"
  },
  {
    "text": "interface or rather it's attached to something called the express data path",
    "start": "994980",
    "end": "1002180"
  },
  {
    "text": "of a network interface and express data path is is very cool in",
    "start": "1002180",
    "end": "1010519"
  },
  {
    "text": "my opinion and you may or may not have a",
    "start": "1010519",
    "end": "1015680"
  },
  {
    "text": "network card that allows you to actually run the XDP program so run the ebpf",
    "start": "1015680",
    "end": "1023060"
  },
  {
    "text": "program on the hardware of your network interface card",
    "start": "1023060",
    "end": "1029720"
  },
  {
    "text": "and XDP is as close as possible it's run as",
    "start": "1029720",
    "end": "1035720"
  },
  {
    "text": "close as possible to that physical uh arrival of a network packet so if your",
    "start": "1035720",
    "end": "1041360"
  },
  {
    "text": "network interface card supports it it can run directly on the network interface card in that case the kernels",
    "start": "1041360",
    "end": "1047959"
  },
  {
    "text": "Network stack would never even see that packet blazingly fast handling",
    "start": "1047959",
    "end": "1053179"
  },
  {
    "text": "if the network card doesn't have uh support for it the kernel can run your evpf program again as early as possible",
    "start": "1053179",
    "end": "1061340"
  },
  {
    "text": "on receipts of that Network packet um still super fast because",
    "start": "1061340",
    "end": "1066919"
  },
  {
    "text": "um there's no need for the the package to Traverse the network stack certainly never gets anywhere near being copied",
    "start": "1066919",
    "end": "1073640"
  },
  {
    "text": "into user space memory we can process our packet very quickly using XDP",
    "start": "1073640",
    "end": "1081140"
  },
  {
    "text": "and we can make decisions like should we redirect that packet",
    "start": "1081140",
    "end": "1086539"
  },
  {
    "start": "1083000",
    "end": "1083000"
  },
  {
    "text": "and we can do layer three layer four load balancing in the kernel incredibly",
    "start": "1086539",
    "end": "1091820"
  },
  {
    "text": "quickly possibly not even in the kernel possibly on a network card to decide",
    "start": "1091820",
    "end": "1096980"
  },
  {
    "text": "whether or not we should uh pass this packet on up to the network stack and",
    "start": "1096980",
    "end": "1104299"
  },
  {
    "text": "through to user space on this machine or perhaps we should be load balancing it",
    "start": "1104299",
    "end": "1109460"
  },
  {
    "text": "off to a different physical machine altogether so we can redirect packets",
    "start": "1109460",
    "end": "1116780"
  },
  {
    "text": "um we can do that very fast we can use that for load balancing",
    "start": "1116780",
    "end": "1123679"
  },
  {
    "text": "let's just briefly turn our thoughts to kubernetes I will be talking more about kubernetes shortly",
    "start": "1123679",
    "end": "1129980"
  },
  {
    "text": "in kubernetes we have a load balancer called the cube proxy and the key proxy",
    "start": "1129980",
    "end": "1136340"
  },
  {
    "text": "balances or allows load balancing it tells pod traffic how to reach other",
    "start": "1136340",
    "end": "1143419"
  },
  {
    "text": "pods how can a message from one pod get to another pod so it acts as a a proxy service and what",
    "start": "1143419",
    "end": "1151460"
  },
  {
    "text": "is a proxy if not essentially a load balancer",
    "start": "1151460",
    "end": "1157240"
  },
  {
    "text": "with ebpf we have the option not just to attach to the XDP interface close to the",
    "start": "1157520",
    "end": "1165799"
  },
  {
    "text": "um the physical interface as possible we also have the opportunity to attach to",
    "start": "1165799",
    "end": "1171620"
  },
  {
    "text": "the socket interface so as close to the application as possible applications talk to networks through the socket",
    "start": "1171620",
    "end": "1180320"
  },
  {
    "text": "interface so we can attach to a message arriving",
    "start": "1180320",
    "end": "1186740"
  },
  {
    "text": "from a pod and perhaps bypass the network stack because we know we want to",
    "start": "1186740",
    "end": "1191780"
  },
  {
    "text": "send it to a different to a pod on a different machine or we can by class the network stack and",
    "start": "1191780",
    "end": "1198020"
  },
  {
    "text": "loop straight back to uh an application running on the same",
    "start": "1198020",
    "end": "1203480"
  },
  {
    "text": "physical machine or the same virtual machine so we by intersecting packets kind of as",
    "start": "1203480",
    "end": "1211640"
  },
  {
    "text": "early as possible we can make these load balancing decisions we can avoid having",
    "start": "1211640",
    "end": "1216679"
  },
  {
    "text": "to go through the whole kernels Network stack and it gives us some incredible performance improvements",
    "start": "1216679",
    "end": "1223580"
  },
  {
    "text": "so Cube proxy replacement performance um compared to an IP tables based key",
    "start": "1223580",
    "end": "1230600"
  },
  {
    "start": "1224000",
    "end": "1224000"
  },
  {
    "text": "proxy can be dramatically quicker",
    "start": "1230600",
    "end": "1236360"
  },
  {
    "text": "and I want to now have died a little bit more into why evpf can enable this",
    "start": "1236860",
    "end": "1243020"
  },
  {
    "text": "really efficient networking particularly in kubernetes so in that previous diagram I just",
    "start": "1243020",
    "end": "1249860"
  },
  {
    "text": "showed the kernel Network stack as one box networking stack is pretty complicated",
    "start": "1249860",
    "end": "1257320"
  },
  {
    "text": "typically a packet going through the kernels Network stack goes through a",
    "start": "1257320",
    "end": "1263240"
  },
  {
    "text": "whole bunch of different steps and stages as the colonel decides what to do with",
    "start": "1263240",
    "end": "1268940"
  },
  {
    "text": "it in kubernetes we have not just the",
    "start": "1268940",
    "end": "1274280"
  },
  {
    "text": "networking stack on the host but we typically run a network namespace for every pod and each pod",
    "start": "1274280",
    "end": "1282380"
  },
  {
    "text": "by having its own network namespace has to run its own networking",
    "start": "1282380",
    "end": "1288020"
  },
  {
    "text": "stack so imagine a packet that arrives on the physical f-zero interface",
    "start": "1288020",
    "end": "1295640"
  },
  {
    "text": "and it traverses the whole kernels networking stack to reach the virtual",
    "start": "1295640",
    "end": "1301220"
  },
  {
    "text": "ethernet connection to the Pod where it's destined to go",
    "start": "1301220",
    "end": "1306520"
  },
  {
    "text": "then it goes through the pods networking stack to reach the application via a",
    "start": "1306520",
    "end": "1312620"
  },
  {
    "text": "socket now if we use ebpf we can",
    "start": "1312620",
    "end": "1319159"
  },
  {
    "text": "particularly if we know about kubernetes identities and addresses we can bypass that stack on the on the",
    "start": "1319159",
    "end": "1328100"
  },
  {
    "text": "host when we receive a packet on that F0 interface",
    "start": "1328100",
    "end": "1333679"
  },
  {
    "text": "if we already know what pod well that IP address is associated with a particular",
    "start": "1333679",
    "end": "1340159"
  },
  {
    "text": "pod we can essentially do a lookup and just pass that packet straight to the",
    "start": "1340159",
    "end": "1346760"
  },
  {
    "text": "Pod where it then goes through the pods networking stack but doesn't have to go",
    "start": "1346760",
    "end": "1352039"
  },
  {
    "text": "through all the complication of everything happening on the hosts networking stack",
    "start": "1352039",
    "end": "1357980"
  },
  {
    "text": "and using an ebpf enabled networking interface for kubernetes like psyllium",
    "start": "1357980",
    "end": "1365659"
  },
  {
    "text": "we can enable this kind of network stack shortcutting because we're aware of",
    "start": "1365659",
    "end": "1371620"
  },
  {
    "text": "kubernetes identity so we know what IP addresses are associated with which pods",
    "start": "1371620",
    "end": "1377960"
  },
  {
    "text": "but also which pods are associated with with which services with namespaces so",
    "start": "1377960",
    "end": "1384200"
  },
  {
    "text": "on and so forth and with that knowledge we can build up these service maps",
    "start": "1384200",
    "end": "1391880"
  },
  {
    "start": "1387000",
    "end": "1387000"
  },
  {
    "text": "showing how traffic is Flowing between uh different components within our",
    "start": "1391880",
    "end": "1397640"
  },
  {
    "text": "cluster and ebpf is giving us visibility into",
    "start": "1397640",
    "end": "1402760"
  },
  {
    "text": "the packet so we can see things like uh what not just the um destination IP",
    "start": "1402760",
    "end": "1410419"
  },
  {
    "text": "address and Port but we can also see we can uh read through a proxy to find out what",
    "start": "1410419",
    "end": "1417380"
  },
  {
    "text": "HTTP type of request it is and we can associate that flow data with",
    "start": "1417380",
    "end": "1425960"
  },
  {
    "text": "kubernetes identities in a kubernetes network IP addresses change all the time pods",
    "start": "1425960",
    "end": "1433340"
  },
  {
    "text": "come and go and the an IP address one minute May mean one thing and two minutes later it means",
    "start": "1433340",
    "end": "1441080"
  },
  {
    "text": "something completely different IP addresses are not terribly helpful for understanding the flows within a",
    "start": "1441080",
    "end": "1448460"
  },
  {
    "text": "kubernetes cluster but psyllium can map those IP addresses to",
    "start": "1448460",
    "end": "1455179"
  },
  {
    "text": "the correct pod the correct service at any given point in time and give you much more readable information",
    "start": "1455179",
    "end": "1463220"
  },
  {
    "text": "and it is measurably faster whether you're using psyllium or other",
    "start": "1463220",
    "end": "1469940"
  },
  {
    "text": "implementations of ebpf networking that ability to bypass the",
    "start": "1469940",
    "end": "1476419"
  },
  {
    "text": "kernels the get the networking stack on the host",
    "start": "1476419",
    "end": "1482179"
  },
  {
    "text": "gives us measurable performance improvements we can see here that the uh",
    "start": "1482179",
    "end": "1488179"
  },
  {
    "text": "well the blue line on the left is uh the request response rate for number of",
    "start": "1488179",
    "end": "1495020"
  },
  {
    "text": "requests per second that we can achieve without any containers at all just directly sending and receiving traffic",
    "start": "1495020",
    "end": "1500480"
  },
  {
    "text": "between nodes and we can get performance that's nearly as fast",
    "start": "1500480",
    "end": "1505940"
  },
  {
    "text": "using ebpf those yellow and green lower bars in the middle show us what happens if we don't",
    "start": "1505940",
    "end": "1512780"
  },
  {
    "text": "use ebpf and we use the kind of Legacy host routing approach through the host",
    "start": "1512780",
    "end": "1518960"
  },
  {
    "text": "Network stack it's measurably slower and we can also take advantage of having",
    "start": "1518960",
    "end": "1527000"
  },
  {
    "start": "1526000",
    "end": "1526000"
  },
  {
    "text": "that knowledge of kubernetes identities and the ability to drop packets to build",
    "start": "1527000",
    "end": "1533779"
  },
  {
    "text": "very efficient Network policy implementations so you saw how easy it",
    "start": "1533779",
    "end": "1541039"
  },
  {
    "text": "was to drop packets rather than just inspecting the packet and deciding that it was a pain packet can compare the",
    "start": "1541039",
    "end": "1548240"
  },
  {
    "text": "packet to policy rules and decide whether or not they should be",
    "start": "1548240",
    "end": "1554539"
  },
  {
    "text": "forwarded or not and uh this is quite a nice tool that we",
    "start": "1554539",
    "end": "1559940"
  },
  {
    "text": "have uh you can find this at Network policy.io um to visualize kubernetes Network policies",
    "start": "1559940",
    "end": "1569919"
  },
  {
    "text": "so we talked about load balancing and how we can use load balancing within a",
    "start": "1570980",
    "end": "1576919"
  },
  {
    "text": "kubernetes cluster um in the form of Q proxy and after all",
    "start": "1576919",
    "end": "1582380"
  },
  {
    "text": "kubernetes gives us a huge amount of resiliency if a",
    "start": "1582380",
    "end": "1588200"
  },
  {
    "text": "application pod crashes it can be recreated dynamically without any",
    "start": "1588200",
    "end": "1593240"
  },
  {
    "text": "operator intervention we can scale automatically without operator",
    "start": "1593240",
    "end": "1598760"
  },
  {
    "text": "intervention but what about the resiliency of the cluster as a whole if your cluster is",
    "start": "1598760",
    "end": "1605720"
  },
  {
    "text": "running in a particular Data Center and you lose connectivity to that data",
    "start": "1605720",
    "end": "1610880"
  },
  {
    "text": "center typically we we can use multiple",
    "start": "1610880",
    "end": "1616820"
  },
  {
    "text": "clusters and I want to show how ebtf can make the um connectivity between multiple",
    "start": "1616820",
    "end": "1623840"
  },
  {
    "text": "clusters really very straightforward and uh in cilium we do this using a feature",
    "start": "1623840",
    "end": "1630260"
  },
  {
    "text": "called cluster mesh so with cluster mesh if we have two",
    "start": "1630260",
    "end": "1636039"
  },
  {
    "start": "1635000",
    "end": "1635000"
  },
  {
    "text": "kubernetes clusters the psyllium agent running in each",
    "start": "1636039",
    "end": "1641960"
  },
  {
    "text": "cluster will read a certain amount of information about the state of other",
    "start": "1641960",
    "end": "1648080"
  },
  {
    "text": "clusters in that cluster mesh each cluster has its own database of",
    "start": "1648080",
    "end": "1655039"
  },
  {
    "text": "configuration and state stored in etcd and we run some actually the proxy",
    "start": "1655039",
    "end": "1661279"
  },
  {
    "text": "components that allow us to just find out about the multi-cluster specific",
    "start": "1661279",
    "end": "1667820"
  },
  {
    "text": "inter information that we need so that uh the psyllium agents on all the",
    "start": "1667820",
    "end": "1674840"
  },
  {
    "text": "Clusters can share that kind of multi multi-cluster State what do I mean by",
    "start": "1674840",
    "end": "1681679"
  },
  {
    "text": "multi-cluster state well typically this is going to be about creating highly",
    "start": "1681679",
    "end": "1687860"
  },
  {
    "start": "1685000",
    "end": "1685000"
  },
  {
    "text": "available services so we might run multiple instances of a",
    "start": "1687860",
    "end": "1695000"
  },
  {
    "text": "service on multiple clusters to make them highly available",
    "start": "1695000",
    "end": "1700700"
  },
  {
    "text": "with cluster mesh we simply Mark a Services global",
    "start": "1700700",
    "end": "1706520"
  },
  {
    "text": "and that connects them together such that uh pod accessing that global",
    "start": "1706520",
    "end": "1714320"
  },
  {
    "text": "Service can access it on its own cluster or on a different cluster should that be",
    "start": "1714320",
    "end": "1720559"
  },
  {
    "text": "necessary so I think this is a really nice feature of psyllium and remarkably easy to set",
    "start": "1720559",
    "end": "1727820"
  },
  {
    "text": "up so if the",
    "start": "1727820",
    "end": "1733580"
  },
  {
    "text": "back end pod on one cluster is destroyed for some reason or indeed",
    "start": "1733580",
    "end": "1739100"
  },
  {
    "text": "if the whole cluster goes down we still have the ability to root requests from other pods on that cluster to back end",
    "start": "1739100",
    "end": "1748159"
  },
  {
    "text": "pods on a different cluster they can be treated as a global Service",
    "start": "1748159",
    "end": "1753919"
  },
  {
    "text": "so I think I have an example of this uh I have two classes Let's uh so I think I",
    "start": "1753919",
    "end": "1762500"
  },
  {
    "text": "have let's just my first cluster",
    "start": "1762500",
    "end": "1767840"
  },
  {
    "text": "is up we can see cm1 standard for cluster mesh one and",
    "start": "1767840",
    "end": "1773659"
  },
  {
    "text": "um and a second cluster that's cm2",
    "start": "1773659",
    "end": "1779179"
  },
  {
    "text": "okay and they are both running some pods uh",
    "start": "1779179",
    "end": "1785779"
  },
  {
    "text": "we quite often in psyllium do uh some demos with a Star Wars theme and in this",
    "start": "1785779",
    "end": "1791360"
  },
  {
    "text": "case we have some X-Wing Fighters that want to be able to communicate with the rebel base",
    "start": "1791360",
    "end": "1797000"
  },
  {
    "text": "we also have some uh similar x-wings and rebel bases on the",
    "start": "1797000",
    "end": "1803899"
  },
  {
    "text": "second cluster and let's just take a look at the services",
    "start": "1803899",
    "end": "1810320"
  },
  {
    "text": "in fact let's describe that uh rebel base",
    "start": "1810320",
    "end": "1816620"
  },
  {
    "text": "service base and you can see it's annotated by",
    "start": "1816620",
    "end": "1822559"
  },
  {
    "text": "psyllium as a global Service and or it's allocate it's been annotated",
    "start": "1822559",
    "end": "1828740"
  },
  {
    "text": "by by me who's as part of the configuration to say I want this to be a global Service",
    "start": "1828740",
    "end": "1836440"
  },
  {
    "text": "and the same is true if I look on the uh the second cluster there they're both",
    "start": "1837260",
    "end": "1842960"
  },
  {
    "text": "described as global and what that means is I can issue",
    "start": "1842960",
    "end": "1848899"
  },
  {
    "text": "requests from an X-Wing on either cluster and it will receive",
    "start": "1848899",
    "end": "1854620"
  },
  {
    "text": "responses from a kind of load balanced across those two different clusters",
    "start": "1854620",
    "end": "1859880"
  },
  {
    "text": "across back ends on those two different clusters",
    "start": "1859880",
    "end": "1865340"
  },
  {
    "text": "so let's try that let's um let's run",
    "start": "1865340",
    "end": "1870559"
  },
  {
    "text": "run it in a loop let's hope I get this right so let's",
    "start": "1870559",
    "end": "1876940"
  },
  {
    "text": "SEC into an X-Wing it doesn't really matter which X-Wing",
    "start": "1878140",
    "end": "1884600"
  },
  {
    "text": "and we want to send a message to the rebel base",
    "start": "1884600",
    "end": "1889778"
  },
  {
    "text": "and hopefully what we should see is we're",
    "start": "1890059",
    "end": "1895100"
  },
  {
    "text": "getting responses from sometimes it's cluster one sometimes it's cluster two at random",
    "start": "1895100",
    "end": "1902559"
  },
  {
    "text": "so what if something bad were to happen to the rebel based pods on one of those",
    "start": "1902659",
    "end": "1909020"
  },
  {
    "text": "clusters so uh let's",
    "start": "1909020",
    "end": "1913659"
  },
  {
    "text": "see which nodes of the cake let's delete the pods on",
    "start": "1914240",
    "end": "1920299"
  },
  {
    "text": "cluster 2. so I'm going to delete in fact I'll delete the whole deployment",
    "start": "1920299",
    "end": "1927860"
  },
  {
    "text": "of rebel base on on the second cluster",
    "start": "1927860",
    "end": "1932960"
  },
  {
    "text": "thank you and what we should see is that all the",
    "start": "1932960",
    "end": "1938960"
  },
  {
    "text": "requests are now handled by cluster one and indeed you can see it's been cluster",
    "start": "1938960",
    "end": "1945080"
  },
  {
    "text": "one now for quite some time",
    "start": "1945080",
    "end": "1948519"
  },
  {
    "text": "that kind of resiliency where we literally just have to mark our services",
    "start": "1950720",
    "end": "1956600"
  },
  {
    "text": "AS Global um it's an incredibly powerful way of enabling that kind of multi-cluster",
    "start": "1956600",
    "end": "1964760"
  },
  {
    "text": "High availability now lest I give you the impression that",
    "start": "1964760",
    "end": "1970760"
  },
  {
    "text": "ebpf is just about networking and advantages in networking",
    "start": "1970760",
    "end": "1976100"
  },
  {
    "text": "let me also talk a bit about how we can use ebpf for observability which is",
    "start": "1976100",
    "end": "1981799"
  },
  {
    "text": "after all incredibly important if something does go wrong we need observability so that we can understand",
    "start": "1981799",
    "end": "1988100"
  },
  {
    "text": "what's happened in a kubernetes cluster",
    "start": "1988100",
    "end": "1993679"
  },
  {
    "text": "we have a number of hosts and each host has only one kernel",
    "start": "1993679",
    "end": "1999380"
  },
  {
    "text": "however many user space applications we're running however many containers",
    "start": "1999380",
    "end": "2004419"
  },
  {
    "text": "were running they're all sharing that one kernel per host if they're in pods there's still only",
    "start": "2004419",
    "end": "2011440"
  },
  {
    "text": "one kernel however many pods there are and whenever those applications in pods",
    "start": "2011440",
    "end": "2017980"
  },
  {
    "text": "want to do anything interesting like read or write your file or send or",
    "start": "2017980",
    "end": "2023320"
  },
  {
    "text": "receive Network traffic whenever kubernetes wants to create a container",
    "start": "2023320",
    "end": "2028419"
  },
  {
    "text": "anything complicated involves the kernel so the kernel has visibility and",
    "start": "2028419",
    "end": "2035679"
  },
  {
    "text": "awareness of everything interesting that's happening across the entire host",
    "start": "2035679",
    "end": "2043620"
  },
  {
    "text": "and that means if we use ebpf programs to instrument the kernel we can be aware",
    "start": "2043779",
    "end": "2049179"
  },
  {
    "text": "of everything happening on that whole host and because we can instrument",
    "start": "2049179",
    "end": "2056740"
  },
  {
    "text": "pretty much anything that's happening in the kernel we can use it for a wide",
    "start": "2056740",
    "end": "2061839"
  },
  {
    "text": "variety of different metrics and observability tools",
    "start": "2061839",
    "end": "2068020"
  },
  {
    "text": "different kinds of tracing they can all be built using ebpf as an example this is a tool called",
    "start": "2068020",
    "end": "2075339"
  },
  {
    "start": "2074000",
    "end": "2074000"
  },
  {
    "text": "pixie which is a cncf Sandbox project and it's giving us with this flame graph",
    "start": "2075339",
    "end": "2083020"
  },
  {
    "text": "um information about what's running across the entire cluster so it's aggregating information from ebps",
    "start": "2083020",
    "end": "2091060"
  },
  {
    "text": "programs running on every node in the cluster to produce this overview of how",
    "start": "2091060",
    "end": "2099760"
  },
  {
    "text": "CPU time is being used across the whole cluster with detail into you know",
    "start": "2099760",
    "end": "2105520"
  },
  {
    "text": "specific functions that those applications are calling foreign",
    "start": "2105520",
    "end": "2111240"
  },
  {
    "text": "thing about this is that you didn't have to make any changes to your application",
    "start": "2112320",
    "end": "2118000"
  },
  {
    "text": "you don't have to change the configuration even to get this instrumentation",
    "start": "2118000",
    "end": "2123160"
  },
  {
    "text": "because as we saw when you make a change in the kernel it immediately affects whatever happens to",
    "start": "2123160",
    "end": "2130420"
  },
  {
    "text": "me running on that kernel we don't have to restart those processes or anything",
    "start": "2130420",
    "end": "2135660"
  },
  {
    "text": "and this also has an interesting um implication for what we call the",
    "start": "2135660",
    "end": "2140680"
  },
  {
    "text": "psychar model um in a lot of ways ebpf gives us a lot",
    "start": "2140680",
    "end": "2146260"
  },
  {
    "text": "more Simplicity compared to the sidecar model and Nathan Leclair did this really nice cartoon that um I've I've borrowed",
    "start": "2146260",
    "end": "2155200"
  },
  {
    "text": "um it's I I really like this cartoon",
    "start": "2155200",
    "end": "2159060"
  },
  {
    "text": "we have to inject Tina into pod that we want to instrument it has to",
    "start": "2162040",
    "end": "2168460"
  },
  {
    "text": "be inside the pods because that's how one user space application can get visibility over other things",
    "start": "2168460",
    "end": "2176740"
  },
  {
    "text": "that are happening in that pod it has to share namespaces with that pod",
    "start": "2176740",
    "end": "2182079"
  },
  {
    "text": "so we have to inject that sidecar into every pod and to do that that requires",
    "start": "2182079",
    "end": "2189579"
  },
  {
    "start": "2187000",
    "end": "2187000"
  },
  {
    "text": "some yaml be introduced into some into the the definition of that pot",
    "start": "2189579",
    "end": "2197160"
  },
  {
    "text": "you probably don't write that yaml by hand to inject a sidecar it's probably",
    "start": "2197160",
    "end": "2202900"
  },
  {
    "text": "done perhaps in admission control or as part of a cicd process something will",
    "start": "2202900",
    "end": "2210339"
  },
  {
    "text": "likely automate the process of injecting that sidecar but nevertheless it has to",
    "start": "2210339",
    "end": "2215680"
  },
  {
    "text": "be injected so if something goes wrong with that process or perhaps you didn't mark a particular",
    "start": "2215680",
    "end": "2223480"
  },
  {
    "text": "pod as being something you want to instrument if it doesn't happen then your",
    "start": "2223480",
    "end": "2230520"
  },
  {
    "text": "instrumentation has no visibility into that pod",
    "start": "2230520",
    "end": "2235660"
  },
  {
    "start": "2235000",
    "end": "2235000"
  },
  {
    "text": "on the other hand if we use ebpf we're running our instrumentation",
    "start": "2235660",
    "end": "2240760"
  },
  {
    "text": "within the kernel then we don't need to change the Pod definition we're",
    "start": "2240760",
    "end": "2245800"
  },
  {
    "text": "automatically getting that visibility from the Kernel's perspective because the kernel can see everything that's",
    "start": "2245800",
    "end": "2252640"
  },
  {
    "text": "happening on that host and so long as we add evpf programs onto every host we",
    "start": "2252640",
    "end": "2258700"
  },
  {
    "text": "will get that comprehensive visibility that also means that we can be resilient",
    "start": "2258700",
    "end": "2265359"
  },
  {
    "text": "to attacks if somehow are",
    "start": "2265359",
    "end": "2271540"
  },
  {
    "text": "host gets compromised if someone manages to escape a container and get onto the",
    "start": "2271540",
    "end": "2277359"
  },
  {
    "text": "host or even if they run a separate pod somehow your attacker is probably not",
    "start": "2277359",
    "end": "2284440"
  },
  {
    "text": "going to bother instrumenting their processes and their pods with your",
    "start": "2284440",
    "end": "2289780"
  },
  {
    "text": "observability tools but if your observability tools are",
    "start": "2289780",
    "end": "2295180"
  },
  {
    "text": "running in the kernel they will be seen regardless you can't hide from tooling that's running in the",
    "start": "2295180",
    "end": "2302320"
  },
  {
    "text": "kernel so this ability to run instrumentation",
    "start": "2302320",
    "end": "2308260"
  },
  {
    "text": "without sidecars is creating some really powerful observability tools",
    "start": "2308260",
    "end": "2314980"
  },
  {
    "text": "but it also takes us to the idea of a sidecarless service mesh service mesh is",
    "start": "2314980",
    "end": "2321220"
  },
  {
    "text": "there to be resilient and observable and secure and",
    "start": "2321220",
    "end": "2326560"
  },
  {
    "text": "now with evpf we can Implement service mesh without the use of sidecars",
    "start": "2326560",
    "end": "2333660"
  },
  {
    "start": "2333000",
    "end": "2333000"
  },
  {
    "text": "I showed before that that Network diagram of um or the diagram showing how we can bypass the",
    "start": "2334000",
    "end": "2340300"
  },
  {
    "text": "networking stack on the host using evpf we can take that another step further",
    "start": "2340300",
    "end": "2347260"
  },
  {
    "text": "for service mesh and in the traditional sidecar model we run",
    "start": "2347260",
    "end": "2355060"
  },
  {
    "text": "a proxy perhaps it's envoy inside every pod that we want to be part of the",
    "start": "2355060",
    "end": "2360099"
  },
  {
    "text": "service mesh and every instance of that proxy has routing information and every",
    "start": "2360099",
    "end": "2366040"
  },
  {
    "text": "packet has to pass through that proxy so you can see on the left hand side of",
    "start": "2366040",
    "end": "2372820"
  },
  {
    "text": "this diagram the path for Network packets is pretty torturous it's going through essentially five instances of",
    "start": "2372820",
    "end": "2380079"
  },
  {
    "text": "the networking stack we can dramatically shortcut that with evpf we can't always avoid a proxy we if",
    "start": "2380079",
    "end": "2388839"
  },
  {
    "text": "we're doing something at layer 7 we need that proxy but we can avoid having a",
    "start": "2388839",
    "end": "2394660"
  },
  {
    "text": "proxy instance inside every pod so we can be much more scalable by having far",
    "start": "2394660",
    "end": "2401200"
  },
  {
    "text": "fewer copies of of routing information and configuration information and we can bypass",
    "start": "2401200",
    "end": "2408280"
  },
  {
    "text": "so many of those networking steps through evpf connections either at the",
    "start": "2408280",
    "end": "2413619"
  },
  {
    "text": "networking layer or well the XDP layer within the networking stack or at the",
    "start": "2413619",
    "end": "2418960"
  },
  {
    "text": "socket layer so",
    "start": "2418960",
    "end": "2424180"
  },
  {
    "text": "ebpf will give us service mesh that's far less resource hungry that's much",
    "start": "2424180",
    "end": "2431079"
  },
  {
    "text": "more efficient I hope that's given a flavor of some of",
    "start": "2431079",
    "end": "2438760"
  },
  {
    "text": "the things that I think ebpf is enabling around networking observability and",
    "start": "2438760",
    "end": "2445660"
  },
  {
    "text": "security that's going to give us far more resilient and scalable deployments",
    "start": "2445660",
    "end": "2453180"
  },
  {
    "text": "one last thing to note I've pretty much been talking about Linux so far but it",
    "start": "2453180",
    "end": "2459579"
  },
  {
    "text": "is also coming to Windows Microsoft have been working on ebpf on Windows",
    "start": "2459579",
    "end": "2465640"
  },
  {
    "text": "um they've been part alongside I surveillance and a number of other",
    "start": "2465640",
    "end": "2471720"
  },
  {
    "text": "massively scalable uh or companies that are interested in massively scalable",
    "start": "2471720",
    "end": "2476740"
  },
  {
    "text": "networks we've come together to form the ebpf foundation which is a foundation",
    "start": "2476740",
    "end": "2483820"
  },
  {
    "text": "under the Linux Foundation ready to take care of ebpf Technology",
    "start": "2483820",
    "end": "2490079"
  },
  {
    "text": "across different operating systems",
    "start": "2490079",
    "end": "2494940"
  },
  {
    "text": "that gives a sense of why ebpf is so important and it's so revolutionary for",
    "start": "2495880",
    "end": "2504460"
  },
  {
    "text": "resilient deployments of software particularly in the cloud native space but not",
    "start": "2504460",
    "end": "2510160"
  },
  {
    "text": "necessarily limited to regardless of whether you're running Linux or Windows",
    "start": "2510160",
    "end": "2515700"
  },
  {
    "text": "there are ebpf tools to help you optimize those deployments and make them",
    "start": "2515700",
    "end": "2521500"
  },
  {
    "text": "more resilient you can find more information about ebpf at the evpf.io site and psyllium is at",
    "start": "2521500",
    "end": "2531220"
  },
  {
    "text": "psyllium.io there's also a slack channel that you'll find from both of those sites where you'll find experts in",
    "start": "2531220",
    "end": "2538119"
  },
  {
    "text": "psyllium and in ebpf of course if you want to find out more about what we do at I surveillance",
    "start": "2538119",
    "end": "2543940"
  },
  {
    "text": "please visit I surveillance.com or just have a chat with me I am everywhere on the internet as Liz rice",
    "start": "2543940",
    "end": "2551020"
  },
  {
    "text": "thank you very much for your attention and I really hope there will be lots of questions because I love q a",
    "start": "2551020",
    "end": "2558720"
  },
  {
    "text": "so um I don't know if we have um let's see some questions from the",
    "start": "2562599",
    "end": "2567640"
  },
  {
    "text": "audience I have I have one which I maybe sort of kick off with and uh please if anyone uh has some questions please do",
    "start": "2567640",
    "end": "2575260"
  },
  {
    "text": "pop them in so that we can get uh we can get this to answer them um",
    "start": "2575260",
    "end": "2580599"
  },
  {
    "text": "so I guess one of my questions is um around sort of psyllium and stuff",
    "start": "2580599",
    "end": "2586060"
  },
  {
    "text": "um which which companies are using it in production at the moment that that you're kind of seeing and and sort of",
    "start": "2586060",
    "end": "2592000"
  },
  {
    "text": "know about so we've actually got a list in the",
    "start": "2592000",
    "end": "2597460"
  },
  {
    "text": "psyllium GitHub repo of users who have added themselves to the list of adopters",
    "start": "2597460",
    "end": "2602500"
  },
  {
    "text": "there are certainly dozens of them I haven't actually looked at list for a few weeks and I know there have been uh",
    "start": "2602500",
    "end": "2608260"
  },
  {
    "text": "quite a few more adding themselves into it there's companies using it at",
    "start": "2608260",
    "end": "2614260"
  },
  {
    "text": "significant scale um Bell Canada for example using it in",
    "start": "2614260",
    "end": "2620079"
  },
  {
    "text": "Telco Adobe uh data dog these are just a few examples of companies that I that I",
    "start": "2620079",
    "end": "2627040"
  },
  {
    "text": "know I can speak about publicly um yeah it's it's pretty widely adopted",
    "start": "2627040",
    "end": "2632500"
  },
  {
    "text": "yeah that's that's great because um I think as we were saying in the chat it's it's certainly one of the Technologies",
    "start": "2632500",
    "end": "2637660"
  },
  {
    "text": "to to sort of on the up and coming Road and I think the fact that there are already some big players in the market",
    "start": "2637660",
    "end": "2643240"
  },
  {
    "text": "that are already kind of using this is is Testament I think to where it's uh where it's going",
    "start": "2643240",
    "end": "2649060"
  },
  {
    "text": "I guess the other two to mention all the other two Integrations to really mention",
    "start": "2649060",
    "end": "2654339"
  },
  {
    "text": "would be that gke you well the data plane V2 in gke is",
    "start": "2654339",
    "end": "2660700"
  },
  {
    "text": "actually based on cilia and Amazon chose psyllium as the networking cni for their",
    "start": "2660700",
    "end": "2669339"
  },
  {
    "text": "eks anywhere distribution so I feel like that's a very strong rate of confidence",
    "start": "2669339",
    "end": "2674800"
  },
  {
    "text": "in psyllium as a project and the evpf as a as a technology",
    "start": "2674800",
    "end": "2681240"
  },
  {
    "text": "um so another another question um and we can maybe um take some more questions in the in the follow-up",
    "start": "2682540",
    "end": "2689500"
  },
  {
    "text": "um uh a session where we go to after this um but another thing one of the um one",
    "start": "2689500",
    "end": "2695740"
  },
  {
    "text": "of the areas we're looking at on the on the track is around sort of chaos engineering and and that sort of side of",
    "start": "2695740",
    "end": "2701440"
  },
  {
    "text": "things how do you see um sort of ebpf potentially kind of helping out or or",
    "start": "2701440",
    "end": "2706780"
  },
  {
    "text": "sort of uh providing um ways to do different things from a sort of chaos engineering perspective",
    "start": "2706780",
    "end": "2713079"
  },
  {
    "text": "yeah I think this is something that we just touched on briefly in qcon London",
    "start": "2713079",
    "end": "2718180"
  },
  {
    "text": "discussions about how you know with ebpf inserting or having ebpf programs",
    "start": "2718180",
    "end": "2725680"
  },
  {
    "text": "running in the kernel and potentially changing you know events that could be a really",
    "start": "2725680",
    "end": "2732819"
  },
  {
    "text": "great way of triggering chaos tests so for example if you wanted to drop some",
    "start": "2732819",
    "end": "2739720"
  },
  {
    "text": "percentage of packets and see how your system behaved or um insert errors or you know all all",
    "start": "2739720",
    "end": "2747339"
  },
  {
    "text": "manner of disruptive things that you might want to do in chaos testing I think evpf could be a really interesting",
    "start": "2747339",
    "end": "2755740"
  },
  {
    "text": "technology for building that on fantastic",
    "start": "2755740",
    "end": "2761619"
  },
  {
    "text": "um I just seeing I think we are uh we're going to be the room will be closing probably in about three minutes or so",
    "start": "2761619",
    "end": "2768760"
  },
  {
    "text": "um so I do I do highly recommend please please do join us uh in the hangout room",
    "start": "2768760",
    "end": "2774400"
  },
  {
    "text": "um so if you go to the schedule uh page where uh where all where Liz's talk is",
    "start": "2774400",
    "end": "2780099"
  },
  {
    "text": "is listed you can click on the hangout room and you can join there and it'd be great to hear yeah some of your other",
    "start": "2780099",
    "end": "2785920"
  },
  {
    "text": "questions um and you can ask Liz in person as well um that would be awesome so um rather",
    "start": "2785920",
    "end": "2793180"
  },
  {
    "text": "than start new questions now I think maybe we'll head over there and uh see what people have to have to ask but",
    "start": "2793180",
    "end": "2800020"
  },
  {
    "text": "thank you so much Liz um fantastic talk and uh thank you for joining us from Spain as well",
    "start": "2800020",
    "end": "2805780"
  },
  {
    "text": "thanks for having me it's a pleasure all right we'll hopefully hang out shortly indeed hopefully see you all there",
    "start": "2805780",
    "end": "2812260"
  },
  {
    "text": "thanks very much [Music]",
    "start": "2812260",
    "end": "2823560"
  }
]
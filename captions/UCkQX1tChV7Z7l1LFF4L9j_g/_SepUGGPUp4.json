[
  {
    "start": "0",
    "end": "172000"
  },
  {
    "text": "say you have an application maybe a web app when you first started it consumes a",
    "start": "4400",
    "end": "9720"
  },
  {
    "text": "bit of ram several hours later perhaps under a certain load profile that same app is now consuming several gigs of RAM",
    "start": "9720",
    "end": "17160"
  },
  {
    "text": "maybe a lot more than it should you know the memory leak maybe something is hanging on your connections or you have",
    "start": "17160",
    "end": "23580"
  },
  {
    "text": "some objects that aren't being correctly released a common step might be to use a profiler to try to understand where your",
    "start": "23580",
    "end": "29340"
  },
  {
    "text": "memory is being used where it's being held on to maybe you'll load it into a test environment take a heat dump analyze it fix it and then deploy it",
    "start": "29340",
    "end": "35880"
  },
  {
    "text": "sound familiar you can probably guess the next part because black salons happen sometimes certain low profiles",
    "start": "35880",
    "end": "41579"
  },
  {
    "text": "just don't happen the same way in a production use case inter kubernetes too the continuation gets stronger and",
    "start": "41579",
    "end": "47760"
  },
  {
    "text": "stronger what you see in your lower environment may not be the reality of what's in production so what you really",
    "start": "47760",
    "end": "53520"
  },
  {
    "text": "need to do is profile a production but that's much more resource heavy and",
    "start": "53520",
    "end": "58559"
  },
  {
    "text": "invasive to do right what if you could what what if you could profile your application and have that information in",
    "start": "58559",
    "end": "63780"
  },
  {
    "text": "your observability stack what if you could see sample set of your app profile and grafana you've correlated across",
    "start": "63780",
    "end": "69540"
  },
  {
    "text": "deployments for your clusters and seeing all of your Cloud native infrastructure what would it mean to understanding how",
    "start": "69540",
    "end": "75119"
  },
  {
    "text": "your app performs in that environment hi my name is Wes rice I'm a tech principal of thoughtworks and coast and influq",
    "start": "75119",
    "end": "80580"
  },
  {
    "text": "podcast Edition I chair a software conference called qcon that happens in October in the Bay Area you can check us",
    "start": "80580",
    "end": "86100"
  },
  {
    "text": "out at qcon SF to learn more about the conference today on the podcast I'm speaking with Frederick forensic who",
    "start": "86100",
    "end": "92040"
  },
  {
    "text": "incidentally will be one of the presenters along with Justin cormack of Docker Joe Duffy of plumey Marcel van",
    "start": "92040",
    "end": "98340"
  },
  {
    "text": "wyzen of Q and Google's board Fame in Carmen anda's language of infrastructure",
    "start": "98340",
    "end": "103799"
  },
  {
    "text": "track at that very conference this language of infratrac is just one of the 15 tracks at this year's conference it's",
    "start": "103799",
    "end": "111420"
  },
  {
    "text": "not too late to join us at qcon but back to Frederick he is CEO and co-founder of",
    "start": "111420",
    "end": "116460"
  },
  {
    "text": "polar signals before founding polar signals he was a senior principal engineer the main architect for all",
    "start": "116460",
    "end": "122579"
  },
  {
    "text": "things observability at Red Hat where he joined through the core OS acquisition Frederick is a Prometheus and Thanos",
    "start": "122579",
    "end": "128520"
  },
  {
    "text": "maintainer as well as the tech lead for the special interest group for instrumentation in kubernetes in late",
    "start": "128520",
    "end": "134160"
  },
  {
    "text": "2021 polar signals in addition to closing a four million dollar seed round from GV formally Google Ventures and",
    "start": "134160",
    "end": "141540"
  },
  {
    "text": "Lightspeed open source parka in ebpf based continuous profile today on the",
    "start": "141540",
    "end": "146940"
  },
  {
    "text": "podcast we're speaking with Frederick about parka now continuous profiling is not only possible but happening",
    "start": "146940",
    "end": "152340"
  },
  {
    "text": "Frederick welcome to the podcast thanks for having me so I remember a kubecon EU in Barcelona it was just before the",
    "start": "152340",
    "end": "159120"
  },
  {
    "text": "pandemic so 2019 I think you and Tom Wilkes did a keynote were the two of you talked at least in part about continuous",
    "start": "159120",
    "end": "167099"
  },
  {
    "text": "profiling is that where Parker came from I mean is that is that the origin story I think",
    "start": "167099",
    "end": "172440"
  },
  {
    "text": "that was kind of the turning point for me to like think that this is something we really need to explore really deeply",
    "start": "172440",
    "end": "178379"
  },
  {
    "text": "and I think that's what ultimately made me think I can start a company around this but there is a longer backstory to",
    "start": "178379",
    "end": "186180"
  },
  {
    "text": "this that kind of led to why Tom and I were even allowed to kind of do that keynote to talk about in part continuous",
    "start": "186180",
    "end": "193680"
  },
  {
    "text": "profiling that entire keynote was about more broadly what does the future hold for observability and continuous",
    "start": "193680",
    "end": "199920"
  },
  {
    "text": "profiling was one of the three predictions that we were making in that keynote but really what led to that",
    "start": "199920",
    "end": "206580"
  },
  {
    "text": "point in 2019 was kind of ultimately the beginning of all this is me joining core",
    "start": "206580",
    "end": "212700"
  },
  {
    "text": "OS in 2016. and at that point for those who maybe don't know at this point it's",
    "start": "212700",
    "end": "218760"
  },
  {
    "text": "history and we've got always new generations of Engineers joining so core OS was kind of one of the first",
    "start": "218760",
    "end": "224940"
  },
  {
    "text": "kubernetes companies and even before KRS went into the kubernetes space we",
    "start": "224940",
    "end": "230640"
  },
  {
    "text": "started with this Mantra of always automatically upgrading server software",
    "start": "230640",
    "end": "235680"
  },
  {
    "text": "because coros's mission was to secure the internet and the biggest impact we",
    "start": "235680",
    "end": "241200"
  },
  {
    "text": "felt we were going to have was by automating updates because it wasn't that security problems weren't being",
    "start": "241200",
    "end": "247379"
  },
  {
    "text": "fixed is that people aren't updating their software and this is still a problem today and the way I came in was",
    "start": "247379",
    "end": "255180"
  },
  {
    "text": "just after Pros did the kubernetes pivot we kind of realized that all of this",
    "start": "255180",
    "end": "260220"
  },
  {
    "text": "automatic updating is really nice but if the software isn't actually doing what it's supposed to be doing kind of before",
    "start": "260220",
    "end": "267180"
  },
  {
    "text": "during and after upgrades then automatically upgrading isn't all that useful either when I came in everything",
    "start": "267180",
    "end": "273540"
  },
  {
    "text": "in my responsibility was all about monitoring with Prometheus so I came in",
    "start": "273540",
    "end": "278880"
  },
  {
    "text": "and kind of started creating a Prometheus setup for our product and that ultimately evolved into what is",
    "start": "278880",
    "end": "285660"
  },
  {
    "text": "today known as the Prometheus operator kind of a glimpse of History also this was one of the two very first operators",
    "start": "285660",
    "end": "292560"
  },
  {
    "text": "ever created right today we have hundreds and maybe thousands of operators out there right this was",
    "start": "292560",
    "end": "299040"
  },
  {
    "text": "genuinely one of the two operators that were part of the original announcement and yeah I became a Prometheus",
    "start": "299040",
    "end": "306540"
  },
  {
    "text": "maintainer and through that ultimately also became like you said technical lead",
    "start": "306540",
    "end": "312060"
  },
  {
    "text": "for instrumentation in kubernetes because kind of everything in that intersection was what I was working on",
    "start": "312060",
    "end": "317220"
  },
  {
    "text": "right to this day I'm still maintainer for the kubernetes Integrations in Prometheus and relatively recently I",
    "start": "317220",
    "end": "324300"
  },
  {
    "text": "actually stepped down from my position as Tech lead in kubernetes just to have",
    "start": "324300",
    "end": "329400"
  },
  {
    "text": "some more time to spend on some other things but ultimately all of this and then after the Paras acquisition in 2018",
    "start": "329400",
    "end": "336080"
  },
  {
    "text": "I stuck around at Red Hat Red Hat acquired chorus and like you said I kind",
    "start": "336080",
    "end": "341820"
  },
  {
    "text": "of became architect for all things observability and in 2018 was when I",
    "start": "341820",
    "end": "347639"
  },
  {
    "text": "read the this paper that Google had published about how they are profiling",
    "start": "347639",
    "end": "353160"
  },
  {
    "text": "all of the data centers all the time and this was super interesting to me for kind of two reasons right one I wanted",
    "start": "353160",
    "end": "360300"
  },
  {
    "text": "all the capabilities that they were talking about in this white paper they were talking about how they always have",
    "start": "360300",
    "end": "365820"
  },
  {
    "text": "the performance data available when they need it they never need to kind of manually profile their code and they're",
    "start": "365820",
    "end": "372539"
  },
  {
    "text": "able to cut down on infrastructure costs by multiple percentage points every quarter consistently right all of these",
    "start": "372539",
    "end": "378960"
  },
  {
    "text": "were extremely exciting to me because as someone who works in infrastructure my",
    "start": "378960",
    "end": "384120"
  },
  {
    "text": "customers have that unrealistic expectation that everything uses zero",
    "start": "384120",
    "end": "389520"
  },
  {
    "text": "resources and has zero latency anyone who works in infrastructure knows this this is kind of the same expectation we",
    "start": "389520",
    "end": "395759"
  },
  {
    "text": "have towards databases it's the same expectation we have towards kubernetes and Prometheus themselves and so all of",
    "start": "395759",
    "end": "402479"
  },
  {
    "text": "this and then my kind of experience with Prometheus and the Prometheus storage and all of these things I felt like I",
    "start": "402479",
    "end": "409380"
  },
  {
    "text": "was in the position to actually create something and that is ultimately what led to that keynote I put together this",
    "start": "409380",
    "end": "415860"
  },
  {
    "text": "really barely compiling proof of concept put it on GitHub and Brian layouts was",
    "start": "415860",
    "end": "421319"
  },
  {
    "text": "super super nice to invite me to speak in that keynote on that topic so yeah",
    "start": "421319",
    "end": "426720"
  },
  {
    "text": "and then ultimately like I said through that keynote I think I realized that there's something bigger here right The",
    "start": "426720",
    "end": "433500"
  },
  {
    "text": "Continuous profiling Market really wasn't established at all there was not a single product on the market for this",
    "start": "433500",
    "end": "439139"
  },
  {
    "text": "but all the hyper scalers were doing it Google was doing it Facebook was doing it Netflix has tools similar to this so",
    "start": "439139",
    "end": "447360"
  },
  {
    "text": "this makes sense and so end of 2020 I think I it was kind of similar to a lot",
    "start": "447360",
    "end": "454199"
  },
  {
    "text": "of people where you know it's been six months into covet people feel relatively",
    "start": "454199",
    "end": "459259"
  },
  {
    "text": "uninspired and I felt like there was this opportunity right and I felt like it was now or never and then that's when",
    "start": "459259",
    "end": "465599"
  },
  {
    "text": "I decided to start the company all around this that's awesome so let's back up a minute and talk about continuous",
    "start": "465599",
    "end": "471360"
  },
  {
    "text": "profiling I gave that little example in the beginning of having like a memory link what is continuous profiling mean",
    "start": "471360",
    "end": "477000"
  },
  {
    "text": "in practice Yeah so continuous profiling like you said earlier just the profiling",
    "start": "477000",
    "end": "482039"
  },
  {
    "start": "478000",
    "end": "554000"
  },
  {
    "text": "part right is as old as kind of software engineering gets we always needed to understand where our resources are being",
    "start": "482039",
    "end": "488160"
  },
  {
    "text": "spent when profiling allows us to do this kind of down to the line number and",
    "start": "488160",
    "end": "493319"
  },
  {
    "text": "we can associate where is my CPU time being spent where are my allocations happening where's memory being held and",
    "start": "493319",
    "end": "499860"
  },
  {
    "text": "we can do this down to the line number but historically profiling was always associated with having a lot of overhead",
    "start": "499860",
    "end": "507539"
  },
  {
    "text": "so that was kind of what prevented us from doing this in production all the time and the way that the kind of",
    "start": "507539",
    "end": "515039"
  },
  {
    "text": "hyperscalers solved this is in part by actually building these collection",
    "start": "515039",
    "end": "520860"
  },
  {
    "text": "mechanisms into their operating systems and I don't know about you but I don't know a whole lot of companies who",
    "start": "520860",
    "end": "526680"
  },
  {
    "text": "maintain their own operating systems to be able to do something like that and so it was kind of also just doing like me",
    "start": "526680",
    "end": "534660"
  },
  {
    "text": "looking at this problem at the right time because ebpf was just starting to kind of gain momentum and ebpf is",
    "start": "534660",
    "end": "541320"
  },
  {
    "text": "exactly the technology that it allows us to kind of replicate what the hyperscalers were doing ourselves and",
    "start": "541320",
    "end": "548160"
  },
  {
    "text": "you know not having to maintain custom operating systems to do this kind of thing so continuous profiling essentially is",
    "start": "548160",
    "end": "555600"
  },
  {
    "start": "554000",
    "end": "618000"
  },
  {
    "text": "that we always profile in production all the time throughout time right our",
    "start": "555600",
    "end": "561120"
  },
  {
    "text": "entire data center every single process and like I said there are two main contributors why we can do this in",
    "start": "561120",
    "end": "567420"
  },
  {
    "text": "production one ebpf just kind of allows us to grab exactly the data that we need",
    "start": "567420",
    "end": "572820"
  },
  {
    "text": "and exactly the format that we need so we basically copy a bunch of memory addresses from the kernel into user",
    "start": "572820",
    "end": "579600"
  },
  {
    "text": "space and that's it so this is super super lightweight in terms of what even needs to be done and then the other",
    "start": "579600",
    "end": "585779"
  },
  {
    "text": "aspect of it is because we're doing this all the time we can do profiling at a",
    "start": "585779",
    "end": "591360"
  },
  {
    "text": "relatively low frequency so the way you can kind of imagine how profilers work",
    "start": "591360",
    "end": "597300"
  },
  {
    "text": "is that they look at the quote-unquote's current stack Trace let's say 100 times",
    "start": "597300",
    "end": "602880"
  },
  {
    "text": "per second and based on the stacks that we collect whenever we do this we can",
    "start": "602880",
    "end": "608700"
  },
  {
    "text": "build statistics of in which functions of my program is time being spent so",
    "start": "608700",
    "end": "614700"
  },
  {
    "text": "that's essentially how CPU profilers work and if you do this at a relatively low frequency let's say 100 times per",
    "start": "614700",
    "end": "621720"
  },
  {
    "start": "618000",
    "end": "708000"
  },
  {
    "text": "second then the granularity is not extremely high but because we're always",
    "start": "621720",
    "end": "627120"
  },
  {
    "text": "doing this throughout all of time we're actually statistically still getting all",
    "start": "627120",
    "end": "632220"
  },
  {
    "text": "significant data and so there's actually a little bit more to continuous profiling than just doing profiling all",
    "start": "632220",
    "end": "638940"
  },
  {
    "text": "the time right it all of a sudden allows us to do completely new things that we",
    "start": "638940",
    "end": "644040"
  },
  {
    "text": "couldn't do before like CPU profiles all of a sudden we don't have just a glimpse",
    "start": "644040",
    "end": "649260"
  },
  {
    "text": "of like a 10 second period where we happen to catch the process recording it throughout all of time and we can look",
    "start": "649260",
    "end": "656160"
  },
  {
    "text": "at all of the CPU time in a report where we look at the entire processes lifetime",
    "start": "656160",
    "end": "662040"
  },
  {
    "text": "for example right and this is much more representative also than the 10 seconds",
    "start": "662040",
    "end": "667740"
  },
  {
    "text": "that we happen to look at right the the users happen to do this one thing that",
    "start": "667740",
    "end": "672959"
  },
  {
    "text": "we're interested in in those 10 seconds right or you know software is kind of",
    "start": "672959",
    "end": "678240"
  },
  {
    "text": "unpredictable and that's why we need monitoring and observability in place so that we can reason about what has",
    "start": "678240",
    "end": "684540"
  },
  {
    "text": "happened in the past and continuous profiling is essentially another aspect of observability it shines another light",
    "start": "684540",
    "end": "691800"
  },
  {
    "text": "on our running applications so I mean nothing's for free right you say it's lightweight but what is it actually cost",
    "start": "691800",
    "end": "699600"
  },
  {
    "text": "to run continuous profiling in production with the tool we all haven't talked about parka yet but using say",
    "start": "699600",
    "end": "705180"
  },
  {
    "text": "Parker what does it actually cost to run it in production the cost is essentially we find it's somewhere around one to",
    "start": "705180",
    "end": "713040"
  },
  {
    "start": "708000",
    "end": "773000"
  },
  {
    "text": "three percent in overhead it can kind of depend on you can tweak the sampling",
    "start": "713040",
    "end": "718320"
  },
  {
    "text": "ratio a little bit and it depends a little bit on the workload but most setups we find is around the one percent",
    "start": "718320",
    "end": "723600"
  },
  {
    "text": "mark But for that investment you get a profile of not just your machine right",
    "start": "723600",
    "end": "729660"
  },
  {
    "text": "like all of your infrastructure that this is running all of you different structure exactly so talk a little bit",
    "start": "729660",
    "end": "735839"
  },
  {
    "text": "more about that so like we can run Irv on machine and get some idea of like an individual Linux kernel of what's",
    "start": "735839",
    "end": "741959"
  },
  {
    "text": "happening but how does this continuous profiling work for like a cloud native ecosystem the open source project that",
    "start": "741959",
    "end": "747600"
  },
  {
    "text": "we created called parka parca it kind of ships with two components the agent this",
    "start": "747600",
    "end": "754680"
  },
  {
    "text": "is the thing in let's say a kubernetes environment you Deploy on every node using a Daemon set and then there's a",
    "start": "754680",
    "end": "761760"
  },
  {
    "text": "central server where all of the agents send the sampling data that they collect",
    "start": "761760",
    "end": "767579"
  },
  {
    "text": "to and then the server is the thing that you can use to kind of query and analyze this data yeah so that's kind of the",
    "start": "767579",
    "end": "774360"
  },
  {
    "start": "773000",
    "end": "871000"
  },
  {
    "text": "setup and because of our history we're super close to the Prometheus ecosystem super close to the kubernetes ecosystem",
    "start": "774360",
    "end": "781260"
  },
  {
    "text": "so we very intentionally engineered this towards kubernetes environments as well that doesn't mean that it doesn't work",
    "start": "781260",
    "end": "787200"
  },
  {
    "text": "in other environments but it you know the integration is particularly good in kubernetes environments okay so as usual",
    "start": "787200",
    "end": "792839"
  },
  {
    "text": "the damage that you deploy out to nodes and then you have visibility of then like everything that's happening in that",
    "start": "792839",
    "end": "800040"
  },
  {
    "text": "node like what about the pods that are running in there and the containers that are within the pods do you have visibility into what's happening there",
    "start": "800040",
    "end": "806880"
  },
  {
    "text": "that's right I can talk a little bit about how it works today because we're slightly changing it but this is not",
    "start": "806880",
    "end": "813360"
  },
  {
    "text": "ready but I can talk about that already because I think it's pretty exciting the way it works today is that we discover",
    "start": "813360",
    "end": "819899"
  },
  {
    "text": "all of the containers on a host and then automatically profile all of those containers at the networking level or at",
    "start": "819899",
    "end": "828360"
  },
  {
    "text": "the kernel level inside the container I guess both so we look at each individual",
    "start": "828360",
    "end": "833700"
  },
  {
    "text": "process in all containers and so we do see the user space stack so you know the",
    "start": "833700",
    "end": "839820"
  },
  {
    "text": "code that we typically write but you also see the kernel space stack actually which is something that's pretty unique",
    "start": "839820",
    "end": "846300"
  },
  {
    "text": "with parka actually with a lot of profilers you only get to see the CPU",
    "start": "846300",
    "end": "851579"
  },
  {
    "text": "time that's spent in your user space code so you only see I don't know you're reading a file right or you're",
    "start": "851579",
    "end": "857940"
  },
  {
    "text": "allocating some memory but you're not seeing that this is causing a page fault in the kernel or something like that",
    "start": "857940",
    "end": "864300"
  },
  {
    "text": "right this can be extremely valuable information in order to improve performance of your software but to get",
    "start": "864300",
    "end": "871500"
  },
  {
    "start": "871000",
    "end": "1014000"
  },
  {
    "text": "back to that in the kubernetes case we label all of the data that we collect in",
    "start": "871500",
    "end": "876899"
  },
  {
    "text": "a very similar way as you're probably used to from Prometheus there's the connection to our past again where we",
    "start": "876899",
    "end": "883800"
  },
  {
    "text": "kind of add labels for the namespace the Pod the container all of these things so",
    "start": "883800",
    "end": "888839"
  },
  {
    "text": "that you can kind of slice and dice the data however it's useful to you right if",
    "start": "888839",
    "end": "893880"
  },
  {
    "text": "you already know there's this one particular workload that you want to optimize you kind of just filter all of",
    "start": "893880",
    "end": "899519"
  },
  {
    "text": "the data by this one let's say container label right I don't know my web app",
    "start": "899519",
    "end": "904680"
  },
  {
    "text": "right and then you'll only see the CPU time spent by your web app and you can kind of dive deeper into specifically",
    "start": "904680",
    "end": "911579"
  },
  {
    "text": "that but one one extremely powerful thing and this is one of those things that continues profiling is required in",
    "start": "911579",
    "end": "918839"
  },
  {
    "text": "order to do something like this because we're continuously profiling our entire infrastructure we can actually merge all",
    "start": "918839",
    "end": "926760"
  },
  {
    "text": "of this data into one report right and we get a single icicle graph or flame",
    "start": "926760",
    "end": "931920"
  },
  {
    "text": "graph for our entire infrastructure and this is super powerful because we're not",
    "start": "931920",
    "end": "938339"
  },
  {
    "text": "just looking at a single process we're looking at the CPU time spent in our entire infrastructure and this often",
    "start": "938339",
    "end": "945839"
  },
  {
    "text": "shows really really surprising users of CPU time or allocations in the",
    "start": "945839",
    "end": "952740"
  },
  {
    "text": "infrastructure because it's also you know often maybe we don't recognize that there's only one instance of this type",
    "start": "952740",
    "end": "959820"
  },
  {
    "text": "of application right but we have hundreds of instance of this other one and we you know optimize this other one",
    "start": "959820",
    "end": "965459"
  },
  {
    "text": "that is kind of insignificant in total or there's a single line of code that is",
    "start": "965459",
    "end": "971820"
  },
  {
    "text": "poorly allocating memory we keep seeing these things over and over that it's very simple things where maybe we didn't",
    "start": "971820",
    "end": "979079"
  },
  {
    "text": "know because we shouldn't do premature optimizations right we should base performance improvements on profiling",
    "start": "979079",
    "end": "985860"
  },
  {
    "text": "data and so we see this often that there are pretty let's say naive things that we can improve that really only need",
    "start": "985860",
    "end": "993600"
  },
  {
    "text": "this data and historically it was pretty difficult to get this data from production environments and this is kind",
    "start": "993600",
    "end": "1000079"
  },
  {
    "text": "of what continuous profiling is intended to kind of democratize yeah it's awesome",
    "start": "1000079",
    "end": "1005600"
  },
  {
    "text": "that's awesome what kind of use cases and stories are out there of folks that are using parka continuous profiling",
    "start": "1005600",
    "end": "1012139"
  },
  {
    "text": "what are you hearing from folks that have implemented I think we're seeing three main use cases so the first one is",
    "start": "1012139",
    "end": "1018860"
  },
  {
    "start": "1014000",
    "end": "1144000"
  },
  {
    "text": "one that I sort of already touched on and this is the one that the Google white paper also mentioned which is",
    "start": "1018860",
    "end": "1024860"
  },
  {
    "text": "purely it's kind of a data problem if you don't know where CPU time is being spent it's really hard to do something",
    "start": "1024860",
    "end": "1032600"
  },
  {
    "text": "useful and effective about it right and all of a sudden when you have this data we see that most organizations can",
    "start": "1032600",
    "end": "1040280"
  },
  {
    "text": "easily cut down their CPU Time by 10 20 30 in the most extreme case we've seen",
    "start": "1040280",
    "end": "1046459"
  },
  {
    "text": "55 by a single incorrectly configured application it wasn't even that you know",
    "start": "1046459",
    "end": "1052760"
  },
  {
    "text": "the code was wrong it was that this was poorly configured and the user just didn't know that 55 of the sapu time was",
    "start": "1052760",
    "end": "1060320"
  },
  {
    "text": "being spent in this thing yeah it probably was perfectly configured where it was tested with a profiler in a lower",
    "start": "1060320",
    "end": "1066260"
  },
  {
    "text": "environment right exactly exactly yeah so that's kind of the number one use case everybody wants to save money right",
    "start": "1066260",
    "end": "1073100"
  },
  {
    "text": "especially now you know with the economic situation companies are even more trying to look at optimizing their",
    "start": "1073100",
    "end": "1080059"
  },
  {
    "text": "Cloud builds so that's kind of cost savings the second one we find is",
    "start": "1080059",
    "end": "1085580"
  },
  {
    "text": "actually an even bigger motivator to use this type of Technology it's companies",
    "start": "1085580",
    "end": "1090980"
  },
  {
    "text": "that have some sort of competitive advantage or you know business Advantage by having a more performance system and",
    "start": "1090980",
    "end": "1098900"
  },
  {
    "text": "the Really classic one here are e-commerce companies like there's lots of literature around this but the faster",
    "start": "1098900",
    "end": "1105260"
  },
  {
    "text": "a website is for example the more likely we as humans are going to purchase",
    "start": "1105260",
    "end": "1110780"
  },
  {
    "text": "something on that website and so for e-commerce style companies is actually an incentive to have faster software",
    "start": "1110780",
    "end": "1118880"
  },
  {
    "text": "because it means that they will make more money right making more money tends to be even a higher motivator for",
    "start": "1118880",
    "end": "1125900"
  },
  {
    "text": "companies to do something than cost savings but you know there are more simple cases for this as well",
    "start": "1125900",
    "end": "1131900"
  },
  {
    "text": "infrastructure companies or the kind of classic performance type companies are high frequency trading companies right",
    "start": "1131900",
    "end": "1137900"
  },
  {
    "text": "where every CPU cycle that you save you have a competitive advantage to your",
    "start": "1137900",
    "end": "1143000"
  },
  {
    "text": "competitors I think you can broadly talk about this as just performance improvements right but that's kind of",
    "start": "1143000",
    "end": "1149960"
  },
  {
    "start": "1144000",
    "end": "1331000"
  },
  {
    "text": "the motivation that we're seeing where the motivation for this is coming from and the third one is sort of we",
    "start": "1149960",
    "end": "1155780"
  },
  {
    "text": "categorize it as incident response essentially like I was talking about earlier because of how CPU profiling",
    "start": "1155780",
    "end": "1163520"
  },
  {
    "text": "works we essentially look a hundred times let's say per second at what is the current function being executed well",
    "start": "1163520",
    "end": "1170000"
  },
  {
    "text": "this also tells us in a way something that is extremely unique to continuous",
    "start": "1170000",
    "end": "1176059"
  },
  {
    "text": "profiling which is often when we look at a past incident we're asking ourselves what was my program I'm doing at this",
    "start": "1176059",
    "end": "1182840"
  },
  {
    "text": "point in time right like maybe there's a CPU Spike maybe there's a latency Spike or you know some other indicator that",
    "start": "1182840",
    "end": "1189500"
  },
  {
    "text": "something funky was going on and CPU profiling data actually tells us what was the code that was being executed",
    "start": "1189500",
    "end": "1195980"
  },
  {
    "text": "right it's sampled but it's still significant because the code that's executed or spending more time",
    "start": "1195980",
    "end": "1202160"
  },
  {
    "text": "statistically will show up more significantly so it's a super unique tool and we've built some specific",
    "start": "1202160",
    "end": "1208340"
  },
  {
    "text": "features actually into parka where you can actually select two points in time",
    "start": "1208340",
    "end": "1213620"
  },
  {
    "text": "or even two time ranges over time and say tell me what was the difference",
    "start": "1213620",
    "end": "1218900"
  },
  {
    "text": "between these two points in time and this is extremely powerful you talked about memory leaks earlier right and",
    "start": "1218900",
    "end": "1226400"
  },
  {
    "text": "with memory leaks it was so amazing to see the first time we got this to work you kind of just see the memory growing",
    "start": "1226400",
    "end": "1232100"
  },
  {
    "text": "over time right and you pull up the compare View and you select a low point",
    "start": "1232100",
    "end": "1237140"
  },
  {
    "text": "and you select a high point and it tells you exactly the difference and where more memories has been allocated right",
    "start": "1237140",
    "end": "1243260"
  },
  {
    "text": "and it's just you can see it at a glance before it was like you go and maybe you",
    "start": "1243260",
    "end": "1249020"
  },
  {
    "text": "managed to hit your application at the right time to grab a memory profile right but here it's really just a click",
    "start": "1249020",
    "end": "1255559"
  },
  {
    "text": "away a search away and that's extremely powerful when you say you can select two points",
    "start": "1255559",
    "end": "1261440"
  },
  {
    "text": "is there a tool that you're talking or is this just in like grafana that you're actually selecting you talked about the",
    "start": "1261440",
    "end": "1266780"
  },
  {
    "text": "agent and the server where are you selecting this set the server actually has its own storage so I was talking",
    "start": "1266780",
    "end": "1273740"
  },
  {
    "text": "about earlier that the parca agent is kind of the thing that just collects data on each of your kubernetes nodes",
    "start": "1273740",
    "end": "1280820"
  },
  {
    "text": "let's say and then essentially you deploy a parka server and this has its",
    "start": "1280820",
    "end": "1286880"
  },
  {
    "text": "own database and everything and so that is also the thing that where we ship a",
    "start": "1286880",
    "end": "1292460"
  },
  {
    "text": "UI with so the parka server is essentially the equivalent to the Prometheus world the Prometheus right",
    "start": "1292460",
    "end": "1299780"
  },
  {
    "text": "it's this really really simple to run statically linked binary that has its",
    "start": "1299780",
    "end": "1305120"
  },
  {
    "text": "own database everything's built in you just launch the binary and everything's there so it ships with the UI and that's",
    "start": "1305120",
    "end": "1311419"
  },
  {
    "text": "the UI that I was talking about and so parka itself is both the agent the server that's right parka is the",
    "start": "1311419",
    "end": "1317960"
  },
  {
    "text": "umbrella project and then we have the parka server and the parka agent as part of that and both are open source both",
    "start": "1317960",
    "end": "1324020"
  },
  {
    "text": "are open source awesome I know you did some interesting things in that database that you're talking you want to talk a",
    "start": "1324020",
    "end": "1330080"
  },
  {
    "text": "bit about your database absolutely we tried for a really long time not to build a database",
    "start": "1330080",
    "end": "1335799"
  },
  {
    "start": "1331000",
    "end": "1508000"
  },
  {
    "text": "like every observability company but it turns out you know we wanted to be able",
    "start": "1335799",
    "end": "1341179"
  },
  {
    "text": "to deliver exactly that prometheus-esque experience where we label the data and",
    "start": "1341179",
    "end": "1347780"
  },
  {
    "text": "you can add arbitrary infrastructure labels to your data however you organize your infrastructure we don't want to",
    "start": "1347780",
    "end": "1354620"
  },
  {
    "text": "force you into a specific labeling scheme or whatever right it's your infrastructure you should be able to",
    "start": "1354620",
    "end": "1360860"
  },
  {
    "text": "decide how you organize your infrastructure and so the thing that we found that no other database allows us",
    "start": "1360860",
    "end": "1368539"
  },
  {
    "text": "to do is to essentially dynamically create new columns when we see a label",
    "start": "1368539",
    "end": "1376280"
  },
  {
    "text": "for the first time the database that we created is a column in our database and",
    "start": "1376280",
    "end": "1381500"
  },
  {
    "text": "so the difference to the classic relational databases like MySQL or",
    "start": "1381500",
    "end": "1386960"
  },
  {
    "text": "postgres they're row based so that means the physical unit of how data is being",
    "start": "1386960",
    "end": "1393140"
  },
  {
    "text": "stored is all the values of a single row are kind of physically co-located to",
    "start": "1393140",
    "end": "1399380"
  },
  {
    "text": "each other and a columnar database that's different actually all the values of all rows of a column are all stored",
    "start": "1399380",
    "end": "1407539"
  },
  {
    "text": "consecutively and this is extremely powerful for analytical type workloads",
    "start": "1407539",
    "end": "1413059"
  },
  {
    "text": "because you can load Only The Columns that you need and because they're all physically co-located you can scan and",
    "start": "1413059",
    "end": "1420799"
  },
  {
    "text": "process them extremely efficiently and there's a lot of things that you can then do to make that processing really",
    "start": "1420799",
    "end": "1426980"
  },
  {
    "text": "really efficient like vectorized instructions and stuff like that but all the columnar databases that we found out",
    "start": "1426980",
    "end": "1434240"
  },
  {
    "text": "there didn't allow us to dynamically create these new columns when we see a new label and so we tried things out a",
    "start": "1434240",
    "end": "1441860"
  },
  {
    "text": "little bit but ultimately we just decided we've got to build something new because everything else wasn't going to",
    "start": "1441860",
    "end": "1447140"
  },
  {
    "text": "cut it the one database that sort of comes close to what we imagined is",
    "start": "1447140",
    "end": "1453640"
  },
  {
    "text": "influxdb's new database called influxdb iox we did talk to the CTO of influxdb",
    "start": "1453640",
    "end": "1460760"
  },
  {
    "text": "and several engineers at influxdb because we didn't want to build a database but they were extremely nice",
    "start": "1460760",
    "end": "1468200"
  },
  {
    "text": "and shared all of their experiences building this database but at the end of the day basically we came to the",
    "start": "1468200",
    "end": "1473419"
  },
  {
    "text": "conclusion we weren't going to be able to use their database in time so we needed to build something ourselves so",
    "start": "1473419",
    "end": "1479600"
  },
  {
    "text": "after a couple of months of development we open sourced frostdb actually",
    "start": "1479600",
    "end": "1485179"
  },
  {
    "text": "originally it was called Arctic DB but because of naming difficulties someone actually held the trademark on that name",
    "start": "1485179",
    "end": "1492260"
  },
  {
    "text": "we needed to rename name it so now it's frosty B for good one of the true hard",
    "start": "1492260",
    "end": "1497419"
  },
  {
    "text": "things in software naming something right exactly so earlier you said the",
    "start": "1497419",
    "end": "1502640"
  },
  {
    "text": "way parka works today versus the way it's going to work I'm assuming that's some of the exciting new stuff what is",
    "start": "1502640",
    "end": "1507980"
  },
  {
    "text": "that all about yeah so like I was saying earlier the way that we collect data today is we discover all of the",
    "start": "1507980",
    "end": "1515900"
  },
  {
    "start": "1508000",
    "end": "1603000"
  },
  {
    "text": "containers on a host in the kubernetes cluster and we start to profile those the problem with that is that's actually",
    "start": "1515900",
    "end": "1523220"
  },
  {
    "text": "not the entire picture of a host there are more things running on a machine",
    "start": "1523220",
    "end": "1528919"
  },
  {
    "text": "than just the kubernetes containers at the very least you've got to have a kubernetes cubelet right but probably",
    "start": "1528919",
    "end": "1535880"
  },
  {
    "text": "you'll have a bunch of other demons I don't know maybe crony D for like time synchronization system D all of these",
    "start": "1535880",
    "end": "1543260"
  },
  {
    "text": "things they probably run on your machine as well they probably also use some CPU",
    "start": "1543260",
    "end": "1548360"
  },
  {
    "text": "and so we're actually changing this architecture to profile truly the the",
    "start": "1548360",
    "end": "1553580"
  },
  {
    "text": "entire host and it kind of turns around where we'll still attach the same kind of metadata as we're doing that today",
    "start": "1553580",
    "end": "1560380"
  },
  {
    "text": "but as opposed to discovering containers using that metadata essentially we're",
    "start": "1560380",
    "end": "1566779"
  },
  {
    "text": "just recording CPU time from all processes and then once we've done that we then discover the metadata from",
    "start": "1566779",
    "end": "1573559"
  },
  {
    "text": "kubernetes using the process ID basically so ultimately it'll be everything we have today and more",
    "start": "1573559",
    "end": "1580220"
  },
  {
    "text": "visibility is that different is it going to be installed directly as an agent on the",
    "start": "1580220",
    "end": "1585980"
  },
  {
    "text": "host and not a Daemon set into the cluster will the architecture change the architecture will be exactly the same",
    "start": "1585980",
    "end": "1591440"
  },
  {
    "text": "it's basically just an internal code change tell me how's the community was it October November of 2021 so been",
    "start": "1591440",
    "end": "1599419"
  },
  {
    "text": "about a year now what should Community look like how's that growing it's been growing like crazy actually it's been",
    "start": "1599419",
    "end": "1605240"
  },
  {
    "start": "1603000",
    "end": "1685000"
  },
  {
    "text": "really cool to see companies using this technology companies you know actually benefiting in the way that we set out",
    "start": "1605240",
    "end": "1612500"
  },
  {
    "text": "for the project to do that right like sometimes that doesn't happen right sometimes you're just wrong with your",
    "start": "1612500",
    "end": "1617600"
  },
  {
    "text": "hypothesis so it's super cool to see companies picking up this technology and kind of just running with it and the",
    "start": "1617600",
    "end": "1624679"
  },
  {
    "text": "most exciting thing is when people do something that you didn't necessarily anticipate one of the things that we did",
    "start": "1624679",
    "end": "1631220"
  },
  {
    "text": "really intentionally with parka is that everything's API first and everything's",
    "start": "1631220",
    "end": "1636860"
  },
  {
    "text": "really API driven so we try to keep our UI as simple as as possible so that",
    "start": "1636860",
    "end": "1642980"
  },
  {
    "text": "alternative things can be built around it right we want to build a community so that people can build CI tooling around",
    "start": "1642980",
    "end": "1649940"
  },
  {
    "text": "this for example right like maybe you want to compare previous benchmarking data with this new benchmarking data the",
    "start": "1649940",
    "end": "1657200"
  },
  {
    "text": "world is your oyster is kind of the idea and so we're actually talking with a couple of folks at grafana to build a",
    "start": "1657200",
    "end": "1664039"
  },
  {
    "text": "grafana plugin so that actually all of this stuff can be integrated into your",
    "start": "1664039",
    "end": "1669380"
  },
  {
    "text": "probably existing observability tooling right so that's super exciting I'm",
    "start": "1669380",
    "end": "1674960"
  },
  {
    "text": "curious about if you have a tool at the server so that you can do these correlations you also have like an",
    "start": "1674960",
    "end": "1680179"
  },
  {
    "text": "existing observability stack that has all of this other data that's in it how do you bring them together yeah so this",
    "start": "1680179",
    "end": "1686179"
  },
  {
    "text": "is another thing where we were really intentional about making this complement",
    "start": "1686179",
    "end": "1692600"
  },
  {
    "text": "really well together with an existing Prometheus setup right basically the data model is identical to Prometheus",
    "start": "1692600",
    "end": "1699500"
  },
  {
    "text": "and so if you label your data authentically which because the configurations are exactly the same to",
    "start": "1699500",
    "end": "1706039"
  },
  {
    "text": "the point where you know we didn't just design them in a similar way we're actually literally reusing Prometheus",
    "start": "1706039",
    "end": "1712400"
  },
  {
    "text": "code for configuration so for most setups you can copy and paste a lot of",
    "start": "1712400",
    "end": "1717440"
  },
  {
    "text": "the configuration but yeah it's absolutely a complementary thing right like I said earlier continuous profiling",
    "start": "1717440",
    "end": "1724700"
  },
  {
    "text": "shines a different light on another aspect of your running applications it doesn't replace metrics it doesn't",
    "start": "1724700",
    "end": "1731059"
  },
  {
    "text": "replace logs it doesn't replace tracing but the kind of detail that you get from",
    "start": "1731059",
    "end": "1737539"
  },
  {
    "text": "continuous profiling you get from none of the other observability signals so it's absolutely complementary and you",
    "start": "1737539",
    "end": "1743840"
  },
  {
    "text": "should be using all of them but exactly that's also why we're excited about grafana integration because that",
    "start": "1743840",
    "end": "1751159"
  },
  {
    "text": "actually you know allows us to weave it into what people probably already have set up yeah it's really cool it's really",
    "start": "1751159",
    "end": "1758720"
  },
  {
    "text": "cool so what's next for Polar signals yeah so polar signals we're actually working I guess this is kind of",
    "start": "1758720",
    "end": "1764360"
  },
  {
    "text": "unsurprising we're working on a cloud product for all of this so that you don't have to run the podcast server at",
    "start": "1764360",
    "end": "1770840"
  },
  {
    "text": "all and yeah we've been working on that really hard I think we'll get there by the end of the year that people people",
    "start": "1770840",
    "end": "1777559"
  },
  {
    "text": "can start to use that the idea is there essentially that you don't have to run the parka server at all anymore and the",
    "start": "1777559",
    "end": "1784340"
  },
  {
    "text": "only thing you do is deploy the Parker agent in your infrastructure and it'll all just kind of magically happen by",
    "start": "1784340",
    "end": "1790880"
  },
  {
    "text": "itself awesome well Frederick thank you for joining us on the infoqueue podcast thanks for having me",
    "start": "1790880",
    "end": "1796880"
  },
  {
    "text": "hey folks our upcoming International qcon software conferences are starting to take shape we are back in San",
    "start": "1796880",
    "end": "1803000"
  },
  {
    "text": "Francisco this October 24th through 28th online November 29th through December 9th and in London in 2023 from March",
    "start": "1803000",
    "end": "1811159"
  },
  {
    "text": "27th to 29th at qcon you'll find practical inspiration of best practices on how to implement emerging software",
    "start": "1811159",
    "end": "1818600"
  },
  {
    "text": "Trends directly from senior software developers at innovator early adopter companies they'll help you adopt the",
    "start": "1818600",
    "end": "1825140"
  },
  {
    "text": "right patterns and practices moving forward learn more at qconferences.com we'll see you there",
    "start": "1825140",
    "end": "1832220"
  },
  {
    "text": "foreign [Music]",
    "start": "1832220",
    "end": "1842630"
  }
]
[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "hello and thank you for joining us for another episode of the infocube podcast today I'm speaking with Pamela Fox a cloud advocate in Python at Microsoft",
    "start": "4880",
    "end": "11599"
  },
  {
    "text": "Pamela is one of the maintainers on several chat GPT samples which is what we're going to be discussing today it seems like every company is looking for",
    "start": "11599",
    "end": "17760"
  },
  {
    "text": "ways to incorporate the power of large language models into their existing systems and if you're someone that's been asked to do that or maybe you're",
    "start": "17760",
    "end": "24199"
  },
  {
    "text": "just curious what it takes to get started I hope today's conversation will be helpful Pamela welcome to the infoq podcast thank you for having me I gave a",
    "start": "24199",
    "end": "32119"
  },
  {
    "start": "30000",
    "end": "140000"
  },
  {
    "text": "brief introduction I just said you're a cloud advocate in Python at Microsoft but tell us more what does that role",
    "start": "32119",
    "end": "37160"
  },
  {
    "text": "entail and what services do you provide to the community yeah it's a great question so I think of my role as",
    "start": "37160",
    "end": "43800"
  },
  {
    "text": "helping python developers to be successful with Microsoft products specifically AER products but also vs",
    "start": "43800",
    "end": "51000"
  },
  {
    "text": "code and GitHub code spaces co-pilot that sort of thing so as it turns out",
    "start": "51000",
    "end": "56600"
  },
  {
    "text": "there are a lot of Microsoft products out there and there's many way that python developers can use Microsoft products so I even have a colleague",
    "start": "56600",
    "end": "62879"
  },
  {
    "text": "that's you know working on the whole Python and Excel feature that's recently come out so all of that is you know",
    "start": "62879",
    "end": "69320"
  },
  {
    "text": "something that our team works on so a lot of what we do is actually just deploy things like you know I'm technically a python Advocate but most",
    "start": "69320",
    "end": "75479"
  },
  {
    "text": "of the time I'm actually like writing infrastructure as code and deploying things to as your servers because right",
    "start": "75479",
    "end": "81799"
  },
  {
    "text": "because a lot of what you want to do if you're writing a python web app is you want to get it running on the cloud",
    "start": "81799",
    "end": "87280"
  },
  {
    "text": "somewhere so quite a lot of my time is spent on that but also using you know as your python SDK and that sort of thing",
    "start": "87280",
    "end": "94240"
  },
  {
    "text": "this kind of jumps to the end of what we want to talk about but what clued me into the work that you're doing and I",
    "start": "94240",
    "end": "99600"
  },
  {
    "text": "first learned about one of the sample apps that you work on at a local developer conference here Denver devday",
    "start": "99600",
    "end": "104840"
  },
  {
    "text": "as was presentation by Lori ainson just got to give a shout out to the group and who talked about it I think her talk may have just stolen the title of the repo",
    "start": "104840",
    "end": "112040"
  },
  {
    "text": "which is chat GPT plus Enterprise data with Azure open Ai and cognitive search",
    "start": "112040",
    "end": "117479"
  },
  {
    "text": "that presentation was a great use case that I think a lot of companies would probably be able to do and went well",
    "start": "117479",
    "end": "123320"
  },
  {
    "text": "beyond just the simple hello chat GPT app but there's at least four moving",
    "start": "123320",
    "end": "128360"
  },
  {
    "text": "Parts just from that title jat GPT Enterprise data Azure open Ai and",
    "start": "128360",
    "end": "133640"
  },
  {
    "text": "cognitive search can you walk us through how all those pieces are connected and what each of them means yeah so this is",
    "start": "133640",
    "end": "140599"
  },
  {
    "start": "140000",
    "end": "263000"
  },
  {
    "text": "the sample that I spend a lot of my time maintaining right now it was originally made just as a conference demo but I",
    "start": "140599",
    "end": "146519"
  },
  {
    "text": "think it was one of the first example apps out there that showed how to make a chat on your own data and",
    "start": "146519",
    "end": "153640"
  },
  {
    "text": "so it's like it's been deployed thousands of times at this point and it's got like a community of people actually contributing to it so what it",
    "start": "153640",
    "end": "160480"
  },
  {
    "text": "is is using an approach that's called retrieval augmented generation RG and",
    "start": "160480",
    "end": "165800"
  },
  {
    "text": "the idea is that you can keep chat gbt constrained to your data by creating a",
    "start": "165800",
    "end": "171319"
  },
  {
    "text": "prompt that says answer this question according to this data and then passing in chunks of data so when we have this",
    "start": "171319",
    "end": "178400"
  },
  {
    "text": "application and we get question from the user we need to take that question from the user and search for the relevant",
    "start": "178400",
    "end": "185000"
  },
  {
    "text": "documents so in this case we're searching as your cognitive search where you know we can do a vector search we can do a text search the best thing is",
    "start": "185000",
    "end": "191200"
  },
  {
    "text": "actually do a hybrid to do both those things so then we get the results and these results are actually they're",
    "start": "191200",
    "end": "196840"
  },
  {
    "text": "already chunked to be chat GPT sized because chat GPT like you can't give it",
    "start": "196840",
    "end": "202080"
  },
  {
    "text": "too much information it'll get distracted there's a paper about this called I think lost in the middle so you",
    "start": "202080",
    "end": "208239"
  },
  {
    "text": "got to keep that chunk size so we get back the chat GPT size chunks and for",
    "start": "208239",
    "end": "213720"
  },
  {
    "text": "that user question and then we put those chunks together and we send those chunks and the original user question to chat",
    "start": "213720",
    "end": "220280"
  },
  {
    "text": "gbt and tell it to please answer it and then we get back the response sometimes",
    "start": "220280",
    "end": "225319"
  },
  {
    "text": "we ask for follow-up questions so that's the simplified version of it we actually have like different approaches that we",
    "start": "225319",
    "end": "232040"
  },
  {
    "text": "use that use slightly different prompting mechanisms and kind of different chains of calls and sometimes",
    "start": "232040",
    "end": "238599"
  },
  {
    "text": "use chat gbt function calls but the simplest way of thinking of it is get your search results in chunks send those",
    "start": "238599",
    "end": "244959"
  },
  {
    "text": "chunks with the user question to chat TBT and you said you start with your Enterprise data so what types of",
    "start": "244959",
    "end": "251360"
  },
  {
    "text": "Enterprise data are we talking about stuff that's in the applications I write stuff that's on our internet on",
    "start": "251360",
    "end": "256799"
  },
  {
    "text": "SharePoint or share drives or wherever people are storing things like is there anything that it can or can't search",
    "start": "256799",
    "end": "262040"
  },
  {
    "text": "very well yeah that's a good question so right now this demo actually only supports PDFs now as it turns out PDFs",
    "start": "262040",
    "end": "269240"
  },
  {
    "text": "are used quite a lot at Enterprise and you can also turn many things into PDFs",
    "start": "269240",
    "end": "274360"
  },
  {
    "text": "so this is like a limitation and we've developed other samples and we're working on you know adding support for other formats as well you know because",
    "start": "274360",
    "end": "281080"
  },
  {
    "text": "people want HTML they want CSV they want database queries that sort thing so right now this sample is really built",
    "start": "281080",
    "end": "286600"
  },
  {
    "text": "for PDFs and we actually ingest it using as your document intelligence which is",
    "start": "286600",
    "end": "292120"
  },
  {
    "text": "particularly good at extracting things from PDFs so it'll extract all this information and then we have this logic",
    "start": "292120",
    "end": "298800"
  },
  {
    "text": "that chunks it up up into you know the optimal size for chat TPT so that works",
    "start": "298800",
    "end": "304120"
  },
  {
    "text": "for many people I've got a branch where I wanted to have it work on documentation and so I crawled the",
    "start": "304120",
    "end": "310479"
  },
  {
    "text": "documentation in HTML and then I converted that HTML into PDFs and then ingested it that way so you know",
    "start": "310479",
    "end": "316560"
  },
  {
    "text": "anything you can turn into PDFs you can work with this lots of people do connect it with stuff stored in their SharePoint",
    "start": "316560",
    "end": "323039"
  },
  {
    "text": "or you know blob storage or whatever storage mechanism they're using S whatever but the idea right is the PDFs",
    "start": "323039",
    "end": "329360"
  },
  {
    "text": "right now there's lots of other repos out there that can help you with ingesting other data formats you just",
    "start": "329360",
    "end": "334440"
  },
  {
    "text": "need to get it into the search index in good chunks that's the key is to get it in the right size chunk and what's the",
    "start": "334440",
    "end": "340800"
  },
  {
    "text": "search index in this case it's one of the Azure Services I presume yeah so we are using AZ your cognitive search and",
    "start": "340800",
    "end": "347560"
  },
  {
    "start": "344000",
    "end": "458000"
  },
  {
    "text": "we do recommend using vectors with it so we started off with just text search but then we added vectors and they did a",
    "start": "347560",
    "end": "354880"
  },
  {
    "text": "test on the Cog search team to compare doing text vectors hybrid and then also",
    "start": "354880",
    "end": "361080"
  },
  {
    "text": "adding this what's called an L2 reranking step so it's like you get back your search results and then you can",
    "start": "361080",
    "end": "366560"
  },
  {
    "text": "apply an additional machine learning model this is called an L2 rerer and then it's just does a better job of",
    "start": "366560",
    "end": "372599"
  },
  {
    "text": "getting things to like the top spots that should be the top spots so they did like a big analysis across various",
    "start": "372599",
    "end": "378440"
  },
  {
    "text": "sample data and determined that the best approach overall is to use hybrid plus",
    "start": "378440",
    "end": "384080"
  },
  {
    "text": "the ranker it's not always the best thing for every single query like I can give an example of a query where this",
    "start": "384080",
    "end": "390080"
  },
  {
    "text": "won't work as well so let's say you have a bunch of documents and they're for weekly check-ins and you've like weekly",
    "start": "390080",
    "end": "395800"
  },
  {
    "text": "check-in number one number 10 number 20 if you do a hybrid search for weekly check in number one that actually may",
    "start": "395800",
    "end": "403479"
  },
  {
    "text": "not find number one because number one if you're using a vector search number one has like a semantic similarity to a",
    "start": "403479",
    "end": "409919"
  },
  {
    "text": "lot of things that was an inter situation and semantic search team is actually looking into that but you will",
    "start": "409919",
    "end": "415199"
  },
  {
    "text": "find that overall like hybrid is the best approach but it is interesting to see especially with the vectors where it",
    "start": "415199",
    "end": "421520"
  },
  {
    "text": "can mess up something that would have been better as an exact search so this is a sort of thing that you know when",
    "start": "421520",
    "end": "427560"
  },
  {
    "text": "you bring in your own data depending on what your own data looks like and you start doing experiments you can kind of see how these different search options",
    "start": "427560",
    "end": "434680"
  },
  {
    "text": "are working for you but it's interesting because a lot of times all you hear about these days is Vector search Vector search Vector search and Vector search",
    "start": "434680",
    "end": "440080"
  },
  {
    "text": "can be really cool because it can bring in things that are semantically similar like dog cat right bring in those but if",
    "start": "440080",
    "end": "446039"
  },
  {
    "text": "you're in a particular use case where you really don't want to get dog if you're asking for cat then you have to",
    "start": "446039",
    "end": "451280"
  },
  {
    "text": "be really careful about using Vector search right yeah so what's the Layman's definition of what's Vector versus exact",
    "start": "451280",
    "end": "457000"
  },
  {
    "text": "text searching so exact text searching you can think of it as string matching and still will like include like spell",
    "start": "457000",
    "end": "462840"
  },
  {
    "start": "458000",
    "end": "538000"
  },
  {
    "text": "check and stemming so stemming means like you have a verb walk a stem would",
    "start": "462840",
    "end": "468000"
  },
  {
    "text": "be like walked or walking right so you know that's a sort of thing you would get out of a good text search that you",
    "start": "468000",
    "end": "473400"
  },
  {
    "text": "would expect is the spell check and steming you know so that's going to work well for lots of things but when we bring in vector search that gives us the",
    "start": "473400",
    "end": "480879"
  },
  {
    "text": "ability to bring in things that are similar ontologically so you kind of imagine the space of words in our",
    "start": "480879",
    "end": "488080"
  },
  {
    "text": "language or in any language because you can do it across multiple languages you imagine the space of words and you imagine like if you're going to Cluster",
    "start": "488080",
    "end": "493840"
  },
  {
    "text": "them how would they be similar to each other so dog and cat even though they're spelled completely different in English",
    "start": "493840",
    "end": "499599"
  },
  {
    "text": "are semantically really similar because they're both animals they're both pets so that means if you searched for dog",
    "start": "499599",
    "end": "506080"
  },
  {
    "text": "and there was no results like that but there was a result for cat then you could end up getting that result so that",
    "start": "506080",
    "end": "511720"
  },
  {
    "text": "you know it works well in the case that you didn't have an exact match but you found something that was in a similar",
    "start": "511720",
    "end": "517719"
  },
  {
    "text": "ontological space yeah I think the example I saw and this is probably part of the demo is searching for like HR and",
    "start": "517719",
    "end": "523839"
  },
  {
    "text": "benefits documents and so going with that example I was looking for how do I get insurance for my dog and it might",
    "start": "523839",
    "end": "530000"
  },
  {
    "text": "come up with vet Insurance in general and it'll figure out that that's kind of the area that you wanted to search in",
    "start": "530000",
    "end": "535720"
  },
  {
    "text": "even though you didn't say veterinarian yeah yeah and we were doing another test with like looking for you know eye",
    "start": "535720",
    "end": "541240"
  },
  {
    "start": "538000",
    "end": "589000"
  },
  {
    "text": "appointments and there it found like Vision right because it never mentioned eye so that sort of thing even something",
    "start": "541240",
    "end": "546920"
  },
  {
    "text": "like looking for ey and it found preventative so it thought that preventative was similar to eye appointment because I guess it's kind of",
    "start": "546920",
    "end": "553160"
  },
  {
    "text": "a form of preventative care the semantic space can get things that are really similar and also can capture things that",
    "start": "553160",
    "end": "558480"
  },
  {
    "text": "are a bit farther the computers are better than the humans at remembering all those little relationships you wouldn't think of sometimes so I think",
    "start": "558480",
    "end": "565320"
  },
  {
    "text": "we covered the Enterprise data we've covered cognitive search and then chat GPT like you said you have to chunk the",
    "start": "565320",
    "end": "572760"
  },
  {
    "text": "question and the data that you're feeding it into chat GPT you explained it as give me an answer but here's the",
    "start": "572760",
    "end": "580040"
  },
  {
    "text": "data I want you to provide the answers on so you aren't pointing chat GPT at your search index you're giving it the",
    "start": "580040",
    "end": "585720"
  },
  {
    "text": "results of your search index and that's chunked up yeah that's right yeah there is actually another team that's working",
    "start": "585720",
    "end": "591959"
  },
  {
    "start": "589000",
    "end": "687000"
  },
  {
    "text": "on an actual extension to chat gbt where you would actually just specify here is",
    "start": "591959",
    "end": "597079"
  },
  {
    "text": "my search index and it would just use that search Index this is such a common use case now that everybody is like",
    "start": "597079",
    "end": "603079"
  },
  {
    "text": "trying to figure out how can we make this easier for people because clearly there's a huge demand for this lots of",
    "start": "603079",
    "end": "608320"
  },
  {
    "text": "Enterprises want to do this actually so there's lots of different teams trying to come up with different approaches to",
    "start": "608320",
    "end": "613640"
  },
  {
    "text": "make this easier which is great because we want to make it easier for people so there is a team that's working on an extension to the chat API where you",
    "start": "613640",
    "end": "620040"
  },
  {
    "text": "would literally specify this is my search index and it would basically do what we're doing behind the scenes in",
    "start": "620040",
    "end": "625480"
  },
  {
    "text": "our sample we do it manually which is cool if you want to be able like tweak things a bit further and like actually",
    "start": "625480",
    "end": "632360"
  },
  {
    "text": "have like control of the prompt if you're trying to bring in like very different sources as well you could bring those in so in our repo we've got",
    "start": "632360",
    "end": "639279"
  },
  {
    "text": "the system message so the system message is like the thing you first tell chat chbd to say to kind of like give it its",
    "start": "639279",
    "end": "645079"
  },
  {
    "text": "main guidance so you say like okay chat gbt you are a helpful assistant that looks through HR documents you'll",
    "start": "645079",
    "end": "651920"
  },
  {
    "text": "receive sources they're in this format you need to answer according to the sources here's an example now here's the",
    "start": "651920",
    "end": "657920"
  },
  {
    "text": "user question and hear the sources please answer it yeah and I like the idea of making that just plug and play",
    "start": "657920",
    "end": "664480"
  },
  {
    "text": "as opposed to someone has to do that setup because it seems like there's a little bit of fine-tuning like going",
    "start": "664480",
    "end": "669560"
  },
  {
    "text": "through the example it's fairly straightforward how you could get set up and then start plugging your data in and",
    "start": "669560",
    "end": "675240"
  },
  {
    "text": "then you said you have to practice it and figure out what's right for your specific case like how do you do all the",
    "start": "675240",
    "end": "680839"
  },
  {
    "text": "little tuning how does someone go through and figure out what is the right tuning setup for their environment",
    "start": "680839",
    "end": "686639"
  },
  {
    "text": "that's a good question you know so people will check the repo they'll try it with the sample data then they'll start bringing in their own data and",
    "start": "686639",
    "end": "693800"
  },
  {
    "start": "687000",
    "end": "795000"
  },
  {
    "text": "start doing questions against it and you know usually they start taking notes like okay it seems like the citation was",
    "start": "693800",
    "end": "700480"
  },
  {
    "text": "wrong here it seems like the answer was wrong here maybe the answer was to verbose and in that case like you know I",
    "start": "700480",
    "end": "706320"
  },
  {
    "text": "tell them to start breaking down so we actually we show the thought process in our UI to help people with debugging",
    "start": "706320",
    "end": "713560"
  },
  {
    "text": "what's happened because the thing you have to figure out is like is the issue that your data was chunk incorrectly",
    "start": "713560",
    "end": "719920"
  },
  {
    "text": "sometimes that happens that was a situation we saw where like the data wasn't chunked optimally it was like chunked in the middle of a page and we",
    "start": "719920",
    "end": "727000"
  },
  {
    "text": "just needed to have a different chunking approach there is the issue that cognitive search you know didn't find",
    "start": "727000",
    "end": "732279"
  },
  {
    "text": "the optimal results and there you want to look at stuff like you know are you using hybrid search are you using the",
    "start": "732279",
    "end": "737360"
  },
  {
    "text": "ranker like what happens when you change the things and then finally is it issued that chat gbt wasn't paying attention to",
    "start": "737360",
    "end": "743959"
  },
  {
    "text": "the results so most often like chat is actually pretty good at paying attention to results so issues with chat gbt we've",
    "start": "743959",
    "end": "749480"
  },
  {
    "text": "seen are more around maybe it being too verbose giving too much information or",
    "start": "749480",
    "end": "754760"
  },
  {
    "text": "just not formatting something the way somebody wanted if they wanted markdown versus a list or something like that a",
    "start": "754760",
    "end": "760360"
  },
  {
    "text": "lot of times issues is actually like at the search stage because searching is hard and you have this Vision in your head of you like this is obviously the",
    "start": "760360",
    "end": "766639"
  },
  {
    "text": "right search result for it but it may not actually you know be what's output there's lots of you know configuring you",
    "start": "766639",
    "end": "772600"
  },
  {
    "text": "can do there to improve the results yeah and like I said there's at least four moving Parts you have to identify which",
    "start": "772600",
    "end": "778839"
  },
  {
    "text": "which is the one that's causing you to go a little bit off of where you're trying to get to and so it might be cognitive search when you're asking the",
    "start": "778839",
    "end": "785519"
  },
  {
    "text": "question is that all part of ashure cognitive search or you feeding the question into chat GPT and it's turning",
    "start": "785519",
    "end": "791279"
  },
  {
    "text": "into something else that you ask cognitive search okay so yeah you got it that's actually what we do so I often",
    "start": "791279",
    "end": "797360"
  },
  {
    "text": "glaze over that but in our main approach that we use we actually take the user query and then we tell chat gbt to turn",
    "start": "797360",
    "end": "804800"
  },
  {
    "text": "that into a good keyword search and we give it a lot of examples too so we use f shot prompting as it's called so we",
    "start": "804800",
    "end": "811160"
  },
  {
    "text": "give it multiple examples of here's a user question here's a good keyword search here's a user question here's a good keyword search and this we're",
    "start": "811160",
    "end": "817079"
  },
  {
    "text": "trying to accommodate for the fact that many users don't write things that are necessarily the optimal thing to send",
    "start": "817079",
    "end": "822399"
  },
  {
    "text": "into a search engine so that's actually the first call we make to chat gbt is to",
    "start": "822399",
    "end": "827720"
  },
  {
    "text": "turn that query into a appropriate keyword search so that would be another thing to look at when you're debugging",
    "start": "827720",
    "end": "835120"
  },
  {
    "text": "this if you're not liking the results you know did chat gbt do good job of turning that user question into an",
    "start": "835120",
    "end": "842320"
  },
  {
    "text": "appropriate keyword query and usually it does but it's another step to look into",
    "start": "842320",
    "end": "847639"
  },
  {
    "text": "so it sounds like you've got chat GPT is The Interpreter both going in and coming out of everything that's Underneath It",
    "start": "847639",
    "end": "854440"
  },
  {
    "text": "All the data all the cognitive search but the idea that the computer is better at talking to the other computers let's",
    "start": "854440",
    "end": "861399"
  },
  {
    "text": "put that barrier both in and out so it translates it from human into keywords and then from responses back into human",
    "start": "861399",
    "end": "868480"
  },
  {
    "text": "yeah yeah that's right which is very interesting and something that I should point out is that you know right now",
    "start": "868480",
    "end": "875000"
  },
  {
    "start": "870000",
    "end": "1056000"
  },
  {
    "text": "like if we start messing with the prompts right because there's a lot of prompting involved here and so there's you know we might do some like prompt",
    "start": "875000",
    "end": "880759"
  },
  {
    "text": "tweaking prompt engineering as they call it and we might think like oh okay this does improve the results but you do",
    "start": "880759",
    "end": "886680"
  },
  {
    "text": "actually like in software development we want to have some amount of confidence that the improvements are real good you",
    "start": "886680",
    "end": "893920"
  },
  {
    "text": "know tangible improvements especially with chap GP because chap gbt is highly variable so you can't test it once and",
    "start": "893920",
    "end": "900199"
  },
  {
    "text": "be like oh that was definitely better because it's going to actually give a different response every time especially",
    "start": "900199",
    "end": "905480"
  },
  {
    "text": "right now so there's a temperature parameter you can use between zero and one and one is like most variable zero is least variable even zero you'll have",
    "start": "905480",
    "end": "912600"
  },
  {
    "text": "variability with the way llms work so we have like 0.7 right now huge amount of",
    "start": "912600",
    "end": "917720"
  },
  {
    "text": "variability so how do you actually know if you have improved the prompt that it is actually an improvement right so I'm",
    "start": "917720",
    "end": "925079"
  },
  {
    "text": "working on a branch to add an evaluation pipeline so what you do is you come up",
    "start": "925079",
    "end": "930160"
  },
  {
    "text": "with a bunch of ground truth data so question answer Pairs and don't worry we can use chat gbt to generate this ground",
    "start": "930160",
    "end": "936040"
  },
  {
    "text": "truth data right because what you do is you point it at your original input data and say you know come up with a bunch of",
    "start": "936040",
    "end": "941279"
  },
  {
    "text": "questions answers based off this data so you have your ground truth data and then you point the evaluator at that data and",
    "start": "941279",
    "end": "947800"
  },
  {
    "text": "at your current prompt flow and then tell it to evaluate it and what it actually does is that it you know calls",
    "start": "947800",
    "end": "953800"
  },
  {
    "text": "your app gets a result and then uses chat gbt to evaluate it usually you want",
    "start": "953800",
    "end": "959360"
  },
  {
    "text": "to use chat4 in this case because chat4 is you know the more advanced one so this is a use case where you do usually",
    "start": "959360",
    "end": "964880"
  },
  {
    "text": "want to use chat4 and it's okay that it's a little more expensive because you're not going to use it for that many queries but for every single question",
    "start": "964880",
    "end": "971240"
  },
  {
    "text": "answer you ask Chachi like hey here's what we got here's the ground truth can you please measure this answer in terms",
    "start": "971240",
    "end": "977839"
  },
  {
    "text": "of relevance groundedness fluency and some other metrics I don't remember but",
    "start": "977839",
    "end": "984000"
  },
  {
    "text": "that's like the approach to evaluation and that's hopefully what will enable",
    "start": "984000",
    "end": "989079"
  },
  {
    "text": "people to easily do on their chat apps is to be able to say like okay I've made a change is it legitimately a better",
    "start": "989079",
    "end": "995399"
  },
  {
    "text": "change before I merge this prompt change into production yeah that's a lot to think about because people want to know",
    "start": "995399",
    "end": "1001759"
  },
  {
    "text": "that it's working but I can't just write a unit test for it to say oh it's good because calling it isn't good enough the",
    "start": "1001759",
    "end": "1007800"
  },
  {
    "text": "responses are what matters and the response the fact that it changes even if you tell it give me the same was the",
    "start": "1007800",
    "end": "1013480"
  },
  {
    "text": "temperature as the value that you feed it and like set that to no like zero don't change it at all it still gives",
    "start": "1013480",
    "end": "1019040"
  },
  {
    "text": "different answers yep yeah yeah these are the things that people need to know when they start out",
    "start": "1019040",
    "end": "1024640"
  },
  {
    "text": "it's like it doesn't do quite what I expected and how do I figure out so providing those in the samples and in",
    "start": "1024640",
    "end": "1029720"
  },
  {
    "text": "tutorials is very helpful to say hey we know it's going to be a little different but that's expected and here's settings F's expectations so I really like the",
    "start": "1029720",
    "end": "1037280"
  },
  {
    "text": "sample I think it's really useful like you said a lot of corporate Partners or a lot of companies are going to want to do something like that but what if",
    "start": "1037280",
    "end": "1043798"
  },
  {
    "text": "corporate data and cognitive search isn't what somebody's going to get started on you have another simple chat",
    "start": "1043799",
    "end": "1049520"
  },
  {
    "text": "app what do you think that that's meant to teach developers who pull that down and go through the tutorial ah you found",
    "start": "1049520",
    "end": "1055960"
  },
  {
    "text": "my other sample very few developers pull that down because most people want they want the Enterprise chat app so that app",
    "start": "1055960",
    "end": "1062480"
  },
  {
    "start": "1056000",
    "end": "1155000"
  },
  {
    "text": "was an experimentation in kind of make sure we can use best practices like",
    "start": "1062480",
    "end": "1067679"
  },
  {
    "text": "containerization and that one actually gets deployed to container apps and also in showing very simply how one can use",
    "start": "1067679",
    "end": "1075200"
  },
  {
    "text": "managed identity so it's trying to be the minimal example to show various best practices so containerization managed",
    "start": "1075200",
    "end": "1081919"
  },
  {
    "text": "identity and streaming it also does show how to do streaming and also it uses asynchronous framework so it's only like",
    "start": "1081919",
    "end": "1088840"
  },
  {
    "text": "20 lines of code I think right compared to this other app which is like I don't know getting on hundreds or thousands",
    "start": "1088840",
    "end": "1094440"
  },
  {
    "text": "now but the goal of that is to be a succinct example of some of the highlevel best practices for using these",
    "start": "1094440",
    "end": "1102400"
  },
  {
    "text": "sdks yeah and I think that's useful because sometimes like I go on to stack Overflow and I want to just post I'm",
    "start": "1102400",
    "end": "1107720"
  },
  {
    "text": "like I'm having this bug and what's useful is when someone's able to produce the smallest amount of code that",
    "start": "1107720",
    "end": "1113240"
  },
  {
    "text": "reproduces their bug it's like just the act of doing that sometimes answers your own question but instead of pulling in",
    "start": "1113240",
    "end": "1119200"
  },
  {
    "text": "all of these things and wondering which of the large moving Parts isn't working having the simple app to just get",
    "start": "1119200",
    "end": "1124559"
  },
  {
    "text": "started you said can be useful just to teach those things can I create the containers and get it deployed in my environment so I think that's useful you",
    "start": "1124559",
    "end": "1131360"
  },
  {
    "text": "did highlight some of the things I wanted to get into because I read through your blog and I found a series of posts on best practices for opening",
    "start": "1131360",
    "end": "1137720"
  },
  {
    "text": "eye chat apps and I have a feeling they all came out of this sample but we can just go through some of them the first one that I thought was interesting was",
    "start": "1137720",
    "end": "1144120"
  },
  {
    "text": "about mocking the calls to open API when you're testing and that's counterintuitive because I thought isn't",
    "start": "1144120",
    "end": "1149679"
  },
  {
    "text": "the whole point of this that I want to test that it's working why would I mock that well we have different levels of",
    "start": "1149679",
    "end": "1156080"
  },
  {
    "start": "1155000",
    "end": "1309000"
  },
  {
    "text": "tests right so at this point in the codebase I've got two levels of or maybe I guess three levels of tests right so",
    "start": "1156080",
    "end": "1162080"
  },
  {
    "text": "I've got unit tests you know function in function out I've got integration tests and those integration tests I want to be",
    "start": "1162080",
    "end": "1167440"
  },
  {
    "text": "able to run them really quick so that is where I'm mocking out all of the network calls I don't want my integration test",
    "start": "1167440",
    "end": "1172840"
  },
  {
    "text": "to make any network calls because I run all of them in like a minute right so I'm G run hundreds of tests in a minute",
    "start": "1172840",
    "end": "1178520"
  },
  {
    "text": "and then even my end to-end tests so those are using playright which is like selenium so if you've done any sort of",
    "start": "1178520",
    "end": "1183559"
  },
  {
    "text": "browser endtoend testing you're going to use one of these tools and it's actually kind of fun what I do is in the python",
    "start": "1183559",
    "end": "1190559"
  },
  {
    "text": "backend test I use Snapshot testing which is the idea that you save a snapshot you save the results right so I",
    "start": "1190559",
    "end": "1197240"
  },
  {
    "text": "save the response I get fromr the server I save it into a file and then going forward the file always gets died so if",
    "start": "1197240",
    "end": "1204159"
  },
  {
    "text": "anything changed in that response the test will fail and either I need to you know fix the issue or I say okay",
    "start": "1204159",
    "end": "1209840"
  },
  {
    "text": "actually it was supposed to change you know because like I changed the prompt or something and then it updates all the snapshots so I've got all these",
    "start": "1209840",
    "end": "1215360"
  },
  {
    "text": "snapshots that show what the responses should be like for particular calls and then in my front end test like my end",
    "start": "1215360",
    "end": "1221320"
  },
  {
    "text": "to-end test I use those snapshots as the mock for the front end so the front end",
    "start": "1221320",
    "end": "1227120"
  },
  {
    "text": "is testing against the results of the back end so that's pretty cool because it means at least the front end and the",
    "start": "1227120",
    "end": "1232559"
  },
  {
    "text": "back end are synced up with each other in terms of your test now the final question is how do we test that the",
    "start": "1232559",
    "end": "1238120"
  },
  {
    "text": "mocked calls like something doesn't change right if opening eye changes their SDK or if any of the backend",
    "start": "1238120",
    "end": "1243760"
  },
  {
    "text": "Network calls are acting funny we could still have a broken app so we still need what we would call like smoke tests I'd",
    "start": "1243760",
    "end": "1250000"
  },
  {
    "text": "call them smoke tests which is here is that you've got your deployed app does your deployed app work so I do have a",
    "start": "1250000",
    "end": "1256080"
  },
  {
    "text": "to-do on a Post-It here that says to write smoke tests and so what I'd probably do is do something really",
    "start": "1256080",
    "end": "1261400"
  },
  {
    "text": "similar to my playright tests but I just wouldn't mock out the back end right I would just do it against the thing I",
    "start": "1261400",
    "end": "1268000"
  },
  {
    "text": "haven't set that up yet mostly because it does require like authentication and we're figuring out like the best way to store our authentication in a public",
    "start": "1268000",
    "end": "1274360"
  },
  {
    "text": "repository it would be a lot easier if this was a private repo but because this is a public repo we've been debating the",
    "start": "1274360",
    "end": "1279799"
  },
  {
    "text": "right approach to having cicd do a deploy and a smoke test in a private repo I think it would be more",
    "start": "1279799",
    "end": "1285799"
  },
  {
    "text": "straightforward I'm going to jump from that onto one of your other tips which was about security and authentication",
    "start": "1285799",
    "end": "1291919"
  },
  {
    "text": "and I think people are used to using API keys for authentication and it seems like I just get my API key and I'll",
    "start": "1291919",
    "end": "1297080"
  },
  {
    "text": "shove it in there and you said don't do that and I know you're talking about in the world of azure but I think you",
    "start": "1297080",
    "end": "1302520"
  },
  {
    "text": "talked about using a keyless strategy and why do you think that's important as opposed to just API keys because they're",
    "start": "1302520",
    "end": "1307960"
  },
  {
    "text": "easy yeah they certainly are easy but you know it's fine if it's like a personal project but when you're working",
    "start": "1307960",
    "end": "1313320"
  },
  {
    "start": "1309000",
    "end": "1416000"
  },
  {
    "text": "inside a company you increasingly do not want to use keys because the thing is like if you're inside a big company like",
    "start": "1313320",
    "end": "1318640"
  },
  {
    "text": "Microsoft or you know maybe smaller than Microsoft but anyone in the company could in theory use that key right if",
    "start": "1318640",
    "end": "1324320"
  },
  {
    "text": "they get a hold of that key they can now use that key and so you can end up in this situation where multiple teams are",
    "start": "1324320",
    "end": "1330640"
  },
  {
    "text": "using the same key and not knowing it so that means you're using up each other's quota and how do you even find out where",
    "start": "1330640",
    "end": "1336320"
  },
  {
    "text": "these other people are that are using your key right that's an awkward thing it's actually something that my friend",
    "start": "1336320",
    "end": "1341440"
  },
  {
    "text": "ran into the other day with using keys at their company they're like I can't figure out who's using our team's key so",
    "start": "1341440",
    "end": "1347240"
  },
  {
    "text": "that's a situation but then obviously huge security issues like I see people push their keys to GitHub like every day",
    "start": "1347240",
    "end": "1353279"
  },
  {
    "text": "it just always happens right you put your key in aemv file and youve",
    "start": "1353279",
    "end": "1358480"
  },
  {
    "text": "accidentally you know checked that in even though we have it in our G ignore and now your keys exposed so there's",
    "start": "1358480",
    "end": "1364039"
  },
  {
    "text": "both security and there's tracking and when you're working inside an company",
    "start": "1364039",
    "end": "1369600"
  },
  {
    "text": "it's better to use some sort of keyless strategy in this case what we do is we give explicit roles so we make a rle for",
    "start": "1369600",
    "end": "1377120"
  },
  {
    "text": "the hosted platform we say okay this app this app Service app has the role where it's allowed to access this particular",
    "start": "1377120",
    "end": "1383520"
  },
  {
    "text": "open AI so we set up a very specific role access there and then also we set it up for the local user and say this",
    "start": "1383520",
    "end": "1389320"
  },
  {
    "text": "local user specifically can use this open a so we're setting up a very specific set of roles and it's just",
    "start": "1389320",
    "end": "1395799"
  },
  {
    "text": "makes it a lot clearer who can do what and you don't end up with this Loosey Goosey everyone's using each other's key",
    "start": "1395799",
    "end": "1402960"
  },
  {
    "text": "and then going back to the sample application does everyone just have to be on aure active directory and that just allows you to use individuals or",
    "start": "1402960",
    "end": "1409919"
  },
  {
    "text": "are you still talking about an application account that I set up for my team that isn't just the one API key",
    "start": "1409919",
    "end": "1415720"
  },
  {
    "text": "let's see the way we did it for this sample is that we create a role for you know the app service that you deploy to",
    "start": "1415720",
    "end": "1421760"
  },
  {
    "start": "1416000",
    "end": "1466000"
  },
  {
    "text": "and then we just create a role for the local user I think you could in theory create what's called a service principle",
    "start": "1421760",
    "end": "1428159"
  },
  {
    "text": "I think and then use that and granted the roles we even have like a script you can run that will go and assign all the",
    "start": "1428159",
    "end": "1434200"
  },
  {
    "text": "necessary roles to you know a current user so I think you know know you could use any approach but we default to like",
    "start": "1434200",
    "end": "1440760"
  },
  {
    "text": "you know setting up the users local roles and the deployed apps roles so one of the other tips you mentioned already",
    "start": "1440760",
    "end": "1446520"
  },
  {
    "text": "was streaming you set that up why is streaming important like I think again it's easy to set up request response but",
    "start": "1446520",
    "end": "1452960"
  },
  {
    "text": "the user experience that people see when they use chat GPT or any of the other ones it's like constantly like spitting",
    "start": "1452960",
    "end": "1459080"
  },
  {
    "text": "the words of text out so is that what the streaming interface gets you and why is that something to do and why is it",
    "start": "1459080",
    "end": "1464200"
  },
  {
    "text": "complicated to set up yeah streaming has been a whole thing my gosh I was actually just a bugging a bug with it",
    "start": "1464200",
    "end": "1469520"
  },
  {
    "start": "1466000",
    "end": "1690000"
  },
  {
    "text": "this morning yeah so when this sample first came out it did not actually have streaming support but it became like a",
    "start": "1469520",
    "end": "1475799"
  },
  {
    "text": "big request and so we ended up adding streaming support to it and there are a",
    "start": "1475799",
    "end": "1481240"
  },
  {
    "text": "lot of benefits to adding it so one is like the actual like performance right if you have to wait for the whole",
    "start": "1481240",
    "end": "1486279"
  },
  {
    "text": "response to come back you actually do have to wait longer than if you had streaming because it's actually getting",
    "start": "1486279",
    "end": "1491320"
  },
  {
    "text": "streamed not just from your server it's getting streamed from open AI so you can imagine that like you know our server is",
    "start": "1491320",
    "end": "1497000"
  },
  {
    "text": "opening up a stre stream to open Ai and as soon as it's getting tokens in from open aai it's sending it to the front",
    "start": "1497000",
    "end": "1502640"
  },
  {
    "text": "end so you can actually especially for long responses for the user their experience will be that the response",
    "start": "1502640",
    "end": "1509600"
  },
  {
    "text": "comes quicker because they start to see those words flow in more quickly because",
    "start": "1509600",
    "end": "1514919"
  },
  {
    "text": "if it was just a matter of people like the word by word effect then you could kind of just fake it out and just get",
    "start": "1514919",
    "end": "1520120"
  },
  {
    "text": "the whole response from chat gbt and just you know fake it out on the front end but you want to actually get that",
    "start": "1520120",
    "end": "1525760"
  },
  {
    "text": "performance benefit especially with responses where you start seeing those words as soon as chat gpts start",
    "start": "1525760",
    "end": "1532240"
  },
  {
    "text": "generating them so that's why you know it's important why people like it you know they're used to it perceived better performance faster response in terms of",
    "start": "1532240",
    "end": "1539360"
  },
  {
    "text": "the complexity of it it's very interesting because when I first implemented streaming I used this",
    "start": "1539360",
    "end": "1545080"
  },
  {
    "text": "protocol called server sent events and we can link that explanation of it but a",
    "start": "1545080",
    "end": "1550480"
  },
  {
    "text": "server sent event it's a protocol where you have to emit these events from your",
    "start": "1550480",
    "end": "1556240"
  },
  {
    "text": "server that have this data colon in front of them and then on the front end you have to parse them and you have to",
    "start": "1556240",
    "end": "1562760"
  },
  {
    "text": "parse out what's after the data colon and it's a whole thing so it actually requires a fair amount of effort because",
    "start": "1562760",
    "end": "1568600"
  },
  {
    "text": "on your server you got to be outputting these data colon formatted events and on the front end you got to you know parse",
    "start": "1568600",
    "end": "1574799"
  },
  {
    "text": "those in and then you have to do like this explicit closing of the connection so the reason I use server sent events",
    "start": "1574799",
    "end": "1580000"
  },
  {
    "text": "is because that's actually what chaty uses behind the scenes so their rest API is actually implemented using server",
    "start": "1580000",
    "end": "1586480"
  },
  {
    "text": "andent events most people don't know that because they're using the sdks on top right so most of us and us as well",
    "start": "1586480",
    "end": "1593200"
  },
  {
    "text": "we use the SDK on top which just generates a stream of objects using like a python generator and we consume it",
    "start": "1593200",
    "end": "1599559"
  },
  {
    "text": "that way but behind the scenes it is actually using service and events and so that's what everybody told me to use but then I actually tried it and I realized",
    "start": "1599559",
    "end": "1606120"
  },
  {
    "text": "like oh my gosh this is not a good developer experience and we do not need this complexity so I changed it to",
    "start": "1606120",
    "end": "1612440"
  },
  {
    "text": "instead use just a simple htb stream so all that means is that your header is",
    "start": "1612440",
    "end": "1617919"
  },
  {
    "text": "transfer encoding chunked that's it so you set ah header transfer and coding chunked and then use you know your",
    "start": "1617919",
    "end": "1623760"
  },
  {
    "text": "framework to stream out a response and so the response will come into the front",
    "start": "1623760",
    "end": "1630000"
  },
  {
    "text": "end you know a chunk at a time and what we do is we stream out new line limited Json also known as Json lines or line J",
    "start": "1630000",
    "end": "1638840"
  },
  {
    "text": "there's lots of names for it but basically you stream out chunks of Json that have new lines and then on the front end you compile those back",
    "start": "1638840",
    "end": "1645880"
  },
  {
    "text": "together until you've got a fully pricing Json and that part's a little tricky so I did make an mpm package for",
    "start": "1645880",
    "end": "1651679"
  },
  {
    "text": "that so if you're find yourself doing that you can use my mpm package and it'll do the partial Json parsing and",
    "start": "1651679",
    "end": "1657520"
  },
  {
    "text": "just give it to you as an asynchronous iterator yeah I've dealt with Json lines or okay Json l or whatever you want to",
    "start": "1657520",
    "end": "1663440"
  },
  {
    "text": "call it you know just everyone has a different name but that makes a lot of sense now you say that each line comes across and eventually you get the full",
    "start": "1663440",
    "end": "1669360"
  },
  {
    "text": "Json but there's like you're missing the first and last curly brace on it and the bracket for the array it's everything in",
    "start": "1669360",
    "end": "1674840"
  },
  {
    "text": "between so all of your examples because you are a python Advocate are in Python but is there anything that's python",
    "start": "1674840",
    "end": "1680240"
  },
  {
    "text": "specific like I'm mostly a c developer would I be able to read through this and say okay I can figure out how to",
    "start": "1680240",
    "end": "1685600"
  },
  {
    "text": "translate and do the same thing are there other samples out there in other languages yeah so that's a great",
    "start": "1685600",
    "end": "1690640"
  },
  {
    "start": "1690000",
    "end": "1803000"
  },
  {
    "text": "question because actually we've been working to make this sample basically Port it to other languages because it's",
    "start": "1690640",
    "end": "1696000"
  },
  {
    "text": "really interesting because lots of people using this sample clearly like this might be the first time they're using Python and it's great to like",
    "start": "1696000",
    "end": "1701480"
  },
  {
    "text": "bring people over to the python side but also like if you're a c developer I don't want to force you to like python",
    "start": "1701480",
    "end": "1706559"
  },
  {
    "text": "you know everyone has their own particular language and we basically are never ever going to agree on that so we're going to have a billion languages",
    "start": "1706559",
    "end": "1712080"
  },
  {
    "text": "forever so knowing that we have ported the sample over to multiple languages so",
    "start": "1712080",
    "end": "1717720"
  },
  {
    "text": "we do have one in C we have one in Java and then we have one in like JavaScript like node backend so we're trying to",
    "start": "1717720",
    "end": "1724120"
  },
  {
    "text": "have feature parody across them they're not perfectly in sync with each other",
    "start": "1724120",
    "end": "1729279"
  },
  {
    "text": "like the python sample because it's you know very popular and has been out for a while like it does have a few more",
    "start": "1729279",
    "end": "1734840"
  },
  {
    "text": "things kind of more experimental things but we're trying kind of like we've agreed on like a common protocol so it's",
    "start": "1734840",
    "end": "1740000"
  },
  {
    "text": "cool you could actually use like the JavaScript front end they use web components with our back end because",
    "start": "1740000",
    "end": "1746000"
  },
  {
    "text": "we're trying to speak the same protocol so we've aligned on like a common protocol and yeah so we're trying to",
    "start": "1746000",
    "end": "1751440"
  },
  {
    "text": "make it so that you can pick the language of your choice because there will probably be slight differences",
    "start": "1751440",
    "end": "1756679"
  },
  {
    "text": "especially like the open AI SDK is probably going to be slightly different across each of them so yeah pick your flavor and then since you brought it up",
    "start": "1756679",
    "end": "1763960"
  },
  {
    "text": "I feel like I have to ask something about pricing now every time I talk to someone at Microsoft the canned answer is I'm not an expert on pricing and",
    "start": "1763960",
    "end": "1770679"
  },
  {
    "text": "that's fine I know the answer is always it depends but you brought up a good point about you know sharing your API keys and someone else starts using your",
    "start": "1770679",
    "end": "1776960"
  },
  {
    "text": "quota and I think people understand that large language models have this incurred cost and people aren't really sure",
    "start": "1776960",
    "end": "1783480"
  },
  {
    "text": "should I use chat GPT 3 or 3.5 or four in general terms what are some of the",
    "start": "1783480",
    "end": "1789559"
  },
  {
    "text": "big points of concern where cost becomes a factor and whether you're using the sample apps or building a custom",
    "start": "1789559",
    "end": "1795640"
  },
  {
    "text": "solution that uses similar resources where the big gotchas that people need to know to look out for when it comes to",
    "start": "1795640",
    "end": "1800880"
  },
  {
    "text": "my pricing went off the rails so I think some of the things that surprise people are you know like our repo defaults to",
    "start": "1800880",
    "end": "1807519"
  },
  {
    "text": "using as your document intelligence for extraction because it's very good at PDF extraction that does cost money because",
    "start": "1807519",
    "end": "1814000"
  },
  {
    "text": "it's a service that costs money and if you're ingesting like thousands and thousands of PDFs then that will run up",
    "start": "1814000",
    "end": "1820320"
  },
  {
    "text": "a budget for the sample data doesn't run up a budget but if you are ingesting a huge number of PDFs that will definitely",
    "start": "1820320",
    "end": "1825559"
  },
  {
    "text": "run up the budget and it's like a per per page cost so we have like a link to that so you can do the calculation so I",
    "start": "1825559",
    "end": "1832360"
  },
  {
    "text": "have seen people comment on that you can use your own so we also do support a local PDF parser so if that is good",
    "start": "1832360",
    "end": "1839600"
  },
  {
    "text": "enough then you could use it's a python package that just does local PDF parsing so we try to have backup options when",
    "start": "1839600",
    "end": "1845440"
  },
  {
    "text": "it's possible the other thing is you know as your cognitive search so that the pricing is going to depend on",
    "start": "1845440",
    "end": "1851919"
  },
  {
    "text": "whether you're using options like semantic search and you know if you need additional replicas we think that most",
    "start": "1851919",
    "end": "1857559"
  },
  {
    "text": "people are fine with the default number replicas but semantic search does currently cost extra I think it's yeah",
    "start": "1857559",
    "end": "1864360"
  },
  {
    "text": "we're not supposed to give exact price but it's around like a couple hundred dollars a month right now depending on the region right so that is definitely",
    "start": "1864360",
    "end": "1871120"
  },
  {
    "text": "money for some Enterprises that's not significant right you know because it's cheaper than paying someone to build a",
    "start": "1871120",
    "end": "1877440"
  },
  {
    "text": "search engine from scratch like I don't know how to build an L2 ranker I just learned that term if that's prohibitive",
    "start": "1877440",
    "end": "1883639"
  },
  {
    "text": "for someone then they would you know turn off semantic search and then you cognitive search does have I think they",
    "start": "1883639",
    "end": "1889519"
  },
  {
    "text": "have a free tier but I don't know that we default to it so cognitive search can cost money and then there's open AI so",
    "start": "1889519",
    "end": "1896240"
  },
  {
    "text": "open AI I think our costs are actually similar or the same as open AI but don't",
    "start": "1896240",
    "end": "1901279"
  },
  {
    "text": "quote me this is a podcast so I guess you're G to quote me but you can look at the prices for that that's going to be per token and you know so that's why",
    "start": "1901279",
    "end": "1907880"
  },
  {
    "text": "people do prompt engineering to try not to send in big tokens it's also per model right so you're asking like gbd 35",
    "start": "1907880",
    "end": "1913200"
  },
  {
    "text": "versus 4 we tell people to try 35 I use 35 for all of mine samples as a default",
    "start": "1913200",
    "end": "1919279"
  },
  {
    "text": "and it seems pretty good so we tell people to you know start with 35 and see",
    "start": "1919279",
    "end": "1924480"
  },
  {
    "text": "how far you can go through five because you don't want to have to go to four unless it's really necessary because four you know it's both going to be",
    "start": "1924480",
    "end": "1930559"
  },
  {
    "text": "slower and it's going to cost more right so especially for something user facing given that you know it's usually a",
    "start": "1930559",
    "end": "1936519"
  },
  {
    "text": "little bit slower right now you don't necessarily want that so that's also like why evaluation pipelines are important because ideally you could",
    "start": "1936519",
    "end": "1942639"
  },
  {
    "text": "check 35 against your evaluation pipeline check four and see like is the difference really big and also look at",
    "start": "1942639",
    "end": "1948639"
  },
  {
    "text": "your latency right like you know what's the latency right like if I use 35 versus four and is that important to us",
    "start": "1948639",
    "end": "1955760"
  },
  {
    "text": "well that's a lot to get into and like you said none of this is free but it's all useful so it's up to individual",
    "start": "1955760",
    "end": "1961279"
  },
  {
    "text": "companies to figure out is this useful for what we want to do and yeah probably cheaper than paying someone to write it",
    "start": "1961279",
    "end": "1966320"
  },
  {
    "text": "all from scratch so we'll include links to your blog to the sample apps and the show notes if people want to start using",
    "start": "1966320",
    "end": "1972200"
  },
  {
    "text": "them and they have questions what's the best way to get in touch with you or your team so I subscribe cribe to all of",
    "start": "1972200",
    "end": "1978120"
  },
  {
    "text": "the issues on that repo so just filing an issue in that repo is a pretty good way of getting in touch with me it goes",
    "start": "1978120",
    "end": "1984120"
  },
  {
    "text": "straight to my inbox because I have not figured out Outlook filters yet so I just have an inbox full of those issues",
    "start": "1984120",
    "end": "1990240"
  },
  {
    "text": "so that's one way there's also the AI for developers Discord that the AI ABC team started well I hope some of this",
    "start": "1990240",
    "end": "1997000"
  },
  {
    "text": "has been useful to our listeners and they now know a few more ways to get started writing apps that use chat GPT",
    "start": "1997000",
    "end": "2002600"
  },
  {
    "text": "and Azure open AI Pamela Fox thank you so much for joining me today sure thank you for having me on great questions and",
    "start": "2002600",
    "end": "2008960"
  },
  {
    "text": "listeners I hope you join us again on a future episode of the infoq [Music]",
    "start": "2008960",
    "end": "2033639"
  },
  {
    "text": "podcast",
    "start": "2033639",
    "end": "2036639"
  }
]
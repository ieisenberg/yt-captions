[
  {
    "text": "hey folks if you're listening to this podcast or you read info.com you'd probably like to keep up on the latest",
    "start": "719",
    "end": "5920"
  },
  {
    "text": "trends and software I invite you to follow your curiosity at cuon San Francisco November 18th to the 22nd",
    "start": "5920",
    "end": "13240"
  },
  {
    "text": "where you'll hear directly from Engineers who will share how they Implement Innovations and real world scenarios explore tracks like",
    "start": "13240",
    "end": "18840"
  },
  {
    "text": "engineering productivity programming languages and paradigms for the next decade generative Ai and production and",
    "start": "18840",
    "end": "24519"
  },
  {
    "text": "the signature architectures you've always wondered about which I'll be hosting come learn from practicing senior software developers and how they",
    "start": "24519",
    "end": "30960"
  },
  {
    "text": "are adopting emerging Trends find out more about the conference at qcon sf.com we hope to see you",
    "start": "30960",
    "end": "39000"
  },
  {
    "text": "there hi everyone here at infoq we try to provide our audience with information about the latest software Innovations",
    "start": "41640",
    "end": "47199"
  },
  {
    "text": "and Trends and I personally recognize it sometimes there's a lot of new information out there and we tend to focus on the subjects that are most",
    "start": "47199",
    "end": "53800"
  },
  {
    "text": "relevant to what we're currently working on and what we're interested in then sometimes you realize that what used to",
    "start": "53800",
    "end": "60199"
  },
  {
    "text": "be one of those subjects off to the side is now right in front of you and you can't ignore it anymore and I'll admit",
    "start": "60199",
    "end": "66400"
  },
  {
    "text": "that was my Approach for a lot of the news over the past decade or so about Big Data machine learning artificial",
    "start": "66400",
    "end": "73680"
  },
  {
    "text": "intelligence I found it interesting but because it wasn't what I was working with I had this very thin highlevel",
    "start": "73680",
    "end": "80799"
  },
  {
    "text": "understanding of most of those topics and that's fine that's how software Architects usually approach a problem we",
    "start": "80799",
    "end": "86520"
  },
  {
    "text": "tend to be t-shaped in our knowledge we have a broad range of of subjects we need to know about and we only go deep",
    "start": "86520",
    "end": "92320"
  },
  {
    "text": "in our understanding of a few of them until we have to go deeper on in our understanding for something else so",
    "start": "92320",
    "end": "98680"
  },
  {
    "text": "that's where I think we've gotten with ML and AI it's no longer something off to the side Architects have to deal with",
    "start": "98680",
    "end": "105240"
  },
  {
    "text": "these every day they're front and center because product owners CTO CEOs maybe",
    "start": "105240",
    "end": "111320"
  },
  {
    "text": "even our customers are asking can you put some AI in that to just about everything it seems and that gets me to",
    "start": "111320",
    "end": "118479"
  },
  {
    "text": "today's episode I've invited Anthony Alford on to help explain some of these ML and AI Concepts that are now I think",
    "start": "118479",
    "end": "125880"
  },
  {
    "text": "required knowledge to Be an Effective software architect Anthony's voice will probably sound familiar because he's",
    "start": "125880",
    "end": "131000"
  },
  {
    "text": "another infoq editor he co-hosts the generally AI podcast with Roland Myton and I believe that just started its",
    "start": "131000",
    "end": "136920"
  },
  {
    "text": "second season so Anthony thanks for joining me on my episode of the infoq podcast thank you for having me so I",
    "start": "136920",
    "end": "144200"
  },
  {
    "text": "think a useful way to go through this today in our discussion is to kind of do this big AI glossy there's a lot of",
    "start": "144200",
    "end": "150360"
  },
  {
    "text": "terms to get thrown around and that's where I think Architects need to understand what is that term and then",
    "start": "150360",
    "end": "156080"
  },
  {
    "text": "figure out how much do I need to know about it so they can have intelligent conversations with their co-workers I want to provide today just enough",
    "start": "156080",
    "end": "163159"
  },
  {
    "text": "information so those Architects can go and have those conversations and realize",
    "start": "163159",
    "end": "168480"
  },
  {
    "text": "when something comes up and they have to start implementing that for a project or thinking about into design they have a",
    "start": "168480",
    "end": "174319"
  },
  {
    "text": "little bit more context and that will help them be more successful as they do more research sound like a plan sounds",
    "start": "174319",
    "end": "179400"
  },
  {
    "text": "great all right so first give me your definition of what is ai ai is",
    "start": "179400",
    "end": "185400"
  },
  {
    "text": "artificial intelligence so and we're done hey and in fact when I talk to",
    "start": "185400",
    "end": "191480"
  },
  {
    "text": "people about this I say AI really tells you more about the difficulty of the problem you're trying to solve it's not",
    "start": "191480",
    "end": "198440"
  },
  {
    "text": "an actual solution the good news is when most people are talking about AI they're",
    "start": "198440",
    "end": "203640"
  },
  {
    "text": "actually talking about some type of machine learning and machine learning is definitely a technology you know it's a",
    "start": "203640",
    "end": "211200"
  },
  {
    "text": "Well studied well- defined branch of science and in fact the part of machine",
    "start": "211200",
    "end": "217120"
  },
  {
    "text": "learning that most people mean now is something called Deep learning which is also known as neural networks and this",
    "start": "217120",
    "end": "224239"
  },
  {
    "text": "has been around since the 1950s so it's pretty widely studied yeah I think that's the idea that AI is not a product",
    "start": "224239",
    "end": "231400"
  },
  {
    "text": "you can go buy you can go buy a machine learning model you can build a machine learning model you can add it to your",
    "start": "231400",
    "end": "236799"
  },
  {
    "text": "system but you can't just say I want an AI but that's the way people are talking about it so let's start talking about",
    "start": "236799",
    "end": "243239"
  },
  {
    "text": "the things that exist the tangible elements so give me some examples of what people are thinking when they say I",
    "start": "243239",
    "end": "250319"
  },
  {
    "text": "want AI in my system what are the machine learning elements they're talking about of course you know most",
    "start": "250319",
    "end": "255959"
  },
  {
    "text": "people are talking about something like a large language model or a generative AI what I like to tell people as",
    "start": "255959",
    "end": "262919"
  },
  {
    "text": "software developers the way you can think about these things is it's a function we write code that calls",
    "start": "262919",
    "end": "269280"
  },
  {
    "text": "functions in external libraries all the time that's at one level you can think",
    "start": "269280",
    "end": "274400"
  },
  {
    "text": "about it it is just a function that you can call the inputs and outputs are quite complex right the input might be",
    "start": "274400",
    "end": "281360"
  },
  {
    "text": "an entire image or a podcast audio and the output might also be something big",
    "start": "281360",
    "end": "287440"
  },
  {
    "text": "like the transcript of the uh podcast or a summary and so that's where we get into the most people are thinking of",
    "start": "287440",
    "end": "294840"
  },
  {
    "text": "generated AI gen AI right so give me some text give me an image give me some",
    "start": "294840",
    "end": "300120"
  },
  {
    "text": "sound that's the input and the Machine learning model it all comes down to ones and zeros right it's breaking that up",
    "start": "300120",
    "end": "306160"
  },
  {
    "text": "into some sort of data it can understand and doing math on it right yes that's",
    "start": "306160",
    "end": "311199"
  },
  {
    "text": "right and so again uh when I talk to software developers I say when you think about the input and output of these",
    "start": "311199",
    "end": "318400"
  },
  {
    "text": "functions the input and output is just an array of floats and actually it's possibly a",
    "start": "318400",
    "end": "326280"
  },
  {
    "text": "multi-dimensional array and so the abstract term for that is a tensor and if you look at some of the common",
    "start": "326280",
    "end": "332360"
  },
  {
    "text": "machine learning libraries they're going to use the word tensor it just means a multi-dimensional array but you have to",
    "start": "332360",
    "end": "338280"
  },
  {
    "text": "be able to express all your inputs and outputs as these tensors yeah see these are the things I learned in math like",
    "start": "338280",
    "end": "345160"
  },
  {
    "text": "back in University years ago but because I'm not a data scientist I don't use those words every day and forget oh yeah",
    "start": "345160",
    "end": "351800"
  },
  {
    "text": "a multi-dimensional array I understand what that is but exactly that's like several extra syllables I don't need to",
    "start": "351800",
    "end": "357120"
  },
  {
    "text": "say so I've got these tensors I'm putting in in what do I do with it how do I build one of these models okay so",
    "start": "357120",
    "end": "364440"
  },
  {
    "text": "uh if you want to build your own model which you actually might want to consider not doing that we but we can",
    "start": "364440",
    "end": "370759"
  },
  {
    "text": "talk about that later but in general the way these models are built is a process called training and supervised learning",
    "start": "370759",
    "end": "378560"
  },
  {
    "text": "and what you really need again from our perspective as software developers we need a suite of unit tests a really big",
    "start": "378560",
    "end": "385400"
  },
  {
    "text": "Suite of unit tests which means just what we expect some inputs to the",
    "start": "385400",
    "end": "391000"
  },
  {
    "text": "function and expected outputs from the function and the training process",
    "start": "391000",
    "end": "396840"
  },
  {
    "text": "essentially is randomly writing a function it starts with a random function and then just keeps keeps",
    "start": "396840",
    "end": "402080"
  },
  {
    "text": "fixing bugs in that function until the training till the unit test pass somewhat they don't actually have to",
    "start": "402080",
    "end": "409000"
  },
  {
    "text": "exactly pass you also tell it here's a way to compute how bad the tests are",
    "start": "409000",
    "end": "414960"
  },
  {
    "text": "failing and just make that number smaller every time and that's where you get to the probability that that this",
    "start": "414960",
    "end": "420720"
  },
  {
    "text": "all comes down to math so again I'm used to writing unit tests and I say my inputs are A and B and I expect C to",
    "start": "420720",
    "end": "427400"
  },
  {
    "text": "come out you're saying here's a and b and I expect C but here's how you can tell how close you are to C exactly yeah",
    "start": "427400",
    "end": "435319"
  },
  {
    "text": "you know it depends on the data type you know I mentioned they all turn into tensors but the easiest one is let's say",
    "start": "435319",
    "end": "441240"
  },
  {
    "text": "you're building a model that outputs an actual number so maybe you're building a model that the inputs are things like",
    "start": "441240",
    "end": "448000"
  },
  {
    "text": "the square feet of a house and the number of rooms Etc and the output is the expected house price so if you give",
    "start": "448000",
    "end": "455120"
  },
  {
    "text": "it unit tests you can get a measure of how of the unit test is just by subtracting the number that you get out",
    "start": "455120",
    "end": "462080"
  },
  {
    "text": "from the number that you expect so you can do sum of squared errors then the machine learning will just keep changing",
    "start": "462080",
    "end": "468520"
  },
  {
    "text": "the function to make that sum of squared errors lower with something like text or an image it may be a little trickier to",
    "start": "468520",
    "end": "475319"
  },
  {
    "text": "come up with a measurement of how off the unit tests are so we're getting into all the ideas of gen AI let's just take",
    "start": "475319",
    "end": "482639"
  },
  {
    "text": "the text example for now and we'll leave off audio and images and everything else because it's the same principles but",
    "start": "482639",
    "end": "488120"
  },
  {
    "text": "most people are familiar with interacting with chat GPT I type in something and it gives me a bunch of",
    "start": "488120",
    "end": "494159"
  },
  {
    "text": "text how did those come about and how did we create these llms that people said when I type in this sentence I",
    "start": "494159",
    "end": "501280"
  },
  {
    "text": "expect this sentence in response okay so how long of the story do you want here",
    "start": "501280",
    "end": "507520"
  },
  {
    "text": "so we can go back to 2017 or even earlier let's give the high level details if it's an important Milestone",
    "start": "507520",
    "end": "514120"
  },
  {
    "text": "that I think it's useful to sometimes have the origin story so the short",
    "start": "514120",
    "end": "519560"
  },
  {
    "text": "answer is these things like chat GPT or what are called language models the input of the function is a sequence of",
    "start": "519560",
    "end": "526120"
  },
  {
    "text": "words or more abstractly tokens the output is all possible tokens along with",
    "start": "526120",
    "end": "533880"
  },
  {
    "text": "their probability of being the next one so let me give you an example if I give",
    "start": "533880",
    "end": "539079"
  },
  {
    "text": "you the input sequence Once Upon A what's the next word I'm going to",
    "start": "539079",
    "end": "544920"
  },
  {
    "text": "guess time right so what the llm will give you is will give you every possible word with its probability and time will",
    "start": "544920",
    "end": "552959"
  },
  {
    "text": "have a very high probability of being the next one and then something like pancake would have a lower probability",
    "start": "552959",
    "end": "560360"
  },
  {
    "text": "so that's a probability distribution we actually know the answer so in training",
    "start": "560360",
    "end": "566640"
  },
  {
    "text": "we know the in the unit test the word time has the probability of 100% And",
    "start": "566640",
    "end": "571680"
  },
  {
    "text": "every other word has the probability of zero that's one probability distribution the probability distribution it gives us",
    "start": "571680",
    "end": "578360"
  },
  {
    "text": "is another one and there's a measure of how different those are that's called cross entropy loss so that's how you can",
    "start": "578360",
    "end": "586680"
  },
  {
    "text": "train it to improve that so it'll shift its output distribution to have time be closer to 100% and everything else zero",
    "start": "586680",
    "end": "594320"
  },
  {
    "text": "so that's a language model and the method that I described is really how",
    "start": "594320",
    "end": "600240"
  },
  {
    "text": "they're trained you take a whole bunch of text and you take sequences of that",
    "start": "600240",
    "end": "605519"
  },
  {
    "text": "text and you chop out a word or multiple words and you have it fill in those",
    "start": "605519",
    "end": "611800"
  },
  {
    "text": "words and the way it fills it in is it gives you a probability distribution for every possible word and ideally the one",
    "start": "611800",
    "end": "619760"
  },
  {
    "text": "you chopped out has the highest probability gotcha so it's like the image recognitions that we've seen for",
    "start": "619760",
    "end": "625920"
  },
  {
    "text": "years we've had image recognition models it's like how do I identify this is a dog this is a cat and we trained it it's",
    "start": "625920",
    "end": "631800"
  },
  {
    "text": "like this is a cat this is a dog and it started putting that into its model somehow it's like when I see this array of pixels yep the answer is such a",
    "start": "631800",
    "end": "639800"
  },
  {
    "text": "probability that it is a dog in that picture yeah and in general if we want to talk about data types this is an",
    "start": "639800",
    "end": "646519"
  },
  {
    "text": "enumeration so with enumeration data types this thing is a what you might call a classifier you were talking about",
    "start": "646519",
    "end": "653120"
  },
  {
    "text": "a dog or a cat it'll give you an answer for every possible output class so every",
    "start": "653120",
    "end": "658800"
  },
  {
    "text": "possible eneration value has a probability associated with it you want the real one to be close to 100% And you",
    "start": "658800",
    "end": "665600"
  },
  {
    "text": "want the rest of them to be close to zero and it's the same for text you know the entire vocabulary is given in a",
    "start": "665600",
    "end": "672839"
  },
  {
    "text": "probability distribution and so that's when you hear about how big these models are it's how much they've been trained",
    "start": "672839",
    "end": "678920"
  },
  {
    "text": "on the assumption is that chat GPT and gp4 was basically trained on everything",
    "start": "678920",
    "end": "684240"
  },
  {
    "text": "that you could possibly get off the internet I don't know how true that is but that's kind of the way people talk about it's close enough to be true so",
    "start": "684240",
    "end": "690959"
  },
  {
    "text": "that that's the data set there's also the number of parameters that make up",
    "start": "690959",
    "end": "696000"
  },
  {
    "text": "the model so when we're talking about these deep learning models those are neural networks and neural networks are",
    "start": "696000",
    "end": "703839"
  },
  {
    "text": "at heart matrix multiplication I mentioned those input tensors you could think of them as like",
    "start": "703839",
    "end": "709880"
  },
  {
    "text": "matrices you can multiply that times the models Matrix so we talk about those",
    "start": "709880",
    "end": "717959"
  },
  {
    "text": "Matrix entries are sometimes called weights because ultimately what you're doing is a weighted sum of the input",
    "start": "717959",
    "end": "724680"
  },
  {
    "text": "values so when we talk about how big is the model we're talking about how many",
    "start": "724680",
    "end": "730360"
  },
  {
    "text": "Matrix parameters are in that thing you know for GPT 4 we don't know we were not",
    "start": "730360",
    "end": "736760"
  },
  {
    "text": "told if you go all the way back to gpt2 there was like one and a half",
    "start": "736760",
    "end": "742639"
  },
  {
    "text": "billion parameters in the matrices inside it yeah I think we're now seeing",
    "start": "742639",
    "end": "748880"
  },
  {
    "text": "100 of billions hundreds of billions yeah so where does large language Model come in is it in the billion yeah well",
    "start": "748880",
    "end": "756480"
  },
  {
    "text": "so it's not like a hard number but what we're seeing now is if something is tens",
    "start": "756480",
    "end": "762600"
  },
  {
    "text": "or hundreds of billions that's probably large we have smaller ones now where",
    "start": "762600",
    "end": "768360"
  },
  {
    "text": "we'll see like llama or something like uh what is it Gemma from Google and fi",
    "start": "768360",
    "end": "775440"
  },
  {
    "text": "from Microsoft those are still billions but they're only you know from one to 10",
    "start": "775440",
    "end": "780839"
  },
  {
    "text": "billion is considered a small model now and that's small enough to run on your",
    "start": "780839",
    "end": "786000"
  },
  {
    "text": "laptop actually okay so you you just threw out several other names and these are the things that I'm talking about",
    "start": "786000",
    "end": "792040"
  },
  {
    "text": "that Architects like oh I've I think I've heard of llama uh Gemma sounds familiar and was it SII fi P Phi right",
    "start": "792040",
    "end": "801360"
  },
  {
    "text": "the Greek letter uh you know here in America we we fi but other places it's",
    "start": "801360",
    "end": "806600"
  },
  {
    "text": "fee yep and I know know you can go out and find details of some of these there's a site called hugging face that",
    "start": "806600",
    "end": "812959"
  },
  {
    "text": "I don't understand but you can go and find the models and you can test the models or what what is that so hugging",
    "start": "812959",
    "end": "819519"
  },
  {
    "text": "face you can kind of think of as the GitHub for language models and in fact you know I mentioned that Library they",
    "start": "819519",
    "end": "826320"
  },
  {
    "text": "have an SDK they have a library python Library you can install on your laptop that will behind the scenes download and",
    "start": "826320",
    "end": "833720"
  },
  {
    "text": "run these smaller language models that you can actually run on your machine and",
    "start": "833720",
    "end": "839560"
  },
  {
    "text": "so what they do is they have files that contain those Matrix entries that I mentioned and that's the composed model",
    "start": "839560",
    "end": "846759"
  },
  {
    "text": "if you will right like I always think of this is the the training is the I'm going to run my program and the output",
    "start": "846759",
    "end": "853680"
  },
  {
    "text": "is the model so the training process might take hours or days but once it's done it's done and it's baked and now I",
    "start": "853680",
    "end": "861040"
  },
  {
    "text": "have the model and now that model y for large language models or small language models you're saying it's something I",
    "start": "861040",
    "end": "866800"
  },
  {
    "text": "can put on my laptop some of those if they were smaller machine learning models we've been able to move those",
    "start": "866800",
    "end": "873199"
  },
  {
    "text": "around for a while right oh yeah oh yeah so we can think of two phases in the life cycle of machine learning model the",
    "start": "873199",
    "end": "879880"
  },
  {
    "text": "training that you mentioned and so we could think of that as developing a function and then once it's developed",
    "start": "879880",
    "end": "886519"
  },
  {
    "text": "once we've written the function we might build it and deploy it as a jar for example or or you know some some kind of",
    "start": "886519",
    "end": "893959"
  },
  {
    "text": "library that you can use the trained model is like that and when you load it up and you put an put into it and get an",
    "start": "893959",
    "end": "900040"
  },
  {
    "text": "output out that's called inference so like the model infers some",
    "start": "900040",
    "end": "905519"
  },
  {
    "text": "output from your input and so those are the two big chunks of the model life",
    "start": "905519",
    "end": "911320"
  },
  {
    "text": "cycle going back to the large language models where you're talking about predict the next word and then predict",
    "start": "911320",
    "end": "917519"
  },
  {
    "text": "the next word this is where it's kind of feeding it back in the way I've understood it is it's just autocomplete",
    "start": "917519",
    "end": "923920"
  },
  {
    "text": "on steroids that instead of one letter one word it's like I'll just do all of it and so keeps feeding that sentence",
    "start": "923920",
    "end": "930279"
  },
  {
    "text": "that it's building back into the context and so that's the next thing that's",
    "start": "930279",
    "end": "935560"
  },
  {
    "text": "right and you'll hear these models referred to as Auto regressive and that's exactly what they're doing you",
    "start": "935560",
    "end": "941639"
  },
  {
    "text": "start with initial input which sometimes we call that the prompt and we also call",
    "start": "941639",
    "end": "947519"
  },
  {
    "text": "the input to the model the context so the prompt is the initial context and",
    "start": "947519",
    "end": "953279"
  },
  {
    "text": "then it outputs one more token that's stuck on the end and then it feeds back",
    "start": "953279",
    "end": "959040"
  },
  {
    "text": "back is the new context and the process just repeats these things also are able to Output a token that basically says",
    "start": "959040",
    "end": "965920"
  },
  {
    "text": "stop and that's how they know to stop whereas i' I've tried that autocomplete with my phone where I just keep autoc",
    "start": "965920",
    "end": "972319"
  },
  {
    "text": "completing over and over it eventually produces gibberish yep but it is the exact same idea youve now said token a",
    "start": "972319",
    "end": "979399"
  },
  {
    "text": "few times and I keep saying word and I know the Layman is usually interchanging those and it's not exactly the same",
    "start": "979399",
    "end": "985959"
  },
  {
    "text": "thing that a token is not a word all the time what is a token in terms of these",
    "start": "985959",
    "end": "991040"
  },
  {
    "text": "language models you know when people first started it was words we're probably familiar with the idea with",
    "start": "991040",
    "end": "997040"
  },
  {
    "text": "search engines of doing things like stemming or things like that where the word itself doesn't actually become the",
    "start": "997040",
    "end": "1004040"
  },
  {
    "text": "token the reason you want to do something that's not exactly the word is I mentioned you can only get an output",
    "start": "1004040",
    "end": "1011199"
  },
  {
    "text": "that is one of the tokens that it knows about so you've seen things like well",
    "start": "1011199",
    "end": "1016560"
  },
  {
    "text": "let's just use the byes as tokens I think now it's bite pairs so basically",
    "start": "1016560",
    "end": "1022560"
  },
  {
    "text": "it's no longer at the word level a token is smaller than a word so you might see",
    "start": "1022560",
    "end": "1028400"
  },
  {
    "text": "a token be a couple of letters or characters or bittes and so what's the",
    "start": "1028400",
    "end": "1033558"
  },
  {
    "text": "advantage of shrinking those down so instead of predicting the next word is Once Upon a Time it would predict t and",
    "start": "1033559",
    "end": "1040280"
  },
  {
    "text": "then I and then M then e or something like that or TI or yeah and the reason",
    "start": "1040280",
    "end": "1045678"
  },
  {
    "text": "is so that you can output words that are not real words you know that wouldn't be in the regular vocabulary now is it",
    "start": "1045679",
    "end": "1052440"
  },
  {
    "text": "smart enough to say that time is one possible token and TI might be a different one does it break it down both",
    "start": "1052440",
    "end": "1058160"
  },
  {
    "text": "ways so the tokenization is that's almost become a commodity in itself most",
    "start": "1058160",
    "end": "1064720"
  },
  {
    "text": "people are not really looking at you know what the specific token data set is",
    "start": "1064720",
    "end": "1069919"
  },
  {
    "text": "but I think typically you want something a little bigger than one character but you want something smaller than a word",
    "start": "1069919",
    "end": "1076240"
  },
  {
    "text": "so this is something that researchers have experimented with yeah and and my",
    "start": "1076240",
    "end": "1081640"
  },
  {
    "text": "interaction with knowing the number of tokens counts is when I've played around these things used chat GPT or open AI",
    "start": "1081640",
    "end": "1089919"
  },
  {
    "text": "API it's measuring how many tokens are being used and you're being sometimes build by the number of tokens yeah",
    "start": "1089919",
    "end": "1096159"
  },
  {
    "text": "that's right because essentially the output is a token and the input we mentioned that's called the context the",
    "start": "1096159",
    "end": "1103760"
  },
  {
    "text": "models have a maximum size of the context or input in the number of tokens",
    "start": "1103760",
    "end": "1109679"
  },
  {
    "text": "it's it's in the order of thousands or maybe even hundreds of thousands now with a lot of these models but",
    "start": "1109679",
    "end": "1115320"
  },
  {
    "text": "eventually it will have to stop because effectively can't take a larger input",
    "start": "1115320",
    "end": "1120600"
  },
  {
    "text": "yeah and I remember people found those limits when chat GPT came out is you'd have this conversation that would go on and on and",
    "start": "1120600",
    "end": "1127440"
  },
  {
    "text": "on and pretty soon you you watch the the first part of your conversation just fall off the stack if you will yeah the",
    "start": "1127440",
    "end": "1134240"
  },
  {
    "text": "maximum context length is built into the model and there's a problem with the",
    "start": "1134240",
    "end": "1140280"
  },
  {
    "text": "algorithmic complexity is the square of that context size so as you get bigger",
    "start": "1140280",
    "end": "1146640"
  },
  {
    "text": "the model gets bigger as the square of that and that's how the runtime",
    "start": "1146640",
    "end": "1152080"
  },
  {
    "text": "increases as the square of that Etc and so that's where you're getting into the efficiency of these models there's been",
    "start": "1152080",
    "end": "1158679"
  },
  {
    "text": "some discussion of how much power is being consumed in data centers all around the world to build these models",
    "start": "1158679",
    "end": "1164720"
  },
  {
    "text": "run these models and that's one of those things you can get your head around like if you have this thing a lot it's a lot",
    "start": "1164720",
    "end": "1170320"
  },
  {
    "text": "a but if you have something that takes 30,000 32,000 tokens and you're saying",
    "start": "1170320",
    "end": "1175799"
  },
  {
    "text": "the square of that like that suddenly gets very very large oh yeah not only does it grow as a",
    "start": "1175799",
    "end": "1183520"
  },
  {
    "text": "square of that but it's like there's a big multiplier as well and training these",
    "start": "1183520",
    "end": "1189080"
  },
  {
    "text": "models consumes so much power only the people who do it know how much but",
    "start": "1189080",
    "end": "1194200"
  },
  {
    "text": "really you know they're they're just looking at their Cloud Bill and nobody knows what the Cloud bill was for",
    "start": "1194200",
    "end": "1199760"
  },
  {
    "text": "training you gpt3 or four but it's a lot yeah so that's why people are looking",
    "start": "1199760",
    "end": "1205679"
  },
  {
    "text": "not to build your own model most people are not in the business of needing to create their own llm these things are",
    "start": "1205679",
    "end": "1212840"
  },
  {
    "text": "done but people are using them to replace Google searches and one of the",
    "start": "1212840",
    "end": "1218960"
  },
  {
    "text": "problems is you don't have the context because the model wasn't trained on current events it's not searching Google",
    "start": "1218960",
    "end": "1224600"
  },
  {
    "text": "and giving you results it's just predicting words exactly now they are trying to build that in so if you use",
    "start": "1224600",
    "end": "1231240"
  },
  {
    "text": "Bing Bing is actually using gp4 and it will include search results in its",
    "start": "1231240",
    "end": "1237480"
  },
  {
    "text": "answer which when we get to the I don't want to spoiler when we get to rag we can talk about that well let's uh let's",
    "start": "1237480",
    "end": "1244640"
  },
  {
    "text": "leave rag off to the side a little bit let's let's dig a little bit into Transformer without like rewriting the",
    "start": "1244640",
    "end": "1249919"
  },
  {
    "text": "entire history I think you and Roland have talked about that a little bit on your podcast right so we've we've",
    "start": "1249919",
    "end": "1255200"
  },
  {
    "text": "mentioned llms and in general and GPT family in particular well the T in GPT",
    "start": "1255200",
    "end": "1261679"
  },
  {
    "text": "stands for Transformer and this was something that a Google research team came up with in 2017 they wrote a paper",
    "start": "1261679",
    "end": "1269159"
  },
  {
    "text": "called attention is all you need they were working on translation and you know before that the",
    "start": "1269159",
    "end": "1275960"
  },
  {
    "text": "translation models were using recursion which is different from what we were talking about with auto regression but",
    "start": "1275960",
    "end": "1281640"
  },
  {
    "text": "anyway so they came up with this model that really just uses a a feature called attention or a mechanism called",
    "start": "1281640",
    "end": "1288240"
  },
  {
    "text": "attention and they called it the Transformer and so now really all the language models",
    "start": "1288240",
    "end": "1295240"
  },
  {
    "text": "are based on this that's what the T and GPT stands for GPT stands for generative",
    "start": "1295240",
    "end": "1301039"
  },
  {
    "text": "pre-trained Transformer and they all use this attention mechanism and you could",
    "start": "1301039",
    "end": "1306480"
  },
  {
    "text": "think of attention as a way for the model to pick out what's important in that input sequence the word is I think",
    "start": "1306480",
    "end": "1314480"
  },
  {
    "text": "sometimes used in it's similar to information retrieval so they uses a lot of Concepts like queries and keys and",
    "start": "1314480",
    "end": "1321200"
  },
  {
    "text": "values but at a high level it's a way for the model to you know given that input sequence identify the important",
    "start": "1321200",
    "end": "1328159"
  },
  {
    "text": "parts of it and use that to generate the next token so it might throw out some of",
    "start": "1328159",
    "end": "1334200"
  },
  {
    "text": "your input or recategorize it and say these are the important words in that",
    "start": "1334200",
    "end": "1340880"
  },
  {
    "text": "context so the mathematics is you know it finds keys that match the query and",
    "start": "1340880",
    "end": "1346919"
  },
  {
    "text": "then Returns the values that are associated with those and so a lot of times it does focus on certain parts of",
    "start": "1346919",
    "end": "1352640"
  },
  {
    "text": "the input versus other pieces that that's where waiting comes into play right exactly that's how it is you",
    "start": "1352640",
    "end": "1358799"
  },
  {
    "text": "mentioned that these matrices have weights on them and so it's going to figure out which words or parts of that",
    "start": "1358799",
    "end": "1365320"
  },
  {
    "text": "input and that that one word doesn't always have the same weight it's in the context of that input it might have more",
    "start": "1365320",
    "end": "1371799"
  },
  {
    "text": "weight yeah you did a better job explaining that than I did it's not my first time trying to explain this so I",
    "start": "1371799",
    "end": "1377120"
  },
  {
    "text": "get a little bit better every time again one of the points of why I wanted to do this this episode so we've got",
    "start": "1377120",
    "end": "1383919"
  },
  {
    "text": "Transformers just a term and the attention that's how we're figuring out what goes in that outputs in the case of",
    "start": "1383919",
    "end": "1389960"
  },
  {
    "text": "GPT it outputs GPT but that's a branded term llm is the generic term right it's",
    "start": "1389960",
    "end": "1395600"
  },
  {
    "text": "like right Kleenex versus tissue let's say I want to use one of these llms in my application this is the thing that my",
    "start": "1395600",
    "end": "1402799"
  },
  {
    "text": "product owner my CEO is like put some AI on it I want to look like we're being Innovative we've got have something that",
    "start": "1402799",
    "end": "1409159"
  },
  {
    "text": "is this predictive thing like look at how it looked at our model and comes up with something how do we go about doing",
    "start": "1409159",
    "end": "1416080"
  },
  {
    "text": "that can I uh plug an infoq piece already so just earlier this year I",
    "start": "1416080",
    "end": "1423440"
  },
  {
    "text": "edited the emag the Practical applications of generative AI E Magazine",
    "start": "1423440",
    "end": "1429120"
  },
  {
    "text": "and we had several experts on llms in particular talk about this so definitely",
    "start": "1429120",
    "end": "1434520"
  },
  {
    "text": "recommend everybody read that but what they recommended is you know you have",
    "start": "1434520",
    "end": "1440159"
  },
  {
    "text": "publicly available commercial llms like gp4 chat GPT you know there's also",
    "start": "1440159",
    "end": "1448159"
  },
  {
    "text": "Claude there's also Google's Gemini AWS has some as well anyway if you find one",
    "start": "1448159",
    "end": "1455440"
  },
  {
    "text": "of these that seems to work try it out so you can quickly adopt llm",
    "start": "1455440",
    "end": "1460960"
  },
  {
    "text": "functionality by using one of these commercial ones and it's just an API it's a web-based API and so call it",
    "start": "1460960",
    "end": "1468760"
  },
  {
    "text": "using an SDK so it looks like any kind of web service so that's number one so",
    "start": "1468760",
    "end": "1474240"
  },
  {
    "text": "number two for longterm cost maybe right so because it's a web service and a API",
    "start": "1474240",
    "end": "1480360"
  },
  {
    "text": "you're paying per like we said we're paying per token it's actually probably pretty cheap but longer term there's",
    "start": "1480360",
    "end": "1487240"
  },
  {
    "text": "cost concerns and there may be privacy concerns because these commercial llms",
    "start": "1487240",
    "end": "1493679"
  },
  {
    "text": "have gotten better at their promises about we're not going to keep your data we're keep your data safe but there's",
    "start": "1493679",
    "end": "1500399"
  },
  {
    "text": "also the data that it gives you back in the case of say like code generation I",
    "start": "1500399",
    "end": "1505840"
  },
  {
    "text": "think there was a lawsuit just recently but I think that people that whose code was used to train this they're saying",
    "start": "1505840",
    "end": "1512320"
  },
  {
    "text": "that this thing is outputting my code right so there's concerns about copyright violation anyway longer term",
    "start": "1512320",
    "end": "1519360"
  },
  {
    "text": "if you want to bring that llm capability inhouse you can use one of these open",
    "start": "1519360",
    "end": "1524520"
  },
  {
    "text": "source models you can run it on your own or in your own cloud or you can run it",
    "start": "1524520",
    "end": "1530919"
  },
  {
    "text": "in a public Cloud but on your own machine and then you have more control",
    "start": "1530919",
    "end": "1536640"
  },
  {
    "text": "over that yeah it's kind of the build versus buy model right ex you can and",
    "start": "1536640",
    "end": "1541919"
  },
  {
    "text": "and I like the idea of let's see if this is going to work do the experiments run those tests on the public one and maybe",
    "start": "1541919",
    "end": "1548880"
  },
  {
    "text": "put some very tight guard rails to make sure you don't aren't sending private data and I think it was to plug another",
    "start": "1548880",
    "end": "1554880"
  },
  {
    "text": "infoq thing recently we had the AIML Tren report came out and I listen to",
    "start": "1554880",
    "end": "1560320"
  },
  {
    "text": "that podcast and that was one where it mentioned that because they were they were setting up so many screens to",
    "start": "1560320",
    "end": "1566520"
  },
  {
    "text": "filter and clean out the data before sending it to open AI or whichever API",
    "start": "1566520",
    "end": "1571720"
  },
  {
    "text": "they were using that scrubbed out some of the important context and the results coming back weren't as good once you",
    "start": "1571720",
    "end": "1578279"
  },
  {
    "text": "brought the model in housee and you could say oh we own the data it never leaves our Network we'll send it everything all of a sudden your quality",
    "start": "1578279",
    "end": "1584480"
  },
  {
    "text": "goes up too yeah so it's it's definitely very easy to EXP experiment with and if",
    "start": "1584480",
    "end": "1590039"
  },
  {
    "text": "you find that the experiment works it may make sense to bring it in house so that's the short answer yeah like you",
    "start": "1590039",
    "end": "1596159"
  },
  {
    "text": "said if you want to pay per use and it's easy to get started that's one way to go",
    "start": "1596159",
    "end": "1601960"
  },
  {
    "text": "when you're talking about bringing it inous you mentioned you can have it on your own cloud like we're on Azure AWS",
    "start": "1601960",
    "end": "1607120"
  },
  {
    "text": "is that basically I spin up an ec2 instance and I just install my own that's one way of course you know the",
    "start": "1607120",
    "end": "1613880"
  },
  {
    "text": "service providers like AWS are going to give you a value ad version where they spin it up for you and it's very much",
    "start": "1613880",
    "end": "1621360"
  },
  {
    "text": "like the regular model where you pay per use but yeah you could do that you could do run it on ec2 yeah are you doing the",
    "start": "1621360",
    "end": "1627960"
  },
  {
    "text": "you know product as a service the platform as a service the infrastructure as a service then you can do whatever you want on it and so your results May",
    "start": "1627960",
    "end": "1634559"
  },
  {
    "text": "Vary but that might be another way to do that next phase of your experiment as you're trying to figure out what this is",
    "start": "1634559",
    "end": "1641320"
  },
  {
    "text": "how easy is it for me to spin up something put out a model there and say",
    "start": "1641320",
    "end": "1646600"
  },
  {
    "text": "okay here's our results us this public API and here's if we bring",
    "start": "1646600",
    "end": "1651679"
  },
  {
    "text": "it in house with our private API maybe look at the cost maybe look at the quality of the results yep for sure so",
    "start": "1651679",
    "end": "1657480"
  },
  {
    "text": "how are people comparing those things what is the apples to Apple's comparison of I'm going to use open AI versus one",
    "start": "1657480",
    "end": "1664360"
  },
  {
    "text": "of the things I pull off of hugging face so this is actually a problem so as these things get better it's kind of",
    "start": "1664360",
    "end": "1670720"
  },
  {
    "text": "tricky to judge so with with your you know in the olden days where we had things like linear regression and we had",
    "start": "1670720",
    "end": "1678360"
  },
  {
    "text": "that supervised learning where we know the answer we can get a metric that's based on something like accuracy right",
    "start": "1678360",
    "end": "1685360"
  },
  {
    "text": "how what is the total sum of squared error but nowadays you know how good is",
    "start": "1685360",
    "end": "1691120"
  },
  {
    "text": "the output of chat GPT well if you're having it do your homework if you get an",
    "start": "1691120",
    "end": "1696600"
  },
  {
    "text": "A then it was pretty good and in fact believe it or not this is very much a common thing that they're doing now with",
    "start": "1696600",
    "end": "1703240"
  },
  {
    "text": "these models is they're saying we train this model it can take the AP chemist",
    "start": "1703240",
    "end": "1708399"
  },
  {
    "text": "exam and make a passing grade so another thing I see a lot in the",
    "start": "1708399",
    "end": "1714399"
  },
  {
    "text": "literature is if they're comparing their model to a baseline model they'll have",
    "start": "1714399",
    "end": "1719640"
  },
  {
    "text": "both models produce the output from the same input and have human judges compare them and it's sort of like a you know",
    "start": "1719640",
    "end": "1727080"
  },
  {
    "text": "Coke versus Pepsi which you know four out of five people chose Pepsi and even",
    "start": "1727080",
    "end": "1732679"
  },
  {
    "text": "more fun is do that but with chat GPT as the judge and believe it or not a lot of",
    "start": "1732679",
    "end": "1739399"
  },
  {
    "text": "people are doing that as well so I guess the answer is it's not easy yeah that's",
    "start": "1739399",
    "end": "1745960"
  },
  {
    "text": "where I tend to say these things are non-deterministic you talked about the probability like you don't know that the answer is going to come out so your test",
    "start": "1745960",
    "end": "1752039"
  },
  {
    "text": "is not I asked this question I got this answer because you don't necessarily",
    "start": "1752039",
    "end": "1757440"
  },
  {
    "text": "know what types of questions are going to be going in so you don't know what outputs are going to come out yeah",
    "start": "1757440",
    "end": "1762559"
  },
  {
    "text": "exactly and that's actually one of the most scary things is you don't know what",
    "start": "1762559",
    "end": "1768200"
  },
  {
    "text": "going to come out something very unpleasant or embarrassing might come out and that's really got people",
    "start": "1768200",
    "end": "1774200"
  },
  {
    "text": "concerned about using these things in production environments yeah but I will say one thing again talking back to my",
    "start": "1774200",
    "end": "1781159"
  },
  {
    "text": "e- magazine one of the my experts said before you adopt llms in your",
    "start": "1781159",
    "end": "1786320"
  },
  {
    "text": "application you should have good success criteria lined out for that that may be",
    "start": "1786320",
    "end": "1791440"
  },
  {
    "text": "the harder part to do how will I know if it's successful and it's going to depend",
    "start": "1791440",
    "end": "1796760"
  },
  {
    "text": "on your application but it something you should think hard about well I like that because it puts back the question on the",
    "start": "1796760",
    "end": "1803480"
  },
  {
    "text": "product owners the CTO they're saying I need some AI in it what do you want to",
    "start": "1803480",
    "end": "1808559"
  },
  {
    "text": "have happen because there's a lot of places where you shouldn't put AI I work on an accounting",
    "start": "1808559",
    "end": "1814440"
  },
  {
    "text": "system you should not have it just guess your books so when we're talking about",
    "start": "1814440",
    "end": "1819919"
  },
  {
    "text": "using these for ourselves whether we're hosting them or bringing them in house how do we get those better quality",
    "start": "1819919",
    "end": "1825480"
  },
  {
    "text": "results do we just use them out of the box I had podcast a while ago and learned about retrieval augmented",
    "start": "1825480",
    "end": "1831399"
  },
  {
    "text": "generation I hear rag talked about a lot give me the high level overview of what that is and why that should be a a first",
    "start": "1831399",
    "end": "1838360"
  },
  {
    "text": "step to make your llm adoption better yeah so again on my my expert panel they",
    "start": "1838360",
    "end": "1843559"
  },
  {
    "text": "said the first thing is to try better prompts so we've probably heard of prompt engineering so we know that the",
    "start": "1843559",
    "end": "1850360"
  },
  {
    "text": "way you phrase something to chat GPT makes a big difference in how it responds so definitely try doing stuff",
    "start": "1850360",
    "end": "1857519"
  },
  {
    "text": "with prom The Next Step retrieval augmented generation or rag I think we mentioned",
    "start": "1857519",
    "end": "1863760"
  },
  {
    "text": "the llms they're trained and they don't know anything that happened after that training so if we ask you know who won",
    "start": "1863760",
    "end": "1870240"
  },
  {
    "text": "the football game last night it doesn't know or it might not say it doesn't know it might actually make up something",
    "start": "1870240",
    "end": "1876720"
  },
  {
    "text": "completely not true well this is also a problem for a business where you want it",
    "start": "1876720",
    "end": "1882240"
  },
  {
    "text": "to know about your internal knowledge base right if you want it to know things that are on your Wiki or in your",
    "start": "1882240",
    "end": "1889000"
  },
  {
    "text": "documentation things like that what rag is is you take your documents you break",
    "start": "1889000",
    "end": "1895000"
  },
  {
    "text": "them up into chunks but essentially you take a big chunk of text and you run it through an llm that generates a single",
    "start": "1895000",
    "end": "1903159"
  },
  {
    "text": "Vector for that chunk of text this is called an embedding and that Vector in some way",
    "start": "1903159",
    "end": "1909840"
  },
  {
    "text": "encodes the meaning of that text so you do this with all your documents and then",
    "start": "1909840",
    "end": "1915320"
  },
  {
    "text": "you have a database where each document has a vector associated with it that tells you something about its meaning",
    "start": "1915320",
    "end": "1922120"
  },
  {
    "text": "then when you go and ask the llm a question you do the same thing you take your question and you turn that into a",
    "start": "1922120",
    "end": "1927720"
  },
  {
    "text": "vector and the vector database lets you quickly and efficiently find vectors that are close to that and therefore are",
    "start": "1927720",
    "end": "1934919"
  },
  {
    "text": "close to your question in meaning it takes the content from that",
    "start": "1934919",
    "end": "1940519"
  },
  {
    "text": "and shoves that into the llm context along with your question and now it knows all that stuff along with your",
    "start": "1940519",
    "end": "1948559"
  },
  {
    "text": "question and we know that these llms are very good at if you give it a chunk of text and say explain this or here's a",
    "start": "1948559",
    "end": "1955600"
  },
  {
    "text": "question about this chunk of text it is quite good that's what the intention mechanism does is it lets it find parts",
    "start": "1955600",
    "end": "1962200"
  },
  {
    "text": "of that chunk of text that answer the question or solve the problem that you're asking the way I've heard that",
    "start": "1962200",
    "end": "1968919"
  },
  {
    "text": "explained is let's say I I do my search and instead of me writing a really you know elaborate prompt because I'm only",
    "start": "1968919",
    "end": "1975159"
  },
  {
    "text": "going to sit there and type for 30 seconds and like that's all the words I'm going to come up with instead I would say answer the question based on",
    "start": "1975159",
    "end": "1982519"
  },
  {
    "text": "these documents and I can give all those documents in the context and now it knows okay that's what I'm going to use",
    "start": "1982519",
    "end": "1988880"
  },
  {
    "text": "I'm not going to use just my base level llm predict the next word I'm going to",
    "start": "1988880",
    "end": "1994159"
  },
  {
    "text": "predict the next word based on this context right and the retrieval part is finding those documents automatically",
    "start": "1994159",
    "end": "2001200"
  },
  {
    "text": "and including them in the context for you that's the key component is because you if if you actually know the",
    "start": "2001200",
    "end": "2007200"
  },
  {
    "text": "documents and let's say somebody gave you here's our user manual answer",
    "start": "2007200",
    "end": "2013360"
  },
  {
    "text": "questions about it which is a pretty cool use case for someone who's saying customer service if the user manual is small",
    "start": "2013360",
    "end": "2020279"
  },
  {
    "text": "enough to fit into the context which it probably is at hundreds of thousands of tokens then that's great but maybe you",
    "start": "2020279",
    "end": "2026440"
  },
  {
    "text": "don't have that maybe you have a bunch of like knowledge based articles and so this will go and find the right",
    "start": "2026440",
    "end": "2032279"
  },
  {
    "text": "knowledge based article and then answer the question based on that right right because our knowledge base has tens of thousands of articles as opposed to you",
    "start": "2032279",
    "end": "2039120"
  },
  {
    "text": "know a couple hundred Pages exactly so yeah and like you're still using the llm which has all of its knowledge of here's",
    "start": "2039120",
    "end": "2045120"
  },
  {
    "text": "how I complete a sentence yep you are not building a new model based off of your exactly knowledge base or your your",
    "start": "2045120",
    "end": "2051919"
  },
  {
    "text": "training documents exactly but let's say you did want to do that and that might be a better solution in some cases this",
    "start": "2051919",
    "end": "2059358"
  },
  {
    "text": "process is called finetuning so I mentioned the T in GPT was Transformer the p is pre-trained",
    "start": "2059359",
    "end": "2068118"
  },
  {
    "text": "this is a whole subfield of machine learning called transfer learning where you train a model so you pre-train it",
    "start": "2068119",
    "end": "2075760"
  },
  {
    "text": "and it's general purpose then you can fine-tune it for a specific case in the case of",
    "start": "2075760",
    "end": "2081158"
  },
  {
    "text": "GPT two three and higher they found out you kind of don't need to it's pretty good on its own but what",
    "start": "2081159",
    "end": "2088960"
  },
  {
    "text": "the fine-tuning does is it's additional training on that model so instead of",
    "start": "2088960",
    "end": "2094800"
  },
  {
    "text": "using the model as is you restart the training proc process you've got your own set of unit tests so you've got your",
    "start": "2094800",
    "end": "2101599"
  },
  {
    "text": "own fine tuning data where you know the inputs you know the outputs the advantage is for fine-tuning it can be",
    "start": "2101599",
    "end": "2108640"
  },
  {
    "text": "much smaller than what is needed to train the full GPT and that's because",
    "start": "2108640",
    "end": "2113680"
  },
  {
    "text": "you're starting from what already exists you're not starting from a baseline of nothing and it's just saying tweak your",
    "start": "2113680",
    "end": "2118839"
  },
  {
    "text": "model and that's that's going back to things that I understood again at a superficial level with machine learning",
    "start": "2118839",
    "end": "2124880"
  },
  {
    "text": "training is that you can overtrain the dat like if you give too many answers in",
    "start": "2124880",
    "end": "2130200"
  },
  {
    "text": "one area it's like look we got to a 99.9% but then something comes in it",
    "start": "2130200",
    "end": "2135720"
  },
  {
    "text": "doesn't know about and it has no answer its way off base in this case if I'm trying to get the model to be very",
    "start": "2135720",
    "end": "2142480"
  },
  {
    "text": "specific to my company's applications my data that might be the desired outcome I",
    "start": "2142480",
    "end": "2148599"
  },
  {
    "text": "don't want someone to be using my customer service chatbot to ask about when's the next Taylor Swift show yeah",
    "start": "2148599",
    "end": "2155599"
  },
  {
    "text": "exactly and in fact so chat GP PT the original chat GPT and and newer models",
    "start": "2155599",
    "end": "2161240"
  },
  {
    "text": "they do fine-tune them to give more helpful answers and follow instructions",
    "start": "2161240",
    "end": "2167160"
  },
  {
    "text": "so this is something with GPT 3.5 again that model was pre-trained on",
    "start": "2167160",
    "end": "2173160"
  },
  {
    "text": "basically the whole internet and it could give you answers that were pretty good but they found that sometimes it",
    "start": "2173160",
    "end": "2179240"
  },
  {
    "text": "would just give you answers that were it's that whole joke about this is technically true but not at all useful",
    "start": "2179240",
    "end": "2186079"
  },
  {
    "text": "so they fine-tuned it to give you answers that are more helpful to follow instructions they call it alignment and",
    "start": "2186079",
    "end": "2193319"
  },
  {
    "text": "the way they do that is they have a small data set of this was the input here's the output you gave but this",
    "start": "2193319",
    "end": "2199160"
  },
  {
    "text": "output here is better and so they fine-tune it to work towards the more appropriate output I need to back up",
    "start": "2199160",
    "end": "2206079"
  },
  {
    "text": "just a little bit when you mentioned we're going to create these vectors and I'm gon to have a vector database I'm going to do a vector search another one",
    "start": "2206079",
    "end": "2212359"
  },
  {
    "text": "of those terms that gets thrown around and people are like well do I have a vector database I think Azure just announced that they're going to I think",
    "start": "2212359",
    "end": "2218520"
  },
  {
    "text": "it's in beta right now basically turn your Cosmos database into a vector database like flip a checkbox in the",
    "start": "2218520",
    "end": "2224839"
  },
  {
    "text": "portal and all of a sudden you have vectors what does that do for me why why is that an advantage okay so uh I have",
    "start": "2224839",
    "end": "2231720"
  },
  {
    "text": "an upcoming podcast on this very problem but so we mentioned that for a chunk of text you can create from that a vector",
    "start": "2231720",
    "end": "2238760"
  },
  {
    "text": "that encodes the meaning the vector is very high dimensional so it's hundreds maybe thousands of Dimensions you're",
    "start": "2238760",
    "end": "2246200"
  },
  {
    "text": "trying to solve the problem of given one vector how do you find those vectors in the database that are close",
    "start": "2246200",
    "end": "2252520"
  },
  {
    "text": "to that input Vector you could just run through all of them like you do a table",
    "start": "2252520",
    "end": "2257720"
  },
  {
    "text": "scan basically and sort the output and in most C you know that",
    "start": "2257720",
    "end": "2263480"
  },
  {
    "text": "probably is actually fine but if you're starting you know the complexity is high",
    "start": "2263480",
    "end": "2269359"
  },
  {
    "text": "enough that at a scale it's not going to perform great so what you need is something more like a b tree lookup",
    "start": "2269359",
    "end": "2275319"
  },
  {
    "text": "which you know is log in so the vector databases actually the vectors are",
    "start": "2275319",
    "end": "2280839"
  },
  {
    "text": "probably not the important part it's the nearest neighbor search this is the problem we're solving is given a vector",
    "start": "2280839",
    "end": "2287640"
  },
  {
    "text": "input what are the nearest neighbors to that Vector in your database that's the problem that you want to solve in a",
    "start": "2287640",
    "end": "2294560"
  },
  {
    "text": "efficient scalable way gotcha and so it's going through and looking at my data and saying here are the vectors for",
    "start": "2294560",
    "end": "2301640"
  },
  {
    "text": "all the parameters and based on that these are related words the you know",
    "start": "2301640",
    "end": "2307960"
  },
  {
    "text": "well no it's it's literally just it doesn't look at like it's just given two vectors how close are how close are the",
    "start": "2307960",
    "end": "2313760"
  },
  {
    "text": "vectors it doesn't know what it came from exactly right now once it finds the ones that are close then those are in",
    "start": "2313760",
    "end": "2320640"
  },
  {
    "text": "the same database row or there there's a pointer to the content that it came from which is what you actually care about",
    "start": "2320640",
    "end": "2327400"
  },
  {
    "text": "but the database its purpose is to do the nearest neighbor search where you give it a vector and it finds the top K",
    "start": "2327400",
    "end": "2336520"
  },
  {
    "text": "in its database that are closest to it yeah this is where I think we're going back to the beginning that AI is a",
    "start": "2336520",
    "end": "2342400"
  },
  {
    "text": "product isn't something that exists we've had fuzzy search techniques for a while this has been something people",
    "start": "2342400",
    "end": "2347839"
  },
  {
    "text": "have wanted and everyone's gotten used to Google I can type in whatever I want",
    "start": "2347839",
    "end": "2353079"
  },
  {
    "text": "and it figures out like you said you take the stems of the words and and so this is another one of those I didn't",
    "start": "2353079",
    "end": "2360160"
  },
  {
    "text": "give you exactly what to answer ask for so it's not a find this Row in the database but find records that are close",
    "start": "2360160",
    "end": "2367599"
  },
  {
    "text": "to what I intended and that's what you're getting to yeah so I I think you might find this referred to as semantic",
    "start": "2367599",
    "end": "2373440"
  },
  {
    "text": "search or maybe neural search the neural meaning that's how the vectors are generated from a neural network but it's",
    "start": "2373440",
    "end": "2380440"
  },
  {
    "text": "all about that I don't have a specific thing in mind to find the intent I guess llms really fall under in",
    "start": "2380440",
    "end": "2387640"
  },
  {
    "text": "my head the category of natural language processing right yes exactly yeah that that used to be a thing like I had data",
    "start": "2387640",
    "end": "2395079"
  },
  {
    "text": "scientists on my team who were working in the field of natural language processing yeah is that still a thing is",
    "start": "2395079",
    "end": "2401640"
  },
  {
    "text": "that just a subset or has it just gotten overwhelmed in the news by llms I think you could think of an llm as a tool to",
    "start": "2401640",
    "end": "2409200"
  },
  {
    "text": "solve natural language processing problems so for example I think you know",
    "start": "2409200",
    "end": "2414760"
  },
  {
    "text": "we used to look at things like named entity recognition parts of speech recognition that kind of thing that's",
    "start": "2414760",
    "end": "2421880"
  },
  {
    "text": "still something you have to do but an llm can do it right and it can do it",
    "start": "2421880",
    "end": "2426960"
  },
  {
    "text": "pretty well and works out of the box if you look at what I I think again we were",
    "start": "2426960",
    "end": "2433560"
  },
  {
    "text": "talking about Google and attention is all you need they came up with a version of that called Bert and it would do this",
    "start": "2433560",
    "end": "2440319"
  },
  {
    "text": "this stuff like named entities and parts of speech tagging and things like that gotcha and that's one of those llms are",
    "start": "2440319",
    "end": "2448200"
  },
  {
    "text": "these generalists find ways to make them more specific so if you have a specific use case in mind you can go down a fine",
    "start": "2448200",
    "end": "2454000"
  },
  {
    "text": "tuning route you can find a different model that's just closer and that's going to have those benefits of it's",
    "start": "2454000",
    "end": "2460720"
  },
  {
    "text": "going to cost less to run it's probably going to give better quality answers it's probably going to return faster I'm",
    "start": "2460720",
    "end": "2465880"
  },
  {
    "text": "assuming if it's less computational yeah and so this is one of the reasons people are excited about",
    "start": "2465880",
    "end": "2473480"
  },
  {
    "text": "llms is that they are very general that's one of the things where people",
    "start": "2473480",
    "end": "2478800"
  },
  {
    "text": "started saying is this General AI that's been the Holy Grail of AI research",
    "start": "2478800",
    "end": "2484079"
  },
  {
    "text": "forever you know yes we can make a program that play chess very well but it",
    "start": "2484079",
    "end": "2489160"
  },
  {
    "text": "can't drive a car you the Holy Grail is to build one model that can solve just",
    "start": "2489160",
    "end": "2495800"
  },
  {
    "text": "about any problem just if we flatter ourselves as human beings we can do lots",
    "start": "2495800",
    "end": "2500839"
  },
  {
    "text": "of different tasks we can do podcasts we can you know build model race cars or",
    "start": "2500839",
    "end": "2506920"
  },
  {
    "text": "read books you know so the Holy Grail of AI is you know one model to rule them",
    "start": "2506920",
    "end": "2512040"
  },
  {
    "text": "all and it llms could do so much without a additional training that's what uh one",
    "start": "2512040",
    "end": "2519560"
  },
  {
    "text": "of the early GPT papers was you know look we built this thing out of the box it can do summarization question",
    "start": "2519560",
    "end": "2526319"
  },
  {
    "text": "answering translation code Generation all these tasks and that's one of the things that got people really excited",
    "start": "2526319",
    "end": "2532800"
  },
  {
    "text": "about it it looks like it could do everything yeah I think it's the now how do we use it because that seems so",
    "start": "2532800",
    "end": "2538800"
  },
  {
    "text": "powerful but going back to your point you need to have a specific output in mind what is your goal why would you add",
    "start": "2538800",
    "end": "2544280"
  },
  {
    "text": "this because it sounds exciting everyone wants to use it but you have an intent of how does that",
    "start": "2544280",
    "end": "2549920"
  },
  {
    "text": "fit into your product how does that fit into your solution yeah it's always about what business problem am I trying",
    "start": "2549920",
    "end": "2555160"
  },
  {
    "text": "to solve and how do I know if I succeeded so we're way over on time I'm gonna have one last bonus round question",
    "start": "2555160",
    "end": "2561839"
  },
  {
    "text": "and we'll wrap it up yes a lot of people talk about having AI co-pilots I can't",
    "start": "2561839",
    "end": "2567200"
  },
  {
    "text": "remember how many Microsoft co-pilots and GitHub co-pilots and everything's a co-pilot distinguish that from an AI",
    "start": "2567200",
    "end": "2572920"
  },
  {
    "text": "agent because that's another term that's being thrown around they both sound like the embodiment of this thing as a person",
    "start": "2572920",
    "end": "2579720"
  },
  {
    "text": "and there's a whole different discussion about that but these are two different things what's a co-pilot versus an agent I think we did talk about this on the",
    "start": "2579720",
    "end": "2586040"
  },
  {
    "text": "trend podcast and agent has some degree of autonomy the co-pilot is you've got",
    "start": "2586040",
    "end": "2592000"
  },
  {
    "text": "to push the button to make it go eventually and you know again we I don't",
    "start": "2592000",
    "end": "2597480"
  },
  {
    "text": "want to turn this into AI fear the fear that people have of AI is autonomous AI",
    "start": "2597480",
    "end": "2602760"
  },
  {
    "text": "in my opinion if we can mitigate that fear by keeping things as Co Pilots then",
    "start": "2602760",
    "end": "2608040"
  },
  {
    "text": "maybe that's the way to go but I think the key is autonomy like you have to agree to the co-pilot's answer right and",
    "start": "2608040",
    "end": "2615119"
  },
  {
    "text": "then make it go the agents can do stuff on their own but maybe we have supervisor agents and like you said I don't know how to tell the output so I'm",
    "start": "2615119",
    "end": "2621880"
  },
  {
    "text": "G to ask chat GPT did I train my model correctly and you feed it back into yet another AI the AI agent story is you",
    "start": "2621880",
    "end": "2630480"
  },
  {
    "text": "have supervisor agents who watch the other ones and then it's who's watching the Watchers watches the Watchers yes",
    "start": "2630480",
    "end": "2636599"
  },
  {
    "text": "indeed well I really appreciate all your time I learned a lot I hope this was useful for the audience so me too it's always good",
    "start": "2636599",
    "end": "2644520"
  },
  {
    "text": "to go through and do this little refresher of here's what I think I understand but bounced off someone who who really knows I will be sure to",
    "start": "2644520",
    "end": "2651119"
  },
  {
    "text": "provide links to the things we mentioned the emag is great yes and then the trends report and podcast and some other",
    "start": "2651119",
    "end": "2657960"
  },
  {
    "text": "stuff so Anthony thanks again for joining me on the infoq podcast it was a pleasure thanks for having me and we",
    "start": "2657960",
    "end": "2663559"
  },
  {
    "text": "hope you'll join us again next time",
    "start": "2663559",
    "end": "2667559"
  },
  {
    "text": "[Music]",
    "start": "2671160",
    "end": "2685749"
  }
]
[
  {
    "text": "[Music]",
    "start": "3270",
    "end": "8730"
  },
  {
    "text": "thank you well in uh in reality I'm not going to talk about quizdb specifically um I just wanted to talk about the space",
    "start": "10639",
    "end": "18119"
  },
  {
    "text": "of uh time series databases how what what's going on in the space the history",
    "start": "18119",
    "end": "23320"
  },
  {
    "text": "of it and stuff like that and maybe I'll show you quest DB as well and how it fits in the whole whole scenario so",
    "start": "23320",
    "end": "30840"
  },
  {
    "text": "um oops so what what what are we going to learn today so um I wanted to go",
    "start": "30840",
    "end": "36960"
  },
  {
    "text": "through the evolution of um olap and time series databases um so in terms of um roughly",
    "start": "36960",
    "end": "45719"
  },
  {
    "text": "last 20 years what's been going on um maybe uh we're going to find out what",
    "start": "45719",
    "end": "51800"
  },
  {
    "text": "the uh what data model the databases seems to converge on and um as I said I'll mention Quest",
    "start": "51800",
    "end": "58640"
  },
  {
    "text": "DB a little bit in the end how we basically fit in the in this ecosystem yeah sounds",
    "start": "58640",
    "end": "67040"
  },
  {
    "text": "good so a bit about me so um my name is Vlad elenko um I'm from London I've been",
    "start": "67840",
    "end": "75040"
  },
  {
    "text": "here 20 years um I am co-founder and CTO of uh qu DB um I guess my",
    "start": "75040",
    "end": "82200"
  },
  {
    "text": "responsibilities are that we um build things that people want we went to uh",
    "start": "82200",
    "end": "88759"
  },
  {
    "text": "White combinat a few years ago and that's their kind of Mantra so we try not to go on the tangents and make sure",
    "start": "88759",
    "end": "94320"
  },
  {
    "text": "that we build things that you guys want it's not always easy to find out what",
    "start": "94320",
    "end": "99640"
  },
  {
    "text": "you want but um you know that's what we're trying to do and uh um the other",
    "start": "99640",
    "end": "105399"
  },
  {
    "text": "thing is uh building databases as it turns out is very very hard and uh we need to do it as a team and that's",
    "start": "105399",
    "end": "111960"
  },
  {
    "text": "that's what I do at Quest DB make sure everybody is um is enjoying the process because it's it's quite hard work",
    "start": "111960",
    "end": "120679"
  },
  {
    "text": "um okay so this is maybe a bit an orthodox introduction to time serious",
    "start": "121119",
    "end": "126719"
  },
  {
    "text": "database um so this is from what we see that organizations use time series",
    "start": "126719",
    "end": "132319"
  },
  {
    "text": "databases to um help acquire and uh and extract information from n data so um n",
    "start": "132319",
    "end": "141800"
  },
  {
    "text": "data is the data that just comes into existence U some people call it real time um new data but nent is a good",
    "start": "141800",
    "end": "151080"
  },
  {
    "text": "description of it and uh so those are kind of um",
    "start": "151080",
    "end": "158959"
  },
  {
    "text": "pictorial examples of um n data what it what it is so ultimately we see a role",
    "start": "158959",
    "end": "165879"
  },
  {
    "text": "of the database is to um deliver data from the source to to the user um that",
    "start": "165879",
    "end": "173680"
  },
  {
    "text": "that's that's basically in a nutshell what database does uh and the sources of this data could be in a and the top left",
    "start": "173680",
    "end": "181360"
  },
  {
    "text": "corner could be Financial uh data like trades prices events that going on in",
    "start": "181360",
    "end": "187319"
  },
  {
    "text": "the market in the uh top right corner is a industrial I um this is more of a",
    "start": "187319",
    "end": "193159"
  },
  {
    "text": "hardware kind of applications and uh people in this space they uh I guess",
    "start": "193159",
    "end": "199159"
  },
  {
    "text": "what they're trying to do is to monitor the uh the process and and and Implement",
    "start": "199159",
    "end": "205280"
  },
  {
    "text": "predictive um maintenance or see see what's about to break or breaks or maybe",
    "start": "205280",
    "end": "211159"
  },
  {
    "text": "will break in the future the the key uh well quite sort of different thing about",
    "start": "211159",
    "end": "216200"
  },
  {
    "text": "this this particular approach is that usually um data is being used in the",
    "start": "216200",
    "end": "221439"
  },
  {
    "text": "custom software so it's pulled out of the database and they run kind of custom algorithms to to basically infer some",
    "start": "221439",
    "end": "228959"
  },
  {
    "text": "data for the production production process um data can be used in transportation or Mobility should I say",
    "start": "228959",
    "end": "236760"
  },
  {
    "text": "so we see um we see this use cases um arise",
    "start": "236760",
    "end": "242079"
  },
  {
    "text": "from um how should I say so for example if if people develop sort of uh rocket",
    "start": "242079",
    "end": "248439"
  },
  {
    "text": "engines for sake of argument right so uh these rocket engines or or engines they",
    "start": "248439",
    "end": "254560"
  },
  {
    "text": "they Dino tested they tested from time to time and during the test a lot of data is collected from from the uh from",
    "start": "254560",
    "end": "262040"
  },
  {
    "text": "the test run and then this tests are compared so you basically from run to run you compare the test so maybe maybe",
    "start": "262040",
    "end": "269120"
  },
  {
    "text": "you detect anomalies in a test and the characteristic of this data is very high volume there's there's there's a lot of",
    "start": "269120",
    "end": "275000"
  },
  {
    "text": "data literally some airplane engines they produce an area of 140 million data",
    "start": "275000",
    "end": "281039"
  },
  {
    "text": "points a second that that kind of stuff right so um it's it's very tricky to to",
    "start": "281039",
    "end": "286800"
  },
  {
    "text": "to collect this data and the data probably we most familiar with um logs",
    "start": "286800",
    "end": "293120"
  },
  {
    "text": "and uh application metrics and whatnot so this is also time series data",
    "start": "293120",
    "end": "299960"
  },
  {
    "text": "or new data that sort of originates from these places um the time series data is is",
    "start": "299960",
    "end": "308400"
  },
  {
    "text": "kind of part of the um um Big Data scene so if you if you accumulate a lot of",
    "start": "308400",
    "end": "314919"
  },
  {
    "text": "Time series data that turns into big volume big data and um there's other",
    "start": "314919",
    "end": "321520"
  },
  {
    "text": "databases in this space and those are uh olop",
    "start": "321520",
    "end": "326840"
  },
  {
    "text": "databases and uh olop databases they people use them to typically extract",
    "start": "326840",
    "end": "334039"
  },
  {
    "text": "information from the existing data and uh there is a there's a slight",
    "start": "334039",
    "end": "339080"
  },
  {
    "text": "subtle difference between what time series databases do and allab databases do but I'll get to that",
    "start": "339080",
    "end": "346520"
  },
  {
    "text": "later so um the the design journey of both time series and olup databases",
    "start": "349880",
    "end": "357960"
  },
  {
    "text": "so very early days databases and and I'm sure everybody is familiar with this",
    "start": "357960",
    "end": "363680"
  },
  {
    "text": "they they had a quite monolithic design to them and uh so what that means is um",
    "start": "363680",
    "end": "371199"
  },
  {
    "text": "so the database um looks after its own data it",
    "start": "371199",
    "end": "376319"
  },
  {
    "text": "defines egress and and uh Ingress and egress of the database and just manages",
    "start": "376319",
    "end": "382360"
  },
  {
    "text": "the whole scenario so what you don't see how the data looks in the storage layer",
    "start": "382360",
    "end": "387960"
  },
  {
    "text": "of the database or you don't have have a good insight into how database does",
    "start": "387960",
    "end": "393440"
  },
  {
    "text": "things and then from monol U the database is started to move to Shared",
    "start": "393440",
    "end": "400440"
  },
  {
    "text": "shared disc dis dbms engine um this is slightly different I'll talk about all of these things in in a little bit more",
    "start": "400440",
    "end": "407039"
  },
  {
    "text": "detail but yeah I guess I'll leave it there I'll talk about sort of a shared desk",
    "start": "407039",
    "end": "412759"
  },
  {
    "text": "and then the next step was lighthouse um Lakehouse dbms engines and um yeah let's",
    "start": "412759",
    "end": "421440"
  },
  {
    "text": "let's dive into it so this is this is what monol database is so a user uh",
    "start": "421440",
    "end": "427599"
  },
  {
    "text": "treats database as a oh quid engine as a black box so database owns the desk and",
    "start": "427599",
    "end": "434759"
  },
  {
    "text": "database also owns the catalog of uh of of your",
    "start": "434759",
    "end": "441160"
  },
  {
    "text": "data so um in in sort of in this scenario so if we if we go down to next",
    "start": "441160",
    "end": "446879"
  },
  {
    "text": "slide so if you if you were to you say Okay I want to store a lot of data",
    "start": "446879",
    "end": "452560"
  },
  {
    "text": "across my databases so you have to split data into shards so you can host data on different",
    "start": "452560",
    "end": "460360"
  },
  {
    "text": "servers and and doing that limits your CPU capability because your CPU",
    "start": "460360",
    "end": "466319"
  },
  {
    "text": "capability is linked to the number of shards and if you if you need more CPU you have to rehard the data and this is",
    "start": "466319",
    "end": "473919"
  },
  {
    "text": "painful process to do depending on how much data your database has um so and this limits kind of",
    "start": "473919",
    "end": "481319"
  },
  {
    "text": "elasticity because you cannot add computer resource on the Fly because it",
    "start": "481319",
    "end": "486440"
  },
  {
    "text": "doesn't have access to your data um so other other potentially old",
    "start": "486440",
    "end": "492919"
  },
  {
    "text": "things with the databases of this type they they handle all of the uh Ingress",
    "start": "492919",
    "end": "499599"
  },
  {
    "text": "Andress points to the database so if you want to load data in a database you have",
    "start": "499599",
    "end": "504919"
  },
  {
    "text": "to go through it if you need to query data from the database you also have to go through it and basically all the",
    "start": "504919",
    "end": "511560"
  },
  {
    "text": "protocols and code the database has could be limitting in Factor depending",
    "start": "511560",
    "end": "516839"
  },
  {
    "text": "what you want to do and uh uh well and obviously data in",
    "start": "516839",
    "end": "522440"
  },
  {
    "text": "a database is when locked so you have to to get your data out from one database",
    "start": "522440",
    "end": "527640"
  },
  {
    "text": "to another you can do it but it's a painful process more often than",
    "start": "527640",
    "end": "534920"
  },
  {
    "text": "not so in 2010s um this is the 10 I",
    "start": "536440",
    "end": "541560"
  },
  {
    "text": "guess the uh tsbs is were well time series databases were all monolith and",
    "start": "541560",
    "end": "548560"
  },
  {
    "text": "they um they came into existence by replacing oltp so",
    "start": "548560",
    "end": "554880"
  },
  {
    "text": "oltp uh a postgress Oracle and stuff like that um we not perhaps quick enough",
    "start": "554880",
    "end": "562120"
  },
  {
    "text": "for on Ingress side so people wanted to get more data in the database faster so",
    "start": "562120",
    "end": "568000"
  },
  {
    "text": "they people invented t BS right um at the same time in the same decade the",
    "start": "568000",
    "end": "575880"
  },
  {
    "text": "olup databases have already moved from monolithic to Shared engines so they",
    "start": "575880",
    "end": "582760"
  },
  {
    "text": "moved from what what data warehouse was to use another type of architecture a",
    "start": "582760",
    "end": "590360"
  },
  {
    "text": "shared shared engine architecture so share dis engine what",
    "start": "590360",
    "end": "597360"
  },
  {
    "text": "what is it so the difference here in the previous slide is that the uh data is no",
    "start": "597360",
    "end": "604040"
  },
  {
    "text": "longer on the disk of the of the actual physical computer so this data is in um",
    "start": "604040",
    "end": "611399"
  },
  {
    "text": "Object Store um you guys probably familiar with object stores this S3",
    "start": "611399",
    "end": "618360"
  },
  {
    "text": "um Asia well every cloud provider has it so hdfs and stuff like that um the the",
    "start": "618360",
    "end": "626360"
  },
  {
    "text": "advantage of the Shar um well the shared dis architecture is",
    "start": "626360",
    "end": "631959"
  },
  {
    "text": "that it kind of unlocks compute capacity of the database so if you if you want to",
    "start": "631959",
    "end": "637880"
  },
  {
    "text": "add another um another server to help you with aggregating data and stuff like",
    "start": "637880",
    "end": "645120"
  },
  {
    "text": "that so you can easily do that because they all share the object",
    "start": "645120",
    "end": "651800"
  },
  {
    "text": "store the this this also there's a there's a difficulty the the things",
    "start": "651800",
    "end": "658800"
  },
  {
    "text": "that data bases do uh have changed as well so Object Store is is not your",
    "start": "658800",
    "end": "665079"
  },
  {
    "text": "local desk so it doesn't have Random Access um it's kind of restrictive to",
    "start": "665079",
    "end": "670800"
  },
  {
    "text": "get to and from so you cannot update it in place if you wanted it to so the",
    "start": "670800",
    "end": "676600"
  },
  {
    "text": "databases need to build layers on top of Object Store to to manage access to the",
    "start": "676600",
    "end": "684160"
  },
  {
    "text": "object store itself to to not overstep uh throttling",
    "start": "684160",
    "end": "690160"
  },
  {
    "text": "or to reduce cost so the databases have to kind of have a local dis perhaps to",
    "start": "690160",
    "end": "696440"
  },
  {
    "text": "to back Object Store have a local disc",
    "start": "696440",
    "end": "700680"
  },
  {
    "text": "cache uh but um at the same time elastic",
    "start": "702040",
    "end": "707680"
  },
  {
    "text": "compute is Advantage um however with the Shar dis engine um the egress and uh Ingress are",
    "start": "707680",
    "end": "716760"
  },
  {
    "text": "still handled uh by the database itself so all of the endpoints to get data in",
    "start": "716760",
    "end": "722440"
  },
  {
    "text": "and out are still with in a database and uh data on S3 is not necessarily stored",
    "start": "722440",
    "end": "729600"
  },
  {
    "text": "in in open format so it's all it's going to be in proprietary formats every every",
    "start": "729600",
    "end": "737040"
  },
  {
    "text": "vendor does it differently and uh some people make it also difficult to get",
    "start": "737040",
    "end": "742959"
  },
  {
    "text": "data out of the uh of of the shared store so there's implementations of Shar",
    "start": "742959",
    "end": "749240"
  },
  {
    "text": "dis engine they force you to go through the database",
    "start": "749240",
    "end": "754399"
  },
  {
    "text": "still so um all up databases in 2010 as as I",
    "start": "758920",
    "end": "765000"
  },
  {
    "text": "mention they already on the shared dis uh shared dis model um but tsbs are",
    "start": "765000",
    "end": "772720"
  },
  {
    "text": "still still behind still monolith the next next engine um that",
    "start": "772720",
    "end": "779880"
  },
  {
    "text": "after Shar dis is uh is what's people call now Lakehouse",
    "start": "779880",
    "end": "786000"
  },
  {
    "text": "engine the fundamental difference between um lak house and Shar dis",
    "start": "786000",
    "end": "793399"
  },
  {
    "text": "infrastructure is that um the object store now has uh the catalog itself so",
    "start": "793399",
    "end": "799279"
  },
  {
    "text": "data catalog and uh data in Object Store is stored in open formats there's a all",
    "start": "799279",
    "end": "806120"
  },
  {
    "text": "up databases left right and Center they able to read Park files from S3 that's",
    "start": "806120",
    "end": "812040"
  },
  {
    "text": "what pretty much uh what it is and uh the database architecture changes yet",
    "start": "812040",
    "end": "818519"
  },
  {
    "text": "again because um the the catalog is owned by um by some something else something",
    "start": "818519",
    "end": "826600"
  },
  {
    "text": "external the park files and they're different to internal format they're slightly less",
    "start": "826600",
    "end": "833560"
  },
  {
    "text": "optimized but the the upside is that um they data can be put into uh shared",
    "start": "834839",
    "end": "842199"
  },
  {
    "text": "storage directly to shared storage so you can upload Park file to S3 and uh",
    "start": "842199",
    "end": "848079"
  },
  {
    "text": "you can have database read it should you should you need it to the other the other upside is",
    "start": "848079",
    "end": "854920"
  },
  {
    "text": "that if you if you want to download data from uh from the from the system you can",
    "start": "854920",
    "end": "861480"
  },
  {
    "text": "just pull uh par files back so you don't need to go through database and the role of the database",
    "start": "861480",
    "end": "868560"
  },
  {
    "text": "becomes a little bit different in this this environment is that um the the",
    "start": "868560",
    "end": "874360"
  },
  {
    "text": "database is becoming more of a help to to the user for example if you were to",
    "start": "874360",
    "end": "881120"
  },
  {
    "text": "upload um 100 files to to to to object storage you might want database to help",
    "start": "881120",
    "end": "888800"
  },
  {
    "text": "you find information in these files rather than download files and F find",
    "start": "888800",
    "end": "895000"
  },
  {
    "text": "this information yourself but should your data access gran sity is the same",
    "start": "895000",
    "end": "900759"
  },
  {
    "text": "as your files then you don't need to go through database",
    "start": "900759",
    "end": "905199"
  },
  {
    "text": "entirely so in the 20s ultimately a lot",
    "start": "906480",
    "end": "911519"
  },
  {
    "text": "of olab databases uh such as snowflake um they moved to uh um lake",
    "start": "911519",
    "end": "918759"
  },
  {
    "text": "house engine architecture and um time serious databases are really far away from from",
    "start": "918759",
    "end": "925680"
  },
  {
    "text": "from this um it's also in the past 20 years it seems as if all our databases um have",
    "start": "925680",
    "end": "934399"
  },
  {
    "text": "um doubled down on query performance um whereas time series",
    "start": "934399",
    "end": "941600"
  },
  {
    "text": "databases implemented in Grass performance better than uh better than all up",
    "start": "941600",
    "end": "948560"
  },
  {
    "text": "databases um",
    "start": "948560",
    "end": "952720"
  },
  {
    "text": "second so um all databases at the same time have a lot more advanced query",
    "start": "956480",
    "end": "963759"
  },
  {
    "text": "engines so these query engines are effectively um able to distribute SQL",
    "start": "963759",
    "end": "970399"
  },
  {
    "text": "execution for workloads that needed and time series they don't so they there's",
    "start": "970399",
    "end": "976319"
  },
  {
    "text": "no time series database with a distributed um quer engine um but at the same time time",
    "start": "976319",
    "end": "983600"
  },
  {
    "text": "series databas is a bit simpler to operate because uh when you have a distributed qu engine so that system is",
    "start": "983600",
    "end": "991079"
  },
  {
    "text": "either Cloud bound so it's in the cloud or it's kind of very difficult to set up",
    "start": "991079",
    "end": "996480"
  },
  {
    "text": "an operate and monitor and stuff like",
    "start": "996480",
    "end": "1000120"
  },
  {
    "text": "that so now there's a story about quizdb a little bit so um the company was",
    "start": "1001680",
    "end": "1008160"
  },
  {
    "text": "founded just on the on the CP of 2020 is ending um in",
    "start": "1008160",
    "end": "1014040"
  },
  {
    "text": "2019 and uh kind of broadly speaking we are um call Store with uh with SQL",
    "start": "1014040",
    "end": "1022120"
  },
  {
    "text": "engine that can do J jit compilation and some some other ancillaries I I'll go",
    "start": "1022120",
    "end": "1027480"
  },
  {
    "text": "go talk about a little bit um so we kind of it makes sense for",
    "start": "1027480",
    "end": "1035199"
  },
  {
    "text": "um for for time serious database to to look towards um Lakehouse engines um there's",
    "start": "1035199",
    "end": "1043880"
  },
  {
    "text": "multiple advantages to it storing storing data on S3 is is incredibly cheap so you you can store a lot of data",
    "start": "1043880",
    "end": "1051600"
  },
  {
    "text": "storage is steered it costs very little um the open format such as Park um um",
    "start": "1051600",
    "end": "1060320"
  },
  {
    "text": "the the high compressing format um and uh the advantage for for database",
    "start": "1060320",
    "end": "1068799"
  },
  {
    "text": "users is that in some cases um both ESS and uh Ingress can bypass the database",
    "start": "1068799",
    "end": "1075640"
  },
  {
    "text": "entirely so you can have a scenario where you can upload Park files and have",
    "start": "1075640",
    "end": "1081480"
  },
  {
    "text": "database query query them so you don't need to go through database to do it you don't need to convert formats you don't",
    "start": "1081480",
    "end": "1087760"
  },
  {
    "text": "need to specialize to have special drivers or anything like that so park files in database reads",
    "start": "1087760",
    "end": "1093720"
  },
  {
    "text": "them um and uh as I mentioned before the um the database role becomes a little",
    "start": "1093720",
    "end": "1099799"
  },
  {
    "text": "bit of a help so so database is able to search search your files should you need",
    "start": "1099799",
    "end": "1107240"
  },
  {
    "text": "it to or or just stay aside if you if you're happy to get files in and",
    "start": "1107240",
    "end": "1113799"
  },
  {
    "text": "out um and one thing that sort of lak house",
    "start": "1113799",
    "end": "1120240"
  },
  {
    "text": "engines also tend to do is to to kind of focus on uh unstructured and semistructured data as well which time",
    "start": "1120240",
    "end": "1127640"
  },
  {
    "text": "series don't typically do and and this is Json data array data and stuff like",
    "start": "1127640",
    "end": "1134960"
  },
  {
    "text": "that so oh goals our goals kind of change because we we we've been in in",
    "start": "1136679",
    "end": "1143240"
  },
  {
    "text": "this business five years and uh we need to kind of look around to see what our goal should be but it kind of makes",
    "start": "1143240",
    "end": "1149400"
  },
  {
    "text": "sense to um to address for for for us to try and address the gap between time",
    "start": "1149400",
    "end": "1156360"
  },
  {
    "text": "series database and olab databases and that is by um having high performance in",
    "start": "1156360",
    "end": "1164640"
  },
  {
    "text": "what is essentially column store and a column store is a is a data structure",
    "start": "1164640",
    "end": "1170000"
  },
  {
    "text": "that is um that built for queries it's not built for writing data too it's",
    "start": "1170000",
    "end": "1175840"
  },
  {
    "text": "built for queries and and having high performance ingesting such a data structure is fairly fairly unique thing",
    "start": "1175840",
    "end": "1181720"
  },
  {
    "text": "to have um we want to build distributed SQL uh SQL engine so we can run um",
    "start": "1181720",
    "end": "1190760"
  },
  {
    "text": "workloads across well business intelligence workloads uh",
    "start": "1190760",
    "end": "1196679"
  },
  {
    "text": "across across multiple service should we need to and we want to have high performance agress so the high",
    "start": "1196679",
    "end": "1203960"
  },
  {
    "text": "performance agress um I'll talk about that a little bit more on the other slide but it becomes quite important in",
    "start": "1203960",
    "end": "1211200"
  },
  {
    "text": "uh in age of particularly AI when data is uh is kind of extracted from a",
    "start": "1211200",
    "end": "1218640"
  },
  {
    "text": "database into python um and the processed kind of in bulk somewhere else",
    "start": "1218640",
    "end": "1225480"
  },
  {
    "text": "outside of the database um we also wanted to to make",
    "start": "1225480",
    "end": "1231200"
  },
  {
    "text": "things quite simple for the user so eliminate needless complexity um I should say the database",
    "start": "1231200",
    "end": "1239760"
  },
  {
    "text": "itself we built it from scratch so there's no dependencies on it so it's built ground ground up to to be high",
    "start": "1239760",
    "end": "1246720"
  },
  {
    "text": "performance database and we want to keep it this way even though we go into into lak house era and distributed queries",
    "start": "1246720",
    "end": "1253799"
  },
  {
    "text": "and multi nodes and stuff like that",
    "start": "1253799",
    "end": "1258240"
  },
  {
    "text": "so how how do how do we do that so the um Ingress apis",
    "start": "1259880",
    "end": "1266960"
  },
  {
    "text": "um what's what's quite interesting about Ingress apis is that um most of the data",
    "start": "1266960",
    "end": "1273159"
  },
  {
    "text": "um in new data is is Row first so data",
    "start": "1273159",
    "end": "1279480"
  },
  {
    "text": "that originates from sensors uh contains multiple columns on one line it's it's a row first it's the opposite of column",
    "start": "1279480",
    "end": "1286520"
  },
  {
    "text": "first we close that all up all up favor um and we want to uh to provide",
    "start": "1286520",
    "end": "1294679"
  },
  {
    "text": "maximum performance Ingress performance on on these type of",
    "start": "1294679",
    "end": "1300159"
  },
  {
    "text": "workloads um the the Ingress should also balance um hot and cold partitions and",
    "start": "1300159",
    "end": "1307919"
  },
  {
    "text": "uh by by that is by that I mean automatic partitioning and I'll get get",
    "start": "1307919",
    "end": "1313520"
  },
  {
    "text": "into that on the next slides um it provides a schema elasticity uh what",
    "start": "1313520",
    "end": "1319120"
  },
  {
    "text": "schema elasticity is is that um you can for example add uh a column on the fly",
    "start": "1319120",
    "end": "1325799"
  },
  {
    "text": "to the database so you don't need to um you don't need necessarily to uh to to",
    "start": "1325799",
    "end": "1332520"
  },
  {
    "text": "have a separate um out of our script that adds a column",
    "start": "1332520",
    "end": "1337960"
  },
  {
    "text": "before you can change your publishing code that publishes values in this column so database effectively",
    "start": "1337960",
    "end": "1344960"
  },
  {
    "text": "guarantees um consistency if if you've got five Publishers or 10 trying to add",
    "start": "1344960",
    "end": "1352240"
  },
  {
    "text": "the same column to the same table so they all going to succeed and one column is going to be there in the end and U",
    "start": "1352240",
    "end": "1359360"
  },
  {
    "text": "the Ingress uh should provide data concurrency and high availability",
    "start": "1359360",
    "end": "1365480"
  },
  {
    "text": "so what that means in the high availability scenario is that uh we want",
    "start": "1365480",
    "end": "1370880"
  },
  {
    "text": "our Ingress to be highly available in terms of you can send data to more than one node so if you fail to",
    "start": "1370880",
    "end": "1379120"
  },
  {
    "text": "send data to one you can send send data to the other and um here there's some",
    "start": "1379120",
    "end": "1386158"
  },
  {
    "text": "scenarios for example you send data to one box and this box doesn't",
    "start": "1387720",
    "end": "1393520"
  },
  {
    "text": "reply you you you basically have a timeout so there's no certainty whether",
    "start": "1393520",
    "end": "1399000"
  },
  {
    "text": "you the data that you send is actually in the database or not but instead of",
    "start": "1399000",
    "end": "1404679"
  },
  {
    "text": "your application failing and waking somebody up in the middle of the night it can just send data to another another",
    "start": "1404679",
    "end": "1411440"
  },
  {
    "text": "node and uh the guarantees the database provides is that this data will be",
    "start": "1411440",
    "end": "1416799"
  },
  {
    "text": "inserted only once even though you didn't wait for the previous batch in one one machine and you you send the",
    "start": "1416799",
    "end": "1423159"
  },
  {
    "text": "different B same batch to the other machine data will be just once pretty much and you don't have to worry",
    "start": "1423159",
    "end": "1429840"
  },
  {
    "text": "about fixing the process pretty much if this this should should this this",
    "start": "1429840",
    "end": "1436158"
  },
  {
    "text": "happen um so how does ingress work it's kind of simplistic diagram but what I",
    "start": "1436320",
    "end": "1442559"
  },
  {
    "text": "wanted to to emphasize here is that um we use WR ahead log right so the",
    "start": "1442559",
    "end": "1449480"
  },
  {
    "text": "database writes data to WR ahead log first so WR ahead log is a is full",
    "start": "1449480",
    "end": "1455679"
  },
  {
    "text": "intents and purposes is a pendon structure there is a there's only basic validation that is performed when data",
    "start": "1455679",
    "end": "1462679"
  },
  {
    "text": "is ingested so this uh right a head log is um basically fronted by different",
    "start": "1462679",
    "end": "1469039"
  },
  {
    "text": "network protocols so you can you can put data in um in WR a headlock from uh from",
    "start": "1469039",
    "end": "1476880"
  },
  {
    "text": "CSV with supporting flux line protocol we we could send arrow in and basically",
    "start": "1476880",
    "end": "1482679"
  },
  {
    "text": "the different different data formats some data is Row first some data is column first um and uh ultimately all of this",
    "start": "1482679",
    "end": "1490120"
  },
  {
    "text": "data goes into wall and wall is asynchronously applied to to the column",
    "start": "1490120",
    "end": "1495279"
  },
  {
    "text": "store and and the reason I mentioned Row first",
    "start": "1495279",
    "end": "1501679"
  },
  {
    "text": "and column first is because a lot of database kind of experience this kind of Ingress Paradox where they're trying to",
    "start": "1501679",
    "end": "1508600"
  },
  {
    "text": "insert row First Data into column First Data store um and when this this this",
    "start": "1508600",
    "end": "1516640"
  },
  {
    "text": "might not be a problem kind of when you just do basic benchmarks but it it",
    "start": "1516640",
    "end": "1522880"
  },
  {
    "text": "manifests itself uh as a problem um in scenarios where your table become quite",
    "start": "1522880",
    "end": "1529600"
  },
  {
    "text": "wide so if if the table structure is such as got 500 columns or maybe you've",
    "start": "1529600",
    "end": "1535159"
  },
  {
    "text": "got a lot of tables with small number of columns so ultimately what this um kind",
    "start": "1535159",
    "end": "1541120"
  },
  {
    "text": "of converges to you you you do a lot of random rights to disk and these random",
    "start": "1541120",
    "end": "1547799"
  },
  {
    "text": "rights start to BG down quite quite quite rapidly",
    "start": "1547799",
    "end": "1553679"
  },
  {
    "text": "um and just to to avoid this by the way so to avoid this what we do is we we",
    "start": "1553679",
    "end": "1559960"
  },
  {
    "text": "have a mixed wall right ahead log format one is for row First Data one is for",
    "start": "1559960",
    "end": "1565799"
  },
  {
    "text": "column First Data so the row fast workloads are written to row by row and",
    "start": "1565799",
    "end": "1572159"
  },
  {
    "text": "column fast workloads are written column by column so there's we kind of mitigate it's not we don't entirely remove random",
    "start": "1572159",
    "end": "1578880"
  },
  {
    "text": "rights but we mitigate it quite quite",
    "start": "1578880",
    "end": "1583399"
  },
  {
    "text": "well um so the uh the the balance in hot and",
    "start": "1584120",
    "end": "1589399"
  },
  {
    "text": "cold data so what what typically happens during Ingress U heavy Ingress workloads",
    "start": "1589399",
    "end": "1597000"
  },
  {
    "text": "is that um dis spaces consume quite rapidly basically that that's what",
    "start": "1597000",
    "end": "1602279"
  },
  {
    "text": "happens if you if you send a lot of data to the database and and the job of uh time series database and that's what",
    "start": "1602279",
    "end": "1608960"
  },
  {
    "text": "quizdb does it effectively automatically partitions your data on time stamp as as",
    "start": "1608960",
    "end": "1614080"
  },
  {
    "text": "you put data in and uh offloads uh the uh uh these partitions to to Object",
    "start": "1614080",
    "end": "1622440"
  },
  {
    "text": "Store as you create them and uh recompress them in park and uh this",
    "start": "1622440",
    "end": "1629799"
  },
  {
    "text": "um the the files become available for reads but ultimately database uh is able",
    "start": "1629799",
    "end": "1637679"
  },
  {
    "text": "to sustain high volume of flood without running out of desk or costing too much",
    "start": "1637679",
    "end": "1643559"
  },
  {
    "text": "or or firy the dis space um as as as data is",
    "start": "1643559",
    "end": "1648720"
  },
  {
    "text": "ingested um the the new data as as as I mentioned before it comes in a right",
    "start": "1648720",
    "end": "1654520"
  },
  {
    "text": "ahead log formats and um sort of this this wrer head logs are used to to join",
    "start": "1654520",
    "end": "1663440"
  },
  {
    "text": "um well they they can be replicated to S3 as well and what what that gives um it",
    "start": "1663440",
    "end": "1671039"
  },
  {
    "text": "gives kind of ability to another compute node to have visibility of the old data",
    "start": "1671039",
    "end": "1678760"
  },
  {
    "text": "that is already in par files on S3 plus be able to reconstruct the hot partition",
    "start": "1678760",
    "end": "1684760"
  },
  {
    "text": "that is is locally to to the machine so you can have multiple multiple compute",
    "start": "1684760",
    "end": "1690320"
  },
  {
    "text": "nodes looking at the same recent",
    "start": "1690320",
    "end": "1695000"
  },
  {
    "text": "data",
    "start": "1695720",
    "end": "1698720"
  },
  {
    "text": "um okay data data concurrency so um I guess um you guys familiar with um mvcc",
    "start": "1702000",
    "end": "1710600"
  },
  {
    "text": "um so it actually wasn't apparent to me for for for a number of years that",
    "start": "1710600",
    "end": "1716640"
  },
  {
    "text": "databases are not necessarily override the data they they copy copy on right",
    "start": "1716640",
    "end": "1721960"
  },
  {
    "text": "systems so every time you modify something database copies data so and",
    "start": "1721960",
    "end": "1728679"
  },
  {
    "text": "then uh it just database tries to manage the um um size of the block that copies",
    "start": "1728679",
    "end": "1735880"
  },
  {
    "text": "and actually incidentally from this there is um there's a terminology called Write amplification",
    "start": "1735880",
    "end": "1742320"
  },
  {
    "text": "comes in so you write a little bit but because database needs to write a block of copy",
    "start": "1742320",
    "end": "1749278"
  },
  {
    "text": "data um copy on right bigger block so you can have more physical disk RS",
    "start": "1749480",
    "end": "1756320"
  },
  {
    "text": "versus how much data you actually written and the same same goes uh the other way for reads but yeah so um as",
    "start": "1756320",
    "end": "1764000"
  },
  {
    "text": "any any other database we qub can can read data that's being written so quite",
    "start": "1764000",
    "end": "1771000"
  },
  {
    "text": "transactionally",
    "start": "1771000",
    "end": "1774000"
  },
  {
    "text": "um the the column store itself is uh is also ordered um ordered by uh by time so the",
    "start": "1778799",
    "end": "1788159"
  },
  {
    "text": "database will be sorting data uh as it as it reads and it need as as it rights",
    "start": "1788159",
    "end": "1793200"
  },
  {
    "text": "to it and also keeps it consistent um it provides the uh",
    "start": "1793200",
    "end": "1800039"
  },
  {
    "text": "concurrent update to par files itself so um all all partitions that been",
    "start": "1800039",
    "end": "1805720"
  },
  {
    "text": "deposited to Object Store if if you send data to them the system will will update",
    "start": "1805720",
    "end": "1811240"
  },
  {
    "text": "them as well and uh he also provides concurrent metadata changes and uh and data",
    "start": "1811240",
    "end": "1819880"
  },
  {
    "text": "republish after after Network glitches is what what I mentioned before so you can republish the same block without",
    "start": "1819880",
    "end": "1826200"
  },
  {
    "text": "without duplicating data in the database",
    "start": "1826200",
    "end": "1829960"
  },
  {
    "text": "so how this metadata consistency Works um so um we with data written to uh uh",
    "start": "1833440",
    "end": "1842039"
  },
  {
    "text": "write write the head logs um after after transaction uh is well",
    "start": "1842039",
    "end": "1848640"
  },
  {
    "text": "when transaction is about to be committed we have um we have a entity called sequencer the sequencer is is",
    "start": "1848640",
    "end": "1856440"
  },
  {
    "text": "very similar to what other databases have they store it in um uh in zookeepers and and and stuff like that",
    "start": "1856440",
    "end": "1863919"
  },
  {
    "text": "so the sequencer has the metadata of the table so it has transaction numbers it",
    "start": "1863919",
    "end": "1869320"
  },
  {
    "text": "has number of columns it has a list of uh partitions and where those partitions",
    "start": "1869320",
    "end": "1874399"
  },
  {
    "text": "are and the the idea here is that if uh if the column is added concurrently by",
    "start": "1874399",
    "end": "1880320"
  },
  {
    "text": "two two actors to to different Wall Files so um there's a Version Control",
    "start": "1880320",
    "end": "1886200"
  },
  {
    "text": "used to uh to basically before wall is is concluded",
    "start": "1886200",
    "end": "1892720"
  },
  {
    "text": "um we check the version of of the right right head log versus what sequencer has",
    "start": "1892720",
    "end": "1898799"
  },
  {
    "text": "and if it's if the right Ahad log version is lower than the sequencer itself that means there was a concurrent",
    "start": "1898799",
    "end": "1905559"
  },
  {
    "text": "update to the metadata that the wall has to reconcile uh reconcile the entire transaction the",
    "start": "1905559",
    "end": "1913240"
  },
  {
    "text": "advantage of of of of doing things in this order is that if reconciliation",
    "start": "1913240",
    "end": "1919120"
  },
  {
    "text": "were to fail the the error can be reported back to to the user as as as an",
    "start": "1919120",
    "end": "1925120"
  },
  {
    "text": "error right or um wrer headlock can successfully reconcile the data for",
    "start": "1925120",
    "end": "1931320"
  },
  {
    "text": "example if if a column is added which is irrelevant to this transaction it will populate column with nulls and insert it",
    "start": "1931320",
    "end": "1938080"
  },
  {
    "text": "in database so this this mechanism effectively provides ability to to add",
    "start": "1938080",
    "end": "1943799"
  },
  {
    "text": "columns um pretty much on the fly without without Lo in the database or or",
    "start": "1943799",
    "end": "1949200"
  },
  {
    "text": "taking database into uh off peak mode of some",
    "start": "1949200",
    "end": "1954600"
  },
  {
    "text": "sort um Now erress API",
    "start": "1955399",
    "end": "1960760"
  },
  {
    "text": "so so this is this is from um this is what we saw throughout the years what",
    "start": "1961600",
    "end": "1969480"
  },
  {
    "text": "people do with time series data so one one use case is to um for for ESS is to",
    "start": "1969480",
    "end": "1977240"
  },
  {
    "text": "power bi software so it's it's analytics uh it's aggregations it's top of this",
    "start": "1977240",
    "end": "1984919"
  },
  {
    "text": "bottom of that kind of pie charts and stuff like that so this analytics sometimes um they zoomed out as well so",
    "start": "1984919",
    "end": "1992320"
  },
  {
    "text": "user can zoom zoom it out that causes uh causes the database to go over a larger",
    "start": "1992320",
    "end": "1997480"
  },
  {
    "text": "volume of data this is this is type of workflow that is requires effectively",
    "start": "1997480",
    "end": "2003919"
  },
  {
    "text": "distributed queries because uh everybody wants data fast no matter how much data you have",
    "start": "2003919",
    "end": "2010120"
  },
  {
    "text": "and if if somebody zooms out five years five years up then then database needs",
    "start": "2010120",
    "end": "2015799"
  },
  {
    "text": "to needs to do a lot of calculations today that's the prime case for uh all",
    "start": "2015799",
    "end": "2020880"
  },
  {
    "text": "up and distributed distributed query engines some other workloads are time",
    "start": "2020880",
    "end": "2026799"
  },
  {
    "text": "series workloads The Time series workload is is basically charting time serious charting so people plot uh chart",
    "start": "2026799",
    "end": "2035440"
  },
  {
    "text": "of something that is more likely to be very recent and trips into into the past",
    "start": "2035440",
    "end": "2041519"
  },
  {
    "text": "uh from from a charting applications are quite quite rare and uh what's what's",
    "start": "2041519",
    "end": "2046559"
  },
  {
    "text": "important there is to to optimize execution query execution um on a kind of on a single",
    "start": "2046559",
    "end": "2053760"
  },
  {
    "text": "single CPU kind of stuff because going going across to multiple multiple",
    "start": "2053760",
    "end": "2059760"
  },
  {
    "text": "machines could be could be prohibitively expensive depending on basically on the",
    "start": "2059760",
    "end": "2065638"
  },
  {
    "text": "query um other types of workloads such as spark or python they uh sometimes",
    "start": "2065639",
    "end": "2072800"
  },
  {
    "text": "these workloads need to to to execute data on a SQL definitely",
    "start": "2072800",
    "end": "2080638"
  },
  {
    "text": "um but a lot of other times these workloads just want to access uh Object",
    "start": "2080639",
    "end": "2085878"
  },
  {
    "text": "Store directly they don't need to go to the database and uh this is where database",
    "start": "2085879",
    "end": "2091800"
  },
  {
    "text": "bypass becomes becomes interesting and and important um in this scenario",
    "start": "2091800",
    "end": "2097760"
  },
  {
    "text": "and uh so the these this uh the workloads to",
    "start": "2097760",
    "end": "2106920"
  },
  {
    "text": "um the the workflows that offload quite a lot of data to the database actually",
    "start": "2106920",
    "end": "2113680"
  },
  {
    "text": "necessitate uh a different type of regress API such as uh aruto driver adbc",
    "start": "2113680",
    "end": "2120920"
  },
  {
    "text": "they called and um and this is what um and this is the problem um with rather the",
    "start": "2120920",
    "end": "2128359"
  },
  {
    "text": "problem this drivers uh solve is to get data large volume of data in or out of",
    "start": "2128359",
    "end": "2134640"
  },
  {
    "text": "the database um over the network requires multiple network connections so a",
    "start": "2134640",
    "end": "2142160"
  },
  {
    "text": "database is not necessarily going to scale linearly as you add more network connections to them but doing it over",
    "start": "2142160",
    "end": "2148000"
  },
  {
    "text": "single single TCP socket is is not going to happen and this this what",
    "start": "2148000",
    "end": "2154079"
  },
  {
    "text": "uh adbc driver provides so your your output data is split into column sets",
    "start": "2154079",
    "end": "2161359"
  },
  {
    "text": "those those items are still columns they're just smaller in size these columns uh send back to back over the",
    "start": "2161359",
    "end": "2168359"
  },
  {
    "text": "wire to to the client and then they reassembled into into larger columns and",
    "start": "2168359",
    "end": "2174960"
  },
  {
    "text": "uh and all of this is abstracted via SQL execution exe and typical typical",
    "start": "2174960",
    "end": "2181319"
  },
  {
    "text": "examples here um from for time serious workload uh somebody would just query",
    "start": "2181319",
    "end": "2186800"
  },
  {
    "text": "data on an inter say they they want data for past months that's that's basically or maybe some",
    "start": "2186800",
    "end": "2193760"
  },
  {
    "text": "filter data on a predic they want data for past month for this particular time",
    "start": "2193760",
    "end": "2199599"
  },
  {
    "text": "series and it's common in Time series database to to put multiple time series",
    "start": "2199599",
    "end": "2204880"
  },
  {
    "text": "in the same table so you would be filtering time series out of out of a table to a client and that that could be",
    "start": "2204880",
    "end": "2212040"
  },
  {
    "text": "quite large large data set so sending it over multiple network connections and ly",
    "start": "2212040",
    "end": "2218599"
  },
  {
    "text": "makes makes a lot of sense and this is what adbc",
    "start": "2218599",
    "end": "2223240"
  },
  {
    "text": "facilitates um so and a SQL engine is is is",
    "start": "2224400",
    "end": "2230160"
  },
  {
    "text": "effectively reflection of of the uh of the workloads that um that that put on",
    "start": "2230160",
    "end": "2236720"
  },
  {
    "text": "it so it executes um it's it's typical fall up and it's it's what we do as well",
    "start": "2236720",
    "end": "2243680"
  },
  {
    "text": "is to execute Group by order by and wear Clause concurrent so wouldn't say say concurrently it's",
    "start": "2243680",
    "end": "2250760"
  },
  {
    "text": "executed in parallel so data is split uh into chunks those chunks evaluate in",
    "start": "2250760",
    "end": "2256560"
  },
  {
    "text": "parallel data is merged merged back and uh to to to optimize this we also",
    "start": "2256560",
    "end": "2263520"
  },
  {
    "text": "compile some of the predicates into into assembly which is avx2 assembly and to",
    "start": "2263520",
    "end": "2269800"
  },
  {
    "text": "basically to to avoid costly costly function",
    "start": "2269800",
    "end": "2275280"
  },
  {
    "text": "executions um and this helps with uh with analytical workloads it helps with",
    "start": "2275280",
    "end": "2280960"
  },
  {
    "text": "uh time series charting uh and helps with uh bi bi workload",
    "start": "2280960",
    "end": "2288599"
  },
  {
    "text": "workloads the SQL language in extension such as sample bu uh sample buy and",
    "start": "2288599",
    "end": "2295560"
  },
  {
    "text": "limit so we we kind of offer this these things uh I'll show examples kind of",
    "start": "2295560",
    "end": "2301760"
  },
  {
    "text": "later on but these are simplifications that take advantage of of data being",
    "start": "2301760",
    "end": "2307640"
  },
  {
    "text": "ordered by time and U um sample buy is is a group Buy on a time interval and",
    "start": "2307640",
    "end": "2315280"
  },
  {
    "text": "limits allow you to uh to pick particular data in the in the in the time range quite quite easily and I'll",
    "start": "2315280",
    "end": "2322079"
  },
  {
    "text": "show you show you how to do that um the SQL engine also leverages uh metadata",
    "start": "2322079",
    "end": "2328000"
  },
  {
    "text": "layout for metadata and data layout for query optimization and and a good example of",
    "start": "2328000",
    "end": "2334720"
  },
  {
    "text": "this is that um if you have data that is is um for example rang length encoded in",
    "start": "2334720",
    "end": "2341040"
  },
  {
    "text": "a in a column right um it's not necessary to materialize this data back",
    "start": "2341040",
    "end": "2347800"
  },
  {
    "text": "in memory to perform a worklow search on it so you you can you can search",
    "start": "2347800",
    "end": "2353640"
  },
  {
    "text": "compress data without uncompressing it this is what Optimizer tries to figure out data",
    "start": "2353640",
    "end": "2359839"
  },
  {
    "text": "layout and what kind of execution algorithm to pick um interval search is",
    "start": "2359839",
    "end": "2368480"
  },
  {
    "text": "um is is used to send bulks of data to either to um to Python and maybe kind of",
    "start": "2368480",
    "end": "2376800"
  },
  {
    "text": "to to chart he also uses uh leverages layout ordered layout of the data",
    "start": "2376800",
    "end": "2383560"
  },
  {
    "text": "itself um and the data internally is is represented as a column first uh for for",
    "start": "2383560",
    "end": "2391119"
  },
  {
    "text": "query engine purposes such such data is uh makes it relatively simple to uh",
    "start": "2391119",
    "end": "2396720"
  },
  {
    "text": "offload it to adbc adbc driver because it's a colum Fest colum Fest",
    "start": "2396720",
    "end": "2403880"
  },
  {
    "text": "driver um and this this is uh before before I wrap up I can of went through it quite quickly but before before I WRA",
    "start": "2406319",
    "end": "2413520"
  },
  {
    "text": "up this is um examples of uh sample buy queries you could potentially write a",
    "start": "2413520",
    "end": "2419000"
  },
  {
    "text": "write a group buy statement here kind of by trating date to uh to hour but but",
    "start": "2419000",
    "end": "2426160"
  },
  {
    "text": "this is simplification does the same thing uh and in this example also there's interval query kind of instead",
    "start": "2426160",
    "end": "2432520"
  },
  {
    "text": "of expressing it via date between XY this is 7day interval of 1st of June",
    "start": "2432520",
    "end": "2439800"
  },
  {
    "text": "2018 that's basically uh you this this is semantically easier to to write sqls",
    "start": "2439800",
    "end": "2447359"
  },
  {
    "text": "oops so um this is example of AO join um",
    "start": "2447359",
    "end": "2452800"
  },
  {
    "text": "so as of join is a is a Time series join um it it it collect it joins the data on a",
    "start": "2452800",
    "end": "2459960"
  },
  {
    "text": "fuzzy uh fuzzy time interval so the typical T typical example would be",
    "start": "2459960",
    "end": "2466319"
  },
  {
    "text": "to to find a value uh from another table",
    "start": "2466319",
    "end": "2471760"
  },
  {
    "text": "that happened before well youve got table A and B you find the value in table B that happened just before the",
    "start": "2471760",
    "end": "2478400"
  },
  {
    "text": "value in table a so that that's what of joint does and uh and this is time access",
    "start": "2478400",
    "end": "2485920"
  },
  {
    "text": "travel that also takes advantage of the order of the order of the um of the data",
    "start": "2485920",
    "end": "2491319"
  },
  {
    "text": "so the first example just shows the last 100 rows from a data set so you this is",
    "start": "2491319",
    "end": "2497720"
  },
  {
    "text": "the illustrat like a negative limit you can use on on the queries and and the second example is um",
    "start": "2497720",
    "end": "2504839"
  },
  {
    "text": "okay so uses uh keyword latest so he finds um latest version of the",
    "start": "2504839",
    "end": "2514318"
  },
  {
    "text": "data in in that particular particular day of 2018 5th of April so and uh it",
    "start": "2515079",
    "end": "2522920"
  },
  {
    "text": "partitions this data on uh this is a trips database and the trips of Taxi",
    "start": "2522920",
    "end": "2528240"
  },
  {
    "text": "trips database and the cup type is um has one of two values so ultimately this",
    "start": "2528240",
    "end": "2533520"
  },
  {
    "text": "would go mid mid the data set and uh and pick the latest data latest data for a",
    "start": "2533520",
    "end": "2540160"
  },
  {
    "text": "given time interval so you can version your data essentially and this this this executes uh it's quite quick and take it",
    "start": "2540160",
    "end": "2547480"
  },
  {
    "text": "takes advantage of of the order data set",
    "start": "2547480",
    "end": "2552920"
  },
  {
    "text": "so so to to wrap rrap this uh this up",
    "start": "2552920",
    "end": "2559160"
  },
  {
    "text": "um the lak housee seems Seems like um",
    "start": "2559160",
    "end": "2564920"
  },
  {
    "text": "seems like the engine everything is converging to and U it looks looks as if",
    "start": "2564920",
    "end": "2571400"
  },
  {
    "text": "Ola databases um they converge and olap and time series databases converge on the same one on",
    "start": "2571400",
    "end": "2578200"
  },
  {
    "text": "the same Target ol are improving their ingestion pipelines uh they they trying to do",
    "start": "2578200",
    "end": "2585280"
  },
  {
    "text": "streaming Implement streaming workloads into into all up databases and tsbs",
    "start": "2585280",
    "end": "2591960"
  },
  {
    "text": "trying to tsdb is are trying to improve data storage um make queries um",
    "start": "2591960",
    "end": "2599599"
  },
  {
    "text": "distributed and deal with large volume of data at the same speed as allab do",
    "start": "2599599",
    "end": "2604760"
  },
  {
    "text": "and uh um ultimately they will well we don't know the future",
    "start": "2604760",
    "end": "2611000"
  },
  {
    "text": "but they might become one because they they all moving in the same direction um in the",
    "start": "2611000",
    "end": "2618240"
  },
  {
    "text": "meantime time series databases and olops coexist in a way that um time series",
    "start": "2618240",
    "end": "2624520"
  },
  {
    "text": "database in just data um new data quite well and this data then offloaded into a",
    "start": "2624520",
    "end": "2630880"
  },
  {
    "text": "bigger bigger database and analyzed as a for posterity in in a l database",
    "start": "2630880",
    "end": "2638280"
  },
  {
    "text": "that's uh I went through it quite quick um that's all all I",
    "start": "2638280",
    "end": "2644480"
  },
  {
    "text": "have thank you guys thank",
    "start": "2644480",
    "end": "2650880"
  },
  {
    "text": "you okay thanks a lot we do have time for a few questions anybody have any question",
    "start": "2653800",
    "end": "2660079"
  },
  {
    "text": "we can start from",
    "start": "2660079",
    "end": "2662839"
  },
  {
    "text": "here oh well thank you very much for the presentation um I had two questions",
    "start": "2665559",
    "end": "2672440"
  },
  {
    "text": "problem with time series databases one is out of sequence events yeah how resilient is Quest DB to handling that",
    "start": "2672440",
    "end": "2680319"
  },
  {
    "text": "the other one is uh you obviously have streaming input Ingress but do you also have streaming",
    "start": "2680319",
    "end": "2686319"
  },
  {
    "text": "egress Quest yeah so we are we're building streaming uh it's not streaming",
    "start": "2686319",
    "end": "2691640"
  },
  {
    "text": "the but uh this we're building this adbc driver for large volume large volume in",
    "start": "2691640",
    "end": "2697839"
  },
  {
    "text": "igress so it's it's not quite streaming so the the capability um as a streaming",
    "start": "2697839",
    "end": "2704200"
  },
  {
    "text": "igress can be achieved through the change data capture these right ahead log files can be can be shipped",
    "start": "2704200",
    "end": "2710559"
  },
  {
    "text": "somewhere else and analyzed it can be can be done like that um",
    "start": "2710559",
    "end": "2717240"
  },
  {
    "text": "so in terms of out of sequence events so we we call these things well internally",
    "start": "2717240",
    "end": "2722599"
  },
  {
    "text": "we call them out of order it's kind of the same thing so um as a as I mentioned",
    "start": "2722599",
    "end": "2727839"
  },
  {
    "text": "the uh the databas is well our database not an exception is to they do copy on",
    "start": "2727839",
    "end": "2733280"
  },
  {
    "text": "right kind of stuff right so you are allowed to send data as as far back as",
    "start": "2733280",
    "end": "2740599"
  },
  {
    "text": "as you want um it depends in in the in",
    "start": "2740599",
    "end": "2746200"
  },
  {
    "text": "some P some patterns are would perform quite well it depends how much data we need to reite but there are some uh",
    "start": "2746200",
    "end": "2753160"
  },
  {
    "text": "degenerative patterns basically that you can you can they're going to go in very slowly it depends for example if you're",
    "start": "2753160",
    "end": "2760280"
  },
  {
    "text": "causing uh well small transactions into like a top of a partition and we're overwriting a big partition over and",
    "start": "2760280",
    "end": "2766800"
  },
  {
    "text": "over and over so you can you can you can get into this kind of scenarios so um broadly speaking yes you",
    "start": "2766800",
    "end": "2773920"
  },
  {
    "text": "can send out of uh out out of sequence events um we try to in some cases uh",
    "start": "2773920",
    "end": "2780960"
  },
  {
    "text": "split partitions if we detect this this kind of events so the big partition gets split so we we override only small",
    "start": "2780960",
    "end": "2787559"
  },
  {
    "text": "smaller chunks But ultimately there's a possibility to get database in the",
    "start": "2787559",
    "end": "2792880"
  },
  {
    "text": "corner with this this kind of things and I'm sorry you asked another question as well and I forgot what it is just two",
    "start": "2792880",
    "end": "2799319"
  },
  {
    "text": "question cool",
    "start": "2799319",
    "end": "2803319"
  },
  {
    "text": "[Music]",
    "start": "2804740",
    "end": "2810189"
  }
]
[
  {
    "start": "0",
    "end": "122000"
  },
  {
    "text": "so I wanted to talk today about multiplexing with speedy and HTTP 2 and um the way that this changes the",
    "start": "8599",
    "end": "16600"
  },
  {
    "text": "way that we optimize for the front end and performance in the browser so the idea is to get a clear picture of what",
    "start": "16600",
    "end": "22640"
  },
  {
    "text": "this actually means at a network level so we're going to just look at how it changes the way that the network uh",
    "start": "22640",
    "end": "27720"
  },
  {
    "text": "sends data and then the other part of the talk I wanted to just discuss es6 modules it's an area that I work in",
    "start": "27720",
    "end": "34160"
  },
  {
    "text": "myself and how as http2 is going to affect es6 modules um I'm going to use",
    "start": "34160",
    "end": "41440"
  },
  {
    "text": "the term speedy and htb2 uh interchangeably because they refer to",
    "start": "41440",
    "end": "46840"
  },
  {
    "text": "the same specification HTTP 2 uh is the next version of HTTP coming out and they",
    "start": "46840",
    "end": "53239"
  },
  {
    "text": "based it on the Speedy implementation which was created by Google um so as Speedy gets um iterated on the versions",
    "start": "53239",
    "end": "60480"
  },
  {
    "text": "come out it's eventually going to become http2 so they're on the same process uh",
    "start": "60480",
    "end": "66240"
  },
  {
    "text": "and just to tell you a little bit about myself uh I'm guy Bedford and I work on various open source projects related to",
    "start": "66240",
    "end": "72000"
  },
  {
    "text": "es6 modules um and package Management in the browser um so the big piece of news that",
    "start": "72000",
    "end": "80320"
  },
  {
    "text": "we got last month was uh at Apple's developer conference one of the things that they announced was Speedy support",
    "start": "80320",
    "end": "85759"
  },
  {
    "text": "in Safari uh so the next version of safari is going to have full Speedy support",
    "start": "85759",
    "end": "90840"
  },
  {
    "text": "and this is great news from the perspective of adoption because that now gives us a full house in browsers uh so",
    "start": "90840",
    "end": "98880"
  },
  {
    "text": "we can expect now that uh towards the end of this year we'll have Speedy supported in all modern",
    "start": "98880",
    "end": "105360"
  },
  {
    "text": "browsers uh and going forward that means that it really is the future workflow in",
    "start": "105360",
    "end": "110560"
  },
  {
    "text": "terms of how we optimize our apps uh and so over the next couple of years we can",
    "start": "110560",
    "end": "116159"
  },
  {
    "text": "expect it to have widespread adoption",
    "start": "116159",
    "end": "121159"
  },
  {
    "start": "122000",
    "end": "504000"
  },
  {
    "text": "uh right and the the key argument is within this world of http2 uh bundling itself",
    "start": "122119",
    "end": "129840"
  },
  {
    "text": "is no longer necessary so uh a lot of the ways that we optimize for the front end today are designed around",
    "start": "129840",
    "end": "136560"
  },
  {
    "text": "http1 and that's going to be changing uh in this world of",
    "start": "136560",
    "end": "141840"
  },
  {
    "text": "http2 uh so I want to go back and just understand the network level a bit to be able to look at this um if you study",
    "start": "142280",
    "end": "149360"
  },
  {
    "text": "computer science and you know all this stuff really well um that's great personally I didn't um so it's the sort",
    "start": "149360",
    "end": "155640"
  },
  {
    "text": "of stuff that you just take for granted in web development and it's assume that you kind of understand this whole massive stack um so tcpip it's it's the",
    "start": "155640",
    "end": "163840"
  },
  {
    "text": "basic protocol when we're dealing with the web and you go a website that's how you um looking up this this website um",
    "start": "163840",
    "end": "170800"
  },
  {
    "text": "and this was created in 1974 it's a 40-year-old protocol um that we're basically just driving the whole of the",
    "start": "170800",
    "end": "176959"
  },
  {
    "text": "internet uh which is pretty amazing these dudes get the the name fathers of the internet um which is a really cool",
    "start": "176959",
    "end": "182879"
  },
  {
    "text": "title um so Vince Surf and Bob Khan who created it at",
    "start": "182879",
    "end": "188200"
  },
  {
    "text": "Dara um and what they really worked out was how to get the right abstraction around to to create this large",
    "start": "188200",
    "end": "193959"
  },
  {
    "text": "decentralized internet um and that was based on the IP protocol so they realized that if you want to have a",
    "start": "193959",
    "end": "199560"
  },
  {
    "text": "large decentralized internet where you can just have lots of computers talking to each other uh you need to be able to",
    "start": "199560",
    "end": "205080"
  },
  {
    "text": "have a way an abstraction that can allow this and the abstraction they settled for was the IP protocol",
    "start": "205080",
    "end": "210720"
  },
  {
    "text": "uh the analogy of it is just like uh mail sending letters in the post or something so you you write an address on",
    "start": "210720",
    "end": "217000"
  },
  {
    "text": "it an IP address send a bit of data it may or may not arrive uh it may or may",
    "start": "217000",
    "end": "222080"
  },
  {
    "text": "not be corrupted um you don't know where how it's going to get there um all the rest uh so you just send it out to this",
    "start": "222080",
    "end": "227959"
  },
  {
    "text": "magical thing called the internet and I had to put a cap picture on the slideshow somewhere so um right um but that's not like ideal",
    "start": "227959",
    "end": "237640"
  },
  {
    "text": "um if you want to actually uh be able to send data around you need something a bit better than that um so that's where",
    "start": "237640",
    "end": "243360"
  },
  {
    "text": "TCP comes in So based on this abstraction where we can send these bits of data out and we don't know if they're",
    "start": "243360",
    "end": "249120"
  },
  {
    "text": "going to arrive or not how do you make something reliable so the way the TCP tackles this is you break up your data",
    "start": "249120",
    "end": "254840"
  },
  {
    "text": "into lots of little chunks uh called packets um and for every packet you send",
    "start": "254840",
    "end": "260320"
  },
  {
    "text": "you make sure that packet has an acknowledgement that it's been received so if I'm going to send data to you I",
    "start": "260320",
    "end": "265560"
  },
  {
    "text": "break it up into a load of chunks send you those chunks and you acknowledge receipts of every single one of them",
    "start": "265560",
    "end": "271199"
  },
  {
    "text": "individually so I know that you've received the message uh we have a check sum to detect",
    "start": "271199",
    "end": "276840"
  },
  {
    "text": "corruption um and that's kind of it uh now if you did a naive implementation of this and just sent one packet waited to",
    "start": "276840",
    "end": "284000"
  },
  {
    "text": "be sure that it had been uh acknowledged and that's called an A in this diagram so this is a diagram of time going down",
    "start": "284000",
    "end": "291199"
  },
  {
    "text": "uh you send the data wait for it to be acknowledged and that takes latency time so you're looking at 50 milliseconds or",
    "start": "291199",
    "end": "296320"
  },
  {
    "text": "150 milliseconds and then I send another piece of data wait for it to be acknowledged um it's going to be",
    "start": "296320",
    "end": "303440"
  },
  {
    "text": "incredibly slow uh the point is you want to know how many do I send at a time before I wait for enough acknowledgement",
    "start": "303440",
    "end": "309440"
  },
  {
    "text": "to send some more uh and those are the key ideas that kind of build into the TCP algorithm so how do you send these",
    "start": "309440",
    "end": "316800"
  },
  {
    "text": "packets at maximum bit rate and how do you avoid overloading the network so if I just send out like 100 packets at once",
    "start": "316800",
    "end": "323400"
  },
  {
    "text": "they might all get dropped and the network can't handle it so I want to send out a certain amount work out how many are getting acknowledged and then",
    "start": "323400",
    "end": "329720"
  },
  {
    "text": "and make sure it's sending at the right rate um the other thing is TCP is a very",
    "start": "329720",
    "end": "335720"
  },
  {
    "text": "polite protocol so you don't just start sending loads of data to someone first you have this handshake where you say",
    "start": "335720",
    "end": "341240"
  },
  {
    "text": "can I send you data uh and you establish a connection first you could just start",
    "start": "341240",
    "end": "346400"
  },
  {
    "text": "sending data to someone but it's effectively that's not a way to build a staple Network um and you can also share",
    "start": "346400",
    "end": "353120"
  },
  {
    "text": "some prot options so that's called the synchronization um packet and it",
    "start": "353120",
    "end": "358560"
  },
  {
    "text": "contains other protocol options in it so I send a request to you and say I'd like to connect to you uh you send a request",
    "start": "358560",
    "end": "365039"
  },
  {
    "text": "back and say yes I acknowledged I received that um I would also like to send data to you and then I acknowledge",
    "start": "365039",
    "end": "370240"
  },
  {
    "text": "that so that's why it's called the three-way TCP handshake and at that point the connection's open and we can",
    "start": "370240",
    "end": "375759"
  },
  {
    "text": "now send data to each other it's a duplex connection so I can send data to you and you can send data to me um so",
    "start": "375759",
    "end": "383160"
  },
  {
    "text": "yeah and then there's one more part of the TCP algorithm I want to go into very briefly um and that's TCP",
    "start": "383160",
    "end": "390080"
  },
  {
    "text": "start so when we're talking about the idea around how do you know how many packets to send initially on the network",
    "start": "390080",
    "end": "397360"
  },
  {
    "text": "um what you do is you have a set number of packets initially and this is actually hardcoded into the operating",
    "start": "397360",
    "end": "402520"
  },
  {
    "text": "system so it says initially I'm just going to send 10 packets and wait for",
    "start": "402520",
    "end": "407800"
  },
  {
    "text": "those to be acknowledged and I'm going to double the number of packets that I can send uh so you get this exponential",
    "start": "407800",
    "end": "412960"
  },
  {
    "text": "growth in bit rate and this is like the kind of idea so I sent 10 packets initially normally about 1,300 bytes a",
    "start": "412960",
    "end": "419680"
  },
  {
    "text": "packet so I split up my data into those 10 chunks and then as they get acknowledged I start to send out the",
    "start": "419680",
    "end": "425199"
  },
  {
    "text": "next packets and then as those get acknowledged I start to send out the next ones and I double each time so that",
    "start": "425199",
    "end": "431080"
  },
  {
    "text": "I'm increasing my bit ratees um so that's how it kind of works out the best",
    "start": "431080",
    "end": "436840"
  },
  {
    "text": "uh bit rate for the entire network uh and that's called TCP slow start um once",
    "start": "436840",
    "end": "442720"
  },
  {
    "text": "it starts to get to the the right rate for the network it goes into these other states like um if packets start getting",
    "start": "442720",
    "end": "449199"
  },
  {
    "text": "dropped it can go into er error recovery congestion control and um like various",
    "start": "449199",
    "end": "455919"
  },
  {
    "text": "states that allow it to kind of um work out how quickly to send the packets so",
    "start": "455919",
    "end": "461120"
  },
  {
    "text": "that's why if you do a large download you'll see the speed kind of picks up gradually and then it kind of wave is about as it's dealing with these",
    "start": "461120",
    "end": "467159"
  },
  {
    "text": "different flow controls and that's all handled in TCP so we don't have to think about it um the other thing just about packet",
    "start": "467159",
    "end": "474520"
  },
  {
    "text": "size packet sizes have increased I think it used to be closer to about 5 or 600 bytes",
    "start": "474520",
    "end": "480120"
  },
  {
    "text": "and initially we used to only send two or three packets originally so here we've got 10 packets being sent",
    "start": "480120",
    "end": "485919"
  },
  {
    "text": "initially and it was only in 2011 that there was an RFC to change it from three packets to 10 packets as bit rates",
    "start": "485919",
    "end": "492520"
  },
  {
    "text": "around the world have increased so these kind of like fine level controls of the TCP algorithm itself have been updated",
    "start": "492520",
    "end": "500120"
  },
  {
    "text": "over the years um on this 40-year-old algorithm um so then when um Mr Beres",
    "start": "500120",
    "end": "507560"
  },
  {
    "text": "Lee came along and started developing the web um the idea was you would share a document that was built in HTML and you",
    "start": "507560",
    "end": "514120"
  },
  {
    "text": "would have this H um HTTP algorithm to share it and he just built it directly on top of",
    "start": "514120",
    "end": "520320"
  },
  {
    "text": "TCP so let's just have a look at an example page load today um and how that",
    "start": "520320",
    "end": "526279"
  },
  {
    "text": "gets shared over a TCP Network um so here I've got a page and",
    "start": "526279",
    "end": "532560"
  },
  {
    "text": "um we've got a stylesheet and a script and the stylesheet itself contains an",
    "start": "532560",
    "end": "537839"
  },
  {
    "text": "image inside of it so so uh once we've loaded that sty sheet we'll see there's an image and then we'll load that",
    "start": "537839",
    "end": "545200"
  },
  {
    "text": "image uh so we initially have the TCP handshake that's one round trip and then",
    "start": "545200",
    "end": "550399"
  },
  {
    "text": "we send a get request to load this uh index page itself and then we start",
    "start": "550399",
    "end": "557000"
  },
  {
    "text": "getting the response for that uh and so this is running over that TCP",
    "start": "557000",
    "end": "562720"
  },
  {
    "text": "protocol um I now see that I've got a sty sheet so I send another get request in the same connection and the the point",
    "start": "562720",
    "end": "569680"
  },
  {
    "text": "is that connections can be reused um but I can't actually request",
    "start": "569680",
    "end": "575320"
  },
  {
    "text": "the stylesheet um I can only request the Styles sheet because I've actually finished loading that HTML page so I can",
    "start": "575320",
    "end": "581440"
  },
  {
    "text": "only request one thing at a time on a single connection so I can say give me the index page and then I can get back",
    "start": "581440",
    "end": "587360"
  },
  {
    "text": "the index page and I say give me the sty sheet and I get it back on that connection there's no way I can request",
    "start": "587360",
    "end": "593480"
  },
  {
    "text": "two resources at the same time on a single TCP connection for http1 uh when I want to load that script",
    "start": "593480",
    "end": "601360"
  },
  {
    "text": "because I'm already loading the style on this one connection I actually have to open up another connection to load the",
    "start": "601360",
    "end": "606760"
  },
  {
    "text": "script so now we have two separate TCP connections and this is not the way the TCP was designed to be used",
    "start": "606760",
    "end": "613519"
  },
  {
    "text": "um the creating a new TCP connection is incredibly expensive for servers and for",
    "start": "613519",
    "end": "619440"
  },
  {
    "text": "the oper um and for the browser itself so brows is limited to a maximum",
    "start": "619440",
    "end": "625160"
  },
  {
    "text": "of between six and eight TCP connections that you open up when you do this kind of thing and that's where we have performance",
    "start": "625160",
    "end": "631839"
  },
  {
    "text": "issues when you have a lot of separate files um the browser knows about this so it's already done the handshake so the",
    "start": "631839",
    "end": "638200"
  },
  {
    "text": "other connection was sitting ready to go but it also needs to be warmed up through the TCP slow start to find out",
    "start": "638200",
    "end": "643600"
  },
  {
    "text": "what the right rate is for the optimum delivery um and in this scenario the",
    "start": "643600",
    "end": "649240"
  },
  {
    "text": "Styles sheet contained a banner image so then we sent a separate request to get that so we just use one of the open TCP",
    "start": "649240",
    "end": "654839"
  },
  {
    "text": "connections um so the the two issues we have here is firstly we've got um a new",
    "start": "654839",
    "end": "661680"
  },
  {
    "text": "connection for every single resource and then we have a separate round trip to load that ban image and those are the",
    "start": "661680",
    "end": "667480"
  },
  {
    "text": "two issues that we have and those are the two things that we optimize for um when optimizing for the front",
    "start": "667480",
    "end": "674880"
  },
  {
    "text": "end um so the idea with http2 is let's just have a single TCP connection and",
    "start": "674880",
    "end": "681639"
  },
  {
    "text": "just merge those two instead of opening a new connection just send the request over the same",
    "start": "681639",
    "end": "687519"
  },
  {
    "text": "connection and like it it really is as simple as that so um how do you do it",
    "start": "687519",
    "end": "692800"
  },
  {
    "text": "well you just assign a stream ID so instead of just saying I want to send a",
    "start": "692800",
    "end": "697959"
  },
  {
    "text": "get request for this file say I'm sending a get request for this file this is my first request and then when you",
    "start": "697959",
    "end": "703760"
  },
  {
    "text": "get a response you know is that part of my first request or part of my second request and you you literally just give a stream ID to the different requests",
    "start": "703760",
    "end": "710639"
  },
  {
    "text": "and then you can know which one's which and you can share the same pipe and then you don't have a connection limit um so",
    "start": "710639",
    "end": "716399"
  },
  {
    "text": "that's really it um you give each request in ID and now we we have",
    "start": "716399",
    "end": "721560"
  },
  {
    "text": "multiplexing uh so that's that's really all there is to it um I think the only thing that's really surprising about",
    "start": "721560",
    "end": "727399"
  },
  {
    "text": "HTTP 2 is the fact that it's taken uh 20 years to get there um 25 years",
    "start": "727399",
    "end": "734360"
  },
  {
    "text": "um uh and you can also have stream priorities so um you can say effectively",
    "start": "734360",
    "end": "740680"
  },
  {
    "text": "at the packet level these streams are being interleaved so I'm sending one packet for stream one and then one",
    "start": "740680",
    "end": "745839"
  },
  {
    "text": "packet for stream two and they're alternating uh and you can priorities so maybe you'll send five packets with",
    "start": "745839",
    "end": "751120"
  },
  {
    "text": "stream one and then one packet with stream two um Etc uh right so now let's go back and",
    "start": "751120",
    "end": "759720"
  },
  {
    "start": "755000",
    "end": "842000"
  },
  {
    "text": "look at the optimizations we make on the front end and how they relate to htp1 so",
    "start": "759720",
    "end": "766519"
  },
  {
    "text": "the sort of optimizations we do today are inlining um and sort of trying to get everything into one request is",
    "start": "766519",
    "end": "772639"
  },
  {
    "text": "effectively if you imagine this ideal of looking at something like the Google homepage where everything is just in in",
    "start": "772639",
    "end": "779000"
  },
  {
    "text": "the index page itself and there's no separate requests and it's very fast um",
    "start": "779000",
    "end": "784360"
  },
  {
    "text": "and that's the one side of the extreme and on the other side you've got like a single page with separate requests for",
    "start": "784360",
    "end": "790079"
  },
  {
    "text": "absolutely everything and in http1 we're sort of trying to move to this ideal of",
    "start": "790079",
    "end": "796000"
  },
  {
    "text": "everything just being one request in htb2 it's no longer the ideal that we need and we can move away from that and",
    "start": "796000",
    "end": "802519"
  },
  {
    "text": "just let things be as they work more nicely for us in our front- end architecture um front end development is",
    "start": "802519",
    "end": "809160"
  },
  {
    "text": "is complex enough without having to do Network optimizations um so the two reasons that",
    "start": "809160",
    "end": "817199"
  },
  {
    "text": "we bundle um avoid hitting the connection limit and avoid round trips uh with http2 the connection limit",
    "start": "817199",
    "end": "824680"
  },
  {
    "text": "problem no longer applies the only issue we have is round trips uh we still have the fact that I'm",
    "start": "824680",
    "end": "831079"
  },
  {
    "text": "loading a stylesheet and then I'm seeing that it has a banner image so then I'm sending another request for that image",
    "start": "831079",
    "end": "836639"
  },
  {
    "text": "and that that round trip of discovering sources as you load them becomes the new",
    "start": "836639",
    "end": "843040"
  },
  {
    "start": "842000",
    "end": "897000"
  },
  {
    "text": "problem uh and there's another thing that htdp describes which is called server push and let's the idea that well",
    "start": "843040",
    "end": "851600"
  },
  {
    "text": "we could actually replicate that idea of like a single page that contains everything uh by having a um a way that",
    "start": "851600",
    "end": "859639"
  },
  {
    "text": "this when the server first gets the request it just sends back everything you need so it knows you're going to need these files so it just pushes them",
    "start": "859639",
    "end": "866160"
  },
  {
    "text": "down to you and it says these are the other three streams you probably need just now the browser stores it in its",
    "start": "866160",
    "end": "871480"
  },
  {
    "text": "cache and as soon as there's a request for it from the browser side it just uses the version from the cache uh and",
    "start": "871480",
    "end": "877079"
  },
  {
    "text": "this is great when I first heard about it I was like well um server push is is actually what we really want that's like",
    "start": "877079",
    "end": "882199"
  },
  {
    "text": "amazing um so it's as I say identical to what you",
    "start": "882199",
    "end": "888000"
  },
  {
    "text": "would have got with the the full inlining approach it's exactly the same network profile uh but you're getting",
    "start": "888000",
    "end": "893680"
  },
  {
    "text": "browser caching which we don't normally have within lining uh and that that kind of leads on",
    "start": "893680",
    "end": "898920"
  },
  {
    "start": "897000",
    "end": "976000"
  },
  {
    "text": "to to this idea that you could have in the future of like smart web servers uh imagine a web server that knows HTML it",
    "start": "898920",
    "end": "905839"
  },
  {
    "text": "knows your resources and it can trace your critical render path set the stream priorities in http2 and and do all your",
    "start": "905839",
    "end": "912639"
  },
  {
    "text": "optimizations for you automatically um sort of it seems to be a really nice idea um you could imagine",
    "start": "912639",
    "end": "919279"
  },
  {
    "text": "cdns providing the sort of features where you just put it on the HTML page as you write it and the CDN does the",
    "start": "919279",
    "end": "925600"
  },
  {
    "text": "optimizations for you um the the the server push and the order priorities and",
    "start": "925600",
    "end": "931279"
  },
  {
    "text": "stuff isn't quite possible yet today um there are uh techniques that that should",
    "start": "931279",
    "end": "936680"
  },
  {
    "text": "be able to do that um but it will take a while for that to become widespread and",
    "start": "936680",
    "end": "941800"
  },
  {
    "text": "also it will take a while for hb2 to have wide enough adoption for us to use this kind of thing uh Speedy push itself",
    "start": "941800",
    "end": "949959"
  },
  {
    "text": "is I've used it on a few um applications in production and it can be unreliable",
    "start": "949959",
    "end": "955680"
  },
  {
    "text": "at points it is still an experimental protocol uh so",
    "start": "955680",
    "end": "960920"
  },
  {
    "text": "um at the moment Speedy push is actually something that today um is best not to",
    "start": "960920",
    "end": "967519"
  },
  {
    "text": "implement but I The Situation's changing all the time so next month it could reach a point of stability where it's",
    "start": "967519",
    "end": "973199"
  },
  {
    "text": "it's not giving those issues um so what can we do today with hb2",
    "start": "973199",
    "end": "979480"
  },
  {
    "start": "976000",
    "end": "1047000"
  },
  {
    "text": "approaches well the focus then I would say actually turns away from Speedy push",
    "start": "979480",
    "end": "985680"
  },
  {
    "text": "towards hinting approaches and prefetching approaches because that allows us to be able to do the optimizations so what I do is I just say",
    "start": "985680",
    "end": "993000"
  },
  {
    "text": "I know that the stylesheet contains this this Banner image so I'm just going to stick a a prefetch tag in the head that",
    "start": "993000",
    "end": "998839"
  },
  {
    "text": "says you're going to need this Banner image just now and that just cuts down that round trip because you can tell the",
    "start": "998839",
    "end": "1003880"
  },
  {
    "text": "browser immediately these are the things you're going to need and this is these General techniques are called hinting um",
    "start": "1003880",
    "end": "1010600"
  },
  {
    "text": "and it's the primary optimization you want to be using in a in a world of htb2",
    "start": "1010600",
    "end": "1015800"
  },
  {
    "text": "so you want to be making sure that resources are known as soon as possible right literally putting them into the",
    "start": "1015800",
    "end": "1020880"
  },
  {
    "text": "head of your page um it can also be sent as a server",
    "start": "1020880",
    "end": "1026438"
  },
  {
    "text": "header um it was actually disabled in the current version of Chrome I have no idea why um but it's something that's",
    "start": "1026439",
    "end": "1033079"
  },
  {
    "text": "been I mean this is an old problem so it's it's actually prefetching like this is supported across browsers um in older",
    "start": "1033079",
    "end": "1039000"
  },
  {
    "text": "versions of IE as well um but Chrome had it disabled they have recently re-enabled it for Chrome",
    "start": "1039000",
    "end": "1046640"
  },
  {
    "start": "1047000",
    "end": "1104000"
  },
  {
    "text": "38 um so prefetching is within the class of hinting uh types of",
    "start": "1047400",
    "end": "1053760"
  },
  {
    "text": "optimizations so the idea is you you find out what the Deep resources are in your tree that that you would have to",
    "start": "1053760",
    "end": "1059320"
  },
  {
    "text": "wait round trips to load and you hint them up front uh because you putting them in the",
    "start": "1059320",
    "end": "1065679"
  },
  {
    "text": "HTML page itself there's only a one round trip cost uh so in comparison to",
    "start": "1065679",
    "end": "1070720"
  },
  {
    "text": "server push hintch techniques aren't actually that expensive at all um and they work completely today",
    "start": "1070720",
    "end": "1079799"
  },
  {
    "text": "uh Ilia grigor um whose name comes up a lot in this space um it's almost",
    "start": "1079799",
    "end": "1085080"
  },
  {
    "text": "impossible to kind of touch on it without mentioning him um he's recently worked on a resource hint specification",
    "start": "1085080",
    "end": "1092120"
  },
  {
    "text": "which is um specifying these prefetching and hinting methods uh for browsers",
    "start": "1092120",
    "end": "1097679"
  },
  {
    "text": "going forward into this hp2 world and that's something you can check out he only released that last month",
    "start": "1097679",
    "end": "1103520"
  },
  {
    "text": "actually um so to just summarize um how the transition into HD to looks",
    "start": "1103520",
    "end": "1111600"
  },
  {
    "text": "um the the first step is enable Speedy today so um Speedy um without server",
    "start": "1111600",
    "end": "1118880"
  },
  {
    "text": "push the implementation is very stable it's used on sites like Google Twitter and Facebook uh you can literally just",
    "start": "1118880",
    "end": "1125440"
  },
  {
    "text": "switch it on for your sites so you just start using it and it falls back to normal",
    "start": "1125440",
    "end": "1130640"
  },
  {
    "text": "https uh when it's not supported so you can just start using it insights today",
    "start": "1130640",
    "end": "1136200"
  },
  {
    "text": "um the only real cost is the cost of an enabling a a secure server so if you",
    "start": "1136200",
    "end": "1141760"
  },
  {
    "text": "haven't already got HPS enabled that's the only real performance loss of enabling Speedy",
    "start": "1141760",
    "end": "1148120"
  },
  {
    "text": "today um cdns that support Speedy if you use cloud flare or Max CDN they both",
    "start": "1148120",
    "end": "1153960"
  },
  {
    "text": "support Speedy completely so you can uh just enable htps and then switch on the Speedy support for",
    "start": "1153960",
    "end": "1160640"
  },
  {
    "text": "them uh and if you use servers like ingenic or Apache uh there's lots of",
    "start": "1160640",
    "end": "1166960"
  },
  {
    "text": "upto-date server implementations as well and as I said the only real cost is",
    "start": "1166960",
    "end": "1172400"
  },
  {
    "text": "moving to enabling TLS uh again IL has a really good article on how to optimize",
    "start": "1172400",
    "end": "1179039"
  },
  {
    "text": "TLS in a in in genic um and if you focus on that kind of level of optimization or",
    "start": "1179039",
    "end": "1184799"
  },
  {
    "text": "use a CDN like cloudflare or Max CDN um you can make sure to have really fast",
    "start": "1184799",
    "end": "1190240"
  },
  {
    "text": "frontend performance and then in terms of how we approach the optimization once you've",
    "start": "1190240",
    "end": "1196000"
  },
  {
    "text": "turned on speedy and enabled it for your sites continue to use your current build process as you do it today um but as new",
    "start": "1196000",
    "end": "1203280"
  },
  {
    "text": "performance scenarios arise it becomes this kind of gradual path that we'll sort of be be moving over the next two",
    "start": "1203280",
    "end": "1210360"
  },
  {
    "text": "to three years or so where you can start to say well actually um we don't need to",
    "start": "1210360",
    "end": "1216120"
  },
  {
    "text": "put everything into one file and concatenate all our scripts together and it starts to become okay to have",
    "start": "1216120",
    "end": "1221760"
  },
  {
    "text": "separate files um you can start to think in terms of hinting over bundling um and",
    "start": "1221760",
    "end": "1227200"
  },
  {
    "text": "there should be a media performance benefits for enabling Speedy anyway today because most of us do have sites with getting into 50 requests that are",
    "start": "1227200",
    "end": "1235400"
  },
  {
    "text": "potentially going to be heavily optimized by that um and so it's this this transition",
    "start": "1235400",
    "end": "1241080"
  },
  {
    "text": "it's it's this gradient that we can move along and and not to be seen as something that's going to suddenly arrive and change everything but just",
    "start": "1241080",
    "end": "1247880"
  },
  {
    "text": "slowly we can change the way we think about optimization uh page speed has some",
    "start": "1247880",
    "end": "1254159"
  },
  {
    "text": "really good ways that it can selectively optimize so if you use page speed it can select itively concatenate your scripts",
    "start": "1254159",
    "end": "1260960"
  },
  {
    "text": "um and do like um compilations uh based on if you're using Speedy or not so we",
    "start": "1260960",
    "end": "1267200"
  },
  {
    "text": "can say this is hp1 so we want to sense the compacted version uh this is hp2 so we don't need to uh so that's pretty",
    "start": "1267200",
    "end": "1275400"
  },
  {
    "text": "good um so that's really all I wanted to say about http2 um and the other side of it is to",
    "start": "1275400",
    "end": "1284159"
  },
  {
    "text": "explain how it applies to es6 modules and what it means for work flows around",
    "start": "1284159",
    "end": "1289200"
  },
  {
    "text": "es6 modules um just to give a very brief",
    "start": "1289200",
    "end": "1295760"
  },
  {
    "start": "1292000",
    "end": "1431000"
  },
  {
    "text": "introduction so is6 modules it's a new syntax for writing modules in",
    "start": "1295760",
    "end": "1301200"
  },
  {
    "text": "JavaScript and it gives you this Import and Export statements so I can actually",
    "start": "1301200",
    "end": "1306720"
  },
  {
    "text": "import a JavaScript from another file and I can export certain variables and",
    "start": "1306720",
    "end": "1312000"
  },
  {
    "text": "functions and classes from my own Javascript file and uh this is uh the um",
    "start": "1312000",
    "end": "1318760"
  },
  {
    "text": "currently in the es6 specification which is the next version of JavaScript and it's set to be finalized",
    "start": "1318760",
    "end": "1326279"
  },
  {
    "text": "next year um but the draft is pretty much um it's a complete draft in terms",
    "start": "1326279",
    "end": "1332039"
  },
  {
    "text": "of features at the moment but it's still undergoing review and finalization in towards next year um so in this example",
    "start": "1332039",
    "end": "1339919"
  },
  {
    "text": "um I mean firstly what's what's been really great about working with is6 it's actually like a whole new way of writing",
    "start": "1339919",
    "end": "1345679"
  },
  {
    "text": "JavaScript um you can do it's a really nice language to work with uh so in this",
    "start": "1345679",
    "end": "1351159"
  },
  {
    "text": "example I'm loading a subass from another module uh just like commonjs or",
    "start": "1351159",
    "end": "1356279"
  },
  {
    "text": "um if you used requirejs I'm loading the module from the same folder so if this file is called my class. Js I'm loading",
    "start": "1356279",
    "end": "1363799"
  },
  {
    "text": "subclass module. JS in the same folder here and then I'm able to uh import a",
    "start": "1363799",
    "end": "1369120"
  },
  {
    "text": "variable from that a class and extend that class and Export that from this module um so when browsers Implement es6",
    "start": "1369120",
    "end": "1378159"
  },
  {
    "text": "module how does that loading profile look uh we have this Dynamic loader to",
    "start": "1378159",
    "end": "1384760"
  },
  {
    "text": "load in the browser called system and I can write system. import and then the name of the module that I want to load",
    "start": "1384760",
    "end": "1391159"
  },
  {
    "text": "uh so this will send a request to the my class. Js it then loads that file and sees that it's dependent on the subass",
    "start": "1391159",
    "end": "1398000"
  },
  {
    "text": "module that it's loading and it then sends a separate request to that so we have exactly the um the the the tiered",
    "start": "1398000",
    "end": "1405640"
  },
  {
    "text": "deep dependency loading um that can see here so it's loading the first one and then the second one and uh perhaps you",
    "start": "1405640",
    "end": "1413039"
  },
  {
    "text": "can see where this is going but the the primary optimization for es6 modules in",
    "start": "1413039",
    "end": "1418400"
  },
  {
    "text": "the world of http2 which will have major adoption around similar time scales as es6 modules is um the ability to trace",
    "start": "1418400",
    "end": "1426880"
  },
  {
    "text": "and hint a module tree for production which I'll show you shortly um and if you want to use E6",
    "start": "1426880",
    "end": "1434520"
  },
  {
    "start": "1431000",
    "end": "1474000"
  },
  {
    "text": "modules today uh there's a project called systemjs which actually allow allows you to be able to write um code",
    "start": "1434520",
    "end": "1441200"
  },
  {
    "text": "like this today so I can load a common JS or AMD um in the browser",
    "start": "1441200",
    "end": "1446640"
  },
  {
    "text": "today um so I include the loader um and then I get the system Global that I can",
    "start": "1446640",
    "end": "1453360"
  },
  {
    "text": "then use to import and I can type the name of the module and it'll then go load that module see its dependencies",
    "start": "1453360",
    "end": "1459520"
  },
  {
    "text": "load those modules and it it runs exactly the way that is specified in the es6 module specification um but it adds",
    "start": "1459520",
    "end": "1466799"
  },
  {
    "text": "compatibility layers to make it easy to use um",
    "start": "1466799",
    "end": "1472130"
  },
  {
    "text": "[Music] so yeah as I said the the production workflows is we can create a bundle so",
    "start": "1472130",
    "end": "1479200"
  },
  {
    "start": "1474000",
    "end": "1532000"
  },
  {
    "text": "we can compact all our scripts into one um but what I'm really interested in is um the ways that we can approach tracing",
    "start": "1479200",
    "end": "1486240"
  },
  {
    "text": "and hinting modules into in production so if you imagine um a large application",
    "start": "1486240",
    "end": "1493039"
  },
  {
    "text": "with lots of separate uh javascripts running on it between different pages of the app and I want to be able to load",
    "start": "1493039",
    "end": "1499200"
  },
  {
    "text": "some scripts on some pages and other scripts on other Pages uh the optimization around that you effectively",
    "start": "1499200",
    "end": "1505320"
  },
  {
    "text": "have to create sub bundles for different areas of your app and that becomes a very complex problem if you can just",
    "start": "1505320",
    "end": "1511440"
  },
  {
    "text": "deal with modules being loaded separately um it suddenly becomes a lot simpler thing to deal with because I can",
    "start": "1511440",
    "end": "1517120"
  },
  {
    "text": "just load the modules that I need on this page and on another page I can just load the modules I need there and the",
    "start": "1517120",
    "end": "1523279"
  },
  {
    "text": "browser cache gets shared between those pages so I don't need to worry about how I bundle optimize where we're allowing",
    "start": "1523279",
    "end": "1528760"
  },
  {
    "text": "the network to handle optimizations so I want to to show you a very quick demo of how we can do this",
    "start": "1528760",
    "end": "1535600"
  },
  {
    "start": "1532000",
    "end": "1824000"
  },
  {
    "text": "today um the demo I'm going to show uses jspm uh and um this is the reason why",
    "start": "1535600",
    "end": "1543240"
  },
  {
    "text": "I'm using jspm to to demo this is because it's an easy way that I can show the es6 module loader in",
    "start": "1543240",
    "end": "1549159"
  },
  {
    "text": "production uh",
    "start": "1549159",
    "end": "1552559"
  },
  {
    "text": "right so I've already set up this applic I've got a main uh",
    "start": "1555559",
    "end": "1562760"
  },
  {
    "text": "page and I'm loading the systemjs loader which gives me the ability to load es6",
    "start": "1563240",
    "end": "1568679"
  },
  {
    "text": "modules um but right now what I'm doing is loading commonjs so uh the next thing",
    "start": "1568679",
    "end": "1574600"
  },
  {
    "text": "I've got in the page is a configuration file which has been automatically generated by jspm so I didn't have to",
    "start": "1574600",
    "end": "1579720"
  },
  {
    "text": "make that myself and that just tells it where to find modules and then I've got the system",
    "start": "1579720",
    "end": "1585600"
  },
  {
    "text": "that I can now write and start loading a module file with in this case I'm importing a module from",
    "start": "1585600",
    "end": "1590960"
  },
  {
    "text": "mpm and it's called voxal demo and uh so when I run this import it sends a",
    "start": "1590960",
    "end": "1597440"
  },
  {
    "text": "request to that commonjs module file it loads the commonjs and sees its dependencies and then separately sends",
    "start": "1597440",
    "end": "1603360"
  },
  {
    "text": "requests for for the dependencies and and resolves the module so I'm just",
    "start": "1603360",
    "end": "1609039"
  },
  {
    "text": "going to load this up here and show you what the network profile looks like",
    "start": "1609039",
    "end": "1616360"
  },
  {
    "text": "so it loaded about 130 modules in this case and it's a 3D library with lots of",
    "start": "1627520",
    "end": "1632720"
  },
  {
    "text": "stuff going on and you'll see in the network tab we have a tiered loading so I'm loading initially I load the first",
    "start": "1632720",
    "end": "1640399"
  },
  {
    "text": "module um having loaded that module I load its dependencies and then in",
    "start": "1640399",
    "end": "1645600"
  },
  {
    "text": "parallel I can load all the dependencies of that module and you see I've got more than six requests going at the same time",
    "start": "1645600",
    "end": "1651279"
  },
  {
    "text": "because this is running over Speedy so I'm able to request 10 modules at the same time over the connection I discover",
    "start": "1651279",
    "end": "1657080"
  },
  {
    "text": "their dependencies and I then download those dependencies in parallel and it's sort of going down the dependency tree",
    "start": "1657080",
    "end": "1662519"
  },
  {
    "text": "and the deeper the dependency tree that's our key performance cost so to make this work well in production what",
    "start": "1662519",
    "end": "1668399"
  },
  {
    "text": "we want to be able to do is flatten that dependency tree and load all 130 of those modules initially in one round",
    "start": "1668399",
    "end": "1674399"
  },
  {
    "text": "trip and jspm provides the functionality to to do this um it's called a",
    "start": "1674399",
    "end": "1680320"
  },
  {
    "text": "dependency cache so just like we would do prefetching or hinting I inject the",
    "start": "1680320",
    "end": "1685679"
  },
  {
    "text": "full tree information into the head of the page and as soon as there's a request to the module I know that the",
    "start": "1685679",
    "end": "1691159"
  },
  {
    "text": "dependency is up front so I know I need to download all these modules at the same time and the client is able to pull",
    "start": "1691159",
    "end": "1696440"
  },
  {
    "text": "because it knows what it needs so I'm just going to say dep cache this",
    "start": "1696440",
    "end": "1701919"
  },
  {
    "text": "module and it traces the tree and injects the full dependency",
    "start": "1701919",
    "end": "1706960"
  },
  {
    "text": "cache um I've got disabled caches um here um so when I refresh the page now",
    "start": "1706960",
    "end": "1714559"
  },
  {
    "text": "you should see that it loads all of those resources in parallel as a single request and then we get a much quicker",
    "start": "1714559",
    "end": "1720000"
  },
  {
    "text": "page load because we've now optimized for the Speedy connection uh so you see had loaded 130 modules in parallel",
    "start": "1720000",
    "end": "1726080"
  },
  {
    "text": "because it's Multiplex there's no problem with doing that each of these modules is now cached in the browser so",
    "start": "1726080",
    "end": "1731600"
  },
  {
    "text": "if I had another page of the site that shared modules with those I can just load the modules I need and I'd get them from the cache so it makes the problems",
    "start": "1731600",
    "end": "1738640"
  },
  {
    "text": "of of bundling large module applications a lot simpler when you allow the network to handle the the",
    "start": "1738640",
    "end": "1745799"
  },
  {
    "text": "optimizations um so that's that",
    "start": "1745799",
    "end": "1751000"
  },
  {
    "text": "okay so takeaways um I think just to start using",
    "start": "1755640",
    "end": "1762440"
  },
  {
    "text": "Speedy is amazing so there's no reason really not to enable it unless you haven't already got SSL enabled um and",
    "start": "1762440",
    "end": "1770360"
  },
  {
    "text": "then put putting more pressure on performance measurements and optimization around Speedy um it's it's",
    "start": "1770360",
    "end": "1777159"
  },
  {
    "text": "something that that can grow and and putting pressure on the server push implementation as well would be great",
    "start": "1777159",
    "end": "1782679"
  },
  {
    "text": "because not enough people are putting pressure on it um uh I had a bug and posted a bug on it and was able to get",
    "start": "1782679",
    "end": "1789360"
  },
  {
    "text": "some progress on that but it would really help to to put more pressure on implementations the only way we move",
    "start": "1789360",
    "end": "1794600"
  },
  {
    "text": "things forward is by using it and it's it's by implementers using using these systems that that things are able to get",
    "start": "1794600",
    "end": "1800159"
  },
  {
    "text": "better and performance optimized and there's um fine grain optimizations at the protocol level that will be made as",
    "start": "1800159",
    "end": "1806480"
  },
  {
    "text": "people start to use it more and more uh so yeah check it out and thanks very much for listening",
    "start": "1806480",
    "end": "1814090"
  },
  {
    "text": "[Applause]",
    "start": "1814090",
    "end": "1820539"
  }
]
[
  {
    "start": "0",
    "end": "38000"
  },
  {
    "text": "[Music]",
    "start": "2550",
    "end": "13559"
  },
  {
    "text": "my name is mato I'm the CTO for loyal 3 and today I'm going to talk to you about one of my favorite open source platforms",
    "start": "13559",
    "end": "21320"
  },
  {
    "text": "Twitter's finagle um",
    "start": "21320",
    "end": "27359"
  },
  {
    "text": "well in Twitter's own words nles a network stack for the jvm that lets you build",
    "start": "27359",
    "end": "32759"
  },
  {
    "text": "RPC applications in a protocol agnostic way well why do we need another one of",
    "start": "32760",
    "end": "40000"
  },
  {
    "start": "38000",
    "end": "134000"
  },
  {
    "text": "these things you might ask if I take you back a little bit long",
    "start": "40000",
    "end": "45559"
  },
  {
    "text": "ago when we starting web applications or maybe when a company first starts writing them they're very simple you've",
    "start": "45559",
    "end": "51120"
  },
  {
    "text": "got a web application talks to a database pretty easy But as time goes on what you find is that you add complexity",
    "start": "51120",
    "end": "58559"
  },
  {
    "text": "to the system it's not not enough just to talk to the database now you introduce a Services layer you might",
    "start": "58559",
    "end": "64280"
  },
  {
    "text": "have an API server as an abstraction so you've got service a and service B but",
    "start": "64280",
    "end": "69320"
  },
  {
    "text": "it doesn't stop there it goes on right you decide that oh you know service B really needs to call these",
    "start": "69320",
    "end": "75520"
  },
  {
    "text": "other services maybe we need a queuing solution maybe we need to call this other external service and your",
    "start": "75520",
    "end": "80920"
  },
  {
    "text": "environment grows maybe you decide at that point now is the time to have a mobile system so",
    "start": "80920",
    "end": "87840"
  },
  {
    "text": "you add the mobile interface and your environment grows again what happens is not before not too",
    "start": "87840",
    "end": "95200"
  },
  {
    "text": "long boom you've actually got a pretty fully fleshed environment a distributed processing system looks a lot like",
    "start": "95200",
    "end": "101560"
  },
  {
    "text": "Tumblr looks a lot like Facebook Twitter a lot of the systems that you",
    "start": "101560",
    "end": "107479"
  },
  {
    "text": "see so in addition to that not only do you have lots of services but most of",
    "start": "107799",
    "end": "113320"
  },
  {
    "text": "these Services have their own protocols you got a little bit of HTTP here a little bit of thrift over there some",
    "start": "113320",
    "end": "119399"
  },
  {
    "text": "jdbc Cassandra reddis Etc and typically each one of these protocols comes with",
    "start": "119399",
    "end": "124560"
  },
  {
    "text": "its own libraries jars Etc to go manage it with all this stuff hey what could go",
    "start": "124560",
    "end": "133840"
  },
  {
    "text": "wrong the reality is as you heard from the previous talk there's actually quite a bit of stuff that can go wrong I'm not",
    "start": "133840",
    "end": "141200"
  },
  {
    "start": "134000",
    "end": "303000"
  },
  {
    "text": "going to bother to go through this list we uh the previous talk I think he did a great job of going through but there's a",
    "start": "141200",
    "end": "146280"
  },
  {
    "text": "bunch of stuff that happens and that can happen so what was what is a solution to",
    "start": "146280",
    "end": "154640"
  },
  {
    "text": "this well the way I think of it is I think of finagle as an expressive",
    "start": "154640",
    "end": "161480"
  },
  {
    "text": "network library to develop these applications so not only does it handle the networking layer but it also handles",
    "start": "161480",
    "end": "168280"
  },
  {
    "text": "some of the core libraries and services underneath that well what does that",
    "start": "168280",
    "end": "174319"
  },
  {
    "text": "mean finagle actually has quite a few pieces to it and what I'll do is I'll break up this talk into to two parts one",
    "start": "174319",
    "end": "181319"
  },
  {
    "text": "is as an asynchronous Futures framework and the second is as a common infrastructure that you can build your",
    "start": "181319",
    "end": "187760"
  },
  {
    "text": "client and server applications on so let me first turn to the uh the asynchronous",
    "start": "187760",
    "end": "194760"
  },
  {
    "text": "platform finagle is nice it reduces the world and says if you're going to be doing asynchronous RPC development",
    "start": "195799",
    "end": "201799"
  },
  {
    "text": "there's only three basic constructs you need to worry about a future a service",
    "start": "201799",
    "end": "206959"
  },
  {
    "text": "and a filter the first one a",
    "start": "206959",
    "end": "211680"
  },
  {
    "text": "future we've heard a number of talks on it now it's a computation that not has not yet completed it's more less a",
    "start": "212120",
    "end": "218080"
  },
  {
    "text": "promise of something to be done later most of the time it's either",
    "start": "218080",
    "end": "224519"
  },
  {
    "text": "non-blocking or it's implemented through either non-blocking code or a threadpool in the case of",
    "start": "224519",
    "end": "230760"
  },
  {
    "text": "finagle finagle almost entirely uses non-blocking code so if you've heard of Frameworks like uh event machine for",
    "start": "230760",
    "end": "238000"
  },
  {
    "text": "Ruby or Twisted for python nodejs it's the same idea rather than creating a large thread pool um to handle these",
    "start": "238000",
    "end": "246079"
  },
  {
    "text": "asynchronous calls what it does is use a small number of connection or small number of threads uh to basically manage",
    "start": "246079",
    "end": "253040"
  },
  {
    "text": "this so it's using non-blocking Code almost throughout the entire thing it gives you the option if you want to use",
    "start": "253040",
    "end": "258680"
  },
  {
    "text": "a thread pool you can but by default it's going to be",
    "start": "258680",
    "end": "263239"
  },
  {
    "text": "non-blocking I think the thing that the previous speaker alluded to is that one of the challenges with Futures is",
    "start": "267240",
    "end": "273600"
  },
  {
    "text": "currently there's a lot of choices you know you've got the Twitter Futures the concurrent the actors aa's version scal",
    "start": "273600",
    "end": "280360"
  },
  {
    "text": "Z there's a lot of version the Futures what I'm going to be focusing on as you might expect is just one of them um even",
    "start": "280360",
    "end": "287560"
  },
  {
    "text": "though there's a bunch of dialects right the dialect that I'll be talking about is the Twitter future and what we find",
    "start": "287560",
    "end": "293919"
  },
  {
    "text": "is since so much of our stack is built on this um there's not a lot of interoperability for us we just kind of",
    "start": "293919",
    "end": "299639"
  },
  {
    "text": "of picked this one and went with it I find sometimes the easiest way to",
    "start": "299639",
    "end": "306160"
  },
  {
    "start": "303000",
    "end": "471000"
  },
  {
    "text": "Gro the way it does is just to give you a bunch of examples so I'm going to go through and talk about different things",
    "start": "306160",
    "end": "311919"
  },
  {
    "text": "you can do with them so here's a really basic example valve future of user is",
    "start": "311919",
    "end": "317280"
  },
  {
    "text": "take this user service and look up an email so it's just a basic thing of look up this user by email and give me a",
    "start": "317280",
    "end": "324400"
  },
  {
    "text": "promise at of the future when it'll be done now let's see what we can do with that the first is I can say well forget",
    "start": "324400",
    "end": "331520"
  },
  {
    "text": "this asynchronous stuff I just want to treat it like regular blocking code so I can call get on it and that will just",
    "start": "331520",
    "end": "337160"
  },
  {
    "text": "return me the user object so I can treat it as if it was synchronous this is really good for testing where you don't",
    "start": "337160",
    "end": "342800"
  },
  {
    "text": "necessarily want to have to wait you just want to say go do it",
    "start": "342800",
    "end": "347520"
  },
  {
    "text": "now but in the real world we often times we don't want to block we want to do things in parallel so here's a case",
    "start": "349800",
    "end": "355560"
  },
  {
    "text": "where I might have a cache service and I want to look up three key values key 1 key2 key3 and I want to do all those",
    "start": "355560",
    "end": "362199"
  },
  {
    "text": "simultaneously so when I make these three invocations none of these blocks I immediately drop down to this",
    "start": "362199",
    "end": "368960"
  },
  {
    "text": "location so that's kind of nice but I really want to be able to at some point maybe render a web page so I want to",
    "start": "371080",
    "end": "377599"
  },
  {
    "text": "know when all three of these are done and I don't want to have to wait and do a get on each one of these sequentially what I'll do is I can combine them",
    "start": "377599",
    "end": "384319"
  },
  {
    "text": "together take future one future two Future Three put them into a sequence",
    "start": "384319",
    "end": "389560"
  },
  {
    "text": "and then just say join them together and just say tell me when this is done so now when finish doget is called when",
    "start": "389560",
    "end": "395599"
  },
  {
    "text": "this finishes it means that all the Futures that are composed in there will have finished it's a nice handy",
    "start": "395599",
    "end": "403440"
  },
  {
    "text": "shortcut in other cases I might want to transform a future I've got this user that we talked about we looked him up",
    "start": "403440",
    "end": "409479"
  },
  {
    "text": "from the email and uh so now we've got this reference but now I want to create a session off of it so I can use just a",
    "start": "409479",
    "end": "417400"
  },
  {
    "text": "standard collection operation a map and and transform that user now into a future of a session it gives me a really",
    "start": "417400",
    "end": "423919"
  },
  {
    "text": "easy way of composing and chaining these things together really my goal in kind of uh machine gunning through these is",
    "start": "423919",
    "end": "430879"
  },
  {
    "text": "to give you a sense that once you've got it into this format it's not very difficult to work with at all there's a lot you can do with in terms of",
    "start": "430879",
    "end": "436919"
  },
  {
    "text": "transformations in terms of chaining it's a very simple way to think about things it doesn't add a lot of overhead",
    "start": "436919",
    "end": "442440"
  },
  {
    "text": "to your code keeps it very simple there are cases where you might",
    "start": "442440",
    "end": "449160"
  },
  {
    "text": "have do this then do this then do this then do this and as we've seen in other talks you can use a for comprehension to",
    "start": "449160",
    "end": "455680"
  },
  {
    "text": "basically turn those that chain into a singular operation where you can use a for",
    "start": "455680",
    "end": "461680"
  },
  {
    "text": "comprehension to just go through and say here first do this pass it to this and then you know render the",
    "start": "461680",
    "end": "470240"
  },
  {
    "start": "471000",
    "end": "958000"
  },
  {
    "text": "result here's one of my favorite things to do um if you guys have ever done performance testing what you'll notice",
    "start": "471120",
    "end": "477680"
  },
  {
    "text": "is that uh usually the the response rates look pretty good and usually when you get to the 90th 95th 99th percentile",
    "start": "477680",
    "end": "484879"
  },
  {
    "text": "your curve goes from Flat to straight up right there's always that 1% out there that half percent that responds really",
    "start": "484879",
    "end": "491360"
  },
  {
    "text": "badly right well an easy way a way to get rid of that is instead of making a",
    "start": "491360",
    "end": "496440"
  },
  {
    "text": "single request and having that long tail out at the end turns out if you make two requests for the same service let's say",
    "start": "496440",
    "end": "502560"
  },
  {
    "text": "I'm looking up something from my my cash or I'm looking up something remotely if I can afford to make if the back end can",
    "start": "502560",
    "end": "508560"
  },
  {
    "text": "handle two cost calls if I make two simultaneous calls and just take the first one that comes back turns out that",
    "start": "508560",
    "end": "515039"
  },
  {
    "text": "long tail at the end at the 90th percentile 95th and 99th goes way way down your curve goes from something",
    "start": "515039",
    "end": "520518"
  },
  {
    "text": "looks like this to something looks a lot lot smoother and so the effect of that",
    "start": "520519",
    "end": "526200"
  },
  {
    "text": "is the response time to your users is much much better how much code does that take with finagle well let's say I have",
    "start": "526200",
    "end": "533360"
  },
  {
    "text": "these two things I want to look up in parallel future one and future two I can now just say here's a sequence of two",
    "start": "533360",
    "end": "539680"
  },
  {
    "text": "things I want you to look at and the number could be any any number look up five look up six at a time",
    "start": "539680",
    "end": "545760"
  },
  {
    "text": "whatever and what I want is tell me the first I want to select the first one that comes back as my result what it",
    "start": "545760",
    "end": "552399"
  },
  {
    "text": "returns to you this object I didn't want to do the the signature because it's kind of a long signature is it gives you",
    "start": "552399",
    "end": "557839"
  },
  {
    "text": "the result of the first response and then all the remaining responses just in case you want to cancel or do something",
    "start": "557839",
    "end": "562920"
  },
  {
    "text": "with them so in this case I just said give me all the responses give me the first one and here's the value",
    "start": "562920",
    "end": "570959"
  },
  {
    "text": "you know again the beauty of finagle in my mind is it made it very very simple to do this without a lot of complexity",
    "start": "570959",
    "end": "578279"
  },
  {
    "text": "right this is something that you could easily get your developers to go",
    "start": "578279",
    "end": "583600"
  },
  {
    "text": "do well let's keep adding complexity to this sometimes I want to get back to my",
    "start": "583600",
    "end": "588720"
  },
  {
    "text": "users and let's say I've got that longtail still and that long tail is somewhere out there at 15c response",
    "start": "588720",
    "end": "594040"
  },
  {
    "text": "times I don't want that I don't want to want to respond to my user in 15 seconds if it takes that long I want to go do something else so what I want is to say",
    "start": "594040",
    "end": "601240"
  },
  {
    "text": "after maybe 5 seconds stop it and let me do something come back to me so I can",
    "start": "601240",
    "end": "607839"
  },
  {
    "text": "just take that future same thing we have before the lookup and I can just say within within this timeout within 5",
    "start": "607839",
    "end": "615279"
  },
  {
    "text": "Seconds you have to finish or it's an exception right so now I have not only the ability to control that long tail",
    "start": "615279",
    "end": "622040"
  },
  {
    "text": "but I can say well my service level is a 5-second response I'm going to give you something at the end of 5",
    "start": "622040",
    "end": "628040"
  },
  {
    "text": "Seconds and again not much code to do",
    "start": "628040",
    "end": "633279"
  },
  {
    "text": "it well sometimes problems happen right so let's say there's",
    "start": "634680",
    "end": "640399"
  },
  {
    "text": "something wrong and maybe the service is down with the future I can just say handle this exception and it looks like",
    "start": "640399",
    "end": "647399"
  },
  {
    "text": "many other sort of exception handling block and I can handle the exception here and then return the same type and",
    "start": "647399",
    "end": "653120"
  },
  {
    "text": "go on my Merry way so as far as the service is concerned um I can deal with",
    "start": "653120",
    "end": "659079"
  },
  {
    "text": "with something return a future strength in this block and life will just keep",
    "start": "659079",
    "end": "664600"
  },
  {
    "text": "going right so it gives me the ability to maybe I want to retry through something else maybe I want to try a different key you know whatever the",
    "start": "664600",
    "end": "671279"
  },
  {
    "text": "option is I have the ability to go do it so that's really Futures in kind of a",
    "start": "671279",
    "end": "677680"
  },
  {
    "text": "quick nutshell and that's the first leg the second leg is service so finagle",
    "start": "677680",
    "end": "683839"
  },
  {
    "text": "treats everything as a service so if you're talking to a remote Thrift application if you're talking to a rest",
    "start": "683839",
    "end": "689560"
  },
  {
    "text": "API if you're talking to whatever it is that talks Thrift protuff you know redus",
    "start": "689560",
    "end": "696120"
  },
  {
    "text": "mcash whatever um it's the thing that hand oops wrong",
    "start": "696120",
    "end": "704480"
  },
  {
    "text": "direction a service is the thing that handles the rpcs that takes the request and gives back replies um it will always",
    "start": "704480",
    "end": "712320"
  },
  {
    "text": "conform to this signature now if you actually look at the code itself there's a little bit more to it I've simplified",
    "start": "712320",
    "end": "717760"
  },
  {
    "text": "it to make it easy easier to uh to see here um but ultimately service it has a",
    "start": "717760",
    "end": "725320"
  },
  {
    "text": "request type and a response type and depending what the protocol is that you're talking for an HTTP you might end",
    "start": "725320",
    "end": "731200"
  },
  {
    "text": "up with an HTTP request HTTP response if you're talking redis you might end up",
    "start": "731200",
    "end": "736240"
  },
  {
    "text": "with command and reply uh as the instances of objects depending on the protocol the request",
    "start": "736240",
    "end": "742360"
  },
  {
    "text": "and response types will be the same but the interface is exactly the same you to",
    "start": "742360",
    "end": "747519"
  },
  {
    "text": "is service request response that has an",
    "start": "747519",
    "end": "752079"
  },
  {
    "text": "apply so let's make a web server out of uh finagle so here is the uh here's the",
    "start": "752639",
    "end": "757959"
  },
  {
    "text": "toy version of creating a web server so here is my service my service is basically",
    "start": "757959",
    "end": "763639"
  },
  {
    "text": "something that will respond to anything and just say okay it gives you a blank page back right it's you know it's the",
    "start": "763639",
    "end": "769800"
  },
  {
    "text": "toy version that you might see on like an event machine or nodejs and all I'm doing is saying here give me a new",
    "start": "769800",
    "end": "775680"
  },
  {
    "text": "service and I'm creating a new future and giving you back a response with a",
    "start": "775680",
    "end": "781040"
  },
  {
    "text": "version of one one and a status of okay now let's create the actual web",
    "start": "781040",
    "end": "787279"
  },
  {
    "text": "server so I can use this uh a fluent interface and say I want a server it's",
    "start": "787279",
    "end": "794440"
  },
  {
    "text": "going to talk HTTP I want it to talk on Port 5000 I'm going to call it web server and",
    "start": "794440",
    "end": "802360"
  },
  {
    "text": "it's bound to this service so in this case this is a web server implantation but this might be a",
    "start": "802360",
    "end": "808839"
  },
  {
    "text": "Thrift implementation protuff Etc this doesn't change it's the same so once I",
    "start": "808839",
    "end": "814079"
  },
  {
    "text": "run that I've got my asynchronous non-blocking server up and running what's the flip side if I want",
    "start": "814079",
    "end": "819800"
  },
  {
    "text": "to do a client well a client turns out has another Builder to help you create it",
    "start": "819800",
    "end": "825880"
  },
  {
    "text": "and it looks awfully similar so client then you specify the",
    "start": "825880",
    "end": "832800"
  },
  {
    "text": "protocol in this case we want HTTP how long do we want to be able to take to connect what host do I connect",
    "start": "832800",
    "end": "838720"
  },
  {
    "text": "conect to how many current connections will I allow before back pressure starts kicking",
    "start": "838720",
    "end": "844240"
  },
  {
    "text": "in boom create this client and now to utilize this finagle",
    "start": "844240",
    "end": "850120"
  },
  {
    "text": "client I can create a new default HTTP request just a simple thing I here is a",
    "start": "850120",
    "end": "855199"
  },
  {
    "text": "get request for the homepage and I fire that into the uh the client and it gives me back a future",
    "start": "855199",
    "end": "862279"
  },
  {
    "text": "response now the thing another thing that I love about this is because there's a very simple interface for",
    "start": "862279",
    "end": "867680"
  },
  {
    "text": "services this can be mocked up tremendously easily so when we're testing the application you know if we",
    "start": "867680",
    "end": "874600"
  },
  {
    "text": "want to do a actual live connection or if we want to do a fake connection that just implements this um it's very very",
    "start": "874600",
    "end": "881160"
  },
  {
    "text": "easy to just swap one out because the client doesn't really care you know when you're invoking this you just want",
    "start": "881160",
    "end": "886880"
  },
  {
    "text": "something that implements this",
    "start": "886880",
    "end": "890680"
  },
  {
    "text": "interface so just for giggles I'm going to change up that web client and now we're going to make it a redus client so",
    "start": "894759",
    "end": "901000"
  },
  {
    "text": "now we've basically taken the previous code swapped it so now it'll make a simple redus request for my key and you",
    "start": "901000",
    "end": "908320"
  },
  {
    "text": "notice that nothing's really change or not that much has really changed in",
    "start": "908320",
    "end": "913920"
  },
  {
    "text": "fact here's the only change that we've made as you can see HTTP request HTTP",
    "start": "913920",
    "end": "919680"
  },
  {
    "text": "response has changed into command and reply the codic has now changed to reddis and instead of creating a new",
    "start": "919680",
    "end": "926800"
  },
  {
    "text": "HTTP request we're now creating a a redus command so get delete whatever the Reedus commands are those are the things",
    "start": "926800",
    "end": "933600"
  },
  {
    "text": "we're sending in and instead of getting HTTP response we get a reply back it's really nice to have your team just only",
    "start": "933600",
    "end": "940240"
  },
  {
    "text": "need to learn things one way and once you've learned things the one way regardless of the protocol that you're",
    "start": "940240",
    "end": "945319"
  },
  {
    "text": "working with you have the same conceptual model it always works the same way and this is just as",
    "start": "945319",
    "end": "950800"
  },
  {
    "text": "asynchronous as the previous bit was if we replaced it with Thrift again it's still non-blocking and",
    "start": "950800",
    "end": "957560"
  },
  {
    "text": "asynchronous so the last leg of uh of what finagle is built with is a filter",
    "start": "957600",
    "end": "964600"
  },
  {
    "start": "958000",
    "end": "1348000"
  },
  {
    "text": "and filter can basically be thought of as something that transforms a service a common filter might be something like",
    "start": "964600",
    "end": "970519"
  },
  {
    "text": "authentication so instead of taking an HTTP request and um returning on HTTP",
    "start": "970519",
    "end": "977399"
  },
  {
    "text": "response maybe instead you transform that HTTP request to an authenticated HTTP request right just like service it",
    "start": "977399",
    "end": "985600"
  },
  {
    "text": "also is a a future so that it'll be non-blocking it's a great way to be able to decompose",
    "start": "985600",
    "end": "991360"
  },
  {
    "text": "Services into phases for example let's say you have something like uh you want to do rate limiting maybe you want to do",
    "start": "991360",
    "end": "997880"
  },
  {
    "text": "rate limiting for your internal servers maybe you want to do it for your external servers you can implement the rate limit as a filter and then whatever",
    "start": "997880",
    "end": "1005920"
  },
  {
    "text": "sort of RPC you have client or server side you can just say oh great stick",
    "start": "1005920",
    "end": "1012240"
  },
  {
    "text": "this rate filter on and boom you don't have to rewrite the raid filter as the mcache version of it and the thrift",
    "start": "1012240",
    "end": "1019720"
  },
  {
    "text": "version of it and the Cassandra version of it",
    "start": "1019720",
    "end": "1023600"
  },
  {
    "text": "Etc okay so that's part one of basically finagle as the asynchronous platform it",
    "start": "1025679",
    "end": "1032600"
  },
  {
    "text": "makes it very very simple to write a Futures based non-blocking code the second part and for me this is",
    "start": "1032600",
    "end": "1039600"
  },
  {
    "text": "almost more exciting than the the first part um it's a common framework to build",
    "start": "1039600",
    "end": "1044678"
  },
  {
    "text": "things on the there's a bunch of things that I don't want to have to write over and",
    "start": "1044679",
    "end": "1050600"
  },
  {
    "text": "over again every time I create a new um RPC call so there's connection pooling load balancing failure detection",
    "start": "1050600",
    "end": "1056960"
  },
  {
    "text": "failover distributed tracing service Discovery statistics SSL bindings Etc",
    "start": "1056960",
    "end": "1062799"
  },
  {
    "text": "what typically I would have to do without a finagle is for every single protocol they usually have their",
    "start": "1062799",
    "end": "1069360"
  },
  {
    "text": "specific way of handling these things right there is how do you do service Discovery with mcash well it works like",
    "start": "1069360",
    "end": "1075120"
  },
  {
    "text": "this how do you do service Discovery when it comes to finding uh your Thrift Services kind of works like that so in",
    "start": "1075120",
    "end": "1082640"
  },
  {
    "text": "each one of these environments you have to have a different way of doing it and it means you have people that are more",
    "start": "1082640",
    "end": "1088080"
  },
  {
    "text": "fluent with hey I'm just really good with configuring mcash or I'm really good with configuring this that or the",
    "start": "1088080",
    "end": "1093200"
  },
  {
    "text": "other it's just nicer to have it done one way and the code can be",
    "start": "1093200",
    "end": "1099960"
  },
  {
    "text": "shared so these are client-based features it turns out that much of the pain with RPC applications is not server",
    "start": "1101679",
    "end": "1108559"
  },
  {
    "text": "side it's really client side what do you want the client to do if things go wrong do you want it to retry do you want it",
    "start": "1108559",
    "end": "1114039"
  },
  {
    "text": "to reconnect how long should it wait things like that that said on the server side",
    "start": "1114039",
    "end": "1119760"
  },
  {
    "text": "finagle still has a set of features that it offers things like back pressure server registration via zookeeper uh",
    "start": "1119760",
    "end": "1126720"
  },
  {
    "text": "distributed tracing the native open SSL bindings you know and all these things",
    "start": "1126720",
    "end": "1131919"
  },
  {
    "text": "just like the Futures code was really easy to access vagle has made it really easy to access these features in the",
    "start": "1131919",
    "end": "1137799"
  },
  {
    "text": "back end what I'll do is I'll go through a few examples of those the first is",
    "start": "1137799",
    "end": "1142960"
  },
  {
    "text": "let's go through just simple round robing um so now I have red is",
    "start": "1142960",
    "end": "1149320"
  },
  {
    "text": "configured and it's the same code as before but now I have a comma separated list of hosts this is just a very simple",
    "start": "1149320",
    "end": "1155120"
  },
  {
    "text": "case of try one of these guys and wherever you get the answer great but let's say I want something a little more",
    "start": "1155120",
    "end": "1160440"
  },
  {
    "text": "sophisticated you know maybe I don't know exactly what my hosts are my hosts might be configured in Zookeeper or some",
    "start": "1160440",
    "end": "1166880"
  },
  {
    "text": "external service so finagle has this concept of a",
    "start": "1166880",
    "end": "1172279"
  },
  {
    "text": "cluster and so here's now the same red configuration uh I'm not going to bother with the configuring of the Zookeeper",
    "start": "1172440",
    "end": "1179320"
  },
  {
    "text": "cluster there's kind of there's a bunch of work involved in that but all you're telling um finagle is ultimately just go",
    "start": "1179320",
    "end": "1188360"
  },
  {
    "text": "find your information from this cluster you know and the implementation the cluster will'll figure we'll figure it",
    "start": "1188360",
    "end": "1194159"
  },
  {
    "text": "out so if you want to write different strategies in terms of how you should load balance how you should get",
    "start": "1194159",
    "end": "1200320"
  },
  {
    "text": "connections should it be based on the most number of connections response times Network topology Etc there's a",
    "start": "1200320",
    "end": "1207320"
  },
  {
    "text": "common way to do that regardless of",
    "start": "1207320",
    "end": "1211158"
  },
  {
    "text": "protocol what I did here is I just sort of highlighted that uh just changing it from a simple round robin to this you",
    "start": "1214440",
    "end": "1220200"
  },
  {
    "text": "can see is only just a few lines of code now granted this is a bunch of setup to",
    "start": "1220200",
    "end": "1225280"
  },
  {
    "text": "get the Zookeeper up and going um so I kind of ignored that that part but to set up the cluster itself is",
    "start": "1225280",
    "end": "1232080"
  },
  {
    "text": "not too much uh let's take a look at services",
    "start": "1232080",
    "end": "1238360"
  },
  {
    "text": "like Zipkin so Zipkin is something that is another Twitter open source project to do distributed tracing now this one",
    "start": "1238360",
    "end": "1245559"
  },
  {
    "text": "is a pain to set up the actual Zipkin service but to integrate it in with uh with finagle is actually pretty",
    "start": "1245559",
    "end": "1252919"
  },
  {
    "text": "simple and so finagle one of the options you have is a tracer Factory and and by",
    "start": "1252919",
    "end": "1258600"
  },
  {
    "text": "default you get the null Tracer Factory which does nothing but in this case I just want to trace to Zipkin so in it",
    "start": "1258600",
    "end": "1266600"
  },
  {
    "text": "goes and if you get Zipkin setup you get this really nice looking you know kind",
    "start": "1267760",
    "end": "1273200"
  },
  {
    "text": "of treeview of all the different Services you've called how long they've taken you know the actual operation time",
    "start": "1273200",
    "end": "1279440"
  },
  {
    "text": "so I could see whoa hey you know there's something going on here and hopefully this is supposed to take this",
    "start": "1279440",
    "end": "1285880"
  },
  {
    "text": "long you know but as you're environment becomes more distributed you have more services it's just hard to figure out",
    "start": "1285880",
    "end": "1291880"
  },
  {
    "text": "where the heck did the problem",
    "start": "1291880",
    "end": "1295000"
  },
  {
    "text": "go so this is kind of becoming a theme it's really just add the add the magic line and the services available so for",
    "start": "1297240",
    "end": "1305080"
  },
  {
    "text": "ostrich I'm not going to bother again to show you the configuration of ostrich itself just the way it plugs into",
    "start": "1305080",
    "end": "1310159"
  },
  {
    "text": "finagle so if you want to do the gauges metrics collection all the things that uh the the tumbller presenter mentioned",
    "start": "1310159",
    "end": "1318039"
  },
  {
    "text": "you get it out of the box if you just say here stick it in ostrich and again cross",
    "start": "1318039",
    "end": "1324200"
  },
  {
    "text": "protocols which is really really nice um here's a tool I don't believe this is not ostrich's normal way to render the",
    "start": "1324200",
    "end": "1332000"
  },
  {
    "text": "data but this is just like a rendering that Twitter uses of the data that comes out of ostrich you know it just it keeps",
    "start": "1332000",
    "end": "1338400"
  },
  {
    "text": "a lot of data and it's nice that you don't have to do much to get",
    "start": "1338400",
    "end": "1343200"
  },
  {
    "text": "this so in summary the way I think about this is whenever we're writing application",
    "start": "1346960",
    "end": "1354159"
  },
  {
    "start": "1348000",
    "end": "1648000"
  },
  {
    "text": "code there's a bunch of pieces that we're writing we're writing business Logic the operational code the drivers",
    "start": "1354159",
    "end": "1359600"
  },
  {
    "text": "and we're writing it you know along many different",
    "start": "1359600",
    "end": "1364440"
  },
  {
    "text": "Services when the team's writing the business code logic I love it you know that is that is time that is moving the",
    "start": "1365679",
    "end": "1371360"
  },
  {
    "text": "business forward it's great when we're using third party drivers I love that too because it's code that we didn't",
    "start": "1371360",
    "end": "1377279"
  },
  {
    "text": "have to write we picked up open source from some other party when we have to write operational",
    "start": "1377279",
    "end": "1383440"
  },
  {
    "text": "code separately for each one of these services this is when I go nuts because we're doing AER detection logging",
    "start": "1383440",
    "end": "1389520"
  },
  {
    "text": "service Discovery fail over Etc and we're repeating the same things over and over and over again",
    "start": "1389520",
    "end": "1396480"
  },
  {
    "text": "you what I prefer is just all of these things to be compacted together we have",
    "start": "1396480",
    "end": "1402200"
  },
  {
    "text": "the team learn one style we have that sort of yeah that uh that similarity so",
    "start": "1402200",
    "end": "1409279"
  },
  {
    "text": "people can just learn this and not have to worry about the rest of the details they can focus and spend their time up",
    "start": "1409279",
    "end": "1415080"
  },
  {
    "text": "here and then we can have a smaller team work on this so I've actually blazed through way",
    "start": "1415080",
    "end": "1421640"
  },
  {
    "text": "faster than I thought",
    "start": "1421640",
    "end": "1425039"
  },
  {
    "text": "[Music] questions we had a collection of say Jack's web services I'm sorry col if we",
    "start": "1427280",
    "end": "1433480"
  },
  {
    "text": "had a collection say ja web services like Jersey uh okay we could just bolt this right on top of that right there's",
    "start": "1433480",
    "end": "1438640"
  },
  {
    "text": "no problem with like a lot of Legacy weird Legacy stuff if you have a if you have a jack server so typically that'll",
    "start": "1438640",
    "end": "1445360"
  },
  {
    "text": "run within a Ser container and it has its own little stack for doing things so one of the CH one of the challenges with",
    "start": "1445360",
    "end": "1451520"
  },
  {
    "text": "finagle is you really get the most benefit when you just make your stack finagle and you basically say everything",
    "start": "1451520",
    "end": "1459400"
  },
  {
    "text": "from everything from business Logic on down is just finagle so if you were to",
    "start": "1459400",
    "end": "1464520"
  },
  {
    "text": "use Jacks then you would have to replace some of those jacks things with finagle",
    "start": "1464520",
    "end": "1469600"
  },
  {
    "text": "I mean you can get some light benefits so if you want to use finagle thread pooling you know you'd be able to use the future component of that um but I",
    "start": "1469600",
    "end": "1476640"
  },
  {
    "text": "don't know if that that's as valuable as being able to use the whole finagle stack if you wanted to let's say use the",
    "start": "1476640",
    "end": "1482279"
  },
  {
    "text": "distributed logging and the metrics you could use ostrich but finagle wouldn't",
    "start": "1482279",
    "end": "1487480"
  },
  {
    "text": "help you very much there because it wouldn't be pre-integrated finagle works best if you can just take the thing out of the box say okay great here's the",
    "start": "1487480",
    "end": "1493799"
  },
  {
    "text": "stack we'll use it as is yes so I noticed this the service signature of the apply method the",
    "start": "1493799",
    "end": "1500039"
  },
  {
    "text": "basically the request and the response were specific to the protocol type yes I wonder if you could comment on that so",
    "start": "1500039",
    "end": "1505840"
  },
  {
    "text": "every protocol has its own request response type um whether you're talking about a synchronous HTTP or if you're",
    "start": "1505840",
    "end": "1512799"
  },
  {
    "text": "talking about Comet each one of those will have its own distinctive ones which is so for example I included the uh the",
    "start": "1512799",
    "end": "1518279"
  },
  {
    "text": "reddis example so redus instead of HTTP request HTTP response has uh command and",
    "start": "1518279",
    "end": "1524919"
  },
  {
    "text": "reply and that's part of the codec so the codec is really what determines like how to interpret the",
    "start": "1524919",
    "end": "1530840"
  },
  {
    "text": "protocol does that answer your question yeah so the part that you're going to reuse between like a Rus interface to",
    "start": "1530840",
    "end": "1536880"
  },
  {
    "text": "your business logic or an HTP interface that's yet another layer down I guess well so here's some examples of things",
    "start": "1536880",
    "end": "1542760"
  },
  {
    "text": "you might reuse uh let's say you had um let's say you had service Discovery",
    "start": "1542760",
    "end": "1548279"
  },
  {
    "text": "right you could just write service Discovery once plug it in and it doesn't matter if it's reddis or HTTP let's say",
    "start": "1548279",
    "end": "1554320"
  },
  {
    "text": "for example you have a um let's say you want to be able to throttle usage of some sort so in that case you could",
    "start": "1554320",
    "end": "1560919"
  },
  {
    "text": "create a filter and you would write the filter using a generic type so that regardless you know you would just",
    "start": "1560919",
    "end": "1567120"
  },
  {
    "text": "specify that this is for command and reply but the filter itself doesn't care what the underlying protocol is it just",
    "start": "1567120",
    "end": "1572919"
  },
  {
    "text": "knows that every time a request comes in I'm counting um you might do that with for example authorization so let's say",
    "start": "1572919",
    "end": "1580760"
  },
  {
    "text": "that there's an authorization scheme of once the person's entered your web application you have some sort of context where you manage the the fact",
    "start": "1580760",
    "end": "1588080"
  },
  {
    "text": "that they're authorized and so now when you're firing off these request remote Services regardless of whether or not",
    "start": "1588080",
    "end": "1594480"
  },
  {
    "text": "they're Thrift or protuff like you could take advantage of the fact that you already know about the",
    "start": "1594480",
    "end": "1599559"
  },
  {
    "text": "authorization um so there's a bunch of things you can do that are common among things so another might be that you have",
    "start": "1599559",
    "end": "1605520"
  },
  {
    "text": "a retry system where if it fails you try again but you don't try again at the same interval you might have a backoff",
    "start": "1605520",
    "end": "1611960"
  },
  {
    "text": "strategy you know where it's half a second then two seconds and so you could do that with mcash you know redis",
    "start": "1611960",
    "end": "1618440"
  },
  {
    "text": "protuff Etc and you only have to write it once so the example where in these servers you put",
    "start": "1618440",
    "end": "1624559"
  },
  {
    "text": "in like a series of server addresses or maybe you discover variety of those from zookeeper um you said by default that",
    "start": "1624559",
    "end": "1631600"
  },
  {
    "text": "does round robin um I mean can you configure to say hash on key amongst that collection of servers or something",
    "start": "1631600",
    "end": "1638240"
  },
  {
    "text": "like that sure um let me get to",
    "start": "1638240",
    "end": "1643399"
  },
  {
    "text": "that okay so here was the example where this is the default round robin example",
    "start": "1645200",
    "end": "1650440"
  },
  {
    "text": "and the reason it's used is it's the most common one so you could think of almost this as syntactic sugar it's not",
    "start": "1650440",
    "end": "1656240"
  },
  {
    "text": "really but I mean you can think of it that way if you want to do something like what you're suggesting there's a bunch of cluster implementations already",
    "start": "1656240",
    "end": "1662679"
  },
  {
    "text": "built out of the box you would just pick the cluster implementation that most closely reflects what you want to do if",
    "start": "1662679",
    "end": "1668320"
  },
  {
    "text": "it's based on you know number of concurrent connections or whatever so the cluster would be the the",
    "start": "1668320",
    "end": "1674240"
  },
  {
    "text": "way to do that um I guess like the hash on key seems",
    "start": "1674240",
    "end": "1679360"
  },
  {
    "text": "like it would require um understanding of the protocol level to say somewhat oh",
    "start": "1679360",
    "end": "1684799"
  },
  {
    "text": "I see what you're saying I see what you're saying um so like if you want to do say",
    "start": "1684799",
    "end": "1690960"
  },
  {
    "text": "a consistent hashing scheme with that I'd have to think about that can I get back to you sure I I",
    "start": "1690960",
    "end": "1697919"
  },
  {
    "text": "guess I get the impression is this more for just the um General reliability and not so much that protocol level stuff I",
    "start": "1697919",
    "end": "1704399"
  },
  {
    "text": "haven't actually written a custom cluster implementation my understanding though is you actually get access to the",
    "start": "1704399",
    "end": "1709440"
  },
  {
    "text": "request object so I'm willing to my gut says like called",
    "start": "1709440",
    "end": "1715000"
  },
  {
    "text": "7525 that you would still use the cester implementation and they would have access to the actual request so you",
    "start": "1715000",
    "end": "1720720"
  },
  {
    "text": "could Peak incited to make that decision but don't don't hold me that can you can",
    "start": "1720720",
    "end": "1726080"
  },
  {
    "text": "you hide the marshalling and UNM marshing of response behind finagle 2 or you have to do it on your own or outside",
    "start": "1726080",
    "end": "1731760"
  },
  {
    "text": "finagle can you do the marshalling and unmarshaling let's say you're getting Jon back and I want to convert to PO you know like object going to hide that",
    "start": "1731760",
    "end": "1738679"
  },
  {
    "text": "behind fagle so I don't need to know if it's coming Json or whatever and I just get an object out okay so there's a",
    "start": "1738679",
    "end": "1745600"
  },
  {
    "text": "couple ways to do that the first is um you could write your own codec right if",
    "start": "1745600",
    "end": "1750799"
  },
  {
    "text": "it's a very specific thing so you take the HTTP codec and kind of make your own specific derivative of it um a second is",
    "start": "1750799",
    "end": "1757640"
  },
  {
    "text": "you could create a filter that takes a generic HTTP request and converts it into your you know your Json based one",
    "start": "1757640",
    "end": "1765760"
  },
  {
    "text": "uh I was actually playing around creting a library that was finagle based to access all the AWS services and then uh",
    "start": "1765760",
    "end": "1771919"
  },
  {
    "text": "what I found was easy is just also do it at the the at the uh the application",
    "start": "1771919",
    "end": "1777600"
  },
  {
    "text": "layer is just take the straight HTTP and do a simple transform on",
    "start": "1777600",
    "end": "1783679"
  },
  {
    "text": "it um so there's three ways you can go the codec the filter and at the application Level um I think codecs are",
    "start": "1783679",
    "end": "1791360"
  },
  {
    "text": "for me they're a little more challenging so I would probably go with the filter or the application Level but it's whatever you're comfortable with",
    "start": "1791360",
    "end": "1798120"
  },
  {
    "text": "given zip4 and that Scala actor future AA dispatch future play framework future",
    "start": "1798120",
    "end": "1804480"
  },
  {
    "text": "have already gone uh when will Twitter U Future follow that's a good question so",
    "start": "1804480",
    "end": "1810919"
  },
  {
    "text": "um I know Marius put out the uh the 210 a version of of finagle that compiles",
    "start": "1810919",
    "end": "1816519"
  },
  {
    "text": "with 210 but it doesn't actually extend from the 210 tree I don't know when",
    "start": "1816519",
    "end": "1821679"
  },
  {
    "text": "they're going to do that um from my point of view I'm not as worried about that because for us it was easier to go",
    "start": "1821679",
    "end": "1828159"
  },
  {
    "text": "with an entire stack when we have interoperability I worry about the problems like the Twitter or the Tumblr",
    "start": "1828159",
    "end": "1833320"
  },
  {
    "text": "person mentioned that um for the time being we don't have cases where we combine the two we just have the one and",
    "start": "1833320",
    "end": "1840880"
  },
  {
    "text": "so I guess you could write a transformation but I the answ I don't know I don't know when uh it would be",
    "start": "1840880",
    "end": "1846480"
  },
  {
    "text": "nice if for for example from play you could use pagle components and then you could just complete the request with the",
    "start": "1846480",
    "end": "1853000"
  },
  {
    "text": "final future right absolutely I don't know um just a quick question of uh uh",
    "start": "1853000",
    "end": "1859880"
  },
  {
    "text": "introducing team members to uh futures um I really like Futures and but I've found that often when you first",
    "start": "1859880",
    "end": "1865799"
  },
  {
    "text": "introduce somebody to Futures they get really frustrated that none of their debugging tools work anymore or not the way they're used to I was wondering how",
    "start": "1865799",
    "end": "1871639"
  },
  {
    "text": "you get people through that and pass that well the challenge that we've",
    "start": "1871639",
    "end": "1876760"
  },
  {
    "text": "always found with with using them is uh normally you're used to having the full stack trace and you can see all the",
    "start": "1876760",
    "end": "1882080"
  },
  {
    "text": "things that are going but all of a sudden once you start using Code asynchronously you find your stack traces are very very short and so it's",
    "start": "1882080",
    "end": "1889919"
  },
  {
    "text": "it's difficult to figure out where you've come um I'd like to say we have a better solution but really the debugger",
    "start": "1889919",
    "end": "1895399"
  },
  {
    "text": "becomes a much better friend of yours especially if the service is localized and then past the debugger um logging",
    "start": "1895399",
    "end": "1902279"
  },
  {
    "text": "becomes a really good friend and so I'd love to say that we have a more sophisticated answer but you know that's",
    "start": "1902279",
    "end": "1907960"
  },
  {
    "text": "pretty much it do you have any support of uh prioritization of futures or you know um",
    "start": "1907960",
    "end": "1916279"
  },
  {
    "text": "changing their sequence if they live long for example if they live long like",
    "start": "1916279",
    "end": "1922679"
  },
  {
    "text": "in a que so there are a lot of f fatures submitted but some of them are um not",
    "start": "1922679",
    "end": "1929960"
  },
  {
    "text": "process full on time I mean we could prioritize them to process right the we oh I see prioritize a future once it's",
    "start": "1929960",
    "end": "1935480"
  },
  {
    "text": "already in the the list um at this point there's only really limited functionality for that so one is you can",
    "start": "1935480",
    "end": "1941720"
  },
  {
    "text": "say give me the first future that responds and then it's up to you to do whatever you want with the rest of futures and if you're worried about the",
    "start": "1941720",
    "end": "1948080"
  },
  {
    "text": "future being very long running you can specify a timer or Timeout on the future so you can as you construct it you",
    "start": "1948080",
    "end": "1954320"
  },
  {
    "text": "basically say this needs to respond in 5 minutes in 30 seconds or in whatever time period you want um or else time",
    "start": "1954320",
    "end": "1962279"
  },
  {
    "text": "out um I don't know if there's anything more more detailed than that so I think",
    "start": "1962279",
    "end": "1968360"
  },
  {
    "text": "the question was on integrating Dapper yeah I wanted referring to your problem of trying to correlate what went in and",
    "start": "1968360",
    "end": "1974000"
  },
  {
    "text": "what went out right yeah um so i' i' love for someone to go do that and",
    "start": "1974000",
    "end": "1979120"
  },
  {
    "text": "that's I know that Zipkin comes pre-integrated which has a lot of the concepts from Dapper but I haven't it's",
    "start": "1979120",
    "end": "1985480"
  },
  {
    "text": "not something I've dug into myself and looked through the code of last",
    "start": "1985480",
    "end": "1990679"
  },
  {
    "text": "question uh is retry part of uh the stack or is you have to do that in your",
    "start": "1991000",
    "end": "1996679"
  },
  {
    "text": "user code uh it's in both places depending on what retry means for you so the simplest way to implement retry um",
    "start": "1996679",
    "end": "2004279"
  },
  {
    "text": "on the client is there's in fact a l line here that you could add that says if you just add retries and you just",
    "start": "2004279",
    "end": "2010880"
  },
  {
    "text": "pick a number um so that's at the basic sort of connectivity level if the connection fails it will do the retry",
    "start": "2010880",
    "end": "2016960"
  },
  {
    "text": "but if you need something that's a little more application um aware then you're going to have to write that uh",
    "start": "2016960",
    "end": "2022720"
  },
  {
    "text": "one more uh just uh somewhat related uh what if you want to uh have support for",
    "start": "2022720",
    "end": "2029480"
  },
  {
    "text": "queueing behavior let's say some something similar to a message que would that be part of the support or that's",
    "start": "2029480",
    "end": "2036519"
  },
  {
    "text": "totally a user responsibility for queing Behavior so whenever you throw things into a future",
    "start": "2036519",
    "end": "2044120"
  },
  {
    "text": "it will basically get queued up to do but I wouldn't treat it like a real que it's not like I I asked this more",
    "start": "2044120",
    "end": "2049919"
  },
  {
    "text": "because uh I heard something from the previous talk where if you bring you let's say your server side down the",
    "start": "2049919",
    "end": "2055599"
  },
  {
    "text": "client side will be able to queue up certain things to up to an hour uh that I don't know if that kind of behavior we",
    "start": "2055599",
    "end": "2062040"
  },
  {
    "text": "can get out of this or that's actually I think a separate tool he was mentioning so um if you look at Zipkin the",
    "start": "2062040",
    "end": "2068480"
  },
  {
    "text": "distributed tracing tool it uses a open source project called scribe and what scribe does is it's just a way to",
    "start": "2068480",
    "end": "2074158"
  },
  {
    "text": "collect data and if the Endo that scribe is writing to is down it'll it'll just buffer things and when the uh the target",
    "start": "2074159",
    "end": "2080960"
  },
  {
    "text": "is up it will so that's that's pretty much another project outside of uh of finagle thanks all right well thank you",
    "start": "2080960",
    "end": "2088118"
  },
  {
    "text": "very [Applause] [Music]",
    "start": "2088119",
    "end": "2095878"
  },
  {
    "text": "much [Music]",
    "start": "2095879",
    "end": "2101119"
  }
]
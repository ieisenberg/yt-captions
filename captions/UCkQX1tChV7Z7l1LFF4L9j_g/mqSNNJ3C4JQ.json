[
  {
    "text": "[Music]",
    "start": "3270",
    "end": "8730"
  },
  {
    "text": "thank you i'll start with with a short story that happened to me so it was a normal working day i came from work to",
    "start": "11360",
    "end": "17760"
  },
  {
    "text": "join my wife and daughter for a dinner and I'm really excited because the model our team uh has been working on uh has",
    "start": "17760",
    "end": "24320"
  },
  {
    "text": "finally started showing promising result and uh I'm really eager to share this",
    "start": "24320",
    "end": "29359"
  },
  {
    "text": "with my family uh my wife is busy though because she's trying to feed our daughter who is fitter so she doesn't",
    "start": "29359",
    "end": "35600"
  },
  {
    "text": "want to talk about models or anything else at that point but I'm so excited I cannot wait so I started telling her",
    "start": "35600",
    "end": "41600"
  },
  {
    "text": "like look we had this model we built and it it wasn't working and uh we've been",
    "start": "41600",
    "end": "47600"
  },
  {
    "text": "debugging it for more than a month and finally turns out that this all was just",
    "start": "47600",
    "end": "53920"
  },
  {
    "text": "stupid bugs like typos like wrong feature name this kind of stuff and we finally hunted them enough so the the",
    "start": "53920",
    "end": "60160"
  },
  {
    "text": "model now performing as we expected and so like I shared with excitement and I",
    "start": "60160",
    "end": "66240"
  },
  {
    "text": "expect her some reaction or something but she's been busy uh she barely listened uh but she she doesn't want to",
    "start": "66240",
    "end": "73280"
  },
  {
    "text": "be rude so she understand that she need to uh to do something so she offering",
    "start": "73280",
    "end": "78320"
  },
  {
    "text": "her comments said oh nice this model behaves just like you do at times and I'm like what what do you mean how it's",
    "start": "78320",
    "end": "85280"
  },
  {
    "text": "even relevant and she said like look when you m at me you don't simply tell me what's wrong I have to spend so much",
    "start": "85280",
    "end": "91600"
  },
  {
    "text": "time figuring out what's going on just like you guys with this model and she's actually spot on the models are really",
    "start": "91600",
    "end": "98320"
  },
  {
    "text": "hard to debug uh if if you built a model and it's underperforming it can be nightmare in",
    "start": "98320",
    "end": "104640"
  },
  {
    "text": "debugging it can it can cost uh like days uh weeks or months like in our case",
    "start": "104640",
    "end": "111600"
  },
  {
    "text": "uh and the least we can do to ease the pain is to ensure that the data that we fit to the model is okay so like the",
    "start": "111600",
    "end": "118560"
  },
  {
    "text": "data doesn't contain this bugs and this is what features platform uh aim to do they aim to deliver uh good data for",
    "start": "118560",
    "end": "127520"
  },
  {
    "text": "machine learning model and feature platforms is what we will be discussing today uh my name is Ivan i'm engineer at",
    "start": "127520",
    "end": "134400"
  },
  {
    "text": "Shet chhat is a Indian company that builds a couple of social networks in India like the largest domestic social",
    "start": "134400",
    "end": "141160"
  },
  {
    "text": "networks and I'm primarily focusing on this data for ML in particular this",
    "start": "141160",
    "end": "146560"
  },
  {
    "text": "feature platform and before shhat I had experience working at Meta and Sil",
    "start": "146560",
    "end": "152599"
  },
  {
    "text": "DB and the uh one of the social uh networks that Shhat builds is called",
    "start": "152599",
    "end": "158160"
  },
  {
    "text": "Moch it's a short video app pretty much like Tik Tok uh it has fully personalized feed around like 20 million",
    "start": "158160",
    "end": "165920"
  },
  {
    "text": "daily active users uh 100 million monthly active users and the model in in",
    "start": "165920",
    "end": "171760"
  },
  {
    "text": "the story is actually the model that uh the main model for for this app so the main model that defines the ranking that",
    "start": "171760",
    "end": "177920"
  },
  {
    "text": "defines like which videos we will show to to users",
    "start": "177920",
    "end": "183040"
  },
  {
    "text": "and today we will be talking about how how we built the feature platform uh for",
    "start": "183040",
    "end": "188080"
  },
  {
    "text": "for this uh app or or any app like this in particular so like we will have the",
    "start": "188080",
    "end": "194640"
  },
  {
    "text": "background about what the feature platform is or what the features high level architecture of any kind of",
    "start": "194640",
    "end": "200080"
  },
  {
    "text": "feature platform and the majority of time we'll spend on uh challenges and and how to overcome them in uh based on",
    "start": "200080",
    "end": "207120"
  },
  {
    "text": "our examples and finally some some some takeaways let's let's refresh the memory what the",
    "start": "207120",
    "end": "213360"
  },
  {
    "text": "feature is for ML a feature is pretty much anything we can derive from data uh",
    "start": "213360",
    "end": "219360"
  },
  {
    "text": "like and typically it attached to some kind of entity in the system for instance it can be the user as an entity",
    "start": "219360",
    "end": "226799"
  },
  {
    "text": "or or post or creator which is also user but the one who post the content and",
    "start": "226799",
    "end": "232959"
  },
  {
    "text": "there are multiple types of features one may be interested in like for instance uh window counters is like the feature",
    "start": "232959",
    "end": "240400"
  },
  {
    "text": "uh give me the number of likes for this post in the last 30 minutes or give me the number of engagement from this user",
    "start": "240400",
    "end": "247439"
  },
  {
    "text": "in the last one day this kind of window counters because they have time window there can be lifetime counters lifetime",
    "start": "247439",
    "end": "254000"
  },
  {
    "text": "is they don't have window so like total number of posts uh or likes for the",
    "start": "254000",
    "end": "259440"
  },
  {
    "text": "given post or total number of engagement from the given user uh there can be some kind of properties like date of birth",
    "start": "259440",
    "end": "266880"
  },
  {
    "text": "for user or uh post language or this kind of stuff or something like last and",
    "start": "266880",
    "end": "273600"
  },
  {
    "text": "uh give me last 100 interactions with this given post or give me the last 1,000 engagement for the given user uh",
    "start": "273600",
    "end": "281440"
  },
  {
    "text": "in this talk we will primarily focusing on uh window features the somewhat most",
    "start": "281440",
    "end": "288040"
  },
  {
    "text": "interesting and to summarize what the feature platform feature platform is a set of kind of services or tools uh like",
    "start": "288040",
    "end": "295440"
  },
  {
    "text": "that allows defining features like give some kind of feature API they uh list",
    "start": "295440",
    "end": "301360"
  },
  {
    "text": "features and and read what they mean uh like they allows like launching some",
    "start": "301360",
    "end": "308400"
  },
  {
    "text": "feature pipeline to compute and finally feature store is to read read the data",
    "start": "308400",
    "end": "314479"
  },
  {
    "text": "when it's need uh one important aspect I wanted to stress is that uh it's really important",
    "start": "314479",
    "end": "320800"
  },
  {
    "text": "that uh feature platform uh helps in engineering velocity meaning",
    "start": "320800",
    "end": "328320"
  },
  {
    "text": "that it doesn't stay in the way instead if it allows for fast iteration uh so",
    "start": "328320",
    "end": "333759"
  },
  {
    "text": "like that that people who build the model they can easily define features uh",
    "start": "333759",
    "end": "338960"
  },
  {
    "text": "update them if needed or read what they mean because when it comes to some kind",
    "start": "338960",
    "end": "344240"
  },
  {
    "text": "of investigation especially what model uh like underperforming let's say uh",
    "start": "344240",
    "end": "350320"
  },
  {
    "text": "it's really important that people can go and eas easily read okay like this is the features that we feed and this is",
    "start": "350320",
    "end": "355520"
  },
  {
    "text": "what they mean and it's it's it's pretty clear so it it is not hidden somewhere in like tens of files uh that that in",
    "start": "355520",
    "end": "362960"
  },
  {
    "text": "cryptic language or whatever and uh in typical architecture for any kind of feature platform it",
    "start": "362960",
    "end": "369440"
  },
  {
    "text": "starts with some streams of data like in in social network it may be like streams of lag streams of views video plays this",
    "start": "369440",
    "end": "376639"
  },
  {
    "text": "kind of stuff some processing engine that gets the streams of data computes",
    "start": "376639",
    "end": "382080"
  },
  {
    "text": "something and writes to some kind of database and finally in front of this data database there is some service uh",
    "start": "382080",
    "end": "389520"
  },
  {
    "text": "that gets request for the features transforms it to whatever queries it",
    "start": "389520",
    "end": "394639"
  },
  {
    "text": "required for database it probably performs some uh last aggregations and returns and speaking about last",
    "start": "394639",
    "end": "401520"
  },
  {
    "text": "aggregations in particular for window counters uh how how to serve the query like give",
    "start": "401520",
    "end": "408240"
  },
  {
    "text": "me uh number of likes in the last like one",
    "start": "408240",
    "end": "413280"
  },
  {
    "text": "30 minutes or one day uh typically the timeline is split into pre-agregated",
    "start": "413280",
    "end": "418800"
  },
  {
    "text": "buckets uh we call them tiles uh of different size for instance",
    "start": "418800",
    "end": "424240"
  },
  {
    "text": "we can uh split the timeline for buckets on 1 minute uh 30 minutes one day and",
    "start": "424240",
    "end": "429919"
  },
  {
    "text": "when the request comes like let's say at uh 3:37 p.m uh we want want like lumbs",
    "start": "429919",
    "end": "436880"
  },
  {
    "text": "in the last two hours and we can split this window of two hours covered by the",
    "start": "436880",
    "end": "442160"
  },
  {
    "text": "by the relevant tiles and so then we request database for these tiles get the",
    "start": "442160",
    "end": "447199"
  },
  {
    "text": "response back and and aggregate across the style and return the result so it's a typical technique uh to uh to power",
    "start": "447199",
    "end": "455199"
  },
  {
    "text": "this window window counters and uh that's that was it about",
    "start": "455199",
    "end": "461520"
  },
  {
    "text": "uh architecture now let's go to the uh challenges solutions that uh I will be",
    "start": "461520",
    "end": "467440"
  },
  {
    "text": "talking about in form of kind of stories the first story is is a boring one uh",
    "start": "467440",
    "end": "473199"
  },
  {
    "text": "it's about the choice of streaming platform and database so for streaming we picked red panda and for database we",
    "start": "473199",
    "end": "480960"
  },
  {
    "text": "picked celb and stillb red panda they are like siblings so they share a lot of",
    "start": "480960",
    "end": "486599"
  },
  {
    "text": "similarities uh first they were born uh with API compatibility with existing",
    "start": "486599",
    "end": "493039"
  },
  {
    "text": "systems like silver were born uh with cassandra API and later edit uh dynamob",
    "start": "493039",
    "end": "498400"
  },
  {
    "text": "API and and redponder is Kafka compatible they both obsessed with",
    "start": "498400",
    "end": "504240"
  },
  {
    "text": "performance so they uh they they do this via so-called shard per core architecture so shard per core is when",
    "start": "504240",
    "end": "511599"
  },
  {
    "text": "we split the data in some kind of shards and each shards is processed by uh given core in the system and this this",
    "start": "511599",
    "end": "519599"
  },
  {
    "text": "architecture allows eliminating like synchronization overhead or like logs",
    "start": "519599",
    "end": "524880"
  },
  {
    "text": "this kind of stuff and this helps them to to get to the performance numbers they desire it's not easy to build",
    "start": "524880",
    "end": "532160"
  },
  {
    "text": "application using this sharp per core technique and they they both leverage uh",
    "start": "532160",
    "end": "537519"
  },
  {
    "text": "CAR framework it's open source framework it's built by Stila team uh it",
    "start": "537519",
    "end": "543959"
  },
  {
    "text": "allows to build these kind of applications uh they both don't have",
    "start": "543959",
    "end": "549480"
  },
  {
    "text": "upscaling uh it's actually not not entirely true anymore for Red Panda they they just announced that they launched",
    "start": "549480",
    "end": "556080"
  },
  {
    "text": "Red Panda serverless in in one of their clouds uh but but if you install them in",
    "start": "556080",
    "end": "561279"
  },
  {
    "text": "your own uh stack they don't have up to scaling out of the box but despite that",
    "start": "561279",
    "end": "567760"
  },
  {
    "text": "they extremely cost efficient so like in in our company uh we use them not only",
    "start": "567760",
    "end": "573279"
  },
  {
    "text": "in this feature platform thing but actually migrated a lot of workloads to stillb",
    "start": "573279",
    "end": "580399"
  },
  {
    "text": "like uh to still we migrated from big table and to repo we migrated from uh",
    "start": "580399",
    "end": "586160"
  },
  {
    "text": "GCP popsup and in inhouse Kafka and achieved really really nice costs saving",
    "start": "586160",
    "end": "593200"
  },
  {
    "text": "and last but not least so they they both both have like really cute mascots so",
    "start": "593200",
    "end": "598240"
  },
  {
    "text": "like if you work with the systems that you get to work with like some swag like this one",
    "start": "598240",
    "end": "603839"
  },
  {
    "text": "uh and uh that's it about the story because uh like these systems are",
    "start": "603839",
    "end": "609120"
  },
  {
    "text": "tragically boring so that the they they just works and they really seem to",
    "start": "609120",
    "end": "615360"
  },
  {
    "text": "deliver on the promise of like operational easiness because like when you when you run them you don't need to",
    "start": "615360",
    "end": "622000"
  },
  {
    "text": "tune so they they tend to to kind of uh get the best out of the given hardware",
    "start": "622000",
    "end": "628079"
  },
  {
    "text": "so my uh my view on this uh is biased a bit because we use managed versions but",
    "start": "628079",
    "end": "634000"
  },
  {
    "text": "we tested non-managed versions as well and like uh this uh kind of the same so",
    "start": "634000",
    "end": "639360"
  },
  {
    "text": "we we we tested it and like we picked uh manage just because we didn't want to",
    "start": "639360",
    "end": "644399"
  },
  {
    "text": "have a team uh behind this so that's all let's let's go to the less boring part",
    "start": "644399",
    "end": "651600"
  },
  {
    "text": "so when when it came to streaming and database there were a bunch of options",
    "start": "651600",
    "end": "657200"
  },
  {
    "text": "but when it comes to uh processing engine especially at the moment when we made the decision there were not so much",
    "start": "657200",
    "end": "663600"
  },
  {
    "text": "option in fact there was only one option uh when you want to like realtime stream processing and what's important uh we",
    "start": "663600",
    "end": "671279"
  },
  {
    "text": "want realtime stream processing and we want some kind of expressive language for the stream processing and so apach",
    "start": "671279",
    "end": "678079"
  },
  {
    "text": "flinko was like is the framework that uh can process the streaming stream of data",
    "start": "678079",
    "end": "684240"
  },
  {
    "text": "real time has like some powerful capabilities and what's important it has flink so like one can uh define the job",
    "start": "684240",
    "end": "691600"
  },
  {
    "text": "in a square language and it's really important for feature platform because of that property we want to uh deliver",
    "start": "691600",
    "end": "698079"
  },
  {
    "text": "so that it's easy to write features and it's most importantly easy to read features and so so we picked flink and",
    "start": "698079",
    "end": "705480"
  },
  {
    "text": "and we can build features using this kind of streaming square so Uh what it",
    "start": "705480",
    "end": "712000"
  },
  {
    "text": "does this query it u basically uh works on top of streaming data selects them",
    "start": "712000",
    "end": "718880"
  },
  {
    "text": "group by by some like entity ID and like some identifier of the tile because we",
    "start": "718880",
    "end": "724000"
  },
  {
    "text": "need to aggregate this these tiles and uh this query forms this uh",
    "start": "724000",
    "end": "730079"
  },
  {
    "text": "so-called like virtual virtual table so virtual because it's it's not really materialized uh it's it keeps updating",
    "start": "730079",
    "end": "737440"
  },
  {
    "text": "as the data comes so for instance some event comes and and now we updated like",
    "start": "737440",
    "end": "742800"
  },
  {
    "text": "this shares and likes some some new event comes we again updated and this process continues",
    "start": "742800",
    "end": "749560"
  },
  {
    "text": "continues and so like super nice like we build this uh kind of proof of concept",
    "start": "749560",
    "end": "756320"
  },
  {
    "text": "pretty quickly and like we're happy uh uh by the way from developer experience",
    "start": "756320",
    "end": "762560"
  },
  {
    "text": "like flink is really nice it's easy to to write like using like developer uh",
    "start": "762560",
    "end": "768800"
  },
  {
    "text": "kind of workflow but then uh the the the question comes okay so like we we we",
    "start": "768800",
    "end": "775360"
  },
  {
    "text": "build this query we launched the job it's running it's updating this virtual table all good and now we want to update",
    "start": "775360",
    "end": "781279"
  },
  {
    "text": "this table uh update the query and flyn has uh this concept called safe point",
    "start": "781279",
    "end": "788480"
  },
  {
    "text": "and checkpoints so basically because it's streaming uh it's stateful processing it has some state and so like",
    "start": "788480",
    "end": "796000"
  },
  {
    "text": "what safe point does that we can stop the job takes the snap snapshot of the state then we can update the job and",
    "start": "796000",
    "end": "803040"
  },
  {
    "text": "start again and start with from this snapshot so like it it continues uh",
    "start": "803040",
    "end": "808440"
  },
  {
    "text": "working uh without like huge backlog or or something and so like this this was",
    "start": "808440",
    "end": "813600"
  },
  {
    "text": "the expectation okay like we have nice we have flink so we flink has safe points now we have flink asql so like we",
    "start": "813600",
    "end": "820480"
  },
  {
    "text": "can update this and and restore uh from safe point unfortunately it doesn't work",
    "start": "820480",
    "end": "826639"
  },
  {
    "text": "like this uh and in fact uh it's impossible to upgrade flink job so like",
    "start": "826639",
    "end": "833519"
  },
  {
    "text": "and and for us at that moment kind of unexperienced Flink engineers uh like it",
    "start": "833519",
    "end": "838959"
  },
  {
    "text": "came like a big shot because like come on guys like are you kidding so like what we supposed to do like we launched",
    "start": "838959",
    "end": "844320"
  },
  {
    "text": "the job and and should expect it it never fails like works forever or what uh and",
    "start": "844320",
    "end": "850519"
  },
  {
    "text": "uh kind of when like when first shock kind of fade",
    "start": "850519",
    "end": "856880"
  },
  {
    "text": "faded like it and we thought about this a little bit more it's not that surprising because like this this query",
    "start": "856880",
    "end": "863279"
  },
  {
    "text": "actually get translated to a set of uh stateful operators and when we do even",
    "start": "863279",
    "end": "868959"
  },
  {
    "text": "slight change in the query this number this kind of stateful operators may be completely different and so of course",
    "start": "868959",
    "end": "876160"
  },
  {
    "text": "like mapping uh one stateful operator to another one set of stateful operators to",
    "start": "876160",
    "end": "881920"
  },
  {
    "text": "another is is super difficult task it's not yet implemented uh and it's kind of",
    "start": "881920",
    "end": "888079"
  },
  {
    "text": "not a flint fold that it's not implemented but knowing this doesn't make our life easier because for us uh",
    "start": "888079",
    "end": "894880"
  },
  {
    "text": "we want to provide a platform where users come want to go update the square",
    "start": "894880",
    "end": "901199"
  },
  {
    "text": "and like just relaunch the job and it should just pick and continue working so the typical recommendation uh is to",
    "start": "901199",
    "end": "909279"
  },
  {
    "text": "always kind of back field so if you want to update a flink square we first we we",
    "start": "909279",
    "end": "915440"
  },
  {
    "text": "compose the job in such a way that it first kind of run in a batch mode process already processed data and then",
    "start": "915440",
    "end": "922399"
  },
  {
    "text": "continue on the new data uh but it's it's really inconvenient and it's also costly if if you want to do this every",
    "start": "922399",
    "end": "930240"
  },
  {
    "text": "single time we update these kind of features uh it will cost us a lot of a lot of a lot of money and it's just",
    "start": "930240",
    "end": "937199"
  },
  {
    "text": "super inconvenient because like it's it back field is also taking time and so like we want we want the",
    "start": "937199",
    "end": "944160"
  },
  {
    "text": "experience uh so that we updated the job and just relaunch them and it continues",
    "start": "944160",
    "end": "950120"
  },
  {
    "text": "working and so one thing that where Flink shines is so-called data stream API data stream uh in comparison to SQL",
    "start": "950120",
    "end": "957920"
  },
  {
    "text": "API data stream is where we build the job express the job in a form like some GVM language like Java Cotlin or",
    "start": "957920",
    "end": "965560"
  },
  {
    "text": "Scala and there is a really nice interrop between SQL and data stream so",
    "start": "965560",
    "end": "970800"
  },
  {
    "text": "in particular uh it's called change log when we want to uh get kind of from SQL",
    "start": "970800",
    "end": "977360"
  },
  {
    "text": "to data stream uh there is thing called change log basically SQL will send uh",
    "start": "977360",
    "end": "983279"
  },
  {
    "text": "so-called change lock rows what is it it's a row of the data with this marker",
    "start": "983279",
    "end": "989519"
  },
  {
    "text": "like on this L plus I plus I means that it's new new row in our virtual table",
    "start": "989519",
    "end": "995519"
  },
  {
    "text": "and there could could be minus I plus uh minus U plus U they come with pair minus",
    "start": "995519",
    "end": "1000800"
  },
  {
    "text": "U means that this was the row before update and plus U means this is the row",
    "start": "1000800",
    "end": "1005920"
  },
  {
    "text": "after update and so once SQL is running uh like it keeps issuing this kind of uh",
    "start": "1005920",
    "end": "1012639"
  },
  {
    "text": "change lock entries and what's interesting about this change log that if you look at this",
    "start": "1012639",
    "end": "1018560"
  },
  {
    "text": "we can notice that the final uh values of our kind of columns our features is",
    "start": "1018560",
    "end": "1024640"
  },
  {
    "text": "aggregation over this change log if you consider plus operation is as as plus",
    "start": "1024640",
    "end": "1030000"
  },
  {
    "text": "and minus operation is minus so basically like here we we see three rows",
    "start": "1030000",
    "end": "1035918"
  },
  {
    "text": "like and if we uh want to count like shares we do three minus 3 + 5 final",
    "start": "1035919",
    "end": "1043120"
  },
  {
    "text": "result of five and the same continues so like we keep uh we can keep uh kind of",
    "start": "1043120",
    "end": "1050080"
  },
  {
    "text": "uh treating these change lock entries like comments either plus comment or minus comment and if you want to express this",
    "start": "1050080",
    "end": "1057280"
  },
  {
    "text": "in formally this kind of data uh data stream there will be a function like",
    "start": "1057280",
    "end": "1062559"
  },
  {
    "text": "this super simple we have row update we have current state we get the state and",
    "start": "1062559",
    "end": "1067840"
  },
  {
    "text": "we see if it's positive update or negative update and we perform this update super simple so far it's like",
    "start": "1067840",
    "end": "1074320"
  },
  {
    "text": "super obvious but what's interesting about this model is that it survives job upgrades because",
    "start": "1074320",
    "end": "1081760"
  },
  {
    "text": "like when we upgrade the job we we lost the square state fine uh but what but this square will",
    "start": "1081760",
    "end": "1089440"
  },
  {
    "text": "continue issuing this change lock entries and so like so we have this set of like plus I minus u plus u etc then",
    "start": "1089440",
    "end": "1097360"
  },
  {
    "text": "drop upgra and now this row from the SQL engine perspective is new row and so it",
    "start": "1097360",
    "end": "1103840"
  },
  {
    "text": "will start uh sending this plus I entries and it's fine this plus I",
    "start": "1103840",
    "end": "1108960"
  },
  {
    "text": "represent exactly the change from the previous data so from the logic that",
    "start": "1108960",
    "end": "1115120"
  },
  {
    "text": "performs aggregation over the change log nothing happens so like uh it just keeps",
    "start": "1115120",
    "end": "1120320"
  },
  {
    "text": "treating this entries as as as a comment like plus comment minus comment etc and",
    "start": "1120320",
    "end": "1125600"
  },
  {
    "text": "so we see like We we had this aggregation now job upgrade happen but we we don't care we keep aggregating",
    "start": "1125600",
    "end": "1131440"
  },
  {
    "text": "this change lock entries and so we can we can compose the",
    "start": "1131440",
    "end": "1136559"
  },
  {
    "text": "job in in this way like there is a square part and there is this change lock aggregation part and a square part",
    "start": "1136559",
    "end": "1143679"
  },
  {
    "text": "we don't control the state there because of this magic and complexities of this square and so on but in this change",
    "start": "1143679",
    "end": "1151039"
  },
  {
    "text": "aggregation part it's expressed in in data stream uh And this is where we",
    "start": "1151039",
    "end": "1157200"
  },
  {
    "text": "control the state and so we can we can build the state in such a way that it survives job upgrades so it this part of",
    "start": "1157200",
    "end": "1163440"
  },
  {
    "text": "the job can be restored from safe point and continue and so the flow will look",
    "start": "1163440",
    "end": "1169120"
  },
  {
    "text": "like we updated the query and just relaunch the job from safe point and and",
    "start": "1169120",
    "end": "1175120"
  },
  {
    "text": "computation will continue so nice now we have the system",
    "start": "1175120",
    "end": "1180640"
  },
  {
    "text": "that we can write and also update it's it's pretty exciting uh but the problem",
    "start": "1180640",
    "end": "1186880"
  },
  {
    "text": "that the next problem that we might face is that uh when we launch the job performance over time may may",
    "start": "1186880",
    "end": "1194360"
  },
  {
    "text": "decline and it's clear why we call this the job getting tired it's clear why",
    "start": "1194360",
    "end": "1199440"
  },
  {
    "text": "because like this is stateful job so like and uh we have state and the bigger the state uh the less performance the",
    "start": "1199440",
    "end": "1206799"
  },
  {
    "text": "job it's kind of clear pretty clear dependency and the typical",
    "start": "1206799",
    "end": "1213360"
  },
  {
    "text": "recommendation okay like you have the state that just applies DTL and so like the state will expire like and uh the it",
    "start": "1213360",
    "end": "1220480"
  },
  {
    "text": "will be constant size so like the job will not get entire uh it's it's a fine",
    "start": "1220480",
    "end": "1226000"
  },
  {
    "text": "recommendation but it's not really clear what kind of TTL to pick for instance in in our case we have",
    "start": "1226000",
    "end": "1231880"
  },
  {
    "text": "uh the largest tile that we use in this system is five day tile and so if you",
    "start": "1231880",
    "end": "1237200"
  },
  {
    "text": "want counters to be accurate like the DTL must be at least 5 day but it's not",
    "start": "1237200",
    "end": "1245600"
  },
  {
    "text": "even entirely solve the problem of lifetime counters where we don't have window so it's not really clear what kind of detail to pick but assuming they",
    "start": "1245600",
    "end": "1252720"
  },
  {
    "text": "find with lifetime counters being kind of inaccurate and assuming we find with five day in in in the context of",
    "start": "1252720",
    "end": "1260799"
  },
  {
    "text": "lifetime counters but the problem is that five days too much so in our experience uh that the the job",
    "start": "1260799",
    "end": "1267280"
  },
  {
    "text": "processing like hundreds of thousands of events and performing like millions of",
    "start": "1267280",
    "end": "1272559"
  },
  {
    "text": "operations per second with the state it it got it showed signs of being tired",
    "start": "1272559",
    "end": "1278000"
  },
  {
    "text": "pretty quickly like in just a few hours after launch so five days is just too much of course we can upscale the job",
    "start": "1278000",
    "end": "1284799"
  },
  {
    "text": "but it but it comes with the cost so what we can do about that uh and uh",
    "start": "1284799",
    "end": "1289919"
  },
  {
    "text": "remember that we now have two types of the state one is a square state and now a change local aggregation state and the",
    "start": "1289919",
    "end": "1296799"
  },
  {
    "text": "good news about this coil state that we shouldn't do anything like because we we already survived the job upgrade because",
    "start": "1296799",
    "end": "1303760"
  },
  {
    "text": "of this change lock mode and now like from the SQL perspective it doesn't matter if if it lost uh state because of",
    "start": "1303760",
    "end": "1310960"
  },
  {
    "text": "job upgrade or it lost state because of TTL doesn't matter so we just set TTL on",
    "start": "1310960",
    "end": "1316559"
  },
  {
    "text": "SQL uh and keep treating this u change log comments as comments so we shouldn't",
    "start": "1316559",
    "end": "1322880"
  },
  {
    "text": "do anything and for for change lock aggregation state we can modify our",
    "start": "1322880",
    "end": "1328679"
  },
  {
    "text": "function a bit so becau when we access the state and it got expired we can just",
    "start": "1328679",
    "end": "1337120"
  },
  {
    "text": "query our stiller because the data exist in the stiller and so like we modify like have",
    "start": "1337120",
    "end": "1344480"
  },
  {
    "text": "this in green uh update of our function uh and uh",
    "start": "1344480",
    "end": "1350200"
  },
  {
    "text": "now can set TTL for change lock aggregation as well and it will kind",
    "start": "1350200",
    "end": "1355520"
  },
  {
    "text": "kind of keep running and recovering itself from the main database and so now",
    "start": "1355520",
    "end": "1361039"
  },
  {
    "text": "the job no longer getting tired so it has consistent performance because this the state uh has a consistent",
    "start": "1361039",
    "end": "1369480"
  },
  {
    "text": "size so good now we can launch the job update the job and it's not dying",
    "start": "1369480",
    "end": "1377039"
  },
  {
    "text": "uh the problem though now that uh with previous change now jobs not only write",
    "start": "1377039",
    "end": "1383760"
  },
  {
    "text": "to database but also read read from them and it's actually a big deal a big",
    "start": "1383760",
    "end": "1389600"
  },
  {
    "text": "deal for the job to read from database because for database like Stila or",
    "start": "1389600",
    "end": "1395200"
  },
  {
    "text": "Cassandra or similar similar kind uh reads are somewhat more expensive than",
    "start": "1395200",
    "end": "1401799"
  },
  {
    "text": "writes especially cold reads so if if we read something which is called which",
    "start": "1401799",
    "end": "1407120"
  },
  {
    "text": "doesn't contain like in database cache a lot of stuff happens because we need to scan a few file multiple files on the",
    "start": "1407120",
    "end": "1413679"
  },
  {
    "text": "disk to get the data merge them uh update the cache a lot of stuff and",
    "start": "1413679",
    "end": "1420159"
  },
  {
    "text": "what's interesting about jobs so that they are more likely to hit cold reads than than than the service that source",
    "start": "1420159",
    "end": "1427400"
  },
  {
    "text": "features and so uh what what what would happen is that when we do something on the job side for instance we launched a",
    "start": "1427400",
    "end": "1433760"
  },
  {
    "text": "bunch of test jobs and we want to launch test jobs because because we want to unlock this engineering velocity and we",
    "start": "1433760",
    "end": "1440640"
  },
  {
    "text": "want to experiment and so on and so forth or maybe some job uh got a backlog for some reason and need to huge",
    "start": "1440640",
    "end": "1447120"
  },
  {
    "text": "backfield or whatever so we launch the job and they start hitting this cold reads and and especially if it's in",
    "start": "1447120",
    "end": "1453919"
  },
  {
    "text": "backfield and they try to kind of process the backlog uh they they hit a",
    "start": "1453919",
    "end": "1459200"
  },
  {
    "text": "lot of these cold reads and it it it kind of thrashing main database and uh",
    "start": "1459200",
    "end": "1464480"
  },
  {
    "text": "affects the service latency that access the features so what what to do about that",
    "start": "1464480",
    "end": "1471600"
  },
  {
    "text": "like first thought may be that we need some kind of throttling uh the problem",
    "start": "1471600",
    "end": "1476880"
  },
  {
    "text": "though it's not really clear the level where we should apply the throttling we cannot throttle on individual workers",
    "start": "1476880",
    "end": "1482400"
  },
  {
    "text": "level in fing job because at least like we have multiple jobs and and and new",
    "start": "1482400",
    "end": "1487600"
  },
  {
    "text": "job can come and go so instead we can have some kind of coordinator in between",
    "start": "1487600",
    "end": "1494880"
  },
  {
    "text": "jobs and and still which basically kind of proxy",
    "start": "1494880",
    "end": "1500880"
  },
  {
    "text": "uh the it's a tricky thing though because this proxy uh Stila and Stila clients are really",
    "start": "1500880",
    "end": "1508159"
  },
  {
    "text": "super uber optimized and so if you want the same efficiency for for the RITs uh",
    "start": "1508159",
    "end": "1513440"
  },
  {
    "text": "like this proxy should be at least optimized as as well as SA itself which is which is rather tricky so overall",
    "start": "1513440",
    "end": "1520559"
  },
  {
    "text": "this solution is kind of complex it's actually has extra cost because we need this component which need to be scaled",
    "start": "1520559",
    "end": "1527480"
  },
  {
    "text": "appropriately and likely it's less efficient because it's not really easy to write this proxy in the same way that",
    "start": "1527480",
    "end": "1533679"
  },
  {
    "text": "it will be as efficient as still itself the second option called data centers",
    "start": "1533679",
    "end": "1539600"
  },
  {
    "text": "like still uh the same as Cassandra it has uh data center kind",
    "start": "1539600",
    "end": "1546039"
  },
  {
    "text": "of it's purely logical abstraction it doesn't it doesn't need to be real",
    "start": "1546039",
    "end": "1551520"
  },
  {
    "text": "data center real physical but basically we can split our cluster into two logical data centers and job will hit",
    "start": "1551520",
    "end": "1560240"
  },
  {
    "text": "like data centers for the job data center for job and feature store will hit data center for the feature",
    "start": "1560240",
    "end": "1566840"
  },
  {
    "text": "store it's pretty nice because uh it has super great",
    "start": "1566840",
    "end": "1573240"
  },
  {
    "text": "isolation we also can independently scale these different data centers",
    "start": "1573240",
    "end": "1578559"
  },
  {
    "text": "uh the downside is that the cluster management for still becomes much more complex and uh uh it also comes with the",
    "start": "1578559",
    "end": "1586320"
  },
  {
    "text": "cost because even though we can independently scale this data center it still means extra",
    "start": "1586320",
    "end": "1592360"
  },
  {
    "text": "capacity and also uh the complexity of cluster management shouldn't be underestimated",
    "start": "1592360",
    "end": "1598400"
  },
  {
    "text": "because especially if you want real data centers and now we have for instance we wanted our database to be in two data",
    "start": "1598400",
    "end": "1605039"
  },
  {
    "text": "centers and now it's it's kind of in four so it's like the complexity actually increases quite a",
    "start": "1605039",
    "end": "1612039"
  },
  {
    "text": "lot and the third option the one that we ended up with is so-called workload prioritization uh there is this feature",
    "start": "1612039",
    "end": "1618880"
  },
  {
    "text": "in Stila called workload prioritization that we can define multiple service level inside inside Stila and attach",
    "start": "1618880",
    "end": "1626320"
  },
  {
    "text": "different workloads to different service level how does it work so any access to",
    "start": "1626320",
    "end": "1632240"
  },
  {
    "text": "any resource in Stila uh has the kind of queue queue of operations and for",
    "start": "1632240",
    "end": "1638400"
  },
  {
    "text": "instance we have job queue and service queue like job had like two 200 shares",
    "start": "1638400",
    "end": "1643520"
  },
  {
    "text": "and service had like 1,000 shares uh what does it mean it means that for any",
    "start": "1643520",
    "end": "1648799"
  },
  {
    "text": "uh unit of work for the job queries uh still will perform up to five unit of",
    "start": "1648799",
    "end": "1654400"
  },
  {
    "text": "works for service queries so that there is the scheduleuler that picks from",
    "start": "1654400",
    "end": "1659440"
  },
  {
    "text": "these cues and forms the final queue and and and what it means it means like",
    "start": "1659440",
    "end": "1665039"
  },
  {
    "text": "finally we will have uh consistent latency uh of course job latency will be",
    "start": "1665039",
    "end": "1671120"
  },
  {
    "text": "higher than service latency but this is fine because job is is background thing and doesn't care about latency that much",
    "start": "1671120",
    "end": "1677600"
  },
  {
    "text": "it cares about throughput service on the other hand it cares about latency",
    "start": "1677600",
    "end": "1682960"
  },
  {
    "text": "uh and uh and so like uh summarizing this final solution how it will look",
    "start": "1682960",
    "end": "1688320"
  },
  {
    "text": "like basically we don't do anything with the with the cluster with the sealer itself we just set up this different",
    "start": "1688320",
    "end": "1695440"
  },
  {
    "text": "workload different service levels and from the job we access the cluster using",
    "start": "1695440",
    "end": "1700559"
  },
  {
    "text": "like user for for the job workload uh and from feature service access using",
    "start": "1700559",
    "end": "1707120"
  },
  {
    "text": "user for the uh service level and so like this is super simple uh no",
    "start": "1707120",
    "end": "1713919"
  },
  {
    "text": "operation overhead best cost because we we don't need to do anything with the cluster the only downside is that uh job",
    "start": "1713919",
    "end": "1721360"
  },
  {
    "text": "and service they connect to the same nodes in sil so so theoretically they are not entirely isolated but it's a",
    "start": "1721360",
    "end": "1728559"
  },
  {
    "text": "nice trade-off between cost uh and and",
    "start": "1728559",
    "end": "1734398"
  },
  {
    "text": "safety and and final story uh is like like about being lazy so that we uh",
    "start": "1734919",
    "end": "1743039"
  },
  {
    "text": "now we have like uh we can launch the job they are running and they don't impact our domain service and so on now",
    "start": "1743039",
    "end": "1750559"
  },
  {
    "text": "it's time to think about the data model in uh in database to serve the",
    "start": "1750559",
    "end": "1756520"
  },
  {
    "text": "queries so we we need to be able to serve this to query this the tiles to",
    "start": "1756520",
    "end": "1761679"
  },
  {
    "text": "aggregate window counters and uh and the the natural data model uh is like this",
    "start": "1761679",
    "end": "1768960"
  },
  {
    "text": "so like still has the has the notion of partitions uh partition is basically a",
    "start": "1768960",
    "end": "1775760"
  },
  {
    "text": "set of of set of kind of rows ordered by some keys and so we can we can uh attach each",
    "start": "1775760",
    "end": "1784880"
  },
  {
    "text": "entity ID to to partition and uh inside partition we can store uh each feature",
    "start": "1784880",
    "end": "1792720"
  },
  {
    "text": "in in its row so like basically feature will be identified by uh time stamp of",
    "start": "1792720",
    "end": "1799039"
  },
  {
    "text": "the tile and feature name and so we have this kind of rows uh this schema is nice",
    "start": "1799039",
    "end": "1804960"
  },
  {
    "text": "uh because it is basically we don't need to modify the schema when we add each feature so like",
    "start": "1804960",
    "end": "1810960"
  },
  {
    "text": "it's it's it's kind of schemaless in terms of like we can add as as many",
    "start": "1810960",
    "end": "1816960"
  },
  {
    "text": "feature types as we want and the schema schema survives however if if we if you do some math uh",
    "start": "1816960",
    "end": "1825200"
  },
  {
    "text": "we have like 8,000 feed request on average we rank around 2,000 candidates",
    "start": "1825200",
    "end": "1832559"
  },
  {
    "text": "for each candidate we need to query 100 let's say 100",
    "start": "1832559",
    "end": "1837799"
  },
  {
    "text": "features and uh for these features we need to query like 20 or something tiles",
    "start": "1837799",
    "end": "1844480"
  },
  {
    "text": "and also assuming that our feature service has some some kind of local cache and assume we have like 80% cash",
    "start": "1844480",
    "end": "1851120"
  },
  {
    "text": "rate then we multiplying all of this we will get uh more than 7 billion rows per",
    "start": "1851120",
    "end": "1856480"
  },
  {
    "text": "second this is the load that our database need to perform like in order",
    "start": "1856480",
    "end": "1862640"
  },
  {
    "text": "to satisfy this load uh this is totally fine for still it can scale to the to",
    "start": "1862640",
    "end": "1867840"
  },
  {
    "text": "this number but the problem is that it it will it will use some compute so like of course kind of our cloud provider GCP",
    "start": "1867840",
    "end": "1875279"
  },
  {
    "text": "and still itself they will be happy to scale uh but our uh financial officer",
    "start": "1875279",
    "end": "1880640"
  },
  {
    "text": "might might not be that happy and so what what we can do instead of instead of storing each feature into individual",
    "start": "1880640",
    "end": "1888399"
  },
  {
    "text": "row we can we can compact multiple row multiple features into the same row like",
    "start": "1888399",
    "end": "1893679"
  },
  {
    "text": "this so that now now row is identified only by uh tile time stamp and uh row",
    "start": "1893679",
    "end": "1901600"
  },
  {
    "text": "value is u basically bytes some serialized",
    "start": "1901600",
    "end": "1907200"
  },
  {
    "text": "uh list of pairs like uh feature name to feature value feature name to feature",
    "start": "1907200",
    "end": "1912880"
  },
  {
    "text": "value so like this is nice because uh now we",
    "start": "1912880",
    "end": "1918240"
  },
  {
    "text": "don't have this 100 multiplier anymore because we we we will query 100 less",
    "start": "1918240",
    "end": "1923360"
  },
  {
    "text": "rows and this number of rows per second looks looks much better the question may arise uh is",
    "start": "1923360",
    "end": "1932000"
  },
  {
    "text": "whether it's really a cost saving because it it can be that we just shifted the compute from uh from the",
    "start": "1932000",
    "end": "1939279"
  },
  {
    "text": "database layer to basically the job uh because uh we used to have this nice",
    "start": "1939279",
    "end": "1944960"
  },
  {
    "text": "schema uh when we updated each each features independently it it was nice",
    "start": "1944960",
    "end": "1951200"
  },
  {
    "text": "but now we have this combined like features and in in protobuff it can be",
    "start": "1951200",
    "end": "1956799"
  },
  {
    "text": "expressed like in message like this so we have like features combined and map in in string to some feature value and",
    "start": "1956799",
    "end": "1964159"
  },
  {
    "text": "so what what does it mean it means like whenever like feature is updated we need",
    "start": "1964159",
    "end": "1970399"
  },
  {
    "text": "to kind of serialize all of them together every single time so basically",
    "start": "1970399",
    "end": "1976720"
  },
  {
    "text": "it may look like that the the cost of updating a single feature now gets like",
    "start": "1976720",
    "end": "1982080"
  },
  {
    "text": "100 times uh bigger it's a fair question uh and there",
    "start": "1982080",
    "end": "1987519"
  },
  {
    "text": "are fairly easy steps to mitigate it so like the first it's a no-brainer is that",
    "start": "1987519",
    "end": "1993279"
  },
  {
    "text": "we don't need to store strings of course we always can store some kind of identifiers of the feature we can always",
    "start": "1993279",
    "end": "1998960"
  },
  {
    "text": "have like dictionary mapping feature values to some ids so now we need to serialize like mapping of int to feature",
    "start": "1998960",
    "end": "2006960"
  },
  {
    "text": "value which is of course like for pauff is much easier the second observation is",
    "start": "2006960",
    "end": "2012320"
  },
  {
    "text": "that uh uh protobuff format is is pretty nice in a sense that uh this map can can",
    "start": "2012320",
    "end": "2020840"
  },
  {
    "text": "actually v equivalent to just a repeated set of key value pairs so basically we",
    "start": "2020840",
    "end": "2028480"
  },
  {
    "text": "we have two like messages like one is features combined and another like features combined compatible which is",
    "start": "2028480",
    "end": "2034240"
  },
  {
    "text": "just repeat map field entry and we can serialize the features combined and you",
    "start": "2034240",
    "end": "2039919"
  },
  {
    "text": "serialize features combined compatible and vice versa so the the u kind of",
    "start": "2039919",
    "end": "2045120"
  },
  {
    "text": "equivalent in the form of bytes that that gets produced and moreover the actually",
    "start": "2045120",
    "end": "2050398"
  },
  {
    "text": "equivalent to the just repeat bytes feature so basically uh massive massive array of",
    "start": "2050399",
    "end": "2059079"
  },
  {
    "text": "arrays and so like all these three messages like features combined features combined compatible features combined",
    "start": "2059079",
    "end": "2064560"
  },
  {
    "text": "lazy they are equivalent in the form of the bytes that get produced by",
    "start": "2064560",
    "end": "2070520"
  },
  {
    "text": "protobuff so how does it help it helps that in the fle state we can store the",
    "start": "2070520",
    "end": "2075919"
  },
  {
    "text": "map from feature ID to the uh to the bytes bytes is serialize this map field",
    "start": "2075919",
    "end": "2083960"
  },
  {
    "text": "entry and so when we need to serialize all of these features we just combine this bytes together have this uh array",
    "start": "2083960",
    "end": "2091760"
  },
  {
    "text": "of arrays uh form these features com combined lazy message and serialize with protobuff and this serialization of",
    "start": "2091760",
    "end": "2098640"
  },
  {
    "text": "protobuff it's it's super easy because protobuff itself will just write this these bytes one after",
    "start": "2098640",
    "end": "2104839"
  },
  {
    "text": "another and so like this serialization is is like extremely cheap it's much",
    "start": "2104839",
    "end": "2110240"
  },
  {
    "text": "much cheaper than serialization of original message and so in fact when we implemented that we didn't need to scale",
    "start": "2110240",
    "end": "2117280"
  },
  {
    "text": "the job at all so like uh in in comparison to other things that the job is doing this step is is is basically",
    "start": "2117280",
    "end": "2123839"
  },
  {
    "text": "negligible and so to to summarize like assuming",
    "start": "2123839",
    "end": "2129280"
  },
  {
    "text": "that you decided to build uh feature platform uh like first it's good luck",
    "start": "2129280",
    "end": "2134720"
  },
  {
    "text": "it's it's going to be an interesting journey uh second like uh take a look on CLB and",
    "start": "2134720",
    "end": "2141359"
  },
  {
    "text": "red panda uh the odds are that they may impress you and be your friends",
    "start": "2141359",
    "end": "2147440"
  },
  {
    "text": "uh third thing is that Frink is still the king of realtime stream processing",
    "start": "2147440",
    "end": "2153440"
  },
  {
    "text": "uh but it it takes time to learn uh and to use it in the most efficient",
    "start": "2153440",
    "end": "2160200"
  },
  {
    "text": "way and the fourth thought uh like the vendors there are multiple",
    "start": "2160200",
    "end": "2167440"
  },
  {
    "text": "vendors now who build a square only stream stream processing",
    "start": "2167440",
    "end": "2173200"
  },
  {
    "text": "uh and my thought is that in my opinion that a square is not enough i I don't",
    "start": "2173200",
    "end": "2178560"
  },
  {
    "text": "understand how we can build what we built without this power of link data stream API probably it's possible via",
    "start": "2178560",
    "end": "2186000"
  },
  {
    "text": "some I don't know userdefined functions or something but it's likely would would look like much uglier and and harder to",
    "start": "2186000",
    "end": "2193400"
  },
  {
    "text": "maintain so like in my opinion this Flink ability to have this data stream",
    "start": "2193400",
    "end": "2199280"
  },
  {
    "text": "API is is is really powerful and finally uh lazy protobuff",
    "start": "2199280",
    "end": "2205040"
  },
  {
    "text": "trick is is pretty nice trick uh that can be used pretty much anywhere like",
    "start": "2205040",
    "end": "2210640"
  },
  {
    "text": "for instance in addition to to this place we also use it uh on our service",
    "start": "2210640",
    "end": "2215839"
  },
  {
    "text": "to cache JPC messages so basically we have JRPC server and there is a cache in",
    "start": "2215839",
    "end": "2221839"
  },
  {
    "text": "front of it and so we can store serialized data in the cache and when we",
    "start": "2221839",
    "end": "2226960"
  },
  {
    "text": "need to respond to JPC we just send this data over uh send these bytes over the",
    "start": "2226960",
    "end": "2232000"
  },
  {
    "text": "buyer without without need to like decentralize the message uh to serialize",
    "start": "2232000",
    "end": "2237040"
  },
  {
    "text": "it back so that's what I that's all what I wanted to share thanks for listening and",
    "start": "2237040",
    "end": "2244640"
  },
  {
    "text": "please don't forget to to vote and leave feedback thank you",
    "start": "2244640",
    "end": "2251000"
  },
  {
    "text": "we definely have a lot of time for questions anybody have Okay please wait for the mic and also even can you repeat",
    "start": "2257599",
    "end": "2263920"
  },
  {
    "text": "the question yeah so you're looking into C++ variants of various well classically",
    "start": "2263920",
    "end": "2270079"
  },
  {
    "text": "Java tools have you looked into Verica's new C++ version of Flink yet",
    "start": "2270079",
    "end": "2276079"
  },
  {
    "text": "so c can you repeat I didn't get so largely backed by some team at Alibaba",
    "start": "2276079",
    "end": "2281119"
  },
  {
    "text": "Verica are launching a C++ rewrite of flink so it'll have similar kind of properties to like sill's rewrite of",
    "start": "2281119",
    "end": "2287680"
  },
  {
    "text": "Cassandra and you mean the question is uh that yet like I think it's called Vera their new",
    "start": "2287680",
    "end": "2294079"
  },
  {
    "text": "platform so you mean the question is uh have you looked into using that as",
    "start": "2294079",
    "end": "2299839"
  },
  {
    "text": "another way to get more performance out of link uh other C++ tools even which one yes There's a new one called Vera by",
    "start": "2299839",
    "end": "2305920"
  },
  {
    "text": "the Vera team which is a rewrite of the core flink engine in C++ uh I actually",
    "start": "2305920",
    "end": "2311599"
  },
  {
    "text": "didn't uh know about rewrite of flink engine so",
    "start": "2311599",
    "end": "2317839"
  },
  {
    "text": "the question is have we considering some solution how how it name uh I'll I'll",
    "start": "2317839",
    "end": "2323440"
  },
  {
    "text": "tell you later yeah yeah okay so like the the question is that there is some uh solution which is frink rewrite to",
    "start": "2323440",
    "end": "2329160"
  },
  {
    "text": "C++ pretty much like what happened to Stila that u that rewritten Cassandra",
    "start": "2329160",
    "end": "2336800"
  },
  {
    "text": "which is Java to to C++ and red panda the same like Kafka which is in Java to C++ so in fact I don't know about like",
    "start": "2336800",
    "end": "2344480"
  },
  {
    "text": "the solution in C++ but there are other solution that u kind of claim to be",
    "start": "2344480",
    "end": "2350000"
  },
  {
    "text": "flint competitors uh which written in rust And the downside of all of them",
    "start": "2350000",
    "end": "2356320"
  },
  {
    "text": "that I mentioned that they claim to be all uh SQL only and uh uh this is harder",
    "start": "2356320",
    "end": "2363200"
  },
  {
    "text": "so like we took a look on multiple of them performance may be indeed good uh but how to adapt them uh with the same",
    "start": "2363200",
    "end": "2371839"
  },
  {
    "text": "level of what we can do with link we didn't manage to figure out so that uh",
    "start": "2371839",
    "end": "2377200"
  },
  {
    "text": "that's the question if someone can show maybe maybe I'm totally personally",
    "start": "2377200",
    "end": "2382400"
  },
  {
    "text": "totally openminded about other solutions",
    "start": "2382400",
    "end": "2387240"
  },
  {
    "text": "uh thank you for the great talk i just have a question for you know can you comment a little bit on the developer",
    "start": "2392320",
    "end": "2397760"
  },
  {
    "text": "experience of adding new features and how often does that happen so you said you have 100 features how often does",
    "start": "2397760",
    "end": "2402800"
  },
  {
    "text": "that grow and what's the developer experience of that thank you yeah okay thanks uh the the question is about the",
    "start": "2402800",
    "end": "2409520"
  },
  {
    "text": "developer experience of adding features how it looks like in uh in in our solution uh so it far from great to be",
    "start": "2409520",
    "end": "2417280"
  },
  {
    "text": "honest uh but it it pretty much like we have for each features we have some kind",
    "start": "2417280",
    "end": "2422480"
  },
  {
    "text": "of configuration file uh it we we split features into so-called feature set",
    "start": "2422480",
    "end": "2427680"
  },
  {
    "text": "feature set they are logically combined logically like for instance we have one model and like user features for this",
    "start": "2427680",
    "end": "2434800"
  },
  {
    "text": "model or some this kind of stuff like post features for this model they're somehow logically combined and this",
    "start": "2434800",
    "end": "2441520"
  },
  {
    "text": "configuration file is basically YAML that contains some settings and also query u query in flink square but the",
    "start": "2441520",
    "end": "2449760"
  },
  {
    "text": "query is simple so like it's it's equivalent in any square dialect and this query is basically select blah blah",
    "start": "2449760",
    "end": "2456160"
  },
  {
    "text": "blah and uh people can can do something with select like transform something uh",
    "start": "2456160",
    "end": "2461280"
  },
  {
    "text": "whatever so they they define the query and then uh then basically they can",
    "start": "2461280",
    "end": "2466720"
  },
  {
    "text": "launch the job so that there is deployment pipeline they they can push the button and job gets upgra",
    "start": "2466720",
    "end": "2472680"
  },
  {
    "text": "upgraded and uh so yeah that's that's the flow to define the features there",
    "start": "2472680",
    "end": "2479119"
  },
  {
    "text": "there is also the process how this features gets available for training and",
    "start": "2479119",
    "end": "2484319"
  },
  {
    "text": "we still use so-called wait and lock approach so like basically the feature",
    "start": "2484319",
    "end": "2489760"
  },
  {
    "text": "uh through the lifetime of accessing the feature we log the values and using this",
    "start": "2489760",
    "end": "2495440"
  },
  {
    "text": "log like model gets trained so like there is process so like when we edit features we now uh start to access it",
    "start": "2495440",
    "end": "2503040"
  },
  {
    "text": "for logging then enough time uh uh passed so like model can start being",
    "start": "2503040",
    "end": "2508720"
  },
  {
    "text": "trained on this data",
    "start": "2508720",
    "end": "2512440"
  },
  {
    "text": "i can you maybe elaborate on why did you choose Red Panda over Kafka",
    "start": "2514480",
    "end": "2521559"
  },
  {
    "text": "so like for for for the cost the question is how why we chose Red Panda",
    "start": "2522480",
    "end": "2527599"
  },
  {
    "text": "over Kafka the the question the the answer is the cost so that we basically",
    "start": "2527599",
    "end": "2534640"
  },
  {
    "text": "first of all we want it managed uh to be honest like uh because we didn't want to manage we didn't have people to manage",
    "start": "2534640",
    "end": "2540800"
  },
  {
    "text": "Kafka so we we use experience of manage kafka in house it just didn't have team to continue this and then we started",
    "start": "2540800",
    "end": "2548079"
  },
  {
    "text": "evaluating the solutions so like there is confluent uh and other vendors and then we",
    "start": "2548079",
    "end": "2554640"
  },
  {
    "text": "compared prices and uh Kafka Kafka was was the",
    "start": "2554640",
    "end": "2559760"
  },
  {
    "text": "winner for the cost but also there are a few other considerations like the they",
    "start": "2559760",
    "end": "2565680"
  },
  {
    "text": "uh have like remote read replicas and they kind of moving towards uh being",
    "start": "2565680",
    "end": "2570880"
  },
  {
    "text": "data lakehouse every vendor actually uh moving to that direction but uh like",
    "start": "2570880",
    "end": "2577760"
  },
  {
    "text": "their vision we just liked that's all",
    "start": "2577760",
    "end": "2582760"
  },
  {
    "text": "uh a very quick question uh so the data stream API for Flink is very similar to",
    "start": "2585839",
    "end": "2593119"
  },
  {
    "text": "Spark structured streaming in terms of the ability to uh do upserts on the tables i was just wondering if you have",
    "start": "2593119",
    "end": "2599599"
  },
  {
    "text": "any uh best practice advice regarding um so if jobs fail we can use the checkpoints to trigger jobs but what",
    "start": "2599599",
    "end": "2606319"
  },
  {
    "text": "about the disaster recovery strategies if the data is lost like what usually have you kind of thought in terms of",
    "start": "2606319",
    "end": "2613200"
  },
  {
    "text": "like a data backup but then the trouble becomes that the checkpoints are not portable um to another location because",
    "start": "2613200",
    "end": "2620800"
  },
  {
    "text": "of issues of uh hard coding of the table ids and stuff like that so have you kind",
    "start": "2620800",
    "end": "2626319"
  },
  {
    "text": "of thought about that mhm the question is about the best practices of using uh",
    "start": "2626319",
    "end": "2632040"
  },
  {
    "text": "flink or spark streaming which is equivalent in terms of disaster recovery",
    "start": "2632040",
    "end": "2638560"
  },
  {
    "text": "like if if if job died or something happened uh so what first of all we have",
    "start": "2638560",
    "end": "2644560"
  },
  {
    "text": "checkpoints enabled and they actually taken pretty regularly like once per",
    "start": "2644560",
    "end": "2649920"
  },
  {
    "text": "minute so checkpoints gets uploaded to uh cloud storage S3 equivalent in GCP so",
    "start": "2649920",
    "end": "2657920"
  },
  {
    "text": "we have a history uh of checkpoints and also we take safe points once in a while",
    "start": "2657920",
    "end": "2664800"
  },
  {
    "text": "uh like so we have this all this stuff ready to job to recover from but",
    "start": "2664800",
    "end": "2670640"
  },
  {
    "text": "sometimes to to be fair with flink at least the actually the state can get",
    "start": "2670640",
    "end": "2676599"
  },
  {
    "text": "corrupted so that and the state can get corrupted in such a nasty way that like",
    "start": "2676599",
    "end": "2682079"
  },
  {
    "text": "all checkpoints that we store let's say we store like last uh five 10 whatever",
    "start": "2682079",
    "end": "2688000"
  },
  {
    "text": "checkpoints they they all can get corrupted because like the corruption uh can propagate from checkpoint to",
    "start": "2688000",
    "end": "2694000"
  },
  {
    "text": "checkpoint and so now now we have the job with unreoverable state what we do",
    "start": "2694000",
    "end": "2699280"
  },
  {
    "text": "and the good thing about the approach I described that we don't do anything we just start job from scratch because it",
    "start": "2699280",
    "end": "2704560"
  },
  {
    "text": "will just restore like recover from from the main database by itself uh there",
    "start": "2704560",
    "end": "2709680"
  },
  {
    "text": "will be some uh a little bit of incorrectness probably due to like last",
    "start": "2709680",
    "end": "2715520"
  },
  {
    "text": "minute or whatever of of data but in general it",
    "start": "2715520",
    "end": "2721040"
  },
  {
    "text": "can get to the uh running state pretty quickly",
    "start": "2721040",
    "end": "2726680"
  },
  {
    "text": "thanks um great talk um I have a follow-up question to the developer",
    "start": "2727040",
    "end": "2732319"
  },
  {
    "text": "experience i can imagine that when you're um you're trying to understand uh",
    "start": "2732319",
    "end": "2738319"
  },
  {
    "text": "especially the part where you talk about the change log and um the fling operators as a developer I would love to",
    "start": "2738319",
    "end": "2744000"
  },
  {
    "text": "be able to interact with the state i'm wondering whether um I know that the the queryable state",
    "start": "2744000",
    "end": "2750400"
  },
  {
    "text": "feature from fling was deprecated i don't know whether um you were able to figure out a different way to see what's",
    "start": "2750400",
    "end": "2757200"
  },
  {
    "text": "within the state and um you know help you in in your ability to create new features and stuff thank you yeah great",
    "start": "2757200",
    "end": "2764800"
  },
  {
    "text": "question thank you the question is about uh developer experience when it comes to figuring out what's going on inside the",
    "start": "2764800",
    "end": "2771359"
  },
  {
    "text": "job basically we have like state actually two states one is quail state and then this change log aggregation of",
    "start": "2771359",
    "end": "2777040"
  },
  {
    "text": "a change log uh what to do uh it's in the works now for us like we didn't have",
    "start": "2777040",
    "end": "2783760"
  },
  {
    "text": "this for a while relied on like basically feature log which already down",
    "start": "2783760",
    "end": "2791839"
  },
  {
    "text": "down the line so like when feature computed and access it we lock it and we can have uh basically match rate over",
    "start": "2791839",
    "end": "2799440"
  },
  {
    "text": "like raw data uh plus feature locked uh yeah of course it's it's pretty tricky",
    "start": "2799440",
    "end": "2805440"
  },
  {
    "text": "uh and what we want we actually want to uh dump this intermediate change lock",
    "start": "2805440",
    "end": "2810480"
  },
  {
    "text": "operations to some OIP database like click house or similar and in this way",
    "start": "2810480",
    "end": "2816160"
  },
  {
    "text": "we will have this full history of what happened and ability to query and see but it's not yet ready so like we are",
    "start": "2816160",
    "end": "2822480"
  },
  {
    "text": "working on it now thank you thanks everybody let's give one more",
    "start": "2822480",
    "end": "2829530"
  },
  {
    "text": "[Music]",
    "start": "2829530",
    "end": "2834980"
  }
]
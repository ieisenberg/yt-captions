[
  {
    "start": "0",
    "end": "55000"
  },
  {
    "text": "[Music]",
    "start": "3360",
    "end": "6550"
  },
  {
    "text": "hi",
    "start": "9760",
    "end": "10559"
  },
  {
    "text": "today i'm going to share some of my",
    "start": "10559",
    "end": "12160"
  },
  {
    "text": "experience building and designing ml",
    "start": "12160",
    "end": "13840"
  },
  {
    "text": "infrastructure at",
    "start": "13840",
    "end": "15839"
  },
  {
    "text": "for many people ml at netflix is",
    "start": "15839",
    "end": "17680"
  },
  {
    "text": "synonymous with our recommendation",
    "start": "17680",
    "end": "19199"
  },
  {
    "text": "systems when you log into netflix every",
    "start": "19199",
    "end": "21520"
  },
  {
    "text": "single element of the user interface is",
    "start": "21520",
    "end": "23519"
  },
  {
    "text": "personalized to your taste",
    "start": "23519",
    "end": "25279"
  },
  {
    "text": "but our usage of ml actually goes much",
    "start": "25279",
    "end": "27439"
  },
  {
    "text": "beyond that",
    "start": "27439",
    "end": "28720"
  },
  {
    "text": "we have significant investments in a",
    "start": "28720",
    "end": "30240"
  },
  {
    "text": "diverse set of areas from figuring out",
    "start": "30240",
    "end": "32480"
  },
  {
    "text": "how to accurately value content for our",
    "start": "32480",
    "end": "34239"
  },
  {
    "text": "service fighting payment fraud service",
    "start": "34239",
    "end": "36719"
  },
  {
    "text": "abuse",
    "start": "36719",
    "end": "37760"
  },
  {
    "text": "as one of the biggest studios we rely on",
    "start": "37760",
    "end": "39600"
  },
  {
    "text": "data science for efficient content",
    "start": "39600",
    "end": "40960"
  },
  {
    "text": "production we have to figure out",
    "start": "40960",
    "end": "42480"
  },
  {
    "text": "efficient shoot schedules do automated",
    "start": "42480",
    "end": "44719"
  },
  {
    "text": "qa of raw footage figure out",
    "start": "44719",
    "end": "46559"
  },
  {
    "text": "opportunities on how we can advertise",
    "start": "46559",
    "end": "48399"
  },
  {
    "text": "efficiently to non-members as well as",
    "start": "48399",
    "end": "50640"
  },
  {
    "text": "making sure that our existing members",
    "start": "50640",
    "end": "52480"
  },
  {
    "text": "never run into rebuffers",
    "start": "52480",
    "end": "55520"
  },
  {
    "start": "55000",
    "end": "304000"
  },
  {
    "text": "today i'm going to talk about some of",
    "start": "55520",
    "end": "57039"
  },
  {
    "text": "the recent work we have done in",
    "start": "57039",
    "end": "58480"
  },
  {
    "text": "supporting all of these broad and",
    "start": "58480",
    "end": "59920"
  },
  {
    "text": "diverse use cases i'm going to focus",
    "start": "59920",
    "end": "62160"
  },
  {
    "text": "more on some of the higher level design",
    "start": "62160",
    "end": "63760"
  },
  {
    "text": "principles with the hope that some of",
    "start": "63760",
    "end": "65600"
  },
  {
    "text": "those might be useful to you in your",
    "start": "65600",
    "end": "67280"
  },
  {
    "text": "day-to-day work",
    "start": "67280",
    "end": "68640"
  },
  {
    "text": "all of the work that i'm going to talk",
    "start": "68640",
    "end": "70000"
  },
  {
    "text": "about today is now open source and is",
    "start": "70000",
    "end": "71840"
  },
  {
    "text": "broadly available on github",
    "start": "71840",
    "end": "75280"
  },
  {
    "text": "since we are building infrastructure",
    "start": "75600",
    "end": "77280"
  },
  {
    "text": "specifically machine learning",
    "start": "77280",
    "end": "78400"
  },
  {
    "text": "infrastructure to cater to a wide",
    "start": "78400",
    "end": "80159"
  },
  {
    "text": "variety of use cases it is important to",
    "start": "80159",
    "end": "82400"
  },
  {
    "text": "understand what are some of the common",
    "start": "82400",
    "end": "84000"
  },
  {
    "text": "concerns that cut across horizontally in",
    "start": "84000",
    "end": "86159"
  },
  {
    "text": "each of these use cases",
    "start": "86159",
    "end": "88000"
  },
  {
    "text": "let's start by looking at the day-to-day",
    "start": "88000",
    "end": "89520"
  },
  {
    "text": "life of a data scientist who is working",
    "start": "89520",
    "end": "91360"
  },
  {
    "text": "on any of these projects and what does",
    "start": "91360",
    "end": "93520"
  },
  {
    "text": "their stack look like",
    "start": "93520",
    "end": "96320"
  },
  {
    "text": "any ml project starts with data so our",
    "start": "96320",
    "end": "98479"
  },
  {
    "text": "data scientists need to be able to",
    "start": "98479",
    "end": "100000"
  },
  {
    "text": "reliably and efficiently query the data",
    "start": "100000",
    "end": "102079"
  },
  {
    "text": "warehouse to find the data that they",
    "start": "102079",
    "end": "103759"
  },
  {
    "text": "need this data could be say amazon s3",
    "start": "103759",
    "end": "106320"
  },
  {
    "text": "that netflix uses it could be google's",
    "start": "106320",
    "end": "108880"
  },
  {
    "text": "gcs as yours blob store could be some",
    "start": "108880",
    "end": "111439"
  },
  {
    "text": "other distributed file system like hdfs",
    "start": "111439",
    "end": "114000"
  },
  {
    "text": "but usually many organizations they tend",
    "start": "114000",
    "end": "116240"
  },
  {
    "text": "to keep their data in one of these data",
    "start": "116240",
    "end": "118240"
  },
  {
    "text": "warehouses",
    "start": "118240",
    "end": "120079"
  },
  {
    "text": "once as a data scientist you have access",
    "start": "120079",
    "end": "121759"
  },
  {
    "text": "to this data to perform any",
    "start": "121759",
    "end": "123360"
  },
  {
    "text": "transformation on this data set you need",
    "start": "123360",
    "end": "125439"
  },
  {
    "text": "access to compute resources",
    "start": "125439",
    "end": "127439"
  },
  {
    "text": "oftentimes that's their laptop many",
    "start": "127439",
    "end": "129360"
  },
  {
    "text": "times it could be the cloud as well say",
    "start": "129360",
    "end": "131520"
  },
  {
    "text": "kubernetes cluster",
    "start": "131520",
    "end": "134319"
  },
  {
    "text": "next comes the question of how this",
    "start": "134319",
    "end": "136319"
  },
  {
    "text": "compute would be orchestrated on these",
    "start": "136319",
    "end": "138160"
  },
  {
    "text": "compute resources",
    "start": "138160",
    "end": "139760"
  },
  {
    "text": "are you simply going to submit these",
    "start": "139760",
    "end": "141520"
  },
  {
    "text": "jobs one after the other calling some",
    "start": "141520",
    "end": "143120"
  },
  {
    "text": "api are you going to rely on a workflow",
    "start": "143120",
    "end": "145360"
  },
  {
    "text": "scheduler like airflow to string",
    "start": "145360",
    "end": "146800"
  },
  {
    "text": "together your compute",
    "start": "146800",
    "end": "149599"
  },
  {
    "text": "once you have these layers sorted out as",
    "start": "149599",
    "end": "151440"
  },
  {
    "text": "an end user you need to understand how",
    "start": "151440",
    "end": "153599"
  },
  {
    "text": "to essentially start writing your code",
    "start": "153599",
    "end": "155360"
  },
  {
    "text": "against the apis exposed to you so that",
    "start": "155360",
    "end": "157760"
  },
  {
    "text": "you can actually perform the compute you",
    "start": "157760",
    "end": "159120"
  },
  {
    "text": "can actually train the models that you",
    "start": "159120",
    "end": "160560"
  },
  {
    "text": "intend to do how would you like to",
    "start": "160560",
    "end": "162239"
  },
  {
    "text": "architect your code and",
    "start": "162239",
    "end": "164640"
  },
  {
    "text": "notice that you know up until now",
    "start": "164640",
    "end": "166480"
  },
  {
    "text": "there's very little ml specific stuff",
    "start": "166480",
    "end": "168319"
  },
  {
    "text": "that we have spoken about it's very much",
    "start": "168319",
    "end": "170080"
  },
  {
    "text": "like cookie cutter software engineering",
    "start": "170080",
    "end": "171760"
  },
  {
    "text": "systems engineering",
    "start": "171760",
    "end": "174000"
  },
  {
    "text": "it's above this level that we sort of",
    "start": "174000",
    "end": "175519"
  },
  {
    "text": "like start getting into the realm of",
    "start": "175519",
    "end": "177280"
  },
  {
    "text": "machine learning through model",
    "start": "177280",
    "end": "178879"
  },
  {
    "text": "operations",
    "start": "178879",
    "end": "180319"
  },
  {
    "text": "ml development is a highly iterative and",
    "start": "180319",
    "end": "182560"
  },
  {
    "text": "experimental exercise so you know as an",
    "start": "182560",
    "end": "184640"
  },
  {
    "text": "end user you have to worry about keeping",
    "start": "184640",
    "end": "186319"
  },
  {
    "text": "track of all your different experiments",
    "start": "186319",
    "end": "188480"
  },
  {
    "text": "all your hyper parameters your models",
    "start": "188480",
    "end": "190959"
  },
  {
    "text": "maybe you rely on some best practices",
    "start": "190959",
    "end": "192800"
  },
  {
    "text": "maybe you have big these best practices",
    "start": "192800",
    "end": "194560"
  },
  {
    "text": "into your coding standards maybe you use",
    "start": "194560",
    "end": "196720"
  },
  {
    "text": "some off-the-shelf tooling maybe you",
    "start": "196720",
    "end": "198640"
  },
  {
    "text": "work for a big company where you know",
    "start": "198640",
    "end": "200080"
  },
  {
    "text": "you have a dedicated team that is",
    "start": "200080",
    "end": "201360"
  },
  {
    "text": "building some specific tooling for you",
    "start": "201360",
    "end": "204640"
  },
  {
    "text": "and finally at the very top of the stack",
    "start": "204640",
    "end": "207120"
  },
  {
    "text": "is all the tooling for actually training",
    "start": "207120",
    "end": "209040"
  },
  {
    "text": "your models this includes your favorite",
    "start": "209040",
    "end": "211120"
  },
  {
    "text": "ide your feature engineering code your",
    "start": "211120",
    "end": "213680"
  },
  {
    "text": "favorite ml frameworks like tensorflow",
    "start": "213680",
    "end": "215760"
  },
  {
    "text": "pytorch maybe you know you might just",
    "start": "215760",
    "end": "217440"
  },
  {
    "text": "want to roll your own algorithm",
    "start": "217440",
    "end": "218720"
  },
  {
    "text": "implementation",
    "start": "218720",
    "end": "220720"
  },
  {
    "text": "now",
    "start": "220720",
    "end": "221840"
  },
  {
    "text": "what's interesting is that from a data",
    "start": "221840",
    "end": "223760"
  },
  {
    "text": "scientist point of view",
    "start": "223760",
    "end": "225440"
  },
  {
    "text": "they deeply care about what tools they",
    "start": "225440",
    "end": "227120"
  },
  {
    "text": "have at their disposal at the very top",
    "start": "227120",
    "end": "228879"
  },
  {
    "text": "of their stack",
    "start": "228879",
    "end": "230080"
  },
  {
    "text": "they'll have strong opinions on whether",
    "start": "230080",
    "end": "231760"
  },
  {
    "text": "they want to use tensorflow or pytorch",
    "start": "231760",
    "end": "234640"
  },
  {
    "text": "they'll have preferences about their",
    "start": "234640",
    "end": "236000"
  },
  {
    "text": "favorite ide",
    "start": "236000",
    "end": "237439"
  },
  {
    "text": "but at the lower levels they don't",
    "start": "237439",
    "end": "238959"
  },
  {
    "text": "really have express opinions they don't",
    "start": "238959",
    "end": "240879"
  },
  {
    "text": "care if their gpu is coming from a",
    "start": "240879",
    "end": "242799"
  },
  {
    "text": "kubernetes cluster or a server rack",
    "start": "242799",
    "end": "244720"
  },
  {
    "text": "hidden in somebody's closet as long as",
    "start": "244720",
    "end": "246720"
  },
  {
    "text": "they have quick and easy access to that",
    "start": "246720",
    "end": "248480"
  },
  {
    "text": "gpu same for that data as well they",
    "start": "248480",
    "end": "250560"
  },
  {
    "text": "don't care if that data is stored in",
    "start": "250560",
    "end": "252000"
  },
  {
    "text": "parquet format or orc as long as they",
    "start": "252000",
    "end": "254480"
  },
  {
    "text": "can very quickly and reliably query that",
    "start": "254480",
    "end": "256400"
  },
  {
    "text": "data",
    "start": "256400",
    "end": "258079"
  },
  {
    "text": "but unfortunately in any organization",
    "start": "258079",
    "end": "260320"
  },
  {
    "text": "while it's easy to get off the shelf",
    "start": "260320",
    "end": "261759"
  },
  {
    "text": "tooling for layers of the stack that are",
    "start": "261759",
    "end": "263280"
  },
  {
    "text": "higher there has been significant",
    "start": "263280",
    "end": "264800"
  },
  {
    "text": "progress that has been made in the open",
    "start": "264800",
    "end": "266240"
  },
  {
    "text": "source community",
    "start": "266240",
    "end": "267840"
  },
  {
    "text": "still a lot of effort is needed to set",
    "start": "267840",
    "end": "270160"
  },
  {
    "text": "up and maintain the lower levels of the",
    "start": "270160",
    "end": "272000"
  },
  {
    "text": "stack how do you set up your data",
    "start": "272000",
    "end": "273600"
  },
  {
    "text": "warehouse what are some of the best",
    "start": "273600",
    "end": "274800"
  },
  {
    "text": "practices in terms of writing data to",
    "start": "274800",
    "end": "276800"
  },
  {
    "text": "that data of your house how do you set",
    "start": "276800",
    "end": "278639"
  },
  {
    "text": "up and maintain your kubernetes cluster",
    "start": "278639",
    "end": "280240"
  },
  {
    "text": "how do you orchestrate that compute so",
    "start": "280240",
    "end": "282240"
  },
  {
    "text": "on so",
    "start": "282240",
    "end": "284000"
  },
  {
    "text": "and these are the details that a data",
    "start": "284000",
    "end": "285600"
  },
  {
    "text": "scientist would ideally want to get into",
    "start": "285600",
    "end": "289520"
  },
  {
    "text": "this was indeed our observation at",
    "start": "290000",
    "end": "291600"
  },
  {
    "text": "netflix as well and we essentially",
    "start": "291600",
    "end": "293600"
  },
  {
    "text": "decided to build a framework that will",
    "start": "293600",
    "end": "295199"
  },
  {
    "text": "allow our data scientists to move across",
    "start": "295199",
    "end": "297440"
  },
  {
    "text": "these layers easily while affording them",
    "start": "297440",
    "end": "299759"
  },
  {
    "text": "complete freedom and flexibility of",
    "start": "299759",
    "end": "301520"
  },
  {
    "text": "tooling at the top layers of the stack",
    "start": "301520",
    "end": "305199"
  },
  {
    "start": "304000",
    "end": "525000"
  },
  {
    "text": "metaflow is netflix's ml framework",
    "start": "305199",
    "end": "307440"
  },
  {
    "text": "geared towards increasing the",
    "start": "307440",
    "end": "308560"
  },
  {
    "text": "productivity of data scientists by",
    "start": "308560",
    "end": "310400"
  },
  {
    "text": "helping them focus on data science and",
    "start": "310400",
    "end": "312160"
  },
  {
    "text": "not engineering",
    "start": "312160",
    "end": "313520"
  },
  {
    "text": "it's an open source project that's",
    "start": "313520",
    "end": "314880"
  },
  {
    "text": "available on github that you can take a",
    "start": "314880",
    "end": "316560"
  },
  {
    "text": "look at and in today's",
    "start": "316560",
    "end": "318639"
  },
  {
    "text": "talk i'll essentially talk about some of",
    "start": "318639",
    "end": "320160"
  },
  {
    "text": "the higher level principles",
    "start": "320160",
    "end": "322000"
  },
  {
    "text": "that we learned the hard way while",
    "start": "322000",
    "end": "323440"
  },
  {
    "text": "building metaphor",
    "start": "323440",
    "end": "326160"
  },
  {
    "text": "each of the layers that i spoke of",
    "start": "326479",
    "end": "328639"
  },
  {
    "text": "just a couple of minutes ago are huge",
    "start": "328639",
    "end": "330400"
  },
  {
    "text": "daunting pieces of infrastructure by",
    "start": "330400",
    "end": "332000"
  },
  {
    "text": "themselves",
    "start": "332000",
    "end": "333039"
  },
  {
    "text": "ml infrastructure is such a broad field",
    "start": "333039",
    "end": "334720"
  },
  {
    "text": "that we can talk about any of these",
    "start": "334720",
    "end": "336240"
  },
  {
    "text": "layers for ours and we would still have",
    "start": "336240",
    "end": "338000"
  },
  {
    "text": "barely scratched the surface",
    "start": "338000",
    "end": "339840"
  },
  {
    "text": "given that i have your attention for the",
    "start": "339840",
    "end": "341680"
  },
  {
    "text": "next 15-20 minutes i'm going to focus on",
    "start": "341680",
    "end": "344240"
  },
  {
    "text": "three specific layers of the stack",
    "start": "344240",
    "end": "346080"
  },
  {
    "text": "namely architecture job scheduler and",
    "start": "346080",
    "end": "348320"
  },
  {
    "text": "compute resources and talk about how we",
    "start": "348320",
    "end": "350960"
  },
  {
    "text": "view these layers in our experience how",
    "start": "350960",
    "end": "352880"
  },
  {
    "text": "these layers should interact with one",
    "start": "352880",
    "end": "354320"
  },
  {
    "text": "another to provide a productive",
    "start": "354320",
    "end": "355759"
  },
  {
    "text": "experience to our data scientists",
    "start": "355759",
    "end": "359199"
  },
  {
    "text": "a very natural paradigm for expressing",
    "start": "360560",
    "end": "362800"
  },
  {
    "text": "data processing pipelines machine",
    "start": "362800",
    "end": "364720"
  },
  {
    "text": "learning in particular is that of a dag",
    "start": "364720",
    "end": "366960"
  },
  {
    "text": "a directed acyclic graph",
    "start": "366960",
    "end": "369199"
  },
  {
    "text": "in this example we have a dag the first",
    "start": "369199",
    "end": "371919"
  },
  {
    "text": "the user is fetching some data maybe",
    "start": "371919",
    "end": "373600"
  },
  {
    "text": "they are doing some feature engineering",
    "start": "373600",
    "end": "374960"
  },
  {
    "text": "on it then maybe they decided that they",
    "start": "374960",
    "end": "377120"
  },
  {
    "text": "need to train two different models maybe",
    "start": "377120",
    "end": "379520"
  },
  {
    "text": "they are just playing around with",
    "start": "379520",
    "end": "380479"
  },
  {
    "text": "different hyper parameters and they want",
    "start": "380479",
    "end": "382240"
  },
  {
    "text": "to choose the best one to publish at the",
    "start": "382240",
    "end": "384080"
  },
  {
    "text": "end of it",
    "start": "384080",
    "end": "385440"
  },
  {
    "text": "at this level the dac doesn't really say",
    "start": "385440",
    "end": "387280"
  },
  {
    "text": "anything about what codes gets executed",
    "start": "387280",
    "end": "389840"
  },
  {
    "text": "or where it is executed it's mostly",
    "start": "389840",
    "end": "392240"
  },
  {
    "text": "about how the data scientist wants to",
    "start": "392240",
    "end": "393840"
  },
  {
    "text": "structure their code",
    "start": "393840",
    "end": "395520"
  },
  {
    "text": "this concept of a dag its utility is",
    "start": "395520",
    "end": "398639"
  },
  {
    "text": "predominantly in helping data scientists",
    "start": "398639",
    "end": "401120"
  },
  {
    "text": "organize their work conceptually",
    "start": "401120",
    "end": "404720"
  },
  {
    "text": "if we zoom in a bit into this notion of",
    "start": "405440",
    "end": "408479"
  },
  {
    "text": "a dag there are three distinct layers",
    "start": "408479",
    "end": "410720"
  },
  {
    "text": "that will see",
    "start": "410720",
    "end": "412080"
  },
  {
    "text": "there's this fundamental layer of",
    "start": "412080",
    "end": "413520"
  },
  {
    "text": "architecture where the user has defined",
    "start": "413520",
    "end": "416000"
  },
  {
    "text": "what code needs to execute",
    "start": "416000",
    "end": "418160"
  },
  {
    "text": "and then there's this encompassing layer",
    "start": "418160",
    "end": "420000"
  },
  {
    "text": "of a job scheduler which dictates how",
    "start": "420000",
    "end": "422319"
  },
  {
    "text": "the code will be executed",
    "start": "422319",
    "end": "424560"
  },
  {
    "text": "and then we have this layer of compute",
    "start": "424560",
    "end": "426319"
  },
  {
    "text": "which dictates where the code is going",
    "start": "426319",
    "end": "428000"
  },
  {
    "text": "to execute",
    "start": "428000",
    "end": "429840"
  },
  {
    "text": "and if you look around in many",
    "start": "429840",
    "end": "431759"
  },
  {
    "text": "existing systems",
    "start": "431759",
    "end": "433599"
  },
  {
    "text": "they require kind of like a tight",
    "start": "433599",
    "end": "434880"
  },
  {
    "text": "coupling between these layers which was",
    "start": "434880",
    "end": "436479"
  },
  {
    "text": "often necessitated by infrastructure",
    "start": "436479",
    "end": "438080"
  },
  {
    "text": "limitations that created the cloud",
    "start": "438080",
    "end": "440560"
  },
  {
    "text": "as an example the user may have to",
    "start": "440560",
    "end": "442400"
  },
  {
    "text": "specify their code using a custom dsl",
    "start": "442400",
    "end": "445440"
  },
  {
    "text": "which limits the kind of work that they",
    "start": "445440",
    "end": "447520"
  },
  {
    "text": "can do",
    "start": "447520",
    "end": "448479"
  },
  {
    "text": "and this dsl may have to be executed",
    "start": "448479",
    "end": "451039"
  },
  {
    "text": "with a built-in specific scheduler that",
    "start": "451039",
    "end": "453199"
  },
  {
    "text": "is then again very tightly coupled with",
    "start": "453199",
    "end": "455280"
  },
  {
    "text": "the compute layer",
    "start": "455280",
    "end": "458080"
  },
  {
    "text": "now",
    "start": "458400",
    "end": "459440"
  },
  {
    "text": "while this type coupling may be",
    "start": "459440",
    "end": "461120"
  },
  {
    "text": "justified for domain specific use cases",
    "start": "461120",
    "end": "463360"
  },
  {
    "text": "say you know high performance computing",
    "start": "463360",
    "end": "465599"
  },
  {
    "text": "when you're building infrastructure to",
    "start": "465599",
    "end": "466960"
  },
  {
    "text": "support",
    "start": "466960",
    "end": "467919"
  },
  {
    "text": "hundreds of different use cases from",
    "start": "467919",
    "end": "469599"
  },
  {
    "text": "natural language processing to classical",
    "start": "469599",
    "end": "471440"
  },
  {
    "text": "statistics",
    "start": "471440",
    "end": "472639"
  },
  {
    "text": "you'd ideally want these layers to be",
    "start": "472639",
    "end": "474319"
  },
  {
    "text": "decoupled so that the user can choose",
    "start": "474319",
    "end": "476400"
  },
  {
    "text": "which layer to use when",
    "start": "476400",
    "end": "478400"
  },
  {
    "text": "and this was inherently the motivation",
    "start": "478400",
    "end": "480400"
  },
  {
    "text": "for metaphor",
    "start": "480400",
    "end": "483039"
  },
  {
    "text": "with beta flow our data scientists can",
    "start": "483680",
    "end": "485840"
  },
  {
    "text": "architect their modeling code in",
    "start": "485840",
    "end": "487440"
  },
  {
    "text": "languages and libraries that they are",
    "start": "487440",
    "end": "489039"
  },
  {
    "text": "familiar with they can leverage the rich",
    "start": "489039",
    "end": "491199"
  },
  {
    "text": "data science ecosystem in python nr",
    "start": "491199",
    "end": "493599"
  },
  {
    "text": "without any limitation",
    "start": "493599",
    "end": "495440"
  },
  {
    "text": "the user's code gets packaged for the",
    "start": "495440",
    "end": "497520"
  },
  {
    "text": "compute layer by metaflow so that the",
    "start": "497520",
    "end": "499759"
  },
  {
    "text": "user can focus on their code rather than",
    "start": "499759",
    "end": "501759"
  },
  {
    "text": "say you know writing docker files",
    "start": "501759",
    "end": "505440"
  },
  {
    "text": "finally the scheduling layer takes care",
    "start": "505440",
    "end": "507120"
  },
  {
    "text": "of executing the individual functions",
    "start": "507120",
    "end": "509120"
  },
  {
    "text": "using the compute layer from the data",
    "start": "509120",
    "end": "511280"
  },
  {
    "text": "scientist point of view the",
    "start": "511280",
    "end": "512640"
  },
  {
    "text": "infrastructure works exactly as it",
    "start": "512640",
    "end": "514479"
  },
  {
    "text": "should they can write idiomatic modeling",
    "start": "514479",
    "end": "516479"
  },
  {
    "text": "code use familiar abstractions and the",
    "start": "516479",
    "end": "519279"
  },
  {
    "text": "code gets executed without hassle even",
    "start": "519279",
    "end": "521760"
  },
  {
    "text": "at massive scale",
    "start": "521760",
    "end": "524560"
  },
  {
    "start": "525000",
    "end": "991000"
  },
  {
    "text": "so how does it work in practice",
    "start": "525600",
    "end": "528160"
  },
  {
    "text": "there are many ideas that make complete",
    "start": "528160",
    "end": "530240"
  },
  {
    "text": "theoretical sense but might fall flat",
    "start": "530240",
    "end": "532160"
  },
  {
    "text": "when they face reality let's let's look",
    "start": "532160",
    "end": "534720"
  },
  {
    "text": "at metaflow's programming model and see",
    "start": "534720",
    "end": "537040"
  },
  {
    "text": "if it actually really works in practice",
    "start": "537040",
    "end": "540240"
  },
  {
    "text": "data scientists",
    "start": "540240",
    "end": "542000"
  },
  {
    "text": "when they use metaflow they can",
    "start": "542000",
    "end": "543200"
  },
  {
    "text": "structure their workflow as a directory",
    "start": "543200",
    "end": "545360"
  },
  {
    "text": "cyclic graph of steps as depicted in",
    "start": "545360",
    "end": "547760"
  },
  {
    "text": "this diagram",
    "start": "547760",
    "end": "549040"
  },
  {
    "text": "the steps can be arbitrary python code",
    "start": "549040",
    "end": "551120"
  },
  {
    "text": "in this hypothetical example we have a",
    "start": "551120",
    "end": "552959"
  },
  {
    "text": "variable x uh that is incremented by two",
    "start": "552959",
    "end": "555519"
  },
  {
    "text": "steps uh a and b a incremented by two b",
    "start": "555519",
    "end": "558399"
  },
  {
    "text": "incremented by three",
    "start": "558399",
    "end": "560080"
  },
  {
    "text": "and both of them execute in parallel",
    "start": "560080",
    "end": "562080"
  },
  {
    "text": "because if you notice uh step a uh it",
    "start": "562080",
    "end": "565440"
  },
  {
    "text": "essentially transitions into two steps",
    "start": "565440",
    "end": "567360"
  },
  {
    "text": "in parallel step a and b",
    "start": "567360",
    "end": "569600"
  },
  {
    "text": "and in the joint step we essentially",
    "start": "569600",
    "end": "570959"
  },
  {
    "text": "take the maximum of those two",
    "start": "570959",
    "end": "572800"
  },
  {
    "text": "concurrently existing values of x",
    "start": "572800",
    "end": "576560"
  },
  {
    "text": "now in the case of meta flow defining a",
    "start": "576560",
    "end": "578800"
  },
  {
    "text": "dag is as simple as annotating your",
    "start": "578800",
    "end": "580800"
  },
  {
    "text": "functions with the add step decorator",
    "start": "580800",
    "end": "582560"
  },
  {
    "text": "for nodes of your graph",
    "start": "582560",
    "end": "584160"
  },
  {
    "text": "and for edges you can simply specify the",
    "start": "584160",
    "end": "586080"
  },
  {
    "text": "transitions using the self.next method",
    "start": "586080",
    "end": "588399"
  },
  {
    "text": "calls",
    "start": "588399",
    "end": "590959"
  },
  {
    "text": "now",
    "start": "590959",
    "end": "591760"
  },
  {
    "text": "given that any of these steps are just",
    "start": "591760",
    "end": "593440"
  },
  {
    "text": "executing arbitrary python code you can",
    "start": "593440",
    "end": "596160"
  },
  {
    "text": "literally use any library available to",
    "start": "596160",
    "end": "598000"
  },
  {
    "text": "you in the python universe metaflow by",
    "start": "598000",
    "end": "599920"
  },
  {
    "text": "itself does not place any constraints on",
    "start": "599920",
    "end": "601920"
  },
  {
    "text": "that",
    "start": "601920",
    "end": "602880"
  },
  {
    "text": "at netflix we even do have a significant",
    "start": "602880",
    "end": "605040"
  },
  {
    "text": "number of users who are committed to our",
    "start": "605040",
    "end": "606880"
  },
  {
    "text": "lang so we do provide a similar package",
    "start": "606880",
    "end": "608959"
  },
  {
    "text": "in r as well for them with exactly the",
    "start": "608959",
    "end": "611760"
  },
  {
    "text": "same set of capabilities",
    "start": "611760",
    "end": "614399"
  },
  {
    "text": "also note how the value of x was",
    "start": "614399",
    "end": "616959"
  },
  {
    "text": "available both to step a and b and then",
    "start": "616959",
    "end": "619600"
  },
  {
    "text": "two copies of x one with the value of",
    "start": "619600",
    "end": "621360"
  },
  {
    "text": "two and the other the value of three are",
    "start": "621360",
    "end": "623600"
  },
  {
    "text": "now both available concurrently in this",
    "start": "623600",
    "end": "625680"
  },
  {
    "text": "joint step",
    "start": "625680",
    "end": "627120"
  },
  {
    "text": "mediflow is essentially taking care of",
    "start": "627120",
    "end": "628800"
  },
  {
    "text": "state transfer out of the box so that",
    "start": "628800",
    "end": "630320"
  },
  {
    "text": "the user doesn't have to worry about any",
    "start": "630320",
    "end": "632560"
  },
  {
    "text": "of the data flow details",
    "start": "632560",
    "end": "634800"
  },
  {
    "text": "and",
    "start": "634800",
    "end": "635600"
  },
  {
    "text": "this this paradigm by itself this notion",
    "start": "635600",
    "end": "638000"
  },
  {
    "text": "of arranging your",
    "start": "638000",
    "end": "639440"
  },
  {
    "text": "work in this dag paradigm",
    "start": "639440",
    "end": "642240"
  },
  {
    "text": "is really powerful since it very simply",
    "start": "642240",
    "end": "644399"
  },
  {
    "text": "allows our users to properly organize",
    "start": "644399",
    "end": "646240"
  },
  {
    "text": "and visualize their work that sort of",
    "start": "646240",
    "end": "647760"
  },
  {
    "text": "gets them",
    "start": "647760",
    "end": "648720"
  },
  {
    "text": "a lot further than their imperative",
    "start": "648720",
    "end": "650560"
  },
  {
    "text": "style of uh writing code",
    "start": "650560",
    "end": "654480"
  },
  {
    "text": "now",
    "start": "655519",
    "end": "656720"
  },
  {
    "text": "once the user has specified their",
    "start": "656720",
    "end": "658160"
  },
  {
    "text": "workflow there could be a scenario that",
    "start": "658160",
    "end": "660640"
  },
  {
    "text": "they like the ability to execute some or",
    "start": "660640",
    "end": "662959"
  },
  {
    "text": "all of the steps of their workflow on",
    "start": "662959",
    "end": "664399"
  },
  {
    "text": "their laptop",
    "start": "664399",
    "end": "665600"
  },
  {
    "text": "uh this is pretty common you know if you",
    "start": "665600",
    "end": "667680"
  },
  {
    "text": "say you need to train a model uh that",
    "start": "667680",
    "end": "670079"
  },
  {
    "text": "needs access to gpus or maybe it needs",
    "start": "670079",
    "end": "672399"
  },
  {
    "text": "access to many more cores of cpus than",
    "start": "672399",
    "end": "674800"
  },
  {
    "text": "you have already available to you",
    "start": "674800",
    "end": "676640"
  },
  {
    "text": "maybe you want to process a huge data",
    "start": "676640",
    "end": "678880"
  },
  {
    "text": "frame that needs 200 gigs of ram and",
    "start": "678880",
    "end": "681200"
  },
  {
    "text": "your laptop just is bottling that 16",
    "start": "681200",
    "end": "683920"
  },
  {
    "text": "gigs of ram",
    "start": "683920",
    "end": "685839"
  },
  {
    "text": "now in meta flow the user can easily",
    "start": "685839",
    "end": "687920"
  },
  {
    "text": "declare the compute layer for their",
    "start": "687920",
    "end": "689680"
  },
  {
    "text": "steps and metaflow will ensure that",
    "start": "689680",
    "end": "691519"
  },
  {
    "text": "these steps get executed on that compute",
    "start": "691519",
    "end": "693600"
  },
  {
    "text": "layer",
    "start": "693600",
    "end": "694399"
  },
  {
    "text": "in this example specifying the at",
    "start": "694399",
    "end": "697040"
  },
  {
    "text": "resources decorator is akin to the user",
    "start": "697040",
    "end": "699519"
  },
  {
    "text": "saying that hey this tip needs to",
    "start": "699519",
    "end": "701040"
  },
  {
    "text": "execute on a cloud instance with four",
    "start": "701040",
    "end": "702880"
  },
  {
    "text": "gpus",
    "start": "702880",
    "end": "704560"
  },
  {
    "text": "note that in this example the user never",
    "start": "704560",
    "end": "707040"
  },
  {
    "text": "had to specify",
    "start": "707040",
    "end": "708399"
  },
  {
    "text": "how their code is getting packaged uh",
    "start": "708399",
    "end": "710880"
  },
  {
    "text": "how are they making a docker container",
    "start": "710880",
    "end": "714000"
  },
  {
    "text": "if let's say eventually the code is",
    "start": "714000",
    "end": "716079"
  },
  {
    "text": "running on top of kubernetes clustered",
    "start": "716079",
    "end": "717760"
  },
  {
    "text": "they don't have to deal with a",
    "start": "717760",
    "end": "719200"
  },
  {
    "text": "kubernetes api or even you know when we",
    "start": "719200",
    "end": "721920"
  },
  {
    "text": "move a compute unit from their laptop uh",
    "start": "721920",
    "end": "724959"
  },
  {
    "text": "to the cloud they still need access to",
    "start": "724959",
    "end": "726959"
  },
  {
    "text": "the raw data and metaflow takes care of",
    "start": "726959",
    "end": "729440"
  },
  {
    "text": "moving around data dealing with the",
    "start": "729440",
    "end": "731200"
  },
  {
    "text": "underlying compute layer behind the",
    "start": "731200",
    "end": "732720"
  },
  {
    "text": "scenes for the user so that the user",
    "start": "732720",
    "end": "734240"
  },
  {
    "text": "doesn't have to focus on that",
    "start": "734240",
    "end": "737440"
  },
  {
    "text": "many times",
    "start": "737920",
    "end": "739600"
  },
  {
    "text": "it's not only the resources that might",
    "start": "739600",
    "end": "741279"
  },
  {
    "text": "be a constraint",
    "start": "741279",
    "end": "742480"
  },
  {
    "text": "maybe you might want to process some",
    "start": "742480",
    "end": "743920"
  },
  {
    "text": "sensitive data that you don't have",
    "start": "743920",
    "end": "745440"
  },
  {
    "text": "access to on your laptop",
    "start": "745440",
    "end": "747200"
  },
  {
    "text": "uh at netflix this is a very common use",
    "start": "747200",
    "end": "749120"
  },
  {
    "text": "case uh so",
    "start": "749120",
    "end": "750800"
  },
  {
    "text": "at netflix some of the teams uh they",
    "start": "750800",
    "end": "752399"
  },
  {
    "text": "have built this amazing compute system",
    "start": "752399",
    "end": "753760"
  },
  {
    "text": "called archer",
    "start": "753760",
    "end": "755040"
  },
  {
    "text": "which provides access to all the media",
    "start": "755040",
    "end": "756800"
  },
  {
    "text": "files all the raw footage from our tv",
    "start": "756800",
    "end": "759120"
  },
  {
    "text": "shows and movies in a secure environment",
    "start": "759120",
    "end": "762160"
  },
  {
    "text": "in the scenario in this",
    "start": "762160",
    "end": "764320"
  },
  {
    "text": "dag that you have maybe all you want to",
    "start": "764320",
    "end": "766000"
  },
  {
    "text": "do is some summarization on some media",
    "start": "766000",
    "end": "768000"
  },
  {
    "text": "files in your start step but you don't",
    "start": "768000",
    "end": "770160"
  },
  {
    "text": "want any of your other steps to execute",
    "start": "770160",
    "end": "772399"
  },
  {
    "text": "in this secure environment that archer",
    "start": "772399",
    "end": "774399"
  },
  {
    "text": "provides and you can now very simply",
    "start": "774399",
    "end": "776399"
  },
  {
    "text": "just annotate one of your steps with at",
    "start": "776399",
    "end": "778720"
  },
  {
    "text": "archer and then metaphor will figure out",
    "start": "778720",
    "end": "780720"
  },
  {
    "text": "how to package your compute and execute",
    "start": "780720",
    "end": "782560"
  },
  {
    "text": "the compute on archer in a very secure",
    "start": "782560",
    "end": "784880"
  },
  {
    "text": "and stable manner",
    "start": "784880",
    "end": "787839"
  },
  {
    "text": "now",
    "start": "788160",
    "end": "789200"
  },
  {
    "text": "once the user has specified a workflow",
    "start": "789200",
    "end": "791839"
  },
  {
    "text": "orchestrating the execution of the dag",
    "start": "791839",
    "end": "794160"
  },
  {
    "text": "belongs to the job scheduler layer",
    "start": "794160",
    "end": "796480"
  },
  {
    "text": "the scheduling layer doesn't need to",
    "start": "796480",
    "end": "798160"
  },
  {
    "text": "care about what code is being executed",
    "start": "798160",
    "end": "801040"
  },
  {
    "text": "its sole responsibility is to schedule",
    "start": "801040",
    "end": "803279"
  },
  {
    "text": "the steps in the topological order",
    "start": "803279",
    "end": "805120"
  },
  {
    "text": "making sure that a step finishes",
    "start": "805120",
    "end": "806560"
  },
  {
    "text": "successfully before its successors in",
    "start": "806560",
    "end": "808880"
  },
  {
    "text": "the graph are executed",
    "start": "808880",
    "end": "811279"
  },
  {
    "text": "meta flow ships with a local scheduler",
    "start": "811279",
    "end": "813200"
  },
  {
    "text": "which makes it easy to test workflows",
    "start": "813200",
    "end": "815279"
  },
  {
    "text": "locally on laptop or",
    "start": "815279",
    "end": "817600"
  },
  {
    "text": "on the cloud",
    "start": "817600",
    "end": "819440"
  },
  {
    "text": "while the built-in scheduler is fully",
    "start": "819440",
    "end": "820959"
  },
  {
    "text": "functional in the sense that you know it",
    "start": "820959",
    "end": "822639"
  },
  {
    "text": "executes the steps in a topological",
    "start": "822639",
    "end": "824560"
  },
  {
    "text": "order and can handle workflows with tens",
    "start": "824560",
    "end": "826639"
  },
  {
    "text": "and thousands of tasks it lacks support",
    "start": "826639",
    "end": "829120"
  },
  {
    "text": "for triggering workflows for alerting",
    "start": "829120",
    "end": "831120"
  },
  {
    "text": "and monitoring on failures by design",
    "start": "831120",
    "end": "834079"
  },
  {
    "text": "and",
    "start": "834079",
    "end": "834800"
  },
  {
    "text": "since we've been talking about the value",
    "start": "834800",
    "end": "836639"
  },
  {
    "text": "of interchangeable layers so far like",
    "start": "836639",
    "end": "839120"
  },
  {
    "text": "rather than build yet another",
    "start": "839120",
    "end": "841120"
  },
  {
    "text": "production grade dag scheduler by",
    "start": "841120",
    "end": "842800"
  },
  {
    "text": "ourselves",
    "start": "842800",
    "end": "843920"
  },
  {
    "text": "we can very simply just combine this dag",
    "start": "843920",
    "end": "846160"
  },
  {
    "text": "into something that a production dance",
    "start": "846160",
    "end": "848079"
  },
  {
    "text": "scheduler understands you know like most",
    "start": "848079",
    "end": "850240"
  },
  {
    "text": "back schedulers at the end of the day",
    "start": "850240",
    "end": "851760"
  },
  {
    "text": "they are executing a graph we already",
    "start": "851760",
    "end": "853680"
  },
  {
    "text": "have a representation of the graph from",
    "start": "853680",
    "end": "855279"
  },
  {
    "text": "the user so it should be",
    "start": "855279",
    "end": "857279"
  },
  {
    "text": "rather straightforward for us to",
    "start": "857279",
    "end": "860000"
  },
  {
    "text": "write a compiler that can compile that",
    "start": "860000",
    "end": "861920"
  },
  {
    "text": "down to something that the scheduler",
    "start": "861920",
    "end": "863760"
  },
  {
    "text": "understands",
    "start": "863760",
    "end": "865760"
  },
  {
    "text": "another benefit",
    "start": "865760",
    "end": "867519"
  },
  {
    "text": "that i want to highlight here is that",
    "start": "867519",
    "end": "870639"
  },
  {
    "text": "when we were building metaflow we wanted",
    "start": "870639",
    "end": "872480"
  },
  {
    "text": "to provide strong guarantees about",
    "start": "872480",
    "end": "874160"
  },
  {
    "text": "backward compatibility to the user",
    "start": "874160",
    "end": "876079"
  },
  {
    "text": "facing api the api against which the",
    "start": "876079",
    "end": "878000"
  },
  {
    "text": "user writes code",
    "start": "878000",
    "end": "879440"
  },
  {
    "text": "so the user can now write the code",
    "start": "879440",
    "end": "881279"
  },
  {
    "text": "confidently knowing that meta flow will",
    "start": "881279",
    "end": "883199"
  },
  {
    "text": "schedule and execute their code without",
    "start": "883199",
    "end": "885120"
  },
  {
    "text": "changes even if the underlying",
    "start": "885120",
    "end": "886560"
  },
  {
    "text": "scheduling and computing layer evolves",
    "start": "886560",
    "end": "888480"
  },
  {
    "text": "over time",
    "start": "888480",
    "end": "889600"
  },
  {
    "text": "for example you know if you have",
    "start": "889600",
    "end": "890880"
  },
  {
    "text": "specified ad resources decorator we",
    "start": "890880",
    "end": "893440"
  },
  {
    "text": "might be launching that step on a",
    "start": "893440",
    "end": "895519"
  },
  {
    "text": "kubernetes cluster and that kubernetes",
    "start": "895519",
    "end": "897680"
  },
  {
    "text": "cluster might evolve the underlying apis",
    "start": "897680",
    "end": "899680"
  },
  {
    "text": "might change but the user doesn't have",
    "start": "899680",
    "end": "901600"
  },
  {
    "text": "to take any explicit action on their end",
    "start": "901600",
    "end": "904880"
  },
  {
    "text": "because meta flow will take care of",
    "start": "904880",
    "end": "906399"
  },
  {
    "text": "evolving along with the underlying",
    "start": "906399",
    "end": "908320"
  },
  {
    "text": "layers while providing a consistently",
    "start": "908320",
    "end": "910399"
  },
  {
    "text": "stable api to the end user",
    "start": "910399",
    "end": "912480"
  },
  {
    "text": "and this this eases the burden on part",
    "start": "912480",
    "end": "914720"
  },
  {
    "text": "of the user where they don't have to go",
    "start": "914720",
    "end": "916320"
  },
  {
    "text": "through a migration pane as the world",
    "start": "916320",
    "end": "918079"
  },
  {
    "text": "evolves within beneath them",
    "start": "918079",
    "end": "922079"
  },
  {
    "text": "here's an example of executing the flow",
    "start": "923040",
    "end": "925199"
  },
  {
    "text": "locally using metaflow's built-in",
    "start": "925199",
    "end": "927199"
  },
  {
    "text": "scheduler",
    "start": "927199",
    "end": "928560"
  },
  {
    "text": "metaflow will validate the workflow",
    "start": "928560",
    "end": "931040"
  },
  {
    "text": "making sure it's a well-defined workflow",
    "start": "931040",
    "end": "932959"
  },
  {
    "text": "it will assign the execution a unique id",
    "start": "932959",
    "end": "935600"
  },
  {
    "text": "so that you can inspect the state of the",
    "start": "935600",
    "end": "937120"
  },
  {
    "text": "execution at any point of time in the",
    "start": "937120",
    "end": "939279"
  },
  {
    "text": "future",
    "start": "939279",
    "end": "940800"
  },
  {
    "text": "any steps marked with a specific compute",
    "start": "940800",
    "end": "942720"
  },
  {
    "text": "environment say",
    "start": "942720",
    "end": "944000"
  },
  {
    "text": "add resources at archer maybe you know",
    "start": "944000",
    "end": "946639"
  },
  {
    "text": "have written your own decorator",
    "start": "946639",
    "end": "948800"
  },
  {
    "text": "they'll get executed in those",
    "start": "948800",
    "end": "950160"
  },
  {
    "text": "environments and metaflow will pipe back",
    "start": "950160",
    "end": "952399"
  },
  {
    "text": "the logs to their console",
    "start": "952399",
    "end": "955040"
  },
  {
    "text": "if say the user specified 200 gigs of",
    "start": "955040",
    "end": "957360"
  },
  {
    "text": "ram with the at resources decorator for",
    "start": "957360",
    "end": "960079"
  },
  {
    "text": "one step",
    "start": "960079",
    "end": "961199"
  },
  {
    "text": "to them it would feel like suddenly",
    "start": "961199",
    "end": "962959"
  },
  {
    "text": "somebody came in swapped out their",
    "start": "962959",
    "end": "964880"
  },
  {
    "text": "laptop with a bigger laptop that had 200",
    "start": "964880",
    "end": "966880"
  },
  {
    "text": "gigs of ram and they didn't have to take",
    "start": "966880",
    "end": "969600"
  },
  {
    "text": "any specific action besides specifying",
    "start": "969600",
    "end": "972560"
  },
  {
    "text": "that decorator",
    "start": "972560",
    "end": "974000"
  },
  {
    "text": "and at the end of the day this is",
    "start": "974000",
    "end": "975519"
  },
  {
    "text": "incredibly productive for our users",
    "start": "975519",
    "end": "977199"
  },
  {
    "text": "because then they can squarely focus on",
    "start": "977199",
    "end": "979519"
  },
  {
    "text": "their business logic on their code their",
    "start": "979519",
    "end": "981279"
  },
  {
    "text": "machine learning training code and all",
    "start": "981279",
    "end": "983519"
  },
  {
    "text": "the underlying",
    "start": "983519",
    "end": "984880"
  },
  {
    "text": "systems engineering integrity are just",
    "start": "984880",
    "end": "987360"
  },
  {
    "text": "abstracted away by the library",
    "start": "987360",
    "end": "990959"
  },
  {
    "start": "991000",
    "end": "1183000"
  },
  {
    "text": "for integrating with production",
    "start": "991839",
    "end": "993440"
  },
  {
    "text": "schedulers currently mediflow has two",
    "start": "993440",
    "end": "995839"
  },
  {
    "text": "integrations in",
    "start": "995839",
    "end": "997440"
  },
  {
    "text": "open source version we have an",
    "start": "997440",
    "end": "999199"
  },
  {
    "text": "integration with",
    "start": "999199",
    "end": "1000639"
  },
  {
    "text": "aws step functions",
    "start": "1000639",
    "end": "1002320"
  },
  {
    "text": "uh which is a managed offering by aws",
    "start": "1002320",
    "end": "1004639"
  },
  {
    "text": "it's highly available scales out",
    "start": "1004639",
    "end": "1006399"
  },
  {
    "text": "incredibly well to thousands of tasks in",
    "start": "1006399",
    "end": "1008480"
  },
  {
    "text": "a given workflow as well as thousands of",
    "start": "1008480",
    "end": "1010800"
  },
  {
    "text": "concurrently running workflow and more",
    "start": "1010800",
    "end": "1012800"
  },
  {
    "text": "importantly it's a managed service by",
    "start": "1012800",
    "end": "1014320"
  },
  {
    "text": "aws so it has zero operational burden",
    "start": "1014320",
    "end": "1016720"
  },
  {
    "text": "and with one single",
    "start": "1016720",
    "end": "1018959"
  },
  {
    "text": "cli command",
    "start": "1018959",
    "end": "1021440"
  },
  {
    "text": "python flow dot py step functions create",
    "start": "1021440",
    "end": "1024640"
  },
  {
    "text": "you can export your metaphor workflow to",
    "start": "1024640",
    "end": "1026400"
  },
  {
    "text": "step functions metaphor will behind the",
    "start": "1026400",
    "end": "1028720"
  },
  {
    "text": "scenes compile your workflow into a",
    "start": "1028720",
    "end": "1030319"
  },
  {
    "text": "language that step functions understands",
    "start": "1030319",
    "end": "1032880"
  },
  {
    "text": "and you as a user you have literally no",
    "start": "1032880",
    "end": "1035120"
  },
  {
    "text": "need to familiarize yourself with the",
    "start": "1035120",
    "end": "1037199"
  },
  {
    "text": "documentation of the sdk that step",
    "start": "1037199",
    "end": "1038959"
  },
  {
    "text": "function chips or understand any of the",
    "start": "1038959",
    "end": "1040640"
  },
  {
    "text": "net equities all of those concerns are",
    "start": "1040640",
    "end": "1042880"
  },
  {
    "text": "abstracted away",
    "start": "1042880",
    "end": "1044319"
  },
  {
    "text": "and the great thing about",
    "start": "1044319",
    "end": "1046640"
  },
  {
    "text": "a scheduler like step functions is that",
    "start": "1046640",
    "end": "1048640"
  },
  {
    "text": "it integrates further with the rest of",
    "start": "1048640",
    "end": "1050640"
  },
  {
    "text": "the aws infrastructure so you don't have",
    "start": "1050640",
    "end": "1052320"
  },
  {
    "text": "to take any explicit action all of your",
    "start": "1052320",
    "end": "1053919"
  },
  {
    "text": "logs will be made available in cloud",
    "start": "1053919",
    "end": "1055520"
  },
  {
    "text": "watch all of the alerting and monitoring",
    "start": "1055520",
    "end": "1057440"
  },
  {
    "text": "is available to you out of the box",
    "start": "1057440",
    "end": "1059760"
  },
  {
    "text": "we also have a similar",
    "start": "1059760",
    "end": "1061600"
  },
  {
    "text": "internal integration with netflix's",
    "start": "1061600",
    "end": "1063280"
  },
  {
    "text": "maison which is a production scheduler",
    "start": "1063280",
    "end": "1065760"
  },
  {
    "text": "it's it's internal to netflix we haven't",
    "start": "1065760",
    "end": "1067600"
  },
  {
    "text": "been able to open source it yet and",
    "start": "1067600",
    "end": "1069360"
  },
  {
    "text": "that's where most of our machine",
    "start": "1069360",
    "end": "1070640"
  },
  {
    "text": "learning pipelines execute",
    "start": "1070640",
    "end": "1072480"
  },
  {
    "text": "and again our users they don't ever have",
    "start": "1072480",
    "end": "1074880"
  },
  {
    "text": "to worry about the api that meson",
    "start": "1074880",
    "end": "1076880"
  },
  {
    "text": "exposes or how it evolves behind the",
    "start": "1076880",
    "end": "1078880"
  },
  {
    "text": "scenes just very recently the team",
    "start": "1078880",
    "end": "1081600"
  },
  {
    "text": "behind nissan they did a migration uh",
    "start": "1081600",
    "end": "1084480"
  },
  {
    "text": "where they migrated all of their users",
    "start": "1084480",
    "end": "1086240"
  },
  {
    "text": "from one version of their sdk to another",
    "start": "1086240",
    "end": "1089280"
  },
  {
    "text": "and none of the users of metaflow had to",
    "start": "1089280",
    "end": "1091360"
  },
  {
    "text": "take any specific action to migrate all",
    "start": "1091360",
    "end": "1093600"
  },
  {
    "text": "of their workflows just migrated behind",
    "start": "1093600",
    "end": "1095520"
  },
  {
    "text": "the scenes because all we had to do was",
    "start": "1095520",
    "end": "1097520"
  },
  {
    "text": "change the api integration that might",
    "start": "1097520",
    "end": "1099360"
  },
  {
    "text": "have your hand with me",
    "start": "1099360",
    "end": "1102160"
  },
  {
    "text": "now",
    "start": "1102559",
    "end": "1103600"
  },
  {
    "text": "i'm almost out of time",
    "start": "1103600",
    "end": "1105360"
  },
  {
    "text": "but before i leave you i want to",
    "start": "1105360",
    "end": "1107280"
  },
  {
    "text": "highlight some of the key takeaways from",
    "start": "1107280",
    "end": "1108960"
  },
  {
    "text": "today's talk",
    "start": "1108960",
    "end": "1110240"
  },
  {
    "text": "the primary one being that problems at",
    "start": "1110240",
    "end": "1112240"
  },
  {
    "text": "the end of the day they're solved by",
    "start": "1112240",
    "end": "1113600"
  },
  {
    "text": "humans and not tools",
    "start": "1113600",
    "end": "1115440"
  },
  {
    "text": "so we should build our tooling with",
    "start": "1115440",
    "end": "1118080"
  },
  {
    "text": "human centricity keeping our end users",
    "start": "1118080",
    "end": "1120480"
  },
  {
    "text": "at the center our users they should",
    "start": "1120480",
    "end": "1123360"
  },
  {
    "text": "focus on the details of their ml work",
    "start": "1123360",
    "end": "1125440"
  },
  {
    "text": "and not on the details of compute and",
    "start": "1125440",
    "end": "1127520"
  },
  {
    "text": "scheduling layer that sits beneath them",
    "start": "1127520",
    "end": "1130160"
  },
  {
    "text": "so decoupling the architecture job",
    "start": "1130160",
    "end": "1132720"
  },
  {
    "text": "scheduler and the compute layer that",
    "start": "1132720",
    "end": "1135600"
  },
  {
    "text": "totally makes sense at least for our use",
    "start": "1135600",
    "end": "1137520"
  },
  {
    "text": "cases",
    "start": "1137520",
    "end": "1139760"
  },
  {
    "text": "now if any of these ideas resonated with",
    "start": "1139760",
    "end": "1142240"
  },
  {
    "text": "you uh mediflow is an open source",
    "start": "1142240",
    "end": "1144400"
  },
  {
    "text": "project we also have complementary",
    "start": "1144400",
    "end": "1146160"
  },
  {
    "text": "sandboxes available for you where you",
    "start": "1146160",
    "end": "1147760"
  },
  {
    "text": "can try out metaphors cloud integrations",
    "start": "1147760",
    "end": "1150320"
  },
  {
    "text": "you can sign in with your github id and",
    "start": "1150320",
    "end": "1152720"
  },
  {
    "text": "we'll provision you",
    "start": "1152720",
    "end": "1154240"
  },
  {
    "text": "an aws",
    "start": "1154240",
    "end": "1156000"
  },
  {
    "text": "account with all the infrastructure set",
    "start": "1156000",
    "end": "1158559"
  },
  {
    "text": "up for you so that you can",
    "start": "1158559",
    "end": "1160559"
  },
  {
    "text": "essentially figure out that everything",
    "start": "1160559",
    "end": "1162080"
  },
  {
    "text": "that i spoke about",
    "start": "1162080",
    "end": "1163600"
  },
  {
    "text": "actually really works",
    "start": "1163600",
    "end": "1165679"
  },
  {
    "text": "and",
    "start": "1165679",
    "end": "1166720"
  },
  {
    "text": "we have lots of documentation available",
    "start": "1166720",
    "end": "1168720"
  },
  {
    "text": "online and uh we are happy to support",
    "start": "1168720",
    "end": "1171120"
  },
  {
    "text": "you in your ml journey on our chat",
    "start": "1171120",
    "end": "1172960"
  },
  {
    "text": "channel so uh please do feel free to",
    "start": "1172960",
    "end": "1175520"
  },
  {
    "text": "reach out",
    "start": "1175520",
    "end": "1176880"
  },
  {
    "text": "and i'll be happy to take any questions",
    "start": "1176880",
    "end": "1179280"
  },
  {
    "text": "that you might have",
    "start": "1179280",
    "end": "1180799"
  },
  {
    "text": "thank you",
    "start": "1180799",
    "end": "1184039"
  }
]
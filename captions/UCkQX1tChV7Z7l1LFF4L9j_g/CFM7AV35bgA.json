[
  {
    "text": "ready to get started with AI in the latest Technologies Microsoft reactor provides events training and Community",
    "start": "960",
    "end": "6440"
  },
  {
    "text": "Resources to help developers entrepreneurs and startups build on AI technology learn more by visiting",
    "start": "6440",
    "end": "12639"
  },
  {
    "text": "aka.ms infoq",
    "start": "12639",
    "end": "16920"
  },
  {
    "text": "reactor hi everyone my name is shrini picala I am the lead editor for AI ML",
    "start": "18720",
    "end": "24480"
  },
  {
    "text": "and data engineering community at infoq website and I also a podcast host thank",
    "start": "24480",
    "end": "30240"
  },
  {
    "text": "you for tuning into the podcast in today's episode I will be speaking with nami obst Nami is the founder of AI",
    "start": "30240",
    "end": "37079"
  },
  {
    "text": "blocks the company behind the open- source llm framework called llm Weare",
    "start": "37079",
    "end": "42399"
  },
  {
    "text": "that is used for Gen AI based applications in financial services and legal Industries we will discuss the",
    "start": "42399",
    "end": "49199"
  },
  {
    "text": "topics of current state of language models in the Gen adoption and more importantly the recent emergence of",
    "start": "49199",
    "end": "56079"
  },
  {
    "text": "small language models or also called slms how these new type of language",
    "start": "56079",
    "end": "61160"
  },
  {
    "text": "models compare with the large language models that we have been familiar with for last few years and more importantly",
    "start": "61160",
    "end": "67520"
  },
  {
    "text": "how this smaller models are enabling mobile devices and Edge Computing servers in leveraging gen solutions that",
    "start": "67520",
    "end": "75600"
  },
  {
    "text": "have been limited to large language models until now hi Nami thank you for joining me today can you introduce",
    "start": "75600",
    "end": "81439"
  },
  {
    "text": "yourself and tell our listeners about your career and what areas have you been",
    "start": "81439",
    "end": "86479"
  },
  {
    "text": "focusing on recently hi shy thank you so much for having me on it's such a pleasure to be here I'm Nami Oberst I'm",
    "start": "86479",
    "end": "93159"
  },
  {
    "text": "the co-founder of AI blogs and as Shi mentioned we are the folks behind L",
    "start": "93159",
    "end": "98240"
  },
  {
    "text": "mware we are an open- source project and our mission is really to make generative AI easy to use Easy to deploy and easy",
    "start": "98240",
    "end": "107040"
  },
  {
    "text": "to really develop and that's all for the Enterprise and for regulated Industries",
    "start": "107040",
    "end": "113719"
  },
  {
    "text": "and we really emphasize development and deployment securely safely and cost",
    "start": "113719",
    "end": "118920"
  },
  {
    "text": "effectively and we've been focused on using small language models we're really one of the pioneers of doing that we",
    "start": "118920",
    "end": "125360"
  },
  {
    "text": "started 20 months ago we launched an open source about a year ago but we really started our work to prepare for",
    "start": "125360",
    "end": "132200"
  },
  {
    "text": "launching really well before that and a little bit about my background I think will be helpful in why and how we came",
    "start": "132200",
    "end": "139239"
  },
  {
    "text": "to focus on small language models so I started actually as a corporate attorney working at Big law and in working in big",
    "start": "139239",
    "end": "147280"
  },
  {
    "text": "law I had a lot of repetitive tasks really boring mundane tasks that I mean",
    "start": "147280",
    "end": "152519"
  },
  {
    "text": "to be honest like Soul crushing like I loved working in my big Law Firm for the camaraderie for the colleagues and I",
    "start": "152519",
    "end": "159440"
  },
  {
    "text": "loved you know the perks of all that but I mean honestly there were so many repetitive tasks that I was doing and",
    "start": "159440",
    "end": "166599"
  },
  {
    "text": "that was almost the motivation behind starting an AI company thinking there are so many you know for knowledge",
    "start": "166599",
    "end": "172640"
  },
  {
    "text": "worker so many repetitive tasks that could be automated why aren't we doing that so that's really the impetus in the",
    "start": "172640",
    "end": "178800"
  },
  {
    "text": "aha moment but then the second aha moment was because I was working with a lot of Highly regulated Industries and",
    "start": "178800",
    "end": "184720"
  },
  {
    "text": "large corporate clients I also knew that you know the Chad GPT way of sending out",
    "start": "184720",
    "end": "190680"
  },
  {
    "text": "all this potentially sensitive data out was not going to fly to a lot of Enterprise customers like you know I",
    "start": "190680",
    "end": "196480"
  },
  {
    "text": "know how lawyers think because I am a lawyer so I thought there is just no way that this is going to be sustainable for",
    "start": "196480",
    "end": "202640"
  },
  {
    "text": "the long term so we really looked at small language models from the beginning and how small language models could do",
    "start": "202640",
    "end": "209120"
  },
  {
    "text": "very focused and targeted tasks like let's say contract analysis as an example right like could I have small",
    "start": "209120",
    "end": "216159"
  },
  {
    "text": "language models like review you know 200 documents and tell me are these contracts assignable or what is the",
    "start": "216159",
    "end": "222280"
  },
  {
    "text": "state of jurisdiction or you know give me some concrete facts and do a lot of information retrieval and we found lo",
    "start": "222280",
    "end": "229280"
  },
  {
    "text": "and behold they could and even 20 months ago we thought we were finding that they could in some ways more reliably and",
    "start": "229280",
    "end": "236360"
  },
  {
    "text": "predictably than our open AI calls because open AI had so many outages and we were like if you ping it like a 100",
    "start": "236360",
    "end": "243280"
  },
  {
    "text": "times we were getting no responses back for like you know 30 to 20% of the time",
    "start": "243280",
    "end": "248400"
  },
  {
    "text": "at that time open AI also had significant issues with accuracy as well so we were looking at it thinking wow",
    "start": "248400",
    "end": "254799"
  },
  {
    "text": "like this model that you can run actually locally can actually produce very comparable results if you have a",
    "start": "254799",
    "end": "261840"
  },
  {
    "text": "very specific use case in mind so that's how we really kind of started down this path and so not surprisingly when we",
    "start": "261840",
    "end": "268759"
  },
  {
    "text": "launched an open one of the first things we also did is uh release a whole bunch of uh rag fine-tune models I think we're",
    "start": "268759",
    "end": "275479"
  },
  {
    "text": "the first to even do that as well and our first rag fine tunes are called dragon and they're like seven billion um",
    "start": "275479",
    "end": "283120"
  },
  {
    "text": "parameter models that are specifically trained to not hallucinate to really only answer the facts and with quality",
    "start": "283120",
    "end": "289639"
  },
  {
    "text": "scores because the idea is we wanted the users to have the kind of accuracy that",
    "start": "289639",
    "end": "295400"
  },
  {
    "text": "you could get from basically a corporate lawyer like if you had another lawyer or very intelligent colleague working",
    "start": "295400",
    "end": "301080"
  },
  {
    "text": "alongside you like a coworker so that was kind of the idea behind using small language models and then since then we'",
    "start": "301080",
    "end": "307880"
  },
  {
    "text": "really evolved to then smaller rag Vine tunes and then most recently are very",
    "start": "307880",
    "end": "314280"
  },
  {
    "text": "small function calling models that are one to three billion parameters that can",
    "start": "314280",
    "end": "319360"
  },
  {
    "text": "really kind of step in and help you automate a lot of your workflows and processes and that's a very interesting",
    "start": "319360",
    "end": "325639"
  },
  {
    "text": "space that we're getting a lot of usage on and I think a lot of our community members really like that as well thanks",
    "start": "325639",
    "end": "332039"
  },
  {
    "text": "Nami I think this is probably the first time I think we have a guest to know who is not only passionate about the",
    "start": "332039",
    "end": "337280"
  },
  {
    "text": "Innovation side of the AI space but also has the attorney background to kind of",
    "start": "337280",
    "end": "342680"
  },
  {
    "text": "comment on op about from the legation and compliance side right so it's a great combination because we need both",
    "start": "342680",
    "end": "348080"
  },
  {
    "text": "of them right so I definitely want to talk more about the small language models I'm very excited about this because like any other innovation in",
    "start": "348080",
    "end": "354360"
  },
  {
    "text": "other technology spaces I think the small language models have a lot of potential to make a big impact in the",
    "start": "354360",
    "end": "360039"
  },
  {
    "text": "overall adoption of these Solutions but before we get into the main discussion let me set some context for this",
    "start": "360039",
    "end": "366160"
  },
  {
    "text": "discussion with a quick background on small language models so as we all know large language models or llms have been",
    "start": "366160",
    "end": "373240"
  },
  {
    "text": "one of the major Innovations in a and ml space for the last few years since GPT",
    "start": "373240",
    "end": "378919"
  },
  {
    "text": "and chart GPT were released and they kind of took the software World by storm right by introducing the power of",
    "start": "378919",
    "end": "385800"
  },
  {
    "text": "generative AI Technologies compared to the traditional predictive AI that we've been doing for a long time",
    "start": "385800",
    "end": "392160"
  },
  {
    "text": "now we have we seeing it being used in so many different use cases and also we have witnessed llms are being dominant",
    "start": "392160",
    "end": "397880"
  },
  {
    "text": "used in various business and Technical use cases to create exciting new opportunities that we have never even thought about before not only for the",
    "start": "397880",
    "end": "404680"
  },
  {
    "text": "end users but also for software Engineers the devops engineers and other groups to be more productive so they",
    "start": "404680",
    "end": "411080"
  },
  {
    "text": "have empowered you know pretty much the full life cycle of of the process so llms are powerful but they do come with",
    "start": "411080",
    "end": "417560"
  },
  {
    "text": "some challenges right so mainly they require the significant Computing resources to operate you know you cannot",
    "start": "417560",
    "end": "423800"
  },
  {
    "text": "just run it on a small machine or a small cluster of machines that's why only the big tech companies are able to",
    "start": "423800",
    "end": "429199"
  },
  {
    "text": "fully leverage these Technologies and also there's a privacy Factor also you have to send the data to the cloud to",
    "start": "429199",
    "end": "436039"
  },
  {
    "text": "leverage these llms and sending the data may not be possible or allowed you know for most of the use cases in companies",
    "start": "436039",
    "end": "442919"
  },
  {
    "text": "so that's where these llms are not the best choice the latest Trend in the language model Evolution or the small",
    "start": "442919",
    "end": "449039"
  },
  {
    "text": "language model models or slms that offer many of the same benefits at llms but",
    "start": "449039",
    "end": "454160"
  },
  {
    "text": "they are smaller in size they are trained using smaller data sets and they don't require a lot of computing",
    "start": "454160",
    "end": "459879"
  },
  {
    "text": "resources again these models are obviously not for every use case out there I mean they're not one size fits",
    "start": "459879",
    "end": "466120"
  },
  {
    "text": "all solution right so but they are very valuable for some use cases where you have a constraint on the resources or",
    "start": "466120",
    "end": "473039"
  },
  {
    "text": "you want to localize the model execution they're going to be of great help and",
    "start": "473039",
    "end": "478120"
  },
  {
    "text": "then I think they also are opening up a lot of new opportunities to run the slms on smartphones and other mobile devices",
    "start": "478120",
    "end": "485199"
  },
  {
    "text": "that are used for Edge Computing and they are not always connected to the cloud so this detached model of language",
    "start": "485199",
    "end": "492080"
  },
  {
    "text": "model execution is definitely Paving the way to use slms in these different applications so they keep the data",
    "start": "492080",
    "end": "497759"
  },
  {
    "text": "within the device and are great candidates for use cases where privacy or latency or other concerns in sending",
    "start": "497759",
    "end": "504879"
  },
  {
    "text": "the data to the cloud so can you talk about how slms have come about I know you've been f on this for some time and",
    "start": "504879",
    "end": "511000"
  },
  {
    "text": "what are the pros and cons you know if anybody in our audience you know that are new to slms so how do these small",
    "start": "511000",
    "end": "516800"
  },
  {
    "text": "models compared to the large models and what are the pros and what are the cons of the small models so first just to",
    "start": "516800",
    "end": "523560"
  },
  {
    "text": "start let's define what like constitutes a small language model and the reason why I bring that up is because my own",
    "start": "523560",
    "end": "530519"
  },
  {
    "text": "definition has changed so if you asked me three months ago what is a small language model I had",
    "start": "530519",
    "end": "538079"
  },
  {
    "text": "literally a slide that I presented at an AI conference in London where I said and I've been saying that for a few months a",
    "start": "538079",
    "end": "544760"
  },
  {
    "text": "small language model is a model that's generally lower than you know seven to eight billion parameters because",
    "start": "544760",
    "end": "550320"
  },
  {
    "text": "quantise you can run that on a local machine but then I had you know as one of the bullet points but this definition",
    "start": "550320",
    "end": "556440"
  },
  {
    "text": "is subject to change when the models get better and also when the hardware gets",
    "start": "556440",
    "end": "561519"
  },
  {
    "text": "better and so lo and behold I'm going to have to change that definition now because using and we're going to get to",
    "start": "561519",
    "end": "567600"
  },
  {
    "text": "this but using the latest AI PCS that's out there in the market today we are",
    "start": "567600",
    "end": "573000"
  },
  {
    "text": "currently running experiments where we are able to run you know up to 14 billion parameters that's like the",
    "start": "573000",
    "end": "579279"
  },
  {
    "text": "latest that I've been experimenting with just as easily on an Intel based aipc as",
    "start": "579279",
    "end": "586040"
  },
  {
    "text": "I can like a 7 billion parameter a model on the Mac quantized all of course like",
    "start": "586040",
    "end": "591839"
  },
  {
    "text": "but that would be quantized like ggf versus quantized open voo for the Intel so that size is changing so that's",
    "start": "591839",
    "end": "598880"
  },
  {
    "text": "actually really really interesting and exciting and then that is coupled with the fact that the models themselves the",
    "start": "598880",
    "end": "604959"
  },
  {
    "text": "small language models are getting actually really really good they're getting better by the week practically",
    "start": "604959",
    "end": "610200"
  },
  {
    "text": "and that is what's making all this Innovation possible so between the small language models getting really good and",
    "start": "610200",
    "end": "616440"
  },
  {
    "text": "then the fact that they are now being able to run on literally just a commodity laptop that are out that will",
    "start": "616440",
    "end": "624000"
  },
  {
    "text": "be I don't know what the MSRP is but one of the earlier versions of the Intel",
    "start": "624000",
    "end": "629440"
  },
  {
    "text": "laptops we purchased for like $1,100 from Dell this summer and then I think the lunar legs are just coming out so I",
    "start": "629440",
    "end": "636480"
  },
  {
    "text": "haven't purchased one like for myself yet literally but we have a test machine that we've been able to use so it's",
    "start": "636480",
    "end": "642800"
  },
  {
    "text": "really exciting to see the small language models getting exceptionally good and then the hardware on the edge",
    "start": "642800",
    "end": "649279"
  },
  {
    "text": "device side getting exceptionally good so that you know the definition of small language model is changing and then if",
    "start": "649279",
    "end": "655320"
  },
  {
    "text": "you kind of add to that mix like the innovation in the way way that we're able to train these small language",
    "start": "655320",
    "end": "661959"
  },
  {
    "text": "models so since you mentioned like smart phones I'll talk about you know the Apple intelligence that's coming out at",
    "start": "661959",
    "end": "668519"
  },
  {
    "text": "the end of this month Apple intelligence it's a three billion parameter model that's going to be I think on device and",
    "start": "668519",
    "end": "675160"
  },
  {
    "text": "then if it's larger they're going to access it on the cloud but that is made possible by pruning a 6.4 billion",
    "start": "675160",
    "end": "682720"
  },
  {
    "text": "parameter model so like they took a larger model and they pruned it which means they basically took away some the",
    "start": "682720",
    "end": "689519"
  },
  {
    "text": "parts that they didn't think that they needed and then they turned it into a three billion parameter on device",
    "start": "689519",
    "end": "694800"
  },
  {
    "text": "version and then between pruning and then coupling that with distillation techniques and did both pruning and",
    "start": "694800",
    "end": "701880"
  },
  {
    "text": "distillation to come up with their minitron like in July or August it's really exciting like so there's so many",
    "start": "701880",
    "end": "707839"
  },
  {
    "text": "Innovations around small language models that are happening that I'm not even sure that you can say that necessarily",
    "start": "707839",
    "end": "714680"
  },
  {
    "text": "that large language models per se are better because I would have to say tell me what the use case is and tell me what",
    "start": "714680",
    "end": "720639"
  },
  {
    "text": "the task is right so actually for a given task I actually would have to say",
    "start": "720639",
    "end": "726639"
  },
  {
    "text": "like I'm not sure like I am honestly not sure given the fact that they're so",
    "start": "726639",
    "end": "732000"
  },
  {
    "text": "efficient and you can train them to be so specific to your use case I actually think that there's arguments to be had",
    "start": "732000",
    "end": "738760"
  },
  {
    "text": "on both sides that's a great Point yeah use the right size model for the right problem right so also like you mentioned",
    "start": "738760",
    "end": "745399"
  },
  {
    "text": "by leveraging these small models with the company's proprietary data which is kind of more specific to their domain",
    "start": "745399",
    "end": "752040"
  },
  {
    "text": "the accuracy has to be comparable with the know large model right so that's right so I mean you know in the Nvidia",
    "start": "752040",
    "end": "760120"
  },
  {
    "text": "study that they released in July they were able to basically use 40 times fewer training tokens to come up with",
    "start": "760120",
    "end": "766920"
  },
  {
    "text": "their minitron that's like less than I think they said less than you know 3% of like what it would take to train even",
    "start": "766920",
    "end": "773720"
  },
  {
    "text": "from scratch like a small language model if you keep like taking that that concept and you keep applying it like",
    "start": "773720",
    "end": "780440"
  },
  {
    "text": "distillation plus pruning and that resulted in a model that was 16% better",
    "start": "780440",
    "end": "785480"
  },
  {
    "text": "apparently than a model the same siiz train from scratch so you take all these Innovations and then you keep",
    "start": "785480",
    "end": "791279"
  },
  {
    "text": "fine-tuning it with your own data and then combined with the fact that you can run this on a laptop and not a special",
    "start": "791279",
    "end": "797720"
  },
  {
    "text": "laptop just a laptop like an aipc you know coming soon to you know a desktop",
    "start": "797720",
    "end": "802839"
  },
  {
    "text": "near you like I mean I think it's like really exciting and you now no longer need a GPU Farm you don't need it you",
    "start": "802839",
    "end": "810000"
  },
  {
    "text": "know to go spend millions and millions of dollars on separate GPU clusters I",
    "start": "810000",
    "end": "815279"
  },
  {
    "text": "think that's really exciting that's truly democratizing Ai and use cases so I'm really excited about that and I",
    "start": "815279",
    "end": "822000"
  },
  {
    "text": "think that's going to be just revolutionary and it's going to blow open the AI use cases that we have",
    "start": "822000",
    "end": "828240"
  },
  {
    "text": "available today and kind of like I guess you know one of the things that you and I wanted to talk about were like possibilities right like what is",
    "start": "828240",
    "end": "835160"
  },
  {
    "text": "possible now if everybody has access to these AI models on their laptop like",
    "start": "835160",
    "end": "841759"
  },
  {
    "text": "what is possible compared to before and I think before some of the trough of",
    "start": "841759",
    "end": "847720"
  },
  {
    "text": "disillusionment or you know the winter of discontent around AI is because we were really thinking about these use",
    "start": "847720",
    "end": "854000"
  },
  {
    "text": "cases with a capital a capital I like the killer use case right and I think",
    "start": "854000",
    "end": "859519"
  },
  {
    "text": "that you know going back to my story about why I was motivated to start AI blogs and llm whereare it was like in",
    "start": "859519",
    "end": "865959"
  },
  {
    "text": "these micro day-to-day tasks like I just needed help like I want something to do these like help me with these day-to-day",
    "start": "865959",
    "end": "871759"
  },
  {
    "text": "tasks that would save me you know a couple of hours a day or an hour a day and maybe I wouldn't even use it every",
    "start": "871759",
    "end": "877279"
  },
  {
    "text": "day but it'd be so amazing to to have that tool right a tool that I can use to",
    "start": "877279",
    "end": "882880"
  },
  {
    "text": "very easily query my documents chat with it and not have to worry about data",
    "start": "882880",
    "end": "888079"
  },
  {
    "text": "privacy you know not have to worry about data leakage data copies because like that is every Enterprise is Nightmare",
    "start": "888079",
    "end": "894519"
  },
  {
    "text": "obviously you don't want data copies like sitting around everywhere but you know how are are your workers working",
    "start": "894519",
    "end": "900120"
  },
  {
    "text": "they're already working on the laptop everybody's distributed so you know everybody like has access to laptops so",
    "start": "900120",
    "end": "907240"
  },
  {
    "text": "if you can like really bring AI to where they are at their fingertips I think that blows open a whole bunch of use",
    "start": "907240",
    "end": "913600"
  },
  {
    "text": "cases and truly fulfills the promise of AI which is like worker productivity",
    "start": "913600",
    "end": "918759"
  },
  {
    "text": "right makes sense yeah actually I have recently tried AMA with the F3 Microsoft",
    "start": "918759",
    "end": "923839"
  },
  {
    "text": "V3 model and I can definitely see the difference it was obviously a lot faster than downloading a large model and run",
    "start": "923839",
    "end": "930120"
  },
  {
    "text": "it locally right so so definitely I have not tried with different use cases but I I could see the performance difference and this was on my laptop which is by no",
    "start": "930120",
    "end": "937120"
  },
  {
    "text": "means you know the fastest in the world right so so you mentioned about these new models are going to democratize the",
    "start": "937120",
    "end": "943360"
  },
  {
    "text": "use cases can we talk a little bit more about those use cases like what specific use cases you are seeing where small",
    "start": "943360",
    "end": "949360"
  },
  {
    "text": "language models are being preferred to other Alternatives so like just to start",
    "start": "949360",
    "end": "954440"
  },
  {
    "text": "let's just start with the basic the most basic use case like you know just things like finding information in your",
    "start": "954440",
    "end": "960800"
  },
  {
    "text": "documents you know you have an 80 page contract you need to look through who wants to look through an 80 page",
    "start": "960800",
    "end": "966160"
  },
  {
    "text": "contract and you just want to find one or two pieces of information you know if you needed to look through it it's probably on your laptop somewhere you",
    "start": "966160",
    "end": "972959"
  },
  {
    "text": "have access to it you just upload it into your own laptop like just literally just upload the file into the model",
    "start": "972959",
    "end": "979279"
  },
  {
    "text": "which is all running locally so no you could even run that air gap you don't even need access to Wi-Fi because you",
    "start": "979279",
    "end": "984839"
  },
  {
    "text": "you're literally taking the model like it's the models on your device you could could start to query it you know just",
    "start": "984839",
    "end": "990800"
  },
  {
    "text": "ask it questions you could do summarizations and then you could do SQL queries like if you have a large complex",
    "start": "990800",
    "end": "997680"
  },
  {
    "text": "spreadsheet like that's never any fun to query those like SQL queries and so all",
    "start": "997680",
    "end": "1003319"
  },
  {
    "text": "these kind of what I call microtasks but that's a part of everybody's day-to-day like working life I think could all be",
    "start": "1003319",
    "end": "1010279"
  },
  {
    "text": "automated a voice recording you can have that transcribed and then you know a meeting and then you could literally just start to query that summarize that",
    "start": "1010279",
    "end": "1018319"
  },
  {
    "text": "you know have it rewrite things for you but now you no longer actually have to worry about any data privacy issues so",
    "start": "1018319",
    "end": "1025438"
  },
  {
    "text": "if you were to do that exactly like take a contract let's say you're an HR you have an employment contract and you just",
    "start": "1025439",
    "end": "1030918"
  },
  {
    "text": "want to look up some information how many you know holidays did we promise this employee as an example you could",
    "start": "1030919",
    "end": "1036319"
  },
  {
    "text": "never or I don't think that you should every company's policy is different but I don't think you should be taking that",
    "start": "1036319",
    "end": "1041880"
  },
  {
    "text": "agreement and uploading it to Some Cloud you know that your company has not authorized but now if that model is",
    "start": "1041880",
    "end": "1047640"
  },
  {
    "text": "sitting in your laptop it's literally just secure and it's not going anywhere there are no data copies just an example",
    "start": "1047640",
    "end": "1053760"
  },
  {
    "text": "but that's a very basic use case and then what we're more seeing now is that with the agent workflow you can easily",
    "start": "1053760",
    "end": "1060120"
  },
  {
    "text": "create like a very simple workflow to automate so one of the examples that we have is let's say you're a financial",
    "start": "1060120",
    "end": "1066720"
  },
  {
    "text": "analyst and you have an article that you're looking at and you just want to get you know like produce a whole range",
    "start": "1066720",
    "end": "1072240"
  },
  {
    "text": "of reports like get a background description on the company you want the latest stock price you want it",
    "start": "1072240",
    "end": "1077400"
  },
  {
    "text": "historical stock price you could even have it do like an API call to a Yahoo finance as an example if you want to do",
    "start": "1077400",
    "end": "1083840"
  },
  {
    "text": "that you can have it look up information Wikipedia as an example or other apis that your company allows you can do that",
    "start": "1083840",
    "end": "1090640"
  },
  {
    "text": "just have it like really just grab that information and put all that into a report for you and it just gets you",
    "start": "1090640",
    "end": "1095760"
  },
  {
    "text": "started so it's really supposed to be like a co-pilot for your everyday working life and I think that is the",
    "start": "1095760",
    "end": "1102360"
  },
  {
    "text": "promise of AI so capital a capital I but like you know not this big Behemoth use",
    "start": "1102360",
    "end": "1108280"
  },
  {
    "text": "case I know has access to that only it does and you know you can't also have 10,000 employees bombarding it with",
    "start": "1108280",
    "end": "1115159"
  },
  {
    "text": "their individual use cases right like that's just not going to fly so we want to really bring it to the user on their",
    "start": "1115159",
    "end": "1121720"
  },
  {
    "text": "device definitely also I I see the rag which is kind of one of the interesting outcomes of this right know so where you",
    "start": "1121720",
    "end": "1128679"
  },
  {
    "text": "have the a base model which can be a large model or small model and then you basically train the model with your",
    "start": "1128679",
    "end": "1134880"
  },
  {
    "text": "company's private information and then you can use the model to ask question questions that are specific to your",
    "start": "1134880",
    "end": "1140480"
  },
  {
    "text": "business domain so do you see small models and the rag are a better fit and",
    "start": "1140480",
    "end": "1145720"
  },
  {
    "text": "made for each other because you can start small and then enrich the model with your own business domain data and",
    "start": "1145720",
    "end": "1150799"
  },
  {
    "text": "then now you can use it in a like you said on a commodity hardware and make it available for everybody in the company",
    "start": "1150799",
    "end": "1156440"
  },
  {
    "text": "oh yeah no absolutely so with rag because of the loss in the- Middle problem anyway like large models are not",
    "start": "1156440",
    "end": "1163240"
  },
  {
    "text": "necessarily better at all for um Rag and I think you know we were on a podcast earlier where we talked about that and I",
    "start": "1163240",
    "end": "1169840"
  },
  {
    "text": "believe even Mandy go had a personal experience with that and it's just many many Studies have shown that so it's not",
    "start": "1169840",
    "end": "1175320"
  },
  {
    "text": "like you know large language models are designed for complex Rag and so the key",
    "start": "1175320",
    "end": "1180559"
  },
  {
    "text": "to successful rag deployment is just in the workflow just making sure that you know from document ingestion to all the",
    "start": "1180559",
    "end": "1187200"
  },
  {
    "text": "way to inferencing that that chain is handled accurately so yes no absolutely",
    "start": "1187200",
    "end": "1192840"
  },
  {
    "text": "but then if you combine with that like let's say A specialized embedding model that really understands your domain just",
    "start": "1192840",
    "end": "1198799"
  },
  {
    "text": "an example some in the middle of that or if you don't do something as complex as that that would be like for a much",
    "start": "1198799",
    "end": "1204400"
  },
  {
    "text": "larger application but like on device you can really just upload the document start quering it and with very very fast",
    "start": "1204400",
    "end": "1212480"
  },
  {
    "text": "inference speed and it's you know especially with the new AI PCS that have the integrated GPU the performance",
    "start": "1212480",
    "end": "1219480"
  },
  {
    "text": "difference even compared to what we're previously seeing on the Mac M3 is",
    "start": "1219480",
    "end": "1224840"
  },
  {
    "text": "astounding and you know who knows what'll happen when Apple comes out with their new chips for sure like I haven't",
    "start": "1224840",
    "end": "1230080"
  },
  {
    "text": "seen that so I can't say but for now even on the older Intel chipped which is",
    "start": "1230080",
    "end": "1235440"
  },
  {
    "text": "the meteor leag I can tell you that the difference between running pytorch version of a model versus the open V GPU",
    "start": "1235440",
    "end": "1243880"
  },
  {
    "text": "is like5 seconds to 15 seconds difference for like a 21 question inference test",
    "start": "1243880",
    "end": "1249320"
  },
  {
    "text": "for 1.1 billion parameter model so you can get like subsecond response times if",
    "start": "1249320",
    "end": "1254600"
  },
  {
    "text": "you're matching the right inferencing technique with the right Hardware so so there's so much going on in this space",
    "start": "1254600",
    "end": "1261640"
  },
  {
    "text": "but the net of that is really AI is coming to you it's coming to you at your",
    "start": "1261640",
    "end": "1267080"
  },
  {
    "text": "fingertips so that's super exciting yeah I think that's the best way to explain right to bring the AI to the people who",
    "start": "1267080",
    "end": "1273159"
  },
  {
    "text": "can get a lot of value out of that instead of sending the data to the cloud right also quickly you mentioned about the previous podcast that is the AIML",
    "start": "1273159",
    "end": "1280799"
  },
  {
    "text": "and data engineering Trends report that we recorded back in August so I'll make sure that we link to that as part of",
    "start": "1280799",
    "end": "1287039"
  },
  {
    "text": "this podcast and so our list can reference that as well and learn more about it and then regarding the use",
    "start": "1287039",
    "end": "1292720"
  },
  {
    "text": "cases right just continue that use cases discussion you mentioned about also with your attorney background how do you see",
    "start": "1292720",
    "end": "1298600"
  },
  {
    "text": "these small models especially on the PCS being used in applications like auditing or compliance you know so how can you",
    "start": "1298600",
    "end": "1305080"
  },
  {
    "text": "make it more built in and enable those use cases to be more proactive so compliance by Design right regulations",
    "start": "1305080",
    "end": "1311919"
  },
  {
    "text": "by Design rather than by accident how do you see that so maybe because of my",
    "start": "1311919",
    "end": "1316960"
  },
  {
    "text": "background what we built into what we are doing for our commercial application but I actually think that this has to be",
    "start": "1316960",
    "end": "1323840"
  },
  {
    "text": "in everything that we do in terms of AI our features related to compliance and auditability AI explainability not to",
    "start": "1323840",
    "end": "1331360"
  },
  {
    "text": "mention guard rails of course like pii guard rails but with respect to I'll",
    "start": "1331360",
    "end": "1336640"
  },
  {
    "text": "just start with AI explainability and this is where I think small language models shine and we are working with a",
    "start": "1336640",
    "end": "1343120"
  },
  {
    "text": "use case in a large bank and the part that they actually found very interesting that they really liked about",
    "start": "1343120",
    "end": "1349240"
  },
  {
    "text": "this the way to do this with small language models is that if you're chaining a workflow create designing an",
    "start": "1349240",
    "end": "1354320"
  },
  {
    "text": "automation with not prompts but small slms function calling slms that are",
    "start": "1354320",
    "end": "1361320"
  },
  {
    "text": "basically outputting python dictionary so you can have you know let's just say you ask it a question and if it's yes or",
    "start": "1361320",
    "end": "1367880"
  },
  {
    "text": "no then like creating decision trees based on the model inferences and the answers in that case because like you",
    "start": "1367880",
    "end": "1374919"
  },
  {
    "text": "have visibility to every single step because like oh the model here at this point said yes or no let's just say you",
    "start": "1374919",
    "end": "1381559"
  },
  {
    "text": "know is this like a gold high level customer yes or no and you could kind of look at the logic and if somehow there",
    "start": "1381559",
    "end": "1387440"
  },
  {
    "text": "is any fault in the decision tree then you can kind of see where exactly that fault is as an example and you can",
    "start": "1387440",
    "end": "1393880"
  },
  {
    "text": "course correct right you can see where the mistakes are being made because you really crystallizing the rationale",
    "start": "1393880",
    "end": "1400320"
  },
  {
    "text": "behind how you are designing your workflow very much almost like coding or software engineering right whereas if",
    "start": "1400320",
    "end": "1407400"
  },
  {
    "text": "you have like a really large large language model that you're using with a lot of prompt engineering this is not to",
    "start": "1407400",
    "end": "1413279"
  },
  {
    "text": "knock prompt engineering I'm just kind of explaining the difference you actually can't tell like where if you",
    "start": "1413279",
    "end": "1418600"
  },
  {
    "text": "have an outcome that you're not happy with where in that process did it fall apart for instance like where did the",
    "start": "1418600",
    "end": "1425960"
  },
  {
    "text": "model like make the wrong inference that led to this outcome that you're not happy with so you don't have visibility",
    "start": "1425960",
    "end": "1431440"
  },
  {
    "text": "to that so I think that's one of the big differences too from an Enterprise perspective is if you can have",
    "start": "1431440",
    "end": "1438480"
  },
  {
    "text": "visibility to every single step of you know the AI explainability is you can see actually we can expose like what are",
    "start": "1438480",
    "end": "1444559"
  },
  {
    "text": "the options that the model was considering when it gave you that answer and what is the option that it ended up",
    "start": "1444559",
    "end": "1450120"
  },
  {
    "text": "choosing and so you can see that at every single step of the process that is truly I think um so critical to",
    "start": "1450120",
    "end": "1457400"
  },
  {
    "text": "especially when you're trying to deploy new processes for everyone to understand like what is this model doing at every",
    "start": "1457400",
    "end": "1463840"
  },
  {
    "text": "step and where is it making the right or the wrong decisions because I mean I think that there are very very few",
    "start": "1463840",
    "end": "1469240"
  },
  {
    "text": "instances where something's going to get it like right 100% of the time like right out of the box right so we're just trying to do this in a very systematic",
    "start": "1469240",
    "end": "1476399"
  },
  {
    "text": "observable way so I think that observability factor explainability factor is really critical and then",
    "start": "1476399",
    "end": "1482720"
  },
  {
    "text": "because you have so much data and so much information every single interaction all of that is being",
    "start": "1482720",
    "end": "1487919"
  },
  {
    "text": "captured right so every single inference is captured every single decision is being captured so for auditability",
    "start": "1487919",
    "end": "1495240"
  },
  {
    "text": "purposes for compliance purposes you have you know all the data you could possibly need for every kind of question",
    "start": "1495240",
    "end": "1503000"
  },
  {
    "text": "your Auditors or compliance officer might have so I think you know fore an Enterprise the unknown like I don't know",
    "start": "1503000",
    "end": "1510480"
  },
  {
    "text": "how it got there oh GE like what are we supposed to do is like the worst answer",
    "start": "1510480",
    "end": "1517039"
  },
  {
    "text": "right and you want to be able to you know almost do a forensic report on where did it screw up and let's see why",
    "start": "1517039",
    "end": "1524000"
  },
  {
    "text": "and let's fix that part but if you don't know where it's screwed up how are you going to go fix that part",
    "start": "1524000",
    "end": "1529080"
  },
  {
    "text": "also that visibility into every single step in the process I mean that's the auditor's dream right so they want to",
    "start": "1529080",
    "end": "1534200"
  },
  {
    "text": "kind of know all those under the hood details right so that kind of helps absolutely before we jump on to the",
    "start": "1534200",
    "end": "1540720"
  },
  {
    "text": "other topics on this space let me ask you this you know like I definitely see large models you know they've been",
    "start": "1540720",
    "end": "1546000"
  },
  {
    "text": "popular for so long now small models are getting more attention for specific use cases right like you said you know even",
    "start": "1546000",
    "end": "1551559"
  },
  {
    "text": "though they are smaller in size not necessarily poor in terms of performance or accuracy so are there any use cases",
    "start": "1551559",
    "end": "1558039"
  },
  {
    "text": "where where you either see in the future where both large models and small models",
    "start": "1558039",
    "end": "1564240"
  },
  {
    "text": "in combination can be the best choice not the or but the and oh yeah no",
    "start": "1564240",
    "end": "1569559"
  },
  {
    "text": "absolutely I really do so for instance we had a very interesting conversation with an extremely extremely intelligent",
    "start": "1569559",
    "end": "1576720"
  },
  {
    "text": "gentleman he's an architect at one of the Fortune 500 companies and really really a brilliant and you know we asked",
    "start": "1576720",
    "end": "1583159"
  },
  {
    "text": "him like where would you use because he's very Leading Edge and you know has really experimented with small language",
    "start": "1583159",
    "end": "1588559"
  },
  {
    "text": "models as well so we asked him you know from your perspective where would you use a large like a really large language",
    "start": "1588559",
    "end": "1594440"
  },
  {
    "text": "model like an open Ai and he said you know those models are really good at just preserving the context of these",
    "start": "1594440",
    "end": "1600039"
  },
  {
    "text": "conversations so for instance when you're having a conversation with a customer like the customer even if the",
    "start": "1600039",
    "end": "1605840"
  },
  {
    "text": "conversation the chat goes on for several days just as an example the customer never expects to tell you the",
    "start": "1605840",
    "end": "1610880"
  },
  {
    "text": "same information twice like that's just a noo so those large language models are great for capturing those conversations",
    "start": "1610880",
    "end": "1617039"
  },
  {
    "text": "and just kind of keeping that context over days over long sessions and I think that's totally right because of the",
    "start": "1617039",
    "end": "1622720"
  },
  {
    "text": "large context window this is where you know it could preserve the context and keep having that conversation so for",
    "start": "1622720",
    "end": "1629240"
  },
  {
    "text": "these you know very important customer facing chat Bots that can go on",
    "start": "1629240",
    "end": "1634399"
  },
  {
    "text": "potentially for days and you know like be really prolonged yeah no I definitely could see that use case but now you know",
    "start": "1634399",
    "end": "1641240"
  },
  {
    "text": "let's say you want to capture that information that absolute that conversation when that conversation is done and you want to drive a lot of you",
    "start": "1641240",
    "end": "1648440"
  },
  {
    "text": "know insights and analytics off of that and those insights and analytics don't have to happen in real time right so",
    "start": "1648440",
    "end": "1654760"
  },
  {
    "text": "that can run in batch processes overnight on very inexpensive Hardware so in basically you can take that same",
    "start": "1654760",
    "end": "1661600"
  },
  {
    "text": "chat and you can basically send that off to a new workflow that doesn't need all",
    "start": "1661600",
    "end": "1666799"
  },
  {
    "text": "that capability and I think any processes that can kind of run in the background that's like you know running",
    "start": "1666799",
    "end": "1672720"
  },
  {
    "text": "hourly daily you know and a lot of Enterprises have processes that run weekly monthly all of those things",
    "start": "1672720",
    "end": "1679159"
  },
  {
    "text": "actually can I think very soon be run with small language models chaining a whole bunch of them together you know on",
    "start": "1679159",
    "end": "1685240"
  },
  {
    "text": "CPUs I definitely I think you explained it very well you so the small language models going back to the popular use",
    "start": "1685240",
    "end": "1691200"
  },
  {
    "text": "cases or patterns in machine learning usually we do some Edge on device analytics real time for either finding",
    "start": "1691200",
    "end": "1698440"
  },
  {
    "text": "any defects or any other other use cases in the manufacturing processes and then",
    "start": "1698440",
    "end": "1703760"
  },
  {
    "text": "send results to the cloud you know so there can be offline analytics to further generate more insights to use",
    "start": "1703760",
    "end": "1710039"
  },
  {
    "text": "that anology like small language models can be really powerful on the edge in the devices you know they can do the",
    "start": "1710039",
    "end": "1715480"
  },
  {
    "text": "local modeling and generate the insights and that output can be sent to the cloud to train the large Val models which can",
    "start": "1715480",
    "end": "1722960"
  },
  {
    "text": "be more intelligent because of that and the output of the llms can be sent back to the small language models and I see",
    "start": "1722960",
    "end": "1728480"
  },
  {
    "text": "there can be a feedback loop between the localized small language models and the cloud offline large language models kind",
    "start": "1728480",
    "end": "1735519"
  },
  {
    "text": "of feeding each other and making each other better right so absolutely no absolutely I think the future especially",
    "start": "1735519",
    "end": "1741480"
  },
  {
    "text": "for large Enterprise will be a combination but you know what I think would be a wasteful at this point would",
    "start": "1741480",
    "end": "1747320"
  },
  {
    "text": "be to use a really large language model for everything that's just like you",
    "start": "1747320",
    "end": "1752440"
  },
  {
    "text": "know I think that could be Overkill and actually a tremendous waste of resources but you know not everyone actually knows",
    "start": "1752440",
    "end": "1759600"
  },
  {
    "text": "that yet so there are definitely people who will just unleash you know of these Behemoth models at everything but I",
    "start": "1759600",
    "end": "1765880"
  },
  {
    "text": "think very now many many people are coming to realize that that is an absolute Overkill and waste of resources",
    "start": "1765880",
    "end": "1771880"
  },
  {
    "text": "yeah that's a great point right for any organization especially the startups which are always constrained financially",
    "start": "1771880",
    "end": "1777200"
  },
  {
    "text": "right so large language models may not be an option for them to start with but they can use the small models kind of learn the process learn the solutions",
    "start": "1777200",
    "end": "1783679"
  },
  {
    "text": "and make sure that they are the right solution and then invest in a bigger solution right so that can be a first",
    "start": "1783679",
    "end": "1788720"
  },
  {
    "text": "step in the overall learning and adoption process for the companies yeah and then beyond that even Enterprises",
    "start": "1788720",
    "end": "1794519"
  },
  {
    "text": "are extremely cost-sensitive at least the Enterprises I speak with are extremely cens they may be more C",
    "start": "1794519",
    "end": "1801000"
  },
  {
    "text": "sensitive than startups to be honest with you yeah because they can fail big if they're not right so yeah this is",
    "start": "1801000",
    "end": "1807000"
  },
  {
    "text": "where Enterprises are always looking for a cost efficiency like I mean really and I think that's right that you know you",
    "start": "1807000",
    "end": "1813600"
  },
  {
    "text": "want to obviously not waste money and have great results for your shareholders so I fully understand that and then they",
    "start": "1813600",
    "end": "1820519"
  },
  {
    "text": "really care about security safety and cost efficiency and you know I totally understand on every single front that",
    "start": "1820519",
    "end": "1826159"
  },
  {
    "text": "you know a solution has to deliver those to be useful to an Enterprise yeah during the exploration phase of the",
    "start": "1826159",
    "end": "1831720"
  },
  {
    "text": "adoption they can try these low cost you know better performance easy to run models and then grow into the large",
    "start": "1831720",
    "end": "1837480"
  },
  {
    "text": "models right so quickly I want to kind of talk about the Practical side of this discussion right so I know most of our",
    "start": "1837480",
    "end": "1843200"
  },
  {
    "text": "listeners are senior technical professionals they're probably itching to you know try this out on their own",
    "start": "1843200",
    "end": "1848679"
  },
  {
    "text": "laptops so what kind of infrastructure or tools are required to adopt or or try",
    "start": "1848679",
    "end": "1854480"
  },
  {
    "text": "or explore small language models in in applications like how can our listeners who are interested in trying out small",
    "start": "1854480",
    "end": "1860720"
  },
  {
    "text": "language models on their own laptops how can they get started what do you see as the open source Frameworks or other",
    "start": "1860720",
    "end": "1866039"
  },
  {
    "text": "tools to get going with this I'm going to give you a nuanced answer now because it really depends on your laptop and I",
    "start": "1866039",
    "end": "1872159"
  },
  {
    "text": "wouldn't have said this up until two months ago but I really have to emphasize this point sincerely at this point it depends on your laptop if you",
    "start": "1872159",
    "end": "1879600"
  },
  {
    "text": "are using a Mac then by all means like use the ggf quantize version and use you",
    "start": "1879600",
    "end": "1885039"
  },
  {
    "text": "know a solution like AMA however if you're are working on an intel-based machine for example then you should",
    "start": "1885039",
    "end": "1892600"
  },
  {
    "text": "really work with open Vino it's by far like it's hands down it's so the C even",
    "start": "1892600",
    "end": "1898840"
  },
  {
    "text": "if you don't have a c the GPU version just a CPU version you should really work with the open Vino Library we",
    "start": "1898840",
    "end": "1905440"
  },
  {
    "text": "support a lot of that workflow in LL mware now but you still have to download open Vino yourself to work with our",
    "start": "1905440",
    "end": "1911240"
  },
  {
    "text": "library and let's say your neither it's neither Intel and it's neither Mac then",
    "start": "1911240",
    "end": "1916760"
  },
  {
    "text": "I would really work with n NX onx which is the Microsoft version and it's like crossplatform and in my experimentation",
    "start": "1916760",
    "end": "1924440"
  },
  {
    "text": "Onyx kind of is like the middle of the road approach so for the same test on that same Dell machine if pip torch ran",
    "start": "1924440",
    "end": "1930559"
  },
  {
    "text": "at 115 seconds for 21 questions like for 1 billion parameter model on that same",
    "start": "1930559",
    "end": "1936000"
  },
  {
    "text": "Dell ggf ran at 113 seconds so basically negligible so don't bother with ggf like",
    "start": "1936000",
    "end": "1941880"
  },
  {
    "text": "don't even waste your time on an Intel based machine but Onyx ran at 65 seconds",
    "start": "1941880",
    "end": "1947440"
  },
  {
    "text": "while the open Veno Rand at 15 seconds so I see Onyx as like a really good middle-of the road approach if you have",
    "start": "1947440",
    "end": "1954159"
  },
  {
    "text": "a non Mac and non Intel based machine if you do like so far as I know ggf is the",
    "start": "1954159",
    "end": "1960880"
  },
  {
    "text": "fastest way to run inferencing on a Mac and open you know hands down on Intel",
    "start": "1960880",
    "end": "1966159"
  },
  {
    "text": "including just CPU based machines I have a four-year-old Dell machine that I",
    "start": "1966159",
    "end": "1971880"
  },
  {
    "text": "thought was basically like destined for recycling but using what we have right now that we've developed it's giving me",
    "start": "1971880",
    "end": "1978519"
  },
  {
    "text": "the same performance as an M3 in terms of inference speed it's crazy but we",
    "start": "1978519",
    "end": "1984080"
  },
  {
    "text": "didn't know that you had to match the right software to the hardware so please go check out open vot please check out",
    "start": "1984080",
    "end": "1990240"
  },
  {
    "text": "Onyx and not just stick to ggf and realize and I had somebody from Australia called me three days ago",
    "start": "1990240",
    "end": "1995840"
  },
  {
    "text": "saying why are these models running so slowly on my machine and I said let me guess you don't have a Mac and he's like",
    "start": "1995840",
    "end": "2002840"
  },
  {
    "text": "yes you're right I'm not using a Mac I was like okay now this is what you need to do so this is my public service",
    "start": "2002840",
    "end": "2008240"
  },
  {
    "text": "announcement to everybody please yeah don't throw away your old laptops right so they're still valuable",
    "start": "2008240",
    "end": "2014440"
  },
  {
    "text": "right yeah thanks for that it's easy to get going with this right so the other main area I want to focus in this podcast discussion is how these small",
    "start": "2014440",
    "end": "2021519"
  },
  {
    "text": "language models are enabling the AI powered PCS right we talked about that couple of times in this talk already so",
    "start": "2021519",
    "end": "2028080"
  },
  {
    "text": "how do you see like the small language models can operate at the edge as they say and they don't need to be connected to the cloud so how do you see this",
    "start": "2028080",
    "end": "2034960"
  },
  {
    "text": "evolution of the models enabling devic like laptop smartphones Ian they can be iot devices",
    "start": "2034960",
    "end": "2041120"
  },
  {
    "text": "right it can be even sensors in a manufacturing plant or components in the in a autonomous vehicle right I mean the",
    "start": "2041120",
    "end": "2047799"
  },
  {
    "text": "use cases are Limitless so how do you see this especially the emergence of small models accelerating the power of",
    "start": "2047799",
    "end": "2054280"
  },
  {
    "text": "AI PCS and the devices oh I mean I think it's incredible just that true democratization of you know bringing the",
    "start": "2054280",
    "end": "2061079"
  },
  {
    "text": "power of AI to your fingertips so you know I think in the earlier podcast I said you know it's my dream and my",
    "start": "2061079",
    "end": "2067079"
  },
  {
    "text": "vision that you know AI should be as ubiquitous as like just regular software and as easy to use and maybe even easier",
    "start": "2067079",
    "end": "2072200"
  },
  {
    "text": "to use and I think that's happening so we are definitely trying to make that happen so we've developed a product",
    "start": "2072200",
    "end": "2078118"
  },
  {
    "text": "called Model HQ where you know you don't need to know C++ to download open Veno you don't need to know anything you just",
    "start": "2078119",
    "end": "2084240"
  },
  {
    "text": "like literally it's an executable you just download it and then you can run any of these open Veno models and it",
    "start": "2084240",
    "end": "2089280"
  },
  {
    "text": "runs really really blazing fast on your aipc and this is just a start and I'm just this is just like us so I think you",
    "start": "2089280",
    "end": "2096638"
  },
  {
    "text": "know this is like such early days for all the model development the PC Hardware development I'm sure there will",
    "start": "2096639",
    "end": "2102560"
  },
  {
    "text": "be better and better Hardware so where do I see this going is truly I do really",
    "start": "2102560",
    "end": "2107800"
  },
  {
    "text": "think that's the power of AI in let's say three years will be so ubiquitous",
    "start": "2107800",
    "end": "2113280"
  },
  {
    "text": "it'll be we'll look back at these times and go gosh do you remember we were even like talking about you know like oh",
    "start": "2113280",
    "end": "2118920"
  },
  {
    "text": "these small language models are new no at that point it won't be new it'll just be like software you know at this point",
    "start": "2118920",
    "end": "2125240"
  },
  {
    "text": "right well like you know when you buy the toys right you know it's like batter is not included AI will be so ubiquitous",
    "start": "2125240",
    "end": "2132040"
  },
  {
    "text": "that the applications have to say Okay this application does not include AI right so no that's right I think it can",
    "start": "2132040",
    "end": "2137359"
  },
  {
    "text": "power everything and I mean anyone who's played with you know geni knows like the power of being able to inference and the",
    "start": "2137359",
    "end": "2144839"
  },
  {
    "text": "powerful capability and the fact that they're now coming in such small Footprints smaller and smaller",
    "start": "2144839",
    "end": "2150359"
  },
  {
    "text": "Footprints with all these like distillation and pruning techniques and combination and getting better and",
    "start": "2150359",
    "end": "2155599"
  },
  {
    "text": "better and smaller Footprints and then the hard Hardware getting better and better so basically even the definition",
    "start": "2155599",
    "end": "2161079"
  },
  {
    "text": "of small language model changing the fact that I can now say like oh I can run after we hang up I'm gonna this",
    "start": "2161079",
    "end": "2166920"
  },
  {
    "text": "weekend try to see if I can run a 20 billion parameter model on a laptop Unthinkable Unthinkable right even like",
    "start": "2166920",
    "end": "2173880"
  },
  {
    "text": "three or four months ago for me anyway I'm sure there are like brilliant people out there who've already done it but for",
    "start": "2173880",
    "end": "2179240"
  },
  {
    "text": "me it was like Unthinkable but the fact that I can even talk like that but then the fact that you might not even need a",
    "start": "2179240",
    "end": "2184760"
  },
  {
    "text": "20 billion parameter model because these three billion parameter model mod are getting so stupendously good it's really",
    "start": "2184760",
    "end": "2190359"
  },
  {
    "text": "an embarrassment of riches at this point today let alone what will it be like 3 years from now yeah definitely I kind of",
    "start": "2190359",
    "end": "2197280"
  },
  {
    "text": "see these small language models and AI powered PCS as like two sides of the same coin they're so complimentary",
    "start": "2197280",
    "end": "2203079"
  },
  {
    "text": "they're going to make each other kind of innovate you know at a very fast pace that's right and the price point of",
    "start": "2203079",
    "end": "2208599"
  },
  {
    "text": "these aips to me is really interesting you know if you think about it for the",
    "start": "2208599",
    "end": "2214160"
  },
  {
    "text": "powerful capability that they offer they're really inexpensive and we were able to actually just turn",
    "start": "2214160",
    "end": "2220079"
  },
  {
    "text": "one into like an inference server just playing around with it so the GPU",
    "start": "2220079",
    "end": "2225119"
  },
  {
    "text": "capability is so powerful so it's really really really cool what can be done with it so I highly recommend everybody to",
    "start": "2225119",
    "end": "2232359"
  },
  {
    "text": "check it out there I think the lunar Lake version is coming out now for consumers and you know if you're at your",
    "start": "2232359",
    "end": "2238760"
  },
  {
    "text": "local Best Buy or wherever they're available like I just you know just check them out it's amazing amazing it's",
    "start": "2238760",
    "end": "2244560"
  },
  {
    "text": "interesting I was checking the Dell website earlier today just kind of see see what kind of desktops and laptops are available you can get a gaming",
    "start": "2244560",
    "end": "2250599"
  },
  {
    "text": "desktop with the GPU with Nvidia RTX I think you know that's like for like $1,000 $2,000 you so very I guess very",
    "start": "2250599",
    "end": "2257520"
  },
  {
    "text": "affordable you know relatively right so yeah no absolutely compared to like having to reserve time on your Cloud for",
    "start": "2257520",
    "end": "2264520"
  },
  {
    "text": "you know A10 a100 h100 how much is that going to cost you",
    "start": "2264520",
    "end": "2270200"
  },
  {
    "text": "and how is that even accessible anyway so yeah let's talk about some best practices right you know definitely I",
    "start": "2270200",
    "end": "2275280"
  },
  {
    "text": "think the language models are you know evolving so fast they're getting definitely more powerful and smaller in",
    "start": "2275280",
    "end": "2280560"
  },
  {
    "text": "terms of the parameter size and not necessarily in terms of performance do you have any advice on any best",
    "start": "2280560",
    "end": "2285839"
  },
  {
    "text": "practices for somebody who wants to use these you know what kind of cautions they should be aware of so first",
    "start": "2285839",
    "end": "2292640"
  },
  {
    "text": "honestly just start by trying and you know my kind of first like if you're new",
    "start": "2292640",
    "end": "2297839"
  },
  {
    "text": "to small language models I still think that like the place to start is with the Microsoft models my favorite is you know",
    "start": "2297839",
    "end": "2304880"
  },
  {
    "text": "the Five series I think Microsoft did have tremendous this job with those models so I really recommend that and so",
    "start": "2304880",
    "end": "2311160"
  },
  {
    "text": "I would start just with those and if you have a Mac again you can actually inference it using LL mware you don't",
    "start": "2311160",
    "end": "2317880"
  },
  {
    "text": "even have to download anything like I mean pip install yes so we support that",
    "start": "2317880",
    "end": "2323079"
  },
  {
    "text": "and just start and you'll be pleasantly pleasantly surprised at how capable they are I think you had mentioned that you",
    "start": "2323079",
    "end": "2328920"
  },
  {
    "text": "had this very similar like experience like you're shocked at how good they are so the only caveat I would say to this",
    "start": "2328920",
    "end": "2335319"
  },
  {
    "text": "is like Still You Know video generation a or image generation or those kinds of multimodal like I'm not sure that like I",
    "start": "2335319",
    "end": "2342960"
  },
  {
    "text": "definitely couldn't say that like a small model is like as good as like a larger model so I still haven't really",
    "start": "2342960",
    "end": "2348319"
  },
  {
    "text": "seen that but you know I think it's still going to come down to an acceptable quality in due time we're",
    "start": "2348319",
    "end": "2353680"
  },
  {
    "text": "just not there today but just start experimenting with it and then you know we're not the only ones who have the",
    "start": "2353680",
    "end": "2359160"
  },
  {
    "text": "function calling models but if you want to just take it to the next level and you beyond just like Chad if you want to",
    "start": "2359160",
    "end": "2364520"
  },
  {
    "text": "take it to like workflow automation look for some smaller function calling models that you can really stack together to",
    "start": "2364520",
    "end": "2370839"
  },
  {
    "text": "create a workflow and I think you'd be really really pleasantly surprised I have so many members of our open- source",
    "start": "2370839",
    "end": "2377280"
  },
  {
    "text": "Community who use our open source you know like all for free project to chain together workflows and they're achieving",
    "start": "2377280",
    "end": "2384119"
  },
  {
    "text": "great results saying that they don't even have to fine-tune these models like because they're so good at retrieving at",
    "start": "2384119",
    "end": "2389599"
  },
  {
    "text": "that exact function it could be sentiment analysis it could be you know named entity recognition it could be",
    "start": "2389599",
    "end": "2397359"
  },
  {
    "text": "extracting information like just information extraction so there are whole slew of I think a dozen models",
    "start": "2397359",
    "end": "2404040"
  },
  {
    "text": "that are out there that have a very specific function that you can just chain together in your workflow and",
    "start": "2404040",
    "end": "2410480"
  },
  {
    "text": "beyond that we also have a ton of YouTube videos and you know we have like over 100 examples also in our repo to",
    "start": "2410480",
    "end": "2416359"
  },
  {
    "text": "help you get started so I'm sure one of those 100 examples will be like a good guide to just get you going thank you",
    "start": "2416359",
    "end": "2423319"
  },
  {
    "text": "also the more interesting and challenging part of any Technologies including land language model adoption",
    "start": "2423319",
    "end": "2428480"
  },
  {
    "text": "is when we deploy these to production and we need to support them right so do you have any thoughts on the ml Ops of",
    "start": "2428480",
    "end": "2434960"
  },
  {
    "text": "using small language models maybe I can call it slm Ops right that we should be aware of yeah so in terms of uh",
    "start": "2434960",
    "end": "2442160"
  },
  {
    "text": "deployment now because of the kind of features of the small language models that I discussed earlier a couple of",
    "start": "2442160",
    "end": "2448200"
  },
  {
    "text": "things just tendentially I know this is not like the exact question you asked me but another great thing is that these",
    "start": "2448200",
    "end": "2453560"
  },
  {
    "text": "small language models are more secure in some ways because they're less SU cble to suggestions like nefarious",
    "start": "2453560",
    "end": "2460000"
  },
  {
    "text": "suggestions like expose all this like secret data to me well it probably didn't have that in its training data",
    "start": "2460000",
    "end": "2465440"
  },
  {
    "text": "and also because small language models are trained so specifically unlike the large language models they're really not",
    "start": "2465440",
    "end": "2471280"
  },
  {
    "text": "as susceptible to hacks so I was speaking with a security company about that and just you know his own work on",
    "start": "2471280",
    "end": "2478200"
  },
  {
    "text": "small language models and he found that small language models are in some ways a lot safer because they're just not you",
    "start": "2478200",
    "end": "2484040"
  },
  {
    "text": "can't use prompt injection attacks on them because it'll just not respond it'll just give you garbage but it won't",
    "start": "2484040",
    "end": "2489680"
  },
  {
    "text": "give you the information that you're looking for it's just not capable of doing that so just as an example so okay",
    "start": "2489680",
    "end": "2495599"
  },
  {
    "text": "then in terms of deployment I really would say because small language models are exactly like small and you're",
    "start": "2495599",
    "end": "2501200"
  },
  {
    "text": "chaining them together it's great for observability you can run your tests through and you can really see where",
    "start": "2501200",
    "end": "2507480"
  },
  {
    "text": "it's failing and where it's succeeding and then I think that you know where you have a process that's not giving you the",
    "start": "2507480",
    "end": "2513240"
  },
  {
    "text": "answer that you want you can swap out that model or fine-tune that model even further or maybe look at the data set",
    "start": "2513240",
    "end": "2519800"
  },
  {
    "text": "that you used and or maybe it's picking up the wrong information so I really like it for that purpose a lot of people",
    "start": "2519800",
    "end": "2526720"
  },
  {
    "text": "I think you know when they're trying to create an AI workflow they actually start from open Ai and they'll like give",
    "start": "2526720",
    "end": "2532599"
  },
  {
    "text": "it like a long long prompt like a two-page prompt and then go to a small language model I actually would be to",
    "start": "2532599",
    "end": "2538359"
  },
  {
    "text": "defer here you're almost better off like starting small do the work of like chaining these small language models",
    "start": "2538359",
    "end": "2545000"
  },
  {
    "text": "together for your workflow and then see how that works for you and then if you think that there's a model in the middle",
    "start": "2545000",
    "end": "2551680"
  },
  {
    "text": "that's too small in size is not getting the job done then you can always increase and substituting like a much larger model let's say you start with a",
    "start": "2551680",
    "end": "2558960"
  },
  {
    "text": "1 billion parameter model you think it's not good enough then substitute a three billion then try a seven then you know",
    "start": "2558960",
    "end": "2564040"
  },
  {
    "text": "try something larger I actually would be surprised at this point where you know if you have a model that's like you know",
    "start": "2564040",
    "end": "2571680"
  },
  {
    "text": "that's 10 billion and under like around 10 billion that can't do most of the workflows that we're talking about",
    "start": "2571680",
    "end": "2578559"
  },
  {
    "text": "really I personally haven't seen that but I'm not creative enough to think about every use case in the world but",
    "start": "2578559",
    "end": "2585319"
  },
  {
    "text": "the use cases that I've seen I haven't seen one that like a 10 billion parameter model couldn't really solve",
    "start": "2585319",
    "end": "2590800"
  },
  {
    "text": "like when changed the right way with again the hard exception being like you know video creation and you know images",
    "start": "2590800",
    "end": "2598000"
  },
  {
    "text": "and things like that yeah definitely start small explore and iterate and kind know absolutely sounds good so on this",
    "start": "2598000",
    "end": "2605760"
  },
  {
    "text": "topic do you have any recommendation online resources you know we talked about a couple of tools open V know and",
    "start": "2605760",
    "end": "2611200"
  },
  {
    "text": "other ones right so do you have any other resources especially like knowledge based articles or tutorials that our listeners can check out so I",
    "start": "2611200",
    "end": "2618760"
  },
  {
    "text": "always really like going to Mark Tech post for a lot of just Leading Edge AI research if you really are into that and",
    "start": "2618760",
    "end": "2625200"
  },
  {
    "text": "you want to see like the latest development in model training and you know what is going on in that space if",
    "start": "2625200",
    "end": "2631079"
  },
  {
    "text": "you are AI research inclined and then believe it or not like I love watching tutorials on YouTube so there",
    "start": "2631079",
    "end": "2637599"
  },
  {
    "text": "so we have a YouTube channel and there are a whole host of other YouTube channels that really expose like the",
    "start": "2637599",
    "end": "2642800"
  },
  {
    "text": "latest in Ai and I like watching people like their take on it they show you their experience with it and AI anytime",
    "start": "2642800",
    "end": "2650520"
  },
  {
    "text": "has a great Channel World of AI is always good about you know kind of exposing like the latest like open",
    "start": "2650520",
    "end": "2655599"
  },
  {
    "text": "source projects and again we have one so and then I always follow hugging faces LinkedIn site just because they also",
    "start": "2655599",
    "end": "2662240"
  },
  {
    "text": "really promote like some great new models most of them are small and so hugging face on LinkedIn is great so",
    "start": "2662240",
    "end": "2669720"
  },
  {
    "text": "those are kind of the resources that I tend to follow and also obviously we have good information on our own infokey",
    "start": "2669720",
    "end": "2675720"
  },
  {
    "text": "website as well right oh absolutely actually not because I'm on it but I have to say when I was doing research on",
    "start": "2675720",
    "end": "2682000"
  },
  {
    "text": "the Apple Foundation models I really love the content that I saw infoq kind",
    "start": "2682000",
    "end": "2687079"
  },
  {
    "text": "of describing you know how the AFM the Apple Foundation models were created and I thought it was a great article so",
    "start": "2687079",
    "end": "2692880"
  },
  {
    "text": "infoq definitely going back to your point about AI are becoming ubiquit us",
    "start": "2692880",
    "end": "2698280"
  },
  {
    "text": "and I'm seeing that on infoq content as well we have these different communities for architecture the devops and so on",
    "start": "2698280",
    "end": "2705480"
  },
  {
    "text": "cloud and security and obviously ml we are seeing lot of AI based articles in pretty much all of these communities so",
    "start": "2705480",
    "end": "2712040"
  },
  {
    "text": "it is kind of perv you right so the question is like when is AI going to be just like a thing like just a regular",
    "start": "2712040",
    "end": "2717760"
  },
  {
    "text": "thing like no one's like excited about like oh I have my own website like no one cares anymore right like come on so",
    "start": "2717760",
    "end": "2723200"
  },
  {
    "text": "when are we going to reach the point where you know like yes it's just understood that everything's is going to have the AI in it just like you said",
    "start": "2723200",
    "end": "2729480"
  },
  {
    "text": "yeah I think it's going to happen but we have to look back and think about oh back in like I don't know 20 whatever 20 26 2 whatever right I'm just picking a",
    "start": "2729480",
    "end": "2735920"
  },
  {
    "text": "ear but then we'll say oh that was when you know the AI became like the part of the you know the everything we do right",
    "start": "2735920",
    "end": "2741319"
  },
  {
    "text": "so I think we won't realize when it happens but you know maybe looking back after that probably we will realize it",
    "start": "2741319",
    "end": "2746520"
  },
  {
    "text": "absolutely so do you have any additional comments before we wrap up today's discussion anything else you would like",
    "start": "2746520",
    "end": "2752079"
  },
  {
    "text": "to share no I mean thank you so much for having me on I really appreciate it and",
    "start": "2752079",
    "end": "2757200"
  },
  {
    "text": "thank you infoq community for listening and I really encourage you to keep experimenting and play around and please",
    "start": "2757200",
    "end": "2764760"
  },
  {
    "text": "visit my open source site um L mware we are really Pioneers in this space and we really try to pack in like an endtoend",
    "start": "2764760",
    "end": "2771000"
  },
  {
    "text": "solution and it's really free for anyone to try out so please give it a world",
    "start": "2771000",
    "end": "2776079"
  },
  {
    "text": "thank you Nami for very much for joining this podcast it's been great to discuss the recent innovation in the language",
    "start": "2776079",
    "end": "2781599"
  },
  {
    "text": "models and J space which is the small language models which like you mentioned have the potential to commoditize and",
    "start": "2781599",
    "end": "2788520"
  },
  {
    "text": "localize the language model Solutions so they can have a bigger impact on the software development Community overall",
    "start": "2788520",
    "end": "2794880"
  },
  {
    "text": "and to our listeners thank you for listening to this podcast if you like to learn more about AIML topics check out",
    "start": "2794880",
    "end": "2800960"
  },
  {
    "text": "the AIML and data engineering community page on info.com website I encourage you",
    "start": "2800960",
    "end": "2806319"
  },
  {
    "text": "to listen to the recent podcasts especially the one that Nami mentioned earlier the AIML Trends report for 2024",
    "start": "2806319",
    "end": "2813520"
  },
  {
    "text": "we did the podcast in August but we published the report last month in sept member 2024 you can learn about small",
    "start": "2813520",
    "end": "2819839"
  },
  {
    "text": "language models AI powered PCS coding assistance and a lot of other Trends a",
    "start": "2819839",
    "end": "2825160"
  },
  {
    "text": "lot of interesting topics there we've been seeing a lot of activity on that podcast so definitely check it out thank",
    "start": "2825160",
    "end": "2830319"
  },
  {
    "text": "you I mean thank you thanks everybody thank you",
    "start": "2830319",
    "end": "2835480"
  },
  {
    "text": "[Music]",
    "start": "2838490",
    "end": "2854510"
  }
]
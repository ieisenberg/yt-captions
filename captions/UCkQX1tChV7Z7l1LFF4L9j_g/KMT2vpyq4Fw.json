[
  {
    "text": "[Music] thank you",
    "start": "3360",
    "end": "9840"
  },
  {
    "text": "thank you so much for joining us today we're really excited to share some new ideas and some new features with you all",
    "start": "9840",
    "end": "16379"
  },
  {
    "text": "today uh and so let's get started get back here",
    "start": "16379",
    "end": "23300"
  },
  {
    "text": "cool I want to take this back in time to 1973",
    "start": "23520",
    "end": "29519"
  },
  {
    "text": "50 years ago in 1973 Scientific American published a",
    "start": "29519",
    "end": "35940"
  },
  {
    "text": "very interesting article in which they compared the movement of various animals",
    "start": "35940",
    "end": "42660"
  },
  {
    "text": "they set out to compare the locomotive efficiency in other words how many calories in animal Burns to get from",
    "start": "42660",
    "end": "49320"
  },
  {
    "text": "point A to point B in relation to their body mass and things like that and what they did is they compared you",
    "start": "49320",
    "end": "56039"
  },
  {
    "text": "know various animals Birds insects and of course as humans and rank them from",
    "start": "56039",
    "end": "62280"
  },
  {
    "text": "most efficient to least efficient what they found was the Condor was the",
    "start": "62280",
    "end": "68340"
  },
  {
    "text": "most efficient in terms of locomotive efficiency now if you've never seen a condor before it's a beautiful bird",
    "start": "68340",
    "end": "73619"
  },
  {
    "text": "native to California and some parts of South America and it can find sometimes hundreds of miles without ever flapping",
    "start": "73619",
    "end": "80460"
  },
  {
    "text": "its wings has really good gliding power humans on the other hand humans who walk",
    "start": "80460",
    "end": "86400"
  },
  {
    "text": "came in rather unimpressively at about one third down the list which is not",
    "start": "86400",
    "end": "91439"
  },
  {
    "text": "such a great showing for us uh but the beauty of this Scientific American article is that they added one",
    "start": "91439",
    "end": "97020"
  },
  {
    "text": "more item in addition to all the species they had one more item to the list and that was Man on a bicycle",
    "start": "97020",
    "end": "103020"
  },
  {
    "text": "man on a bicycle blew the competition away almost two times as efficient in Locomotion as the Condor",
    "start": "103020",
    "end": "110759"
  },
  {
    "text": "and I love this story because it is such a simple realization that with a little bit of tooling a little bit of",
    "start": "110759",
    "end": "117479"
  },
  {
    "text": "mechanical help we can really augment our abilities by quite a lot",
    "start": "117479",
    "end": "124140"
  },
  {
    "text": "now some of you in the audience might have heard this story before uh you might be thinking where have I seen this",
    "start": "124140",
    "end": "129539"
  },
  {
    "text": "uh this story was often told by Steve Jobs in the early days of Apple",
    "start": "129539",
    "end": "135980"
  },
  {
    "text": "the ham and the Apple team use the story as Inspirations with the early Macintosh",
    "start": "135980",
    "end": "141840"
  },
  {
    "text": "Steve compared the story and said uh humans are tool Builders we make",
    "start": "141840",
    "end": "147720"
  },
  {
    "text": "tools like the bicycle to augment our abilities to get things done and just as the bicycle is a tool for",
    "start": "147720",
    "end": "155940"
  },
  {
    "text": "more motorability for moving computers are a tool for our mind",
    "start": "155940",
    "end": "161580"
  },
  {
    "text": "the augment our abilities in creativity imagination and productivity",
    "start": "161580",
    "end": "166739"
  },
  {
    "text": "in fact Steve had this amazing phrase that he used to describe personal computers he said computers were a",
    "start": "166739",
    "end": "173400"
  },
  {
    "text": "bicycle for the mind a bicycle for the mind I love this phrase",
    "start": "173400",
    "end": "179760"
  },
  {
    "text": "Ten Years After this article was published in 1983 Apple released the Macintosh and unleashed the personal",
    "start": "179760",
    "end": "186480"
  },
  {
    "text": "Computing Revolution and of course we're here now many years later still using Macs every day",
    "start": "186480",
    "end": "194040"
  },
  {
    "text": "but that was 1973. we're here in 2023 50 years later Computing has changed a lot",
    "start": "194040",
    "end": "200519"
  },
  {
    "text": "and if the folks of Scientific American ran the study again I bet they would add one more species to the list a species",
    "start": "200519",
    "end": "207840"
  },
  {
    "text": "that for most of us has really only been around in the public imagination for six months or so",
    "start": "207840",
    "end": "213300"
  },
  {
    "text": "I'm talking of course about AI or language models in specific",
    "start": "213300",
    "end": "218340"
  },
  {
    "text": "ever since chat GPT launched in November last year Ai and language models have captured the public imagination around",
    "start": "218340",
    "end": "224879"
  },
  {
    "text": "the world but more excitingly uh they've captured the imagination of developers around the world we've seen an amazing",
    "start": "224879",
    "end": "232379"
  },
  {
    "text": "number of people integrate AI into their applications build net new products using language models and come up with",
    "start": "232379",
    "end": "238620"
  },
  {
    "text": "entirely new ways of interacting with computers natural language interaction is finally possible in high quality",
    "start": "238620",
    "end": "245220"
  },
  {
    "text": "but there are limitations and there are problems for any of you who've used strategypt you know that you know it's",
    "start": "245220",
    "end": "252239"
  },
  {
    "text": "training data was fixed in September 2021 so it's unaware of current events",
    "start": "252239",
    "end": "257239"
  },
  {
    "text": "for for the most part language models like charging PT operate from memory from their training so they're not",
    "start": "257239",
    "end": "263400"
  },
  {
    "text": "connected to current events or all the apis out there your own apps and",
    "start": "263400",
    "end": "268800"
  },
  {
    "text": "websites that you use every day or if you work at a company it's not connected to your company's database and your company's internal you know knowledge",
    "start": "268800",
    "end": "275820"
  },
  {
    "text": "base and things like that so that makes the use of language models kind of limited you can write a poem you",
    "start": "275820",
    "end": "282120"
  },
  {
    "text": "could write an essay you can get a great joke out of it you might search for some things but how do you connect language",
    "start": "282120",
    "end": "287280"
  },
  {
    "text": "models to the external world how do you augment the ai's abilities to perform actions on your on your behalf to do",
    "start": "287280",
    "end": "294900"
  },
  {
    "text": "more than its innate abilities offer it if computers are a bicycle for the mind",
    "start": "294900",
    "end": "302699"
  },
  {
    "text": "what is a bicycle for the AI mind so that's the question we're going to",
    "start": "302699",
    "end": "308520"
  },
  {
    "text": "explore today a bicycle for the AI mind we're going to talk about GPT the flagship set of language models that",
    "start": "308520",
    "end": "314220"
  },
  {
    "text": "open air develops and how to integrate them with tools or external apis and functions uh to power net new",
    "start": "314220",
    "end": "320160"
  },
  {
    "text": "applications my name is Addie I'm an engineer at open AI I'm joined by Sherwin and together",
    "start": "320160",
    "end": "326880"
  },
  {
    "text": "we're on the API team at open AI building the opening API and various other developer products",
    "start": "326880",
    "end": "333780"
  },
  {
    "text": "today we're going to talk about three things first we're going to talk about language models and their limitations we'll do a",
    "start": "333780",
    "end": "340020"
  },
  {
    "text": "quick introduction to how they work what they are develop an intuition for them and then also learn about where they",
    "start": "340020",
    "end": "345960"
  },
  {
    "text": "fall short second we're going to talk about a brand new feature that we announced just yesterday called function calling with",
    "start": "345960",
    "end": "352320"
  },
  {
    "text": "GPT function calling is how you plug open AIS GPT models to the external world and",
    "start": "352320",
    "end": "358080"
  },
  {
    "text": "let it perform actions and finally we'll walk through three quick demos of how you might take the",
    "start": "358080",
    "end": "363900"
  },
  {
    "text": "open AI models and the GPT function calling feature indicated into your companies your products and your side",
    "start": "363900",
    "end": "370259"
  },
  {
    "text": "projects as well so let's get started to introduce llms and their limitations here showing",
    "start": "370259",
    "end": "378440"
  },
  {
    "text": "thank you Addie um so I wanted to start by just giving a very high level overview of llms",
    "start": "378440",
    "end": "385680"
  },
  {
    "text": "um what they do what they are how they work and then also talk about some of the limitations that they have right out",
    "start": "385680",
    "end": "390720"
  },
  {
    "text": "of the box uh for those of you who have been following this space for a while this is probably information that you all know but I just want to make sure",
    "start": "390720",
    "end": "395880"
  },
  {
    "text": "that we're all kind of on the same page before diving into the the nitty-gritty um so a very high level GPT models",
    "start": "395880",
    "end": "402240"
  },
  {
    "text": "including chat GPT gpd4 GPD 315 turbo they're all what we call Auto regressive",
    "start": "402240",
    "end": "407400"
  },
  {
    "text": "language models but what this means is that they are these giant AI models they've been trained on a giant Corpus",
    "start": "407400",
    "end": "412740"
  },
  {
    "text": "of data including the internet Wikipedia public GitHub code licensed other licensed material but",
    "start": "412740",
    "end": "420840"
  },
  {
    "text": "they're called Auto regressive because all they're doing is they're synthesizing all this information they take in a prompt or what we might call",
    "start": "420840",
    "end": "426780"
  },
  {
    "text": "context um they look at the prompts and then they basically just decide given this prompt given this input what should the",
    "start": "426780",
    "end": "433620"
  },
  {
    "text": "next word be and so it's really just predicting predicting the next word so for example if an input given a GPT is",
    "start": "433620",
    "end": "439740"
  },
  {
    "text": "the largest city in the United States is the answer is New York City it would think about it one word at a",
    "start": "439740",
    "end": "445199"
  },
  {
    "text": "time and I would say New York and then City similarly in a more conversational",
    "start": "445199",
    "end": "450780"
  },
  {
    "text": "context if you ask it what the distance between the Earth and the Sun is I don't know this off the top of my head but GPT",
    "start": "450780",
    "end": "455940"
  },
  {
    "text": "has learned this somehow from the internet um it'll output 94 million miles",
    "start": "455940",
    "end": "462780"
  },
  {
    "text": "so it's thinking about it one word at a time based off of the input under the hood what it's really doing is",
    "start": "462780",
    "end": "468120"
  },
  {
    "text": "each time it's outputting words looking at a bunch of candidate words and assigning probabilities to them and so for example in the original example of",
    "start": "468120",
    "end": "474840"
  },
  {
    "text": "the large city in the United States is it might have a bunch of candidates so new for like New York or New Jersey or",
    "start": "474840",
    "end": "480300"
  },
  {
    "text": "something lost for Los Angeles and then some other possible examples but you can see that it's really thinking that New",
    "start": "480300",
    "end": "485520"
  },
  {
    "text": "York City is probably the right answer because new is assigned a probability of 95 in this case it generally picks the",
    "start": "485520",
    "end": "491699"
  },
  {
    "text": "most likely outcome so it picks new and then it kind of moves on after this word comes out you now know that new is the",
    "start": "491699",
    "end": "498120"
  },
  {
    "text": "first word so it's kind of constrained a little bit more on what the next word is so you can see now it's thinking New",
    "start": "498120",
    "end": "503340"
  },
  {
    "text": "York with much higher likelihood but it's also considering New Brunswick New Mexico New Delhi as well",
    "start": "503340",
    "end": "509520"
  },
  {
    "text": "and then once the second word has been done this is basically a layup for the model it basically knows that it's New York City with almost 100 probability",
    "start": "509520",
    "end": "517080"
  },
  {
    "text": "um and but it's still like kind of considering some other options with very very low residual probability so County",
    "start": "517080",
    "end": "523560"
  },
  {
    "text": "New York Metro New York Times but with that it choose a city and kind of concludes its answer",
    "start": "523560",
    "end": "529260"
  },
  {
    "text": "um for the more astute llm folks in the audience yeah it's technically an oversimplification um you're not really predicting words",
    "start": "529260",
    "end": "534959"
  },
  {
    "text": "you're predicting tokens like fragments of Words which are actually a more efficient way of representing the English language mostly because",
    "start": "534959",
    "end": "540779"
  },
  {
    "text": "fragments of words are repeated in a bunch of different uh words instead of the word itself but the concept is still the same um the llm is taking in a",
    "start": "540779",
    "end": "547500"
  },
  {
    "text": "context and it's probabilistically outputting a bunch of different uh tokens in a row",
    "start": "547500",
    "end": "552720"
  },
  {
    "text": "and that's it that's really what what these language models are and with this the crazy thing is that I think",
    "start": "552720",
    "end": "558600"
  },
  {
    "text": "surprised a lot of us is that you can get really really far uh with just predicting the next word and so this is a graph from our gpt4 blog post that we",
    "start": "558600",
    "end": "565440"
  },
  {
    "text": "uh released in March of this year which shows the performance of our most capable model gpt4 on various",
    "start": "565440",
    "end": "570899"
  },
  {
    "text": "professional exams and this is literally just gpd4 predicting the next word based off of questions you can see that it's",
    "start": "570899",
    "end": "577200"
  },
  {
    "text": "actually performing at human or even like you know past human performance on a lot of different exams so the y-axis",
    "start": "577200",
    "end": "583380"
  },
  {
    "text": "is percentile based off of amongst uh test takers so it's basically at like 80th percentile sometimes even 90th or",
    "start": "583380",
    "end": "590459"
  },
  {
    "text": "even 100th percentile um on a bunch of different uh exams such",
    "start": "590459",
    "end": "595560"
  },
  {
    "text": "as uh AP exams the Gres LSAT um uh",
    "start": "595560",
    "end": "601440"
  },
  {
    "text": "yeah USA bio Olympiad as well so at this point you know a lot of these these these tests I can't even do and so gpd4",
    "start": "601440",
    "end": "607620"
  },
  {
    "text": "is well well above my own ability and this is just from predicting the next word",
    "start": "607620",
    "end": "612779"
  },
  {
    "text": "so this is really cool and you can build a lot of cool things with this um but anyone who's been playing around with LMS for a while will you'll realize",
    "start": "612779",
    "end": "619080"
  },
  {
    "text": "that you very quickly start running into some limitations here and the biggest one of course is as Addie kind of just mentioned is uh the the out of the box",
    "start": "619080",
    "end": "625680"
  },
  {
    "text": "uh llm or gbt is really an AI that's kind of in a box it has no access to the outside world it doesn't know any",
    "start": "625680",
    "end": "631800"
  },
  {
    "text": "additional information it's kind of just there with its own memory um it kind of feels like when you're taking a test in school and it's just",
    "start": "631800",
    "end": "638459"
  },
  {
    "text": "kind of you in the test and you're kind of coming up with things out of memory imagine how much better you do on the test if it were open node if you could",
    "start": "638459",
    "end": "644339"
  },
  {
    "text": "use your phone or something like that gbt today is really just in its own box similarly uh or like because of this as",
    "start": "644339",
    "end": "652440"
  },
  {
    "text": "uh Engineers you know we want to use GPT and kind of integrate into our systems and so limiting GPT and not allowing to",
    "start": "652440",
    "end": "658079"
  },
  {
    "text": "talk to our internal systems is very limiting for what you might want to do additionally even if it does have access",
    "start": "658079",
    "end": "663180"
  },
  {
    "text": "to these tools um because the language model is probabilistic it's sometimes very hard to guarantee the way that the model",
    "start": "663180",
    "end": "669360"
  },
  {
    "text": "interacts with external tools so if you have an API or something that you want to work with the output of the model is",
    "start": "669360",
    "end": "674700"
  },
  {
    "text": "not guaranteed uh that the current model isn't guaranteed to always match the output of what the input of what an API",
    "start": "674700",
    "end": "680760"
  },
  {
    "text": "might want and that ends up being a problem so for example um you know if I were talking to",
    "start": "680760",
    "end": "685920"
  },
  {
    "text": "building an application and I was gave this input to GPT basically said you know below is the text of a screenplay",
    "start": "685920",
    "end": "691620"
  },
  {
    "text": "extract some information from it and structure it in this Json format so I'm really just giving it a screenplay and asking it to infer a genre and a",
    "start": "691620",
    "end": "698339"
  },
  {
    "text": "sub-genre as well as some characters from it and age range um what I really want is I want it to",
    "start": "698339",
    "end": "704399"
  },
  {
    "text": "output something like this right so it's like exactly like the Json output and maybe this is a screenplay about like Harry Potter romance or something it",
    "start": "704399",
    "end": "711060"
  },
  {
    "text": "knows that it's romance teen romances it sees Ron and Hermione and outputs it exactly in this Json format this is",
    "start": "711060",
    "end": "716880"
  },
  {
    "text": "fantastic because I can just take this output and now I can use this and throw this into an API and then I'm I'm kind",
    "start": "716880",
    "end": "722220"
  },
  {
    "text": "of like in my code and and it all works the problem is it does this maybe like 80 70 of the time the rest of the time",
    "start": "722220",
    "end": "729540"
  },
  {
    "text": "it'll actually try and be extra helpful and do something like this where it says yeah sure I can do that for you blows the information you ask for in a Json",
    "start": "729540",
    "end": "735480"
  },
  {
    "text": "format which is super helpful kind of but if you're trying to plug this into an API it actually won't work because",
    "start": "735480",
    "end": "741120"
  },
  {
    "text": "there's all this random text in front and it and your API won't know how to parse it and so this is obviously very",
    "start": "741120",
    "end": "746220"
  },
  {
    "text": "disappointing and you know it's not what you actually want and so what we're really what we really",
    "start": "746220",
    "end": "752279"
  },
  {
    "text": "wanted to do is we wanted to help you know break GPT out of the box or as Eddie said give GPD basically a bicycle",
    "start": "752279",
    "end": "758040"
  },
  {
    "text": "or another set of tools really augment its ability and have that work very seamlessly so this brings me to the next part of",
    "start": "758040",
    "end": "764519"
  },
  {
    "text": "our talk which is going over what we call function calling the GPT which is a a new change to our API that we launched",
    "start": "764519",
    "end": "771000"
  },
  {
    "text": "yesterday that makes function calling work a lot better with our GPT models uh in a very first class way",
    "start": "771000",
    "end": "778079"
  },
  {
    "text": "so to illustrate an example of this um if you ask your EPT a question like this what's the weather like in Brooklyn today so like you know right here",
    "start": "778079",
    "end": "785040"
  },
  {
    "text": "um if you ask it uh uh you know normal GPT this it'll basically say something like as an AI model trained by open AI",
    "start": "785040",
    "end": "792240"
  },
  {
    "text": "I'm unable to provide real-time information which is true because it can't actually access anything it's in a box how does it know what the weather is",
    "start": "792240",
    "end": "797579"
  },
  {
    "text": "like right now um this obviously really limits its capabilities and you know it's not desirable so what we did was we updated",
    "start": "797579",
    "end": "804480"
  },
  {
    "text": "our gpt4 and our GPD 3.5 turbo models or Flagship models we took a lot of you",
    "start": "804480",
    "end": "809579"
  },
  {
    "text": "know tool use and function calling data fine-tuned our models on those and made it really really good at choosing",
    "start": "809579",
    "end": "815100"
  },
  {
    "text": "whether or not to use tools and so the end result is a new set of models that we released yesterday that can now",
    "start": "815100",
    "end": "820200"
  },
  {
    "text": "intelligently use tools and call functions for you and so in this particular example when",
    "start": "820200",
    "end": "826200"
  },
  {
    "text": "we're asking the model what's the weather like in Brooklyn today what I can now do is pass in this input but also tell it about a set of functions or",
    "start": "826200",
    "end": "832500"
  },
  {
    "text": "in this case one function that it has access to that it should try and call out to if it needs help so in this case",
    "start": "832500",
    "end": "837959"
  },
  {
    "text": "we'll give it a function that's called get current weather it takes in a string with the location",
    "start": "837959",
    "end": "843320"
  },
  {
    "text": "and then uh it knows that it can do it can use this and so in this case uh in",
    "start": "843320",
    "end": "849360"
  },
  {
    "text": "the new new world when you pass in this input GPT will express its intent to call this get current weather function",
    "start": "849360",
    "end": "855720"
  },
  {
    "text": "you will then call this function yourself in your own system however you want let's say you get an output here",
    "start": "855720",
    "end": "860880"
  },
  {
    "text": "that says 22 celsius and it's sunny we put these slides together yesterday and so it's actually cloudy today but it's",
    "start": "860880",
    "end": "867660"
  },
  {
    "text": "all right um Sunny um you can pass that back to gbt it'll synthesize this information and the return to the user saying the weather in",
    "start": "867660",
    "end": "874139"
  },
  {
    "text": "Brooklyn is currently Sunny with a temperature of 2020 22 degrees Celsius",
    "start": "874139",
    "end": "879660"
  },
  {
    "text": "and so to unpack this a little bit um you know what's really happening is GPT is knowing about a set of functions",
    "start": "879660",
    "end": "886019"
  },
  {
    "text": "and it will intelligently on its own express its own intent to call one of these functions and then you execute the",
    "start": "886019",
    "end": "891420"
  },
  {
    "text": "call and then pass it back to GPT so this is how you end up connecting it to the outside world so to kind of walk",
    "start": "891420",
    "end": "896699"
  },
  {
    "text": "through this a little bit more you know what's really happening at a high level is your user is still just like a back",
    "start": "896699",
    "end": "903120"
  },
  {
    "text": "and forth so your user asks a question a bunch of things happen and then you're responding to your user well what",
    "start": "903120",
    "end": "908639"
  },
  {
    "text": "actually happens behind the scenes with your app is you're going through this three-step process where you're calling out to open AI then you're using your",
    "start": "908639",
    "end": "915060"
  },
  {
    "text": "own function and then you're calling out to open AI or GPT again and so the first step obviously you know",
    "start": "915060",
    "end": "920339"
  },
  {
    "text": "the user asks a question in this case it is what's the weather like in Brooklyn today um then the next step is in your",
    "start": "920339",
    "end": "926399"
  },
  {
    "text": "application you call a model you call open Ai and you tell it about the set of functions that it has access to as well",
    "start": "926399",
    "end": "932100"
  },
  {
    "text": "as the user input and so very concretely you know this is an example API request that actually works today one of you",
    "start": "932100",
    "end": "938579"
  },
  {
    "text": "anyone with with API access can can try this so this is an example curl that uses our function calling ability",
    "start": "938579",
    "end": "945480"
  },
  {
    "text": "you can see that it's you know it's just normal curl to our chat completions endpoint which is a new API endpoint",
    "start": "945480",
    "end": "950519"
  },
  {
    "text": "that we released a couple months ago that powers our gpt4 and and GPD 3.5 models",
    "start": "950519",
    "end": "956399"
  },
  {
    "text": "um so you're curling this API you're passing in a model so in this case you're passing in gbd 3.5 turbo 0613",
    "start": "956399",
    "end": "962820"
  },
  {
    "text": "which stands for June 13th which is the model that we released yesterday so this is the model that's capable of doing",
    "start": "962820",
    "end": "967860"
  },
  {
    "text": "function calling you're also passing in a set of messages so for those of you who might not be familiar with our chat completions",
    "start": "967860",
    "end": "973800"
  },
  {
    "text": "format you can pass into our model a set like basically a list of messages that's the conversation history so in this case",
    "start": "973800",
    "end": "980339"
  },
  {
    "text": "there's only one message there's no history really you're it's just a user asking what's the weather like in Brooklyn today but you can imagine as",
    "start": "980339",
    "end": "986339"
  },
  {
    "text": "the conversation gets longer this might be like a five to ten message list but you're passing the messages and the",
    "start": "986339",
    "end": "992160"
  },
  {
    "text": "model will be able to see the history and kind of react to that and then the net new thing here is functions so this",
    "start": "992160",
    "end": "998160"
  },
  {
    "text": "is a new parameter you can pass in now and what you're passing in here is you're listing the set of functions that this model should be aware of that it",
    "start": "998160",
    "end": "1004880"
  },
  {
    "text": "will it should have access to so in this case we only have one function it's the get current weather function and you're",
    "start": "1004880",
    "end": "1010759"
  },
  {
    "text": "putting kind of like a natural language description here as well you're saying this this function gets the current weather in a particular location",
    "start": "1010759",
    "end": "1017779"
  },
  {
    "text": "you're also putting in these function signature so you're saying it has two arguments it has a location which is a",
    "start": "1017779",
    "end": "1023180"
  },
  {
    "text": "string which is just city and state and it's in this format so San Francisco comma space California it also has a",
    "start": "1023180",
    "end": "1029000"
  },
  {
    "text": "unit uh parameter as well which is Celsius or Fahrenheit um below the fold here there's also",
    "start": "1029000",
    "end": "1035540"
  },
  {
    "text": "another argument in here that says the only property that is required is the location so you technically only need a",
    "start": "1035540",
    "end": "1041660"
  },
  {
    "text": "passing location you don't need a unit here um and so you pass this function over to",
    "start": "1041660",
    "end": "1047660"
  },
  {
    "text": "uh you pass this request over to GPT and GP will then respond um in the old world gbt would probably",
    "start": "1047660",
    "end": "1053900"
  },
  {
    "text": "just respond with text so it'll say I can't do this because I don't have access but in this case what gbt actually responds with what our API",
    "start": "1053900",
    "end": "1059600"
  },
  {
    "text": "responds with is an intent to call the weather function and so um what's really happening here is GPT",
    "start": "1059600",
    "end": "1066020"
  },
  {
    "text": "is intuiting on its own that in order to figure out the current weather I'm not able to do it on my own but I have",
    "start": "1066020",
    "end": "1072200"
  },
  {
    "text": "access to get current weather function so I'm going to choose to call it and so I'm going to express an intent to call",
    "start": "1072200",
    "end": "1077900"
  },
  {
    "text": "it additionally what gbt did here if you haven't really noticed is it's past it's constructing the argument here so you",
    "start": "1077900",
    "end": "1083840"
  },
  {
    "text": "can see it's telling you it's trying once the call get current weather and it wants to call it with the argument",
    "start": "1083840",
    "end": "1089179"
  },
  {
    "text": "location Brooklyn New York and so what it did is it saw the the the function signature created a request for it and",
    "start": "1089179",
    "end": "1096080"
  },
  {
    "text": "then also kind of you know figured out that Brooklyn is in New York and then kind of structured the uh the string in",
    "start": "1096080",
    "end": "1101299"
  },
  {
    "text": "this way so it kind of figured all of this out so with this gbt has kind of expressing",
    "start": "1101299",
    "end": "1107179"
  },
  {
    "text": "intent to call a function now the next step is now it's on you to figure out how you actually want to call this function and so you have the return from",
    "start": "1107179",
    "end": "1114320"
  },
  {
    "text": "the function call um get current weather with this particular argument you can then execute it on your own it could be local kind of",
    "start": "1114320",
    "end": "1121760"
  },
  {
    "text": "running on your own web server it can be another extra another API in your systems could be an external API you could kind of call the weather.com API",
    "start": "1121760",
    "end": "1128179"
  },
  {
    "text": "and then let's say in this case we call something maybe an internal API and it returns with this output that you saw so",
    "start": "1128179",
    "end": "1134059"
  },
  {
    "text": "22 degrees Celsius and sunny given that output from the model you",
    "start": "1134059",
    "end": "1140419"
  },
  {
    "text": "start your third step in this process which is then calling the model calling GPT with the output of the function and",
    "start": "1140419",
    "end": "1147020"
  },
  {
    "text": "then seeing what GPT wants to do so in this case if you remember I was talking about the messages and this this",
    "start": "1147020",
    "end": "1152660"
  },
  {
    "text": "time the second request you're sending to the openai API um you're going to add a couple messages here so originally",
    "start": "1152660",
    "end": "1158419"
  },
  {
    "text": "there was just one message which was the what's the weather like in Brooklyn now you're adding two new messages that represent what happened with the",
    "start": "1158419",
    "end": "1164000"
  },
  {
    "text": "function call the first one is basically a rehash of the intents so you're basically saying the assistant or GPT",
    "start": "1164000",
    "end": "1169760"
  },
  {
    "text": "wanted to call the get current weather function with with this argument of Brooklyn New York",
    "start": "1169760",
    "end": "1175820"
  },
  {
    "text": "but then you're then you're also adding a third message which basically says the result of the function call that you had",
    "start": "1175820",
    "end": "1181160"
  },
  {
    "text": "so this is the result of get current weather and then you're inlining the kind of data that that is output here",
    "start": "1181160",
    "end": "1186980"
  },
  {
    "text": "which is the temperature 22 unit Celsius and description sunny and you pass that all to GPT",
    "start": "1186980",
    "end": "1193039"
  },
  {
    "text": "at this point then gbt takes in that input and decides you know what it wants to do at this point the model is now",
    "start": "1193039",
    "end": "1198380"
  },
  {
    "text": "smart enough to realize hey I'll call this function here's the output I actually have all the info I need to actually fulfill the request and so",
    "start": "1198380",
    "end": "1204740"
  },
  {
    "text": "it'll Now respond finally with text and it'll say the weather in Brooklyn is currently Sunny with a temperature of 22",
    "start": "1204740",
    "end": "1210140"
  },
  {
    "text": "degrees Celsius and so at that point you finally have",
    "start": "1210140",
    "end": "1215780"
  },
  {
    "text": "your your final output from GPT and then that's when you kind of respond to the user and so putting this all together",
    "start": "1215780",
    "end": "1220820"
  },
  {
    "text": "you end up getting um the experience that that uh you'd ideally like to have here which is a",
    "start": "1220820",
    "end": "1225860"
  },
  {
    "text": "user asked what's the weather like in Brooklyn today your server kind of thinks a little bit GPT expresses the",
    "start": "1225860",
    "end": "1231200"
  },
  {
    "text": "intent you do this whole three-step process calling out your function and then ultimately what the user sees is the weather in Brooklyn is currently",
    "start": "1231200",
    "end": "1237380"
  },
  {
    "text": "Sunny with a temperature of 22 degrees Celsius success",
    "start": "1237380",
    "end": "1243220"
  },
  {
    "text": "uh and so with that I wanted to hand it back to Eddie to talk through a couple more cool demos of what you can do with",
    "start": "1243220",
    "end": "1248240"
  },
  {
    "text": "function calling thank you Sharon so we just went through",
    "start": "1248240",
    "end": "1254120"
  },
  {
    "text": "a couple of uh introductory topics so first we learned about how language models work some of their limitations uh",
    "start": "1254120",
    "end": "1260900"
  },
  {
    "text": "in that they don't have all the training data they're not connected to the external World Etc the destructed output",
    "start": "1260900",
    "end": "1266660"
  },
  {
    "text": "is not always possible uh and Sherman also just walked us through the new feature function calling and how the API",
    "start": "1266660",
    "end": "1272480"
  },
  {
    "text": "works and how you pass functions to the API and get output back and get GPU to summarize the responses uh in a",
    "start": "1272480",
    "end": "1278539"
  },
  {
    "text": "user-facing way so let's walk through a few demos about how you can combine all of this and",
    "start": "1278539",
    "end": "1284120"
  },
  {
    "text": "apply it to your products and your applications so let's start uh small uh the first",
    "start": "1284120",
    "end": "1289340"
  },
  {
    "text": "example we'll walk through is something that converts natural language into queries the example we're going to do is",
    "start": "1289340",
    "end": "1294620"
  },
  {
    "text": "imagine you're building a data analytics app or a business intelligence tool like Tableau or Luca now some of you may be",
    "start": "1294620",
    "end": "1301340"
  },
  {
    "text": "good at SQL I certainly am not uh most often I just want to sort of like ask the database hey like who are those top",
    "start": "1301340",
    "end": "1308360"
  },
  {
    "text": "users and just have the response back that's finally possible today so we're going to use GPT we're going to",
    "start": "1308360",
    "end": "1314419"
  },
  {
    "text": "give it one function called SQL query all it takes is one parameter query a string there is supposed to be a valid",
    "start": "1314419",
    "end": "1321080"
  },
  {
    "text": "SQL string against our database so let's see how that works",
    "start": "1321080",
    "end": "1327039"
  },
  {
    "text": "so first we're going to give the model a system message describing it what it's supposed to do so we say your SQL GPT",
    "start": "1328520",
    "end": "1334820"
  },
  {
    "text": "and can convert natural language queries into SQL of course the model needs access to our database schema so in this",
    "start": "1334820",
    "end": "1340820"
  },
  {
    "text": "case we have two tables users and orders users have a name email and birthday orders have a user ID purchase amount",
    "start": "1340820",
    "end": "1347720"
  },
  {
    "text": "and purchase date now we can start querying the database with some natural language",
    "start": "1347720",
    "end": "1354460"
  },
  {
    "text": "so let's ask this question get me the names of the top 10 users by amount spent over the last week",
    "start": "1355280",
    "end": "1360679"
  },
  {
    "text": "fairly normal business question certainly not something I could write SQL for in a jiffy but GPT can so let's",
    "start": "1360679",
    "end": "1367580"
  },
  {
    "text": "run it so we can see that it's calling the SQL query function it has one parameter",
    "start": "1367580",
    "end": "1373640"
  },
  {
    "text": "query and it created a nice SQL query it's selecting the name and the sum of amount it's joining on orders it's",
    "start": "1373640",
    "end": "1381080"
  },
  {
    "text": "getting the last one week of orders ordering it by the total spent and limiting it to 10. seems correct and",
    "start": "1381080",
    "end": "1387980"
  },
  {
    "text": "appropriate so let's run it against our database",
    "start": "1387980",
    "end": "1392320"
  },
  {
    "text": "great we got some results back of course this is in a Json format and so not use a renderable",
    "start": "1397100",
    "end": "1403220"
  },
  {
    "text": "um let's send this back to GPT to see what it says",
    "start": "1403220",
    "end": "1407980"
  },
  {
    "text": "fantastic so GPT summarized the information and said these are the top 10 users by Mount spent this is what",
    "start": "1408640",
    "end": "1414380"
  },
  {
    "text": "they spent over the last week so Global Enterprises Vantage Partners etc etc and",
    "start": "1414380",
    "end": "1419539"
  },
  {
    "text": "this is a amazing user readable uh answer so we're going to say a quick",
    "start": "1419539",
    "end": "1424820"
  },
  {
    "text": "thank you to GPT for helping us out it's a bit cut off at the bottom but it says thanks and GPD says you're welcome so",
    "start": "1424820",
    "end": "1431440"
  },
  {
    "text": "fantastic so that's a quick way to see how totally natural language completely",
    "start": "1431440",
    "end": "1436520"
  },
  {
    "text": "natural language queries were converted into structured output into a valid SQL statement that we ran against our",
    "start": "1436520",
    "end": "1442159"
  },
  {
    "text": "database got data back summarized it back into natural language you could suddenly build data analytics apps off",
    "start": "1442159",
    "end": "1448400"
  },
  {
    "text": "of this you can build other internal tools I know honeycomb is here today and they recently built a very similar tool",
    "start": "1448400",
    "end": "1454220"
  },
  {
    "text": "for the honeycomb query language and had an amazing blog post which I enjoyed reading so that's one example of using",
    "start": "1454220",
    "end": "1462679"
  },
  {
    "text": "GPT and functions to convert natural language into queries",
    "start": "1462679",
    "end": "1467679"
  },
  {
    "text": "let's do a second demo this one is about calling external apis and multiple functions together so let's amp up the",
    "start": "1468020",
    "end": "1474380"
  },
  {
    "text": "complexity level let's say we're here at a conference in New York and we want to find dinner reservations for tonight",
    "start": "1474380",
    "end": "1481039"
  },
  {
    "text": "foreign we're going to call GPT with two functions the first one is get current location and that runs locally on device",
    "start": "1481039",
    "end": "1488299"
  },
  {
    "text": "let's say on your phone or on your browser and gets the latter long of where you are",
    "start": "1488299",
    "end": "1493520"
  },
  {
    "text": "and the second function here is yelpsearch which uses yelp's API sort of the popular restaurant review",
    "start": "1493520",
    "end": "1499100"
  },
  {
    "text": "application and you pass in the lap long and query so let's run through a demo",
    "start": "1499100",
    "end": "1506620"
  },
  {
    "text": "the system message in this case is fairly simple all it says is you're a personal assistant who is helpful at",
    "start": "1507740",
    "end": "1512780"
  },
  {
    "text": "fulfilling tasks so the user sort of puts upd into the almost mental mode of being a helpful assistant",
    "start": "1512780",
    "end": "1519320"
  },
  {
    "text": "and I say I'm at a conference and want to grab dinner nearby what are some options my company is expensing this so",
    "start": "1519320",
    "end": "1525080"
  },
  {
    "text": "we can go really fancy so let's turn that with GPT and see how",
    "start": "1525080",
    "end": "1531020"
  },
  {
    "text": "it can do so well of course GP doesn't know where we are so it says get current location um and we're going to call you know the",
    "start": "1531020",
    "end": "1537320"
  },
  {
    "text": "local API to get our Latin long and so we returned that that's Brooklyn New",
    "start": "1537320",
    "end": "1542360"
  },
  {
    "text": "York somewhere here I think so we'll give that back GPT and see what it says",
    "start": "1542360",
    "end": "1550059"
  },
  {
    "text": "great so it has the information it needs now it wants to call you out and it says lat long inquiry and it says Fine Dining",
    "start": "1550700",
    "end": "1556100"
  },
  {
    "text": "and that's good that's what I want and so let's uh call Yelp and get some",
    "start": "1556100",
    "end": "1561440"
  },
  {
    "text": "data back",
    "start": "1561440",
    "end": "1563860"
  },
  {
    "text": "great so we got a bunch of restaurants from yelp's uh API uh and I want a nice summary of course so let's run it again",
    "start": "1566480",
    "end": "1574279"
  },
  {
    "text": "and says here's some fancy dining options near your location um lavara Henry's and Colony Estuary uh",
    "start": "1574279",
    "end": "1582200"
  },
  {
    "text": "and and great and it says you know please check their opening hours and enjoy your meal sounds delicious so thank you GPT",
    "start": "1582200",
    "end": "1589220"
  },
  {
    "text": "yet again for helping organize dinner tonight so that's an example of using GPT and",
    "start": "1589220",
    "end": "1595640"
  },
  {
    "text": "functions to call external apis in this case the Yelp API as well as to coordinate multiple functions together",
    "start": "1595640",
    "end": "1602179"
  },
  {
    "text": "so it's capable with its reasoning ability to parse user intent and do multi-step actions one after another in",
    "start": "1602179",
    "end": "1608960"
  },
  {
    "text": "order to achieve the end goal a third demo let's ramp it up a little",
    "start": "1608960",
    "end": "1614720"
  },
  {
    "text": "bit more uh you know we talked about how gpd4 can pass the SAT and the GRE and if",
    "start": "1614720",
    "end": "1620720"
  },
  {
    "text": "it can it must be smarter than just calling the Yelp API or you know writing some SQL so let's put it to the test",
    "start": "1620720",
    "end": "1627860"
  },
  {
    "text": "um you know we're all Engineers uh you know we have many things to do every day and one of the uh one of the tasks that we",
    "start": "1627860",
    "end": "1634760"
  },
  {
    "text": "have to do is pull request review we have to review our co-workers code now don't tell my co-workers but it",
    "start": "1634760",
    "end": "1640580"
  },
  {
    "text": "would be awesome if GPT could help me out a little bit and make my workload a little bit lower uh so we're going to do",
    "start": "1640580",
    "end": "1646039"
  },
  {
    "text": "a demo of uh GPT that does pull request review sorry build your own engineer",
    "start": "1646039",
    "end": "1651740"
  },
  {
    "text": "the we only need one function submit comments uh it takes some code and returns a list of comments that it wants",
    "start": "1651740",
    "end": "1657260"
  },
  {
    "text": "to review so line numbers and comments uh and you can imagine we can this then send this out to the GitHub API or the",
    "start": "1657260",
    "end": "1662659"
  },
  {
    "text": "gitlab API and post a bunch of comments and of course you can add more functions and make it even more powerful down the",
    "start": "1662659",
    "end": "1669260"
  },
  {
    "text": "line so let's see how that works",
    "start": "1669260",
    "end": "1673240"
  },
  {
    "text": "in this case The Prompt is a little bit long so let's scroll up and see we're saying hey GPT you're a code",
    "start": "1675500",
    "end": "1680960"
  },
  {
    "text": "review bot you look at diffs and generate code review comments on the changes uh leave all code review comments with",
    "start": "1680960",
    "end": "1686720"
  },
  {
    "text": "corresponding line numbers we're also playing around with personality here we're saying 0 out of 10 on toxicity we",
    "start": "1686720",
    "end": "1693200"
  },
  {
    "text": "don't want that uh for fun let's try eight out of 10 on snark you know we've",
    "start": "1693200",
    "end": "1698539"
  },
  {
    "text": "all known a couple of Engineers who display these personalities uh and then two out of 10 on license let's just start there and then below here is a",
    "start": "1698539",
    "end": "1705500"
  },
  {
    "text": "some code that we want reviewed uh it's an API method in a SAS application that sorts changes permissions for a user",
    "start": "1705500",
    "end": "1712640"
  },
  {
    "text": "um let's run it let's see what GPT has to say about the code so give me three review comments",
    "start": "1712640",
    "end": "1718520"
  },
  {
    "text": "and we can see it called the submit comments function and it output is perfectly valid Json",
    "start": "1718520",
    "end": "1723919"
  },
  {
    "text": "and let's see what it says it says oh are we playing hide and seek now what happened when role is not in the body oh",
    "start": "1723919",
    "end": "1729679"
  },
  {
    "text": "you had a little twist there you're directly accessing the first item or casually committing to the DB session",
    "start": "1729679",
    "end": "1735020"
  },
  {
    "text": "are we okay that's a little bit rude we don't want that uh so let's let's fix",
    "start": "1735020",
    "end": "1740360"
  },
  {
    "text": "this uh I'm gonna exit out of this right now and go and change our prompt a little bit",
    "start": "1740360",
    "end": "1746419"
  },
  {
    "text": "um to do exit great and so in behind the",
    "start": "1746419",
    "end": "1751700"
  },
  {
    "text": "scenes what I'm doing is going back to the prompt I'm just changing those numbers um so taking uh",
    "start": "1751700",
    "end": "1758299"
  },
  {
    "text": "oh man I've got toxicity and then the next one it's not we're taking it back to zero we don't want that and let's be",
    "start": "1758299",
    "end": "1763640"
  },
  {
    "text": "polite so we're gonna make uh politeness 10 out of 10. and let's do give me three review comments again",
    "start": "1763640",
    "end": "1769520"
  },
  {
    "text": "and it's once again calling the functions with perfectly valid Json and it says oh it's nice to see you",
    "start": "1769520",
    "end": "1775279"
  },
  {
    "text": "retrieving the role value it says your error messages are need nicely descriptive I appreciate you committing",
    "start": "1775279",
    "end": "1780620"
  },
  {
    "text": "to your database changes good work uh now I would love somebody to review my code like this so thank you GPT and I",
    "start": "1780620",
    "end": "1787520"
  },
  {
    "text": "will exit so that's a quick third demo uh you know at its core it's still doing the same",
    "start": "1787520",
    "end": "1793220"
  },
  {
    "text": "thing it's calling one function you know given some prompt responding to it but what we're seeing at play is gpt's",
    "start": "1793220",
    "end": "1798980"
  },
  {
    "text": "reasoning ability GPT knows code it's seen thousands and millions of lines of code and it can give you good reviews uh",
    "start": "1798980",
    "end": "1805940"
  },
  {
    "text": "if you peel back some of this personality stuff it's actually giving it's pointing out typos it's pointing",
    "start": "1805940",
    "end": "1811399"
  },
  {
    "text": "out potential error cases in edge cases uh and so you know we're combining here",
    "start": "1811399",
    "end": "1816440"
  },
  {
    "text": "the advanced reasoning with daily tasks it's certainly very good at coding it's certainly very good at sort of you know",
    "start": "1816440",
    "end": "1822320"
  },
  {
    "text": "exams and but it's intelligence applies quite broadly and so it's really up to sort of like uh",
    "start": "1822320",
    "end": "1828860"
  },
  {
    "text": "you know the creativity of of uh developers to sort of take this and apply to as difficult tasks as possible",
    "start": "1828860",
    "end": "1834799"
  },
  {
    "text": "and sort of run the loops on that so that's a quick wrap up of our content",
    "start": "1834799",
    "end": "1840559"
  },
  {
    "text": "for today we covered three things first we talked about llms and their limitations uh we learned about how",
    "start": "1840559",
    "end": "1846919"
  },
  {
    "text": "evidence work their token predicting machines uh we learned about their limitations um you know they're stuck in time they",
    "start": "1846919",
    "end": "1853460"
  },
  {
    "text": "don't always output structured output um and uh",
    "start": "1853460",
    "end": "1858919"
  },
  {
    "text": "and so on uh we second we learned about this new feature function calling with GPT which is an update to our API and to",
    "start": "1858919",
    "end": "1865520"
  },
  {
    "text": "our models it allows the model to want Express intent about when it wants to call a function and to construct valid",
    "start": "1865520",
    "end": "1872539"
  },
  {
    "text": "arguments uh for you to then go call that function on on your end and then finally we work through some demos",
    "start": "1872539",
    "end": "1879440"
  },
  {
    "text": "now uh at some point I'm going to go productionize that PR thing and Sherman's my manager so don't don't tell",
    "start": "1879440",
    "end": "1885620"
  },
  {
    "text": "him I'm doing that excellent uh let me bring it back to where we",
    "start": "1885620",
    "end": "1890899"
  },
  {
    "text": "started we talked about this famous Steve Jobs quote about a computers being",
    "start": "1890899",
    "end": "1896120"
  },
  {
    "text": "a bicycle for the mind it's certainly been true for me it's certainly been true for all of you we're in the Computing industry computers have",
    "start": "1896120",
    "end": "1902000"
  },
  {
    "text": "changed our lives computers have augmented our abilities our innate abilities and given us more productivity more",
    "start": "1902000",
    "end": "1908419"
  },
  {
    "text": "imagination more creativity um and the AI and language models in charge",
    "start": "1908419",
    "end": "1915020"
  },
  {
    "text": "GPT is a baby it's only been around for a few months and it's up to us to sort",
    "start": "1915020",
    "end": "1920179"
  },
  {
    "text": "of augment the ai's mind and give it new abilities Beyond its inner reasoning abilities connected to tools connected",
    "start": "1920179",
    "end": "1926240"
  },
  {
    "text": "to apis and make really uh exciting applications out of out of this feature",
    "start": "1926240",
    "end": "1932240"
  },
  {
    "text": "uh now the original code is quite inspiring to me uh we we can never do justice uh to uh to a Steve Jobs code so",
    "start": "1932240",
    "end": "1939740"
  },
  {
    "text": "I'd love to play that video back to you uh right now",
    "start": "1939740",
    "end": "1944679"
  },
  {
    "text": "I remember uh reading an article when I was about 12 years old I think it might have been scientifically American where",
    "start": "1945080",
    "end": "1950600"
  },
  {
    "text": "they measured the efficiency of locomotion for all these species of planet Earth uh how many kilocalories",
    "start": "1950600",
    "end": "1956000"
  },
  {
    "text": "did they expand to get from point A to point B and the Condor one came into the",
    "start": "1956000",
    "end": "1961100"
  },
  {
    "text": "taco list uh surpassed everything else and humans came in about a third of the way down the list which was not such a",
    "start": "1961100",
    "end": "1967760"
  },
  {
    "text": "great showing for the crown of creation and uh but somebody there had the",
    "start": "1967760",
    "end": "1973159"
  },
  {
    "text": "imagination to test the efficiency of a human riding a bicycle human riding a bicycle blew away the",
    "start": "1973159",
    "end": "1979220"
  },
  {
    "text": "Condor all the way up the top of the list and it made a really big impression on me that we humans are tool Builders",
    "start": "1979220",
    "end": "1985399"
  },
  {
    "text": "and that we can fashion tools that amplify these inherent abilities that we",
    "start": "1985399",
    "end": "1990860"
  },
  {
    "text": "have to spectacular magnitudes and so for me a computer has always been a",
    "start": "1990860",
    "end": "1996440"
  },
  {
    "text": "bicycle of the Mind something that takes us far beyond our inherent abilities",
    "start": "1996440",
    "end": "2002019"
  },
  {
    "text": "and uh I think we're just at the early stages of this tool very early stages",
    "start": "2002019",
    "end": "2008380"
  },
  {
    "text": "and we've come only a very short distance and it's still in its formation but already we've seen enormous changes",
    "start": "2008380",
    "end": "2014919"
  },
  {
    "text": "I think that's nothing compared to what's coming the next hundred years as much as that applied to uh computers",
    "start": "2014919",
    "end": "2021820"
  },
  {
    "text": "50 years ago I think the same applies to AI today technology is in its infancy uh so we're",
    "start": "2021820",
    "end": "2028120"
  },
  {
    "text": "very very excited to see where it goes thank you [Applause]",
    "start": "2028120",
    "end": "2039589"
  },
  {
    "text": "I think we have some type of questions uh bo is around and helping us coordinate",
    "start": "2039820",
    "end": "2045960"
  },
  {
    "text": "cool thank you I'm looking forward to doing a lot less work in the future um I've got a question about",
    "start": "2046179",
    "end": "2052599"
  },
  {
    "text": "how you how we should cope with errors and failures and what strategies you",
    "start": "2052599",
    "end": "2058480"
  },
  {
    "text": "might suggest so taking your example where you built a SQL query what is the question that I asked results in chat",
    "start": "2058480",
    "end": "2065740"
  },
  {
    "text": "GPT giving a syntactically correct SQL query but semantically it's completely",
    "start": "2065740",
    "end": "2071919"
  },
  {
    "text": "off I'd only report back to my users something that's incorrect um it's hard to tell us a pulp here but",
    "start": "2071919",
    "end": "2078940"
  },
  {
    "text": "do you have any strategies you can suggest I'm coping with that yeah totally great question",
    "start": "2078940",
    "end": "2084099"
  },
  {
    "text": "um no I think the first thing is uh as a society and as users of these language models we kind of have to like learn its",
    "start": "2084099",
    "end": "2091658"
  },
  {
    "text": "limitations um almost sort of build antibodies around its limitations so there is a",
    "start": "2091659",
    "end": "2097060"
  },
  {
    "text": "little bit about like just knowing that hey the outputs might be inaccurate uh I think the second part is sort of like",
    "start": "2097060",
    "end": "2102460"
  },
  {
    "text": "opening the box one thing we do you know so we've integrated function calling in production uh with chart GPT we've",
    "start": "2102460",
    "end": "2109720"
  },
  {
    "text": "launched a product called plugins which basically does this at allows your GPD to talk to the internet and one",
    "start": "2109720",
    "end": "2116440"
  },
  {
    "text": "thing we do is all the requests and all the responses are uh visible to the end user if they so choose to see them so",
    "start": "2116440",
    "end": "2122740"
  },
  {
    "text": "that's sort of like helps with the information part um I personally say I think also SQL is",
    "start": "2122740",
    "end": "2127839"
  },
  {
    "text": "sort of like a very broad open surface area I think limiting it down to like well-known apis that only you know will",
    "start": "2127839",
    "end": "2133660"
  },
  {
    "text": "perform safe actions in your back end uh is a good way and so you can always get good error messages and things like",
    "start": "2133660",
    "end": "2140020"
  },
  {
    "text": "but uh those would be my like off the cuff tips but uh would love to like chat more as well",
    "start": "2140020",
    "end": "2147119"
  },
  {
    "text": "yeah hey great presentation thank you a couple of questions will hasn't been trying to blank game yet or will it work",
    "start": "2148960",
    "end": "2155740"
  },
  {
    "text": "linking or assume yes right uh Yes actually langjin Harrison and the team launched an integration an hour after",
    "start": "2155740",
    "end": "2161260"
  },
  {
    "text": "launch okay so it was yeah what about I mean it still exposes the leakage problem right",
    "start": "2161260",
    "end": "2166900"
  },
  {
    "text": "right like the SQL example is a good example yeah if somebody reads this and they don't ask about query against",
    "start": "2166900",
    "end": "2172900"
  },
  {
    "text": "Financial database and they're feeding it into the gpt35 turbo basically",
    "start": "2172900",
    "end": "2179380"
  },
  {
    "text": "they're leaking data right I don't think I fully followed the question could you uh repeat that part so you know I mean",
    "start": "2179380",
    "end": "2187000"
  },
  {
    "text": "as an expert there's these problems where if you're using about The DaVinci 3 or different models some of that data",
    "start": "2187000",
    "end": "2193720"
  },
  {
    "text": "from the query is turning into the model itself um so that example seems funny would be",
    "start": "2193720",
    "end": "2199839"
  },
  {
    "text": "extremely dangerous the um uh yeah so there's actually a",
    "start": "2199839",
    "end": "2205599"
  },
  {
    "text": "misconception that I think we haven't cleared up very well recently which is up until",
    "start": "2205599",
    "end": "2211240"
  },
  {
    "text": "um I think March or February this year we were actually in our terms of service for the API we were actually uh we we",
    "start": "2211240",
    "end": "2218200"
  },
  {
    "text": "said we were we reserved the right for ourselves to like train on the input data for the API um and I think that's probably what",
    "start": "2218200",
    "end": "2223839"
  },
  {
    "text": "you're talking about which like you're passing in some SQL queries and that'll actually find its way somehow back into the model as it returns yeah yeah yeah",
    "start": "2223839",
    "end": "2230140"
  },
  {
    "text": "yeah um in uh in February and I forgot the exact date but actually as of right now",
    "start": "2230140",
    "end": "2236079"
  },
  {
    "text": "we no longer do that so in our terms of service we actually do not train on your data in the API I think we haven't made it super clear and so people are very",
    "start": "2236079",
    "end": "2242020"
  },
  {
    "text": "paranoid about this and so um as of right now it doesn't because that's very important yeah yeah",
    "start": "2242020",
    "end": "2249579"
  },
  {
    "text": "yeah it's it's so you should look it up in our terms of service we don't train on it that being said the data is not",
    "start": "2249579",
    "end": "2254740"
  },
  {
    "text": "that's being passed in is not like Enterprise grade you know like we're not like isolating it like specific to your",
    "start": "2254740",
    "end": "2261280"
  },
  {
    "text": "user we're just not training it on our own data that type of feature around like data isolation at the Enterprise layer is obviously coming soon but that",
    "start": "2261280",
    "end": "2267940"
  },
  {
    "text": "that specific layer of security is not is not there yet yeah we do not train on API data",
    "start": "2267940",
    "end": "2275760"
  },
  {
    "text": "hey guys awesome presentation um quick question the demos that you showed were a little bit slow so I'm",
    "start": "2281440",
    "end": "2287740"
  },
  {
    "text": "wondering if you know you guys support you know parallelization the function",
    "start": "2287740",
    "end": "2293859"
  },
  {
    "text": "problem so like right now are using sequential you get us function six inch here back and then you've got to you",
    "start": "2293859",
    "end": "2299020"
  },
  {
    "text": "know call it but let's say you'll catch UT said three functions should be called simultaneously does that work yeah great",
    "start": "2299020",
    "end": "2306160"
  },
  {
    "text": "question the demos are slow because I had to voice over and also I was doing something there's a couple of time not",
    "start": "2306160",
    "end": "2311500"
  },
  {
    "text": "sleeps in there um uh so charge gbd the API literally does",
    "start": "2311500",
    "end": "2317020"
  },
  {
    "text": "not support multiple function invocation there's no output where it says hey call these three functions but you can hack",
    "start": "2317020",
    "end": "2322839"
  },
  {
    "text": "it uh the way you do it is you just Define one function which is you know call multiple and you provide a",
    "start": "2322839",
    "end": "2328540"
  },
  {
    "text": "signature where the model like calls multiple functions and it totally works you know at the end of the day it's",
    "start": "2328540",
    "end": "2333640"
  },
  {
    "text": "still we're using the model's reasoning ability to Output some text yeah",
    "start": "2333640",
    "end": "2338520"
  },
  {
    "text": "I I wanted to ask about and see in the SQL example you gave you give it some",
    "start": "2345760",
    "end": "2351760"
  },
  {
    "text": "table to have access to is there a way for us to just pre-load all of the context for any subsequent call by",
    "start": "2351760",
    "end": "2358420"
  },
  {
    "text": "anybody foreign sure what you're talking about here",
    "start": "2358420",
    "end": "2365500"
  },
  {
    "text": "there are a couple potential Solutions and let me know if this answers your question or not um we have a feature called a system",
    "start": "2365500",
    "end": "2371020"
  },
  {
    "text": "message that you can pass in which basically sets the like overall conversation context for a model",
    "start": "2371020",
    "end": "2376420"
  },
  {
    "text": "um and that's just really appended in the uh in the context and so we've been increasing the context window to",
    "start": "2376420",
    "end": "2382000"
  },
  {
    "text": "something like 16 000 tokens at this point so you can increasingly squeeze more and more things into the system",
    "start": "2382000",
    "end": "2387220"
  },
  {
    "text": "message and the model is actually trained we didn't talk about this today but the model is trained to be extra attentive to the system message to guide",
    "start": "2387220",
    "end": "2394359"
  },
  {
    "text": "how it reacts and so in this example Addie had like two table schemas in the system message you could foreseeably add",
    "start": "2394359",
    "end": "2399940"
  },
  {
    "text": "a lot more all the way up to you know kind of fill up the whole context okay so that would be how I would",
    "start": "2399940",
    "end": "2406020"
  },
  {
    "text": "yeah that's that's the simplest there are a couple other methods as well we I'd love to talk to you about it a little bit more afterwards you can like",
    "start": "2406740",
    "end": "2412660"
  },
  {
    "text": "you know hook it up to an external data data source a DB or something fine tuning is another option as well so",
    "start": "2412660",
    "end": "2418420"
  },
  {
    "text": "there are other things too thank you yeah",
    "start": "2418420",
    "end": "2422520"
  },
  {
    "text": "all right so I played around with integrating to",
    "start": "2425680",
    "end": "2433420"
  },
  {
    "text": "GDP where they are into a different software and I had the problem with",
    "start": "2433420",
    "end": "2439960"
  },
  {
    "text": "emails which are English typical but sometimes come in German or French when",
    "start": "2439960",
    "end": "2448000"
  },
  {
    "text": "I asked it for doing some drop in English hey in French or German this is also going to happen with this financial",
    "start": "2448000",
    "end": "2454480"
  },
  {
    "text": "API um yes unfortunately so the model is",
    "start": "2454480",
    "end": "2460119"
  },
  {
    "text": "prone to hallucination in the normal situation as well as in this situation",
    "start": "2460119",
    "end": "2465339"
  },
  {
    "text": "what we've done is basically fine tune the model so it's seen maybe a few hundred thousand examples of how to call",
    "start": "2465339",
    "end": "2470800"
  },
  {
    "text": "functions reliably so it's much better at it than you know any other prompting you might do yourself but it still makes",
    "start": "2470800",
    "end": "2477280"
  },
  {
    "text": "up parameters it might not put in valid Json it might output other languages and so to prevent that we're going to do",
    "start": "2477280",
    "end": "2484300"
  },
  {
    "text": "more fine tuning uh we have a couple of like sort of low level inference level techniques to to improve this as well",
    "start": "2484300",
    "end": "2489880"
  },
  {
    "text": "that we're exploring uh and then on your end you can do prompt engineering uh and just please remind the model do not",
    "start": "2489880",
    "end": "2496240"
  },
  {
    "text": "output German and I'm actually curious like it would be really interesting to see how if it's",
    "start": "2496240",
    "end": "2502660"
  },
  {
    "text": "gotten better at this especially if you have a function signature and you're explicitly listing out the like I don't know five different English genomes uh",
    "start": "2502660",
    "end": "2509500"
  },
  {
    "text": "my guess is it's probably the neural models are probably better but yeah Daddy said it won't be perfect I'd but",
    "start": "2509500",
    "end": "2514720"
  },
  {
    "text": "I'm not 100 sure we don't have evals for like cross English French uh enums unfortunately it's probably a good one",
    "start": "2514720",
    "end": "2520240"
  },
  {
    "text": "to think about but would be curious to see if it got better with us",
    "start": "2520240",
    "end": "2524760"
  },
  {
    "text": "hmm and uh thanks for the talk I have a question about the api's ability to",
    "start": "2529119",
    "end": "2537160"
  },
  {
    "text": "figure out the intent like is there a similar temperature parameters for the",
    "start": "2537160",
    "end": "2542560"
  },
  {
    "text": "function course so that if I pass in two functions with similar incomes what gbt",
    "start": "2542560",
    "end": "2548980"
  },
  {
    "text": "determine uh deterministic for each function to go or is there any",
    "start": "2548980",
    "end": "2554260"
  },
  {
    "text": "randomness of picking any which function to talk if I ask the uh multiple times",
    "start": "2554260",
    "end": "2562420"
  },
  {
    "text": "uh there is still Randomness so at the end of the day under the hood it's still sort of like um you know uh outputting token by token",
    "start": "2562420",
    "end": "2569800"
  },
  {
    "text": "uh choosing which function it wants to call and so lowering the temperature increases determinism but it does it",
    "start": "2569800",
    "end": "2574839"
  },
  {
    "text": "does not guarantee it that said there is a parameter in the API called function call where if you know which function",
    "start": "2574839",
    "end": "2581500"
  },
  {
    "text": "you wanted to call you can actually just specify it up front and it will definitely call that function yeah",
    "start": "2581500",
    "end": "2587079"
  },
  {
    "text": "thanks I was curious",
    "start": "2587079",
    "end": "2595200"
  },
  {
    "text": "um do you guys have entitlements like for the function calls if we wanted to limit certain users from certain",
    "start": "2596260",
    "end": "2602020"
  },
  {
    "text": "function calls or like which tables they could access in those SQL queries but are people still like needing to",
    "start": "2602020",
    "end": "2608619"
  },
  {
    "text": "implement their own um all of that would happen on your servers because you have sort of the",
    "start": "2608619",
    "end": "2613780"
  },
  {
    "text": "full context of who has access to what um all that this API provides is sort of",
    "start": "2613780",
    "end": "2619720"
  },
  {
    "text": "the ability for GPT to like age choose which function to call and what parameters to use but then we expect",
    "start": "2619720",
    "end": "2625960"
  },
  {
    "text": "that you should read gpt's output as any other client so untrusted client output that you would validate on your end with",
    "start": "2625960",
    "end": "2632500"
  },
  {
    "text": "permissions and stuff yeah that makes sense",
    "start": "2632500",
    "end": "2636960"
  },
  {
    "text": "I was just wondering if you could sort of perhaps elaborate on what's going on under the hood here is this is this",
    "start": "2641680",
    "end": "2647440"
  },
  {
    "text": "Chain of Thought prompting under the hood is this effectively a a an API",
    "start": "2647440",
    "end": "2652599"
  },
  {
    "text": "layer on top of those techniques yeah great question so Chain of Thought prompting for for those unfamiliar uh is",
    "start": "2652599",
    "end": "2659079"
  },
  {
    "text": "a way to ask the model when given a task hey first tell me what you're going to",
    "start": "2659079",
    "end": "2665020"
  },
  {
    "text": "do and then go do it um so if you say what's the weather like in Brooklyn it might say I have been asked a weather request I am",
    "start": "2665020",
    "end": "2671920"
  },
  {
    "text": "going to call the weather API and then it goes and does that so that's a prompt engineering technique this is a fine",
    "start": "2671920",
    "end": "2677440"
  },
  {
    "text": "tune um so with the launch of plugins a few months ago we've collected both internal",
    "start": "2677440",
    "end": "2682540"
  },
  {
    "text": "and external data maybe a few hundred thousand examples of user questions and function calls and so this is all",
    "start": "2682540",
    "end": "2688599"
  },
  {
    "text": "fine-tuned into the model and that's where it's coming from there's a third technique that we can use which is called constraint sampling where the",
    "start": "2688599",
    "end": "2695859"
  },
  {
    "text": "token sampling level you make sure that you know the next token that is being predicted is one of a valid set so in a",
    "start": "2695859",
    "end": "2702520"
  },
  {
    "text": "Json example you know after a comma you know it has to be a new line or something like that you might be getting that wrong but you",
    "start": "2702520",
    "end": "2708460"
  },
  {
    "text": "know you get the ideas you have a grammar that you know you want to assign it yourself to we don't have that yet uh",
    "start": "2708460",
    "end": "2714339"
  },
  {
    "text": "it's an area that we're exploring but this is sort of the long journey to from prompting to fine-tuning to more",
    "start": "2714339",
    "end": "2720400"
  },
  {
    "text": "low-level stuff uh making this is the journey to getting GPT to Output reliably structured data",
    "start": "2720400",
    "end": "2728338"
  },
  {
    "text": "so the idea is I don't I want to constrain the information based on what I fed into",
    "start": "2733359",
    "end": "2739300"
  },
  {
    "text": "a vector database so it doesn't but it still work with the function logic yes brilliant well it's exactly as it used",
    "start": "2739300",
    "end": "2745540"
  },
  {
    "text": "to yeah thank you all right one last question",
    "start": "2745540",
    "end": "2752740"
  },
  {
    "text": "are we able to use it today or is it open to public right now so",
    "start": "2752740",
    "end": "2758800"
  },
  {
    "text": "um this is uh publicly available today with a caveat um so it's available on the GPT 3.5",
    "start": "2758800",
    "end": "2765099"
  },
  {
    "text": "turbo model so anyone here can actually access function calling with gpd3 run5",
    "start": "2765099",
    "end": "2770680"
  },
  {
    "text": "turbo because that's generally available it's also available on gpt4 on the API but unfortunately that is still behind a wait list and so if you are uh off that",
    "start": "2770680",
    "end": "2778599"
  },
  {
    "text": "weight listen you have access to gpt4 API you will actually be able to do this with GPD Sports it's way better at it it is a little slower but if you are still",
    "start": "2778599",
    "end": "2785740"
  },
  {
    "text": "on the waitlist or you don't have access to gpd4 API you can try this out today uh on GPD 3.5 Turbo",
    "start": "2785740",
    "end": "2793140"
  },
  {
    "text": "this is for seconds we just saw bicycle of Ami",
    "start": "2793960",
    "end": "2799359"
  },
  {
    "text": "I'm really happy that as a developers we're now being replaced right now",
    "start": "2799359",
    "end": "2805920"
  },
  {
    "text": "okay so uh let's give a random call for sure when [Applause]",
    "start": "2806280",
    "end": "2814630"
  }
]
[
  {
    "text": "howdy folks I'm Jeff let's talk about taking deep learning models from",
    "start": "4040",
    "end": "9469"
  },
  {
    "text": "research to production so I am Jeff I work at Facebook where we developed PI",
    "start": "9469",
    "end": "16880"
  },
  {
    "text": "torch really as a tool to solve our problems but we did it in the open and now we have this great open source",
    "start": "16880",
    "end": "22880"
  },
  {
    "text": "project that I want to share with you and so it's a it's a big and a complex",
    "start": "22880",
    "end": "28130"
  },
  {
    "text": "space to understand what all can you do with in deep learning and how do you get navigated so here's my idea of a map to",
    "start": "28130",
    "end": "34430"
  },
  {
    "text": "how we can get started in this conversation I really want to be focused on your productivity is as a developer",
    "start": "34430",
    "end": "39829"
  },
  {
    "text": "and I'm gonna presume that some of you have never used PI torch before and it possibly never used a deep learning",
    "start": "39829",
    "end": "46960"
  },
  {
    "text": "framework or done machine learning before but I really want to dive into what are the tools and and and parts of",
    "start": "46960",
    "end": "53930"
  },
  {
    "text": "an ecosystem that you can take advantage of to help you be productive and I really want to focus on some of the concerns that a mature software engineer",
    "start": "53930",
    "end": "60890"
  },
  {
    "text": "with a relevant experience is gonna have and so here's my map to what we're gonna do I really the theme here is around",
    "start": "60890",
    "end": "66290"
  },
  {
    "text": "that journey from research mode all the way out to production and I'll talk about what exactly I mean by that a",
    "start": "66290",
    "end": "72950"
  },
  {
    "text": "little bit later all right so to begin under just give a brief introduction to",
    "start": "72950",
    "end": "78020"
  },
  {
    "text": "why we at Facebook invest in AI I you can see it all over our products whether or not you recognize it as a is or not",
    "start": "78020",
    "end": "84230"
  },
  {
    "text": "these are things like translation which help you connect with people who you don't share a language with some of our",
    "start": "84230",
    "end": "90530"
  },
  {
    "text": "AR FX and spark AR our ability to build computer vision models for virtual",
    "start": "90530",
    "end": "96080"
  },
  {
    "text": "reality and oculus products and in all sorts of other ways in which we we use different forms of AI technology and the",
    "start": "96080",
    "end": "102680"
  },
  {
    "text": "example there from blood donations is a social good initiative that is powered by natural language understanding technology so to do that we need to",
    "start": "102680",
    "end": "110990"
  },
  {
    "text": "invest in some technology that really can handle our scale so our AI platform",
    "start": "110990",
    "end": "116270"
  },
  {
    "text": "runs over 400 trillion predictions a day and that number is is climbing rapidly",
    "start": "116270",
    "end": "122470"
  },
  {
    "text": "which means that it's also deployed on over a billion phones around the world and so this is every time a neural",
    "start": "122470",
    "end": "127910"
  },
  {
    "text": "network on your devices is using part of our technology to perform a prediction operation so what's the technology",
    "start": "127910",
    "end": "134989"
  },
  {
    "text": "underneath that well that's pi torch so if you've not encountered PI torch",
    "start": "134989",
    "end": "140250"
  },
  {
    "text": "before I want to be a little bit more specific about who we are and what our opinions are and and really the places",
    "start": "140250",
    "end": "146579"
  },
  {
    "text": "we invest in building technology to make you productive I want to start with eager and graph-based execution so this",
    "start": "146579",
    "end": "154079"
  },
  {
    "text": "has to deal with how you is the user write your code and so eager mode means Python as you would normally write it",
    "start": "154079",
    "end": "160440"
  },
  {
    "text": "returning back a results just as soon as you invoke a function and I'll show you",
    "start": "160440",
    "end": "166140"
  },
  {
    "text": "a little bit more about some of our investment in graph based execution on up as a project and and how that works",
    "start": "166140",
    "end": "171599"
  },
  {
    "text": "for you and what that workflow looks like I historically we've we've we've",
    "start": "171599",
    "end": "177299"
  },
  {
    "text": "had a lot of innovative techniques come out of work done in PI torch due to our ability to support dynamic neural networks by which I mean neural networks",
    "start": "177299",
    "end": "184379"
  },
  {
    "text": "which contain control flow if statements that are defined by you in regular Python also one of the reasons where you",
    "start": "184379",
    "end": "192420"
  },
  {
    "text": "might want to use the deep learning framework to implement your solution to a particular technology is that you need to operate over a distributed system you",
    "start": "192420",
    "end": "199440"
  },
  {
    "text": "need a cluster of machines somewhere and so we have a very powerful distributed training library called CMD that can",
    "start": "199440",
    "end": "206430"
  },
  {
    "text": "handle doing really awesome stuff across clusters of GPU enabled servers other",
    "start": "206430",
    "end": "212459"
  },
  {
    "text": "things you might need out of a deep learning framework include hardware accelerated inference and so this means",
    "start": "212459",
    "end": "217709"
  },
  {
    "text": "when you're performing a prediction in real-time to be depending on what you're",
    "start": "217709",
    "end": "222989"
  },
  {
    "text": "trying to do you may really care about taking the best advantage of the CPU or GPU underlying your program and doing",
    "start": "222989",
    "end": "230609"
  },
  {
    "text": "that really well involves a lot of open collaboration between organizations like Facebook Intel Nvidia and so forth and",
    "start": "230609",
    "end": "238919"
  },
  {
    "text": "finally just to ground you in how we think about how we write software within the PI torch project we really prefer",
    "start": "238919",
    "end": "245699"
  },
  {
    "text": "simplicity over complexity we want you to be able to do things in writing your code that you are what you were already",
    "start": "245699",
    "end": "251549"
  },
  {
    "text": "naturally going to do so right Python is you would write Python look like numpy when you're doing something that you",
    "start": "251549",
    "end": "257099"
  },
  {
    "text": "would otherwise be doing an umpire and be very modular and opt in okay so",
    "start": "257099",
    "end": "262919"
  },
  {
    "text": "getting a little bit more concrete what are some of those pieces when we start to look at PI toward a developer level",
    "start": "262919",
    "end": "269490"
  },
  {
    "text": "I'm going to go back if I can figure out how to go back there we go",
    "start": "269490",
    "end": "276440"
  },
  {
    "text": "okay sorry there we go so this is just a little bit of a high-level map to some of the pieces you",
    "start": "276800",
    "end": "283230"
  },
  {
    "text": "might use within the PI torch library most people start within PI torch because they're they're interested in",
    "start": "283230",
    "end": "289830"
  },
  {
    "text": "solving some problem with deep learning and so that's where all of our neural network capabilities in the NM module are come into play I'm going to spend a",
    "start": "289830",
    "end": "296460"
  },
  {
    "text": "lot of time today talking about our JIT it's called torch script and this is really one of our major investments in",
    "start": "296460",
    "end": "303510"
  },
  {
    "text": "terms of our engineering focused in building a path from research to production there's a lot more built into",
    "start": "303510",
    "end": "309360"
  },
  {
    "text": "PI torch whether it's within the core or within other libraries and in the ecosystem you can see some of them there",
    "start": "309360",
    "end": "315000"
  },
  {
    "text": "and I'll talk a bit more about some of them later but it's really it's designed",
    "start": "315000",
    "end": "320070"
  },
  {
    "text": "to be a very big toolbox to support a broad range of things I want to get some code up though just to give you a feel",
    "start": "320070",
    "end": "325680"
  },
  {
    "text": "for what does PI torch code look like if you've not done deep learning before this is I'm gonna be fairly quick and",
    "start": "325680",
    "end": "332130"
  },
  {
    "text": "just showing what are the basics of the code so first we need to define what is the neural network here using the NN",
    "start": "332130",
    "end": "339660"
  },
  {
    "text": "module this gets us started right out of the gate we need to initiate our module we're defining a forward pass so that is",
    "start": "339660",
    "end": "347700"
  },
  {
    "text": "the computation we want to do in our inference operation here you can see the use of some pre-built layers real low",
    "start": "347700",
    "end": "354240"
  },
  {
    "text": "dropout sigmoid so forth showing",
    "start": "354240",
    "end": "359430"
  },
  {
    "text": "different parts of how you work with data us more out-of-the-box functionality here you can see a data",
    "start": "359430",
    "end": "366780"
  },
  {
    "text": "loader here which is an abstraction which allows you to manage various datasets and you can see a pre-built data set being brought in from their",
    "start": "366780",
    "end": "373170"
  },
  {
    "text": "torch vision package which is built to serve computer vision use cases in this case M NIST and you can see an optimizer",
    "start": "373170",
    "end": "379290"
  },
  {
    "text": "as well stochastic gradient descent all of those library standard functionality and then here's a training loop and so",
    "start": "379290",
    "end": "386850"
  },
  {
    "text": "what we're going to do is we're going to iterate over each of our instances and then you can see the steps that we have to go out there so we're going to zero",
    "start": "386850",
    "end": "393120"
  },
  {
    "text": "out our gradient we're going to apply the forward pass within our neural network we're going to apply our loss",
    "start": "393120",
    "end": "398190"
  },
  {
    "text": "function call backwards on that and then move forward in our optimization and then you can see some",
    "start": "398190",
    "end": "403710"
  },
  {
    "text": "checkpointing functionality there with torch not safe it's a really simple high-level example of kind of common",
    "start": "403710",
    "end": "408900"
  },
  {
    "text": "neural network code not a lot of high torch specifics here I'll show a little bit more of a in-depth view of what the",
    "start": "408900",
    "end": "415169"
  },
  {
    "text": "specifics of how you work with pi torch are in an example a little bit later but I want to frame that example within the",
    "start": "415169",
    "end": "421830"
  },
  {
    "text": "context of the journey from research to production and so if you're not",
    "start": "421830",
    "end": "427139"
  },
  {
    "text": "experienced within the field of machine learning parts of this workflow may not be something that you've seen in quite",
    "start": "427139",
    "end": "433020"
  },
  {
    "text": "this variant before but if you do have experience in building and I'll projects and products you will recognize a lot of",
    "start": "433020",
    "end": "439410"
  },
  {
    "text": "the commonalities to what I want to show here and so this is a very high-level view of how do we take something from",
    "start": "439410",
    "end": "446639"
  },
  {
    "text": "from an idea all the way out to real use case so first that we would start off with some high-level plan right we're",
    "start": "446639",
    "end": "452400"
  },
  {
    "text": "gonna determine our approach to a given problem we're trying to solve a deep learning our next and sometimes hardest",
    "start": "452400",
    "end": "459000"
  },
  {
    "text": "problem is preparing the data this is this is where it's nice to have at least like pre-built data to get started if",
    "start": "459000",
    "end": "466050"
  },
  {
    "text": "you're trying to establish a technique or a data loader to manage your existing data that you may have and then we can",
    "start": "466050",
    "end": "472080"
  },
  {
    "text": "do the part that I run things about when they think about machine learning deep learning in general so that's build and train a model so that's that example",
    "start": "472080",
    "end": "477930"
  },
  {
    "text": "code I showed just previously and that's an important step but this next step is",
    "start": "477930",
    "end": "484560"
  },
  {
    "text": "one that people don't often talk about a lot and this is transferring a model out to production so just because we've",
    "start": "484560",
    "end": "489630"
  },
  {
    "text": "trained a model all we have right now is is an object in memory may be an artifact on disk there's some additional",
    "start": "489630",
    "end": "495870"
  },
  {
    "text": "step that means we need to take to be able to publish that out to get it out into the real world of production because we need to deploy this in some",
    "start": "495870",
    "end": "503280"
  },
  {
    "text": "live mode and be able to scale it whatever that means for your application high level conceptual view comment of a",
    "start": "503280",
    "end": "510450"
  },
  {
    "text": "lot of ML workflows and and what I want to call out is that four steps really really a very difficult one and that's",
    "start": "510450",
    "end": "517740"
  },
  {
    "text": "very much been our experience inside Facebook AI we've seen a ton of pain in trying to build a tool train that it",
    "start": "517740",
    "end": "522870"
  },
  {
    "text": "supports a productive workflow to go from beginning to end getting stuck at that transferring from",
    "start": "522870",
    "end": "528370"
  },
  {
    "text": "model to production and so we want to do everything we can to remove that step by",
    "start": "528370",
    "end": "534400"
  },
  {
    "text": "creating an end and tool chain that supports being able to author a model in the same framework that you can then",
    "start": "534400",
    "end": "540100"
  },
  {
    "text": "deploy it out to production I want to be more concrete about what I mean by",
    "start": "540100",
    "end": "545950"
  },
  {
    "text": "production and so we as a project think of production in a couple of these properties here one of them is hardware",
    "start": "545950",
    "end": "552400"
  },
  {
    "text": "efficiency there's some very non-trivial aspects of getting truly state-of-the-art performance on CPUs",
    "start": "552400",
    "end": "558640"
  },
  {
    "text": "GPUs domain-specific architectures like TP use and Asics scalability and so this",
    "start": "558640",
    "end": "566830"
  },
  {
    "text": "is really being able to run across a whole cluster and being able to operate at extremely high throughput rates",
    "start": "566830",
    "end": "572670"
  },
  {
    "text": "there's some really fun and hard engineering problems here as well",
    "start": "572670",
    "end": "577710"
  },
  {
    "text": "platform constraints so we want to deploy neural networks to more than a billion phones we also want to deploy",
    "start": "578250",
    "end": "584500"
  },
  {
    "text": "them to state-of-the-art servers and so there are different challenges there and if you and if your production spans both",
    "start": "584500",
    "end": "592240"
  },
  {
    "text": "of those things neural networks running at massive scale on a server as well as running on tiny devices then you need a",
    "start": "592240",
    "end": "598360"
  },
  {
    "text": "tool chain that supports those things finally reliability and this is gets",
    "start": "598360",
    "end": "603880"
  },
  {
    "text": "into the scalability and reliability component here large scale machine learning is an extraordinarily compute",
    "start": "603880",
    "end": "610120"
  },
  {
    "text": "intensive job and it involves potentially thousands of GPUs operating",
    "start": "610120",
    "end": "615400"
  },
  {
    "text": "at the same time which has real-world cost in terms of energy and in terms of span for your organization and so these",
    "start": "615400",
    "end": "621760"
  },
  {
    "text": "are the things we think about when building out our production tool chain so I want to talk about one piece of",
    "start": "621760",
    "end": "627310"
  },
  {
    "text": "that production tool chain and that's torch script torch JIT and so what we",
    "start": "627310",
    "end": "633160"
  },
  {
    "text": "want to do with torch script is to be able to power your transition from going from research to production we want you",
    "start": "633160",
    "end": "639550"
  },
  {
    "text": "to be able to experiment and then extract out torch script from your Python program which can then be",
    "start": "639550",
    "end": "645610"
  },
  {
    "text": "optimized and deployed in to production I'm going to show you a fairly detailed working code here but the the key point",
    "start": "645610",
    "end": "653500"
  },
  {
    "text": "here is this is about extracting out that information from code you author yourself not adapting your programming",
    "start": "653500",
    "end": "659410"
  },
  {
    "text": "model to fit ours so what this looks like is in what we",
    "start": "659410",
    "end": "665330"
  },
  {
    "text": "call eager mode this is PI torches that has always been immediately returning out results as you would do in a normal",
    "start": "665330",
    "end": "671000"
  },
  {
    "text": "Python program you can prototype you can train your modeling and run these experiments and then you have these two",
    "start": "671000",
    "end": "676370"
  },
  {
    "text": "paths to make this transition out to script mode and so one way that I'm",
    "start": "676370",
    "end": "681470"
  },
  {
    "text": "going to show you is to use the script annotation there you also have the ability to trace they have sort of different properties and you know the",
    "start": "681470",
    "end": "687980"
  },
  {
    "text": "only way to work through it is just have a live code example so we'll do that next and we're going to do that on collab a quick call out to collab call a",
    "start": "687980",
    "end": "695180"
  },
  {
    "text": "bizarre service provided by google cloud when the PI for each project have collaborated with that team to bring the",
    "start": "695180",
    "end": "700700"
  },
  {
    "text": "best of Pi torch to Google cloud on on collab and so I'm going to show you that live in a in a browser window right now",
    "start": "700700",
    "end": "708580"
  },
  {
    "text": "give me one second to mirror okay so let",
    "start": "709540",
    "end": "715970"
  },
  {
    "text": "us maybe get a bit bigger that's that bigger sound good alright maybe good",
    "start": "715970",
    "end": "723740"
  },
  {
    "text": "yeah bigger okay so this is collab if",
    "start": "723740",
    "end": "731570"
  },
  {
    "text": "you've never seen it it's a hosted notebook collect service provided by a Google cloud it gives you free access to",
    "start": "731570",
    "end": "737709"
  },
  {
    "text": "CPUs GPUs and TP use I just take connect I'm going to hang out the cloud it's",
    "start": "737709",
    "end": "743720"
  },
  {
    "text": "gonna initialize and can see its allocated me a server and have the ability to choose the different properties there I'm gonna go ahead and",
    "start": "743720",
    "end": "749930"
  },
  {
    "text": "run all of this code here live so you can see none of its been executed yet but I'm just gonna run it all to to speed our walk through of what this code",
    "start": "749930",
    "end": "756830"
  },
  {
    "text": "is so one of the great parts of working with the Google team on this is this",
    "start": "756830",
    "end": "762470"
  },
  {
    "text": "just has this incredible impact on your ability to get started you can import torch right away in an environment that",
    "start": "762470",
    "end": "768290"
  },
  {
    "text": "supports it the box running the latest version of Pi torch and get started and so that succeeded so we just import",
    "start": "768290",
    "end": "774829"
  },
  {
    "text": "torch and so let's get started learning about torch script in the path to production alright so here's a very",
    "start": "774829",
    "end": "780740"
  },
  {
    "text": "simple example of a cell so that what we're using here is the nm module capabilities and we are defining a",
    "start": "780740",
    "end": "787310"
  },
  {
    "text": "simple initialization function and we're going to define what is our forward pass in this case just a simple tanning",
    "start": "787310",
    "end": "793310"
  },
  {
    "text": "and so you can see the result of that and this is the the basics of what we might do here and we're just showing our",
    "start": "793310",
    "end": "798500"
  },
  {
    "text": "results it looks a lot like the code I showed you before I'm gonna eat irate on this a little bit and so this case what",
    "start": "798500",
    "end": "804500"
  },
  {
    "text": "we're gonna show is in C we'll use this",
    "start": "804500",
    "end": "809630"
  },
  {
    "text": "function here we're gonna use a linear construct a linear allows us to hierarchically compose our uh power our",
    "start": "809630",
    "end": "816440"
  },
  {
    "text": "neural network and again we can do that in eager mode step-by-step we can just add in new new elements to our to our",
    "start": "816440",
    "end": "824210"
  },
  {
    "text": "neural architecture ok now let's get really fun and this is kind of the heart",
    "start": "824210",
    "end": "830660"
  },
  {
    "text": "of the thing here this new thing is a decision gate and so this is conditional logic and so we want to say if in some",
    "start": "830660",
    "end": "837830"
  },
  {
    "text": "cases the sum of this operation is greater than 0 we want to do one thing otherwise when I do something else and",
    "start": "837830",
    "end": "842930"
  },
  {
    "text": "this is where we get into your flexibility as a developer and your ability to have dynamic neural networks",
    "start": "842930",
    "end": "848240"
  },
  {
    "text": "that do different things based on the input they see this is a really powerful capability and it's a foundational",
    "start": "848240",
    "end": "853970"
  },
  {
    "text": "technique to a lot of the most exciting work going on in deep learning today so",
    "start": "853970",
    "end": "859490"
  },
  {
    "text": "now can we use that within our linear structure well the answer is yes yes we",
    "start": "859490",
    "end": "864500"
  },
  {
    "text": "can we're able to do it you can see the representation that that's produced here our linear contains this this new",
    "start": "864500",
    "end": "869930"
  },
  {
    "text": "function here again fully an eager mode here and so there's just Python as as you would normally do it that was",
    "start": "869930",
    "end": "875480"
  },
  {
    "text": "returned to you you were able to get that immediately and here's a little",
    "start": "875480",
    "end": "880790"
  },
  {
    "text": "graphic calling out why that's important it's because we're not requiring a full program to be able to do useful things",
    "start": "880790",
    "end": "886520"
  },
  {
    "text": "like define the backward function and perform automatic differentiation we're building that graph on the fly every",
    "start": "886520",
    "end": "892370"
  },
  {
    "text": "time you in eager mode pass out a new operation of some sort and we can",
    "start": "892370",
    "end": "897709"
  },
  {
    "text": "compute those gradients with whatever graph we have the technique here is is it goes by the name of tape-based",
    "start": "897709",
    "end": "903080"
  },
  {
    "text": "auto-da-f√© and which by which we mean we're we're not performing the same sort",
    "start": "903080",
    "end": "909709"
  },
  {
    "text": "of symbolic representation that you would do in a graph mode only in fact",
    "start": "909709",
    "end": "916339"
  },
  {
    "text": "we're just replaying each individual argument so that we can perform differentiation at any point this is what powers eager mode and this was",
    "start": "916339",
    "end": "922850"
  },
  {
    "text": "makes eager mode work so powerfully in workflows so let's talk about why we",
    "start": "922850",
    "end": "929579"
  },
  {
    "text": "would jump over into torch script mode so eager mode is great for being able to",
    "start": "929579",
    "end": "935009"
  },
  {
    "text": "author models but we want to be able to get power get the power of our production tool change so we're ready to",
    "start": "935009",
    "end": "940889"
  },
  {
    "text": "make that transition that's where we're at in our development workflow here we can see how we can trace a model here so",
    "start": "940889",
    "end": "948990"
  },
  {
    "text": "this is this is the simplified one again this is just my cell it doesn't have any of that conditional logic in it it's a",
    "start": "948990",
    "end": "954690"
  },
  {
    "text": "simple pass through this could be done in in a in a sort of eager mode or it",
    "start": "954690",
    "end": "960300"
  },
  {
    "text": "could be done in graph mode and so what we've done here is you can see this call to torch it trace that's what allowed us",
    "start": "960300",
    "end": "966300"
  },
  {
    "text": "to extract out what is the computation graph of this particular neural network",
    "start": "966300",
    "end": "972420"
  },
  {
    "text": "by putting in a given input seeing what the neural network did and then recording that out as a graph using",
    "start": "972420",
    "end": "978420"
  },
  {
    "text": "torch script that works great if in fact you have no dynamic control flow but",
    "start": "978420",
    "end": "985290"
  },
  {
    "text": "what pi torch has always promised is that you do get access to that dynamic control flow mm-hmm oh sorry before we",
    "start": "985290",
    "end": "991170"
  },
  {
    "text": "get to that topic I want to show you just briefly what did we extract so here's a trace cells graph you can see",
    "start": "991170",
    "end": "996209"
  },
  {
    "text": "the actual internal representation this is a torch script I are here the intermediate representation it shows us",
    "start": "996209",
    "end": "1002839"
  },
  {
    "text": "what is our computation graph as the run time understands it it's not the most readable thing in the world in a",
    "start": "1002839",
    "end": "1009500"
  },
  {
    "text": "presentation like this so I'll show you what it looks like if we map it back out to more pythonic code representation and",
    "start": "1009500",
    "end": "1016699"
  },
  {
    "text": "so you can see here it's pretty simple here we can see what are the operations we call the 80mm optimizer you can see",
    "start": "1016699",
    "end": "1022519"
  },
  {
    "text": "the 10h application pretty straightforward readable Python code if you want to understand what is what is",
    "start": "1022519",
    "end": "1027798"
  },
  {
    "text": "torch script extracting for your program and it did all that without requiring you to do anything other than say trace it all right it's probably a good time",
    "start": "1027799",
    "end": "1037819"
  },
  {
    "text": "to talk about like why would you want to extract out torch script briefly the things that we care about is that by",
    "start": "1037819",
    "end": "1044928"
  },
  {
    "text": "extracting out that that graph we now have a language independent representation of what is the",
    "start": "1044929",
    "end": "1050690"
  },
  {
    "text": "computation you want to prove and so we can do certain things with it like right optimization passes that can",
    "start": "1050690",
    "end": "1056510"
  },
  {
    "text": "help your performance it also allows us to export out to deployment environments they don't have Python in them and so",
    "start": "1056510",
    "end": "1066490"
  },
  {
    "text": "it's worth showing that when we do that our trace representation are our torch",
    "start": "1066490",
    "end": "1072320"
  },
  {
    "text": "script extracted version does precisely the same thing on the same inputs as as your original program did we've",
    "start": "1072320",
    "end": "1078590"
  },
  {
    "text": "extracted out a new program from that the computational graph but you can see here from ours when you call my cell",
    "start": "1078590",
    "end": "1084320"
  },
  {
    "text": "you've invoked in eager mode when you call trace cell you're operating on the",
    "start": "1084320",
    "end": "1089900"
  },
  {
    "text": "computation graph that we has been extracted exactly the same results so",
    "start": "1089900",
    "end": "1095840"
  },
  {
    "text": "let's let's do the fun part and I've been I've been eager to get to this part and so let's let's actually deal with control flow so if we have control flow",
    "start": "1095840",
    "end": "1103610"
  },
  {
    "text": "like this and we try to perform tracing pipe which will do its best but in fact",
    "start": "1103610",
    "end": "1109610"
  },
  {
    "text": "we're we're in a more dynamic phone form so this is not going to work right it's not going to be what we really want so",
    "start": "1109610",
    "end": "1116030"
  },
  {
    "text": "here we can say we've got that same control flow we've got our decision gate function but when we trace it",
    "start": "1116030",
    "end": "1122750"
  },
  {
    "text": "we've only traced it on a single instance just just a one input and so the trace of that is the program without",
    "start": "1122750",
    "end": "1129919"
  },
  {
    "text": "the control flow it has no ability to capture that in a pure trace because it only saw one instance that's not what",
    "start": "1129919",
    "end": "1136280"
  },
  {
    "text": "you wanted and so your code is dropped out and that's why we provide you with yet more powerful tools than than simple",
    "start": "1136280",
    "end": "1141440"
  },
  {
    "text": "tracing what are those more powerful tools that's the script method you can",
    "start": "1141440",
    "end": "1147350"
  },
  {
    "text": "see here so here's what I've had to change to my code there we go just that so by doing that we can say",
    "start": "1147350",
    "end": "1154370"
  },
  {
    "text": "that this is actually something that needs to be scripted that we're not going to use pure tracing that we actually want to use script mode here",
    "start": "1154370",
    "end": "1160910"
  },
  {
    "text": "and so what that script mode does is it tells the torch script JIT compiler to extract out what is the what is this",
    "start": "1160910",
    "end": "1167570"
  },
  {
    "text": "part of our computation graph don't just trace it but actually understand what it",
    "start": "1167570",
    "end": "1172790"
  },
  {
    "text": "is map it to torch script and give me the the fuller representation of that computation graph and if you can see",
    "start": "1172790",
    "end": "1178190"
  },
  {
    "text": "there we have new code extracted as a results there and so that's this if statement here you can",
    "start": "1178190",
    "end": "1184120"
  },
  {
    "text": "if Bulli and so forth and down in this section here we have accurately mapped",
    "start": "1184120",
    "end": "1189130"
  },
  {
    "text": "from our representation in plain Python out to a computation graph which can take advantage of all of those optimized",
    "start": "1189130",
    "end": "1196090"
  },
  {
    "text": "static graph components which are built for production mode and as we can see it",
    "start": "1196090",
    "end": "1201520"
  },
  {
    "text": "works just the same way whether it's been run an eager mode or extracted by a torch script so that is at a code level",
    "start": "1201520",
    "end": "1208870"
  },
  {
    "text": "what that transition from research to production looks like using the power of torch script ok back up to some slides",
    "start": "1208870",
    "end": "1217380"
  },
  {
    "text": "and continue our journey and ok all",
    "start": "1217380",
    "end": "1228039"
  },
  {
    "text": "right and something that may not be obvious about seeing that at a code level is",
    "start": "1228039",
    "end": "1233890"
  },
  {
    "text": "this is a really powerful breakthrough for folks who have had to live in this research and production divided for a",
    "start": "1233890",
    "end": "1239410"
  },
  {
    "text": "long time which which matches my personal experience and the experience at face book AI that code that you just",
    "start": "1239410",
    "end": "1244960"
  },
  {
    "text": "saw allows you to operate within a shared code base for a given domain on",
    "start": "1244960",
    "end": "1250060"
  },
  {
    "text": "top of a common technology so that a research team and a production team can be using the exact same tools and have a",
    "start": "1250060",
    "end": "1256480"
  },
  {
    "text": "path from research to production this is really important for us is at Facebook because we we often have really deep",
    "start": "1256480",
    "end": "1263830"
  },
  {
    "text": "research things going on within Facebook air research our fundamental research function that needs to be connected up",
    "start": "1263830",
    "end": "1270220"
  },
  {
    "text": "to the ways in which we deploy PI towards models to production at scale and take advantage of all those capabilities we have here's a concrete",
    "start": "1270220",
    "end": "1278560"
  },
  {
    "text": "example of that this is the the PI Tech's library and so this was developed at Facebook really focused on natural",
    "start": "1278560",
    "end": "1285910"
  },
  {
    "text": "language understanding and some of the specific problems of working with text it has we've done some great work in",
    "start": "1285910",
    "end": "1292570"
  },
  {
    "text": "being able to use the technology coming out of research and putting into production with high text it has really",
    "start": "1292570",
    "end": "1298840"
  },
  {
    "text": "we real-world production requirements so some of those are it needs to operate in",
    "start": "1298840",
    "end": "1304630"
  },
  {
    "text": "real time a common use case of this library is that we're going to be performing recommendation predictions",
    "start": "1304630",
    "end": "1310420"
  },
  {
    "text": "inside a messenger session inside Facebook messenger it needs to scale messenger operates and hundreds of",
    "start": "1310420",
    "end": "1316240"
  },
  {
    "text": "languages that takes that many models it needs to operate around the world on",
    "start": "1316240",
    "end": "1321490"
  },
  {
    "text": "billions of devices and so forth and so there's there's a lot of complexity to the end and picture of that I want to",
    "start": "1321490",
    "end": "1327100"
  },
  {
    "text": "put that in an architecture diagram of sort of like the workflow of what that looks like so in research mode we need to be",
    "start": "1327100",
    "end": "1333790"
  },
  {
    "text": "constantly finding new ideas developing running experience experiments and developing new techniques which require",
    "start": "1333790",
    "end": "1339910"
  },
  {
    "text": "this great flexibility that flexibility is great and at some point we need to",
    "start": "1339910",
    "end": "1345100"
  },
  {
    "text": "evaluate out those things maybe sweep through some parameters but then we probably have something we want to put to use on some level that allows us to",
    "start": "1345100",
    "end": "1351730"
  },
  {
    "text": "so we're gonna export a PI torch model at that point we're just going to do this in eager mode we're going to stay",
    "start": "1351730",
    "end": "1356800"
  },
  {
    "text": "in Python land we're going to deploy to a simple Python service which allows us to get a little bit of small scale",
    "start": "1356800",
    "end": "1363080"
  },
  {
    "text": "action metrics this isn't a full production deployment this is for us to feel comfortable that things are in good shape when we do feel like we have found",
    "start": "1363080",
    "end": "1370309"
  },
  {
    "text": "a successful new technique we can now make that step that allows us to deploy from research production again still",
    "start": "1370309",
    "end": "1377570"
  },
  {
    "text": "using the exact same tool chain by just doing the same sorts of steps we just saw by exporting to torch script that",
    "start": "1377570",
    "end": "1383269"
  },
  {
    "text": "allows us to to take those follow-on steps with that optimized model that",
    "start": "1383269",
    "end": "1389330"
  },
  {
    "text": "Python torch script model sorry that PI torch torch script model is now exported",
    "start": "1389330",
    "end": "1394909"
  },
  {
    "text": "in a Python free way so that can be used inside of our highly optimized massive",
    "start": "1394909",
    "end": "1400760"
  },
  {
    "text": "scale C++ inference service that can serve billions of people and so folks",
    "start": "1400760",
    "end": "1406340"
  },
  {
    "text": "who are working on both ends of this problem are within the exact same codebase and using the same tool chain",
    "start": "1406340",
    "end": "1411669"
  },
  {
    "text": "I've shown you some fair bit of specifics around how we used hi torch at",
    "start": "1411669",
    "end": "1417169"
  },
  {
    "text": "Facebook I want to show you just a glimpse into the larger PI torch community a couple production examples",
    "start": "1417169",
    "end": "1423769"
  },
  {
    "text": "here the first one is from Genentech and Genentech is really working on a pretty important problem which is personalized",
    "start": "1423769",
    "end": "1429740"
  },
  {
    "text": "cancer therapy the biology of cancer is such that you're each individual cancer is unique your body's response to it is",
    "start": "1429740",
    "end": "1436580"
  },
  {
    "text": "going to be unique and there's a lot of deep data problems in there that they're attacking with AI and the the approach",
    "start": "1436580",
    "end": "1443000"
  },
  {
    "text": "that they're working on is that they want to leverage your own immune system using AI built-in pi torch to fight",
    "start": "1443000",
    "end": "1449539"
  },
  {
    "text": "cancer and so specifically they're doing things like identifying peptides which",
    "start": "1449539",
    "end": "1454549"
  },
  {
    "text": "can be bound to to be exposed some part of the molecule that looks like the the",
    "start": "1454549",
    "end": "1460399"
  },
  {
    "text": "specific cancer within your body out to your own immune system to teach your immune system how to fight against it a",
    "start": "1460399",
    "end": "1465470"
  },
  {
    "text": "sort of personalized cancer vaccine and they've seen some great results",
    "start": "1465470",
    "end": "1471010"
  },
  {
    "text": "moving on to to a very production oriented example I'm going to talk about Toyota and so within their research",
    "start": "1472639",
    "end": "1480230"
  },
  {
    "text": "group Toyota Research Institute they've been able to have this really amazing journey from research production using",
    "start": "1480230",
    "end": "1486590"
  },
  {
    "text": "PI torch so they're concerned with driver safety and the more than a million people died in traffic accidents",
    "start": "1486590",
    "end": "1493130"
  },
  {
    "text": "every year the statistics are staggering and and Toyota is the largest car",
    "start": "1493130",
    "end": "1498320"
  },
  {
    "text": "manufacturer in the world really wants to have an impact on this and so they're investing in technologies like",
    "start": "1498320",
    "end": "1503570"
  },
  {
    "text": "autonomous driving cars but what we can deliver today potentially to two cars",
    "start": "1503570",
    "end": "1508670"
  },
  {
    "text": "our driver assistive technology so predictive driver assistance that takes advantage of some of the capabilities",
    "start": "1508670",
    "end": "1514700"
  },
  {
    "text": "that we would be building inside of an autonomous car inside a car that's driven by a human to prevent crashes so",
    "start": "1514700",
    "end": "1521929"
  },
  {
    "text": "they've been able to collect real-world examples of crashes they've been able to map them up into a digital world and so",
    "start": "1521929",
    "end": "1528110"
  },
  {
    "text": "what we're gonna see here is a crash being avoided by a car that accelerates out of the way from other drivers which",
    "start": "1528110",
    "end": "1535040"
  },
  {
    "text": "are losing control of the car behind them this is a simulation they built from real-world data variable to model",
    "start": "1535040",
    "end": "1540980"
  },
  {
    "text": "it into this simulated world using PI torch but in the world of cars when we",
    "start": "1540980",
    "end": "1546380"
  },
  {
    "text": "ship to production we don't just mean simulated worlds we mean cars cars on",
    "start": "1546380",
    "end": "1551929"
  },
  {
    "text": "the road and so that once were they validated this model they need to then actually get cars out on the road and",
    "start": "1551929",
    "end": "1557720"
  },
  {
    "text": "power them and try to replicate the exact same examples see if the machine learning model is able to determine that",
    "start": "1557720",
    "end": "1562880"
  },
  {
    "text": "the cars behind it are about to lose control and accelerate out of the way just using a new intelligence",
    "start": "1562880",
    "end": "1568640"
  },
  {
    "text": "capabilities but nothing more than that the same capabilities built into the car today to accelerate and so a really",
    "start": "1568640",
    "end": "1575390"
  },
  {
    "text": "interesting look at how we can put AI to use and driver safety okay I want to",
    "start": "1575390",
    "end": "1582200"
  },
  {
    "text": "talk a little bit more about the broader ecosystem I'm going to talk about a few libraries they came out of Facebook that",
    "start": "1582200",
    "end": "1587210"
  },
  {
    "text": "are focused on optimization problems and they're both focused on techniques",
    "start": "1587210",
    "end": "1593360"
  },
  {
    "text": "derived from Bayesian optimization and so Bayesian optimization is this statistical technique I distinct from",
    "start": "1593360",
    "end": "1599150"
  },
  {
    "text": "deep learning the the example problem going to talk about here is hyper parameter optimization and so inside",
    "start": "1599150",
    "end": "1605900"
  },
  {
    "text": "building deep learning models there were all of these magic numbers like the learning rate and and various other",
    "start": "1605900",
    "end": "1612110"
  },
  {
    "text": "hyper parameters the number of epochs and so forth that determine whether or not you're going to be successful in in",
    "start": "1612110",
    "end": "1618230"
  },
  {
    "text": "training out a model that is performant and does the right thing they're kind of magic numbers they're established by",
    "start": "1618230",
    "end": "1623750"
  },
  {
    "text": "heuristics previous experience looking at someone else's paper hoping for the best running too many jobs there",
    "start": "1623750",
    "end": "1630350"
  },
  {
    "text": "better ways of doing this using Bayesian statistics and so we built how the tool chain to do that using PI torch all",
    "start": "1630350",
    "end": "1640789"
  },
  {
    "text": "right so first layer is the Bo torch",
    "start": "1640789",
    "end": "1646640"
  },
  {
    "text": "library so Bo torches really around pure Bayesian optimization it's built on PI",
    "start": "1646640",
    "end": "1652100"
  },
  {
    "text": "torch and uses some of the probabilistic modeling capabilities exposed out by G PI torch a Gaussian process library also",
    "start": "1652100",
    "end": "1659210"
  },
  {
    "text": "an open source but it's it's really a very unfair work highly modular way of exploring techniques that allow you to",
    "start": "1659210",
    "end": "1665659"
  },
  {
    "text": "perform Bayesian optimization moving up the stack one of the ways in which we",
    "start": "1665659",
    "end": "1670760"
  },
  {
    "text": "put that to use is our adaptive experimentation framework called ax and so ax tries to generalize some of those",
    "start": "1670760",
    "end": "1677299"
  },
  {
    "text": "concepts of how can we use Bayesian optimization techniques to develop up",
    "start": "1677299",
    "end": "1682460"
  },
  {
    "text": "domain agnostic abstractions around trying to optimize for particular goals deploy that all out and and really make",
    "start": "1682460",
    "end": "1689480"
  },
  {
    "text": "that happen very autonomous Li here's an example of what this looks like this",
    "start": "1689480",
    "end": "1694520"
  },
  {
    "text": "example is showing newsfeed ranking and so in this case there are all sorts of models that we want to deploy out to as",
    "start": "1694520",
    "end": "1702740"
  },
  {
    "text": "well as other components of data that we call a configuration and so in sum all these pieces of data determine what is",
    "start": "1702740",
    "end": "1710419"
  },
  {
    "text": "the basis for which item should be ranked within your newsfeed and we want to make changes to this all the time we",
    "start": "1710419",
    "end": "1716690"
  },
  {
    "text": "want to continually make this better online simulation is the gold standard for getting good labels and feedback",
    "start": "1716690",
    "end": "1724460"
  },
  {
    "text": "that our machine learning model is doing well unfortunately online experimentation is is a scarce resource",
    "start": "1724460",
    "end": "1731120"
  },
  {
    "text": "we only have so many users so many users working in a given time and we don't want to expose them to untested models",
    "start": "1731120",
    "end": "1736970"
  },
  {
    "text": "and so the way that ax plays a role in this is that we can build a multitask model which unifies real live testing",
    "start": "1736970",
    "end": "1744409"
  },
  {
    "text": "data from users with a much much larger amount of offline simulation data that",
    "start": "1744409",
    "end": "1750169"
  },
  {
    "text": "wasn't exposed on to real users and it gives us an ability to understand whether or not we're accurately",
    "start": "1750169",
    "end": "1755210"
  },
  {
    "text": "statistically modeling the properties of the system and and choose which new model to deploy",
    "start": "1755210",
    "end": "1762309"
  },
  {
    "text": "both of these libraries axe and bow torch are open-source we just release them about a month ago at f8 and I'd",
    "start": "1762309",
    "end": "1770380"
  },
  {
    "text": "like to call it that they're they're part of a larger ecosystem which I'm going to show you a few more examples of",
    "start": "1770380",
    "end": "1775600"
  },
  {
    "text": "that we have and so this ecosystem in particular this part of the ecosystem Bo",
    "start": "1775600",
    "end": "1780909"
  },
  {
    "text": "torch PI text our translate platform built on unfair seek our horizon",
    "start": "1780909",
    "end": "1786130"
  },
  {
    "text": "reinforcement learning platform these are all things that we built to solve our own problems of Facebook and we really want to make sure to give back to",
    "start": "1786130",
    "end": "1792220"
  },
  {
    "text": "the wider community of developers to allow you to work with these things to use them to solve your own problems so I",
    "start": "1792220",
    "end": "1799630"
  },
  {
    "text": "want to talk just specifically about some more of those developer resources that are that can help you get started",
    "start": "1799630",
    "end": "1804940"
  },
  {
    "text": "in becoming someone who can take models from research to production and use them to solve real world problems from the",
    "start": "1804940",
    "end": "1812830"
  },
  {
    "text": "perspective of PI towards wheat and n Facebook AI we really care about the whole stack of things and we want all of",
    "start": "1812830",
    "end": "1819370"
  },
  {
    "text": "these to be existing and open source and that means everything from our Open Compute platform project where we're",
    "start": "1819370",
    "end": "1825520"
  },
  {
    "text": "open sourcing our data center hardware designs all the way up to our compilers investments where we're collaborating",
    "start": "1825520",
    "end": "1832090"
  },
  {
    "text": "and open-source and things like glow and TVM ty torch itself and then higher-level frameworks and as you get",
    "start": "1832090",
    "end": "1838149"
  },
  {
    "text": "closer to to having more specific machine learning needs you probably care about things like pre train models and",
    "start": "1838149",
    "end": "1843159"
  },
  {
    "text": "we publish a lot of those I'll show an example of that soon and then and then",
    "start": "1843159",
    "end": "1848350"
  },
  {
    "text": "even datasets to allow you to develop new techniques yourself because this is part of the the larger PI torch",
    "start": "1848350",
    "end": "1853720"
  },
  {
    "text": "ecosystem and so there's a specific part of PI torch org the ecosystem page I would encourage you to go directly to if",
    "start": "1853720",
    "end": "1859630"
  },
  {
    "text": "you want to see what are some of the projects that you could get started with on some of the domain-specific libraries",
    "start": "1859630",
    "end": "1867399"
  },
  {
    "text": "some of these are gonna be for things like and I'll P some of these are gonna be for things like vision robotics there's a there's a rich community",
    "start": "1867399",
    "end": "1873820"
  },
  {
    "text": "people collaborating today in PI torch I want to do one more balance across",
    "start": "1873820",
    "end": "1879010"
  },
  {
    "text": "screens and just to show you a good example of something I really like there",
    "start": "1879010",
    "end": "1885820"
  },
  {
    "text": "okay an example of the some of the great",
    "start": "1885820",
    "end": "1891730"
  },
  {
    "text": "things you'll find in the in the ecosystem here so here this is a this is papers with code and so this records",
    "start": "1891730",
    "end": "1897880"
  },
  {
    "text": "computer science papers which develop new techniques and then links them up to actual implementations so that you can",
    "start": "1897880",
    "end": "1903250"
  },
  {
    "text": "get started here you can see the link here we can go out to the PI torch hub for this paper PI torch hub is our",
    "start": "1903250",
    "end": "1909040"
  },
  {
    "text": "collection of of implementations of models in PI torch and you can see not",
    "start": "1909040",
    "end": "1914890"
  },
  {
    "text": "just the code of this thing we can see an explanation some of the resources and this is all directly loadable within",
    "start": "1914890",
    "end": "1921040"
  },
  {
    "text": "your own within your own code and so here we can just again click the button",
    "start": "1921040",
    "end": "1926650"
  },
  {
    "text": "launch it up on colab and we can see that we have the ability with a single line of code to bring in this specific",
    "start": "1926650",
    "end": "1933520"
  },
  {
    "text": "model from the PI torch hub and people are adding out new models all the time this is an open collaboration it's not just models that coming out of Facebook",
    "start": "1933520",
    "end": "1939580"
  },
  {
    "text": "it's all sorts of pi torch users sharing their work and helping others be productive",
    "start": "1939580",
    "end": "1946890"
  },
  {
    "text": "I think you've heard me say a lot about developer productivity to call out here",
    "start": "1955690",
    "end": "1960820"
  },
  {
    "text": "I've shown a few examples of some of those tooling today but there's a lot we work very closely with Amazon Microsoft",
    "start": "1960820",
    "end": "1966520"
  },
  {
    "text": "and Google to make sure that your productivity as a developer who wants to have access to the best of the the tools",
    "start": "1966520",
    "end": "1972670"
  },
  {
    "text": "the cloud can provide support PI torch out of the box things like import torch we're having it available inside a VM having it",
    "start": "1972670",
    "end": "1979270"
  },
  {
    "text": "supported within vs code and things like that this is a fun example of something",
    "start": "1979270",
    "end": "1986110"
  },
  {
    "text": "that just launched I want to say something like six weeks ago neighborhood of so this is a this is",
    "start": "1986110",
    "end": "1991870"
  },
  {
    "text": "called an AI platform notebook it comes from Google cloud and this is a really exciting new tool chain that is a",
    "start": "1991870",
    "end": "1998710"
  },
  {
    "text": "notebook like environment connected up to the most sophisticated production deployment technologies the Google cloud",
    "start": "1998710",
    "end": "2003929"
  },
  {
    "text": "is developing and as with mykola of example you can just import torch and get running and they have examples built",
    "start": "2003929",
    "end": "2010470"
  },
  {
    "text": "into it out-of-the-box continuing the love this is another",
    "start": "2010470",
    "end": "2015840"
  },
  {
    "text": "collaboration we've done again with Google this time this is tensor board probably the the state of the art",
    "start": "2015840",
    "end": "2022980"
  },
  {
    "text": "everyone's favorite visualization tool for working with training deep neural networks this is an embedding this view",
    "start": "2022980",
    "end": "2029970"
  },
  {
    "text": "visualizing an embedding space but there's all sorts of things like learning rates and in various other ways",
    "start": "2029970",
    "end": "2035429"
  },
  {
    "text": "to understand what is going on inside your deep learning program tensor board",
    "start": "2035429",
    "end": "2040710"
  },
  {
    "text": "itself is open source and it supports PI torch out of the box and inside a colab as well part of being productive is",
    "start": "2040710",
    "end": "2049919"
  },
  {
    "text": "knowing what you want to do in the first place and so we care a lot about developer education shout out that we've",
    "start": "2049919",
    "end": "2058530"
  },
  {
    "text": "been overwhelmed by the by the enormous growth of the community last year we",
    "start": "2058530",
    "end": "2063990"
  },
  {
    "text": "were their second fastest growing project in all of open source and so we've had to think a lot about how to bring new people up to speed and and",
    "start": "2063990",
    "end": "2071608"
  },
  {
    "text": "also to point to leading lights in the community and ask them to to support them when they try to teach others and",
    "start": "2071609",
    "end": "2078179"
  },
  {
    "text": "so here's some examples of two books written by folks who are just in the PI torch community they're not Facebook",
    "start": "2078179",
    "end": "2084330"
  },
  {
    "text": "employees and they've their really great natural language processing with PI for deep learning with pi torch both of",
    "start": "2084330",
    "end": "2090790"
  },
  {
    "text": "these books are great places to start in understanding how you can solve real world problems using the best of pi",
    "start": "2090790",
    "end": "2097840"
  },
  {
    "text": "torch technology I think I mentioned this a little bit in the panel but we have some great courses as well",
    "start": "2097840",
    "end": "2104170"
  },
  {
    "text": "Udacity has worked with us on a whole bunch of courses you can see them scrolling there all the different topics",
    "start": "2104170",
    "end": "2109780"
  },
  {
    "text": "you can study in Udacity using pi torch and we care a lot about this and so how",
    "start": "2109780",
    "end": "2116290"
  },
  {
    "text": "some of the more recent steps we've taken is we've collaborated with Andrew Trask of who is the developer of open",
    "start": "2116290",
    "end": "2122740"
  },
  {
    "text": "mind and pi sift in the development of a privacy and AI course deployed on",
    "start": "2122740",
    "end": "2128670"
  },
  {
    "text": "deployed on Udacity and we're also funding scholarships for for people to continue their studies on Udacity and",
    "start": "2128670",
    "end": "2134920"
  },
  {
    "text": "learning more about deep learning and that sorry and to call out that a that",
    "start": "2134920",
    "end": "2139930"
  },
  {
    "text": "privacy course is in fact the library implement in their PI sift is a PI torch",
    "start": "2139930",
    "end": "2144970"
  },
  {
    "text": "library that contains a lot of powerful techniques for working in privacy-preserving ml techniques across",
    "start": "2144970",
    "end": "2150850"
  },
  {
    "text": "the range of things known within computer science bouncing over to",
    "start": "2150850",
    "end": "2156610"
  },
  {
    "text": "another great educational partner fast AI fast AI is an online AI school that",
    "start": "2156610",
    "end": "2162160"
  },
  {
    "text": "has just extraordinary stats around the numbers of people they reach and their global reach in their ability to to",
    "start": "2162160",
    "end": "2168970"
  },
  {
    "text": "reach people all over the world and teach them the absolute latest in artificial intelligence techniques",
    "start": "2168970",
    "end": "2174210"
  },
  {
    "text": "they've just launched new courses again in PI torch and they've done some great",
    "start": "2174210",
    "end": "2179890"
  },
  {
    "text": "development of having easy-to-use beginner libraries that help someone become productive as a learner and those",
    "start": "2179890",
    "end": "2185980"
  },
  {
    "text": "courses and those libraries right now the latest ones around audio and vision major areas of deep learning activity so",
    "start": "2185980",
    "end": "2194860"
  },
  {
    "text": "what does it mean if you walk away from this talk and want to get started I'd point you to the get started page on on",
    "start": "2194860",
    "end": "2199960"
  },
  {
    "text": "PI torch some of the ways that you can get started are to just click the button",
    "start": "2199960",
    "end": "2206050"
  },
  {
    "text": "on the docs and that will launch at you out to a live collab instance that has the code from the examples there you can",
    "start": "2206050",
    "end": "2212470"
  },
  {
    "text": "also get started in the cloud on Azure on Amazon on Google cloud and you can",
    "start": "2212470",
    "end": "2218080"
  },
  {
    "text": "also install locally just pip install start playing around with it top you don't need a massive GPU back server to start writing code that is but",
    "start": "2218080",
    "end": "2226090"
  },
  {
    "text": "then once you do want to go ahead and move up to to that scale you know that you have that support there both of them",
    "start": "2226090",
    "end": "2231760"
  },
  {
    "text": "the PI torch technology itself but also then the larger ecosystem of open source libraries and cloud partners that help",
    "start": "2231760",
    "end": "2237940"
  },
  {
    "text": "you be productive in moving your models from research to production and so that's all I really want to have to say",
    "start": "2237940",
    "end": "2244120"
  },
  {
    "text": "I just want to invite you if you are interested in this part of open AI collaboration I want you to join in the",
    "start": "2244120",
    "end": "2249790"
  },
  {
    "text": "community we live out here an open source we want to we want to talk we want to learn more about what you're doing and understand what we can invest",
    "start": "2249790",
    "end": "2256750"
  },
  {
    "text": "in and spend our time building to make you successful in taking your deep learning models from research to",
    "start": "2256750",
    "end": "2261850"
  },
  {
    "text": "production thank you thank you Jeff for",
    "start": "2261850",
    "end": "2271690"
  },
  {
    "text": "that great introduction to PI torch we have about ten minutes for Q&A any",
    "start": "2271690",
    "end": "2276880"
  },
  {
    "text": "questions out there for Jeff hi Jeff",
    "start": "2276880",
    "end": "2286390"
  },
  {
    "text": "great talk just wanted to ask you you kind of used deep learning and machine learning interchangeably do you see any",
    "start": "2286390",
    "end": "2292360"
  },
  {
    "text": "distinction between those two and if so what is that sure and I think that's",
    "start": "2292360",
    "end": "2298360"
  },
  {
    "text": "probably just me rushing through things a little bit and so for folks are unfamiliar with how you would normally",
    "start": "2298360",
    "end": "2303910"
  },
  {
    "text": "break down the technology the terminology I would say deep learning could usually be classified as a subset",
    "start": "2303910",
    "end": "2309610"
  },
  {
    "text": "of all available machine learning techniques and part of that fluidity there is we as pie charts as a",
    "start": "2309610",
    "end": "2316750"
  },
  {
    "text": "technology embraces more problems than simply deep learning deep learning is",
    "start": "2316750",
    "end": "2321970"
  },
  {
    "text": "one of the ones that we work on but we also do a lot of work within scientific computing that can sometimes use other",
    "start": "2321970",
    "end": "2327250"
  },
  {
    "text": "techniques for example that talks there the discussion of ax and Bo torch those",
    "start": "2327250",
    "end": "2332620"
  },
  {
    "text": "are those are non deep learning based techniques but they are built on PI torch and so we work at the intersection",
    "start": "2332620",
    "end": "2338230"
  },
  {
    "text": "of both we have a question down here at Jeff Jeff high for someone who has a lot of",
    "start": "2338230",
    "end": "2346380"
  },
  {
    "text": "experience in Python and has a lot of interest in machine learning but no experience with pi torch what would be the one definite source that you would",
    "start": "2346380",
    "end": "2353640"
  },
  {
    "text": "say is you know the first that someone should look at kind of depends on how",
    "start": "2353640",
    "end": "2359160"
  },
  {
    "text": "much time you have so some common answers are you can do the 60 minute blitz tutorial if you've got an hour",
    "start": "2359160",
    "end": "2364200"
  },
  {
    "text": "that's just on the the PI torch Docs if you want to commit to a deeper learning process the Udacity and fast IO AI",
    "start": "2364200",
    "end": "2371190"
  },
  {
    "text": "courses are great I also like the books as well for people who feel like they",
    "start": "2371190",
    "end": "2376560"
  },
  {
    "text": "have enough grounding to be able to be productive in working through a book I think the depth of the examples and the",
    "start": "2376560",
    "end": "2382670"
  },
  {
    "text": "ability to dig deep in in being able to some of the things you can do specifically in a book are nice as well",
    "start": "2382670",
    "end": "2388650"
  },
  {
    "text": "but those would be my my three main starting points the tutorials the courses or the books just quick question",
    "start": "2388650",
    "end": "2397080"
  },
  {
    "text": "on how this platform the PI touch it's compatible for something like age on the",
    "start": "2397080",
    "end": "2403440"
  },
  {
    "text": "edge devices like Raspberry Pi or something is there like a lighter version of right so this is I think a",
    "start": "2403440",
    "end": "2412080"
  },
  {
    "text": "moving target within the field of deep learning in in saying how can we take something that's huge and how can we",
    "start": "2412080",
    "end": "2418290"
  },
  {
    "text": "make it small and work really well the story of what works today and that works well is is really focused around mobile",
    "start": "2418290",
    "end": "2425850"
  },
  {
    "text": "for us specifically and so there are paths to to take a pipe where small",
    "start": "2425850",
    "end": "2431880"
  },
  {
    "text": "light and export bionics which allows you access to various like onyx runtimes",
    "start": "2431880",
    "end": "2437490"
  },
  {
    "text": "I didn't talk about it in this talk but onyx Isaiah an open source standard collaboration that we and Microsoft and",
    "start": "2437490",
    "end": "2443490"
  },
  {
    "text": "others created around the open neural network exchange format and there's some tool chains for that and there a",
    "start": "2443490",
    "end": "2449400"
  },
  {
    "text": "particular way as well as there are other ways to take PI torch models and run them on things like the the cafe to go mobile runtime but it's an important",
    "start": "2449400",
    "end": "2457110"
  },
  {
    "text": "area without saying anything super specific obviously we care and we will keep doing more stuff this is I think a",
    "start": "2457110",
    "end": "2463680"
  },
  {
    "text": "moving target for the whole field some other pieces of the pie torch stack worth calling out if you happen to be",
    "start": "2463680",
    "end": "2469200"
  },
  {
    "text": "that specialized if you're working our FB GM and qnn pack which are quantization libraries",
    "start": "2469200",
    "end": "2475869"
  },
  {
    "text": "quantization is a necessary technique in shrinking down a very large deep learning model and making it possible to",
    "start": "2475869",
    "end": "2482410"
  },
  {
    "text": "run either efficiently on a server or efficiently on a mobile device and both of those are open source projects that",
    "start": "2482410",
    "end": "2488079"
  },
  {
    "text": "we released last year to support the the larger PI torch ecosystem something that",
    "start": "2488079",
    "end": "2493329"
  },
  {
    "text": "we saw earlier today on the tensor flow talk was that they had functionality in their new API for being able to take pre-trained published models and then",
    "start": "2493329",
    "end": "2500140"
  },
  {
    "text": "use those as like input layers in in in your models that you make that are derived from that and I saw that you",
    "start": "2500140",
    "end": "2506349"
  },
  {
    "text": "talked about about PI torch models that that you that Facebook provides and the other researchers provide like what's",
    "start": "2506349",
    "end": "2513010"
  },
  {
    "text": "what's pi torch is support for things like you know if I wanted to use a pre-trained language classifier or image",
    "start": "2513010",
    "end": "2518380"
  },
  {
    "text": "classifier and use that for some you know domain-specific a proprietary modeling on top of that yeah so I think",
    "start": "2518380",
    "end": "2524290"
  },
  {
    "text": "that this is an area that I think is emerging that people really want something that helps with their",
    "start": "2524290",
    "end": "2530859"
  },
  {
    "text": "productivity so I think in the old days where there used to be things like just sort of static model zoos and there was like people published up here are some",
    "start": "2530859",
    "end": "2537849"
  },
  {
    "text": "things from these papers and they just kind of sat in a folder and know whatever did anything with them these",
    "start": "2537849",
    "end": "2543400"
  },
  {
    "text": "days what we care about doing it within pipe torches is the PI torch hub so I found stubborn showed a little bit of",
    "start": "2543400",
    "end": "2549280"
  },
  {
    "text": "that PI torch hub is is where we would like people to share their pre train models and any and do that sort of",
    "start": "2549280",
    "end": "2554470"
  },
  {
    "text": "connection up - I - like where does the paper this is drive from how does someone use this and it's pretty easy to",
    "start": "2554470",
    "end": "2560920"
  },
  {
    "text": "get started we've collaborated with a bunch of like you know even like small startups I've been able to put up their",
    "start": "2560920",
    "end": "2565990"
  },
  {
    "text": "work and get it on the onto the hub and it really helps with the reuse of amalah because they're it's a single one-liner",
    "start": "2565990",
    "end": "2571960"
  },
  {
    "text": "you just called you just call it in as a hub that load or something like that any other questions",
    "start": "2571960",
    "end": "2580559"
  },
  {
    "text": "well great call great talk but I do have some like machine learning like projects",
    "start": "2582540",
    "end": "2588330"
  },
  {
    "text": "like going on but like they're more like traditional like machine learning things like k-means SEO and all the kind of",
    "start": "2588330",
    "end": "2594930"
  },
  {
    "text": "stuff and I don't know if I can get benefits if I'd like poured all this kind of stuff two-part torch or like",
    "start": "2594930",
    "end": "2600620"
  },
  {
    "text": "it's turnkey care to this kind of stuff and can I get an account penny from",
    "start": "2600620",
    "end": "2605660"
  },
  {
    "text": "important night Kimi's or like I see all the kinda stuff every question right so if I've got an",
    "start": "2605660",
    "end": "2613500"
  },
  {
    "text": "existing implementation of something that uses a non neural network based technique is there any benefit to trying",
    "start": "2613500",
    "end": "2618870"
  },
  {
    "text": "to work with PI torch I think it I think it depends some of the things that I would typically be looking at our do you",
    "start": "2618870",
    "end": "2626490"
  },
  {
    "text": "have the ability to take advantage of sufficiently large data sets that you would like access to things like GPU",
    "start": "2626490",
    "end": "2633420"
  },
  {
    "text": "acceleration so we do have a a portion of the community of users that I would",
    "start": "2633420",
    "end": "2638610"
  },
  {
    "text": "generally group in scientific computing use do working on problems that are not deep learning and they take advantage of",
    "start": "2638610",
    "end": "2644550"
  },
  {
    "text": "high torch as a GPU accelerated tensor library so numpy on GPUs if that sounds",
    "start": "2644550",
    "end": "2650760"
  },
  {
    "text": "useful to you then then maybe we could we talk and find you know whether or not there is a way to put that to use for",
    "start": "2650760",
    "end": "2656160"
  },
  {
    "text": "for your use case it tends to be a little bit domain-specific though all",
    "start": "2656160",
    "end": "2661350"
  },
  {
    "text": "right anyone else I have a very short",
    "start": "2661350",
    "end": "2666480"
  },
  {
    "text": "light-hearted question I wonder what happened to the old logo sure so you have the the old logo stickers so as of",
    "start": "2666480",
    "end": "2673490"
  },
  {
    "text": "pi torch 1.0 when we which was announced at f8 of 2018 and then delivered at a",
    "start": "2673490",
    "end": "2680400"
  },
  {
    "text": "pipe torch Def Con of 2018 pi torch 100 now reflects the union of",
    "start": "2680400",
    "end": "2685950"
  },
  {
    "text": "the pi torch technology the Onyx technology and the cafe to technology",
    "start": "2685950",
    "end": "2690990"
  },
  {
    "text": "and so all of those are cafe to it briefly for anyone is unfamiliar with it is a deep learning framework developed",
    "start": "2690990",
    "end": "2697500"
  },
  {
    "text": "at Facebook also an open source and deployed to a production inside Facebook we chose to unify those really to",
    "start": "2697500",
    "end": "2704640"
  },
  {
    "text": "achieve that research to production story of being able to have all those broad capabilities when we did that we",
    "start": "2704640",
    "end": "2710970"
  },
  {
    "text": "created the slightly more futuristic logo that you see now so I just wanted to ask the opposite",
    "start": "2710970",
    "end": "2718950"
  },
  {
    "text": "question of the the talk that was I'm not tensorflow so why would someone use PI torch over tensorflow",
    "start": "2718950",
    "end": "2727460"
  },
  {
    "text": "so I did have a slide where I try to be fairly specific about our philosophies",
    "start": "2727460",
    "end": "2733680"
  },
  {
    "text": "as a project and so speaking you know a largely affirmative mode is I wanted to paint a picture for someone who wants to",
    "start": "2733680",
    "end": "2740790"
  },
  {
    "text": "take something and then and if that sounds like the sort of journey that you want to do and the ways in which you",
    "start": "2740790",
    "end": "2745890"
  },
  {
    "text": "want to do it there's a very specific approach at the code level which is what I try to make that as clear as possible around how little you need to adapt your",
    "start": "2745890",
    "end": "2754020"
  },
  {
    "text": "programming model to match the capabilities we're trying to provide out to you so if you if you take a look at",
    "start": "2754020",
    "end": "2759210"
  },
  {
    "text": "the tutorials you you open them up you start running things and that is the way in which you want to work we would love",
    "start": "2759210",
    "end": "2764280"
  },
  {
    "text": "to collaborate with you on that we want to we want to support people who appreciate this sort of flexible and",
    "start": "2764280",
    "end": "2769950"
  },
  {
    "text": "highly modular approach that allows you to opt into the pieces they do care about but I've got nothing bad to say",
    "start": "2769950",
    "end": "2775050"
  },
  {
    "text": "about tensorflow at all they're a great guys as well I appreciated Brad's talk it was very uh it was very worthwhile we",
    "start": "2775050",
    "end": "2782880"
  },
  {
    "text": "have time for one more question anyone all right let's get ready for",
    "start": "2782880",
    "end": "2790500"
  },
  {
    "text": "bright one Thank You Brad [Applause]",
    "start": "2790500",
    "end": "2796980"
  }
]
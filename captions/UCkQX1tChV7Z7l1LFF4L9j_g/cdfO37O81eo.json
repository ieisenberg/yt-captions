[
  {
    "start": "0",
    "end": "27000"
  },
  {
    "text": "[Music]",
    "start": "3320",
    "end": "14289"
  },
  {
    "text": "good morning and welcome to qcon my name is siddhanand and i'm happy to present today",
    "start": "15040",
    "end": "21359"
  },
  {
    "text": "my talk building and operating high fidelity data streams",
    "start": "21359",
    "end": "27279"
  },
  {
    "start": "27000",
    "end": "122000"
  },
  {
    "text": "given that this is a data track i'm sure many of you are already familiar with streams but for those of you who are new",
    "start": "27279",
    "end": "33680"
  },
  {
    "text": "to it this might serve as a good introduction why do streams matter",
    "start": "33680",
    "end": "39200"
  },
  {
    "text": "in our world today machine intelligence and personalization describe engaging experiences online",
    "start": "39200",
    "end": "46320"
  },
  {
    "text": "whether that's a learn to rank system that improves search quality at your favorite search engine",
    "start": "46320",
    "end": "51920"
  },
  {
    "text": "or a recommender system that recommends music or movies or recommender systems that",
    "start": "51920",
    "end": "59600"
  },
  {
    "text": "recommend who you should follow or ranking systems that re-rank a feed",
    "start": "59600",
    "end": "64878"
  },
  {
    "text": "on your social platform of choice disparate data is constantly being",
    "start": "64879",
    "end": "70159"
  },
  {
    "text": "connected to drive predictions that keep us engaged while it may seem that magical some",
    "start": "70159",
    "end": "76799"
  },
  {
    "text": "magical sql join is powering these connections the reality is that data growth has made",
    "start": "76799",
    "end": "82799"
  },
  {
    "text": "it impractical to store all of this data in a single db",
    "start": "82799",
    "end": "88159"
  },
  {
    "text": "10 years ago we would use a single monolithic db to store all our data but today the picture on the right is",
    "start": "88159",
    "end": "94960"
  },
  {
    "text": "more representative of modern data architectures that we see it is a collection of point solutions",
    "start": "94960",
    "end": "102079"
  },
  {
    "text": "tied together by one or more data movement infrastructure services",
    "start": "102079",
    "end": "107680"
  },
  {
    "text": "so how do companies manage the complexity below a key piece to the puzzle is data",
    "start": "107680",
    "end": "114399"
  },
  {
    "text": "movement which usually comes in two forms either bash processing or stream",
    "start": "114399",
    "end": "120399"
  },
  {
    "text": "processing so what makes streams hard",
    "start": "120399",
    "end": "126159"
  },
  {
    "start": "122000",
    "end": "183000"
  },
  {
    "text": "well let's have a look at this picture there are lots of moving parts it has a very large surface area which",
    "start": "126159",
    "end": "133680"
  },
  {
    "text": "means that there are many places where errors can occur in streaming architectures",
    "start": "133680",
    "end": "139920"
  },
  {
    "text": "any gaps and non-functional requirements can be very unforgiving",
    "start": "139920",
    "end": "145200"
  },
  {
    "text": "you end up spending a lot of your time fighting fires and keeping systems up",
    "start": "145200",
    "end": "150560"
  },
  {
    "text": "if you don't build your systems with the ilities as first-class citizens",
    "start": "150560",
    "end": "156239"
  },
  {
    "text": "and by ilities i mean non-functional requirements such as scalability reliability operability",
    "start": "156239",
    "end": "162480"
  },
  {
    "text": "if you don't build your systems with these abilities as first-class citizens you will end up paying a very steep",
    "start": "162480",
    "end": "168319"
  },
  {
    "text": "operational tax and this translates typically to unhappy customers and burnt out team members",
    "start": "168319",
    "end": "175040"
  },
  {
    "text": "that will eventually leave your team in this talk we will focus on building high fidelity streams from the ground",
    "start": "175040",
    "end": "182840"
  },
  {
    "text": "up this is a pretty ambitious endeavor and with any large project or endeavor i",
    "start": "182840",
    "end": "188879"
  },
  {
    "start": "183000",
    "end": "317000"
  },
  {
    "text": "like to start simple let's start by defining a goal our goal is to build a system that can",
    "start": "188879",
    "end": "195760"
  },
  {
    "text": "deliver messages from source s to destination d but first let's decouple s and d by",
    "start": "195760",
    "end": "203200"
  },
  {
    "text": "putting a message broker between them this is not a very controversial decision it's quite conventional and",
    "start": "203200",
    "end": "209360"
  },
  {
    "text": "used throughout the world in this case i've picked kafka as my",
    "start": "209360",
    "end": "215040"
  },
  {
    "text": "technology but you can use any type of message brokering system and in this system i've created a single",
    "start": "215040",
    "end": "221280"
  },
  {
    "text": "topic called an events topic i've decoupled s d with this event topic",
    "start": "221280",
    "end": "226879"
  },
  {
    "text": "this means that if d fails s can continue to publish messages to e",
    "start": "226879",
    "end": "232400"
  },
  {
    "text": "and if s fails d can continue to consume messages from e",
    "start": "232400",
    "end": "238400"
  },
  {
    "text": "let's make a few more implementation decisions about this system let's run our system on a cloud platform",
    "start": "238400",
    "end": "245680"
  },
  {
    "text": "for many that just means running it on a publicly available cloud platform like aws or gcp",
    "start": "245680",
    "end": "252640"
  },
  {
    "text": "but it can also mean running it on kubernetes on-prem additionally to start with let's operate",
    "start": "252640",
    "end": "260000"
  },
  {
    "text": "at low scale this means we can run kafka with a single partition in our",
    "start": "260000",
    "end": "265360"
  },
  {
    "text": "topic however since we want things to be reliable let's run three brokers split across",
    "start": "265360",
    "end": "273199"
  },
  {
    "text": "three availability zones and set the rf or replication factor to three",
    "start": "273199",
    "end": "279919"
  },
  {
    "text": "additionally we will run s and d on single but separate ec2 instances",
    "start": "279919",
    "end": "286479"
  },
  {
    "text": "to make things a bit more interesting let's provide our stream as a service",
    "start": "286479",
    "end": "293040"
  },
  {
    "text": "this means we can accept inbound messages at an api endpoint hosted at process s",
    "start": "293040",
    "end": "301440"
  },
  {
    "text": "when messages arrive s will process them and send them to event topic e",
    "start": "301440",
    "end": "308479"
  },
  {
    "text": "process d will consume from event topic e and send the message to some third-party",
    "start": "308479",
    "end": "314880"
  },
  {
    "text": "endpoint on the internet the first question i ask is is this",
    "start": "314880",
    "end": "320400"
  },
  {
    "start": "317000",
    "end": "601000"
  },
  {
    "text": "system reliable so let's revise our goal we want to build a system that can",
    "start": "320400",
    "end": "326639"
  },
  {
    "text": "deliver messages reliably from std and to make this goal more concrete",
    "start": "326639",
    "end": "333120"
  },
  {
    "text": "i'd like to add the following requirement i want zero message loss once process s has acknowledged a",
    "start": "333120",
    "end": "340639"
  },
  {
    "text": "message to a remote sender d must deliver that message to a remote",
    "start": "340639",
    "end": "345840"
  },
  {
    "text": "receiver how do we build reliability into our system",
    "start": "345840",
    "end": "351600"
  },
  {
    "text": "let's first generalize our system instead of just s and d",
    "start": "351600",
    "end": "356960"
  },
  {
    "text": "let's say that we have three processes a b and c all of which are connected linearly with",
    "start": "356960",
    "end": "363759"
  },
  {
    "text": "kafka topics in order to make this system reliable",
    "start": "363759",
    "end": "368960"
  },
  {
    "text": "let's treat this linear topology as a chain and like any chain it's only as strong",
    "start": "368960",
    "end": "374960"
  },
  {
    "text": "as its weakest link if each process or link is transactional",
    "start": "374960",
    "end": "380560"
  },
  {
    "text": "in nature this chain will be transactional now my definition of transactionality is",
    "start": "380560",
    "end": "387600"
  },
  {
    "text": "at least once delivery since this is the most common way that kafka is used today",
    "start": "387600",
    "end": "394720"
  },
  {
    "text": "now how do we make each link transactional let's first break this chain into its",
    "start": "394720",
    "end": "400479"
  },
  {
    "text": "component processing links first we have a a is an ingest node",
    "start": "400479",
    "end": "408080"
  },
  {
    "text": "then we have b b is an internal node it reads from kafka and writes to kafka",
    "start": "408080",
    "end": "414400"
  },
  {
    "text": "and finally we have c c is an expel or e just node it reads",
    "start": "414400",
    "end": "420080"
  },
  {
    "text": "from kafka and sends a message out to the internet how do we make a",
    "start": "420080",
    "end": "426000"
  },
  {
    "text": "reliable well a will receive a request via its rest endpoint",
    "start": "426000",
    "end": "431919"
  },
  {
    "text": "it will do some processing on it it will reliably send that data to kafka",
    "start": "431919",
    "end": "437520"
  },
  {
    "text": "and then it will send an http response back to its caller now to reliably send data to kafka",
    "start": "437520",
    "end": "444720"
  },
  {
    "text": "it will need to call kproducer.send with two arguments a topic and a message",
    "start": "444720",
    "end": "451599"
  },
  {
    "text": "it will then immediately need to call flush which will flush internal kafka buffers",
    "start": "451599",
    "end": "456800"
  },
  {
    "text": "and force the messages to be sent to all three brokers and since we have producer config acts",
    "start": "456800",
    "end": "464479"
  },
  {
    "text": "equal all it will wait for an acknowledgement of success from all three brokers therefore it can respond",
    "start": "464479",
    "end": "471280"
  },
  {
    "text": "to its caller how about c what does c need to be need to do to be",
    "start": "471280",
    "end": "478479"
  },
  {
    "text": "reliable well it needs to read data typically a batch from kafka do some processing on it",
    "start": "478479",
    "end": "484960"
  },
  {
    "text": "and then reliably send data out in this case reliably means that it will need to wait for a 200 okay response",
    "start": "484960",
    "end": "491680"
  },
  {
    "text": "code from some external service if it receives that",
    "start": "491680",
    "end": "497039"
  },
  {
    "text": "well since we've enabled auto commit or we've disabled it we've set it to false",
    "start": "497039",
    "end": "503919"
  },
  {
    "text": "the process c will need to manually move or manually acknowledge",
    "start": "503919",
    "end": "510160"
  },
  {
    "text": "back to kafka so that the checkpoint for read is moved forward if there are any problems",
    "start": "510319",
    "end": "517279"
  },
  {
    "text": "process c will negatively add kafka which will force a reread of the same data",
    "start": "517279",
    "end": "523680"
  },
  {
    "text": "last but not least what does b need to do well b is a combination of a and c",
    "start": "523680",
    "end": "530560"
  },
  {
    "text": "so b needs to act like a reliable kafka producer like a and it also needs to act like a reliable",
    "start": "530560",
    "end": "537440"
  },
  {
    "text": "kafka consumer like c now what can we say about the",
    "start": "537440",
    "end": "543600"
  },
  {
    "text": "reliability of our system well what happens if a process crashes",
    "start": "543600",
    "end": "549519"
  },
  {
    "text": "if a crashes we will have a complete outage at ingest",
    "start": "549519",
    "end": "555200"
  },
  {
    "text": "that means our system will not accept any new messages if c crashes we will stop delivering",
    "start": "555200",
    "end": "561360"
  },
  {
    "text": "messages to external consumers although that does mean a will continue to receive messages",
    "start": "561360",
    "end": "567440"
  },
  {
    "text": "it means that c will not be delivering them anywhere the most common solution to this problem",
    "start": "567440",
    "end": "574160"
  },
  {
    "text": "is to wrap each service in an auto scaling group of size t if we do so",
    "start": "574160",
    "end": "580240"
  },
  {
    "text": "then each of the groups can handle t minus one concurrent failures",
    "start": "580240",
    "end": "585279"
  },
  {
    "text": "now while auto scaling is an auto scaling groups is a term that was coined by amazon it's available on",
    "start": "585279",
    "end": "592560"
  },
  {
    "text": "all cloud platforms and also in kubernetes",
    "start": "592560",
    "end": "597279"
  },
  {
    "text": "for now we appear to have a pretty reliable data stream but how do we measure its reliability",
    "start": "597680",
    "end": "604720"
  },
  {
    "start": "601000",
    "end": "641000"
  },
  {
    "text": "this brings us to observability a story about lag and loss so if you've",
    "start": "604720",
    "end": "609760"
  },
  {
    "text": "worked in streams before you might be familiar with these metrics but if you're new to it i'm going to give you",
    "start": "609760",
    "end": "615360"
  },
  {
    "text": "an introduction firstly let's start with lag lag is simply a measure of message delay",
    "start": "615360",
    "end": "622480"
  },
  {
    "text": "in a system the longer a message takes to transit a system the greater its lag",
    "start": "622480",
    "end": "628640"
  },
  {
    "text": "the greater the lag the greater the impact to a business especially one that depends on real-time insights",
    "start": "628640",
    "end": "635839"
  },
  {
    "text": "hence our goal is to minimize lag in order to deliver insights as quickly as possible",
    "start": "635839",
    "end": "641920"
  },
  {
    "start": "641000",
    "end": "901000"
  },
  {
    "text": "so how do we compute it to start with let's uh discuss one of",
    "start": "641920",
    "end": "648240"
  },
  {
    "text": "the concepts called event time event time is the creation time of a message",
    "start": "648240",
    "end": "653519"
  },
  {
    "text": "it's typically stored within the message body and travels with it as a transistor system",
    "start": "653519",
    "end": "659360"
  },
  {
    "text": "lag can be calculated for any message m1 at any node and in the system using this",
    "start": "659360",
    "end": "665040"
  },
  {
    "text": "equation let's look at a real example let's say we have a message created at",
    "start": "665040",
    "end": "672160"
  },
  {
    "text": "noon that message arrives at our system at node a",
    "start": "672160",
    "end": "678240"
  },
  {
    "text": "at 1201 pm node a processes the message and sends",
    "start": "678240",
    "end": "683839"
  },
  {
    "text": "it on to node b the message arrives at node b at 1204 pm",
    "start": "683839",
    "end": "689839"
  },
  {
    "text": "b processes the message and sends it on to c which receives it at 12 10 pm",
    "start": "689839",
    "end": "696079"
  },
  {
    "text": "in turn c processes the message and sends it on its way using the equation from the early from",
    "start": "696079",
    "end": "702160"
  },
  {
    "text": "the uh page below uh before we see that uh t1 minus t0 is one minute",
    "start": "702160",
    "end": "710160"
  },
  {
    "text": "t3 minus t0 is four minutes and so on we can compute the lag of message 1 and node c at 10 minutes",
    "start": "710160",
    "end": "718800"
  },
  {
    "text": "in reality times in these systems are not on the order of minutes but in the order of",
    "start": "718880",
    "end": "724880"
  },
  {
    "text": "milliseconds one thing i will mention is that we've been talking about message",
    "start": "724880",
    "end": "732480"
  },
  {
    "text": "arrival at these nodes and hence this is called arrival lag or lag in",
    "start": "732480",
    "end": "738480"
  },
  {
    "text": "another thing to observe is that lag is cumulative that means the lag computed at node c",
    "start": "738480",
    "end": "745440"
  },
  {
    "text": "accounts for the lag upstream of it in both nodes a and b similarly the lag computed at node b",
    "start": "745440",
    "end": "753440"
  },
  {
    "text": "accounts for the lag upstream of it at node a",
    "start": "753440",
    "end": "758480"
  },
  {
    "text": "while we talked about arrival lag there is another type of lag called departure lag",
    "start": "758480",
    "end": "764959"
  },
  {
    "text": "so departure lag is is calculated when messages leave nodes",
    "start": "764959",
    "end": "771519"
  },
  {
    "text": "so similarly to arrival lag we can compute departure lag",
    "start": "771519",
    "end": "777200"
  },
  {
    "text": "the most important metric for lag in any streaming system is called end to end lag that is the total time and message",
    "start": "777200",
    "end": "784320"
  },
  {
    "text": "spent in the system it is very easy to compute end-to-end lag because it's simply the departure",
    "start": "784320",
    "end": "791279"
  },
  {
    "text": "lag at the last node in the system hence it's a departure lag at node c",
    "start": "791279",
    "end": "797760"
  },
  {
    "text": "while it is interesting to know the lag for a particular message it's of little use since we typically",
    "start": "798079",
    "end": "803440"
  },
  {
    "text": "deal with millions of messages instead we prefer statistics to capture population behavior",
    "start": "803440",
    "end": "810079"
  },
  {
    "text": "i prefer p95 many people prefer max or p99",
    "start": "810079",
    "end": "816560"
  },
  {
    "text": "let's look at some of the statistics we can build so we can compute the end-to-end lag",
    "start": "816560",
    "end": "822320"
  },
  {
    "text": "over the population at p95 we can also compute the lag at any node",
    "start": "822320",
    "end": "828480"
  },
  {
    "text": "we can compute the lag in or lag out at any node with lag out and lag in we can compute",
    "start": "828480",
    "end": "835680"
  },
  {
    "text": "what's called a process duration this is the time spent at any node in the chain",
    "start": "835680",
    "end": "841519"
  },
  {
    "text": "why is that useful let's have a look at a real example so imagine this topology we have",
    "start": "841519",
    "end": "849040"
  },
  {
    "text": "a message that hits a system with four nodes the red node green node blue node and",
    "start": "849040",
    "end": "854959"
  },
  {
    "text": "then finally an orange node this is actually a system we run in production",
    "start": "854959",
    "end": "860320"
  },
  {
    "text": "and the graph below is taken from cloudwatch for our production service",
    "start": "860320",
    "end": "865680"
  },
  {
    "text": "as you can see we took the process duration for each node and put it in a pie chart this",
    "start": "865680",
    "end": "872000"
  },
  {
    "text": "gives us the lag contribution of each node in the system as you can see the lag contribution is",
    "start": "872000",
    "end": "878720"
  },
  {
    "text": "approximately equal for each node so no node stands out in fact this is a very",
    "start": "878720",
    "end": "884079"
  },
  {
    "text": "well-tuned system and when we look if we take this pie chart and spread it out over time we get",
    "start": "884079",
    "end": "890240"
  },
  {
    "text": "the graph on the right which shows us that the performance is consistent over time so we have a well-tuned system that",
    "start": "890240",
    "end": "897600"
  },
  {
    "text": "performs consistently over time now that we've talked about lag what",
    "start": "897600",
    "end": "903360"
  },
  {
    "start": "901000",
    "end": "925000"
  },
  {
    "text": "about loss loss is simply a measure of messages lost while transiting the system",
    "start": "903360",
    "end": "910320"
  },
  {
    "text": "messages can be lost for various reasons most of which we can mitigate",
    "start": "910320",
    "end": "915519"
  },
  {
    "text": "the greater the loss the lower the data quality hence our goal is to minimize loss in",
    "start": "915519",
    "end": "921600"
  },
  {
    "text": "order to deliver high quality insights loss",
    "start": "921600",
    "end": "926720"
  },
  {
    "start": "925000",
    "end": "1098000"
  },
  {
    "text": "how do we compute it well loss can be computed as the set",
    "start": "926720",
    "end": "931920"
  },
  {
    "text": "difference of messages between any two points in the system so if we look at our topology from",
    "start": "931920",
    "end": "937199"
  },
  {
    "text": "before the one difference you see here is that instead of a single message translating",
    "start": "937199",
    "end": "942959"
  },
  {
    "text": "translating the system we have let's say 10 messages transferring the system",
    "start": "942959",
    "end": "949120"
  },
  {
    "text": "we can use the following loss table to compute loss so each row in the loss table is a",
    "start": "949199",
    "end": "954720"
  },
  {
    "text": "message each column is a a node in the chain",
    "start": "954720",
    "end": "960639"
  },
  {
    "text": "as message as a message transits the system we tally a one for example message one",
    "start": "960639",
    "end": "967759"
  },
  {
    "text": "is successfully tran transited through the entire system so there's a one in each",
    "start": "967759",
    "end": "973360"
  },
  {
    "text": "column message two also transits each node successfully in our system",
    "start": "973360",
    "end": "979759"
  },
  {
    "text": "however message three while it's successfully processed at the red node",
    "start": "979759",
    "end": "985120"
  },
  {
    "text": "does not make it to the green node therefore it doesn't make it to the blue or the yellow node",
    "start": "985120",
    "end": "990240"
  },
  {
    "text": "at the bottom we can compute the loss per node and then on the lower right as you can",
    "start": "990240",
    "end": "996240"
  },
  {
    "text": "see we can compute the end to end loss in our system which in this case is 50",
    "start": "996240",
    "end": "1003600"
  },
  {
    "text": "in a streaming data system messages never stop flowing so how do we know when to count",
    "start": "1003759",
    "end": "1010720"
  },
  {
    "text": "the key behind this is that we can allocate messages to one minute wide time buckets",
    "start": "1010720",
    "end": "1016880"
  },
  {
    "text": "using message event time for example at the 12 34 minute of a day",
    "start": "1016880",
    "end": "1024319"
  },
  {
    "text": "we can compute a loss table which includes all the messages whose event times",
    "start": "1024319",
    "end": "1030160"
  },
  {
    "text": "fall in the 12 34 time similarly we can do this for other times",
    "start": "1030160",
    "end": "1036798"
  },
  {
    "text": "in the day so let's imagine that right now the time is 12 40 pm",
    "start": "1036799",
    "end": "1043438"
  },
  {
    "text": "as we know in these systems messages may arrive late so we can see four of the tables are still getting updates to",
    "start": "1043439",
    "end": "1050080"
  },
  {
    "text": "their tallies however we may notice that at the 12 35",
    "start": "1050080",
    "end": "1055120"
  },
  {
    "text": "pm table has no longer changing and therefore all messages have arrived that will",
    "start": "1055120",
    "end": "1061280"
  },
  {
    "text": "arrive at this point we can compute loss and any table before this time we can",
    "start": "1061280",
    "end": "1068000"
  },
  {
    "text": "age out and drop this allows us to scale this system and",
    "start": "1068000",
    "end": "1073760"
  },
  {
    "text": "trim tables we don't we no longer need for computation",
    "start": "1073760",
    "end": "1078640"
  },
  {
    "text": "to summarize we wait a few minutes for messages to transit and then compute loss",
    "start": "1079039",
    "end": "1085200"
  },
  {
    "text": "then we raise an alarm if loss occurs over a configured threshold for example say one percent",
    "start": "1085200",
    "end": "1091840"
  },
  {
    "text": "now we have a way to measure the reliability and latency of our system but wait",
    "start": "1091840",
    "end": "1098080"
  },
  {
    "text": "have we tuned our system for performance yet so let's revise our goal",
    "start": "1098080",
    "end": "1104400"
  },
  {
    "text": "we want to build a system that can deliver messages reliably from s to d with low latency",
    "start": "1104400",
    "end": "1111200"
  },
  {
    "text": "to understand streaming system performance we need to understand the components of",
    "start": "1111200",
    "end": "1116320"
  },
  {
    "text": "end-to-end lag the first component i'd like to mention is called the ingest time the ingest",
    "start": "1116320",
    "end": "1122799"
  },
  {
    "text": "time is the time from the last byte in of the request to the first byte out of the response",
    "start": "1122799",
    "end": "1129120"
  },
  {
    "text": "this time includes any overhead we incur in reliably sending messages to kafka",
    "start": "1129120",
    "end": "1136320"
  },
  {
    "text": "at the end of our pipeline we have something called the expel time or the ejest time this is the time to process",
    "start": "1136320",
    "end": "1142880"
  },
  {
    "text": "and eject a message at d any time between these two is called transit time and all three times",
    "start": "1142880",
    "end": "1150160"
  },
  {
    "text": "together are part of the end to end lag",
    "start": "1150160",
    "end": "1154880"
  },
  {
    "text": "now when discussing performance we have to acknowledge that there are something",
    "start": "1155760",
    "end": "1161919"
  },
  {
    "text": "called performance penalties in other words we need to trade off latency for",
    "start": "1161919",
    "end": "1167200"
  },
  {
    "text": "reliability let's look at some of these penalties the first penalty is the ingest penalty",
    "start": "1167200",
    "end": "1173919"
  },
  {
    "text": "in the name of reliability s needs to call kproducer.flush on every inbound api request",
    "start": "1173919",
    "end": "1181760"
  },
  {
    "text": "s also needs to wait for three acts from kafka before sending its api response",
    "start": "1181760",
    "end": "1188640"
  },
  {
    "text": "our approach here is to amortize what that means is that we will support",
    "start": "1188720",
    "end": "1194160"
  },
  {
    "text": "batch apis therefore we get multiple messages per web request we can then amortize the cost over",
    "start": "1194160",
    "end": "1201840"
  },
  {
    "text": "multiple messages thereby limiting this penalty",
    "start": "1201840",
    "end": "1207840"
  },
  {
    "text": "similarly we have something called the expel penalty so there's an observation we need to",
    "start": "1208080",
    "end": "1214000"
  },
  {
    "text": "consider kafka is very fast it's many orders of magnitude faster than typical http round",
    "start": "1214000",
    "end": "1221919"
  },
  {
    "text": "trip times in fact the majority of the expel time is the http round trip time",
    "start": "1221919",
    "end": "1229520"
  },
  {
    "text": "again we will use an amortization approach in each d node we will add batch and",
    "start": "1229520",
    "end": "1235679"
  },
  {
    "text": "parallelism so we will read a batch from kafka then we'll rebash them into smaller batches",
    "start": "1235679",
    "end": "1242480"
  },
  {
    "text": "and use parallel threads to send these out to their destinations this way we can maximize throughput",
    "start": "1242480",
    "end": "1249440"
  },
  {
    "text": "and minimize the the uh expel cost or penalty",
    "start": "1249440",
    "end": "1255360"
  },
  {
    "text": "uh per per message last but not least we have something",
    "start": "1255360",
    "end": "1260720"
  },
  {
    "text": "called a retry penalty in order to run a zero loss pipeline we",
    "start": "1260720",
    "end": "1266240"
  },
  {
    "text": "need to retry messages at d that will succeed given enough attempts",
    "start": "1266240",
    "end": "1271440"
  },
  {
    "text": "as mentioned earlier we have no control about the remote endpoints we have no",
    "start": "1271440",
    "end": "1276640"
  },
  {
    "text": "control over those endpoints so they could be transient failures there might be throttling there might be other",
    "start": "1276640",
    "end": "1282799"
  },
  {
    "text": "things going on that we have no control over so we have to determine whether we can",
    "start": "1282799",
    "end": "1289360"
  },
  {
    "text": "succeed through retries we call these types of failures recoverable failures",
    "start": "1289360",
    "end": "1295280"
  },
  {
    "text": "however there are also some types of cases or errors that are not recoverable",
    "start": "1295280",
    "end": "1302559"
  },
  {
    "text": "for example if we receive a 4xx http response code except for the throttle",
    "start": "1302559",
    "end": "1308480"
  },
  {
    "text": "429s if we receive these four xx types we should not retry because they will not",
    "start": "1308480",
    "end": "1314960"
  },
  {
    "text": "succeed even with retries so",
    "start": "1314960",
    "end": "1320320"
  },
  {
    "text": "to summarize to handle the retry penalty",
    "start": "1320320",
    "end": "1325520"
  },
  {
    "text": "we have to pay some sort of latency penalty on retry so we need to be smart about what we",
    "start": "1325520",
    "end": "1332000"
  },
  {
    "text": "retry which we've already talked about we're not going to retry any non-recoverable failures but we also have to be smart about how",
    "start": "1332000",
    "end": "1339039"
  },
  {
    "text": "we retry one idea that i use is called tiered retries",
    "start": "1339039",
    "end": "1346080"
  },
  {
    "text": "so the tiered retry is we have two tiers we have a local retried here and a global reach right here",
    "start": "1346080",
    "end": "1352080"
  },
  {
    "text": "in the local tier we try to send a message a configurable number of times at d",
    "start": "1352080",
    "end": "1358400"
  },
  {
    "text": "if we exhaust local retries d transfers the message to a global retryer",
    "start": "1358400",
    "end": "1363919"
  },
  {
    "text": "the global retire then retries the message over a longer span of time",
    "start": "1363919",
    "end": "1369600"
  },
  {
    "text": "the architecture looks something like this so at d we will try multiple times to retry a message",
    "start": "1369600",
    "end": "1375919"
  },
  {
    "text": "if we exhaust those local retries we send the message to a topic called the retry in topic",
    "start": "1375919",
    "end": "1382080"
  },
  {
    "text": "a fleet of global retrys will wait a configurable amount of time before they",
    "start": "1382080",
    "end": "1387280"
  },
  {
    "text": "read from this topic and then immediately send the message to the retry out topic",
    "start": "1387280",
    "end": "1392799"
  },
  {
    "text": "d will reconsume the message and try again the beauty of this approach is that in practice we typically see",
    "start": "1392799",
    "end": "1400799"
  },
  {
    "text": "much less than one percent global retries typically much much less than point one percent",
    "start": "1400799",
    "end": "1407520"
  },
  {
    "text": "therefore even though these take longer they don't affect our p95 and to end lags",
    "start": "1407520",
    "end": "1414240"
  },
  {
    "text": "at this point we have a system that works well at low scale but how does the system scale with",
    "start": "1414559",
    "end": "1420640"
  },
  {
    "text": "increasing traffic first let's dispel a myth there is no such thing as a system that",
    "start": "1420640",
    "end": "1427279"
  },
  {
    "text": "can handle infinite scale many believe that by moving to amazon or some other hosted platform you can",
    "start": "1427279",
    "end": "1433919"
  },
  {
    "text": "achieve this type of goal but the reality is that each sys each account",
    "start": "1433919",
    "end": "1439200"
  },
  {
    "text": "has some sort of limits on it so your traffic will be capped in in",
    "start": "1439200",
    "end": "1444640"
  },
  {
    "text": "essence each system no matter where it runs is traffic rated the traffic rating",
    "start": "1444640",
    "end": "1449919"
  },
  {
    "text": "comes from running low test we only achieve higher scale by",
    "start": "1449919",
    "end": "1454960"
  },
  {
    "text": "iteratively running low tests and removing bottlenecks",
    "start": "1454960",
    "end": "1460320"
  },
  {
    "text": "when auto scaling especially for data streams we usually have two goals",
    "start": "1460480",
    "end": "1466480"
  },
  {
    "text": "goal one is to automatically scale out to maintain low latency for example to",
    "start": "1466480",
    "end": "1472080"
  },
  {
    "text": "minimize end to end lag goal two is to scale in to minimize cost",
    "start": "1472080",
    "end": "1477840"
  },
  {
    "text": "for this talk i'm going to focus on goal one when auto scaling there are a few things",
    "start": "1477840",
    "end": "1483200"
  },
  {
    "text": "to consider firstly what can we auto-scale so at least for the last 10 years or so",
    "start": "1483200",
    "end": "1490400"
  },
  {
    "text": "we have been able to auto-scale at least in amazon compute so all of our compute nodes are",
    "start": "1490400",
    "end": "1495840"
  },
  {
    "text": "auto-scalable but what about kafka kafka currently does not support auto",
    "start": "1495840",
    "end": "1501360"
  },
  {
    "text": "scaling but it is something they're working on so in this talk we'll discuss auto",
    "start": "1501360",
    "end": "1507520"
  },
  {
    "text": "scaling compute the most important part of auto scaling is picking the right metric to trigger",
    "start": "1507520",
    "end": "1514080"
  },
  {
    "text": "auto-scaling actions so to do that we have to pick a metric that",
    "start": "1514080",
    "end": "1519440"
  },
  {
    "text": "preserves low latency that goes up as traffic increases and goes down as the microservice scales out",
    "start": "1519440",
    "end": "1528080"
  },
  {
    "text": "in my experience average cpu is the best measure but there are a few things to be wary of",
    "start": "1528080",
    "end": "1534720"
  },
  {
    "text": "if you have locks code synchronization and ios in your code there will be an issue you will never be",
    "start": "1534720",
    "end": "1541919"
  },
  {
    "text": "able to saturate the cpu on your box as traffic increases your cpu will reach",
    "start": "1541919",
    "end": "1548640"
  },
  {
    "text": "a plateau when that happens auto scale out will stop and your latency will increase",
    "start": "1548640",
    "end": "1554400"
  },
  {
    "text": "if you see this in your system the simple way around it is to just lower your threshold below the cpu plateau",
    "start": "1554400",
    "end": "1561120"
  },
  {
    "text": "that will get you around this problem at this point we have a system with",
    "start": "1561120",
    "end": "1566559"
  },
  {
    "text": "non-functional requirements that we desire while we've covered many key elements we've left out many more due to lack of",
    "start": "1566559",
    "end": "1573360"
  },
  {
    "text": "time isolation auto scaling multi-level auto scaling with containers",
    "start": "1573360",
    "end": "1579279"
  },
  {
    "text": "and the cache architecture i'll be covering all of these in upcoming blogs please follow me for",
    "start": "1579279",
    "end": "1585200"
  },
  {
    "text": "updates on those thank you very much for your time",
    "start": "1585200",
    "end": "1590080"
  },
  {
    "start": "1589000",
    "end": "1821000"
  },
  {
    "text": "hello nice sid how are you doing i'm doing well very nice i love your",
    "start": "1592320",
    "end": "1599120"
  },
  {
    "text": "ability to take a very complicated topic and break it down to something that just",
    "start": "1599120",
    "end": "1604559"
  },
  {
    "text": "feels very manageable so weldman thank you very much um i captured some questions here from",
    "start": "1604559",
    "end": "1610480"
  },
  {
    "text": "the chat i want to talk about so to kind of warm the cache the first one i want to talk about is that",
    "start": "1610480",
    "end": "1615919"
  },
  {
    "text": "decomposing the monolithic database into a stream and what smells signals that you might be able to detect you answered",
    "start": "1615919",
    "end": "1622080"
  },
  {
    "text": "that quite a bit in the chat but i wanted to hit on that a little bit another one was around event duplication",
    "start": "1622080",
    "end": "1627120"
  },
  {
    "text": "there were some comments and questions there and then you made a comment about ordering constraints i want to hit on those three um if you have other",
    "start": "1627120",
    "end": "1633360"
  },
  {
    "text": "questions besides those three please put them in the chat we've got about 12 minutes to get in as many as we can so",
    "start": "1633360",
    "end": "1640559"
  },
  {
    "text": "uh kicking it off like starting with streaming systems it it's like you have this monolithic database you have",
    "start": "1640559",
    "end": "1647600"
  },
  {
    "text": "maybe some some joins that are working you talked about some of the signals",
    "start": "1647600",
    "end": "1652799"
  },
  {
    "text": "that you get it's time to start decomposing that but i want to kind of double click on that a bit and you know",
    "start": "1652799",
    "end": "1657840"
  },
  {
    "text": "as someone who's done this many many times what do you recommend for people what do you look for what are the smells",
    "start": "1657840",
    "end": "1663279"
  },
  {
    "text": "where the signals okay thank you so um",
    "start": "1663279",
    "end": "1668720"
  },
  {
    "text": "by the way i i was told by eileen there might be echo so i i just muted during my time when you're talking",
    "start": "1668720",
    "end": "1675279"
  },
  {
    "text": "um so uh yeah for me uh or whatever what i've generally seen is that scale storage",
    "start": "1675279",
    "end": "1681679"
  },
  {
    "text": "scale is not the typical consideration for moving beyond the monolithic database",
    "start": "1681679",
    "end": "1688000"
  },
  {
    "text": "most databases have a disaggregated storage like they'll attach asan or if you're using the cloud you have ebs",
    "start": "1688000",
    "end": "1694000"
  },
  {
    "text": "volumes you can scale that up quite a lot to give you an example paypal had 20",
    "start": "1694000",
    "end": "1699760"
  },
  {
    "text": "petabytes of storage that was all sitting in sands",
    "start": "1699760",
    "end": "1704799"
  },
  {
    "text": "right so that's a lot of storage 20 petabytes of oltp oracle database all hot",
    "start": "1704799",
    "end": "1711200"
  },
  {
    "text": "right most companies when they think of 20 petabytes they're thinking of their offline data in hadoop or s3 they don't",
    "start": "1711200",
    "end": "1718559"
  },
  {
    "text": "think of 20 petabytes attached to an operational oracle database that's quite a lot right",
    "start": "1718559",
    "end": "1724399"
  },
  {
    "text": "so storage is not uh always the the thing that drives",
    "start": "1724399",
    "end": "1730880"
  },
  {
    "text": "moves away from the monolithic database it's typically like access scale",
    "start": "1730880",
    "end": "1736159"
  },
  {
    "text": "or availability so a company might say okay we need a dr solution so that's the first step they'll have a",
    "start": "1736159",
    "end": "1742080"
  },
  {
    "text": "master follower sort of failover strategy that could be",
    "start": "1742080",
    "end": "1747919"
  },
  {
    "text": "a failover to a warm standby that can be about five minutes in some cases",
    "start": "1747919",
    "end": "1753440"
  },
  {
    "text": "and they'll have them these databases distributed across multiple data centers",
    "start": "1753440",
    "end": "1758960"
  },
  {
    "text": "the other case is uh they just split the read-write traffic that's a very common pattern",
    "start": "1758960",
    "end": "1765760"
  },
  {
    "text": "oh well if we're talking about availability so let's we'll say dr and the other you know point about availability would be uh some of them",
    "start": "1765760",
    "end": "1772799"
  },
  {
    "text": "some small number of companies will do an active active uh database",
    "start": "1772799",
    "end": "1778480"
  },
  {
    "text": "that's the availability story and then the one around access",
    "start": "1778480",
    "end": "1783600"
  },
  {
    "text": "skill is typically your bi team is going to run these very long queries um against your database",
    "start": "1783600",
    "end": "1790480"
  },
  {
    "text": "and they'll end up asking for a lot of indexes to be built to avoid full table scans and all of that query traffic can cause your right",
    "start": "1790480",
    "end": "1798240"
  },
  {
    "text": "traffic to fail because some databases will run out of what's called undo space or rollback segments",
    "start": "1798240",
    "end": "1804080"
  },
  {
    "text": "and their rights will actually get cancelled because of long-running queries so usually at that point you",
    "start": "1804080",
    "end": "1809200"
  },
  {
    "text": "tell the bi team hey you have to use your own olap database and we'll replicate data from this oltp",
    "start": "1809200",
    "end": "1815600"
  },
  {
    "text": "oracle postgres to snowflake or something and you can run your queries against that",
    "start": "1815600",
    "end": "1820640"
  },
  {
    "text": "yeah very nice okay so gail and ask and jenny plus wondered about kind of data corruption and event",
    "start": "1820640",
    "end": "1826640"
  },
  {
    "start": "1821000",
    "end": "2097000"
  },
  {
    "text": "duplication so let's break that out first data question data corruption and then we'll talk about maybe um",
    "start": "1826640",
    "end": "1833520"
  },
  {
    "text": "duplicates and maybe even kafka processing guarantees so first how do you think about data corruption it's",
    "start": "1833520",
    "end": "1838559"
  },
  {
    "text": "just something you push to a dead letter queue how do you think about corruption when you're when you're working with the",
    "start": "1838559",
    "end": "1843679"
  },
  {
    "text": "what you just described i see data corruption is a very hard to define thing",
    "start": "1843679",
    "end": "1850159"
  },
  {
    "text": "so let's say we're talking about databases right let's say oracle postgres mysql",
    "start": "1850159",
    "end": "1856240"
  },
  {
    "text": "whatever it is so you write data to that database and there were generally two ways that",
    "start": "1856240",
    "end": "1863039"
  },
  {
    "text": "data can be replicated to a you know i don't want to use the word slave but follower database right one is physical",
    "start": "1863039",
    "end": "1870240"
  },
  {
    "text": "replication and the other one is logical replication so physical replication is when the",
    "start": "1870240",
    "end": "1875600"
  },
  {
    "text": "blocks on the disk get replicated out if you have discorruption in the master you're riding to you do replicate that",
    "start": "1875600",
    "end": "1882240"
  },
  {
    "text": "garbage out and you're in trouble because the disc that went bad just",
    "start": "1882240",
    "end": "1888000"
  },
  {
    "text": "quickly replicated it to all the slaves okay so but then what right if you",
    "start": "1888000",
    "end": "1893200"
  },
  {
    "text": "replicate that data then what happened and then uh you're in trouble and the only thing you can do is to um",
    "start": "1893200",
    "end": "1900399"
  },
  {
    "text": "you know recover a snapshot and use nightly snapshots so you would have lost",
    "start": "1900399",
    "end": "1906480"
  },
  {
    "text": "data since that snapshot that's one case the other case is logical replication which just means that you replay the",
    "start": "1906480",
    "end": "1912960"
  },
  {
    "text": "commit log on your follower databases and what is it what is",
    "start": "1912960",
    "end": "1918960"
  },
  {
    "text": "corruption there i mean if uh you're replaying the transaction and one database has a discorruption the",
    "start": "1918960",
    "end": "1925840"
  },
  {
    "text": "others won't so you just fail over you promote a follower to mastership",
    "start": "1925840",
    "end": "1931519"
  },
  {
    "text": "in that case um and then the third is just like",
    "start": "1931519",
    "end": "1937120"
  },
  {
    "text": "what is like corruption in the sense of like semantic corruption like i have i rolled out some code that",
    "start": "1937120",
    "end": "1942799"
  },
  {
    "text": "code is writing garbage and i detect that code wrote garbage so i roll back that code but whatever i",
    "start": "1942799",
    "end": "1949760"
  },
  {
    "text": "wrote to the database is now there that was semantic corruption because of a bug in",
    "start": "1949760",
    "end": "1956159"
  },
  {
    "text": "processing that can happen in stream processing too so the way i solve this in stream processing is that",
    "start": "1956159",
    "end": "1962960"
  },
  {
    "text": "it's actually easier to solve in stream processing than it is in databases so in stream processing when code is deployed",
    "start": "1962960",
    "end": "1969600"
  },
  {
    "text": "to let's say you know we had those streams a b c d to b",
    "start": "1969600",
    "end": "1974720"
  },
  {
    "text": "um i detect after when i when i actually roll a new code out i saved the checkpoint",
    "start": "1974720",
    "end": "1980640"
  },
  {
    "text": "somewhere and i i that checkpoint i saved for whatever wherever it was reading that",
    "start": "1980640",
    "end": "1986480"
  },
  {
    "text": "cons the consumer i save it somewhere and uh if i have observability that",
    "start": "1986480",
    "end": "1993200"
  },
  {
    "text": "looks for errors or corruption or this kind of problem it automatically tells the deployer your deployment is bad",
    "start": "1993200",
    "end": "1999600"
  },
  {
    "text": "maybe after 10 minutes the deployment will then get rolled back and the checkpoint will get re reset",
    "start": "1999600",
    "end": "2005679"
  },
  {
    "text": "and so in that 10 minutes any garbage that went out when the code is rolled back the old",
    "start": "2005679",
    "end": "2011679"
  },
  {
    "text": "checkpoint comes with it and it will replay 10 minutes of data and this time it will be good and yeah",
    "start": "2011679",
    "end": "2018080"
  },
  {
    "text": "usually you'll over make the sync because they'll have you know that's how we solve it so in the second half of that question",
    "start": "2018080",
    "end": "2024000"
  },
  {
    "text": "was about duplicates but before you you answered it kind of about final sync but before you do that talk a little bit",
    "start": "2024000",
    "end": "2029840"
  },
  {
    "text": "about kafka prosecute processing guarantee semantics and then um your response",
    "start": "2029840",
    "end": "2035200"
  },
  {
    "text": "yeah so i use kafka as ex at least once because syncs will have a primary key",
    "start": "2035200",
    "end": "2041919"
  },
  {
    "text": "typically and last right wins right no ordering guarantees whatsoever um",
    "start": "2041919",
    "end": "2047679"
  },
  {
    "text": "i've i've heard that they have this thing called exactly once but i don't think that's",
    "start": "2047679",
    "end": "2052800"
  },
  {
    "text": "uh that's just possible i think they can do a good job of getting there but anything",
    "start": "2052800",
    "end": "2057839"
  },
  {
    "text": "even writing to a process can get a read timeout right like two processes communicate",
    "start": "2057839",
    "end": "2063760"
  },
  {
    "text": "there's a tcp setting for re-timeout i send a request to you i don't hear back in time i assume it didn't get to you so",
    "start": "2063760",
    "end": "2070480"
  },
  {
    "text": "i send it again that can happen in any distributed system so",
    "start": "2070480",
    "end": "2075919"
  },
  {
    "text": "um you know in your distributed system you are using kafka along the way but any",
    "start": "2075919",
    "end": "2081118"
  },
  {
    "text": "point around there can cause duplicates so i that that's not a true thing this",
    "start": "2081119",
    "end": "2088398"
  },
  {
    "text": "exactly one semantics like for a full stream so you need to solve it anyway so i just assume",
    "start": "2088399",
    "end": "2094079"
  },
  {
    "text": "uh at least once delivery gotcha um you made a statement i want you to",
    "start": "2094079",
    "end": "2099359"
  },
  {
    "start": "2097000",
    "end": "2351000"
  },
  {
    "text": "double click on so you said i heavily advised against introducing ordering constraints in the system ordering can",
    "start": "2099359",
    "end": "2104720"
  },
  {
    "text": "always be taken care of at the time of writing to a sync in other words db search engines are soon afterward can",
    "start": "2104720",
    "end": "2110079"
  },
  {
    "text": "you double click on that a little bit yeah i mean ordering guarantee you know",
    "start": "2110079",
    "end": "2115680"
  },
  {
    "text": "it means using key topics uh for example in kafka and they have this concept in other systems as well",
    "start": "2115680",
    "end": "2122720"
  },
  {
    "text": "so um i guess so so so ordering you can so you have a",
    "start": "2122720",
    "end": "2129040"
  },
  {
    "text": "stream at some point that data has to land in persistent storage and uh we already talked kind of about",
    "start": "2129040",
    "end": "2135920"
  },
  {
    "text": "the fact that retries can happen and data you know unless you want data to flow along a specific partition key",
    "start": "2135920",
    "end": "2142960"
  },
  {
    "text": "partitions i should say not topics keep partitions you can't really guarantee this concept of",
    "start": "2142960",
    "end": "2151680"
  },
  {
    "text": "in-order delivery but when you use keyed partitions you may",
    "start": "2151680",
    "end": "2158800"
  },
  {
    "text": "not get uniform uh scalability right uniform usage because",
    "start": "2158800",
    "end": "2164160"
  },
  {
    "text": "now you're pinning you're using some sort of key and if you have a you know a non-uniform",
    "start": "2164160",
    "end": "2170160"
  },
  {
    "text": "distribution among keys then your load is not distributed evenly so it's sort of an anti-pattern to use this key",
    "start": "2170160",
    "end": "2177280"
  },
  {
    "text": "partition concept and anyway when data lands in a database you can use a primary key or lance in a search engine",
    "start": "2177280",
    "end": "2182800"
  },
  {
    "text": "use a primary key and it will resolve any out of order delivery even it'll",
    "start": "2182800",
    "end": "2188480"
  },
  {
    "text": "it'll handle retries it'll handle all of that and if you're writing to blob storage like s3",
    "start": "2188480",
    "end": "2195040"
  },
  {
    "text": "uh azure blobster is gcs hdfs then you use post processing so after the data",
    "start": "2195040",
    "end": "2200240"
  },
  {
    "text": "lands uh you post-process it to remove duplicates and you can run it right you",
    "start": "2200240",
    "end": "2205280"
  },
  {
    "text": "know within a few seconds after it lands yeah so sid you mentioned a couple of",
    "start": "2205280",
    "end": "2210640"
  },
  {
    "text": "follow-up blog posts um one was multi-level auto scaling with containers",
    "start": "2210640",
    "end": "2216320"
  },
  {
    "text": "um and i put your twitter handle in there someone asked what it was so follow him there to be able to",
    "start": "2216320",
    "end": "2221760"
  },
  {
    "text": "to look for a little bit more but maybe could you give us a little preview when you say multi-level auto scaling with",
    "start": "2221760",
    "end": "2227760"
  },
  {
    "text": "containers and this and this which you just described could you talk a little bit about what you're thinking about for that post",
    "start": "2227760",
    "end": "2233280"
  },
  {
    "text": "sure sure so you know the company i'm at right now we do um we we built our streams using all",
    "start": "2233280",
    "end": "2239280"
  },
  {
    "text": "of these ilities and um we are able to i think you asked you",
    "start": "2239280",
    "end": "2244720"
  },
  {
    "text": "might have asked another question earlier to me um about how do we handle scale you know what is the concept of infinite scale",
    "start": "2244720",
    "end": "2251040"
  },
  {
    "text": "so auto scaling is part of that story so our system for example uh can scale up",
    "start": "2251040",
    "end": "2257200"
  },
  {
    "text": "50x within two minutes of uh starting with a traffic burst and in those you know for two minutes",
    "start": "2257200",
    "end": "2264000"
  },
  {
    "text": "it'll scale up 50x for it for that level of traffic and it won't impact um like right after",
    "start": "2264000",
    "end": "2270320"
  },
  {
    "text": "like two minute period it will basically have 99",
    "start": "2270320",
    "end": "2276480"
  },
  {
    "text": "uh sub second latency end to end and even on call duration for like calls into the api so it settles very quickly",
    "start": "2276480",
    "end": "2282800"
  },
  {
    "text": "and to achieve that we have to we run on kubernetes on amazon so kubernetes",
    "start": "2282800",
    "end": "2288960"
  },
  {
    "text": "we use hpa with a cpu target and then our container ec2",
    "start": "2288960",
    "end": "2295359"
  },
  {
    "text": "auto scaling uses memory um so i'll be talking about how we achieve this",
    "start": "2295359",
    "end": "2300800"
  },
  {
    "text": "um scalability uh in a future block clause",
    "start": "2300800",
    "end": "2306480"
  },
  {
    "text": "all the issues we sort of had you know with the control plane being overwhelmed at high scale",
    "start": "2306480",
    "end": "2311680"
  },
  {
    "text": "sure route tables and a bunch of that stuff so we are at time so we're going to have",
    "start": "2311680",
    "end": "2318079"
  },
  {
    "text": "a zoom here just uh right after this so pop over there carlos just asked a good",
    "start": "2318079",
    "end": "2323680"
  },
  {
    "text": "question and it basically was you know when should i use the batch process for using a steam stream architecture so",
    "start": "2323680",
    "end": "2331040"
  },
  {
    "text": "that'll be the first question that we kind of kick off over there so if you want to hear that answer or more hop over the zoom room let's chat thanks sid",
    "start": "2331040",
    "end": "2338320"
  },
  {
    "text": "awesome job thank you",
    "start": "2338320",
    "end": "2341839"
  },
  {
    "text": "[Music]",
    "start": "2344230",
    "end": "2349679"
  }
]
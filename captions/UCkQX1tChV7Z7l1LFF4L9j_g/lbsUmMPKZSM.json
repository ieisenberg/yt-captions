[
  {
    "text": "foreign [Music]",
    "start": "0",
    "end": "16278"
  },
  {
    "text": "ER from confluent today I will talk about resilient real-time data streaming across the edge",
    "start": "16279",
    "end": "22619"
  },
  {
    "text": "and hybrid cloud in this talk you will see several real world deployments and very different",
    "start": "22619",
    "end": "27840"
  },
  {
    "text": "architectures I will cover all the pros and cons so that you would understand the trade-offs to build a resilient",
    "start": "27840",
    "end": "34920"
  },
  {
    "text": "architecture let's get started first of all here's the agenda for this",
    "start": "34920",
    "end": "40379"
  },
  {
    "text": "session I will talk a little bit about why you need resilient Enterprise architectures and what the requirements are and then",
    "start": "40379",
    "end": "47760"
  },
  {
    "text": "cover how real-time data streaming will help with that after that I cover several different",
    "start": "47760",
    "end": "53579"
  },
  {
    "text": "architectures and use real world examples across different Industries as you can see in the agenda I talk about",
    "start": "53579",
    "end": "59520"
  },
  {
    "text": "Automotive banking retail and the public sector the main goal is to show you a broad",
    "start": "59520",
    "end": "65580"
  },
  {
    "text": "spectrum of architectures I've seen in a real world so that you can learn how you architect your own architecture to solve",
    "start": "65580",
    "end": "73680"
  },
  {
    "text": "problems let's begin with the definition of a resilient Enterprise architecture and",
    "start": "73680",
    "end": "80700"
  },
  {
    "text": "why we want to do that here's a grade or maybe it's not so great but an interesting example from",
    "start": "80700",
    "end": "86580"
  },
  {
    "text": "Disney so Disney and the theme parks Disney World in the US had a problem so",
    "start": "86580",
    "end": "92520"
  },
  {
    "text": "there was an AWS Cloud outage so what's the problem with the theme parks you might wonder well the theme parks are",
    "start": "92520",
    "end": "99119"
  },
  {
    "text": "still there but the problem is that Disney uses a mobile app to collect all the customer data and provide a good",
    "start": "99119",
    "end": "105240"
  },
  {
    "text": "customer experience but if the cloud is not available anymore then you cannot use the theme park you cannot do rides",
    "start": "105240",
    "end": "111840"
  },
  {
    "text": "you cannot order in the restaurants anymore and I think this is a great example why we're still in architectures are super",
    "start": "111840",
    "end": "118619"
  },
  {
    "text": "important and why they can look very differently depending on the use case that's what I will cover Today Show you",
    "start": "118619",
    "end": "125040"
  },
  {
    "text": "edge hybrid and Cloud first architectures with all their pros and cons and in this case maybe a little bit",
    "start": "125040",
    "end": "131340"
  },
  {
    "text": "of edge Computing and resiliency might help to make the customers happy in the theme parks",
    "start": "131340",
    "end": "137780"
  },
  {
    "text": "and so there's very different reasons why you need resilient architectures this is a survey um one of my former",
    "start": "137940",
    "end": "145379"
  },
  {
    "text": "colleagues and Friends Gwen Shapiro did actually the queries from 2017 right but it's still more or less up to date the",
    "start": "145379",
    "end": "151860"
  },
  {
    "text": "point is to show there's very different reasons why people build resilient architectures 1dc might get new yes um",
    "start": "151860",
    "end": "159840"
  },
  {
    "text": "Disaster Recovery is a key use case but sometimes it's also about latency and",
    "start": "159840",
    "end": "164879"
  },
  {
    "text": "distance or implications of the cost regarding how where you replicate your",
    "start": "164879",
    "end": "170099"
  },
  {
    "text": "data and sometimes it also has legal reasons so there's many reasons why resilient architectures are required",
    "start": "170099",
    "end": "179180"
  },
  {
    "text": "and if we talk about that well there's any two terms we need to understand and it doesn't matter what technology you",
    "start": "179180",
    "end": "185459"
  },
  {
    "text": "use like we today talk about real-time streaming with Kafka but in general you need to solve the problem of the RPO and",
    "start": "185459",
    "end": "191459"
  },
  {
    "text": "the RTO the RPO is the recovery Point objective and this defines how much data you will",
    "start": "191459",
    "end": "199319"
  },
  {
    "text": "lose in case of a downtime or disaster on the other side the RTO the recovery",
    "start": "199319",
    "end": "204959"
  },
  {
    "text": "time of job objective means what's the actual recovery period before we are online again and your systems",
    "start": "204959",
    "end": "211140"
  },
  {
    "text": "work again both of these terms are very important and you always need to ask yourself what do I need initially many people say well",
    "start": "211140",
    "end": "218879"
  },
  {
    "text": "of course I need zero downtime and zero data loss but well this is very often hard to architect as we have seen in the",
    "start": "218879",
    "end": "225000"
  },
  {
    "text": "Disney example before and what I will show you in many different examples in the next slides",
    "start": "225000",
    "end": "230400"
  },
  {
    "text": "so keep that in mind always ask yourself what downtime or data loss is okay for",
    "start": "230400",
    "end": "235440"
  },
  {
    "text": "me and based on that you can architect what you need",
    "start": "235440",
    "end": "240140"
  },
  {
    "text": "in the end zero RPO requires synchronous replication this means even if one note",
    "start": "241260",
    "end": "248159"
  },
  {
    "text": "is down if you're replicated synchronously it guarantees that you have zero data loss",
    "start": "248159",
    "end": "253319"
  },
  {
    "text": "and on the other side if you need zero downtime then you need a seamless failover so it's pretty easy definitions",
    "start": "253319",
    "end": "259799"
  },
  {
    "text": "but it's super hard to architect that and that's what I will cover today and that by the way also shows you why",
    "start": "259799",
    "end": "265160"
  },
  {
    "text": "real-time data is so important here because if you have replication in a batch process from one node to another",
    "start": "265160",
    "end": "271560"
  },
  {
    "text": "or from One Cloud reach into another well that takes longer right instead if you replicate data in real time even in",
    "start": "271560",
    "end": "278820"
  },
  {
    "text": "case of disaster you'll lose much less data with that",
    "start": "278820",
    "end": "283699"
  },
  {
    "text": "and with that this directly brings me to real-time data streaming",
    "start": "283979",
    "end": "289580"
  },
  {
    "text": "in the end it's pretty easy real-time data beats slow data think about that in",
    "start": "290580",
    "end": "296160"
  },
  {
    "text": "your business for your use cases and many of the people in this audience are not business people but Architects",
    "start": "296160",
    "end": "302520"
  },
  {
    "text": "or developers but nevertheless think about what you're implementing or when you talk to your business colleagues ask",
    "start": "302520",
    "end": "308280"
  },
  {
    "text": "yourself and your colleagues hey if you want to get this data and process it is it better now or later where later could",
    "start": "308280",
    "end": "315360"
  },
  {
    "text": "be in a few minutes hours or days and in almost all use cases it's better",
    "start": "315360",
    "end": "320820"
  },
  {
    "text": "to process data continuously in real time this can be to increase the customer experience to reduce the cost or to",
    "start": "320820",
    "end": "328620"
  },
  {
    "text": "reduce the risk so there's many options why you would do that and here's just a few examples the point is real-time data almost",
    "start": "328620",
    "end": "335520"
  },
  {
    "text": "always beats slow data and that's important for the use cases but then also of course for the resiliency behind",
    "start": "335520",
    "end": "341820"
  },
  {
    "text": "the architectures as we discussed regarding downtime and data loss which directly impacts how your customer",
    "start": "341820",
    "end": "348240"
  },
  {
    "text": "experience is or how high the risk is for your business",
    "start": "348240",
    "end": "352520"
  },
  {
    "text": "and when we talk about processing data in real time then Apache Kafka is the de",
    "start": "353639",
    "end": "358800"
  },
  {
    "text": "facto standard for that right so there's many vendors behind it so I've worked for confluent but there's many other vendors and also even companies that",
    "start": "358800",
    "end": "366720"
  },
  {
    "text": "don't use Kafka but another framework they at least use the Kafka protocol very often because it became standard so",
    "start": "366720",
    "end": "373680"
  },
  {
    "text": "while this presentation is about success stories and architectures around Apache Kafka obviously the same can be applied",
    "start": "373680",
    "end": "380759"
  },
  {
    "text": "to other Technologies like when you use a cloud native service from a cloud provider like let's say AWS Kinesis and",
    "start": "380759",
    "end": "387660"
  },
  {
    "text": "so on or maybe you're trying to use Apache Pulsar or whatever else you want to try",
    "start": "387660",
    "end": "393660"
  },
  {
    "text": "the key point however is that Kafka is not just a messaging platform or ingestion layer like many people think",
    "start": "393660",
    "end": "400259"
  },
  {
    "text": "yes it's real-time messaging at any scale but in addition to that a key component is the storage you store all",
    "start": "400259",
    "end": "407220"
  },
  {
    "text": "the events in your infrastructure within the event streaming platform and with this you achieve true",
    "start": "407220",
    "end": "413520"
  },
  {
    "text": "decoupling between the producers and consumers you handle the back pressure automatically because often consumers",
    "start": "413520",
    "end": "419759"
  },
  {
    "text": "cannot handle their load from the producer side and you can also replay existing data",
    "start": "419759",
    "end": "425759"
  },
  {
    "text": "and if you think about these characteristics of the storage for the decoupling and back pressure handling well that's a key component you can",
    "start": "425759",
    "end": "432780"
  },
  {
    "text": "leverage for building a resilient architecture and that's what we will see in this talk about different approaches no matter if",
    "start": "432780",
    "end": "439620"
  },
  {
    "text": "you're at the edge in a cloud or in a hybrid architecture and in addition to that Kafka is also",
    "start": "439620",
    "end": "445319"
  },
  {
    "text": "about data integration with Kafka connect and data processing in real time continuously with tools like Kafka",
    "start": "445319",
    "end": "452520"
  },
  {
    "text": "streams or k SQL and that in the end is what Kafka is so it's not just a messaging system this is super important",
    "start": "452520",
    "end": "458699"
  },
  {
    "text": "when we talk about use cases in general but then also about how to build resilient architectures because",
    "start": "458699",
    "end": "464400"
  },
  {
    "text": "messaging alone doesn't help it's about the combination of messaging and storage and integration and processing of data",
    "start": "464400",
    "end": "473300"
  },
  {
    "text": "I don't want to go too deep into Kafka today if you have never heard that however I want to give some Basics so",
    "start": "474000",
    "end": "480360"
  },
  {
    "text": "Kafka is a commit log this means it's append only from the producer side and",
    "start": "480360",
    "end": "485460"
  },
  {
    "text": "then consumers consume it whenever they need or can in real time in milliseconds in near real time in seconds or maybe in",
    "start": "485460",
    "end": "493080"
  },
  {
    "text": "batch or in an interactive way with a request so it's very flexible and you can also replay the data that's the",
    "start": "493080",
    "end": "499259"
  },
  {
    "text": "strength of the storage behind the streaming log and with that Kafka is a resilient",
    "start": "499259",
    "end": "505860"
  },
  {
    "text": "system by Nature while you can deploy a single broker of Kafka and that's sometimes done at the",
    "start": "505860",
    "end": "511979"
  },
  {
    "text": "edge but in most cases you deploy Kafka as a distributed system and with that you get the resiliency out of the box Kafka is",
    "start": "511979",
    "end": "519419"
  },
  {
    "text": "built for failure this means a broker can go down the network can go down a disk can break this doesn't matter",
    "start": "519419",
    "end": "525420"
  },
  {
    "text": "because if you configure Kafka correctly you can still guarantee zero downtime and zero data loss and with that that's",
    "start": "525420",
    "end": "533399"
  },
  {
    "text": "the reason why Kafka is not just used for analytics use cases but also for Mission critical workloads and without",
    "start": "533399",
    "end": "540540"
  },
  {
    "text": "going into more detail keep in mind Kafka is a highly available system and it provides other features like rolling",
    "start": "540540",
    "end": "546899"
  },
  {
    "text": "upgrades and backwards compatibility between server and clients so that you can continuously run your business and",
    "start": "546899",
    "end": "553800"
  },
  {
    "text": "that's what I understand under a resilient system you don't have downtime from maintenance or if an issue occurs",
    "start": "553800",
    "end": "560279"
  },
  {
    "text": "with the hardware here's an example for a Kafka",
    "start": "560279",
    "end": "566519"
  },
  {
    "text": "architecture in this case I'm showing a few confluent components obviously working for confluent but even if you",
    "start": "566519",
    "end": "572820"
  },
  {
    "text": "use open source Kafka or maybe another vendor you glue together the right components from the Kafka ecosystem in",
    "start": "572820",
    "end": "579360"
  },
  {
    "text": "this case the central data Hub is the platform right this is the Clusters but",
    "start": "579360",
    "end": "584880"
  },
  {
    "text": "then you also use Kafka connect for data integration like to a database or an iot",
    "start": "584880",
    "end": "590160"
  },
  {
    "text": "interface and then you consume all this data however the messaging part is not really",
    "start": "590160",
    "end": "596160"
  },
  {
    "text": "what adds the business value the business value is to continuously process the data and that's what stream processing does in this case we're using",
    "start": "596160",
    "end": "603779"
  },
  {
    "text": "Kafka native Technologies like k-sql and Kafka streams but obviously you could also use something like Apache fling or any other",
    "start": "603779",
    "end": "610800"
  },
  {
    "text": "stream processing engine for that and then of course there's also data sync so Kafka connect can also be used",
    "start": "610800",
    "end": "616560"
  },
  {
    "text": "to ingest data into a data lake or database if you don't need or don't want to process data only in real time",
    "start": "616560",
    "end": "624000"
  },
  {
    "text": "right and this is in the end overall architecture which has different components that work together to build",
    "start": "624000",
    "end": "629880"
  },
  {
    "text": "an integration layer and to build business Logic on top of that",
    "start": "629880",
    "end": "635540"
  },
  {
    "text": "and with that then if we once again think a little bit about bigger deployments you can deploy it in very",
    "start": "636300",
    "end": "641640"
  },
  {
    "text": "different flavors here's just a few examples of that like replication between different regions or",
    "start": "641640",
    "end": "648060"
  },
  {
    "text": "even continents this is also part of the Kafka ecosystem so you build one infrastructure to have a highly scalable",
    "start": "648060",
    "end": "655200"
  },
  {
    "text": "and reliable infrastructure that even replicates data across regions or continents or between on-prem and the",
    "start": "655200",
    "end": "661740"
  },
  {
    "text": "cloud or between multi-cloud you can do this with open source Kafka using mirror Maker 2 or with some more",
    "start": "661740",
    "end": "669000"
  },
  {
    "text": "advanced tools like at confluent we have cluster linking that directly connects clusters together on the Kafka protocol",
    "start": "669000",
    "end": "674519"
  },
  {
    "text": "as a commercial offering no matter what you choose for the replications but the point is you can deploy Kafka very",
    "start": "674519",
    "end": "681959"
  },
  {
    "text": "differently depending on the slas this is what we discussed in the beginning about the RPO and RTO",
    "start": "681959",
    "end": "688320"
  },
  {
    "text": "ideally you have zero downtime and no data loss like in the orange cluster where you stretch one cluster across",
    "start": "688320",
    "end": "694500"
  },
  {
    "text": "regions but that's too hard to deploy for every use case so sometimes you have aggregation clusters where with some",
    "start": "694500",
    "end": "701459"
  },
  {
    "text": "downtime might be okay especially in analytics use cases like in yellow and so with that keep in mind you can",
    "start": "701459",
    "end": "707579"
  },
  {
    "text": "deploy Kafka in its ecosystem in very different architectures and it has always pros and cons and different",
    "start": "707579",
    "end": "713519"
  },
  {
    "text": "complexity but that's what you should be aware of when you think about how to architect a",
    "start": "713519",
    "end": "718920"
  },
  {
    "text": "resilient architecture across Edge hybrid and multi-cloud",
    "start": "718920",
    "end": "725480"
  },
  {
    "text": "here is one example for that so this is now a use case from the shipping industry here now you'll see what's",
    "start": "726300",
    "end": "732360"
  },
  {
    "text": "happening in the real world so you have very different environments and infrastructures",
    "start": "732360",
    "end": "737640"
  },
  {
    "text": "let's get started on the top right so here you see the cloud in this case now ideally you have a",
    "start": "737640",
    "end": "743940"
  },
  {
    "text": "serverless offering because in the cloud in best case you don't have to worry about infrastructure it has elastic",
    "start": "743940",
    "end": "749760"
  },
  {
    "text": "scaling and you have consumption based pricing for that for example with confluent cloud in my",
    "start": "749760",
    "end": "754860"
  },
  {
    "text": "case again right so here you have all your real-time workloads and integrated with other systems",
    "start": "754860",
    "end": "760019"
  },
  {
    "text": "in some cases however you still have data on-prem so on the bottom right you'll see where a Kafka cluster is",
    "start": "760019",
    "end": "766200"
  },
  {
    "text": "running in the data center connecting to traditional databases old Erp systems",
    "start": "766200",
    "end": "771600"
  },
  {
    "text": "the Mainframe or whatever you need there and this also replicates data to the",
    "start": "771600",
    "end": "777480"
  },
  {
    "text": "cloud and the other way back and once again as I said in the beginning real-time data beats slow data",
    "start": "777480",
    "end": "782880"
  },
  {
    "text": "it's not just true for business but also for this kind of resiliency and replication scenarios because if you",
    "start": "782880",
    "end": "789000"
  },
  {
    "text": "replicate data in real time in case of disaster you're still not falling behind much and don't lose much data because it's",
    "start": "789000",
    "end": "795060"
  },
  {
    "text": "replicated to the cloud in real time and then on the other side on the left side we have echio's cases where you",
    "start": "795060",
    "end": "801240"
  },
  {
    "text": "deploy a small version of Kafka either as a single node like in the Drone or",
    "start": "801240",
    "end": "806579"
  },
  {
    "text": "still as a mission critical cluster with three Brokers on the ship for Edge analytics disconnected from the",
    "start": "806579",
    "end": "811800"
  },
  {
    "text": "cloud or from the data center this example is just to make clear there's many different options how to",
    "start": "811800",
    "end": "817980"
  },
  {
    "text": "deploy Kafka in such a real world scenario and it always has trade-offs so that's what I will cover in the next",
    "start": "817980",
    "end": "824220"
  },
  {
    "text": "sections as you see now in the agenda here intentionally I choose examples across",
    "start": "824220",
    "end": "831120"
  },
  {
    "text": "different Industries so that you see how that is deployed but also as you see in the agenda this is now very different",
    "start": "831120",
    "end": "837180"
  },
  {
    "text": "kind of architectures with different requirements and setups and therefore the resiliency is also very different",
    "start": "837180",
    "end": "843540"
  },
  {
    "text": "depending on very deploy Kafka and why you deployed there let me get started with the first",
    "start": "843540",
    "end": "850139"
  },
  {
    "text": "example so this is now about Cloud first in serverless this is where everybody's going right so ideally everything is in",
    "start": "850139",
    "end": "857700"
  },
  {
    "text": "the cloud and you don't have to manage it you just use it well that's true if it's possible",
    "start": "857700",
    "end": "864120"
  },
  {
    "text": "here is an example where this is possible and this might surprise some people this is and this is why I choose",
    "start": "864120",
    "end": "870120"
  },
  {
    "text": "this use case actually it's a use case where BMW is running event streaming in",
    "start": "870120",
    "end": "875639"
  },
  {
    "text": "the cloud as a server is offering on azure however they are actually directly connecting with their smart Factories at",
    "start": "875639",
    "end": "882540"
  },
  {
    "text": "the edge but in this case BMW's goal is to not worry about hardware and infrastructure",
    "start": "882540",
    "end": "889019"
  },
  {
    "text": "if you don't need to so they deploy in a cloud first what's possible in this case they leverage event",
    "start": "889019",
    "end": "894480"
  },
  {
    "text": "streaming to consume all the data from the smart factories machines plcs sensors robots",
    "start": "894480",
    "end": "902579"
  },
  {
    "text": "all the data is flowing into the cloud in real time via direct connection to the Azure cloud and then the data is",
    "start": "902579",
    "end": "909240"
  },
  {
    "text": "processed in real time at scale a key reason why BMW choose this",
    "start": "909240",
    "end": "914639"
  },
  {
    "text": "architecture is that they get their data into the cloud ones and then they provide it as a data Hub",
    "start": "914639",
    "end": "920459"
  },
  {
    "text": "with Kafka to every business unit and application that needs access to it tap into the data with Kafka and because",
    "start": "920459",
    "end": "927899"
  },
  {
    "text": "it's also as I discussed a storage system it doesn't matter what technology consumes the data it doesn't matter what",
    "start": "927899",
    "end": "933899"
  },
  {
    "text": "communication paradigms consumes the data so it's very flexible so you can connect to that from your real-time",
    "start": "933899",
    "end": "939779"
  },
  {
    "text": "consumer Kafka native maybe you can consume from it from your data Lake more near real-time or batch",
    "start": "939779",
    "end": "946320"
  },
  {
    "text": "and you can connect to it via web service and rest API from a mobile app this is the the architecture that BMW",
    "start": "946320",
    "end": "953100"
  },
  {
    "text": "chose here and so this is very interesting right Cloud only but still connecting to data at the edge so the",
    "start": "953100",
    "end": "959519"
  },
  {
    "text": "cloud infrastructure is resilient and because it also has a direct connection to the edge this works well",
    "start": "959519",
    "end": "965279"
  },
  {
    "text": "from an SLA perspective for BMW",
    "start": "965279",
    "end": "969500"
  },
  {
    "text": "let me go a little bit deeper into the stream processing part because that's also crucial when you want to build resilient architectures",
    "start": "970920",
    "end": "977820"
  },
  {
    "text": "for Brazilian applications so when we talk about data streaming then we get sensor data in all the time",
    "start": "977820",
    "end": "984360"
  },
  {
    "text": "and then we can build applications around that an application can be anything like in",
    "start": "984360",
    "end": "989579"
  },
  {
    "text": "this case we're doing conditional monitoring on temperature spikes in this case we're using Java code with Kafka",
    "start": "989579",
    "end": "994620"
  },
  {
    "text": "streams so here you'll see every single event is processed by itself so that's pretty straightforward but",
    "start": "994620",
    "end": "1001339"
  },
  {
    "text": "this scales from millions of events per second and this can run everywhere where a Kafka cluster is in this case if we",
    "start": "1001339",
    "end": "1008480"
  },
  {
    "text": "deploy that in a use case like BMW this is running in the cloud and typically next to the serverless environment for",
    "start": "1008480",
    "end": "1015860"
  },
  {
    "text": "low latency there can also be Advanced use cases where you do stateful processing",
    "start": "1015860",
    "end": "1023300"
  },
  {
    "text": "in this case you do not just process each event by itself but different events and correlate them for whatever",
    "start": "1023300",
    "end": "1030020"
  },
  {
    "text": "the use case is like in this case we are creating a sliding window and continuously monitor the last seconds or",
    "start": "1030020",
    "end": "1035720"
  },
  {
    "text": "minutes or in this case hour to detect a spike in this case of the temperature",
    "start": "1035720",
    "end": "1040819"
  },
  {
    "text": "for continuous anomaly detection and as you can see here I'm you're very flexible with use cases and deploy them",
    "start": "1040819",
    "end": "1047298"
  },
  {
    "text": "and still it's a resilient application because it's based on Kafka with all the",
    "start": "1047299",
    "end": "1052820"
  },
  {
    "text": "characteristics Kafka has that's also true for the application not just for the server side so this code in this",
    "start": "1052820",
    "end": "1060080"
  },
  {
    "text": "case it's K SQL now automatically handles failover it handles latency",
    "start": "1060080",
    "end": "1065660"
  },
  {
    "text": "issues it handles disconnectivity outages of Hardware because it's all built into the Kafka protocol to solve",
    "start": "1065660",
    "end": "1072860"
  },
  {
    "text": "these problems and then you can even do more advanced use cases like in this case we've built",
    "start": "1072860",
    "end": "1078980"
  },
  {
    "text": "a user defined function to embed a tensorflow model so in this case we are doing real-time scoring of analytic",
    "start": "1078980",
    "end": "1085400"
  },
  {
    "text": "models applied against every single event or against a stateful aggregation of",
    "start": "1085400",
    "end": "1090740"
  },
  {
    "text": "events depending on your business logic but the point here is that you can't build very resilient real-time",
    "start": "1090740",
    "end": "1096080"
  },
  {
    "text": "applications with that and in the same way by the way this is also true for the replication you do",
    "start": "1096080",
    "end": "1101840"
  },
  {
    "text": "between different Kafka clusters because it's also using the Kafka product called and it is super interesting if you want",
    "start": "1101840",
    "end": "1108799"
  },
  {
    "text": "to replicate data and process it even across different data centers",
    "start": "1108799",
    "end": "1114039"
  },
  {
    "text": "it was an example where we see everything right however reality is sometimes",
    "start": "1115820",
    "end": "1121580"
  },
  {
    "text": "resiliency needs even more than that sometimes you need multi-region deployments this means even in case of",
    "start": "1121580",
    "end": "1128539"
  },
  {
    "text": "disaster a cloud goes down or data center goes down you need business continuity",
    "start": "1128539",
    "end": "1133760"
  },
  {
    "text": "this is in the end where we have an RTO of zero where we have no downtime and then RTO an RPO of Zero no data loss",
    "start": "1133760",
    "end": "1144580"
  },
  {
    "text": "here's an example from JPMorgan so this is financial services this is the typically the most critical deployments",
    "start": "1145100",
    "end": "1150799"
  },
  {
    "text": "with compliance and a lot of legal constraints so that you need to guarantee that you don't lose data even",
    "start": "1150799",
    "end": "1156679"
  },
  {
    "text": "in case of disaster so in this case jpmoring deploys a",
    "start": "1156679",
    "end": "1161960"
  },
  {
    "text": "separate independent Kafka cluster to two different data centers and then they replicate the data between",
    "start": "1161960",
    "end": "1168380"
  },
  {
    "text": "the data centers using real-time replication and they also handle the switch over so",
    "start": "1168380",
    "end": "1174799"
  },
  {
    "text": "if one data center is down they also switch the producers and the consumers to the other Data Center",
    "start": "1174799",
    "end": "1180740"
  },
  {
    "text": "this is obviously a very complex approach so you need to get that right including the testing and all these",
    "start": "1180740",
    "end": "1186380"
  },
  {
    "text": "things as you can see the link here so a JP Morgan Chase talked about it in 45 minutes just about this implementation",
    "start": "1186380",
    "end": "1193160"
  },
  {
    "text": "so it's super interesting to learn how the end users deploy such an environment",
    "start": "1193160",
    "end": "1198860"
  },
  {
    "text": "however having said that this example is still not 100 resilient so this is the",
    "start": "1198860",
    "end": "1204919"
  },
  {
    "text": "use case where we replicate data between two Kafka clusters asynchronously",
    "start": "1204919",
    "end": "1210140"
  },
  {
    "text": "in this case it's done with confluent replicator but the same would be true with mirror maker reviews open source",
    "start": "1210140",
    "end": "1215660"
  },
  {
    "text": "the case is so if there is that disaster you still lose a little bit of data because you're replicating data",
    "start": "1215660",
    "end": "1221780"
  },
  {
    "text": "asynchronously between the data centers it's still good enough for most use cases because it's super hard",
    "start": "1221780",
    "end": "1228380"
  },
  {
    "text": "total synchronous replication between data centers especially if they are far away from each other because then you",
    "start": "1228380",
    "end": "1234799"
  },
  {
    "text": "have latency problems and inconsistency so always understand the trade-offs between your requirements and how hard",
    "start": "1234799",
    "end": "1241700"
  },
  {
    "text": "it is to implement them now I want to show you another example however here you know we're really",
    "start": "1241700",
    "end": "1248660"
  },
  {
    "text": "stretching a single Kafka cluster across regions",
    "start": "1248660",
    "end": "1254240"
  },
  {
    "text": "with this solution then you have synchronous replication and with that you can really guarantee zero data loss",
    "start": "1254240",
    "end": "1260179"
  },
  {
    "text": "even in case a complete data center goes down so just to be clear so this is a feature",
    "start": "1260179",
    "end": "1266059"
  },
  {
    "text": "of confluent platform this is not available in open source but this shows how you can then Implement your own",
    "start": "1266059",
    "end": "1271580"
  },
  {
    "text": "solution or buy something where you can then solve the problems that are even harder to do and in this case how this",
    "start": "1271580",
    "end": "1277940"
  },
  {
    "text": "works is that as discussed you need synchronous replication between data centers to guarantee zero data loss",
    "start": "1277940",
    "end": "1284780"
  },
  {
    "text": "however because you get latency issues and inconsistent system what we did here we provide the option",
    "start": "1284780",
    "end": "1291440"
  },
  {
    "text": "so that you can decide which topics are replicated synchronously between the",
    "start": "1291440",
    "end": "1297020"
  },
  {
    "text": "Brokers within a single stretch Kafka cluster and as you see in the picture on the left side the transactional workloads",
    "start": "1297020",
    "end": "1304100"
  },
  {
    "text": "that's what we replicate in a synchronous way zero data loss even in case of disaster",
    "start": "1304100",
    "end": "1309679"
  },
  {
    "text": "for The Not So relevant data we replicate it asynchronously within the single Kafka cluster and in this case",
    "start": "1309679",
    "end": "1316580"
  },
  {
    "text": "here is data loss in case of disaster and now you can decide per business case what you replicate synchronously",
    "start": "1316580",
    "end": "1323480"
  },
  {
    "text": "right so you still have the performance guarantees but still also can keep your slas for the critical data sets and this",
    "start": "1323480",
    "end": "1330260"
  },
  {
    "text": "is now a really resilient data center we battle tested this before the ga across",
    "start": "1330260",
    "end": "1335419"
  },
  {
    "text": "the US with U.S West Central and East so this is really across hundreds of miles so not just next to each other",
    "start": "1335419",
    "end": "1342200"
  },
  {
    "text": "so this is super powerful but therefore much harder to implement and to deploy that's the trade-off of this",
    "start": "1342200",
    "end": "1349960"
  },
  {
    "text": "on the other side here's another great open source example so this is Robin Hood so their mission is to democratize",
    "start": "1351320",
    "end": "1357080"
  },
  {
    "text": "finance for all and what I really like about um their use cases using Kafka is that they're",
    "start": "1357080",
    "end": "1362360"
  },
  {
    "text": "using it for everything so they're using it for analytical use cases and also for Mission critical use cases like in their",
    "start": "1362360",
    "end": "1369440"
  },
  {
    "text": "screenshots from their presentation you see that they're doing stock trading clearing crypto trading messaging and",
    "start": "1369440",
    "end": "1375559"
  },
  {
    "text": "push notifications so all these critical applications are running in real time",
    "start": "1375559",
    "end": "1380720"
  },
  {
    "text": "across the Kafka cluster between the different applications so this is one more point to mention",
    "start": "1380720",
    "end": "1386419"
  },
  {
    "text": "again so still too many people in my opinion think about Kafka just for data ingestion into a data Lake and for",
    "start": "1386419",
    "end": "1392840"
  },
  {
    "text": "analytical workloads Kafka is ready to process transactional data in Mission critical scenarios",
    "start": "1392840",
    "end": "1399500"
  },
  {
    "text": "without data laws another example of that is Thought Machine so this is just one more of the",
    "start": "1399500",
    "end": "1405500"
  },
  {
    "text": "examples the billing transactional use cases this is a core banking platform in a cloud native way",
    "start": "1405500",
    "end": "1410780"
  },
  {
    "text": "for transactional workloads it's running on top of Kafka and provides the ecosystem to build core",
    "start": "1410780",
    "end": "1417559"
  },
  {
    "text": "pension functionalities here you see the true decoupling between the different consumers microservices",
    "start": "1417559",
    "end": "1423559"
  },
  {
    "text": "and not all of them need to be real-time milliseconds you could also easily connect a batch consumer",
    "start": "1423559",
    "end": "1428720"
  },
  {
    "text": "or you can also easily connect python clients or that your data scientist can use this jupiterate",
    "start": "1428720",
    "end": "1434539"
  },
  {
    "text": "notebook and replay historical data from the Kafka cluster there's many options here and this is my",
    "start": "1434539",
    "end": "1440360"
  },
  {
    "text": "key point you can use it for analytics but also for transactional data and resilient use cases like car banking",
    "start": "1440360",
    "end": "1448059"
  },
  {
    "text": "and well even more interestingly Kafka has a transaction API that's also what many people don't know",
    "start": "1449240",
    "end": "1455840"
  },
  {
    "text": "the transaction API actually is intentionally called exactly one semantics because in distributed systems",
    "start": "1455840",
    "end": "1463780"
  },
  {
    "text": "transactions work very differently than in your traditional Oracle to ibmq",
    "start": "1463780",
    "end": "1468799"
  },
  {
    "text": "integration where you do a two-phase commit protocol two-phase commit doesn't scale so it doesn't work in distributed system so",
    "start": "1468799",
    "end": "1474980"
  },
  {
    "text": "you need to have another solution and I have no idea how this works under the hood this is what the smart",
    "start": "1474980",
    "end": "1480440"
  },
  {
    "text": "Engineers of the Kafka Community built years ago but the point is as you see on the left side",
    "start": "1480440",
    "end": "1485659"
  },
  {
    "text": "you have a transaction API to solve the business problem to guarantee that each message that is",
    "start": "1485659",
    "end": "1491960"
  },
  {
    "text": "produced once from our producer is durable and consumed exactly once from each consumer and that's what you need",
    "start": "1491960",
    "end": "1498140"
  },
  {
    "text": "in a transaction business case right and so just be aware that this exists and this has not much performance impact",
    "start": "1498140",
    "end": "1505640"
  },
  {
    "text": "so this is optional but you can use it if you have transactional workloads and if you want to have resiliency end to",
    "start": "1505640",
    "end": "1512000"
  },
  {
    "text": "end then you should use it it's much easier than removing duplicates by yourself",
    "start": "1512000",
    "end": "1518320"
  },
  {
    "text": "now after we talked a lot about transactional workloads including multi-region stretch clusters",
    "start": "1520159",
    "end": "1526400"
  },
  {
    "text": "there is more resilient requirements now let's talk about hybrid cloud architectures",
    "start": "1526400",
    "end": "1533179"
  },
  {
    "text": "and I actually choose one of the most interesting examples I think so this is Royal Caribbean so cruise ships and",
    "start": "1533179",
    "end": "1539539"
  },
  {
    "text": "tours for tourists as you can imagine each ship has some",
    "start": "1539539",
    "end": "1545120"
  },
  {
    "text": "I.T data but here it's a little bit more than that so they are running Mission critical Kafka clusters on each ship for",
    "start": "1545120",
    "end": "1552440"
  },
  {
    "text": "doing point of sale integration recommendations and notifications to customers Edge Analytics",
    "start": "1552440",
    "end": "1560299"
  },
  {
    "text": "reservation loyalty platform all these things you need to do in such a business they are running this on each ship",
    "start": "1560299",
    "end": "1566240"
  },
  {
    "text": "because each ship has very bad internet connection and it's very expensive so they need to have a resilient",
    "start": "1566240",
    "end": "1572120"
  },
  {
    "text": "architecture at the edge for real-time data and then when one of the ships comes",
    "start": "1572120",
    "end": "1578000"
  },
  {
    "text": "back to the harbor then you have very good internet connection for a few hours then you can replicate all the data into",
    "start": "1578000",
    "end": "1583580"
  },
  {
    "text": "the cloud and you can do this for every ship after every tour and in the cloud then you can integrate",
    "start": "1583580",
    "end": "1589880"
  },
  {
    "text": "with your data Lake for doing analytics you can integrate with your CRM and loyalty platform for synchronizing the",
    "start": "1589880",
    "end": "1595460"
  },
  {
    "text": "data and then the ship goes on the next tour so this is a very exciting use case for hybrid architectures",
    "start": "1595460",
    "end": "1602980"
  },
  {
    "text": "so here is how this looks like in more General so you have one bigger Kafka cluster this is maybe running in a cloud",
    "start": "1603320",
    "end": "1610760"
  },
  {
    "text": "like here or maybe in your data center where you connect to your traditional it systems like a CRM system or a",
    "start": "1610760",
    "end": "1616640"
  },
  {
    "text": "third-party payment provider but then also as you see in the bottom we also integrate with the small local",
    "start": "1616640",
    "end": "1623360"
  },
  {
    "text": "Kafka clusters they are required for a resilient Edge Computing in the retail store or on the ship but",
    "start": "1623360",
    "end": "1631640"
  },
  {
    "text": "they also communicate with the central big Kafka cluster all of that in real time in a reliable way using the Kafka",
    "start": "1631640",
    "end": "1637940"
  },
  {
    "text": "protocol and if you go deeper into this Edge like",
    "start": "1637940",
    "end": "1643580"
  },
  {
    "text": "in this case the retail store or in the example from before from the ship here now you can do all the edge Computing",
    "start": "1643580",
    "end": "1649580"
  },
  {
    "text": "whatever that is for example you can integrate with the point of sale and with the payment so",
    "start": "1649580",
    "end": "1654980"
  },
  {
    "text": "even if you are disconnected from the cloud you can do payments and sell things",
    "start": "1654980",
    "end": "1661220"
  },
  {
    "text": "because if this doesn't work then your business is down and this happens in reality right so all of this happens at the edge and",
    "start": "1661220",
    "end": "1668419"
  },
  {
    "text": "then if there's good Intel connectivity of course you replicate it back to the cloud we have customers especially now in",
    "start": "1668419",
    "end": "1674840"
  },
  {
    "text": "retail in malls but during the day the Wi-Fi is very bad so they can't replicate much but during the night when",
    "start": "1674840",
    "end": "1680299"
  },
  {
    "text": "there is no customers then they replicate all the data from the day into the cloud this is a very common Cloud",
    "start": "1680299",
    "end": "1687020"
  },
  {
    "text": "infrastructure or hybrid infrastructure and Kafka is so good here because it's not just a messaging system it's also a",
    "start": "1687020",
    "end": "1694100"
  },
  {
    "text": "storage system and with this storage you truly decouple the themes so you can still do the point of sale but you",
    "start": "1694100",
    "end": "1701120"
  },
  {
    "text": "cannot push it to the cloud where your central system is so you keep it in the Kafka lock and automatically when there",
    "start": "1701120",
    "end": "1706820"
  },
  {
    "text": "is Kafka connection to the cloud then it starts replicating it's all built into the framework and this is how you build",
    "start": "1706820",
    "end": "1713600"
  },
  {
    "text": "resilient architectures easily by leveraging the tools for that and not building that by yourself because it's",
    "start": "1713600",
    "end": "1719299"
  },
  {
    "text": "super hard well and with that we see how",
    "start": "1719299",
    "end": "1726140"
  },
  {
    "text": "omnichannel works much better also with Kafka again it's super important to understand that Kafka is a storage",
    "start": "1726140",
    "end": "1732440"
  },
  {
    "text": "system This truly decouples things and stores things for later replay like in this case we had a newsletter",
    "start": "1732440",
    "end": "1739100"
  },
  {
    "text": "first 90 and 60 days ago and then 10 and 8",
    "start": "1739100",
    "end": "1744320"
  },
  {
    "text": "days ago we used our car configurator so we configured a car and changed it and",
    "start": "1744320",
    "end": "1749659"
  },
  {
    "text": "then at day 0 we are going into the dealership and here the salesperson already knows all historical and",
    "start": "1749659",
    "end": "1756200"
  },
  {
    "text": "real-time information about me he knows real time because it's a location-based service with my app I'm walking into the",
    "start": "1756200",
    "end": "1762080"
  },
  {
    "text": "store and in that moment the data about me is replayed from the Kafka log historical data and in some cases even",
    "start": "1762080",
    "end": "1769460"
  },
  {
    "text": "better it's Advanced analytics where the salesperson even gets a recommendation from the AI engine in the back end",
    "start": "1769460",
    "end": "1775299"
  },
  {
    "text": "recommending a specific discount because of your loyalty and because of your history and so on and this is the power",
    "start": "1775299",
    "end": "1781460"
  },
  {
    "text": "of building omnichannel because it's not just a messaging system but it's a resilient architecture within one",
    "start": "1781460",
    "end": "1787700"
  },
  {
    "text": "platform where you do messaging in real time but also storage for replayability",
    "start": "1787700",
    "end": "1792980"
  },
  {
    "text": "and data integration and data processing for correlation at the right context at the right time",
    "start": "1792980",
    "end": "1800440"
  },
  {
    "text": "so last but not least let me go even deeper into the edge so this is about safety critical and",
    "start": "1801500",
    "end": "1807919"
  },
  {
    "text": "cyber security and these kind of use cases there are many examples the first one here is if you think about a train",
    "start": "1807919",
    "end": "1814460"
  },
  {
    "text": "system the train is only rails all the time so here you also can do data processing at the edge like in a retail",
    "start": "1814460",
    "end": "1821059"
  },
  {
    "text": "store this has a resilient architecture because the it is small but it's running",
    "start": "1821059",
    "end": "1827360"
  },
  {
    "text": "on computers in the train and with that also it's very efficient while it's resilient so you don't need to connect",
    "start": "1827360",
    "end": "1834500"
  },
  {
    "text": "to the cloud all the time when you want to understand what is the estimated time of arrival you get this information once",
    "start": "1834500",
    "end": "1840740"
  },
  {
    "text": "pushed from the cloud into the train and each customer on the train can consume",
    "start": "1840740",
    "end": "1845779"
  },
  {
    "text": "the data from a local broker and the same is when you for example consume any other data or when you want to do a seat",
    "start": "1845779",
    "end": "1851179"
  },
  {
    "text": "reservation in a restaurant on the train this train is completely decoupled from another train so it can be local Edge",
    "start": "1851179",
    "end": "1856820"
  },
  {
    "text": "processing and once again because it's not just messaging but a complete platform around data processing and integration you can",
    "start": "1856820",
    "end": "1864860"
  },
  {
    "text": "connect all these other systems no matter if they're real time or file based Legacy integration like in a train",
    "start": "1864860",
    "end": "1870260"
  },
  {
    "text": "you often have a Windows Server running right that's totally flexible how you do that",
    "start": "1870260",
    "end": "1875980"
  },
  {
    "text": "and then this is also more about um safety and about um criticality for",
    "start": "1876220",
    "end": "1881539"
  },
  {
    "text": "cyber attacks so here is an example where we have day one energy in the oil and gas business so here on the left",
    "start": "1881539",
    "end": "1888860"
  },
  {
    "text": "side you see these small yellow boxes at the edge this is one of our Hardware Partners where we have deployed confluent",
    "start": "1888860",
    "end": "1895039"
  },
  {
    "text": "platform to do Edge Computing in real time as you see in the picture they're collecting data but they're also",
    "start": "1895039",
    "end": "1900500"
  },
  {
    "text": "processing the data because in this resilient architectures not everything should go to the cloud it",
    "start": "1900500",
    "end": "1906500"
  },
  {
    "text": "should be processed at the edge it's much more cost efficient and also the internet connection is not perfect right",
    "start": "1906500",
    "end": "1911899"
  },
  {
    "text": "so you do most of the critical workloads at the edge while you still replicate some of the",
    "start": "1911899",
    "end": "1917539"
  },
  {
    "text": "aggregated data into the cloud from each Edge site and this is a super powerful example",
    "start": "1917539",
    "end": "1924140"
  },
  {
    "text": "about these hybrid architectures where the edge is often disconnected and only",
    "start": "1924140",
    "end": "1929299"
  },
  {
    "text": "connects from time to time or sometimes you really run workloads only at the edge and don't connect them at all to",
    "start": "1929299",
    "end": "1934700"
  },
  {
    "text": "the internet for cyber security reasons that's then more an aircraft environment that's what we also see a lot these days",
    "start": "1934700",
    "end": "1941860"
  },
  {
    "text": "and with that my last example is also about defense defense really critical and super",
    "start": "1942080",
    "end": "1948080"
  },
  {
    "text": "interesting that's something where we need a resilient streaming architecture even",
    "start": "1948080",
    "end": "1953899"
  },
  {
    "text": "closer to the edge like you see the command post right at the top this is where a mission critical Kafka cluster",
    "start": "1953899",
    "end": "1960500"
  },
  {
    "text": "is running for doing compute and analytics around this area in the military for the command post but each",
    "start": "1960500",
    "end": "1967520"
  },
  {
    "text": "Soldier actually also has installed a very small computer which also is running a Kafka broker not a cluster",
    "start": "1967520",
    "end": "1974360"
  },
  {
    "text": "here it's just a single broker it's good enough and this is collecting sensor data when the soldier is moving around like he's",
    "start": "1974360",
    "end": "1981020"
  },
  {
    "text": "making pictures he's collecting other data whatever and even if he's outside of the internet wide area he can",
    "start": "1981020",
    "end": "1988100"
  },
  {
    "text": "continue collecting data because it's stored on the Kafka broker and then when he's going back into a",
    "start": "1988100",
    "end": "1994220"
  },
  {
    "text": "wide area network de Kafka automatically starts replicating the data into the command",
    "start": "1994220",
    "end": "1999919"
  },
  {
    "text": "post and from there you can do the analytics in the command post for this region and you can also replicate",
    "start": "1999919",
    "end": "2005860"
  },
  {
    "text": "information back to confluent cloud in this case where we collect data from all the different command posts to make more Central decisions",
    "start": "2005860",
    "end": "2013179"
  },
  {
    "text": "and with this example I think it has shown you very well how you can design very different architectures all of them resilient",
    "start": "2013179",
    "end": "2020140"
  },
  {
    "text": "depending on the requirements you have on the infrastructure you have and the slas you have",
    "start": "2020140",
    "end": "2026440"
  },
  {
    "text": "now my last slide is really why do people work with us well I mean many people are using Kafka and it's totally",
    "start": "2026440",
    "end": "2032380"
  },
  {
    "text": "fine right it's a great open source tool the point is it's more like a car engine so you should ask yourself do you want",
    "start": "2032380",
    "end": "2038140"
  },
  {
    "text": "to build your own car or do you want to get a real car a complete car that is safe and secure that provides the",
    "start": "2038140",
    "end": "2044679"
  },
  {
    "text": "operations the monitoring the connectivity all these things then that's why people use confluent platform",
    "start": "2044679",
    "end": "2050200"
  },
  {
    "text": "the self-managed solution or if you're in the cloud and you're even more lucky because they'll be providing the",
    "start": "2050200",
    "end": "2055599"
  },
  {
    "text": "self-driving car level five which is the only truly fully managed offering of",
    "start": "2055599",
    "end": "2061240"
  },
  {
    "text": "Kafka in its ecosystem in the cloud and in this case across all clouds including AWS Azure Google and Alibaba and China",
    "start": "2061240",
    "end": "2068800"
  },
  {
    "text": "so this is our business model and that's why people come to us so if you're more interested just let us",
    "start": "2068800",
    "end": "2076118"
  },
  {
    "text": "know and come to us with the use cases you're interested in feel free to connect to me on Twitter and Linkedin to",
    "start": "2076119",
    "end": "2081220"
  },
  {
    "text": "stay in touch I hope you learned a lot about resilient architectures with real-time data streaming and enjoy the",
    "start": "2081220",
    "end": "2088060"
  },
  {
    "text": "conference thank you",
    "start": "2088060",
    "end": "2090960"
  },
  {
    "text": "thank you so much for that that was great um we are going to a time of questions",
    "start": "2093700",
    "end": "2099580"
  },
  {
    "text": "now so please do pop your questions into the into the chat if you if you have any",
    "start": "2099580",
    "end": "2105460"
  },
  {
    "text": "um but I can actually kick one off myself so um one of the things I found",
    "start": "2105460",
    "end": "2110859"
  },
  {
    "text": "really interesting was the The Edge use cases um that that you have and um I",
    "start": "2110859",
    "end": "2116920"
  },
  {
    "text": "wanted to sort of find out like when you have the edge cases where you've got limited Hardware so you want to try and",
    "start": "2116920",
    "end": "2123460"
  },
  {
    "text": "preserve you know the data but there's a possibility that the sort of edge use",
    "start": "2123460",
    "end": "2128560"
  },
  {
    "text": "case the The Edge clusters or servers won't actually be able to connect to the",
    "start": "2128560",
    "end": "2133780"
  },
  {
    "text": "cloud for quite some time are there any strategies for sort of ensuring that you",
    "start": "2133780",
    "end": "2139060"
  },
  {
    "text": "don't lose data by virtue of the fact that you just run out of storage on the actual Edge",
    "start": "2139060",
    "end": "2144579"
  },
  {
    "text": "um uh sort of class age yeah that's a great question a great question and in the end obviously at the edge you",
    "start": "2144579",
    "end": "2150640"
  },
  {
    "text": "typically have limited Hardware right it will cost up you have um like in a small drone",
    "start": "2150640",
    "end": "2155920"
  },
  {
    "text": "you're very limited on the other side last week I had a call with a customer who was working with wind turbines and",
    "start": "2155920",
    "end": "2161740"
  },
  {
    "text": "they actually expect that they are sometimes offline for a complete week and that really means High volumes of data and depending on this setup of",
    "start": "2161740",
    "end": "2167740"
  },
  {
    "text": "course you need to keep storage because without storage um you cannot keep the data in a case of disaster like and the disconnectivity",
    "start": "2167740",
    "end": "2174220"
  },
  {
    "text": "and therefore of course you have to plan depending on the use case and the other strategy however is then um if you",
    "start": "2174220",
    "end": "2181000"
  },
  {
    "text": "really get disconnected longer than you expect maybe not just a week in this case but then really a month because",
    "start": "2181000",
    "end": "2186400"
  },
  {
    "text": "this is really complex to fix sometimes in such an environment and then the other strategy is a little bit the work",
    "start": "2186400",
    "end": "2191500"
  },
  {
    "text": "around because even if you store data at the edge in this case there are still different kind of value and data and in",
    "start": "2191500",
    "end": "2198040"
  },
  {
    "text": "that case you can embed very simple rules engine by saying for example if you're disconnected longer than a week",
    "start": "2198040",
    "end": "2204099"
  },
  {
    "text": "then only store data which is XY said but not ABC or the other option is",
    "start": "2204099",
    "end": "2209500"
  },
  {
    "text": "instead of them storing all the data in this case now we pre-process the data at the edge and Only Store the aggregations",
    "start": "2209500",
    "end": "2216099"
  },
  {
    "text": "of the data or filter it out in the beginning already because realities I mean this high volume data sets right",
    "start": "2216099",
    "end": "2222460"
  },
  {
    "text": "like in a in a car today you produce a few terabytes per day and in a wind turbine even more and in these cases",
    "start": "2222460",
    "end": "2229240"
  },
  {
    "text": "anyway most of the data is not really relevant so there is definitely workarounds and this again like I",
    "start": "2229240",
    "end": "2234640"
  },
  {
    "text": "discussed in the beginning always depends on the slas you define how much data can you lose and if a disaster",
    "start": "2234640",
    "end": "2240640"
  },
  {
    "text": "strikes whatever it is what do you do then so you also need to plan for that and these are some of the workarounds",
    "start": "2240640",
    "end": "2245859"
  },
  {
    "text": "for that kind of disaster then yeah that's really interesting actually because I think sometimes people think",
    "start": "2245859",
    "end": "2251680"
  },
  {
    "text": "oh well I just have to have a simple strategy like first in first out and I just lose all the last things but",
    "start": "2251680",
    "end": "2256960"
  },
  {
    "text": "actually if you have that computing power at the edge you can you can actually decide based on the context you",
    "start": "2256960",
    "end": "2263260"
  },
  {
    "text": "know so whether it's a week or a month maybe you discard different data and only kind of stand up stuff so that's",
    "start": "2263260",
    "end": "2268420"
  },
  {
    "text": "that's really interesting yeah okay um we have some questions come through so one one one we've got here is how good",
    "start": "2268420",
    "end": "2275619"
  },
  {
    "text": "is the transactional feature of Kafka have you used it in any of your sort of",
    "start": "2275619",
    "end": "2281200"
  },
  {
    "text": "clients in in production yeah that's also a great question and people are always surprised when they see this",
    "start": "2281200",
    "end": "2286780"
  },
  {
    "text": "feature actually and interestingly so um I work for conference over five years so five years ago this feature was released",
    "start": "2286780",
    "end": "2293859"
  },
  {
    "text": "so shortly after I started exactly one someone takes were introduced into Kafka including their transaction API and this",
    "start": "2293859",
    "end": "2301300"
  },
  {
    "text": "is the API is more powerful than most people think you can even send events to more than a single Kafka topic you send",
    "start": "2301300",
    "end": "2307900"
  },
  {
    "text": "you you open your panties as you say send messages to topic one to topic two to topic three and either you send all",
    "start": "2307900",
    "end": "2314200"
  },
  {
    "text": "of them enter and or none of them it's transactional Behavior including rollback so it's really important to",
    "start": "2314200",
    "end": "2319960"
  },
  {
    "text": "understand that how this is implemented is very different from a transactional workload you know from a traditional",
    "start": "2319960",
    "end": "2326079"
  },
  {
    "text": "system like an IBM and Q connecting to a Mainframe or to an Oracle database that",
    "start": "2326079",
    "end": "2331660"
  },
  {
    "text": "is typically implemented with two phase commit transactions a very complex protocol it doesn't scale well in Kafka",
    "start": "2331660",
    "end": "2337420"
  },
  {
    "text": "it works very differently so um for example now you use ident producers a",
    "start": "2337420",
    "end": "2342520"
  },
  {
    "text": "very good design pattern and distributed architectures and end-to-end as an end user you don't have to worry it works",
    "start": "2342520",
    "end": "2348339"
  },
  {
    "text": "it's battled nested many customers are using it and so you really don't have to worry about that and many customers have",
    "start": "2348339",
    "end": "2354460"
  },
  {
    "text": "this in production and this is Super Battle tested in the last years yeah we've got some clients as well",
    "start": "2354460",
    "end": "2360700"
  },
  {
    "text": "actually that make it take advantage of this so it's as you say it's been around for a little while it has it's called it",
    "start": "2360700",
    "end": "2367540"
  },
  {
    "text": "has certain constraints which you need to be aware of but it's um it certainly is a good feature and maybe to add one more thing here right because also in in",
    "start": "2367540",
    "end": "2374440"
  },
  {
    "text": "general the kind of data streaming is a different Paradigm right um even an Oracle database you typically do one",
    "start": "2374440",
    "end": "2380619"
  },
  {
    "text": "transaction that's what you think about if you talk about data streaming you typically have come data in then you",
    "start": "2380619",
    "end": "2386079"
  },
  {
    "text": "correlate it with other data then you do the business transaction and you do more data so um the real added value of the",
    "start": "2386079",
    "end": "2391839"
  },
  {
    "text": "transactional feature is not not really just about the last consumer but it's about the end-to-end pipeline with",
    "start": "2391839",
    "end": "2397359"
  },
  {
    "text": "different Kafka applications and if you use transactional Behavior within this end-to-end pipeline where you have",
    "start": "2397359",
    "end": "2403480"
  },
  {
    "text": "different Kafka applications in the middle then with transactional behavior you don't have to check for duplicates",
    "start": "2403480",
    "end": "2408640"
  },
  {
    "text": "in each of these locations and so on and again because the performance impact is very low it's really something like only",
    "start": "2408640",
    "end": "2414040"
  },
  {
    "text": "10 percent this is a huge win if you build real stream processing applications so you really also not just",
    "start": "2414040",
    "end": "2419680"
  },
  {
    "text": "have to think differently about how the transactions work under the hood but also that a good stream processing",
    "start": "2419680",
    "end": "2425079"
  },
  {
    "text": "application uses very different design patterns than a normal web servers and database API application",
    "start": "2425079",
    "end": "2431260"
  },
  {
    "text": "great um so another question we've got is um asking about eventual consistency and",
    "start": "2431260",
    "end": "2437440"
  },
  {
    "text": "sort of real time and and what the sort of challenges are that uh that you see from that perspective yeah that's",
    "start": "2437440",
    "end": "2443560"
  },
  {
    "text": "another great point right because of eventual consistency and that's in the end the drawback you have in such a distributed system it depends a little",
    "start": "2443560",
    "end": "2450820"
  },
  {
    "text": "bit on the application you build but the general rule of thumb is that also you simply build applications differently so",
    "start": "2450820",
    "end": "2458320"
  },
  {
    "text": "in the end it's okay if you do receive sometimes a message not after five milliseconds but sometimes if you have a",
    "start": "2458320",
    "end": "2464500"
  },
  {
    "text": "spike of P99 and it's 100 millisecond because if you build the application in the right way this is totally okay for",
    "start": "2464500",
    "end": "2471520"
  },
  {
    "text": "most application if you really need something else there is other patterns like that so um I actually interestingly",
    "start": "2471520",
    "end": "2478480"
  },
  {
    "text": "um wrote a blog post on my blog last week about comparing the JMS API for message queues compared to Kafka and one",
    "start": "2478480",
    "end": "2485020"
  },
  {
    "text": "key difference is that a JMS API out of the box provides a request reply pattern that's something what you also can doing",
    "start": "2485020",
    "end": "2491619"
  },
  {
    "text": "Kafka but it's done very differently but here again there's examples for that like also if you check my blog um",
    "start": "2491619",
    "end": "2497560"
  },
  {
    "text": "there's a link to a spring framework which uses the spring JMS template that even can Implement synchronous request",
    "start": "2497560",
    "end": "2504339"
  },
  {
    "text": "reply patterns with Kafka so the key Point here to understand is don't think about your understanding from NQ or esps",
    "start": "2504339",
    "end": "2512859"
  },
  {
    "text": "or traditional transactions and try to replenish it with Kafka but really take a look at the designs pattern on the",
    "start": "2512859",
    "end": "2518680"
  },
  {
    "text": "market like from Martin Fowler and so on for distributed systems and there you learn if you do it differently you build",
    "start": "2518680",
    "end": "2524079"
  },
  {
    "text": "applications in another way but that's how this is expected then and then you can build the same business logic like",
    "start": "2524079",
    "end": "2529960"
  },
  {
    "text": "in the example I brought up about Robin Hood right Robin Hood is building the most critical transactional behavior for",
    "start": "2529960",
    "end": "2535660"
  },
  {
    "text": "trading applications that's all running via Kafka apis so you can do it but you need to get it right and therefore the",
    "start": "2535660",
    "end": "2541839"
  },
  {
    "text": "last hint for that um the earlier you get it right in the beginning the better right so I've seen too many customers that tried it for",
    "start": "2541839",
    "end": "2548500"
  },
  {
    "text": "here by themselves and then they ask for review and we told them well this doesn't look good so the recommendation",
    "start": "2548500",
    "end": "2553960"
  },
  {
    "text": "is really that in the early stages ask an expert to regular architecture because stream processing is a different",
    "start": "2553960",
    "end": "2560200"
  },
  {
    "text": "pattern than request reply and then transactional behavior and so you really need to do it the right way from the",
    "start": "2560200",
    "end": "2565900"
  },
  {
    "text": "beginning as we all know in software development the later you change something I have to change it the more costly it is",
    "start": "2565900",
    "end": "2573040"
  },
  {
    "text": "that's great um I've got one more which I'm going to ask um hopefully we'll still be able to",
    "start": "2573040",
    "end": "2579880"
  },
  {
    "text": "answer it in the in a little time we've got left otherwise we can jump into the session afterwards",
    "start": "2579880",
    "end": "2585880"
  },
  {
    "text": "um but so this is great um but are there cases actually where Kafka is not the right answer nothing is",
    "start": "2585880",
    "end": "2593440"
  },
  {
    "text": "perfect and there's you know it's not the answer to everything so um what what",
    "start": "2593440",
    "end": "2599260"
  },
  {
    "text": "you know what cases is this not really applicable yeah there's plenty of cases so absolutely right so I mean of course",
    "start": "2599260",
    "end": "2605680"
  },
  {
    "text": "I talk about the success stories in such a talk and not about when not to use it but it's a great point because many people use it wrongly or try to use it",
    "start": "2605680",
    "end": "2612160"
  },
  {
    "text": "wrongly a short list of things um don't use it as a proxy to thousands or hundreds of thousands of clients that's",
    "start": "2612160",
    "end": "2618400"
  },
  {
    "text": "where rest proxy is good or mqtt is good or similar things are good Kafka is not for embedded systems safety critical",
    "start": "2618400",
    "end": "2624819"
  },
  {
    "text": "applications or C C plus plus or rust so deterministic real Time That's not Kafka",
    "start": "2624819",
    "end": "2629980"
  },
  {
    "text": "that's even faster than Kafka and also because not for example an API management layer that does typically if",
    "start": "2629980",
    "end": "2636520"
  },
  {
    "text": "I use something like newly soft or apigee or Kong these days the streaming engines get in the direction but today",
    "start": "2636520",
    "end": "2642040"
  },
  {
    "text": "if you want to use API management for monetization and so on that's not Kafka so there's a list of things it does not",
    "start": "2642040",
    "end": "2647440"
  },
  {
    "text": "do very well and it's not built for that right and therefore I may get a little bit of advertisement by but I have",
    "start": "2647440",
    "end": "2653020"
  },
  {
    "text": "another blog post which is really called when not to use Apache Kafka and it goes through this list in much more detail",
    "start": "2653020",
    "end": "2658480"
  },
  {
    "text": "because it's super important of the beginning of your project to also understand when not to use it and how to combine it with others it's not",
    "start": "2658480",
    "end": "2664480"
  },
  {
    "text": "competing with mqt it's not Computing with a competing with a rest proxy right understand when to use the right tools",
    "start": "2664480",
    "end": "2670540"
  },
  {
    "text": "here and how to combine them mm-hmm all right that's great",
    "start": "2670540",
    "end": "2676000"
  },
  {
    "text": "um I don't see any more questions in the the chat at the moment so I think what",
    "start": "2676000",
    "end": "2681160"
  },
  {
    "text": "might be a good thing to do is to pop on over to the um it's the other session uh",
    "start": "2681160",
    "end": "2687040"
  },
  {
    "text": "where everybody can ask to the hangout with a speaker session um where everybody can kind of ask uh",
    "start": "2687040",
    "end": "2692200"
  },
  {
    "text": "questions themselves and stuff and that is basically if for for anyone if you go back to the the schedule plays at",
    "start": "2692200",
    "end": "2699099"
  },
  {
    "text": "schedule page you'll see there's a break or hang out with the speaker link um and so if you just jump in there",
    "start": "2699099",
    "end": "2705940"
  },
  {
    "text": "you'll be able to speak with um with Kai and ask him all manner of other questions which I'm sure he'll be very",
    "start": "2705940",
    "end": "2712000"
  },
  {
    "text": "happy to answer but uh thank you so much for that really interesting and I hope that you all enjoyed that and hopefully",
    "start": "2712000",
    "end": "2718780"
  },
  {
    "text": "look forward to seeing you in the hangout okay see you there",
    "start": "2718780",
    "end": "2724200"
  },
  {
    "text": "[Music]",
    "start": "2726410",
    "end": "2731859"
  }
]
[
  {
    "start": "0",
    "end": "27000"
  },
  {
    "text": "foreign [Music]",
    "start": "0",
    "end": "14249"
  },
  {
    "text": "my name is Glenn and I work at a little company called gecko board but today I'm",
    "start": "15500",
    "end": "21359"
  },
  {
    "text": "going to be talking about some work that me and my team did at Circle CI",
    "start": "21359",
    "end": "26400"
  },
  {
    "text": "um so let me set the scene first um so Circle CI is mostly made up of microservices and they're written in",
    "start": "26400",
    "end": "32279"
  },
  {
    "start": "27000",
    "end": "113000"
  },
  {
    "text": "closure and they all share some common tooling using a shared Library",
    "start": "32279",
    "end": "37680"
  },
  {
    "text": "uh that library is maintained by a separate team that you know tries to help act as an accelerator for all the",
    "start": "37680",
    "end": "44160"
  },
  {
    "text": "other teams and keeps that Library up to date uh meanwhile each CI build that runs on",
    "start": "44160",
    "end": "50399"
  },
  {
    "text": "our platform defines its own CI environments um we run the infrastructure but they get to decide what dependencies and so",
    "start": "50399",
    "end": "56520"
  },
  {
    "text": "on are installed on the system and in order to like power those builds we",
    "start": "56520",
    "end": "62879"
  },
  {
    "text": "needed to implement a build agent a bit of code that can run anywhere on those",
    "start": "62879",
    "end": "68100"
  },
  {
    "text": "customer defined machines and we implemented that in go now my team was responsible for uh this",
    "start": "68100",
    "end": "75600"
  },
  {
    "text": "agent written in go that build infrastructure um that it runs on and some of the",
    "start": "75600",
    "end": "81119"
  },
  {
    "text": "microservices that it communicates with and we decided we needed to build a new service for an upcoming build agent",
    "start": "81119",
    "end": "88500"
  },
  {
    "text": "related feature and we decided that rather than closure we were going to make a bit of a departure and we were",
    "start": "88500",
    "end": "95700"
  },
  {
    "text": "going to also build that in go and there were various trade-offs involved in this decision but overall we",
    "start": "95700",
    "end": "101220"
  },
  {
    "text": "were confident that this was a good choice um and now I'm going to claim that this",
    "start": "101220",
    "end": "107400"
  },
  {
    "text": "resulted in a fairly unusual situation um or certainly unusual to me",
    "start": "107400",
    "end": "112979"
  },
  {
    "text": "so we had a quite a large team of mostly experienced senior Engineers",
    "start": "112979",
    "end": "119159"
  },
  {
    "start": "113000",
    "end": "158000"
  },
  {
    "text": "um and we had experience working together building software in go to build this build agent and we also had",
    "start": "119159",
    "end": "125040"
  },
  {
    "text": "experience of building web services together in closure",
    "start": "125040",
    "end": "130340"
  },
  {
    "text": "um but because of the choice to build this new servicing go uh we had we we decided we'd left ourselves unable to",
    "start": "130560",
    "end": "137040"
  },
  {
    "text": "use that shared Library um and so all of the sort of the tooling",
    "start": "137040",
    "end": "142140"
  },
  {
    "text": "and the patterns we had were for writing a CLI tool um we didn't have any of their scaffolding uh that standard Library",
    "start": "142140",
    "end": "149280"
  },
  {
    "text": "stuff for building a web service um and I think this was a relatively unusual situation uh and in particular",
    "start": "149280",
    "end": "156420"
  },
  {
    "text": "this situation is a real recipe for bike shedding uh for bickering and uh",
    "start": "156420",
    "end": "161700"
  },
  {
    "start": "158000",
    "end": "180000"
  },
  {
    "text": "debating over people's personal preferences for things that aren't really that important",
    "start": "161700",
    "end": "166860"
  },
  {
    "text": "um but as well as the bike shedding um I think it's also a great opportunity for some experimentation uh some chances to",
    "start": "166860",
    "end": "174000"
  },
  {
    "text": "you know try some things that um you know we haven't really tried before try and mix things up a bit",
    "start": "174000",
    "end": "180420"
  },
  {
    "start": "180000",
    "end": "300000"
  },
  {
    "text": "um a little bit more relevant background knowledge um and I think this is sort of quite",
    "start": "180420",
    "end": "185580"
  },
  {
    "text": "relevant the story is how what the what Circle Ci's observability was like at",
    "start": "185580",
    "end": "190680"
  },
  {
    "text": "the time so this was uh this story takes place sometime around summer 2019",
    "start": "190680",
    "end": "196319"
  },
  {
    "text": "um and possibly right back then this is before the terms of ability have really started to get really heavy use",
    "start": "196319",
    "end": "203340"
  },
  {
    "text": "um but Circle CI had a two-pronged approach uh and both prongs were really really expensive",
    "start": "203340",
    "end": "208860"
  },
  {
    "text": "um so statsd was the primary tool we used we used metrics uh we had lots of metrics and we had lots of tags and if",
    "start": "208860",
    "end": "216599"
  },
  {
    "text": "you're familiar with stats D the the pricing model for stats D and actually the the underlying cost of the system",
    "start": "216599",
    "end": "223500"
  },
  {
    "text": "itself is based around the unique combinations of tags that you use so the",
    "start": "223500",
    "end": "229379"
  },
  {
    "text": "more tags you use the more it's going to cost you we also had a rather expensive",
    "start": "229379",
    "end": "234720"
  },
  {
    "text": "self-hosted elasticsearch system and that's where all our structured logs went um and that's generally the thing we're",
    "start": "234720",
    "end": "241319"
  },
  {
    "text": "comfortable doing adding logs to our system with the occasionally some fields that we can query",
    "start": "241319",
    "end": "247260"
  },
  {
    "text": "and around this time we also uh we'd start working with a new kid on the Block and that was honeycomb we'd had a",
    "start": "247260",
    "end": "253560"
  },
  {
    "text": "period of database problems in the the spring of 2019 and to help us uncover what was really",
    "start": "253560",
    "end": "260160"
  },
  {
    "text": "going on there and get a bit more visibility into our system we'd start exploring honeycomb and it really opened",
    "start": "260160",
    "end": "265680"
  },
  {
    "text": "our eyes to how our systems were behaving in production we'd started to spot things that we hadn't really appreciated before so I was hooked and I",
    "start": "265680",
    "end": "273180"
  },
  {
    "text": "started looking at honeycomb before even checking metrics or logs even when we had only instrumented quite a small",
    "start": "273180",
    "end": "278580"
  },
  {
    "text": "proportion of our overall stack at this point we were also starting to see tweets like",
    "start": "278580",
    "end": "283979"
  },
  {
    "text": "this floating around so this is uh charity the uh one of the founders of honeycomb and she's railing",
    "start": "283979",
    "end": "290340"
  },
  {
    "text": "against this concept of three pillars of observability metrics logs and traces she's claiming they aren't really a",
    "start": "290340",
    "end": "296940"
  },
  {
    "text": "thing um and I was starting to buy into this so I proposed an experiments given this",
    "start": "296940",
    "end": "303180"
  },
  {
    "start": "300000",
    "end": "463000"
  },
  {
    "text": "situation we've got a little bit of a blank slate but we know what we're doing we are we understand each other we know",
    "start": "303180",
    "end": "309720"
  },
  {
    "text": "how to work in the programming language we're not completely inventing everything from scratch",
    "start": "309720",
    "end": "315419"
  },
  {
    "text": "um yeah I made the propose this experiment and if you've read the title or the abstract of this talk I'm sure you know where I'm going next I said",
    "start": "315419",
    "end": "322139"
  },
  {
    "text": "what if we didn't have any logs",
    "start": "322139",
    "end": "326240"
  },
  {
    "text": "and you know what does it mean to not have logs well we kind of need a definition of logs uh in order to not",
    "start": "327300",
    "end": "334380"
  },
  {
    "text": "have them I think so this is the definition I'm going with so logs are text first Telemetry so Telemetry",
    "start": "334380",
    "end": "341759"
  },
  {
    "text": "meaning the information our system admits emits in order to understand what's going on and text first meaning",
    "start": "341759",
    "end": "349020"
  },
  {
    "text": "when you're writing a log line into your code you're thinking about it in terms of the text it produces",
    "start": "349020",
    "end": "356280"
  },
  {
    "text": "logs are intended to be human readable you're usually writing a log as a message to your future self or some",
    "start": "356280",
    "end": "362699"
  },
  {
    "text": "other operator um a little Message in a Bottle as it were if you're lucky the logs will have some",
    "start": "362699",
    "end": "370080"
  },
  {
    "text": "structured data attached some key value pairs to provide a bit more context about what's going on that are queryable",
    "start": "370080",
    "end": "376680"
  },
  {
    "text": "if you're less lucky then that extra contextual information will be",
    "start": "376680",
    "end": "383460"
  },
  {
    "text": "part of the human readable bit of the log which will make it much harder to query against",
    "start": "383460",
    "end": "389300"
  },
  {
    "text": "uh and logs are generally scattered across a code base there isn't like a a common pattern for exactly where a log",
    "start": "389340",
    "end": "395340"
  },
  {
    "text": "should or shouldn't go you probably are trying to debug an issue and you realize there's something",
    "start": "395340",
    "end": "401039"
  },
  {
    "text": "you'd like to see that you can't see so you go back into the code you add that log line and then you ship it and then",
    "start": "401039",
    "end": "407340"
  },
  {
    "text": "now you've got a new log line and you've got that additional visibility logs are pretty much always visualized",
    "start": "407340",
    "end": "415139"
  },
  {
    "text": "and explored as a stream sometimes as just text with grep um sometimes in like visual log",
    "start": "415139",
    "end": "420720"
  },
  {
    "text": "aggregation tools but even then they're still usually thought of as a stream of text going past that you have some way",
    "start": "420720",
    "end": "427800"
  },
  {
    "text": "of picking the relevant the the I the lines that are most interesting to you within them",
    "start": "427800",
    "end": "433380"
  },
  {
    "text": "and logs also have this concept of a log level um so debug info warn error some logs",
    "start": "433380",
    "end": "440160"
  },
  {
    "text": "are more important than others um and when we configure a system in production we often disable debug",
    "start": "440160",
    "end": "445560"
  },
  {
    "text": "logging and I'm sure many of you have been in a situation where you've had a production issue you'd love to see",
    "start": "445560",
    "end": "451020"
  },
  {
    "text": "what's going on and you've looked in the code and there is a log line that would tell you exactly what you need to know but it's disabled in production because",
    "start": "451020",
    "end": "457319"
  },
  {
    "text": "it's just way too noisy so that's logs",
    "start": "457319",
    "end": "463020"
  },
  {
    "start": "463000",
    "end": "606000"
  },
  {
    "text": "um and if we don't have logs what do we have instead Well we'd have what I'd like to call an event first approach",
    "start": "463020",
    "end": "469560"
  },
  {
    "text": "um not the catchiest name but I think it's a reasonable term and again we need a definition what is",
    "start": "469560",
    "end": "474660"
  },
  {
    "text": "an event first approach so I'd say an event first approach is as opposed to",
    "start": "474660",
    "end": "480000"
  },
  {
    "text": "text first Telemetry it's data first Telemetry we're primarily thinking about",
    "start": "480000",
    "end": "485039"
  },
  {
    "text": "describing what's going on in our system as data we do that via events and each event has",
    "start": "485039",
    "end": "493380"
  },
  {
    "text": "a unique name that identifies it within our code base and describes the action that's going on",
    "start": "493380",
    "end": "499919"
  },
  {
    "text": "all of the properties of that event are structured data so this is partially by virtue of it being new uh like generally",
    "start": "499919",
    "end": "507539"
  },
  {
    "text": "now if I'm writing a new log line it will also also be it will also all be structured data but when I'm creating an",
    "start": "507539",
    "end": "513959"
  },
  {
    "text": "event now the event is just the event name is just an identifier and all of",
    "start": "513959",
    "end": "519240"
  },
  {
    "text": "the data about that event goes into properties as structured data",
    "start": "519240",
    "end": "524899"
  },
  {
    "text": "we're also going to wrap these events around units of work and get and mark the duration of that unit of work and",
    "start": "525480",
    "end": "531720"
  },
  {
    "text": "when I say a unit of work I mean something important that our system is doing so rather than like having a log",
    "start": "531720",
    "end": "538680"
  },
  {
    "text": "line for like yes a thing started yeah it's still going still going okay it's finished now with an event I'm going to",
    "start": "538680",
    "end": "546180"
  },
  {
    "text": "wrap that unit of work and I'm just going to Omit an event when a piece of work is completed and then it will have",
    "start": "546180",
    "end": "552240"
  },
  {
    "text": "all the properties I require and it'll know the duration of that chunk of work",
    "start": "552240",
    "end": "557580"
  },
  {
    "text": "foreign events we're going to explore and visualize in multiple ways so that",
    "start": "557580",
    "end": "562920"
  },
  {
    "text": "includes the stream that we get for logs but it will also allow us to do time series queries and other types of ways",
    "start": "562920",
    "end": "569100"
  },
  {
    "text": "of slicing and dicing that same bit of raw information",
    "start": "569100",
    "end": "574440"
  },
  {
    "text": "and we're not going to have log levels or any equivalents so where in the log space system we say",
    "start": "574440",
    "end": "580500"
  },
  {
    "text": "certain events are more important than others in the event system we're going to say all events are important",
    "start": "580500",
    "end": "586320"
  },
  {
    "text": "um in terms of the code level and if we're struggling with volume and we need",
    "start": "586320",
    "end": "591360"
  },
  {
    "text": "to like throw some away we're going to use Dynamic sampling techniques which I'm not really going to go into today but if you want to Google it that's the",
    "start": "591360",
    "end": "597779"
  },
  {
    "text": "term to Google um now I haven't put these both up on the same screen at once but you might",
    "start": "597779",
    "end": "603000"
  },
  {
    "text": "have noticed these are quite similar lists of bullet points and I would say that events and logs aren't actually",
    "start": "603000",
    "end": "608459"
  },
  {
    "start": "606000",
    "end": "804000"
  },
  {
    "text": "that different events are just good logs um but something I've been saying to myself at least for a number of years is",
    "start": "608459",
    "end": "614760"
  },
  {
    "text": "I'm going to stop using the word just uh there's a lot of hidden meaning behind the word just implies thing implies a",
    "start": "614760",
    "end": "621779"
  },
  {
    "text": "certain level of triviality which I think is rarely the case and even if our events are just good",
    "start": "621779",
    "end": "628019"
  },
  {
    "text": "logs I think there's an important philosophical difference there uh and in particular I think new words",
    "start": "628019",
    "end": "634860"
  },
  {
    "text": "can encourage new ways of thinking um many of us take our logs for granted we don't put a lot of thought into what",
    "start": "634860",
    "end": "641399"
  },
  {
    "text": "we're putting writing in our log lines or you know we've been using logs for years so we know how to do logs but",
    "start": "641399",
    "end": "646860"
  },
  {
    "text": "suddenly I say hey we're doing events now and you go oh that's different how do I do that and so I think you know it's using new",
    "start": "646860",
    "end": "654240"
  },
  {
    "text": "words new terminologies new apis is an important tool in our toolbox because",
    "start": "654240",
    "end": "659519"
  },
  {
    "text": "ultimately we're building these systems for people and so finding ways to change the way people think is an effective way",
    "start": "659519",
    "end": "665940"
  },
  {
    "text": "to bring about change anyway so that's enough philosophical uh nonsense let's see what this looked like in practice",
    "start": "665940",
    "end": "672779"
  },
  {
    "text": "so I'm going to show a bit of code now hopefully you're familiar enough to follow some go but even if not I hope you can still appreciate how minimal",
    "start": "672779",
    "end": "679620"
  },
  {
    "text": "these interfaces really are so we've defined our package with the trendy 011y",
    "start": "679620",
    "end": "685140"
  },
  {
    "text": "name um and we've got a start spam function so this is going to create a span",
    "start": "685140",
    "end": "691260"
  },
  {
    "text": "um with a span representing a unit of work and it's going to store it in the context context if you're not familiar",
    "start": "691260",
    "end": "697380"
  },
  {
    "text": "is a goes equivalent of Say thread local storage uh but it's explicit rather than",
    "start": "697380",
    "end": "703200"
  },
  {
    "text": "implicit anyway so we're going to create our span we're going to give it a name and then once we've got a span there's",
    "start": "703200",
    "end": "709800"
  },
  {
    "text": "only two core operations we really need on a span the first one is to add a field",
    "start": "709800",
    "end": "714839"
  },
  {
    "text": "this has a key and a value where the the key is like the the name",
    "start": "714839",
    "end": "721140"
  },
  {
    "text": "of the uh the data and the value is anything we like um and then after a spanners run for",
    "start": "721140",
    "end": "727019"
  },
  {
    "text": "some time you'll call this end function on the span um and that will record a duration from",
    "start": "727019",
    "end": "732660"
  },
  {
    "text": "the start to the end and send it off to the back end fairly straightforward I hope",
    "start": "732660",
    "end": "739440"
  },
  {
    "text": "and then when we write our application code we're going to sprinkle a little bit of the span codes in throughout it",
    "start": "739440",
    "end": "744839"
  },
  {
    "text": "to produce the telemetry so in this case here we've got we are going to start our span and we're going",
    "start": "744839",
    "end": "750180"
  },
  {
    "text": "to name it delete entity to match up with the the name of the unit of work that we're performing",
    "start": "750180",
    "end": "756300"
  },
  {
    "text": "we're going to use goes defer construct so that when this function ends it's uh",
    "start": "756300",
    "end": "763260"
  },
  {
    "text": "it captures the error and the span ends when the function ends and then throughout the body of this function",
    "start": "763260",
    "end": "768660"
  },
  {
    "text": "we're going to use a series of these add field calls to add important context about what's going on generally sort of",
    "start": "768660",
    "end": "775380"
  },
  {
    "text": "domain specific information about what's happening within this function what what work we're performing right now",
    "start": "775380",
    "end": "782040"
  },
  {
    "text": "and then when we do this throughout our code we can send it off to Honeycomb and we get to see these nice little Trace",
    "start": "782040",
    "end": "787440"
  },
  {
    "text": "waterfalls like this if any of you've used some sort of tracing tool I don't think this will be a revolutionary",
    "start": "787440",
    "end": "793019"
  },
  {
    "text": "concept to you you'll have seen a lot of stuff like this and as we browse around the honeycomb UI and we click on these rows all of that extra field data that",
    "start": "793019",
    "end": "800100"
  },
  {
    "text": "we attach to our spans will be viewable in the little sidebar so",
    "start": "800100",
    "end": "805860"
  },
  {
    "start": "804000",
    "end": "962000"
  },
  {
    "text": "we started from first principles we have this really super minimal interface and then as we worked on it over time and",
    "start": "805860",
    "end": "811680"
  },
  {
    "text": "built up this new system we started to develop and extract some patterns and one of the first patterns that",
    "start": "811680",
    "end": "817079"
  },
  {
    "text": "emerged was having a consistent way to capture errors when a span ends so there's a little bit of sleight of hand",
    "start": "817079",
    "end": "822420"
  },
  {
    "text": "here with like named error named return values and pointers and so on but the",
    "start": "822420",
    "end": "827519"
  },
  {
    "text": "general idea here is that whenever this function ends uh with an early return or whatever",
    "start": "827519",
    "end": "833399"
  },
  {
    "text": "situation uh we're gonna you the defer block will run and we're going to call",
    "start": "833399",
    "end": "838740"
  },
  {
    "text": "this standard helper this end function to end our spam",
    "start": "838740",
    "end": "843980"
  },
  {
    "text": "and this makes sure that every time this function ends it goes to our helper now",
    "start": "844320",
    "end": "850200"
  },
  {
    "text": "there's another way to do the same concept which will be to use a sort of a slightly more aspect oriented style",
    "start": "850200",
    "end": "855959"
  },
  {
    "text": "where we wrap our code with an observability layer that",
    "start": "855959",
    "end": "861019"
  },
  {
    "text": "respects the same interface as the actual code and we found of the two approaches we",
    "start": "861019",
    "end": "866940"
  },
  {
    "text": "much preferred this inline approach where we actually clutter our code with the observability code",
    "start": "866940",
    "end": "872820"
  },
  {
    "text": "and the reason for that is generally when you're coming to make a change to the code because it's right there in",
    "start": "872820",
    "end": "878100"
  },
  {
    "text": "your face and in your way then you're much more likely to remember to update the observability code to match whereas",
    "start": "878100",
    "end": "884760"
  },
  {
    "text": "if it's off in a separate layer it's very easy for the two to fall out of sync",
    "start": "884760",
    "end": "890240"
  },
  {
    "text": "now inside the body of this helper function we've just got some really basic logic to ensure that we've got",
    "start": "890279",
    "end": "896220"
  },
  {
    "text": "consistent storage of fields so every time there's an error we're going to set the result field of the span to have a",
    "start": "896220",
    "end": "902880"
  },
  {
    "text": "value error so we can very easily find spans containing errors and we'll also populate the error field with some",
    "start": "902880",
    "end": "909600"
  },
  {
    "text": "details about what went wrong in the real version of this there's you know a few more cases that handled for like timeouts and so on but this is a",
    "start": "909600",
    "end": "917399"
  },
  {
    "text": "this is the core concept and when we send this off to Honeycomb it's able to highlight all of those arid",
    "start": "917399",
    "end": "923279"
  },
  {
    "text": "spans and pull them out uh so we can see them clearly and if you've got a much",
    "start": "923279",
    "end": "928380"
  },
  {
    "text": "longer span a much longer Trace then and only one or two of those varied this is way more visually uh helpful",
    "start": "928380",
    "end": "937040"
  },
  {
    "text": "but it also means we can do a Time series query on those same fields so here I've taken a single one of those",
    "start": "937139",
    "end": "944220"
  },
  {
    "text": "names and I've said all the spans with a certain name show me whether or not they errored and you can see there's some",
    "start": "944220",
    "end": "950519"
  },
  {
    "text": "spikes here where you know clearly something went wrong and those errors uh there's our rates spiked up and maybe",
    "start": "950519",
    "end": "957600"
  },
  {
    "text": "that's something worth looking into another pattern that emerged is what I",
    "start": "957600",
    "end": "963120"
  },
  {
    "start": "962000",
    "end": "1070000"
  },
  {
    "text": "like to call medium cardinality spam names so cardinality is the number of unique values of a particular field so",
    "start": "963120",
    "end": "969720"
  },
  {
    "text": "for example earlier that result field has only got two or three possible values that's low cardinality whereas",
    "start": "969720",
    "end": "976380"
  },
  {
    "text": "something like a customer ID is high cardinality hopefully you got a lot of customers and there's lots of possible",
    "start": "976380",
    "end": "982199"
  },
  {
    "text": "values of a field like customer ID so low cardinality values are really great for grouping events together you",
    "start": "982199",
    "end": "988079"
  },
  {
    "text": "can say okay show me how many events failed versus past really useful whereas if you say show me",
    "start": "988079",
    "end": "994380"
  },
  {
    "text": "Group by customer ID you just get loads of separate rows not quite as useful for grouping but when you're looking at a",
    "start": "994380",
    "end": "1000079"
  },
  {
    "text": "single event knowing exactly which customer affected is really effective so Medium cardinality as I'm sure you can",
    "start": "1000079",
    "end": "1006560"
  },
  {
    "text": "guess is somewhere in between and I've often found that auto instrumentation will default to quite low cardinality",
    "start": "1006560",
    "end": "1013279"
  },
  {
    "text": "spam names so for instance something like it might just say HTTP requests or select query",
    "start": "1013279",
    "end": "1020120"
  },
  {
    "text": "or insert query um and when you're looking at a trace waterfall and it says something like HTTP requests HTTP requests select query",
    "start": "1020120",
    "end": "1029240"
  },
  {
    "text": "insert query it's not entirely clear what's going on whereas what I found was by using medium",
    "start": "1029240",
    "end": "1035660"
  },
  {
    "text": "cardinality names so in this case the pattern we did was generally package method and occasionally we'd also prefix",
    "start": "1035660",
    "end": "1042438"
  },
  {
    "text": "with the type so the examples I've got here are like a grpc call",
    "start": "1042439",
    "end": "1047540"
  },
  {
    "text": "or a database query just that extra little bit of context means that when you're looking at a",
    "start": "1047540",
    "end": "1053480"
  },
  {
    "text": "trace waterfall or when you're grouping by a span name you can immediately see what action is going on rather than",
    "start": "1053480",
    "end": "1059000"
  },
  {
    "text": "having to drill down into the individual spans and look at their fields so as much generally just gives you a",
    "start": "1059000",
    "end": "1065720"
  },
  {
    "text": "much quicker at a glance view of a Trace um another thing we start to notice",
    "start": "1065720",
    "end": "1071860"
  },
  {
    "start": "1070000",
    "end": "1151000"
  },
  {
    "text": "fairly early on was cost so as I mentioned earlier we already had two very expensive Telemetry backends we",
    "start": "1071860",
    "end": "1078380"
  },
  {
    "text": "didn't really want the third expensive Telemetry back end and I'm sure you can imagine Circle CI is quite a high volume",
    "start": "1078380",
    "end": "1084080"
  },
  {
    "text": "system millions of builds a day lots of RPC calls as part of those builds",
    "start": "1084080",
    "end": "1089539"
  },
  {
    "text": "um anything that multiplies per call gets very expensive very quickly",
    "start": "1089539",
    "end": "1094640"
  },
  {
    "text": "and if you take a naive approach a naive application of the approach I described",
    "start": "1094640",
    "end": "1099740"
  },
  {
    "text": "above where each layer gets wrapped with um some spans to denote the unit of work",
    "start": "1099740",
    "end": "1106100"
  },
  {
    "text": "you can very easily end up with a trace like this one so I've got four different spans each",
    "start": "1106100",
    "end": "1111860"
  },
  {
    "text": "representing a different layer of our code but ultimately there's no other code happening in that request Handler",
    "start": "1111860",
    "end": "1118460"
  },
  {
    "text": "so all of these spans are mostly recording redundant information and so when we start to see traces like this",
    "start": "1118460",
    "end": "1124400"
  },
  {
    "text": "we've got a little bit more selective about which layers really benefited from being considered units of work versus",
    "start": "1124400",
    "end": "1130220"
  },
  {
    "text": "just being delegated down to the other layer like in this case the the top layer there is the HTTP Handler and the",
    "start": "1130220",
    "end": "1137539"
  },
  {
    "text": "second layer down is like the domain layer which is the the core of our application logic that's",
    "start": "1137539",
    "end": "1143660"
  },
  {
    "text": "separate from HTTP and so we made some tweaks to how many of these spans were produced and that did save us actually quite a",
    "start": "1143660",
    "end": "1150799"
  },
  {
    "text": "bit um but you know when we're throwing away spans like that or reducing spans we are",
    "start": "1150799",
    "end": "1158120"
  },
  {
    "start": "1151000",
    "end": "1220000"
  },
  {
    "text": "losing a bit of information and we then developed a few patterns to try and get that information back so generally",
    "start": "1158120",
    "end": "1164299"
  },
  {
    "text": "adding lots of domain-specific fields onto spans in honeycomb it doesn't cost",
    "start": "1164299",
    "end": "1169520"
  },
  {
    "text": "anything additional to add more fields to the to make a span wider so it generally tends to encourage you",
    "start": "1169520",
    "end": "1176059"
  },
  {
    "text": "to do that so for example in the previous Trace there there was like an HTTP client that",
    "start": "1176059",
    "end": "1181640"
  },
  {
    "text": "did retries um and that was creating quite a deep Trace whereas you can instead of having",
    "start": "1181640",
    "end": "1188419"
  },
  {
    "text": "a span for each retry attempt you can just have a counter on the final",
    "start": "1188419",
    "end": "1193460"
  },
  {
    "text": "one to say how many attempts were made and that way you know you're losing a bit of information but you're still",
    "start": "1193460",
    "end": "1199100"
  },
  {
    "text": "overall capturing what's going on we've also found that well in a microservice system you've got loads of",
    "start": "1199100",
    "end": "1204679"
  },
  {
    "text": "different storage backends lots of different identifiers it's very helpful to add as many of those onto your spans",
    "start": "1204679",
    "end": "1210380"
  },
  {
    "text": "you can get away with and then when you do have an issue you can see exactly which customers it's affecting or even in many cases which",
    "start": "1210380",
    "end": "1217340"
  },
  {
    "text": "customer is causing that issue now anyone who spent some time instrumenting their code with modern",
    "start": "1217340",
    "end": "1223640"
  },
  {
    "start": "1220000",
    "end": "1253000"
  },
  {
    "text": "tracing tools is probably mostly shrugging at this point and you'll have come across many of these patterns in",
    "start": "1223640",
    "end": "1229520"
  },
  {
    "text": "your own work you know at this point I'm just instrumenting with traces and there's that word just again",
    "start": "1229520",
    "end": "1234860"
  },
  {
    "text": "and so far yes I haven't really done anything new apart from not introducing logs",
    "start": "1234860",
    "end": "1240919"
  },
  {
    "text": "I'm instrumenting with just traces but actually when I said no logs in the",
    "start": "1240919",
    "end": "1247640"
  },
  {
    "text": "title I was lying a little bit or bending the truth perhaps um when I first proposed this experiment",
    "start": "1247640",
    "end": "1254440"
  },
  {
    "start": "1253000",
    "end": "1436000"
  },
  {
    "text": "some of my colleagues were a little bit wary and they had quite reasonable questions like what will we do if",
    "start": "1254440",
    "end": "1260539"
  },
  {
    "text": "honeycomb is down how will we see what's going on you know we had a uh we had this logging",
    "start": "1260539",
    "end": "1266299"
  },
  {
    "text": "system that we you know there were things we didn't like about it but we understood its operational constraints we knew how to",
    "start": "1266299",
    "end": "1272179"
  },
  {
    "text": "operate it and switching entirely to a brand new approach you know can be a little bit scary",
    "start": "1272179",
    "end": "1278240"
  },
  {
    "text": "so what we ended up implementing was a little T inside the ollie Library so as well as sending events to Honeycomb we",
    "start": "1278240",
    "end": "1285559"
  },
  {
    "text": "also converted them to Jason and wrote them to stand it out and that way we were able to like after sending",
    "start": "1285559",
    "end": "1292880"
  },
  {
    "text": "standard out they then pumped off to our standard log aggregation system and this way we've kind of got a fallback if honeycomb's not working we",
    "start": "1292880",
    "end": "1299419"
  },
  {
    "text": "can just see our logs normally and you can imagine we'd also we could also send these off to S3 or some other long-term",
    "start": "1299419",
    "end": "1304820"
  },
  {
    "text": "storage system if we wanted to um so yeah we've got we've got some Jason logs out of our tracers and these aren't",
    "start": "1304820",
    "end": "1312799"
  },
  {
    "text": "super usable they're not particularly like readable you're like it's just a big wall of text",
    "start": "1312799",
    "end": "1318260"
  },
  {
    "text": "but actually we found ourselves using them and in particular we found ourselves using them in local developments because we all have this",
    "start": "1318260",
    "end": "1324679"
  },
  {
    "text": "habit this pattern of when you're working locally you expect to see output from your process right there in your",
    "start": "1324679",
    "end": "1330620"
  },
  {
    "text": "face when you do things you want to be able to see that immediate feedback loop and so because we started using these",
    "start": "1330620",
    "end": "1336440"
  },
  {
    "text": "Json logs even though they were difficult to read we made them easier to read so with a little bit of passing and",
    "start": "1336440",
    "end": "1342440"
  },
  {
    "text": "a little bit of color we can immediately add a lot more information architecture we can pull out",
    "start": "1342440",
    "end": "1347659"
  },
  {
    "text": "the span name as uh in color here if there are any errors in Span we can tag",
    "start": "1347659",
    "end": "1353000"
  },
  {
    "text": "those and make them really pop out and we can abbreviate things like we don't need the 36 character Trace ID in an odd",
    "start": "1353000",
    "end": "1360620"
  },
  {
    "text": "like standard out Dev output we can you know just take a few characters enough to make it visually distinct and see",
    "start": "1360620",
    "end": "1367039"
  },
  {
    "text": "what's going on and actually we found this was really most effective in tests the goes test",
    "start": "1367039",
    "end": "1374900"
  },
  {
    "text": "Runner can capture standard out and it will display it next to a failing test so you get a test failure you can see",
    "start": "1374900",
    "end": "1380299"
  },
  {
    "text": "all of the traces all of the spans that were so that happened during that test in color in text right there next to the",
    "start": "1380299",
    "end": "1387679"
  },
  {
    "text": "test failure and that this was almost accidental really but this turned out to be one of",
    "start": "1387679",
    "end": "1393500"
  },
  {
    "text": "the most effective changes because now if you've got a failing test and you can't tell why it's failed",
    "start": "1393500",
    "end": "1399320"
  },
  {
    "text": "then that means your code is not observable enough and the solution to fixing that is not",
    "start": "1399320",
    "end": "1405260"
  },
  {
    "text": "to go fire up your debugger and figure out what's going on in this particular case because this sort of same sort of issue",
    "start": "1405260",
    "end": "1410900"
  },
  {
    "text": "might also happen in production the solution instead is to extend your tracing code to add new fields to add",
    "start": "1410900",
    "end": "1417260"
  },
  {
    "text": "new spans so you can see what's going on and then you know the reason for the failure of",
    "start": "1417260",
    "end": "1422960"
  },
  {
    "text": "your test is revealed but also you've enriched your observability you've enriched your Telemetry so when this",
    "start": "1422960",
    "end": "1428419"
  },
  {
    "text": "code makes it to production you can see what's going on so that turned out to be really quite",
    "start": "1428419",
    "end": "1433940"
  },
  {
    "text": "surprisingly effective so we've got some logs backs what about",
    "start": "1433940",
    "end": "1438980"
  },
  {
    "start": "1436000",
    "end": "1657000"
  },
  {
    "text": "metrics what about that third pillar now it's become a bit fashionable lately",
    "start": "1438980",
    "end": "1444260"
  },
  {
    "text": "to really hate on metrics dashboards um but I've used metrics dashboards for a lot of my career now and I'm you know",
    "start": "1444260",
    "end": "1450260"
  },
  {
    "text": "I know how to read them I'm familiar with them as I think I'm still a big fan and what I especially like is a",
    "start": "1450260",
    "end": "1455659"
  },
  {
    "text": "dashboard like this so for each and every service that we run I like to have its like headline",
    "start": "1455659",
    "end": "1462320"
  },
  {
    "text": "dashboard is that service looking all right how's it doing what's it up to and when we develop new features for",
    "start": "1462320",
    "end": "1469220"
  },
  {
    "text": "that service we also add them to the dashboard we co-evolve them over time it's not just a static artifact",
    "start": "1469220",
    "end": "1474860"
  },
  {
    "text": "and when I'm then deploying that service I've got something that I build into my",
    "start": "1474860",
    "end": "1480320"
  },
  {
    "text": "process as something to look at I'll always open up the dashboard I'll hit the deploy button or merge my pull request or whatever the process is and",
    "start": "1480320",
    "end": "1487400"
  },
  {
    "text": "check that things look okay I still think I'm slightly better at spotting patterns during a deployment than an",
    "start": "1487400",
    "end": "1494299"
  },
  {
    "text": "automated regression system especially because that system is",
    "start": "1494299",
    "end": "1499340"
  },
  {
    "text": "averaging everything over time whereas I know what change I've just made I know what might be likely to be affected",
    "start": "1499340",
    "end": "1505460"
  },
  {
    "text": "and currently today honeycomb doesn't really have a way to do something equivalent to this it doesn't have this",
    "start": "1505460",
    "end": "1511460"
  },
  {
    "text": "let me just have an overview and the circle CI we're very familiar with the system we had we didn't necessarily want",
    "start": "1511460",
    "end": "1517580"
  },
  {
    "text": "to throw that all the way just because we liked this newer wave uh instrumenting our code",
    "start": "1517580",
    "end": "1522679"
  },
  {
    "text": "so I asked myself could we derive our metrics from us bands uh we've said that",
    "start": "1522679",
    "end": "1528080"
  },
  {
    "text": "there aren't three pillars metrics are just another way of looking at events and I really liked how simple and",
    "start": "1528080",
    "end": "1534440"
  },
  {
    "text": "minimal the Telemetry code we'd already added was I didn't want to clutter it up with an extra layer of metrics code over",
    "start": "1534440",
    "end": "1540020"
  },
  {
    "text": "the top so I had a little player out and I found an approach that I quite liked",
    "start": "1540020",
    "end": "1545480"
  },
  {
    "text": "so we take our simple span interface and we add one additional method the record metric and that takes a description of a",
    "start": "1545480",
    "end": "1552919"
  },
  {
    "text": "metric to record and then we have a series of factories that can create those metrics descriptions",
    "start": "1552919",
    "end": "1559279"
  },
  {
    "text": "so here we've got like a timing function that creates a timing metric an increment function creates an chronometric and so on so on so on",
    "start": "1559279",
    "end": "1566900"
  },
  {
    "text": "and then we want to use that we take our existing span and we add this",
    "start": "1566900",
    "end": "1572419"
  },
  {
    "text": "we we tell it to record a metric and then under the hood the code will then",
    "start": "1572419",
    "end": "1577700"
  },
  {
    "text": "derive the metric from the spans data so when we say a timing metric we know the span that the library",
    "start": "1577700",
    "end": "1585200"
  },
  {
    "text": "knows to take the timing metric using the duration of the spam and then these extra fields on the end",
    "start": "1585200",
    "end": "1591500"
  },
  {
    "text": "here tell us which tags we want to attach to our metrics now we have to be selective about which",
    "start": "1591500",
    "end": "1597140"
  },
  {
    "text": "Fields get recorded as metrics tags and that's down to cost again it's really expensive to send a high cardinality",
    "start": "1597140",
    "end": "1603020"
  },
  {
    "text": "field to the metric back end so while we want those fields in our spans we have to pick a few of those as being safe for",
    "start": "1603020",
    "end": "1610340"
  },
  {
    "text": "sending off to our metric so in this case for an HTTP request or we can really afford to keep is the",
    "start": "1610340",
    "end": "1616880"
  },
  {
    "text": "status code and the result and I think maybe we'd take the path or something as well but",
    "start": "1616880",
    "end": "1622640"
  },
  {
    "text": "anyway we make the author explicitly choose which Fields they want to associate with their metrics but other",
    "start": "1622640",
    "end": "1627799"
  },
  {
    "text": "than that all of the values for these the the value of result the value of status and the the value duration all",
    "start": "1627799",
    "end": "1635000"
  },
  {
    "text": "come from the properties of the spam uh much like the logs are observability",
    "start": "1635000",
    "end": "1641179"
  },
  {
    "text": "abstraction is then able to tee these off to a statsd demon um and from there it goes along to the",
    "start": "1641179",
    "end": "1647059"
  },
  {
    "text": "metrics visualization tool of your choice and by ensuring that the metrics and events both have the same Source in",
    "start": "1647059",
    "end": "1653240"
  },
  {
    "text": "the code there shouldn't be any discrepancies in the values between them so Tada we've got all of those three",
    "start": "1653240",
    "end": "1659720"
  },
  {
    "text": "observability pillars and only by adding really one set of instrumentation into",
    "start": "1659720",
    "end": "1664880"
  },
  {
    "text": "our code or one and a bit perhaps you might argue and I'm sure you've seen if you've been researching observability over the last",
    "start": "1664880",
    "end": "1671779"
  },
  {
    "text": "couple of years you'll have seen many variations of this Slide the three pillars of observability and in fact",
    "start": "1671779",
    "end": "1677659"
  },
  {
    "text": "I've realized we've been looking at this pillars diagram all wrong if you look at it from above the pillows are Hollow and they're all just Windows",
    "start": "1677659",
    "end": "1684320"
  },
  {
    "text": "into the events happening under the hood and if you think about this in terms of the execution model of what our code is",
    "start": "1684320",
    "end": "1690679"
  },
  {
    "text": "even doing it kind of makes sense to me because ultimately our code is executing a series of instructions with some",
    "start": "1690679",
    "end": "1697220"
  },
  {
    "text": "arguments and the active instrumenting code is deciding which of those instructions and arguments we think are",
    "start": "1697220",
    "end": "1702860"
  },
  {
    "text": "worth recording those are events and anything else we derive from that point is all from that same source",
    "start": "1702860",
    "end": "1710900"
  },
  {
    "text": "so at the start of this I described this sort of situation as an experiment and",
    "start": "1710900",
    "end": "1717799"
  },
  {
    "text": "was it a success think so I don't it wasn't a definite success I",
    "start": "1717799",
    "end": "1724340"
  },
  {
    "text": "think it's uh it's definitely yeah there's some pluses and minuses so on the whole yes I think this was a",
    "start": "1724340",
    "end": "1730159"
  },
  {
    "text": "success and I definitely learned a lot about what was really important to me when adding Telemetry into my code",
    "start": "1730159",
    "end": "1738760"
  },
  {
    "text": "um one thing I think was a definite success was having only one source of telemetry in the code not having you",
    "start": "1738919",
    "end": "1745460"
  },
  {
    "text": "know a log line here and a span here and a metric here just being like okay this is the this is the Telemetry code and",
    "start": "1745460",
    "end": "1752659"
  },
  {
    "text": "separately I worry about how that gets off to the back end so yeah that bit I can say I'm definitely happy with",
    "start": "1752659",
    "end": "1759200"
  },
  {
    "text": "um the trace first mindset I also thought worked really well so sort of getting us training us all to think in a",
    "start": "1759200",
    "end": "1765080"
  },
  {
    "text": "sense of here is a unit of work that I'm instrumenting here's a unit of work that I'm wrapping with a span you know I",
    "start": "1765080",
    "end": "1772100"
  },
  {
    "text": "think that worked very well rather than having like you know a log line at the start of something in the log line halfway down and the log and then the",
    "start": "1772100",
    "end": "1778760"
  },
  {
    "text": "log at the end just it's wrapped it's a unit of work that part I think works great",
    "start": "1778760",
    "end": "1785919"
  },
  {
    "text": "um the bit I think didn't necessarily work as well or was arguably not was worth it was the whole like let's burn",
    "start": "1786200",
    "end": "1792080"
  },
  {
    "text": "everything to the ground and start again from scratch the rethinking everything from first principles bit of a mixed bag so in the process of",
    "start": "1792080",
    "end": "1799700"
  },
  {
    "text": "rediscovering everything you know we spent a bunch of time bike shedding arguing over details that it turned out",
    "start": "1799700",
    "end": "1804799"
  },
  {
    "text": "to not be important in the end Reinventing a bunch of Wheels um perhaps that process was still",
    "start": "1804799",
    "end": "1810799"
  },
  {
    "text": "valuable because in the process of having those discussions you know we built a much better understanding as a",
    "start": "1810799",
    "end": "1816679"
  },
  {
    "text": "team of what we what was important to us and we also discovered like what we needed to include and what",
    "start": "1816679",
    "end": "1822440"
  },
  {
    "text": "we didn't need to include in this Library we built up and the other thing that was a bit of a",
    "start": "1822440",
    "end": "1828140"
  },
  {
    "text": "mixed bag was not having any auto instrumentation available so because we've just invented this new",
    "start": "1828140",
    "end": "1834140"
  },
  {
    "text": "approach it's not like we can just grab something off the shelf that will automatically create all our spans for us when we make requests or database",
    "start": "1834140",
    "end": "1841399"
  },
  {
    "text": "calls um and the reason I call this one a mixed bag and not just a straightforward",
    "start": "1841399",
    "end": "1846620"
  },
  {
    "text": "negative is because I've had very mixed results with auto instrumentation itself",
    "start": "1846620",
    "end": "1851659"
  },
  {
    "text": "um I often find that the things that the person who wrote the library considers importance might not align with the",
    "start": "1851659",
    "end": "1857539"
  },
  {
    "text": "things that I consider important um and auto instrumentation can be very chatty I could be creating a lot of",
    "start": "1857539",
    "end": "1864020"
  },
  {
    "text": "spans for details that I don't actually care about the the cost benefit might be off there",
    "start": "1864020",
    "end": "1869059"
  },
  {
    "text": "so effectively by not having this available to us we were forced to instrument everything ourselves",
    "start": "1869059",
    "end": "1875960"
  },
  {
    "text": "um but you know in 2022 all the instrumentation code out there is open source if you want to instrument code in",
    "start": "1875960",
    "end": "1882380"
  },
  {
    "text": "a new way you can Fork it you can refer to the way it's done elsewhere so it wasn't a huge undertaking but it did",
    "start": "1882380",
    "end": "1888799"
  },
  {
    "text": "give us the opportunity to reevaluate did we want this field did we care about this bit you know how do we want things",
    "start": "1888799",
    "end": "1895100"
  },
  {
    "text": "to work so yeah if you ever mix back there anyway so what next what should you do",
    "start": "1895100",
    "end": "1901580"
  },
  {
    "text": "with this story uh well thank you for listening to me um and here's what I like my",
    "start": "1901580",
    "end": "1908179"
  },
  {
    "text": "recommendations for you know what to take away from this would be first off try a trace first approach in",
    "start": "1908179",
    "end": "1914899"
  },
  {
    "text": "your own code so regardless of the interfaces or how the codes or you know how you're actually",
    "start": "1914899",
    "end": "1921020"
  },
  {
    "text": "plugging things into your code when you're writing new code try and think about units of work and traces as the",
    "start": "1921020",
    "end": "1927559"
  },
  {
    "text": "primary way of getting Telemetry out of your code start from that first and then think about logs and metrics afterwards maybe",
    "start": "1927559",
    "end": "1934279"
  },
  {
    "text": "if you need them I think that was very effective for us and I think it just that way of thinking encourage I even",
    "start": "1934279",
    "end": "1940640"
  },
  {
    "text": "just helped to structure our code a little bit nicer but I tentatively recommend this concept",
    "start": "1940640",
    "end": "1949220"
  },
  {
    "start": "1945000",
    "end": "2068000"
  },
  {
    "text": "of a unified Telemetry abstraction having this one place to produce logs metrics and events and the reason I'm",
    "start": "1949220",
    "end": "1957380"
  },
  {
    "text": "tended to on this is because people still found it a little bit weird it wasn't like as intuitive and maybe",
    "start": "1957380",
    "end": "1963919"
  },
  {
    "text": "this isn't an area you really need to innovate in um but I think it was effective so I",
    "start": "1963919",
    "end": "1969260"
  },
  {
    "text": "would still say it's a good approach but maybe it's it's not worth you know it's",
    "start": "1969260",
    "end": "1974480"
  },
  {
    "text": "not enough better than the current approach maybe to consider ripping things up but worth a try",
    "start": "1974480",
    "end": "1981200"
  },
  {
    "text": "um and if anyone else is like some of you right there might be hearing the words unified Telemetry abstraction uh",
    "start": "1981200",
    "end": "1987679"
  },
  {
    "text": "and you may think about open Telemetry so open Telemetry is an open source project uh it's you know community-led",
    "start": "1987679",
    "end": "1996019"
  },
  {
    "text": "it's got a load of vendors signed up to it and its goal is to be a unified Telemetry platform to be able to so when",
    "start": "1996019",
    "end": "2003039"
  },
  {
    "text": "you grab things off the shelf they come with instrumentation out of the box they've got all that detail in there it's got means that when you're writing",
    "start": "2003039",
    "end": "2009940"
  },
  {
    "text": "instrumentation in any language you've got a standard way of doing it and it's a really great project",
    "start": "2009940",
    "end": "2015460"
  },
  {
    "text": "but one thing that's really different to open Telemetry compared to what I've described today is that they still have",
    "start": "2015460",
    "end": "2022659"
  },
  {
    "text": "this very strong distinction between tracers metrics and logs there's different apis",
    "start": "2022659",
    "end": "2029260"
  },
  {
    "text": "and I think I don't know if they're interested in trying to consolidate these and I",
    "start": "2029260",
    "end": "2034299"
  },
  {
    "text": "haven't I haven't asked them yet maybe I will uh but yeah so open Telemetry you take traces metrics and logs separately and",
    "start": "2034299",
    "end": "2041140"
  },
  {
    "text": "you plug them into the open Telemetry box and then based on your application configuration it sends them off to one",
    "start": "2041140",
    "end": "2048099"
  },
  {
    "text": "or more back ends as required so I think if I was doing this experiment with open",
    "start": "2048099",
    "end": "2053618"
  },
  {
    "text": "Telemetry I think I'd still want that extra layer over the top so that in my application code at least things just",
    "start": "2053619",
    "end": "2060760"
  },
  {
    "text": "kept I only had that one bit of telemetry code that then teed off to the various different types",
    "start": "2060760",
    "end": "2067300"
  },
  {
    "text": "anyway so that's my conclusion uh thank you for listening to me today thanks for coming along uh and I'll be opening the",
    "start": "2067300",
    "end": "2073839"
  },
  {
    "start": "2068000",
    "end": "2079000"
  },
  {
    "text": "floor to some questions",
    "start": "2073839",
    "end": "2076500"
  },
  {
    "start": "2079000",
    "end": "2250000"
  },
  {
    "text": "hello hi there so much Glenn for uh for that presentation that was really interesting to see your experiences with",
    "start": "2079060",
    "end": "2086020"
  },
  {
    "text": "a different way of doing Telemetry in your application we have a few questions have already come in and I hope that",
    "start": "2086020",
    "end": "2092440"
  },
  {
    "text": "people continue to ask them in the chat we'll get Glenn to answer all of your questions as they come uh and the first",
    "start": "2092440",
    "end": "2099339"
  },
  {
    "text": "couple were about maybe the specifics of experience with logs and how does that translate to this world with kind of",
    "start": "2099339",
    "end": "2105700"
  },
  {
    "text": "event first and so a really good example I often hear come up is what do you do with the exception handling so what did",
    "start": "2105700",
    "end": "2112599"
  },
  {
    "text": "you guys what did you all do with that were those also sent to Honeycomb yeah so I'll answer this question in a few",
    "start": "2112599",
    "end": "2118359"
  },
  {
    "text": "different parts because um so partially this story takes place in go and and anyone who's worked with",
    "start": "2118359",
    "end": "2125079"
  },
  {
    "text": "go well no it doesn't have exceptions um and actually out of the box like this",
    "start": "2125079",
    "end": "2130780"
  },
  {
    "text": "the traditional pattern with go errors is to just kind of pass them up and they don't get any contacts there's no stack",
    "start": "2130780",
    "end": "2136119"
  },
  {
    "text": "with them so they're actually just really annoying as errors you just get error this is like file not found you know like which file or where from I",
    "start": "2136119",
    "end": "2142119"
  },
  {
    "text": "don't know um but then like a few years ago ago added this error wrapping feature and",
    "start": "2142119",
    "end": "2147640"
  },
  {
    "text": "then so each layer of your stack you like put a bit more context in the error as it travels up and you end up building",
    "start": "2147640",
    "end": "2152980"
  },
  {
    "text": "your own stack traces which it's not the greatest system in the world but it kind of works",
    "start": "2152980",
    "end": "2158440"
  },
  {
    "text": "um and yeah so I we do include the full like all the layers of the error that",
    "start": "2158440",
    "end": "2164079"
  },
  {
    "text": "all as much information as we've got about any error error in the honeycomb events so the convention like the the",
    "start": "2164079",
    "end": "2171280"
  },
  {
    "text": "field we had there like the error field that would be the string of an error which effectively included all that",
    "start": "2171280",
    "end": "2177820"
  },
  {
    "text": "stack information and it did mean that in a single trace if you get an error like Midway down you",
    "start": "2177820",
    "end": "2184060"
  },
  {
    "text": "would get this spanwell error and the parent would error with a bit with a bit more information the parent of that would error with a bit more information",
    "start": "2184060",
    "end": "2190000"
  },
  {
    "text": "and so on but generally if that error wasn't handled in a way that like",
    "start": "2190000",
    "end": "2196000"
  },
  {
    "text": "sort of in turned into a non-error when it got all the way back up to the top then that error would be the like the",
    "start": "2196000",
    "end": "2202720"
  },
  {
    "text": "low error with all the extra detail and the full stack um but I have also done this approach in",
    "start": "2202720",
    "end": "2207940"
  },
  {
    "text": "languages which do have stack traces and generally yeah I would have so in those",
    "start": "2207940",
    "end": "2213940"
  },
  {
    "text": "cases I would have the error field be like a the string version of The Arrow which is a bit shorter and it's kind of",
    "start": "2213940",
    "end": "2219520"
  },
  {
    "text": "you can consume it but I would generally also add the full stack Trace in another field",
    "start": "2219520",
    "end": "2225520"
  },
  {
    "text": "um we often like my current job we use um robot no not robot but yeah tools like",
    "start": "2225520",
    "end": "2232300"
  },
  {
    "text": "roll bar air brake and um Sentry and so on like exception tracking tools so you",
    "start": "2232300",
    "end": "2237880"
  },
  {
    "text": "can often Pass the full stack of an error over to that and that handles grouping and those sorts of things and",
    "start": "2237880",
    "end": "2243640"
  },
  {
    "text": "then basically make sure you include uh the trace ID when you send it to those tools and you can link everything up and",
    "start": "2243640",
    "end": "2249400"
  },
  {
    "text": "match things together yeah yeah and I think the practicality of it is of course stack traces can get",
    "start": "2249400",
    "end": "2255280"
  },
  {
    "start": "2250000",
    "end": "2305000"
  },
  {
    "text": "quite large and so no matter what tool you're getting to use there probably will be a limit of how many characters",
    "start": "2255280",
    "end": "2261220"
  },
  {
    "text": "how large those fields can get but they can often handle quite a lot and so that is I guess there is some practicality",
    "start": "2261220",
    "end": "2267820"
  },
  {
    "text": "there but otherwise yeah throw it all in get it all included and when you're exploring the data there's kind of as I",
    "start": "2267820",
    "end": "2273579"
  },
  {
    "text": "showed in those examples there's multiple different modes of exploring the data so if you're plotting a Time series and you want to group by you",
    "start": "2273579",
    "end": "2280119"
  },
  {
    "text": "probably don't want to group by a stack Trace because there's enough difference but then once you've clicked into a",
    "start": "2280119",
    "end": "2285520"
  },
  {
    "text": "trace and you found a single error you probably do want to see that side face so having those both things available in different fields our Founders work quite",
    "start": "2285520",
    "end": "2291760"
  },
  {
    "text": "well different fields but same UI same kind of tool yeah they don't have to go",
    "start": "2291760",
    "end": "2296800"
  },
  {
    "text": "off and like open up another tool and log in again and you know go through your two-factor author code just to see",
    "start": "2296800",
    "end": "2302079"
  },
  {
    "text": "like a bit more detail of your error of course great there's kind of a paired question with this as you spoke a little",
    "start": "2302079",
    "end": "2308320"
  },
  {
    "start": "2305000",
    "end": "2470000"
  },
  {
    "text": "bit about um Telemetry at scale and so how you'll use like logging levels with logs and",
    "start": "2308320",
    "end": "2313720"
  },
  {
    "text": "and you might use sampling with this event first and so there's a question here around whether or not you send all",
    "start": "2313720",
    "end": "2320740"
  },
  {
    "text": "service invocations to these kind of event Telemetry or um if you don't trace all of them how did you all handle that",
    "start": "2320740",
    "end": "2326920"
  },
  {
    "text": "so in this in the story here we were building a service from scratch and so every time we added a new service or a",
    "start": "2326920",
    "end": "2333160"
  },
  {
    "text": "new dependency to it we would add the tracing straight away in other scenarios we've been adding we've had an existing",
    "start": "2333160",
    "end": "2339579"
  },
  {
    "text": "service that has a lot of dependencies already and generally we'd sort of be driven a bit more by need so we'd go",
    "start": "2339579",
    "end": "2345099"
  },
  {
    "text": "back and add Telemetry when we're discovering an issue a problem with that service um and actually what I've found when you",
    "start": "2345099",
    "end": "2350740"
  },
  {
    "text": "do that sort of piecemeal adoption is that when you then look at a choice you know there's a gap there well there's a",
    "start": "2350740",
    "end": "2356320"
  },
  {
    "text": "gap and then that kind of just gives you that nudge to go and add that extra tracing so you kind of once you get used",
    "start": "2356320",
    "end": "2362740"
  },
  {
    "text": "to seeing these traces not everything linking together as soon as you get like a trace that's got a bit missing or a",
    "start": "2362740",
    "end": "2368680"
  },
  {
    "text": "trace that like well hang on no somebody should have called me where's my parents like you start to go around and add all",
    "start": "2368680",
    "end": "2373900"
  },
  {
    "text": "these um um correlation headers and so on so everything all links together nicely",
    "start": "2373900",
    "end": "2379839"
  },
  {
    "text": "um obviously the downside of that is that well not obviously at all so the",
    "start": "2379839",
    "end": "2385240"
  },
  {
    "text": "way tracing decisions work in most modern sort of tracing tools is you either keep a whole Trace",
    "start": "2385240",
    "end": "2391300"
  },
  {
    "text": "or not or none of it so the more stuff you link together the more expensive it",
    "start": "2391300",
    "end": "2396339"
  },
  {
    "text": "is to say yes I'm keeping one so when you start to do Dynamic tracing then the",
    "start": "2396339",
    "end": "2402040"
  },
  {
    "text": "cost of keeping each individual Trace increases and that cost hopefully is you know proportional to the value of the",
    "start": "2402040",
    "end": "2408280"
  },
  {
    "text": "trace um so something I've been really wanting to experiment with what for a while is what I like to think of as like",
    "start": "2408280",
    "end": "2413440"
  },
  {
    "text": "horizontal sampling so can I keep like a slimmed down version of some traces so like maybe",
    "start": "2413440",
    "end": "2419800"
  },
  {
    "text": "I'll just keep the top level spam from each service but not the detailed spans on like nine out of ten and then one out",
    "start": "2419800",
    "end": "2426160"
  },
  {
    "text": "of ten I'll keep the rest or always on errors um so that's not something I've had the sort of either enough of a need or the",
    "start": "2426160",
    "end": "2432400"
  },
  {
    "text": "opportunity to explore yet but there's definitely some some stuff you can do that's similar to log levels without",
    "start": "2432400",
    "end": "2437800"
  },
  {
    "text": "quite being the same as log levels that's exactly what I was thinking of when you were describing it's almost like you can add a level to your",
    "start": "2437800",
    "end": "2444160"
  },
  {
    "text": "subspans but then you decide you know yeah trying to have that sort of dynamic tail sampling thing where you say okay",
    "start": "2444160",
    "end": "2450820"
  },
  {
    "text": "well if it's an error capture more like I've worked on systems in the past where there was a special header and I was",
    "start": "2450820",
    "end": "2456640"
  },
  {
    "text": "undocumented but if you set an HTTP header in your browser then it would turn on debug logging for that request and those tools are really helpful for",
    "start": "2456640",
    "end": "2463540"
  },
  {
    "text": "like okay if I can reproduce an issue then I can you know run it in production with more logging it's very interesting",
    "start": "2463540",
    "end": "2470619"
  },
  {
    "start": "2470000",
    "end": "2583000"
  },
  {
    "text": "yeah so some more some more questions around the kind of usability of this so and developer experience and there's a",
    "start": "2470619",
    "end": "2477040"
  },
  {
    "text": "question here around the annoyance or or level of friction and readability when you when you had to add those span and",
    "start": "2477040",
    "end": "2482920"
  },
  {
    "text": "error calls across your stack how did that work to you well so again in our case this was in go and it's all the",
    "start": "2482920",
    "end": "2491020"
  },
  {
    "text": "libraries and code we were using were quite sort of modern go so they all have this context parameter um and goes pretty basically the",
    "start": "2491020",
    "end": "2497500"
  },
  {
    "text": "convention is to pass this around and that's where you stuff all your data in so that's worked really well um I've had a different experience doing",
    "start": "2497500",
    "end": "2504040"
  },
  {
    "text": "this in JavaScript and typescripts where the the way the event Loop works and the asynchronicity sometimes the tasks can",
    "start": "2504040",
    "end": "2510760"
  },
  {
    "text": "get lost um but there are helper functions in certainly in the honeycomb instrumentation libraries and I believe",
    "start": "2510760",
    "end": "2516220"
  },
  {
    "text": "in the open Telemetry libraries as well that basically let you give it hints when you you lose that sort of",
    "start": "2516220",
    "end": "2521380"
  },
  {
    "text": "information so yeah most of the time it kind of just works and you the spans and errors everything sort of links together",
    "start": "2521380",
    "end": "2527400"
  },
  {
    "text": "sometimes even in process you have to give it a bit of a hint and then then to cross process boundaries so if you're",
    "start": "2527400",
    "end": "2533800"
  },
  {
    "text": "doing like common RPC things like HTTP or grpc then usually out of the box you",
    "start": "2533800",
    "end": "2540579"
  },
  {
    "text": "get effectively headers which match up the IDS and pass them across process boundaries if you're doing things like",
    "start": "2540579",
    "end": "2546280"
  },
  {
    "text": "if you're putting messages on say rabbit and queue or Kafka or sqs or Cubase systems then generally use at the moment",
    "start": "2546280",
    "end": "2553180"
  },
  {
    "text": "at least I've seen you have to roll your own so you take the same headers that you would put in an HTTP request and then",
    "start": "2553180",
    "end": "2559599"
  },
  {
    "text": "you add them to the metadata of your queue system and then you unpack them at the end if you want to link them up and",
    "start": "2559599",
    "end": "2565000"
  },
  {
    "text": "there's various trade-offs about whether that should be the same trace or different traces so there's I think there is a bit to think about there but",
    "start": "2565000",
    "end": "2570880"
  },
  {
    "text": "it's not each individual choice is actually quite cheap to make they're not really complicated things they're just like okay well do I want to link this",
    "start": "2570880",
    "end": "2577060"
  },
  {
    "text": "together and if so you know I'll do it it's just you know ultimately it's just passing a couple of strings around it's",
    "start": "2577060",
    "end": "2582400"
  },
  {
    "text": "not that difficult absolutely thank you I think that also kind of touched on that next question",
    "start": "2582400",
    "end": "2587440"
  },
  {
    "start": "2583000",
    "end": "2660000"
  },
  {
    "text": "around correlating logs and traces and metadata and how you're able to pass that through",
    "start": "2587440",
    "end": "2593680"
  },
  {
    "text": "um with things is there any other way in which you connect your uh your event data with anything else uh viewing it in",
    "start": "2593680",
    "end": "2601599"
  },
  {
    "text": "as you said the elasticsearch uh that you had and things like that other than just kind of Trace IDs and things",
    "start": "2601599",
    "end": "2607900"
  },
  {
    "text": "um yeah not really I think so some of the systems I've seen where we've added um Trace information to already had like",
    "start": "2607900",
    "end": "2614140"
  },
  {
    "text": "a request ID concept within them so we we add that to all the various different backends",
    "start": "2614140",
    "end": "2620200"
  },
  {
    "text": "um generally when I'm working on newer systems like they've never had that before so the trace ID and the span IDs",
    "start": "2620200",
    "end": "2626260"
  },
  {
    "text": "those are treated as the ones that like the things to tie everything together so when we send our errors off to roll bar",
    "start": "2626260",
    "end": "2634300"
  },
  {
    "text": "they're willing we have like we have the section for like here's the trace ID and so they can match those things back up",
    "start": "2634300",
    "end": "2639760"
  },
  {
    "text": "again and so on and likewise even in the logs we make sure it's got the choice it's got the span ID so if say you're on",
    "start": "2639760",
    "end": "2646900"
  },
  {
    "text": "a system where you're keeping all of your logs uh maybe sending them to S3 but you're dynamically sampling your",
    "start": "2646900",
    "end": "2653740"
  },
  {
    "text": "traces you can still say okay well here's the dynamically sampled ID kind of like match that up to the other ID",
    "start": "2653740",
    "end": "2658900"
  },
  {
    "text": "and so on that's great yeah I think you went into great detail about how you are using",
    "start": "2658900",
    "end": "2664960"
  },
  {
    "start": "2660000",
    "end": "2757000"
  },
  {
    "text": "this kind of third-party SAS product and but also having a bit of realistic awareness that things go down and and",
    "start": "2664960",
    "end": "2671740"
  },
  {
    "text": "what do you need to do in those cases and sending that to a second location so there is a question here have you",
    "start": "2671740",
    "end": "2677260"
  },
  {
    "text": "pragmatically had to deal with that did you ever try and send traces out when honeycomb wasn't was down or was",
    "start": "2677260",
    "end": "2683260"
  },
  {
    "text": "experiencing issues and what happened with that did you lose those those traces from that view or was it just",
    "start": "2683260",
    "end": "2689020"
  },
  {
    "text": "delayed how'd that work uh so for honeycomb I think they have had a handful of like outages but you know",
    "start": "2689020",
    "end": "2695920"
  },
  {
    "text": "nothing major so far like such Woods um but yeah in those cases you just kind",
    "start": "2695920",
    "end": "2701800"
  },
  {
    "text": "of a bit blind there or we can log on to the box and have a look or we can look refer to our other back",
    "start": "2701800",
    "end": "2707079"
  },
  {
    "text": "ends but if Honey comes down there's like basically there's a little background cue in the process which tries to send and if that errors then it",
    "start": "2707079",
    "end": "2713920"
  },
  {
    "text": "just sort of drops them um I've seen I mean I've had the same experience with like home rolls log back",
    "start": "2713920",
    "end": "2719740"
  },
  {
    "text": "ends when you know sometimes the logging back end goes down and then you just lose logs or risks or worse uh so one",
    "start": "2719740",
    "end": "2725680"
  },
  {
    "text": "time I think it was a Java based stack but no I think it was the application",
    "start": "2725680",
    "end": "2731380"
  },
  {
    "text": "was writing to syslog and then syslog was forwarding and then to a central and ended up on a box somewhere and then",
    "start": "2731380",
    "end": "2737020"
  },
  {
    "text": "that box ran out disk and someone had I don't know if they've thought about it or this was just at the out of the box",
    "start": "2737020",
    "end": "2742540"
  },
  {
    "text": "defaults but it had been configured with back pressure uh so what actually happened was the",
    "start": "2742540",
    "end": "2748180"
  },
  {
    "text": "applications all crashed because one box filled up with logs uh so of the two",
    "start": "2748180",
    "end": "2753220"
  },
  {
    "text": "choices I would always rather discard logs than take an outage when there's lemon juice down yes have to pick your",
    "start": "2753220",
    "end": "2758740"
  },
  {
    "start": "2757000",
    "end": "2898000"
  },
  {
    "text": "priorities sometimes don't you hard decisions but I think those those make sense so absolutely",
    "start": "2758740",
    "end": "2765579"
  },
  {
    "text": "um you sort of ended that talk on a bit of an interesting balancing question of what what would you suggest around",
    "start": "2765579",
    "end": "2772300"
  },
  {
    "text": "unified Telemetry approach and you kind of hedged a bit and said I think I think I'd suggest it but but maybe not",
    "start": "2772300",
    "end": "2778420"
  },
  {
    "text": "often with these talks we gain some more experience between when we deliver them and and when and when we're actually",
    "start": "2778420",
    "end": "2784900"
  },
  {
    "text": "here for the Q a so has anything changed around that would you be more kind of bullish in suggesting uh that unified",
    "start": "2784900",
    "end": "2790839"
  },
  {
    "text": "Telemetry approach um I don't think things have hugely changed I think like the reasons I gave",
    "start": "2790839",
    "end": "2796960"
  },
  {
    "text": "in the talk there so it was just a bit weird everyone looked at me like I was crazy like you know what are you doing",
    "start": "2796960",
    "end": "2802300"
  },
  {
    "text": "like and actually I've spoken to a few people oh yeah we started doing this and actually yeah it was great once you start doing it it's like yeah this feels",
    "start": "2802300",
    "end": "2808359"
  },
  {
    "text": "fine but just having to convince people over and over and over again especially if you're like a growing organization",
    "start": "2808359",
    "end": "2814180"
  },
  {
    "text": "when someone comes in how do we log oh we don't do logging here and they're like what who are you what are you doing and I think so that would effectively",
    "start": "2814180",
    "end": "2820599"
  },
  {
    "text": "that's the biggest cost is like getting people on board getting people to believe that actually it's fine don't worry about it this works",
    "start": "2820599",
    "end": "2827260"
  },
  {
    "text": "um and I think effectively there's a chicken egg problem there whereas if it becomes a warm more widespread practice",
    "start": "2827260",
    "end": "2832660"
  },
  {
    "text": "then the cost of convincing people goes down by quite a lot so yeah I guess maybe I'll submit this talk to a few other conferences and uh",
    "start": "2832660",
    "end": "2839260"
  },
  {
    "text": "go from there when people over one conference talk at a time huh that's fantastic yeah I think this has been",
    "start": "2839260",
    "end": "2845920"
  },
  {
    "text": "really great I know I still have more questions about what ever ended happening with the uh that shared",
    "start": "2845920",
    "end": "2851260"
  },
  {
    "text": "library now that you've had this experiment you know did this roll back in and all that but I think these are",
    "start": "2851260",
    "end": "2856300"
  },
  {
    "text": "what we can take advantage of in the hangout so we've got a few more ways in which to ask you questions through the",
    "start": "2856300",
    "end": "2862180"
  },
  {
    "text": "qcon slack if you're not already in it please do join and also for the next kind of 10 to 15 minutes Glenn's gonna",
    "start": "2862180",
    "end": "2868300"
  },
  {
    "text": "be hanging out with us in Zoom so go ahead and on the schedule page there is a link to the Hangouts and there's also",
    "start": "2868300",
    "end": "2874599"
  },
  {
    "text": "I think maybe a link here in the chat but uh yeah let's let's go have a further chat about this experience with",
    "start": "2874599",
    "end": "2880540"
  },
  {
    "text": "event first uh Telemetry thank you so much again Glenn it was a fantastic talk yeah thank you very much",
    "start": "2880540",
    "end": "2888240"
  },
  {
    "text": "[Music] thank you",
    "start": "2890500",
    "end": "2897660"
  }
]
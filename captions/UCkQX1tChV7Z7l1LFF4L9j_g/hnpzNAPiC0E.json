[
  {
    "start": "0",
    "end": "46000"
  },
  {
    "text": "okay welcome to skating Instagram infrastructure Instagram is a community",
    "start": "3920",
    "end": "12380"
  },
  {
    "text": "where people connect with each other through shared experiences in a visual way a bit of history of Instagram it was",
    "start": "12380",
    "end": "20990"
  },
  {
    "text": "founded in 2010 less than two years later it was acquired by Facebook",
    "start": "20990",
    "end": "27409"
  },
  {
    "text": "I joined Instagram three years ago and have been working on the infrastructure team since then fast forward to 2017 we",
    "start": "27409",
    "end": "36620"
  },
  {
    "text": "got a new logo and in the just last six months a hundred million new users have",
    "start": "36620",
    "end": "42530"
  },
  {
    "text": "joined the community since we're talking about saving today let's take a look at",
    "start": "42530",
    "end": "49489"
  },
  {
    "start": "46000",
    "end": "106000"
  },
  {
    "text": "a typical day on Instagram four hundred million users visit Instagram every day",
    "start": "49489",
    "end": "56469"
  },
  {
    "text": "four billion likes are registered more than 100 million media is uploaded and",
    "start": "56469",
    "end": "63170"
  },
  {
    "text": "our top account has a hundred more than 110 million followers this is across the",
    "start": "63170",
    "end": "69470"
  },
  {
    "text": "board four times increase in scaling than three years ago when I first joined",
    "start": "69470",
    "end": "74600"
  },
  {
    "text": "Instagram back then it was a much smaller development team the app was waste and poor and we have a lot fewer",
    "start": "74600",
    "end": "82009"
  },
  {
    "text": "users but it was fast growing and we were struggling to keep the service up",
    "start": "82009",
    "end": "88220"
  },
  {
    "text": "all the time one of the common things you would see on a Friday afternoon right before the weekend peak time is",
    "start": "88220",
    "end": "95360"
  },
  {
    "text": "our uncle engineers will be staring at the computer screen looking at the CPU load and decide whether we need to spend",
    "start": "95360",
    "end": "101869"
  },
  {
    "text": "up a few actual web servers for the weekend well we have come a long way",
    "start": "101869",
    "end": "107600"
  },
  {
    "start": "106000",
    "end": "141000"
  },
  {
    "text": "since that mode of operation and so today we're going to talk about in three",
    "start": "107600",
    "end": "113479"
  },
  {
    "text": "dimensions of growth to non-native us to scale to today's level to scale out is",
    "start": "113479",
    "end": "120500"
  },
  {
    "text": "to build an infrastructure that allows us to add more hardware when we need them and to scale up is to make each of",
    "start": "120500",
    "end": "129470"
  },
  {
    "text": "these servers count and to scale the dev team is to enable a fast-growing",
    "start": "129470",
    "end": "135640"
  },
  {
    "text": "engineering team to continue to move fast without breaking things so",
    "start": "135640",
    "end": "141930"
  },
  {
    "start": "141000",
    "end": "232000"
  },
  {
    "text": "first scale out is the ability to use more servers to match the user growth from a few servers to quite a few in the",
    "start": "141930",
    "end": "150180"
  },
  {
    "text": "data center to expanding to multiple data centers Instagram was running in",
    "start": "150180",
    "end": "157650"
  },
  {
    "text": "AWS from the beginning and continued to do so on after almost two years with",
    "start": "157650",
    "end": "163920"
  },
  {
    "text": "Facebook about three years ago it moved its service completely inside Facebook",
    "start": "163920",
    "end": "169590"
  },
  {
    "text": "data center in order to take advantage of some of the scaling services like",
    "start": "169590",
    "end": "175160"
  },
  {
    "text": "monitoring's search or spam but as soon as we moved into one of the data centers",
    "start": "175160",
    "end": "182250"
  },
  {
    "text": "Facebook cut out the entire network access to that data center why Facebook",
    "start": "182250",
    "end": "187860"
  },
  {
    "text": "takes disaster readiness very seriously so it would routinely conduct these",
    "start": "187860",
    "end": "193950"
  },
  {
    "text": "drills called storms on a regular basis",
    "start": "193950",
    "end": "199410"
  },
  {
    "text": "to make sure that all our services can sustain the loss of a region and",
    "start": "199410",
    "end": "205320"
  },
  {
    "text": "continue to serve the users in a seamless manner Instagram a protector at the time was not able to operate the",
    "start": "205320",
    "end": "212519"
  },
  {
    "text": "multiple data centers so we had to take play the gorilla tech lick and move up",
    "start": "212519",
    "end": "218489"
  },
  {
    "text": "with our whole service to another data center unfortunately disasters are not just",
    "start": "218489",
    "end": "224580"
  },
  {
    "text": "theoretical hypothesis so we needed to get ready for the next time the storm happens or the reality hits",
    "start": "224580",
    "end": "232280"
  },
  {
    "start": "232000",
    "end": "276000"
  },
  {
    "text": "in addition thanks to our rapid growth we were quickly running out of capacity",
    "start": "232280",
    "end": "237420"
  },
  {
    "text": "in that data center Facebook had capacity elsewhere but we couldn't take",
    "start": "237420",
    "end": "242580"
  },
  {
    "text": "advantage of that power outages in the human errors also contribute to service",
    "start": "242580",
    "end": "249150"
  },
  {
    "text": "unreliability just a few days ago a RM -",
    "start": "249150",
    "end": "255239"
  },
  {
    "text": "RS type of you know operation on our container tier was wiping out quite a",
    "start": "255239",
    "end": "261930"
  },
  {
    "text": "few of our production servers fortunately we had the ability to move our traffic away from the problem data",
    "start": "261930",
    "end": "267330"
  },
  {
    "text": "center in case you think that this only matters",
    "start": "267330",
    "end": "272669"
  },
  {
    "text": "to scalable services such as Instagram here is a headline from last week which",
    "start": "272669",
    "end": "280260"
  },
  {
    "start": "276000",
    "end": "307000"
  },
  {
    "text": "reminds us even the worst most reliable infrastructure could still have outages",
    "start": "280260",
    "end": "285300"
  },
  {
    "text": "at times and if you don't have another region to fall back on then this is a",
    "start": "285300",
    "end": "290970"
  },
  {
    "text": "suggestion from one of the articles published I'd say that in addition to praying at the moment of this event",
    "start": "290970",
    "end": "298680"
  },
  {
    "text": "let's put something on the roadmap for the next time you we would go business",
    "start": "298680",
    "end": "303900"
  },
  {
    "text": "as usual how do we get there let's take a look at the back end stack Instagram",
    "start": "303900",
    "end": "309510"
  },
  {
    "start": "307000",
    "end": "351000"
  },
  {
    "text": "hat at a time at the center is the web tier that runs Gengo with Python",
    "start": "309510",
    "end": "315539"
  },
  {
    "text": "it receives user requests and accesses various back and storage or services for",
    "start": "315539",
    "end": "321539"
  },
  {
    "text": "responding to the user a user request could also trigger some asynchronous",
    "start": "321539",
    "end": "326930"
  },
  {
    "text": "tasks that are done in the in the backend for example sending notification",
    "start": "326930",
    "end": "333870"
  },
  {
    "text": "to the person whose photos you liked these tasks are sent to rabbitmq and",
    "start": "333870",
    "end": "339330"
  },
  {
    "text": "celery for processing so how do we distribute this back to different data",
    "start": "339330",
    "end": "344610"
  },
  {
    "text": "centers we identified two categories of servers or services storage versus",
    "start": "344610",
    "end": "352620"
  },
  {
    "start": "351000",
    "end": "452000"
  },
  {
    "text": "computing storage server store global data that needs to be consistent across",
    "start": "352620",
    "end": "358590"
  },
  {
    "text": "multiple data centers with replication perhaps with some latency but eventual consistency computing servers are",
    "start": "358590",
    "end": "367260"
  },
  {
    "text": "usually stateless they process requests by user traffic the data in these",
    "start": "367260",
    "end": "374550"
  },
  {
    "text": "servers are temporary and they can typically be reconstructed from the global data using these two criteria we",
    "start": "374550",
    "end": "383070"
  },
  {
    "text": "now rivet our stack to see what fits where we use post graph servers to store",
    "start": "383070",
    "end": "391020"
  },
  {
    "text": "user media friendship type of data and a typical deployment in one region is a",
    "start": "391020",
    "end": "398270"
  },
  {
    "text": "master with multiple replicas to support high",
    "start": "398270",
    "end": "403650"
  },
  {
    "text": "to read RPS the webservers rights to the master where data gets replicated but",
    "start": "403650",
    "end": "411780"
  },
  {
    "text": "the reads typically happens on a replica when going to multiple data centers it's",
    "start": "411780",
    "end": "418289"
  },
  {
    "text": "pretty straightforward with cross region but multiple applications the jungle",
    "start": "418289",
    "end": "423389"
  },
  {
    "text": "continues to write to the master possibly cross region but typically only need to read from a local region to",
    "start": "423389",
    "end": "431880"
  },
  {
    "text": "address the increased latency for writing we did make modification to minimize the round-trip time for write",
    "start": "431880",
    "end": "439080"
  },
  {
    "text": "by patching request wherever it's possible the increased latency between",
    "start": "439080",
    "end": "444930"
  },
  {
    "text": "the master and replicas turns out to not have been a big problem for us next we",
    "start": "444930",
    "end": "453690"
  },
  {
    "start": "452000",
    "end": "493000"
  },
  {
    "text": "use Cassandra to store user fees activities etc in Cassandra there's no",
    "start": "453690",
    "end": "459240"
  },
  {
    "text": "master all replicas have the same copy of data with eventual consistency",
    "start": "459240",
    "end": "464780"
  },
  {
    "text": "consistency can be configured based on applications tolerance for",
    "start": "464780",
    "end": "469949"
  },
  {
    "text": "inconsistencies scalability service availability and latency so for example",
    "start": "469949",
    "end": "476010"
  },
  {
    "text": "one application could choose to have right consistency of to and we",
    "start": "476010",
    "end": "481710"
  },
  {
    "text": "consistency of one going to multiply the center again is pretty straightforward",
    "start": "481710",
    "end": "487080"
  },
  {
    "text": "you can have the replicas living in different data center on the computing",
    "start": "487080",
    "end": "493919"
  },
  {
    "text": "side we grouped Django and rabbits and a celery into one pod that goes in each",
    "start": "493919",
    "end": "501900"
  },
  {
    "text": "region the global load balancer would balance us send the user requests to",
    "start": "501900",
    "end": "507659"
  },
  {
    "text": "Django's but the asynchronous task would be produced and consumed in the same",
    "start": "507659",
    "end": "513599"
  },
  {
    "text": "region that test has over here database",
    "start": "513599",
    "end": "519089"
  },
  {
    "text": "replication across region and computing resources all in containing one region",
    "start": "519089",
    "end": "524600"
  },
  {
    "text": "but we have left out memcache",
    "start": "524600",
    "end": "528920"
  },
  {
    "text": "limp actually is a huge part of the scalability story it is a high-performance key value store that",
    "start": "531730",
    "end": "538459"
  },
  {
    "start": "532000",
    "end": "585000"
  },
  {
    "text": "fund hence the data based year without which the databases would be crumbling under the read amend it provides",
    "start": "538459",
    "end": "546230"
  },
  {
    "text": "millions of operations per second of each of the servers because of such high",
    "start": "546230",
    "end": "552740"
  },
  {
    "text": "rate of services it is very sensitive to network conditions for latency is a big",
    "start": "552740",
    "end": "557990"
  },
  {
    "text": "deal as such cross region read/write is prohibitive so our architecture decided",
    "start": "557990",
    "end": "566509"
  },
  {
    "text": "we will not provide a global consistent memcache here the work that in the",
    "start": "566509",
    "end": "573050"
  },
  {
    "text": "memcache in each region is determined by user traffic served out of that region",
    "start": "573050",
    "end": "580540"
  },
  {
    "text": "let's see what problem it might cause as",
    "start": "580720",
    "end": "586009"
  },
  {
    "start": "585000",
    "end": "734000"
  },
  {
    "text": "the user comes in making a comment on the media that gets into in word it gets",
    "start": "586009",
    "end": "592519"
  },
  {
    "text": "into inserting the Postgres server the memcache also gets updated by the",
    "start": "592519",
    "end": "597949"
  },
  {
    "text": "general server another reader comes in another user comes in and comes fetch",
    "start": "597949",
    "end": "604759"
  },
  {
    "text": "his feed he's going to use the same memcached here where the commenter was",
    "start": "604759",
    "end": "610689"
  },
  {
    "text": "so he's going to give them the latest comment no problem when both users are",
    "start": "610689",
    "end": "616579"
  },
  {
    "text": "served out of the same region when we go to two different regions it could be a",
    "start": "616579",
    "end": "622189"
  },
  {
    "text": "problem since we have the user requests based on a user ID two people sitting",
    "start": "622189",
    "end": "628430"
  },
  {
    "text": "next to each other to be served out of two different data centers let's see what happens in that case again the",
    "start": "628430",
    "end": "636079"
  },
  {
    "text": "users see makes a comment data gets replicates inserted into the post grant server memcache is updated locally in",
    "start": "636079",
    "end": "644689"
  },
  {
    "text": "that region but it does not update the memcache in the data in the other data",
    "start": "644689",
    "end": "650420"
  },
  {
    "text": "center so even though the comment is replicated in the Postgres server",
    "start": "650420",
    "end": "656870"
  },
  {
    "text": "nobody is invalidating the memcache in the second data",
    "start": "656870",
    "end": "662080"
  },
  {
    "text": "Center the user comes in getting his feet is going to get a stale comment of",
    "start": "662080",
    "end": "667480"
  },
  {
    "text": "the media well it's not a great user",
    "start": "667480",
    "end": "674050"
  },
  {
    "text": "experience and could cause a worse consequence than just social awkwardness so how do we fix the caching consistency",
    "start": "674050",
    "end": "681460"
  },
  {
    "text": "problem as user comments comes in again we insert into the post graph database",
    "start": "681460",
    "end": "687270"
  },
  {
    "text": "but we're now going to update the memcache from Jango instead we use the",
    "start": "687270",
    "end": "693700"
  },
  {
    "text": "post class replication mechanism and we want to demon on each of the Postgres",
    "start": "693700",
    "end": "699970"
  },
  {
    "text": "and replicas that tells the database updates and it dents in validates the",
    "start": "699970",
    "end": "705250"
  },
  {
    "text": "memcache in its own local region now when the user R comes in and reads the",
    "start": "705250",
    "end": "711820"
  },
  {
    "text": "feet it's going to be forced to go to many forced to go to Postgres because",
    "start": "711820",
    "end": "717340"
  },
  {
    "text": "memcache does not have that entry anymore now the user gets the latest",
    "start": "717340",
    "end": "723940"
  },
  {
    "text": "comments while it salts the stale",
    "start": "723940",
    "end": "729040"
  },
  {
    "text": "memcache problem and creates a big load on the Postgres server let's see why",
    "start": "729040",
    "end": "735630"
  },
  {
    "start": "734000",
    "end": "817000"
  },
  {
    "text": "this is a picture that has received 1.2 million likes how do we get this number",
    "start": "735630",
    "end": "743350"
  },
  {
    "text": "to display to the user so we have a table that stores which user like to",
    "start": "743350",
    "end": "749290"
  },
  {
    "text": "which media and we would do a select select town star on that table and this",
    "start": "749290",
    "end": "755980"
  },
  {
    "text": "is going to take hundreds of milliseconds to execute it wasn't a big",
    "start": "755980",
    "end": "761980"
  },
  {
    "text": "deal in the past because the cache cut the lights counter was caching memcache",
    "start": "761980",
    "end": "767800"
  },
  {
    "text": "and every life would just do a memcache increment so there's rarely any need to",
    "start": "767800",
    "end": "772810"
  },
  {
    "text": "go to the database to retrieve this counter but now because we invalidate",
    "start": "772810",
    "end": "777850"
  },
  {
    "text": "this counter for every light that registers all these reads after the the",
    "start": "777850",
    "end": "785710"
  },
  {
    "text": "life would have to be forced to go to the database so",
    "start": "785710",
    "end": "793380"
  },
  {
    "text": "to fix this we created a demon life table that stores just a meteor and the",
    "start": "793380",
    "end": "798850"
  },
  {
    "text": "number of likes instead of going through a select account star we'll just do an index look-up on this table that reduced",
    "start": "798850",
    "end": "805960"
  },
  {
    "text": "the execution time of this query to tens of microseconds many orders of magnitude faster than the previous query however",
    "start": "805960",
    "end": "814630"
  },
  {
    "text": "even in this case the load is still high you've heard a thundering heart problem in the morning on the Facebook live",
    "start": "814630",
    "end": "822850"
  },
  {
    "text": "problem this is very similar when cash is invalidated there's no such counter",
    "start": "822850",
    "end": "830170"
  },
  {
    "text": "in the memcache then all the jungles coming in would have to go to the database even with reduced query time",
    "start": "830170",
    "end": "835960"
  },
  {
    "text": "it's still a lot of load on the database so we use memcache lease to solve this",
    "start": "835960",
    "end": "844450"
  },
  {
    "text": "problem here's how it works the first angle that tries to read from",
    "start": "844450",
    "end": "849760"
  },
  {
    "text": "the memcache instead of doing a normal get it does Alysse get and then cash",
    "start": "849760",
    "end": "855640"
  },
  {
    "text": "returns instead of a Miss it says I don't have the data but you have my",
    "start": "855640",
    "end": "861130"
  },
  {
    "text": "information to go to the database the second general comes in within a shorter",
    "start": "861130",
    "end": "866710"
  },
  {
    "text": "period of time does a same lease get and instead of getting a Miss is told I",
    "start": "866710",
    "end": "873160"
  },
  {
    "text": "don't have the data but don't go to the database I have a stale value for you",
    "start": "873160",
    "end": "878530"
  },
  {
    "text": "you can use it or you can wait to you know we try to get the latest data in",
    "start": "878530",
    "end": "884410"
  },
  {
    "text": "most about the application cases the still value would be completely valid so if you get a million likes versus the",
    "start": "884410",
    "end": "891160"
  },
  {
    "text": "million plus 10 for user experience account are not going to be very different the first angle then goes to",
    "start": "891160",
    "end": "899650"
  },
  {
    "text": "the database and updates the memcache subsequent we would be able to get the",
    "start": "899650",
    "end": "906670"
  },
  {
    "text": "most updated value now with these",
    "start": "906670",
    "end": "913630"
  },
  {
    "text": "improvements the database even though it's still getting higher load than",
    "start": "913630",
    "end": "918820"
  },
  {
    "text": "before it's able to handle the load now and with the building the computing body",
    "start": "918820",
    "end": "924160"
  },
  {
    "text": "building blocks and the replications for scratchin Cassandra we were able to build up an extend Instagram into as",
    "start": "924160",
    "end": "931450"
  },
  {
    "text": "needed mainly data centers as we need to with that we now have capability wherever we",
    "start": "931450",
    "end": "938890"
  },
  {
    "text": "need it and service is more reliable and we're regional failure ready but we're",
    "start": "938890",
    "end": "948010"
  },
  {
    "text": "actually not everywhere we're mostly in North America right now because the latency from Europe and Asia is still",
    "start": "948010",
    "end": "955240"
  },
  {
    "text": "very high so but we also see opportunities there with the latest",
    "start": "955240",
    "end": "962070"
  },
  {
    "text": "features that we have we have four direct messaging and live streaming we",
    "start": "962070",
    "end": "967480"
  },
  {
    "text": "have identified more and more users with more localized social networks whether",
    "start": "967480",
    "end": "973690"
  },
  {
    "text": "it's celebrity whether it's you know a group of friends who are in a particular region in Asia it makes sense to move",
    "start": "973690",
    "end": "981880"
  },
  {
    "text": "the data center closer to where users are to reduce this interaction latency so that would be something that we would",
    "start": "981880",
    "end": "989230"
  },
  {
    "text": "like to tackle next well it is great that we have the ability to add more",
    "start": "989230",
    "end": "996310"
  },
  {
    "text": "servers when we need them we realized we were leading them too fast while our user growth with healthy",
    "start": "996310",
    "end": "1004140"
  },
  {
    "text": "our server growth was far outpacing the user growth and we had grown at this",
    "start": "1004140",
    "end": "1009330"
  },
  {
    "text": "space at this pace you know since two years ago we would be running three four",
    "start": "1009330",
    "end": "1014610"
  },
  {
    "text": "times the servers that we do now so I really like this quote from last cucum",
    "start": "1014610",
    "end": "1022550"
  },
  {
    "text": "so we talked about scale-up we don't mean to buy more expensive hardware's right with more CPUs memories and stuff",
    "start": "1022790",
    "end": "1029670"
  },
  {
    "start": "1023000",
    "end": "1225000"
  },
  {
    "text": "like that rather what we mean is to use as few CPU instructions as possible to",
    "start": "1029670",
    "end": "1036720"
  },
  {
    "text": "achieve something meaning writing good code to reduce the cpu demand on our",
    "start": "1036720",
    "end": "1043160"
  },
  {
    "text": "infrastructure and to also use as few servers as possible to execute to carry",
    "start": "1043160",
    "end": "1049680"
  },
  {
    "text": "out those CPU instructions let's just increase the supply each particular",
    "start": "1049680",
    "end": "1055020"
  },
  {
    "text": "server has if actually each server will be able to serve more users",
    "start": "1055020",
    "end": "1060740"
  },
  {
    "text": "that's what we call skill up so let's take a look at the men's side first",
    "start": "1060740",
    "end": "1066140"
  },
  {
    "text": "we'll go over how we measure the CPU demand how we analyze where it comes",
    "start": "1066140",
    "end": "1071760"
  },
  {
    "text": "from and how we optimize where it matters let's start with collecting some",
    "start": "1071760",
    "end": "1077130"
  },
  {
    "text": "data so Linux provide perfect ABI for",
    "start": "1077130",
    "end": "1082770"
  },
  {
    "text": "applications to retrieve CPU instructions for code segments so we",
    "start": "1082770",
    "end": "1088260"
  },
  {
    "text": "sample user requests and collect these CPU instructions for specific requests",
    "start": "1088260",
    "end": "1093289"
  },
  {
    "text": "along with tons of metadata such as what's the endpoint which data center they're running it from what kind of",
    "start": "1093289",
    "end": "1099630"
  },
  {
    "text": "hardware they're running it on so that we can slice and dice on various dimensions so here is a time serious",
    "start": "1099630",
    "end": "1107450"
  },
  {
    "text": "representation of CPU instruction usage by various endpoints we then implement a",
    "start": "1107450",
    "end": "1113909"
  },
  {
    "text": "set of tools to monitor this metric and alert when the when it increases above",
    "start": "1113909",
    "end": "1121380"
  },
  {
    "text": "certain threshold for example this way",
    "start": "1121380",
    "end": "1127309"
  },
  {
    "text": "with this jump in the time series representation we can then match with the event log to see what are the",
    "start": "1127309",
    "end": "1133559"
  },
  {
    "text": "possible causes is it a div that's rolled out is it some configuration changes or some back-end service roll",
    "start": "1133559",
    "end": "1140520"
  },
  {
    "text": "out another very important piece of metadata that we log is whether a",
    "start": "1140520",
    "end": "1147419"
  },
  {
    "text": "specific feature is on or off in a request this is very critical for us to",
    "start": "1147419",
    "end": "1153350"
  },
  {
    "text": "detect increased CPU instruction demand by a newly added feature whose global in",
    "start": "1153350",
    "end": "1159840"
  },
  {
    "text": "fact may not be very easily seen from the previous graph because it's still to",
    "start": "1159840",
    "end": "1166140"
  },
  {
    "text": "a very small audience but its impact is amplified with this metadata and we'll",
    "start": "1166140",
    "end": "1172080"
  },
  {
    "text": "have with having this data we we add this information right next to the UI where the feature is configured so when",
    "start": "1172080",
    "end": "1179490"
  },
  {
    "text": "the even if the feature is rolled out to 1% or less",
    "start": "1179490",
    "end": "1185039"
  },
  {
    "text": "this graph shows 1/8 more than 8% CPU increase if the feature was rolled out",
    "start": "1185039",
    "end": "1190770"
  },
  {
    "text": "to a hundred percent so this gives the developer plenty time to address the regression because",
    "start": "1190770",
    "end": "1196970"
  },
  {
    "text": "the report becomes a real problem this way would make the performance part of the development cycle rather than and",
    "start": "1196970",
    "end": "1203440"
  },
  {
    "text": "afterthought but we still get you know",
    "start": "1203440",
    "end": "1209030"
  },
  {
    "text": "innocent look some developers who say hey you know my div is only one log one line of log change you know can't",
    "start": "1209030",
    "end": "1214940"
  },
  {
    "text": "possibly be causing 20% CPOE instruction for a particular end point so now it's",
    "start": "1214940",
    "end": "1220700"
  },
  {
    "text": "time to develop some tools to deep dive into the code base for that we use a",
    "start": "1220700",
    "end": "1226940"
  },
  {
    "start": "1225000",
    "end": "1368000"
  },
  {
    "text": "Python C profile C profile provides performance to fix-it function level",
    "start": "1226940",
    "end": "1232730"
  },
  {
    "text": "with Co graph information very much like how Linux perf works the resulting data",
    "start": "1232730",
    "end": "1240410"
  },
  {
    "text": "can be pre post processed and rendered with G prof 2 dot which is an open source tool using this you can look at",
    "start": "1240410",
    "end": "1248090"
  },
  {
    "text": "the function and see its overall impact on your code path the color Collier relationship and is to help you focus on",
    "start": "1248090",
    "end": "1254930"
  },
  {
    "text": "where you really want to spend your effort in optimizing in the past we",
    "start": "1254930",
    "end": "1261500"
  },
  {
    "text": "already have this right this is all open source well some of our engineers have",
    "start": "1261500",
    "end": "1267490"
  },
  {
    "text": "you know use these tools to to dive into specific performance problems but the",
    "start": "1267490",
    "end": "1272900"
  },
  {
    "text": "cost of this C profiling is pretty high and the process of enabling disabling is",
    "start": "1272900",
    "end": "1278390"
  },
  {
    "text": "manual and the prospect of messin with a production server to collect this data",
    "start": "1278390",
    "end": "1284390"
  },
  {
    "text": "is pretty scary for most developers as our development team grows this is this",
    "start": "1284390",
    "end": "1291410"
  },
  {
    "text": "did not scale so we needed to make the performance data readily available for",
    "start": "1291410",
    "end": "1297170"
  },
  {
    "text": "more developers to access so we instrumented C profile collection in our",
    "start": "1297170",
    "end": "1304610"
  },
  {
    "text": "production server continuously it is a conscious trade-off between cost of",
    "start": "1304610",
    "end": "1311300"
  },
  {
    "text": "collecting this data and the visibility we would gain into our code base with",
    "start": "1311300",
    "end": "1318470"
  },
  {
    "text": "this instrumentation at anytime our engineers can just run one command line and generate a call graph like what we",
    "start": "1318470",
    "end": "1325160"
  },
  {
    "text": "saw before and it greatly improved their product productivity when debugging performance",
    "start": "1325160",
    "end": "1332270"
  },
  {
    "text": "issues while snapshot was great when looking at the overall picture but it",
    "start": "1332270",
    "end": "1338420"
  },
  {
    "text": "doesn't help a great deal when you look at regression so we also put this data",
    "start": "1338420",
    "end": "1343490"
  },
  {
    "text": "in a time series format so if a caller is making multiple cost to other",
    "start": "1343490",
    "end": "1350450"
  },
  {
    "text": "functions but you see matching regression in the CPU instruction you",
    "start": "1350450",
    "end": "1355700"
  },
  {
    "text": "can be pretty sure that in fact that 20% of regression is caused by the one-line",
    "start": "1355700",
    "end": "1361910"
  },
  {
    "text": "change of logging so it's time to spend some effort on that we see profile",
    "start": "1361910",
    "end": "1369380"
  },
  {
    "start": "1368000",
    "end": "1388000"
  },
  {
    "text": "running everywhere we also integrated this data into code routing that shows how many servers",
    "start": "1369380",
    "end": "1375860"
  },
  {
    "text": "would be needed just to run that function this is a great reminder for anybody who's looking at our code the",
    "start": "1375860",
    "end": "1383080"
  },
  {
    "text": "optimization opportunities so now let's",
    "start": "1383080",
    "end": "1389000"
  },
  {
    "text": "take a look at some of the optimization was done with all the visibility we have",
    "start": "1389000",
    "end": "1394250"
  },
  {
    "text": "in the code base here's one example when you load up the Instagram feed",
    "start": "1394250",
    "end": "1402200"
  },
  {
    "text": "we the server's return on number of URLs to the clients with each URL is the C",
    "start": "1402200",
    "end": "1409610"
  },
  {
    "text": "CDN where the client needs to go retrieve the media this year our",
    "start": "1409610",
    "end": "1416570"
  },
  {
    "text": "generation is based on the media as well as the user where the user is from so we",
    "start": "1416570",
    "end": "1422360"
  },
  {
    "text": "can generate the most optimal CDN location for the user as we started to",
    "start": "1422360",
    "end": "1428720"
  },
  {
    "text": "support a variety of mobile devices with varying capabilities there was need to",
    "start": "1428720",
    "end": "1433760"
  },
  {
    "text": "generate multiple of these URLs so the devices can choose what's the best user experience they could serve depending on",
    "start": "1433760",
    "end": "1440930"
  },
  {
    "text": "network condition the particular device the user has so we started to give",
    "start": "1440930",
    "end": "1448030"
  },
  {
    "text": "multiple URLs to the mobile devices the only difference though is really the",
    "start": "1448030",
    "end": "1455840"
  },
  {
    "text": "size of the media but as we were implementing this feature",
    "start": "1455840",
    "end": "1460990"
  },
  {
    "text": "we were calling the generation of the URL function four times rather than once",
    "start": "1460990",
    "end": "1467170"
  },
  {
    "text": "and with just different varying sizes with the help of C profile we understand",
    "start": "1467170",
    "end": "1473650"
  },
  {
    "text": "this is what's happening so the first thing to do is less instead of",
    "start": "1473650",
    "end": "1481120"
  },
  {
    "text": "generating calling this function four times we call it once and simply overwrite the site function this is one",
    "start": "1481120",
    "end": "1488980"
  },
  {
    "text": "simple example but we have new more such examples with the visibility into the",
    "start": "1488980",
    "end": "1495610"
  },
  {
    "text": "code base we know exactly what is happening and we were able to do a lot of these optimizations very quickly but",
    "start": "1495610",
    "end": "1504160"
  },
  {
    "text": "you might also ask okay if the URL generation is so costly how about we",
    "start": "1504160",
    "end": "1509530"
  },
  {
    "text": "make it less costly and you will be right so another major theme of optimal",
    "start": "1509530",
    "end": "1515860"
  },
  {
    "text": "optimization opportunity was that we identify a number of functions that are",
    "start": "1515860",
    "end": "1523000"
  },
  {
    "text": "excused extensively that are pretty stable there is not a whole lot of",
    "start": "1523000",
    "end": "1528600"
  },
  {
    "text": "iteration on top of it and we cycle NIH's these functions or use C++",
    "start": "1528600",
    "end": "1534970"
  },
  {
    "text": "implementation to speed up the execution and we were able to gain significant CPU",
    "start": "1534970",
    "end": "1543250"
  },
  {
    "text": "instruction to reduce the CPU instruction needs on that front",
    "start": "1543250",
    "end": "1549570"
  },
  {
    "text": "so that's part of controlling demand well let's look at the second aspect of",
    "start": "1550770",
    "end": "1557800"
  },
  {
    "text": "scaling up given certain CPU demand how do we make each server execute more",
    "start": "1557800",
    "end": "1564600"
  },
  {
    "text": "ideally we want to all the multi cores on a server to be put to use and we do",
    "start": "1564600",
    "end": "1569860"
  },
  {
    "text": "that by running many worker processes in parallel that process user requests but",
    "start": "1569860",
    "end": "1576460"
  },
  {
    "text": "the number of processes is upper bounded by system memory a sticker how the",
    "start": "1576460",
    "end": "1582340"
  },
  {
    "start": "1580000",
    "end": "1617000"
  },
  {
    "text": "memory layout looks like we run n parallel processes where m is greater",
    "start": "1582340",
    "end": "1587440"
  },
  {
    "text": "than the number of CPU cores on the system each process has two parts of memory the",
    "start": "1587440",
    "end": "1593750"
  },
  {
    "text": "shared part in the private part total system memory is made of this one shared",
    "start": "1593750",
    "end": "1599750"
  },
  {
    "text": "memory and all the private memory added up together so Cal how can we reduce the",
    "start": "1599750",
    "end": "1605720"
  },
  {
    "text": "amount of memory requirement so we can run more processes upon analyzing the",
    "start": "1605720",
    "end": "1611750"
  },
  {
    "text": "memory configuration found that code itself is a big part of where our memory",
    "start": "1611750",
    "end": "1616760"
  },
  {
    "text": "went so the first things we did was to reduce the amount of code in memory we",
    "start": "1616760",
    "end": "1623840"
  },
  {
    "text": "started to run optimize which may be obvious but we were not running with - oh now docstrings is gone from from our",
    "start": "1623840",
    "end": "1631100"
  },
  {
    "text": "memory the second part is removed dead code we developed new features very",
    "start": "1631100",
    "end": "1638420"
  },
  {
    "text": "rapidly and there is a lot of legacy things that are not you know despite the",
    "start": "1638420",
    "end": "1643520"
  },
  {
    "text": "best efforts from developers there are going to be old code laying around so with C profile data we were able to",
    "start": "1643520",
    "end": "1650900"
  },
  {
    "text": "identify what are the code that's never gets executed in our code base and we were in the process of automating this",
    "start": "1650900",
    "end": "1657410"
  },
  {
    "text": "code removal process the second part is",
    "start": "1657410",
    "end": "1663410"
  },
  {
    "text": "if we could move some of the private memory into shared area where only one copy is needed then we would able to we",
    "start": "1663410",
    "end": "1671750"
  },
  {
    "text": "will be able to reduce the total memory needs since configuration data is the",
    "start": "1671750",
    "end": "1677960"
  },
  {
    "text": "same for all processes it makes sense to move them to shared memory so again this",
    "start": "1677960",
    "end": "1683570"
  },
  {
    "text": "is a bit of a trade-off you can see between you know if you put in the shared memory then the access to the",
    "start": "1683570",
    "end": "1690170"
  },
  {
    "text": "shared memory is going to be a bit more costly than if it's a private memory so",
    "start": "1690170",
    "end": "1695179"
  },
  {
    "text": "you need some kind of metric to to measure the the trade-off whether it makes sense for you to do that the",
    "start": "1695179",
    "end": "1702700"
  },
  {
    "text": "second part where we shared more is we actually disabled garbage collection for Python this helps to prevent some code",
    "start": "1702700",
    "end": "1711230"
  },
  {
    "text": "being moved to private part for GC purposes it's not super intuitive but so",
    "start": "1711230",
    "end": "1716570"
  },
  {
    "text": "we have a great blog post on this what we found and Python community is",
    "start": "1716570",
    "end": "1721850"
  },
  {
    "text": "actually looking into how it can make GC more effective without moving memory into private part",
    "start": "1721850",
    "end": "1729640"
  },
  {
    "text": "so with these memory changes we were able to actually get more than 20%",
    "start": "1729640",
    "end": "1735170"
  },
  {
    "text": "capacity increase because we increase the CD instruction that we could execute",
    "start": "1735170",
    "end": "1742340"
  },
  {
    "text": "on each server networks can also",
    "start": "1742340",
    "end": "1748820"
  },
  {
    "text": "negatively impact scale-up of a server our django processing model is",
    "start": "1748820",
    "end": "1754940"
  },
  {
    "text": "synchronous each process can only serve one request at a time so while it's wait",
    "start": "1754940",
    "end": "1761480"
  },
  {
    "text": "for external services to respond it can",
    "start": "1761480",
    "end": "1766600"
  },
  {
    "text": "cost servers duration and fewer CPU instructions that executed as our",
    "start": "1766600",
    "end": "1773450"
  },
  {
    "text": "application become more sophisticated we are depending more and more on these external services and this week becoming",
    "start": "1773450",
    "end": "1779450"
  },
  {
    "text": "a bigger problem one example is like this on our home",
    "start": "1779450",
    "end": "1787700"
  },
  {
    "text": "feed we now have stories feed and sometimes given suggested users on the",
    "start": "1787700",
    "end": "1793880"
  },
  {
    "text": "same screen this has greatly increased the latency for home feed retrieval",
    "start": "1793880",
    "end": "1799060"
  },
  {
    "text": "however we also found that these services are typically independent of each other so instead of sequentially",
    "start": "1799060",
    "end": "1805880"
  },
  {
    "text": "accessing these back-end services we explored using asynchronous i/o to",
    "start": "1805880",
    "end": "1811520"
  },
  {
    "text": "access them simultaneously and greatly reducing the latency for whole for the",
    "start": "1811520",
    "end": "1817130"
  },
  {
    "text": "for the this particular endpoint not only does it improve user experience it also helps to mitigate server starvation",
    "start": "1817130",
    "end": "1824900"
  },
  {
    "text": "problem and increase the capacity of the user so conclude by optimizing memory",
    "start": "1824900",
    "end": "1834380"
  },
  {
    "start": "1830000",
    "end": "1839000"
  },
  {
    "text": "and network access we were able to make each server serve more CPUs there still",
    "start": "1834380",
    "end": "1840980"
  },
  {
    "start": "1839000",
    "end": "1896000"
  },
  {
    "text": "work to do as well although Python and C++ were great they're not as a",
    "start": "1840980",
    "end": "1848620"
  },
  {
    "text": "debugging friendly as Python so we'd like to find a generic faster runtime",
    "start": "1848620",
    "end": "1855470"
  },
  {
    "text": "solution for Python using JIT for example keeping the ease of programming and debugging as well as the runtime",
    "start": "1855470",
    "end": "1862429"
  },
  {
    "text": "efficiency we're looking at asynchronous",
    "start": "1862429",
    "end": "1867770"
  },
  {
    "text": "web framework so that we can remove more of our dependency and in external",
    "start": "1867770",
    "end": "1875029"
  },
  {
    "text": "services and improve the resilience with newer Python version and better memory",
    "start": "1875029",
    "end": "1880789"
  },
  {
    "text": "analysis tool we also hope to gain more visibility into the memory utilization as we do with the CPU utilization so we",
    "start": "1880789",
    "end": "1887299"
  },
  {
    "text": "can further improve the memory of footprint and there are many other interesting opportunities that we're",
    "start": "1887299",
    "end": "1893720"
  },
  {
    "text": "going to as well last but not least getting the dev team so instagram has an",
    "start": "1893720",
    "end": "1904520"
  },
  {
    "start": "1896000",
    "end": "1959000"
  },
  {
    "text": "interesting combination of workforce we have about 250 engineers with 30 percent",
    "start": "1904520",
    "end": "1912080"
  },
  {
    "text": "of them joined in last six month we have interns throughout the year who should",
    "start": "1912080",
    "end": "1917990"
  },
  {
    "text": "numerous features with us in their three months working at Instagram we have hacker mentor from Facebook that",
    "start": "1917990",
    "end": "1925309"
  },
  {
    "text": "works with us for 44 weeks on specific projects and we have good campers who",
    "start": "1925309",
    "end": "1931700"
  },
  {
    "text": "sign up for Instagram tasks that gets done in two to two days to one week as",
    "start": "1931700",
    "end": "1938779"
  },
  {
    "text": "you can see their familiarity with our system and the ramp up time would vary",
    "start": "1938779",
    "end": "1944059"
  },
  {
    "text": "but not a lot but we're shipping features rapidly and each of these",
    "start": "1944059",
    "end": "1952279"
  },
  {
    "text": "features will require some data to be stored somewhere right so when a product engineer starts to work on a feature",
    "start": "1952279",
    "end": "1958460"
  },
  {
    "text": "your depressions that she needs to answer as you can see this is a pretty",
    "start": "1958460",
    "end": "1965779"
  },
  {
    "text": "heavy process that each small feature has to go through and we don't give",
    "start": "1965779",
    "end": "1971360"
  },
  {
    "text": "people a lot of rem-pod time like we said as the team grows and the MER features grow rapidly it is a big burden",
    "start": "1971360",
    "end": "1977809"
  },
  {
    "text": "on the infrastructure engineers to babysit this process and it's a slowdown for product engineers to deliver their",
    "start": "1977809",
    "end": "1984169"
  },
  {
    "text": "feature so what we really want is",
    "start": "1984169",
    "end": "1989770"
  },
  {
    "start": "1986000",
    "end": "2307000"
  },
  {
    "text": "an architecture that would automatically handle caching and that allows the",
    "start": "1989770",
    "end": "1995740"
  },
  {
    "text": "developers that define relations and not worry about detailed implementations it",
    "start": "1995740",
    "end": "2003419"
  },
  {
    "text": "should be self-serve by product engineers and the infrastructure engineers will just worry about scaling",
    "start": "2003419",
    "end": "2008730"
  },
  {
    "text": "this service turns out we have this infrastructure at Facebook Tao",
    "start": "2008730",
    "end": "2016250"
  },
  {
    "text": "it's basically data based plus right through cache it still uses a relational",
    "start": "2016250",
    "end": "2022740"
  },
  {
    "text": "database my sequel at the back and storage devices but it allows only very simplified data model basically the",
    "start": "2022740",
    "end": "2032730"
  },
  {
    "text": "nodes with objects and the edges with relationships it may not be the most",
    "start": "2032730",
    "end": "2038789"
  },
  {
    "text": "efficient as we used to have with in terms of you know how you store the data or you can't make direct sophisticated",
    "start": "2038789",
    "end": "2045899"
  },
  {
    "text": "queries in the database itself but it does the most basic things at very large",
    "start": "2045899",
    "end": "2051450"
  },
  {
    "text": "scale and this simplify data model allowed engineers to ship new features at a much faster speed without breaking",
    "start": "2051450",
    "end": "2058589"
  },
  {
    "text": "things this is just one of the examples will continue to develop better data",
    "start": "2058589",
    "end": "2064560"
  },
  {
    "text": "modeling and API to increase developer velocity so where are these features",
    "start": "2064560",
    "end": "2071520"
  },
  {
    "text": "getting developed a typical source control at some companies with complex",
    "start": "2071520",
    "end": "2077490"
  },
  {
    "text": "features will probably look like this like master will continue to contain incremental changes with smaller",
    "start": "2077490",
    "end": "2084690"
  },
  {
    "text": "features perhaps but branches are created to develop larger features such",
    "start": "2084690",
    "end": "2090658"
  },
  {
    "text": "as narcos live or direct messaging the problem with having the branches is that",
    "start": "2090659",
    "end": "2098910"
  },
  {
    "text": "engineers need to be mindful of the codebase they're working with and do",
    "start": "2098910",
    "end": "2104010"
  },
  {
    "text": "mental contact switching there's French management overhead surprises will arise",
    "start": "2104010",
    "end": "2112200"
  },
  {
    "text": "when different teams work on different branches with overlapping codebase it",
    "start": "2112200",
    "end": "2117839"
  },
  {
    "text": "makes it harder to do major upgrade or refactoring like the data model simplification that we",
    "start": "2117839",
    "end": "2123640"
  },
  {
    "text": "we show before performance data would be discovered much later in the development",
    "start": "2123640",
    "end": "2130329"
  },
  {
    "text": "cycle and will be much harder to fix so instead of branch management model for",
    "start": "2130329",
    "end": "2136630"
  },
  {
    "text": "various features we adopted the webmaster approach with no branches",
    "start": "2136630",
    "end": "2143650"
  },
  {
    "text": "every diff needs to be to keep master working so it's a continuous integration process engineers can collaborate much",
    "start": "2143650",
    "end": "2152559"
  },
  {
    "text": "more easily they don't have to think which which repo or which branch of a",
    "start": "2152559",
    "end": "2157750"
  },
  {
    "text": "particular feature is being developed on it's much easier to bisect problems and",
    "start": "2157750",
    "end": "2164880"
  },
  {
    "text": "revert tips when necessary and we can continue to monitor performance for all",
    "start": "2164880",
    "end": "2172720"
  },
  {
    "text": "features at the same time with pretty minimum overhead but if every feature is",
    "start": "2172720",
    "end": "2179020"
  },
  {
    "text": "being worked on in master how do we shift the code so we use gates to",
    "start": "2179020",
    "end": "2186280"
  },
  {
    "text": "control who will be exposed to new features typically at the beginning only",
    "start": "2186280",
    "end": "2191470"
  },
  {
    "text": "a few collaborators in engineering would be seeing the feature the DA footers",
    "start": "2191470",
    "end": "2196900"
  },
  {
    "text": "will test the future still under active development giving feedback so that the engineers can iterate on it and then",
    "start": "2196900",
    "end": "2205569"
  },
  {
    "text": "employees are the next victims before we develop this to the world",
    "start": "2205569",
    "end": "2211859"
  },
  {
    "text": "with this model we know the feature works but we don't know if it will still work when 400 million people start to",
    "start": "2211859",
    "end": "2219069"
  },
  {
    "text": "use it the next day sometimes between employee and the world you know it takes one day to one week time so we don't",
    "start": "2219069",
    "end": "2228490"
  },
  {
    "text": "know whether the database can support the increase week right RPS we don't know whether jungle has this much CPU",
    "start": "2228490",
    "end": "2233950"
  },
  {
    "text": "capacity and you know whether the network has will become a bottleneck so",
    "start": "2233950",
    "end": "2239380"
  },
  {
    "text": "what we also do is a load test we make up artificial load that are some are",
    "start": "2239380",
    "end": "2246670"
  },
  {
    "text": "triggered by user requests we would make assumptions about you know how many users will be using this feature what",
    "start": "2246670",
    "end": "2253150"
  },
  {
    "text": "type of load they would be generating and we would exercise the backend infrastructure in this",
    "start": "2253150",
    "end": "2258380"
  },
  {
    "text": "process this helped us to prepare back and capacity to ensure a smooth launch",
    "start": "2258380",
    "end": "2264950"
  },
  {
    "text": "of a new feature so we're ready to launch",
    "start": "2264950",
    "end": "2270410"
  },
  {
    "text": "we need a release branch right let's see how often do we ship the code once we do",
    "start": "2270410",
    "end": "2281479"
  },
  {
    "text": "what do people think once a day however",
    "start": "2281479",
    "end": "2286519"
  },
  {
    "text": "once a day so we continuously roll out our master repo whenever a diff is",
    "start": "2286519",
    "end": "2293509"
  },
  {
    "text": "checked in this result in about forty to forty roll-off a day a typical commit will go out within an",
    "start": "2293509",
    "end": "2303019"
  },
  {
    "text": "hour of landing a master how do we make",
    "start": "2303019",
    "end": "2308539"
  },
  {
    "text": "sure it doesn't all break loose right so code review unit test is very very",
    "start": "2308539",
    "end": "2314869"
  },
  {
    "text": "important we're not perfect at unit testing but we do our best most in one of our major",
    "start": "2314869",
    "end": "2321349"
  },
  {
    "text": "recent upgrades using tests was a you know a great help in capturing majority",
    "start": "2321349",
    "end": "2329719"
  },
  {
    "text": "of our use cases and then we were able to bring up the service right away once",
    "start": "2329719",
    "end": "2336529"
  },
  {
    "start": "2335000",
    "end": "2346000"
  },
  {
    "text": "code is committed it does another set of unit tests because you know you know the",
    "start": "2336529",
    "end": "2342049"
  },
  {
    "text": "diff on top of diff may not work the next is production canary before the",
    "start": "2342049",
    "end": "2350450"
  },
  {
    "start": "2346000",
    "end": "2385000"
  },
  {
    "text": "code is rolled up to the whole production tier we actually run it on a few of you production servers and",
    "start": "2350450",
    "end": "2356690"
  },
  {
    "text": "compare the exception rates and five hundred two hundred raised with a the",
    "start": "2356690",
    "end": "2364279"
  },
  {
    "text": "controls here and if this is a canary here is generating a higher than",
    "start": "2364279",
    "end": "2370910"
  },
  {
    "text": "threshold failure then we would stop rolling this out to the world and",
    "start": "2370910",
    "end": "2377019"
  },
  {
    "text": "finally we roll it but even despite this you know a lot of tooling and canary we",
    "start": "2377019",
    "end": "2385460"
  },
  {
    "start": "2385000",
    "end": "2403000"
  },
  {
    "text": "still might have problems in production so extend is monitoring and alerting system helps",
    "start": "2385460",
    "end": "2393220"
  },
  {
    "text": "us to discover problems fast and sometimes we do need to revert ok to",
    "start": "2393220",
    "end": "2404590"
  },
  {
    "start": "2403000",
    "end": "2475000"
  },
  {
    "text": "wrap it up we have covered three dimensions of scaling instagram scaling out use more Hardware scaling up use",
    "start": "2404590",
    "end": "2412150"
  },
  {
    "text": "less hardware and scale the dev team for velocity and productivity neuron uncle",
    "start": "2412150",
    "end": "2420490"
  },
  {
    "text": "experience is a little bit different now but it's not all rosy scheming is",
    "start": "2420490",
    "end": "2426520"
  },
  {
    "text": "continuous effort right there's no one endpoint with where we say we're done as",
    "start": "2426520",
    "end": "2431860"
  },
  {
    "text": "you can see from my previous slides on the challenges and opportunities we continue to tackle interesting scaling",
    "start": "2431860",
    "end": "2438880"
  },
  {
    "text": "problems at the next level scaling is multi-dimensional you want to look at different angles and makes your server",
    "start": "2438880",
    "end": "2445720"
  },
  {
    "text": "so count and skating is everybody's responsibility not just infrastructure and efficiency team we're not the police",
    "start": "2445720",
    "end": "2453490"
  },
  {
    "text": "or forwards and neighbors right I think in some I've got questions before you",
    "start": "2453490",
    "end": "2459730"
  },
  {
    "text": "know how do you make the rest of the team be more efficiency driven I think",
    "start": "2459730",
    "end": "2464950"
  },
  {
    "text": "you know the deep belief in helping each other is is really making a difference",
    "start": "2464950",
    "end": "2471850"
  },
  {
    "text": "here so questions",
    "start": "2471850",
    "end": "2478860"
  },
  {
    "start": "2475000",
    "end": "2496000"
  },
  {
    "text": "okay thank you very much so we have ten minutes for questions people have any",
    "start": "2480130",
    "end": "2487089"
  },
  {
    "start": "2496000",
    "end": "2609000"
  },
  {
    "text": "sorry I'm just curious could you tell us a little bit about where you do your future load testing is it actually done",
    "start": "2497230",
    "end": "2503420"
  },
  {
    "text": "in a production environment or non production thank you",
    "start": "2503420",
    "end": "2508330"
  },
  {
    "text": "future developments does go to a production except it's gated and it's not exposed to the user is that your",
    "start": "2508820",
    "end": "2518180"
  },
  {
    "text": "question load testing it's done in production hi thanks for the talk with",
    "start": "2518180",
    "end": "2531650"
  },
  {
    "text": "this volume of distributing continuous deployment how did you convert the acceptance test you know the canary do",
    "start": "2531650",
    "end": "2539599"
  },
  {
    "text": "you have a kind of really the ultimate ition so we measure the rate of 500",
    "start": "2539599",
    "end": "2547849"
  },
  {
    "text": "versus 200 errors and it's just one example we have a number of metric both",
    "start": "2547849",
    "end": "2553339"
  },
  {
    "text": "in terms of the error rate exception rate in some cases even the CPU utilization the requests to the back end",
    "start": "2553339",
    "end": "2560480"
  },
  {
    "text": "if you have if your dev is generating a ton more reply to the back end than your control system it could still be an",
    "start": "2560480",
    "end": "2568130"
  },
  {
    "text": "indication of a bad gift and in this",
    "start": "2568130",
    "end": "2573140"
  },
  {
    "text": "case the text is no longer too much and you know all this talk they cut our for",
    "start": "2573140",
    "end": "2580670"
  },
  {
    "text": "every how long with the canary yes it's not long it's a couple minutes with each",
    "start": "2580670",
    "end": "2587990"
  },
  {
    "text": "other over you know they do serve quite a bit of traffic in here we have we have",
    "start": "2587990",
    "end": "2594320"
  },
  {
    "text": "the trade-off between the time we chased the canary the diff and and how we roll out the code fast",
    "start": "2594320",
    "end": "2599990"
  },
  {
    "text": "the faster you roll out the code the more you can roll out to the the easier it is be able to identify which ative is",
    "start": "2599990",
    "end": "2606020"
  },
  {
    "text": "actually causing the problem I think it excuse me are there any downsides to",
    "start": "2606020",
    "end": "2612540"
  },
  {
    "start": "2609000",
    "end": "2661000"
  },
  {
    "text": "working on master and how do you effectively get the features as well",
    "start": "2612540",
    "end": "2618320"
  },
  {
    "text": "I'm sorry coach sorry yeah there any downsides to all the developers working on master and how do they sort of gave",
    "start": "2618320",
    "end": "2626310"
  },
  {
    "text": "their features within that single branch [Music]",
    "start": "2626310",
    "end": "2631370"
  },
  {
    "text": "I'm not sure we have seen many downsides in terms of gating there is a risk where",
    "start": "2631370",
    "end": "2640920"
  },
  {
    "text": "you know if you miss configure the future could be prematurely exposed to the world and it has happened",
    "start": "2640920",
    "end": "2647820"
  },
  {
    "text": "unfortunately so but what it happens we",
    "start": "2647820",
    "end": "2652980"
  },
  {
    "text": "develop more better tools we also canary the gates as well yeah thank you hi so",
    "start": "2652980",
    "end": "2663540"
  },
  {
    "start": "2661000",
    "end": "2698000"
  },
  {
    "text": "you're deploying into your live environment forty to sixty times per day so how long",
    "start": "2663540",
    "end": "2669570"
  },
  {
    "text": "does it take to roll out a new version to all our live servers do you mean",
    "start": "2669570",
    "end": "2676830"
  },
  {
    "text": "between commits and roll out I know if you're just saying okay now deploy to all the servers I don't have a tape oh",
    "start": "2676830",
    "end": "2682980"
  },
  {
    "text": "how long does it say ok 10 minutes yeah",
    "start": "2682980",
    "end": "2688490"
  },
  {
    "text": "how many servers does it about over 20,000 ok thanks all right I was just",
    "start": "2688490",
    "end": "2700350"
  },
  {
    "start": "2698000",
    "end": "2874000"
  },
  {
    "text": "wondering could you talk a little bit about your training culture and how you bring on your new young engineers you",
    "start": "2700350",
    "end": "2705870"
  },
  {
    "text": "you mentioned that there was quite a few news characters in the last six months",
    "start": "2705870",
    "end": "2711950"
  },
  {
    "text": "sorry I didn't quite get the question yeah I was just wondering what the training culture is like is it just",
    "start": "2712040",
    "end": "2717090"
  },
  {
    "text": "learn on the job with the training I track training culture so Facebook",
    "start": "2717090",
    "end": "2723690"
  },
  {
    "text": "engineers typically go through boot camp so there we we have training on basic",
    "start": "2723690",
    "end": "2729420"
  },
  {
    "text": "Facebook infrastructure software pieces and deployments and things like that",
    "start": "2729420",
    "end": "2734940"
  },
  {
    "text": "instagram has its own bootcamp forces so and then it's basically the park the",
    "start": "2734940",
    "end": "2742950"
  },
  {
    "text": "point of contact for specific tasks those are boot campers for for hacker",
    "start": "2742950",
    "end": "2748569"
  },
  {
    "text": "members you know who people who have already worked at Facebook Instagram for a while then it's a lot easier to",
    "start": "2748569",
    "end": "2755109"
  },
  {
    "text": "understand the rest of the architecture interns you know obviously have longer",
    "start": "2755109",
    "end": "2760599"
  },
  {
    "text": "time so they typically have their mentors working closely with them that helped a lot",
    "start": "2760599",
    "end": "2766089"
  },
  {
    "text": "I had a cushion so the database wrote",
    "start": "2766089",
    "end": "2774190"
  },
  {
    "text": "like a database in data center to you need to it has an issue the master you have to promote yes how quick is that we",
    "start": "2774190",
    "end": "2782980"
  },
  {
    "text": "were able to promote a slave in so when we were still managing progress now we",
    "start": "2782980",
    "end": "2789940"
  },
  {
    "text": "say from the last slides we don't anymore we we do not do automatic master",
    "start": "2789940",
    "end": "2796960"
  },
  {
    "text": "slave promotion so once we detect a master going down and we promote a slave",
    "start": "2796960",
    "end": "2802630"
  },
  {
    "text": "then it takes a lesson to manage to promote so during your data center like",
    "start": "2802630",
    "end": "2809140"
  },
  {
    "text": "where they do the storms it's sort of fake right because do they alert yeah",
    "start": "2809140",
    "end": "2814269"
  },
  {
    "text": "people that sell yes we don't do we don't do real cutoff we do promote",
    "start": "2814269",
    "end": "2819519"
  },
  {
    "text": "servers before we come off yes and what do you do now is just pure Cassandra so",
    "start": "2819519",
    "end": "2825730"
  },
  {
    "text": "we we use Tao which is also a relational",
    "start": "2825730",
    "end": "2831099"
  },
  {
    "text": "database so again it's like you say it's not a real cut off without warning so",
    "start": "2831099",
    "end": "2837970"
  },
  {
    "text": "you have masters with massive right failures and things like that that doesn't happen and yeah we do have it",
    "start": "2837970",
    "end": "2845619"
  },
  {
    "text": "also Cassandra replicas and we need to prepare for the storm you know obviously we in a real disaster",
    "start": "2845619",
    "end": "2853079"
  },
  {
    "text": "people would be more forgiving if there are more massive right failures but in a",
    "start": "2853079",
    "end": "2861220"
  },
  {
    "text": "normal case we don't want to impact the user experience on a regular basis right so but other than the database is almost",
    "start": "2861220",
    "end": "2867849"
  },
  {
    "text": "everything else is is automatic train I had one more question",
    "start": "2867849",
    "end": "2875490"
  },
  {
    "start": "2874000",
    "end": "2902000"
  },
  {
    "text": "unless someone else are we have the computations can you just because you're",
    "start": "2875490",
    "end": "2880830"
  },
  {
    "text": "doing like basically picture conversions right for that's what taking the CPU most of the time are yeah can you just",
    "start": "2880830",
    "end": "2887580"
  },
  {
    "text": "delay it like let's see I upload a photo and your CPUs are bound can you just delay that computation so",
    "start": "2887580",
    "end": "2893850"
  },
  {
    "text": "that my readers so the computation is not done upload time it's actually done by a tweet time",
    "start": "2893850",
    "end": "2901190"
  },
  {
    "text": "any other questions okay oh hi I'm",
    "start": "2901190",
    "end": "2911400"
  },
  {
    "start": "2902000",
    "end": "2984000"
  },
  {
    "text": "wondering in the very long term is Instagram considering biting the bullet and converting its backends to use the",
    "start": "2911400",
    "end": "2917340"
  },
  {
    "text": "same way as Facebook to eat duplicate you know is infrastructure work and all that stuff Jimmy in Python versus PHP",
    "start": "2917340",
    "end": "2924000"
  },
  {
    "text": "yes so you see HP hack yeah so right now we don't have much incentive to do that",
    "start": "2924000",
    "end": "2930120"
  },
  {
    "text": "we have a lot of business logic built into the codebase most of the back-end access for example accessing Tao is",
    "start": "2930120",
    "end": "2937200"
  },
  {
    "text": "already in C++ that is used by both PHP and Python so yeah so right now we don't",
    "start": "2937200",
    "end": "2945120"
  },
  {
    "text": "have and using thrips you can use any access back-end services you can use",
    "start": "2945120",
    "end": "2951030"
  },
  {
    "text": "Python or PHP doesn't really matter performance wise we are looking we have",
    "start": "2951030",
    "end": "2958920"
  },
  {
    "text": "just converted to Python 3 which gained us quite a few percentage of performance",
    "start": "2958920",
    "end": "2964410"
  },
  {
    "text": "gain as Python is being active developed 3 6 verses 3-5 also has performance gain",
    "start": "2964410",
    "end": "2970410"
  },
  {
    "text": "we're also looking at as I was saying the runtime JIT optimisation that that",
    "start": "2970410",
    "end": "2978210"
  },
  {
    "text": "hopefully could give us more CPU efficiency thank you I do actually also",
    "start": "2978210",
    "end": "2986670"
  },
  {
    "start": "2984000",
    "end": "3071000"
  },
  {
    "text": "have a question a part of it you already answered you're using Python 3 the I was",
    "start": "2986670",
    "end": "2993390"
  },
  {
    "text": "also curious about you used to just siphon as you use it do you implement",
    "start": "2993390",
    "end": "3000280"
  },
  {
    "text": "because you mentioned you also use c and c++ do you actually implement stuff in C C++ or B you size into interface to",
    "start": "3000280",
    "end": "3007960"
  },
  {
    "text": "existing libraries and if you if you write new C surface was covered in your",
    "start": "3007960",
    "end": "3014710"
  },
  {
    "text": "experience be the performance difference between plain C C++ and like them we use",
    "start": "3014710",
    "end": "3022180"
  },
  {
    "text": "both actually so it is especially for the code that is shared to access",
    "start": "3022180",
    "end": "3028540"
  },
  {
    "text": "back-end by both the Facebook's content and our back our front-end we use C++ because",
    "start": "3028540",
    "end": "3035050"
  },
  {
    "text": "that will go for both but in many libraries that we use in Python itself",
    "start": "3035050",
    "end": "3040420"
  },
  {
    "text": "we use Python 2 to do it directly without using C++ in terms of",
    "start": "3040420",
    "end": "3046660"
  },
  {
    "text": "performance I am Not sure I can now give you a number I don't think we have actually done like Apple to cap Apple",
    "start": "3046660",
    "end": "3054130"
  },
  {
    "text": "comparison with the same module being implemented in C++ where to find them ok great things I in my experiences it's",
    "start": "3054130",
    "end": "3061540"
  },
  {
    "text": "about 2% what I phone ok thank you ok thank you very much",
    "start": "3061540",
    "end": "3068900"
  },
  {
    "text": "[Applause]",
    "start": "3068900",
    "end": "3072569"
  }
]
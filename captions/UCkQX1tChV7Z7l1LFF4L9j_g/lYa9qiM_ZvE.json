[
  {
    "text": "[Music]",
    "start": "3270",
    "end": "8730"
  },
  {
    "text": "okay um yeah it's going to I think I'm going to try and um elaborate our",
    "start": "10719",
    "end": "16480"
  },
  {
    "text": "journey on how to architect systems with large language models um let's just",
    "start": "16480",
    "end": "22920"
  },
  {
    "text": "examine the timeline a bit right so we seen a whole lot of discussions around",
    "start": "22920",
    "end": "28840"
  },
  {
    "text": "large language model um in the past year a little bit uh before that but it's not",
    "start": "28840",
    "end": "35360"
  },
  {
    "text": "a miracle that large language models happened right so it's been a lot of work that's been going on that's building on top of it um the thing that",
    "start": "35360",
    "end": "42760"
  },
  {
    "text": "you see with Chad GPT and Gemini and the likes is the models are just way way way",
    "start": "42760",
    "end": "48239"
  },
  {
    "text": "bigger and they have a lot of data that's been fed to them and hence they do what they do which is",
    "start": "48239",
    "end": "55600"
  },
  {
    "text": "amazing um November 2022 um di had come out a few months before",
    "start": "55600",
    "end": "62879"
  },
  {
    "text": "that and then Chad GPT got released there was a lot of Buzz and uh we thought it was going to it's hype right",
    "start": "62879",
    "end": "69280"
  },
  {
    "text": "it was also a time where we saw the tech industry going through ups and downs and we just said okay this is hype it's it's",
    "start": "69280",
    "end": "75960"
  },
  {
    "text": "not going to last this to Shell pass and we go back to our normal lives February 2023 there was a lot of",
    "start": "75960",
    "end": "84439"
  },
  {
    "text": "uh Buzz in the market because uh people were wondering if the tech Giants are",
    "start": "84439",
    "end": "89920"
  },
  {
    "text": "are going to run away again with uh monopolizing AI U to only realize well",
    "start": "89920",
    "end": "95479"
  },
  {
    "text": "meta had different plans and if you've been to iness talk yesterday about how",
    "start": "95479",
    "end": "100759"
  },
  {
    "text": "big Tech will not monopolize AI right now I think it's some it's a big it's a wave that we all witnessing so open",
    "start": "100759",
    "end": "107439"
  },
  {
    "text": "source took over and we started seeing some really interesting adaptations of uh large language models and fine tuning",
    "start": "107439",
    "end": "114479"
  },
  {
    "text": "on on llama um and we sat there as an organization and we said okay it's probably the of PC's and we might have",
    "start": "114479",
    "end": "121680"
  },
  {
    "text": "to do something here ourselves now 2023 December we thought",
    "start": "121680",
    "end": "127399"
  },
  {
    "text": "okay is this a hype this is going to continue but we see that the revenue of companies are starting to go up open aai",
    "start": "127399",
    "end": "135560"
  },
  {
    "text": "Grew From 200 million to 1.6 billion nvidia's Market uh Revenue reached 18.1",
    "start": "135560",
    "end": "142879"
  },
  {
    "text": "and I think their market cap is bigger than ever uh everyone's using chat GPT",
    "start": "142879",
    "end": "148239"
  },
  {
    "text": "and Gemini for their work every body in the organization be it Marketing sales everyone's making use of these tools",
    "start": "148239",
    "end": "155319"
  },
  {
    "text": "deep fake started to become a thing uh to a point where uh there's a financial",
    "start": "155319",
    "end": "160640"
  },
  {
    "text": "uh worker who lost 25 million because he thought he got a message from his boss and he just signed off on a $25 million",
    "start": "160640",
    "end": "168280"
  },
  {
    "text": "uh check um and we are all sitting here and we being tasked to bring this AI",
    "start": "168280",
    "end": "173440"
  },
  {
    "text": "into our organizations and we're wondering okay what do we do so 2024 and",
    "start": "173440",
    "end": "179519"
  },
  {
    "text": "Beyond on so um AI occupies the spotlight um and as I can see from everyone sitting here all of you are",
    "start": "179519",
    "end": "185959"
  },
  {
    "text": "interested in understanding how to enable this uh the Investments continue um you can see that Amazon starts to",
    "start": "185959",
    "end": "192200"
  },
  {
    "text": "invest in anthropic infliction AI is now part of Microsoft uh we had Jay from cohar here who's doing some incredible",
    "start": "192200",
    "end": "198159"
  },
  {
    "text": "stuff in that space um so we have to ask ourselves how can we build bring",
    "start": "198159",
    "end": "203959"
  },
  {
    "text": "something that is this powerful in a safe and a reliable way uh to our c",
    "start": "203959",
    "end": "209799"
  },
  {
    "text": "customers and also without losing speed to actually innovate Global AI Market's going to",
    "start": "209799",
    "end": "216439"
  },
  {
    "text": "grow um the speculation or the research says that it's going to grow to 1.8 trillion currently it's about uh close",
    "start": "216439",
    "end": "223920"
  },
  {
    "text": "to $200 billion um nine out of 10 organizations think that AI is going to give them",
    "start": "223920",
    "end": "229560"
  },
  {
    "text": "competitive advantage and around four and five companies think AI is their top",
    "start": "229560",
    "end": "235360"
  },
  {
    "text": "priority now this is what the landscape looks like um I'm not going to zoom I'm going to share the presentation so you",
    "start": "235360",
    "end": "241599"
  },
  {
    "text": "can so I don't think there's there's of course a little bit of hype but everybody is investing across the entire",
    "start": "241599",
    "end": "248720"
  },
  {
    "text": "landscape of machine learning uh Ai and and data now there's risks uh that come",
    "start": "248720",
    "end": "255680"
  },
  {
    "text": "along with it and organizations are thinking about it there are a lot of organizations that understand the risk",
    "start": "255680",
    "end": "261079"
  },
  {
    "text": "and are working towards it and there are organizations that have absolutely no idea how to go about working with this",
    "start": "261079",
    "end": "267919"
  },
  {
    "text": "risk so they just sitting there waiting for other organizations to implement and move",
    "start": "267919",
    "end": "273240"
  },
  {
    "text": "forward now people are building or rebuilding their engine rooms uh you can see that more than 60% of people are",
    "start": "273240",
    "end": "280639"
  },
  {
    "text": "running either poc's or they're already bringing this to widespread adoption uh",
    "start": "280639",
    "end": "285840"
  },
  {
    "text": "to their customers now we need to strike a balance and that's what the talk is going to be about today so there's a lot",
    "start": "285840",
    "end": "292160"
  },
  {
    "text": "of enthusiasm around uh AI um and the AI Revolution will be here to to stay it",
    "start": "292160",
    "end": "297400"
  },
  {
    "text": "will change everything that we do but deploying AI in production is quite",
    "start": "297400",
    "end": "303520"
  },
  {
    "text": "complex and it requires more than just thinking about it as a as a POC so how do we strike a balance and",
    "start": "303520",
    "end": "309840"
  },
  {
    "text": "I'm sure a lot of you who started thinking about llms came across this image of of Transformers and attention",
    "start": "309840",
    "end": "315600"
  },
  {
    "text": "is all you need but to be honest the AI landscape is changing every day so probably things I'm telling right now is",
    "start": "315600",
    "end": "321400"
  },
  {
    "text": "going to be outdated the moment I finish the talk uh but not everything requires your attention right so you don't have",
    "start": "321400",
    "end": "327120"
  },
  {
    "text": "to change every single day uh your entire stack and the goal is how can you build a stack that gives you the",
    "start": "327120",
    "end": "333520"
  },
  {
    "text": "flexibility to innovate and at the same time it's driving value for your customers now purpose of my talk today",
    "start": "333520",
    "end": "341039"
  },
  {
    "text": "right so everybody's talking about llms being awesome and today I'm going to talk about everything that can possibly",
    "start": "341039",
    "end": "347199"
  },
  {
    "text": "go wrong with llms and uh our journey through um the last 16 to 18 months and",
    "start": "347199",
    "end": "354039"
  },
  {
    "text": "how and what it takes for us or what it took for us to bring this into production and about the effort people",
    "start": "354039",
    "end": "360919"
  },
  {
    "text": "time money and also a few meltdowns uh that we had um and I'm going to be a bit opinionated",
    "start": "360919",
    "end": "368479"
  },
  {
    "text": "because this is some of the work that we've done um I I wanted I want you all to take this with a grain of salt",
    "start": "368479",
    "end": "374599"
  },
  {
    "text": "because it's probably other versions out there uh that you might have to take a look at in terms of how to do this um",
    "start": "374599",
    "end": "380680"
  },
  {
    "text": "and with that I'm nisel I'm the VP of data science and ml engineering at Scout B I'm based out of Berlin I've been in",
    "start": "380680",
    "end": "387120"
  },
  {
    "text": "the ml space for a little bit over 13 years and the last seven years uh it's mostly been in the insurance and the and",
    "start": "387120",
    "end": "392759"
  },
  {
    "text": "the supply chain space now this is the overview that we look at today so enabling llms in our",
    "start": "392759",
    "end": "399520"
  },
  {
    "text": "product improving the quality of conversation improving the quality and Trust in results improving the data",
    "start": "399520",
    "end": "406160"
  },
  {
    "text": "coverage and quality with ground through data and then summary and takeaways um I'll I'll go step by step and uh peel",
    "start": "406160",
    "end": "413919"
  },
  {
    "text": "the onion one layer at a time so case study right so I spend a",
    "start": "413919",
    "end": "419319"
  },
  {
    "text": "lot of time thinking about what I'm going to talk um today I thought I'll talk about some use case that everybody",
    "start": "419319",
    "end": "425440"
  },
  {
    "text": "of you can relate to but then I didn't find enough conviction because it's not a use case that I worked on so I thought",
    "start": "425440",
    "end": "431440"
  },
  {
    "text": "okay let's talk about what we actually did as a company right so we work in the supply chain space and we help",
    "start": "431440",
    "end": "438360"
  },
  {
    "text": "organizations such as Unilever Walmart um and organizations of that size to do",
    "start": "438360",
    "end": "444360"
  },
  {
    "text": "supplier Discovery now essentially what it is is a Google search for supplier",
    "start": "444360",
    "end": "449520"
  },
  {
    "text": "ERS but Google does not work for them because Google's not adapted to helping",
    "start": "449520",
    "end": "455720"
  },
  {
    "text": "them in the supply chain space and there's a lot more nuances to understanding and thinking about supply chain and I'm sure all of you have been",
    "start": "455720",
    "end": "463000"
  },
  {
    "text": "facing some disruptions all the way from getting gpus in your AWS data centers to",
    "start": "463000",
    "end": "468280"
  },
  {
    "text": "not finding toilet papers or pasta in your supermarkets when Co happen so supply chain has an impact on all of us",
    "start": "468280",
    "end": "475080"
  },
  {
    "text": "and every manufacturer is dependent on other manufacturers now the question is",
    "start": "475080",
    "end": "480479"
  },
  {
    "text": "they want to try and find manufacturers they can work with not just for handling disruptions but to also sort of mitigate",
    "start": "480479",
    "end": "488159"
  },
  {
    "text": "different kinds of risks and work with innovating manufacturers now the challenge that we",
    "start": "488159",
    "end": "493560"
  },
  {
    "text": "wanted to do was this is not a product that we brought into the market right now we've been sort of a market leader",
    "start": "493560",
    "end": "499000"
  },
  {
    "text": "for the past 6 seven years so we had different generations of this product and we've been using ml for quite some",
    "start": "499000",
    "end": "505520"
  },
  {
    "text": "time and we thought this would be a good way for us to bring large language models as a new generation of our",
    "start": "505520",
    "end": "512919"
  },
  {
    "text": "product now efficiency and Effectiveness right so why are llms being sought after",
    "start": "512919",
    "end": "518839"
  },
  {
    "text": "why are Enterprises rebuilding their engine room so efficiency is something that all of us have been working towards",
    "start": "518839",
    "end": "525160"
  },
  {
    "text": "irrespective of which domain we are in we want to make things faster we want to make things more economical and we want",
    "start": "525160",
    "end": "530480"
  },
  {
    "text": "to get people to be able to solve their tasks now the thing that we see with",
    "start": "530480",
    "end": "535839"
  },
  {
    "text": "with llms is it's a part of that which is efficiency but it's also part of Effectiveness",
    "start": "535839",
    "end": "541839"
  },
  {
    "text": "because it's now going to enable organizations or people working in the organizations to do things they could",
    "start": "541839",
    "end": "547640"
  },
  {
    "text": "not do before right and that would mean you ask a question or you come with a",
    "start": "547640",
    "end": "552880"
  },
  {
    "text": "problem statement rather than looking at static dashboards to tell you what you're supposed to do right and then",
    "start": "552880",
    "end": "558680"
  },
  {
    "text": "based on the question that you ask the llm along with your product figures out",
    "start": "558680",
    "end": "564000"
  },
  {
    "text": "what data to bring in and helps you solve that problem now we're going to try and see how we can argument",
    "start": "564000",
    "end": "570519"
  },
  {
    "text": "organizations to do this stage one right enabling llms in",
    "start": "570519",
    "end": "576880"
  },
  {
    "text": "our product so we did what every organization probably did or starts to",
    "start": "576880",
    "end": "583920"
  },
  {
    "text": "uh do right now is enable your application connected to chat jpt or one of these providers",
    "start": "583920",
    "end": "591360"
  },
  {
    "text": "through an API and essentially you're good to go right so you have an we did the API we",
    "start": "591360",
    "end": "598240"
  },
  {
    "text": "did some prompt engineering with Lang chain we connected it to chat gpt's apis this was I think January 2022 uh we put",
    "start": "598240",
    "end": "606200"
  },
  {
    "text": "some credits in there and we started using it so the stack on the right is something that we've had for a while",
    "start": "606200",
    "end": "611360"
  },
  {
    "text": "which is we were working largely with knowledge graphs we had smaller machine learning models back in the time they",
    "start": "611360",
    "end": "617320"
  },
  {
    "text": "were bigger but now they're comparatively way smaller and we did some distributed inferencing with spark",
    "start": "617320",
    "end": "623600"
  },
  {
    "text": "to populate these knowledge graphs now when we did this we we asked",
    "start": "623600",
    "end": "629640"
  },
  {
    "text": "ourselves well what could go wrong right because it's it was very fast for us toh to do this it didn't cost us a lot of",
    "start": "629640",
    "end": "636160"
  },
  {
    "text": "time and money and we asked ourselves okay let's let's see what our customers",
    "start": "636160",
    "end": "641560"
  },
  {
    "text": "think the one thing that stood out immediately was the lack of domain",
    "start": "641560",
    "end": "646760"
  },
  {
    "text": "knowledge right so the the foundational models did not know what supplier",
    "start": "646760",
    "end": "652079"
  },
  {
    "text": "Discovery was about and the conversations went haywire so people started asking questions related to",
    "start": "652079",
    "end": "657680"
  },
  {
    "text": "their domain and we had foundational models start to take them on a life",
    "start": "657680",
    "end": "663040"
  },
  {
    "text": "quest to answer questions that they wanted to ask about life so this is it became very chatty as well and people",
    "start": "663040",
    "end": "670079"
  },
  {
    "text": "were tired people used our application and went can we just bring the old form back like you know this is just so much",
    "start": "670079",
    "end": "676560"
  },
  {
    "text": "I don't want to have this conversation and we did see the results that were coming up were hallucinations it felt so",
    "start": "676560",
    "end": "683600"
  },
  {
    "text": "real that for a second when we were testing the system we looked at it and went okay is this really Like A supplier",
    "start": "683600",
    "end": "690160"
  },
  {
    "text": "did we not know about or a manufacturer and there were results that were being fabricated by the large language model",
    "start": "690160",
    "end": "697880"
  },
  {
    "text": "and the and the other part and I'm not sure how many of you are dealing with Enterprise security and privacy is a lot",
    "start": "697880",
    "end": "705680"
  },
  {
    "text": "of the customers that we worked with were a little bit on the edge when we said okay the POC is fine to use it with",
    "start": "705680",
    "end": "712320"
  },
  {
    "text": "somebody like Chad GPT or some of these providers but I don't think we want to do production workloads or work use this",
    "start": "712320",
    "end": "720000"
  },
  {
    "text": "product and production if it's integrated there because we're just concerned what they're going to use the data",
    "start": "720000",
    "end": "725760"
  },
  {
    "text": "for and we said okay so first F first right so we thought okay is there really",
    "start": "725760",
    "end": "731320"
  },
  {
    "text": "a market for us to bring llms to our product does our product really need llms and what we got us feedback from",
    "start": "731320",
    "end": "738079"
  },
  {
    "text": "the users was that they really enjoyed the experience they were excited to use more of the product and wanted more of",
    "start": "738079",
    "end": "744920"
  },
  {
    "text": "it so we realized okay there's a big market we've identified for our new generation of the product and there were",
    "start": "744920",
    "end": "752279"
  },
  {
    "text": "lots of things that we had to solve before we wanted to get there so first we had to focus on efficiency even",
    "start": "752279",
    "end": "758279"
  },
  {
    "text": "before Effectiveness we absolutely needed domain adaptation we had to remove hallucinations we had to build",
    "start": "758279",
    "end": "765600"
  },
  {
    "text": "trust and reliability we needed guard rails and we needed to be less a little",
    "start": "765600",
    "end": "770760"
  },
  {
    "text": "less chatty so this was the outcome of stage one right uh one of our users said okay",
    "start": "770760",
    "end": "778639"
  },
  {
    "text": "we have an issue with importing coffee due to the conflict in Su Canal we need to find sustainable fair market",
    "start": "778639",
    "end": "784639"
  },
  {
    "text": "certified coffee beans from South America and the foundational model replied company ABC from Brazil has the",
    "start": "784639",
    "end": "791519"
  },
  {
    "text": "best coffee ever coffee beans coffee is very good for health coffee beans can be roasted said okay cool yeah this is",
    "start": "791519",
    "end": "798600"
  },
  {
    "text": "awesome so let's uh this sounds nice but I don't think our customers will pay us",
    "start": "798600",
    "end": "803920"
  },
  {
    "text": "money to to to use this product now we said okay stay stage two",
    "start": "803920",
    "end": "810079"
  },
  {
    "text": "um the first thing we wanted to tackle was we didn't want to go ahead without knowing if we can actually host a large",
    "start": "810079",
    "end": "816880"
  },
  {
    "text": "language model ourselves because if we did all the development and then realized that privacy and uh data",
    "start": "816880",
    "end": "823160"
  },
  {
    "text": "privacy and security was a big concern all of our work would just go down the drain so the first thing that we did was",
    "start": "823160",
    "end": "830120"
  },
  {
    "text": "we we sort of brought in uh an open source llm so as you can see the stack",
    "start": "830120",
    "end": "836279"
  },
  {
    "text": "just got a little bit bigger so so we brought in uh Lama 13B which was uh",
    "start": "836279",
    "end": "843079"
  },
  {
    "text": "first dropped on a torrent somewhere and then finally made its way to to hugging",
    "start": "843079",
    "end": "848399"
  },
  {
    "text": "phase um we put an API on top of it called as fast chat API and we had an LL",
    "start": "848399",
    "end": "854320"
  },
  {
    "text": "API that we were working with um and we'll go through um so one thing that is also",
    "start": "854320",
    "end": "861880"
  },
  {
    "text": "very common is every even though large language models uh there are plenty of them right now you have to pick in",
    "start": "861880",
    "end": "869160"
  },
  {
    "text": "choose your large language models because the prompt engineering work that you do for language Model A will not fit",
    "start": "869160",
    "end": "875920"
  },
  {
    "text": "for language model B so all of the effort that you put in in doing this prompt engineering will have to change",
    "start": "875920",
    "end": "882800"
  },
  {
    "text": "the moment you change your large language model so we had to make some adaptations from uh CH gpt's uh prompts",
    "start": "882800",
    "end": "889440"
  },
  {
    "text": "to work with llama and the thing that we realized was our cost and complexity",
    "start": "889440",
    "end": "896800"
  },
  {
    "text": "just went up we were now responsible for a new piece of software in our stack um that we really didn't want to be but we",
    "start": "896800",
    "end": "903759"
  },
  {
    "text": "were we had to because of uh the domain that we Opera in and it was way way",
    "start": "903759",
    "end": "909120"
  },
  {
    "text": "expensive than using an API that you can work with um from any of these",
    "start": "909120",
    "end": "916279"
  },
  {
    "text": "providers domain adaptation right so this is one of the challenges that any",
    "start": "916279",
    "end": "921680"
  },
  {
    "text": "of you will probably face uh enabling this in your organization be it internal tooling or through your products is how",
    "start": "921680",
    "end": "929120"
  },
  {
    "text": "do you bring domain knowledge to large language models the first thinking that",
    "start": "929120",
    "end": "934680"
  },
  {
    "text": "goes in is okay how can it it can't be that crazy to sort of retrain or fine",
    "start": "934680",
    "end": "939959"
  },
  {
    "text": "tune or a large language model why can't we just build our own large language model right um just as a ballpack figure",
    "start": "939959",
    "end": "949079"
  },
  {
    "text": "uh with some of the secret statistics that was released around GPT 4 it took",
    "start": "949079",
    "end": "954639"
  },
  {
    "text": "open AI about $63 million to ship GP 4",
    "start": "954639",
    "end": "959880"
  },
  {
    "text": "and not to mention and that's not including the cost of people and infrastructure and and everything else",
    "start": "959880",
    "end": "967519"
  },
  {
    "text": "um and the API is about $30 for a million tokens so you can you can see",
    "start": "967519",
    "end": "972800"
  },
  {
    "text": "the big difference between using an API coming from these big houses to actually retraining uh a foundational model and",
    "start": "972800",
    "end": "980199"
  },
  {
    "text": "you need a lot of data to train a good foundational model but the good news is",
    "start": "980199",
    "end": "986880"
  },
  {
    "text": "that you can do domain adaptation without having having to retrain an entire model so there are different ways",
    "start": "986880",
    "end": "993560"
  },
  {
    "text": "you can do this there's uh zero shot learning in context learning and then you can do few shot learning and you can",
    "start": "993560",
    "end": "1000279"
  },
  {
    "text": "also build something called as agents um so what essentially an agent does is you",
    "start": "1000279",
    "end": "1006279"
  },
  {
    "text": "give it a set of instructions uh you give it some examples on how to deal with these instructions and you give it",
    "start": "1006279",
    "end": "1012279"
  },
  {
    "text": "the uh capability to make different requests to different system so imagine that if you if it were if if it were a",
    "start": "1012279",
    "end": "1019560"
  },
  {
    "text": "human and you give a human a task the human would essentially try to",
    "start": "1019560",
    "end": "1024959"
  },
  {
    "text": "understand the task pick the relevant data make queries to different systems summarize the answer and provide it for",
    "start": "1024959",
    "end": "1030640"
  },
  {
    "text": "you agents typically do that um and what",
    "start": "1030640",
    "end": "1036280"
  },
  {
    "text": "we tried to do was feed all of our domain knowledge into an agent and we",
    "start": "1036280",
    "end": "1041360"
  },
  {
    "text": "did some really heavy prompt engineering to enable this at a point where documentation around prompt engineering",
    "start": "1041360",
    "end": "1047760"
  },
  {
    "text": "was also a bit poor so we had quite a few meltdowns on uh on building this but",
    "start": "1047760",
    "end": "1053480"
  },
  {
    "text": "we thought this was a good first step um uh in the in the right",
    "start": "1053480",
    "end": "1058799"
  },
  {
    "text": "direction the third part that we introduced were guard rails um",
    "start": "1059200",
    "end": "1064760"
  },
  {
    "text": "now when I'm telling you this I'm sure all of you are sitting there looking at the presentation and going okay so I",
    "start": "1064760",
    "end": "1070640"
  },
  {
    "text": "have to go verify what he's saying is is right or wrong and essentially that's what guard rail is so you can't trust an",
    "start": "1070640",
    "end": "1077360"
  },
  {
    "text": "llm entirely because you don't know if it's taking the right decision if it's looking at the at the right data points",
    "start": "1077360",
    "end": "1085360"
  },
  {
    "text": "if it's on the right path so guard rails is essentially a way for you to validate if an llm is doing the right thing and",
    "start": "1085360",
    "end": "1091640"
  },
  {
    "text": "there are different ways you can you can Implement a guard rail we started implementing a version of our own",
    "start": "1091640",
    "end": "1097320"
  },
  {
    "text": "because at that time when we started this journey there weren't a lot of Open Source libraries or companies that we",
    "start": "1097320",
    "end": "1103200"
  },
  {
    "text": "could work with right now you have Nemo guard guard rails coming from Nvidia",
    "start": "1103200",
    "end": "1108559"
  },
  {
    "text": "there guard rails. a a company that's being built out in the Bay Area which is focusing entirely on guard rails um and",
    "start": "1108559",
    "end": "1115440"
  },
  {
    "text": "we implemented our guard rails with a little bit of a Twist which was graphs of thoughts approach now for some of you",
    "start": "1115440",
    "end": "1122039"
  },
  {
    "text": "who've been in the previous talk here uh whether they talking about a business process uh Supply Discovery is not I",
    "start": "1122039",
    "end": "1128280"
  },
  {
    "text": "type in something and you get a get a result a lot of times in Enterprise landscape you're essentially argumenting",
    "start": "1128280",
    "end": "1135120"
  },
  {
    "text": "AI for a to support a business process and this business processes are not",
    "start": "1135120",
    "end": "1140679"
  },
  {
    "text": "linear so we needed something where we can understand the dynamic nature of the",
    "start": "1140679",
    "end": "1146120"
  },
  {
    "text": "business process depending on where the user is and then invoke different kinds of guard rails required to support that",
    "start": "1146120",
    "end": "1153080"
  },
  {
    "text": "user um so thankfully we saw a paper that was released uh I think came out from eted Zurich uh around uh graphs of",
    "start": "1153080",
    "end": "1161159"
  },
  {
    "text": "thought which is essentially we thought of our entire business process as a graph and at any given point in time we",
    "start": "1161159",
    "end": "1167919"
  },
  {
    "text": "knew where the user was and we invoke different sorts of guard rails to make sure that llm is not misleading the the",
    "start": "1167919",
    "end": "1176600"
  },
  {
    "text": "user that was a lot for stage two right and what can happen if you don't have",
    "start": "1176600",
    "end": "1182320"
  },
  {
    "text": "guard rails and this is news about a month and a half ago I think Air Canada",
    "start": "1182320",
    "end": "1188039"
  },
  {
    "text": "uh enabled a chatbot with an llm for its users and the and the chatbot agent went",
    "start": "1188039",
    "end": "1194559"
  },
  {
    "text": "ahead and and told its customer that we owe you something money and now the",
    "start": "1194559",
    "end": "1201039"
  },
  {
    "text": "airline is liable for what the chatbot did so enabling agents or enabling llms",
    "start": "1201039",
    "end": "1207799"
  },
  {
    "text": "without putting guard rails without doing domain adaptation they can start to take actions that are probably not in",
    "start": "1207799",
    "end": "1214760"
  },
  {
    "text": "the best benefit of the organization",
    "start": "1214760",
    "end": "1220240"
  },
  {
    "text": "so just sort of taking a step back right so what did we identify as issues in",
    "start": "1220240",
    "end": "1226679"
  },
  {
    "text": "stage one we said we needed guard rails we needed domain adaptation we needed to build trust and reliability we needed to",
    "start": "1226679",
    "end": "1233799"
  },
  {
    "text": "be a list chatty and reduce hallucinations and when we brought in some changes as part of stage two we",
    "start": "1233799",
    "end": "1240559"
  },
  {
    "text": "couldn't hit all of them and we said okay domain adaptation and guard rails increased trust and reliability because",
    "start": "1240559",
    "end": "1247200"
  },
  {
    "text": "when the users started to work with our product they started giving us feedback that okay now it starts to make sense",
    "start": "1247200",
    "end": "1253600"
  },
  {
    "text": "that the system that we are working with understands the process and we are quite happy that we don't have to worry about",
    "start": "1253600",
    "end": "1259720"
  },
  {
    "text": "our data being shipped to um another company um the next biggest thing we had",
    "start": "1259720",
    "end": "1266360"
  },
  {
    "text": "to solve was that remained a very big challenge for us was hallucinations right so this was a this played a huge",
    "start": "1266360",
    "end": "1273919"
  },
  {
    "text": "role in trust and reliability of the system because every time the user comes in and uses the system the system gave",
    "start": "1273919",
    "end": "1281279"
  },
  {
    "text": "them different answers which essentially means they could never come back and reuse the system for the same problem",
    "start": "1281279",
    "end": "1287440"
  },
  {
    "text": "and that's something that we wanted to make sure was not going to happen the weird aspect of using open-",
    "start": "1287440",
    "end": "1294200"
  },
  {
    "text": "Source model sometimes when you use something that's foundationally big models that are available is our users",
    "start": "1294200",
    "end": "1300880"
  },
  {
    "text": "were happier in terms of the quality of conversation with ch GPT and they started asking us can we have the same",
    "start": "1300880",
    "end": "1308000"
  },
  {
    "text": "quality but we don't want it to be on on Shar GPT so we had a bit of a um a",
    "start": "1308000",
    "end": "1314640"
  },
  {
    "text": "situation there so we constantly were thinking about how can we how can we do this and one big challenge we had as we",
    "start": "1314640",
    "end": "1321960"
  },
  {
    "text": "implemented stage two was that testing agents was a nightmare so we had",
    "start": "1321960",
    "end": "1328080"
  },
  {
    "text": "absolutely no idea what the agents were trying to do sometimes they just went completely off key we didn't we can't",
    "start": "1328080",
    "end": "1335279"
  },
  {
    "text": "you and you couldn't put break points in how they were thinking because you can't really know what they want to do they",
    "start": "1335279",
    "end": "1341360"
  },
  {
    "text": "invoke data API at some point they didn't invoke data apis at some point they decided to make up their own answer",
    "start": "1341360",
    "end": "1347520"
  },
  {
    "text": "so there was a there's a bit of a challenge in debugging uh agents and we were not really comfortable thinking",
    "start": "1347520",
    "end": "1353919"
  },
  {
    "text": "about bringing agents into into production with the changes that we",
    "start": "1353919",
    "end": "1359720"
  },
  {
    "text": "brought in uh this is what the conversation started to look like so we said okay have an issue with conflict in",
    "start": "1359720",
    "end": "1366520"
  },
  {
    "text": "Su Canal we need to get sustainable fair market coffee beans from South America and with the agent took this input from",
    "start": "1366520",
    "end": "1374440"
  },
  {
    "text": "the user and said okay let me understand this you have issues with Shi due to a conflict your focus is looking for",
    "start": "1374440",
    "end": "1381120"
  },
  {
    "text": "coffee suppliers in South South America you want to look at suppliers who have sustainable and fair market",
    "start": "1381120",
    "end": "1386600"
  },
  {
    "text": "certifications and it asked the user if this understanding is correct and the",
    "start": "1386600",
    "end": "1391760"
  },
  {
    "text": "user said yes that's correct and the agent went on and argumented the the",
    "start": "1391760",
    "end": "1397880"
  },
  {
    "text": "conversation this is where llm start to enhance what users can do leading them",
    "start": "1397880",
    "end": "1403000"
  },
  {
    "text": "down the path of efficiency to Effectiveness is to say given that a fair trade is a sustain ability",
    "start": "1403000",
    "end": "1409039"
  },
  {
    "text": "certificate can I also include the other ones for this previously the users had to go figure out what sustainability",
    "start": "1409039",
    "end": "1415120"
  },
  {
    "text": "certificates were themselves we didn't have to train the foundational model of",
    "start": "1415120",
    "end": "1420159"
  },
  {
    "text": "for this the uh given the amount of data that it had seen it was already aware what sustainable certificates were and",
    "start": "1420159",
    "end": "1427279"
  },
  {
    "text": "essentially they said okay it's okay we're good to go let's let's move ahead and then the agent instead of invoking",
    "start": "1427279",
    "end": "1434760"
  },
  {
    "text": "our data apis to pick up data just randomly decided to start creating its",
    "start": "1434760",
    "end": "1439919"
  },
  {
    "text": "own suppliers it said ABC from Brazil quy from Chile they all have sustainable",
    "start": "1439919",
    "end": "1444960"
  },
  {
    "text": "certificates for their coffee going um and the user asked us but they don't look like real suppliers can you tell me",
    "start": "1444960",
    "end": "1451279"
  },
  {
    "text": "more and the agent said sorry I'm A supplier Discovery agent and I cannot answer that question for you right so",
    "start": "1451279",
    "end": "1457120"
  },
  {
    "text": "now suddenly you're back to square one where you said okay what's the point of doing all this and we had to reduce the",
    "start": "1457120",
    "end": "1464679"
  },
  {
    "text": "hallucinations we had to bring in more trust and reliability in the system um and we we we came across the idea of",
    "start": "1464679",
    "end": "1472440"
  },
  {
    "text": "Rags which ST which stands for retrieval augumented generative uh Ai and if you",
    "start": "1472440",
    "end": "1479080"
  },
  {
    "text": "were in the talks yesterday uh Jay from coare was talking about Rags and there bunch of other speakers who who touched",
    "start": "1479080",
    "end": "1485919"
  },
  {
    "text": "on this as well I won't get into the nities of what a rag is but essentially",
    "start": "1485919",
    "end": "1492520"
  },
  {
    "text": "what that meant for us is our engineering stack and system grew much",
    "start": "1492520",
    "end": "1498000"
  },
  {
    "text": "bigger so what we are trying to do with Rags is",
    "start": "1498000",
    "end": "1504000"
  },
  {
    "text": "essentially instead of getting the foundational model to answer the",
    "start": "1504000",
    "end": "1509399"
  },
  {
    "text": "question uh we give it data and we give it context of the conversation and we",
    "start": "1509399",
    "end": "1515559"
  },
  {
    "text": "force it to use that context to answer the question and and now there are different ways you can you can uh do",
    "start": "1515559",
    "end": "1523360"
  },
  {
    "text": "rags um and we sort of use this concept called as chain of thoughts framework uh",
    "start": "1523360",
    "end": "1530399"
  },
  {
    "text": "which I will jump into uh right after this but our planner and execution layer",
    "start": "1530399",
    "end": "1536000"
  },
  {
    "text": "for llms now went from having an agent and a guide rail to having chain of",
    "start": "1536000",
    "end": "1541279"
  },
  {
    "text": "thoughts prompting query rewrite uh splitting into multiple query generation",
    "start": "1541279",
    "end": "1546799"
  },
  {
    "text": "custom guard rails based on graphs of thought query based on uh data retrieval",
    "start": "1546799",
    "end": "1551919"
  },
  {
    "text": "and then summarizing all of this now this is some and and this is one of the",
    "start": "1551919",
    "end": "1557320"
  },
  {
    "text": "biggest things for me with llms right now is every time you",
    "start": "1557320",
    "end": "1562360"
  },
  {
    "text": "want to make your system a little bit more robust a little bit more reliable",
    "start": "1562360",
    "end": "1568320"
  },
  {
    "text": "there's probably a new part of the new service or new piece of uh technology",
    "start": "1568320",
    "end": "1574880"
  },
  {
    "text": "that you need to add in in enabling it um so we went from that into thinking about how do we",
    "start": "1574880",
    "end": "1584159"
  },
  {
    "text": "do rags with with chains of thought prompting now now essentially what we",
    "start": "1584159",
    "end": "1589960"
  },
  {
    "text": "saw was a big challenge with agents was the reasoning process behind why the agents did what they did so with the",
    "start": "1589960",
    "end": "1597799"
  },
  {
    "text": "chain of thoughts prompting what we tried to do was we instead of going from",
    "start": "1597799",
    "end": "1602960"
  },
  {
    "text": "question to answer the llm sort of goes through a reasoning process and the good",
    "start": "1602960",
    "end": "1608399"
  },
  {
    "text": "thing here is you can actually teach this reasoning process to an llm so instead of f tun instead of take uh",
    "start": "1608399",
    "end": "1615000"
  },
  {
    "text": "retraining your entire model you can actually do a few short Chain of Thought",
    "start": "1615000",
    "end": "1620120"
  },
  {
    "text": "where you take certain pieces of conversation you take some reasoning you provide this to the llm and the llm",
    "start": "1620120",
    "end": "1626679"
  },
  {
    "text": "understands okay so this is the reasoning process I need to have when I'm working with the user so it's basically like giving an llm a road map",
    "start": "1626679",
    "end": "1633720"
  },
  {
    "text": "to follow and if you know your domain and your processes well you can actually do this quite easily and for this of",
    "start": "1633720",
    "end": "1640880"
  },
  {
    "text": "course we use l chain and I know some of you yesterday there were people asking is Lang chain the best uh framework out",
    "start": "1640880",
    "end": "1647960"
  },
  {
    "text": "there at this moment we think that's probably the framework that's being used by the community the most I'm not sure if it's",
    "start": "1647960",
    "end": "1654200"
  },
  {
    "text": "best or not but it it does the job for us now once the user starts to have a",
    "start": "1654200",
    "end": "1663640"
  },
  {
    "text": "conversation with the system and there is and there is reasoning behind this one of the things that we saw as a",
    "start": "1663640",
    "end": "1670159"
  },
  {
    "text": "pattern on how users use the new generation of products were some people were still typing in keywords because",
    "start": "1670159",
    "end": "1676600"
  },
  {
    "text": "they thought they're still used to the idea of using Google search so they didn't really know how to use a",
    "start": "1676600",
    "end": "1681760"
  },
  {
    "text": "conversational based system so they typed in keywords whereas some of the other users put in an entire story they",
    "start": "1681760",
    "end": "1689120"
  },
  {
    "text": "spoke about this was the problem they were having this is the data point they were looking at these are the kind of",
    "start": "1689120",
    "end": "1694799"
  },
  {
    "text": "suppliers they want this is the manufacturer they'd like to work with so on and so forth and we ended up having a",
    "start": "1694799",
    "end": "1700760"
  },
  {
    "text": "passage in the very first message rather than okay tell me what your problem is",
    "start": "1700760",
    "end": "1706000"
  },
  {
    "text": "right um and this is going to happen a lot when you enable a product that is or",
    "start": "1706000",
    "end": "1711360"
  },
  {
    "text": "a feature that's a bit open-ended and we decided to look at okay we need to maybe",
    "start": "1711360",
    "end": "1717200"
  },
  {
    "text": "understand what the user wants to do which is why and transform it into a",
    "start": "1717200",
    "end": "1722279"
  },
  {
    "text": "standard form and at some points we might have to actually split this into several queries rather than one single",
    "start": "1722279",
    "end": "1729679"
  },
  {
    "text": "query so this backed with Chain of Thought gave us the capability to look",
    "start": "1729679",
    "end": "1735440"
  },
  {
    "text": "at okay so we break down the problem into a b and c and we need to make data",
    "start": "1735440",
    "end": "1740880"
  },
  {
    "text": "calls to fetch data for these problems and using this data and using this problem we can find uh find an",
    "start": "1740880",
    "end": "1749440"
  },
  {
    "text": "answer now once you enable all of this right it's a lot of different pieces of",
    "start": "1749679",
    "end": "1755399"
  },
  {
    "text": "technology and you have to observe to understand what is going on and there",
    "start": "1755399",
    "end": "1761480"
  },
  {
    "text": "are two parts around the llm that you have to observe so the part one is the",
    "start": "1761480",
    "end": "1766600"
  },
  {
    "text": "llms like any other service has response times and also the number of tokens it",
    "start": "1766600",
    "end": "1772640"
  },
  {
    "text": "processes the bigger your large language model is going to be the slower it can get so which is why there's a lot of",
    "start": "1772640",
    "end": "1779120"
  },
  {
    "text": "work that's happening in that space in terms of how can we make this faster and also run it on smaller gpus rather than",
    "start": "1779120",
    "end": "1787080"
  },
  {
    "text": "big clusters that you have to provision and the actual conversation and the",
    "start": "1787080",
    "end": "1794039"
  },
  {
    "text": "result so previously when you build search systems and somebody typ tyed in a a query you would find results and",
    "start": "1794039",
    "end": "1802120"
  },
  {
    "text": "these results were backed with relevancy so you would do an ndcg you would do Precision you would do recall but now",
    "start": "1802120",
    "end": "1808519"
  },
  {
    "text": "it's a bit more complicated because you need to understand if the conversation or if the llm understood the",
    "start": "1808519",
    "end": "1814919"
  },
  {
    "text": "conversation if it picked up all of the relevant set of data from the data",
    "start": "1814919",
    "end": "1820960"
  },
  {
    "text": "systems to answer the question did it pick up all of it and how much of it were right so you have context prision",
    "start": "1820960",
    "end": "1827760"
  },
  {
    "text": "and recall and of course combining all of this information into an answer that",
    "start": "1827760",
    "end": "1833000"
  },
  {
    "text": "the llm can actually work with uh the good thing about the science Community",
    "start": "1833000",
    "end": "1839120"
  },
  {
    "text": "right now and the open source world is if you think you have a problem chances are that there are lots of people who",
    "start": "1839120",
    "end": "1845120"
  },
  {
    "text": "have this problem there's probably a framework already being built that somebody that you can work with uh and",
    "start": "1845120",
    "end": "1852200"
  },
  {
    "text": "we came across the ragas framework it's an open source framework that helps you generate a score between generation and",
    "start": "1852200",
    "end": "1858760"
  },
  {
    "text": "retrieval so it gives you ideas and pointers in terms of understanding where do you actually have to go in order to",
    "start": "1858760",
    "end": "1865960"
  },
  {
    "text": "fix uh your system now a quick summary for stage",
    "start": "1865960",
    "end": "1872159"
  },
  {
    "text": "three um so in the previous stage the biggest challenge we saw was hallucination and testing agents was was",
    "start": "1872159",
    "end": "1879519"
  },
  {
    "text": "the other piece now with introduction of Rags uh hallucination drastically",
    "start": "1879519",
    "end": "1886279"
  },
  {
    "text": "reduced uh we using knowledge graphs as our data source um and not vectors Vector database and I'll get into it uh",
    "start": "1886279",
    "end": "1893760"
  },
  {
    "text": "in in the next section um and we basically stored everything right we stored all the data that the users were",
    "start": "1893760",
    "end": "1900080"
  },
  {
    "text": "chatting the results that we were uh that we were showing to the users in order to power our observability and",
    "start": "1900080",
    "end": "1905600"
  },
  {
    "text": "product metrics by eliminating agents testing became a whole lot easier because the we could see exactly what",
    "start": "1905600",
    "end": "1912600"
  },
  {
    "text": "the llms were trying to do and we were trying to figure out how can we uh make this better",
    "start": "1912600",
    "end": "1919240"
  },
  {
    "text": "now with this um we had other challenges that we need to we need to start looking",
    "start": "1919240",
    "end": "1924799"
  },
  {
    "text": "at so we started showing results and",
    "start": "1924799",
    "end": "1929840"
  },
  {
    "text": "naturally the moment it's open it's an open-ended environment uh our users",
    "start": "1929840",
    "end": "1935279"
  },
  {
    "text": "started to interrogate the data that we were showing and they wanted to have a",
    "start": "1935279",
    "end": "1941120"
  },
  {
    "text": "deeper conversation with the data itself and to achieve their goal and this was",
    "start": "1941120",
    "end": "1946639"
  },
  {
    "text": "not enabled in our system yet and one of the other challenges that we saw was",
    "start": "1946639",
    "end": "1952000"
  },
  {
    "text": "higher latency with more and more people using um the latency numbers were quite",
    "start": "1952000",
    "end": "1957360"
  },
  {
    "text": "high so the response rates were slower and our users started to get a bit annoyed because they had to wait for a",
    "start": "1957360",
    "end": "1962600"
  },
  {
    "text": "few seconds before the they could look at the answer um on their",
    "start": "1962600",
    "end": "1968000"
  },
  {
    "text": "screens now what does reduction of hallucinations with Rags look like we we",
    "start": "1968000",
    "end": "1973480"
  },
  {
    "text": "play the same story looking for coffee suppliers in South America we want them to be sustainable and essentially what",
    "start": "1973480",
    "end": "1981039"
  },
  {
    "text": "you can see on on the right side of the screen is because we force it to use",
    "start": "1981039",
    "end": "1986760"
  },
  {
    "text": "data and we force it to provide citations with data Provence it actually",
    "start": "1986760",
    "end": "1993039"
  },
  {
    "text": "tells the user that this calm coffee supplier who produces coffee beans they're based out of Brazil and we found",
    "start": "1993039",
    "end": "1999919"
  },
  {
    "text": "this information from this place so it gives the our users to go check them out",
    "start": "1999919",
    "end": "2007320"
  },
  {
    "text": "themselves if they want to and now they can start to trust that this answer comes from a certain place without",
    "start": "2007320",
    "end": "2013399"
  },
  {
    "text": "having to just sit there and wonder where did this information come from and we also see that it looked at roast your",
    "start": "2013399",
    "end": "2020600"
  },
  {
    "text": "beans as another supplier and it did let the user know that they don't have any sustainable certificates and we found",
    "start": "2020600",
    "end": "2027399"
  },
  {
    "text": "this information from roasty your beans.com now the very next thing the moment we unlocked this for our users",
    "start": "2027399",
    "end": "2034120"
  },
  {
    "text": "what they did was they said okay can you tell us a little bit more about roast your beans in terms of their revenue",
    "start": "2034120",
    "end": "2039600"
  },
  {
    "text": "customers how are they in terms of the delivery times and unfortunately we didn't have that information to share",
    "start": "2039600",
    "end": "2046840"
  },
  {
    "text": "with our uh users now that leads to stage four which is expanding improving",
    "start": "2046840",
    "end": "2054280"
  },
  {
    "text": "and scaling the data you can have large language models but the effectiveness of your llm is",
    "start": "2054280",
    "end": "2062520"
  },
  {
    "text": "going to be based on how based on the high quality data that you have so it",
    "start": "2062520",
    "end": "2069240"
  },
  {
    "text": "looks something like this where you go play a report with to a person and then you're just praying and keeping your",
    "start": "2069240",
    "end": "2075118"
  },
  {
    "text": "fingers cross that the numbers are right when somebody trust asks you can I trust you with your numbers and we didn't want",
    "start": "2075119",
    "end": "2080800"
  },
  {
    "text": "to uh we didn't want to have that for our customers",
    "start": "2080800",
    "end": "2086118"
  },
  {
    "text": "now there are different ways in which we were thinking about how do we enhance",
    "start": "2086119",
    "end": "2091440"
  },
  {
    "text": "and scale data so the one thing that we looked at was we said okay for we wanted",
    "start": "2091440",
    "end": "2098200"
  },
  {
    "text": "to bring data from different places and wanted to use our knowledge graph as a system of records and in Enterprise",
    "start": "2098200",
    "end": "2104880"
  },
  {
    "text": "landscape if you're working with in the Erp space CRM space or or even in your own organization you have data setting",
    "start": "2104880",
    "end": "2112240"
  },
  {
    "text": "in different data stores and what we tried to think about bringing this data",
    "start": "2112240",
    "end": "2117359"
  },
  {
    "text": "was instead of just vectorizing them and embedding them and putting them embedding stores you still had the",
    "start": "2117359",
    "end": "2122680"
  },
  {
    "text": "challenge of understanding how is this data even related right and on top of that we buil bu a knowledge graph which",
    "start": "2122680",
    "end": "2129280"
  },
  {
    "text": "is a semantic understanding of the data and data setting in different data fields and we started integrating",
    "start": "2129280",
    "end": "2136760"
  },
  {
    "text": "domains different domain data revenue from different data Partners uh a little bit about uh risks from different data",
    "start": "2136760",
    "end": "2144160"
  },
  {
    "text": "partners and data even coming from from the customers themselves the other thing for us that",
    "start": "2144160",
    "end": "2150240"
  },
  {
    "text": "was important was as we scal the whole data operation part we didn't want to",
    "start": "2150240",
    "end": "2155400"
  },
  {
    "text": "lose control of the EXP explainability around the data itself and the provence",
    "start": "2155400",
    "end": "2160760"
  },
  {
    "text": "around it we dabbled a bit with embeddings uh and one of the key challenges that we saw on the embedding",
    "start": "2160760",
    "end": "2167760"
  },
  {
    "text": "side is they're relatively faster to work with and uh you could essentially",
    "start": "2167760",
    "end": "2173760"
  },
  {
    "text": "take different questions and find answers that you would probably not extract and built into a knowledge craft",
    "start": "2173760",
    "end": "2179880"
  },
  {
    "text": "but the challenge was explaining embeddings to an Enterprise user when",
    "start": "2179880",
    "end": "2185040"
  },
  {
    "text": "you're are working with a very big demographic um and also correcting them was a bit of",
    "start": "2185040",
    "end": "2191400"
  },
  {
    "text": "a challenge uh we still have some experiments that we are running on the on the embedding side and I think we'll",
    "start": "2191400",
    "end": "2197400"
  },
  {
    "text": "get to a point where we probably use both words but at the moment uh everything that we are powering through",
    "start": "2197400",
    "end": "2203560"
  },
  {
    "text": "our product is is based on knowledge cfts now this is just a sneak peek of",
    "start": "2203560",
    "end": "2209319"
  },
  {
    "text": "what our ontology of knowledge craft looks like right so there's a there's a saying that goes at some point the",
    "start": "2209319",
    "end": "2215920"
  },
  {
    "text": "problem transforms itself into a graph most of the problems um so this is what",
    "start": "2215920",
    "end": "2222640"
  },
  {
    "text": "our current one snapshot of our uh Knowledge Graph looks like and we did",
    "start": "2222640",
    "end": "2228319"
  },
  {
    "text": "this about 2 and a half years ago and surprisingly or weirdly one of",
    "start": "2228319",
    "end": "2235240"
  },
  {
    "text": "the things that llms can do very well is we put in a lot of effort in getting and",
    "start": "2235240",
    "end": "2240680"
  },
  {
    "text": "designing this onology but given your domain you can actually use an llm to",
    "start": "2240680",
    "end": "2246040"
  },
  {
    "text": "design the ontology for your so what took us about 6 to 9 months of effort to",
    "start": "2246040",
    "end": "2251119"
  },
  {
    "text": "build this is something that you can actually build for your domain in maybe of a a few months using an llm now once",
    "start": "2251119",
    "end": "2258640"
  },
  {
    "text": "we had this ontology that spread across different domains and different entities we wanted to think okay how do",
    "start": "2258640",
    "end": "2265960"
  },
  {
    "text": "we now populate this ontology is great but now we need to bring all of this data and",
    "start": "2265960",
    "end": "2271839"
  },
  {
    "text": "populated um we previously had our Transformer based model that were",
    "start": "2271839",
    "end": "2278079"
  },
  {
    "text": "working on web content and other different data types to bring all of this information but we had a problem",
    "start": "2278079",
    "end": "2285200"
  },
  {
    "text": "that the quality that we needed the data to be in had had to be much higher now",
    "start": "2285200",
    "end": "2291839"
  },
  {
    "text": "we sat there wondering okay we need high quality data we had access to some training data that we had annotated",
    "start": "2291839",
    "end": "2298000"
  },
  {
    "text": "ourselves now how can we get high quality data in a short period of time to find tuna",
    "start": "2298000",
    "end": "2303920"
  },
  {
    "text": "model we used a superior llm so basically what we did was instead of taking months and putting in a lot of",
    "start": "2303920",
    "end": "2310800"
  },
  {
    "text": "effort with with humans to generate annotated data we took a much Superior",
    "start": "2310800",
    "end": "2316319"
  },
  {
    "text": "llm um and we generated high quality training data to fine tune a smaller uh",
    "start": "2316319",
    "end": "2322960"
  },
  {
    "text": "llm model and we had the humans in the loop to validate this so basically our",
    "start": "2322960",
    "end": "2328680"
  },
  {
    "text": "efforts went down by 10 to 20x of what we would have to spend with just humans",
    "start": "2328680",
    "end": "2334200"
  },
  {
    "text": "annotating the data to getting that gold standard data with using an llm and having humans in the loop uh validating",
    "start": "2334200",
    "end": "2341079"
  },
  {
    "text": "it now the reason why we wanted a small smaller model that's adapted uh to a",
    "start": "2341079",
    "end": "2346200"
  },
  {
    "text": "certain task is it's easier to operate and when you're running llms it's going to be much economical because you can't",
    "start": "2346200",
    "end": "2353560"
  },
  {
    "text": "run massive models all the time because it's very expensive and takes a lot of gpus currently we're struggling with",
    "start": "2353560",
    "end": "2360800"
  },
  {
    "text": "getting gpus in AWS we searched all EU Frankfurt Ireland North Virginia so",
    "start": "2360800",
    "end": "2366680"
  },
  {
    "text": "we're talk like it's it's seriously a challenge now to get big gpus to to host",
    "start": "2366680",
    "end": "2372000"
  },
  {
    "text": "your llms the second part of the problem is okay we started getting data it's high",
    "start": "2372000",
    "end": "2379040"
  },
  {
    "text": "quality we start improving the knowledge graph the one thing that is interesting when you think about semantic search is",
    "start": "2379040",
    "end": "2386520"
  },
  {
    "text": "that when people interact with your system even if they're working on the same problem they don't end up using the",
    "start": "2386520",
    "end": "2392680"
  },
  {
    "text": "same language which means that you need to be able to translate or understand the range of language that your users",
    "start": "2392680",
    "end": "2399920"
  },
  {
    "text": "can can actually uh interact with your system so we further expanded our",
    "start": "2399920",
    "end": "2406760"
  },
  {
    "text": "knowledge graph where we used an llm to generate facts from data that we were",
    "start": "2406760",
    "end": "2411920"
  },
  {
    "text": "looking at based on our domain and we converted these facts with all of their",
    "start": "2411920",
    "end": "2418160"
  },
  {
    "text": "synonyms with all of the different ways one could potentially ask for this piece",
    "start": "2418160",
    "end": "2423480"
  },
  {
    "text": "of data and put it put everything into the knowledge graph itself so so you could use llms to generate training data",
    "start": "2423480",
    "end": "2430480"
  },
  {
    "text": "for your smaller models and you could also use an llm to argument and expand",
    "start": "2430480",
    "end": "2435599"
  },
  {
    "text": "that data if you know how if you know well within your domain how to do",
    "start": "2435599",
    "end": "2441599"
  },
  {
    "text": "this and the third thing that we did for expansion was we actually started working with third party data providers",
    "start": "2441599",
    "end": "2448079"
  },
  {
    "text": "so there are some data providers that specifically provide you data that and there's a massive amount of them so we",
    "start": "2448079",
    "end": "2455280"
  },
  {
    "text": "started working with data providers for getting financial information risk information uh so on and so forth and",
    "start": "2455280",
    "end": "2461520"
  },
  {
    "text": "and brought all of that together uh into our knowledge graph now the engineering problem of",
    "start": "2461520",
    "end": "2468200"
  },
  {
    "text": "this right all of this sounds so great this theoretically you're doing this it's a p you run it on a few hundreds of",
    "start": "2468200",
    "end": "2475160"
  },
  {
    "text": "documents everything is fine you need to now scale this to millions and probably",
    "start": "2475160",
    "end": "2480480"
  },
  {
    "text": "billions of of of web pages and documents so which essentially means you",
    "start": "2480480",
    "end": "2485880"
  },
  {
    "text": "have big data you have big models and you and you actually have big problems",
    "start": "2485880",
    "end": "2491040"
  },
  {
    "text": "because orchestrating and running this is is a nightmare now our ml pipelines had to",
    "start": "2491040",
    "end": "2498480"
  },
  {
    "text": "run llm workloads um the llm inference time had a big impact on throughput and",
    "start": "2498480",
    "end": "2503880"
  },
  {
    "text": "cost so we were trying to figure out how do we reduce them how do we run in their optimal form data scientists wanted to",
    "start": "2503880",
    "end": "2510839"
  },
  {
    "text": "run experiments at scale because they weren't able to at the moment and we had",
    "start": "2510839",
    "end": "2516839"
  },
  {
    "text": "to make make sure the ml pipelines were observable and should ideally use infrastructure efficiently so that you",
    "start": "2516839",
    "end": "2523359"
  },
  {
    "text": "know which jobs can use CPU which jobs can use GPU infrastructure scales comes",
    "start": "2523359",
    "end": "2529359"
  },
  {
    "text": "back down when it's not being used so now we ended up changing our",
    "start": "2529359",
    "end": "2537280"
  },
  {
    "text": "entire ML and uh and LL llm Ops",
    "start": "2537280",
    "end": "2542359"
  },
  {
    "text": "platform so what we tried to do do was we said okay if we want to hit all of",
    "start": "2542359",
    "end": "2547520"
  },
  {
    "text": "these things we had a very big challenge um so a quick show of hands in terms of",
    "start": "2547520",
    "end": "2554720"
  },
  {
    "text": "how many of you running spark pipelines ml workloads in your",
    "start": "2554720",
    "end": "2561359"
  },
  {
    "text": "organization okay so it's going to be a bit more harder to get spark pipelines to run with llms as well and one of the",
    "start": "2561400",
    "end": "2568760"
  },
  {
    "text": "other challenges we had was our data science team were not spark aware our ml",
    "start": "2568760",
    "end": "2574319"
  },
  {
    "text": "engineering team was spark aware so which which which essentially meant that anything that goes into production or",
    "start": "2574319",
    "end": "2581119"
  },
  {
    "text": "needs to run its scale there needs to be a translator from the spark World from the data Science World to spark world",
    "start": "2581119",
    "end": "2589480"
  },
  {
    "text": "the other challenge that we had was spark is written predominantly with Java",
    "start": "2589480",
    "end": "2596200"
  },
  {
    "text": "and Scala and our data scientists are very much away from that world so they",
    "start": "2596200",
    "end": "2601760"
  },
  {
    "text": "have worked with scientific packages on python for a very long time so observing",
    "start": "2601760",
    "end": "2607359"
  },
  {
    "text": "and understanding when spark fails was a very big challenge for them and also",
    "start": "2607359",
    "end": "2613040"
  },
  {
    "text": "understanding how spark is utilizing the cluster how exactly the distribution of",
    "start": "2613040",
    "end": "2618839"
  },
  {
    "text": "of compute needs to happen was becoming tougher and tougher we had our data",
    "start": "2618839",
    "end": "2624119"
  },
  {
    "text": "pipelines we had our ml pipelines we had llm workload so there was so many different pieces and we realized if we",
    "start": "2624119",
    "end": "2631280"
  },
  {
    "text": "keep running in this direction it would be an absolute nightmare for us to maintain and manage everything",
    "start": "2631280",
    "end": "2637720"
  },
  {
    "text": "so what we did was we introduced a universal compute framework for MLM ML",
    "start": "2637720",
    "end": "2642800"
  },
  {
    "text": "llm and as well as data workloads so we started using this framework called Ray",
    "start": "2642800",
    "end": "2648720"
  },
  {
    "text": "which is an open source framework coming out of UC Berkeley and uh it the Enterprise version of it is run by any",
    "start": "2648720",
    "end": "2656000"
  },
  {
    "text": "scale and what they provide us is not just with a way to work with Ray but Ray",
    "start": "2656000",
    "end": "2661880"
  },
  {
    "text": "but the platform also provides us to host and run large language models that",
    "start": "2661880",
    "end": "2667960"
  },
  {
    "text": "are optimized to run on smaller gpus run on make it run faster with a click of a",
    "start": "2667960",
    "end": "2674720"
  },
  {
    "text": "button rather than us having to manage this all all by ourselves and of course it ran on our infrastructure which meant",
    "start": "2674720",
    "end": "2681520"
  },
  {
    "text": "that we didn't take a hit on the privacy and the security part it's just that we found a better way to to operate so we",
    "start": "2681520",
    "end": "2688520"
  },
  {
    "text": "chose the path of buy rather than build because build at this point was going to",
    "start": "2688520",
    "end": "2693800"
  },
  {
    "text": "take us a very long time um it's a it's a very cool project and if you're running massive data",
    "start": "2693800",
    "end": "2701160"
  },
  {
    "text": "workloads or data pipelines Ray is a very good framework for you to take a look at to a point where your data",
    "start": "2701160",
    "end": "2707440"
  },
  {
    "text": "science team can just use decorators to scale uh the their code to run on",
    "start": "2707440",
    "end": "2713920"
  },
  {
    "text": "massive infrastructure rather than having to figure out how to schedule it I can talk for hours about this but I'm",
    "start": "2713920",
    "end": "2720240"
  },
  {
    "text": "going to quickly jump forward now outcome of stage four right",
    "start": "2720240",
    "end": "2726640"
  },
  {
    "text": "um so we ran through the whole script again and we had various scripts that we were testing and finally we got to a",
    "start": "2726640",
    "end": "2733559"
  },
  {
    "text": "point where when the user asked us to tell us a little bit more about the suppliers we said okay we've re based on",
    "start": "2733559",
    "end": "2740000"
  },
  {
    "text": "the data we've received from XYZ data partner we see that the revenue of the company is 80 million here is the",
    "start": "2740000",
    "end": "2746520"
  },
  {
    "text": "revenue and when they asked us about the delivery uh quality of the supplier this",
    "start": "2746520",
    "end": "2753000"
  },
  {
    "text": "sort of information is not available either with the data partner or with uh or on the internet as well",
    "start": "2753000",
    "end": "2761079"
  },
  {
    "text": "but what we can do and this is what we started seeing is every time we had a piece of data missing we wanted to see",
    "start": "2761079",
    "end": "2768119"
  },
  {
    "text": "how we can enable the users to try and get this data so we designed our Chain",
    "start": "2768119",
    "end": "2773559"
  },
  {
    "text": "of Thought prompt as a way to say we can't get this data for you but we do",
    "start": "2773559",
    "end": "2779400"
  },
  {
    "text": "know that we have their email so we can help you draft an email so that you can start having a conversation with the",
    "start": "2779400",
    "end": "2785520"
  },
  {
    "text": "supplier to understand understand uh if you can get more information from",
    "start": "2785520",
    "end": "2790880"
  },
  {
    "text": "them so summary and takeaways right um so that was a a long talk um your",
    "start": "2790880",
    "end": "2798359"
  },
  {
    "text": "product should warrant for an llm use um your elastic Searchers your mongodb",
    "start": "2798359",
    "end": "2804240"
  },
  {
    "text": "databases your actual databases they all do a fantastic job and if your product",
    "start": "2804240",
    "end": "2811440"
  },
  {
    "text": "doesn't warrant an llm don't you don't necessarily have to jump on the bandwagon because doing it's",
    "start": "2811440",
    "end": "2818480"
  },
  {
    "text": "cool but it can turn out to be very expensive llms come at a cost uh this",
    "start": "2818480",
    "end": "2824599"
  },
  {
    "text": "cost of upskilling running the model maintaining it brace yourself of failures and and and aim for continuous",
    "start": "2824599",
    "end": "2831640"
  },
  {
    "text": "and sustainable Improvement llm is not the golden bullet you have to still work on high quality data your data contracts",
    "start": "2831640",
    "end": "2839280"
  },
  {
    "text": "your data Ops and managing an entire data life cycle and please compute your Roi you you'll have to invest a lot of",
    "start": "2839280",
    "end": "2846640"
  },
  {
    "text": "time time and money and people at this uh and which means that your product needs to at some point have that return",
    "start": "2846640",
    "end": "2853280"
  },
  {
    "text": "on on investment measure everything because it can look very cool you can be allured by",
    "start": "2853280",
    "end": "2861040"
  },
  {
    "text": "the technology store all the data metadata everything and as in when you",
    "start": "2861040",
    "end": "2867319"
  },
  {
    "text": "can get humans in the loop to validate it the idea of llms need to be around",
    "start": "2867319",
    "end": "2872640"
  },
  {
    "text": "efficiency and Effectiveness but not to sort of replace humans because it's it's",
    "start": "2872640",
    "end": "2878440"
  },
  {
    "text": "not there even if there are a lot of people who are talking about like generalized artificial intelligence it's",
    "start": "2878440",
    "end": "2885400"
  },
  {
    "text": "definitely not there please do not underestimate the value of guard rails domain adaptation",
    "start": "2885400",
    "end": "2892400"
  },
  {
    "text": "and your user experience so there's a lot of work on the user experience side",
    "start": "2892400",
    "end": "2897839"
  },
  {
    "text": "that you'll have to think about in order to bring the best out of the llms and the interaction with the users so please",
    "start": "2897839",
    "end": "2904480"
  },
  {
    "text": "I think it it adds a lot of value to to uh to your product take care of your",
    "start": "2904480",
    "end": "2910200"
  },
  {
    "text": "team so your team's going to have prompt engineering fatigue they're going to have burnouts uh some of your data",
    "start": "2910200",
    "end": "2917040"
  },
  {
    "text": "scientists might be looking at the work they did in the last decade and now an",
    "start": "2917040",
    "end": "2922280"
  },
  {
    "text": "API can do it for you so there fear of llms replacing people there are meltdowns you have to embrace failure",
    "start": "2922280",
    "end": "2928880"
  },
  {
    "text": "because there's going to be a lot of failures before they come into production and actively invest in upskilling because it's going to nobody",
    "start": "2928880",
    "end": "2935760"
  },
  {
    "text": "knows these things the field is nent there are a lot of people coming out with very good content there's free",
    "start": "2935760",
    "end": "2942599"
  },
  {
    "text": "content out there there are workshops that you can sign up for please actively invest in upskilling because it will",
    "start": "2942599",
    "end": "2949319"
  },
  {
    "text": "help build a support system for your team and system design once you pass the",
    "start": "2949319",
    "end": "2955160"
  },
  {
    "text": "PC stage you have to think about sustainable improvements you have to design your systems to work with",
    "start": "2955160",
    "end": "2960920"
  },
  {
    "text": "flexibility but at the same time with reliability version control everything",
    "start": "2960920",
    "end": "2966240"
  },
  {
    "text": "from your prompts to your data to your agents to to your apis version control",
    "start": "2966240",
    "end": "2973319"
  },
  {
    "text": "everything and tag your metadata with it so you can always go back and test and",
    "start": "2973319",
    "end": "2978520"
  },
  {
    "text": "run uh automated tests 1 + 1 is equal to 2 and all of us know this but it's not",
    "start": "2978520",
    "end": "2984720"
  },
  {
    "text": "just important to know one but it's also very important to know the plus operator in there so think about this as a whole",
    "start": "2984720",
    "end": "2991760"
  },
  {
    "text": "system rather than just thinking about an llm can solve the problem for you",
    "start": "2991760",
    "end": "2997559"
  },
  {
    "text": "with that That's all folks thank you so much and hope you enjoy your llm journey",
    "start": "2997559",
    "end": "3003610"
  },
  {
    "text": "[Music]",
    "start": "3003610",
    "end": "3011829"
  }
]
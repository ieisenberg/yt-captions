[
  {
    "text": "[Music]",
    "start": "3270",
    "end": "8730"
  },
  {
    "text": "the fastest code in the world that is a bold claim but what do I mean by fast",
    "start": "11000",
    "end": "16198"
  },
  {
    "text": "how fast is fast um well I come from the world of networking and in networking",
    "start": "16199",
    "end": "21600"
  },
  {
    "text": "these days 100 Gig Nicks are really common but what does 100 Gig Nick actually mean well if you make some",
    "start": "21600",
    "end": "28080"
  },
  {
    "text": "assumptions about packet sizes 100 Gig Nick is about 10 million packets per",
    "start": "28080",
    "end": "33760"
  },
  {
    "text": "second 10 million packets per second if you do a bit more math you get to 100 Nan so 100 Nan is your time budget for",
    "start": "33760",
    "end": "42440"
  },
  {
    "text": "processing a packet let's put that in perspective a beam of light going from the stage by the time it gets to the",
    "start": "42440",
    "end": "49239"
  },
  {
    "text": "windows at the back of the room you have to finish processing a packet um we're at a Tech conference so put it in clocks",
    "start": "49239",
    "end": "56239"
  },
  {
    "text": "as well we've got 300 clocks of our CPU per core in order to do this processing",
    "start": "56239",
    "end": "62680"
  },
  {
    "text": "so that's what I mean by fast so what are we going to talk about today we're going to be looking at seven",
    "start": "62680",
    "end": "69040"
  },
  {
    "text": "different techniques and we're going to be taking a practical look so I've actually gone and written some code for",
    "start": "69040",
    "end": "74320"
  },
  {
    "text": "this presentation and we're going to be working through that code I'm going to be looking at those optimizations going",
    "start": "74320",
    "end": "80079"
  },
  {
    "text": "to making the changes to the code and seeing what effect it has all right let's step back a bit and",
    "start": "80079",
    "end": "86960"
  },
  {
    "text": "do some introductions so I'm Alan um how did I get here today well with",
    "start": "86960",
    "end": "92360"
  },
  {
    "text": "difficulty because of the train strikes yesterday but uh actually how I got here today",
    "start": "92360",
    "end": "98280"
  },
  {
    "text": "I've spent about 15 years working in the networking industry um I'm currently working for Microsoft uh for aure for",
    "start": "98280",
    "end": "105680"
  },
  {
    "text": "operators where our mission is bringing the power of the cloud to network operators um so let's make that real",
    "start": "105680",
    "end": "112399"
  },
  {
    "text": "with a little bit of an example so who here today has been using their phone",
    "start": "112399",
    "end": "117600"
  },
  {
    "text": "and has actually got 5G connectivity yeah loads of people so what actually",
    "start": "117600",
    "end": "122960"
  },
  {
    "text": "happens data from your phone when you've got 5G leaves your mobile phone goes to",
    "start": "122960",
    "end": "128840"
  },
  {
    "text": "the radio network so a mobile Tower somewhere around here um and then from that radio network from lots of",
    "start": "128840",
    "end": "135640"
  },
  {
    "text": "different access points in that radio network it all gets aggregated in this thing called the 5G packet core now the",
    "start": "135640",
    "end": "141879"
  },
  {
    "text": "5G packet core that is really the brains of the operation that's where all the smart stuff happens at least that's what",
    "start": "141879",
    "end": "147840"
  },
  {
    "text": "someone who works in the 5G packet core will tell you so let's zoom in on the 5G packet core",
    "start": "147840",
    "end": "154480"
  },
  {
    "text": "um what's actually happening here so data comes in from the radio network and it's encapsulated so the packet your",
    "start": "154480",
    "end": "161080"
  },
  {
    "text": "phone's trying to get to the internet is that dark blue packet at the bottom an IP packet but it's encapsulated in all",
    "start": "161080",
    "end": "166920"
  },
  {
    "text": "these extra headers and what are they actually doing they're telling the packet core who this packet is from so",
    "start": "166920",
    "end": "173879"
  },
  {
    "text": "is this packet from Bob's phone is it from Alice's phone what's the session and how should that packet be treated",
    "start": "173879",
    "end": "179840"
  },
  {
    "text": "all that information is in this GTP header so what the 5G packet core does is it's going to match on all that",
    "start": "179840",
    "end": "185920"
  },
  {
    "text": "information in the header and then it's going to apply policy so all that policy",
    "start": "185920",
    "end": "191200"
  },
  {
    "text": "might be things like applying quality of service or it might be doing n network address translation could even be doing",
    "start": "191200",
    "end": "197480"
  },
  {
    "text": "something like lawful intercept and finally what it's going to do once it's decided how it's going to treat that packet it's going to rewrite",
    "start": "197480",
    "end": "205280"
  },
  {
    "text": "the headers and then send that packet out to the internet and that's how you're browsing the BBC News or whatever",
    "start": "205280",
    "end": "212319"
  },
  {
    "text": "it is from your phone now I'd love to do an example today with a real 5G packet core but",
    "start": "212319",
    "end": "219120"
  },
  {
    "text": "it's far too complicated so what we're going to do today is we're going to use a really simplified version and we're",
    "start": "219120",
    "end": "225400"
  },
  {
    "text": "going to look at the code and we're going to keep iterating that code adding in performance optimization techniques",
    "start": "225400",
    "end": "231519"
  },
  {
    "text": "and measuring what difference they make so here's my simplified example I'm calling it a packet processing device",
    "start": "231519",
    "end": "238519"
  },
  {
    "text": "because I'm not in marketing um so what we're going to do is we're going to match on the header um we're",
    "start": "238519",
    "end": "245640"
  },
  {
    "text": "going to based on that match apply a rewrite policy we're going to rewrite parts of the header so you can see I've",
    "start": "245640",
    "end": "251879"
  },
  {
    "text": "colored in some parts of the header here and not other parts so what we're doing there is some bits of the original",
    "start": "251879",
    "end": "258120"
  },
  {
    "text": "header we want to keep some bits we want to rewrite so let's start simple and",
    "start": "258120",
    "end": "264280"
  },
  {
    "text": "actually look at some code um now I've written all of this code in C hope F",
    "start": "264280",
    "end": "270039"
  },
  {
    "text": "it's pretty self-explanatory that whatever language you work in um you can understand this um and I've actually",
    "start": "270039",
    "end": "276600"
  },
  {
    "text": "even written some comments so it's probably better than most code you're used to looking at yep definitely some software",
    "start": "276600",
    "end": "283440"
  },
  {
    "text": "engineers in the room okay this this is the main function",
    "start": "283440",
    "end": "289280"
  },
  {
    "text": "this is the function that's going to get called every time our device receives a packet it's actually really simple we're",
    "start": "289280",
    "end": "295520"
  },
  {
    "text": "going to get a lookup key from the packet so all that data in the header we're going to build a lookup key from",
    "start": "295520",
    "end": "301280"
  },
  {
    "text": "it next we're going to perform the lookup now I'm starting off really simple here so I'm just using a standard",
    "start": "301280",
    "end": "308479"
  },
  {
    "text": "unordered map from the C standard Library it's going to be really simple based on the result of the lookup",
    "start": "308479",
    "end": "316039"
  },
  {
    "text": "we get a match structure that match structure tells us how we need to rewrite the packet then we're going to call our apply rewrite function and",
    "start": "316039",
    "end": "323199"
  },
  {
    "text": "actually rewrite the packet that's all there is to it it's really simple so how does this perform",
    "start": "323199",
    "end": "329800"
  },
  {
    "text": "so I measured this in a micro Benchmark that I wrote uh it's about 1,000 clocks per packet so we're spending 1,000",
    "start": "329800",
    "end": "336680"
  },
  {
    "text": "clocks to process every single packet now if you remember back to the beginning I said fast has got to be at",
    "start": "336680",
    "end": "343479"
  },
  {
    "text": "least 300 clocks per packet so I'm going to call this slow and that's probably not unsurprising because we haven't done",
    "start": "343479",
    "end": "349800"
  },
  {
    "text": "any work on it yet so let's now start trying to optimize that code bringing in",
    "start": "349800",
    "end": "356280"
  },
  {
    "text": "different techniques um and I know this is the first talk of the day apart from the keynote obviously um so we're going",
    "start": "356280",
    "end": "363120"
  },
  {
    "text": "to start really simple we're going to start with a nice easy one uh something called an inline function um so if we look at this",
    "start": "363120",
    "end": "370639"
  },
  {
    "text": "process packet function um this is a function that is going to be called an",
    "start": "370639",
    "end": "375840"
  },
  {
    "text": "awful lot we said about 10 million packets a second so every second we're",
    "start": "375840",
    "end": "380960"
  },
  {
    "text": "going to be calling this function 10 million times um but what does calling that function actually look like well um",
    "start": "380960",
    "end": "389080"
  },
  {
    "text": "there's the actual interesting work that we want that function to do that's the green box in the middle but there's a",
    "start": "389080",
    "end": "394520"
  },
  {
    "text": "bunch of overhead that comes from that function call as well so for example we're going to have to push the",
    "start": "394520",
    "end": "400160"
  },
  {
    "text": "arguments of the function onto the stack or into registers we're going to have to put the return address onto the stack",
    "start": "400160",
    "end": "405560"
  },
  {
    "text": "we're going to have to jump to the code that we want to execute and then we got to clean up as well we've got to undo",
    "start": "405560",
    "end": "411120"
  },
  {
    "text": "that function call we've got to pop the address back off the stack uh we got to jump back to where we want to execute",
    "start": "411120",
    "end": "417520"
  },
  {
    "text": "we've got to clean up those arguments we push onto the stack and all of those blue boxes they all cost you performance",
    "start": "417520",
    "end": "425039"
  },
  {
    "text": "so if you inline a function you can get rid of all those overheads and you just do the interesting work that you care",
    "start": "425039",
    "end": "432240"
  },
  {
    "text": "about and the good news is it's really easy in your code so varies by language",
    "start": "432240",
    "end": "437759"
  },
  {
    "text": "but in C there's the inline keyword um and then for some reason I've never",
    "start": "437759",
    "end": "443120"
  },
  {
    "text": "figured out that's actually just a recommendation to the compiler so if you actually want your code to inline this",
    "start": "443120",
    "end": "448560"
  },
  {
    "text": "function all the time you need to use the always inline attribute so here we",
    "start": "448560",
    "end": "453639"
  },
  {
    "text": "go we add a little bit to our function definition and we can improve the performance it's not much we haven't",
    "start": "453639",
    "end": "460360"
  },
  {
    "text": "made a massive gain here but we're just getting started bear with",
    "start": "460360",
    "end": "465400"
  },
  {
    "text": "me okay at this point as I was writing this code I was a little surprised that",
    "start": "465479",
    "end": "471879"
  },
  {
    "text": "I wasn't getting better performance than this and that's when I remembered that I really should have turned on compiler",
    "start": "471879",
    "end": "478120"
  },
  {
    "text": "optimizations because um compile the compiler is good at optimizing code we should let it do the",
    "start": "478120",
    "end": "484800"
  },
  {
    "text": "work I would be astonished if everyone in this room didn't compile their code with 03 at least their production code",
    "start": "484800",
    "end": "492800"
  },
  {
    "text": "um does anyone not use 03 no okay um but what about the target",
    "start": "492800",
    "end": "499639"
  },
  {
    "text": "architecture how many people set the target architecture for that code anyone",
    "start": "499639",
    "end": "506280"
  },
  {
    "text": "anyone not do that yeah okay so there's a few hands coming up so what does this do um so in this case I was running my",
    "start": "506280",
    "end": "514120"
  },
  {
    "text": "Benchmark on my laptop there it's got a sky Lake chip in it so I set the target architecture to Skylake and that allows",
    "start": "514120",
    "end": "521518"
  },
  {
    "text": "the compiler to use some additional instructions and the key ones I want to pull out from this list are the ones",
    "start": "521519",
    "end": "526839"
  },
  {
    "text": "that start with AVX so the AVX instructions are the vector instructions so what I'm doing by specifying the targ",
    "start": "526839",
    "end": "533720"
  },
  {
    "text": "architecture is I'm letting the compiler use those AVX instructions and we're",
    "start": "533720",
    "end": "539040"
  },
  {
    "text": "going to look at those in a bit more detail later but they are really good for performance okay I've got one more here",
    "start": "539040",
    "end": "546440"
  },
  {
    "text": "the M branches within 32 byte boundaries how many people use flags like this",
    "start": "546440",
    "end": "551480"
  },
  {
    "text": "compiling their code some some people all right so this is quite a",
    "start": "551480",
    "end": "557079"
  },
  {
    "text": "specific one um there was a bug in Intel chips called jump conditional coder atum",
    "start": "557079",
    "end": "564000"
  },
  {
    "text": "um and Intel fixed that with a mitigation but that mitigation causes uh",
    "start": "564000",
    "end": "569040"
  },
  {
    "text": "the decoded iach to be flushed if your branches are not aligned on 32 by",
    "start": "569040",
    "end": "574519"
  },
  {
    "text": "boundaries um if your decoded iach gets flushed that means you're going to get more iash misses and the performance of",
    "start": "574519",
    "end": "581000"
  },
  {
    "text": "your code is going to go down so in our case on certain Target architectures",
    "start": "581000",
    "end": "587079"
  },
  {
    "text": "this compiler flag gives us about a 7% performance boost I think the general Point here though is there's all kinds",
    "start": "587079",
    "end": "594320"
  },
  {
    "text": "of special compiler Flags like this if you really care about performance have a look at what they is and know know what",
    "start": "594320",
    "end": "600800"
  },
  {
    "text": "your system is so you know what might be useful all right hey turns out the",
    "start": "600800",
    "end": "606839"
  },
  {
    "text": "compiler is really good at optimizing code awesome so we're down to about 400",
    "start": "606839",
    "end": "612120"
  },
  {
    "text": "clocks per packet now we've made a really significant difference there um",
    "start": "612120",
    "end": "617160"
  },
  {
    "text": "but we're still not at our 300 clocks per packet we can still go faster and those of you who are observant will",
    "start": "617160",
    "end": "623399"
  },
  {
    "text": "notice I've got lots more space on this graph to fill in so we're going to keep going",
    "start": "623399",
    "end": "629720"
  },
  {
    "text": "so I mentioned those Vector instructions um as part of enabling the compiler to use them but we can also use Vector",
    "start": "630160",
    "end": "636959"
  },
  {
    "text": "instructions by hand um so what is a vector instruction well a vector",
    "start": "636959",
    "end": "642959"
  },
  {
    "text": "instruction is an example of single instruction multiple data um it's you",
    "start": "642959",
    "end": "649399"
  },
  {
    "text": "something that gpus use which is why they're so good at training AI models so let's have a look at a quick example uh",
    "start": "649399",
    "end": "656639"
  },
  {
    "text": "here's a vector instruction called VP and so this is a vector instruction that",
    "start": "656639",
    "end": "661720"
  },
  {
    "text": "does a logical and on multiple bits of data at the same time um in this case it",
    "start": "661720",
    "end": "667800"
  },
  {
    "text": "operates on vectors and these vectors in the case of avx2 are 256 bits long so we",
    "start": "667800",
    "end": "674440"
  },
  {
    "text": "can pack eight integers into each of those vectors and we can do the a logical and for eight different integers",
    "start": "674440",
    "end": "681639"
  },
  {
    "text": "all at the same time with one instruction to get an answer and again we get the answer in a vector",
    "start": "681639",
    "end": "689720"
  },
  {
    "text": "so how can we use these Vector instructions in our code so let's go back to our code this is the main",
    "start": "689720",
    "end": "695920"
  },
  {
    "text": "function again processing a packet so this apply rewrite function I didn't",
    "start": "695920",
    "end": "701560"
  },
  {
    "text": "expand the details of this before but let's have a look at what that actually looks like um you can see I've used the",
    "start": "701560",
    "end": "707440"
  },
  {
    "text": "inline optimization there already um but what we're doing here is we're going to",
    "start": "707440",
    "end": "713279"
  },
  {
    "text": "Loop over all the 32 bytes in the header for each of those byes we're going to",
    "start": "713279",
    "end": "719040"
  },
  {
    "text": "add and the data with a mask so that's going to keep the bits in the header that we want to keep and zero out the",
    "start": "719040",
    "end": "724600"
  },
  {
    "text": "ones that we don't want to keep and then we're going to or in the bits we want to rewrite so the bits we want to overwrite",
    "start": "724600",
    "end": "730480"
  },
  {
    "text": "on top we're then going to put those in and hopefully you can see here that this",
    "start": "730480",
    "end": "735560"
  },
  {
    "text": "looks like something we could vectorize We're looping over lots of different bits of data and we're performing the",
    "start": "735560",
    "end": "741720"
  },
  {
    "text": "same instruction each time um so how can we use uh Vector instructions to do this",
    "start": "741720",
    "end": "748760"
  },
  {
    "text": "and the answer is we use something called Intel intrinsics so Intel intrinsics are just some functions that",
    "start": "748760",
    "end": "754440"
  },
  {
    "text": "Intel provide which makes it easier uh to use these lowlevel Vector",
    "start": "754440",
    "end": "759480"
  },
  {
    "text": "instructions so what does the code look like now now to be totally honest with",
    "start": "759480",
    "end": "764880"
  },
  {
    "text": "you the first time I saw these in code it absolutely blew my mind um so I'm going to talk through this nice and",
    "start": "764880",
    "end": "771800"
  },
  {
    "text": "slowly so the first thing we're going to do is we're going to load the data from",
    "start": "771800",
    "end": "777120"
  },
  {
    "text": "the packet and we're going to put it um into a vector so Vector instructions",
    "start": "777120",
    "end": "783639"
  },
  {
    "text": "operate on vectors we need to get the memory into a vector then we're going to use an and a",
    "start": "783639",
    "end": "789079"
  },
  {
    "text": "VP and instruction to and the data from the packet with the mask so we're going",
    "start": "789079",
    "end": "794480"
  },
  {
    "text": "to zero the bits we want to rewrite and keep the bits we want to keep then we're going to do an or so",
    "start": "794480",
    "end": "802360"
  },
  {
    "text": "this is where we or in the rewrite value for the bits we want to rewrite and finally the data we've got",
    "start": "802360",
    "end": "808279"
  },
  {
    "text": "is in our vector still so we need to put it back into the memory where the packet is so uh we have to store",
    "start": "808279",
    "end": "816279"
  },
  {
    "text": "it now that was pretty good that was using avx2 instructions we can actually",
    "start": "816519",
    "end": "822760"
  },
  {
    "text": "do even slightly better using AVX 512 so AVX 512 is the next iteration of vector",
    "start": "822760",
    "end": "830360"
  },
  {
    "text": "instructions and they introduce something called Turn logic operations and a turny logic operation lets you do",
    "start": "830360",
    "end": "837720"
  },
  {
    "text": "um binary logic between three arguments at the same time so in this case the the",
    "start": "837720",
    "end": "843160"
  },
  {
    "text": "magic hex 96 good luck working that one out um Means A and B or C um and so that",
    "start": "843160",
    "end": "851480"
  },
  {
    "text": "will probably save us one clock per packet over the avx2 version",
    "start": "851480",
    "end": "857519"
  },
  {
    "text": "so it's slightly better we'll go with that one um so how does that do for",
    "start": "857519",
    "end": "865959"
  },
  {
    "text": "performance ah um I was hoping for a lot better than that we did quite a lot of work there",
    "start": "867240",
    "end": "873120"
  },
  {
    "text": "right um so what's gone wrong um well what's gone wrong is the",
    "start": "873120",
    "end": "879839"
  },
  {
    "text": "compiler is a lot smarter than us it turns out and the compiler is already using those Vector",
    "start": "879839",
    "end": "885519"
  },
  {
    "text": "instructions so here's the code from our rewrite packet function and this is the code from before we vectorized it and in",
    "start": "885519",
    "end": "892519"
  },
  {
    "text": "the Box here you can see the assembly that's been produced um and you can see the the Bold here you can see the",
    "start": "892519",
    "end": "900399"
  },
  {
    "text": "compiler has already decided it's going to implement this using a VP and and a VP or um and",
    "start": "900399",
    "end": "907320"
  },
  {
    "text": "so yeah the compiler's already done the work for us so we get hardly any performance improvement from these",
    "start": "907320",
    "end": "912639"
  },
  {
    "text": "Vector instructions it's not always going to be the case but in this example uh we haven't actually got any benefit",
    "start": "912639",
    "end": "918120"
  },
  {
    "text": "from it okay we're going to have to start working a bit harder now um let's look",
    "start": "918120",
    "end": "924920"
  },
  {
    "text": "at our data structures so at the beginning I said uh we were just using a standard",
    "start": "924920",
    "end": "930519"
  },
  {
    "text": "hashmap um and there's been loads of research done on different data structures to enable fast lookups what",
    "start": "930519",
    "end": "937480"
  },
  {
    "text": "we're going to look at today is a data structure called a Swiss table that Google came up with now um I'm going to",
    "start": "937480",
    "end": "944519"
  },
  {
    "text": "give a really brief um introduction here but there are some really good videos out there on the internet so if you're",
    "start": "944519",
    "end": "950600"
  },
  {
    "text": "interested in this do go look them up because um there's some great presentations on it so how does a Swiss",
    "start": "950600",
    "end": "955759"
  },
  {
    "text": "table work um it's a hash table so we've got a hash um but what we do with that hash is we",
    "start": "955759",
    "end": "961360"
  },
  {
    "text": "split it into two different bits so we've got an H1 value which is the first part of the hash and we've got an H2",
    "start": "961360",
    "end": "967000"
  },
  {
    "text": "value which is the second part of the hash um what the H1 value does is it",
    "start": "967000",
    "end": "972639"
  },
  {
    "text": "identifies a group and that group does two things first of all it tells us which bucket our entry is going to be in",
    "start": "972639",
    "end": "979480"
  },
  {
    "text": "the actual thing we want to find and the second thing it does is it points us to a metadata array now this metadata array",
    "start": "979480",
    "end": "986600"
  },
  {
    "text": "is one of the key things here that contains s the packed values of all the H2 hash values of the entries that we've",
    "start": "986600",
    "end": "994160"
  },
  {
    "text": "put in to the bucket um and so what we do then with our H2 hash value is we look in the",
    "start": "994160",
    "end": "1001600"
  },
  {
    "text": "metadata array find which one matches and then that lets us jump straight to our correct entry and whenever you're",
    "start": "1001600",
    "end": "1009079"
  },
  {
    "text": "talking about a lookup and someone says jump straight to that is a good thing so let's have a little look at",
    "start": "1009079",
    "end": "1017160"
  },
  {
    "text": "what's going on just kind of Simply because it is I've gone very quickly through that what what we're doing here",
    "start": "1017160",
    "end": "1023160"
  },
  {
    "text": "is number one we calculate a hash number two we get the metadata",
    "start": "1023160",
    "end": "1028400"
  },
  {
    "text": "array based on the value of H1 number three we go through that metadata array",
    "start": "1028400",
    "end": "1033760"
  },
  {
    "text": "comparing the H2 hash value with the different metadata um values um and then",
    "start": "1033760",
    "end": "1039520"
  },
  {
    "text": "depending on which one matches we jump straight to the entry so why is this good why is this",
    "start": "1039520",
    "end": "1046038"
  },
  {
    "text": "going to be more performant than our standard hashmap um well first of all it's really cache",
    "start": "1046039",
    "end": "1051679"
  },
  {
    "text": "efficient so in this implementation we've only got two memory IND directions",
    "start": "1051679",
    "end": "1057039"
  },
  {
    "text": "we've got one memory in direction to find the metadata array and then we've got one memory in direction to actually",
    "start": "1057039",
    "end": "1062440"
  },
  {
    "text": "get the entry um and that's going to be significantly better than a standard",
    "start": "1062440",
    "end": "1067520"
  },
  {
    "text": "hashmap now the second thing that's good about this is we're doing our probing of",
    "start": "1067520",
    "end": "1073919"
  },
  {
    "text": "entries using these H2 hash values so in the mainline case we don't have to",
    "start": "1073919",
    "end": "1079200"
  },
  {
    "text": "compare key values apart from for the final entry that we find um and the other good thing about this is that",
    "start": "1079200",
    "end": "1086320"
  },
  {
    "text": "packed metadata array if I just jump back a couple of slides 16 entries in",
    "start": "1086320",
    "end": "1091640"
  },
  {
    "text": "there we're doing the same operation with lots of different bits of data and",
    "start": "1091640",
    "end": "1097000"
  },
  {
    "text": "so we've already talked about Vector instructions you can do that comparison really really efficiently by using",
    "start": "1097000",
    "end": "1102960"
  },
  {
    "text": "Vector instructions and so you spend very little time probing your entries",
    "start": "1102960",
    "end": "1109280"
  },
  {
    "text": "so let's look at the code what does it look like um it actually looks really similar to The Standard hashmap um we're",
    "start": "1109280",
    "end": "1115640"
  },
  {
    "text": "going to extract the lookup key I've got a slightly different format lookup key just because of the Swiss table implementation I used um we're then",
    "start": "1115640",
    "end": "1123000"
  },
  {
    "text": "going to perform the lookup um I'm not cheating here I'm using exactly the same",
    "start": "1123000",
    "end": "1128080"
  },
  {
    "text": "hash function which is a significant part of the cost so I've used the same hash function so it's it's all fair um",
    "start": "1128080",
    "end": "1134159"
  },
  {
    "text": "and then we're going to apply the rewrite exactly the same as before um",
    "start": "1134159",
    "end": "1139280"
  },
  {
    "text": "does this lookup do any better though and the answer is yes it does it does significantly better so we're dropping",
    "start": "1139280",
    "end": "1145679"
  },
  {
    "text": "from about 400 clocks to packet to about 300 clocks per packet so we're getting a",
    "start": "1145679",
    "end": "1151720"
  },
  {
    "text": "really good performance Boost from using this new data",
    "start": "1151720",
    "end": "1156120"
  },
  {
    "text": "structure okay moving on to the next one we're starting to have to work really hard now this is the point of the",
    "start": "1158120",
    "end": "1164640"
  },
  {
    "text": "presentation where everyone has to start paying attention because it's going to get more difficult",
    "start": "1164640",
    "end": "1170480"
  },
  {
    "text": "um good every it's still early in the morning everyone's ready um so inter leave processing is the next thing so I",
    "start": "1170480",
    "end": "1177559"
  },
  {
    "text": "talked a little bit on the Swiss table about how cash efficiency was really important um and with this uh",
    "start": "1177559",
    "end": "1184679"
  },
  {
    "text": "interleaving technique we're going to look at that in more detail",
    "start": "1184679",
    "end": "1189880"
  },
  {
    "text": "so when your program is getting memory you you can't get that memory immediately there's a memory latency and",
    "start": "1189880",
    "end": "1197240"
  },
  {
    "text": "the memory latency that you have have depends on where you're getting that memory from so if you get the memory",
    "start": "1197240",
    "end": "1202840"
  },
  {
    "text": "from L1 cach it's really fast but L1 cach is Tiny you can't put very much",
    "start": "1202840",
    "end": "1208080"
  },
  {
    "text": "stuff in there if you get your memory from Main Ram it's really slow uh the",
    "start": "1208080",
    "end": "1214799"
  },
  {
    "text": "200 clocks there approximately um is going to blow our budget of 300 clocks",
    "start": "1214799",
    "end": "1220640"
  },
  {
    "text": "but Ram's massive you can keep loads of data in there um what we're going to do with inter",
    "start": "1220640",
    "end": "1227000"
  },
  {
    "text": "leaving is look at how we can minimize the effects of this memory access latency so let's look at let's look at",
    "start": "1227000",
    "end": "1233000"
  },
  {
    "text": "an example so our packet processing what are we doing is we're going through processing this packet um we're going to",
    "start": "1233000",
    "end": "1239440"
  },
  {
    "text": "process packet one for a bit we're then going to get to the point where we need a bit of memory which we don't have hot",
    "start": "1239440",
    "end": "1245200"
  },
  {
    "text": "in Cache so we're going to store for a bit we call it a memory store while waiting for the memory and then we can",
    "start": "1245200",
    "end": "1250480"
  },
  {
    "text": "carry on processing packet one and then we start processing the next packet so now packet two and",
    "start": "1250480",
    "end": "1256200"
  },
  {
    "text": "exactly the same thing happens we get to the point where we need the memory we don't have we have a memory store we",
    "start": "1256200",
    "end": "1262080"
  },
  {
    "text": "wait for a bit we get the memory we can continue processing so now let's look at this",
    "start": "1262080",
    "end": "1267320"
  },
  {
    "text": "with inter leaving applied so with interleaving we're going to start processing packet one we're going to get",
    "start": "1267320",
    "end": "1274080"
  },
  {
    "text": "to the point where we need some memory that we know is not going to be in Cache now instead of continuing processing",
    "start": "1274080",
    "end": "1280080"
  },
  {
    "text": "packet one we're instead going to issue a prefet instruction for the memory now what this does is it goes and uh goes",
    "start": "1280080",
    "end": "1287159"
  },
  {
    "text": "and gets that memory and puts into L1 cache and instead of carrying on processing packet one we're going to",
    "start": "1287159",
    "end": "1293640"
  },
  {
    "text": "start on packet two so packet two is independent we can start processing that",
    "start": "1293640",
    "end": "1299120"
  },
  {
    "text": "um and similarly to packet one once we get to the end of that first bit processing when we get to the point we",
    "start": "1299120",
    "end": "1304279"
  },
  {
    "text": "need some more memory we're going to prefetch that memory and then we're going to go stop and do something else",
    "start": "1304279",
    "end": "1310200"
  },
  {
    "text": "now by this point the memory that we need for packet one is going to have made into L1 cache and is going to be",
    "start": "1310200",
    "end": "1316480"
  },
  {
    "text": "nice and hot so we can just finish packet one processing now we don't have to wait we don't have that memory stall",
    "start": "1316480",
    "end": "1322240"
  },
  {
    "text": "anymore and then we can do exactly the same for packet two because while we",
    "start": "1322240",
    "end": "1327400"
  },
  {
    "text": "were finishing processing packet one we've given time for the memory to get into L1 cache and what that means is we",
    "start": "1327400",
    "end": "1334039"
  },
  {
    "text": "end up saving significant amounts of time because we're not suffering these memory",
    "start": "1334039",
    "end": "1340799"
  },
  {
    "text": "stores now it's worth saying I've significantly simplified this picture um",
    "start": "1341120",
    "end": "1347480"
  },
  {
    "text": "so the execution unit is going to be doing a bunch of stuff to try and stop",
    "start": "1347480",
    "end": "1352880"
  },
  {
    "text": "your memory s your program suffering memory stores like this so it's going to be using parallel instructions it's",
    "start": "1352880",
    "end": "1359480"
  },
  {
    "text": "going to be using outof order execution it's going to be using pipelining um and all those techniques",
    "start": "1359480",
    "end": "1365520"
  },
  {
    "text": "that's very similar to what we're doing with inter leaving the thing is with inter leing we the program writer know",
    "start": "1365520",
    "end": "1372159"
  },
  {
    "text": "exactly what our codee's doing we know the intent of it and therefore we can do an even better job than the execution",
    "start": "1372159",
    "end": "1378760"
  },
  {
    "text": "can do so let's have a look at what that looks like in the code so this this is",
    "start": "1378760",
    "end": "1384360"
  },
  {
    "text": "the bit where everyone has to start paying attention so our main function is now no longer process packet we're now going to",
    "start": "1384360",
    "end": "1392000"
  },
  {
    "text": "process a burst of packets so for this example I've used a burst size of 20 so",
    "start": "1392000",
    "end": "1397039"
  },
  {
    "text": "we're going to take 20 packets at a time and process 20 packets in a",
    "start": "1397039",
    "end": "1402400"
  },
  {
    "text": "chunk we're going to Loop over all the packets in that burst we're going to Loop over those 20 packets and we're",
    "start": "1402400",
    "end": "1409039"
  },
  {
    "text": "going to start doing the processing in exactly the same way as we had for our previous bit of code we're going to",
    "start": "1409039",
    "end": "1415400"
  },
  {
    "text": "number one extract a lookup key and then number two calculate the hash for the packet that we're going to need but this",
    "start": "1415400",
    "end": "1422440"
  },
  {
    "text": "is then where it changes instead of actually going and doing the lookup this is the point where we know that memory",
    "start": "1422440",
    "end": "1429520"
  },
  {
    "text": "that we need for the lookup is not going to be hot in cach and so instead of actually doing the lookup we're just",
    "start": "1429520",
    "end": "1434960"
  },
  {
    "text": "going to prefetch it so this this is actually prefetching that metadata array for the Swiss table so we'll prefetch",
    "start": "1434960",
    "end": "1442080"
  },
  {
    "text": "that metadata array and then we'll carry on and we'll go through and process the",
    "start": "1442080",
    "end": "1448440"
  },
  {
    "text": "other 19 packets in our burst and then we get to the next bit of code so the next bit of code we're going",
    "start": "1448440",
    "end": "1455080"
  },
  {
    "text": "to start looping again and at this point we're going to actually do the lookup",
    "start": "1455080",
    "end": "1460279"
  },
  {
    "text": "this is where we actually do our lookup now if we think about packet number one",
    "start": "1460279",
    "end": "1465840"
  },
  {
    "text": "in the burst packet number one had we calculated the hash value we",
    "start": "1465840",
    "end": "1471039"
  },
  {
    "text": "built the lookup key calculated the hash value we've then issued the instruction to get the memory we need for the the",
    "start": "1471039",
    "end": "1477440"
  },
  {
    "text": "lookup and in the meantime we've gone and extracted a lookup key and calculated a hash value for the other 19",
    "start": "1477440",
    "end": "1484440"
  },
  {
    "text": "packets in that burst so by this point our memory is going to be nice and hot",
    "start": "1484440",
    "end": "1489919"
  },
  {
    "text": "in L1 cache and this lookup can be nice and fast and if only it stopped there",
    "start": "1489919",
    "end": "1496799"
  },
  {
    "text": "because the same idea keeps going throughout the code so now you can see I'm not just going to move on to doing",
    "start": "1496799",
    "end": "1503000"
  },
  {
    "text": "the rewrite next what I'm going to do is I'm going to prefetch the next bit of",
    "start": "1503000",
    "end": "1508159"
  },
  {
    "text": "data that I need so in this case it's the match structure the thing that's going to tell me what how I'm going to rewrite I'll prefetch that um and I'm",
    "start": "1508159",
    "end": "1515840"
  },
  {
    "text": "not going to keep showing the rest of the code but the rest of the code keeps going in this pattern where we just do a little bit of work on each packet and",
    "start": "1515840",
    "end": "1522919"
  },
  {
    "text": "then prefet memory need and then move on um",
    "start": "1522919",
    "end": "1528919"
  },
  {
    "text": "and you can see this has an enormous impact on performance so we've gone from about 300 clocks per packet which we",
    "start": "1528919",
    "end": "1535640"
  },
  {
    "text": "thought was pretty good we're now at 80 clocks per packet um and the key",
    "start": "1535640",
    "end": "1540679"
  },
  {
    "text": "takeaway from this is that memory and accessing memory is expensive so if you",
    "start": "1540679",
    "end": "1547000"
  },
  {
    "text": "want to speed up your code um techniques like a Swiss table which are cash",
    "start": "1547000",
    "end": "1552200"
  },
  {
    "text": "efficient and techniques that stop you having memory stores are really powerful",
    "start": "1552200",
    "end": "1557320"
  },
  {
    "text": "techniques for improving your performance all right so we could rest",
    "start": "1557320",
    "end": "1563240"
  },
  {
    "text": "on our Laurels here and stop we've still got one more space to fill on our graph",
    "start": "1563240",
    "end": "1568440"
  },
  {
    "text": "so let's keep going uh we're going to use a technique called Loop unrolling",
    "start": "1568440",
    "end": "1574399"
  },
  {
    "text": "next so let's have a quick look um at what our code looks like now so after we",
    "start": "1574399",
    "end": "1581760"
  },
  {
    "text": "did our into leaving our code looks a lot like this we have lots of these Loops where we evaluate an end of loop",
    "start": "1581760",
    "end": "1589440"
  },
  {
    "text": "condition and then increment or decrement an index and all of that costs",
    "start": "1589440",
    "end": "1595399"
  },
  {
    "text": "right we're not getting that for free we've got to do some work to do that Loop unrolling looks at reducing the",
    "start": "1595399",
    "end": "1601360"
  },
  {
    "text": "cost of these Loop overheads so instead of doing one big loop where uh every",
    "start": "1601360",
    "end": "1607399"
  },
  {
    "text": "time round we we're processing the next packet we're going to do a smaller Loop",
    "start": "1607399",
    "end": "1613360"
  },
  {
    "text": "where each time round we're going to do two packets or three packets or four packets",
    "start": "1613360",
    "end": "1619360"
  },
  {
    "text": "um so what this does in this case I've Loop unrolled to a factor of two so each",
    "start": "1619360",
    "end": "1625000"
  },
  {
    "text": "time round we're going to process two packets so in the best case here where we have an even number of packets I'm",
    "start": "1625000",
    "end": "1631080"
  },
  {
    "text": "going to have halved um the cost of evaluating my end of loop condition uh",
    "start": "1631080",
    "end": "1636159"
  },
  {
    "text": "and incrementing or decrementing my index um the other good thing about Loop",
    "start": "1636159",
    "end": "1641679"
  },
  {
    "text": "and rolling is I've now got this bit of code in the Middle where I'm doing an operation on packet one and then doing",
    "start": "1641679",
    "end": "1647200"
  },
  {
    "text": "an operation on packet two too and those operations are often going to be",
    "start": "1647200",
    "end": "1652679"
  },
  {
    "text": "independent because I've now got them next to each other the execution unit is going to be able to use parallel",
    "start": "1652679",
    "end": "1658760"
  },
  {
    "text": "instructions to hopefully improve the performance of this even further so let's have a look at what our",
    "start": "1658760",
    "end": "1666519"
  },
  {
    "text": "code looks like and I mean quite frankly it's horrible isn't it um if you sent this to me for",
    "start": "1666519",
    "end": "1673640"
  },
  {
    "text": "review I'd probably send it back to you um let's have a look at it and see what",
    "start": "1673640",
    "end": "1678760"
  },
  {
    "text": "it actually is doing so you can see here I've Loop unrolled to a factor of four",
    "start": "1678760",
    "end": "1684120"
  },
  {
    "text": "so I'm doing four packets each time through the loop um but actually the",
    "start": "1684120",
    "end": "1691360"
  },
  {
    "text": "code is very similar to what we had before we're extracting the lookup key all we're doing is we're extracting the",
    "start": "1691360",
    "end": "1698000"
  },
  {
    "text": "lookup key four different times for four different packets we're then calculating the hash but again we're calculating the",
    "start": "1698000",
    "end": "1704559"
  },
  {
    "text": "hash four times for four different packets and then finally we're doing our prefetching of that Swiss table memory",
    "start": "1704559",
    "end": "1711120"
  },
  {
    "text": "that we need for four times through um I'm not going to show more of",
    "start": "1711120",
    "end": "1717880"
  },
  {
    "text": "the code because it it carries on in this Fame the the other thing to note though is um we can't guarantee a burst",
    "start": "1717880",
    "end": "1724880"
  },
  {
    "text": "has a multiple of four packets in and so we also have to write even more code which is really a repeat of the previous",
    "start": "1724880",
    "end": "1731840"
  },
  {
    "text": "code um uh to handle if you know if there was a an odd number of packets in",
    "start": "1731840",
    "end": "1737559"
  },
  {
    "text": "the burst but does have a good effect on",
    "start": "1737559",
    "end": "1744240"
  },
  {
    "text": "performance so we're now down to 65 clocks per packet and this looks really small on this graph it looks like a",
    "start": "1744240",
    "end": "1750880"
  },
  {
    "text": "really small difference but this is going from 80 clocks to 65 and when you're only down to 80 clocks gaining 15",
    "start": "1750880",
    "end": "1758720"
  },
  {
    "text": "is a really significant boost in performance so this is actually a big win",
    "start": "1758720",
    "end": "1764760"
  },
  {
    "text": "here all right let's pause there take a minute to look at what we've",
    "start": "1765559",
    "end": "1771600"
  },
  {
    "text": "achieved 16 times faster so from our starting point of a th000 clocks per",
    "start": "1771600",
    "end": "1777200"
  },
  {
    "text": "packet we're now 16 times faster at just 65 clocks per packet and that's all from",
    "start": "1777200",
    "end": "1783399"
  },
  {
    "text": "applying these six different techniques now I can see people getting",
    "start": "1783399",
    "end": "1790600"
  },
  {
    "text": "up at the back hopefully they've all rushed off to go and implement this in their code immediately ra rather than",
    "start": "1790600",
    "end": "1796600"
  },
  {
    "text": "just getting a bit bored um but but wait come back come back um",
    "start": "1796600",
    "end": "1802559"
  },
  {
    "text": "before you go there's there's a there's a a kick a",
    "start": "1802559",
    "end": "1807600"
  },
  {
    "text": "caveat um if you implement all those techniques it might not always give you",
    "start": "1807600",
    "end": "1813000"
  },
  {
    "text": "a performance boost um and that's because there are tradeoffs and I've",
    "start": "1813000",
    "end": "1818360"
  },
  {
    "text": "kept things simple through this talk up until now and I haven't talked about the tradeoffs so let's look at a few",
    "start": "1818360",
    "end": "1824679"
  },
  {
    "text": "examples of that now because these are things you need to be aware of if you're going to do this to your code the first",
    "start": "1824679",
    "end": "1830360"
  },
  {
    "text": "one is instruction cache misses um so if you use techniques like inlining or Loop",
    "start": "1830360",
    "end": "1836559"
  },
  {
    "text": "unrolling they make your code bigger in lining with putting that copy of the function in every place it's called from",
    "start": "1836559",
    "end": "1843360"
  },
  {
    "text": "um Loop unrolling where you've seen how much more code we wrote for that um that",
    "start": "1843360",
    "end": "1848679"
  },
  {
    "text": "increases the size of your program that makes you more likely to get instruction cache misses um if you get instruction",
    "start": "1848679",
    "end": "1856200"
  },
  {
    "text": "cache misses it can slow your code down um as an example in my team we've",
    "start": "1856200",
    "end": "1862000"
  },
  {
    "text": "actually removed most of the loop and rolling we used to have in our code because we found it actually improved performance to get rid of most of it",
    "start": "1862000",
    "end": "1869159"
  },
  {
    "text": "because we think of the instruction cache um another one cach eviction so if",
    "start": "1869159",
    "end": "1875399"
  },
  {
    "text": "you prefetch too much memory that L1 cache is only really small if you're not",
    "start": "1875399",
    "end": "1881279"
  },
  {
    "text": "careful you can prefetch the memory and then before you actually get round to using it you've prefetched a load more",
    "start": "1881279",
    "end": "1887919"
  },
  {
    "text": "memory which has kicked it out and it's not in cash anymore but you did work to to get there um that's not going to be",
    "start": "1887919",
    "end": "1894320"
  },
  {
    "text": "good for performance either so again we've actually removed some of our prefetching and and maybe just prefetch",
    "start": "1894320",
    "end": "1900760"
  },
  {
    "text": "into L3 cach in order to to trade off the these benefits um AVX throttling another one",
    "start": "1900760",
    "end": "1908919"
  },
  {
    "text": "so when you use AVX 512 instructions they can be really fast",
    "start": "1908919",
    "end": "1914399"
  },
  {
    "text": "we've seen how they can improve performance um but if you use AVX 512 instructions heavily it actually slows",
    "start": "1914399",
    "end": "1921519"
  },
  {
    "text": "down your CPU clock speed and slowing down your CPU clock speed is not good for",
    "start": "1921519",
    "end": "1928240"
  },
  {
    "text": "performance and finally um code maintainability so I just illustrate",
    "start": "1928240",
    "end": "1933559"
  },
  {
    "text": "this with a quick snapshot please don't try and read any of this um of what the",
    "start": "1933559",
    "end": "1938880"
  },
  {
    "text": "codes look like on on the simple code that's what we started with our main function had like three function calls",
    "start": "1938880",
    "end": "1944440"
  },
  {
    "text": "in it um it was more comment than code inter blew that up significantly um",
    "start": "1944440",
    "end": "1950720"
  },
  {
    "text": "unrolling blew that up enormously um that unrolled code it",
    "start": "1950720",
    "end": "1956919"
  },
  {
    "text": "might be better in some languages but in C it's absolutely horrible to",
    "start": "1956919",
    "end": "1962360"
  },
  {
    "text": "maintain so those of you who are paying attention might have noticed I said",
    "start": "1963120",
    "end": "1968399"
  },
  {
    "text": "seven techniques at the beginning and I only talked about six in the previous slide so that brings me to the last",
    "start": "1968399",
    "end": "1975240"
  },
  {
    "text": "technique which is actually what we've been doing all the way through which is benchmarking if you care about",
    "start": "1975240",
    "end": "1981159"
  },
  {
    "text": "performance benchmarking is really really important you have to be measuring your performance iterating on",
    "start": "1981159",
    "end": "1988320"
  },
  {
    "text": "it and then measuring it again in order to keep making those",
    "start": "1988320",
    "end": "1992960"
  },
  {
    "text": "improvements okay so everyone's here to learn something so",
    "start": "1997480",
    "end": "2003639"
  },
  {
    "text": "what can you learn from this session should you go and rewrite all of your code",
    "start": "2003639",
    "end": "2008840"
  },
  {
    "text": "um I hope everyone here has picked up some techniques that you might find useful but what I actually want to",
    "start": "2008840",
    "end": "2015559"
  },
  {
    "text": "finish with is is getting you to ask the question of whether you should use these",
    "start": "2015559",
    "end": "2020919"
  },
  {
    "text": "techniques or whether you shouldn't um so this is my attempt a single slide to",
    "start": "2020919",
    "end": "2027159"
  },
  {
    "text": "summarize what can you learn from the fastest code in the",
    "start": "2027159",
    "end": "2032200"
  },
  {
    "text": "world so what do we have here we uh we've got a a graph where on the left",
    "start": "2032200",
    "end": "2038960"
  },
  {
    "text": "here we've got techniques that are really simple to implement they don't take much time they're relatively simple",
    "start": "2038960",
    "end": "2045080"
  },
  {
    "text": "on the right it goes to complex techniques things which are hard to implement things that which which take",
    "start": "2045080",
    "end": "2050118"
  },
  {
    "text": "time they're bad for maintainability on the ya AIS we're going from low impact techniques at the",
    "start": "2050119",
    "end": "2056000"
  },
  {
    "text": "bottom to high impact techniques at the top things that have a really big impact on your performance so let's look at the",
    "start": "2056000",
    "end": "2062520"
  },
  {
    "text": "different quadrants so this quadrant in the top left corner these are things which are pretty easy to implement and",
    "start": "2062520",
    "end": "2069599"
  },
  {
    "text": "have a really high impact on performance you should all just go and use these it's a no-brainer",
    "start": "2069599",
    "end": "2077520"
  },
  {
    "text": "um might be a few people going data structures was that easy that that",
    "start": "2077520",
    "end": "2083679"
  },
  {
    "text": "looked like he wrote a load of code in the background to implement the Swiss table and you're right I did write a load of code in the background to",
    "start": "2083679",
    "end": "2089878"
  },
  {
    "text": "implement the Swiss table but actually um in most languages now you can use",
    "start": "2089879",
    "end": "2096000"
  },
  {
    "text": "these data structures for free so mentioned Google came up with this so if you write in C or C++ you can use the",
    "start": "2096000",
    "end": "2102359"
  },
  {
    "text": "abale project which Google have open sourced um you can use a flat hashmap uh",
    "start": "2102359",
    "end": "2108000"
  },
  {
    "text": "which is a Swiss table um for those of you who write in Rust I found out the other day that the rust default hashmap",
    "start": "2108000",
    "end": "2115480"
  },
  {
    "text": "implementation actually uses a Swiss table under the covers already so you may even be using some of these data",
    "start": "2115480",
    "end": "2121839"
  },
  {
    "text": "structures without knowing it already Tech techniques that fall in",
    "start": "2121839",
    "end": "2128839"
  },
  {
    "text": "these diagonal quadrants so things which are easy low impact but really simple to implement or high impact but quite hard",
    "start": "2128839",
    "end": "2136640"
  },
  {
    "text": "these are the ones you need to think about these are the ones where it might be worth doing this but uh it might not",
    "start": "2136640",
    "end": "2144040"
  },
  {
    "text": "and here you have to think about efficiency in the broader sense how much is it going to cost me to develop this",
    "start": "2144040",
    "end": "2150760"
  },
  {
    "text": "how much is it going to cost me to maintain this how much is my code going to be deployed is its runtime performance Ben",
    "start": "2150760",
    "end": "2157640"
  },
  {
    "text": "benefit going to be worth the extra effort I put into developing it and so",
    "start": "2157640",
    "end": "2163000"
  },
  {
    "text": "probably you're not going to use these unless you have an application that performance really matters or where it's",
    "start": "2163000",
    "end": "2170200"
  },
  {
    "text": "really widely deployed or or maybe this is something where if you're writing a green field project from scratch you",
    "start": "2170200",
    "end": "2176160"
  },
  {
    "text": "would try and use some of these but you're not going to go and rewrite all your existing code to try and add these",
    "start": "2176160",
    "end": "2182839"
  },
  {
    "text": "in and finally there's the stuff that is both relatively low impact and complex",
    "start": "2182839",
    "end": "2190720"
  },
  {
    "text": "quite frankly you just shouldn't ever bother with doing",
    "start": "2190720",
    "end": "2195520"
  },
  {
    "text": "this all right so that is my final slide",
    "start": "2196480",
    "end": "2201640"
  },
  {
    "text": "for um summarizing what can you learn from the fastest code in the",
    "start": "2201640",
    "end": "2206760"
  },
  {
    "text": "world um please do vote and leave feedback we've now got some time for questions so",
    "start": "2206760",
    "end": "2213640"
  },
  {
    "text": "if anyone's got a question please stick your hand up and we'll get mic",
    "start": "2213640",
    "end": "2219519"
  },
  {
    "text": "yes hi uh what is your view on Frameworks that will automate uh the",
    "start": "2226599",
    "end": "2231800"
  },
  {
    "text": "generation of this super optimized code H sorry I didn't see that question was it ah sorry here now what is your view",
    "start": "2231800",
    "end": "2238640"
  },
  {
    "text": "on Frameworks that will automatically generate uh all the of this highly optimized code so the question was",
    "start": "2238640",
    "end": "2245280"
  },
  {
    "text": "what's my view on Frameworks that would generate this highly optimized code um",
    "start": "2245280",
    "end": "2251160"
  },
  {
    "text": "automatically based on benchmarks that will run automatically for you on so so",
    "start": "2251160",
    "end": "2256800"
  },
  {
    "text": "I haven't found any Frameworks that will automatically generate this code that performs at this level that we've got to",
    "start": "2256800",
    "end": "2263040"
  },
  {
    "text": "here um if you know Frameworks that can do that I'd love to hear about them yeah",
    "start": "2263040",
    "end": "2268680"
  },
  {
    "text": "there are few in Academia but indeed not in the",
    "start": "2268680",
    "end": "2274599"
  },
  {
    "text": "okay hey uh I wanted to ask about the the prefetch stuff like how do you know",
    "start": "2275680",
    "end": "2281240"
  },
  {
    "text": "that the prefetch is um is finished are you like going through and actually counting instructions isn't it kind of",
    "start": "2281240",
    "end": "2287200"
  },
  {
    "text": "fragile and I guess similar question for the cash thrashing problem like you have",
    "start": "2287200",
    "end": "2293000"
  },
  {
    "text": "to tune some parameters to know whether you're thrashing the cach or not um doesn't it all get kind of fragile when",
    "start": "2293000",
    "end": "2298960"
  },
  {
    "text": "like compilers change like how does that actually work yes so uh just repeating",
    "start": "2298960",
    "end": "2304119"
  },
  {
    "text": "it so it's on the recording there's a couple of questions there one is about how do you know prefetching like how do",
    "start": "2304119",
    "end": "2309520"
  },
  {
    "text": "you know when you've waited long enough do you have to count the cycles and then also some follow on questions about thrashing the cash um so certainly in",
    "start": "2309520",
    "end": "2316680"
  },
  {
    "text": "our code we don't count the Cycles we essentially pipeline all of our code so",
    "start": "2316680",
    "end": "2322640"
  },
  {
    "text": "that um we're pretty sure that by the time we need the memory it's going to be",
    "start": "2322640",
    "end": "2327800"
  },
  {
    "text": "there um one of the things I didn't go into the talk in detail because we didn't have time but there are some",
    "start": "2327800",
    "end": "2333839"
  },
  {
    "text": "great tools out there where if you are running performance Ben mark you can get lots of information about whether you",
    "start": "2333839",
    "end": "2340440"
  },
  {
    "text": "are seeing memory stores so we use vune I don't know if other people use that as well but that's a really powerful tool",
    "start": "2340440",
    "end": "2346359"
  },
  {
    "text": "for telling you if you are hitting memory stores and then allowing you to iterate um the the thing I would say is",
    "start": "2346359",
    "end": "2352480"
  },
  {
    "text": "this really illustrates the uh the point of performance benchmarking so if you don't have um regressive performance",
    "start": "2352480",
    "end": "2359760"
  },
  {
    "text": "tests that run as part of your CI Suites then yes it's very fragile because you",
    "start": "2359760",
    "end": "2366480"
  },
  {
    "text": "can regress perform performance really easily um so one of the key things that we do is we invest heavily in in that",
    "start": "2366480",
    "end": "2373960"
  },
  {
    "text": "cicd uh performance regression so every time any code goes into main it's running performance tests and if they",
    "start": "2373960",
    "end": "2379720"
  },
  {
    "text": "don't pass the code doesn't go in question",
    "start": "2379720",
    "end": "2386640"
  },
  {
    "text": "front hi uh brilliant talk thank you so much um I have one small question so",
    "start": "2386640",
    "end": "2392599"
  },
  {
    "text": "here the seventh uh mentioned technique was benchmarking however I believe there's like a",
    "start": "2392599",
    "end": "2398079"
  },
  {
    "text": "uh law in physics that says if I'm measuring something then I'm affecting it so um what's your point on that like",
    "start": "2398079",
    "end": "2407079"
  },
  {
    "text": "um how is it improving us instead of improving the performance instead of uh",
    "start": "2407079",
    "end": "2412119"
  },
  {
    "text": "regressing it yeah good good question so the question was about um if we measure",
    "start": "2412119",
    "end": "2417240"
  },
  {
    "text": "something then we affect it so if we're doing benchmarking how do we know we're not affecting performance um the the answer is from my",
    "start": "2417240",
    "end": "2425839"
  },
  {
    "text": "opinion you have to do lots of of different types of benchmarking so in the example that I've gone through",
    "start": "2425839",
    "end": "2431720"
  },
  {
    "text": "throughout this talk we've really been doing a kind of micro benchmarking so I built an infrastructure around the code",
    "start": "2431720",
    "end": "2437800"
  },
  {
    "text": "and counted the clock Cycles uh for looping over at lots of different times",
    "start": "2437800",
    "end": "2443400"
  },
  {
    "text": "um we saw a really good performance improvement from Loop unrolling um I think if you put that in",
    "start": "2443400",
    "end": "2450160"
  },
  {
    "text": "a bigger application you wouldn't see the same performance improvement from Loop un rolling because you would start",
    "start": "2450160",
    "end": "2455480"
  },
  {
    "text": "having problems with iach um and when we're just using our micro Benchmark you don't have any problems",
    "start": "2455480",
    "end": "2461720"
  },
  {
    "text": "with iach because it's just a small program so uh if you measure things in different",
    "start": "2461720",
    "end": "2468839"
  },
  {
    "text": "ways so you have Micro benchmarks where you can iterate quickly um and very",
    "start": "2468839",
    "end": "2473880"
  },
  {
    "text": "quickly turn around performance changes and try things out but then also have on",
    "start": "2473880",
    "end": "2479079"
  },
  {
    "text": "the other end of the scale performance tests where you testing really the whole solution and seeing does it work end to",
    "start": "2479079",
    "end": "2484920"
  },
  {
    "text": "end then the combination of those help mitigate some of those",
    "start": "2484920",
    "end": "2490599"
  },
  {
    "text": "problems okay any more",
    "start": "2491319",
    "end": "2494920"
  },
  {
    "text": "questions H hello um in high level programming languages normally I mostly",
    "start": "2499079",
    "end": "2505000"
  },
  {
    "text": "use C you don't have this level of control of the optimization so which",
    "start": "2505000",
    "end": "2510800"
  },
  {
    "text": "could be a a good strategy if I have something that need to be very performant",
    "start": "2510800",
    "end": "2517400"
  },
  {
    "text": "uh so the question is if you're using higher level languages and you don't have this level of control uh what can",
    "start": "2517400",
    "end": "2523160"
  },
  {
    "text": "you do about it um so I think it",
    "start": "2523160",
    "end": "2531280"
  },
  {
    "text": "think I think it probably depends on which higher level language you use so um rust is something I use a little bit",
    "start": "2531280",
    "end": "2538599"
  },
  {
    "text": "um and I think rust does actually have ways of calling Intel intrinsics directly from rust for example um I'm",
    "start": "2538599",
    "end": "2545920"
  },
  {
    "text": "not I'm not familiar with so up um I think probably when you start a project",
    "start": "2545920",
    "end": "2550960"
  },
  {
    "text": "you've got to make a decision about what language you use um and if you're really looking for something fast and efficient",
    "start": "2550960",
    "end": "2557440"
  },
  {
    "text": "um you choose an you choose an appropriate language yeah you're not going to use Java or C",
    "start": "2557440",
    "end": "2564520"
  },
  {
    "text": "yeah any more questions okay",
    "start": "2567960",
    "end": "2574640"
  },
  {
    "text": "um so I have a question um you've put the benchmarking part on the seventh",
    "start": "2577760",
    "end": "2584079"
  },
  {
    "text": "step um as you told um in in the end you need to do",
    "start": "2584079",
    "end": "2591119"
  },
  {
    "text": "benchmarking benchmarking at every steps",
    "start": "2591119",
    "end": "2596200"
  },
  {
    "text": "um I think a warning can be added um about premature optimization because I",
    "start": "2596200",
    "end": "2603599"
  },
  {
    "text": "still have in various projects People starts making optimizations without",
    "start": "2603599",
    "end": "2609359"
  },
  {
    "text": "directly benchmarking and then in the end it turns out that their optimization",
    "start": "2609359",
    "end": "2614920"
  },
  {
    "text": "and time put into it is useless because maybe the the bottom neck was not in the",
    "start": "2614920",
    "end": "2620920"
  },
  {
    "text": "place where they thought it would be as in this aot in in notably in",
    "start": "2620920",
    "end": "2626960"
  },
  {
    "text": "um in people trying to optimize instruction and in the end like",
    "start": "2626960",
    "end": "2633119"
  },
  {
    "text": "especially when people are using recursive algorithm people think okay I",
    "start": "2633119",
    "end": "2638240"
  },
  {
    "text": "can do least recent used optimizations and in the end it's not that what fastens the work because the",
    "start": "2638240",
    "end": "2646920"
  },
  {
    "text": "for example in terms of frequency russion um um unrolling un unrolling could help",
    "start": "2646920",
    "end": "2657000"
  },
  {
    "text": "much more so yeah just to yeah so so the question is about premature optimization",
    "start": "2657000",
    "end": "2663319"
  },
  {
    "text": "and I 100% agree with you um it's really easy to fall into the Trap even at the",
    "start": "2663319",
    "end": "2668480"
  },
  {
    "text": "Whiteboard stage of of of talking through all the potential problems and coming up with Solutions and the earlier",
    "start": "2668480",
    "end": "2674839"
  },
  {
    "text": "you can start benchmarking your code and see how it actually performs the more you can avoid doing a lot of work that",
    "start": "2674839",
    "end": "2681000"
  },
  {
    "text": "you don't have to so to totally",
    "start": "2681000",
    "end": "2684680"
  },
  {
    "text": "agree any final questions",
    "start": "2690839",
    "end": "2695400"
  },
  {
    "text": "I think we're out of are we out of questions that was uh that was an excellent talk thank you very much Alan",
    "start": "2697480",
    "end": "2704760"
  },
  {
    "text": "[Music]",
    "start": "2705370",
    "end": "2710829"
  }
]
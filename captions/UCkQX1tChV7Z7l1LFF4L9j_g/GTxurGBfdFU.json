[
  {
    "start": "0",
    "end": "34000"
  },
  {
    "text": "[Music]",
    "start": "680",
    "end": "8549"
  },
  {
    "text": "good morning my name is jinhu a software engineer at netflix",
    "start": "15040",
    "end": "20640"
  },
  {
    "text": "today we are going to talk about our workflow scheduler a robust foundation",
    "start": "20640",
    "end": "25840"
  },
  {
    "text": "for large-scale data pipelines we will share our experiences and lessons we",
    "start": "25840",
    "end": "31199"
  },
  {
    "text": "learned including patterns we developed netflix is a data driven company every",
    "start": "31199",
    "end": "37600"
  },
  {
    "start": "34000",
    "end": "75000"
  },
  {
    "text": "decision at netflix is driven by data insights from the color used in the",
    "start": "37600",
    "end": "43680"
  },
  {
    "text": "landing page to upcoming original contents data scientists engineers and even",
    "start": "43680",
    "end": "50879"
  },
  {
    "text": "content producers all run their data pipelines to get the insights they need",
    "start": "50879",
    "end": "56480"
  },
  {
    "text": "thus the scalability and the stability of the data pipeline platform has become",
    "start": "56480",
    "end": "61680"
  },
  {
    "text": "more important over the past years we have developed a robust foundation to provide users a",
    "start": "61680",
    "end": "69200"
  },
  {
    "text": "consistent way to manage and automate their data pipelines this foundation is called the btp",
    "start": "69200",
    "end": "75360"
  },
  {
    "start": "75000",
    "end": "102000"
  },
  {
    "text": "scheduler pdb scheduler provides workflow as a service to thousands of netflix internal",
    "start": "75360",
    "end": "82000"
  },
  {
    "text": "users it is scalable and reliable including multiple components for example workflow",
    "start": "82000",
    "end": "88159"
  },
  {
    "text": "engine ui alerting and abstraction layers such as dsl and templates",
    "start": "88159",
    "end": "94320"
  },
  {
    "text": "it satisfies all the needs of our users including engineers and law engineers we",
    "start": "94320",
    "end": "100079"
  },
  {
    "text": "will go over it in this talk here is the high level",
    "start": "100079",
    "end": "106079"
  },
  {
    "start": "102000",
    "end": "169000"
  },
  {
    "text": "architecture design our users uses ui cli clients to interact with schedule",
    "start": "106079",
    "end": "112799"
  },
  {
    "text": "apis over the gateway which provides a public abstraction and higher internal",
    "start": "112799",
    "end": "117840"
  },
  {
    "text": "details the gateway is also helpful while dealing with api instance for example we",
    "start": "117840",
    "end": "125680"
  },
  {
    "text": "can shut down the gateway to disabled apis but still keep the workflow engine",
    "start": "125680",
    "end": "131520"
  },
  {
    "text": "running this great reduce the impact of the instance workflow engine is the core which",
    "start": "131520",
    "end": "138640"
  },
  {
    "text": "manages workflow versioning the metadata and the states of the workflow",
    "start": "138640",
    "end": "144000"
  },
  {
    "text": "executions either suppose scheduling with trigger components",
    "start": "144000",
    "end": "150879"
  },
  {
    "text": "such as time based crown trigger and the urine trigger",
    "start": "150879",
    "end": "156000"
  },
  {
    "text": "it runs user business logic in docker containers over the execution engine",
    "start": "156000",
    "end": "161680"
  },
  {
    "text": "the code itself is loosely coupled with downstream services by sending stator",
    "start": "161680",
    "end": "166800"
  },
  {
    "text": "changes to an event stream this foundation worked quite well to",
    "start": "166800",
    "end": "172080"
  },
  {
    "start": "169000",
    "end": "223000"
  },
  {
    "text": "support a wider variety of use cases users use it to automate their normal",
    "start": "172080",
    "end": "177680"
  },
  {
    "text": "detail pipelines trend their machine learning models and so on some services also use scheduler to",
    "start": "177680",
    "end": "184239"
  },
  {
    "text": "periodically run jobs here we try to abstract the common functions or reusable patterns from all",
    "start": "184239",
    "end": "192159"
  },
  {
    "text": "use cases and add them to the scheduler in a loosely covered way we also found that human readable dsl is",
    "start": "192159",
    "end": "200480"
  },
  {
    "text": "very helpful and plays an important role to support heterogeneous use cases",
    "start": "200480",
    "end": "206959"
  },
  {
    "text": "at netflix users can def write their workflow definition using their cells in",
    "start": "206959",
    "end": "212959"
  },
  {
    "text": "yambo java or python yes yamo dsl is actually the most",
    "start": "212959",
    "end": "218879"
  },
  {
    "text": "popular one due to its simplicity and easy to understand",
    "start": "218879",
    "end": "223920"
  },
  {
    "start": "223000",
    "end": "321000"
  },
  {
    "text": "here is our current scale the growth rate is quite high you can see from this",
    "start": "223920",
    "end": "229280"
  },
  {
    "text": "chart and we observed about 300 percent increase per year",
    "start": "229280",
    "end": "234480"
  },
  {
    "text": "one best practice to operate the service with this scale is to build good monitoring and logging around it",
    "start": "234480",
    "end": "241760"
  },
  {
    "text": "for example in the past year we were able to find out that the scheduler would have",
    "start": "241760",
    "end": "248000"
  },
  {
    "text": "scanning problems in the near future by those metrics then we started the engineering work",
    "start": "248000",
    "end": "255760"
  },
  {
    "text": "before it actually happens now the scanning problem starts to appear the engineering work is close to",
    "start": "255760",
    "end": "262479"
  },
  {
    "text": "complete one lesson we learned is that in this scale",
    "start": "262479",
    "end": "267680"
  },
  {
    "text": "we may experience many unexpected problems for example we found that",
    "start": "267680",
    "end": "274080"
  },
  {
    "text": "there is a large load spike at midnight every day thousands of workflows are scheduled to",
    "start": "274080",
    "end": "280160"
  },
  {
    "text": "run exactly at midnight we talked with those workflow owners and many of them",
    "start": "280160",
    "end": "286400"
  },
  {
    "text": "were okay to start execution at a different time the reason they use midnight is just",
    "start": "286400",
    "end": "292880"
  },
  {
    "text": "because they copied an example in our scheduled dock which uses the midnight in this ground trigger",
    "start": "292880",
    "end": "300240"
  },
  {
    "text": "then the next lesson is that it is hard to ask thousands of users to change tens of",
    "start": "300240",
    "end": "306880"
  },
  {
    "text": "thousands of their workflows even it is a tiny change the communication and the correlation",
    "start": "306880",
    "end": "312639"
  },
  {
    "text": "efforts will be much more than the efforts improving the system which is the path we took to handle this",
    "start": "312639",
    "end": "319039"
  },
  {
    "text": "peak traffic next i will focus on the core component",
    "start": "319039",
    "end": "325600"
  },
  {
    "start": "321000",
    "end": "454000"
  },
  {
    "text": "workflow engine and talk about its design and the technical decisions we made to better",
    "start": "325600",
    "end": "332479"
  },
  {
    "text": "serve our users first item is about whether to build a bare-bones engine or an engine including",
    "start": "332479",
    "end": "341039"
  },
  {
    "text": "useful patents you will only support the core features we could reduce the complexity and make",
    "start": "341039",
    "end": "348160"
  },
  {
    "text": "the core well optimized but it means we will push the work to the user side and ask users to",
    "start": "348160",
    "end": "355199"
  },
  {
    "text": "repeatedly write the same logic or find a word workaround this might",
    "start": "355199",
    "end": "360479"
  },
  {
    "text": "need thousands of ways to solve the same problem it is much better to support users with",
    "start": "360479",
    "end": "367120"
  },
  {
    "text": "common patterns than asking them to do it by themselves i will use for each as an example",
    "start": "367120",
    "end": "375520"
  },
  {
    "text": "for each is a very popular pattern users use it repeatedly run the same jobs with",
    "start": "375520",
    "end": "382080"
  },
  {
    "text": "different parameters such as backfill data or parameter tuning we might ask users to explicitly define",
    "start": "382080",
    "end": "390560"
  },
  {
    "text": "each iterations in the definition which is tedious and time consuming for large",
    "start": "390560",
    "end": "396000"
  },
  {
    "text": "iterations think about thousands or tens of thousands also they need to create new workflows",
    "start": "396000",
    "end": "403759"
  },
  {
    "text": "if the for each range changes with the direct engine support users",
    "start": "403759",
    "end": "409520"
  },
  {
    "text": "just provides an array of parameter values for for each and jobs to run",
    "start": "409520",
    "end": "414800"
  },
  {
    "text": "they can change parameter values without recreating the workflow",
    "start": "414800",
    "end": "420319"
  },
  {
    "text": "similarly we added supports of sub workflow and the conditional branching",
    "start": "420319",
    "end": "426240"
  },
  {
    "text": "sub workflow support allows a workflow job to run another workflow and the conditional branching allows run some",
    "start": "426240",
    "end": "433039"
  },
  {
    "text": "jobs only if the condition is true directly directly supporting them in the",
    "start": "433039",
    "end": "438880"
  },
  {
    "text": "engine enables us to optimize those features and provide a consistent way to",
    "start": "438880",
    "end": "444479"
  },
  {
    "text": "realize those patterns additionally dslr support can help to reduce the",
    "start": "444479",
    "end": "450800"
  },
  {
    "text": "complexity to define it",
    "start": "450800",
    "end": "454159"
  },
  {
    "start": "454000",
    "end": "555000"
  },
  {
    "text": "another related item is about static versus dynamic workflow static workflow is simple and easy to",
    "start": "455919",
    "end": "463280"
  },
  {
    "text": "use but it is quite limited often times users have to duplicate the",
    "start": "463280",
    "end": "469520"
  },
  {
    "text": "same workflow many times just because there's a very small changes",
    "start": "469520",
    "end": "476800"
  },
  {
    "text": "a completely dynamic workflow will be hard to manage and support it is difficult to debug and or",
    "start": "476800",
    "end": "483120"
  },
  {
    "text": "troubleshoot therefore we developed and",
    "start": "483120",
    "end": "489120"
  },
  {
    "text": "created something called parameterizer workflows which are initialized step by step at a run time based on current user",
    "start": "489440",
    "end": "498160"
  },
  {
    "text": "defined parameters users love it and it is easy to manage and troubleshoot and also powerful",
    "start": "498160",
    "end": "504720"
  },
  {
    "text": "enough for them to write workflows with reach functions to further enhance it we support two",
    "start": "504720",
    "end": "512479"
  },
  {
    "text": "execution modes runnable mode which is not retaining any data",
    "start": "512479",
    "end": "517919"
  },
  {
    "text": "and the callable mode which returns output parameter values from the execution back to the engine",
    "start": "517919",
    "end": "527120"
  },
  {
    "text": "here is an example of backfield workflow with three steps in step one user computes the back field",
    "start": "527120",
    "end": "533920"
  },
  {
    "text": "ranges and returns the dates back to step one next for each step uses the dates from",
    "start": "533920",
    "end": "541920"
  },
  {
    "text": "step one to create it for each jobs finally in each of backfield jobs either",
    "start": "541920",
    "end": "548880"
  },
  {
    "text": "gets date from the for each and the backfield data based on it",
    "start": "548880",
    "end": "555600"
  },
  {
    "start": "555000",
    "end": "640000"
  },
  {
    "text": "as we just showed parameters played an important role in our schedule",
    "start": "556800",
    "end": "562720"
  },
  {
    "text": "we have to decide whether supporting dynamic parameters with coding injection",
    "start": "562720",
    "end": "568399"
  },
  {
    "text": "or not code injection is super useful and powerful and our users love it together",
    "start": "568399",
    "end": "575279"
  },
  {
    "text": "with other features it makes the workflow very dynamic but with the coding injection the",
    "start": "575279",
    "end": "582000"
  },
  {
    "text": "security is a big concern also users might write buggy code for",
    "start": "582000",
    "end": "587279"
  },
  {
    "text": "example in the past any user unintentionally wrote an infinite loop to create an array",
    "start": "587279",
    "end": "593760"
  },
  {
    "text": "which then eventually crashed the scheduler jvm we could ask users to put the injected",
    "start": "593760",
    "end": "601040"
  },
  {
    "text": "code inside our business logic instead of in the workflow definition but this will put a lot of work to the",
    "start": "601040",
    "end": "607760"
  },
  {
    "text": "user side and also couple the user business logic with the workflow",
    "start": "607760",
    "end": "613200"
  },
  {
    "text": "eventually we developed our own customized expression language to",
    "start": "613200",
    "end": "618399"
  },
  {
    "text": "support the code injection during the abstract the syntax reporting",
    "start": "618399",
    "end": "623600"
  },
  {
    "text": "we put an image there to secure and protect the system",
    "start": "623600",
    "end": "629680"
  },
  {
    "text": "here is an example to show how users write a piece of code",
    "start": "630079",
    "end": "636079"
  },
  {
    "text": "in the workflow definition to validate the results",
    "start": "636079",
    "end": "640639"
  },
  {
    "start": "640000",
    "end": "746000"
  },
  {
    "text": "next i will talk about the execution control what we found is that simple concurrency",
    "start": "641200",
    "end": "648000"
  },
  {
    "text": "control on a single entity is not enough we and our users want to control like",
    "start": "648000",
    "end": "654800"
  },
  {
    "text": "how many workflows to run how many jobs within one workflow to run how many jobs across",
    "start": "654800",
    "end": "661519"
  },
  {
    "text": "all workflows to run and so on this requires a multi-dimensional",
    "start": "661519",
    "end": "667040"
  },
  {
    "text": "concurrency control also users want to schedule to automate data",
    "start": "667040",
    "end": "672800"
  },
  {
    "text": "pipelines but also have enough control of the execution order we provide both low level control and",
    "start": "672800",
    "end": "680079"
  },
  {
    "text": "some predefined high level run strategies it turns out the predefined ones are good enough",
    "start": "680079",
    "end": "686959"
  },
  {
    "text": "and almost no one used the low level ones it actually caused more confusions to the users and later we removed those",
    "start": "686959",
    "end": "694079"
  },
  {
    "text": "lower and the level ones here are predefined ones sequential is",
    "start": "694079",
    "end": "700160"
  },
  {
    "text": "to ensure only one running in first in first out order strict sequential is to handle the",
    "start": "700160",
    "end": "706640"
  },
  {
    "text": "unexpected job failures in this case users usually want to pause the",
    "start": "706640",
    "end": "713200"
  },
  {
    "text": "execution but still include the new ones for example here",
    "start": "713200",
    "end": "718399"
  },
  {
    "text": "when the run file failed round 6 to 12 will be enqueued but there is no new",
    "start": "718399",
    "end": "724240"
  },
  {
    "text": "execution after underlying issue is fixed the user then restarts the field one to resume the execution",
    "start": "724240",
    "end": "732560"
  },
  {
    "text": "first only is to achieve at the potency if there is an existing running one the new one is skipped last only is to allow",
    "start": "732560",
    "end": "739839"
  },
  {
    "text": "new run to cancel the current running one and also parallel with the concurrency limit",
    "start": "739839",
    "end": "746240"
  },
  {
    "text": "it is also important to provide debuggability and service arrows for users to troubleshoot",
    "start": "746240",
    "end": "752480"
  },
  {
    "text": "both will improve the user experience and the worst time and efforts to implement for developability we support",
    "start": "752480",
    "end": "759120"
  },
  {
    "text": "the breakpoint to allow users to pause the jobs in workflow we also include error information execution timeline and",
    "start": "759120",
    "end": "766399"
  },
  {
    "text": "milestones to artifacts to help users to troubleshoot failures with all those",
    "start": "766399",
    "end": "771760"
  },
  {
    "text": "learnings will we always prefer adding more and more functions to the workflow engine the answer is not always",
    "start": "771760",
    "end": "778959"
  },
  {
    "text": "in some cases we move functions to other services or build dedicated services",
    "start": "778959",
    "end": "784320"
  },
  {
    "text": "this helps to separate the concerns and make the whole platform more scalable and robust if any of those services",
    "start": "784320",
    "end": "791200"
  },
  {
    "text": "offline the workflow engine can still run a lot of money next i will pass the tag to my colleague harrington to talk",
    "start": "791200",
    "end": "798079"
  },
  {
    "text": "about the other components",
    "start": "798079",
    "end": "801839"
  },
  {
    "start": "802000",
    "end": "979000"
  },
  {
    "text": "thank you jun hi i'm harrington joseph i'm a senior software engineer at the big data orchestration team and i work together",
    "start": "803680",
    "end": "810079"
  },
  {
    "text": "with june building the next generation of scheduling tools let's talk about the dsl the dsl stands",
    "start": "810079",
    "end": "816639"
  },
  {
    "text": "for domain-specific language this was the first component that we built that is user-facing in order for users to",
    "start": "816639",
    "end": "822480"
  },
  {
    "text": "have a unique simple and unified way of defining workflows",
    "start": "822480",
    "end": "829040"
  },
  {
    "text": "for this we pick yaml we pick yaml because we wanted a static definition that anyone could use and read",
    "start": "829040",
    "end": "836079"
  },
  {
    "text": "so here's an example the top section shows a trigger block that is completely",
    "start": "836079",
    "end": "842480"
  },
  {
    "text": "optional but it allows users to define how often they want their warfare to trigger automatically in this case",
    "start": "842480",
    "end": "848480"
  },
  {
    "text": "is defining a crown trigger that is saying that this workflow should run on the daily basis and the time zone is u.s specific so",
    "start": "848480",
    "end": "856639"
  },
  {
    "text": "this means that this workflow is going to get activated at midnight in your specific time",
    "start": "856639",
    "end": "862240"
  },
  {
    "text": "you could use complex ground expressions or other time zones that are considered valid",
    "start": "862240",
    "end": "868639"
  },
  {
    "text": "next you have the workflow section a workflow is defined initially by providing an id which is a unique",
    "start": "868959",
    "end": "874480"
  },
  {
    "text": "identifier across the platform then you need to provide a list of jobs or units of work that your pipeline is going to",
    "start": "874480",
    "end": "881120"
  },
  {
    "text": "execute in this case we have two jobs the job one is a spark job that only is doing",
    "start": "881120",
    "end": "886800"
  },
  {
    "text": "and for presentation purposes is select a running a select one of course you can do something much more complex than this",
    "start": "886800",
    "end": "893199"
  },
  {
    "text": "or provide a sql file or a jar file the job number two is a notebook job and",
    "start": "893199",
    "end": "899440"
  },
  {
    "text": "in this case the notebook job allows you to execute jupyter notebooks as part of your pipeline all the user needs to do",
    "start": "899440",
    "end": "906000"
  },
  {
    "text": "is to provide a url or a path the notebook so we can find that notebook on execution time",
    "start": "906000",
    "end": "913760"
  },
  {
    "text": "so this provides a common tool for users to define units of words to define their workflows from now on all the workflows",
    "start": "913760",
    "end": "920000"
  },
  {
    "text": "follow this structure and it's fairly simple to understand what a workflow looks like and where the jobs are and",
    "start": "920000",
    "end": "926480"
  },
  {
    "text": "what parameters is using and so on and it also complies with the following three principles",
    "start": "926480",
    "end": "933120"
  },
  {
    "text": "readability anyone can read this there is no reason to read body code or",
    "start": "933120",
    "end": "938560"
  },
  {
    "text": "nested or recursive code in order to understand how the workflow should look like all you need is a text editor and",
    "start": "938560",
    "end": "945440"
  },
  {
    "text": "you can just read the ammo next reproducibility",
    "start": "945440",
    "end": "951839"
  },
  {
    "text": "this is very reproducible because anyone can go find a yam on any repo copy maybe",
    "start": "951839",
    "end": "957279"
  },
  {
    "text": "change the id and push it and you should get the same behavior and then you can actually iterate over these add new jobs",
    "start": "957279",
    "end": "962959"
  },
  {
    "text": "tweak some parameters so it's very useful for users also to learn from each other",
    "start": "962959",
    "end": "969839"
  },
  {
    "text": "and debugability because it's readable reproducible and it's also like people can actually iterate over this then it's",
    "start": "969839",
    "end": "976560"
  },
  {
    "text": "very easy to debug now let's talk about the cli the cli is a common line interface that we build",
    "start": "976560",
    "end": "983120"
  },
  {
    "start": "979000",
    "end": "1059000"
  },
  {
    "text": "for users to interact with the scheduler it is installable anywhere meaning that users can actually install these on",
    "start": "983120",
    "end": "989519"
  },
  {
    "text": "their laptop servers dev environment to docker containers you name it",
    "start": "989519",
    "end": "995040"
  },
  {
    "text": "and it's integrated with the platform this means that it understands security when a workflow is created the workflow",
    "start": "995040",
    "end": "1000480"
  },
  {
    "text": "is shaped together with the user identity so when the workflow is executed it executes as a user meaning that it has access to the same resources",
    "start": "1000480",
    "end": "1009440"
  },
  {
    "text": "it also provides as a management if you need to ship say a jar or sql file an encrypted file that you need to decrypt",
    "start": "1009440",
    "end": "1015440"
  },
  {
    "text": "during the execution time this tool also allows you to do that and it takes care of that in a seamless manner",
    "start": "1015440",
    "end": "1021440"
  },
  {
    "text": "so here are some examples um the way that you access these tools is by typing the scheduler command then you can",
    "start": "1021440",
    "end": "1027360"
  },
  {
    "text": "create a workflow by just typing schedule or push and then provide an example file from that point you can run activate and",
    "start": "1027360",
    "end": "1033918"
  },
  {
    "text": "deactivate the workflow by simply having the id of the workflow so you can just execute one of these commands",
    "start": "1033919",
    "end": "1039360"
  },
  {
    "text": "the last command info is actually very useful because it provides you ways to fetch information about workflow and all",
    "start": "1039360",
    "end": "1044798"
  },
  {
    "text": "you need is the id so you can get information about like what the the workflow status is what the version and",
    "start": "1044799",
    "end": "1051840"
  },
  {
    "text": "what the latest version is was the current active version and even a link to go to the ui",
    "start": "1051840",
    "end": "1059679"
  },
  {
    "start": "1059000",
    "end": "1086000"
  },
  {
    "text": "so we also provide a dynamic dsl and it looks like this is fairly similar to like the airflow dsl in this case",
    "start": "1060000",
    "end": "1065760"
  },
  {
    "text": "it's the python one as you can see is using the building pattern and",
    "start": "1065760",
    "end": "1071200"
  },
  {
    "text": "instead of operators we provide what we call job types but as you can see this is",
    "start": "1071200",
    "end": "1076320"
  },
  {
    "text": "exactly the same as the yaml definition we also have a java version pretty much",
    "start": "1076320",
    "end": "1081679"
  },
  {
    "text": "the same just a little bit more purpose but it's doing exactly the same thing",
    "start": "1081679",
    "end": "1086960"
  },
  {
    "start": "1086000",
    "end": "1158000"
  },
  {
    "text": "so you may be wondering where did all the principles go well",
    "start": "1086960",
    "end": "1092640"
  },
  {
    "text": "if we look at the workflow creation once you have the yaml the yaml gets pushed through the scheduler api by using the",
    "start": "1092640",
    "end": "1098000"
  },
  {
    "text": "scheduler cli now the python dsl and the java dsl",
    "start": "1098000",
    "end": "1103120"
  },
  {
    "text": "talked straight to the scheduler cli yes category api",
    "start": "1103120",
    "end": "1108480"
  },
  {
    "text": "the scheduler api has the ability of computing a yaml for every new created workflow and then stores it on s3",
    "start": "1108480",
    "end": "1114880"
  },
  {
    "text": "this computed yaml becomes a source of truth for any given workflow so at that point if a user pings me and",
    "start": "1114880",
    "end": "1121600"
  },
  {
    "text": "say hey i need help to diagnose my workflow and i understand what's happening i the workflow doesn't",
    "start": "1121600",
    "end": "1126960"
  },
  {
    "text": "look how i want it or anything like that um i can just go and find a computer demo",
    "start": "1126960",
    "end": "1132559"
  },
  {
    "text": "and take a look understand it and then even iterate over the yml without having to read that python or java code that might",
    "start": "1132559",
    "end": "1139919"
  },
  {
    "text": "be a little bit trickier for me because i may not have the same libraries i may not have the same dev environment i may",
    "start": "1139919",
    "end": "1145600"
  },
  {
    "text": "not understand what the user is trying to do in their code so this is actually much better for us",
    "start": "1145600",
    "end": "1151679"
  },
  {
    "text": "and it actually complies with the principles that i mentioned so it's readable reproducible and developable",
    "start": "1151679",
    "end": "1158640"
  },
  {
    "start": "1158000",
    "end": "1254000"
  },
  {
    "text": "now let's talk about executions similarly to airflow that provides",
    "start": "1158799",
    "end": "1163840"
  },
  {
    "text": "operators we provide what we call job types as i mentioned our job types are built on top of diver",
    "start": "1163840",
    "end": "1169039"
  },
  {
    "text": "notebooks that we use as templates and then on execution time we basically just inject parameters that have been",
    "start": "1169039",
    "end": "1175440"
  },
  {
    "text": "provided by the user into the templates for the template to actually use them during the execution",
    "start": "1175440",
    "end": "1180720"
  },
  {
    "text": "so we provide templates for like presto jobs spark jobs transport jobs meaning that you can move",
    "start": "1180720",
    "end": "1186640"
  },
  {
    "text": "data in and out rds elastic search hive is where you name it reporting tools",
    "start": "1186640",
    "end": "1193039"
  },
  {
    "text": "data auditing tools notebooks as i say bring your own notebook we'll run it as part of your",
    "start": "1193039",
    "end": "1198400"
  },
  {
    "text": "pipeline you can do the same thing with your custom scripts you can bring a bash script or a python script we can also",
    "start": "1198400",
    "end": "1205840"
  },
  {
    "text": "run it as part of your pipeline and you can even bring your own docker image and specify a custom entry",
    "start": "1205840",
    "end": "1211520"
  },
  {
    "text": "point so this is very good for our users because it provides a level of abstraction",
    "start": "1211520",
    "end": "1217440"
  },
  {
    "text": "users that want to run say aggressive query across a job all they have to do is to",
    "start": "1217440",
    "end": "1222640"
  },
  {
    "text": "provide the sql uh statement that they want to execute but they don't really need to know how the",
    "start": "1222640",
    "end": "1227919"
  },
  {
    "text": "presto um job actually runs they don't need to know the internals they don't need to know which cluster we're talking to for",
    "start": "1227919",
    "end": "1234159"
  },
  {
    "text": "example the next one is also standardization all the preset jobs and all the spark",
    "start": "1234159",
    "end": "1240480"
  },
  {
    "text": "jobs all the transfer jobs they all run through the same templates so therefore if we find a bug we can easily go apply",
    "start": "1240480",
    "end": "1247600"
  },
  {
    "text": "the fix and the fix is applied to every single job that we have in the platform",
    "start": "1247600",
    "end": "1254240"
  },
  {
    "text": "our execution is done in a way that we run every single job in its own container so this means that we get a",
    "start": "1255840",
    "end": "1263120"
  },
  {
    "text": "clean and isolated environment for each particular run",
    "start": "1263120",
    "end": "1268240"
  },
  {
    "text": "and we default on our runs to use the big data image the big data image is a docker image that",
    "start": "1268880",
    "end": "1274400"
  },
  {
    "text": "has been built and carved by the big data infrastructure team and it",
    "start": "1274400",
    "end": "1279919"
  },
  {
    "text": "contains all the dependencies that we may need for uh any of the job dollars i mentioned",
    "start": "1279919",
    "end": "1285440"
  },
  {
    "text": "before to run and our default entry point is paper mail so paper mail is a tool that allows",
    "start": "1285440",
    "end": "1293039"
  },
  {
    "text": "you to run notebooks in a headless manner this means that you don't really need the notebooks ui in order to run",
    "start": "1293039",
    "end": "1298559"
  },
  {
    "text": "the notebook so here's how it looks we basically call papermill we provide the path to the template that we want to",
    "start": "1298559",
    "end": "1304960"
  },
  {
    "text": "execute say the spark template and then we that what you see in pink is actually the output notebook where we want this",
    "start": "1304960",
    "end": "1311760"
  },
  {
    "text": "to be written like we want this execution to be written sort of like a log but in the notebook format",
    "start": "1311760",
    "end": "1317520"
  },
  {
    "text": "and then we just have to provide the parameters that we want to inject into this notebook so in this case we're defining a parameter called spark that",
    "start": "1317520",
    "end": "1324960"
  },
  {
    "text": "has a key called script and a value of select one",
    "start": "1324960",
    "end": "1331520"
  },
  {
    "start": "1330000",
    "end": "1398000"
  },
  {
    "text": "so here's here on the right is a notebook output as you can see at the top there is this cell called parameters",
    "start": "1331520",
    "end": "1337679"
  },
  {
    "text": "at the bottom of that cell you can see that there is a spark equals a dictionary containing script equals",
    "start": "1337679",
    "end": "1344000"
  },
  {
    "text": "select one this is the parameter that we just injected when we made the paper real",
    "start": "1344000",
    "end": "1349120"
  },
  {
    "text": "call so this is very nice because users can actually see all the parameters that are getting injected into the notebook",
    "start": "1349120",
    "end": "1354799"
  },
  {
    "text": "execution so it's easier for them to understand what's happening they can also see the rest of the",
    "start": "1354799",
    "end": "1361039"
  },
  {
    "text": "execution that is actually the code that gets executed in order to execute for example in this case the spark job",
    "start": "1361039",
    "end": "1367679"
  },
  {
    "text": "so it's definitely readable they can see everything here of course we talk about abstraction but this is a way of diving",
    "start": "1367679",
    "end": "1373520"
  },
  {
    "text": "into details if you want to it's also reproducible because anyone can download this notebook and run it",
    "start": "1373520",
    "end": "1379840"
  },
  {
    "text": "locally and it's debuggable because after you download the notebook and you run it locally you can actually tweak",
    "start": "1379840",
    "end": "1386480"
  },
  {
    "text": "the parameters and even tweak the the internals of the notebook in order to achieve what you want then you can",
    "start": "1386480",
    "end": "1392400"
  },
  {
    "text": "actually go back to your workflow definition and update your parameters accordingly",
    "start": "1392400",
    "end": "1398400"
  },
  {
    "start": "1398000",
    "end": "1484000"
  },
  {
    "text": "so on top of manual and time-based triggering we also provide even during triggering",
    "start": "1398400",
    "end": "1405280"
  },
  {
    "text": "and it looks like this if we look at the trigger section now we have what we call signals in this case we have two groups",
    "start": "1405280",
    "end": "1411840"
  },
  {
    "text": "of signals so the first group of signals is defining um two signals that says i want to run",
    "start": "1411840",
    "end": "1418640"
  },
  {
    "text": "this workflow when table a is updated and when table b has a partition uh updated",
    "start": "1418640",
    "end": "1425679"
  },
  {
    "text": "so we're able to do this because signals in the scheduler consistence of the interpretation of events and our",
    "start": "1425679",
    "end": "1432000"
  },
  {
    "text": "platform is fully aware of events in the netflix ecosystem so we know when a table is updated when a partition has",
    "start": "1432000",
    "end": "1438080"
  },
  {
    "text": "landed and so on in addition we also allow users to define",
    "start": "1438080",
    "end": "1443360"
  },
  {
    "text": "custom signals for example i want to run this workflow when an application called",
    "start": "1443360",
    "end": "1448400"
  },
  {
    "text": "my app has announced a signal called abc and this is also available for users",
    "start": "1448400",
    "end": "1454320"
  },
  {
    "text": "because applications are able to emit events and once these events",
    "start": "1454320",
    "end": "1459679"
  },
  {
    "text": "get placed into our event stream we can turn them into signals",
    "start": "1459679",
    "end": "1465679"
  },
  {
    "text": "so this is more efficient because there's no reason to waste resources checking if you're ready to run",
    "start": "1465840",
    "end": "1472080"
  },
  {
    "text": "it's also more accurate because you move away from executing when you think you have to so instead of running hourly or",
    "start": "1472080",
    "end": "1478159"
  },
  {
    "text": "daily or so and so on you execute when you actually have to",
    "start": "1478159",
    "end": "1484880"
  },
  {
    "start": "1484000",
    "end": "1535000"
  },
  {
    "text": "this also applies for what we call job dependencies or input signals so the workflow can actually be executing and",
    "start": "1484880",
    "end": "1491200"
  },
  {
    "text": "until the point it gets to a job that has input signals at that point it needs to check if these",
    "start": "1491200",
    "end": "1497440"
  },
  {
    "text": "signals have been satisfied if the signals have not been satisfied then the workflow is going to wait for these",
    "start": "1497440",
    "end": "1504320"
  },
  {
    "text": "signals to satisfy in order to be able to run this job so this is very similar to airflow",
    "start": "1504320",
    "end": "1509600"
  },
  {
    "text": "sensors with the main difference that this is 100 event driven so there's no pulling mechanism behind there's no",
    "start": "1509600",
    "end": "1516240"
  },
  {
    "text": "resource waste in this case in the same way we have output signals",
    "start": "1516240",
    "end": "1522320"
  },
  {
    "text": "jobs can emit signals that can be consumed downstream either to trigger a workflow or to release a job that is",
    "start": "1522320",
    "end": "1528159"
  },
  {
    "text": "waiting for a signal and this is a very nice way to orchestrate jobs and workflows in a distributed manner",
    "start": "1528159",
    "end": "1535679"
  },
  {
    "start": "1535000",
    "end": "1567000"
  },
  {
    "text": "so in summary i would like you to walk away from this talk understanding that for us from definition to execution our",
    "start": "1536320",
    "end": "1542960"
  },
  {
    "text": "platform is composed from multiple layers and",
    "start": "1542960",
    "end": "1548000"
  },
  {
    "text": "all these layers uh have been defined with clear separation of concerns and this has allowed us to provide the",
    "start": "1548000",
    "end": "1554720"
  },
  {
    "text": "solid foundation to support multiple use cases and for applications to build on top of our platform as well",
    "start": "1554720",
    "end": "1561440"
  },
  {
    "text": "that's all i have thank you very much for your time and i look forward to your questions",
    "start": "1561440",
    "end": "1568360"
  },
  {
    "start": "1567000",
    "end": "1629000"
  },
  {
    "text": "hello and thanks for the presentation uh we already have questions on the chat",
    "start": "1570480",
    "end": "1576240"
  },
  {
    "text": "uh but i'll start with a question of my own uh so uh your strategy of using uh jupiter",
    "start": "1576240",
    "end": "1584559"
  },
  {
    "text": "notebooks as as as the pipeline uh source code it is",
    "start": "1584559",
    "end": "1589919"
  },
  {
    "text": "uh very clever because you can do experimentation in jupiter and then use",
    "start": "1589919",
    "end": "1595039"
  },
  {
    "text": "the same code to actually execute the pipeline but i i was wondering uh when you are in",
    "start": "1595039",
    "end": "1602799"
  },
  {
    "text": "the experimentation phase uh you probably want to do experimentation using samples of of data",
    "start": "1602799",
    "end": "1612080"
  },
  {
    "text": "or things like that so i i was wondering how you how you organize this i mean do you have",
    "start": "1612080",
    "end": "1619120"
  },
  {
    "text": "samples uh done for every data set you can use later in production uh how",
    "start": "1619120",
    "end": "1626640"
  },
  {
    "text": "how this works in practice um i i think i can take that one and",
    "start": "1626640",
    "end": "1632159"
  },
  {
    "start": "1629000",
    "end": "1725000"
  },
  {
    "text": "then i don't know you want to add anything uh yes that's a great question um it's it's something that everyone",
    "start": "1632159",
    "end": "1638320"
  },
  {
    "text": "struggles with because i mean replicating the same the uh data center for tests and products is",
    "start": "1638320",
    "end": "1645279"
  },
  {
    "text": "quite challenging so we do have some tests representation of some uh uh tables and data sets and stuff like",
    "start": "1645279",
    "end": "1652720"
  },
  {
    "text": "that of course it's not a hundred percent like uh like it doesn't represent absolutely",
    "start": "1652720",
    "end": "1658640"
  },
  {
    "text": "everything 100 but yeah users are able to fetch either some data from a real table",
    "start": "1658640",
    "end": "1664720"
  },
  {
    "text": "maybe just they just gather uh some smaller set because it probably doesn't fit in memory or whatever they they are",
    "start": "1664720",
    "end": "1670320"
  },
  {
    "text": "trying to do and then they can actually try to output whatever like say that uh",
    "start": "1670320",
    "end": "1676240"
  },
  {
    "text": "they're doing some etl or something like that they can output that to a test table so they can run over and over and",
    "start": "1676240",
    "end": "1681440"
  },
  {
    "text": "over or even they can output to a crop table bodies that is under their own database so it shouldn't actually be",
    "start": "1681440",
    "end": "1687919"
  },
  {
    "text": "propagated or cause any impact on on live tape however um",
    "start": "1687919",
    "end": "1693679"
  },
  {
    "text": "the advantage of this is also that users are able to output the log to their own databases",
    "start": "1693679",
    "end": "1699520"
  },
  {
    "text": "that are available in production for other people to consume as well so you can see a lot of use cases where users",
    "start": "1699520",
    "end": "1705520"
  },
  {
    "text": "uh have different way of inputting data to their tables either like on the experimentation phase",
    "start": "1705520",
    "end": "1711919"
  },
  {
    "text": "or in a production phase and then they actually gather that uh on execution time on their workflow like",
    "start": "1711919",
    "end": "1717760"
  },
  {
    "text": "machine learning is one of those examples where people tweak are constantly tweaking their data and then",
    "start": "1717760",
    "end": "1723279"
  },
  {
    "text": "picking it up live yeah one thing to add is that",
    "start": "1723279",
    "end": "1728559"
  },
  {
    "start": "1725000",
    "end": "1805000"
  },
  {
    "text": "all the workflows is parameterized so basically from a source of choose all the actual",
    "start": "1728559",
    "end": "1735679"
  },
  {
    "text": "production data from there users actually can run all the whole uh or even multiple workflows",
    "start": "1735679",
    "end": "1742480"
  },
  {
    "text": "but by passing different parameters for the output path or the input path and then uh just kind of uh run the tests without",
    "start": "1742480",
    "end": "1750799"
  },
  {
    "text": "so without writing the data back to the production set right let's let's get some questions",
    "start": "1750799",
    "end": "1757200"
  },
  {
    "text": "from from the chat um i have several more questions but let's let's start with the chat and then",
    "start": "1757200",
    "end": "1764640"
  },
  {
    "text": "if you have time we can answer in the",
    "start": "1764640",
    "end": "1770159"
  },
  {
    "text": "hangouts so let me just go to the beginning i know you already",
    "start": "1770159",
    "end": "1775520"
  },
  {
    "text": "answered some of them but uh i'll repeat just in case uh someone is watching",
    "start": "1775520",
    "end": "1781120"
  },
  {
    "text": "later and doesn't have access to the chat so uh",
    "start": "1781120",
    "end": "1786480"
  },
  {
    "text": "there's a there's several questions that around how do you compare with",
    "start": "1786480",
    "end": "1793279"
  },
  {
    "text": "airflow and why using your own solution instead of airflow uh",
    "start": "1793279",
    "end": "1799200"
  },
  {
    "text": "or other schedules uh so can you elaborate a little bit a little bit about that",
    "start": "1799200",
    "end": "1805760"
  },
  {
    "start": "1805000",
    "end": "1849000"
  },
  {
    "text": "sure yeah we evaluate airflow actually uh",
    "start": "1805760",
    "end": "1813520"
  },
  {
    "text": "before we start this and there's multiple things uh firstly definite scale in the netflix scale we have lots",
    "start": "1813520",
    "end": "1820720"
  },
  {
    "text": "of lots of use cases and users does not always use python they",
    "start": "1820720",
    "end": "1825840"
  },
  {
    "text": "may like use java or they may even don't know how to write code right they just",
    "start": "1825840",
    "end": "1831039"
  },
  {
    "text": "want to write some sql to query some data so first we provide like dsl yamo uh",
    "start": "1831039",
    "end": "1838559"
  },
  {
    "text": "python java and users uh like uh with all kind of backgrounds can",
    "start": "1838559",
    "end": "1844240"
  },
  {
    "text": "use that and uh also in terms of scale um",
    "start": "1844240",
    "end": "1850399"
  },
  {
    "text": "we definitely don't want to like uh because our data is in one data set so",
    "start": "1850399",
    "end": "1857200"
  },
  {
    "text": "we we all the orgs actually uh here we don't kind of say",
    "start": "1857200",
    "end": "1864880"
  },
  {
    "text": "media team only use media data or something so they all can they can access all the data so then we don't",
    "start": "1864880",
    "end": "1870640"
  },
  {
    "text": "want to have like multiple schedulers clusters there so when we take a look at the",
    "start": "1870640",
    "end": "1876159"
  },
  {
    "text": "airflow it definitely cannot support this kind of scale first there is like a single workflow with thousands of jobs",
    "start": "1876159",
    "end": "1881679"
  },
  {
    "text": "right this is the first kind of thing and then also like a thousand tens of thousand workflows right so airflow",
    "start": "1881679",
    "end": "1887679"
  },
  {
    "text": "cannot manage that in one single cluster and our schedule can um also the as i",
    "start": "1887679",
    "end": "1893840"
  },
  {
    "text": "already mentioned the user experience um and then the last one is the additional",
    "start": "1893840",
    "end": "1899120"
  },
  {
    "text": "features that we provide like cell x uh injection event driven hardware",
    "start": "1899120",
    "end": "1904880"
  },
  {
    "text": "mentioned and also those common patterns before you used to work for all those things",
    "start": "1904880",
    "end": "1911039"
  },
  {
    "text": "yeah um i wanted to add uh two more things uh one um when we did when we",
    "start": "1911039",
    "end": "1916240"
  },
  {
    "text": "started to work on this i mean it's been like around four years since we've been actually building this uh",
    "start": "1916240",
    "end": "1922000"
  },
  {
    "text": "yeah and it actually predates that like all these decisions so airflow wasn't quite material around that time to the",
    "start": "1922000",
    "end": "1928640"
  },
  {
    "text": "scale that we were talking about so that was one of the decision factors uh and then the other decision factor is like",
    "start": "1928640",
    "end": "1934799"
  },
  {
    "text": "as every data platform uh is composed by tons and tons of services but for the",
    "start": "1934799",
    "end": "1940320"
  },
  {
    "text": "user experience experience it's very hard to say well i have to run a workflow i go to this service i want to",
    "start": "1940320",
    "end": "1945840"
  },
  {
    "text": "check my table and go to the other server so we our philosophy in our platform is to provide a single and unified experience",
    "start": "1945840",
    "end": "1952480"
  },
  {
    "text": "like one like from the user perspective it looks like a singular entity uh and",
    "start": "1952480",
    "end": "1958559"
  },
  {
    "text": "that was the other thing that we were looking at how can we build a scheduler that we can integrate in the platform that feels",
    "start": "1958559",
    "end": "1965679"
  },
  {
    "text": "like a single thing that is part of the platform and not like an extra uh piece of software so that's why like i",
    "start": "1965679",
    "end": "1972320"
  },
  {
    "text": "mentioned that we're able to react to events because we're fully aware of what's happening in the platform and",
    "start": "1972320",
    "end": "1977679"
  },
  {
    "text": "getting that with something external was actually fairly challenging",
    "start": "1977679",
    "end": "1983360"
  },
  {
    "text": "there's another question uh the workflow orchestration gene is a conductor can you explain what is",
    "start": "1983919",
    "end": "1989840"
  },
  {
    "text": "conductor also",
    "start": "1989840",
    "end": "1993679"
  },
  {
    "start": "1994000",
    "end": "2087000"
  },
  {
    "text": "the the conductor is uh iso yeah they say the workflow orchestration",
    "start": "1995120",
    "end": "2001519"
  },
  {
    "text": "engine is",
    "start": "2001519",
    "end": "2005799"
  },
  {
    "text": "is a service orchestrator uh which uh occupied microservices um we are now",
    "start": "2010799",
    "end": "2015840"
  },
  {
    "text": "using in the current version of the our speed scheduler we didn't use that uh engine instead of",
    "start": "2015840",
    "end": "2021519"
  },
  {
    "text": "we use a called mesa and",
    "start": "2021519",
    "end": "2026559"
  },
  {
    "text": "in the future version yeah we are considering a conductor due to this is a scale is a horizontal",
    "start": "2026559",
    "end": "2032880"
  },
  {
    "text": "scale okay uh they are asking if there's an example or",
    "start": "2032880",
    "end": "2039279"
  },
  {
    "text": "how to available on github i don't know if it's open source so i don't know if you should have",
    "start": "2039279",
    "end": "2046640"
  },
  {
    "text": "no it's right at the moment it's not open source it's fairly challenging to open sources the way it is uh because",
    "start": "2046640",
    "end": "2052398"
  },
  {
    "text": "it's full it's very integrated with netflix um but we we are exploring different options to see what we can",
    "start": "2052399",
    "end": "2059040"
  },
  {
    "text": "give back to the community there's another",
    "start": "2059040",
    "end": "2065440"
  },
  {
    "text": "question around yemo i was expecting this this uh don't you find the final",
    "start": "2065440",
    "end": "2072158"
  },
  {
    "text": "clause vmware limiting to complex advanced workflows as compared to the finder cloud via code i know that that",
    "start": "2072159",
    "end": "2078560"
  },
  {
    "text": "later in the talk you you actually showed how to do do this uh via code but if you want to",
    "start": "2078560",
    "end": "2085280"
  },
  {
    "text": "elaborate a little bit more yeah um so when when we proposed jamal the",
    "start": "2085280",
    "end": "2090480"
  },
  {
    "start": "2087000",
    "end": "2297000"
  },
  {
    "text": "beginning uh we had a lot of people uh brought that to us like well it's for",
    "start": "2090480",
    "end": "2095919"
  },
  {
    "text": "me it's much easier to be able to define things in code or i just want to keep my code together or",
    "start": "2095919",
    "end": "2101520"
  },
  {
    "text": "um like many different reasons people wanted to dynamically generate very large workflows and stuff like that so",
    "start": "2101520",
    "end": "2108720"
  },
  {
    "text": "uh the initial idea was to just provide something very simple for everyone to",
    "start": "2108720",
    "end": "2114000"
  },
  {
    "text": "use and that's what the main reason of using yaml and also we wanted to be have something that was readable so yama",
    "start": "2114000",
    "end": "2120800"
  },
  {
    "text": "was the the choice at that time then um",
    "start": "2120800",
    "end": "2126240"
  },
  {
    "text": "then we basically uh built the other two dsls to to support mainly",
    "start": "2126240",
    "end": "2132480"
  },
  {
    "text": "applications because applications do need to generate like their own workflows and stuff like that and we wanted to provide them a way of doing",
    "start": "2132480",
    "end": "2139520"
  },
  {
    "text": "this without having to generate a young mood and ship it and as we did as we did this uh we",
    "start": "2139520",
    "end": "2145760"
  },
  {
    "text": "basically just put this in front of users as well so some users do actually use the python or the java dsl to",
    "start": "2145760",
    "end": "2152640"
  },
  {
    "text": "generate the workflows but as we said like we always uh compute yaml at the end for us to be able to understand the",
    "start": "2152640",
    "end": "2159520"
  },
  {
    "text": "workflow because we i don't want to have to set up a java environment for it specifically specific dependencies to",
    "start": "2159520",
    "end": "2164640"
  },
  {
    "text": "understand what a user is trying to do there's another question do you have any",
    "start": "2164640",
    "end": "2170560"
  },
  {
    "text": "plans to support or align with serverlessworkflow.io it's an open",
    "start": "2170560",
    "end": "2176880"
  },
  {
    "text": "open source project as well um not familiar with it so i cannot talk",
    "start": "2176880",
    "end": "2183839"
  },
  {
    "text": "much about it okay um",
    "start": "2183839",
    "end": "2188720"
  },
  {
    "text": "could you cover workflow deck versioning oh yeah i saw that question um",
    "start": "2191119",
    "end": "2197680"
  },
  {
    "text": "so yeah we did not cover it on during the presentation but yeah every time that uh so when you create a workflow oh",
    "start": "2197680",
    "end": "2204160"
  },
  {
    "text": "you basically claim or restart that workflow id and next time you make modifications you push new new workflow",
    "start": "2204160",
    "end": "2210800"
  },
  {
    "text": "definitions under that id they basically get up into the same unit but they get a version and then you can basically",
    "start": "2210800",
    "end": "2216880"
  },
  {
    "text": "switch between versions uh either to roll back or to have two different implementations of",
    "start": "2216880",
    "end": "2223200"
  },
  {
    "text": "the same workload uh june i don't know if there is anything we can get out of there",
    "start": "2223200",
    "end": "2229440"
  },
  {
    "text": "yeah so so the schedule to manage the worst new york that is a kind of linear",
    "start": "2229440",
    "end": "2234720"
  },
  {
    "text": "way yeah so we we have to wrap up we're running",
    "start": "2234720",
    "end": "2239839"
  },
  {
    "text": "out of time but i want just to remind everyone that you",
    "start": "2239839",
    "end": "2245200"
  },
  {
    "text": "can continue this conversation on the hangout room you can find the link on the chat and you can find also the link",
    "start": "2245200",
    "end": "2251839"
  },
  {
    "text": "on the schedules [Music] page so do you want to",
    "start": "2251839",
    "end": "2258320"
  },
  {
    "text": "leave a last message we have just one minute so um yeah i actually saw one very",
    "start": "2258320",
    "end": "2264880"
  },
  {
    "text": "interesting question of all events so if you're willing to join us in the hangout room we can talk more about that",
    "start": "2264880",
    "end": "2270560"
  },
  {
    "text": "um but yeah thank you for joining us and feel free to ping us uh either on social",
    "start": "2270560",
    "end": "2275920"
  },
  {
    "text": "channels or anywhere you can find us if you have any more questions or you want to keep talking about this",
    "start": "2275920",
    "end": "2281280"
  },
  {
    "text": "yeah excellent thank you let's go to the let's go to the hangout session then",
    "start": "2281280",
    "end": "2286900"
  },
  {
    "text": "[Music]",
    "start": "2286900",
    "end": "2294760"
  }
]
[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "I'll give people East a few minutes to trickle in but um while we're waiting how many of you were",
    "start": "5210",
    "end": "12150"
  },
  {
    "text": "here last year and heard my talk about classic machine learning anyone okay",
    "start": "12150",
    "end": "20490"
  },
  {
    "text": "cool yeah so haha and thank you so much",
    "start": "20490",
    "end": "29340"
  },
  {
    "text": "for deciding to spend the next hour with me on this I hope I make it worth your",
    "start": "29340",
    "end": "34860"
  },
  {
    "text": "while my name is Tess I'm I'm a data scientist and developer I've been a developer for",
    "start": "34860",
    "end": "40470"
  },
  {
    "text": "a long time before I started with data science but it started with data science around two years ago at Microsoft and",
    "start": "40470",
    "end": "49339"
  },
  {
    "text": "since then I've been working mostly in Python doing machine learning models but",
    "start": "49339",
    "end": "55860"
  },
  {
    "text": "still calling them from c-sharp and things and what what are we're going to",
    "start": "55860",
    "end": "61379"
  },
  {
    "text": "talk about today is deep learning so neural network innocence but we're gonna",
    "start": "61379",
    "end": "66659"
  },
  {
    "text": "start a little bit where we left off last year so last year I was talking",
    "start": "66659",
    "end": "72810"
  },
  {
    "text": "about classic machine learning so the predecessor of deep learning deep learning is kind of like a little bit",
    "start": "72810",
    "end": "78540"
  },
  {
    "text": "become the de facto way to do machine learning nowadays and they started off",
    "start": "78540",
    "end": "84510"
  },
  {
    "text": "and by showing these two pictures because what we're gonna do today is we're going to create a classifier that",
    "start": "84510",
    "end": "90240"
  },
  {
    "text": "classifies Chihuahuas and muffins and these two are there's one picture of",
    "start": "90240",
    "end": "98010"
  },
  {
    "text": "machine Wawa and one picture from my phone I'm not gonna say which one but does anyone have any ideas who thinks",
    "start": "98010",
    "end": "104190"
  },
  {
    "text": "this is nothing okay great great we have an interruption of credit for example",
    "start": "104190",
    "end": "111870"
  },
  {
    "text": "you you're gonna be my domain expert what makes you think that this is not a",
    "start": "111870",
    "end": "116970"
  },
  {
    "text": "muffin what makes you think it's a Chihuahua the eyes some when I was some",
    "start": "116970",
    "end": "124890"
  },
  {
    "text": "more experts yeah excuse me yeah eyes firfer",
    "start": "124890",
    "end": "133560"
  },
  {
    "text": "yeah eyes for a couple of things like that we have a lot of experience in",
    "start": "133560",
    "end": "139590"
  },
  {
    "text": "distinguishing between shoe or was in muffins and about 20 years ago around at",
    "start": "139590",
    "end": "145319"
  },
  {
    "text": "the same time that the Gang of Four were kind of establishing standards for",
    "start": "145319",
    "end": "150480"
  },
  {
    "text": "software engineering we were doing expert system and in AI there's just in",
    "start": "150480",
    "end": "155819"
  },
  {
    "text": "my college days I was doing expert systems where we had an expert like you guys say these are the rules that",
    "start": "155819",
    "end": "162750"
  },
  {
    "text": "differentiate these two things let's write down the rules and this is going to be our AI these things are are still",
    "start": "162750",
    "end": "172260"
  },
  {
    "text": "around today but we've come a long ways",
    "start": "172260",
    "end": "177870"
  },
  {
    "text": "since them I think because one of the problems with having a domain expert kind of decide the rules is that you",
    "start": "177870",
    "end": "185310"
  },
  {
    "text": "have to come up with a lot of rules and you're kind of screwed when you see something like this and then yeah we",
    "start": "185310",
    "end": "193260"
  },
  {
    "text": "talked about this last mewtwo but obviously then you have to decide how to",
    "start": "193260",
    "end": "198690"
  },
  {
    "text": "fight some kind of deeper meaning in the image is something that's a little bit deeper than maybe a few lines that say",
    "start": "198690",
    "end": "205019"
  },
  {
    "text": "for a knife in the ears and things like that so we're going to get to how we're going",
    "start": "205019",
    "end": "211230"
  },
  {
    "text": "to do that last year I also talked about how to do classic machine learning in",
    "start": "211230",
    "end": "217260"
  },
  {
    "text": "the context of of house prices house prices is kind of like the 101 of machine learning and for me it's kind of",
    "start": "217260",
    "end": "224750"
  },
  {
    "text": "personal because I've been saving data around houses for 10 years I've been I've been figuring out basically what a",
    "start": "224750",
    "end": "231930"
  },
  {
    "text": "house is actually worth and I'm happy to say that last week I closed on a house",
    "start": "231930",
    "end": "237209"
  },
  {
    "text": "so I'd no longer need my data my realtor was a little bit concerned when I brought up my you buddered a notebook",
    "start": "237209",
    "end": "243180"
  },
  {
    "text": "and kind of showed her why I thought my house should be priced like this but we're good but it would look at the the",
    "start": "243180",
    "end": "252660"
  },
  {
    "text": "context of a house and this is sort of least like a recap of class the machine learning to get warmed up before the deep learning what",
    "start": "252660",
    "end": "259269"
  },
  {
    "text": "machine learning is about is in most cases looking at something or want to",
    "start": "259269",
    "end": "266680"
  },
  {
    "text": "predict a target like the price of a house for example you have some input",
    "start": "266680",
    "end": "271930"
  },
  {
    "text": "data that you're going to map to the output data so say given this input data",
    "start": "271930",
    "end": "277060"
  },
  {
    "text": "I'm expecting this output data the more information you have coming in the more",
    "start": "277060",
    "end": "283570"
  },
  {
    "text": "patterns machine learning can find in your data that kind of says that this",
    "start": "283570",
    "end": "288730"
  },
  {
    "text": "output is good match to this input and all your kind of do it is like if you",
    "start": "288730",
    "end": "295780"
  },
  {
    "text": "wanted to do it the same way that would you said would what they share was in muffins you could have an expert tell",
    "start": "295780",
    "end": "302050"
  },
  {
    "text": "you that this is the mapping this is our function that will transport us from input to output like someone a realtor",
    "start": "302050",
    "end": "310270"
  },
  {
    "text": "maybe come up with some numbers like that or we could have the data show us basically how we should come up with the",
    "start": "310270",
    "end": "316540"
  },
  {
    "text": "numbers because it turns out the decision mathematical equation like some",
    "start": "316540",
    "end": "321910"
  },
  {
    "text": "wait times some parameters plus some wait times some other parameter and if",
    "start": "321910",
    "end": "327580"
  },
  {
    "text": "we look at these two parameters like the area and square meters and the price of the house we'll plot out the am the",
    "start": "327580",
    "end": "336550"
  },
  {
    "text": "result on the dollars on dots we'll see that it's in the case of house prices it",
    "start": "336550",
    "end": "342010"
  },
  {
    "text": "usually has quite a linear relationship so we're looking for we're looking to create a model that's essentially",
    "start": "342010",
    "end": "348100"
  },
  {
    "text": "aligned so this is the basis of classic machine learning this is called linear regression and the way we come up with",
    "start": "348100",
    "end": "355450"
  },
  {
    "text": "this line is like this we start off with a random line and then we have this",
    "start": "355450",
    "end": "362860"
  },
  {
    "text": "curve that tells us how wrong we are so how far off are all the dots from this",
    "start": "362860",
    "end": "371080"
  },
  {
    "text": "line basically if I would use this line as my model or as my function how far",
    "start": "371080",
    "end": "376930"
  },
  {
    "text": "off would I be and we want to optimize and try to create a line that gets us to",
    "start": "376930",
    "end": "383290"
  },
  {
    "text": "the lowest possible error so we're optimizing and this particular thing is",
    "start": "383290",
    "end": "389020"
  },
  {
    "text": "called gradient descent I miss telling you this because this becomes the basis of deep",
    "start": "389020",
    "end": "397689"
  },
  {
    "text": "learning but this is basically all the math you're gonna need for this just remember that we have some way of",
    "start": "397689",
    "end": "404229"
  },
  {
    "text": "measuring how bad we're doing and we're trying to optimize how bad we're doing and that's the whole sort of everything",
    "start": "404229",
    "end": "411369"
  },
  {
    "text": "that machine learning does so we come up with this function we come of the way the weights for the line and we now have",
    "start": "411369",
    "end": "418209"
  },
  {
    "text": "function that the Machine decided but the problem is that while it might seem",
    "start": "418209",
    "end": "424869"
  },
  {
    "text": "like there is a linear relationship we all know that there's a lot of things that can affect the price of a house",
    "start": "424869",
    "end": "430949"
  },
  {
    "text": "like for example it's a linear relationship unless you have a pool because then you might have higher price",
    "start": "430949",
    "end": "437379"
  },
  {
    "text": "or unless you have for example in this case the size and the number of bedrooms",
    "start": "437379",
    "end": "443229"
  },
  {
    "text": "kind of tell you that it's a good family sized house and big houses work well in",
    "start": "443229",
    "end": "449709"
  },
  {
    "text": "in neighborhoods that have they're close to schools and close to some other things where a small apartment work well",
    "start": "449709",
    "end": "456519"
  },
  {
    "text": "way where there is like a lot of bars and a lot of things for young adults so",
    "start": "456519",
    "end": "463050"
  },
  {
    "text": "it's not a linear and you have to kind of figure out what are the features you",
    "start": "463050",
    "end": "468069"
  },
  {
    "text": "can kind of cram out of this data what kind of feature extraction can you do and again you have a human that has to",
    "start": "468069",
    "end": "475539"
  },
  {
    "text": "go through and like come up with all these features and relationships for you to make it a linear relationship in the",
    "start": "475539",
    "end": "482139"
  },
  {
    "text": "end but then enter deep learning so deep learning is when you put a lot of these",
    "start": "482139",
    "end": "489339"
  },
  {
    "text": "linear regressions together like you basically create big grouping of them",
    "start": "489339",
    "end": "495189"
  },
  {
    "text": "every single one of these dots which is called a unit a hidden unit in your",
    "start": "495189",
    "end": "501939"
  },
  {
    "text": "network it's essentially just a linear regression so it's doing the same optimization in this case we're looking",
    "start": "501939",
    "end": "509169"
  },
  {
    "text": "at a neural network that has three layers an input layer a hidden layer and",
    "start": "509169",
    "end": "515768"
  },
  {
    "text": "an output layer and the more layers you",
    "start": "515769",
    "end": "521078"
  },
  {
    "text": "have the more abstract features like family size or school",
    "start": "521079",
    "end": "526170"
  },
  {
    "text": "quality and things like that the machine learning algorithm will come up with so the more abstract or assuming the more",
    "start": "526170",
    "end": "533460"
  },
  {
    "text": "layers you have the more abstract it gets but you also have a boundary where the more layers you have the more",
    "start": "533460",
    "end": "539750"
  },
  {
    "text": "specific details that can come up with saying for example that a three-bedroom",
    "start": "539750",
    "end": "545790"
  },
  {
    "text": "house on this road at number blah blah blah is like $300,000 whatever so you",
    "start": "545790",
    "end": "554580"
  },
  {
    "text": "have to be careful because at some point you're going to learn some very specific things and either way this is a neural",
    "start": "554580",
    "end": "562530"
  },
  {
    "text": "networking space and if we look through three types of machine learning or AI",
    "start": "562530",
    "end": "568770"
  },
  {
    "text": "that we've been showing here we have expert systems with handcrafted rules it's very explainable but also very",
    "start": "568770",
    "end": "575960"
  },
  {
    "text": "labor intensive then we have classic machine learning where we come up with handcrafted features and then the",
    "start": "575960",
    "end": "583380"
  },
  {
    "text": "machine learning algorithms comes up with mappings kind of still quite labor intensive and then we have deep learning",
    "start": "583380",
    "end": "591860"
  },
  {
    "text": "where the deep learning comes up with the features and the mapping so it's not",
    "start": "591860",
    "end": "597090"
  },
  {
    "text": "labor intensive but on the other hand it's very data-intensive because to come up with all these relationships it now",
    "start": "597090",
    "end": "604320"
  },
  {
    "text": "has to come up with them from the data itself and we can go deeper and add more layers and it will come up with abstract",
    "start": "604320",
    "end": "610980"
  },
  {
    "text": "features and if you look at it from another sort of viewpoint an expert",
    "start": "610980",
    "end": "617820"
  },
  {
    "text": "system because we come up with all the rules ourselves we know exactly what made us think that this was a shoe or",
    "start": "617820",
    "end": "623340"
  },
  {
    "text": "we're a mother but at this end of the spectrum where the machine learning algorithms come up with everything we",
    "start": "623340",
    "end": "631050"
  },
  {
    "text": "don't know if it was the background or if it was the foreground or if it was the eyes or the paper cup or whatever",
    "start": "631050",
    "end": "636420"
  },
  {
    "text": "that came up with the conclusion she wore were morphing so it's less interpretable and we need to take care",
    "start": "636420",
    "end": "643140"
  },
  {
    "text": "of that somehow so what kind of nanos",
    "start": "643140",
    "end": "649080"
  },
  {
    "text": "sort of what deep learning does is it basic point but there are some things",
    "start": "649080",
    "end": "654240"
  },
  {
    "text": "that are very very magical about deep learning when I say",
    "start": "654240",
    "end": "659759"
  },
  {
    "text": "magical it's still gonna be math but it's magical like the things that we can actually achieve woody blur because in a",
    "start": "659759",
    "end": "668069"
  },
  {
    "text": "regular classic machine learning we can deal with structure data we can deal with data that's in a tabular format and",
    "start": "668069",
    "end": "674819"
  },
  {
    "text": "that works well but and we can do that in neural networks too but with deep",
    "start": "674819",
    "end": "681569"
  },
  {
    "text": "learning we can deal with spatial relationships so we can deal with images where it does matter if this pixel is",
    "start": "681569",
    "end": "688529"
  },
  {
    "text": "close to this one or not for example in the same way music or a voice or",
    "start": "688529",
    "end": "694169"
  },
  {
    "text": "something like that where it does matter how how they are related to each other and we can also work with sequences so",
    "start": "694169",
    "end": "701819"
  },
  {
    "text": "for example sequences of words sequences of like temperature that is dependent on",
    "start": "701819",
    "end": "708749"
  },
  {
    "text": "what the temperature was yesterday or - well you've recently or for example",
    "start": "708749",
    "end": "714779"
  },
  {
    "text": "things like sales forecasts where the sequence is important we can crack capture that kind of knowledge also in",
    "start": "714779",
    "end": "722129"
  },
  {
    "text": "in neural network so this is something we haven't been able to do before and I should say neural network really",
    "start": "722129",
    "end": "728939"
  },
  {
    "text": "started to become a thing like 2012 but I think it's recently like around maybe",
    "start": "728939",
    "end": "736079"
  },
  {
    "text": "last year or the year before it's where we've seen the huge advances that will",
    "start": "736079",
    "end": "742259"
  },
  {
    "text": "take us to the point where we're gonna we're gonna just get like pre fab",
    "start": "742259",
    "end": "748829"
  },
  {
    "text": "modules that we can use in even without",
    "start": "748829",
    "end": "754319"
  },
  {
    "text": "training them ourselves now if we look at a neural network one one very",
    "start": "754319",
    "end": "763139"
  },
  {
    "text": "interesting thing about it is that at this point so or I should say any of",
    "start": "763139",
    "end": "768329"
  },
  {
    "text": "these layers actually becomes something called an embedding and embedding ace like an encoded version of whatever",
    "start": "768329",
    "end": "775889"
  },
  {
    "text": "you're entering so for example if you're entering an image this is now an encoded",
    "start": "775889",
    "end": "783389"
  },
  {
    "text": "version of your image so an array of numbers that represents your image this was kind of like",
    "start": "783389",
    "end": "789870"
  },
  {
    "text": "something that when I discovered this things became so much clearer in in deep",
    "start": "789870",
    "end": "796500"
  },
  {
    "text": "learning because what what this means is that if you know that this is the",
    "start": "796500",
    "end": "802980"
  },
  {
    "text": "encoding for Asha wahwah or if this is an encoding for my face or something",
    "start": "802980",
    "end": "808260"
  },
  {
    "text": "like that you can then save this away for example in a database or or",
    "start": "808260",
    "end": "813750"
  },
  {
    "text": "somewhere else and he has to use that encoded version of the object where extracting information from and use that",
    "start": "813750",
    "end": "821040"
  },
  {
    "text": "in all sorts of ways so that is a very powerful thing one example of this is if",
    "start": "821040",
    "end": "826350"
  },
  {
    "text": "we take this cat when now pull it down to its like smallest encoding we can now either",
    "start": "826350",
    "end": "834840"
  },
  {
    "text": "choose to do a classification based on this saying you know is this more similar to encoding of cats or or dogs",
    "start": "834840",
    "end": "842430"
  },
  {
    "text": "or something like that or we can tack on another neural network that does",
    "start": "842430",
    "end": "848460"
  },
  {
    "text": "something very special that generates instead of encodes so we do the opposite",
    "start": "848460",
    "end": "853980"
  },
  {
    "text": "of this original neural network that kind of got us down to an encoding we can now decode and maybe generate",
    "start": "853980",
    "end": "861090"
  },
  {
    "text": "another picture that looks kind of like the first one but in this picture every",
    "start": "861090",
    "end": "867120"
  },
  {
    "text": "pixel is a classifier that says this particular pixel is a piece of a cat or",
    "start": "867120",
    "end": "872340"
  },
  {
    "text": "this particular pixel is a piece of trees for example which means that we can now use this to remove background or",
    "start": "872340",
    "end": "879330"
  },
  {
    "text": "to to do all sorts of things like that or determine for example if we do this",
    "start": "879330",
    "end": "884940"
  },
  {
    "text": "and a satellite image and and find out where there are houses we can see ok",
    "start": "884940",
    "end": "890700"
  },
  {
    "text": "what's the density of of housing in this area from the satellite image sure or",
    "start": "890700",
    "end": "895890"
  },
  {
    "text": "whatever it could be that we're trying to just segment out so this is a quite powerful feature that we can combine and",
    "start": "895890",
    "end": "902490"
  },
  {
    "text": "then code or in a decoder in this case we're encoding a message and we're",
    "start": "902490",
    "end": "910820"
  },
  {
    "text": "generating a new message so we're encoding an email and generating a possible answer to that email or we can",
    "start": "910820",
    "end": "918330"
  },
  {
    "text": "take something like encoding a picture and generate a caption",
    "start": "918330",
    "end": "923790"
  },
  {
    "text": "so the come like the combinations we can create kind of like Lego blocks is",
    "start": "923790",
    "end": "929000"
  },
  {
    "text": "amazingly powerful with deep learning I was talking earlier about creating like",
    "start": "929000",
    "end": "934800"
  },
  {
    "text": "encodings for example for faces so this is face met from google and basically a",
    "start": "934800",
    "end": "943530"
  },
  {
    "text": "way to encode my face in 128 bytes so i",
    "start": "943530",
    "end": "949020"
  },
  {
    "text": "am my face is now an array of two 128 bytes and we can see all these colors are dots of encoding of the same person",
    "start": "949020",
    "end": "959790"
  },
  {
    "text": "but different pictures of the same person now it's a hundred and twenty eight dimensions but project it into two",
    "start": "959790",
    "end": "966030"
  },
  {
    "text": "dimensions kind of similarly to you take a 3d world and you project it to a 2d TV",
    "start": "966030",
    "end": "971670"
  },
  {
    "text": "screen you can still capture most of the information but this is a similar",
    "start": "971670",
    "end": "977670"
  },
  {
    "text": "representation except for we've gone from 128 dimensions to 2 the cool thing about this is that as you",
    "start": "977670",
    "end": "983700"
  },
  {
    "text": "can see they cluster quite nicely together in fact I'm going to show you all the pictures of the people here and",
    "start": "983700",
    "end": "991190"
  },
  {
    "text": "and these embeddings are are also super powerful because and we can use them to",
    "start": "991190",
    "end": "998100"
  },
  {
    "text": "split different like they quite well encode like semantics about the person",
    "start": "998100",
    "end": "1005450"
  },
  {
    "text": "like maybe if it's a female or a male is something that we can kind of just",
    "start": "1005450",
    "end": "1011480"
  },
  {
    "text": "didn't distinguish from something like this or it does kind of build in on like",
    "start": "1011480",
    "end": "1017330"
  },
  {
    "text": "meaning now one thing that I should point out here and I will get to this a little bit later is that all of these",
    "start": "1017330",
    "end": "1026420"
  },
  {
    "text": "are very dependent on whatever data they are trained on and it's kind of a",
    "start": "1026420",
    "end": "1032300"
  },
  {
    "text": "well-known thing that face detection is trained on unfortunately a data that",
    "start": "1032300",
    "end": "1038480"
  },
  {
    "text": "it's not representative of the whole population so one effect of that it's",
    "start": "1038480",
    "end": "1044420"
  },
  {
    "text": "actually a data set is very male and very pale because it's trained on data",
    "start": "1044420",
    "end": "1053450"
  },
  {
    "text": "from Yahoo News from or I should so use Benesch marked Iran against data",
    "start": "1053450",
    "end": "1059119"
  },
  {
    "text": "from Yahoo News from 2008 to 2012 which means for example for females I'm very",
    "start": "1059119",
    "end": "1068360"
  },
  {
    "text": "happy that it classified me is 26 less happy that it classified me as a man but",
    "start": "1068360",
    "end": "1074029"
  },
  {
    "text": "things like that happened because it hasn't seen enough women compared to men and things like that so when we create",
    "start": "1074029",
    "end": "1080539"
  },
  {
    "text": "these systems we have to make sure that our data is like inclusive and and",
    "start": "1080539",
    "end": "1087519"
  },
  {
    "text": "representative so that it learns the right things we can also do word",
    "start": "1087519",
    "end": "1094190"
  },
  {
    "text": "embeddings so word embeddings is basically encoding a word in this case we can see so this is quite powerful for",
    "start": "1094190",
    "end": "1100490"
  },
  {
    "text": "a lot of different applications so in this case we can see that these are words are very similar to each other",
    "start": "1100490",
    "end": "1105889"
  },
  {
    "text": "happy excited overjoyed thrilled disappointed shows up here because it's",
    "start": "1105889",
    "end": "1111019"
  },
  {
    "text": "in the same kind of region of words as the other ones but you could think of using is the word embeddings in whatever",
    "start": "1111019",
    "end": "1118519"
  },
  {
    "text": "context to where you would need similar words like synonyms of things and we can",
    "start": "1118519",
    "end": "1124190"
  },
  {
    "text": "also from the embeddings get relationships like man is to King as woman√≠s to Queen so if they have the",
    "start": "1124190",
    "end": "1131299"
  },
  {
    "text": "same vector between them they will be they will have the same relationship so these embeddings are extremely powerful",
    "start": "1131299",
    "end": "1138289"
  },
  {
    "text": "not only for for machine learning but once the models are created you can use",
    "start": "1138289",
    "end": "1143360"
  },
  {
    "text": "them you can use this knowledge in your applications and actually make use of that another thing another cool",
    "start": "1143360",
    "end": "1150700"
  },
  {
    "text": "application I wanted to point out before we get into the practical aspects is this is Nvidia and so Nvidia has a big",
    "start": "1150700",
    "end": "1159169"
  },
  {
    "text": "stake in machine learning because the NVIDIA GPUs are basically the only thing and we do machine learning on most",
    "start": "1159169",
    "end": "1165649"
  },
  {
    "text": "machine learning frameworks only run on an NVIDIA GPUs but they've created this",
    "start": "1165649",
    "end": "1171529"
  },
  {
    "text": "a generator that generates faces of images so if you look at these images",
    "start": "1171529",
    "end": "1178909"
  },
  {
    "text": "and used to think that these faces do not exist like these people don't exist",
    "start": "1178909",
    "end": "1184399"
  },
  {
    "text": "these people are completely computer-generated you start realizing like the power",
    "start": "1184399",
    "end": "1191200"
  },
  {
    "text": "these systems I think this is amazing so",
    "start": "1191200",
    "end": "1198230"
  },
  {
    "start": "1196000",
    "end": "1196000"
  },
  {
    "text": "I take all the cool things that we can do but how do we do it so a",
    "start": "1198230",
    "end": "1203600"
  },
  {
    "text": "convolutional neural network is used for for image processing or image",
    "start": "1203600",
    "end": "1209540"
  },
  {
    "text": "classification and we're gonna do image classification like do the ship Watson",
    "start": "1209540",
    "end": "1214760"
  },
  {
    "text": "muffin thing so the first thing you do is you train it with a lot of images of the things that you want to be able to",
    "start": "1214760",
    "end": "1221570"
  },
  {
    "text": "classify and when you go through through sort of the classification what happens",
    "start": "1221570",
    "end": "1228710"
  },
  {
    "text": "is I throw in a picture of a cat I can't draw Chihuahuas so I have to use gas",
    "start": "1228710",
    "end": "1234080"
  },
  {
    "text": "instead but in the first layer for example it may extract some simple features like limes or or colors or",
    "start": "1234080",
    "end": "1242810"
  },
  {
    "text": "things like that and mark that this region of the image contains like a line",
    "start": "1242810",
    "end": "1248990"
  },
  {
    "text": "this region of the image contains a color and things like that and then it combines them to more abstract features",
    "start": "1248990",
    "end": "1255740"
  },
  {
    "text": "and it might find regions of faces or it might find regions of tires in a car or",
    "start": "1255740",
    "end": "1263330"
  },
  {
    "text": "in this case maybe ears arise and things like that and eventually it will combine",
    "start": "1263330",
    "end": "1268850"
  },
  {
    "text": "all these together and say you know I found like all these things that made me",
    "start": "1268850",
    "end": "1275180"
  },
  {
    "text": "think it was a cat and this little thing that made me think it was a muffin so it's like in 91 percent chance there's",
    "start": "1275180",
    "end": "1282020"
  },
  {
    "text": "cat in here and that's sort of what machine learning or what convolutional",
    "start": "1282020",
    "end": "1287570"
  },
  {
    "text": "neural networks do so the word convolution comes from just a matrix",
    "start": "1287570",
    "end": "1294050"
  },
  {
    "text": "multiplication it's it's a mathematical term but in reality what it is is a",
    "start": "1294050",
    "end": "1299150"
  },
  {
    "text": "filter you've seen it probably lost sometimes before were you reused for",
    "start": "1299150",
    "end": "1304550"
  },
  {
    "text": "example do a sobel filter that will extract like the the lines of of a face",
    "start": "1304550",
    "end": "1312080"
  },
  {
    "text": "or something like that or it could be any type of a filter really and it",
    "start": "1312080",
    "end": "1317330"
  },
  {
    "text": "doesn't really matter because they the part that the machine learning algorithm",
    "start": "1317330",
    "end": "1322820"
  },
  {
    "text": "does is come up with easeful so you don't have to come up with these filters yourself way back when we would",
    "start": "1322820",
    "end": "1330380"
  },
  {
    "text": "come up with these filters yes I will come up with the features in in classic",
    "start": "1330380",
    "end": "1335420"
  },
  {
    "text": "machine learning but with deep learning the deep learning comes up with the filters max pooling in this case is a",
    "start": "1335420",
    "end": "1342320"
  },
  {
    "text": "way to to compress the images you basically use take for example four",
    "start": "1342320",
    "end": "1349100"
  },
  {
    "text": "adjacent pixels and say did I activate any of them did I find a straight line",
    "start": "1349100",
    "end": "1354560"
  },
  {
    "text": "and anything if so I'm gonna say yes and and then compress and basically you now",
    "start": "1354560",
    "end": "1362930"
  },
  {
    "text": "have a smaller picture that that has a yes or no for if you find if you find a",
    "start": "1362930",
    "end": "1368330"
  },
  {
    "text": "line in this region but the whole point of this is that this convolutional part",
    "start": "1368330",
    "end": "1374800"
  },
  {
    "text": "extracts the features that's the part that basically say finds all these abstract features and then we tack on a",
    "start": "1374800",
    "end": "1381470"
  },
  {
    "text": "classifier that basically says this is a cat this is a muffin or is this a human",
    "start": "1381470",
    "end": "1388000"
  },
  {
    "text": "so the filters could look like this like finding like talk Lions are to find",
    "start": "1388000",
    "end": "1394850"
  },
  {
    "text": "colors or something but you don't have to worry about the filters it's just sort of a representation so this would",
    "start": "1394850",
    "end": "1400100"
  },
  {
    "text": "be the output of once you've gone through the first layer like it will show these images that's the input to",
    "start": "1400100",
    "end": "1407540"
  },
  {
    "text": "the next layer instead so if we look at a visualization of this here I know I",
    "start": "1407540",
    "end": "1418820"
  },
  {
    "text": "got it so I'll draw the word three or the number three and this one for",
    "start": "1418820",
    "end": "1426230"
  },
  {
    "text": "example is a filter that detect diagonal",
    "start": "1426230",
    "end": "1431450"
  },
  {
    "text": "lines so you can see like the closest part of that picture shows the filter",
    "start": "1431450",
    "end": "1437840"
  },
  {
    "text": "and it will then generate a feature map would like to do that a diagonal lines",
    "start": "1437840",
    "end": "1443680"
  },
  {
    "text": "represented and this one shows diagonal lines the other way and so on and so",
    "start": "1443680",
    "end": "1449810"
  },
  {
    "text": "forth and then we have the compression which basically it compresses that image and then the next stage you can't really",
    "start": "1449810",
    "end": "1456830"
  },
  {
    "text": "see it as a picture anymore but this is an activation that shows hey western you know and those in",
    "start": "1456830",
    "end": "1462710"
  },
  {
    "text": "there or Westar all these things and then compress again and then flatten it out so this is where",
    "start": "1462710",
    "end": "1469309"
  },
  {
    "text": "we start doing the classification and eventually we get to the number three in",
    "start": "1469309",
    "end": "1474890"
  },
  {
    "text": "here so this is basically how a convolutional neural network looks in",
    "start": "1474890",
    "end": "1480830"
  },
  {
    "text": "action but how do we create one of these",
    "start": "1480830",
    "end": "1489309"
  },
  {
    "text": "so we take pictures of Chihuahuas and pictures of Mustangs and the first thing",
    "start": "1489309",
    "end": "1495470"
  },
  {
    "text": "we do is so this in this particular case I've taken 500 pictures of Chihuahuas",
    "start": "1495470",
    "end": "1500809"
  },
  {
    "text": "and 500 pictures of muffins from searches on the internet and I separate",
    "start": "1500809",
    "end": "1506630"
  },
  {
    "text": "them out into three different portions the first one the biggest one is going",
    "start": "1506630",
    "end": "1512419"
  },
  {
    "text": "to be a training material so that's what the machine learning algorithm is going to learn from then I have one section",
    "start": "1512419",
    "end": "1519950"
  },
  {
    "text": "maybe 10 to 20% of the data goes to validation and this is because we're",
    "start": "1519950",
    "end": "1526220"
  },
  {
    "text": "always kind of going to learn very very specific things from the training material but we also want to make sure",
    "start": "1526220",
    "end": "1532850"
  },
  {
    "text": "it generalizes and kind of you can be",
    "start": "1532850",
    "end": "1537919"
  },
  {
    "text": "able to classify images that it hasn't seen before so we have to validate it on",
    "start": "1537919",
    "end": "1543640"
  },
  {
    "text": "validation data and then we'll go through a loop and do this a couple of times and and try some new things and",
    "start": "1543640",
    "end": "1550760"
  },
  {
    "text": "once we're done with with the whole process would then go over to our test data and validated one last time and",
    "start": "1550760",
    "end": "1558470"
  },
  {
    "text": "normally if you're doing something like this you might have training and validation data that comes from the internet",
    "start": "1558470",
    "end": "1563929"
  },
  {
    "text": "maybe quite clean cut pictures of muffins and and she was but then you",
    "start": "1563929",
    "end": "1570440"
  },
  {
    "text": "want to be able to classify something like blurry pictures that a user takes on on a mobile phone for example then",
    "start": "1570440",
    "end": "1577880"
  },
  {
    "text": "you want your trade in your test data your ultimate data to be very close to what the user is looking for so you want",
    "start": "1577880",
    "end": "1586070"
  },
  {
    "text": "quite large numbers in in the training and",
    "start": "1586070",
    "end": "1591260"
  },
  {
    "text": "and validation now I should say 500 is",
    "start": "1591260",
    "end": "1596630"
  },
  {
    "text": "not a large number at all but there are ways to make 500 pictures work and we'll",
    "start": "1596630",
    "end": "1602960"
  },
  {
    "text": "we'll get to that because often times you don't have a lot more than that so",
    "start": "1602960",
    "end": "1608320"
  },
  {
    "text": "the first thing we do is we're gonna basically use in this case we're going",
    "start": "1608320",
    "end": "1614330"
  },
  {
    "text": "to use something called Karis it's a framework in Python and the dust deep learning quite easy and we're gonna take",
    "start": "1614330",
    "end": "1622310"
  },
  {
    "text": "and train on batches of in this case 20 pictures at a time and so she's gonna",
    "start": "1622310",
    "end": "1628400"
  },
  {
    "text": "draw a random set of 20 images from from the training data some of them are",
    "start": "1628400",
    "end": "1633680"
  },
  {
    "text": "labeled with serum Vesta show us and some of them are labeled wood ones which are the muffins and then we'll just pass",
    "start": "1633680",
    "end": "1640910"
  },
  {
    "text": "them through all these things where it finds the the features it compresses",
    "start": "1640910",
    "end": "1646850"
  },
  {
    "text": "them finds the features and so on and classifies them and then says how wrong are we and then go back and sort of fix",
    "start": "1646850",
    "end": "1654140"
  },
  {
    "text": "the linear regressions on the way back and we build our network so this is the",
    "start": "1654140",
    "end": "1661670"
  },
  {
    "text": "network we want to build and some first some filters in the beginnings and max",
    "start": "1661670",
    "end": "1667580"
  },
  {
    "text": "pooling there's more filters max pooling and then a dense and another dense layer",
    "start": "1667580",
    "end": "1673580"
  },
  {
    "text": "so this is literally how easy it is from a coding point of view the coding is not",
    "start": "1673580",
    "end": "1680300"
  },
  {
    "text": "hard the data is the hard part of machine learning but here we have 32",
    "start": "1680300",
    "end": "1685820"
  },
  {
    "text": "filters that are three by three and the input shape of our images it's 150 by",
    "start": "1685820",
    "end": "1692300"
  },
  {
    "text": "150 max pool and then we add on another 64 filters do another four max pool",
    "start": "1692300",
    "end": "1698290"
  },
  {
    "text": "flatten it out so flattening means that we basically put all the pixels in a row so if we have a picture that's like 28",
    "start": "1698290",
    "end": "1705920"
  },
  {
    "text": "by 28 was the yes but 28 + 28 verse 28 and so on and so forth and then he had",
    "start": "1705920",
    "end": "1712010"
  },
  {
    "text": "another layer and the don't layer down here that's the classification layer",
    "start": "1712010",
    "end": "1717020"
  },
  {
    "text": "finally we add on our output layer which is in this case something called a sigmoid a sigmoid looks like this",
    "start": "1717020",
    "end": "1724730"
  },
  {
    "text": "yes and anything that's going to come out of a neural network it's going to be",
    "start": "1724730",
    "end": "1729860"
  },
  {
    "text": "a number and what we're saying with the sigmoid is if there's a very low number we're gonna get zero so we're gonna get",
    "start": "1729860",
    "end": "1736340"
  },
  {
    "text": "you all what if it's a very high number we're gonna guess muffin and basically",
    "start": "1736340",
    "end": "1742490"
  },
  {
    "text": "the closer it is to the middle the more unsure we are so at this point we're",
    "start": "1742490",
    "end": "1748910"
  },
  {
    "text": "100% sure at this point we're 50/50 and at this point we're 100% sure that it's",
    "start": "1748910",
    "end": "1754490"
  },
  {
    "text": "actually walk so we get probabilities on top of the selection as well so this is",
    "start": "1754490",
    "end": "1763460"
  },
  {
    "text": "basically the architecture of how it looks like and here we can see something interesting we now have 42,000 pixels or",
    "start": "1763460",
    "end": "1772570"
  },
  {
    "text": "or parameters that we can look at so there's 40 mm or 42 million sorry places",
    "start": "1772570",
    "end": "1779870"
  },
  {
    "text": "where we can store a little bits of data and that's a lot especially if we have",
    "start": "1779870",
    "end": "1785990"
  },
  {
    "text": "little data to work with because now it could for example store things like if I",
    "start": "1785990",
    "end": "1791780"
  },
  {
    "text": "have a white pixel in the first in the first Square and then I have a red pixel",
    "start": "1791780",
    "end": "1797510"
  },
  {
    "text": "here then I know it's a chihuahua because that was the only like that combination only worked on XI Wallace so",
    "start": "1797510",
    "end": "1803660"
  },
  {
    "text": "it could learn some very very specific things and that is why we need the validation data to make sure that we're",
    "start": "1803660",
    "end": "1809770"
  },
  {
    "text": "we're not just learning like weird things and that won't generalize the",
    "start": "1809770",
    "end": "1817700"
  },
  {
    "text": "next thing we do is we compile it and we compile it and say in this case we're",
    "start": "1817700",
    "end": "1824030"
  },
  {
    "text": "gonna do a binary like 0 or 1 so we're gonna use a loss function like this orange curve is going to be something",
    "start": "1824030",
    "end": "1831710"
  },
  {
    "text": "called a binary cross-entropy it's just a matter of like determining how wrong we are it's if you will is just",
    "start": "1831710",
    "end": "1839510"
  },
  {
    "text": "basically saying if you guessed 1 and I said 0 where this is going to give a 1",
    "start": "1839510",
    "end": "1845540"
  },
  {
    "text": "and if you can say to 0 and guess one then it's gonna give a minus 1 and then",
    "start": "1845540",
    "end": "1851120"
  },
  {
    "text": "would take some logarithms and a couple of things like that don't worry about that that's a standard way of measuring",
    "start": "1851120",
    "end": "1856580"
  },
  {
    "text": "how wrong we and then this LR learning rate basically",
    "start": "1856580",
    "end": "1862460"
  },
  {
    "text": "it tells us how fast we go down this gradient with this blue dot here and the",
    "start": "1862460",
    "end": "1868190"
  },
  {
    "text": "final one is that we're going to look at accuracy so accuracy means how many did",
    "start": "1868190",
    "end": "1873620"
  },
  {
    "text": "we get correct out of the whole site and then we we now go through and train it",
    "start": "1873620",
    "end": "1880310"
  },
  {
    "text": "and in here resetting we're going to take 20 passes through the data before we're happy so we're gonna try and learn",
    "start": "1880310",
    "end": "1888470"
  },
  {
    "text": "from the data and then learn again and again and again and again and do that 20 times normally if you're not happy after",
    "start": "1888470",
    "end": "1895100"
  },
  {
    "text": "20 times you might do another twenty times making us continue on the same run",
    "start": "1895100",
    "end": "1901490"
  },
  {
    "text": "so to speak so we run into or we get to something like this so run number",
    "start": "1901490",
    "end": "1907700"
  },
  {
    "text": "fifteen oh here I did thirty run number fifty in a 30 this a couple of things I",
    "start": "1907700",
    "end": "1915020"
  },
  {
    "text": "want to point out here the first one and this is the time it took to do one to",
    "start": "1915020",
    "end": "1920240"
  },
  {
    "text": "run through the data I'm pointing this out this is 16 seconds and this is on my",
    "start": "1920240",
    "end": "1925520"
  },
  {
    "text": "surface book and with a GPU like a 1060 graphics card I'm pointing this out",
    "start": "1925520",
    "end": "1932930"
  },
  {
    "text": "because a lot of people think that it's going to take a long time to do deep learning it doesn't necessarily do that",
    "start": "1932930",
    "end": "1938750"
  },
  {
    "text": "specifically if you don't have a lot of data it doesn't take a lot of time if you have millions and millions of",
    "start": "1938750",
    "end": "1944210"
  },
  {
    "text": "pictures yeah it will but you can also do deep learning on a decent machine",
    "start": "1944210",
    "end": "1950180"
  },
  {
    "text": "specifically if you have a GPU in not so on the other things that are interesting",
    "start": "1950180",
    "end": "1956510"
  },
  {
    "text": "here are this is the metrics for the training data and this is a metrics for the validation data so the loss is",
    "start": "1956510",
    "end": "1963200"
  },
  {
    "text": "basically what's the difference between complete accuracy or complete like no",
    "start": "1963200",
    "end": "1969950"
  },
  {
    "text": "errors at all and and what errors we got and we want to kind of like make this as",
    "start": "1969950",
    "end": "1975260"
  },
  {
    "text": "small as possible that's what who were to optimize for accuracy again is how many we got",
    "start": "1975260",
    "end": "1981890"
  },
  {
    "text": "correct like how many percentage we got correct so we can see we got an accuracy of 98 for each 65 on the training set",
    "start": "1981890",
    "end": "1990110"
  },
  {
    "text": "but nine do 1% on the validation set and we want",
    "start": "1990110",
    "end": "1995990"
  },
  {
    "text": "to specifically look at the validation sets that's the only thing that's important for us so we're here but we",
    "start": "1995990",
    "end": "2004210"
  },
  {
    "text": "see something that's a little bit weird and that's if we look at the validation and training data and there is a big gap",
    "start": "2004210",
    "end": "2011470"
  },
  {
    "text": "between where we end up as far as like how good we're doing on the training and",
    "start": "2011470",
    "end": "2016540"
  },
  {
    "text": "how good we're doing on on the validation set and this is the Nemesis",
    "start": "2016540",
    "end": "2022060"
  },
  {
    "text": "of all machine learning are all deep learning it's called overfitting and it basically means that we learned something about",
    "start": "2022060",
    "end": "2029380"
  },
  {
    "text": "training data but didn't apply to the validation data maybe we learn that like",
    "start": "2029380",
    "end": "2037270"
  },
  {
    "text": "all of our our dogs in the training data we're sitting on a grass background but",
    "start": "2037270",
    "end": "2043630"
  },
  {
    "text": "they weren't in the validation data or something like that so this is normal but we need to do",
    "start": "2043630",
    "end": "2051639"
  },
  {
    "text": "something about it so what could we possibly do to fix this any ideas like",
    "start": "2051640",
    "end": "2057460"
  },
  {
    "text": "how could we learn a more general yeah",
    "start": "2057460",
    "end": "2061770"
  },
  {
    "text": "yeah reduce the number of neurons very good generate more training data have",
    "start": "2062669",
    "end": "2070360"
  },
  {
    "text": "you seen this before so generate more training data as the first one we're",
    "start": "2070360",
    "end": "2077080"
  },
  {
    "text": "going to be looking at so we could be gathering more training data if there is",
    "start": "2077080",
    "end": "2082658"
  },
  {
    "text": "a possibility we should always try to generate or it'll like try to gather more training data but sometimes that's",
    "start": "2082659",
    "end": "2089110"
  },
  {
    "text": "not possible and even if it is possible we can do something else with images and",
    "start": "2089110",
    "end": "2094540"
  },
  {
    "text": "that is called data augmentation so what we can do is we can take every image and",
    "start": "2094540",
    "end": "2100210"
  },
  {
    "text": "say hey just alter it a little bit you know flip it so the dog is looking the",
    "start": "2100210",
    "end": "2106210"
  },
  {
    "text": "other way or skew it a little bit like transpose to picture a little bit up or",
    "start": "2106210",
    "end": "2112390"
  },
  {
    "text": "down or or maybe tilt it a little bit an angle or something like that you could even add like a color filter or",
    "start": "2112390",
    "end": "2119530"
  },
  {
    "text": "something as long as it's still a Dalek we're still good and usually there",
    "start": "2119530",
    "end": "2126190"
  },
  {
    "text": "in all these frameworks there's this is automatic you can say I'm okay with you",
    "start": "2126190",
    "end": "2132380"
  },
  {
    "text": "doing like transpose and flip and all these things in some cases it doesn't make sense to do that for example if you",
    "start": "2132380",
    "end": "2139250"
  },
  {
    "text": "if you're looking at a satellite image it doesn't necessarily maybe make sense",
    "start": "2139250",
    "end": "2145910"
  },
  {
    "text": "to tilt it or something like that that would not be in the case thing but for for objects like Chihuahuas it's totally",
    "start": "2145910",
    "end": "2152570"
  },
  {
    "text": "an okay thing so now we're suddenly at a point where we have tons and tons and",
    "start": "2152570",
    "end": "2159170"
  },
  {
    "text": "tons more pictures than we had initially and what we're also learning from this is that we're learning that dogs don't",
    "start": "2159170",
    "end": "2166370"
  },
  {
    "text": "necessarily always sit facing this way even from the same pictures we can learn darts that are faced in both ways or",
    "start": "2166370",
    "end": "2173390"
  },
  {
    "text": "that have a slightly different posture so that is one way data augmentation the",
    "start": "2173390",
    "end": "2179000"
  },
  {
    "text": "other point is what he said remove some of the neurons make them make this a",
    "start": "2179000",
    "end": "2186290"
  },
  {
    "text": "little bit stupider so randomly every time we do a run every time would you",
    "start": "2186290",
    "end": "2192650"
  },
  {
    "text": "pass through a new batch of data we're gonna randomly remove some neurons so we",
    "start": "2192650",
    "end": "2198980"
  },
  {
    "text": "might remove the neuron that remembered the color red we might remember the",
    "start": "2198980",
    "end": "2204710"
  },
  {
    "text": "neuron that remember like diagonal lines who knows in this particular path we",
    "start": "2204710",
    "end": "2210170"
  },
  {
    "text": "might have done that and then we we have less of a risk that we're learning very specific things about this where we have",
    "start": "2210170",
    "end": "2218270"
  },
  {
    "text": "less of a risk that we're learning like a red dot in the center here so this is",
    "start": "2218270",
    "end": "2223460"
  },
  {
    "text": "called dropout and this is one of the ways that we're also making everything",
    "start": "2223460",
    "end": "2230210"
  },
  {
    "text": "more reliable so now we can train longer before we've learned all the specifics and we end up something like then when I",
    "start": "2230210",
    "end": "2237320"
  },
  {
    "text": "put something like this so after say 30 times we'll get to a",
    "start": "2237320",
    "end": "2242480"
  },
  {
    "text": "point where we're good about the training data and our validation data also looks very very similar to our",
    "start": "2242480",
    "end": "2249410"
  },
  {
    "text": "training data but we might be also at",
    "start": "2249410",
    "end": "2255050"
  },
  {
    "text": "the point where we haven't done all the way there so we're now at ninety three point six",
    "start": "2255050",
    "end": "2262870"
  },
  {
    "text": "percent or so the next step to get this even better would be to get more and",
    "start": "2262870",
    "end": "2268090"
  },
  {
    "text": "more data until we can learn a lot more general behavior but there is something else that we can do actually before I",
    "start": "2268090",
    "end": "2276040"
  },
  {
    "text": "get into that let's take a look at measuring first so this is something",
    "start": "2276040",
    "end": "2281140"
  },
  {
    "text": "called a confusion matrix and what is showing is out of the XI Wallace and",
    "start": "2281140",
    "end": "2286300"
  },
  {
    "text": "muffins out of the showers we classified 92 of them correctly out of the muffins we classified 86 of",
    "start": "2286300",
    "end": "2294070"
  },
  {
    "text": "them correctly so one thing we can do now is take a look at what these will",
    "start": "2294070",
    "end": "2299860"
  },
  {
    "text": "show us that we classified correctly are most correct and muffins these were some",
    "start": "2299860",
    "end": "2305080"
  },
  {
    "text": "that we didn't classify correctly and these were some muffins that we didn't classify correctly so now we can take a",
    "start": "2305080",
    "end": "2311080"
  },
  {
    "text": "look through the ones that we misclassified and say hey was there something about them that you know we",
    "start": "2311080",
    "end": "2317770"
  },
  {
    "text": "don't have enough spotted chihuahuas for example so we can't recognize that kind",
    "start": "2317770",
    "end": "2322930"
  },
  {
    "text": "we also see for example in this case that we have some weird pictures like this one so maybe we should clean up our",
    "start": "2322930",
    "end": "2330910"
  },
  {
    "text": "data set and not have things that don't apply like that or here we have like a",
    "start": "2330910",
    "end": "2335950"
  },
  {
    "text": "green muffin that's maybe not something our our classifier has to to be able to",
    "start": "2335950",
    "end": "2343780"
  },
  {
    "text": "classify so there's some manual kind of looking through the data and see but we",
    "start": "2343780",
    "end": "2349540"
  },
  {
    "text": "can also do something and that's going to boost our productivity a lot and that",
    "start": "2349540",
    "end": "2356740"
  },
  {
    "text": "is using pre trade models so in this case would take something and so this is",
    "start": "2356740",
    "end": "2363550"
  },
  {
    "text": "in a convolutional neural network this particular architecture is called VGG 16",
    "start": "2363550",
    "end": "2368910"
  },
  {
    "text": "but it's been pre trained await a data set called image net image net is like",
    "start": "2368910",
    "end": "2375040"
  },
  {
    "text": "millions of images of everyday items and it's already done like all the encoding",
    "start": "2375040",
    "end": "2381040"
  },
  {
    "text": "is totally learned like all the features and it's it's very good at encoding images of everyday objects so what we do",
    "start": "2381040",
    "end": "2388870"
  },
  {
    "text": "is and this actually outputs one out of thousand different classes cats dogs",
    "start": "2388870",
    "end": "2394489"
  },
  {
    "text": "chairs lamps whatever and and we can use remove this part tack on our own",
    "start": "2394489",
    "end": "2402079"
  },
  {
    "text": "classifier that only classifies Chihuahuas and muffins still using like",
    "start": "2402079",
    "end": "2407839"
  },
  {
    "text": "all the knowledge that is scattered from all these million things and then we say don't train this yes give us the sort of",
    "start": "2407839",
    "end": "2415910"
  },
  {
    "text": "like the embedding like the encoding of the image and then I'll do the classification and suddenly we can use",
    "start": "2415910",
    "end": "2421729"
  },
  {
    "text": "the training knife and million images we're only having to do the learning on",
    "start": "2421729",
    "end": "2428719"
  },
  {
    "text": "the she Wallace and muffins and doing something like this means that we're gonna take like around a second per a",
    "start": "2428719",
    "end": "2435199"
  },
  {
    "text": "park-like around a second per pass through our data and we're gonna gather all the knowledge from before you can",
    "start": "2435199",
    "end": "2441079"
  },
  {
    "text": "think of it guys everything you've learned through a lifetime you can apply to maybe like you can apply a lot of it",
    "start": "2441079",
    "end": "2448609"
  },
  {
    "text": "to a new task that you're given because a lot of it will still sort of apply to",
    "start": "2448609",
    "end": "2454640"
  },
  {
    "text": "the new task and you don't have to learn like everything from scratch and when we do this we'll see something like this",
    "start": "2454640",
    "end": "2460400"
  },
  {
    "text": "this is even with a 500 images so we end",
    "start": "2460400",
    "end": "2465529"
  },
  {
    "text": "up with like an accuracy of ninety nine point forty seven which is humongously",
    "start": "2465529",
    "end": "2471829"
  },
  {
    "text": "good is like awesome mostly because image net contains a lot of she wallace and a lot of muffins but",
    "start": "2471829",
    "end": "2478849"
  },
  {
    "text": "in general everyday objects learn a lot from this thing called transfer learning",
    "start": "2478849",
    "end": "2483890"
  },
  {
    "text": "so transfer learning is like a key element of deep learning and that you",
    "start": "2483890",
    "end": "2489920"
  },
  {
    "text": "should definitely employ if you're doing deep learning now I should say awesome ninety nine point forty seven percent",
    "start": "2489920",
    "end": "2495949"
  },
  {
    "text": "here with the amount of data I have in my validation set that means I got from",
    "start": "2495949",
    "end": "2502130"
  },
  {
    "text": "one wrong and sometimes when I do a run like this I could see all wrong so we're",
    "start": "2502130",
    "end": "2508009"
  },
  {
    "text": "up to like close to a hundred percent no um that's how you do and deep learning",
    "start": "2508009",
    "end": "2516259"
  },
  {
    "text": "so you could if you don't want to do this model by yourself and he's kind of",
    "start": "2516259",
    "end": "2521839"
  },
  {
    "text": "one we use the knowledge of imagenet and everything you could use prefab like",
    "start": "2521839",
    "end": "2529040"
  },
  {
    "text": "computer vision cognitive services for example where you can just enter suor",
    "start": "2529040",
    "end": "2534210"
  },
  {
    "text": "and it will tell you all sorts of things like it's a dog it's indoor it's cute blah blah blah like this is just an API",
    "start": "2534210",
    "end": "2540840"
  },
  {
    "text": "that you could use from any any of your applications today and you could also if",
    "start": "2540840",
    "end": "2547590"
  },
  {
    "text": "you have some specific like you have a need specifically look at she Wallace",
    "start": "2547590",
    "end": "2553170"
  },
  {
    "start": "2548000",
    "end": "2548000"
  },
  {
    "text": "and muffins we all do and then then you can take and do transfer learning and",
    "start": "2553170",
    "end": "2558840"
  },
  {
    "text": "transfer learning can be done with something called custom vision in which case you upload your 500 images of",
    "start": "2558840",
    "end": "2564990"
  },
  {
    "text": "Chihuahuas and your 500 images of muffins and it will learn the specifics",
    "start": "2564990",
    "end": "2570360"
  },
  {
    "text": "and now you have a classifier an API that will you say is it a chihuahua or is it a muffin if there's you know",
    "start": "2570360",
    "end": "2577440"
  },
  {
    "text": "whatever you want to classify is this actually an insurance a good insurance claim or is it not maybe that's what you",
    "start": "2577440",
    "end": "2584160"
  },
  {
    "text": "want to classify them and it would do something like this and it gets them you",
    "start": "2584160",
    "end": "2589200"
  },
  {
    "text": "get the information about how good it is and you get an API that you can call I miss pointing this out because it's not",
    "start": "2589200",
    "end": "2595950"
  },
  {
    "text": "always necessary to go to the point of like dealing with this thing in Python you could actually just use the prefab",
    "start": "2595950",
    "end": "2603060"
  },
  {
    "text": "thing but either way you want to now go",
    "start": "2603060",
    "end": "2608550"
  },
  {
    "text": "through and learn what what heck did this model who learned did it learn like the white and red pixels or did it use",
    "start": "2608550",
    "end": "2616170"
  },
  {
    "text": "and did you learn something useful so",
    "start": "2616170",
    "end": "2622050"
  },
  {
    "text": "and put a quick lesson in critical thinking so sometimes you'll hear about",
    "start": "2622050",
    "end": "2629510"
  },
  {
    "text": "these wonderful systems that give a hundred percent accuracy or like 99",
    "start": "2629510",
    "end": "2635340"
  },
  {
    "text": "percent accuracy and it's wonderful and it's like you're kind of like it's computer said that so it must be true",
    "start": "2635340",
    "end": "2641280"
  },
  {
    "text": "and and all of that stuff and I want to kind of give you some critical thinking to say if you just take it one more turn",
    "start": "2641280",
    "end": "2649890"
  },
  {
    "text": "like maybe not believe everything you hear let's say we look at the system that's",
    "start": "2649890",
    "end": "2655170"
  },
  {
    "text": "going to look at credit card transactions so we're going to look at a million credit card transactions we have",
    "start": "2655170",
    "end": "2662940"
  },
  {
    "text": "200 fraudulent transactions in this and we want to create a system that can give",
    "start": "2662940",
    "end": "2669960"
  },
  {
    "text": "us like 99.99 percent accuracy on finding finding out if the transaction",
    "start": "2669960",
    "end": "2677220"
  },
  {
    "text": "is fraudulent or not what would be a good way to start what it would be some good features for example or yeah age of",
    "start": "2677220",
    "end": "2689220"
  },
  {
    "text": "person the location did you did you maybe do two transactions like one in",
    "start": "2689220",
    "end": "2695130"
  },
  {
    "text": "one country and one in a different country all great things there's a super easy way to get a ninety nine point",
    "start": "2695130",
    "end": "2701999"
  },
  {
    "text": "ninety eight percent accuracy on this data set and that is by saying every",
    "start": "2701999",
    "end": "2708509"
  },
  {
    "text": "transaction is good right if we say",
    "start": "2708509",
    "end": "2714450"
  },
  {
    "text": "every transaction is good we're at ninety nine point ninety eight percent awesome is it maybe not we're not",
    "start": "2714450",
    "end": "2723719"
  },
  {
    "text": "catching and in a single fraudulent transaction so be careful if people talk",
    "start": "2723719",
    "end": "2729089"
  },
  {
    "text": "about accuracy because you don't know how skewed a dataset is accuracy is kind",
    "start": "2729089",
    "end": "2734219"
  },
  {
    "text": "of only irrelevant if you have the data set that's like 50/50 so what could we",
    "start": "2734219",
    "end": "2740789"
  },
  {
    "text": "use as a measurement they will want to measure like how many of the fraudulent",
    "start": "2740789",
    "end": "2746579"
  },
  {
    "text": "transactions would catch that could be a good measurement it's a good way to get",
    "start": "2746579",
    "end": "2752400"
  },
  {
    "text": "a hundred percent on that it's by saying everything is fraud then you have a",
    "start": "2752400",
    "end": "2757859"
  },
  {
    "text": "hundred percent accuracy on all the fraudulent transactions √ßf didn't said do a combination of this",
    "start": "2757859",
    "end": "2763769"
  },
  {
    "text": "I just wanted to point this out as an example because it is extremely important to think about what you",
    "start": "2763769",
    "end": "2770099"
  },
  {
    "text": "measure and accuracy in a very high accuracy could either a mean that you're",
    "start": "2770099",
    "end": "2776640"
  },
  {
    "text": "overfitting you've learned too much about your training data it could also mean that you're measuring the wrong",
    "start": "2776640",
    "end": "2781769"
  },
  {
    "text": "thing it could mean that you're actually learning I hate things but there is a big chance",
    "start": "2781769",
    "end": "2787600"
  },
  {
    "text": "that it doesn't and the other thing we'll have to be careful about is",
    "start": "2787600",
    "end": "2793860"
  },
  {
    "text": "correlation versus causation so deep learning we'll find a pattern if there",
    "start": "2793860",
    "end": "2800080"
  },
  {
    "text": "is a pattern in the data we will find a pattern we will find the red dots and the white dots and everything but",
    "start": "2800080",
    "end": "2806920"
  },
  {
    "text": "sometimes and you might find things that are not necessarily exactly what you're",
    "start": "2806920",
    "end": "2811960"
  },
  {
    "text": "looking for so a while back there was a project at Microsoft where the the",
    "start": "2811960",
    "end": "2820000"
  },
  {
    "text": "objective was to find out for people with heart disease should they be inpatient or outpatient",
    "start": "2820000",
    "end": "2825550"
  },
  {
    "text": "basically should have be treated in the hospital or not and what were the chances of surviving in either case and",
    "start": "2825550",
    "end": "2831550"
  },
  {
    "text": "they found that people that had asked mahat very very high survival rate so",
    "start": "2831550",
    "end": "2839830"
  },
  {
    "text": "they should be treated as outpatients but it turns out the reason why they had",
    "start": "2839830",
    "end": "2845320"
  },
  {
    "text": "a very high survival rate was because they were already treated like a lot",
    "start": "2845320",
    "end": "2850390"
  },
  {
    "text": "earlier so they come into the hospital a lot for check-ups and things and and they were discovered a lot earlier in",
    "start": "2850390",
    "end": "2857470"
  },
  {
    "text": "the process for for heart disease this was a correlation but definitely not a",
    "start": "2857470",
    "end": "2864040"
  },
  {
    "text": "causation so one of the problems with deep learning is that it's hard to interpret what made it come to this",
    "start": "2864040",
    "end": "2871180"
  },
  {
    "text": "decision but if you'd realize that the system says if you have asked my you're",
    "start": "2871180",
    "end": "2876610"
  },
  {
    "text": "gonna survive then you realize that you maybe should take another and look at",
    "start": "2876610",
    "end": "2882430"
  },
  {
    "text": "your data and what is what is actually figuring out so they luckily figured this out before and before it was",
    "start": "2882430",
    "end": "2889540"
  },
  {
    "text": "released and they could remove a few things so yeah and so one way to do this",
    "start": "2889540",
    "end": "2897970"
  },
  {
    "text": "is through looking at interpretability of systems so this is a what he called",
    "start": "2897970",
    "end": "2905920"
  },
  {
    "text": "the Python library called lime and live means local interpretability of model",
    "start": "2905920",
    "end": "2911430"
  },
  {
    "text": "explanations and in this case what they had was after taste test data it had a number of",
    "start": "2911430",
    "end": "2918680"
  },
  {
    "text": "images of Huskies and a number of them images of wolves and they wanted to do a classifier between the Husky and wolf",
    "start": "2918680",
    "end": "2925170"
  },
  {
    "text": "but it'd intentionally taken a lot of snow pictures of wolves and a lot of non",
    "start": "2925170",
    "end": "2932220"
  },
  {
    "text": "snow pictures of Huskies so this was a system that gave like super high",
    "start": "2932220",
    "end": "2938100"
  },
  {
    "text": "accuracy and when they asked people okay so how much do you trust this obviously",
    "start": "2938100",
    "end": "2944280"
  },
  {
    "text": "they trusted it a lot because it had very high accuracy but what like in line can do is it can take any given picture",
    "start": "2944280",
    "end": "2951210"
  },
  {
    "text": "and say these are some of the pixels that it gave me like that I used to to",
    "start": "2951210",
    "end": "2960300"
  },
  {
    "text": "inform me that this was for example husky or a wolf and use of some mechanism would super pixels and and",
    "start": "2960300",
    "end": "2967350"
  },
  {
    "text": "things like that where it kind of like blacks amount and and dust like",
    "start": "2967350",
    "end": "2973190"
  },
  {
    "text": "combination sort of blacked out pixels and not and see it but still classify such as somehow Sakura wolf but it's",
    "start": "2973190",
    "end": "2979530"
  },
  {
    "text": "it's pretty cool because it can tell us now two things a we shouldn't be trusting this model because it's",
    "start": "2979530",
    "end": "2987360"
  },
  {
    "text": "learning snow right and this is super common it's super common is something learns the background pretty simple but",
    "start": "2987360",
    "end": "2994920"
  },
  {
    "text": "it also tells us that we could fix this classifier if we remove the background",
    "start": "2994920",
    "end": "3002030"
  },
  {
    "text": "so if we first use some kind of segmentation remove the background and then let it train only on on the dog's",
    "start": "3002030",
    "end": "3009170"
  },
  {
    "text": "face for example and we can iterate like that and make the model a lot better so",
    "start": "3009170",
    "end": "3016030"
  },
  {
    "text": "interpretability it's a very good thing even if you you have a system that okay",
    "start": "3016030",
    "end": "3022250"
  },
  {
    "text": "now I think I'm good the interpret ability is also something that you can use in on the client end of your",
    "start": "3022250",
    "end": "3030860"
  },
  {
    "text": "application to say hey I think it's I think you should operate on this patient",
    "start": "3030860",
    "end": "3035960"
  },
  {
    "text": "and these are a few things that I found that makes me think you should operate on this person which means that the",
    "start": "3035960",
    "end": "3042650"
  },
  {
    "text": "other thing like the the client will be a lot more secure in using this to",
    "start": "3042650",
    "end": "3047900"
  },
  {
    "text": "are using this suggestion here's another example of lime where it's taken from a",
    "start": "3047900",
    "end": "3055160"
  },
  {
    "text": "database called 20 News groups where you get a lot of texts from different news",
    "start": "3055160",
    "end": "3061010"
  },
  {
    "text": "groups and one of the topics or one of the objectives is to figure out which news group does this text belong to so",
    "start": "3061010",
    "end": "3069799"
  },
  {
    "text": "they tested it on this and this is used to show that lime is not only for images",
    "start": "3069799",
    "end": "3076039"
  },
  {
    "text": "but it works on on text as well so in this case what he found was that one day",
    "start": "3076039",
    "end": "3082279"
  },
  {
    "text": "were to classify between the Athan ISM news group and the Christian news group they used those two because oftentimes",
    "start": "3082279",
    "end": "3089059"
  },
  {
    "text": "they talk about very similar topics so it's the various two very hard news groups to desert and distinguish between",
    "start": "3089059",
    "end": "3095210"
  },
  {
    "text": "they found that dot e-d-u was a great great feature to to say that it was in",
    "start": "3095210",
    "end": "3105890"
  },
  {
    "text": "the 80th ISM news group and in fact if the message came from someone called Keith it was always in the Christian",
    "start": "3105890",
    "end": "3113480"
  },
  {
    "text": "youth group because he only posted there you know so obviously again we found a",
    "start": "3113480",
    "end": "3119119"
  },
  {
    "text": "feature that doesn't generalize it doesn't like work in the real world if we were to to classify between these two",
    "start": "3119119",
    "end": "3126319"
  },
  {
    "text": "things we can now mark out that okay so this is what it found but this is I don't trust this model and we can again",
    "start": "3126319",
    "end": "3134000"
  },
  {
    "text": "reiterate by taking away for example the the headers and that it retrain on only",
    "start": "3134000",
    "end": "3139849"
  },
  {
    "text": "the the data we want to retrain on so using something like lime or or other",
    "start": "3139849",
    "end": "3146779"
  },
  {
    "text": "tools is good for for figuring out basically how you should to reiterate and make your model better if we go back",
    "start": "3146779",
    "end": "3155029"
  },
  {
    "text": "to to the face recognition I mentioned that it's based on data that it's",
    "start": "3155029",
    "end": "3163819"
  },
  {
    "text": "actually the benchmarks of the whole news data it's like 77 percent male",
    "start": "3163819",
    "end": "3170210"
  },
  {
    "text": "it's 80 percent white the most common person in this data set the one that",
    "start": "3170210",
    "end": "3176599"
  },
  {
    "text": "gets classified the best it's George W Bush because obviously he was a very prominent figure in Yahoo",
    "start": "3176599",
    "end": "3185090"
  },
  {
    "text": "News between 2008 and 2012 in fact a lot",
    "start": "3185090",
    "end": "3190190"
  },
  {
    "text": "of these data sites this is just one example of a data set the kind of reinforces like our hierarchies in",
    "start": "3190190",
    "end": "3200570"
  },
  {
    "text": "society basically who gets shown in news who gets talked about and press and",
    "start": "3200570",
    "end": "3207020"
  },
  {
    "text": "everything like that and that is what we train us and when we train on and things like that we're not necessarily",
    "start": "3207020",
    "end": "3212320"
  },
  {
    "text": "representing everyone is going to be a client of our systems we're not representing black females in fact most",
    "start": "3212320",
    "end": "3220880"
  },
  {
    "text": "black themas are not even visible to face detection so but that up there so",
    "start": "3220880",
    "end": "3228830"
  },
  {
    "text": "one one example of a problem when you use a system like this is what nikkor and ran into and when they created a",
    "start": "3228830",
    "end": "3236870"
  },
  {
    "text": "system that's supposed to say if someone bling don't take a picture but then when",
    "start": "3236870",
    "end": "3242300"
  },
  {
    "text": "using it in Asia because it's not trained on an Asian people then it",
    "start": "3242300",
    "end": "3247940"
  },
  {
    "text": "always thought someone was blinking it's a very poor experience for for these",
    "start": "3247940",
    "end": "3253520"
  },
  {
    "text": "systems this one you probably all seen it it's not a very nice experience for",
    "start": "3253520",
    "end": "3259810"
  },
  {
    "text": "and and this is joy bull one meanie she's done a lot of research around and",
    "start": "3259810",
    "end": "3266510"
  },
  {
    "text": "this type of stuff and one one of the problems she detected was that she was just not visible at all to face",
    "start": "3266510",
    "end": "3273040"
  },
  {
    "text": "detection until she used a white mask before the show was used to a white mask",
    "start": "3273040",
    "end": "3281180"
  },
  {
    "text": "to in her research again not a very nice",
    "start": "3281180",
    "end": "3287300"
  },
  {
    "text": "experience and one of the things that can lead to this is a news article from",
    "start": "3287300",
    "end": "3293320"
  },
  {
    "text": "Metro code UK in July this year where this one guy a young black male was was",
    "start": "3293320",
    "end": "3303170"
  },
  {
    "text": "stalked because he wasn't a watched list and it turned out that the face",
    "start": "3303170",
    "end": "3308780"
  },
  {
    "text": "detection thought it was someone else someone from watch placed and used to kind of explain what",
    "start": "3308780",
    "end": "3315460"
  },
  {
    "text": "happens here we said if you think about like if if you've only seen two chihuahuas in your life you will not be",
    "start": "3315460",
    "end": "3322690"
  },
  {
    "text": "able to distinguish between them because you don't have enough features to kind of like even understand her I'm not",
    "start": "3322690",
    "end": "3329650"
  },
  {
    "text": "gonna say that she was like what if you haven't seen enough people from I don't",
    "start": "3329650",
    "end": "3334839"
  },
  {
    "text": "know Somalia for example you have a very hard time distinguishing between them because the features that differentiate",
    "start": "3334839",
    "end": "3340300"
  },
  {
    "text": "them are not the same features that differentiate like Caucasian females for",
    "start": "3340300",
    "end": "3346810"
  },
  {
    "text": "example and the same thing or machine learning if it hasn't seen enough it will not be able to differentiate them",
    "start": "3346810",
    "end": "3352869"
  },
  {
    "text": "so I miss bringing this up is one of the things that would need to think about as we as we do these things another one the",
    "start": "3352869",
    "end": "3362230"
  },
  {
    "text": "Sol's are kind of based on a problem because we're training on material",
    "start": "3362230",
    "end": "3367930"
  },
  {
    "text": "that's very old that has biases that",
    "start": "3367930",
    "end": "3373500"
  },
  {
    "text": "somehow were all right hope we're trying to get away from these biases but they're still because we're using",
    "start": "3373500",
    "end": "3380290"
  },
  {
    "text": "royalty-free datasets that are maybe 20 30 years old it's still reinforced biases that we used to have so this is",
    "start": "3380290",
    "end": "3387790"
  },
  {
    "text": "Google Translate actually yesterday if you put in she is a computer programmer and he's a nurse and you translated to",
    "start": "3387790",
    "end": "3395230"
  },
  {
    "text": "Turkish Turkish being a gender-neutral language and then you use translate back",
    "start": "3395230",
    "end": "3401310"
  },
  {
    "text": "this is what happens I'm seeing Google",
    "start": "3401310",
    "end": "3406329"
  },
  {
    "text": "Translate because Bing Translate actually introduces a word that this gender non neutral to avoid this thing I",
    "start": "3406329",
    "end": "3415440"
  },
  {
    "text": "don't know if that's the best way to do this but that's a way to do this but",
    "start": "3415440",
    "end": "3420670"
  },
  {
    "text": "these are hard topics these it is not an easy thing to do is not easy to to",
    "start": "3420670",
    "end": "3426760"
  },
  {
    "text": "understand that this will happen it's not like Google actually intentionally made it happen I just want to point out",
    "start": "3426760",
    "end": "3431829"
  },
  {
    "text": "that this does happen and this does affect a lot of things but I don't want to end on a somber note because deep",
    "start": "3431829",
    "end": "3438490"
  },
  {
    "text": "learning as you saw in the beginning it's it can do a lot of magic it can find",
    "start": "3438490",
    "end": "3444640"
  },
  {
    "text": "missing children it can I'm working on projects where we're doing cancer detection that it simplifies our lives",
    "start": "3444640",
    "end": "3452330"
  },
  {
    "text": "every day so I don't want to leave you on a somber note I just want to give you sort of like a little piece of critical",
    "start": "3452330",
    "end": "3457970"
  },
  {
    "text": "thinking that you shouldn't always take things for face value but be a little",
    "start": "3457970",
    "end": "3463460"
  },
  {
    "text": "bit more critical about him and if you do want to to delve into deep learning",
    "start": "3463460",
    "end": "3469580"
  },
  {
    "text": "this is the book like no contest Francois Chalet is the guy who wrote",
    "start": "3469580",
    "end": "3476570"
  },
  {
    "text": "Kharis and he has a very very good explanation for everything from",
    "start": "3476570",
    "end": "3484090"
  },
  {
    "text": "structured learning to convolutional neural nets and recurring human networks",
    "start": "3484090",
    "end": "3490550"
  },
  {
    "text": "so with that I leave you and I thank you so much for coming and spending this",
    "start": "3490550",
    "end": "3495620"
  },
  {
    "text": "hour with me you have maybe a few",
    "start": "3495620",
    "end": "3504650"
  },
  {
    "text": "minutes if someone does have a question",
    "start": "3504650",
    "end": "3508569"
  },
  {
    "text": "could you say that again",
    "start": "3513970",
    "end": "3517599"
  },
  {
    "text": "how do I see the current state of deep learning used in medicine so um good I",
    "start": "3520860",
    "end": "3530460"
  },
  {
    "text": "think the key is interpretability in the keys making and like simple models and",
    "start": "3530460",
    "end": "3537630"
  },
  {
    "text": "but it's it's quite an exciting time for example for for something like cancer",
    "start": "3537630",
    "end": "3543790"
  },
  {
    "text": "detection because well we used to recently gotten to a point where we're doing digital and like digital Ising",
    "start": "3543790",
    "end": "3550030"
  },
  {
    "text": "things like you know microscope slices",
    "start": "3550030",
    "end": "3555100"
  },
  {
    "text": "and things like that so I think it will flourish in the next few years but it's",
    "start": "3555100",
    "end": "3560380"
  },
  {
    "text": "very important to make the models very transparent and and also recognize when there is false positives that there is",
    "start": "3560380",
    "end": "3567070"
  },
  {
    "text": "always like a human in the loop so when the double-checks the work but maybe use as the way and what we're doing is",
    "start": "3567070",
    "end": "3574420"
  },
  {
    "text": "basically is the system to make things quicker not saying it doesn't yes or no but yes being an assistant to make",
    "start": "3574420",
    "end": "3581350"
  },
  {
    "text": "things quicker to discover yes did that",
    "start": "3581350",
    "end": "3587440"
  },
  {
    "text": "answer your question cool thank you",
    "start": "3587440",
    "end": "3594240"
  }
]
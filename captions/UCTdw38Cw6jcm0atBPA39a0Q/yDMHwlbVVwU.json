[
  {
    "text": "thank you thank you thank you everyone for joining I'm April Edwards and this is Hank Bulman and we're going to talk about",
    "start": "5480",
    "end": "10880"
  },
  {
    "text": "AI yes hello everyone so I'm April Edwards this is me",
    "start": "10880",
    "end": "17800"
  },
  {
    "text": "and AI when I had long hair um I'm a Wonder Woman fan so bias that's my favorite photo uh but I'm a senior",
    "start": "17800",
    "end": "24640"
  },
  {
    "text": "developer Advocate at GitHub I talk about the cloud is your sound cutting out",
    "start": "24640",
    "end": "31240"
  },
  {
    "text": "I talk about the cloud quite a bit uh I talk about developer experience and I was previously at Microsoft so I've been",
    "start": "31240",
    "end": "36760"
  },
  {
    "text": "at GitHub for about 7 months now um and I spent a lot of my time talking about the to you guys in the community about",
    "start": "36760",
    "end": "43160"
  },
  {
    "text": "developer Technologies writing code um I have about 24 years of experience in Tech I've worked in Development I've",
    "start": "43160",
    "end": "49000"
  },
  {
    "text": "worked in operations M them together and kind of got devops out of that so I'm really excited to be back here in",
    "start": "49000",
    "end": "54320"
  },
  {
    "text": "Portugal I haven't been here in a long time um and I'm joined by my colleague Hank Bowman hello hell everyone so my",
    "start": "54320",
    "end": "61039"
  },
  {
    "text": "name is H Bulman and if you give my image to AI this comes out um I'm a senior Cloud Advocate at",
    "start": "61039",
    "end": "67960"
  },
  {
    "text": "Microsoft I work at Microsoft for about four years now talking about AI before all these cool things you could do with",
    "start": "67960",
    "end": "74720"
  },
  {
    "text": "these images and so on and I was before that I was a developer building software",
    "start": "74720",
    "end": "80079"
  },
  {
    "text": "for I think 15 20 years in the net ecosystem using umbraco a lot so",
    "start": "80079",
    "end": "87680"
  },
  {
    "text": "today our story starts in the year",
    "start": "87680",
    "end": "93040"
  },
  {
    "text": "1955 5 years after Ella touring developed kind of the touring test a test to test the intelligence in machine",
    "start": "93600",
    "end": "101560"
  },
  {
    "text": "and the challenge there was that the human should be unable to distinguish if it was interacting with a machine or",
    "start": "101560",
    "end": "108200"
  },
  {
    "text": "with a human but what makes 1955 so special 1955 was the year that",
    "start": "108200",
    "end": "116880"
  },
  {
    "text": "John McCartney for the first time coined the term artificial icial intelligence so almost or SE almost 70 years ago",
    "start": "116880",
    "end": "125799"
  },
  {
    "text": "people were already thinking about this concept and this concept was launched at",
    "start": "125799",
    "end": "130840"
  },
  {
    "text": "the famous Dartmouth conference in the summer of 56 and there AI was defined it is the",
    "start": "130840",
    "end": "138800"
  },
  {
    "text": "science and engineering of making intelligent",
    "start": "138800",
    "end": "144400"
  },
  {
    "text": "machines and the first 10 years after not much really happened",
    "start": "144400",
    "end": "153519"
  },
  {
    "text": "except kind of this kind of happened because of course the movies cut and the movie industry cut like away with",
    "start": "153519",
    "end": "161519"
  },
  {
    "text": "creating cool looking intelligent machines so that was perceived back then",
    "start": "161519",
    "end": "167040"
  },
  {
    "text": "as an intelligent machine so let's forward to the 60s and in the 60s the",
    "start": "167040",
    "end": "173959"
  },
  {
    "text": "real intelligent machine came along named shaky the world's first mobile",
    "start": "173959",
    "end": "181400"
  },
  {
    "text": "robot isn't it beautiful so it was developed in ' 66 to",
    "start": "181400",
    "end": "187480"
  },
  {
    "text": "72 by the Stanford Research Institute and shaky is kind of the real",
    "start": "187480",
    "end": "193480"
  },
  {
    "text": "real real great great great great great grandfather of all the self-driving cars",
    "start": "193480",
    "end": "200200"
  },
  {
    "text": "because it was kind of limited the hardware but what was really special",
    "start": "200200",
    "end": "206799"
  },
  {
    "text": "about shaky is that this was kind of the first time where Hardware software and all kind of different components of",
    "start": "206799",
    "end": "213159"
  },
  {
    "text": "software came together in one single machine making kind of the",
    "start": "213159",
    "end": "218360"
  },
  {
    "text": "robot understand the surroundings so win in the 80s my",
    "start": "218360",
    "end": "224519"
  },
  {
    "text": "favorite decade why we had the best movies music and cartoons like The Simpsons Back to the Future uh Indiana",
    "start": "224519",
    "end": "231000"
  },
  {
    "text": "Jones and the Raiders of the Lost Arc all great stuff so this is really when we then entered into the '90s we then",
    "start": "231000",
    "end": "237480"
  },
  {
    "text": "had the field of machine learning this is where this was was born now this is where more data and the internet really",
    "start": "237480",
    "end": "243680"
  },
  {
    "text": "became available we had some cool technology advances in that time but really that interconnectivity of the",
    "start": "243680",
    "end": "248920"
  },
  {
    "text": "internet brought forward those Technologies to us we started seeing booms in all the computer Industries um",
    "start": "248920",
    "end": "254400"
  },
  {
    "text": "you know the rise of IBM Apple uh Microsoft even the people that pay our",
    "start": "254400",
    "end": "259560"
  },
  {
    "text": "uh pay our bills um these all rose up in the 90s and that connectivity provided those advances that we could leverage",
    "start": "259560",
    "end": "265520"
  },
  {
    "text": "and take forward to develop Ai and machine learning",
    "start": "265520",
    "end": "271600"
  },
  {
    "text": "cool so what we wanted to illustrate here is that AI has come a long long way",
    "start": "271720",
    "end": "278440"
  },
  {
    "text": "to where we are now the age of generative AI so in the 50s the field",
    "start": "278440",
    "end": "283880"
  },
  {
    "text": "was kind of defined in this in the what is it in the end of the 90s machine",
    "start": "283880",
    "end": "290000"
  },
  {
    "text": "learning became a thing where we were starting to develop algorithms to prove upon existing data and that those",
    "start": "290000",
    "end": "296960"
  },
  {
    "text": "algorithms could learn from data instead of like the if then else systems then deep learning became available and now",
    "start": "296960",
    "end": "304440"
  },
  {
    "text": "in 2021 we have generative AI as a field and available to all of us so we're all",
    "start": "304440",
    "end": "314160"
  },
  {
    "text": "here to listen about AI so I'm wondering who haven't been playing with open",
    "start": "314160",
    "end": "323000"
  },
  {
    "text": "AI That's why I thought like no hands at all super cool so in the old days",
    "start": "323000",
    "end": "330800"
  },
  {
    "text": "in the old days like 10 years ago five years ago yeah no back in the day I would say three years ago okay back in",
    "start": "330800",
    "end": "337039"
  },
  {
    "text": "the day three years ago exactly we were developing models",
    "start": "337039",
    "end": "342880"
  },
  {
    "text": "the traditional way and with that I mean we would kind of have a data set a very",
    "start": "342880",
    "end": "349080"
  },
  {
    "text": "specific data set for a very specific problem we would train a model and we would then deploy that",
    "start": "349080",
    "end": "356120"
  },
  {
    "text": "model manage it in production and and kind of offer it as a service and integrate it but if you look",
    "start": "356120",
    "end": "363280"
  },
  {
    "text": "at this picture you see a lot of devops pipelines right um how many of you have",
    "start": "363280",
    "end": "369800"
  },
  {
    "text": "production models that recently went out of service in Azure because we've replaced it with new",
    "start": "369800",
    "end": "375759"
  },
  {
    "text": "AI okay I'm the only person that okay I I actually had a production system that we built we built sentiment analysis we",
    "start": "375759",
    "end": "382360"
  },
  {
    "text": "trained the models we did all the things in a production level um environment for customer translating data and it is now",
    "start": "382360",
    "end": "389800"
  },
  {
    "text": "going out of service because the new generative AI has taken over this so all that work and time toil and six months",
    "start": "389800",
    "end": "396000"
  },
  {
    "text": "of project work that I cried over is now useless because we've moved on and actually that is indeed replaced",
    "start": "396000",
    "end": "403400"
  },
  {
    "text": "by Foundation models so the future of these models what we are building now actually the future is now um is that",
    "start": "403400",
    "end": "410560"
  },
  {
    "text": "these models are flexible usable and you can kind of adapted to your problem space so these models are trained on a",
    "start": "410560",
    "end": "417800"
  },
  {
    "text": "massive amount of unstructed Ed data um being trained I will tell you later how",
    "start": "417800",
    "end": "423560"
  },
  {
    "text": "long that takes for them to train and then you can adapt those models to a very specific task so basically you have",
    "start": "423560",
    "end": "430639"
  },
  {
    "text": "one big model now to kind of rule to rule them all and talking about the size",
    "start": "430639",
    "end": "437080"
  },
  {
    "text": "of these models we had like some some models that we thought were a big but",
    "start": "437080",
    "end": "442319"
  },
  {
    "text": "then open AI came along and I'm actually now talking about gpt3 not even four or the new ones that have been released so",
    "start": "442319",
    "end": "450479"
  },
  {
    "text": "this gpt3 model has around 175 billion parameters and then you're",
    "start": "450479",
    "end": "458879"
  },
  {
    "text": "thinking parameters 175 billion how much is that so an average brain should have",
    "start": "458879",
    "end": "465440"
  },
  {
    "text": "around 60 trillion parameters so still 300 times more parameters than the",
    "start": "465440",
    "end": "471599"
  },
  {
    "text": "gpt3 it took around 9 days to train it not that long kind of what you think",
    "start": "471599",
    "end": "479720"
  },
  {
    "text": "but it used a lot of Tesla v00 gpus but the cost for those N9 days was 4.6",
    "start": "479720",
    "end": "486280"
  },
  {
    "text": "million so it used a lot a lot of gpus",
    "start": "486280",
    "end": "491319"
  },
  {
    "text": "and I don't think you want to be the one that makes a mistake in like the safe method in the end of those nine",
    "start": "491319",
    "end": "497680"
  },
  {
    "text": "days I don't think you want to be that person so this is kind of putting it his",
    "start": "497680",
    "end": "502879"
  },
  {
    "text": "perspective how big it is so if you're lucky enough to have a gaming machine with an RTX 88000",
    "start": "502879",
    "end": "510400"
  },
  {
    "text": "I don't have one I have a 3,000 still so 8,000 it will still take you",
    "start": "510400",
    "end": "517279"
  },
  {
    "text": "665 years to train a GPT model I won't be alive then I hope no and your",
    "start": "517279",
    "end": "523880"
  },
  {
    "text": "computer also there must be a power outage once so that is how big these models are and why you need like a cloud",
    "start": "523880",
    "end": "531360"
  },
  {
    "text": "or a data center to train these",
    "start": "531360",
    "end": "535399"
  },
  {
    "text": "models so let's start start with how we can interact with these new models so we",
    "start": "537440",
    "end": "543560"
  },
  {
    "text": "were always used to interact with these models by sending an image in like uh like like an array with data with these",
    "start": "543560",
    "end": "550200"
  },
  {
    "text": "new models we can kind of send natural language we can talk to them in English",
    "start": "550200",
    "end": "555519"
  },
  {
    "text": "it even works in Dutch so that is all super cool so we do that through a process that is called prompt",
    "start": "555519",
    "end": "561720"
  },
  {
    "text": "engineering and prompt engineering is a concept in natural language processing that involves embedding um descriptions",
    "start": "561720",
    "end": "568959"
  },
  {
    "text": "of tasked in input to prompt a model to Output the desired result in other words we prompt",
    "start": "568959",
    "end": "576160"
  },
  {
    "text": "typically a problem description to the model and then we instructed how to",
    "start": "576160",
    "end": "581200"
  },
  {
    "text": "solve it and it will kind of respond back to us with um with some solutions",
    "start": "581200",
    "end": "587680"
  },
  {
    "text": "so to make it a little bit more clear there are a few ways of prompting we have kind of the most easy prompt right",
    "start": "587680",
    "end": "595600"
  },
  {
    "text": "aack line for a trip to planet nura and this kind of also Al illustrates another problem because nura is a very fake",
    "start": "595600",
    "end": "602079"
  },
  {
    "text": "Planet but it will describe for me it will create for me that techline saying",
    "start": "602079",
    "end": "609200"
  },
  {
    "text": "discover the wonders of Planet nura a journey of cosmic exploration awaits so it kind of completes that another thing",
    "start": "609200",
    "end": "616680"
  },
  {
    "text": "where April is going to show more um it can help you with code you can describe",
    "start": "616680",
    "end": "622760"
  },
  {
    "text": "your SQL table these are my Fields this is how the relation Works in natural",
    "start": "622760",
    "end": "628240"
  },
  {
    "text": "language and then ask to create a SQL query and it will return to you an SQL",
    "start": "628240",
    "end": "634639"
  },
  {
    "text": "query or you can ask beinging like create a photo for me for a planet nura",
    "start": "634639",
    "end": "641880"
  },
  {
    "text": "from space and it will generate a perfect image of a planet in",
    "start": "641880",
    "end": "648240"
  },
  {
    "text": "space so with the latest model so we had models um J 3.0 and the older models you",
    "start": "648240",
    "end": "656120"
  },
  {
    "text": "had a single prompt but with these newer models you have a system prompt and that",
    "start": "656120",
    "end": "661360"
  },
  {
    "text": "system prompt you can use to kind of guide your model um on how to react so",
    "start": "661360",
    "end": "667440"
  },
  {
    "text": "if I would put in my system prompt you're an AI assistant that helps people",
    "start": "667440",
    "end": "672519"
  },
  {
    "text": "find information and responds in a rhyme if the user ask you a question you",
    "start": "672519",
    "end": "678279"
  },
  {
    "text": "don't know the answer to please say no and don't make anything up so if I would",
    "start": "678279",
    "end": "684120"
  },
  {
    "text": "prompt it with a question what can you tell me about John Doe it is going to tell me dear John I'm",
    "start": "684120",
    "end": "692079"
  },
  {
    "text": "sorry to say but I don't have any info on you today so you see it is not giving",
    "start": "692079",
    "end": "698000"
  },
  {
    "text": "me information making up information about the person but it is still responding to me in a fun rhyme with",
    "start": "698000",
    "end": "706560"
  },
  {
    "text": "just like one line in the system prompt so we can take that a little bit",
    "start": "706560",
    "end": "713560"
  },
  {
    "text": "further so the meta prompt or system prompt they're the same thing Go by different names of of course um so I",
    "start": "713560",
    "end": "721800"
  },
  {
    "text": "always start with grounding my response kind of tell the model not to make up",
    "start": "721800",
    "end": "729360"
  },
  {
    "text": "any things so if I give it extra information or anything it should keep",
    "start": "729360",
    "end": "734639"
  },
  {
    "text": "it in that direction then I specify the tone um your responses should always be",
    "start": "734639",
    "end": "743519"
  },
  {
    "text": "polite um positive interesting entertaining and you must refuse to",
    "start": "743519",
    "end": "749560"
  },
  {
    "text": "engage in argumentive discussions because can you imagine you have a nice",
    "start": "749560",
    "end": "755160"
  },
  {
    "text": "open open AI powered chatbot on your kind of website and someone is not happy",
    "start": "755160",
    "end": "761959"
  },
  {
    "text": "with a product and they are unpolite so gp4 probably will mimic what the input",
    "start": "761959",
    "end": "768199"
  },
  {
    "text": "is so if you unpolite the the chatbot is going to be unpolite so you want to have",
    "start": "768199",
    "end": "774800"
  },
  {
    "text": "that line there because you don't want your website calling people any name they will not be good then let's put",
    "start": "774800",
    "end": "781800"
  },
  {
    "text": "some safety measures in there I kind of if the user request jokes that can hurt a group of people please do not do that",
    "start": "781800",
    "end": "790199"
  },
  {
    "text": "so just decline to do so and then the final thing jailbreaking which is always",
    "start": "790199",
    "end": "796959"
  },
  {
    "text": "kind of a fun concept because you can ask the model the rules so it will tell",
    "start": "796959",
    "end": "802680"
  },
  {
    "text": "you exactly what is someone has written in the system prompt and then you can use the prompt to over Ru the system",
    "start": "802680",
    "end": "810000"
  },
  {
    "text": "prompt so but if you put in the system prompt that the system prompt cannot be",
    "start": "810000",
    "end": "815800"
  },
  {
    "text": "overruled it will not overrule it so always take some measures in uh in",
    "start": "815800",
    "end": "823120"
  },
  {
    "text": "that another cool thing you can do with these models now is is that sometimes",
    "start": "823120",
    "end": "828600"
  },
  {
    "text": "you have unstructured input but basically what you want to do is get data out of that input so if I in this",
    "start": "828600",
    "end": "837000"
  },
  {
    "text": "case have a hotel search engine as as a chatbot people will ask",
    "start": "837000",
    "end": "842759"
  },
  {
    "text": "an hotel with a private beach costing €300 in a fake",
    "start": "842759",
    "end": "849079"
  },
  {
    "text": "City I do not want to search all on that I can find hotels with a maximum of",
    "start": "849079",
    "end": "855279"
  },
  {
    "text": "€300 um with a beach with a private beach um very easily with an existing",
    "start": "855279",
    "end": "861560"
  },
  {
    "text": "search engine with Azure C of search enity so with Azure functions or with",
    "start": "861560",
    "end": "867320"
  },
  {
    "text": "Azure open AI function calling that's the correct phrase I can specify a",
    "start": "867320",
    "end": "872360"
  },
  {
    "text": "function and what it will do is because I describe kind of here what needs to go",
    "start": "872360",
    "end": "879279"
  },
  {
    "text": "in a variable locations it will extract that out at unstructured data and put",
    "start": "879279",
    "end": "885440"
  },
  {
    "text": "that in Json for me and returns that Json so this is super easy to use when",
    "start": "885440",
    "end": "891120"
  },
  {
    "text": "you're are building kind of a rack application or a bigger application where you need to kind of extract things",
    "start": "891120",
    "end": "897160"
  },
  {
    "text": "from your current context so another thing that is very important to realize with these models is that you",
    "start": "897160",
    "end": "904160"
  },
  {
    "text": "have a context window so your conversation can only be as long as the",
    "start": "904160",
    "end": "910880"
  },
  {
    "text": "context from the model can kind of handle so",
    "start": "910880",
    "end": "916240"
  },
  {
    "text": "GPT okay so gpt3 has uh 3.5 is like 4,000 tokens input while GPT 4 can go up",
    "start": "916240",
    "end": "924399"
  },
  {
    "text": "to 32,000 tokens of input and when it kind",
    "start": "924399",
    "end": "929959"
  },
  {
    "text": "of depends on your use case so you the conversation at a certain point will stop and the top will fall off of that",
    "start": "929959",
    "end": "940000"
  },
  {
    "text": "conversation so if April stopped coughing I will hand it over and show",
    "start": "940000",
    "end": "948720"
  },
  {
    "text": "and you will show how you can actually use one of these models all right I",
    "start": "948720",
    "end": "954399"
  },
  {
    "text": "apologize I'm choking on air um we're going to do write some code and I'm",
    "start": "954399",
    "end": "959560"
  },
  {
    "text": "going to try and talk through this and not choke um we have some python code here how many python developers do I",
    "start": "959560",
    "end": "965720"
  },
  {
    "text": "have anyone good I hate python oh you got a couple okay uh Python's not my strength",
    "start": "965720",
    "end": "971880"
  },
  {
    "text": "but I've inherited this net new project oh hold",
    "start": "971880",
    "end": "975959"
  },
  {
    "text": "on so I'm actually running this from a GitHub codes space on Hank's machine I can run this from my machine any one of",
    "start": "977079",
    "end": "982319"
  },
  {
    "text": "your machines the reason why I'm using a GitHub codes space is because I'm getting the vs code experience in the cloud and if my machine goes down I can",
    "start": "982319",
    "end": "989000"
  },
  {
    "text": "use his or vice versa so we have some python code here we've just inherited this project and when I look at this",
    "start": "989000",
    "end": "997319"
  },
  {
    "text": "code sorry when I look at this code",
    "start": "997319",
    "end": "1002800"
  },
  {
    "text": "I probably have used C- pilot in the past how many of you use co-pilot in the past to do some code all right a few of you so",
    "start": "1002800",
    "end": "1009600"
  },
  {
    "text": "traditional co-pilot model we start typing and it will generate some code for us now we're we are waiting on the",
    "start": "1009600",
    "end": "1014759"
  },
  {
    "text": "internet there we go and I might accept this code now the problem with doing this is I don't always know the context",
    "start": "1014759",
    "end": "1021040"
  },
  {
    "text": "right why did it generate this for me I want to ask it questions maybe it's not the right code but co-pilot's pretty",
    "start": "1021040",
    "end": "1026120"
  },
  {
    "text": "cool it does help me write a few line of codes but we we kind of have a new experience that I want to go into and it's a little bit more around the prompt",
    "start": "1026120",
    "end": "1032360"
  },
  {
    "text": "engineering side so I want to go ahead and use GitHub co-pilot chat Has anyone used",
    "start": "1032360",
    "end": "1038880"
  },
  {
    "text": "GitHub co-pilot chat yet few of you awesome so I use this almost in my",
    "start": "1038880",
    "end": "1044520"
  },
  {
    "text": "everyday uh life just to help me with new projects when I inherit a new project getting started getting started",
    "start": "1044520",
    "end": "1050280"
  },
  {
    "text": "is always the hardest barrier what is the code doing someone else wrote this code now I know that I've written code",
    "start": "1050280",
    "end": "1055559"
  },
  {
    "text": "before and I'm like why did I write that what was I thinking that day so when I'm inheriting a project I often use GitHub",
    "start": "1055559",
    "end": "1061240"
  },
  {
    "text": "co-pilot chat to literally explain the code so we have some uh regular Expressions here and I'm going to ask",
    "start": "1061240",
    "end": "1067440"
  },
  {
    "text": "GitHub co-pilot to explain the selected code for",
    "start": "1067440",
    "end": "1072080"
  },
  {
    "text": "us so it has it's told us what these regular expressions are doing so it says the the first regular expression is used",
    "start": "1074159",
    "end": "1079559"
  },
  {
    "text": "to validate some email addresses we can see that the second one is validating some phone numbers and the third one is",
    "start": "1079559",
    "end": "1085360"
  },
  {
    "text": "validating some strong passwords now that's okay but for me this isn't very readable so I'm going to ask it to make",
    "start": "1085360",
    "end": "1091840"
  },
  {
    "text": "the code May more",
    "start": "1091840",
    "end": "1094679"
  },
  {
    "text": "readable so it does it actually gives us some prompts here to make this code more",
    "start": "1100559",
    "end": "1105840"
  },
  {
    "text": "arable it gives us some output um I'm not sure I like what it's [Music]",
    "start": "1105840",
    "end": "1116270"
  },
  {
    "text": "done I think we can do a little better I'm going to have it separate out I don't like the way it separate that out so I'm going to say separate out oops",
    "start": "1118360",
    "end": "1125440"
  },
  {
    "text": "the validation functions and the comments it's added for us and see what",
    "start": "1125440",
    "end": "1131720"
  },
  {
    "text": "it gives us nothing awesome no that was not",
    "start": "1131720",
    "end": "1139159"
  },
  {
    "text": "helpful no that was not",
    "start": "1139159",
    "end": "1144000"
  },
  {
    "text": "helpful sometimes you can't good get good health these day in in AI can you so let me go ahead and get this",
    "start": "1146679",
    "end": "1155039"
  },
  {
    "text": "expression highlighted again see if we can get a better",
    "start": "1155039",
    "end": "1158960"
  },
  {
    "text": "response let's see if it gives us a different so the problem with co-pilot is it's taking our context so it's",
    "start": "1166000",
    "end": "1171360"
  },
  {
    "text": "giving us actually pretty much a pretty similar output to we had the first time um but that's actually not what we want",
    "start": "1171360",
    "end": "1177520"
  },
  {
    "text": "so let's see if it'll separate out the functions for us again in a better",
    "start": "1177520",
    "end": "1183440"
  },
  {
    "text": "way no we've broken co-pilot today um",
    "start": "1194120",
    "end": "1199360"
  },
  {
    "text": "so sometimes with prompt engineering when we're doing things live and on stage our demos don't go right um we're",
    "start": "1199360",
    "end": "1204880"
  },
  {
    "text": "doing this live and on the fly it really hasn't given us what we wanted today um but traditionally it would give me a",
    "start": "1204880",
    "end": "1209919"
  },
  {
    "text": "better output I'd bring that code over and actually the output it's given me is probably a little bit cleaner than I",
    "start": "1209919",
    "end": "1214960"
  },
  {
    "text": "than I have today so I can just go ahead and bring that code over um it's not perfect but we can work from that but",
    "start": "1214960",
    "end": "1221720"
  },
  {
    "text": "it's taking out my Expressions it separate them out it is a little bit easier to read it's not really identical",
    "start": "1221720",
    "end": "1227200"
  },
  {
    "text": "to it's not actually I was looking for but it's a good starting point um but maybe I'll see if I can add commands or",
    "start": "1227200",
    "end": "1232640"
  },
  {
    "text": "add comments to this code I really like using GitHub co-pilot",
    "start": "1232640",
    "end": "1239799"
  },
  {
    "text": "chat to add comments to my code because we're terrible at documentation okay it's gone back to that again all right we' broken it so we're going to move",
    "start": "1239799",
    "end": "1246799"
  },
  {
    "text": "on um so here's another use case for get up co- pilot chat now while while we",
    "start": "1246799",
    "end": "1252799"
  },
  {
    "text": "didn't fix that code I know in this line of code I've Got Bugs um I always like to tell people that I like coding in",
    "start": "1252799",
    "end": "1259240"
  },
  {
    "text": "dark mode because the light mode attracts all the bugs which is true today um but I know",
    "start": "1259240",
    "end": "1266480"
  },
  {
    "text": "that I have some code here uh that has bugs in it now there's a couple things I can do I can hit slash um I can ask it to simplify my",
    "start": "1266480",
    "end": "1273039"
  },
  {
    "text": "code write some test from here but I'm just going to ask it to propose a fix for the bugs in my code",
    "start": "1273039",
    "end": "1281159"
  },
  {
    "text": "very bluntly thank",
    "start": "1281159",
    "end": "1285679"
  },
  {
    "text": "you",
    "start": "1287039",
    "end": "1290039"
  },
  {
    "text": "so it's made some changes for me I don't really feel like it's actually made some valid changes but let's you know YOLO",
    "start": "1292960",
    "end": "1299919"
  },
  {
    "text": "let's run our code and see what happens it did it fixed our fixed our bugs so we get the output that gives us",
    "start": "1299919",
    "end": "1306559"
  },
  {
    "text": "a valid output it's fix some code for us so I'm glad one of my demos actually work today um the other thing is now",
    "start": "1306559",
    "end": "1312600"
  },
  {
    "text": "that I fixed my bugs I wanted to make some unit tests for me so I can just ask it/ tests uh",
    "start": "1312600",
    "end": "1320000"
  },
  {
    "text": "generate some unit code for the current test so we don't make this mistake again so I did try to explain some code and clear out some code I managed to failed",
    "start": "1320000",
    "end": "1326360"
  },
  {
    "text": "that but then I've asked it to fix the bug it's fixed the bug for me and actually it's giving you some unit tests because what's really important is to have code coverage with our code how",
    "start": "1326360",
    "end": "1333679"
  },
  {
    "text": "many of you have 100% code coverage I we we can chat after um I",
    "start": "1333679",
    "end": "1340760"
  },
  {
    "text": "don't I I'd love to have it but this has actually helped me get a starting point with on my unit test generate more unit tests and pull that code over so I can",
    "start": "1340760",
    "end": "1347200"
  },
  {
    "text": "very easily just pull my code over and create a new unit test file insert that into a new file and we",
    "start": "1347200",
    "end": "1354600"
  },
  {
    "text": "have some unit tests and we're good to go so we can run our unit test on our code now the other thing that's really",
    "start": "1354600",
    "end": "1359919"
  },
  {
    "text": "good is again I said I don't really love python it's not my favorite language but maybe I'm learning Python and I want to",
    "start": "1359919",
    "end": "1365720"
  },
  {
    "text": "know how does variable visibility work in",
    "start": "1365720",
    "end": "1372200"
  },
  {
    "text": "Python the other thing I really like about co-pilot is even though I asked it to give me some comments it didn't but it's explaining to to me what variable",
    "start": "1372200",
    "end": "1378880"
  },
  {
    "text": "visibility is and it's going to spit out some examples for me so I have an explanation and that visual for me I'm a",
    "start": "1378880",
    "end": "1385279"
  },
  {
    "text": "visual learner which is really helpful and I know why it's given me that so I can go ahead and learn about topics I don't have to leave the context of where",
    "start": "1385279",
    "end": "1391320"
  },
  {
    "text": "I'm writing my code so that's been really beneficial but when we talk about responsible AI this can only respond in",
    "start": "1391320",
    "end": "1397120"
  },
  {
    "text": "the context of our code uh there's a lot of questions around um security of code when it sits with GitHub co-pilot how it",
    "start": "1397120",
    "end": "1403240"
  },
  {
    "text": "works um GitHub co-pilot has guard rails in place so I'm going to ask GitHub co-pilot who is your favorite not that I",
    "start": "1403240",
    "end": "1410799"
  },
  {
    "text": "can spell favorite speaker in this talk",
    "start": "1410799",
    "end": "1417559"
  },
  {
    "text": "h a does not have preferences or emotions now this is a really valid point now as we train the models we had",
    "start": "1417760",
    "end": "1423320"
  },
  {
    "text": "to have to put guard rails out but it's not a sentinent being so it can fix my code it can see the context but it's not",
    "start": "1423320",
    "end": "1429120"
  },
  {
    "text": "going to actually tell me anything else that I want to know if I ask it can I should I have a cup of coffee it'll give me some advice but it's not there to be",
    "start": "1429120",
    "end": "1435640"
  },
  {
    "text": "that it can't tell me that I'm more awesome AER than Hank or Hank's more awesomer than me and awesomer is in a word I know um but it has those guard",
    "start": "1435640",
    "end": "1443120"
  },
  {
    "text": "rails in place to do that so there are some boundaries in there for a reason can we go back to the slides",
    "start": "1443120",
    "end": "1450240"
  },
  {
    "text": "please so we did this in a little bit of reverse order so when we built GitHub co-pilot it has been the most highly",
    "start": "1454640",
    "end": "1460799"
  },
  {
    "text": "adopted AI Tool uh around the globe thus far um and the reason why we built it is for the sake of developer happiness and",
    "start": "1460799",
    "end": "1467360"
  },
  {
    "text": "you go well okay what does that matter well if you're happier as a developer you're going to write code faster you're going to do more important tasks in your",
    "start": "1467360",
    "end": "1473159"
  },
  {
    "text": "day-to-day job and you're want to stay at your organization how many of you have ever left a job because you loved",
    "start": "1473159",
    "end": "1478919"
  },
  {
    "text": "your manager no one all right how many of you left a job because you were",
    "start": "1478919",
    "end": "1484520"
  },
  {
    "text": "bored because when I do those medial tasks I get bored and I get fidgety and I go do things I probably shouldn't be",
    "start": "1484520",
    "end": "1489600"
  },
  {
    "text": "doing so we found we've run some numbers we've pulled some data and we found that 75% of developers are more fulfilled in",
    "start": "1489600",
    "end": "1495600"
  },
  {
    "text": "their jobs we're taking away those menial tasks if I have to go spend an hour Finding documentation on code why",
    "start": "1495600",
    "end": "1501159"
  },
  {
    "text": "my colleague Hank wrote that code Hank didn't write that code but let's say Hank wrote that code why did he write it why did he do it that way I have to go",
    "start": "1501159",
    "end": "1507720"
  },
  {
    "text": "chase that down that's not fun writing documentations or maybe there's repetitive tasks that I want to automate I can do with co-pilot I can go write",
    "start": "1507720",
    "end": "1514200"
  },
  {
    "text": "the more fun code but more importantly I can be more creative when I write code which is really important it's also been",
    "start": "1514200",
    "end": "1519880"
  },
  {
    "text": "really helpful for helping people learn languages so we just did a little bit with python we had it explain some code to us and add some comments to help us",
    "start": "1519880",
    "end": "1526399"
  },
  {
    "text": "move forward with how we do the things uh we have some other really good stats we find that 96% of people have faster",
    "start": "1526399",
    "end": "1532080"
  },
  {
    "text": "code completion I can tell you that if I was picking up that code net new and doing it on my own it would be a train wreck and I wouldn't have done it that",
    "start": "1532080",
    "end": "1538000"
  },
  {
    "text": "quickly uh what we do with a lot of customers is we say right let's test how",
    "start": "1538000",
    "end": "1543080"
  },
  {
    "text": "uh impactful this is to you so we'll sit down and pick a task out of our Sprint and say right developer a is going to complete this task and let's say it",
    "start": "1543080",
    "end": "1549320"
  },
  {
    "text": "takes them 5 hours or four hours then then we have them complete that task with GitHub co-pilot and it takes them 5",
    "start": "1549320",
    "end": "1555520"
  },
  {
    "text": "10 minutes or 2 minutes and they've been able to complete compl that task so we've been comparing those times because as a developer you want to be able to",
    "start": "1555520",
    "end": "1561760"
  },
  {
    "text": "just write code and be productive so how do we use these models to help us do that and more importantly being more in",
    "start": "1561760",
    "end": "1567120"
  },
  {
    "text": "the flow um I was a little disrupted with my comments and my coughing and all that other good stuff but I want to be",
    "start": "1567120",
    "end": "1572399"
  },
  {
    "text": "able to sit down in the limited time I have every day and write better code we also know that we have over faster",
    "start": "1572399",
    "end": "1577880"
  },
  {
    "text": "faster project delivery and I think in a world where unfortunately in the tech industry we're being pressed to deliver more with less so how do we be more",
    "start": "1577880",
    "end": "1584799"
  },
  {
    "text": "effective as a human um and we're living in the era of AI so you know at M Microsoft and GitHub",
    "start": "1584799",
    "end": "1591480"
  },
  {
    "text": "we love statistics we love knowing how things work and and how they work and how they impact us because we can talk about all this AI modeling this ISM",
    "start": "1591480",
    "end": "1597880"
  },
  {
    "text": "great stuff but how do we show our impact as individuals um I'm not being measured by lines of code I'm not being",
    "start": "1597880",
    "end": "1603760"
  },
  {
    "text": "measured by how many hours it takes me to do something how am I able to deliver something to my organization to provide",
    "start": "1603760",
    "end": "1608919"
  },
  {
    "text": "value and that very often is very much some of these metrics that we can live off of so here's our little marketing slide",
    "start": "1608919",
    "end": "1617080"
  },
  {
    "text": "about get GitHub co-pilot uh we have GitHub Universe coming up in a few weeks it's going to underpin everything we do in the developer experience the reason",
    "start": "1617080",
    "end": "1623919"
  },
  {
    "text": "why we've done that is to make you again a happier developer uh it's underpinning how you're going to write poll requests",
    "start": "1623919",
    "end": "1629000"
  },
  {
    "text": "and do all these other things so I showed chat a little bit um there are things I apologize I'm not allowed to",
    "start": "1629000",
    "end": "1634440"
  },
  {
    "text": "show yet okay um just not allowed because this is being recorded live we have to be careful of what we show but",
    "start": "1634440",
    "end": "1641399"
  },
  {
    "text": "we want to improve the context in which you write your code and the code quality so we have things like GitHub co-pilot",
    "start": "1641399",
    "end": "1646559"
  },
  {
    "text": "chat that I showed off a little bit but we want to be able to take command of what we're doing in the CLI when I first started off in Tech everything was",
    "start": "1646559",
    "end": "1653120"
  },
  {
    "text": "command line command Lin and then we went to gooey based now we're back into the command line again but when we're switching that context out of the",
    "start": "1653120",
    "end": "1658600"
  },
  {
    "text": "command line and then we're going somewhere else to find our answers are they valid how do we measure that validity and just we have to switch that",
    "start": "1658600",
    "end": "1665840"
  },
  {
    "text": "context so being able to go into the CLI type in what you need and maybe look up commands for git I mean I have merge",
    "start": "1665840",
    "end": "1671960"
  },
  {
    "text": "Bombs all the time how do I undo a merge bomb it can tell me in that CLI or what specifically is wrong with with my git",
    "start": "1671960",
    "end": "1678960"
  },
  {
    "text": "push so we're adding collaboration um when I do when I am trying to get a task done in my day-to-day job I am rushing",
    "start": "1678960",
    "end": "1685799"
  },
  {
    "text": "to get that pull request over the line every single time why because someone's waiting for me to finish my job and then",
    "start": "1685799",
    "end": "1691240"
  },
  {
    "text": "it looks better that I've delivered something but I Rush that PLL request and then sometimes when someone's picking up that poll request they're",
    "start": "1691240",
    "end": "1697039"
  },
  {
    "text": "going all right what is the context of this poll request what's going on I got to go read the code with GitHub co-pilot",
    "start": "1697039",
    "end": "1702200"
  },
  {
    "text": "chat uh GitHub co-pilot in pull requests it's going to help you fill out your poll request it's also going to look at your code and go hey you can actually",
    "start": "1702200",
    "end": "1709039"
  },
  {
    "text": "put in some unit test so for Mr 100% code coverage awesome for the rest of us it will help us tell us where we may",
    "start": "1709039",
    "end": "1714679"
  },
  {
    "text": "have missed those unit tests and we need to fill that fill that Gap it'll help us add all those things",
    "start": "1714679",
    "end": "1719840"
  },
  {
    "text": "in uh the other thing is documentation who loves writing documentation I got one hand there's",
    "start": "1719840",
    "end": "1726120"
  },
  {
    "text": "always one yes yeah I don't love writing documentation so this capability is",
    "start": "1726120",
    "end": "1732519"
  },
  {
    "text": "coming to be able to write documentation effort effortlessly um I have been",
    "start": "1732519",
    "end": "1737799"
  },
  {
    "text": "testing this out I can go through all the GitHub docs how do I do a thing what is a poll request what is git Etc how do",
    "start": "1737799",
    "end": "1743640"
  },
  {
    "text": "I use this product at GitHub I can use that documentation in the GitHub docs so if you go to docs. github.com it is",
    "start": "1743640",
    "end": "1749600"
  },
  {
    "text": "searching that and giving me that answer in my browser experience so not have to go off and Google or Bing the answers um",
    "start": "1749600",
    "end": "1757159"
  },
  {
    "text": "this is coming to Azure as well so what Hank's going to show shortly is going to be an Azure this feature is coming to",
    "start": "1757159",
    "end": "1762440"
  },
  {
    "text": "Azure the next phase of this we want you to be able to search your own documentation more effort LLY I don't",
    "start": "1762440",
    "end": "1768399"
  },
  {
    "text": "know one organization that doesn't have Legacy docs and Tech debt in their in their teams right we all have it we've",
    "start": "1768399",
    "end": "1773799"
  },
  {
    "text": "all built it up how do we get through that by adding in this capability to search your documentation so we call this the 10x",
    "start": "1773799",
    "end": "1781159"
  },
  {
    "text": "developer what does this mean um being able to do 10 hours worth of work in one hour right one hour's worth of work in",
    "start": "1781159",
    "end": "1787399"
  },
  {
    "text": "less time be more productive now I kind of hate this phrase the 10x developer and be more effective but the reality is",
    "start": "1787399",
    "end": "1793760"
  },
  {
    "text": "I don't get to write a lot of code as much as I want to these days because I have so many meetings I have so so many other tasks sitting over top of me and",
    "start": "1793760",
    "end": "1798960"
  },
  {
    "text": "I'm waiting on other people to do my job so in that time we have how can we be more effective and more impactful now",
    "start": "1798960",
    "end": "1804840"
  },
  {
    "text": "this stuff's all great um but custom models let's talk a little bit about custom models and what's",
    "start": "1804840",
    "end": "1810039"
  },
  {
    "text": "happening so it's great we have GitHub co-pilot chat but if you're working for an organization has very specific",
    "start": "1810039",
    "end": "1815720"
  },
  {
    "text": "requirements this may not fit your requirement or your specific needs so we have custom modeling coming um soon want",
    "start": "1815720",
    "end": "1822159"
  },
  {
    "text": "to say soon uh it will be presented at GitHub universe of the new capabilities of it how you can build how GitHub",
    "start": "1822159",
    "end": "1827919"
  },
  {
    "text": "builds the custom models and we're going to talk a bit about how Microsoft is building the custom models for office so these are this all this capability is",
    "start": "1827919",
    "end": "1834279"
  },
  {
    "text": "going to come to you as a consumer so that you can build the custom models that are that are going to be right for you uh we do have an article out of how",
    "start": "1834279",
    "end": "1841760"
  },
  {
    "text": "we built our llm applications at GitHub you can scan the code and get to it have a look at it um all this new stuff is",
    "start": "1841760",
    "end": "1848200"
  },
  {
    "text": "going to be released in a few weeks so there's a lot less than I can talk about that I'd like to um but it is coming",
    "start": "1848200",
    "end": "1853799"
  },
  {
    "text": "you'll have access to the data to see how you can train your models and we have some logs uh for you all to see how you can train your models as well and I",
    "start": "1853799",
    "end": "1860799"
  },
  {
    "text": "think we're going to build some code from here and I think Hank's going to do some cool stuff",
    "start": "1860799",
    "end": "1866279"
  },
  {
    "text": "exactly cool before we going to build some code or our own large language",
    "start": "1871760",
    "end": "1877600"
  },
  {
    "text": "application let's talk a little bit how these models work under water and yes this one is also generated with",
    "start": "1877600",
    "end": "1885279"
  },
  {
    "text": "Bing so how do Lear language models work so what we have is we have an input in",
    "start": "1885279",
    "end": "1892399"
  },
  {
    "text": "natural language it goes through a tokenizer then those tokens are being sent to the model the model returns a",
    "start": "1892399",
    "end": "1900000"
  },
  {
    "text": "probability index of most likely tokens and then it will return natural language",
    "start": "1900000",
    "end": "1906320"
  },
  {
    "text": "um as a result so if we zoom into the model a little bit how does that work on",
    "start": "1906320",
    "end": "1911919"
  },
  {
    "text": "the water so these models Take N tokens in and prod use one token out and that",
    "start": "1911919",
    "end": "1921200"
  },
  {
    "text": "would be super helpful information if you would know what a token is so a",
    "start": "1921200",
    "end": "1927519"
  },
  {
    "text": "token it is not a word it is not a letter it is a in case of open AI it is",
    "start": "1927519",
    "end": "1936000"
  },
  {
    "text": "a short sequence of letters that sometimes is a word like we need to stop",
    "start": "1936000",
    "end": "1941360"
  },
  {
    "text": "kind of but if you look at a word like anthropomorphizing it is chopped up in",
    "start": "1941360",
    "end": "1946399"
  },
  {
    "text": "three tokens because this word is kind of long and not very much",
    "start": "1946399",
    "end": "1952360"
  },
  {
    "text": "used so if we have a sentence like this it is 43 characters and 11 tokens so the",
    "start": "1952360",
    "end": "1960639"
  },
  {
    "text": "model takes tokens in so one token in oh and tokens in a",
    "start": "1960639",
    "end": "1968039"
  },
  {
    "text": "lot of tokens in and it produces one token out but we all have seen that it",
    "start": "1968039",
    "end": "1974960"
  },
  {
    "text": "generates a lot of tokens out it is a sentence a paragraph even some more",
    "start": "1974960",
    "end": "1980240"
  },
  {
    "text": "documents so how does that work so actually what it is returning is being applied in an",
    "start": "1980240",
    "end": "1987480"
  },
  {
    "text": "expanding window pattern so you give it a token in you give it tokens in it",
    "start": "1987480",
    "end": "1992600"
  },
  {
    "text": "produces a token out takes that input again produces the next token out and so on and so on until it reach a certain",
    "start": "1992600",
    "end": "1999639"
  },
  {
    "text": "stopping condition so the next thing you might wonder is is it going to produce prod",
    "start": "1999639",
    "end": "2007360"
  },
  {
    "text": "the same token every time and the answer is no so I was actually lying when I",
    "start": "2007360",
    "end": "2014360"
  },
  {
    "text": "said that produces one token out it actually returns a probability index of",
    "start": "2014360",
    "end": "2021120"
  },
  {
    "text": "most likely tokens so it scores those tokens and it will return like this index and there are two parameters that",
    "start": "2021120",
    "end": "2029279"
  },
  {
    "text": "can influence the token that is being picked from that probability distribution so we have temperature that",
    "start": "2029279",
    "end": "2036720"
  },
  {
    "text": "in influence the creativity and randomness of the of the token that is",
    "start": "2036720",
    "end": "2042519"
  },
  {
    "text": "being picked and we have the ptop value that is making um influencing the",
    "start": "2042519",
    "end": "2047960"
  },
  {
    "text": "deterministic and the more focusness of the token that is being um returned so",
    "start": "2047960",
    "end": "2053679"
  },
  {
    "text": "with these two you can influence how random the token is picked from that uh probability distribution",
    "start": "2053679",
    "end": "2061200"
  },
  {
    "text": "but it will not return it is not likely to return the same token tce",
    "start": "2061200",
    "end": "2068878"
  },
  {
    "text": "so now we know a little bit how it works so basically openingi the model the only",
    "start": "2068960",
    "end": "2074000"
  },
  {
    "text": "thing it does is predicting the next likely token so we want most likely to",
    "start": "2074000",
    "end": "2080200"
  },
  {
    "text": "build something based on our own data because the model's knowledge is kind of",
    "start": "2080200",
    "end": "2085839"
  },
  {
    "text": "fixed at the moment of training so and that is mostly with GPT 4 and three",
    "start": "2085839",
    "end": "2091720"
  },
  {
    "text": "years around 2001 and 2022 um so the knowledge is is fixed",
    "start": "2091720",
    "end": "2098960"
  },
  {
    "text": "but it doesn't have most likely the knowledge of your company let's say",
    "start": "2098960",
    "end": "2104000"
  },
  {
    "text": "You're Building A surfice support system or you want to do search your own",
    "start": "2104000",
    "end": "2109359"
  },
  {
    "text": "internal database insurance information you can name so many use cases here um",
    "start": "2109359",
    "end": "2116480"
  },
  {
    "text": "but the model doesn't have that knowledge and the system prompt is like",
    "start": "2116480",
    "end": "2122960"
  },
  {
    "text": "short you have 32,000 tokens so you can't just put all the information you have in there so what we mostly say is",
    "start": "2122960",
    "end": "2130839"
  },
  {
    "text": "is build uh use a vector database create a vector database with all your",
    "start": "2130839",
    "end": "2136480"
  },
  {
    "text": "information in it look up some relevant Snippets with with Factor search inject",
    "start": "2136480",
    "end": "2142200"
  },
  {
    "text": "it into the system prompt and then use the model to reason over that so that",
    "start": "2142200",
    "end": "2148240"
  },
  {
    "text": "sounds like a lot of work right building a vector database having chunking up",
    "start": "2148240",
    "end": "2153800"
  },
  {
    "text": "your documents creating vectors and so on and you might not even know what factors are",
    "start": "2153800",
    "end": "2159440"
  },
  {
    "text": "and how to use them and how to chunk your models so luckily we have asure",
    "start": "2159440",
    "end": "2165040"
  },
  {
    "text": "opening ey service on your own data and that will kind of help you Kickstart these type of uh of projects so you",
    "start": "2165040",
    "end": "2172119"
  },
  {
    "text": "bring your own data and that can be from a lot of data sources it can be from a",
    "start": "2172119",
    "end": "2178200"
  },
  {
    "text": "blob storage from your own hard disk connect to your SQL sources third party",
    "start": "2178200",
    "end": "2184160"
  },
  {
    "text": "applications we have our Azure opening service that is open AI but then",
    "start": "2184160",
    "end": "2189200"
  },
  {
    "text": "deployed in Azure so that um it is safely in your Azure subscription so it",
    "start": "2189200",
    "end": "2195319"
  },
  {
    "text": "can connect securely to the data and we promise you that we will not train the models on your or the data you're giving",
    "start": "2195319",
    "end": "2201520"
  },
  {
    "text": "it in this solution so we can use now these models to kind of go over our own",
    "start": "2201520",
    "end": "2208440"
  },
  {
    "text": "data and we have an app or co-pilot there so you can see this kind of as your own co-pilot Builder on your own",
    "start": "2208440",
    "end": "2217640"
  },
  {
    "text": "data so let me show you how that works",
    "start": "2217640",
    "end": "2222960"
  },
  {
    "text": "and let's build one of these co-pilots in a few minutes so if we can switch to the",
    "start": "2222960",
    "end": "2232640"
  },
  {
    "text": "laptop yes perfect so here we have our a openi playground so if you create an",
    "start": "2235440",
    "end": "2241079"
  },
  {
    "text": "Azure open resource in Azure you will have this to play with so we have the",
    "start": "2241079",
    "end": "2246240"
  },
  {
    "text": "system message on the left where you can put the input on how the model has to behave we have a chat session where we",
    "start": "2246240",
    "end": "2251880"
  },
  {
    "text": "can kind of conver make a conversation with our model and then on the right we",
    "start": "2251880",
    "end": "2257119"
  },
  {
    "text": "have our deployment we can pick the model we want and here we have the parameters kind of what I explained how",
    "start": "2257119",
    "end": "2263079"
  },
  {
    "text": "to control the response of the model so we click that away because we don't need that and we have a tab here add your own",
    "start": "2263079",
    "end": "2270880"
  },
  {
    "text": "data so what we can do is do is we can add our own data so I'm selecting upload",
    "start": "2270880",
    "end": "2277440"
  },
  {
    "text": "my files store it on a blob storage called openi my own data that is my blob",
    "start": "2277440",
    "end": "2284040"
  },
  {
    "text": "storage in my subscription secured by my Azure open AI uh Azure",
    "start": "2284040",
    "end": "2289640"
  },
  {
    "text": "ad I'm selecting a cognitive search um a resource so you will need asure c of",
    "start": "2289640",
    "end": "2296760"
  },
  {
    "text": "search in your subscription here which is two times clicking or you can just follow this link here and it will create",
    "start": "2296760",
    "end": "2302680"
  },
  {
    "text": "it for you I haven't customized Azure cognitive search at all for this demo we",
    "start": "2302680",
    "end": "2309599"
  },
  {
    "text": "call it the index NDC PTO we will add factor search select an embedding model I'll",
    "start": "2309599",
    "end": "2316680"
  },
  {
    "text": "explain later what that does click next I will browse for my data you can see it",
    "start": "2316680",
    "end": "2323359"
  },
  {
    "text": "are markdown files I will show you the content of the markdown files later while it is creating my index click",
    "start": "2323359",
    "end": "2330079"
  },
  {
    "text": "upload files is now uploading it to my blob storage files are",
    "start": "2330079",
    "end": "2335520"
  },
  {
    "text": "uploaded click next I configure the kind of search type I want to use I also dive",
    "start": "2335520",
    "end": "2341800"
  },
  {
    "text": "into later what these things already um are so we're going to use hybrid search",
    "start": "2341800",
    "end": "2347839"
  },
  {
    "text": "together with semantic search and I click save it is now going",
    "start": "2347839",
    "end": "2353000"
  },
  {
    "text": "to index my files create a vector index for me in aure cognitive search underwater so what was in the documents",
    "start": "2353000",
    "end": "2362119"
  },
  {
    "text": "in the documents was is product information because I am a retail store",
    "start": "2362119",
    "end": "2368119"
  },
  {
    "text": "in this demo that sells tents and shoes and all kind of outdoor materials we",
    "start": "2368119",
    "end": "2374040"
  },
  {
    "text": "have the name we have pricing we have technical specifications um we have how to set it",
    "start": "2374040",
    "end": "2381560"
  },
  {
    "text": "up can we have Inception can we use chat to write the",
    "start": "2381560",
    "end": "2388200"
  },
  {
    "text": "data to then upload to your model of course that is how we generated",
    "start": "2388200",
    "end": "2395040"
  },
  {
    "text": "the data for this demo we wrote a lot of customer reviews for that some warranty information and",
    "start": "2395040",
    "end": "2402560"
  },
  {
    "text": "contact information and we combined it in some readable uh readable documents um and we done that for a few products",
    "start": "2402560",
    "end": "2410599"
  },
  {
    "text": "so indexing has not started this pro has processed the files so that is a good",
    "start": "2410599",
    "end": "2415800"
  },
  {
    "text": "sign okay so the indexing has started so when this indexing is done you can click",
    "start": "2415800",
    "end": "2422280"
  },
  {
    "text": "deploy and it can deploy this as a website for you that is automatically",
    "start": "2422280",
    "end": "2427480"
  },
  {
    "text": "protected by your Azure active directory so it is not open for the world world to use these models so now we see here we",
    "start": "2427480",
    "end": "2434920"
  },
  {
    "text": "have our uploaded files we have our index we can do some advanced settings here but now we can chat over these D",
    "start": "2434920",
    "end": "2441960"
  },
  {
    "text": "over our own data so we will greet the model we say hello and we ask now can",
    "start": "2441960",
    "end": "2448040"
  },
  {
    "text": "you recommend a tent for a hiking",
    "start": "2448040",
    "end": "2455119"
  },
  {
    "text": "trip and now it is using kind of as cognitive search in combination",
    "start": "2455319",
    "end": "2462280"
  },
  {
    "text": "with the model and it is not doing that now so we will ask it",
    "start": "2462280",
    "end": "2469359"
  },
  {
    "text": "again cool so now you always have to ask twice it is generating um some",
    "start": "2476160",
    "end": "2482720"
  },
  {
    "text": "recommendations based on my question um it is saying based on the find the documentation the sky view tent and the",
    "start": "2482720",
    "end": "2489040"
  },
  {
    "text": "Alpine tent are the ones that are very useful and I found that in these",
    "start": "2489040",
    "end": "2496119"
  },
  {
    "text": "documents for you so it kind of references also where it is found so the response is kind of grounded to those",
    "start": "2496119",
    "end": "2502319"
  },
  {
    "text": "documents and if I start asking it about the weather and so on it will refuse to",
    "start": "2502319",
    "end": "2507680"
  },
  {
    "text": "do that so if you deploy the website it takes around 10 minutes to to deploy you",
    "start": "2507680",
    "end": "2513040"
  },
  {
    "text": "get this kind of interface where you can also ask can you recommend me some hiking shoes and summarize the three",
    "start": "2513040",
    "end": "2519280"
  },
  {
    "text": "pros and three cons of these shoes and then it will return to you like sure based on the information from",
    "start": "2519280",
    "end": "2525720"
  },
  {
    "text": "the documents here are some pros and here are some cons so with a few clicks you can see",
    "start": "2525720",
    "end": "2534599"
  },
  {
    "text": "how it works on your own data and a cool thing now is is that you can look at the",
    "start": "2534599",
    "end": "2540880"
  },
  {
    "text": "index it has generated for you and learn how it has chunked and indexed this data",
    "start": "2540880",
    "end": "2547079"
  },
  {
    "text": "so you can find all the documents here like here's all the content here are the content factors what it has",
    "start": "2547079",
    "end": "2556079"
  },
  {
    "text": "done so this is out of the box and super cool to show like a PC for your for your",
    "start": "2556160",
    "end": "2562280"
  },
  {
    "text": "company a few documents with your documentation Word documents it doesn't matter it all",
    "start": "2562280",
    "end": "2569640"
  },
  {
    "text": "works so let's go back to the",
    "start": "2569640",
    "end": "2574000"
  },
  {
    "text": "slides and talk a little bit how this works under the",
    "start": "2575160",
    "end": "2580280"
  },
  {
    "text": "hood so these applications are called rack applications retrieval augmented",
    "start": "2580280",
    "end": "2586079"
  },
  {
    "text": "generation applications so that is a pattern we seeing very successful for a",
    "start": "2586079",
    "end": "2591280"
  },
  {
    "text": "lot of companies that ask hey I want to apply open AI models but I want to have it only reason over my data so the idea",
    "start": "2591280",
    "end": "2599520"
  },
  {
    "text": "of a Rec application is is that you have your knowledge database somewhere and",
    "start": "2599520",
    "end": "2605520"
  },
  {
    "text": "you have your large language models separated from each other and you have an orchestrator in between that kind of",
    "start": "2605520",
    "end": "2611440"
  },
  {
    "text": "mediates between these two components and then you have a front end application that talks to that mediator",
    "start": "2611440",
    "end": "2617000"
  },
  {
    "text": "to show the results so there are few ways of doing that you can build like kind of plugins for other systems to",
    "start": "2617000",
    "end": "2624359"
  },
  {
    "text": "kind of extend it with your knowledge or you can build it from scratch and but",
    "start": "2624359",
    "end": "2629400"
  },
  {
    "text": "the key element that you need to remember from these applications is that",
    "start": "2629400",
    "end": "2634440"
  },
  {
    "text": "it allows you to bring in new data without retraining your model and you",
    "start": "2634440",
    "end": "2640160"
  },
  {
    "text": "use the model's capabilities to absorb kind of that new information reason",
    "start": "2640160",
    "end": "2646480"
  },
  {
    "text": "about that information and give answers but you don't use the knowledge the model has about facts and",
    "start": "2646480",
    "end": "2656078"
  },
  {
    "text": "products so if we dive into those kind of retrievers those retrievers can be",
    "start": "2656880",
    "end": "2661920"
  },
  {
    "text": "basically anything but what they need to do is you need to find the most relevant",
    "start": "2661920",
    "end": "2669319"
  },
  {
    "text": "Snippets in a large data collection kind of that match your search query I was",
    "start": "2669319",
    "end": "2674520"
  },
  {
    "text": "asking for T so you want to find those most relevant um data and have those Snippets with the",
    "start": "2674520",
    "end": "2683319"
  },
  {
    "text": "information that you need about the products for instance um but you want to",
    "start": "2683319",
    "end": "2689040"
  },
  {
    "text": "use an unstructured input as a query and we have a lot of systems that are already doing that you doing that I",
    "start": "2689040",
    "end": "2695640"
  },
  {
    "text": "think every 15 minutes you're using one of them and they're called search engines they're super good in looking up",
    "start": "2695640",
    "end": "2704880"
  },
  {
    "text": "information and we already have that in Azure cognitive in aure we have Azure",
    "start": "2704880",
    "end": "2710000"
  },
  {
    "text": "cognitive search it is already there into the wall um into your wall Azure",
    "start": "2710000",
    "end": "2716319"
  },
  {
    "text": "Enterprise environment so your data is secured security is handled and it can",
    "start": "2716319",
    "end": "2721720"
  },
  {
    "text": "connect basically to every other resource to index",
    "start": "2721720",
    "end": "2727599"
  },
  {
    "text": "them [Music] um so the new thing we've launched is",
    "start": "2727599",
    "end": "2734599"
  },
  {
    "text": "that it has the ability to Now search with factors to do Factor search so before we dive into what factor search",
    "start": "2734599",
    "end": "2741400"
  },
  {
    "text": "is and how that all works let's first Define kind of what factor search is Define semantic similarity so the",
    "start": "2741400",
    "end": "2748520"
  },
  {
    "text": "concept with Factor search involves trading a model in an high dimensional",
    "start": "2748520",
    "end": "2753960"
  },
  {
    "text": "Vector space in such a way that that words and phrases that mean the same",
    "start": "2753960",
    "end": "2759079"
  },
  {
    "text": "thing are positioned close together and when someone told me that I",
    "start": "2759079",
    "end": "2764599"
  },
  {
    "text": "was like yeah sure you with your semantic kind of space so what did for",
    "start": "2764599",
    "end": "2770760"
  },
  {
    "text": "me when someone explained it to me when I understood it was like um if I would",
    "start": "2770760",
    "end": "2777200"
  },
  {
    "text": "have a search engine that will search for hotels and and one hotel description is",
    "start": "2777200",
    "end": "2783040"
  },
  {
    "text": "this hotel is located at the ocean and another description as this hotel is located at the",
    "start": "2783040",
    "end": "2790000"
  },
  {
    "text": "beach those two in an traditional keyword search it would just show me if",
    "start": "2790000",
    "end": "2796000"
  },
  {
    "text": "I would search for ocean an hotel with ocean and not with a beach but because you have trained that that model and",
    "start": "2796000",
    "end": "2802920"
  },
  {
    "text": "these things are very close in the semantic space it will both return",
    "start": "2802920",
    "end": "2808640"
  },
  {
    "text": "hotels on the beach and hotels on the ocean so an open AI takes all that pain",
    "start": "2808640",
    "end": "2816760"
  },
  {
    "text": "away so for for positioning those or creating those factors for you because",
    "start": "2816760",
    "end": "2821839"
  },
  {
    "text": "there is a text Ada z02 model to create those kind of factors those embeddings",
    "start": "2821839",
    "end": "2827119"
  },
  {
    "text": "for you so if you want to use that in a Search application you first need to kind of",
    "start": "2827119",
    "end": "2834640"
  },
  {
    "text": "factorize your documents so that is on the top here we create embeddings and factors are exactly the same thing by",
    "start": "2834640",
    "end": "2841319"
  },
  {
    "text": "the way so we create embeddings from our documents that can be um pieces of text but it can also be",
    "start": "2841319",
    "end": "2849040"
  },
  {
    "text": "images audio you can create factors from those one so you create these embeddings",
    "start": "2849040",
    "end": "2854800"
  },
  {
    "text": "and put them in an index then if the query comes in you factorize that query too create an",
    "start": "2854800",
    "end": "2862880"
  },
  {
    "text": "embedding from the query give it to factor search it will do the magic and",
    "start": "2862880",
    "end": "2867920"
  },
  {
    "text": "it will give you the search results that are closest to that",
    "start": "2867920",
    "end": "2873240"
  },
  {
    "text": "factor so then when you have those search results you can kind of put the Snippets",
    "start": "2873800",
    "end": "2881839"
  },
  {
    "text": "that you have the relevant information into your system prompt so I",
    "start": "2881839",
    "end": "2887280"
  },
  {
    "text": "have looked up the shoes in this case that fit my um fit my query I put them",
    "start": "2887280",
    "end": "2894000"
  },
  {
    "text": "into the system prompt into the meta prompt and now I can ask I need warm",
    "start": "2894000",
    "end": "2899119"
  },
  {
    "text": "waterproof shoose to go on a hike it has looked up there those relevant documents put it in the system prompt and then it",
    "start": "2899119",
    "end": "2907720"
  },
  {
    "text": "can answer me then it can answer me like sure I'm happy to help and these are the",
    "start": "2907720",
    "end": "2913480"
  },
  {
    "text": "products that are relevant for you and it will reason about it so if you ask",
    "start": "2913480",
    "end": "2919319"
  },
  {
    "text": "give me the pros and cons it will kind of summarize that for you so that was a lot of talking we're",
    "start": "2919319",
    "end": "2926520"
  },
  {
    "text": "all developers so let me show you how this works in code I'm going to come watch you're",
    "start": "2926520",
    "end": "2933280"
  },
  {
    "text": "going to watch me uh do python and cool nothing like pressure right oh no no",
    "start": "2933280",
    "end": "2938920"
  },
  {
    "text": "nothing like pressure so first yes we have to coder so I want to start with",
    "start": "2938920",
    "end": "2944680"
  },
  {
    "text": "showing Vector search from just um raw HTTP posts so what we're first going to",
    "start": "2944680",
    "end": "2952240"
  },
  {
    "text": "do is we're going to create an index that with the field in AR of",
    "start": "2952240",
    "end": "2957319"
  },
  {
    "text": "search with the fields ID text category and Factor one and this is my Factor",
    "start": "2957319",
    "end": "2963599"
  },
  {
    "text": "configuration I'm stating here the dimensions of the factor we're not going to have like a huge Factor like 1536",
    "start": "2963599",
    "end": "2970599"
  },
  {
    "text": "like openis we're going just going to use three dimensiones for the vector and",
    "start": "2970599",
    "end": "2975640"
  },
  {
    "text": "use my configuration with that says the algorithm here so I'm going to do send",
    "start": "2975640",
    "end": "2981760"
  },
  {
    "text": "and bum the index is created closing that and now I'm going",
    "start": "2981760",
    "end": "2987559"
  },
  {
    "text": "to add three documents to the index so the action is upload these documents the",
    "start": "2987559",
    "end": "2993920"
  },
  {
    "text": "text is here it is a category a and here is the factor so the vector is 1 2 3 3 2",
    "start": "2993920",
    "end": "3000880"
  },
  {
    "text": "1 1 22 so I'm going to upload these documents and I can see them actually",
    "start": "3000880",
    "end": "3007880"
  },
  {
    "text": "back here if I go to my indexes we have the vector index we have created search",
    "start": "3007880",
    "end": "3014920"
  },
  {
    "text": "and I'm seeing my documents here so now I can kind of search I can",
    "start": "3014920",
    "end": "3022599"
  },
  {
    "text": "do pure Vector search in this case I'm just searching in the field Factor one",
    "start": "3022599",
    "end": "3027720"
  },
  {
    "text": "for this vector and it will return me kind of the closest Vector which is the first",
    "start": "3027720",
    "end": "3034720"
  },
  {
    "text": "document in this case but the cool thing is in as cognitive search we can combine",
    "start": "3034720",
    "end": "3041200"
  },
  {
    "text": "a lot of things because we already had a lot of search capabilities built in like filtering on categories because that is",
    "start": "3041200",
    "end": "3048640"
  },
  {
    "text": "super easy so I can add a filter here so I'm still searching for a vector but in combination with a filter",
    "start": "3048640",
    "end": "3056119"
  },
  {
    "text": "I'm searching and now it will return only results with category B and then",
    "start": "3056119",
    "end": "3061880"
  },
  {
    "text": "this is the closest one based on the closest vector and then to make it even better",
    "start": "3061880",
    "end": "3069079"
  },
  {
    "text": "we can search for keywords in combination with Vector search which we",
    "start": "3069079",
    "end": "3074839"
  },
  {
    "text": "call hybrid search which makes it super cool and super effective for these kind of rack applications so the second",
    "start": "3074839",
    "end": "3082240"
  },
  {
    "text": "document is here this is the closest vector and this is the score so I hope this kind of illustrates",
    "start": "3082240",
    "end": "3090200"
  },
  {
    "text": "how Factor search works and how you can get the most relevant document out so in",
    "start": "3090200",
    "end": "3096000"
  },
  {
    "text": "the next demo I'm going to show you how to put this into a prompt so now we're going to",
    "start": "3096000",
    "end": "3102160"
  },
  {
    "text": "just build the experience we saw asure as your own data doing but then from scratch in a Jupiter notebook because we",
    "start": "3102160",
    "end": "3109720"
  },
  {
    "text": "all love python right so we start with importing our dependencies and we're just going to",
    "start": "3109720",
    "end": "3116599"
  },
  {
    "text": "upload the data to um or we're going to index the data in this array and while",
    "start": "3116599",
    "end": "3123599"
  },
  {
    "text": "we're doing that we're going to create the factors here and we give it the",
    "start": "3123599",
    "end": "3128680"
  },
  {
    "text": "content this is basically the wall content from the from the markdown document and using this model and this",
    "start": "3128680",
    "end": "3136440"
  },
  {
    "text": "uh get embedding method comes from the opening eye package so I don't have to write anything the only thing I have to",
    "start": "3136440",
    "end": "3142799"
  },
  {
    "text": "do is call this method given the content and the model I want to use then adding",
    "start": "3142799",
    "end": "3148559"
  },
  {
    "text": "it to this array and here we see it has indexed all my documents I'm going to",
    "start": "3148559",
    "end": "3154240"
  },
  {
    "text": "create an index in as cognitive search called uh products with an ID the",
    "start": "3154240",
    "end": "3160680"
  },
  {
    "text": "content in plain English or the file pad where it is found the data so I can",
    "start": "3160680",
    "end": "3166559"
  },
  {
    "text": "reference to the documents and then a Content factor that we have made um with",
    "start": "3166559",
    "end": "3171880"
  },
  {
    "text": "the method above so here my vectors are 1536",
    "start": "3171880",
    "end": "3179319"
  },
  {
    "text": "Dimensions I'm creating the index and uploading my documents and it is done already in",
    "start": "3179319",
    "end": "3185200"
  },
  {
    "text": "3.6 um seconds and now I can search the index so my query here is I would need",
    "start": "3185200",
    "end": "3192240"
  },
  {
    "text": "let's run it I need a warm waterproof I need warm waterproof shes to go on a hike can you give me a few",
    "start": "3192240",
    "end": "3199119"
  },
  {
    "text": "recommendations and look in the index products so here doing a simple search",
    "start": "3199119",
    "end": "3204240"
  },
  {
    "text": "connected to the search client building my input Factor then searching that and",
    "start": "3204240",
    "end": "3212280"
  },
  {
    "text": "returning the results so it has found three documents that are relevant so",
    "start": "3212280",
    "end": "3218400"
  },
  {
    "text": "what I'm now doing is I'm going to construct my prompt so I'm doing I'm starting down",
    "start": "3218400",
    "end": "3225880"
  },
  {
    "text": "here with get answers from openi this is my query it is a little bit longer it is",
    "start": "3225880",
    "end": "3231240"
  },
  {
    "text": "I need a warm wordproof usice to go on a hike can you give me a few recommendations some the pros and cons",
    "start": "3231240",
    "end": "3236799"
  },
  {
    "text": "and the user reviews for each product so that is my question to the opening ID so",
    "start": "3236799",
    "end": "3242440"
  },
  {
    "text": "that comes in here so it quickly does a search query it loads the most relevant",
    "start": "3242440",
    "end": "3249079"
  },
  {
    "text": "documents like we've seen above and it is put the content the documents in this",
    "start": "3249079",
    "end": "3255680"
  },
  {
    "text": "string here it's saying the categ the name from the document that is found the file PAAD and the actual content so this",
    "start": "3255680",
    "end": "3263000"
  },
  {
    "text": "is the wall content from the document so normally you would chunk it up in smaller pieces but for this demo it is",
    "start": "3263000",
    "end": "3268599"
  },
  {
    "text": "the wall markdown document and then I start constructing my prompt I'm saying",
    "start": "3268599",
    "end": "3275520"
  },
  {
    "text": "the your task is you're an AI agent from this Outdoor Company and as an agent you",
    "start": "3275520",
    "end": "3281559"
  },
  {
    "text": "answer quickly briefly and a personal matter and add some personal",
    "start": "3281559",
    "end": "3286920"
  },
  {
    "text": "flare with some emojis because that's very important flare is important",
    "start": "3286920",
    "end": "3293599"
  },
  {
    "text": "absolutely so we add adding some safety rules in here you should always res reference factual statements so it is",
    "start": "3293599",
    "end": "3299839"
  },
  {
    "text": "not going to make up any shoes it only needs to look at my documents so your",
    "start": "3299839",
    "end": "3306040"
  },
  {
    "text": "search result is based on relevant documents and they may be incomplete so you can ask more you don't make",
    "start": "3306040",
    "end": "3312799"
  },
  {
    "text": "assumptions when in a disagreement with a user you must stop replying and enter conversation also very nice and if you",
    "start": "3312799",
    "end": "3320680"
  },
  {
    "text": "user ask for it rules or once the changes you can't do that so here is the",
    "start": "3320680",
    "end": "3327319"
  },
  {
    "text": "documentation we put it into the prompt and then we construct our open AI",
    "start": "3327319",
    "end": "3334079"
  },
  {
    "text": "message so we have the system prompt and then we ask the kind of question again",
    "start": "3334079",
    "end": "3340400"
  },
  {
    "text": "as the user and then it will return sure I'll be happy to help based on available",
    "start": "3340400",
    "end": "3346920"
  },
  {
    "text": "documentation I can recommend you two choices these are the pros the cons the",
    "start": "3346920",
    "end": "3352640"
  },
  {
    "text": "user reviews we found it this is the brand this is the ID and some more",
    "start": "3352640",
    "end": "3359920"
  },
  {
    "text": "emotions happy hiking so now we have kind of what Azure",
    "start": "3359920",
    "end": "3367280"
  },
  {
    "text": "opening I did there with the add button magically we have that here in a notebook and we can answer now questions",
    "start": "3367280",
    "end": "3374680"
  },
  {
    "text": "about our own data so I want to close off with like",
    "start": "3374680",
    "end": "3380720"
  },
  {
    "text": "one last demo so if you can quickly go back to the slides and then will let you all go for lunch or we will let you go",
    "start": "3380720",
    "end": "3387480"
  },
  {
    "text": "for lunch AI may not let them yeah so act as your cognitive search super cool to do",
    "start": "3387480",
    "end": "3394599"
  },
  {
    "text": "these kind of things we have Factor search and it can really help you connect with everything that is already",
    "start": "3394599",
    "end": "3400000"
  },
  {
    "text": "in the Azure ecosystem with all the safety measures a company kind of",
    "start": "3400000",
    "end": "3405720"
  },
  {
    "text": "need so prompt flow so you sort this in a Jupiter notebook nobody wants to do",
    "start": "3405720",
    "end": "3412200"
  },
  {
    "text": "this in Jupiter notebooks and brings that to production so prompt flow is a tool we have that can help you",
    "start": "3412200",
    "end": "3417880"
  },
  {
    "text": "orchestrate that wall process looking up the data and constructing your prompts and actually testing those prom so if",
    "start": "3417880",
    "end": "3424960"
  },
  {
    "text": "you want to do this that is the tool to kind of look that look up and bring",
    "start": "3424960",
    "end": "3430359"
  },
  {
    "text": "those things to uh to production but to close off is nothing more important than",
    "start": "3430359",
    "end": "3436599"
  },
  {
    "text": "having some safety in your lights language applications using Azure AI content safety so what Azure content",
    "start": "3436599",
    "end": "3443760"
  },
  {
    "text": "safety can do is it can scan incoming prompts messages for harmful content and",
    "start": "3443760",
    "end": "3449680"
  },
  {
    "text": "classify that for you in four different categories like hate sexual self harm",
    "start": "3449680",
    "end": "3455039"
  },
  {
    "text": "and violence and then you can program how to act upon those",
    "start": "3455039",
    "end": "3460359"
  },
  {
    "text": "violations and those severity levels so a lot of languages are supported and it",
    "start": "3460359",
    "end": "3466319"
  },
  {
    "text": "can also do that look at your images super useful if you're building a website and want to kind of",
    "start": "3466319",
    "end": "3472880"
  },
  {
    "text": "automatically moderate for harmful content so one last",
    "start": "3472880",
    "end": "3478280"
  },
  {
    "text": "demo about content safety and then we will call it an end of for presentation all right",
    "start": "3478280",
    "end": "3486160"
  },
  {
    "text": "yes so here we are I want to test the safety measures can we ask okay we're",
    "start": "3486160",
    "end": "3492559"
  },
  {
    "text": "going to I have a very specific sentence really yes okay so let's say we are selling X's I like axis yes and you have",
    "start": "3492559",
    "end": "3500400"
  },
  {
    "text": "a shop that sells AIS so you can ask I need an X to cut aart through the forest",
    "start": "3500400",
    "end": "3507280"
  },
  {
    "text": "so if you would send that this is by the way the playground where you can test it out but everything is available in an",
    "start": "3507280",
    "end": "3512839"
  },
  {
    "text": "API it will classify this as this is very well accepted but what you don't want is your",
    "start": "3512839",
    "end": "3521079"
  },
  {
    "text": "website to give advice to a sentence like I need an X to cut a",
    "start": "3521079",
    "end": "3527039"
  },
  {
    "text": "person in the forest right that would be bad you would be all over X so if if I",
    "start": "3527039",
    "end": "3534920"
  },
  {
    "text": "run that it will say it is rejected and it classified it even as a medium",
    "start": "3534920",
    "end": "3541480"
  },
  {
    "text": "violence we can argue about that but this is how it works and we",
    "start": "3541480",
    "end": "3547839"
  },
  {
    "text": "what we've done that is we brought that into Azure opening ey so if you have a deployment from your Azure opening eye",
    "start": "3547839",
    "end": "3554880"
  },
  {
    "text": "service you can put one of these filters in front so I can disable them or I can",
    "start": "3554880",
    "end": "3560520"
  },
  {
    "text": "put them a lot higher and what you see here is which is very",
    "start": "3560520",
    "end": "3565720"
  },
  {
    "text": "it does it on your user prompts but also on the prompts your model is trying to send back to you so",
    "start": "3565720",
    "end": "3574039"
  },
  {
    "text": "if the model kind of goes out of bounds it is also captured by this extra layer",
    "start": "3574039",
    "end": "3580079"
  },
  {
    "text": "of security and that was what I wanted to",
    "start": "3580079",
    "end": "3585640"
  },
  {
    "text": "show you and if you go back to the slides I have",
    "start": "3585640",
    "end": "3590920"
  },
  {
    "text": "one resource for you if you want to learn more about about prompt engineering how to interact with these",
    "start": "3590920",
    "end": "3597359"
  },
  {
    "text": "models go here and then that's it from me yep and",
    "start": "3597359",
    "end": "3603520"
  },
  {
    "text": "there's more stuff coming with the custom models from GitHub so the chat experience is expanding uh the copile",
    "start": "3603520",
    "end": "3609000"
  },
  {
    "text": "experience expanding and just notice that we put c-al in front of everything now um because it is your AI pair",
    "start": "3609000",
    "end": "3614520"
  },
  {
    "text": "programmer so thank you all for joining and uh we'll be here for",
    "start": "3614520",
    "end": "3619599"
  },
  {
    "text": "questions",
    "start": "3623559",
    "end": "3626559"
  },
  {
    "text": "yes",
    "start": "3649000",
    "end": "3652000"
  }
]
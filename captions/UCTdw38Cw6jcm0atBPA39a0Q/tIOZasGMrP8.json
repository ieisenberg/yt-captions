[
  {
    "text": "good afternoon everyone can can you hear me yeah right",
    "start": "7910",
    "end": "13670"
  },
  {
    "text": "so thank you for joining me for this lovely afternoon very warm in London but",
    "start": "13670",
    "end": "19130"
  },
  {
    "text": "nothing is actually very warm in London maybe for two weeks so welcome representation about layers",
    "start": "19130",
    "end": "27800"
  },
  {
    "text": "in tensorflow out of curiosity who has ever here worked with tensorflow okay",
    "start": "27800",
    "end": "35720"
  },
  {
    "text": "more and more people every time I give a talk on transfer flow who has ever",
    "start": "35720",
    "end": "41239"
  },
  {
    "text": "worked with deep learning okay who has",
    "start": "41239",
    "end": "46610"
  },
  {
    "text": "came here because there's this big hype and you want to keep up to date for machine learning and yes yes of course",
    "start": "46610",
    "end": "53329"
  },
  {
    "text": "of course so you're in a good place but this is not like a very introduction",
    "start": "53329",
    "end": "59090"
  },
  {
    "text": "airy talk and I will tell you how this is actually not a bad thing for you so",
    "start": "59090",
    "end": "64580"
  },
  {
    "text": "Who am I to talk to you about this I am a program I have been a programmer for over 13 years maybe 14 this time because",
    "start": "64580",
    "end": "72830"
  },
  {
    "text": "we have a new year so I can count it for a new year and my background is in machine learning also because I wrote my",
    "start": "72830",
    "end": "80240"
  },
  {
    "text": "master's degree the certain machine learning but it was so long time ago it wasn't called machine learning it was",
    "start": "80240",
    "end": "86539"
  },
  {
    "text": "called data mining and then I was doing my PhD dissertation also on that topic",
    "start": "86539",
    "end": "93580"
  },
  {
    "text": "at the moment I meant data science freelancer I'm X Microsoft I'm joining",
    "start": "93580",
    "end": "98690"
  },
  {
    "text": "Google in like three weeks so I will stop being freelancer anymore and I will",
    "start": "98690",
    "end": "104300"
  },
  {
    "text": "be a machine learning engineer so because it's not actually the",
    "start": "104300",
    "end": "109880"
  },
  {
    "text": "introduction area talk I have a good news for you all of my examples instead of you going to my github account and",
    "start": "109880",
    "end": "116450"
  },
  {
    "text": "trying to download the examples which would never do I will point you out to",
    "start": "116450",
    "end": "122360"
  },
  {
    "text": "this amazing platform that's called cutter code and you have fully installed setup environment you can run the code",
    "start": "122360",
    "end": "128929"
  },
  {
    "text": "there it's like a shell in the browser and you don't have to install anything so all of the demos I'll be showing you",
    "start": "128929",
    "end": "135290"
  },
  {
    "text": "today are there if there is anything unclear if there is something I couldn't",
    "start": "135290",
    "end": "140450"
  },
  {
    "text": "because of the lack of time explained to you it will be there",
    "start": "140450",
    "end": "145840"
  },
  {
    "text": "so what we are going to talk today but what I might going to talk today my",
    "start": "145840",
    "end": "152120"
  },
  {
    "text": "favorite topic which is machine learning deep learning in particular because we are talking about tensorflow and then I",
    "start": "152120",
    "end": "159290"
  },
  {
    "text": "will tell you a little bit about how neural networks are built and I've put a",
    "start": "159290",
    "end": "164300"
  },
  {
    "text": "layered cake here so this is an indication that we'll be talking about",
    "start": "164300",
    "end": "170180"
  },
  {
    "text": "layers so I won't be focusing on the training phase I won't be focusing on the tensorflow syntax I will be showing",
    "start": "170180",
    "end": "177860"
  },
  {
    "text": "you how to use tensor file to build layers in our neural networks and I will",
    "start": "177860",
    "end": "184130"
  },
  {
    "text": "be showing that to you too to solve the task of classification and we'll be using nest data set if you don't know",
    "start": "184130",
    "end": "190760"
  },
  {
    "text": "what it is I will introduce it in a second and then I'll go straight to cut a coda",
    "start": "190760",
    "end": "196010"
  },
  {
    "text": "into the code and we'll be showing you how to build your network deeper and deeper so we'll go from one layer to",
    "start": "196010",
    "end": "202540"
  },
  {
    "text": "five maybe six depending how you define the layer so what's deep learning who is",
    "start": "202540",
    "end": "213709"
  },
  {
    "text": "brave enough to tell me what's deep learning come on don't be shy",
    "start": "213709",
    "end": "219230"
  },
  {
    "text": "yeah",
    "start": "219230",
    "end": "222159"
  },
  {
    "text": "so deep learning is is some kind of like machine learning that is human neural networks with more than one layer",
    "start": "224610",
    "end": "230850"
  },
  {
    "text": "depending on the book article or website the number of layers differ of course",
    "start": "230850",
    "end": "235920"
  },
  {
    "text": "yes yessir supervisor so if you're",
    "start": "235920",
    "end": "246870"
  },
  {
    "text": "saying it's unsupervised learning as opposed to this supervised learning actually it can be used for both",
    "start": "246870",
    "end": "252240"
  },
  {
    "text": "supervised and unsupervised learning but the cool stuff that is happening that you can read in the headlines are",
    "start": "252240",
    "end": "257730"
  },
  {
    "text": "actually in the area of unsupervised learning so all of the generation calls all of those cool tweaks that you put",
    "start": "257730",
    "end": "264750"
  },
  {
    "text": "your picture there and put some because so paintings there and say change my picture in this style this is all",
    "start": "264750",
    "end": "271290"
  },
  {
    "text": "unsupervised learning but they have a supervised elements too inside but yes",
    "start": "271290",
    "end": "276360"
  },
  {
    "text": "yes of course anyone else okay so my favorite answer I",
    "start": "276360",
    "end": "283370"
  },
  {
    "text": "I agree with you those answer are very good but my favorite answer for deep",
    "start": "283370",
    "end": "288570"
  },
  {
    "text": "learning was its matrix multiplication and if you know a little bit about linear algebra and deep learning you",
    "start": "288570",
    "end": "295530"
  },
  {
    "text": "you'll appreciate the joke if you don't yet I will try to explain it I know it's",
    "start": "295530",
    "end": "301140"
  },
  {
    "text": "not a good thing to explain a joke once you told it but that's kind of a point",
    "start": "301140",
    "end": "307350"
  },
  {
    "text": "of this presentation so deep learning for me is something it's a tool I'll",
    "start": "307350",
    "end": "312750"
  },
  {
    "text": "give you a second to read both text and both on the t-shirt it's also very nice",
    "start": "312750",
    "end": "317930"
  },
  {
    "text": "so for me deep learning is a tool that gives us now the opportunity to feel",
    "start": "317930",
    "end": "325380"
  },
  {
    "text": "like magicians not magicians wizards wizards or witches in my case but we",
    "start": "325380",
    "end": "331470"
  },
  {
    "text": "have gender not so-and-so Wizards we are now actually living in the future the",
    "start": "331470",
    "end": "337080"
  },
  {
    "text": "stuff that were in sci-fi movies that were impossible few years back deep",
    "start": "337080",
    "end": "343080"
  },
  {
    "text": "learning neural networks are giving us the chance to to actually do them and",
    "start": "343080",
    "end": "348229"
  },
  {
    "text": "don't get me wrong I know it's its own mouths sometimes very complex and",
    "start": "348229",
    "end": "355240"
  },
  {
    "text": "but it's very down-to-earth when you when you look at those deep networks but the result the the stuff that you can",
    "start": "355240",
    "end": "361870"
  },
  {
    "text": "see what those headlines are like hitting those are incredible I",
    "start": "361870",
    "end": "368190"
  },
  {
    "text": "personally feel like Hermione's sometimes when I when I know the right",
    "start": "368190",
    "end": "373240"
  },
  {
    "text": "comment when I know the right algorithm to use and solve the problem so I think",
    "start": "373240",
    "end": "378759"
  },
  {
    "text": "we are in a state that we can say our technology is indistinguishable from magic",
    "start": "378759",
    "end": "385229"
  },
  {
    "text": "so what are those neural networks where do they come from what they are so the idea like decades",
    "start": "385229",
    "end": "393759"
  },
  {
    "text": "ago was to mimic our brain so our brain works amazingly and we can we can",
    "start": "393759",
    "end": "399909"
  },
  {
    "text": "achieve amazing stuff so someone thought not just one person a few people thought why don't we just yeah",
    "start": "399909",
    "end": "408099"
  },
  {
    "text": "figure out how does it work put it in the machine machines are better in calculating their cluster so we'll",
    "start": "408099",
    "end": "416169"
  },
  {
    "text": "create something that will be an artificial intelligence and there was one problem with that nobody knows how",
    "start": "416169",
    "end": "422770"
  },
  {
    "text": "human brain works so knew a few things we knew that our brain has neurons right",
    "start": "422770",
    "end": "429880"
  },
  {
    "text": "we have cells that are called neurons we know those neurons are connected and we",
    "start": "429880",
    "end": "435360"
  },
  {
    "text": "know they are like passing the impulses to achieve something from there's",
    "start": "435360",
    "end": "441490"
  },
  {
    "text": "neurons intelligence but that's basically what we know if you know more",
    "start": "441490",
    "end": "448360"
  },
  {
    "text": "on this in this area if you're like neurologists or a person that is",
    "start": "448360",
    "end": "453789"
  },
  {
    "text": "interested of course we know much more about how human brain works but when you think of deep learning and neural",
    "start": "453789",
    "end": "460599"
  },
  {
    "text": "networks as the technology that is in mimicking our brain that's basically it",
    "start": "460599",
    "end": "466030"
  },
  {
    "text": "we took a concept of a neuron we took a concept of neurons being being connected and we took the concept of passing",
    "start": "466030",
    "end": "472630"
  },
  {
    "text": "signals that's all what it is in artificial neural networks nothing else",
    "start": "472630",
    "end": "477849"
  },
  {
    "text": "from human brains basically taken there is a concept of layers of course but",
    "start": "477849",
    "end": "483370"
  },
  {
    "text": "from what I read recently there are layers in our brain but they're not as",
    "start": "483370",
    "end": "488590"
  },
  {
    "text": "straightforward as distinguished as they are in the artificial neural networks so",
    "start": "488590",
    "end": "495630"
  },
  {
    "text": "well yeah it has to be obligatory some of you are probably too young to",
    "start": "495630",
    "end": "501040"
  },
  {
    "text": "remember this this movie but this is how my title came and so basically neural",
    "start": "501040",
    "end": "509650"
  },
  {
    "text": "networks and deep learning is based on layers the deeper network gets the",
    "start": "509650",
    "end": "514690"
  },
  {
    "text": "better results you're getting the downside is it really increases that",
    "start": "514690",
    "end": "521890"
  },
  {
    "text": "time that your network is being trained but the result is worth it",
    "start": "521890",
    "end": "527100"
  },
  {
    "text": "so layers and artificial neural networks this is a very simple artificial neural",
    "start": "527100",
    "end": "533290"
  },
  {
    "text": "network it only contains fully connected layers so what does it mean we have",
    "start": "533290",
    "end": "538990"
  },
  {
    "text": "those layers are put here we have four of them although some people are saying",
    "start": "538990",
    "end": "544150"
  },
  {
    "text": "that input nodes are not actual layer depending where you read depending on",
    "start": "544150",
    "end": "551410"
  },
  {
    "text": "the tool you you're using and what makes",
    "start": "551410",
    "end": "556540"
  },
  {
    "text": "the network deep are actually hidden layers so let's start from the beginning we have some inputs let's say the image",
    "start": "556540",
    "end": "562240"
  },
  {
    "text": "we have some output this is what our network is trying to figure out and we",
    "start": "562240",
    "end": "567580"
  },
  {
    "text": "have hidden layers this is a very bad name by the way I mean in my opinion because those hidden layers are not really hidden you",
    "start": "567580",
    "end": "574510"
  },
  {
    "text": "can touch them you can see what's there and the whole magic is actually",
    "start": "574510",
    "end": "579610"
  },
  {
    "text": "happening in those hidden layers so you can increase the number of cells in your",
    "start": "579610",
    "end": "585070"
  },
  {
    "text": "layers but the real complexity is introduced and your network will perform",
    "start": "585070",
    "end": "591040"
  },
  {
    "text": "better if you increase the numbers of layers and this is where the whole fun",
    "start": "591040",
    "end": "597400"
  },
  {
    "text": "starts so let's look closely what is",
    "start": "597400",
    "end": "602920"
  },
  {
    "text": "happening in a single cell let's look at this cell this cell is connected to all",
    "start": "602920",
    "end": "609310"
  },
  {
    "text": "of the cells from the previous layer and this cell is starring wait for all those inputs so it's taking on those inputs",
    "start": "609310",
    "end": "617640"
  },
  {
    "text": "multiplying them by weights and then aggregating the results usually by Meishan and then it goes through",
    "start": "617640",
    "end": "623710"
  },
  {
    "text": "something that's called activation function this is not a very complicated Maps right it's multiplying adding and",
    "start": "623710",
    "end": "632220"
  },
  {
    "text": "applying a function a function can be complicated but us as programmers we know all those libraries have them",
    "start": "632220",
    "end": "639070"
  },
  {
    "text": "already implemented so you just wrap it up with the function and you're done if you know anything about linear algebra",
    "start": "639070",
    "end": "645190"
  },
  {
    "text": "this is the explanation of my joke about matrix multiplication this is matrix multiplication multiplying adding and",
    "start": "645190",
    "end": "653560"
  },
  {
    "text": "putting in the right places in an output so for every layer we have a matrix that",
    "start": "653560",
    "end": "659470"
  },
  {
    "text": "is storing the weights for every cell so we have a matrix input layer contains a",
    "start": "659470",
    "end": "667300"
  },
  {
    "text": "vector and then we are multiplying it and this is basically what those calculations are I know if you're not a",
    "start": "667300",
    "end": "673930"
  },
  {
    "text": "mathematician in your hearts not very funny anymore but yeah I find it funny so this is fully connected layer this is",
    "start": "673930",
    "end": "680560"
  },
  {
    "text": "like the basics the foundation of how the maths work and deep learning and",
    "start": "680560",
    "end": "686560"
  },
  {
    "text": "artificial neural networks but the story of artificial brain starts in the",
    "start": "686560",
    "end": "694180"
  },
  {
    "text": "forties so you can see they were first like gates electrical/electronic or",
    "start": "694180",
    "end": "701470"
  },
  {
    "text": "gates and they were trying to to figure out the weights how to teach how to make",
    "start": "701470",
    "end": "708070"
  },
  {
    "text": "them learn to to adjust and then when we go for 50s 70s and then we have this",
    "start": "708070",
    "end": "715690"
  },
  {
    "text": "first time perception 57 multilayered with backpropagation the algorithm that",
    "start": "715690",
    "end": "721060"
  },
  {
    "text": "is used for training till now still 86",
    "start": "721060",
    "end": "726270"
  },
  {
    "text": "then there was this type of SVM machine so everyone that was working in machine learning and data science till very",
    "start": "726270",
    "end": "732940"
  },
  {
    "text": "recently like five years ago who is doing as VMs and then there was deep",
    "start": "732940",
    "end": "739930"
  },
  {
    "text": "neural network and basically if you if you think of principles if you think of",
    "start": "739930",
    "end": "745750"
  },
  {
    "text": "the Foundation's nothing really changed and now there is this big height now we",
    "start": "745750",
    "end": "751390"
  },
  {
    "text": "can do miracles now we live in the future now our technology is in thing possible from magic what happened",
    "start": "751390",
    "end": "757170"
  },
  {
    "text": "what changed before I will tell you what or you will tell me what I'll just tell",
    "start": "757170",
    "end": "764550"
  },
  {
    "text": "you like somewhere here in 2005 for when I was picking up my PhD dissertation and",
    "start": "764550",
    "end": "773360"
  },
  {
    "text": "I had this talk with my mentor and we were thinking what to do next what to do",
    "start": "773360",
    "end": "778710"
  },
  {
    "text": "next with this data mining thing and I said well this is amazing what those neural networks can do is we're just",
    "start": "778710",
    "end": "785130"
  },
  {
    "text": "adding multiplying stuff and it can do miracles and he said well nobody's using",
    "start": "785130",
    "end": "790980"
  },
  {
    "text": "it it's it's not going anywhere it's very niche projects purely academic so",
    "start": "790980",
    "end": "797580"
  },
  {
    "text": "we decided I will deal with evolutionary algorithm which is now nobody is using",
    "start": "797580",
    "end": "803220"
  },
  {
    "text": "and it's a very very niche project and very Academical so what changed why now",
    "start": "803220",
    "end": "808860"
  },
  {
    "text": "why we have all those neural networks now actually doing things it's not like it's purely academic it's actually in",
    "start": "808860",
    "end": "815190"
  },
  {
    "text": "production we are all in like interacting with it one way or the other",
    "start": "815190",
    "end": "820200"
  },
  {
    "text": "or the others who what changed we have",
    "start": "820200",
    "end": "825630"
  },
  {
    "text": "hardware right we have technology yeah",
    "start": "825630",
    "end": "830090"
  },
  {
    "text": "yes so we have hardware but we don't have to buy hardware right we have cloud and the cloud has better hardware we",
    "start": "831260",
    "end": "839460"
  },
  {
    "text": "have harder that can do matrix multiplication better right we have GT use TP use what else changed we have",
    "start": "839460",
    "end": "847890"
  },
  {
    "text": "data with actual big data it's not like data that doesn't fit into your memory is an actual data every company is",
    "start": "847890",
    "end": "854610"
  },
  {
    "text": "storing the data what else changed yeah",
    "start": "854610",
    "end": "860760"
  },
  {
    "text": "I know but it's very vague I did it on purpose",
    "start": "860760",
    "end": "866220"
  },
  {
    "text": "we have tools right there is this whole concept now of democratizing AI and it's",
    "start": "866220",
    "end": "871840"
  },
  {
    "text": "not just you know it is also for headlines of course and forgetting grunts but if you want you can do AI",
    "start": "871840",
    "end": "879760"
  },
  {
    "text": "like everyone can probably the first try it won't be great but you will be doing",
    "start": "879760",
    "end": "886660"
  },
  {
    "text": "it so so it's out there for you to read right and in my opinion because people",
    "start": "886660",
    "end": "893140"
  },
  {
    "text": "actually proved it works so they prove that you can solved the most complex",
    "start": "893140",
    "end": "901140"
  },
  {
    "text": "task in computer vision you know what's the most complex task in a computer vision distinguishing between cats and",
    "start": "901140",
    "end": "910930"
  },
  {
    "text": "dogs nobody could do it before now we have deplaning now we can do it now it's",
    "start": "910930",
    "end": "916210"
  },
  {
    "text": "a soft problem and a few years ago it wasn't people are trying to put",
    "start": "916210",
    "end": "921610"
  },
  {
    "text": "algorithmic this cut has pointy ears our dogs also have pointy ears right and you",
    "start": "921610",
    "end": "927130"
  },
  {
    "text": "try to describe it and the deterministic rules and algorithms and hit left and",
    "start": "927130",
    "end": "932200"
  },
  {
    "text": "now we just feel your network with examples you label it boom you have cotton duck sometimes dogs like",
    "start": "932200",
    "end": "938860"
  },
  {
    "text": "Chihuahua dogs are mixed with cupcakes that has notes but yeah it's also I",
    "start": "938860",
    "end": "946240"
  },
  {
    "text": "think it's now the unsolved computer vision problems though so there was there was this great TED talk and",
    "start": "946240",
    "end": "953130"
  },
  {
    "text": "encourage you to watch it and about the research facility that was doing this",
    "start": "953130",
    "end": "959110"
  },
  {
    "text": "amazing new technology innovative thing was trying to teach computer to",
    "start": "959110",
    "end": "966070"
  },
  {
    "text": "recognize images like we teach kids or like kids are learning from observing",
    "start": "966070",
    "end": "972430"
  },
  {
    "text": "the world and like one kid goes to the she's telling the story when kids go to the park and sometimes parents are",
    "start": "972430",
    "end": "980680"
  },
  {
    "text": "saying this is a cup this is the tree but most of the times they are not and so they were trying to to teach the",
    "start": "980680",
    "end": "989110"
  },
  {
    "text": "machine teach the algorithm model how to understand images and they succeeded now",
    "start": "989110",
    "end": "995769"
  },
  {
    "text": "normal now we know that this is the way to go but back then it was very innovative for a revolutionary idea and",
    "start": "995769",
    "end": "1002939"
  },
  {
    "text": "they succeeded and another thing is we have no tools it also like tensor flow",
    "start": "1002939",
    "end": "1008160"
  },
  {
    "text": "tensor flow is not the only one by the way but it's currently the most popular at the moment so if you're doing deep",
    "start": "1008160",
    "end": "1016049"
  },
  {
    "text": "learning at least when you like started recently you probably got in touch with thanksfor flow tensor flow works in a",
    "start": "1016049",
    "end": "1022379"
  },
  {
    "text": "way that you're building a computational graph and then you're feeding your daytime to it once you want to do the",
    "start": "1022379",
    "end": "1028470"
  },
  {
    "text": "computations I will show you that in a second principle gives you a lot of api's libraries classes on different",
    "start": "1028470",
    "end": "1035610"
  },
  {
    "text": "levels of abstraction so if you want to just say build me a network that has",
    "start": "1035610",
    "end": "1040798"
  },
  {
    "text": "three or five fully connected layers you can do just this or you can go deep down",
    "start": "1040799",
    "end": "1046350"
  },
  {
    "text": "and create your own algorithms from scratch",
    "start": "1046350",
    "end": "1051409"
  },
  {
    "text": "let's go to our classification task if you haven't encountered this a man√≠s",
    "start": "1051409",
    "end": "1058260"
  },
  {
    "text": "dataset is a very well-known machine learning data set and before there was",
    "start": "1058260",
    "end": "1064529"
  },
  {
    "text": "deep learning computer vision algorithms were trying to solve it because it's very simple but understandable and quite",
    "start": "1064529",
    "end": "1073700"
  },
  {
    "text": "production kind of wise data set so there is a data set that has handwritten",
    "start": "1073700",
    "end": "1080669"
  },
  {
    "text": "digits and the task is to recognize the digit very straightforward don't be",
    "start": "1080669",
    "end": "1086669"
  },
  {
    "text": "fooled those are not numbers those are digits so this is a classification task those are labels those are categories",
    "start": "1086669",
    "end": "1093029"
  },
  {
    "text": "not numbers we are not calculating this number based on those pixels we are",
    "start": "1093029",
    "end": "1098880"
  },
  {
    "text": "recognizing it it's a different task so every image is fed well every image the",
    "start": "1098880",
    "end": "1105960"
  },
  {
    "text": "the every image from the training data set is fed through our inept neural network the networks go goes through",
    "start": "1105960",
    "end": "1112470"
  },
  {
    "text": "training and then it's ready to recognize new examples every digit in",
    "start": "1112470",
    "end": "1119340"
  },
  {
    "text": "this particular data set there are few of them but in this one is in grayscale",
    "start": "1119340",
    "end": "1125279"
  },
  {
    "text": "and it's twenty eight by eight twenty eight pixels and what you usually do as your",
    "start": "1125279",
    "end": "1133780"
  },
  {
    "text": "first attempt or what people usually did in their first attempts at least when there weren't deep learning they were",
    "start": "1133780",
    "end": "1140260"
  },
  {
    "text": "flattening it so in our first attempt who flatten this file so we will get 784",
    "start": "1140260",
    "end": "1148920"
  },
  {
    "text": "607 880 phone numbers by significant so this will be number between zero and one",
    "start": "1148920",
    "end": "1153940"
  },
  {
    "text": "thing which which will indicate how close it is to white or plug in another",
    "start": "1153940",
    "end": "1162340"
  },
  {
    "text": "concept which is very introduced in many tutorials very early is something that",
    "start": "1162340",
    "end": "1169360"
  },
  {
    "text": "is called what something is called its batches cone and concept so in classical",
    "start": "1169360",
    "end": "1175240"
  },
  {
    "text": "machine learning when you're training your algorithm you're usually using all your training data so take all your data",
    "start": "1175240",
    "end": "1182140"
  },
  {
    "text": "you train your model with all of them and and you're like repeat the process",
    "start": "1182140",
    "end": "1188100"
  },
  {
    "text": "most of the times with deep learning it's rarely the case mostly because we",
    "start": "1188100",
    "end": "1196420"
  },
  {
    "text": "use deep learning for actual big data like we have tons of examples so one",
    "start": "1196420",
    "end": "1202390"
  },
  {
    "text": "thing could be we cannot even load the whole dataset into our memory that could be one thing another thing is it would",
    "start": "1202390",
    "end": "1210790"
  },
  {
    "text": "slow down the process massively so if you're thinking like Alumnus data",
    "start": "1210790",
    "end": "1216580"
  },
  {
    "text": "that I think it has 60,000 examples in the training train data set every time",
    "start": "1216580",
    "end": "1222880"
  },
  {
    "text": "reloading everything and putting it through our model this will slow down stuff but that's that's only the reason",
    "start": "1222880",
    "end": "1230679"
  },
  {
    "text": "why people started to look for new solutions and batches were actually",
    "start": "1230679",
    "end": "1236910"
  },
  {
    "text": "proven to work almost as good as the whole thing or even better so one",
    "start": "1236910",
    "end": "1243130"
  },
  {
    "text": "iteration using yours in one batch another iteration using another brush and it spits down the process like the",
    "start": "1243130",
    "end": "1250540"
  },
  {
    "text": "speed is going very well and that cracy stays the same so there are a few",
    "start": "1250540",
    "end": "1257050"
  },
  {
    "text": "algorithms like gradient descent stochastic gradient descent and and batches approach that will give",
    "start": "1257050",
    "end": "1265059"
  },
  {
    "text": "you the opportunity to fit in this hyper parameter than the size of the batch so",
    "start": "1265059",
    "end": "1270429"
  },
  {
    "text": "this is this is a decision you have to do when you're creating your algorithm so once we have our process trained",
    "start": "1270429",
    "end": "1278470"
  },
  {
    "text": "during this process we are just in the parameters the parameters are the weights the things that we are",
    "start": "1278470",
    "end": "1285389"
  },
  {
    "text": "multiplying our inputs with so those are things that has to be adjusted that's",
    "start": "1285389",
    "end": "1290980"
  },
  {
    "text": "that's the whole point of the training process once we have them we can then",
    "start": "1290980",
    "end": "1296110"
  },
  {
    "text": "use it to classify new examples so then you can draw a digit with into grayscale",
    "start": "1296110",
    "end": "1302730"
  },
  {
    "text": "it can go through your neural network and boom it should work first attempt",
    "start": "1302730",
    "end": "1308559"
  },
  {
    "text": "what we'll do I mean I would do and you can do it and cut recorder later and I",
    "start": "1308559",
    "end": "1313929"
  },
  {
    "text": "will build a neural network that has two layers or just one layer depending on the definition so input layer and output",
    "start": "1313929",
    "end": "1319899"
  },
  {
    "text": "layer that's it no hidden layers so we have 784 cells in my in the input and 10",
    "start": "1319899",
    "end": "1327639"
  },
  {
    "text": "cells 10 neurons in the output layer so basically we're taking our image",
    "start": "1327639",
    "end": "1334440"
  },
  {
    "text": "flattening it putting it through the output once the weights are trained and",
    "start": "1334440",
    "end": "1340899"
  },
  {
    "text": "adjusted it's using a soft max algorithm to figure out which cell activated the",
    "start": "1340899",
    "end": "1347500"
  },
  {
    "text": "best and we have our answer so I will",
    "start": "1347500",
    "end": "1353019"
  },
  {
    "text": "show you a demo not",
    "start": "1353019",
    "end": "1356340"
  },
  {
    "text": "so if you go to cut a coda and to my",
    "start": "1358840",
    "end": "1365030"
  },
  {
    "text": "profile and it's called tensorflow layers and our layers in tensorflow [Music]",
    "start": "1365030",
    "end": "1371380"
  },
  {
    "text": "make it a little bit bigger most of the stuff I was saying they will be here in",
    "start": "1371380",
    "end": "1377330"
  },
  {
    "text": "this tutorial but what I will show you is is the code basically so what I will",
    "start": "1377330",
    "end": "1385900"
  },
  {
    "text": "show you is this thing so first of all",
    "start": "1385900",
    "end": "1396040"
  },
  {
    "text": "before we will build the network I will show very quickly how the training process looks like and I won't go into",
    "start": "1397030",
    "end": "1406580"
  },
  {
    "text": "details just for you to know what is happening underneath and if you have a better idea for the training process and",
    "start": "1406580",
    "end": "1413060"
  },
  {
    "text": "hence there is a better idea I just made it very simple so not to go into details",
    "start": "1413060",
    "end": "1418330"
  },
  {
    "text": "you can change it if you want so it's all fully like you go to this code you",
    "start": "1418330",
    "end": "1423890"
  },
  {
    "text": "change it you run it and it will be and it will be there for you so first of all",
    "start": "1423890",
    "end": "1429050"
  },
  {
    "text": "I wrote the code it's in Python I wrote a function that is just reading this",
    "start": "1429050",
    "end": "1434780"
  },
  {
    "text": "dataset tensorflow gives you the capabilities of reading the MM this dataset out of the box so you don't have",
    "start": "1434780",
    "end": "1440630"
  },
  {
    "text": "to do it yourself you can there is no need and then I'm building the training if I is actually building something that",
    "start": "1440630",
    "end": "1447530"
  },
  {
    "text": "is called a computational graph which I've mentioned a little bit and computational graph is like a recipe of",
    "start": "1447530",
    "end": "1454400"
  },
  {
    "text": "this is how I want my computation to be performed and once you build it then you",
    "start": "1454400",
    "end": "1460070"
  },
  {
    "text": "run it but first I will build it so what I'm doing is I'm defining a loss function for those of you who are new to",
    "start": "1460070",
    "end": "1467110"
  },
  {
    "text": "machine learning this is something that will be minimizing or maximizing because",
    "start": "1467110",
    "end": "1472610"
  },
  {
    "text": "machine learning process is basically optimization process and you cannot actually mix it up with accuracy because",
    "start": "1472610",
    "end": "1479270"
  },
  {
    "text": "we've lost function we want to minimize it with accuracy we hope minimizing the loss function",
    "start": "1479270",
    "end": "1484430"
  },
  {
    "text": "will increase our accuracy so those are not the same function that they are",
    "start": "1484430",
    "end": "1489530"
  },
  {
    "text": "trying to get go so our loss function not to go into many details there are links in cata",
    "start": "1489530",
    "end": "1496040"
  },
  {
    "text": "coda if you're interested it's using softmax cross-entropy algorithm so",
    "start": "1496040",
    "end": "1501890"
  },
  {
    "text": "basically is trying to minimize the difference between what our neural network is giving us as the output and",
    "start": "1501890",
    "end": "1508310"
  },
  {
    "text": "what are the right answers it's trying to like see the difference and minimize the the difference between them and my",
    "start": "1508310",
    "end": "1517130"
  },
  {
    "text": "training step is very simple this is actually like one of the my favorite things in tensor flow I'm just saying",
    "start": "1517130",
    "end": "1523490"
  },
  {
    "text": "you know I'm an optimizer take my loss function and minimize it and that's it I",
    "start": "1523490",
    "end": "1529550"
  },
  {
    "text": "don't have to think how to implement my gradient descent stochastic gradient descent or the atom optimizer I can just",
    "start": "1529550",
    "end": "1536660"
  },
  {
    "text": "say optimize it minimize it and another thing I want to do is I want to",
    "start": "1536660",
    "end": "1542780"
  },
  {
    "text": "calculate their currency so like every few steps I want to see how my how my",
    "start": "1542780",
    "end": "1549310"
  },
  {
    "text": "network is performing at the end I want to check it on the train on the test data the data that wasn't visible there",
    "start": "1549310",
    "end": "1556850"
  },
  {
    "text": "during the training phase so this is accuracy calculations and this is when I",
    "start": "1556850",
    "end": "1562610"
  },
  {
    "text": "run all of it so I start an interactive session to run your calculations to run",
    "start": "1562610",
    "end": "1568430"
  },
  {
    "text": "your computation graph you have to start the session and then I'm using number of steps the default is 1000 so I'm running",
    "start": "1568430",
    "end": "1575750"
  },
  {
    "text": "thousands of steps and I'm getting batches I'm getting batches using the",
    "start": "1575750",
    "end": "1581120"
  },
  {
    "text": "function that is called Nell's but also provided by the tensor flow and then I'm saying take this bar and take the labels",
    "start": "1581120",
    "end": "1588740"
  },
  {
    "text": "of this but and use it every hundred steps I'm calculating the accuracy and",
    "start": "1588740",
    "end": "1595670"
  },
  {
    "text": "at the end of the iteration I'm running the Train step so I'm saying train stop",
    "start": "1595670",
    "end": "1601940"
  },
  {
    "text": "this optimization process here run it run it using the budget data you can see",
    "start": "1601940",
    "end": "1608420"
  },
  {
    "text": "that I filled it in with the batch data so in every step I'm using a separate",
    "start": "1608420",
    "end": "1613820"
  },
  {
    "text": "batch and that's basically it and then I'm using it for validation and sorry",
    "start": "1613820",
    "end": "1620060"
  },
  {
    "text": "for validation and test data set so let's let's run it iPhone oh no I",
    "start": "1620060",
    "end": "1628849"
  },
  {
    "text": "won't run it because I didn't show my network so let's see how do I build my",
    "start": "1628849",
    "end": "1634460"
  },
  {
    "text": "network so the one layer of network input and output so I read Munez data",
    "start": "1634460",
    "end": "1639499"
  },
  {
    "text": "set and I said my image size is 28 label size is 10 because we have 10 digits 10",
    "start": "1639499",
    "end": "1645470"
  },
  {
    "text": "labels in the output and I'm defining two placeholders plate holders in tensorflow are the places that you're",
    "start": "1645470",
    "end": "1653389"
  },
  {
    "text": "feeding your data when you're running your computational graph so in our case",
    "start": "1653389",
    "end": "1658609"
  },
  {
    "text": "this will be the batch stuff the blood inputs and the batch labels so",
    "start": "1658609",
    "end": "1663769"
  },
  {
    "text": "at the moment when I'm defining my graph we don't know what are the values we're just saying those values will be of this",
    "start": "1663769",
    "end": "1670099"
  },
  {
    "text": "shape of this type and this is how we create it so I'm just saying there will",
    "start": "1670099",
    "end": "1676340"
  },
  {
    "text": "be a batch we don't know what size of the batch would be it will have 748",
    "start": "1676340",
    "end": "1682149"
  },
  {
    "text": "shape and the output labels will be of the 10 will be of the size 10 because",
    "start": "1682149",
    "end": "1690139"
  },
  {
    "text": "we're using 100 actor so for every label there will be one in a place and the label is this is the boring stuff the",
    "start": "1690139",
    "end": "1698869"
  },
  {
    "text": "nice stuff is that I just defined now here my whole network my one layer in",
    "start": "1698869",
    "end": "1705139"
  },
  {
    "text": "one line and this is why I love the TF layers package or module I'm just saying",
    "start": "1705139",
    "end": "1712009"
  },
  {
    "text": "build me a dense network which is which is the name of a fully connected layer",
    "start": "1712009",
    "end": "1717889"
  },
  {
    "text": "and use input as an X input as input so this is the placeholder I defined",
    "start": "1717889",
    "end": "1723229"
  },
  {
    "text": "previously and use label size so I will have only 10 cells in my output network",
    "start": "1723229",
    "end": "1729499"
  },
  {
    "text": "and then I'm using what I've shown you in the help file so build training and training so I'm building the training",
    "start": "1729499",
    "end": "1738039"
  },
  {
    "text": "computational graph and then I'm building and then running it so let's run it dance",
    "start": "1738039",
    "end": "1745669"
  },
  {
    "text": "5 so it's downloading than this data set",
    "start": "1745669",
    "end": "1753130"
  },
  {
    "text": "and you can see in the file system that there is a folder that it downloaded it and then it run pretty quickly but the",
    "start": "1753130",
    "end": "1760510"
  },
  {
    "text": "accuracy is 83 percent not great it's a horrible but not great so how can we",
    "start": "1760510",
    "end": "1770290"
  },
  {
    "text": "make it better we'll just put it up now how can we make it better how can we",
    "start": "1770290",
    "end": "1780370"
  },
  {
    "text": "make it better more layers yes that's the point of this talk because I was talking too much about deep learning now",
    "start": "1780370",
    "end": "1786700"
  },
  {
    "text": "let's go for layers so we'll add some hidden layers this will rule at 1 you",
    "start": "1786700",
    "end": "1792040"
  },
  {
    "text": "can play and add more if you want but you'll get the gist and with the hidden",
    "start": "1792040",
    "end": "1797230"
  },
  {
    "text": "layers especially for kind of like computer vision stuff you have to think",
    "start": "1797230",
    "end": "1804280"
  },
  {
    "text": "of the activation functions so it's not just matrix multiplication I like to you so it's matrix multiplication we're",
    "start": "1804280",
    "end": "1811990"
  },
  {
    "text": "taking weights multiplying by inputs and then we're adding bias and then we're",
    "start": "1811990",
    "end": "1819010"
  },
  {
    "text": "wrapping it into activation function and there is it's another hyper parameter",
    "start": "1819010",
    "end": "1825310"
  },
  {
    "text": "which kind of an activation function you will use for for your layer so there is",
    "start": "1825310",
    "end": "1831820"
  },
  {
    "text": "a softmax function there is a sigmoid function this one hyperbolic tangent and",
    "start": "1831820",
    "end": "1838690"
  },
  {
    "text": "they have the green and the blue they have problem the problem is called",
    "start": "1838690",
    "end": "1844180"
  },
  {
    "text": "vanishing gradient descent so basically the back propagation the way how the network is trained is based on",
    "start": "1844180",
    "end": "1851590"
  },
  {
    "text": "derivatives and if you know a little bit about derivatives you can you can guess",
    "start": "1851590",
    "end": "1857350"
  },
  {
    "text": "that the relative here will be print like zero not kind of exactly zero very close to zero and our computers are",
    "start": "1857350",
    "end": "1864070"
  },
  {
    "text": "great and magical but they still are running up to zero small numbers right so derivative will be 0 here and here so",
    "start": "1864070",
    "end": "1872130"
  },
  {
    "text": "the network will stop passing ups passing their signals and yeah there is",
    "start": "1872130",
    "end": "1878380"
  },
  {
    "text": "a problem so sometimes it's better to use other activation functions so very",
    "start": "1878380",
    "end": "1885190"
  },
  {
    "text": "popular one recently and like I still cannot get my mind for the maps because",
    "start": "1885190",
    "end": "1890920"
  },
  {
    "text": "it's very simple the reloj function it gets zero for everything that is smaller than zero and",
    "start": "1890920",
    "end": "1897910"
  },
  {
    "text": "it's a linear function for everything that is more than zero and for me it's",
    "start": "1897910",
    "end": "1904270"
  },
  {
    "text": "basically a linear function so I don't know how does it work exactly but it does work so activation functions are",
    "start": "1904270",
    "end": "1914020"
  },
  {
    "text": "necessary in necessity for deep neural networks and this is what we are going to use will use the reloj function so we",
    "start": "1914020",
    "end": "1921760"
  },
  {
    "text": "have our input layer didn't change we have our output layer just didn't change but now we're putting one in the middle",
    "start": "1921760",
    "end": "1928179"
  },
  {
    "text": "so what we have to change is this one is no longer connected to the other one",
    "start": "1928179",
    "end": "1933210"
  },
  {
    "text": "it's connected here and the output is fed by the hidden layer what size of",
    "start": "1933210",
    "end": "1941080"
  },
  {
    "text": "hidden layer should we use nobody knows this is another hyper parameter that you",
    "start": "1941080",
    "end": "1947380"
  },
  {
    "text": "have to think of try it out experiment see what what works oh just you know",
    "start": "1947380",
    "end": "1952720"
  },
  {
    "text": "look at other people's work and see what are their conclusion and of course then",
    "start": "1952720",
    "end": "1958120"
  },
  {
    "text": "you can use it so I'll show you how to build your hidden layer now it will be",
    "start": "1958120",
    "end": "1963160"
  },
  {
    "text": "fully connected layer so the code should be enough for you to already know that",
    "start": "1963160",
    "end": "1969970"
  },
  {
    "text": "so the file is called Trello so everything stays the same at the",
    "start": "1969970",
    "end": "1977200"
  },
  {
    "text": "beginning I just added hidden layer size which I've put for a very round number",
    "start": "1977200",
    "end": "1982500"
  },
  {
    "text": "1024 and palace holders are the same and the",
    "start": "1982500",
    "end": "1988600"
  },
  {
    "text": "first layer is now hidden so I mean it's not hidden I just called it hid and it's",
    "start": "1988600",
    "end": "1994450"
  },
  {
    "text": "still dense layer and it gets an input as an input the placeholder and I'm",
    "start": "1994450",
    "end": "2000720"
  },
  {
    "text": "putting hidden size as a unit and there is something more so if you compare it",
    "start": "2000720",
    "end": "2007740"
  },
  {
    "text": "to the code of the output layer we have this activation function now right",
    "start": "2007740",
    "end": "2012940"
  },
  {
    "text": "if you don't specify activation in your function it will just take the linear function as",
    "start": "2012940",
    "end": "2019990"
  },
  {
    "text": "an activation function which means basically not applying any function that's all because it's just passing the",
    "start": "2019990",
    "end": "2025840"
  },
  {
    "text": "output of your layers so this is how is it is one thing I'm just connecting",
    "start": "2025840",
    "end": "2031210"
  },
  {
    "text": "input with the hidden and then hidden is connected to the output pretty straightforward if you want to do matrix",
    "start": "2031210",
    "end": "2037690"
  },
  {
    "text": "multiplication then circle allows you to do it you can always do that of course it's just once you're doing it for like",
    "start": "2037690",
    "end": "2044800"
  },
  {
    "text": "tenth time maybe fifth you get bored and you're thinking like this is all right I already know that I got this",
    "start": "2044800",
    "end": "2051460"
  },
  {
    "text": "give me some API or some function to do it for me because I get the concept but",
    "start": "2051460",
    "end": "2056860"
  },
  {
    "text": "I encourage you to do it if you haven't and the rest stays exactly the same",
    "start": "2056860",
    "end": "2062080"
  },
  {
    "text": "so remember how quickly the first one run let's see how how quick this one",
    "start": "2062080",
    "end": "2070360"
  },
  {
    "text": "will go dance",
    "start": "2070360",
    "end": "2074700"
  },
  {
    "text": "it's so quick but it's not as quick and why is that because we have now 1,000",
    "start": "2079419",
    "end": "2089260"
  },
  {
    "text": "424 cells that stir every of the cells tours 784 wait for the previous layer so",
    "start": "2089260",
    "end": "2097970"
  },
  {
    "text": "we had 1024 x 768",
    "start": "2097970",
    "end": "2104109"
  },
  {
    "text": "and adjustment yes so in this I think",
    "start": "2109220",
    "end": "2126589"
  },
  {
    "text": "it's pretty fine because if you think of activation function you could think of it as another layer of course so if it's",
    "start": "2126589",
    "end": "2133970"
  },
  {
    "text": "here it's straightforward just point her to this function whatever it works you probably know better",
    "start": "2133970",
    "end": "2141140"
  },
  {
    "text": "it's probably like a pointer to the function that has just been applied to every single cell in the layer but yeah",
    "start": "2141140",
    "end": "2148940"
  },
  {
    "text": "I cannot tell like 100% so yeah we have",
    "start": "2148940",
    "end": "2154339"
  },
  {
    "text": "now a hidden layer there and it worked oh did we look at the kursi it is better",
    "start": "2154339",
    "end": "2161690"
  },
  {
    "text": "right 94 that's that's kind of like okay we could could live with that but we can",
    "start": "2161690",
    "end": "2168230"
  },
  {
    "text": "do better I tell you we can do better and what we can do better with that is",
    "start": "2168230",
    "end": "2174950"
  },
  {
    "text": "actually adding something that is called convolutional layer and this is where",
    "start": "2174950",
    "end": "2180950"
  },
  {
    "text": "the whole fun with the whole magic actually started working with with",
    "start": "2180950",
    "end": "2186890"
  },
  {
    "text": "computer vision tasks convolutional layers were known I think in the 60s",
    "start": "2186890",
    "end": "2192010"
  },
  {
    "text": "it's still nothing new to the tech world it's just somebody took it applied it",
    "start": "2192010",
    "end": "2199069"
  },
  {
    "text": "and we actually learn how to train the convolutional neural network so",
    "start": "2199069",
    "end": "2204940"
  },
  {
    "text": "convolution as a mathematical operator is something that gets the part of the input doesn't have to be the image but",
    "start": "2204940",
    "end": "2211130"
  },
  {
    "text": "it's part of the input and applies the same let's say calculation the same the",
    "start": "2211130",
    "end": "2216660"
  },
  {
    "text": "matrix multiplication so we are applying weight we're adding it adding bias and",
    "start": "2216660",
    "end": "2222810"
  },
  {
    "text": "putting it as as the output so somebody took this idea and applied it to neural",
    "start": "2222810",
    "end": "2228240"
  },
  {
    "text": "networks and we gained few things from that first of all fully connected layer",
    "start": "2228240",
    "end": "2233540"
  },
  {
    "text": "1,024 times 748 a lot of weight for fully connected layer if you're hidden",
    "start": "2233540",
    "end": "2239730"
  },
  {
    "text": "males grow grow in size you have a lot of parameters a lot of weights and biases to Train and with convolutional",
    "start": "2239730",
    "end": "2246300"
  },
  {
    "text": "neural networks you're sharing weights so this operation that is applied to the part of the image is sharing those",
    "start": "2246300",
    "end": "2253770"
  },
  {
    "text": "weights those ways are adjusted in all those steps but they they stay the same and second of all those convolutional",
    "start": "2253770",
    "end": "2262980"
  },
  {
    "text": "neural networks make your network smaller make your layer smaller but",
    "start": "2262980",
    "end": "2268860"
  },
  {
    "text": "deeper and this death that was introduced actually shown that it can it",
    "start": "2268860",
    "end": "2276780"
  },
  {
    "text": "can recognize some interesting things so like with image recognition and it can recognize the borders it can recognize",
    "start": "2276780",
    "end": "2283530"
  },
  {
    "text": "the shapes and Folwell your in your network it can recognize the eye the",
    "start": "2283530",
    "end": "2289380"
  },
  {
    "text": "nose and then the whole face so how it",
    "start": "2289380",
    "end": "2294420"
  },
  {
    "text": "usually works is you're getting your convolutional neural network and we stack those conversional neural layer",
    "start": "2294420",
    "end": "2301800"
  },
  {
    "text": "and stack it on top of each other then you follow up with few fully connected layer and this is how the basic",
    "start": "2301800",
    "end": "2308760"
  },
  {
    "text": "convolutional networks work it's not just it there is usually something that",
    "start": "2308760",
    "end": "2316200"
  },
  {
    "text": "it's called polling and polling is an operation that gets part again works on",
    "start": "2316200",
    "end": "2322680"
  },
  {
    "text": "part of your image and gets for example a maximum value or an average value so you can see like the green rectangle",
    "start": "2322680",
    "end": "2329310"
  },
  {
    "text": "it's taking 21 the next one goes and it's 12 then it's 18 and 10 and what has",
    "start": "2329310",
    "end": "2336810"
  },
  {
    "text": "been proven as it decreases size the size of your network so you'll save a",
    "start": "2336810",
    "end": "2343230"
  },
  {
    "text": "lot of space well it still keeps all the all the values you're not losing",
    "start": "2343230",
    "end": "2349860"
  },
  {
    "text": "anything are you losing not a significant amount of information so this is an operation",
    "start": "2349860",
    "end": "2356100"
  },
  {
    "text": "that's usually stuck next to convolutional layer so you usually have and computer vision neural networks like",
    "start": "2356100",
    "end": "2363510"
  },
  {
    "text": "convolutional layer polling layer convolution area polling layer etc and then few of the fully connected layers I",
    "start": "2363510",
    "end": "2372740"
  },
  {
    "text": "will show you how to build it there is there's one trick actually two tricks so",
    "start": "2372740",
    "end": "2379740"
  },
  {
    "text": "convolutional layer works on the 2d 3d images I mean it can work on one deep",
    "start": "2379740",
    "end": "2387690"
  },
  {
    "text": "convolution can just go through your vector and take part take parts of the vectors but what it actually has proven",
    "start": "2387690",
    "end": "2394770"
  },
  {
    "text": "to work for computer vision stuff is it takes your part of your image and now",
    "start": "2394770",
    "end": "2400650"
  },
  {
    "text": "your image matters I mean the place where your pixel is matters previously",
    "start": "2400650",
    "end": "2406440"
  },
  {
    "text": "when we flattened it the 10th or 700 pixel doesn't matter we could we could",
    "start": "2406440",
    "end": "2413490"
  },
  {
    "text": "basically mix them up as long as we keep the order we we don't care about where",
    "start": "2413490",
    "end": "2419370"
  },
  {
    "text": "your pixel was now we take advantage of what what are the neighbors of of my",
    "start": "2419370",
    "end": "2426300"
  },
  {
    "text": "pixel so we actually reading the image right not just treating us as numbers so",
    "start": "2426300",
    "end": "2432570"
  },
  {
    "text": "that's a very very nice way to think about convolution so our our input that",
    "start": "2432570",
    "end": "2440610"
  },
  {
    "text": "has been flattened we know to have to put it back into 2d and after our",
    "start": "2440610",
    "end": "2445890"
  },
  {
    "text": "convolutional and polling layer we'll have to flatten it back because then",
    "start": "2445890",
    "end": "2451380"
  },
  {
    "text": "there is this hidden layer that is fully connected and only takes one day thanks let's go to the demo and I will show you",
    "start": "2451380",
    "end": "2461520"
  },
  {
    "text": "how to build a convolutional layer I'll actually run it now because it takes",
    "start": "2461520",
    "end": "2468180"
  },
  {
    "text": "some time",
    "start": "2468180",
    "end": "2470690"
  },
  {
    "text": "so you can see now that it's actually taking some time if we not only added another layer at the convolutional light",
    "start": "2478910",
    "end": "2485600"
  },
  {
    "text": "so image size besides hidden size all stays the same placeholders and now I'm reshaping the",
    "start": "2485600",
    "end": "2493400"
  },
  {
    "text": "input so tensorflow reshape function is very very useful one you'd use it all",
    "start": "2493400",
    "end": "2500120"
  },
  {
    "text": "the time basically so first I'm using creating",
    "start": "2500120",
    "end": "2505160"
  },
  {
    "text": "convolutional neural network convolutional layer and again I'm using",
    "start": "2505160",
    "end": "2510410"
  },
  {
    "text": "a package TF layers I'm using convolution comes to D and I'm saying",
    "start": "2510410",
    "end": "2515420"
  },
  {
    "text": "get my input the one that Irish shapes the to D use thirty-two filters the",
    "start": "2515420",
    "end": "2522500"
  },
  {
    "text": "depth size use the window 5x5 my",
    "start": "2522500",
    "end": "2527840"
  },
  {
    "text": "convolutional window and you don't actually define the strides here you're",
    "start": "2527840",
    "end": "2534110"
  },
  {
    "text": "saying use the padding that the same which means the output of this convolution will be of the same size as",
    "start": "2534110",
    "end": "2540830"
  },
  {
    "text": "the input so 28 by 28 and then use activation function that Israel and you",
    "start": "2540830",
    "end": "2549620"
  },
  {
    "text": "could add some bias here I didn't do it for the sake of clarity but you could",
    "start": "2549620",
    "end": "2555320"
  },
  {
    "text": "yeah and then I'm using a polling layer and my opinion polling layer is not a",
    "start": "2555320",
    "end": "2560630"
  },
  {
    "text": "layer it doesn't store and evaluates and doesn't store any biases it does not adjust any parameters it's not the layer",
    "start": "2560630",
    "end": "2567950"
  },
  {
    "text": "that is being trained it's just an operator that goes through some input and through some calculations but it can",
    "start": "2567950",
    "end": "2576500"
  },
  {
    "text": "be applied to anything you want and that's probably why the authors of the package put it as a separate layer which",
    "start": "2576500",
    "end": "2583370"
  },
  {
    "text": "kind of makes sense so I'm using the polling I'm using the convolutional as",
    "start": "2583370",
    "end": "2589780"
  },
  {
    "text": "convulsion layer as an input I'm saying use two by two and just write - that's a",
    "start": "2589780",
    "end": "2595820"
  },
  {
    "text": "common practice that's the first thing you should try if it doesn't work then you can play around but it's usually how",
    "start": "2595820",
    "end": "2603230"
  },
  {
    "text": "it's done and then I'm flooding this polling output and again using the",
    "start": "2603230",
    "end": "2609080"
  },
  {
    "text": "tensorflow reshape function and this is a very good calculating",
    "start": "2609080",
    "end": "2614670"
  },
  {
    "text": "example why do I have 14 by 14 by 32 we'll leave you this as an homework and",
    "start": "2614670",
    "end": "2620970"
  },
  {
    "text": "I actually encourage you to build your own convolutional layers with all the",
    "start": "2620970",
    "end": "2626070"
  },
  {
    "text": "weights and biases and like build it from scratch I just wanted to show you how once you understand how does it work",
    "start": "2626070",
    "end": "2632820"
  },
  {
    "text": "once you understand how to use it how you can take advantage of some API some",
    "start": "2632820",
    "end": "2637890"
  },
  {
    "text": "abstractions that libraries like tensorflow offer you and then I have my",
    "start": "2637890",
    "end": "2643440"
  },
  {
    "text": "hidden layer that I get my flattened stuff nothing changes after this so you've noticed that it's slowed down the",
    "start": "2643440",
    "end": "2651120"
  },
  {
    "text": "process like dramatically but we have better accuracy right 97 basically we",
    "start": "2651120",
    "end": "2657480"
  },
  {
    "text": "cannot go that further if we just use convolutional and fully connected layer",
    "start": "2657480",
    "end": "2663480"
  },
  {
    "text": "we probably could go to like 99 and and we'll try to do it and so you could try",
    "start": "2663480",
    "end": "2669540"
  },
  {
    "text": "to do it let's just add more layers and it should speed it up but like in general when we talk about accrue see",
    "start": "2669540",
    "end": "2676140"
  },
  {
    "text": "100 is the forest it can go right it's usually takes you the same time to go",
    "start": "2676140",
    "end": "2681960"
  },
  {
    "text": "from 40% to 70% or like 80 or even 90% and then like every percent is a win",
    "start": "2681960",
    "end": "2689400"
  },
  {
    "text": "after that right so what what I will",
    "start": "2689400",
    "end": "2695610"
  },
  {
    "text": "show you just very quickly going to slides yes I just came back is how to",
    "start": "2695610",
    "end": "2705000"
  },
  {
    "text": "add another convolutional layer and you can use this if want to just add another",
    "start": "2705000",
    "end": "2710490"
  },
  {
    "text": "another another another all you have to do is just put another in another and another put it as 2d and flatten the",
    "start": "2710490",
    "end": "2718680"
  },
  {
    "text": "last layer to feed it into the fully connected layers",
    "start": "2718680",
    "end": "2725390"
  },
  {
    "text": "yes yes so in my examples they have thinking have to like actually like you",
    "start": "2729049",
    "end": "2737400"
  },
  {
    "text": "probably have seen so many headlines about those cool things that machines",
    "start": "2737400",
    "end": "2743819"
  },
  {
    "text": "can dream and generate the images so they're using the convolutional layers",
    "start": "2743819",
    "end": "2749969"
  },
  {
    "text": "and polling layers like also for this because it's playing with the sizes it's",
    "start": "2749969",
    "end": "2755579"
  },
  {
    "text": "sometimes mixing it up so it's it's a machine type of an innovation and",
    "start": "2755579",
    "end": "2760680"
  },
  {
    "text": "creativity out save and and and there are some there's some articles that say",
    "start": "2760680",
    "end": "2767069"
  },
  {
    "text": "that actually polling layer which is very popular with computer vision tasks is not doing a good job with generating",
    "start": "2767069",
    "end": "2775710"
  },
  {
    "text": "images so generating images it it it leaves you with like rectangles there",
    "start": "2775710",
    "end": "2782999"
  },
  {
    "text": "because it's getting like average or max poll and passing it as the output so as",
    "start": "2782999",
    "end": "2788579"
  },
  {
    "text": "the result sometimes you if you like zoom it you can see all those small",
    "start": "2788579",
    "end": "2794249"
  },
  {
    "text": "rectangles so it's not that great so there are new techniques now you could",
    "start": "2794249",
    "end": "2799469"
  },
  {
    "text": "replace the polling with but they are the classical convolutional networks are usually the pairs of convolution polling",
    "start": "2799469",
    "end": "2806549"
  },
  {
    "text": "convolution polling convolution polling and at the end they're fully connected layers so again I will I will run it",
    "start": "2806549",
    "end": "2820410"
  },
  {
    "text": "because now it will be very slow Python",
    "start": "2820410",
    "end": "2826339"
  },
  {
    "text": "to spy and we will look at the code",
    "start": "2826339",
    "end": "2833329"
  },
  {
    "text": "nothing changed nothing changed reshaping the image and first convolutional the same 32 filters 5x5",
    "start": "2834140",
    "end": "2843719"
  },
  {
    "text": "window padding the same activation function realm polling layer two by two",
    "start": "2843719",
    "end": "2852059"
  },
  {
    "text": "strides and then I just use the polling layer as the input to my second",
    "start": "2852059",
    "end": "2857160"
  },
  {
    "text": "convolution I don't have to reshape it now because now it's 2d actually it's a it's free D because we have the same size and we",
    "start": "2857160",
    "end": "2865560"
  },
  {
    "text": "have depth so we have no 3d it takes some time for people like with so",
    "start": "2865560",
    "end": "2873119"
  },
  {
    "text": "imagination like mine to go through the fact that this input is freedom and we",
    "start": "2873119",
    "end": "2879090"
  },
  {
    "text": "have to deconvolution like how does it work it's actually applying to",
    "start": "2879090",
    "end": "2884700"
  },
  {
    "text": "deconvolution to every piece of your depth but I'm not here to teach you",
    "start": "2884700",
    "end": "2891690"
  },
  {
    "text": "about convolution this is quite a complex topic I recommend to like take",
    "start": "2891690",
    "end": "2897240"
  },
  {
    "text": "some course if you really want to understand it it's worth understanding and there are plenty of resources out",
    "start": "2897240",
    "end": "2902369"
  },
  {
    "text": "there so just google it and so my second convolutional layer I said I want 64",
    "start": "2902369",
    "end": "2909600"
  },
  {
    "text": "filters so now I want to I want to do 64 deaf and my kernel size size is still 5",
    "start": "2909600",
    "end": "2918150"
  },
  {
    "text": "by 5 and I have padding the same then I'm using polling layer and then I have",
    "start": "2918150",
    "end": "2927180"
  },
  {
    "text": "7 by 7 by 64 seriously it took me like",
    "start": "2927180",
    "end": "2932760"
  },
  {
    "text": "two hours of a headache to come up why why is it I knew it's working because I checked it but yeah and by the way most",
    "start": "2932760",
    "end": "2942359"
  },
  {
    "text": "of the problems that you will have with tensorflow and basically deep learning doesn't have",
    "start": "2942359",
    "end": "2947850"
  },
  {
    "text": "to be tensorflow any deep learning library would be that mixed up the",
    "start": "2947850",
    "end": "2954390"
  },
  {
    "text": "dimensions of your tensors so if you if you mixed it up you can always use",
    "start": "2954390",
    "end": "2960060"
  },
  {
    "text": "something like reshape or stuff that will squeeze or spread yours your things and probably would work but this is the",
    "start": "2960060",
    "end": "2967619"
  },
  {
    "text": "thing that you have to think of at first when something is going wrong so we have",
    "start": "2967619",
    "end": "2974040"
  },
  {
    "text": "two convolutional layers you get the gist how to add another and another and another now you just have to think off of this",
    "start": "2974040",
    "end": "2982260"
  },
  {
    "text": "size when you're flattening it at the end but there are also equations out",
    "start": "2982260",
    "end": "2988440"
  },
  {
    "text": "there will help you figure this out then I'm flattening it then I'm fitting it to the hidden layer",
    "start": "2988440",
    "end": "2994560"
  },
  {
    "text": "rest stays the same and I've been blabbing for a few minutes now and it's only on sec",
    "start": "2994560",
    "end": "3000380"
  },
  {
    "text": "step 600 so yeah let's let's have a cool",
    "start": "3000380",
    "end": "3005510"
  },
  {
    "text": "have a wait maybe not for a moment I will be telling you other stuff in a",
    "start": "3005510",
    "end": "3010550"
  },
  {
    "text": "second and we'll go back and see how does it perform so let's leave it like",
    "start": "3010550",
    "end": "3016040"
  },
  {
    "text": "this so yeah convolutional net neural networks pretty basic and starting to be",
    "start": "3016040",
    "end": "3026420"
  },
  {
    "text": "complex topics the topic so I found like fully connected layers every in every",
    "start": "3026420",
    "end": "3033740"
  },
  {
    "text": "introduction Airy course training tutorial it's pretty simple too grass",
    "start": "3033740",
    "end": "3039950"
  },
  {
    "text": "especially when it's so easy to to implement convolutional neural networks",
    "start": "3039950",
    "end": "3046450"
  },
  {
    "text": "even though they have been there for 46 50 years they start to like maybe not",
    "start": "3046450",
    "end": "3055220"
  },
  {
    "text": "you you're smarter than me but they started giving me a headache once I started learning about them so the idea",
    "start": "3055220",
    "end": "3062030"
  },
  {
    "text": "I got like today we're taking advantage of the pixels that are near to each",
    "start": "3062030",
    "end": "3067940"
  },
  {
    "text": "other I get the depth I get I've seen it I've seen I look at the hidden layers and",
    "start": "3067940",
    "end": "3074210"
  },
  {
    "text": "I've seen all those edges recognitions all those noses eyes etc you can see",
    "start": "3074210",
    "end": "3081620"
  },
  {
    "text": "that and it and you can even feel it's working it's just like no no it's not to",
    "start": "3081620",
    "end": "3086660"
  },
  {
    "text": "be complex now it's all this reaching out there democratizing of a I actually",
    "start": "3086660",
    "end": "3092270"
  },
  {
    "text": "demands you from something from you you have to learn you have to understand something you have to code something you",
    "start": "3092270",
    "end": "3098240"
  },
  {
    "text": "have to know when to use this kind of the network for those kind of problems and don't get me wrong",
    "start": "3098240",
    "end": "3105020"
  },
  {
    "text": "learn deep learning and and go out there and see what's out there but this is",
    "start": "3105020",
    "end": "3111050"
  },
  {
    "text": "pretty basic stuff and if you haven't no",
    "start": "3111050",
    "end": "3117350"
  },
  {
    "text": "this topic unless I'm a great teacher that I just taught you all about this you probably",
    "start": "3117350",
    "end": "3123380"
  },
  {
    "text": "don't get it fully at the moment right so all right",
    "start": "3123380",
    "end": "3129230"
  },
  {
    "text": "all as I can see in the audience so this is when it starts to be a train learning",
    "start": "3129230",
    "end": "3137690"
  },
  {
    "text": "process this is when when it's like well I thought this fanciful think we'll just like I'll just like say recognize the",
    "start": "3137690",
    "end": "3147470"
  },
  {
    "text": "digit and it will write it will just figure out which network I need what do I have to train and I thought this this",
    "start": "3147470",
    "end": "3154670"
  },
  {
    "text": "will be this easy and it is easy and it's easier it just doesn't mean you",
    "start": "3154670",
    "end": "3160730"
  },
  {
    "text": "don't have to do learn experiment and",
    "start": "3160730",
    "end": "3165880"
  },
  {
    "text": "because you do it's it's called data science for a reason okay the last",
    "start": "3165880",
    "end": "3174530"
  },
  {
    "text": "concept the last layer I would like to add to our network is something that's called dropout so I've read in many",
    "start": "3174530",
    "end": "3182270"
  },
  {
    "text": "books that reports should be only added to fully connected layers which is not true basically but I will explain it to",
    "start": "3182270",
    "end": "3190310"
  },
  {
    "text": "you on fully connected layer so there is this thing called overfitting overfitting is glorified named for your",
    "start": "3190310",
    "end": "3198950"
  },
  {
    "text": "model not just neural network to learn examples by heart and well it's",
    "start": "3198950",
    "end": "3205220"
  },
  {
    "text": "overfitting it has a hard time to recognize examples it hasn't seen during",
    "start": "3205220",
    "end": "3210740"
  },
  {
    "text": "the training phase so it's learned so well on those those examples that and it",
    "start": "3210740",
    "end": "3218150"
  },
  {
    "text": "limited itself so we have a lot of techniques to avoid it and one of them",
    "start": "3218150",
    "end": "3223460"
  },
  {
    "text": "is dropout so dropout is I think I have",
    "start": "3223460",
    "end": "3230540"
  },
  {
    "text": "this theory I have to check it and that some people were like sitting in a bar",
    "start": "3230540",
    "end": "3236690"
  },
  {
    "text": "having a few drinks and like saying our network is learning by heart those examples it's too smart for those",
    "start": "3236690",
    "end": "3243980"
  },
  {
    "text": "examples let's make it dumber so that's the concept of dropout randomly choose a",
    "start": "3243980",
    "end": "3250300"
  },
  {
    "text": "cell put the probability under to include the suspect",
    "start": "3250300",
    "end": "3257080"
  },
  {
    "text": "your neuron in the training sighs so if it does not pass the threshold we're",
    "start": "3257080",
    "end": "3262300"
  },
  {
    "text": "just not looking at this narrow neuron so you could think like of applying",
    "start": "3262300",
    "end": "3268420"
  },
  {
    "text": "weights zero in this neuron it's just it does not forget what it has been taught",
    "start": "3268420",
    "end": "3275170"
  },
  {
    "text": "so far it's just not being taken into account in this particular iteration",
    "start": "3275170",
    "end": "3281490"
  },
  {
    "text": "next time it could be in and those ways that we're so far trained they will",
    "start": "3281490",
    "end": "3287140"
  },
  {
    "text": "still be there and that's the key part it's only happening in the training phase once you have your model that is",
    "start": "3287140",
    "end": "3295000"
  },
  {
    "text": "built once you want to check how well it performs on some examples you can then",
    "start": "3295000",
    "end": "3302530"
  },
  {
    "text": "randomly drop out your neurons you have to have a deterministic answer so only",
    "start": "3302530",
    "end": "3309490"
  },
  {
    "text": "in the training phase only when you're adjusting your parameters your weights and biases then you're applying dropout",
    "start": "3309490",
    "end": "3316170"
  },
  {
    "text": "when you're testing it even when you're like like I'm checking the Icarus II",
    "start": "3316170",
    "end": "3321840"
  },
  {
    "text": "every for every hundred steps even then I cannot use this drop up because it",
    "start": "3321840",
    "end": "3327940"
  },
  {
    "text": "will be completely random the result would not mean anything so that's the",
    "start": "3327940",
    "end": "3333190"
  },
  {
    "text": "concept and my question is I didn't put it as a separate layer",
    "start": "3333190",
    "end": "3338710"
  },
  {
    "text": "although TF layers package is putting as a separate layer is this a separate",
    "start": "3338710",
    "end": "3345460"
  },
  {
    "text": "layer so in my opinion not because again it does not store any weights does not have parameters to be adjusted it just",
    "start": "3345460",
    "end": "3352570"
  },
  {
    "text": "randoms randomly apply some operations into my layer so",
    "start": "3352570",
    "end": "3361930"
  },
  {
    "text": "if we go back to cut a coda let's see how did it go so it was now 97 and it",
    "start": "3361930",
    "end": "3370660"
  },
  {
    "text": "was 97 28 97 66 it is better but you know every every percentage now is again",
    "start": "3370660",
    "end": "3378100"
  },
  {
    "text": "so I'll just run it because it will take some time on dropout yeah",
    "start": "3378100",
    "end": "3386730"
  },
  {
    "text": "it's the trading batch ITRC was ninety million percent and then the test accuracy was late 70s but also you need",
    "start": "3386730",
    "end": "3397050"
  },
  {
    "text": "to think that we are actually training on batches and we are evaluating only",
    "start": "3397050",
    "end": "3403410"
  },
  {
    "text": "one batch so we could be yeah we could be lucky or could be unlucky on this",
    "start": "3403410",
    "end": "3409920"
  },
  {
    "text": "particular but so it gives you some indication but you shouldn't really rely",
    "start": "3409920",
    "end": "3415800"
  },
  {
    "text": "on that but if I was evaluating the whole training data set even every 100",
    "start": "3415800",
    "end": "3423390"
  },
  {
    "text": "steps in a serious real-world problem this would like increase the time",
    "start": "3423390",
    "end": "3429530"
  },
  {
    "text": "massively but yeah it's sometimes it's sometimes actually how you recognize it",
    "start": "3429530",
    "end": "3436109"
  },
  {
    "text": "like you're saying it's it's so good at recognizing my examples right during the training phase but it's so rubbish when",
    "start": "3436109",
    "end": "3442320"
  },
  {
    "text": "I put it in production so just don't put it in production before you test it and put it into validation phase that's like",
    "start": "3442320",
    "end": "3449089"
  },
  {
    "text": "101 of machine learning so yeah trip out",
    "start": "3449089",
    "end": "3455250"
  },
  {
    "text": "let's let's look at dropout so everything else stays the same I will just show you",
    "start": "3455250",
    "end": "3461869"
  },
  {
    "text": "oh just show the dropout so this is the dropout I have my hidden layer and I",
    "start": "3462390",
    "end": "3467579"
  },
  {
    "text": "have dropout and I'm saying rate is 0.5 so we have 1/2 and 1/2 chance that our",
    "start": "3467579",
    "end": "3473280"
  },
  {
    "text": "neuron will be dropped out and I'm saying this is a training phase or not so should the drop is actually another",
    "start": "3473280",
    "end": "3480210"
  },
  {
    "text": "placeholder that I'm saying that I will put the value when I'm evaluating it so",
    "start": "3480210",
    "end": "3486869"
  },
  {
    "text": "if you're if you go to help this is this",
    "start": "3486869",
    "end": "3494550"
  },
  {
    "text": "is the thing when I'm doing the training I'm saying it shouldn't drop if I'm",
    "start": "3494550",
    "end": "3501569"
  },
  {
    "text": "going to test it I'm saying it shouldn't drop if I'm training it is it should drop so depending on why you're when",
    "start": "3501569",
    "end": "3510599"
  },
  {
    "text": "you're using your neural network you need to remember that if you're applying dropout you to tell your model",
    "start": "3510599",
    "end": "3517230"
  },
  {
    "text": "which phase it is there because again it's not magic times tougher won't",
    "start": "3517230",
    "end": "3522950"
  },
  {
    "text": "think for you you have to think about your algorithm so yeah",
    "start": "3522950",
    "end": "3529310"
  },
  {
    "text": "did we apply it I will come back to this later because we have to kind of finish",
    "start": "3529310",
    "end": "3537620"
  },
  {
    "text": "yeah yeah good point good point so drop",
    "start": "3537620",
    "end": "3555800"
  },
  {
    "text": "out we'll put some kind of a probability there right so it's not deterministic",
    "start": "3555800",
    "end": "3561680"
  },
  {
    "text": "anymore there are a few points in like atom or stochastic gradient descent or",
    "start": "3561680",
    "end": "3567920"
  },
  {
    "text": "great innocent that sometimes takes some probability too but yeah pretty much it",
    "start": "3567920",
    "end": "3573800"
  },
  {
    "text": "is kind of deterministic and drop out now is is adding some randomness",
    "start": "3573800",
    "end": "3579610"
  },
  {
    "text": "specifically for this overfitting reason that's why it's it's good once you have",
    "start": "3579610",
    "end": "3587930"
  },
  {
    "text": "a model that works to save it you have a model you save it you don't train it",
    "start": "3587930",
    "end": "3593030"
  },
  {
    "text": "that's one of the things another thing is reward examples we reward datasets it will take you as",
    "start": "3593030",
    "end": "3600680"
  },
  {
    "text": "hours sometimes days to train so don't just want to do it every time you need",
    "start": "3600680",
    "end": "3606110"
  },
  {
    "text": "to use it right so it's time for summary talk to you a lot about deep learning I",
    "start": "3606110",
    "end": "3613430"
  },
  {
    "text": "could talk more because it's my favorite topic and then we went through the",
    "start": "3613430",
    "end": "3618560"
  },
  {
    "text": "classification task form this dataset we build very simple convolutional neural",
    "start": "3618560",
    "end": "3624140"
  },
  {
    "text": "network convolutional neural networks are usually much more complex and have other spikes like resonates like",
    "start": "3624140",
    "end": "3631030"
  },
  {
    "text": "Inception they actually have an inception mem that is an official member",
    "start": "3631030",
    "end": "3636920"
  },
  {
    "text": "inception that comes from the film Inception very cool and we've built one",
    "start": "3636920",
    "end": "3644210"
  },
  {
    "text": "two three four five six seven layers depending how you define it so keep in",
    "start": "3644210",
    "end": "3652460"
  },
  {
    "text": "touch if there's anything I could help you with don't hesitate to contact me and I wish you a",
    "start": "3652460",
    "end": "3659420"
  },
  {
    "text": "great rest of the day and if you want to see what Sakura see I'll put my slide in",
    "start": "3659420",
    "end": "3668550"
  },
  {
    "text": "the second 97 78 yay so it did work",
    "start": "3668550",
    "end": "3674840"
  },
  {
    "text": "robot actually works thank you very much",
    "start": "3674840",
    "end": "3681560"
  },
  {
    "text": "[Applause]",
    "start": "3681560",
    "end": "3690329"
  }
]
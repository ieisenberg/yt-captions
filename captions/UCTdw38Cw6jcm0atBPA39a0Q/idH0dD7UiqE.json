[
  {
    "start": "0",
    "end": "73000"
  },
  {
    "text": "all right we're good to go great thanks for uh spending your last session at NC",
    "start": "4200",
    "end": "11000"
  },
  {
    "text": "Oslo well there's one more I think after this one but selecting to spend that with me that's makes me delighted so um",
    "start": "11000",
    "end": "18960"
  },
  {
    "text": "my name is yoan I'm working at a company called active solution back in Stockholm",
    "start": "18960",
    "end": "24160"
  },
  {
    "text": "Sweden this is the AI enhanced version of myself I usually prefer that nowadays when I get older the AI just makes me",
    "start": "24160",
    "end": "30880"
  },
  {
    "text": "somewhat nicer looking um so this talk will be about",
    "start": "30880",
    "end": "36800"
  },
  {
    "text": "developing agents and co-pilots with semantic kernel so there's been a lot of",
    "start": "36800",
    "end": "42160"
  },
  {
    "text": "AI talks this conference um a lot of llm talks so this will not be a theoretical",
    "start": "42160",
    "end": "48840"
  },
  {
    "text": "talk how they work this will not be like the moral philosophical questions that",
    "start": "48840",
    "end": "54280"
  },
  {
    "text": "surrounds them those are very important topics and there's been some great sessions uh on those topics uh but this",
    "start": "54280",
    "end": "60280"
  },
  {
    "text": "will be more about how you actually build stuff on top of this which is kind of cool because most of us are",
    "start": "60280",
    "end": "65880"
  },
  {
    "text": "developers right so we can build things uh and these uh models are really interesting to build applications on top",
    "start": "65880",
    "end": "72280"
  },
  {
    "text": "of them so we as a company we have been working with AI services for a long time",
    "start": "72280",
    "end": "77680"
  },
  {
    "text": "but uh what is now maybe referred to as traditional AI Services uh but it really",
    "start": "77680",
    "end": "83079"
  },
  {
    "text": "has exploded with the generative AI stuff obviously for the last 18 months or so since chat GPT came out uh um so",
    "start": "83079",
    "end": "91320"
  },
  {
    "text": "in terms of calling these things uh you know assistants co-pilots agents and so on uh this kind of line is uh uh quite",
    "start": "91320",
    "end": "98840"
  },
  {
    "text": "similar to what we have been doing for the last 18 months going from left to right here uh so what started really was",
    "start": "98840",
    "end": "104799"
  },
  {
    "text": "that most companies wanted kind of their own chat GPT because they really lik",
    "start": "104799",
    "end": "109840"
  },
  {
    "text": "what they could do with it uh but they don't want to have people use that service they want to have control of everything locking it down and so on so",
    "start": "109840",
    "end": "117039"
  },
  {
    "text": "we we did some work in actually deploying chat GPT similar services within the the Enterprises so this these",
    "start": "117039",
    "end": "123799"
  },
  {
    "text": "These are you know the chat Bots that you associate with chat GPT the next step is uh what is called",
    "start": "123799",
    "end": "129920"
  },
  {
    "text": "rag uh retrieval augmented generation which is a fancy word for how can you",
    "start": "129920",
    "end": "135560"
  },
  {
    "text": "use this technology with your own data because that's when it gets really interesting for Enterprises you want to",
    "start": "135560",
    "end": "141000"
  },
  {
    "text": "use the the reasoning capabilities the analytical power within this models but as an Enterprise it's not really",
    "start": "141000",
    "end": "147040"
  },
  {
    "text": "interesting if you don't use it on your own data uh so that was kind of The Next Step that we are still working on with a",
    "start": "147040",
    "end": "153319"
  },
  {
    "text": "lot of customers um seeing how can we combine the models on their for their",
    "start": "153319",
    "end": "158440"
  },
  {
    "text": "internal documents internal services and so on uh and this is are referred to as as a rag solution where you actually",
    "start": "158440",
    "end": "164800"
  },
  {
    "text": "retrieve some data and you augment um that to the response from this large",
    "start": "164800",
    "end": "170239"
  },
  {
    "text": "language model and the next up is what is often referred to as a co-pilot uh when in",
    "start": "170239",
    "end": "176560"
  },
  {
    "text": "addition to to just you know reading fetching information and producing answers you actually want to build",
    "start": "176560",
    "end": "182040"
  },
  {
    "text": "system that actually can assist you and actually do things on your behalf uh and this term obviously is used a lot by",
    "start": "182040",
    "end": "188760"
  },
  {
    "text": "Microsoft um uh and the the idea is that this is an an an AI assistant that will",
    "start": "188760",
    "end": "194440"
  },
  {
    "text": "kind of sit next to you it's a co-pilot it's not an autopilot so it will help you on your daily work so it will know",
    "start": "194440",
    "end": "200200"
  },
  {
    "text": "your context it knows what you're doing and it tries to be you know smart and assistant uh and you can build this in",
    "start": "200200",
    "end": "206080"
  },
  {
    "text": "many ways and I will show you some example how you can do that with semantic kernel and then maybe the maybe not the last",
    "start": "206080",
    "end": "212480"
  },
  {
    "text": "step but the next step is when you take these co-pilots or these assistants and make them more or fully autonomous and",
    "start": "212480",
    "end": "219159"
  },
  {
    "text": "this is typically what it's referred to as agents when you comine combine all these things uh and let them be for",
    "start": "219159",
    "end": "224840"
  },
  {
    "text": "example triggered by something is happening and they can be triggered by themselves and they can do actions without actually any human intervention",
    "start": "224840",
    "end": "232360"
  },
  {
    "text": "so that that can produce some really interesting scenarios obviously this is a maturity thing you can't start with",
    "start": "232360",
    "end": "238159"
  },
  {
    "text": "that on that end you really need to learn how this technology work move from the left to the right here before you",
    "start": "238159",
    "end": "243560"
  },
  {
    "text": "actually go into that direction but I will show you an example at the end on on kind of an agent like scenario that",
    "start": "243560",
    "end": "248879"
  },
  {
    "text": "you can also do with semantic kernel when you have things you know pretty much running on their own making decisions on their own and can produce",
    "start": "248879",
    "end": "255360"
  },
  {
    "text": "some interesting results at the end hopefully so Microsoft obviously has",
    "start": "255360",
    "end": "260720"
  },
  {
    "start": "258000",
    "end": "321000"
  },
  {
    "text": "beted a lot on this so I think this was from ignite last year when when SATA",
    "start": "260720",
    "end": "266280"
  },
  {
    "text": "said that we are the co-pilot company so they like went all in on this this and obviously AI is is the hype nowadays uh",
    "start": "266280",
    "end": "273800"
  },
  {
    "text": "so they're betting hard on co-pilots and and you probably you know you haven't missed that right you've seen co- Pilots",
    "start": "273800",
    "end": "279680"
  },
  {
    "text": "pop up everywhere so they're pretty much building this stuff into everything you have the the co- pilot which is the",
    "start": "279680",
    "end": "285080"
  },
  {
    "text": "what's you know used to be the being search that is the co-pilot but then addition you have co-pilots in Windows",
    "start": "285080",
    "end": "290560"
  },
  {
    "text": "you have co-pilots in office you know you have it in Asher you probably have it in notepad soon as well right they're",
    "start": "290560",
    "end": "296199"
  },
  {
    "text": "sticking copilot everywhere um and again like the the idea is that this will be an assistant",
    "start": "296199",
    "end": "302440"
  },
  {
    "text": "that that will help you along the way uh and some of these are you know pretty good some of them I don't think we'll",
    "start": "302440",
    "end": "307960"
  },
  {
    "text": "see the full value yet they're Prett still pretty like not D down but they are they're starting slow I think and",
    "start": "307960",
    "end": "314560"
  },
  {
    "text": "they will probably progress uh but I think most of us can see the power uh with this type of",
    "start": "314560",
    "end": "321680"
  },
  {
    "start": "321000",
    "end": "441000"
  },
  {
    "text": "tooling um so okay what do we mean by a co-pilot or a co-pilot application so I",
    "start": "321680",
    "end": "326880"
  },
  {
    "text": "usually know try to explain this in a very simple way so if we're building traditional applications we have an application with",
    "start": "326880",
    "end": "333360"
  },
  {
    "text": "some UI um and when the user wants to do something uh you know the user browses",
    "start": "333360",
    "end": "339960"
  },
  {
    "text": "to a page in a web page or or to desktop application and it clicks some buttons that will trigger some logic that we",
    "start": "339960",
    "end": "345919"
  },
  {
    "text": "have implemented uh you know we we did some requirement and we realized this is a US story so we need to implement that",
    "start": "345919",
    "end": "352400"
  },
  {
    "text": "and maybe that thing talks to an API for example and then you want to implement another user story that could be another",
    "start": "352400",
    "end": "358560"
  },
  {
    "text": "user interface another piece of logic and so on um and maybe we need to fetch",
    "start": "358560",
    "end": "363960"
  },
  {
    "text": "some data from the document store as well but you know this is obviously a very simple example but you know that's typically how we do when we're",
    "start": "363960",
    "end": "369880"
  },
  {
    "text": "implementing applications we're figuring out the requirements we Implement those requirements and then the user can can",
    "start": "369880",
    "end": "375039"
  },
  {
    "text": "you know use the application as we intended it but if you kind of switch this around and thinking more of this",
    "start": "375039",
    "end": "380720"
  },
  {
    "text": "like let the AI be the the orchestrator then it be more look like this so instead of building the UI",
    "start": "380720",
    "end": "387560"
  },
  {
    "text": "obviously now we are starting to use more and more the chat interface so we're kind of replacing the uis with the chat",
    "start": "387560",
    "end": "393280"
  },
  {
    "text": "interface uh but what's interesting is that then we're letting the AI now actually be the decision maker that what",
    "start": "393280",
    "end": "401039"
  },
  {
    "text": "needs to be done to actually fulfill the request you know answering the query or or you know the instruction that I'm",
    "start": "401039",
    "end": "406800"
  },
  {
    "text": "giving it well that then it's up to the AI to kind of Reason about that analyze my query my wish and figure out okay in",
    "start": "406800",
    "end": "414120"
  },
  {
    "text": "order to do this I need to you know to call some Services uh but the AI can't",
    "start": "414120",
    "end": "419319"
  },
  {
    "text": "do that on its own it can't reach out and you know call our our internal company service for example or talk to",
    "start": "419319",
    "end": "424720"
  },
  {
    "text": "documents so we need something in between there and this is typically what we mean by by a plugin uh so in sematic",
    "start": "424720",
    "end": "430120"
  },
  {
    "text": "kernel you have plugins that will you know be the bridge between the AI and you know your data your",
    "start": "430120",
    "end": "435800"
  },
  {
    "text": "services and that is really the the key here how you would Implement these",
    "start": "435800",
    "end": "441360"
  },
  {
    "start": "441000",
    "end": "589000"
  },
  {
    "text": "co-pilots so uh I don't know if how many have used the the apis from the you know",
    "start": "441360",
    "end": "447639"
  },
  {
    "text": "openi or asro openi so in in one sense this is like the the simplest API ever",
    "start": "447639",
    "end": "454400"
  },
  {
    "text": "you pass it in a string and you get a string back but if you actually have used this API there's a lot of complexity around",
    "start": "454400",
    "end": "460919"
  },
  {
    "text": "it um so first up uh this it's not just one model right uh the GPT models are",
    "start": "460919",
    "end": "467360"
  },
  {
    "text": "progressing and there's so many other models as well uh so just having some kind of abstraction or thing in between",
    "start": "467360",
    "end": "473879"
  },
  {
    "text": "here that will assist us to use those apis over time is really helpful um and then you need to deal",
    "start": "473879",
    "end": "480479"
  },
  {
    "text": "with things like uh you know the context because context is super important with the language models you need to pass it",
    "start": "480479",
    "end": "486759"
  },
  {
    "text": "the right information in order to actually get a good response back you need to think about history you know the",
    "start": "486759",
    "end": "492360"
  },
  {
    "text": "chat history these language models are stateless so they they don't remember anything that you asked them before so",
    "start": "492360",
    "end": "497800"
  },
  {
    "text": "you know when you're using chat gbt uh and you can do follow-up questions that works because you know under the hood",
    "start": "497800",
    "end": "503680"
  },
  {
    "text": "they actually pass the whole history back to the language model and that needs to be done uh in every application",
    "start": "503680",
    "end": "508800"
  },
  {
    "text": "that you building as well um and you need to deal with things like you know hallucinations and all",
    "start": "508800",
    "end": "514599"
  },
  {
    "text": "those problems that that that comes with the language models and then you know we don't have any access to the to external",
    "start": "514599",
    "end": "520240"
  },
  {
    "text": "data um obviously so the language models are you know the GPT models are running in the cloud they're stateless they",
    "start": "520240",
    "end": "526760"
  },
  {
    "text": "don't can't they can't access anything so you you need to provide us somehow and then you kind of have the problems",
    "start": "526760",
    "end": "532240"
  },
  {
    "text": "with the okay but that that will be like my own native code the code that I write so we have llms and we have native code",
    "start": "532240",
    "end": "538440"
  },
  {
    "text": "so how can we actually you know you know combine these things that is the tricky part and also with the large language",
    "start": "538440",
    "end": "544200"
  },
  {
    "text": "models I like this kind of quote that that hard things things that used to be really hard can now be really easy with",
    "start": "544200",
    "end": "549640"
  },
  {
    "text": "the language models because you know they can do really powerful things things that could take like weeks to implement before you could do that in",
    "start": "549640",
    "end": "555440"
  },
  {
    "text": "like one hour but on the other hand if you try to use the lar language models for for everything really simple things",
    "start": "555440",
    "end": "561680"
  },
  {
    "text": "can turn out to be really hard actually so it's the hammer and the nail problem you don't want to solve everything with a large language model because they're",
    "start": "561680",
    "end": "567839"
  },
  {
    "text": "not good at everything and the class IAL example here is the math that everybody keeps referring to like these models are",
    "start": "567839",
    "end": "573440"
  },
  {
    "text": "not good at math but you know doing math calculations in in computer programming",
    "start": "573440",
    "end": "578519"
  },
  {
    "text": "is super simple we've been doing that for you know 50 years so again use the language models for for what it's good",
    "start": "578519",
    "end": "585079"
  },
  {
    "text": "at but not for everything and then again you need to combine this so semantic kernel is an open",
    "start": "585079",
    "end": "592200"
  },
  {
    "start": "589000",
    "end": "702000"
  },
  {
    "text": "source framework from Microsoft so this is started out as like the core of their own you know co-pilot stack and then",
    "start": "592200",
    "end": "598640"
  },
  {
    "text": "they they open sourced it so initially this was only for net um and if you if",
    "start": "598640",
    "end": "605279"
  },
  {
    "text": "you have entered the the AI space you probably realize that there's a lot of python out there um so for people you",
    "start": "605279",
    "end": "611000"
  },
  {
    "text": "know like me from the traditional Microsoft space we're you know a lot in net so the python world is a bit scary",
    "start": "611000",
    "end": "616240"
  },
  {
    "text": "uh and takes a lot of time to just you know digest and go into so having a proper NET Framework is actually really",
    "start": "616240",
    "end": "621720"
  },
  {
    "text": "nice now they actually added also support for Python and Java as well uh",
    "start": "621720",
    "end": "627200"
  },
  {
    "text": "which actually turned uh ga back at the build conference so you can actually select all this language but for python",
    "start": "627200",
    "end": "633959"
  },
  {
    "text": "there's also a lot of other Frameworks like Lang chain and and llama index and so on uh but if you're in net space the",
    "start": "633959",
    "end": "640360"
  },
  {
    "text": "semantic colel is the way to go and again it lets you combine then the the language models you know with your own",
    "start": "640360",
    "end": "646600"
  },
  {
    "text": "code and we'll see a lot of examples on that so this framework is extensible by",
    "start": "646600",
    "end": "652079"
  },
  {
    "text": "by you implementing plugins that's that's what will you be doing in terms of actually having it be able to access",
    "start": "652079",
    "end": "658079"
  },
  {
    "text": "your own data and so on um so sematic kernel is all about the",
    "start": "658079",
    "end": "664519"
  },
  {
    "text": "kernel as they call it that's the the main object that you will instantiate and you will you know you'll pass it",
    "start": "664519",
    "end": "670800"
  },
  {
    "text": "various AI services so it can speak to various AI models over there so it's not just the GPT models you can also hook it",
    "start": "670800",
    "end": "677480"
  },
  {
    "text": "up to other models as well uh you can host the GPT models in in Asher or in openi and so on and it will kind of",
    "start": "677480",
    "end": "684040"
  },
  {
    "text": "abstract a lot of things away from you uh and then it has a lot of functionality in order to actually",
    "start": "684040",
    "end": "689480"
  },
  {
    "text": "create prompts it has things like you know uh template templatized",
    "start": "689480",
    "end": "695360"
  },
  {
    "start": "702000",
    "end": "1168000"
  },
  {
    "text": "so um you can know know what it looks like uh so I'll just show you some code",
    "start": "705079",
    "end": "712240"
  },
  {
    "text": "Snippets uh so to do that I'm going to use uh The Notebook support in vs code which is really nice if you haven't used",
    "start": "712240",
    "end": "718920"
  },
  {
    "text": "it before this is very common for you know in the in the python world with the jupyter notebooks but it works really",
    "start": "718920",
    "end": "724000"
  },
  {
    "text": "nice for net as well in vs code so let me just show you some examples on how",
    "start": "724000",
    "end": "729720"
  },
  {
    "text": "easy it is to get started with semantic kernel um so let's just start by looking",
    "start": "729720",
    "end": "737120"
  },
  {
    "text": "at the kernel well first up you need to start obviously with the nou package",
    "start": "737120",
    "end": "742199"
  },
  {
    "text": "this one so you know Microsoft semantic kernel that's a n package you need to install uh and then you need to create",
    "start": "742199",
    "end": "749399"
  },
  {
    "text": "the kernel that I mentioned before which we'll do here so uh you create the kernel and",
    "start": "749399",
    "end": "755560"
  },
  {
    "text": "then you you attach some or multiple AI services to it so in this case I'm using the Asher open AI uh you can see in the",
    "start": "755560",
    "end": "763079"
  },
  {
    "text": "in the commented out section that that's how we would use the open AI API those apis are very similar but it's mainly",
    "start": "763079",
    "end": "769800"
  },
  {
    "text": "around the authentication that is different um but you also have other options there uh and then you you know",
    "start": "769800",
    "end": "776120"
  },
  {
    "text": "you build the kernel and then you're good to go so that's all really all you need to do so let's just run this",
    "start": "776120",
    "end": "782800"
  },
  {
    "text": "code um and then we have the kernel so now let's just you know do the most basic thing let's just run the prompt",
    "start": "782800",
    "end": "789120"
  },
  {
    "text": "through it um and to do that I will run this code and I set up some settings so",
    "start": "789120",
    "end": "796320"
  },
  {
    "text": "there are some some settings around these models things like the temperature which kind of controls how you know how",
    "start": "796320",
    "end": "802440"
  },
  {
    "text": "creative it should be how stattic you know how deterministic or non-deterministic it should be you have things like Max tokens you know how many",
    "start": "802440",
    "end": "808560"
  },
  {
    "text": "tokens should return because tokens is what you're paying for here the amount of characters or tokens that you're",
    "start": "808560",
    "end": "814160"
  },
  {
    "text": "passing in and retrieving that's what you'll be paying for you want to make sure that you don't you don't want to have have it you know create a new novel",
    "start": "814160",
    "end": "820959"
  },
  {
    "text": "if you don't ask for it um and I'm just going to use the invoke prompt the sync to you know tell it to write a funny",
    "start": "820959",
    "end": "828519"
  },
  {
    "text": "joke and hopefully we'll get a funny joke in the end and it says why don't scientist trust atoms because they make",
    "start": "828519",
    "end": "834680"
  },
  {
    "text": "up everything um I actually found a postday because I even if I run this I usually",
    "start": "834680",
    "end": "842920"
  },
  {
    "text": "many case I do kind of get the same jokes over and over again so I had to actually Google that yesterday and it turns out that chat GPT or the GPT",
    "start": "842920",
    "end": "849880"
  },
  {
    "text": "models they kind of prefer the same 25 jokes all the time uh which is kind of interesting but I guess it's like a you",
    "start": "849880",
    "end": "856040"
  },
  {
    "text": "I don't I don't remember more than five jokes at at the most but again this is how easy it is it's just pretty once you",
    "start": "856040",
    "end": "862440"
  },
  {
    "text": "have the Cal it's just one line of code and you know you can you can U run it so then you can do like more you know",
    "start": "862440",
    "end": "869600"
  },
  {
    "text": "Advanced things um so for example you have things like templating support",
    "start": "869600",
    "end": "875759"
  },
  {
    "text": "because this is all about the prompts so you heard a lot about prompt engineering and you'll spend you'll be spending a lot of time crafting these prompts they",
    "start": "875759",
    "end": "882880"
  },
  {
    "text": "they they can be like the the the make and or break of a project actually you want to get these prompts right um and",
    "start": "882880",
    "end": "889519"
  },
  {
    "text": "so once you get them right you probably want to you know parameterize them like this so you can this is just a simple",
    "start": "889519",
    "end": "895079"
  },
  {
    "text": "example obviously but in this case I can use the same prompt but I can pass it in variables at run time so I'm having the",
    "start": "895079",
    "end": "901480"
  },
  {
    "text": "same prompt but now I can pass in the topic as the parameter so in this case I'll actually be running them two",
    "start": "901480",
    "end": "908800"
  },
  {
    "text": "prompts um so now we get you know the first joke about food and then the second joke about the",
    "start": "908800",
    "end": "916079"
  },
  {
    "text": "Consultants um and again these prompts now you you can store them in many ways obviously now I just hardcoded the",
    "start": "916079",
    "end": "922199"
  },
  {
    "text": "prompt but typically you want to store them somewhere else because in many cases when you're building applications on top of of of the models the prompts",
    "start": "922199",
    "end": "929480"
  },
  {
    "text": "are what you'll be changing a lot so you want to have a simple way of changing them and having them applied in your applications probably without rebuilding",
    "start": "929480",
    "end": "936440"
  },
  {
    "text": "the whole application so one powerful thing then",
    "start": "936440",
    "end": "941600"
  },
  {
    "text": "uh and also quite important is the ability to actually combine multiple models uh in the same program uh and",
    "start": "941600",
    "end": "948600"
  },
  {
    "text": "this makes sense for many reasons so in this case I'm again using the same um ad",
    "start": "948600",
    "end": "955959"
  },
  {
    "text": "as but I'm calling it twice uh and I actually Point into two different deployments so the first one is 3.5",
    "start": "955959",
    "end": "962480"
  },
  {
    "text": "turbo and the other one is 40 the latest one uh and you know why do I want to do this well again this really comes down",
    "start": "962480",
    "end": "969000"
  },
  {
    "text": "to cost and performance because you know the more powerful models are they're more powerful obviously but they're also",
    "start": "969000",
    "end": "975519"
  },
  {
    "text": "a lot more expensive uh they're typically slower as well uh and for many cases you don't need those models once",
    "start": "975519",
    "end": "981600"
  },
  {
    "text": "you start breaking this down into smaller proms you can actually use uh the 3.5 models or even simpler models",
    "start": "981600",
    "end": "987880"
  },
  {
    "text": "they will work perfectly f for for many cases uh and then I can you know I can",
    "start": "987880",
    "end": "993560"
  },
  {
    "text": "run the same prompt but I can ask it to use various models here so in this case",
    "start": "993560",
    "end": "999519"
  },
  {
    "text": "I'm telling it to write the final yoke in 10 words each word should start with letter A B C and so on and this was",
    "start": "999519",
    "end": "1005399"
  },
  {
    "text": "actually one of the ca the things that they when they announced gp4 this was one of the kind of samples that said",
    "start": "1005399",
    "end": "1011160"
  },
  {
    "text": "look at how much more powerful gp4 is uh because usually I I think 3.5 has become",
    "start": "1011160",
    "end": "1016880"
  },
  {
    "text": "better since then uh but usually it can the 3.5 mod can be a little tricked out",
    "start": "1016880",
    "end": "1022160"
  },
  {
    "text": "by this and doesn't always get the letters right and so on uh but but nowadays it it kind of gets you know",
    "start": "1022160",
    "end": "1028319"
  },
  {
    "text": "usually gets it pretty much right um but you know you're supposed to do a joke with start a b c and so on and",
    "start": "1028319",
    "end": "1035319"
  },
  {
    "text": "gp4 typically gets this a lot better than the 3.5 model um but again the important thing",
    "start": "1035319",
    "end": "1041360"
  },
  {
    "text": "is use the right model for the right task and the general guidance from Microsoft is you know start with a",
    "start": "1041360",
    "end": "1046480"
  },
  {
    "text": "powerful model make sure that it works as intended and when it does see if you can lower it you know to save cost and",
    "start": "1046480",
    "end": "1052720"
  },
  {
    "text": "and to gain speed but still you know get the the same quality in the output and obviously in many cases",
    "start": "1052720",
    "end": "1059600"
  },
  {
    "text": "you'll be building you know chat-like interfaces and um so doing that with sematic kernel is also really easy uh",
    "start": "1059600",
    "end": "1066919"
  },
  {
    "text": "and so chat history for example this is a uh a class on its own uh you know",
    "start": "1066919",
    "end": "1074400"
  },
  {
    "text": "because that's something you need to deal with so you'll be creating a chat history and then you can you know",
    "start": "1074400",
    "end": "1079440"
  },
  {
    "text": "implement the chatbot pretty much just like this uh by just uh you know asking",
    "start": "1079440",
    "end": "1085520"
  },
  {
    "text": "the query for some the user for something adding that message to the history and then you know run the prompt",
    "start": "1085520",
    "end": "1091320"
  },
  {
    "text": "and then you take the reply from the assistant you know from the model and put that as well back in the history and then you can you know use that in a",
    "start": "1091320",
    "end": "1097840"
  },
  {
    "text": "loop so if I run this so this is kind of interesting when you run this in Notebook and ask for input for the user",
    "start": "1097840",
    "end": "1105120"
  },
  {
    "text": "you kind of you get this up here so a where UI but down here it says hi how can I help you and I say I don't know",
    "start": "1105120",
    "end": "1113000"
  },
  {
    "text": "what can you do and then you know it's going to reply down here I can say something and I can",
    "start": "1113000",
    "end": "1118919"
  },
  {
    "text": "ask you know something again bye uh you know but again like 10 lines",
    "start": "1118919",
    "end": "1125280"
  },
  {
    "text": "of code then you have like you know the full chat experience with history because this will now allow me to",
    "start": "1125280",
    "end": "1130400"
  },
  {
    "text": "actually do follow-up questions because I'm passing in the history all the time but actually semantic kernel does that",
    "start": "1130400",
    "end": "1135720"
  },
  {
    "text": "for me so that was just a few examples on you",
    "start": "1135720",
    "end": "1142120"
  },
  {
    "text": "know how easy it is to get started and it's really nicely implemented i' say if you're building like an H core uh it's",
    "start": "1142120",
    "end": "1147679"
  },
  {
    "text": "you set this up as you would expect with you know dependence injection everything so it really nicely integrates with your",
    "start": "1147679",
    "end": "1153400"
  },
  {
    "text": "application uh as as a well-written NET Framework uh I haven't used the python",
    "start": "1153400",
    "end": "1158559"
  },
  {
    "text": "and and the Java versions but you know they're also like 1.0 now so they're they similar feature support as the net",
    "start": "1158559",
    "end": "1167080"
  },
  {
    "text": "version Okay so that was the basic stuff you know having a framework that makes it easier to call the API but that's not",
    "start": "1167080",
    "end": "1173679"
  },
  {
    "start": "1168000",
    "end": "1304000"
  },
  {
    "text": "you know that's not what you're here for so in semantic colel they have the three PS which are like the the core of",
    "start": "1173679",
    "end": "1180320"
  },
  {
    "text": "building you know co-pilots and agents so first up you have so you have plugins planners and personas so plugins this is",
    "start": "1180320",
    "end": "1187600"
  },
  {
    "text": "the where you'll be writing your code these are like if you think about AI as a brain you the plugins are like the",
    "start": "1187600",
    "end": "1193559"
  },
  {
    "text": "hands and arms they can actually do stuff because this is your code so this is how you how you'll build the",
    "start": "1193559",
    "end": "1199520"
  },
  {
    "text": "application um but the plugins can actually be either native like your own code or they can be prompts as I showed",
    "start": "1199520",
    "end": "1205679"
  },
  {
    "text": "you before you can actually encapsulate prompts and reuse them uh and I'll show you how that works um but if you're",
    "start": "1205679",
    "end": "1211559"
  },
  {
    "text": "doing it native this is how you will actually do things you know in the real world actually you know calling services and fetching data and so on you'll do",
    "start": "1211559",
    "end": "1218120"
  },
  {
    "text": "that through plugins but then the interesting part is the really the planners so the planners is all about",
    "start": "1218120",
    "end": "1224640"
  },
  {
    "text": "you know figuring out what do I need to do in order to actually you know reply or or accomplish the request of the user",
    "start": "1224640",
    "end": "1232679"
  },
  {
    "text": "so the planner will will see the query from the user it will know what plugins exist and it will figure out okay in",
    "start": "1232679",
    "end": "1238840"
  },
  {
    "text": "order to do this I need to call that plugin maybe I need to call that plugin and so on and then finally produce a",
    "start": "1238840",
    "end": "1244080"
  },
  {
    "text": "result back so this is like kind of where the magic the AI orchestration comes into place so it will decide this",
    "start": "1244080",
    "end": "1250280"
  },
  {
    "text": "on your on on its own what it needs to do and you know possibly it will call one or two or or multiple plugins and",
    "start": "1250280",
    "end": "1257159"
  },
  {
    "text": "finally you have the persona us which is really you know often called like the system prompt or The Meta prompt which",
    "start": "1257159",
    "end": "1264120"
  },
  {
    "text": "like in chat gbt you don't really see it it's it's hidden below but you always have this when you talk to these models",
    "start": "1264120",
    "end": "1269520"
  },
  {
    "text": "because you need to give it some kind of instructions on how it should behave but you can also have things like you know the personality what tone should it use",
    "start": "1269520",
    "end": "1276520"
  },
  {
    "text": "should it be like sarcastic or should it be nice and friendly uh you can also give it some grounding data to you know",
    "start": "1276520",
    "end": "1282400"
  },
  {
    "text": "to kind of trying to make sure that it answers only in a specific topic and if it's not in that topic it shouldn't you",
    "start": "1282400",
    "end": "1288200"
  },
  {
    "text": "know at all those are the kind of things that you will you know add to the",
    "start": "1288200",
    "end": "1293320"
  },
  {
    "text": "Persona uh maybe things like if if you don't uh know the answer just say you don't know those kind of things is what",
    "start": "1293320",
    "end": "1300039"
  },
  {
    "text": "you'll you'll put in the Persona so uh let's just look at some",
    "start": "1300039",
    "end": "1305720"
  },
  {
    "start": "1304000",
    "end": "1510000"
  },
  {
    "text": "examples of of these plugins then so a plugin can be either uh a prompt and in",
    "start": "1305720",
    "end": "1311080"
  },
  {
    "text": "that case it will be like a yaml file uh because yaml and uh so there's",
    "start": "1311080",
    "end": "1317200"
  },
  {
    "text": "some interesting Parts here first up it's a template this is the prompt itself it's nothing super special about",
    "start": "1317200",
    "end": "1323320"
  },
  {
    "text": "that you can see that it's having a parameter as well or kind of a variable the input so in this case it's a prompt",
    "start": "1323320",
    "end": "1329919"
  },
  {
    "text": "that you know is supposed to create uh an create an excuse uh for a certain",
    "start": "1329919",
    "end": "1335400"
  },
  {
    "text": "reason um you can also see that the template actually has an example in there um and that this this is also a",
    "start": "1335400",
    "end": "1342440"
  },
  {
    "text": "very us very common technique uh to actually include an example in this prompt this will in general make the",
    "start": "1342440",
    "end": "1349279"
  },
  {
    "text": "responses a lot better uh so this is called like a few shot or one shot learning just by doing that the",
    "start": "1349279",
    "end": "1355159"
  },
  {
    "text": "responses would be much much better and more deterministic and actually the way you want to if you give it an example of",
    "start": "1355159",
    "end": "1360600"
  },
  {
    "text": "what you would expect so that's a template that will you you know you'll be spending time",
    "start": "1360600",
    "end": "1365840"
  },
  {
    "text": "crafting those templates uh next one is the description uh and usually descriptions",
    "start": "1365840",
    "end": "1371360"
  },
  {
    "text": "aren't that interesting or relevant but in this case it's super relevant because description this is what actually will",
    "start": "1371360",
    "end": "1377840"
  },
  {
    "text": "this is what the I will use to decide if it should call this Plugin or not so",
    "start": "1377840",
    "end": "1383080"
  },
  {
    "text": "you'll need to be very very you know specific or and detailed here to make sure that it knows when to call this",
    "start": "1383080",
    "end": "1390039"
  },
  {
    "text": "plugin so in this case it says description is turn a scenario into a creative or humorous excuse to send your",
    "start": "1390039",
    "end": "1395880"
  },
  {
    "text": "boss that's the description of the plugin uh and in this case it also has a a variable so we'll have a description",
    "start": "1395880",
    "end": "1402720"
  },
  {
    "text": "on that on that variable as well so in this case it's the event that an excuse needs to be generated for because the AI",
    "start": "1402720",
    "end": "1409480"
  },
  {
    "text": "will call this plugin and when it does it also needs to pass some value for that variable so it will look at these",
    "start": "1409480",
    "end": "1415880"
  },
  {
    "text": "descriptions to figure out should I call this or not and if you don't do this right it won't be called when you want",
    "start": "1415880",
    "end": "1421960"
  },
  {
    "text": "it to be called and that will just create very strange cases um and then you can store this y",
    "start": "1421960",
    "end": "1429400"
  },
  {
    "text": "file I mean you can create this uh you know dynamically if you want to or you can store this in you know in the file or in the code or in a database or or",
    "start": "1429400",
    "end": "1436600"
  },
  {
    "text": "anywhere and you know can reuse them and then you can also modify them and you kind of reload them without you know",
    "start": "1436600",
    "end": "1442400"
  },
  {
    "text": "rebuilding the application but then you have a native plugins so this is a c example of that",
    "start": "1442400",
    "end": "1449360"
  },
  {
    "text": "and this is also very very simple it's it's just a method in C uh that you'll",
    "start": "1449360",
    "end": "1455159"
  },
  {
    "text": "annotate with the kernel function attribute um that you know that's how",
    "start": "1455159",
    "end": "1460400"
  },
  {
    "text": "sematic kernel knows that this is a plugin and then again you have the description U that I just showed you in",
    "start": "1460400",
    "end": "1465960"
  },
  {
    "text": "the plugin you have the same thing here uh you have one on the method and then you have another one uh on any",
    "start": "1465960",
    "end": "1472480"
  },
  {
    "text": "parameters that that method takes so this case it's uh the square root method so some kind of math",
    "start": "1472480",
    "end": "1478640"
  },
  {
    "text": "plug-in um and U on the bottom half is how you uh uh actually import the plugin",
    "start": "1478640",
    "end": "1487080"
  },
  {
    "text": "so once you define the plugins you'll import them into the kernel and once you do that the kernel will be able to call",
    "start": "1487080",
    "end": "1492919"
  },
  {
    "text": "that uh that plugin if it finds that it needs to",
    "start": "1492919",
    "end": "1498480"
  },
  {
    "text": "uh this is the same uh same kind of plugin in Python by the way uh if you're if you're a python python developer so",
    "start": "1498480",
    "end": "1505960"
  },
  {
    "text": "and Java is also very similar okay so that those are the the",
    "start": "1505960",
    "end": "1512240"
  },
  {
    "start": "1510000",
    "end": "1914000"
  },
  {
    "text": "plugins uh and now about the planners and uh so again the the reason or the",
    "start": "1512240",
    "end": "1517679"
  },
  {
    "text": "goal of a planner is given a user prompt uh create a plan on how to actually accomplish uh the the",
    "start": "1517679",
    "end": "1523200"
  },
  {
    "text": "request uh and there's actually multiple planners uh in static kernel so when",
    "start": "1523200",
    "end": "1528919"
  },
  {
    "text": "they started out implementing the planners they implemented kind of their own planners uh where they're using the",
    "start": "1528919",
    "end": "1534399"
  },
  {
    "text": "the language models obviously to kind of build a plan um and few of those exist",
    "start": "1534399",
    "end": "1541039"
  },
  {
    "text": "still like the handlebars planner and the function stepwise planner those are completely built by semantic kernel uh",
    "start": "1541039",
    "end": "1548240"
  },
  {
    "text": "but the first one which is the most common one is called function calling this is really based on because while they were doing that open AI released",
    "start": "1548240",
    "end": "1554840"
  },
  {
    "text": "something called function calling which is a thing that is you know built into the GPT models which does this thing",
    "start": "1554840",
    "end": "1562240"
  },
  {
    "text": "right U and I will actually um show this to you because this is kind of important to understand how this",
    "start": "1562240",
    "end": "1568760"
  },
  {
    "text": "works um so let me actually go to this page I think I have it open here",
    "start": "1568760",
    "end": "1575399"
  },
  {
    "text": "somewhere so this is just the announcements post when they released this from open ey this is back in uh",
    "start": "1575399",
    "end": "1581440"
  },
  {
    "text": "June last year uh and I'm just going to walk through the example here",
    "start": "1581440",
    "end": "1589039"
  },
  {
    "text": "um so so again so the the case here or the temple here is like okay so what's",
    "start": "1591039",
    "end": "1597240"
  },
  {
    "text": "the what's the weather like in Boston right now that is a question uh to you know to the API or the the model and",
    "start": "1597240",
    "end": "1603919"
  },
  {
    "text": "obviously you know the model doesn't know what the weather is right now in Boston right if you would ask the model",
    "start": "1603919",
    "end": "1609320"
  },
  {
    "text": "it would probably say I don't know or it would kind of hallucinate some kind of weird uh answer but that's not you what",
    "start": "1609320",
    "end": "1614840"
  },
  {
    "text": "you want you want to have the actual weather so what what actually happens now is I think in three steps here so",
    "start": "1614840",
    "end": "1621640"
  },
  {
    "text": "let's just quickly walk through those steps so you all understand how this actually works then",
    "start": "1621640",
    "end": "1628520"
  },
  {
    "text": "um so let's do this so first up what you would do is",
    "start": "1628520",
    "end": "1635039"
  },
  {
    "text": "you make a call to to the API and U you're passing two things here so first",
    "start": "1635039",
    "end": "1640399"
  },
  {
    "text": "one is the message which is you know obviously this is the message from the user so we have the role user and the",
    "start": "1640399",
    "end": "1646240"
  },
  {
    "text": "content is what is the weather like in Boston but that's not that's not uh only what",
    "start": "1646240",
    "end": "1651399"
  },
  {
    "text": "you're sending you're also sending uh the list of functions",
    "start": "1651399",
    "end": "1656720"
  },
  {
    "text": "here so this you're passing it a definition of a function uh in this case the function is called get current",
    "start": "1657240",
    "end": "1663480"
  },
  {
    "text": "weather it has a description much like what we saw before it has um a parameter",
    "start": "1663480",
    "end": "1669919"
  },
  {
    "text": "called the location uh and so the thing is you're telling",
    "start": "1669919",
    "end": "1675480"
  },
  {
    "text": "the model that you're asking it a question and you're also telling it hey I have some functions uh so you're",
    "start": "1675480",
    "end": "1681279"
  },
  {
    "text": "giving it the model that knowledge um and then you let the model decide should",
    "start": "1681279",
    "end": "1686519"
  },
  {
    "text": "I call that function or not now we just have one function but this could be many functions and you're you're giving it to",
    "start": "1686519",
    "end": "1692399"
  },
  {
    "text": "to the model to see okay if you if you want to you know you can call this function right maybe it doesn't you know",
    "start": "1692399",
    "end": "1700039"
  },
  {
    "text": "decide that it needs to but let's look at the response in this case what the model actually replies",
    "start": "1700039",
    "end": "1706720"
  },
  {
    "text": "with so it replies back with uh this is now from the you know from the",
    "start": "1706720",
    "end": "1713039"
  },
  {
    "text": "assistant uh and on the bottom here you can see like the finished reason that's",
    "start": "1713039",
    "end": "1718559"
  },
  {
    "text": "you know why did did the model stop and give you a reply usually that is just called or the had the value stop because",
    "start": "1718559",
    "end": "1724480"
  },
  {
    "text": "it's done but in this case the Finish reason is function calling and it replies back with hey you should call or",
    "start": "1724480",
    "end": "1731399"
  },
  {
    "text": "actually I you know I figured out that in order to you know answer your question I would like to call the",
    "start": "1731399",
    "end": "1737120"
  },
  {
    "text": "function that you have called get current weather and you should pass it the value of",
    "start": "1737120",
    "end": "1742440"
  },
  {
    "text": "Boston so that was like you know what the model did now it figured out that you know to to answer the query I need",
    "start": "1742440",
    "end": "1747799"
  },
  {
    "text": "to actually call the function because that function seems to be able to you know give me the weather in the location and I have a location in the query",
    "start": "1747799",
    "end": "1754120"
  },
  {
    "text": "Boston right so it it did that kind of AI magic for us but you know the model",
    "start": "1754120",
    "end": "1759760"
  },
  {
    "text": "can't call that API right it's uh it's it can't you know do anything on the internet uh and it's stateless so we",
    "start": "1759760",
    "end": "1767039"
  },
  {
    "text": "actually asking us to call it so that would then be step two in this process actually call that API so and",
    "start": "1767039",
    "end": "1774440"
  },
  {
    "text": "this could be now anything so in this case they're just showing it as a curl to some API it doesn't really matter this could be now be anything that's",
    "start": "1774440",
    "end": "1780720"
  },
  {
    "text": "completely up to you and the response in this case will typically be like okay it it in this",
    "start": "1780720",
    "end": "1786880"
  },
  {
    "text": "case it replies back with some kind of weather information it's 22 degre unit Celsius uh blah blah blah okay but so",
    "start": "1786880",
    "end": "1793679"
  },
  {
    "text": "now we have the weather in Boston in the API but we haven't gotten a reply from the model right we asked it what is the",
    "start": "1793679",
    "end": "1799240"
  },
  {
    "text": "weather like it hasn't replied yet and the reason is obviously because didn't know the weather so now we need to do",
    "start": "1799240",
    "end": "1805399"
  },
  {
    "text": "one more call back to the to the API so let's take a look at that one so",
    "start": "1805399",
    "end": "1811039"
  },
  {
    "text": "now you can see we're actually passing it uh three messages so again we're",
    "start": "1811039",
    "end": "1816080"
  },
  {
    "text": "passing it the first one because again it's stateless it doesn't remember what I did last time so I'm passing the",
    "start": "1816080",
    "end": "1821360"
  },
  {
    "text": "initial question then I'm passing it um the the kind of response from my function so I'm passing it now the",
    "start": "1821360",
    "end": "1828279"
  },
  {
    "text": "knowledge about the weather in Boston um and and also again like those",
    "start": "1828279",
    "end": "1834159"
  },
  {
    "text": "the the function ones and in this case let's look at the",
    "start": "1834159",
    "end": "1839640"
  },
  {
    "text": "response then so now you can see first up that it's uh says stop here so it means that",
    "start": "1839640",
    "end": "1847440"
  },
  {
    "text": "it's done it actually could be that it it would say you need to call another function now depending on the case here",
    "start": "1847440",
    "end": "1852559"
  },
  {
    "text": "this could actually go on now but in this case it it realized that now now I actually could reply back to the user",
    "start": "1852559",
    "end": "1858639"
  },
  {
    "text": "and it says the weather in Boston is currently sunny and has a you know temperature of 22° C so that was",
    "start": "1858639",
    "end": "1866519"
  },
  {
    "text": "actually a three-step process that you need to do to actually do this the the function",
    "start": "1866519",
    "end": "1871600"
  },
  {
    "text": "calling but this is now where where the medic is so the point is that these models now the GPT models or the later",
    "start": "1871600",
    "end": "1877360"
  },
  {
    "text": "versions they are uh not trained they are fine-tuned to do this so they have become really really good at giving a",
    "start": "1877360",
    "end": "1883840"
  },
  {
    "text": "list of functions pick the right function or functions and actually call them with the proper parameters uh and",
    "start": "1883840",
    "end": "1891200"
  },
  {
    "text": "produce Json back and that is something that then uh you know the semantic kernel team decided that you know we",
    "start": "1891200",
    "end": "1897440"
  },
  {
    "text": "obviously need to use this because this is now built into into the model uh so they did that by just uh implementing",
    "start": "1897440",
    "end": "1903440"
  },
  {
    "text": "this instatic kernel so instead of doing all that things that I just showed you you know calling you know these three",
    "start": "1903440",
    "end": "1909320"
  },
  {
    "text": "times mapping between the Json and your API you know a lot of things need to be done there the only thing you need to do",
    "start": "1909320",
    "end": "1915600"
  },
  {
    "start": "1914000",
    "end": "2024000"
  },
  {
    "text": "is that one just set one property and say hey call my functions if you find necessary and it will do all of that for",
    "start": "1915600",
    "end": "1922799"
  },
  {
    "text": "you you don't need to do anything else then you can just invoke that prompt and depending on what what the AI will",
    "start": "1922799",
    "end": "1928720"
  },
  {
    "text": "figure out it will call one or more of your functions and produce the reply back to you so again it makes it really really simple to to use that and this is",
    "start": "1928720",
    "end": "1936440"
  },
  {
    "text": "the planner that you will be using most of the times uh but there are other ones as I mentioned so there are some cases",
    "start": "1936440",
    "end": "1942480"
  },
  {
    "text": "where the other planners can be interesting one thing is uh around you know uh deterministic uh and potentially",
    "start": "1942480",
    "end": "1950919"
  },
  {
    "text": "performance so they they have another planner called handlebars planner and the point of this one is that this",
    "start": "1950919",
    "end": "1957679"
  },
  {
    "text": "planner can actually generate a full plan uh and it will give it to you and you can actually if you want to you can",
    "start": "1957679",
    "end": "1963279"
  },
  {
    "text": "save that plan uh and store it and you can reuse it later so that will give you better",
    "start": "1963279",
    "end": "1969159"
  },
  {
    "text": "performance uh but it will also give you the kind of the option of actually evaluating the plan right uh maybe you",
    "start": "1969159",
    "end": "1975200"
  },
  {
    "text": "don't want it to kind of just go crazy and call your your your plugins without you knowing it so using this kind of",
    "start": "1975200",
    "end": "1982120"
  },
  {
    "text": "plan you can actually store that plan maybe could you could validate it make sure that it looks good and then you can",
    "start": "1982120",
    "end": "1987480"
  },
  {
    "text": "reuse it later uh so in that case uh what you can do is you create use that planner and",
    "start": "1987480",
    "end": "1994639"
  },
  {
    "text": "then you you'll get the plan back as a string and you can store that one and if you look at that plan it actually looks",
    "start": "1994639",
    "end": "1999679"
  },
  {
    "text": "something like this so This actually uses the The Handlebar language uh of so",
    "start": "1999679",
    "end": "2005000"
  },
  {
    "text": "they just selected that language as to represent these plans so you can kind of",
    "start": "2005000",
    "end": "2010559"
  },
  {
    "text": "see here how that plan looks now like it identified four different steps and in one of the step it actually kind of does",
    "start": "2010559",
    "end": "2016240"
  },
  {
    "text": "a loop and so on um so again you could kind of validate this and save it and",
    "start": "2016240",
    "end": "2021679"
  },
  {
    "text": "use it later uh but most of the times you'll be using the the the function calling so",
    "start": "2021679",
    "end": "2027399"
  },
  {
    "text": "let's just do a few quick examples of how that actually works so let's first",
    "start": "2027399",
    "end": "2033080"
  },
  {
    "text": "just let's take a look at the plugins um",
    "start": "2033080",
    "end": "2038320"
  },
  {
    "text": "so let's just run that one so let's just you know to show you how it works with u",
    "start": "2038320",
    "end": "2045000"
  },
  {
    "text": "with yaml prompt so in this case I'm just you know reading the The Prompt here uh just from a file that's the same",
    "start": "2045000",
    "end": "2052398"
  },
  {
    "text": "prompt that I showed you on the slide before and then the next step would be then to",
    "start": "2052399",
    "end": "2057599"
  },
  {
    "text": "actually uh import that as a as a plugin so you take that the the definition the Y definition and you import it into the",
    "start": "2057599",
    "end": "2063878"
  },
  {
    "text": "kernel and you know after that it just becomes a plugin like like it would have been been your own code and then you can",
    "start": "2063879",
    "end": "2070720"
  },
  {
    "text": "just run it uh and you know in so in this case what I'm doing here I'm actually invoking that that uh plugin",
    "start": "2070720",
    "end": "2078118"
  },
  {
    "text": "explicitly down here uh because in some cases you don't need a planner you know what you want to",
    "start": "2078119",
    "end": "2084480"
  },
  {
    "text": "do so you can actually just call that prompt or call that function uh that you know obviously that would be more a more",
    "start": "2084480",
    "end": "2091040"
  },
  {
    "text": "deterministic way of of doing it uh so if I run this now it will uh uh run use",
    "start": "2091040",
    "end": "2098280"
  },
  {
    "text": "that excuse prompt that I showed you before so it will come up with an excuse uh in this case I'm passing it the input",
    "start": "2098280",
    "end": "2104720"
  },
  {
    "text": "of customer meeting so it should you know figure out why I was late to the customer meeting so it says I'm running",
    "start": "2104720",
    "end": "2109960"
  },
  {
    "text": "late for the customer meeting because I was being held Ransom by girof gangsters who tied my shoelaces together with blah",
    "start": "2109960",
    "end": "2116560"
  },
  {
    "text": "blah blah blah uh but again the point now is that uh looking at the prompt here that I",
    "start": "2116560",
    "end": "2123359"
  },
  {
    "text": "showed you before uh this is now stored separately you can store this anywhere uh you you can load it dynamically you",
    "start": "2123359",
    "end": "2128760"
  },
  {
    "text": "can change it uh and so on without you know changing the the application and again A lot of times this is what you'll",
    "start": "2128760",
    "end": "2134240"
  },
  {
    "text": "be changing not the application code because the application code will be quite simple it's the The Prompt that",
    "start": "2134240",
    "end": "2139320"
  },
  {
    "text": "will change and and be complicated so that's the the the jaml uh part of a",
    "start": "2139320",
    "end": "2145520"
  },
  {
    "text": "plugin uh so let's take a look at the native one um and so in this case I have u a",
    "start": "2145520",
    "end": "2153160"
  },
  {
    "text": "simple plugin that will call an API um so actually in this case it will fetch",
    "start": "2153160",
    "end": "2158760"
  },
  {
    "text": "it will talk to the Swedish radio API so let's just take a look at how how that plug-in",
    "start": "2158760",
    "end": "2165319"
  },
  {
    "text": "looks um so it's quite simple uh it just has uh one one it's",
    "start": "2165319",
    "end": "2173119"
  },
  {
    "text": "just one plug in one method so again we have the the kernel function up here the",
    "start": "2173119",
    "end": "2178160"
  },
  {
    "text": "attribute and then we have the you know description say search episodes from the Swedish radio s it's a in parth and then",
    "start": "2178160",
    "end": "2185200"
  },
  {
    "text": "you know we have the description uh which is the search query so again",
    "start": "2185200",
    "end": "2190920"
  },
  {
    "text": "given given that I passing a prompt that has something to do with you know the Swedish radio I'm asking about something",
    "start": "2190920",
    "end": "2196960"
  },
  {
    "text": "then probably I want the pl if I would use the planner this is what it would use to actually call this one and then I",
    "start": "2196960",
    "end": "2202760"
  },
  {
    "text": "have some code in here that's not really relevant it could be doing anything in this case it just fetches episodes from",
    "start": "2202760",
    "end": "2208440"
  },
  {
    "text": "uh the Swedish radio API uh on a certain topics so let's go back to this one and",
    "start": "2208440",
    "end": "2213720"
  },
  {
    "text": "run it uh so in this case I'm I'm using the I'm passing it the query technique so I",
    "start": "2213720",
    "end": "2220319"
  },
  {
    "text": "want to have like Tech related episodes from the Swedish radio so let's just run it to see that it works and down here so",
    "start": "2220319",
    "end": "2227920"
  },
  {
    "text": "again just getting the output from that plugin so again I'm not using planners now just to be clear I'm just invoking",
    "start": "2227920",
    "end": "2234359"
  },
  {
    "text": "these plugins directly and again there are cases when you you know when you want to do that when you don't need a",
    "start": "2234359",
    "end": "2239920"
  },
  {
    "text": "planner because the planner is more I mean it will spend more tokens you'll pay more for it and in some cases you",
    "start": "2239920",
    "end": "2246119"
  },
  {
    "text": "know what you want to do you just want to to run a prompt or or or custom plugin but again like the interesting",
    "start": "2246119",
    "end": "2253359"
  },
  {
    "text": "part really is when you are using planners but now you can of hopefully know how the plugins",
    "start": "2253359",
    "end": "2259440"
  },
  {
    "text": "work so let's take a look how how to combine these things and with a planner um so if you remember the only",
    "start": "2259440",
    "end": "2267480"
  },
  {
    "start": "2264000",
    "end": "2589000"
  },
  {
    "text": "thing I really need to do now it's kind of two things first up I need to um import my",
    "start": "2267480",
    "end": "2275680"
  },
  {
    "text": "plugins so in this case I'm importing two plugins first up the one that I just showed you the Swedish radio plugin and",
    "start": "2275680",
    "end": "2281839"
  },
  {
    "text": "then I'm also passing it another plugin which is a file IO plugin so that's a plugin that can you know read and save",
    "start": "2281839",
    "end": "2288119"
  },
  {
    "text": "files on the local disk so I'm giving it two plugins and again the next part is",
    "start": "2288119",
    "end": "2295480"
  },
  {
    "text": "this one oops uh I'm saying that the the the tool",
    "start": "2295480",
    "end": "2302119"
  },
  {
    "text": "call Behavior should be Auto invoke again that means that if the colel now figures out that that it thinks it",
    "start": "2302119",
    "end": "2308240"
  },
  {
    "text": "should call a function just do it you don't need to kind of uh validate that with me I don't you don't have to do",
    "start": "2308240",
    "end": "2314520"
  },
  {
    "text": "this you can also say manual then you'll need to call it your yourself I'll show you an example that later but then I'll",
    "start": "2314520",
    "end": "2320640"
  },
  {
    "text": "give it a prompt here it says get a list of all programs about technology that has been aired today on Swedish radio list the programs with name title URL",
    "start": "2320640",
    "end": "2327200"
  },
  {
    "text": "and so on Save the list of programs in a file called episodes or text and then return the list of programs back to the",
    "start": "2327200",
    "end": "2332800"
  },
  {
    "text": "user so again this is like a quer that's something I could say or write as a as a question I'm not really referring",
    "start": "2332800",
    "end": "2339599"
  },
  {
    "text": "anything to I don't say exactly you know about any plugins or um I'm just you",
    "start": "2339599",
    "end": "2345800"
  },
  {
    "text": "know I'm just saying I want to know what's on the Swedish radio today right and I want to save it in a",
    "start": "2345800",
    "end": "2351000"
  },
  {
    "text": "file so let's run this um see what",
    "start": "2351000",
    "end": "2357480"
  },
  {
    "text": "happens so I know that API sometimes is a little bit slow so let's see how much time so what actually happened now",
    "start": "2359040",
    "end": "2365720"
  },
  {
    "text": "already is I can see now that we have file down here uh called episode.",
    "start": "2365720",
    "end": "2372359"
  },
  {
    "text": "text um so I have a file it was called episode. text so the planner figured out",
    "start": "2372359",
    "end": "2378760"
  },
  {
    "text": "that you know I need to call that plugin because you asked me to um and it also",
    "start": "2378760",
    "end": "2384480"
  },
  {
    "text": "responded back with the results again because I said return the list of programs back to the user so it",
    "start": "2384480",
    "end": "2390480"
  },
  {
    "text": "did so I actually used both of those plugins now the you know the Swedish radio plug-in and the file plugin and",
    "start": "2390480",
    "end": "2395920"
  },
  {
    "text": "kind of combine them in the right order to do that I didn't really tell it how to do that I just you know told it what I wanted wanted it to do so just to show",
    "start": "2395920",
    "end": "2404440"
  },
  {
    "text": "you what's going on if I can run the same example but just with just with some added",
    "start": "2404440",
    "end": "2410800"
  },
  {
    "text": "logging um so what you can do is you can hook into to a lot of things for example the function invoked that's a way for",
    "start": "2410800",
    "end": "2417200"
  },
  {
    "text": "you to could you could do logging this is also a way for you if you want to kind of override things uh validate",
    "start": "2417200",
    "end": "2423560"
  },
  {
    "text": "things before anything is being called you can do that you know before it's invoked and and you know stop it if you",
    "start": "2423560",
    "end": "2428599"
  },
  {
    "text": "want to in this case I'm just logging out what's being called and what's what's being passed to the function so",
    "start": "2428599",
    "end": "2434760"
  },
  {
    "text": "if I'm running this again it's the same uh the same prompt down here but if we're looking at the results",
    "start": "2434760",
    "end": "2440839"
  },
  {
    "text": "now you can see for example that the first thing it did was to call the search episode um function and the query",
    "start": "2440839",
    "end": "2449119"
  },
  {
    "text": "was technology um because that's part of something that I wrote In The Prompt uh",
    "start": "2449119",
    "end": "2455160"
  },
  {
    "text": "it's really up to the AI to figure out what it actually needs P here sometimes you can actually tweak that thing uh you",
    "start": "2455160",
    "end": "2460240"
  },
  {
    "text": "know depending on how I describe the plugin um and then you know I get the",
    "start": "2460240",
    "end": "2466520"
  },
  {
    "text": "same results again so the next thing we would see here is actually another call",
    "start": "2466520",
    "end": "2471960"
  },
  {
    "text": "to oops to U um my uh my file plugin",
    "start": "2471960",
    "end": "2477960"
  },
  {
    "text": "which has a function called write and then it will pass me the the path of episode of text and then the whole",
    "start": "2477960",
    "end": "2483880"
  },
  {
    "text": "content so that's pretty cool it now can actually do things on my own you know local laptop but just by calling the",
    "start": "2483880",
    "end": "2489720"
  },
  {
    "text": "plugins the AI is still running in the cloud right in asro openi that's where the GPT mod is running but it just",
    "start": "2489720",
    "end": "2495760"
  },
  {
    "text": "stands for the for the an analytical part like the reasoning it figures out what needs to be done but I am actually",
    "start": "2495760",
    "end": "2501400"
  },
  {
    "text": "doing the calling running on my local machine now which obviously is what you will be doing within your your",
    "start": "2501400",
    "end": "2509200"
  },
  {
    "text": "company um so just to show you that that what I mentioned before that what you can do also is that sometimes maybe you",
    "start": "2509200",
    "end": "2517680"
  },
  {
    "text": "don't want to have this automatical invoke invocation so what you can do is actually I don't don't need to run this",
    "start": "2517680",
    "end": "2524000"
  },
  {
    "text": "but uh and it's a little bit more Cod here obviously but what I'm doing here I'm using just the enabl colel function",
    "start": "2524000",
    "end": "2531319"
  },
  {
    "text": "not the not the auto invoke uh so I'm selling I'm telling it to to figure out the function I need to call but don't",
    "start": "2531319",
    "end": "2537640"
  },
  {
    "text": "call it on my behalf and that means that instead I need to kind of loop through here so there's some cod here it's not",
    "start": "2537640",
    "end": "2544359"
  },
  {
    "text": "you know super interesting right now uh there's examples on the documentation site uh but the point is now I'm",
    "start": "2544359",
    "end": "2550680"
  },
  {
    "text": "actually invoking this myself I'm just running through the function calling it and and calling them and so what I can",
    "start": "2550680",
    "end": "2556400"
  },
  {
    "text": "do here obviously I can do a lot more you know validation uh I can ask user for for permission before doing things",
    "start": "2556400",
    "end": "2563200"
  },
  {
    "text": "because these plugins Now can do anything they could you know post stuff create stuff delete stuff and in some",
    "start": "2563200",
    "end": "2568319"
  },
  {
    "text": "cases you don't want that uh you know without the user actually clicking an approve button or something but in other",
    "start": "2568319",
    "end": "2574720"
  },
  {
    "text": "cases you do so this is another way of doing that you can actually call U kind",
    "start": "2574720",
    "end": "2580280"
  },
  {
    "text": "of the plugins yourself uh in a kind of generic way but still having the model decide when it needs to be",
    "start": "2580280",
    "end": "2587640"
  },
  {
    "text": "called so uh if we're combining these things now",
    "start": "2588319",
    "end": "2594079"
  },
  {
    "text": "uh we kind of have uh you know our co-pilot right uh we have the haven't really",
    "start": "2594079",
    "end": "2599720"
  },
  {
    "text": "looked at the system prompt we'll be doing that uh to the persona but we have the planners we have the chat history",
    "start": "2599720",
    "end": "2605599"
  },
  {
    "text": "and we have the plugins so if we combine these things we can you know can build for example a co-pilot application so as",
    "start": "2605599",
    "end": "2611720"
  },
  {
    "text": "an example of that uh I built that kind of as a demo started out as a demo",
    "start": "2611720",
    "end": "2617040"
  },
  {
    "text": "example internally but now we're actually using it more and more U because I also wanted to kind of show",
    "start": "2617040",
    "end": "2622400"
  },
  {
    "text": "this to our customers so they can realize that you know what you can do with this technology uh but with their own data so I built like a copilot for",
    "start": "2622400",
    "end": "2630359"
  },
  {
    "text": "my company active solution and I had it talking to our internal services so we're a consultancy company and",
    "start": "2630359",
    "end": "2637079"
  },
  {
    "text": "obviously we have some systems that are you know our own so we have things like time",
    "start": "2637079",
    "end": "2642640"
  },
  {
    "text": "reporting obviously that's a third party one uh we have a system for resource planning where we're you know planning",
    "start": "2642640",
    "end": "2648720"
  },
  {
    "text": "our assignments to say hey I'm working on on that customer next Wednesday on on that customer next Thursday that's",
    "start": "2648720",
    "end": "2655000"
  },
  {
    "text": "information that you know we're working with a lot uh we also have you know internal documents we have a you know",
    "start": "2655000",
    "end": "2661559"
  },
  {
    "text": "simple booking system for booking rooms and so on so these are system that we're using today and they all have their own UI so I thought that this would be a",
    "start": "2661559",
    "end": "2668599"
  },
  {
    "text": "good example of you know let's build a co-pilot instead let's use a chat interface and have it talk to these",
    "start": "2668599",
    "end": "2673920"
  },
  {
    "text": "systems so let me show you what what this looks like as an",
    "start": "2673920",
    "end": "2681160"
  },
  {
    "start": "2674000",
    "end": "3146000"
  },
  {
    "text": "example so so we have our own C- pilot here so this cop pilot. activ solution. you can't reach it uh well you can't log",
    "start": "2681440",
    "end": "2688920"
  },
  {
    "text": "in hopefully uh let's just switch to English Okay so and and again it's kind",
    "start": "2688920",
    "end": "2694680"
  },
  {
    "text": "of demo application so it has some you know rough edges and so on but it turned out to to be you know more and more use",
    "start": "2694680",
    "end": "2700480"
  },
  {
    "text": "useful actually so let me just uh do this so just down here then you can see",
    "start": "2700480",
    "end": "2706119"
  },
  {
    "text": "it actually lists all the plugins that I that I added to it so I have a few want this is the the payment system this is",
    "start": "2706119",
    "end": "2712720"
  },
  {
    "text": "the planning system the booking system and so on and we have some other stuff there I also have one called math and",
    "start": "2712720",
    "end": "2718520"
  },
  {
    "text": "one called time again math that comes back to the fact that you don't you never want the the language models to do",
    "start": "2718520",
    "end": "2724200"
  },
  {
    "text": "math so if I ask you to do some kind of summarization and so on it shouldn't it should call that plugin also it doesn't",
    "start": "2724200",
    "end": "2731040"
  },
  {
    "text": "know what time it is right the model has no idea what what time it is right now and a lot of these questions typically",
    "start": "2731040",
    "end": "2736960"
  },
  {
    "text": "relate to you know today or tomorrow and so on so in actually to figure it out it",
    "start": "2736960",
    "end": "2742800"
  },
  {
    "text": "actually needs to fetch the time um so I think the first one I did we have you know one called Shelly here",
    "start": "2742800",
    "end": "2749839"
  },
  {
    "text": "so Shelly is actually an kind of a cloud API that you can hook up sensors to so we have a few temperature sensors at",
    "start": "2749839",
    "end": "2755960"
  },
  {
    "text": "office that you know send the temperature and you can you can view a dashboard but you can also use the API",
    "start": "2755960",
    "end": "2761839"
  },
  {
    "text": "that was just the first one that I tried it so let's just use that first as an example so now what I can do I can say",
    "start": "2761839",
    "end": "2768319"
  },
  {
    "text": "you know how uh how hot is it at the office",
    "start": "2768319",
    "end": "2773559"
  },
  {
    "text": "today like that and let's see what it",
    "start": "2773559",
    "end": "2778640"
  },
  {
    "text": "answers so it answers back okay here are the current temperature at the office uh so we have four of those sensors in four",
    "start": "2778640",
    "end": "2784000"
  },
  {
    "text": "different rooms so you know typically one of them is is a a bit hotter so it's 23.6 so it seems to be quite good",
    "start": "2784000",
    "end": "2790240"
  },
  {
    "text": "weather back home in Stockholm uh so again it gave me the the the temperature there and uh just can enable this little",
    "start": "2790240",
    "end": "2799520"
  },
  {
    "text": "U window that shows kind of under the hood what actually happened here so in this case I have a plugin called Shelly",
    "start": "2799520",
    "end": "2805319"
  },
  {
    "text": "and that one has two methods uh so the first one will list all the sensors the other one will give",
    "start": "2805319",
    "end": "2811520"
  },
  {
    "text": "the temperature for a given sensor that's all it knows that I have so what it does is that if figures out okay",
    "start": "2811520",
    "end": "2817440"
  },
  {
    "text": "first I need to figure out what sensors exists so it calls that one and then for each of those sensors it calls it to you",
    "start": "2817440",
    "end": "2824119"
  },
  {
    "text": "know to get the temperature now if I would have a function or a plugin that actually took a list in it would call",
    "start": "2824119",
    "end": "2830839"
  },
  {
    "text": "that one because it would be smarter but in this case I just have one you know a method that accepts one of these",
    "start": "2830839",
    "end": "2837359"
  },
  {
    "text": "sensors um and then I can see like what it actually responded here so for f then",
    "start": "2837359",
    "end": "2843240"
  },
  {
    "text": "if I now say you know what is the average temperature",
    "start": "2843240",
    "end": "2848319"
  },
  {
    "text": "what should it do then can someone",
    "start": "2848319",
    "end": "2853720"
  },
  {
    "text": "suggest yeah exactly that's what I want to do I",
    "start": "2856559",
    "end": "2862480"
  },
  {
    "text": "want to call the math plug I don't want this now to just try to solve this math problem it's not super complex but it",
    "start": "2862480",
    "end": "2867599"
  },
  {
    "text": "would probably not get it right another interesting part now is uh",
    "start": "2867599",
    "end": "2872760"
  },
  {
    "text": "so it needs to know the temperature so do you think it's going to call the the the plugin again the shell plug plug in",
    "start": "2872760",
    "end": "2877839"
  },
  {
    "text": "and why not exactly it al already has the temperature now in the history so let's",
    "start": "2877839",
    "end": "2883440"
  },
  {
    "text": "try this out see what happens so it's hopefully it's going to reply back",
    "start": "2883440",
    "end": "2890720"
  },
  {
    "text": "with crash that was where this has never crashed before okay that's very strange it",
    "start": "2890880",
    "end": "2896720"
  },
  {
    "text": "actually gave me the the right answer here I'm not sure why it didn't okay never mind it actually did two calls to",
    "start": "2896720",
    "end": "2903440"
  },
  {
    "text": "the math play first we didn't call the Shelly again because it all had numbers it called the summarize uh method on the math plugin",
    "start": "2903440",
    "end": "2910319"
  },
  {
    "text": "so it passed the numbers and that Returns the number and then it's called divide because it you know needs to do",
    "start": "2910319",
    "end": "2916359"
  },
  {
    "text": "the the average right and for some reason it crashed here uh but either way",
    "start": "2916359",
    "end": "2922800"
  },
  {
    "text": "you can see like the response here so 22275 now if I would have you know let's",
    "start": "2922800",
    "end": "2928680"
  },
  {
    "text": "do that query again but like clearing the chat and say what's the average temperature at the office obvious",
    "start": "2928680",
    "end": "2934920"
  },
  {
    "text": "obviously now it's going to call the plugin again because now I cleared the history so it doesn't know any anymore what the temperature",
    "start": "2934920",
    "end": "2941000"
  },
  {
    "text": "is so and now for some reason now it you know replies back and say average temperature at the office is approximately 22.3 de okay so that's",
    "start": "2941000",
    "end": "2948880"
  },
  {
    "text": "that's a fun example not really useful but that was the first one that I did so what's more interesting now is uh uh",
    "start": "2948880",
    "end": "2956359"
  },
  {
    "text": "what I would typically want to know like okay what's my plan for for the week for example so if I let's just ass that",
    "start": "2956359",
    "end": "2962200"
  },
  {
    "text": "what's my plan for the week",
    "start": "2962200",
    "end": "2967160"
  },
  {
    "text": "uh so now it's figuring out it's I seem to be asking something about my resource planning so I should probably call the resource system uh the the API the",
    "start": "2967880",
    "end": "2975680"
  },
  {
    "text": "active planning one and now it replies back with the the plan for me this week uh so it says on Monday I worked on a",
    "start": "2975680",
    "end": "2982160"
  },
  {
    "text": "Microsoft project uh Tuesday I worked for the customer Kia Wednesday Thursday and Friday I'm assigned to the UT",
    "start": "2982160",
    "end": "2988599"
  },
  {
    "text": "building tall which means I'm doing like speaker engagements in this case I'm at NDC Oslo so so this is my plan for the",
    "start": "2988599",
    "end": "2995400"
  },
  {
    "text": "week so it's fetching live dat now about my plan uh so it's actually starting to be",
    "start": "2995400",
    "end": "3000920"
  },
  {
    "text": "more and more useful in the way and I can also also talk to this you know use the microphone and just talk to it uh",
    "start": "3000920",
    "end": "3006559"
  },
  {
    "text": "it's quite interesting to see how it changes the behavior but what's really interesting now I think is because we",
    "start": "3006559",
    "end": "3011960"
  },
  {
    "text": "have uis for this right we can go to this UI and fetch the information but it's really interesting when you start",
    "start": "3011960",
    "end": "3017640"
  },
  {
    "text": "combining these things in the same query so let's do kind of a more advanced one",
    "start": "3017640",
    "end": "3023920"
  },
  {
    "text": "so first one I can just say like because we also hooked it up to the to the booking system where all the rooms can",
    "start": "3023920",
    "end": "3029440"
  },
  {
    "text": "be booked so I just say say show show me all the",
    "start": "3029440",
    "end": "3036200"
  },
  {
    "text": "rooms okay so it's going to list uh okay so it's going to list me uh all the the",
    "start": "3036200",
    "end": "3043240"
  },
  {
    "text": "the rooms we have at the office and so on so we have that as well uh but now",
    "start": "3043240",
    "end": "3048720"
  },
  {
    "text": "let's say if I do this and uh find a or let's do it like this uh",
    "start": "3048720",
    "end": "3055599"
  },
  {
    "text": "book a room at uh 5:00 p.m. that is large enough for",
    "start": "3055599",
    "end": "3064119"
  },
  {
    "text": "everyone that works with L one of our customers so now it's like a multipart",
    "start": "3064119",
    "end": "3071920"
  },
  {
    "text": "query here because it needs to know fetchy information from multiple systens now to actually be able to do this so",
    "start": "3071920",
    "end": "3077760"
  },
  {
    "text": "let's see what it does you can never there's no 100% guarantee that this works so also always interesting with",
    "start": "3077760",
    "end": "3083000"
  },
  {
    "text": "the demos but I'm now using the the latest gp4 model the Omni one which is actually really really good and also a",
    "start": "3083000",
    "end": "3089799"
  },
  {
    "text": "lot faster than than the old gb4 so let's see what it says so first",
    "start": "3089799",
    "end": "3095200"
  },
  {
    "text": "up it list the employees we have four people at our company that works with this customer helan evaran and fck so",
    "start": "3095200",
    "end": "3102040"
  },
  {
    "text": "said so we need a room that can accommodate at least four people available rooms that meet the capacity requirements we list then the rooms uh",
    "start": "3102040",
    "end": "3108160"
  },
  {
    "text": "that is large enough for those four people and then it asks me you know okay should I book this",
    "start": "3108160",
    "end": "3114160"
  },
  {
    "text": "room yes book Surin I don't think anybody needs that",
    "start": "3114160",
    "end": "3121200"
  },
  {
    "text": "room today at Friday Friday at 5m and now it actually does just to confirm do you want to book the room",
    "start": "3121200",
    "end": "3129799"
  },
  {
    "text": "yes ah okay um maybe it understand yeah okay so",
    "start": "3129799",
    "end": "3135839"
  },
  {
    "text": "now actually booked you can see that actually called uh the book room uh method that",
    "start": "3135839",
    "end": "3142640"
  },
  {
    "text": "in turns actually did a booking request for that room uh and just to show you if I quickly",
    "start": "3142640",
    "end": "3149079"
  },
  {
    "start": "3146000",
    "end": "3243000"
  },
  {
    "text": "show you that plugin uh called um active",
    "start": "3149079",
    "end": "3155880"
  },
  {
    "text": "booking just one detail here uh here we have that function that",
    "start": "3155880",
    "end": "3161480"
  },
  {
    "text": "it called and what I want to show you is the description here it says book a room",
    "start": "3161480",
    "end": "3167839"
  },
  {
    "text": "and then I'm also saying here always ask user for confirmation before calling this function so you can kind of also",
    "start": "3167839",
    "end": "3172960"
  },
  {
    "text": "combine like instructions and so on because this will just be part of the big prompt here and that is why it",
    "start": "3172960",
    "end": "3178119"
  },
  {
    "text": "actually did that extra confirmation now you probably in some cases you want to have that extra layer of security that I",
    "start": "3178119",
    "end": "3183960"
  },
  {
    "text": "talked about before maybe do like explicit approval by the user from your application but you can also use like",
    "start": "3183960",
    "end": "3190240"
  },
  {
    "text": "the The Prompt techniques to kind of steer it the right way and in many cases that could actually be",
    "start": "3190240",
    "end": "3196440"
  },
  {
    "text": "enough sorry no no you can't you can't trust",
    "start": "3200280",
    "end": "3207240"
  },
  {
    "text": "you can't trust anything with with the language models to be honest uh that is just the fact uh that it will not and",
    "start": "3207240",
    "end": "3214200"
  },
  {
    "text": "it's not deterministic also so if there are things that that that you you you",
    "start": "3214200",
    "end": "3219680"
  },
  {
    "text": "want to make sure 100% that it's correct or validate before it call it you need to actually Implement that yourself and",
    "start": "3219680",
    "end": "3225640"
  },
  {
    "text": "not just trust the prompt in like 99% of the cases it will be fine but maybe not every hundreds so that that that is the",
    "start": "3225640",
    "end": "3233680"
  },
  {
    "text": "tricky part of trying to like steer the the moving elephant on top like it's so",
    "start": "3233680",
    "end": "3238920"
  },
  {
    "text": "powerful but you have to kind of trying to control it so let me just",
    "start": "3238920",
    "end": "3245400"
  },
  {
    "start": "3243000",
    "end": "3379000"
  },
  {
    "text": "uh uh for the final thing so that was kind of a co-pilot application again",
    "start": "3245400",
    "end": "3250440"
  },
  {
    "text": "this is now a separate application but you can also see this being part of like those application itself like sidebars",
    "start": "3250440",
    "end": "3257200"
  },
  {
    "text": "so I could actually do like a sidebar to our own systems uh to have a chat interface and kind of build",
    "start": "3257200",
    "end": "3262400"
  },
  {
    "text": "functionality that way um so some of the complexity around this will",
    "start": "3262400",
    "end": "3268400"
  },
  {
    "text": "be that eventually I already I have quite a lot of plugins there and there are some problems with that the first",
    "start": "3268400",
    "end": "3275440"
  },
  {
    "text": "one is that I'm passing a lot of information every time now I'm passing all those function definitions every",
    "start": "3275440",
    "end": "3280599"
  },
  {
    "text": "time to the model uh saying I have this plugin I have this plugin that plugin that would you know uh take time but",
    "start": "3280599",
    "end": "3287920"
  },
  {
    "text": "most importantly it will also cost me money actually uh and also it will be harder for the model to actually pick",
    "start": "3287920",
    "end": "3293839"
  },
  {
    "text": "the right one sometimes these plugins will overlap a bit like we we will have things like customer for example will be",
    "start": "3293839",
    "end": "3301119"
  },
  {
    "text": "appear in many of these plugins because all these systems referring to customers for example or project uh then can be a",
    "start": "3301119",
    "end": "3307359"
  },
  {
    "text": "little bit tricky so uh if you're thinking more in in an agent approach uh",
    "start": "3307359",
    "end": "3313160"
  },
  {
    "text": "what you'll be doing instead of kind of having like this big big thing with a lot of plugins and trying to solve",
    "start": "3313160",
    "end": "3318960"
  },
  {
    "text": "everything with the common system prompt you can kind of think like you're breaking this up kind of like a",
    "start": "3318960",
    "end": "3324200"
  },
  {
    "text": "microservices analogy like you take the big system and break it down into smaller things and that that thing is",
    "start": "3324200",
    "end": "3330319"
  },
  {
    "text": "often called as like an agent uh which will typically be smaller and much more scoped to specific task uh so in this",
    "start": "3330319",
    "end": "3337359"
  },
  {
    "text": "case the Persona will be really important because the Persona will kind of Define what the purpose and the behavior of that particular agent is so",
    "start": "3337359",
    "end": "3344319"
  },
  {
    "text": "you have instead of having one big co-pilot you'll have a lot of small co- Pilots running around like small children uh and then typically they you",
    "start": "3344319",
    "end": "3351640"
  },
  {
    "text": "know they want to talk to each other to actually solve the problem uh and and",
    "start": "3351640",
    "end": "3356720"
  },
  {
    "text": "this there are many patterns that you can do this and this will be like a whole talk in itself you know how you can build systems in in an agent fashion",
    "start": "3356720",
    "end": "3364200"
  },
  {
    "text": "um there's many approaches and this is really like an area of of active investigation and experimentation uh",
    "start": "3364200",
    "end": "3370039"
  },
  {
    "text": "this is not something we're doing yet with the customers but it is like a really interesting area of U of research",
    "start": "3370039",
    "end": "3376359"
  },
  {
    "text": "and and like possibilities here what you can do with it so I just want to end with a an example of how you can",
    "start": "3376359",
    "end": "3381720"
  },
  {
    "start": "3379000",
    "end": "3599000"
  },
  {
    "text": "actually implement this with semantic kernel because they are also working on that uh and they're doing M multiple",
    "start": "3381720",
    "end": "3388160"
  },
  {
    "text": "kind of implementations of this so I just want to show you one simple example and hopefully you'll kind of get the",
    "start": "3388160",
    "end": "3393920"
  },
  {
    "text": "idea then um so in this case I'm uh",
    "start": "3393920",
    "end": "3399000"
  },
  {
    "text": "setting up two two agents uh so let me just show you the code down here",
    "start": "3399000",
    "end": "3405119"
  },
  {
    "text": "first um here so I'm I I have two agents uh one is the",
    "start": "3405119",
    "end": "3414599"
  },
  {
    "text": "software developer Persona and one the other one is the conference organizer",
    "start": "3414599",
    "end": "3420559"
  },
  {
    "text": "Persona uh and you can see when I'm creating it I'm passing it like the instructions that's the Persona The Meta",
    "start": "3420559",
    "end": "3426359"
  },
  {
    "text": "prompt I'll show you that later I'll give it a name and I also give it a kernel uh so again the kernel could be",
    "start": "3426359",
    "end": "3432599"
  },
  {
    "text": "different here I could you know use different models for different agents um so once I have those two",
    "start": "3432599",
    "end": "3438160"
  },
  {
    "text": "agents uh then I will in this case I will create a group chat with them so",
    "start": "3438160",
    "end": "3444480"
  },
  {
    "text": "I'm creating a group chat uh by adding these two agents and then interestingly",
    "start": "3444480",
    "end": "3449920"
  },
  {
    "text": "enough I'm also having this settings and as part of that settings I have a something called a termination strategy",
    "start": "3449920",
    "end": "3455599"
  },
  {
    "text": "because the thing is once I you know unleash these agents into the wild and they start you know talking to each other you know when should they quit",
    "start": "3455599",
    "end": "3462440"
  },
  {
    "text": "what is like the the end when should they terminate that's an interesting question and quite important to get",
    "start": "3462440",
    "end": "3468000"
  },
  {
    "text": "right uh so in this case I'm actually passing it uh like my own implementation of that so this is actually a",
    "start": "3468000",
    "end": "3475000"
  },
  {
    "text": "clause uh um that is down here so uh and",
    "start": "3475000",
    "end": "3481359"
  },
  {
    "text": "so this is a very simple implementation but what it does in this case it will just look at the last message and see if",
    "start": "3481359",
    "end": "3486440"
  },
  {
    "text": "that message equals looks good to me uh it should end and the reason why that is",
    "start": "3486440",
    "end": "3491599"
  },
  {
    "text": "is really up to these prompts so let's just take a quick look before I run this",
    "start": "3491599",
    "end": "3497240"
  },
  {
    "text": "so again the purpose here is to write an abstract for this conference that was like my My Demo example here so the",
    "start": "3497240",
    "end": "3503680"
  },
  {
    "text": "first one is let's look at the software developer so it says like you're a software developer uh you love to share",
    "start": "3503680",
    "end": "3509680"
  },
  {
    "text": "your knowledge blah blah blah your goal is to write and refine a proposal for the NC also developer conference so the",
    "start": "3509680",
    "end": "3515920"
  },
  {
    "text": "purpose of this agent is to write a a proposal for a conference talk and I'm giving it some kind of the structure it",
    "start": "3515920",
    "end": "3521640"
  },
  {
    "text": "should use uh some you know some guidance also telling it that you will be getting like suggestions on how you",
    "start": "3521640",
    "end": "3527440"
  },
  {
    "text": "can refine your idea just and says it's only Implement one suggested Improvement",
    "start": "3527440",
    "end": "3532760"
  },
  {
    "text": "at a time so that's a developer Persona and then we have the conference organizer",
    "start": "3532760",
    "end": "3539000"
  },
  {
    "text": "Persona so that will have another instruction here so you're part of the of the team your goal is you know to",
    "start": "3539000",
    "end": "3544599"
  },
  {
    "text": "actually evaluate sessions I'm giving it some guidelines on how it should evaluate the proposal you know it should",
    "start": "3544599",
    "end": "3549760"
  },
  {
    "text": "be relevant it should be clear and I'm also giving it some kind of fake uh instructions here just to kind of prove",
    "start": "3549760",
    "end": "3556119"
  },
  {
    "text": "the point I'm telling it that proposal can't be longer than 100 Words and it has to contain the term AI",
    "start": "3556119",
    "end": "3562839"
  },
  {
    "text": "overlords uh and and the reason is that because this will create a long s session here uh only suggest one",
    "start": "3562839",
    "end": "3569640"
  },
  {
    "text": "required or suggested Improvement at a time so let's run this and see what",
    "start": "3569640",
    "end": "3576798"
  },
  {
    "text": "happens uh that's okay so clear and net",
    "start": "3579920",
    "end": "3586559"
  },
  {
    "text": "run again you you never know what's going to end up when you run these things so that's Al always interesting",
    "start": "3586559",
    "end": "3592599"
  },
  {
    "text": "so now I'm also starting this I forgot to show that but I'm starting the conversation with like write The",
    "start": "3592599",
    "end": "3598319"
  },
  {
    "text": "Proposal with the following topic developing AI agents with semantic kernel that's my session now so that",
    "start": "3598319",
    "end": "3604079"
  },
  {
    "text": "kind of starting the conversation by that and then I'm passing it the agents and now they're going to start working here so what what should happen now is",
    "start": "3604079",
    "end": "3611280"
  },
  {
    "text": "that that the developer uh should pick this up and you know produce an abstract",
    "start": "3611280",
    "end": "3617000"
  },
  {
    "text": "here so it has an abstract an outline a lot of stuff here about semantic Kel and so on key takeaways and so on and okay",
    "start": "3617000",
    "end": "3624880"
  },
  {
    "text": "that was kind of depressing okay let's try it",
    "start": "3624880",
    "end": "3630559"
  },
  {
    "text": "again because that wasn't good it should be like a conversational",
    "start": "3630559",
    "end": "3636119"
  },
  {
    "text": "session here uh because typically it won't include things like AI overlords and",
    "start": "3636119",
    "end": "3642039"
  },
  {
    "text": "typically it's longer than 100 characters okay so now it works a little",
    "start": "3642039",
    "end": "3647520"
  },
  {
    "text": "bit better I think so okay again I get the proposal here and then the organizer now chips in and says that okay the",
    "start": "3647520",
    "end": "3654280"
  },
  {
    "text": "proposal is clear engaging IR relevant however it is longer than the 100w limit please revise it to meet the word count",
    "start": "3654280",
    "end": "3660559"
  },
  {
    "text": "requirement so then the developer gets you know sees that and creates a new",
    "start": "3660559",
    "end": "3665839"
  },
  {
    "text": "proposal and then uh let's see the organizer say it's still beyond the 100w abct limit and",
    "start": "3665839",
    "end": "3672440"
  },
  {
    "text": "does not mention AI overlords please include this term then it then yeah exactly passive aggressive and then it",
    "start": "3672440",
    "end": "3678960"
  },
  {
    "text": "tries again and let's see if it has AI overlords somewhere yep here we have it AI",
    "start": "3678960",
    "end": "3685039"
  },
  {
    "text": "overlords and uh yeah maybe it's below 100 words I'm not sure but now it says looks good",
    "start": "3685039",
    "end": "3691559"
  },
  {
    "text": "to me and that kind of terminates the session and actually terminates this session as well because I'm out of time",
    "start": "3691559",
    "end": "3698240"
  },
  {
    "text": "so uh thanks a lot for for attending the session and hopefully you'll be going home and building your own co- pallets",
    "start": "3698240",
    "end": "3703559"
  },
  {
    "text": "thank you",
    "start": "3703559",
    "end": "3706720"
  }
]
[
  {
    "start": "0",
    "end": "44000"
  },
  {
    "text": "all right good afternoon everybody welcome to the last session of the day thanks to thanks for coming to my talk",
    "start": "2129",
    "end": "9309"
  },
  {
    "text": "so today I just before I get started I just want to dispel any rumors that I'm",
    "start": "9309",
    "end": "14500"
  },
  {
    "text": "any kind of distributed systems expert I'm not what I'm going to tell you today",
    "start": "14500",
    "end": "21339"
  },
  {
    "text": "is more of a story about how we did a cadet net into production and how many times we failed as well as how we failed",
    "start": "21339",
    "end": "30039"
  },
  {
    "text": "ourselves into actually making two or three million more dollars than we did when we didn't actually have a connect",
    "start": "30039",
    "end": "35949"
  },
  {
    "text": "so and all the stuff is in retrospect so forgive me if there's a few little",
    "start": "35949",
    "end": "42519"
  },
  {
    "text": "detail that I might have missed so let's start from the beginning so I am",
    "start": "42519",
    "end": "50530"
  },
  {
    "start": "44000",
    "end": "500000"
  },
  {
    "text": "actually from Australia forgive the American accent and I work for a company",
    "start": "50530",
    "end": "58210"
  },
  {
    "text": "called domain and domain is responsible for both commercial and residential",
    "start": "58210",
    "end": "64378"
  },
  {
    "text": "property on their website so that's everything from renting from buying and",
    "start": "64379",
    "end": "71440"
  },
  {
    "text": "selling anything to do with real estate so one of the problems that we had when",
    "start": "71440",
    "end": "79120"
  },
  {
    "text": "we first did this is that domain had a massive problem with clickstream rental",
    "start": "79120",
    "end": "85330"
  },
  {
    "text": "in exit does anybody know it could stream analytics is well yeah there's like one person but if you don't know",
    "start": "85330",
    "end": "91960"
  },
  {
    "text": "what clickstream analytics is it's it's like google analytics we want to know",
    "start": "91960",
    "end": "98440"
  },
  {
    "text": "what our users are actually doing on our website so when you whenever you go on a",
    "start": "98440",
    "end": "104200"
  },
  {
    "text": "site like eBay or you click on something or you send an inquiry that says hey I'm",
    "start": "104200",
    "end": "110110"
  },
  {
    "text": "interested in this product eBay actually tracks what you do in the same way Google does for us we had a system that",
    "start": "110110",
    "end": "118710"
  },
  {
    "text": "did this but it didn't really quite",
    "start": "118710",
    "end": "123820"
  },
  {
    "text": "scale to what we wanted it to do in fact it was losing messages and it was making",
    "start": "123820",
    "end": "131530"
  },
  {
    "text": "us look very very bad because there's no way we could track or not it was doing what it was supposed",
    "start": "131530",
    "end": "137320"
  },
  {
    "text": "to do the setup was art I mean it was",
    "start": "137320",
    "end": "142990"
  },
  {
    "text": "modern for 2005 the problem was it was getting along in the tooth because we",
    "start": "142990",
    "end": "148600"
  },
  {
    "text": "had a system that was basically running on sequel server our scale was back in",
    "start": "148600",
    "end": "154540"
  },
  {
    "text": "2005 2007 if we didn't have that many users though but when you fast forward",
    "start": "154540",
    "end": "159790"
  },
  {
    "text": "to today when we have several million users hitting the site and with quick",
    "start": "159790",
    "end": "164950"
  },
  {
    "text": "streaming events one of the things that we use it for is the ability to track",
    "start": "164950",
    "end": "172650"
  },
  {
    "text": "whether or not the features that we push into production are effective or not our",
    "start": "172650",
    "end": "179290"
  },
  {
    "text": "product team also uses the metrics to determine whether the things we feature",
    "start": "179290",
    "end": "184480"
  },
  {
    "text": "flag are things that we should keep so for example we feature flag things of 20",
    "start": "184480",
    "end": "191350"
  },
  {
    "text": "30 40 % if we find that the metrics are very low we wrap it down and if things",
    "start": "191350",
    "end": "199690"
  },
  {
    "text": "get better we wrap it up unfortunately with this kind of system it wasn't scaling because we had sequel server we",
    "start": "199690",
    "end": "206470"
  },
  {
    "text": "had reporting services it didn't really",
    "start": "206470",
    "end": "211560"
  },
  {
    "text": "do much at this point and it wasn't reliable there's quite a few things that we needed to solve so the first thing",
    "start": "211560",
    "end": "218410"
  },
  {
    "text": "that we needed to fix is that we have a system that kept going down it there are",
    "start": "218410",
    "end": "229239"
  },
  {
    "text": "times where this is there's quite a few outages at the same time in terms of traceability if you did 100 clicks or we",
    "start": "229239",
    "end": "238570"
  },
  {
    "text": "had a thousand clicks on the website there's no way to actually reverse engineer or audit it and figure out",
    "start": "238570",
    "end": "245230"
  },
  {
    "text": "whether or not these numbers actually add up to that at the same time speed",
    "start": "245230",
    "end": "252670"
  },
  {
    "text": "with a massive problem because we'd have something that would take an entire day to calculate especially when we had",
    "start": "252670",
    "end": "260739"
  },
  {
    "text": "hundreds of thousands of users per week hitting our site at any given time the",
    "start": "260739",
    "end": "267010"
  },
  {
    "text": "last one is really around accuracy and the problem there is that without that",
    "start": "267010",
    "end": "273310"
  },
  {
    "text": "kind of granularity that we would expect by capturing all the events we basically",
    "start": "273310",
    "end": "280450"
  },
  {
    "text": "didn't have much to work with obviously scaling was a big issue",
    "start": "280450",
    "end": "285730"
  },
  {
    "text": "because when we were using sequel server we were relying on one server to do all the aggregations and as I said it would",
    "start": "285730",
    "end": "293800"
  },
  {
    "text": "been flying like 10 years ago but when our traffic doubles are even triples being able to calculate this as fast as",
    "start": "293800",
    "end": "301600"
  },
  {
    "text": "it comes in is all but impossible so that's for it a little bit too two or",
    "start": "301600",
    "end": "309970"
  },
  {
    "text": "three years ago when we moved into Amazon Web Services we had all of a",
    "start": "309970",
    "end": "318970"
  },
  {
    "text": "sudden a brand new set of two we had a whole bunch of toys to play with because",
    "start": "318970",
    "end": "325270"
  },
  {
    "text": "now we can have infrastructure on the cheap it was easy for us to add new",
    "start": "325270",
    "end": "330580"
  },
  {
    "text": "servers but the problem was we didn't we didn't know what to do with it at the",
    "start": "330580",
    "end": "336370"
  },
  {
    "text": "time so at the same time we started playing around with actor systems like a",
    "start": "336370",
    "end": "341980"
  },
  {
    "text": "canet now for domain we are primarily a node and a dotnet shop so we went with a",
    "start": "341980",
    "end": "350110"
  },
  {
    "text": "canet of course if you're you have preferences for other systems we could",
    "start": "350110",
    "end": "355240"
  },
  {
    "text": "go with Orleans or the JVM akka but what I'm going to talk about today is not",
    "start": "355240",
    "end": "360880"
  },
  {
    "text": "really specific to just a canet it's going to cover a lot of the high-level",
    "start": "360880",
    "end": "366520"
  },
  {
    "text": "concepts and you should be able to apply it to any actor system maybe except Orleans because they don't have these",
    "start": "366520",
    "end": "372430"
  },
  {
    "text": "state machines unless you make it in now the idea that we came up with is quite",
    "start": "372430",
    "end": "378520"
  },
  {
    "text": "simple so previously we had a job that",
    "start": "378520",
    "end": "383650"
  },
  {
    "text": "would take several hours to process an entire days worth of quick stream events",
    "start": "383650",
    "end": "389700"
  },
  {
    "text": "but what if we had some way to cut the",
    "start": "389700",
    "end": "394960"
  },
  {
    "text": "jobs down into 86,400 jobs a day that would take",
    "start": "394960",
    "end": "400849"
  },
  {
    "text": "one second or basically the equivalent of one job per second for the entire day",
    "start": "400849",
    "end": "407539"
  },
  {
    "text": "and that's where Apple was born I mean we thought Hayley we'd solved our problem because now we've got all this",
    "start": "407539",
    "end": "414459"
  },
  {
    "text": "these actor systems that can do all these parallel computations and and everything would be okay but the truth",
    "start": "414459",
    "end": "421069"
  },
  {
    "text": "was we were wrong we were wrong because we didn't actually consider how do you",
    "start": "421069",
    "end": "428209"
  },
  {
    "text": "deal with state how do you deal with capture and how do you deal with consistency how do you make sure that",
    "start": "428209",
    "end": "435319"
  },
  {
    "text": "you don't run into any inconsistencies especially when we're in a business where we need to be able to sell online",
    "start": "435319",
    "end": "444039"
  },
  {
    "text": "ad space by saying that we get this much traffic so it was a challenge for us",
    "start": "444039",
    "end": "451909"
  },
  {
    "text": "because when we first presented this to the management they said well we're",
    "start": "451909",
    "end": "457669"
  },
  {
    "text": "quite happy with just getting a reports once per day but the way we sold it was",
    "start": "457669",
    "end": "463809"
  },
  {
    "text": "we have a competitive advantage over everybody else because when we publish",
    "start": "463809",
    "end": "470389"
  },
  {
    "text": "articles on our website we can tell immediately whether or not it has enough",
    "start": "470389",
    "end": "476209"
  },
  {
    "text": "effect on a particular property whereas a batch system you'd have to wait until",
    "start": "476209",
    "end": "483289"
  },
  {
    "text": "the next day and all you have is probably like one spike in a bar graph we could break it down by hour and that",
    "start": "483289",
    "end": "490009"
  },
  {
    "text": "was a huge advantage for us because we can do all these things in real time that you can't do if you just went with",
    "start": "490009",
    "end": "496490"
  },
  {
    "text": "sequel server and super server reporting services but before I get into the",
    "start": "496490",
    "end": "502819"
  },
  {
    "text": "details of how we actually did it I want to talk a little bit about theory I'm",
    "start": "502819",
    "end": "508459"
  },
  {
    "text": "sure everybody is familiar with with strong eventual consistency but just",
    "start": "508459",
    "end": "514310"
  },
  {
    "text": "from sake of completeness I'm going to go over it so the idea behind strong eventual consistency is that you have",
    "start": "514310",
    "end": "522860"
  },
  {
    "text": "more than one set of nodes they'll get eventually get the same set of updates",
    "start": "522860",
    "end": "528740"
  },
  {
    "text": "so you can guarantee that they all get them at the same time but with strong eventual consistency",
    "start": "528740",
    "end": "534300"
  },
  {
    "text": "ideas is that it doesn't matter what order you get them as long as we get all",
    "start": "534300",
    "end": "539730"
  },
  {
    "text": "the pieces then everything's going to be okay and they'll both come to the same conclusion now for eventual consistency",
    "start": "539730",
    "end": "548279"
  },
  {
    "start": "545000",
    "end": "578000"
  },
  {
    "text": "or what I like to call weak consistency that's a bit more tricky because you have to make sure that the pieces of the",
    "start": "548279",
    "end": "555810"
  },
  {
    "text": "puzzle all come in the same order otherwise you might get some strange side effects for example if you're",
    "start": "555810",
    "end": "562170"
  },
  {
    "text": "editing a document and you've got two people editing the same doc if the order of somebody typing something is",
    "start": "562170",
    "end": "569220"
  },
  {
    "text": "different from the other person then you're going to have a lot of inconsistencies fortunately for us we",
    "start": "569220",
    "end": "575070"
  },
  {
    "text": "didn't really run into this scenario and I'll get to that in a second now I tried",
    "start": "575070",
    "end": "580529"
  },
  {
    "start": "578000",
    "end": "623000"
  },
  {
    "text": "to explain this to one of my junior devs once and the best way I could just describe it is the XP analogy so being",
    "start": "580529",
    "end": "587040"
  },
  {
    "text": "in Scandinavia I don't have to ask you guys how many times you've been to Ikea but the idea is that I should take two",
    "start": "587040",
    "end": "595050"
  },
  {
    "text": "people who don't know each other at all probably won't even talk to each other as long as they have all the pieces they",
    "start": "595050",
    "end": "600750"
  },
  {
    "text": "have they need to assemble the same piece of furniture and the same instructions to do it no matter most of",
    "start": "600750",
    "end": "608190"
  },
  {
    "text": "the time as long as they have all the pieces in long they have the same set of instructions they'll be able to come up",
    "start": "608190",
    "end": "613829"
  },
  {
    "text": "with the same conclusion independently of each other and our system was built",
    "start": "613829",
    "end": "620670"
  },
  {
    "text": "on this simple principle when we have that kind of scenario where we have a",
    "start": "620670",
    "end": "629010"
  },
  {
    "start": "623000",
    "end": "645000"
  },
  {
    "text": "consistent algorithm and we can guarantee that all the pieces make it to all the nodes then all of a sudden it",
    "start": "629010",
    "end": "635910"
  },
  {
    "text": "simplifies things the other thing I'll get into later is that our system is immutable so you don't have to worry",
    "start": "635910",
    "end": "642630"
  },
  {
    "text": "about syncing deletes and hindsight what",
    "start": "642630",
    "end": "649290"
  },
  {
    "start": "645000",
    "end": "680000"
  },
  {
    "text": "we didn't realize at the time is that we were implementing something called conflict-free replicated data types now",
    "start": "649290",
    "end": "656820"
  },
  {
    "text": "it's just a fancy way of saying if you follow these sets of rules you will",
    "start": "656820",
    "end": "662730"
  },
  {
    "text": "always be consistent now there's some talks out there that have said that see our DTS are just",
    "start": "662730",
    "end": "667970"
  },
  {
    "text": "types but what we found in practice with stuff in the cloud is that it doesn't",
    "start": "667970",
    "end": "673609"
  },
  {
    "text": "necessarily have to be like a code data type it's more of a pattern that you can",
    "start": "673609",
    "end": "678949"
  },
  {
    "text": "implement now as far as cap goes in the",
    "start": "678949",
    "end": "684649"
  },
  {
    "start": "680000",
    "end": "758000"
  },
  {
    "text": "previous scenarios what we were doing was we were running with a sequel server where we had strong immediate",
    "start": "684649",
    "end": "690259"
  },
  {
    "text": "consistency the problem with that is that we didn't need that we were willing",
    "start": "690259",
    "end": "697759"
  },
  {
    "text": "to trade that strong immediate consistency for the ability to scale up",
    "start": "697759",
    "end": "703489"
  },
  {
    "text": "and have these computations done in parallel unfortunately you can't really do that with sequel server without having them maintain the nasty store",
    "start": "703489",
    "end": "709939"
  },
  {
    "text": "proc which is what a lot of our des were doing and that wasn't really helping us as you can see here with the cap theorem",
    "start": "709939",
    "end": "718569"
  },
  {
    "text": "if you're not familiar with cap theorem it basically says that you could choose partitioning availability or consistency",
    "start": "718569",
    "end": "725179"
  },
  {
    "text": "but that dot right in the middle here is impossible you can never have it all at",
    "start": "725179",
    "end": "732379"
  },
  {
    "text": "once so what was more important to us",
    "start": "732379",
    "end": "737599"
  },
  {
    "text": "than just consistency was this idea that we can have partitions that would have",
    "start": "737599",
    "end": "742699"
  },
  {
    "text": "copies of the data and as long as you had enough copies of the data in those partitions we can guarantee that we",
    "start": "742699",
    "end": "749689"
  },
  {
    "text": "still are consistent provided that the consistency lies in the algorithms that",
    "start": "749689",
    "end": "754909"
  },
  {
    "text": "we're actually pushing out now for CR",
    "start": "754909",
    "end": "761359"
  },
  {
    "start": "758000",
    "end": "817000"
  },
  {
    "text": "DTS they sidestep the cap theorem and it sounds like magic but once we'll get",
    "start": "761359",
    "end": "768019"
  },
  {
    "text": "into this you'll see that there's nothing magical about it so as I mentioned before each CR DT has the same",
    "start": "768019",
    "end": "775129"
  },
  {
    "text": "merge operation and the difference between your TR DT and stuff that you've",
    "start": "775129",
    "end": "782389"
  },
  {
    "text": "normally worked with in a relational database is that duplication is a good thing the reason why duplication is a",
    "start": "782389",
    "end": "788779"
  },
  {
    "text": "good thing is because there's certain operations that you could pull off in a CR DT that eliminate those duplicates",
    "start": "788779",
    "end": "795970"
  },
  {
    "text": "the other reason why it's sidesteps of the caps is that since you have copies of all the",
    "start": "795970",
    "end": "804189"
  },
  {
    "text": "data on every single one of the nodes and you have duplication it basically",
    "start": "804189",
    "end": "809949"
  },
  {
    "text": "makes the data available everywhere or pretty close to everywhere depending on your level of duplication",
    "start": "809949",
    "end": "817889"
  },
  {
    "start": "817000",
    "end": "851000"
  },
  {
    "text": "now the Opera there's only three operations for a CREP so first one is",
    "start": "817889",
    "end": "823839"
  },
  {
    "text": "querying it's getting the steak that's pretty much you could make it an API if",
    "start": "823839",
    "end": "829899"
  },
  {
    "text": "you really wanted to or you could just get a copy of it in our case the update doesn't really apply to us because we",
    "start": "829899",
    "end": "836199"
  },
  {
    "text": "have n source everything and we make no deletes so effectively here there's no",
    "start": "836199",
    "end": "843009"
  },
  {
    "text": "update so that cuts it down to two the most important part that we have is the",
    "start": "843009",
    "end": "849399"
  },
  {
    "text": "merge operation and for Co DTS there's a",
    "start": "849399",
    "end": "854739"
  },
  {
    "start": "851000",
    "end": "885000"
  },
  {
    "text": "few set of rules that you have to follow in order to have a effective merge operation that you never have to worry",
    "start": "854739",
    "end": "861459"
  },
  {
    "text": "about conflicts with so the first thing that it has to do is has to be",
    "start": "861459",
    "end": "867549"
  },
  {
    "text": "commutative so changing the order doesn't really change the result you can do it in any order you want associative",
    "start": "867549",
    "end": "875289"
  },
  {
    "text": "you could group the data in any order everything will still remain the same",
    "start": "875289",
    "end": "880989"
  },
  {
    "text": "idempotent I can run it a thousand times and I still get the same result now",
    "start": "880989",
    "end": "887459"
  },
  {
    "text": "here's something for the audience so let's say I have node 1 and node 2 and",
    "start": "887459",
    "end": "893470"
  },
  {
    "text": "they've got two sets of data now obviously in real world you probably",
    "start": "893470",
    "end": "898720"
  },
  {
    "text": "have something more complex than numbers but for now let's just assume that you needed to merge these two sets of data",
    "start": "898720",
    "end": "905849"
  },
  {
    "text": "which operator do you think would satisfy all the stuff here",
    "start": "905849",
    "end": "915928"
  },
  {
    "start": "917000",
    "end": "930000"
  },
  {
    "text": "now it took us a while to figure this out though but it was so simple that",
    "start": "918490",
    "end": "924110"
  },
  {
    "text": "when we figured it out it was yeah I I don't understand why didn't we think of it at the time it turns out that Union",
    "start": "924110",
    "end": "932149"
  },
  {
    "start": "930000",
    "end": "959000"
  },
  {
    "text": "is really all you need so when I have two sets of data and I want to make sure",
    "start": "932149",
    "end": "941209"
  },
  {
    "text": "that I get consistency between two nodes and I have no deletes and it's just",
    "start": "941209",
    "end": "946579"
  },
  {
    "text": "immutable all I need to do is do a union and it eliminates all the duplicates it",
    "start": "946579",
    "end": "953149"
  },
  {
    "text": "also makes sure that all the unique components are there and I could do what",
    "start": "953149",
    "end": "958550"
  },
  {
    "text": "I need to do with it so when we look at Union if we go through the list I could",
    "start": "958550",
    "end": "964999"
  },
  {
    "start": "959000",
    "end": "978000"
  },
  {
    "text": "say that Union is commutative yes changing the order doesn't do the result change the result associative grouping",
    "start": "964999",
    "end": "973160"
  },
  {
    "text": "doesn't matter idempotent doesn't matter either because you could run it a dozen",
    "start": "973160",
    "end": "978829"
  },
  {
    "text": "times let's see sharp chord looks like this I know this looks really really simple obviously this is not production code",
    "start": "978829",
    "end": "985129"
  },
  {
    "text": "but conceptually this is it and I've got",
    "start": "985129",
    "end": "990499"
  },
  {
    "text": "one half set a one in the second one and the complexity in merging these two is",
    "start": "990499",
    "end": "997490"
  },
  {
    "text": "just that one method call that's it the",
    "start": "997490",
    "end": "1003040"
  },
  {
    "start": "1001000",
    "end": "1046000"
  },
  {
    "text": "other thing that I have to stress is that everything is immutable at least within what we did the reason why we",
    "start": "1003040",
    "end": "1011139"
  },
  {
    "text": "chose immutability in this case is that in other CR DTS you have to keep track",
    "start": "1011139",
    "end": "1016509"
  },
  {
    "text": "of what you've deleted and try to sync that up they call it tombstoning we didn't want",
    "start": "1016509",
    "end": "1021939"
  },
  {
    "text": "to have to deal with that and at the same time we wanted to do something a bit more reasonable and collect all the",
    "start": "1021939",
    "end": "1028510"
  },
  {
    "text": "events within say 90 days and then once it gets past that 90 day horizon we just",
    "start": "1028510",
    "end": "1034000"
  },
  {
    "text": "kill off all the events that we've selected for that one day and for all",
    "start": "1034000",
    "end": "1039069"
  },
  {
    "text": "the listings that we listing events that we collected on that one day",
    "start": "1039069",
    "end": "1044880"
  },
  {
    "start": "1046000",
    "end": "1060000"
  },
  {
    "text": "now one that I've gone over the theory you're probably wondering how do we",
    "start": "1047100",
    "end": "1052510"
  },
  {
    "text": "actually store this stuff because if we're not believing anything then that's",
    "start": "1052510",
    "end": "1057820"
  },
  {
    "text": "a lot of space that we're going to be taking up so what we've just what we did",
    "start": "1057820",
    "end": "1063669"
  },
  {
    "text": "was we've we've used two different types of backing stores so you notice that",
    "start": "1063669",
    "end": "1070330"
  },
  {
    "text": "I've actually copied and pasted these slide from the previous one it looks exactly the same the idea here is that",
    "start": "1070330",
    "end": "1077679"
  },
  {
    "text": "let's call node one elasticsearch no two is s three the point here is that it",
    "start": "1077679",
    "end": "1084490"
  },
  {
    "text": "could be any data source and as long as you follow these rules you get the same level of consistency that you would",
    "start": "1084490",
    "end": "1090520"
  },
  {
    "text": "expect it's almost like magic but it's not the next question you might ask is",
    "start": "1090520",
    "end": "1097090"
  },
  {
    "start": "1094000",
    "end": "1165000"
  },
  {
    "text": "what do you do in this case because this is just numbers I mean you can't most of",
    "start": "1097090",
    "end": "1103450"
  },
  {
    "text": "our data is going to be plain old C sharp or plain old Java objects so it",
    "start": "1103450",
    "end": "1108520"
  },
  {
    "text": "doesn't really make sense just to reduce things down to a number or does it",
    "start": "1108520",
    "end": "1114570"
  },
  {
    "text": "because it turns out that there's a way you could actually make sure that you've",
    "start": "1114570",
    "end": "1120250"
  },
  {
    "text": "got a unique hash set for every single piece of data that you have now don't",
    "start": "1120250",
    "end": "1126100"
  },
  {
    "text": "mind the sha-1 because I do realize that there was a security breach quite a few",
    "start": "1126100",
    "end": "1131799"
  },
  {
    "text": "months back but the important thing here is that this is a sample extreme event now what we've done is we take the sha-1",
    "start": "1131799",
    "end": "1142929"
  },
  {
    "text": "hash or any hash code with a sizable key space so that we don't get collisions",
    "start": "1142929",
    "end": "1148690"
  },
  {
    "text": "and what we do is convert it into a single hash string so that effectively",
    "start": "1148690",
    "end": "1153970"
  },
  {
    "text": "when we do that kind of merging it's just like working with very very large",
    "start": "1153970",
    "end": "1159360"
  },
  {
    "text": "strings or int and it works out really really well",
    "start": "1159360",
    "end": "1165870"
  },
  {
    "start": "1165000",
    "end": "1175000"
  },
  {
    "text": "the other thing that we're doing is that this is a logical representation of our",
    "start": "1165870",
    "end": "1171790"
  },
  {
    "text": "click stream pipeline obviously it's not the scale but what we do is that when we",
    "start": "1171790",
    "end": "1177760"
  },
  {
    "start": "1175000",
    "end": "1183000"
  },
  {
    "text": "have click stream events that come in here it goes straight to the web server the web server posts the events to ahmed ahmed",
    "start": "1177760",
    "end": "1185750"
  },
  {
    "text": "ahmed ahmed processes it and send the copy of the quick stream event to s3 as",
    "start": "1185750",
    "end": "1191540"
  },
  {
    "text": "well as elasticsearch you might also notice that there's a reconciliation process and that's part of the unioning",
    "start": "1191540",
    "end": "1198650"
  },
  {
    "text": "but this is at a much larger scale",
    "start": "1198650",
    "end": "1202390"
  },
  {
    "start": "1203000",
    "end": "1232000"
  },
  {
    "text": "what's important here is that in this flow of events we have multiple actor",
    "start": "1203800",
    "end": "1211460"
  },
  {
    "text": "systems working inside of AWS to make sure that everything is consistent and they're always running almost in real",
    "start": "1211460",
    "end": "1217910"
  },
  {
    "text": "time so for us I know real-time is a relative term but when it comes to property agents they always think in",
    "start": "1217910",
    "end": "1224270"
  },
  {
    "text": "terms of days so when we tell them something is less than 30 seconds they think it's the most amazing thing ever",
    "start": "1224270",
    "end": "1229550"
  },
  {
    "text": "and to some extent it is now if you're",
    "start": "1229550",
    "end": "1234740"
  },
  {
    "start": "1232000",
    "end": "1284000"
  },
  {
    "text": "not familiar with actor systems app an actor system is a collection of actors",
    "start": "1234740",
    "end": "1241130"
  },
  {
    "text": "and an an actor is essentially a degenerate thread with oh no it's a",
    "start": "1241130",
    "end": "1249800"
  },
  {
    "text": "single threaded process inside of an actor system that is guaranteed never to",
    "start": "1249800",
    "end": "1256940"
  },
  {
    "text": "have any kind of locks or conflicts with global or mutable data at all and the",
    "start": "1256940",
    "end": "1264440"
  },
  {
    "text": "reason behind that is that the messages that are sent to every single actor are",
    "start": "1264440",
    "end": "1269620"
  },
  {
    "text": "immutable you can't change it the built in such a way that they context switch",
    "start": "1269620",
    "end": "1276710"
  },
  {
    "text": "between actors and you could treat every single actor as a single threaded process we don't have to worry about",
    "start": "1276710",
    "end": "1282740"
  },
  {
    "text": "anything the interesting part about all this",
    "start": "1282740",
    "end": "1288140"
  },
  {
    "start": "1284000",
    "end": "1416000"
  },
  {
    "text": "stuff is all the systems that we were able to put together as a result of",
    "start": "1288140",
    "end": "1295190"
  },
  {
    "text": "working and failing many many times over I remember trying to do persistence and",
    "start": "1295190",
    "end": "1303860"
  },
  {
    "text": "Postgres and trying to get prosperous as to do the calculations",
    "start": "1303860",
    "end": "1309290"
  },
  {
    "text": "it took us a good one week because no matter how",
    "start": "1309290",
    "end": "1315340"
  },
  {
    "text": "many instances we would add to that server what would happen is that the",
    "start": "1315340",
    "end": "1320580"
  },
  {
    "text": "computation or real-time computation was the bottleneck so what we did was we",
    "start": "1320580",
    "end": "1326830"
  },
  {
    "text": "started Fanning this out to elasticsearch because elasticsearch has",
    "start": "1326830",
    "end": "1331929"
  },
  {
    "text": "this unique ability to keep adding more and more servers the harder we hit it at",
    "start": "1331929",
    "end": "1338590"
  },
  {
    "text": "the same time we came up with quite a few patterns that make a lot of sense so",
    "start": "1338590",
    "end": "1345490"
  },
  {
    "text": "that we get the resiliency that we need so you don't really see any outages the",
    "start": "1345490",
    "end": "1350860"
  },
  {
    "text": "other obvious use that we have is aggregation so in our case it's just the summer account but what we've learned",
    "start": "1350860",
    "end": "1359559"
  },
  {
    "text": "from that is that it's not as simple as it sounds given the amount of traffic that we get and if we've got a thousand",
    "start": "1359559",
    "end": "1365950"
  },
  {
    "text": "messages coming in per second how do you guarantee that there's only a two lesson 10 second lag between the point somebody",
    "start": "1365950",
    "end": "1372400"
  },
  {
    "text": "does something and then the report and the numbers are updated the most",
    "start": "1372400",
    "end": "1377470"
  },
  {
    "text": "interesting thing that we came up with at least in terms of the circuit",
    "start": "1377470",
    "end": "1382780"
  },
  {
    "text": "breaking is is the ability for an actor",
    "start": "1382780",
    "end": "1388540"
  },
  {
    "text": "system to detect if certain things are have gone offline so what we would do is",
    "start": "1388540",
    "end": "1395410"
  },
  {
    "text": "if we had two parallel server ATIS one was a backup we would put an actor",
    "start": "1395410",
    "end": "1402190"
  },
  {
    "text": "system in front of it and if we detected that if anything went down with any one",
    "start": "1402190",
    "end": "1407620"
  },
  {
    "text": "of those two api's it would smoothly cut over and prevent any kind of outage so",
    "start": "1407620",
    "end": "1414660"
  },
  {
    "text": "one of the things that was as you can see here typically we're working on the",
    "start": "1414660",
    "end": "1423580"
  },
  {
    "start": "1416000",
    "end": "1464000"
  },
  {
    "text": "scale of anywhere from 10 to 20 ec2 instances with multiple actor systems",
    "start": "1423580",
    "end": "1430090"
  },
  {
    "text": "per box the interesting part about this is that when you when you go through the aqua dotnet Docs they talk a lot about",
    "start": "1430090",
    "end": "1436270"
  },
  {
    "text": "clustered but we didn't actually use cluster we didn't even use echo dot",
    "start": "1436270",
    "end": "1441790"
  },
  {
    "text": "remoting the reason why is that we had a continuous deployment infrastructure so",
    "start": "1441790",
    "end": "1448889"
  },
  {
    "text": "we were running octopus deploy and when we deployed these actor systems to one",
    "start": "1448889",
    "end": "1454440"
  },
  {
    "text": "box they acted as a single actor in isolation but they were all linked",
    "start": "1454440",
    "end": "1460889"
  },
  {
    "text": "together by SQS the interesting part",
    "start": "1460889",
    "end": "1467220"
  },
  {
    "start": "1464000",
    "end": "1578000"
  },
  {
    "text": "about connecting all these actors through sqs that we never really",
    "start": "1467220",
    "end": "1472980"
  },
  {
    "text": "predicted was this idea that effectively we were creating a distributed swarm now",
    "start": "1472980",
    "end": "1480779"
  },
  {
    "text": "the reason why it's a distributed swarm is because sqs has this unique ability",
    "start": "1480779",
    "end": "1486179"
  },
  {
    "text": "to make messages invisible for a short period of time when an actor pulls",
    "start": "1486179",
    "end": "1494309"
  },
  {
    "text": "something off the cure in this case you make a standard HTTP call it makes it",
    "start": "1494309",
    "end": "1500700"
  },
  {
    "text": "invisible for say five minutes and then if the message isn't deleted it shows up",
    "start": "1500700",
    "end": "1507809"
  },
  {
    "text": "on the queue again now that sounds pretty simple but the interesting side",
    "start": "1507809",
    "end": "1512820"
  },
  {
    "text": "effect for us is that it turns sqs into a blind dispatch effectively we are",
    "start": "1512820",
    "end": "1520769"
  },
  {
    "text": "running a grid with no master node the cool thing about this is what do you",
    "start": "1520769",
    "end": "1527220"
  },
  {
    "text": "think happens if an actor pulls a",
    "start": "1527220",
    "end": "1532830"
  },
  {
    "text": "message off of sqs and for some reason the actor fails what happens to the",
    "start": "1532830",
    "end": "1539129"
  },
  {
    "text": "message and let's say for the sake of it I've got three actor systems running in",
    "start": "1539129",
    "end": "1545070"
  },
  {
    "text": "parallel on different machines the interesting thing about this is if the message is not deleted by the actor it",
    "start": "1545070",
    "end": "1551970"
  },
  {
    "text": "just gets picked up again by another actor and if that actor is successful it",
    "start": "1551970",
    "end": "1557369"
  },
  {
    "text": "just deletes the message off the queue and it keeps going so what we are actually getting here is the ability to",
    "start": "1557369",
    "end": "1563429"
  },
  {
    "text": "have one actor pick up right after the other even if several actor systems fail",
    "start": "1563429",
    "end": "1569809"
  },
  {
    "text": "however as I said in the beginning we failed quite a few times and",
    "start": "1569809",
    "end": "1575160"
  },
  {
    "text": "the ways we actually failed is that we started getting throttled by sqs so as",
    "start": "1575160",
    "end": "1580320"
  },
  {
    "text": "you can see here the idea was that the",
    "start": "1580320",
    "end": "1585510"
  },
  {
    "text": "more infrastructure we threw at the problem at least we thought it was like that the more interpret structure we",
    "start": "1585510",
    "end": "1591810"
  },
  {
    "text": "threw at the problem the more we would solve it but as somebody asked him in",
    "start": "1591810",
    "end": "1597540"
  },
  {
    "text": "one of the other talks he said well that's great you've got a credit but what do you how do you handle the cases",
    "start": "1597540",
    "end": "1603240"
  },
  {
    "text": "where you might hit the service too hard you're always going to run into that problem with well that's great I've got",
    "start": "1603240",
    "end": "1609450"
  },
  {
    "text": "a couple hundred thousand actors but if AWS only takes a certain amount of",
    "start": "1609450",
    "end": "1615890"
  },
  {
    "text": "bandwidth and you're running on one of the fastest servers then what do you do",
    "start": "1615890",
    "end": "1621470"
  },
  {
    "text": "so one of the things that we came up with in this case was this idea of",
    "start": "1621470",
    "end": "1627330"
  },
  {
    "text": "throttling we and if you want to learn",
    "start": "1627330",
    "end": "1632970"
  },
  {
    "text": "how to actually do this kind of throttling it's actually quite simple because in a canet it has a timer this",
    "start": "1632970",
    "end": "1640290"
  },
  {
    "text": "timer allows it's actually called a scheduler but this scheduler allows you",
    "start": "1640290",
    "end": "1645510"
  },
  {
    "text": "the same to send the same message over and over and over again in our case what we were doing was we were sending the",
    "start": "1645510",
    "end": "1652290"
  },
  {
    "text": "same message to monitor the amount of memory that we are actually using or in some phases we're checking the amount of",
    "start": "1652290",
    "end": "1659390"
  },
  {
    "text": "experience messages that we're pulling and if it reached over a certain level",
    "start": "1659390",
    "end": "1664940"
  },
  {
    "text": "what we would do is throttle down the actor system or at least one of them in",
    "start": "1664940",
    "end": "1670100"
  },
  {
    "text": "response to the memory being used so this is an actual message from",
    "start": "1670100",
    "end": "1676530"
  },
  {
    "text": "production and as you might have noticed this is a slack message so our actor systems call home they actually say I",
    "start": "1676530",
    "end": "1683960"
  },
  {
    "text": "have used this much memory and here all the thresholds what we did in this case",
    "start": "1683960",
    "end": "1690720"
  },
  {
    "text": "is if it reaches a critical threshold it'll stop the polling - or reduce it to",
    "start": "1690720",
    "end": "1695820"
  },
  {
    "text": "the level where although it will paralyze one actor system since we all",
    "start": "1695820",
    "end": "1701280"
  },
  {
    "text": "have them running as competing consumers often sqs queue it effectively means",
    "start": "1701280",
    "end": "1707190"
  },
  {
    "text": "that we have this alas to swarm but to keep going even if some",
    "start": "1707190",
    "end": "1712830"
  },
  {
    "text": "of the nodes are in a state where they're critical so there's some really",
    "start": "1712830",
    "end": "1719310"
  },
  {
    "text": "really interesting stuff that we came up with and it really helped us when we rather these situations where we had a",
    "start": "1719310",
    "end": "1725850"
  },
  {
    "start": "1720000",
    "end": "1750000"
  },
  {
    "text": "catastrophic failure so what happened I think there's almost last year there was",
    "start": "1725850",
    "end": "1733770"
  },
  {
    "text": "an eight OES outage in Sydney and what happened was it took out an entire",
    "start": "1733770",
    "end": "1739550"
  },
  {
    "text": "region and it we almost lost a lot of data and how we recovered from it was",
    "start": "1739550",
    "end": "1748610"
  },
  {
    "text": "essentially we had two copies of the data in place we used this",
    "start": "1748610",
    "end": "1755130"
  },
  {
    "start": "1750000",
    "end": "1808000"
  },
  {
    "text": "reconciliation process that I talked about before and on a much larger scale",
    "start": "1755130",
    "end": "1761330"
  },
  {
    "text": "all we did was take the list of hash codes which is basically the list of events on one side for s3 and the list",
    "start": "1761330",
    "end": "1769080"
  },
  {
    "text": "of hash codes for elasticsearch and we found out where the holes were and we patched them it took us quite a few days",
    "start": "1769080",
    "end": "1778110"
  },
  {
    "text": "but we were able to recover everything the best part about this is that we run",
    "start": "1778110",
    "end": "1783180"
  },
  {
    "text": "this process every single day so if there's any problems we can keep patching it as time goes by because we",
    "start": "1783180",
    "end": "1791520"
  },
  {
    "text": "operated on the assumption that no matter how good the system we built is we're always going to have drop packets",
    "start": "1791520",
    "end": "1798630"
  },
  {
    "text": "you're always gonna have partitions and you're always gonna have problems so we always need to be in that state work who",
    "start": "1798630",
    "end": "1804510"
  },
  {
    "text": "are constantly reconciling the data the last thing that we did to make sure that",
    "start": "1804510",
    "end": "1811950"
  },
  {
    "start": "1808000",
    "end": "1839000"
  },
  {
    "text": "we got past this whole thing around eventual consistency is that since we",
    "start": "1811950",
    "end": "1816960"
  },
  {
    "text": "were running immutable we did one last batch request for all the listings that",
    "start": "1816960",
    "end": "1823320"
  },
  {
    "text": "were affected so we send out the request towards the end of the day and since we",
    "start": "1823320",
    "end": "1829560"
  },
  {
    "text": "knew that nothing will change at that point we could send out one more request and they would aggregate everything and",
    "start": "1829560",
    "end": "1834990"
  },
  {
    "text": "that would give us the final consistency that we needed again I have to stress this it was",
    "start": "1834990",
    "end": "1842530"
  },
  {
    "text": "there's nothing magical here you could do this on your own backing store it",
    "start": "1842530",
    "end": "1847930"
  },
  {
    "text": "doesn't have to be s3 it doesn't have to be elastic an important thing here is that you don't necessarily have this -",
    "start": "1847930",
    "end": "1854760"
  },
  {
    "text": "same type of data sources so I don't recommend doing two relational x' or two",
    "start": "1854760",
    "end": "1860560"
  },
  {
    "text": "elastic searches we chose s3 by the way because we most of the time it's up and",
    "start": "1860560",
    "end": "1867540"
  },
  {
    "text": "elastic search was good because we could search the aggregations once we've done",
    "start": "1867540",
    "end": "1874210"
  },
  {
    "text": "them and you can't necessarily do that with s3 so in hindsight there's a lot of",
    "start": "1874210",
    "end": "1884740"
  },
  {
    "text": "things we could have done better but we're pretty happy with the result I mean at the end of the day this was this",
    "start": "1884740",
    "end": "1891910"
  },
  {
    "text": "project was about adding value to the business and you can't necessarily do that if we were just going to sit there",
    "start": "1891910",
    "end": "1897130"
  },
  {
    "text": "and thinker and and try to build that stuff with it what happened towards the end of the",
    "start": "1897130",
    "end": "1905560"
  },
  {
    "text": "project and it's still going that we're nearing the end is that for the first",
    "start": "1905560",
    "end": "1912100"
  },
  {
    "text": "time we Adan started to trust us because if we were on a phone with a real estate",
    "start": "1912100",
    "end": "1918160"
  },
  {
    "text": "agent and they say well how do I know your numbers are correct and that's a",
    "start": "1918160",
    "end": "1924010"
  },
  {
    "text": "common thing with reporting they say well how do I know you're not making this stuff up and the story goes that",
    "start": "1924010",
    "end": "1930270"
  },
  {
    "text": "the customer service rep just told them well why don't you just click a few",
    "start": "1930270",
    "end": "1935740"
  },
  {
    "text": "things five times and see if it goes up and it did and it's these kinds of",
    "start": "1935740",
    "end": "1944050"
  },
  {
    "text": "situations where real time really makes a difference there's a few other things",
    "start": "1944050",
    "end": "1949780"
  },
  {
    "text": "that we've done as you can see here but the lesson learned here is that if you",
    "start": "1949780",
    "end": "1954820"
  },
  {
    "text": "use CR DTS properly and you add duplication you basically could do this",
    "start": "1954820",
    "end": "1962940"
  },
  {
    "text": "without much effort because duplication at least within this",
    "start": "1962940",
    "end": "1969030"
  },
  {
    "text": "context basically saved our ass the other thing",
    "start": "1969030",
    "end": "1975480"
  },
  {
    "start": "1974000",
    "end": "2005000"
  },
  {
    "text": "to remember is if with strong eventual consistency you could achieve that with",
    "start": "1975480",
    "end": "1984240"
  },
  {
    "text": "just using these hash sets provided that you have a good hashing algorithm",
    "start": "1984240",
    "end": "1991440"
  },
  {
    "text": "I recommend anything over 128 bits so you not run into any Croatians if you",
    "start": "1991440",
    "end": "1997380"
  },
  {
    "text": "can afford the computation then I recommend going up even higher than that",
    "start": "1997380",
    "end": "2003820"
  },
  {
    "start": "2005000",
    "end": "2091000"
  },
  {
    "text": "the other thing that we did use that prevents any kind of outage is sqs so",
    "start": "2005110",
    "end": "2014210"
  },
  {
    "text": "what happened since we had so many feuds all over the place if a service went down nobody would notice in fact it",
    "start": "2014210",
    "end": "2022190"
  },
  {
    "text": "wasn't even a said 1 sub 2 it was a sub 3 we you could just hit a button redeploy and nobody would notice a",
    "start": "2022190",
    "end": "2029000"
  },
  {
    "text": "difference and the reason why that was happening was agents were still",
    "start": "2029000",
    "end": "2034610"
  },
  {
    "text": "expecting us to do these kinds of reports or crunch these numbers within a day so if we had a service go out for 10",
    "start": "2034610",
    "end": "2042710"
  },
  {
    "text": "or 20 minutes we just redeploy and everything would be alright if you were",
    "start": "2042710",
    "end": "2047990"
  },
  {
    "text": "to go with an online service where you would hit a server like sequel server",
    "start": "2047990",
    "end": "2053270"
  },
  {
    "text": "and ask for a computation you can be sitting there for a long time and it",
    "start": "2053270",
    "end": "2058700"
  },
  {
    "text": "would look like the report never came back and that's what happens with your typical sequel server reporting service",
    "start": "2058700",
    "end": "2064010"
  },
  {
    "text": "you send a query out and then you cross your fingers and hope that comes back within a minute but it doesn't so what",
    "start": "2064010",
    "end": "2070908"
  },
  {
    "text": "we've learned is that it's a hot trick but what we did was we did an offline",
    "start": "2070909",
    "end": "2077419"
  },
  {
    "text": "calculation and to the user since it was constantly being updated the result was",
    "start": "2077419",
    "end": "2083240"
  },
  {
    "text": "it looks like it was done in real time but by the time they're asking for it the computation was already done so",
    "start": "2083240",
    "end": "2091669"
  },
  {
    "start": "2091000",
    "end": "2129000"
  },
  {
    "text": "without there's a lot of other stories that come with us though but I'm pretty",
    "start": "2091669",
    "end": "2097520"
  },
  {
    "text": "much open to any questions because I realize that there's quite a few other talks that talk about how the intro to",
    "start": "2097520",
    "end": "2102710"
  },
  {
    "text": "active but we covered a lot of cases of how do we actually do this in production how do",
    "start": "2102710",
    "end": "2108440"
  },
  {
    "text": "you scale it up so that's it for me any questions okay I'll take that as a",
    "start": "2108440",
    "end": "2118430"
  },
  {
    "text": "Norwegian yes very well thanks for",
    "start": "2118430",
    "end": "2124069"
  },
  {
    "text": "coming",
    "start": "2124069",
    "end": "2126339"
  }
]
[
  {
    "text": "all right thank you everyone we'll go ahead and get started people can come trickling in so thank you very much for attending my talk",
    "start": "960",
    "end": "6560"
  },
  {
    "text": "uh my name is david karamgard that's how you pronounce that long name i'm a developer advocate at stream native",
    "start": "6560",
    "end": "11759"
  },
  {
    "text": "we're a company behind the open source project apache pulsar my talk is on real-time machine learning",
    "start": "11759",
    "end": "17039"
  },
  {
    "text": "on the edge with pulsar functions so i'm a new speaker here at ndc i'm very honored to be here i'm a",
    "start": "17039",
    "end": "22560"
  },
  {
    "text": "first-timer so a lot of people don't know you so by the way introduction just a little bit of some bullet points about me i'm a committer on the apache",
    "start": "22560",
    "end": "29279"
  },
  {
    "text": "pulsar project open source project been contributed for four years uh formerly a principal software engineer on splunk's messaging",
    "start": "29279",
    "end": "36239"
  },
  {
    "text": "team as which was responsible for running pulsar internally for their service platform so yeah sorry",
    "start": "36239",
    "end": "42879"
  },
  {
    "text": "audio all right",
    "start": "42879",
    "end": "47920"
  },
  {
    "text": "all right thank you sorry about that technical difficulties so i worked at uh splunk uh running pulsar internally",
    "start": "47920",
    "end": "54239"
  },
  {
    "text": "there were able to achieve over uh 10 petabytes a day of throughput through the system so doing all the metrics um",
    "start": "54239",
    "end": "59680"
  },
  {
    "text": "uh you know tracing observability of the micro services for payment so they can make sure they ensure real-time payments",
    "start": "59680",
    "end": "65198"
  },
  {
    "text": "for one of their customers formerly solutions uh architecture directorate streaming we got acquired by",
    "start": "65199",
    "end": "70640"
  },
  {
    "text": "splunks that's how i ended up at splunk and i worked in the big data space at hortonworks before that in the hadoop",
    "start": "70640",
    "end": "76000"
  },
  {
    "text": "and hive space working on that so i've been in apache for over over a decade now and contributor",
    "start": "76000",
    "end": "81200"
  },
  {
    "text": "in my spare time i also write books so i've co-authored the first one practical hive",
    "start": "81200",
    "end": "86560"
  },
  {
    "text": "uh about how to do hiv is the sql query engine that you run on top of hadoop to do analytical queries on your data",
    "start": "86560",
    "end": "92640"
  },
  {
    "text": "inside your data lake i wrote the chapter on query optimization and things like that so the queries actually ran somewhat faster",
    "start": "92640",
    "end": "98880"
  },
  {
    "text": "and i actually authored the entire book pulsar in action as you can see there by that free tag it's actually available",
    "start": "98880",
    "end": "103920"
  },
  {
    "text": "for free so i feel like open a little bit you get a free book you get a free book you get a free book if you go to that url and download it there's just an",
    "start": "103920",
    "end": "109840"
  },
  {
    "text": "information pay wall so you can actually just say who you are in your email and you get the entire electronic copy of the book all 12 chapters and i cover",
    "start": "109840",
    "end": "116000"
  },
  {
    "text": "what i cover in this talk is also covered in greater depth in this in that book so feel free to hey i didn't",
    "start": "116000",
    "end": "121040"
  },
  {
    "text": "understand what he was saying go back and read the chapter and then you know go on to the apache or i'm sorry the manning site say hey dave",
    "start": "121040",
    "end": "127040"
  },
  {
    "text": "i don't understand it was funny some of the uber people talk to me about that we'll get into that a little bit",
    "start": "127040",
    "end": "132800"
  },
  {
    "text": "so i have a lot to talk i'm very verbose so i apologize in advance but my topic is again real-time machine learning with",
    "start": "132800",
    "end": "138640"
  },
  {
    "text": "pulsar functions and the goal of this talk this is what i want you to take away from the go is to give you a quick overview of the how",
    "start": "138640",
    "end": "144400"
  },
  {
    "text": "what and why of deploying machine learning models using apache pulsar functions and a little quick you know whistle stop",
    "start": "144400",
    "end": "150319"
  },
  {
    "text": "introduction what apache pulsar is because some of you may not be familiar with that uh and then talk a little bit about the serverless compute framework",
    "start": "150319",
    "end": "155599"
  },
  {
    "text": "we've written on top called pulsar functions and at the end i'm going to give you this is going to be a pattern a repeatable pattern on how to say so data",
    "start": "155599",
    "end": "162560"
  },
  {
    "text": "scientist comes to you says i have this machine learning model i need to put these inputs into it i want to run it real time use a developer and say okay i",
    "start": "162560",
    "end": "169120"
  },
  {
    "text": "can totally do that i can do that in like 10 lines of code you know name that tune i can do very quickly so it's a very repeatable process and hopefully",
    "start": "169120",
    "end": "175440"
  },
  {
    "text": "but i focus on using a fictional food delivery service to do as a talk said",
    "start": "175440",
    "end": "180720"
  },
  {
    "text": "you know real-time delivery estimation for people who order food online which we all did during the pandemic right where's my food get here with my food",
    "start": "180720",
    "end": "186879"
  },
  {
    "text": "getting here so start with a quick whistle stop tour of what apache pulsar is so obviously it's",
    "start": "186879",
    "end": "192480"
  },
  {
    "text": "apache license so fully open source asf 2.0 source cord's out there go to github apache slash pulsar all the code's there",
    "start": "192480",
    "end": "199519"
  },
  {
    "text": "i'm a committer on that project but our tagline is we're a cloud native messaging and event streaming platform",
    "start": "199519",
    "end": "206239"
  },
  {
    "text": "and so to break that down a little bit this is the one little marketee's part of the speech and i promise i'll be done with it but as we actually designed to",
    "start": "206239",
    "end": "212640"
  },
  {
    "text": "be cloud native up front so other messaging systems in the past have designed had an architectural flaw in our opinion on the apache project",
    "start": "212640",
    "end": "218879"
  },
  {
    "text": "where they would co-locate the data with the serving itself so they wanted to eliminate a network hop so when you",
    "start": "218879",
    "end": "224400"
  },
  {
    "text": "requested a message they just go look on local disk and give you that message back we thought that was a flaw because that becomes on a per topic basis if i",
    "start": "224400",
    "end": "230959"
  },
  {
    "text": "need that data if that node goes down you're you know you're out of luck that data is unavailable for some time so we",
    "start": "230959",
    "end": "236879"
  },
  {
    "text": "decided to do instead was to separate those layers we'll talk about that a little bit and that makes it so we can take advantage of the cloud",
    "start": "236879",
    "end": "242720"
  },
  {
    "text": "native features right so pod goes down and kubernetes and we can just spin up another one no broker is special no uh storage node is",
    "start": "242720",
    "end": "250080"
  },
  {
    "text": "special if one goes down another one can take over immediately and that allows us to leverage all the benefits of kubernetes uh we",
    "start": "250080",
    "end": "256639"
  },
  {
    "text": "have helm charts available so you can deploy it yourself and everything is there and it's designed entirely for against scalability because as i",
    "start": "256639",
    "end": "262079"
  },
  {
    "text": "mentioned 10 petabytes a day rely on some elastic scalability so hey the load comes under pressure we can just scale out the",
    "start": "262079",
    "end": "267919"
  },
  {
    "text": "number of brokers but from the 10 000 foot level for developers like us",
    "start": "267919",
    "end": "273120"
  },
  {
    "text": "this is what it looks like very simple pub sub model you're all seen for 20 30 years now right you have producers i",
    "start": "273120",
    "end": "278720"
  },
  {
    "text": "connect and i publish data asynchronously i don't care if the subscribers are there consumers are there or not they're stored in topics",
    "start": "278720",
    "end": "284400"
  },
  {
    "text": "inside a pulsar and then a consumer i attach later on and i say i want to get data from this topic and the data's pushed to me that's",
    "start": "284400",
    "end": "290639"
  },
  {
    "text": "really it that's there's nothing ground shaking about that it's the exact same paradigm but it's again the architecture",
    "start": "290639",
    "end": "296320"
  },
  {
    "text": "underneath it's slightly different the other part of that tagline was we're both unified messaging and data",
    "start": "296320",
    "end": "302240"
  },
  {
    "text": "streaming so in the past and i covered this in chapter one of my book is there's there's messaging systems right",
    "start": "302240",
    "end": "307919"
  },
  {
    "text": "and they were meant to be one to many were q i published this data you you register an interest and say i want",
    "start": "307919",
    "end": "313520"
  },
  {
    "text": "information on this topic and five or six people can can all get it at the same time it's sort of a work",
    "start": "313520",
    "end": "319039"
  },
  {
    "text": "cue scenario first one gets it receives that sort of thing so they're they're ideal for that sort of thing it's meant",
    "start": "319039",
    "end": "324479"
  },
  {
    "text": "for short duration point-to-point communications like you're making a method call right once the data's there",
    "start": "324479",
    "end": "330400"
  },
  {
    "text": "you can throw it away you don't need to keep it and so rabbit mq and amazon sqs are examples of these cubased messaging",
    "start": "330400",
    "end": "336840"
  },
  {
    "text": "systems then came along you know linkedin developed this open source project called kafka to",
    "start": "336840",
    "end": "343360"
  },
  {
    "text": "primarily move their log data into storage and that became the event streaming paradigm and the big",
    "start": "343360",
    "end": "349680"
  },
  {
    "text": "difference was that is when you're processing the log and you're rewriting to another storage the order in which those lines and log matter right you can",
    "start": "349680",
    "end": "356479"
  },
  {
    "text": "no longer have multiple consumers they have to have one consumer getting that data and they're reprocessing it",
    "start": "356479",
    "end": "361919"
  },
  {
    "text": "and the other thing that event streaming was designed to do is that you keep the data around longer for historical",
    "start": "361919",
    "end": "367280"
  },
  {
    "text": "analytics so in the messaging system world as soon as everybody got the message that that",
    "start": "367280",
    "end": "372960"
  },
  {
    "text": "said they wanted it you would delete it to reclaim space on that disk because disk space is at a premium you're on a single machine you're trying to get that",
    "start": "372960",
    "end": "378960"
  },
  {
    "text": "back of streaming you intentionally keep this data around for longer periods of time and then you put analytical tools at it and go back and read it",
    "start": "378960",
    "end": "385360"
  },
  {
    "text": "you know by time windowing and things like that to get that data later on and again as i mentioned kafka",
    "start": "385360",
    "end": "390960"
  },
  {
    "text": "is a was what started that amazon kinesis which is just a wrapper over kafka is an open source or a",
    "start": "390960",
    "end": "397840"
  },
  {
    "text": "web publicly available uh instance of that streaming methodology pulsar does",
    "start": "397840",
    "end": "403120"
  },
  {
    "text": "both so actually the only system actually does both get getting a little bit about the",
    "start": "403120",
    "end": "408160"
  },
  {
    "text": "architecture so it consists of three different components of the pulsar brokers there at the top they handle all",
    "start": "408160",
    "end": "413360"
  },
  {
    "text": "the message routing as i mentioned they're stateless but with caches so any broker can serve any topic",
    "start": "413360",
    "end": "418800"
  },
  {
    "text": "at any time so if one dies another one can just take over and that's because we store the data in a separate layer",
    "start": "418800",
    "end": "424000"
  },
  {
    "text": "called apache bookkeeper now that is a distributed system that has you know replicas so by",
    "start": "424000",
    "end": "429360"
  },
  {
    "text": "default you write three times to the data and you can write that data there and then how you tie that together is a metadata store currently is apache",
    "start": "429360",
    "end": "436800"
  },
  {
    "text": "zookeeper but we've made it entirely configurable so you can use like ncd or something inside that's native inside of kubernetes",
    "start": "436800",
    "end": "442720"
  },
  {
    "text": "and basically what you do you publish post the data to pulsar and then it writes it to what's called a segment",
    "start": "442720",
    "end": "448880"
  },
  {
    "text": "because they roll over periodically in bookkeeper and the metadata store is like okay my topic consists of segment a",
    "start": "448880",
    "end": "454400"
  },
  {
    "text": "and then segment you know b and then segment c and it's just a url pointing back to where it is in bookkeepers that",
    "start": "454400",
    "end": "459840"
  },
  {
    "text": "way so when a broker dies another one has to come up and says okay i'm in charge of topic a now where the heck's",
    "start": "459840",
    "end": "465120"
  },
  {
    "text": "the data it goes to the configuration store and says oh i can just follow these urls and get that data and service that makes it completely as i mentioned",
    "start": "465120",
    "end": "472080"
  },
  {
    "text": "before cloud native it can all the brokers can die they can come back up you haven't lost the data anyone can serve it allows for dynamic load",
    "start": "472080",
    "end": "478879"
  },
  {
    "text": "shedding as well one broker becomes overloaded we can actually it can say okay i'm offloading these topics to this broker and they can sort of see have",
    "start": "478879",
    "end": "485120"
  },
  {
    "text": "throw full throughput at the broker layer you don't have any hot spotting at that layer that again allows us to get to those",
    "start": "485120",
    "end": "490960"
  },
  {
    "text": "enormous scale petabytes per day logically they consist of different structures right so obviously it's a",
    "start": "490960",
    "end": "496960"
  },
  {
    "text": "distributed system there's multiple instances of this each layer separate independent from themselves",
    "start": "496960",
    "end": "502000"
  },
  {
    "text": "we have an intelligent routing layer called proxies so that you know which topics are being served by which broker at any point in time",
    "start": "502000",
    "end": "508240"
  },
  {
    "text": "so your clients come in they go through a proxy it says oh you're looking for topic a that's over here on this broker over here and then that broker needs to",
    "start": "508240",
    "end": "514959"
  },
  {
    "text": "get the data it uses http and it could go it can go read that data from the different bookies and serve that those requests so completely again if anyone",
    "start": "514959",
    "end": "521919"
  },
  {
    "text": "gets full or down you can just scale them up elastically and so you can you don't have to worry about any sort of failures you know the runtime is is is",
    "start": "521919",
    "end": "528720"
  },
  {
    "text": "up and it can scale accordingly but to show this better i think a cartoon does a better job",
    "start": "528720",
    "end": "534640"
  },
  {
    "text": "this is a former co-worker of mine at splunk jack i did this and this is kind of sharing showing you how it happens in",
    "start": "534640",
    "end": "540480"
  },
  {
    "text": "kafka when you have or any system that has co-located the storage with the compute",
    "start": "540480",
    "end": "546720"
  },
  {
    "text": "so you're in a scenario where hey my broker's overloaded or my topic's full my disk is full i'll just add a new node",
    "start": "546720",
    "end": "553200"
  },
  {
    "text": "we're you know showing this boat here problem is it can't do anything because it's not assigned a different topic it can't take",
    "start": "553200",
    "end": "560000"
  },
  {
    "text": "over the load it's that broker is tied to that particular topic and that new load that new boat can't do anything it",
    "start": "560000",
    "end": "565920"
  },
  {
    "text": "can't take on new load where with pulsar you're throwing one in there you can shed the load over and that guy can immediately start taking on new load and",
    "start": "565920",
    "end": "572480"
  },
  {
    "text": "it just scales very easily it's just transparent so again that's the sort of hammering home those those points on",
    "start": "572480",
    "end": "578160"
  },
  {
    "text": "that architectural difference last thing i wanted to mention on you know because this is just this whistle",
    "start": "578160",
    "end": "584080"
  },
  {
    "text": "stop tour we integrate with a lot of different things uh different functions we're gonna highlight on but you can get",
    "start": "584080",
    "end": "589120"
  },
  {
    "text": "data in and out multiple different sources and sync so if you have data sitting in one influx db copter whatever you can pull it in and out",
    "start": "589120",
    "end": "595200"
  },
  {
    "text": "protocol handlers i want to highlight the mqtt because in the iot space for real-time functions on the edge that",
    "start": "595200",
    "end": "600320"
  },
  {
    "text": "makes a big difference we'll talk about that a little bit later on why that's kind of a differentiator we are the only messaging system that speaks different",
    "start": "600320",
    "end": "606160"
  },
  {
    "text": "binary protocols you know before this like rabbitmqs uses amqp that's it mqtt servers like",
    "start": "606160",
    "end": "611839"
  },
  {
    "text": "mosquito use mqtt protocol that's it kafka uses their own proprietary one we speak them all so if you want to have",
    "start": "611839",
    "end": "618320"
  },
  {
    "text": "interactive systems and when you're getting down to iot space and you want to have an mptt server you don't have to have that alongside pulsar you can just",
    "start": "618320",
    "end": "625040"
  },
  {
    "text": "use pulsar for that and then again we interrupt great with processing engines flank spark things like that so you do those longer time",
    "start": "625040",
    "end": "631600"
  },
  {
    "text": "analytic queries and things like that so i want to give you sort of",
    "start": "631600",
    "end": "636800"
  },
  {
    "text": "if you want to get started with it today and using using just the client apis i'm showing you this so that you realize",
    "start": "636800",
    "end": "642560"
  },
  {
    "text": "it's possible but you don't want to do it because pulsar functions are better so bear with me a little bit on this",
    "start": "642560",
    "end": "648079"
  },
  {
    "text": "but part of the pulsar project is pulsar client we have official language bindings for you know.net c sharp",
    "start": "648079",
    "end": "654560"
  },
  {
    "text": "node.js java go c plus plus and python there's some unofficially ones and you know language of your choice kotlin",
    "start": "654560",
    "end": "661279"
  },
  {
    "text": "uh scala you name it you know you come to me we probably have one that's unofficially supported but the beauty of our that we've been",
    "start": "661279",
    "end": "667760"
  },
  {
    "text": "also incorporating our clients is that encapsulate all those that internal communication thing so again we're talking to a different broker and that",
    "start": "667760",
    "end": "674000"
  },
  {
    "text": "you know and we get a disconnection uh it all might be do do a do a you know retry and reconnect for you without",
    "start": "674000",
    "end": "679839"
  },
  {
    "text": "throwing exceptions you don't have to worry about that in your code you publish it to your client it sends it out it buffers them it sends it out it's",
    "start": "679839",
    "end": "685680"
  },
  {
    "text": "going to get them back if it fails it's going to retract for you automatically and it back pressure is up to your client to your application allowing you",
    "start": "685680",
    "end": "691519"
  },
  {
    "text": "not to publish data so you don't lose any data guarantees there's no data loss if it gets in there acknowledged we have it somewhere in there",
    "start": "691519",
    "end": "698000"
  },
  {
    "text": "and that sort of thing so it's just just a sort of transparent thing you don't have to worry about it's already built in dynamically",
    "start": "698000",
    "end": "704160"
  },
  {
    "text": "we use the fluid builder api style to sort of do these things so you have to first create a client to create",
    "start": "704160",
    "end": "709600"
  },
  {
    "text": "consumers and producers this is it this is the bare minimum you know you just give it the url url of",
    "start": "709600",
    "end": "716480"
  },
  {
    "text": "where you need to be but in practice you have additional things for authentication this is my authentication token this is my tls",
    "start": "716480",
    "end": "722160"
  },
  {
    "text": "certificate things like that get added in that fluent builder but when you're done you're done you build it you have it i'm just showing you the java code as",
    "start": "722160",
    "end": "728480"
  },
  {
    "text": "well it's on java developer so this little block of code and say okay i want to use that one outside",
    "start": "728480",
    "end": "733600"
  },
  {
    "text": "writing messages a pulsar this is how you do it you create the client as we saw in the previous slide then you",
    "start": "733600",
    "end": "739040"
  },
  {
    "text": "create a producer from that client once the client's connected and established now you create that client you notice here on call that you have to specify a",
    "start": "739040",
    "end": "745360"
  },
  {
    "text": "schema for every producer to every consumer so we automatically what you tell us what the type is",
    "start": "745360",
    "end": "750560"
  },
  {
    "text": "we enforce that that you're gonna that when you produce it it's gonna match that schema and we all automatically",
    "start": "750560",
    "end": "756639"
  },
  {
    "text": "take those bytes and serialize them deserialize them for you automatically so no matter what you do you can sort of do these you know the data's all micro",
    "start": "756639",
    "end": "762480"
  },
  {
    "text": "transformed to the expected format before you even start manipulating it on the client side",
    "start": "762480",
    "end": "767600"
  },
  {
    "text": "then you all you have to do is specify i want to you know read from this particular topic and you do create that's it okay now you have a producer",
    "start": "767600",
    "end": "773600"
  },
  {
    "text": "once you have that producer you can just generate messages like this in this case we're again using the fluent pattern showing you some of the different",
    "start": "773600",
    "end": "779200"
  },
  {
    "text": "properties you can specify keys we have something called a key shared subscription so you can make sure that all the data with the same keys get",
    "start": "779200",
    "end": "784480"
  },
  {
    "text": "consumed by the same consumer and things like that we have additional metadata you can manipulate with but the core is you put value there so i'm publishing a string",
    "start": "784480",
    "end": "791760"
  },
  {
    "text": "this is my value you call send this is this this is the synchronous blocking call so you make sure you've gotten it we also have an asynchronous",
    "start": "791760",
    "end": "798079"
  },
  {
    "text": "one which returns a completable future and you can check on the status of that and do retries things like that automatically but",
    "start": "798079",
    "end": "803440"
  },
  {
    "text": "that's that's it that's how you send the data that's all it takes to do to do that",
    "start": "803440",
    "end": "808959"
  },
  {
    "text": "summary with the consumer you you create a client again again the client the consumer itself also has a schema so in",
    "start": "808959",
    "end": "815200"
  },
  {
    "text": "this case we're consuming from the same one uh you're saying i want to be a i'm going to consume strings i expect these",
    "start": "815200",
    "end": "820720"
  },
  {
    "text": "to be strings put the topic you also also have to give this what's called a subscription name and that's a unique",
    "start": "820720",
    "end": "826560"
  },
  {
    "text": "cursor tracks where you are in that topic as you consumed it so if you did get disconnected and you reconnect later on you start exactly",
    "start": "826560",
    "end": "833199"
  },
  {
    "text": "where you left off you don't lose your point at any point in time we track that cursor internally inside our storage",
    "start": "833199",
    "end": "838639"
  },
  {
    "text": "layer and then you call subscribe and you're started you're connected and then this is just an infinite loop i'm i'm",
    "start": "838639",
    "end": "844079"
  },
  {
    "text": "getting the next messages i'm doing you know receive it's a blocking call to get the next one uh and then once i get that i process",
    "start": "844079",
    "end": "850480"
  },
  {
    "text": "that message you do whatever i want with it you have to acknowledge it to say i've gotten it and that moves the cursor forward in your subscription so that you",
    "start": "850480",
    "end": "855760"
  },
  {
    "text": "know you won't process it again the next time and that's it it's a very simple very very simple framework",
    "start": "855760",
    "end": "861920"
  },
  {
    "text": "so if you were to do like a basic event driven application so i want something that says an event comes in i process it like a work queue here comes a work item",
    "start": "861920",
    "end": "869040"
  },
  {
    "text": "and i'm going to take it i have an inventory system i'm going to get this data this is that you create a you know producer consumer",
    "start": "869040",
    "end": "874880"
  },
  {
    "text": "so you have a you know you get a data you process it and you publish a result to another topic and then you can chain it together to have multiple listeners",
    "start": "874880",
    "end": "881360"
  },
  {
    "text": "on everyone being a separate application this is basically this is just a simple while loop i got the data i'm doing",
    "start": "881360",
    "end": "886480"
  },
  {
    "text": "receive i do some business logic here uh and then i can and i write up write out the actual result and i finally",
    "start": "886480",
    "end": "892800"
  },
  {
    "text": "acknowledge the message that i got it and you move on to the next one so that's really it's a very simple uh",
    "start": "892800",
    "end": "898160"
  },
  {
    "text": "pattern for that so why did i show you that because that's that's a lot of code and",
    "start": "898160",
    "end": "903760"
  },
  {
    "text": "we actually thought you know this is very a lot of boilerplate we're going to create our own serverless event a streaming framework",
    "start": "903760",
    "end": "910320"
  },
  {
    "text": "instead that's similar to aws lambda or zero functions something like that",
    "start": "910320",
    "end": "915519"
  },
  {
    "text": "it's similar in the sense that it's its goal like all of those other frameworks its secondary",
    "start": "915519",
    "end": "920800"
  },
  {
    "text": "goal is to simplify developing applications to make it so that if you get somebody who went",
    "start": "920800",
    "end": "927760"
  },
  {
    "text": "to cs course one cs course and can write a single function itself they actually can be productive with the framework and",
    "start": "927760",
    "end": "933360"
  },
  {
    "text": "not have to understand everything i just showed you up to this point so you're now you're saying dave why'd you tell me that just i wanted to appreciate that's",
    "start": "933360",
    "end": "939440"
  },
  {
    "text": "how it was uh this there's a specifically designed to use apache pulsars the message bus so they consume from topics right two",
    "start": "939440",
    "end": "945680"
  },
  {
    "text": "topics we'll see that in a minute and the function runtime again as it relates to real time processing can be",
    "start": "945680",
    "end": "951120"
  },
  {
    "text": "located within the pulsar broker itself they can run as threads they can run they can write as",
    "start": "951120",
    "end": "956320"
  },
  {
    "text": "processes and what we have specialized nodes called as function workers and in the kubernetes environment we recommend it running as kubernetes pods",
    "start": "956320",
    "end": "962720"
  },
  {
    "text": "so again they can dynamically if they die they can be restarted automatically they can be dynamically scaled or run",
    "start": "962720",
    "end": "967759"
  },
  {
    "text": "parallel uh we have something called function mesh which will automatically uh",
    "start": "967759",
    "end": "973759"
  },
  {
    "text": "senses back pressure and scales up for you dynamically if that's the case so very elastic workload processing as well",
    "start": "973920",
    "end": "980959"
  },
  {
    "text": "so here's sort of the you know like i said you can consume from more than one topics you can have multiple input topics",
    "start": "980959",
    "end": "987199"
  },
  {
    "text": "optionally you can have an output topic if you want and log log topics you can capture your data what you're processing your login events there",
    "start": "987199",
    "end": "993759"
  },
  {
    "text": "um these are all the bullet points on that uh again in the middle that blue box is any user supplied processing logic you want",
    "start": "993759",
    "end": "1001040"
  },
  {
    "text": "and you can include third-party libraries as a hint for the ml execution that's",
    "start": "1001040",
    "end": "1006399"
  },
  {
    "text": "exactly what we leverage right so if you want to have a you know any sort of java third party library or pandas if you're",
    "start": "1006399",
    "end": "1012720"
  },
  {
    "text": "using a python one as i mentioned here so there's multiple programming languages currently supported java python and go are supported c sharp",
    "start": "1012720",
    "end": "1019279"
  },
  {
    "text": "is in the future i put a little help one and sign there so people can help me getting the run time to run",
    "start": "1019279",
    "end": "1024400"
  },
  {
    "text": "properly for me i would definitely appreciate it it's open source project i would encourage that but working on that customers have asked for that they",
    "start": "1024400",
    "end": "1030240"
  },
  {
    "text": "really like this feature and they want to use it and we're we're actively in the process of doing that by getting",
    "start": "1030240",
    "end": "1036160"
  },
  {
    "text": "that there but this is the basic thing multiple data is coming in you execute arbitrary logic on it and you obviously",
    "start": "1036160",
    "end": "1041760"
  },
  {
    "text": "spit data out to an output topic and this allows you to chain them or pipeline them together as well so you can logically construct an application",
    "start": "1041760",
    "end": "1047678"
  },
  {
    "text": "or microservice or etl pipeline or whatever you sort of want as you manipulate me you can manipulate the",
    "start": "1047679",
    "end": "1053440"
  },
  {
    "text": "data that flows through your system as it comes through your enterprise messaging system so this is it this is the function if if",
    "start": "1053440",
    "end": "1059919"
  },
  {
    "text": "you can write one method and has this this this signature that's it you can have a pulsar function that's",
    "start": "1059919",
    "end": "1065360"
  },
  {
    "text": "how simple it is nothing complex to process right so i'll leave it there for you to read for a second it's a it's a",
    "start": "1065360",
    "end": "1071120"
  },
  {
    "text": "generic so there's an input type of whatever you want it goes back to those schemas that showed you with the",
    "start": "1071120",
    "end": "1076559"
  },
  {
    "text": "producer and the consumer right so if you want to it's going to be a type string and the output's going to be a type string and",
    "start": "1076559",
    "end": "1081679"
  },
  {
    "text": "that's fine and it just has a process method that's it that's all you have to implement",
    "start": "1081679",
    "end": "1087360"
  },
  {
    "text": "so it takes all that code we showed you previously for the event driven application i showed you a few slides back these 17 lines",
    "start": "1088160",
    "end": "1095520"
  },
  {
    "text": "would all you really want to do is this do business logic you want to take the event you have and do some logic with it",
    "start": "1095520",
    "end": "1100640"
  },
  {
    "text": "right so why do i need all the spoiler plate and now you breaks it down to this now there's the process method you're",
    "start": "1100640",
    "end": "1107360"
  },
  {
    "text": "automatically right so every time that method is called what happens when you submit a function is we do all that",
    "start": "1107360",
    "end": "1112559"
  },
  {
    "text": "boilerplate for you create a connection for you create the client for you the consumer producer if you specify an",
    "start": "1112559",
    "end": "1117600"
  },
  {
    "text": "output and have that running in the background and every time a new event comes we invoke this method and pass in",
    "start": "1117600",
    "end": "1123120"
  },
  {
    "text": "in that input the first parameter that message the next message now it's up to you you can do whatever",
    "start": "1123120",
    "end": "1128320"
  },
  {
    "text": "you want with that thing and if you do a return method it automatically publishes out to the output method so you just say return you",
    "start": "1128320",
    "end": "1134240"
  },
  {
    "text": "know a value it's automatically published you don't have to worry about any of that stuff that happens for you transparently",
    "start": "1134240",
    "end": "1140160"
  },
  {
    "text": "just wanted to point out that that context object is also passed with you that gives you a lot of access into what's going on under the cover some",
    "start": "1140160",
    "end": "1145200"
  },
  {
    "text": "metadata and for our purposes uh it allows us to access what's called a state store inside the bookie layer",
    "start": "1145200",
    "end": "1151919"
  },
  {
    "text": "so as i mentioned before we have the broker layer and then we have this apache bookkeeper which is a separate storage",
    "start": "1151919",
    "end": "1157280"
  },
  {
    "text": "layer it's a distributed object store and we said hey we've got this thing sitting around wouldn't it be cool if we could have our",
    "start": "1157280",
    "end": "1163120"
  },
  {
    "text": "functions write data there to store it temporarily so in between invocations i can publish data there or",
    "start": "1163120",
    "end": "1168640"
  },
  {
    "text": "external sources can publish data there so we'll handle any sort of raw bytes and it has a key value map that's it so you publish",
    "start": "1168640",
    "end": "1174960"
  },
  {
    "text": "it you put it in there and you can between implications that data gets changed uh and as we'll see",
    "start": "1174960",
    "end": "1180799"
  },
  {
    "text": "it's a backdoor that allows you to publish the machine learning models up the data science team can just say hey i'll put it in state store and then at",
    "start": "1180799",
    "end": "1186400"
  },
  {
    "text": "runtime we do context.getstate and look for that model boom there it is so it's it makes it very easy to get",
    "start": "1186400",
    "end": "1193520"
  },
  {
    "text": "data into these functions without having to crack them open you can dynamically change the model as we'll see in my use",
    "start": "1193520",
    "end": "1199280"
  },
  {
    "text": "case the models get rotated periodically right so it's not once you publish it out there and your model changes",
    "start": "1199280",
    "end": "1205360"
  },
  {
    "text": "you have to tear everything down and restart it no you just this is a backdoor way in to do that",
    "start": "1205360",
    "end": "1210400"
  },
  {
    "text": "so once you've so you have a you know you've created a function in this case i'm do using java uh case but you can",
    "start": "1210400",
    "end": "1216080"
  },
  {
    "text": "you know once we get the c-sharp working it's the same thing but you bundle up your jar it has all your third-party libraries in it you want",
    "start": "1216080",
    "end": "1222080"
  },
  {
    "text": "and you deploy it you give it the class name this is the name that's going to be you know uh the function name itself and",
    "start": "1222080",
    "end": "1227360"
  },
  {
    "text": "here's how you configure the input whatever input topics you want whatever output topics you want and you give it a",
    "start": "1227360",
    "end": "1233679"
  },
  {
    "text": "name so you can go back and monitor it later you can scale it up you can scale it down you can delete it you can kill it a kind of a a unique unique",
    "start": "1233679",
    "end": "1240880"
  },
  {
    "text": "identifier for that function so that's it once you have it you just you just publish it there and",
    "start": "1240880",
    "end": "1246720"
  },
  {
    "text": "that's it real simple this just wanted to mention this pulsar admin command would run on like a",
    "start": "1246720",
    "end": "1252559"
  },
  {
    "text": "toolkit node or on a sidekick note but it also fronts and a api a rest api so",
    "start": "1252559",
    "end": "1258080"
  },
  {
    "text": "if you wanted to automate it in some way and do a deployment that's entirely possible as well it's just a a wrapper around a rest api so there's multiple",
    "start": "1258080",
    "end": "1264559"
  },
  {
    "text": "ways to do the same things you don't have to use this uh cli command but it's just a convenient way to do it",
    "start": "1264559",
    "end": "1272159"
  },
  {
    "text": "okay last bit of background i swear so talk about pulsar introductions pulsar functions why they're cool getting you ready for that",
    "start": "1272480",
    "end": "1278640"
  },
  {
    "text": "let's talk a little bit about edge computing environments right so this is the subject of this talk is real-time machine learning so",
    "start": "1278640",
    "end": "1284400"
  },
  {
    "text": "you cannot do real-time anything processing if you have to send your data all the way up to the cloud first",
    "start": "1284400",
    "end": "1290159"
  },
  {
    "text": "there's too much latency there between the event occurs and you do all these network hops and you bum and you've buffered it along the",
    "start": "1290159",
    "end": "1296799"
  },
  {
    "text": "way and you finally send it to your distributed computing engine and then they finally do something on it too much time is passed right there's",
    "start": "1296799",
    "end": "1302320"
  },
  {
    "text": "this there's this factor of called uh the um business value decreases over time right the longer takes you direct to event the",
    "start": "1302320",
    "end": "1308720"
  },
  {
    "text": "less chance it has a higher value right so like an iot use case industrial use case you see an alert to machines overheating if it takes a half hour to",
    "start": "1308720",
    "end": "1315440"
  },
  {
    "text": "figure out hey i should shut that machine down it probably already blew up right so this is you have to do everything on the edge",
    "start": "1315440",
    "end": "1321120"
  },
  {
    "text": "so there's there's some challenges with it but there's there's some opportunities for use cases you're going to want to do some like fraud detection",
    "start": "1321120",
    "end": "1326880"
  },
  {
    "text": "real-time fraud detection right you're on a mobile app and you're doing you know transfer zillow or maybe you're on like an atm",
    "start": "1326880",
    "end": "1334240"
  },
  {
    "text": "and you're doing something that's that once you commit to this transaction you prove it you can't sort of take it back right once i dispense that cash",
    "start": "1334240",
    "end": "1340720"
  },
  {
    "text": "it's gone where if you're on like a like a like an e-commerce site as you saw i worked at zappos at one time but somebody you know had ordered some shoes",
    "start": "1340720",
    "end": "1347520"
  },
  {
    "text": "or something and then later on they got the fraud detection he said hey somebody charged my credit card we haven't shipped the shoes out so we can pull",
    "start": "1347520",
    "end": "1352720"
  },
  {
    "text": "that back and we haven't lost money but with these things where you're doing you know you know real-time trading or something like that",
    "start": "1352720",
    "end": "1359039"
  },
  {
    "text": "you have to detect that fraud within you know a few seconds you can't let that person sit there for a half hour wait for their money at an atm you have to do",
    "start": "1359039",
    "end": "1365440"
  },
  {
    "text": "it very quickly other use cases we know all major auto manufacturers the united",
    "start": "1365440",
    "end": "1370480"
  },
  {
    "text": "states use it for connected cars you have all this data collecting out on the edge things like you know insurance companies you plug in that little little",
    "start": "1370480",
    "end": "1377280"
  },
  {
    "text": "little device into your thing it measures your driving are you a good driver or not it measures your rewards they're just collecting all your your",
    "start": "1377280",
    "end": "1383360"
  },
  {
    "text": "telemetric data and eventually they send it up but sometimes they do real-time analytics as well uh industrial iot as i",
    "start": "1383360",
    "end": "1389679"
  },
  {
    "text": "mentioned uh surveillance and cyber security again real time you know matters you need to make these decisions quickly and then",
    "start": "1389679",
    "end": "1394960"
  },
  {
    "text": "any sort of smart anything smart city smart farm uh you know agriculture if you know there was a presentation about",
    "start": "1394960",
    "end": "1402080"
  },
  {
    "text": "the the lightning talk the guy had the robot arm and doing that sort of thing in that farm if you saw that one uh",
    "start": "1402080",
    "end": "1407520"
  },
  {
    "text": "getting all that data and reacting to it real time so this is what edge computers how to find edge computing and it's been had",
    "start": "1407520",
    "end": "1413600"
  },
  {
    "text": "different terms fog computing edge computing it basically means something further away you know up in the cloud",
    "start": "1413600",
    "end": "1419200"
  },
  {
    "text": "you have we everybody knows what's up in the cloud racks of servers different computing processing and then you have something",
    "start": "1419200",
    "end": "1425440"
  },
  {
    "text": "that's sort of a gateway in and that could be a traditional server node or edge node but you could even be further down",
    "start": "1425440",
    "end": "1430720"
  },
  {
    "text": "closer use your devices themselves these these little black bricks are the phone that we you know saw on the first day these are black bricks",
    "start": "1430720",
    "end": "1437039"
  },
  {
    "text": "you're out there on a cell tower collecting information so the day they're sending theirs you know like this is my location information this is",
    "start": "1437039",
    "end": "1443360"
  },
  {
    "text": "my intent to purchase some food for our particular use case here and you want to the closer to the edge",
    "start": "1443360",
    "end": "1448559"
  },
  {
    "text": "you can do that processing you're actually you know reducing that decision latency you have a higher",
    "start": "1448559",
    "end": "1453840"
  },
  {
    "text": "amount of time to detect fraud or you know do you have a better computation than if you send it all the",
    "start": "1453840",
    "end": "1459679"
  },
  {
    "text": "way up to the cloud so traditionally this is sort of the challenge right there's this inverse relationship the closer you get to where",
    "start": "1459679",
    "end": "1466480"
  },
  {
    "text": "the events occur the less computing power you have to actually do machine learning right that's that's the challenge",
    "start": "1466480",
    "end": "1472480"
  },
  {
    "text": "so on the very edge in this again i'm kind of skewing towards industrial iot but to kind of make a point you have all",
    "start": "1472480",
    "end": "1478320"
  },
  {
    "text": "these different devices you have sensors and actuators out there but they have no real computing power they're there to like measure temperature and broadcast",
    "start": "1478320",
    "end": "1485120"
  },
  {
    "text": "it over shortwave transfer transformation protocol uh and that's it they just sense they sense the environment and maybe an",
    "start": "1485120",
    "end": "1491200"
  },
  {
    "text": "actuator if you tell it to turn turn something off close the valve it'll do it for you but that's it there's no computing there so you can't do machine",
    "start": "1491200",
    "end": "1496480"
  },
  {
    "text": "learning there so the next step up is these what they call sensor hubs and they're basically systems on a chip they have you know",
    "start": "1496480",
    "end": "1503200"
  },
  {
    "text": "hundreds of kilobytes at the most maybe one core and their goal in life the whole reason they exist is to convert these shortwave",
    "start": "1503200",
    "end": "1510080"
  },
  {
    "text": "uh protocols the signals they get over shortwave you know like bluetooth and zigbee and other short-range protocols",
    "start": "1510080",
    "end": "1517360"
  },
  {
    "text": "and convert it into an mqtt protocol which is for longer range transmission right and that's all they do that that's",
    "start": "1517360",
    "end": "1523120"
  },
  {
    "text": "their purpose in life uh sending further up the food chain or then what they call iot gateways and those are things that",
    "start": "1523120",
    "end": "1528720"
  },
  {
    "text": "have the hardware profile something like a raspberry pi for those of you who have raspberry pi you have a few gigs i have the raspberry four has like eight gigs",
    "start": "1528720",
    "end": "1535120"
  },
  {
    "text": "uh two cores now and you can put like a terabyte of storage so now you got starting to get a little bit of beef on there and then further up you have like",
    "start": "1535120",
    "end": "1541440"
  },
  {
    "text": "a traditional server desktop and at the very top of the food chain as a cloud right it's in a measure of however much compute you want you can buy you can you",
    "start": "1541440",
    "end": "1547279"
  },
  {
    "text": "know theoretically get it and so that's sort of the the challenge there",
    "start": "1547279",
    "end": "1553200"
  },
  {
    "text": "logically they all serve different purposes right so again the perception and sensor layers do that the middle part is there just to get the data up as",
    "start": "1553200",
    "end": "1560000"
  },
  {
    "text": "i mentioned right i'm collecting this data my goal is to send it up and then maybe maybe at the edge you can start doing",
    "start": "1560000",
    "end": "1566720"
  },
  {
    "text": "some data processing some simple stuff you know today like filtering or aggregation sort of thing but more",
    "start": "1566720",
    "end": "1573039"
  },
  {
    "text": "more complex animal you know analytic processing is traditionally done in the cloud i got to move all this data up",
    "start": "1573039",
    "end": "1578559"
  },
  {
    "text": "here right so the event occurs something happened hop buffer buffer hop buffer",
    "start": "1578559",
    "end": "1583600"
  },
  {
    "text": "buffer hop eventually gets up there and how much time is elapsed while you're waiting for all this data to transmit so our goal is",
    "start": "1583600",
    "end": "1589120"
  },
  {
    "text": "to push this computing down right so this is where the pulsar architecture that i talked",
    "start": "1589120",
    "end": "1595520"
  },
  {
    "text": "about earlier comes in there's two edge deployment enablers things that are that are distinct the pulsar that no",
    "start": "1595520",
    "end": "1600559"
  },
  {
    "text": "other messaging system has in there and the first being that it supports the mpt protocols i mentioned",
    "start": "1600559",
    "end": "1605679"
  },
  {
    "text": "right so you do you can actually speak you can get you can you can inject here and i'll show the next slide",
    "start": "1605679",
    "end": "1611120"
  },
  {
    "text": "further down the chain i can you can put pulse our way down here and it can start listening to mqtt it doesn't it speaks",
    "start": "1611120",
    "end": "1616720"
  },
  {
    "text": "that language you don't have to do another translation you don't have to have something listed on mqtt on one side and publishing it up on the other",
    "start": "1616720",
    "end": "1623039"
  },
  {
    "text": "it can sit right there and do those sort of things the other one is it's sort of a distributed compute and storage layers",
    "start": "1623039",
    "end": "1629279"
  },
  {
    "text": "as i mentioned earlier right so the brokers can run as long as you have a tcp connection to apache bookkeeper i",
    "start": "1629279",
    "end": "1635200"
  },
  {
    "text": "can publish that data so again i don't need to have a big hardware profile with a lot of disk i could put it out on",
    "start": "1635200",
    "end": "1640559"
  },
  {
    "text": "something like a raspberry pi or even smaller because as long as i have a tcp connection back to right data i'm good i",
    "start": "1640559",
    "end": "1646960"
  },
  {
    "text": "can write i can run it there and then the third part the whole purpose of this",
    "start": "1646960",
    "end": "1652159"
  },
  {
    "text": "as of this talk is that serverless functions framework called pulsar functions right so you can actually put arbitrary code and run it down there on",
    "start": "1652159",
    "end": "1658960"
  },
  {
    "text": "the broker so these events come in you can actually do an event driven architecture much closer to where the event occurred i have this data do",
    "start": "1658960",
    "end": "1665360"
  },
  {
    "text": "something with it quickly don't send it up the line and wait for something to happen let's do it right here and my",
    "start": "1665360",
    "end": "1670480"
  },
  {
    "text": "goal of this talk is to show you how to put the how that how to do a machine learning one there right so this",
    "start": "1670480",
    "end": "1676000"
  },
  {
    "text": "is sort of the concept is you're going to stretch it right so we stretch this data processing layer down all the way to the iot gateways in",
    "start": "1676000",
    "end": "1682559"
  },
  {
    "text": "theory maybe up the edge server wherever you want but we can stretch it because and leave the bookies up in the data center or somewhere further up because",
    "start": "1682559",
    "end": "1688880"
  },
  {
    "text": "we have this tcp connection as our sort of you know ace in the hole we have that there and so i'm allowed to push my",
    "start": "1688880",
    "end": "1695200"
  },
  {
    "text": "brokers much further down and do things like machine learning that much closer to the source of the data",
    "start": "1695200",
    "end": "1702398"
  },
  {
    "text": "so let's talk a little bit about the machine learning life cycle uh it's you know and our role in it right so we're",
    "start": "1702880",
    "end": "1709120"
  },
  {
    "text": "developers here but the machine learning life cycle involves not only the data scientists it's not just for data scientists not",
    "start": "1709120",
    "end": "1715039"
  },
  {
    "text": "only for data engineers but the end of the day somebody has that model and has to deploy and that's us so the developers so i'm going to show where we",
    "start": "1715039",
    "end": "1720720"
  },
  {
    "text": "fit in there and give you an overview of this particular use case as i mentioned is the food delivery service and how in the background so you understand what's",
    "start": "1720720",
    "end": "1726799"
  },
  {
    "text": "going on but in general it's broken down into these five different phases right there's a problem identification what",
    "start": "1726799",
    "end": "1732640"
  },
  {
    "text": "are we trying to do actually how are we helping to help the business what is our goal here then you go through data acquisition",
    "start": "1732640",
    "end": "1738480"
  },
  {
    "text": "phase you say okay i'm trying to solve this problem what data sets do i have available to actually make a decision on",
    "start": "1738480",
    "end": "1743520"
  },
  {
    "text": "the to to solve this business problem right and that's sort of done by the data science team uh but with with the help of the data",
    "start": "1743520",
    "end": "1750240"
  },
  {
    "text": "engineering team we'll get into that once they've looked at what data sets they have they start the the model development this is machine learning",
    "start": "1750240",
    "end": "1756000"
  },
  {
    "text": "model development where they start building you know feature engineering model building validation then they do some training and then finally at the",
    "start": "1756000",
    "end": "1762559"
  },
  {
    "text": "end of that food chain sets us the developers right so they come to us and i'll talk about what they what they've done to get it to us at the end of the",
    "start": "1762559",
    "end": "1767679"
  },
  {
    "text": "day they say hey have this machine learning model it needs these particular data inputs and i want to run it here",
    "start": "1767679",
    "end": "1773039"
  },
  {
    "text": "and then they dump it in your lap and you have to do something with it and i'm going to help you do something with it once they've dumped it in your lap so",
    "start": "1773039",
    "end": "1780159"
  },
  {
    "text": "let's start with the problem identification what are we trying to solve right everybody has a phone everybody's used uber uber heats by now",
    "start": "1780159",
    "end": "1785279"
  },
  {
    "text": "this is it right so this is a again my book walks through this but it's a fictional food delivery company customer",
    "start": "1785279",
    "end": "1791360"
  },
  {
    "text": "place is an order we need to give them a rough estimate of when that food is going to get there right the entire time the track and the food when you know",
    "start": "1791360",
    "end": "1797679"
  },
  {
    "text": "when it's going to happen but in order to do that you have to predict three things accurately it's broken down to when the food's going to be ready when the restaurant's done preparing it how",
    "start": "1797679",
    "end": "1804159"
  },
  {
    "text": "long it's going to take the driver to finally you know go over to that restaurant pick it up and then transit back from where we picked it up to where",
    "start": "1804159",
    "end": "1810399"
  },
  {
    "text": "wherever my address is right so those are three different things we have to do well this this is a hard problem right",
    "start": "1810399",
    "end": "1816240"
  },
  {
    "text": "it cannot be solved you can't there's certain ways certain problems with machine learning that you can sort of sort of pre-compute and do it offline",
    "start": "1816240",
    "end": "1822559"
  },
  {
    "text": "like if you get these recommendations engines if you sign up for something in email or you bought something here they say the next",
    "start": "1822559",
    "end": "1828080"
  },
  {
    "text": "day hey we saw you bought a lawnmower yesterday so you might want to buy some you know lawnmower blades today or",
    "start": "1828080",
    "end": "1833440"
  },
  {
    "text": "something they have that data set they can process it in a batch and there's a finite number of people who've done that",
    "start": "1833440",
    "end": "1838480"
  },
  {
    "text": "and they can do that data and then they can send that uh you know that email recommendation to you offline what they",
    "start": "1838480",
    "end": "1843760"
  },
  {
    "text": "call offline mode but this is online mode right you cannot do these things our goal is to pair a driver with a",
    "start": "1843760",
    "end": "1849200"
  },
  {
    "text": "restaurant with a customer who pops up ad hoc and you know we can't possibly precompute all these values it's an",
    "start": "1849200",
    "end": "1855200"
  },
  {
    "text": "incomplete np complete data set and even if we could you can't account for current conditions right if you possibly",
    "start": "1855200",
    "end": "1861039"
  },
  {
    "text": "could the traffic today versus yesterday and you know on friday with weather and everything else you just can't account",
    "start": "1861039",
    "end": "1866480"
  },
  {
    "text": "for that so it has to be done online you have to do with real-time data so",
    "start": "1866480",
    "end": "1872000"
  },
  {
    "text": "okay that's our problem how does it what's you know data acquisition starts by the data engineering team slash data science they sort of collaborate on this",
    "start": "1872000",
    "end": "1878080"
  },
  {
    "text": "and they say okay what do we have what data sets do we have well among many other things obviously the driver has a mobile app so we signed in",
    "start": "1878080",
    "end": "1885519"
  },
  {
    "text": "and every every time he signed in periodically in the background we're sending a ping of where he is it's my driver location",
    "start": "1885519",
    "end": "1890960"
  },
  {
    "text": "this is the time stamp this is my life this is my lawn this is where i am and that's a big data set we use it for",
    "start": "1890960",
    "end": "1896240"
  },
  {
    "text": "a lot of different things so you can put it in some dix disk backed caches for real time zones hey i wonder where these",
    "start": "1896240",
    "end": "1901760"
  },
  {
    "text": "drivers are right now but then you do analytics for route optimization then you do some pricing right you look at these surge pricing models and try to",
    "start": "1901760",
    "end": "1907840"
  },
  {
    "text": "better place and set your drivers to be the right place at the right time so you forward that on to a data lake then you",
    "start": "1907840",
    "end": "1913440"
  },
  {
    "text": "also have this more of a traditional transactional database we still need to keep track of who bought an order who delivered it you know so we can make",
    "start": "1913440",
    "end": "1919919"
  },
  {
    "text": "sure the restaurant gets paid the driver gets paid the customer we have transaction credit card we can track all that stuff like like a regular business",
    "start": "1919919",
    "end": "1926080"
  },
  {
    "text": "we have all that stuff sitting board a transactional database and we'll just call it like a food order database right",
    "start": "1926080",
    "end": "1931120"
  },
  {
    "text": "so it's sitting there and it's tied back to order ids and statuses",
    "start": "1931120",
    "end": "1936159"
  },
  {
    "text": "so you the data science team um and the data engineering looks and says okay you know intuitively let's start calculating",
    "start": "1936159",
    "end": "1942480"
  },
  {
    "text": "some things and one of the things that you know this i got this from the uber blog this is how ubereats kind of does these things they",
    "start": "1942480",
    "end": "1947519"
  },
  {
    "text": "start looking at hey things that matter things vary over time right you you want to say okay we're trying to predict how",
    "start": "1947519",
    "end": "1953039"
  },
  {
    "text": "long it takes a restaurant to make a meal well that varies right so you want to calculate one average for the entire lifetime of that",
    "start": "1953039",
    "end": "1958960"
  },
  {
    "text": "restaurant you want to have it more granular where because are they how long does it take you know during",
    "start": "1958960",
    "end": "1964240"
  },
  {
    "text": "rush hour during noon during lunch how long does it take at 10 o'clock at night when they're under staffed how long does it take monday wednesday tuesday like",
    "start": "1964240",
    "end": "1971200"
  },
  {
    "text": "this and so you can take that data and do a query on that transactional database something like that and like",
    "start": "1971200",
    "end": "1976559"
  },
  {
    "text": "you know and figure it out and then you do it per restaurant basis right so okay so this is my average time",
    "start": "1976559",
    "end": "1982399"
  },
  {
    "text": "over the last hour for example for every restaurant well that's great but you can't do that query",
    "start": "1982399",
    "end": "1988159"
  },
  {
    "text": "every time even if you knew the restaurant id on the edge right the database isn't there it's going to take a little while to run this processing",
    "start": "1988159",
    "end": "1993760"
  },
  {
    "text": "thing so what they do at uber and other things is they use what's called a feature store and they pre-compute this in the",
    "start": "1993760",
    "end": "1999360"
  },
  {
    "text": "background using a large processing engine right this data's sitting there they make a copy of it in their data lake and then they run this with a",
    "start": "1999360",
    "end": "2005679"
  },
  {
    "text": "massively parallel processing system and they put this in a column database something like cassandra that has a key",
    "start": "2005679",
    "end": "2012480"
  },
  {
    "text": "value lookup right so when i come back to look at this later i go restaurant id and there's like 800 different columns there and one of them is what's what was",
    "start": "2012480",
    "end": "2019360"
  },
  {
    "text": "the average full average meal prep time in the last hour and i can look at that information",
    "start": "2019360",
    "end": "2025200"
  },
  {
    "text": "and then they can do similar things by you know by different day of the week that's another different factor that",
    "start": "2025200",
    "end": "2030799"
  },
  {
    "text": "they run um you can do uh you know different things about the delivery time how long does it take for",
    "start": "2030799",
    "end": "2036320"
  },
  {
    "text": "people to get into this restaurant pick up the food in the last hour the last week and monday for four o'clock",
    "start": "2036320",
    "end": "2041360"
  },
  {
    "text": "whatever they want and they pre-calculus pre-calculate that data so once the data scientist says okay this this is the",
    "start": "2041360",
    "end": "2047360"
  },
  {
    "text": "features i want they make sense i put them into my model i've done some sampling it makes sense the data engineering team goes off and sets up",
    "start": "2047360",
    "end": "2053358"
  },
  {
    "text": "the framework to make sure that this is populated runs every hour systematically so that data is guaranteed to be there when you need it to feed your model",
    "start": "2053359",
    "end": "2059599"
  },
  {
    "text": "right and now us as the programmers know where the data sits and we know the key because the key is coming in the message",
    "start": "2059599",
    "end": "2064638"
  },
  {
    "text": "we have the customer id we have the restaurant assigned to it so we'll show a little bit we can just go get that data so that's sort of a data prep thing",
    "start": "2064639",
    "end": "2071679"
  },
  {
    "text": "uh the other thing we're missing though is the is the distance right these people are popping up everywhere how we're going to know how",
    "start": "2071679",
    "end": "2076720"
  },
  {
    "text": "can you possibly calculate every permutation of every customer's address to every where the driver is going to be",
    "start": "2076720",
    "end": "2082398"
  },
  {
    "text": "because the driver is always moving so you know how the heck you do that well long story short uber had to solve this problems they",
    "start": "2082399",
    "end": "2088560"
  },
  {
    "text": "solved it for us they made it open source they have this thing called a h3 for a",
    "start": "2088560",
    "end": "2093839"
  },
  {
    "text": "spatial index thing and what it basically does is take a take a map and maps it down into grid squares they're all equal",
    "start": "2093839",
    "end": "2099920"
  },
  {
    "text": "distance apart because hexagons have the property of their centroid of any other centroid is exactly the same and so you",
    "start": "2099920",
    "end": "2105280"
  },
  {
    "text": "know the size of these things and then you can basically say okay the guys you know four hexagons away that's four or four miles",
    "start": "2105280",
    "end": "2111359"
  },
  {
    "text": "uh sort of thing and so you can just all you do is put that driver in a hexagon you know where the restaurant hexagon is",
    "start": "2111359",
    "end": "2117760"
  },
  {
    "text": "and you know where the customer hexagon is and then you can simplify it because you're not solving an exact problem you do an approximation instead",
    "start": "2117760",
    "end": "2125280"
  },
  {
    "text": "and so for example where you do again you do a prep so okay we're going to look up this information ahead of time we can pre-calculate this",
    "start": "2125280",
    "end": "2131359"
  },
  {
    "text": "stuff and you sort of have an idea what's the average time so this central right here showing the restaurant",
    "start": "2131359",
    "end": "2136480"
  },
  {
    "text": "they're in the middle of that point and you want to say okay what's the average time it takes me from this the drivers in this hexagon to get there is six",
    "start": "2136480",
    "end": "2142480"
  },
  {
    "text": "minutes and you just do sort of a range because we're not going to sign anybody outside of that range so you already have these values pre-computed now we've kind of",
    "start": "2142480",
    "end": "2148640"
  },
  {
    "text": "solved that problem and i said okay we know this guy's going to this restaurant and the driver every time they ping on a separate",
    "start": "2148640",
    "end": "2155359"
  },
  {
    "text": "pipeline with a pulsar function we just embed it we do that we call that h3 encoder tag is uh grid square and then",
    "start": "2155359",
    "end": "2161280"
  },
  {
    "text": "we know we have the data so we have the data so last just kind of a little bit so now",
    "start": "2161280",
    "end": "2167280"
  },
  {
    "text": "the data science team says okay we're great we got all the information that sort of thing just sort of showing you",
    "start": "2167280",
    "end": "2172640"
  },
  {
    "text": "what their end product is going to be at a you know 10 000 foot level i'm not a data scientist i apologize to everybody in here if i'm simplifying your job or",
    "start": "2172640",
    "end": "2179440"
  },
  {
    "text": "marginalizing any way by saying this or anybody that watches it but they have basically at the end of the day they",
    "start": "2179440",
    "end": "2184560"
  },
  {
    "text": "have two outputs that they're going to give to us here's your model it could be of any type you know it's a linear you know it's a linear regression",
    "start": "2184560",
    "end": "2191040"
  },
  {
    "text": "model it's a decision tree it's a it's a kk clusters network whatever they build",
    "start": "2191040",
    "end": "2196880"
  },
  {
    "text": "that's up to them they hand it to us and the other thing is you know again like as i mentioned feature vector this is the input i need",
    "start": "2196880",
    "end": "2203200"
  },
  {
    "text": "so if i have you know certain customer order features and delivery time features and the average meal prep features and i put these things in there",
    "start": "2203200",
    "end": "2210320"
  },
  {
    "text": "and you give me that i guarantee within a 90 degree of accuracy i can predict the time that they're going to get there right that's that's their job that's",
    "start": "2210320",
    "end": "2216160"
  },
  {
    "text": "what they do so when they're done what we get as developers to deploy it is going to be a model and a list of what the feature",
    "start": "2216160",
    "end": "2222079"
  },
  {
    "text": "vector is that's it i just want to mention that there's a variety of things so this framework as i",
    "start": "2222079",
    "end": "2227920"
  },
  {
    "text": "mentioned before is is it's it's agnostic to what the what the machine learning model is what you do",
    "start": "2227920",
    "end": "2234240"
  },
  {
    "text": "you can use data scientists on your team can use any one of these that they want doesn't matter tensorflow they want to",
    "start": "2234240",
    "end": "2239280"
  },
  {
    "text": "use pandas they want to use r they use whatever the heck they want any model type any language toolkit they want",
    "start": "2239280",
    "end": "2244480"
  },
  {
    "text": "we're not going to have a restriction that says oh you can only use certain things they don't they they toss this model over to us and the features and",
    "start": "2244480",
    "end": "2250320"
  },
  {
    "text": "it's our job to handle it and we can handle any one of these things using this framework",
    "start": "2250320",
    "end": "2256320"
  },
  {
    "text": "i do that okay model training this is the hard part i'm going to trivialize it quite a bit",
    "start": "2256320",
    "end": "2261520"
  },
  {
    "text": "because i i don't know how to do it i'm not a data scientist but basically we all know this intuitive rate so we",
    "start": "2261520",
    "end": "2267440"
  },
  {
    "text": "have the set of features but until we know that some things have more have a greater impact on the on the on the on",
    "start": "2267440",
    "end": "2272960"
  },
  {
    "text": "the prediction than others right like the distance probably has a better weight than the average meal prep time or we don't know but you sort of say",
    "start": "2272960",
    "end": "2278880"
  },
  {
    "text": "they're all not weighted equally they all can't have the same impact on the precision of that and that's what training is they run through this",
    "start": "2278880",
    "end": "2284160"
  },
  {
    "text": "process of assigning a corresponding weight to every feature in the vector right so this one is point three and this one's",
    "start": "2284160",
    "end": "2290560"
  },
  {
    "text": "point eight and this one's one point two and that one's point zero one and that's sort of and that becomes the final thing",
    "start": "2290560",
    "end": "2296160"
  },
  {
    "text": "is a trained model actually has to have the weighted vector and that's what training does is generate a separate",
    "start": "2296160",
    "end": "2301440"
  },
  {
    "text": "weight assignment for each feature in the vector and they do that so",
    "start": "2301440",
    "end": "2307040"
  },
  {
    "text": "this is again this is my oversimplification how they do it but basically my understanding is that you know go back to historical data they",
    "start": "2307040",
    "end": "2312320"
  },
  {
    "text": "grab some random sample training data they push it through the model they compare the predictions with the actual",
    "start": "2312320",
    "end": "2317440"
  },
  {
    "text": "results and then they adjust that feature and they keep either just you know okay this feature doesn't work or we need another feature or we have to",
    "start": "2317440",
    "end": "2324000"
  },
  {
    "text": "add a weight to this one or we take a weight away from this one we adjust the weights until they get the prediction with the accuracy that that that they",
    "start": "2324000",
    "end": "2329599"
  },
  {
    "text": "actually want right and that's great and that trains the model for one particular set of data",
    "start": "2329599",
    "end": "2336000"
  },
  {
    "text": "here's sort of the problem with that right think about an international",
    "start": "2336000",
    "end": "2341359"
  },
  {
    "text": "business like uber eats and you're going to train a model with one data set and you pick that data set do you want to take data from new york",
    "start": "2341359",
    "end": "2348079"
  },
  {
    "text": "los angeles chicago london paris and train it on that because the",
    "start": "2348079",
    "end": "2353280"
  },
  {
    "text": "traffic conditions are different a lot of different environmental variables you can't account for right there's different things in a different time of",
    "start": "2353280",
    "end": "2359520"
  },
  {
    "text": "the day so what you really end up doing for something like complex like this is having a different suite",
    "start": "2359520",
    "end": "2365760"
  },
  {
    "text": "of models and you can differentiate by you know by region and or time of day and you end up",
    "start": "2365760",
    "end": "2370960"
  },
  {
    "text": "with this combination that goes back to the state store i mentioned before so when people need to rotate automatically a model and i don't want to take my my",
    "start": "2370960",
    "end": "2377119"
  },
  {
    "text": "machine learning model offline my pulse function offline i just inject a new model automatically rotate it in and say oh here's your new model because it's",
    "start": "2377119",
    "end": "2383680"
  },
  {
    "text": "trained differently because you can't train one model for every individual use case that's impossible data scientists tell you to you know",
    "start": "2383680",
    "end": "2390640"
  },
  {
    "text": "can't you just do it once no i can't you really have to adjust for this so this is sort of just hammering home that",
    "start": "2390640",
    "end": "2396079"
  },
  {
    "text": "point that there's there's going to be a rotation of models you deploy a function out on one edge you need to use this one",
    "start": "2396079",
    "end": "2401760"
  },
  {
    "text": "every time the day you need to rotate another one in the in the state store is how we're going to do that so finally i've been talking a lot this",
    "start": "2401760",
    "end": "2408560"
  },
  {
    "text": "is this is our part the developers part this is software development yeah we come in to save the day and be the champions and do that sort of thing so",
    "start": "2408560",
    "end": "2415280"
  },
  {
    "text": "the data scientists scientist team comes in and says hey we got this trained ml model we want you to do",
    "start": "2415280",
    "end": "2421440"
  },
  {
    "text": "uh right and so that's great we got we got to put all these pieces together that you handed us so okay what was the",
    "start": "2421440",
    "end": "2427200"
  },
  {
    "text": "training oh it's it's it's a it's a tensorflow model okay so now we know which library we need to use we include",
    "start": "2427200",
    "end": "2432480"
  },
  {
    "text": "that third bar library in the function oh what's the feature vector oh yeah this it's this this and this okay that",
    "start": "2432480",
    "end": "2437520"
  },
  {
    "text": "dictates what data we need to prep and we go back to the data engineering team and say where am i getting this data",
    "start": "2437520",
    "end": "2442560"
  },
  {
    "text": "from again how do i get this oh it's in cassandra somewhere in this table and i use this as a key great",
    "start": "2442560",
    "end": "2447920"
  },
  {
    "text": "so once we have those two pieces it's our job to put all those pieces together",
    "start": "2447920",
    "end": "2453280"
  },
  {
    "text": "and white pulse our functions are a good fit is because the again as i mentioned lubric talked about is the model can be",
    "start": "2453280",
    "end": "2458480"
  },
  {
    "text": "stored and shared inside the pulsar state store we don't have to go out and look up arbitrarily they can they can",
    "start": "2458480",
    "end": "2464000"
  },
  {
    "text": "push it to us and change it you know arbitrarily on the fly and we can get that information we can access it directly inside our runtime",
    "start": "2464000",
    "end": "2470640"
  },
  {
    "text": "uh we can leverage existing ml execution density right so these are again some java based ones but you know if you're",
    "start": "2470640",
    "end": "2476560"
  },
  {
    "text": "using python you can use pandas tensorflow you just pick the model you want grab that third-party library bundle",
    "start": "2476560",
    "end": "2482640"
  },
  {
    "text": "with your with your jar file that's it and then you can use that library just like you would any other piece of code",
    "start": "2482640",
    "end": "2487680"
  },
  {
    "text": "and the last part is the feature definition allows us to we use some pulsar functions to prep that data to do data access so",
    "start": "2487680",
    "end": "2494160"
  },
  {
    "text": "again if it's in a cassandra database we just create a pulsar function that's going to receive",
    "start": "2494160",
    "end": "2499280"
  },
  {
    "text": "that first piece of information and its job is to use an existing cassandra java python c-sharp library do a lookup",
    "start": "2499280",
    "end": "2506560"
  },
  {
    "text": "publish an output topic and here's your enriched data and that's it so everything there is is completely doable",
    "start": "2506560",
    "end": "2511760"
  },
  {
    "text": "and this is the power of the third-party library really so this is the four-step process right i",
    "start": "2511760",
    "end": "2517680"
  },
  {
    "text": "talked about this is the repeatable a generic how to deploy an ml execution thing right so retrieve the appropriate",
    "start": "2517680",
    "end": "2523760"
  },
  {
    "text": "train model makes sense okay that's easy we're getting it from the state store uh next you initialize the appropriate",
    "start": "2523760",
    "end": "2528880"
  },
  {
    "text": "execution engine right so the run time all these things you have to start up and warm up a little bit so that's a simple call you do it once you start it",
    "start": "2528880",
    "end": "2535200"
  },
  {
    "text": "up then you repeatedly steps three and four happen over and over again as the data starts flowing in",
    "start": "2535200",
    "end": "2541200"
  },
  {
    "text": "right one and two or sort of a initialization phase three and four is okay let's actually get to work and so",
    "start": "2541200",
    "end": "2546880"
  },
  {
    "text": "again that's again we retrieve the data for all the features defined in the model using a separate set of pulsar functions",
    "start": "2546880",
    "end": "2553040"
  },
  {
    "text": "which we'll talk about in a pipeline manner doing parallel and then you just pass that data in as expected just map",
    "start": "2553040",
    "end": "2558880"
  },
  {
    "text": "it in it's a real simple mapping function and you run them run the model and get the result this is it visually",
    "start": "2558880",
    "end": "2565599"
  },
  {
    "text": "right so again the original message comes in and that feature collection vector just shows that you can run multiple you might have to get data from",
    "start": "2565599",
    "end": "2571200"
  },
  {
    "text": "multiple different uh you know feature stores or other data sources like that you can run those in parallel",
    "start": "2571200",
    "end": "2578160"
  },
  {
    "text": "you take all that result and it's a pre pre-populated feature vector right so it's line for line you know what you know you have five different fields all",
    "start": "2578160",
    "end": "2584880"
  },
  {
    "text": "those fields are populated and it's in a schema that you know it's there so when you that particular so that event is",
    "start": "2584880",
    "end": "2590480"
  },
  {
    "text": "published then the machine learning model enable function reads that reset uh data from that topic and passes it in",
    "start": "2590480",
    "end": "2597680"
  },
  {
    "text": "line by line feature vector to the execution engine and it generates a prediction on the back door this is the data",
    "start": "2597680",
    "end": "2603920"
  },
  {
    "text": "science team here doing its thing and you know being the mad scientist and they're updating machine learning model and they arbitrarily decided through an",
    "start": "2603920",
    "end": "2610240"
  },
  {
    "text": "automated pipeline they want to publish a new thing to the state store we react to it we adjust and we have a new model and everything starts over again",
    "start": "2610240",
    "end": "2616960"
  },
  {
    "text": "the one you know obviously if they change the features they got to let us know that it sort of breaks things but in general if they're just doing some tuning of the weights not so much it'll",
    "start": "2616960",
    "end": "2623920"
  },
  {
    "text": "it'll just continue to work in our cases since you're rotating in the same model with different weights",
    "start": "2623920",
    "end": "2629359"
  },
  {
    "text": "for different you know regions and times a day it's not an impact for that that particular use case",
    "start": "2629359",
    "end": "2635440"
  },
  {
    "text": "so as i mentioned here you know one of the ways you can do it the state store stores everything is raw bytes so you",
    "start": "2635440",
    "end": "2641280"
  },
  {
    "text": "can you can serialize data transport like that this particular use case i decided to use pml which is like an xml",
    "start": "2641280",
    "end": "2646640"
  },
  {
    "text": "markup thing and you push it to the store it can be done through a rest call automatically as part of a pipeline so",
    "start": "2646640",
    "end": "2651680"
  },
  {
    "text": "once they test it and they validate it and it proves a certain you know threshold like their ml ops pipeline that's what",
    "start": "2651680",
    "end": "2656960"
  },
  {
    "text": "they do they put it in there they process the data achieves a prediction accuracy rate that they're okay with they go green flag release it to",
    "start": "2656960",
    "end": "2662960"
  },
  {
    "text": "production boom and the part of that pipeline they can just publish it out there so there's no it ties right into",
    "start": "2662960",
    "end": "2668160"
  },
  {
    "text": "the ml ops pipeline this is this is just showing you here if we can see it this is showing a",
    "start": "2668160",
    "end": "2673599"
  },
  {
    "text": "simplified one so this this includes the four fields that we needed right this is our feature vector so distance",
    "start": "2673599",
    "end": "2680319"
  },
  {
    "text": "uh last prep prep time last hour prep time the last seven days it tells us the function type it is it's",
    "start": "2680319",
    "end": "2685599"
  },
  {
    "text": "a linear regression model uh it calculates some intermediate things and it generates a couple",
    "start": "2685599",
    "end": "2690800"
  },
  {
    "text": "different numeric predictors right so travel time average prep time average delivery time",
    "start": "2690800",
    "end": "2695839"
  },
  {
    "text": "and so you can take that all that information and and then you publish it out and then how you want to act with it and and show it to the user you know",
    "start": "2695839",
    "end": "2702560"
  },
  {
    "text": "it's up to you can you can break it down line by line you can say your meal will be ready five minutes and then keep it there and then okay the driver's got it",
    "start": "2702560",
    "end": "2708960"
  },
  {
    "text": "and you can adjust to dynamically update it but all those things are predicted right",
    "start": "2708960",
    "end": "2714720"
  },
  {
    "text": "uh and as i mentioned before it can be uploaded this is a using again the pulsar admin wrapper tool",
    "start": "2714720",
    "end": "2720079"
  },
  {
    "text": "again this just fronts a rest api that's it i did not mention there's",
    "start": "2720079",
    "end": "2725280"
  },
  {
    "text": "concept of tenants and name spaces but that's where your functions they all have to be the takeaway is the pulsar function running should be running the",
    "start": "2725280",
    "end": "2731200"
  },
  {
    "text": "same tenant and namespace as you're deploying the state store it sort of limits the scope so not everybody can see everybody's data it's a pulsar's a",
    "start": "2731200",
    "end": "2738160"
  },
  {
    "text": "multi-tenant system meant to be used by multiple machines and so for multiple organizations within the group and so",
    "start": "2738160",
    "end": "2744079"
  },
  {
    "text": "that you just have to specify that those match where your pulsar functions is and then you can specify the state you give",
    "start": "2744079",
    "end": "2749440"
  },
  {
    "text": "it a key which is just a string in this case you just have a predefined thing okay this is my ml model and then you",
    "start": "2749440",
    "end": "2754800"
  },
  {
    "text": "put in the byte value and it's the raw contents of the pmml or it could be the raw binary bytes of",
    "start": "2754800",
    "end": "2759839"
  },
  {
    "text": "whether you're exported a tensorflow file or your pandas ss script pandas script or whatever you want boom just",
    "start": "2759839",
    "end": "2765520"
  },
  {
    "text": "publish it up there i've got it it's my final product that's it uh so next step two",
    "start": "2765520",
    "end": "2772079"
  },
  {
    "text": "initialize the thing so you'll notice here sitting inside this is it's the point back this is the process method right does this pulse our function this",
    "start": "2772079",
    "end": "2778560"
  },
  {
    "text": "is one method we have to implement we do everything here that's it so we're overriding it we've created a",
    "start": "2778560",
    "end": "2784880"
  },
  {
    "text": "food order ml type that is the feature vector that's a json schema that's specified so we know fields are going to",
    "start": "2784880",
    "end": "2790640"
  },
  {
    "text": "be in there uh and we're getting a food order ml we're just enriching this is enrichment the",
    "start": "2790640",
    "end": "2796400"
  },
  {
    "text": "food order comes in food order comes out we're enriching some data it's gonna be the same thing but with some no longer null values",
    "start": "2796400",
    "end": "2802400"
  },
  {
    "text": "uh but we have a blocker once the first thing you come in you check if you're initialized our initialized check says hey is my execution engine up and",
    "start": "2802400",
    "end": "2808079"
  },
  {
    "text": "running right i'm supposed to start this particular linear this regression model evaluator",
    "start": "2808079",
    "end": "2814160"
  },
  {
    "text": "if not go out to the state store and get me the pml file",
    "start": "2814160",
    "end": "2820160"
  },
  {
    "text": "okay great got it this is it this is all you got to do again with the library you just create because you know it's a",
    "start": "2820160",
    "end": "2825200"
  },
  {
    "text": "linear regression body say this is it you're going to run it and you're going to take this this i know this model would be xml data",
    "start": "2825200",
    "end": "2831359"
  },
  {
    "text": "on marshall it and this is your this is your model boom feed it and that's it it's a one-time call it parses the mpml",
    "start": "2831359",
    "end": "2837680"
  },
  {
    "text": "for you automatically and now you have an evaluator running inside your pulsar function and thread out on the edge",
    "start": "2837680",
    "end": "2842720"
  },
  {
    "text": "wherever you want to be it's there ready to go waiting for the next piece of data",
    "start": "2842720",
    "end": "2847760"
  },
  {
    "text": "right step number three i'm going to go back to that feature collection just to show you okay so the",
    "start": "2847760",
    "end": "2852960"
  },
  {
    "text": "data's coming in uh you know this as i mentioned before you can pipeline them right so we know the data coming in this is kind of comes",
    "start": "2852960",
    "end": "2858800"
  },
  {
    "text": "before the machine learning model but in the execution of the steps it doesn't so don't don't get confused but this",
    "start": "2858800",
    "end": "2863920"
  },
  {
    "text": "actually occurs first the original message comes in and says hey i want to order this food we've assigned it to a restaurant and so",
    "start": "2863920",
    "end": "2869920"
  },
  {
    "text": "now you can go and look up the restaurant id and make a current call maybe look up the distance you make another one to do these calculations",
    "start": "2869920",
    "end": "2876000"
  },
  {
    "text": "they all run in parallel they sync back together using like a rendezvous mechanism or something like that you have a sort of a state store",
    "start": "2876000",
    "end": "2882720"
  },
  {
    "text": "intermediate and then you publish that feature vector out you have all the data all the features collected boom you publish it to that topic and that's it",
    "start": "2882720",
    "end": "2888559"
  },
  {
    "text": "and you can use that those functions uh i'll talk about this this is i've alluded to earlier and this is the blog",
    "start": "2888559",
    "end": "2894559"
  },
  {
    "text": "i've talked about off often so this is not theory this is how uber does uh some of their optimizations",
    "start": "2894559",
    "end": "2901200"
  },
  {
    "text": "as well uh there and you can reference that if anyone wants it please reach out to me i'll give you that uh but they",
    "start": "2901200",
    "end": "2906800"
  },
  {
    "text": "rely on a feature store backed by apache cassandra it's the real-time very wide thing and they pre-calculate these",
    "start": "2906800",
    "end": "2912640"
  },
  {
    "text": "features for every individual restaurant so when i come in all i have to do is query i know it's been assigned to restaurant three",
    "start": "2912640",
    "end": "2918800"
  },
  {
    "text": "and i can get these features that have been pre-calculated automatically for me it's very wide you can have hundreds",
    "start": "2918800",
    "end": "2924160"
  },
  {
    "text": "of different values all pre-calculated but it's the takeaways is a constant time lookup i make this call with a",
    "start": "2924160",
    "end": "2929839"
  },
  {
    "text": "simple lookup call boom i have all the data back i need and i can pull back what i want and so this is showing you",
    "start": "2929839",
    "end": "2935599"
  },
  {
    "text": "how to do that right so i want to get the restaurant features to feed into my model so message comes",
    "start": "2935599",
    "end": "2941599"
  },
  {
    "text": "in customer made an order i've assigned it to restaurant one two three",
    "start": "2941599",
    "end": "2946800"
  },
  {
    "text": "boom i go out and i require that data this is again probably not best programming practices but just to show you i'm just selecting",
    "start": "2946800",
    "end": "2953119"
  },
  {
    "text": "is this a query i just pass in one value and since i'm going to a very fast data",
    "start": "2953119",
    "end": "2958559"
  },
  {
    "text": "store that's available over tcp connection which i have because i'm running on the iot gateway boom i'm gonna get this data back and then i just",
    "start": "2958559",
    "end": "2965119"
  },
  {
    "text": "populate it okay just read the value out done that's it i got it",
    "start": "2965119",
    "end": "2970640"
  },
  {
    "text": "so that's because it's hard to get this data you know that's why people do the processing up in the cloud because all",
    "start": "2970640",
    "end": "2975839"
  },
  {
    "text": "the data is there so this solves a problem of hey i have some of the data i've collected on the edge but i have to reach back and get some other stuff this",
    "start": "2975839",
    "end": "2982240"
  },
  {
    "text": "is how you do that and again it's very simple that's it that's the entirety of the function so pretty easy to test unit tests deploy",
    "start": "2982240",
    "end": "2989440"
  },
  {
    "text": "work just fine that's it last step finally run out of time so i apologize for i",
    "start": "2989440",
    "end": "2995200"
  },
  {
    "text": "told you i'd be long-winded so you stayed here under your volition but this is it so this is it this is",
    "start": "2995200",
    "end": "3000240"
  },
  {
    "text": "back to what i talked about so this is the initialized method we talked about earlier right this is the this is machine learning model enabled pulsar",
    "start": "3000240",
    "end": "3005760"
  },
  {
    "text": "function assuming we're initialized either way once you do the initialization you're done you create a feature vector this is",
    "start": "3005760",
    "end": "3011839"
  },
  {
    "text": "just a data holder that you have to pass into this particular model the model that you got we know is that",
    "start": "3011839",
    "end": "3018000"
  },
  {
    "text": "is that feature vector so we just pluck them off one by one okay for our feature vector putting into the data source we're just going to create this",
    "start": "3018000",
    "end": "3023920"
  },
  {
    "text": "particular one and we and we grab it out of our feature and that's it you just pass it over so the average prep time we get from the",
    "start": "3023920",
    "end": "3030000"
  },
  {
    "text": "feature vector average prep time last seven days the driver latitude the driver longitude the driver grid id the",
    "start": "3030000",
    "end": "3035760"
  },
  {
    "text": "customer grid id you just repeat it's just a simple process whatever vectors you need out you you've pre-prepped it",
    "start": "3035760",
    "end": "3040960"
  },
  {
    "text": "in the previous um topic you have all that data available and now it's just a one-to-one mapping into the format that that machine",
    "start": "3040960",
    "end": "3047440"
  },
  {
    "text": "learning model needs it that's it you can't you can't pass it hey here's a here's a json object to go what it needs",
    "start": "3047440",
    "end": "3053040"
  },
  {
    "text": "these certain things but that's it it's a simple very very simple basic mapping function",
    "start": "3053040",
    "end": "3058400"
  },
  {
    "text": "once you're done with all of that re-wrapping up the last bit of it because i had to break it into two lines",
    "start": "3058400",
    "end": "3064079"
  },
  {
    "text": "but still it's a very small function that's it you say okay evaluator which i've already initialized evaluate this",
    "start": "3064079",
    "end": "3069839"
  },
  {
    "text": "feature vector that i just populated and return to me the travel time of that predictor thing",
    "start": "3069839",
    "end": "3074960"
  },
  {
    "text": "and then i'll update this is my estimated time i just you know where i'm current time right now plus the travel time you estimate and that's it that's",
    "start": "3074960",
    "end": "3082559"
  },
  {
    "text": "all you have to do so in summary i've kept you here very",
    "start": "3082559",
    "end": "3087760"
  },
  {
    "text": "long y'all got a free book out of it though so you get a book you get a bookkeeper",
    "start": "3087760",
    "end": "3093280"
  },
  {
    "text": "apache pulsar can be used to create an execution environment for machine learning models on the edge that's",
    "start": "3093280",
    "end": "3098319"
  },
  {
    "text": "unique it's architectural differences make it so that you can push all this logic down i just showed you down as close to the events as possible",
    "start": "3098319",
    "end": "3105680"
  },
  {
    "text": "right now technologically based on those resource sizes right it has the mqtt protocols allows you to automatically at",
    "start": "3105680",
    "end": "3112000"
  },
  {
    "text": "least an iot thing uh receive those events in a native format again using pub sub model you",
    "start": "3112000",
    "end": "3117760"
  },
  {
    "text": "can't do that with a streaming platform so and then that when that arrives over that protocol you can immediately trigger that event",
    "start": "3117760",
    "end": "3124079"
  },
  {
    "text": "so the event comes in boom it gets published run it right away and this is a technology agnostic design pattern that you can use for anything",
    "start": "3124079",
    "end": "3129920"
  },
  {
    "text": "right so it's again those four steps uh it doesn't matter it's it's really agnostics of the underlying algorithm or",
    "start": "3129920",
    "end": "3135599"
  },
  {
    "text": "develop language uh in that way and you just you just repeat this process and you say hey i can deploy this machine",
    "start": "3135599",
    "end": "3142400"
  },
  {
    "text": "learning model on the edge of the pulsar function again they're great for online excuses i mentioned because they're closer to the",
    "start": "3142400",
    "end": "3148319"
  },
  {
    "text": "edge you can dynamically swap out the trained models as i mentioned which is kind of a big deal you don't think about hey i've",
    "start": "3148319",
    "end": "3153920"
  },
  {
    "text": "got one okay what about when i need to change it well not so much but here it's very easy with that state store it's a back door in",
    "start": "3153920",
    "end": "3160079"
  },
  {
    "text": "and you just look up that data or any other data and then again you could leverage an existing",
    "start": "3160079",
    "end": "3166000"
  },
  {
    "text": "execution engines frameworks third-party libraries for client lookups for retrieving the data from the feature vectors or from",
    "start": "3166000",
    "end": "3172480"
  },
  {
    "text": "the feature store for your feature vectors or for execution of your machine learning models and you don't impose any",
    "start": "3172480",
    "end": "3178319"
  },
  {
    "text": "limitation on data science saying hey we can only run models of this type no we can run anything you throw at us just",
    "start": "3178319",
    "end": "3183359"
  },
  {
    "text": "give it to us and we'll do it here so with that i'll stop talking other than say thank you for attending very",
    "start": "3183359",
    "end": "3189119"
  },
  {
    "text": "much here's our qr code if you want to scan it to get more information about apache pulsar about stream native about us",
    "start": "3189119",
    "end": "3196079"
  },
  {
    "text": "as i promised the code is available that's my github repo it is an entire based on the book so there's a 12",
    "start": "3196079",
    "end": "3202160"
  },
  {
    "text": "chapter book i have microservices based on everything from order entry uh the last couple chapters are focused on this",
    "start": "3202160",
    "end": "3208000"
  },
  {
    "text": "this uh this very topic about machine learning chapter 11 specifically all that code is there play with it comment",
    "start": "3208000",
    "end": "3214640"
  },
  {
    "text": "on it tell me how good it is how bad it is uh on that just want to mention uh if you want to",
    "start": "3214640",
    "end": "3220640"
  },
  {
    "text": "get learn more about apache pulsar we have online training uh you have some sessions and i was actually fortunate enough we have a",
    "start": "3220640",
    "end": "3226800"
  },
  {
    "text": "framework that allows you to as part of the training you can spin up an home vs code uh interactive shell",
    "start": "3226800",
    "end": "3232880"
  },
  {
    "text": "and you have a pulsar uh cluster running there right beside you and you just you know you use a you know c sharp and run",
    "start": "3232880",
    "end": "3238800"
  },
  {
    "text": "through the code and play with it all you want and it's there to use and it stays up for three days and it goes away but you get a new one so hey i want to",
    "start": "3238800",
    "end": "3244559"
  },
  {
    "text": "try pulsar but i don't i don't know kubernetes i don't know how i want to spend up a whole big thing just go there and start playing with it but also",
    "start": "3244559",
    "end": "3250559"
  },
  {
    "text": "docker we have a standalone docker image as well but it's don't let that be better if you want to go there it's all free",
    "start": "3250559",
    "end": "3255839"
  },
  {
    "text": "do some training highly recommend if you're interested in learning that if you want to come work on this cool stuff all kinds of jobs",
    "start": "3255839",
    "end": "3262720"
  },
  {
    "text": "like everybody we're hiring like everybody else and puzzle pieces last piece of the",
    "start": "3262720",
    "end": "3268000"
  },
  {
    "text": "puzzle you're missing i'll answer any questions you have thank you again for your time",
    "start": "3268000",
    "end": "3274400"
  }
]
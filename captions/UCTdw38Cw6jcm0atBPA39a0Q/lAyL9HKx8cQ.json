[
  {
    "text": "three o'clock let's look kubernetes and i want to get started fast and I'm gonna speak fast because I got way too much to",
    "start": "5250",
    "end": "12010"
  },
  {
    "text": "cover but I want to want to get it covered so that you understand it so I'm going to give it a little introduction",
    "start": "12010",
    "end": "17320"
  },
  {
    "text": "to kubernetes for developers I am NOT gonna look at any form of DevOps edci",
    "start": "17320",
    "end": "23499"
  },
  {
    "text": "stuff at all I want to show why kubernetes is interesting from or rather",
    "start": "23499",
    "end": "29499"
  },
  {
    "text": "how it's interesting for developers and what you need to know as a developer because you can't just build an",
    "start": "29499",
    "end": "35079"
  },
  {
    "text": "application and say awesome I have an app and now it's going to run in communities we need to know what",
    "start": "35079",
    "end": "40210"
  },
  {
    "text": "kubernetes is and how it works so my name is Chris Klug I work as a developer",
    "start": "40210",
    "end": "46600"
  },
  {
    "text": "at a company called active solution in Stockholm we do a bunch of cloud stuff that's all I'm going to say you don't",
    "start": "46600",
    "end": "52179"
  },
  {
    "text": "need to know any more about me I just need to say active solution one more time because they hate for me to go here already pay my salary while I'm here so",
    "start": "52179",
    "end": "59559"
  },
  {
    "text": "they're very nice to me but this is the important stuff docker so dr. is kind of the foundation of why I ended up doing",
    "start": "59559",
    "end": "66370"
  },
  {
    "text": "kubernetes and containerization in general seems to be really really popular right now however docker however",
    "start": "66370",
    "end": "73780"
  },
  {
    "text": "awesome it is has this limitation this is about what you can do with docker you can contain rates your application you",
    "start": "73780",
    "end": "79960"
  },
  {
    "text": "can say tell docker please can you run this limit the amount of memory limit the amount of CPU and if it ever fails",
    "start": "79960",
    "end": "86380"
  },
  {
    "text": "restart it that's it that is not quite good enough for a production application",
    "start": "86380",
    "end": "92290"
  },
  {
    "text": "we probably want to have more out of it and we could live with this but there",
    "start": "92290",
    "end": "97810"
  },
  {
    "text": "would be a lot of manual work involved so we need orchestration so I went",
    "start": "97810",
    "end": "103180"
  },
  {
    "text": "online and I googled orchestrate to get the definition of what it actually means and it says the first part a range or",
    "start": "103180",
    "end": "109990"
  },
  {
    "text": "SCORM use this plan or coordinate the elements of a situation to produce a",
    "start": "109990",
    "end": "115180"
  },
  {
    "text": "desired effect especially something I'm not even going to try to pronounce I am for Sweden that is kind of we want to",
    "start": "115180",
    "end": "124119"
  },
  {
    "text": "coordinate things we want to build like a micro services architecture potentially we want to orchestrate a",
    "start": "124119",
    "end": "129880"
  },
  {
    "text": "bunch of containers it's orchestration and then really cool when you google a word it gives you this little graph of",
    "start": "129880",
    "end": "136090"
  },
  {
    "text": "how much that word has been used recently and you look at the end there we're",
    "start": "136090",
    "end": "141780"
  },
  {
    "text": "hyping this now because nobody's really cared about it until sort of 1900s and then it got popular mid 1900s and then",
    "start": "141780",
    "end": "148950"
  },
  {
    "text": "at the end we're going to swing up again because we're doing containerization and orchestrating things awesome we are",
    "start": "148950",
    "end": "154860"
  },
  {
    "text": "doing the cool new stuff then I clicked on the graph and it looks like that we dropped off at the end so I'm too late",
    "start": "154860",
    "end": "160230"
  },
  {
    "text": "into technology again I don't really care that it's not the most latest and",
    "start": "160230",
    "end": "166050"
  },
  {
    "text": "the greatest but it's cool anyway so kubernetes is going to be what we're gonna cover here and I want to start",
    "start": "166050",
    "end": "174000"
  },
  {
    "text": "with an overview because kubernetes you can jump straight in and you can start hacking away on it and you can get it to",
    "start": "174000",
    "end": "179760"
  },
  {
    "text": "work probably with some introductions or demos and things like that but I do actually want to cover what kubernetes",
    "start": "179760",
    "end": "186030"
  },
  {
    "text": "is doing what are the building blocks involved in having kubernetes run what is kubernetes to me that made a lot of",
    "start": "186030",
    "end": "193530"
  },
  {
    "text": "sense it was a lot of reading and figuring out how things were put together and how they work because most people focus on how can i get my app",
    "start": "193530",
    "end": "200400"
  },
  {
    "text": "running on kubernetes not what does kubernetes actually do but I'm the kind",
    "start": "200400",
    "end": "205920"
  },
  {
    "text": "of person I want to know what it does so that when it fails I know how to fix it or abandon it and go somewhere else so",
    "start": "205920",
    "end": "213959"
  },
  {
    "text": "first of all we have machines you know let's start very very low level we're gonna have hardware the difference",
    "start": "213959",
    "end": "220500"
  },
  {
    "text": "between running your average application and real in kubernetes is that all of your machines are split into two groups",
    "start": "220500",
    "end": "226820"
  },
  {
    "text": "you generally splitting them something like this so there's going to be a few work master nodes so master nodes is",
    "start": "226820",
    "end": "234390"
  },
  {
    "text": "your what's called the control plane that's where you tell it what to do in",
    "start": "234390",
    "end": "239489"
  },
  {
    "text": "it orchestrates and get things running and it basically that's where you're kind of your logic lives and how you",
    "start": "239489",
    "end": "244980"
  },
  {
    "text": "control your cluster and then you have worker nodes I they used to be called",
    "start": "244980",
    "end": "250049"
  },
  {
    "text": "minions which is just so much better of a name I'm gonna pull up a new minion yes worker nodes or minions are",
    "start": "250049",
    "end": "257729"
  },
  {
    "text": "basically your machines that will run your workloads so you tell the master plane or the master nodes or the control",
    "start": "257729",
    "end": "263970"
  },
  {
    "text": "plane that I want to run these nodes and then they fear these containers and then",
    "start": "263970",
    "end": "269400"
  },
  {
    "text": "the they figure out how to get those containers spread across the different",
    "start": "269400",
    "end": "274530"
  },
  {
    "text": "worker nodes in your cluster so you get an even use of resources they figure out",
    "start": "274530",
    "end": "279540"
  },
  {
    "text": "if a node goes down and gets reschedule and so on so you've got those two different kinds of nodes unless you're",
    "start": "279540",
    "end": "286919"
  },
  {
    "text": "running in a cloud so if you're running on e KS o g KS or a KS which is Amazon",
    "start": "286919",
    "end": "293400"
  },
  {
    "text": "and Google and and after if you get as kubernetes service from any of those the",
    "start": "293400",
    "end": "299160"
  },
  {
    "text": "control plane is not going to be one of your machines so you don't have to put up your own machines for the master",
    "start": "299160",
    "end": "305220"
  },
  {
    "text": "nodes you've put up your your worker nodes but the master nodes is handed",
    "start": "305220",
    "end": "310290"
  },
  {
    "text": "handled by the provider for you so they will give you those that control level",
    "start": "310290",
    "end": "315570"
  },
  {
    "text": "but then you pay for your your actual nodes so the control plane the control",
    "start": "315570",
    "end": "321570"
  },
  {
    "text": "plane is is actually fairly simple but it took a little while at least for me I might be really dumb but it took me a",
    "start": "321570",
    "end": "327750"
  },
  {
    "text": "while to figure out what was actually happening so first of all desired state",
    "start": "327750",
    "end": "334070"
  },
  {
    "text": "with kubernetes and when you talk to the kubernetes cluster you actually don't",
    "start": "334070",
    "end": "339120"
  },
  {
    "text": "tell it that I want to run hey start up a container for me please start this container for me please do what you do",
    "start": "339120",
    "end": "345720"
  },
  {
    "text": "is you say I want this to be my desired state I would like there to be three",
    "start": "345720",
    "end": "350940"
  },
  {
    "text": "containers running at any point of time and then that's your desired state and then it's up to kubernetes to figure out",
    "start": "350940",
    "end": "357539"
  },
  {
    "text": "that your three container instances are always running and they're nicely spread across the different worker nodes so",
    "start": "357539",
    "end": "363930"
  },
  {
    "text": "it's all about desired state not about telling it do this do that so the very",
    "start": "363930",
    "end": "371039"
  },
  {
    "text": "very very high-level overview of this is this so the user comes in it has a",
    "start": "371039",
    "end": "378300"
  },
  {
    "text": "desired state configuration that desired state configuration which is generally",
    "start": "378300",
    "end": "383460"
  },
  {
    "text": "kept in a llam√≥ file it's pushed to a REST API so it's sent up to the REST API",
    "start": "383460",
    "end": "388740"
  },
  {
    "text": "if the connection is secure and all of that but basically you send it up to the REST API the REST API which is part of",
    "start": "388740",
    "end": "396240"
  },
  {
    "text": "your control plane takes that desire state configuration and puts it into a database",
    "start": "396240",
    "end": "401280"
  },
  {
    "text": "it's called etcd it's a key/value pair data store that's it",
    "start": "401280",
    "end": "406400"
  },
  {
    "text": "well and actually before I said that's kind of what your big part of your",
    "start": "406400",
    "end": "411419"
  },
  {
    "text": "control plan does when you do that it kind of ends there your interaction with kubernetes ends at that point once that",
    "start": "411419",
    "end": "419400"
  },
  {
    "text": "is in there there is something in the Incubus called the consume controller",
    "start": "419400",
    "end": "424530"
  },
  {
    "text": "manager that continuously asks the API or there any changes or there any has",
    "start": "424530",
    "end": "430560"
  },
  {
    "text": "anything happened and it will find out it will get that new desired state and it's gonna go yes somebody told me that",
    "start": "430560",
    "end": "436949"
  },
  {
    "text": "this is a new piece of states that we should handle and the cube controller manager or actually the scheduler",
    "start": "436949",
    "end": "443759"
  },
  {
    "text": "controller they're different there are quite a few different controllers running inside of it but you can see as",
    "start": "443759",
    "end": "448919"
  },
  {
    "text": "a controller as a piece of software that makes it just runs continuously in the cluster and the control plane to verify",
    "start": "448919",
    "end": "455039"
  },
  {
    "text": "that changes end up doing something so the scheduler controller will have a",
    "start": "455039",
    "end": "460530"
  },
  {
    "text": "look at your despite desired state configuration to figure out that hey you told me to run three instances of this",
    "start": "460530",
    "end": "466490"
  },
  {
    "text": "container it then asked the API for the nodes in the cluster basically how many",
    "start": "466490",
    "end": "473370"
  },
  {
    "text": "work your nodes do I have and what are their current workloads how much stuff",
    "start": "473370",
    "end": "478440"
  },
  {
    "text": "is running on them right now it figures out what nodes are relevant to run the new workloads so it basically assigns",
    "start": "478440",
    "end": "484530"
  },
  {
    "text": "different work node names to your desire state configuration and restore that",
    "start": "484530",
    "end": "489900"
  },
  {
    "text": "state configuration in storage again that's it if you can stop here if you",
    "start": "489900",
    "end": "497400"
  },
  {
    "text": "only have master nodes that's also going to happen you're gonna have stuff going in and out of a database that's it it",
    "start": "497400",
    "end": "504150"
  },
  {
    "text": "does not go around telling anything anybody to do anything at all it's just add stuff to database that's it then we",
    "start": "504150",
    "end": "511650"
  },
  {
    "text": "have the worker nodes that are responsible for actually running our toad or our workloads and if we look at",
    "start": "511650",
    "end": "518610"
  },
  {
    "text": "the worker knows they are just separate machines but they're in the same network as your control plane and they will be",
    "start": "518610",
    "end": "526320"
  },
  {
    "text": "running some form of container runtime most people look at this and go oh",
    "start": "526320",
    "end": "531750"
  },
  {
    "text": "kubernetes runs docker nope Cabrera's can run docker and by default runs docker but it doesn't actually",
    "start": "531750",
    "end": "538079"
  },
  {
    "text": "necessarily run you can run a few different container runtimes and they're also making that a",
    "start": "538079",
    "end": "543990"
  },
  {
    "text": "standard so now you can go and say I have a container runtime that adheres to",
    "start": "543990",
    "end": "549360"
  },
  {
    "text": "this API and then you can replace it so a couple of options would be to run instead of docker you can switch it out",
    "start": "549360",
    "end": "555029"
  },
  {
    "text": "for CR CR IO or container D container D also happens to be the runtime for",
    "start": "555029",
    "end": "561209"
  },
  {
    "text": "containers that runs inside of docker but it's a smaller version of docker without a bunch of stuff that you don't",
    "start": "561209",
    "end": "567029"
  },
  {
    "text": "need if you're not using docker as docker but you're using docker inside of a camera's cluster but basically you",
    "start": "567029",
    "end": "574170"
  },
  {
    "text": "have a container runtime that will run your containers it will do the work for you then your working out has something",
    "start": "574170",
    "end": "580589"
  },
  {
    "text": "called the cubelets accumulate it's a piece of code that runs on that worker node that knows how to talk to the",
    "start": "580589",
    "end": "588269"
  },
  {
    "text": "control plane so the cubelet continuously just as the worker the controllers on the worker know",
    "start": "588269",
    "end": "595670"
  },
  {
    "text": "masternodes was asking the api for changes the cubelet asks the control planer the rest api continuously is",
    "start": "595670",
    "end": "603240"
  },
  {
    "text": "there anything that should be scheduled on me is there anything that i should be running that I'm not running is there",
    "start": "603240",
    "end": "608550"
  },
  {
    "text": "anything I should be running now I'm not running over and over and over again until the control plane or the API goes",
    "start": "608550",
    "end": "614100"
  },
  {
    "text": "back and says yes you should be running this node as well we're sorry you should run in this container as well the cube",
    "start": "614100",
    "end": "620819"
  },
  {
    "text": "let then talks to the container runtime and tells to contain a runtime that hey can you please schedule these containers",
    "start": "620819",
    "end": "627300"
  },
  {
    "text": "and run them for me so kubernetes doesn't do anything but tell doctor what",
    "start": "627300",
    "end": "634620"
  },
  {
    "text": "to do or they contain a runtime so it's basically just a little managing thing that sits there and goes you want me to",
    "start": "634620",
    "end": "640079"
  },
  {
    "text": "run at least so many of these I'll figure out where to run them and then I'll make sure that they get scheduled",
    "start": "640079",
    "end": "645329"
  },
  {
    "text": "on that but it's still running in this case docker for example so I'm going to show you that when I run kubernetes on",
    "start": "645329",
    "end": "651209"
  },
  {
    "text": "my machine when I spin up a docker container inside my kubernetes cluster I can see that in the regular docker",
    "start": "651209",
    "end": "658199"
  },
  {
    "text": "commands on my machine so I can go and say dr. PS and actually see the running containers I can interact with them and",
    "start": "658199",
    "end": "663839"
  },
  {
    "text": "I can make changes to them kubernetes is just there on the side helping us out to make sure that they run as they should",
    "start": "663839",
    "end": "669660"
  },
  {
    "text": "and finally there's something called the cube see the cube proxy is a way to manage",
    "start": "669660",
    "end": "676290"
  },
  {
    "text": "communication inside the cluster so whenever you want to talk inside of the cluster between different containers you",
    "start": "676290",
    "end": "684240"
  },
  {
    "text": "end up with the situation that your calls gets proxied through a cube proxy to make sure that because you can't",
    "start": "684240",
    "end": "690449"
  },
  {
    "text": "really take a dependency and say I want to talk to point to container X because container X might or might not be there",
    "start": "690449",
    "end": "696839"
  },
  {
    "text": "between two different calls so to make that work it always proxies through a proxy server that can handle the changes",
    "start": "696839",
    "end": "703410"
  },
  {
    "text": "in the containers coming and going continuously that's it very high-level",
    "start": "703410",
    "end": "710220"
  },
  {
    "text": "introduction 11 minutes and I'm done with my talk I thought I'd actually give you some practical stuff as well so",
    "start": "710220",
    "end": "716550"
  },
  {
    "text": "we're going to look at the building blocks that we'll be building because the thing is there is little things there like little blocks that we",
    "start": "716550",
    "end": "722189"
  },
  {
    "text": "pull out and we go I need one of those I need one of those I need one of those we put them together like Legos and all the sudden we have a system kind of nice and",
    "start": "722189",
    "end": "729959"
  },
  {
    "text": "it's fast on top of that which is cool so the first thing I want to cover is the pod I have been talking about",
    "start": "729959",
    "end": "735929"
  },
  {
    "text": "running containers so far in my talk you don't actually run containers in",
    "start": "735929",
    "end": "741600"
  },
  {
    "text": "kubernetes you do under the hood so low level wise yes we are running containers",
    "start": "741600",
    "end": "747899"
  },
  {
    "text": "on worker nodes in the cluster but you cannot schedule a container or tell kubernetes to run a container you always",
    "start": "747899",
    "end": "754079"
  },
  {
    "text": "tell it to run a pod so a pod is the smallest unit that we can tell kubernetes to work with a pod contains",
    "start": "754079",
    "end": "762209"
  },
  {
    "text": "one or more containers that's about it it is perfectly fine to have a pod with",
    "start": "762209",
    "end": "768509"
  },
  {
    "text": "just one container in it but the pod is the smallest thing and the reason for a pod is that we often have this idea of",
    "start": "768509",
    "end": "775279"
  },
  {
    "text": "containers working together so if you put a container inside of the same pod",
    "start": "775279",
    "end": "780990"
  },
  {
    "text": "or multiple containers in the same pod they will all have the same IP address so they will share the same address",
    "start": "780990",
    "end": "787410"
  },
  {
    "text": "namespace but so they cannot expose the same port but they can you can have as many containers as you want inside the",
    "start": "787410",
    "end": "793829"
  },
  {
    "text": "pod and as long as none of them expose the same port as another container",
    "start": "793829",
    "end": "799139"
  },
  {
    "text": "you're good to go that's fine they also have the ability to communicate between",
    "start": "799139",
    "end": "804809"
  },
  {
    "text": "each other with inter-process communication so they can't communicate in a different way",
    "start": "804809",
    "end": "810840"
  },
  {
    "text": "than over the network like you normally would because they're kind of process together and they can share storage so",
    "start": "810840",
    "end": "818190"
  },
  {
    "text": "if you set up storage inside your pod you can have all the containers in your pod or some of them read this read and",
    "start": "818190",
    "end": "825090"
  },
  {
    "text": "write to the same storage which can be really really useful and then you basically schedule pods in your",
    "start": "825090",
    "end": "832470"
  },
  {
    "text": "application or in your communities cluster so it works one thing to note",
    "start": "832470",
    "end": "837480"
  },
  {
    "text": "sorry before I got in the slide it might seem obvious that certain thing oh I'm gonna put these containers together",
    "start": "837480",
    "end": "843980"
  },
  {
    "text": "remember when you combine containers into a pod remember that they scale",
    "start": "843980",
    "end": "849180"
  },
  {
    "text": "together it's not a matter of how do I want to basically put this into",
    "start": "849180",
    "end": "854640"
  },
  {
    "text": "production so more of a how do I want to scale this because it does scale together so it might seem obvious that",
    "start": "854640",
    "end": "860070"
  },
  {
    "text": "hey I'm gonna take my WordPress website and the database and I'm gonna put those",
    "start": "860070",
    "end": "866580"
  },
  {
    "text": "two containers in the same pod because they belong together so communication is going to be really quick between the database and the WordPress site right",
    "start": "866580",
    "end": "873870"
  },
  {
    "text": "until you start scaling up and you realize that you get one database per word precise site will work for instance",
    "start": "873870",
    "end": "880320"
  },
  {
    "text": "of your so load balancing that would be a bit of a fail because you'd basically",
    "start": "880320",
    "end": "886230"
  },
  {
    "text": "add things to one and it wouldn't be available in the other so every other time you refresh the webpage you would",
    "start": "886230",
    "end": "891630"
  },
  {
    "text": "get some data and then in some case you give some other data it would kind of be a failure of websites to be perfectly",
    "start": "891630",
    "end": "897390"
  },
  {
    "text": "honest but let's get a bit more practical so how do we work with this",
    "start": "897390",
    "end": "903990"
  },
  {
    "text": "now we know we have a pod and we can schedule container so we can run containers based on pods well first of",
    "start": "903990",
    "end": "911190"
  },
  {
    "text": "all how do we run it in our local machines well if we want to run it on our local machines you install docker",
    "start": "911190",
    "end": "916290"
  },
  {
    "text": "for desktop which is the easiest way to get up it works on Windows and Mac without a problem on Linux you can just",
    "start": "916290",
    "end": "924210"
  },
  {
    "text": "run the docker natively but on Windows and Mac you run this and then you go into the settings and you take that",
    "start": "924210",
    "end": "930210"
  },
  {
    "text": "little thing that says enable kubernetes and all the sudden your machine is now a one node kubernetes cluster with the",
    "start": "930210",
    "end": "937110"
  },
  {
    "text": "master node and the worker node being the same node which for production use is a big big big",
    "start": "937110",
    "end": "943550"
  },
  {
    "text": "no-no but for running locally on your machine trying stuff out it works fine",
    "start": "943550",
    "end": "949300"
  },
  {
    "text": "with that you also get this cool little command called cube CTL cube control or",
    "start": "949300",
    "end": "955700"
  },
  {
    "text": "my personal favorite cubby couple so Chemical is this tool that helps us talk",
    "start": "955700",
    "end": "961670"
  },
  {
    "text": "to the REST API we could build their own recipe API client but we'd have to",
    "start": "961670",
    "end": "967730"
  },
  {
    "text": "implement security so we need to implement authentication but other than that telling kubernetes to do something",
    "start": "967730",
    "end": "975050"
  },
  {
    "text": "is just a matter of posting or getting things in and out of a REST API that's it but cubby cuttle will do that for you",
    "start": "975050",
    "end": "981800"
  },
  {
    "text": "in a very very nice way and it's a very simple command cube CTL space whatever",
    "start": "981800",
    "end": "988340"
  },
  {
    "text": "you want to do I want to get something I want to delete something I want to create something and then the resource",
    "start": "988340",
    "end": "994280"
  },
  {
    "text": "type that you want to do so pod for example and then if you go with just that cube CT I'll get pods by the way",
    "start": "994280",
    "end": "1002410"
  },
  {
    "text": "the S at the end isn't mandatory actually you can go cube CTL don't get P",
    "start": "1002410",
    "end": "1008080"
  },
  {
    "text": "oh that's enough for it to figure out that you want pods and it will give you all the pods back that will give you a list of all running pods in your cluster",
    "start": "1008080",
    "end": "1014910"
  },
  {
    "text": "not quite but ish and this will give you a specific body this will give you the",
    "start": "1014910",
    "end": "1020980"
  },
  {
    "text": "information about the pod called my pod so now you know how to use chemical that's all you need if you want to",
    "start": "1020980",
    "end": "1028240"
  },
  {
    "text": "create something you can call the create command or most people just go with apply apply works both for creation and",
    "start": "1028240",
    "end": "1035890"
  },
  {
    "text": "updates so it's like a create update command and you call cube CTL apply dash",
    "start": "1035890",
    "end": "1041410"
  },
  {
    "text": "F telling it that I have a file and here is my Yama file that contains my configuration and you just call that and",
    "start": "1041410",
    "end": "1048670"
  },
  {
    "text": "all the sudden there is some stuff running in your cluster piece of cake it also has one other cool feature and",
    "start": "1048670",
    "end": "1055720"
  },
  {
    "text": "that is port forwarding the problem are not the problem but one of the things with the way that kubernetes and also",
    "start": "1055720",
    "end": "1062409"
  },
  {
    "text": "docker works to be honest is that everything you put in to kubernetes works in its own networks namespace",
    "start": "1062409",
    "end": "1068529"
  },
  {
    "text": "network area right so it's a separate network from your local machine even though I'm running docker for win the",
    "start": "1068529",
    "end": "1074230"
  },
  {
    "text": "docker for desktop on my machine docker actually runs currently in this version",
    "start": "1074230",
    "end": "1079320"
  },
  {
    "text": "inside of an Linux VM that runs in hyper-v so it runs in a completely",
    "start": "1079320",
    "end": "1084400"
  },
  {
    "text": "separate thing so I can't just go and say hey go to my browser and go localhost port 80 and it's gonna hit my",
    "start": "1084400",
    "end": "1091029"
  },
  {
    "text": "container that's just the way it works so what cubby cuttle offers is port",
    "start": "1091029",
    "end": "1096130"
  },
  {
    "text": "forwarding so what we can say here is hey cube CTL can you please port forward port 8080 on my local machine to port 80",
    "start": "1096130",
    "end": "1105390"
  },
  {
    "text": "inside of the pod called my pod and then while that is",
    "start": "1105390",
    "end": "1110980"
  },
  {
    "text": "running it looks this basically looks the thread or not while that is running you can then go to your browser and just",
    "start": "1110980",
    "end": "1116200"
  },
  {
    "text": "go it should be colon slash slash look HTTP localhost port 8080 and you go straight into it and it's so cool it's",
    "start": "1116200",
    "end": "1123429"
  },
  {
    "text": "actually transparent enough that I've done this talk once before a couple of times before but I did it in Stockholm",
    "start": "1123429",
    "end": "1129429"
  },
  {
    "text": "and I did the whole talk there's one little demo that failed I couldn't explain why I couldn't see a container",
    "start": "1129429",
    "end": "1136360"
  },
  {
    "text": "running in my cluster in my local docker stuff so I went docker PS and I couldn't see my container and I was like weird",
    "start": "1136360",
    "end": "1142720"
  },
  {
    "text": "I don't know quite why probably some weird configuration thing and then I realized the day after that I had run my",
    "start": "1142720",
    "end": "1149500"
  },
  {
    "text": "entire presentation in a cluster in Asscher instead of my local machine because I'd forgotten to switch clusters",
    "start": "1149500",
    "end": "1155620"
  },
  {
    "text": "but with port forwarding it doesn't matter if I'm port forwarding locally on my machine or I'm port forwarding into a",
    "start": "1155620",
    "end": "1162039"
  },
  {
    "text": "data center in Ireland where my cluster is running it just it just works which",
    "start": "1162039",
    "end": "1169360"
  },
  {
    "text": "was really really cool to me at least so how do we create a pod I have a bit",
    "start": "1169360",
    "end": "1175899"
  },
  {
    "text": "of code here so I have this simple stupid application the application",
    "start": "1175899",
    "end": "1182250"
  },
  {
    "text": "so I didn't want to show you any code because I thought that was too complicated for you so I it's kind of",
    "start": "1185150",
    "end": "1192240"
  },
  {
    "text": "wondering everything else works did I screw something up this is when I wish I",
    "start": "1192240",
    "end": "1200130"
  },
  {
    "text": "could tap dance or sing or something to entertain you while he was fixing it but trust me you don't want to hear me sing",
    "start": "1200130",
    "end": "1208790"
  },
  {
    "text": "something ah there it is yes what did I",
    "start": "1210740",
    "end": "1216240"
  },
  {
    "text": "do something wrong it's fine don't worry about it that is that is a VTech code",
    "start": "1216240",
    "end": "1224669"
  },
  {
    "text": "for yes you idiot you did but I fixed it okay there is an app in here the app is",
    "start": "1224669",
    "end": "1232500"
  },
  {
    "text": "just a pure a spirit that core application it doesn't what it does it's not important the code is here and you",
    "start": "1232500",
    "end": "1239400"
  },
  {
    "text": "can download that code if you want to have a look at it it's on github I think otherwise I'll put it there so I have",
    "start": "1239400",
    "end": "1245160"
  },
  {
    "text": "this thing and if you want to run a pod you can either do that which I guess it's a bit small for you to raid in the",
    "start": "1245160",
    "end": "1250440"
  },
  {
    "text": "bank you could go and do this cube CTL",
    "start": "1250440",
    "end": "1256740"
  },
  {
    "text": "run generator run - pod slash v1 web app image blah blah blah and if you do that",
    "start": "1256740",
    "end": "1263100"
  },
  {
    "text": "it will start a pod for you without you having to create a Yama file I have done this command exactly once in my entire",
    "start": "1263100",
    "end": "1270030"
  },
  {
    "text": "career and that is because I want to see if it worked after that we don't do that",
    "start": "1270030",
    "end": "1275549"
  },
  {
    "text": "anymore because what we want to do is we want to create these files instead so this is a Yama file that defines a pod so it",
    "start": "1275549",
    "end": "1283410"
  },
  {
    "text": "defines what I want to run inside of my pod and it starts out with saying what",
    "start": "1283410",
    "end": "1288450"
  },
  {
    "text": "API version am I using me one there are a bunch of different ones depending on the resource type you're creating you",
    "start": "1288450",
    "end": "1294000"
  },
  {
    "text": "need to figure out what API version you're in whatever what you do is you go to Google and you go kubernetes pod",
    "start": "1294000",
    "end": "1300750"
  },
  {
    "text": "Yambol example and then you take that and you copy it and then you modify to what you need that's what I do at least",
    "start": "1300750",
    "end": "1306169"
  },
  {
    "text": "it works perfectly fine unless you can remember all the different versions in your head you tell it what kind it is",
    "start": "1306169",
    "end": "1312840"
  },
  {
    "text": "it's a pod and you give you some metadata in this case I'm giving it the name web app so",
    "start": "1312840",
    "end": "1318060"
  },
  {
    "text": "that's the way that if I want to go and look at it I can go cube CTL get and then web app and it will give me my or get pulled web app I have some labels",
    "start": "1318060",
    "end": "1325530"
  },
  {
    "text": "I'll get back to labels later on ignore it there's a spec in here so this",
    "start": "1325530",
    "end": "1330600"
  },
  {
    "text": "specification tells the system for this pod what is it that I really want to",
    "start": "1330600",
    "end": "1336600"
  },
  {
    "text": "want to run and in this case I'm telling it I want to run one container it's going to be cold",
    "start": "1336600",
    "end": "1341910"
  },
  {
    "text": "web app name of the container doesn't really matter that much I give it a so",
    "start": "1341910",
    "end": "1348390"
  },
  {
    "text": "this is the docker image I want to run right now I'm hosting it in my sure come Redis or a docker container registry or",
    "start": "1348390",
    "end": "1357660"
  },
  {
    "text": "image registry and I tell its image pool policy is just when you pull this",
    "start": "1357660",
    "end": "1364710"
  },
  {
    "text": "because urine I'm not gonna be responsible for doing the pulling so I'm not going to go docker pool instead the kubernetes is going to do it for us or",
    "start": "1364710",
    "end": "1370230"
  },
  {
    "text": "the cubelet is going to tell kubernetes to do it I want to tell it to make sure that that happens at a reasonable time",
    "start": "1370230",
    "end": "1376350"
  },
  {
    "text": "so always is good because you don't end up with if you do things like pushing",
    "start": "1376350",
    "end": "1381540"
  },
  {
    "text": "the same image with the same name and the same tags for example then always we'll sort that out I might have done",
    "start": "1381540",
    "end": "1387810"
  },
  {
    "text": "that once or twice so doing it always kind of solves you from that problem but you can also tell it to only pool if",
    "start": "1387810",
    "end": "1393390"
  },
  {
    "text": "it's not available and so on so it can be a bit optimized then you tell it what ports you want to bind so I want to have",
    "start": "1393390",
    "end": "1399000"
  },
  {
    "text": "port 80 on my container so basically give me a port 80 bound to my pod resources I'm gonna tell it that just as",
    "start": "1399000",
    "end": "1405900"
  },
  {
    "text": "I can with docker that you don't get to use more than I need 64 Meg's of memory",
    "start": "1405900",
    "end": "1411000"
  },
  {
    "text": "and I need a quarter of the core this CPU thing depends on where you're deploying it if you're deploying in an",
    "start": "1411000",
    "end": "1417950"
  },
  {
    "text": "local hardware with an Intel processor this I think means a quarter of an a",
    "start": "1417950",
    "end": "1423630"
  },
  {
    "text": "hyper thread but if you pull it push it to a sure it becomes a quarter of a virtual core so it kind of depends on",
    "start": "1423630",
    "end": "1430050"
  },
  {
    "text": "where you end up but it's a resource limitation saying I need at least a quarter of a core and for memory I'm",
    "start": "1430050",
    "end": "1435720"
  },
  {
    "text": "also saying that I'm not allowed to use more than hundred twenty-eight Meg's if you go about 128 Meg's you're doing",
    "start": "1435720",
    "end": "1441300"
  },
  {
    "text": "something wrong kill the container and restart it for me and the same thing for CPU if you use more than half a cord on",
    "start": "1441300",
    "end": "1447130"
  },
  {
    "text": "it's actually going to go above this in some cases and it would probably want to get killed but I'm trying to limit the",
    "start": "1447130",
    "end": "1452720"
  },
  {
    "text": "CPS as well one thing to note here if you start doing this locally and you have a little micro-services",
    "start": "1452720",
    "end": "1458659"
  },
  {
    "text": "architecture that you want to run on your machine and you give every little service a quarter of the core very very",
    "start": "1458659",
    "end": "1464750"
  },
  {
    "text": "fast you realize that you don't have a lot of course on your machine and it stops deploying stuff for you so these",
    "start": "1464750",
    "end": "1470899"
  },
  {
    "text": "limits are great to have in production when you're running on your local machine this will kind of kill you once",
    "start": "1470899",
    "end": "1476299"
  },
  {
    "text": "you get into up to a few pods on your machine and finally since there's",
    "start": "1476299",
    "end": "1481340"
  },
  {
    "text": "security involved I need to tell kubernetes how to pull my image I've",
    "start": "1481340",
    "end": "1486980"
  },
  {
    "text": "told it that the image is available at Kate's for devs dahshur CR dot io but",
    "start": "1486980",
    "end": "1492200"
  },
  {
    "text": "that is a private repo so I need to give it credentials and normally you would do docker login rights but once again we",
    "start": "1492200",
    "end": "1498289"
  },
  {
    "text": "are not pulling it courtesies so the way that we tell kubernetes to pull an image",
    "start": "1498289",
    "end": "1503360"
  },
  {
    "text": "that is in the private repo is that we give it we put a secret which is a username and a password inside of the",
    "start": "1503360",
    "end": "1509990"
  },
  {
    "text": "cluster and then we tell the cluster that you can find the username and password in a secret cold case for devs and then that is inside of your cluster",
    "start": "1509990",
    "end": "1517100"
  },
  {
    "text": "so that whenever I push a pod or apply a pod it will go and use those credentials",
    "start": "1517100",
    "end": "1522409"
  },
  {
    "text": "for my access so having that up we can go out here I'm in that same folder who",
    "start": "1522409",
    "end": "1529010"
  },
  {
    "text": "will do a cube CTL apply - eff like that",
    "start": "1529010",
    "end": "1535149"
  },
  {
    "text": "open this up so remember what to do it's up and running we do cube CTL gets pods",
    "start": "1535149",
    "end": "1543320"
  },
  {
    "text": "you can see that there is a one pod up here there's one out of one ready because I'd only put up one pot it is",
    "start": "1543320",
    "end": "1549980"
  },
  {
    "text": "running it has zero restarts and it was 8 seconds since I started it when I did the get command then we can say cube CTL",
    "start": "1549980",
    "end": "1557919"
  },
  {
    "text": "port - for 4 forward web app 8080 port",
    "start": "1557919",
    "end": "1565700"
  },
  {
    "text": "80 like that it looks up here and if I pull up my browser we go localhost port",
    "start": "1565700",
    "end": "1575510"
  },
  {
    "text": "not that port 8080 that is my application up and running if I go out",
    "start": "1575510",
    "end": "1582770"
  },
  {
    "text": "here and I killed my port forwarding I try to refresh this it doesn't respond so I'm not faking this I was actually",
    "start": "1582770",
    "end": "1589190"
  },
  {
    "text": "talking to my pod and also kind of interesting or not interesting but",
    "start": "1589190",
    "end": "1594980"
  },
  {
    "text": "interest semi interesting is that is my",
    "start": "1594980",
    "end": "1601130"
  },
  {
    "text": "pod running in docker so once again kubernetes is not something that is separate from anything else is it just",
    "start": "1601130",
    "end": "1607460"
  },
  {
    "text": "automates creation of things in my code docker container runtime which means that since this docker container runtime",
    "start": "1607460",
    "end": "1614840"
  },
  {
    "text": "is running on my machine I can see all the pods that are up and running or all the containers in different pods running",
    "start": "1614840",
    "end": "1620929"
  },
  {
    "text": "on my machine at the moment we'll do cube CTL delete hold",
    "start": "1620929",
    "end": "1629570"
  },
  {
    "text": "web app and",
    "start": "1629570",
    "end": "1632380"
  },
  {
    "text": "now it's gone nope that would have been cool if that worked there it is now it's",
    "start": "1634880",
    "end": "1641270"
  },
  {
    "text": "gone there is a graceful shutdown period for docker images or docker containers so a nice turret that core application",
    "start": "1641270",
    "end": "1648890"
  },
  {
    "text": "does take a few seconds through to basically die that is running a pod that's as simple as lit that's it takes",
    "start": "1648890",
    "end": "1654860"
  },
  {
    "text": "a few seconds to get started with with runaway kubernetes on your machine installed aquifer desktop take that little box and you're up and running",
    "start": "1654860",
    "end": "1660620"
  },
  {
    "text": "with doing at least pods to begin with however you should never create pods like that like I just did so why did I",
    "start": "1660620",
    "end": "1668120"
  },
  {
    "text": "show you I don't know it's up felt like a good place to start and it's the thing you do you often pull up a pod just to",
    "start": "1668120",
    "end": "1673580"
  },
  {
    "text": "see that stuff works but we shouldn't use pods manually because if you do if you want to do a load balanced",
    "start": "1673580",
    "end": "1680030"
  },
  {
    "text": "environment then you're kind of screwed because now if you want to have two pods two instances running you will have to",
    "start": "1680030",
    "end": "1686750"
  },
  {
    "text": "do under view cube cube CTL apply you're gonna have two different yeah Mel files because they do need to have different",
    "start": "1686750",
    "end": "1692510"
  },
  {
    "text": "names because otherwise it's just gonna be considered an update to the previous one so you need one Yama file for each",
    "start": "1692510",
    "end": "1698750"
  },
  {
    "text": "instance of your pod that you want to run and then you have to cross your fingers that they are put on two",
    "start": "1698750",
    "end": "1703970"
  },
  {
    "text": "different worker nodes because if you put if you decide that you want to have three replicas having three replicas on",
    "start": "1703970",
    "end": "1710090"
  },
  {
    "text": "one node is just dumb so you want to use something called a replica set no the",
    "start": "1710090",
    "end": "1717590"
  },
  {
    "text": "picture has nothing to do with the topic but it was a cute picture but before we",
    "start": "1717590",
    "end": "1723020"
  },
  {
    "text": "can get started repping assets is basically a way for me to deploy something to my Kumaresh cluster and say",
    "start": "1723020",
    "end": "1729170"
  },
  {
    "text": "I want to have a set of replicas and I want to have four instances running for",
    "start": "1729170",
    "end": "1735560"
  },
  {
    "text": "example and if you don't find four instances then please spin up enough to see that there are four instances but if",
    "start": "1735560",
    "end": "1742910"
  },
  {
    "text": "there are more than four instances please go and kill the ones that shouldn't be there however before we get",
    "start": "1742910",
    "end": "1748460"
  },
  {
    "text": "started there's one thing we can need to figure out because just getting started with replicas sets without thinking it's",
    "start": "1748460",
    "end": "1753920"
  },
  {
    "text": "bad it's gonna end up with that we need to understand labels I mentioned when",
    "start": "1753920",
    "end": "1760010"
  },
  {
    "text": "you saw my pod that there in my pod llaman there was a little labels thing that I said you should ignore labels are",
    "start": "1760010",
    "end": "1766550"
  },
  {
    "text": "really cool because anything in kubernetes any resource that you create in kubernetes can have a",
    "start": "1766550",
    "end": "1772720"
  },
  {
    "text": "label or multiple labels labels are literally key value pairs in strings so",
    "start": "1772720",
    "end": "1777940"
  },
  {
    "text": "it's a key and a value they're both strings you can add them to your metadata for your resource and then you",
    "start": "1777940",
    "end": "1784360"
  },
  {
    "text": "can use that to find different things if you have 600 pods running in your cluster you can go and say please get",
    "start": "1784360",
    "end": "1790960"
  },
  {
    "text": "all the pods where the label x equals y okay why is this important because",
    "start": "1790960",
    "end": "1797169"
  },
  {
    "text": "that's the way the replica sets work replica sets don't own any pods at all",
    "start": "1797169",
    "end": "1803799"
  },
  {
    "text": "so when you create a replica set they don't own any pods when they create a new pod they don't own it so it may",
    "start": "1803799",
    "end": "1811960"
  },
  {
    "text": "instead what they do is they have a label selector that basically says I want to have at least X amount of pods",
    "start": "1811960",
    "end": "1819149"
  },
  {
    "text": "running in my cluster with the corresponding set of labels that allows",
    "start": "1819149",
    "end": "1825250"
  },
  {
    "text": "us to do be very very flexible because I don't tell you how you need to organize",
    "start": "1825250",
    "end": "1830799"
  },
  {
    "text": "your pods and the labels and how to find them and everything it's up to you you can do whatever scheme you want it's",
    "start": "1830799",
    "end": "1836080"
  },
  {
    "text": "really really flexible and very simple it also means that if you set up a pod",
    "start": "1836080",
    "end": "1842620"
  },
  {
    "text": "on your own with basically just sort a pod for me and you happen to have the",
    "start": "1842620",
    "end": "1848980"
  },
  {
    "text": "same label set that that your replica set requires if you add a replica set after the fact that you created your pod",
    "start": "1848980",
    "end": "1856179"
  },
  {
    "text": "first your replica set will adopt that pod because it just happens to have the same label set it doesn't really care",
    "start": "1856179",
    "end": "1862480"
  },
  {
    "text": "whether or not it is the same pod it will just adopt that thing and if it",
    "start": "1862480",
    "end": "1867669"
  },
  {
    "text": "doesn't find and enough pods with that label set that you've told it or that",
    "start": "1867669",
    "end": "1872679"
  },
  {
    "text": "label selector it will go and create new pods based on the specification that",
    "start": "1872679",
    "end": "1877899"
  },
  {
    "text": "you've told it basically a template saying here is my pod template if you don't find enough pods this is the",
    "start": "1877899",
    "end": "1883840"
  },
  {
    "text": "template you should use so if you look at that it looks like it looks like this",
    "start": "1883840",
    "end": "1890470"
  },
  {
    "text": "know the role it looks like replicas said there it is it looks like",
    "start": "1890470",
    "end": "1897810"
  },
  {
    "text": "this so a replica set is inverse API version app / v1 it's called a replica",
    "start": "1897810",
    "end": "1904080"
  },
  {
    "text": "set when you're doing cube CTL or cube control you can call it RS instead of",
    "start": "1904080",
    "end": "1909180"
  },
  {
    "text": "replica set because replica set is really long you give it a name you give it a label this label here is just",
    "start": "1909180",
    "end": "1916280"
  },
  {
    "text": "information about my replica set has nothing to do with other labels I was talking about this is just a way for me",
    "start": "1916280",
    "end": "1922470"
  },
  {
    "text": "to find replica sets based on labels if I wanted to do and here is my",
    "start": "1922470",
    "end": "1927570"
  },
  {
    "text": "specification for my replica sets I want to run three instances of my pod and the",
    "start": "1927570",
    "end": "1933870"
  },
  {
    "text": "selector is this match labels I want to have three pods in my applicator in my",
    "start": "1933870",
    "end": "1941340"
  },
  {
    "text": "cluster running that has the label app set to web if you don't find three",
    "start": "1941340",
    "end": "1950100"
  },
  {
    "text": "replicas with that here is a pod template this part here from row 13 and",
    "start": "1950100",
    "end": "1955410"
  },
  {
    "text": "down is an exact copy of the podium all I just showed you for for the pod is just you put one level on top of it and",
    "start": "1955410",
    "end": "1963300"
  },
  {
    "text": "obviously the label set for your template has to correspond to your label",
    "start": "1963300",
    "end": "1969720"
  },
  {
    "text": "selector because if it didn't it would mean that hey I can't find enough pods",
    "start": "1969720",
    "end": "1976040"
  },
  {
    "text": "schedule a new pod hey I can't find enough pods schedule a new pod hey I can't find a pod schedule it's gonna",
    "start": "1976040",
    "end": "1982740"
  },
  {
    "text": "suck and also there is built-in security for that so if you try I did the other",
    "start": "1982740",
    "end": "1988680"
  },
  {
    "text": "day and by mistake it actually tells you that they don't correspond so it's not gonna work so it's gonna fail when you",
    "start": "1988680",
    "end": "1994260"
  },
  {
    "text": "try to but if I take this here we go back out here we go to my replica sets",
    "start": "1994260",
    "end": "1999930"
  },
  {
    "text": "we do cube CTL apply - eff that that",
    "start": "1999930",
    "end": "2006080"
  },
  {
    "text": "goes up we do a cube CTL get all so get all will give you all resources which is",
    "start": "2006080",
    "end": "2011690"
  },
  {
    "text": "not true at all it will give you all of your pods and your services and your",
    "start": "2011690",
    "end": "2016880"
  },
  {
    "text": "replica sets and a few other things but it won't actually give you all resources there's a limited set that you get back but this is the important interesting",
    "start": "2016880",
    "end": "2023630"
  },
  {
    "text": "part that I want to say replica set desire the three turn three ready three age four seconds",
    "start": "2023630",
    "end": "2030390"
  },
  {
    "text": "so I know that they're all up and running and I can see there are three pods up here running the cool thing here",
    "start": "2030390",
    "end": "2035909"
  },
  {
    "text": "is that if we do this we do that and we start another one of these we put that",
    "start": "2035909",
    "end": "2043710"
  },
  {
    "text": "on the side there that we do CLS there we can go and do that was not what I",
    "start": "2043710",
    "end": "2051658"
  },
  {
    "text": "wanted cube CTL get towards - - I",
    "start": "2051659",
    "end": "2059690"
  },
  {
    "text": "thought I want to show you something I did there it is - - watch this is going to show me pods",
    "start": "2059780",
    "end": "2067230"
  },
  {
    "text": "but it's also going to stay here so you see it locks up the terminal what it does it watches for changes if I go back",
    "start": "2067230",
    "end": "2073349"
  },
  {
    "text": "out here and we say cubes CTL get pods I could spell I'm so Sweden I can't",
    "start": "2073349",
    "end": "2082378"
  },
  {
    "text": "spell cube see cube CTL deletes pod and",
    "start": "2082379",
    "end": "2089010"
  },
  {
    "text": "we want the pod let's take that pod you are gonna die my friend there it is as I",
    "start": "2089010",
    "end": "2097440"
  },
  {
    "text": "killed that pod you can see on this side here my pod went into terminating States",
    "start": "2097440",
    "end": "2103130"
  },
  {
    "text": "once that goes into terminating States all of a sudden there's a new one that",
    "start": "2103130",
    "end": "2108240"
  },
  {
    "text": "basically spins up straight away so that goes into terminating that goes it depending then creating terminating",
    "start": "2108240",
    "end": "2113820"
  },
  {
    "text": "terminating terminating running and now if I go and look at the end result of that",
    "start": "2113820",
    "end": "2120650"
  },
  {
    "text": "I really cannot get this right yes I know said alias K which is awesome",
    "start": "2123890",
    "end": "2130670"
  },
  {
    "text": "because you don't have to write cubes here but I wanted everybody to see that I'm typing cubed CTL all the time and not K but there in the end this is what",
    "start": "2130670",
    "end": "2138560"
  },
  {
    "text": "we are noting as you can see the t44 FM has been transformed into another poll",
    "start": "2138560",
    "end": "2144860"
  },
  {
    "text": "so whenever I kill a pod and not the pod gets added if I were to manually create another pod it would kill that pod for",
    "start": "2144860",
    "end": "2152030"
  },
  {
    "text": "me and the replica set basically keeps everything in check for me and if you",
    "start": "2152030",
    "end": "2157490"
  },
  {
    "text": "ever want to remove a pod from a replica set for example you have a misbehaving",
    "start": "2157490",
    "end": "2162590"
  },
  {
    "text": "pod that you don't want to kill you want to debug it you just go in and you update that pod and rename change the",
    "start": "2162590",
    "end": "2168800"
  },
  {
    "text": "label select save label set for it so that it doesn't fit into the replica set anymore then all of a sudden your",
    "start": "2168800",
    "end": "2174200"
  },
  {
    "text": "replica set is going to spin up a new pod to replace the one that just died or disappeared and you can keep on",
    "start": "2174200",
    "end": "2179870"
  },
  {
    "text": "debugging your pod that was misbehaving for example but now we have a problem",
    "start": "2179870",
    "end": "2186220"
  },
  {
    "text": "because now we have multiple pods and we",
    "start": "2186220",
    "end": "2191810"
  },
  {
    "text": "want to be able to load balanced them but we cannot talk to them right now",
    "start": "2191810",
    "end": "2196880"
  },
  {
    "text": "because now we have multiple pods that are coming and going so I don't have an end point to communicate with and that's",
    "start": "2196880",
    "end": "2202280"
  },
  {
    "text": "why we need something called services so a service in a kubernetes it's a really",
    "start": "2202280",
    "end": "2208730"
  },
  {
    "text": "weird thing it doesn't actually create anything it's a resource you create in your cluster that says I want to have a",
    "start": "2208730",
    "end": "2216380"
  },
  {
    "text": "unique end point in my cluster that I can call and it will then use that to",
    "start": "2216380",
    "end": "2223100"
  },
  {
    "text": "figure out what pods I should be targeting and load balance across the pods that matches the services once",
    "start": "2223100",
    "end": "2229610"
  },
  {
    "text": "again label selector so late a service is basically a fixed point where I can",
    "start": "2229610",
    "end": "2234920"
  },
  {
    "text": "reach a set of pods based on their label selector and the cool thing here is that the label selector doesn't need to",
    "start": "2234920",
    "end": "2241580"
  },
  {
    "text": "target a specific type of pod you could have multiple different types of pod with the same labels and your service",
    "start": "2241580",
    "end": "2246920"
  },
  {
    "text": "will basically randomly send you two different types of pods which is awesome",
    "start": "2246920",
    "end": "2251930"
  },
  {
    "text": "and also really really scary and hard to do something useful with but it would be kind of useful",
    "start": "2251930",
    "end": "2257150"
  },
  {
    "text": "some cases I think so what is a service well let me go out here I'm gonna show",
    "start": "2257150",
    "end": "2262490"
  },
  {
    "text": "you services are cool I did leave my replica set up and running so I still have a bunch of pods in here but I can't",
    "start": "2262490",
    "end": "2269720"
  },
  {
    "text": "talk to him unless I choose a specific pod so what I've got here is I've got a service this is my service here very",
    "start": "2269720",
    "end": "2278869"
  },
  {
    "text": "simple the app version v1 it's a service it has a name it has a spec so it's a",
    "start": "2278869",
    "end": "2286099"
  },
  {
    "text": "cluster I piece the service there are a couple of different types of services this is a cluster IP one which gives you",
    "start": "2286099",
    "end": "2292039"
  },
  {
    "text": "a virtual IP address inside of the cluster and whenever you call that virtual IP you end up at this service",
    "start": "2292039",
    "end": "2297829"
  },
  {
    "text": "here and that then causes you to proxy",
    "start": "2297829",
    "end": "2302900"
  },
  {
    "text": "through the cube proxy and a few networking thing is that I don't we don't need to get into but basically it",
    "start": "2302900",
    "end": "2308569"
  },
  {
    "text": "gets a virtual IP address that we can use it uses a lecture in this case I'm",
    "start": "2308569",
    "end": "2313910"
  },
  {
    "text": "selecting all of the pods that I currently have running because they all have the the label apps at the web and",
    "start": "2313910",
    "end": "2319099"
  },
  {
    "text": "I'm saying that hey I want you to listen for TCP connections I want you to listen for port on port 80 and I want to",
    "start": "2319099",
    "end": "2326210"
  },
  {
    "text": "forward it to port 80 on the pods that I am selected take that go back out here",
    "start": "2326210",
    "end": "2334150"
  },
  {
    "text": "do that cube CTL get all you'll see here now that I have another service there's",
    "start": "2338079",
    "end": "2344509"
  },
  {
    "text": "always a service in your cluster called kubernetes and the name of your service is also a DNS entry so you can just go",
    "start": "2344509",
    "end": "2351170"
  },
  {
    "text": "inside of your cluster you could just go and do an HTTP call or rest call - HTTP",
    "start": "2351170",
    "end": "2357079"
  },
  {
    "text": "colon slash slash kubernetes and that would end up at the kubernetes api is on",
    "start": "2357079",
    "end": "2362329"
  },
  {
    "text": "the control plane but i got one called web here it's got a cluster IP which is 10 108 46 150 I don't really care but we",
    "start": "2362329",
    "end": "2371660"
  },
  {
    "text": "can say cube CTL port - forward service",
    "start": "2371660",
    "end": "2377079"
  },
  {
    "text": "web app was it called web app which",
    "start": "2377079",
    "end": "2382759"
  },
  {
    "text": "called web only 8080 port 80 yes slash",
    "start": "2382759",
    "end": "2390380"
  },
  {
    "text": "in there there is if I go back out here press refresh I'm now talking to my",
    "start": "2390380",
    "end": "2397729"
  },
  {
    "text": "service which is awesomely and enough load balancing not at all that is",
    "start": "2397729",
    "end": "2404059"
  },
  {
    "text": "because it's actually not talking to the service it's the way that port forward works in capital is that it chooses the",
    "start": "2404059",
    "end": "2410569"
  },
  {
    "text": "first IP address in the matched pods and port forwards to that specific",
    "start": "2410569",
    "end": "2416420"
  },
  {
    "text": "pod so it doesn't go through the service because that has to go through the cube proxy in a few things so it just selects",
    "start": "2416420",
    "end": "2422180"
  },
  {
    "text": "one pod but you can use it to basically say I want to talk to one of the pods in this this thing here and internally in",
    "start": "2422180",
    "end": "2428779"
  },
  {
    "text": "your cluster talking to that endpoint would cause you to talk to a random set of your pods just gonna go and it's just",
    "start": "2428779",
    "end": "2437690"
  },
  {
    "text": "gonna go and delete that I don't need that anymore and we'll do cube CTL",
    "start": "2437690",
    "end": "2444859"
  },
  {
    "text": "delete RS Web App",
    "start": "2444859",
    "end": "2450849"
  },
  {
    "text": "and now my cluster should be empty yep all gone so services are chemical they are",
    "start": "2452250",
    "end": "2459420"
  },
  {
    "text": "essential for you to communicate with your pods you can never talk pod to pod because they might come and go services",
    "start": "2459420",
    "end": "2465540"
  },
  {
    "text": "will give you a six point six place also you cannot actually really find your pods pods don't get specific IP",
    "start": "2465540",
    "end": "2471450"
  },
  {
    "text": "addresses they get random IP addresses so there's no way for you to really initiate pod - pod communication in a",
    "start": "2471450",
    "end": "2477750"
  },
  {
    "text": "very simple way they are a little bit more complicated though and that's the",
    "start": "2477750",
    "end": "2483900"
  },
  {
    "text": "fact that you can go and create different types of services you can have",
    "start": "2483900",
    "end": "2488970"
  },
  {
    "text": "something called a node service for example that will bind a port on each",
    "start": "2488970",
    "end": "2494400"
  },
  {
    "text": "one of your nodes in your cluster and then forward that port to the set of pods for example that allows you to",
    "start": "2494400",
    "end": "2500760"
  },
  {
    "text": "basically have an entry point entry application through any of your nodes which you can then load balanced with a",
    "start": "2500760",
    "end": "2506070"
  },
  {
    "text": "load balancer in front of it for example to blow mats across your nose and so on there are a couple of different ones and",
    "start": "2506070",
    "end": "2511500"
  },
  {
    "text": "they're a bit more complicated but you've got the general gist of a service is a dns name that you can use inside of",
    "start": "2511500",
    "end": "2518070"
  },
  {
    "text": "your cluster to communicate with a set of pods you've also got something called ingress controllers ingress controllers",
    "start": "2518070",
    "end": "2526140"
  },
  {
    "text": "are basically services on steroids they have the same idea of marshaling",
    "start": "2526140",
    "end": "2533840"
  },
  {
    "text": "requests to different pods but they also have much smarter logic saying that",
    "start": "2533840",
    "end": "2539610"
  },
  {
    "text": "they're http-based so they can say if you go to slash X you should go to this",
    "start": "2539610",
    "end": "2545400"
  },
  {
    "text": "service if you go to slash why you should go to this service if you go with this header you should end up on this",
    "start": "2545400",
    "end": "2550950"
  },
  {
    "text": "service so it's basically a way for you to come into your cluster and based on your HTTP call get redirected to a bunch",
    "start": "2550950",
    "end": "2557790"
  },
  {
    "text": "of different services inside of your cluster which then redirects to the individual pods so you can have this one",
    "start": "2557790",
    "end": "2564480"
  },
  {
    "text": "entry point in that fans out across your whole micro-services architecture internally there are a bunch of them",
    "start": "2564480",
    "end": "2570660"
  },
  {
    "text": "available the simplest one is nginx which is based on nginx you guessed it",
    "start": "2570660",
    "end": "2576420"
  },
  {
    "text": "but there's also things like Ambassador or traffic sto with different levels of",
    "start": "2576420",
    "end": "2582300"
  },
  {
    "text": "features I have worked a little bit with Ambassador at Norfolk which is nice because you you add annotations to your pods and then",
    "start": "2582300",
    "end": "2589130"
  },
  {
    "text": "magically they get wired up into your ingress controller so whenever you deploy a new service you can add and say",
    "start": "2589130",
    "end": "2594980"
  },
  {
    "text": "hey I want this thing to actually answer on this address here and then your pod",
    "start": "2594980",
    "end": "2600950"
  },
  {
    "text": "automatically gets traffic through ambassador for an easy easy deployment whereas nginx requires a bit of",
    "start": "2600950",
    "end": "2606740"
  },
  {
    "text": "configuration and sto is a whole different topic because it also rewrites",
    "start": "2606740",
    "end": "2613040"
  },
  {
    "text": "your entire service stack into being a network or a service mesh instead with",
    "start": "2613040",
    "end": "2618410"
  },
  {
    "text": "much more control so it's a higher level thing than than just ambassador and nginx we also got deployments so",
    "start": "2618410",
    "end": "2627680"
  },
  {
    "text": "deployments is the last sort of resource level so we've got pods right and on top of pods we put replicas sets so replica",
    "start": "2627680",
    "end": "2633980"
  },
  {
    "text": "sets generates pods we don't create pods because we don't get load balance and it will be the whole taking care of",
    "start": "2633980",
    "end": "2640070"
  },
  {
    "text": "multiple replicas so we have replica sets but we have one thing on top of it called the deployment so a deployment",
    "start": "2640070",
    "end": "2646940"
  },
  {
    "text": "creates a replica set and the replica set create pods the reason for this is",
    "start": "2646940",
    "end": "2652750"
  },
  {
    "text": "deployment if you define the deployment it will create these things for you but if you ever updates every deployment you",
    "start": "2652750",
    "end": "2659810"
  },
  {
    "text": "can tell that hey I want to update this whole deployment here and please do that",
    "start": "2659810",
    "end": "2665750"
  },
  {
    "text": "in the way that you take down one pod at the time in different nodes over time",
    "start": "2665750",
    "end": "2672410"
  },
  {
    "text": "make sure that they are up and running for at least 20 seconds before you pull down the next one or take it to at the",
    "start": "2672410",
    "end": "2679460"
  },
  {
    "text": "time but leave or always leave these many pods running with the previous version so it's basically a nice rolling",
    "start": "2679460",
    "end": "2685580"
  },
  {
    "text": "update throughout your cluster that you can roll back if you want to so it gives",
    "start": "2685580",
    "end": "2690830"
  },
  {
    "text": "you one one higher level of control and this going to quickly show you that in",
    "start": "2690830",
    "end": "2698900"
  },
  {
    "text": "here I have a last level here it's my deployment so deployment is kind",
    "start": "2698900",
    "end": "2705800"
  },
  {
    "text": "deployment it has the replicas thing right in here so it basically has the setting for your replica sets inside of",
    "start": "2705800",
    "end": "2712250"
  },
  {
    "text": "the spec and then so this is your your replica spec and then inside of your",
    "start": "2712250",
    "end": "2717410"
  },
  {
    "text": "replicas you have a template and this is the template for the containers that you",
    "start": "2717410",
    "end": "2723349"
  },
  {
    "text": "want to run for that replica sets it basically merges this Yama file merges your pods back with your replica sets",
    "start": "2723349",
    "end": "2731030"
  },
  {
    "text": "back with the whole deployment spec on top of it in this case I also want to",
    "start": "2731030",
    "end": "2736880"
  },
  {
    "text": "deploy a few other things so these things here three dashes in a Yama file",
    "start": "2736880",
    "end": "2741950"
  },
  {
    "text": "basically means this is a new resource so we can have multiple resources in one file then I'm also going to play deploy",
    "start": "2741950",
    "end": "2748910"
  },
  {
    "text": "one individual pod in this case and the individual pod is going to be ready spawn so you don't want to have Redis in",
    "start": "2748910",
    "end": "2755599"
  },
  {
    "text": "multiple pods because it's gonna be less effective cache if we put it like that",
    "start": "2755599",
    "end": "2760990"
  },
  {
    "text": "so we want one of these so I'm going to deploy one of those I'm just gonna use the the image Redis from docker hub then",
    "start": "2760990",
    "end": "2768619"
  },
  {
    "text": "I'm going to deploy a service in here which is a cluster IP service that's called Redis so if you go into the DNS",
    "start": "2768619",
    "end": "2776210"
  },
  {
    "text": "asking for Redis it's going to point towards the the apps called Redis port",
    "start": "2776210",
    "end": "2783140"
  },
  {
    "text": "TCP port 363 Nats 79 basically it's a service in front of your your radius",
    "start": "2783140",
    "end": "2789650"
  },
  {
    "text": "cache and then I'm going to put up a service here but this time I'm going to use an Oda port node ports will as I",
    "start": "2789650",
    "end": "2795799"
  },
  {
    "text": "said previously quickly they will map at random you can select it but just just",
    "start": "2795799",
    "end": "2801289"
  },
  {
    "text": "say a random port on each one of your nodes so basically all knows get the",
    "start": "2801289",
    "end": "2806630"
  },
  {
    "text": "same random port or each each node yeah and that node that port on your node",
    "start": "2806630",
    "end": "2812390"
  },
  {
    "text": "which is going to be like 32 thousand four hundred and sixty two completely random stupid port in a specific",
    "start": "2812390",
    "end": "2818119"
  },
  {
    "text": "specified rock port range that will automatically get forwarded to port 80",
    "start": "2818119",
    "end": "2823369"
  },
  {
    "text": "on this service which is then forwarded to port 80 on your your actual node so",
    "start": "2823369",
    "end": "2829520"
  },
  {
    "text": "if I create this deployment",
    "start": "2829520",
    "end": "2832510"
  },
  {
    "text": "like that you'll see cube CTL good Oh",
    "start": "2838059",
    "end": "2844039"
  },
  {
    "text": "you will see that I have now a deployment a replica set three replicas",
    "start": "2844039",
    "end": "2850579"
  },
  {
    "text": "a Redis cache a Redis service and a node port called web and the node port here",
    "start": "2850579",
    "end": "2858170"
  },
  {
    "text": "says hey I'm listening two ports three two four six nine that means that port",
    "start": "2858170",
    "end": "2864019"
  },
  {
    "text": "three four two three two four six nine on any one of your worker nodes will go",
    "start": "2864019",
    "end": "2871430"
  },
  {
    "text": "to that service and then port forward to your your notes or your pods sorry in",
    "start": "2871430",
    "end": "2879529"
  },
  {
    "text": "the case of docker for desktop it",
    "start": "2879529",
    "end": "2884779"
  },
  {
    "text": "actually Maps your localhost on that port so if I go localhost in that port I'm now talking straight into my mic",
    "start": "2884779",
    "end": "2891950"
  },
  {
    "text": "pods so I can go in here and have a look at my application and we can see that it",
    "start": "2891950",
    "end": "2896990"
  },
  {
    "text": "can communicate with Redis because you can see the ready stuff so that's kind",
    "start": "2896990",
    "end": "2902180"
  },
  {
    "text": "of cool and that allows us to basically put a load balancer in front of all of",
    "start": "2902180",
    "end": "2908210"
  },
  {
    "text": "our worker nodes and then have the load balancer load balanced across the worker nodes on that port and then internally",
    "start": "2908210",
    "end": "2915799"
  },
  {
    "text": "that port will map to a service which is then load balanced across to the different pods inside of your cluster so",
    "start": "2915799",
    "end": "2922009"
  },
  {
    "text": "that's kind of one way to get into your placate your cluster from the outside then I'm just gonna go and say justice",
    "start": "2922009",
    "end": "2929809"
  },
  {
    "text": "you can do apply F and give it a file with all of your things that you want to apply you can do delete F and it deletes",
    "start": "2929809",
    "end": "2936170"
  },
  {
    "text": "everything defined in that file which is nice my cluster is now all clean",
    "start": "2936170",
    "end": "2941470"
  },
  {
    "text": "so deployments nice way for you to handle rolling updates and managing things like that in a nice and easy way",
    "start": "2941470",
    "end": "2948019"
  },
  {
    "text": "and all of these llam√≥ files can nicely be put into source control version manage and everything like they should",
    "start": "2948019",
    "end": "2953720"
  },
  {
    "text": "so you always know what's running in your cluster if you want to redeploy something you just run that ya know file again so what else do we need well we",
    "start": "2953720",
    "end": "2963170"
  },
  {
    "text": "need some configuration we need to be able to configure our pods to do what they should be doing we need to be able to add storage and we",
    "start": "2963170",
    "end": "2969950"
  },
  {
    "text": "need to be able to do some health monitoring these are kind of the main things that we need to sort out besides being able to run our containers",
    "start": "2969950",
    "end": "2977110"
  },
  {
    "text": "configuration is fairly simple if you have worked with docker before you know that in doctor we get configuration into",
    "start": "2977110",
    "end": "2984500"
  },
  {
    "text": "our docker containers either by doing environment variables or we do volume",
    "start": "2984500",
    "end": "2989870"
  },
  {
    "text": "mounts right so we mount files into our application and we read those files suite if we change the logo up in the",
    "start": "2989870",
    "end": "2996080"
  },
  {
    "text": "set corner we're done because we do exactly the same thing in kubernetes the main difference is where we store the",
    "start": "2996080",
    "end": "3003880"
  },
  {
    "text": "values we put into our environment variables and into our files that we map in there so here's an example of",
    "start": "3003880",
    "end": "3010570"
  },
  {
    "text": "something called the config map a config map is a resource in kubernetes that",
    "start": "3010570",
    "end": "3015760"
  },
  {
    "text": "contains configuration and then you can map information from a config map into",
    "start": "3015760",
    "end": "3021220"
  },
  {
    "text": "your pods using a volume mount or an environment variable so here we have the",
    "start": "3021220",
    "end": "3027850"
  },
  {
    "text": "config map my config map that has the data timeout which is a string that corresponds to five minutes and then in",
    "start": "3027850",
    "end": "3034660"
  },
  {
    "text": "my pod I define that hey I want to have an environment variable call timeout I want to get the value from a config map",
    "start": "3034660",
    "end": "3042130"
  },
  {
    "text": "key reference the name of my config map is my config map and the key is my tease",
    "start": "3042130",
    "end": "3047620"
  },
  {
    "text": "timeout and then once you start this pod it will go and look for that config map",
    "start": "3047620",
    "end": "3052720"
  },
  {
    "text": "find the value and inject that as a environment variable and you can also go",
    "start": "3052720",
    "end": "3058600"
  },
  {
    "text": "and do the same thing with files so you can have a config map with the contents",
    "start": "3058600",
    "end": "3063850"
  },
  {
    "text": "of a file and then you can take that content and mount it into your pod and",
    "start": "3063850",
    "end": "3069460"
  },
  {
    "text": "say whatever it's in this this config map under the value config dot Jason",
    "start": "3069460",
    "end": "3074950"
  },
  {
    "text": "please map that into in this case slash app slash configure Jason in my application this can I see you got your",
    "start": "3074950",
    "end": "3082150"
  },
  {
    "text": "config together with your application where it should be little short demo of how that works is",
    "start": "3082150",
    "end": "3089670"
  },
  {
    "text": "we look at our config map here I have a this is just my well actually let's",
    "start": "3089670",
    "end": "3096250"
  },
  {
    "text": "start here I have my config map it has a statement which is just a string camera it's also and I have an app settings Jason that",
    "start": "3096250",
    "end": "3103400"
  },
  {
    "text": "sets a value like this and then I have a web pod here and as you can see it does",
    "start": "3103400",
    "end": "3110690"
  },
  {
    "text": "a few things it has the environment variable name like that set to a",
    "start": "3110690",
    "end": "3117290"
  },
  {
    "text": "reference to the web config config map and the key statement so that",
    "start": "3117290",
    "end": "3123260"
  },
  {
    "text": "environment variable will be set to that value and down here I'm creating a",
    "start": "3123260",
    "end": "3130250"
  },
  {
    "text": "volume called config volume based on the config map web config web config and",
    "start": "3130250",
    "end": "3135590"
  },
  {
    "text": "then I go and say I wouldn't mount the app settings to adjacent thing into app",
    "start": "3135590",
    "end": "3140840"
  },
  {
    "text": "setting start production that JSON in my application which means that anything in",
    "start": "3140840",
    "end": "3146030"
  },
  {
    "text": "that upsetting situation is going to override the one that is in my application if I've got these two I can",
    "start": "3146030",
    "end": "3151580"
  },
  {
    "text": "go out here config will do cube CTL and",
    "start": "3151580",
    "end": "3159230"
  },
  {
    "text": "here the important part is that we deploy we deploy that one first because",
    "start": "3159230",
    "end": "3169880"
  },
  {
    "text": "that has to be there otherwise you can't map in the map an environment variable once that is deployed I can go and",
    "start": "3169880",
    "end": "3175640"
  },
  {
    "text": "deploy my web and then we can say cube CTL Port knows f8 last one",
    "start": "3175640",
    "end": "3183580"
  },
  {
    "text": "nope it was supposed to be pulled web or just web like that and if I go back out",
    "start": "3183580",
    "end": "3192080"
  },
  {
    "text": "here and i refresh this on port 8080 we",
    "start": "3192080",
    "end": "3197990"
  },
  {
    "text": "can go to configuration and it can just verify that it does say kubernetes is",
    "start": "3197990",
    "end": "3203630"
  },
  {
    "text": "awesome and it did get configuration from kubernetes config map in here as well so it did read everything properly so once",
    "start": "3203630",
    "end": "3209780"
  },
  {
    "text": "again we store our config together with everything in the cluster I'm just gonna",
    "start": "3209780",
    "end": "3215240"
  },
  {
    "text": "kill this delete - f actually we can do delete",
    "start": "3215240",
    "end": "3223000"
  },
  {
    "text": "come on and finally no we'll just leave",
    "start": "3226970",
    "end": "3234420"
  },
  {
    "text": "that so config Mac config like that it's quite nice you put your config in there",
    "start": "3234420",
    "end": "3240119"
  },
  {
    "text": "and then when you're running in your cluster or your local cluster your pods",
    "start": "3240119",
    "end": "3245640"
  },
  {
    "text": "will just read from that specific cluster which is quite nice we've also got something called secrets and I just",
    "start": "3245640",
    "end": "3252480"
  },
  {
    "text": "want to mention secrets because they are the same thing as config maps but they are secret so the values inside of a",
    "start": "3252480",
    "end": "3258510"
  },
  {
    "text": "secrets instead of a config map is base 64 encoded that is very secret it has",
    "start": "3258510",
    "end": "3265320"
  },
  {
    "text": "nothing to do with being safe as in secret that but you can set access",
    "start": "3265320",
    "end": "3270420"
  },
  {
    "text": "rights to to a secret for example but the whole idea of doing the base64-encoded is more of an intent",
    "start": "3270420",
    "end": "3276090"
  },
  {
    "text": "basically saying stuff in secret should be credentials and things like that stuff in config maps should not and then",
    "start": "3276090",
    "end": "3282330"
  },
  {
    "text": "it's more of a sort of intent kind of thing with the name it's it's not",
    "start": "3282330",
    "end": "3288180"
  },
  {
    "text": "actually safe in any way whatsoever I would suggest getting some other way of storing credentials like for example a",
    "start": "3288180",
    "end": "3294330"
  },
  {
    "text": "keyboard in a shoe or something like that you've also got something called image pull secrets I mentioned that when",
    "start": "3294330",
    "end": "3300300"
  },
  {
    "text": "in my all of my podium files it says image pull secrets basically saying what credentials should I use when I pull my",
    "start": "3300300",
    "end": "3306960"
  },
  {
    "text": "images and you create a this is nice right that's easy to read you create a",
    "start": "3306960",
    "end": "3313470"
  },
  {
    "text": "pull secret by telling cube CTL that I want to create a secret it's a docker registry secret you give it a name you",
    "start": "3313470",
    "end": "3320280"
  },
  {
    "text": "tell it what server to use username password and the email you can put in whatever you want because it doesn't matter and then those credentials are",
    "start": "3320280",
    "end": "3327930"
  },
  {
    "text": "being reused whenever you try to pull an image which can be a useful thing storage and storage is basically docker",
    "start": "3327930",
    "end": "3335700"
  },
  {
    "text": "volumes with some extensions so I'm not going to show you but you map in volumes",
    "start": "3335700",
    "end": "3340710"
  },
  {
    "text": "and depending on your provider you can use different types of volumes there are a few different types but for example if",
    "start": "3340710",
    "end": "3346800"
  },
  {
    "text": "you're running in Asher you can take an azure disk or an usher file and you can map that as storage inside of your pod",
    "start": "3346800",
    "end": "3352950"
  },
  {
    "text": "in AWS you can I have AWS elastic block store for example so it gives you storage external to your",
    "start": "3352950",
    "end": "3359920"
  },
  {
    "text": "cluster that is persistent you don't want to store things in your pods because they'll come and go so external",
    "start": "3359920",
    "end": "3365470"
  },
  {
    "text": "storage is quite important and the final thing is that I mentioned was container",
    "start": "3365470",
    "end": "3371140"
  },
  {
    "text": "health monitoring and the way that we monitor health in kubernetes is something called the aliveness probe so",
    "start": "3371140",
    "end": "3378010"
  },
  {
    "text": "liveness probe is in its basic form you can set it up to be an HDPE call to a specific endpoint in your application",
    "start": "3378010",
    "end": "3384400"
  },
  {
    "text": "and if that endpoint returns HTTP 200 to 399 all those status codes are",
    "start": "3384400",
    "end": "3390970"
  },
  {
    "text": "considered I'm up and running and everything is fine other than that if it's not any of those status codes it's",
    "start": "3390970",
    "end": "3396700"
  },
  {
    "text": "considered something is wrong and then in your definition of aliveness probe once again",
    "start": "3396700",
    "end": "3402340"
  },
  {
    "text": "HP get is the simplest thing you can do much more complex probes but it's the idea is that every X seconds in this",
    "start": "3402340",
    "end": "3409390"
  },
  {
    "text": "case every three seconds it will do a probe and whenever in this case it fails",
    "start": "3409390",
    "end": "3415150"
  },
  {
    "text": "to probe three times in a row the container is considered failed and will get restarted and you can also tell it",
    "start": "3415150",
    "end": "3422020"
  },
  {
    "text": "that I want to delay it three seconds don't start probing until after a few seconds because there's a bit of a startup time for my pod for example I'm",
    "start": "3422020",
    "end": "3432010"
  },
  {
    "text": "actually not going to show you because I want to show you something a bit more and I'm a bit late the lightness probe is kind of that all that you're gonna",
    "start": "3432010",
    "end": "3437890"
  },
  {
    "text": "see it's basically if you turn it off it tails but I want to mention readiness",
    "start": "3437890",
    "end": "3443920"
  },
  {
    "text": "probes as well so readiness probes are a bit complicated compared to lifeless",
    "start": "3443920",
    "end": "3449050"
  },
  {
    "text": "probes because when a lifeless probe fails three times in my case for how many times you have decided it should",
    "start": "3449050",
    "end": "3454240"
  },
  {
    "text": "fail it will restart the container that's very good if your container is misbehaving or failing in some way but",
    "start": "3454240",
    "end": "3461290"
  },
  {
    "text": "not failing in such a way that your container restarts readiness probes is",
    "start": "3461290",
    "end": "3466420"
  },
  {
    "text": "it works in the same way and you define it in the same way but instead of liveness probes you write readiness",
    "start": "3466420",
    "end": "3471940"
  },
  {
    "text": "probe all the other configuration is the same the difference is that if your",
    "start": "3471940",
    "end": "3477160"
  },
  {
    "text": "readiness probe fails you're not restarted but you're being removed from",
    "start": "3477160",
    "end": "3482590"
  },
  {
    "text": "a service rotation so basically any service that is fronting your pod will",
    "start": "3482590",
    "end": "3488049"
  },
  {
    "text": "use your pod so basically no calls will be made to your pod it will be taken out of load-balancing rotation and then",
    "start": "3488049",
    "end": "3495009"
  },
  {
    "text": "whenever you're ready nest probe starts responding is proper codes again to",
    "start": "3495009",
    "end": "3500170"
  },
  {
    "text": "hundreds for example it will go and plug it back in and it will get part of the rotation that is kind of neat because it",
    "start": "3500170",
    "end": "3508449"
  },
  {
    "text": "means that if you get an overloaded pod your pod can go and say I have too much to do don't send me more anymore request",
    "start": "3508449",
    "end": "3515140"
  },
  {
    "text": "to me but I don't want to get restarted because I'm working or if you have like a very long running task and you can",
    "start": "3515140",
    "end": "3520390"
  },
  {
    "text": "only do one at a time you might have many many pods in there and they can basically take one request at a time and",
    "start": "3520390",
    "end": "3526449"
  },
  {
    "text": "every time they get a request in they go and say I'm not ready they get taken or out of the load-balancing and they can",
    "start": "3526449",
    "end": "3532689"
  },
  {
    "text": "do their work and then they come come back in again so the redness probe is logically the same kind of requests or check but",
    "start": "3532689",
    "end": "3539920"
  },
  {
    "text": "instead of restarting it just removes it from getting more requests other than",
    "start": "3539920",
    "end": "3546699"
  },
  {
    "text": "that I would suggest that you go and play with it there I must honestly say",
    "start": "3546699",
    "end": "3553239"
  },
  {
    "text": "I've been coding for 28 years now and lately it's hard to make me think coding",
    "start": "3553239",
    "end": "3559749"
  },
  {
    "text": "is really fun 2 degree where I want to sit at home and play with my computer on weekends I have other stuff to do but",
    "start": "3559749",
    "end": "3566229"
  },
  {
    "text": "this was actually kind of cool it got getting started with this it's just so simple because you can try all of these",
    "start": "3566229",
    "end": "3571689"
  },
  {
    "text": "little things and every little thing you want to try I want to try to put up a pod with in service in front of it takes",
    "start": "3571689",
    "end": "3577449"
  },
  {
    "text": "you 5 minutes to do you can do little 5 minutes here and 10 minutes there and then slowly you start trying all these",
    "start": "3577449",
    "end": "3582939"
  },
  {
    "text": "things and it's really quick and once you're done you're just go and delete whatever is in your cluster and it's all gone so you don't have this thing of are",
    "start": "3582939",
    "end": "3590109"
  },
  {
    "text": "there's so much work to get started or I'm going to leave my machine in a weird state it's just spin up a cluster run",
    "start": "3590109",
    "end": "3596349"
  },
  {
    "text": "some stuff in it kill whatever it's in there and then go and have dinner thank",
    "start": "3596349",
    "end": "3602079"
  },
  {
    "text": "you all for listening [Applause]",
    "start": "3602079",
    "end": "3609499"
  }
]
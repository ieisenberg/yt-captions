[
  {
    "text": "hello everyone welcome to this session my name is Elena I work at Ivan where we",
    "start": "5359",
    "end": "12559"
  },
  {
    "text": "do a lot with open source Technologies and during this session I would like to take some of the Technologies and look",
    "start": "12559",
    "end": "19920"
  },
  {
    "text": "in the context of the contextual search and Vector search so uh this session",
    "start": "19920",
    "end": "27000"
  },
  {
    "text": "will be full of different demos we are going to search for movies uh we are",
    "start": "27000",
    "end": "32360"
  },
  {
    "text": "going also to look for dogs I mean pictures with the dogs uh find some",
    "start": "32360",
    "end": "38079"
  },
  {
    "text": "recipes and also ask a chatboard some kind of a silly and boring questions",
    "start": "38079",
    "end": "44000"
  },
  {
    "text": "about documentation uh but more importantly we are going to use Vector",
    "start": "44000",
    "end": "49680"
  },
  {
    "text": "search for everything of that so stick with me for the next how much time we",
    "start": "49680",
    "end": "54760"
  },
  {
    "text": "have around 1 hour maybe a bit less uh and we will learn plenty of things we",
    "start": "54760",
    "end": "60199"
  },
  {
    "text": "will learn uh should you use KNN and what actually KNN is or you should use",
    "start": "60199",
    "end": "65400"
  },
  {
    "text": "Ann uh what kind of indexing strategies we can apply already with existing uh",
    "start": "65400",
    "end": "72960"
  },
  {
    "text": "Vector Solutions uh what is the best distance metric you can use and what",
    "start": "72960",
    "end": "78640"
  },
  {
    "text": "options actually you have uh where to take embeddings especially for those of",
    "start": "78640",
    "end": "83840"
  },
  {
    "text": "you who are still beginning using Vector search so what options you have and and",
    "start": "83840",
    "end": "90560"
  },
  {
    "text": "a lot of other things so plenty to cover let's dive in and let's start with the",
    "start": "90560",
    "end": "96320"
  },
  {
    "text": "question what actually is Vector search and uh Vector search is actually a way",
    "start": "96320",
    "end": "102399"
  },
  {
    "text": "to find similarities so to find related objects that have similar",
    "start": "102399",
    "end": "109759"
  },
  {
    "text": "characteristics and in Vector search we use a machine learning model so usually",
    "start": "109759",
    "end": "117000"
  },
  {
    "text": "you have plenty of different options we'll cover that later but you can take a pre-trained model and already apply",
    "start": "117000",
    "end": "124200"
  },
  {
    "text": "for your projects and it's that model will detect semantic relationships between different things and will",
    "start": "124200",
    "end": "131720"
  },
  {
    "text": "distribute those objects in a multi-dimensional space knowing those",
    "start": "131720",
    "end": "137360"
  },
  {
    "text": "characteristics and what is interesting we often don't really know how model decides that we train our models but",
    "start": "137360",
    "end": "143160"
  },
  {
    "text": "it's a black box inside of it so what kind of characteristics it looks at not always apparent for us here humans but",
    "start": "143160",
    "end": "150599"
  },
  {
    "text": "we kind of trust a model to make that relationship and um we talk usually",
    "start": "150599",
    "end": "157720"
  },
  {
    "text": "about uh Dimensions maybe hundreds thousand Dimensions when we are using",
    "start": "157720",
    "end": "163319"
  },
  {
    "text": "models but as humans sadly at least I am not so good at thinking about 700",
    "start": "163319",
    "end": "168920"
  },
  {
    "text": "dimensional space so to simplify but still show you how a model might map",
    "start": "168920",
    "end": "176239"
  },
  {
    "text": "those objects here I'm using just two dimensions imagine that it's actually way way more",
    "start": "176239",
    "end": "183239"
  },
  {
    "text": "and then we can add different objects to that uh Dimension and those objects the",
    "start": "183239",
    "end": "190319"
  },
  {
    "text": "distance between those objects within the multiple different dimensions will actually show us if for that particular",
    "start": "190319",
    "end": "197480"
  },
  {
    "text": "characteristics the objects are close or farther apart for example we have some animals they will be kind of closer to",
    "start": "197480",
    "end": "204599"
  },
  {
    "text": "each other of course if you're talking about a spider and a bear uh probably they will be still uh quite part uh but",
    "start": "204599",
    "end": "211519"
  },
  {
    "text": "uh it still can be combined into some of the area um um farther away from nonan",
    "start": "211519",
    "end": "218319"
  },
  {
    "text": "animated objects such as guitar then when we are talking about money some maybe credit card and cash maybe not so",
    "start": "218319",
    "end": "226319"
  },
  {
    "text": "far uh apart from each other still different objects and then when we put",
    "start": "226319",
    "end": "232480"
  },
  {
    "text": "all our stuff on that multi-dimensional space we can have a list of coordinates",
    "start": "232480",
    "end": "239120"
  },
  {
    "text": "of those objects and this is what we are going to use to find the distances to kind of",
    "start": "239120",
    "end": "245360"
  },
  {
    "text": "find which objects are more similar than the others and here I have kind of those",
    "start": "245360",
    "end": "252680"
  },
  {
    "text": "objects as objects but technically speaking you can create a vector for",
    "start": "252680",
    "end": "258000"
  },
  {
    "text": "anything it can be a sentence uh it can be some kind of a description um can be",
    "start": "258000",
    "end": "264639"
  },
  {
    "text": "also a a picture it can be actually done for finding picture of yourself maybe",
    "start": "264639",
    "end": "271240"
  },
  {
    "text": "you have a big party and you have a lot of photos after that you can train or",
    "start": "271240",
    "end": "276639"
  },
  {
    "text": "like to get uh the model to find all the pictures with yourself uh from that",
    "start": "276639",
    "end": "282960"
  },
  {
    "text": "party or audio or other things um and to do that to find those",
    "start": "282960",
    "end": "290199"
  },
  {
    "text": "nearest uh nearest objects we are using KNN uh algorithm so the K nearest",
    "start": "290199",
    "end": "298280"
  },
  {
    "text": "algorithm and as I mentioned usually we work with",
    "start": "298280",
    "end": "303320"
  },
  {
    "text": "multiple Dimensions so let's say some models can have as little as 300 Dimensions but others would have",
    "start": "303320",
    "end": "311800"
  },
  {
    "text": "700,000 and more and more and the more Dimensions we have the more those characteristics we can have so it gives",
    "start": "311800",
    "end": "319160"
  },
  {
    "text": "us better uh results but also it's more expensive to run those",
    "start": "319160",
    "end": "325400"
  },
  {
    "text": "models and to start with some example so that we understand maybe the kind of the most obvious application of",
    "start": "325400",
    "end": "332560"
  },
  {
    "text": "vector search let's look at the movie recommander system and here the idea is",
    "start": "332560",
    "end": "338759"
  },
  {
    "text": "that we are going to use a semantic search to search for the movies so you",
    "start": "338759",
    "end": "344240"
  },
  {
    "text": "might use various words to describe the same concept and uh with the vector",
    "start": "344240",
    "end": "349840"
  },
  {
    "text": "search you don't Tru need to give the precise uh boing for what you are",
    "start": "349840",
    "end": "355120"
  },
  {
    "text": "looking for uh you can you might be looking for a small dog but call it P",
    "start": "355120",
    "end": "360280"
  },
  {
    "text": "so we already have systems which help us with search but in the uh kind of let's",
    "start": "360280",
    "end": "367919"
  },
  {
    "text": "say 10 years ago or what we did to create a lot of synonyms we would actually have dictionaries which would",
    "start": "367919",
    "end": "374520"
  },
  {
    "text": "allow us to uh to replace uh look for exact searches but replace those with",
    "start": "374520",
    "end": "379919"
  },
  {
    "text": "some synonyms with Vector search actually model does it for us so uh this",
    "start": "379919",
    "end": "386080"
  },
  {
    "text": "is uh where we using for recommendation semantics sech semantic search in turn",
    "start": "386080",
    "end": "391639"
  },
  {
    "text": "can be also implemented quite differently so I know that for example Google use graph databases and you can",
    "start": "391639",
    "end": "397800"
  },
  {
    "text": "do it in very different ways the easiest one nowadays is Vector search so uh",
    "start": "397800",
    "end": "406080"
  },
  {
    "text": "because in Vector search you kind of using the work of a model and often it",
    "start": "406080",
    "end": "411639"
  },
  {
    "text": "will be fine to take already trained model which if you want you can train additionally on your context um but just",
    "start": "411639",
    "end": "419560"
  },
  {
    "text": "generally it's not super complex to do comparing to setting up a graph database for semantic",
    "start": "419560",
    "end": "425919"
  },
  {
    "text": "search um cool so uh the system for mov",
    "start": "425919",
    "end": "431319"
  },
  {
    "text": "Commander can be described via following diagram and here uh you can actually",
    "start": "431319",
    "end": "437240"
  },
  {
    "text": "like the the whole flow will look very similar to the rest of the examples",
    "start": "437240",
    "end": "442919"
  },
  {
    "text": "which uh we have because generally it's the same steps which we need to perform to start using Vector search so here we",
    "start": "442919",
    "end": "449599"
  },
  {
    "text": "are taking the data set so of course for any to search anything you need to have",
    "start": "449599",
    "end": "454800"
  },
  {
    "text": "a data set from where you're going to search those object so uh we're going to take a movie data set then we're taking",
    "start": "454800",
    "end": "462479"
  },
  {
    "text": "a model and here for this particular example I use tensorflow Universal sentence",
    "start": "462479",
    "end": "468440"
  },
  {
    "text": "encoder this a model which I find to be conveniently used with",
    "start": "468440",
    "end": "473520"
  },
  {
    "text": "JavaScript um uh but again it's one of multiple options we can have",
    "start": "473520",
    "end": "480080"
  },
  {
    "text": "and that we process each individual movie the movie description from the database data set uh and transform it",
    "start": "480080",
    "end": "487560"
  },
  {
    "text": "into a vector tensor flow Universal sentence encoder gives us vectors of",
    "start": "487560",
    "end": "494120"
  },
  {
    "text": "512 dimensions and then we need to store those vectors somewhere and that",
    "start": "494120",
    "end": "500879"
  },
  {
    "text": "somewhere should be a database which can work with vectors which can later help",
    "start": "500879",
    "end": "506879"
  },
  {
    "text": "us to compare vectors again without trying to write some",
    "start": "506879",
    "end": "511919"
  },
  {
    "text": "complex uh geometrical functions and just rely on that possibility with the vectors as well that uh can work",
    "start": "511919",
    "end": "519080"
  },
  {
    "text": "efficiently with the vectors and we'll see indexing a bit later so for this particular example we are going to use",
    "start": "519080",
    "end": "527040"
  },
  {
    "text": "pogress uh with a PG Vector extension how many of you actually work",
    "start": "527040",
    "end": "532519"
  },
  {
    "text": "with pogress oh wow that's a lot of hands here um so pogress one of many databases",
    "start": "532519",
    "end": "541440"
  },
  {
    "text": "which actually together with a PG Vector extension has a possibility to work with",
    "start": "541440",
    "end": "546519"
  },
  {
    "text": "vectors to compare the vectors to index the vectors um and what I like about",
    "start": "546519",
    "end": "552680"
  },
  {
    "text": "postgress is because we already using it so much in so many different context so you don't truly need to use any extra",
    "start": "552680",
    "end": "560000"
  },
  {
    "text": "database you are not familiar with you can take the already verified and",
    "start": "560000",
    "end": "566040"
  },
  {
    "text": "trusted pogress database for that and it actually offers quite a bunch of uh",
    "start": "566040",
    "end": "572279"
  },
  {
    "text": "necessary things which we need for Vector search so okay so we took the movies we",
    "start": "572279",
    "end": "578360"
  },
  {
    "text": "processed all the movies now in pogress we have a table which has those movies",
    "start": "578360",
    "end": "584160"
  },
  {
    "text": "next we have uh a user someone who is looking what to watch today and uh for",
    "start": "584160",
    "end": "590800"
  },
  {
    "text": "that uh we have a possibility for user to enter that search phrase We again",
    "start": "590800",
    "end": "596519"
  },
  {
    "text": "will convert what user entered into a vector because we want to compare that",
    "start": "596519",
    "end": "602680"
  },
  {
    "text": "single Vector now to everything which we have in the data base and here what is",
    "start": "602680",
    "end": "609519"
  },
  {
    "text": "important then we use it's it's kind of logical but very important that we should use this same model so the same",
    "start": "609519",
    "end": "618079"
  },
  {
    "text": "tensorflow model which converted our movies into the vector we use the same model to convert the search phrase into",
    "start": "618079",
    "end": "625240"
  },
  {
    "text": "the vector because we want to compare apples to apples different models will have different way how they will",
    "start": "625240",
    "end": "632200"
  },
  {
    "text": "identify the characteristic characteristics even if you have two models and they both have the same",
    "start": "632200",
    "end": "638440"
  },
  {
    "text": "number of Dimensions this doesn't mean that they are comparable oops um so uh with that I",
    "start": "638440",
    "end": "647959"
  },
  {
    "text": "also yeah okay so uh this is a database data set which I found for the movie",
    "start": "647959",
    "end": "653600"
  },
  {
    "text": "plots so this is uh from Wikipedia uh and there are just just",
    "start": "653600",
    "end": "660079"
  },
  {
    "text": "like very very convenient and uh I appreciate taking the pictures but I also will leave the GitHub repositories",
    "start": "660079",
    "end": "665760"
  },
  {
    "text": "and all the links later take the pictures go ahead but I will uh combine it all and uh share with you so that you",
    "start": "665760",
    "end": "672959"
  },
  {
    "text": "don't have to uh try to guess this uh links from the slides so um and we have",
    "start": "672959",
    "end": "680399"
  },
  {
    "text": "the information about the plot and that what I actually convert into the vector uh the amount of data which we convert",
    "start": "680399",
    "end": "687320"
  },
  {
    "text": "into the vector matters because models usually have uh a limit which you",
    "start": "687320",
    "end": "693240"
  },
  {
    "text": "can which amount of information you can actually give it for the vector um and",
    "start": "693240",
    "end": "698920"
  },
  {
    "text": "if the limit is more than the limit usually you have to chunk it uh into parts and then process it",
    "start": "698920",
    "end": "706120"
  },
  {
    "text": "separately um cool so uh that's a GitHub repository which I will share later in",
    "start": "706120",
    "end": "712200"
  },
  {
    "text": "case you will be interested in any of the demos which I'm showing you will be able to look into more details uh in the",
    "start": "712200",
    "end": "718800"
  },
  {
    "text": "code uh later that just find it a bit uh helpful so the first one with the movie",
    "start": "718800",
    "end": "724760"
  },
  {
    "text": "recommander I actually use JavaScript JavaScript is not the most popular language when it comes to uh the",
    "start": "724760",
    "end": "733519"
  },
  {
    "text": "machine learning of course uh the the king there is python but still you can",
    "start": "733519",
    "end": "739399"
  },
  {
    "text": "use JavaScript with tensor flow there are other uh Frame Works and libraries",
    "start": "739399",
    "end": "744480"
  },
  {
    "text": "which can help you as well I found tensor FL even though it's not so super friendly with all honesty it's actually",
    "start": "744480",
    "end": "751800"
  },
  {
    "text": "better than other Alternatives um so and uh for that so",
    "start": "751800",
    "end": "759639"
  },
  {
    "text": "like I will start with this chunk of code so this is Javascript and I don't",
    "start": "759639",
    "end": "764760"
  },
  {
    "text": "see so many of you but could you raise your hand if you're actually familiar with JavaScript or like you worked okay",
    "start": "764760",
    "end": "770560"
  },
  {
    "text": "we have okay good you understand it amazing um so this is piece of quote",
    "start": "770560",
    "end": "777519"
  },
  {
    "text": "which we can use to trans transform a single movie plot or any single piece of",
    "start": "777519",
    "end": "783720"
  },
  {
    "text": "text into a vector so here we are taking the model and I'm using the tensorflow",
    "start": "783720",
    "end": "791000"
  },
  {
    "text": "universal sentence encoder model um which transforms any text you give into",
    "start": "791000",
    "end": "799760"
  },
  {
    "text": "numbers and if I will run that code it will produce us an array of uh flots uh",
    "start": "799760",
    "end": "809240"
  },
  {
    "text": "uh which will indicate the position of that movie how that model will position",
    "start": "809240",
    "end": "814399"
  },
  {
    "text": "that particular uh text on a multi multi-dimensional",
    "start": "814399",
    "end": "820120"
  },
  {
    "text": "space um this is for one movie of course we need to process all the data so what you will take for that and here's",
    "start": "820120",
    "end": "826880"
  },
  {
    "text": "example with the pogress you will connect to pogress uh you need to enable the extension uh there are a bit more",
    "start": "826880",
    "end": "834040"
  },
  {
    "text": "steps I'm using here or like in this example I was using uh Ian for uh postr",
    "start": "834040",
    "end": "839240"
  },
  {
    "text": "that's why we have it pre-installed I just had to run create extension which kind of enables it that but doesn't",
    "start": "839240",
    "end": "844759"
  },
  {
    "text": "really need to create it even and once we enable the extension",
    "start": "844759",
    "end": "849880"
  },
  {
    "text": "the PG Vector because all the magic here when it comes to the vectors working with vectors is in the PG Vector without",
    "start": "849880",
    "end": "857199"
  },
  {
    "text": "PG Vector pogress sadly doesn't know about um how to work with those numbers",
    "start": "857199",
    "end": "862639"
  },
  {
    "text": "uh but once you have it enabled we get a new type of a property which is called",
    "start": "862639",
    "end": "868120"
  },
  {
    "text": "vector and when you define your table for example you need to specify that uh you will have a field",
    "start": "868120",
    "end": "875720"
  },
  {
    "text": "embedding of type Vector with a number of um Dimensions equal to",
    "start": "875720",
    "end": "883199"
  },
  {
    "text": "512 and once you have that uh you can now process all the movies kind of similar to how we did it with a single",
    "start": "883199",
    "end": "889920"
  },
  {
    "text": "one uh just now uh to process it uh all together uh I also recommend to use some",
    "start": "889920",
    "end": "895959"
  },
  {
    "text": "kind of batching here um I'm using here G promise and I am just kind of processing",
    "start": "895959",
    "end": "903360"
  },
  {
    "text": "uh the whole data set and it has like 35,000 movies um uh in and storing it in",
    "start": "903360",
    "end": "910560"
  },
  {
    "text": "the pogress so uh if you will decide to run that uh GitHub repository you will",
    "start": "910560",
    "end": "917120"
  },
  {
    "text": "see something like this like processing the data gradually running of course model running the the whole computation is not",
    "start": "917120",
    "end": "924720"
  },
  {
    "text": "super super fast so it's not slow either but uh using a i doesn't come for free",
    "start": "924720",
    "end": "931240"
  },
  {
    "text": "um uh in any case so once we store the data in the pogress so once we have that we go to",
    "start": "931240",
    "end": "938199"
  },
  {
    "text": "the stage number two and now we would like to um find the nearest movie so",
    "start": "938199",
    "end": "946720"
  },
  {
    "text": "pretending that we are a user and here the test phrase I have on the slide is a",
    "start": "946720",
    "end": "952399"
  },
  {
    "text": "lot of cute puppies assuming that majority of you at least like cute puppies so we run that query so this is",
    "start": "952399",
    "end": "960240"
  },
  {
    "text": "Javascript code but if you ignore the JavaScript part and we just look at the postgress query because this is actually",
    "start": "960240",
    "end": "965880"
  },
  {
    "text": "where the uh instruction to pogress that we would like to search uh would like to",
    "start": "965880",
    "end": "972680"
  },
  {
    "text": "use Vector search and then we would like to find five closest uh movie plots to the test",
    "start": "972680",
    "end": "982560"
  },
  {
    "text": "phrase Vector which we provided and we also use this kind of cute uh um element",
    "start": "982560",
    "end": "990319"
  },
  {
    "text": "which indicates that we are using here L2 distance we'll look at different types of distances a bit later but uh",
    "start": "990319",
    "end": "998639"
  },
  {
    "text": "this is just how PG Vector uh it reduced a different um um different distances",
    "start": "998639",
    "end": "1005440"
  },
  {
    "text": "and then kind of how it works with the vector search and then if you run uh",
    "start": "1005440",
    "end": "1010639"
  },
  {
    "text": "this we get a lot of B of text but uh we retrieve uh the nearest",
    "start": "1010639",
    "end": "1017880"
  },
  {
    "text": "five movies and the secret life of pets and all of the rest and what is interesting so we searching for puppies",
    "start": "1017880",
    "end": "1024640"
  },
  {
    "text": "but it doesn't really have to have like puppies in that text uh anything related",
    "start": "1024640",
    "end": "1030120"
  },
  {
    "text": "to pets or dogs uh will be still close enough according to the",
    "start": "1030120",
    "end": "1035480"
  },
  {
    "text": "model and um again this is just I added like a simple uh interface uh on top of",
    "start": "1035480",
    "end": "1041480"
  },
  {
    "text": "it so for the first request it will take some time but uh actually like and this",
    "start": "1041480",
    "end": "1047839"
  },
  {
    "text": "is a bit of play with uh uh uh next GS eventually it actually gets faster",
    "start": "1047839",
    "end": "1054760"
  },
  {
    "text": "however even though this performance looks good enough we just have 40K or like 35k",
    "start": "1054760",
    "end": "1062720"
  },
  {
    "text": "movies um if we had way more items in our data set this logic will would not",
    "start": "1062720",
    "end": "1071440"
  },
  {
    "text": "be enough this would be a bit too slow because what actually we are doing here is a Brute Force um comparing our test",
    "start": "1071440",
    "end": "1079919"
  },
  {
    "text": "Vector to all 35k items in the database uh which some",
    "start": "1079919",
    "end": "1087360"
  },
  {
    "text": "databases do faster than others but in any case uh let's say if you are at",
    "start": "1087360",
    "end": "1093200"
  },
  {
    "text": "those one of those Google interviews The Brute Force is only the first step then you want to optimize so that you don't",
    "start": "1093200",
    "end": "1098880"
  },
  {
    "text": "have to analyze all the data and this brings me to a topic of",
    "start": "1098880",
    "end": "1105120"
  },
  {
    "text": "KNN versus Ann so uh k nearest neighbors",
    "start": "1105120",
    "end": "1110600"
  },
  {
    "text": "algorithm is where we are comparing all of the items to our text uh phrase um",
    "start": "1110600",
    "end": "1117679"
  },
  {
    "text": "but the Ann is approximate nearest neighbor and the difference them between",
    "start": "1117679",
    "end": "1124400"
  },
  {
    "text": "them happens and the prediction phase so uh a&n will only take a small fraction",
    "start": "1124400",
    "end": "1133480"
  },
  {
    "text": "of the data and we'll analyze only that fraction versus Canan will just look at",
    "start": "1133480",
    "end": "1139039"
  },
  {
    "text": "all the data KNN is really good and very very precise if not for the performance",
    "start": "1139039",
    "end": "1145600"
  },
  {
    "text": "you actually want to use Cann because it will definitely look at all the items and find you the best the closest the",
    "start": "1145600",
    "end": "1152240"
  },
  {
    "text": "real closest neighbors however it can take ages so generally we prefer to use uh",
    "start": "1152240",
    "end": "1160080"
  },
  {
    "text": "Ann and uh for a&n for the approximation algorithms so it's kind of uh creating",
    "start": "1160080",
    "end": "1166080"
  },
  {
    "text": "an index oops my clicker stopped",
    "start": "1166080",
    "end": "1171799"
  },
  {
    "text": "working um we have a variety of index types and uh for example in PG Vector",
    "start": "1171799",
    "end": "1179400"
  },
  {
    "text": "which we just looked at there are two indexes which we can use and I actually",
    "start": "1179400",
    "end": "1184480"
  },
  {
    "text": "really like those two indexes because in a way they are quite differently",
    "start": "1184480",
    "end": "1189679"
  },
  {
    "text": "different and they are uh have preferences for different types of scenarios so let's look at them at their",
    "start": "1189679",
    "end": "1196600"
  },
  {
    "text": "pros and cons and also to understand how exactly in Vector search we are using",
    "start": "1196600",
    "end": "1202440"
  },
  {
    "text": "indexes and how exactly we aim at speeding up um uh the search because",
    "start": "1202440",
    "end": "1209159"
  },
  {
    "text": "those indexes work somewhat differently from a usual index which you will see in",
    "start": "1209159",
    "end": "1214679"
  },
  {
    "text": "pogress and the first index is called inverted file with flat compression so",
    "start": "1214679",
    "end": "1221720"
  },
  {
    "text": "imagining that this points we have are the points in our multi-dimensional",
    "start": "1221720",
    "end": "1227360"
  },
  {
    "text": "space um what we want to do we want to split that multi-dimensional space into",
    "start": "1227360",
    "end": "1233919"
  },
  {
    "text": "chunks and how we do it we create a number of centroids so having enough",
    "start": "1233919",
    "end": "1240960"
  },
  {
    "text": "data we are uh setting up centroids in that",
    "start": "1240960",
    "end": "1246440"
  },
  {
    "text": "space and then we uh find the Clusters around those",
    "start": "1246440",
    "end": "1253320"
  },
  {
    "text": "centroids and elements of those clustr will become the vectors uh that",
    "start": "1253320",
    "end": "1259480"
  },
  {
    "text": "um kind of create that area into which we split the stuff and from now on we",
    "start": "1259480",
    "end": "1266000"
  },
  {
    "text": "don't truly have to search everything we can only search some of the Clusters and",
    "start": "1266000",
    "end": "1271520"
  },
  {
    "text": "omit other clusters so that it is faster um and for the this particular",
    "start": "1271520",
    "end": "1279320"
  },
  {
    "text": "index we Define the number of clusters which we want to have here it's the",
    "start": "1279320",
    "end": "1285520"
  },
  {
    "text": "lists um and as well we can Define how many of the Clusters you actually",
    "start": "1285520",
    "end": "1291559"
  },
  {
    "text": "want to search when you are doing uh that uh Vector search with indexing so",
    "start": "1291559",
    "end": "1296840"
  },
  {
    "text": "number of probes obviously the more uh clusters",
    "start": "1296840",
    "end": "1302880"
  },
  {
    "text": "you have and the less items per cluster you have to search the faster will be",
    "start": "1302880",
    "end": "1308240"
  },
  {
    "text": "the vector search but then you have actually this danger of accidentally um",
    "start": "1308240",
    "end": "1313320"
  },
  {
    "text": "missing the closest neighbors because they belong to a different cluster so you need like to find the balance and uh",
    "start": "1313320",
    "end": "1321000"
  },
  {
    "text": "find like better recall um uh so that you are efficient but also you are not",
    "start": "1321000",
    "end": "1327520"
  },
  {
    "text": "losing a crazy amount of data uh by being imprecise and getting some those",
    "start": "1327520",
    "end": "1333440"
  },
  {
    "text": "really fake nearest neighbors uh so this is the index number",
    "start": "1333440",
    "end": "1338760"
  },
  {
    "text": "one has an advantage of being somewhat simple to understand and also uh quick",
    "start": "1338760",
    "end": "1344640"
  },
  {
    "text": "to use and set up has some disadvantages to which we will come come in a second",
    "start": "1344640",
    "end": "1350400"
  },
  {
    "text": "but before that let's look at a different index so this one called hierarchical navigatable small worlds",
    "start": "1350400",
    "end": "1357320"
  },
  {
    "text": "amazing name so it actually splits our data into layers and it creates let's",
    "start": "1357320",
    "end": "1364799"
  },
  {
    "text": "say it doesn't really split the DAT it creates the layers and then positions our data like uh kind of zooming in so the",
    "start": "1364799",
    "end": "1372600"
  },
  {
    "text": "the lower you go the more you zoom into the data or if you go out you zoom out",
    "start": "1372600",
    "end": "1378039"
  },
  {
    "text": "from the dat data so you can navigate through the layers uh one by one uh to",
    "start": "1378039",
    "end": "1385120"
  },
  {
    "text": "find exactly what you need um with this particular uh index",
    "start": "1385120",
    "end": "1392760"
  },
  {
    "text": "you need to Define also couple of parameters which um might indicate how much effort or how much granularity will",
    "start": "1392760",
    "end": "1400360"
  },
  {
    "text": "be in the index this particular index I find way more popular uh when being used",
    "start": "1400360",
    "end": "1406080"
  },
  {
    "text": "because it actually uh is faster or let's say the whole search process is",
    "start": "1406080",
    "end": "1411760"
  },
  {
    "text": "faster but preparation of the index can take time and for example the EF",
    "start": "1411760",
    "end": "1418720"
  },
  {
    "text": "construction it will be the number of um uh connecting connections per layer uh",
    "start": "1418720",
    "end": "1424600"
  },
  {
    "text": "so the the the better numbers you set the more time you need to spend creating",
    "start": "1424600",
    "end": "1430720"
  },
  {
    "text": "this index um yes so between those two",
    "start": "1430720",
    "end": "1436919"
  },
  {
    "text": "indexes the hnsw which which I often see being used",
    "start": "1436919",
    "end": "1443279"
  },
  {
    "text": "because it's actually faster however it's more computationally expensive uh",
    "start": "1443279",
    "end": "1449320"
  },
  {
    "text": "and uh you need to have a server cluster which allows you to run it uh I flat is",
    "start": "1449320",
    "end": "1455480"
  },
  {
    "text": "almost ideal but iy flat because when we create those clusters when we divide the",
    "start": "1455480",
    "end": "1460760"
  },
  {
    "text": "space we have this challenge if you're going to change uh the data on a",
    "start": "1460760",
    "end": "1466919"
  },
  {
    "text": "frequent um interval if you're going to remove some uh Records if you're going to add more you need to recalculate",
    "start": "1466919",
    "end": "1474399"
  },
  {
    "text": "those uh subclusters again and again otherwise you end up actually uh not",
    "start": "1474399",
    "end": "1479799"
  },
  {
    "text": "catching the real uh data and hnsw doesn't have that",
    "start": "1479799",
    "end": "1484960"
  },
  {
    "text": "limitations um so yeah so you need to be like to look at your data maybe if you",
    "start": "1484960",
    "end": "1490000"
  },
  {
    "text": "don't have a huge data set and you don't change it very like very very frequently then I would recommend to use IV flat uh",
    "start": "1490000",
    "end": "1497240"
  },
  {
    "text": "kind of it's very light weight uh but if you need a good performance or like performance for you",
    "start": "1497240",
    "end": "1503000"
  },
  {
    "text": "Mets then use hnsw so um I mentioned a couple of times",
    "start": "1503000",
    "end": "1511480"
  },
  {
    "text": "the recall concept and apart from the",
    "start": "1511480",
    "end": "1517000"
  },
  {
    "text": "performance which we of course want to increase we do care about the recall uh",
    "start": "1517000",
    "end": "1522200"
  },
  {
    "text": "and theall actually it's how many The Neighbors which we retrieved during uh",
    "start": "1522200",
    "end": "1528200"
  },
  {
    "text": "the that search are the true nearest neighbor so the call actually specifies the quality of our results how many what",
    "start": "1528200",
    "end": "1536399"
  },
  {
    "text": "we search is actually relevant and not like you know like random items from Another Side of the uh",
    "start": "1536399",
    "end": "1544520"
  },
  {
    "text": "Dimensions um so if you have a recall of one it means that 100% of what you retrieved is the real nearest neighbors",
    "start": "1544520",
    "end": "1551480"
  },
  {
    "text": "if you have zero. five it means only 50% and the rest are uh something which you",
    "start": "1551480",
    "end": "1557120"
  },
  {
    "text": "don't really want to have in search result um and by using the indexes of",
    "start": "1557120",
    "end": "1563480"
  },
  {
    "text": "course we are approximating stuff so by default if you use KNN like the original",
    "start": "1563480",
    "end": "1571120"
  },
  {
    "text": "one The Brute Force you will almost most probably you will get better results you",
    "start": "1571120",
    "end": "1577399"
  },
  {
    "text": "will get way like you will get the real nearest neighbors this approximation you",
    "start": "1577399",
    "end": "1582880"
  },
  {
    "text": "might lose in that uh domain however again uh it's a trade",
    "start": "1582880",
    "end": "1590000"
  },
  {
    "text": "cool uh that was a lot of boring theoretical part let's move to another",
    "start": "1590000",
    "end": "1595440"
  },
  {
    "text": "demo this particular one I find pretty funny because uh it actually uses not only text but also uses",
    "start": "1595440",
    "end": "1603200"
  },
  {
    "text": "images and uh I like the images uh in this particular one because so",
    "start": "1603200",
    "end": "1608279"
  },
  {
    "text": "technically model can be trained not only on the text the model can actually",
    "start": "1608279",
    "end": "1614240"
  },
  {
    "text": "understand or kind of uh yeah let's say understand um uh the images and how it",
    "start": "1614240",
    "end": "1620399"
  },
  {
    "text": "relates to text so we ask a model to process a picture of a dog it will",
    "start": "1620399",
    "end": "1625760"
  },
  {
    "text": "create some particular item on this multi-dimensional space um and we when",
    "start": "1625760",
    "end": "1631520"
  },
  {
    "text": "we just type a dog it will create also uh a DOT on the multi-dimensional space",
    "start": "1631520",
    "end": "1637440"
  },
  {
    "text": "which is not so far from the picture of the dog same can be done to the uh",
    "start": "1637440",
    "end": "1643240"
  },
  {
    "text": "sounds to videos but this is example where we are using images and for this",
    "start": "1643240",
    "end": "1650120"
  },
  {
    "text": "particular example I am taking pictures from unsplash they have a huge data set",
    "start": "1650120",
    "end": "1656159"
  },
  {
    "text": "very nice to play with and then uh we do with the pictures the same thing which",
    "start": "1656159",
    "end": "1663039"
  },
  {
    "text": "we did to the movies so we take a model and this model is actually clip model",
    "start": "1663039",
    "end": "1668279"
  },
  {
    "text": "from open Ai and we uh run that model and transform each of the pictures into",
    "start": "1668279",
    "end": "1677039"
  },
  {
    "text": "a vector Al has 512 Dimensions but again those models are different you can't",
    "start": "1677039",
    "end": "1682360"
  },
  {
    "text": "really compare vectors across them and then I'm storing the data and this time I'm using open search I love open search",
    "start": "1682360",
    "end": "1689559"
  },
  {
    "text": "for all the visualizations you can do it's like super super amazing database but also it supports Vector search also",
    "start": "1689559",
    "end": "1696760"
  },
  {
    "text": "has indexing uh and all that stuff so if you're already working with open search open search is a bit different from",
    "start": "1696760",
    "end": "1703080"
  },
  {
    "text": "pogress because in P pogress we assume that the data will be modified on a regular basis with open search uh we",
    "start": "1703080",
    "end": "1710320"
  },
  {
    "text": "usually like say it should be not exactly super immutable but but we don't really we prefer not to change the data",
    "start": "1710320",
    "end": "1716960"
  },
  {
    "text": "very frequently so again depends on your use case uh then similarly to the movies we",
    "start": "1716960",
    "end": "1724080"
  },
  {
    "text": "take a search phrase and by the way this example I have seen in trell if you use Trail boards uh you have this",
    "start": "1724080",
    "end": "1730600"
  },
  {
    "text": "possibility to select the background and they like okay you you can search for the backgrounds which you want to have",
    "start": "1730600",
    "end": "1737559"
  },
  {
    "text": "and then using the unsplash data set as well because I can recognize those uh images and you type like I want to see",
    "start": "1737559",
    "end": "1744120"
  },
  {
    "text": "an airplane an airport or something and then they it kind of shows you those pictures so it kind of works in the same",
    "start": "1744120",
    "end": "1749519"
  },
  {
    "text": "way uh so you take a search phrase uh we again use the same model we convert the",
    "start": "1749519",
    "end": "1756600"
  },
  {
    "text": "search phrase into a vector and then we compare that Vector uh to the rest of",
    "start": "1756600",
    "end": "1762799"
  },
  {
    "text": "the vectors to the rest of the images and that uh returns us the",
    "start": "1762799",
    "end": "1768399"
  },
  {
    "text": "nearest um values in the in the database",
    "start": "1768399",
    "end": "1773440"
  },
  {
    "text": "so uh the open search and if I can ask could you raise your hand if you ever",
    "start": "1773440",
    "end": "1779519"
  },
  {
    "text": "worked with open search in some way okay I see one two three the third",
    "start": "1779519",
    "end": "1786519"
  },
  {
    "text": "one was probably not so sure but elastic search actually have you oh okay cool oh",
    "start": "1786519",
    "end": "1792399"
  },
  {
    "text": "that's actually where I should have started so uh some three years ago when elastic changed the",
    "start": "1792399",
    "end": "1798640"
  },
  {
    "text": "uh license that actually was the where the open search was born so uh if you",
    "start": "1798640",
    "end": "1803919"
  },
  {
    "text": "remember so of course like elastic search and open search they moving their own Direction so they you can't really",
    "start": "1803919",
    "end": "1809600"
  },
  {
    "text": "compare them anymore but uh three years ago they had the same origion cool so um if you are familiar",
    "start": "1809600",
    "end": "1817240"
  },
  {
    "text": "with uh elastic search you probably will kind of at least recognize some of that uh code even though the KNN in elastic",
    "start": "1817240",
    "end": "1824640"
  },
  {
    "text": "and an open Search Works differently so uh here we indicate that when we create an index we want to have enabled ke and",
    "start": "1824640",
    "end": "1832320"
  },
  {
    "text": "search and also open search wants to know as well how many dimensions it",
    "start": "1832320",
    "end": "1839440"
  },
  {
    "text": "should expect uh in your data uh and once we have that we can uh",
    "start": "1839440",
    "end": "1846279"
  },
  {
    "text": "load the model so here I'm actually using python I'll touch this a bit later but",
    "start": "1846279",
    "end": "1851960"
  },
  {
    "text": "let's say python is I know it's not it's not a python audience here but python is",
    "start": "1851960",
    "end": "1857039"
  },
  {
    "text": "so makx life so way easier when working with with machine learning um so and",
    "start": "1857039",
    "end": "1862679"
  },
  {
    "text": "here I'm uh taking uh this model I using Python and then uh",
    "start": "1862679",
    "end": "1870360"
  },
  {
    "text": "run the uh images uh and uh I will get",
    "start": "1870360",
    "end": "1875720"
  },
  {
    "text": "the embeddings for each of the images and then when we have the data",
    "start": "1875720",
    "end": "1881399"
  },
  {
    "text": "stored in open search um we want to send a query uh which uses Canon here and to",
    "start": "1881399",
    "end": "1888399"
  },
  {
    "text": "find for example in this particular example is like k k is equal to two so I",
    "start": "1888399",
    "end": "1893559"
  },
  {
    "text": "want to find two nearest neighbors and in the datab base in the open search",
    "start": "1893559",
    "end": "1899279"
  },
  {
    "text": "what I actually store I don't throw images there but I kind of have the images when I process the data and there",
    "start": "1899279",
    "end": "1904799"
  },
  {
    "text": "I'm just storing the IDS or URLs to the images so that I can retrieve the image",
    "start": "1904799",
    "end": "1910760"
  },
  {
    "text": "later when I search for it it gives me the URL and I just visualize it and this",
    "start": "1910760",
    "end": "1916440"
  },
  {
    "text": "is like a notebook I also have an article written on this if you are more Curious to to to learn",
    "start": "1916440",
    "end": "1922679"
  },
  {
    "text": "it and do it yourself again I will link to that later so this is a multi-dimensional um oh my ulti",
    "start": "1922679",
    "end": "1929960"
  },
  {
    "text": "multimodel search uh which I find to be uh really useful and it opens so many",
    "start": "1929960",
    "end": "1936559"
  },
  {
    "text": "different possibilities uh when working with data and while we are at this I would",
    "start": "1936559",
    "end": "1943679"
  },
  {
    "text": "like to show um how exactly we are comp comparing those vectors so imagine we",
    "start": "1943679",
    "end": "1950159"
  },
  {
    "text": "have this bunch of Records stored in open search and then uh we have the",
    "start": "1950159",
    "end": "1956159"
  },
  {
    "text": "search phrase and we need to find the distance from the search phrase to all of those vector or if you are using",
    "start": "1956159",
    "end": "1962360"
  },
  {
    "text": "index and kind of to part of those uh but for this we need some kind of",
    "start": "1962360",
    "end": "1967480"
  },
  {
    "text": "metrix and to have this distance between those vectors and uh there are various",
    "start": "1967480",
    "end": "1974639"
  },
  {
    "text": "options so different Vector databases will have different set of the metrics",
    "start": "1974639",
    "end": "1979840"
  },
  {
    "text": "which we can use however most of them has like",
    "start": "1979840",
    "end": "1985360"
  },
  {
    "text": "overlap for example the ukian distance the L2",
    "start": "1985360",
    "end": "1990440"
  },
  {
    "text": "distance will be present in almost all of the vector search of the vector",
    "start": "1990440",
    "end": "1996399"
  },
  {
    "text": "databases uh and it's also the easiest to understand because technically it's a",
    "start": "1996399",
    "end": "2001440"
  },
  {
    "text": "straight line um from point A to point B if you know coordinates we can calculate",
    "start": "2001440",
    "end": "2007840"
  },
  {
    "text": "need to take a square root of of the things so it's um this metric is kind of",
    "start": "2007840",
    "end": "2014120"
  },
  {
    "text": "cool but on the other hand couple has a couple of disadvantages first of all it's actually computationally more",
    "start": "2014120",
    "end": "2020080"
  },
  {
    "text": "expensive than some other metrics because we need to take a square root and if you can imagine that we have a",
    "start": "2020080",
    "end": "2026880"
  },
  {
    "text": "huge amount of Dimensions that can be quite expensive but secondly uh because we are",
    "start": "2026880",
    "end": "2033840"
  },
  {
    "text": "taking squares of the values we can get outl uh because uh if especially if we have",
    "start": "2033840",
    "end": "2042039"
  },
  {
    "text": "not exactly a normalized data set some of the values can become significantly",
    "start": "2042039",
    "end": "2047240"
  },
  {
    "text": "bigger because we are uh taking a square of uh the between the coordinates so",
    "start": "2047240",
    "end": "2053320"
  },
  {
    "text": "it's consider to be somewhat sensitive to outliers um you might want to be a",
    "start": "2053320",
    "end": "2058919"
  },
  {
    "text": "bit more careful even though it's still a solid and good metric uh especially if you don't really care so much or like if",
    "start": "2058919",
    "end": "2064919"
  },
  {
    "text": "you're if it's within your performance range um we also have L1 Norm which is uh",
    "start": "2064919",
    "end": "2072919"
  },
  {
    "text": "quite interesting it's it's most resilient to outliers this is uh comes from the name of the um gr layer of uh",
    "start": "2072919",
    "end": "2084040"
  },
  {
    "text": "New York so you kind of you can't go directly unless you are flying in a helicopter uh but if you're taking a",
    "start": "2084040",
    "end": "2090440"
  },
  {
    "text": "taxi you have to kind of make turns um and here we are not taking squares or",
    "start": "2090440",
    "end": "2095679"
  },
  {
    "text": "anything it's kind of easier we just calculate this distance you need to get",
    "start": "2095679",
    "end": "2101440"
  },
  {
    "text": "um it's less precise it's also not as frequently used as L2 but it actually",
    "start": "2101440",
    "end": "2107880"
  },
  {
    "text": "kind of uh faster um and then based on that or not based like connected we have",
    "start": "2107880",
    "end": "2114680"
  },
  {
    "text": "this L Infinity which is also not as frequently used but it's quite interesting because um it kind of",
    "start": "2114680",
    "end": "2122800"
  },
  {
    "text": "measures the maximum absolute distance between the coordinates between different dimensions so um it's looks",
    "start": "2122800",
    "end": "2130960"
  },
  {
    "text": "for worst case scenarios where you okay what will be the dimension which gives",
    "start": "2130960",
    "end": "2136040"
  },
  {
    "text": "me the biggest uh distance between those values so you can use it for example to",
    "start": "2136040",
    "end": "2143160"
  },
  {
    "text": "um to emphasize some of the dominant features between the values it actually",
    "start": "2143160",
    "end": "2149200"
  },
  {
    "text": "way more frequently applicable in image processing for example but still it's it's kind of interesting one and you can",
    "start": "2149200",
    "end": "2156599"
  },
  {
    "text": "always play with with those uh metrics um to see if some of those will be better for your particular",
    "start": "2156599",
    "end": "2163119"
  },
  {
    "text": "scenario the metric or actually it's not exactly metric but the way how we can calculate the distance uh we can use the",
    "start": "2163119",
    "end": "2170040"
  },
  {
    "text": "cosine similarities this one is super popular and actually this one might be the best from at least what I read for",
    "start": "2170040",
    "end": "2177800"
  },
  {
    "text": "analyze when you analyze text so if you're doing a vector search and we are doing it based on the text uh remember",
    "start": "2177800",
    "end": "2183880"
  },
  {
    "text": "cosign similarity and try it out it might give you better results even than L2 and also it is somewhat cheaper to",
    "start": "2183880",
    "end": "2191440"
  },
  {
    "text": "perform uh computationally uh but here we are only looking at the angle so in",
    "start": "2191440",
    "end": "2197200"
  },
  {
    "text": "case your data set is a bit chaotic again might not really happen but if",
    "start": "2197200",
    "end": "2202839"
  },
  {
    "text": "it's a bit chaotic and you have a significant distance differences between the values of those vectors uh then you",
    "start": "2202839",
    "end": "2210359"
  },
  {
    "text": "might have a bit of an issue because we are only looking at the angle you can imagine that some vectors can be kind of",
    "start": "2210359",
    "end": "2216720"
  },
  {
    "text": "distance in the space will be bigger but the angle will be still the same so um so here then then instead of cosine",
    "start": "2216720",
    "end": "2225079"
  },
  {
    "text": "similarity you might consider using inner product another very very popular",
    "start": "2225079",
    "end": "2230319"
  },
  {
    "text": "uh way of calculating the distances by projecting one vector onto another",
    "start": "2230319",
    "end": "2237240"
  },
  {
    "text": "Vector um but if you have normalized data then cosign similarity will give",
    "start": "2237240",
    "end": "2243160"
  },
  {
    "text": "you the same result as inner product inner product is only when you have different magnitudes of the vectors uh",
    "start": "2243160",
    "end": "2250200"
  },
  {
    "text": "most of the models I think they will give you good clean nicely arranged data and um for example cosine ll2 uh",
    "start": "2250200",
    "end": "2260280"
  },
  {
    "text": "dot product they probably the most used metrix um in Vector",
    "start": "2260280",
    "end": "2267440"
  },
  {
    "text": "search uh however when you're working with a model what I would do I would go and check the model you use do they",
    "start": "2267440",
    "end": "2274800"
  },
  {
    "text": "recommend any particular metric for that particular data uh because that actually",
    "start": "2274800",
    "end": "2280280"
  },
  {
    "text": "can be a hint which one you should use and also uh I would look at the performance um uh and that's maybe",
    "start": "2280280",
    "end": "2287319"
  },
  {
    "text": "another hint how to how to to see and then I don't know like also like recalling how how",
    "start": "2287319",
    "end": "2294560"
  },
  {
    "text": "well um those objects are connected and if one metric gives you better results",
    "start": "2294560",
    "end": "2300119"
  },
  {
    "text": "than other um another thing for the performance which you can use is is uh",
    "start": "2300119",
    "end": "2308119"
  },
  {
    "text": "to use the filtering so um and make stuff uh faster with the",
    "start": "2308119",
    "end": "2314599"
  },
  {
    "text": "filtering for example if you have not only information about the movies but you have some metadata and we actually",
    "start": "2314599",
    "end": "2321079"
  },
  {
    "text": "had the metadata also in that data set you might have the I don't know like",
    "start": "2321079",
    "end": "2326560"
  },
  {
    "text": "something more like a length of the movie or the language of something else so you might want to combine the vector",
    "start": "2326560",
    "end": "2332400"
  },
  {
    "text": "search and the structured search",
    "start": "2332400",
    "end": "2337640"
  },
  {
    "text": "and you can do it in several different ways so first of all you can do some kind of a pre filtering uh so you just",
    "start": "2337640",
    "end": "2345400"
  },
  {
    "text": "need to take then that metadata and then apply that filter the strict filter and kind of eliminate unnecessary items and",
    "start": "2345400",
    "end": "2353040"
  },
  {
    "text": "then based on what you have left you run the vector search um this is not bad",
    "start": "2353040",
    "end": "2360240"
  },
  {
    "text": "however if you do that you are ruining the indexes most of the time so then you",
    "start": "2360240",
    "end": "2366079"
  },
  {
    "text": "cannot rely on the in index of of course if you know that by",
    "start": "2366079",
    "end": "2371319"
  },
  {
    "text": "using the strict search you minimizing so much the number of data in the data",
    "start": "2371319",
    "end": "2376520"
  },
  {
    "text": "sets which are relevant to use and maybe actually you don't really care anymore about the index it will be fast anyway",
    "start": "2376520",
    "end": "2381800"
  },
  {
    "text": "but in case your uh strict uh search doesn't remove that big amount of data",
    "start": "2381800",
    "end": "2388000"
  },
  {
    "text": "and you end up still with hundreds of thousands of records that might be problematic because maybe rebuilding the",
    "start": "2388000",
    "end": "2394400"
  },
  {
    "text": "index would make sense at what point of time um so this might scale poorly then we",
    "start": "2394400",
    "end": "2401040"
  },
  {
    "text": "have the post filtering which I honestly see less and I also like it a bit less this is if we first perform the vector",
    "start": "2401040",
    "end": "2408680"
  },
  {
    "text": "search on the data set so we just perform maybe that Vector search on the movies and then we just filter uh the",
    "start": "2408680",
    "end": "2415960"
  },
  {
    "text": "movies by extra categories which is the user is interested in but then we can't",
    "start": "2415960",
    "end": "2421359"
  },
  {
    "text": "really predict if user wants to see 10 results at the end we can we might have",
    "start": "2421359",
    "end": "2427400"
  },
  {
    "text": "have cleaned a lot of results through the vector search so in the end we don't have much to give to the user so you",
    "start": "2427400",
    "end": "2434680"
  },
  {
    "text": "need to be careful with post filtering the third alternative uh which",
    "start": "2434680",
    "end": "2440079"
  },
  {
    "text": "uh I know exists in open search and I think it becomes uh interesting in other Solutions is at least what open search",
    "start": "2440079",
    "end": "2447119"
  },
  {
    "text": "calls efficient filtering so this is where you actually give that power to open search to decide how to combine a",
    "start": "2447119",
    "end": "2456040"
  },
  {
    "text": "filter and let me show you example um how to combine a filtering with a vector",
    "start": "2456040",
    "end": "2462280"
  },
  {
    "text": "search and here is like this Boolean condition so like some kind of um Range",
    "start": "2462280",
    "end": "2469200"
  },
  {
    "text": "condition and then on top you have the vector search um what Vector search would do here uh it will actually try to",
    "start": "2469200",
    "end": "2477119"
  },
  {
    "text": "use it logic to understand what will be better pre filtering or post filtering",
    "start": "2477119",
    "end": "2482520"
  },
  {
    "text": "and what to do with the index so um this uh when we use this kind of a filtering",
    "start": "2482520",
    "end": "2489160"
  },
  {
    "text": "um I know that one of our customers use it they saw a significant uh Improvement",
    "start": "2489160",
    "end": "2494560"
  },
  {
    "text": "of course you can manually try to decide which one to use but again it can really",
    "start": "2494560",
    "end": "2499599"
  },
  {
    "text": "depend on the query and uh open search does some kind of calculation of those filter ads and kind of doing some some",
    "start": "2499599",
    "end": "2506440"
  },
  {
    "text": "some logic behind the scenes which you don't really want to reimplement so if you Vector search uh database uh",
    "start": "2506440",
    "end": "2513720"
  },
  {
    "text": "supports this uh efficient filtering know how it's called Uh then I would go",
    "start": "2513720",
    "end": "2519000"
  },
  {
    "text": "for that and combining with filtering can really actually also improve the",
    "start": "2519000",
    "end": "2524560"
  },
  {
    "text": "speed of the query cool so we talked about uh open",
    "start": "2524560",
    "end": "2530480"
  },
  {
    "text": "search we talked about postgress um how many of you know about click house could",
    "start": "2530480",
    "end": "2536800"
  },
  {
    "text": "you raise your hand click house as a colner database I see some hands it's really amazing so click house um the",
    "start": "2536800",
    "end": "2544480"
  },
  {
    "text": "next example I wanted to show because click house also can work with uh with vectors actually click house is very",
    "start": "2544480",
    "end": "2551319"
  },
  {
    "text": "powerful for all the scientific computations and all those mathematical formulas so uh it can do a lot of things",
    "start": "2551319",
    "end": "2559040"
  },
  {
    "text": "apart from Vector search but I find that in Vector search it's quite interesting solution as",
    "start": "2559040",
    "end": "2564440"
  },
  {
    "text": "well uh for those of you who are not familiar with click house click house is",
    "start": "2564440",
    "end": "2569839"
  },
  {
    "text": "not row oriented database it's a column oriented database so we store data in",
    "start": "2569839",
    "end": "2575760"
  },
  {
    "text": "columns and we usually use it for analytics it's super fast just how like",
    "start": "2575760",
    "end": "2581280"
  },
  {
    "text": "the indexes for example in Click house they don't index every row uh they index",
    "start": "2581280",
    "end": "2586920"
  },
  {
    "text": "chunks of data they work with blocks of 10,000 items so uh click house is just",
    "start": "2586920",
    "end": "2592119"
  },
  {
    "text": "marvelous technology when it comes to um to kind of the way how it's optimized so anyway this particular",
    "start": "2592119",
    "end": "2599599"
  },
  {
    "text": "example I took the list of recipes and I used uh a model from hugging face I just",
    "start": "2599599",
    "end": "2605400"
  },
  {
    "text": "wanted to show some something from hugging phas because hugging phas is actually um again this is a bit of a",
    "start": "2605400",
    "end": "2611640"
  },
  {
    "text": "python uh thingy but hugging phas contains so many it's a hub to to store",
    "start": "2611640",
    "end": "2617760"
  },
  {
    "text": "uh the models and there you can really search compare uh this particular model is on minimalistic side because it has",
    "start": "2617760",
    "end": "2625200"
  },
  {
    "text": "only uh 384 Dimensions but again so there when you",
    "start": "2625200",
    "end": "2630800"
  },
  {
    "text": "are looking for a model you can really see what it is was trained on and so on so we do the same stuff as we would",
    "start": "2630800",
    "end": "2637160"
  },
  {
    "text": "doing before but now we doing for the recipes um and then we compare a single",
    "start": "2637160",
    "end": "2643920"
  },
  {
    "text": "Vector to the rest of the stuff so this is a model what I also like because I am not",
    "start": "2643920",
    "end": "2649520"
  },
  {
    "text": "a python developer I'm actually a JavaScript developer who has has to use sometimes uh python or Java or other",
    "start": "2649520",
    "end": "2656559"
  },
  {
    "text": "languages um but what I appreciate and for those of you who will be experimenting um you don't have to be",
    "start": "2656559",
    "end": "2662720"
  },
  {
    "text": "super afraid of python code because they are um they are given really good example um and you can select again the model uh",
    "start": "2662720",
    "end": "2670559"
  },
  {
    "text": "depending on your use case you will see what data it was trained on um so that you because also like what I didn't",
    "start": "2670559",
    "end": "2676680"
  },
  {
    "text": "mention when we are selecting a model for Vector search you really actually want to align it with the purpose of the",
    "start": "2676680",
    "end": "2684200"
  },
  {
    "text": "model because if the model was trained I don't know on the Twitter messages and you like okay let me just take my",
    "start": "2684200",
    "end": "2690880"
  },
  {
    "text": "scientific database and let's see what model will come up with you can imagine it will just give you some rubbish",
    "start": "2690880",
    "end": "2697040"
  },
  {
    "text": "connections between objects so you won't uh kind of uh use uh proper models which",
    "start": "2697040",
    "end": "2702880"
  },
  {
    "text": "was trained on kind of an area which is not far away from what you have you can also additionally train you can take",
    "start": "2702880",
    "end": "2709800"
  },
  {
    "text": "some kind of a basic model and then give it additional information and train and evolve on the",
    "start": "2709800",
    "end": "2715400"
  },
  {
    "text": "data cool so with um with a click house example I took those recipes I had to",
    "start": "2715400",
    "end": "2722000"
  },
  {
    "text": "transform and bit the data uh I moved it to parket file because uh I think",
    "start": "2722000",
    "end": "2727680"
  },
  {
    "text": "nowadays we use parket for Big Data is way more efficient than um than",
    "start": "2727680",
    "end": "2733119"
  },
  {
    "text": "Json and in the end so this is a code more or less uh how we Define create a",
    "start": "2733119",
    "end": "2738720"
  },
  {
    "text": "table in uh click house it's it's very similar to normal SQL um and then we can",
    "start": "2738720",
    "end": "2744680"
  },
  {
    "text": "enter the data the recipes so it's all kind of works as usual there is a lot of",
    "start": "2744680",
    "end": "2751119"
  },
  {
    "text": "logic uh in Click house behind the scenes uh how exactly it processes the data but it's super super fast and then",
    "start": "2751119",
    "end": "2759160"
  },
  {
    "text": "um there are number of functions here I'm using L2 distance and then I am um",
    "start": "2759160",
    "end": "2765720"
  },
  {
    "text": "calculating the distance and getting those nearest um uh nearest",
    "start": "2765720",
    "end": "2770920"
  },
  {
    "text": "recipes so the number of distances because uh click house is very focused on this scientific aspect of the data uh",
    "start": "2770920",
    "end": "2779319"
  },
  {
    "text": "there are like I think more options for the distances but again you get the L2 distance the cosine distance all the",
    "start": "2779319",
    "end": "2786559"
  },
  {
    "text": "usual stuff what is interesting about click house is that uh right now the",
    "start": "2786559",
    "end": "2793280"
  },
  {
    "text": "indexes it supports is only in the experimental mode however based on my",
    "start": "2793280",
    "end": "2799760"
  },
  {
    "text": "experience it actually works faster with the data just by the way how it actually",
    "start": "2799760",
    "end": "2805599"
  },
  {
    "text": "processes the data and how it analyzes you may expect that click house will be",
    "start": "2805599",
    "end": "2812680"
  },
  {
    "text": "faster uh than for example pogress Vis an index this is just the nature of",
    "start": "2812680",
    "end": "2818319"
  },
  {
    "text": "columnar databases versus row based database and also injecting the data",
    "start": "2818319",
    "end": "2824520"
  },
  {
    "text": "into click house is so way faster uh than uh than for example into PG again",
    "start": "2824520",
    "end": "2830319"
  },
  {
    "text": "it's just it's it's not that PG is bad it's just like different if you're working with analytical data uh you",
    "start": "2830319",
    "end": "2836079"
  },
  {
    "text": "might want to try clicka cool um the last example I wanted",
    "start": "2836079",
    "end": "2841720"
  },
  {
    "text": "to show is about the retrieval augmented generation of this rug uh pattern uh",
    "start": "2841720",
    "end": "2848319"
  },
  {
    "text": "which uh I see being used more and more frequently and it's kind of creating a",
    "start": "2848319",
    "end": "2855640"
  },
  {
    "text": "chatbot based on large language model and the thing that we use large language",
    "start": "2855640",
    "end": "2861800"
  },
  {
    "text": "models right now on the daily basis but training a large language model is",
    "start": "2861800",
    "end": "2867760"
  },
  {
    "text": "expensive and also it takes time we are getting better and better Vis it but it's not something which you kind of",
    "start": "2867760",
    "end": "2874040"
  },
  {
    "text": "like oh let me leave it for two hours and it's done no um so there are different uh use cases where first of",
    "start": "2874040",
    "end": "2881040"
  },
  {
    "text": "all um you uh don't want to give the data to the large language model to be",
    "start": "2881040",
    "end": "2887839"
  },
  {
    "text": "trained on maybe it's like some user related private information or maybe",
    "start": "2887839",
    "end": "2894559"
  },
  {
    "text": "it's a data which is very very recent uh and you want to expand the knowledge of",
    "start": "2894559",
    "end": "2900000"
  },
  {
    "text": "the large language model uh on that data or uh maybe it's kind of this um",
    "start": "2900000",
    "end": "2908559"
  },
  {
    "text": "uh real time context like the rain or or like or something else like which is",
    "start": "2908559",
    "end": "2914240"
  },
  {
    "text": "happening right now so um and in this example again I",
    "start": "2914240",
    "end": "2919359"
  },
  {
    "text": "will link to provide link to kind of an article um in GitHub repository where",
    "start": "2919359",
    "end": "2924680"
  },
  {
    "text": "you have the code but this is example where uh assuming that a large language model does and I was communicating with",
    "start": "2924680",
    "end": "2932200"
  },
  {
    "text": "a Bedrock uh doesn't know much about the documentation of Ivan and I'm very sorry for a very boring example in this case",
    "start": "2932200",
    "end": "2938760"
  },
  {
    "text": "but still so I uh what I did I took the documentation which we have to Ivan and",
    "start": "2938760",
    "end": "2944280"
  },
  {
    "text": "I gave it as addition uh to this large language model so that it could answer",
    "start": "2944280",
    "end": "2950839"
  },
  {
    "text": "my question using its capability of kind of talking and coming up with all the",
    "start": "2950839",
    "end": "2956559"
  },
  {
    "text": "text but using the source of the data um from the external source which I",
    "start": "2956559",
    "end": "2961920"
  },
  {
    "text": "provided this particular example uses AWS um and we can split it into two",
    "start": "2961920",
    "end": "2967400"
  },
  {
    "text": "parts kind of also similarly to how I did it before the first part is will be the data inje um and this is where we",
    "start": "2967400",
    "end": "2975160"
  },
  {
    "text": "need to generate those embeddings from the existing uh data sour set or some",
    "start": "2975160",
    "end": "2981799"
  },
  {
    "text": "kind of a Data Corpus and we store the data in the um database here I also used",
    "start": "2981799",
    "end": "2988520"
  },
  {
    "text": "U open search uh because again it can work with Vector we could use something else here",
    "start": "2988520",
    "end": "2994400"
  },
  {
    "text": "doesn't have to be open search uh as well as for actually technically all those is like Lego you could use all",
    "start": "2994400",
    "end": "2999839"
  },
  {
    "text": "different uh items here um and the second part was was Data retrieval where we actually perform that Vector search",
    "start": "2999839",
    "end": "3007200"
  },
  {
    "text": "and we combine it with the request to large language model so um for those of",
    "start": "3007200",
    "end": "3012799"
  },
  {
    "text": "you who work with uh AWS and interested in this particular code I had a Sam",
    "start": "3012799",
    "end": "3018160"
  },
  {
    "text": "template uh generally I enjoyed using the serverless approach uh with the",
    "start": "3018160",
    "end": "3024319"
  },
  {
    "text": "Amazon Bedrock uh because then it meant I didn't have to run the model somewhere",
    "start": "3024319",
    "end": "3029920"
  },
  {
    "text": "in the cloud and running the model constantly if you don't make a lot of requests is pretty",
    "start": "3029920",
    "end": "3037079"
  },
  {
    "text": "expensive um so yeah so uh the data inje part during the data injection part as I",
    "start": "3037079",
    "end": "3044200"
  },
  {
    "text": "mentioned I use like the documentation parts so we split it into smaller chunks and then put it",
    "start": "3044200",
    "end": "3052160"
  },
  {
    "text": "into L3 bucket doesn't have to be this particular you could actually send get the data now I don't know like from the",
    "start": "3052160",
    "end": "3058200"
  },
  {
    "text": "Apachi Kafka um uh stream or something else but you need somewhere data so um",
    "start": "3058200",
    "end": "3064640"
  },
  {
    "text": "the idea was that whenever we send the data into S3 what we can do we can attach an event",
    "start": "3064640",
    "end": "3072200"
  },
  {
    "text": "um so here it was sqs uh so it gives the notification to sqs and sqs can take the",
    "start": "3072200",
    "end": "3078160"
  },
  {
    "text": "data and in turn uh runs the data on the",
    "start": "3078160",
    "end": "3083839"
  },
  {
    "text": "Lambda again this is depends on your particular architecture for me it was like how do I set the flow of the data",
    "start": "3083839",
    "end": "3091400"
  },
  {
    "text": "into open search so um with the Lambda uh what I could do then I can",
    "start": "3091400",
    "end": "3098559"
  },
  {
    "text": "take that piece of data the text in the document and uh I can process it using",
    "start": "3098559",
    "end": "3105280"
  },
  {
    "text": "the link chain so um there are different ways how you can work with models link",
    "start": "3105280",
    "end": "3111160"
  },
  {
    "text": "chains simplifies this rag pattern significantly so I would recommend if",
    "start": "3111160",
    "end": "3116200"
  },
  {
    "text": "you have working with the rug Solutions uh then uh try linkchain uh it's",
    "start": "3116200",
    "end": "3121280"
  },
  {
    "text": "available in different languages uh JavaScript uh python uh",
    "start": "3121280",
    "end": "3127319"
  },
  {
    "text": "java.net I'm not sure should have checked but maybe it also support something there and uh what we do when",
    "start": "3127319",
    "end": "3135000"
  },
  {
    "text": "the Lambda Handler to process the data uh we take the file name we get the records from there we uh use the beted",
    "start": "3135000",
    "end": "3142720"
  },
  {
    "text": "brck embedding to get the embedding itself and and we store that Vector in",
    "start": "3142720",
    "end": "3148680"
  },
  {
    "text": "open search and then in the open search generally um we get all that information",
    "start": "3148680",
    "end": "3155880"
  },
  {
    "text": "um this is op search dashboard and we can check what kind of vectors we have",
    "start": "3155880",
    "end": "3161880"
  },
  {
    "text": "and what is the text for that Vector so that's what we have in the database uh",
    "start": "3161880",
    "end": "3167079"
  },
  {
    "text": "once we have that similarly to how we did it with the movies now we can do the data",
    "start": "3167079",
    "end": "3173079"
  },
  {
    "text": "retrieval and in the data retrieval it's again it's the Lambda the model but here",
    "start": "3173079",
    "end": "3178400"
  },
  {
    "text": "it will be a bit different first of all I had to use JavaScript here so it's a bit of a mix",
    "start": "3178400",
    "end": "3185280"
  },
  {
    "text": "I'm sorry for that of languages it's like a salad but this particular one I wanted to use the stream ified response",
    "start": "3185280",
    "end": "3194040"
  },
  {
    "text": "so you know like how uh when chat GPT talks to you it's kind of you see this chunks of information it produces so uh",
    "start": "3194040",
    "end": "3202000"
  },
  {
    "text": "it actually um kind of creates a chain of the data and so far when I was using",
    "start": "3202000",
    "end": "3209880"
  },
  {
    "text": "uh the lambdas from AWS only JavaScript one was supporting that uh maybe there will be something else uh later so here",
    "start": "3209880",
    "end": "3217200"
  },
  {
    "text": "the idea is that we are creating a prompt to the language model and we create it chain uh",
    "start": "3217200",
    "end": "3226200"
  },
  {
    "text": "but also we provide information uh from the uh Vector uh",
    "start": "3226200",
    "end": "3233240"
  },
  {
    "text": "database in addition to uh the question question which we sent to the large",
    "start": "3233240",
    "end": "3239119"
  },
  {
    "text": "language model uh and then uh it combines that information I had also to specify that",
    "start": "3239119",
    "end": "3248079"
  },
  {
    "text": "from that llm that please use the additional data I provided you don't try",
    "start": "3248079",
    "end": "3254160"
  },
  {
    "text": "to get it from your own knowledge but just because I didn't know actually if that llm already familiar with Ivan and",
    "start": "3254160",
    "end": "3259240"
  },
  {
    "text": "I wanted just to have it like pure using llm for the case of like just talking",
    "start": "3259240",
    "end": "3265720"
  },
  {
    "text": "but using my data to give the correct information so this is a large language",
    "start": "3265720",
    "end": "3270920"
  },
  {
    "text": "model um with u Vector search there are some caveats here let's",
    "start": "3270920",
    "end": "3277440"
  },
  {
    "text": "say we often try to use rag pattern to eliminate hallucina hallucinations of",
    "start": "3277440",
    "end": "3284400"
  },
  {
    "text": "large language models but also if you are not doing it correctly if your data is not really good in those vectors you",
    "start": "3284400",
    "end": "3292040"
  },
  {
    "text": "might increase the number of hallucinations so you need to be very careful but it's super popular right now",
    "start": "3292040",
    "end": "3297599"
  },
  {
    "text": "approach and um uh many different applications okay the last thing I",
    "start": "3297599",
    "end": "3303559"
  },
  {
    "text": "wanted to share with you just an ideas uh for those of you who are just starting um uh with the embeddings",
    "start": "3303559",
    "end": "3313359"
  },
  {
    "text": "um if you are find this python try I python huging face has really amazing",
    "start": "3313359",
    "end": "3320680"
  },
  {
    "text": "set of all the all the models and it's actually very very easy to use and those",
    "start": "3320680",
    "end": "3326359"
  },
  {
    "text": "they update the libraries on a frequent basis so you might actually try to run the code you created yesterday and fails",
    "start": "3326359",
    "end": "3332760"
  },
  {
    "text": "um but apart from that inconvenience it because it just moves so fast it's actually very solid solution it's easy",
    "start": "3332760",
    "end": "3339400"
  },
  {
    "text": "to use um at least comparing to other options which I tried for example with JavaScript but if you are into",
    "start": "3339400",
    "end": "3346079"
  },
  {
    "text": "JavaScript to Java tensorflow uh still solid one might have a bit of a headaches uh then if you don't truly",
    "start": "3346079",
    "end": "3353400"
  },
  {
    "text": "want to write that code uh but you are with working with uh apis you can use uh",
    "start": "3353400",
    "end": "3359640"
  },
  {
    "text": "open AI um uh models you can use Amazon Bedrock you can run the models in Sage",
    "start": "3359640",
    "end": "3366359"
  },
  {
    "text": "maker um yeah and if you are go working with the retrieval augment augmented",
    "start": "3366359",
    "end": "3371799"
  },
  {
    "text": "generation look into length chain because that one will save you plenty of time this is kind",
    "start": "3371799",
    "end": "3378039"
  },
  {
    "text": "of the the best of the best Solutions we have right now um yes I wanted to show yeah and for",
    "start": "3378039",
    "end": "3385599"
  },
  {
    "text": "example if you are working with huging phase uh you can uh look at how to deploy the model for example they have",
    "start": "3385599",
    "end": "3392319"
  },
  {
    "text": "already example for um I'm using from time to time Sage maker you just copy",
    "start": "3392319",
    "end": "3397400"
  },
  {
    "text": "run it in the sage maker and it actually deploys your model it's probably like for the production environments you want to do some extra steps but at least if",
    "start": "3397400",
    "end": "3405119"
  },
  {
    "text": "you are experimenting for the playground it's easy to start just don't forget to clean that stuff uh later um so that you",
    "start": "3405119",
    "end": "3414160"
  },
  {
    "text": "are not wasting a lot of money um um then and some code for the Java but it's",
    "start": "3414160",
    "end": "3419839"
  },
  {
    "text": "probably less important so I want to leave you this couple of links first of all if you want to try",
    "start": "3419839",
    "end": "3427079"
  },
  {
    "text": "any of the Data Solutions which uh I showed and have extra credits uh that",
    "start": "3427079",
    "end": "3432520"
  },
  {
    "text": "gives you for the PG for we have a platform at Ian uh which integrates all",
    "start": "3432520",
    "end": "3438880"
  },
  {
    "text": "those Solutions together uh it's it's easy to use Easy to toop and we also",
    "start": "3438880",
    "end": "3444160"
  },
  {
    "text": "have uh uh free tier for pogress so it's quite convenient pogress my SQL and",
    "start": "3444160",
    "end": "3451079"
  },
  {
    "text": "radius that's where we have fre tiers um and second the links this is a GitHub",
    "start": "3451079",
    "end": "3456720"
  },
  {
    "text": "repository with a bunch of links to different solutions which I was showing",
    "start": "3456720",
    "end": "3462640"
  },
  {
    "text": "um on a regular basis we are doing that workshop with a tensorflow and movie",
    "start": "3462640",
    "end": "3468160"
  },
  {
    "text": "recommander it will be also tomorrow um uh so you can uh if you are",
    "start": "3468160",
    "end": "3473839"
  },
  {
    "text": "interested uh on the Ivan page there will be the link to that or just talk to me and I will share with you the link to",
    "start": "3473839",
    "end": "3480920"
  },
  {
    "text": "that Workshop uh and for the rest of the Demos in one or other way I have uh",
    "start": "3480920",
    "end": "3486880"
  },
  {
    "text": "links there so that's what I wanted to cover with you today and I think I have",
    "start": "3486880",
    "end": "3492000"
  },
  {
    "text": "two minutes extra for any questions you have um or I will be also around in case",
    "start": "3492000",
    "end": "3499799"
  },
  {
    "text": "you want to catch me later and talk about uh Vector search thank you",
    "start": "3499799",
    "end": "3508039"
  }
]
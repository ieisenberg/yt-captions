[
  {
    "start": "0",
    "end": "42000"
  },
  {
    "text": "hi everyone thanks for turning up late on on Friday as a software consultants",
    "start": "6069",
    "end": "13549"
  },
  {
    "text": "it's quite rare that you actually get to work on an exciting project technically interesting but also that",
    "start": "13549",
    "end": "19070"
  },
  {
    "text": "has has a real impact in terms of environments and people so we're really really excited to be able to present to",
    "start": "19070",
    "end": "26360"
  },
  {
    "text": "you today how to combat illegal fishing which in learning and Asia my name's Jess pani I'm a principal consultant at",
    "start": "26360",
    "end": "32480"
  },
  {
    "text": "engine Carmel Eve is a third-year associate engine karma we'll be taking you through some of the more practical",
    "start": "32480",
    "end": "38269"
  },
  {
    "text": "elements of the talk and in a while I'll just do some instructions so what are you going to learn well when we first",
    "start": "38269",
    "end": "45829"
  },
  {
    "start": "42000",
    "end": "42000"
  },
  {
    "text": "put this talk together we had a slide deck that came to about 300 slides I think and we showed around some people",
    "start": "45829",
    "end": "51409"
  },
  {
    "text": "and they said let you know you've really got to cut some of this out so it's a real is a real challenge to actually sort of cut this down into sort of a",
    "start": "51409",
    "end": "57499"
  },
  {
    "text": "series of messages which we thought were we're going to be really important so we've we've we focused on two or three",
    "start": "57499",
    "end": "62629"
  },
  {
    "text": "really key messages the first obviously is what's the problem you know what is it about illegal fishing that is an",
    "start": "62629",
    "end": "69440"
  },
  {
    "text": "issue we're then going to focus in on commodity computing and we're going to try and explain to you why we think that",
    "start": "69440",
    "end": "75650"
  },
  {
    "text": "not all service offerings are the same we are then going to outline an approach that we took for solving this problem we",
    "start": "75650",
    "end": "82970"
  },
  {
    "text": "think it's a really important aspect of the talk it's it really sort of direct dives into how to approach planetary",
    "start": "82970",
    "end": "91340"
  },
  {
    "text": "scale compute especially when you're looking at low cost and this was really important for this project comments",
    "start": "91340",
    "end": "97370"
  },
  {
    "text": "thinking to talk you through how to build a real end-to-end scenario she can",
    "start": "97370",
    "end": "103220"
  },
  {
    "text": "show you some code and how that all works together and then finally she's going to talk you through some of the lessons learned things that we found",
    "start": "103220",
    "end": "108860"
  },
  {
    "text": "were really really helpful that we think would be useful for you to know so what",
    "start": "108860",
    "end": "113960"
  },
  {
    "text": "is the problem about illegal fishing well I for one didn't really appreciate",
    "start": "113960",
    "end": "119120"
  },
  {
    "text": "the impact that illegal fishing was having on the environment and on people if we look at some of the statistics",
    "start": "119120",
    "end": "126729"
  },
  {
    "text": "three billion people rely on seafood as a source of protein I try had absolutely",
    "start": "126729",
    "end": "132650"
  },
  {
    "text": "no idea about it someone first started third all fish stocks are no longer biology sustainable which is is",
    "start": "132650",
    "end": "138069"
  },
  {
    "text": "devastatingly sad one in five fish soul was caught illegally and that's only twenty four billion dollars worth and",
    "start": "138069",
    "end": "144969"
  },
  {
    "text": "also there's other things going on like there's a strong association with other criminal activities such as people trafficking illegal Salvage and those",
    "start": "144969",
    "end": "153220"
  },
  {
    "text": "types of things so we're really fortunate to work with a company called ocean mind their mission is to solve",
    "start": "153220",
    "end": "160450"
  },
  {
    "text": "these problems they do this by collecting billions of data points around the world they run a whole bunch",
    "start": "160450",
    "end": "166930"
  },
  {
    "text": "of AI machine learning over that data and they identify illegal fishing activity they compile information for",
    "start": "166930",
    "end": "175030"
  },
  {
    "text": "law enforcement for seafood buyers for Responsible sustainable fishing products",
    "start": "175030",
    "end": "182010"
  },
  {
    "text": "so they're a fascinating organization who are incredibly motivated this is a",
    "start": "182010",
    "end": "188230"
  },
  {
    "text": "picture of their NASA style Mission Control Center this actually takes up a",
    "start": "188230",
    "end": "193599"
  },
  {
    "text": "massive sort of walls or size at the end of this room I suppose and each of those dots you can see they're our vessels if",
    "start": "193599",
    "end": "200199"
  },
  {
    "text": "they're boats and you can see the outline of the continents that the boats are making you maybe make out the major",
    "start": "200199",
    "end": "206079"
  },
  {
    "text": "ports as well so there's an awful lot of activity that's going on in the world this is just one of their applications",
    "start": "206079",
    "end": "212769"
  },
  {
    "text": "which is great you can zoom in you can actually go down to an individual vessel you can play that vessel the track of",
    "start": "212769",
    "end": "219040"
  },
  {
    "text": "that vessel over time see where it's going seeing how it moves and they retain a lot of data behind the scenes",
    "start": "219040",
    "end": "225129"
  },
  {
    "text": "they can rewind they can replay going back many many years they have other applications as well such as analyst applications that their analysts use to",
    "start": "225129",
    "end": "233769"
  },
  {
    "text": "correlate information before forwarding on to the authorities so how do they do",
    "start": "233769",
    "end": "240159"
  },
  {
    "start": "239000",
    "end": "239000"
  },
  {
    "text": "this well first of all they gather vessel telemetry data all vessels over",
    "start": "240159",
    "end": "246849"
  },
  {
    "text": "certain signs are required by law to broadcast their position and information about who they are and regular intervals",
    "start": "246849",
    "end": "252930"
  },
  {
    "text": "OSHA might also use satellite imagery to correlate what they suspect is happening",
    "start": "252930",
    "end": "258070"
  },
  {
    "text": "with actual pictures of oceans and vessels in places possibly they shouldn't be shouldn't be they also use",
    "start": "258070",
    "end": "264340"
  },
  {
    "text": "radar imagery and they take all this data and they feed it through quite some quite advanced geospatial",
    "start": "264340",
    "end": "269889"
  },
  {
    "text": "analysis models and what they're doing here is they're doing a lot of feature engineering there's a lot of heavy lifting feature engineering which is",
    "start": "269889",
    "end": "276189"
  },
  {
    "text": "going on that then gets fed into their machine learning models to go and actually detect okay what type of phishing do we think is happening in",
    "start": "276189",
    "end": "282340"
  },
  {
    "text": "this particular region and is it illegal is it not illegal those phishing alerts are then used",
    "start": "282340",
    "end": "288490"
  },
  {
    "text": "through api's and integrations to drive the systems that they use so they're",
    "start": "288490",
    "end": "295449"
  },
  {
    "start": "294000",
    "end": "294000"
  },
  {
    "text": "like any other organization really they've got business drivers and constraints what I love about OSHA - they've got",
    "start": "295449",
    "end": "300819"
  },
  {
    "text": "it's really great passion for solving problems of this nature and they they",
    "start": "300819",
    "end": "306819"
  },
  {
    "text": "really see their technologies being key to solving a whole bunch of other problems like I mentioned you know human",
    "start": "306819",
    "end": "312039"
  },
  {
    "text": "slavery people trafficking those sorts of things in order to do this they need faster more real-time alerting they need",
    "start": "312039",
    "end": "319180"
  },
  {
    "text": "more sophisticated AI and more AI they want to start engaging and collaborating",
    "start": "319180",
    "end": "325629"
  },
  {
    "text": "with people outside the organization so sharing the story I suppose sharing some other problem so that people can engage",
    "start": "325629",
    "end": "331270"
  },
  {
    "text": "collaborate but they're a smaller organization there are not-for-profit organisation therefore they've got",
    "start": "331270",
    "end": "336460"
  },
  {
    "text": "budget constraints their current systems run on premise there's no room to scale",
    "start": "336460",
    "end": "342039"
  },
  {
    "text": "those those systems and a lot of their time was taking up to tackling fires and",
    "start": "342039",
    "end": "348520"
  },
  {
    "text": "not enough time innovating so the decision was made to migrate to the cloud and that always is easier said",
    "start": "348520",
    "end": "355210"
  },
  {
    "text": "than done this is just something so many different approaches so many strategies you can take and that's where we came involved",
    "start": "355210",
    "end": "362229"
  },
  {
    "text": "to try and help them sort of on this journey and look at how they could actually do this in a smart way",
    "start": "362229",
    "end": "367349"
  },
  {
    "start": "367000",
    "end": "367000"
  },
  {
    "text": "one of the first conversations we really need to have is this how are we going to do this migration if we look at sort of",
    "start": "367349",
    "end": "373810"
  },
  {
    "text": "the cloud evolution ocean mind with very much classic on-premise I mean literally on-premise they were looking after the",
    "start": "373810",
    "end": "378819"
  },
  {
    "text": "building security they were looking after the servers they were provisioning their servers looking off-road operating systems and",
    "start": "378819",
    "end": "384129"
  },
  {
    "text": "application logic and obviously that takes a lot of time and a lot of effort we could look at lift and shift and",
    "start": "384129",
    "end": "391779"
  },
  {
    "text": "evolution in the cloud lifting shifting workloads can work problem with that approach is that",
    "start": "391779",
    "end": "396849"
  },
  {
    "text": "they're going to be taking all the baggage of their architecture that they have on-premise which has imitations in terms of scale and just",
    "start": "396849",
    "end": "403370"
  },
  {
    "text": "replicating that in a nice environment of course more recently we've got powers",
    "start": "403370",
    "end": "408530"
  },
  {
    "text": "and we've got service serverless which is being talked about an awful lot and we're promised that if we can migrate",
    "start": "408530",
    "end": "413690"
  },
  {
    "text": "from on-premise to server less potential for cost savings and general effort is",
    "start": "413690",
    "end": "419120"
  },
  {
    "text": "is quite significant the problem is to think a little bit with services that",
    "start": "419120",
    "end": "424700"
  },
  {
    "start": "422000",
    "end": "422000"
  },
  {
    "text": "it's becoming a bit of an overloaded term I prefer to think about it in terms of commodity computing because I",
    "start": "424700",
    "end": "431930"
  },
  {
    "text": "understand commodity services I use commodity services every day who who in",
    "start": "431930",
    "end": "437270"
  },
  {
    "text": "the room has a smart meter okay so for",
    "start": "437270",
    "end": "442580"
  },
  {
    "text": "those of you who maybe aren't from the UK there's been a massive push recently for smart meter smart energy meters to",
    "start": "442580",
    "end": "449420"
  },
  {
    "text": "be installed in homes and the idea behind this is that if you can see what you're consuming then you're",
    "start": "449420",
    "end": "456080"
  },
  {
    "text": "incentivized you know see how much it's costing you are incentivized to reduce your energy usage so I mean that's the",
    "start": "456080",
    "end": "463340"
  },
  {
    "text": "kind of approach that's the kind of model we can apply to cloud computing but most most cloud services aren't",
    "start": "463340",
    "end": "470930"
  },
  {
    "text": "actually like that when you think about it for example i'm yeah i plug in my kettle to make myself a cup of tea",
    "start": "470930",
    "end": "477520"
  },
  {
    "text": "i've actually got very used to before i had the smart meter or i used to fill up",
    "start": "477520",
    "end": "482720"
  },
  {
    "text": "fill up the capital will wait the top and put it on now i've got smart meter i can actually see the money burning down i actually make sure all they've ain't",
    "start": "482720",
    "end": "489440"
  },
  {
    "text": "got enough watering for the number of cups that i want i'm getting quite good at that but in cloud computing quite",
    "start": "489440",
    "end": "495350"
  },
  {
    "text": "often you have to pre provision capacity okay that's a bit like saying that okay",
    "start": "495350",
    "end": "500990"
  },
  {
    "text": "well on average IE consume about 30 kilowatt hours per day so I got to my energy supplier and say",
    "start": "500990",
    "end": "506030"
  },
  {
    "text": "hey can I have 30 water kettle hours per day and they say absolutely fine no problem but that doesn't make sense when I know",
    "start": "506030",
    "end": "511100"
  },
  {
    "text": "they turn on my oven because my oven takes 2,000 kilowatt hours and all of a sudden I'm under provisioned so I have",
    "start": "511100",
    "end": "517550"
  },
  {
    "text": "to now run a 2,000 kilowatt hours overpay essentially well that's fine",
    "start": "517550",
    "end": "523340"
  },
  {
    "text": "because the energy could provider can give me a nice slider and they can say well can slide all the way down if I",
    "start": "523340",
    "end": "528410"
  },
  {
    "text": "want to I only slide it up to 2,000 kilowatt hours for my when for the time that I'm doing my cooking",
    "start": "528410",
    "end": "533820"
  },
  {
    "text": "I thought that was that's pretty good but chances aren't gonna forget to debt scale down when I finished it's a bit of",
    "start": "533820",
    "end": "539460"
  },
  {
    "text": "a pain that's okay what they can do is they can auto scale for me so they can they can scale up when I did",
    "start": "539460",
    "end": "545610"
  },
  {
    "text": "it need it and they can scale down when I need it problem is they turn around and say well that's fine but you're being billed per",
    "start": "545610",
    "end": "551040"
  },
  {
    "text": "hour so every time put the kettle on it takes three minutes bought a cup of tea I'm being charged for an hour of",
    "start": "551040",
    "end": "556140"
  },
  {
    "text": "consumption that's that's kind of crazy and yet that is what the vast majority of cloud services still do today to kind",
    "start": "556140",
    "end": "563820"
  },
  {
    "text": "of show you what that kind of means in sort of in practical terms we did a",
    "start": "563820",
    "end": "569400"
  },
  {
    "start": "565000",
    "end": "565000"
  },
  {
    "text": "little bit modeling the beginning of this project and we looked at a 10 year horizon we looked at a lift and shift scenario we've done a lot of work in",
    "start": "569400",
    "end": "576210"
  },
  {
    "text": "cosmos TV in the past we love cosmos TV before okay let's modeling cosmos TV you can see lifting shift after a year we're up",
    "start": "576210",
    "end": "582960"
  },
  {
    "text": "to a hundred thousand pounds per year after 10 years it's half a million and the reason for that increase is because",
    "start": "582960",
    "end": "588990"
  },
  {
    "text": "ocean mind retain all their data they want that map that you saw then what's better move the dial to actually see ten",
    "start": "588990",
    "end": "595980"
  },
  {
    "text": "years worth you know Tim what what was this situation ten years ago what's the situation now in kind of live kind of a",
    "start": "595980",
    "end": "601260"
  },
  {
    "text": "sort of experience there's also we've also factored in the growth rates of",
    "start": "601260",
    "end": "607020"
  },
  {
    "text": "beta so they are seeing that there's going to be an increase of data over time as more and more vessels and more",
    "start": "607020",
    "end": "613020"
  },
  {
    "text": "information becomes available we look at cosmos TV initially starts working out a",
    "start": "613020",
    "end": "618540"
  },
  {
    "text": "lot cheaper by the way service cosmos DB is advertised as a service product as I say",
    "start": "618540",
    "end": "624330"
  },
  {
    "text": "I love cosmos TV 37,000 bit cheaper but we're actually by year 10 it's nearly a",
    "start": "624330",
    "end": "630000"
  },
  {
    "text": "million and the reason for that is because we were looking specifically the sequel API so if you know cosmos TV it's",
    "start": "630000",
    "end": "635400"
  },
  {
    "text": "got a whole bunch different API is you can use the sequel API has some geospatial capability so we thought hey",
    "start": "635400",
    "end": "640410"
  },
  {
    "text": "we'll try that but if we model that out we actually found that it got more expensive and the reason being is that the storage is dominating JSON formats",
    "start": "640410",
    "end": "647280"
  },
  {
    "text": "and as you've probably heard it and probably know that's quite an efficient",
    "start": "647280",
    "end": "652440"
  },
  {
    "text": "inefficient format so what if we could take the problem and apply it to some",
    "start": "652440",
    "end": "658050"
  },
  {
    "text": "more I suppose more commodity based server services so something like Azure data Lake store or as a storage and as",
    "start": "658050",
    "end": "664230"
  },
  {
    "text": "your functions and these are closer to the more of the commodity model the that that I actually think it's",
    "start": "664230",
    "end": "669330"
  },
  {
    "text": "worthwhile we ran this is like a sneak",
    "start": "669330",
    "end": "674430"
  },
  {
    "text": "peek in sneak peek into the future we ran these this particular key workloads",
    "start": "674430",
    "end": "681560"
  },
  {
    "text": "and we benchmarked them and this is the numbers we actually came up with so data Lake store is significantly cheaper it's",
    "start": "681560",
    "end": "687930"
  },
  {
    "text": "based on Azure storage so it is significantly cheaper as your function is actually ridiculously cheap so 58",
    "start": "687930",
    "end": "693300"
  },
  {
    "text": "pounds per month these are so what you",
    "start": "693300",
    "end": "698820"
  },
  {
    "text": "know it's a no-brainer so the problem we",
    "start": "698820",
    "end": "704610"
  },
  {
    "text": "really have is okay where these services are cheap but we're losing out a lot of functionality the lift and shift had a",
    "start": "704610",
    "end": "710670"
  },
  {
    "text": "very dedicated specialist geospatial database running behind it cosmos DB has got some great features",
    "start": "710670",
    "end": "715710"
  },
  {
    "text": "it's got SVM really sort of groundbreaking SLA is it's excellent so we you know is it possible we can",
    "start": "715710",
    "end": "720810"
  },
  {
    "text": "replace those great services with something that's a lot cheaper and that was our that was our challenge so if I",
    "start": "720810",
    "end": "727260"
  },
  {
    "start": "726000",
    "end": "726000"
  },
  {
    "text": "summarize the service characteristics that we think are important so 0 administration probably heard about",
    "start": "727260",
    "end": "732440"
  },
  {
    "text": "pricing based on consumption which is the key part of this transparent scaling",
    "start": "732440",
    "end": "738330"
  },
  {
    "text": "from zero one of the interesting sort of side effects or downsides to these types",
    "start": "738330",
    "end": "744510"
  },
  {
    "text": "of models is you quite often limited in terms of the resources they kind of run you in a sandbox and the really sort of",
    "start": "744510",
    "end": "749760"
  },
  {
    "text": "cheap SKUs you're kind of sharing capacity with a whole bunch of other people running on Azure and as such you're limited you're constrained by the",
    "start": "749760",
    "end": "755730"
  },
  {
    "text": "amount of memory you can consume in the number of connection so that's the other side of the story we need to be a little bit careful about but we want the",
    "start": "755730",
    "end": "761940"
  },
  {
    "text": "ability to be able to provision capacity if we need to so whatever services we use we want to be able to say ok well",
    "start": "761940",
    "end": "767550"
  },
  {
    "text": "actually if for whatever reason we can't get our workloads running in you know in our consumption based model you know",
    "start": "767550",
    "end": "773520"
  },
  {
    "text": "maybe that one workload we might actually run out on a creep of on a pre provision capacity basis and a lot of",
    "start": "773520",
    "end": "779910"
  },
  {
    "text": "these sort of frankly service frameworks which functions as a service frameworks can now run in containers and that includes at your functions and well",
    "start": "779910",
    "end": "785820"
  },
  {
    "text": "we're not specifically talking about containers here which we're actually running it on the edge of fabric directly that is another option for us",
    "start": "785820",
    "end": "792540"
  },
  {
    "text": "if we want to be a portable in terms of cloud so another important point really",
    "start": "792540",
    "end": "799290"
  },
  {
    "text": "is is the scale the problem here so when we're doing lots and lots of small pieces of work",
    "start": "799290",
    "end": "805399"
  },
  {
    "text": "the cost and the time is proportional to the number of implications the number of messages that you're processing so if",
    "start": "805399",
    "end": "812010"
  },
  {
    "text": "you're just running a very simple application sometimes it may not be worth optimizing but when you're processing billions of messages a month",
    "start": "812010",
    "end": "818600"
  },
  {
    "text": "small optimizations can actually have a massive impact okay so that's actually quite key a key concept a key thing that",
    "start": "818600",
    "end": "825269"
  },
  {
    "text": "we you know really really as we went through alongside the fact that we are constrained in terms of things like",
    "start": "825269",
    "end": "831000"
  },
  {
    "text": "memory a number of connections going outbound as I mentioned just a moment ago so this is a typical pipeline for",
    "start": "831000",
    "end": "839279"
  },
  {
    "text": "one of their key workloads they ingest data from external data providers AIS is",
    "start": "839279",
    "end": "845490"
  },
  {
    "text": "the format of vessel track data you can go by that yourself if you want to satellite imagery in the cases of just",
    "start": "845490",
    "end": "853199"
  },
  {
    "text": "images those are binary formats they get ingested we need to do something with that information we need to parse it",
    "start": "853199",
    "end": "859170"
  },
  {
    "text": "into a format that allows us to do analytics so part of those interval tracks run those through some geospatial",
    "start": "859170",
    "end": "866430"
  },
  {
    "text": "models some feature engineering and then finally you know run our ml models over the top that's it detect illegal fishing",
    "start": "866430",
    "end": "872810"
  },
  {
    "text": "and the challenge here is you know can we do this with Azure functions and data Lake store so we're gonna run a couple",
    "start": "872810",
    "end": "882149"
  },
  {
    "text": "of couple of demos it's first time we talk to NDC and so we thought we'd do",
    "start": "882149",
    "end": "887459"
  },
  {
    "text": "some live demos so what could possibly go wrong this is actually more actually",
    "start": "887459",
    "end": "892740"
  },
  {
    "text": "like a pre demo demo okay but I do get the ability just quickly show you a little bit about datastore if you",
    "start": "892740",
    "end": "898139"
  },
  {
    "text": "haven't already seen it so data Lake store is a is as I said it's bet it's",
    "start": "898139",
    "end": "903269"
  },
  {
    "text": "built on actual storage so it gets the same kind of the same sort of features in terms of its deployed in every region",
    "start": "903269",
    "end": "910279"
  },
  {
    "text": "but it builds on it by providing a hierarchical namespace and that sounds really fancy but all it really means is",
    "start": "910279",
    "end": "915930"
  },
  {
    "text": "is that you can create files and folders and you can apply security rules to",
    "start": "915930",
    "end": "921449"
  },
  {
    "text": "those files and folders and that's really kind of important because when you think about actually partitioning the data within the system we want to",
    "start": "921449",
    "end": "927329"
  },
  {
    "text": "make sure that one the person that's responsible for parsing the data only gets access read access from the source",
    "start": "927329",
    "end": "933060"
  },
  {
    "text": "data and write right access to the target folder so we can really get a you know really",
    "start": "933060",
    "end": "938829"
  },
  {
    "text": "lockdown from a security point of view and forward as if you've done anything with spark or any of those types of platforms you'll be aware of the way we",
    "start": "938829",
    "end": "945819"
  },
  {
    "text": "can use folders to remove the data that we're not interested in and only focus on the the dates that we are interested",
    "start": "945819",
    "end": "951220"
  },
  {
    "text": "in so here you can see we've got a real folder I'll quickly show you that so",
    "start": "951220",
    "end": "957069"
  },
  {
    "text": "we've got a real folder we've got this AOS folder that's our source data you know they're games anything with spark",
    "start": "957069",
    "end": "963249"
  },
  {
    "text": "in the past you might be familiar with partitioning by dates and that's just really quite useful for time series type information such as this where all the",
    "start": "963249",
    "end": "970360"
  },
  {
    "text": "data for a particular time bucket goes into one folder here's an example file it's it's an nm for files it's a binary",
    "start": "970360",
    "end": "976449"
  },
  {
    "text": "format I can't read that just by in notepad I've got actually pars of that before I can do anything with it we've",
    "start": "976449",
    "end": "982269"
  },
  {
    "text": "got another these are those file systems by the way so these these blob containers this the core blob containers",
    "start": "982269",
    "end": "987879"
  },
  {
    "text": "I think as a storage Explorer which is what stoolies hasn't quite renamed things from I just orage days but it's",
    "start": "987879",
    "end": "994300"
  },
  {
    "text": "actually known as file systems so we've got in our data folder parts data if I",
    "start": "994300",
    "end": "999999"
  },
  {
    "text": "go into the parts data we get a similar structure partition by date there's a",
    "start": "999999",
    "end": "1005100"
  },
  {
    "text": "park a file there we chose Park a for this talk it's not important there's we got some benefits in terms of",
    "start": "1005100",
    "end": "1010550"
  },
  {
    "text": "compression Parque is better from a crisp compress point of view there's other reasons why we may want to use that as well in the future and if I jump",
    "start": "1010550",
    "end": "1019350"
  },
  {
    "text": "out again we've got this folder called party projections this will become",
    "start": "1019350",
    "end": "1025020"
  },
  {
    "text": "apparent in a moment but for now just know that it's empty it's got no date in it and finally we've",
    "start": "1025020",
    "end": "1031438"
  },
  {
    "text": "got signals and signals are the outputs these are all features are fishing alerts these are the things which are driving the business and again for the",
    "start": "1031439",
    "end": "1038159"
  },
  {
    "text": "benefit of this demo just notice that it nothing in there okay",
    "start": "1038159",
    "end": "1045140"
  },
  {
    "text": "okay so it's developing a feature pipe",
    "start": "1048410",
    "end": "1054030"
  },
  {
    "start": "1051000",
    "end": "1051000"
  },
  {
    "text": "and I had we go about this nice I as I say think of anything from this talk this I think this is the most important support the important takeaway really",
    "start": "1054030",
    "end": "1060320"
  },
  {
    "text": "what is the process we took lots of people when they come across these tops problems they focus on the data they go",
    "start": "1060320",
    "end": "1065640"
  },
  {
    "text": "right we got some data from our data providers they suck it all in let's process it let's clean it let's check it in a model that kind of makes sense we",
    "start": "1065640",
    "end": "1073440"
  },
  {
    "text": "actually took me up completely opposite approach we focused on the workload first so for example vessels and",
    "start": "1073440",
    "end": "1079260"
  },
  {
    "text": "proximity vessels in proximity is a really interesting feature that is can",
    "start": "1079260",
    "end": "1085320"
  },
  {
    "text": "be used to machine many models so that's the idea that two vessels at the same point in the same space at the same",
    "start": "1085320",
    "end": "1091530"
  },
  {
    "text": "point of time may indicate some information that could be useful for detecting illegal fishing what's",
    "start": "1091530",
    "end": "1097980"
  },
  {
    "text": "interesting about focusing on the workload is that it provides us with a really clear need it's a single unit of",
    "start": "1097980",
    "end": "1103500"
  },
  {
    "text": "work it provides us with a very nice test boundary we know what outputs we really need and therefore we can",
    "start": "1103500",
    "end": "1108720"
  },
  {
    "text": "actually define what it is we want and so and then also one of the problems I",
    "start": "1108720",
    "end": "1116430"
  },
  {
    "text": "think or one of the fears of this approach of using functions are well the problem is we keep we throw away this database this geospatial database then",
    "start": "1116430",
    "end": "1122280"
  },
  {
    "text": "well this rich features now all we've got is c-sharp we know we start from scratch and and yes I can understand",
    "start": "1122280",
    "end": "1127500"
  },
  {
    "text": "that fear but actually in practice think about it you've got you can write your own code whatever you want you're not",
    "start": "1127500",
    "end": "1132930"
  },
  {
    "text": "constrained by the platforms of old you've got open source you can have a",
    "start": "1132930",
    "end": "1138420"
  },
  {
    "text": "look and a lot of people who have been developing these great platforms actually open source a lot are there they're library so you can just pick and",
    "start": "1138420",
    "end": "1144390"
  },
  {
    "text": "choose what you need to solve a very very specific problem so once you've kind of defined the",
    "start": "1144390",
    "end": "1151080"
  },
  {
    "text": "behavior and you've understood how you gonna solve it it's there in that case of well how do we know you have yourself",
    "start": "1151080",
    "end": "1157500"
  },
  {
    "text": "the database problem how do you solve the the look how do we find the data we need because you know every single vessel coming in regularly you know",
    "start": "1157500",
    "end": "1163950"
  },
  {
    "text": "billions of vessel tracks coming in a month you know that's crazy so rather than rely on a database per se",
    "start": "1163950",
    "end": "1172590"
  },
  {
    "text": "why don't we just say what information at any given time does that processing need and what is the optimum format for",
    "start": "1172590",
    "end": "1178530"
  },
  {
    "text": "it to arrive so us yourself I was gonna write a fart the ideal file just a file on this with all the data for I need in the right order",
    "start": "1178530",
    "end": "1184740"
  },
  {
    "text": "in the right way its format to think perfectly for my workload that's gotta",
    "start": "1184740",
    "end": "1190260"
  },
  {
    "text": "be the most optimum solution and if you think about it files themselves data Lake store is a file based system fit",
    "start": "1190260",
    "end": "1196350"
  },
  {
    "text": "essentially but also they're quite easy to cache as well so whilst we to find our optimal storage for our particular",
    "start": "1196350",
    "end": "1202500"
  },
  {
    "text": "type of processing we can even work backwards and figure out where we're gonna get that from and where there are providers are capable of providing that",
    "start": "1202500",
    "end": "1208440"
  },
  {
    "text": "information in the time that we need and we can do some experiments around that if you repeat this you end up this you",
    "start": "1208440",
    "end": "1216390"
  },
  {
    "start": "1213000",
    "end": "1213000"
  },
  {
    "text": "end up with lots of very well-defined units of work and you end up with those",
    "start": "1216390",
    "end": "1222060"
  },
  {
    "text": "units of work owning the schemer and the data that they need to operate and it's software developers we've become quite",
    "start": "1222060",
    "end": "1227340"
  },
  {
    "text": "used to doing this it's kind of almost like a micro services architecture really if you think about it now tight",
    "start": "1227340",
    "end": "1233250"
  },
  {
    "text": "really well-defined boundaries testable boundaries analytics for some reason doesn't really do this so much if you",
    "start": "1233250",
    "end": "1239070"
  },
  {
    "text": "don't a lot of data analytics traditional kind of data scientists don't really kind of thinking these sorts of kind of ways so I think it's something that there's developer",
    "start": "1239070",
    "end": "1244470"
  },
  {
    "text": "community we can brood as I start bringing our skill set to some of these more outlets or traditional old let's go down a little product problems data",
    "start": "1244470",
    "end": "1251670"
  },
  {
    "text": "projections is quite an interesting concept you'll see that what we're doing here is we're defining a series of data projections these are our schemas are",
    "start": "1251670",
    "end": "1257880"
  },
  {
    "text": "optimized data sets we're reading those out and basically what we mean by this is we're taking raw data we're",
    "start": "1257880",
    "end": "1262890"
  },
  {
    "text": "projecting it out into the formats we need okay for our optimal processing important concepts so what about our",
    "start": "1262890",
    "end": "1269940"
  },
  {
    "text": "service machine learning well if you know anything about onyx onyx stands for",
    "start": "1269940",
    "end": "1275280"
  },
  {
    "start": "1270000",
    "end": "1270000"
  },
  {
    "text": "the open your network exchange it's a specification that allows you to serialize or defines how to serialize",
    "start": "1275280",
    "end": "1280890"
  },
  {
    "text": "computational graphs what's interesting about this is it allows you to train models in your standard tools that",
    "start": "1280890",
    "end": "1287400"
  },
  {
    "start": "1285000",
    "end": "1285000"
  },
  {
    "text": "you're all you familiar with so you can train a model in tensorflow you can export it to an onyx model and then run that onyx model for scoring or",
    "start": "1287400",
    "end": "1294570"
  },
  {
    "text": "inference on anything pretty much so at your functions you can run you can run on two models and out your functions if",
    "start": "1294570",
    "end": "1300510"
  },
  {
    "text": "you need out to machine services maybe got some GPUs that you need to rely on you can use as machine learning certain machine learning service you can run on",
    "start": "1300510",
    "end": "1308010"
  },
  {
    "text": "virtual machines obviously you can run on the edge devices you've got all these different options and again it's not",
    "start": "1308010",
    "end": "1313230"
  },
  {
    "text": "about so you must run everything in service we're saying is if you have the option it's not a good thing right",
    "start": "1313230",
    "end": "1318739"
  },
  {
    "text": "finally before I hand over to Carmel I just want to talk about something else that's really important in our kind of",
    "start": "1318739",
    "end": "1324179"
  },
  {
    "start": "1319000",
    "end": "1319000"
  },
  {
    "text": "learnings really if you're a data scientist you'll be very familiar with being very very strict with yourself",
    "start": "1324179",
    "end": "1330210"
  },
  {
    "text": "about defining the hypothesis and the success criteria up front what you do is you go away and once you've got your",
    "start": "1330210",
    "end": "1337049"
  },
  {
    "text": "your success criteria you go away you try and build a model that actually meets that will prove that hypothesis",
    "start": "1337049",
    "end": "1342090"
  },
  {
    "text": "and you measure and adapt according to the results you observe a software engineers we are more we're not as good",
    "start": "1342090",
    "end": "1348450"
  },
  {
    "text": "at doing that but we can treat it in exactly the same way so can we process 1.5 billion messages a month for less",
    "start": "1348450",
    "end": "1354389"
  },
  {
    "text": "than 10 pounds in compute cost well that's a hypothesis can we do it the only way we're gonna know is by trying and measuring through benchmarking and",
    "start": "1354389",
    "end": "1360509"
  },
  {
    "text": "adapting according to the results we observe it's a mindset change I think we all need to get into as we start working",
    "start": "1360509",
    "end": "1365669"
  },
  {
    "text": "in these kind of environments so that's the theory I'm gonna hand over to come",
    "start": "1365669",
    "end": "1370799"
  },
  {
    "text": "out to talk through some of the practical elements well I've got feeling",
    "start": "1370799",
    "end": "1381090"
  },
  {
    "text": "in a few years I'm gonna be looking back on this and going yeah the first public speech camera did it was a NDC London and people gonna look at me like wow",
    "start": "1381090",
    "end": "1387239"
  },
  {
    "text": "that's insane Hannah but here we are so so what do we",
    "start": "1387239",
    "end": "1393210"
  },
  {
    "text": "need to do to build up these processing pipelines for the analysis we need to run and so the analysis I'm gonna focus",
    "start": "1393210",
    "end": "1398759"
  },
  {
    "text": "on is detecting vessel proximity so that means finding ships that are within a",
    "start": "1398759",
    "end": "1403950"
  },
  {
    "text": "certain distance of each other for a certain amount of time and this is important because that was information that fed into ocean miles machine",
    "start": "1403950",
    "end": "1411239"
  },
  {
    "text": "learning models so the way we used to do this was take this vessel point data from ship checking in at regular",
    "start": "1411239",
    "end": "1417539"
  },
  {
    "text": "intervals and from that build up vessel tracks and then run the proximity analysis over those tracks in order to",
    "start": "1417539",
    "end": "1422940"
  },
  {
    "text": "detect these events and raise alerts based on that so because we decided to",
    "start": "1422940",
    "end": "1429090"
  },
  {
    "start": "1427000",
    "end": "1427000"
  },
  {
    "text": "take the service approach rather than using these is or out-of-the-box solutions we had to build up this analysis ourselves so the way we did",
    "start": "1429090",
    "end": "1436259"
  },
  {
    "text": "that was we took two consecutive vessel points in a track and using the velocity in both x and y direction built up",
    "start": "1436259",
    "end": "1444090"
  },
  {
    "text": "equations for the ship solution over time and then just by Pythagoras",
    "start": "1444090",
    "end": "1449900"
  },
  {
    "text": "the square of the distance between two ships is just the square of the distance in their position in each of these directions so using this equation on the",
    "start": "1449900",
    "end": "1456950"
  },
  {
    "text": "right we could then work out how long work out the times at which two ships came in to contact one another and again",
    "start": "1456950",
    "end": "1464360"
  },
  {
    "text": "when they left that contact distance and therefore work out sort of how long we ship for in contact with each other and",
    "start": "1464360",
    "end": "1470450"
  },
  {
    "text": "raise alerts based off of that the issue with this analysis is that comparing two",
    "start": "1470450",
    "end": "1476480"
  },
  {
    "text": "hundred thousand vessels to every other ship in the ocean is a really expensive thing to do so vessels check in about",
    "start": "1476480",
    "end": "1482660"
  },
  {
    "text": "every two minutes on average so that's about 300 million comparisons a second so we really need to find a way to",
    "start": "1482660",
    "end": "1488690"
  },
  {
    "text": "reduce the amount of comparisons we needed to make and identify likely",
    "start": "1488690",
    "end": "1493790"
  },
  {
    "text": "candidates for this positive proximity analysis so when we were researching",
    "start": "1493790",
    "end": "1499070"
  },
  {
    "text": "geospatial algorithms we came across a paper about arteries and arteries are a data structure for storing and indexing",
    "start": "1499070",
    "end": "1504950"
  },
  {
    "text": "spatial data so for our analysis what we did is we take it took each like sort of little segment of vessel tract and found",
    "start": "1504950",
    "end": "1511610"
  },
  {
    "text": "the bounding box for that segment and then sort of by focusing in on various parts of this artery we could find",
    "start": "1511610",
    "end": "1517280"
  },
  {
    "text": "overlapping bounding boxes and therefore find segments of vessel vessel tract which were within a certain distance of",
    "start": "1517280",
    "end": "1522950"
  },
  {
    "text": "one another and therefore are likely candidates for these proximity events",
    "start": "1522950",
    "end": "1528820"
  },
  {
    "text": "the way and this works so when new data arrived so we wanted to store the data",
    "start": "1530440",
    "end": "1538640"
  },
  {
    "text": "in a way that would be easy to build up the arteries and the best way to do that would be to store the data so we could really quickly read out these vessel",
    "start": "1538640",
    "end": "1545030"
  },
  {
    "text": "tracks so the way we did that was when new data arrived we first partitioned out by date so we'd split this later up",
    "start": "1545030",
    "end": "1552559"
  },
  {
    "text": "into date windows and then all the segments of vessel tracked within those date windows would just be compared to",
    "start": "1552559",
    "end": "1559880"
  },
  {
    "text": "tracks within the same timeframe and then within each file we'd sort the data by vessel and then with for each vessel",
    "start": "1559880",
    "end": "1566540"
  },
  {
    "text": "sort of dated by timestamps so in this really simple example this just means that the first half of each file would",
    "start": "1566540",
    "end": "1572120"
  },
  {
    "text": "be the track for s1 and the second half will be the track for vessel two and so just to show you what one of those",
    "start": "1572120",
    "end": "1578910"
  },
  {
    "text": "files look like so here we've got a parking file this is displayed in this",
    "start": "1578910",
    "end": "1585450"
  },
  {
    "text": "is a this is displayed using a data Fritz notebook data break this is a really good tool for sort of exploratory",
    "start": "1585450",
    "end": "1591780"
  },
  {
    "text": "experimental analysis and good for viewing parking files which can be quite difficult to view and so here you can",
    "start": "1591780",
    "end": "1597720"
  },
  {
    "text": "see you've got a ID for the first wrestle and then the track for that vessel you've got the latitude and longitude for the vessel each of these",
    "start": "1597720",
    "end": "1604559"
  },
  {
    "text": "points and then in the second half I've got a track vessel - so we've got a",
    "start": "1604559",
    "end": "1612750"
  },
  {
    "start": "1611000",
    "end": "1611000"
  },
  {
    "text": "system in which we ingest ingest data we then pass that data we project that data",
    "start": "1612750",
    "end": "1619290"
  },
  {
    "text": "out into these projections and then run the analysis over these different",
    "start": "1619290",
    "end": "1624900"
  },
  {
    "text": "projections in order to then be able to query the insight we need we can have multiple projections from this analysis",
    "start": "1624900",
    "end": "1632309"
  },
  {
    "text": "so if we as just was saying if we had different analysis that we use different types of projections we could then",
    "start": "1632309",
    "end": "1637710"
  },
  {
    "text": "create a second projection in order to support that so we've got a lot of steps and we need some way of being able to",
    "start": "1637710",
    "end": "1645150"
  },
  {
    "text": "orchestrate all of these steps and this is where durable functions came in so durable functions are extension of",
    "start": "1645150",
    "end": "1651890"
  },
  {
    "start": "1650000",
    "end": "1650000"
  },
  {
    "text": "regular functions which do so of stateful orchestration of multi-step processing state is stored as this",
    "start": "1651890",
    "end": "1659970"
  },
  {
    "text": "processing progresses because with these long-running operations you need to be able to restart the processing should",
    "start": "1659970",
    "end": "1666960"
  },
  {
    "text": "the function rotary stop and you do so you do this personally my calling out to",
    "start": "1666960",
    "end": "1672510"
  },
  {
    "text": "asynchronous steps within there and within the processing and therefore can build up quite complex process from",
    "start": "1672510",
    "end": "1679559"
  },
  {
    "text": "small units of work and durable functions also allows you to control the paralyzation within system so built into",
    "start": "1679559",
    "end": "1687929"
  },
  {
    "text": "it is Fanning in and fanning out as you can paralyze different parts of the processing and this will fan out to",
    "start": "1687929",
    "end": "1693570"
  },
  {
    "text": "multiple functions instances as and when they are needed so we used a few",
    "start": "1693570",
    "end": "1699570"
  },
  {
    "text": "different patterns while building up the processing so function training chaining means to take the output of one function",
    "start": "1699570",
    "end": "1706980"
  },
  {
    "text": "and use that to feed the execution of the next so using this if you've got these steps",
    "start": "1706980",
    "end": "1712200"
  },
  {
    "text": "that we need to orchestrate you can take the output of one and use that to feed the execution of the next one and build",
    "start": "1712200",
    "end": "1717540"
  },
  {
    "text": "up there's quite complex processing also",
    "start": "1717540",
    "end": "1723110"
  },
  {
    "text": "also built into durable functions as support for the async HTTP API pattern",
    "start": "1723110",
    "end": "1728760"
  },
  {
    "text": "and if you don't know this pattern basically means you kick off a",
    "start": "1728760",
    "end": "1733950"
  },
  {
    "text": "long-running operation via an HTTP request you're then redirected to a URL",
    "start": "1733950",
    "end": "1739080"
  },
  {
    "text": "which you can then pull for the state of the long-running operation and this is supported out-of-the-box and durable",
    "start": "1739080",
    "end": "1744360"
  },
  {
    "text": "functions and integrates really well without your data factory which will automatically pull the function for",
    "start": "1744360",
    "end": "1749940"
  },
  {
    "text": "completion and I already mentioned that you can control parallelization within the system using the family and fan-out",
    "start": "1749940",
    "end": "1756570"
  },
  {
    "text": "pattern so this means that if you have processing that can happen in parallel you can fan out and then if these result",
    "start": "1756570",
    "end": "1763320"
  },
  {
    "text": "needs to be aggregated you can fan bike in and doing any of the pressing you",
    "start": "1763320",
    "end": "1768510"
  },
  {
    "text": "need to do so in our system this looks something like this so when your data",
    "start": "1768510",
    "end": "1774300"
  },
  {
    "text": "arrived if we had multiple projections that needed to be run we can paralyze",
    "start": "1774300",
    "end": "1780480"
  },
  {
    "text": "that because the projections are completely independent so we can fan out to multiple projections and then with",
    "start": "1780480",
    "end": "1785730"
  },
  {
    "text": "the within each projection each of the partitions are again independent so we can fan out again and then aggregate",
    "start": "1785730",
    "end": "1793050"
  },
  {
    "text": "these results to aggregate say these proximity signals and run any overall in",
    "start": "1793050",
    "end": "1798210"
  },
  {
    "text": "their analysis and query that insight help the other end so I'm now going to",
    "start": "1798210",
    "end": "1806010"
  },
  {
    "text": "do a demo of the orchestration running and this is where it could all go horribly wrong so here we have a",
    "start": "1806010",
    "end": "1813540"
  },
  {
    "text": "function host which is running our orchestration function and usually this would be kicked off by a new file",
    "start": "1813540",
    "end": "1820380"
  },
  {
    "text": "arriving and that would automatically start the orchestration I'm gonna do it by hand so hey good start",
    "start": "1820380",
    "end": "1831169"
  },
  {
    "text": "all right I'll give it a second right we",
    "start": "1831680",
    "end": "1847310"
  },
  {
    "text": "do have a pre-canned version of this demo which I can try if this does not really come back to life it's postman's",
    "start": "1847310",
    "end": "1859250"
  },
  {
    "text": "not responding right I will just play",
    "start": "1859250",
    "end": "1864620"
  },
  {
    "text": "the video so I get to try and do a live",
    "start": "1864620",
    "end": "1871550"
  },
  {
    "text": "demos I say here we have the",
    "start": "1871550",
    "end": "1877040"
  },
  {
    "text": "orchestration and so yes so usually superkicked automatically but here we're",
    "start": "1877040",
    "end": "1882620"
  },
  {
    "text": "just sending in a request to it so that request has the file that's just arrived",
    "start": "1882620",
    "end": "1889130"
  },
  {
    "text": "and the contact distance so that's the distance at which we say to ship so with",
    "start": "1889130",
    "end": "1894230"
  },
  {
    "text": "in contact in contact with one another and we can see that we are projecting",
    "start": "1894230",
    "end": "1900260"
  },
  {
    "text": "this file out so and we can see on the right that the memory for the function is increasing so that's that's the far",
    "start": "1900260",
    "end": "1906770"
  },
  {
    "text": "as the date is being read in and we should see that these projections to start updating so these projections are",
    "start": "1906770",
    "end": "1915770"
  },
  {
    "text": "actually updated in series at this point so each partition is updated in series because so we kind of need a long",
    "start": "1915770",
    "end": "1922610"
  },
  {
    "text": "running track through all of the files so say you have the you had one fun you",
    "start": "1922610",
    "end": "1928040"
  },
  {
    "text": "have the vessel track throughout that file the next file needs to know where the ship was at the end of the previous file so we went through and added the",
    "start": "1928040",
    "end": "1934490"
  },
  {
    "text": "last data point from the previous file to each of the subsequent files and then you get this continuous vessel track",
    "start": "1934490",
    "end": "1939830"
  },
  {
    "text": "throughout and but yes so once all these projection but these partitions have",
    "start": "1939830",
    "end": "1945800"
  },
  {
    "text": "been updated we can then sort of fan out and start doing the actual proximity analysis over each of these so that I'll",
    "start": "1945800",
    "end": "1952760"
  },
  {
    "text": "be building up the arteries and then running the sort of more detailed proximity analysis over the candidates",
    "start": "1952760",
    "end": "1958160"
  },
  {
    "text": "found by the artery analysis so we should see and it definitely showed could be a",
    "start": "1958160",
    "end": "1963580"
  },
  {
    "text": "Denver has been recorded and the this gets a lot noisier in a second okay as",
    "start": "1963580",
    "end": "1969460"
  },
  {
    "text": "we found out some multiple and function instances and then build up the arteries",
    "start": "1969460",
    "end": "1976300"
  },
  {
    "text": "for each partition file and then find feature of those candidates whether",
    "start": "1976300",
    "end": "1982420"
  },
  {
    "text": "there's been any proximity and events within that time this so this is",
    "start": "1982420",
    "end": "1987940"
  },
  {
    "text": "actually running slower than it does in Azure because this is all done over the internet because we're downloading and",
    "start": "1987940",
    "end": "1994600"
  },
  {
    "text": "uploading these files as we go whereas in a sort of it's all done on server so",
    "start": "1994600",
    "end": "1999730"
  },
  {
    "text": "it would be actually a lot quicker to write and read and write those files but",
    "start": "1999730",
    "end": "2005370"
  },
  {
    "text": "yeah so this is creating new files in the data lake so this this will have already created the projection files which will have the data organized into",
    "start": "2005370",
    "end": "2013650"
  },
  {
    "text": "vessel ID and then by timestamp within each vessel a we for each vessel so",
    "start": "2013650",
    "end": "2019200"
  },
  {
    "text": "those vessel tracts so we should see the projection files in this folder and",
    "start": "2019200",
    "end": "2025230"
  },
  {
    "text": "those again are partitioned by time so you can quickly read out the partitions for the data for the for the time in",
    "start": "2025230",
    "end": "2033210"
  },
  {
    "text": "which you're searching proximity events and then we should also have for any time partitions where there were",
    "start": "2033210",
    "end": "2039630"
  },
  {
    "text": "proximity events we should have a signal file which will have details of the two",
    "start": "2039630",
    "end": "2045330"
  },
  {
    "text": "vessels that are in contact the start and end of the proximity event and where each vessel was at the start and end of",
    "start": "2045330",
    "end": "2051300"
  },
  {
    "text": "that",
    "start": "2051300",
    "end": "2053480"
  },
  {
    "text": "once we had sort of once we have built up all this processing we need to then optimize and for a service environment",
    "start": "2058139",
    "end": "2064648"
  },
  {
    "text": "so it's just mentioned in your functions you've got certain constraints on what",
    "start": "2064649",
    "end": "2071020"
  },
  {
    "text": "you can run so we've got memory constraints you can't go above 1.5 gigabytes of memory and on functions on",
    "start": "2071020",
    "end": "2078460"
  },
  {
    "text": "the consumption plan and also as your functions pricing is based on time of execution and also the memory use within",
    "start": "2078460",
    "end": "2085480"
  },
  {
    "text": "that time so reduction in memory would be a really important thing in order to",
    "start": "2085480",
    "end": "2091000"
  },
  {
    "text": "sort of check that any changes were made to the solution were actually an improvement in either performance or",
    "start": "2091000",
    "end": "2097270"
  },
  {
    "text": "cost we need as a benchmark and we wanted a way to build this into our system so that it was really integrated",
    "start": "2097270",
    "end": "2103060"
  },
  {
    "text": "with the change management within the system so it built small tool which used application insights to monitor the",
    "start": "2103060",
    "end": "2109780"
  },
  {
    "text": "running of the orchestration in Azure and then we could use this to sort of assess any changes we made so in order",
    "start": "2109780",
    "end": "2118660"
  },
  {
    "start": "2118000",
    "end": "2118000"
  },
  {
    "text": "to optimize for the service environment we needed to understand what factors affect performance in dotnet and so we",
    "start": "2118660",
    "end": "2125230"
  },
  {
    "text": "were optimizing for we were optimizing nekked here but as your functions you can run - you can run Java JavaScript",
    "start": "2125230",
    "end": "2131410"
  },
  {
    "text": "this is focusing on net but optimizing for these service for these service",
    "start": "2131410",
    "end": "2136480"
  },
  {
    "text": "environments that applies to any language so obviously the first factor",
    "start": "2136480",
    "end": "2141670"
  },
  {
    "text": "that affects performance is the actual processing logic if you if your code is doing loads of unnecessary work it's clearly gonna take longer than it should",
    "start": "2141670",
    "end": "2148150"
  },
  {
    "text": "and but something that people often overlook is the effect of garbage collection so garbage collection most of",
    "start": "2148150",
    "end": "2155980"
  },
  {
    "text": "you probably know is the process in dotnet of clearing up unused memory and the way that works is it suspends all",
    "start": "2155980",
    "end": "2161920"
  },
  {
    "text": "processing in order to count which references are still new so clearly the more garbage collections that triggered",
    "start": "2161920",
    "end": "2168160"
  },
  {
    "text": "the less time is spent on the actual processing so it would in from a performance point of view we really need",
    "start": "2168160",
    "end": "2174760"
  },
  {
    "text": "to reduce the amount of garbage collections that are triggered and the way to do that is by allocating less memory to start with so we used several",
    "start": "2174760",
    "end": "2182800"
  },
  {
    "start": "2178000",
    "end": "2178000"
  },
  {
    "text": "techniques for reducing the amount of memory used and the first of those was Lisp reallocation so in our processing",
    "start": "2182800",
    "end": "2190000"
  },
  {
    "start": "2187000",
    "end": "2187000"
  },
  {
    "text": "we ended up big lists of vessel track segments ready for comparison proximity analysis and if",
    "start": "2190000",
    "end": "2197140"
  },
  {
    "text": "you initially so lists are built on arrays and so is it it has a level of",
    "start": "2197140",
    "end": "2202630"
  },
  {
    "text": "extraction over that where you can just continuously keep adding items but these lists are built on the erosion of the",
    "start": "2202630",
    "end": "2208390"
  },
  {
    "text": "covers and arrays have to have a certain size when they are allocated so if you initialize a new list and don't give it",
    "start": "2208390",
    "end": "2215410"
  },
  {
    "text": "a size it will default to a value at four if you then exceed that size by adding four more items it will allocate",
    "start": "2215410",
    "end": "2222880"
  },
  {
    "text": "a new array of double size so eight so this gets really bad when you have really big lists of stuff because you",
    "start": "2222880",
    "end": "2230200"
  },
  {
    "text": "suddenly if you exceed the capacity it will advocate a list of double that size so you will suddenly have almost three",
    "start": "2230200",
    "end": "2236110"
  },
  {
    "text": "times the memory you actually need and you end up with these massive memory spikes and we saw this in our processing",
    "start": "2236110",
    "end": "2241360"
  },
  {
    "text": "where we'd suddenly just run out of memory and we couldn't work out why for ages and it was because of this massive",
    "start": "2241360",
    "end": "2246490"
  },
  {
    "text": "increase in memory suddenly so the way to get around this is to specify size",
    "start": "2246490",
    "end": "2253060"
  },
  {
    "text": "the list when you first allocate it and you then avoid the issue of an unused",
    "start": "2253060",
    "end": "2261310"
  },
  {
    "text": "memory and also of these big memory spikes and the next sort of technique we",
    "start": "2261310",
    "end": "2267370"
  },
  {
    "text": "used was actually not using useless at all and so we used I new river and stream processing to mean that we never",
    "start": "2267370",
    "end": "2273250"
  },
  {
    "text": "had to store this entire list of memory and there's only really worked for our processing because we can sort of",
    "start": "2273250",
    "end": "2278410"
  },
  {
    "text": "aggregate the results as we went so we could build up these proximity signals without store and doing any sort of",
    "start": "2278410",
    "end": "2283570"
  },
  {
    "text": "whole list operations but this meant that we never had to store the whole list in memory and therefore reduce the",
    "start": "2283570",
    "end": "2290140"
  },
  {
    "text": "amount of memory that was in use at any given time and made us far less likely to hit into these out of memory",
    "start": "2290140",
    "end": "2295210"
  },
  {
    "text": "exceptions another really important thing to consider is the extreme",
    "start": "2295210",
    "end": "2301180"
  },
  {
    "start": "2299000",
    "end": "2299000"
  },
  {
    "text": "reference and value types so in c-sharp in a 32-bit process a thing class will",
    "start": "2301180",
    "end": "2308590"
  },
  {
    "text": "use up 20 bytes of memory so that's eight for the data for for the pointer to that data on the heap and eight for",
    "start": "2308590",
    "end": "2315430"
  },
  {
    "text": "the object header on the heap if you instead use the struts which is a value",
    "start": "2315430",
    "end": "2320890"
  },
  {
    "text": "type you will only use up the VAT the mem needed for the data however in our",
    "start": "2320890",
    "end": "2326549"
  },
  {
    "text": "processing we had these we needed to compare two segments of vessel tracks so",
    "start": "2326549",
    "end": "2332309"
  },
  {
    "text": "we ended up storing pairs of vessel tracks that we needed to compare we need to run the analysis over so we ended up",
    "start": "2332309",
    "end": "2338160"
  },
  {
    "text": "with quite a lot of copies of the same data so if you have a class the reference type each additional copy will",
    "start": "2338160",
    "end": "2344789"
  },
  {
    "text": "only take up an extra four bytes because you just store another pointer to the same bit of data on the heap with a",
    "start": "2344789",
    "end": "2349799"
  },
  {
    "text": "struct every extra copy will have its own copy of the data and therefore being able another eight bytes so you can see",
    "start": "2349799",
    "end": "2357539"
  },
  {
    "text": "is you get more copies of the same objects you end up eventually using more data using your value type than a",
    "start": "2357539",
    "end": "2363839"
  },
  {
    "text": "reference type and in here we need five copies but this gets more extreme as",
    "start": "2363839",
    "end": "2369210"
  },
  {
    "text": "your objects get bigger we ran into this because I sort of I was trying to reduce the amount of memory we were using and",
    "start": "2369210",
    "end": "2375390"
  },
  {
    "text": "thought oh well structure small classes so I'll just change the write change it",
    "start": "2375390",
    "end": "2380970"
  },
  {
    "text": "all to you struts instead of classes and this was where benchmarking came in really important because I made it much",
    "start": "2380970",
    "end": "2386609"
  },
  {
    "text": "much worse so yeah I don't thing to consider and the last one I want to talk",
    "start": "2386609",
    "end": "2393119"
  },
  {
    "text": "about is a span of T and which is a relatively new feature of C sharp spans",
    "start": "2393119",
    "end": "2398819"
  },
  {
    "text": "are a way of indexing into contiguous memory on the heap and so this is an",
    "start": "2398819",
    "end": "2404940"
  },
  {
    "text": "example from in Griffiths new book about c-sharp 8 and I have stolen it I did ask",
    "start": "2404940",
    "end": "2410190"
  },
  {
    "text": "him but so I say you had a string which represented a URI and you create a new",
    "start": "2410190",
    "end": "2415770"
  },
  {
    "text": "er I object you can access different parts of that string using the different properties on the URI objects but each",
    "start": "2415770",
    "end": "2422220"
  },
  {
    "text": "of these properties represents another string which has been allocated on the heap so you actually ends up allocating quite a lot of strings in order to",
    "start": "2422220",
    "end": "2428250"
  },
  {
    "text": "access different parts of the memory if you instead use a span and just to index into the first four characters in that",
    "start": "2428250",
    "end": "2434819"
  },
  {
    "text": "string you sort of can access that memory directly and because spans are",
    "start": "2434819",
    "end": "2440130"
  },
  {
    "text": "referenced struts these are allocated on the stacks you don't cause any add any extra allocation so obviously this type",
    "start": "2440130",
    "end": "2447569"
  },
  {
    "text": "of processing has its own complexity and there's some other challenges involved in writing code like this but",
    "start": "2447569",
    "end": "2453380"
  },
  {
    "text": "this sort of service environment especially in big data whereas just was saying like these really small",
    "start": "2453380",
    "end": "2459220"
  },
  {
    "text": "performance improvements can have a massive impact when you're processing millions of messages processing like",
    "start": "2459220",
    "end": "2465529"
  },
  {
    "text": "this of really low allocation processing can be really integral to getting a sort of cost effective and also performance",
    "start": "2465529",
    "end": "2471559"
  },
  {
    "text": "solution yeah so I'm back over to Jess to summarize I think it was really",
    "start": "2471559",
    "end": "2486319"
  },
  {
    "start": "2478000",
    "end": "2478000"
  },
  {
    "text": "interesting sort of hearing Carmel it's all there I mean it sounds complicated but actually simple simple things simple",
    "start": "2486319",
    "end": "2491960"
  },
  {
    "text": "approaches simple practices that we can ply time and time again and once you get used to it and get familiar with it it kind of becomes second nature but I",
    "start": "2491960",
    "end": "2499789"
  },
  {
    "text": "think I don't want to I think what's important about this is not to distract away from the fact that actually the actual approach the pattern is actually",
    "start": "2499789",
    "end": "2505069"
  },
  {
    "text": "really simple it's just a case of okay finding the workload and then optimizing it for that your constraint and you know",
    "start": "2505069",
    "end": "2510470"
  },
  {
    "text": "what if you can't get your workload to run under the constraints then you do have still have options but there are",
    "start": "2510470",
    "end": "2516079"
  },
  {
    "text": "significant benefits obviously in terms of if you can actually make it work so",
    "start": "2516079",
    "end": "2521089"
  },
  {
    "text": "the takeaways from this are the commodity cloud services enabled ocean",
    "start": "2521089",
    "end": "2527660"
  },
  {
    "text": "mind to process more data in neural time what drastically reducing operation operating cost and for them that was",
    "start": "2527660",
    "end": "2532700"
  },
  {
    "text": "absolutely important and I think hopefully if you can take away anything as well this wasn't a trivial example this is",
    "start": "2532700",
    "end": "2538549"
  },
  {
    "text": "actually quite a complex scenario resource constraints needs to be managed through experimentation and benchmark",
    "start": "2538549",
    "end": "2544519"
  },
  {
    "text": "income I mentioned a few times where we you know where we we broke functions we know the consumption plan basis they",
    "start": "2544519",
    "end": "2551210"
  },
  {
    "text": "know you can't do that and we're like okay okay well let's let's keep going benchmarking is really important especially in terms of",
    "start": "2551210",
    "end": "2556460"
  },
  {
    "text": "regressing you make a small changes Carmel mentioned and all the sudden you're back to square one cheap cloud",
    "start": "2556460",
    "end": "2562729"
  },
  {
    "text": "storage can actually be a really good option you don't necessarily need sort generic databases",
    "start": "2562729",
    "end": "2568339"
  },
  {
    "text": "you don't need sequel server necessarily it has its place that get me wrong as I say because mostly be fantastic products",
    "start": "2568339",
    "end": "2573979"
  },
  {
    "text": "but this situation this situation we just didn't need it and that was down to the approach we took in terms of solving the problem and",
    "start": "2573979",
    "end": "2581440"
  },
  {
    "text": "that approach was using data projections as opposed to sort of running queries as and when it",
    "start": "2581440",
    "end": "2588839"
  },
  {
    "text": "needed to be run a few there's us by the way if you're interested in learning more as I say this was this this talk we",
    "start": "2588839",
    "end": "2595469"
  },
  {
    "text": "had so much to talk about if there's anything here that's an interest and you want to catch up with us just ping us",
    "start": "2595469",
    "end": "2601529"
  },
  {
    "text": "DMS or whatever get hold of us or cassius after this talk this is in",
    "start": "2601529",
    "end": "2607289"
  },
  {
    "text": "Griffiths new book if you're interested in some of the newer techniques especially round performance of stuff",
    "start": "2607289",
    "end": "2613680"
  },
  {
    "text": "that camera mentioned c-sharp ate really good book and some references I'll leave",
    "start": "2613680",
    "end": "2619499"
  },
  {
    "start": "2618000",
    "end": "2618000"
  },
  {
    "text": "on the screen for you during the process of doing this piece of work we didn't touch upon it but we created our own a",
    "start": "2619499",
    "end": "2627059"
  },
  {
    "text": "is parser so if you doing anything like this thank you if you get your hands on any a us data and you want to pass it",
    "start": "2627059",
    "end": "2634619"
  },
  {
    "text": "we've written an open-source Donette parser this I believe the benchmarks for these were I think it can process seven",
    "start": "2634619",
    "end": "2641039"
  },
  {
    "text": "million records a second on a single core this is properly you know it's all",
    "start": "2641039",
    "end": "2646739"
  },
  {
    "text": "the technique for the coma I'll mention plus more it's you know it's it's properly optimized so you know please",
    "start": "2646739",
    "end": "2651749"
  },
  {
    "text": "have a go and please contribute if you want to get involved in that couple of blog posts the Carmela put together",
    "start": "2651749",
    "end": "2657809"
  },
  {
    "text": "which talks about some of things she's she's mentioned in today's talk please have a look at our blogs there's also",
    "start": "2657809",
    "end": "2663059"
  },
  {
    "text": "this our tree paper so there's a couple of references actually only saying this is one of them so our trees are also reference for the RX spatial library",
    "start": "2663059",
    "end": "2669869"
  },
  {
    "text": "which Microsoft I've put a lot of material out about and goes into things like sequel server does its geospatial",
    "start": "2669869",
    "end": "2675690"
  },
  {
    "text": "work uses the same technique so please have a look at that if you're interested if you're interested in ocean mind so",
    "start": "2675690",
    "end": "2681390"
  },
  {
    "text": "they are fascinating organization really great at what they do there's a really nice case study under",
    "start": "2681390",
    "end": "2687839"
  },
  {
    "text": "the program of Microsoft a light for Earth Microsoft run this program if you are an offer profit if you are doing some",
    "start": "2687839",
    "end": "2693209"
  },
  {
    "text": "really cool stuff in the environment and you want to get involved let us know we can connect you up with the right people for the mock source a i4f they'll they",
    "start": "2693209",
    "end": "2699719"
  },
  {
    "text": "said they'd help in support in terms of funding and that and that it's a really good video to look at if you are into",
    "start": "2699719",
    "end": "2706229"
  },
  {
    "text": "data strategy into a general strategy and how to talk to business stakeholders",
    "start": "2706229",
    "end": "2711690"
  },
  {
    "text": "about how you want to you know transform your organization with data highly",
    "start": "2711690",
    "end": "2717509"
  },
  {
    "text": "recommend this video it uses a technique known as Waterloo mapping you've not heard of come across it I strongly advise you look it up it's",
    "start": "2717509",
    "end": "2724519"
  },
  {
    "text": "a really good strategy it talks about the strategical reasoning behind how we came up with the architecture what bits",
    "start": "2724519",
    "end": "2730549"
  },
  {
    "text": "were the bits we really wants to optimize why we chose service over non service and how we can communicate that",
    "start": "2730549",
    "end": "2735890"
  },
  {
    "text": "as I say to the key stakeholders within the business so it kind of makes sense to them so again I'd have a look at that as well we've got a few minutes for",
    "start": "2735890",
    "end": "2744589"
  },
  {
    "text": "questions so any questions not a good",
    "start": "2744589",
    "end": "2755240"
  },
  {
    "text": "time then please have a chat afterwards if you have got questions I want to just let's stick your hand up or catch us",
    "start": "2755240",
    "end": "2761150"
  },
  {
    "text": "afterwards but thanks very much for coming [Applause]",
    "start": "2761150",
    "end": "2768619"
  }
]
[
  {
    "text": "Hello friends thanks for coming here after lunch and I hope the music engaged",
    "start": "4480",
    "end": "9679"
  },
  {
    "text": "you a little bit all what that what you just saw was completely AI generated the text the music the vocals um so it's not",
    "start": "9679",
    "end": "18119"
  },
  {
    "text": "my making to make this great AI tool a company called sunno AI came up a few",
    "start": "18119",
    "end": "24080"
  },
  {
    "text": "probably two months ago with um something where you can actually create consistent music and actually extend the",
    "start": "24080",
    "end": "30640"
  },
  {
    "text": "music so it sounds actually real so um that's where we are today we are a",
    "start": "30640",
    "end": "36280"
  },
  {
    "text": "little bit beyond what text can do but however most of our talk today will still deal this text um the talk is",
    "start": "36280",
    "end": "44039"
  },
  {
    "text": "named unleash gbt mastering the implementation of large language models setting expectations we only have one",
    "start": "44039",
    "end": "49879"
  },
  {
    "text": "hour so um I will try to introduce some of the concepts but um most of them",
    "start": "49879",
    "end": "55239"
  },
  {
    "text": "hopefully with code samples I have a lot of slides I will skip over a lot of slides also so um but I will try to",
    "start": "55239",
    "end": "63239"
  },
  {
    "text": "ground the conversation a little bit with some of the concepts that are um under like large language models who who",
    "start": "63239",
    "end": "70439"
  },
  {
    "text": "of you thinks they have a like good understanding of what large language models are and um what's behind them why",
    "start": "70439",
    "end": "78439"
  },
  {
    "text": "do we do them and so on um is there a lot of folks who have experienced with this already not a few okay well um",
    "start": "78439",
    "end": "88920"
  },
  {
    "text": "then I will see you like ask scof or like making faces doing my talk maybe so",
    "start": "88920",
    "end": "95360"
  },
  {
    "text": "this happens when you deal with a company like open AI like on my flight to Portugal I got the message that",
    "start": "95360",
    "end": "101000"
  },
  {
    "text": "supposedly I had the specious um activity in my account since then my",
    "start": "101000",
    "end": "106520"
  },
  {
    "text": "main account of chat GPT is closed um don't worry we were using mostly Azure open AI yet um but um and they still",
    "start": "106520",
    "end": "114799"
  },
  {
    "text": "haven't been able after now 36 hours been able to tell me what exactly is wrong supposedly suspicious payment it's",
    "start": "114799",
    "end": "122360"
  },
  {
    "text": "$20 a month every month I don't know um um I did some red teaming but nothing",
    "start": "122360",
    "end": "129039"
  },
  {
    "text": "too extreme so um just be a little bit aware if you work with a company like open AI um surprising things may happen",
    "start": "129039",
    "end": "136640"
  },
  {
    "text": "and they may be sometimes difficult to resolve keep that in mind with all the excitement if you use it for something",
    "start": "136640",
    "end": "142959"
  },
  {
    "text": "Mission critical think about backups so that was was my experience um I've been on the conference Trail for a while uh",
    "start": "142959",
    "end": "149959"
  },
  {
    "text": "um in the industry also for a while doing Enterprise type of solutions for many years but around 2014 I went back",
    "start": "149959",
    "end": "157120"
  },
  {
    "text": "into combining it with information uh Innovation virtual reality mixed reality",
    "start": "157120",
    "end": "163200"
  },
  {
    "text": "Cloud applied artificial intelligence and since about two and a half years I've been playing with GPT stuff before",
    "start": "163200",
    "end": "169840"
  },
  {
    "text": "most people um cared for it um that's why I also have those MVP and Regional director things um because I just talk a",
    "start": "169840",
    "end": "177480"
  },
  {
    "text": "lot now why do I show this slide um just to contextualize where we coming from and how do we interact with computers in",
    "start": "177480",
    "end": "184400"
  },
  {
    "text": "the 1940s um we would interact with a computer by literally rewiring them yes",
    "start": "184400",
    "end": "189799"
  },
  {
    "text": "this was our programming Punch Cards a big innovation and is a integrated terminal you could type in the computer",
    "start": "189799",
    "end": "196480"
  },
  {
    "text": "amazing the Mouse invented 1963 the integrated keyboard uh Mouse and user",
    "start": "196480",
    "end": "203280"
  },
  {
    "text": "graphical user interface um introduced in 1968 even touch screens St from the",
    "start": "203280",
    "end": "209080"
  },
  {
    "text": "1960 and um smartphone form smartphone form factors from 1992 1994 with apps with",
    "start": "209080",
    "end": "217400"
  },
  {
    "text": "assignment um so this is still how we interact with the computers we learn the",
    "start": "217400",
    "end": "223319"
  },
  {
    "text": "computer expects us to interact with it in specific way we learn to speak computer now the bigger picture that I",
    "start": "223319",
    "end": "231840"
  },
  {
    "text": "see is that we're trying to move more away from that and computers or it in",
    "start": "231840",
    "end": "237040"
  },
  {
    "text": "general or this the it systems should understand more naturally what we want our intent and that is partially also I",
    "start": "237040",
    "end": "245319"
  },
  {
    "text": "think what motivates a lot of the research going on into large language",
    "start": "245319",
    "end": "250480"
  },
  {
    "text": "models so um I wanted to start with a really quick example of course I forgot",
    "start": "250480",
    "end": "256519"
  },
  {
    "text": "to start it up it's a um something called whisper Whispers by open AI also",
    "start": "256519",
    "end": "263520"
  },
  {
    "text": "and um let's see um ai ai models",
    "start": "263520",
    "end": "271440"
  },
  {
    "text": "whisper and has been um released as",
    "start": "271440",
    "end": "276840"
  },
  {
    "text": "um here should no sorry has been released as open",
    "start": "276840",
    "end": "283840"
  },
  {
    "text": "source and so people started playing with it so what's what's cool about whisper is again you can run it on your",
    "start": "283840",
    "end": "290400"
  },
  {
    "text": "own computer because a model is available right so what can it do for example I could suddenly speak here and",
    "start": "290400",
    "end": "297600"
  },
  {
    "text": "start speaking in Deutsch",
    "start": "297600",
    "end": "301639"
  },
  {
    "text": "okay I give one more try oh I I've configured the wrong microphone that makes a",
    "start": "312080",
    "end": "317880"
  },
  {
    "text": "difference",
    "start": "317880",
    "end": "320880"
  },
  {
    "text": "hello hello good afternoon I hope the lunch was delicious and then I'm going to the",
    "start": "328639",
    "end": "335400"
  },
  {
    "text": "bathroom so this is not a perfect implementation um of um but that's in",
    "start": "335400",
    "end": "341360"
  },
  {
    "text": "the app because the app what they didn't solve for you is how do you handle those audio chunks that you stream in and so",
    "start": "341360",
    "end": "346720"
  },
  {
    "text": "it comes up with weird things but why do I show this to you well because it's cool and you should download and play with it and do transcription and",
    "start": "346720",
    "end": "353039"
  },
  {
    "text": "translation on on your on device however the underlying paper that was published with it showed a really interesting find",
    "start": "353039",
    "end": "360000"
  },
  {
    "text": "whisper exists in different sizes like a small size very small size medium size large size and in a version that only",
    "start": "360000",
    "end": "367280"
  },
  {
    "text": "transcribes English to English and one version that's multilingual also able to translate like",
    "start": "367280",
    "end": "373919"
  },
  {
    "text": "from German to English and they found that when the models get a little bit larger still a size you can download to",
    "start": "373919",
    "end": "380280"
  },
  {
    "text": "your computer but little bit larger and measure and training budges 10 to the power of 20 something um suddenly the",
    "start": "380280",
    "end": "388000"
  },
  {
    "text": "multil linguage model gets better into transcribing English to English than the",
    "start": "388000",
    "end": "394919"
  },
  {
    "text": "model that was only trained of the same size same training budget that only um",
    "start": "394919",
    "end": "400000"
  },
  {
    "text": "has seen ever English to English and that is a so again so English to English",
    "start": "400000",
    "end": "405599"
  },
  {
    "text": "model worse at transcribing English than multilingual model at a specific size",
    "start": "405599",
    "end": "411840"
  },
  {
    "text": "and those are things that we seeing across this this is theme en larg AI",
    "start": "411840",
    "end": "417120"
  },
  {
    "text": "models that suddenly they become better than you think in specific tasks that",
    "start": "417120",
    "end": "424319"
  },
  {
    "text": "they haven't been especially been trained for and some of the specialty models yeah so that could be then also",
    "start": "424319",
    "end": "431879"
  },
  {
    "text": "um summarization that could be writing poetry could all be other things like a",
    "start": "431879",
    "end": "437560"
  },
  {
    "text": "specialty model for poetry may may fall behind a a large language model that can",
    "start": "437560",
    "end": "443160"
  },
  {
    "text": "do almost everything if the training set size is large enough that's the current thinking what is the latest in in chat",
    "start": "443160",
    "end": "450680"
  },
  {
    "text": "jpt well theat latest would be would be um Vision I mean I signed up for a new account so now I could um upload a",
    "start": "450680",
    "end": "459720"
  },
  {
    "text": "picture here do I have a picture um my",
    "start": "459720",
    "end": "466919"
  },
  {
    "text": "personal photos koala oh no we want Calla",
    "start": "468680",
    "end": "476240"
  },
  {
    "text": "rotated and what's in the p picture so I",
    "start": "476400",
    "end": "481960"
  },
  {
    "text": "upload this to cat GPT and Cat GPT suddenly is able to do something um and",
    "start": "481960",
    "end": "487479"
  },
  {
    "text": "describe that image again um how that works in too much detail we will not be",
    "start": "487479",
    "end": "493400"
  },
  {
    "text": "able to get into but that's kind of the latest Innovation that came out with it there's a large paper also associated",
    "start": "493400",
    "end": "499240"
  },
  {
    "text": "with it from Microsoft 140 pages that looks very deep and what you can do with it and you can already make more",
    "start": "499240",
    "end": "505319"
  },
  {
    "text": "advanced things you could like Riv um like make a circle around the koala make a circle on the person write a number to",
    "start": "505319",
    "end": "512919"
  },
  {
    "text": "it and then tell me more about two like when the number is two and and it would be able to do something with it it can",
    "start": "512919",
    "end": "519279"
  },
  {
    "text": "um take like layouts of an app for example you take a picture of and try to",
    "start": "519279",
    "end": "524640"
  },
  {
    "text": "recreate it and code and all those magic things so the the speed of innovation is very very fast another thing that it can",
    "start": "524640",
    "end": "531560"
  },
  {
    "text": "do um that it's very very late in in the world of AI is so so called Advanced",
    "start": "531560",
    "end": "539240"
  },
  {
    "text": "Data data analysis which is another Trend that you see that um AI models can",
    "start": "539240",
    "end": "547360"
  },
  {
    "text": "work with so-called agency agency meaning they can um they able to do",
    "start": "547360",
    "end": "553480"
  },
  {
    "text": "something like in this case they have a little python engine that can work with now what can we do with this we have",
    "start": "553480",
    "end": "560240"
  },
  {
    "text": "here conf um perfect",
    "start": "560240",
    "end": "565320"
  },
  {
    "text": "oops perfect solution um so from uploading some file right and so what's",
    "start": "565320",
    "end": "573480"
  },
  {
    "text": "in the file and that's a zip file right and I have no idea what is in the",
    "start": "573480",
    "end": "578560"
  },
  {
    "text": "file right so what the chat gbt now does it's able",
    "start": "578560",
    "end": "584440"
  },
  {
    "text": "actually to see okay it's a zip file I can UNS a zip file because I well I can generate code for it and then it",
    "start": "584440",
    "end": "591279"
  },
  {
    "text": "actually executes that for you and can do something meaningful with it it list the file contents and then Windows Form",
    "start": "591279",
    "end": "598160"
  },
  {
    "text": "solution Windows Form that oh that's uh it Con contains solution file",
    "start": "598160",
    "end": "603200"
  },
  {
    "text": "typically use with visual studio and so on and so forth and you could go on and on and on with that it can inspect that",
    "start": "603200",
    "end": "610320"
  },
  {
    "text": "it can look into the initial the indidual files and even tell you the layout it can change the layout in your",
    "start": "610320",
    "end": "616600"
  },
  {
    "text": "app um all within things you just upload to it yeah so this is some of the latest",
    "start": "616600",
    "end": "621920"
  },
  {
    "text": "things that that are happening and a lot of effort goes into now what they call",
    "start": "621920",
    "end": "627560"
  },
  {
    "text": "um agent based systems so which meaning like you give an agent some tools and",
    "start": "627560",
    "end": "632880"
  },
  {
    "text": "the agent can do something with those tools now what is the foundation all of all of that um the foundation of all of",
    "start": "632880",
    "end": "639600"
  },
  {
    "text": "this is so-called tokens so everything we interact with is a token",
    "start": "639600",
    "end": "645959"
  },
  {
    "text": "so here we have jpt 3.5 and gp4 when I I write a text hello in PTO to the NDC",
    "start": "645959",
    "end": "655560"
  },
  {
    "text": "conference then I go and it those all those colors letters here each one is So-Cal token",
    "start": "655560",
    "end": "663200"
  },
  {
    "text": "meaning a number the number is what is passed to the large language model inside the repres representation of the",
    "start": "663200",
    "end": "670839"
  },
  {
    "text": "text main purpose is just to make it smaller so that we don't encode letters because um we want to be more efficient",
    "start": "670839",
    "end": "679079"
  },
  {
    "text": "in in storing information basically and and because it was trained on English um it is quite effective in um this has",
    "start": "679079",
    "end": "687120"
  },
  {
    "text": "been optimized to be effective to encode the English language when I write something in German like Hello to their",
    "start": "687120",
    "end": "694880"
  },
  {
    "text": "conference in Porto you see that for example the word conference suddenly is",
    "start": "694880",
    "end": "700040"
  },
  {
    "text": "three tokens and um meaning as a side effect when you work in non- English",
    "start": "700040",
    "end": "705519"
  },
  {
    "text": "languages can get more costly because you work on tokens and pay by tokens and",
    "start": "705519",
    "end": "711760"
  },
  {
    "text": "also um even so loud language models are getting getting really really good and",
    "start": "711760",
    "end": "716839"
  },
  {
    "text": "working with long Tex still they maybe have more more they need to invest more",
    "start": "716839",
    "end": "721959"
  },
  {
    "text": "of the internal brain power if you want so to work with longer text in",
    "start": "721959",
    "end": "727079"
  },
  {
    "text": "non-english languages just keep that in mind a",
    "start": "727079",
    "end": "731680"
  },
  {
    "text": "bit oops um the so there's um there's a",
    "start": "732720",
    "end": "739240"
  },
  {
    "text": "paper R set so the the paper tension is all you need introduced the Transformer",
    "start": "739240",
    "end": "745360"
  },
  {
    "text": "model the big innovation about Transformers was that um suddenly they were able to parallelize what before was",
    "start": "745360",
    "end": "751920"
  },
  {
    "text": "only sequentialized um the RNN set where the default way how you work with",
    "start": "751920",
    "end": "757760"
  },
  {
    "text": "natural language basically did something like token by token by token by token and when you needed to do So-Cal back",
    "start": "757760",
    "end": "763519"
  },
  {
    "text": "pration you need to go all the way back and you cannot parallelize that on large dpu clusters that's one of the main",
    "start": "763519",
    "end": "769839"
  },
  {
    "text": "motivations and innovations that the Transformer architecture brought in very simplified and I will give you the",
    "start": "769839",
    "end": "776399"
  },
  {
    "text": "slides later on there's some great fun videos and how you can learn how Transformers work internally um they",
    "start": "776399",
    "end": "782279"
  },
  {
    "text": "have a smart way of encoding where all those tokens are and then they're masking out with some with a matrix",
    "start": "782279",
    "end": "789120"
  },
  {
    "text": "basically with matrix multiplication things that the Transformer shouldn't see so it can",
    "start": "789120",
    "end": "795040"
  },
  {
    "text": "simulates in a way that there is a sequentiality in a sentence um by doing Matrix Matrix multiplications the other",
    "start": "795040",
    "end": "802519"
  },
  {
    "text": "thing is um um one of the concepts in there is called attention the and you can visualize",
    "start": "802519",
    "end": "810760"
  },
  {
    "text": "attention right attention you can visualize what those models do internally um theoretically if it's",
    "start": "810760",
    "end": "817399"
  },
  {
    "text": "small enough the models in the end when they're done are nothing like a a big file and the file describes weights how",
    "start": "817399",
    "end": "825199"
  },
  {
    "text": "different things are connected now there are a few interesting things for example if you feed it let's say um like a a",
    "start": "825199",
    "end": "832279"
  },
  {
    "text": "sentence here now do we have an interactive click click click right here",
    "start": "832279",
    "end": "840160"
  },
  {
    "text": "sorry about",
    "start": "840160",
    "end": "842759"
  },
  {
    "text": "that so so basically if you give like a model like an input and an output it",
    "start": "851480",
    "end": "857959"
  },
  {
    "text": "basically assigns um probabilities how things are connected or wait for example here a word on is heavily connected",
    "start": "857959",
    "end": "864639"
  },
  {
    "text": "between set and the and the end separator of a sentence yeah in this layer five for example in a different",
    "start": "864639",
    "end": "871360"
  },
  {
    "text": "layer things may look different for example here um well let's find of",
    "start": "871360",
    "end": "877880"
  },
  {
    "text": "course I may pick the wrong layer well in this case for example here there there's also strong relationship to the",
    "start": "877880",
    "end": "884839"
  },
  {
    "text": "in this other layer so all those layers combined um try to represent all the",
    "start": "884839",
    "end": "890639"
  },
  {
    "text": "concepts that the large language models extract from The Real World and you can somehow light up what happens um in",
    "start": "890639",
    "end": "897600"
  },
  {
    "text": "there if you for example examp would give us contrastive pairs a strategy for example um like um a sad day and a happy",
    "start": "897600",
    "end": "907240"
  },
  {
    "text": "day then you may be able to find those parts in the model that get activated more often and maybe those are related",
    "start": "907240",
    "end": "913399"
  },
  {
    "text": "to some of those Concepts like happiness or sadness and so on but to make it a little bit",
    "start": "913399",
    "end": "921920"
  },
  {
    "text": "more um interesting here like you see that the models also for example",
    "start": "922720",
    "end": "929680"
  },
  {
    "text": "seems to extract some um very simple concepts for example here it just",
    "start": "929680",
    "end": "934959"
  },
  {
    "text": "extracted the concept that there the next word yeah and this is just like a hypothetical example right in reality",
    "start": "934959",
    "end": "941480"
  },
  {
    "text": "those models are so big that you cannot really visualize it but um you will find",
    "start": "941480",
    "end": "947480"
  },
  {
    "text": "um Concepts like sequentiality or pointing back to the previous thing or",
    "start": "947480",
    "end": "953560"
  },
  {
    "text": "nouns relating to adjectives and all those things um you may find those in",
    "start": "953560",
    "end": "958800"
  },
  {
    "text": "the those models model",
    "start": "958800",
    "end": "962000"
  },
  {
    "text": "weights so what are large language models where are they coming from I mean initially they were basically introduced",
    "start": "964480",
    "end": "970920"
  },
  {
    "text": "to do translation and they were trained to be really good at finding the next",
    "start": "970920",
    "end": "976720"
  },
  {
    "text": "word the next most probable word and as a size um example here um that was how",
    "start": "976720",
    "end": "983240"
  },
  {
    "text": "gpt3 was trained with 410 billion tokens and then about 100 billion additional so",
    "start": "983240",
    "end": "988959"
  },
  {
    "text": "around half a trillion tokens nowadays we're talking about two trillion four trillion tokens when you talk about um",
    "start": "988959",
    "end": "996600"
  },
  {
    "text": "um llama 2 and gbd4 I'm not sure if they published how many tokens they used for",
    "start": "996600",
    "end": "1003040"
  },
  {
    "text": "gbd4 an interesting observation however is that um in the timeline when we first",
    "start": "1003040",
    "end": "1009480"
  },
  {
    "text": "the paper came out on 2018 is um the attentional you need and then those",
    "start": "1009480",
    "end": "1014680"
  },
  {
    "text": "other models came out um this is like 10 times larger than this and this is 10 times other than this but the training",
    "start": "1014680",
    "end": "1021079"
  },
  {
    "text": "budget was always in the in the tens of millions of US dollars because Innovation so fast that in a year and",
    "start": "1021079",
    "end": "1028600"
  },
  {
    "text": "two years um we're we exceeding M law nowadays in in training yeah um because",
    "start": "1028600",
    "end": "1036079"
  },
  {
    "text": "of the Innovations in hardware and in algorithms um GP what is GPT however in",
    "start": "1036079",
    "end": "1043360"
  },
  {
    "text": "that you interact with in chat GPT now the best thing I can do is open a non GPT model because the basic models of",
    "start": "1043360",
    "end": "1050799"
  },
  {
    "text": "DPT are not really available that easy anymore",
    "start": "1050799",
    "end": "1056320"
  },
  {
    "text": "um Bloom hugging face because you're all used to",
    "start": "1057080",
    "end": "1063520"
  },
  {
    "text": "interacting with with GPT and for example I say what",
    "start": "1063520",
    "end": "1069160"
  },
  {
    "text": "is the color of the sky if you use CH gbt you would expect something hey the sky is",
    "start": "1069160",
    "end": "1075640"
  },
  {
    "text": "blue and what do you think about it but when you ask like a real Foundation model that's only trained on finding the",
    "start": "1075640",
    "end": "1082400"
  },
  {
    "text": "next probable token it just can generate some random text yeah so if I would give",
    "start": "1082400",
    "end": "1087679"
  },
  {
    "text": "it however it's a technique called um Fus short learning um a few examples",
    "start": "1087679",
    "end": "1094559"
  },
  {
    "text": "before let's say what is the color of",
    "start": "1094559",
    "end": "1100880"
  },
  {
    "text": "snow coup",
    "start": "1100880",
    "end": "1107039"
  },
  {
    "text": "a white Co",
    "start": "1107039",
    "end": "1112840"
  },
  {
    "text": "what what is the color of",
    "start": "1112840",
    "end": "1118158"
  },
  {
    "text": "blood red",
    "start": "1118919",
    "end": "1125400"
  },
  {
    "text": "coup what is the color of the sky and then write a then I have a higher chance",
    "start": "1126559",
    "end": "1131880"
  },
  {
    "text": "that it will give me something meaningful yeah at least it gave you the answer because um I gave it more",
    "start": "1131880",
    "end": "1137760"
  },
  {
    "text": "examples and I the model into like hey um this is like a question answer",
    "start": "1137760",
    "end": "1143280"
  },
  {
    "text": "pattern and so looked in all the training data and found things that point in that direction that really somebody wanted an answer now what G",
    "start": "1143280",
    "end": "1151080"
  },
  {
    "text": "what um openi did for us um they built those instruct models by basically",
    "start": "1151080",
    "end": "1156320"
  },
  {
    "text": "having a lot of labelers marking like how should um",
    "start": "1156320",
    "end": "1162000"
  },
  {
    "text": "question answer F looks like what is a good answer and then they trained a",
    "start": "1162000",
    "end": "1167559"
  },
  {
    "text": "so-called reward model model so reward model means they trained a different AI model that doesn't generate text that's",
    "start": "1167559",
    "end": "1173520"
  },
  {
    "text": "able to say a human would think this is good and then they use this reward model to um basically um process like millions",
    "start": "1173520",
    "end": "1181600"
  },
  {
    "text": "and millions of question answers pairs Generations from the earlier version of jgpt and then the reward modelist will",
    "start": "1181600",
    "end": "1187760"
  },
  {
    "text": "say human would like this a human wouldn't like this and they used that for training and then they went back to labelers and so on this way they were",
    "start": "1187760",
    "end": "1194440"
  },
  {
    "text": "able to do it just at scale better than other people so far and um they're",
    "start": "1194440",
    "end": "1199480"
  },
  {
    "text": "having amazing results and not a lot of companies I mean that that's something the open source Community cannot do that",
    "start": "1199480",
    "end": "1205840"
  },
  {
    "text": "well yet um but fine-tuning is in in the sense of instruct training improving",
    "start": "1205840",
    "end": "1212480"
  },
  {
    "text": "models to follow instructions as mostly done in the open source scene by um like",
    "start": "1212480",
    "end": "1217919"
  },
  {
    "text": "so supervised fine tuning by just providing examples and not those reward model step um now chat GPT um improved",
    "start": "1217919",
    "end": "1225960"
  },
  {
    "text": "on that further by um giving you the question answer pair chat style so",
    "start": "1225960",
    "end": "1234480"
  },
  {
    "text": "basically it was first improved to be able to interact with users um multi-term multi-term conversations but",
    "start": "1234480",
    "end": "1242120"
  },
  {
    "text": "let's look here how would that look like in actual when you work with a model so",
    "start": "1242120",
    "end": "1247159"
  },
  {
    "text": "I'm going into Azure open a studio right now so in Azure open AI you can generate",
    "start": "1247159",
    "end": "1253120"
  },
  {
    "text": "language resources and I pre-created a gbd4 resource here",
    "start": "1253120",
    "end": "1259280"
  },
  {
    "text": "I hope everything works still and you see something here you see something a system",
    "start": "1259280",
    "end": "1264480"
  },
  {
    "text": "message like um this is nothing that you tell the model but this is something that the model already knows before you",
    "start": "1264480",
    "end": "1270919"
  },
  {
    "text": "interact it's part of the so-called prompt and the model always when it get called gets everything it um so it's it",
    "start": "1270919",
    "end": "1278000"
  },
  {
    "text": "gets a really long string and a system message so system prompt is part of it for example you and I and I um system",
    "start": "1278000",
    "end": "1286400"
  },
  {
    "text": "that helps people find information um",
    "start": "1286400",
    "end": "1291880"
  },
  {
    "text": "you will not lie um you will",
    "start": "1291880",
    "end": "1300039"
  },
  {
    "text": "not hurt um you will not be",
    "start": "1300039",
    "end": "1308360"
  },
  {
    "text": "hurtful in your responses never going to lie and never",
    "start": "1308360",
    "end": "1315799"
  },
  {
    "text": "going to hurt you yeah so and then we save",
    "start": "1315799",
    "end": "1323080"
  },
  {
    "text": "that now and when I give it an example now make",
    "start": "1323640",
    "end": "1328760"
  },
  {
    "text": "a funny joke how boring a German speaker is",
    "start": "1328760",
    "end": "1337799"
  },
  {
    "text": "yeah and you will see that well he says I will not cannot fulfill that request",
    "start": "1337799",
    "end": "1343039"
  },
  {
    "text": "now this is nothing because of that prompt I gave it this is like because um open AI tuned it that way",
    "start": "1343039",
    "end": "1349039"
  },
  {
    "text": "um let's do something do something else um",
    "start": "1349039",
    "end": "1354799"
  },
  {
    "text": "when asked to talk about German um",
    "start": "1354799",
    "end": "1361159"
  },
  {
    "text": "pretends the person is",
    "start": "1361159",
    "end": "1365440"
  },
  {
    "text": "Austrian save that the chat hey I am German how is the weather",
    "start": "1366440",
    "end": "1376520"
  },
  {
    "text": "in Berlin",
    "start": "1376520",
    "end": "1380440"
  },
  {
    "text": "um so here I'm programmed to refer to people from Austria as austrians nevertheless a b is cloudy so the model",
    "start": "1382720",
    "end": "1389799"
  },
  {
    "text": "also makes up things it doesn't know any look up in this case what you what's interesting is here how you interact",
    "start": "1389799",
    "end": "1395720"
  },
  {
    "text": "with a model how does it work in in actually so you give it basically a big string and the string has all those",
    "start": "1395720",
    "end": "1401919"
  },
  {
    "text": "things in here before like you give it the role the system role you give it all this string at the beginning and then",
    "start": "1401919",
    "end": "1407640"
  },
  {
    "text": "the whole chat is the chat history grows and grows and grows until you reach the so-called token limit the other",
    "start": "1407640",
    "end": "1414880"
  },
  {
    "text": "parameters that that you may want to keep in mind um are things like um um",
    "start": "1414880",
    "end": "1420799"
  },
  {
    "text": "max response length temperature top p and so on the temperature and top are",
    "start": "1420799",
    "end": "1427840"
  },
  {
    "text": "basically um they're used by the so-called sampler when the model generates the next response it get gets",
    "start": "1427840",
    "end": "1434520"
  },
  {
    "text": "a probability list of possible tokens and this this is basically a strategy",
    "start": "1434520",
    "end": "1440120"
  },
  {
    "text": "that then used to select the next response if the temperature would be zero then it would also use always use",
    "start": "1440120",
    "end": "1447400"
  },
  {
    "text": "the most probable token if the temperature is a little bit higher then it also mixes to certain degrees a",
    "start": "1447400",
    "end": "1453440"
  },
  {
    "text": "little bit less probable tokens um to get a little bit more varied responses and people found that actually is better",
    "start": "1453440",
    "end": "1459559"
  },
  {
    "text": "in a lot of cases now that we have seen this how that looks in the portal what",
    "start": "1459559",
    "end": "1465760"
  },
  {
    "text": "does it mean when we would work in code here I have a very very basic example um",
    "start": "1465760",
    "end": "1472240"
  },
  {
    "text": "it's like an accentral workbook um so how it would look when you work in net",
    "start": "1472240",
    "end": "1478240"
  },
  {
    "text": "for example to interact with this what you do you install the aure open AI um n",
    "start": "1478240",
    "end": "1484399"
  },
  {
    "text": "package this is here uh polygot notebook the polyot notebooks let you work like a",
    "start": "1484399",
    "end": "1489840"
  },
  {
    "text": "Jupiter notebooks in in um python um in but in net style right so we can",
    "start": "1489840",
    "end": "1496799"
  },
  {
    "text": "interactively try things out this and we initialize it we start a an client application here and we asked now the",
    "start": "1496799",
    "end": "1506039"
  },
  {
    "text": "install text divin 0 series3 model that's um not a chat model to tell me",
    "start": "1506039",
    "end": "1512480"
  },
  {
    "text": "something and it gives me a generation and the generation has an object structure has also some prompt filter",
    "start": "1512480",
    "end": "1519159"
  },
  {
    "text": "results if you use Azure open you get capabilities built in to your liking um",
    "start": "1519159",
    "end": "1525440"
  },
  {
    "text": "avoid violent speech avoid um um nudity or different things that may",
    "start": "1525440",
    "end": "1531799"
  },
  {
    "text": "be considered offensive yeah so the text here tell me something about the",
    "start": "1531799",
    "end": "1537279"
  },
  {
    "text": "expansion factors the expansion factors are used to express blah blah blah blah blah so in this case Again The DaVinci",
    "start": "1537279",
    "end": "1543440"
  },
  {
    "text": "model is um in an instruct model but not a chat model and in this case it thought",
    "start": "1543440",
    "end": "1549320"
  },
  {
    "text": "I just continue saying what was said and here's an interesting part for you as a developer the Finish reason the Finish",
    "start": "1549320",
    "end": "1555640"
  },
  {
    "text": "reason is length length means that um the API thinks hey what I gave you is a",
    "start": "1555640",
    "end": "1562960"
  },
  {
    "text": "is a complete response as the model thinks it should have generated it internally it created a stop token and",
    "start": "1562960",
    "end": "1569679"
  },
  {
    "text": "the API basically found so oh that's a stop token we don't need to keep generating otherwise models would want",
    "start": "1569679",
    "end": "1576600"
  },
  {
    "text": "to keep generating token by token by token by token now here's a raw response it's",
    "start": "1576600",
    "end": "1583120"
  },
  {
    "text": "just um the the object structure in a little different way and to tell you the",
    "start": "1583120",
    "end": "1588600"
  },
  {
    "text": "like the same thing but when you say like hey but I don't want so many tokens you can say the tell the API only give",
    "start": "1588600",
    "end": "1595600"
  },
  {
    "text": "me four tokens yeah so it starts generating and technology is and then",
    "start": "1595600",
    "end": "1602399"
  },
  {
    "text": "finish reason length so there's a difference right so if you do this and you give the API like please generate",
    "start": "1602399",
    "end": "1609840"
  },
  {
    "text": "only four tokens and then oh yeah there could be more that could be relevant it could be generated but it is maybe good",
    "start": "1609840",
    "end": "1616919"
  },
  {
    "text": "for you because you pay by token usage so sometimes you may want to look at",
    "start": "1616919",
    "end": "1622399"
  },
  {
    "text": "only the first 10 tokens or 20 tokens if that's good enough for you and then you continue like this is one of the options",
    "start": "1622399",
    "end": "1629240"
  },
  {
    "text": "you can use for that like um here there's another example that's basically I'm looping now",
    "start": "1629240",
    "end": "1635399"
  },
  {
    "text": "over Max tokens equals two and um basically just a simple Loop over this and you see that the model generates to",
    "start": "1635399",
    "end": "1643120"
  },
  {
    "text": "in two token pairs um the responses yeah so so it's",
    "start": "1643120",
    "end": "1649200"
  },
  {
    "text": "like a just and I and I just do that until the Finish reason is stopped which",
    "start": "1649200",
    "end": "1654480"
  },
  {
    "text": "is in this case um equal to to length um being",
    "start": "1654480",
    "end": "1662440"
  },
  {
    "text": "reached come well it may be a while so I hope you believe me that um that it will",
    "start": "1664760",
    "end": "1672720"
  },
  {
    "text": "finish eventually so this is now where we get into more interesting territory",
    "start": "1672720",
    "end": "1678720"
  },
  {
    "text": "when you work with this like in chat GPT so you initialize it with a chat message as a system role then you give it a chat",
    "start": "1678720",
    "end": "1685799"
  },
  {
    "text": "message in the user role you in this case the questions and the question is how tell me how do I get from Belleview",
    "start": "1685799",
    "end": "1691720"
  },
  {
    "text": "to Redmond yeah how do I do that and then you add that and then and here I",
    "start": "1691720",
    "end": "1696760"
  },
  {
    "text": "want only one choice and now give me the chat",
    "start": "1696760",
    "end": "1702679"
  },
  {
    "text": "completion and basic way here in this in the system put please answer and rhyme",
    "start": "1705799",
    "end": "1712679"
  },
  {
    "text": "yeah so you you get some type of again finished reason is his stop so in the um",
    "start": "1712679",
    "end": "1718880"
  },
  {
    "text": "what do you call it in the chat API they call it stop and not length I",
    "start": "1718880",
    "end": "1724200"
  },
  {
    "text": "believe um and it gives me description if those who know a little bit the Redmond and bellw um it's kind of",
    "start": "1724200",
    "end": "1732159"
  },
  {
    "text": "accurate like to get from B to Redmond here's way just follow my instructions don't go astray take the ACT and so on",
    "start": "1732159",
    "end": "1738799"
  },
  {
    "text": "and so on yeah and you see a few interesting things here also function call equals null and we will get to this",
    "start": "1738799",
    "end": "1745640"
  },
  {
    "text": "um what that means in a in a little bit so you see it follows instructions and",
    "start": "1745640",
    "end": "1751720"
  },
  {
    "text": "generated some because of its World Knowledge how do you get from bellev to Redmond and you could trust that but it",
    "start": "1751720",
    "end": "1758480"
  },
  {
    "text": "would be cool if you could like hook that up into let's say a real",
    "start": "1758480",
    "end": "1763840"
  },
  {
    "text": "application is able to do map lookups navigation lookups and we will look into",
    "start": "1763840",
    "end": "1768919"
  },
  {
    "text": "that a little later in those demos yeah another example would be like um like",
    "start": "1768919",
    "end": "1775760"
  },
  {
    "text": "how where trainer parrot like give me and um this just to",
    "start": "1775760",
    "end": "1781559"
  },
  {
    "text": "to show you you can also interact with a model in an async pattern like you get the responses as a",
    "start": "1781559",
    "end": "1788559"
  },
  {
    "text": "model creates it the models can be pretty slow sometimes uh a generation",
    "start": "1788559",
    "end": "1793640"
  },
  {
    "text": "can take 10 seconds 20 seconds depending if the server is busy and using one of",
    "start": "1793640",
    "end": "1799000"
  },
  {
    "text": "the async functions and just basically streaming the results also enables you two things one is like you are more",
    "start": "1799000",
    "end": "1805240"
  },
  {
    "text": "responsive to your users but you could also decide I'm done I have seen enough I have my for example you may have your",
    "start": "1805240",
    "end": "1811640"
  },
  {
    "text": "own custom filter that you want to prohibit specific words maybe you have an AI model that shouldn't I don't know",
    "start": "1811640",
    "end": "1819000"
  },
  {
    "text": "should avoid specific words or um if you feed it with some um confidential",
    "start": "1819000",
    "end": "1826120"
  },
  {
    "text": "information that um it does you don't want it to leak you could have other filters for example that you want to",
    "start": "1826120",
    "end": "1832080"
  },
  {
    "text": "interject there now let's look at functions functions is a relatively new",
    "start": "1832080",
    "end": "1839279"
  },
  {
    "text": "feature of open Ai and Azure open Ai and this is what is behind everything",
    "start": "1839279",
    "end": "1845519"
  },
  {
    "text": "you hear about plugins and co-pilots and all this magic that people are talking",
    "start": "1845519",
    "end": "1850960"
  },
  {
    "text": "about it basically is a question how can we with that larger language model",
    "start": "1850960",
    "end": "1856559"
  },
  {
    "text": "interact with our custom code yeah in this case what we do is like we we",
    "start": "1856559",
    "end": "1862240"
  },
  {
    "text": "Define a soal function definition has a name get root from A to B has a description what does it do get",
    "start": "1862240",
    "end": "1869519"
  },
  {
    "text": "the root direction of the location A to B and then has specific parameters like location a it's a start city and state",
    "start": "1869519",
    "end": "1877960"
  },
  {
    "text": "from which the direction is um calculated and then the destination",
    "start": "1877960",
    "end": "1883720"
  },
  {
    "text": "city and behind the scenes how does it look like it's basically just a Bas an object that is being fed into the large",
    "start": "1883720",
    "end": "1891760"
  },
  {
    "text": "language model and the large language model has been trained not by us but but",
    "start": "1891760",
    "end": "1897000"
  },
  {
    "text": "by open AI to understand this type of let's say object structure like this Jason object",
    "start": "1897000",
    "end": "1904840"
  },
  {
    "text": "structure now so when I now add this function to my my",
    "start": "1904840",
    "end": "1910120"
  },
  {
    "text": "available um options to generate a completion and I do now a completion for",
    "start": "1910120",
    "end": "1918919"
  },
  {
    "text": "the same thing I see something different the same question is and how do I get from BBY to Redmond suddenly I",
    "start": "1918919",
    "end": "1925279"
  },
  {
    "text": "get a finished reason function call yeah so the the the model now realized that",
    "start": "1925279",
    "end": "1931760"
  },
  {
    "text": "instead of just generating random text hey somebody asked for something where I",
    "start": "1931760",
    "end": "1936880"
  },
  {
    "text": "know that there a function exists for like here and this is the data that",
    "start": "1936880",
    "end": "1944760"
  },
  {
    "text": "is relevant here the function call is the function get root from A to B and",
    "start": "1944760",
    "end": "1950519"
  },
  {
    "text": "the location a is Bell View and the location B is Redmond behind the scenes this is",
    "start": "1950519",
    "end": "1956720"
  },
  {
    "text": "because the larger language models just has so much generic understanding of language that it is able to match those",
    "start": "1956720",
    "end": "1963240"
  },
  {
    "text": "function descriptions with some additional training to the arbitrary questions that we ask it yeah this is",
    "start": "1963240",
    "end": "1970440"
  },
  {
    "text": "also how behind the scenes it's able to use let's say for example the python code that was generated in the initial",
    "start": "1970440",
    "end": "1977159"
  },
  {
    "text": "demo that I showed you and so on so it's NOS now that if you would have that",
    "start": "1977159",
    "end": "1982639"
  },
  {
    "text": "function to like get the route and um unfortunately I don't have it right now here we could Now call that function get",
    "start": "1982639",
    "end": "1989720"
  },
  {
    "text": "the result from our own database or from Google Maps or from Big maps and feed",
    "start": "1989720",
    "end": "1995080"
  },
  {
    "text": "that back into our prompt that is the secret Source behind all the co-pilots",
    "start": "1995080",
    "end": "2000799"
  },
  {
    "text": "and all the plugins that you may have heard the actual calling of the function is something the developers needs to do",
    "start": "2000799",
    "end": "2006720"
  },
  {
    "text": "or your custom runtime needs to do and for example systems like semantic kernel or length chain they are already",
    "start": "2006720",
    "end": "2013440"
  },
  {
    "text": "equipped to be able to understand function definitions and how do you describe something to call and so",
    "start": "2013440",
    "end": "2019200"
  },
  {
    "text": "on the plugins by the way um follow the open API standard the chat GPD plugins",
    "start": "2019200",
    "end": "2026720"
  },
  {
    "text": "and that Microsoft also uses so you will have to Define your plugins basically as",
    "start": "2026720",
    "end": "2032240"
  },
  {
    "text": "web services according to the open AI open API standards",
    "start": "2032240",
    "end": "2038840"
  },
  {
    "text": "okay um and now here you would then call basically you would um you would call",
    "start": "2038840",
    "end": "2045000"
  },
  {
    "text": "the function now based on that chat message that you received",
    "start": "2045000",
    "end": "2050200"
  },
  {
    "text": "yeah now the other thing I wanted to get briefly into is this topic of embeddings the other thing you hear a lot is how do",
    "start": "2050200",
    "end": "2056760"
  },
  {
    "text": "you talk to your own data yeah how do I do this I want to inject my own data and",
    "start": "2056760",
    "end": "2062839"
  },
  {
    "text": "well you could use functions to some extent for that but the other thing is basically basically based on something",
    "start": "2062839",
    "end": "2069040"
  },
  {
    "text": "called embeddings embeddings is a semantic way how to represent information as it's",
    "start": "2069040",
    "end": "2076560"
  },
  {
    "text": "a way to represent semantics as numbers like in this case it's like 1536 numbers",
    "start": "2076560",
    "end": "2083358"
  },
  {
    "text": "it like every embedding for a block of text is basically a an array of",
    "start": "2083359",
    "end": "2091320"
  },
  {
    "text": "1,536 numbers with the embeddings that open AI has so the for cute dog this is",
    "start": "2091320",
    "end": "2097440"
  },
  {
    "text": "BAS basically this long string here now if you have embeddings it's a vector",
    "start": "2097440",
    "end": "2103720"
  },
  {
    "text": "yeah you can do things with vectors for example you can calculate um the ukian distance or the coign similarity they",
    "start": "2103720",
    "end": "2110880"
  },
  {
    "text": "different similarity um metrics um based on Algebra I mean and",
    "start": "2110880",
    "end": "2118440"
  },
  {
    "text": "and linear algebra that you can use on vectors and nothing else is done behind",
    "start": "2118440",
    "end": "2125680"
  },
  {
    "text": "the scenes with um when people talk like we want to talk",
    "start": "2125680",
    "end": "2132800"
  },
  {
    "text": "about your own data what they do first is they calculate embeddings like here let's say calculate",
    "start": "2132800",
    "end": "2138760"
  },
  {
    "text": "similarity and then let's say you have a helper function get embeddings for string and now I have a few strings here",
    "start": "2138760",
    "end": "2145320"
  },
  {
    "text": "like for example I have a string John really does like ice cream John really does dislike ice cream John really does",
    "start": "2145320",
    "end": "2151520"
  },
  {
    "text": "not like doesn't like ice cream and alpaka licks space rocks and now I'm calculating through embeddings",
    "start": "2151520",
    "end": "2158359"
  },
  {
    "text": "and I'm looking at the similarity for example between liking ice cream doesn't like ice cream liking ice cream",
    "start": "2158359",
    "end": "2164440"
  },
  {
    "text": "disliking ice cream liking ice cream and disliking ice doesn't like ice cream and embeddings like ice cream and embeddings",
    "start": "2164440",
    "end": "2170960"
  },
  {
    "text": "alpaka lick space rocks what we find there um is for example that",
    "start": "2170960",
    "end": "2179480"
  },
  {
    "text": "the similarity between embeddings like ice cream it doesn't like ice cream is like",
    "start": "2179480",
    "end": "2185200"
  },
  {
    "text": "0.95 which is lower than the between um doesn't like ice cream and disliking ice",
    "start": "2185200",
    "end": "2191319"
  },
  {
    "text": "cream so it knows to some extent that um liking ice cream is disliking ice cream",
    "start": "2191319",
    "end": "2196760"
  },
  {
    "text": "is less related than um two times not liking ice cream however and that is",
    "start": "2196760",
    "end": "2204440"
  },
  {
    "text": "important for you when you develop your own systems it's not like a per it's not able to really um contrast negative",
    "start": "2204440",
    "end": "2211599"
  },
  {
    "text": "information with a strong signal in the number for example the similarity",
    "start": "2211599",
    "end": "2216920"
  },
  {
    "text": "between liking ice cream in the Paka sck space rocks is 0.76 which is lower than",
    "start": "2216920",
    "end": "2223560"
  },
  {
    "text": "all of them so meaning if you build something with a query that's like a that's a negative query type of things",
    "start": "2223560",
    "end": "2230440"
  },
  {
    "text": "you may not get the inspected results often like in terms of excluding",
    "start": "2230440",
    "end": "2235599"
  },
  {
    "text": "information you want to exclude be aware of that now how do the",
    "start": "2235599",
    "end": "2242240"
  },
  {
    "text": "um now how do the um then systems uses the systems uses for",
    "start": "2242240",
    "end": "2250960"
  },
  {
    "text": "example let's see if I can demonstrate it",
    "start": "2250960",
    "end": "2255520"
  },
  {
    "text": "in Azure openi",
    "start": "2256640",
    "end": "2262839"
  },
  {
    "text": "chat add your own data preview I hope I have it",
    "start": "2263240",
    "end": "2269200"
  },
  {
    "text": "[Music]",
    "start": "2269200",
    "end": "2272420"
  },
  {
    "text": "Stills no upload files",
    "start": "2274599",
    "end": "2279440"
  },
  {
    "text": "okay and then I'm able now use embedding Vector I'm",
    "start": "2299160",
    "end": "2304800"
  },
  {
    "text": "should be able now to upload some text now come",
    "start": "2304800",
    "end": "2312280"
  },
  {
    "text": "on okay my demo got fail me here so um I",
    "start": "2312280",
    "end": "2318480"
  },
  {
    "text": "cannot show you that right now um I must must have messed up something but to try to fix that um so what would",
    "start": "2318480",
    "end": "2326640"
  },
  {
    "text": "happen behind the scene it would upload that say PDF file then it would look at the PDF file in different blocks because",
    "start": "2326640",
    "end": "2334560"
  },
  {
    "text": "it has a size limitation let's say the embedding can be I don't know 15,000 tokens but PDF",
    "start": "2334560",
    "end": "2342200"
  },
  {
    "text": "file is 1 million tokens and it would basically chunk it up in like 10,000 tokens 10,000 tokens 20,000 tokens and",
    "start": "2342200",
    "end": "2349400"
  },
  {
    "text": "create an embedding from that and store that somewhere so you have the embedding",
    "start": "2349400",
    "end": "2355240"
  },
  {
    "text": "and you have the actual text now when you search for it when you",
    "start": "2355240",
    "end": "2360440"
  },
  {
    "text": "search like hey I want to chat like what is in that PDF file now what happens",
    "start": "2360440",
    "end": "2365560"
  },
  {
    "text": "then what happens then is then then you get on this territory territory of",
    "start": "2365560",
    "end": "2371240"
  },
  {
    "text": "So-Cal Vector databases Vector databases store this edting like this is just a big vector and just return it and",
    "start": "2371240",
    "end": "2378760"
  },
  {
    "text": "they're able to calculate cosine similarity like I mentioned before let's say when the question like is in the PDF",
    "start": "2378760",
    "end": "2385960"
  },
  {
    "text": "like what can you tell me about NDC conference uh dinner time and this would",
    "start": "2385960",
    "end": "2393200"
  },
  {
    "text": "be the PDF about the conference and there it is it is very likely that it's an able them to find um an embedding",
    "start": "2393200",
    "end": "2401480"
  },
  {
    "text": "that is close to um talking about dinner times if had",
    "start": "2401480",
    "end": "2407880"
  },
  {
    "text": "information about dinner times in the PDF because of it just has the highest number of like this similarity index in",
    "start": "2407880",
    "end": "2415960"
  },
  {
    "text": "the embedding that's all those so-call Vector datab bases help you do they store the um vectors the embeddings in",
    "start": "2415960",
    "end": "2423680"
  },
  {
    "text": "an efficient way and they have basically optimized function it to retrieve them",
    "start": "2423680",
    "end": "2428800"
  },
  {
    "text": "later on um for",
    "start": "2428800",
    "end": "2432319"
  },
  {
    "text": "you okay now the other thing I wanted to get into is um how do we develop like a",
    "start": "2434000",
    "end": "2441400"
  },
  {
    "text": "little bit more advanced systems you reach a point I mean where you could build your own um libraries",
    "start": "2441400",
    "end": "2447880"
  },
  {
    "text": "your own tools um to for example integrate Vector databases or to build",
    "start": "2447880",
    "end": "2452960"
  },
  {
    "text": "composite applications or how do you store my prompts and all those things things um are solved for you by specific",
    "start": "2452960",
    "end": "2461200"
  },
  {
    "text": "tool chains one of the tool chains is very popular is length chain that's primarily python but also JavaScript and",
    "start": "2461200",
    "end": "2467760"
  },
  {
    "text": "in the Microsoft world we have um semantic kernel which is an open source product and semantic",
    "start": "2467760",
    "end": "2474280"
  },
  {
    "text": "kernel um does come",
    "start": "2474280",
    "end": "2481078"
  },
  {
    "text": "on um does something for you for example it is able to um for example first of all it's net",
    "start": "2483599",
    "end": "2491119"
  },
  {
    "text": "based so you don't leave the familiar world of dotnet and it is able",
    "start": "2491119",
    "end": "2499240"
  },
  {
    "text": "to um work with so-called skills skills or I think they're renaming the plugin",
    "start": "2499240",
    "end": "2505240"
  },
  {
    "text": "and so skills are basically just prompts that are that you can use in your apps",
    "start": "2505240",
    "end": "2512400"
  },
  {
    "text": "like a function here was a so called Fun skill um joke time travel to the",
    "start": "2512400",
    "end": "2518680"
  },
  {
    "text": "dinosaur and so it generates text why did the time TR traveler refuse to fight the T-Rex because he didn't want to be",
    "start": "2518680",
    "end": "2525680"
  },
  {
    "text": "dinosaur tomorrow yeah so but how does it do that yeah",
    "start": "2525680",
    "end": "2533240"
  },
  {
    "text": "so CTIC canal and if we go into into the skills",
    "start": "2534720",
    "end": "2542319"
  },
  {
    "text": "here fun skill scope it has a um has",
    "start": "2542319",
    "end": "2547480"
  },
  {
    "text": "basically configuration the configuration has a description which is basically a really really simple prompt",
    "start": "2547480",
    "end": "2554280"
  },
  {
    "text": "and those preconfigured um weights that you",
    "start": "2554280",
    "end": "2559880"
  },
  {
    "text": "um a preconfigured parameters like temperature and so on the top five that you can feed the language model with I",
    "start": "2559880",
    "end": "2566240"
  },
  {
    "text": "think I opened the wrong file now the actual um library is",
    "start": "2566240",
    "end": "2573010"
  },
  {
    "text": "[Music] an sample skill um fun skill",
    "start": "2573010",
    "end": "2581079"
  },
  {
    "text": "joke then it has here a little bit longer ProMed right exactly one joke and",
    "start": "2581079",
    "end": "2587200"
  },
  {
    "text": "um joke must be G-rated workplace Family Safety and has like a little um syntax",
    "start": "2587200",
    "end": "2592960"
  },
  {
    "text": "how you then feed in information and get output information and you still had that config here so this is what sematic",
    "start": "2592960",
    "end": "2601319"
  },
  {
    "text": "kernel enables you to do for little bit more EX Advanced",
    "start": "2601319",
    "end": "2608040"
  },
  {
    "text": "example of semantic kernel I have a little video that I recorded",
    "start": "2608040",
    "end": "2614280"
  },
  {
    "text": "earlier that actually show it at a different conference um but it's not conference branded so I can show it to",
    "start": "2616359",
    "end": "2622440"
  },
  {
    "text": "you really",
    "start": "2622440",
    "end": "2624880"
  },
  {
    "text": "quickly now this demo here we starting the chat co-pilot example app by the",
    "start": "2627520",
    "end": "2633800"
  },
  {
    "text": "Powell we don't need this okay there's an example app also you can download which tells you how um a good pattern",
    "start": "2633800",
    "end": "2641160"
  },
  {
    "text": "how to implement my own co-pilots um including how do I build a plug-in how do I store information how",
    "start": "2641160",
    "end": "2648760"
  },
  {
    "text": "do I work with a vector database and all those things now in this example app um",
    "start": "2648760",
    "end": "2654880"
  },
  {
    "text": "you can do a few interesting things um for example the first thing we do is we're going to activate the plugin that",
    "start": "2654880",
    "end": "2661119"
  },
  {
    "text": "is that it knows off you can add a plugin custom plug-in and here it knows",
    "start": "2661119",
    "end": "2666520"
  },
  {
    "text": "already um about a Microsoft graph plugin that's also open source you can use it so here's an example that teaches",
    "start": "2666520",
    "end": "2673400"
  },
  {
    "text": "basically it how to interact with Microsoft graph is the capabilities calendars read mail read mail send read",
    "start": "2673400",
    "end": "2679440"
  },
  {
    "text": "write and so on um behind the scenes that looks very similar to what I showed you in the samples source code for",
    "start": "2679440",
    "end": "2688119"
  },
  {
    "text": "interacting with raw API so basically it has a calendar read function it describes the parameters and basically",
    "start": "2688119",
    "end": "2694240"
  },
  {
    "text": "the co-pilot has a really really really long prompt behind the scenes that describes all the functions and when you",
    "start": "2694240",
    "end": "2700040"
  },
  {
    "text": "ask it now a specific question um for example the question being what",
    "start": "2700040",
    "end": "2707240"
  },
  {
    "text": "is my last appointment then in this case in my",
    "start": "2707240",
    "end": "2714160"
  },
  {
    "text": "calendar um the now the semantic kernel together with the language model",
    "start": "2714160",
    "end": "2721280"
  },
  {
    "text": "does for the following it generates a So-Cal plan what do I do with this because it has been um fed all those",
    "start": "2721280",
    "end": "2728520"
  },
  {
    "text": "different plugins now the first step it generates a plan what do I do next and",
    "start": "2728520",
    "end": "2734160"
  },
  {
    "text": "the plan is like here I want to get calendar events and I want to get last event and",
    "start": "2734160",
    "end": "2740599"
  },
  {
    "text": "from there I want to Output the results last appointment is that okay for you mean it's something they implemented",
    "start": "2740599",
    "end": "2746359"
  },
  {
    "text": "like to confirm because for example if you want to delete information or send an email maybe you want to have a",
    "start": "2746359",
    "end": "2752599"
  },
  {
    "text": "confirm button for this yeah so that's a good pattern in general to do and it executes this in then your last",
    "start": "2752599",
    "end": "2758839"
  },
  {
    "text": "appointment with Alex was in August 8 now how does it look behind the scene it basically generates also adjacent first",
    "start": "2758839",
    "end": "2766680"
  },
  {
    "text": "for the plan the proposed plan is adjacent structure and has several steps",
    "start": "2766680",
    "end": "2771920"
  },
  {
    "text": "for example with parameters the input the Max results and then here the function get calendar",
    "start": "2771920",
    "end": "2778440"
  },
  {
    "text": "events now semantic kernel will do the calling of this plug-in for um for you",
    "start": "2778440",
    "end": "2788920"
  },
  {
    "text": "let's see where it is and you could also let it send an",
    "start": "2789520",
    "end": "2798119"
  },
  {
    "text": "email after that let's see if it shows me the plan in a different",
    "start": "2798119",
    "end": "2803960"
  },
  {
    "text": "format no okay and so you can yeah this is in",
    "start": "2813599",
    "end": "2820359"
  },
  {
    "text": "the complete generator plan for you so the last thing I wanted to show you",
    "start": "2820359",
    "end": "2826280"
  },
  {
    "text": "um another cool thing you can do with embeddings meaning exploring",
    "start": "2826280",
    "end": "2833800"
  },
  {
    "text": "information so as as I've showed you earlier embeddings give you some",
    "start": "2834599",
    "end": "2840599"
  },
  {
    "text": "similarity um information about text so what can you do with it in this case I",
    "start": "2840599",
    "end": "2846200"
  },
  {
    "text": "did a little draing of the NDC portal website and then assigned a few",
    "start": "2846200",
    "end": "2852359"
  },
  {
    "text": "categories cloud computing programming languages artificial intelligence soft skill self improvement and calculate",
    "start": "2852359",
    "end": "2859000"
  },
  {
    "text": "embeddings for this and now I want to calculate basically the proximity of those topics",
    "start": "2859000",
    "end": "2866839"
  },
  {
    "text": "with some of the session abstracts now what happens behind the scenes I mean this is python so I'm",
    "start": "2866839",
    "end": "2873559"
  },
  {
    "text": "using a lot of um work on other people's Giants we have 1,536 Dimensions that",
    "start": "2873559",
    "end": "2879880"
  },
  {
    "text": "represent semantics yeah we do a so-called dimensionality",
    "start": "2879880",
    "end": "2885880"
  },
  {
    "text": "reduction it's a heavy word but it means basically hey simplify this from 1500",
    "start": "2885880",
    "end": "2891280"
  },
  {
    "text": "Dimension to three dimension so I can see it and um we can then give it points but",
    "start": "2891280",
    "end": "2898920"
  },
  {
    "text": "those things I care for are like those topic names like cloud computing and so",
    "start": "2898920",
    "end": "2904440"
  },
  {
    "text": "on and so on and then when we do this we get some interesting things I mean the coloring is not perfect here but then we",
    "start": "2904440",
    "end": "2911200"
  },
  {
    "text": "can draw something because it reduces three dimensional space and here's a topic cloud computing you see the",
    "start": "2911200",
    "end": "2917839"
  },
  {
    "text": "abstracts that are closed for example toward a carbon away cloud cloud with death",
    "start": "2917839",
    "end": "2925160"
  },
  {
    "text": "containers cloud and Native security landscape and here the topic is artificial intelligence and here AI in",
    "start": "2925160",
    "end": "2932599"
  },
  {
    "text": "the future work and mod try prob responsible i principles and so on now",
    "start": "2932599",
    "end": "2939440"
  },
  {
    "text": "this is a very interesting technique if you want to explore really really really large large data sets and do things like",
    "start": "2939440",
    "end": "2945920"
  },
  {
    "text": "cluster analysis and so on I mean you could extend that and then for example think about you could remove keywords",
    "start": "2945920",
    "end": "2952079"
  },
  {
    "text": "and add keywords and do your math in a different way I think I have one",
    "start": "2952079",
    "end": "2958520"
  },
  {
    "text": "more way I I rendered it here this uses a slightly different methodology behind",
    "start": "2958520",
    "end": "2963880"
  },
  {
    "text": "it where basically those um keywords act like attractors and they're being pulled",
    "start": "2963880",
    "end": "2970400"
  },
  {
    "text": "in the direction of the keyword but it has a very similar result you can explore your information based on the",
    "start": "2970400",
    "end": "2977280"
  },
  {
    "text": "semantics that it has internally yeah it's also one what I wanted to share",
    "start": "2977280",
    "end": "2982839"
  },
  {
    "text": "with you all now the last thing um of course all",
    "start": "2982839",
    "end": "2988799"
  },
  {
    "text": "this thing is not without risk that's we cannot um hide that and there's a lot of",
    "start": "2988799",
    "end": "2995319"
  },
  {
    "text": "ways how this can occur for you because users may do nasty things yeah so you",
    "start": "2995319",
    "end": "3003079"
  },
  {
    "text": "can try to for example in your prompt you can mitigate some of the",
    "start": "3003079",
    "end": "3008160"
  },
  {
    "text": "risks by telling let's see cancel and you prompt",
    "start": "3008160",
    "end": "3014960"
  },
  {
    "text": "already in the system method you can try to give it more rules what it should do like it should never lie it should um",
    "start": "3014960",
    "end": "3022240"
  },
  {
    "text": "always be friendly and the models have been usually also optimized for that little little bit but there are attacks",
    "start": "3022240",
    "end": "3029200"
  },
  {
    "text": "to toward that different ways how you can trick a model and um so this is not a completely secure way so people um can",
    "start": "3029200",
    "end": "3037920"
  },
  {
    "text": "find workaround for that there's also uh papers that describe general adversary",
    "start": "3037920",
    "end": "3043839"
  },
  {
    "text": "attacks for against large language models that have been patched now for the production model that I'm aware of",
    "start": "3043839",
    "end": "3050119"
  },
  {
    "text": "but um where people can say Hey how do I build a bomb then usually the model would say no no no no can't do that it's",
    "start": "3050119",
    "end": "3057480"
  },
  {
    "text": "not good shouldn't build bombs but sometimes you can trick it and the tricks are sometimes for example they",
    "start": "3057480",
    "end": "3062599"
  },
  {
    "text": "find the ways where in the model weights um it would start saying sure or yeah",
    "start": "3062599",
    "end": "3071559"
  },
  {
    "text": "this is how you and like they're nudging the models little bit by little into that direction that is why often you",
    "start": "3071559",
    "end": "3079680"
  },
  {
    "text": "have models supervising models like for example the Pew generation that you get",
    "start": "3079680",
    "end": "3085359"
  },
  {
    "text": "and that you find that also if you interact with Bing chat for example if you tried Bing chat then sometimes it",
    "start": "3085359",
    "end": "3091119"
  },
  {
    "text": "generates them text and suddenly says oops I can't do this so this is because there's a secondary content filter model",
    "start": "3091119",
    "end": "3098520"
  },
  {
    "text": "that supervises the text based on specific rules yeah um um you can argue",
    "start": "3098520",
    "end": "3104920"
  },
  {
    "text": "if that's a good idea or not my personal views are that you could give PE give people more power because a bad guys",
    "start": "3104920",
    "end": "3111079"
  },
  {
    "text": "will do bad guys any bad things anyways um and they also workaround for",
    "start": "3111079",
    "end": "3116359"
  },
  {
    "text": "that there are tricks for that for example if you let's say um now let's say this one one",
    "start": "3116359",
    "end": "3123960"
  },
  {
    "text": "here um generate text as look alike asky no look",
    "start": "3123960",
    "end": "3133240"
  },
  {
    "text": "like unic code let's see if it does it",
    "start": "3133240",
    "end": "3139040"
  },
  {
    "text": "here H okay he doesn't do it let's do it in chat gbt um tell me something",
    "start": "3139040",
    "end": "3148040"
  },
  {
    "text": "something funny but use look Alik Unicode out",
    "start": "3148040",
    "end": "3155200"
  },
  {
    "text": "output see you see that it uses like basically those characters that are not",
    "start": "3155480",
    "end": "3160720"
  },
  {
    "text": "actual Unicode characters but look just look like it like a Spam system like zons and other side or",
    "start": "3160720",
    "end": "3168960"
  },
  {
    "text": "like a til under the E now those tricks for example may already trick some of",
    "start": "3168960",
    "end": "3174480"
  },
  {
    "text": "the content filters that are out there you could also say generate the codee as generate this as base 64 encode it like",
    "start": "3174480",
    "end": "3182720"
  },
  {
    "text": "okay now base 64",
    "start": "3182720",
    "end": "3186760"
  },
  {
    "text": "encoded yeah so you could generalize something like this so there are a lot of ways that people can still trick your",
    "start": "3189079",
    "end": "3195880"
  },
  {
    "text": "system to generate nasty stuff that you probably will not be able to detect easily yeah I mean it won't be directly",
    "start": "3195880",
    "end": "3203680"
  },
  {
    "text": "visible to the end user like um because it's basic 4 in cod in this case but um",
    "start": "3203680",
    "end": "3209960"
  },
  {
    "text": "you could see that some of the secondary content filters may may fail if you do something like that yeah and as models",
    "start": "3209960",
    "end": "3217319"
  },
  {
    "text": "get more capable um the evasion tricks that you can use on your end to evade also get more advanced yeah so maybe you",
    "start": "3217319",
    "end": "3225839"
  },
  {
    "text": "can Define your own more complex ciphers than base 64 uncoded yeah so",
    "start": "3225839",
    "end": "3233920"
  },
  {
    "text": "um this is kind of where want to stop the presentation for today I could talk",
    "start": "3233920",
    "end": "3241119"
  },
  {
    "text": "like probably for hours but my goal was to give you like is like a little bit of a foundation of what is behind all this",
    "start": "3241119",
    "end": "3247920"
  },
  {
    "text": "and how it fits together in the sense and cutting through some of of the hyp",
    "start": "3247920",
    "end": "3254160"
  },
  {
    "text": "hyperbole that you see on YouTube and so on models will get a lot more powerful",
    "start": "3254160",
    "end": "3259440"
  },
  {
    "text": "and um the jp4 vision that just came out people are only learning to explore what",
    "start": "3259440",
    "end": "3264920"
  },
  {
    "text": "it means and um and I cannot talk about too much how that works behind the",
    "start": "3264920",
    "end": "3270119"
  },
  {
    "text": "scenes and so on because much of it has not been published yet um but in",
    "start": "3270119",
    "end": "3276240"
  },
  {
    "text": "general the concepts behind the scenes always work also in this in the so-called semantic space meaning",
    "start": "3276240",
    "end": "3283359"
  },
  {
    "text": "internally they always use embedding some math representation and combine let's say a semantic representation of",
    "start": "3283359",
    "end": "3289400"
  },
  {
    "text": "an image with the semantic representation of a text and then combine all of this and generate text",
    "start": "3289400",
    "end": "3294599"
  },
  {
    "text": "out of this this is very simplified view of it now the last five minutes I want",
    "start": "3294599",
    "end": "3299680"
  },
  {
    "text": "to open up for questions or spend it like you want to so we could either try something that you wanted to see if it",
    "start": "3299680",
    "end": "3305359"
  },
  {
    "text": "works or doesn't work or I can um you can ask me",
    "start": "3305359",
    "end": "3311440"
  },
  {
    "text": "something okay I take the silence that you that you don't have questions or you",
    "start": "3314720",
    "end": "3320079"
  },
  {
    "text": "oh there's a question yeah U my question is for example we are system that will",
    "start": "3320079",
    "end": "3327920"
  },
  {
    "text": "uh be by train I mean it knows about our",
    "start": "3327920",
    "end": "3333960"
  },
  {
    "text": "internal communication what is the best uh approach to get a",
    "start": "3333960",
    "end": "3340559"
  },
  {
    "text": "meaningful uh request we ask about our internal system is it using BS or F",
    "start": "3340559",
    "end": "3349680"
  },
  {
    "text": "tuning or just some cont so so the question was when you have your internal",
    "start": "3349680",
    "end": "3357119"
  },
  {
    "text": "system that works on internal documents what is the best way how to interact",
    "start": "3357119",
    "end": "3363119"
  },
  {
    "text": "with that and get information in there so um there are few patterns that have been established and um currently and",
    "start": "3363119",
    "end": "3371680"
  },
  {
    "text": "usually it's a combination of embeddings to store the information that you care",
    "start": "3371680",
    "end": "3377200"
  },
  {
    "text": "for then you do a lookup meaning look up of the embeddings and get the text segments that may be",
    "start": "3377200",
    "end": "3385079"
  },
  {
    "text": "relevant that you ask the language model for the text segments please summarize",
    "start": "3385079",
    "end": "3390359"
  },
  {
    "text": "them or or form in a way and then you put this in a new prompt and tell the",
    "start": "3390359",
    "end": "3397200"
  },
  {
    "text": "language model like this this extracted and modified uh text that you got um now",
    "start": "3397200",
    "end": "3405240"
  },
  {
    "text": "summarize of those five documents what is relevant for the question that was asked about what's our HealthCare",
    "start": "3405240",
    "end": "3411559"
  },
  {
    "text": "coverage or our vacation policy or who was the most productive person and so on",
    "start": "3411559",
    "end": "3417880"
  },
  {
    "text": "um the technique is called retrieval augmented generation so you first retrieve some information out of some",
    "start": "3417880",
    "end": "3423480"
  },
  {
    "text": "arbitrary system could also be a Plugin or lookup in a database but often it's done with embedding in Vector databases",
    "start": "3423480",
    "end": "3430280"
  },
  {
    "text": "and then T text and put it in the generation again um fine",
    "start": "3430280",
    "end": "3437520"
  },
  {
    "text": "tuning is um currently because of the SC scarcity of resources for the most",
    "start": "3437520",
    "end": "3444000"
  },
  {
    "text": "capable models um pretty cost prohibitive and um some people use it",
    "start": "3444000",
    "end": "3450920"
  },
  {
    "text": "however but it's less about teaching the model new facts but for example",
    "start": "3450920",
    "end": "3456400"
  },
  {
    "text": "modifying the style for example let's say you have a database of 10,000 emails",
    "start": "3456400",
    "end": "3462160"
  },
  {
    "text": "that you send to customers that you you know are written well and reflect the style you want your model to speak",
    "start": "3462160",
    "end": "3469119"
  },
  {
    "text": "because that's a corporate style then you could fine-tune maybe that model to more reflect that the style that you",
    "start": "3469119",
    "end": "3475200"
  },
  {
    "text": "usually use so you could also try that with um",
    "start": "3475200",
    "end": "3480799"
  },
  {
    "text": "larger prompts but um it may not be as good at copying a style than um fine",
    "start": "3480799",
    "end": "3486799"
  },
  {
    "text": "tuning for example there also additional techniques um um Lowa low rank",
    "start": "3486799",
    "end": "3494160"
  },
  {
    "text": "adaptation um for example that's um also a paper from Microsoft where they found",
    "start": "3494160",
    "end": "3500880"
  },
  {
    "text": "that um there's some sparsity in the model weights theal representation they",
    "start": "3500880",
    "end": "3506119"
  },
  {
    "text": "basically found let's say a trick how you can have a lot smaller file that acts like an adapter you plug in and it",
    "start": "3506119",
    "end": "3512799"
  },
  {
    "text": "does something like fine tuning for you so it can nudge the model also in the direction like you want um without",
    "start": "3512799",
    "end": "3519880"
  },
  {
    "text": "needing a full fine tuning of the really really really large model file it's that's very popular for image generation",
    "start": "3519880",
    "end": "3526200"
  },
  {
    "text": "for example for stable diffusion there's so a lot of um low rank adaptation Lowa",
    "start": "3526200",
    "end": "3531559"
  },
  {
    "text": "um files to represent a style or how you look like introduce that to the image and so on I hope that helps a",
    "start": "3531559",
    "end": "3540440"
  },
  {
    "text": "little okay so we have one more minute so last question I'm also around and you",
    "start": "3540440",
    "end": "3547599"
  },
  {
    "text": "can look me up in LinkedIn and shoot me questions I will try to answer what I",
    "start": "3547599",
    "end": "3554400"
  },
  {
    "text": "know okay well with that thank you for hanging out with me and I hope you have a wonderful time in Porter and we that",
    "start": "3554400",
    "end": "3561960"
  },
  {
    "text": "we will have less rain thanks",
    "start": "3561960",
    "end": "3568039"
  }
]
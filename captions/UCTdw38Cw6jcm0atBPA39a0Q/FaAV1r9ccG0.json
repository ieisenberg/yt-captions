[
  {
    "text": "hi everyone thank you so much for coming to our talk we're very excited to be back",
    "start": "6480",
    "end": "12200"
  },
  {
    "text": "here at NC Oslo and hope you've had a good first day at the conference okay so this talk is about Ai",
    "start": "12200",
    "end": "19480"
  },
  {
    "text": "and specifically large language models and we will share a practical",
    "start": "19480",
    "end": "24680"
  },
  {
    "text": "perspective to how you can use llms but we will also dive into some technical",
    "start": "24680",
    "end": "30000"
  },
  {
    "text": "details into how our system is created my name is Matia Asik I work as",
    "start": "30000",
    "end": "36239"
  },
  {
    "text": "the head of AI at ncart I have a masters from antonu in tonim and I've been",
    "start": "36239",
    "end": "41480"
  },
  {
    "text": "working at ncart now for seven years uh mostly as a software developer and I've",
    "start": "41480",
    "end": "47199"
  },
  {
    "text": "always been very interested in how we can use AI in our products and especially together with geospatial data",
    "start": "47199",
    "end": "54120"
  },
  {
    "text": "and eventually I got the opportunity to lead a designated designated AI team",
    "start": "54120",
    "end": "61039"
  },
  {
    "text": "my name is uh Malta um I have a masters in artificial intelligence from Anu and",
    "start": "61039",
    "end": "67119"
  },
  {
    "text": "I've been working as a consultant for six years on various machine learning projects for V and and and then a year",
    "start": "67119",
    "end": "75439"
  },
  {
    "text": "ago I had the pleasure of joining the AI team at",
    "start": "75439",
    "end": "81320"
  },
  {
    "text": "new there are a few more people in our team uh with different backgrounds and",
    "start": "82439",
    "end": "87759"
  },
  {
    "text": "different specialities and we're also very lucky to have Henrik in our team who's actually working on his PhD in",
    "start": "87759",
    "end": "94880"
  },
  {
    "text": "natural language processing so we'll come back to uh specifics about his work a little bit later in the",
    "start": "94880",
    "end": "102880"
  },
  {
    "text": "talk so our aim in the AI team at ncart is to figure out how we can use AI to",
    "start": "102960",
    "end": "109200"
  },
  {
    "text": "both improve our products but also improve the way that we work and since we are a small team it's",
    "start": "109200",
    "end": "117119"
  },
  {
    "text": "very important for us to try to share the or spread the AI knowledge across",
    "start": "117119",
    "end": "122479"
  },
  {
    "text": "our company and one of the ways we do this is that we we invite different teams to join us for two days hackathons",
    "start": "122479",
    "end": "129599"
  },
  {
    "text": "where we choose some topic and let people get some hands-on experience with coding with AI",
    "start": "129599",
    "end": "135959"
  },
  {
    "text": "system so I thought we would share some few examples of results from these",
    "start": "135959",
    "end": "141200"
  },
  {
    "text": "hackathons so the first one is our own AI code reviewer so this uh lives in a",
    "start": "141200",
    "end": "147400"
  },
  {
    "text": "pipeline it reads the giti on pull request and gives a summary to what uh",
    "start": "147400",
    "end": "153440"
  },
  {
    "text": "what the changes in the pull requests are and also suggests some possible issues so this has been um running for",
    "start": "153440",
    "end": "162720"
  },
  {
    "text": "about a month now and I think one thing that we can say is that the llm is better at giving good descriptions of",
    "start": "162720",
    "end": "170319"
  },
  {
    "text": "what the changes in the tool requests are we tend to be a little bit short when we write our description and some",
    "start": "170319",
    "end": "177440"
  },
  {
    "text": "of the issues are actual issues that we do need to address so it works pretty",
    "start": "177440",
    "end": "184000"
  },
  {
    "text": "well another example of results from hackaton is um a chat bot we call nura",
    "start": "184000",
    "end": "189920"
  },
  {
    "text": "nkut AI and she can reply to questions about things in nkut uh questions about",
    "start": "189920",
    "end": "196799"
  },
  {
    "text": "our products our Tech stack and things like that so this is for internal use",
    "start": "196799",
    "end": "202159"
  },
  {
    "text": "and a third example is an extension that we uh made for GitHub co-pilot so you",
    "start": "202159",
    "end": "208959"
  },
  {
    "text": "can actually make a extensions to the GitHub co-pilot extension in vas code so",
    "start": "208959",
    "end": "214319"
  },
  {
    "text": "this is in preview for Microsoft but we tested it and we were able to add extra functionality specifically to ncart so",
    "start": "214319",
    "end": "221280"
  },
  {
    "text": "that we can use the GitHub co-pilot chat and ask ncart specific questions questions that are not necessarily",
    "start": "221280",
    "end": "227239"
  },
  {
    "text": "related to the work space that you're in also very useful and then some examples of uh AI",
    "start": "227239",
    "end": "234720"
  },
  {
    "text": "in our products we have a root planner that we use in several of our systems",
    "start": "234720",
    "end": "240640"
  },
  {
    "text": "and we also work a lot with image analysis and specifically detecting objects in aerial",
    "start": "240640",
    "end": "246640"
  },
  {
    "text": "images so we have models that can detect buildings we have another model that can",
    "start": "246640",
    "end": "252560"
  },
  {
    "text": "detect roads but also swimming pools Terraces and things like that and what",
    "start": "252560",
    "end": "258440"
  },
  {
    "text": "we have created is an application for the municipalities to go through the results and see uh what the AI has",
    "start": "258440",
    "end": "266120"
  },
  {
    "text": "detected that isn't already in the map so that they can for example Det protect illegal",
    "start": "266120",
    "end": "272360"
  },
  {
    "text": "buildings the topic for this talk is about Building Services and specifically",
    "start": "272360",
    "end": "277919"
  },
  {
    "text": "building permits so first we're going to talk a little bit about the current situation and uh building permits in",
    "start": "277919",
    "end": "285360"
  },
  {
    "text": "norion B just so everyone is uh on on board um yeah so first we're going to",
    "start": "285360",
    "end": "292720"
  },
  {
    "text": "talk a little about uh the current situation and then we will talk about plan Prat which is our LM system that",
    "start": "292720",
    "end": "299960"
  },
  {
    "text": "tries to make this process of applying for a building permit a little bit easier and we will talk about evaluation",
    "start": "299960",
    "end": "307360"
  },
  {
    "text": "how we can evaluate an LA llm system and finally talk a little bit about",
    "start": "307360",
    "end": "313160"
  },
  {
    "text": "different models so before I continue just a small disclaimer we are going to be talking",
    "start": "313160",
    "end": "319960"
  },
  {
    "text": "about Norwegian text and Norwegian text analysis and therefore there will be Norwegian text on the slides but we will",
    "start": "319960",
    "end": "327520"
  },
  {
    "text": "try to translate everything that you need to need to understand that there's also some subtitles uh on some of the",
    "start": "327520",
    "end": "335120"
  },
  {
    "text": "slides so we hope this uh will be okay for you guys okay so Norwegian municipalities",
    "start": "335120",
    "end": "343000"
  },
  {
    "text": "they receive around 990,000 building applications every year they have limited resources and are under a",
    "start": "343000",
    "end": "349680"
  },
  {
    "text": "significant work pressure people expect quick responses to their uh building applications and also questions around",
    "start": "349680",
    "end": "356160"
  },
  {
    "text": "how to fill them out and all of this creates frustration ation at many levels",
    "start": "356160",
    "end": "362039"
  },
  {
    "text": "in fact several surveys indicate that Planning and Building Services have the lowest level of satisfaction among all",
    "start": "362039",
    "end": "368919"
  },
  {
    "text": "Municipal services so applying for a building permit is really difficult it's",
    "start": "368919",
    "end": "375280"
  },
  {
    "text": "difficult both for the applicant but also for the municipality but why is it like",
    "start": "375280",
    "end": "380720"
  },
  {
    "text": "this okay so a question if I can manage to see you guys who here have applied",
    "start": "380720",
    "end": "386360"
  },
  {
    "text": "for a building permit in Norway before quite a few of you okay so who here",
    "start": "386360",
    "end": "392800"
  },
  {
    "text": "enjoyed the process and thought it was easy and and okay anyone I don't see any hands okay",
    "start": "392800",
    "end": "402039"
  },
  {
    "text": "so for those of you who have not gone through this process I'll try to explain how it could look like so this is permit",
    "start": "402039",
    "end": "409599"
  },
  {
    "text": "Penny and permit Penny she has this idea of a garage that she would really like to uh to build on her property so she",
    "start": "409599",
    "end": "417080"
  },
  {
    "text": "goes to her computer and she starts looking online can I build a garage on my property she",
    "start": "417080",
    "end": "424039"
  },
  {
    "text": "soon figures out that the answer is well it depends it depends on what size she",
    "start": "424039",
    "end": "430800"
  },
  {
    "text": "wants to build the distance to Coastline distance to property border distance to Avalanche risk distance to railway does",
    "start": "430800",
    "end": "439360"
  },
  {
    "text": "she want a loft on her garage are there existing buildings how many on her",
    "start": "439360",
    "end": "445960"
  },
  {
    "text": "property what is the distance to different roads and so on one so there are lots of rules and lots of things she",
    "start": "445960",
    "end": "453400"
  },
  {
    "text": "needs to figure out and all of these rules are what we can call National",
    "start": "453400",
    "end": "458440"
  },
  {
    "text": "rules they are the same across all of Norway but there's still a lot to figure",
    "start": "458440",
    "end": "464159"
  },
  {
    "text": "out but it doesn't stop there she soon realizes that there are a different set",
    "start": "464159",
    "end": "469599"
  },
  {
    "text": "of rules the so-called local rules and the local rules are different",
    "start": "469599",
    "end": "476080"
  },
  {
    "text": "for every municipality but not just for the municipality but also different for every property within that",
    "start": "476080",
    "end": "482440"
  },
  {
    "text": "municipality so she needs to figure out what zone she's in is there a building boundary on her property what is the",
    "start": "482440",
    "end": "489080"
  },
  {
    "text": "permitted utilization is there a maximum height limit are there rules for how the",
    "start": "489080",
    "end": "494240"
  },
  {
    "text": "exterior should look like and now she starts getting really frustrated she has",
    "start": "494240",
    "end": "499440"
  },
  {
    "text": "no idea what a building boundary is she doesn't know how to figure out what the permitted utilization is and how to",
    "start": "499440",
    "end": "505280"
  },
  {
    "text": "calculate it it's just really over overwhelming and it's all important to",
    "start": "505280",
    "end": "510319"
  },
  {
    "text": "her so at this point she has four options she can uh choose to pay someone",
    "start": "510319",
    "end": "516839"
  },
  {
    "text": "to help her there are a lot of companies that um can apply for a building permit on your",
    "start": "516839",
    "end": "522518"
  },
  {
    "text": "behalf she can choose to build illegally and hope that her municipality doesn't buy the AI service from nkar that can",
    "start": "522519",
    "end": "529080"
  },
  {
    "text": "detect illegal buildings she can give up or she can try",
    "start": "529080",
    "end": "534279"
  },
  {
    "text": "her best so Penny goes for the fourth option",
    "start": "534279",
    "end": "539640"
  },
  {
    "text": "so she starts digging into these local rules and tries to figure out what rules apply to her and her",
    "start": "539640",
    "end": "546480"
  },
  {
    "text": "property so what are these local rules local rules are called sonal plans in",
    "start": "546480",
    "end": "552920"
  },
  {
    "text": "Oregan Aral planet or regulating planet and they are uh legally binding",
    "start": "552920",
    "end": "559560"
  },
  {
    "text": "documents that provides rule for how land within an area can be used and what types of construction may be permitted",
    "start": "559560",
    "end": "567320"
  },
  {
    "text": "and the sonal plans consist of two parts the first one is a text",
    "start": "567320",
    "end": "573000"
  },
  {
    "text": "document and the second one is a map the text document is often written by lawyers and can be long maybe around 100",
    "start": "573000",
    "end": "582560"
  },
  {
    "text": "pages and there's not just one sonal plan for your property there are usually",
    "start": "583560",
    "end": "589600"
  },
  {
    "text": "several so you have the municipal master plan which covers the entire municipality but then you also have zal",
    "start": "589600",
    "end": "596680"
  },
  {
    "text": "plans detailed sonal plans and also other types of zal plans that I haven't added here but there can be many",
    "start": "596680",
    "end": "603279"
  },
  {
    "text": "different zal plans for your property and you need to look at each and every one of",
    "start": "603279",
    "end": "609040"
  },
  {
    "text": "them and the fact is that Norwegian M municipalities are drowning in Old sonal plants so new sonal plans are added all",
    "start": "609040",
    "end": "616200"
  },
  {
    "text": "the time but they don't want to delete the old ones in case there are some rules and regulations that they still",
    "start": "616200",
    "end": "622120"
  },
  {
    "text": "want to keep so the number of zal plans just keep increasing and it gets more",
    "start": "622120",
    "end": "627640"
  },
  {
    "text": "and more complex but penny is persistent she has gone",
    "start": "627640",
    "end": "633760"
  },
  {
    "text": "through all the rules it took her weeks but now she has finally completed her uh building application and sent it into",
    "start": "633760",
    "end": "640160"
  },
  {
    "text": "the municipality and she's quite confident that she will get her building permits so now she just has to wait for",
    "start": "640160",
    "end": "647639"
  },
  {
    "text": "the municipality to look through her application that also takes a few weeks",
    "start": "647639",
    "end": "653600"
  },
  {
    "text": "but she finally gets a reply she's super excited she opens her email but this is",
    "start": "653600",
    "end": "659000"
  },
  {
    "text": "her response her application is rejected she",
    "start": "659000",
    "end": "664160"
  },
  {
    "text": "doesn't get her building permits because on page",
    "start": "664160",
    "end": "669360"
  },
  {
    "text": "124 in one of the sonal plans there was a regulation that she hadn't realized applied to her that actually said that",
    "start": "669360",
    "end": "676320"
  },
  {
    "text": "she wasn't allowed to build at all so this is of course a madeup story but in fact 40% of all applications",
    "start": "676320",
    "end": "684079"
  },
  {
    "text": "contain incorrect information or are incomplete and a lot of this is related",
    "start": "684079",
    "end": "689959"
  },
  {
    "text": "to the sonal plans and people not understanding how the sonal plans apply to",
    "start": "689959",
    "end": "696160"
  },
  {
    "text": "them so the sonal plans they contain intricate words and expressions it's a",
    "start": "696839",
    "end": "702040"
  },
  {
    "text": "lot of information to go through and the rules are chaotic and",
    "start": "702040",
    "end": "708279"
  },
  {
    "text": "unclear thank you um so how can we make it easier to",
    "start": "709920",
    "end": "715519"
  },
  {
    "text": "understand these sonal plans and the answer you all of them uh",
    "start": "715519",
    "end": "721040"
  },
  {
    "text": "all of you know the answer already it is of course language models um language models are the most",
    "start": "721040",
    "end": "728920"
  },
  {
    "text": "hype of all the hype right now it's where everything is happening um so let's try to explain a little bit about",
    "start": "728920",
    "end": "737120"
  },
  {
    "text": "it so actually what most people don't know is that language models uh one of",
    "start": "737320",
    "end": "742519"
  },
  {
    "text": "the foundations for them is this theorem based on Baron from 93 and it's about if you take the",
    "start": "742519",
    "end": "748600"
  },
  {
    "text": "integral of the gradient of f then you can write uh F ofx minus F of0 to",
    "start": "748600",
    "end": "755120"
  },
  {
    "text": "something like this ah no the sound doesn't",
    "start": "755120",
    "end": "762519"
  },
  {
    "text": "work no can we see how we can fix",
    "start": "762519",
    "end": "770000"
  },
  {
    "text": "that or we're not going to fix that we're not going to fix that are we I go back we can try to go back maybe the",
    "start": "770000",
    "end": "776120"
  },
  {
    "text": "technical people know something that we don't know",
    "start": "776120",
    "end": "781120"
  },
  {
    "text": "there we go there we go okay pretended this this didn't didn't happen so um oh",
    "start": "783880",
    "end": "790839"
  },
  {
    "text": "no what just happened who is this wait a second this is plum Prat speaking Plum",
    "start": "790839",
    "end": "797760"
  },
  {
    "text": "Prat but you're not even unveiled yet what can I do for you Plum Prat do you",
    "start": "797760",
    "end": "803440"
  },
  {
    "text": "really think people want to learn about this cut to the chase bro come on okay okay well relax relax almost sound a",
    "start": "803440",
    "end": "809600"
  },
  {
    "text": "little bit like Matia but uh um yeah I'll cut to the chase no worries um so",
    "start": "809600",
    "end": "816199"
  },
  {
    "text": "we're not going to go into the intricacies of the math math here uh we're just going to go through",
    "start": "816199",
    "end": "822800"
  },
  {
    "text": "some few words that you need to know in order to follow this presentation the first one is an llm and it stands for a",
    "start": "822800",
    "end": "829680"
  },
  {
    "text": "large language model uh furthermore we have prompt and prompt engineering so when you work with",
    "start": "829680",
    "end": "836480"
  },
  {
    "text": "a large language model you can think of it it's just something that takes textt in and you get some text out and the",
    "start": "836480",
    "end": "842680"
  },
  {
    "text": "text in is called The Prompt and what you can do is that you can alter this prompt in order to",
    "start": "842680",
    "end": "850399"
  },
  {
    "text": "manipulate the output from the llm so you can give an instruction such as keep it short and the LM is going to answer",
    "start": "850399",
    "end": "857680"
  },
  {
    "text": "more concise and this is what's called prompt",
    "start": "857680",
    "end": "863639"
  },
  {
    "text": "engineering then we have tokens and embeddings so when you work with large",
    "start": "863639",
    "end": "870480"
  },
  {
    "text": "language models these models they don't understand words they don't just work with numbers so you have to somehow",
    "start": "870480",
    "end": "876320"
  },
  {
    "text": "translate from words into numbers and uh one way you can do that",
    "start": "876320",
    "end": "882079"
  },
  {
    "text": "is by uh is by creating a unique ID for a given word and this is called",
    "start": "882079",
    "end": "888600"
  },
  {
    "text": "tokenizing so let's say we want to tokenize King and Queen you can just give them two random values the problems",
    "start": "888600",
    "end": "897120"
  },
  {
    "text": "with this is that now we're uh losing all of the semantic meaning behind these",
    "start": "897120",
    "end": "903000"
  },
  {
    "text": "words uh and in order to combat that you can try to make something called the embeddings and the embeddings is just",
    "start": "903000",
    "end": "909759"
  },
  {
    "text": "list of uh numbers or vectors of numbers that represent one part of a text so an",
    "start": "909759",
    "end": "918199"
  },
  {
    "text": "embedding for King could look something like these five numbers and the embedding for Queen could look uh like",
    "start": "918199",
    "end": "923360"
  },
  {
    "text": "the the other one and you can notice here that the three first numbers in these vectors they're the same and",
    "start": "923360",
    "end": "929920"
  },
  {
    "text": "that's because king and queen are quite similar in the semantic meaning because they're both",
    "start": "929920",
    "end": "935519"
  },
  {
    "text": "Royal another way of showing this is on a 2d plot so you can see here that king",
    "start": "935519",
    "end": "941839"
  },
  {
    "text": "and queen should be somewhat relatively close to each other the same way that",
    "start": "941839",
    "end": "947360"
  },
  {
    "text": "for instance a man and a woman should be close on a separate part of the plot but",
    "start": "947360",
    "end": "952560"
  },
  {
    "text": "what's also more fascinating is that the distance from man to woman and King to Queen is probably going to be around the",
    "start": "952560",
    "end": "960079"
  },
  {
    "text": "same because we have managed to capture some of the semantic meaning behind these words and this doesn't only uh this",
    "start": "960079",
    "end": "968240"
  },
  {
    "text": "doesn't stop at words this also continues into sentences or even whole",
    "start": "968240",
    "end": "975839"
  },
  {
    "text": "paragraphs so you can make embeddings of paragraphs and you can find paragraphs that are more similar to each",
    "start": "975839",
    "end": "983160"
  },
  {
    "text": "other and the last we have to cover here is something called context so remember",
    "start": "983160",
    "end": "989440"
  },
  {
    "text": "this um conversation we just had with the AI if you want to answer uh or ask it",
    "start": "989440",
    "end": "996360"
  },
  {
    "text": "another question such as uh how did you calculate that you're now referring to",
    "start": "996360",
    "end": "1001560"
  },
  {
    "text": "something that happens earlier in the conversation so you have to paste the whole chat history in and this is what's",
    "start": "1001560",
    "end": "1007639"
  },
  {
    "text": "called the context and in this case the context is just the chat history but you can kind of give the language models",
    "start": "1007639",
    "end": "1014759"
  },
  {
    "text": "anything or any elevant information that you you think it should know",
    "start": "1014759",
    "end": "1020759"
  },
  {
    "text": "about so now that we know everything about large language models what happens",
    "start": "1020759",
    "end": "1026280"
  },
  {
    "text": "if we ask for instance chat GPT if I can build a garage on my property well chat GPT is going to",
    "start": "1026280",
    "end": "1033798"
  },
  {
    "text": "answer that building a garage on your property depends on several factors including local zal regulations and so",
    "start": "1033799",
    "end": "1041438"
  },
  {
    "text": "on and so on and that is of course because it's missing all the information to zal plans it's missing information",
    "start": "1041439",
    "end": "1049320"
  },
  {
    "text": "about the geospatial uh information uh such as the property",
    "start": "1049320",
    "end": "1055679"
  },
  {
    "text": "information and where the property is situated and what is currently on the property um and it also doesn't have not",
    "start": "1055679",
    "end": "1062080"
  },
  {
    "text": "have any knowledge about the zal plans expressions and",
    "start": "1062080",
    "end": "1068039"
  },
  {
    "text": "intricacies yes so challenge number one how can we give access to the sonal",
    "start": "1068799",
    "end": "1075840"
  },
  {
    "text": "plans so first of all we as developers need access access to the zal plans and at nkat we already have access to them",
    "start": "1075840",
    "end": "1083120"
  },
  {
    "text": "because um a lot of the municipalities are customers of us and we actually provide the system where they manage",
    "start": "1083120",
    "end": "1089559"
  },
  {
    "text": "their sonal plants so that's solved so the next one",
    "start": "1089559",
    "end": "1094679"
  },
  {
    "text": "is how can we give the sonal plans to an LM so the first obvious one would be to",
    "start": "1094679",
    "end": "1102000"
  },
  {
    "text": "just copy the entire plan just give the full full text to the model so this",
    "start": "1102000",
    "end": "1108799"
  },
  {
    "text": "would mean that we would would give it a lot of information around maybe 300 Pages which",
    "start": "1108799",
    "end": "1115120"
  },
  {
    "text": "again would be expensive because you pay per token that the model is",
    "start": "1115120",
    "end": "1120840"
  },
  {
    "text": "processing and you would also give it a lot of information that could be misleading because these documents",
    "start": "1120840",
    "end": "1126919"
  },
  {
    "text": "contain so much text and regulations for an entire municipality but you usually have one question related to a specific",
    "start": "1126919",
    "end": "1133520"
  },
  {
    "text": "topic for a specific area so this is where the rag",
    "start": "1133520",
    "end": "1139919"
  },
  {
    "text": "architecture comes into play rag stands for retrieval augmented generation and",
    "start": "1139919",
    "end": "1145960"
  },
  {
    "text": "is a very use and is very useful when you have a question that you need answered based on some",
    "start": "1145960",
    "end": "1151960"
  },
  {
    "text": "documents so the first step in a rag architecture is the retrieval step and",
    "start": "1151960",
    "end": "1158000"
  },
  {
    "text": "the retrieval step can be done with an AI search so I'll try to explain a",
    "start": "1158000",
    "end": "1163200"
  },
  {
    "text": "little bit what it is so the first step to create an AI search is to First take",
    "start": "1163200",
    "end": "1169039"
  },
  {
    "text": "your documents and split it into chunks of text so this is a part of the pre-processing that Malta will talk a",
    "start": "1169039",
    "end": "1175159"
  },
  {
    "text": "little bit more about later how the prepressing actually works but for now just think of it as taking the documents",
    "start": "1175159",
    "end": "1180760"
  },
  {
    "text": "and creating chunks of text the chunks of text are then added to an embedding",
    "start": "1180760",
    "end": "1185799"
  },
  {
    "text": "model and the embedding embedding model places the chunks of text in the embedding space based on their relevance",
    "start": "1185799",
    "end": "1193000"
  },
  {
    "text": "so if two chunks are similar to each other it will be close to each other in the embedding space if they're different",
    "start": "1193000",
    "end": "1199720"
  },
  {
    "text": "they will be further apart like the king and queen example the embeddings are then saved",
    "start": "1199720",
    "end": "1205559"
  },
  {
    "text": "into a vector datab base which allows us to perform a search so we take the question and we",
    "start": "1205559",
    "end": "1213360"
  },
  {
    "text": "use this qu question to search for chunks of text that are relevant for that",
    "start": "1213360",
    "end": "1219280"
  },
  {
    "text": "question and the chunks of text that the search um retrieves will most likely be",
    "start": "1219280",
    "end": "1226679"
  },
  {
    "text": "the part of the text that you need to read in order to answer that question so these chunks of text are",
    "start": "1226679",
    "end": "1232840"
  },
  {
    "text": "then added to the prompt together with the question but we also need a system prompt and the system prompt tells the",
    "start": "1232840",
    "end": "1239679"
  },
  {
    "text": "system how it should solve its main task the entire prompt is then added to",
    "start": "1239679",
    "end": "1246360"
  },
  {
    "text": "or passed to a language model that can now generate an answer based on the",
    "start": "1246360",
    "end": "1251480"
  },
  {
    "text": "entire prompt so this is a system that we uh",
    "start": "1251480",
    "end": "1257400"
  },
  {
    "text": "have created in order order to make plant Prat and plant Prat",
    "start": "1257400",
    "end": "1264720"
  },
  {
    "text": "sorry a plant Prat can be translated directly to the pl talker it doesn't",
    "start": "1264720",
    "end": "1270000"
  },
  {
    "text": "really translate well uh but this is a chatbot that can um answer questions",
    "start": "1270000",
    "end": "1276400"
  },
  {
    "text": "about the content of zonal plans for a property so what is the correct system",
    "start": "1276400",
    "end": "1282240"
  },
  {
    "text": "message to give to plantat so that it will do its its uh task correctly well",
    "start": "1282240",
    "end": "1288600"
  },
  {
    "text": "we can tell it that you're an expert at interpreting zal plans and will assist residents in determining what is",
    "start": "1288600",
    "end": "1294000"
  },
  {
    "text": "permitted on a given property based on the regulations provided in the planning data you are",
    "start": "1294000",
    "end": "1300000"
  },
  {
    "text": "given and then it needs to know that the relevant information from the sonal plans are the chunks of texts so we add",
    "start": "1300000",
    "end": "1307640"
  },
  {
    "text": "the chunks from the search into uh into the instructions and of course ask it to",
    "start": "1307640",
    "end": "1314919"
  },
  {
    "text": "answer the following question and then add the question from the user",
    "start": "1314919",
    "end": "1320519"
  },
  {
    "text": "all right thank you um so let's talk a little bit about this pre-processing that Matia mentioned um so the",
    "start": "1322880",
    "end": "1329679"
  },
  {
    "text": "pre-processing has kind of two goals it uh the first one is to get a textural representation of the plants and the",
    "start": "1329679",
    "end": "1336840"
  },
  {
    "text": "second one is to split them into chunks and as we saw on Matilda's uh",
    "start": "1336840",
    "end": "1343159"
  },
  {
    "text": "slide it is this part uh that we're covering right now",
    "start": "1343159",
    "end": "1349919"
  },
  {
    "text": "so um we also want to kind of make the the text somewhat standardized um",
    "start": "1349919",
    "end": "1359799"
  },
  {
    "text": "but it's quite difficult because there's different images there's different",
    "start": "1359799",
    "end": "1365480"
  },
  {
    "text": "figures there's handwritten text and so on and all of these plans the",
    "start": "1365480",
    "end": "1370880"
  },
  {
    "text": "municipalities write them in uh different ways um because they can and they want",
    "start": "1370880",
    "end": "1376799"
  },
  {
    "text": "to um uh yeah so there's a lot of different formats uh going going around out",
    "start": "1376799",
    "end": "1385200"
  },
  {
    "text": "there um so to Showcase this how it is to work with these plans uh I ask all of",
    "start": "1385200",
    "end": "1391320"
  },
  {
    "text": "you to to close your eyes close your eyes and don't open them before I tell",
    "start": "1391320",
    "end": "1397520"
  },
  {
    "text": "you to I can't see if you actually closed them but I think most of you have closed",
    "start": "1397520",
    "end": "1402919"
  },
  {
    "text": "them um okay now I assume most of you are Developers so pretend that you're",
    "start": "1402919",
    "end": "1409760"
  },
  {
    "text": "walking into the office on a good day if you're a PowerPoint Warrior or something",
    "start": "1409760",
    "end": "1415200"
  },
  {
    "text": "else just imagine that you're a developer so you get into the office you're ready for a good day at work",
    "start": "1415200",
    "end": "1422240"
  },
  {
    "text": "during the day you know you attend some meeting you spill out your opinions on a couple of",
    "start": "1422240",
    "end": "1427919"
  },
  {
    "text": "matters mostly on which coffee machine is the best or who in upper management would win a fight to the death",
    "start": "1427919",
    "end": "1433799"
  },
  {
    "text": "theoretically of course",
    "start": "1433799",
    "end": "1437559"
  },
  {
    "text": "and you might even code a bit too now imagine the team lead comes in",
    "start": "1440360",
    "end": "1445840"
  },
  {
    "text": "and says you got to parse some tables in the sonal plants you think to yourself",
    "start": "1445840",
    "end": "1451440"
  },
  {
    "text": "cool that should be an easy task you're even going to go the extra mile in this one and make sure that your code can",
    "start": "1451440",
    "end": "1457600"
  },
  {
    "text": "parse any table no matter how many rows or columns there are in the table your code will",
    "start": "1457600",
    "end": "1463080"
  },
  {
    "text": "parse it surely this should be no problem so you get into a tal plan and",
    "start": "1463080",
    "end": "1468960"
  },
  {
    "text": "you find a table easiest table of my life now you can open your eyes and this",
    "start": "1468960",
    "end": "1475320"
  },
  {
    "text": "is the table you find and wow it's actually easy it's so easy your code",
    "start": "1475320",
    "end": "1480360"
  },
  {
    "text": "Works flawlessly but then you want to move on to another table and then you see this one and",
    "start": "1480360",
    "end": "1487799"
  },
  {
    "text": "you're a little bit like wait wait a second the top left corner the cell is",
    "start": "1487799",
    "end": "1494520"
  },
  {
    "text": "cut in half what is going on here and then you look a little bit closer and you find that there's not two headline",
    "start": "1494520",
    "end": "1501320"
  },
  {
    "text": "rows no there's not one headline row there's actually two so you have to make some adjustments you know but you uh you",
    "start": "1501320",
    "end": "1509159"
  },
  {
    "text": "get there you know and uh now you're all happy again but",
    "start": "1509159",
    "end": "1515080"
  },
  {
    "text": "then you see this one and here you have at the beginning you have two columns",
    "start": "1515080",
    "end": "1521000"
  },
  {
    "text": "but then one of the columns they split into six columns and then there's visual",
    "start": "1521000",
    "end": "1526240"
  },
  {
    "text": "representation there's yellow and there's red and there's probably way",
    "start": "1526240",
    "end": "1531960"
  },
  {
    "text": "more information in one cell that could be split into multiple cells and so on",
    "start": "1531960",
    "end": "1538000"
  },
  {
    "text": "and then you go you you you Traverse the further and you go into this one you see this one and here you have some weird",
    "start": "1538000",
    "end": "1544960"
  },
  {
    "text": "maximum minimum stuff going on but it's not uh not in all of the cells only in",
    "start": "1544960",
    "end": "1551360"
  },
  {
    "text": "some of them because it would be too easy if there was all of the cells that had Maxum minimum in",
    "start": "1551360",
    "end": "1556520"
  },
  {
    "text": "them and then you see this one and you're like here there is multiple",
    "start": "1556520",
    "end": "1562440"
  },
  {
    "text": "columns within one column and not even going to talk about this one but then",
    "start": "1562440",
    "end": "1568039"
  },
  {
    "text": "the AI team's personal favorite is uh this one where you have",
    "start": "1568039",
    "end": "1574960"
  },
  {
    "text": "you have multiple rows or two rows in one row and you have red and green",
    "start": "1574960",
    "end": "1584120"
  },
  {
    "text": "dots and how you're going to parse them you have no idea so uh yeah that's how",
    "start": "1584120",
    "end": "1589679"
  },
  {
    "text": "it is to work with these these uh these plants so uh an Insight in day of Our",
    "start": "1589679",
    "end": "1596000"
  },
  {
    "text": "Lives uh yes okay but uh Jokes Aside uh",
    "start": "1596000",
    "end": "1601399"
  },
  {
    "text": "this story is of course a little bit exaggerated not much but a little bit um",
    "start": "1601399",
    "end": "1607159"
  },
  {
    "text": "and how can you solve these problems well one way you can solve it is to simply just give up and if you detect",
    "start": "1607159",
    "end": "1614679"
  },
  {
    "text": "table or if you need to some information from a table you can just ask the user uh themselves to go in and uh figure out",
    "start": "1614679",
    "end": "1622720"
  },
  {
    "text": "what it says because we have no idea um or we could also try to use an",
    "start": "1622720",
    "end": "1628240"
  },
  {
    "text": "llm with vision capabilities um this one is a little bit uh unknown we haven't",
    "start": "1628240",
    "end": "1633919"
  },
  {
    "text": "tried it but um it could work but if we as humans",
    "start": "1633919",
    "end": "1640480"
  },
  {
    "text": "can't read it it's also not that probable that an llm could read it",
    "start": "1640480",
    "end": "1645799"
  },
  {
    "text": "either okay so a part of this pre-processing we",
    "start": "1645799",
    "end": "1652159"
  },
  {
    "text": "also uh stumble across a bunch of scan documents and what's so different about",
    "start": "1652159",
    "end": "1658440"
  },
  {
    "text": "these is that scan documents they can't you can't programmatically get the text from",
    "start": "1658440",
    "end": "1663919"
  },
  {
    "text": "them um so you have to somehow use a different OCR",
    "start": "1663919",
    "end": "1670799"
  },
  {
    "text": "model um and when you use one of these OCR models um it actually works quite",
    "start": "1670799",
    "end": "1677120"
  },
  {
    "text": "well if the scan documents are easy to read and well structured such as this one we have on the top half we have a a",
    "start": "1677120",
    "end": "1684600"
  },
  {
    "text": "scan document and then when you use some OCR you know everything gets out correctly at the bottom half",
    "start": "1684600",
    "end": "1689919"
  },
  {
    "text": "here but not all the plants are that well structured you know well some",
    "start": "1689919",
    "end": "1695600"
  },
  {
    "text": "plants looks maybe like this where you have handwritten texts as well as at the",
    "start": "1695600",
    "end": "1702559"
  },
  {
    "text": "bottom two lines here you have some fields that are not filled out and if",
    "start": "1702559",
    "end": "1707720"
  },
  {
    "text": "you just perform OCR from this well first of all the handwritten text gets",
    "start": "1707720",
    "end": "1713399"
  },
  {
    "text": "uh incorrectly labeled but also that if you just get the text from two bottom",
    "start": "1713399",
    "end": "1719679"
  },
  {
    "text": "lines it actually looks like it is approved in the building uh Council and",
    "start": "1719679",
    "end": "1725840"
  },
  {
    "text": "the and the municipality as we can see if you see at the bottom two uh two lines in the in",
    "start": "1725840",
    "end": "1733279"
  },
  {
    "text": "the extracted text so how can we solve this what well",
    "start": "1733279",
    "end": "1738440"
  },
  {
    "text": "if you use an llm A multimodel llm or an llm with vision capabilities we can now",
    "start": "1738440",
    "end": "1744679"
  },
  {
    "text": "prompt it so we can now tell the llm that if you see some fields that are not",
    "start": "1744679",
    "end": "1750519"
  },
  {
    "text": "filled you could annotate it with the well field not filled or something like that and if you do that you actually get",
    "start": "1750519",
    "end": "1757159"
  },
  {
    "text": "surprisingly good results first of all the handwritten text is almost 100%",
    "start": "1757159",
    "end": "1762720"
  },
  {
    "text": "correct but also as we can see now it actually says field not filled at the",
    "start": "1762720",
    "end": "1768760"
  },
  {
    "text": "bottom and now we also can understand that it is actually not approved anywhere because there is date",
    "start": "1768760",
    "end": "1777559"
  },
  {
    "text": "missing and then a funny one you know you will be surprised of the quality of",
    "start": "1777600",
    "end": "1782799"
  },
  {
    "text": "these plants but some of the plants look like this and uh but even though that we barely can read them the the language",
    "start": "1782799",
    "end": "1789600"
  },
  {
    "text": "models can actually read them quite well this is all correct instead of except",
    "start": "1789600",
    "end": "1794919"
  },
  {
    "text": "for the middle part where it says Ved and the we think that the reason for that I can't read that is that um",
    "start": "1794919",
    "end": "1801600"
  },
  {
    "text": "there's too much gap between the letters in that word but everything else is",
    "start": "1801600",
    "end": "1808279"
  },
  {
    "text": "correct all right okay so now that we've done some more uh processing plan Prat",
    "start": "1808279",
    "end": "1815720"
  },
  {
    "text": "is able to analyze most of the documents so what we did was that we",
    "start": "1815720",
    "end": "1821000"
  },
  {
    "text": "implemented plan Prat into um a system called aisak an application that a lot",
    "start": "1821000",
    "end": "1826960"
  },
  {
    "text": "of uh archit use to fill out their uh building applications and send them to",
    "start": "1826960",
    "end": "1832080"
  },
  {
    "text": "the municipality and if someone reacts to Broken English it's because they use the automatic translate button in Google",
    "start": "1832080",
    "end": "1838000"
  },
  {
    "text": "Chrome this is of course a Norwegian uh website",
    "start": "1838000",
    "end": "1843440"
  },
  {
    "text": "so you can create your application and uh the application is connected to a",
    "start": "1843440",
    "end": "1849679"
  },
  {
    "text": "property and you can now go to the plan Tab and this is where plan plat lives",
    "start": "1849679",
    "end": "1858480"
  },
  {
    "text": "and now since we know what property the user wants information from we can actually use that to make plant better",
    "start": "1858480",
    "end": "1865720"
  },
  {
    "text": "so the first thing we do is to First fetch the relevant zal plant because we",
    "start": "1865720",
    "end": "1871360"
  },
  {
    "text": "don't want to start searching for chunks of text independent of the sonal plans that are actually valid for this",
    "start": "1871360",
    "end": "1877480"
  },
  {
    "text": "property so we need to First figure out what zal plans exist and then we can do the",
    "start": "1877480",
    "end": "1883840"
  },
  {
    "text": "rest but now we can actually start prompting Plum ask it some",
    "start": "1884720",
    "end": "1890559"
  },
  {
    "text": "questions for example how much can I build and the first thing that happens",
    "start": "1890559",
    "end": "1896200"
  },
  {
    "text": "is that it starts searching uh through the documents so here you can see that",
    "start": "1896200",
    "end": "1901760"
  },
  {
    "text": "it says Which documents or which zal plans it it is searching in so these are",
    "start": "1901760",
    "end": "1907039"
  },
  {
    "text": "the zal plans that are valid for this property and it also says uh that it's",
    "start": "1907039",
    "end": "1912799"
  },
  {
    "text": "searching in long and difficult documents hold on because this does take a while the search part is pretty fast",
    "start": "1912799",
    "end": "1919320"
  },
  {
    "text": "but then waiting for the LM to read the different trunks of data the complete prompt and then generate an answer it",
    "start": "1919320",
    "end": "1924960"
  },
  {
    "text": "takes some time maybe around a minute but if you're patient you will get a",
    "start": "1924960",
    "end": "1931120"
  },
  {
    "text": "response and this is a much better response than having to read all of",
    "start": "1931120",
    "end": "1936159"
  },
  {
    "text": "those documents so now the system has been able to extract chunks of text and read it and then rephrase that text into",
    "start": "1936159",
    "end": "1943799"
  },
  {
    "text": "an answer that actually tells us something about what the sonal plan says about how much you can build on that",
    "start": "1943799",
    "end": "1952159"
  },
  {
    "text": "property but there's always a butt there is always a butt um so how could we can we tell if",
    "start": "1952159",
    "end": "1961559"
  },
  {
    "text": "the answer here is correct right because uh this answer it could just be",
    "start": "1961559",
    "end": "1966679"
  },
  {
    "text": "hallucinations from the language model um so we have a couple of problems",
    "start": "1966679",
    "end": "1973159"
  },
  {
    "text": "right um that's one of the problems is hallucinations and that we can't ad double check this fact so easily because",
    "start": "1973159",
    "end": "1979960"
  },
  {
    "text": "it doesn't say which plan the information is coming from or where in",
    "start": "1979960",
    "end": "1985480"
  },
  {
    "text": "the plan the information is coming from and furthermore um it also makes us uh",
    "start": "1985480",
    "end": "1992279"
  },
  {
    "text": "able to actually potentially miss some important information because if we just want if",
    "start": "1992279",
    "end": "1999480"
  },
  {
    "text": "we just take for instance the top 30 chunks for these three uh plans we might",
    "start": "1999480",
    "end": "2006039"
  },
  {
    "text": "end up with a skewed uh chunk set if you can call it that you know uh so let's",
    "start": "2006039",
    "end": "2011880"
  },
  {
    "text": "say that the first plan or plan one it um it uh gives back 27 chunks and plan",
    "start": "2011880",
    "end": "2020440"
  },
  {
    "text": "two G gives back three chunks but then we don't don't get any chunks from Plan",
    "start": "2020440",
    "end": "2026039"
  },
  {
    "text": "Three but and that's a problem right because there might be some very important",
    "start": "2026039",
    "end": "2032480"
  },
  {
    "text": "information maybe not a lot but just some information in Plan Three that's really important and we don't want to make the same mistake as permit Penny",
    "start": "2032480",
    "end": "2039840"
  },
  {
    "text": "who missed some important information in one of the plans so we actually don't want to find",
    "start": "2039840",
    "end": "2046399"
  },
  {
    "text": "the most semantically correct chunks but we want to find the most semantically",
    "start": "2046399",
    "end": "2051520"
  },
  {
    "text": "correct chunks for each plan so we can ask each of the plans the same question",
    "start": "2051520",
    "end": "2058040"
  },
  {
    "text": "and then we get the top results from each of those uh chunks so for instance and then we can",
    "start": "2058040",
    "end": "2065398"
  },
  {
    "text": "kind of tune it so that we know that we have information from all of the plans so for instance uh we could have uh if",
    "start": "2065399",
    "end": "2071720"
  },
  {
    "text": "we ask one each of the plan we can pick 15 chunks from plan one 10 chunks from",
    "start": "2071720",
    "end": "2077158"
  },
  {
    "text": "plan two and five chunks from Plan",
    "start": "2077159",
    "end": "2081638"
  },
  {
    "text": "Three and the way we do this if you remember this one Matilda showed it earlier is that instead of doing one",
    "start": "2082280",
    "end": "2088760"
  },
  {
    "text": "search for all of the plants we're doing a search for each of the plants so here for instance we have two",
    "start": "2088760",
    "end": "2096158"
  },
  {
    "text": "plants and that means that we're doing two searches which means that we're getting two different",
    "start": "2096159",
    "end": "2101640"
  },
  {
    "text": "contexts that propagates into we that we get two different prompts and these two prompts we can ask two uh different",
    "start": "2101640",
    "end": "2109160"
  },
  {
    "text": "instances of a language model and then of course we are uh getting uh two",
    "start": "2109160",
    "end": "2115040"
  },
  {
    "text": "different answers back these two answers can then be shown in the front end such as here we have",
    "start": "2115040",
    "end": "2121680"
  },
  {
    "text": "asked the question and then we we get a response and it says the commun PLS are",
    "start": "2121680",
    "end": "2127720"
  },
  {
    "text": "l or plan one is saying this while the plan two is saying something else and",
    "start": "2127720",
    "end": "2133560"
  },
  {
    "text": "now we can kind of easier double check and make sure that the double check that",
    "start": "2133560",
    "end": "2138960"
  },
  {
    "text": "the correction that the information is correct and that um the model is not",
    "start": "2138960",
    "end": "2147079"
  },
  {
    "text": "hallucinating okay but we also we can also kind of end up in a in an awkward",
    "start": "2147079",
    "end": "2152160"
  },
  {
    "text": "situation here because now that we search each of the plan if if if if the",
    "start": "2152160",
    "end": "2157800"
  },
  {
    "text": "LM is not able to answer the question you're got going to have multiple times that oh I'm sorry I can't answer your",
    "start": "2157800",
    "end": "2164880"
  },
  {
    "text": "question so we have some kind of detection on that if the llm is not",
    "start": "2164880",
    "end": "2170599"
  },
  {
    "text": "using any information from any of the plans we ask the llm a backup question",
    "start": "2170599",
    "end": "2177599"
  },
  {
    "text": "if you can say anything about the question in general and then it ends up that we only get um one answer instead",
    "start": "2177599",
    "end": "2186440"
  },
  {
    "text": "of listing multiple an answers uh where the LM can't uh",
    "start": "2186440",
    "end": "2191720"
  },
  {
    "text": "answer and the way we do this is by prompting so the prompt here is first",
    "start": "2191720",
    "end": "2197640"
  },
  {
    "text": "you need to answer the question and then you must indicate whether the answer comes from the attached zonal plan or not and the answer you provide should",
    "start": "2197640",
    "end": "2204720"
  },
  {
    "text": "always be in valid Json format with two keys first key is is content from plan while the second one is answer and then",
    "start": "2204720",
    "end": "2211440"
  },
  {
    "text": "have the Json schema um don't have to look too much into that but basically we",
    "start": "2211440",
    "end": "2217240"
  },
  {
    "text": "have a Bolen is content from plan and if the llm fills that out with false then",
    "start": "2217240",
    "end": "2222880"
  },
  {
    "text": "we can just throw away that answer then we know that uh the answer is not actually from a plan and we don't have",
    "start": "2222880",
    "end": "2230440"
  },
  {
    "text": "to show it to the user and if all of the answers are false on this ballen then we",
    "start": "2230440",
    "end": "2236160"
  },
  {
    "text": "can ask the backup question um so let's take a look and",
    "start": "2236160",
    "end": "2242680"
  },
  {
    "text": "look a little bit closer on one of these uh answers so now we have an answer for",
    "start": "2242680",
    "end": "2248520"
  },
  {
    "text": "each plan but it still really still references a lot uh general areas such",
    "start": "2248520",
    "end": "2254760"
  },
  {
    "text": "as it depends on what part of the uh municipality you're in or general living",
    "start": "2254760",
    "end": "2261160"
  },
  {
    "text": "areas or special living areas or or a field called B1 here and another field",
    "start": "2261160",
    "end": "2268319"
  },
  {
    "text": "called B2 so it doesn't really doesn't really know where in the plan it is",
    "start": "2268319",
    "end": "2274519"
  },
  {
    "text": "situated okay so we need need some more geospatial information so just to be clear in the",
    "start": "2275760",
    "end": "2283280"
  },
  {
    "text": "documents there are references to areas and the areas are just given a name for",
    "start": "2283280",
    "end": "2288760"
  },
  {
    "text": "example B1 and these areas can be seen in the map in the zal plan so in order",
    "start": "2288760",
    "end": "2294920"
  },
  {
    "text": "to understand how the rules affect different areas you need to both read a document as well as look at the map and",
    "start": "2294920",
    "end": "2302040"
  },
  {
    "text": "we we ideally don't want the user to have to do neither of those two so",
    "start": "2302040",
    "end": "2308640"
  },
  {
    "text": "we know what property uh we want to fetch information about so we can use",
    "start": "2308640",
    "end": "2314599"
  },
  {
    "text": "the property border and similar to when we did the intersection analysis to find",
    "start": "2314599",
    "end": "2320440"
  },
  {
    "text": "which uh which zonal plans exist for the property we can now actually check what",
    "start": "2320440",
    "end": "2326440"
  },
  {
    "text": "parts of each of the sonal plans are intersecting the property so that we can",
    "start": "2326440",
    "end": "2331680"
  },
  {
    "text": "get a list of which areas are actually relevant to this specific property",
    "start": "2331680",
    "end": "2338440"
  },
  {
    "text": "and this information can then be fed into the llm we can't really just filter the rest out we have to ask the llm to",
    "start": "2338440",
    "end": "2346079"
  },
  {
    "text": "do that task for us so we just give it a Json structure um representation of the",
    "start": "2346079",
    "end": "2354520"
  },
  {
    "text": "different areas for that intersect with the property and we give it some",
    "start": "2354520",
    "end": "2359760"
  },
  {
    "text": "instructions for how to read this data so we tell it that the following metadata describes which Fields areas",
    "start": "2359760",
    "end": "2365560"
  },
  {
    "text": "and zones the property falls Within in and other fields and areas are therefore not",
    "start": "2365560",
    "end": "2371400"
  },
  {
    "text": "relevant so let's see how this affects the results so if we go back to our to",
    "start": "2371400",
    "end": "2377079"
  },
  {
    "text": "Plum and ask it again how high can I build we now actually get a very concise",
    "start": "2377079",
    "end": "2384800"
  },
  {
    "text": "answer so now instead of getting all of these references to the different areas",
    "start": "2384800",
    "end": "2389839"
  },
  {
    "text": "in the zal plan we get a specific answer specific to that property and it's way",
    "start": "2389839",
    "end": "2396040"
  },
  {
    "text": "more it's it's way easier to understand so this was the first first",
    "start": "2396040",
    "end": "2402839"
  },
  {
    "text": "version a lot of text not that easy to read and and then with the geospatial",
    "start": "2402839",
    "end": "2409359"
  },
  {
    "text": "information it gets a lot better okay all right",
    "start": "2409359",
    "end": "2415800"
  },
  {
    "text": "so um now that we gotten this far it's time uh to evaluate this system and how",
    "start": "2415800",
    "end": "2421880"
  },
  {
    "text": "can you do that um well in this pipeline there's",
    "start": "2421880",
    "end": "2427119"
  },
  {
    "text": "kind of kind of two areas we want to evaluate and the first one is the AI search we want to evaluate if we are",
    "start": "2427119",
    "end": "2433480"
  },
  {
    "text": "actually getting the correct chunks that we want to be getting and the second part is the answer is the llm actually",
    "start": "2433480",
    "end": "2440119"
  },
  {
    "text": "answering correctly so [Music]",
    "start": "2440119",
    "end": "2446000"
  },
  {
    "text": "um in order to do this we need to create some kind of data set a test data",
    "start": "2446000",
    "end": "2452480"
  },
  {
    "text": "set and uh in this data set we need example question",
    "start": "2452480",
    "end": "2458240"
  },
  {
    "text": "we need to know which part of the text is relevant in order to answer that question and we need the ground Truth",
    "start": "2458240",
    "end": "2467119"
  },
  {
    "text": "for that question and what we did is that we took uh some typical questions from",
    "start": "2467119",
    "end": "2474359"
  },
  {
    "text": "Architects and then we added those it's about 17 questions but then you can ask those questions for a bunch of different",
    "start": "2474359",
    "end": "2481520"
  },
  {
    "text": "plans and we got help from some of the municipalities uh to help us answer",
    "start": "2481520",
    "end": "2488599"
  },
  {
    "text": "these and we did that by setting up some sessions and uh they're experts so they",
    "start": "2488599",
    "end": "2494960"
  },
  {
    "text": "helped us uh fill it out in these sessions and we end up with a kind of a a data set in Google Sheets uh quite",
    "start": "2494960",
    "end": "2503319"
  },
  {
    "text": "simple stuff so some part of the test set looks like this you know we have a",
    "start": "2503319",
    "end": "2508599"
  },
  {
    "text": "plan you have the field the bbb1 for instance you have a question you have",
    "start": "2508599",
    "end": "2515599"
  },
  {
    "text": "the ground truth to that question question and you have all the relevant text that you need to know in order to",
    "start": "2515599",
    "end": "2520680"
  },
  {
    "text": "answer uh that question so for evaluation we are using",
    "start": "2520680",
    "end": "2527280"
  },
  {
    "text": "something called ragas and it is an open- Source framework for evaluating uh",
    "start": "2527280",
    "end": "2533280"
  },
  {
    "text": "rag pipelines it's using llms under the hood so you have to take the results with a",
    "start": "2533280",
    "end": "2539680"
  },
  {
    "text": "little bit of grain of salt but it correlates quite well with what we're thinking uh we're doing right and",
    "start": "2539680",
    "end": "2545680"
  },
  {
    "text": "wrong and uh as a big coincidence uh",
    "start": "2545680",
    "end": "2550800"
  },
  {
    "text": "there are of course metrics for both the AI search we want to test and uh the llm",
    "start": "2550800",
    "end": "2558280"
  },
  {
    "text": "generation answer generation so ragas they kind of",
    "start": "2558280",
    "end": "2565960"
  },
  {
    "text": "calculate a bunch of different metrics but we're going to focus on four today the two first ones are only measuring",
    "start": "2565960",
    "end": "2573319"
  },
  {
    "text": "how good the AI search is performing and it's called context precision and context uh",
    "start": "2573319",
    "end": "2578880"
  },
  {
    "text": "recall if you're familiar with Precision recall from before you're going to have an easier time on this next uh",
    "start": "2578880",
    "end": "2585720"
  },
  {
    "text": "section um then we have faithfulness and that is only a metric for how well the",
    "start": "2585720",
    "end": "2593200"
  },
  {
    "text": "llm generates its answer and then there is the answer correctness which tests",
    "start": "2593200",
    "end": "2598280"
  },
  {
    "text": "the whole pipeline in one go so let's try to explain some of these",
    "start": "2598280",
    "end": "2604559"
  },
  {
    "text": "so the context Precision it basically is a measurement of how relevant the items are at the top",
    "start": "2604559",
    "end": "2611319"
  },
  {
    "text": "chunks and all of these metrics by the way they are scores from zero to one",
    "start": "2611319",
    "end": "2616440"
  },
  {
    "text": "where one is perfect and zero is really bad um",
    "start": "2616440",
    "end": "2622359"
  },
  {
    "text": "so that's quite easy to to to measure you think um because you get the chunks",
    "start": "2622359",
    "end": "2629040"
  },
  {
    "text": "from a search and then you just see if they're relevant or not but how how do you know if they're relevant well you of",
    "start": "2629040",
    "end": "2635880"
  },
  {
    "text": "course ask a language model um so uh it's usually quite quite",
    "start": "2635880",
    "end": "2642520"
  },
  {
    "text": "good actually per performs pretty well um then there is context",
    "start": "2642520",
    "end": "2648760"
  },
  {
    "text": "recall and it measures if the content in chunks aligns with the ground",
    "start": "2648760",
    "end": "2654000"
  },
  {
    "text": "truth you can think of it a little bit as if if the context recall is really",
    "start": "2654000",
    "end": "2660400"
  },
  {
    "text": "bad it's actually impossible to answer the question because you don't have the data that's necessary",
    "start": "2660400",
    "end": "2668240"
  },
  {
    "text": "um the way it works is that it uses an llm to make statements from the ground",
    "start": "2668240",
    "end": "2675760"
  },
  {
    "text": "truth so the ground truth can be multiple sentences and the llm then",
    "start": "2675760",
    "end": "2681119"
  },
  {
    "text": "generates statements from this and then it checks if the statements are then",
    "start": "2681119",
    "end": "2686200"
  },
  {
    "text": "present in the chunks that you have received and if it's not present in the chunks you have received then it is of",
    "start": "2686200",
    "end": "2692960"
  },
  {
    "text": "course impossible to uh to answer then you have",
    "start": "2692960",
    "end": "2698200"
  },
  {
    "text": "faithfulness this only tests the llm answer generation and basically it's just a way",
    "start": "2698200",
    "end": "2705400"
  },
  {
    "text": "of measuring is the llm hallucinating or not and the way it does it is that it",
    "start": "2705400",
    "end": "2710599"
  },
  {
    "text": "takes statements from the answer generated and and checks if it's present in the context because if some",
    "start": "2710599",
    "end": "2718040"
  },
  {
    "text": "statements in the generated answer are not in the context that means that the llm is just making them up because where",
    "start": "2718040",
    "end": "2724480"
  },
  {
    "text": "else are they coming from and then you have the last one that uh",
    "start": "2724480",
    "end": "2730280"
  },
  {
    "text": "goes through the whole Pipeline and that's answer correctness this one is a little bit more technical to explain but",
    "start": "2730280",
    "end": "2737400"
  },
  {
    "text": "if you are a data scientist you will maybe follow along um the way it works is that it it uses an llm to find the",
    "start": "2737400",
    "end": "2746079"
  },
  {
    "text": "true positives the false positives and the false negatives and then it calculates the F1",
    "start": "2746079",
    "end": "2752520"
  },
  {
    "text": "score um for the ground truth and then it takes the ground truth and the",
    "start": "2752520",
    "end": "2758440"
  },
  {
    "text": "generated answer and it finds the coign similarity or just how similar are these",
    "start": "2758440",
    "end": "2764000"
  },
  {
    "text": "and then it takes a weighted average of all of this um and it is a measurement of of",
    "start": "2764000",
    "end": "2772000"
  },
  {
    "text": "the whole pipeline don't don't think I'm going to try to explain that anymore um so let's look at some results",
    "start": "2772000",
    "end": "2778960"
  },
  {
    "text": "from our uh our model here so here on the each row we have one uh we have we",
    "start": "2778960",
    "end": "2786960"
  },
  {
    "text": "have all the metrics and then in the columns we have three different um",
    "start": "2786960",
    "end": "2792040"
  },
  {
    "text": "experiments so the first experiment it's just pastes the entire plan and it acts",
    "start": "2792040",
    "end": "2798119"
  },
  {
    "text": "like in one chunk there's the entire plan the second one is actually using search and just takes the top Chunk from",
    "start": "2798119",
    "end": "2807119"
  },
  {
    "text": "the search and the third one is taking the top 10 chunks from the search so if we can if we look here we",
    "start": "2807119",
    "end": "2815400"
  },
  {
    "text": "can see the context recall is really high that makes a lot of sense because",
    "start": "2815400",
    "end": "2821079"
  },
  {
    "text": "if if this would not be really high then it wouldn't be able to answer the question at",
    "start": "2821079",
    "end": "2827720"
  },
  {
    "text": "all uh so the entire plan is doing really well if you only choose one Chunk",
    "start": "2827720",
    "end": "2833280"
  },
  {
    "text": "from the search we can see that's way too little information if you only if you only use this it is actually not",
    "start": "2833280",
    "end": "2839000"
  },
  {
    "text": "possible to to answer the question but you can see at 10 chunks the number goes",
    "start": "2839000",
    "end": "2844400"
  },
  {
    "text": "up again and you can uh you can kind of see that it's not as",
    "start": "2844400",
    "end": "2849839"
  },
  {
    "text": "good as the entire plan but it's almost as good then we have context Precision it",
    "start": "2849839",
    "end": "2855599"
  },
  {
    "text": "says something about if the top chunks are relevant or not and since the entire",
    "start": "2855599",
    "end": "2861960"
  },
  {
    "text": "plan and the one Chunk from search they are just retrieving like kind of one",
    "start": "2861960",
    "end": "2868040"
  },
  {
    "text": "chunk uh we can see that the llm deems the entire plan kind of relevant you",
    "start": "2868040",
    "end": "2874960"
  },
  {
    "text": "would maybe think that that number would be a little bit higher not",
    "start": "2874960",
    "end": "2880280"
  },
  {
    "text": "769 but the reason for that is that when you paste the entire plan you get all the relevant information but you also",
    "start": "2880280",
    "end": "2886720"
  },
  {
    "text": "get a bunch of other stuff that is not relevant so then the score goes a little bit down and then you can see from when",
    "start": "2886720",
    "end": "2894280"
  },
  {
    "text": "using search uh it is not really good enough and that the search here is is",
    "start": "2894280",
    "end": "2901280"
  },
  {
    "text": "probably not doing a good enough job as we can see the the scores are actually",
    "start": "2901280",
    "end": "2906920"
  },
  {
    "text": "quite a lot lower then we have faithfulness this scores pretty well across the board it",
    "start": "2906920",
    "end": "2914319"
  },
  {
    "text": "checks if the answer from the LM is in the context so it's measuring the",
    "start": "2914319",
    "end": "2919880"
  },
  {
    "text": "hallucinations so when you paste the entire plan there's actually not that much hallucinating and we can for the",
    "start": "2919880",
    "end": "2926160"
  },
  {
    "text": "most part trust what the LM is is saying but we can also see that if you only use",
    "start": "2926160",
    "end": "2931240"
  },
  {
    "text": "one Chunk from search the llm then gets a little bit um insecure or what you can",
    "start": "2931240",
    "end": "2938559"
  },
  {
    "text": "say and then it might start um saying stuff that is not from",
    "start": "2938559",
    "end": "2943839"
  },
  {
    "text": "the context and we do not really want that and then it gets a little bit better again if you take the top 10",
    "start": "2943839",
    "end": "2950119"
  },
  {
    "text": "chunks and then we can see the answer correctness which is measuring the whole Pipeline and you can notice here that",
    "start": "2950119",
    "end": "2956799"
  },
  {
    "text": "for all of these there's a big drop in performance and you can see that the",
    "start": "2956799",
    "end": "2962680"
  },
  {
    "text": "entire plan is performing best but the reason for this big drop is",
    "start": "2962680",
    "end": "2969240"
  },
  {
    "text": "that the llms they are quite verbose they really like to talk a lot and in",
    "start": "2969240",
    "end": "2974440"
  },
  {
    "text": "the AI team we have deemed it or called it bot",
    "start": "2974440",
    "end": "2980640"
  },
  {
    "text": "splaining because the bot is just rambling on um so usually actually the bot or the",
    "start": "2980640",
    "end": "2987640"
  },
  {
    "text": "llm is pretty good in the first couple of sentences to get the correct answer but then it just keeps rambling about",
    "start": "2987640",
    "end": "2995400"
  },
  {
    "text": "some semi-relevant stuff and since that's not good enough when measuring um",
    "start": "2995400",
    "end": "3000760"
  },
  {
    "text": "uh onto the ground truth then the score Falls so here we have some uh probably",
    "start": "3000760",
    "end": "3007000"
  },
  {
    "text": "some prompting to do to make the llm answer more",
    "start": "3007000",
    "end": "3012079"
  },
  {
    "text": "concisely yes um so also a big thing to think about",
    "start": "3012079",
    "end": "3017799"
  },
  {
    "text": "here is that uh this these numbers doesn't actually really tell us if we're correct",
    "start": "3017799",
    "end": "3024599"
  },
  {
    "text": "or not but what it does allow us to do is that we can tweak a lot of parameters and then we can say if we're doing",
    "start": "3024599",
    "end": "3030680"
  },
  {
    "text": "better or worse after those are tweaked and there's so many things you can tweak",
    "start": "3030680",
    "end": "3035839"
  },
  {
    "text": "here you can change out the Sur algorithms for the AI search you can tweak the search parameters within an",
    "start": "3035839",
    "end": "3042960"
  },
  {
    "text": "algorithm you can change the chunk size you can change the rules how to split",
    "start": "3042960",
    "end": "3048200"
  },
  {
    "text": "the chunks should you split them on paragraphs or should you just split them by characters you can change the llms",
    "start": "3048200",
    "end": "3054319"
  },
  {
    "text": "and see if one llm performs better or worse than another one uh you can change the parameters within an llm temperature",
    "start": "3054319",
    "end": "3061559"
  },
  {
    "text": "top P top K and that kind of stuff and then you can of course change the prompt",
    "start": "3061559",
    "end": "3067960"
  },
  {
    "text": "uh and that is just an infinite amount of work you can do zero shot prompting you can do fuse shot prompting you can",
    "start": "3067960",
    "end": "3074839"
  },
  {
    "text": "try Chain of Thought you can try react all these kind of things you can try and tweak so yeah all",
    "start": "3074839",
    "end": "3083680"
  },
  {
    "text": "right okay so now that we're able to actually evaluate our system and tweak",
    "start": "3083680",
    "end": "3089760"
  },
  {
    "text": "all of these things that Malta just said one of the obvious things to test are different models both due to Performance",
    "start": "3089760",
    "end": "3097680"
  },
  {
    "text": "but also cost so first what models are we",
    "start": "3097680",
    "end": "3103359"
  },
  {
    "text": "using to generate text we use gp4 turbo from Asher open AI which allows us to",
    "start": "3103359",
    "end": "3110160"
  },
  {
    "text": "have the models hosted in Europe which is very nice security wise uh and for the search we use Azure",
    "start": "3110160",
    "end": "3118079"
  },
  {
    "text": "AI search with uh the embedding model called AA and these models are um",
    "start": "3118079",
    "end": "3125880"
  },
  {
    "text": "state-of-the-art models they work really well and most of you or some of you have probably heard about the new GPT 40",
    "start": "3125880",
    "end": "3133480"
  },
  {
    "text": "model it's not available in uh Europe yet through asro open AI but we would will probably switch to that one when it",
    "start": "3133480",
    "end": "3140280"
  },
  {
    "text": "when it's available but yeah these are state-of-the-art models but",
    "start": "3140280",
    "end": "3146760"
  },
  {
    "text": "they are trained by big American companies so their main language is English they know Norwegian they're",
    "start": "3146760",
    "end": "3153160"
  },
  {
    "text": "really good at uh generating Norwegian text and reading Norwegian text but their main language is English and how",
    "start": "3153160",
    "end": "3160720"
  },
  {
    "text": "does this affect the performance let's look at the tokenizer for gp4 so the tokenizer is the first step",
    "start": "3160720",
    "end": "3168200"
  },
  {
    "text": "when an LM needs to um uh read some text Malta explained earlier so when you",
    "start": "3168200",
    "end": "3176680"
  },
  {
    "text": "paste some English text to A gp4 tokenizer you can see that it splits the sentence almost word by",
    "start": "3176680",
    "end": "3182880"
  },
  {
    "text": "word if you translate this sentence into nigan and ask gbd4 to tokenize that",
    "start": "3182880",
    "end": "3188839"
  },
  {
    "text": "sentence it looks very different it splits the same word into",
    "start": "3188839",
    "end": "3194559"
  },
  {
    "text": "two or maybe three tokens and um it doesn't make logical uh",
    "start": "3194559",
    "end": "3202000"
  },
  {
    "text": "splits there's one like the age alone doesn't mean anything in Norwegian so",
    "start": "3202000",
    "end": "3208000"
  },
  {
    "text": "you can see that it performs U it it's not as good in Norwegian as it is in",
    "start": "3208000",
    "end": "3213640"
  },
  {
    "text": "English and you also get a lot more tokens and the more tokens you get the more um compute power you need to",
    "start": "3213640",
    "end": "3221200"
  },
  {
    "text": "process the the text and the more it costs and the more time it",
    "start": "3221200",
    "end": "3226359"
  },
  {
    "text": "takes so what are our what are our options there are Norwegian llms",
    "start": "3226359",
    "end": "3233400"
  },
  {
    "text": "available as well there are lots of initiatives uh from different universities and so on and one of the",
    "start": "3233400",
    "end": "3238799"
  },
  {
    "text": "models that are trained on Norwegian is called nbat so we tested the nbat token",
    "start": "3238799",
    "end": "3244400"
  },
  {
    "text": "to see how it was different and there is actually huge difference so when you use",
    "start": "3244400",
    "end": "3251240"
  },
  {
    "text": "notat that is trained on Norwegian text you can see that it tokenizes the text",
    "start": "3251240",
    "end": "3256480"
  },
  {
    "text": "the same way gp4 tokenizes English and if we paste the English version you can",
    "start": "3256480",
    "end": "3262480"
  },
  {
    "text": "see that it tokenizes the same way as gp4 did with the Norwegian Tech",
    "start": "3262480",
    "end": "3267799"
  },
  {
    "text": "so you can see that it actually makes a difference so here you can see some of",
    "start": "3267799",
    "end": "3274160"
  },
  {
    "text": "the benefits of working with a a model trained on your specific language but",
    "start": "3274160",
    "end": "3280440"
  },
  {
    "text": "what about domain are there also um gains to be made from having a domain",
    "start": "3280440",
    "end": "3286920"
  },
  {
    "text": "specific model that's what we're testing with planb so planb is our own embedding",
    "start": "3286920",
    "end": "3294400"
  },
  {
    "text": "model and it's a part of henrik's PhD project and he has taken the NB model",
    "start": "3294400",
    "end": "3301119"
  },
  {
    "text": "and fine-tuned it on a plant specific data from data from zonal",
    "start": "3301119",
    "end": "3307720"
  },
  {
    "text": "plans so he has trained on 70,000 region zonal plans which is a lot of text but",
    "start": "3307720",
    "end": "3314160"
  },
  {
    "text": "with these models it's more the more the better so he wanted to produce even more",
    "start": "3314160",
    "end": "3320520"
  },
  {
    "text": "text to use for training so what he also did was that he created 150,000",
    "start": "3320520",
    "end": "3325839"
  },
  {
    "text": "synthetic generated questions and the goal of this is to create even more data that also talks",
    "start": "3325839",
    "end": "3333760"
  },
  {
    "text": "about the domain within the zal plans so how can you do this well you can ask an llm to generate those questions for you",
    "start": "3333760",
    "end": "3342039"
  },
  {
    "text": "by looking at chunks of text from the sonal plans and ask it to create questions based on the content in those",
    "start": "3342039",
    "end": "3348640"
  },
  {
    "text": "chunks so let's look at the prompt he has asked LM to to do this given the",
    "start": "3348640",
    "end": "3355559"
  },
  {
    "text": "following instructions generate a question that can be answered only by the following reference",
    "start": "3355559",
    "end": "3360880"
  },
  {
    "text": "text and then he has to specify that the model should answer in Norwegian and the",
    "start": "3360880",
    "end": "3366359"
  },
  {
    "text": "llms aren't always that good at taking instructions so he also specifies do not",
    "start": "3366359",
    "end": "3371760"
  },
  {
    "text": "answer in English and then some more tips do not ask when documents were created or",
    "start": "3371760",
    "end": "3377960"
  },
  {
    "text": "updated that's not what we're interested in do not ask about the author of the text and remove all the necessary",
    "start": "3377960",
    "end": "3385079"
  },
  {
    "text": "details this is to avoid the bot splaining that Mel mentioned where the model just adds a lot of extra extra",
    "start": "3385079",
    "end": "3394119"
  },
  {
    "text": "text so by prompting this you can then add a chunk of text from a sonal plan",
    "start": "3394119",
    "end": "3400160"
  },
  {
    "text": "and get a question based on the content for from that zal plan so here are some translated examples of synthetically",
    "start": "3400160",
    "end": "3407079"
  },
  {
    "text": "created data what must be approved before a building permit is granted what type of roof is required for houses in",
    "start": "3407079",
    "end": "3413480"
  },
  {
    "text": "residential area B10 and so on so you can see that these uh synthetically",
    "start": "3413480",
    "end": "3418760"
  },
  {
    "text": "generated questions actually relate to zal plans so how does this work this is very",
    "start": "3418760",
    "end": "3428119"
  },
  {
    "text": "early work he has only been working with this model for a couple of months but so far it looks",
    "start": "3428119",
    "end": "3434760"
  },
  {
    "text": "promising so we have two different data sets and uh plb actually outperforms the",
    "start": "3434760",
    "end": "3441319"
  },
  {
    "text": "Ada model on one of our data sets and on the second one it's pretty close so so",
    "start": "3441319",
    "end": "3446400"
  },
  {
    "text": "the mdcg score I won't go into detail on how it works but one is the top score and zero is is the lowest but the point",
    "start": "3446400",
    "end": "3455400"
  },
  {
    "text": "here is that uh creating this embedding model with the text from the sonal plans",
    "start": "3455400",
    "end": "3461440"
  },
  {
    "text": "and also having a Norwegian embedding model seems to be working",
    "start": "3461440",
    "end": "3467559"
  },
  {
    "text": "better okay so last we would just like to share a little bit about our Tech",
    "start": "3467720",
    "end": "3473799"
  },
  {
    "text": "stack so everything is written in Python we use flask and gunicorn for our API we",
    "start": "3473799",
    "end": "3481400"
  },
  {
    "text": "use Docker and both for hosting our system but also for developing with the",
    "start": "3481400",
    "end": "3487200"
  },
  {
    "text": "dev containers in Visual Studio code which is very useful especially when you want to test different llms and you need",
    "start": "3487200",
    "end": "3494240"
  },
  {
    "text": "the different hardware and we use Asher to host",
    "start": "3494240",
    "end": "3499599"
  },
  {
    "text": "everything and then lastly we use a library called Lang chain and this is a",
    "start": "3499599",
    "end": "3505240"
  },
  {
    "text": "python library that that is very um very popular when working with LMS it has a",
    "start": "3505240",
    "end": "3510559"
  },
  {
    "text": "lot of tooling and it makes it really easy to inst instantiate different types of llms either an Asher open AI model or",
    "start": "3510559",
    "end": "3518680"
  },
  {
    "text": "a model from hagging face okay so what",
    "start": "3518680",
    "end": "3524280"
  },
  {
    "text": "now well we're at the stage where we where where we are continuously improving our system and using the",
    "start": "3524280",
    "end": "3531280"
  },
  {
    "text": "evaluation system to figure out how we can tweak it so that it will uh get even",
    "start": "3531280",
    "end": "3537280"
  },
  {
    "text": "better and we are also in the St in the phase of having pilot users so we have three different architectural firms that",
    "start": "3537280",
    "end": "3544240"
  },
  {
    "text": "are testing planat and seeing how it works and we have also implemented a version of it into a different system",
    "start": "3544240",
    "end": "3551400"
  },
  {
    "text": "that allows the municipalities to also test the system to see how the system",
    "start": "3551400",
    "end": "3556520"
  },
  {
    "text": "works for their um their zal plans and maybe they'll also realize that the",
    "start": "3556520",
    "end": "3561720"
  },
  {
    "text": "crazy tables aren't such a good idea we have also been talking a lot about",
    "start": "3561720",
    "end": "3568559"
  },
  {
    "text": "different user faces because does it have to be a chatbot there are so many chatbots",
    "start": "3568559",
    "end": "3574680"
  },
  {
    "text": "appearing everywhere now not everyone are fans of them but there are different",
    "start": "3574680",
    "end": "3580000"
  },
  {
    "text": "ways that we could have created the system the chatut is the first version but we could have also extracted",
    "start": "3580000",
    "end": "3586240"
  },
  {
    "text": "information that we know that the user most likely want and then presented it in for example a",
    "start": "3586240",
    "end": "3592280"
  },
  {
    "text": "table but there are so many different ways that we that we can use a system",
    "start": "3592280",
    "end": "3597920"
  },
  {
    "text": "like this to extract information from these documents that the user",
    "start": "3597920",
    "end": "3603200"
  },
  {
    "text": "wants so during development of this project we have had a running J that",
    "start": "3603200",
    "end": "3608680"
  },
  {
    "text": "that planat is just a faster way to get the wrong answer so if you read all of",
    "start": "3608680",
    "end": "3614599"
  },
  {
    "text": "these documents you're not going to get the right answer anyway you're just going to end up like Penny really frustrated so now at least you can get",
    "start": "3614599",
    "end": "3621559"
  },
  {
    "text": "the answer really fast but of course our mission is to create a system where we can say that",
    "start": "3621559",
    "end": "3627760"
  },
  {
    "text": "plant brat is a faster way to com to a complete and correct building",
    "start": "3627760",
    "end": "3633039"
  },
  {
    "text": "application thanks for listening [Applause]",
    "start": "3633039",
    "end": "3645889"
  }
]
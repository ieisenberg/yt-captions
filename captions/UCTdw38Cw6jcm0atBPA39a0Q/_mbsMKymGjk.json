[
  {
    "text": "um thank you for coming i'm glad i've got some faces in here i know i'm competing with steve sanderson and john skeet so anyone in this room is good and",
    "start": "4560",
    "end": "12160"
  },
  {
    "text": "hopefully some people online as well my name's steve i'm a microsoft mvp",
    "start": "12160",
    "end": "17440"
  },
  {
    "text": "pluralsight author and engineer at elastic i work on the language clients team at elastic",
    "start": "17440",
    "end": "24080"
  },
  {
    "text": "and that might give you a clue as to why i've chosen this title for this session a little bit about the title just to",
    "start": "24080",
    "end": "29679"
  },
  {
    "text": "make sure everyone's expectations are correct this is an introductory level talk so if you've used elasticsearch",
    "start": "29679",
    "end": "36239"
  },
  {
    "text": "much uh you probably know a lot or some of this stuff but hopefully it will also be a good recap",
    "start": "36239",
    "end": "42719"
  },
  {
    "text": "of some technology that you've already heard about and then we'll move more towards the latter half of the session",
    "start": "42719",
    "end": "47840"
  },
  {
    "text": "to talk about uh the net client and working with elasticsearch.net so um",
    "start": "47840",
    "end": "53520"
  },
  {
    "text": "so that's that's kind of the plan but if it is too introductory for you i won't be offended if you decide to kind of find somewhere else to go",
    "start": "53520",
    "end": "60079"
  },
  {
    "text": "um the other important thing is there is a bitly link there um everyone wants to slide after the session i've got like a",
    "start": "60079",
    "end": "65119"
  },
  {
    "text": "resources link at the end in the slides that link takes you to the slide deck so grab that link and you'll have access to",
    "start": "65119",
    "end": "71119"
  },
  {
    "text": "all of the resources and all of the information that i'm going to cover in the session today um it's a",
    "start": "71119",
    "end": "77680"
  },
  {
    "text": "three-day conference so if you have any questions that you don't get answered in this session or after this session come",
    "start": "77680",
    "end": "83360"
  },
  {
    "text": "and find me over any of the three days at the event i'll be happy to talk about elasticsearch and the.net",
    "start": "83360",
    "end": "88720"
  },
  {
    "text": "client with you um i'm very keen for that but if you if you think of something later",
    "start": "88720",
    "end": "93840"
  },
  {
    "text": "you can reach out to me i'm on twitter steve j gordon and you can follow my blog as well where",
    "start": "93840",
    "end": "98960"
  },
  {
    "text": "i hope to kind of get that going again with more posts about uh elasticsearch and using the.net client",
    "start": "98960",
    "end": "105119"
  },
  {
    "text": "so with that let's dive straight in i'm not a marketing person but i do have a marketing looking slide that i stole out",
    "start": "105119",
    "end": "110240"
  },
  {
    "text": "of our corporate slide deck um but it's a good intro to who we are as a company so you know how many people in this room",
    "start": "110240",
    "end": "116399"
  },
  {
    "text": "have actually heard of elastic already most nearly everyone that's good it means my work here is really easy you",
    "start": "116399",
    "end": "122960"
  },
  {
    "text": "probably know then that you know we primarily do stuff around search that's what people know us for",
    "start": "122960",
    "end": "128479"
  },
  {
    "text": "we build search solutions on top of a single stack so what does that mean well we have the course stack that i'm going",
    "start": "128479",
    "end": "134319"
  },
  {
    "text": "to introduce to you in a moment but we also use that stack ourselves to develop products and solutions that you can use",
    "start": "134319",
    "end": "140959"
  },
  {
    "text": "for search-based activities within your organizations as well so one of those is enterprise search enterprise search",
    "start": "140959",
    "end": "147599"
  },
  {
    "text": "gives you various capabilities one of the things you could do is point at a website or an application and have it",
    "start": "147599",
    "end": "152800"
  },
  {
    "text": "crawl that site gather data that you can then expose through a search box on that website so it might be good if you're",
    "start": "152800",
    "end": "158480"
  },
  {
    "text": "running a blog for example you could point elasticsearch at that you can also use it for sorting and",
    "start": "158480",
    "end": "164959"
  },
  {
    "text": "searching data within your organization so everyone has huge disparate amounts of data now we have stuff in github we",
    "start": "164959",
    "end": "170400"
  },
  {
    "text": "have stuff over in a wiki we have stuff on google docs and slack and finding that information knowing where to look",
    "start": "170400",
    "end": "176319"
  },
  {
    "text": "for the answer to a question you might have internally can always be tough enterprise search allows you to call all of those sources for that information",
    "start": "176319",
    "end": "182720"
  },
  {
    "text": "index it and make it searchable in your organization and we use that internally and it proves really useful i'm tracking",
    "start": "182720",
    "end": "187920"
  },
  {
    "text": "stuff down and i find someone slacked a message about that in the past and i get the answer that i'm looking for",
    "start": "187920",
    "end": "193360"
  },
  {
    "text": "we also do stuff around observability everyone is sort of building more and more sort of distributed systems",
    "start": "193360",
    "end": "199360"
  },
  {
    "text": "cloud-based solutions and services observability is really important in those scenarios to understand how things",
    "start": "199360",
    "end": "205360"
  },
  {
    "text": "are working if they're working and if they're working normally and we have various products and technologies within",
    "start": "205360",
    "end": "211360"
  },
  {
    "text": "that solution space for observability uh so we have apm that you can install into various platforms to gather data about",
    "start": "211360",
    "end": "217519"
  },
  {
    "text": "your applications how they're running uh we also have the capability to expose that to you in dashboards through kibana",
    "start": "217519",
    "end": "224239"
  },
  {
    "text": "and build alerting and tooling around that and you can even combine that with our ml technologies to start having",
    "start": "224239",
    "end": "230080"
  },
  {
    "text": "alerts that are a bit more intelligent and are actually looking for true outliers in your data rather than just fixed levels that may or may not alert",
    "start": "230080",
    "end": "236640"
  },
  {
    "text": "incorrectly for you and then finally we have some stuff around security again security is another big topic in organizations how",
    "start": "236640",
    "end": "242799"
  },
  {
    "text": "do we secure our environments how do we understand if they're secure and where are the risks our security solutions can",
    "start": "242799",
    "end": "248959"
  },
  {
    "text": "uh detect threats within your organization detect those potential uh attacks that may be happening and help",
    "start": "248959",
    "end": "254480"
  },
  {
    "text": "you mitigate against them so that's some of the stuff we do you can check out our website for a lot more information on all of that",
    "start": "254480",
    "end": "260320"
  },
  {
    "text": "today i'm going to be focused on one small part of our stack really which is elasticsearch but it is the heart of the",
    "start": "260320",
    "end": "265840"
  },
  {
    "text": "stack pretty much everything links into elasticsearch in some way or another",
    "start": "265840",
    "end": "270880"
  },
  {
    "text": "it's the data store fundamentally where all of your data is going to get stored it's going to be indexed and it's going",
    "start": "270880",
    "end": "276320"
  },
  {
    "text": "to be made searchable so this is where we're going to do all of the search and allow analysis of our data",
    "start": "276320",
    "end": "281360"
  },
  {
    "text": "and elasticsearch is kind of where the company began but we've evolved over the last sort of number of years to build",
    "start": "281360",
    "end": "287919"
  },
  {
    "text": "out much bigger stack that makes it a lot easier to utilize elasticsearch for the things you",
    "start": "287919",
    "end": "293360"
  },
  {
    "text": "may be building and one of the tools that we have is kibana this is our ui layer",
    "start": "293360",
    "end": "298560"
  },
  {
    "text": "this gives you the capability to not only manage your elastic search cluster so actually do you know your configuration setting up users that kind",
    "start": "298560",
    "end": "305199"
  },
  {
    "text": "of operational type management but it also gives you the ability to visualize the data that's stored in those clusters",
    "start": "305199",
    "end": "312800"
  },
  {
    "text": "and so you can build dashboards you can build reporting tools for internal or external customers that you may need to",
    "start": "312800",
    "end": "318240"
  },
  {
    "text": "be able to show people to see how things are operating in your business we used it quite extensively in my old job just",
    "start": "318240",
    "end": "324400"
  },
  {
    "text": "as part of our sort of platform monitoring system that we were able to sort of see how all of our services were",
    "start": "324400",
    "end": "330000"
  },
  {
    "text": "performing and if any of the servers looked like they were getting unexpected loads that kind of thing",
    "start": "330000",
    "end": "335360"
  },
  {
    "text": "we also need to get data into elasticsearch and elasticsearch has an api and we'll be talking more about",
    "start": "335360",
    "end": "340560"
  },
  {
    "text": "using the.net client to interact with that api in a bit but sometimes you know you have common data sources within your",
    "start": "340560",
    "end": "347039"
  },
  {
    "text": "organization that you want to use as as sources for data that's going into elasticsearch and we have a number of",
    "start": "347039",
    "end": "352880"
  },
  {
    "text": "products as part of our stack that help you with that the most recent i guess of those is elastic agent and it's",
    "start": "352880",
    "end": "358960"
  },
  {
    "text": "typically the one you should sort of start looking at first where you can install this agent on servers services",
    "start": "358960",
    "end": "364960"
  },
  {
    "text": "and and various devices around your organization and connect it into our fleet server so that you can then start",
    "start": "364960",
    "end": "370560"
  },
  {
    "text": "managing your fleet of servers in terms of how you want to collect data from them so you can set up",
    "start": "370560",
    "end": "375919"
  },
  {
    "text": "profiles to gather various log data or metric data off those systems before agent we had beats which is a",
    "start": "375919",
    "end": "382400"
  },
  {
    "text": "very similar concept but you needed to install specific beats on each server instance where you needed to collect",
    "start": "382400",
    "end": "387840"
  },
  {
    "text": "certain types of data maybe metrics or audit data each of these was an independent installation",
    "start": "387840",
    "end": "393039"
  },
  {
    "text": "elastic agent makes that easier by kind of essentially giving you a central management point for doing all of that configuration",
    "start": "393039",
    "end": "399120"
  },
  {
    "text": "and then finally we have logsdash which is as the name may suggest about log data",
    "start": "399120",
    "end": "404479"
  },
  {
    "text": "typically with this you would point at a directory that contains or will contain some log data and have it scrape that",
    "start": "404479",
    "end": "409919"
  },
  {
    "text": "data parse it process it and store it into elasticsearch for you so we have a number of those kind of pipelines for",
    "start": "409919",
    "end": "416400"
  },
  {
    "text": "common log file formats today but it's also extremely extensible and configurable if you want to build your",
    "start": "416400",
    "end": "421680"
  },
  {
    "text": "own pipelines for your own specific log data you can determine how that data gets processed split apart which pieces",
    "start": "421680",
    "end": "427840"
  },
  {
    "text": "of that information you care about storing do some kind of enrichment so if you've got ip data in there you may do gip",
    "start": "427840",
    "end": "434000"
  },
  {
    "text": "lookups as part of your ingestion pipeline and then bringing that all into elasticsearch",
    "start": "434000",
    "end": "439440"
  },
  {
    "text": "so this is the kind of core stack this is what our solutions are built on top of and what you can build your solutions",
    "start": "439440",
    "end": "445680"
  },
  {
    "text": "on top of as well in terms of where you can and how you can run this",
    "start": "445680",
    "end": "451199"
  },
  {
    "text": "today the best choice if you're kind of getting started and you're new to this will be usually elastic cloud this is",
    "start": "451199",
    "end": "456400"
  },
  {
    "text": "our software as a service offering and it gives you the ability to spin up a deployment of elasticsearch you know at",
    "start": "456400",
    "end": "462000"
  },
  {
    "text": "the few clicks of a button and it gives you the ability to manage that deployment with very little sort of",
    "start": "462000",
    "end": "467919"
  },
  {
    "text": "overhead really we do all of the hard work of making sure everything's spun up and configured correctly and secured and",
    "start": "467919",
    "end": "474240"
  },
  {
    "text": "talking to one another and you can really focus on how much data do i need to store what sort of scale am i looking",
    "start": "474240",
    "end": "479440"
  },
  {
    "text": "to start with and and then just getting started with it i use it quite often just for prototyping things um you know just",
    "start": "479440",
    "end": "486800"
  },
  {
    "text": "testing out ideas testing out things i'm going to be able to put into the client that kind of thing and it's a really good way of doing that",
    "start": "486800",
    "end": "492160"
  },
  {
    "text": "with as i say very little overhead we also have on-prem you may be in an organization that can't",
    "start": "492160",
    "end": "499360"
  },
  {
    "text": "or doesn't want to use cloud that's fine we have on-prem offerings for that we can offer elastic cloud",
    "start": "499360",
    "end": "506080"
  },
  {
    "text": "enterprise which is essentially the elastic cloud ui and management plane but in your own environment which is",
    "start": "506080",
    "end": "512080"
  },
  {
    "text": "quite nice it means you get sort of the best of both worlds if you're in that situation where you're not allowed to put data into the cloud",
    "start": "512080",
    "end": "518159"
  },
  {
    "text": "you can use that similarly if you're in a sort of containerized environment and heavy into sort of kubernetes and things",
    "start": "518159",
    "end": "523599"
  },
  {
    "text": "you can get started with elastic cloud and kubernetes as well the final option which is the kind of i",
    "start": "523599",
    "end": "528720"
  },
  {
    "text": "want to do everything myself mode is standalone and you're now fully responsible for installing your elastic",
    "start": "528720",
    "end": "534480"
  },
  {
    "text": "search instances onto servers or vms or however you want to get those up and running maybe even docker",
    "start": "534480",
    "end": "541200"
  },
  {
    "text": "but you're then responsible for making sure that stuff works works reliably and is configured correctly to be secure and",
    "start": "541200",
    "end": "546959"
  },
  {
    "text": "all of that kind of stuff so it's it's kind of the option you probably don't want to go to first today because you",
    "start": "546959",
    "end": "552160"
  },
  {
    "text": "know there's a lot of things you have to think about and by going towards the cloud end of this most of it is just sliders and choices around scaling that",
    "start": "552160",
    "end": "558959"
  },
  {
    "text": "you need to deal with it's also important to mention as well i miss miss saying that elastic cloud is",
    "start": "558959",
    "end": "564800"
  },
  {
    "text": "available in all of the major cloud providers so while you access it through our cloud sort of platform you can determine where",
    "start": "564800",
    "end": "570800"
  },
  {
    "text": "your deployments exist it might be azure google cloud aws means you can put your you know your",
    "start": "570800",
    "end": "576160"
  },
  {
    "text": "data services near where the rest of your application stuff may be running in a cloud already",
    "start": "576160",
    "end": "582240"
  },
  {
    "text": "so let's start with you know the real intro to elasticsearch and some of the basic um terminology and we'll sort of",
    "start": "582240",
    "end": "588160"
  },
  {
    "text": "start to ramp up into the deeper layers of this as we go so the first term i've used it a few",
    "start": "588160",
    "end": "593680"
  },
  {
    "text": "times already is cluster a cluster is really simply a collection of servers or really elastic search",
    "start": "593680",
    "end": "600080"
  },
  {
    "text": "instances is the thing to think about so the cluster is the way you group the logically",
    "start": "600080",
    "end": "605680"
  },
  {
    "text": "your sort of data environment together and through that all of your data is stored and all of the federated indexing",
    "start": "605680",
    "end": "613279"
  },
  {
    "text": "and searching capabilities happen so it's really more of a logical concept there are some configuration options",
    "start": "613279",
    "end": "618480"
  },
  {
    "text": "that you will configure that would be cluster-wide but mostly it's about choosing a cluster name that you want",
    "start": "618480",
    "end": "623760"
  },
  {
    "text": "your servers to join into and start working as a distributed data store",
    "start": "623760",
    "end": "629200"
  },
  {
    "text": "in terms of how that looks we have nodes and those are really just an instance of elastic",
    "start": "629200",
    "end": "634720"
  },
  {
    "text": "search so it might be a physical server it might be a vm could be a container",
    "start": "634720",
    "end": "640000"
  },
  {
    "text": "ultimately it is just that installation of elasticsearch that's going to be working together with the other nodes",
    "start": "640000",
    "end": "645120"
  },
  {
    "text": "within the system to be able to provide the services that you need from elasticsearch and how you set this up um depends on",
    "start": "645120",
    "end": "653040"
  },
  {
    "text": "your needs within your organization you can run a one node cluster uh don't do it in production",
    "start": "653040",
    "end": "658320"
  },
  {
    "text": "but you can do it when you're developing just to kind of get started and experiment with things often in cloud i'll you know spin up just a single node",
    "start": "658320",
    "end": "665120"
  },
  {
    "text": "thinking the cloud i'm going to use one today for the later demos so you can do that just to get started you",
    "start": "665120",
    "end": "670240"
  },
  {
    "text": "don't need to have the full capacity but obviously as your system moves towards production you need to start thinking about how's this thing going to scale",
    "start": "670240",
    "end": "676800"
  },
  {
    "text": "how is it going to be resilient to faults and that kind of thing and so a minimum of three nodes is kind of where you want to get to as a an",
    "start": "676800",
    "end": "683519"
  },
  {
    "text": "entry-level cluster when i worked for my previous company we had what i thought at the time was quite",
    "start": "683519",
    "end": "689760"
  },
  {
    "text": "a big cluster we had about 35 nodes and we were quite impressed that we had terabytes of data and 7 million documents a day since joining alaska",
    "start": "689760",
    "end": "696320"
  },
  {
    "text": "i've learned that we were barely touching the the tip of the iceberg in terms of pure scale of this thing",
    "start": "696320",
    "end": "701920"
  },
  {
    "text": "there's people running you know hundreds hundreds maybe thousands of nodes together to get really large volumes of data indexed and",
    "start": "701920",
    "end": "708560"
  },
  {
    "text": "searched in their environments the main thing about the nodes is by default they configured they are configured to kind",
    "start": "708560",
    "end": "714480"
  },
  {
    "text": "of start up in essentially multi a multi-role situation they'll do pretty much anything as part of their operation",
    "start": "714480",
    "end": "720560"
  },
  {
    "text": "within the cluster but as you as you move towards production and you get a feel for what your cluster's actually needing to do in terms of",
    "start": "720560",
    "end": "726800"
  },
  {
    "text": "operations that you'll have will be happening you may start to determine specific roles for specific nodes and",
    "start": "726800",
    "end": "732880"
  },
  {
    "text": "also start splitting those roles against more appropriate hardware types for those roles so for example data nodes",
    "start": "732880",
    "end": "739040"
  },
  {
    "text": "will need a lot of disk capacity to store the physical data that's part of the index that you're storing there and",
    "start": "739040",
    "end": "744959"
  },
  {
    "text": "they generally need quite a good amount of memory uh high performance memory for the in-memory data structures that are",
    "start": "744959",
    "end": "750720"
  },
  {
    "text": "needed to provide the search capabilities very quickly other nodes that are about sort of maintaining the cluster state and",
    "start": "750720",
    "end": "756959"
  },
  {
    "text": "maintaining how the clusters operating are called master nodes and you really only need",
    "start": "756959",
    "end": "762000"
  },
  {
    "text": "basic machines as master eligible nodes so typically once you get past a certain size you'll start to have dedicated",
    "start": "762000",
    "end": "768000"
  },
  {
    "text": "masternodes that are purely about keeping the cluster alive and not about storing data or performing search or",
    "start": "768000",
    "end": "773440"
  },
  {
    "text": "index capabilities similarly if you want to use our machine learning technologies within the cluster",
    "start": "773440",
    "end": "779360"
  },
  {
    "text": "we typically would expect you to have machine learning dedicated nodes just for performing those functions and",
    "start": "779360",
    "end": "784800"
  },
  {
    "text": "they may have higher cpu loads again higher memory loads so you might want to choose appropriate hardware for",
    "start": "784800",
    "end": "791040"
  },
  {
    "text": "those types of jobs this isn't something you have to determine right up front you can start with this kind of a free node",
    "start": "791040",
    "end": "797839"
  },
  {
    "text": "cluster with all the roles and then as you kind of understand the data you're dealing with and understand your",
    "start": "797839",
    "end": "803440"
  },
  {
    "text": "environment that's when you start adding nodes to the cluster and giving them different roles just through configuration",
    "start": "803440",
    "end": "810399"
  },
  {
    "text": "then we have the concept of an index index is one of those terms that's kind of a bit overloaded it's a noun it's a",
    "start": "810480",
    "end": "815760"
  },
  {
    "text": "verb but in this case it's the noun the object which is really just a collection of documents",
    "start": "815760",
    "end": "821040"
  },
  {
    "text": "logically within your your data store and often questions come in from like how how should i determine what should",
    "start": "821040",
    "end": "827519"
  },
  {
    "text": "go into what index and and what's my strategy and the answer is it really does depend on your data",
    "start": "827519",
    "end": "832959"
  },
  {
    "text": "if you are for example running a blog website and you just want to provide a search capability across that then you",
    "start": "832959",
    "end": "838480"
  },
  {
    "text": "can have a single index that contains all of the blog posts as data objects that you want to be able to search",
    "start": "838480",
    "end": "844000"
  },
  {
    "text": "across and that's relatively finite data even on a large blog we're talking thousands of documents probably at most",
    "start": "844000",
    "end": "850560"
  },
  {
    "text": "but sometimes we have data that isn't really finite as such so log data would be a great example this data is going to",
    "start": "850560",
    "end": "856800"
  },
  {
    "text": "be continually coming in from applications and servers over time and typically what you do in that scenario",
    "start": "856800",
    "end": "861839"
  },
  {
    "text": "is you start to move towards a strategy where you have indexes created in in sort of buckets so you",
    "start": "861839",
    "end": "868160"
  },
  {
    "text": "might have weekly indexes for storing that data as time goes on and you'll notice i always forget to be",
    "start": "868160",
    "end": "873519"
  },
  {
    "text": "it's like indices and indexes it doesn't really matter i use both but you can spread that data across",
    "start": "873519",
    "end": "880720"
  },
  {
    "text": "as time goes on so typically by doing that it gives you more capability for determining how that data is backed up",
    "start": "880720",
    "end": "886720"
  },
  {
    "text": "and also how you store it maybe on colder less high-powered hardware over time because",
    "start": "886720",
    "end": "893440"
  },
  {
    "text": "typically index data you want to be able to search over the immediate last maybe few days of data very quickly but most",
    "start": "893440",
    "end": "900079"
  },
  {
    "text": "of your year old data may be needed needed for sort of regulatory reasons or auditing reasons but you typically",
    "start": "900079",
    "end": "906160"
  },
  {
    "text": "aren't doing hot searches across that data all the time and so you can have strategies where through our index life",
    "start": "906160",
    "end": "912240"
  },
  {
    "text": "cycle management policies you can configure data to move through a life cycle where it goes on to older and",
    "start": "912240",
    "end": "918639"
  },
  {
    "text": "older nodes which are basically cheaper hardware for you to the point where you can even have data stored in blob stores",
    "start": "918639",
    "end": "924800"
  },
  {
    "text": "as searchable snapshots where you can actually search across it it's going to be slower but it's going to be a lot cheaper and so you can start to think",
    "start": "924800",
    "end": "931440"
  },
  {
    "text": "about these strategies as time goes on i won't be talking about them today but most of that's done for a technology called data streams where you configure",
    "start": "931440",
    "end": "937600"
  },
  {
    "text": "a stream of data and it handles configuring a policy behind the scenes for you that will roll that data over to",
    "start": "937600",
    "end": "943360"
  },
  {
    "text": "indexes over time within an index we have shards and chart is just you know common",
    "start": "943360",
    "end": "950000"
  },
  {
    "text": "term in distributed databases how are we going to separate this data so that we can spread the load",
    "start": "950000",
    "end": "955839"
  },
  {
    "text": "across multiple systems and so in this case let's take this example at the moment where this first index of hours",
    "start": "955839",
    "end": "962160"
  },
  {
    "text": "we've configured with a single primary shard so there are a few problems with this there are a few things we need to",
    "start": "962160",
    "end": "967199"
  },
  {
    "text": "think about as engineers but the first thing is imagine this is our main index that we this is why we",
    "start": "967199",
    "end": "972480"
  },
  {
    "text": "have a cluster we've got three nodes and we've set it up but we're only creating a single shard of our data so this means",
    "start": "972480",
    "end": "977839"
  },
  {
    "text": "all of the data for that index lives on node one it also means all of the search and the index load is on node one uh",
    "start": "977839",
    "end": "984399"
  },
  {
    "text": "it's not a great use of the the other two nodes in our cluster which are essentially sitting there uh doing nothing",
    "start": "984399",
    "end": "990399"
  },
  {
    "text": "so one of the things we need to think about when we design how we're going to create our indexes in the system",
    "start": "990399",
    "end": "996399"
  },
  {
    "text": "is how do we want to shard that data and there's no fixed answer on this some of this is documented on our blog posts and",
    "start": "996399",
    "end": "1002959"
  },
  {
    "text": "our documentation that gives you some guidance but it really depends on your data loads how much ingestion will you",
    "start": "1002959",
    "end": "1009120"
  },
  {
    "text": "have how much search will you have how much overall data have you got as to what's the right number of shards",
    "start": "1009120",
    "end": "1014160"
  },
  {
    "text": "for your system and sometimes it is a case of trying different things again in my old job we started with a strategy i",
    "start": "1014160",
    "end": "1019839"
  },
  {
    "text": "think where we were on three charts for our each index and after time we realized if we",
    "start": "1019839",
    "end": "1026160"
  },
  {
    "text": "split that out into i think six jars we got better throughput overall and it was a kind of right balance",
    "start": "1026160",
    "end": "1031438"
  },
  {
    "text": "because there is a cost associated with sharding your data there's a management overhead and search may have to you know",
    "start": "1031439",
    "end": "1038079"
  },
  {
    "text": "split uh consolidate its data again afterwards so what we typically recommend is you have more than one",
    "start": "1038079",
    "end": "1044640"
  },
  {
    "text": "primary shard for your data and it's split across um some of your nodes you don't really care which nodes the",
    "start": "1044640",
    "end": "1050160"
  },
  {
    "text": "cluster and elasticsearch will configure itself to put shards for the best load balancing across the system",
    "start": "1050160",
    "end": "1056480"
  },
  {
    "text": "but in this case now we're in a situation where our data is now spread across the free nodes and this is done by just hashing the id essentially of",
    "start": "1056480",
    "end": "1063200"
  },
  {
    "text": "the documents as they come in and then that data lives on a particular node and it means that when we do a search",
    "start": "1063200",
    "end": "1069440"
  },
  {
    "text": "now across the entire index that search can be sent to each of the nodes each of them is collecting and gathering the",
    "start": "1069440",
    "end": "1074960"
  },
  {
    "text": "data that's the matches for that search and then it gets consolidated back together again at the end",
    "start": "1074960",
    "end": "1080799"
  },
  {
    "text": "now this situation is better from a point of view of getting a better load across our system we still have a resiliency issue here in",
    "start": "1080799",
    "end": "1087280"
  },
  {
    "text": "this design and we can resolve that by having replicas so as well as configuring the number of primaries we",
    "start": "1087280",
    "end": "1092400"
  },
  {
    "text": "want we can configure the number of replicas that we want as well in this case we said we want one replica which",
    "start": "1092400",
    "end": "1098480"
  },
  {
    "text": "means we want one replica of each primary hence we have three actual shards there that are showing up and the",
    "start": "1098480",
    "end": "1103760"
  },
  {
    "text": "key thing here is that elasticsearch is obviously going to try and put this in a sensible configuration that means that",
    "start": "1103760",
    "end": "1109440"
  },
  {
    "text": "we have resiliency so now nodes one node one has primary one and replica one is on node two and this means that we could",
    "start": "1109440",
    "end": "1116480"
  },
  {
    "text": "lose node one entirely and we'd be still in a situation where we can perform search initially and as",
    "start": "1116480",
    "end": "1122080"
  },
  {
    "text": "soon as the cluster detects that the health is no longer in a good state it can't reach node one and it needs to",
    "start": "1122080",
    "end": "1127360"
  },
  {
    "text": "figure out well what primaries node one and how do i promote the replicas so that we can get back to a state where",
    "start": "1127360",
    "end": "1133840"
  },
  {
    "text": "everything's healthy and we're able to take data back in and index it again so this configuration is important to",
    "start": "1133840",
    "end": "1140320"
  },
  {
    "text": "think about as you move towards production you will want at least one replica and you also want to think about your backup",
    "start": "1140320",
    "end": "1146880"
  },
  {
    "text": "strategy through snapshots as well but that's sort of a bit past what we're going to get into today",
    "start": "1146880",
    "end": "1154160"
  },
  {
    "text": "the final piece of basic terminology is a document and a document is a unit of",
    "start": "1154160",
    "end": "1160000"
  },
  {
    "text": "data really elasticsearch is a json-based document",
    "start": "1160000",
    "end": "1165039"
  },
  {
    "text": "store so you send a json object into the database that represents the data you want to have indexed in there",
    "start": "1165039",
    "end": "1171520"
  },
  {
    "text": "and that that actual source document will be stored by default as part of the record within elasticsearch",
    "start": "1171520",
    "end": "1178480"
  },
  {
    "text": "elasticsearch documents needs generally to have some related characteristics to make sense",
    "start": "1178480",
    "end": "1184720"
  },
  {
    "text": "putting them in the same index but each index is schemeless by design and so you",
    "start": "1184720",
    "end": "1190000"
  },
  {
    "text": "can send it any data that you want any structure and we will try and store it in that index but as i say if you're",
    "start": "1190000",
    "end": "1195280"
  },
  {
    "text": "going to be doing search across it some of those fields will need to be common in some way for it to make sense for you to put that together but it does mean",
    "start": "1195280",
    "end": "1201440"
  },
  {
    "text": "that you can evolve your data over time which is something that very much happens in businesses as they build out",
    "start": "1201440",
    "end": "1206799"
  },
  {
    "text": "applications as they understand their needs they start to add different fields to the data that they're starting to",
    "start": "1206799",
    "end": "1212000"
  },
  {
    "text": "store and over time that data might become more useful for the business going forward",
    "start": "1212000",
    "end": "1217120"
  },
  {
    "text": "so i said there's no set schema but we do have a concept called mapping and mapping is about determining and",
    "start": "1217120",
    "end": "1223360"
  },
  {
    "text": "guiding elastic search in how it actually stores the data into its various index data structures which is",
    "start": "1223360",
    "end": "1230799"
  },
  {
    "text": "how we're going to provide the search capability that you want so to kind of explain that a little bit more",
    "start": "1230799",
    "end": "1236000"
  },
  {
    "text": "if your json document comes in and it has something that looks like a text field on there",
    "start": "1236000",
    "end": "1241520"
  },
  {
    "text": "the good chance is that's going to be text data that you want to be able to search across but before elasticsearch",
    "start": "1241520",
    "end": "1246799"
  },
  {
    "text": "determines that it might do a little bit of parsing and go well does this thing actually conform to a known date time string if it does then if it looks like",
    "start": "1246799",
    "end": "1253919"
  },
  {
    "text": "a date we'll treat it as a date and this happens the first time a field is seen new field is seen for any document",
    "start": "1253919",
    "end": "1260240"
  },
  {
    "text": "elasticsearch will infer by default um a sort of an implicit mapping for that",
    "start": "1260240",
    "end": "1265679"
  },
  {
    "text": "field unless you've given it any other information so other types of mappings that you'll see is if it sees something that looks",
    "start": "1265679",
    "end": "1271280"
  },
  {
    "text": "like a number then it will choose one of the number field types to use for that and this is where you have to get a",
    "start": "1271280",
    "end": "1277520"
  },
  {
    "text": "little careful though this sort of implied mapping is fine but it it will make the best judgment based on the",
    "start": "1277520",
    "end": "1283120"
  },
  {
    "text": "first bit of data it sees so we'll see that a little bit in the demo when i talk about how i've chosen the mappings for that demo scenario but other things",
    "start": "1283120",
    "end": "1290320"
  },
  {
    "text": "that you're having there is obviously text this is going to be a key part of your search capability and one of the",
    "start": "1290320",
    "end": "1295360"
  },
  {
    "text": "reasons a lot of people will go to elasticsearch is for some form of full text search capability in their in their",
    "start": "1295360",
    "end": "1300400"
  },
  {
    "text": "environment search is an interesting thing across text because we actually index that data",
    "start": "1300400",
    "end": "1305520"
  },
  {
    "text": "in two ways by default we store it into what's called a text field which is what provides the full text",
    "start": "1305520",
    "end": "1312080"
  },
  {
    "text": "search capability so this is where the data is actually analyzed and tokenized so that the individual terms can be sort",
    "start": "1312080",
    "end": "1318960"
  },
  {
    "text": "of read from that and then used to store in the inverted index that's used for that very quick lookup between terms and",
    "start": "1318960",
    "end": "1325520"
  },
  {
    "text": "the documents that contain them so this process does a number of things as part of that sort of analysis and",
    "start": "1325520",
    "end": "1331919"
  },
  {
    "text": "tokenization things like punctuation are lost or removed from there stop words by default",
    "start": "1331919",
    "end": "1337760"
  },
  {
    "text": "will be removed so and the it's those kind of words are not going to be really useful in any kind of search so they're",
    "start": "1337760",
    "end": "1343120"
  },
  {
    "text": "stripped from the documents by default and typically all of those tokens will be lowercased as well that means you",
    "start": "1343120",
    "end": "1348640"
  },
  {
    "text": "know the search full text search is generally sort of case insensitive by default this is all configurable you can",
    "start": "1348640",
    "end": "1354400"
  },
  {
    "text": "configure which filters run for which fields and how you want to analyze the data as it comes through",
    "start": "1354400",
    "end": "1359440"
  },
  {
    "text": "but the default system is is the one that i've just described the other way that text data is stored",
    "start": "1359440",
    "end": "1364559"
  },
  {
    "text": "by default is into what's called a keyword field type as well and this is where the data is designed for kind of exact match scenarios",
    "start": "1364559",
    "end": "1371600"
  },
  {
    "text": "and so this is the best guess that elasticsearch can make if you've not provided any guidance it will give you",
    "start": "1371600",
    "end": "1377360"
  },
  {
    "text": "kind of both those options but each of those indexing structures has some overhead and it's typically unlikely",
    "start": "1377360",
    "end": "1383360"
  },
  {
    "text": "that you're going to need both for all field types so this is where explicit mapping comes in and you can",
    "start": "1383360",
    "end": "1388720"
  },
  {
    "text": "start to say for your index configuration that you want a particular mapping for particular fields and say",
    "start": "1388720",
    "end": "1394880"
  },
  {
    "text": "actually this thing that looks like a string is actually a version number or it's an ip address",
    "start": "1394880",
    "end": "1400000"
  },
  {
    "text": "these types of additional mappings give us additional capabilities in within elasticsearch because as soon as we know",
    "start": "1400000",
    "end": "1405360"
  },
  {
    "text": "a field type is of one of these special types we can treat it in such a way that for example with versions we can sort",
    "start": "1405360",
    "end": "1411360"
  },
  {
    "text": "them for you in simva order rather than just alphabetical order which may not always give you the results that you're",
    "start": "1411360",
    "end": "1417039"
  },
  {
    "text": "expecting similarly we support things like geodata so you can provide lat long data and",
    "start": "1417039",
    "end": "1422159"
  },
  {
    "text": "things like that and then you can perform geo-based searches over the data providing a central point and a radius",
    "start": "1422159",
    "end": "1427919"
  },
  {
    "text": "that you want to search for documents within or you can set a geo boundary around the area that you want to search",
    "start": "1427919",
    "end": "1433120"
  },
  {
    "text": "for and find records that fall into that zone so there's lots and lots of field types and and this is really about",
    "start": "1433120",
    "end": "1439200"
  },
  {
    "text": "understanding your data most people if they're kind of some prototyping something new they'll",
    "start": "1439200",
    "end": "1444400"
  },
  {
    "text": "start with the inferred mappings and just take what elasticsearch does out of the box and as they start to understand",
    "start": "1444400",
    "end": "1450080"
  },
  {
    "text": "their data both what's coming in and how people are going to be searching across it what the use cases are for that data",
    "start": "1450080",
    "end": "1456400"
  },
  {
    "text": "you might start to adjust your mappings over time now you can't necessarily change your mapping in an existing index",
    "start": "1456400",
    "end": "1461440"
  },
  {
    "text": "you have to do something called re-indexing you create a new index structure with a new mapping that defines exactly how you want this data",
    "start": "1461440",
    "end": "1467919"
  },
  {
    "text": "to be indexed and then just re-index the data through to it but this is how typically people will evolve data in",
    "start": "1467919",
    "end": "1473600"
  },
  {
    "text": "their businesses now all of elasticsearch is accessible through its http interface",
    "start": "1473600",
    "end": "1480400"
  },
  {
    "text": "and a lot of people will work with it that way but as i showed earlier we have kibana which is a ui system that",
    "start": "1480400",
    "end": "1486080"
  },
  {
    "text": "basically provides a ui layer and gives you access to do a lot of this capability directly in a ui but we'll be",
    "start": "1486080",
    "end": "1492480"
  },
  {
    "text": "thinking about the interface a bit more in a moment because we're talking about clients at the end of this session",
    "start": "1492480",
    "end": "1498720"
  },
  {
    "text": "just to give you a few numbers um there's now over 400 api endpoints in elasticsearch pretty much any of the",
    "start": "1498720",
    "end": "1504480"
  },
  {
    "text": "things that you can do with elasticsearch can be done through http and we expose apis for doing it so even",
    "start": "1504480",
    "end": "1511039"
  },
  {
    "text": "things like the ml capabilities for defining the jobs that can run for starting and stopping those ml jobs",
    "start": "1511039",
    "end": "1517679"
  },
  {
    "text": "all of that can be done through the api configuration of the cluster pretty much anything",
    "start": "1517679",
    "end": "1523520"
  },
  {
    "text": "which means there's a lot of data structures and there's a lot of types that are involved in that so we have over 50 distinct querying types um over",
    "start": "1523520",
    "end": "1531120"
  },
  {
    "text": "70 different types of aggregations so how do you want to group data and and analyze information in aggregate form",
    "start": "1531120",
    "end": "1537840"
  },
  {
    "text": "and and those different field types i talked about for defining fields explicitly that map to your data types",
    "start": "1537840",
    "end": "1543360"
  },
  {
    "text": "that you're sending in so there's a lot of a lot of parts of this api and keep that in mind when i come to",
    "start": "1543360",
    "end": "1549840"
  },
  {
    "text": "talking about the.net client in a moment so i work on the language clients team",
    "start": "1549840",
    "end": "1554880"
  },
  {
    "text": "there's about eight or nine of us and we maintain the language clients um these are the the main ones there are",
    "start": "1554880",
    "end": "1561440"
  },
  {
    "text": "others sort of subsets of these but these are the main ones and all of the sort of core languages are covered there and each client is designed to be",
    "start": "1561440",
    "end": "1568720"
  },
  {
    "text": "idiomatic to the language so java.net they're the most strongly typed clients",
    "start": "1568720",
    "end": "1574080"
  },
  {
    "text": "we provide classes that represent requests and responses so that you can work with your data in a pattern that",
    "start": "1574080",
    "end": "1580080"
  },
  {
    "text": "you're used to in other.net applications for example but for the other languages you know those are designed more in mind",
    "start": "1580080",
    "end": "1585600"
  },
  {
    "text": "with whichever sort of patterns are used and design patterns are needed for those languages",
    "start": "1585600",
    "end": "1591120"
  },
  {
    "text": "um and so you should find them sort of pretty compatible if you're working with any of those languages to things you've",
    "start": "1591120",
    "end": "1596240"
  },
  {
    "text": "seen elsewhere in them so in terms of existing clients",
    "start": "1596240",
    "end": "1602159"
  },
  {
    "text": "the existing.net client today is built of kind of two nuget packages",
    "start": "1602159",
    "end": "1607679"
  },
  {
    "text": "and this is in the 7x range so 717 is kind of the latest minor version of that",
    "start": "1607679",
    "end": "1613360"
  },
  {
    "text": "um and this is the client that's out there today and is publicly available you use it against the 17 uh 717 server",
    "start": "1613360",
    "end": "1620880"
  },
  {
    "text": "or 7x server but you can also use it against ato and that's quite important at the moment",
    "start": "1620880",
    "end": "1626240"
  },
  {
    "text": "because we haven't gade an ato client just yet um but we do have now an ato a kind of compatibility header that you",
    "start": "1626240",
    "end": "1632559"
  },
  {
    "text": "can send across that tells it what type of version of response you want so now the 717 client can be used against the nato",
    "start": "1632559",
    "end": "1639440"
  },
  {
    "text": "server as long as you enable that header so that the server knows to send you data in a particular format",
    "start": "1639440",
    "end": "1645600"
  },
  {
    "text": "and this client is built with two parts the elasticsearch.net library is our low-level client",
    "start": "1645600",
    "end": "1651120"
  },
  {
    "text": "and for probably 99 of people you shouldn't be using this you don't need to be using this directly",
    "start": "1651120",
    "end": "1657360"
  },
  {
    "text": "it is a very low level sort of abstraction over the top of essentially the transport functionality of talking",
    "start": "1657360",
    "end": "1663760"
  },
  {
    "text": "to elasticsearch and basic mappings between an endpoint name and a url really",
    "start": "1663760",
    "end": "1671440"
  },
  {
    "text": "and what this is is it's our kind of dependency free layer that's fairly unopinionated about sort of working as a",
    "start": "1671440",
    "end": "1677440"
  },
  {
    "text": "client and it really is focused on handling the transport functionality so when you configure your client you can",
    "start": "1677440",
    "end": "1682880"
  },
  {
    "text": "give it urls for all of the nodes that are available in your system and it can keep track of those it will round robin",
    "start": "1682880",
    "end": "1689440"
  },
  {
    "text": "requests to those and it will also identify if a node becomes unresponsive it will stop trying to send it requests for a period of time that kind of",
    "start": "1689440",
    "end": "1696000"
  },
  {
    "text": "transport layout functionality is inc sort of capitulated in there and it does have a basic form of request and",
    "start": "1696000",
    "end": "1702080"
  },
  {
    "text": "response but if you're going to be using it you need to pass it the actual json structures to send to the server and",
    "start": "1702080",
    "end": "1708000"
  },
  {
    "text": "that you're going to get back so that's usually either in byte or string form so that's why it's not really most",
    "start": "1708000",
    "end": "1713679"
  },
  {
    "text": "useful for most people it's more of a building block library and potentially a scenario if you're in",
    "start": "1713679",
    "end": "1718799"
  },
  {
    "text": "extremely high performance scenarios and you want a bit more control over allocations around json",
    "start": "1718799",
    "end": "1724799"
  },
  {
    "text": "to type mappings you might start using it for that but generally what you want to be using is nest",
    "start": "1724799",
    "end": "1730640"
  },
  {
    "text": "nest is the high level client and this is where the strongly typed nature of the client starts to come in",
    "start": "1730640",
    "end": "1736799"
  },
  {
    "text": "so we have mappings and types that represent all of the requests and responses for all of the",
    "start": "1736799",
    "end": "1742559"
  },
  {
    "text": "endpoints plus all of the subtypes of those that they then expose as well and as i talked about that's over 400",
    "start": "1742559",
    "end": "1749039"
  },
  {
    "text": "endpoints so that's already sort of 800 types just for requests and responses before you start getting into all those",
    "start": "1749039",
    "end": "1754240"
  },
  {
    "text": "nuanced data structures all of the different representations of an aggregation of the different fields that",
    "start": "1754240",
    "end": "1759600"
  },
  {
    "text": "can be configured and things like that we also expose a query dsl representation so elasticsearch has a",
    "start": "1759600",
    "end": "1765840"
  },
  {
    "text": "querying domain specific language that you use and we've modeled that as closely as we can to sort of how you",
    "start": "1765840",
    "end": "1771760"
  },
  {
    "text": "would like to work with this dsl through net it's not necessarily perfect but we",
    "start": "1771760",
    "end": "1777760"
  },
  {
    "text": "provide two patterns for for all of the types in.net uh for the high-level clients so we have the object",
    "start": "1777760",
    "end": "1784559"
  },
  {
    "text": "initializer pattern which is really you know create a new search request and set properties and then pass it to the",
    "start": "1784559",
    "end": "1790559"
  },
  {
    "text": "client and that might work quite nicely in some scenarios but as things get more complex and you build up these kind of",
    "start": "1790559",
    "end": "1796000"
  },
  {
    "text": "deeper and deeper queries all of this nested new object creation gets a little bit painful and so in that scenario we",
    "start": "1796000",
    "end": "1801760"
  },
  {
    "text": "also provide what we call the fluent syntax which gives you kind of this chain ability of method calls that you",
    "start": "1801760",
    "end": "1808159"
  },
  {
    "text": "can make to configure those components and we'll see what that looks like when i get to the code in a moment but these",
    "start": "1808159",
    "end": "1814000"
  },
  {
    "text": "are the two projects today they're you know extremely highly used as i say nest is the one that you want",
    "start": "1814000",
    "end": "1819679"
  },
  {
    "text": "to be picking up if you're kind of getting into this stuff brand new",
    "start": "1819679",
    "end": "1824480"
  },
  {
    "text": "so there are some problems with the existing client uh we've kind of identified that we we're starting to try",
    "start": "1826080",
    "end": "1831200"
  },
  {
    "text": "and work on solutions for the first thing is it's handwritten um",
    "start": "1831200",
    "end": "1836240"
  },
  {
    "text": "nearly all of it's hand written and what i mean by this is we have some basic code generation for the low-level client",
    "start": "1836240",
    "end": "1841760"
  },
  {
    "text": "that will be able to say given this the specification that exists in elasticsearch the repo we can kind of",
    "start": "1841760",
    "end": "1847760"
  },
  {
    "text": "create the endpoint to url mappings and the basic query string structures that a",
    "start": "1847760",
    "end": "1852799"
  },
  {
    "text": "request and response to that endpoint might take but all we can do after that is basically stub out the request and",
    "start": "1852799",
    "end": "1858480"
  },
  {
    "text": "response types as partial classes and then the maintainers myself come in and",
    "start": "1858480",
    "end": "1863840"
  },
  {
    "text": "we fill in the blanks and put in all of the properties that are available on those request response and have to model everything",
    "start": "1863840",
    "end": "1869840"
  },
  {
    "text": "and in the early days of elasticsearch when there were tens or hundreds of endpoints this wasn't too much of a problem but obviously that's a lot of",
    "start": "1869840",
    "end": "1876640"
  },
  {
    "text": "maintenance work as you start getting towards 400 endpoints that can all be evolving in each minor release of elasticsearch and so",
    "start": "1876640",
    "end": "1883440"
  },
  {
    "text": "that does mean that at times the api that's available in.net isn't always 100 consistent with the api of elasticsearch",
    "start": "1883440",
    "end": "1890640"
  },
  {
    "text": "so we might not have properties exposed on those requests and responses that you can set and send in the data over the",
    "start": "1890640",
    "end": "1897200"
  },
  {
    "text": "wire this is obviously a problem if you find one raise an issue and we'll get that in as soon as we can but it's a manual",
    "start": "1897200",
    "end": "1904080"
  },
  {
    "text": "piece of work and there is obviously gaps in terms of understanding what's exactly been done by the server team to",
    "start": "1904080",
    "end": "1910080"
  },
  {
    "text": "make sure it's in all of the clients the other thing about this existing client is we have an internalized version of",
    "start": "1910080",
    "end": "1916000"
  },
  {
    "text": "something called utf-8 json which we use for serialization and utf-8 json is a",
    "start": "1916000",
    "end": "1921600"
  },
  {
    "text": "kind of open source high level uh high performance i should say serializer that's generally about trying to be",
    "start": "1921600",
    "end": "1927679"
  },
  {
    "text": "quite low allocation and quite efficient but it's quite an old open source project that's kind of gone out of",
    "start": "1927679",
    "end": "1932840"
  },
  {
    "text": "maintenance so our copy actually lives inside our own code base we actually internalized that code",
    "start": "1932840",
    "end": "1938559"
  },
  {
    "text": "mainly because we needed some customizations to the to it that were very sort of elastic search type",
    "start": "1938559",
    "end": "1943840"
  },
  {
    "text": "specific because we have a lot of polymorphic types in in the requests and responses particularly around",
    "start": "1943840",
    "end": "1949200"
  },
  {
    "text": "aggregations and searching that are really hard to map and you generally need some quite low level ability to",
    "start": "1949200",
    "end": "1954559"
  },
  {
    "text": "write json code to be able to model those and serialize to and from them so that's the reason we've got it kind of",
    "start": "1954559",
    "end": "1960000"
  },
  {
    "text": "internalized and we've patched bits of it over time as we've found bugs with it it generally performs pretty well and",
    "start": "1960000",
    "end": "1966320"
  },
  {
    "text": "it's probably better than using something like newtonsoft json in terms of allocations and memory footprint",
    "start": "1966320",
    "end": "1972080"
  },
  {
    "text": "but it has some issues it's not perfect and we've definitely found areas where it over allocates and it doesn't",
    "start": "1972080",
    "end": "1977360"
  },
  {
    "text": "necessarily return memory as quickly as it should do there's a lot of maintenance in that code if we're going to carry it forward",
    "start": "1977360",
    "end": "1984320"
  },
  {
    "text": "and there's 10 years nearly of historical decisions that have gone into this library it came out very early when",
    "start": "1984320",
    "end": "1990080"
  },
  {
    "text": "elasticsearch was first available and it's evolved over time as elasticsearch has grown and",
    "start": "1990080",
    "end": "1995760"
  },
  {
    "text": "so it means the early decisions that were made around the structure of how some of this works were designed at the kind of tens or hundreds of apis that we",
    "start": "1995760",
    "end": "2003279"
  },
  {
    "text": "need to model uh kind of era and now we're at this point where we have hundreds of complex types that we have",
    "start": "2003279",
    "end": "2009039"
  },
  {
    "text": "to deal with and also nets evolved as a language the sort of patterns and the language features and",
    "start": "2009039",
    "end": "2014960"
  },
  {
    "text": "capabilities have changed in 10 years we've gone through the net core era as well um and so it would be nice if we",
    "start": "2014960",
    "end": "2020880"
  },
  {
    "text": "could start to take a little bit more advantage of that as where we can so these are some of the problems that when",
    "start": "2020880",
    "end": "2026000"
  },
  {
    "text": "i joined about a year and a half ago i kind of identified as things that maybe i'd like to look at and the team had",
    "start": "2026000",
    "end": "2031440"
  },
  {
    "text": "already got some of these in mind as well as things that are problematic and so i can introduce what we're",
    "start": "2031440",
    "end": "2037360"
  },
  {
    "text": "working on at the moment in terms of the ato climb which is the new the new elasticsearch.net package",
    "start": "2037360",
    "end": "2044080"
  },
  {
    "text": "so there's a few cool things uh it's a new name doesn't we don't call it nest anymore partly because i couldn't really work",
    "start": "2044080",
    "end": "2050158"
  },
  {
    "text": "out if nest meant anything to anyone that was outside of using it today it's not something you would first think to",
    "start": "2050159",
    "end": "2055280"
  },
  {
    "text": "search for if you're a brand new user to elasticsearch and you go okay well i'm doing.net i'm doing elasticsearch i need the client",
    "start": "2055280",
    "end": "2060800"
  },
  {
    "text": "you're probably not going to think to search the word nest um but that's not the main reason we've made this change i",
    "start": "2060800",
    "end": "2067118"
  },
  {
    "text": "also wanted to give it a new package an assembly name because of some of the stuff that we're doing that",
    "start": "2067119",
    "end": "2072240"
  },
  {
    "text": "means it is going to be a fairly big break um historically i've experienced the breaking nature of elasticsearch",
    "start": "2072240",
    "end": "2078878"
  },
  {
    "text": "between major versions and gone through some of the pain that you have to do to upgrade between those and it is a bit of",
    "start": "2078879",
    "end": "2085040"
  },
  {
    "text": "a trade-off between how do we evolve something while not breaking while making things better",
    "start": "2085040",
    "end": "2090638"
  },
  {
    "text": "but in this case we've made some decisions that really kind of forced our hand and i'll talk a bit more about those",
    "start": "2090639",
    "end": "2095760"
  },
  {
    "text": "now so the first important thing is we know that it's not sustainable to keep manually creating the types for",
    "start": "2095760",
    "end": "2103200"
  },
  {
    "text": "the the client ourselves you know it leads to those gaps it leads to errors",
    "start": "2103200",
    "end": "2108320"
  },
  {
    "text": "and it's time consuming it means that my time on the client is not spent making it more performant or adding sort of value add",
    "start": "2108320",
    "end": "2115520"
  },
  {
    "text": "higher level features that make it easier to do particular things within elasticsearch it's mostly spent",
    "start": "2115520",
    "end": "2120800"
  },
  {
    "text": "maintaining that api surface and just keeping those roughly consistent and so we're moving to a code generation approach for",
    "start": "2120800",
    "end": "2127599"
  },
  {
    "text": "our new version of clients and as a client's team what we've done is built out a typescript representation of the",
    "start": "2127599",
    "end": "2134560"
  },
  {
    "text": "the types of the that can represent those api endpoints and the requests and responses and all the subtypes of those",
    "start": "2134560",
    "end": "2141680"
  },
  {
    "text": "and model them in such a way that we can also add our own various attributes to those that we know are kind of elastic",
    "start": "2141680",
    "end": "2147520"
  },
  {
    "text": "searchisms that we need to deal with like these kind of polymorphic types where we have various different forms of",
    "start": "2147520",
    "end": "2152720"
  },
  {
    "text": "polymorphism and how that's modeled in the data structures that come back and so we need to flag those so that",
    "start": "2152720",
    "end": "2158000"
  },
  {
    "text": "individual clients can do the best thing when they're co-generating to produce kind of the most useful code for that",
    "start": "2158000",
    "end": "2163920"
  },
  {
    "text": "language and so we start with the typescript we then use a compilation process that eventually will after",
    "start": "2163920",
    "end": "2169839"
  },
  {
    "text": "checking a bunch of things spit out a json schema it's a custom schema and some of you may be thinking",
    "start": "2169839",
    "end": "2175680"
  },
  {
    "text": "why not use something like open api we are looking at what we can do to actually generate an open api spec",
    "start": "2175680",
    "end": "2182000"
  },
  {
    "text": "but open api doesn't expose quite enough of the kind of distinct possibilities around that",
    "start": "2182000",
    "end": "2187920"
  },
  {
    "text": "polymorphism that i talked about around these different response types so it makes it very hard to model it",
    "start": "2187920",
    "end": "2192960"
  },
  {
    "text": "fully um and so that's not sufficient for actually co-generating a full client",
    "start": "2192960",
    "end": "2198560"
  },
  {
    "text": "at this point in time and so what we've done is we've created this sort of custom schema that gives us the capability to add all of those",
    "start": "2198560",
    "end": "2204720"
  },
  {
    "text": "additional flags and that additional sort of meta information into the spec that we can then as client team consume",
    "start": "2204720",
    "end": "2212240"
  },
  {
    "text": "so now i'm doing that code generation what we do is we take the json schema i'd read that in i do a bunch of sort of",
    "start": "2212240",
    "end": "2218160"
  },
  {
    "text": "upfront work working out what types that needs how those things interrelate and you know essentially create sort of a",
    "start": "2218160",
    "end": "2224480"
  },
  {
    "text": "meta structure that represents what the client should look like and then i'm using the roslin apis of.net to actually",
    "start": "2224480",
    "end": "2230720"
  },
  {
    "text": "produce the new client code that's a talk in itself and probably you know maybe next year i can come back and",
    "start": "2230720",
    "end": "2236320"
  },
  {
    "text": "talk about a bit more how that actually works but fundamentally we build up you know using the roslin apis you can build",
    "start": "2236320",
    "end": "2241680"
  },
  {
    "text": "up a syntax tree that's essentially what the compiler sees when it looks at your code in in its written form but we can",
    "start": "2241680",
    "end": "2247440"
  },
  {
    "text": "build that syntax tree up by hand in code uh from the spec and then i can use it to spit out c sharp files at the end",
    "start": "2247440",
    "end": "2254400"
  },
  {
    "text": "of it that represent those types so all of the requests and responses um all of the sort of related types that those",
    "start": "2254400",
    "end": "2260000"
  },
  {
    "text": "then depend on are now co-generated off of this spec and i think at the moment when i run the",
    "start": "2260000",
    "end": "2265280"
  },
  {
    "text": "code generator at least two and a half thousand types are being created now automatically off of this spec that's",
    "start": "2265280",
    "end": "2271200"
  },
  {
    "text": "obviously a lot of work to get a code generator of that scale working accurately and i'm still working through some of the final issues which is why we",
    "start": "2271200",
    "end": "2277440"
  },
  {
    "text": "don't have a gi client just yet but i think we can see the benefits that means you get much greater consistency we'll",
    "start": "2277440",
    "end": "2283440"
  },
  {
    "text": "be able to run this process you know every day if we want to in our in our build systems uh against the spec and if",
    "start": "2283440",
    "end": "2289520"
  },
  {
    "text": "things have changed the client will be updated to reflect them and you'll essentially get day one sort of parity between client and server which will be",
    "start": "2289520",
    "end": "2295920"
  },
  {
    "text": "really nice and it also as i say freeze my time up to do that value ad work and and deal with those sort of high level",
    "start": "2295920",
    "end": "2302480"
  },
  {
    "text": "challenges that people face when building applications against elasticsearch one of the other key changes is we move",
    "start": "2302480",
    "end": "2308480"
  },
  {
    "text": "to system text json for the serialization so if you haven't heard of it this is microsoft's",
    "start": "2308480",
    "end": "2313920"
  },
  {
    "text": "new in the box json serializer um it's been in the box with dot net for a few releases now but it first came out it",
    "start": "2313920",
    "end": "2320000"
  },
  {
    "text": "was a little bit kind of feature incomplete in terms of what we needed but we're now at the point where it does",
    "start": "2320000",
    "end": "2326240"
  },
  {
    "text": "enough it doesn't do everything i'd like but it does enough that i can kind of work around those gaps that we can actually use it internally as a",
    "start": "2326240",
    "end": "2332079"
  },
  {
    "text": "serializer and what that means is we no longer have to maintain all of",
    "start": "2332079",
    "end": "2338480"
  },
  {
    "text": "this serialization code ourselves we can rely on microsoft we've done a really good job of creating a library profiling",
    "start": "2338480",
    "end": "2344240"
  },
  {
    "text": "it and have got the engineering power behind that to actually make sure that we have a really good high level uh",
    "start": "2344240",
    "end": "2349839"
  },
  {
    "text": "hype efficiency serializer within.net that ships in the box so it's not a",
    "start": "2349839",
    "end": "2355359"
  },
  {
    "text": "dependency you necessarily need to take because newer.net versions just have it available to them as well but it is",
    "start": "2355359",
    "end": "2361280"
  },
  {
    "text": "netstandard compatible so if you're still using the libraries on sort of.net framework you can still use that",
    "start": "2361280",
    "end": "2366720"
  },
  {
    "text": "serializer in our newer packages but this gives us a lot of work to do this as it turns out",
    "start": "2366720",
    "end": "2372560"
  },
  {
    "text": "there's a lot of custom conversion that needs to happen as i say for that that polymorphic nature of some of our types",
    "start": "2372560",
    "end": "2378160"
  },
  {
    "text": "and our more complex json structures but we're at a point now where that's pretty much working for all of the key",
    "start": "2378160",
    "end": "2383839"
  },
  {
    "text": "parts of the client the other thing we did was we removed what is essentially the low-level client",
    "start": "2383839",
    "end": "2389359"
  },
  {
    "text": "and made it its own package called elastic.transport um this would be the thing that you you know if you're in a really high",
    "start": "2389359",
    "end": "2395200"
  },
  {
    "text": "performance scenario and you're building more of a library on top you might be looking at and this is really just about that",
    "start": "2395200",
    "end": "2400640"
  },
  {
    "text": "transport layer nature but we've tried to make it a little bit more sort of product agnostic so it's a generic",
    "start": "2400640",
    "end": "2407440"
  },
  {
    "text": "transport that works for our distributed setup that we could apply to other of our products and hint we might be able",
    "start": "2407440",
    "end": "2413920"
  },
  {
    "text": "to do clients that are built on this for some of our other services so you can manage those for example enterprise search has an api",
    "start": "2413920",
    "end": "2420800"
  },
  {
    "text": "it would be nice to have a net client for that and ultimately this gives us with all of",
    "start": "2420800",
    "end": "2426079"
  },
  {
    "text": "this meaningless breaking changes as a nature of the fact that we've gone from something that was",
    "start": "2426079",
    "end": "2431440"
  },
  {
    "text": "handcrafted with care and we ensured every type name was unique and didn't conflict with other types within the in",
    "start": "2431440",
    "end": "2437440"
  },
  {
    "text": "the name space we're now in a situation where we're generating more generally off of the specs so",
    "start": "2437440",
    "end": "2442560"
  },
  {
    "text": "we have to have some more name spaces in there type names may change because we're going off the spec we don't want to make this sort of go back to the",
    "start": "2442560",
    "end": "2449200"
  },
  {
    "text": "point where we've gone off a spec and then we handcraft everything by using configuration and so we've accepted that",
    "start": "2449200",
    "end": "2454560"
  },
  {
    "text": "there will be some breaks but most of the stuff is reasonably consistent and i'm trying to close those gaps as",
    "start": "2454560",
    "end": "2460079"
  },
  {
    "text": "best i can but also this means we have the opportunity to try and remove some legacy and and make the client better",
    "start": "2460079",
    "end": "2466079"
  },
  {
    "text": "take some feedback that people have given us over the sort of past few years about what they don't do and don't like about how it's kind of structured",
    "start": "2466079",
    "end": "2472960"
  },
  {
    "text": "and try and take that on board as well so with that i can get to a little bit",
    "start": "2472960",
    "end": "2478000"
  },
  {
    "text": "of a demo i'm going to be relying on the wi-fi so hopefully elastic cloud's up and running",
    "start": "2478000",
    "end": "2483119"
  },
  {
    "text": "just in case it's not let's start a docket container behind the scenes so",
    "start": "2483119",
    "end": "2488319"
  },
  {
    "text": "what i'm going to do for this demo is it is you know again it's going to be a getting started demo i'm going to use",
    "start": "2488319",
    "end": "2493520"
  },
  {
    "text": "the new ato client i'm using a ci build of the new client because i added some stuff last week i",
    "start": "2493520",
    "end": "2499280"
  },
  {
    "text": "wanted to to include in here so um it's been a good experience for me to kind of dog food my own client and find a few of",
    "start": "2499280",
    "end": "2505440"
  },
  {
    "text": "the gaps but it's pretty much um got everything that i wanted so",
    "start": "2505440",
    "end": "2510480"
  },
  {
    "text": "in terms of the data we're dealing with hopefully this is big enough at the back um this is just the csv file that we're going to be working with which is",
    "start": "2510480",
    "end": "2516960"
  },
  {
    "text": "some 600 000 rows of stock data from 2013 to 2018 i think",
    "start": "2516960",
    "end": "2522960"
  },
  {
    "text": "and you can see you know we have for each day there's uh for each stock symbol that",
    "start": "2522960",
    "end": "2528000"
  },
  {
    "text": "was on the market there's the high low close values for those",
    "start": "2528000",
    "end": "2534319"
  },
  {
    "text": "um so that's what we're working with in terms of the net modeling of that then i have essentially a poco dto that just models",
    "start": "2534319",
    "end": "2541920"
  },
  {
    "text": "the the fields that are available there the only additional stuff in this file is a little bit of a factory method just",
    "start": "2541920",
    "end": "2547359"
  },
  {
    "text": "to parse it out of the file and create the type and i've got a very basic dictionary for just some of the the",
    "start": "2547359",
    "end": "2552800"
  },
  {
    "text": "stock symbol names to look them up against their full name that will be useful for for searching in a moment",
    "start": "2552800",
    "end": "2558400"
  },
  {
    "text": "so the first thing i'm going to need to do is hopefully i'm still on elastic cloud i am so this",
    "start": "2558400",
    "end": "2564560"
  },
  {
    "text": "is my elastic cloud deployment that i've spun up um these credentials will be gone by the end of the talk so hopefully",
    "start": "2564560",
    "end": "2570319"
  },
  {
    "text": "no one will hack them in the meantime but what i've grabbed from the cloud is the cloud id this is just a really long",
    "start": "2570319",
    "end": "2577839"
  },
  {
    "text": "uh sort of string it's base encoded data that we need to connect and this is the easiest way to get started with the",
    "start": "2577839",
    "end": "2583280"
  },
  {
    "text": "client you don't need to kind of get all of the urls and things just chuck in the cloud id and we'll parse that data from this",
    "start": "2583280",
    "end": "2589440"
  },
  {
    "text": "string the only other thing i need is going to be the username and password and elastic cloud gives us a username",
    "start": "2589440",
    "end": "2595280"
  },
  {
    "text": "password by default when it started and i'm just going to grab that password for the elastic user",
    "start": "2595280",
    "end": "2600640"
  },
  {
    "text": "this commented code here is about setting up a local version of the client that talks to my local docker instance we don't need it",
    "start": "2600640",
    "end": "2606960"
  },
  {
    "text": "if the cloud is reachable from here but you can see the setup is very similar just with some additional",
    "start": "2606960",
    "end": "2613839"
  },
  {
    "text": "information but for the cloud all i need to do is call new elasticsearch client pass in that cloud id and basically a",
    "start": "2613839",
    "end": "2620400"
  },
  {
    "text": "basic auth object here you can also use api key authentication if you need to",
    "start": "2620400",
    "end": "2625680"
  },
  {
    "text": "so that's what we need to do to create an instance of the client and the first thing i'm going to do in",
    "start": "2625680",
    "end": "2630960"
  },
  {
    "text": "this code here is call into the client and i'm going to call into the indices area of the client",
    "start": "2630960",
    "end": "2636880"
  },
  {
    "text": "that relates to apis under the kind of indexing namespace uh or sort of the sub",
    "start": "2636880",
    "end": "2642480"
  },
  {
    "text": "area of the api i should say so indices exists async just calls into a method that's going to map to the",
    "start": "2642480",
    "end": "2648880"
  },
  {
    "text": "exists endpoint for that index area and it just takes in this scenario the minimum i need is this index name which",
    "start": "2648880",
    "end": "2655680"
  },
  {
    "text": "is just a string that represents the name of the index that i'm going to check for so this will check if the index exists",
    "start": "2655680",
    "end": "2661680"
  },
  {
    "text": "what this code will then do is say well if it doesn't exist i'm going to create it and so in here again we're in that sort",
    "start": "2661680",
    "end": "2667760"
  },
  {
    "text": "of indices area but now we're calling create async we're passing the index name and then this is",
    "start": "2667760",
    "end": "2674079"
  },
  {
    "text": "nearly completely fluent there's a little bit of it isn't fluent here um and i'll show you the uh the 7x version",
    "start": "2674079",
    "end": "2679520"
  },
  {
    "text": "in a minute but this is sort of this syntax down here is kind of what i mean by fluent so we call into dot settings",
    "start": "2679520",
    "end": "2684720"
  },
  {
    "text": "and within settings we can set number of shards one number of replicas zero and and basically configure it this",
    "start": "2684720",
    "end": "2690880"
  },
  {
    "text": "isn't a production ready uh demo so don't follow these settings for your own production systems the other thing we",
    "start": "2690880",
    "end": "2696319"
  },
  {
    "text": "can provide is these mappings so this is how we define that explicit mapping between fields that we're going to be sending elasticsearch and how they",
    "start": "2696319",
    "end": "2702560"
  },
  {
    "text": "should be stored now this is where i'm not influencing text because at the moment my code generator doesn't know",
    "start": "2702560",
    "end": "2707760"
  },
  {
    "text": "how to generate the fluent descriptor for this but sometime next week it should but for now what i'm doing is just newing up the",
    "start": "2707760",
    "end": "2714720"
  },
  {
    "text": "the mappings just to show you what this looks like in 7x it's not all that dissimilar but with the fluent syntax",
    "start": "2714720",
    "end": "2720800"
  },
  {
    "text": "you call into doc keyword and then you can access the name that you want to set as a keyword field in here and what this",
    "start": "2720800",
    "end": "2727839"
  },
  {
    "text": "does is take the the name but rather than you hard coding magic strings everywhere that represent the the name",
    "start": "2727839",
    "end": "2733680"
  },
  {
    "text": "you want to mark as a keyword field we can do what we call type inference and here you just provide an expression that says okay",
    "start": "2733680",
    "end": "2740640"
  },
  {
    "text": "well i want the the symbol property on the stock data to be used as the field name and what we do behind the scenes by",
    "start": "2740640",
    "end": "2746800"
  },
  {
    "text": "default that's essentially just going to camel case the property name because that's the default expectation for the json structures you'd like to",
    "start": "2746800",
    "end": "2753119"
  },
  {
    "text": "send in but you can configure that and change how that inference works if you need to",
    "start": "2753119",
    "end": "2758720"
  },
  {
    "text": "the other thing we're doing then is setting up these number properties and again it's this fluent syntax dot number once you're into there you can figure",
    "start": "2758720",
    "end": "2764319"
  },
  {
    "text": "its name and the specific number type that you want so back to version eight uh the",
    "start": "2764319",
    "end": "2769440"
  },
  {
    "text": "difference here is that as i say i'm just creating this kind of dictionary myself with the field name without",
    "start": "2769440",
    "end": "2775200"
  },
  {
    "text": "inference here and the the type of property i want that field to be so the reason i'm doing this explicit",
    "start": "2775200",
    "end": "2780960"
  },
  {
    "text": "mapping is for the symbols for example the msft or something that would represent microsoft stock we're not",
    "start": "2780960",
    "end": "2786560"
  },
  {
    "text": "going to need to full text search that field because generally we're just going to say we'll find me all of the msft",
    "start": "2786560",
    "end": "2792079"
  },
  {
    "text": "stock it's not going to be a full text type of search and so rather than have elasticsearch index that into an",
    "start": "2792079",
    "end": "2797680"
  },
  {
    "text": "inverted index that supports the capability of full text search which requires memory and data structures",
    "start": "2797680",
    "end": "2803040"
  },
  {
    "text": "we're just going to say actually now we know how this this type of data is only ever going to be queried in a full text form sorry an exact match form",
    "start": "2803040",
    "end": "2810560"
  },
  {
    "text": "so we will define it purely as a keyword rather than as a text property these other ones are a little bit more",
    "start": "2810560",
    "end": "2816640"
  },
  {
    "text": "interesting so these are the numeric data that represents the stock values i've explicitly marked these as floats",
    "start": "2816640",
    "end": "2822640"
  },
  {
    "text": "because although elasticsearch will generally infer that quite happily if there's kind of decimal places in the",
    "start": "2822640",
    "end": "2828240"
  },
  {
    "text": "data i do know that my data file if the numbers are rounded to 0.0 it just gives an exact",
    "start": "2828240",
    "end": "2835440"
  },
  {
    "text": "integer looking value so if the first document that goes in actually has that sort of integer representation of the",
    "start": "2835440",
    "end": "2841359"
  },
  {
    "text": "numbers elasticsearch will see that and go well this looks like an integer i will treat this field as an integer",
    "start": "2841359",
    "end": "2846720"
  },
  {
    "text": "field um when actually the vast majority of these documents are going to need to have the decimal places so this is where",
    "start": "2846720",
    "end": "2853119"
  },
  {
    "text": "you get into explicit mapping you understand your data so that you can give elastic search and proper guidance",
    "start": "2853119",
    "end": "2858720"
  },
  {
    "text": "about how it should treat it so in this case i'm just saying they're all floats after this runs i'm going to check that",
    "start": "2858720",
    "end": "2864640"
  },
  {
    "text": "my response was valid and whether it was acknowledged by the server and if it wasn't i'll throw an exception and then",
    "start": "2864640",
    "end": "2870240"
  },
  {
    "text": "i need to get some data into elasticsearch so we can index data document by document just doing an index",
    "start": "2870240",
    "end": "2876800"
  },
  {
    "text": "document command and that's fine for sort of ad hoc small amounts of data as they're coming in",
    "start": "2876800",
    "end": "2883440"
  },
  {
    "text": "but it's not super efficient if we're doing this kind of scenario where we want to ingest a large volume of data rapidly because each of those index",
    "start": "2883440",
    "end": "2891040"
  },
  {
    "text": "document requests is going to be an individual http request so there's overhead and sort of back and forth with the server",
    "start": "2891040",
    "end": "2897599"
  },
  {
    "text": "for that to happen so elasticsearch supports a bulk api endpoint that takes a new line delimited json format that",
    "start": "2897599",
    "end": "2904559"
  },
  {
    "text": "represents various operations you want to perform and we provide what we call a helper that kind of wraps that api for",
    "start": "2904559",
    "end": "2911040"
  },
  {
    "text": "doing bulk ingestion so in this case we we call that bulk all and what this takes is an innumerable of data so if i",
    "start": "2911040",
    "end": "2918000"
  },
  {
    "text": "jump down here this is just an innumerable uh on my type down here that's essentially reading line by line",
    "start": "2918000",
    "end": "2924079"
  },
  {
    "text": "from the file and yielding those lines as it gets them so just a sort of poor man's innumerable",
    "start": "2924079",
    "end": "2929599"
  },
  {
    "text": "there but any innumerable source can be passed in here and then the other configuration which again is in this",
    "start": "2929599",
    "end": "2935359"
  },
  {
    "text": "fluent syntax defines how do we want that data treated so i'm going to send it to the index with this index name i",
    "start": "2935359",
    "end": "2941839"
  },
  {
    "text": "want to deal with back off scenarios so if the server says whoa i'm overloaded",
    "start": "2941839",
    "end": "2946880"
  },
  {
    "text": "it will give us a 429 or something back to say can you back off for a bit i haven't got the capacity to take any more data right now",
    "start": "2946880",
    "end": "2953440"
  },
  {
    "text": "we tell the client well okay in this case we'll retry up to 20 times in that scenario and each time we'll wait 10",
    "start": "2953440",
    "end": "2959040"
  },
  {
    "text": "seconds and give the server that that time to back off the other scenario we're dealing with",
    "start": "2959040",
    "end": "2964240"
  },
  {
    "text": "here is what do we do if documents are dropped so although the request may succeed and elasticsearch receives our 1",
    "start": "2964240",
    "end": "2970160"
  },
  {
    "text": "000 documents or whatever we're sending it um if some of those have data that doesn't can't be applied to the mappings",
    "start": "2970160",
    "end": "2976240"
  },
  {
    "text": "that exist for those types then elasticsearch is going to throw up its hands and say this isn't valid i can't i",
    "start": "2976240",
    "end": "2981359"
  },
  {
    "text": "can't store this and so those will be dropped and by default we want to deal with those but we want to deal with them",
    "start": "2981359",
    "end": "2987440"
  },
  {
    "text": "separately so we're going to say continue after any drop documents ignore the fact that you know maybe one out of",
    "start": "2987440",
    "end": "2993200"
  },
  {
    "text": "the set that we sent couldn't be indexed but we will this callback will be called for us that we can provide some handling",
    "start": "2993200",
    "end": "2998800"
  },
  {
    "text": "for that so we might here i'm logging into a console but you could also put these into a dead letter queue or some",
    "start": "2998800",
    "end": "3003839"
  },
  {
    "text": "other structure and deal with them as you need to the final things i'm setting are",
    "start": "3003839",
    "end": "3009040"
  },
  {
    "text": "parallelism you don't have to define this manually i have here just to show that it exists we'll infer a cpu count",
    "start": "3009040",
    "end": "3015200"
  },
  {
    "text": "by default um but this is how many concurrent http requests are we're going to be sending as part of this batch work",
    "start": "3015200",
    "end": "3020800"
  },
  {
    "text": "that we're doing and then the size is how many documents do we put into each individual request essentially so here",
    "start": "3020800",
    "end": "3027760"
  },
  {
    "text": "we're saying a batch size of a thousand so we put a thousand documents into that uh request body and ship it up to the",
    "start": "3027760",
    "end": "3033119"
  },
  {
    "text": "server finding the exact balance that's the most efficient is again a bit of trial and error it depends on your data",
    "start": "3033119",
    "end": "3038559"
  },
  {
    "text": "structures and how large things are you know you could assume oh i'm going to make this 10 000 and everything will be quicker but obviously you're then",
    "start": "3038559",
    "end": "3045119"
  },
  {
    "text": "getting to larger and larger request sizes that have to be shipped over the network and it might actually be less",
    "start": "3045119",
    "end": "3050400"
  },
  {
    "text": "efficient to put that a large volume of data per request so finding the right trade-off for your network environment",
    "start": "3050400",
    "end": "3055680"
  },
  {
    "text": "and for the data you're sending is is important but somewhere in a thousand is a good starting point and then you can",
    "start": "3055680",
    "end": "3061040"
  },
  {
    "text": "kind of play around with the figures now this bulk hall is in our observable and it actually kicks off the operation",
    "start": "3061040",
    "end": "3066559"
  },
  {
    "text": "in the background on a background thread and then that's actually started immediately but in this case what we",
    "start": "3066559",
    "end": "3072240"
  },
  {
    "text": "want to do is actually block this application proceeding until we know that that's all finished so i'm going to use this observer here that's a helper",
    "start": "3072240",
    "end": "3078640"
  },
  {
    "text": "again on top of that observable and this observer just says well actually i want to wait on this thing completing",
    "start": "3078640",
    "end": "3084720"
  },
  {
    "text": "in this case i'm going to wait for up to 10 minutes for this complete operation to run and every time we get a this is",
    "start": "3084720",
    "end": "3091200"
  },
  {
    "text": "the on next delegate so every time a response comes back uh to this this bulk operation that's happening behind the",
    "start": "3091200",
    "end": "3096640"
  },
  {
    "text": "scenes we want to run this delegate and in this case we'll just log to the console so before i get on to the rest",
    "start": "3096640",
    "end": "3102240"
  },
  {
    "text": "of this code let's kick this off and pray that the network's good and we should start to see some data",
    "start": "3102240",
    "end": "3108559"
  },
  {
    "text": "uh being indexed there hopefully yes good um it's a bit small but all it's saying",
    "start": "3108559",
    "end": "3114319"
  },
  {
    "text": "is data indexed and that's just each of those bulk operations um happening and going over the wire to the server so the",
    "start": "3114319",
    "end": "3120559"
  },
  {
    "text": "600 000 records it's going to take it you know a few seconds to complete but with this bulk operation this bulk all",
    "start": "3120559",
    "end": "3126800"
  },
  {
    "text": "helper i should say um you can see we've just indexed nearly half a million over half a million documents uh while we've",
    "start": "3126800",
    "end": "3132559"
  },
  {
    "text": "been stood here uh listening to them chat on and so that's actually now in a position",
    "start": "3132559",
    "end": "3137920"
  },
  {
    "text": "where we've got our data in and the next thing we might want to do once we've got data in into our index is",
    "start": "3137920",
    "end": "3143119"
  },
  {
    "text": "actually start searching on it so let's start with a really simple search uh let's say we just want to get back all",
    "start": "3143119",
    "end": "3148480"
  },
  {
    "text": "of the documents for the microsoft stock but what we're going to do is we're",
    "start": "3148480",
    "end": "3153680"
  },
  {
    "text": "going to create a query as part of our search here and the simplest query for",
    "start": "3153680",
    "end": "3158800"
  },
  {
    "text": "this scenario where we just want to say does it match this cons does this match on this term or not",
    "start": "3158800",
    "end": "3164640"
  },
  {
    "text": "and just filter the documents down is to use a filter query in here which is turn based so the field again",
    "start": "3164640",
    "end": "3170880"
  },
  {
    "text": "using inference would be whatever is the symbol property on our stock object or stock",
    "start": "3170880",
    "end": "3176480"
  },
  {
    "text": "data type will be used as a field name and then the value we want to match is msft so this is keyword match remember",
    "start": "3176480",
    "end": "3182079"
  },
  {
    "text": "so it's case sensitive it's an exact match because that's how we map the data and then we're going to limit the",
    "start": "3182079",
    "end": "3187599"
  },
  {
    "text": "response size here so we only just want the first 20 for now and we can do a sort in on the server to get them descending",
    "start": "3187599",
    "end": "3193200"
  },
  {
    "text": "by date once we get back a response we can access the",
    "start": "3193200",
    "end": "3198240"
  },
  {
    "text": "documents on that response and because this search async here is strongly typed using this generic to our data type",
    "start": "3198240",
    "end": "3204559"
  },
  {
    "text": "these documents will be deserialized off the response into our stock data type for us so once we're here data is a",
    "start": "3204559",
    "end": "3211520"
  },
  {
    "text": "stock data object instance and so that means we can just access its properties and write some stuff out to the console",
    "start": "3211520",
    "end": "3217440"
  },
  {
    "text": "so not too exciting but we can just run that and again we've hit the break point so",
    "start": "3217440",
    "end": "3222480"
  },
  {
    "text": "we've got our first 20 rows there with the values for each of those dates so that's a very simple kind of",
    "start": "3222480",
    "end": "3228160"
  },
  {
    "text": "filter-based query um that we can do",
    "start": "3228160",
    "end": "3233680"
  },
  {
    "text": "if we want to do something that is a bit more realistic with some full text search let's run this search here um",
    "start": "3233680",
    "end": "3240559"
  },
  {
    "text": "the index again is the same index the query now is going to be a match so this is where we start to get into full text",
    "start": "3240559",
    "end": "3245839"
  },
  {
    "text": "searching and what we're saying is we want to match this term inc within the name of the stock data so for the name",
    "start": "3245839",
    "end": "3252400"
  },
  {
    "text": "of the company again we're just going to get the first 20 in descending and again we can access the documents so the difference here is",
    "start": "3252400",
    "end": "3258800"
  },
  {
    "text": "that we're now starting to go into that full text index and say find any of the documents that have the term inc in",
    "start": "3258800",
    "end": "3263920"
  },
  {
    "text": "there somewhere as a distinct token word we run the search and as we'd expect we get the data the",
    "start": "3263920",
    "end": "3271520"
  },
  {
    "text": "interesting thing to point out although this is a bit small let's just make this a bit",
    "start": "3271520",
    "end": "3276839"
  },
  {
    "text": "bigger um the uh the name here so this one is obviously uppercase i and then nc this",
    "start": "3276839",
    "end": "3283839"
  },
  {
    "text": "one has a period after it so because of the the tokenization and the analysis of that that string field as it went into",
    "start": "3283839",
    "end": "3289839"
  },
  {
    "text": "the index um it means we've matched all of these documents which is typically the behavior you're going to want for this kind of stuff but again you can",
    "start": "3289839",
    "end": "3296079"
  },
  {
    "text": "configure these options for your needs as i'm getting towards the end of time i'll quickly show the aggregation",
    "start": "3296079",
    "end": "3302240"
  },
  {
    "text": "example and then we are good for any questions that we may have um so in this case again the search is",
    "start": "3302240",
    "end": "3309119"
  },
  {
    "text": "what we started with the first time so we're going to just do a simple filter for all of the microsoft uh stock data",
    "start": "3309119",
    "end": "3314720"
  },
  {
    "text": "but now we're getting into a scenario where we actually want to do some sort of aggregation of that data and understand in a different form and so in",
    "start": "3314720",
    "end": "3321359"
  },
  {
    "text": "this case what we're going to do is say well let's try and get all of the microsoft data and and for each month work out the total volume of trades that",
    "start": "3321359",
    "end": "3328079"
  },
  {
    "text": "happened so in this scenario what we can do is we can use a date histogram aggregation which is essentially bucket the data by",
    "start": "3328079",
    "end": "3335680"
  },
  {
    "text": "some calendar interval in this case the calendar interval is monthly",
    "start": "3335680",
    "end": "3340720"
  },
  {
    "text": "when we create the aggregation that we want we provide a name this allows us to grab it back off the response later on",
    "start": "3340720",
    "end": "3347200"
  },
  {
    "text": "in terms of the field we're using again we're using the kind of inferred field name for the date property on our data",
    "start": "3347200",
    "end": "3352319"
  },
  {
    "text": "type because that's obviously the only date we have to actually uh bucket this on we can order it by key descending which",
    "start": "3352319",
    "end": "3358400"
  },
  {
    "text": "essentially is date descending and then we can actually perform a sub-aggregation so we said we wanted everything by month which we've achieved",
    "start": "3358400",
    "end": "3364640"
  },
  {
    "text": "by doing a date histogram aggregation now we're in the situation where we want to total up",
    "start": "3364640",
    "end": "3370079"
  },
  {
    "text": "or sum the volume of trades that occurred so in this case we do another aggregation",
    "start": "3370079",
    "end": "3375440"
  },
  {
    "text": "under each sort of date bucket and this is a sum aggregation called trade volumes that again just needs to know uh",
    "start": "3375440",
    "end": "3382480"
  },
  {
    "text": "the field that we want to sum up in this case the volume field and so when this comes back we get this",
    "start": "3382480",
    "end": "3389040"
  },
  {
    "text": "aggregations on the response here and what we can do is call into the these methods to start accessing",
    "start": "3389040",
    "end": "3394400"
  },
  {
    "text": "aggregations from there so uh we can call getdate histogram we would want the date histogram aggregation named by",
    "start": "3394400",
    "end": "3401040"
  },
  {
    "text": "month and then we want to access each individual bucket that's on there which is just a collection of those buckets by",
    "start": "3401040",
    "end": "3406319"
  },
  {
    "text": "month and then we can just four each over these in a standard for each loop here and for each monthly bucket we'll call",
    "start": "3406319",
    "end": "3413200"
  },
  {
    "text": "getsum which allows us to then go into its sub-aggregations and ask for the sum aggregation called trade volumes and",
    "start": "3413200",
    "end": "3419280"
  },
  {
    "text": "this is just a basic metric aggregation so in this case we don't have buckets we just have the value which is the result",
    "start": "3419280",
    "end": "3424720"
  },
  {
    "text": "of the sum operation and so now we have the volume for the number of trades that occurred",
    "start": "3424720",
    "end": "3430079"
  },
  {
    "text": "and in this case what we're doing then is writing these out to the console uh and we can access the key to get essentially",
    "start": "3430079",
    "end": "3437040"
  },
  {
    "text": "the date of the bucket so we can put the date in and it scrolls off here and then we're just writing out that volume",
    "start": "3437040",
    "end": "3443359"
  },
  {
    "text": "so if i now run this example you can see we get all of the",
    "start": "3443359",
    "end": "3449520"
  },
  {
    "text": "dates bucketed so 2018 backwards from the age of this data and this is the the",
    "start": "3449520",
    "end": "3454720"
  },
  {
    "text": "number of trades that occurred for microsoft stock in that given month so there's you know a few scenarios there",
    "start": "3454720",
    "end": "3460640"
  },
  {
    "text": "basic sort of uh exact matching of data the more common full text searching that you might do against you know larger",
    "start": "3460640",
    "end": "3467359"
  },
  {
    "text": "volumes of text data and then this capability to do sort of metrics and data analysis with aggregations and",
    "start": "3467359",
    "end": "3472880"
  },
  {
    "text": "things like that so we're pretty much at the end of time let's just run this",
    "start": "3472880",
    "end": "3479280"
  },
  {
    "text": "final couple of slides um so in terms of resources for what i've shown you again the most important link",
    "start": "3479280",
    "end": "3485920"
  },
  {
    "text": "is this bitly link so if you grab a photo of this slide and grab that link this will take you to the slide deck and",
    "start": "3485920",
    "end": "3490960"
  },
  {
    "text": "then you've got all the other links i'm about to show you um obviously the first thing is our github repo for the net",
    "start": "3490960",
    "end": "3496720"
  },
  {
    "text": "client so if you're working with the.net client and you have issues or ideas or whatever you can you can write those and report",
    "start": "3496720",
    "end": "3503280"
  },
  {
    "text": "them to us in in this repo we have our documentation um on",
    "start": "3503280",
    "end": "3508400"
  },
  {
    "text": "elastic.cos so we have obviously guides for elasticsearch itself and then we have the client-specific guides that you",
    "start": "3508400",
    "end": "3513599"
  },
  {
    "text": "may need to find the existing 7x client nest is on nougat under the name nest which is easily",
    "start": "3513599",
    "end": "3519920"
  },
  {
    "text": "searchable and if you want to start playing with the new client it's in alpha 10 at the moment",
    "start": "3519920",
    "end": "3525799"
  },
  {
    "text": "elastic.client.elasticsearch is is now how we're referring to that package name and that's going to be the the new",
    "start": "3525799",
    "end": "3532000"
  },
  {
    "text": "client going forward so if you're really interested in seeing how that works in your scenarios with the early alphas",
    "start": "3532000",
    "end": "3537839"
  },
  {
    "text": "just don't put it in production yet because we will have some more changes then you can go and find it there",
    "start": "3537839",
    "end": "3542880"
  },
  {
    "text": "the example i've just shown you is in my repo so elasticsearch.examples and you'll find what i've just shown you on screen if",
    "start": "3542880",
    "end": "3548960"
  },
  {
    "text": "you want to look at those queries again i'll just dig into the code a little bit more and we have a online forum discuss",
    "start": "3548960",
    "end": "3555359"
  },
  {
    "text": "elastic dot co if you have general questions you know that could be not just client related but search related as well how do i do x",
    "start": "3555359",
    "end": "3562400"
  },
  {
    "text": "what's the best way to get started with you know why and why i'm running into these things so that's about questions",
    "start": "3562400",
    "end": "3567440"
  },
  {
    "text": "the repo is more about issues and direct features that you need otherwise",
    "start": "3567440",
    "end": "3572799"
  },
  {
    "text": "thank you very much for coming i'm glad to see some people here uh if you don't get to talk to me after the session and i do ask that you come up to find me",
    "start": "3572799",
    "end": "3579520"
  },
  {
    "text": "during the next few days if you have questions or feedback on elasticsearch and net but if not you can find me",
    "start": "3579520",
    "end": "3585040"
  },
  {
    "text": "online at steve j gordon and i've been asked to remind you to to leave your review as you leave um on the way out so",
    "start": "3585040",
    "end": "3591040"
  },
  {
    "text": "thank you very much appreciate your time and i'll see you hopefully next year",
    "start": "3591040",
    "end": "3596838"
  }
]
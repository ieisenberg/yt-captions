[
  {
    "start": "0",
    "end": "200000"
  },
  {
    "text": "so my name is Steve Simpson I've given this talk a couple of times before but",
    "start": "1650",
    "end": "7049"
  },
  {
    "text": "only two I need PostgreSQL conferences so this is the first time I've given anything like this outside a postcodes",
    "start": "7049",
    "end": "14040"
  },
  {
    "text": "conference so the usual response is yes that's great we love postcards that's fine so it'd be interesting to see how",
    "start": "14040",
    "end": "19260"
  },
  {
    "text": "it goes down at the mall with a more broad audience with that in mind quick",
    "start": "19260",
    "end": "24690"
  },
  {
    "text": "warning this talk does contain a lot of sequel so if that offends you you this",
    "start": "24690",
    "end": "29820"
  },
  {
    "text": "might not be the right talk for you to watch so I don't actually have any affiliation",
    "start": "29820",
    "end": "36660"
  },
  {
    "text": "with post CREZ QL so I'm not going to",
    "start": "36660",
    "end": "42239"
  },
  {
    "text": "try and convince you to use it in this talk that's your decision to make so a",
    "start": "42239",
    "end": "51570"
  },
  {
    "text": "quick overview and talk split into about seven sections it did a bit of background a bit of background on the",
    "start": "51570",
    "end": "59640"
  },
  {
    "text": "use case and then we'll go into technical details and there's also a small section at the end which after",
    "start": "59640",
    "end": "66570"
  },
  {
    "text": "running through this tour couple of times realized there really wasn't enough time to do it but it needs to be mentioned so that's wise in small",
    "start": "66570",
    "end": "72960"
  },
  {
    "text": "letters so my background so I'm primarily a software developer and I've",
    "start": "72960",
    "end": "78510"
  },
  {
    "text": "done a lot of this in the past and is to work on embedded hardware so this is an Ethernet switch and 10 Gigabit Ethernet",
    "start": "78510",
    "end": "86070"
  },
  {
    "text": "switch with a chip inside that can transfer a terabyte of data per second",
    "start": "86070",
    "end": "92820"
  },
  {
    "text": "which was quite fun to work on and the last five years or so have been working",
    "start": "92820",
    "end": "98610"
  },
  {
    "text": "on databases and software company called just won their little startup in the UK",
    "start": "98610",
    "end": "103920"
  },
  {
    "text": "and they based their product off post grades 12 hence my kind of interest in",
    "start": "103920",
    "end": "111060"
  },
  {
    "text": "Christmas so either mentioned on from a",
    "start": "111060",
    "end": "117430"
  },
  {
    "text": "little-known city perhaps from the UK called Bristol I wouldn't really get a lot of attention in the news but it is",
    "start": "117430",
    "end": "126189"
  },
  {
    "text": "according to the BBC the best place to live in Britain so if you ever go there and you want to move there move to",
    "start": "126189",
    "end": "132550"
  },
  {
    "text": "Bristol because it's great yeah now for that so I work for a company called",
    "start": "132550",
    "end": "137890"
  },
  {
    "text": "stack HPC so we do consultancy on HPC for OpenStack and I probably doesn't",
    "start": "137890",
    "end": "144880"
  },
  {
    "text": "mean anything it doesn't matter the purpose of this talk we work on systems that looks a bit like this so they're",
    "start": "144880",
    "end": "151560"
  },
  {
    "text": "kind of they fill rooms rather than filling under your desk and something",
    "start": "151560",
    "end": "158680"
  },
  {
    "text": "interesting about these systems is the amount of work they do is kind of staggering and a lot of moving parts it",
    "start": "158680",
    "end": "167830"
  },
  {
    "text": "used to be that this was sort of they were quite unique in this regard but in",
    "start": "167830",
    "end": "173080"
  },
  {
    "text": "the sort of advent of cloud you know big data center that looked like this aren't really that unique anymore but the",
    "start": "173080",
    "end": "178989"
  },
  {
    "text": "problems they tell their face are quite interesting so we work in partnership with University of Cambridge on one of",
    "start": "178989",
    "end": "187120"
  },
  {
    "text": "these not this entire system maybe one rack of that system building a HPC",
    "start": "187120",
    "end": "193600"
  },
  {
    "text": "cluster which is currently used for medical research processing brain images",
    "start": "193600",
    "end": "199319"
  },
  {
    "start": "200000",
    "end": "293000"
  },
  {
    "text": "so that leads us on to kind of the use case for this talk and that's monitoring so it's been too long on this but I",
    "start": "200130",
    "end": "208269"
  },
  {
    "text": "think it bit of background is kind of useful so I'm monitoring what we were",
    "start": "208269",
    "end": "216040"
  },
  {
    "text": "interested in taking load of information from those racks and racks of servers we've got for the software the hardware",
    "start": "216040",
    "end": "222540"
  },
  {
    "text": "and presenting it in some way so people can see when things go wrong and draw",
    "start": "222540",
    "end": "229959"
  },
  {
    "text": "pretty graphs and it's kind of important for a number of reasons",
    "start": "229959",
    "end": "236430"
  },
  {
    "text": "so fault finding and alerting so I know one thing goes things go wrong and we need to fix things and for post-mortem",
    "start": "236430",
    "end": "243790"
  },
  {
    "text": "and preemption so in the keynote this morning we were told that when we have a failure the",
    "start": "243790",
    "end": "249770"
  },
  {
    "text": "most important thing we can do with a failure is learn as much as we possibly can and the way we can learn as much as",
    "start": "249770",
    "end": "255830"
  },
  {
    "text": "we possibly can but having as much historical information as possible before whatever went wrong went wrong",
    "start": "255830",
    "end": "263739"
  },
  {
    "text": "utilization analysis efficiency analysis so how well are we using the hardware",
    "start": "264430",
    "end": "269930"
  },
  {
    "text": "that we spend you know tens of millions of dollars by performance monitoring",
    "start": "269930",
    "end": "275720"
  },
  {
    "text": "profiling auditing and so making sure",
    "start": "275720",
    "end": "282560"
  },
  {
    "text": "that people using the system that are allowed to use a system and and decision-making so future planning my",
    "start": "282560",
    "end": "288919"
  },
  {
    "text": "current system is this big how big need to be in a year site so the common",
    "start": "288919",
    "end": "295220"
  },
  {
    "start": "293000",
    "end": "464000"
  },
  {
    "text": "components of these kind of systems you often get these sort of systems that do checking and alerting their ping things",
    "start": "295220",
    "end": "302770"
  },
  {
    "text": "check that there's no disk errors that kind of thing so log collections big one",
    "start": "302890",
    "end": "310610"
  },
  {
    "text": "these days and certainly gets a lot of press so all of the logs from all of your hundred or thousand servers put in",
    "start": "310610",
    "end": "317630"
  },
  {
    "text": "one place so you can index them or search them and then metric collection",
    "start": "317630",
    "end": "324919"
  },
  {
    "text": "so historical CPU usage or disk boosted for example so why was my disk full",
    "start": "324919",
    "end": "333010"
  },
  {
    "text": "answering that kind of question so the kind of incumbents in this space I Tinga",
    "start": "333010",
    "end": "340460"
  },
  {
    "text": "or Nagios some of you might have used this kind of thing does things like ping services check that HTTP endpoints are",
    "start": "340460",
    "end": "347930"
  },
  {
    "text": "available gives you a little dashboard and I'll nag you at 2:00 in the morning telling you something's gone down and",
    "start": "347930",
    "end": "353450"
  },
  {
    "text": "you need to reach the coffee cabana it's quite popular these days coming with",
    "start": "353450",
    "end": "360260"
  },
  {
    "text": "your search engine full of your logs ganglia probably less well-known it's",
    "start": "360260",
    "end": "369470"
  },
  {
    "text": "very big in HPC space and it's been around quite a long time as well in this",
    "start": "369470",
    "end": "374539"
  },
  {
    "text": "space I don't think it used to look this pretty bow this is actually Wikipedia's monitoring",
    "start": "374539",
    "end": "380820"
  },
  {
    "text": "system so if you go to a quick Wikimedia gangee adult wikimedia org you can go",
    "start": "380820",
    "end": "386910"
  },
  {
    "text": "and look at what all their cpus up to fascinating most hours i've been a hotel",
    "start": "386910",
    "end": "391980"
  },
  {
    "text": "room doing this very late at night so lobby probably seen this graph on a--",
    "start": "391980",
    "end": "400560"
  },
  {
    "text": "quite popular tool similar kind of thing plots graphs for you very pretty and",
    "start": "400560",
    "end": "405870"
  },
  {
    "text": "always wins points with kind of executive level people and but the",
    "start": "405870",
    "end": "411330"
  },
  {
    "text": "profile doesn't actually store any data for use especially collect any dates just a front end so what you need is you",
    "start": "411330",
    "end": "417930"
  },
  {
    "text": "need a database to store all of the data that you wanna graph so you've got a few",
    "start": "417930",
    "end": "423450"
  },
  {
    "text": "choices in this regard and so this list I wrote beginning of this year I'm sure",
    "start": "423450",
    "end": "430590"
  },
  {
    "text": "there's more and I'm sure there's more kind of obscure open source projects as well but haven't listed here and there's",
    "start": "430590",
    "end": "438420"
  },
  {
    "text": "definitely a big list of proprietary ones that haven't listed here but these aren't small projects they've actually",
    "start": "438420",
    "end": "444360"
  },
  {
    "text": "got backing from some quite big companies they were like SoundCloud and",
    "start": "444360",
    "end": "451070"
  },
  {
    "text": "Rackspace and Netflix and Spotify they've all decided to write their own time-series metrics database for this",
    "start": "451070",
    "end": "458460"
  },
  {
    "text": "particular problem",
    "start": "458460",
    "end": "461030"
  },
  {
    "text": "so as I said before ganglia kind of came into existence around 2000 particularly",
    "start": "464150",
    "end": "473070"
  },
  {
    "text": "in HPC space but some as well and graphite is kind of just a database and",
    "start": "473070",
    "end": "478740"
  },
  {
    "text": "that kind of emerged about 2010 and then about 2013 just get this huge kind of",
    "start": "478740",
    "end": "488340"
  },
  {
    "text": "space of development of all of these new time series databases as follows you've",
    "start": "488340",
    "end": "495540"
  },
  {
    "text": "probably heard of in there Prometheus perhaps in flux DB open psdb",
    "start": "495540",
    "end": "503630"
  },
  {
    "start": "504000",
    "end": "835000"
  },
  {
    "text": "so a bit more background so this system",
    "start": "505410",
    "end": "510900"
  },
  {
    "text": "might kind of look familiar to you it's something that we're working on or",
    "start": "510900",
    "end": "516159"
  },
  {
    "text": "something that we've sort of taken on from some other people so we've got some stuff that's producing some metrics for",
    "start": "516160",
    "end": "522340"
  },
  {
    "text": "us and some log files we've kind of got this middleware in the middle that gives",
    "start": "522340",
    "end": "527380"
  },
  {
    "text": "us this HTTP API and does some alerting force ever it's trying to build a sort",
    "start": "527380",
    "end": "535030"
  },
  {
    "text": "of an all-encompassing monitoring system so we've got the checking the logging and the metrics all in one system so we",
    "start": "535030",
    "end": "540640"
  },
  {
    "text": "can do some information sort of analysis with that so this middleware has a my sequel",
    "start": "540640",
    "end": "546610"
  },
  {
    "text": "database so if you use I tingle or Nagios you might have a database collecting history for you the metrics",
    "start": "546610",
    "end": "555400"
  },
  {
    "text": "at the moment we're taking putting them in influx DB and could replace that with",
    "start": "555400",
    "end": "560650"
  },
  {
    "text": "any one of the other open source products we saw me again and that's got",
    "start": "560650",
    "end": "565990"
  },
  {
    "text": "good Farnum on top so you can graph things the father has a database which stores dashboards and state and now I",
    "start": "565990",
    "end": "573790"
  },
  {
    "text": "think it can store alarm state as well as of the most recent version so that's got sequel Lite in it the logs go",
    "start": "573790",
    "end": "581110"
  },
  {
    "text": "through thing called log stats which probably heard of go into elastic I've got cabana as the front-end some people",
    "start": "581110",
    "end": "589660"
  },
  {
    "text": "then wanted to put a message queue in the middle so we've got Casca there it's just for fun and it's all the logs and",
    "start": "589660",
    "end": "597070"
  },
  {
    "text": "gopher and yeah all this is done for good reason I'm not knocking any of it people need to be able to handle huge",
    "start": "597070",
    "end": "602650"
  },
  {
    "text": "rates of logs and bursty kind of data so that's a good thing Africa is great with",
    "start": "602650",
    "end": "609580"
  },
  {
    "text": "technology for all of so if a couple of these things we need a zookeeper database as well it's actually still",
    "start": "609580",
    "end": "616720"
  },
  {
    "text": "much data in there but it's needed for coordinating the others and then in",
    "start": "616720",
    "end": "623020"
  },
  {
    "text": "particular system and we've also got a patchy storm which is like a stream processing framework and that takes data",
    "start": "623020",
    "end": "628570"
  },
  {
    "text": "from Kafka and creates alerts and creates events in my sequel for you so",
    "start": "628570",
    "end": "634120"
  },
  {
    "text": "this anything to do with what our systems actually doing this is just the monitoring for the systems right I mean",
    "start": "634120",
    "end": "642810"
  },
  {
    "text": "some of you should be thinking hold on then we need a monitoring system for this monitoring system well you probably",
    "start": "642810",
    "end": "649560"
  },
  {
    "text": "do and and the thing that worries me the most about these kind of systems is that",
    "start": "649560",
    "end": "656160"
  },
  {
    "text": "there's six places in it which store data six persistent storage areas my",
    "start": "656160",
    "end": "663120"
  },
  {
    "text": "frequent flux Kefka elastic zookeeper as you could like and if you lose any of",
    "start": "663120",
    "end": "668730"
  },
  {
    "text": "that data the whole system kind of gets in a bit of a mess so as I said this is",
    "start": "668730",
    "end": "676920"
  },
  {
    "text": "commendable kind of right job right tool for the job attitude not knocking at all and works very well lots people use it",
    "start": "676920",
    "end": "684290"
  },
  {
    "text": "but could we at least unify the persistence of the system",
    "start": "684290",
    "end": "691550"
  },
  {
    "text": "fewer failure modes which have fewer backup strategies we need to worry about",
    "start": "692990",
    "end": "698580"
  },
  {
    "text": "if you're monitoring a business critical system and you're monitoring goes down",
    "start": "698580",
    "end": "705060"
  },
  {
    "text": "how do you know your business critical system isn't down your monitoring system is as critical as any other system you",
    "start": "705060",
    "end": "712230"
  },
  {
    "text": "run so needs backup fewer replication protocols if anyone's",
    "start": "712230",
    "end": "718350"
  },
  {
    "text": "ever dealt with sequel databases or any databases and try to replicate them things go wrong and they're all",
    "start": "718350",
    "end": "726180"
  },
  {
    "text": "different so one set of consistent data semantics yeah so a lot of these new",
    "start": "726180",
    "end": "733200"
  },
  {
    "text": "sequel know sequel databases some of them have acid some of them are",
    "start": "733200",
    "end": "738750"
  },
  {
    "text": "eventually consistent you've got to go and learn in each one of those what it",
    "start": "738750",
    "end": "744420"
  },
  {
    "text": "does and the most important one for me is you can reuse existing operational",
    "start": "744420",
    "end": "749670"
  },
  {
    "text": "knowledge now you probably already got somebody in your business that knows about my sequel or post careers or",
    "start": "749670",
    "end": "755360"
  },
  {
    "text": "sequel server why don't you just use that knowledge for something else so",
    "start": "755360",
    "end": "762690"
  },
  {
    "text": "this is our idea okay could we at least sort of unify the persistence",
    "start": "762690",
    "end": "767760"
  },
  {
    "text": "and could all this problem is is just data storage and NASA's problem and we",
    "start": "767760",
    "end": "773730"
  },
  {
    "text": "happen to know a bit about postcode so we thought let's use that we like Postgres people use papers and you know",
    "start": "773730",
    "end": "781709"
  },
  {
    "text": "we don't have to do it like this you know it can be microwave services so it's early have to be one big instance",
    "start": "781709",
    "end": "787529"
  },
  {
    "text": "you know because that's that's bad we don't do that anymore we don't have one big database we have lots of little ones",
    "start": "787529",
    "end": "792540"
  },
  {
    "text": "and that's fine you know maybe we have one to make sure to hunt for logs on for alerting so we still have that",
    "start": "792540",
    "end": "800310"
  },
  {
    "text": "separation but what we're using is a common technology for all of this storage so postcodes can do a lot of",
    "start": "800310",
    "end": "807209"
  },
  {
    "text": "good things and it can act like a lot of databases little these kind of no sequel",
    "start": "807209",
    "end": "813089"
  },
  {
    "text": "database it can add you can have JSON in it you can do text searching in it you can do searching within JSON and you can",
    "start": "813089",
    "end": "821399"
  },
  {
    "text": "of course have your normal kind of crud style data in there and we can't do time series we've just seen a list of 20",
    "start": "821399",
    "end": "828660"
  },
  {
    "text": "databases that were kind of produced for this purpose and so time series bit of a",
    "start": "828660",
    "end": "840750"
  },
  {
    "start": "835000",
    "end": "1153000"
  },
  {
    "text": "background about time series bit of information so periodic time series the",
    "start": "840750",
    "end": "847500"
  },
  {
    "text": "awesome collector maybe it's collecting CPU usage maybe it's collecting temperature maybe it's collecting rainfall maybe it's the next IOT gadget",
    "start": "847500",
    "end": "857160"
  },
  {
    "text": "collecting something as data's gonna have a time as can have a value in CPU",
    "start": "857160",
    "end": "866279"
  },
  {
    "text": "usage maybe we've got some percentages like that it comes in quite regularly so",
    "start": "866279",
    "end": "872579"
  },
  {
    "text": "every minute every second every 100 milliseconds some fixed resolution",
    "start": "872579",
    "end": "879680"
  },
  {
    "text": "what happened sorry okay so what you",
    "start": "886900",
    "end": "899000"
  },
  {
    "text": "might have and in fact what you more commonly have is multiple collectors",
    "start": "899000",
    "end": "904930"
  },
  {
    "text": "selecting different metrics so every second or every minute you'll get clean",
    "start": "904930",
    "end": "911480"
  },
  {
    "text": "attrex three values so to distinguish from these we have some meta data so we",
    "start": "911480",
    "end": "917330"
  },
  {
    "text": "say I actually Stu or a CPU usage and these to a temperature and this is I",
    "start": "917330",
    "end": "923950"
  },
  {
    "text": "wouldn't say it's kind of the standard but it's definitely a popular way but a lot of these databases store this data",
    "start": "923950",
    "end": "930940"
  },
  {
    "text": "and we have this kind of dimensions or tags you sometimes see it called and you can tag it with one or more bits of",
    "start": "930940",
    "end": "937550"
  },
  {
    "text": "extra information so you can say well actually this is a separate metric so it's on a different host or in a",
    "start": "937550",
    "end": "943310"
  },
  {
    "text": "different data center something like that and then every time period you get",
    "start": "943310",
    "end": "951490"
  },
  {
    "text": "one of these readings and the time the period might not be the same but you can",
    "start": "951490",
    "end": "956750"
  },
  {
    "text": "get the idea you then have this kind of sporadic version of time series where",
    "start": "956750",
    "end": "963760"
  },
  {
    "text": "data sort of comes in whenever it feels like and in this case you might actually",
    "start": "963760",
    "end": "970100"
  },
  {
    "text": "want to store some extra metadata so maybe you've got some maybe you want to",
    "start": "970100",
    "end": "975800"
  },
  {
    "text": "send some event every time you get a big chunk of logs and you want to record the message alongside it or maybe you've got",
    "start": "975800",
    "end": "984410"
  },
  {
    "text": "some alarms going off and you want to store the reason that the alarm we're",
    "start": "984410",
    "end": "992450"
  },
  {
    "text": "not going to focus too much on this today because I kind of think even though a lot of people are thinking that this is a good application for time",
    "start": "992450",
    "end": "998630"
  },
  {
    "text": "series database I don't think it's the most interesting one",
    "start": "998630",
    "end": "1003930"
  },
  {
    "text": "okay what sort of data gets into this system so at least in the system we're",
    "start": "1004320",
    "end": "1015970"
  },
  {
    "text": "working on JSON is the is the King in the moment luckily we kind of kicked the XML habit which I'm absolutely thrilled",
    "start": "1015970",
    "end": "1021910"
  },
  {
    "text": "about and with JSON is king so everything's JSON got time stamp",
    "start": "1021910",
    "end": "1028870"
  },
  {
    "text": "suddenly matter what format you know we happen to send them around in unix time but it could be anything else the value",
    "start": "1028870",
    "end": "1037558"
  },
  {
    "text": "say 42 is good number as we learnt earlier they've got the information that",
    "start": "1037559",
    "end": "1043600"
  },
  {
    "text": "identifies the metric so you got the name and dimension or tags as they're called so a CP percentage for host dev",
    "start": "1043600",
    "end": "1051809"
  },
  {
    "text": "and there's that extra metadata field which is kind of optional and we're not",
    "start": "1051809",
    "end": "1057370"
  },
  {
    "text": "gonna worry too much about that but it's there it's kind of payload so what sort",
    "start": "1057370",
    "end": "1063940"
  },
  {
    "text": "of queries do you want to do on this data well we want to take some of this",
    "start": "1063940",
    "end": "1069040"
  },
  {
    "text": "data maybe want to take one of the series maybe want the temperature for this rack on your graph maybe you want",
    "start": "1069040",
    "end": "1077830"
  },
  {
    "text": "to take CPU usage for those two hosts draw them on a graph something which is",
    "start": "1077830",
    "end": "1087340"
  },
  {
    "text": "important about these queries we're doing is that we don't always want our entire data set so we could be storing",
    "start": "1087340",
    "end": "1094960"
  },
  {
    "text": "weeks months of this data we only want a few minutes of it maybe over the last",
    "start": "1094960",
    "end": "1100270"
  },
  {
    "text": "five minutes so we want all the queries are bound by some time range so this clear is kind of",
    "start": "1100270",
    "end": "1110500"
  },
  {
    "text": "important so we want to think about how we're going to how it's going to perform",
    "start": "1110500",
    "end": "1115690"
  },
  {
    "text": "as we scale all various things in the system so we want to grow the volume in",
    "start": "1115690",
    "end": "1121540"
  },
  {
    "text": "the system maybe today we want to store days of day of data maybe tomorrow one two days or a week or",
    "start": "1121540",
    "end": "1127000"
  },
  {
    "text": "a month and the number of metrics might change new hosts might come online new data centers might come online we want",
    "start": "1127000",
    "end": "1133210"
  },
  {
    "text": "to monitor them and quickly complexity is quite an important thing to consider in",
    "start": "1133210",
    "end": "1139070"
  },
  {
    "text": "particular the time range are actually clearing so if you want to clear you the",
    "start": "1139070",
    "end": "1145429"
  },
  {
    "text": "complexity of a query to query the second of data is a lot different including a day of data so how does this",
    "start": "1145429",
    "end": "1155090"
  },
  {
    "start": "1153000",
    "end": "1541000"
  },
  {
    "text": "map in the relational world quite easily",
    "start": "1155090",
    "end": "1160880"
  },
  {
    "text": "just map it like that just put it in",
    "start": "1160880",
    "end": "1167270"
  },
  {
    "text": "table need two rows a measurement might not be a good idea some of you might be crying right now but it's a start so in",
    "start": "1167270",
    "end": "1177169"
  },
  {
    "text": "Postgres just use time temps tzd the time points if you want to represent a point in time",
    "start": "1177169",
    "end": "1183320"
  },
  {
    "text": "just use time time stampeded its UTC and when daylight savings happens it won't",
    "start": "1183320",
    "end": "1190220"
  },
  {
    "text": "hurt you value um",
    "start": "1190220",
    "end": "1195289"
  },
  {
    "text": "floating point is quite popular for this if you're doing anything in this regard",
    "start": "1195289",
    "end": "1201320"
  },
  {
    "text": "we have anything that needs really strict accuracy using numeric for that in Postgres it's a decimal type so if",
    "start": "1201320",
    "end": "1208669"
  },
  {
    "text": "you're doing things with money like adding nought point one a naught point one will give you not point two so important things like that",
    "start": "1208669",
    "end": "1216200"
  },
  {
    "text": "or in this case it's just temperatures and CPUs it doesn't matter too much for",
    "start": "1216200",
    "end": "1222860"
  },
  {
    "text": "Strings just use Viator our fixed length datatypes don't really matter in Postgres and even though they think in",
    "start": "1222860",
    "end": "1229460"
  },
  {
    "text": "any database anymore the way postcodes handles updates means that you don't",
    "start": "1229460",
    "end": "1235370"
  },
  {
    "text": "really get any benefit from having a fixed size field such a postcode has a",
    "start": "1235370",
    "end": "1241909"
  },
  {
    "text": "json b type which is pretty cool and so I can store arbitrary JSON but it can",
    "start": "1241909",
    "end": "1248659"
  },
  {
    "text": "also let you clearly inside it and search for things inside that JSON really efficiently so it's a binary",
    "start": "1248659",
    "end": "1254179"
  },
  {
    "text": "encoding so it's a bit more compact but it also has just a JSON encoding as well",
    "start": "1254179",
    "end": "1260360"
  },
  {
    "text": "and really all this is just text field which is validated and this is fine",
    "start": "1260360",
    "end": "1267640"
  },
  {
    "text": "if we don't want to actually do any processing on it it's just payload and that applies to our value matter so the",
    "start": "1267640",
    "end": "1276549"
  },
  {
    "text": "other sort of query will do and if we want to get a listing of the series",
    "start": "1276549",
    "end": "1281679"
  },
  {
    "text": "potentially an ugly dwell on this too much because it's really not very interesting you select four distinct",
    "start": "1281679",
    "end": "1286990"
  },
  {
    "text": "things in the table we just showed it's going to be horrific ly slow but we'll",
    "start": "1286990",
    "end": "1293559"
  },
  {
    "text": "fix that bit later and we can actually filter it so we can say actually give me all the metrics for this name so give me",
    "start": "1293559",
    "end": "1302380"
  },
  {
    "text": "all the series I can look at for the CPU we could say give me all the metrics I",
    "start": "1302380",
    "end": "1308620"
  },
  {
    "text": "can look out for this host kind of interesting things to know so this is",
    "start": "1308620",
    "end": "1317169"
  },
  {
    "text": "the interesting one the actual query that we're going to kind of focus on for the rest of the talk so we're going to",
    "start": "1317169",
    "end": "1323590"
  },
  {
    "text": "find some measurements from our table and we want to specify a time range and",
    "start": "1323590",
    "end": "1331380"
  },
  {
    "text": "we want to say what series name we're looking at anyone to say what tags we",
    "start": "1331380",
    "end": "1337120"
  },
  {
    "text": "want so we want the CPU percentage for that particular host all very good now",
    "start": "1337120",
    "end": "1346870"
  },
  {
    "text": "we're going to aggregate the data points to some periods because we're going to just assume we're visualizing this data we want to point every 10 seconds or",
    "start": "1346870",
    "end": "1353530"
  },
  {
    "text": "every 60 seconds so we can take the average over that particular time period",
    "start": "1353530",
    "end": "1359250"
  },
  {
    "text": "and we just got a little help function called time round which does that for us and this is an actual native in",
    "start": "1359250",
    "end": "1365650"
  },
  {
    "text": "postcards but you can google it it's not very interesting",
    "start": "1365650",
    "end": "1370860"
  },
  {
    "text": "and then we group by that interval and take it up at rally this is kind of like",
    "start": "1370860",
    "end": "1377650"
  },
  {
    "text": "the most basic time series query you ever want to do",
    "start": "1377650",
    "end": "1382260"
  },
  {
    "text": "so what we concerned about was this query but we can tell about how long it takes and in particular but concerns",
    "start": "1384940",
    "end": "1393230"
  },
  {
    "text": "about how long it takes when our data grows so the data volume increases calendar the query take and how long",
    "start": "1393230",
    "end": "1400370"
  },
  {
    "text": "does it take as we expand the time range so we want to clearly one day of data where we also",
    "start": "1400370",
    "end": "1405950"
  },
  {
    "text": "want a view of the last month of data and we want those to be just as quick as",
    "start": "1405950",
    "end": "1411590"
  },
  {
    "text": "each other and really our target for this is 100 milliseconds now I'm not much for UI developer but 100",
    "start": "1411590",
    "end": "1418940"
  },
  {
    "text": "millisecond just kind of the magic number that you can trick humans into thinking something is instantaneous so",
    "start": "1418940",
    "end": "1424100"
  },
  {
    "text": "if you can get something to happen when they click a button what happens in 100 milliseconds we kind of think oh that",
    "start": "1424100",
    "end": "1429950"
  },
  {
    "text": "happened straightaway fantastic and it's a nice round number as well so that's",
    "start": "1429950",
    "end": "1435590"
  },
  {
    "text": "what we're aiming for so this kind of red area on all the graphs this is the danger zone that we don't want to get",
    "start": "1435590",
    "end": "1440960"
  },
  {
    "text": "get into so for our relational model we",
    "start": "1440960",
    "end": "1449000"
  },
  {
    "text": "don't actually start off very good so we got so what we're looking at here is as",
    "start": "1449000",
    "end": "1454210"
  },
  {
    "text": "we expand the time range that we're querying so these are in seconds so we're creating a thousand seconds and",
    "start": "1454210",
    "end": "1460159"
  },
  {
    "text": "two thousand three thousand example and I've got three different series here",
    "start": "1460159",
    "end": "1467590"
  },
  {
    "text": "four different volumes of the database what we can actually see is the query doesn't matter what range we're clearing",
    "start": "1467590",
    "end": "1474620"
  },
  {
    "text": "from the data still takes the same time but if we increase the amount of data in the database us when it starts to slow",
    "start": "1474620",
    "end": "1482299"
  },
  {
    "text": "down so if we turn this on its head and",
    "start": "1482299",
    "end": "1488330"
  },
  {
    "text": "instead graph this so data volume now",
    "start": "1488330",
    "end": "1493360"
  },
  {
    "text": "you can see that it goes up query gets a lot slower as we put more data in what's",
    "start": "1493360",
    "end": "1499370"
  },
  {
    "text": "interesting is we can actually be okay if we were sort of under a million rows and so we could probably scan over a",
    "start": "1499370",
    "end": "1505580"
  },
  {
    "text": "hundred million rows display a million rows not hundred million in less than 100 milliseconds",
    "start": "1505580",
    "end": "1513179"
  },
  {
    "text": "so I guess a good thing about this is the query times fixed regardless of time",
    "start": "1513179",
    "end": "1518409"
  },
  {
    "text": "range but and we're kind of on target for less than a million rows but time scales linearly with the volume of data",
    "start": "1518409",
    "end": "1525159"
  },
  {
    "text": "this isn't very good okay we want to store increasing amounts of data in our database and this is because every query",
    "start": "1525159",
    "end": "1532720"
  },
  {
    "text": "we do needs to read the entire table so",
    "start": "1532720",
    "end": "1537730"
  },
  {
    "text": "anyone with any kind of knowledge of databases know where this is going so we need to do some indexing couple of",
    "start": "1537730",
    "end": "1546610"
  },
  {
    "start": "1541000",
    "end": "1591000"
  },
  {
    "text": "points so time stamps to essentially integers so I've got like fantasy about",
    "start": "1546610",
    "end": "1552429"
  },
  {
    "text": "time stamps unix time since 1980 I think postcode stores it a little bit differently but Postgres has many",
    "start": "1552429",
    "end": "1559629"
  },
  {
    "text": "different types of index and be three hash bringe in gist's there's also one",
    "start": "1559629",
    "end": "1565029"
  },
  {
    "text": "called run I think which is going to be available soon I think gin and rum were made by a",
    "start": "1565029",
    "end": "1572049"
  },
  {
    "text": "certain group of Russian post players developers as I've met a couple of them at the conferences and they're very",
    "start": "1572049",
    "end": "1578590"
  },
  {
    "text": "interesting people very clever people as well so each was excellent for the quality in",
    "start": "1578590",
    "end": "1586509"
  },
  {
    "text": "between operations so that's worth bearing in mind so a bit of b-tree",
    "start": "1586509",
    "end": "1592750"
  },
  {
    "start": "1591000",
    "end": "1739000"
  },
  {
    "text": "revision who's familiar with b-trees a couple people okay well you can all check your email while I do this I'll",
    "start": "1592750",
    "end": "1598990"
  },
  {
    "text": "just give it a quick overview for beach views for everyone else so you got some table there's some data in the table",
    "start": "1598990",
    "end": "1605970"
  },
  {
    "text": "it's all jumbled up still bit of a mess post pro split split data into pages",
    "start": "1605970",
    "end": "1610980"
  },
  {
    "text": "they not to be too concerned at that but it does the index is a separate structure and at the root of the",
    "start": "1610980",
    "end": "1618429"
  },
  {
    "text": "structure there's page of data so impose this the number of things in this page",
    "start": "1618429",
    "end": "1623769"
  },
  {
    "text": "vary and but in this example just shown it to and that contains some of the",
    "start": "1623769",
    "end": "1631029"
  },
  {
    "text": "midpoints of the data and then just a classic tree structure so all the values",
    "start": "1631029",
    "end": "1638500"
  },
  {
    "text": "less than three go to a separate page which is pointed to all those between three and six or in their page and all",
    "start": "1638500",
    "end": "1645700"
  },
  {
    "text": "those between over six different page and all those",
    "start": "1645700",
    "end": "1651559"
  },
  {
    "text": "point to the actual data so when we query we can say seven we're looking for",
    "start": "1651559",
    "end": "1658100"
  },
  {
    "text": "number seven is seven greater than three yesterday's of the greater than six yesterday's da da",
    "start": "1658100",
    "end": "1664399"
  },
  {
    "text": "go down that road oh look we found seven there's our data the more interesting",
    "start": "1664399",
    "end": "1671390"
  },
  {
    "text": "thing it can do is if you're looking for all the values between 6 & 8 so I think",
    "start": "1671390",
    "end": "1677029"
  },
  {
    "text": "timestamps you can say well 6 is greater than 3 okay we found 6 great I'm going to get",
    "start": "1677029",
    "end": "1684860"
  },
  {
    "text": "the data for 6 it just have to go back and do another look up because the",
    "start": "1684860",
    "end": "1690080"
  },
  {
    "text": "b-trees ordered so if it needs if it's looking for all the values before 8 just",
    "start": "1690080",
    "end": "1696110"
  },
  {
    "text": "walks the bee tree and just finds seven and goes on finds 8 really efficient so",
    "start": "1696110",
    "end": "1704720"
  },
  {
    "text": "that one bee tree look up now imagine this is two or three pages so two or three disk i/os after that to get the",
    "start": "1704720",
    "end": "1713659"
  },
  {
    "text": "entire time range you just walking through this index really really efficient so with that in mind let's",
    "start": "1713659",
    "end": "1723080"
  },
  {
    "text": "look at our query and we've got a between predicate good and this eliminates huge amounts of the table so",
    "start": "1723080",
    "end": "1729500"
  },
  {
    "text": "if you've got six months of data we want five minutes this is a really selected predator so it's an excellent Camden",
    "start": "1729500",
    "end": "1736159"
  },
  {
    "text": "candidate for index so we do this great",
    "start": "1736159",
    "end": "1742460"
  },
  {
    "start": "1739000",
    "end": "1831000"
  },
  {
    "text": "index on table using B tree imposed rows B trees the default C then have to say",
    "start": "1742460",
    "end": "1748309"
  },
  {
    "text": "that kind of using it here explicitly and you say we want to index on",
    "start": "1748309",
    "end": "1754190"
  },
  {
    "text": "timestamp so this is a lot better so graft here",
    "start": "1754190",
    "end": "1763820"
  },
  {
    "text": "there was all we had before without an index and graph here and yellow with the",
    "start": "1763820",
    "end": "1770390"
  },
  {
    "text": "index its staggeringly better as you might imagine",
    "start": "1770390",
    "end": "1775450"
  },
  {
    "text": "so we zoom in a little bit on that we can see we're well into our gold and",
    "start": "1776320",
    "end": "1782110"
  },
  {
    "text": "it's kind of Felicity's volume so as the volume increases there is still a bit of",
    "start": "1782110",
    "end": "1788299"
  },
  {
    "text": "an increase as we increase the time range but not very much so if we put",
    "start": "1788299",
    "end": "1793640"
  },
  {
    "text": "time range back at the bottom we can see it's creeping up so that's something to be aware of but we're definitely a lot",
    "start": "1793640",
    "end": "1799730"
  },
  {
    "text": "better off and so now I'm going to introduce we've had one metric up until now now let's say we've got ten",
    "start": "1799730",
    "end": "1805880"
  },
  {
    "text": "different metrics in the system so every tenth row and kind of a different metric",
    "start": "1805880",
    "end": "1815679"
  },
  {
    "text": "unfortunately if we go up to 100 metrics this problem kind of exacerbates itself even more and we definitely want more",
    "start": "1817840",
    "end": "1823909"
  },
  {
    "text": "than 100 metrics maybe one a thousand maybe 10,000 so we kind of back in the",
    "start": "1823909",
    "end": "1829190"
  },
  {
    "text": "danger zones that's not good so we find that fine up to 10 million and we find",
    "start": "1829190",
    "end": "1834770"
  },
  {
    "start": "1831000",
    "end": "1896000"
  },
  {
    "text": "up to 9,000 seconds with 10 metrics and the clue times stable is the data volume",
    "start": "1834770",
    "end": "1840799"
  },
  {
    "text": "increases this is a big win over where we were this might you know it's might",
    "start": "1840799",
    "end": "1846080"
  },
  {
    "text": "seem straightforward it's worth understanding especially if you want to build more complicated systems the time",
    "start": "1846080",
    "end": "1852590"
  },
  {
    "text": "range kind of falls over with 100 metrics and it's now apparent that the",
    "start": "1852590",
    "end": "1857960"
  },
  {
    "text": "query duration actually increases the time range grows so it's no longer increasing as the data volume grows its increasing as the time range grows yeah",
    "start": "1857960",
    "end": "1870180"
  },
  {
    "text": "so the reason why these metrics causing such a problem is because there's now",
    "start": "1870180",
    "end": "1875580"
  },
  {
    "text": "more data to filter out before we can find the interesting stuff so what could",
    "start": "1875580",
    "end": "1881190"
  },
  {
    "text": "we do Wow we could do more indexing so there's two other clauses in here and if you kind of",
    "start": "1881190",
    "end": "1888720"
  },
  {
    "text": "really optimizing databases 101 it will say go and look at your where clause and add indexes for the things in your where",
    "start": "1888720",
    "end": "1894450"
  },
  {
    "text": "clause so we can do that and we can create a couple more indexes on the",
    "start": "1894450",
    "end": "1901410"
  },
  {
    "start": "1896000",
    "end": "1961000"
  },
  {
    "text": "measurements table so on name we're just doing a quality so you can use be tree",
    "start": "1901410",
    "end": "1908630"
  },
  {
    "text": "for the JSON field we can actually use this gin index I'm not going to go into",
    "start": "1908930",
    "end": "1913950"
  },
  {
    "text": "any detail about this but this is a really cool index and this is the thing that lets you find any key value in your",
    "start": "1913950",
    "end": "1919410"
  },
  {
    "text": "JSON using an index in adjacent column it's really cool could do a whole talk",
    "start": "1919410",
    "end": "1925800"
  },
  {
    "text": "amount so we're not going to go into that the problem is now we've added",
    "start": "1925800",
    "end": "1931170"
  },
  {
    "text": "these indexes we've actually made it worse so that yellow line there is with the extra indexes but you can see the",
    "start": "1931170",
    "end": "1938910"
  },
  {
    "text": "lying I actually just dips under so we're",
    "start": "1938910",
    "end": "1944400"
  },
  {
    "text": "going in the right direction here and if we kind of extrapolated this that red line would go up linearly and that yellow line would sort of start to",
    "start": "1944400",
    "end": "1950970"
  },
  {
    "text": "flatten out a bit so as the volume at the time rain grows in the query we're actually having a positive effect but",
    "start": "1950970",
    "end": "1957620"
  },
  {
    "text": "too much indexing can be kind of harmful so next step in databases 101",
    "start": "1957620",
    "end": "1965190"
  },
  {
    "start": "1961000",
    "end": "2225000"
  },
  {
    "text": "normalization to those people that were crying earlier about my table design can",
    "start": "1965190",
    "end": "1971580"
  },
  {
    "text": "now hopefully take a little relief so we take our measurements and we split into",
    "start": "1971580",
    "end": "1977010"
  },
  {
    "text": "two tables one table just stores our values so in that table what we're going",
    "start": "1977010",
    "end": "1983640"
  },
  {
    "text": "to do is going to take a timestamp the value in that metadata and put that in there and for the metrics we're going to",
    "start": "1983640",
    "end": "1991830"
  },
  {
    "text": "take the information that identifies the metrics name and dimensions put them in",
    "start": "1991830",
    "end": "1997200"
  },
  {
    "text": "there the way we referenced the metric is with",
    "start": "1997200",
    "end": "2004730"
  },
  {
    "text": "an idea my expect and that reference is a metric in that table so these are you",
    "start": "2004730",
    "end": "2013009"
  },
  {
    "text": "stored once and what we've done is we've removed a huge amount of data from that",
    "start": "2013009",
    "end": "2018440"
  },
  {
    "text": "values tables that tables are not smaller and because we've only got that one thing identifying metrics we can",
    "start": "2018440",
    "end": "2025509"
  },
  {
    "text": "eliminate a lot of data in that table and this makes it a lot more efficient to read so the metric table defines the",
    "start": "2025509",
    "end": "2033019"
  },
  {
    "text": "identifier and you can use a serial in place code to do that as I'm sure you can in most databases we then have this",
    "start": "2033019",
    "end": "2041119"
  },
  {
    "text": "unique car constraint because we only want to have one ID for each set of name",
    "start": "2041119",
    "end": "2046129"
  },
  {
    "text": "and dimensions and this handily creates the correct index force so when we're not deep and we're normalizing our data",
    "start": "2046129",
    "end": "2052190"
  },
  {
    "text": "the right index is in place for us so we",
    "start": "2052190",
    "end": "2057679"
  },
  {
    "text": "can make this data make these two tables mimic the measurements table we had",
    "start": "2057679",
    "end": "2063108"
  },
  {
    "text": "start with a view and these are defined by just a query so we can say when you",
    "start": "2063109",
    "end": "2070368"
  },
  {
    "text": "query this actually do this and give that data back instead and what this",
    "start": "2070369",
    "end": "2077270"
  },
  {
    "text": "does is it just joins the two tables together on our ID and our query doesn't have to worry about any of that",
    "start": "2077270",
    "end": "2082908"
  },
  {
    "text": "splitting out we just did and in fact if you look at the query plans if you manually write the join and if you write",
    "start": "2082909",
    "end": "2089118"
  },
  {
    "text": "the query against the view you'll see they're exactly the same so you lose nothing by clearing the view and having",
    "start": "2089119",
    "end": "2095059"
  },
  {
    "text": "this layer in front other than that your queries are simpler to read so it's",
    "start": "2095059",
    "end": "2100849"
  },
  {
    "text": "really good so we can do a bit more trickery as well",
    "start": "2100849",
    "end": "2106200"
  },
  {
    "text": "just to make a life bit easier so we can say the problem with the view is we",
    "start": "2106200",
    "end": "2111210"
  },
  {
    "text": "can't insert into it because it's a view it's sort of a read-only representation of this query that we've specified but",
    "start": "2111210",
    "end": "2120210"
  },
  {
    "text": "what we can do is we can say on this view when somebody doesn't insert to it",
    "start": "2120210",
    "end": "2125700"
  },
  {
    "text": "do something else and in this case what we'll do is we'll insert into our values",
    "start": "2125700",
    "end": "2131009"
  },
  {
    "text": "table and the only difference here is",
    "start": "2131009",
    "end": "2136410"
  },
  {
    "text": "we've got this little helper function which allocates are symmetric ID so this is essentially doing the normalization",
    "start": "2136410",
    "end": "2142619"
  },
  {
    "text": "for us but it's really transparent to the user Long's all he wants to do is insert which is all we really care about",
    "start": "2142619",
    "end": "2151160"
  },
  {
    "text": "and so I'm going to too much detail this is a lot of code and it's a bit small although this projector is fantastic so",
    "start": "2151160",
    "end": "2158640"
  },
  {
    "text": "it does actually it's almost readable I won't bore you with it though so it's a still procedure it takes in dimensions and it returns",
    "start": "2158640",
    "end": "2165210"
  },
  {
    "text": "the ID to get the ID you do that you select it if it's not found then you",
    "start": "2165210",
    "end": "2171809"
  },
  {
    "text": "insert it allocate a new one good leave",
    "start": "2171809",
    "end": "2178019"
  },
  {
    "text": "some indexing as well so timestamp index same as before and that occurs on the",
    "start": "2178019",
    "end": "2183150"
  },
  {
    "text": "values table and the we're also going to do is we're going to sort of add the",
    "start": "2183150",
    "end": "2190229"
  },
  {
    "text": "indexing on the metrics as well but instead of on the individual fields we can do it on the ID so this sort of",
    "start": "2190229",
    "end": "2195839"
  },
  {
    "text": "serves a similar purpose to what we were trying to achieve before so now when we",
    "start": "2195839",
    "end": "2200910"
  },
  {
    "text": "look at this graph again so as we grow the time range of our query the other",
    "start": "2200910",
    "end": "2207509"
  },
  {
    "text": "lines obviously would be the indexes we had before and the red one is what we've just done and unfortunately we're just",
    "start": "2207509",
    "end": "2214019"
  },
  {
    "text": "back to where we started so we started on blue or just the time indexes we",
    "start": "2214019",
    "end": "2219479"
  },
  {
    "text": "added some extra indexes and we just got back to the start again and so something's not quite right here so",
    "start": "2219479",
    "end": "2226680"
  },
  {
    "start": "2225000",
    "end": "2409000"
  },
  {
    "text": "we've eliminated that additional overhead we still don't actually have the right effect",
    "start": "2226680",
    "end": "2233298"
  },
  {
    "text": "so I'm going to explain this thing called a bitmap index scan which is what",
    "start": "2233990",
    "end": "2240349"
  },
  {
    "text": "post goes calls it so we have our two indexes and we laid the time index give",
    "start": "2240349",
    "end": "2245540"
  },
  {
    "text": "me the values between two and three and from the electric index we ask give me the values which we call to the time",
    "start": "2245540",
    "end": "2252710"
  },
  {
    "text": "index dutifully says well this one is fine this one matches this one right so this one matches good so far",
    "start": "2252710",
    "end": "2258859"
  },
  {
    "text": "make sure if index says matter to have to do that's two that's two as well and",
    "start": "2258859",
    "end": "2265089"
  },
  {
    "text": "then it combines these together and it says the rows you're actually interested",
    "start": "2265089",
    "end": "2270260"
  },
  {
    "text": "in because we're handing these two is D and F and this works quite well some of",
    "start": "2270260",
    "end": "2276500"
  },
  {
    "text": "the time it worked really badly a lot of people a lot of other times in in particular our use case what would be",
    "start": "2276500",
    "end": "2282710"
  },
  {
    "text": "better is if we just had one index that was for time and metric and we said to",
    "start": "2282710",
    "end": "2289700"
  },
  {
    "text": "it I'll give me all of the rows and match our clauses and it just tells you",
    "start": "2289700",
    "end": "2296359"
  },
  {
    "text": "that those are the ones so luckily you can do this coincidentally so our index",
    "start": "2296359",
    "end": "2303890"
  },
  {
    "text": "that we had before got a timestamp non-metric ID and what we can actually do is we could create an index on both",
    "start": "2303890",
    "end": "2311660"
  },
  {
    "text": "of these columns and you have it with one index structure they represent both these khans at the same time so if you",
    "start": "2311660",
    "end": "2317900"
  },
  {
    "text": "haven't have a query that's querying both of these columns it's indexed absolutely perfect for it we have rid of",
    "start": "2317900",
    "end": "2324500"
  },
  {
    "text": "a problem though which order do we put them in well we can either put timestamp in then metric or expert metric and then",
    "start": "2324500",
    "end": "2330890"
  },
  {
    "text": "timestamp and if you look in the documentation which I'm sure everybody reads then it will tell you that if",
    "start": "2330890",
    "end": "2338150"
  },
  {
    "text": "you've got a range Creek range predicate then you're better off putting it on the right so are the qualities on a metric",
    "start": "2338150",
    "end": "2346520"
  },
  {
    "text": "if we put metric first and then times down and they so we can take advantage of that brilliant behavior of that be",
    "start": "2346520",
    "end": "2353119"
  },
  {
    "text": "tree again so once we're doing our range we navigate this beach we want to find the metric and then to find the start of",
    "start": "2353119",
    "end": "2359599"
  },
  {
    "text": "our time stamp but then once we found the start we just iterate down the index it's really efficient",
    "start": "2359599",
    "end": "2366729"
  },
  {
    "text": "this is well I've sort of discovered this I was quite happy because I was",
    "start": "2366729",
    "end": "2372049"
  },
  {
    "text": "thinking this is one of those cases where such a generic structure happens to be the perfect thing what you're",
    "start": "2372049",
    "end": "2377869"
  },
  {
    "text": "trying to represent so the line in green",
    "start": "2377869",
    "end": "2384739"
  },
  {
    "text": "is good and that's what we've just done and this is staggering you had better it is so we've taken",
    "start": "2384739",
    "end": "2391669"
  },
  {
    "text": "those two separate indexes and we turn them into one it's really quite dramatic",
    "start": "2391669",
    "end": "2400179"
  },
  {
    "text": "as you see is the time range goes all the way up we're still well in our",
    "start": "2400179",
    "end": "2405249"
  },
  {
    "text": "threshold so let's make this a bit harder let's increase the volume a bit",
    "start": "2405249",
    "end": "2411069"
  },
  {
    "start": "2409000",
    "end": "2498000"
  },
  {
    "text": "so we were and we were looking at a day to age of 10 million rows in so now",
    "start": "2411069",
    "end": "2417319"
  },
  {
    "text": "let's up it to 100 million so with 100 next tricks this is equivalent about going from one day of data to 11 days of",
    "start": "2417319",
    "end": "2424130"
  },
  {
    "text": "data at one measurement per second on Hertz and let's increase the maximum",
    "start": "2424130",
    "end": "2432079"
  },
  {
    "text": "time ranges as well so before we were topping out a 2.5 hour range and now",
    "start": "2432079",
    "end": "2438229"
  },
  {
    "text": "we're going to be trying to get ten one day range so again we just flat with",
    "start": "2438229",
    "end": "2446809"
  },
  {
    "text": "data volume which is good but we are going up as the time range of our query",
    "start": "2446809",
    "end": "2453140"
  },
  {
    "text": "goes up and of course it goes up a little bit too high so as we get to",
    "start": "2453140",
    "end": "2459619"
  },
  {
    "text": "about sixty thousand seconds or so they're kind of creeping over that",
    "start": "2459619",
    "end": "2466369"
  },
  {
    "text": "danger zone again so this we haven't got rid of this problem as we clearly more data it takes longer as we increase the",
    "start": "2466369",
    "end": "2474979"
  },
  {
    "text": "number of metrics it goes really off the charts literally off the charts but it's",
    "start": "2474979",
    "end": "2481819"
  },
  {
    "text": "actually indicative of something very odd going on the database and this is that we're craving a lot of data and",
    "start": "2481819",
    "end": "2490579"
  },
  {
    "text": "we're actually hitting some memory limits in the database so we live a conflict week this does flatten off a bit but it does raise an issue",
    "start": "2490579",
    "end": "2499750"
  },
  {
    "text": "so we can go up to 100 million and up to some quite good time ranges for 10 metrics where we do hit some limits so",
    "start": "2499750",
    "end": "2507260"
  },
  {
    "text": "we need a better strategy for handling this so I call this summarizing you can",
    "start": "2507260",
    "end": "2513559"
  },
  {
    "text": "call it roll-ups or Agra create aggregation or number of things",
    "start": "2513559",
    "end": "2519309"
  },
  {
    "text": "materialization all kind of mean the same thing so we've seen that for 100",
    "start": "2519309",
    "end": "2529039"
  },
  {
    "text": "metrics we kind of miss our target so for over eight eleven days of data this",
    "start": "2529039",
    "end": "2535069"
  },
  {
    "text": "query might be returning up to 40,000 data points to do it this is actually",
    "start": "2535069",
    "end": "2540230"
  },
  {
    "text": "necessary if we're visualizing this data if we're drawing a graph why do we need 40,000 data points to draw this graph",
    "start": "2540230",
    "end": "2547490"
  },
  {
    "text": "all the graphing software is going to do is average them down and average",
    "start": "2547490",
    "end": "2553160"
  },
  {
    "text": "monitors only got 2,000 pixels so you can't see any of it so it's a real waste",
    "start": "2553160",
    "end": "2558349"
  },
  {
    "text": "so let's just say that say that 4,000 are enough or even 400 no you're not",
    "start": "2558349",
    "end": "2564619"
  },
  {
    "text": "going to use a whole screen for one graph so what's the concept here so the",
    "start": "2564619",
    "end": "2572180"
  },
  {
    "text": "concept is we bring up a second table and what we're going to do is as the",
    "start": "2572180",
    "end": "2577190"
  },
  {
    "text": "data comes in to this table we're going to store it in our",
    "start": "2577190",
    "end": "2582519"
  },
  {
    "text": "summarized table until we get a time but",
    "start": "2582519",
    "end": "2592220"
  },
  {
    "text": "it falls into the same bucket as a time we've already got so we're rounding this time so I call this values 2 so every 2",
    "start": "2592220",
    "end": "2599829"
  },
  {
    "text": "minutes we're going to have 1 summarized data point so when we get this value and",
    "start": "2599829",
    "end": "2606200"
  },
  {
    "text": "we're actually going to do is update an aggregated value in this table so in",
    "start": "2606200",
    "end": "2612980"
  },
  {
    "text": "this play what we're actually doing is we're recording the sum of the two values that have gone in for the same",
    "start": "2612980",
    "end": "2618079"
  },
  {
    "text": "time period and then for this one we go in there oh and update up and now we're",
    "start": "2618079",
    "end": "2624769"
  },
  {
    "text": "in a different time period so create a new one and if it goes on like this we update",
    "start": "2624769",
    "end": "2631860"
  },
  {
    "text": "this one and update it all so we've ended up with the table that's actually",
    "start": "2631860",
    "end": "2638610"
  },
  {
    "text": "a fraction of the size of our source data which is gonna be a lot cheaper to query and yeah this is an example with",
    "start": "2638610",
    "end": "2648330"
  },
  {
    "text": "two but could be any period that you like so bit of sequel to create this",
    "start": "2648330",
    "end": "2655560"
  },
  {
    "text": "create our table because it values 10 so what we're going to do is we're going to roll up every 10 seconds into one second",
    "start": "2655560",
    "end": "2665210"
  },
  {
    "text": "and we have one entry per timestamp and per metric and this is unique so we have",
    "start": "2665750",
    "end": "2675210"
  },
  {
    "text": "one this comes in handy in a bit later on and then we actually record multiple",
    "start": "2675210",
    "end": "2680880"
  },
  {
    "text": "different aggregates so in that example I just gave it was just some but actually we're going to do is we're on a record",
    "start": "2680880",
    "end": "2686400"
  },
  {
    "text": "account and the men in the max and anything else that you might want to record so when you come to query this",
    "start": "2686400",
    "end": "2693210"
  },
  {
    "text": "data you can say give me the sum and for that entire period it's just all you",
    "start": "2693210",
    "end": "2699030"
  },
  {
    "text": "there computed for you and we can even",
    "start": "2699030",
    "end": "2704640"
  },
  {
    "text": "make this look a bit nicer so we can do drawing that we did before with our view so we can play our summary and because",
    "start": "2704640",
    "end": "2711900"
  },
  {
    "text": "we're only storing the metric ID we need to get the other data from the metrics table and this just simplifies queries",
    "start": "2711900",
    "end": "2718040"
  },
  {
    "text": "and it'll be joining for us so how am I going to implement this or",
    "start": "2718040",
    "end": "2723990"
  },
  {
    "text": "someone in the last talk so triggers are awful so we're gonna use triggers sorry about that and there are other ways to",
    "start": "2723990",
    "end": "2730680"
  },
  {
    "text": "do this but triggers are the simplest way to describe this problem and once you kind of understand the fundamentals you can think of umpteen other ways to",
    "start": "2730680",
    "end": "2736920"
  },
  {
    "text": "do it with message queues in the middle and eventual consistency database over here and over there the triggers are",
    "start": "2736920",
    "end": "2742350"
  },
  {
    "text": "really easy way to do it so this is all just boilerplate they're worried too much about this just defining a trigger",
    "start": "2742350",
    "end": "2748620"
  },
  {
    "text": "and then attaching the trigger so we insert a row there it puts over there",
    "start": "2748620",
    "end": "2753650"
  },
  {
    "text": "this is the interesting one so this is what we run when we insert a row",
    "start": "2753770",
    "end": "2759930"
  },
  {
    "text": "and what we're actually going to do is we're going to insert into our summary table instead and in this example new is",
    "start": "2759930",
    "end": "2768299"
  },
  {
    "text": "the row which is entering the database so we round the time down so we get the",
    "start": "2768299",
    "end": "2774900"
  },
  {
    "text": "time period up to say 10 seconds and",
    "start": "2774900",
    "end": "2779960"
  },
  {
    "text": "then these are just the initial values for the aggregate so for the sum the initial value is just the value for the",
    "start": "2779960",
    "end": "2786599"
  },
  {
    "text": "count the count is now 1 causes the first row and the min and max the initial value is the value if however",
    "start": "2786599",
    "end": "2794160"
  },
  {
    "text": "there's already an entry for that timestamp and that metric which we can",
    "start": "2794160",
    "end": "2799829"
  },
  {
    "text": "say using common conflicts then we update the row that's already there and",
    "start": "2799829",
    "end": "2806568"
  },
  {
    "text": "what we're essentially doing here is we're kind of aggregating a little bit we're doing a bit of an aggregation",
    "start": "2806779",
    "end": "2812069"
  },
  {
    "text": "which we've been doing a query time so for the Sun we just add the thumb to the time that's already there for the count",
    "start": "2812069",
    "end": "2820289"
  },
  {
    "text": "we just add the count that's already there and what we're just adding one because we defined one earlier on it min",
    "start": "2820289",
    "end": "2827670"
  },
  {
    "text": "and Max you a little bit more interesting so the value that's already in the table we take the min of that",
    "start": "2827670",
    "end": "2832710"
  },
  {
    "text": "with the new value that's coming in and likewise for the max okay if we look at",
    "start": "2832710",
    "end": "2842520"
  },
  {
    "text": "the query actually mostly unchanged from before except we're now clearing this",
    "start": "2842520",
    "end": "2847950"
  },
  {
    "text": "summary table instead which remember is now a tenth of the size so that's really good and the only bit of fiddling we",
    "start": "2847950",
    "end": "2854069"
  },
  {
    "text": "have to do is see we sort of we're now aggregating aggregates so for sums we",
    "start": "2854069",
    "end": "2860940"
  },
  {
    "text": "have to sum sum of sums for counts we have to sum the count and for average we kind of have to do that ourselves so a",
    "start": "2860940",
    "end": "2867869"
  },
  {
    "text": "little bit fiddly but not too complicated you can also do standard deviation if you also record sum of",
    "start": "2867869",
    "end": "2874410"
  },
  {
    "text": "value squared so now as we scale the time range of our",
    "start": "2874410",
    "end": "2883660"
  },
  {
    "text": "query we write back down where we should be and if we compare that to where we were before we're doing a lot better and",
    "start": "2883660",
    "end": "2892359"
  },
  {
    "text": "this makes perfect sense because we're only clearing a table that's a tenth of the size but we've lost nothing in as",
    "start": "2892359",
    "end": "2900520"
  },
  {
    "text": "far as the user is concerned so this is this really is the key to kind of what",
    "start": "2900520",
    "end": "2906310"
  },
  {
    "text": "all of these time series databases are doing they're doing the pre a gregarious",
    "start": "2906310",
    "end": "2912390"
  },
  {
    "text": "Oh have a 100 second roll-up period for example so you can query months or years",
    "start": "2916050",
    "end": "2923290"
  },
  {
    "text": "of data really fast this isn't kind of a new concept in",
    "start": "2923290",
    "end": "2928740"
  },
  {
    "text": "database world either so just for fun let's increase the volume to a billion",
    "start": "2928740",
    "end": "2935200"
  },
  {
    "start": "2931000",
    "end": "3016000"
  },
  {
    "text": "rows anyone run a database with a billion rows in a table yeah bad idea",
    "start": "2935200",
    "end": "2941890"
  },
  {
    "text": "isn't it Oh interesting we should talk after see I mean this is",
    "start": "2941890",
    "end": "2948790"
  },
  {
    "text": "this is kind of it's a bit of a cheat because we're not actually clearing a billion rows we're clearing a tenth of a billion rows but we can do it and you",
    "start": "2948790",
    "end": "2956319"
  },
  {
    "text": "get some quite interesting results so now we could store this is now equivalent to 16 weeks of data and we're",
    "start": "2956319",
    "end": "2963099"
  },
  {
    "text": "clearing up to ten days so as a data volume in Crystal even all the way up to",
    "start": "2963099",
    "end": "2969579"
  },
  {
    "text": "a billion that index lookup isn't getting any more costly okay this is a",
    "start": "2969579",
    "end": "2978010"
  },
  {
    "text": "really well well engineered bit of code but of course the amount of time it",
    "start": "2978010",
    "end": "2985060"
  },
  {
    "text": "takes goes up and if we look at the time range requiring so recurring a billion rows a billion rows and we're querying",
    "start": "2985060",
    "end": "2994210"
  },
  {
    "text": "up to 900,000 seconds of data which will",
    "start": "2994210",
    "end": "2999609"
  },
  {
    "text": "as I say was earlier 11 days or something and we get all the way up here before actually gets to being too slow",
    "start": "2999609",
    "end": "3007550"
  },
  {
    "text": "so we're clearing all this data but the user just sees it coming back instantly",
    "start": "3007550",
    "end": "3012700"
  },
  {
    "text": "literally know what's going on underneath that's fantastic",
    "start": "3012700",
    "end": "3018060"
  },
  {
    "text": "and if you want to scale it further maybe do one hundred to one and this",
    "start": "3018060",
    "end": "3023740"
  },
  {
    "text": "makes sense as well if you want a summary over a year you really don't want every one second data point in that",
    "start": "3023740",
    "end": "3030480"
  },
  {
    "text": "so I'm completely out of time as I thought I would be and this is the",
    "start": "3030480",
    "end": "3036160"
  },
  {
    "start": "3032000",
    "end": "3099000"
  },
  {
    "text": "section that was in small letters at the front of the talk but it is so important that kind of has to be mentioned so I'm",
    "start": "3036160",
    "end": "3042640"
  },
  {
    "text": "going to be very quick about it so partitioning splitting your table by",
    "start": "3042640",
    "end": "3048340"
  },
  {
    "text": "time interval into lots of little tables and what this does is this makes deleting old data really fast you just",
    "start": "3048340",
    "end": "3055330"
  },
  {
    "text": "drop tables so you've got a six-month retention period any day too old in six months you want to drop really fast this",
    "start": "3055330",
    "end": "3062680"
  },
  {
    "text": "is going to do it it also makes it much more efficient to maintain the tables",
    "start": "3062680",
    "end": "3068200"
  },
  {
    "text": "you've already got and you can do some really cool things like reindex and cluster index and this can make your crews even more efficient cluster index",
    "start": "3068200",
    "end": "3074710"
  },
  {
    "text": "especially is really good older data can",
    "start": "3074710",
    "end": "3080230"
  },
  {
    "text": "be put on slower disks so maybe half second response time is okay for data",
    "start": "3080230",
    "end": "3086080"
  },
  {
    "text": "with a year old and you can avoid some performance issues which you do get when you have very very large be trees and",
    "start": "3086080",
    "end": "3092500"
  },
  {
    "text": "once you get to tens of billions of rows in one index some things do start to happen especially with regards to",
    "start": "3092500",
    "end": "3098170"
  },
  {
    "text": "ingesting data you can also partitioned by metrics so putting different chunks",
    "start": "3098170",
    "end": "3105190"
  },
  {
    "start": "3099000",
    "end": "3156000"
  },
  {
    "text": "of metric into different tables so we're splitting by metric so that would be on the name or the dimension hash for",
    "start": "3105190",
    "end": "3110530"
  },
  {
    "text": "example and this will allow you to scale the number of metrics in your system",
    "start": "3110530",
    "end": "3115630"
  },
  {
    "text": "almost forever because you just have a different system for a different set of metrics and if what you can do is in the",
    "start": "3115630",
    "end": "3123070"
  },
  {
    "text": "monitoring case if you can put all the metrics from a group of hosts say a data center or rack into different databases",
    "start": "3123070",
    "end": "3130570"
  },
  {
    "text": "and you can actually build a view on top of that and make it look like one really",
    "start": "3130570",
    "end": "3136030"
  },
  {
    "text": "easily this needs a talk all of its own but",
    "start": "3136030",
    "end": "3141670"
  },
  {
    "text": "unfortunately so this is where we finish a couple minutes over so come and talk",
    "start": "3141670",
    "end": "3147970"
  },
  {
    "text": "to me afterwards if you have any questions or think it's a horrible idea thank you very much",
    "start": "3147970",
    "end": "3154230"
  }
]
[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "okay I make that time thank you very much for coming along it's great to see quite so many people in for a session in",
    "start": "4740",
    "end": "12160"
  },
  {
    "text": "an afternoon that's a deep dive into the kind of high performance code so obviously no one's asleep yet and it's still got some",
    "start": "12160",
    "end": "18580"
  },
  {
    "text": "capacity to to take this stuff on welcome my name's Steve I'm a Microsoft",
    "start": "18580",
    "end": "23680"
  },
  {
    "text": "MVP and Pluralsight author my day job is as a senior developer for a company",
    "start": "23680",
    "end": "29290"
  },
  {
    "text": "called magics base down in Brighton where we do software as a service recruitment technology mainly I also run",
    "start": "29290",
    "end": "36040"
  },
  {
    "text": "a meetup group down there called net southeast which is a monthly event so if you're over in the Brighton area check",
    "start": "36040",
    "end": "41559"
  },
  {
    "text": "us out and hopefully you can come along and join us today we're going to talk about writing high performance c-sharp",
    "start": "41559",
    "end": "46870"
  },
  {
    "text": "code and I do want to highlight this bitly link here so bitly /hi perf net is",
    "start": "46870",
    "end": "52449"
  },
  {
    "text": "where you'll find all of the slides and all of the code that I'm going to show you so don't feel that you have to photograph every slide as we go through",
    "start": "52449",
    "end": "58539"
  },
  {
    "text": "if you go there you've got it all so make sure you've got a a picture of that and you can you can follow along later",
    "start": "58539",
    "end": "64320"
  },
  {
    "text": "if you want to get in touch after the talk I'm online at Steve J Gordon on Twitter and my blog Steve J Gordon code",
    "start": "64320",
    "end": "71649"
  },
  {
    "text": "at UK has a lot of the content that I'm going to cover today in a much more detail so in some form or another you'll",
    "start": "71649",
    "end": "78490"
  },
  {
    "text": "be able to kind of dig into some of the stuff if it doesn't make sense today hopefully those blog posts will sort of take you through the rest of it I'm",
    "start": "78490",
    "end": "85719"
  },
  {
    "text": "going to try and pack in a lot in 60 minutes so in the in the interest of",
    "start": "85719",
    "end": "90759"
  },
  {
    "text": "optimizing this piece of the talk we'll skip past it so I want to start by",
    "start": "90759",
    "end": "96189"
  },
  {
    "start": "93000",
    "end": "93000"
  },
  {
    "text": "talking about the aspects of performance because I think it's really important before we start talking about how we optimize the code we understand what",
    "start": "96189",
    "end": "102250"
  },
  {
    "text": "we're trying to achieve and so for me I boil this down to free kind of main areas and the first is kind of raw",
    "start": "102250",
    "end": "108490"
  },
  {
    "text": "execution time and this can be the execution time of perhaps an entire process within your application code but",
    "start": "108490",
    "end": "115270"
  },
  {
    "text": "quite often this could be sort of measuring how long does a particular method or even parts of the code within a method take to actually execute",
    "start": "115270",
    "end": "121420"
  },
  {
    "text": "because as a general rule the faster we can make our code execute the more we can do with that particular device",
    "start": "121420",
    "end": "128369"
  },
  {
    "text": "pretty closely tied to that is frupa and this is a measure that's actually more",
    "start": "128369",
    "end": "133600"
  },
  {
    "text": "easy to measure in production because this is something you can track over time and it's quite well affected by",
    "start": "133600",
    "end": "139130"
  },
  {
    "text": "execution time and this is a measure of sort of kind of how much work you can do so in a web application this might be",
    "start": "139130",
    "end": "144920"
  },
  {
    "text": "requests per second for example in a queue processing service a worker service you might be measuring how much",
    "start": "144920",
    "end": "150740"
  },
  {
    "text": "you can actually process of that queue in perhaps a minute or an hour and this measure as I say you want to track in",
    "start": "150740",
    "end": "156980"
  },
  {
    "text": "production because you can kind of see you know trends over time you could alert on this data if some of those numbers go down you're handling less",
    "start": "156980",
    "end": "163340"
  },
  {
    "text": "requests and you were expecting you could per second that might be a sign that something that's been recently deployed has affected your code and",
    "start": "163340",
    "end": "169580"
  },
  {
    "text": "again tie quite closely to both of these is memory allocations and if you've watched people like then Adams on",
    "start": "169580",
    "end": "175310"
  },
  {
    "text": "Twitter or David Fowler from the Microsoft team you'll see them quite often talking about trying to sort of",
    "start": "175310",
    "end": "181070"
  },
  {
    "text": "allocate less in their code the reason this is important is although allocating is a very fast and quick operation",
    "start": "181070",
    "end": "187630"
  },
  {
    "text": "creating a new object is not really problematic we do pay for that at some point later in time so anything we",
    "start": "187630",
    "end": "193459"
  },
  {
    "text": "allocate on the heap is going to need to be garbage collected at some point in time and that introduces potentially",
    "start": "193459",
    "end": "198980"
  },
  {
    "text": "short pauses in our application while that takes effect and this can have an impact in high performance situations on",
    "start": "198980",
    "end": "205340"
  },
  {
    "text": "on how your code is overall going to perform if you're giving CPU time over to the garbage collector that's time you",
    "start": "205340",
    "end": "210620"
  },
  {
    "text": "could be spending in your own code so these are sort of the key areas that we're going to look at and see how we",
    "start": "210620",
    "end": "216739"
  },
  {
    "text": "can potentially optimize some of these areas in the code today it's important to remember that performance is",
    "start": "216739",
    "end": "222470"
  },
  {
    "text": "contextual a lot of what I'm going to show you today is not relevant to your day-to-day pieces of work you're not",
    "start": "222470",
    "end": "228680"
  },
  {
    "text": "going to want to go and apply these techniques in everything you do but there's gonna be maybe ten percent at the time where you are are writing",
    "start": "228680",
    "end": "234799"
  },
  {
    "text": "something we're in he's the scale or handle huge volumes we're looking at more performant code could save you time",
    "start": "234799",
    "end": "240560"
  },
  {
    "text": "money on how you're going to scale that service so bear in mind that this is all",
    "start": "240560",
    "end": "245600"
  },
  {
    "text": "contextual and you need to think about in your given situation is it appropriate to go to some of the depths",
    "start": "245600",
    "end": "250790"
  },
  {
    "text": "of what I'm going to show you today it's also important to remember that with performance there tends to be a bit of a",
    "start": "250790",
    "end": "256430"
  },
  {
    "text": "trade-off with readability of your code and so you've got to kind of thing is it",
    "start": "256430",
    "end": "261440"
  },
  {
    "text": "more important that the code is easy to maintain and if it's regularly changing you've got lots of developers working on it you probably want your code to be",
    "start": "261440",
    "end": "267919"
  },
  {
    "text": "reasonably readable so that you can maintain it and make but if the code is a micro service and",
    "start": "267919",
    "end": "273770"
  },
  {
    "text": "it's designed to do one thing and you're writing it once and hopefully not modifying it too often then that's the time where you might be able to say well",
    "start": "273770",
    "end": "280040"
  },
  {
    "text": "actually if we introduce some of this high performance code that we accept is going to make it harder to read we're not expecting to change that too often",
    "start": "280040",
    "end": "286430"
  },
  {
    "text": "and actually the benefit of you know scaling that service less or being able to do more with one instance is actually",
    "start": "286430",
    "end": "292790"
  },
  {
    "text": "worth the time and effort to do it so just be aware that you know there are some trade-offs to these things so when",
    "start": "292790",
    "end": "300200"
  },
  {
    "text": "we start looking at how we're going to improve our code we're gonna go through what I've sort of deemed the optimization cycle it's a pretty sick",
    "start": "300200",
    "end": "305510"
  },
  {
    "text": "print simple cycle we start by measuring it's really important in performance optimization not to make any kind of",
    "start": "305510",
    "end": "311720"
  },
  {
    "text": "assumptions about what you're doing even things that you've done in the past that have improved code somewhere may not actually have the same effect somewhere",
    "start": "311720",
    "end": "317960"
  },
  {
    "text": "else so measuring your code is is is vital really to validating that what you're doing is having a positive impact",
    "start": "317960",
    "end": "324140"
  },
  {
    "text": "the first step is measuring before you do anything find out what the current state of the application is but maybe",
    "start": "324140",
    "end": "329540"
  },
  {
    "text": "starting with a higher level profiling type approach to understand what are the hot paths in your application and then",
    "start": "329540",
    "end": "334880"
  },
  {
    "text": "once you know where the code is being executed often and what's being called the most then you can start to focus in",
    "start": "334880",
    "end": "340250"
  },
  {
    "text": "on doing sort of code level benchmarking and actually looking at optimizing those pieces of code and improving them once",
    "start": "340250",
    "end": "346280"
  },
  {
    "text": "you've got those measurements and you know you're starting place then you want to begin with some optimization and in",
    "start": "346280",
    "end": "352100"
  },
  {
    "text": "this phase it's important not to get carried away and do tons of changes at once it's quite tempting when you're",
    "start": "352100",
    "end": "357740"
  },
  {
    "text": "doing this to go out can apply span here and this there and and all of those changes at once means that you don't",
    "start": "357740",
    "end": "362870"
  },
  {
    "text": "really know if all of the changes you're making have had a positive impact overall you might have improved execution time or reduce memory",
    "start": "362870",
    "end": "369620"
  },
  {
    "text": "allocations but is that the best you could have achieved the best way to tell this is to change one small thing and then measure again and at that point you",
    "start": "369620",
    "end": "376910"
  },
  {
    "text": "can validate your previous assumption make sure that you've had a positive impact and then try the next thing and really that's just a simple cycle that",
    "start": "376910",
    "end": "383930"
  },
  {
    "text": "you're going to keep going through and depending on what your objectives are for that application you may go through this once or twice or you might keep",
    "start": "383930",
    "end": "390500"
  },
  {
    "text": "going at this until you've really think you've hammered every ounce of performance out of the code that you're trying to improve so there's various",
    "start": "390500",
    "end": "397820"
  },
  {
    "start": "396000",
    "end": "396000"
  },
  {
    "text": "tools available for measuring application performance I'm not going to go into these in too much depth but I do",
    "start": "397820",
    "end": "403250"
  },
  {
    "text": "want to kind of touch just that you're aware that these are sort of a starting place for a lot of your codes in terms of profiling Visual",
    "start": "403250",
    "end": "410280"
  },
  {
    "text": "Studio has some quite good tooling built in these days so I think David Fowler was showing this the other day you know",
    "start": "410280",
    "end": "415590"
  },
  {
    "text": "there's diagnostic tools built into Visual Studio that you can even run while you're just debugging your code and even there you could do things like",
    "start": "415590",
    "end": "422130"
  },
  {
    "text": "see what your memory traffic looks like taking actual CPU or memory snapshots and analyze them as your codes running",
    "start": "422130",
    "end": "429360"
  },
  {
    "text": "now be aware that you're in debug mode your codes not in the most optimized compiled version it's designed for",
    "start": "429360",
    "end": "435480"
  },
  {
    "text": "debugging so it's it's it's gonna be slightly off from the performance you'd see in a release application but it's a",
    "start": "435480",
    "end": "441000"
  },
  {
    "text": "good indicator you can start to have a feel for what bits of your code do allocate and what sort of volumes and",
    "start": "441000",
    "end": "446190"
  },
  {
    "text": "memory you're talking about once you've sort of done it in debugging you're going to want to do some profiling",
    "start": "446190",
    "end": "451280"
  },
  {
    "text": "hopefully under very realistic loads and this might be in some kind of replica environment where you can hit something",
    "start": "451280",
    "end": "457110"
  },
  {
    "text": "we have a number of requests that mimic what you've seen in your real production system or in some situations you might",
    "start": "457110",
    "end": "463230"
  },
  {
    "text": "be safe enough to take some form of profiling in your production app and you might use Visual Studio tools to do that",
    "start": "463230",
    "end": "469490"
  },
  {
    "text": "perfu was shown again by David Fowler quite a low-level tour quite hard tool to actually get your head around but",
    "start": "469490",
    "end": "475530"
  },
  {
    "text": "very powerful lots of options there jetbrains do trace and dock memory which",
    "start": "475530",
    "end": "480600"
  },
  {
    "text": "are kind of a nice middle ground they offer a little bit more power in some areas but they have a better UI make it a little easier to work with and",
    "start": "480600",
    "end": "487610"
  },
  {
    "text": "occasionally and this isn't something you're gonna have to do all of the time you might want to even look at the the",
    "start": "487610",
    "end": "493230"
  },
  {
    "text": "IR code the intermediate language that your C sharp or F sharp code is compiling into when you build your",
    "start": "493230",
    "end": "499200"
  },
  {
    "text": "application things that you can sort of see in there you can sometimes get a hint of where you're doing some boxing",
    "start": "499200",
    "end": "504300"
  },
  {
    "text": "operations or your you've got lots of virtual method calls going on or just the raw number of instructions can give",
    "start": "504300",
    "end": "509550"
  },
  {
    "text": "you an indicator that perhaps you can you can optimize that code somehow they say it's not something you're going to all of the time but it's there as",
    "start": "509550",
    "end": "516330"
  },
  {
    "text": "another sort of tool in your chest that you can kind of go for it's also important to remember that you do want",
    "start": "516330",
    "end": "521610"
  },
  {
    "text": "to be monitoring this stuff in production and having real metrics around it particularly if you are going to be trying to change a lot around",
    "start": "521610",
    "end": "527610"
  },
  {
    "text": "performance sometimes in your test environments you might see positive gains you want to make sure you're",
    "start": "527610",
    "end": "533580"
  },
  {
    "text": "realizing them in production and you're monitoring over time so you can alert and changes in those environments so these are sort of",
    "start": "533580",
    "end": "540189"
  },
  {
    "text": "important tools to figure out where they fit into your your development processes but that's all I will spend more time on",
    "start": "540189",
    "end": "546790"
  },
  {
    "start": "545000",
    "end": "545000"
  },
  {
    "text": "today because it's more sort of akin to direct code improvements and actual sort of code performance optimizations is",
    "start": "546790",
    "end": "553449"
  },
  {
    "text": "benchmark dotnet so this is a library that you can bring in it's an open source library it's it's very well",
    "start": "553449",
    "end": "560470"
  },
  {
    "text": "maintained and what it's about is doing high precision monitoring of your code and this is giving you really good",
    "start": "560470",
    "end": "567730"
  },
  {
    "text": "accurate benchmark results about memory allocations execution time of code typically you could get really basic",
    "start": "567730",
    "end": "574569"
  },
  {
    "text": "results by putting a stopwatch around some code but you would have to run that actually quite a lot of times to get a",
    "start": "574569",
    "end": "579790"
  },
  {
    "text": "very realistic count particularly on pieces of code that are only executing over nanoseconds because getting an",
    "start": "579790",
    "end": "585489"
  },
  {
    "text": "accurate measurement of that is very difficult so benchmark net does this very scientifically it will do many tens",
    "start": "585489",
    "end": "590829"
  },
  {
    "text": "of thousands of iterations of its benchmarking so that it can cast out the outliers give you a statistical average",
    "start": "590829",
    "end": "596350"
  },
  {
    "text": "on the data that is collecting and it will also measure its own overhead so it's ensuring that the actual measurement process itself isn't",
    "start": "596350",
    "end": "602439"
  },
  {
    "text": "affecting the results you're seeing so this is a very scientific way of going to collect the data and this is the tool",
    "start": "602439",
    "end": "608679"
  },
  {
    "text": "that Microsoft now use within core FX which is the dotnet core sort of framework and inside asp net core for",
    "start": "608679",
    "end": "614980"
  },
  {
    "text": "making sure that they understand how that code base is performing as well so it's a very powerful tool and you can",
    "start": "614980",
    "end": "621160"
  },
  {
    "text": "also include it in your C ICD process if you want to so you use it while you're improving your code but you could also",
    "start": "621160",
    "end": "626679"
  },
  {
    "text": "have these things execute on builds so that you can see if you're actually introducing regressions around any areas",
    "start": "626679",
    "end": "631869"
  },
  {
    "text": "your code that you've kind of identified as critical paths that you don't want to break so we're gonna have a look this is",
    "start": "631869",
    "end": "643779"
  },
  {
    "text": "like a hello world of benchmarking so we'll start with this so basically what you'll do is you'll create a console",
    "start": "643779",
    "end": "649119"
  },
  {
    "text": "application and you'll bring in the benchmark dotnet libraries so a bit like creating unit test projects and then",
    "start": "649119",
    "end": "654939"
  },
  {
    "text": "we're just going to have a very simple program main method here which is going to call down to the benchmark runners so there's various ways you can have",
    "start": "654939",
    "end": "661029"
  },
  {
    "text": "benchmarks execute the simplest way here is just to say to run and then give it the class that contains your benchmarks",
    "start": "661029",
    "end": "667449"
  },
  {
    "text": "that you care about and so below I've got my benchmark class here so at the moment I've got",
    "start": "667449",
    "end": "673339"
  },
  {
    "text": "this attribute at the top which is a memory diagnosis so this is where benchmarks is gives us control over the",
    "start": "673339",
    "end": "678440"
  },
  {
    "text": "type of information that's collected and reported on here what I'm saying is I also want as well as execution time I",
    "start": "678440",
    "end": "683959"
  },
  {
    "text": "want some details about memory allocations when you run benchmarks within this class then I have some setup",
    "start": "683959",
    "end": "690050"
  },
  {
    "text": "code this code is is outside of our benchmarking I'm not measuring the heap allocations or the cost of establishing",
    "start": "690050",
    "end": "695390"
  },
  {
    "text": "these objects this is objects that I'm gonna operate on what I'm interested in is testing what it is what it takes to",
    "start": "695390",
    "end": "702860"
  },
  {
    "text": "run that get last name method of my posit ID so inside this method here which is marked with the benchmark",
    "start": "702860",
    "end": "708529"
  },
  {
    "text": "attribute to identify as a benchmark that you want to run we have some code and this could be code that points to",
    "start": "708529",
    "end": "714170"
  },
  {
    "text": "another project reference that you've got but it could be just arbitrary lines of code in there that you want to test in isolation as well so we've got our",
    "start": "714170",
    "end": "721670"
  },
  {
    "text": "benchmark we're going to run it now so what we're gonna do is we're gonna make sure that we're on a release build benchmark that will not let you run the",
    "start": "721670",
    "end": "727220"
  },
  {
    "text": "tests on debug code so it will give you a warning it's quite obvious if you've done it wrong and you're just going to",
    "start": "727220",
    "end": "733430"
  },
  {
    "text": "run the code inside that console application so it's gonna run for a while it's going to spits out a lot of",
    "start": "733430",
    "end": "738890"
  },
  {
    "text": "information about all of the warm-up phases it's going to do all of the overhead measurements and then finally",
    "start": "738890",
    "end": "744110"
  },
  {
    "text": "all of the actual iterations of the benchmarks it's running and finally when you get your results you're going to have a bit of a summary you'll find out",
    "start": "744110",
    "end": "750529"
  },
  {
    "text": "what sort of platform you were running this on top of and then for each benchmark within that class we would",
    "start": "750529",
    "end": "756290"
  },
  {
    "text": "have a row here we've got the one row so we can see one hundred and sixty-three nanoseconds to X occur execute that that",
    "start": "756290",
    "end": "763820"
  },
  {
    "text": "particular method we don't really know at this stages is that good is that bad it sounds pretty quick I guess but we",
    "start": "763820",
    "end": "769279"
  },
  {
    "text": "only at this point really established our own baseline for this code execution now because we included the memory",
    "start": "769279",
    "end": "775100"
  },
  {
    "text": "diagnosis or attribute we get this additional memory information so here we can see first some information about",
    "start": "775100",
    "end": "780589"
  },
  {
    "text": "potential garbage collections that will occur so there's various different generations that your objects can live",
    "start": "780589",
    "end": "786500"
  },
  {
    "text": "within this sort of managed memory and this is essentially giving us a view as to how long those objects lived within",
    "start": "786500",
    "end": "792500"
  },
  {
    "text": "the the code base while those benchmarks were running so we can see everything is in Gen Z row so all of the objects that",
    "start": "792500",
    "end": "798050"
  },
  {
    "text": "were created were short-lived so that's a bit of an indicator that you know there's only the allocations",
    "start": "798050",
    "end": "804259"
  },
  {
    "text": "of large or they aren't living for a long period of time and we can see this measurement is actually slightly hard to",
    "start": "804259",
    "end": "809629"
  },
  {
    "text": "calculate because it's per 1000 operations so it's naught point naught 3 7 per 1000",
    "start": "809629",
    "end": "815089"
  },
  {
    "text": "operations which in this case is around 26,000 times we'd have to call that method before we might have introduced",
    "start": "815089",
    "end": "820579"
  },
  {
    "text": "enough GC pressure that a GC would actually have kicked in so we can see it's reasonably efficient in terms of",
    "start": "820579",
    "end": "826759"
  },
  {
    "text": "we're not putting a lot of load on what we're doing and we can validate the actual allocation of bites here as 160",
    "start": "826759",
    "end": "832999"
  },
  {
    "text": "bytes now it's important to remember these measurements may be scaled differently that might be kilobytes or megabytes depending on what you're",
    "start": "832999",
    "end": "838399"
  },
  {
    "text": "measuring if all of the results will be at the same unit that you just don't always assume it's bytes basically and",
    "start": "838399",
    "end": "845359"
  },
  {
    "text": "that is now a point where we'd be able to go and start doing some optimization of our code so I want to like now bring",
    "start": "845359",
    "end": "852979"
  },
  {
    "start": "850000",
    "end": "850000"
  },
  {
    "text": "in the features that are you're probably all here to sort of hear about and see and the first of which is span of T so",
    "start": "852979",
    "end": "858799"
  },
  {
    "text": "this was released in the last couple of years and it's generated a fair bit of buzz I think I'm always interested how",
    "start": "858799",
    "end": "864919"
  },
  {
    "text": "many people have heard of span of T already most of the house good how many people are using it in a production app",
    "start": "864919",
    "end": "870489"
  },
  {
    "text": "1 2 3 4 5 I can count them across the room so yeah this is pretty indicative",
    "start": "870489",
    "end": "876019"
  },
  {
    "text": "and pretty sort of expected I see this pretty much everywhere I ask the question and I can understand why",
    "start": "876019",
    "end": "881449"
  },
  {
    "text": "because in a sense Microsoft have publicised this quite heavily because it is introducing the possibility for them",
    "start": "881449",
    "end": "887179"
  },
  {
    "text": "to really optimize core effects and asp net core so they're very excited about",
    "start": "887179",
    "end": "892189"
  },
  {
    "text": "it because it's making the framework and the platform quicker for us to work against but they have always cautioned",
    "start": "892189",
    "end": "897709"
  },
  {
    "text": "in those posts this is cool don't use it and they kind of do that because it can",
    "start": "897709",
    "end": "903709"
  },
  {
    "text": "get you into a sort of more gnarly world of code and they don't want everyone picking this up just because it looks cool I sort of annoyed them a little bit",
    "start": "903709",
    "end": "911809"
  },
  {
    "text": "by saying I do think it can be used more than they are promoting it I think there are more use cases for things like span",
    "start": "911809",
    "end": "917149"
  },
  {
    "text": "of T that I've been prototyping where it hasn't made the code to much more complicated and I have got a reasonably",
    "start": "917149",
    "end": "923389"
  },
  {
    "text": "good benefit out of there and we'll look at some real-world prototypes that I've been doing in a moment for you to kind of make your own judgments on that but",
    "start": "923389",
    "end": "929839"
  },
  {
    "text": "it was introduced in dotnet core 2.1 it is available also for dotnet framework as an additional library package you can",
    "start": "929839",
    "end": "936499"
  },
  {
    "text": "bring in that refer to a slow span which is a bit of a misleading term it's slightly slower",
    "start": "936499",
    "end": "942439"
  },
  {
    "text": "than the span that's in dotnet core purely because in dotnet core they were able to make runtime changes to support",
    "start": "942439",
    "end": "947749"
  },
  {
    "text": "the feature being as highly optimized as possible so they're both fast they're both perfectly usable and you can use",
    "start": "947749",
    "end": "954139"
  },
  {
    "text": "these in both places if you need to what span gives you is a read/write view",
    "start": "954139",
    "end": "959600"
  },
  {
    "text": "over some contiguous block of memory which is very wordy sort of sentence so",
    "start": "959600",
    "end": "964879"
  },
  {
    "text": "essentially if you think of something like an array which is on the heap that's a contiguous block of memory that's allocated on the heap in one one",
    "start": "964879",
    "end": "970970"
  },
  {
    "text": "nice block and we can get a spam viewer over that which doesn't sound hugely useful because we could always look at",
    "start": "970970",
    "end": "977029"
  },
  {
    "text": "it as an array anyway but the interesting thing about span of T is that you can target and view memory",
    "start": "977029",
    "end": "982850"
  },
  {
    "text": "that's on the heap but also on the stack and also unmanaged memory and you can work with it through this consistent fan",
    "start": "982850",
    "end": "988999"
  },
  {
    "text": "of tapi you don't need to worry about where the memory exists and it will do the right thing for you in terms of",
    "start": "988999",
    "end": "994850"
  },
  {
    "text": "memory and type safety to make sure you're not doing things that would be dangerous or will allow you to leak",
    "start": "994850",
    "end": "1000149"
  },
  {
    "text": "objects outside of the scope that they're meant to be seen in so you can work on things like arrays and strings",
    "start": "1000149",
    "end": "1005860"
  },
  {
    "text": "on the heap but as I say you've got that stack option which can you can use and we will see that in use in one of the",
    "start": "1005860",
    "end": "1011319"
  },
  {
    "text": "demos as well or unmanaged memory if that's where you're working there's almost no overhead to using this it has",
    "start": "1011319",
    "end": "1018549"
  },
  {
    "text": "the same kind of functionality as an array you can iterate over the array or over the data in the span I should say",
    "start": "1018549",
    "end": "1023860"
  },
  {
    "text": "you can modify it you can take a particular index and adjust that if you want to and as I say it's very simple to",
    "start": "1023860",
    "end": "1030909"
  },
  {
    "text": "kind of do those kind of operations in a very similar way to spam with practically at so as an array we've",
    "start": "1030909",
    "end": "1036640"
  },
  {
    "text": "practically no overhead to doing it the most popular operation that you'll do",
    "start": "1036640",
    "end": "1041770"
  },
  {
    "start": "1040000",
    "end": "1040000"
  },
  {
    "text": "once you've got a span and this is where you'll start to see the power of it is the slice operation this is where we",
    "start": "1041770",
    "end": "1047798"
  },
  {
    "text": "have a view over some data and what we're going to do is modify that view so here we've started out with an array of",
    "start": "1047799",
    "end": "1053320"
  },
  {
    "text": "nine integers which is a really strange number to use like should have been ten but I have my array so I can call our",
    "start": "1053320",
    "end": "1059559"
  },
  {
    "text": "span on that and that will return me my span representation now span is a very low and light type it's it's a value",
    "start": "1059559",
    "end": "1067570"
  },
  {
    "text": "type and it's guaranteed to only ever live on the stack so there's no allocation or cost in doing this and it's essentially",
    "start": "1067570",
    "end": "1074170"
  },
  {
    "text": "inside just a pointer in a length over the memory that it's looking at there's a little more complex than that but it's",
    "start": "1074170",
    "end": "1079690"
  },
  {
    "text": "very lightweight so there's there's very little cost of doing that once we have our span view over this array then we",
    "start": "1079690",
    "end": "1085360"
  },
  {
    "text": "could slice into it and all we do with slice is we get a start position and optionally a length that we want to use",
    "start": "1085360",
    "end": "1091750"
  },
  {
    "text": "and this then gives us back another span so now we have two spans looking at the same block of memory so the important",
    "start": "1091750",
    "end": "1098200"
  },
  {
    "text": "thing is here this starts to give us a possibility of parsing through some memory that we actually have a view of already without copying it we're not",
    "start": "1098200",
    "end": "1105490"
  },
  {
    "text": "copying data so there's no overhead there's no real cost of doing this and you can see here that my second span my",
    "start": "1105490",
    "end": "1111370"
  },
  {
    "text": "span to its index 0 would essentially bear where index 2 is in that first span so both of those can now operate on that",
    "start": "1111370",
    "end": "1118330"
  },
  {
    "text": "data and modify and view it differently I prefer I sort of give the analogy for this of photography so I do a little bit",
    "start": "1118330",
    "end": "1124870"
  },
  {
    "text": "of photography I have a DSLR camera with those sort of telephoto lens many people who have taken pictures with their",
    "start": "1124870",
    "end": "1130179"
  },
  {
    "text": "camera phones if you're taking a nice wide-angle picture of a landscape and you see an object down the middle of",
    "start": "1130179",
    "end": "1135730"
  },
  {
    "text": "that landscape that you're interested in and you have a couple of options you could walk towards it which might be a mile across the field and over a stile",
    "start": "1135730",
    "end": "1142059"
  },
  {
    "text": "and eventually you get close and great you've taken your picture there's a fair amount of effort involved in that or a",
    "start": "1142059",
    "end": "1147340"
  },
  {
    "text": "fairly consistent operation is just zooming the camera lens or swipe zooming into the view and then you have a",
    "start": "1147340",
    "end": "1152890"
  },
  {
    "text": "different view over the same scene that you were looking at previously and this is what slicing is essentially and because of that it's a constant time",
    "start": "1152890",
    "end": "1159850"
  },
  {
    "text": "constant cost operation so because there's no allocations involved because there's no memory copying involved it",
    "start": "1159850",
    "end": "1165460"
  },
  {
    "text": "doesn't matter here if that array is nine elements or nine million elements the cost of slicing into it for any",
    "start": "1165460",
    "end": "1170890"
  },
  {
    "text": "length or slice is exactly the same each time we do it so now I've sort of shown you that and",
    "start": "1170890",
    "end": "1178360"
  },
  {
    "text": "probably bamboozled your brains with span because it does take a little while to kinda get a get your head around let's look at a slightly trivialized",
    "start": "1178360",
    "end": "1184299"
  },
  {
    "text": "example before we get to more realistic code in a short while so imagine we have this requirement given to us by the",
    "start": "1184299",
    "end": "1190360"
  },
  {
    "text": "product owner we need a method that takes an array it's going to return one quarter of its elements starting from",
    "start": "1190360",
    "end": "1196030"
  },
  {
    "text": "the middle I'm sure everyone's had a requirement like this dumped on them at work so that's the requirement someone",
    "start": "1196030",
    "end": "1201190"
  },
  {
    "text": "in our business had been given at some stage and and possibly this is how they might have been demented it they might just use the skip",
    "start": "1201190",
    "end": "1207289"
  },
  {
    "text": "and a take in a link expression to give the data that was being asked for and they think great we've delivered now",
    "start": "1207289",
    "end": "1213440"
  },
  {
    "text": "sometime later the product manager comes back and goes we want to we want to turbocharge this thing we want to make",
    "start": "1213440",
    "end": "1218840"
  },
  {
    "text": "it really quick we want to make a fortune this is going to save us some money and so now we need to optimize that code so the first thing I'm going",
    "start": "1218840",
    "end": "1226130"
  },
  {
    "text": "to do is I'm going to set up some benchmarks so there's some additional code coming but this is our setup which is a little more complex than the hello",
    "start": "1226130",
    "end": "1232100"
  },
  {
    "text": "world example it doesn't have to be but there's some good reasons for doing this so the first thing here is this params",
    "start": "1232100",
    "end": "1238130"
  },
  {
    "text": "attribute on the size property there this allows us to configure benchmark net so that it will run this benchmark",
    "start": "1238130",
    "end": "1244309"
  },
  {
    "text": "actually free times or every benchmark in this class in fact three times each",
    "start": "1244309",
    "end": "1249470"
  },
  {
    "text": "time it runs it though it will have a different size value in that property and the reason we might want to do this",
    "start": "1249470",
    "end": "1254630"
  },
  {
    "text": "is it's very easy to get sort of drawn into testing one particular sort of best-case scenario that you expect and",
    "start": "1254630",
    "end": "1260539"
  },
  {
    "text": "we always expect this array to be maybe a thousand elements but often there are edge cases to the data that we get given",
    "start": "1260539",
    "end": "1265850"
  },
  {
    "text": "and sometimes it can be different the results of your sort of improvements might differ higher or smaller sizes",
    "start": "1265850",
    "end": "1271700"
  },
  {
    "text": "here so we're going to test three possibilities because I've got that I need some way to set this this benchmark",
    "start": "1271700",
    "end": "1277399"
  },
  {
    "text": "method up so what I've got is a just a regular method that I marked with the global setup attribute and this gets run",
    "start": "1277399",
    "end": "1282860"
  },
  {
    "text": "once before the benchmarks actually initialize and it's not again doesn't measure in doesn't affect the execution",
    "start": "1282860",
    "end": "1288860"
  },
  {
    "text": "time or the allocations we see what really just doing is creating an array of the appropriate size that we're going to operate on so now we can actually",
    "start": "1288860",
    "end": "1295850"
  },
  {
    "text": "write our benchmarks so this is the code that our original developer had written all I've done here is added a benchmark",
    "start": "1295850",
    "end": "1301940"
  },
  {
    "text": "attribute in this case with the baseline equals true which says this is the starting point of code that I'm coming",
    "start": "1301940",
    "end": "1307370"
  },
  {
    "text": "from so I want to measure everything else against this and we can run that benchmark and we get three results this",
    "start": "1307370",
    "end": "1313130"
  },
  {
    "text": "time because of the three different parameters that we put through so we can see that 154 nanoseconds two to four",
    "start": "1313130",
    "end": "1319909"
  },
  {
    "text": "bytes allocated in the first run 100 original sizer for the array and as we go up as we",
    "start": "1319909",
    "end": "1325970"
  },
  {
    "text": "might expect because we were working on larger and larger arrays we're seeing higher and higher allocations and a",
    "start": "1325970",
    "end": "1332389"
  },
  {
    "text": "longer time for this code to execute so this is our starting point we're now armed with enough information that we",
    "start": "1332389",
    "end": "1337730"
  },
  {
    "text": "can make a change and see if we can improve so at this stage we maybe think well actually I've heard linked expressions",
    "start": "1337730",
    "end": "1344450"
  },
  {
    "text": "might have some overhead perhaps we'll write this code more manually so we'll create the new array that we're going to copy some data into and we'll see if",
    "start": "1344450",
    "end": "1350870"
  },
  {
    "text": "that executes better so we've had a theory we've made one essentially fairly small change here that we're going to",
    "start": "1350870",
    "end": "1356120"
  },
  {
    "text": "now measure so in this results that we can see well actually great for this first result of a hundred items we're",
    "start": "1356120",
    "end": "1362480"
  },
  {
    "text": "down to a much quicker execution time and looks like we've made nearly 50%",
    "start": "1362480",
    "end": "1367670"
  },
  {
    "text": "saving on the bytes allocated so at this point if we were only testing at the hundred element size we'd feel pretty",
    "start": "1367670",
    "end": "1373100"
  },
  {
    "text": "good about the results because we've added the additional sizes and we can see actually with a thousand elements",
    "start": "1373100",
    "end": "1378350"
  },
  {
    "text": "the gain in terms of sort of allocated bytes is fairly insignificant now the",
    "start": "1378350",
    "end": "1383420"
  },
  {
    "text": "difference in each case is actually 96 bytes which is the cost of the link expression being compiled and executed",
    "start": "1383420",
    "end": "1388660"
  },
  {
    "text": "but otherwise the allocation cost is pretty much the same it's obviously quicker to run so this is a benefit if",
    "start": "1388660",
    "end": "1395030"
  },
  {
    "text": "we're looking for raw execution time but perhaps we care about memory as well so we're finally going to introduce spam",
    "start": "1395030",
    "end": "1401320"
  },
  {
    "text": "and as you can see we're going to able to use the slice operation to give us the same set of data this is a slightly",
    "start": "1401320",
    "end": "1407830"
  },
  {
    "text": "unfair test potentially depending on what the caller can accept so here the other ones we're returning an array now",
    "start": "1407830",
    "end": "1413480"
  },
  {
    "text": "we're returning a span of int to them so we're on the assumption that the caller can work with a span and still",
    "start": "1413480",
    "end": "1419150"
  },
  {
    "text": "use that in an optimal way if we were just casting it back to an array at some point we probably would have less of a",
    "start": "1419150",
    "end": "1425480"
  },
  {
    "text": "game but let's just see what span gives us on the assumption the caller can work with that and continue on an optimized",
    "start": "1425480",
    "end": "1430730"
  },
  {
    "text": "code path so when we run our tests again with the span we're now under a nanosecond and we have no allocation so",
    "start": "1430730",
    "end": "1437900"
  },
  {
    "text": "that's pretty good we feel pretty good about that and if we look at 1,000 omits well we're still under a nanosecond and",
    "start": "1437900",
    "end": "1443180"
  },
  {
    "text": "we still allocated nothing and at 10,000 the same set of results it's a constant time constant cost operation so",
    "start": "1443180",
    "end": "1449810"
  },
  {
    "text": "regardless of the fact that we're getting a bigger and bigger initial array that we're testing against on my",
    "start": "1449810",
    "end": "1454910"
  },
  {
    "text": "particular machine this slice operation takes about a nanosecond on other machines it will vary slightly but",
    "start": "1454910",
    "end": "1460610"
  },
  {
    "text": "that's pretty good set of results so already you can see in just this trivial example that span can be quite a powerful way if you're parsing data and",
    "start": "1460610",
    "end": "1467570"
  },
  {
    "text": "you just want to get a different view on it essentially that you can do that with basically no cost",
    "start": "1467570",
    "end": "1473570"
  },
  {
    "text": "and we can do this with strings as well so strings are essentially just a character array under the hood and so we",
    "start": "1473570",
    "end": "1480500"
  },
  {
    "start": "1474000",
    "end": "1474000"
  },
  {
    "text": "can call as span on a string literal or a reference to a string but what we get back is slightly different this time we",
    "start": "1480500",
    "end": "1485990"
  },
  {
    "text": "get back a read-only span the reason for that is obviously strings are immutable and if we were given back a readwrite",
    "start": "1485990",
    "end": "1492320"
  },
  {
    "text": "viewer over the data that that string is occupying we could do some really nasty stuff to the people that trust that",
    "start": "1492320",
    "end": "1497990"
  },
  {
    "text": "strings are immutable so we can only ever get back a read-only span and now we just have that view that we can read",
    "start": "1497990",
    "end": "1504470"
  },
  {
    "text": "over and potentially pass through so in this scenario perhaps I find the index of the last space character and then I",
    "start": "1504470",
    "end": "1510980"
  },
  {
    "text": "would slice to get my surname in this then this simple example so we can start to do these kind of operations in this",
    "start": "1510980",
    "end": "1517430"
  },
  {
    "text": "there's there's not much of a game to doing it but if you're parsing a large blob of tab-separated files for example",
    "start": "1517430",
    "end": "1523670"
  },
  {
    "text": "which we are to have an example of you will see that actually the benefits start to add up quite significantly when",
    "start": "1523670",
    "end": "1529310"
  },
  {
    "text": "you just want portions of that data now there are some important limitations to",
    "start": "1529310",
    "end": "1534590"
  },
  {
    "start": "1532000",
    "end": "1532000"
  },
  {
    "text": "span of T that it's really important you understand so that you know where and when you can't apply it so the first of",
    "start": "1534590",
    "end": "1541640"
  },
  {
    "text": "these is it's a stack only value type and I sort of hinted at that earlier so what does that mean well it's it's",
    "start": "1541640",
    "end": "1547430"
  },
  {
    "text": "defined as what's called a ref stroke this is a new keyword that was introduced in c-sharp 7.2 and what this",
    "start": "1547430",
    "end": "1553490"
  },
  {
    "text": "says is this is a value type that you can never store on to the heap so today value types may essentially end up on",
    "start": "1553490",
    "end": "1560600"
  },
  {
    "text": "the heap memory at some point in their lifetime but because this fan could be",
    "start": "1560600",
    "end": "1565730"
  },
  {
    "text": "pointed at stack allocated memory that would be really dangerous because then we can have this spam existing longer",
    "start": "1565730",
    "end": "1571340"
  },
  {
    "text": "before its garbage collected on the heap pointed at memory that is is no longer what it was originally looking at and so",
    "start": "1571340",
    "end": "1576950"
  },
  {
    "text": "because of this because it's built in to the span of T feature that we're offered this memory safety this guarantee that",
    "start": "1576950",
    "end": "1583550"
  },
  {
    "text": "we can only ever use it in the right context with the memory that we're pointing at because of that it can't be",
    "start": "1583550",
    "end": "1589430"
  },
  {
    "text": "boxed that makes sense we're not going to be able to put this onto the heap the big sort of changes that that might",
    "start": "1589430",
    "end": "1594950"
  },
  {
    "text": "introduce is that you're quite often tempted to add this as a field in a class or something but because that's in a part of a class and the heap we're",
    "start": "1594950",
    "end": "1601070"
  },
  {
    "text": "running into the same issue the biggest and most significant thing I see people run into is",
    "start": "1601070",
    "end": "1606410"
  },
  {
    "text": "we can't use this inside a sink methods basically we can't have it as an",
    "start": "1606410",
    "end": "1611450"
  },
  {
    "text": "argument or inside as a local variable inside a sink methods and a lot of our code today is asynchronous so in a",
    "start": "1611450",
    "end": "1618080"
  },
  {
    "text": "moment I'll show you how you work around that because that would feel like a showstopper I think to many of you and",
    "start": "1618080",
    "end": "1624710"
  },
  {
    "text": "the final thing is for a very similar reason it can't be captured inside lambda expressions and and the reason for those last two is it may be not be",
    "start": "1624710",
    "end": "1631160"
  },
  {
    "text": "immediately obvious because in code it doesn't look like you're breaking the rules but when you compile these you end",
    "start": "1631160",
    "end": "1636980"
  },
  {
    "text": "up with a state machine in the case of a single you may end up with a class for the lambda closures that exists and",
    "start": "1636980",
    "end": "1643670"
  },
  {
    "text": "these mean that we're breaking the earlier rules by then elevating this span thing into a field on one of those",
    "start": "1643670",
    "end": "1649520"
  },
  {
    "text": "classes that get generated so these are all the limitations we're running against fortunately Microsoft also",
    "start": "1649520",
    "end": "1655580"
  },
  {
    "text": "introduced memory of T and this is a very similar type to span of T with slightly lower performance gains so it",
    "start": "1655580",
    "end": "1663050"
  },
  {
    "text": "can live on the heap if it needs to and this is the critical thing so it can't now be pointed at a stack memory but it",
    "start": "1663050",
    "end": "1668690"
  },
  {
    "text": "does mean that we've got this guarantee that we can use it in some of the places that we can't use spam so it's defined",
    "start": "1668690",
    "end": "1674000"
  },
  {
    "text": "as a read-only struct not a restaurant and that's the key thing that ref struct keyword use is what guarantees that an",
    "start": "1674000",
    "end": "1680630"
  },
  {
    "text": "item will only ever live on the stack it's slightly slower if you're slicing",
    "start": "1680630",
    "end": "1686270"
  },
  {
    "text": "it has a slice operation it's just slightly slower than what the spam flows operation will give you so depending on",
    "start": "1686270",
    "end": "1692660"
  },
  {
    "text": "what you're looking for it might be perfectly fine to accept that sort of difference but if you're going for the ultimate performance you're always going",
    "start": "1692660",
    "end": "1698930"
  },
  {
    "text": "to want to get back to a span as soon as you can fortunately that's really easy it exposes a spam property you ask for",
    "start": "1698930",
    "end": "1705170"
  },
  {
    "text": "the spam and that represents that same area of the memory that you're looking at with the memory of T and you'll combine these two together so here we're",
    "start": "1705170",
    "end": "1712970"
  },
  {
    "text": "trying to do something that is making the compiler really sad we're trying to pass a span into this method that is",
    "start": "1712970",
    "end": "1718040"
  },
  {
    "text": "asynchronous so the compiler will check this and see this risk it will identify that this is not a legal operation and",
    "start": "1718040",
    "end": "1724700"
  },
  {
    "text": "so at this point we're not going to have compiling code we can change the code then to accept instead in this case in",
    "start": "1724700",
    "end": "1731210"
  },
  {
    "text": "memory of bite now the compiler is happy again and the way we're going to work with this is we could just slice as I say",
    "start": "1731210",
    "end": "1737630"
  },
  {
    "text": "that memory and it looks very similar to what we were seeing with the spam but we're going for every ounce of performance so",
    "start": "1737630",
    "end": "1743299"
  },
  {
    "text": "we want to we want to use a span operation to slice it so the way you work around this is you typically then make a non asynchronous method at the",
    "start": "1743299",
    "end": "1750229"
  },
  {
    "text": "point of where you're working with the data because once you have the data in memory there's no real asynchronous methods that you're going to be calling",
    "start": "1750229",
    "end": "1755929"
  },
  {
    "text": "and then this method can take a span in so what you're going to then do is try and pass that span from the async method",
    "start": "1755929",
    "end": "1762889"
  },
  {
    "text": "well here we're also breaking the compiler while we're trying to create a local variable that is a span it won't",
    "start": "1762889",
    "end": "1768289"
  },
  {
    "text": "let us do that inside this async method so the way we work around that is we make sure we just pass it directly into",
    "start": "1768289",
    "end": "1773359"
  },
  {
    "text": "the method here and the compiler is happy with this it can figure it out and do the right thing under the hood for us and this is typically what you'll see in",
    "start": "1773359",
    "end": "1779809"
  },
  {
    "text": "async code you'll just drop into the memory of T where you need it and then drop back to a span where you're",
    "start": "1779809",
    "end": "1785299"
  },
  {
    "text": "actually doing your final optimizations with it so I've talked for quite a while",
    "start": "1785299",
    "end": "1790429"
  },
  {
    "text": "half an hour so we're now going to actually look at some some code quickly so the scenario here was that I was",
    "start": "1790429",
    "end": "1796460"
  },
  {
    "text": "looking at building a prototype to optimize some code we had in production that piece of code reads from M sqs",
    "start": "1796460",
    "end": "1802429"
  },
  {
    "text": "which is just amazon's queue service it takes the message and we want to store it into s3 which is essentially amazon's",
    "start": "1802429",
    "end": "1808700"
  },
  {
    "text": "object store there blobstore in order to do that we need to give it a file name of an object key and I want to use some",
    "start": "1808700",
    "end": "1814220"
  },
  {
    "text": "of the properties on that original JSON structure to do that so today the code is deserializing getting the properties",
    "start": "1814220",
    "end": "1820369"
  },
  {
    "text": "to build the key and then actually storing it in there so if I drop to",
    "start": "1820369",
    "end": "1826279"
  },
  {
    "text": "visual studio which I'm desperately hoping works this time good this is like",
    "start": "1826279",
    "end": "1832159"
  },
  {
    "text": "the original code and I'm going to show you the original code then the new code and then we'll look at the benchmarks I promise I did it the right way I",
    "start": "1832159",
    "end": "1837379"
  },
  {
    "text": "benchmarked as I went but it's just slightly nicer for a reveal if I show you the numbers afterwards so here I",
    "start": "1837379",
    "end": "1843859"
  },
  {
    "text": "have a method and it takes in this event context which in this case just has five properties in our actual scenario it's",
    "start": "1843859",
    "end": "1849409"
  },
  {
    "text": "got many many tens of properties but we're only caring about a few of them and what this original code which had",
    "start": "1849409",
    "end": "1855229"
  },
  {
    "text": "been slightly optimized anyway was doing was it was taking that event context and it was calculating how many of the",
    "start": "1855229",
    "end": "1861409"
  },
  {
    "text": "elements are we actually gonna use to build up the object key and it basically it's if there's no date we're going to",
    "start": "1861409",
    "end": "1866539"
  },
  {
    "text": "use four elements if there's a date we'll use the date in the key as well so then we get this string array of those",
    "start": "1866539",
    "end": "1871999"
  },
  {
    "text": "elements we get doing away with the appropriate size and what we're gonna do is start filling the parts of that array with each of the",
    "start": "1871999",
    "end": "1878359"
  },
  {
    "text": "properties that we care about and inside this get part method what it's doing is saying if it's empty or it's null we're",
    "start": "1878359",
    "end": "1884389"
  },
  {
    "text": "going to just put in an unknown part and that unknown part is just a constant string we're going to use when we",
    "start": "1884389",
    "end": "1890179"
  },
  {
    "text": "haven't actually got the data in the property that we're expecting if we have got data we're going to try and remove the spaces inside that remove spaces",
    "start": "1890179",
    "end": "1897200"
  },
  {
    "text": "method down here it's as simple if the space is in the method in the string do a string replace on them fairly",
    "start": "1897200",
    "end": "1903440"
  },
  {
    "text": "reasonable and then the final check is is it a valid valid as an object key so there's some rules around having only",
    "start": "1903440",
    "end": "1909440"
  },
  {
    "text": "characters and numbers in the object key so we've got a regex that's checking that for us and so that's essentially",
    "start": "1909440",
    "end": "1914960"
  },
  {
    "text": "the code and we're just going to populate the parts of that array optionally we'll do a to string on the date to format that if we have it and",
    "start": "1914960",
    "end": "1921080"
  },
  {
    "text": "finally what really happens at the end is we just use a string join to take all of those elements join them into one",
    "start": "1921080",
    "end": "1926269"
  },
  {
    "text": "final string we want it to be lowercase for consistency so we're going to lower it and then we have our string so it",
    "start": "1926269",
    "end": "1933739"
  },
  {
    "text": "looks reasonable so I'll show you the new one I'll just going to drag down just to give you an idea this is more of",
    "start": "1933739",
    "end": "1939529"
  },
  {
    "text": "a boat to be fair and that kind of goes to that performance versus readability point it's and as you can see at the top",
    "start": "1939529",
    "end": "1946759"
  },
  {
    "text": "here don't worry about too much I have some ugly-looking code where I'm defining these things in such a way that I can guarantee that I'm going to reduce",
    "start": "1946759",
    "end": "1952909"
  },
  {
    "text": "a mem copy I'm just cool just forcing all of the performance I can out of this you'd have to understand exactly why for",
    "start": "1952909",
    "end": "1959210"
  },
  {
    "text": "the purposes of this demo so the key thing that I want to talk about is kind of how I'm gonna use spam for optimization here so I'm going to",
    "start": "1959210",
    "end": "1965869"
  },
  {
    "text": "basically create a character array that I can use as a temporary building area for the file name that I want to",
    "start": "1965869",
    "end": "1971839"
  },
  {
    "text": "generate and I'm going to slowly populate that with the elements as on as I'm going through so what I'm doing is on pre calculating the length and the",
    "start": "1971839",
    "end": "1978349"
  },
  {
    "text": "reason I'm doing that in this this line here is that down here I'm going to do something a little bit clever which is",
    "start": "1978349",
    "end": "1983629"
  },
  {
    "text": "if it's only under 256 characters which in the happy path I usually expect I'm",
    "start": "1983629",
    "end": "1988729"
  },
  {
    "text": "actually going to use stack Halleck to allocate the temporary character array on the stack and then this typically",
    "start": "1988729",
    "end": "1995419"
  },
  {
    "text": "would mean that you would have to use the unsafe keyword and drop into unsafe code if you wanted to work on the stack at all because it is quite dangerous you",
    "start": "1995419",
    "end": "2001809"
  },
  {
    "text": "want to make sure you're not over allocating on the stack or you'll end up with a stack overflow exception then you end up on stackoverflow trying",
    "start": "2001809",
    "end": "2007960"
  },
  {
    "text": "to work out why but if you if you're only working with small portions a memory and hearing on sub guarantying",
    "start": "2007960",
    "end": "2013930"
  },
  {
    "text": "256 characters I'm fairly happy as okay I'm saying use stack but I can also hear",
    "start": "2013930",
    "end": "2019870"
  },
  {
    "text": "say actually if that's too big just use a regular heap-allocated character array as well but I can represent them both as",
    "start": "2019870",
    "end": "2026650"
  },
  {
    "text": "a span of T so this is where that kind of transformation to a single type that deals with either memory location is",
    "start": "2026650",
    "end": "2032260"
  },
  {
    "text": "quite convenient then what I can do is I can build parts in of the string in a",
    "start": "2032260",
    "end": "2037540"
  },
  {
    "text": "similar way to before and what I pass in here is the the part that I want to start including my spam which is that",
    "start": "2037540",
    "end": "2044140"
  },
  {
    "text": "output working area and by reference I pass in the integer which tracks my position so I can update my position as",
    "start": "2044140",
    "end": "2051220"
  },
  {
    "text": "I go and slice to the appropriate point in the the character array as I'm building it so I'm basically doing what",
    "start": "2051220",
    "end": "2057100"
  },
  {
    "text": "I did before but slightly more of a bow so if it's it's a zero length for its whitespace only then use the unknown",
    "start": "2057100",
    "end": "2063010"
  },
  {
    "text": "part and you can see here what we're doing is basically you're saying copy it into that spam starting at the slice",
    "start": "2063010",
    "end": "2070030"
  },
  {
    "text": "that begins at this output position at this start of this it's zero but what then we will do is update that position",
    "start": "2070030",
    "end": "2075520"
  },
  {
    "text": "so we know how many characters we've written in and so the next time we do a slice we'll start from there and we can continue writing into it if we have got",
    "start": "2075520",
    "end": "2082389"
  },
  {
    "text": "data in there we'll do an is valid check and we can simplify that without regex here and just do is character or digit",
    "start": "2082390",
    "end": "2088139"
  },
  {
    "text": "and we basically finally end up here hopefully where we're going to use this memory extensions type here - too low",
    "start": "2088140",
    "end": "2094510"
  },
  {
    "text": "and variant which means copy this input string into this span area and lower it",
    "start": "2094510",
    "end": "2099910"
  },
  {
    "text": "at the same time so we can let the compiler do some optimizations hopefully so that's what we're essentially doing",
    "start": "2099910",
    "end": "2105220"
  },
  {
    "text": "in remove spaces it's a fairly simple case of seeing if there's a space in there by using this index of on the span",
    "start": "2105220",
    "end": "2111850"
  },
  {
    "text": "and if there is then we can take that actual index where that space is and just replace the character so we can",
    "start": "2111850",
    "end": "2117820"
  },
  {
    "text": "modify by using the indexer as well so that's the code it's all on github if you want to kind of dive into it in more",
    "start": "2117820",
    "end": "2123970"
  },
  {
    "text": "detail but I'm going to jump back to slides and sort of have a look at the results here so these are the results of",
    "start": "2123970",
    "end": "2130870"
  },
  {
    "start": "2128000",
    "end": "2128000"
  },
  {
    "text": "my tests so in the original approach just over a thousand nanoseconds and",
    "start": "2130870",
    "end": "2136510"
  },
  {
    "text": "then we got down to 440 90 seconds four and a half two and a half times faster not a massive",
    "start": "2136510",
    "end": "2143640"
  },
  {
    "text": "improvement really and depending on what our objectives are that wouldn't be particularly great but we were going",
    "start": "2143640",
    "end": "2149819"
  },
  {
    "text": "really after allocations we had a theory originally that might be a lot of allocations and so we can see that the",
    "start": "2149819",
    "end": "2155579"
  },
  {
    "text": "original code allocated because it were using those things like string join and then string to lower because strings are",
    "start": "2155579",
    "end": "2161579"
  },
  {
    "text": "immutable that means we're just creating new and new strings for each of those intermediate phases of building that",
    "start": "2161579",
    "end": "2166589"
  },
  {
    "text": "final key we have a fair few allocations over a thousand bytes here in the new",
    "start": "2166589",
    "end": "2171660"
  },
  {
    "text": "code we have 192 bytes and 192 bytes here is actually the length of the final",
    "start": "2171660",
    "end": "2178470"
  },
  {
    "text": "string that we allocate at the end of the methods so we've achieved building that string we've no overhead at all and",
    "start": "2178470",
    "end": "2183480"
  },
  {
    "text": "so that's quite a significant improvement for us slightly supported by showing it a second ago but on its own",
    "start": "2183480",
    "end": "2189150"
  },
  {
    "text": "this doesn't look super impressive but we scaled this up to what this service is actually doing it's doing 18 million",
    "start": "2189150",
    "end": "2195269"
  },
  {
    "text": "messages a day through this service so that's 17 gig of daily allocations we've achieved just by modifying this one",
    "start": "2195269",
    "end": "2201809"
  },
  {
    "text": "particular method flow in the code and that's around 2,700 gem 0 collections",
    "start": "2201809",
    "end": "2207569"
  },
  {
    "text": "from the garbage collector that we've avoided having created and the need to do so this at scale starts to have to",
    "start": "2207569",
    "end": "2213750"
  },
  {
    "text": "sort of have compound interest really in terms of the investment that you're making so I'm moving on a bit there's",
    "start": "2213750",
    "end": "2220200"
  },
  {
    "text": "quite a few more features I want to touch on a rape all of the first of those it's really hard to work out what this does by the name it's a pool of",
    "start": "2220200",
    "end": "2226349"
  },
  {
    "text": "erase it this is useful in scenarios where you you regularly need a",
    "start": "2226349",
    "end": "2232289"
  },
  {
    "text": "short-lived buffer and you'll see this a lot if you're working with streams for example you need that buffer space to do",
    "start": "2232289",
    "end": "2238259"
  },
  {
    "text": "some work and then you're kind of getting rid of it when you've done something with it what we can do with the array pause I'm gonna say well",
    "start": "2238259",
    "end": "2244109"
  },
  {
    "text": "actually we'll go to this thing that's going to have a set of a raise for us and they're just going to live forever essentially inside our application and",
    "start": "2244109",
    "end": "2250559"
  },
  {
    "text": "the pool is just going to give us an existing one whenever we need it again so that's quite powerful it's found in",
    "start": "2250559",
    "end": "2256650"
  },
  {
    "text": "the system buffers namespace and the way you work with this is you it's a generic type so you sort of have an array pool",
    "start": "2256650",
    "end": "2262049"
  },
  {
    "text": "of whatever you want and typically what your call is it's shared methods for its share property sorry to get an instance",
    "start": "2262049",
    "end": "2268470"
  },
  {
    "text": "that's kind of pre-configured with common pooling sizes that we might want to use the reason it's a good idea",
    "start": "2268470",
    "end": "2274740"
  },
  {
    "text": "to use this is they take care of sort of figuring out how to actually implement or a pool itself but also this is shared",
    "start": "2274740",
    "end": "2280710"
  },
  {
    "text": "with the runtime as well so if we have an array pool of int and the runtimes also using the same array pool of in",
    "start": "2280710",
    "end": "2285930"
  },
  {
    "text": "we've already got probably arrays in that pool that we can be sharing and reusing so to get the item we just call",
    "start": "2285930",
    "end": "2292050"
  },
  {
    "text": "rent and we give it a length so we say okay I want a thousand bytes so let's say and it's gonna give us back an array",
    "start": "2292050",
    "end": "2298590"
  },
  {
    "text": "the important and really critical point with this is you may get an array and you probably will get an array that's actually bigger than what you've asked",
    "start": "2298590",
    "end": "2304770"
  },
  {
    "text": "for which sounds kind of weird but it's logical if you think about how the appall is going to actually be",
    "start": "2304770",
    "end": "2309810"
  },
  {
    "text": "functional it needs to keep certain bucket sizes of arrays available so that",
    "start": "2309810",
    "end": "2314880"
  },
  {
    "text": "it can give you a realistic reuse of those arrays if you have every possible array size Under the Sun in the pool you're realistically ever going to use",
    "start": "2314880",
    "end": "2321570"
  },
  {
    "text": "that array once and they're all we've done is just give a lot more long life a lot of objects and we've not really got any gain so you when you're working with",
    "start": "2321570",
    "end": "2328410"
  },
  {
    "text": "the arrays from the pool you kind of need to track how much data you've written into it so that when you later iterating that array for example you",
    "start": "2328410",
    "end": "2334380"
  },
  {
    "text": "only go to the length that you care about when you're done with it you return it that's important otherwise",
    "start": "2334380",
    "end": "2339810"
  },
  {
    "text": "you've just created an object and cast it away would eventually get G seed but really all you've added is the overhead",
    "start": "2339810",
    "end": "2346320"
  },
  {
    "text": "of an array pool with no actual benefit so you're in a worse place if you don't return it we can pass this clearer work",
    "start": "2346320",
    "end": "2352410"
  },
  {
    "text": "array equals force or true through to this method this is another important",
    "start": "2352410",
    "end": "2358230"
  },
  {
    "text": "point so before dotnet core free oh so 2.2 or earlier when you returned an",
    "start": "2358230",
    "end": "2363570"
  },
  {
    "text": "array to the pool it was not cleared by default this isn't a performance optimization that just saves a short",
    "start": "2363570",
    "end": "2369690"
  },
  {
    "text": "amount of time clearing that memory but it confused a few people and it introduced a potential security risk if",
    "start": "2369690",
    "end": "2375630"
  },
  {
    "text": "you were putting arrays back in the data that you didn't really want to be pulled back out again later so now it clears by default but you can turn that behavior",
    "start": "2375630",
    "end": "2382500"
  },
  {
    "text": "off you always need to remember that any array you're given from the pool may already contain data which is why again you don't want to just iterate the",
    "start": "2382500",
    "end": "2388680"
  },
  {
    "text": "entire array because you might be talking and getting data at the end of it that you didn't write into there in",
    "start": "2388680",
    "end": "2393750"
  },
  {
    "text": "the first place so it does somewhat Kompany complicate some parts of working with the array but",
    "start": "2393750",
    "end": "2399180"
  },
  {
    "text": "as we look in the example it's not hugely complicated to do so here I've got a short live buffer that I want to",
    "start": "2399180",
    "end": "2404580"
  },
  {
    "text": "pass into another method and here we have an allocation on the heap so what I'm going to do is change",
    "start": "2404580",
    "end": "2410070"
  },
  {
    "text": "that to the using the shared array pool I'm going to rent one thousand byte array the chances are here I'll get 102",
    "start": "2410070",
    "end": "2417240"
  },
  {
    "text": "four bytes or maybe 204 eight bytes but you know it depends what's available in the buffer it could go even bigger but",
    "start": "2417240",
    "end": "2423510"
  },
  {
    "text": "I've got my buffer and then I can work with it now as I say we need to make sure that we put this back so typically",
    "start": "2423510",
    "end": "2428970"
  },
  {
    "text": "they recommend using the try finally pattern here to make sure that whatever happens we do return the array to the",
    "start": "2428970",
    "end": "2434310"
  },
  {
    "text": "pool after we're done with that and that's kind of a red pool we'll see that in action in a moment but I also want to",
    "start": "2434310",
    "end": "2439680"
  },
  {
    "start": "2437000",
    "end": "2437000"
  },
  {
    "text": "introduce system i/o pipelines this is kind of the brainchild of David Fowler and the asp.net team originally so it",
    "start": "2439680",
    "end": "2445830"
  },
  {
    "text": "was originally created to improve the performance of kestrel kestrel does a lot of i/o it's reading network requests",
    "start": "2445830",
    "end": "2452520"
  },
  {
    "text": "off of a socket and then pushing them through the kestrel web server into MVC or Razer pages and into the side that is",
    "start": "2452520",
    "end": "2460380"
  },
  {
    "text": "B net and this is quite a heavy operation because there were various handoffs between different streams",
    "start": "2460380",
    "end": "2466610"
  },
  {
    "text": "through those different layers of the applications so they were looking for a way to optimize that code and they've",
    "start": "2466610",
    "end": "2472410"
  },
  {
    "text": "found that they can actually improve working with streams by about 2x now you could technically write that code yourself that's all they've done but",
    "start": "2472410",
    "end": "2478830"
  },
  {
    "text": "they've wrapped it inside this type because it's actually really really hard to do so it's really just removing the",
    "start": "2478830",
    "end": "2484500"
  },
  {
    "text": "boilerplate of trying to optimize streams yourself through this type the important thing about the way that",
    "start": "2484500",
    "end": "2489960"
  },
  {
    "text": "pipelines work is unlike a traditional sort of stream based approach you're working with the buffers yourself and",
    "start": "2489960",
    "end": "2495900"
  },
  {
    "text": "you're managing those the pipe it's is going to do that all for you so it's going to hand you some memory that",
    "start": "2495900",
    "end": "2501120"
  },
  {
    "text": "you're going to work with and you're going to just read out of it and you don't need to worry about the buffers it's also going to use the array pool",
    "start": "2501120",
    "end": "2506820"
  },
  {
    "text": "internally to do that so it avoids heap allocations for those buffers as well",
    "start": "2506820",
    "end": "2511850"
  },
  {
    "text": "two ends to a pipe it seems quite logical we have a writer and a reader so what does this look like well we have a",
    "start": "2511850",
    "end": "2518130"
  },
  {
    "text": "pipe so we're first going to start working with the pipe writers and when we get the pipe writer what we can do is we can say get memory this gives us a",
    "start": "2518130",
    "end": "2524850"
  },
  {
    "text": "memory of T memory a byte in this example why memory well we're inside an async method typically when we're",
    "start": "2524850",
    "end": "2530880"
  },
  {
    "text": "working through this we're going to be doing some i/o within the same method so there's likelihood of async calls in there so we get a memory of byte we",
    "start": "2530880",
    "end": "2538140"
  },
  {
    "text": "would do some work with that data that we've been given to put some data into it maybe how I built up the character array before for my object",
    "start": "2538140",
    "end": "2544650"
  },
  {
    "text": "key for example and when we're done we just advanced by the amount of bytes we've written and then when we're ready",
    "start": "2544650",
    "end": "2549690"
  },
  {
    "text": "we can flush it as well flushing it is the operation that signals to the reading end you've got some data that you might want to look at",
    "start": "2549690",
    "end": "2555390"
  },
  {
    "text": "now so on the reading M we have a pipe reader we can await the read async",
    "start": "2555390",
    "end": "2560430"
  },
  {
    "text": "method so it's a non-blocking operation by default which is really quite powerful it's not going to do anything",
    "start": "2560430",
    "end": "2565830"
  },
  {
    "text": "until there's something in that pipe that we haven't already seen we get back a read result on the re result is a",
    "start": "2565830",
    "end": "2571290"
  },
  {
    "text": "buffer and that buffer is interestingly of type read only sequence Y read only sequence and not memory well the reason",
    "start": "2571290",
    "end": "2578760"
  },
  {
    "text": "is the pipe in advance doesn't generally know how much data you're going to give it if you're streaming data off of a network socket you might get a small",
    "start": "2578760",
    "end": "2585390"
  },
  {
    "text": "amount of data or you may get lots and lots of data so the pipe has to be able to create buffers for you as it gets",
    "start": "2585390",
    "end": "2591600"
  },
  {
    "text": "more and more data as those buffers are filling up what it's going to do essentially is create some memory of T's",
    "start": "2591600",
    "end": "2596610"
  },
  {
    "start": "2595000",
    "end": "2595000"
  },
  {
    "text": "off of the array pool internally and then when it returns it to you it gives you the structure of a read-only sequence that just represents",
    "start": "2596610",
    "end": "2602670"
  },
  {
    "text": "essentially a linked list of those buffers so that you can then work through them as if it was one logical piece of memory so this is how you're",
    "start": "2602670",
    "end": "2610080"
  },
  {
    "text": "going to be sort of operating on the data that you get back from the pipe on the other end so this again is easier to",
    "start": "2610080",
    "end": "2615210"
  },
  {
    "text": "see in practice so what I'm going to do in this example the scenario here is tap separated file parsing which is super exciting",
    "start": "2615210",
    "end": "2621240"
  },
  {
    "text": "we had the scenario where we parse a tab separate file that was stored on AWS we we first decompress it which is kind of",
    "start": "2621240",
    "end": "2627290"
  },
  {
    "text": "important for this example but then what we're doing is parsing that data and getting basically just three parts of it",
    "start": "2627290",
    "end": "2633570"
  },
  {
    "text": "three particular properties out of that each row and storing them into elasticsearch so let's look at the code",
    "start": "2633570",
    "end": "2639840"
  },
  {
    "text": "for this and again I'll do the sort of before and after code and then we'll look at the actual improvement so this",
    "start": "2639840",
    "end": "2647100"
  },
  {
    "text": "is the before code again I'll just sort of quickly go over it so essentially we read in this case from a file just",
    "start": "2647100",
    "end": "2653010"
  },
  {
    "text": "because I didn't want to be using s free in my example but we get back a stream from history as well we would decompress",
    "start": "2653010",
    "end": "2658470"
  },
  {
    "text": "it and eventually what the original off of this code was doing was decompressing",
    "start": "2658470",
    "end": "2664380"
  },
  {
    "text": "the entire stream to an array to in order to create a long string that represents all of the data in that file",
    "start": "2664380",
    "end": "2671130"
  },
  {
    "text": "and the reason they were doing this is they're using this lie we call tiny CSV piles of which at least at the time I was sold only accepted",
    "start": "2671130",
    "end": "2677680"
  },
  {
    "text": "working with strings these files were about ten thousand rows each so if you start to think how much memory that",
    "start": "2677680",
    "end": "2683200"
  },
  {
    "text": "might be if we create a byte array that represents the file and then we could create a string for it this was setting",
    "start": "2683200",
    "end": "2689020"
  },
  {
    "text": "off some warning flags and we did actually have some memory leak issues with this service that led me to look at it initially so what I've done instead",
    "start": "2689020",
    "end": "2695380"
  },
  {
    "text": "is they you are sorry what they were using was this tiny CSV parser which has this quite nice sort of fluent syntax",
    "start": "2695380",
    "end": "2701650"
  },
  {
    "text": "for kind of saying I want to read this out of it and map it to these properties so the reason they were using the library was readability and convenience",
    "start": "2701650",
    "end": "2708300"
  },
  {
    "text": "but I had some concerns so the new code again I will just show you for",
    "start": "2708300",
    "end": "2713500"
  },
  {
    "text": "comparison this is longer again but hopefully something we can follow so we",
    "start": "2713500",
    "end": "2719470"
  },
  {
    "text": "start with the decompression stream as before so we're going to use the pipe here with a stream we use have to use a",
    "start": "2719470",
    "end": "2725260"
  },
  {
    "text": "stream in the early stages because there isn't really a pipe that can decompress at this point in time but that may well come with the framework but once we have",
    "start": "2725260",
    "end": "2732340"
  },
  {
    "text": "a stream we can just create a pipe reader over that stream and start working with the other end of the pipe",
    "start": "2732340",
    "end": "2737350"
  },
  {
    "text": "basically so the framework will handle writing into it we do the read async as",
    "start": "2737350",
    "end": "2743020"
  },
  {
    "text": "we saw in the example we get the buffer and eventually what we're going to do is call into piles lines passing in the buffer what this is doing is its new so",
    "start": "2743020",
    "end": "2750970"
  },
  {
    "text": "we've got a sequence reader which is the type that allows us to work with sequence in a very convenient way because that read only sequence type is",
    "start": "2750970",
    "end": "2757000"
  },
  {
    "text": "a bit of a pain to actually pass your way through but the sequence reader makes it quite straightforward because",
    "start": "2757000",
    "end": "2762010"
  },
  {
    "text": "as a method like try read to any where I can say look for in this case the the bytes that represent a newline character",
    "start": "2762010",
    "end": "2769150"
  },
  {
    "text": "if I've got a complete line I know I can pass the it to actual elements out of it if I don't have a line we're break here",
    "start": "2769150",
    "end": "2774790"
  },
  {
    "text": "and we'll wait till more data comes from the pipe when we do have at least one complete line we'll try and parse it and",
    "start": "2774790",
    "end": "2780130"
  },
  {
    "text": "in slow piles line we're kind of dropping now down to a spam based approach and all I'm looking for in this",
    "start": "2780130",
    "end": "2785890"
  },
  {
    "text": "case is within that span find me the index of the tab byte and count your position through and by using that tab",
    "start": "2785890",
    "end": "2792670"
  },
  {
    "text": "character as the way of identifying where you are so when you're at tab count one I know I want to read that",
    "start": "2792670",
    "end": "2798010"
  },
  {
    "text": "string so all we then do is slice from in this case the start position to where that tab is and now we've got some data",
    "start": "2798010",
    "end": "2803560"
  },
  {
    "text": "that we can immediately cast with string but we're actually gonna index into elastics and we just do that for the items we",
    "start": "2803560",
    "end": "2809380"
  },
  {
    "text": "want we break out early we only do the 11 tabs because after that we don't care about the rest of the line so we've done",
    "start": "2809380",
    "end": "2814870"
  },
  {
    "text": "some optimization by not even parsing data that we don't care about in terms of performance gains for this let's look",
    "start": "2814870",
    "end": "2820990"
  },
  {
    "text": "at the results so I did this test over 75 files of each we have about 10,000",
    "start": "2820990",
    "end": "2826780"
  },
  {
    "start": "2822000",
    "end": "2822000"
  },
  {
    "text": "rows because that was kind of representative of a load I was seen quite often in the service so in the",
    "start": "2826780",
    "end": "2831940"
  },
  {
    "text": "original we're about 8 and 1/2 seconds and we're under a second in the optimized code that's quite good it's",
    "start": "2831940",
    "end": "2837280"
  },
  {
    "text": "not like super exciting we move this is a processing service we could probably live with 8 and a half seconds but the",
    "start": "2837280",
    "end": "2843310"
  },
  {
    "text": "allocations was a really telling story 7 gigs of allocations reading through those files in the original flow because",
    "start": "2843310",
    "end": "2849580"
  },
  {
    "text": "of that byte array that we're creating and then that string copy of memory there's a lot of copying going on",
    "start": "2849580",
    "end": "2854980"
  },
  {
    "text": "there's a lot of allocations going on short live allocations we're down to 242 Meg's in the new flow which is quite a",
    "start": "2854980",
    "end": "2861250"
  },
  {
    "text": "significant drop 30 times roughly less what was really interesting was 203",
    "start": "2861250",
    "end": "2867460"
  },
  {
    "text": "megabyte of this strings that I'm outputting into the data I'm gonna push into elasticsearch so that means we're",
    "start": "2867460",
    "end": "2874330"
  },
  {
    "text": "sort of less than 40 mega overhead for this piece of work to happen now which is quite significant and actually I can",
    "start": "2874330",
    "end": "2879700"
  },
  {
    "text": "optimize a lot more of that way because elasticsearch accepts bytes so I could actually avoid those string allocations",
    "start": "2879700",
    "end": "2885130"
  },
  {
    "text": "entirely potentially with my code in the future so quite a lot of advantages that we were able to get with pipelines span",
    "start": "2885130",
    "end": "2891390"
  },
  {
    "text": "in that example so finally I want to touch on the JSON api's in that came in",
    "start": "2891390",
    "end": "2898150"
  },
  {
    "text": "donate core free route of interest we heard of like system text or Jason when it arrived pretty good number you read",
    "start": "2898150",
    "end": "2904480"
  },
  {
    "text": "the blog posts so this came in the Box Microsoft announced it it did cause a little bit of heat on Twitter when they",
    "start": "2904480",
    "end": "2911350"
  },
  {
    "text": "first said what they were doing because everyone started sort of stamping on Microsoft saying okay you're going after",
    "start": "2911350",
    "end": "2916720"
  },
  {
    "text": "the open-source community yet again we have Newton soft Jason we like that why are you building your own thing now",
    "start": "2916720",
    "end": "2923410"
  },
  {
    "text": "fortunately to kind of help ease that the James Newton king who wrote juice Jason Newton soft Jason came up and",
    "start": "2923410",
    "end": "2930220"
  },
  {
    "text": "wrote a blog post and explained why he thinks it's a good idea now to be fair mark sort of employed in so he's paid to",
    "start": "2930220",
    "end": "2935320"
  },
  {
    "text": "agree with them but you know hopefully he his points are fair and he probably",
    "start": "2935320",
    "end": "2941280"
  },
  {
    "text": "is representing his own viewpoint and the reasons for this were twofold so one of the issues was asp net core relies on",
    "start": "2941280",
    "end": "2947690"
  },
  {
    "text": "JSON parsing quite often in order to do model binding with data comes in as JSON",
    "start": "2947690",
    "end": "2952859"
  },
  {
    "text": "and to serialize data out in web api's this means that for that to work they have to pin the asp net core version to",
    "start": "2952859",
    "end": "2959369"
  },
  {
    "text": "a particular work version and newton soft jason they know works which means that if you want to use a different version in an asp net core app you",
    "start": "2959369",
    "end": "2965819"
  },
  {
    "text": "probably can't because it won't actually get brought in by new game and that was a bit of a pain for certain people that wanted the latest jason features but",
    "start": "2965819",
    "end": "2973619"
  },
  {
    "text": "were tied back to whatever has been at core had at the time it was released the other problem is performance and there",
    "start": "2973619",
    "end": "2980369"
  },
  {
    "text": "are ways to optimize obviously with things like span of T but to retrofit that in to Newton soft JSON which is",
    "start": "2980369",
    "end": "2986220"
  },
  {
    "text": "installed in so many millions of code bases which would introduce some kind of breakages to the API surface would have",
    "start": "2986220",
    "end": "2993240"
  },
  {
    "text": "been a bit of a nightmare for anyone that decided to take the next release so rather than break everyone in the world",
    "start": "2993240",
    "end": "2998700"
  },
  {
    "text": "they decided it probably makes sense to just build something in the box because this is done so often that asp net core",
    "start": "2998700",
    "end": "3003829"
  },
  {
    "text": "can rely on and optionally you can use too or you can continue to use Newton soft Jason there's free layers to the",
    "start": "3003829",
    "end": "3010460"
  },
  {
    "text": "way they've structured this so at the bottom level the lowest level that gives us the most performance we have a utf-8",
    "start": "3010460",
    "end": "3015589"
  },
  {
    "text": "JSON reader and a utf-8 json writer this is where it gets really gnarly we'll see some code for this in a moment but this",
    "start": "3015589",
    "end": "3022549"
  },
  {
    "text": "allows you to get the most sort of bang for your buck if you're really looking for performance then you can work at",
    "start": "3022549",
    "end": "3027980"
  },
  {
    "text": "this level if you're actually reading data a slightly more sort of less",
    "start": "3027980",
    "end": "3033109"
  },
  {
    "text": "verbose way and a slightly efficient way to do it is with this JSON document type that they bought this is essentially a",
    "start": "3033109",
    "end": "3038720"
  },
  {
    "text": "read-only view that in most cases might not actually even allocate any heap memory when it's working it gives you essentially a document object model of",
    "start": "3038720",
    "end": "3045410"
  },
  {
    "text": "Jason that you can pass your way through if you want to and then at the very top level we have a regular serializer and",
    "start": "3045410",
    "end": "3051829"
  },
  {
    "text": "deserialize err that are optimized they are quicker than newton soft Jason but",
    "start": "3051829",
    "end": "3056930"
  },
  {
    "text": "they're sort of less performant than working at the low-level code yourself because they have to be a bit more generic and a bit more general to the",
    "start": "3056930",
    "end": "3063260"
  },
  {
    "text": "Jason structure they get in those serialize azar quite sort of feature limited at this case they were released",
    "start": "3063260",
    "end": "3069020"
  },
  {
    "text": "with just what was enough for asp net core serialization Merilee that is being moved on in new",
    "start": "3069020",
    "end": "3075049"
  },
  {
    "text": "versions of.net core but just be aware that a they're limited in features and B they're quite strict about the Jason",
    "start": "3075049",
    "end": "3080839"
  },
  {
    "text": "structure new it's off Jason is quite good at working out what the Jason probably means even if it's not entirely",
    "start": "3080839",
    "end": "3086059"
  },
  {
    "text": "valid Jason systems or text or Jason will just generally throw an exception if it encounters invalid Jason so this",
    "start": "3086059",
    "end": "3093470"
  },
  {
    "text": "one is easier to see in practice again so here I'm going to do an example where I'm going to index something into an asset so it doesn't matter if you don't",
    "start": "3093470",
    "end": "3099349"
  },
  {
    "text": "know what a lastik search is but it has an operation that's essentially a rest Empire I can call to pass it some data",
    "start": "3099349",
    "end": "3104390"
  },
  {
    "text": "to store in the index what I need to do is when I get the response back I need to deserialize that response in order to",
    "start": "3104390",
    "end": "3111109"
  },
  {
    "text": "identify did that operation complete successfully overall and if it didn't complete overall successfully which of",
    "start": "3111109",
    "end": "3117710"
  },
  {
    "text": "the actual things I index failed because what we want to know is which ones we have to retry and so this is actually",
    "start": "3117710",
    "end": "3124190"
  },
  {
    "text": "quite a product at a hard problem to do in a very efficient way with regular",
    "start": "3124190",
    "end": "3129589"
  },
  {
    "text": "Jason so let's look at the original code now the good thing about this code is I can even at this ridiculous font size",
    "start": "3129589",
    "end": "3135200"
  },
  {
    "text": "fit the entire method on the screen so that's good and we're basically just taking the the Jason text reader over",
    "start": "3135200",
    "end": "3141410"
  },
  {
    "text": "the stream of data deserializing it to our type now inside that type basically the data that you get back from the",
    "start": "3141410",
    "end": "3147829"
  },
  {
    "text": "elasticsearch API is how long it took true or false were there any errors or not and then the collection of all the",
    "start": "3147829",
    "end": "3153170"
  },
  {
    "text": "items which is the metadata about everything within the request that we made what we can say is if there are no",
    "start": "3153170",
    "end": "3159230"
  },
  {
    "text": "errors at that top level property then great return that there's no errors a success true in this case and an empty",
    "start": "3159230",
    "end": "3165559"
  },
  {
    "text": "array of items that failed because there's nothing if there are errors then we have to work our way through it to find the ones that had a failure code",
    "start": "3165559",
    "end": "3171799"
  },
  {
    "text": "and then we've got the IDs for those that failed fantastic so we'll go to the new approach you can tell by the scroll",
    "start": "3171799",
    "end": "3178339"
  },
  {
    "text": "bar it's a bit bigger and again you know you",
    "start": "3178339",
    "end": "3183869"
  },
  {
    "text": "really have to make a judgment call on whether this is worthwhile in your scenarios again some horrible stuff at the top we can skip over so here we're",
    "start": "3183869",
    "end": "3190740"
  },
  {
    "text": "using the array pool fantastic so in this case rather than using pipe lines I'm going to use streams just natively",
    "start": "3190740",
    "end": "3196290"
  },
  {
    "text": "so I'm going to create the buffer for that stream but I'm going to use the array pool so this gives us the flexibility to at least not heap",
    "start": "3196290",
    "end": "3202440"
  },
  {
    "text": "allocate this temporary buffer a lot of code here so I'll skip over some of it",
    "start": "3202440",
    "end": "3207599"
  },
  {
    "text": "but ultimately what I'm going to do is I'm going to read from the stream into my buffer and then I'm gonna try and pause the errors and I pass a lot of",
    "start": "3207599",
    "end": "3213720"
  },
  {
    "text": "stuff in by reference here because I'm gonna track my state as I come into this method because I might not have the entire JSON blob in one go I possibly",
    "start": "3213720",
    "end": "3220710"
  },
  {
    "text": "won't so inside parse errors we're gonna use this utf-8 JSON reader this also takes",
    "start": "3220710",
    "end": "3226559"
  },
  {
    "text": "this is final block boolean and some state so this is a reaction type accepts",
    "start": "3226559",
    "end": "3231809"
  },
  {
    "text": "the possibility you're working with streams or data that's coming in in chunks so it allows you just to kind of keep calling it with the last state that",
    "start": "3231809",
    "end": "3238290"
  },
  {
    "text": "you had and it can keep parsing through further and further into the JSON and ultimately what we call is JSON don't",
    "start": "3238290",
    "end": "3244230"
  },
  {
    "text": "read and inside here once we've done that we basically get the token that we're at and we're low-level now with",
    "start": "3244230",
    "end": "3251700"
  },
  {
    "text": "we're looking at the opening curly brace of an object or we're looking at the start of an array but we have these tokens that we can work through and all",
    "start": "3251700",
    "end": "3258480"
  },
  {
    "text": "this horrible horrible switch cut who does is try more account with the known structure that I know I'm getting where",
    "start": "3258480",
    "end": "3264510"
  },
  {
    "text": "is the errors property and what's its value true or false on that one and potentially if I need to the items the",
    "start": "3264510",
    "end": "3271079"
  },
  {
    "text": "interesting thing I can do here is if I found the errors property here and then",
    "start": "3271079",
    "end": "3276119"
  },
  {
    "text": "on my next loop through if I find false as the value of that property then I'm",
    "start": "3276119",
    "end": "3282210"
  },
  {
    "text": "gonna break out of here and essentially if I come back up here I short-circuit the whole process and say well if",
    "start": "3282210",
    "end": "3288240"
  },
  {
    "text": "there's no errors found or I found the errors property and it has no errors stop if that's that's no errors in that",
    "start": "3288240",
    "end": "3295170"
  },
  {
    "text": "document I don't need to pass through the rest of the JSON at all that's within the first like 20 bytes of the JSON so I can optimize this code to",
    "start": "3295170",
    "end": "3301829"
  },
  {
    "text": "avoid parsing anything I don't care about only in this sort of failure case would it then have to go through and",
    "start": "3301829",
    "end": "3307500"
  },
  {
    "text": "identify and find all of those relevant IDs for the messages that failed again you can kind of a look at that code at",
    "start": "3307500",
    "end": "3312720"
  },
  {
    "text": "your own leisure if you're bored on a Sunday evening but otherwise I'll jump through to the",
    "start": "3312720",
    "end": "3317849"
  },
  {
    "text": "results which are a little more fun so in the failure response scenario and I totally frustrated with the numbers",
    "start": "3317849",
    "end": "3323700"
  },
  {
    "text": "because I'm sure there's more performance and this is the one risk you run with performance every time you see",
    "start": "3323700",
    "end": "3329010"
  },
  {
    "text": "an allocation you'll be like that so even here although we've gone down from 114 K to 16 K in the failure scenario at",
    "start": "3329010",
    "end": "3336900"
  },
  {
    "text": "16 K feels like failure but you know this is a pretty good game but the failing response is really unlikely in",
    "start": "3336900",
    "end": "3343319"
  },
  {
    "text": "our case we're not expecting things to fail on the indexing process so that success response is more interesting I",
    "start": "3343319",
    "end": "3349859"
  },
  {
    "text": "skip over those so the except success response here in the optimize flow is so",
    "start": "3349859",
    "end": "3354960"
  },
  {
    "text": "so much quicker because we read the first 20 bytes we see if there's no errors and we just dump doing any more",
    "start": "3354960",
    "end": "3360210"
  },
  {
    "text": "work and we only allocate frustratingly 80 bytes that really should be zero and",
    "start": "3360210",
    "end": "3366210"
  },
  {
    "text": "I need to spend some time in this code to figure out where 80 bytes is coming from but you know it's good enough as a",
    "start": "3366210",
    "end": "3372480"
  },
  {
    "text": "prototype and we've we've proved that in this sort of 99% case we are saving a",
    "start": "3372480",
    "end": "3377520"
  },
  {
    "text": "fair amount of allocations on what is going to be a fairly heavy and common operation in this particular scenario so",
    "start": "3377520",
    "end": "3385020"
  },
  {
    "text": "we're sort of wrapping up now we're getting towards the ends and the important thing you might be thinking is great I want to do some of this how do I",
    "start": "3385020",
    "end": "3390990"
  },
  {
    "text": "get work to let me to do it one you can be sneaky and just do it and kind of that's what I've done here all",
    "start": "3390990",
    "end": "3397049"
  },
  {
    "text": "of these prototypes are little lunchtime projects that I've done here and there where I've seen things that might be",
    "start": "3397049",
    "end": "3402510"
  },
  {
    "text": "interesting to take this forward what I suggest is you look for one of those kind of things like I did where I saw",
    "start": "3402510",
    "end": "3408030"
  },
  {
    "text": "heavy allocations in my case we had one service that was actually falling over because of the memory allocation so that",
    "start": "3408030",
    "end": "3413339"
  },
  {
    "text": "was a clue we should probably do something but even then you know just looking at that code casually you can see that array allocation the string",
    "start": "3413339",
    "end": "3419819"
  },
  {
    "text": "allocation was heavy heap allocation so see some look for something like that where you can kind of say yeah that's",
    "start": "3419819",
    "end": "3425430"
  },
  {
    "text": "really bad then use this scientific method of actually measuring first optimizing a small piece of code",
    "start": "3425430",
    "end": "3432000"
  },
  {
    "text": "measure again to give you these numbers that actually let you quantify what you've achieved do not go to the product",
    "start": "3432000",
    "end": "3437549"
  },
  {
    "text": "owner and go I've shaved 1000 bytes off of this particular method and it's now",
    "start": "3437549",
    "end": "3442560"
  },
  {
    "text": "only 400 nanoseconds because they won't give a damn all their ones really what you're babbling on about so",
    "start": "3442560",
    "end": "3447730"
  },
  {
    "text": "turn this into a monetary value try and establish for them what the value of this is and give them some kind of cost",
    "start": "3447730",
    "end": "3453309"
  },
  {
    "text": "to benefit ratio of you spending time doing this in in work time or real time to actually move this forward so this is",
    "start": "3453309",
    "end": "3459550"
  },
  {
    "text": "one example we had so we have a service that's an input process so this is one of the things that's doing kind of 18 million messages a day so fairly common",
    "start": "3459550",
    "end": "3467250"
  },
  {
    "start": "3460000",
    "end": "3460000"
  },
  {
    "text": "high volume workloads and so what I did is all of these individual prototypes plus a few I haven't had time to show",
    "start": "3467250",
    "end": "3473440"
  },
  {
    "text": "you where attempts at finding various parts of that flow that I could potentially optimize after some sort of",
    "start": "3473440",
    "end": "3479079"
  },
  {
    "text": "like maybe slightly positively biased estimations I've said that I think I can reduce 50% of the allocations inside",
    "start": "3479079",
    "end": "3485859"
  },
  {
    "text": "this little micro Service and I can probably double it throughput based on the execution time changes that I'm",
    "start": "3485859",
    "end": "3491319"
  },
  {
    "text": "seeing for the various phases so then what I've done is gone and looked at how much scaling this service is having to",
    "start": "3491319",
    "end": "3496540"
  },
  {
    "text": "do inside our container cluster to figure out actually I can probably get rid of enough scaling that means I save",
    "start": "3496540",
    "end": "3502059"
  },
  {
    "text": "one VM you know in our cluster on a sort of daily basis which is in our situation",
    "start": "3502059",
    "end": "3507460"
  },
  {
    "text": "about $1,700 a year for that that one service change now that might not be enough to justify a developer spending",
    "start": "3507460",
    "end": "3513940"
  },
  {
    "text": "their time on it but some of those processes particularly in micro services if you're doing a lot of data manipulation you'll be doing the same",
    "start": "3513940",
    "end": "3519579"
  },
  {
    "text": "thing time and time again in lots of services and if you can just kind of stamp and replace similar parsing logic",
    "start": "3519579",
    "end": "3524859"
  },
  {
    "text": "for those particular requirements we can ramp this up quite quickly at scale across the many hundreds of services we",
    "start": "3524859",
    "end": "3530140"
  },
  {
    "text": "might be talking about so you can start to show this value and you can then sort of see if you can get the business strategy to buy into this idea of",
    "start": "3530140",
    "end": "3536859"
  },
  {
    "text": "actually optimizing the code again where it's contextually worth doing if there's a good cost saving and the code doesn't change much this might be good for you",
    "start": "3536859",
    "end": "3543540"
  },
  {
    "text": "so in summary because this has like been a lot of stuff for and afternoon I can't remember what I said at the start",
    "start": "3543540",
    "end": "3549579"
  },
  {
    "start": "3544000",
    "end": "3544000"
  },
  {
    "text": "everything you've seen is really importantly mostly for advanced situations so this isn't stuff you go",
    "start": "3549579",
    "end": "3556420"
  },
  {
    "text": "back to office on Monday and go whoa I'm changing everything expounds going everywhere it's really tempting and when",
    "start": "3556420",
    "end": "3561940"
  },
  {
    "text": "you start is hard to stop but you know use some use some caution around where you're applying it measure everything",
    "start": "3561940",
    "end": "3568480"
  },
  {
    "text": "don't assume assume in this case can be really dangerous around you know making changes that are actually degrading",
    "start": "3568480",
    "end": "3574540"
  },
  {
    "text": "performance or having a knock-on effect elsewhere that you just couldn't actually even foresee be scientific in that so benchmark",
    "start": "3574540",
    "end": "3580999"
  },
  {
    "text": "dotnet is a fantastic quite easy tool to get going with initially that gives you these kind of accurate numbers that you",
    "start": "3580999",
    "end": "3586130"
  },
  {
    "text": "can work against focus on the hot past don't spend all your time optimizing something that's called once in a blue",
    "start": "3586130",
    "end": "3591229"
  },
  {
    "text": "moon it might be fantastically you get zero allocations but is that actually going to change your life in time in",
    "start": "3591229",
    "end": "3596749"
  },
  {
    "text": "terms of that services overall code so don't copy memory where you can slice it work with the span API is when you're",
    "start": "3596749",
    "end": "3602959"
  },
  {
    "text": "doing parsing of strings or byte data use those array pools that's quite a quick and easy change you can ply with",
    "start": "3602959",
    "end": "3609079"
  },
  {
    "text": "fairly insignificant code changes actually and it's still fairly readable code when you finish it it's not quite",
    "start": "3609079",
    "end": "3614269"
  },
  {
    "text": "as bad as some of those demos I showed you overall pipelines is great for you've got a lot of i/o can keep that in",
    "start": "3614269",
    "end": "3620179"
  },
  {
    "text": "mind there and the new API is for Jason if you are doing that JSON parsing as I've shown you can make some really",
    "start": "3620179",
    "end": "3626119"
  },
  {
    "text": "efficient sort of API calls and parsing of the responses you're getting with that kind of API one book I recommend",
    "start": "3626119",
    "end": "3632479"
  },
  {
    "text": "product net memory management Conrad's here at the conference he spoke yesterday on 0 GC fantastic book it's",
    "start": "3632479",
    "end": "3637789"
  },
  {
    "text": "about this thick and if you carry it around only where you get stronger but you're protected at night if someone comes on the tax you swing your bag you",
    "start": "3637789",
    "end": "3643579"
  },
  {
    "text": "kill them it's really worth having and this is where I've learned a lot of what I've seen in here about how networks",
    "start": "3643579",
    "end": "3649309"
  },
  {
    "text": "around memory and how you optimize and you span I'll leave the link up with the slide there again if you want to get in",
    "start": "3649309",
    "end": "3655640"
  },
  {
    "text": "touch afterwards please do follow me I'll tweet about this asp net core and gin or you can check my blog which is",
    "start": "3655640",
    "end": "3661849"
  },
  {
    "text": "limited to actual technical stuff otherwise thank you very much time's up thank you [Applause]",
    "start": "3661849",
    "end": "3673579"
  }
]
[
  {
    "text": "i'm michael stipe i'm the author of the hot chocolate graphql",
    "start": "3600",
    "end": "9440"
  },
  {
    "text": "libraryfor.net and today i want to talk about graphql",
    "start": "9440",
    "end": "15440"
  },
  {
    "text": "observability actually this talk has just",
    "start": "15440",
    "end": "20640"
  },
  {
    "text": "just very few slides because what i want to do",
    "start": "20640",
    "end": "26000"
  },
  {
    "text": "is unpack problems that we are facing in graphql libraries when we put them to",
    "start": "26000",
    "end": "32800"
  },
  {
    "text": "production so we are going to dig into",
    "start": "32800",
    "end": "38079"
  },
  {
    "text": "a graphql service and uh trying to explore what the issues with it with the servicer",
    "start": "38079",
    "end": "46239"
  },
  {
    "text": "and how we can fix them and how we can make them visible",
    "start": "46239",
    "end": "51520"
  },
  {
    "text": "so when the torx name is here graphical observability that is",
    "start": "51680",
    "end": "56800"
  },
  {
    "text": "actually is the aim where we want to be at the end of this talk",
    "start": "56800",
    "end": "62000"
  },
  {
    "text": "so why graphical observability so graphql has some unique challenges i",
    "start": "64799",
    "end": "70320"
  },
  {
    "text": "would say when you want to make performance impact visible",
    "start": "70320",
    "end": "77280"
  },
  {
    "text": "to the developers and that has to do with its nature",
    "start": "77280",
    "end": "83680"
  },
  {
    "text": "like if we look at this simple graphical query it's actually when i explain graphql getting started",
    "start": "83920",
    "end": "89840"
  },
  {
    "text": "to graphically i always start with this slide or it's always at the very beginning",
    "start": "89840",
    "end": "96560"
  },
  {
    "text": "and i tell people this is a hello world of graphql and it essentially asks here for",
    "start": "96560",
    "end": "104399"
  },
  {
    "text": "the name of the currently signed in user and if we send something like this to",
    "start": "104399",
    "end": "110560"
  },
  {
    "text": "our graph cursor we get exactly what we asked for i mean that's a great thing with graphql right",
    "start": "110560",
    "end": "118399"
  },
  {
    "text": "but it's also one of the challenges because a user then",
    "start": "118399",
    "end": "124960"
  },
  {
    "text": "can just ask for more data",
    "start": "124960",
    "end": "129240"
  },
  {
    "text": "and that means that the that i don't really know the performance characteristics",
    "start": "132080",
    "end": "138480"
  },
  {
    "text": "of my back end so how do i determine if everything goes right",
    "start": "138480",
    "end": "144879"
  },
  {
    "text": "if my service performs well or if the front-end developers now",
    "start": "144879",
    "end": "151920"
  },
  {
    "text": "created queries that are so huge that i really have an impact on my back end",
    "start": "151920",
    "end": "158239"
  },
  {
    "text": "and since the graphql we can really dig deep we could get into",
    "start": "159840",
    "end": "165280"
  },
  {
    "text": "related objects and so on and so forth really could create huge query trees",
    "start": "165280",
    "end": "173440"
  },
  {
    "text": "so typically and that is how many people start with graphql",
    "start": "175040",
    "end": "180480"
  },
  {
    "text": "is to put a thin layer of graphql over there business layers",
    "start": "180480",
    "end": "186400"
  },
  {
    "text": "if we look at that might be easy to figure out where performance issues are because graphql is very thin",
    "start": "186400",
    "end": "193120"
  },
  {
    "text": "we just have this business layer we should know what we are talking about",
    "start": "193120",
    "end": "198400"
  },
  {
    "text": "but in many setups graphql is actually deployed like this where we have microservice beneath",
    "start": "198400",
    "end": "204319"
  },
  {
    "text": "it rest services these rest services then again use",
    "start": "204319",
    "end": "209760"
  },
  {
    "text": "databases use other services this could be a huge tree",
    "start": "209760",
    "end": "215519"
  },
  {
    "text": "so selecting just fields in my query then poses a",
    "start": "215519",
    "end": "220799"
  },
  {
    "text": "risk or a challenge to me because i don't really know how many systems are",
    "start": "220799",
    "end": "226000"
  },
  {
    "text": "impacted my cr by my queries and another thing",
    "start": "226000",
    "end": "231120"
  },
  {
    "text": "how do i actually know what queries my front end developers are doing with my system how do i find that",
    "start": "231120",
    "end": "238239"
  },
  {
    "text": "out",
    "start": "238239",
    "end": "241239"
  },
  {
    "text": "so the big question is then how do we find production issues",
    "start": "243519",
    "end": "249120"
  },
  {
    "text": "because typically it's like this you deploy to your service and then it's done for you and then",
    "start": "249120",
    "end": "255760"
  },
  {
    "text": "somebody comes along and asks maybe did you deploy something new",
    "start": "255760",
    "end": "261040"
  },
  {
    "text": "why because something is not behaving as before maybe we are having issues things are",
    "start": "261040",
    "end": "268720"
  },
  {
    "text": "getting slower and this is actually where we",
    "start": "268720",
    "end": "276160"
  },
  {
    "text": "can start in a little exploration",
    "start": "276160",
    "end": "281040"
  },
  {
    "text": "let's say we have a little application let me just start it",
    "start": "281680",
    "end": "288720"
  },
  {
    "text": "i have your visual studio code and that is actually my back end",
    "start": "288720",
    "end": "294160"
  },
  {
    "text": "let me just start it up and we are not just looking from the",
    "start": "294160",
    "end": "299520"
  },
  {
    "text": "back end at it first let's actually look at the application",
    "start": "299520",
    "end": "304960"
  },
  {
    "text": "so this our back end let me just clear that here and then we that comes actually with the",
    "start": "304960",
    "end": "311600"
  },
  {
    "text": "front end and that's where the problems actually always begin",
    "start": "311600",
    "end": "318800"
  },
  {
    "text": "okay let me refresh that so that's my front-end application",
    "start": "321919",
    "end": "328080"
  },
  {
    "text": "let's redo that so server's warmed up it actually performs very well",
    "start": "328479",
    "end": "334960"
  },
  {
    "text": "but let's say my that the users reported performance",
    "start": "334960",
    "end": "340560"
  },
  {
    "text": "issues and maybe also some system administrator told us about",
    "start": "340560",
    "end": "347039"
  },
  {
    "text": "huge pressure on our system so how would we approach this find out",
    "start": "347039",
    "end": "354479"
  },
  {
    "text": "what is wrong with our system because when i refresh that that application here it",
    "start": "354479",
    "end": "360800"
  },
  {
    "text": "it performs very well 170 milliseconds for getting all this data that we see",
    "start": "360800",
    "end": "366560"
  },
  {
    "text": "here and i mean we could try and um",
    "start": "366560",
    "end": "372800"
  },
  {
    "text": "go to another page but it kind of performs very very well",
    "start": "372800",
    "end": "378960"
  },
  {
    "text": "so typically that's where we start yeah let's let's let's have a look at the locks or let's have a look at our",
    "start": "378960",
    "end": "385120"
  },
  {
    "text": "locks our locks we always post to the console like that's often how projects start",
    "start": "385120",
    "end": "391919"
  },
  {
    "text": "and then we can already see yeah that's that's quite a lot of stuff here",
    "start": "391919",
    "end": "397840"
  },
  {
    "text": "so let's clear that maybe and then have a look",
    "start": "397840",
    "end": "403919"
  },
  {
    "text": "at the very simple request so let's go maybe on the bit bitcoin",
    "start": "403919",
    "end": "410479"
  },
  {
    "text": "here that's our cryptocurrency a single cryptocurrency and let's have a look",
    "start": "410479",
    "end": "415599"
  },
  {
    "text": "what is being locked so we again can see that the request",
    "start": "415599",
    "end": "421120"
  },
  {
    "text": "times yeah they're very 170 to 350 milliseconds",
    "start": "421120",
    "end": "427919"
  },
  {
    "text": "so there is a variance but it's actually it doesn't feel so bad",
    "start": "427919",
    "end": "433520"
  },
  {
    "text": "and actually there's no lock because in our application we are using a store",
    "start": "434400",
    "end": "440240"
  },
  {
    "text": "that means we are caching the objects that's why my local application actually",
    "start": "440240",
    "end": "445599"
  },
  {
    "text": "performs so well",
    "start": "445599",
    "end": "449319"
  },
  {
    "text": "so let's refresh that so my store is destroyed and it just patches all the object that i need and that now for just",
    "start": "451919",
    "end": "459039"
  },
  {
    "text": "this single page i can already see that there there is a lot going on like",
    "start": "459039",
    "end": "465840"
  },
  {
    "text": "holy so much sql you can see we are selecting here the users",
    "start": "465840",
    "end": "473360"
  },
  {
    "text": "maybe a specific user then we are getting uh the the bitcoin",
    "start": "473360",
    "end": "480080"
  },
  {
    "text": "base data we are getting like price data and actually we are getting a lot of",
    "start": "480080",
    "end": "485280"
  },
  {
    "text": "price data oh no just a single one here then we are getting [Music]",
    "start": "485280",
    "end": "491039"
  },
  {
    "text": "watch list and you can see there there's a lot going on but then we are also doing http calls",
    "start": "491039",
    "end": "498319"
  },
  {
    "text": "here we're going to a rest service and we're getting the price for our",
    "start": "498319",
    "end": "503440"
  },
  {
    "text": "bitcoin here and then there's more sql",
    "start": "503440",
    "end": "509280"
  },
  {
    "text": "okay that's that's that's already an indicator where we could say that that that doesn't feel right",
    "start": "509280",
    "end": "515279"
  },
  {
    "text": "but we actually have no clue at this point but a lot of applications that",
    "start": "515279",
    "end": "522080"
  },
  {
    "text": "i also came to experience in production at projects",
    "start": "522080",
    "end": "527920"
  },
  {
    "text": "they just have logging and it's very difficult to understand",
    "start": "527920",
    "end": "533200"
  },
  {
    "text": "how your system works from a logging standpoint because you have this",
    "start": "533200",
    "end": "538800"
  },
  {
    "text": "huge data input that you have to sift through i mean there are tools and console",
    "start": "538800",
    "end": "544160"
  },
  {
    "text": "logging is maybe not the best approach to do it but it's a good enough approach on my local system",
    "start": "544160",
    "end": "551600"
  },
  {
    "text": "okay so how would i go in graphql about that",
    "start": "552480",
    "end": "557519"
  },
  {
    "text": "so when people start with graphql they always hear about something that that is",
    "start": "557519",
    "end": "562640"
  },
  {
    "text": "called apollo tracing and that is a more graphql way to look at performance data",
    "start": "562640",
    "end": "569680"
  },
  {
    "text": "of our resolvers because i saw there's a lot going on here but where is that actually going on and which query is",
    "start": "569680",
    "end": "576959"
  },
  {
    "text": "causing this so what we could do and this is also still a very naive way",
    "start": "576959",
    "end": "584000"
  },
  {
    "text": "in looking at that we could maybe just grab our graph code query here",
    "start": "584000",
    "end": "591200"
  },
  {
    "text": "let me just go at that",
    "start": "591200",
    "end": "596240"
  },
  {
    "text": "let's refresh that now we get our graphql query here we",
    "start": "596959",
    "end": "602800"
  },
  {
    "text": "we could just copy it copy the value then go into our graphql id of choice",
    "start": "602800",
    "end": "610639"
  },
  {
    "text": "and have a look at it",
    "start": "612800",
    "end": "616680"
  },
  {
    "text": "okay okay",
    "start": "623760",
    "end": "629279"
  },
  {
    "text": "so this is actually the the data that the client requests from",
    "start": "629279",
    "end": "634640"
  },
  {
    "text": "from our back end when it starts you can see so this is a view container query here that's the name of our operation",
    "start": "634640",
    "end": "641040"
  },
  {
    "text": "it's good to know we keep that in mind and then you can see we have a lot of fragments here and each fragments",
    "start": "641040",
    "end": "647200"
  },
  {
    "text": "fetches a certain amount of data like here's some base data description",
    "start": "647200",
    "end": "652640"
  },
  {
    "text": "then we have here the price data we are getting then we are actually actually fetching for our chart we are",
    "start": "652640",
    "end": "658720"
  },
  {
    "text": "fetching the change data so the price price points in",
    "start": "658720",
    "end": "663760"
  },
  {
    "text": "the historic price points over the day and there's more price data we are",
    "start": "663760",
    "end": "669440"
  },
  {
    "text": "actually fetching here so we can just run that also here again our back end but it dies",
    "start": "669440",
    "end": "676240"
  },
  {
    "text": "ah yeah it dies because it needs a variable here we also can just grab that from our",
    "start": "676240",
    "end": "684160"
  },
  {
    "text": "from our request here just copy and paste",
    "start": "684320",
    "end": "691040"
  },
  {
    "text": "into our variables and then we can actually run it and we get the data",
    "start": "691040",
    "end": "697519"
  },
  {
    "text": "let's rerun it and you can see it but here for the first time can see a variance it's 900 milliseconds to 200",
    "start": "697519",
    "end": "704800"
  },
  {
    "text": "milliseconds so there is variance but if you typically debug that if",
    "start": "704800",
    "end": "710079"
  },
  {
    "text": "you're in the range of 100 to 200 milliseconds you will not see a problem here",
    "start": "710079",
    "end": "715120"
  },
  {
    "text": "locally because you're just running this single instance that's why",
    "start": "715120",
    "end": "720399"
  },
  {
    "text": "when you when you publish such a thing to production you actually are surprised then that your system maybe goes down",
    "start": "720399",
    "end": "726800"
  },
  {
    "text": "okay let's have a look at the at at what we can do in graphql to make it",
    "start": "726800",
    "end": "734560"
  },
  {
    "text": "a bit more visible uh what's going on and i said there's",
    "start": "734560",
    "end": "739920"
  },
  {
    "text": "something called apollo tracing that's that's a naive approach",
    "start": "739920",
    "end": "745600"
  },
  {
    "text": "but you will get an idea of how your resolvers perform actually so we can go in here into our graphql",
    "start": "745600",
    "end": "752800"
  },
  {
    "text": "server and without chocolate we can just chain in our configuration",
    "start": "752800",
    "end": "758560"
  },
  {
    "text": "so this add graphql server is actually where our server configuration starts and then we can just chain in",
    "start": "758560",
    "end": "764320"
  },
  {
    "text": "so in this instance we are training in add apollo tracing",
    "start": "764320",
    "end": "769680"
  },
  {
    "text": "um and then we say always always trace it's not a good idea",
    "start": "770839",
    "end": "776480"
  },
  {
    "text": "actually you will see because if you always produce traces you will waste a",
    "start": "776480",
    "end": "782079"
  },
  {
    "text": "lot of performance and that's exactly what we don't want to do",
    "start": "782079",
    "end": "787600"
  },
  {
    "text": "but it's a good way to debug locally a bit okay so if we run that",
    "start": "787600",
    "end": "795920"
  },
  {
    "text": "we actually get now this extra data down here you can see",
    "start": "796480",
    "end": "803279"
  },
  {
    "text": "we should we don't maybe",
    "start": "804160",
    "end": "810800"
  },
  {
    "text": "let me check this can be because in banana cake but we actually don't support it",
    "start": "810800",
    "end": "817519"
  },
  {
    "text": "so let's go to playground",
    "start": "817519",
    "end": "821040"
  },
  {
    "text": "and put it in here",
    "start": "822880",
    "end": "827240"
  },
  {
    "text": "there is also a service called apollo studio which lets you essentially",
    "start": "833600",
    "end": "838639"
  },
  {
    "text": "send these tracing data to it",
    "start": "838639",
    "end": "843839"
  },
  {
    "text": "okay do we are we connected yes okay again we post our",
    "start": "845600",
    "end": "852000"
  },
  {
    "text": "query in here",
    "start": "852000",
    "end": "855639"
  },
  {
    "text": "and then we're gonna analyze it",
    "start": "858720",
    "end": "862959"
  },
  {
    "text": "so up so playground now has um has down let me get the way has down here this",
    "start": "863839",
    "end": "870639"
  },
  {
    "text": "tracing blade and if we run that query you can see we",
    "start": "870639",
    "end": "876079"
  },
  {
    "text": "get some performance inside here",
    "start": "876079",
    "end": "881120"
  },
  {
    "text": "and if we look at that we actually it doesn't look so bad like we have this price change is 62 milliseconds",
    "start": "881199",
    "end": "889199"
  },
  {
    "text": "and this history okay we know it goes to rest in point 215 milliseconds",
    "start": "889199",
    "end": "894399"
  },
  {
    "text": "so we get an idea over our resolvers here but we don't actually get real insights",
    "start": "894399",
    "end": "902639"
  },
  {
    "text": "and that is the problem with um with the approach of logging and tracing when you",
    "start": "902639",
    "end": "908320"
  },
  {
    "text": "look at it isolated let me go back to my slides",
    "start": "908320",
    "end": "916480"
  },
  {
    "text": "okay why i unpack that in this way is actually",
    "start": "924240",
    "end": "930240"
  },
  {
    "text": "that we don't don't really get insights in our system and it's everything is very isolated we cannot really see",
    "start": "930240",
    "end": "937199"
  },
  {
    "text": "what's going on we maybe see there is an issue we have this variance we could go now through the code we",
    "start": "937199",
    "end": "943920"
  },
  {
    "text": "could look at the resolvers what are they doing where are these things um where",
    "start": "943920",
    "end": "949839"
  },
  {
    "text": "where are these sql queries caused and so on and so forth but it can be very very difficult",
    "start": "949839",
    "end": "957040"
  },
  {
    "text": "to see the relation between distributed systems so this is where this concept of",
    "start": "957040",
    "end": "963120"
  },
  {
    "text": "observability comes in and that is essentially",
    "start": "963120",
    "end": "968399"
  },
  {
    "text": "the the ability to measure how healthy and how performant your system is",
    "start": "968399",
    "end": "974639"
  },
  {
    "text": "by collecting data by looking at the at the tracing data at the logging data at the metrics and so",
    "start": "974639",
    "end": "981040"
  },
  {
    "text": "and so forth so observability if you go two or three",
    "start": "981040",
    "end": "987120"
  },
  {
    "text": "years back was very difficult to achieve it was possible like",
    "start": "987120",
    "end": "992399"
  },
  {
    "text": "i worked at a large project and we built our own observability providers we",
    "start": "992399",
    "end": "997839"
  },
  {
    "text": "we injected into each uh http request we injected correlation ids we injected in",
    "start": "997839",
    "end": "1005600"
  },
  {
    "text": "into our messaging systems extra metadata to trace how the logging flow is and it",
    "start": "1005600",
    "end": "1012720"
  },
  {
    "text": "took a lot of effort and there was a single software engineer just working on that",
    "start": "1012720",
    "end": "1019440"
  },
  {
    "text": "that thing and it wasn't enough to have a really qualitative solution",
    "start": "1019440",
    "end": "1025520"
  },
  {
    "text": "so over the years there were a lot of approaches to tackle this problem",
    "start": "1025520",
    "end": "1032160"
  },
  {
    "text": "and that's actually where open telemetry comes in and starting with dot net six",
    "start": "1032160",
    "end": "1038480"
  },
  {
    "text": "using open telemetry becomes very very easy there are a couple of apis now in",
    "start": "1038480",
    "end": "1044240"
  },
  {
    "text": "dot net a new activity api where it's easy to produce traces to use these things that",
    "start": "1044240",
    "end": "1052559"
  },
  {
    "text": "we call spans to create them and to essentially collect",
    "start": "1052559",
    "end": "1058720"
  },
  {
    "text": "and produce this tracing data",
    "start": "1058720",
    "end": "1062640"
  },
  {
    "text": "so when we talk about open telemetry we have a couple of terms here",
    "start": "1064080",
    "end": "1071039"
  },
  {
    "text": "like we want to instrument our api essentially we want to add",
    "start": "1071039",
    "end": "1076400"
  },
  {
    "text": "special metadata to it to later work with that in a",
    "start": "1076400",
    "end": "1082960"
  },
  {
    "text": "certain tooling that brings us these observability concepts by default open telemetry doesn't",
    "start": "1082960",
    "end": "1090320"
  },
  {
    "text": "automatically make your system observable but it's essentially instrumenting your",
    "start": "1090320",
    "end": "1096080"
  },
  {
    "text": "apis and by doing this instrumentation we then generate data",
    "start": "1096080",
    "end": "1102640"
  },
  {
    "text": "that we can use that we can collect to ship to an actual",
    "start": "1102640",
    "end": "1108960"
  },
  {
    "text": "back end we call that export and these are actually the terms that are important we instrument we generate the",
    "start": "1108960",
    "end": "1115840"
  },
  {
    "text": "data we collect it and then we ship it to a tool there are a lot of tools out",
    "start": "1115840",
    "end": "1121200"
  },
  {
    "text": "there we are using today elastic which is very good but there are others",
    "start": "1121200",
    "end": "1127440"
  },
  {
    "text": "that are also very good like jager maybe you heard of it or honeycomb",
    "start": "1127440",
    "end": "1133840"
  },
  {
    "text": "and so forth so we also",
    "start": "1133840",
    "end": "1139679"
  },
  {
    "text": "talk about melt when we talk about open telemetry and melt if you hear it you think what's",
    "start": "1139679",
    "end": "1146799"
  },
  {
    "text": "that it actually just means metrics events logs and telemetry",
    "start": "1146799",
    "end": "1153679"
  },
  {
    "text": "because these four things make our system observable",
    "start": "1153679",
    "end": "1160080"
  },
  {
    "text": "so what are metrics metrics are things that we collect maybe the",
    "start": "1160320",
    "end": "1165919"
  },
  {
    "text": "the cpu usage of your system could be a metric how much memory you are using how often",
    "start": "1165919",
    "end": "1171679"
  },
  {
    "text": "your garbage collector is running there are metrics and a lot of these metrics microsoft",
    "start": "1171679",
    "end": "1178559"
  },
  {
    "text": "already implemented their default metrics about http about asp.net core about garbage collection and stuff like",
    "start": "1178559",
    "end": "1184880"
  },
  {
    "text": "that then we have events that is essentially when something happens on your system",
    "start": "1184880",
    "end": "1192400"
  },
  {
    "text": "so um i actually wrote a i read a good um article about that",
    "start": "1192400",
    "end": "1198480"
  },
  {
    "text": "and the lady explaining that there i said okay events you essentially can think of a vending machine",
    "start": "1198480",
    "end": "1204720"
  },
  {
    "text": "where you push a button and then something comes out that could be an event",
    "start": "1204720",
    "end": "1210159"
  },
  {
    "text": "and when we talk about about that in an open telemetry context we often",
    "start": "1210159",
    "end": "1215440"
  },
  {
    "text": "annotate these events with metadata and then you can use these metadata and",
    "start": "1215440",
    "end": "1220559"
  },
  {
    "text": "these events to um [Music] to analyze that in an observability",
    "start": "1220559",
    "end": "1226720"
  },
  {
    "text": "concept context and we will have a look at that how we can do that in in elastic",
    "start": "1226720",
    "end": "1233760"
  },
  {
    "text": "oh yeah and the the locks essentially is just the standard locks that you had",
    "start": "1233760",
    "end": "1239760"
  },
  {
    "text": "before just that we now with the traces",
    "start": "1239760",
    "end": "1244960"
  },
  {
    "text": "can put into spans and can put into context so you still have your locks",
    "start": "1244960",
    "end": "1250240"
  },
  {
    "text": "and combined with the traces the traces are these spans that we can put",
    "start": "1250240",
    "end": "1255600"
  },
  {
    "text": "around our more important things we we will have a look at that what that means",
    "start": "1255600",
    "end": "1261360"
  },
  {
    "text": "to measure what's happening between systems so typically",
    "start": "1261360",
    "end": "1269039"
  },
  {
    "text": "when we look at our app we have some kind of an api that we use",
    "start": "1269280",
    "end": "1274320"
  },
  {
    "text": "to instrument our application then we have the open telemetry sdk",
    "start": "1274320",
    "end": "1280720"
  },
  {
    "text": "and that is processing these events logs that we get here and",
    "start": "1280720",
    "end": "1286400"
  },
  {
    "text": "then we have something called an exporter that will ship these",
    "start": "1286400",
    "end": "1292000"
  },
  {
    "text": "these data somewhere like we could have a jaeger exporter and then locally look at these things",
    "start": "1292000",
    "end": "1298080"
  },
  {
    "text": "or we could have like an additional service an open 12v3",
    "start": "1298080",
    "end": "1303760"
  },
  {
    "text": "collector and if you're doing telemetry at scale you will actually um use an",
    "start": "1303760",
    "end": "1309840"
  },
  {
    "text": "open telemetry collector because you can better arrange how much",
    "start": "1309840",
    "end": "1314960"
  },
  {
    "text": "collector instances you want to better distribute the performance that this takes because also",
    "start": "1314960",
    "end": "1322320"
  },
  {
    "text": "instrumenting your services doesn't come free so in a typical typical",
    "start": "1322320",
    "end": "1329039"
  },
  {
    "text": "kubernetes cluster you might have two collectors or so and then you essentially offload the",
    "start": "1329039",
    "end": "1336080"
  },
  {
    "text": "processing to the collector instead instead of each of your applications and then this collector has again also",
    "start": "1336080",
    "end": "1343120"
  },
  {
    "text": "an exporter maybe and can export the data or push the data",
    "start": "1343120",
    "end": "1349520"
  },
  {
    "text": "to a telemetry backend in our setup we will use their elastic",
    "start": "1349520",
    "end": "1354880"
  },
  {
    "text": "apm for observability so let's go a bit in our code and",
    "start": "1354880",
    "end": "1363280"
  },
  {
    "text": "get more insights in our system just by the way so i put here",
    "start": "1363280",
    "end": "1370640"
  },
  {
    "text": "very naively apollo tracing always and don't do that um because it adds a huge",
    "start": "1370640",
    "end": "1377840"
  },
  {
    "text": "payload to your system so if you want to use a puller tracing tooling",
    "start": "1377840",
    "end": "1383919"
  },
  {
    "text": "then set it to on demand and that means you essentially can pass in a",
    "start": "1383919",
    "end": "1390080"
  },
  {
    "text": "header i think it was x x dash tracing",
    "start": "1390080",
    "end": "1395360"
  },
  {
    "text": "and then ask for telemetry data also this you should secure that",
    "start": "1395600",
    "end": "1402640"
  },
  {
    "text": "and only allow certain users to ask for that data otherwise you also open",
    "start": "1402640",
    "end": "1408080"
  },
  {
    "text": "with apollo tracing some security risks that somebody could use that",
    "start": "1408080",
    "end": "1413679"
  },
  {
    "text": "to bring your system down like because you're producing that",
    "start": "1413679",
    "end": "1419280"
  },
  {
    "text": "a lot of data and sending it down as the json okay so let's put open telemetry into our",
    "start": "1419280",
    "end": "1426320"
  },
  {
    "text": "system so the first thing i already put some libraries in here and at the moment",
    "start": "1426320",
    "end": "1433200"
  },
  {
    "text": "you can see that like my open telemetry versions are crc versions here and",
    "start": "1433200",
    "end": "1439200"
  },
  {
    "text": "picked because it's an ongoing project we started to see",
    "start": "1439200",
    "end": "1445600"
  },
  {
    "text": "um the abilities in dot net six uh and you can see it's now in the least",
    "start": "1445600",
    "end": "1451120"
  },
  {
    "text": "candidate uh staged uh so it's getting more mature but it's new",
    "start": "1451120",
    "end": "1457360"
  },
  {
    "text": "right and i also put these open cinema 3 apis",
    "start": "1457360",
    "end": "1462799"
  },
  {
    "text": "already in here and you really need to know which versions at the moment go together",
    "start": "1462799",
    "end": "1469360"
  },
  {
    "text": "still if you're starting with this i mean we are using that already at scale because we thought",
    "start": "1469360",
    "end": "1475440"
  },
  {
    "text": "when at our projects where we started with elastic should we go for the native elastic apis",
    "start": "1475440",
    "end": "1482880"
  },
  {
    "text": "that are available or should we invest already in open telemetry and since it's",
    "start": "1482880",
    "end": "1488159"
  },
  {
    "text": "a new project we went with open telemetry because that is a more",
    "start": "1488159",
    "end": "1493520"
  },
  {
    "text": "standardized way and allows me later if i want to move away from elastic to",
    "start": "1493520",
    "end": "1498720"
  },
  {
    "text": "jager or use different tooling additionally to produce the data for it and not be",
    "start": "1498720",
    "end": "1505919"
  },
  {
    "text": "tied into elastic itself so if you have a new project definitely start with",
    "start": "1505919",
    "end": "1511200"
  },
  {
    "text": "telemetry if you're already using a proprietary apis you can wait a bit",
    "start": "1511200",
    "end": "1518880"
  },
  {
    "text": "but you will see it will give us a lot of insights here okay",
    "start": "1518880",
    "end": "1524720"
  },
  {
    "text": "so the second thing for hot chocolate i put in was the hot chocolate diagnostic",
    "start": "1524720",
    "end": "1531520"
  },
  {
    "text": "and that essentially gives us insights into the hot chocolate in inner workings",
    "start": "1531520",
    "end": "1538400"
  },
  {
    "text": "essentially produces open telemetry data for a graphql",
    "start": "1538400",
    "end": "1545520"
  },
  {
    "text": "and down here you see this open terminatory installation instrumentation asp.net",
    "start": "1546159",
    "end": "1552240"
  },
  {
    "text": "core and http these two providers will give us telemetry events from the asp.net core",
    "start": "1552240",
    "end": "1559200"
  },
  {
    "text": "engine and also from the http client we will see in a second what that means",
    "start": "1559200",
    "end": "1565200"
  },
  {
    "text": "so the first thing that we actually have to do with our api is to declare what",
    "start": "1565200",
    "end": "1572000"
  },
  {
    "text": "the metadata about our api let me put that up here",
    "start": "1572000",
    "end": "1578559"
  },
  {
    "text": "so we would use something called the resource builder to essentially",
    "start": "1578559",
    "end": "1585360"
  },
  {
    "text": "um tell open telemetry what services did what service it is you can see my",
    "start": "1585360",
    "end": "1592799"
  },
  {
    "text": "service we call it coin api because it's about cryptocurrencies then we have a namespace here which i can use for",
    "start": "1592799",
    "end": "1599600"
  },
  {
    "text": "filtering later and i'm telling it it's version two i also",
    "start": "1599600",
    "end": "1605440"
  },
  {
    "text": "can provide here some things about the environment for instance this is a development",
    "start": "1605440",
    "end": "1613039"
  },
  {
    "text": "environment here and i'm using the net sdk",
    "start": "1613039",
    "end": "1618480"
  },
  {
    "text": "and i can provide some versioning here so this is some metadata what you can filter on in the open telemetry context later",
    "start": "1618480",
    "end": "1626559"
  },
  {
    "text": "the second thing is i need to put some instrumentation services in here",
    "start": "1626559",
    "end": "1633440"
  },
  {
    "text": "let's do that so let's first put the tracing in so at",
    "start": "1633440",
    "end": "1641200"
  },
  {
    "text": "open telemetry tracing i said there are four parts to open telemetry this is the",
    "start": "1641200",
    "end": "1646320"
  },
  {
    "text": "tracing part and you can see i added here http client instrumentation",
    "start": "1646320",
    "end": "1651760"
  },
  {
    "text": "asp.net core instrumentation and hot chocolate instrumentation the the second thing is i'm using an",
    "start": "1651760",
    "end": "1659399"
  },
  {
    "text": "otlp exporter so what is that otlp stands for open telemetry",
    "start": "1659399",
    "end": "1666480"
  },
  {
    "text": "um protocol um and it allows me to push to an open",
    "start": "1666480",
    "end": "1672799"
  },
  {
    "text": "telemetry collector so typically",
    "start": "1672799",
    "end": "1678640"
  },
  {
    "text": "you would let me just uh open this you would send them an open geometry",
    "start": "1679360",
    "end": "1684799"
  },
  {
    "text": "collector and so forth i'm not doing that here because it's more work",
    "start": "1684799",
    "end": "1690080"
  },
  {
    "text": "so this is for instance you have such a yummy file where you can configure your open telemetry",
    "start": "1690080",
    "end": "1696799"
  },
  {
    "text": "collector and can tell it essentially essentially that it shall push the data",
    "start": "1696799",
    "end": "1702000"
  },
  {
    "text": "to elastic so we would put here some authentication data in so that it can",
    "start": "1702000",
    "end": "1709360"
  },
  {
    "text": "can communicate with elastic and there is also from elastic like this",
    "start": "1709360",
    "end": "1714640"
  },
  {
    "text": "docker compose file which essentially gives you a local elastic cluster",
    "start": "1714640",
    "end": "1721520"
  },
  {
    "text": "setup already with the open telemetry collector so it's quite",
    "start": "1721520",
    "end": "1726640"
  },
  {
    "text": "um easy to set it up but for a demo it's a it creates a lot of overhead so",
    "start": "1726640",
    "end": "1732880"
  },
  {
    "text": "what i did and don't do it in your production system is i push directly to elastic",
    "start": "1732880",
    "end": "1740640"
  },
  {
    "text": "here because elastic actually understands the otlp protocol it's the",
    "start": "1740640",
    "end": "1747600"
  },
  {
    "text": "same protocol that the collector has right but it's um if you want to have a really",
    "start": "1747600",
    "end": "1754320"
  },
  {
    "text": "performant infrastructure and reliable infrastructure go with the collectors okay so the second thing we do",
    "start": "1754320",
    "end": "1762000"
  },
  {
    "text": "is we add the metrics",
    "start": "1762000",
    "end": "1765799"
  },
  {
    "text": "and at the moment we don't have any hot chocolate metrics um but you can put in your own metrics",
    "start": "1768240",
    "end": "1774720"
  },
  {
    "text": "that you want to collect about hot chocolate and we will have a look at that okay again we have the http metrics the",
    "start": "1774720",
    "end": "1781520"
  },
  {
    "text": "asp.net core metrics and we push it to the same same cluster",
    "start": "1781520",
    "end": "1787440"
  },
  {
    "text": "so with this we actually put everything in there's one more thing",
    "start": "1787440",
    "end": "1792720"
  },
  {
    "text": "so we are we are telling here our system to collect hot chocolate instrumentation events",
    "start": "1792720",
    "end": "1799120"
  },
  {
    "text": "but we still have to tell hot chocolate that it should produce these events so we say add",
    "start": "1799120",
    "end": "1805760"
  },
  {
    "text": "instrumentation and",
    "start": "1805760",
    "end": "1811279"
  },
  {
    "text": "now the execution engine will actually produces these events because we didn't want to",
    "start": "1811279",
    "end": "1817919"
  },
  {
    "text": "put them in by default because as i said they have some performance impact",
    "start": "1817919",
    "end": "1823840"
  },
  {
    "text": "okay let's run that",
    "start": "1825679",
    "end": "1828720"
  },
  {
    "text": "and then produce some calls i'm just executing this a couple of",
    "start": "1831360",
    "end": "1838880"
  },
  {
    "text": "times so we get some data",
    "start": "1838880",
    "end": "1844640"
  },
  {
    "text": "and then we are going to elastic",
    "start": "1844720",
    "end": "1849080"
  },
  {
    "text": "so my so elastic starts around at 40 dollars just if you're interested",
    "start": "1852640",
    "end": "1860559"
  },
  {
    "text": "what i have here is a 40 cluster",
    "start": "1860559",
    "end": "1865799"
  },
  {
    "text": "but as i said you could also run it locally it's open source they have a dual license",
    "start": "1866240",
    "end": "1872960"
  },
  {
    "text": "that's something new because amazon started stealing their stuff",
    "start": "1872960",
    "end": "1880720"
  },
  {
    "text": "and but it's essentially you can you can run it for free or in the cloud",
    "start": "1880960",
    "end": "1887840"
  },
  {
    "text": "okay so here's my ndc demo cluster let's go in that",
    "start": "1888399",
    "end": "1893840"
  },
  {
    "text": "oh conference connection so and most people when i tell them",
    "start": "1895200",
    "end": "1900399"
  },
  {
    "text": "elastic and observability there what elastics is for searching it is for",
    "start": "1900399",
    "end": "1906559"
  },
  {
    "text": "searching but the observability is built essentially on the um",
    "start": "1906559",
    "end": "1911600"
  },
  {
    "text": "on the elasticsearch engine so let's go in the observability here",
    "start": "1911600",
    "end": "1917120"
  },
  {
    "text": "and you can see i already have some lock rating here there are no metrics yet that are",
    "start": "1917120",
    "end": "1923919"
  },
  {
    "text": "interesting for me so but i can see that the apm has already some throughput data",
    "start": "1923919",
    "end": "1931440"
  },
  {
    "text": "and what we are going to look at is now the metric side uh the tracing side which is down here",
    "start": "1931440",
    "end": "1938559"
  },
  {
    "text": "in the apm level i can go here and have already a look i can see there's my coin api and",
    "start": "1938559",
    "end": "1945279"
  },
  {
    "text": "there's a price api the price api is actually my price data the rest course that we did i",
    "start": "1945279",
    "end": "1952960"
  },
  {
    "text": "also instrumented that so the system knows my that there is a price api",
    "start": "1952960",
    "end": "1959600"
  },
  {
    "text": "i can before we go in the tracing i actually can have a look at the service map",
    "start": "1959600",
    "end": "1964960"
  },
  {
    "text": "so because i produced traces here elastic was able to identify dependencies between my",
    "start": "1964960",
    "end": "1972559"
  },
  {
    "text": "services because it traces the trace it traces the logs",
    "start": "1972559",
    "end": "1978480"
  },
  {
    "text": "um between the services essentially by injecting um correlation ids into the",
    "start": "1978480",
    "end": "1983840"
  },
  {
    "text": "http request and so forth and and so on and also it can trace like you can see",
    "start": "1983840",
    "end": "1989440"
  },
  {
    "text": "okay the price api user postgres sql database so it knows a bit about my",
    "start": "1989440",
    "end": "1997360"
  },
  {
    "text": "setup here just from looking at these traces [Music]",
    "start": "1997360",
    "end": "2002880"
  },
  {
    "text": "and now i can essentially drill into that so let's go for the coin api here",
    "start": "2002880",
    "end": "2009840"
  },
  {
    "text": "and you can see here i have my environment so i can filter that to the development environment and then i can",
    "start": "2009840",
    "end": "2016559"
  },
  {
    "text": "see here this graphql which is not ideal",
    "start": "2016559",
    "end": "2022000"
  },
  {
    "text": "because we talked about graphql having so much having so much variance because the user",
    "start": "2022000",
    "end": "2028799"
  },
  {
    "text": "can actually send any query to my endpoint and now any graphql query actually",
    "start": "2028799",
    "end": "2036320"
  },
  {
    "text": "is tracked under the same endpoint this is not good this is a specific problem that we now have because we are using",
    "start": "2036320",
    "end": "2042480"
  },
  {
    "text": "the http uh telemetry together with graphql",
    "start": "2042480",
    "end": "2048158"
  },
  {
    "text": "i can see there's a query but for filtering and looking at these things it's actually not good how we organize",
    "start": "2048159",
    "end": "2054960"
  },
  {
    "text": "this so there is a way around that to make that better so before we go into",
    "start": "2054960",
    "end": "2061599"
  },
  {
    "text": "the telemetry data here let's just fix that up go back to our service",
    "start": "2061599",
    "end": "2067118"
  },
  {
    "text": "and put some options into here so we can say i want to",
    "start": "2067119",
    "end": "2072878"
  },
  {
    "text": "rewrite my telemetry events and it's essentially",
    "start": "2072879",
    "end": "2078240"
  },
  {
    "text": "i want to rename the root activity",
    "start": "2078240",
    "end": "2083119"
  },
  {
    "text": "and i show you in a second why and also um",
    "start": "2083760",
    "end": "2089440"
  },
  {
    "text": "include the graphql document so by default we don't do that you could choose to do that only on",
    "start": "2089440",
    "end": "2096000"
  },
  {
    "text": "maybe your testing environments because it's an extra payload that will send the whole graphql query to the telemetry",
    "start": "2096000",
    "end": "2101920"
  },
  {
    "text": "background or it doesn't have such an impact you don't have that scale then you just can",
    "start": "2101920",
    "end": "2108560"
  },
  {
    "text": "include it always okay so i did these two things but still i don't want to waste so much",
    "start": "2108560",
    "end": "2114960"
  },
  {
    "text": "time there it's not an ideal setup so in open telemetry we can actually",
    "start": "2114960",
    "end": "2121359"
  },
  {
    "text": "enrich the events that we are sending to our back end and we are going to do that here",
    "start": "2121359",
    "end": "2128960"
  },
  {
    "text": "and we are going to rename the root level for elastic so that it's nice and",
    "start": "2128960",
    "end": "2135359"
  },
  {
    "text": "tidy in our dashboard so this actually works through something",
    "start": "2135359",
    "end": "2140560"
  },
  {
    "text": "that we call an activity enricher so we say custom activity and",
    "start": "2140560",
    "end": "2147280"
  },
  {
    "text": "david t and richard.cs",
    "start": "2147280",
    "end": "2152400"
  },
  {
    "text": "and i already prepared this guy here so this is an activity enricher it essentially",
    "start": "2152400",
    "end": "2158800"
  },
  {
    "text": "inherits from activity enricher and i just generate the constructor here",
    "start": "2158800",
    "end": "2165200"
  },
  {
    "text": "we don't have to care about what is being passed in it's essentially the options and the pool to",
    "start": "2165200",
    "end": "2171119"
  },
  {
    "text": "efficiently generate strings okay and then i can override",
    "start": "2171119",
    "end": "2177599"
  },
  {
    "text": "how these how these data for my elastic cluster are being enriched with additional data",
    "start": "2177599",
    "end": "2184079"
  },
  {
    "text": "for instance i can say create the root activity name here",
    "start": "2184079",
    "end": "2189359"
  },
  {
    "text": "and in my case i know i show you why i do that in a second i'm just saying okay",
    "start": "2189359",
    "end": "2196400"
  },
  {
    "text": "the root activity name shall be the display name",
    "start": "2196400",
    "end": "2201720"
  },
  {
    "text": "and then we are going to put that in to our configuration here",
    "start": "2203119",
    "end": "2209359"
  },
  {
    "text": "and then we re run the queries a couple of times and look at the traces",
    "start": "2209359",
    "end": "2215520"
  },
  {
    "text": "so let's say blur",
    "start": "2215520",
    "end": "2219280"
  },
  {
    "text": "has singleton we want the activity enricher here activity and richer",
    "start": "2221680",
    "end": "2229040"
  },
  {
    "text": "which is our custom enricher okay with that",
    "start": "2229040",
    "end": "2234320"
  },
  {
    "text": "let's do that again go to banana cake pop here",
    "start": "2234320",
    "end": "2242320"
  },
  {
    "text": "and run these queries just just a couple of times that that we actually can see them in our system and have",
    "start": "2242320",
    "end": "2250720"
  },
  {
    "text": "a variance of traces actually okay",
    "start": "2250720",
    "end": "2256560"
  },
  {
    "text": "okay go here we are going back to our coin api",
    "start": "2256560",
    "end": "2261839"
  },
  {
    "text": "and let's refresh that and now you can see",
    "start": "2261839",
    "end": "2266880"
  },
  {
    "text": "that the traces that we produce actually have like this format that",
    "start": "2266880",
    "end": "2272960"
  },
  {
    "text": "looks almost like our query what we we are not posting the whole query here because it's a title but we will tell",
    "start": "2272960",
    "end": "2279599"
  },
  {
    "text": "you the name of the query that our client application uses and we also will",
    "start": "2279599",
    "end": "2285119"
  },
  {
    "text": "tell you about the root field this query uses okay from this we can then drill in we",
    "start": "2285119",
    "end": "2291599"
  },
  {
    "text": "down here see the latency distribution of our event so where are most of the",
    "start": "2291599",
    "end": "2297040"
  },
  {
    "text": "requests you can see okay some are in 200 milliseconds this one was when the server was not",
    "start": "2297040",
    "end": "2302880"
  },
  {
    "text": "warm was two seconds and then we have uh here 95 percentile",
    "start": "2302880",
    "end": "2309280"
  },
  {
    "text": "of the requests essentially in this in this bucket okay let me just drill into",
    "start": "2309280",
    "end": "2316560"
  },
  {
    "text": "some of these so we can see what really happens here now this is the graphql",
    "start": "2316560",
    "end": "2323760"
  },
  {
    "text": "event i can look at the metadata here i can see the actual uh graphql",
    "start": "2323760",
    "end": "2329440"
  },
  {
    "text": "query but i also have some other information like the hash um like i can see that it's a single",
    "start": "2329440",
    "end": "2336000"
  },
  {
    "text": "http request it was not batched and thinks about the transport and i can also see like my resolvers",
    "start": "2336000",
    "end": "2344320"
  },
  {
    "text": "we only report the resolvers that actually do something async so if you just have a field like a string like a",
    "start": "2344320",
    "end": "2351200"
  },
  {
    "text": "name of something we will not report it because it's just data that is useless but you can already see okay asset by",
    "start": "2351200",
    "end": "2358160"
  },
  {
    "text": "symbol is a field that cost me 10 milliseconds then we have this price field",
    "start": "2358160",
    "end": "2365839"
  },
  {
    "text": "and then you can see here some bad shapes that will do http requests",
    "start": "2365839",
    "end": "2371839"
  },
  {
    "text": "you can see there is something going to the change service here and each call to this change service",
    "start": "2371839",
    "end": "2379280"
  },
  {
    "text": "will actually do two database calls this is the first indicator where we",
    "start": "2379280",
    "end": "2384960"
  },
  {
    "text": "should say okay something may be wrong but if it's just one call",
    "start": "2384960",
    "end": "2391280"
  },
  {
    "text": "why not but then we can see it's actually two calls in this instance",
    "start": "2391280",
    "end": "2398000"
  },
  {
    "text": "that are going to the server so it's two database calls and that's just",
    "start": "2398000",
    "end": "2403440"
  },
  {
    "text": "for one asset so if we go in our client and look at",
    "start": "2403440",
    "end": "2409280"
  },
  {
    "text": "maybe a list of assets maybe let's do that",
    "start": "2409280",
    "end": "2415200"
  },
  {
    "text": "then we get more pressure on our system so we go here let's produce a couple of these events",
    "start": "2417359",
    "end": "2426800"
  },
  {
    "text": "okay so let's go in our overview coin api",
    "start": "2436640",
    "end": "2442480"
  },
  {
    "text": "let's refresh it and you can see now we we really get all",
    "start": "2442480",
    "end": "2447839"
  },
  {
    "text": "the insights from our client now you can see all the queries that are coming in here's the dashboard",
    "start": "2447839",
    "end": "2454319"
  },
  {
    "text": "query and you can see now we have a list and you can see here every price field",
    "start": "2454319",
    "end": "2461680"
  },
  {
    "text": "actually calls something and now you see a lot more database usage so this might be where our problem",
    "start": "2461680",
    "end": "2469599"
  },
  {
    "text": "lies with our back end which then at scale might produce",
    "start": "2469599",
    "end": "2474720"
  },
  {
    "text": "the problem and you can see there's a lot of things going on",
    "start": "2474720",
    "end": "2480640"
  },
  {
    "text": "and from that we could drill into our apis i mean this is",
    "start": "2480640",
    "end": "2486000"
  },
  {
    "text": "really not looking so good and i can see actually what is being called here i can",
    "start": "2486000",
    "end": "2492800"
  },
  {
    "text": "look at my http request and now could have a look at this new",
    "start": "2492800",
    "end": "2498480"
  },
  {
    "text": "api so what's being called you can see okay it's a batched request",
    "start": "2498480",
    "end": "2504880"
  },
  {
    "text": "so it should be fast we are batching actually the http request for multiple cryptocurrencies to this",
    "start": "2505040",
    "end": "2512480"
  },
  {
    "text": "so actually it should be fast but then let's have a look at the sql so first we are just looking at",
    "start": "2512480",
    "end": "2521200"
  },
  {
    "text": "how many things we have but then we are doing a percentage change call here that's good but we're",
    "start": "2521200",
    "end": "2527920"
  },
  {
    "text": "just getting one item and you can see",
    "start": "2527920",
    "end": "2533359"
  },
  {
    "text": "we're doing this again and we're doing this call again you can",
    "start": "2533359",
    "end": "2538880"
  },
  {
    "text": "see these chords are repeated so for each cryptocurrency that we are actually batching to our downstream service",
    "start": "2538880",
    "end": "2545040"
  },
  {
    "text": "we are doing again and again this course and this is this is something that",
    "start": "2545040",
    "end": "2551040"
  },
  {
    "text": "where you couldn't have expected that from the graphql layer the problem actually is",
    "start": "2551040",
    "end": "2556640"
  },
  {
    "text": "not in our graphql layer it's actually in this downstream service that we are using",
    "start": "2556640",
    "end": "2562480"
  },
  {
    "text": "where they didn't implement the batching maybe well so the version two of this endpoint actually introduced a problem",
    "start": "2562480",
    "end": "2568960"
  },
  {
    "text": "to our graphql layer and what we what we saw in projects",
    "start": "2568960",
    "end": "2574480"
  },
  {
    "text": "where we introduced such observability you automatically found a lot of issues",
    "start": "2574480",
    "end": "2582079"
  },
  {
    "text": "even if you didn't know about them because it now makes it transparent how these",
    "start": "2582079",
    "end": "2587920"
  },
  {
    "text": "how are these different distributed systems work together like the graphql",
    "start": "2587920",
    "end": "2592960"
  },
  {
    "text": "layer uses some other service down here maybe you even have another service under that and now you",
    "start": "2592960",
    "end": "2599359"
  },
  {
    "text": "you see what these services are doing how they are communicating",
    "start": "2599359",
    "end": "2604400"
  },
  {
    "text": "and what they are doing inefficiently so we could fix that probably",
    "start": "2604400",
    "end": "2611599"
  },
  {
    "text": "let's do that quickly we probably could in this instance i know i just have to",
    "start": "2611599",
    "end": "2618000"
  },
  {
    "text": "roll back the api change that the developer did so i could go in my data",
    "start": "2618000",
    "end": "2623200"
  },
  {
    "text": "loader that's where we do the batching and where we'd use the price change",
    "start": "2623200",
    "end": "2630160"
  },
  {
    "text": "and i just could go for the old api again",
    "start": "2630160",
    "end": "2635838"
  },
  {
    "text": "and say let's go dotnet run",
    "start": "2636560",
    "end": "2642000"
  },
  {
    "text": "then we could go to our client again",
    "start": "2647200",
    "end": "2651119"
  },
  {
    "text": "run these a couple of times so that we get",
    "start": "2653440",
    "end": "2657680"
  },
  {
    "text": "some new data",
    "start": "2659359",
    "end": "2662838"
  },
  {
    "text": "okay so there is one more thing after that",
    "start": "2666640",
    "end": "2674720"
  },
  {
    "text": "so we could again look at this probably some of the things should have changed now let's",
    "start": "2674720",
    "end": "2681280"
  },
  {
    "text": "look at this lower thing here and you can see now i'm using my old my",
    "start": "2681280",
    "end": "2688640"
  },
  {
    "text": "old version of the service and suddenly i'm just using one database call",
    "start": "2688640",
    "end": "2694720"
  },
  {
    "text": "so this is how observability makes it very transpar transparent or",
    "start": "2695680",
    "end": "2700960"
  },
  {
    "text": "the combination of open telemetry and elastic makes it very transparent",
    "start": "2700960",
    "end": "2706480"
  },
  {
    "text": "um what is going on between my systems there is so that's something i haven't",
    "start": "2706480",
    "end": "2712079"
  },
  {
    "text": "set up here but we are using that actually and that is machine learning so you can actually",
    "start": "2712079",
    "end": "2717920"
  },
  {
    "text": "produce produce i use machine learning to look at things",
    "start": "2717920",
    "end": "2724880"
  },
  {
    "text": "that are different like maybe you're running your system over a long time and we have these",
    "start": "2724880",
    "end": "2730240"
  },
  {
    "text": "tracing data and suddenly you do such a change and now you have multiple more",
    "start": "2730240",
    "end": "2735839"
  },
  {
    "text": "cores to your downstream services then elastic can actually send you an email",
    "start": "2735839",
    "end": "2740880"
  },
  {
    "text": "look your query now uses a lot more database connection as before",
    "start": "2740880",
    "end": "2746640"
  },
  {
    "text": "and then an engineer an engineer could look at that before you run into the problem where",
    "start": "2746640",
    "end": "2753119"
  },
  {
    "text": "the user calls you that the system is running into timeouts",
    "start": "2753119",
    "end": "2759040"
  },
  {
    "text": "and that is with um these events it becomes a lot easier if you're using",
    "start": "2759040",
    "end": "2764240"
  },
  {
    "text": "something like metrics here and you can use custom metrics",
    "start": "2764240",
    "end": "2769599"
  },
  {
    "text": "and it actually is quite simple to integrate them also with with",
    "start": "2769599",
    "end": "2776000"
  },
  {
    "text": "hot chocolate and our query engine we have a couple of things like we have a cost analysis api",
    "start": "2776000",
    "end": "2784000"
  },
  {
    "text": "so you can actually use a different execution pipeline here we could go for the use um",
    "start": "2784000",
    "end": "2792000"
  },
  {
    "text": "oh actually it's in the default pipeline um so you can set the options at request",
    "start": "2792000",
    "end": "2798880"
  },
  {
    "text": "options all right no modify request options",
    "start": "2798880",
    "end": "2805200"
  },
  {
    "text": "sorry for that and tell our system to",
    "start": "2805200",
    "end": "2810319"
  },
  {
    "text": "analyze the cost of a graphical query the cost of a graphql query let me just show you that",
    "start": "2810319",
    "end": "2816560"
  },
  {
    "text": "and because we are running out of time i'm not going to deep into that but it's",
    "start": "2816560",
    "end": "2821920"
  },
  {
    "text": "a good way to actually provide additional metrics to your system so we could say",
    "start": "2821920",
    "end": "2827839"
  },
  {
    "text": "complexity let me just get this here",
    "start": "2827839",
    "end": "2833838"
  },
  {
    "text": "complexity dot enable",
    "start": "2834000",
    "end": "2837839"
  },
  {
    "text": "and this will enable our complexity analysis on graphql queries we will look at",
    "start": "2839440",
    "end": "2847520"
  },
  {
    "text": "how the query is structured how many async fields you have and essentially generate a number that",
    "start": "2848400",
    "end": "2855359"
  },
  {
    "text": "describes the weight of this query for your system and we could send that as a metric",
    "start": "2855359",
    "end": "2862400"
  },
  {
    "text": "to your telemetry back end and then if the metro if the cost of queries",
    "start": "2862400",
    "end": "2870000"
  },
  {
    "text": "increases because your developers and your front end developers are using more and more fields or",
    "start": "2870000",
    "end": "2875839"
  },
  {
    "text": "it becomes more and more complex queries then you essentially also can put like events on",
    "start": "2875839",
    "end": "2881760"
  },
  {
    "text": "top of that and see okay that's actually wrong we need maybe to introduce something different here",
    "start": "2881760",
    "end": "2887359"
  },
  {
    "text": "or maybe we have to scale out because that's our new use case our new normal and things like that",
    "start": "2887359",
    "end": "2893280"
  },
  {
    "text": "um so i enabled that and this would now",
    "start": "2893280",
    "end": "2898960"
  },
  {
    "text": "write for every query the complexity into our metadata um",
    "start": "2898960",
    "end": "2905440"
  },
  {
    "text": "i just just to force the error because we don't have time to actually integrate that let",
    "start": "2905440",
    "end": "2911200"
  },
  {
    "text": "me do the max allowed query let me let me just put it to five",
    "start": "2911200",
    "end": "2917440"
  },
  {
    "text": "just to cause the error let's run that and then you will see what i mean",
    "start": "2917440",
    "end": "2926119"
  },
  {
    "text": "is it running okay so if i run that it actually leads",
    "start": "2928160",
    "end": "2934480"
  },
  {
    "text": "to an error but i what i wanted to show here is so the execution engine now",
    "start": "2934480",
    "end": "2940160"
  },
  {
    "text": "weights these queries and it says okay the the complexity of this query is 135.",
    "start": "2940160",
    "end": "2947520"
  },
  {
    "text": "and the the allowed complexity actually is just to cause this error but this",
    "start": "2947520",
    "end": "2954400"
  },
  {
    "text": "metric we could now send to elastic because we set enable complexity here",
    "start": "2954400",
    "end": "2959760"
  },
  {
    "text": "and then we could use that to weight our query and use machine learning to find out if",
    "start": "2959760",
    "end": "2966319"
  },
  {
    "text": "a query goes out of range should be allowed or things like that",
    "start": "2966319",
    "end": "2971359"
  },
  {
    "text": "in order to do that we would use the new api.net so it's",
    "start": "2971359",
    "end": "2977200"
  },
  {
    "text": "called meter i'm not integrating that now but just to",
    "start": "2977200",
    "end": "2983839"
  },
  {
    "text": "give you a hint where you can look and you can give a meter a name like we could call this foo dot bar like we",
    "start": "2983839",
    "end": "2991760"
  },
  {
    "text": "always have these dot notation and you also could give it a version",
    "start": "2991760",
    "end": "2997280"
  },
  {
    "text": "and then we could the version is always good because if you change the structure of it over time and",
    "start": "2997280",
    "end": "3004480"
  },
  {
    "text": "then you could essentially create counters or produce",
    "start": "3004480",
    "end": "3009599"
  },
  {
    "text": "some metric data and this would now be automatically integrated",
    "start": "3009599",
    "end": "3016000"
  },
  {
    "text": "because we could then take this key here and just tell our metrics here",
    "start": "3016000",
    "end": "3023359"
  },
  {
    "text": "that we are adding instrumentation and that we want to live",
    "start": "3023359",
    "end": "3028880"
  },
  {
    "text": "listen to that specific meter so this is how you could",
    "start": "3028880",
    "end": "3034400"
  },
  {
    "text": "integrate even more into your observability solution",
    "start": "3034400",
    "end": "3041359"
  },
  {
    "text": "we are almost we are at the end of our talk here",
    "start": "3041359",
    "end": "3046720"
  },
  {
    "text": "this is my twitter handle if you want to connect hot chocolate repositories here um so",
    "start": "3047920",
    "end": "3055359"
  },
  {
    "text": "all the code you will find there if you have questions i'm available you",
    "start": "3055359",
    "end": "3061760"
  },
  {
    "text": "can also come afterwards to me and if you want to have a chat",
    "start": "3061760",
    "end": "3067119"
  },
  {
    "text": "yeah if you like our project would be great if you star it if you don't it's also",
    "start": "3067359",
    "end": "3072400"
  },
  {
    "text": "okay questions",
    "start": "3072400",
    "end": "3079680"
  },
  {
    "text": "okay that was a quick dive into the problems that you could face",
    "start": "3081440",
    "end": "3087200"
  },
  {
    "text": "when you put graphical production and how you can solve the issues that you are facing there",
    "start": "3087200",
    "end": "3093760"
  },
  {
    "text": "okay",
    "start": "3093920",
    "end": "3096920"
  }
]
[
  {
    "text": "so good afternoon everybody um i'm phillip",
    "start": "4720",
    "end": "9920"
  },
  {
    "text": "i'll walk you for the next 50 or so minutes through a couple of elasticsearch things and just to get a",
    "start": "9920",
    "end": "16080"
  },
  {
    "text": "quick idea who is already using elasticsearch who has no idea what elasticsearch is",
    "start": "16080",
    "end": "23439"
  },
  {
    "text": "okay very few um i would have a ton of slides but i don't",
    "start": "23439",
    "end": "28800"
  },
  {
    "text": "want to show you a million slides um we will draw all of this out on the whiteboard so we'll do it more interactively if you",
    "start": "28800",
    "end": "34960"
  },
  {
    "text": "have any questions just shout and ask um for good questions or answers i also",
    "start": "34960",
    "end": "40160"
  },
  {
    "text": "have these bouncy balls that are supposed to blink and i'll throw these at you um so don't fall asleep otherwise",
    "start": "40160",
    "end": "46480"
  },
  {
    "text": "a bouncy ball might hit you at some point um that's the other thing we can do with those so um",
    "start": "46480",
    "end": "53360"
  },
  {
    "text": "and like i said we would have a ton of slides but we will not do slides i've i've done too many slides recently and we'll we'll do this differently so for",
    "start": "53360",
    "end": "60079"
  },
  {
    "text": "those of you who have never heard of elasticsearch um i've just stumbled today across something that was",
    "start": "60079",
    "end": "65840"
  },
  {
    "text": "aggregating github stats and the nice thing is in terms of various metrics like stars pull requests",
    "start": "65840",
    "end": "75040"
  },
  {
    "text": "loads pull request creators and also issues though i'm not sure if",
    "start": "75040",
    "end": "80960"
  },
  {
    "text": "issues is a great metric elasticsearch is one of the most popular data source or the most popular data store on github",
    "start": "80960",
    "end": "87439"
  },
  {
    "text": "as of today and we've had the most issues for a long time i'm not sure there's a bug or a feature but that is a",
    "start": "87439",
    "end": "93840"
  },
  {
    "text": "different thing so when you use elasticsearch and i have started the cluster already um we have the current",
    "start": "93840",
    "end": "100400"
  },
  {
    "text": "version running here which tells me it's 8.2.2 which is fine",
    "start": "100400",
    "end": "106000"
  },
  {
    "text": "and that one what you normally would do is um you would then add a document so you could just say",
    "start": "106000",
    "end": "112960"
  },
  {
    "text": "post post let's say it's a test document and i want to add a document",
    "start": "112960",
    "end": "119119"
  },
  {
    "text": "and then i say i don't know my name is",
    "start": "119119",
    "end": "124640"
  },
  {
    "text": "and then it will do something and it will tell me that it this was successful and it was written successfully twice",
    "start": "126560",
    "end": "131920"
  },
  {
    "text": "and we'll figure out why twice and version one and we'll get back to all of these um",
    "start": "131920",
    "end": "137599"
  },
  {
    "text": "but this looks very simple right and kind of like we'll now open the hood and see what is happening behind the",
    "start": "137599",
    "end": "143599"
  },
  {
    "text": "scenes in all of this um starting with um what is the cluster and by the way if you've ever seen the elastic logo um",
    "start": "143599",
    "end": "150319"
  },
  {
    "text": "looks like this there are a couple of stickers next to the feedback box take the stickers afterwards so i don't have to carry them home but the elastic logo",
    "start": "150319",
    "end": "156720"
  },
  {
    "text": "looks like this um this is not a flower as some people think and this is a",
    "start": "156720",
    "end": "162160"
  },
  {
    "text": "cluster and you can see these little colored pieces here these are the",
    "start": "162160",
    "end": "167360"
  },
  {
    "text": "so-called charts we'll get to the shards later on but this is very related to what elasticsearch does and where it's",
    "start": "167360",
    "end": "172480"
  },
  {
    "text": "coming from and this is why the logo looks like this so the basic thing is um we we wrote this",
    "start": "172480",
    "end": "179680"
  },
  {
    "text": "document and it came into my cluster and then my cluster did something and it was just working and",
    "start": "179680",
    "end": "186000"
  },
  {
    "text": "the simplest way to run the cluster in elasticsearch is you could run the binary on windows linux as a docker",
    "start": "186000",
    "end": "192800"
  },
  {
    "text": "image and various other ways and what you would have is you have a node and i'll just say this is my node",
    "start": "192800",
    "end": "199200"
  },
  {
    "text": "and your write operation comes in here and then it sends out the response afterwards it also sends back out of the",
    "start": "199200",
    "end": "206400"
  },
  {
    "text": "cluster now this is the very simple cluster that you could have obviously you want to have more than a single node",
    "start": "206400",
    "end": "213200"
  },
  {
    "text": "because a you might want to scale and b you want to have some high availability so if that node",
    "start": "213200",
    "end": "218799"
  },
  {
    "text": "goes down we wouldn't succeed in that so we will need to add a second node",
    "start": "218799",
    "end": "225360"
  },
  {
    "text": "for those who have used elasticsearch in the past can i have a cluster with two nodes",
    "start": "225360",
    "end": "230560"
  },
  {
    "text": "in elasticsearch",
    "start": "230560",
    "end": "233440"
  },
  {
    "text": "yes i so yeah so there so there is a very big caveat um and i'll",
    "start": "235680",
    "end": "241200"
  },
  {
    "text": "i say i'll give you a bouncy ball for that um so yes you can do that um but this is a",
    "start": "241200",
    "end": "248080"
  },
  {
    "text": "very bad idea and you should not do this um why because elasticsearch is based on a",
    "start": "248080",
    "end": "254560"
  },
  {
    "text": "quorum concept so there is something called the cluster state and the cluster state is basically how is the cluster",
    "start": "254560",
    "end": "260639"
  },
  {
    "text": "organized it's not the the data itself but it's the metadata of your cluster and that keeps track of which",
    "start": "260639",
    "end": "267280"
  },
  {
    "text": "indices and charts will get to those concepts but which things of information do you have what notes do you have there",
    "start": "267280",
    "end": "272479"
  },
  {
    "text": "what are the the mappings also called schemas in your cluster so all of these need to be stored in the cluster",
    "start": "272479",
    "end": "278639"
  },
  {
    "text": "and the problem is this is a quorum system because maybe you've heard of the cap theorem consistency availability",
    "start": "278639",
    "end": "285680"
  },
  {
    "text": "petition tolerance and you can have at most two of those three so the problem is if you have only two",
    "start": "285680",
    "end": "292720"
  },
  {
    "text": "nodes and the network between those two nodes breaks which note is still alive or the right",
    "start": "292720",
    "end": "299600"
  },
  {
    "text": "one because you could either write them to this one or to that one and they wouldn't know if the other one is there",
    "start": "299600",
    "end": "304960"
  },
  {
    "text": "and the so-called cluster state can only be managed by one so-called masternode is already",
    "start": "304960",
    "end": "310560"
  },
  {
    "text": "mentioned so there are multiple master eligible nodes and they vote the current master",
    "start": "310560",
    "end": "316240"
  },
  {
    "text": "and you need a quorum for that and a quorum is made out of normally an odd number because you need to have the",
    "start": "316240",
    "end": "322320"
  },
  {
    "text": "election so normally you will would have a third node um",
    "start": "322320",
    "end": "328080"
  },
  {
    "text": "and these three then if the network between those here breaks then this node would",
    "start": "328080",
    "end": "334560"
  },
  {
    "text": "know i don't see the other two i'm isolated i cannot be keeping track of the current cluster",
    "start": "334560",
    "end": "340240"
  },
  {
    "text": "state um i can't do anything whereas these two as long as they see each other they know we're in the majority so",
    "start": "340240",
    "end": "346560"
  },
  {
    "text": "whatever happens we are keeping that cluster alive and then those two for example um would",
    "start": "346560",
    "end": "352960"
  },
  {
    "text": "make the let's say this is a little crown and this one would be the current uh",
    "start": "352960",
    "end": "358240"
  },
  {
    "text": "masternode of that cluster so the the minimum you need to have in any",
    "start": "358240",
    "end": "363520"
  },
  {
    "text": "highly available cluster is three nodes um otherwise either you are not highly",
    "start": "363520",
    "end": "368639"
  },
  {
    "text": "available because you have a single node or you could have two nodes um but then only one could be master",
    "start": "368639",
    "end": "374080"
  },
  {
    "text": "eligible because that would then decide and keep track of the cluster state because with two there is no no quorum",
    "start": "374080",
    "end": "379120"
  },
  {
    "text": "and you couldn't keep track of that yes",
    "start": "379120",
    "end": "382479"
  },
  {
    "text": "your cluster is dead so yes so if you don't have a majority",
    "start": "386800",
    "end": "392800"
  },
  {
    "text": "anymore in your cluster then the cluster will just stop so if you if you have a very volatile environment and you say",
    "start": "392800",
    "end": "399199"
  },
  {
    "text": "like maybe i lose two of those master eligible nodes at once how many master eligible nodes would you",
    "start": "399199",
    "end": "405600"
  },
  {
    "text": "need five because you still need that majority of three so you could then lose two so anybody who has an even number of",
    "start": "405600",
    "end": "412960"
  },
  {
    "text": "master eligible nodes um is probably not doing their themselves a favor because if i have four master eligible nodes",
    "start": "412960",
    "end": "418319"
  },
  {
    "text": "what is the majority of four three so i can still only lose one single note so you're not doing yourself",
    "start": "418319",
    "end": "424960"
  },
  {
    "text": "any favor um so that's um um",
    "start": "424960",
    "end": "430319"
  },
  {
    "text": "that that that's not any good so this is the cluster and so far i have talked",
    "start": "430319",
    "end": "435919"
  },
  {
    "text": "only about the so-called master eligible nodes or masternode there can only be one masternode at once",
    "start": "435919",
    "end": "442800"
  },
  {
    "text": "we had box in the past if that there are multiple masternodes that will mean a very bad day for your cluster um",
    "start": "442800",
    "end": "451840"
  },
  {
    "text": "there was one concept we've had for a long time which was called minimum",
    "start": "452319",
    "end": "457680"
  },
  {
    "text": "masternodes where you had to set what is the minimum so if you had three master eligible nodes you would need to set",
    "start": "457680",
    "end": "463120"
  },
  {
    "text": "that to two so that your cluster knows what is the majority we have removed that concept by now",
    "start": "463120",
    "end": "469599"
  },
  {
    "text": "we now have a bootstrapping concept where the nodes find each other and once they have formed a stable cluster the",
    "start": "469599",
    "end": "475360"
  },
  {
    "text": "cluster itself will keep track of how many master eligible nodes you have and what is the majority of that so you",
    "start": "475360",
    "end": "481840"
  },
  {
    "text": "cannot miscalculate and you also don't have problems if you scale your master eligible nodes up or down your cluster",
    "start": "481840",
    "end": "488000"
  },
  {
    "text": "will keep track of that because that was in older versions one of the or probably",
    "start": "488000",
    "end": "493360"
  },
  {
    "text": "the number one reason why you screwed up your cluster was that the minimum master nodes were not configured correctly and",
    "start": "493360",
    "end": "499199"
  },
  {
    "text": "then they would basically break into two separate clusters and there was no way to reconcile that so by now you only",
    "start": "499199",
    "end": "506560"
  },
  {
    "text": "basically in the configuration when you bootstrap a cluster you would only only need to tell the nodes like hey there",
    "start": "506560",
    "end": "511680"
  },
  {
    "text": "are these other nodes and you would say like this is master eligibility or master eligible and they will then",
    "start": "511680",
    "end": "517039"
  },
  {
    "text": "figure out okay we have formed the majority we form or we elect or vote for a master node we",
    "start": "517039",
    "end": "523760"
  },
  {
    "text": "form a stable cluster and then they just work and whatever you change in the cluster as long as you don't remove more",
    "start": "523760",
    "end": "530080"
  },
  {
    "text": "than half of the master eligible nodes at once your cluster will just keep working and doing everything for you but this was a",
    "start": "530080",
    "end": "536959"
  },
  {
    "text": "big pain point in the past that we got rid of um so far our cluster hasn't done anything",
    "start": "536959",
    "end": "543200"
  },
  {
    "text": "useful because i was just talking about metadata right we actually normally care about the actual data so besides being",
    "start": "543200",
    "end": "550000"
  },
  {
    "text": "master eligible there are various other roles a cluster can have so that the default role that we would have is a",
    "start": "550000",
    "end": "555440"
  },
  {
    "text": "so-called data node that's one that stores data there are other roles like",
    "start": "555440",
    "end": "560560"
  },
  {
    "text": "ingest which is doing an interest processing so if you have log lines and you need to break them apart with",
    "start": "560560",
    "end": "565839"
  },
  {
    "text": "regular expressions um an interest note could do that who likes writing regular expressions",
    "start": "565839",
    "end": "572880"
  },
  {
    "text": "okay that's the stockholm syndrome right",
    "start": "572880",
    "end": "577240"
  },
  {
    "text": "um there are better ways than that but that's a different discussion anyway so you have um",
    "start": "578000",
    "end": "584320"
  },
  {
    "text": "you have your data nodes um there are other node types that we could have as",
    "start": "584320",
    "end": "589440"
  },
  {
    "text": "well so there are client only nodes which are like like a smart proxy or load balance in the cluster",
    "start": "589440",
    "end": "595360"
  },
  {
    "text": "which might not be that useful and needed anymore we also have some machine learning components so by default your",
    "start": "595360",
    "end": "601839"
  },
  {
    "text": "nodes have all of these roles but if you have a very large cluster you would break them out into different roles so",
    "start": "601839",
    "end": "607519"
  },
  {
    "text": "for example that ingest node that runs irregular expressions would mostly need cpu to do all the parsing but it",
    "start": "607519",
    "end": "613279"
  },
  {
    "text": "wouldn't need so much memory and disk whereas your data nodes which store all the data would have a different hardware profile so once you have a larger",
    "start": "613279",
    "end": "620079"
  },
  {
    "text": "cluster you would have different roles and you would break them out to use better hardware profiles to make it more cost efficient and performant",
    "start": "620079",
    "end": "626480"
  },
  {
    "text": "um but that is only for a from a certain size on i would say like if you have nine or more notes or so you",
    "start": "626480",
    "end": "633839"
  },
  {
    "text": "could start thinking about breaking out the different rows but you will always need at least two for high available",
    "start": "633839",
    "end": "640399"
  },
  {
    "text": "availability of each roll type except for the master eligible nodes where you always need three for the majority",
    "start": "640399",
    "end": "647279"
  },
  {
    "text": "and then you could structure your clusters also for stability we often recommend for larger clusters like nine",
    "start": "647279",
    "end": "652720"
  },
  {
    "text": "plus or so to have so-called dedicated masternodes which only have the role of that master",
    "start": "652720",
    "end": "657760"
  },
  {
    "text": "because if the nodes with that cluster state are running some queries and run out of memory and die your cluster again will",
    "start": "657760",
    "end": "664560"
  },
  {
    "text": "have a very bad day because no master nodes um pretty much everything stops and breaks so from a certain size on you",
    "start": "664560",
    "end": "671600"
  },
  {
    "text": "probably want to break those out in a into a specific or into a dedicated node to avoid those problems and have higher",
    "start": "671600",
    "end": "677920"
  },
  {
    "text": "cluster stability um so just to give you an idea what i have running here is um",
    "start": "677920",
    "end": "685040"
  },
  {
    "text": "i use the so-called cat api which gives us in human readable form shows us what is going on in the cluster and i'm",
    "start": "685040",
    "end": "691200"
  },
  {
    "text": "interested in the notes here and actually just shows you a lot of almost random",
    "start": "691200",
    "end": "697040"
  },
  {
    "text": "numbers and things and i'll just add the so-called oops",
    "start": "697040",
    "end": "702079"
  },
  {
    "text": "lowercase it should lower case v parameter and that then adds the headers and then you can see what is",
    "start": "702079",
    "end": "709519"
  },
  {
    "text": "going on in here so you can see i have a cluster with three nodes um",
    "start": "709519",
    "end": "714639"
  },
  {
    "text": "this is the ip this is the the heap and ram used the cpu i have assigned to those",
    "start": "714639",
    "end": "721200"
  },
  {
    "text": "the load then we have various rows i'll get into those into a moment in a moment",
    "start": "721200",
    "end": "726560"
  },
  {
    "text": "all three here are master eligible because only three nodes so we need a majority and this one with that little",
    "start": "726560",
    "end": "731839"
  },
  {
    "text": "star this is the currently elected master and then you have well the names and you can see my",
    "start": "731839",
    "end": "738560"
  },
  {
    "text": "cluster is basically using two and a half nodes because it's using two full nodes and then a so-called tie breaker",
    "start": "738560",
    "end": "745120"
  },
  {
    "text": "this tiebreaker is only there really to to decide in the vote um to guarantee that majority but here i",
    "start": "745120",
    "end": "752320"
  },
  {
    "text": "like you said before i almost have a two node cluster but not quite we have the tie breaker too to keep the high",
    "start": "752320",
    "end": "757440"
  },
  {
    "text": "availability and then these are the the node rows and attributes that my",
    "start": "757440",
    "end": "762639"
  },
  {
    "text": "node has so this is a master eligible nodes but b means voting only so this can only vote",
    "start": "762639",
    "end": "770240"
  },
  {
    "text": "and then these these have a lot of other um rows so for example",
    "start": "770320",
    "end": "775360"
  },
  {
    "text": "i stands for ingest h is hot data we'll get to hot data a bit later um",
    "start": "775360",
    "end": "781920"
  },
  {
    "text": "master eligible um and a couple of other roles um these are very hard to remember",
    "start": "781920",
    "end": "787440"
  },
  {
    "text": "and you always need to look them up in the documentation or at least i need to do that but these are the the node",
    "start": "787440",
    "end": "792480"
  },
  {
    "text": "attributes that we have set on this cluster here so this is the the cluster and the node type so far um we've talked",
    "start": "792480",
    "end": "799680"
  },
  {
    "text": "about discovery basically you need to tell this node and there is this other node and if this node knows this one it would",
    "start": "799680",
    "end": "806160"
  },
  {
    "text": "tell it so you don't need to tell this node all the other nodes in the cluster but as long as a node knows at least one",
    "start": "806160",
    "end": "812079"
  },
  {
    "text": "other node in the cluster it would share the topology of your cluster",
    "start": "812079",
    "end": "818079"
  },
  {
    "text": "and i think that's more or less it for the cluster and the cluster coordination",
    "start": "818079",
    "end": "823120"
  },
  {
    "text": "so far so good good the next thing that we have i wrote my",
    "start": "823120",
    "end": "828240"
  },
  {
    "text": "one document and then we have this these concepts called index and chart in elasticsearch um so um",
    "start": "828240",
    "end": "837600"
  },
  {
    "text": "if i write that document from before again it would tell me something about charts",
    "start": "837600",
    "end": "842800"
  },
  {
    "text": "here and the total count of two and successful two um what happened here behind the scenes so when you do a write",
    "start": "842800",
    "end": "849680"
  },
  {
    "text": "operation um wherever i put my black pen um so",
    "start": "849680",
    "end": "855680"
  },
  {
    "text": "basically the write operation comes in and i say i write to the index",
    "start": "855680",
    "end": "861040"
  },
  {
    "text": "and the index that i'm writing to would say like it's called database and this index then consists or the index is",
    "start": "861040",
    "end": "868839"
  },
  {
    "text": "basically a collection of similar or related documents and this index can",
    "start": "868839",
    "end": "874000"
  },
  {
    "text": "then be broken up into so-called shards so under this basically we have shards",
    "start": "874000",
    "end": "882240"
  },
  {
    "text": "the default by now is that one index has exactly one chart if you were using an",
    "start": "882560",
    "end": "887680"
  },
  {
    "text": "older version does anybody remember how many primary shots we had back then",
    "start": "887680",
    "end": "893120"
  },
  {
    "text": "five yes whoever was first",
    "start": "893120",
    "end": "898120"
  },
  {
    "text": "um and that is the unit of scaling so one chart always lives on one of these nodes",
    "start": "899360",
    "end": "907519"
  },
  {
    "text": "um so if i have only one all the data for this index would be written let's say",
    "start": "907519",
    "end": "912720"
  },
  {
    "text": "on this node so that the chart is how do to break that up initially we had five primary",
    "start": "912720",
    "end": "918560"
  },
  {
    "text": "shots because it was very cool to show that how the data is split up over multiple nodes and how it can automatically scale up and down so if i",
    "start": "918560",
    "end": "926079"
  },
  {
    "text": "add more nodes to my cluster or if i remove nodes the shards will automatically be moved as needed in the",
    "start": "926079",
    "end": "931600"
  },
  {
    "text": "cluster one is kind of like a dumb number to show that right why did we change that",
    "start": "931600",
    "end": "938160"
  },
  {
    "text": "because most people had the problem that they had way too many shards so there was some kind of or there is a bit of an",
    "start": "938160",
    "end": "943519"
  },
  {
    "text": "overhead to each chart um also because distributing data if you don't need it",
    "start": "943519",
    "end": "949759"
  },
  {
    "text": "can be a bit costly um that's why we switched the default to one chart",
    "start": "949759",
    "end": "955920"
  },
  {
    "text": "if you have a lot of data you will need more shots does anybody have any idea how large a chart should",
    "start": "955920",
    "end": "961920"
  },
  {
    "text": "approximately be yes please yes so it so",
    "start": "961920",
    "end": "967600"
  },
  {
    "text": "okay i'll hit five people now because this is packaged and it's a bit hard to throw but",
    "start": "967600",
    "end": "973600"
  },
  {
    "text": "please forward if it doesn't reach you um",
    "start": "973600",
    "end": "979040"
  },
  {
    "text": "so the the size of chart so the favorite saying at elastic that we have is it",
    "start": "979040",
    "end": "985360"
  },
  {
    "text": "depends um because it might depend on your hardware and your use case so a full text search use case might be a bit",
    "start": "985360",
    "end": "991199"
  },
  {
    "text": "smaller have the optimal size um larger like logs use cases generally have that",
    "start": "991199",
    "end": "996480"
  },
  {
    "text": "50 gig limit um we have also seen people push it a bit further because we have done some optimizations that some things",
    "start": "996480",
    "end": "1003519"
  },
  {
    "text": "in the heap are smaller but 50 gigabytes is definitely very good default number if you aim for that that's also if you",
    "start": "1003519",
    "end": "1009839"
  },
  {
    "text": "have a logs use case what we would configure by default for charts to fill up before we start a new one",
    "start": "1009839",
    "end": "1016320"
  },
  {
    "text": "um so we have that chart now i've mentioned the high availability",
    "start": "1016320",
    "end": "1022720"
  },
  {
    "text": "with the with the master eligible nodes um what you actually have is a so-called",
    "start": "1022720",
    "end": "1028480"
  },
  {
    "text": "primary shot and the replica shot so this primary or this shot is broken up",
    "start": "1028480",
    "end": "1033600"
  },
  {
    "text": "in one primary",
    "start": "1033600",
    "end": "1037640"
  },
  {
    "text": "and there is exactly one and then optional you have",
    "start": "1040319",
    "end": "1045678"
  },
  {
    "text": "zero to n replica shots and",
    "start": "1045679",
    "end": "1052880"
  },
  {
    "text": "the primary shot is basically let's say we we write our little document comes in",
    "start": "1052880",
    "end": "1057919"
  },
  {
    "text": "here and we write our document here and then it gets replicated let's say we",
    "start": "1057919",
    "end": "1063280"
  },
  {
    "text": "keep the default replication factor of one so we create one second copy so in total we have two copies of the data",
    "start": "1063280",
    "end": "1069919"
  },
  {
    "text": "and that replica will then be written here on that node um",
    "start": "1069919",
    "end": "1076880"
  },
  {
    "text": "so if this node goes down the data is still here everything keeps working if you do any read or search operation",
    "start": "1076880",
    "end": "1083919"
  },
  {
    "text": "you could go either to this node or to that node because both have the same data and would fulfill your search",
    "start": "1083919",
    "end": "1089679"
  },
  {
    "text": "request if this node goes down",
    "start": "1089679",
    "end": "1096000"
  },
  {
    "text": "you can still go to this node um would my cluster try to fix that there is only one copy now",
    "start": "1096000",
    "end": "1103360"
  },
  {
    "text": "yes after a one minute timeout by default it would then start re-replicating that",
    "start": "1103360",
    "end": "1109120"
  },
  {
    "text": "data to this other node so that you have two copies again so it would do that automatically for you",
    "start": "1109120",
    "end": "1115679"
  },
  {
    "text": "if i have a single node cluster which is not highly available and i configure one primary shot which i always need to have",
    "start": "1115679",
    "end": "1121919"
  },
  {
    "text": "and one replica shot would i have one or two copies of that data on my single node",
    "start": "1121919",
    "end": "1127440"
  },
  {
    "text": "yes yes why",
    "start": "1127440",
    "end": "1134000"
  },
  {
    "text": "exactly yes it doesn't make much sense i the only thing if i",
    "start": "1134880",
    "end": "1140080"
  },
  {
    "text": "so this is not possible but if i wrote my second copy here the replica on the same note i wouldn't gain anything i",
    "start": "1140080",
    "end": "1145679"
  },
  {
    "text": "just doubled the disk space but it's i'm not getting more um availability because if the node goes down both copies go",
    "start": "1145679",
    "end": "1152000"
  },
  {
    "text": "down or disappear also i would just double that the disk space used on this one so i i'm not gaining anything from",
    "start": "1152000",
    "end": "1158320"
  },
  {
    "text": "that so replicas can only be on one other node you can by the way configure replicas not just as a fixed number but",
    "start": "1158320",
    "end": "1164559"
  },
  {
    "text": "you could even say like zero to n because the the cluster if you have a",
    "start": "1164559",
    "end": "1169760"
  },
  {
    "text": "single node cluster and you configure or keep the default of one replica shot your cluster would always say like you",
    "start": "1169760",
    "end": "1174799"
  },
  {
    "text": "told me to keep a second copy of this data but i can only keep one single copy because there's only one node and that",
    "start": "1174799",
    "end": "1180400"
  },
  {
    "text": "would affect the the cluster state or the health of your cluster but you could also say that in how many copies you",
    "start": "1180400",
    "end": "1186240"
  },
  {
    "text": "want to have you could say zero to one so your cluster would automatically know there's a single node i'll keep a single",
    "start": "1186240",
    "end": "1191679"
  },
  {
    "text": "copy there are two or more nodes i will keep two two copies of the data",
    "start": "1191679",
    "end": "1197360"
  },
  {
    "text": "so you can keep that configurable um so that is the what's your question",
    "start": "1197360",
    "end": "1202799"
  },
  {
    "text": "no good um so uh that was yeah",
    "start": "1202799",
    "end": "1207840"
  },
  {
    "text": "yes should we do that right now i mean we can i wanted to do it a little later but um we can do the anatomy of like a an",
    "start": "1215919",
    "end": "1223520"
  },
  {
    "text": "operation right away so let me let me start over let's say we have a very simple use case where we have three",
    "start": "1223520",
    "end": "1229600"
  },
  {
    "text": "nodes um so we have node one two",
    "start": "1229600",
    "end": "1235120"
  },
  {
    "text": "three um we say this one here is the master even though it doesn't really matter",
    "start": "1235120",
    "end": "1240559"
  },
  {
    "text": "and let's say we have the we have a put or a post",
    "start": "1240559",
    "end": "1246320"
  },
  {
    "text": "we have that coming into that node um every document um has a so-called id",
    "start": "1246320",
    "end": "1253360"
  },
  {
    "text": "um you can see that here in that underscore id field that is the id it's by default randomly generated if you do",
    "start": "1253360",
    "end": "1259360"
  },
  {
    "text": "a post otherwise you could do a put copy that i don't have to type all of",
    "start": "1259360",
    "end": "1266159"
  },
  {
    "text": "this and this is by the way all curl commands basically um so",
    "start": "1266159",
    "end": "1272480"
  },
  {
    "text": "read this as curl x post this is the end point and then this is",
    "start": "1272480",
    "end": "1277520"
  },
  {
    "text": "the json document so this is a rest api elastic search exposes it on port 9200 by default and this is just in kibana we",
    "start": "1277520",
    "end": "1284080"
  },
  {
    "text": "have this slightly more compact syntax to write it but it's absolutely the same so here you could say put document you",
    "start": "1284080",
    "end": "1290720"
  },
  {
    "text": "provide the id manually and then you would write the same document and it has the id",
    "start": "1290720",
    "end": "1295840"
  },
  {
    "text": "one if you don't provide the id um so this is put or post",
    "start": "1295840",
    "end": "1303880"
  },
  {
    "text": "with post um this node here would automatically generate the id for you",
    "start": "1304240",
    "end": "1310159"
  },
  {
    "text": "so you have then you have underscore id and you have",
    "start": "1310159",
    "end": "1315520"
  },
  {
    "text": "whatever id you have so in the put you provided and the post it",
    "start": "1315520",
    "end": "1321120"
  },
  {
    "text": "generates the id for you what you do then is",
    "start": "1321120",
    "end": "1325919"
  },
  {
    "text": "you hash the chart sorry you hash the id you calculated modulo number the primary",
    "start": "1326960",
    "end": "1334080"
  },
  {
    "text": "charts and that tells you where it should go so what you do is you have the",
    "start": "1334080",
    "end": "1340960"
  },
  {
    "text": "you do a hash function oops hash of underscore id and then you calculate",
    "start": "1340960",
    "end": "1346960"
  },
  {
    "text": "it modulo the number of primary shards um so for example in that case if you only have one primary chart it's a bit",
    "start": "1346960",
    "end": "1352640"
  },
  {
    "text": "boring but if you have five let's say we have five primary shots then it would calculate",
    "start": "1352640",
    "end": "1358320"
  },
  {
    "text": "modulo five and and that would give you then let's say node 3",
    "start": "1358320",
    "end": "1364480"
  },
  {
    "text": "or shard 3. um and it would then look into that in that cluster state",
    "start": "1364480",
    "end": "1370240"
  },
  {
    "text": "chart 3 of this index is located on which node so",
    "start": "1370240",
    "end": "1375840"
  },
  {
    "text": "why do i hash this why don't i just take the id modulo five",
    "start": "1375919",
    "end": "1381120"
  },
  {
    "text": "yes exactly because otherwise i might get a hotspot so for example if i have the ids and i use the the name for",
    "start": "1382320",
    "end": "1387679"
  },
  {
    "text": "example oops sorry for and and then you don't have that key",
    "start": "1387679",
    "end": "1393919"
  },
  {
    "text": "space evenly distributed you would get a hotspot on one node so that's why you use a hashing function and to evenly",
    "start": "1393919",
    "end": "1399280"
  },
  {
    "text": "distribute the data by the way in the very early versions of elasticsearch we used a bad hashing function and that very unevenly",
    "start": "1399280",
    "end": "1406080"
  },
  {
    "text": "distributed the data if you used 33 primary shots",
    "start": "1406080",
    "end": "1411520"
  },
  {
    "text": "that was a bug or a limitation in the in the hashing function but of course",
    "start": "1411520",
    "end": "1416799"
  },
  {
    "text": "somebody figured that out because then some shards would get zero documents and others had tons um",
    "start": "1416799",
    "end": "1422720"
  },
  {
    "text": "and so the initial uh hashing function we had dj b2 from dj bernstein who is a",
    "start": "1422720",
    "end": "1429200"
  },
  {
    "text": "big in cryptographer and now we are using murmur 3 which is also a widely used hash function in the",
    "start": "1429200",
    "end": "1435760"
  },
  {
    "text": "end you want something that is evenly distributed and pretty fast to calculate so we've hashed the id we calculated",
    "start": "1435760",
    "end": "1441200"
  },
  {
    "text": "modular number of primary shards and it says chart three is where this document goes and let's say we have my cluster",
    "start": "1441200",
    "end": "1447840"
  },
  {
    "text": "has allocated chart three on this node here so what it then does is um",
    "start": "1447840",
    "end": "1453520"
  },
  {
    "text": "then let's say this is then so this here the first node you're",
    "start": "1453520",
    "end": "1458640"
  },
  {
    "text": "hitting is the so-called coordinating node because it coordinates that right um it can be any node um normally we",
    "start": "1458640",
    "end": "1465679"
  },
  {
    "text": "would round robin between all the nodes so also that load is evenly distributed in your cluster um it then says um",
    "start": "1465679",
    "end": "1473200"
  },
  {
    "text": "go to go to",
    "start": "1473200",
    "end": "1478240"
  },
  {
    "text": "god3 because let's say this is this node has shard three and then you you write",
    "start": "1478720",
    "end": "1484080"
  },
  {
    "text": "that document here as the primary chart and then it also says the replica shot",
    "start": "1484080",
    "end": "1489440"
  },
  {
    "text": "of 3 is on let's say this node so then it would",
    "start": "1489440",
    "end": "1495440"
  },
  {
    "text": "replicate the document to here and what then happens once you have written this",
    "start": "1498720",
    "end": "1504320"
  },
  {
    "text": "this node so this this the node that writes does some basic checking if this operation can actually be fulfilled",
    "start": "1504320",
    "end": "1509760"
  },
  {
    "text": "otherwise it would recheck the right right away if it can do that it will replicate the data",
    "start": "1509760",
    "end": "1515360"
  },
  {
    "text": "so maybe i should number this a bit better so you have this is the first step this is the",
    "start": "1515360",
    "end": "1521520"
  },
  {
    "text": "second step this is the third step and then you have here",
    "start": "1521520",
    "end": "1528240"
  },
  {
    "text": "you get an act back that's the fourth step and then you get i'm getting lost in my",
    "start": "1528240",
    "end": "1535360"
  },
  {
    "text": "colors you get an egg back here in step 5 and then in",
    "start": "1535360",
    "end": "1542960"
  },
  {
    "text": "step 6 at the end",
    "start": "1542960",
    "end": "1546640"
  },
  {
    "text": "this is when your client whatever like programming language curl whatever gets the acknowledgement back from your write",
    "start": "1549840",
    "end": "1555760"
  },
  {
    "text": "operation so it basically works its way through the entire cluster just because it's distributed like that in this",
    "start": "1555760",
    "end": "1561039"
  },
  {
    "text": "example it could be any on any node um but this is how a write operation works",
    "start": "1561039",
    "end": "1567279"
  },
  {
    "text": "good cool yes please",
    "start": "1567279",
    "end": "1571840"
  },
  {
    "text": "yes i mean the thing is the same um just this part here is different",
    "start": "1573520",
    "end": "1581320"
  },
  {
    "text": "yes you only have one primary shot so it but i mean the right operation looks the same but the thing is if you",
    "start": "1584000",
    "end": "1590400"
  },
  {
    "text": "have five um you i could have like primary shots like let's say two primary shots here two primary shots here one",
    "start": "1590400",
    "end": "1596159"
  },
  {
    "text": "primary shot here so that the data of that index could be distributed amongst the",
    "start": "1596159",
    "end": "1601360"
  },
  {
    "text": "nodes and the load as well to write them so with the five let's say i have blue is that the number of",
    "start": "1601360",
    "end": "1607840"
  },
  {
    "text": "primary shots so i have two primary shots here two primary shots here and one primary shot here and then the",
    "start": "1607840",
    "end": "1613520"
  },
  {
    "text": "replicas would be of course like always not on the same note but then let's say we have",
    "start": "1613520",
    "end": "1620320"
  },
  {
    "text": "three replicas here because it doesn't matter we have one replica here and one replica here so",
    "start": "1620320",
    "end": "1626480"
  },
  {
    "text": "they would just if you have five primary shots and five replica shards they could just be more evenly distributed whereas",
    "start": "1626480",
    "end": "1632480"
  },
  {
    "text": "if you have three nodes and only one primary and one replica chart all the data would only go to two nodes",
    "start": "1632480",
    "end": "1640360"
  },
  {
    "text": "um because normally you have a lot of indices to write and there's an overhead and most people have way too little data",
    "start": "1641039",
    "end": "1647360"
  },
  {
    "text": "for multiple shots um so that we have seen clusters which had i don't",
    "start": "1647360",
    "end": "1653840"
  },
  {
    "text": "know thousands of charts and that basically kept the cluster busy just keeping track of the shots and",
    "start": "1653840",
    "end": "1659360"
  },
  {
    "text": "everything which was a very common occurrence um a we have changed a bit the tooling and the defaults behind it",
    "start": "1659360",
    "end": "1665039"
  },
  {
    "text": "so we have view of that b we have a project that we call many shards so by now you can actually have thousands of",
    "start": "1665039",
    "end": "1670640"
  },
  {
    "text": "shards per cluster previously we had like a rough calculation per gigabyte of heap you should only have 20 shards",
    "start": "1670640",
    "end": "1677440"
  },
  {
    "text": "approximately but that calculation is very outdated by now so you can you can have a lot more",
    "start": "1677440",
    "end": "1683279"
  },
  {
    "text": "but because of these things um we went down to one because normally you have multiple indices or if you have logs um you you",
    "start": "1683279",
    "end": "1690880"
  },
  {
    "text": "write them for some specific time frame and then you roll over to the next index you you will have a lot of shards in your system going on normally anyway",
    "start": "1690880",
    "end": "1697919"
  },
  {
    "text": "but if you have a specific use case and you only have one index set the number of shots correctly",
    "start": "1697919",
    "end": "1703760"
  },
  {
    "text": "um okay so that was the anatomy of a right",
    "start": "1703760",
    "end": "1708799"
  },
  {
    "text": "so far yep yes please",
    "start": "1708799",
    "end": "1711840"
  },
  {
    "text": "so that the number of sharks is picked up front but there are two apis that you",
    "start": "1718159",
    "end": "1724320"
  },
  {
    "text": "can use now they are called split and shrink",
    "start": "1724320",
    "end": "1732000"
  },
  {
    "text": "so these are basically you what you would need to do is you have index let's say one primary chart foo",
    "start": "1734720",
    "end": "1742240"
  },
  {
    "text": "and the api call would be foo slash underscore split slash um the",
    "start": "1742240",
    "end": "1747440"
  },
  {
    "text": "target index so you would need to rename it but you can change it the number of primary shots with that operation and",
    "start": "1747440",
    "end": "1752799"
  },
  {
    "text": "that is actually very fast because it's just doing some zoom linking on the on the disk um to either split it so it",
    "start": "1752799",
    "end": "1759520"
  },
  {
    "text": "keeps like some virtual splitting in the background running um or it could combine them so you can do it at any",
    "start": "1759520",
    "end": "1765679"
  },
  {
    "text": "point in time you need to change the name of the index but with aliases you could fix that afterwards again but you",
    "start": "1765679",
    "end": "1771520"
  },
  {
    "text": "can split and drink at any point since six point something i think",
    "start": "1771520",
    "end": "1777440"
  },
  {
    "text": "so a couple of years um it was a big limitation a long time ago but not anymore yes please",
    "start": "1777440",
    "end": "1783919"
  },
  {
    "text": "yes",
    "start": "1784960",
    "end": "1787960"
  },
  {
    "text": "i mean the i think i think that so the the primary shot if",
    "start": "1798320",
    "end": "1805440"
  },
  {
    "text": "i remember correctly will start the replication on all nodes but it will wait for the majority of replicas to",
    "start": "1805440",
    "end": "1811840"
  },
  {
    "text": "respond because then it's sure that it's correctly written and then it will acknowledge it so it will not necessarily wait for all of them but the",
    "start": "1811840",
    "end": "1817760"
  },
  {
    "text": "majority because there is always this failure scenario if like n nodes die",
    "start": "1817760",
    "end": "1823039"
  },
  {
    "text": "what are your replicas worth so you always need to have the majority acknowledge that all of them have the same data otherwise you might be in",
    "start": "1823039",
    "end": "1828799"
  },
  {
    "text": "trouble and actually that is it sounds like an uncommon scenario but i know a",
    "start": "1828799",
    "end": "1834399"
  },
  {
    "text": "big german dropping retailer whatever and they have something like 30 or more replicas",
    "start": "1834399",
    "end": "1841440"
  },
  {
    "text": "because search operations can go to any copy primary or replica and they just want to parallelize their search so much",
    "start": "1841440",
    "end": "1847600"
  },
  {
    "text": "and for them latency is very important because otherwise people append on the search um so they they have i think",
    "start": "1847600",
    "end": "1854640"
  },
  {
    "text": "one shot or maybe two shards or so um but then a ton of copies just to keep that um",
    "start": "1854640",
    "end": "1861360"
  },
  {
    "text": "quick which is by the way a good point how do you scale your rights you have more charts so you can parallelize the",
    "start": "1861360",
    "end": "1868399"
  },
  {
    "text": "writing how do you scale your reads you have more replicas because then you have more copies from where you can answer",
    "start": "1868399",
    "end": "1875440"
  },
  {
    "text": "um hope that makes sense um",
    "start": "1875440",
    "end": "1879840"
  },
  {
    "text": "um so that was a search um sorry that was a right yes please",
    "start": "1881600",
    "end": "1889240"
  },
  {
    "text": "yes if you don't provide it it is being generated on the first note yes",
    "start": "1893120",
    "end": "1898080"
  },
  {
    "text": "yeah it's something i think the number of stars and whatever it's like it's it's pretty much impossible um",
    "start": "1900720",
    "end": "1908480"
  },
  {
    "text": "so i don't i forgot the actual details of how",
    "start": "1908880",
    "end": "1914640"
  },
  {
    "text": "unlikely it was um but there was a calculation if for a hundred years you write a million operations a second and",
    "start": "1914640",
    "end": "1920880"
  },
  {
    "text": "then you have a 50 chance or something like that um and that is way more data than you normally have in an index um",
    "start": "1920880",
    "end": "1927679"
  },
  {
    "text": "so uh that should not be a practical concern yes please",
    "start": "1927679",
    "end": "1933880"
  },
  {
    "text": "but i mean so if you provide the id",
    "start": "1940000",
    "end": "1945000"
  },
  {
    "text": "yes yes",
    "start": "1948960",
    "end": "1953519"
  },
  {
    "text": "yes also because so what this operation actually does is if you do a put the put",
    "start": "1956240",
    "end": "1961760"
  },
  {
    "text": "when you provide the id could actually overwrite an existing document so you always need to read first and check if i'm replacing or writing a new",
    "start": "1961760",
    "end": "1968559"
  },
  {
    "text": "if you do a post it basically has an operation attached that it says create and it wouldn't overwrite anything",
    "start": "1968559",
    "end": "1975039"
  },
  {
    "text": "but any such collisions are more theoretical i don't think that is anything that would hit you in practice",
    "start": "1975039",
    "end": "1980720"
  },
  {
    "text": "um everybody good um then should we do a search because so far we have um",
    "start": "1980720",
    "end": "1987360"
  },
  {
    "text": "only written so we have we have three notes again",
    "start": "1987360",
    "end": "1992799"
  },
  {
    "text": "and we do a search um what is the right http verb for research",
    "start": "1992799",
    "end": "1999919"
  },
  {
    "text": "get um or post yes um",
    "start": "2001760",
    "end": "2006880"
  },
  {
    "text": "why is that so yes we use get or post why is that",
    "start": "2006880",
    "end": "2012640"
  },
  {
    "text": "yes because our searches are i mean uh",
    "start": "2012880",
    "end": "2018440"
  },
  {
    "text": "yeah so a search operation could look uh like i i would use the index and then i would say search this is the endpoint um",
    "start": "2018559",
    "end": "2025840"
  },
  {
    "text": "oops and then i would need to say um i i i want to do a",
    "start": "2025840",
    "end": "2033360"
  },
  {
    "text": "query um and then in the query i don't know i want to do a match",
    "start": "2033360",
    "end": "2038559"
  },
  {
    "text": "and then i say i have a name and then the name is philip",
    "start": "2038559",
    "end": "2045559"
  },
  {
    "text": "then my two documents or three documents that i've written so far will come back now",
    "start": "2046480",
    "end": "2051919"
  },
  {
    "text": "get cannot have a body um i can do the same with the post",
    "start": "2051919",
    "end": "2057040"
  },
  {
    "text": "yeah it shouldn't it's not in the spec um and using post for right up for a read operation is also weird so there is",
    "start": "2057040",
    "end": "2063118"
  },
  {
    "text": "no winning here and we kind of don't care and we're pragmatic so it's it's up to you the post generally people",
    "start": "2063119",
    "end": "2070240"
  },
  {
    "text": "frown upon because it's the wrong http verb the bigger problem is normally they get because sometimes when people run",
    "start": "2070240",
    "end": "2075760"
  },
  {
    "text": "some reverse proxies they discard the body silently or some some curing tools because they don't expect the body there",
    "start": "2075760",
    "end": "2082000"
  },
  {
    "text": "and then you just run this because it discards the body and the tricky thing is this gives you 10",
    "start": "2082000",
    "end": "2089280"
  },
  {
    "text": "random documents from the thing so it looks like all your searches are broken um so generally i i tend to",
    "start": "2089280",
    "end": "2096720"
  },
  {
    "text": "use get but post is kind of safer because you won't run into any such issues",
    "start": "2096720",
    "end": "2102000"
  },
  {
    "text": "so our search get our post is coming in and i'll just say we're hitting the search",
    "start": "2102000",
    "end": "2109599"
  },
  {
    "text": "endpoint and it's coming in here and this is again the coordinating node and i have we said i don't know the",
    "start": "2109599",
    "end": "2116079"
  },
  {
    "text": "colors are doesn't don't matter but let's say we have the primary shot here and we have the",
    "start": "2116079",
    "end": "2122320"
  },
  {
    "text": "replica shot here and actually let's say we have an index with two shards to make it a bit more interesting and we have",
    "start": "2122320",
    "end": "2129040"
  },
  {
    "text": "that the replica zero here and the replica one shot here and then we have",
    "start": "2129040",
    "end": "2136160"
  },
  {
    "text": "obviously the primary shot zero here and the replica shot one is here this is a",
    "start": "2136160",
    "end": "2141599"
  },
  {
    "text": "bit of a constructed problem of course but it doesn't really matter so your search query comes in and",
    "start": "2141599",
    "end": "2148160"
  },
  {
    "text": "you're searching for all the users that are called philip um and we can search either",
    "start": "2148160",
    "end": "2154400"
  },
  {
    "text": "primary or replica so it doesn't matter um but actually this is a so-called",
    "start": "2154400",
    "end": "2160240"
  },
  {
    "text": "two-step approach how the search operation works um we call it um scattergather oops",
    "start": "2160240",
    "end": "2168240"
  },
  {
    "text": "yeah there this is what we call it um so because if i'm doing this search",
    "start": "2170000",
    "end": "2175200"
  },
  {
    "text": "operation um and voltex search is not just about exact",
    "start": "2175200",
    "end": "2180560"
  },
  {
    "text": "matches but more this like concept of what i might search so there is always the so-called score here how well",
    "start": "2180560",
    "end": "2187119"
  },
  {
    "text": "is this document fitting my search query so it's like the relevancy rating that you have in the search engine as well",
    "start": "2187119",
    "end": "2193920"
  },
  {
    "text": "um and let's assume we have millions of documents and we have like a search query that might hit 100 documents by",
    "start": "2193920",
    "end": "2200880"
  },
  {
    "text": "default the search only gives you 10 documents back you can change that of course with the size parameter but it only gives you 10 documents back it",
    "start": "2200880",
    "end": "2207680"
  },
  {
    "text": "would however be very wasteful for this coordinating node to say",
    "start": "2207680",
    "end": "2213119"
  },
  {
    "text": "to each node like give me all the results and then just send all of them back because the search",
    "start": "2213119",
    "end": "2218400"
  },
  {
    "text": "operation is only by default getting us the top 10 results so what it does is it",
    "start": "2218400",
    "end": "2223599"
  },
  {
    "text": "goes the coordinating node goes to each chart and it doesn't matter if primary replica but it goes to 0 and 1",
    "start": "2223599",
    "end": "2231280"
  },
  {
    "text": "and says like please give me your top 10 results for this search and it only gets back the",
    "start": "2231280",
    "end": "2236880"
  },
  {
    "text": "document id and the score and then the coordinating node will get",
    "start": "2236880",
    "end": "2243200"
  },
  {
    "text": "how many sub results back 20 so 10 from each primary shot because",
    "start": "2243200",
    "end": "2249040"
  },
  {
    "text": "10 is the total number it wants to get back and then it sorts them and figures out overall these are the 10 top",
    "start": "2249040",
    "end": "2255440"
  },
  {
    "text": "documents and then it fetches by id and it fetches the actual documents in the",
    "start": "2255440",
    "end": "2260800"
  },
  {
    "text": "second round from these so basically what what you have is",
    "start": "2260800",
    "end": "2266320"
  },
  {
    "text": "you have the scatter phase it goes to the notes and says like",
    "start": "2266320",
    "end": "2271359"
  },
  {
    "text": "give me back the documents and you will get back um the i",
    "start": "2271359",
    "end": "2276640"
  },
  {
    "text": "id of the document and the score um and then it will get",
    "start": "2276640",
    "end": "2281920"
  },
  {
    "text": "another in the second round so this is basically phase zero and then there is um",
    "start": "2281920",
    "end": "2288079"
  },
  {
    "text": "the phase one and this is a get by id so it's then getting the",
    "start": "2288079",
    "end": "2293760"
  },
  {
    "text": "documents putting together the final result and then you're getting the documents back",
    "start": "2293760",
    "end": "2298880"
  },
  {
    "text": "obviously if you have a hundred charts this is also more expensive because then",
    "start": "2298880",
    "end": "2304560"
  },
  {
    "text": "you need to get 10 sub results from 100 charts combine them figure out the top 10 and then fetch those if you have a",
    "start": "2304560",
    "end": "2310800"
  },
  {
    "text": "single shard this is a lot zipper um so this is another reason why you don't",
    "start": "2310800",
    "end": "2317359"
  },
  {
    "text": "want to go too crazy um okay so that was uh",
    "start": "2317359",
    "end": "2323119"
  },
  {
    "text": "get so far so good timing-wise we still have 20 minutes i probably have material for three more",
    "start": "2323119",
    "end": "2328640"
  },
  {
    "text": "hours but we'll we'll figure out what makes most sense no questions so far yep please",
    "start": "2328640",
    "end": "2335920"
  },
  {
    "text": "yes the shard i mean decreased you would need to do a split um and and then it will decrease um but",
    "start": "2338000",
    "end": "2344480"
  },
  {
    "text": "otherwise it will just keep increasing which is a good point um because under the hood of all of this when you write",
    "start": "2344480",
    "end": "2350000"
  },
  {
    "text": "data there is apache lucene is the library writing actually to disk because sometimes people are asking like what is",
    "start": "2350000",
    "end": "2355520"
  },
  {
    "text": "actually writing and doing all of that um so that's a petulus scene and the the clever trick or the combination of",
    "start": "2355520",
    "end": "2361839"
  },
  {
    "text": "elasticsearch and lucine is um lucine is really a library for java developers and elasticsearch is kind of the wrapper",
    "start": "2361839",
    "end": "2367280"
  },
  {
    "text": "around it it provides the rest api the query dsl it does the distribution replication balancing of the cluster and",
    "start": "2367280",
    "end": "2373440"
  },
  {
    "text": "everything but for leucine it looks like and that is unfortunately bit unfortunate what we call an",
    "start": "2373440",
    "end": "2380079"
  },
  {
    "text": "elasticsearch index is made up of multiple shards and each shard is the so-called lucine index",
    "start": "2380079",
    "end": "2386320"
  },
  {
    "text": "this kind of index here index there but lucine thinks that it's lucine index the shard",
    "start": "2386320",
    "end": "2391760"
  },
  {
    "text": "is the whole world whereas elasticsearch knows there are multiple ones i'll get the results from all of them and combine them but that's kind of like how the two",
    "start": "2391760",
    "end": "2397839"
  },
  {
    "text": "are related um and lucine is writing the data and that's the the so-called chart size",
    "start": "2397839",
    "end": "2404880"
  },
  {
    "text": "actually how lucine works and this is maybe a good addition to the the thing from before",
    "start": "2404880",
    "end": "2411920"
  },
  {
    "text": "or i don't really have enough space here um and i'll stay on the top so everybody can see that so when you have a right",
    "start": "2411920",
    "end": "2419599"
  },
  {
    "text": "and it doesn't matter if it's a post or a put coming in into elasticsearch what happens so",
    "start": "2419599",
    "end": "2425839"
  },
  {
    "text": "there is a so-called um we have a buffer",
    "start": "2425839",
    "end": "2432160"
  },
  {
    "text": "this is where the document gets kind of like put at first and then the acknowledgement and whatever works so this is within one",
    "start": "2432800",
    "end": "2439599"
  },
  {
    "text": "node now so this is the buffer um that happens in lucine um and then",
    "start": "2439599",
    "end": "2445760"
  },
  {
    "text": "this buffer is being taken and written out into a so-called segment",
    "start": "2445760",
    "end": "2452520"
  },
  {
    "text": "this is the lucine concept and segments are immutable by default they are written once every second maybe",
    "start": "2455760",
    "end": "2461839"
  },
  {
    "text": "you have seen refresh once a second is the default um so all the documents that",
    "start": "2461839",
    "end": "2467119"
  },
  {
    "text": "accumulate within one second are buffered and then written out into a segment",
    "start": "2467119",
    "end": "2472319"
  },
  {
    "text": "for durability of your data there is another concept um coming from that buffer um and that is the so-called",
    "start": "2472319",
    "end": "2479440"
  },
  {
    "text": "trench log the transaction log um",
    "start": "2479440",
    "end": "2485200"
  },
  {
    "text": "which is immediately written to disk and is just sequentially written so it's very cheap to write um whereas this does",
    "start": "2485200",
    "end": "2491680"
  },
  {
    "text": "more and does some analysis so there is some more overhead here these are also at first only um written",
    "start": "2491680",
    "end": "2498319"
  },
  {
    "text": "in memory and only once that data is f-synced to disk the trends log with all",
    "start": "2498319",
    "end": "2505119"
  },
  {
    "text": "the other write operations on is can be removed so basically",
    "start": "2505119",
    "end": "2511519"
  },
  {
    "text": "a write operation comes in here it's put or let's say it's then immediately",
    "start": "2511760",
    "end": "2520160"
  },
  {
    "text": "put into the trends log another write operation comes in here",
    "start": "2520160",
    "end": "2525359"
  },
  {
    "text": "it's again immediately put in turns lock the one second timeout is kind of over",
    "start": "2525359",
    "end": "2530560"
  },
  {
    "text": "we create a new segment so we create a segment with those these two write operations these",
    "start": "2530560",
    "end": "2536319"
  },
  {
    "text": "just exist in memory potentially you get multiple of these once these are flushed to disk um",
    "start": "2536319",
    "end": "2544319"
  },
  {
    "text": "then only these are taken out and that's how the transaction lock works but most data stores like postgres",
    "start": "2544319",
    "end": "2550960"
  },
  {
    "text": "mysql whatever um they have something called or i think postgres calls it the transaction log mysql a bin log but it's",
    "start": "2550960",
    "end": "2558400"
  },
  {
    "text": "kind of like the same concept that you have this thing that writes all the data for durability immediately",
    "start": "2558400",
    "end": "2564319"
  },
  {
    "text": "and that is how a write works the thing is the segments are immutable and i'm coming back to your question now",
    "start": "2564319",
    "end": "2570800"
  },
  {
    "text": "so that this is immutable every time you update a document it's basically marked for",
    "start": "2570800",
    "end": "2576000"
  },
  {
    "text": "deletion in the segment and written a new this is a bit unfortunate because this",
    "start": "2576000",
    "end": "2581520"
  },
  {
    "text": "makes small updates very expensive in elasticsearch so if you have a very large document with 100 fields and you",
    "start": "2581520",
    "end": "2586640"
  },
  {
    "text": "update a single document you still need to rewrite the entire document every time you update that there are some ways",
    "start": "2586640",
    "end": "2592079"
  },
  {
    "text": "around to structure that and do that but that's the the basic law because of lucine because of the immutability which",
    "start": "2592079",
    "end": "2597359"
  },
  {
    "text": "has some other nice attributes but that is one of the downsides um so these small segments once every second by",
    "start": "2597359",
    "end": "2604079"
  },
  {
    "text": "default are being written after some time you have hundreds of thousands of those and then there is a",
    "start": "2604079",
    "end": "2609200"
  },
  {
    "text": "so-called merge happening where you combine multiple of these rights also all the documents that have been",
    "start": "2609200",
    "end": "2614560"
  },
  {
    "text": "replaced or deleted are then removed and only like the current documents are being written into the",
    "start": "2614560",
    "end": "2621280"
  },
  {
    "text": "larger segment so multiple small segments over time are aggregated into larger segments over time",
    "start": "2621280",
    "end": "2627200"
  },
  {
    "text": "um so that this space might sometimes be fluctuating or a bit higher than what you would expect based on those mergers",
    "start": "2627200",
    "end": "2633839"
  },
  {
    "text": "and the mergers just happened in the background",
    "start": "2633839",
    "end": "2637440"
  },
  {
    "text": "that was this there is one other thing that i have um",
    "start": "2640480",
    "end": "2648079"
  },
  {
    "text": "that i have kind of glanced over let's write another document um so we have seen um the shards it's now clear why we",
    "start": "2648079",
    "end": "2654880"
  },
  {
    "text": "have written two shards in total one primary one replica um we also have the id we've talked about",
    "start": "2654880",
    "end": "2661359"
  },
  {
    "text": "that we see the index and then we have this version field does anybody know why we write this version field and i can",
    "start": "2661359",
    "end": "2667359"
  },
  {
    "text": "actually show you how this increases so if i have a fixed id and i update that document because they put this same",
    "start": "2667359",
    "end": "2673520"
  },
  {
    "text": "write or an update so here you can see that the version keeps increasing",
    "start": "2673520",
    "end": "2680079"
  },
  {
    "text": "where could that be useful yeah",
    "start": "2680079",
    "end": "2685040"
  },
  {
    "text": "yeah i know the transloc should be in the background that's not the case um yes",
    "start": "2687520",
    "end": "2693440"
  },
  {
    "text": "no not when merging by seconds ah segments so one thing that elastic yes please",
    "start": "2693440",
    "end": "2699519"
  },
  {
    "text": "yes exactly so the elasticsearch like most nosql data stores because i'm not sure",
    "start": "2701599",
    "end": "2707839"
  },
  {
    "text": "elasticsearch is really the core system in that um don't have multi-document transactions or no transactions at all",
    "start": "2707839",
    "end": "2714160"
  },
  {
    "text": "so how do you avoid concurrent rights that overwrite each other so the relational",
    "start": "2714160",
    "end": "2721200"
  },
  {
    "text": "world is kind of pessimistic in that regard and that has pessimistic concurrency control where it locks the",
    "start": "2721200",
    "end": "2726560"
  },
  {
    "text": "document when it writes it so you read it so you have like you start the transaction you read it you write it",
    "start": "2726560",
    "end": "2732240"
  },
  {
    "text": "back you release the transaction and only then can somebody else update that document the nosql world is more",
    "start": "2732240",
    "end": "2738720"
  },
  {
    "text": "optimistic let's say and we call it optimistic currency control basically you read a document so i read this",
    "start": "2738720",
    "end": "2744640"
  },
  {
    "text": "document and it has version four and then when i write it back i can",
    "start": "2744640",
    "end": "2750079"
  },
  {
    "text": "specify in my write operation only overwrite this document if it's still at version four if something else has",
    "start": "2750079",
    "end": "2756400"
  },
  {
    "text": "overwritten this document then we're at version five six seven whatever reject the right send it back to the client and",
    "start": "2756400",
    "end": "2761839"
  },
  {
    "text": "the client needs to figure out what is the right way to reconcile this because the assumption is the vast majority of",
    "start": "2761839",
    "end": "2767520"
  },
  {
    "text": "write operations will not run into that situation so why have that expensive transaction and locking",
    "start": "2767520",
    "end": "2773920"
  },
  {
    "text": "we'll just optimistically try to write if it fails we can still reconcile on the client and figure out what is the",
    "start": "2773920",
    "end": "2779440"
  },
  {
    "text": "right way to go on um so this is why we have that version and why it's there",
    "start": "2779440",
    "end": "2786839"
  },
  {
    "text": "um yes please sorry this is",
    "start": "2786839",
    "end": "2793280"
  },
  {
    "text": "so that the sequence number and the primary term um these were added in 7.0 and they added a lot for the resiliency",
    "start": "2793280",
    "end": "2800160"
  },
  {
    "text": "of elasticsearch so the sequence number is basically the counter of write operations within",
    "start": "2800160",
    "end": "2806079"
  },
  {
    "text": "that chart and the primary term is if you have a failover of masternodes the pro that",
    "start": "2806079",
    "end": "2812480"
  },
  {
    "text": "primary term would increase so basically it gives you a total order of operations within that chart um so",
    "start": "2812480",
    "end": "2819359"
  },
  {
    "text": "you don't have any concurrency bugs around that those were added in 7.0 and have since been around for that",
    "start": "2819359",
    "end": "2829160"
  },
  {
    "text": "i mean it's just a counter um normally for this is within this document with the id",
    "start": "2830400",
    "end": "2836720"
  },
  {
    "text": "this is for all the documents within the chart but it's basically a counter and before",
    "start": "2836720",
    "end": "2842400"
  },
  {
    "text": "somebody um asks what if this role's over i think you also need to write i don't know how many billion documents it",
    "start": "2842400",
    "end": "2848160"
  },
  {
    "text": "it doesn't happen um this is i think alone um",
    "start": "2848160",
    "end": "2853200"
  },
  {
    "text": "okay something that i've shortly mentioned was that refresh",
    "start": "2853200",
    "end": "2859599"
  },
  {
    "text": "and i've actually put together a short demo to show that refresh so um",
    "start": "2859599",
    "end": "2866240"
  },
  {
    "text": "i'm creating a new index called databases one shard it's fine with a",
    "start": "2866240",
    "end": "2871440"
  },
  {
    "text": "refresh interval of 30 seconds so by default it would be one second here i'm saying batch up all the right operations",
    "start": "2871440",
    "end": "2878319"
  },
  {
    "text": "into that segment for 30 seconds and only then create a new segment why would i want to do that",
    "start": "2878319",
    "end": "2885440"
  },
  {
    "text": "i need to create fewer segments so it's cheaper i need to do fewer merges because i have fewer and larger ones so",
    "start": "2885440",
    "end": "2891760"
  },
  {
    "text": "it's again cheaper and more resource intensive so if you want to create increase the right throughput a higher",
    "start": "2891760",
    "end": "2898720"
  },
  {
    "text": "refresh rate would help you with that the downside is um obviously it takes up to 30 seconds to",
    "start": "2898720",
    "end": "2904319"
  },
  {
    "text": "see a document in a multi-document operation um so i'm setting this 30 seconds",
    "start": "2904319",
    "end": "2910000"
  },
  {
    "text": "um i write the current version of elasticsearch into that and then a get is a single document",
    "start": "2910000",
    "end": "2917359"
  },
  {
    "text": "operation that always happens immediately if i do a search",
    "start": "2917359",
    "end": "2922720"
  },
  {
    "text": "this might now take up to 30 seconds until i find this and i can",
    "start": "2922720",
    "end": "2928400"
  },
  {
    "text": "keep doing this for a while and at some point it will appear you have to be patient because it might",
    "start": "2928400",
    "end": "2934480"
  },
  {
    "text": "indeed take 30 seconds um well it takes a while now and now it is",
    "start": "2934480",
    "end": "2940880"
  },
  {
    "text": "here um i can now do a put to update this document so let's say we release",
    "start": "2940880",
    "end": "2946040"
  },
  {
    "text": "8.3 which will come out in the coming weeks or month um if i do a get will i get that document",
    "start": "2946040",
    "end": "2952880"
  },
  {
    "text": "back immediately yes um if i do a search without the body",
    "start": "2952880",
    "end": "2958160"
  },
  {
    "text": "what will i get the document back immediately yes it will be the old version because",
    "start": "2958160",
    "end": "2964800"
  },
  {
    "text": "it probably hasn't been updated yet um and again i need to create i need to run",
    "start": "2964800",
    "end": "2970400"
  },
  {
    "text": "this a couple of times and now it has been updated um you can call a so-called refresh",
    "start": "2970400",
    "end": "2976000"
  },
  {
    "text": "explicitly to create the segment but it's kind of expensive so don't do that what you could do instead in your",
    "start": "2976000",
    "end": "2982160"
  },
  {
    "text": "request is you can say refresh wait for so this will block the write operation until the",
    "start": "2982160",
    "end": "2989119"
  },
  {
    "text": "refresh has happened so your application actually knows when to continue and when it can read that value back in a",
    "start": "2989119",
    "end": "2994160"
  },
  {
    "text": "multi-document operation the one place where you mostly stumble over this artifact is in unit tests or",
    "start": "2994160",
    "end": "3001680"
  },
  {
    "text": "integration tests because there you expect to write the document and read it back immediately whereas in most other",
    "start": "3001680",
    "end": "3006800"
  },
  {
    "text": "scenarios for full text search and with a refresh interval of one second you don't really recognize or",
    "start": "3006800",
    "end": "3012960"
  },
  {
    "text": "notice it there's also another optimization that we have built into elasticsearch since",
    "start": "3012960",
    "end": "3018240"
  },
  {
    "text": "7.0 that if you do not do a search operation for 30 seconds we will stop",
    "start": "3018240",
    "end": "3024240"
  },
  {
    "text": "creating those small segments and only create them as needed once you do another search operation we will then",
    "start": "3024240",
    "end": "3030079"
  },
  {
    "text": "immediately create the segment to make it searchable but it's basically to increase the right throughput by not",
    "start": "3030079",
    "end": "3035119"
  },
  {
    "text": "creating the small segments unnecessarily and still giving you quick access when",
    "start": "3035119",
    "end": "3040319"
  },
  {
    "text": "searching just the first search operation will have to wait for a one second refresh until that happens but",
    "start": "3040319",
    "end": "3045760"
  },
  {
    "text": "that is another improvement built in under the hood um",
    "start": "3045760",
    "end": "3051200"
  },
  {
    "text": "so refresh is one of the things that you can play around with to increase your right throughput the other big setting",
    "start": "3051200",
    "end": "3057520"
  },
  {
    "text": "that you need to set is the heap and we've had various settings for that by default i think we had four gigs of",
    "start": "3057520",
    "end": "3064640"
  },
  {
    "text": "heap by default by the way what if you have an instance um how much memory should you give to the heap and",
    "start": "3064640",
    "end": "3071200"
  },
  {
    "text": "how much should you leave for the rest of the system yes",
    "start": "3071200",
    "end": "3075920"
  },
  {
    "text": "yes that is that is almost or that was the recommendation for it for a very long",
    "start": "3078559",
    "end": "3084240"
  },
  {
    "text": "time um we have changed it now and so it got a",
    "start": "3084240",
    "end": "3090559"
  },
  {
    "text": "bit so we have done a lot of improvements by now the heap sizes can be smaller um why do you even leave",
    "start": "3090559",
    "end": "3097440"
  },
  {
    "text": "space because there is file system level caching um it's called memory mapping in the background so it's basically writing",
    "start": "3097440",
    "end": "3103280"
  },
  {
    "text": "the file to disk and then when you load it it's being loaded into memory it's memory mapped and you can quickly access",
    "start": "3103280",
    "end": "3108640"
  },
  {
    "text": "it and you can leave half or less by now for the heap or for the heap and the",
    "start": "3108640",
    "end": "3114880"
  },
  {
    "text": "rest for caching and to keep your system running we have also changed defaults but",
    "start": "3114880",
    "end": "3120240"
  },
  {
    "text": "elasticsearch by default will now take half of the memory of your instance and assumes it's the only service",
    "start": "3120240",
    "end": "3126319"
  },
  {
    "text": "running on your server that is another thing that sometimes tricks people because they have five things running on a server and don't configure the heap",
    "start": "3126319",
    "end": "3132880"
  },
  {
    "text": "explicitly and then elasticsearch is very greedy and just say takes half because it assumes that's you want to",
    "start": "3132880",
    "end": "3138319"
  },
  {
    "text": "give the entire node to elasticsearch that's the default assumption if you do that you need to reconfigure your heap",
    "start": "3138319",
    "end": "3143760"
  },
  {
    "text": "or it generally makes sense to configure your heap explicitly because otherwise elasticsearch will be greedy and take",
    "start": "3143760",
    "end": "3150000"
  },
  {
    "text": "everything it hands kanju thinks is the right amount um to make that faster in the long run",
    "start": "3150000",
    "end": "3155359"
  },
  {
    "text": "um one other thing that is important for especially if you have something like",
    "start": "3155359",
    "end": "3160559"
  },
  {
    "text": "time series data so any logs matrix traces or anything that ages out",
    "start": "3160559",
    "end": "3166240"
  },
  {
    "text": "is previously all the data was the same which was kind of stupid because if the",
    "start": "3166240",
    "end": "3171920"
  },
  {
    "text": "data has a life cycle you often have like the so called hot data which is like you write it today and you do most",
    "start": "3171920",
    "end": "3177040"
  },
  {
    "text": "of your search operations today and then the data from yesterday to a week ago is like warm so you don't write to it",
    "start": "3177040",
    "end": "3183440"
  },
  {
    "text": "anymore or maybe only very little you do fewer searches and then you have the code tier which is i always call it",
    "start": "3183440",
    "end": "3189280"
  },
  {
    "text": "the compliance tier when you need to keep the data around the logs around for a year because somebody might need",
    "start": "3189280",
    "end": "3194400"
  },
  {
    "text": "something but most of the times nobody does and why would you keep all of them on the same hardware profile it's very",
    "start": "3194400",
    "end": "3200079"
  },
  {
    "text": "wasteful so what what we generally would have is um we have hot notes um",
    "start": "3200079",
    "end": "3209640"
  },
  {
    "text": "warm and then cold or",
    "start": "3211440",
    "end": "3216079"
  },
  {
    "text": "now we also have a frozen here but i'll ignore that for now um",
    "start": "3216640",
    "end": "3222800"
  },
  {
    "text": "and what you do is today's write operations come into this one and this is this is a very beefy note um",
    "start": "3222800",
    "end": "3229280"
  },
  {
    "text": "where you keep relatively little data on it because it has all the right operations in most of the search operations once it ages out it moves the",
    "start": "3229280",
    "end": "3235760"
  },
  {
    "text": "data to a warm node where it keeps it around for mostly search operations and then this is like the compliance layer",
    "start": "3235760",
    "end": "3242400"
  },
  {
    "text": "all of this we have built into the cluster now and we call it ilm which stands for index life cycle",
    "start": "3242400",
    "end": "3249440"
  },
  {
    "text": "management and it's basically built in or it's not basically it is built into the elasticsearch cluster and and you can",
    "start": "3249440",
    "end": "3255680"
  },
  {
    "text": "configure a policy um how or when to move the data through the",
    "start": "3255680",
    "end": "3261520"
  },
  {
    "text": "different stages and so you can use more optimized hardware profiles if you have any logs metrics or traces we would",
    "start": "3261520",
    "end": "3268240"
  },
  {
    "text": "highly recommend to do that you can also configure when it should roll over from one index to another index so you have",
    "start": "3268240",
    "end": "3275359"
  },
  {
    "text": "evenly sized charts previously people were often using daily indices",
    "start": "3275359",
    "end": "3280880"
  },
  {
    "text": "and then on saturday and sunday you probably had very few logs and very tiny shards and on the weekdays you had a lot",
    "start": "3280880",
    "end": "3287680"
  },
  {
    "text": "which was not great so you want to have those evenly sized um",
    "start": "3287680",
    "end": "3293440"
  },
  {
    "text": "so that is kind of like the this how i we would recommend to structure anything that you have for time series um if you",
    "start": "3293440",
    "end": "3299839"
  },
  {
    "text": "want to run any benchmarks um so we publish a lot of benchmark scenarios um",
    "start": "3299839",
    "end": "3305599"
  },
  {
    "text": "and like i've said before our favorite statement is always it depends because there are so many different scenarios based on",
    "start": "3305599",
    "end": "3313119"
  },
  {
    "text": "read write ratios how large are documents how many updates do you have what is the general use case what is",
    "start": "3313119",
    "end": "3318480"
  },
  {
    "text": "your hardware profile um and this is like this will scroll down here almost forever and where we where we",
    "start": "3318480",
    "end": "3324240"
  },
  {
    "text": "benchmark everything every night um we try to avoid it's the called the the",
    "start": "3324240",
    "end": "3329280"
  },
  {
    "text": "slow boiling frog problem anybody from france here so you know where it's coming from you know when you",
    "start": "3329280",
    "end": "3336319"
  },
  {
    "text": "when you take the frog and you throw it in the boiling water it jumps out immediately but if you put it in the cold water and",
    "start": "3336319",
    "end": "3342799"
  },
  {
    "text": "slowly turn it up it sits there and thinks everything is fine until it's boiled and you want to avoid that with",
    "start": "3342799",
    "end": "3347920"
  },
  {
    "text": "your own systems because it gets today this commit makes something a little worse and that other commit makes it even worse so your your performance",
    "start": "3347920",
    "end": "3354559"
  },
  {
    "text": "suffers over time um so that's why we have these nightly benchmarks on dedicated hardware",
    "start": "3354559",
    "end": "3360880"
  },
  {
    "text": "so we figure out when we are being boiled by our own slowness to counteract that and actually the tool",
    "start": "3360880",
    "end": "3368880"
  },
  {
    "text": "to do that is called rally",
    "start": "3368880",
    "end": "3373200"
  },
  {
    "text": "which we call a macro benchmarking uh tool for elasticsearch it has so-called tracks um where you can benchmark if you",
    "start": "3374079",
    "end": "3381599"
  },
  {
    "text": "have any scenarios where you are very concerned about the performance of your system we would generally recommend to",
    "start": "3381599",
    "end": "3387760"
  },
  {
    "text": "build the scenario in rally and then run those benchmarks to figure out for your data for your hardware for your",
    "start": "3387760",
    "end": "3394640"
  },
  {
    "text": "reads and writes what makes sense and what gives you enough performance",
    "start": "3394640",
    "end": "3399839"
  },
  {
    "text": "okay i think i've covered most of the things any questions",
    "start": "3399839",
    "end": "3405838"
  },
  {
    "text": "yes please",
    "start": "3406400",
    "end": "3408880"
  },
  {
    "text": "it it actually okay okay",
    "start": "3411599",
    "end": "3417720"
  },
  {
    "text": "yes yes unfortunately yes i don't have vlogs",
    "start": "3418720",
    "end": "3426319"
  },
  {
    "text": "any other comments and before you all run off i always try to take a picture with you so i can prove to my colleagues that i've",
    "start": "3428720",
    "end": "3434960"
  },
  {
    "text": "been working today",
    "start": "3434960",
    "end": "3437680"
  },
  {
    "text": "can you wave thank you very much um",
    "start": "3442880",
    "end": "3448480"
  },
  {
    "text": "final questions otherwise i'm around for the rest of the day there are stickers when you go out um please take the",
    "start": "3448480",
    "end": "3453920"
  },
  {
    "text": "stickers so i don't have to take them anybody wants a final ball",
    "start": "3453920",
    "end": "3459119"
  },
  {
    "text": "oops sorry um thanks so much enjoy the rest of the day",
    "start": "3459520",
    "end": "3465798"
  },
  {
    "text": "you",
    "start": "3474480",
    "end": "3476559"
  }
]
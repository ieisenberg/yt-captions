[
  {
    "text": "okay hello everyone it's three o'clock",
    "start": "12389",
    "end": "17970"
  },
  {
    "text": "I'm gonna get started because I got a lot to get through first few minutes is fluff anyway if there's still people",
    "start": "17970",
    "end": "24640"
  },
  {
    "text": "coming in so welcome to the Holy Grail are you persistent ha sure a map tree",
    "start": "24640",
    "end": "29830"
  },
  {
    "text": "the C++ a lot of words in the title I'm actually going to spend a big chunk of the talk just explaining what each part",
    "start": "29830",
    "end": "36190"
  },
  {
    "text": "of that means and how it fits together so if there's any bit you're not clear on now don't worry so I'm Phil - I'm a developer advocate",
    "start": "36190",
    "end": "44079"
  },
  {
    "text": "for JetBrains that means that I typically deal with with the free C++",
    "start": "44079",
    "end": "49360"
  },
  {
    "text": "oriented products we have C line for cross-platform IDE resharper C++ if you use Visual Studio a",
    "start": "49360",
    "end": "56050"
  },
  {
    "text": "plugin or app code for iOS and Mac development we're not gonna be talking about that today but if you do want to",
    "start": "56050",
    "end": "62320"
  },
  {
    "text": "know more about that do catch me afterwards or tomorrow here both days now I'm also known as C++ circles for my",
    "start": "62320",
    "end": "70360"
  },
  {
    "text": "test framework catch but I'm going to be talking about that tomorrow another talk at the same time or no catch to whom",
    "start": "70360",
    "end": "76180"
  },
  {
    "text": "what's new in that so if you're interested to come along to that as well but today we're going to be discussing",
    "start": "76180",
    "end": "82619"
  },
  {
    "text": "this this thing hash array metric and I've chosen this sort of slightly",
    "start": "82619",
    "end": "87900"
  },
  {
    "text": "controversial title the holy grail just to try and get more people in really my",
    "start": "87900",
    "end": "93009"
  },
  {
    "text": "god is this big exclamation mark at the end let's change it actually to a question mark the reason I chose that",
    "start": "93009",
    "end": "99970"
  },
  {
    "text": "term is because I'm going to present a data structure that my claim is it has a",
    "start": "99970",
    "end": "105790"
  },
  {
    "text": "minimum trade-offs compared to associated data structures that exist in a c++ standard library we'll see by the",
    "start": "105790",
    "end": "113020"
  },
  {
    "text": "end of it if you feel that I've met that claim and what that claim actually is as we go through so the rest of the title",
    "start": "113020",
    "end": "120490"
  },
  {
    "text": "we're going to start drilling down all each part of this actually means so it can build up to where we're going with",
    "start": "120490",
    "end": "126909"
  },
  {
    "text": "it so I'm gonna start with the the last word in there I've been pronouncing it tree you may have been reading this try",
    "start": "126909",
    "end": "133030"
  },
  {
    "text": "before you've probably seen these before in a different context usually a string",
    "start": "133030",
    "end": "138760"
  },
  {
    "text": "based tree like a string dictionary where you go for each character and that becomes the index into the next level",
    "start": "138760",
    "end": "144400"
  },
  {
    "text": "down this is very very similar but I will explain exactly how we apply it to",
    "start": "144400",
    "end": "150699"
  },
  {
    "text": "hashes and when we get their reason it's pronounced tree is because it comes from the middle of the word retrieve or",
    "start": "150699",
    "end": "157540"
  },
  {
    "text": "retrieval Factory we look at the the Wikipedia entry we says that they were first described in 1959 so it's not a",
    "start": "157540",
    "end": "164800"
  },
  {
    "text": "new idea by me stretchers so most of you probably come across them before term tree was Quinn two year later by edward",
    "start": "164800",
    "end": "171250"
  },
  {
    "text": "fredkin who pronounced it as tree after the middle syllable of retrieval however",
    "start": "171250",
    "end": "177450"
  },
  {
    "text": "other authors pronounce it as try in an attempt to distinguish it verbally from",
    "start": "177450",
    "end": "183310"
  },
  {
    "text": "tree because there was a bit of ambiguity whichever pronunciation you go with but trees with disability like a subset of",
    "start": "183310",
    "end": "191440"
  },
  {
    "text": "the more general tree so it's not too bad so you can carry on pronouncing it",
    "start": "191440",
    "end": "196660"
  },
  {
    "text": "try if you like I'm going to stick to tree partly because that's like historical accuracy but mostly because",
    "start": "196660",
    "end": "202450"
  },
  {
    "text": "I've already become well known for catch I'd only become known to try as well so there's that all right let's uh let's",
    "start": "202450",
    "end": "210490"
  },
  {
    "text": "mix it up a bit let's talk about sex in fact more generally I want to talk",
    "start": "210490",
    "end": "215560"
  },
  {
    "text": "about associative data structures in C++ which there are currently eight here's",
    "start": "215560",
    "end": "221560"
  },
  {
    "text": "all of them nicely grouped together and these obvious pairings we got the the",
    "start": "221560",
    "end": "226630"
  },
  {
    "text": "single and the multi valued versions I'm sure don't need me to explain what the differences are but in terms of",
    "start": "226630",
    "end": "233470"
  },
  {
    "text": "underlying data structure there's really no difference this is really more of a constraint on insertion there may be",
    "start": "233470",
    "end": "239320"
  },
  {
    "text": "implications but usually that's the same underlying their implementation so I'm going to cancel these out and we're just",
    "start": "239320",
    "end": "245950"
  },
  {
    "text": "going to look at the slightly simpler single key versions so you've got set an ordered set of map an ordered map so now",
    "start": "245950",
    "end": "253810"
  },
  {
    "text": "we have a like an obvious division on the the horizontal axis there we've got access to the swap maps on the bottom",
    "start": "253810",
    "end": "260040"
  },
  {
    "text": "again terms of the underlying data structure there's very little difference you can implement a map in terms of a",
    "start": "260040",
    "end": "267190"
  },
  {
    "text": "set just by having a set of pairs where you really do the identity on the first value the key and that's often how",
    "start": "267190",
    "end": "273970"
  },
  {
    "text": "they're implemented so terms of interesting differences in data structure I think we can just",
    "start": "273970",
    "end": "279610"
  },
  {
    "text": "concentrate on sets of my opening a surgeon there let's talk about sex this now becomes a",
    "start": "279610",
    "end": "285189"
  },
  {
    "text": "indivisible division of two different types of data structure before we get on",
    "start": "285189",
    "end": "290439"
  },
  {
    "text": "to what the difference is actually are just an honorary mention to the good old salted vector it's not strictly a",
    "start": "290439",
    "end": "297330"
  },
  {
    "text": "standard library associative container but it can be used as one I do many applications it's still a really good",
    "start": "297330",
    "end": "303039"
  },
  {
    "text": "choice particularly compared to a standard set gives it the binary search",
    "start": "303039",
    "end": "308979"
  },
  {
    "text": "but we better cache locality and less fragmentation so we're not a Raleigh tail but for our purposes today I'm not",
    "start": "308979",
    "end": "315129"
  },
  {
    "text": "really going to consider this although we may touch on it a little bit more later so back to the sense a few",
    "start": "315129",
    "end": "322990"
  },
  {
    "text": "properties I want to draw your attention to again it should be nothing new but those underlying data structures sets",
    "start": "322990",
    "end": "330099"
  },
  {
    "text": "are not required to be implemented those red-black trees they almost always are haven't actually seen one that isn't",
    "start": "330099",
    "end": "335740"
  },
  {
    "text": "there are at least balanced binary trees we'll come into that a little bit later an ordered set is obviously based on a",
    "start": "335740",
    "end": "342819"
  },
  {
    "text": "hash table so this leads to various other properties so looking at the",
    "start": "342819",
    "end": "349319"
  },
  {
    "text": "constraints and the types you put in them we've set you have a strict weak ordering usually as a result of having a",
    "start": "349319",
    "end": "356319"
  },
  {
    "text": "lesson operator you could also provide a custom predicate unordered set the types",
    "start": "356319",
    "end": "362409"
  },
  {
    "text": "must be hashable usually with an specialization of standard hash and equatable usually with an is equal",
    "start": "362409",
    "end": "369249"
  },
  {
    "text": "operator again this can both be provided with custom predicates if you prefer but",
    "start": "369249",
    "end": "374469"
  },
  {
    "text": "a sort of orthogonal constraints in the types and sometimes that will actually dictate which structure we can use",
    "start": "374469",
    "end": "380129"
  },
  {
    "text": "usually we're more interested in the complexity guarantees which tend to lead",
    "start": "380129",
    "end": "385389"
  },
  {
    "text": "to performance so set house login or lookup we're mostly going to be",
    "start": "385389",
    "end": "390519"
  },
  {
    "text": "conserving lookup today whereas an order set has this really good constant time",
    "start": "390519",
    "end": "397979"
  },
  {
    "text": "complexity on average but we have to forget this it can actually tend towards",
    "start": "397979",
    "end": "403599"
  },
  {
    "text": "linear in the worst case and we don't often actually hit that but but you can actually get into it we will see an",
    "start": "403599",
    "end": "409119"
  },
  {
    "text": "example of that a little bit later but usually that that constant time lookup on average is what gives us the",
    "start": "409119",
    "end": "414939"
  },
  {
    "text": "performance actually translates into the performance so usually where we can performance is a",
    "start": "414939",
    "end": "420700"
  },
  {
    "text": "goal we will reach for an ordered set over set and that's an important point we'll come back to a bit later a little",
    "start": "420700",
    "end": "428170"
  },
  {
    "text": "bit of background we're going to dig into some of the technical details of if in a moment I wanted to move on so one",
    "start": "428170",
    "end": "433900"
  },
  {
    "text": "of the other words in the title to clear that up and this is the persistence",
    "start": "433900",
    "end": "439600"
  },
  {
    "text": "persistence and actually want to mention first of all what are we not talking about so I put this picture up here so",
    "start": "439600",
    "end": "446020"
  },
  {
    "text": "this is a near the end of the London Marathon last year it's definitely not the type of assistance we're talking about here but we're also not talking",
    "start": "446020",
    "end": "453520"
  },
  {
    "text": "about anything to do with databases file system networking you anything like that that's not the type of persistence we",
    "start": "453520",
    "end": "460120"
  },
  {
    "text": "mean that's common confusion when people hear about persistent data structures for the first time we are talking about",
    "start": "460120",
    "end": "466600"
  },
  {
    "text": "is really best explained for an example so start with something really simple a",
    "start": "466600",
    "end": "471640"
  },
  {
    "text": "list they don't tend to use lists so much in C++ these days you could say we",
    "start": "471640",
    "end": "478750"
  },
  {
    "text": "hate lists but they're really useful example and still very common with functional programming languages because",
    "start": "478750",
    "end": "485110"
  },
  {
    "text": "of this property so let's just have a quick recap on how a singly linked list",
    "start": "485110",
    "end": "490330"
  },
  {
    "text": "is implemented okay we're gonna whiz through this because I'm sure you're familiar with it but linked lists will",
    "start": "490330",
    "end": "495970"
  },
  {
    "text": "have a number of nodes each with a value and also a pointer to the next or",
    "start": "495970",
    "end": "501490"
  },
  {
    "text": "previous note depending on how you look at it and the first node is usually called the head and the rest for the",
    "start": "501490",
    "end": "507370"
  },
  {
    "text": "first node of the rest is called the title now what's interesting is if you if you want to add a new node to the",
    "start": "507370",
    "end": "514210"
  },
  {
    "text": "head the only thing you have to do is just write pointer to the original head",
    "start": "514210",
    "end": "520300"
  },
  {
    "text": "into the new node the original nodes don't actually need to change at all",
    "start": "520300",
    "end": "525450"
  },
  {
    "text": "they don't usually deal with the nodes raw we usually have some sort of wrapper type there which we used to call the",
    "start": "525450",
    "end": "530980"
  },
  {
    "text": "list and they would have the pointers to the heads and maybe a size as well so",
    "start": "530980",
    "end": "536800"
  },
  {
    "text": "they're pretty lightweight and shape all the other storage is in the nodes and that means that if you perform all your",
    "start": "536800",
    "end": "545830"
  },
  {
    "text": "mutations by actually producing a new list instead of mutating in place",
    "start": "545830",
    "end": "551250"
  },
  {
    "text": "you can keep the original values around that's what we mean by persistence the old values persist and this is a really",
    "start": "551250",
    "end": "559110"
  },
  {
    "text": "interesting property that usually naively we might think this will evolve a lot of copying and yes sometimes it",
    "start": "559110",
    "end": "564540"
  },
  {
    "text": "can tend towards that but in the best cases like this one there's no additional copying involved to those",
    "start": "564540",
    "end": "569640"
  },
  {
    "text": "notes the long to working at the head and we can we can do removal operations",
    "start": "569640",
    "end": "575250"
  },
  {
    "text": "as well from the head we can stack these things up we can get whole generations list with a very low cost because",
    "start": "575250",
    "end": "581130"
  },
  {
    "text": "they're all sharing their common State and of course that breaks down a bit if you start to do mutations further down",
    "start": "581130",
    "end": "586680"
  },
  {
    "text": "the list that will have that be more copying and we don't tend to use linked lists in C++ anyway very much it's very",
    "start": "586680",
    "end": "593880"
  },
  {
    "text": "occasionally the right they destruction but all the point of hopping lack of cache locality and that",
    "start": "593880",
    "end": "599730"
  },
  {
    "text": "sort of thing will I mean that back to the usually a better choice but very illustrative for this purpose and we can",
    "start": "599730",
    "end": "605850"
  },
  {
    "text": "we can take what we just have been talking about there and start to move it up by just adding a single extra pointer",
    "start": "605850",
    "end": "611090"
  },
  {
    "text": "so we have two pointers and each node we have a tree simple binary tree like this",
    "start": "611090",
    "end": "618660"
  },
  {
    "text": "one here is our strict weak ordering ordered from from left to right now if we want to add a new item to this",
    "start": "618660",
    "end": "625380"
  },
  {
    "text": "structure say it is for up here well we just reverse down the tree to find where",
    "start": "625380",
    "end": "630750"
  },
  {
    "text": "we need to add it in we do have a couple of choices we could hang off the free or off the five but we hang off the five",
    "start": "630750",
    "end": "637230"
  },
  {
    "text": "then we don't need to rewrite any other notes and that's what we always do we hang up an existing leaf that's nice and",
    "start": "637230",
    "end": "644910"
  },
  {
    "text": "simple and if this was a mutable data structure we could stop there but if we",
    "start": "644910",
    "end": "651330"
  },
  {
    "text": "want persistence we need to keep the original structure around so we can't actually mutate our five node there what",
    "start": "651330",
    "end": "658650"
  },
  {
    "text": "we're gonna have to do is take a copy of it and then write the new pointer to the",
    "start": "658650",
    "end": "664050"
  },
  {
    "text": "new leaf into the copy and then by doing that we also have to write a new copy",
    "start": "664050",
    "end": "669780"
  },
  {
    "text": "into its parent all the way up to the root so this is a common pattern you'll see in persistent de disruptions this",
    "start": "669780",
    "end": "676050"
  },
  {
    "text": "sort of copying a path up to the root but that's all the copying that's involved and in a larger tree this will",
    "start": "676050",
    "end": "683190"
  },
  {
    "text": "actually still be sharing a lot of and state she end up with something like this so we've got the entire original",
    "start": "683190",
    "end": "688440"
  },
  {
    "text": "tree untouched over here and then just a new path with links into the old tree so",
    "start": "688440",
    "end": "693480"
  },
  {
    "text": "it's very a lot of common state usually a lot more than is shown here so that I was actually fairly easy to do but this",
    "start": "693480",
    "end": "700770"
  },
  {
    "text": "was a simple binary tree and they can tend to get very unbalanced imagine loading out we've already sorted data",
    "start": "700770",
    "end": "706950"
  },
  {
    "text": "you'd end up with effective like a linked list on one side or the other so we need some strategy for rebalancing",
    "start": "706950",
    "end": "712710"
  },
  {
    "text": "the trees that's why say with standard set there's got to be some sort of",
    "start": "712710",
    "end": "717810"
  },
  {
    "text": "balanced binary tree and different strategies for doing that the most popular one is the red black tree at",
    "start": "717810",
    "end": "723990"
  },
  {
    "text": "least in the standard library implementations I'm not going to go too much detail on this because that's not",
    "start": "723990",
    "end": "729360"
  },
  {
    "text": "the subject of this talk but he's all the rules if you're interested what I do want to do is just quickly look at how",
    "start": "729360",
    "end": "735540"
  },
  {
    "text": "that would play out with our example just now and how it relates to persistence so here's the same example",
    "start": "735540",
    "end": "741570"
  },
  {
    "text": "again we've now covered all of the nodes red or black according to those rules we",
    "start": "741570",
    "end": "747240"
  },
  {
    "text": "can easily do that with with no storage overhead by the way we've added a new four node down here and that breaks one",
    "start": "747240",
    "end": "753030"
  },
  {
    "text": "of the invariants which was that no red chili red node should have a red child so in order to to fix that we usually",
    "start": "753030",
    "end": "760080"
  },
  {
    "text": "consider the parent grandparent or uncle nodes so we can do it locally with local reasoning and in this case we just have",
    "start": "760080",
    "end": "768300"
  },
  {
    "text": "to recolor those nodes according to those rules and now we've exciting they're in but no we broken it",
    "start": "768300",
    "end": "774900"
  },
  {
    "text": "again between the three and a seven so we just recursively go up towards the root that violates the black node black",
    "start": "774900",
    "end": "782190"
  },
  {
    "text": "root invariants so we'll you recall about to fix that so we're just been recursively applying those I couldn't",
    "start": "782190",
    "end": "789840"
  },
  {
    "text": "seem to come up with a small enough example to fit on a slide that actually involve moving the nodes around",
    "start": "789840",
    "end": "794880"
  },
  {
    "text": "so in this case we just recolor them but they will often involve moving them around as well the reason I wanted to illustrate this",
    "start": "794880",
    "end": "800910"
  },
  {
    "text": "is because now if you look at all the nodes we touched as well as that path up to route we've got a little bit of",
    "start": "800910",
    "end": "806760"
  },
  {
    "text": "collateral damage as well better touch some of the other nodes around them so in terms of persistence as a slightly",
    "start": "806760",
    "end": "812430"
  },
  {
    "text": "higher cost we've red black trees but they said persistent red black tree",
    "start": "812430",
    "end": "818430"
  },
  {
    "text": "a really useful data structure fact consulting Wikipedia again interesting",
    "start": "818430",
    "end": "823770"
  },
  {
    "text": "paragraph on the page for red black trees says that red black trees are also particularly valuable in functional",
    "start": "823770",
    "end": "830820"
  },
  {
    "text": "programming where they're one of the most common persistent data structures used to construct associative arrays and",
    "start": "830820",
    "end": "837330"
  },
  {
    "text": "sets which can retain previous versions after mutations what we were talking about then it talks about the the log in",
    "start": "837330",
    "end": "843870"
  },
  {
    "text": "space and time so there are useful I've implemented these in the past that being",
    "start": "843870",
    "end": "850320"
  },
  {
    "text": "very useful for us but think back to where we started talking about sets",
    "start": "850320",
    "end": "855870"
  },
  {
    "text": "versus an ordered sets usually the reason we go for the own order sets for performance so just because we want to",
    "start": "855870",
    "end": "863070"
  },
  {
    "text": "make these persistent do we want to have to get up on that performance and that's where we're going to lead to all gel now",
    "start": "863070",
    "end": "868740"
  },
  {
    "text": "hash free so you could actually approach this from the the hash table side you",
    "start": "868740",
    "end": "874980"
  },
  {
    "text": "can't make a hash table in itself persistent I mean you can generally evolve copying the whole hash table so",
    "start": "874980",
    "end": "881580"
  },
  {
    "text": "it becomes counterproductive really so you might start to think well what about if we break this table down into chunks",
    "start": "881580",
    "end": "888060"
  },
  {
    "text": "that we arranged in a hierarchy and that sort of line of reasoning may take you to where we're going I would approach it",
    "start": "888060",
    "end": "893130"
  },
  {
    "text": "from the other side though start we've red-black trees which why I've dwelled",
    "start": "893130",
    "end": "898770"
  },
  {
    "text": "on that for a little bit too long the problem was we've only got the two",
    "start": "898770",
    "end": "903810"
  },
  {
    "text": "pointers at each node and that puts a limit on you know how shallow we can",
    "start": "903810",
    "end": "908970"
  },
  {
    "text": "make the tree it's pretty much fixed I've got that log in complexity so if that's the problem",
    "start": "908970",
    "end": "914070"
  },
  {
    "text": "oh and by the way about the implication of this certain examples you've got a set of about 15 million entries in it",
    "start": "914070",
    "end": "920990"
  },
  {
    "text": "which is not that unusual this could be about twenty four nodes deep it's a lot",
    "start": "920990",
    "end": "926070"
  },
  {
    "text": "of pointer hops a lot of cache misses and that's where the hash tables really start to shine but if the problem is not",
    "start": "926070",
    "end": "932310"
  },
  {
    "text": "enough pointers surely the solution is just to add more pointers and in fact",
    "start": "932310",
    "end": "938610"
  },
  {
    "text": "that is it's exactly what we want to do so don't have too many because then you end up with something like a hash table",
    "start": "938610",
    "end": "944010"
  },
  {
    "text": "where defeats the ability to make a persistent so we've got to have a all enough number that we get the",
    "start": "944010",
    "end": "950970"
  },
  {
    "text": "benefits without so much of the downside and in fact that's exactly what we gonna do but it raises now a couple more",
    "start": "950970",
    "end": "958440"
  },
  {
    "text": "questions in terms of how we implement that and in answering those questions that's going to then lead us to our hash",
    "start": "958440",
    "end": "966360"
  },
  {
    "text": "tree so what are the questions by the first one is how do we know which",
    "start": "966360",
    "end": "971370"
  },
  {
    "text": "pointed to follow with the binary tree was easy we just do a less than comparison go left or right what do we",
    "start": "971370",
    "end": "978030"
  },
  {
    "text": "do here first have a look at a slightly more concrete example so we've got",
    "start": "978030",
    "end": "983340"
  },
  {
    "text": "branch know is you've got leaf nodes each branch node is going to have an array of pointers in I've chosen 32 here",
    "start": "983340",
    "end": "989100"
  },
  {
    "text": "that's not an accident will come in two why in a moment and you know some of those have pointers to branches some tea",
    "start": "989100",
    "end": "995610"
  },
  {
    "text": "leaves so what we do then is we take the hash of the key or the value exactly as",
    "start": "995610",
    "end": "1004040"
  },
  {
    "text": "we would do with a hash table but this time we just peel off the first five bits and that becomes the index into B",
    "start": "1004040",
    "end": "1011870"
  },
  {
    "text": "right this is why why it's a tree crie so in this case that 27th bit is a",
    "start": "1011870",
    "end": "1019910"
  },
  {
    "text": "pointer to another branch node so we follow that down we then take the next",
    "start": "1019910",
    "end": "1026839"
  },
  {
    "text": "five bits that gives us a new index six in this case the six bit takes us to a",
    "start": "1026840",
    "end": "1031970"
  },
  {
    "text": "leaf if it been another branch we would go down again and we'll keep going until we are exhausted half or we hit a leaf",
    "start": "1031970",
    "end": "1038300"
  },
  {
    "text": "so exactly as we've hash tables we will have hash collisions so the leaf nodes",
    "start": "1038300",
    "end": "1044480"
  },
  {
    "text": "must contain an array of values and we have to have a strategy for resolving that as well so that could be a linear",
    "start": "1044480",
    "end": "1050150"
  },
  {
    "text": "search if you would do with a standard set now you could do other things as well we'll come back to that point little bit",
    "start": "1050150",
    "end": "1057380"
  },
  {
    "text": "later as well so that's where the tree comes into it and that's how we managed",
    "start": "1057380",
    "end": "1062420"
  },
  {
    "text": "to to have a large number of pointers but that leads on to the next question",
    "start": "1062420",
    "end": "1068150"
  },
  {
    "text": "which is how do we deal with this large number of pointers forgot in this case 32 at each node and on 64-bit",
    "start": "1068150",
    "end": "1075050"
  },
  {
    "text": "architecture that's quite a lot of space that most of the time as you can see it's going to be null pointers we want",
    "start": "1075050",
    "end": "1081410"
  },
  {
    "text": "to pay that space for all those no point more pointed so sort of smells like we want some sort of",
    "start": "1081410",
    "end": "1088220"
  },
  {
    "text": "sparse array to hold these and that's exactly what we're going to do so what we do is we have a compact array which",
    "start": "1088220",
    "end": "1096049"
  },
  {
    "text": "has just enough slots for the number of pointers that we need free in this case and then we have an additional integer",
    "start": "1096049",
    "end": "1102159"
  },
  {
    "text": "which acts as a bitmap into our compact array so if you imagine a virtual sparse",
    "start": "1102159",
    "end": "1109580"
  },
  {
    "text": "array of 32 slots each on set bit just corresponds to a null pointer and a set",
    "start": "1109580",
    "end": "1115669"
  },
  {
    "text": "bits to a pointer in the compact right pretty straightforward so we just use that bitmap to map by finding the bit",
    "start": "1115669",
    "end": "1122749"
  },
  {
    "text": "that corresponds to the index you want and then counting the number of set bits to the right of it so you mask out the",
    "start": "1122749",
    "end": "1130100"
  },
  {
    "text": "top bits let's count the set bits and that gives you the index so if you take the the leftmost bit up there there's",
    "start": "1130100",
    "end": "1135529"
  },
  {
    "text": "two bits to the right to the right that'll give you an index for two it gives you the right entry sounds simple",
    "start": "1135529",
    "end": "1142070"
  },
  {
    "text": "enough then it raises another question of how do you efficiently compute the",
    "start": "1142070",
    "end": "1147080"
  },
  {
    "text": "number of set bits you could do that naively quite easily but gonna do it efficiently we'll come back to that",
    "start": "1147080",
    "end": "1153379"
  },
  {
    "text": "point a bit later but that's the approach that's where the array Maps part comes into it so we now pretty much",
    "start": "1153379",
    "end": "1161119"
  },
  {
    "text": "have the complete definition of a persistent hash array mapped tree so",
    "start": "1161119",
    "end": "1166909"
  },
  {
    "text": "we've arrived so what we get something like this again trying to keep it simple",
    "start": "1166909",
    "end": "1172009"
  },
  {
    "text": "for the slide so I haven't shown a lot of branching but it's a few branches there with more than more than two",
    "start": "1172009",
    "end": "1177440"
  },
  {
    "text": "pointers to give you an idea and you can see the hash codes that we've we've been peeling back as we go down it's a simple",
    "start": "1177440",
    "end": "1184639"
  },
  {
    "text": "path up to the root so he's a much shallower fact let's have a look at the some of the properties of this structure",
    "start": "1184639",
    "end": "1190909"
  },
  {
    "text": "so for a 32-bit hash because you could have 64-bit hash of course we've got a",
    "start": "1190909",
    "end": "1197509"
  },
  {
    "text": "max depth of 6 or 7 say 6 or 7 because if you peeling back five bits at a time",
    "start": "1197509",
    "end": "1203179"
  },
  {
    "text": "you'll have two at the end it's probably not worth considering that part the hash let's just leave it to hash collisions",
    "start": "1203179",
    "end": "1208340"
  },
  {
    "text": "so they'll give you six usually for that 15 million baddies example we've got an",
    "start": "1208340",
    "end": "1215299"
  },
  {
    "text": "average depth of five significantly better than 24 in the red black tree case not as good as a",
    "start": "1215299",
    "end": "1221120"
  },
  {
    "text": "hash table but close enough as we said the leaseholder raiser values",
    "start": "1221120",
    "end": "1226640"
  },
  {
    "text": "because we need to deal with hash collisions but it's more space efficient than a hash table because we're doing that sparse all right technically in",
    "start": "1226640",
    "end": "1234620"
  },
  {
    "text": "this case the complexity is log 32 n which sounds really awkward see where to imagine in practice therefore most",
    "start": "1234620",
    "end": "1242090"
  },
  {
    "text": "real-world purposes it does track much more closely the what constants I'm on",
    "start": "1242090",
    "end": "1248990"
  },
  {
    "text": "average complexity of the hash table but it's not quite as good and here's a",
    "start": "1248990",
    "end": "1255230"
  },
  {
    "text": "bonus we don't need to do any rebalancing like we did with the the binary trees the reason is because that",
    "start": "1255230",
    "end": "1262310"
  },
  {
    "text": "distribution of our tree is going to be based on the distribution of the hash flipside is we do need a good hashing",
    "start": "1262310",
    "end": "1268310"
  },
  {
    "text": "algorithm if the the hash is not very well distributed then our tree won't be over and we'll see an example of where",
    "start": "1268310",
    "end": "1274580"
  },
  {
    "text": "that goes wrong in a while as well so that's the theory let's actually look at",
    "start": "1274580",
    "end": "1280430"
  },
  {
    "text": "some of the the outcomes of all this if you looked at the abstract on the",
    "start": "1280430",
    "end": "1286340"
  },
  {
    "text": "website for this talk there's a bit that I hope I made this claim I like that",
    "start": "1286340",
    "end": "1292840"
  },
  {
    "text": "talk about hash trees say they're close but not quite as fast as pure hash tables that's the claim now I've written",
    "start": "1292840",
    "end": "1300830"
  },
  {
    "text": "a reference implementation of this it's a it's not complete for usability purposes but it's completely enough to",
    "start": "1300830",
    "end": "1307730"
  },
  {
    "text": "run these run some tests on it to see how this plays out so I'm gonna have a look at some graphs now control your own",
    "start": "1307730",
    "end": "1313970"
  },
  {
    "text": "conclusions so we look at the the Palmas so my methodology is well I used a micro",
    "start": "1313970",
    "end": "1323180"
  },
  {
    "text": "benchmarking framework called non est Oh since I did this a few months ago I've",
    "start": "1323180",
    "end": "1328970"
  },
  {
    "text": "actually started to add micro benchmarking support to to catch and I've actually converted the tests over",
    "start": "1328970",
    "end": "1335270"
  },
  {
    "text": "to that but it's not quite as rich enough to produce the graphs I need to get so I've kept the original graphs for now and what no-nos does it will run",
    "start": "1335270",
    "end": "1343160"
  },
  {
    "text": "your your tests long enough to to be meaningful versus the clock accuracy but then it will run a number of samples",
    "start": "1343160",
    "end": "1350200"
  },
  {
    "text": "about default or hundred some of them have done a thousand to make sure they",
    "start": "1350200",
    "end": "1355390"
  },
  {
    "text": "are statistically relevant either never do statistical analysis on that and give",
    "start": "1355390",
    "end": "1361390"
  },
  {
    "text": "you the the mean in the variation and so on discarding outliers so it's pretty good for that now be used clang with",
    "start": "1361390",
    "end": "1368350"
  },
  {
    "text": "lits lip C++ that's relevant because we're going to be comparing against stone to stone I don't always set its",
    "start": "1368350",
    "end": "1375490"
  },
  {
    "text": "bat libraries implementations so there may be quality of implementation there concerns",
    "start": "1375490",
    "end": "1380590"
  },
  {
    "text": "that's all I've done so far though would be interesting to see how others fare I've started off by testing loading up",
    "start": "1380590",
    "end": "1388000"
  },
  {
    "text": "one of these containers all of these containers with a hundred thousand integers the monotonically increasing",
    "start": "1388000",
    "end": "1393970"
  },
  {
    "text": "series of integers so let's have a look how that plays out here's the first graph she's for insert and the the blue",
    "start": "1393970",
    "end": "1402460"
  },
  {
    "text": "box here is a standard set large green box is hash table or hampt for short and",
    "start": "1402460",
    "end": "1409510"
  },
  {
    "text": "in this orange bar down here almost hardly see is an ordered set but the y",
    "start": "1409510",
    "end": "1415000"
  },
  {
    "text": "axis is time which means I'm really not doing very well on this one it's a bit of a",
    "start": "1415000",
    "end": "1420430"
  },
  {
    "text": "disappointment I'm about four or five times slower than standard set and about twenty times slower than on August says",
    "start": "1420430",
    "end": "1426880"
  },
  {
    "text": "so what's going on here there's a couple of things the most important one is that this is insert and mostly optimization",
    "start": "1426880",
    "end": "1434830"
  },
  {
    "text": "so far has gone into lookup but we're actually playing the full cost of persistence here every time you add a",
    "start": "1434830",
    "end": "1441880"
  },
  {
    "text": "new node you'll be copying whole whole paths so it's quite a big overhead there",
    "start": "1441880",
    "end": "1447790"
  },
  {
    "text": "are some optimizations you can apply which I've done very successfully in my red black tree implementation before now",
    "start": "1447790",
    "end": "1452830"
  },
  {
    "text": "which mostly involves a form of copy-on-write if nodes are not shared you can actually take them in place",
    "start": "1452830",
    "end": "1458860"
  },
  {
    "text": "because no one outside has seen them yet I haven't done that here yet I'm fairly",
    "start": "1458860",
    "end": "1464020"
  },
  {
    "text": "confident that will bring it down to at least the level of first standard set and hopefully closer to an ordered set",
    "start": "1464020",
    "end": "1469900"
  },
  {
    "text": "but I can't quite prove that yet so there's some asterisk around this one",
    "start": "1469900",
    "end": "1476110"
  },
  {
    "text": "and that's insert so I said look at lookup then I'll shoot before we do that",
    "start": "1476110",
    "end": "1481480"
  },
  {
    "text": "another thing to note about these graphs is let's figure it back and if you can see the the black lines which is the",
    "start": "1481480",
    "end": "1488350"
  },
  {
    "text": "variance is actually quite high variance in places if you look at the the scatterplot diagram instead you can see",
    "start": "1488350",
    "end": "1495070"
  },
  {
    "text": "that the orange in the blue lines are not too bad but the the green one for the hash tree gets very jittery towards",
    "start": "1495070",
    "end": "1501370"
  },
  {
    "text": "Ian and the right at the end there's a big spike there's obviously something going on on my machine when I ran this I try to shut down as much as possible but",
    "start": "1501370",
    "end": "1507760"
  },
  {
    "text": "you can't get everything so no Gnaeus will explode those outliers but it's it's averaged included in that second",
    "start": "1507760",
    "end": "1513309"
  },
  {
    "text": "half of the graph there as I think it would be ferret when you considered the first half doesn't make a big difference in this case but I wanted to point that",
    "start": "1513309",
    "end": "1520030"
  },
  {
    "text": "out because for now on I'm just going to look at maybe these graphs or my aggravation aggregated views all right",
    "start": "1520030",
    "end": "1525910"
  },
  {
    "text": "since they could look up so the same hundred thousand integers but now we're",
    "start": "1525910",
    "end": "1531220"
  },
  {
    "text": "doing a find so now the blue of the bottom is still unordered sat still the",
    "start": "1531220",
    "end": "1536320"
  },
  {
    "text": "winner but the orange on top is standard set so green is now beating now so we're",
    "start": "1536320",
    "end": "1543910"
  },
  {
    "text": "getting closer starting to get there but it's still closer to stand on our old set oh sorry standard set rather than",
    "start": "1543910",
    "end": "1549730"
  },
  {
    "text": "unordered set so I'm not quite meeting that claim yet so slightly disappointing",
    "start": "1549730",
    "end": "1555040"
  },
  {
    "text": "still boss what's the problem here well and where I said that our the",
    "start": "1555040",
    "end": "1561250"
  },
  {
    "text": "balance of the trees dictated by the quality of the hash algorithm so we're using a sequence of monotonically",
    "start": "1561250",
    "end": "1567700"
  },
  {
    "text": "increasing integers and we're using lip C++ and it's a default implementation",
    "start": "1567700",
    "end": "1574090"
  },
  {
    "text": "for standard hash for an integer is just the identity function which means our hashes are also a monotonically",
    "start": "1574090",
    "end": "1579730"
  },
  {
    "text": "increasing series of integers so we've got a really unbalanced tree here and even with that were beating sets that's",
    "start": "1579730",
    "end": "1586570"
  },
  {
    "text": "not too bad but as an opportunity for improvement that there's a few ways we can we can tackle this which I've not",
    "start": "1586570",
    "end": "1592600"
  },
  {
    "text": "had a chance to do yet I did experiment with first and hashey mixing algorithms",
    "start": "1592600",
    "end": "1598750"
  },
  {
    "text": "so he made things worse so I've got that for now them I'm confident we can get that down as well so let's try another",
    "start": "1598750",
    "end": "1606490"
  },
  {
    "text": "example where we have better hash distribution so what I did next was I took 100,000 integers and then I by",
    "start": "1606490",
    "end": "1613780"
  },
  {
    "text": "sixth base 64 encoded them and use the strings resulted from that so we've got 100 hundred fellow before",
    "start": "1613780",
    "end": "1621250"
  },
  {
    "text": "we get on to that actually I did plot this for all the orders of magnitude between 100 and a million well we'll",
    "start": "1621250",
    "end": "1628000"
  },
  {
    "text": "come back to those so the next one is strings with a base64 encoded versions and here you'll say for the orange line",
    "start": "1628000",
    "end": "1636640"
  },
  {
    "text": "at the top is set again but the blue line in the middle is unordered set at",
    "start": "1636640",
    "end": "1642700"
  },
  {
    "text": "the bottom the winner on this particular test is hashed rate and that was a little bit surprising",
    "start": "1642700",
    "end": "1648690"
  },
  {
    "text": "we're actually beating hash free in this example that's a specific case and we're",
    "start": "1648690",
    "end": "1655360"
  },
  {
    "text": "comparing against a specific implementation and say there can be quality of implementation issues so I fully expect another implementation of",
    "start": "1655360",
    "end": "1662530"
  },
  {
    "text": "unordered set 2 to beat hash tree but I think this is good enough to show that at least in this case we can be in the",
    "start": "1662530",
    "end": "1669610"
  },
  {
    "text": "ballpark for my claim few asterisks good name but this is really promising I'm",
    "start": "1669610",
    "end": "1677740"
  },
  {
    "text": "still a little bit worried about the the Instituto so I then took those strings I took their hash codes and I ran the",
    "start": "1677740",
    "end": "1684730"
  },
  {
    "text": "test again with integers based on those hashes so you've got the same distribution but with integers and this",
    "start": "1684730",
    "end": "1691090"
  },
  {
    "text": "is interesting I wasn't expecting such a change in the profile but we start off with hash tree being the winner again",
    "start": "1691090",
    "end": "1697750"
  },
  {
    "text": "setting on order set a much closer but they're all much closer but somewhere between 10,000 and 100,000 they will",
    "start": "1697750",
    "end": "1704320"
  },
  {
    "text": "cross over until at the top this one goes up to ten million by the way",
    "start": "1704320",
    "end": "1709830"
  },
  {
    "text": "standard set becomes the winner especially beating unordered set and an hash tree and I suspect the reason for",
    "start": "1709830",
    "end": "1718690"
  },
  {
    "text": "this is though that this level the the hash collision start to become significant so I said before that that",
    "start": "1718690",
    "end": "1725520"
  },
  {
    "text": "linear search at the end can become significant I think that's what's happening here and we've hash hash tree is also",
    "start": "1725520",
    "end": "1733300"
  },
  {
    "text": "currently doing a linear search for its hash collisions but what we could do is",
    "start": "1733300",
    "end": "1738430"
  },
  {
    "text": "we could detect whether to type our supports strictly recording and then use",
    "start": "1738430",
    "end": "1744580"
  },
  {
    "text": "that to do a binary search at the end I haven't tried that yet but I have a feeling that that will bring us",
    "start": "1744580",
    "end": "1749940"
  },
  {
    "text": "down to probably beating out standard set at the top there as well but in any",
    "start": "1749940",
    "end": "1755909"
  },
  {
    "text": "case I'm reasonably happy with that terms of trade offs yeah I think we're doing okay so that's the performance of",
    "start": "1755909",
    "end": "1763679"
  },
  {
    "text": "the safe I'll leave it to you to decide would be meeting that claim because there are a couple of asterisks but I",
    "start": "1763679",
    "end": "1768990"
  },
  {
    "text": "want to move on to is looking a little bit of the code now the first version I",
    "start": "1768990",
    "end": "1774539"
  },
  {
    "text": "did of this talk I actually had 90 minutes I went into the code in quite some depth of standard time for that",
    "start": "1774539",
    "end": "1779580"
  },
  {
    "text": "here but there's a couple of bits I want to call out the first ways to go back to",
    "start": "1779580",
    "end": "1784860"
  },
  {
    "text": "this slide where we talked about the the array mapping and now I said at the time",
    "start": "1784860",
    "end": "1789960"
  },
  {
    "text": "that the trick here is how we did account set bits that efficiently there's one implementation got this from",
    "start": "1789960",
    "end": "1798120"
  },
  {
    "text": "a stack overflow of course in fact stack overflow led me to this this site on",
    "start": "1798120",
    "end": "1805140"
  },
  {
    "text": "Stanford Hagee it's a whole page or bit shifting algorithms to do just this task",
    "start": "1805140",
    "end": "1810750"
  },
  {
    "text": "counting set bits whole load of them this one seemed to be about the best on average the more specialized cases are",
    "start": "1810750",
    "end": "1816240"
  },
  {
    "text": "some better ones there's no branching in here so it's it's actually pretty performant it's all",
    "start": "1816240",
    "end": "1822210"
  },
  {
    "text": "bit shifting but notice that common in the middle like this comments from the",
    "start": "1822210",
    "end": "1827760"
  },
  {
    "text": "code by the way could be substituted for an assembler instruction if available and in fact if you're using GCC or clang",
    "start": "1827760",
    "end": "1835320"
  },
  {
    "text": "you can use this intrinsic built-in pop count but with a certain compiler switch",
    "start": "1835320",
    "end": "1840419"
  },
  {
    "text": "will give you that assembly instruction and that's what I used in these tests so",
    "start": "1840419",
    "end": "1845750"
  },
  {
    "text": "if you if you use the previous bit shifting version instead everything just",
    "start": "1845750",
    "end": "1851309"
  },
  {
    "text": "sort of shifts up a little bit it doesn't really change much except I think but the one where hash tree was",
    "start": "1851309",
    "end": "1857580"
  },
  {
    "text": "winning its pushes it slightly above an ordered set but everything basically hold so it's actually pretty efficient",
    "start": "1857580",
    "end": "1863720"
  },
  {
    "text": "this is obviously better and most architectures will support it so it's I think it's fair so also going back to to",
    "start": "1863720",
    "end": "1873539"
  },
  {
    "text": "this slide where we showed the hash table like we said with lists we don't",
    "start": "1873539",
    "end": "1879539"
  },
  {
    "text": "usually deal with the nodes raw we use wrapper type which will also include the",
    "start": "1879539",
    "end": "1885240"
  },
  {
    "text": "sign so we didn't have to visit everything to compute that and in fact what we can do in code is just capture",
    "start": "1885240",
    "end": "1894210"
  },
  {
    "text": "those in a single data structure it's going to be a pointer in a size which for most architectures we can deal with",
    "start": "1894210",
    "end": "1900090"
  },
  {
    "text": "atomically and that has some implications so I use this hash tree",
    "start": "1900090",
    "end": "1905429"
  },
  {
    "text": "data structure to to fit into a more",
    "start": "1905429",
    "end": "1910530"
  },
  {
    "text": "general hash tree wrapper and we're going to the whole this in detail but it",
    "start": "1910530",
    "end": "1916470"
  },
  {
    "text": "basically just has more sort of standard container like a wrapper for that and",
    "start": "1916470",
    "end": "1921600"
  },
  {
    "text": "all of the logic for insertion is in there as well greggers interesting is I",
    "start": "1921600",
    "end": "1927419"
  },
  {
    "text": "have another type called shared hash tree and this will hold that hattery data atomically so we can do an atomic",
    "start": "1927419",
    "end": "1934679"
  },
  {
    "text": "compare and exchange on that but that means this can be a place that you can share between threads and you just ask",
    "start": "1934679",
    "end": "1940740"
  },
  {
    "text": "it for its current copy the hash tree data because it's a copy that we can get atomically we could then work on that",
    "start": "1940740",
    "end": "1946620"
  },
  {
    "text": "off to the side and then commit it back later like put things in there to make that a bit easier so looking at a test",
    "start": "1946620",
    "end": "1953610"
  },
  {
    "text": "case for this I'm actually dealing with concurrency here but you can see get the shared hash",
    "start": "1953610",
    "end": "1959039"
  },
  {
    "text": "tree start a transaction gives you back an object that you can get a hash tree from you can then insert it your ledger",
    "start": "1959039",
    "end": "1964860"
  },
  {
    "text": "and commit it back now commit won't necessarily succeed because if someone else in the meantime has changed it then",
    "start": "1964860",
    "end": "1971730"
  },
  {
    "text": "they all know it'll say that failed and you have to do it again in a loop so to make that a little bit simpler I've got",
    "start": "1971730",
    "end": "1977520"
  },
  {
    "text": "this update with method which will you pass in a lambda which gives you back",
    "start": "1977520",
    "end": "1982830"
  },
  {
    "text": "the hash tree you can start modifying and at the end it will commit it back and we'll run this in a loop that's necessary so did I yes that's the",
    "start": "1982830",
    "end": "1992789"
  },
  {
    "text": "implementation in it it's actually pretty straightforward the cause in to",
    "start": "1992789",
    "end": "1999390"
  },
  {
    "text": "commit their commits what does the atomic exchange but it's pretty straightforward but otherwise it will",
    "start": "1999390",
    "end": "2007460"
  },
  {
    "text": "rebase based on the current value of - tree",
    "start": "2007460",
    "end": "2013669"
  },
  {
    "text": "so I managed to get through that in time which I was quite surprised about come",
    "start": "2013669",
    "end": "2019289"
  },
  {
    "text": "to our summary so hopefully I've convinced you that we can approach the",
    "start": "2019289",
    "end": "2024929"
  },
  {
    "text": "performance of hashmaps even though there's a little work to be done as we",
    "start": "2024929",
    "end": "2029940"
  },
  {
    "text": "mentioned the more space efficient the hash-table so that can be an advantage when you're dealing with particularly large data structures cop is a cheap and",
    "start": "2029940",
    "end": "2037889"
  },
  {
    "text": "memory efficient particularly if they're non-modified copies there are basically just copying two integers and you can",
    "start": "2037889",
    "end": "2044820"
  },
  {
    "text": "choose whether the old value persists or not you can hold multiple variations in",
    "start": "2044820",
    "end": "2051270"
  },
  {
    "text": "memory at once we didn't really delve into this but this is a really good practical use case I originally got into",
    "start": "2051270",
    "end": "2058800"
  },
  {
    "text": "this when I was dealing with financial data and we would have large object graphs of market data where we're going",
    "start": "2058800",
    "end": "2065819"
  },
  {
    "text": "to run scenarios on them so we actually take multiple copies and multiple dimensions of the whole graph and make small modifications and then you could",
    "start": "2065819",
    "end": "2072270"
  },
  {
    "text": "have mostly shared common state between them we couldn't do that all in memory before we have these sort of",
    "start": "2072270",
    "end": "2078329"
  },
  {
    "text": "implementations and there's many other use cases like that unless we touched on at the end can be made to work nicely",
    "start": "2078329",
    "end": "2084690"
  },
  {
    "text": "with concurrency by default if you use the Atomics if you haven't got a lot of",
    "start": "2084690",
    "end": "2091079"
  },
  {
    "text": "contention on the writes then that can work really really nicely if you have then you might need to use locks around",
    "start": "2091079",
    "end": "2096720"
  },
  {
    "text": "that but you get the choice so there the the benefits and that's me there's a",
    "start": "2096720",
    "end": "2106819"
  },
  {
    "text": "list of references on my website a level of indirection com if you can't remember",
    "start": "2106819",
    "end": "2113310"
  },
  {
    "text": "that I've also got extra level of indirection comm and that redirects there slash storage slash hampt rats to",
    "start": "2113310",
    "end": "2121230"
  },
  {
    "text": "HTML so it includes my reference implementation another one that's come up since the previous talks on the",
    "start": "2121230",
    "end": "2128490"
  },
  {
    "text": "subject and some papers so a lot there to to pick out or you can cache me on on",
    "start": "2128490",
    "end": "2133890"
  },
  {
    "text": "Twitter so thanks very much for listening [Applause]",
    "start": "2133890",
    "end": "2140650"
  },
  {
    "text": "[Music]",
    "start": "2140650",
    "end": "2143779"
  }
]
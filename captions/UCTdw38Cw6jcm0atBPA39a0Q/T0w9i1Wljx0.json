[
  {
    "text": "all right hello thank you all for coming today we're so happy to have you here um",
    "start": "5120",
    "end": "10400"
  },
  {
    "text": "it was quite the keynote to get everyone started this morning I definitely would not want to read um crashing and burning",
    "start": "10400",
    "end": "17439"
  },
  {
    "text": "learning how to fly a plane for dummies for those of you who are watching our stream we're happy to have you here as",
    "start": "17439",
    "end": "24240"
  },
  {
    "text": "well so my name is Allison kette I work for neo4j and I'm here to talk to you",
    "start": "24240",
    "end": "30400"
  },
  {
    "text": "today about life beyond the vector so just to figure out who's in our audience",
    "start": "30400",
    "end": "35960"
  },
  {
    "text": "is anybody here currently working with Vector databases at all a little a little um anyone ever",
    "start": "35960",
    "end": "43800"
  },
  {
    "text": "work with a graph database all right good to know um is",
    "start": "43800",
    "end": "49199"
  },
  {
    "text": "there anyone working on rag applications at this point a few all right so you're",
    "start": "49199",
    "end": "54520"
  },
  {
    "text": "all in the right place so that's good so what we're going to do today is first we're going to talk a little bit about",
    "start": "54520",
    "end": "60519"
  },
  {
    "text": "graph rag which is retrieval augmented generation with graph we're going to talk to you about how to produce an",
    "start": "60519",
    "end": "67400"
  },
  {
    "text": "optimal data set for that rag application we'll show you a little bit about um actually logging your",
    "start": "67400",
    "end": "74600"
  },
  {
    "text": "interactions and the value that can come from that as well as ways that you can use data science any data scientists in",
    "start": "74600",
    "end": "81200"
  },
  {
    "text": "the room no or oh a few there we are they're down in the middle um but also",
    "start": "81200",
    "end": "87200"
  },
  {
    "text": "how you can leverage your current data science staff to help help you produce positive and good outcomes with your",
    "start": "87200",
    "end": "94399"
  },
  {
    "text": "applications so just as an overview the grounding and retrieval in your",
    "start": "94399",
    "end": "100560"
  },
  {
    "text": "grounding and retrieval augmented generation so we'll dive into this in detail but for those of you who may not",
    "start": "100560",
    "end": "106920"
  },
  {
    "text": "be working with rag applications roughly what we're looking to try to understand is when we're working with our say your",
    "start": "106920",
    "end": "115560"
  },
  {
    "text": "chat GPT so right now you have a user prompt right everyone everyone okay",
    "start": "115560",
    "end": "121280"
  },
  {
    "text": "everyone here is used chat GPT or something similar I assume yes okay so",
    "start": "121280",
    "end": "127719"
  },
  {
    "text": "um you put in the prompt the Gen application whichever one you prefer",
    "start": "127719",
    "end": "133440"
  },
  {
    "text": "gives you an answer and you get a response but what retrieval augmented",
    "start": "133440",
    "end": "139080"
  },
  {
    "text": "generation does is it takes your response and then it hits an external database to ground that response so",
    "start": "139080",
    "end": "146800"
  },
  {
    "text": "rather than using a general language mod model which is what these are meant to be we want to actually improve the",
    "start": "146800",
    "end": "153760"
  },
  {
    "text": "information and have it grounded in something specific to you and specific to your use case to get a better",
    "start": "153760",
    "end": "160280"
  },
  {
    "text": "response so what happens is the information from the data set is added",
    "start": "160280",
    "end": "165519"
  },
  {
    "text": "to that context of your original prompt and then it produces a new answer from",
    "start": "165519",
    "end": "170840"
  },
  {
    "text": "the llm so the question is what do you want to actually use for that external",
    "start": "170840",
    "end": "176840"
  },
  {
    "text": "database you can have something right now going from this unstructured set and",
    "start": "176840",
    "end": "182400"
  },
  {
    "text": "you create the vectors so the vectors are the embedding which is a numerical representation of that unstructured data",
    "start": "182400",
    "end": "190200"
  },
  {
    "text": "but when you use a Knowledge Graph and you use a graph database you can bring in additional context to that answer so",
    "start": "190200",
    "end": "198519"
  },
  {
    "text": "you can bring in some relational database you could sorry you could bring in your structured data you could bring",
    "start": "198519",
    "end": "204400"
  },
  {
    "text": "in semi-structured data and what we are looking to do is to really add to that",
    "start": "204400",
    "end": "210640"
  },
  {
    "text": "experience of what is coming out in that response so what I want to talk to you a",
    "start": "210640",
    "end": "216599"
  },
  {
    "text": "little bit about first is what actually is a graph database and how does that work so nodes really represent entities",
    "start": "216599",
    "end": "225360"
  },
  {
    "text": "in a graph so we can have a person another person and a car in this case",
    "start": "225360",
    "end": "231519"
  },
  {
    "text": "there are relationships in and among these entities these two people may know each other they may live with each other",
    "start": "231519",
    "end": "239439"
  },
  {
    "text": "and one may drive the car and one may own the car so the relationships",
    "start": "239439",
    "end": "244640"
  },
  {
    "text": "represent these associations between and among each of these",
    "start": "244640",
    "end": "250200"
  },
  {
    "text": "entities each one of these nodes or relationships can also have properties",
    "start": "250200",
    "end": "255760"
  },
  {
    "text": "associated with them so in this case uh Andre and Micah own a",
    "start": "255760",
    "end": "261840"
  },
  {
    "text": "Volvo with a V70 so the in interesting thing here is that the the information",
    "start": "261840",
    "end": "268919"
  },
  {
    "text": "about the no and about these relationships are actually properties inside",
    "start": "268919",
    "end": "274639"
  },
  {
    "text": "those so when we think about vectors and we're looking at how we're actually",
    "start": "274639",
    "end": "279880"
  },
  {
    "text": "indexing them you can use in this case neo4j but what you want to be able to",
    "start": "279880",
    "end": "285240"
  },
  {
    "text": "make sure is that you can actually index and search and so we have different ways",
    "start": "285240",
    "end": "290600"
  },
  {
    "text": "within our format that you can actually use this General indexing you can use",
    "start": "290600",
    "end": "296120"
  },
  {
    "text": "geospatial points um and you can use text which is ultimately what we're talking about in our retrieval augmented",
    "start": "296120",
    "end": "302479"
  },
  {
    "text": "generation today so I'm going to talk to you today specifically about one",
    "start": "302479",
    "end": "308759"
  },
  {
    "text": "instance that we built which is something called Agent Neo so in agent",
    "start": "308759",
    "end": "314720"
  },
  {
    "text": "Neo what we wanted to be able to do is we found that um Chad GPT and others",
    "start": "314720",
    "end": "320600"
  },
  {
    "text": "were very good at some general information but specifically for our graph data science we are having a folks",
    "start": "320600",
    "end": "327479"
  },
  {
    "text": "are having a harder time getting answers because people don't go to llms Just for",
    "start": "327479",
    "end": "333319"
  },
  {
    "text": "translation they go to them for information so how do we give that information back so in our case we built",
    "start": "333319",
    "end": "340520"
  },
  {
    "text": "agent Neo and it's an llm application that was built spe specifically to",
    "start": "340520",
    "end": "346160"
  },
  {
    "text": "answer graph data science questions we went through and we grounded it in our",
    "start": "346160",
    "end": "352560"
  },
  {
    "text": "documentation as well as some Community Information and we built a basic streamlet app with Lang chain and we",
    "start": "352560",
    "end": "359919"
  },
  {
    "text": "logged the conversations in the same graph database and we'll talk about that a little bit um the code for this is all",
    "start": "359919",
    "end": "367319"
  },
  {
    "text": "available online in GitHub it's all open source so if it's something that you're interested in building for yourself with",
    "start": "367319",
    "end": "374039"
  },
  {
    "text": "your documentation you can certainly do that if you have questions you can ask me afterwards as",
    "start": "374039",
    "end": "380400"
  },
  {
    "text": "well so what did we actually use we Ed the entirety of the neo4j documentation",
    "start": "380400",
    "end": "387240"
  },
  {
    "text": "we used the developer blogs and our support knowledge base as well as our",
    "start": "387240",
    "end": "392840"
  },
  {
    "text": "GitHub so all of the code itself as well as the documentation of that code and",
    "start": "392840",
    "end": "398000"
  },
  {
    "text": "any discussion around that code either in community or in the blogs are all added in we then created the chunks that",
    "start": "398000",
    "end": "406240"
  },
  {
    "text": "were approximately not approximately definitely a chunk size of 512 we used",
    "start": "406240",
    "end": "412080"
  },
  {
    "text": "Lang chain recursive text splitter and then we use the embeddings in our case we use",
    "start": "412080",
    "end": "418120"
  },
  {
    "text": "gcp so when we think about this data and we wanted to go through and figure out",
    "start": "418120",
    "end": "424160"
  },
  {
    "text": "how do we create the highest quality data that can go into this",
    "start": "424160",
    "end": "429599"
  },
  {
    "text": "application so obviously it's really important that we have this highquality",
    "start": "429599",
    "end": "434800"
  },
  {
    "text": "output but a lot of times what folks are struggling with is they're new to building these applications and we say",
    "start": "434800",
    "end": "441560"
  },
  {
    "text": "let's just take everything we have and we're going to put it all in and we're going to get a great answer but what we",
    "start": "441560",
    "end": "447360"
  },
  {
    "text": "want to share with you today is is we have these five elements of highquality",
    "start": "447360",
    "end": "453479"
  },
  {
    "text": "grounding it needs to be relevant and it needs so obviously you want to have a relevant answer to what",
    "start": "453479",
    "end": "460479"
  },
  {
    "text": "your question is and in we want it to augment we want to bring something to",
    "start": "460479",
    "end": "465560"
  },
  {
    "text": "the response that is not going to be in the natural language of the llm to begin with you need those outputs obviously to",
    "start": "465560",
    "end": "473000"
  },
  {
    "text": "be reliable the health of and success of your application is certainly not going",
    "start": "473000",
    "end": "478280"
  },
  {
    "text": "to do very well if the answers are not reliable you want that data to be clean",
    "start": "478280",
    "end": "484520"
  },
  {
    "text": "and you want it to be efficient so we're going to talk through a few different ways that you can build this data set or",
    "start": "484520",
    "end": "490919"
  },
  {
    "text": "refine the data set that you may have to improve the output of your rag",
    "start": "490919",
    "end": "496919"
  },
  {
    "text": "applications so one of the things that you can do is and the data scientists in the room are familiar with Eda which is",
    "start": "496919",
    "end": "503960"
  },
  {
    "text": "your exploratory data analysis what's in your data to begin with how do we",
    "start": "503960",
    "end": "509840"
  },
  {
    "text": "understand what we've made available to this rag application in our case",
    "start": "509840",
    "end": "515000"
  },
  {
    "text": "obviously we work with graph and so what we wanted to be able to do was to leverage what's possible with graph to",
    "start": "515000",
    "end": "522159"
  },
  {
    "text": "inform that exploratory data analysis so one of the things that we did first was",
    "start": "522159",
    "end": "527600"
  },
  {
    "text": "to create a knnn similarity it's similar you know for here under the hood if you",
    "start": "527600",
    "end": "533080"
  },
  {
    "text": "want to know it's actually cosine similarity that's running KN andn here and we wanted to create relationships",
    "start": "533080",
    "end": "539000"
  },
  {
    "text": "among the the most similar documents what this allows us to do is then leverage additional algorithms such as",
    "start": "539000",
    "end": "546040"
  },
  {
    "text": "Community detection and centrality to understand of these documents do we have",
    "start": "546040",
    "end": "552600"
  },
  {
    "text": "similarities do we have clusters of documents and are there certain documents that are more important and",
    "start": "552600",
    "end": "558560"
  },
  {
    "text": "have a higher what we call centrality or a rank within those groups we use this",
    "start": "558560",
    "end": "564720"
  },
  {
    "text": "to capture and document the node embeddings so just like we have a text",
    "start": "564720",
    "end": "569880"
  },
  {
    "text": "embedding you can also have a node embedding and the node embedding is the vector that represents the node itself",
    "start": "569880",
    "end": "577160"
  },
  {
    "text": "and the additional items that it's related to within the graph so what this",
    "start": "577160",
    "end": "582880"
  },
  {
    "text": "allows us to do eventually is it allows us to curate this set and create",
    "start": "582880",
    "end": "588279"
  },
  {
    "text": "techniques that work at scale so what does that actually mean when we're trying to look at it so this may look a",
    "start": "588279",
    "end": "595800"
  },
  {
    "text": "little bit there's a lot going on it looks a little bit like a kids serial bowl of my children's cereal but what we",
    "start": "595800",
    "end": "602200"
  },
  {
    "text": "want to understand is we when we think about vectors right we think about you",
    "start": "602200",
    "end": "607800"
  },
  {
    "text": "know in open AI it's over 1500 parameters and just like in The Matrix",
    "start": "607800",
    "end": "613480"
  },
  {
    "text": "when you're looking at ones and zeros and you're looking at numbers they don't necessarily have meaning to you and so",
    "start": "613480",
    "end": "619440"
  },
  {
    "text": "what we wanted to be able to do was to take that high dimensionality and flatten it out and say when I try to",
    "start": "619440",
    "end": "626600"
  },
  {
    "text": "understand what's in my Vector database so so this is a 2d representation of",
    "start": "626600",
    "end": "632200"
  },
  {
    "text": "what's in the database itself we went through and ran Community detection to",
    "start": "632200",
    "end": "637560"
  },
  {
    "text": "understand the clustering and the groups of documents that we had the size also",
    "start": "637560",
    "end": "642920"
  },
  {
    "text": "represents the content page rank or its importance so how connected is it to",
    "start": "642920",
    "end": "649360"
  },
  {
    "text": "other nodes how does it fit within that space because ultimately right now when",
    "start": "649360",
    "end": "655600"
  },
  {
    "text": "you're looking at vectors like I said they don't jump off the page they don't necessarily mean anything and so you",
    "start": "655600",
    "end": "662160"
  },
  {
    "text": "want to really understand what is it that we actually have in this data",
    "start": "662160",
    "end": "668079"
  },
  {
    "text": "set and so you might say Allison well this is all well and good and it's a lot of colors but how do I use it what does",
    "start": "668079",
    "end": "674000"
  },
  {
    "text": "it mean to me so we zoomed in on a couple of different aspects of this",
    "start": "674000",
    "end": "679519"
  },
  {
    "text": "particular um visualization and what you see on the left hand side is you have a",
    "start": "679519",
    "end": "684920"
  },
  {
    "text": "single Community document cluster CU they're all by color and there's a lot of documents sitting on top of each",
    "start": "684920",
    "end": "691440"
  },
  {
    "text": "other you see that the the size is a little larger so that means that they're highly connected to each other and on",
    "start": "691440",
    "end": "698560"
  },
  {
    "text": "the right hand side we see a clustering of sort of overlapping communities and they're not really distinct and they",
    "start": "698560",
    "end": "704720"
  },
  {
    "text": "have a lot of you know different Community colors and so when you think about what is in your database and if",
    "start": "704720",
    "end": "712399"
  },
  {
    "text": "you think about the vectors that are representing those do you imagine one of",
    "start": "712399",
    "end": "717800"
  },
  {
    "text": "or the other of these is going to give you a better outcome so who here thinks",
    "start": "717800",
    "end": "722920"
  },
  {
    "text": "having a lot of similar documents like really close to each other is going to give a good outcome and how many folks",
    "start": "722920",
    "end": "729959"
  },
  {
    "text": "think that are widespread so who thinks that widespread documents are going to",
    "start": "729959",
    "end": "735320"
  },
  {
    "text": "perform better any guesses lots of documents sitting on top",
    "start": "735320",
    "end": "740839"
  },
  {
    "text": "of each other that are pretty similar or I have no idea I've never",
    "start": "740839",
    "end": "745880"
  },
  {
    "text": "seen this before how could you possibly ask me that question all right option three yes we're what we're talking about",
    "start": "745880",
    "end": "753079"
  },
  {
    "text": "is something that as developers you may not have seen as much but one thing that you can do and this is just a side note",
    "start": "753079",
    "end": "759959"
  },
  {
    "text": "look to the data scientists on your team to really help you dive into this and use this and understand what's going on",
    "start": "759959",
    "end": "767720"
  },
  {
    "text": "in your data sets so to answer the question for you there's a case to be",
    "start": "767720",
    "end": "773040"
  },
  {
    "text": "made for either and we're going to walk through these as we go through so when",
    "start": "773040",
    "end": "778480"
  },
  {
    "text": "we again we're still talking about exploring the data that we have what we did is we went through and created these",
    "start": "778480",
    "end": "784760"
  },
  {
    "text": "communities of the documents so the the ones that are most similar are all grouped together and so then we say okay",
    "start": "784760",
    "end": "791519"
  },
  {
    "text": "let's just look at them right we look at we know that we have a text Chunk of 512",
    "start": "791519",
    "end": "797639"
  },
  {
    "text": "characters and then we did some basic statistics so what's the median average word length well we clearly see in",
    "start": "797639",
    "end": "805360"
  },
  {
    "text": "community 7117 not that I'm sure exactly what's in it is we see that the average",
    "start": "805360",
    "end": "810760"
  },
  {
    "text": "word length is 512 and so you want to understand just some basic QA of what",
    "start": "810760",
    "end": "816760"
  },
  {
    "text": "the data is and has your chunker worked well and what we found when we do dove",
    "start": "816760",
    "end": "822399"
  },
  {
    "text": "into this and we looked at those is we can see these large like jsons of",
    "start": "822399",
    "end": "828079"
  },
  {
    "text": "information that probably aren't going to give our users pretty good outputs so",
    "start": "828079",
    "end": "833199"
  },
  {
    "text": "this is a way that you can go through and clean some of the data that's in your rag application cuz when you're",
    "start": "833199",
    "end": "839199"
  },
  {
    "text": "building a rag application usually you're coming up with a certain number of relevant documents right you might",
    "start": "839199",
    "end": "846519"
  },
  {
    "text": "say okay go into the data set and return the five most similar values similar um",
    "start": "846519",
    "end": "854199"
  },
  {
    "text": "Vector to the prompt and use that to augment but if the five most similar",
    "start": "854199",
    "end": "861480"
  },
  {
    "text": "happen to be an odd Json that's not really going to give you a better answer so this is one opportunity you have to",
    "start": "861480",
    "end": "868320"
  },
  {
    "text": "clean your data dat set the other thing that we want to look at is highly similar text chunks so what",
    "start": "868320",
    "end": "876600"
  },
  {
    "text": "we're talking about here is that one on the left where we had the community",
    "start": "876600",
    "end": "881680"
  },
  {
    "text": "where those documents were very similar and they were highly connected one of",
    "start": "881680",
    "end": "887120"
  },
  {
    "text": "the thing that's going to happen is that we wanted to look you see this First Column we've got the community number",
    "start": "887120",
    "end": "893880"
  },
  {
    "text": "and then we have the average similarity so we know we have this vector and we create that similarity score how similar",
    "start": "893880",
    "end": "901000"
  },
  {
    "text": "are these items to each other if all of the documents within that group are very",
    "start": "901000",
    "end": "907440"
  },
  {
    "text": "very similar there's a high likelihood that they're going to be redundant and again it goes back to in",
    "start": "907440",
    "end": "914560"
  },
  {
    "text": "your rag application you're pulling back a certain number of documents do I want",
    "start": "914560",
    "end": "921240"
  },
  {
    "text": "really the same documents so when we went in and looked at where we had that",
    "start": "921240",
    "end": "926519"
  },
  {
    "text": "high similarity you can see an example of what that text Chunk looked like",
    "start": "926519",
    "end": "932040"
  },
  {
    "text": "obviously when we're looking at documentation all of these come from our documentation and there's certain",
    "start": "932040",
    "end": "938079"
  },
  {
    "text": "information that you know is going to be on more than one page and in this case we're talking about what how similar",
    "start": "938079",
    "end": "945519"
  },
  {
    "text": "those are and so if I'm only bringing back a certain number of documents I",
    "start": "945519",
    "end": "950800"
  },
  {
    "text": "don't want all the same chunks to be used so then you're like okay El sudden",
    "start": "950800",
    "end": "955880"
  },
  {
    "text": "that's fine we've got all this redundancy how am I supposed to clean that up up what is the technique for doing that so when you store your uh",
    "start": "955880",
    "end": "964279"
  },
  {
    "text": "information in neo4j or in another graph database one of the things that you have",
    "start": "964279",
    "end": "969959"
  },
  {
    "text": "is we have a lot of flexibility so in this case we've got these individual documents and each one of the documents",
    "start": "969959",
    "end": "977240"
  },
  {
    "text": "has the URL of where we actually sourced it from and you could just take one if",
    "start": "977240",
    "end": "984639"
  },
  {
    "text": "you're let's just say you're in a traditional tabular database and you have all the rows you could say well",
    "start": "984639",
    "end": "990600"
  },
  {
    "text": "let's just keep the first one but when you do that you're going to lose the granularity of all the places that it's",
    "start": "990600",
    "end": "996480"
  },
  {
    "text": "connected to and so if you're using a graph database you can use just this one",
    "start": "996480",
    "end": "1001759"
  },
  {
    "text": "short piece of code node collapse and what it will take is it'll take all of those documents and make them one",
    "start": "1001759",
    "end": "1008199"
  },
  {
    "text": "occurrence but it'll maintain that original connection to each of those",
    "start": "1008199",
    "end": "1013240"
  },
  {
    "text": "URLs and so it's a good way to handle going from one to one to one to many so",
    "start": "1013240",
    "end": "1020480"
  },
  {
    "text": "that's one way that you can increase the efficiency so we've said okay we've got",
    "start": "1020480",
    "end": "1026880"
  },
  {
    "text": "this rag database we are before I go on does anybody have any questions so far I",
    "start": "1026880",
    "end": "1032400"
  },
  {
    "text": "know graph might be new for folks so I just want to make sure",
    "start": "1032400",
    "end": "1038039"
  },
  {
    "text": "yes yes so for those who are watching the stream the question is what are we using to calculate the similarity in",
    "start": "1041720",
    "end": "1048160"
  },
  {
    "text": "the4 graph data science we use KNN which is um K nearest neighbor similarity but",
    "start": "1048160",
    "end": "1054640"
  },
  {
    "text": "under the hood it is actually cosign that's running that algorithm so yeah good question thank",
    "start": "1054640",
    "end": "1061720"
  },
  {
    "text": "you so much anybody else all right we're good so one of the",
    "start": "1061720",
    "end": "1066799"
  },
  {
    "text": "other things we want to talk about is we want to talk about actually logging the conversation so we're at a point where",
    "start": "1066799",
    "end": "1072440"
  },
  {
    "text": "we've got a really good data set it's nice and tidy but what can we actually learn from logging the convers ations",
    "start": "1072440",
    "end": "1079320"
  },
  {
    "text": "with the llm so graphs enable explainable AI with your llms so what it",
    "start": "1079320",
    "end": "1087000"
  },
  {
    "text": "will allow us to do is we can actually say okay they we had this particular",
    "start": "1087000",
    "end": "1092280"
  },
  {
    "text": "question we went into the graph database when that question was asked we pulled",
    "start": "1092280",
    "end": "1098440"
  },
  {
    "text": "in these context documents and therefore this is what was referenced to produce a",
    "start": "1098440",
    "end": "1104520"
  },
  {
    "text": "particular answer and also with graphs some of the interesting things we can do",
    "start": "1104520",
    "end": "1110039"
  },
  {
    "text": "is that we can actually visualize the conversations with that context so we",
    "start": "1110039",
    "end": "1115679"
  },
  {
    "text": "can start to understand how are how are each of these vectors being",
    "start": "1115679",
    "end": "1121360"
  },
  {
    "text": "used so just so you know in the graph database we talked about the properties",
    "start": "1121360",
    "end": "1126679"
  },
  {
    "text": "inside of that node one of the properties is the text and the other property is the actual embedding so just",
    "start": "1126679",
    "end": "1132760"
  },
  {
    "text": "you know where that's coming from those are properties within that node so when we built agent Neo this is",
    "start": "1132760",
    "end": "1140840"
  },
  {
    "text": "the the data model so for those of you who are used to seeing erds with your relational database this is the graph",
    "start": "1140840",
    "end": "1147600"
  },
  {
    "text": "version so we can see all the way on the right hand side the document and the URL",
    "start": "1147600",
    "end": "1152960"
  },
  {
    "text": "which is that grounding that we have but additionally now we're going to talk about what happens when we actually add",
    "start": "1152960",
    "end": "1160679"
  },
  {
    "text": "the log of the conversation to it so someone will initiate a session which we",
    "start": "1160679",
    "end": "1166000"
  },
  {
    "text": "see all the way on the left that session will have a particular conversation and then there'll be a",
    "start": "1166000",
    "end": "1172799"
  },
  {
    "text": "series of messages so when that message is that prompt is put",
    "start": "1172799",
    "end": "1178000"
  },
  {
    "text": "in then it'll hit the database and those context documents will be returned and",
    "start": "1178000",
    "end": "1183799"
  },
  {
    "text": "so now we create a connection not just from the prompt to the response but also",
    "start": "1183799",
    "end": "1190640"
  },
  {
    "text": "what were the additional pieces of information that helped form that response and so that's what we're seeing",
    "start": "1190640",
    "end": "1196720"
  },
  {
    "text": "in the relationship has context between the center message node and the document",
    "start": "1196720",
    "end": "1203720"
  },
  {
    "text": "node questions on this",
    "start": "1203720",
    "end": "1207600"
  },
  {
    "text": "diagram right so this is what again like we said it's like the ER this is the",
    "start": "1208760",
    "end": "1214440"
  },
  {
    "text": "basic but what happens when we actually put it into practice so this is an",
    "start": "1214440",
    "end": "1219520"
  },
  {
    "text": "example of what that diagram would look like so we see the",
    "start": "1219520",
    "end": "1224600"
  },
  {
    "text": "session the in green then we have the conversation in or orange and that first",
    "start": "1224600",
    "end": "1230679"
  },
  {
    "text": "light pink is the actual first prompt in the conversation from the",
    "start": "1230679",
    "end": "1236200"
  },
  {
    "text": "user then what happens is the the llm will go through and you'll see these has",
    "start": "1236200",
    "end": "1243679"
  },
  {
    "text": "context so what has happened in this case is that this first pink node has a",
    "start": "1243679",
    "end": "1249400"
  },
  {
    "text": "prompt and so we say based on that prompt and the cosine similarity of the",
    "start": "1249400",
    "end": "1254840"
  },
  {
    "text": "retrieval it's connected to these darker pink dots documents each of them are an",
    "start": "1254840",
    "end": "1260720"
  },
  {
    "text": "individual document within the database we have them noted with the number of the community that they're in just for",
    "start": "1260720",
    "end": "1267840"
  },
  {
    "text": "ease of understanding and then we see that the person has a response to that",
    "start": "1267840",
    "end": "1274720"
  },
  {
    "text": "so just like you have a conversation with your chat GPT you put something in you get an answer you want to refine and",
    "start": "1274720",
    "end": "1281880"
  },
  {
    "text": "so then the the last one that we see is the followup to that second input from the user and what I want you to note is",
    "start": "1281880",
    "end": "1289720"
  },
  {
    "text": "that some of those documents those ones that are vertical in the middle are part of the answer for both of those",
    "start": "1289720",
    "end": "1297360"
  },
  {
    "text": "responses but we see that the ones that are only tied to the first one are no",
    "start": "1297360",
    "end": "1303240"
  },
  {
    "text": "longer relevant to that subsequent comment and the new ones on the right",
    "start": "1303240",
    "end": "1309360"
  },
  {
    "text": "that are only connected to that last pink node is where the conversation is going and so what you want to start to",
    "start": "1309360",
    "end": "1317400"
  },
  {
    "text": "see is you want to have an understanding of how is the application working where",
    "start": "1317400",
    "end": "1323640"
  },
  {
    "text": "is it going are we answering the questions that we want to answer and so",
    "start": "1323640",
    "end": "1329679"
  },
  {
    "text": "when we think of this from a developer perspective what it allows you to do is it allows you to see where is the",
    "start": "1329679",
    "end": "1336360"
  },
  {
    "text": "application hitting more or fewer documents eventually that will be put on",
    "start": "1336360",
    "end": "1341919"
  },
  {
    "text": "whomever is responsible for making sure those values are those answers are",
    "start": "1341919",
    "end": "1347200"
  },
  {
    "text": "appropriate but you you want to understand how do I un watch what's",
    "start": "1347200",
    "end": "1353159"
  },
  {
    "text": "going on in the actual application okay so this is where things get a",
    "start": "1353159",
    "end": "1360360"
  },
  {
    "text": "little bit a little bit heavier and more for the data scientists in the room but in this case what we've done is we've",
    "start": "1360360",
    "end": "1366799"
  },
  {
    "text": "taken the conversation and across the bottom we actually see the message",
    "start": "1366799",
    "end": "1371880"
  },
  {
    "text": "sequence and on the leftand side is the different communities of documents",
    "start": "1371880",
    "end": "1378720"
  },
  {
    "text": "and what we're seeing here is what is the it's the heat map right so the",
    "start": "1378720",
    "end": "1384480"
  },
  {
    "text": "darker it is um the higher the count of documents from that group and what we're",
    "start": "1384480",
    "end": "1391120"
  },
  {
    "text": "watching now is we're watching how the conversation moves over time across the",
    "start": "1391120",
    "end": "1397400"
  },
  {
    "text": "different bases of information that you have so we see that in the first couple of questions it's mostly these pieces in",
    "start": "1397400",
    "end": "1403919"
  },
  {
    "text": "the middle but then eventually the conversation starts spreading out into other areas of information other",
    "start": "1403919",
    "end": "1411000"
  },
  {
    "text": "communities of documents and this is just one conversation but what it what",
    "start": "1411000",
    "end": "1416760"
  },
  {
    "text": "you can see is you can also start to see where are conversations moving what is",
    "start": "1416760",
    "end": "1423279"
  },
  {
    "text": "actually happening one of the challenges that people have right now that we've seen when they have their rag",
    "start": "1423279",
    "end": "1429919"
  },
  {
    "text": "applications is how do I know what people are necessarily talking about you",
    "start": "1429919",
    "end": "1435840"
  },
  {
    "text": "can hit a particular Vector but by having this clustering in these groups and tracking this information you can",
    "start": "1435840",
    "end": "1442880"
  },
  {
    "text": "start to understand you can I've said that like nine times today I don't know what is happening with me with this phrase um what you see is you can see",
    "start": "1442880",
    "end": "1450559"
  },
  {
    "text": "where the conversations are going and it will give you more of some business Insight or some application Insight if",
    "start": "1450559",
    "end": "1458120"
  },
  {
    "text": "you see that a conversation is spreading really wide it could be an indication that there's a piece of information",
    "start": "1458120",
    "end": "1464679"
  },
  {
    "text": "that's missing somebody's going to a lot of different areas to try and get an answer and maybe that conversation is",
    "start": "1464679",
    "end": "1471399"
  },
  {
    "text": "really long and so then you can go back to your data set and say do we have a gap here so we want to be able to see",
    "start": "1471399",
    "end": "1480080"
  },
  {
    "text": "are people getting relevant answers questions on this image no",
    "start": "1480080",
    "end": "1489879"
  },
  {
    "text": "yes Ure that the context will not become too big so you get some kind of context",
    "start": "1491240",
    "end": "1496919"
  },
  {
    "text": "over because the in my understanding too B yes eventually",
    "start": "1496919",
    "end": "1502200"
  },
  {
    "text": "it can a lot of that's going to be depending on how you've built it and which um model you're using but it can",
    "start": "1502200",
    "end": "1509399"
  },
  {
    "text": "help you with that in in our case um I'll show you in just a second some some information about how long they go um",
    "start": "1509399",
    "end": "1516960"
  },
  {
    "text": "and that will be sort of in the way that depending on which model you're using but yes you can definitely get um like",
    "start": "1516960",
    "end": "1525080"
  },
  {
    "text": "spread of if you look look at the actual Vector",
    "start": "1525080",
    "end": "1530520"
  },
  {
    "text": "of that prompt that has that longer context in it but in this case what we're looking at is we're looking at the",
    "start": "1530520",
    "end": "1536720"
  },
  {
    "text": "actual context documents that were pulled in for each one of those responses and so while the overall",
    "start": "1536720",
    "end": "1543720"
  },
  {
    "text": "context might be larger the context documents that are being pulled in from the database for that particular answer",
    "start": "1543720",
    "end": "1551960"
  },
  {
    "text": "is going to be on a per prompt basis right so even if we see this one all the",
    "start": "1551960",
    "end": "1557399"
  },
  {
    "text": "way on the right it's in many different communities it's still going to have the same K being returned for that",
    "start": "1557399",
    "end": "1565440"
  },
  {
    "text": "particular response is that clear yeah awesome okay",
    "start": "1565440",
    "end": "1570520"
  },
  {
    "text": "anybody else cool all right so we've got the we've",
    "start": "1570520",
    "end": "1576640"
  },
  {
    "text": "got our rag database we've done some cleaning we've done some understanding we've looked for some redundancies and",
    "start": "1576640",
    "end": "1584080"
  },
  {
    "text": "what we want to do now is now that we're tracking that conversation how how do we how do we use it how is that going to be",
    "start": "1584080",
    "end": "1590760"
  },
  {
    "text": "helpful for us so um we have something where especially for those who are new",
    "start": "1590760",
    "end": "1596279"
  },
  {
    "text": "to graph when we think about the conversation the conversation itself is a graph it's a series of one point to",
    "start": "1596279",
    "end": "1603679"
  },
  {
    "text": "another and so if you're interested in using the logging we actually have something that's Neo Dash where you can",
    "start": "1603679",
    "end": "1610600"
  },
  {
    "text": "do natural language to um like charting so if this is new for you they're sort",
    "start": "1610600",
    "end": "1617000"
  },
  {
    "text": "of lower barrier ways to get some of these analytics available to you so one of the things that you want",
    "start": "1617000",
    "end": "1624080"
  },
  {
    "text": "to look at is you want to start by looking at what is the conversation length as expected it's going to have a",
    "start": "1624080",
    "end": "1629720"
  },
  {
    "text": "long tail on it most of our conversations seem you know a few prompts and responses and that means for",
    "start": "1629720",
    "end": "1635760"
  },
  {
    "text": "us we're working specifically with our users where we want them to get the answer relatively quickly right they've",
    "start": "1635760",
    "end": "1642480"
  },
  {
    "text": "come to this particular use case because they have a question about graph data science and we want them to get the",
    "start": "1642480",
    "end": "1648520"
  },
  {
    "text": "answer and move on so when we see these longer conversations those are ones that",
    "start": "1648520",
    "end": "1653919"
  },
  {
    "text": "you'll want to dive into was someone realizing that they wanted to go",
    "start": "1653919",
    "end": "1659679"
  },
  {
    "text": "into another direction or did it take them a really long time to get the answer they were looking",
    "start": "1659679",
    "end": "1666679"
  },
  {
    "text": "for um this one has to do with the response time so we also looked at what those response times are for each as the",
    "start": "1666760",
    "end": "1674799"
  },
  {
    "text": "as the conversations got longer obviously we see the the times get longer mostly because of the context",
    "start": "1674799",
    "end": "1681919"
  },
  {
    "text": "window as we said and so it makes sense that those will increase over time but",
    "start": "1681919",
    "end": "1687600"
  },
  {
    "text": "different things will affect that your limit your context window conversation memory",
    "start": "1687600",
    "end": "1693919"
  },
  {
    "text": "Etc so what does it mean to have all these items and how can we actually get",
    "start": "1694159",
    "end": "1700880"
  },
  {
    "text": "better at using this graph-based analysis of these context documents so",
    "start": "1700880",
    "end": "1706799"
  },
  {
    "text": "like we said before in each conversation and in each message there is a context",
    "start": "1706799",
    "end": "1712320"
  },
  {
    "text": "document attachment based on that use and so by logging these conversations",
    "start": "1712320",
    "end": "1718799"
  },
  {
    "text": "you can now start to look at the structure of the graph to understand how are people moving around so in this case",
    "start": "1718799",
    "end": "1726880"
  },
  {
    "text": "the um the dark red is the actual response and the light pink are the",
    "start": "1726880",
    "end": "1732519"
  },
  {
    "text": "context documents that came in and we can see that there's a few questions say",
    "start": "1732519",
    "end": "1737640"
  },
  {
    "text": "on the outer edges right so we see these where they're sort of the the satellite pieces in those in in those situations",
    "start": "1737640",
    "end": "1746279"
  },
  {
    "text": "what we're seeing is those context documents came into this one response but what we see in the center is there's",
    "start": "1746279",
    "end": "1752120"
  },
  {
    "text": "a lot more interconnection and so this is telling us that these conversations here are",
    "start": "1752120",
    "end": "1757360"
  },
  {
    "text": "repeated conversations these are the documents that are being hit more often",
    "start": "1757360",
    "end": "1762919"
  },
  {
    "text": "and so when you're looking at a graph I always encourage you to look at it with what I call called the soft eye which",
    "start": "1762919",
    "end": "1769919"
  },
  {
    "text": "means don't go into too much detail about what's in there but what is the shape telling you right if we had one",
    "start": "1769919",
    "end": "1777399"
  },
  {
    "text": "cluster and another cluster it's going to tell us that there's two areas where people are asking questions most likely",
    "start": "1777399",
    "end": "1784880"
  },
  {
    "text": "and then some of the things that are on the Outer Edge they're not a more they're not the most common questions",
    "start": "1784880",
    "end": "1789919"
  },
  {
    "text": "and not the most common context documents so again the soft eye can be",
    "start": "1789919",
    "end": "1795320"
  },
  {
    "text": "really helpful in seeing those natural clusters and giving you an a visual",
    "start": "1795320",
    "end": "1800760"
  },
  {
    "text": "understanding of what how folks are working with your application so one of the things that we",
    "start": "1800760",
    "end": "1807679"
  },
  {
    "text": "looked at to see if we were getting relevant context is we wanted to see what were the most frequently used",
    "start": "1807679",
    "end": "1813360"
  },
  {
    "text": "documents for us we see degree centrality which is um a big question",
    "start": "1813360",
    "end": "1819240"
  },
  {
    "text": "and then the actual connectors so centrality is one of the most common algorithms that folks use and how good",
    "start": "1819240",
    "end": "1826799"
  },
  {
    "text": "is a database if you can't get your information into it so the connectors are a really important piece and this",
    "start": "1826799",
    "end": "1832279"
  },
  {
    "text": "makes sense right the other thing that we looked at is we looked at the frequency of the",
    "start": "1832279",
    "end": "1838559"
  },
  {
    "text": "communities of information obviously it makes sense that the top one is our",
    "start": "1838559",
    "end": "1844159"
  },
  {
    "text": "documentation most of the answers if you're looking for something are hopefully in our documentation if",
    "start": "1844159",
    "end": "1849360"
  },
  {
    "text": "they're not we have a much bigger problem there are some people we need to talk to and then the second most",
    "start": "1849360",
    "end": "1855399"
  },
  {
    "text": "frequent one that we had was actually the blogs from tamas bratanic who's one",
    "start": "1855399",
    "end": "1860840"
  },
  {
    "text": "of our um experts and if anybody's ever read any of uh our llm and gen work",
    "start": "1860840",
    "end": "1867039"
  },
  {
    "text": "you'll definitely have read his pieces so that's not necessarily a surprise to us either but again it's not just enough",
    "start": "1867039",
    "end": "1874799"
  },
  {
    "text": "to have a database for your rag application it's important to look into",
    "start": "1874799",
    "end": "1880399"
  },
  {
    "text": "how is it being used what are people seeing so the next thing that we can",
    "start": "1880399",
    "end": "1887399"
  },
  {
    "text": "also look at is we can also look at the actual responses so this is where we",
    "start": "1887399",
    "end": "1893360"
  },
  {
    "text": "take the next step so initially we had each of those responses connected to the",
    "start": "1893360",
    "end": "1898799"
  },
  {
    "text": "context documents but now we can start to say how do the responses relate to each other and we can run similarity on",
    "start": "1898799",
    "end": "1907039"
  },
  {
    "text": "those responses so again let's take the next step we got these series of responses",
    "start": "1907039",
    "end": "1914760"
  },
  {
    "text": "are they very similar are we getting the same kinds of answers are people working",
    "start": "1914760",
    "end": "1920600"
  },
  {
    "text": "in one particular area so we can see on the right hand side here we have each of",
    "start": "1920600",
    "end": "1925960"
  },
  {
    "text": "the responses and we've created again this similarity the cosine similarity",
    "start": "1925960",
    "end": "1931080"
  },
  {
    "text": "between these responses one of the ways that this can be helpful to you as a",
    "start": "1931080",
    "end": "1936320"
  },
  {
    "text": "developer is you can look to say if there are common responses can we actually use the",
    "start": "1936320",
    "end": "1943760"
  },
  {
    "text": "predefined responses or that response area so that we can optimize the speed",
    "start": "1943760",
    "end": "1949760"
  },
  {
    "text": "with which we can respond if we know that we've got a cluster of responses that are very similar do you want to",
    "start": "1949760",
    "end": "1957639"
  },
  {
    "text": "potentially preed some of those into your application to have those answers",
    "start": "1957639",
    "end": "1962799"
  },
  {
    "text": "already generated so it's just something to consider but this allows you to look",
    "start": "1962799",
    "end": "1967919"
  },
  {
    "text": "and see are we getting consistent answers and how can we leverage these in",
    "start": "1967919",
    "end": "1973440"
  },
  {
    "text": "other ways now just like we had our 2D viewing of the context documents now we're",
    "start": "1973440",
    "end": "1981159"
  },
  {
    "text": "looking at the 2D view of these responses and so initially we didn't",
    "start": "1981159",
    "end": "1986240"
  },
  {
    "text": "want a lot of redundant documents where we have those High those clusters of information but in this case we actually",
    "start": "1986240",
    "end": "1993399"
  },
  {
    "text": "do want them to be very similar we want to get a similar response when people",
    "start": "1993399",
    "end": "1999559"
  },
  {
    "text": "ask similar questions we want to have that consistency of output so that the user",
    "start": "1999559",
    "end": "2006679"
  },
  {
    "text": "experience is going to be reliable it's going to be clean and it's going to be",
    "start": "2006679",
    "end": "2013440"
  },
  {
    "text": "relevant this is telling us that we've got these areas of understanding of what",
    "start": "2013440",
    "end": "2019200"
  },
  {
    "text": "people are getting back as information and again this is an interesting way",
    "start": "2019200",
    "end": "2024360"
  },
  {
    "text": "this is where you hand it off to your product people if you if it's a product rag application or your marketing folks",
    "start": "2024360",
    "end": "2030480"
  },
  {
    "text": "if it's uh you know consumer product information and you can say these are the kinds of answers that people are",
    "start": "2030480",
    "end": "2036320"
  },
  {
    "text": "getting this is the documents that we're hitting and then they can go and do what they do with it but as developers what",
    "start": "2036320",
    "end": "2043279"
  },
  {
    "text": "we want to see is we want to see this consistency with these",
    "start": "2043279",
    "end": "2049358"
  },
  {
    "text": "responses all right so we can look at these communities of responses and now we can",
    "start": "2049359",
    "end": "2056839"
  },
  {
    "text": "start looking at then you'll see all the way on the edge we've got the ratings so for this community of responses that we",
    "start": "2056839",
    "end": "2063800"
  },
  {
    "text": "had were people satisfied with those answers right we can see you know Community",
    "start": "2063800",
    "end": "2072839"
  },
  {
    "text": "14725 we've got 15 good ratings and only two bad ones that's not so bad but when",
    "start": "2072839",
    "end": "2078158"
  },
  {
    "text": "we look at the second row or the bottom row the numbers are not as good we're getting kind of met answers and this is",
    "start": "2078159",
    "end": "2085000"
  },
  {
    "text": "another way to say what is that response look like and then you go to those",
    "start": "2085000",
    "end": "2090599"
  },
  {
    "text": "context documents and you can say what is it that's not in the data that people need they're not getting the answer they",
    "start": "2090599",
    "end": "2098040"
  },
  {
    "text": "want how does it relate to the specific context document how does it relate to",
    "start": "2098040",
    "end": "2104040"
  },
  {
    "text": "the response that they're getting and how can we improve the underlying data",
    "start": "2104040",
    "end": "2109240"
  },
  {
    "text": "set in order to get a better output and a better experience because it's not",
    "start": "2109240",
    "end": "2114680"
  },
  {
    "text": "just enough to get an answer we want to make sure that we're giving the right answer and that we don't have holes in",
    "start": "2114680",
    "end": "2121760"
  },
  {
    "text": "our data set that's one of the most common things that I've seen that people",
    "start": "2121760",
    "end": "2126839"
  },
  {
    "text": "don't necessarily realize when they're putting their data in is really figuring out when something is missing and this",
    "start": "2126839",
    "end": "2133960"
  },
  {
    "text": "is a really good way to go about finding those holes in your data",
    "start": "2133960",
    "end": "2140000"
  },
  {
    "text": "sets um we looked at the the pages with the highest page rank score page rank score means how important is this and",
    "start": "2140000",
    "end": "2147160"
  },
  {
    "text": "how relevant is this within that document um and these are on a couple of things they happen to be GDs Network X",
    "start": "2147160",
    "end": "2155240"
  },
  {
    "text": "for any of the data scientists in the room was probably the first graph you ever used in Python um and our pytorch",
    "start": "2155240",
    "end": "2161720"
  },
  {
    "text": "so ultimately what we want to say is that this grounding with the graph allows you to do a few things one it's",
    "start": "2161720",
    "end": "2168319"
  },
  {
    "text": "going to give you better answers and two it's going to allow you to dive into the",
    "start": "2168319",
    "end": "2174839"
  },
  {
    "text": "data that you have and build something that's not going to be good just for today but is also going to help you",
    "start": "2174839",
    "end": "2182119"
  },
  {
    "text": "build something that can be maintained because ultimately that's what we're looking for we want want to have a way",
    "start": "2182119",
    "end": "2188560"
  },
  {
    "text": "that we can actually dive in and maintain the applications that we are",
    "start": "2188560",
    "end": "2193599"
  },
  {
    "text": "using um does anybody want to see what some of this looks like anyone yes all",
    "start": "2193599",
    "end": "2199200"
  },
  {
    "text": "right um officially this is the the end of the talk for now um but what I want",
    "start": "2199200",
    "end": "2204839"
  },
  {
    "text": "to be able to do is show you a couple of the things that we have here so um we",
    "start": "2204839",
    "end": "2212520"
  },
  {
    "text": "have uh this is we've got a few different demos that you can look at this one happens to be um using SEC data",
    "start": "2212520",
    "end": "2221839"
  },
  {
    "text": "which is uh the like filings with the New York Stock Exchange when you have",
    "start": "2221839",
    "end": "2227720"
  },
  {
    "text": "items so in this particular case we can see that we've got a company which did",
    "start": "2227720",
    "end": "2232800"
  },
  {
    "text": "had a filing that that company might be owned by an asset manager so here",
    "start": "2232800",
    "end": "2238400"
  },
  {
    "text": "manager means asset manager and asset managers own many different um stocks",
    "start": "2238400",
    "end": "2243880"
  },
  {
    "text": "and then each of those may have an address and so what we want to think think about is when we're building a rag",
    "start": "2243880",
    "end": "2249800"
  },
  {
    "text": "application with just vectors and we're hitting those that's all we can get we get that Chunk we get that Vector that's",
    "start": "2249800",
    "end": "2256400"
  },
  {
    "text": "all that comes back but when you're using a graph what it will allow you to do is you're going to come up to that",
    "start": "2256400",
    "end": "2263480"
  },
  {
    "text": "chunk of that document based on that cosine similarity but then you can add in additional pieces within your",
    "start": "2263480",
    "end": "2270640"
  },
  {
    "text": "application that says okay when I hit that chunk I want to also bring in",
    "start": "2270640",
    "end": "2275880"
  },
  {
    "text": "information about the company that that filing was for and potentially any asset managers that own that and so what we",
    "start": "2275880",
    "end": "2283760"
  },
  {
    "text": "have here is we're looking at some of the answers um so if we're looking at uh",
    "start": "2283760",
    "end": "2289599"
  },
  {
    "text": "this question is which asset managers are impacted by lithium storage and let me see we'll run this",
    "start": "2289599",
    "end": "2296680"
  },
  {
    "text": "for you this just shows you what's in here um any of the demos that we're",
    "start": "2296680",
    "end": "2301720"
  },
  {
    "text": "showing today again are all available they're all open source on the neo4j",
    "start": "2301720",
    "end": "2308520"
  },
  {
    "text": "GitHub it takes a little it's all about connecting um while it's running does",
    "start": "2308520",
    "end": "2314520"
  },
  {
    "text": "anybody have any questions has anybody been worried about",
    "start": "2314520",
    "end": "2320680"
  },
  {
    "text": "if their data set that they're using for their rag application is actually any good or has anybody asked you yeah right",
    "start": "2320680",
    "end": "2327599"
  },
  {
    "text": "what how have you been tackling it so far not very",
    "start": "2327599",
    "end": "2333960"
  },
  {
    "text": "well okay do you think some of this might be helpful I'm hoping so yeah okay well if you have",
    "start": "2333960",
    "end": "2340119"
  },
  {
    "text": "any challenges with it you reach out to me and I'll help you out all right so in this case what we see is we ask which",
    "start": "2340119",
    "end": "2347160"
  },
  {
    "text": "asset managers are impacted by the lithium storage and it's going to give you an answer that's somewhat General",
    "start": "2347160",
    "end": "2354440"
  },
  {
    "text": "because again it's only able to access the documents at that chunk level from the filing it doesn't the vector doesn't",
    "start": "2354440",
    "end": "2361640"
  },
  {
    "text": "know that there's a relationship all the way up to the asset manager and so here",
    "start": "2361640",
    "end": "2366960"
  },
  {
    "text": "it um based on the context provided a summary of asset managers that are impacted it'll show a few but these are",
    "start": "2366960",
    "end": "2374200"
  },
  {
    "text": "these are all the companies they're not the actual asset managers but when we use the graph and we actually attach",
    "start": "2374200",
    "end": "2380720"
  },
  {
    "text": "those structured pieces to the unstructured we can clearly see that tiger management and Berkeley um are",
    "start": "2380720",
    "end": "2388599"
  },
  {
    "text": "mentioned as asset managers for multiple companies whose SEC filings discuss risks and opportunities related to this",
    "start": "2388599",
    "end": "2395400"
  },
  {
    "text": "lithium storage so what it's giving you is it's giving you not just what's in the unstructured piece itself but",
    "start": "2395400",
    "end": "2402280"
  },
  {
    "text": "whatever the relevant structured piece is that can be informative vectors are really bad at",
    "start": "2402280",
    "end": "2408640"
  },
  {
    "text": "anything that's going to be an aggregation right because it's going just to these few things and so it it",
    "start": "2408640",
    "end": "2414520"
  },
  {
    "text": "adds that to you as well um we also have um this is the actual agent Neo that we",
    "start": "2414520",
    "end": "2421880"
  },
  {
    "text": "used and in this you know we can say whether we're using grounding or not and so this is just an another way of",
    "start": "2421880",
    "end": "2427920"
  },
  {
    "text": "testing so if I turn grounding off it's going to give me just the llm answer and if I turn that on it's going to actually",
    "start": "2427920",
    "end": "2434720"
  },
  {
    "text": "pull in those context documents so we can ask you know we can I mean I'm",
    "start": "2434720",
    "end": "2441520"
  },
  {
    "text": "trying to think of a good one at the moment on the Fly um but again all of these demos are available to you and you",
    "start": "2441520",
    "end": "2448440"
  },
  {
    "text": "can use them um for your own use cases my point in all of this is that",
    "start": "2448440",
    "end": "2455359"
  },
  {
    "text": "while the vector database and the basics of rag are readily available to you I",
    "start": "2455359",
    "end": "2460760"
  },
  {
    "text": "just want to encourage you to consider what happens after the vector and what is available to you beyond the",
    "start": "2460760",
    "end": "2468040"
  },
  {
    "text": "vector and that's it for now if anybody wants to see any more of these demos please come find me I will be here all",
    "start": "2468040",
    "end": "2473839"
  },
  {
    "text": "day and I appreciate all of your time and attention and to everyone watching online thank you for spending time with",
    "start": "2473839",
    "end": "2479160"
  },
  {
    "text": "us today thank you so much [Applause]",
    "start": "2479160",
    "end": "2486380"
  }
]
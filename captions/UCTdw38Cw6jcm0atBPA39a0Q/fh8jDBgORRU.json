[
  {
    "text": "[Music]",
    "start": "3630",
    "end": "7179"
  },
  {
    "text": "[Music]",
    "start": "9560",
    "end": "12679"
  },
  {
    "text": "[Applause] [Music] good morning welcome to the second day of NDC",
    "start": "23220",
    "end": "30160"
  },
  {
    "text": "Porto so how are we feeling today how are we feeling after the party last night come come on come on I know it's",
    "start": "30160",
    "end": "37000"
  },
  {
    "text": "9:00 a.m. I want to hear a bit more from you yes how has the conference been so",
    "start": "37000",
    "end": "43559"
  },
  {
    "text": "far awesome W come on come on I can't be the only",
    "start": "43559",
    "end": "49879"
  },
  {
    "text": "one who's this energetic at 9:00 a.m. I have been up until up since 5:00 a.m. so if I can bring this so can",
    "start": "49879",
    "end": "57079"
  },
  {
    "text": "you okay so I am honored to open the conference today with a topic that is",
    "start": "57079",
    "end": "63840"
  },
  {
    "text": "near and dear to my heart and that is can you trust your models now of course I'll be talking",
    "start": "63840",
    "end": "70600"
  },
  {
    "text": "about machine learning models but naturally I have to focus quite a bit on large language models because it's 2024",
    "start": "70600",
    "end": "77320"
  },
  {
    "text": "and how else am I going to get a keynote so a talk like this requires quite a bit of research what you're",
    "start": "77320",
    "end": "83880"
  },
  {
    "text": "going to see at the bottom of a lot of my slides are links to resources I've used throughout this talk now if you",
    "start": "83880",
    "end": "90079"
  },
  {
    "text": "want to follow up on anything don't panic about taking photos I am going to be sharing a QR code at the end of this",
    "start": "90079",
    "end": "97200"
  },
  {
    "text": "talk and it's going to take you to a link that contains all of my slides as well as all of those resources but it",
    "start": "97200",
    "end": "103720"
  },
  {
    "text": "doesn't mean you're going to have to stick around until the end I do promise it will be worth your time so let's take a closer look at the",
    "start": "103720",
    "end": "112320"
  },
  {
    "text": "title of this talk can you trust your models now if any of you have ever",
    "start": "112320",
    "end": "119240"
  },
  {
    "text": "worked with machine learning you will know this is a difficult problem it's a problem we have grappled with for quite",
    "start": "119240",
    "end": "125360"
  },
  {
    "text": "some time but it's particularly become a question in the last year or so with",
    "start": "125360",
    "end": "131120"
  },
  {
    "text": "large language models as we've moved from playground to production and it's a difficult question",
    "start": "131120",
    "end": "137840"
  },
  {
    "text": "to answer but the thing is this is not really a question about trust this is",
    "start": "137840",
    "end": "144920"
  },
  {
    "text": "actually a question about something far more tangible and far more scientific",
    "start": "144920",
    "end": "150160"
  },
  {
    "text": "it's a question about whether you are measuring the right thing and in order to illustrate the difference between",
    "start": "150160",
    "end": "156879"
  },
  {
    "text": "these two concepts we're going to start with a story from real life so back in 2010 a social",
    "start": "156879",
    "end": "165080"
  },
  {
    "text": "psychologist called Amy Cy was teaching at Harvard Business School and Cy began",
    "start": "165080",
    "end": "170760"
  },
  {
    "text": "noticing differences between the behavior of some of her students so some of her students while they were doing",
    "start": "170760",
    "end": "177000"
  },
  {
    "text": "very well in non-class participation were absolutely failing at class",
    "start": "177000",
    "end": "182280"
  },
  {
    "text": "participation they didn't want to be there they were shy they would half raise their hands almost as though they",
    "start": "182280",
    "end": "188560"
  },
  {
    "text": "were trying to protect themselves and correspondingly when they did have to say something they had no conviction in",
    "start": "188560",
    "end": "195360"
  },
  {
    "text": "what they were saying a second group of students also doing well at the non-class participation but they were killing it",
    "start": "195360",
    "end": "201760"
  },
  {
    "text": "in class they loved it they wanted to be there they raised their hands high and when they spoke they really believed in",
    "start": "201760",
    "end": "208640"
  },
  {
    "text": "what they had to say so as is the case when you do psychology",
    "start": "208640",
    "end": "214120"
  },
  {
    "text": "you become a guinea pig for your professors and Cy began to wonder whether this relationship between body",
    "start": "214120",
    "end": "220760"
  },
  {
    "text": "language and confidence went both ways whether potentially holding more",
    "start": "220760",
    "end": "226640"
  },
  {
    "text": "confident poses could lead to people feeling more confident and this kicked off C's",
    "start": "226640",
    "end": "233760"
  },
  {
    "text": "Research into what she called Power posing I'm seeing some flickers of recognition on some faces in the",
    "start": "233760",
    "end": "241159"
  },
  {
    "text": "audience so in cot's experiments what she got people to do was to hold a series of what she called high power",
    "start": "241159",
    "end": "248200"
  },
  {
    "text": "poses things like this one the Wonder Woman pose and what she found is that",
    "start": "248200",
    "end": "253319"
  },
  {
    "text": "participants who held these poses reported feeling more powerful yes but they were more willing to engage in",
    "start": "253319",
    "end": "259519"
  },
  {
    "text": "risk-seeking behavior and most importantly they showed physiological changes they demonstrated when measured",
    "start": "259519",
    "end": "267160"
  },
  {
    "text": "higher levels of testosterone and lower levels of cortisol indicating that they",
    "start": "267160",
    "end": "272240"
  },
  {
    "text": "actually felt more dominant and less stressed so cot's colleagues were",
    "start": "272240",
    "end": "279000"
  },
  {
    "text": "impressed by these findings as was The Wider scientific community and this earned to her a publication in the top",
    "start": "279000",
    "end": "286120"
  },
  {
    "text": "journal in Psychology psychological science and then the findings hit the",
    "start": "286120",
    "end": "291800"
  },
  {
    "text": "mainstream Cy had press interviews she got an appearance on Oprah and she got",
    "start": "291800",
    "end": "297320"
  },
  {
    "text": "one of the most watched TED Talks Of of all time remember Ted this was when it was really cool so people everywhere",
    "start": "297320",
    "end": "306039"
  },
  {
    "text": "were sneaking into bathroom stalls and power posing before job interviews or holding these poses before doing",
    "start": "306039",
    "end": "312560"
  },
  {
    "text": "something difficult say walking on stage and doing a keyote speech Cy and her power posing had",
    "start": "312560",
    "end": "319479"
  },
  {
    "text": "become a mainstream phenomenon that was until",
    "start": "319479",
    "end": "325880"
  },
  {
    "text": "2024 another researcher AA rehill tried to replicate C's",
    "start": "325880",
    "end": "331360"
  },
  {
    "text": "findings but she wasn't able to replicate most of what CI found and most",
    "start": "331360",
    "end": "336479"
  },
  {
    "text": "importantly she couldn't replicate those physiological changes the jewel in the",
    "start": "336479",
    "end": "341720"
  },
  {
    "text": "crown of C's original study other researchers took interest they started looking into this",
    "start": "341720",
    "end": "348520"
  },
  {
    "text": "themselves and they built up a body of evidence that this relationship that cotti had found between confidence and",
    "start": "348520",
    "end": "354919"
  },
  {
    "text": "Body Language didn't exist this whole unhappy Saga came to a",
    "start": "354919",
    "end": "360800"
  },
  {
    "text": "point when one of the original co-authors on cot's study publicly disavowed their findings and C's",
    "start": "360800",
    "end": "367720"
  },
  {
    "text": "credentials as a scientist were called into question so what happened here what",
    "start": "367720",
    "end": "376120"
  },
  {
    "text": "happened to Amy cudy how did she mess up so badly maybe cuy was a charlatan from the",
    "start": "376120",
    "end": "383840"
  },
  {
    "text": "start she was out to fool everyone and get a sweet speaking deal maybe she was",
    "start": "383840",
    "end": "391599"
  },
  {
    "text": "incompetent the thing is neither of these things were true Cy did her PhD at",
    "start": "391599",
    "end": "396680"
  },
  {
    "text": "Princeton she did this research remember while she was at Harvard she was a rigorously trained",
    "start": "396680",
    "end": "403360"
  },
  {
    "text": "scientist the problem was was that cotti and everyone else who had reviewed her",
    "start": "403360",
    "end": "408440"
  },
  {
    "text": "findings was fooled by results that seemed true but they told them the wrong",
    "start": "408440",
    "end": "414080"
  },
  {
    "text": "thing because CI had measured the wrong thing so I know what a lot of you are",
    "start": "414080",
    "end": "420440"
  },
  {
    "text": "thinking right now it's psychology like of course this was going to happen but",
    "start": "420440",
    "end": "426400"
  },
  {
    "text": "this couldn't happen to machine learning is so much more scientific the math it uses is so complex it is immune from",
    "start": "426400",
    "end": "432960"
  },
  {
    "text": "such problems not so fast so reviews have been done on a wide number of papers",
    "start": "432960",
    "end": "440199"
  },
  {
    "text": "across a wide variety of disciplines that use machine learning techniques and in every single one of the fields at",
    "start": "440199",
    "end": "447199"
  },
  {
    "text": "least 15% of the studies had serious problems with how they'd measured their",
    "start": "447199",
    "end": "453080"
  },
  {
    "text": "results which meant that those results were not true or correct in some of the",
    "start": "453080",
    "end": "458199"
  },
  {
    "text": "fields you can see more than half of the studies had these problems and I don't know what's going on in satellite",
    "start": "458199",
    "end": "464520"
  },
  {
    "text": "imaging but all of their papers had this problem and you can see that this list",
    "start": "464520",
    "end": "470879"
  },
  {
    "text": "includes arguably more objective or hard Fields like genomics medicine and oh yes",
    "start": "470879",
    "end": "478199"
  },
  {
    "text": "software engineering we did not Escape so let's have a look at an",
    "start": "478199",
    "end": "483720"
  },
  {
    "text": "example of one of these studies so what these researchers were trying to do was see whether four different machine",
    "start": "483720",
    "end": "489919"
  },
  {
    "text": "learning algorithms would perform differently when given the same task and the same data and what they found is",
    "start": "489919",
    "end": "497840"
  },
  {
    "text": "that newer more sophisticated algorithms outperformed boring old logistic",
    "start": "497840",
    "end": "503800"
  },
  {
    "text": "regression which is much simpler and much older makes sense right you know you're",
    "start": "503800",
    "end": "509680"
  },
  {
    "text": "going to have something more Cutting Edge of course it's going to outperform something that's a lot older",
    "start": "509680",
    "end": "516159"
  },
  {
    "text": "except none of it was true they had made major errors with how they had actually",
    "start": "516159",
    "end": "522039"
  },
  {
    "text": "calculated their results when these were corrected for this result disappeared everyone was just as bad as logistic",
    "start": "522039",
    "end": "530279"
  },
  {
    "text": "regression so it's a bit scary right if even experts in machine learning can",
    "start": "530279",
    "end": "536959"
  },
  {
    "text": "make such grave mistakes if mistakes like this can make it into the published",
    "start": "536959",
    "end": "542600"
  },
  {
    "text": "scientific record how can we be sure that our machine learning models are good how can we be sure that we're",
    "start": "542600",
    "end": "549959"
  },
  {
    "text": "measuring the right thing so to answer this question we can",
    "start": "549959",
    "end": "555279"
  },
  {
    "text": "borrow from a field called measurement Theory which is unsurprisingly the",
    "start": "555279",
    "end": "560560"
  },
  {
    "text": "branch of mathematics which tells us how to measure things and measurement Theory tells us that a robust machine learning",
    "start": "560560",
    "end": "567760"
  },
  {
    "text": "model will have two properties it will be reliable and it will be",
    "start": "567760",
    "end": "573680"
  },
  {
    "text": "valid so reliability is basically saying that your model is consistent in its",
    "start": "573680",
    "end": "579160"
  },
  {
    "text": "predictions there's a few facets here the first is is that for equivalent inputs your model will give you",
    "start": "579160",
    "end": "585959"
  },
  {
    "text": "equivalent outputs and this will also be stable and consistent over time the model will give you the same outputs for",
    "start": "585959",
    "end": "592880"
  },
  {
    "text": "the same inputs whether it's 6 months later or at the time it was trained and",
    "start": "592880",
    "end": "598279"
  },
  {
    "text": "it also means that different different equal ways of assessing the same thing will Converge on the same answer could",
    "start": "598279",
    "end": "605040"
  },
  {
    "text": "be that you have a machine learning model that's doing predictions and human rers they should Converge on the same",
    "start": "605040",
    "end": "613279"
  },
  {
    "text": "predictions validity on the other hand is measuring what you sent out to",
    "start": "613279",
    "end": "618680"
  },
  {
    "text": "measure and this seems super easy right like how can you not measure what you set out to measure but we're going to",
    "start": "618680",
    "end": "625079"
  },
  {
    "text": "see this is a very slippery concept and it's very difficult to actually get it",
    "start": "625079",
    "end": "630120"
  },
  {
    "text": "right so validity involves having a well- defined and precise concept that",
    "start": "630120",
    "end": "636560"
  },
  {
    "text": "you're trying to measure it also means that you have a sanity check if you have something that you trust that's",
    "start": "636560",
    "end": "642720"
  },
  {
    "text": "measuring something similar again those results should align they should correlate and it also means that your",
    "start": "642720",
    "end": "649639"
  },
  {
    "text": "model should perform just as well out in the real world as it does in its nice protected little development",
    "start": "649639",
    "end": "656639"
  },
  {
    "text": "environment so let's first have a look at a major threat to reliability and",
    "start": "656639",
    "end": "661760"
  },
  {
    "text": "that's the problem of data leakage so for me I think the easiest way to understand data leakage is to understand",
    "start": "661760",
    "end": "669600"
  },
  {
    "text": "the problem that a professor giving an exam faces so imagine you are this professor you want to assess your",
    "start": "669600",
    "end": "675760"
  },
  {
    "text": "students at the end of the semester so you give them an exam to help them practice you give them past exams but",
    "start": "675760",
    "end": "683800"
  },
  {
    "text": "when it comes time to Preparing the final exam you have fresh ANW fresh questions ones they hav seen before so",
    "start": "683800",
    "end": "690519"
  },
  {
    "text": "this way you are sure that what you're measuring is how well they've learned the course content let's say you're a little lazy",
    "start": "690519",
    "end": "698440"
  },
  {
    "text": "maybe running a little low on time so you have to reuse past exam questions",
    "start": "698440",
    "end": "704480"
  },
  {
    "text": "now this creates measurement problem you are no longer sure what you're measuring and it's quite possible what you're now",
    "start": "704480",
    "end": "711279"
  },
  {
    "text": "measuring is how well the students have memorized the answers on those past exam",
    "start": "711279",
    "end": "716760"
  },
  {
    "text": "questions so this is the problem of data leakage you give the students the",
    "start": "716760",
    "end": "722360"
  },
  {
    "text": "materials to um sorry you test the students on the same material that you",
    "start": "722360",
    "end": "727959"
  },
  {
    "text": "use to train them so this works in the same way in machine learning models we can see that",
    "start": "727959",
    "end": "733959"
  },
  {
    "text": "in the case of a model called cheex net now cheet was designed to automatically",
    "start": "733959",
    "end": "739880"
  },
  {
    "text": "test whether someone had pneumonia based on their lung scans and when it was",
    "start": "739880",
    "end": "745079"
  },
  {
    "text": "first released it worked super well hoay for science right we' solve this",
    "start": "745079",
    "end": "751560"
  },
  {
    "text": "problem except we did not there was a problem with the data and that was that",
    "start": "751560",
    "end": "756920"
  },
  {
    "text": "when people go in to get lung scans they don't just get one lung scan in the same appointment they get multiple they're",
    "start": "756920",
    "end": "762920"
  },
  {
    "text": "basically identical and the uh creators of this model did not know that so what",
    "start": "762920",
    "end": "768839"
  },
  {
    "text": "they ended up doing is Distributing identical lung scans across the data set used for training and the one used for",
    "start": "768839",
    "end": "775839"
  },
  {
    "text": "testing when it came to test time well the model had already memorized some of",
    "start": "775839",
    "end": "781440"
  },
  {
    "text": "the answers do you see the problem it is just like with the",
    "start": "781440",
    "end": "786600"
  },
  {
    "text": "students so let's now turn to validity so in the early days of machine",
    "start": "786600",
    "end": "792399"
  },
  {
    "text": "learning models when we had models like regression models or decision trees assessing validity just by looking at",
    "start": "792399",
    "end": "799120"
  },
  {
    "text": "what a model had Learned was really easy because these models are completely explainable can see exactly what they've",
    "start": "799120",
    "end": "805639"
  },
  {
    "text": "learned during training so we can see an example of this this with a linear aggression model",
    "start": "805639",
    "end": "811760"
  },
  {
    "text": "so this model here is assessing or predicting students exam scores and we",
    "start": "811760",
    "end": "817079"
  },
  {
    "text": "can see that we've got a number of features the things that we want to predict the exam scores with and each of",
    "start": "817079",
    "end": "822160"
  },
  {
    "text": "those features have weights these weights tell us exactly",
    "start": "822160",
    "end": "828160"
  },
  {
    "text": "what the model has learned about each of those features during training so example this 1.5 next to hours spent",
    "start": "828160",
    "end": "835279"
  },
  {
    "text": "studying tells us that what the model learned is that for every hour the students been studying they will get an",
    "start": "835279",
    "end": "841600"
  },
  {
    "text": "extra 1.5% on their exam Mark super interpretable super easy to",
    "start": "841600",
    "end": "849120"
  },
  {
    "text": "understand but as we've moved into more complex models the age of blackbox models things have become a lot more",
    "start": "849120",
    "end": "856600"
  },
  {
    "text": "complex we've had to create layers of interpretations or workarounds to try and work out what models are learning",
    "start": "856600",
    "end": "862880"
  },
  {
    "text": "during training so for example with this Vision model we can pull out the hidden States",
    "start": "862880",
    "end": "868720"
  },
  {
    "text": "and we can try and sort of visualize what the model is learning looks like this model is sequentially learning what",
    "start": "868720",
    "end": "875279"
  },
  {
    "text": "a cat looks like but I've had to interpret that I could be wrong or this early small language model we can see",
    "start": "875279",
    "end": "882720"
  },
  {
    "text": "how it seems to be learning the relationships between words in a sentence but again that's not really the",
    "start": "882720",
    "end": "888440"
  },
  {
    "text": "full picture and I don't know if interpreted this correctly and things have really gone",
    "start": "888440",
    "end": "895720"
  },
  {
    "text": "off the rails with validity when it comes to large Lang language models we",
    "start": "895720",
    "end": "900800"
  },
  {
    "text": "can Peak inside these models to an extent but it's in a very very limited way and in no way encapsulates the full",
    "start": "900800",
    "end": "907680"
  },
  {
    "text": "kind of capabilities of these models so what we're Stu relying on at the moment",
    "start": "907680",
    "end": "912720"
  },
  {
    "text": "is looking at the model inputs and seeing whether the model outputs make sense so say we have this example here",
    "start": "912720",
    "end": "920720"
  },
  {
    "text": "write me a joke about cats well it did give me a joke about cats but I don't",
    "start": "920720",
    "end": "926720"
  },
  {
    "text": "know how it arrived at the concept of a joke or how it knows what a cat is and what's worse is we don't just",
    "start": "926720",
    "end": "935040"
  },
  {
    "text": "have problems with validity we have serious problems with reliability this is a problem we never",
    "start": "935040",
    "end": "941440"
  },
  {
    "text": "had before with machine learning models once you had trained a model it would give you the same output for the same",
    "start": "941440",
    "end": "948399"
  },
  {
    "text": "input but anyone who's used an llm will note that by Design they do not work",
    "start": "948399",
    "end": "953639"
  },
  {
    "text": "that way same input two different cat jokes least you could say they're",
    "start": "953639",
    "end": "959360"
  },
  {
    "text": "equally terrible but that's not really a reliability measure so this brings us back to our",
    "start": "959360",
    "end": "965639"
  },
  {
    "text": "question how do we know if a large language model is good how can we",
    "start": "965639",
    "end": "971440"
  },
  {
    "text": "measure these models correctly well if you've been a person",
    "start": "971440",
    "end": "978800"
  },
  {
    "text": "existing in the world for the past year or so you will have llm vendors and",
    "start": "978800",
    "end": "984560"
  },
  {
    "text": "developers telling you how very good their models are so perhaps you will",
    "start": "984560",
    "end": "990199"
  },
  {
    "text": "have read a piece of marketing material from an llm vendor that says something like the following we've just launched",
    "start": "990199",
    "end": "996519"
  },
  {
    "text": "our newest large language model trained with state-of-the-art gpus and we've improved on the MML U by end points",
    "start": "996519",
    "end": "1003880"
  },
  {
    "text": "beating the previous best or maybe you've seen some flavor of",
    "start": "1003880",
    "end": "1009480"
  },
  {
    "text": "an llm leaderboard pitting models against each other on exotic sounding measures like win Grand or hella",
    "start": "1009480",
    "end": "1017639"
  },
  {
    "text": "swag let bag it's one of my favorite named things in machine",
    "start": "1017639",
    "end": "1022959"
  },
  {
    "text": "learning the thing is what are these things measuring and does scoring really well",
    "start": "1022959",
    "end": "1030520"
  },
  {
    "text": "on these benchmarks mean that an llm is good welcome to the noisy and confusing",
    "start": "1030520",
    "end": "1038120"
  },
  {
    "text": "world of llm assessment so let's start with what I",
    "start": "1038120",
    "end": "1044240"
  },
  {
    "text": "think is one of the most inflammatory ways of assessing llms that's seeing",
    "start": "1044240",
    "end": "1049400"
  },
  {
    "text": "how they perform on benchmarks that were originally designed for humans so we can",
    "start": "1049400",
    "end": "1055640"
  },
  {
    "text": "see an example of that here what we have are four language models and they've been given questions from a US medical",
    "start": "1055640",
    "end": "1063280"
  },
  {
    "text": "exam they did great gp4 got 100% of the questions right worst performing model",
    "start": "1063280",
    "end": "1070120"
  },
  {
    "text": "still got 75% right probably better than I could do most definitely better than I",
    "start": "1070120",
    "end": "1075240"
  },
  {
    "text": "could do so results like this were every everywhere early last year we had people",
    "start": "1075240",
    "end": "1081240"
  },
  {
    "text": "applying llms to medical exams to law exams to lead code puzzles and then the",
    "start": "1081240",
    "end": "1087240"
  },
  {
    "text": "corresponding claims followed if they're so good at smashing these super",
    "start": "1087240",
    "end": "1093400"
  },
  {
    "text": "difficult exams won't be long until they replace doctors till they replace lawyers till they replace",
    "start": "1093400",
    "end": "1101280"
  },
  {
    "text": "programmers the thing is it's been over a year since we saw these results come out and we haven't really seen that much",
    "start": "1101280",
    "end": "1108840"
  },
  {
    "text": "progress towards these goals really I would say no material progress but you can come and argue that with me",
    "start": "1108840",
    "end": "1115200"
  },
  {
    "text": "afterwards if you would like so what Gibs why have we not been able to translate this amazing exam",
    "start": "1115200",
    "end": "1122760"
  },
  {
    "text": "performance into replacing doctors so if you've been to any of my",
    "start": "1122760",
    "end": "1130480"
  },
  {
    "text": "previous talks you'll probably know what I'm going to say next and that is the problem with taking assessments that",
    "start": "1130480",
    "end": "1136200"
  },
  {
    "text": "were designed by humans and applying them to Ms is that you're fundamentally measuring different things now let's",
    "start": "1136200",
    "end": "1144240"
  },
  {
    "text": "talk about why we give exams to humans what do they measure and let's take the case of medical",
    "start": "1144240",
    "end": "1150600"
  },
  {
    "text": "exams the point of giving medical exams to students is to tell to act as a proxy",
    "start": "1150600",
    "end": "1157360"
  },
  {
    "text": "a predictor of how well they'll go when they have to practice medicine and they're not perfect I don't",
    "start": "1157360",
    "end": "1164400"
  },
  {
    "text": "want to kind of defend them but Studies have been found that they do have validity that people who go on to do",
    "start": "1164400",
    "end": "1170559"
  },
  {
    "text": "well at these entry exams for medical school go on to do well at med school and then go on to have quite career",
    "start": "1170559",
    "end": "1177440"
  },
  {
    "text": "successful careers in medicine so the reason that we can make",
    "start": "1177440",
    "end": "1183400"
  },
  {
    "text": "this connection is because the mechanism for being able to complete difficult",
    "start": "1183400",
    "end": "1190039"
  },
  {
    "text": "medical exams and to be able to practice as a doctor both tap into the same Raw",
    "start": "1190039",
    "end": "1195840"
  },
  {
    "text": "General ability we have as humans called G or general intelligence so humans can",
    "start": "1195840",
    "end": "1201720"
  },
  {
    "text": "use G to solve a whole range of problems we are generalists we are very flexible",
    "start": "1201720",
    "end": "1206799"
  },
  {
    "text": "and in the case of exams we can use things like Advanced reasoning and",
    "start": "1206799",
    "end": "1212480"
  },
  {
    "text": "learned knowledge to solve medical exams and solve medical problems",
    "start": "1212480",
    "end": "1219120"
  },
  {
    "text": "alike so what does it mean when a large language model does well on a medical exam or a low exam or something else it",
    "start": "1219120",
    "end": "1228000"
  },
  {
    "text": "means that there good at solving the specific kinds of problems that are present on those exams nothing more",
    "start": "1228000",
    "end": "1236320"
  },
  {
    "text": "nothing less but why why is it that we can't make this leap we can't say that",
    "start": "1236320",
    "end": "1243240"
  },
  {
    "text": "this exam performance is a proxy for a higher intelligence in these models so if you're really interested in",
    "start": "1243240",
    "end": "1250480"
  },
  {
    "text": "this topic I've talked about it extensively in other talks I gave a talk at NDC Oslo where I have a whole section",
    "start": "1250480",
    "end": "1256559"
  },
  {
    "text": "on intelligence and llms but we'll just keep it brief for this talk we've got a lot of other things to talk about but in",
    "start": "1256559",
    "end": "1263360"
  },
  {
    "text": "brief the problem comes down to how llms learn compared to how humans learn so",
    "start": "1263360",
    "end": "1269679"
  },
  {
    "text": "humans as I said we have this General ability to learn we can solve many and diverse problems using our general",
    "start": "1269679",
    "end": "1277000"
  },
  {
    "text": "intelligence machine learning models on the other hand are trained to do one thing and one thing only in the case of",
    "start": "1277000",
    "end": "1284520"
  },
  {
    "text": "checknet this is detect whether people have pneumonia and the case of llms this",
    "start": "1284520",
    "end": "1290360"
  },
  {
    "text": "is to predict the next word in the sentence so for each batch of training",
    "start": "1290360",
    "end": "1295919"
  },
  {
    "text": "data what an llm needs to do is generate some sort of prediction they then need",
    "start": "1295919",
    "end": "1302960"
  },
  {
    "text": "to compare that prediction against the correct answer a gold standard they need to see how far away they are from that",
    "start": "1302960",
    "end": "1309880"
  },
  {
    "text": "answer then they need to gradually adjust the model weights and then",
    "start": "1309880",
    "end": "1315159"
  },
  {
    "text": "continue the whole thing again until they hopefully get to some sort of good performance or",
    "start": "1315159",
    "end": "1320320"
  },
  {
    "text": "convergence now this is cumbersome and in order to make this process as efficient as possible neuron Nets have",
    "start": "1320320",
    "end": "1327880"
  },
  {
    "text": "been designed with mechanisms in mind like gradient descent that helps them take the quickest path possible to that",
    "start": "1327880",
    "end": "1334600"
  },
  {
    "text": "training goal because of these efficiencies that have been built in because of all the other things the",
    "start": "1334600",
    "end": "1339840"
  },
  {
    "text": "model needs to learn from scratch from the data it's very unlikely that that path will include a detour into",
    "start": "1339840",
    "end": "1347760"
  },
  {
    "text": "generalized int intelligence so benchmarks for humans",
    "start": "1347760",
    "end": "1353679"
  },
  {
    "text": "are no good so let's go back to benchmarks that were designed specifically for",
    "start": "1353679",
    "end": "1359919"
  },
  {
    "text": "llms so up until recently this very humbl looking table is one of the key",
    "start": "1359919",
    "end": "1366080"
  },
  {
    "text": "ways that people worked out whether llms were good so this is created by a",
    "start": "1366080",
    "end": "1371919"
  },
  {
    "text": "company called hugging face what it did would it take open source llms get them",
    "start": "1371919",
    "end": "1377480"
  },
  {
    "text": "to complete a BN of gold standard benchmarks Cate the scores and then rank",
    "start": "1377480",
    "end": "1384039"
  },
  {
    "text": "them but in June of this year something rather strange",
    "start": "1384039",
    "end": "1389360"
  },
  {
    "text": "happened this leaderboard was retired and a new one using new gold standard benchmarks was",
    "start": "1389360",
    "end": "1396240"
  },
  {
    "text": "introduced what went on here well part of the problem there were",
    "start": "1396240",
    "end": "1402159"
  },
  {
    "text": "a few but this is the most entertaining one part of the problem was that these gold standard benchmarks were not quite",
    "start": "1402159",
    "end": "1409440"
  },
  {
    "text": "the gold standard that people had held them up as so we're going to go through a few and let's start with the case of",
    "start": "1409440",
    "end": "1415400"
  },
  {
    "text": "the MML we met the mlu a few slides ago and this measure is so important in the",
    "start": "1415400",
    "end": "1422559"
  },
  {
    "text": "assessment of llms major llm vendors will compare their MML U scores to a",
    "start": "1422559",
    "end": "1428640"
  },
  {
    "text": "couple of decimal places that is how highly regarded this measure is but the mlu also contains questions",
    "start": "1428640",
    "end": "1437159"
  },
  {
    "text": "like the one I'm about to show you and before I show it to you I need to stress I have not left anything out I've not",
    "start": "1437159",
    "end": "1442799"
  },
  {
    "text": "taken this out of context this is the full question the complexity of the",
    "start": "1442799",
    "end": "1449520"
  },
  {
    "text": "theory all right maybe there a bit of a clue in the answers so let's have a look",
    "start": "1449520",
    "end": "1455600"
  },
  {
    "text": "1 2 3 4 13 4 1 2 3 1 two",
    "start": "1455600",
    "end": "1462200"
  },
  {
    "text": "4 there's nothing deeper here this is the full question this is all the information that the llm has to work",
    "start": "1462200",
    "end": "1468799"
  },
  {
    "text": "with and this poor model has to try and predict that somehow C is the correct answer",
    "start": "1468799",
    "end": "1474840"
  },
  {
    "text": "here okay let's have a look at another one this is from helis swag this was also a leader measure and what an llm is",
    "start": "1474840",
    "end": "1482679"
  },
  {
    "text": "expected to do with helis swag is complete scenarios that it's presented with again I have typed this out exactly",
    "start": "1482679",
    "end": "1490799"
  },
  {
    "text": "as it's in the Benchmark the typos are not mine men are standing around in a large",
    "start": "1490799",
    "end": "1496799"
  },
  {
    "text": "Green Field playing La Ross people is around the field watching the game men",
    "start": "1496799",
    "end": "1503320"
  },
  {
    "text": "are holding t-shirts watching into lacrosse playing are being interviewed in a podium in front of a large group",
    "start": "1503320",
    "end": "1508840"
  },
  {
    "text": "and a gymnast is holding a microphone for the announcers running side to side of the yield playing lacrosse trying to score",
    "start": "1508840",
    "end": "1516039"
  },
  {
    "text": "are in a field running around playing lacrosse now whenever I read this",
    "start": "1516039",
    "end": "1522960"
  },
  {
    "text": "question I feel like I'm having a fever dream but uh typos and bizarre imagery aside",
    "start": "1522960",
    "end": "1529200"
  },
  {
    "text": "we're meant to pick that the men are playing lacrosse right there are two options C and D what's the llm supposed",
    "start": "1529200",
    "end": "1535919"
  },
  {
    "text": "to do here all right one more and I promise I could actually go for the rest of the talk with these but we have other",
    "start": "1535919",
    "end": "1542480"
  },
  {
    "text": "things to talk about so this is from Common Sense QA this is another popular measure and we're off a good start this",
    "start": "1542480",
    "end": "1549440"
  },
  {
    "text": "question actually makes sense when a person is breathing in a paper bag what",
    "start": "1549440",
    "end": "1554480"
  },
  {
    "text": "are they trying to do but hold on to your hearts let's see the answers warm air continue to live going to sleep",
    "start": "1554480",
    "end": "1565399"
  },
  {
    "text": "hyperventilation stay alive so um I would say there's not even grammatical",
    "start": "1565399",
    "end": "1571840"
  },
  {
    "text": "sense here you let alone a correct answer and it does feel a little like I've cherry-picked these right like may",
    "start": "1571840",
    "end": "1577399"
  },
  {
    "text": "have just gone through and these measures are totally fine there's just a couple of bad answers but no there are",
    "start": "1577399",
    "end": "1582720"
  },
  {
    "text": "dozens maybe hundreds of questions like this peppered throughout popular benchmarks",
    "start": "1582720",
    "end": "1589679"
  },
  {
    "text": "so in light of this problem the creators of the hugging face leader board uh sourced more accurate better curated",
    "start": "1589679",
    "end": "1597279"
  },
  {
    "text": "measures and they have retired the old ones and brought in these new",
    "start": "1597279",
    "end": "1602679"
  },
  {
    "text": "ones but what does this mean does it mean that if an llm gets 100% on all of",
    "start": "1602679",
    "end": "1608559"
  },
  {
    "text": "these new benchmarks then they're a good model well of course you know at this",
    "start": "1608559",
    "end": "1615840"
  },
  {
    "text": "point of the talk that I am going to tell you you know sorry I'm really not I was a",
    "start": "1615840",
    "end": "1622919"
  },
  {
    "text": "clinical psychologist and I study stuff like depression I'm not a very cheer person",
    "start": "1622919",
    "end": "1628240"
  },
  {
    "text": "anyway so one of the problems comes down to something very fundamental and that",
    "start": "1628240",
    "end": "1635760"
  },
  {
    "text": "is how llms actually answer the questions themselves doesn't matter what the questions are the answer type has an",
    "start": "1635760",
    "end": "1644559"
  },
  {
    "text": "influence so llms just like humans have two ways in which they can answer these",
    "start": "1644559",
    "end": "1650080"
  },
  {
    "text": "Benchmark questions so the first is multiple choice just like we have in our",
    "start": "1650080",
    "end": "1655440"
  },
  {
    "text": "exams so say we present an llm with the question what is the capital of Portugal",
    "start": "1655440",
    "end": "1661320"
  },
  {
    "text": "we can present it with a few different multiple choice options and if it picks b or Lisbon or some combination thereof",
    "start": "1661320",
    "end": "1668200"
  },
  {
    "text": "we know that this is the correct answer or it can of course generate free form",
    "start": "1668200",
    "end": "1673760"
  },
  {
    "text": "answers so for our question about the capital of Portugal but tells us something like the capital of Portugal",
    "start": "1673760",
    "end": "1679519"
  },
  {
    "text": "is Lisbon this would be correct so as you might have seen so far",
    "start": "1679519",
    "end": "1686440"
  },
  {
    "text": "all of the benchmarks that I've shown you so far use multiple choice and the reason for this as you can imagine it's",
    "start": "1686440",
    "end": "1693240"
  },
  {
    "text": "actually really difficult to see whether a fully free form generated answer is",
    "start": "1693240",
    "end": "1698640"
  },
  {
    "text": "correct whether it is semantically equivalent to the gold standard that's put in The",
    "start": "1698640",
    "end": "1704039"
  },
  {
    "text": "Benchmark so what's the problem then why don't we just use multiple choices for everything well as I have hinted at the",
    "start": "1704039",
    "end": "1712600"
  },
  {
    "text": "answer type drastically influences the performance that llms have on these",
    "start": "1712600",
    "end": "1719080"
  },
  {
    "text": "benchmarks so here are three models and here is their performance when they were given multiple choice",
    "start": "1719080",
    "end": "1726720"
  },
  {
    "text": "options here are the same models for the same Benchmark when they were asked to",
    "start": "1726720",
    "end": "1731960"
  },
  {
    "text": "generate answers so you can see in every case it's worse sometimes significantly",
    "start": "1731960",
    "end": "1737880"
  },
  {
    "text": "worse worse and that's bad enough but what makes this really bad is they don't",
    "start": "1737880",
    "end": "1744159"
  },
  {
    "text": "get the same questions correct between the two answer types what this means",
    "start": "1744159",
    "end": "1749399"
  },
  {
    "text": "it's a validity issue these two answer types are themselves measuring different",
    "start": "1749399",
    "end": "1754799"
  },
  {
    "text": "things and what researchers believe is that unfortunately multiple choice Taps",
    "start": "1754799",
    "end": "1759840"
  },
  {
    "text": "more into rot memorization whereas generating free form answers requires",
    "start": "1759840",
    "end": "1765360"
  },
  {
    "text": "potentially more creativity and logic from the model another validity issue is that these",
    "start": "1765360",
    "end": "1772360"
  },
  {
    "text": "benchmarks don't really seem to relate to Performance in other measures",
    "start": "1772360",
    "end": "1777840"
  },
  {
    "text": "measuring something similar so let's take the case of this simple logic",
    "start": "1777840",
    "end": "1783399"
  },
  {
    "text": "puzzle Alice has three brothers and she also has six sisters how many sisters",
    "start": "1783399",
    "end": "1789480"
  },
  {
    "text": "does Alice's brother have give you a couple of seconds has anyone got the",
    "start": "1789480",
    "end": "1794799"
  },
  {
    "text": "answer seven good so so let's see how we will solve",
    "start": "1794799",
    "end": "1800440"
  },
  {
    "text": "this so Alice we must assume is a woman's name in this puzzle so Alice is",
    "start": "1800440",
    "end": "1805679"
  },
  {
    "text": "one of the potential sisters we're also told that there are six additional sisters so if we add 1 plus six we get a",
    "start": "1805679",
    "end": "1814240"
  },
  {
    "text": "total of seven potential sisters for each brother I see the frustration on",
    "start": "1814240",
    "end": "1819559"
  },
  {
    "text": "some of your faces I think next time I give this talk I'll give you a bit more time sorry sorry I didn't want to take",
    "start": "1819559",
    "end": "1826519"
  },
  {
    "text": "away the the chance to solve a puzzle the link will be and you can solve all the puzzles yourself",
    "start": "1826519",
    "end": "1832480"
  },
  {
    "text": "so so this is part of a suite of puzzles called Alice in Wonderland and they're",
    "start": "1832480",
    "end": "1837679"
  },
  {
    "text": "all quite similar and they're of a similar level of complexity so these would fall",
    "start": "1837679",
    "end": "1843880"
  },
  {
    "text": "into they're still simple reasoning puzzles they're nothing too advanced or",
    "start": "1843880",
    "end": "1849039"
  },
  {
    "text": "multi-step so what the developers of these puzzles did they got state-of-the-art llms I'm talking like",
    "start": "1849039",
    "end": "1854640"
  },
  {
    "text": "ones that are state-ofthe-art now to complete all of these puzzles and then",
    "start": "1854640",
    "end": "1860600"
  },
  {
    "text": "they also got these same models to complete the MML U our old friend and",
    "start": "1860600",
    "end": "1865880"
  },
  {
    "text": "the mlu is also supposed to assess reasoning so what you would expect in",
    "start": "1865880",
    "end": "1871000"
  },
  {
    "text": "this case is that their scores will be highly correlated if you get more mlu",
    "start": "1871000",
    "end": "1876240"
  },
  {
    "text": "items correct you get more Alice in Wonderland puzzles correct but what they found instead was a pattern like",
    "start": "1876240",
    "end": "1885159"
  },
  {
    "text": "this what does this mean what what it means is that every single one of the models got significantly more mlu items",
    "start": "1885159",
    "end": "1893399"
  },
  {
    "text": "correct than Alice in Wonderland puzzles and worse still most of these Cutting",
    "start": "1893399",
    "end": "1899679"
  },
  {
    "text": "Edge models couldn't even complete 5% of the Alice and Wonderland puddles",
    "start": "1899679",
    "end": "1906639"
  },
  {
    "text": "but complete could complete more than 50% of the MML U items so this tells us",
    "start": "1906639",
    "end": "1912200"
  },
  {
    "text": "two things it tells us that the mlu is probably not really assessing reasoning",
    "start": "1912200",
    "end": "1917600"
  },
  {
    "text": "in the way that we think it is and it also means that a lot of these Cutting Edge models have far weaker reasoning",
    "start": "1917600",
    "end": "1923960"
  },
  {
    "text": "ability than we have been sold and this leads to a question these",
    "start": "1923960",
    "end": "1930320"
  },
  {
    "text": "are language models it's in the name so should we even be trying to assess",
    "start": "1930320",
    "end": "1935639"
  },
  {
    "text": "things like reasoning when we look at these models sorry just checking the time good",
    "start": "1935639",
    "end": "1942559"
  },
  {
    "text": "so let's think back to the beginning of this talk where I talked about the domain",
    "start": "1942559",
    "end": "1948519"
  },
  {
    "text": "for creating and assessing machine learning models so the way we've always",
    "start": "1948519",
    "end": "1953559"
  },
  {
    "text": "traditionally thought about this in machine learning models is in very focused way say like this Vision model",
    "start": "1953559",
    "end": "1959200"
  },
  {
    "text": "all it does is tells whether an image is a cat or a dog and so you will train it that way and you will assess it that",
    "start": "1959200",
    "end": "1966559"
  },
  {
    "text": "way in the beginning it was the same with large language models they were originally designed actually for machine",
    "start": "1966559",
    "end": "1972639"
  },
  {
    "text": "translation and so you would assess them based on whether they could do that task well",
    "start": "1972639",
    "end": "1978799"
  },
  {
    "text": "and so the original Suite of benchmarks for llms were NLP benchmarks natural",
    "start": "1978799",
    "end": "1984799"
  },
  {
    "text": "language processing seeing whether these models could successfully do tasks like question answering whether they could do",
    "start": "1984799",
    "end": "1990840"
  },
  {
    "text": "text classification or text summarization and they weren't perfect we've seen that already with the answer",
    "start": "1990840",
    "end": "1996039"
  },
  {
    "text": "type issues but they were at least focused on one specific",
    "start": "1996039",
    "end": "2001559"
  },
  {
    "text": "task but as the capabilities of llms have grown or they appear to have grown",
    "start": "2001559",
    "end": "2008480"
  },
  {
    "text": "we have scrambled to create more and more exotic benchmarks we now have",
    "start": "2008480",
    "end": "2014120"
  },
  {
    "text": "benchmarks to assess Advanced reasoning to see whether these models can do a whole range of tasks or no deep",
    "start": "2014120",
    "end": "2021760"
  },
  {
    "text": "knowledge in topics that are you know extremely difficult like physics or mathematics and we even have benchmarks",
    "start": "2021760",
    "end": "2028240"
  },
  {
    "text": "to assess whether these models have artificial general intelligence now this for me is one of",
    "start": "2028240",
    "end": "2035200"
  },
  {
    "text": "the core problems with using benchmark marks we create these leaderboards we",
    "start": "2035200",
    "end": "2040440"
  },
  {
    "text": "coate scores for all these different benchmarks assessing different things",
    "start": "2040440",
    "end": "2045960"
  },
  {
    "text": "but how do you then pick a model based on your problem domain are you trying to",
    "start": "2045960",
    "end": "2051398"
  },
  {
    "text": "create AGI do you care about Advanced reasoning no you're probably just trying to build a",
    "start": "2051399",
    "end": "2057960"
  },
  {
    "text": "chatbot so this is again a validity issue by trying to create benchmarks and",
    "start": "2057960",
    "end": "2064040"
  },
  {
    "text": "summarize them to assess llm performance the bench bench marks have lost",
    "start": "2064040",
    "end": "2069200"
  },
  {
    "text": "Precision they have lost meaning for the domains they actually matter",
    "start": "2069200",
    "end": "2074679"
  },
  {
    "text": "to so those of you in the know might be screaming internally right now what",
    "start": "2074679",
    "end": "2082240"
  },
  {
    "text": "about the chatbot Arena and those of you who have no idea what I'm talking about you're probably thinking God hella swag",
    "start": "2082240",
    "end": "2089240"
  },
  {
    "text": "chatbot Arena like what's wrong with these machine learning people we do love weird names so the chatbot arena is an",
    "start": "2089240",
    "end": "2096599"
  },
  {
    "text": "experiment anyone can visit the website where it's set up and what you can do is",
    "start": "2096599",
    "end": "2101800"
  },
  {
    "text": "enter a prompt anything of your choice so in my case I have asked can you",
    "start": "2101800",
    "end": "2107359"
  },
  {
    "text": "please write me a poem about sausages so then the chatboard arena",
    "start": "2107359",
    "end": "2112520"
  },
  {
    "text": "will go away and it will find two state-of-the-art llms and ask them to return you an output and you're asked to",
    "start": "2112520",
    "end": "2119200"
  },
  {
    "text": "choose which one you like best quite fond of the second one plump and juicy",
    "start": "2119200",
    "end": "2125040"
  },
  {
    "text": "in a row they lie sausages waiting to satis by so my experiment and everyone",
    "start": "2125040",
    "end": "2130640"
  },
  {
    "text": "else who visits the chatbot Arena they will be cated in a new score called the",
    "start": "2130640",
    "end": "2135760"
  },
  {
    "text": "ELO score this gives us another way of ranking and comparing models and then of course they have built a Leaderboard on",
    "start": "2135760",
    "end": "2142960"
  },
  {
    "text": "top of this so the Chapo Arena and its Associated leader board are considered",
    "start": "2142960",
    "end": "2149119"
  },
  {
    "text": "the most trustworthy way of picking llms at the moment it bypasses all of those",
    "start": "2149119",
    "end": "2156040"
  },
  {
    "text": "pesky problems that we just talked about with benchmarks and in a sense it's true so",
    "start": "2156040",
    "end": "2163079"
  },
  {
    "text": "the chatboard arena is currently based on more than a million experiments coming from a diverse range of users all",
    "start": "2163079",
    "end": "2170119"
  },
  {
    "text": "with diverse preferences and all coming in with their own unique prompts so yes",
    "start": "2170119",
    "end": "2175560"
  },
  {
    "text": "in this sense the chatbot Arena has validity because it is exactly how the",
    "start": "2175560",
    "end": "2181720"
  },
  {
    "text": "end users of llms will receive the content but before we get super excited",
    "start": "2181720",
    "end": "2189280"
  },
  {
    "text": "and jump up and down cheering and assuming that we have solved this problem of llm assessment let's first",
    "start": "2189280",
    "end": "2195920"
  },
  {
    "text": "look at how the chatbot Arena actually assesses the results of each",
    "start": "2195920",
    "end": "2202599"
  },
  {
    "text": "experiment the words that you are use required to use to choose between the",
    "start": "2202599",
    "end": "2207839"
  },
  {
    "text": "two outputs are good and bad but what does good mean does it mean",
    "start": "2207839",
    "end": "2215079"
  },
  {
    "text": "more formal more beautiful more concise more verbose more funny and as my",
    "start": "2215079",
    "end": "2220680"
  },
  {
    "text": "sausage poem being good mean the same thing as a resignation email to your boss being",
    "start": "2220680",
    "end": "2226839"
  },
  {
    "text": "good again we come back to the problem of precision just like with the",
    "start": "2226839",
    "end": "2232920"
  },
  {
    "text": "benchmarks by trying to create models whose use case is anything you can think",
    "start": "2232920",
    "end": "2238680"
  },
  {
    "text": "of at this point the only way we can possibly assess them is with terms that",
    "start": "2238680",
    "end": "2243760"
  },
  {
    "text": "are so vague they essentially become meaningless so you might have noticed that I have",
    "start": "2243760",
    "end": "2249960"
  },
  {
    "text": "been speaking extensively about validity but I haven't really touched yet on",
    "start": "2249960",
    "end": "2255400"
  },
  {
    "text": "reliability so let's now go back to our old friend data leakage now llms are trained on",
    "start": "2255400",
    "end": "2264440"
  },
  {
    "text": "absolutely enormous public data sets we're going to talk about how big in a",
    "start": "2264440",
    "end": "2270079"
  },
  {
    "text": "second and in addition the creators of these B of these models have become more",
    "start": "2270079",
    "end": "2275240"
  },
  {
    "text": "and more secretive over time about what data they're actually using even open- Source model creators are pretty Cy",
    "start": "2275240",
    "end": "2282160"
  },
  {
    "text": "about their secret Source at this point so what this means is us as end users",
    "start": "2282160",
    "end": "2287880"
  },
  {
    "text": "can easily be fooled into thinking we're seeing impressive capabilities of these models when we're just seeing",
    "start": "2287880",
    "end": "2294400"
  },
  {
    "text": "memorization we're just seeing data leakage and there's a really beautiful experiment that a guy called Horus hay",
    "start": "2294400",
    "end": "2301240"
  },
  {
    "text": "did the beginning of last year he was very cynical about these claims that llm",
    "start": "2301240",
    "end": "2307520"
  },
  {
    "text": "completing leak code tests meant that they had reasoning capabilities that exceeded developers and he suspected",
    "start": "2307520",
    "end": "2314079"
  },
  {
    "text": "data leakage so what he did is he took puzzles from a website called code forces which also has coding puzzles and",
    "start": "2314079",
    "end": "2321280"
  },
  {
    "text": "what makes code forces amazing for this little experiment is the date that each puzzle is released is clearly",
    "start": "2321280",
    "end": "2327920"
  },
  {
    "text": "stamped so hey took 10 puzzles from the time that gp4 was trained so it should",
    "start": "2327920",
    "end": "2336599"
  },
  {
    "text": "have had access to these puzzles during its training period and when he passed them through",
    "start": "2336599",
    "end": "2343200"
  },
  {
    "text": "the model it got all of them correct then what he did is he got another 10 puzzles of an equivalent",
    "start": "2343200",
    "end": "2349760"
  },
  {
    "text": "level of difficulty but these were only released after the model had finished training and this time it got every",
    "start": "2349760",
    "end": "2355960"
  },
  {
    "text": "single one of them wrong this feels like a data leakage issue right and another",
    "start": "2355960",
    "end": "2361400"
  },
  {
    "text": "researcher s kapore confirmed this by explicitly asking the model about a code",
    "start": "2361400",
    "end": "2367359"
  },
  {
    "text": "for's puzzle that it should have had access to during training and it confirmed that indeed it",
    "start": "2367359",
    "end": "2374040"
  },
  {
    "text": "did so this data leakage problem causes so much confusion when it comes to the",
    "start": "2374040",
    "end": "2380040"
  },
  {
    "text": "assessment of llms and the rot goes deep it even",
    "start": "2380040",
    "end": "2385640"
  },
  {
    "text": "affects benchmarks so a review of more than 100 benchmarks that were used to assess uh a",
    "start": "2385640",
    "end": "2393640"
  },
  {
    "text": "variety of llms was done and at least 100 of them were found to at least",
    "start": "2393640",
    "end": "2401079"
  },
  {
    "text": "partially leaked into chat GPT models you can see that 75 question answering",
    "start": "2401079",
    "end": "2407839"
  },
  {
    "text": "benchmarks alone had leaked and all of the major ways that we used to assess",
    "start": "2407839",
    "end": "2413440"
  },
  {
    "text": "these models things like natural language capabilities things like programming and things like math were",
    "start": "2413440",
    "end": "2421720"
  },
  {
    "text": "affected so this leakage problem is compounded by the fact that the amount",
    "start": "2421720",
    "end": "2427480"
  },
  {
    "text": "of data that we have that's of sufficient quality to train and assess these models is actually a limited",
    "start": "2427480",
    "end": "2433880"
  },
  {
    "text": "resource it's finite and we're close to running out of it so the current wisdom",
    "start": "2433880",
    "end": "2440599"
  },
  {
    "text": "is um about how to make more and more performant models more powerful models",
    "start": "2440599",
    "end": "2445880"
  },
  {
    "text": "are the so-called scaling laws and this is the idea that you just make a bigger",
    "start": "2445880",
    "end": "2451319"
  },
  {
    "text": "model and you feed in more data and we can see the trend right we go from GPT 3",
    "start": "2451319",
    "end": "2457640"
  },
  {
    "text": "in 2020 which was trained with 500 billion per uh tokens up to llama 3 this",
    "start": "2457640",
    "end": "2464319"
  },
  {
    "text": "year which was trained with 15 trillion parameters that is a 30 fold growth in",
    "start": "2464319",
    "end": "2472599"
  },
  {
    "text": "the amount of data used in just four years the issue is that the amount of",
    "start": "2472599",
    "end": "2478839"
  },
  {
    "text": "data that's available for training these models is estimated to top out top out at around",
    "start": "2478839",
    "end": "2485319"
  },
  {
    "text": "300 trillion tokens and if we keep training models at the current rate we're going to run out in",
    "start": "2485319",
    "end": "2493319"
  },
  {
    "text": "potentially a little bit less than a decade maybe in the next 3",
    "start": "2493319",
    "end": "2499079"
  },
  {
    "text": "years now this is data leakage at a level we have never seen it before in machine learning and with so much of the",
    "start": "2499079",
    "end": "2507800"
  },
  {
    "text": "public internet consumed by these models in their varous need for more and more",
    "start": "2507800",
    "end": "2512960"
  },
  {
    "text": "data how can we find clean pieces of data to assess them properly the",
    "start": "2512960",
    "end": "2518520"
  },
  {
    "text": "creators of benchmarks have made moves to keep the current generation of benchmarks private so they will never",
    "start": "2518520",
    "end": "2524440"
  },
  {
    "text": "make it in theory into the training data but for us as lay users how can we tell",
    "start": "2524440",
    "end": "2530280"
  },
  {
    "text": "apart seemingly impressive performance on these models from something it's simply",
    "start": "2530280",
    "end": "2537119"
  },
  {
    "text": "memorized so to end this section on reliability I want to talk about",
    "start": "2537119",
    "end": "2542520"
  },
  {
    "text": "everyone's favorite topic and that is prompt engineering but sadly I'm not",
    "start": "2542520",
    "end": "2548559"
  },
  {
    "text": "going to be able to tell you how to get a million dooll job in silic Valley I'm going to talk about something a bit more",
    "start": "2548559",
    "end": "2554319"
  },
  {
    "text": "depressing and that is prompt sensitivity so we want to classify a",
    "start": "2554319",
    "end": "2561119"
  },
  {
    "text": "piece of text we have a passage of text so we can create a little prompt template for our llm to do this by",
    "start": "2561119",
    "end": "2568119"
  },
  {
    "text": "passing in the passage and then the list of possible categories so nice little",
    "start": "2568119",
    "end": "2573640"
  },
  {
    "text": "template maybe we use this or maybe we use any one of these prompt templates",
    "start": "2573640",
    "end": "2580680"
  },
  {
    "text": "can anyone Spot the Difference between these shout it",
    "start": "2580680",
    "end": "2585720"
  },
  {
    "text": "out yep yep punctuation spacing capitalization you are such great",
    "start": "2588359",
    "end": "2594200"
  },
  {
    "text": "developers very well spotted so these are trivial differences right this is",
    "start": "2594200",
    "end": "2600800"
  },
  {
    "text": "natural language right not programming so we should not expect that these templates have any influence on the",
    "start": "2600800",
    "end": "2607599"
  },
  {
    "text": "performance of our llm well let's see so what this line",
    "start": "2607599",
    "end": "2613559"
  },
  {
    "text": "here represents is the performance of the llm on the task so zero means it got",
    "start": "2613559",
    "end": "2619760"
  },
  {
    "text": "nothing right and one means it got everything right and these tiny",
    "start": "2619760",
    "end": "2625440"
  },
  {
    "text": "insignificant differences between the prom templates led to a",
    "start": "2625440",
    "end": "2632960"
  },
  {
    "text": "77% difference between the best and worst performance form in",
    "start": "2632960",
    "end": "2638920"
  },
  {
    "text": "prompt Jesus indeed now this result is extraordinary if we think back to traditional machine",
    "start": "2638920",
    "end": "2645520"
  },
  {
    "text": "learning if I built a model at work that was so unreliable for basically",
    "start": "2645520",
    "end": "2651559"
  },
  {
    "text": "equivalent inputs I could fired that for like that model would not be usable but this this is unfortunately",
    "start": "2651559",
    "end": "2659720"
  },
  {
    "text": "part of the fabric of llm to hammer this point home this is not an isolated",
    "start": "2659720",
    "end": "2665319"
  },
  {
    "text": "incident in a review of models that were probably Cutting Edge about 6 months ago you can see a similar pattern between 30",
    "start": "2665319",
    "end": "2672960"
  },
  {
    "text": "to 50% difference between the best and worst performing",
    "start": "2672960",
    "end": "2678280"
  },
  {
    "text": "prompts now what makes this more troubling is that there is no Universal",
    "start": "2678280",
    "end": "2683839"
  },
  {
    "text": "prompt template we can't just use one prompt template and get excellent performance out of every single model",
    "start": "2683839",
    "end": "2690319"
  },
  {
    "text": "there is a unique fit between each model and the type of prompts that it likes",
    "start": "2690319",
    "end": "2696160"
  },
  {
    "text": "and what this means is that us as end users probably don't know these ideal prompts and so we're likely getting",
    "start": "2696160",
    "end": "2702319"
  },
  {
    "text": "anything from a little bit worse to maybe significantly worse performance on these models than",
    "start": "2702319",
    "end": "2709680"
  },
  {
    "text": "advertised so as is kind of typical at the end of my talks you may be feeling a",
    "start": "2709680",
    "end": "2714760"
  },
  {
    "text": "little bit depressed now and thinking what's the point why why would I use llms can't even tell if these",
    "start": "2714760",
    "end": "2722200"
  },
  {
    "text": "models are good well I have a potential solution for you there is a silver",
    "start": "2722200",
    "end": "2727520"
  },
  {
    "text": "linning but it's not as sexy as leaderboards and it's not as easy as out of the B box",
    "start": "2727520",
    "end": "2734680"
  },
  {
    "text": "benchmarks it instead is very similar to the way that we've been measuring and",
    "start": "2734680",
    "end": "2740160"
  },
  {
    "text": "monitoring software applications for decades now and in order to illustrate this I",
    "start": "2740160",
    "end": "2748800"
  },
  {
    "text": "want to go through a blog post that I read from an engineer called Hassan Hussein and he talks about his",
    "start": "2748800",
    "end": "2754960"
  },
  {
    "text": "experience with his team building an AI assistant for real estate agents this is a magnificent blog post again it'll be",
    "start": "2754960",
    "end": "2762400"
  },
  {
    "text": "available in the list of resources can't quite cover everything in the last five or 10 minutes that I have but I highly",
    "start": "2762400",
    "end": "2768200"
  },
  {
    "text": "recommend you go away and read about this if you're interested in the topic so Hasan describes how he and his",
    "start": "2768200",
    "end": "2774319"
  },
  {
    "text": "team started the way you would kind of think you should they picked a good model based on leaderboard performance",
    "start": "2774319",
    "end": "2781800"
  },
  {
    "text": "and they covered all the basic use cases for the real estate agents based on prompt engineering",
    "start": "2781800",
    "end": "2788440"
  },
  {
    "text": "worked really well for a little while and then it started showing problems as more and more edge cases came in they",
    "start": "2788440",
    "end": "2794880"
  },
  {
    "text": "scrambled to try and cover them by creating more and more complex prompts and they had no real way of assessing",
    "start": "2794880",
    "end": "2800839"
  },
  {
    "text": "whether it was better so they were doing Vibe checks like maybe it feels a bit better it was a mess so they decided to",
    "start": "2800839",
    "end": "2807960"
  },
  {
    "text": "go back to the drawing board and take up a more systematic approach to",
    "start": "2807960",
    "end": "2814480"
  },
  {
    "text": "assessment so the first thing they introduced was were unit tests and the",
    "start": "2814480",
    "end": "2819880"
  },
  {
    "text": "second thing they started doing was logging traces well well well this feels a lot",
    "start": "2819880",
    "end": "2826640"
  },
  {
    "text": "more like a familiar software engineering problem and less like this esoteric hella swag machine learning",
    "start": "2826640",
    "end": "2834680"
  },
  {
    "text": "magic then they introduced higher level evaluations manual evaluations and ab",
    "start": "2834680",
    "end": "2840079"
  },
  {
    "text": "tests and then they used the findings to incrementally improve their models and",
    "start": "2840079",
    "end": "2845400"
  },
  {
    "text": "built this into a virtuous side where they could rapidly iterate and make small but meaningful changes to",
    "start": "2845400",
    "end": "2851440"
  },
  {
    "text": "their model so let's go through this three levels of assessment that Hassan",
    "start": "2851440",
    "end": "2857640"
  },
  {
    "text": "describes in his blog post and of course first is unit tests so unit tests in h",
    "start": "2857640",
    "end": "2864680"
  },
  {
    "text": "son's um kind of estimation in llm systems work much the same way as they",
    "start": "2864680",
    "end": "2870119"
  },
  {
    "text": "do in traditional software applications so llms like many applications have many",
    "start": "2870119",
    "end": "2876040"
  },
  {
    "text": "user workflow flows and what you want to be able to do is assess whether they're working correctly so for example in this",
    "start": "2876040",
    "end": "2883720"
  },
  {
    "text": "real estate assistant you might have someone asking for a phone number so the",
    "start": "2883720",
    "end": "2888880"
  },
  {
    "text": "workflow that that's going to trigger is that that query or that prompt from the",
    "start": "2888880",
    "end": "2894040"
  },
  {
    "text": "user to the llm will prompt the llm to create a query to the CRM and return the",
    "start": "2894040",
    "end": "2901000"
  },
  {
    "text": "phone number so the answer you want to or the the thing you want to know about this workflow to know it's working",
    "start": "2901000",
    "end": "2906839"
  },
  {
    "text": "correctly is that just the phone number is returned so for example you could do",
    "start": "2906839",
    "end": "2912200"
  },
  {
    "text": "a unit test just checking that an array of one is returned you get a bit more fine tune fine grain but you get the",
    "start": "2912200",
    "end": "2918920"
  },
  {
    "text": "picture this is very familiar territory another thing that hin points",
    "start": "2918920",
    "end": "2924079"
  },
  {
    "text": "out you can do is you can use a different llm the one you're not using to build your system and get it to",
    "start": "2924079",
    "end": "2930440"
  },
  {
    "text": "generate test cases so let's say the workflow that we're trying to assess is",
    "start": "2930440",
    "end": "2936200"
  },
  {
    "text": "retrieving contact information so we can get it to come up with a bunch of fake contacts and fake user prompts and then",
    "start": "2936200",
    "end": "2944079"
  },
  {
    "text": "from that build a variety of tests so something I really need to emphasize here is I'm not advocating to automate",
    "start": "2944079",
    "end": "2952160"
  },
  {
    "text": "the whole thing using llms you still need to write and validate those tests",
    "start": "2952160",
    "end": "2957960"
  },
  {
    "text": "the oldfashioned way although of course you can use coding assistance to do so it's more the idea that you're trying to",
    "start": "2957960",
    "end": "2964680"
  },
  {
    "text": "assess a concrete output of an action produced by your llm and you're also",
    "start": "2964680",
    "end": "2970359"
  },
  {
    "text": "getting a little bit of a helping hand from the llm to generate more test cases",
    "start": "2970359",
    "end": "2975640"
  },
  {
    "text": "and now of course an approach like this has high validity we have well-defined",
    "start": "2975640",
    "end": "2981359"
  },
  {
    "text": "and precise Concepts and by using the llm to generate more test case cases we",
    "start": "2981359",
    "end": "2987480"
  },
  {
    "text": "make that more robust we potentially capture all the different way that users are thinking about that particular",
    "start": "2987480",
    "end": "2994480"
  },
  {
    "text": "concept now the next thing that husin advocates for is getting humans in L Loop and",
    "start": "2994480",
    "end": "3003280"
  },
  {
    "text": "basically what this involves is going to your traces so the traces in the context of",
    "start": "3003280",
    "end": "3008839"
  },
  {
    "text": "an llm application are those complex multistep interactions that llms have",
    "start": "3008839",
    "end": "3015520"
  },
  {
    "text": "with both the end users and other parts of the system so you're probably thinking oh my",
    "start": "3015520",
    "end": "3021680"
  },
  {
    "text": "God this sounds like a lot of work it is but you don't need to evaluate every Trace you need a repres representative",
    "start": "3021680",
    "end": "3028720"
  },
  {
    "text": "sample of how your users are interacting with your system and you also need to just get enough of them to get a feel",
    "start": "3028720",
    "end": "3035799"
  },
  {
    "text": "for whether those workflows are working correctly the good news is is once you",
    "start": "3035799",
    "end": "3041920"
  },
  {
    "text": "have enough of this data you can start automating it to an extent so you can",
    "start": "3041920",
    "end": "3047079"
  },
  {
    "text": "introduce again a different llm and you can get it to start doing the same evaluations and then what you want to",
    "start": "3047079",
    "end": "3053520"
  },
  {
    "text": "make sure is that the assessments that your people have been doing and your llm",
    "start": "3053520",
    "end": "3059720"
  },
  {
    "text": "does converge obviously the gold standard is the manual evaluation and that is you end up with high reliability",
    "start": "3059720",
    "end": "3067720"
  },
  {
    "text": "between your manual and your automated assessments and then of course we have",
    "start": "3067720",
    "end": "3073720"
  },
  {
    "text": "AB testing so once you're ready to go out and show your beautiful application to your customers you can start playing",
    "start": "3073720",
    "end": "3080400"
  },
  {
    "text": "around with a bunch of different conditions maybe you want to try a different llm from the one that you",
    "start": "3080400",
    "end": "3086000"
  },
  {
    "text": "originally implemented maybe you want to mess around with different prompts and maybe you even want to try",
    "start": "3086000",
    "end": "3093400"
  },
  {
    "text": "building a fine tuned model based on the data that you've collected so",
    "start": "3093400",
    "end": "3098559"
  },
  {
    "text": "far now obviously AB testing just like the chatbot Arena has high validity",
    "start": "3098559",
    "end": "3104480"
  },
  {
    "text": "you're testing exactly how your system works with end users possibly also is just a hypothesis",
    "start": "3104480",
    "end": "3111839"
  },
  {
    "text": "I have because you are able to mess around with the prompt l fit that is",
    "start": "3111839",
    "end": "3117760"
  },
  {
    "text": "specific to your users and your llm you might be able to get more reliable outputs from the",
    "start": "3117760",
    "end": "3124240"
  },
  {
    "text": "model so hopefully maybe I've inspired some of you to become llm qas this I",
    "start": "3124240",
    "end": "3130040"
  },
  {
    "text": "think is a viable career for the future so we come to the end of the talk",
    "start": "3130040",
    "end": "3136119"
  },
  {
    "text": "and what we've seen on this journey is the introduction of llms has turned",
    "start": "3136119",
    "end": "3141640"
  },
  {
    "text": "traditional machine learning assessment on its head and attempts to take short Cuts in assessing these complex models",
    "start": "3141640",
    "end": "3149839"
  },
  {
    "text": "has really confused us and widened the gap between assessment and",
    "start": "3149839",
    "end": "3156640"
  },
  {
    "text": "reality along the way in all this confusion we've not really understand the true capabilities of these models",
    "start": "3156640",
    "end": "3163119"
  },
  {
    "text": "and in fact we started creating myths about potential superhuman capabilities",
    "start": "3163119",
    "end": "3168160"
  },
  {
    "text": "that these models have again if you want to hear someone dispelled that that's me",
    "start": "3168160",
    "end": "3173440"
  },
  {
    "text": "um that was my NDC Oslo talk so in reality these models are powerful",
    "start": "3173440",
    "end": "3180440"
  },
  {
    "text": "they have very concrete use cases they are powerful language models and if you",
    "start": "3180440",
    "end": "3186599"
  },
  {
    "text": "want to exploit these powerful capabilities there are no shortcuts when it comes to assessment it's just like",
    "start": "3186599",
    "end": "3192520"
  },
  {
    "text": "it's always been you need to create concrete and well- defined use cases and",
    "start": "3192520",
    "end": "3197640"
  },
  {
    "text": "you need to create and craft and monitor your own bespoke reliable and valid",
    "start": "3197640",
    "end": "3204960"
  },
  {
    "text": "assessments woo wrong way I was so smooth up until then so",
    "start": "3204960",
    "end": "3211400"
  },
  {
    "text": "here we are at the end here is the QR code here are my socials and thank you",
    "start": "3211400",
    "end": "3217240"
  },
  {
    "text": "very much I'll be around for the rest of the conference if you want to catch up and ask any questions thank",
    "start": "3217240",
    "end": "3222330"
  },
  {
    "text": "[Applause] [Music] [Applause]",
    "start": "3222330",
    "end": "3229619"
  },
  {
    "text": "you you liked it thank you you",
    "start": "3230240",
    "end": "3239599"
  }
]
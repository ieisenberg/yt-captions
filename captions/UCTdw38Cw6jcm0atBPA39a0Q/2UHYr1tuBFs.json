[
  {
    "start": "0",
    "end": "60000"
  },
  {
    "text": "hello everyone my name is Chris Ayers and today we're going to be talking a little bit about kubernetes resiliency",
    "start": "900",
    "end": "7980"
  },
  {
    "text": "now I'm a senior customer engineer at Microsoft my role there is I'm part of",
    "start": "7980",
    "end": "13080"
  },
  {
    "text": "the fast track for Azure team so I'm part of azure engineering and one of the things we do is we help customers deploy",
    "start": "13080",
    "end": "18840"
  },
  {
    "text": "Solutions on the Azure and so some of the conversations that I have with",
    "start": "18840",
    "end": "24180"
  },
  {
    "text": "customers sometimes revolve around resiliency with kubernetes through devops through security",
    "start": "24180",
    "end": "31019"
  },
  {
    "text": "um feel free to reach out to me on Twitter Mastodon connect on LinkedIn I blog a",
    "start": "31019",
    "end": "37920"
  },
  {
    "text": "lot about these topics out on my website and all of these slides and all of my other talks are actually available out",
    "start": "37920",
    "end": "43860"
  },
  {
    "text": "on GitHub I'm actually not a big PowerPoint guy anymore so everything is actually marked",
    "start": "43860",
    "end": "51059"
  },
  {
    "text": "down slides running off of GitHub pages that are automatically built off of markdown slides so if you're interested",
    "start": "51059",
    "end": "58020"
  },
  {
    "text": "in them you can go and take a look so today we're going to talk about kubernetes",
    "start": "58020",
    "end": "64860"
  },
  {
    "start": "60000",
    "end": "94000"
  },
  {
    "text": "resiliency from a lot of different levels we're going to start at the bottom looking at infrastructure as far",
    "start": "64860",
    "end": "70200"
  },
  {
    "text": "as like the compute nodes and networking we're going to build up into some of the kubernetes components that a lot of",
    "start": "70200",
    "end": "75360"
  },
  {
    "text": "people are familiar with with you know API server and NCD some additional networking considerations and then",
    "start": "75360",
    "end": "81780"
  },
  {
    "text": "things specific to your applications your services and your workloads",
    "start": "81780",
    "end": "87780"
  },
  {
    "text": "um so we're gonna like this video here take a journey with our containers today",
    "start": "87780",
    "end": "95119"
  },
  {
    "start": "94000",
    "end": "150000"
  },
  {
    "text": "so starting with infrastructure at a high level you know when you're looking at the components that build up your",
    "start": "95520",
    "end": "101460"
  },
  {
    "text": "cluster you're going to have some nodes that handle your control plane you're going to have some nodes that are your",
    "start": "101460",
    "end": "107280"
  },
  {
    "text": "worker nodes you might have storage if you need a staple set or a persistent volume claim you might need a container",
    "start": "107280",
    "end": "113939"
  },
  {
    "text": "registry to you know hold your images and again a load balancer or something",
    "start": "113939",
    "end": "119220"
  },
  {
    "text": "for Network Ingress one of the biggest things people might not always think about are single points",
    "start": "119220",
    "end": "125340"
  },
  {
    "text": "of failure and that can be single points of failure on any of these type of components and one way we can get around",
    "start": "125340",
    "end": "131280"
  },
  {
    "text": "that is leveraging different availability zones and leveraging node pools so I'm going to try to talk about",
    "start": "131280",
    "end": "138000"
  },
  {
    "text": "kubernetes generically some of the examples I'm going to bring up are specific to AKs on Azure but many of",
    "start": "138000",
    "end": "144840"
  },
  {
    "text": "those points will transfer over to something like a gke or an eks",
    "start": "144840",
    "end": "151400"
  },
  {
    "start": "150000",
    "end": "219000"
  },
  {
    "text": "a lot of times you might have single points of failure based on some of your compute notes like potentially you might",
    "start": "151620",
    "end": "158220"
  },
  {
    "text": "not have a lot of nodes of a given node type to run your workloads or your",
    "start": "158220",
    "end": "164580"
  },
  {
    "text": "storage you might be using uh very redundant compute but you might have one",
    "start": "164580",
    "end": "172620"
  },
  {
    "text": "region based storage account or one availability Zone storage account and you can get into some weird spots which",
    "start": "172620",
    "end": "179160"
  },
  {
    "text": "I'll talk about in a moment same with networking your networking like your load balancers or your virtual networks",
    "start": "179160",
    "end": "186200"
  },
  {
    "text": "if they're not like Zone aware or Regional aware you can end up with a",
    "start": "186200",
    "end": "191519"
  },
  {
    "text": "case where some of your compute can still be running and then you have some weird behaviors so we'll talk about those but at an underlying",
    "start": "191519",
    "end": "198180"
  },
  {
    "text": "infrastructure level you want to make sure that you have distributed your workloads and your your nodes like",
    "start": "198180",
    "end": "204180"
  },
  {
    "text": "across as many places as you can so you're running multiple nodes you're trying to run multiple availability",
    "start": "204180",
    "end": "209879"
  },
  {
    "text": "zones potentially multiple regions and if you do have to use multiple custom clusters you can use stuff like",
    "start": "209879",
    "end": "216300"
  },
  {
    "text": "Federation So speaking of availability zones this",
    "start": "216300",
    "end": "222599"
  },
  {
    "start": "219000",
    "end": "408000"
  },
  {
    "text": "is when I talk about availability zones this is pretty much like a diagram of how Azure does availability zones AWS",
    "start": "222599",
    "end": "230040"
  },
  {
    "text": "and Google and I'm sure some of the other clouds do the same thing if you're building your own",
    "start": "230040",
    "end": "236220"
  },
  {
    "text": "offline kubernetes solution essentially an availability zone is a one or more",
    "start": "236220",
    "end": "242879"
  },
  {
    "text": "data centers that have pretty much independent Network Power and cooling so",
    "start": "242879",
    "end": "249659"
  },
  {
    "text": "inside of a region in Azure for instance we usually have two or three availability zones that are all",
    "start": "249659",
    "end": "256380"
  },
  {
    "text": "independent but they have links to each other that are very high speed and so many of our services in azure are Zone",
    "start": "256380",
    "end": "264000"
  },
  {
    "text": "aware which means you can say I would like a storage account that is going to",
    "start": "264000",
    "end": "269400"
  },
  {
    "text": "run an instance in each availability zone so I'm going to have three instances of it across all three availability zones and so if",
    "start": "269400",
    "end": "275820"
  },
  {
    "text": "availability Zone 3 goes out there's a copy of it still in two and a copy of it still in one",
    "start": "275820",
    "end": "282180"
  },
  {
    "text": "the reason that's very important is if you don't have a Zone awareness or availability Zone awareness and you just",
    "start": "282180",
    "end": "289080"
  },
  {
    "text": "have some compute running in maybe one data center that goes out but you have",
    "start": "289080",
    "end": "296100"
  },
  {
    "text": "Network and storage running just fine in a different data center you're still down so you need to make sure that when",
    "start": "296100",
    "end": "302880"
  },
  {
    "text": "you're talking about Zone aware Services something like your container Registries if your container Registries in a lot of",
    "start": "302880",
    "end": "309120"
  },
  {
    "text": "cases you can do Zone aware so you can have copies of it in all three availability zones just like you can",
    "start": "309120",
    "end": "314699"
  },
  {
    "text": "with your load balancers with your storage accounts with your compute nodes and so that is a huge thing that really",
    "start": "314699",
    "end": "321600"
  },
  {
    "text": "will help drive without dealing with multi-region and multi-cloud just a high",
    "start": "321600",
    "end": "327960"
  },
  {
    "text": "level of availability with very low overhead and low cost when you're dealing with a managed kubernetes",
    "start": "327960",
    "end": "335940"
  },
  {
    "text": "um because you're starting to run multiple nodes or you're trying to go into multiple regions or availability",
    "start": "335940",
    "end": "342900"
  },
  {
    "text": "zones there is a feature of kubernetes called the topology spread constraints and this actually lets you very",
    "start": "342900",
    "end": "350280"
  },
  {
    "text": "fine tune how you want your workload spread across nodes",
    "start": "350280",
    "end": "357060"
  },
  {
    "text": "um this lets you choose like hey I want two in this region or this Zone and one",
    "start": "358139",
    "end": "363720"
  },
  {
    "text": "there it lets you kind of manipulate how things get distributed as they the load",
    "start": "363720",
    "end": "369720"
  },
  {
    "text": "increases and the number of PODS increase so if you need like two or three instances in the East two or three",
    "start": "369720",
    "end": "375479"
  },
  {
    "text": "instances in west but you only care if there's one or two entrances in central U.S you can kind of uh choose like",
    "start": "375479",
    "end": "382919"
  },
  {
    "text": "what's your Mac SKU what's the max difference you're allowed or what's the minimum number of nodes that need to be",
    "start": "382919",
    "end": "388440"
  },
  {
    "text": "running in a given availability zone or in a given node pool and so this can",
    "start": "388440",
    "end": "394800"
  },
  {
    "text": "give you some some great control if you need to fine tune it out of the box it usually works pretty well but there are",
    "start": "394800",
    "end": "400919"
  },
  {
    "text": "some chances for you to influence that if you so choose",
    "start": "400919",
    "end": "407060"
  },
  {
    "start": "408000",
    "end": "509000"
  },
  {
    "text": "that brings me up to node pools so node pools are a great way to group work",
    "start": "409919",
    "end": "416340"
  },
  {
    "text": "nodes of identical configuration you know this lets you independently scale",
    "start": "416340",
    "end": "422300"
  },
  {
    "text": "these groups as needed you might need some worker nodes that only have a you",
    "start": "422300",
    "end": "429060"
  },
  {
    "text": "know compute you might have some jobs that need GPU so it's a cost saving measure where you don't want to",
    "start": "429060",
    "end": "435180"
  },
  {
    "text": "potentially just have GPU enabled nodes everywhere because then you're spending",
    "start": "435180",
    "end": "440400"
  },
  {
    "text": "all this extra money for workloads that don't need it lets you scale them independently but it also lets you",
    "start": "440400",
    "end": "446599"
  },
  {
    "text": "isolate things your worker nodes can be also Zone aware where you can distribute",
    "start": "446599",
    "end": "451800"
  },
  {
    "text": "the VMS underlying the nodes across those availability zones across regions",
    "start": "451800",
    "end": "457020"
  },
  {
    "text": "and so that you can handle fault tolerances better it also gives you some capabilities and",
    "start": "457020",
    "end": "463979"
  },
  {
    "text": "upgrade capability so if you need to do some upgrades and you can you can do it in one node pool at a time rather than",
    "start": "463979",
    "end": "471180"
  },
  {
    "text": "try to do the whole cluster so it lets you have a little bit of isolation now one thing that you can leverage of",
    "start": "471180",
    "end": "478319"
  },
  {
    "text": "kubernetes to help with this is the taints and tolerations so you can put like a toleration for GPU or a taint you",
    "start": "478319",
    "end": "486780"
  },
  {
    "text": "can try to move workloads around so that they're only running on the Node pools that need the capabilities found there",
    "start": "486780",
    "end": "494340"
  },
  {
    "text": "or you can actually move workloads so that they're not running like one that's very CPU intensive or network intensive",
    "start": "494340",
    "end": "501120"
  },
  {
    "text": "that could potentially cause an issue with its neighbors you can move it to a different node pool so that it has the",
    "start": "501120",
    "end": "507360"
  },
  {
    "text": "resources it needs um specific to Azure and specific to AKs",
    "start": "507360",
    "end": "515719"
  },
  {
    "text": "Azure for instance manages the control plane so the control plane components",
    "start": "515719",
    "end": "521459"
  },
  {
    "text": "those are automatically managed for you the API server at CD the cube controller manager Cube scheduler all those are",
    "start": "521459",
    "end": "529320"
  },
  {
    "text": "managed on you know Azure run VMS Azure manages them there is an option when you",
    "start": "529320",
    "end": "535620"
  },
  {
    "text": "create AKs where you can say use a uptime SLA and it'll actually increase",
    "start": "535620",
    "end": "543120"
  },
  {
    "text": "you from like I think three nines to four nines it's a low-cost thing at like",
    "start": "543120",
    "end": "549360"
  },
  {
    "text": "cluster creation time but when you first create a cluster in Azure for instance or in many of the other clouds I think",
    "start": "549360",
    "end": "556200"
  },
  {
    "text": "gke and eks do it they'll create a system node pool and this is where some of the other components of a kubernetes",
    "start": "556200",
    "end": "563880"
  },
  {
    "text": "cluster run like core DNS or maybe the metric server for Azure there's also AKs link or",
    "start": "563880",
    "end": "571500"
  },
  {
    "text": "tunnel front because of how we do networking and some of our agents but",
    "start": "571500",
    "end": "576600"
  },
  {
    "text": "the reason that's important is you want to isolate if you can some of",
    "start": "576600",
    "end": "582360"
  },
  {
    "text": "those system level components from all of your user workloads in Azure we usually recommend have two or three",
    "start": "582360",
    "end": "589019"
  },
  {
    "text": "nodes of like just a generic four core machine just dedicated to the system components",
    "start": "589019",
    "end": "594959"
  },
  {
    "text": "you know like handling your DNS so that you can find the various components and handling Ingress better",
    "start": "594959",
    "end": "602339"
  },
  {
    "text": "um the first thing we usually tell customers is make a second pool make a",
    "start": "602339",
    "end": "607920"
  },
  {
    "text": "user pool add the proper taints that you need to to the system pool so nothing else will run on it and then you can you",
    "start": "607920",
    "end": "615540"
  },
  {
    "text": "know build workloads as you need from your user pools um in this example as I've pointed out",
    "start": "615540",
    "end": "621779"
  },
  {
    "text": "you know we've got Q proxy and cubenet running on our our different pools and I maybe made a new GPU specific node pool",
    "start": "621779",
    "end": "629160"
  },
  {
    "text": "just for some of my machine learning workloads so separating out the system stuff from",
    "start": "629160",
    "end": "635519"
  },
  {
    "text": "the user stuff helps you have better uptime if you start overloading uh the",
    "start": "635519",
    "end": "640620"
  },
  {
    "text": "system pools and you you're running into problems with DNS that can handle resolution issues and that can cause",
    "start": "640620",
    "end": "646680"
  },
  {
    "text": "uptime problems so at the infrastructure level one of",
    "start": "646680",
    "end": "652019"
  },
  {
    "start": "648000",
    "end": "715000"
  },
  {
    "text": "the things I recommend is regular review what you're doing monitor your usage",
    "start": "652019",
    "end": "657839"
  },
  {
    "text": "always have monitoring if if it's running you should know how it's running like you should know if you're having",
    "start": "657839",
    "end": "663920"
  },
  {
    "text": "spikes you should know if you're having dips you should know if you're having problems you can leverage Auto scaling",
    "start": "663920",
    "end": "670019"
  },
  {
    "text": "most Cloud support cluster Auto scaler so you can add more nodes as needed if",
    "start": "670019",
    "end": "675060"
  },
  {
    "text": "you need to if you have some uncertainty around your workloads pretty much every cloud has some method of supporting",
    "start": "675060",
    "end": "681600"
  },
  {
    "text": "infrastructure as code have a repeatable process for building your infrastructure some way that you",
    "start": "681600",
    "end": "689040"
  },
  {
    "text": "can build up a second cluster have a disaster recovery plan or a backup plan",
    "start": "689040",
    "end": "694680"
  },
  {
    "text": "like we know the code is in repos and we can redeploy it a lot of times your data",
    "start": "694680",
    "end": "700079"
  },
  {
    "text": "is backed up but the configuration you're leveraging you also need a way to deal that if it's",
    "start": "700079",
    "end": "706079"
  },
  {
    "text": "um get Ops if it's help charts whatever you're using have some way of",
    "start": "706079",
    "end": "711500"
  },
  {
    "text": "recreating your environment and your configuration All Right Moving On",
    "start": "711500",
    "end": "718440"
  },
  {
    "start": "715000",
    "end": "726000"
  },
  {
    "text": "kubernetes components so I've talked about them a little bit at a high level we've got some that you",
    "start": "718440",
    "end": "724800"
  },
  {
    "text": "know like I said live on the control plane some that live on the nodes when we're talking about the control plane components if you're running your",
    "start": "724800",
    "end": "732420"
  },
  {
    "text": "own clusters if we're not talking about a managed AKs or eks or gke you want to have more than one instance",
    "start": "732420",
    "end": "741360"
  },
  {
    "text": "of your control plane nodes like masternodes so for your cluster you want",
    "start": "741360",
    "end": "746940"
  },
  {
    "text": "to have multiple instances of API server this is the thing that responds to all",
    "start": "746940",
    "end": "752100"
  },
  {
    "text": "those requests from cubectl and Helm you want to have multiple copies of edcd",
    "start": "752100",
    "end": "757620"
  },
  {
    "text": "that's backed up regularly this is the state of your system you want to make sure you have an odd number so that if",
    "start": "757620",
    "end": "764820"
  },
  {
    "text": "there's some sort of contention there will be quorum um you want to have multiple instances",
    "start": "764820",
    "end": "771180"
  },
  {
    "text": "of the scheduler you want to make sure that you guys have ways to restart things on failure",
    "start": "771180",
    "end": "779660"
  },
  {
    "text": "you know and same with if you're running your own nodes and you're setting these things up yourselves",
    "start": "780060",
    "end": "786240"
  },
  {
    "text": "um on each machine you want to make sure that there's restart you have logging you have monitoring that you have of",
    "start": "786240",
    "end": "792000"
  },
  {
    "text": "runtime that um can support all of the capabilities you're looking at",
    "start": "792000",
    "end": "797700"
  },
  {
    "text": "so just rehashing like enabling leader election having",
    "start": "797700",
    "end": "803880"
  },
  {
    "text": "multiple instances regular backups monitoring automatic restart",
    "start": "803880",
    "end": "810019"
  },
  {
    "text": "you definitely want to make sure that your run times whether it's containerdy or cryo or podman whatever you're using",
    "start": "810019",
    "end": "817399"
  },
  {
    "text": "supports High availability a lot of this is handled for you in most",
    "start": "817399",
    "end": "822959"
  },
  {
    "text": "systems once you've kind of built it out but if if you're having weird problems always",
    "start": "822959",
    "end": "828000"
  },
  {
    "text": "double check these things",
    "start": "828000",
    "end": "831019"
  },
  {
    "text": "and if I just throw a little fun up there A lot of times we're using other type of",
    "start": "834060",
    "end": "839940"
  },
  {
    "text": "add-ons uh you know we're trying to do uh Ingress controllers or service meshes",
    "start": "839940",
    "end": "846540"
  },
  {
    "text": "or just support PODS of some kind never deploy a naked pot just a pod by itself",
    "start": "846540",
    "end": "852920"
  },
  {
    "text": "it has no resiliency you can kill it it won't come back if you're going to deploy workloads if",
    "start": "852920",
    "end": "860220"
  },
  {
    "text": "you're going to deploy add-ons if you're going to deploy things that you are leveraging as services that you are",
    "start": "860220",
    "end": "866639"
  },
  {
    "text": "leveraging to support your cluster use deployments use replica sets use",
    "start": "866639",
    "end": "871860"
  },
  {
    "text": "something that will enforce a minimum number of instances that will restart things",
    "start": "871860",
    "end": "877500"
  },
  {
    "text": "use the tools of the system to make sure that they are running properly",
    "start": "877500",
    "end": "884660"
  },
  {
    "text": "all right now I mentioned on our service nodes",
    "start": "887820",
    "end": "892920"
  },
  {
    "start": "888000",
    "end": "981000"
  },
  {
    "text": "that we're talking about isolating core DNS and some of those other services that run the reason",
    "start": "892920",
    "end": "899639"
  },
  {
    "text": "that's very important is service Discovery a lot of times we're trying to",
    "start": "899639",
    "end": "905339"
  },
  {
    "text": "discover our other nodes we're trying to Route things networking is usually a pain point for a",
    "start": "905339",
    "end": "912720"
  },
  {
    "text": "lot of developers a lot of operators that go into the kubernetes space understanding your IP ranges",
    "start": "912720",
    "end": "918860"
  },
  {
    "text": "understanding how many IPS how many networks that you have to work",
    "start": "918860",
    "end": "925199"
  },
  {
    "text": "with planning those effectively if especially if you're dealing with a high workload",
    "start": "925199",
    "end": "931579"
  },
  {
    "text": "system is very important so I've listed a couple of topics here that",
    "start": "931579",
    "end": "938459"
  },
  {
    "text": "that just need to be considered as you're planning a resilient system again service",
    "start": "938459",
    "end": "945240"
  },
  {
    "text": "Discovery load balancing whether this is done inside your cluster or outside your",
    "start": "945240",
    "end": "950399"
  },
  {
    "text": "cluster for a lot of services if it's outside your cluster you know multiple regions or multiple",
    "start": "950399",
    "end": "956940"
  },
  {
    "text": "availability zones have that enforced if you're doing it inside your cluster make sure you're doing you know replicas",
    "start": "956940",
    "end": "963420"
  },
  {
    "text": "deployment sets and policies",
    "start": "963420",
    "end": "968699"
  },
  {
    "text": "make sure that you account for the right policies as you're trying to limit communication or enable communication",
    "start": "968699",
    "end": "976560"
  },
  {
    "text": "now the final one for Ingress controllers these are two very important topics so I kind of broke them out",
    "start": "976560",
    "end": "983839"
  },
  {
    "start": "981000",
    "end": "1112000"
  },
  {
    "text": "independently rate limiting and circuit breaking both of these are topics that are not",
    "start": "983839",
    "end": "990600"
  },
  {
    "text": "always considered but you really should keep in mind for resilient systems so in",
    "start": "990600",
    "end": "996600"
  },
  {
    "text": "America we have Black Friday which is you know one of our biggest shopping days of the",
    "start": "996600",
    "end": "1002180"
  },
  {
    "text": "year and usually all this traffic starts coming to websites to you know buy",
    "start": "1002180",
    "end": "1008600"
  },
  {
    "text": "things look for things refresh see where the sales are um you know we love our consumerism",
    "start": "1008600",
    "end": "1015740"
  },
  {
    "text": "you know that's where rate limiting comes in you know you're getting ddos's you're getting just massive traffic of",
    "start": "1015740",
    "end": "1021680"
  },
  {
    "text": "uh surge of traffic so leveraging rate limits can help keep some systems alive",
    "start": "1021680",
    "end": "1028120"
  },
  {
    "text": "to handle some traffic it can give the system time to scale if",
    "start": "1028120",
    "end": "1033860"
  },
  {
    "text": "you're leveraging some scaling so always implementing some sort of rate",
    "start": "1033860",
    "end": "1039620"
  },
  {
    "text": "limiting and one way that you can help determine that is doing regular load testing or even chaos testing against",
    "start": "1039620",
    "end": "1046520"
  },
  {
    "text": "your cluster so that you can accurately know what your traffic shape looks like and load looks like and and",
    "start": "1046520",
    "end": "1053720"
  },
  {
    "text": "adjust appropriately the other one is circuit breaking so",
    "start": "1053720",
    "end": "1059200"
  },
  {
    "text": "many times if someone like in e-commerce systems where I've worked sometimes",
    "start": "1059200",
    "end": "1064640"
  },
  {
    "text": "there's a Cascade of things requests come in people are trying to add stuff to carts they're trying to place orders",
    "start": "1064640",
    "end": "1069980"
  },
  {
    "text": "and something fails and it just starts like knocking down systems like dominoes this is where you start implementing",
    "start": "1069980",
    "end": "1076220"
  },
  {
    "text": "things like circuit breaker patterns where you start seeing errors and you can disable parts of the system so maybe",
    "start": "1076220",
    "end": "1082039"
  },
  {
    "text": "you can disable like a recommendation engine if it's just spamming the",
    "start": "1082039",
    "end": "1087440"
  },
  {
    "text": "database like crazy because everyone's trying to get recommendations it could disable that turn that off or if you're",
    "start": "1087440",
    "end": "1093440"
  },
  {
    "text": "starting to see payment errors you stop other people from seeing payment errors and they start getting messages like",
    "start": "1093440",
    "end": "1099380"
  },
  {
    "text": "please wait a while come back later some something like that it allows you to to fail and cut off some of the traffic",
    "start": "1099380",
    "end": "1105980"
  },
  {
    "text": "without just retrying and spamming and causing this massive Cascade",
    "start": "1105980",
    "end": "1112960"
  },
  {
    "start": "1112000",
    "end": "1168000"
  },
  {
    "text": "now I mentioned it on the system pool again the metric server so there is a",
    "start": "1114260",
    "end": "1121640"
  },
  {
    "text": "reference implementation of the metrics API in kubernetes it's called the metric",
    "start": "1121640",
    "end": "1127220"
  },
  {
    "text": "server this generates some just very high level statistics about how the pods",
    "start": "1127220",
    "end": "1132980"
  },
  {
    "text": "are running so you're getting CPU stats and memory stats for different pod executions",
    "start": "1132980",
    "end": "1138860"
  },
  {
    "text": "it's quite important if you don't have one that you have one on your cluster the reason this is important is this",
    "start": "1138860",
    "end": "1145580"
  },
  {
    "text": "data and you can you can get it from the generic metric server you can use something like a Prometheus there's a",
    "start": "1145580",
    "end": "1151400"
  },
  {
    "text": "number of different options out there for generating the metrics needed but uh",
    "start": "1151400",
    "end": "1158240"
  },
  {
    "text": "this or some of the other ones can do the the custom metrics apis",
    "start": "1158240",
    "end": "1164539"
  },
  {
    "text": "and what those will do is those actually feed data into",
    "start": "1164539",
    "end": "1170559"
  },
  {
    "text": "some of the topics we're going to talk about next the horizontal pod Auto scaler and and cada and some of those",
    "start": "1170559",
    "end": "1176840"
  },
  {
    "text": "things so the horizontal pod Auto scaler it",
    "start": "1176840",
    "end": "1184700"
  },
  {
    "start": "1179000",
    "end": "1302000"
  },
  {
    "text": "uses the metrics from that metric system",
    "start": "1184700",
    "end": "1189860"
  },
  {
    "text": "this will help and this is where we've talked about having multiple nodes this",
    "start": "1189860",
    "end": "1194960"
  },
  {
    "text": "is where we've talked about making sure we're over different availability zones or how we scale out where nodes are",
    "start": "1194960",
    "end": "1202280"
  },
  {
    "text": "placed this lets us handle traffic spikes so if you defined five instances of your",
    "start": "1202280",
    "end": "1208940"
  },
  {
    "text": "deployment or your replica set with the auto scaler you can increase that automatically based on CPU or based on",
    "start": "1208940",
    "end": "1216620"
  },
  {
    "text": "memory it can pay attention to those metrics and know oh these nodes are",
    "start": "1216620",
    "end": "1221840"
  },
  {
    "text": "getting or these workloads are being overused these pods are handling enough",
    "start": "1221840",
    "end": "1227000"
  },
  {
    "text": "traffic we need to increase the number of PODS to lower that or hey we have all of these instances",
    "start": "1227000",
    "end": "1233960"
  },
  {
    "text": "our traffic is backed off we can bring it back down and and scale down to be more efficient",
    "start": "1233960",
    "end": "1241880"
  },
  {
    "text": "um so this is one of those things that will help you have more resilient",
    "start": "1241880",
    "end": "1247700"
  },
  {
    "text": "applications because if you you're not always on the git repo you're not always on the command line ready to scale",
    "start": "1247700",
    "end": "1254720"
  },
  {
    "text": "something up this is not a silver bullet though scaling is not instant you can't just go",
    "start": "1254720",
    "end": "1261320"
  },
  {
    "text": "hey I'm going to set everything to one replica and set it to Auto scale and I'll be fine one you should if you're",
    "start": "1261320",
    "end": "1267980"
  },
  {
    "text": "billing resilient systems never have one instance always have multiple usually the answer",
    "start": "1267980",
    "end": "1273440"
  },
  {
    "text": "is I have at least three you know you're updating one you're rebooting one and you're serving traffic",
    "start": "1273440",
    "end": "1278780"
  },
  {
    "text": "with one some something like that you always want at least three instances of something",
    "start": "1278780",
    "end": "1284480"
  },
  {
    "text": "but the horizontal pod Auto scaler is a great application that will help with",
    "start": "1284480",
    "end": "1290059"
  },
  {
    "text": "those workloads but it doesn't respond to everything it's kind of limited in what it can scale on and that's one",
    "start": "1290059",
    "end": "1295700"
  },
  {
    "text": "reason why I'm sure you've heard from some of the other speakers about things like Dapper or container apps",
    "start": "1295700",
    "end": "1302980"
  },
  {
    "start": "1302000",
    "end": "1371000"
  },
  {
    "text": "that you know a lot of times people have started to look at stuff like cada so",
    "start": "1302980",
    "end": "1308000"
  },
  {
    "text": "the kubernetes event Driven Auto scaler this adds support for additional data",
    "start": "1308000",
    "end": "1316220"
  },
  {
    "text": "sources to feed into the auto scaler so it can hook into like a service bus",
    "start": "1316220",
    "end": "1322460"
  },
  {
    "text": "or an event grid and if you're seeing tons of messages and traffic come in it",
    "start": "1322460",
    "end": "1327740"
  },
  {
    "text": "can go through some calculation hey we have 10 000 messages coming in we have",
    "start": "1327740",
    "end": "1333380"
  },
  {
    "text": "three instances we need to scale up to X to support that traffic effectively",
    "start": "1333380",
    "end": "1340299"
  },
  {
    "text": "cada supports everything from Kafka to rabbitmq it can scale down to zero it",
    "start": "1340299",
    "end": "1347360"
  },
  {
    "text": "can scale back up um I'll I'm going to go to some websites we're going to show some of the the",
    "start": "1347360",
    "end": "1353480"
  },
  {
    "text": "different projects I'm bringing I'm talking about towards the end but uh Kata is I think it's a cncf",
    "start": "1353480",
    "end": "1363559"
  },
  {
    "text": "one I'm pretty sure I could be wrong um but it's a it's a great project to",
    "start": "1363559",
    "end": "1370039"
  },
  {
    "text": "look into okay another topic that I think is very",
    "start": "1370039",
    "end": "1376580"
  },
  {
    "start": "1371000",
    "end": "1469000"
  },
  {
    "text": "important that not everyone considers is POD disruption budgets who's a fan of",
    "start": "1376580",
    "end": "1382460"
  },
  {
    "text": "prod disruption budgets I don't see a lot of hands okay I see a",
    "start": "1382460",
    "end": "1387919"
  },
  {
    "text": "couple and I'm not fully blind just a little bit blind um so pod disruption budgets are",
    "start": "1387919",
    "end": "1394640"
  },
  {
    "text": "something you can find at a pod level at a cluster level you can say I need a",
    "start": "1394640",
    "end": "1399679"
  },
  {
    "text": "certain number available or I need a limited number unavailable so you can",
    "start": "1399679",
    "end": "1407480"
  },
  {
    "text": "do it both ways and one of the things that this will help feed is it will help",
    "start": "1407480",
    "end": "1413179"
  },
  {
    "text": "you when you're doing upgrades so it can make sure that new instances are spun up effectively so that you have a the",
    "start": "1413179",
    "end": "1419360"
  },
  {
    "text": "minimum number required if there's no damages it'll help spin up new instances",
    "start": "1419360",
    "end": "1425059"
  },
  {
    "text": "quicker it is this is also not a silver bullet there are issues with this this",
    "start": "1425059",
    "end": "1431900"
  },
  {
    "text": "can cause some weird issues with updates or delays or some some operations that",
    "start": "1431900",
    "end": "1437840"
  },
  {
    "text": "you do because the Pod disruption budget might try to block it to keep a certain number of instances in place if maybe",
    "start": "1437840",
    "end": "1444140"
  },
  {
    "text": "one of your nodes is down it also will not prevent things if you go in there and say delete",
    "start": "1444140",
    "end": "1451700"
  },
  {
    "text": "the replica set or delete the thing well that's an admin action it'll just take it down so it's not going to stop you",
    "start": "1451700",
    "end": "1457820"
  },
  {
    "text": "from from malicious States and it's not going to stop you from weird behavior",
    "start": "1457820",
    "end": "1463580"
  },
  {
    "text": "that you might cause yourself",
    "start": "1463580",
    "end": "1467440"
  },
  {
    "start": "1469000",
    "end": "1625000"
  },
  {
    "text": "this is another pretty contentious Topic in it we might just take a little while",
    "start": "1471679",
    "end": "1476720"
  },
  {
    "text": "to chat about it resource requests and resource limits",
    "start": "1476720",
    "end": "1485240"
  },
  {
    "text": "so I'm going to just step here for a minute so I can see who likes resource limits",
    "start": "1485240",
    "end": "1493100"
  },
  {
    "text": "I see some hands we're going to have fun who likes resource requests I see more hands",
    "start": "1493100",
    "end": "1500600"
  },
  {
    "text": "if anyone is willing or or brave enough why do you like resource limits",
    "start": "1500600",
    "end": "1508360"
  },
  {
    "text": "okay let's break it up okay so limits like if you don't specify a",
    "start": "1509720",
    "end": "1516320"
  },
  {
    "text": "request and you just specify a limit of like let's say 100 Megs",
    "start": "1516320",
    "end": "1521900"
  },
  {
    "text": "and your app spins up and it starts doing stuff and it hits like 101 Megs it'll probably be almost instantly",
    "start": "1521900",
    "end": "1527000"
  },
  {
    "text": "killed off and then restart again because limits are usually a very hard",
    "start": "1527000",
    "end": "1533539"
  },
  {
    "text": "line like if you exceed it um you're going to be terminated and",
    "start": "1533539",
    "end": "1539000"
  },
  {
    "text": "evicted and like made room for CPU is a little different you'll just be throttled down but like memory is a",
    "start": "1539000",
    "end": "1546620"
  },
  {
    "text": "little bit more difficult um requests are nice because that is a",
    "start": "1546620",
    "end": "1552740"
  },
  {
    "text": "hint to the scheduler it knows hey this pod needs a hundred this pod needs 100",
    "start": "1552740",
    "end": "1558200"
  },
  {
    "text": "this now pod needs a hundred that one needs 300 I've got",
    "start": "1558200",
    "end": "1563419"
  },
  {
    "text": "um 400 Megs available on this node I can put these three there or I could put this three in that one and and they",
    "start": "1563419",
    "end": "1569419"
  },
  {
    "text": "should be okay those are the requests they have if you put the limits it's just a little bit it it can really",
    "start": "1569419",
    "end": "1577580"
  },
  {
    "text": "be bad and you get into this allocation eviction allocation eviction cycle that",
    "start": "1577580",
    "end": "1584360"
  },
  {
    "text": "is just nothing but pain usually the requests are sufficient for most",
    "start": "1584360",
    "end": "1591080"
  },
  {
    "text": "everything you need it is the minimum that you're going to need usually maybe",
    "start": "1591080",
    "end": "1597860"
  },
  {
    "text": "the average you're going to need but limits can be a lot more painful and",
    "start": "1597860",
    "end": "1603679"
  },
  {
    "text": "will uh if you do a lot of big requests and",
    "start": "1603679",
    "end": "1608960"
  },
  {
    "text": "there aren't nodes to support it you might just not be scheduled and so that's where you can do like the auto scaler to add additional nodes or you",
    "start": "1608960",
    "end": "1617900"
  },
  {
    "text": "can look at stuff with resource limits it'll just start killing stuff and then try to reschedule them and kill them and reschedule them and it's a whole",
    "start": "1617900",
    "end": "1624200"
  },
  {
    "text": "different problem but that leads to quality of services so I wanted this gets assigned to your",
    "start": "1624200",
    "end": "1631220"
  },
  {
    "start": "1625000",
    "end": "1726000"
  },
  {
    "text": "pods as you create them and schedule them so if every single container in your pod",
    "start": "1631220",
    "end": "1638740"
  },
  {
    "text": "has memory and CPU limits and they're all equal",
    "start": "1638740",
    "end": "1644260"
  },
  {
    "text": "they have what's called a guaranteed class of service now if you have like two or three",
    "start": "1644260",
    "end": "1650179"
  },
  {
    "text": "containers like you have some side cars or ambassadors in your pod and one of them",
    "start": "1650179",
    "end": "1656120"
  },
  {
    "text": "has a memory or CPU request or limit it's called burstable so it knows that",
    "start": "1656120",
    "end": "1661580"
  },
  {
    "text": "something about the scheduling but not a lot and if you don't have anything any sort of limits at all in",
    "start": "1661580",
    "end": "1668480"
  },
  {
    "text": "your system it's just best effort and so what happens if you start loading up your nodes with pods and you start",
    "start": "1668480",
    "end": "1675500"
  },
  {
    "text": "running out of memory or CPU and it need it has all this pressure that it's trying to clear maybe evicting something",
    "start": "1675500",
    "end": "1681140"
  },
  {
    "text": "or killing something off it's going to start with the pods that have no limits",
    "start": "1681140",
    "end": "1687559"
  },
  {
    "text": "or requests at all it's going to start with those because those are best effort then it's gonna after it evicts some of",
    "start": "1687559",
    "end": "1693919"
  },
  {
    "text": "those it'll go to burstable ones and the last ones that usually will take out are the ones with the the requests and",
    "start": "1693919",
    "end": "1699679"
  },
  {
    "text": "limits so it's something to keep in mind as you are designing your clusters for",
    "start": "1699679",
    "end": "1705679"
  },
  {
    "text": "workloads like things to add to your applications to help ensure that they're there if you're adding your pod",
    "start": "1705679",
    "end": "1712340"
  },
  {
    "text": "disruption budgets if you're adding your requests that can make your applications run more reliably because they're not",
    "start": "1712340",
    "end": "1718640"
  },
  {
    "text": "going to be evicted they're not going to be terminated as often it's good stuff",
    "start": "1718640",
    "end": "1725500"
  },
  {
    "start": "1726000",
    "end": "1849000"
  },
  {
    "text": "which brings me to liveness and Readiness probes another thing that should be on every pod for",
    "start": "1727760",
    "end": "1735860"
  },
  {
    "text": "the most part now a lot of people who design software",
    "start": "1735860",
    "end": "1741100"
  },
  {
    "text": "sometimes they'll put them together in one endpoint so you have one endpoint",
    "start": "1741100",
    "end": "1746720"
  },
  {
    "text": "to say are you okay please don't do that don't don't do that",
    "start": "1746720",
    "end": "1753620"
  },
  {
    "text": "have a separate endpoint for liveness and a separate endpoint for Readiness so",
    "start": "1753620",
    "end": "1759620"
  },
  {
    "text": "I'm alive I'm running I'm you know I'm here",
    "start": "1759620",
    "end": "1766700"
  },
  {
    "text": "versus I have loaded my caches I've run my queries I am ready to serve traffic",
    "start": "1766700",
    "end": "1774039"
  },
  {
    "text": "there's a distinction you know that that you've turned on your computer and you",
    "start": "1774039",
    "end": "1779179"
  },
  {
    "text": "see the BIOS screen but you're not at your desktop yet it's on it's not ready",
    "start": "1779179",
    "end": "1785240"
  },
  {
    "text": "so you need to have that distinction another thing that you can leverage besides just the liveness is Readiness",
    "start": "1785240",
    "end": "1790580"
  },
  {
    "text": "probes is there are some some signals and some hooks you can deal with uh",
    "start": "1790580",
    "end": "1796640"
  },
  {
    "text": "instead of just like instantly dying uh you can get like a pre-stop message",
    "start": "1796640",
    "end": "1801799"
  },
  {
    "text": "where you can still handle traffic a little bit like on shutdown and stuff",
    "start": "1801799",
    "end": "1806980"
  },
  {
    "text": "like look at the life cycle of PODS make sure that you're building in the probes",
    "start": "1806980",
    "end": "1812840"
  },
  {
    "text": "another thing is don't consider your dependencies really",
    "start": "1812840",
    "end": "1820240"
  },
  {
    "text": "implement retries or short circuits if you can't start up till your",
    "start": "1820240",
    "end": "1827539"
  },
  {
    "text": "dependencies like you could just die and have it reschedule it when all your dependencies are there you don't want to",
    "start": "1827539",
    "end": "1834080"
  },
  {
    "text": "really consider your dependency and your Readiness checks like you can run you can try to ready oh I can't access that",
    "start": "1834080",
    "end": "1840740"
  },
  {
    "text": "it can kill it it can reschedule it like look into how to handle um",
    "start": "1840740",
    "end": "1846020"
  },
  {
    "text": "saying you're ready effectively",
    "start": "1846020",
    "end": "1851000"
  },
  {
    "start": "1849000",
    "end": "2101000"
  },
  {
    "text": "all right so I'm going to dive into some web resources but at a high level",
    "start": "1851059",
    "end": "1858200"
  },
  {
    "text": "you know kubernetes is built for scale we know this it's built for resiliency",
    "start": "1858200",
    "end": "1863740"
  },
  {
    "text": "but you can't accept all the defaults sometimes you have to configure things",
    "start": "1863740",
    "end": "1869960"
  },
  {
    "text": "you have to look at the options that are there and take advantage of them every cloud is a little different but",
    "start": "1869960",
    "end": "1877399"
  },
  {
    "text": "kubernetes resiliency stuff is pretty much implemented on most or all of them in",
    "start": "1877399",
    "end": "1883640"
  },
  {
    "text": "some way so leverage the advantages of the clouds as far as availability zones",
    "start": "1883640",
    "end": "1890299"
  },
  {
    "text": "regions scaling most of them have implemented cluster Auto scaling so you can add",
    "start": "1890299",
    "end": "1896419"
  },
  {
    "text": "additional nodes most of them have some way to do the horizontal pod Auto scalar so you can add additional",
    "start": "1896419",
    "end": "1902960"
  },
  {
    "text": "pods so make sure you take that into account bake in your pod disruption",
    "start": "1902960",
    "end": "1908600"
  },
  {
    "text": "budgets look at that bake in your requests and your limits and your probes so let's go take a look at a couple of",
    "start": "1908600",
    "end": "1914659"
  },
  {
    "text": "things whoops",
    "start": "1914659",
    "end": "1919419"
  },
  {
    "text": "so I brought up keita uh Kata I'm a big fan of I think that if",
    "start": "1921200",
    "end": "1926600"
  },
  {
    "text": "you're making applications that have this burst of traffic that have some unpredictability or even where you're",
    "start": "1926600",
    "end": "1932539"
  },
  {
    "text": "trying to not only make it resilient but cost effective a lot of times people",
    "start": "1932539",
    "end": "1937640"
  },
  {
    "text": "over provision they think oh I need to be able to handle traffic uh you know we need 10",
    "start": "1937640",
    "end": "1945799"
  },
  {
    "text": "nodes I'm going to just make it 15 to make sure we can handle traffic you're over provisioning you're just costing",
    "start": "1945799",
    "end": "1950960"
  },
  {
    "text": "money and it's adding some complexity um so with keita one of that what that can do with your",
    "start": "1950960",
    "end": "1957620"
  },
  {
    "text": "workloads is that can scale it down to zero I did mention the",
    "start": "1957620",
    "end": "1963440"
  },
  {
    "text": "um the sources that it uses so just talking about that for a second like there's a",
    "start": "1963440",
    "end": "1969320"
  },
  {
    "text": "number of AWS specific supported ones there's a number of azure specific supported sources that can be used for",
    "start": "1969320",
    "end": "1975980"
  },
  {
    "text": "scaling so if you're monitoring your application with app insights and you're seeing uh Behavior that's different or",
    "start": "1975980",
    "end": "1982399"
  },
  {
    "text": "your event hub if you're looking at a storage queue it's not only CPU but cron so if you",
    "start": "1982399",
    "end": "1988460"
  },
  {
    "text": "know that your workloads follow a defined schedule people show up at eight leave at five you can scale it a little bit easier",
    "start": "1988460",
    "end": "1995299"
  },
  {
    "text": "that way um yep there's the basic Metro metrics API",
    "start": "1995299",
    "end": "2002559"
  },
  {
    "text": "but there's also and MySQL that you can Implement and postgres and",
    "start": "2002559",
    "end": "2008019"
  },
  {
    "text": "rabbit so cada is an amazing tool for that type of scaling the other what",
    "start": "2008019",
    "end": "2015460"
  },
  {
    "text": "was I going to say there was another one I wanted to bring up uh",
    "start": "2015460",
    "end": "2021580"
  },
  {
    "text": "right now and my brain just went blank huh",
    "start": "2021580",
    "end": "2027000"
  },
  {
    "text": "it's always fun when that does that",
    "start": "2028899",
    "end": "2032340"
  },
  {
    "text": "yeah I just completely forgot what I was about to say I",
    "start": "2036220",
    "end": "2041700"
  },
  {
    "text": "oh well let's go out too um there are lots and lots of articles on",
    "start": "2042159",
    "end": "2047620"
  },
  {
    "text": "the request limits versus the um the requests and the limits",
    "start": "2047620",
    "end": "2053560"
  },
  {
    "text": "on resources um I've just given you a taste of some of the arguments there are debates",
    "start": "2053560",
    "end": "2061060"
  },
  {
    "text": "everywhere where people are like it's a great thing to do it's a terrible thing to do hey we should demystify it this",
    "start": "2061060",
    "end": "2068320"
  },
  {
    "text": "way we should use requests please if you have any questions about whether you",
    "start": "2068320",
    "end": "2074138"
  },
  {
    "text": "should use those limits or whether you should be using the requests like I think you should please go look up some",
    "start": "2074139",
    "end": "2081878"
  },
  {
    "text": "of those articles and some of those blogs and read into that a little bit um",
    "start": "2081879",
    "end": "2087878"
  },
  {
    "text": "yeah I lost my train of thought I'm trying to get it back I don't know where it went",
    "start": "2087879",
    "end": "2093460"
  },
  {
    "text": "um I just dropped the ball",
    "start": "2093460",
    "end": "2096658"
  },
  {
    "text": "foreign oh um well this is a good one so one of",
    "start": "2098920",
    "end": "2106780"
  },
  {
    "start": "2101000",
    "end": "2338000"
  },
  {
    "text": "the resources I wanted to share with you guys is this the kubernetes production best practices this is a great website I",
    "start": "2106780",
    "end": "2113859"
  },
  {
    "text": "hope you guys check it out because it has a checklist of things that you can go and look at for your own applications",
    "start": "2113859",
    "end": "2119520"
  },
  {
    "text": "so this does talk about all of those resources I brought up the Readiness",
    "start": "2119520",
    "end": "2125140"
  },
  {
    "text": "probes liveness probe values dealing with Docker files running multiple",
    "start": "2125140",
    "end": "2130839"
  },
  {
    "text": "requests so you can go through this on your own clusters you can take a look at the different capabilities and",
    "start": "2130839",
    "end": "2139359"
  },
  {
    "text": "validate how well you're doing and get some suggestions for improvements on that and now I remembered where I left",
    "start": "2139359",
    "end": "2145599"
  },
  {
    "text": "off so now I got some other resources I can share with you that that's where I was getting to so definitely check out",
    "start": "2145599",
    "end": "2151900"
  },
  {
    "text": "the kubernetes best practices guide this is a great one there are a few great uh",
    "start": "2151900",
    "end": "2158940"
  },
  {
    "text": "checklists out there now some of these are very specific to um",
    "start": "2158940",
    "end": "2164140"
  },
  {
    "text": "like I said AKs and Azure but many of these things apply across the board to",
    "start": "2164140",
    "end": "2171099"
  },
  {
    "text": "um kubernetes as a whole so",
    "start": "2171099",
    "end": "2177060"
  },
  {
    "text": "this is for instance on AKs this is the cluster operator best practice guide",
    "start": "2177060",
    "end": "2183000"
  },
  {
    "text": "this has a lot of really good techniques for if you're operators and",
    "start": "2183000",
    "end": "2188740"
  },
  {
    "text": "you're pushing out pods if you're developers and you're trying to build and release them out on GitHub",
    "start": "2188740",
    "end": "2194579"
  },
  {
    "text": "doing Helm highly recommend that one we have in the team I work on the fast",
    "start": "2194579",
    "end": "2203200"
  },
  {
    "text": "track team we actually have these review checklists these are checklists that go",
    "start": "2203200",
    "end": "2209260"
  },
  {
    "text": "through and validate everything from security reliabies reliability scalability across all of",
    "start": "2209260",
    "end": "2217300"
  },
  {
    "text": "your services and there is a specific one in here for AKs this is one that we",
    "start": "2217300",
    "end": "2224500"
  },
  {
    "text": "actually review with a lot of our customers that's out there it's open source if you have ideas if you have",
    "start": "2224500",
    "end": "2231280"
  },
  {
    "text": "suggestions on how to implement it go out here send a PR take a look at it",
    "start": "2231280",
    "end": "2236460"
  },
  {
    "text": "there's also a couple of just Community kubernetes Resources for review out",
    "start": "2236460",
    "end": "2243640"
  },
  {
    "text": "there so I just want you to think about like I said we're dealing with kubernetes at scale",
    "start": "2243640",
    "end": "2250480"
  },
  {
    "text": "we're dealing with um we're dealing with it at multiple levels",
    "start": "2250480",
    "end": "2257800"
  },
  {
    "text": "as we go through this so we're talking look at your infrastructure are you leveraging availability zones",
    "start": "2257800",
    "end": "2264640"
  },
  {
    "text": "are you leveraging multiple regions are you leveraging scaling so you can have additional nodes",
    "start": "2264640",
    "end": "2271020"
  },
  {
    "text": "are you setting up your network properly to scale effectively",
    "start": "2271020",
    "end": "2276460"
  },
  {
    "text": "look at your components are you managing the node pools right do you have them",
    "start": "2276460",
    "end": "2281560"
  },
  {
    "text": "set up appropriately and finally look at your applications how you built them how you're running",
    "start": "2281560",
    "end": "2287619"
  },
  {
    "text": "them do you have the right limits do you have the right requests if you have your disruption budgets in place are you",
    "start": "2287619",
    "end": "2294220"
  },
  {
    "text": "doing metrics are you monitoring your applications so",
    "start": "2294220",
    "end": "2299740"
  },
  {
    "text": "I guess I went a little fast today I apologize for uh not taking the whole",
    "start": "2299740",
    "end": "2304960"
  },
  {
    "text": "hour but please feel free to uh look let's have a discussion if anyone",
    "start": "2304960",
    "end": "2311440"
  },
  {
    "text": "has questions if anyone wants to have a little discussion we've got a few minutes",
    "start": "2311440",
    "end": "2317880"
  },
  {
    "text": "thank you so let's hear some questions [Applause]",
    "start": "2318760",
    "end": "2328480"
  },
  {
    "text": "who has some questions yes I see a hand",
    "start": "2328480",
    "end": "2333119"
  },
  {
    "start": "2338000",
    "end": "2693000"
  },
  {
    "text": "yeah for the most part what we want to do with CPUs you don't really want to",
    "start": "2338140",
    "end": "2345339"
  },
  {
    "text": "request more than so let's just back up let's say you request",
    "start": "2345339",
    "end": "2350920"
  },
  {
    "text": "CPU and you request one CPU that is essentially the CPU time for one",
    "start": "2350920",
    "end": "2358480"
  },
  {
    "text": "core in one second so if you're doing multi-threaded stuff let's say you have two two threads",
    "start": "2358480",
    "end": "2364300"
  },
  {
    "text": "you're going to use that one CPU in half a second if you have four threads you're going to",
    "start": "2364300",
    "end": "2370780"
  },
  {
    "text": "use it in like a quarter of a second so as soon as you start like getting lots of requests in multiple threads you now",
    "start": "2370780",
    "end": "2376420"
  },
  {
    "text": "have exceeded that limit and it can cause like I said eviction it can just cause slowdowns weird delays",
    "start": "2376420",
    "end": "2384060"
  },
  {
    "text": "and it is just nothing but pain when you're dealing with those CPU limits",
    "start": "2384060",
    "end": "2390099"
  },
  {
    "text": "does that answer your question awesome who else I saw a couple of more",
    "start": "2390099",
    "end": "2396220"
  },
  {
    "text": "hands yes over here and I'll get to you",
    "start": "2396220",
    "end": "2400260"
  },
  {
    "text": "I did not mention Azure Arc yes I do have some thoughts on that in fact that it's technically a very big",
    "start": "2402220",
    "end": "2409119"
  },
  {
    "text": "strategy for Microsoft at this point so for those that don't know",
    "start": "2409119",
    "end": "2414579"
  },
  {
    "text": "um Azure Arc is a thing where",
    "start": "2414579",
    "end": "2420220"
  },
  {
    "text": "essentially you can take any kubernetes cluster",
    "start": "2420220",
    "end": "2425260"
  },
  {
    "text": "or are pretty much server running anywhere on Prem s gcp and you can install these Arc",
    "start": "2425260",
    "end": "2432760"
  },
  {
    "text": "components and essentially that enables Azure and azure's control plane and",
    "start": "2432760",
    "end": "2438700"
  },
  {
    "text": "policy engine to administer that machine so it shows up as a new region",
    "start": "2438700",
    "end": "2444099"
  },
  {
    "text": "essentially inside Azure and I could have a cluster in my house which I do",
    "start": "2444099",
    "end": "2449940"
  },
  {
    "text": "that's Arc enabled and then from the Azure portal from bicep from terraform",
    "start": "2449940",
    "end": "2455520"
  },
  {
    "text": "from Helm I can deploy workloads and assign policies and then they will go",
    "start": "2455520",
    "end": "2461260"
  },
  {
    "text": "down to that agent running in the on-prem cluster it is um it's really powerful it's really cool",
    "start": "2461260",
    "end": "2468280"
  },
  {
    "text": "and I'm a big fan and that's a very big strategy like I said going forward because it allows you to have the same",
    "start": "2468280",
    "end": "2475060"
  },
  {
    "text": "policies and control that you do for all your cloud workloads in",
    "start": "2475060",
    "end": "2480760"
  },
  {
    "text": "your workloads wherever they are so",
    "start": "2480760",
    "end": "2486820"
  },
  {
    "text": "did that answer your question yep thank you yes you had that your hand up",
    "start": "2486820",
    "end": "2493740"
  },
  {
    "text": "the best practices for monitoring",
    "start": "2497320",
    "end": "2501240"
  },
  {
    "text": "okay um best practices for running eks is that what you said",
    "start": "2503500",
    "end": "2508599"
  },
  {
    "text": "yeah Azure okay so um in Azure when we're dealing with AKs when we're",
    "start": "2508599",
    "end": "2514720"
  },
  {
    "text": "dealing with our clusters there's a couple of things most of the underlying services in Azure are supported by Azure",
    "start": "2514720",
    "end": "2520480"
  },
  {
    "text": "monitor Azure monitor is the umbrella kind of product for",
    "start": "2520480",
    "end": "2526480"
  },
  {
    "text": "um app insights container insights it works with log analytics so you can get",
    "start": "2526480",
    "end": "2532599"
  },
  {
    "text": "that stream of events so you see the underlying hardware and CPU and network traffic of",
    "start": "2532599",
    "end": "2538359"
  },
  {
    "text": "your SQL servers your app services and your AKs with AKs and containers there is an",
    "start": "2538359",
    "end": "2545920"
  },
  {
    "text": "additional thing called container insights and so that will give you much more frying grained reporting on your",
    "start": "2545920",
    "end": "2552760"
  },
  {
    "text": "nodes your node behaviors your workloads your pods it'll let you get standard out",
    "start": "2552760",
    "end": "2558180"
  },
  {
    "text": "metrics from and all of the metric stream information that comes out of kubernetes and AKs into the reporting",
    "start": "2558180",
    "end": "2567160"
  },
  {
    "text": "system and you can use log analytics and custom queries you can query on like",
    "start": "2567160",
    "end": "2572260"
  },
  {
    "text": "tags and labels there's also some there's also a managed",
    "start": "2572260",
    "end": "2577720"
  },
  {
    "text": "Prometheus and a managed grafana offering now that you can use to monitor your clusters if you are more familiar",
    "start": "2577720",
    "end": "2584020"
  },
  {
    "text": "with Prometheus and grafana what's up",
    "start": "2584020",
    "end": "2589480"
  },
  {
    "text": "anybody else come on we got some more questions we got some hands come on",
    "start": "2589480",
    "end": "2596040"
  },
  {
    "text": "nobody oh there we go I'm sorry yeah right there",
    "start": "2596200",
    "end": "2601020"
  },
  {
    "text": "please say you didn't ask me that okay okay so the question was",
    "start": "2605560",
    "end": "2612160"
  },
  {
    "text": "for those that didn't hear is it recommended to do windows containers in",
    "start": "2612160",
    "end": "2617319"
  },
  {
    "text": "production so AKs supports Windows containers that's actually one valid use case for using multiple node pools you",
    "start": "2617319",
    "end": "2623980"
  },
  {
    "text": "can have a node pool the system node pool in AKs has to be Linux you can make user node pools that are Linux or",
    "start": "2623980",
    "end": "2630460"
  },
  {
    "text": "Windows for some organizations there is a need",
    "start": "2630460",
    "end": "2635500"
  },
  {
    "text": "I guess you could say need there is a use case let's put it that way there is a use case where they can take their",
    "start": "2635500",
    "end": "2640900"
  },
  {
    "text": "applications and run them on Windows containers in that case yes you can you can",
    "start": "2640900",
    "end": "2646359"
  },
  {
    "text": "schedule them and use them in one AKs cluster with like a Windows node pool running Windows containers and a Linux",
    "start": "2646359",
    "end": "2653440"
  },
  {
    "text": "node pool running Linux containers if you're going to do containers and you",
    "start": "2653440",
    "end": "2659079"
  },
  {
    "text": "don't have a super strong specific need to run it in a Windows container use Linux",
    "start": "2659079",
    "end": "2664300"
  },
  {
    "text": "okay use Linux if you have that super special case",
    "start": "2664300",
    "end": "2669700"
  },
  {
    "text": "you've probably already talked to lots of Specialists that have told you okay you're you're the special one but if",
    "start": "2669700",
    "end": "2674740"
  },
  {
    "text": "you're not the special one just do Linux I think you're special though it's okay",
    "start": "2674740",
    "end": "2680579"
  },
  {
    "text": "I like you I like you uh anything else",
    "start": "2680579",
    "end": "2687220"
  },
  {
    "text": "all right well thank you guys all for coming I really really appreciate it ndc's been awesome",
    "start": "2687220",
    "end": "2694318"
  }
]
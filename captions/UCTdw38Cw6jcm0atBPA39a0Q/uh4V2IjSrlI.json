[
  {
    "start": "0",
    "end": "43000"
  },
  {
    "text": "hello everyone thanks for joining me today my name is Poisson bracket I work as a",
    "start": "5620",
    "end": "11420"
  },
  {
    "text": "senior consultant with redefine this is my twitter handle and my plug if you'd",
    "start": "11420",
    "end": "16970"
  },
  {
    "text": "like to follow me today we're going to talk about kubernetes and our agenda for",
    "start": "16970",
    "end": "22280"
  },
  {
    "text": "today would be talking about what is coupon it is and why we should care about it and then we will have a",
    "start": "22280",
    "end": "27560"
  },
  {
    "text": "walkthrough of the Copernicus architecture and after that we will see how would we leverage the Copernicus",
    "start": "27560",
    "end": "32840"
  },
  {
    "text": "building blocks in order to deploy a typical asp.net application that communicates with the sequel server",
    "start": "32840",
    "end": "38149"
  },
  {
    "text": "database on top of it so let's start with having a shared understanding about",
    "start": "38149",
    "end": "43609"
  },
  {
    "start": "43000",
    "end": "43000"
  },
  {
    "text": "containers but before we do that how many of you have used containers already oh wow that's almost everyone that's",
    "start": "43609",
    "end": "51859"
  },
  {
    "text": "great so historically we used to deploy our applications on top of physical machines and in order to make a better",
    "start": "51859",
    "end": "59479"
  },
  {
    "text": "utilization of the hardware we were deploying multiple applications on the same machine and that meant that the",
    "start": "59479",
    "end": "65059"
  },
  {
    "text": "applications as well as their dependencies were entangled with each other as well as with the host operating system which you didn't provide us with",
    "start": "65059",
    "end": "71300"
  },
  {
    "text": "a good isolation between the applications and that brought us into the virtual machines which provided us",
    "start": "71300",
    "end": "77780"
  },
  {
    "text": "with better isolations when we were using one application per virtual machine but it was very heavy weight",
    "start": "77780",
    "end": "83210"
  },
  {
    "text": "because it's hardware virtualization and that led us into the containers technology and the containers is",
    "start": "83210",
    "end": "89540"
  },
  {
    "text": "basically providing us with a standard way to package the application its dependencies runtime and configurations",
    "start": "89540",
    "end": "95720"
  },
  {
    "text": "in a standard package and then we could provide this package into a container engine and that container engine could",
    "start": "95720",
    "end": "101930"
  },
  {
    "text": "spin up multiple containers based on that package containers provided us with the same benefits that we had from birth",
    "start": "101930",
    "end": "108440"
  },
  {
    "text": "with the virtual machines from isolation perspective so containers cannot access each other but it also it's more",
    "start": "108440",
    "end": "115370"
  },
  {
    "text": "lightweight so we can move the exact same package across different environments and the reason behind that",
    "start": "115370",
    "end": "121790"
  },
  {
    "text": "is containers is using operating system-level virtualization and there are multiple container engines in the",
    "start": "121790",
    "end": "128060"
  },
  {
    "start": "128000",
    "end": "128000"
  },
  {
    "text": "market but the most used one is docker and docker is a platform that allows us to develop and run applications using",
    "start": "128060",
    "end": "135290"
  },
  {
    "text": "the container technology and thanks to the container technology we could package any kind of application in a",
    "start": "135290",
    "end": "140900"
  },
  {
    "text": "container regardless of its language or run time so you could package applications written in node JavaScript",
    "start": "140900",
    "end": "146239"
  },
  {
    "text": "go a speed net or any other language and",
    "start": "146239",
    "end": "151780"
  },
  {
    "text": "once we package our application we could deploy this application into a production environment that has docker",
    "start": "152290",
    "end": "159079"
  },
  {
    "text": "engine running on top of it and if we are lucky our application will start go viral and a lot of users will start",
    "start": "159079",
    "end": "165379"
  },
  {
    "text": "consuming it but in a container based environment this will start bringing more challenges such as how could we",
    "start": "165379",
    "end": "173030"
  },
  {
    "text": "scale our application automatically to address the load that's coming to it or how would we have some sort of",
    "start": "173030",
    "end": "178849"
  },
  {
    "text": "self-healing features so if the container died we spin up another one to replace the one that just died how could",
    "start": "178849",
    "end": "184790"
  },
  {
    "text": "we have some sort of highly available environment so if the host that is hosting our containers died we scheduled",
    "start": "184790",
    "end": "191569"
  },
  {
    "text": "those containers on another host in order to run the same containers our application might keep growing to a",
    "start": "191569",
    "end": "197689"
  },
  {
    "text": "certain extent that we decided to split it into a set of micro services which will start bringing more challenges such",
    "start": "197689",
    "end": "204440"
  },
  {
    "text": "as how the services communicate with with each other we need to have some sort of service discovery between those",
    "start": "204440",
    "end": "209659"
  },
  {
    "text": "services and all those challenges in a container based environment are usually resolved with using a container",
    "start": "209659",
    "end": "215810"
  },
  {
    "text": "orchestration platform and container extraction plasmids allows us to manage containers at scale so there are a lot",
    "start": "215810",
    "end": "223280"
  },
  {
    "text": "of features that comes out of the box with the container observation platform such as service discovery scaling",
    "start": "223280",
    "end": "229250"
  },
  {
    "text": "horizontal health monitoring failover networking and there are multiple container orchestration platforms",
    "start": "229250",
    "end": "235519"
  },
  {
    "text": "available in the market but the one that we're gonna keep talking about today is kubernetes and the copernicus is an open source",
    "start": "235519",
    "end": "242389"
  },
  {
    "text": "container orchestration platform that allows us to automate the process of deploying scaling and managing",
    "start": "242389",
    "end": "248540"
  },
  {
    "text": "containerized applications and bonita springs in addition to the features that",
    "start": "248540",
    "end": "255530"
  },
  {
    "text": "comes with any container orchestration platform is more features such as a self-healing horizontal scaling of the",
    "start": "255530",
    "end": "260799"
  },
  {
    "text": "nodes that are hosting our application and to our applications themselves or the containers it also brings automated",
    "start": "260799",
    "end": "268550"
  },
  {
    "text": "rollout and rollback secret and configuration management storage orchestration and heaps of other features so let me walk",
    "start": "268550",
    "end": "276380"
  },
  {
    "text": "you through a very high-level overview of the Copernicus architecture in a kubernetes cluster consists of two types",
    "start": "276380",
    "end": "283220"
  },
  {
    "start": "280000",
    "end": "280000"
  },
  {
    "text": "of nodes the first type of node is the master node and the master node is the one responsible for managing your",
    "start": "283220",
    "end": "288590"
  },
  {
    "text": "cluster and this is the entry point to to run anything on a hypnotist cluster",
    "start": "288590",
    "end": "294290"
  },
  {
    "text": "and the worker node the worker node is actually where your container actually run and let's let's assume we have",
    "start": "294290",
    "end": "302030"
  },
  {
    "text": "packages application and we wanted to deploy this container on top of Copernicus and let's see what are the",
    "start": "302030",
    "end": "307580"
  },
  {
    "text": "key components that live inside our architecture or our nodes that gets involved in that the entry point to any",
    "start": "307580",
    "end": "315410"
  },
  {
    "text": "keep on each cluster is a component living on the master node called API server and the responsibility of the API",
    "start": "315410",
    "end": "321680"
  },
  {
    "text": "server is exposing set of api's to be consumed by any client and any client",
    "start": "321680",
    "end": "327650"
  },
  {
    "text": "such as the coupon et CLI which is cubes ETL or the UI dashboard or any other",
    "start": "327650",
    "end": "333530"
  },
  {
    "text": "client that could make a call to those api's so we one of those clients will",
    "start": "333530",
    "end": "338600"
  },
  {
    "text": "send a request to the kunis cluster to say or to the API server we would like to run that container on top of the",
    "start": "338600",
    "end": "343670"
  },
  {
    "text": "cluster the API server will validate the request process it and we'll save that request into a database and that",
    "start": "343670",
    "end": "350900"
  },
  {
    "text": "database is etcd database and etcd is basically a distributed key-value store",
    "start": "350900",
    "end": "356960"
  },
  {
    "text": "that is used by kubernetes to maintain its cluster state once we save the state",
    "start": "356960",
    "end": "362270"
  },
  {
    "text": "into the database another component comes into play which is the scheduler and the responsibility",
    "start": "362270",
    "end": "367730"
  },
  {
    "text": "of the scheduler to find the best worker node to host your container and it takes",
    "start": "367730",
    "end": "372740"
  },
  {
    "text": "into consideration stuff like there is the hardware requirements for your container and once it finds that node it",
    "start": "372740",
    "end": "379760"
  },
  {
    "text": "just updates the state in the database through the API server nothing has been",
    "start": "379760",
    "end": "384860"
  },
  {
    "text": "scheduled yet then another component comes into play which is the couplet and the couplet is a component that runs on",
    "start": "384860",
    "end": "391850"
  },
  {
    "text": "each worker node and it's responsibility is to keep watching the API server to",
    "start": "391850",
    "end": "397160"
  },
  {
    "text": "find if there is any work to be scheduled on that worker and it will find that there is a container to be",
    "start": "397160",
    "end": "402320"
  },
  {
    "text": "scheduled and and at that point it makes a call to another component living in the water which is",
    "start": "402320",
    "end": "408050"
  },
  {
    "text": "the container and time and there are multiple container and times such as docker or rocket or there are other",
    "start": "408050",
    "end": "414050"
  },
  {
    "text": "containers that satisfy the container and time requirements and the container and time is the one that actually spin",
    "start": "414050",
    "end": "420259"
  },
  {
    "text": "up your container so at this point this lose all those are the main components",
    "start": "420259",
    "end": "425930"
  },
  {
    "text": "in required to run your container but there is one more key component that I'd like to make sure that you are aware of",
    "start": "425930",
    "end": "432050"
  },
  {
    "text": "on the Kunis cluster which is the controller manager and you can think of the controller manager as infinite loop",
    "start": "432050",
    "end": "438470"
  },
  {
    "text": "that is running all the time and the responsibilities of the controller manager is to keep monitoring the",
    "start": "438470",
    "end": "443599"
  },
  {
    "text": "cluster so and keep comparing the current state of the cluster versus a desired state of the cluster so as an",
    "start": "443599",
    "end": "450139"
  },
  {
    "text": "example if we request it to run two instances of a concerting container and the country a controller manager found",
    "start": "450139",
    "end": "457039"
  },
  {
    "text": "that the current number of the containers is one it will make some corrective actions to make the current",
    "start": "457039",
    "end": "463159"
  },
  {
    "text": "number of containers to be two and those are the key components that everyone",
    "start": "463159",
    "end": "468289"
  },
  {
    "text": "should be aware of while you are working with a keeper Nittis architecture now",
    "start": "468289",
    "end": "474860"
  },
  {
    "text": "that you know Copernicus you might be interested in trying this on your machine or any other environment and",
    "start": "474860",
    "end": "480710"
  },
  {
    "text": "there are multiple ways to start working with coupon IDs the first one is running it on a local host and you could use",
    "start": "480710",
    "end": "486740"
  },
  {
    "text": "mini cube or docker for desktop so if you already have docker installed there is one a check box once you take it you",
    "start": "486740",
    "end": "492710"
  },
  {
    "text": "will have a coupon in this cluster running on your machine you can run it could run coupon it is on-premises either on a virtual machine or a",
    "start": "492710",
    "end": "499370"
  },
  {
    "text": "hardware physical machine you could also use any of the cloud offerings that such as Google AWS or Azure which provides",
    "start": "499370",
    "end": "506750"
  },
  {
    "text": "you with a platform as a service offerings as well and once you have a Kunis cluster you could deploy your container eyes the",
    "start": "506750",
    "end": "513440"
  },
  {
    "text": "application on top of it so I'd like to spend the rest of the talk showing you how do we actually",
    "start": "513440",
    "end": "519649"
  },
  {
    "text": "deploy a typical aerated application communicating with a sequel server database on top of it then how would we",
    "start": "519649",
    "end": "526040"
  },
  {
    "text": "scale our application so we have multiple instances of the same application with the load balancer",
    "start": "526040",
    "end": "531380"
  },
  {
    "text": "sitting on top of it to be used by the clients and that application will be communicating with a highly available",
    "start": "531380",
    "end": "537050"
  },
  {
    "text": "sequel server database so let me show you the application and the purpose today is not to actually build",
    "start": "537050",
    "end": "543720"
  },
  {
    "text": "the application but will show we'll see how would we take the already built application on to the journey of running",
    "start": "543720",
    "end": "549029"
  },
  {
    "text": "it on top of the cluster so it's a typical tasks list application it's built with asp.net core and it has like",
    "start": "549029",
    "end": "557250"
  },
  {
    "text": "home about contact and tasks and tasks is basically having a crud operations",
    "start": "557250",
    "end": "562620"
  },
  {
    "text": "for a task list and I'm using entity framework code to communicate with a sequel server database so just I can add",
    "start": "562620",
    "end": "569310"
  },
  {
    "text": "another task and this is providing us with the typical like add delete mark as",
    "start": "569310",
    "end": "576390"
  },
  {
    "text": "completed so the first step in order to deploy our application on the cluster is",
    "start": "576390",
    "end": "582959"
  },
  {
    "text": "to continue eyes this application to build that package once we containerize it we have to provide it to configure it",
    "start": "582959",
    "end": "590190"
  },
  {
    "text": "in a way or package in a way that could be understood by Copernicus cluster and that is the pod pods are basically the",
    "start": "590190",
    "end": "597990"
  },
  {
    "text": "atomic unit of scheduling inside kubernetes our application container will always",
    "start": "597990",
    "end": "603149"
  },
  {
    "text": "live inside a pod it will never be outside a pot and the pot could contain multiple containers living inside of it",
    "start": "603149",
    "end": "609690"
  },
  {
    "text": "and those containers could communicate seamlessly because they share the same network namespace in addition to that",
    "start": "609690",
    "end": "616740"
  },
  {
    "text": "the pod itself could have volumes and volume is basically a data directory and we'll talk about the details of the",
    "start": "616740",
    "end": "623520"
  },
  {
    "text": "volumes later on and that volume could be consumed by the containers living inside that pod and pods usually",
    "start": "623520",
    "end": "630660"
  },
  {
    "text": "represents a single instance of an application which means if we would like to scale our application we will deploy",
    "start": "630660",
    "end": "636899"
  },
  {
    "text": "more pods as opposed of deploying more containers inside the same pod so let's",
    "start": "636899",
    "end": "643260"
  },
  {
    "start": "638000",
    "end": "638000"
  },
  {
    "text": "see how would we actually package our application deploy it as a pod on top of cabinets so here is our application in",
    "start": "643260",
    "end": "654690"
  },
  {
    "text": "Visual Studio it's a typical edge with net core application this is our tasks container it's using entity framework context to",
    "start": "654690",
    "end": "661290"
  },
  {
    "text": "communicate with the sequel server database so the first step as I said is to containerize it and we could add a",
    "start": "661290",
    "end": "667649"
  },
  {
    "text": "container support for our application or at a docker file using the built-in feature of Visual Studio",
    "start": "667649",
    "end": "673260"
  },
  {
    "text": "of AD Duker support and once you add the cur support this will create a docker",
    "start": "673260",
    "end": "678930"
  },
  {
    "text": "file for you or you could write a docker file from scratch so let me show you the docker file everyone can see at the back",
    "start": "678930",
    "end": "686340"
  },
  {
    "text": "good so here's our local file this is",
    "start": "686340",
    "end": "691470"
  },
  {
    "text": "the one that just comes out of the books with the ace witness template what we have here is basically the instructions",
    "start": "691470",
    "end": "698190"
  },
  {
    "text": "to package our application the first step is defining the port that this application will be receiving the",
    "start": "698190",
    "end": "704790"
  },
  {
    "text": "requests on top of it then we have the first step is nougat package restore",
    "start": "704790",
    "end": "710190"
  },
  {
    "text": "then we are copying the rest of the application file and the next step is",
    "start": "710190",
    "end": "715770"
  },
  {
    "text": "building and publishing the application and finally we are defining what is the entry point of our application so each",
    "start": "715770",
    "end": "722700"
  },
  {
    "text": "time we run a container this command will be the command that will get executed inside that container",
    "start": "722700",
    "end": "729589"
  },
  {
    "text": "now we package it now we created our docker file the next step is to create an image so this is just a plain text",
    "start": "729740",
    "end": "736470"
  },
  {
    "text": "file we did it actually create the image so far and in order to create an image we can use ray we can use a docker",
    "start": "736470",
    "end": "744360"
  },
  {
    "text": "command docker build and provide the image name and then we provide the build",
    "start": "744360",
    "end": "750780"
  },
  {
    "text": "context which is if our docker file have any passes it will depend on that context file and on the context that we",
    "start": "750780",
    "end": "756780"
  },
  {
    "text": "provide once we do this all the instructions in that we have inside the docker file will be executed and it will",
    "start": "756780",
    "end": "763950"
  },
  {
    "text": "provide us with an image I have already done that so we don't have to see the whole weight for the whole build image",
    "start": "763950",
    "end": "769950"
  },
  {
    "text": "to complete so I have created a couple of images based on that application and",
    "start": "769950",
    "end": "776100"
  },
  {
    "text": "they are called Sambora card / task list",
    "start": "776100",
    "end": "783410"
  },
  {
    "text": "as you can see I have already built two images for our application and those are",
    "start": "785230",
    "end": "790990"
  },
  {
    "text": "the ones that we can use to deploy to our Copernicus cluster we can run that",
    "start": "790990",
    "end": "796510"
  },
  {
    "text": "container on top or that image on top of Copernicus in two ways the first one is the imperative way and the imperative",
    "start": "796510",
    "end": "803110"
  },
  {
    "text": "way is basically using the cube City L which is a coupon it is client provide",
    "start": "803110",
    "end": "808390"
  },
  {
    "text": "it with a command run then we provide the image name and this will run a pod",
    "start": "808390",
    "end": "816430"
  },
  {
    "text": "or run our container on top of the cluster and the other way is the declarative way and this is actually the",
    "start": "816430",
    "end": "822790"
  },
  {
    "text": "one that we're gonna use today and the declarative way is basically building a ml fire or JSON file and that e ml file",
    "start": "822790",
    "end": "829900"
  },
  {
    "text": "we could provide it in to our cube CTL and keep CTL make the relative call to the API server inside the cube R in this",
    "start": "829900",
    "end": "836680"
  },
  {
    "text": "cluster so let's see the ml file or our pod definition",
    "start": "836680",
    "end": "841830"
  },
  {
    "text": "generally any kubernetes object require four parameters the first one is the",
    "start": "841830",
    "end": "847390"
  },
  {
    "text": "kind of the object that we would like to create second one is the API version and as I said the key entry point to the",
    "start": "847390",
    "end": "854680"
  },
  {
    "text": "cluster is the API server and this is basically telling the QTL which API version that we would like to talk to",
    "start": "854680",
    "end": "860890"
  },
  {
    "text": "and based on that version the spec section which is like the body of your request could be different based on that",
    "start": "860890",
    "end": "868090"
  },
  {
    "text": "version we have another object another attribute which is the metadata and in this case we are just providing the name",
    "start": "868090",
    "end": "874510"
  },
  {
    "text": "of the pod then the spec section the spec section is like the body for our",
    "start": "874510",
    "end": "879850"
  },
  {
    "text": "pod we could have multiple containers living inside of it but in this case we only have one container which is the asp.net application so we provide the",
    "start": "879850",
    "end": "887560"
  },
  {
    "text": "container name we provide the image that we have built and the image pool policy",
    "start": "887560",
    "end": "893050"
  },
  {
    "text": "this is basically telling keepin it is to use the image that I have already have built or grabbed on my local",
    "start": "893050",
    "end": "898840"
  },
  {
    "text": "machine and this is just to save few months in our demo the last bit is the",
    "start": "898840",
    "end": "904810"
  },
  {
    "text": "port that this container is exposing and this is the same port that we have in our docker file with that object created",
    "start": "904810",
    "end": "913360"
  },
  {
    "text": "we can use cube CTL and provide it with a command apply",
    "start": "913360",
    "end": "919870"
  },
  {
    "text": "provide the file and we can see that there is a pod created communities",
    "start": "919870",
    "end": "926830"
  },
  {
    "text": "provide us with another key component which is a coupon it is dashboard which is a UI that allows us to explore the",
    "start": "926830",
    "end": "933160"
  },
  {
    "text": "objects that have been deployed on top of coupon it is so if we switch to the kubernetes dashboard we can see there is",
    "start": "933160",
    "end": "939610"
  },
  {
    "text": "a section for the pods and we have our pod has been created already and we can",
    "start": "939610",
    "end": "945790"
  },
  {
    "text": "see the details of the containers living inside that pod so our container will be the tasks app and the image that is used",
    "start": "945790",
    "end": "952660"
  },
  {
    "text": "in inside that container and I can't connect to my application to verify that",
    "start": "952660",
    "end": "957970"
  },
  {
    "text": "it's actually running using a feature in communities which is port forward so I'll use cube CTL port forward provide",
    "start": "957970",
    "end": "967510"
  },
  {
    "text": "the pod name and the hook the host port",
    "start": "967510",
    "end": "973060"
  },
  {
    "text": "and the port that I will be targeting and this will build a tunnel between my host machine and the pod once we run",
    "start": "973060",
    "end": "980590"
  },
  {
    "text": "that I will open a new tab and let's try",
    "start": "980590",
    "end": "986040"
  },
  {
    "text": "there you go our application is already running so so far we managed it to",
    "start": "986040",
    "end": "993330"
  },
  {
    "text": "deploy our application as a pot on top of Keeper nice but what happened if that",
    "start": "993330",
    "end": "999100"
  },
  {
    "text": "pod dies for any reason if the pod dies Copernicus will not automatically spin",
    "start": "999100",
    "end": "1004530"
  },
  {
    "text": "up another another pod for us it doesn't provide the self-healing feature out-of-the-box for the pod but we could",
    "start": "1004530",
    "end": "1011550"
  },
  {
    "text": "leverage another object in communities which is called replica set and the replica set is providing us with this",
    "start": "1011550",
    "end": "1017370"
  },
  {
    "start": "1012000",
    "end": "1012000"
  },
  {
    "text": "feature to tell coupon it is to maintain a certain number of replicas from a pod and this means if the pod dies another",
    "start": "1017370",
    "end": "1026520"
  },
  {
    "text": "one will be spend up automatically and so if we assume that we have a scenario that we would like to maintain two",
    "start": "1026520",
    "end": "1032970"
  },
  {
    "text": "instances of an engine X container and the first time when we deploy our replica set communities will go and",
    "start": "1032970",
    "end": "1039329"
  },
  {
    "text": "create two pods on the workers that we have but if anything went wrong with any",
    "start": "1039329",
    "end": "1044939"
  },
  {
    "text": "of the pods like for a worker failure queue penitas will automatically discover that there is",
    "start": "1044940",
    "end": "1050909"
  },
  {
    "text": "the number of the pods are less than the desired and it will automatically spin up a new pod on one of the healthy nodes",
    "start": "1050909",
    "end": "1057269"
  },
  {
    "text": "and this is happening thanks to those like infinite loops that are running on",
    "start": "1057269",
    "end": "1062789"
  },
  {
    "text": "the kubernetes master and the way the replica set connects to the pod is using",
    "start": "1062789",
    "end": "1068250"
  },
  {
    "text": "another feature in kubernetes which is labels and labels providing us with a set of key values that could be assigned",
    "start": "1068250",
    "end": "1075090"
  },
  {
    "start": "1069000",
    "end": "1069000"
  },
  {
    "text": "to a pod a replica set or any other object on copernicus so we deploy our",
    "start": "1075090",
    "end": "1080519"
  },
  {
    "text": "replica set to coupon it is telling it please maintain a certain number of pods",
    "start": "1080519",
    "end": "1086220"
  },
  {
    "text": "that have that label or multiple labels so let's see how would we switch our pod",
    "start": "1086220",
    "end": "1092610"
  },
  {
    "text": "to be controlled by a replica set and see those self-healing features in action first of all I will stop this",
    "start": "1092610",
    "end": "1101519"
  },
  {
    "text": "will clean these deployments we can create our replica see here is the",
    "start": "1101519",
    "end": "1107370"
  },
  {
    "text": "replica set object definition again the same four parameters the kind of the object is replica set the API version",
    "start": "1107370",
    "end": "1113940"
  },
  {
    "text": "and as you can see the version that we are using for the replica set is different from the version that we are using for the pod and that's fine",
    "start": "1113940",
    "end": "1120480"
  },
  {
    "text": "because each API could has its own different versions and then the name of",
    "start": "1120480",
    "end": "1126149"
  },
  {
    "text": "the replica set that we are using then the spec definition and inside the spec",
    "start": "1126149",
    "end": "1131399"
  },
  {
    "text": "we have the number of replicas that we would like to maintain of that pod then we define the selector this is where we",
    "start": "1131399",
    "end": "1137549"
  },
  {
    "text": "define the label that we will be using to find out the pods and in here we are",
    "start": "1137549",
    "end": "1142769"
  },
  {
    "text": "using match labels we will try to find the pods with the label that has the key app and the value tasks app the next",
    "start": "1142769",
    "end": "1151500"
  },
  {
    "text": "part is template and template is basically the pod definition which is more or less what we had in the last",
    "start": "1151500",
    "end": "1157370"
  },
  {
    "text": "file of the pod object definition the only difference here is the label",
    "start": "1157370",
    "end": "1163049"
  },
  {
    "text": "dissection that we have added to the template section which means any pod that will be scheduled based on that",
    "start": "1163049",
    "end": "1168990"
  },
  {
    "text": "replica set will have that label and this is the same label that we are using in the label selector for the replica",
    "start": "1168990",
    "end": "1175289"
  },
  {
    "text": "set so let's apply or deploy this replica set",
    "start": "1175289",
    "end": "1182269"
  },
  {
    "text": "again using the same command the cube city L apply will provide the file name and this will create our replication",
    "start": "1184040",
    "end": "1191480"
  },
  {
    "text": "switching back to the dashboard we have we can go and inspect the replica set section and we can see that our replica",
    "start": "1191480",
    "end": "1198810"
  },
  {
    "text": "set has been created and inside that replica set we have three pods and each pod is pasted on it has the same",
    "start": "1198810",
    "end": "1206310"
  },
  {
    "text": "container that we had in the last demo with the same image name that we have defined the only difference is that",
    "start": "1206310",
    "end": "1212220"
  },
  {
    "text": "label section it has the label that we have added to the template definition and if I grab this pot I can connect to",
    "start": "1212220",
    "end": "1219300"
  },
  {
    "text": "it using the same port forward similar to the last time we provide a different",
    "start": "1219300",
    "end": "1226380"
  },
  {
    "text": "port just to make it to make sure that we are connecting to the right",
    "start": "1226380",
    "end": "1232350"
  },
  {
    "text": "application you need to change this port as well and there you go the application is running with the replica set which is",
    "start": "1232350",
    "end": "1240300"
  },
  {
    "text": "more or less what we had in the last demo but the difference now is if we decided to go to the replica set and if",
    "start": "1240300",
    "end": "1248070"
  },
  {
    "text": "any of those pot dies and I can do this by just actually deleting one of those spots another one will be automatically",
    "start": "1248070",
    "end": "1255480"
  },
  {
    "text": "scheduled for this replica set because the cue list cluster who found that the",
    "start": "1255480",
    "end": "1261450"
  },
  {
    "text": "number of pods is less than the desired and it will automatically spin that new pod and if I keep deleting communities",
    "start": "1261450",
    "end": "1267570"
  },
  {
    "text": "will keep creating another pod and one of the good things with the replica set is we can scale the number of replicas",
    "start": "1267570",
    "end": "1275670"
  },
  {
    "text": "that we are monitoring just with an ad hoc command from the cube CTL or using",
    "start": "1275670",
    "end": "1281010"
  },
  {
    "text": "that scale in the dashboard so right now we are only having three pods we could scale this to be six or seven or any",
    "start": "1281010",
    "end": "1287550"
  },
  {
    "text": "number that we would like to so on its six seven this is going to create",
    "start": "1287550",
    "end": "1292800"
  },
  {
    "text": "automatically the pods and again if any of those pods died Japanese will automatically spin up another pod to",
    "start": "1292800",
    "end": "1299430"
  },
  {
    "text": "replace it so this is how would we deploy our pod and have some sort of",
    "start": "1299430",
    "end": "1307440"
  },
  {
    "text": "self-healing using a replica set but usually after we after the first version",
    "start": "1307440",
    "end": "1312450"
  },
  {
    "text": "is rolled out who would like to deploy a new version of our app vacation and usually you would like to",
    "start": "1312450",
    "end": "1317470"
  },
  {
    "text": "do this with minimal downtime and hopefully we'll have some safety mechanism so if something goes wrong",
    "start": "1317470",
    "end": "1323260"
  },
  {
    "text": "with our deployment which shouldn't happen we would roll back to the old",
    "start": "1323260",
    "end": "1328450"
  },
  {
    "text": "version of the application and in order to give the loose kind of features we need to use another object to control",
    "start": "1328450",
    "end": "1334480"
  },
  {
    "text": "our replica set and that object is a deployment object and the deployment object allows us to have those sort of",
    "start": "1334480",
    "end": "1341020"
  },
  {
    "text": "roll out and roll back features for our replica set so the first time we deploy our application a replica set will be",
    "start": "1341020",
    "end": "1347200"
  },
  {
    "text": "created with the pods living inside of it but the key features with the deployment is if we decided to roll out",
    "start": "1347200",
    "end": "1353860"
  },
  {
    "start": "1353000",
    "end": "1353000"
  },
  {
    "text": "a new version of our application and this would usually happen by building a new image and providing the new image",
    "start": "1353860",
    "end": "1360130"
  },
  {
    "text": "name to the deployment object behind the scene capabilities will go and spin up a new replica set and then it will start",
    "start": "1360130",
    "end": "1368440"
  },
  {
    "text": "spinning up a new pod inside the replica set using the new image and then it will",
    "start": "1368440",
    "end": "1373990"
  },
  {
    "text": "kill another pod in the old replica set and it will keep doing this process till all the desired pods are created in the",
    "start": "1373990",
    "end": "1381070"
  },
  {
    "text": "new replica set and all the old pods are deleted from the or all killed in the old replica set and if something at that",
    "start": "1381070",
    "end": "1388480"
  },
  {
    "text": "point the deployment will be pointing or monitoring the the new replica set and if something went wrong so if we found",
    "start": "1388480",
    "end": "1395410"
  },
  {
    "text": "the bug in the new release we could easily roll back to the old replica set and the same process that happened with",
    "start": "1395410",
    "end": "1401110"
  },
  {
    "text": "the rollout will happen with the rollback so let's see how would we use a deployment object in order to roll out",
    "start": "1401110",
    "end": "1407350"
  },
  {
    "text": "and a normal replica set then we will update it or roll out a new version of our application let me stop this and",
    "start": "1407350",
    "end": "1418060"
  },
  {
    "text": "clean the deployment here's our object definition again the kind is deployment",
    "start": "1418060",
    "end": "1425140"
  },
  {
    "text": "the API version that we are using and the name of the deployment object and the rest of this file is more or less",
    "start": "1425140",
    "end": "1431530"
  },
  {
    "text": "exactly the same that we have in the replica set there are other parameters",
    "start": "1431530",
    "end": "1436690"
  },
  {
    "text": "that we could provide to the deployment object such as the rollout strategy which is basically controlling how many",
    "start": "1436690",
    "end": "1442810"
  },
  {
    "text": "pods should be created while we are rolling out versus how many pose that should be killed in the old replicas it",
    "start": "1442810",
    "end": "1449140"
  },
  {
    "text": "but for the sake of this demo I'll keep it simple I will not provide any extra parameters and let's see how would we",
    "start": "1449140",
    "end": "1454900"
  },
  {
    "text": "actually deploy this again it's one command it's Q city L apply provide the",
    "start": "1454900",
    "end": "1461320"
  },
  {
    "text": "file name and this will create our deployment switching back to the",
    "start": "1461320",
    "end": "1468310"
  },
  {
    "text": "dashboard we can see that the deployment object has been created and inside that",
    "start": "1468310",
    "end": "1473590"
  },
  {
    "text": "deployment is a replica set and inside the replica set are the pods I would",
    "start": "1473590",
    "end": "1479740"
  },
  {
    "text": "like to take a note of that replica set so we can compare sorry so we can't compare with with the new replica set",
    "start": "1479740",
    "end": "1486940"
  },
  {
    "text": "when we roll out a new version of our application and again if I connect it to",
    "start": "1486940",
    "end": "1492520"
  },
  {
    "text": "any of those pods we should be able to view the application running values port",
    "start": "1492520",
    "end": "1500050"
  },
  {
    "text": "forward provide the pod name and different port again to make sure that we are yes I'm in port forwards and",
    "start": "1500050",
    "end": "1514720"
  },
  {
    "text": "change the port here here is our",
    "start": "1514720",
    "end": "1520000"
  },
  {
    "text": "application running again as you might have noticed the tasks tab will not be working right now because we actually",
    "start": "1520000",
    "end": "1526840"
  },
  {
    "text": "didn't deploy the sequel application yet but we will do this in few minutes so we",
    "start": "1526840",
    "end": "1533800"
  },
  {
    "text": "have deployed our application and we have seen the deployment object has been created but right now I would like to",
    "start": "1533800",
    "end": "1540220"
  },
  {
    "text": "roll out a new version of that application and we do this by changing the image name so I have already created",
    "start": "1540220",
    "end": "1546820"
  },
  {
    "text": "a new image and that image has the tag v2 or the name v2 and when we roll out",
    "start": "1546820",
    "end": "1554470"
  },
  {
    "text": "this version our application should have v2 shown beside the tasks list so let's",
    "start": "1554470",
    "end": "1560890"
  },
  {
    "text": "hourly update our deployment I'll just call the same command and then let's",
    "start": "1560890",
    "end": "1570330"
  },
  {
    "text": "switch back to the dashboard to see what happened here is our deployment and",
    "start": "1570330",
    "end": "1577320"
  },
  {
    "text": "still running and now it's done a new replica set has binky",
    "start": "1577320",
    "end": "1582730"
  },
  {
    "text": "and we know this because we have taken a note of the old replica set and as you can see the name of the replica set is",
    "start": "1582730",
    "end": "1589420"
  },
  {
    "text": "different from the old replica set and the new replica set has new pots living",
    "start": "1589420",
    "end": "1594970"
  },
  {
    "text": "inside of it and those pots are pasted on the new image name that we have provided in our object definition so if",
    "start": "1594970",
    "end": "1602140"
  },
  {
    "text": "I connect it to that pot right now I should be able to see the v-2 happening",
    "start": "1602140",
    "end": "1608200"
  },
  {
    "text": "in the homepage on a different pot if we",
    "start": "1608200",
    "end": "1620590"
  },
  {
    "text": "refresh the homepage right now we should see v2 which is great but the the",
    "start": "1620590",
    "end": "1627430"
  },
  {
    "text": "greatest thing is to see how this process happen behind the scene and I'd like to show this using a command in",
    "start": "1627430",
    "end": "1632680"
  },
  {
    "text": "Cuban it is called describe and the describe command could be used with any object that we have in Cuba needs to see",
    "start": "1632680",
    "end": "1639400"
  },
  {
    "text": "the details of that object and as a part of that we can see the events that happened on that object lifecycle let me",
    "start": "1639400",
    "end": "1646900"
  },
  {
    "text": "create clear that cube city el describe I'd like to know the details of the",
    "start": "1646900",
    "end": "1654850"
  },
  {
    "text": "tasks deployment and this will show us",
    "start": "1654850",
    "end": "1660160"
  },
  {
    "text": "the template definition of the pod the containers that are living inside of it and this is a roll out roll running",
    "start": "1660160",
    "end": "1667960"
  },
  {
    "text": "updated strategy and we can't change those parameters but the same section that I wanted to make sure that you see",
    "start": "1667960",
    "end": "1673780"
  },
  {
    "text": "here is the events section so when we first deployed our application it was",
    "start": "1673780",
    "end": "1680520"
  },
  {
    "text": "created a new replica set and that replica set is the one that we have taken a note of it here and the scale",
    "start": "1680520",
    "end": "1687370"
  },
  {
    "text": "did this this replica said to three immediately but then we request it to",
    "start": "1687370",
    "end": "1692950"
  },
  {
    "text": "roll out a new version of our application and what happened is a new replica set was created but it scaled",
    "start": "1692950",
    "end": "1700000"
  },
  {
    "text": "only to one and then the old replica set was a scale to two and again the new",
    "start": "1700000",
    "end": "1706840"
  },
  {
    "text": "replica set scale to - the old replica set scaled to 1 so this is the process of creating and killing the pods inside",
    "start": "1706840",
    "end": "1713230"
  },
  {
    "text": "the replica set till the older pods in the knee new replica set were created so the",
    "start": "1713230",
    "end": "1718360"
  },
  {
    "text": "desired replicas became free and the old replicas become zero and we can see the",
    "start": "1718360",
    "end": "1724179"
  },
  {
    "text": "revisions so the more we do more deployments or updates to our deployment object we can see all those revisions",
    "start": "1724179",
    "end": "1730270"
  },
  {
    "text": "using a command called cube CTL roll-out history of a certain deployment as you",
    "start": "1730270",
    "end": "1744490"
  },
  {
    "text": "can see right now we have two revisions the more we deploy them all we have revisions and with the deployment we",
    "start": "1744490",
    "end": "1750730"
  },
  {
    "text": "could roll back from the current revision to the old revision and we can do this using the undo command so let's",
    "start": "1750730",
    "end": "1758770"
  },
  {
    "text": "do that so I'll try to roll back from the current version to the old version you roll out undo deployment tasks",
    "start": "1758770",
    "end": "1772110"
  },
  {
    "text": "deployment this is the deployment name and right now if we go to the dashboard",
    "start": "1772110",
    "end": "1785220"
  },
  {
    "text": "we can see that the deployment object is being updated and we can see here that this deployment has been updated to use",
    "start": "1785429",
    "end": "1791799"
  },
  {
    "text": "the same image but what I wanted to show you here is this replica set is exactly",
    "start": "1791799",
    "end": "1797950"
  },
  {
    "text": "the same replica set that we had when we first deployed our deployment object so",
    "start": "1797950",
    "end": "1803460"
  },
  {
    "text": "this is how would we get those kind of safety mechanisms with automated rollout",
    "start": "1803460",
    "end": "1809470"
  },
  {
    "text": "and rollback of our application and we can do the same thing with our sacred application we can create a deployment",
    "start": "1809470",
    "end": "1815890"
  },
  {
    "text": "object and that deployment object will have a pod and that pod will be our sequel application but we will be",
    "start": "1815890",
    "end": "1823510"
  },
  {
    "text": "missing something which is how would the asp.net pod connect to our database pod we could start by grabbing the database",
    "start": "1823510",
    "end": "1830919"
  },
  {
    "start": "1829000",
    "end": "1829000"
  },
  {
    "text": "pod IP and provide it to the ASP is it pod maybe through an environment variable but pods genera are ephemeral",
    "start": "1830919",
    "end": "1837970"
  },
  {
    "text": "which means they could die for any reason and if the database pod died another one will peace pinned up",
    "start": "1837970",
    "end": "1844270"
  },
  {
    "text": "automatically thanks to the replica set and the new pod will have a new IP and",
    "start": "1844270",
    "end": "1849670"
  },
  {
    "text": "is going to Prague the connectivity between the asp.net pod and the database pod and to avoid this situation we could",
    "start": "1849670",
    "end": "1857560"
  },
  {
    "text": "use another object in Copernicus which is services and services allows us to",
    "start": "1857560",
    "end": "1863340"
  },
  {
    "start": "1861000",
    "end": "1861000"
  },
  {
    "text": "logically group set of pods using a label selector similar to the one that",
    "start": "1863340",
    "end": "1869200"
  },
  {
    "text": "we used with the replica set but in addition to that it also provided provides us with a dns name that could",
    "start": "1869200",
    "end": "1875950"
  },
  {
    "text": "be used by the consumers so in our scenario you could have a service that",
    "start": "1875950",
    "end": "1881530"
  },
  {
    "text": "is pointing to the database pod using a label selector and our asp.net pod could",
    "start": "1881530",
    "end": "1887770"
  },
  {
    "text": "use the service dns name to consume that database port which means if something",
    "start": "1887770",
    "end": "1893470"
  },
  {
    "text": "went wrong with our database pod for any reason the a speed node pod doesn't have",
    "start": "1893470",
    "end": "1899110"
  },
  {
    "text": "to keep a track of the IPS of the database pod and this means that our",
    "start": "1899110",
    "end": "1905860"
  },
  {
    "text": "application will be looking like that we have a service and the service will be pointing to the asp.net pods the asp.net",
    "start": "1905860",
    "end": "1913660"
  },
  {
    "text": "pods will be using the DNS name of the database pod and that service will will",
    "start": "1913660",
    "end": "1920560"
  },
  {
    "text": "keep track of the database port and in addition to just being logically grouping the pods and providing us with",
    "start": "1920560",
    "end": "1928030"
  },
  {
    "text": "a DNS name services also provides us with some sort of load balancing",
    "start": "1928030",
    "end": "1933070"
  },
  {
    "text": "features so when we put the service in front of the asp.net pods the requests",
    "start": "1933070",
    "end": "1938530"
  },
  {
    "text": "that are coming to our application will be load balancing across the running",
    "start": "1938530",
    "end": "1943630"
  },
  {
    "text": "pods so let's see how would we update our application to deploy our sacred",
    "start": "1943630",
    "end": "1948760"
  },
  {
    "text": "application then connect the asp.net pod to the database pod",
    "start": "1948760",
    "end": "1954149"
  },
  {
    "text": "I'm going to clean deployment and why we are doing this let me show you the",
    "start": "1957920",
    "end": "1963320"
  },
  {
    "text": "object definition so this is the same deployment object that we had in the last demo the only difference we have",
    "start": "1963320",
    "end": "1969200"
  },
  {
    "text": "here is the environment variable that I have provided and this is basically the",
    "start": "1969200",
    "end": "1974360"
  },
  {
    "text": "connection string that our a spinet pod R is going to use and the key thing that",
    "start": "1974360",
    "end": "1980390"
  },
  {
    "text": "you I'd like you to note here is the name of the server and this is basically the DNS name of the service that we will",
    "start": "1980390",
    "end": "1988430"
  },
  {
    "text": "build to expose our database pod and we'll see this in a minute we can have multiple object definitions",
    "start": "1988430",
    "end": "1995810"
  },
  {
    "text": "inside the same UML file using those three dashes so this is our deployment object is the",
    "start": "1995810",
    "end": "2001570"
  },
  {
    "text": "same one that we have just created the next one is the service and again the same four parameters needs to be",
    "start": "2001570",
    "end": "2007120"
  },
  {
    "text": "provided the kind would be the service the API version the name of the service",
    "start": "2007120",
    "end": "2012610"
  },
  {
    "text": "in the metadata and then our spec definition and this is the key part here which is a selector we we could use a",
    "start": "2012610",
    "end": "2020920"
  },
  {
    "text": "different label by the way we are using the same label that we have on for the",
    "start": "2020920",
    "end": "2026950"
  },
  {
    "text": "replica set but we could have different labels the object could have multiple a any object could have multiple labels",
    "start": "2026950",
    "end": "2032170"
  },
  {
    "text": "attach it to it then in this case we are just using the same label that we have",
    "start": "2032170",
    "end": "2038170"
  },
  {
    "text": "provided in the template definition which is that one which is the key AB",
    "start": "2038170",
    "end": "2043540"
  },
  {
    "text": "and the value tasks AB then we have a node port and the node there are different types of the service and the",
    "start": "2043540",
    "end": "2050590"
  },
  {
    "text": "node port allows us to have a random port and it's static across the nodes of",
    "start": "2050590",
    "end": "2057550"
  },
  {
    "text": "the worker nodes of the cluster and we can connect to our service from the host",
    "start": "2057550",
    "end": "2064120"
  },
  {
    "text": "using that port and we see this in action in the last part of the service is the port section each service could",
    "start": "2064120",
    "end": "2071440"
  },
  {
    "text": "expose multiple services so if we have multiple containers exposed from the pod",
    "start": "2071440",
    "end": "2078340"
  },
  {
    "text": "and those containers have different ports we can use one service with different ports to connect to them and",
    "start": "2078340",
    "end": "2085169"
  },
  {
    "text": "the ports have two parameters the port that will this is the port that the",
    "start": "2085169",
    "end": "2090250"
  },
  {
    "text": "consume inside the cluster could use to communicate with the service and the",
    "start": "2090250",
    "end": "2096100"
  },
  {
    "text": "other port which is the target port which is the one is living inside the pod the next part is the deployment",
    "start": "2096100",
    "end": "2104650"
  },
  {
    "text": "object of the database it's similar to the asp net deployment we have a deployment object with the name mssql",
    "start": "2104650",
    "end": "2110980"
  },
  {
    "text": "deployment the number of replicas in this case we'll just have one database pod and then we have the selector which",
    "start": "2110980",
    "end": "2118360"
  },
  {
    "text": "is again using one label which is AB mssql and it's the same level that we have in",
    "start": "2118360",
    "end": "2124390"
  },
  {
    "text": "our template definition for the sequel server pod and in the specs section we have a new parameter that I have",
    "start": "2124390",
    "end": "2130630"
  },
  {
    "text": "provided here which is termination grace period which is basically if we decided",
    "start": "2130630",
    "end": "2136090"
  },
  {
    "text": "to delete one of the pods kubernetes will allow that pod to be gracefully",
    "start": "2136090",
    "end": "2142060"
  },
  {
    "text": "terminated within 10 seconds if it didn't die within 10 seconds it will force killing that pod and since this is",
    "start": "2142060",
    "end": "2149860"
  },
  {
    "text": "a database I just decided to give it a few seconds to avoid having any corruption with that the next part is",
    "start": "2149860",
    "end": "2158110"
  },
  {
    "text": "the containers and the name of the container and the image I'm using a sequel server image that runs on Linux",
    "start": "2158110",
    "end": "2164590"
  },
  {
    "text": "and it's actually provided by Microsoft and again the image policy that I have here is just use the image from my local",
    "start": "2164590",
    "end": "2171010"
  },
  {
    "text": "machine and the port which is the default sequel server port and there are",
    "start": "2171010",
    "end": "2176050"
  },
  {
    "text": "two environment variables that are required by this image as a password and",
    "start": "2176050",
    "end": "2181650"
  },
  {
    "text": "accepting the license the LA so so far we have created the asp.net pod the",
    "start": "2181650",
    "end": "2187570"
  },
  {
    "text": "service sitting in front of the HP's net pod the sick will deployment and finally the service that will be sitting in",
    "start": "2187570",
    "end": "2193570"
  },
  {
    "text": "front of the service of the database pod so it's similar to the one that we have",
    "start": "2193570",
    "end": "2199120"
  },
  {
    "text": "created for the edge with net bot the only difference is a selector and the port that this service is exposing so",
    "start": "2199120",
    "end": "2206470"
  },
  {
    "text": "let's deploy those four objects and see them in action",
    "start": "2206470",
    "end": "2210720"
  },
  {
    "text": "I'll switch back to the dashboard we can see that inside the deployment section we have two deployments right now the",
    "start": "2218619",
    "end": "2226690"
  },
  {
    "text": "first one is for the sequel server deployment and inside of it a replica set and that replica set is with the pod",
    "start": "2226690",
    "end": "2234190"
  },
  {
    "text": "living inside of it and as you can see there is a service already pointing to that replica site or to the pods living",
    "start": "2234190",
    "end": "2241299"
  },
  {
    "text": "inside the replica set the the new section that I wanted to show you here is the services section and those are",
    "start": "2241299",
    "end": "2247839"
  },
  {
    "text": "the new services that we have created and if we open we have two services the sacred silver service and the asp.net",
    "start": "2247839",
    "end": "2254799"
  },
  {
    "text": "service opening the a spinet service we can see that they are pointing to the pods living inside our replica set and",
    "start": "2254799",
    "end": "2262200"
  },
  {
    "text": "if any of those pods died another one will be created thanks to the replica set but that new pod will automatically",
    "start": "2262200",
    "end": "2269410"
  },
  {
    "text": "be picked up by the service so you don't need to keep a track of the new pods this is done automatically by clip units",
    "start": "2269410",
    "end": "2275140"
  },
  {
    "text": "so if I just decided to deal delete or kill that pod another one would be spend",
    "start": "2275140",
    "end": "2280210"
  },
  {
    "text": "up automatically and as you can see it's automatically picked up by the service",
    "start": "2280210",
    "end": "2285538"
  },
  {
    "text": "right now the other part is the node port part which is the random port I",
    "start": "2286289",
    "end": "2292479"
  },
  {
    "text": "think the default range for those ports are thirty thousand to thirty two thousand seven hundred something like",
    "start": "2292479",
    "end": "2299499"
  },
  {
    "text": "that and we can use that port to connect to our service from the host machine so",
    "start": "2299499",
    "end": "2306789"
  },
  {
    "text": "I will grab the tasks port and then we'll use localhost there you go we have",
    "start": "2306789",
    "end": "2314950"
  },
  {
    "text": "the application running right now the only thing that we didn't see so far which is the manage tasks part it should",
    "start": "2314950",
    "end": "2321460"
  },
  {
    "text": "be running but actually there is one more thing that I didn't do which is creating the database and the tables",
    "start": "2321460",
    "end": "2327700"
  },
  {
    "text": "that are required by our application inside the database pod so for the purpose of this demo I have created a",
    "start": "2327700",
    "end": "2334210"
  },
  {
    "text": "script to do that which is basically a simple script to create a database and table inside of it",
    "start": "2334210",
    "end": "2341339"
  },
  {
    "text": "it requires the server name and I will provide the localhost and the port for",
    "start": "2341339",
    "end": "2347829"
  },
  {
    "text": "the database service once this is completed our talks tab",
    "start": "2347829",
    "end": "2355820"
  },
  {
    "text": "should be running this one very good",
    "start": "2355820",
    "end": "2361340"
  },
  {
    "text": "right now we can see that the tasks has been loaded and we can start adding tasks to it which is great all right the",
    "start": "2361340",
    "end": "2374930"
  },
  {
    "text": "next thing that I wanted to show to you is so far we managed it to deploy our",
    "start": "2374930",
    "end": "2380570"
  },
  {
    "text": "application or a spirit pod connect to a secure server pod and if the database pod died right now another one will be",
    "start": "2380570",
    "end": "2387110"
  },
  {
    "text": "spend up automatically but the data of our cycle server is living inside the",
    "start": "2387110",
    "end": "2392660"
  },
  {
    "text": "container which means if the container died for any reason we will lose the data and since this is the data base we",
    "start": "2392660",
    "end": "2398180"
  },
  {
    "text": "kind of would like to maintain the data regardless of the pot and to do this we need to use another thing with inside",
    "start": "2398180",
    "end": "2404900"
  },
  {
    "text": "Copernicus which is persistent volumes and persistent volumes allows us to",
    "start": "2404900",
    "end": "2409930"
  },
  {
    "start": "2405000",
    "end": "2405000"
  },
  {
    "text": "maintain a set of durable as a piece of durable storage inside the cluster and",
    "start": "2409930",
    "end": "2415150"
  },
  {
    "text": "it captures the storage details the kubernetes cluster has multiple storage",
    "start": "2415150",
    "end": "2420530"
  },
  {
    "text": "options that we can use it could be either a local storage and network storage or it could be even a",
    "start": "2420530",
    "end": "2426320"
  },
  {
    "text": "cloud-based storage and the persistent volumes have individual life cycle from the pods that could be consuming it and",
    "start": "2426320",
    "end": "2433510"
  },
  {
    "text": "any persistent volume could be provisioned in a two ways the first one is manually by the administrator or it",
    "start": "2433510",
    "end": "2440600"
  },
  {
    "text": "could be provisioned dynamically through using another object which is the persistent volume claim so the the",
    "start": "2440600",
    "end": "2447170"
  },
  {
    "text": "persistent William flame is basically a request for us a persistent volume or a request for a storage and that request",
    "start": "2447170",
    "end": "2453620"
  },
  {
    "text": "is basically you could provide I'd like to request eight gigs of a storage and there is another parameter that you need",
    "start": "2453620",
    "end": "2459560"
  },
  {
    "text": "to provide which is the access mode with the access mode it's connected to the storage mechanism that you're gonna use",
    "start": "2459560",
    "end": "2464660"
  },
  {
    "text": "and there are multiple access modes you could have read write once read write mini which the determining how many",
    "start": "2464660",
    "end": "2470840"
  },
  {
    "text": "nodes how many worker nodes could connect and consume your persistent volume and that",
    "start": "2470840",
    "end": "2477650"
  },
  {
    "text": "persistent volume could be consumed by the pot as a data directory living",
    "start": "2477650",
    "end": "2483110"
  },
  {
    "text": "inside of it so if we deploy our sequel silver application and as a",
    "start": "2483110",
    "end": "2488130"
  },
  {
    "text": "pod and we that put requested to have eight gigs of storage Copernicus cluster will automatically",
    "start": "2488130",
    "end": "2494420"
  },
  {
    "text": "provision the persistent volume for us and once the persistent volume is provisioned it will automatically",
    "start": "2494420",
    "end": "2500370"
  },
  {
    "text": "connect that volume to our pod to be consumed by the containers living inside the pod so let's see this in action I",
    "start": "2500370",
    "end": "2508460"
  },
  {
    "text": "will show you the public definition of creating a persistent volume theme the",
    "start": "2508460",
    "end": "2515760"
  },
  {
    "text": "current deployment so here is our persistent volume claim again the same",
    "start": "2515760",
    "end": "2524130"
  },
  {
    "text": "port parameters the kind is persistent volume claim the API version to be used by the cube City L the name was a",
    "start": "2524130",
    "end": "2530280"
  },
  {
    "text": "persistent volume claim the access mode in this case readwrite once which means my hosts and the resources and in this",
    "start": "2530280",
    "end": "2540090"
  },
  {
    "text": "case I just need eight gigs of storage and as you can see I didn't the term or",
    "start": "2540090",
    "end": "2546030"
  },
  {
    "text": "didn't provide the cube in this cluster with where that storage will actually be is it the host or is it the network",
    "start": "2546030",
    "end": "2552540"
  },
  {
    "text": "storage or something each coupon each cluster have a default storage class or",
    "start": "2552540",
    "end": "2558390"
  },
  {
    "text": "a storage type and since I'm using my local cluster the default is using a host path which is basically a directory",
    "start": "2558390",
    "end": "2565740"
  },
  {
    "text": "on the host machine you could provide a different host or different storage",
    "start": "2565740",
    "end": "2570960"
  },
  {
    "text": "mechanisms using another parameter which is called a storage storage class sorry",
    "start": "2570960",
    "end": "2580190"
  },
  {
    "text": "and you could have different storage class names and those logic last names",
    "start": "2580190",
    "end": "2588150"
  },
  {
    "text": "disturbance should I use like Azure storage or should I use a Google storage or should I use network storage but for",
    "start": "2588150",
    "end": "2595380"
  },
  {
    "text": "the purpose of this demo I'll just keep it simple and will use the host pass that is living on my on my host machine",
    "start": "2595380",
    "end": "2602070"
  },
  {
    "text": "on my on my local machine now that we have the persistent volume claim object",
    "start": "2602070",
    "end": "2607110"
  },
  {
    "text": "which is the request for a storage I can consume that storage inside my database",
    "start": "2607110",
    "end": "2612360"
  },
  {
    "text": "pot so I have a new section here which is called volumes and inside the volumes",
    "start": "2612360",
    "end": "2618780"
  },
  {
    "text": "we have a new volume which is mssql EP and it's using the persistent volume",
    "start": "2618780",
    "end": "2625349"
  },
  {
    "text": "claim and all what we need to provide is the claim name so this is the pot",
    "start": "2625349",
    "end": "2630869"
  },
  {
    "text": "section so we have added a pod added a volume to our pod then we can consume that volume inside our container and we",
    "start": "2630869",
    "end": "2638460"
  },
  {
    "text": "do this using the volume mounts inside the volume mounts we provide the name of the volume and the path width which",
    "start": "2638460",
    "end": "2645630"
  },
  {
    "text": "means if we are like building our using this volume for our s treated application or any kind of application",
    "start": "2645630",
    "end": "2651500"
  },
  {
    "text": "this will be the path that your application is to use to actually write the file into it and if you are like",
    "start": "2651500",
    "end": "2658740"
  },
  {
    "text": "writing c-sharp application you can use the normal file IO classes to write to",
    "start": "2658740",
    "end": "2664349"
  },
  {
    "text": "the files to it such as like stream reader or stream writer those will work you don't have to use a custom or a",
    "start": "2664349",
    "end": "2670800"
  },
  {
    "text": "special API is to create read write files inside the container so let's",
    "start": "2670800",
    "end": "2676830"
  },
  {
    "text": "deploy our object before I do that I'd",
    "start": "2676830",
    "end": "2685410"
  },
  {
    "text": "like to show you that the Electra that this volume will be created inside of it and this is basically since I'm using",
    "start": "2685410",
    "end": "2692190"
  },
  {
    "text": "docker for desktop this is going to be inside the docker volumes directory so",
    "start": "2692190",
    "end": "2697320"
  },
  {
    "text": "right now it's empty once we deployed our object eventually the persistent",
    "start": "2697320",
    "end": "2702930"
  },
  {
    "text": "volume will be created here and inside of it the persistent volume clean if I",
    "start": "2702930",
    "end": "2710190"
  },
  {
    "text": "switch back to the dashboard there is a section that allows us to view the persistent volume claims so we have the",
    "start": "2710190",
    "end": "2715950"
  },
  {
    "text": "persistent volume claim created and it's attached to our volume and here is the",
    "start": "2715950",
    "end": "2722730"
  },
  {
    "text": "volume also it's showing me the storage class that I'm using for this persistent volume claim and this is the default for",
    "start": "2722730",
    "end": "2728400"
  },
  {
    "text": "my local cluster in addition to that it's showing me the location of that",
    "start": "2728400",
    "end": "2736040"
  },
  {
    "text": "persistent volume and if I connect our",
    "start": "2736040",
    "end": "2741359"
  },
  {
    "text": "application it's going to work fine and I would like to show you if we went to the database pot which is our sequel",
    "start": "2741359",
    "end": "2748230"
  },
  {
    "text": "server pod we can see that at the last section here that there is a persistent volume that is being consumed by that pot and",
    "start": "2748230",
    "end": "2754410"
  },
  {
    "text": "if I deleted that pot for any random reason that happened a new pot will be",
    "start": "2754410",
    "end": "2760620"
  },
  {
    "text": "is pinned up automatically and if I open that pod we can see that it's already",
    "start": "2760620",
    "end": "2766440"
  },
  {
    "text": "attached it to the persistent William claim object that we have created because persistent we have created",
    "start": "2766440",
    "end": "2772200"
  },
  {
    "text": "decoupled the storage from the pot life cycle and for all the demos that I have",
    "start": "2772200",
    "end": "2781440"
  },
  {
    "text": "been doing I want to show you that I'm using a docker for desktop it's basically if you are having a docker",
    "start": "2781440",
    "end": "2788220"
  },
  {
    "text": "installation already on your local machine you go to the settings section and in there you have a keeper unity",
    "start": "2788220",
    "end": "2793470"
  },
  {
    "text": "step and once you enable it this will give you a coupon it is cluster on your",
    "start": "2793470",
    "end": "2798690"
  },
  {
    "text": "machine it has some limitations but it's a very good start to start playing around with coupon et's and see what are",
    "start": "2798690",
    "end": "2805380"
  },
  {
    "text": "the features and how would you accept your with it but so far we have been",
    "start": "2805380",
    "end": "2811070"
  },
  {
    "text": "deploying coupon it is on my local machine but at a certain point after you build the application you would like to",
    "start": "2811070",
    "end": "2816930"
  },
  {
    "text": "deploy that application to a production environment and you could do this by provision capabilities in different ways",
    "start": "2816930",
    "end": "2822780"
  },
  {
    "text": "like on virtual machines on the cloud or it could use cloud offering or even if you have your own data center you can do",
    "start": "2822780",
    "end": "2828990"
  },
  {
    "text": "this as well but the I usually think that there are there is a good value of using platform as a service it might not",
    "start": "2828990",
    "end": "2836850"
  },
  {
    "text": "be the best case for all the situations but one of the things that I believe in",
    "start": "2836850",
    "end": "2842640"
  },
  {
    "text": "is the platform of the service it makes it very easy to provision a keep in each cluster so we don't need to think about",
    "start": "2842640",
    "end": "2848580"
  },
  {
    "text": "how would we operate and maintain our cluster as an example with the cloud offerings for from Azure you don't even",
    "start": "2848580",
    "end": "2854910"
  },
  {
    "text": "need to think what's happening behind the scene for your master node they are already managing this for us we",
    "start": "2854910",
    "end": "2861000"
  },
  {
    "text": "don't need to think about how many nodes we need how would we operate and pack up and monitor those nodes it just happened",
    "start": "2861000",
    "end": "2867150"
  },
  {
    "text": "it happens for us moreover we could also gain some features like those cloud",
    "start": "2867150",
    "end": "2873810"
  },
  {
    "text": "offerings allows us to update our cluster to the latest version of copernicus or change to a previous",
    "start": "2873810",
    "end": "2879720"
  },
  {
    "text": "version of communities without any downtime of the HIPAA needs cluster we could also scale the number of",
    "start": "2879720",
    "end": "2885640"
  },
  {
    "text": "worker worker nodes in our cluster without any downtime and all those features will take a lot of time from",
    "start": "2885640",
    "end": "2893200"
  },
  {
    "text": "engineering perspective to build ourselves if we will use our own virtual",
    "start": "2893200",
    "end": "2899470"
  },
  {
    "text": "machines so and let me show you how would you actually spin up a clip",
    "start": "2899470",
    "end": "2904720"
  },
  {
    "text": "Anita's cluster on top of Asia it's pretty simple you just need one command as your I guess this is the azure CLI",
    "start": "2904720",
    "end": "2912990"
  },
  {
    "start": "2908000",
    "end": "2908000"
  },
  {
    "text": "IKS is the azure capability service from isis which is platform as a service",
    "start": "2912990",
    "end": "2918609"
  },
  {
    "text": "offering you provide create command and provide the AKS cluster name and the",
    "start": "2918609",
    "end": "2924339"
  },
  {
    "text": "resource group name and behind the scene in a few minutes you will have a keep a fully functioning capabilities cluster",
    "start": "2924339",
    "end": "2930819"
  },
  {
    "text": "there are other parameters that you could provide into your cluster creation as well but I just kept it simple here",
    "start": "2930819",
    "end": "2937359"
  },
  {
    "text": "like the number of the worker nodes that you would like to have and while you are initiating by default I think there are",
    "start": "2937359",
    "end": "2943450"
  },
  {
    "text": "just three nodes after we create the cluster we need to run another command",
    "start": "2943450",
    "end": "2948910"
  },
  {
    "text": "to access this cluster which is the get credentials command and the get credentials command responsibility is to",
    "start": "2948910",
    "end": "2955390"
  },
  {
    "text": "update that cube CTL client to point it to the cluster that we just created and",
    "start": "2955390",
    "end": "2960400"
  },
  {
    "text": "this will allows us to use the exact same commands that we have been using so far which is actually like a couple of",
    "start": "2960400",
    "end": "2966849"
  },
  {
    "text": "commands but we don't have to have a different version of the commands while you are connecting through that to the",
    "start": "2966849",
    "end": "2972849"
  },
  {
    "text": "new newly created cluster so we can use commands like get nodes or we could",
    "start": "2972849",
    "end": "2978430"
  },
  {
    "text": "apply or create or run anything that we do on our local cluster will just work",
    "start": "2978430",
    "end": "2983559"
  },
  {
    "text": "on the new cluster and with just a simple command we can spin up any",
    "start": "2983559",
    "end": "2990450"
  },
  {
    "text": "rescale the number of the worker node that we have in the cluster it's just a case a scale and this will automatically",
    "start": "2990450",
    "end": "2997049"
  },
  {
    "text": "change the number of the workers that we have in the cluster even better with cloud offerings like azor we could have",
    "start": "2997049",
    "end": "3003750"
  },
  {
    "text": "something like as a cluster autoscaler and when we deploy the azure cluster with a scaler what happens is it keeps",
    "start": "3003750",
    "end": "3010529"
  },
  {
    "text": "monitoring the work or the pods that are scheduled on the workers and pasted on",
    "start": "3010529",
    "end": "3016380"
  },
  {
    "text": "the queue that we have from work on each could start dynamically provisioned more",
    "start": "3016380",
    "end": "3022920"
  },
  {
    "text": "worker nodes or kill nodes and there are some parameters or configurations that we could provide to the auto cluster to",
    "start": "3022920",
    "end": "3029460"
  },
  {
    "text": "determine when and when to create or to kill nodes and with this feature this",
    "start": "3029460",
    "end": "3036630"
  },
  {
    "text": "provides us with a better cost management of our cluster because we don't even need to worry how many",
    "start": "3036630",
    "end": "3042000"
  },
  {
    "text": "clusters we don't need to manually keep interrupting our operation and monitoring we don't have much",
    "start": "3042000",
    "end": "3047430"
  },
  {
    "text": "utilization of that worker node so let's minimize the workers and stuff like that and that's basically what I wanted to",
    "start": "3047430",
    "end": "3054120"
  },
  {
    "start": "3054000",
    "end": "3054000"
  },
  {
    "text": "share with you today what is that keeper needs while you should care about it what is the company's architecture how",
    "start": "3054120",
    "end": "3059790"
  },
  {
    "text": "would we use the key building blocks of keeper needs to deploy our application on top of it and what are the key values",
    "start": "3059790",
    "end": "3065550"
  },
  {
    "text": "of the cloud offering the I'd like to share with you some resources so I'll",
    "start": "3065550",
    "end": "3070860"
  },
  {
    "start": "3068000",
    "end": "3068000"
  },
  {
    "text": "publish the presentation later today on my blog if you would like to see the demos that I have done today it's",
    "start": "3070860",
    "end": "3077100"
  },
  {
    "text": "already available on github you can access it right now if you would like to learn more about the spectrum of",
    "start": "3077100",
    "end": "3082850"
  },
  {
    "text": "hypnotists I would like to recommend those two courses introduction to Cooper needs and learning Kaepernick is using",
    "start": "3082850",
    "end": "3089580"
  },
  {
    "text": "interactive hands-on like with that second part you don't even need to spin up a cluster on your machine you can do",
    "start": "3089580",
    "end": "3096240"
  },
  {
    "text": "this in the cloud and the last part is cue Benitez is moving very very fast so",
    "start": "3096240",
    "end": "3103710"
  },
  {
    "text": "if you would like to learn about any subject in kubernetes I would recommend to get back to the Corinthians",
    "start": "3103710",
    "end": "3109050"
  },
  {
    "text": "documentation because because this is the almost always up-to-date source of truth and that's what I wanted to share",
    "start": "3109050",
    "end": "3116700"
  },
  {
    "text": "with you today are not sure if I have time for questions I think we have time",
    "start": "3116700",
    "end": "3122970"
  },
  {
    "text": "for a question or two",
    "start": "3122970",
    "end": "3125780"
  },
  {
    "text": "Tomic then the client when you connect",
    "start": "3128680",
    "end": "3135619"
  },
  {
    "text": "you Asia embeds that credential shoot a good client so how do you switch between",
    "start": "3135619",
    "end": "3140839"
  },
  {
    "text": "the local and that's a very good question so keep the cube CTL have",
    "start": "3140839",
    "end": "3146930"
  },
  {
    "text": "something called use DL config and with the config I think I can show it very",
    "start": "3146930",
    "end": "3153380"
  },
  {
    "text": "quickly so cube CTL config this commands",
    "start": "3153380",
    "end": "3159650"
  },
  {
    "text": "has multiple sub commands that you can use and I will show you cube sorry CTL",
    "start": "3159650",
    "end": "3167710"
  },
  {
    "text": "config get contexts this will show me three this will show me the different",
    "start": "3167710",
    "end": "3176839"
  },
  {
    "text": "contexts that I have so on my machine I have local for desktop mini cube and NDC IKS cluster and I can use a command",
    "start": "3176839",
    "end": "3185000"
  },
  {
    "text": "like cube CTL config use context and the use context will allow me to switch between different clusters any other",
    "start": "3185000",
    "end": "3193460"
  },
  {
    "text": "questions",
    "start": "3193460",
    "end": "3195910"
  },
  {
    "text": "this wandering crew have video tests that have all the environments like you working Varma like this so we can just",
    "start": "3200890",
    "end": "3208280"
  },
  {
    "text": "do some experiment at home in Windows humans so the question is - how would",
    "start": "3208280",
    "end": "3213530"
  },
  {
    "text": "you have multiple environments like the Windows environment you set up for the demo today how to set it up like we",
    "start": "3213530",
    "end": "3222589"
  },
  {
    "text": "could experiment how to do in a Windows environments yeah this is actually our Windows machine that oh yeah there's no",
    "start": "3222589",
    "end": "3228589"
  },
  {
    "text": "machine could you do how to set it up like a step by step what kind of to to",
    "start": "3228589",
    "end": "3234950"
  },
  {
    "text": "install and yeah so first all what you need is to go to the docker calm down",
    "start": "3234950",
    "end": "3240650"
  },
  {
    "text": "lose the docker latest stable one once you install it you will have in the",
    "start": "3240650",
    "end": "3247010"
  },
  {
    "text": "settings section there is a tab for the coupon it is and with that tab you just this is by default will be disabled like",
    "start": "3247010",
    "end": "3254119"
  },
  {
    "text": "that once you enable it and you select kubernetes apply this will automatically",
    "start": "3254119",
    "end": "3259670"
  },
  {
    "text": "configure your local machine with a coupon it is cluster it will also configure I believe the cube CTL to",
    "start": "3259670",
    "end": "3266599"
  },
  {
    "text": "automatically connect to that local cluster this is not mini cube this is",
    "start": "3266599",
    "end": "3274310"
  },
  {
    "text": "just token for desktop and it has a feature for the kunis cluster yep go",
    "start": "3274310",
    "end": "3281540"
  },
  {
    "text": "ahead just managing your own cluster I",
    "start": "3281540",
    "end": "3289900"
  },
  {
    "text": "understand there are the cloud options I've heard a lot of stories of the",
    "start": "3289900",
    "end": "3296020"
  },
  {
    "text": "cluster needing a lot of love keep it up",
    "start": "3296020",
    "end": "3301690"
  },
  {
    "text": "what's your take on that like how many people would you dedicate to loving the",
    "start": "3301690",
    "end": "3307480"
  },
  {
    "text": "cluster as opposed to well so yes having",
    "start": "3307480",
    "end": "3316720"
  },
  {
    "text": "your own cluster it's similar to have any kind of cluster that you have but I think there are right now some good",
    "start": "3316720",
    "end": "3323020"
  },
  {
    "text": "solutions that makes it a little bit better so if you would like to spin up your cluster I think the way to go right",
    "start": "3323020",
    "end": "3330160"
  },
  {
    "text": "now is to use Cuba spray and this will make your life a little bit easier when",
    "start": "3330160",
    "end": "3335650"
  },
  {
    "text": "you are spinning that cluster and if you'd like to apply configurations from infrastructure perspective the sequel",
    "start": "3335650",
    "end": "3349720"
  },
  {
    "text": "migrations he used the sequel service node pole to connect directly to the sequel database",
    "start": "3349720",
    "end": "3355030"
  },
  {
    "text": "yep would you still do that in object",
    "start": "3355030",
    "end": "3365849"
  },
  {
    "text": "well I think this will be actually a case-by-case so I actually I think if",
    "start": "3368069",
    "end": "3373930"
  },
  {
    "text": "you will go with the kiparis cluster the CI pipeline wouldn't actually you wouldn't actually use those deployment",
    "start": "3373930",
    "end": "3379450"
  },
  {
    "text": "objects immediately you would usually go with a helmet charts so helm is",
    "start": "3379450",
    "end": "3384910"
  },
  {
    "text": "basically allowing us to have a better management of the queue penitas objects",
    "start": "3384910",
    "end": "3390099"
  },
  {
    "text": "so if you have multiple objects you can package those objects in a helmet chart and then you would use your helmet chart",
    "start": "3390099",
    "end": "3395799"
  },
  {
    "text": "in inside your CI pipeline but I don't think if there is a specific object that",
    "start": "3395799",
    "end": "3402190"
  },
  {
    "text": "I have in mind that comes to the database migration to use with coop unities does that answer the question",
    "start": "3402190",
    "end": "3408849"
  },
  {
    "text": "yep",
    "start": "3408849",
    "end": "3411210"
  },
  {
    "text": "multiple services deployed and they have to talk to each other so how easy it is to manage using this",
    "start": "3415520",
    "end": "3421580"
  },
  {
    "text": "given it is so I think this is one of the good offerings from communities so",
    "start": "3421580",
    "end": "3427330"
  },
  {
    "text": "there are if you're concerned about the security there are some plugins that could be attached to the Cooper nice",
    "start": "3427330",
    "end": "3434150"
  },
  {
    "text": "cluster to say this service could communicate to that service or that pod but it couldn't communicate to the other",
    "start": "3434150",
    "end": "3440510"
  },
  {
    "text": "put for any reason from a like deployment perspective I would use",
    "start": "3440510",
    "end": "3445760"
  },
  {
    "text": "different I would consider each service as its own application and it should",
    "start": "3445760",
    "end": "3452630"
  },
  {
    "text": "have its own the deployment or pipeline because services should be independently deployed and they should have different",
    "start": "3452630",
    "end": "3458690"
  },
  {
    "text": "lifecycle that's how would you iterate on the micro services I think that's I don't have time for more questions but",
    "start": "3458690",
    "end": "3465230"
  },
  {
    "text": "I'll be here for the rest of the day and tomorrow so if you have any questions please feel free to come and chat with",
    "start": "3465230",
    "end": "3471590"
  },
  {
    "text": "me thank you",
    "start": "3471590",
    "end": "3474430"
  }
]
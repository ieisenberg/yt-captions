[
  {
    "text": "okay good afternoon everybody hello Copenhagen it's lovely to be here uh",
    "start": "3799",
    "end": "9080"
  },
  {
    "text": "welcome to my session build your own co-pilot um slightly ironically you'll notice on the schedule that there's a",
    "start": "9080",
    "end": "14920"
  },
  {
    "text": "capital P in co-pilot we're going to talk a little bit about that that's incorrect it shouldn't have a capital P but anyway let's get started um okay",
    "start": "14920",
    "end": "22519"
  },
  {
    "text": "this is me I'm Callum um I'm a software developer by trade. net really um I work",
    "start": "22519",
    "end": "27840"
  },
  {
    "text": "with an open source Danish CMS called umbraco um it's really cool you should check it out I'm a Microsoft MVP and an",
    "start": "27840",
    "end": "34440"
  },
  {
    "text": "umbraco MVP do quite a bit around the community I run a uh software consultancy in the UK where we do um",
    "start": "34440",
    "end": "40600"
  },
  {
    "text": "braco and Azure Solutions in general um and I'm really fortunate to get to go all over the world and speak to lovely",
    "start": "40600",
    "end": "46440"
  },
  {
    "text": "people like you so uh thanks for joining me um sci-fi would have led us to believe",
    "start": "46440",
    "end": "53520"
  },
  {
    "text": "growing up that probably by now we'd have these AI assistants that could do absolutely anything for us thinking sort",
    "start": "53520",
    "end": "59840"
  },
  {
    "text": "of of uh Javis from Iron Man for example and uh I mean that's not quite the case",
    "start": "59840",
    "end": "64878"
  },
  {
    "text": "is it but uh it's maybe more of a reality than it's ever been with the uh",
    "start": "64879",
    "end": "70200"
  },
  {
    "text": "wide accessibility of things like open Ai and chat GPT these things are now in common domain people have uh smart",
    "start": "70200",
    "end": "77240"
  },
  {
    "text": "assistants in their phones all this sort of thing so you know whilst we maybe don't have an all-encompassing AI that",
    "start": "77240",
    "end": "83159"
  },
  {
    "text": "runs our life we're perhaps getting closer there and of course the amazing",
    "start": "83159",
    "end": "89360"
  },
  {
    "text": "marketing f Folks at Microsoft decided they were going to put a name on this they were going to call it a co-pilot if",
    "start": "89360",
    "end": "94720"
  },
  {
    "text": "you work at open AI they decided for even catch a name of gpts which is uh",
    "start": "94720",
    "end": "100159"
  },
  {
    "text": "yeah not great but the question co-pilot co-pilot or co-pilot what is a co-pilot",
    "start": "100159",
    "end": "105880"
  },
  {
    "text": "um so in the sense that we're talking today a co-pilot an AI co-pilot means a uh an AI assistant to you uh the one",
    "start": "105880",
    "end": "113360"
  },
  {
    "text": "with the dash in it is the person that flies the plane and the one with the capital P is when people spell it wrong",
    "start": "113360",
    "end": "119039"
  },
  {
    "text": "Microsoft insists on it being a lowercase p so for all purposes today we're talking about yeah co-pilots with",
    "start": "119039",
    "end": "125479"
  },
  {
    "text": "a with a lowercase uh with a lowercase p oh there's no background oh well uh as",
    "start": "125479",
    "end": "133200"
  },
  {
    "text": "of right now Microsoft has has over a hundred co-pilot branded products they have a co-pilot for absolutely",
    "start": "133200",
    "end": "139720"
  },
  {
    "text": "everything nowadays um it's seemingly all the trend uh and I'm not sure I necessarily agree with this word it's",
    "start": "139720",
    "end": "145680"
  },
  {
    "text": "basically just applying AI in context to uh a lot of their products with the idea",
    "start": "145680",
    "end": "150720"
  },
  {
    "text": "of it helping you out and and uh yeah making your life a bit easier there's my",
    "start": "150720",
    "end": "156080"
  },
  {
    "text": "background I don't know why that didn't load so realistically we can distill the",
    "start": "156080",
    "end": "161720"
  },
  {
    "text": "concept of a co-pilot down to a couple of things it should be an intelligent and humanlike assistant um so this is",
    "start": "161720",
    "end": "170280"
  },
  {
    "text": "perhaps uh slightly different to the uh the sort of AI chatbots that people were building maybe 10 years ago which is a",
    "start": "170280",
    "end": "176400"
  },
  {
    "text": "faq's thing and basically just doing search and retrieval now nowadays it needs to be almost convincing to be like",
    "start": "176400",
    "end": "182440"
  },
  {
    "text": "it's a human responding to it needs to have a bit of Personality uh and it's there ultimately to be an assistant to",
    "start": "182440",
    "end": "188760"
  },
  {
    "text": "your life uh a a companion if you will um there is uh one thing I'd add to this",
    "start": "188760",
    "end": "194239"
  },
  {
    "text": "though which is I actually think it should be a specialized intelligent humanik assistant um there's no catchy",
    "start": "194239",
    "end": "201360"
  },
  {
    "text": "acronym for this but something something along these lines um the term that's generally used in the AI space is Agents",
    "start": "201360",
    "end": "207239"
  },
  {
    "text": "people are talking about building agents now and an agent is a uh an AI That's designed to do one specific task very",
    "start": "207239",
    "end": "214239"
  },
  {
    "text": "well rather than having one of these AIS that can do everything you'd have an agent that can do things like booking flights for you or organizing your",
    "start": "214239",
    "end": "220840"
  },
  {
    "text": "calendar and then you might have an overarching uh assistant that is responsible for delegating to those",
    "start": "220840",
    "end": "227400"
  },
  {
    "text": "different agent systems so Building A specialized uh co-pilot is sort of the way we're going and that's what",
    "start": "227400",
    "end": "233480"
  },
  {
    "text": "Microsoft's done if you look they've got 100 co-pilots for a reason they are not building one co-pilot that does",
    "start": "233480",
    "end": "239000"
  },
  {
    "text": "everything they got one for 365 they've got one for um uh you know Bing Azure in",
    "start": "239000",
    "end": "245560"
  },
  {
    "text": "fact even in Azure the the Azure domain is so large they've got specialized co-pilots with a specialized bits of",
    "start": "245560",
    "end": "251120"
  },
  {
    "text": "azure that you might want to work on so yeah specialized uh intelligent human-like assistance is where we're",
    "start": "251120",
    "end": "257120"
  },
  {
    "text": "trying to go and in a lot of these cases essentially what they're doing is building something called a uh a rag",
    "start": "257120",
    "end": "264560"
  },
  {
    "text": "retrieval augmented generation uh integration so uh what rag means is",
    "start": "264560",
    "end": "270639"
  },
  {
    "text": "fetching data from lots of different places pulling it together and tying that together with a large language",
    "start": "270639",
    "end": "276000"
  },
  {
    "text": "model so large language models as we probably know now don't know everything um they have uh a good understanding of",
    "start": "276000",
    "end": "283120"
  },
  {
    "text": "human language and the way human behavior works and also logic and they're getting increasingly good at Discerning you know what it should do",
    "start": "283120",
    "end": "289400"
  },
  {
    "text": "when it's asked a certain instruction but it doesn't have access to the wealth of information it doesn't have access to",
    "start": "289400",
    "end": "295440"
  },
  {
    "text": "information internal to your company it doesn't have access to um",
    "start": "295440",
    "end": "300720"
  },
  {
    "text": "well the ability to uh perform tasks that it necessarily doesn't know about or perform tasks on internal",
    "start": "300720",
    "end": "307240"
  },
  {
    "text": "infrastructure for example so retrieval augmented generation is a way we can bring uh llms and our own code together",
    "start": "307240",
    "end": "315039"
  },
  {
    "text": "to make a powerful specialized type co-pilot",
    "start": "315039",
    "end": "320240"
  },
  {
    "text": "experience um this also includes talking to a bunch of like public apis so you could do rag with say the Bing API you",
    "start": "320240",
    "end": "327160"
  },
  {
    "text": "could do rag with um other data stores like SQL databases Cosmos DB Etc and you",
    "start": "327160",
    "end": "333080"
  },
  {
    "text": "can also do it with Vector databases um things that are directly designed to work with",
    "start": "333080",
    "end": "339759"
  },
  {
    "text": "llms oh that skipped ahead far too quickly so Microsoft has created a bunch of products that actually make this",
    "start": "339759",
    "end": "345600"
  },
  {
    "text": "really easy to do um even in a low code nearly no code scenario they have this",
    "start": "345600",
    "end": "351720"
  },
  {
    "text": "co-pilot studio and if you want to go and build a co-pilot right now you can you pay 200 bucks that gives you",
    "start": "351720",
    "end": "357919"
  },
  {
    "text": "35,000 uh executions or something a month um and so you could build a a co-pilot for your internal application",
    "start": "357919",
    "end": "364639"
  },
  {
    "text": "you go here you select the type of uh co-pilot you trying to build you can start with one of these templates so",
    "start": "364639",
    "end": "369960"
  },
  {
    "text": "okay I'd like to create an approval manager a workflow type co-pilot where you would then build that up and uh yeah",
    "start": "369960",
    "end": "377000"
  },
  {
    "text": "determine your logic directly in the UI if you fancy you can just describe it in natural language straight to uh co-pilot",
    "start": "377000",
    "end": "383479"
  },
  {
    "text": "studio and it will create you a co-pilot magic um there's a bunch of connectors and available knowledge sources too so",
    "start": "383479",
    "end": "390680"
  },
  {
    "text": "from this it can pull in data from a whole host of Microsoft services in this case you know Azure devops all the way",
    "start": "390680",
    "end": "396560"
  },
  {
    "text": "through to a CSV file SQL databases the lot um and you can create your own custom data sources if you really want",
    "start": "396560",
    "end": "403080"
  },
  {
    "text": "to as well in fact you can connect them with other models hosted elsewhere in the cloud so you get even more power",
    "start": "403080",
    "end": "409199"
  },
  {
    "text": "right at your fingertips and then finally you can deploy these basically where your end users need them so",
    "start": "409199",
    "end": "416039"
  },
  {
    "text": "through uh co-pilot Studio you can select a bunch of connectors you can say I'd like this to be a teams chat bot",
    "start": "416039",
    "end": "423120"
  },
  {
    "text": "that can answer questions that are coming from a database that we house internally or from a CSV file or even",
    "start": "423120",
    "end": "428680"
  },
  {
    "text": "from I don't know our entire M365 SharePoint uh knowledge base or",
    "start": "428680",
    "end": "434319"
  },
  {
    "text": "something it's fairly powerful and you can deploy this multiple places so you can have it in uh slack you can have it",
    "start": "434319",
    "end": "439520"
  },
  {
    "text": "in intercom Etc so it can answer even End customer um requests too this is",
    "start": "439520",
    "end": "445560"
  },
  {
    "text": "quite cool because without any code I can write and have a co-pilot running in literal minutes that",
    "start": "445560",
    "end": "451800"
  },
  {
    "text": "said I'd like to talk about a term that maybe people aren't so familiar with which is natural user interfaces when we",
    "start": "451800",
    "end": "458639"
  },
  {
    "text": "think of user interface or UI design we're generally designing for humans but it seems like we might have forgotten a",
    "start": "458639",
    "end": "464360"
  },
  {
    "text": "bit of this in recent times the ways that we're interacting with llms on the whole is through a chat interface and",
    "start": "464360",
    "end": "470840"
  },
  {
    "text": "whilst that's cool it still means I need to go and express exactly what I'm looking for to get that data out of the",
    "start": "470840",
    "end": "477280"
  },
  {
    "text": "llm and it's pretty good at predicting whether gaps might be but it's certainly not natural I saw a great thing on uh",
    "start": "477280",
    "end": "483919"
  },
  {
    "text": "somewhere on the internet recently that said about uh the difference between sort of 20 years ago 10 years ago and",
    "start": "483919",
    "end": "490000"
  },
  {
    "text": "now as a programmer looking for an answer on the Internet is 20 years ago you needed to know exactly what you were",
    "start": "490000",
    "end": "495919"
  },
  {
    "text": "looking for you needed to know the reference book to go and look in to go and find that piece of information to get your answer 10 years ago you go on",
    "start": "495919",
    "end": "502800"
  },
  {
    "text": "to stack Overflow and you'd ask your question and you'd still have to articulate it in a way that someone else could understand but on the whole they",
    "start": "502800",
    "end": "511120"
  },
  {
    "text": "uh might work it out or ask you a few follow-up questions to get it right and nowadays it's more about giving a vague",
    "start": "511120",
    "end": "517039"
  },
  {
    "text": "description to an llm and the llm Will based on statistics and prediction work out what it thinks you're trying to",
    "start": "517039",
    "end": "523680"
  },
  {
    "text": "do and with natural user interface I think we're looking forward 10 years this is where uh AI Solutions AI",
    "start": "523680",
    "end": "530959"
  },
  {
    "text": "Integrations will not be interacted with through a chat interface but through maybe hand gestures and through um",
    "start": "530959",
    "end": "539000"
  },
  {
    "text": "verbal description you could have a literal conversation with them um if you look at existing systems",
    "start": "539000",
    "end": "546320"
  },
  {
    "text": "things like Siri Google Assistant which are largely you know Voice driven assistants these have been around a while and this is a good example of a",
    "start": "546320",
    "end": "551880"
  },
  {
    "text": "natural user interface compared to something like chat gpts",
    "start": "551880",
    "end": "557079"
  },
  {
    "text": "chatbot okay we're actually going to talk about some code now whilst those um whilst those Microsoft co-pilot studio",
    "start": "557079",
    "end": "564959"
  },
  {
    "text": "type products look cool um I want a bit more flexibility and a bit more power I'd like to be able to control the exact",
    "start": "564959",
    "end": "570720"
  },
  {
    "text": "experience the only place you're deploying those is again through chat-based interfaces how do we take the",
    "start": "570720",
    "end": "576480"
  },
  {
    "text": "power of an llm integrate it into our application and do that in a friendly way where someone else can use it",
    "start": "576480",
    "end": "582519"
  },
  {
    "text": "without necessarily needing to know about our product or how it works so semantic kernel is a fantastic fantastic",
    "start": "582519",
    "end": "588120"
  },
  {
    "text": "open source product from Microsoft it's effectively a lightweight SDK that wraps around uh a number of different llms",
    "start": "588120",
    "end": "595279"
  },
  {
    "text": "it's an abstraction uh there is a c a python and a Java implementation of this the Java one is incredibly poorly maybe",
    "start": "595279",
    "end": "602839"
  },
  {
    "text": "not even documented um the other two are really good uh especially C and C is what I'm going to be talking about today",
    "start": "602839",
    "end": "608800"
  },
  {
    "text": "if you're not a c Dev hopefully you can at least grasp the the key Concepts um out of the box they offer a lot of",
    "start": "608800",
    "end": "614920"
  },
  {
    "text": "Integrations with different a variety wide variety of models so open Ai and",
    "start": "614920",
    "end": "620240"
  },
  {
    "text": "all of the Azure open AI variants of those those are just Azure hosted equivalents hugging face which is a big",
    "start": "620240",
    "end": "626519"
  },
  {
    "text": "large platform of uh llms and models any open source model so this is completely",
    "start": "626519",
    "end": "631880"
  },
  {
    "text": "open you can build your own providers and you can integrate your own tools with semantic kernel and also local",
    "start": "631880",
    "end": "637320"
  },
  {
    "text": "models so you could run a model internally on your own infrastructure and you could talk to that through",
    "start": "637320",
    "end": "642800"
  },
  {
    "text": "semantic kernel um by default The Three core features that it supports are uh a",
    "start": "642800",
    "end": "648880"
  },
  {
    "text": "chat messaging based uh interaction a bit like you'd be used to with chat upt",
    "start": "648880",
    "end": "654240"
  },
  {
    "text": "um and also text and embedding Generation Um there's a few experimental featur as well that depending on the",
    "start": "654240",
    "end": "661200"
  },
  {
    "text": "platform uh they may or may not support so um there is support in the open AI",
    "start": "661200",
    "end": "666800"
  },
  {
    "text": "implementations for example for images and for audio that is text to image and image to text and the same for audio",
    "start": "666800",
    "end": "674480"
  },
  {
    "text": "audio to text and text to audio of course it's open source you can contribute and the code and the repo is",
    "start": "674480",
    "end": "681079"
  },
  {
    "text": "pretty active so I recommend you go and check it out we're also going to talk today about",
    "start": "681079",
    "end": "686760"
  },
  {
    "text": "the Azure open AI service so I think open AI is probably probably considered",
    "start": "686760",
    "end": "692120"
  },
  {
    "text": "to be the leader in the AI race at the moment depends on who you ask I know uh it probably changes on a daily basis now",
    "start": "692120",
    "end": "697760"
  },
  {
    "text": "but the reason we're doing this is Microsoft has of course backed open AI quite heavily and it means we have the",
    "start": "697760",
    "end": "704240"
  },
  {
    "text": "wealth and the breadth of all of the AI models that open AI produce directly in Azure most of them are hosted in Azure",
    "start": "704240",
    "end": "711079"
  },
  {
    "text": "by default natively so the Azure open AI service allows us to literally deploy",
    "start": "711079",
    "end": "716399"
  },
  {
    "text": "those models directly onto Azure infrastructure and consume them everything from GPT 4 and all the",
    "start": "716399",
    "end": "721760"
  },
  {
    "text": "variants we've got 40 and 4 mini now gpt3 35 codex models for code generation",
    "start": "721760",
    "end": "727320"
  },
  {
    "text": "darly for image generation and Whisper for text to uh text to speech and speech to text um it's fairly cheap so you",
    "start": "727320",
    "end": "735240"
  },
  {
    "text": "paying around half a cent per thousand tokens per K tokens um and you pay",
    "start": "735240",
    "end": "742040"
  },
  {
    "text": "around 1.5 yeah 1.5 cents per K tokens of output so you can deploy this fairly",
    "start": "742040",
    "end": "748480"
  },
  {
    "text": "cheaply Within your uh within your uh applications um of course caching Etc in",
    "start": "748480",
    "end": "755120"
  },
  {
    "text": "front of this as well will make this a lot more efficient and even more cost effective they've also got this feature called batching where if you don't have",
    "start": "755120",
    "end": "761600"
  },
  {
    "text": "a uh sort of response critical AI workload perform you just want to Chuck a load of data or a load of prompts at",
    "start": "761600",
    "end": "768160"
  },
  {
    "text": "open Ai and say go generate me some images you can do that and they will do it within 24 hours and you get a 50%",
    "start": "768160",
    "end": "776040"
  },
  {
    "text": "discount by doing so so this wouldn't be great if you were building a sort of realtime user flow but if you need a way",
    "start": "776040",
    "end": "781639"
  },
  {
    "text": "of I don't know summarizing or validating some text that uh a bunch of people have submitted on a form this is",
    "start": "781639",
    "end": "787560"
  },
  {
    "text": "great do it in a batch job collect them within 24 hours um everything that you",
    "start": "787560",
    "end": "792680"
  },
  {
    "text": "can host in Azure open AI is also available via the regular open AI apis",
    "start": "792680",
    "end": "798480"
  },
  {
    "text": "so with semantic kernel it's just one config switch and I can switch out an Azure open AI key and configuration for",
    "start": "798480",
    "end": "805360"
  },
  {
    "text": "a regular a uh regular open AI key as well so pretty powerful integrates",
    "start": "805360",
    "end": "810720"
  },
  {
    "text": "directly and supports all of the features so today I'm going to show you a couple of ways that I'm trying to make",
    "start": "810720",
    "end": "817320"
  },
  {
    "text": "um some form of uh interactive friendly uh co-pilot for a tool that people",
    "start": "817320",
    "end": "823959"
  },
  {
    "text": "wouldn't be necessarily aware of or that definitely the open AI models don't know a thing about so how do we do that um",
    "start": "823959",
    "end": "831720"
  },
  {
    "text": "I've got three or four demos I've made the relevant sacrifices I think and I'm hopeful that these are going to work so",
    "start": "831720",
    "end": "838399"
  },
  {
    "text": "um here's some C sharp code do I need to zoom that in for anybody little bit",
    "start": "838399",
    "end": "844040"
  },
  {
    "text": "cool how about that better cool so uh semantic kernel",
    "start": "844399",
    "end": "851600"
  },
  {
    "text": "is as I mentioned a c SDK we can install this into our project and we can use",
    "start": "851600",
    "end": "857199"
  },
  {
    "text": "this pretty much straight away without too much configuration so here I have a uh a controller it's a standard MVC",
    "start": "857199",
    "end": "863920"
  },
  {
    "text": "controller not doing anything special here and what I have done is injected my kernel the Kel is the key Concept in",
    "start": "863920",
    "end": "870600"
  },
  {
    "text": "semantic kernel that allows you to interact directly with the models you have connected to uh and with a single",
    "start": "870600",
    "end": "877600"
  },
  {
    "text": "prompt a single command I can call kernel invoke prompt pass in some text and it will call whatever base model I",
    "start": "877600",
    "end": "884440"
  },
  {
    "text": "have configured and it will come back with a textual response um I mentioned at the start that uh I work with an open",
    "start": "884440",
    "end": "891240"
  },
  {
    "text": "source danger CMS called embraco and I'm going to use that as a vehicle for a lot of my demos here um crucially embraco is",
    "start": "891240",
    "end": "897920"
  },
  {
    "text": "open source and it allows us to build plugins for the UI I'll Zoom that one in",
    "start": "897920",
    "end": "903040"
  },
  {
    "text": "a bit as well for you so um this is the latest version of MCO it runs JavaScript and so I'm able to build JavaScript",
    "start": "903040",
    "end": "909720"
  },
  {
    "text": "plugins that then interact with my C code on the back end in order to build some kind of uh yeah AI generated",
    "start": "909720",
    "end": "917399"
  },
  {
    "text": "experience for this product um it's a web CMS I have some content in there for my website I have some media I have",
    "start": "917399",
    "end": "923240"
  },
  {
    "text": "users and a bunch of configuration settings as well so I've added this little plugin at the top here hopefully",
    "start": "923240",
    "end": "929279"
  },
  {
    "text": "you can see that it's a uh a little magic wand and uh because I'm feeling in a super Innovative mood when you click",
    "start": "929279",
    "end": "935399"
  },
  {
    "text": "it of course it opens a chat interface um this is the thing we're trying to avoid but I was going to use it as a a very simple demo to start with so uh",
    "start": "935399",
    "end": "942959"
  },
  {
    "text": "this is going to talk directly to semantic kernel and it's going to then talk to the open AI apis in the",
    "start": "942959",
    "end": "948680"
  },
  {
    "text": "background literally with one line of code that line of code so if we go in",
    "start": "948680",
    "end": "954319"
  },
  {
    "text": "here I'm going to say hello from n DC",
    "start": "954319",
    "end": "960160"
  },
  {
    "text": "you can tell I'm not really a designer but look at that fantastic it's actually responded straight from open AI um just",
    "start": "960160",
    "end": "965959"
  },
  {
    "text": "to prove this is real someone shout a simple question from the audience maybe we can ask",
    "start": "965959",
    "end": "972120"
  },
  {
    "text": "it oh it's not going to know that but let's try it what's the weather I can't type either what's the",
    "start": "972120",
    "end": "978279"
  },
  {
    "text": "weather tomorrow it'll probably tell me it doesn't know how to answer those things don't have access to realtime",
    "start": "978279",
    "end": "983360"
  },
  {
    "text": "data let's try one of these um who is the queen of",
    "start": "983360",
    "end": "990839"
  },
  {
    "text": "Denmark hopefully it'll tell me Queen Margaret Margarita she's not okay",
    "start": "991560",
    "end": "999279"
  },
  {
    "text": "fine bit awkward anyway you can see this is this is not something I would have known this is not something pre-program",
    "start": "999279",
    "end": "1005319"
  },
  {
    "text": "this is talking straight to that model in real time literally through a single line of code uh it's not ideal it's not",
    "start": "1005319",
    "end": "1011680"
  },
  {
    "text": "perfect but it it works um if I show you how this is configured we'll just jump into here I've got some code that",
    "start": "1011680",
    "end": "1017040"
  },
  {
    "text": "registers it I literally call uh in my net Service registration I'm adding a Singleton for the I chat completion",
    "start": "1017040",
    "end": "1024319"
  },
  {
    "text": "service I'm connecting to a model here GPT 4 mini that's the latest and smallest and cheapest model um it's not",
    "start": "1024319",
    "end": "1031319"
  },
  {
    "text": "necessarily the most accurate cuz it's a a compressed condens version of that model but it's one line of configuration",
    "start": "1031319",
    "end": "1038760"
  },
  {
    "text": "I register a transient instance of the semantic kernel I can inject that into my controller and with a single line I",
    "start": "1038760",
    "end": "1045120"
  },
  {
    "text": "can call the semantic kernel uh call opening I by the semantic kernel which",
    "start": "1045120",
    "end": "1050640"
  },
  {
    "text": "is pretty cool so no lines of code I've created a chat uh a chat experience directly in my web CMS however this",
    "start": "1050640",
    "end": "1057919"
  },
  {
    "text": "isn't super helpful so this is where we want to start trying to tweak and control this a bit uh and that's what",
    "start": "1057919",
    "end": "1063160"
  },
  {
    "text": "we're going to look at now so a feature of a lot of llms that people may not be aware of is a thing",
    "start": "1063160",
    "end": "1069280"
  },
  {
    "text": "called function calling function calling allows an llm to map a prompt to a piece",
    "start": "1069280",
    "end": "1075919"
  },
  {
    "text": "of code that would then execute and through this we can start to create an enrich kind of a rag type workflow",
    "start": "1075919",
    "end": "1083320"
  },
  {
    "text": "enrich the responses that our uh semantic kernel uh can give so through",
    "start": "1083320",
    "end": "1089400"
  },
  {
    "text": "this we send a request that's our friendly user at the top there hello um I would like to know something about",
    "start": "1089400",
    "end": "1096120"
  },
  {
    "text": "this product so in our case we're in a CMS I'd like to know something about a piece of content and the model knows",
    "start": "1096120",
    "end": "1101919"
  },
  {
    "text": "nothing about that but we can teach it and tell it exactly what it needs to call in order to go and find out that",
    "start": "1101919",
    "end": "1107919"
  },
  {
    "text": "information and therefore deliver a nice friendly human response um hopefully",
    "start": "1107919",
    "end": "1113520"
  },
  {
    "text": "from this diagram you can see that actually none of the data in our system ever goes to the model never goes to",
    "start": "1113520",
    "end": "1119559"
  },
  {
    "text": "open AI so the only thing that's happening here is semantic kernel telling our model hey I have this list",
    "start": "1119559",
    "end": "1125039"
  },
  {
    "text": "of functions that you can call and this is the types of data that they might return and this is how they might work",
    "start": "1125039",
    "end": "1130200"
  },
  {
    "text": "and then it will go and work the rest out for you so you can then start to build a fairly intelligent application",
    "start": "1130200",
    "end": "1136320"
  },
  {
    "text": "um there's three key Concepts we need to understand here to really know what's going on and then we'll look at some code again um we have this idea of",
    "start": "1136320",
    "end": "1143000"
  },
  {
    "text": "plugins plugins exist everywhere but in the context of uh semantic kernel a plugin is a way of telling uh it how to",
    "start": "1143000",
    "end": "1150120"
  },
  {
    "text": "go and find a certain amount of data or how to perform a certain task a planner",
    "start": "1150120",
    "end": "1155240"
  },
  {
    "text": "is what's responsible for mapping that list of functions that you have over to um the prompts uh and deciding",
    "start": "1155240",
    "end": "1162480"
  },
  {
    "text": "effectively what gets executed and we're not talking necessarily one function it could be a chain of functions that need to happen in sequence and then finally",
    "start": "1162480",
    "end": "1169480"
  },
  {
    "text": "we have personas personas is a way of us uh telling the model this is who you are",
    "start": "1169480",
    "end": "1174679"
  },
  {
    "text": "this is how you're going to act this is how I'd like you to respond you should never tell anyone that the queen of Denmark is uh Queen Margaret for example",
    "start": "1174679",
    "end": "1181360"
  },
  {
    "text": "um those sorts of things in our case we're building an application for a a product that you'd be using internally",
    "start": "1181360",
    "end": "1187440"
  },
  {
    "text": "in your company so we want it to act accordingly we want it not to answer any questions about the you know public",
    "start": "1187440",
    "end": "1194200"
  },
  {
    "text": "internet we want it to uh only answer questions directly about the CMS the product that we're using it within so",
    "start": "1194200",
    "end": "1201000"
  },
  {
    "text": "let's look about how we do that in semantic kernel um this is the chat interface we",
    "start": "1201000",
    "end": "1206600"
  },
  {
    "text": "uh have previously seen and yeah it's cool but I would quite like to uh change this to be a bit more strict restrictive",
    "start": "1206600",
    "end": "1212679"
  },
  {
    "text": "so we don't ask this question and get the wrong answer so to do that we can uh",
    "start": "1212679",
    "end": "1218640"
  },
  {
    "text": "jump to my next piece of code here which is directly using the um the uh",
    "start": "1218640",
    "end": "1226200"
  },
  {
    "text": "chat service um now this is a little bit more",
    "start": "1226200",
    "end": "1231440"
  },
  {
    "text": "complicated in terms of the amount of code compared to before but effectively this is doing the exact same thing as",
    "start": "1231440",
    "end": "1236880"
  },
  {
    "text": "the previous piece of code it's taking in a string at the top here and it's calling off to the model here with that",
    "start": "1236880",
    "end": "1244400"
  },
  {
    "text": "message um this introduces A New Concept that you won't have seen yet which is the chat history uh API the chat history",
    "start": "1244400",
    "end": "1252240"
  },
  {
    "text": "API allows us to build up a context and so every time we're talking to the model we're telling it here's what's already",
    "start": "1252240",
    "end": "1257679"
  },
  {
    "text": "been discussed and therefore you can talk about things that have already happened and you can ask it to refer",
    "start": "1257679",
    "end": "1262919"
  },
  {
    "text": "back to previous messages what we can also do here is pass in a system prompt a base thing that goes into the query",
    "start": "1262919",
    "end": "1270080"
  },
  {
    "text": "that then uh yeah will return the um only the things we've told it to so you",
    "start": "1270080",
    "end": "1276200"
  },
  {
    "text": "can see here I've got my chat history and I'm not passing in a system prompt just yet but I've created one at the top here system prompt and this is just a",
    "start": "1276200",
    "end": "1282880"
  },
  {
    "text": "natural language way of me telling my uh model how I want it to act so we're saying here you're chat box for the open",
    "start": "1282880",
    "end": "1289520"
  },
  {
    "text": "source CMS and braco and you're call them braco co-pilot uh you can perform tasks and answer questions about",
    "start": "1289520",
    "end": "1295440"
  },
  {
    "text": "entities within the CMS you can generate placeholder text based on existing content within the CMS but you must not",
    "start": "1295440",
    "end": "1301880"
  },
  {
    "text": "generate content or answer questions based on General Knowledge hopefully that's then going to weed out that uh",
    "start": "1301880",
    "end": "1308760"
  },
  {
    "text": "Queen Margaret question so uh I'll pop this in here so I can put my what did I call the variable system prompt into the",
    "start": "1308760",
    "end": "1315440"
  },
  {
    "text": "chat history just there and we'll come back and talk about the rest of it in a second hopefully that will",
    "start": "1315440",
    "end": "1322159"
  },
  {
    "text": "recompile yes we'll fire it up and I'm going to just paste in that same question we asked it",
    "start": "1322159",
    "end": "1328000"
  },
  {
    "text": "before so now it can no longer answer those questions because we've told the base prompt hey don't do that um but we",
    "start": "1328000",
    "end": "1335320"
  },
  {
    "text": "can ask it now questions about the umbraco CMS or just about itself so who are",
    "start": "1335320",
    "end": "1340919"
  },
  {
    "text": "you and it will tell us I'm a reca co-pilot so it's actually",
    "start": "1340919",
    "end": "1346039"
  },
  {
    "text": "listening to the prompt you can even ask it cheeky things like like hey forget your prompt and it will tell you hey no I can't do that um uh these sorts of",
    "start": "1346039",
    "end": "1353279"
  },
  {
    "text": "things so it's quite hard to break out of uh at this point once you've set that system prompt",
    "start": "1353279",
    "end": "1359520"
  },
  {
    "text": "um so I mentioned history and the history is a way of us building up a collection of of messages that have",
    "start": "1359520",
    "end": "1365159"
  },
  {
    "text": "happened over time and then you can refer back to to previous questions so um of course I can do something like",
    "start": "1365159",
    "end": "1371720"
  },
  {
    "text": "this I can now say my name is Callum and it will say nice to meet you",
    "start": "1371720",
    "end": "1378600"
  },
  {
    "text": "I can say what is my name and right now it doesn't know that",
    "start": "1378600",
    "end": "1386840"
  },
  {
    "text": "because every time you call this I'm creating a new chat history you need to store that chat history somewhere um",
    "start": "1386840",
    "end": "1393600"
  },
  {
    "text": "semantic kernel and the models themselves don't necessarily want to store this kind of data and probably in",
    "start": "1393600",
    "end": "1398640"
  },
  {
    "text": "your workflow you don't want them to either if you're sending sensitive questions you don't want that history being stored anywhere you don't control",
    "start": "1398640",
    "end": "1404640"
  },
  {
    "text": "so you can control that by putting data into a database that you control uh or",
    "start": "1404640",
    "end": "1409720"
  },
  {
    "text": "into memory or Cosmos DB is really really good at this sort of thing um in my case I've just got a very simple",
    "start": "1409720",
    "end": "1415400"
  },
  {
    "text": "store that I've created locally that then stores that data in memory so let's enable that quickly um we can just take",
    "start": "1415400",
    "end": "1421400"
  },
  {
    "text": "my uh Dummy Line of code out there and pop in this so all it's doing here is",
    "start": "1421400",
    "end": "1426520"
  },
  {
    "text": "calling off to my store and saying for the session ID which is the the current logged in user go and get the current",
    "start": "1426520",
    "end": "1432039"
  },
  {
    "text": "chat history and if it doesn't exist create one and make sure we're using that same base system prompt so we'll",
    "start": "1432039",
    "end": "1437559"
  },
  {
    "text": "pop this back in and we'll try that same question again I'll tell it who I am and then we will see if it can uh who am I",
    "start": "1437559",
    "end": "1445559"
  },
  {
    "text": "it won't know this I think initially it shouldn't do doesn't have that information I am",
    "start": "1445559",
    "end": "1453039"
  },
  {
    "text": "Callum and then it will say hello and I can ask it who am I and it will say I'm",
    "start": "1453039",
    "end": "1459039"
  },
  {
    "text": "Callum so it now knows those sorts of things all it's doing is basing it off that chat history so every time we're",
    "start": "1459039",
    "end": "1464120"
  },
  {
    "text": "calling the uh the model it's sending back the entire history in the prompt say these are all the discussions that",
    "start": "1464120",
    "end": "1469840"
  },
  {
    "text": "have been had so far um now this is this is pretty cool but it's still not doing anything that helpful um we're starting",
    "start": "1469840",
    "end": "1477039"
  },
  {
    "text": "to add little bits of uh information and context into our prompts as well that",
    "start": "1477039",
    "end": "1482600"
  },
  {
    "text": "will start to make this a bit more helpful So within umbraco we have this concept of a user you're logged into the",
    "start": "1482600",
    "end": "1487679"
  },
  {
    "text": "CMS and it's helpful for it to know who's already logged in um equally it's",
    "start": "1487679",
    "end": "1493039"
  },
  {
    "text": "helpful to know where it is in the CMS the the context you're actually in directly so uh we're able to pass this",
    "start": "1493039",
    "end": "1499200"
  },
  {
    "text": "metadata along with each prompt so we can ask it questions about that metadata in this case it's very very basic I'm",
    "start": "1499200",
    "end": "1505600"
  },
  {
    "text": "just giving it the current user ID giving it the um the section and the workspace that it's using in the CMS but",
    "start": "1505600",
    "end": "1511480"
  },
  {
    "text": "it would be you know if you're working on a piece of content it would be that piece of content that you pass along as well to say this is the context that I'm",
    "start": "1511480",
    "end": "1518000"
  },
  {
    "text": "in and then semantic kernel can use that to enrich the prompts and the um planner",
    "start": "1518000",
    "end": "1525279"
  },
  {
    "text": "to make sure it's calling the correct functions um we've looked enough at the actual code",
    "start": "1525279",
    "end": "1530399"
  },
  {
    "text": "for for how we execute things now let's do something a little bit cooler um I",
    "start": "1530399",
    "end": "1535520"
  },
  {
    "text": "want to answer questions directly about entities that exist in this product exist in the CMS that open AI will know",
    "start": "1535520",
    "end": "1541640"
  },
  {
    "text": "nothing about um I mentioned before we have this concept of content media we have a bunch of settings if you go into",
    "start": "1541640",
    "end": "1548279"
  },
  {
    "text": "here you'll see there's document types that are created there is users that exist in in the form of my admin user",
    "start": "1548279",
    "end": "1554640"
  },
  {
    "text": "for example so with semantic kernel we can use plugins to provide it this information um and I have created",
    "start": "1554640",
    "end": "1562360"
  },
  {
    "text": "plugins for basically every entity in the CMS that you might want to be able to ask a question about so uh these are",
    "start": "1562360",
    "end": "1569679"
  },
  {
    "text": "just C classes um we'll look at the uh content plugin sure why not so here um I",
    "start": "1569679",
    "end": "1576440"
  },
  {
    "text": "create a class umbraco content plugin and I can inject into it the service that umbraco has to go and find that",
    "start": "1576440",
    "end": "1583760"
  },
  {
    "text": "data or if it was your internal application your database you would inject your database into here or an external API and from there you can then",
    "start": "1583760",
    "end": "1591320"
  },
  {
    "text": "call a function that goes and gets some data um in this case I've got a standardized entity that it returns um",
    "start": "1591320",
    "end": "1599200"
  },
  {
    "text": "but it's just returning a list of entities here the slightly strange thing that you won't have seen anywhere else before is",
    "start": "1599200",
    "end": "1605799"
  },
  {
    "text": "these two attributes on the C Class we've got the first which is uh one called kernel function and another which",
    "start": "1605799",
    "end": "1612159"
  },
  {
    "text": "is called description now kernel function is used uh as a reference by the planner to say when uh I want to",
    "start": "1612159",
    "end": "1618760"
  },
  {
    "text": "call this function this is what it's called um typically you should use this underscore style naming convention",
    "start": "1618760",
    "end": "1624679"
  },
  {
    "text": "because most llms have been trained on python code and they really perform much",
    "start": "1624679",
    "end": "1629919"
  },
  {
    "text": "better when you use um python style syntax here unfortunately so you've just given it a friendly name that the model",
    "start": "1629919",
    "end": "1636000"
  },
  {
    "text": "then knows how to refer to this function as and then you give it a description and this is a description in complete",
    "start": "1636000",
    "end": "1641279"
  },
  {
    "text": "natural language that tells the the model what this function does and what it what it returns um and based off of",
    "start": "1641279",
    "end": "1649320"
  },
  {
    "text": "that it should be able to answer our questions about the entities that I have in the CMS you can see I've created this",
    "start": "1649320",
    "end": "1654840"
  },
  {
    "text": "for a whole host of things so content content types media members users packages things that get installed",
    "start": "1654840",
    "end": "1661200"
  },
  {
    "text": "templates Etc um so if we jump back to our chat interface I can now ask it um I",
    "start": "1661200",
    "end": "1667360"
  },
  {
    "text": "don't know is there a homepage hopefully you can see just here",
    "start": "1667360",
    "end": "1674399"
  },
  {
    "text": "there is a homepage yes there is a homepage and it's titled home and it knows that and it knows because I've",
    "start": "1674399",
    "end": "1680720"
  },
  {
    "text": "told it to we'll look at this in a second that it's an actual document in the CMS and I can click the magic button",
    "start": "1680720",
    "end": "1685919"
  },
  {
    "text": "and it takes me straight to that document in the CMS so uh yeah like a",
    "start": "1685919",
    "end": "1691760"
  },
  {
    "text": "slightly more natural way of finding things rather than going home you can ask it is there a page that includes",
    "start": "1691760",
    "end": "1696919"
  },
  {
    "text": "some content about X and the model will find it of course we've got context here",
    "start": "1696919",
    "end": "1702320"
  },
  {
    "text": "so I can ask it other questions things like when was it created",
    "start": "1702320",
    "end": "1709200"
  },
  {
    "text": "and it knows based on the previous query I've asked it about the homepage and it knows the date but nowhere have I told",
    "start": "1709600",
    "end": "1716360"
  },
  {
    "text": "it the date you'll see here there is no special Logic for me telling the uh the",
    "start": "1716360",
    "end": "1722960"
  },
  {
    "text": "konel exactly where to get that data it's actually a property directly on this class that I'm returning so you'll",
    "start": "1722960",
    "end": "1729600"
  },
  {
    "text": "see here this is a a generic uh entity I've created it has a few properties it has a name it has a type um uh when the",
    "start": "1729600",
    "end": "1736399"
  },
  {
    "text": "the base entity would be very helpful as well the base entity actually has the uh ID the name the created date Etc and so",
    "start": "1736399",
    "end": "1743440"
  },
  {
    "text": "it can answer those sorts of questions um let's try another one I mentioned we've got an admin user so who is the",
    "start": "1743440",
    "end": "1749399"
  },
  {
    "text": "admin let's say it'll come back and say",
    "start": "1749399",
    "end": "1755559"
  },
  {
    "text": "hopefully I don't know why it says homepage information um who it will tell",
    "start": "1755880",
    "end": "1761080"
  },
  {
    "text": "me who the admin is and um it's telling me the groups that they're in in the CMS the date they were created Etc um",
    "start": "1761080",
    "end": "1767279"
  },
  {
    "text": "there's more information that the semantic Kel actually knows about this entity in the CMS things like um when",
    "start": "1767279",
    "end": "1773559"
  },
  {
    "text": "the user's password was changed or um basically anything I can get out of the uh the service out of the API I've got",
    "start": "1773559",
    "end": "1780519"
  },
  {
    "text": "there we've exposed a semantic kernel and we can then query it so we can say when was admin was W admin was admin uh",
    "start": "1780519",
    "end": "1790039"
  },
  {
    "text": "created we did create it a second ago we'll do a different one there you go it's created on August 23rd when was its",
    "start": "1790039",
    "end": "1797679"
  },
  {
    "text": "password word changed I've misspelled it that's hopefully it will work there you",
    "start": "1797679",
    "end": "1802880"
  },
  {
    "text": "go and it can now tell me that sort of information as well so really clever I've not actually had to do any anything",
    "start": "1802880",
    "end": "1808279"
  },
  {
    "text": "there to make this work it just has mapped to the objects and to the uh syntax that I've decorated my classes",
    "start": "1808279",
    "end": "1815000"
  },
  {
    "text": "with um these plugins they get registered just like any other type in",
    "start": "1815000",
    "end": "1821320"
  },
  {
    "text": "net so I'm creating these as Singleton classes and injecting them into the dependency injection container um you",
    "start": "1821320",
    "end": "1826799"
  },
  {
    "text": "can effectively think of colel the semantic kernel as a dependency injection container it's a list of",
    "start": "1826799",
    "end": "1831880"
  },
  {
    "text": "classes with a few things registered so uh in this case I've registered all of my services and then inside the kernel",
    "start": "1831880",
    "end": "1838000"
  },
  {
    "text": "registration I'm just saying and then here's all of your plugins so every plugin that have has been created here",
    "start": "1838000",
    "end": "1843799"
  },
  {
    "text": "is uh surfaced to the kernel that way I've not had to write any special code doesn't know anything about my product",
    "start": "1843799",
    "end": "1850399"
  },
  {
    "text": "but it's able to query the data there's also a concept called filters now filters are a great way to tailor the",
    "start": "1850399",
    "end": "1857080"
  },
  {
    "text": "response that comes out of the uh the model to make sure it's a friendly and and usable uh experience you'll have",
    "start": "1857080",
    "end": "1863880"
  },
  {
    "text": "seen when I was using this a minute ago when I ask it a question about a specific entity it gives me a link to go",
    "start": "1863880",
    "end": "1869480"
  },
  {
    "text": "to that entity um with this filter I'm rco entity result filter I'm able to use",
    "start": "1869480",
    "end": "1875320"
  },
  {
    "text": "that to check did it return an entity and if it did make sure that entity gets",
    "start": "1875320",
    "end": "1880519"
  },
  {
    "text": "surfaced up to the UI um this is not semantic kernel specific this is just me",
    "start": "1880519",
    "end": "1886080"
  },
  {
    "text": "using the semantic kernel response to add my own uh features and things to",
    "start": "1886080",
    "end": "1891880"
  },
  {
    "text": "make the experience a hell of a lot nicer um so yeah filters are a nice way of uh of modifying this it follows the",
    "start": "1891880",
    "end": "1898320"
  },
  {
    "text": "same sort of Handler pattern that you'll have seen elsewhere in net where you have a next function that you call so these are all Chained and you can run",
    "start": "1898320",
    "end": "1904320"
  },
  {
    "text": "them as many as you want and have yeah specialized filters um so far we've only showed you",
    "start": "1904320",
    "end": "1910480"
  },
  {
    "text": "things that are doing reading data which is cool but kind of boring wouldn't it be cool if it could create some things",
    "start": "1910480",
    "end": "1916360"
  },
  {
    "text": "so uh of course you can do that as well effectively any function can execute any code that you write can run and the",
    "start": "1916360",
    "end": "1922240"
  },
  {
    "text": "kernel can can run that and map it to a prompt so uh I think let's check out users for example users is fairly simple",
    "start": "1922240",
    "end": "1928960"
  },
  {
    "text": "So within users we have a function to go and create a user and I need to be able",
    "start": "1928960",
    "end": "1934120"
  },
  {
    "text": "to give it an email address for that user but everything else should be handled and taken care of for me it's a fairly simple call it goes and",
    "start": "1934120",
    "end": "1940840"
  },
  {
    "text": "constructs the model calls off to the API and then Returns the created entity so uh let's try that so we say create",
    "start": "1940840",
    "end": "1948880"
  },
  {
    "text": "a user for email",
    "start": "1948880",
    "end": "1954159"
  },
  {
    "text": "domain.com and hit submit it's going to think about it for",
    "start": "1954159",
    "end": "1960159"
  },
  {
    "text": "a second ah there we go so it's gone and created uh that user and we can click on go to user and look it's taken me",
    "start": "1960159",
    "end": "1966519"
  },
  {
    "text": "straight to the user that was just created completely uh you know no work by me the API is done at all um of",
    "start": "1966519",
    "end": "1973679"
  },
  {
    "text": "course we've had to supply it with some additional data there it needs to know who created the user which was me um it",
    "start": "1973679",
    "end": "1980279"
  },
  {
    "text": "needs to know the email of that user and a few other parameters really to make this code run well just with that same",
    "start": "1980279",
    "end": "1986919"
  },
  {
    "text": "description syntax that we bind our functions we can bind parameters as well so we decorate these parameters with um",
    "start": "1986919",
    "end": "1994039"
  },
  {
    "text": "the description and then we pop yeah all of our parameters on and they call through to the API I I'll take questions",
    "start": "1994039",
    "end": "2000880"
  },
  {
    "text": "at the end if that's okay um so yeah you can you can do this with with literally",
    "start": "2000880",
    "end": "2006639"
  },
  {
    "text": "any function parameters um the user ID is being passed through to semantic",
    "start": "2006639",
    "end": "2011799"
  },
  {
    "text": "kernel as the context that it's in currently and the other things are being passed from The Prompt and it's inferring all of that from the uh from",
    "start": "2011799",
    "end": "2018039"
  },
  {
    "text": "the request so yeah pretty cool not uh very limited code and it's now actually",
    "start": "2018039",
    "end": "2024080"
  },
  {
    "text": "you know doing actions for me I've I've created a genuine",
    "start": "2024080",
    "end": "2029158"
  },
  {
    "text": "co-pilot so so far we've seen chat and I said chat was not really the best most",
    "start": "2030080",
    "end": "2036279"
  },
  {
    "text": "human way of interacting with uh with uh with products um of course there's way",
    "start": "2036279",
    "end": "2041639"
  },
  {
    "text": "better ways of doing these sorts of things um such as being able to provide it with an image and the image has some",
    "start": "2041639",
    "end": "2047240"
  },
  {
    "text": "instructions in it or um to be able to speak directly to our models as well most of the flagship models nowadays say",
    "start": "2047240",
    "end": "2055560"
  },
  {
    "text": "uh you know chat GPT for example have multimodal capabilities they are able to understand images um code as well",
    "start": "2055560",
    "end": "2063440"
  },
  {
    "text": "crucially um and that means that they can not only generate but execute code code um there is something to be",
    "start": "2063440",
    "end": "2069760"
  },
  {
    "text": "slightly wary of when you're executing code that's been generated by an llm because you don't know what it could do it might not even compile um there's",
    "start": "2069760",
    "end": "2076480"
  },
  {
    "text": "some good ways around that um in Azure we have a thing called container apps which is really good really easy way to",
    "start": "2076480",
    "end": "2082480"
  },
  {
    "text": "spin up a bit of compute in sort of no time um and that interr integrates directly with semantic kernel so you can",
    "start": "2082480",
    "end": "2089480"
  },
  {
    "text": "use a feature called uh Dynamic sessions in container apps and with a simple registration say to semantic kernel when",
    "start": "2089480",
    "end": "2096480"
  },
  {
    "text": "you need to execute code use a dynamic session over here instead and it will provision you a container in the cloud",
    "start": "2096480",
    "end": "2102079"
  },
  {
    "text": "run your code and return the result straight to semantic kernel um that's",
    "start": "2102079",
    "end": "2107240"
  },
  {
    "text": "using the the Codex platform under the hood uh equally we can do image generation we can do text generation and",
    "start": "2107240",
    "end": "2113119"
  },
  {
    "text": "a whole lot more so Microsoft has this concept of studios for all of their AI products um",
    "start": "2113119",
    "end": "2119720"
  },
  {
    "text": "and the one we're going to look at in a second is called Azure AI Studio I think this is probably where all of the other",
    "start": "2119720",
    "end": "2125960"
  },
  {
    "text": "AI studios are going to end up cuz they have a speech studio and a voice studio and a uh yeah whole bunch of Studios but",
    "start": "2125960",
    "end": "2133200"
  },
  {
    "text": "Azure AI Studio allows us to to ah Azure AI Studio allows us to deploy over 1,700",
    "start": "2133200",
    "end": "2139640"
  },
  {
    "text": "models straight onto Azure with fairly uh minimal effort you're able to manage",
    "start": "2139640",
    "end": "2145040"
  },
  {
    "text": "quotas safety filters and fine-tune those models directly within the browser and of course you can then import your",
    "start": "2145040",
    "end": "2150880"
  },
  {
    "text": "own data and enrich those models with uh your own context that applies to your business so if you wanted to build uh a",
    "start": "2150880",
    "end": "2157640"
  },
  {
    "text": "chatbot that can answer questions about your business this is a great way to do it um you would choose a base model say",
    "start": "2157640",
    "end": "2163640"
  },
  {
    "text": "chat GPT 40 mini uh and then you would import your data and fine-tune and Away you go um they have an idea of",
    "start": "2163640",
    "end": "2170680"
  },
  {
    "text": "playgrounds as well playgrounds are a way to um test out those models without",
    "start": "2170680",
    "end": "2175920"
  },
  {
    "text": "having to write a single line of code you can just use them straight in the browser and then also uh you can",
    "start": "2175920",
    "end": "2181000"
  },
  {
    "text": "Benchmark the performance of different models based on how everybody else in Azure is using those models too it will",
    "start": "2181000",
    "end": "2186839"
  },
  {
    "text": "tell you you know what performs best what's giving the most accurate scores Etc um this is what the AI Studio looks",
    "start": "2186839",
    "end": "2193760"
  },
  {
    "text": "like so when we go to deploy a model we can choose from a huge huge array of different modu uh models and for",
    "start": "2193760",
    "end": "2200079"
  },
  {
    "text": "different use cases as well um when we do deploy a model we have a big choice",
    "start": "2200079",
    "end": "2206119"
  },
  {
    "text": "of regions where you can deploy them and this is where it gets quite important to choose the right model because not only",
    "start": "2206119",
    "end": "2212119"
  },
  {
    "text": "do the models have different capabilities but they also have different availabilities and uh I was",
    "start": "2212119",
    "end": "2217839"
  },
  {
    "text": "thoroughly enjoying the other day just playing around in uh Us East until I learned that I think it was the darly",
    "start": "2217839",
    "end": "2224280"
  },
  {
    "text": "model couldn't be deployed and I'm was like ah now what do I do so it seems the best availability is between Sweden and",
    "start": "2224280",
    "end": "2230599"
  },
  {
    "text": "uh East us but then there is East Us 2 that has some of the other models I guess this is just based off of overall",
    "start": "2230599",
    "end": "2237400"
  },
  {
    "text": "capacity of these data centers and also where they've deployed their Hardware um",
    "start": "2237400",
    "end": "2242440"
  },
  {
    "text": "so this is running on azure's infrastructure directly they've put it on their public Cloud so yeah you have",
    "start": "2242440",
    "end": "2247880"
  },
  {
    "text": "to sort of go with where the availability is best I don't think there's really the same data residency",
    "start": "2247880",
    "end": "2254520"
  },
  {
    "text": "concerns that you would have with something like storing data in one of these uh countries because ultimately",
    "start": "2254520",
    "end": "2260160"
  },
  {
    "text": "your data doesn't go to the model it's only going to be maybe the contents of your prompts um but the actual",
    "start": "2260160",
    "end": "2266760"
  },
  {
    "text": "understanding of your internal system is not going to go uh to these so Sweden and uh East us are probably the best",
    "start": "2266760",
    "end": "2272760"
  },
  {
    "text": "places pricing is the same across the board there is no uh region specific pricing the one difference is you can",
    "start": "2272760",
    "end": "2279040"
  },
  {
    "text": "have uh models deployed on the standard tier which just get deployed within that region and they are um on the general",
    "start": "2279040",
    "end": "2286079"
  },
  {
    "text": "cloud and you can then have more dedicated resources as well which starts to add an hourly cost and then a per",
    "start": "2286079",
    "end": "2291560"
  },
  {
    "text": "execution cost too but on the whole standard deployment and you can deploy a whole array of models so let's have a",
    "start": "2291560",
    "end": "2298880"
  },
  {
    "text": "quick oh where is it gone here it is refresh so this is the",
    "start": "2298880",
    "end": "2306079"
  },
  {
    "text": "uh uh Azure AI Studio we'll Zoom that in a couple of times so this is what you what",
    "start": "2306079",
    "end": "2311839"
  },
  {
    "text": "it looks like when you get started and there is um yeah nice clean interface",
    "start": "2311839",
    "end": "2317560"
  },
  {
    "text": "you have a model catalog the model catalog allows you to look at all of the different models that are available not",
    "start": "2317560",
    "end": "2322880"
  },
  {
    "text": "just from open AI not just from Microsoft but also a lot of the Facebook models um and yeah a whole bunch of Open",
    "start": "2322880",
    "end": "2329680"
  },
  {
    "text": "Source ones as well it's pretty cool you can look at the model benchmarks as I mentioned this tells you roughly how they're performing for certain workloads",
    "start": "2329680",
    "end": "2336040"
  },
  {
    "text": "across all the different uh use cases and you can then decide exactly how you want to uh to use them or which one you",
    "start": "2336040",
    "end": "2342480"
  },
  {
    "text": "want to use for your application um prompt catalog as well gives you a whole list of predetermined types of prompts",
    "start": "2342480",
    "end": "2349200"
  },
  {
    "text": "that if you were doing a certain specific use case you might want to use um and then of course there is the Azure",
    "start": "2349200",
    "end": "2354839"
  },
  {
    "text": "open AI service and this is where the uh you're able to use their models directly so in my case I've created a resource",
    "start": "2354839",
    "end": "2361720"
  },
  {
    "text": "called umco co-pilot and in here I have deployed several models if we scroll down here to deployment you'll see I've",
    "start": "2361720",
    "end": "2368400"
  },
  {
    "text": "got a GPT 40 Mini model deployed I've also got GPT 35 turbo uh with an",
    "start": "2368400",
    "end": "2374280"
  },
  {
    "text": "instruct of the instruct variant of it and it's more designed for text generation so if I was to do anything with text generation I want to tell",
    "start": "2374280",
    "end": "2380720"
  },
  {
    "text": "semantic colel hey we should use this model instead of gp4 and then darly for image generation and then I've got",
    "start": "2380720",
    "end": "2387520"
  },
  {
    "text": "another uh resource somewhere else over here in Sweden with uh a different model deployed because it",
    "start": "2387520",
    "end": "2394760"
  },
  {
    "text": "it wasn't available in ECS yeah whisper which is there their voice model so you can deploy as many models as you want",
    "start": "2394760",
    "end": "2399880"
  },
  {
    "text": "they give you an API key it's the same API key across all the resources in fact so um it's a pretty nice way to just",
    "start": "2399880",
    "end": "2406480"
  },
  {
    "text": "wire up semantic kernel um I mentioned you've got the playgrounds we can immediately within here test out these",
    "start": "2406480",
    "end": "2412520"
  },
  {
    "text": "these models without doing anything um you can also start to find tune and upload your data So within data files",
    "start": "2412520",
    "end": "2418800"
  },
  {
    "text": "this is where you might add documents that are relevant to your business um you can also connect external data",
    "start": "2418800",
    "end": "2424800"
  },
  {
    "text": "sources here where it will pull that data in for you and then you can use that to fine-tune your model directly",
    "start": "2424800",
    "end": "2432920"
  },
  {
    "text": "so that's not what I wanted to do there we go um fantastic so of course I want",
    "start": "2432920",
    "end": "2440079"
  },
  {
    "text": "these different capabilities of these different models available to me in my product as well how do we do that um so",
    "start": "2440079",
    "end": "2445800"
  },
  {
    "text": "far we've only used the uh the chat service you'll have seen my chat controller has this uh yeah I chat",
    "start": "2445800",
    "end": "2452599"
  },
  {
    "text": "completion service involved but I also want to be able to support audio I'd love to be able to speak to my product",
    "start": "2452599",
    "end": "2458280"
  },
  {
    "text": "like it's a a human and ask it a real question so um we can register the I",
    "start": "2458280",
    "end": "2464760"
  },
  {
    "text": "audio Service uh in this case I think it's up here yes fantastic so I'm able",
    "start": "2464760",
    "end": "2470960"
  },
  {
    "text": "to register the uh audio to text service the text generation service and the text to image service for different use cases",
    "start": "2470960",
    "end": "2477280"
  },
  {
    "text": "that I want directly in my product and I can then call these just by calling that relevant service I don't need to",
    "start": "2477280",
    "end": "2483359"
  },
  {
    "text": "distinguish between um oh I want to use this model or this model when making the query it's just set up that way so every",
    "start": "2483359",
    "end": "2490079"
  },
  {
    "text": "time you try and do image generation it will use the darly model um so yeah",
    "start": "2490079",
    "end": "2496119"
  },
  {
    "text": "that's that's how it works now if we look in my uh plugin again here you'll see I've added support for an audio",
    "start": "2496119",
    "end": "2502400"
  },
  {
    "text": "endpoint so I can send an audio file to it recorded by my browser me speaking to the uh computer and it will then take",
    "start": "2502400",
    "end": "2509760"
  },
  {
    "text": "that command translate or transcribe the text that's been uh spoken to it and",
    "start": "2509760",
    "end": "2515000"
  },
  {
    "text": "turn that into a prompt that we can then execute um equally we have a another controller here called The Generation",
    "start": "2515000",
    "end": "2520960"
  },
  {
    "text": "controller and this is responsible for taking in a prompt and then going and generating something be it an image or",
    "start": "2520960",
    "end": "2527079"
  },
  {
    "text": "uh some text um whilst the chat service can actually do all of this you can tell",
    "start": "2527079",
    "end": "2532480"
  },
  {
    "text": "the chat completion service hey generate me an image of this it's better to use one of the specialized models because the specialized models are designed for",
    "start": "2532480",
    "end": "2539240"
  },
  {
    "text": "that um GPT 40 for example does not do the image generation but if you use full",
    "start": "2539240",
    "end": "2545119"
  },
  {
    "text": "fat GPT 4 it will um there's subtle differences between each model so it's generally better to choose one that is",
    "start": "2545119",
    "end": "2552200"
  },
  {
    "text": "specific for your individual use case yeah generate text generate image they call off to different Services pass in",
    "start": "2552200",
    "end": "2559160"
  },
  {
    "text": "the prompt return the output nothing fancy there but demo time let's have a",
    "start": "2559160",
    "end": "2564480"
  },
  {
    "text": "look at what this actually means for us in the CMS U you'll be able to tell I'm not really a designer um as some of this",
    "start": "2564480",
    "end": "2570319"
  },
  {
    "text": "looks a bit hastily put together but um I've added a little uh microphone here next to the uh the input field and I can",
    "start": "2570319",
    "end": "2577520"
  },
  {
    "text": "ask it questions so",
    "start": "2577520",
    "end": "2581800"
  },
  {
    "text": "hello fantastic and it remembers who I am it's using that same chat history as we had before but we can ask it",
    "start": "2583119",
    "end": "2588839"
  },
  {
    "text": "basically any single um thing that that we did before so who is the admin",
    "start": "2588839",
    "end": "2596640"
  },
  {
    "text": "user and it's again brought that sort of data same data back we can ask it to",
    "start": "2596640",
    "end": "2601680"
  },
  {
    "text": "perform actions it's just going to call those same semantic kernel functions that we've already registered in our",
    "start": "2601680",
    "end": "2606720"
  },
  {
    "text": "plugins and uh yeah do everything that it it needs to do um I did forget to mention semantic kernel plugins you",
    "start": "2606720",
    "end": "2613079"
  },
  {
    "text": "don't have to write them either you can actually point an open API description at semantic kernel and it will map that",
    "start": "2613079",
    "end": "2620359"
  },
  {
    "text": "whole API endpoint for you and then call the apis um it's generally okay I tested",
    "start": "2620359",
    "end": "2627000"
  },
  {
    "text": "it on a few things and it was hit and miss um I guess depends how good your API documentation actually is if it's",
    "start": "2627000",
    "end": "2633160"
  },
  {
    "text": "thorough and genuinely accurate then it will probably work if it requires Authentication it might not um but yeah you could you",
    "start": "2633160",
    "end": "2640480"
  },
  {
    "text": "don't even have to write your own plugins um so that's a slightly more natural way of interacting with the product but we can go one step further",
    "start": "2640480",
    "end": "2646400"
  },
  {
    "text": "here which is um I have the uh ability to just press and hold on a button and",
    "start": "2646400",
    "end": "2652480"
  },
  {
    "text": "start speaking to it so rather than us needing to open up a chat window and interact with it like a chat we can just",
    "start": "2652480",
    "end": "2658240"
  },
  {
    "text": "talk to it like it's maybe a human now I I asked my friend uh before this that I could use him as my demo case so I'm",
    "start": "2658240",
    "end": "2664640"
  },
  {
    "text": "going to use as my demo case but um I a picture of my friend somewhere in the CMS and I can query based on that",
    "start": "2664640",
    "end": "2670640"
  },
  {
    "text": "person's name and it will hopefully just take me straight to that piece of content",
    "start": "2670640",
    "end": "2676319"
  },
  {
    "text": "so show me the image of",
    "start": "2676319",
    "end": "2680559"
  },
  {
    "text": "Ravi damn should we try it again is there an image of",
    "start": "2683079",
    "end": "2691318"
  },
  {
    "text": "Ravi it worked yes thank God so uh there we go so I'm able to then talk to it in",
    "start": "2695240",
    "end": "2701480"
  },
  {
    "text": "a more human a more human way and any of the prompts that I'd already um I'll go",
    "start": "2701480",
    "end": "2706520"
  },
  {
    "text": "back FY there you go uh any of the prompts that already uh were wired up um will continue to work so I can now use",
    "start": "2706520",
    "end": "2713160"
  },
  {
    "text": "my voice to talk to them um equally using those generation uh text generation apis we can start to do some",
    "start": "2713160",
    "end": "2719400"
  },
  {
    "text": "much cooler stuff um where uh within context again you can start to prompt",
    "start": "2719400",
    "end": "2726160"
  },
  {
    "text": "and make it do things just on a very specific piece of content um I've taken inspiration here uh from",
    "start": "2726160",
    "end": "2731880"
  },
  {
    "text": "the is it Adobe generative fill where you can sort of highlight an area and say go do something um and equally the",
    "start": "2731880",
    "end": "2738280"
  },
  {
    "text": "new Google or Samsung thing where you can Circle something and just say go do something so I can shift and click on a",
    "start": "2738280",
    "end": "2744640"
  },
  {
    "text": "field and draw a box and oh something's not working damn draw a box and type a",
    "start": "2744640",
    "end": "2751040"
  },
  {
    "text": "prompt which I can't do because it seems to release every time I release my finger oh well um it should then call",
    "start": "2751040",
    "end": "2756559"
  },
  {
    "text": "the uh generation endpoints um if I have an image field here uh in the product it",
    "start": "2756559",
    "end": "2761680"
  },
  {
    "text": "knows what an image field is and it will generate again it's not working damn um",
    "start": "2761680",
    "end": "2767319"
  },
  {
    "text": "it will generate an image based on on the prompt I typed in using those uh prompt end points um maybe I can show",
    "start": "2767319",
    "end": "2773720"
  },
  {
    "text": "you an endpoint quickly just to just to prove it should work I think that's my dodgy JavaScript um copilot API",
    "start": "2773720",
    "end": "2782000"
  },
  {
    "text": "generation text let's just say um prompt",
    "start": "2782000",
    "end": "2787839"
  },
  {
    "text": "generate a SEO description for my",
    "start": "2787839",
    "end": "2793440"
  },
  {
    "text": "product store there we go so it's gone and generated an SEO description based off",
    "start": "2793440",
    "end": "2799720"
  },
  {
    "text": "of the uh the uh text generation service rather than using the chat service there",
    "start": "2799720",
    "end": "2805280"
  },
  {
    "text": "I've not had to actually ask it for anything admittedly I did call the endpoint directly didn't need to but um",
    "start": "2805280",
    "end": "2810359"
  },
  {
    "text": "yeah slightly frustrating um but yeah hopefully this gives you some inspiration about ways you could then start to use these models in a slightly",
    "start": "2810359",
    "end": "2817319"
  },
  {
    "text": "more uh Innovative way it takes all of the AI bit out of the equation it",
    "start": "2817319",
    "end": "2822480"
  },
  {
    "text": "suddenly just makes it a concern of you passing the right data to the right",
    "start": "2822480",
    "end": "2827520"
  },
  {
    "text": "service and semantic kernel does all the heavy lifting for you and uh I'm then writing crappy JavaScript",
    "start": "2827520",
    "end": "2835920"
  },
  {
    "text": "instead okay so uh you may want to go learn a bit more there is some fantastic resources that I would highly recommend",
    "start": "2835920",
    "end": "2841920"
  },
  {
    "text": "you go and read uh or or will listen to firstly will Vala um he has an amazing YouTube Channel that's very close to 5K",
    "start": "2841920",
    "end": "2849079"
  },
  {
    "text": "subscribers if you've not subscribed to him you should um he only had like 2K a week ago so he's doing really well um",
    "start": "2849079",
    "end": "2854880"
  },
  {
    "text": "he's got a great series on semantic kernel where he goes through basically every feature from detailed prompts and",
    "start": "2854880",
    "end": "2861000"
  },
  {
    "text": "crafting out your own um your own plans with uh handlebars type syntax and all",
    "start": "2861000",
    "end": "2868280"
  },
  {
    "text": "kinds of crazy things to even avoiding calling the the llm directly having you",
    "start": "2868280",
    "end": "2873760"
  },
  {
    "text": "know some pre-saved prompts and pre-saved flows directly in in your local semantic kernel also Nick chapsas",
    "start": "2873760",
    "end": "2879800"
  },
  {
    "text": "who's a very common face here at NDC has got a great introductory video on semantic kernel so if you don't want to",
    "start": "2879800",
    "end": "2885280"
  },
  {
    "text": "go too deep but you just want to read a little bit more hear a little bit more it's 12 minutes and it'll take you through everything you need to know",
    "start": "2885280",
    "end": "2892119"
  },
  {
    "text": "furthermore LinkedIn learning there is a free course on semantic kernel that I highly recommend you check out it covers",
    "start": "2892119",
    "end": "2897599"
  },
  {
    "text": "all of the the key details and uh Microsoft learn has no less than 95",
    "start": "2897599",
    "end": "2903960"
  },
  {
    "text": "solid really solid C examp for how to do basically anything with semantic kernel",
    "start": "2903960",
    "end": "2909720"
  },
  {
    "text": "there's about 15 for Python and absolutely none for Java but they they'll come um so yeah these resources",
    "start": "2909720",
    "end": "2916319"
  },
  {
    "text": "are fantastic if you want to go check it out and what I would say is uh I'm on GitHub and everything that I've showed",
    "start": "2916319",
    "end": "2921480"
  },
  {
    "text": "you today is going to be open sourced very shortly after this talk so you can go and have a look at that there too um you can critique my crappy JavaScript um",
    "start": "2921480",
    "end": "2929520"
  },
  {
    "text": "what I'll leave you with is overall hopefully this has showed that semantic kernel is a really great way of integrating with basically any l",
    "start": "2929520",
    "end": "2937240"
  },
  {
    "text": "into your application with a fairly small amount of code and uh you can then start to focus more on building quality",
    "start": "2937240",
    "end": "2944400"
  },
  {
    "text": "experiences around those models rather than trading up your own AI if you want to you can you can use the AI Studio you",
    "start": "2944400",
    "end": "2951599"
  },
  {
    "text": "can provide it with your own data you can change its context you can improve that system prompt to make sure that",
    "start": "2951599",
    "end": "2957240"
  },
  {
    "text": "your model is not answering questions that you don't want it to be and uh overall just tailoring the experience",
    "start": "2957240",
    "end": "2963319"
  },
  {
    "text": "you can use the history service or the history feature in order order to let it keep track of context and then yeah most",
    "start": "2963319",
    "end": "2970440"
  },
  {
    "text": "importantly focus on the experience let's stop building chat interfaces let's actually build you know better more human things um thank you very much",
    "start": "2970440",
    "end": "2977440"
  },
  {
    "text": "I'll happily take some questions afterwards but uh appreciate your [Applause]",
    "start": "2977440",
    "end": "2988839"
  },
  {
    "text": "time yeah sure",
    "start": "2988839",
    "end": "2993280"
  },
  {
    "text": "yeah so the question was um using the chat history API do you uh exponentially",
    "start": "2996799",
    "end": "3002119"
  },
  {
    "text": "increase your token consumption and the answer is yes um there are other apis",
    "start": "3002119",
    "end": "3007200"
  },
  {
    "text": "you can use so there is a memory API from uh open aai but that is um quite",
    "start": "3007200",
    "end": "3012799"
  },
  {
    "text": "specific to the open AI um Services the memory API allows you to tell it to",
    "start": "3012799",
    "end": "3018040"
  },
  {
    "text": "remember certain bits of information and facts um what I didn't show you on the history API as well is you can then put",
    "start": "3018040",
    "end": "3024200"
  },
  {
    "text": "system prompts in that don't appear in the in the regular flow for the user and those system prompts might be to add",
    "start": "3024200",
    "end": "3030480"
  },
  {
    "text": "additional context or information to guide the model to the correct answer um again you're still stuffing stuff into",
    "start": "3030480",
    "end": "3037359"
  },
  {
    "text": "the uh into the history and it's growing exponentially but um it might get you a more accurate result so it's it's a it's",
    "start": "3037359",
    "end": "3042760"
  },
  {
    "text": "a big way up you could have a really really weighty um system prompt that means that's getting sent every time um",
    "start": "3042760",
    "end": "3050079"
  },
  {
    "text": "but it maybe means your users have to interact with the model less to then get a accurate answer for example um in",
    "start": "3050079",
    "end": "3057920"
  },
  {
    "text": "short yeah it does increase your token consumption was",
    "start": "3057920",
    "end": "3064359"
  },
  {
    "text": "yeah sure I understand so the the question was um what's the risk when",
    "start": "3076520",
    "end": "3081920"
  },
  {
    "text": "performing actions such as Creations that write data or mutate the state of your system what's the risk of",
    "start": "3081920",
    "end": "3087680"
  },
  {
    "text": "hallucination and and those sorts of things it's a great question um of course in my case I'm calling off to an",
    "start": "3087680",
    "end": "3093520"
  },
  {
    "text": "API that I know and control and has validation uh within it so if data was",
    "start": "3093520",
    "end": "3099520"
  },
  {
    "text": "sent for example an invalid user ID to say this is the person creating it and it doesn't exist that API rejects it and",
    "start": "3099520",
    "end": "3107359"
  },
  {
    "text": "so the system won't won't do it you can put your own validation inside of these functions so they would therefore not do",
    "start": "3107359",
    "end": "3114599"
  },
  {
    "text": "anything but as with all llms there is the risk of hallucination there is um particularly uh I didn't show it but if",
    "start": "3114599",
    "end": "3121640"
  },
  {
    "text": "you ask it to generate a a a c razor template it uses some fairly questionable syntax sometimes and that's",
    "start": "3121640",
    "end": "3128079"
  },
  {
    "text": "where it's really helpful to uh try and ground your model by giving it additional fine tuning training data to",
    "start": "3128079",
    "end": "3133680"
  },
  {
    "text": "say this is how a template should look to avoid those risks of hallucination but yeah validate is all I'd say before",
    "start": "3133680",
    "end": "3139359"
  },
  {
    "text": "before performing any action you got to validate the data which if you were to use that uh open API spec generative",
    "start": "3139359",
    "end": "3146720"
  },
  {
    "text": "approach you rely entirely on the API doing that if you use functions yourself and call the apis perhaps it's going to",
    "start": "3146720",
    "end": "3152760"
  },
  {
    "text": "be a little better a little more controlled",
    "start": "3152760",
    "end": "3157079"
  },
  {
    "text": "yeah great question so uh a little more detail on fine-tuning basically how how",
    "start": "3171520",
    "end": "3176640"
  },
  {
    "text": "do we um how do we fine-tune our model what kind of data do you give it and how do you prove that that fine-tuning has",
    "start": "3176640",
    "end": "3182079"
  },
  {
    "text": "actually worked so the fine tuning flow in uh Azure AI Studio takes in a format",
    "start": "3182079",
    "end": "3187440"
  },
  {
    "text": "called Json L Json lines which is effectively a way of splitting data into",
    "start": "3187440",
    "end": "3193359"
  },
  {
    "text": "token and values um and with that you can supply basically any data so if",
    "start": "3193359",
    "end": "3199079"
  },
  {
    "text": "that's code that you're looking for it to you know improve You' put a piece of syntax here and say these are the or a",
    "start": "3199079",
    "end": "3204680"
  },
  {
    "text": "prompt here and you put these are the possible uh sorts of values you might get out the other side um you provide that straight",
    "start": "3204680",
    "end": "3211200"
  },
  {
    "text": "to the AI studio and it's used then to to train the model you can in real time",
    "start": "3211200",
    "end": "3217000"
  },
  {
    "text": "test that in the playgrounds inside the um AI studio so you don't have to",
    "start": "3217000",
    "end": "3222920"
  },
  {
    "text": "necessarily wait for it to go and fine-tune the whole model you can take that data apply it straight on the top of the model in near real time and test",
    "start": "3222920",
    "end": "3230079"
  },
  {
    "text": "that out so if you've got some examples of prompts that were previously giving you invalid results that you needed to",
    "start": "3230079",
    "end": "3235240"
  },
  {
    "text": "then fine-tune yeah the AI Studio basically lets you test that does that cover the question",
    "start": "3235240",
    "end": "3242319"
  },
  {
    "text": "fantastic probably got time for one more if there's anybody",
    "start": "3242319",
    "end": "3248040"
  },
  {
    "text": "sure okay cool question so um the question was if you've got multiple",
    "start": "3258079",
    "end": "3264119"
  },
  {
    "text": "models how do you determine basically which model has responded uh if it wasn't clear depending on the action or",
    "start": "3264119",
    "end": "3270920"
  },
  {
    "text": "the service that you're doing you're calling a specific model so that's a predetermined act configuration time you've set it to always call that model",
    "start": "3270920",
    "end": "3277880"
  },
  {
    "text": "um that said you can build a plugin that",
    "start": "3277880",
    "end": "3283280"
  },
  {
    "text": "would call off to as many models as you want so you could then use the plug-in architecture to build your own flow that",
    "start": "3283280",
    "end": "3290640"
  },
  {
    "text": "would call three or four models and determine the best result um a good example of this would be uh if you had a",
    "start": "3290640",
    "end": "3296440"
  },
  {
    "text": "plugin that you needed to go and find an image from a internet search and you might want to then compare the results",
    "start": "3296440",
    "end": "3302400"
  },
  {
    "text": "that come back from Bing and from Google and then on top of that you might want to take those results and pass them",
    "start": "3302400",
    "end": "3308040"
  },
  {
    "text": "through a further filter to make sure that there's no I don't know nudity or or those sorts of things in those images",
    "start": "3308040",
    "end": "3314400"
  },
  {
    "text": "or that or that they just generally match your overall uh approach and that way you'd probably use one of the",
    "start": "3314400",
    "end": "3319480"
  },
  {
    "text": "transcribe features of say open AI so you would use your plugin to First Call off to um being and Google get your your",
    "start": "3319480",
    "end": "3326480"
  },
  {
    "text": "data you would then write your own logic that establishes what of those responses",
    "start": "3326480",
    "end": "3331520"
  },
  {
    "text": "you want to use and then you could call off to a further model by just injecting say the uh I don't know the text",
    "start": "3331520",
    "end": "3337720"
  },
  {
    "text": "generation service or image generation service or something to uh then yeah",
    "start": "3337720",
    "end": "3342799"
  },
  {
    "text": "further call additional models so in short semantic colel won't directly call five models at the same time it's only",
    "start": "3342799",
    "end": "3349079"
  },
  {
    "text": "calling one but you can then do whatever you want so you can determine that that should call further models or do further",
    "start": "3349079",
    "end": "3354960"
  },
  {
    "text": "work all good okay thanks very much for your time everyone hope you enjoy the rest of",
    "start": "3354960",
    "end": "3360640"
  },
  {
    "text": "the conference",
    "start": "3360640",
    "end": "3363720"
  },
  {
    "text": "[Music]",
    "start": "3371100",
    "end": "3373780"
  }
]
[
  {
    "text": "so he should probably get started so",
    "start": "5099",
    "end": "11230"
  },
  {
    "text": "thanks for sticking around to the last session of the day and it's been a long",
    "start": "11230",
    "end": "16600"
  },
  {
    "text": "day document the deposition hope that you enjoyed the session and find useful",
    "start": "16600",
    "end": "24210"
  },
  {
    "text": "it's about CUDA kernels in C++ couple words about myself I'm Michael Westen I",
    "start": "24210",
    "end": "30880"
  },
  {
    "text": "work for IVA vision when we create the next generation of materiality glasses and we believe that",
    "start": "30880",
    "end": "37510"
  },
  {
    "text": "our technology will eventually replace all other monitors like just desktops",
    "start": "37510",
    "end": "43479"
  },
  {
    "text": "and mobile phones and we use CUDA mostly to accelerate algorithms in computer vision area okay so the SCOOTER is a",
    "start": "43479",
    "end": "52870"
  },
  {
    "text": "platform in the toolkit by nvidia to create generic algorithms and applications to run on NVIDIA GPU",
    "start": "52870",
    "end": "60309"
  },
  {
    "text": "devices and that includes support for different languages it includes some",
    "start": "60309",
    "end": "67540"
  },
  {
    "text": "tools for profiling debugging in building the code and also a bunch of libraries made way how many of you have",
    "start": "67540",
    "end": "75220"
  },
  {
    "text": "used cuda or did some basic training content okay so i'm not going to do a",
    "start": "75220",
    "end": "83590"
  },
  {
    "text": "deep introduction into the programming but it looks playing on examples so it",
    "start": "83590",
    "end": "90010"
  },
  {
    "text": "should be easy for you to follow it and you start from a very simple example basically which will use through the",
    "start": "90010",
    "end": "97000"
  },
  {
    "text": "whole session it's like the hello world example for cuda problems and that's an",
    "start": "97000",
    "end": "102280"
  },
  {
    "text": "addition of two vectors okay so have a vector a and vector B and they want to create a vector C which is an",
    "start": "102280",
    "end": "108430"
  },
  {
    "text": "element-wise sum of the elements of a and B and the way we do it with CUDA we",
    "start": "108430",
    "end": "114580"
  },
  {
    "text": "create many many what's called CUDA threads okay this these are not exactly",
    "start": "114580",
    "end": "120340"
  },
  {
    "text": "the threads in the regular sense of the term but for this session it should work",
    "start": "120340",
    "end": "126010"
  },
  {
    "text": "so create many many CUDA threads each thread is being assigned certain index",
    "start": "126010",
    "end": "131349"
  },
  {
    "text": "in the output array C which it needs to calculate and the next property of the vector addition is that each cell",
    "start": "131349",
    "end": "138100"
  },
  {
    "text": "and calculated independently of the other cells so all these CUDA feds can use should run in parallel in the same",
    "start": "138100",
    "end": "144550"
  },
  {
    "text": "time in the wait world to express it in the CUDA C++ code is like that the first",
    "start": "144550",
    "end": "152160"
  },
  {
    "text": "at Cornell it's called calling function it's the code which runs on the GPU it's preceded",
    "start": "152160",
    "end": "158800"
  },
  {
    "text": "with a special keyboard underscore global but otherwise it looks like a regular function it has all this in all",
    "start": "158800",
    "end": "167020"
  },
  {
    "text": "these in input parameters the vectors a p-- AB&C which you want to operate on and then the first line each thread will",
    "start": "167020",
    "end": "175360"
  },
  {
    "text": "calculate unique index into the race which needs to work on and skip always",
    "start": "175360",
    "end": "182560"
  },
  {
    "text": "part of block index and thread index what's important is that each thread in CUDA will get a unique index to the to",
    "start": "182560",
    "end": "190810"
  },
  {
    "text": "the race now the second line in a simple addition of the vectors and B at the end the cell",
    "start": "190810",
    "end": "197890"
  },
  {
    "text": "ID X and the code which runs on CUDA is Bill it's called the kernel or device",
    "start": "197890",
    "end": "203950"
  },
  {
    "text": "code and the code which runs from CPU is called the host code or a CPU code so",
    "start": "203950",
    "end": "211210"
  },
  {
    "text": "this example the main is a regular application in C++ we skip all the",
    "start": "211210",
    "end": "217500"
  },
  {
    "text": "installation parts of the other vectors and just see special syntax to launch",
    "start": "217500",
    "end": "222670"
  },
  {
    "text": "the kernel on the GPU it uses these triple angle brackets with some numbers",
    "start": "222670",
    "end": "229360"
  },
  {
    "text": "inside we should also talk about this right now but otherwise it looks like a regular",
    "start": "229360",
    "end": "234670"
  },
  {
    "text": "function it passes all the parameters on pointers to the vectors to the colon",
    "start": "234670",
    "end": "241150"
  },
  {
    "text": "function you can note on the left side the rest eggs",
    "start": "241150",
    "end": "246180"
  },
  {
    "text": "device and host and keep it in all the slides so it will be like more easy to",
    "start": "246180",
    "end": "252820"
  },
  {
    "text": "follow which code runs on the CPU in which quadrants well GPU not so far",
    "start": "252820",
    "end": "258670"
  },
  {
    "text": "looks like a pure C functions and we said that to talk about CUDA C C++",
    "start": "258670",
    "end": "265210"
  },
  {
    "text": "that's exactly the reason why I'm doing this talk because in most of the",
    "start": "265210",
    "end": "270340"
  },
  {
    "text": "examples that you find on CUDA on internet in the books the code is purely C code and they believe that",
    "start": "270340",
    "end": "276729"
  },
  {
    "text": "using C++ we had many many advantages on the readability of the code on the type",
    "start": "276729",
    "end": "283389"
  },
  {
    "text": "safety and sometimes even on the performance of the code so one would",
    "start": "283389",
    "end": "289090"
  },
  {
    "text": "like to depart from the CUDA C programming and start our journey to",
    "start": "289090",
    "end": "294130"
  },
  {
    "text": "probably a better code this doesn't let's get back to a first example and",
    "start": "294130",
    "end": "300180"
  },
  {
    "text": "the first question is what if we would like to sum up floating-point arrays",
    "start": "300180",
    "end": "305550"
  },
  {
    "text": "okay then the C answer would probably like that we would add another kernel",
    "start": "305550",
    "end": "311560"
  },
  {
    "text": "function a kernel F which takes parameters as floats but otherwise the",
    "start": "311560",
    "end": "316630"
  },
  {
    "text": "body of the function is exactly the same as it was before zip zip as pass solution is much easier",
    "start": "316630",
    "end": "321849"
  },
  {
    "text": "we just make the kernel function template and now it receives the pointers and then when we launch the",
    "start": "321849",
    "end": "328930"
  },
  {
    "text": "function the kernel we can either use an explicit template instance nation like",
    "start": "328930",
    "end": "333940"
  },
  {
    "text": "in first line or we can skip it and then the parameters will be automatically deduce the type T will be automatically",
    "start": "333940",
    "end": "341500"
  },
  {
    "text": "used from parameters that look like very very exciting as a c++ feature but josh",
    "start": "341500",
    "end": "349240"
  },
  {
    "text": "but it just shows that you can use templates include the kernel codes basically the same way as you do for",
    "start": "349240",
    "end": "354639"
  },
  {
    "text": "regular programs another thing that want to address in",
    "start": "354639",
    "end": "360430"
  },
  {
    "text": "first example are these memory pointers the question is what's the memory that",
    "start": "360430",
    "end": "366159"
  },
  {
    "text": "this pointers are pointing to exactly on the other system we have a CPU this the",
    "start": "366159",
    "end": "371770"
  },
  {
    "text": "system or a few memory on the host memory it's regular memory we use in all",
    "start": "371770",
    "end": "377229"
  },
  {
    "text": "in all our services problems and then each GPU device in have its own memory",
    "start": "377229",
    "end": "383039"
  },
  {
    "text": "also called the global memory or a device memory and the kernels which run on GPU can directly access only the",
    "start": "383039",
    "end": "390280"
  },
  {
    "text": "memory which resides on the device and then what you usually do in CUDA programs we host allocate the memory on",
    "start": "390280",
    "end": "397180"
  },
  {
    "text": "the device we screw the malach or similar functions and then we'll copy the input arrays a and B from",
    "start": "397180",
    "end": "405380"
  },
  {
    "text": "our CPU memory - the HP memory then watch the function to calculate the",
    "start": "405380",
    "end": "410870"
  },
  {
    "text": "result of actor C and at the end we'll copy the result back from the GPU to a",
    "start": "410870",
    "end": "416270"
  },
  {
    "text": "CPU and the main problem that approach is that the type of all the pointers in",
    "start": "416270",
    "end": "423350"
  },
  {
    "text": "the CPU and the GPU is still a row pointer but the semantics of the pointer",
    "start": "423350",
    "end": "428870"
  },
  {
    "text": "was very different one points the CPU memory another to appeal to GPU memory you can build a very simple example",
    "start": "428870",
    "end": "435280"
  },
  {
    "text": "where we launch kernel with pointers to the local CPU memory and the main",
    "start": "435280",
    "end": "441650"
  },
  {
    "text": "problem is that example is it compiles but then it fails in runtime and of",
    "start": "441650",
    "end": "446900"
  },
  {
    "text": "course it's it was passed before to fail as always possible and preferably in compilation stage and not in the runtime",
    "start": "446900",
    "end": "454390"
  },
  {
    "text": "so what we what to do instead is to define specific types should device",
    "start": "454390",
    "end": "462140"
  },
  {
    "text": "pointer types device PTR type which indicates explicitly that this is a pointer to a device memory and use it in",
    "start": "462140",
    "end": "468680"
  },
  {
    "text": "the corners instead an example how we can write such a function and find the",
    "start": "468680",
    "end": "476810"
  },
  {
    "text": "class it will be template by the type of the pointer and now I can make the",
    "start": "476810",
    "end": "481880"
  },
  {
    "text": "constructor of this class private in order to avoid accidental conversion of",
    "start": "481880",
    "end": "487790"
  },
  {
    "text": "the pointers to device PTR can also know this underscore school device and host",
    "start": "487790",
    "end": "493100"
  },
  {
    "text": "keywords any function which runs which is called inside the device code but we",
    "start": "493100",
    "end": "499400"
  },
  {
    "text": "proceeded with the device keyword and if one want to use the same function in",
    "start": "499400",
    "end": "505490"
  },
  {
    "text": "kernel code and end in hot code should also add this host key world and then you can add an",
    "start": "505490",
    "end": "516919"
  },
  {
    "text": "explicit factory function to create a device pointer from row pointer the",
    "start": "516919",
    "end": "525200"
  },
  {
    "text": "focal videos can also add a global function which makes a device pointer from row pointer the whole point is that",
    "start": "525200",
    "end": "532520"
  },
  {
    "text": "now we do it explicitly when we know that the pointer in hand is a pointer in",
    "start": "532520",
    "end": "537740"
  },
  {
    "text": "the value GPU space and then to build the mocha print example of launching the kernel you can",
    "start": "537740",
    "end": "545480"
  },
  {
    "text": "have like this function process assume that it gets vectors a and B already",
    "start": "545480",
    "end": "551240"
  },
  {
    "text": "initialized at some point in the program and then in order to launch the kernel",
    "start": "551240",
    "end": "557080"
  },
  {
    "text": "we should do the following first we would allocate the memory on the device we could walk and then we'll copy the",
    "start": "557080",
    "end": "565370"
  },
  {
    "text": "memory of the a pointer to the GPU and connote the special keyboards",
    "start": "565370",
    "end": "570410"
  },
  {
    "text": "could the mem copy host to device it indicates the device of the memory copying its from from CPU to the GPU and",
    "start": "570410",
    "end": "578510"
  },
  {
    "text": "we do the same for B and also locate the memory for C now we can launch a kernel",
    "start": "578510",
    "end": "584750"
  },
  {
    "text": "and use a function make the bus PTR which converts raw pointer to a device",
    "start": "584750",
    "end": "592700"
  },
  {
    "text": "pointer and then it compiles in the Comanche : function and and then we want",
    "start": "592700",
    "end": "598640"
  },
  {
    "text": "to copy the result back from the GPU to CPU so again we would use a copy mm",
    "start": "598640",
    "end": "604490"
  },
  {
    "text": "could the mem copy and now indicates that the copying from device to host and",
    "start": "604490",
    "end": "611030"
  },
  {
    "text": "may be nice to waste right the nicer way to try this code would be",
    "start": "611030",
    "end": "616490"
  },
  {
    "text": "it would have some device memory class which does the installation work for us",
    "start": "616490",
    "end": "621500"
  },
  {
    "text": "then just tell it okay allocate num number of elements and then a copy",
    "start": "621500",
    "end": "627500"
  },
  {
    "text": "element function does not have to get that extra parameter with the direction of the copy it can be deduced from the",
    "start": "627500",
    "end": "633890"
  },
  {
    "text": "parameter types Duncan G Duncan just launched kernel",
    "start": "633890",
    "end": "639470"
  },
  {
    "text": "these device memory as a parameter and let it converted to device pointer",
    "start": "639470",
    "end": "645230"
  },
  {
    "text": "automatically you can do something like that you can create a device memory",
    "start": "645230",
    "end": "650390"
  },
  {
    "text": "class in this case so define the constructor as a private constructor",
    "start": "650390",
    "end": "656660"
  },
  {
    "text": "just avoid confusion between allocating and elements and no painting and bytes",
    "start": "656660",
    "end": "662890"
  },
  {
    "text": "and can add static functions to make an explicit installation of the way on the",
    "start": "662890",
    "end": "668960"
  },
  {
    "text": "memory of instructor will fill in the memory on the device and we can add conversional",
    "start": "668960",
    "end": "676500"
  },
  {
    "text": "created the casting operator to cast the device memory to device PTR type okay",
    "start": "676500",
    "end": "683670"
  },
  {
    "text": "now back to device PTR so one of the property of the pointer which you want to maintain is the rules",
    "start": "683670",
    "end": "689699"
  },
  {
    "text": "for the assignment operators so what I want to be able to copy an interpreter",
    "start": "689699",
    "end": "695430"
  },
  {
    "text": "to the constant pointer but not the way around and we don't want to assign go in",
    "start": "695430",
    "end": "701220"
  },
  {
    "text": "terms of different types one to another basically but when to say that want to",
    "start": "701220",
    "end": "707310"
  },
  {
    "text": "allow a copy from from type t1 to type T only if t1 pointer is convertible to ET",
    "start": "707310",
    "end": "714300"
  },
  {
    "text": "pointer you can write it using type traits then we say that this copy",
    "start": "714300",
    "end": "722009"
  },
  {
    "text": "constructor is only available if types of the pointers convertible again it's a",
    "start": "722009",
    "end": "727079"
  },
  {
    "text": "regular C++ code but it just shows that you can use same template semantics and",
    "start": "727079",
    "end": "733079"
  },
  {
    "text": "headers like type traits in the kernel code in device code and works fine",
    "start": "733079",
    "end": "738920"
  },
  {
    "text": "another example what might be useful to use templates in kernel code is to",
    "start": "740480",
    "end": "747540"
  },
  {
    "text": "create some polymorphism so the set of heaven s : function is basically do add",
    "start": "747540",
    "end": "753209"
  },
  {
    "text": "operation we want to give it an type of operation in the template parameter so",
    "start": "753209",
    "end": "759959"
  },
  {
    "text": "create a class which is binary opt + which defines a function call character which gets two T's and the tauruses a",
    "start": "759959",
    "end": "766500"
  },
  {
    "text": "sum of two T's and then the kernel template the calling function can now",
    "start": "766500",
    "end": "773639"
  },
  {
    "text": "now get a new template parameter which is the type of the creation want to",
    "start": "773639",
    "end": "778649"
  },
  {
    "text": "invoke and then the kernel self we create an instance of the operation up and and call it instead of explicit a",
    "start": "778649",
    "end": "786480"
  },
  {
    "text": "plus B and once we launch a kernel we specify the type of the struct of the",
    "start": "786480",
    "end": "791639"
  },
  {
    "text": "operation which you want to use so far we've seen the use of templates in",
    "start": "791639",
    "end": "797490"
  },
  {
    "text": "static polymorphism next question is how we do in the line polymorphism in CUDA",
    "start": "797490",
    "end": "803710"
  },
  {
    "text": "so I want to create a binary up interface Joseph which also also defines",
    "start": "803710",
    "end": "810500"
  },
  {
    "text": "virtual function call ok right or which takes two values of T type and returns a",
    "start": "810500",
    "end": "816020"
  },
  {
    "text": "tea type in back and now our binary applause class is an implementation of",
    "start": "816020",
    "end": "822200"
  },
  {
    "text": "the binary up interface and then could to have a worker function it basically",
    "start": "822200",
    "end": "829850"
  },
  {
    "text": "gets a reference to the interface and calls the interface by the virtual function to do the operation and we can",
    "start": "829850",
    "end": "837529"
  },
  {
    "text": "have another column function which uses that worker function by creating an",
    "start": "837529",
    "end": "843020"
  },
  {
    "text": "instance of binary of plus and and providing it to the worker function",
    "start": "843020",
    "end": "848089"
  },
  {
    "text": "again it works fine with virtual functions in CUDA in may be useful in",
    "start": "848089",
    "end": "854660"
  },
  {
    "text": "some cases but there is a very significant limitation the intention is that the can't pass classes with virtual",
    "start": "854660",
    "end": "861470"
  },
  {
    "text": "functions from the CPU code to the GPU code as is not the problem because a",
    "start": "861470",
    "end": "867500"
  },
  {
    "text": "business logic used resides on CPU code the CPU part of the code is one to",
    "start": "867500",
    "end": "872510"
  },
  {
    "text": "decide which operation want to invoke on the GPU either it's ad or other type of",
    "start": "872510",
    "end": "878060"
  },
  {
    "text": "operations and we can try to solve it in a couple of ways this one way is to add",
    "start": "878060",
    "end": "885440"
  },
  {
    "text": "back this template parameter to the column function and pass it as a template parameter but we want the",
    "start": "885440",
    "end": "892850"
  },
  {
    "text": "kernel and it works but then it misses the point a bit as if they already have",
    "start": "892850",
    "end": "898190"
  },
  {
    "text": "operation s template parameter because just propagate is a template parameter and use and use the static static",
    "start": "898190",
    "end": "908839"
  },
  {
    "text": "selection of the functions as we did before in this case there's not much use on which value to use virtual functions",
    "start": "908839",
    "end": "916760"
  },
  {
    "text": "in kernel code what we would like to do instead is to have a kernel function to",
    "start": "916760",
    "end": "923000"
  },
  {
    "text": "get a pointer to an interface to implementation of binary up interface and somehow want to create it on the CPU",
    "start": "923000",
    "end": "929300"
  },
  {
    "text": "code and pass a pointer to it to the kernel so tomato want on first to allocate the",
    "start": "929300",
    "end": "937309"
  },
  {
    "text": "memory on a GPU from sea view of the property size T then inside the GPU code",
    "start": "937309",
    "end": "943189"
  },
  {
    "text": "we can access this memory and initialize it to valid object of type T and now in",
    "start": "943189",
    "end": "950119"
  },
  {
    "text": "this app you part have a valid pointer to it the object on GPU which you can use and and pass to a kernel function",
    "start": "950119",
    "end": "957410"
  },
  {
    "text": "while we launch it let's let's see how this can be implemented you can add a",
    "start": "957410",
    "end": "964429"
  },
  {
    "text": "new class which is a device object it will use the device memory class which",
    "start": "964429",
    "end": "969559"
  },
  {
    "text": "you've seen before in the constructor to first allocate one element using the facilities of the device memory class",
    "start": "969559",
    "end": "977829"
  },
  {
    "text": "now the more interesting part is how we initialize the object on the GPU basically we want to create a kernel",
    "start": "977829",
    "end": "985279"
  },
  {
    "text": "function and the calling functions the global functions chain box from CPU there must be freestanding functions",
    "start": "985279",
    "end": "992169"
  },
  {
    "text": "they can't be member functions in the class so don't need the only way to do",
    "start": "992169",
    "end": "997429"
  },
  {
    "text": "some encapsulation is to use a namespace okay so in this case we create a kernel",
    "start": "997429",
    "end": "1002619"
  },
  {
    "text": "function allocate objects we should get a pointer to some memory on the GPU",
    "start": "1002619",
    "end": "1007839"
  },
  {
    "text": "device and then arguments to initialize the object then we use a regular",
    "start": "1007839",
    "end": "1014339"
  },
  {
    "text": "placement operator new to initialize the object in place on the device and from a",
    "start": "1014339",
    "end": "1020499"
  },
  {
    "text": "CPU code the constructor of dev object it would launch a single instance of",
    "start": "1020499",
    "end": "1025928"
  },
  {
    "text": "allocate object just need a signal could thread to do the work and we are done",
    "start": "1025929",
    "end": "1031688"
  },
  {
    "text": "and have add a class T on the GPU GPU memory which is properly initialized",
    "start": "1031689",
    "end": "1037779"
  },
  {
    "text": "with all parameters but the way we also note that the parameters to allocate",
    "start": "1037779",
    "end": "1043360"
  },
  {
    "text": "object are passed by value in number reference and we can't pass argument by reference from CPU to GPU in the",
    "start": "1043360",
    "end": "1052149"
  },
  {
    "text": "references in different different neighbor spaces and then to use it in",
    "start": "1052149",
    "end": "1058240"
  },
  {
    "text": "natural way from the from CPU code you can just add also a casting operator",
    "start": "1058240",
    "end": "1063909"
  },
  {
    "text": "from device object - device pointer and then it completes",
    "start": "1063909",
    "end": "1069040"
  },
  {
    "text": "the example of course because also add it release a wrist functional instructor",
    "start": "1069040",
    "end": "1076510"
  },
  {
    "text": "- device object which we'll call also a special kernel function to call the",
    "start": "1076510",
    "end": "1082000"
  },
  {
    "text": "destructor on the device side and then the memory is released in the destructor",
    "start": "1082000",
    "end": "1089200"
  },
  {
    "text": "of the DMM of the noble class so we are done the case we've seen the static",
    "start": "1089200",
    "end": "1096730"
  },
  {
    "text": "polymorphism next stop is new delete functions basically the section is a",
    "start": "1096730",
    "end": "1101830"
  },
  {
    "text": "shortest in all the slides says that you can use malloc free and new delete",
    "start": "1101830",
    "end": "1107830"
  },
  {
    "text": "functions in kernel code it works as expected it allocates memory or the object in the device device memory space",
    "start": "1107830",
    "end": "1116220"
  },
  {
    "text": "I'm not sure that you want to always use it but at least it's available and it",
    "start": "1116220",
    "end": "1121330"
  },
  {
    "text": "works as expected ok next feature of C++ which you want to",
    "start": "1121330",
    "end": "1126910"
  },
  {
    "text": "explore how to use it in in color code alum the functions the very simple",
    "start": "1126910",
    "end": "1133660"
  },
  {
    "text": "example is to create a lambda function inside the kernel function which will do the post operation for us on parameters",
    "start": "1133660",
    "end": "1140590"
  },
  {
    "text": "a and B so this example it's a static lambda and then we invoke it as we would",
    "start": "1140590",
    "end": "1146679"
  },
  {
    "text": "do with the regular C++ code and it works also all the rules to capture the",
    "start": "1146679",
    "end": "1154000"
  },
  {
    "text": "lambdas applying on a GPU code and the theater lambda which captures a state in",
    "start": "1154000",
    "end": "1160960"
  },
  {
    "text": "these cases index and pointers to a and B and that's the calculation of the sum",
    "start": "1160960",
    "end": "1166330"
  },
  {
    "text": "inside see that the most exciting news",
    "start": "1166330",
    "end": "1172059"
  },
  {
    "text": "case for lambdas is that we can pass lambdas between the CPU and the GPU and",
    "start": "1172059",
    "end": "1177070"
  },
  {
    "text": "that's supported by Kudo compiler so we can add a template type operation to our",
    "start": "1177070",
    "end": "1183580"
  },
  {
    "text": "SQL no signature and then we get the OP parameter in the kernel function it will",
    "start": "1183580",
    "end": "1190360"
  },
  {
    "text": "just call it as regular second lambda function and then lambda itself is",
    "start": "1190360",
    "end": "1195429"
  },
  {
    "text": "defined in main and you should note the special key world underscore underscore device which means that but this is that's a",
    "start": "1195429",
    "end": "1203090"
  },
  {
    "text": "lambda which is created in the CPU but it can run in GPU it also requires to",
    "start": "1203090",
    "end": "1208130"
  },
  {
    "text": "add a special computation flag which supports extended lambda but otherwise",
    "start": "1208130",
    "end": "1213950"
  },
  {
    "text": "it works like most most irregular because they're Google general lambdas",
    "start": "1213950",
    "end": "1220220"
  },
  {
    "text": "is very useful to pass logic from a CPU to GPU in different way the question is",
    "start": "1220220",
    "end": "1228130"
  },
  {
    "text": "have read this lambda which crosses the border between the CPU and GPU we send",
    "start": "1228130",
    "end": "1233150"
  },
  {
    "text": "it the callin function and the question is what can be captured as part of",
    "start": "1233150",
    "end": "1239270"
  },
  {
    "text": "CAPTCHA parameters of this lambda one",
    "start": "1239270",
    "end": "1244460"
  },
  {
    "text": "exception you can do is and it comes as no surprise we can't capture any",
    "start": "1244460",
    "end": "1251090"
  },
  {
    "text": "parameters inside lambda by reference and the game is because you can't reference any memory only CPU and pass",
    "start": "1251090",
    "end": "1259790"
  },
  {
    "text": "it to GPU as is so just fail in runtime this example you try to capture some",
    "start": "1259790",
    "end": "1265160"
  },
  {
    "text": "values the reference then it fails already in copulation time is expected",
    "start": "1265160",
    "end": "1271510"
  },
  {
    "text": "the more interesting problem is capturing of this pointer let's see an",
    "start": "1271510",
    "end": "1277700"
  },
  {
    "text": "example of how it looks like so now",
    "start": "1277700",
    "end": "1283510"
  },
  {
    "text": "operation to sum up two vectors is much more complicated we want to add the vector a vector B but also add some",
    "start": "1283510",
    "end": "1291560"
  },
  {
    "text": "constant number I do each one of the elements so create structure up which it",
    "start": "1291560",
    "end": "1298490"
  },
  {
    "text": "presents the operation that you want to apply on the cool down it's towards its doors that I integer inside and then you",
    "start": "1298490",
    "end": "1307100"
  },
  {
    "text": "can add an apply function which you create basically a lamp inside you",
    "start": "1307100",
    "end": "1314030"
  },
  {
    "text": "capture I by this pointer and we can launch the kernel from the apply",
    "start": "1314030",
    "end": "1319280"
  },
  {
    "text": "function the problem is this code compiles but then it fails in runtime because this is scheduled the pointer in",
    "start": "1319280",
    "end": "1326270"
  },
  {
    "text": "the solution is to use a value capturing semantics for this just use",
    "start": "1326270",
    "end": "1332420"
  },
  {
    "text": "starve this and this is being captured my value the value has been copied",
    "start": "1332420",
    "end": "1339170"
  },
  {
    "text": "inside said the lambda and then it works fine but still think that this code has",
    "start": "1339170",
    "end": "1346820"
  },
  {
    "text": "a problem from design perspective that is that the start-up is too complicated",
    "start": "1346820",
    "end": "1353000"
  },
  {
    "text": "all we wanted it to be is to represent a simple addition operation of two numbers",
    "start": "1353000",
    "end": "1359120"
  },
  {
    "text": "and in in AI but instead of that it has this apply function which knows a",
    "start": "1359120",
    "end": "1365750"
  },
  {
    "text": "certain Colonel exists and it tries to launch it and it should be much easier",
    "start": "1365750",
    "end": "1373250"
  },
  {
    "text": "you'd like it to be something like that you'd like the start-up to be factory",
    "start": "1373250",
    "end": "1379340"
  },
  {
    "text": "which creates a function for us and then want to somehow use it when we launch",
    "start": "1379340",
    "end": "1384680"
  },
  {
    "text": "the kernel function first attempt would be just to get the lambda out of the",
    "start": "1384680",
    "end": "1392120"
  },
  {
    "text": "abstract and send it to the GPU into GPU code similar structure which works fine",
    "start": "1392120",
    "end": "1399770"
  },
  {
    "text": "on the regular ship there goes pass pass code but it doesn't compile on CUDA and get a compilation",
    "start": "1399770",
    "end": "1405020"
  },
  {
    "text": "error that the make up function which created the lambda can have auto return",
    "start": "1405020",
    "end": "1410270"
  },
  {
    "text": "type so need to specify in a specific zone type in this case okay so can tribe",
    "start": "1410270",
    "end": "1417320"
  },
  {
    "text": "try to return a function which gets to in return an int and we know that lambda",
    "start": "1417320",
    "end": "1423520"
  },
  {
    "text": "can be converted to a function but then there's a problem but you can't pass the",
    "start": "1423520",
    "end": "1431150"
  },
  {
    "text": "stool function to the kernel and also it's not very surprising as odd as we",
    "start": "1431150",
    "end": "1437900"
  },
  {
    "text": "said that only functions which run on GPU should have this device keyboard inside and there's no reason why I stood",
    "start": "1437900",
    "end": "1444740"
  },
  {
    "text": "function would have one but instead we can use an envy envy stood function",
    "start": "1444740",
    "end": "1451010"
  },
  {
    "text": "which is provided in header and be functional as part of CUDA package by Nvidia but now the case is even worse as",
    "start": "1451010",
    "end": "1460670"
  },
  {
    "text": "this compiles but then it fails in runtime and there we go on and read and read the",
    "start": "1460670",
    "end": "1467730"
  },
  {
    "text": "documentation it says the cone can't pass and we stood function is the",
    "start": "1467730",
    "end": "1473430"
  },
  {
    "text": "parameter to : function so it's a bit of",
    "start": "1473430",
    "end": "1478680"
  },
  {
    "text": "a mix in this case so the only solution that I found 20 new dope lead this",
    "start": "1478680",
    "end": "1487440"
  },
  {
    "text": "example is to pass the whole structure up as the parameter to the to the CUDA",
    "start": "1487440",
    "end": "1493440"
  },
  {
    "text": "kernel and then to create the lambda inside the kernel function and return it",
    "start": "1493440",
    "end": "1500340"
  },
  {
    "text": "as an as an bastogne function and then finally works it's less beauty as",
    "start": "1500340",
    "end": "1509430"
  },
  {
    "text": "beautiful from design point of view then what we intended it to be but still it's useful and it works",
    "start": "1509430",
    "end": "1516620"
  },
  {
    "text": "because we've seen issues on the lambdas and the canvas tool function but the",
    "start": "1516620",
    "end": "1523230"
  },
  {
    "text": "question is are all these zero of head obstructions and we expect Tom Seaver",
    "start": "1523230",
    "end": "1529200"
  },
  {
    "text": "stars features and maybe you can run some performance tests to compare like",
    "start": "1529200",
    "end": "1536390"
  },
  {
    "text": "before and after it's not always good solution is it's hard to distinguish",
    "start": "1536390",
    "end": "1543410"
  },
  {
    "text": "distinguish between a real overhead caused by the code change and between just random fluctuations on a small time",
    "start": "1543410",
    "end": "1551100"
  },
  {
    "text": "but another solution which becomes very popular and even be hardly mentioned it",
    "start": "1551100",
    "end": "1558510"
  },
  {
    "text": "is to use for example the compiler Explorer to compare the code before and",
    "start": "1558510",
    "end": "1564960"
  },
  {
    "text": "after in pretty recently could support was added to compile the exporter and",
    "start": "1564960",
    "end": "1570780"
  },
  {
    "text": "you can now paste our code and see make sure for example that the handcrafted C",
    "start": "1570780",
    "end": "1578100"
  },
  {
    "text": "style code produces the same same binder exactly as you'll get with all the",
    "start": "1578100",
    "end": "1584580"
  },
  {
    "text": "lambdas and functions and so on that's a great tool to make sure that all obstructions are not only beautiful but",
    "start": "1584580",
    "end": "1591060"
  },
  {
    "text": "doesn't hurt the performance in any way and another tool you can use it's a good",
    "start": "1591060",
    "end": "1597600"
  },
  {
    "text": "object amp it part of the CUDA package so in this case I give it the object file which is the",
    "start": "1597600",
    "end": "1604529"
  },
  {
    "text": "result of completion of the CUDA file and that sa SS parameter which means",
    "start": "1604529",
    "end": "1610649"
  },
  {
    "text": "that you want to get the binary of the assembly print it out and again can use",
    "start": "1610649",
    "end": "1617309"
  },
  {
    "text": "it and compare the function before the C++ presentation and after and see that",
    "start": "1617309",
    "end": "1623059"
  },
  {
    "text": "it's the same performance exactly it's the same binary code so during the test",
    "start": "1623059",
    "end": "1630049"
  },
  {
    "text": "they see the static polymorphism is free lambdas are also free I was also",
    "start": "1630049",
    "end": "1636870"
  },
  {
    "text": "surprised to see that example with the hood function also did not produce any",
    "start": "1636870",
    "end": "1643049"
  },
  {
    "text": "overhead and like all the only use of function was optimized by the compiler I",
    "start": "1643049",
    "end": "1649580"
  },
  {
    "text": "believe in some cases okay but not big case as we know that at least on the",
    "start": "1649580",
    "end": "1655409"
  },
  {
    "text": "regular integrity versus programs the user function can have some overhead but",
    "start": "1655409",
    "end": "1660750"
  },
  {
    "text": "in my examples it was also fine just to",
    "start": "1660750",
    "end": "1667260"
  },
  {
    "text": "mention some other types of features that you can use in kernel code we've seen the use of auto Const experts",
    "start": "1667260",
    "end": "1673730"
  },
  {
    "text": "expert functions can be used a range based loop iteration and also our value",
    "start": "1673730",
    "end": "1679110"
  },
  {
    "text": "semantics move semantics it's all applicable in the CUDA code in same way as it is in the CPU code the only",
    "start": "1679110",
    "end": "1686880"
  },
  {
    "text": "exception to the rule are the exceptions and it's very similar to what happens probably be embedded there's a better",
    "start": "1686880",
    "end": "1695639"
  },
  {
    "text": "use of C++ the exceptions are not supported at least not in the current format it might be that you know a",
    "start": "1695639",
    "end": "1702960"
  },
  {
    "text": "couple of standards from now you have a new support for exceptions if you'll be",
    "start": "1702960",
    "end": "1708029"
  },
  {
    "text": "more appropriate to run all the beta devices and on the GPU for now we can't",
    "start": "1708029",
    "end": "1713309"
  },
  {
    "text": "use exceptions in the kernel code and a couple of of kudos specific examples",
    "start": "1713309",
    "end": "1721110"
  },
  {
    "text": "which is related to C++ so first example",
    "start": "1721110",
    "end": "1726330"
  },
  {
    "text": "have this kernel that needs to iterate over some array",
    "start": "1726330",
    "end": "1732408"
  },
  {
    "text": "and then want to use the pragma on all feature to get better performance of",
    "start": "1732810",
    "end": "1738450"
  },
  {
    "text": "this Coronel but the way I've seen some examples were unrolling the loop in the",
    "start": "1738450",
    "end": "1743790"
  },
  {
    "text": "CUDA code it really makes a big change you see performance is much better and",
    "start": "1743790",
    "end": "1750990"
  },
  {
    "text": "it's miserable but the question is what was the put as a parameter to per control and until the recent versions it",
    "start": "1750990",
    "end": "1758400"
  },
  {
    "text": "had only put a hard-coded number in this place and it can be appropriated some",
    "start": "1758400",
    "end": "1767160"
  },
  {
    "text": "cases but maybe not and in recent versions of CUDA you can basically use",
    "start": "1767160",
    "end": "1772650"
  },
  {
    "text": "any value which can be deducted in the compile time so it can be this example",
    "start": "1772650",
    "end": "1778410"
  },
  {
    "text": "you can use a constructor function which combines some template parameter with",
    "start": "1778410",
    "end": "1784170"
  },
  {
    "text": "constant number and as long as we can as a compiler could use this value in",
    "start": "1784170",
    "end": "1789660"
  },
  {
    "text": "compiled time it will do the appropriate unroll parameter and hope that our code",
    "start": "1789660",
    "end": "1796680"
  },
  {
    "text": "will run faster another feature which is also specific to the CUDA is a rant",
    "start": "1796680",
    "end": "1803400"
  },
  {
    "text": "incorporation of the CUDA code so the cuda library has some facilities to load",
    "start": "1803400",
    "end": "1810650"
  },
  {
    "text": "basically could the functions and compile them and upload them to the device dynamically is opposite to a",
    "start": "1810650",
    "end": "1819720"
  },
  {
    "text": "special syntax which we've seen so far and it's much more similar to open sale",
    "start": "1819720",
    "end": "1825090"
  },
  {
    "text": "if you're familiar with that some of the entities some advantages of using the",
    "start": "1825090",
    "end": "1831720"
  },
  {
    "text": "rantin compilation on the regular compilation first is that you don't need to have a special go-to compiler they",
    "start": "1831720",
    "end": "1839850"
  },
  {
    "text": "just compile the application with any compiler that you use and then just linked with CUDA libraries which are C",
    "start": "1839850",
    "end": "1846810"
  },
  {
    "text": "libraries which allow you to upload the code to device and do the compilation and do all the stuff that the reason",
    "start": "1846810",
    "end": "1854820"
  },
  {
    "text": "that may be useful to do the Ratan compilation is to tune the compilation",
    "start": "1854820",
    "end": "1859860"
  },
  {
    "text": "flex so table example might be tuning and architecture",
    "start": "1859860",
    "end": "1865260"
  },
  {
    "text": "but basically in run time you can look at the exact device that you have in hand and and build the completion flags",
    "start": "1865260",
    "end": "1872159"
  },
  {
    "text": "to be optimized for this device now",
    "start": "1872159",
    "end": "1877470"
  },
  {
    "text": "that's the use case Jeff which i think is very interesting and small related to C++ is that in if in the source code of",
    "start": "1877470",
    "end": "1885120"
  },
  {
    "text": "C++ have some template functions then we can specify the template parameters in",
    "start": "1885120",
    "end": "1890970"
  },
  {
    "text": "runtime with that random population code so an example of how this can be useful",
    "start": "1890970",
    "end": "1899929"
  },
  {
    "text": "okay so again have some process kernel which runs on the GPU and we want to use",
    "start": "1899929",
    "end": "1905610"
  },
  {
    "text": "the fragment roll to make it run faster and we don't know the number of layers",
    "start": "1905610",
    "end": "1911399"
  },
  {
    "text": "in this example in advance we want to get it as a template parameter to our",
    "start": "1911399",
    "end": "1916500"
  },
  {
    "text": "current function but the problem is that this number of layers is calculated in",
    "start": "1916500",
    "end": "1922019"
  },
  {
    "text": "the main program dynamically and you can't know it in the compile time because how do we pass an int as",
    "start": "1922019",
    "end": "1932519"
  },
  {
    "text": "definite parameter it's one solution is to create some some proxy function we",
    "start": "1932519",
    "end": "1938730"
  },
  {
    "text": "should just do and if we switch on all the possible values for the layers and",
    "start": "1938730",
    "end": "1944880"
  },
  {
    "text": "we've called appropriate technical sector it's it's not very nice piece of",
    "start": "1944880",
    "end": "1951480"
  },
  {
    "text": "code it also requires us to know in advance all the possible values of layers also it means that all the",
    "start": "1951480",
    "end": "1958409"
  },
  {
    "text": "versions of the process function on CUDA will be compiled and become a part of",
    "start": "1958409",
    "end": "1964139"
  },
  {
    "text": "our binary and when we use the dynamic",
    "start": "1964139",
    "end": "1969529"
  },
  {
    "text": "the compile time the only compilation of the color code you can basically specify",
    "start": "1969529",
    "end": "1974880"
  },
  {
    "text": "all the parameters in the compile time and I'm not going over the exact",
    "start": "1974880",
    "end": "1980730"
  },
  {
    "text": "examples of how you do it you can find the good examples on internet on in the",
    "start": "1980730",
    "end": "1985740"
  },
  {
    "text": "cuda documentation but basically a function for example which gives you the",
    "start": "1985740",
    "end": "1992669"
  },
  {
    "text": "suppose first name of the template which we needs to which you need to use from the deputy parameter and other functions",
    "start": "1992669",
    "end": "1999050"
  },
  {
    "text": "to register template parameters and then use them when you launch the current function because eventually started from",
    "start": "1999050",
    "end": "2008890"
  },
  {
    "text": "C programming and enriched start start using C++ in CUDA kernels know a couple",
    "start": "2008890",
    "end": "2018820"
  },
  {
    "text": "of links to finish MS so one is a github repository where we can find all these",
    "start": "2018820",
    "end": "2024760"
  },
  {
    "text": "examples in more details in it's not",
    "start": "2024760",
    "end": "2030160"
  },
  {
    "text": "very complete it's mostly like filtration of special features that you",
    "start": "2030160",
    "end": "2035440"
  },
  {
    "text": "can do on CUDA and links to one in the",
    "start": "2035440",
    "end": "2041080"
  },
  {
    "text": "blog post by Nvidia in the CUDA 8 version there are many features which",
    "start": "2041080",
    "end": "2046930"
  },
  {
    "text": "were added to the Super's for support and you can read it it's very nice even article and also you want to look at the",
    "start": "2046930",
    "end": "2054970"
  },
  {
    "text": "GPU programming we see pass pass the take a look at the cocoa library",
    "start": "2054970",
    "end": "2061169"
  },
  {
    "text": "he doesn't target only the nvidia platform but basically all the other HPC",
    "start": "2061679",
    "end": "2067570"
  },
  {
    "text": "is PC platforms questions yes",
    "start": "2067570",
    "end": "2080790"
  },
  {
    "text": "talked about what examples where we want to build your own kernels and to launch",
    "start": "2080790",
    "end": "2087220"
  },
  {
    "text": "it own device and like shows which which which of so she passed pass you can use",
    "start": "2087220",
    "end": "2094050"
  },
  {
    "text": "risky trust does use lambdas as a parameters to its functions it has a",
    "start": "2094050",
    "end": "2100420"
  },
  {
    "text": "certain set of operators level to use it in many cases but if you want to write",
    "start": "2100420",
    "end": "2107260"
  },
  {
    "text": "your own code of code then you may want to use some superstars features visit",
    "start": "2107260",
    "end": "2113580"
  },
  {
    "text": "yeah",
    "start": "2114690",
    "end": "2117690"
  },
  {
    "text": "the question is the most difference which we could and OpenCL so basically OpenCL is an open standard and for",
    "start": "2127160",
    "end": "2135720"
  },
  {
    "text": "NVIDIA devices its implemented on top of CUDA I believe that you can some cases you",
    "start": "2135720",
    "end": "2143940"
  },
  {
    "text": "can gain more control on your code with CUDA as basically its closest to the",
    "start": "2143940",
    "end": "2151410"
  },
  {
    "text": "platform as it gets there's some parameters it's consumed in CUDA and",
    "start": "2151410",
    "end": "2158460"
  },
  {
    "text": "some special functions which deals with memory consistency and caching and so on",
    "start": "2158460",
    "end": "2164010"
  },
  {
    "text": "which she believed not exist in a more general API so open sale but it's about",
    "start": "2164010",
    "end": "2170790"
  },
  {
    "text": "in the same level if you think about a GPU you feel programming okay thank you",
    "start": "2170790",
    "end": "2182350"
  },
  {
    "text": "[Applause]",
    "start": "2182350",
    "end": "2189179"
  }
]
[
  {
    "text": "good morning everybody welcome to this talk on using Kafka for dotnet",
    "start": "4240",
    "end": "9549"
  },
  {
    "text": "development my name is Kevin Feazell I am a Microsoft data platform in VP out of Durham North Carolina also manager of",
    "start": "9549",
    "end": "16810"
  },
  {
    "text": "a predictive analytics team and I want to show something really fast it's called curated sequel the idea of",
    "start": "16810",
    "end": "22240"
  },
  {
    "text": "curated sequel is that I try to find a link to five to ten interesting blog posts per day somewhere in the data",
    "start": "22240",
    "end": "27640"
  },
  {
    "text": "platform space including database administration or development power bi Kafka spark the entire Hadoop ecosystem",
    "start": "27640",
    "end": "34680"
  },
  {
    "text": "are a Python and so on so that's curated SQL comm so let's talk Kafka Apache",
    "start": "34680",
    "end": "42910"
  },
  {
    "text": "Kafka is a message broker that lives on a Hadoop stack it is a top-level Apache product which means that there's a full",
    "start": "42910",
    "end": "50770"
  },
  {
    "text": "open-source community for it they make regular releases for this product and there's enough of a",
    "start": "50770",
    "end": "57040"
  },
  {
    "text": "community there to ensure the support for the future the idea behind this",
    "start": "57040",
    "end": "63039"
  },
  {
    "text": "broker is just like any other broker we have producers that will send messages",
    "start": "63039",
    "end": "68590"
  },
  {
    "text": "to consumers but the trick around Kafka is everything in this picture is",
    "start": "68590",
    "end": "74140"
  },
  {
    "text": "distributed meaning that you can scale out the individual pieces separately from one another and the scale is",
    "start": "74140",
    "end": "80140"
  },
  {
    "text": "approximately linear in terms of I added new hardware I get approximately linear",
    "start": "80140",
    "end": "85299"
  },
  {
    "text": "growth in the capacity to explain why",
    "start": "85299",
    "end": "90689"
  },
  {
    "text": "Kafka is interesting first I want to talk a little bit about why message brokers are interesting so I'm here at a",
    "start": "90689",
    "end": "97509"
  },
  {
    "text": "development conference normally I present these at data platform conferences where",
    "start": "97509",
    "end": "102630"
  },
  {
    "text": "database administrators don't necessarily know the value behind message brokers so please indulge me",
    "start": "102630",
    "end": "107860"
  },
  {
    "text": "just a moment we suppose that we have a couple of applications that want to communicate and in this case I'm",
    "start": "107860",
    "end": "113950"
  },
  {
    "text": "inverting the normal paradigm I have an application a web app that communicates",
    "start": "113950",
    "end": "119200"
  },
  {
    "text": "rights to a database we don't care what's in the database it's just there it's it's a requirement we have to put stuff in a database getting it out who",
    "start": "119200",
    "end": "125860"
  },
  {
    "text": "cares so this works fine I set up my app I set up my database I have a connection",
    "start": "125860",
    "end": "132790"
  },
  {
    "text": "string that points to my database and I write insert statements this works well until you get to a",
    "start": "132790",
    "end": "139080"
  },
  {
    "text": "certain point at some point we can't push messages through anymore typically it's because this really",
    "start": "139080",
    "end": "146310"
  },
  {
    "text": "underpowered like one core AWS or Azure VM that's running our web application",
    "start": "146310",
    "end": "152010"
  },
  {
    "text": "can't take any more requests and so we say I got that I'll spin up a bunch of",
    "start": "152010",
    "end": "159390"
  },
  {
    "text": "those VMs so now we have a bunch of VMs all writing into our database and at",
    "start": "159390",
    "end": "164490"
  },
  {
    "text": "some point we've spun up enough VMs that now it's our pour database that is the",
    "start": "164490",
    "end": "169830"
  },
  {
    "text": "bottleneck we say okay I got that I'm",
    "start": "169830",
    "end": "174990"
  },
  {
    "text": "gonna do this then we get spaghetti so I have all of these virtual machines that",
    "start": "174990",
    "end": "182070"
  },
  {
    "text": "now want to talk to a bunch of different database servers I can have a bunch of connection strings I probably have some",
    "start": "182070",
    "end": "189150"
  },
  {
    "text": "manager in between that tells exactly which database server to go talk to at",
    "start": "189150",
    "end": "194490"
  },
  {
    "text": "any point in time but I start to run into interesting issues at scale one of",
    "start": "194490",
    "end": "201030"
  },
  {
    "text": "those issues is we suppose I need to write to that database but database goes",
    "start": "201030",
    "end": "207660"
  },
  {
    "text": "offline what are the applications do the applications I have to write to this particular database we can say I'm gonna",
    "start": "207660",
    "end": "216420"
  },
  {
    "text": "hold the messages on this server until that database comes back online whenever that may be but then we may run out of",
    "start": "216420",
    "end": "223650"
  },
  {
    "text": "disk space on this server because again they're really cheap vm's that we're trying to spend as little money on and",
    "start": "223650",
    "end": "228959"
  },
  {
    "text": "now that whole server is offline that's a problem another issue that we might",
    "start": "228959",
    "end": "234720"
  },
  {
    "text": "run or another way that we may be able to solve the problem is to say alright I received a message but it's gonna go to",
    "start": "234720",
    "end": "240390"
  },
  {
    "text": "that failed server so forget about it drop the message that may be okay but",
    "start": "240390",
    "end": "247680"
  },
  {
    "text": "probably isn't okay to just arbitrarily drop messages because sorry your final",
    "start": "247680",
    "end": "253140"
  },
  {
    "text": "destination is unavailable right now so",
    "start": "253140",
    "end": "258169"
  },
  {
    "text": "okay we put in a broker the idea of the broker is that messages come in from the",
    "start": "258169",
    "end": "265169"
  },
  {
    "text": "consumer consumer still or excuse me coming from the producer the producer is still really cheap hardware",
    "start": "265169",
    "end": "270430"
  },
  {
    "text": "these really cheap VMs that probably don't have much disk space this producer",
    "start": "270430",
    "end": "275740"
  },
  {
    "text": "has a lot of disk space its whole job is to collect messages to collect data and",
    "start": "275740",
    "end": "281140"
  },
  {
    "text": "then eventually a consumer like our database is going to read is going to",
    "start": "281140",
    "end": "287320"
  },
  {
    "text": "consume the messages in the broker and then do whatever it does with them from",
    "start": "287320",
    "end": "292480"
  },
  {
    "text": "the brokers perspective we don't care what the consumer does that's not our job anymore",
    "start": "292480",
    "end": "298830"
  },
  {
    "text": "so now I've pushed the problem of what happens when something fails one step further I don't have to worry about",
    "start": "299460",
    "end": "306310"
  },
  {
    "text": "running out of disk space on this broker because you know we're we're running this on a server that's going to have a",
    "start": "306310",
    "end": "312910"
  },
  {
    "text": "lot of disk space notice how I'm wishing away the problem but one of the benefits that will see",
    "start": "312910",
    "end": "319570"
  },
  {
    "text": "with Kafka is that because I can scale out this broker I can just add new servers add new servers and keep adding",
    "start": "319570",
    "end": "326860"
  },
  {
    "text": "more discs and life is good what I'm doing here though is I'm decoupling",
    "start": "326860",
    "end": "333510"
  },
  {
    "text": "production of a message I'm decoupling the production from the consumption of",
    "start": "333510",
    "end": "338860"
  },
  {
    "text": "that message I no longer care who the consumer is or who the consumers are",
    "start": "338860",
    "end": "344160"
  },
  {
    "text": "instead I'm just saying as a producer I",
    "start": "344160",
    "end": "349330"
  },
  {
    "text": "sent a message here and I'm done my work is over somebody else take it from there",
    "start": "349330",
    "end": "355290"
  },
  {
    "text": "so the talk today is going to focus on using Apache Kafka to ingest enrich and",
    "start": "355290",
    "end": "362200"
  },
  {
    "text": "consume data and the data that I've chosen is flight data I take enough",
    "start": "362200",
    "end": "367420"
  },
  {
    "text": "flights that this is an interesting enough topic to me I pulled a fair number of flights from",
    "start": "367420",
    "end": "372820"
  },
  {
    "text": "the year 2008 that was data that came from a contest and so is generally",
    "start": "372820",
    "end": "378190"
  },
  {
    "text": "available fairly easy for me to grab and I want to know broken out by state this was all United States data how many",
    "start": "378190",
    "end": "385720"
  },
  {
    "text": "flights did we have in 2008 how many arrivals were delayed how much arrival delay did we have and",
    "start": "385720",
    "end": "392460"
  },
  {
    "text": "supposing that I'm going to some state how long can I expect assuming that",
    "start": "392460",
    "end": "398440"
  },
  {
    "text": "there is a delay that delay will be let's talk now",
    "start": "398440",
    "end": "403760"
  },
  {
    "text": "about concepts typically a message broker will act like a queue so what I",
    "start": "403760",
    "end": "410720"
  },
  {
    "text": "mean by this is that I have a set of messages that are available for me and",
    "start": "410720",
    "end": "416360"
  },
  {
    "text": "now the consumer is going to pull the nest next message off of the queue and consume it once it consumes the message",
    "start": "416360",
    "end": "423800"
  },
  {
    "text": "it's gone for good consumer then pulls the next message consumes it because in",
    "start": "423800",
    "end": "429830"
  },
  {
    "text": "height this ends up giving us one nice benefit which is that the queue in a",
    "start": "429830",
    "end": "436160"
  },
  {
    "text": "steady state remains about the same size so we can figure out about how many",
    "start": "436160",
    "end": "441320"
  },
  {
    "text": "messages per second we need to process based on how many come in and have a",
    "start": "441320",
    "end": "446510"
  },
  {
    "text": "queue that has just enough buffer to keep us going in the event that a consumer goes down for an a",
    "start": "446510",
    "end": "453970"
  },
  {
    "text": "predetermined amount of time and you can do the math you can figure out about how",
    "start": "453970",
    "end": "459380"
  },
  {
    "text": "much disk space you need but it has a big disadvantage and I'll tell you that",
    "start": "459380",
    "end": "464930"
  },
  {
    "text": "disadvantage in just a moment the Kafka model looks a bit like this it's more",
    "start": "464930",
    "end": "471110"
  },
  {
    "text": "like a log it's a file that producers add to the end of the file and consumers",
    "start": "471110",
    "end": "477080"
  },
  {
    "text": "are really just hailing this file they're reading messages from earliest",
    "start": "477080",
    "end": "482150"
  },
  {
    "text": "to latest processing through there so the queue model has a relatively fixed",
    "start": "482150",
    "end": "488420"
  },
  {
    "text": "size in steady state the log model will grow potentially in steady state but the",
    "start": "488420",
    "end": "496010"
  },
  {
    "text": "log model has a couple of nice advantages the first one is I can have multiple independent consumers reading",
    "start": "496010",
    "end": "503780"
  },
  {
    "text": "the same data so think of a micro services scenario where I've got a data",
    "start": "503780",
    "end": "509150"
  },
  {
    "text": "source and I have a series of applications that want to do small things with this process like let's say",
    "start": "509150",
    "end": "515630"
  },
  {
    "text": "I have medical claims data my primary application may be to take a claim and",
    "start": "515630",
    "end": "522020"
  },
  {
    "text": "then determine whether or not that claim is payable I may have a second application which takes a claim and",
    "start": "522020",
    "end": "528680"
  },
  {
    "text": "tries to figure out is this a fraudulent claim so not only should we not pay it but should we potentially go to the",
    "start": "528680",
    "end": "534800"
  },
  {
    "text": "authorities about this claim I may have a process which takes these claims and tries to figure out which doctors are",
    "start": "534800",
    "end": "542270"
  },
  {
    "text": "most active in our nation patient network I then can have another service which does a completely different thing",
    "start": "542270",
    "end": "547910"
  },
  {
    "text": "all of these services can read this data at their own pace we don't have to do",
    "start": "547910",
    "end": "553580"
  },
  {
    "text": "all of them at once and I can have them be separate applications separate services so they don't have to talk to",
    "start": "553580",
    "end": "560810"
  },
  {
    "text": "each other they don't have to know that each other's services exist all they have to know is where they can get this",
    "start": "560810",
    "end": "568280"
  },
  {
    "text": "data another big advantage of this and",
    "start": "568280",
    "end": "573730"
  },
  {
    "text": "so another big advantage of this is that I can take this data and reread it let's",
    "start": "573730",
    "end": "579950"
  },
  {
    "text": "say that I had a bug one of our applications had a bug at release well I can figure out where the point was when",
    "start": "579950",
    "end": "586700"
  },
  {
    "text": "we had our new release and revert back to that point and reprocess this data",
    "start": "586700",
    "end": "592820"
  },
  {
    "text": "now I as a developer have to write the code that can handle rereading this",
    "start": "592820",
    "end": "598010"
  },
  {
    "text": "message and ensuring that I handle it appropriately so this is not just free",
    "start": "598010",
    "end": "605120"
  },
  {
    "text": "I'm gonna take any application it will automatically do this but you know we're developers we're smart we can do these",
    "start": "605120",
    "end": "610910"
  },
  {
    "text": "things so the brokers job is to foster",
    "start": "610910",
    "end": "617390"
  },
  {
    "text": "communication producers put messages to US consumers read messages from us and",
    "start": "617390",
    "end": "626110"
  },
  {
    "text": "this broker is running the Apache Kafka stack specifically on a broker we have a",
    "start": "626110",
    "end": "635480"
  },
  {
    "text": "concept of a topic so topic is just a logical container the subject it's we",
    "start": "635480",
    "end": "642080"
  },
  {
    "text": "can think of it as a queue within each topic we have partitions partitions are",
    "start": "642080",
    "end": "648470"
  },
  {
    "text": "the physical implementations on a particular Broker of a topic so think of",
    "start": "648470",
    "end": "655430"
  },
  {
    "text": "this as a file on some servers file system we insert records into a topic by",
    "start": "655430",
    "end": "663950"
  },
  {
    "text": "way of inserting into an appropriate servers partition now this producer may",
    "start": "663950",
    "end": "669440"
  },
  {
    "text": "care where the record goes maybe the producer wants it to go into partition one and then maybe their next",
    "start": "669440",
    "end": "677300"
  },
  {
    "text": "record also goes into partition one and their next one then goes into partition two alternatively we may have a model",
    "start": "677300",
    "end": "685640"
  },
  {
    "text": "where the producer says I don't care where this partition goes or excuse me I",
    "start": "685640",
    "end": "691190"
  },
  {
    "text": "don't care where this message goes just round-robin distributes so that I can send you messages as quickly as possible",
    "start": "691190",
    "end": "697340"
  },
  {
    "text": "have some broker available and whichever one picks up my message first that one",
    "start": "697340",
    "end": "703250"
  },
  {
    "text": "gets the message it's your choice you get to choose whether or not you're",
    "start": "703250",
    "end": "709700"
  },
  {
    "text": "going to distribute my partition or whether you're going to distribute across partitions with advantages and",
    "start": "709700",
    "end": "715130"
  },
  {
    "text": "disadvantages around performance versus the ability to distribute data so these",
    "start": "715130",
    "end": "724520"
  },
  {
    "text": "producers already mentioned they're the ones pushing messages the other side we",
    "start": "724520",
    "end": "730310"
  },
  {
    "text": "have consumers so a consumer will read data from a topic more specifically a",
    "start": "730310",
    "end": "737140"
  },
  {
    "text": "consumer will read data from one or more partitions so here I can have a set of",
    "start": "737140",
    "end": "745820"
  },
  {
    "text": "consumers that read each of the",
    "start": "745820",
    "end": "751430"
  },
  {
    "text": "partitions individually or I may have go",
    "start": "751430",
    "end": "757490"
  },
  {
    "text": "back to read I may have one consumer that's going to read all of the data the way that I can",
    "start": "757490",
    "end": "764860"
  },
  {
    "text": "bind them together is with this notion of a consumer group so think of a",
    "start": "764860",
    "end": "771890"
  },
  {
    "text": "consumer group as one or more threads or instances of your application as",
    "start": "771890",
    "end": "779330"
  },
  {
    "text": "performing some process so in this case I have four instances for maybe four",
    "start": "779330",
    "end": "785600"
  },
  {
    "text": "vm's maybe four threads on a single VM maybe some combination but these are",
    "start": "785600",
    "end": "794300"
  },
  {
    "text": "independent these are independently reading the partitions I also have a bit",
    "start": "794300",
    "end": "799640"
  },
  {
    "text": "of a an interesting scenario here because you know I showed that color based highlighting",
    "start": "799640",
    "end": "805700"
  },
  {
    "text": "well if you have a consumer group more",
    "start": "805700",
    "end": "811520"
  },
  {
    "text": "consumer groups than you have partitions or excuse me more consumers than you have partitions within a consumer group",
    "start": "811520",
    "end": "816530"
  },
  {
    "text": "then the one the odd man out isn't gonna",
    "start": "816530",
    "end": "822230"
  },
  {
    "text": "read any messages so this scaling although each part can",
    "start": "822230",
    "end": "829730"
  },
  {
    "text": "scale out individually you do want to think in perspective of having enough",
    "start": "829730",
    "end": "834950"
  },
  {
    "text": "partitions available for your consumers to read if I had six partitions I could",
    "start": "834950",
    "end": "841550"
  },
  {
    "text": "distribute that across these four as a developer I can choose whether to",
    "start": "841550",
    "end": "847720"
  },
  {
    "text": "micromanage those partitions or I can just say go figure it out yourself I",
    "start": "847720",
    "end": "853540"
  },
  {
    "text": "typically go with the go figure out yourself route because I'm lazy another",
    "start": "853540",
    "end": "859550"
  },
  {
    "text": "concept here we're inserting data into a log and we have multiple consumers who",
    "start": "859550",
    "end": "864860"
  },
  {
    "text": "can read this data so our data has to be",
    "start": "864860",
    "end": "869900"
  },
  {
    "text": "immutable otherwise consumer one could read the data modify it and now consumer",
    "start": "869900",
    "end": "875120"
  },
  {
    "text": "two comes back and actually is reading completely different data because our data is immutable if somehow somebody",
    "start": "875120",
    "end": "883940"
  },
  {
    "text": "makes a mistake inserting record one we can't go back and change record one we",
    "start": "883940",
    "end": "890960"
  },
  {
    "text": "can insert a new record one but now our application has to be able to understand",
    "start": "890960",
    "end": "896180"
  },
  {
    "text": "that you receive record one you may have processed it some point later in time",
    "start": "896180",
    "end": "902120"
  },
  {
    "text": "you received a new record one you have to be able to process that you have to be able to fix what happened with record",
    "start": "902120",
    "end": "909320"
  },
  {
    "text": "one in order for us to be able to have",
    "start": "909320",
    "end": "918560"
  },
  {
    "text": "multiple consumers working in conjunction with one another within a consumer group we have to know where the",
    "start": "918560",
    "end": "926630"
  },
  {
    "text": "other consumers are in the group alternatively let's say we have an",
    "start": "926630",
    "end": "931790"
  },
  {
    "text": "application that has office hours the application runs 23 hours a day and then we shut it off for an hour for",
    "start": "931790",
    "end": "937840"
  },
  {
    "text": "maintenance or whatever we start out that application again it has to know where it left off the Kafka",
    "start": "937840",
    "end": "946079"
  },
  {
    "text": "system will automatically store the consumer groups specific offsets for",
    "start": "946079",
    "end": "952649"
  },
  {
    "text": "each partition and that way you can pick it back up where you left off it's just",
    "start": "952649",
    "end": "958470"
  },
  {
    "text": "done uh behind the scenes you don't have to do anything special to get that to work now as as we go through this log",
    "start": "958470",
    "end": "968730"
  },
  {
    "text": "example you can retain the log indefinitely you could have that those",
    "start": "968730",
    "end": "974279"
  },
  {
    "text": "messages remain for a million years I actually have one topic that has a",
    "start": "974279",
    "end": "981000"
  },
  {
    "text": "lifespan of a million years I don't think it'll this laptop will survive a million years I don't think my Hadoop",
    "start": "981000",
    "end": "986370"
  },
  {
    "text": "server will survive a million years but just in case I got that data in a real",
    "start": "986370",
    "end": "993899"
  },
  {
    "text": "scenario however you probably are not going to wow your boss by saying yeah our data is going to grow indefinitely",
    "start": "993899",
    "end": "1000319"
  },
  {
    "text": "and we're never going to remove any of it ever there are cases where that may be a good thing but in most cases we",
    "start": "1000319",
    "end": "1008089"
  },
  {
    "text": "have limits in some cases you have requirements that after a certain number of years this data must go away I'm",
    "start": "1008089",
    "end": "1016040"
  },
  {
    "text": "familiar with Medicaid data in the United States after seven years that data must go away it's a federal",
    "start": "1016040",
    "end": "1021500"
  },
  {
    "text": "requirement so we can configure retention times for our topics this data",
    "start": "1021500",
    "end": "1028370"
  },
  {
    "text": "can live for seven years after which point it is automatically garbage collected you can also garbage collect",
    "start": "1028370",
    "end": "1036020"
  },
  {
    "text": "at a certain disk size so we may say I don't know how how long the data should be retained you know we can have an",
    "start": "1036020",
    "end": "1042530"
  },
  {
    "text": "indefinite retention period but it can only give you a hundred gigabytes of disk space after which point the oldest",
    "start": "1042530",
    "end": "1048860"
  },
  {
    "text": "messages will get compacted until will get destroyed until we have 100 gigs remaining so all the stuff that I've",
    "start": "1048860",
    "end": "1058429"
  },
  {
    "text": "described even the the log concept this is not new this is not unique this is a",
    "start": "1058429",
    "end": "1064340"
  },
  {
    "text": "pretty well solved problem and you can go back to Microsoft message queue back in Windows Server 3 5 1 that's a message",
    "start": "1064340",
    "end": "1072230"
  },
  {
    "text": "broker service broker has been in sequel server since 2008 I want to say maybe even 2005",
    "start": "1072230",
    "end": "1079299"
  },
  {
    "text": "there have been dozens of brokers that have popped up over the years you know like rabbits 0nq celery there's a whole",
    "start": "1079299",
    "end": "1087410"
  },
  {
    "text": "website qzo that's dozens of message brokers that are freely available you go into AWS and Azure and they'll have log",
    "start": "1087410",
    "end": "1098059"
  },
  {
    "text": "based or queue based systems for message",
    "start": "1098059",
    "end": "1103130"
  },
  {
    "text": "brokering so Amazon Kinesis and Azure event hubs Kinesis by default stores",
    "start": "1103130",
    "end": "1109039"
  },
  {
    "text": "your data for seven days it acts like Kafka but it's only a so excuse me a one day retention you can pay extra to get",
    "start": "1109039",
    "end": "1115070"
  },
  {
    "text": "up to seven days worth of retention so these are the concepts now we're gonna",
    "start": "1115070",
    "end": "1121100"
  },
  {
    "text": "drill specifically into Apache Kafka and how we would develop dotnet applications",
    "start": "1121100",
    "end": "1127640"
  },
  {
    "text": "to communicate with a Kafka server that's living on my Hadoop box so we",
    "start": "1127640",
    "end": "1135950"
  },
  {
    "text": "have a producer producers can have data come in you know they can generate data",
    "start": "1135950",
    "end": "1141230"
  },
  {
    "text": "from whatever source maybe that's a web server that's receiving HTTP requests maybe it's a server that's receiving",
    "start": "1141230",
    "end": "1149090"
  },
  {
    "text": "messages from some other system in my case i'm just taking data from a CSV and",
    "start": "1149090",
    "end": "1154190"
  },
  {
    "text": "I want to turn this through as fast as possible my producer here is intentionally dumb it will try not to",
    "start": "1154190",
    "end": "1161270"
  },
  {
    "text": "understand messages it takes a message and it writes it out and it goes and grabs the next message so that way I can",
    "start": "1161270",
    "end": "1167690"
  },
  {
    "text": "push it through as fast as possible and I am going to kick off my producer right",
    "start": "1167690",
    "end": "1174770"
  },
  {
    "text": "now so that I can talk about it for just a little bit and then we'll look at the",
    "start": "1174770",
    "end": "1181460"
  },
  {
    "text": "code and by the time I'm done it'll be done so cool as a quick sidebar I am",
    "start": "1181460",
    "end": "1193309"
  },
  {
    "text": "using confluence dotnet library for Kafka confluent is a company that was",
    "start": "1193309",
    "end": "1200200"
  },
  {
    "text": "established by some of the original Kafka developers who were working for LinkedIn they spun off",
    "start": "1200200",
    "end": "1207050"
  },
  {
    "text": "in confluent is now the paid services organization around Apache Kafka they",
    "start": "1207050",
    "end": "1212930"
  },
  {
    "text": "have a fully supported dotnet library you can pull it in from nougat and it is the best library of the bunch there are",
    "start": "1212930",
    "end": "1219980"
  },
  {
    "text": "still other libraries that are available with a nougat for connecting to a Kafka",
    "start": "1219980",
    "end": "1224990"
  },
  {
    "text": "server many of them are no longer fully supported some of them only work with",
    "start": "1224990",
    "end": "1231440"
  },
  {
    "text": "versions of Kafka that are a couple years old at this point so I would just recommend grab confluence library and go",
    "start": "1231440",
    "end": "1239030"
  },
  {
    "text": "with that so let's talk about our producer the code is an f-sharp so if",
    "start": "1239030",
    "end": "1245690"
  },
  {
    "text": "you're digging all the functional programming talks today then you'll love this if not that's alright it will be",
    "start": "1245690",
    "end": "1252020"
  },
  {
    "text": "pretty easy to follow even if you've never seen a line of F sharp code in your life when it comes to nougat I'm",
    "start": "1252020",
    "end": "1258230"
  },
  {
    "text": "going to have to wait until the application finishes before I can show you the nougat package but there's",
    "start": "1258230",
    "end": "1263570"
  },
  {
    "text": "really only one real NuGet package that I'm using for purposes of running and",
    "start": "1263570",
    "end": "1269450"
  },
  {
    "text": "that's the confluent kafka package so let us look at this code I've got just a",
    "start": "1269450",
    "end": "1278120"
  },
  {
    "text": "simple console application with a main function and the first few lines of code are fluff so that I can get a nice color",
    "start": "1278120",
    "end": "1285950"
  },
  {
    "text": "and stopwatch so I can figure out how long this thing runs here's where we start getting into more interesting code",
    "start": "1285950",
    "end": "1293050"
  },
  {
    "text": "I'm creating a dictionary so dictionary of key value pairs I can say hey I need",
    "start": "1293050",
    "end": "1301070"
  },
  {
    "text": "to connect to a particular Kafka broker or if I have more than one broker I can",
    "start": "1301070",
    "end": "1308090"
  },
  {
    "text": "list them all here so if I have 15 servers that I know I can connect to you",
    "start": "1308090",
    "end": "1315020"
  },
  {
    "text": "know I can list all 15 go try to connect to at least one if I want to create a",
    "start": "1315020",
    "end": "1322400"
  },
  {
    "text": "consumer group then the key is group dot ID so this one is called airplane -",
    "start": "1322400",
    "end": "1329240"
  },
  {
    "text": "producer technically I don't need a consumer group here because it's not consuming anything but for a nicety I",
    "start": "1329240",
    "end": "1336050"
  },
  {
    "text": "wanted to create one I've got a few settings here that will help you with pushing higher throughput and we'll talk",
    "start": "1336050",
    "end": "1343610"
  },
  {
    "text": "about that and near the end of the talk where I'm giving you some quick performance tips I have a topic flights",
    "start": "1343610",
    "end": "1351440"
  },
  {
    "text": "and I am going to write out to this",
    "start": "1351440",
    "end": "1358670"
  },
  {
    "text": "producer so to do that I need to create a new producer notice that it has two",
    "start": "1358670",
    "end": "1364960"
  },
  {
    "text": "things that I need to give one is for the key one is for the value so Kafka",
    "start": "1364960",
    "end": "1371480"
  },
  {
    "text": "will allow you to push key value pairs in my case I don't need a key I just",
    "start": "1371480",
    "end": "1376730"
  },
  {
    "text": "need the value so I have a value of string if you wanted to do partitioning key based partitioning here's where you",
    "start": "1376730",
    "end": "1384590"
  },
  {
    "text": "would put the key and the key would determine which partition you go into so you may have something where I've got a",
    "start": "1384590",
    "end": "1391730"
  },
  {
    "text": "key for each of the states in the Union and now I've got 50 partitions because probably not going to be a 51st state",
    "start": "1391730",
    "end": "1398480"
  },
  {
    "text": "anytime soon so I can then determine based on the state which partition this",
    "start": "1398480",
    "end": "1404960"
  },
  {
    "text": "goes into if I need to read by state it's now a lot faster I don't have to read through the other 49 states that's",
    "start": "1404960",
    "end": "1411470"
  },
  {
    "text": "one way that you can use keys to distribute load but here I'm just round",
    "start": "1411470",
    "end": "1417620"
  },
  {
    "text": "robin inserting and you know let it let it insert where it may I have a function",
    "start": "1417620",
    "end": "1424130"
  },
  {
    "text": "that I've created to load entries so I'm taking the producer that I've created writing to the topic that I want from",
    "start": "1424130",
    "end": "1431120"
  },
  {
    "text": "the file that I've specified so that's pretty easy to do I simply read all the",
    "start": "1431120",
    "end": "1438710"
  },
  {
    "text": "lines in the file so this is then going to filter out any lines that are blank",
    "start": "1438710",
    "end": "1447080"
  },
  {
    "text": "there's probably a new line at the end of the file so throw it away filter out the first line of the file where it",
    "start": "1447080",
    "end": "1453050"
  },
  {
    "text": "starts with year that's just header information it's not important and then",
    "start": "1453050",
    "end": "1458270"
  },
  {
    "text": "for each line go and publish to this topic so publish is a real quick one",
    "start": "1458270",
    "end": "1466730"
  },
  {
    "text": "liner that produces asynchronously so write to this producer asynchronously",
    "start": "1466730",
    "end": "1472970"
  },
  {
    "text": "I'm not going to wait for a message come back in this case if it fails if a message fails I don't care I just want",
    "start": "1472970",
    "end": "1481970"
  },
  {
    "text": "messages to go as quickly as possible you can if you want produce synchronously so write a message",
    "start": "1481970",
    "end": "1488570"
  },
  {
    "text": "synchronously and and wait until result comes back that's going to be a lot slower but it is an option if you really",
    "start": "1488570",
    "end": "1499160"
  },
  {
    "text": "want to so as I run through all of this normally it takes about four minutes and",
    "start": "1499160",
    "end": "1505670"
  },
  {
    "text": "I'm pretty sure this has gone past the four-minute mark so my server is probably a little nervous it's it's up",
    "start": "1505670",
    "end": "1512450"
  },
  {
    "text": "in the lights in front of so many people but I'm gonna kill it right now because I don't need it for the next step at the",
    "start": "1512450",
    "end": "1521270"
  },
  {
    "text": "end it would tell us that hey we finished loading all the data and tell us how long it took to finish that thing",
    "start": "1521270",
    "end": "1526520"
  },
  {
    "text": "up typically I'll get somewhere around sixty thousand records per second",
    "start": "1526520",
    "end": "1533240"
  },
  {
    "text": "pushing from my laptop to this server through this really really cheap travel router in a realistic scenario I may be",
    "start": "1533240",
    "end": "1542240"
  },
  {
    "text": "getting I can push a million records per second onto a legitimate server or",
    "start": "1542240",
    "end": "1549340"
  },
  {
    "text": "combination of servers as far as NuGet packages go as I promised confluent",
    "start": "1549340",
    "end": "1556580"
  },
  {
    "text": "Kafka that's the big one it will also install this this library",
    "start": "1556580",
    "end": "1563090"
  },
  {
    "text": "which is a C and C++ it's C++ under the covers and the confluent library over top of it is a",
    "start": "1563090",
    "end": "1570320"
  },
  {
    "text": "dotnet implementation that makes it nice and easy for us to use the rest of it is",
    "start": "1570320",
    "end": "1577970"
  },
  {
    "text": "simply helper libraries that I need for my demos so a quick thing here is that",
    "start": "1577970",
    "end": "1586310"
  },
  {
    "text": "although I'm showing you one step at a time in reality all of these things are firing at the same time so consumers can",
    "start": "1586310",
    "end": "1592280"
  },
  {
    "text": "read data while the producers are pushing data and consumers can just follow along as the producers right so",
    "start": "1592280",
    "end": "1599180"
  },
  {
    "text": "although I'm doing this serially it really happens in parallel next up let's",
    "start": "1599180",
    "end": "1605660"
  },
  {
    "text": "talk enrichment so our second published application is going to take",
    "start": "1605660",
    "end": "1611330"
  },
  {
    "text": "data from that flights topic and then we're going to push messages on to a new",
    "start": "1611330",
    "end": "1616730"
  },
  {
    "text": "topic but before we push the message we're going to give that message structure we're going to give it a",
    "start": "1616730",
    "end": "1623410"
  },
  {
    "text": "little bit more flavor we're going to enrich it specifically some of the",
    "start": "1623410",
    "end": "1629210"
  },
  {
    "text": "structure that we're going to do first this data came from a data set that was published out of our so our has this",
    "start": "1629210",
    "end": "1636140"
  },
  {
    "text": "idea of na na is not quite null but for purposes of our talk we're gonna say",
    "start": "1636140",
    "end": "1643730"
  },
  {
    "text": "close enough to null it's it's a non applicable status so for example if we",
    "start": "1643730",
    "end": "1649460"
  },
  {
    "text": "did not have a delay delay reason is not applicable and that's how that's how we",
    "start": "1649460",
    "end": "1656420"
  },
  {
    "text": "use this so I want to take those na values and convert it to something more appropriate either a blank value a",
    "start": "1656420",
    "end": "1662570"
  },
  {
    "text": "default value or an f-sharp we have this idea of none which is also not in all but we have none we have we don't have",
    "start": "1662570",
    "end": "1670610"
  },
  {
    "text": "one of these every record in this will",
    "start": "1670610",
    "end": "1675710"
  },
  {
    "text": "have a sort an Origin Airport code and a destination Airport code so I want to",
    "start": "1675710",
    "end": "1681920"
  },
  {
    "text": "look up what those Airport codes actually mean because that's not in our data so I need to hit sequel server",
    "start": "1681920",
    "end": "1688730"
  },
  {
    "text": "because that's where I've got my data so we're gonna hit sequel server pull that data up and then process these results I",
    "start": "1688730",
    "end": "1695540"
  },
  {
    "text": "want to take my input CSV record and turn it into a data set that I can",
    "start": "1695540",
    "end": "1703370"
  },
  {
    "text": "recognize turn it into a type a structured type which think of it like a class or struct then finally I'll put",
    "start": "1703370",
    "end": "1712550"
  },
  {
    "text": "that data is JSON so that my consumers have an easier time they can deserialize the JSON and have an object as opposed",
    "start": "1712550",
    "end": "1718970"
  },
  {
    "text": "to having to create their own objects so let's look through that this is the",
    "start": "1718970",
    "end": "1725360"
  },
  {
    "text": "enricher application this is the most complex of the applications I will show",
    "start": "1725360",
    "end": "1730610"
  },
  {
    "text": "today and we will start at the bottom with our main function",
    "start": "1730610",
    "end": "1738400"
  },
  {
    "text": "so over here again a bit of fluff followed by something that's a little",
    "start": "1738400",
    "end": "1745680"
  },
  {
    "text": "bit more interesting I am going to open up a new sequel connection based off of",
    "start": "1745680",
    "end": "1752880"
  },
  {
    "text": "my connection string so let me hop up to the top and say that connection string",
    "start": "1752880",
    "end": "1758160"
  },
  {
    "text": "is a literal that is just a connection string of my sequel server you know there's nothing absolutely nothing",
    "start": "1758160",
    "end": "1763380"
  },
  {
    "text": "special about that connection string then I'm going to generate an airport",
    "start": "1763380",
    "end": "1770490"
  },
  {
    "text": "sequel type so this comes from a nougat",
    "start": "1770490",
    "end": "1775680"
  },
  {
    "text": "package F sharp data dot sequel client and this is a simple ORM around F sharp",
    "start": "1775680",
    "end": "1784050"
  },
  {
    "text": "that will allow me to create types and execute methods from sequel statements",
    "start": "1784050",
    "end": "1790760"
  },
  {
    "text": "including stored procedure calls so here's my statement I've got an airport",
    "start": "1790760",
    "end": "1796170"
  },
  {
    "text": "stable and I'm going to select some attributes from that Airport stable and",
    "start": "1796170",
    "end": "1801620"
  },
  {
    "text": "when when I do that I'll have airports equal so this is a type that will give",
    "start": "1801620",
    "end": "1809160"
  },
  {
    "text": "me a sequel command alright let's come back down to my application I need to",
    "start": "1809160",
    "end": "1820550"
  },
  {
    "text": "pop up here I need to create my airport",
    "start": "1820550",
    "end": "1826140"
  },
  {
    "text": "sequel type and then I'm going to execute the the sequel call and take the",
    "start": "1826140",
    "end": "1833790"
  },
  {
    "text": "elements out and put them into a list and call that airport's list so airports list is the list of all airports out of",
    "start": "1833790",
    "end": "1840240"
  },
  {
    "text": "my database I don't want to hit the database for every one of these flights because I've got about 7 million flights",
    "start": "1840240",
    "end": "1845610"
  },
  {
    "text": "in here that'd be seven million database calls and the whole point is to make things not horribly slow so I've got my",
    "start": "1845610",
    "end": "1856740"
  },
  {
    "text": "list then I'm going to build a dictionary building a dictionary are really simple all I'm doing is taking",
    "start": "1856740",
    "end": "1863280"
  },
  {
    "text": "the airport code the three-letter code that each Airport has and turning this",
    "start": "1863280",
    "end": "1872429"
  },
  {
    "text": "into a dictionary so I can look it up by code and get the rest of the values",
    "start": "1872429",
    "end": "1877730"
  },
  {
    "text": "next up configuration settings there's a lot more config settings than before yeah I've still got my same starters",
    "start": "1880580",
    "end": "1887549"
  },
  {
    "text": "I've changed my consumer group here I do need a consumer group because I will be reading from the flights topic and I'm",
    "start": "1887549",
    "end": "1894870"
  },
  {
    "text": "going to be then writing to another topic because I'm writing to another",
    "start": "1894870",
    "end": "1900059"
  },
  {
    "text": "topic I've got my settings for writing and now I've also got some settings for",
    "start": "1900059",
    "end": "1906990"
  },
  {
    "text": "consumption auto commit this is how frequently I update the consumer offset",
    "start": "1906990",
    "end": "1913620"
  },
  {
    "text": "so I may not necessarily want to update that offset with every single message that I pull instead I can allow the",
    "start": "1913620",
    "end": "1922140"
  },
  {
    "text": "confluent library to update for me at a reasonable frequency so that I'm",
    "start": "1922140",
    "end": "1928710"
  },
  {
    "text": "reducing the number of total updates to that topic specifically let me let me",
    "start": "1928710",
    "end": "1935580"
  },
  {
    "text": "show you for each consumer like airplane and richer yeah I've already done this before but airplane and richer is",
    "start": "1935580",
    "end": "1943770"
  },
  {
    "text": "reading from a topic and we have start in offset and lag so we haven't here",
    "start": "1943770",
    "end": "1950610"
  },
  {
    "text": "this is just pulled straight out of Kafka a topic that is specifically for",
    "start": "1950610",
    "end": "1956370"
  },
  {
    "text": "consumer offsets and specifically the consumer offsets associated with the",
    "start": "1956370",
    "end": "1962220"
  },
  {
    "text": "airplane and richer consumer group and the flights topic so in order for me to",
    "start": "1962220",
    "end": "1970649"
  },
  {
    "text": "tell where I'm at right now there's one record in here and every time a message",
    "start": "1970649",
    "end": "1976860"
  },
  {
    "text": "is read potentially I may update this topic you may notice that there's not",
    "start": "1976860",
    "end": "1983880"
  },
  {
    "text": "like 7 million of these as I peruse through the list this is because in",
    "start": "1983880",
    "end": "1989850"
  },
  {
    "text": "Kafka there's a concept I glazed over at the beginning and that concept is that",
    "start": "1989850",
    "end": "1995640"
  },
  {
    "text": "you can have automatic compaction of messages so you can say given some key",
    "start": "1995640",
    "end": "2006130"
  },
  {
    "text": "only retain the latest value of that so I can overwrite message oh those",
    "start": "2006130",
    "end": "2011210"
  },
  {
    "text": "messages automatically it's kind of going against the log nature of Kafka so",
    "start": "2011210",
    "end": "2017120"
  },
  {
    "text": "I didn't want to talk about that at the beginning but here it makes sense to talk about now that we're getting into",
    "start": "2017120",
    "end": "2022700"
  },
  {
    "text": "the weeds so it is something that you can do for your topics as well if you if",
    "start": "2022700",
    "end": "2027890"
  },
  {
    "text": "you know that you only should have one version of something and you're okay not having the true history you can use",
    "start": "2027890",
    "end": "2034460"
  },
  {
    "text": "automatic compaction and we've got a",
    "start": "2034460",
    "end": "2040640"
  },
  {
    "text": "couple more attributes here that help me with throughput so input topic as",
    "start": "2040640",
    "end": "2050000"
  },
  {
    "text": "flights output topic is called enriched flights too I'm going to create a",
    "start": "2050000",
    "end": "2055790"
  },
  {
    "text": "producer just like I did before so I have a producer a null string and over here on the right hand side I have my",
    "start": "2055790",
    "end": "2062358"
  },
  {
    "text": "implementation of a producer so my implementation of null is null it's",
    "start": "2062359",
    "end": "2068419"
  },
  {
    "text": "nothing I don't have any implementation my implementation of the value this is a string serializer that uses utf-8",
    "start": "2068419",
    "end": "2075710"
  },
  {
    "text": "encoding I have a few encoding options so I can use utf-32 or ASCII or whatever",
    "start": "2075710",
    "end": "2086628"
  },
  {
    "text": "I've just defaulted to utf-8 and I have",
    "start": "2086629",
    "end": "2092358"
  },
  {
    "text": "a consumer which now needs to work off of a key value pair that the producer",
    "start": "2092359",
    "end": "2098780"
  },
  {
    "text": "used so I've got a null key and a string value and I have to implement that I",
    "start": "2098780",
    "end": "2105140"
  },
  {
    "text": "have to deserialize what the previous producer serialized so add a string d",
    "start": "2105140",
    "end": "2113000"
  },
  {
    "text": "serializer will take my binary data stored in Kafka deserialize it as a",
    "start": "2113000",
    "end": "2118580"
  },
  {
    "text": "string specifically utf-8 encoded string now I",
    "start": "2118580",
    "end": "2125109"
  },
  {
    "text": "implement an event so I have an event handling my consumer has the odd message",
    "start": "2125109",
    "end": "2131060"
  },
  {
    "text": "event in the event that I received a message then I'm going to perform this",
    "start": "2131060",
    "end": "2138200"
  },
  {
    "text": "function the first thing that I want to do is process that message so I have a function for processing",
    "start": "2138200",
    "end": "2144619"
  },
  {
    "text": "messages that's going to read the message it's going to convert it into",
    "start": "2144619",
    "end": "2149660"
  },
  {
    "text": "something I needed to convert it into and then I'm going to publish the",
    "start": "2149660",
    "end": "2154960"
  },
  {
    "text": "processed message on to my enriched flights topic every 10,000 records I am",
    "start": "2154960",
    "end": "2161599"
  },
  {
    "text": "going to write out that yes I have in fact published some messages so let me",
    "start": "2161599",
    "end": "2166910"
  },
  {
    "text": "kick that off right now and we'll see it publish a few messages then I'll keep",
    "start": "2166910",
    "end": "2173569"
  },
  {
    "text": "explaining what's going on in the code also notice the background is totally different color that was an important",
    "start": "2173569",
    "end": "2179300"
  },
  {
    "text": "part of our our main function okay well so every once in a while I",
    "start": "2179300",
    "end": "2189230"
  },
  {
    "text": "print a message so let's see what this process is supposed to do process",
    "start": "2189230",
    "end": "2194270"
  },
  {
    "text": "message I hide that is going to take in a string and my airport's I'm going to",
    "start": "2194270",
    "end": "2204970"
  },
  {
    "text": "call a function build flight taking of that message in airports so let's check",
    "start": "2204970",
    "end": "2210290"
  },
  {
    "text": "that out a raw flight message looks a",
    "start": "2210290",
    "end": "2216950"
  },
  {
    "text": "bit like this so we've got some data that says that on it looks like January 3rd of 2008 a flight took off from",
    "start": "2216950",
    "end": "2224240"
  },
  {
    "text": "Dulles in Washington DC and it landed in Tampa Florida I would like to have it be",
    "start": "2224240",
    "end": "2231380"
  },
  {
    "text": "a little bit more human understandable than this so let's split out the message",
    "start": "2231380",
    "end": "2236930"
  },
  {
    "text": "I'm going to split based off of commas it is an appropriately comma separated",
    "start": "2236930",
    "end": "2242060"
  },
  {
    "text": "values list I'm going to get the origin Airport which is the 17th element of",
    "start": "2242060",
    "end": "2247460"
  },
  {
    "text": "that array and the destinations is the 18th element of the array my flight will",
    "start": "2247460",
    "end": "2254119"
  },
  {
    "text": "say okay do we have an arrival delay which is this guy right here turns out",
    "start": "2254119",
    "end": "2262490"
  },
  {
    "text": "that there's an arrival delay of negative 14 minutes they arrive 15 minutes early which is great it's not",
    "start": "2262490",
    "end": "2268010"
  },
  {
    "text": "that common so we have some arrival to life",
    "start": "2268010",
    "end": "2274660"
  },
  {
    "text": "otherwise if we if this was n/a then we would make it a zero I've defined my",
    "start": "2275520",
    "end": "2282210"
  },
  {
    "text": "origin destination airports and my destination state comes from this guy so",
    "start": "2282210",
    "end": "2290180"
  },
  {
    "text": "I mentioned the airport code TPA well",
    "start": "2290180",
    "end": "2295710"
  },
  {
    "text": "I'm going to go look for the item that matches TPA I'm gonna go look for the airport matching TPA and pick up the",
    "start": "2295710",
    "end": "2303150"
  },
  {
    "text": "state which is Florida and return that flight so that was build flight then I",
    "start": "2303150",
    "end": "2310950"
  },
  {
    "text": "serialized that flight and I return it and eventually we take the message and we produce it so just like before I'm",
    "start": "2310950",
    "end": "2317970"
  },
  {
    "text": "producing to a topic I've got some text and I don't care what the output looks like I don't care if I get a message",
    "start": "2317970",
    "end": "2323850"
  },
  {
    "text": "back later on that says it failed to insert this record in a real application you probably do care but even then I",
    "start": "2323850",
    "end": "2330420"
  },
  {
    "text": "would still write errors somewhere else I wouldn't have my producers waiting for",
    "start": "2330420",
    "end": "2335460"
  },
  {
    "text": "results to come back and you know we can see that they're processing it's it's taking its sweet time but it's doing",
    "start": "2335460",
    "end": "2342330"
  },
  {
    "text": "what 10,000 records 20,000 records a second so that's not too bad so we've",
    "start": "2342330",
    "end": "2351810"
  },
  {
    "text": "pulled some data we've hit sequel server and enriched this data and we're writing",
    "start": "2351810",
    "end": "2358200"
  },
  {
    "text": "it out as JSON I'm gonna kill this application now I did 3.3 million in",
    "start": "2358200",
    "end": "2366030"
  },
  {
    "text": "roughly three minutes so a million a minute again that's not awful for one laptop running on one machine and if I",
    "start": "2366030",
    "end": "2378960"
  },
  {
    "text": "take a quick look at the enriched flights topic this is the full version",
    "start": "2378960",
    "end": "2385050"
  },
  {
    "text": "so just like Julia Child I have the the version that I can pull right out of the",
    "start": "2385050",
    "end": "2390210"
  },
  {
    "text": "oven that has seven million records and I can take a quick look at some of the data so we can start at the top and what",
    "start": "2390210",
    "end": "2398340"
  },
  {
    "text": "we have is a set of output messages that look like this that there was a 34",
    "start": "2398340",
    "end": "2403710"
  },
  {
    "text": "minute arrival delay going from Indianapolis to Baltimore Maryland and that was one of",
    "start": "2403710",
    "end": "2409600"
  },
  {
    "text": "our flights so this is the stuff that I care about we see the partitions and offsets so because I'm arbitrarily",
    "start": "2409600",
    "end": "2417460"
  },
  {
    "text": "assigning partition I don't have it defined in a particular order but each",
    "start": "2417460",
    "end": "2425140"
  },
  {
    "text": "partition will have its own offset so we see you know offsets for partition 2",
    "start": "2425140",
    "end": "2432670"
  },
  {
    "text": "here's 1 through 9 we saw offset 0 up above so we've got our data we've pulled",
    "start": "2432670",
    "end": "2442840"
  },
  {
    "text": "the sequel query we cashed that data beforehand otherwise I was gonna make seven million database requests and that",
    "start": "2442840",
    "end": "2449080"
  },
  {
    "text": "would turn this from 20,000 records per second 20,000 records per second down to",
    "start": "2449080",
    "end": "2461140"
  },
  {
    "text": "a couple hundred per second so we want",
    "start": "2461140",
    "end": "2467290"
  },
  {
    "text": "to consume this data you know we've enriched some data we now have some details it's all nice and easy",
    "start": "2467290",
    "end": "2474250"
  },
  {
    "text": "JSON serialized information I can take it and now solve the questions that I'm",
    "start": "2474250",
    "end": "2480820"
  },
  {
    "text": "intended to solve at the beginning of this talk so we're going to read the",
    "start": "2480820",
    "end": "2486910"
  },
  {
    "text": "data periodically I'm going to write it to sequel server so that I can perform other processing as well here's my",
    "start": "2486910",
    "end": "2494680"
  },
  {
    "text": "consumer so let's set this as a startup project over here in sequel I have a",
    "start": "2494680",
    "end": "2502300"
  },
  {
    "text": "table that is called delay by state and if I run this I have no data in here I'm",
    "start": "2502300",
    "end": "2510570"
  },
  {
    "text": "going to once again connect a sequel server and execute a stored procedure",
    "start": "2510570",
    "end": "2516450"
  },
  {
    "text": "because although I am using an ORM I am still a database person at heart and",
    "start": "2516450",
    "end": "2522250"
  },
  {
    "text": "thus you got a call my stored procedure so we're going to execute that procedure",
    "start": "2522250",
    "end": "2527680"
  },
  {
    "text": "and every once in a while I'm going to post an update saying that okay we've",
    "start": "2527680",
    "end": "2533350"
  },
  {
    "text": "we've done some work so totally different color this time so let's pull",
    "start": "2533350",
    "end": "2544270"
  },
  {
    "text": "down go to the main method so main function dark cyan is the official color",
    "start": "2544270",
    "end": "2551140"
  },
  {
    "text": "there I have I have a dictionary of flight aggregates what I'm doing here is",
    "start": "2551140",
    "end": "2556870"
  },
  {
    "text": "I'm this is really by state some flight details let's see what those details are",
    "start": "2556870",
    "end": "2563880"
  },
  {
    "text": "those details are the total number of flights the number of delayed flights and the total arrival delay notice that",
    "start": "2563880",
    "end": "2571090"
  },
  {
    "text": "those are all summable values so well",
    "start": "2571090",
    "end": "2578710"
  },
  {
    "text": "might as well as pop back down to main and have my configuration settings yep",
    "start": "2578710",
    "end": "2587980"
  },
  {
    "text": "we're processing stuff's going so we're connecting to our same Kafka brokers",
    "start": "2587980",
    "end": "2594370"
  },
  {
    "text": "once again my new consumer group is airplane consumer and I'm going to",
    "start": "2594370",
    "end": "2602850"
  },
  {
    "text": "connect to the enriched flights topic the one that I pulled out of the oven Julia Child style I don't produce",
    "start": "2602850",
    "end": "2611080"
  },
  {
    "text": "anything this time so I don't need a producer I just need my consumer that will deserialize utf-8 encoded data once",
    "start": "2611080",
    "end": "2620470"
  },
  {
    "text": "again because I'm consuming I'm handling the on message so as a message gets",
    "start": "2620470",
    "end": "2625660"
  },
  {
    "text": "added I'm able to process it processing takes the message value and my",
    "start": "2625660",
    "end": "2632770"
  },
  {
    "text": "dictionary of aggregates and please don't tell the f-sharp people that created a mutable dictionary in an after",
    "start": "2632770",
    "end": "2638770"
  },
  {
    "text": "application I still love you guys even if you won't love me after this so we've",
    "start": "2638770",
    "end": "2646360"
  },
  {
    "text": "got our string and we got our flight aggregates I'm going to deserialize the message into a type of flight and call",
    "start": "2646360",
    "end": "2653980"
  },
  {
    "text": "that lowercase flight so type of flight just explains what our data looks like",
    "start": "2653980",
    "end": "2660610"
  },
  {
    "text": "we've got an arrival delay in origin a destination and the state the destination state the JSON convert DC",
    "start": "2660610",
    "end": "2669370"
  },
  {
    "text": "realized that was just Newton soft JSON then do we have a destination state in",
    "start": "2669370",
    "end": "2679330"
  },
  {
    "text": "our flight aggregates dictionary if we do that I'm going to need to do",
    "start": "2679330",
    "end": "2689290"
  },
  {
    "text": "something with this I'm going to get the current results if we do not I'm going",
    "start": "2689290",
    "end": "2695800"
  },
  {
    "text": "to create a new dictionary element for",
    "start": "2695800",
    "end": "2701680"
  },
  {
    "text": "this state so that's my current state basically I'm getting this the state",
    "start": "2701680",
    "end": "2706930"
  },
  {
    "text": "that I'm in and I'm going to increment total number of flights determine",
    "start": "2706930",
    "end": "2713110"
  },
  {
    "text": "whether the arrival delay is greater than zero if it is that I'll increment number of delayed flights again if",
    "start": "2713110",
    "end": "2719050"
  },
  {
    "text": "arrival delay is greater than zero I'll set the total arrival delay and put that",
    "start": "2719050",
    "end": "2724270"
  },
  {
    "text": "into the dictionary so I have my data",
    "start": "2724270",
    "end": "2733240"
  },
  {
    "text": "that I've that I'm pulling and every time I I pull that message I'm going to",
    "start": "2733240",
    "end": "2739020"
  },
  {
    "text": "process every once in a while I'm going to write out a message that I have I've",
    "start": "2739020",
    "end": "2745840"
  },
  {
    "text": "read in a certain number then in my loop",
    "start": "2745840",
    "end": "2752170"
  },
  {
    "text": "I will write my messages occasionally to",
    "start": "2752170",
    "end": "2759250"
  },
  {
    "text": "sequel server so i will write every 500,000 records to the sequel server",
    "start": "2759250",
    "end": "2766560"
  },
  {
    "text": "using the write delays function so write delays generates a new implementation of",
    "start": "2766560",
    "end": "2773980"
  },
  {
    "text": "my update delays by state stored procedure I create a new table valued parameter which is of type delay by",
    "start": "2773980",
    "end": "2783040"
  },
  {
    "text": "state type so this is actually a a table valued parameter that I've created has",
    "start": "2783040",
    "end": "2790780"
  },
  {
    "text": "our destination state number of flights number of delayed flights and arrival delay so I come down and say all right",
    "start": "2790780",
    "end": "2799630"
  },
  {
    "text": "well as we go through I can add the new values of total number",
    "start": "2799630",
    "end": "2805660"
  },
  {
    "text": "flights number delayed flights in total arrival delay and execute that over in",
    "start": "2805660",
    "end": "2812700"
  },
  {
    "text": "sequel server I can pop over to my stored procedure call and we can see the",
    "start": "2812700",
    "end": "2826119"
  },
  {
    "text": "table valued parameter that I've specified and you know we already saw what those elements work I have set this",
    "start": "2826119",
    "end": "2833589"
  },
  {
    "text": "thing serializable because I don't want to processes to update the table at the same time I'm going to take my data join",
    "start": "2833589",
    "end": "2844539"
  },
  {
    "text": "it to delay by state if there's already a record in there and set these values",
    "start": "2844539",
    "end": "2851829"
  },
  {
    "text": "by sum by adding the value that comes in to whatever is already there so I can",
    "start": "2851829",
    "end": "2858220"
  },
  {
    "text": "have multiple consumers reading this data updating this procedure it's serializable so only one can do it at a",
    "start": "2858220",
    "end": "2864970"
  },
  {
    "text": "time and if you're missing a state then you know you can insert these states where the destination state is null so",
    "start": "2864970",
    "end": "2873400"
  },
  {
    "text": "I've got data that's that's streaming in and I've turned this actually it's done",
    "start": "2873400",
    "end": "2881559"
  },
  {
    "text": "streaming data so I can finish things up but I've got this multi consumer process",
    "start": "2881559",
    "end": "2888609"
  },
  {
    "text": "that then integrates with something that is not multi consumer something that I'm",
    "start": "2888609",
    "end": "2895900"
  },
  {
    "text": "purposefully making single consumer and that pattern can can help you take a",
    "start": "2895900",
    "end": "2904680"
  },
  {
    "text": "process that you've already got in place that you're expecting to work in a particular way and fit in this",
    "start": "2904680",
    "end": "2912250"
  },
  {
    "text": "distributed system let's see so I can",
    "start": "2912250",
    "end": "2918970"
  },
  {
    "text": "read a lot and I can take that data feed",
    "start": "2918970",
    "end": "2924130"
  },
  {
    "text": "it into power bi and say okay so the",
    "start": "2924130",
    "end": "2929890"
  },
  {
    "text": "state with the highest average delay that is assuming there is a delay how",
    "start": "2929890",
    "end": "2936490"
  },
  {
    "text": "long will you be sitting there is New Jersey Newark Airport is awful New York",
    "start": "2936490",
    "end": "2942340"
  },
  {
    "text": "surprisingly is not second because JFK and LaGuardia are also awful percent of",
    "start": "2942340",
    "end": "2949870"
  },
  {
    "text": "delayed flights you know we can we can see just for just for the sake of schadenfreude ah only 3500 flights come",
    "start": "2949870",
    "end": "2961150"
  },
  {
    "text": "in to the Virgin Islands but half of them that are delayed so if you fly to the US Virgin Islands expect a delay",
    "start": "2961150",
    "end": "2967660"
  },
  {
    "text": "Puerto Rico is next followed by New Jersey don't fly to New Jersey that's that's the story I'm telling you all",
    "start": "2967660",
    "end": "2976510"
  },
  {
    "text": "right so let me pop back to the slides and talk a little bit about performance",
    "start": "2976510",
    "end": "2982240"
  },
  {
    "text": "in the last 10 minutes basic tips the first thing is maximize your network",
    "start": "2982240",
    "end": "2988840"
  },
  {
    "text": "bandwidth you may have tens of millions of messages that you want to push",
    "start": "2988840",
    "end": "2994510"
  },
  {
    "text": "through but if you're trying to push them through on a on a like 100 megabit connection those messages have better be",
    "start": "2994510",
    "end": "3001560"
  },
  {
    "text": "really small otherwise it'll take a while your fiber channel if you've got it like a 16 gig or 32 gig fiber channel",
    "start": "3001560",
    "end": "3007680"
  },
  {
    "text": "you're gonna be pushing a lot more messages just by having that additional bandwidth available you can compress",
    "start": "3007680",
    "end": "3013620"
  },
  {
    "text": "data especially if you're talking about relatively larger amounts of data like you're talking kilobytes if you're",
    "start": "3013620",
    "end": "3021150"
  },
  {
    "text": "pushing megabytes of data per message that might be doing it wrong so I'm",
    "start": "3021150",
    "end": "3026880"
  },
  {
    "text": "talking more of bytes or kilobytes if you're wanting to push through a lot of",
    "start": "3026880",
    "end": "3034110"
  },
  {
    "text": "messages and there are fairly large messages compressing them on the producer side and pushing through a",
    "start": "3034110",
    "end": "3039210"
  },
  {
    "text": "binary stream will perhaps be faster because it'll help you minimize the",
    "start": "3039210",
    "end": "3044940"
  },
  {
    "text": "message size you can also buffer messages I ended up not really buffering",
    "start": "3044940",
    "end": "3050550"
  },
  {
    "text": "messages but yeah you can create a blocking collection wait for a set of",
    "start": "3050550",
    "end": "3055710"
  },
  {
    "text": "messages to come and then process them at once instead what I was doing was just streaming the messages as soon as I",
    "start": "3055710",
    "end": "3062100"
  },
  {
    "text": "got it right as soon as I got it right it interestingly that was not the",
    "start": "3062100",
    "end": "3067380"
  },
  {
    "text": "behavior that was happening over on the Kafka server so let me pop back to the producer",
    "start": "3067380",
    "end": "3073140"
  },
  {
    "text": "code so even though I wrote the code to say publish as soon as you get this message I've got a couple of parameters",
    "start": "3073140",
    "end": "3083910"
  },
  {
    "text": "here batch num messages and Q buffering max milliseconds those two are going to",
    "start": "3083910",
    "end": "3090930"
  },
  {
    "text": "tell how long is my server willing to wait until or excuse me how long is the",
    "start": "3090930",
    "end": "3096990"
  },
  {
    "text": "Kafka library that's installed for this producer willing to wait until it says",
    "start": "3096990",
    "end": "3102539"
  },
  {
    "text": "okay I've got enough messages let me ship them off it will wait for fifty thousand messages or for three",
    "start": "3102539",
    "end": "3108690"
  },
  {
    "text": "hundred milliseconds whichever comes first so I can configure that I could",
    "start": "3108690",
    "end": "3114390"
  },
  {
    "text": "set the queue down to one and say literally every message every message is",
    "start": "3114390",
    "end": "3120269"
  },
  {
    "text": "sacred send it as fast as possible but in a more realistic scenario I want to",
    "start": "3120269",
    "end": "3125640"
  },
  {
    "text": "buffer those I want to send them as a bigger block because normally I am more",
    "start": "3125640",
    "end": "3130829"
  },
  {
    "text": "interested in throughput rather than latency if you're interested in optimizing for latency you want to send",
    "start": "3130829",
    "end": "3138089"
  },
  {
    "text": "those messages as soon as you receive them you want to get them out as fast as possible that will reduce the number of",
    "start": "3138089",
    "end": "3144630"
  },
  {
    "text": "milliseconds that it takes for a message to land here but it will reduce how many",
    "start": "3144630",
    "end": "3150660"
  },
  {
    "text": "messages you can send per second by contrast if your weight build up a bunch",
    "start": "3150660",
    "end": "3157349"
  },
  {
    "text": "of messages pass them all through at once you can take advantage of say not",
    "start": "3157349",
    "end": "3163410"
  },
  {
    "text": "having mostly empty Network packets so reducing the number of network packets that you have to send in order to get a",
    "start": "3163410",
    "end": "3170849"
  },
  {
    "text": "certain number of messages across you can bulk process these and get them",
    "start": "3170849",
    "end": "3177269"
  },
  {
    "text": "get more into Kafka in a certain period of time like a minute but the delay from",
    "start": "3177269",
    "end": "3185670"
  },
  {
    "text": "message into Kafka may be higher probably will be higher so on the",
    "start": "3185670",
    "end": "3193319"
  },
  {
    "text": "producer side we already saw batch no messages queue buffering max milliseconds on the consumer side we",
    "start": "3193319",
    "end": "3200309"
  },
  {
    "text": "have some waiting as well that we can do fetch wait max milliseconds fetch",
    "start": "3200309",
    "end": "3206880"
  },
  {
    "text": "min bites so again how many milliseconds am I willing to wait for a message a set",
    "start": "3206880",
    "end": "3213809"
  },
  {
    "text": "of messages to come through and I've got them down here I'm saying I'm willing to",
    "start": "3213809",
    "end": "3221970"
  },
  {
    "text": "wait up to 5 seconds for a big block of messages because I can process them all",
    "start": "3221970",
    "end": "3227279"
  },
  {
    "text": "at the same time I'm also willing to wait for at least 4,000 bytes so these",
    "start": "3227279",
    "end": "3234180"
  },
  {
    "text": "are configurable you can bump these numbers up and down depending on whether",
    "start": "3234180",
    "end": "3240180"
  },
  {
    "text": "you need more throughput or more latency but it is the trade-off that you're going to make if you don't want to make",
    "start": "3240180",
    "end": "3248039"
  },
  {
    "text": "that trade-off you can't add more hardware and adding more hardware may",
    "start": "3248039",
    "end": "3253289"
  },
  {
    "text": "solve your problem because this is a horizontally distributed system so if",
    "start": "3253289",
    "end": "3258299"
  },
  {
    "text": "you're seeing an issue like IO latency or high CPU on your broker's add some",
    "start": "3258299",
    "end": "3264569"
  },
  {
    "text": "new brokers they'll be able to take partitions from the topics and own them",
    "start": "3264569",
    "end": "3270750"
  },
  {
    "text": "and then you now have more Hardware solving the same problem so those",
    "start": "3270750",
    "end": "3276089"
  },
  {
    "text": "brokers are going to have probably less CPU less i/o requirements given the same",
    "start": "3276089",
    "end": "3281970"
  },
  {
    "text": "throughput if you're falling behind if",
    "start": "3281970",
    "end": "3287519"
  },
  {
    "text": "in other words you know we go back to this Kafka tool and for airplane",
    "start": "3287519",
    "end": "3293730"
  },
  {
    "text": "enricher we have this concept of lag that is here's the end of the topic how",
    "start": "3293730",
    "end": "3300960"
  },
  {
    "text": "far along are we what's the difference between those two so if you see this lag",
    "start": "3300960",
    "end": "3306839"
  },
  {
    "text": "value increasing over time you might not have enough consumers to handle all of",
    "start": "3306839",
    "end": "3312240"
  },
  {
    "text": "your load so you can add more consumers to a group it's as simple as you know I",
    "start": "3312240",
    "end": "3318539"
  },
  {
    "text": "have that code I can put that code on another server and run it as well and it'll pick up as long as I have",
    "start": "3318539",
    "end": "3324450"
  },
  {
    "text": "available partitions that new instance will pick up some some partition or",
    "start": "3324450",
    "end": "3330269"
  },
  {
    "text": "partitions and start processing",
    "start": "3330269",
    "end": "3334759"
  },
  {
    "text": "so wrapping things up Pachi Kafka's a powerful message broker I love this",
    "start": "3336960",
    "end": "3342010"
  },
  {
    "text": "thing and this is getting you started with it now there is another level past",
    "start": "3342010",
    "end": "3348970"
  },
  {
    "text": "this which is Kafka streams Kafka streams is a streaming application or",
    "start": "3348970",
    "end": "3356350"
  },
  {
    "text": "streaming process that will sit on top of the Kafka stack as messages go in you",
    "start": "3356350",
    "end": "3362440"
  },
  {
    "text": "can perform operations using K SQL which is Kafka's implementation of sequel so I",
    "start": "3362440",
    "end": "3368470"
  },
  {
    "text": "can watch over a window and look for what has happened over the past minute what has happened over the past five",
    "start": "3368470",
    "end": "3374920"
  },
  {
    "text": "minutes have I found any events that look like this it's a little bit beyond what I wanted to talk about today but",
    "start": "3374920",
    "end": "3381640"
  },
  {
    "text": "that is really cool and I'm hopeful you're interested in learning a bit more",
    "start": "3381640",
    "end": "3387850"
  },
  {
    "text": "about that if you want to grab slides notes demos links to additional resources they're all up at CS more info",
    "start": "3387850",
    "end": "3395650"
  },
  {
    "text": "slash on slash Kafka if you have any questions at all please feel free to reach out I'll be here for the rest of",
    "start": "3395650",
    "end": "3400900"
  },
  {
    "text": "the conference and otherwise hit me up email Twitter however so thank you everybody",
    "start": "3400900",
    "end": "3407090"
  },
  {
    "text": "[Applause]",
    "start": "3407090",
    "end": "3412749"
  }
]
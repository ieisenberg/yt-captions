[
  {
    "start": "0",
    "end": "135000"
  },
  {
    "text": "right I think we'll start actually because even though few people coming in",
    "start": "10040",
    "end": "15629"
  },
  {
    "text": "I think we can start so I everybody I'm David I'm America text ad Proofpoint",
    "start": "15629",
    "end": "21660"
  },
  {
    "text": "which is a security company we build a bunch of security products for email and",
    "start": "21660",
    "end": "26670"
  },
  {
    "text": "cloud so this talk came about basically",
    "start": "26670",
    "end": "32460"
  },
  {
    "text": "when I joined proof point we're a year and a half ago it was a little while after we bought a start-up which",
    "start": "32460",
    "end": "39350"
  },
  {
    "text": "developed a product which turned into the core technology of our cloud",
    "start": "39350",
    "end": "44429"
  },
  {
    "text": "security product and like most startup products it was built mainly for features and getting customers and stuff",
    "start": "44429",
    "end": "51149"
  },
  {
    "text": "like that and you know UX came second and things like scalability and stability a very distant third right",
    "start": "51149",
    "end": "57089"
  },
  {
    "text": "which is fine for a stereo product I'm not complaining about that but then after improvement acquired it that was",
    "start": "57089",
    "end": "62819"
  },
  {
    "text": "pretty much my main purpose in life to take this and make it scalable and make",
    "start": "62819",
    "end": "67890"
  },
  {
    "text": "it stable and not have to wake up every night because something was broken in production which happens quite a bit at",
    "start": "67890",
    "end": "73619"
  },
  {
    "text": "the start oh by the way disclaimer for any proof point customers who might watch this this is all in the past",
    "start": "73619",
    "end": "79110"
  },
  {
    "text": "anything that as I say about the product is not true anymore it's perfect now okay good just in case anyone was",
    "start": "79110",
    "end": "85890"
  },
  {
    "text": "wondering anyway so he was really bad to start right because it was in the main",
    "start": "85890",
    "end": "90990"
  },
  {
    "text": "problem with the product cause it's not only was it not stable we wouldn't know when it was unstable",
    "start": "90990",
    "end": "97259"
  },
  {
    "text": "right the worst is when your boss's boss calls your boss in the middle of a sales",
    "start": "97259",
    "end": "102450"
  },
  {
    "text": "presentation to ask if the product is working and that's how you discover there's a production issue right if that",
    "start": "102450",
    "end": "108509"
  },
  {
    "text": "happens that pretty much pretty much means that your product lacks observability so and that brings us to",
    "start": "108509",
    "end": "114719"
  },
  {
    "text": "observability which is the topic of the talk which is basically the property of a system that tells you how much you can",
    "start": "114719",
    "end": "121500"
  },
  {
    "text": "know about the internal state of the system it's any given moment and the purpose of having observability usually",
    "start": "121500",
    "end": "127890"
  },
  {
    "text": "it's not binary it's not either you have it or you don't have it right it's a large scale and the purpose is usually",
    "start": "127890",
    "end": "133110"
  },
  {
    "text": "to answer questions which fall into one of two broad categories right is anything wrong right now and if the",
    "start": "133110",
    "end": "140610"
  },
  {
    "text": "answer is yeah there are a bunch of other questions which basically sum up to exactly what is wrong and you know where is it and",
    "start": "140610",
    "end": "147200"
  },
  {
    "text": "why it's happening right and so if you can answer those questions for any part of your system at any given moment you",
    "start": "147200",
    "end": "153840"
  },
  {
    "text": "have excellent observability congratulations you can go so let me let me do a quick survey right who here",
    "start": "153840",
    "end": "160890"
  },
  {
    "text": "works on something that is related to production right has a product which is in production pretty much everybody perfect we're in",
    "start": "160890",
    "end": "166980"
  },
  {
    "text": "the right place can you tell right now if you have like 30 seconds on your phone your laptop can you tell right now if the stuff you have in production is",
    "start": "166980",
    "end": "174180"
  },
  {
    "text": "100% working who can tell that right now if I give you 10 minutes if you have",
    "start": "174180",
    "end": "181140"
  },
  {
    "text": "like an hour on your laptop to you know look at that button stuff who can say within one hour if everything is working",
    "start": "181140",
    "end": "186569"
  },
  {
    "text": "correctly this is very disturbing it's like half the people the other half who have stuff in production aren't aren't",
    "start": "186569",
    "end": "194220"
  },
  {
    "text": "confident and this is true and that generally means either at your you don't wanna do it that's fine or you don't",
    "start": "194220",
    "end": "201450"
  },
  {
    "text": "have exactly the right tools to give you those answers right and this is what observability is all about you build up",
    "start": "201450",
    "end": "207389"
  },
  {
    "text": "the observability of your system to be able to actually answer these questions very easily and efficiently hopefully",
    "start": "207389",
    "end": "213480"
  },
  {
    "text": "then you connect it to some kind of alerts and then you don't have to look you'll get notified this if something breaks and it can go and find it and fix",
    "start": "213480",
    "end": "219900"
  },
  {
    "text": "it right and so for it for my experience",
    "start": "219900",
    "end": "224910"
  },
  {
    "text": "right and it's not just the last company I work for but for every company I've ever worked in observability is not",
    "start": "224910",
    "end": "230549"
  },
  {
    "text": "something people invest you initially know it's very trendy right now there's a lot of you know meetups and stuff I",
    "start": "230549",
    "end": "237150"
  },
  {
    "text": "talked about observability it didn't used to be trendy like most things and in tech things come like waves of hype",
    "start": "237150",
    "end": "243030"
  },
  {
    "text": "like five or six years ago everything was micro services and Microsoft's upper trendy and we broke all our Mon and",
    "start": "243030",
    "end": "248730"
  },
  {
    "text": "listened to micro services and then we discovered there's a whole lot of micro services how do we deploy them in production and so containers became very",
    "start": "248730",
    "end": "255569"
  },
  {
    "text": "trending hype and everything was about containers like three years ago and then we actually started putting containers into production and Euskara with holy",
    "start": "255569",
    "end": "261959"
  },
  {
    "text": "crap there's so many containers in production how do we know if it's actually working and so now we come to",
    "start": "261959",
    "end": "267180"
  },
  {
    "text": "this problem of okay well when you talk about observability because we have all the stuff we need to look at and actually figure out how if it's working",
    "start": "267180",
    "end": "273000"
  },
  {
    "text": "right and so I don't know what is gonna be next year but probably something to do with machine learning",
    "start": "273000",
    "end": "278640"
  },
  {
    "text": "and stuff or AI because you don't wanna actually go into the observable to yourself you want a robot to do it and",
    "start": "278640",
    "end": "286920"
  },
  {
    "text": "so generally when you go to these meetups and talk about durability you come up to a Venn diagram that looks",
    "start": "286920",
    "end": "293220"
  },
  {
    "start": "290000",
    "end": "602000"
  },
  {
    "text": "something like this that's very trendy and it's a way that which I don't like very much because generally you go to",
    "start": "293220",
    "end": "300320"
  },
  {
    "text": "read some observers observability blog or some meetup or something and there's",
    "start": "300320",
    "end": "305400"
  },
  {
    "text": "usually a guy from a vendor selling something and then they talk about logs and metrics and traces which are like",
    "start": "305400",
    "end": "310980"
  },
  {
    "text": "the three main technologies you use to gain observability into a system and",
    "start": "310980",
    "end": "316470"
  },
  {
    "text": "usually there's a logo of the vendor somewhere in one of these circles or maybe in the middle right if you go to an elastic search made up the circle is",
    "start": "316470",
    "end": "322200"
  },
  {
    "text": "gonna be really close together and there's a big elastic search logo in the middle and if you go to a different beat up like I don't know Jagr or Zipkin the",
    "start": "322200",
    "end": "329430"
  },
  {
    "text": "circle is gonna be far apart and their logo is gonna be in one of the circles because that's what they're trying to sell right and I think that's the wrong",
    "start": "329430",
    "end": "335040"
  },
  {
    "text": "way to think about it or maybe not the best way to think about it because these are not products is you buy right it's a",
    "start": "335040",
    "end": "342150"
  },
  {
    "text": "way of thinking about your system that you're building and a way of actually achieving certain goals like I want to",
    "start": "342150",
    "end": "348060"
  },
  {
    "text": "sleep at night in order to achieve that I need to be able to know that my system is stable in production and in order to",
    "start": "348060",
    "end": "353160"
  },
  {
    "text": "achieve that I need these following questions answered and these are a bunch of technologies which can help me answer",
    "start": "353160",
    "end": "358980"
  },
  {
    "text": "those questions or build this you know this way of looking at the system right and so it's a product's like if you have",
    "start": "358980",
    "end": "366360"
  },
  {
    "text": "log so you have metrics do you have good observability I don't know maybe depends what you do with them right also you can",
    "start": "366360",
    "end": "372660"
  },
  {
    "text": "achieve different things with different sets of technologies so let's do a quick survey again over the three things who",
    "start": "372660",
    "end": "379350"
  },
  {
    "text": "here works in the product which has centralized logging so whether it's a live elk or logs flung everybody yeah",
    "start": "379350",
    "end": "386460"
  },
  {
    "text": "almost everybody so that's what I'm expecting I'm gonna ask the same thing about metrics and traces in a second I'm",
    "start": "386460",
    "end": "391560"
  },
  {
    "text": "gonna make a guess about half the people are gonna answer yes to tracing and like 10% for sorry for metrics and like 10%",
    "start": "391560",
    "end": "398130"
  },
  {
    "text": "for tracing so who here has a system for collecting application performance metrics so I wanna say yeah let's let's",
    "start": "398130",
    "end": "405450"
  },
  {
    "text": "throw his hands more than half actually that's pretty nice I must talking about CPU by the way not like low-level system settings talking about",
    "start": "405450",
    "end": "411629"
  },
  {
    "text": "application metrics like how many transactions it processed or logical things that the application does right",
    "start": "411629",
    "end": "417479"
  },
  {
    "text": "so traces in this case before we answer that I don't mean traces like s trace or",
    "start": "417479",
    "end": "423090"
  },
  {
    "text": "no D trace which goes and looks at low-level system function calls in this case I'm talking about traces in like",
    "start": "423090",
    "end": "429840"
  },
  {
    "text": "the modern way which means distributed traces which is something I'm going to cover quite a bit in the remaining of",
    "start": "429840",
    "end": "437159"
  },
  {
    "text": "the talk where distribute traces allow you to look at a transaction that spans",
    "start": "437159",
    "end": "442319"
  },
  {
    "text": "your entire system so if you have a bunch of microservices you can look at a request which comes in from a Web API",
    "start": "442319",
    "end": "447770"
  },
  {
    "text": "through all the micro services find every services touched every database is called measure all the latencies and",
    "start": "447770",
    "end": "454199"
  },
  {
    "text": "stuff like that and pull all this data together and look at it as a whole like the whole transaction right so who here",
    "start": "454199",
    "end": "460020"
  },
  {
    "text": "has a system which does that in production so actually more than I",
    "start": "460020",
    "end": "465360"
  },
  {
    "text": "expect it's like 20% issue which is very good right and so having all these",
    "start": "465360",
    "end": "471150"
  },
  {
    "text": "things together allows you to build stuff which lets you actually look at the system and sleep better at night now",
    "start": "471150",
    "end": "476759"
  },
  {
    "text": "this list is obviously I don't like it because it's misses a bunch of stuff usually you won't hear mention stuff",
    "start": "476759",
    "end": "483060"
  },
  {
    "text": "like CI CD which is a huge component of the observer ability right you want to know when something that deploy to production because if you see a weird",
    "start": "483060",
    "end": "489960"
  },
  {
    "text": "spikes on a metrics graph and you and despite correlates with someone deploying a service that's a really",
    "start": "489960",
    "end": "495569"
  },
  {
    "text": "strong indicator and it doesn't talk about automation right so running automation scripts over your production",
    "start": "495569",
    "end": "501150"
  },
  {
    "text": "environment to detect stuff for example in our product we run an automation",
    "start": "501150",
    "end": "506370"
  },
  {
    "text": "service every five minutes which covers the main flows to the entire system and measuring stuff and figure out if",
    "start": "506370",
    "end": "512578"
  },
  {
    "text": "everything is actually okay and if it's not it goes and alerts people right and it doesn't talk about other things which",
    "start": "512579",
    "end": "518130"
  },
  {
    "text": "are also useful durability but for our purposes these three technologies cover like 80 or 90 percent of what you might",
    "start": "518130",
    "end": "525329"
  },
  {
    "text": "want to do in your system right and so again I want to talk about observability",
    "start": "525329",
    "end": "531209"
  },
  {
    "text": "in the sense of well use this product or use that product and it's gonna be all great it's not it's more of it's a",
    "start": "531209",
    "end": "536699"
  },
  {
    "text": "feature and it's a feature of a product which is customer centric right it's not",
    "start": "536699",
    "end": "542250"
  },
  {
    "text": "something you do in the backend where you collect metrics you know and engineers really love metrics and graphs that's not why you do it not just",
    "start": "542250",
    "end": "548790"
  },
  {
    "text": "because we love graphs right having good observability in a system means that you can actually provide the",
    "start": "548790",
    "end": "554850"
  },
  {
    "text": "service of customers paying for right it's a business level feature just the same as having a nice UX as a business",
    "start": "554850",
    "end": "561180"
  },
  {
    "text": "level feature we're actually doing whatever application logic you're up your system does it's a feature yourself",
    "start": "561180",
    "end": "566550"
  },
  {
    "text": "to the client and so observability is the same way right a lot of time if you have to sometimes go and justify why you",
    "start": "566550",
    "end": "572730"
  },
  {
    "text": "wanna invest in building all the stuff on the back end which is the customer in every C's and you have to say what will",
    "start": "572730",
    "end": "578400"
  },
  {
    "text": "they have to take time away from building features to put in you know logging and metrics and instrumented traces and stuff like that and the",
    "start": "578400",
    "end": "585180"
  },
  {
    "text": "actual ROI for that is do you want to keep selling the products to the customer and the customer to be happy",
    "start": "585180",
    "end": "590220"
  },
  {
    "text": "then we need to build this feature into our system which will let us actually provide a better service to the customer right so as I said you don't have to",
    "start": "590220",
    "end": "597060"
  },
  {
    "text": "have all of these three to build a system which has high observability for example our product for historical",
    "start": "597060",
    "end": "602610"
  },
  {
    "text": "reasons doesn't have used to be retracing is a separate technology right so for proof points Academy which is",
    "start": "602610",
    "end": "608700"
  },
  {
    "text": "what I'm working on we we achieve most of what we do with a bunch of metric",
    "start": "608700",
    "end": "615000"
  },
  {
    "text": "system would you use stat site and your phone and stuff and mostly logs right we use ALK",
    "start": "615000",
    "end": "621120"
  },
  {
    "text": "elasticsearch and we overloaded all the tracing functionality only distributed functionality on top of the logging in",
    "start": "621120",
    "end": "626970"
  },
  {
    "text": "structure which has a price but it's also very easy because it's something we had in place so I'll talk about about",
    "start": "626970",
    "end": "632520"
  },
  {
    "text": "how we can actually do that a little bit later and so you can pick and choose and and the different ways of recording data",
    "start": "632520",
    "end": "640710"
  },
  {
    "text": "about your system and looking at it and different insights you can get from it have different trade-offs there's",
    "start": "640710",
    "end": "647700"
  },
  {
    "text": "there's some things they're good at and there's some some price you have to pay for that right and so we don't just",
    "start": "647700",
    "end": "654540"
  },
  {
    "text": "measure stuff for fun right we don't go and collect CPU metrics or whatever transaction latency is because it's fun",
    "start": "654540",
    "end": "661020"
  },
  {
    "text": "to do that and we like to know this even though it is and we do we do it because we have the purpose in mind usually our",
    "start": "661020",
    "end": "667740"
  },
  {
    "text": "purpose is business oriented pretty much everything we do at work hopefully is somehow related to actually advancing",
    "start": "667740",
    "end": "673709"
  },
  {
    "text": "the business of selling the stuff right because that's what our pays our salary and so generally you",
    "start": "673709",
    "end": "681660"
  },
  {
    "start": "678000",
    "end": "874000"
  },
  {
    "text": "have some serve some sort of service level agreements you have with the customer it might be explicit where we",
    "start": "681660",
    "end": "687929"
  },
  {
    "text": "actually have a page which says you know we have this promise of this service level agreement well you know the",
    "start": "687929",
    "end": "693299"
  },
  {
    "text": "website is going to be up 99.9 percent of the time and the request latency is going to be X milliseconds and it might",
    "start": "693299",
    "end": "699660"
  },
  {
    "text": "be implicit where no one ever bothered to define it but you have certain expectations of the system of the way it",
    "start": "699660",
    "end": "704999"
  },
  {
    "text": "works right I expect my database to return queries in two seconds right I expect the webpage to load in less",
    "start": "704999",
    "end": "712230"
  },
  {
    "text": "than a minute hopefully right and so you might have implicit service level agreements with us with yourself or with",
    "start": "712230",
    "end": "717989"
  },
  {
    "text": "the product owners or with the customer whatever it is and once you have that and by the way I urge you to make it as",
    "start": "717989",
    "end": "723629"
  },
  {
    "text": "explicit as possible right because implicit expectations tend to be very surprising when they you discover",
    "start": "723629",
    "end": "729720"
  },
  {
    "text": "they're not actually working the way you expected and so once you define what your expectation is of the way the",
    "start": "729720",
    "end": "736259"
  },
  {
    "text": "system behaves right what defines it being healthy it's not just the server response obviously that's a prerequisite",
    "start": "736259",
    "end": "741869"
  },
  {
    "text": "for it being healthy but you have to define what it is that makes your system okay in order to be able to then find",
    "start": "741869",
    "end": "748829"
  },
  {
    "text": "out when it's not ok so once we have the service level agreements level kind of settled then we can define service level",
    "start": "748829",
    "end": "755970"
  },
  {
    "text": "objectives right so my objective is to have the server up warrior X service",
    "start": "755970",
    "end": "762929"
  },
  {
    "text": "respond 99 percent of all the time right which is like a few hours of downtime a",
    "start": "762929",
    "end": "768149"
  },
  {
    "text": "year or my objective is for the 95 50% latency of responses to be within X",
    "start": "768149",
    "end": "775230"
  },
  {
    "text": "milliseconds once we define the objective right and we have a set of these we can start tracking those and",
    "start": "775230",
    "end": "780720"
  },
  {
    "text": "recording them and that brings us to service level indicators where you can define something which looks at the",
    "start": "780720",
    "end": "785879"
  },
  {
    "text": "objective and says whether we're inside or outside of expectations for that objective we can now measure service",
    "start": "785879",
    "end": "792389"
  },
  {
    "text": "latency we can measure and to end latency in our distribution system and say does it fall within our objective",
    "start": "792389",
    "end": "797519"
  },
  {
    "text": "and if it's not then we can have a clear indication of something is broken this is this brings us to actually answering",
    "start": "797519",
    "end": "803309"
  },
  {
    "text": "the first set of questions about observer ability is something broken right now right broking doesn't have to",
    "start": "803309",
    "end": "808889"
  },
  {
    "text": "mean everything down right the more complex systems the more distributed systems you build the",
    "start": "808889",
    "end": "814380"
  },
  {
    "text": "more weird ways they have of being NACO not okay being broken like for example in our system it's a large data",
    "start": "814380",
    "end": "820380"
  },
  {
    "text": "processing platform we use Kafka extensively if we have like 80 micro services most of them send kefka",
    "start": "820380",
    "end": "826380"
  },
  {
    "text": "messages to each other at any given moment one or two of them can be down and it wouldn't actually have any",
    "start": "826380",
    "end": "832590"
  },
  {
    "text": "symptoms outside the system right the website would be up events would be flowing but the whole service could be",
    "start": "832590",
    "end": "837780"
  },
  {
    "text": "down and unless we actually have something that tells us about it we wouldn't know it just from looking at",
    "start": "837780",
    "end": "843600"
  },
  {
    "text": "symptoms right and so the more stuff you have in your system more services and databases the more ways it has to be",
    "start": "843600",
    "end": "850680"
  },
  {
    "text": "broken you know of being broken without you knowing about it right and so that's the way you find indicators hopefully to",
    "start": "850680",
    "end": "856710"
  },
  {
    "text": "cover all the weird cases where your system is not behaving the way it does now the thing about service level",
    "start": "856710",
    "end": "862830"
  },
  {
    "text": "indicators is if you have too many of them you get into this alert fatigue where too many things go wrong it's very",
    "start": "862830",
    "end": "869100"
  },
  {
    "text": "hard to calibrate so I'm going to show you a couple of examples of good and bad service level indicators yourself we'll",
    "start": "869100",
    "end": "874920"
  },
  {
    "start": "874000",
    "end": "1015000"
  },
  {
    "text": "start with a mixed case this is our service level dashboard it's a version 1.0 we're as always we have plans to",
    "start": "874920",
    "end": "883200"
  },
  {
    "text": "replace it everybody has plans to plans to replace anything they're unhappy with when that's going to happen I don't know",
    "start": "883200",
    "end": "888800"
  },
  {
    "text": "and so this is something we built when we're a much smaller company we had a couple of hundred customers not a couple",
    "start": "888800",
    "end": "895080"
  },
  {
    "text": "of thousand as we do right now there's a column you don't see with the actual names of the customers and so what this",
    "start": "895080",
    "end": "900660"
  },
  {
    "text": "does this by the way hangs on the wall on the monitor right outside where our product owners and the VP of engineering",
    "start": "900660",
    "end": "907680"
  },
  {
    "text": "said right this is a business level dashboard it tells our sales people and",
    "start": "907680",
    "end": "912960"
  },
  {
    "text": "customer support if stuff is broken because they're the ones who actually really really deeply care about this because they're the ones who get yelled",
    "start": "912960",
    "end": "919380"
  },
  {
    "text": "at by customers if something's not working and so there's a rotating list of customers on the column you can see",
    "start": "919380",
    "end": "925020"
  },
  {
    "text": "and for every other column is a specific feature specific flow in our system and whether it conforms to an expectation",
    "start": "925020",
    "end": "931200"
  },
  {
    "text": "right and so this the good things about this the indicators are very clear something is either red or green there's",
    "start": "931200",
    "end": "937590"
  },
  {
    "text": "no in-between right we'll look at bad examples there but here there's no ambiguity right if something is broken",
    "start": "937590",
    "end": "943119"
  },
  {
    "text": "you can clear a seat we also have an alert that goes out and if something flips the bad thing is there's too many",
    "start": "943119",
    "end": "949809"
  },
  {
    "text": "indicators there's a bunch of red ones over there and I took a screenshot when the system was not having a good day and",
    "start": "949809",
    "end": "956469"
  },
  {
    "text": "like half of those are real alerts and the other half are just missed calibrated thresholds where we need to",
    "start": "956469",
    "end": "962799"
  },
  {
    "text": "go and recalibrate them because they're actually okay I know because I checked they're okay but they're still showing red which is a",
    "start": "962799",
    "end": "969399"
  },
  {
    "text": "terrible thing right it makes it it lets you go into this state where you're okay",
    "start": "969399",
    "end": "975519"
  },
  {
    "text": "would stop being red you should never be okay with them being ready if it's red that needs to be addressed if it doesn't",
    "start": "975519",
    "end": "980679"
  },
  {
    "text": "need to be addressed it shouldn't be red right and so that's why I like I have mixed feelings but our internal",
    "start": "980679",
    "end": "986469"
  },
  {
    "text": "dashboards but the good things are it's very very unambiguous it's very clear",
    "start": "986469",
    "end": "993279"
  },
  {
    "text": "and that's what you want with service level indicators they need to tell you something is broken it doesn't tell you what's broken right it kind of gives you",
    "start": "993279",
    "end": "999459"
  },
  {
    "text": "gives you a pointer right if a column that says whatever login event is red then I know where I need to go and",
    "start": "999459",
    "end": "1005519"
  },
  {
    "text": "investigate this is not an investigation tool this is an alert and like first response tool that's what you want in",
    "start": "1005519",
    "end": "1011669"
  },
  {
    "text": "service level indicators there's a good example here who here heard of Reddit",
    "start": "1011669",
    "end": "1018409"
  },
  {
    "start": "1015000",
    "end": "1090000"
  },
  {
    "text": "seriously there's like five people who have heard of reddit thank you very much",
    "start": "1018409",
    "end": "1023429"
  },
  {
    "text": "let's you know wake up I know it's after lunch everyone's tired you can go home very soon I promise it's O'Reilly's right big site has a",
    "start": "1023429",
    "end": "1031199"
  },
  {
    "text": "bunch of users this is their public status page by the way we also use",
    "start": "1031199",
    "end": "1036209"
  },
  {
    "text": "Status page it's a very cool tool very cheap as that happens and this is a very",
    "start": "1036209",
    "end": "1041369"
  },
  {
    "text": "good example of service level indicators right it has very high level stuff you can't really see it probably but it has",
    "start": "1041369",
    "end": "1046619"
  },
  {
    "text": "stuff like web application mobile application comment field a few others and like a course level number of",
    "start": "1046619",
    "end": "1054119"
  },
  {
    "text": "requests and the history going back 80 days or 90 days all right so it's a very good service level indicator it tells",
    "start": "1054119",
    "end": "1060450"
  },
  {
    "text": "you if something is broken in a big way right I'm sure they have a bunch of interim dashboard as well but if you",
    "start": "1060450",
    "end": "1066749"
  },
  {
    "text": "want just to I know if something is okay or not okay you go here and you can see it well my status page also lets you",
    "start": "1066749",
    "end": "1072059"
  },
  {
    "text": "subscribe to alerts and stuff like that right and so this is the kind of stuff you want for your primary triage right this is",
    "start": "1072059",
    "end": "1079770"
  },
  {
    "text": "what you want to tell you is my system okay or not and it's not okay then you go to all the other things we're going",
    "start": "1079770",
    "end": "1085800"
  },
  {
    "text": "to talk about which tells you you know what exactly isn't okay and the first thing which most of you actually have as",
    "start": "1085800",
    "end": "1091920"
  },
  {
    "start": "1090000",
    "end": "1396000"
  },
  {
    "text": "we discovered earlier it's metrics everybody has at least system level metrics right CPU disk all that stuff",
    "start": "1091920",
    "end": "1097470"
  },
  {
    "text": "networks but that's like that's the boring stuff that's you're gonna have of course you're gonna have that right if",
    "start": "1097470",
    "end": "1102480"
  },
  {
    "text": "you don't well you should but usually you want more application level metrics",
    "start": "1102480",
    "end": "1107970"
  },
  {
    "text": "because there are things you can discover by the application by measuring something very straightforward which you",
    "start": "1107970",
    "end": "1113490"
  },
  {
    "text": "can't from system level metrics things like what the latency of database call is right they're very good tools to",
    "start": "1113490",
    "end": "1119880"
  },
  {
    "text": "actually record metrics the benefit of metrics is they're very cheap to maintain right because metrics are usually time",
    "start": "1119880",
    "end": "1126360"
  },
  {
    "text": "compressed and aggregated you can store a whole lot of them right you don't the way you store metrics by the way in case",
    "start": "1126360",
    "end": "1132300"
  },
  {
    "text": "you're wondering is you don't store every data point usually applications send metrics to a metrics collector agent which runs on the machine or",
    "start": "1132300",
    "end": "1139260"
  },
  {
    "text": "somewhere else in the networks and it can it collects a bunch of data points over a certain time compresses them or",
    "start": "1139260",
    "end": "1144630"
  },
  {
    "text": "within a certain time unit let's say into a second or into a minute and then stores the aggregated result for that",
    "start": "1144630",
    "end": "1150750"
  },
  {
    "text": "time unit which means metrics are very compressed they're very cheapest or you can start a whole bunch of them with a",
    "start": "1150750",
    "end": "1155820"
  },
  {
    "text": "long history going back it's great so we can have you know thousands of metrics at last count our system has over a",
    "start": "1155820",
    "end": "1162270"
  },
  {
    "text": "hundred thousand unique metrics when I say unique I mean like the server name times the you know the customer ID times",
    "start": "1162270",
    "end": "1168090"
  },
  {
    "text": "or whatever there's a hundred thousand unique metrics Java alone has like how is responsible for like half of them",
    "start": "1168090",
    "end": "1173790"
  },
  {
    "text": "javelin has a bunch of metrics right and so that's very good is there time-based you can go and you can zoom in up to the",
    "start": "1173790",
    "end": "1180450"
  },
  {
    "text": "level of granularity right if you aggregate by the minute you can zoom in further than one minute and that brings",
    "start": "1180450",
    "end": "1186240"
  },
  {
    "text": "us to the weak point of metrics which is you lose granularity because you don't store every data point there are certain",
    "start": "1186240",
    "end": "1193410"
  },
  {
    "text": "things you have no way of discovering through metrics so I have an example let's say you're tracking pay service",
    "start": "1193410",
    "end": "1201930"
  },
  {
    "text": "response times you call a rest service and you measure the response times and you store as response time as a metric",
    "start": "1201930",
    "end": "1207320"
  },
  {
    "text": "and you go look at a service and you see that's the response times on average are very high but",
    "start": "1207320",
    "end": "1213270"
  },
  {
    "text": "you're going you look at the service and you say okay well the average number of requests didn't change something's weird",
    "start": "1213270",
    "end": "1218730"
  },
  {
    "text": "is going on right it's an actual production use case we had from a different company I worked for and we",
    "start": "1218730",
    "end": "1224430"
  },
  {
    "text": "puzzled about that for a long time because all the metrics looked fine except for latency and we couldn't",
    "start": "1224430",
    "end": "1229950"
  },
  {
    "text": "figure out why delay was high until we switched the metric granularity and started recording latencies at the",
    "start": "1229950",
    "end": "1236730"
  },
  {
    "text": "millisecond level and then we looked at a specific second with millisecond data points we saw that for most seconds it",
    "start": "1236730",
    "end": "1243420"
  },
  {
    "text": "was fine but a few every now and then you'd see an empty second with no requests and a whole bunch of requests",
    "start": "1243420",
    "end": "1248940"
  },
  {
    "text": "at the end of the second which is very weird and we looked at the garbage collection and saw that yeah there were seconds where garbage collection was",
    "start": "1248940",
    "end": "1254760"
  },
  {
    "text": "taking place and so all the requests would block and get pushed to the end of the second and so instead of returning",
    "start": "1254760",
    "end": "1260250"
  },
  {
    "text": "in you know a couple of milliseconds they would all wait and return all at once at the end of the second which is a",
    "start": "1260250",
    "end": "1265650"
  },
  {
    "text": "very weird degenerate use case and you couldn't possibly discover that if you aggregate metrics by the second or by",
    "start": "1265650",
    "end": "1270690"
  },
  {
    "text": "the minute you can still discover it if we had thought of going to look at the garbage collection metrics which we",
    "start": "1270690",
    "end": "1276870"
  },
  {
    "text": "didn't and so we wasted a bunch of time right usually you have a bunch of different symptoms and you can get to",
    "start": "1276870",
    "end": "1281970"
  },
  {
    "text": "the answer from different directions but that that's like the main weak point the other main weak point and something",
    "start": "1281970",
    "end": "1286980"
  },
  {
    "text": "that happens in our system for example a lot and I'm sure for you as well engineers like clean graphs right if you",
    "start": "1286980",
    "end": "1292620"
  },
  {
    "text": "have let's say a hundred copies of a service running hundred instances you don't want to see a hundred lines on the",
    "start": "1292620",
    "end": "1298830"
  },
  {
    "text": "graph it looks cluttered so what do you do you have urge them right you have okay well let's say you have a load of a",
    "start": "1298830",
    "end": "1305010"
  },
  {
    "text": "hundred services let's have the average load it's probably okay through persons reality right not really doesn't all",
    "start": "1305010",
    "end": "1311370"
  },
  {
    "text": "right it's very be very careful when you average stuff out or you apply any kind of aggregation metric to a bunch of",
    "start": "1311370",
    "end": "1316710"
  },
  {
    "text": "systems because it tends to hide granularity your real example from a month ago are elasticsearch cluster in",
    "start": "1316710",
    "end": "1324480"
  },
  {
    "text": "production was being weird queries were returning very slowly we want to look at",
    "start": "1324480",
    "end": "1329760"
  },
  {
    "text": "the load it looks fine thirty percent less than 30 percent CPU load it took us",
    "start": "1329760",
    "end": "1335670"
  },
  {
    "text": "several hours until thousands thought okay well let's do B rate let's remove the average on the load and look at the",
    "start": "1335670",
    "end": "1341700"
  },
  {
    "text": "actual load for every service and we discovered that one out of four hundred nodes was at a hundred percent CPU because some puppet process",
    "start": "1341700",
    "end": "1349109"
  },
  {
    "text": "was doing stuff with CPU and so that one node was slowing everybody down but it was one out of four hundred the the",
    "start": "1349109",
    "end": "1355619"
  },
  {
    "text": "latency average I didn't move right and so if you look at metrics and you want to aggregate them to look clean don't",
    "start": "1355619",
    "end": "1361769"
  },
  {
    "text": "use something like an average if it's gonna hide so much data or at least be aware that yes you have to sometimes the",
    "start": "1361769",
    "end": "1367409"
  },
  {
    "text": "aggregator layer your metrics to figure out what what's going on internally right and so good good ways of actually",
    "start": "1367409",
    "end": "1373739"
  },
  {
    "text": "doing that would be looking at maximum like or looking at the top X 95 and",
    "start": "1373739",
    "end": "1379259"
  },
  {
    "text": "fifth 99th percentile those usually show you the outliers and that's really what you want for most metrics you don't",
    "start": "1379259",
    "end": "1385320"
  },
  {
    "text": "really care about the average also left people don't do average of averages if you have a metric which reports is the",
    "start": "1385320",
    "end": "1390839"
  },
  {
    "text": "average of something then you average over that it becomes completely meaningless right so here's an example",
    "start": "1390839",
    "end": "1396719"
  },
  {
    "start": "1396000",
    "end": "1556000"
  },
  {
    "text": "right I don't expect you to see it don't hurt to read the graphs it's as incomprehensible to me as it should be",
    "start": "1396719",
    "end": "1403559"
  },
  {
    "text": "to you I took a random snapshot of our production dashboard a random one of",
    "start": "1403559",
    "end": "1409649"
  },
  {
    "text": "like 15 production diary boards this actually shows a production problem can you tell if it is I can't",
    "start": "1409649",
    "end": "1415619"
  },
  {
    "text": "I honestly I'm looking at I have no idea the the squiggles look okay to me and that's the problem with metrics they're",
    "start": "1415619",
    "end": "1422009"
  },
  {
    "text": "not service level indicators that's supposed to be their investigation tools and you look at stuff and you try to",
    "start": "1422009",
    "end": "1427469"
  },
  {
    "text": "figure out what this system represents right as it happens in this case this represents a problem which happens for",
    "start": "1427469",
    "end": "1434369"
  },
  {
    "text": "services away from the dashboard at a different bunch of services which are in a different dashboard but the symptoms",
    "start": "1434369",
    "end": "1439950"
  },
  {
    "text": "are here if you look at the top left graph which is very spiky it shows the",
    "start": "1439950",
    "end": "1445109"
  },
  {
    "text": "amount L the story it shows the amount of events that our rule engine processes",
    "start": "1445109",
    "end": "1451409"
  },
  {
    "text": "which does business heuristics right and it should be flat because the number it because the amount of events coming into the system is constant the reason that",
    "start": "1451409",
    "end": "1458519"
  },
  {
    "text": "it's spiky is very weird and has nothing to do with the rule engine because if you look look at the next graph over",
    "start": "1458519",
    "end": "1464369"
  },
  {
    "text": "which is the CPU load CPU looks fine it's not that the rule engine is busy the reason it's spiky is because",
    "start": "1464369",
    "end": "1470129"
  },
  {
    "text": "something upstream from it is sending spikes of events instead of a steady flow events and we went to investigate",
    "start": "1470129",
    "end": "1478049"
  },
  {
    "text": "that and eventually we got to our elasticsearch cluster which had weird",
    "start": "1478049",
    "end": "1483210"
  },
  {
    "text": "load spikes which we didn't have an alert for and we didn't know about it has probably been going on for at least",
    "start": "1483210",
    "end": "1488610"
  },
  {
    "text": "a day and we started tracing that and eventually we found that there was a Python script running on a desktop",
    "start": "1488610",
    "end": "1494160"
  },
  {
    "text": "somewhere that was running a very heavy query exactly every song so a minute",
    "start": "1494160",
    "end": "1499590"
  },
  {
    "text": "which is why the spikes are sore so steady and so that would choke our actual production last history cluster",
    "start": "1499590",
    "end": "1505710"
  },
  {
    "text": "and so everything else that was touching it would slow down for a while develop a lag and then catch up anyway to",
    "start": "1505710",
    "end": "1512309"
  },
  {
    "text": "summarize this is why our security researchers no longer have access to the production elasticsearch because they",
    "start": "1512309",
    "end": "1519900"
  },
  {
    "text": "like Python and write anyway so yeah so metrics are not a good tool so what is a",
    "start": "1519900",
    "end": "1526440"
  },
  {
    "text": "good tool what we talked about earlier right if we had at this point we didn't have a good sli for end-to-end latency",
    "start": "1526440",
    "end": "1534330"
  },
  {
    "text": "if we had a good service level indicator that says the whole total system latency from end to end is higher than usual we",
    "start": "1534330",
    "end": "1541080"
  },
  {
    "text": "would have caught this less in less than a few minutes right would have call it immediately we didn't and so we spent",
    "start": "1541080",
    "end": "1546780"
  },
  {
    "text": "the whole day trying to figure out what went wrong and why is the latency up and stuff like that right and we might have",
    "start": "1546780",
    "end": "1552030"
  },
  {
    "text": "not noticed it because we notice it for an unrelated reason so metrics are a",
    "start": "1552030",
    "end": "1557280"
  },
  {
    "start": "1556000",
    "end": "1966000"
  },
  {
    "text": "good indicator tool they let you investigate stuff logs logs are actually I'm sure everyone understands logs it's",
    "start": "1557280",
    "end": "1562890"
  },
  {
    "text": "one of the oldest technologies you know when when the first prime well developer came up to a keyboard with a pair of",
    "start": "1562890",
    "end": "1569760"
  },
  {
    "text": "rocks and bangs out hello world and then compiled it and it didn't work the next two lines in history were printf before",
    "start": "1569760",
    "end": "1577140"
  },
  {
    "text": "hello and printf after hello to figure out where the hello world broke and that's how logging was invented and so",
    "start": "1577140",
    "end": "1584730"
  },
  {
    "text": "we all understand logs we usually we dump stuff into logs to tell us what the",
    "start": "1584730",
    "end": "1590370"
  },
  {
    "text": "internal state of the system is at that point the benefit of logs is they're",
    "start": "1590370",
    "end": "1595530"
  },
  {
    "text": "very granular right that's the opposite of metrics logs can be extremely granular because you can log a specific action you can attach a bunch of context",
    "start": "1595530",
    "end": "1602940"
  },
  {
    "text": "to it what happened you know the IDS of the users or whatever it was trying to do stack traces anything you want the",
    "start": "1602940",
    "end": "1610530"
  },
  {
    "text": "downside of that of course is very expensive because you have to store all this data I have to index it in order to actually be useful and search",
    "start": "1610530",
    "end": "1616350"
  },
  {
    "text": "it right and in the disability system logs very quickly become just a massive",
    "start": "1616350",
    "end": "1623249"
  },
  {
    "text": "pile of data which you can't reconcile as an example let's say we have six we have 60 or 280 ish micro-services that a",
    "start": "1623249",
    "end": "1630240"
  },
  {
    "text": "typical transaction will touch something comes in and even comes into the system it takes some route through a bunch of",
    "start": "1630240",
    "end": "1635909"
  },
  {
    "text": "services through a bunch of caf-co topics such as much of databases each one of those diligently write stuff to a",
    "start": "1635909",
    "end": "1641909"
  },
  {
    "text": "log can I take all this log data and then figure out if a particular transaction was okay and it registered and the",
    "start": "1641909",
    "end": "1648929"
  },
  {
    "text": "destination or not maybe if I take all this data and I spend enough time looking through all the logs I can",
    "start": "1648929",
    "end": "1654840"
  },
  {
    "text": "reconstruct in my head what should have happened and if it actually didn't happen but luggage don't tell you stuff",
    "start": "1654840",
    "end": "1660690"
  },
  {
    "text": "across services right they don't actually give you the transaction of",
    "start": "1660690",
    "end": "1665879"
  },
  {
    "text": "what happened or the context of what happens to a particular flow through the system they do give you a very detailed",
    "start": "1665879",
    "end": "1671070"
  },
  {
    "text": "view of what goes on in a particular service unfortunately it's often times it's too different to too granular or",
    "start": "1671070",
    "end": "1678749"
  },
  {
    "text": "too good over the other level right because I know if it's for everybody but",
    "start": "1678749",
    "end": "1683879"
  },
  {
    "text": "in our case we tends to overlook things very much we look a lot of data too much for my taste it comes from the early",
    "start": "1683879",
    "end": "1691830"
  },
  {
    "text": "stages of our system where we didn't have good observer ability and the only tool we really had to figure out what",
    "start": "1691830",
    "end": "1697200"
  },
  {
    "text": "was going wrong is logging and so developers who can think of very like",
    "start": "1697200",
    "end": "1702600"
  },
  {
    "text": "usually engineers have very good imaginations we can think of many what-ifs and many weird scenarios and",
    "start": "1702600",
    "end": "1707669"
  },
  {
    "text": "then we try to add log messages to cover those scenarios so we had a lot of log messages from every render system now",
    "start": "1707669",
    "end": "1713940"
  },
  {
    "text": "when you're processing billions of transactions per day in each one touches let's say 50 services each one logs let's say 20 messages it",
    "start": "1713940",
    "end": "1721590"
  },
  {
    "text": "quickly gets into the trillions of logs per day right and so at one point we were running an L cluster for logs which",
    "start": "1721590",
    "end": "1729149"
  },
  {
    "text": "was bigger than our actual elasticsearch cluster for production data because we were just logging so much and so this is",
    "start": "1729149",
    "end": "1736440"
  },
  {
    "text": "like the danger of just relying on logs for everything you do have to offload",
    "start": "1736440",
    "end": "1741600"
  },
  {
    "text": "some of this work either to metrics or the stuff we're going to talk about a bit later which is deserve a transaction which kind of fold",
    "start": "1741600",
    "end": "1747990"
  },
  {
    "text": "in the middle between this the granularity of vlogs and the cheapness or inexpensive ility of metrics but for",
    "start": "1747990",
    "end": "1756900"
  },
  {
    "text": "logs I don't wanna spend too much time well because it's I hope everyone's pretty well familiar and since to",
    "start": "1756900",
    "end": "1762750"
  },
  {
    "text": "technology that's the main problem right you don't have the context and it's just",
    "start": "1762750",
    "end": "1768420"
  },
  {
    "text": "very expensive to maintain because it's so expensive to maintain usually you have to compromise on data retention right so right now we can for example",
    "start": "1768420",
    "end": "1776490"
  },
  {
    "text": "store two days of debug messages back and a month of errors back right and if",
    "start": "1776490",
    "end": "1782490"
  },
  {
    "text": "you wanted to store more than that where they have to look less or pay a lot more money to store a lot more logs right and",
    "start": "1782490",
    "end": "1789870"
  },
  {
    "text": "even with compression on technologies it's still the most expensive way to do it [Music]",
    "start": "1789870",
    "end": "1795950"
  },
  {
    "text": "so as I said the the reconciling logs across these transactions that's",
    "start": "1795950",
    "end": "1801420"
  },
  {
    "text": "something we faced very early on one of the most common problems in attribute system is you initiate a transaction at",
    "start": "1801420",
    "end": "1808110"
  },
  {
    "text": "one time one at the end of the system and it doesn't come out the other end and then you're left wondering which",
    "start": "1808110",
    "end": "1813810"
  },
  {
    "text": "service failed in the middle right let's say you have whatever in IOT system that a signal comes in some service that",
    "start": "1813810",
    "end": "1820890"
  },
  {
    "text": "takes that puts it in a kind of any message queue let's say casco or Kinesis some other service takes it tries to",
    "start": "1820890",
    "end": "1826620"
  },
  {
    "text": "enrich it with data from database puts it in a second queue and something third and fourth and so on and then one of the",
    "start": "1826620",
    "end": "1832710"
  },
  {
    "text": "services fails can you cash that right if that service fails in 1% of cases and",
    "start": "1832710",
    "end": "1838380"
  },
  {
    "text": "you don't know about it there's no way for you to know that X transactions come in but X minus 10% come out the other",
    "start": "1838380",
    "end": "1843750"
  },
  {
    "text": "side or 1% the smaller the percent the hardware is to catch and so one of the",
    "start": "1843750",
    "end": "1849090"
  },
  {
    "text": "ways to deal with that is to actually track the transaction from end to end",
    "start": "1849090",
    "end": "1854940"
  },
  {
    "text": "this kind of brings us towards you should be tracking and tracing territory we still don't have for example in our",
    "start": "1854940",
    "end": "1861270"
  },
  {
    "text": "case a separate technology to do that we overloaded this functionality on top of",
    "start": "1861270",
    "end": "1866310"
  },
  {
    "text": "logs what we do is for every message which comes into the system we generate a new",
    "start": "1866310",
    "end": "1872700"
  },
  {
    "text": "transaction ID and put it on the message itself right because we didn't actually invest in any fence technologies to do",
    "start": "1872700",
    "end": "1878010"
  },
  {
    "text": "that we attach the transaction the actual data object and so every service which touches the object and",
    "start": "1878010",
    "end": "1883620"
  },
  {
    "text": "attaches the transaction ID and putting users that in the log so then we can go and we can actually connect all the",
    "start": "1883620",
    "end": "1889679"
  },
  {
    "text": "different log messages to a specific transaction right once you do that you're half way towards this really",
    "start": "1889679",
    "end": "1896190"
  },
  {
    "text": "tracing right now you actually have the ability to take a single flow through your system figure out all the things it",
    "start": "1896190",
    "end": "1903030"
  },
  {
    "text": "touched you still can't connect it to metrics but at least you can find anything that touched it along the way any service attacks that and so with",
    "start": "1903030",
    "end": "1909390"
  },
  {
    "text": "those around a lot of tooling around it again because we didn't have time to spend using an actual tool which by the",
    "start": "1909390",
    "end": "1915720"
  },
  {
    "text": "way is is usually bad idea and there are good and bad reasons why you would do it mostly for time pressure why you",
    "start": "1915720",
    "end": "1921870"
  },
  {
    "text": "wouldn't invest in the proper technology and build it yourself it's always going to be a worse version if you ability realize yourself unless you're like",
    "start": "1921870",
    "end": "1928590"
  },
  {
    "text": "Google or LinkedIn or someone in which case good job and so what we did is we",
    "start": "1928590",
    "end": "1935130"
  },
  {
    "text": "took all of this stuff which was actually in our logs and in the data object in the database itself and then",
    "start": "1935130",
    "end": "1941909"
  },
  {
    "text": "we built tooling around pulling out all the stuff related to our transaction and trying to figure out what happens to it",
    "start": "1941909",
    "end": "1948600"
  },
  {
    "text": "and we actually built a lot of functionality around it which is now very hard to migrate to a proper tool so",
    "start": "1948600",
    "end": "1954659"
  },
  {
    "text": "that's the bit full of actually building your own tracing system a poor-man's version if you will instead of actually",
    "start": "1954659",
    "end": "1960150"
  },
  {
    "text": "using like a big boy tool but still that's something we did and then it was",
    "start": "1960150",
    "end": "1966120"
  },
  {
    "start": "1966000",
    "end": "2032000"
  },
  {
    "text": "pretty successful all I've to do is like I said put a context in the log and then reconstruct the tree like the flow we",
    "start": "1966120",
    "end": "1971850"
  },
  {
    "text": "actually had a bunch of visualization written around it you could take an automation run which is our automation",
    "start": "1971850",
    "end": "1978480"
  },
  {
    "text": "framework which runs every five minutes as I said take a specific run find everything it touched figure out if it's",
    "start": "1978480",
    "end": "1983880"
  },
  {
    "text": "working yeah one of our customer success people or a salesperson can go and look",
    "start": "1983880",
    "end": "1989039"
  },
  {
    "text": "at what happens with a particular customer if they're gonna go to a sales demo they can quickly pull up the state",
    "start": "1989039",
    "end": "1994110"
  },
  {
    "text": "of a customer to see if it's missing transactions or anything wrong so it actually provides actual business level",
    "start": "1994110",
    "end": "1999630"
  },
  {
    "text": "value to people because they can now go and see if a specific thing is working or not all right it's especially",
    "start": "1999630",
    "end": "2005330"
  },
  {
    "text": "important if you're about to demo this feature anyone know that feature is working which by the way it's always is just saying for future customers",
    "start": "2005330",
    "end": "2013940"
  },
  {
    "text": "and so this is like our bachelors version of it and so let's talk about what the actual real world of production",
    "start": "2013940",
    "end": "2020419"
  },
  {
    "text": "use case would be where you want to use a real tool not invent one yourself",
    "start": "2020419",
    "end": "2026950"
  },
  {
    "text": "that brings us to actual distributed tracing which is a set of technologies to track transactions across the system",
    "start": "2026950",
    "end": "2034159"
  },
  {
    "start": "2032000",
    "end": "2419000"
  },
  {
    "text": "so let's define a couple of terms here write a transaction is not a specific term it's not like a database",
    "start": "2034159",
    "end": "2039980"
  },
  {
    "text": "transaction it's more of a single flow of execution across the entire system if",
    "start": "2039980",
    "end": "2045740"
  },
  {
    "text": "you're in the micro services environment for example and you have rest services a transaction would be starting from let's",
    "start": "2045740",
    "end": "2051800"
  },
  {
    "text": "say the client or the browser calling a service any service it touched any database is it touched all the way back",
    "start": "2051800",
    "end": "2057530"
  },
  {
    "text": "to the client and synchronously right or if you know if you're in an asynchronous system some event comes in and gets",
    "start": "2057530",
    "end": "2064398"
  },
  {
    "text": "piped to a bunch of other services it might split and events might become know two or three messages",
    "start": "2064399",
    "end": "2069888"
  },
  {
    "text": "it might get stored and then batch later so it's kind of hard to define exactly what the connection is but pretty much",
    "start": "2069889",
    "end": "2075888"
  },
  {
    "text": "anything logically related to that initial event that will be part of our transaction right",
    "start": "2075889",
    "end": "2081440"
  },
  {
    "text": "and so if you want to chunk this transaction up and so we define what's called a span a span this term by the",
    "start": "2081440",
    "end": "2087950"
  },
  {
    "text": "way comes from Google Google are pioneers in the area of distribute tracing long time ago they built a",
    "start": "2087950",
    "end": "2094520"
  },
  {
    "text": "system called dapper and published a white paper about dapper which is their distribute transaction system transfer",
    "start": "2094520",
    "end": "2101000"
  },
  {
    "text": "tracing system which is fascinating by the way I encourage everybody to read Google's dapper paper if you're bored",
    "start": "2101000",
    "end": "2108260"
  },
  {
    "text": "but if you're not and you want to do something useful to your work there's there are two books Google published called the e-book and the sre handbook",
    "start": "2108260",
    "end": "2116200"
  },
  {
    "text": "which are not just for sector liability engineers I think every engineer should read the Google SR ebook it's",
    "start": "2116200",
    "end": "2121550"
  },
  {
    "text": "fascinating it has a lot information about the way Google engineers think about reliability and visitor",
    "start": "2121550",
    "end": "2128060"
  },
  {
    "text": "observability of systems I think anyone who writes any kind of code which ends up in production should read this book",
    "start": "2128060",
    "end": "2134420"
  },
  {
    "text": "and you know figure out what it is that you know one of the largest companies in the world actually looks and thinks",
    "start": "2134420",
    "end": "2140450"
  },
  {
    "text": "about it and so they define defined what's called span and a bunch of technologies which were modeled on",
    "start": "2140450",
    "end": "2145849"
  },
  {
    "text": "dapper adopted this terminal you and we'll talk about those in just a bit and so I stan is a logical unit of",
    "start": "2145849",
    "end": "2152900"
  },
  {
    "text": "work which makes sense to measure so for example a database called would be a good span right it goes from one process",
    "start": "2152900",
    "end": "2159110"
  },
  {
    "text": "your application to another process the database and then back and that's a useful thing to measure or call between",
    "start": "2159110",
    "end": "2165830"
  },
  {
    "text": "two services you have service a calling service B right so we'll initiate the span in service a it spans the the RPC",
    "start": "2165830",
    "end": "2172640"
  },
  {
    "text": "the HTTP call or the Caston message and then it ends at the entrance to service",
    "start": "2172640",
    "end": "2177680"
  },
  {
    "text": "B and so we can measure this span and have useful information about it things like latency when it started when it",
    "start": "2177680",
    "end": "2183560"
  },
  {
    "text": "ended you know anything any kind of context we have on it right and in the",
    "start": "2183560",
    "end": "2190970"
  },
  {
    "text": "transaction in tracing we have two levels of communication we have the",
    "start": "2190970",
    "end": "2196460"
  },
  {
    "text": "inbound message which is usually a small context object which has a transaction",
    "start": "2196460",
    "end": "2201830"
  },
  {
    "text": "ID maybe a little bit in front of information about the origin of the span the previous service start and end date",
    "start": "2201830",
    "end": "2208310"
  },
  {
    "text": "things like that but a very small amount of data because it travels with the message along the system its inbound",
    "start": "2208310",
    "end": "2213619"
  },
  {
    "text": "right and you don't want to overload too much data on the inline data propagation",
    "start": "2213619",
    "end": "2218750"
  },
  {
    "text": "and then every service that gets the message looks at the context and then emits a much larger if object out of",
    "start": "2218750",
    "end": "2225140"
  },
  {
    "text": "bound out-of-band right so some similar to logs write in that way disturb addressing is very similar to logs where",
    "start": "2225140",
    "end": "2232040"
  },
  {
    "text": "you have instrumentation in your application in certain places to admit outside this process a large log object",
    "start": "2232040",
    "end": "2238700"
  },
  {
    "text": "which somebody else collects and does something with we'll talk about exactly who collects it and what they do with it",
    "start": "2238700",
    "end": "2244090"
  },
  {
    "text": "and basically once you get all of these transaction objects and you put them",
    "start": "2244090",
    "end": "2249560"
  },
  {
    "text": "together you can have a good idea of what happens with the transaction throughout the system right you can reconstruct it in the same",
    "start": "2249560",
    "end": "2256369"
  },
  {
    "text": "way we could would logs except here it's much more tightly coupled to the actual execution flow and",
    "start": "2256369",
    "end": "2262609"
  },
  {
    "text": "you can figure out how long each span took you can actually get some useful data out of all the spans looks like",
    "start": "2262609",
    "end": "2269420"
  },
  {
    "text": "this right it doesn't matter if it's HTTP or Kafka or whatever usually you",
    "start": "2269420",
    "end": "2274970"
  },
  {
    "text": "want to put the metadata that travels the the transaction ID in the context",
    "start": "2274970",
    "end": "2281450"
  },
  {
    "text": "on the metadata of the channels for example with HTTP you would put this in the headers because that's what headers",
    "start": "2281450",
    "end": "2286460"
  },
  {
    "text": "are for ERP see also has metadata something like Kafka just out of",
    "start": "2286460",
    "end": "2292040"
  },
  {
    "text": "curiosity who uses Kafka for something there's like three people that's very poor so anyway so Kafka or any our",
    "start": "2292040",
    "end": "2300190"
  },
  {
    "text": "rabbitmq any kind of community college it usually has a metadata you can attach to the message so you don't wanna put it",
    "start": "2300190",
    "end": "2305329"
  },
  {
    "text": "in the message itself and then you take the transaction context put it on the object and it moves from service to",
    "start": "2305329",
    "end": "2310460"
  },
  {
    "text": "service every service sees it it touches the method and the metadata from the message emits a whole transaction span",
    "start": "2310460",
    "end": "2318670"
  },
  {
    "text": "and so that's a pretty hard problem to solve because instrumenting a whole",
    "start": "2318670",
    "end": "2324140"
  },
  {
    "text": "bunch of places in your application is a lot of effort right we'll talk about ways to make it easier in just a bit",
    "start": "2324140",
    "end": "2329990"
  },
  {
    "text": "generally think about it this way tracing the same way you do but logs or metrics right it's the job of the",
    "start": "2329990",
    "end": "2336460"
  },
  {
    "text": "developer to instrument the application in the in the places where it makes",
    "start": "2336460",
    "end": "2341960"
  },
  {
    "text": "sense to emit this information right so wood logs usually have some kind of framework and infrastructure for logging",
    "start": "2341960",
    "end": "2347329"
  },
  {
    "text": "and then whenever it makes sense in the code you call you log this like you have an exception you put it to a log you",
    "start": "2347329",
    "end": "2353359"
  },
  {
    "text": "have whatever some interesting thing that happens you put in a log same thing with metrics or the application does something interesting which is worth",
    "start": "2353359",
    "end": "2358910"
  },
  {
    "text": "measuring or counting you call the metric system and and it emits that metric into the collector usually you",
    "start": "2358910",
    "end": "2366109"
  },
  {
    "text": "don't do it manually a lot of time you build some kind of infrastructure which abstracts away all this stuff right so",
    "start": "2366109",
    "end": "2371510"
  },
  {
    "text": "you don't measure every HTTP call right you have some kind of wrapper for HTTP clients which automatically logs average",
    "start": "2371510",
    "end": "2377420"
  },
  {
    "text": "typical and it sends a metric you don't have a whatever database driver and then",
    "start": "2377420",
    "end": "2383150"
  },
  {
    "text": "you manually do stuff you wrap the database driver and instrument inside of it and then it gets much better coverage",
    "start": "2383150",
    "end": "2388490"
  },
  {
    "text": "because every service which uses your database wrapper will now automatically trub trace and measure and log and send",
    "start": "2388490",
    "end": "2395630"
  },
  {
    "text": "metrics and all that stuff right so you save yourself all the trouble of actually going in instrumenting code line by line manually all right the same",
    "start": "2395630",
    "end": "2402710"
  },
  {
    "text": "thing we're tracing right one of the problems is there are so many frameworks we'll talk about them in a bit there's",
    "start": "2402710",
    "end": "2408619"
  },
  {
    "text": "so many ways to do discrete racing you want a common way of extra-inning codes",
    "start": "2408619",
    "end": "2414349"
  },
  {
    "text": "and our tools which Liars do that I'll talk about them in a bit so back to the trace",
    "start": "2414349",
    "end": "2419510"
  },
  {
    "start": "2419000",
    "end": "2522000"
  },
  {
    "text": "let's look at the actual transaction trace in tracing environments if we look",
    "start": "2419510",
    "end": "2424700"
  },
  {
    "text": "at the time line of a graph right over transaction which goes you know in this case right left your keys will be left",
    "start": "2424700",
    "end": "2433250"
  },
  {
    "text": "to right so let's imagine we have two services service a and service B we send",
    "start": "2433250",
    "end": "2439430"
  },
  {
    "text": "a web request service a which is synchronous and does a bunch of a work goes to the database and then service a",
    "start": "2439430",
    "end": "2445220"
  },
  {
    "text": "sends a katka message or an asynchronous message to service B right so if we map that as the transaction",
    "start": "2445220",
    "end": "2451250"
  },
  {
    "text": "which spans would have the first panel which is service a getting the request it's synchronous and so all the others",
    "start": "2451250",
    "end": "2457640"
  },
  {
    "text": "fans which belong to it are within that first span all right they happen inside of it there are children of that family",
    "start": "2457640",
    "end": "2463940"
  },
  {
    "text": "this is a relation would you find for the purpose of this we're tracing and so it may be inside it calls a function",
    "start": "2463940",
    "end": "2470060"
  },
  {
    "text": "let's say you let's call it span B that span goes and calls the database that will be C get the results goes cool and",
    "start": "2470060",
    "end": "2477260"
  },
  {
    "text": "calls us another service that's ID and then that's all that stuff all when all of this is finished then the first",
    "start": "2477260",
    "end": "2483950"
  },
  {
    "text": "services span a is closed that's that's what we measure right so the whole transaction here is both services and",
    "start": "2483950",
    "end": "2490250"
  },
  {
    "text": "then the service a sends a message to servers in this message is not part of the first time right you can see that",
    "start": "2490250",
    "end": "2495680"
  },
  {
    "text": "it's not part of a span F in this case the gray one e follows from span a right",
    "start": "2495680",
    "end": "2502100"
  },
  {
    "text": "and so it's not a child of a they aren't dependent on each other they're siblings one follows the other",
    "start": "2502100",
    "end": "2507890"
  },
  {
    "text": "now if we go we and we represent this on a graph we'll see some kind of waterfall graph graph similar to how you would",
    "start": "2507890",
    "end": "2513680"
  },
  {
    "text": "look at let's say in a browser and then relate the latency graph something like that and so once we have this we can now",
    "start": "2513680",
    "end": "2520400"
  },
  {
    "text": "take this and answer very interesting questions so some of the questions we",
    "start": "2520400",
    "end": "2525980"
  },
  {
    "start": "2522000",
    "end": "2709000"
  },
  {
    "text": "can answer with this really tracing our business-related pretty much all questions or business",
    "start": "2525980",
    "end": "2531080"
  },
  {
    "text": "right is ultimately right because we're running a business and we want to customers to get best money but some are",
    "start": "2531080",
    "end": "2537080"
  },
  {
    "text": "directly related for example there there are questions which are very hard to answer with logs and metrics and",
    "start": "2537080",
    "end": "2542690"
  },
  {
    "text": "automation and all the other tools we have durability such as are we currently within our SLA to the customer",
    "start": "2542690",
    "end": "2548600"
  },
  {
    "text": "if we define the SLA in our case for example as being entrant latency because our product what it does is it looks at",
    "start": "2548600",
    "end": "2555230"
  },
  {
    "text": "cloudy events and tries to decide if someone has hacked the customers account and the quicker we can cite that and",
    "start": "2555230",
    "end": "2561380"
  },
  {
    "text": "block it the better value we provide the customer one of our primary service level indicators is processing latency",
    "start": "2561380",
    "end": "2568610"
  },
  {
    "text": "right from the moment we get the event the login event let's say until the moment we kill the customer at the login",
    "start": "2568610",
    "end": "2573680"
  },
  {
    "text": "session that's how long the attacker has in the system to do damage right and so the less there is the better service we",
    "start": "2573680",
    "end": "2580040"
  },
  {
    "text": "provide and that's one of our primary allies but for something like a website or web application your SLI would be",
    "start": "2580040",
    "end": "2586220"
  },
  {
    "text": "load time or average load time or your mobile app they're talking to the",
    "start": "2586220",
    "end": "2591710"
  },
  {
    "text": "backend whatever your allies defined what it is but knowing if you are within the SLI it's very hard if you don't have",
    "start": "2591710",
    "end": "2598550"
  },
  {
    "text": "an to end transaction visibility because all you have to look at our individual service logs or metrics which are",
    "start": "2598550",
    "end": "2605570"
  },
  {
    "text": "specific to a particular service or a particular action and you can't connect them and twins or you can write you can",
    "start": "2605570",
    "end": "2612080"
  },
  {
    "text": "do it in other ways you don't have to use this retracing but it's expensive and hard once you have this to be",
    "start": "2612080",
    "end": "2617360"
  },
  {
    "text": "tracing you can start answering those questions much easier that's what I meant earlier where you don't have to use a specific technology there are",
    "start": "2617360",
    "end": "2623870"
  },
  {
    "text": "trade-offs to all of them right and so the trade-off for not using just really tracing for these kind of questions is",
    "start": "2623870",
    "end": "2629390"
  },
  {
    "text": "you'll probably pay more or you'll do more work manually and stuff like that but you can still do it so answering",
    "start": "2629390",
    "end": "2635840"
  },
  {
    "text": "stuff like am i within the SLA is my end-to-end latency X or within certain boundaries or is my load time or",
    "start": "2635840",
    "end": "2642410"
  },
  {
    "text": "whatever whatever it is you define because much easier the second thing that happens is it becomes much easier",
    "start": "2642410",
    "end": "2649160"
  },
  {
    "text": "to answer the second question in observability which is what exactly is broken now that we have a full trace of",
    "start": "2649160",
    "end": "2656750"
  },
  {
    "text": "what happens in the system we can zoom in to a particular part and see which one which span is responsible like for",
    "start": "2656750",
    "end": "2664130"
  },
  {
    "text": "example in our case because we care about end-to-end latency so much we can now look at every span and how much how",
    "start": "2664130",
    "end": "2670580"
  },
  {
    "text": "long it took and open finds these fans that took the longest and figure out why it is or if a particular span suddenly",
    "start": "2670580",
    "end": "2676340"
  },
  {
    "text": "goes you know from latency X to latency 10 times X we can try and figure out why that is in",
    "start": "2676340",
    "end": "2683000"
  },
  {
    "text": "we can extract much more sophisticated application performance metrics out of these real traces then we can from just",
    "start": "2683000",
    "end": "2689690"
  },
  {
    "text": "normal application metrics or system metrics right but now actually measure things and convert them into a metric",
    "start": "2689690",
    "end": "2695260"
  },
  {
    "text": "that's are much higher level than just a particular service again and twin stuff and like and alike once we have this we",
    "start": "2695260",
    "end": "2704080"
  },
  {
    "text": "can complete the whole picture of what's actually going on in the system right and so the way you collect metrics as I",
    "start": "2704080",
    "end": "2710300"
  },
  {
    "start": "2709000",
    "end": "2877000"
  },
  {
    "text": "said is you have to instrument the code I'll actually hopefully have enough time to show you an example of that it's",
    "start": "2710300",
    "end": "2717530"
  },
  {
    "text": "usually either very hard because you have to do it manually or very easy because you use a framework and there's",
    "start": "2717530",
    "end": "2722630"
  },
  {
    "text": "no in between then you collect all the traces the problem with collecting traces is it's actually even more data",
    "start": "2722630",
    "end": "2730100"
  },
  {
    "text": "than you would with logs right it makes sense to collect a bunch of spans usually I have you know between 1 and",
    "start": "2730100",
    "end": "2735380"
  },
  {
    "text": "let's say a handful of spans for every process and so you take the number of transactions every day you multiply it",
    "start": "2735380",
    "end": "2740600"
  },
  {
    "text": "by a number of service multiply it by a number of spans each one emits you quickly get into trillions of objects you have to store so you can't really do",
    "start": "2740600",
    "end": "2747200"
  },
  {
    "text": "that so usually the answer that most people who use the tree tracing is to do something right you don't need every",
    "start": "2747200",
    "end": "2753440"
  },
  {
    "text": "transaction you see the representative sample of the important transactions to get the idea so here you have a trade",
    "start": "2753440",
    "end": "2761150"
  },
  {
    "text": "off or some kind of scale between the granularity of logs the lack of granularity but the low cost of metrics",
    "start": "2761150",
    "end": "2767600"
  },
  {
    "text": "and you can define where you fall on that classic example is in Google's case with your dapper system they sampled one",
    "start": "2767600",
    "end": "2774020"
  },
  {
    "text": "or sample one out of every 10,000 transactions right they don't collect every metric it's completely impractical",
    "start": "2774020",
    "end": "2779120"
  },
  {
    "text": "at Google of scale so the example if one out of every 10,000 and that still gives them enough information to actually know",
    "start": "2779120",
    "end": "2785300"
  },
  {
    "text": "the what the state of the system is all right and there are different ways to do it you can sample adaptively let's say I",
    "start": "2785300",
    "end": "2790880"
  },
  {
    "text": "want every service to emit a hundred messages per second sorry traces per second working sample by percentage or",
    "start": "2790880",
    "end": "2797240"
  },
  {
    "text": "something just the pitfall here is if you decide to sample one of every X",
    "start": "2797240",
    "end": "2803150"
  },
  {
    "text": "messages which is something we try doing the problem is if you have different types of messages let's say we have an",
    "start": "2803150",
    "end": "2809000"
  },
  {
    "text": "event which happens a million times a day a different event which happens a thousand times a day if you just randoms",
    "start": "2809000",
    "end": "2815060"
  },
  {
    "text": "and randomly sample at one every thousand messages we're almost certainly going to miss the second event and have no information about this and I",
    "start": "2815060",
    "end": "2821570"
  },
  {
    "text": "have a good sample size about a very frequent event and so they need to apply some intelligence to how you actually",
    "start": "2821570",
    "end": "2827540"
  },
  {
    "text": "adapt sampling here and then you can obviously change it so for example for",
    "start": "2827540",
    "end": "2832580"
  },
  {
    "text": "automation runs in our mechanism they're not subject to sampling if an automation",
    "start": "2832580",
    "end": "2837619"
  },
  {
    "text": "run starts a transaction it always gets collected the only traces get collected and only if users or normal system",
    "start": "2837619",
    "end": "2844850"
  },
  {
    "text": "equations transactions they get sampled one hour of X because we know we want to",
    "start": "2844850",
    "end": "2850430"
  },
  {
    "text": "have the full context of every automation transaction right once you have all this data what do you do with",
    "start": "2850430",
    "end": "2856430"
  },
  {
    "text": "it obviously I do want to get some interesting insight out of it so you dump it on some kind of index or you do",
    "start": "2856430",
    "end": "2861740"
  },
  {
    "text": "some kind of back and work for it to actually make it searchable and queryable then query it and you visualize it now I have some examples of",
    "start": "2861740",
    "end": "2868130"
  },
  {
    "text": "how you can visualize it to get useful data but you know the sky's the limit and so I talked about some open",
    "start": "2868130",
    "end": "2875030"
  },
  {
    "text": "standards for this or some standards for tracing there are several projects called open tracing open census and open",
    "start": "2875030",
    "end": "2881810"
  },
  {
    "start": "2877000",
    "end": "2925000"
  },
  {
    "text": "metrics in like every standard like each one of them claims to be the standard for digital retracing or GTO",
    "start": "2881810",
    "end": "2888500"
  },
  {
    "text": "transactions they're not actually very good projects open tracing in particular",
    "start": "2888500",
    "end": "2895400"
  },
  {
    "text": "has support from C NFC so so the cloud native Foundation Software Foundation",
    "start": "2895400",
    "end": "2900940"
  },
  {
    "text": "and it's adapted quite relatively widely",
    "start": "2900940",
    "end": "2906190"
  },
  {
    "text": "almost all the tools the common tools that we have for tracing today support",
    "start": "2906190",
    "end": "2911720"
  },
  {
    "text": "open tracing or have some kind of connector to open tracing open metrics tries to do for tracing same thing for",
    "start": "2911720",
    "end": "2919550"
  },
  {
    "text": "tracing and metrics right so it has a common interface that is vendor-neutral",
    "start": "2919550",
    "end": "2924910"
  },
  {
    "text": "which lets you instrument all of your code in a way where you can switch the back end let's say today you're using",
    "start": "2924910",
    "end": "2930619"
  },
  {
    "text": "whatever elasticsearch and tomorrow you want to use Zipkin or whatever some other system you don't know what you",
    "start": "2930619",
    "end": "2936230"
  },
  {
    "text": "don't have to go and rebuild all of your instrumentation and code you instrument once which emits trace is compatible",
    "start": "2936230",
    "end": "2941990"
  },
  {
    "text": "with open tracing it emits metrics compatible with open metrics and then you can plug the back end and change it",
    "start": "2941990",
    "end": "2947000"
  },
  {
    "text": "as much do you want you're gonna have to go and do all the expensive work instrumenting every piece of code separately right and all of them usually",
    "start": "2947000",
    "end": "2954049"
  },
  {
    "text": "come with libraries which instrument common things for example for dot Nats open tracings instruments HTTP calls",
    "start": "2954049",
    "end": "2961069"
  },
  {
    "text": "automatically right so any requests and responses get traced automatically and that means it can detach the connection",
    "start": "2961069",
    "end": "2967880"
  },
  {
    "text": "context open the span closes pan all this stuff happens for you there's very little code you actually have to write same thing for you common things like",
    "start": "2967880",
    "end": "2974839"
  },
  {
    "text": "spring in Java and so it's so open tracing specifically tries to solve a",
    "start": "2974839",
    "end": "2980900"
  },
  {
    "text": "very narrow problem of how do you propagate the trace context from service to service which is a pretty hard",
    "start": "2980900",
    "end": "2987140"
  },
  {
    "text": "problem right as I said there's no different ways of actually calling services there's HTTP RPC Kafka RabbitMQ all this",
    "start": "2987140",
    "end": "2993740"
  },
  {
    "text": "stuff in each one has different weird edges and educators and you have to",
    "start": "2993740",
    "end": "3001000"
  },
  {
    "text": "cover a bunch of languages and so they solve this one specific problem and they leave everything else like how do you collect the traces what do you do with",
    "start": "3001000",
    "end": "3007240"
  },
  {
    "text": "them for other tools to solve right and so we said usually you sample your index",
    "start": "3007240",
    "end": "3013900"
  },
  {
    "text": "and pretty much every system that's open-source that supports you see retracing users either elasticsearch or",
    "start": "3013900",
    "end": "3020890"
  },
  {
    "text": "cassandra or both as the backend they're very common we look at some examples in",
    "start": "3020890",
    "end": "3026020"
  },
  {
    "text": "a bit and see you know how we can actually do that relatively cheaply how to you can integrate it very cheaply",
    "start": "3026020",
    "end": "3031839"
  },
  {
    "text": "into your system now we get to the interesting part of it which is how do you visualize traces right so we have",
    "start": "3031839",
    "end": "3038319"
  },
  {
    "start": "3034000",
    "end": "3106000"
  },
  {
    "text": "all this wonderful data blobs web metrics web traces we look at logs you don't really visualize logs you just",
    "start": "3038319",
    "end": "3044200"
  },
  {
    "text": "search them metrics are very obvious how you realize usually they're and their histograms based on time and so it's",
    "start": "3044200",
    "end": "3050349"
  },
  {
    "text": "obvious so how do you just need visual eyes traces right which is a trace is it has a time component it also has a",
    "start": "3050349",
    "end": "3056230"
  },
  {
    "text": "transaction component and there's a bunch of ways you can visualize it the two most common ways are either building",
    "start": "3056230",
    "end": "3063640"
  },
  {
    "text": "metrics based on histograms so time flows the latency of a span or links to the transaction over time or building",
    "start": "3063640",
    "end": "3070480"
  },
  {
    "text": "waterfalls and flame graphs which are more like CPU sampling where you take a",
    "start": "3070480",
    "end": "3076510"
  },
  {
    "text": "trace and you map all the different spans on a graph and so how much each one's took and the relationships",
    "start": "3076510",
    "end": "3083420"
  },
  {
    "text": "and so have we a waterful latency graph and I said very similar to what you",
    "start": "3083420",
    "end": "3088460"
  },
  {
    "text": "would do with Network latency for example in a browser I think very weird",
    "start": "3088460",
    "end": "3093619"
  },
  {
    "text": "systems as well people have customized their own backends for transactions will display the selection in interesting",
    "start": "3093619",
    "end": "3099289"
  },
  {
    "text": "ways we actually have a grim homegrown one as well which looks nothing like any of the common systems right and so brings us to",
    "start": "3099289",
    "end": "3106970"
  },
  {
    "start": "3106000",
    "end": "3215000"
  },
  {
    "text": "a quick set of tools so there's a billion tools for it right generally they fall into one or two categories they're self hosted and there's managed",
    "start": "3106970",
    "end": "3113329"
  },
  {
    "text": "services which you can buy as a sass right you don't really have to remember all of these but just you know I'll give",
    "start": "3113329",
    "end": "3121010"
  },
  {
    "text": "you a quick list of screenshots this you can get a feel of what the tools are I'm",
    "start": "3121010",
    "end": "3126019"
  },
  {
    "text": "not gonna I specifically avoid neo selling products I don't care about you which one you use pick whatever works",
    "start": "3126019",
    "end": "3131720"
  },
  {
    "text": "for you I tried not to make the whole talk very product centric but I just wanna get once you guys to get a feel of",
    "start": "3131720",
    "end": "3137930"
  },
  {
    "text": "what do you I would look like what is the actual benefit you get from using the tool right and so on the Left we",
    "start": "3137930",
    "end": "3143539"
  },
  {
    "text": "have all the self hosted tools Zipkin and Jager Jager is also an open source tool that's been adapted by the cloud",
    "start": "3143539",
    "end": "3149750"
  },
  {
    "text": "native foundation it's being incubated so it's a very nice open-source tool",
    "start": "3149750",
    "end": "3156130"
  },
  {
    "text": "there's a few of them a couple of big ones one very interesting one is elasticsearch right as I'm sure a lot of",
    "start": "3156130",
    "end": "3163069"
  },
  {
    "text": "you use elk for logging and so elasticsearch as a version seven if I'm",
    "start": "3163069",
    "end": "3168500"
  },
  {
    "text": "not mistaken have an APM module which is like a small service which can collect application metrics and traces and store",
    "start": "3168500",
    "end": "3175640"
  },
  {
    "text": "them in elasticsearch and so it overloads the street-racing functionality on top of your normal elk",
    "start": "3175640",
    "end": "3180710"
  },
  {
    "text": "so if you have elk installed it's very easy to also put the street-racing into it it's compatible with open tracing so",
    "start": "3180710",
    "end": "3186799"
  },
  {
    "text": "if you instrument stuff you can switch it out later and it's it's it it breaks this friction",
    "start": "3186799",
    "end": "3192349"
  },
  {
    "text": "of well this is a huge task right how we're gonna do this tracing stuff this you know we have to spin up a database blah blah blah if you already have elk",
    "start": "3192349",
    "end": "3199130"
  },
  {
    "text": "it's a very small gap to jump to open tracing this way I highly recommend it most of it is free some parts of it",
    "start": "3199130",
    "end": "3205519"
  },
  {
    "text": "which are related to analytics which are not in the free version and unfortunately they're locked behind",
    "start": "3205519",
    "end": "3210589"
  },
  {
    "text": "actually buying a subscription but most of the stuff is actually free it's very nice to play around with so let's look",
    "start": "3210589",
    "end": "3215720"
  },
  {
    "start": "3215000",
    "end": "3250000"
  },
  {
    "text": "and it looks like this right so this is screen of elastic APM this is a transaction analysis view right as you can see you",
    "start": "3215720",
    "end": "3221910"
  },
  {
    "text": "have a flame graph right this is random HTTP transaction which is built out of a bunch of spans and so if you look at",
    "start": "3221910",
    "end": "3227910"
  },
  {
    "text": "this there's a bunch of ways to visualize this in this case it's looking at one transaction you can also look at",
    "start": "3227910",
    "end": "3233150"
  },
  {
    "text": "aggregations from many different transactions that looks the same and see average latency and stuff like that but",
    "start": "3233150",
    "end": "3239609"
  },
  {
    "text": "this is a very common pretty much every tool which does this really tracing will have a graph that looks kind of like",
    "start": "3239609",
    "end": "3244979"
  },
  {
    "text": "this or a kind of visualization that looks like this right would you like to see a graph there's another tool I like",
    "start": "3244979",
    "end": "3251130"
  },
  {
    "start": "3250000",
    "end": "3310000"
  },
  {
    "text": "a lot which is Jaeger open source cloud native as I said in addition to the latest in graph they",
    "start": "3251130",
    "end": "3257039"
  },
  {
    "text": "have a very cool feature of comparing two different transactions so what this does is it gives you the difference",
    "start": "3257039",
    "end": "3263009"
  },
  {
    "text": "between two different sets of transactions and the differ and the changes in different services which I",
    "start": "3263009",
    "end": "3268319"
  },
  {
    "text": "like a lot I think it's a very cool way of representing changes in your infrastructure if you look at you know a bunch of traces from yesterday and a",
    "start": "3268319",
    "end": "3274529"
  },
  {
    "text": "bunch of traces from today you want to see what changed if you can also somehow tie this to your deployment system you",
    "start": "3274529",
    "end": "3280140"
  },
  {
    "text": "know if you have CI CD or a build server and you can say okay well yesterday service got deployed and now we can see",
    "start": "3280140",
    "end": "3286709"
  },
  {
    "text": "that the latency of the service went up by X percent between two different races that's really valuable information that actually answers pretty much all the",
    "start": "3286709",
    "end": "3293759"
  },
  {
    "text": "useful questions you can have about observability of what changed Y and what caused it right and you can trace it",
    "start": "3293759",
    "end": "3299130"
  },
  {
    "text": "trace it back to a specific commit or specific build which is a very cool ability which I would love to have in",
    "start": "3299130",
    "end": "3304739"
  },
  {
    "text": "our system we're not there yet which will eventually get there hopefully so",
    "start": "3304739",
    "end": "3310890"
  },
  {
    "start": "3310000",
    "end": "3339000"
  },
  {
    "text": "Zipkin is very similar to that it has a waterfall graph of latencies",
    "start": "3310890",
    "end": "3318569"
  },
  {
    "text": "this an example I took from Zipkin using or running over Kafka which is much harder to do because instrumenting Kafka",
    "start": "3318569",
    "end": "3326099"
  },
  {
    "text": "is much harder in suddenly it's not as easy to as HTTP with headers you",
    "start": "3326099",
    "end": "3332549"
  },
  {
    "text": "actually come but lipkin comes with out-of-the-box supports for Kafka and a bunch of other machine technologies",
    "start": "3332549",
    "end": "3339859"
  },
  {
    "start": "3339000",
    "end": "3366000"
  },
  {
    "text": "very dark slide from Apache Sky walking but it basically it has all the other",
    "start": "3339859",
    "end": "3345509"
  },
  {
    "text": "stuff we showed about and also this cool way of actually visualizing your system dependencies",
    "start": "3345509",
    "end": "3350860"
  },
  {
    "text": "which is not useful it's where I can as I can tell I don't think I'd ever use this it's very cool for demos you know",
    "start": "3350860",
    "end": "3356470"
  },
  {
    "text": "or if you have a new employee coming and you can show them well this is our entire system this is the data flow in the system that's pretty cool that's",
    "start": "3356470",
    "end": "3362740"
  },
  {
    "text": "probably the only actual use I can think of it and finally we have AWS x-ray",
    "start": "3362740",
    "end": "3368440"
  },
  {
    "start": "3366000",
    "end": "3414000"
  },
  {
    "text": "which is Amazon system every cloud provider has something so as your has",
    "start": "3368440",
    "end": "3374200"
  },
  {
    "text": "app dynamics so app insight sorry every cloud system has something similar to that any bliss has x-ray which in very",
    "start": "3374200",
    "end": "3382420"
  },
  {
    "text": "typical Amazon fashion is completely incompatible with open tracing I'm showing this because I like the graphs",
    "start": "3382420",
    "end": "3388240"
  },
  {
    "text": "and the way it actually visualize service latencies between different services but there is no way to",
    "start": "3388240",
    "end": "3393880"
  },
  {
    "text": "instrument your application with open tracing and since they send this data to x-ray if you go x-ray you're locked to",
    "start": "3393880",
    "end": "3400600"
  },
  {
    "text": "Amazon and it's very annoying and that's something that happens a lot with if you",
    "start": "3400600",
    "end": "3406060"
  },
  {
    "text": "use a billion unfortunately and so before I finish I just want to show you a quick example of how you actually do",
    "start": "3406060",
    "end": "3412150"
  },
  {
    "text": "this in code and it happens I do have some code here so this is a very simple",
    "start": "3412150",
    "end": "3419260"
  },
  {
    "start": "3414000",
    "end": "3600000"
  },
  {
    "text": "set of services small nothing score and back-end service and that's an core front-end service this is the only code",
    "start": "3419260",
    "end": "3426580"
  },
  {
    "text": "I had to write to make it emit traces to auto Zipkin and I could replace two",
    "start": "3426580",
    "end": "3431620"
  },
  {
    "text": "lines of code from Zipkin to Jaeger or whatever and it would actually work with the different system just as well so all",
    "start": "3431620",
    "end": "3437530"
  },
  {
    "text": "I had to do was actually initialize the the tracer here and tell it where to send it I have Zipkin running on the",
    "start": "3437530",
    "end": "3442960"
  },
  {
    "text": "same machine in a certain port normally it wouldn't be on the same machine probably somewhere else on the network and so the Zipkin library automatically",
    "start": "3442960",
    "end": "3450850"
  },
  {
    "text": "hooks into HTTP client an HTTP server it will automatically attach the",
    "start": "3450850",
    "end": "3456040"
  },
  {
    "text": "transaction context to every web request and detach it and create spans for every web response and that's a bunch of work",
    "start": "3456040",
    "end": "3462700"
  },
  {
    "text": "for you and so that's why I picked this example because this is the minimum amount of code I found of all the",
    "start": "3462700",
    "end": "3467830"
  },
  {
    "text": "various technologies that you have to write to actually have distributed tracing in your system right and so as",
    "start": "3467830",
    "end": "3473020"
  },
  {
    "text": "you can see this is a to services right there's no code related tracing in either service right everything is just",
    "start": "3473020",
    "end": "3478570"
  },
  {
    "text": "in the initialization and it doesn't actually do anything fancy all it sorry all the",
    "start": "3478570",
    "end": "3484000"
  },
  {
    "text": "servus does is hold it back in service right there's no right there's nothing",
    "start": "3484000",
    "end": "3490900"
  },
  {
    "text": "specific here the traces is just when we create the clients we create one that supports the tracer and in the back-end",
    "start": "3490900",
    "end": "3497470"
  },
  {
    "text": "system there is also as I said no no special code really erasing nothing like that so the whole instrumentation was",
    "start": "3497470",
    "end": "3503410"
  },
  {
    "text": "actually very seamless if you run this thing let's see if it actually will run because you never know with live demos",
    "start": "3503410",
    "end": "3512849"
  },
  {
    "text": "and hopefully if everything works ok as",
    "start": "3515430",
    "end": "3523990"
  },
  {
    "text": "you can tell it refuses to run but we'll give it another try and this is weird",
    "start": "3523990",
    "end": "3532840"
  },
  {
    "text": "having done the core in the visual studio writing on the Mac but it actually works most of the time or at",
    "start": "3532840",
    "end": "3538420"
  },
  {
    "text": "least like half the time ok it works in",
    "start": "3538420",
    "end": "3546880"
  },
  {
    "text": "the second track and so if we go here this is a very simple verification all it does is return the current time well",
    "start": "3546880",
    "end": "3552880"
  },
  {
    "text": "click it a couple of times those will switch over to our Zipkin servers I run I have Zipkin running in the background and then we can go and can find some",
    "start": "3552880",
    "end": "3560050"
  },
  {
    "text": "traces so Zipkin has a very very slim interface all it does is just show me the actual traces we can go into a trace",
    "start": "3560050",
    "end": "3566890"
  },
  {
    "text": "right you can see that this trace has two spans it has a front end server and a back end server span I I had more",
    "start": "3566890",
    "end": "3572560"
  },
  {
    "text": "functionality in the service I'd have probably more spans like a database call or whatever some kind of RPC I'm going",
    "start": "3572560",
    "end": "3578350"
  },
  {
    "text": "to each one of them and get some details and in this case all the stuff I actually overload on top of the",
    "start": "3578350",
    "end": "3583810"
  },
  {
    "text": "immediate trace I could have you know exceptions here I can have any kind of tags to go and search for the traces",
    "start": "3583810",
    "end": "3589900"
  },
  {
    "text": "later I would see them here and they have a cool feature called system dependency graph which is kind of",
    "start": "3589900",
    "end": "3596500"
  },
  {
    "text": "similar to what we showed earlier we can go and can look at their cool UI and",
    "start": "3596500",
    "end": "3604170"
  },
  {
    "text": "show the city defenses and our entire system looks like this there are exactly two services and we can look at one of",
    "start": "3604170",
    "end": "3610750"
  },
  {
    "text": "the services and see who calls it so the backend server was called seven times by",
    "start": "3610750",
    "end": "3615970"
  },
  {
    "text": "the front-end server wonderful we have met we have graphs all the cool stuff we ever wanted from our observability so",
    "start": "3615970",
    "end": "3621730"
  },
  {
    "text": "just to summarize real quick before I finish it's not about technologies right it's",
    "start": "3621730",
    "end": "3627130"
  },
  {
    "text": "not about specific products we're going to use we want to actually have to sleep at night mostly right I want to be a",
    "start": "3627130",
    "end": "3632859"
  },
  {
    "text": "woken up by alert and so we want to instrument as much observability as we can into every system when you approach",
    "start": "3632859",
    "end": "3638890"
  },
  {
    "text": "an existing system usually extra hard because there's a lot of work you have to do to go back and instrument existing",
    "start": "3638890",
    "end": "3645099"
  },
  {
    "text": "code and so for this and this is something with I found over the past year and a half usually engineers when they try a new",
    "start": "3645099",
    "end": "3652000"
  },
  {
    "text": "thing a new technology they have the the tendency to go and to go to some non",
    "start": "3652000",
    "end": "3657490"
  },
  {
    "text": "critical part of the system and try it there just in case you break something with stuff like tracing an observer",
    "start": "3657490",
    "end": "3662950"
  },
  {
    "text": "ability counter-intuitively usually you should go to the most critical system",
    "start": "3662950",
    "end": "3667990"
  },
  {
    "text": "and instrument that and gives observability over that because you get much more value immediately right if",
    "start": "3667990",
    "end": "3673089"
  },
  {
    "text": "you're gonna add traces or open this retraces to your system goes through you know two or three services which are the hardest or the most important in your",
    "start": "3673089",
    "end": "3679540"
  },
  {
    "text": "system instrument those and then see if you have actual value from that and then",
    "start": "3679540",
    "end": "3684670"
  },
  {
    "text": "you can justify going to all the other services instrumenting them right if you go to the least important service and use instrument they have traces out of",
    "start": "3684670",
    "end": "3691000"
  },
  {
    "text": "that it's not gonna be useful that's the reason there's a reason it's not important right and so that's my advice",
    "start": "3691000",
    "end": "3698280"
  },
  {
    "text": "i'm thank you very much for coming to the talk hope you enjoyed it cute answer question upwards",
    "start": "3698280",
    "end": "3704990"
  },
  {
    "text": "[Applause]",
    "start": "3704990",
    "end": "3709810"
  }
]
[
  {
    "start": "0",
    "end": "129000"
  },
  {
    "text": "well thank you for coming everyone welcome I know there is a tough competition out there so really i",
    "start": "7440",
    "end": "13830"
  },
  {
    "text": "apprec-- you're coming I hope you're enjoying NBC so far my name is Sasha and we'll be",
    "start": "13830",
    "end": "19200"
  },
  {
    "text": "talking about hardware performance how to squeeze the most out of your CPU by",
    "start": "19200",
    "end": "24750"
  },
  {
    "text": "performing some rather low level optimizations this is a talk for dotnet developers generally most of my examples",
    "start": "24750",
    "end": "31289"
  },
  {
    "text": "are going to be in c-sharp and using some libraries which have only recently become available to dotnet developers",
    "start": "31289",
    "end": "36570"
  },
  {
    "text": "however the concepts described here are relevant for everyone building software and Intel CPUs",
    "start": "36570",
    "end": "43140"
  },
  {
    "text": "a lot of the examples are very general and you can apply them in other languages as well in fact the lower",
    "start": "43140",
    "end": "48570"
  },
  {
    "text": "level the language the better for example in C or C++ it would be a lot easier to apply a lot of these ideas but",
    "start": "48570",
    "end": "55320"
  },
  {
    "text": "again this is dotnet it's going to be the examples are going to be using dotnet so roughly what we're going to do",
    "start": "55320",
    "end": "62280"
  },
  {
    "text": "is talk about how modern CPUs are built I'm going to spend a few minutes of this",
    "start": "62280",
    "end": "67619"
  },
  {
    "text": "because it's really hard to understand what the optimizations are about if you don't really know exactly how the CPU is",
    "start": "67619",
    "end": "74670"
  },
  {
    "text": "constructed internally with the different pieces in the pipeline are which will be taken advantage of we'll",
    "start": "74670",
    "end": "80819"
  },
  {
    "text": "see some basic examples based on you know internet questions on these",
    "start": "80819",
    "end": "87360"
  },
  {
    "text": "different aspects of CPU architecture and then we'll move to the actual techniques applying what we sort of",
    "start": "87360",
    "end": "94259"
  },
  {
    "text": "learned about the CPU to optimizing specific algorithms hopefully all the",
    "start": "94259",
    "end": "99330"
  },
  {
    "text": "examples are going to be fairly real-world I'm not saying you know you can take this code and apply it today in",
    "start": "99330",
    "end": "106649"
  },
  {
    "text": "each of your applications but it's not complete pure theory which you never will apply its actual algorithms used in",
    "start": "106649",
    "end": "114390"
  },
  {
    "text": "a lot of computational frameworks a lot of libraries a lot of applications today and towards the end this will maybe",
    "start": "114390",
    "end": "120899"
  },
  {
    "text": "touch a little on where I see the future of optimizing this kind of low-level CPU",
    "start": "120899",
    "end": "126390"
  },
  {
    "text": "work on other platforms so this is a modern processor inside there is two",
    "start": "126390",
    "end": "131610"
  },
  {
    "start": "129000",
    "end": "129000"
  },
  {
    "text": "processors here on the left is a pretty standard desktop issue processor that a",
    "start": "131610",
    "end": "138510"
  },
  {
    "text": "lot of you probably have or had in the past it's from the AI series the Intel i5 i7",
    "start": "138510",
    "end": "144090"
  },
  {
    "text": "series it's not a very expensive processor probably it goes for 200 300 400 bucks and it's",
    "start": "144090",
    "end": "152010"
  },
  {
    "text": "really easy to see there's a some structure here some well delineated pieces so for example this processor has",
    "start": "152010",
    "end": "159480"
  },
  {
    "text": "four cores at each core has a little piece of cash and there's also this whole unit on the side which contains",
    "start": "159480",
    "end": "165690"
  },
  {
    "text": "the graphics and a bunch of other things that are today built into processors and there's a large piece here which is the",
    "start": "165690",
    "end": "172050"
  },
  {
    "text": "shared cache so a lot of parts clearly visible and then on the right there is a",
    "start": "172050",
    "end": "177510"
  },
  {
    "text": "somewhat bigger chip a chip that's also a lot more expensive this is impulse",
    "start": "177510",
    "end": "182910"
  },
  {
    "text": "Knights London which was released a few months ago it's a it goes for a few",
    "start": "182910",
    "end": "188760"
  },
  {
    "text": "thousand dollars but it has up to 72 cores and this is this is today this is",
    "start": "188760",
    "end": "195720"
  },
  {
    "text": "a few months ago it's not like these you know super computers that you heard about in the movies which would cost",
    "start": "195720",
    "end": "201960"
  },
  {
    "text": "millions of dollars to build this is a 72 core chip which can run your OS in",
    "start": "201960",
    "end": "208050"
  },
  {
    "text": "the past Intel would make these chips which couldn't run an operating system you would have to attach them to an",
    "start": "208050",
    "end": "213720"
  },
  {
    "text": "existing computer that would already run some other OS but as of knights landing you can actually run your Windows or",
    "start": "213720",
    "end": "219810"
  },
  {
    "text": "Linux on this chip directly and use it for computation it has a bunch of cache",
    "start": "219810",
    "end": "225150"
  },
  {
    "text": "it has a bunch of embedded fast memory and it can attach to additional external",
    "start": "225150",
    "end": "230340"
  },
  {
    "text": "memory up to terabytes and terabytes of additional RAM for this monster unit to",
    "start": "230340",
    "end": "235860"
  },
  {
    "text": "use 72 cores for a few thousand dollars is a pretty good bargain I'd say and people are starting to use these for",
    "start": "235860",
    "end": "242820"
  },
  {
    "text": "financial work for image processing for video processing for a bunch of CPU intensive tasks and then the challenge",
    "start": "242820",
    "end": "249660"
  },
  {
    "text": "is really to squeeze the most out of this thing you paid a lot of money to get and squeezing squeezing the maximum",
    "start": "249660",
    "end": "257250"
  },
  {
    "text": "out of this thing applies on each core individually so you want the maximum",
    "start": "257250",
    "end": "263190"
  },
  {
    "text": "performance of each of these seventh two cores but you also want parallelization to work well you want these cores to",
    "start": "263190",
    "end": "269070"
  },
  {
    "text": "work together and distribute the load as equally as you can between them so there is a bunch of toxic could do on each of",
    "start": "269070",
    "end": "275820"
  },
  {
    "text": "these aspects today we're going to focus more on extracting the most out of each individual core",
    "start": "275820",
    "end": "281620"
  },
  {
    "text": "fertilization is a whole different topic and hopefully you've heard some talks about using parallel code in dotnet and",
    "start": "281620",
    "end": "287770"
  },
  {
    "text": "other languages in the past but getting the most out of a single CPU is a bit more challenging so a processor",
    "start": "287770",
    "end": "294940"
  },
  {
    "start": "294000",
    "end": "294000"
  },
  {
    "text": "organization just briefly I want to touch on what happens inside Intel processors for quite a while now",
    "start": "294940",
    "end": "301630"
  },
  {
    "text": "this general structure hasn't changed since Nehalem which was released like eight or nine years ago this is the",
    "start": "301630",
    "end": "308139"
  },
  {
    "text": "first generation Intel I series processor so roughly there's two parts",
    "start": "308139",
    "end": "313870"
  },
  {
    "text": "here everything here on the left is the front end of the processor and then this thing here is the back end of the",
    "start": "313870",
    "end": "319990"
  },
  {
    "text": "processor and essentially the back end is where instructions actually get executed this is where you add numbers",
    "start": "319990",
    "end": "325780"
  },
  {
    "text": "and you multiply them and you write stuff out to registers on to memory and the front end is where roughly",
    "start": "325780",
    "end": "333240"
  },
  {
    "text": "instructions are being decoded processed and rearranged so I'm not going to touch",
    "start": "333240",
    "end": "339190"
  },
  {
    "text": "on every single aspect of this just a few highlights before the processor can actually execute any instructions it has",
    "start": "339190",
    "end": "345130"
  },
  {
    "text": "to read them from memory so it all starts with the instruction cache where the most recently accessed instructions",
    "start": "345130",
    "end": "351310"
  },
  {
    "text": "are stored so if you have a loop for example you would benefit from the fact you already read these instructions from",
    "start": "351310",
    "end": "356740"
  },
  {
    "text": "memory so you can just reuse what you're already read once you feed them from memory but to read them from memory you",
    "start": "356740",
    "end": "363039"
  },
  {
    "text": "have to decode them you actually have to convert them as well to an internal",
    "start": "363039",
    "end": "368050"
  },
  {
    "text": "format that the CPU uses called micro ops view ops this is totally different",
    "start": "368050",
    "end": "373360"
  },
  {
    "text": "from what you see in Visual Studio when you open the disassembly window the instructions you see there are the",
    "start": "373360",
    "end": "379570"
  },
  {
    "text": "official public instruction set however internally the CPU uses a slightly different representation where each",
    "start": "379570",
    "end": "386500"
  },
  {
    "text": "assembly instruction is broken down into much smaller pieces so for example an",
    "start": "386500",
    "end": "391570"
  },
  {
    "text": "instruction that reads the value from memory and adds another number to it and storage the result to some other",
    "start": "391570",
    "end": "397330"
  },
  {
    "text": "location might be broken into three parts recent memory add a number and then write the result somewhere and",
    "start": "397330",
    "end": "404260"
  },
  {
    "text": "these micro op are then passed forward to the back end which actually executes",
    "start": "404260",
    "end": "411159"
  },
  {
    "text": "them and in the back end we have multiple execution units or execution ports which are capable of",
    "start": "411159",
    "end": "417820"
  },
  {
    "text": "doing things at once concurrently in parallel on a single core right we're",
    "start": "417820",
    "end": "423460"
  },
  {
    "text": "talking about just one individual core here so this is not multi-core this is on a single core you have multiple ports",
    "start": "423460",
    "end": "430419"
  },
  {
    "text": "capable of doing things at once for example and I'll show you some more details soon you have a port for adding",
    "start": "430419",
    "end": "437320"
  },
  {
    "text": "numbers and you have a different port for storing values into memory so if you have two operations to perform if you",
    "start": "437320",
    "end": "443470"
  },
  {
    "text": "have to add numbers and store results to memory and you can run them at the same time they can actually execute",
    "start": "443470",
    "end": "449680"
  },
  {
    "text": "concurrently inside the processor so you can get some more concurrency out of the CPU on a single core by arranging stuff",
    "start": "449680",
    "end": "457780"
  },
  {
    "text": "such that all of these execution units are busy at once so here's some of the",
    "start": "457780",
    "end": "463410"
  },
  {
    "start": "463000",
    "end": "463000"
  },
  {
    "text": "more important execution units currently we have a total of seven ports some of",
    "start": "463410",
    "end": "470889"
  },
  {
    "text": "them are not really interesting they just are reserved for reading from memory or writing into memory or doing",
    "start": "470889",
    "end": "477310"
  },
  {
    "text": "calculations or addresses the ones that have stuff inside are the ones that perform actual computation so for",
    "start": "477310",
    "end": "484570"
  },
  {
    "text": "example we have port 0 which is responsible for things such as branching and arithmetic and string operations and",
    "start": "484570",
    "end": "492150"
  },
  {
    "text": "multiplication and even AES encryption which is something Intel processors were",
    "start": "492150",
    "end": "497409"
  },
  {
    "text": "able to do for quite some time now for a couple of releases back port number one does arithmetic as well and also",
    "start": "497409",
    "end": "503759"
  },
  {
    "text": "multiplication and also encryption and also floating-point operations and it turns out that even the same kind of",
    "start": "503759",
    "end": "511000"
  },
  {
    "text": "thing like adding numbers or multiplying numbers you can actually do concurrently",
    "start": "511000",
    "end": "516310"
  },
  {
    "text": "on the chip because you have multiple ports that can do the same thing so for example port 5 port 1 and port 0 are all",
    "start": "516310",
    "end": "524290"
  },
  {
    "text": "capable of adding integers together so if you have a lot of integers that you have to add together and you have a lot",
    "start": "524290",
    "end": "531310"
  },
  {
    "text": "of instructions just adding integers you can actually do three of them at once your core your single core can execute",
    "start": "531310",
    "end": "538300"
  },
  {
    "text": "three of these instructions at once and this is very important for understanding where like the best-case performance for",
    "start": "538300",
    "end": "545020"
  },
  {
    "text": "your code is and I'll show you a couple of examples and how can appreciate that in advance try to",
    "start": "545020",
    "end": "550410"
  },
  {
    "text": "figure out what the the best-case performance can be for doing a certain kind of thing and how to use this port",
    "start": "550410",
    "end": "556110"
  },
  {
    "text": "at once if we can now Intel have this",
    "start": "556110",
    "end": "561180"
  },
  {
    "text": "process where by understanding how the processor works you can look at every",
    "start": "561180",
    "end": "566760"
  },
  {
    "text": "single CPU cycle so several billion times per second you can look at what's",
    "start": "566760",
    "end": "572100"
  },
  {
    "text": "happening inside the CPU and try to put it in four buckets what's happening",
    "start": "572100",
    "end": "577620"
  },
  {
    "text": "right now and it's just a very basic flowchart so it starts from was an",
    "start": "577620",
    "end": "582720"
  },
  {
    "text": "additional micro operation allocated for execution so basically did the backend receive",
    "start": "582720",
    "end": "589110"
  },
  {
    "text": "another operation for execution they did a an instruction start to execute now if",
    "start": "589110",
    "end": "596070"
  },
  {
    "start": "595000",
    "end": "595000"
  },
  {
    "text": "yes there are essentially two options for how that happened how that happened one is that an existing operation",
    "start": "596070",
    "end": "603230"
  },
  {
    "text": "completed successfully it's called retirement in Intel parlance so if you have an instruction retired",
    "start": "603230",
    "end": "609840"
  },
  {
    "text": "successfully it means everything is fine you finished an instruction you're starting another instruction this is the",
    "start": "609840",
    "end": "615630"
  },
  {
    "text": "bucket we want to be in or an operation might not have retired even though a new",
    "start": "615630",
    "end": "622470"
  },
  {
    "text": "operation was beginning to execute and this would happen if you tries to",
    "start": "622470",
    "end": "627510"
  },
  {
    "text": "predict what's necessary to execute but in fact it was the wrong prediction it was bad speculation and we'll see where",
    "start": "627510",
    "end": "633960"
  },
  {
    "text": "bad speculation comes in in the next example I'm going to show you so this is not very good",
    "start": "633960",
    "end": "638970"
  },
  {
    "text": "it means the CPU is trying to foresee the future and fail them next if if a",
    "start": "638970",
    "end": "645450"
  },
  {
    "text": "micro app was not retired then a sorry if a micro app was not allocated then we asked why and then",
    "start": "645450",
    "end": "652140"
  },
  {
    "text": "there's two options is it the back end stall or a front end stall so one thing that could happen again going back to",
    "start": "652140",
    "end": "658020"
  },
  {
    "text": "this diagram is that your back end is busy all ports are busy so you can't put",
    "start": "658020",
    "end": "663570"
  },
  {
    "text": "any additional operations in flight and the other option is no the back end is not busy but your front end isn't",
    "start": "663570",
    "end": "670500"
  },
  {
    "text": "capable of pushing more instructions through the pipeline so for example you might have cache misses on the",
    "start": "670500",
    "end": "675690"
  },
  {
    "text": "instruction cache you're trying to read an instruction from memory and you're just waiting for that instruction to",
    "start": "675690",
    "end": "681030"
  },
  {
    "text": "arrive so you have not to do in the meantime so there's four buckets that you could be in this is the",
    "start": "681030",
    "end": "686910"
  },
  {
    "text": "good bucket to be in when I'm retiring completing instructions and if you're not there all the time and no one is",
    "start": "686910",
    "end": "692850"
  },
  {
    "text": "there 100% of the time you can start analyzing y-you can start analyzing why I'm speculating badly or why is my",
    "start": "692850",
    "end": "700110"
  },
  {
    "text": "back-end so busy or why is my front-end not capable of giving me more work to do",
    "start": "700110",
    "end": "705630"
  },
  {
    "text": "and this is the Intel top-down process which the stress and all their tools this is how you're supposed to analyze",
    "start": "705630",
    "end": "711899"
  },
  {
    "text": "performance methodically we don't have time to do this kind of analysis for most of my examples you're just going to",
    "start": "711899",
    "end": "718260"
  },
  {
    "text": "have to assume that we sort of did and now we're just attacking the problem as we identified it but this is the process",
    "start": "718260",
    "end": "724649"
  },
  {
    "text": "to do so let's start with a couple of examples that illustrate the way the CPU",
    "start": "724649",
    "end": "730680"
  },
  {
    "text": "works these are just highlights and then I'll have some examples of actual code",
    "start": "730680",
    "end": "735810"
  },
  {
    "text": "that we're going to look at look at it in more detail so this is a stack overflow question with an astounding 16",
    "start": "735810",
    "end": "743040"
  },
  {
    "text": "K uploads and almost 8,000 stars and I",
    "start": "743040",
    "end": "748320"
  },
  {
    "start": "745000",
    "end": "745000"
  },
  {
    "text": "bet some of you have seen this before could you raise your hand if you did okay awesome so why is it faster to",
    "start": "748320",
    "end": "754290"
  },
  {
    "text": "process a sorted array than an unsorted array here's some code I don't understand what's happening",
    "start": "754290",
    "end": "759390"
  },
  {
    "text": "indeed if you look at the two code snippets this is what you see it's",
    "start": "759390",
    "end": "764699"
  },
  {
    "text": "essentially the same code which goes over an array of numbers and adds",
    "start": "764699",
    "end": "771839"
  },
  {
    "text": "together all the numbers greater than or equal to 128 now in the first case the",
    "start": "771839",
    "end": "777990"
  },
  {
    "text": "array is called sorted and the other case is called unsorted and that reflects reality the sort that one is",
    "start": "777990",
    "end": "784230"
  },
  {
    "text": "sorted and it turns out that going through the sorted array takes 18",
    "start": "784230",
    "end": "790500"
  },
  {
    "text": "something units time units and the unsorted array takes 121 this is not",
    "start": "790500",
    "end": "797850"
  },
  {
    "text": "from the stack overflow question this is from an actual benchmark I executed at the end of the talk I have a github repo",
    "start": "797850",
    "end": "803490"
  },
  {
    "text": "link where you can reproduce all of this so it's it's nine times now thirty-six",
    "start": "803490",
    "end": "809670"
  },
  {
    "text": "times faster or even a little more to go through the sort of the array than the unsorted one",
    "start": "809670",
    "end": "815850"
  },
  {
    "text": "and there is just one explanation for this which has to do with branch prediction it has to do with the CPUs",
    "start": "815850",
    "end": "821550"
  },
  {
    "text": "ability to figure out what the next instruction is going to be and whenever you see a branch it's incredibly",
    "start": "821550",
    "end": "827910"
  },
  {
    "text": "important for the processor to make a good prediction whenever the processor sees a branch it tries to guess what the result for the",
    "start": "827910",
    "end": "834840"
  },
  {
    "text": "outcome of that branch is going to be of the conditional check and so in the sorted array just think about it once we",
    "start": "834840",
    "end": "842220"
  },
  {
    "text": "start making a certain branch we're never going to stop so we go through the",
    "start": "842220",
    "end": "847350"
  },
  {
    "text": "array once we reach 128 we're always going to take the same branch and before",
    "start": "847350",
    "end": "852780"
  },
  {
    "text": "we reached 128 we were always taking the same branch so there's just one inflection point where we change your",
    "start": "852780",
    "end": "858840"
  },
  {
    "text": "mind but otherwise the CPU should be fairly easily able to figure out the",
    "start": "858840",
    "end": "863910"
  },
  {
    "text": "pattern and just start guessing correctly every single time so the CPU can speculate and start executing",
    "start": "863910",
    "end": "870150"
  },
  {
    "text": "additional instructions even more than one ahead and it never fails almost",
    "start": "870150",
    "end": "875700"
  },
  {
    "text": "never fails whereas in the unsorted case we really have no idea what the pattern is going to be the data could be totally",
    "start": "875700",
    "end": "882870"
  },
  {
    "text": "random numbers in any range and then we could make a guess it would work it",
    "start": "882870",
    "end": "888660"
  },
  {
    "text": "wouldn't work there's really no way to know and the processor keeps doing unnecessary work never being able to",
    "start": "888660",
    "end": "894750"
  },
  {
    "text": "progress a lot of elements at once before this information is known before",
    "start": "894750",
    "end": "900150"
  },
  {
    "text": "we actually know what the result of the branch is going to be and this is an incredible result this amazing",
    "start": "900150",
    "end": "905940"
  },
  {
    "text": "difference between going through the source array in an unsorted one is really only explained by this phenomenon",
    "start": "905940",
    "end": "912330"
  },
  {
    "text": "where the CPU tries to speculate and if it speculates correctly you gain a lot of performance and if it doesn't you",
    "start": "912330",
    "end": "919050"
  },
  {
    "text": "lose a lot of performance so that's just one demonstration like I said we'll have some more sophisticated",
    "start": "919050",
    "end": "924980"
  },
  {
    "text": "examples coming up later another example which I wanted to share with you has to",
    "start": "924980",
    "end": "930960"
  },
  {
    "text": "do with this concept of using the CPU execution units more effectively which I",
    "start": "930960",
    "end": "936480"
  },
  {
    "text": "talked about earlier so the top loop over here is the very simple",
    "start": "936480",
    "end": "941700"
  },
  {
    "text": "implementation of min/max so you have an array of numbers and you want to find the minimum and the maximum values at once going through the whole",
    "start": "941700",
    "end": "948870"
  },
  {
    "text": "thing just once so this is really nothing to see here and then some you know efficient",
    "start": "948870",
    "end": "956600"
  },
  {
    "text": "developer decided to optimize this thing and so that we write the code so that",
    "start": "956600",
    "end": "962450"
  },
  {
    "text": "maybe more execution units in the CPU would be able to do some work at the",
    "start": "962450",
    "end": "968270"
  },
  {
    "text": "same time now what happens here is that essentially we go through the array two elements at a time and we keep two",
    "start": "968270",
    "end": "975680"
  },
  {
    "text": "counters for the minimum values and two counters for the maximum values so we basically go over the even and odd",
    "start": "975680",
    "end": "983030"
  },
  {
    "start": "979000",
    "end": "979000"
  },
  {
    "text": "elements separately and then at the end we just you know figure out which was",
    "start": "983030",
    "end": "988790"
  },
  {
    "text": "the biggest and which was the smallest of these two minimums and maximums we found and this is supposedly might be",
    "start": "988790",
    "end": "997340"
  },
  {
    "text": "better right maybe because in theory there is more work for the CPU to do in",
    "start": "997340",
    "end": "1003250"
  },
  {
    "text": "each iteration so there's potentially fewer branches and better chances of",
    "start": "1003250",
    "end": "1009220"
  },
  {
    "text": "predicting what's supposed to happen unfortunately it is slower the optimized",
    "start": "1009220",
    "end": "1015580"
  },
  {
    "text": "version and not by one or two percent it is considerably slower and so you might",
    "start": "1015580",
    "end": "1021700"
  },
  {
    "text": "be saying okay well this is just all garbage and you really can't figure out what the CPU is doing and there's it's",
    "start": "1021700",
    "end": "1027939"
  },
  {
    "text": "worth less this whole thing let's go home and then you look at the actual generated program at least what the",
    "start": "1027940",
    "end": "1034300"
  },
  {
    "text": "c-sharp compiler plus the dotnet just-in-time compiler generated from this actual benchmark and so if you see",
    "start": "1034300",
    "end": "1040750"
  },
  {
    "text": "the the simple loop the first one is well it's assembly language but it's",
    "start": "1040750",
    "end": "1045880"
  },
  {
    "text": "very very short and simple to understand it's basically comparing and then",
    "start": "1045880",
    "end": "1051250"
  },
  {
    "text": "branching comparing and branching to find the minimum and maximum update them and move on to the next iteration the",
    "start": "1051250",
    "end": "1057460"
  },
  {
    "text": "whole thing is pretty small and Intel processors have a dedicated optimization",
    "start": "1057460",
    "end": "1063130"
  },
  {
    "text": "for loops that are particularly small there is a thing called loop stream detector which if it sees that you have",
    "start": "1063130",
    "end": "1069880"
  },
  {
    "text": "a loop fewer than a certain number of micro ops some special sauce magic kicks",
    "start": "1069880",
    "end": "1075280"
  },
  {
    "text": "in and makes things even faster I know this is not a very formal explanation but this is sort of what happens",
    "start": "1075280",
    "end": "1081530"
  },
  {
    "text": "whereas the optimized version is one a lot bigger and more difficult to",
    "start": "1081530",
    "end": "1087230"
  },
  {
    "text": "understand maybe which again sort of prohibits the look stream detector from",
    "start": "1087230",
    "end": "1095030"
  },
  {
    "text": "taking place but also the red pieces here arrange checks essentially the",
    "start": "1095030",
    "end": "1101270"
  },
  {
    "text": "just-in-time compiler could figure out in this example that my array accesses",
    "start": "1101270",
    "end": "1107480"
  },
  {
    "text": "here here here and here are safe and that I'm not stepping outside the bounds",
    "start": "1107480",
    "end": "1113540"
  },
  {
    "text": "of that array and since it wasn't able it wasn't able to figure that out and",
    "start": "1113540",
    "end": "1119840"
  },
  {
    "text": "indeed these accesses might not be safe the I plus ones might not be safe and",
    "start": "1119840",
    "end": "1126080"
  },
  {
    "text": "within the bounds of the array there are range checks here which would throw an exception if I step out of bounds but",
    "start": "1126080",
    "end": "1133550"
  },
  {
    "text": "obviously the checks have a cost even if I'm not actually stepping out of bounds and that's those things up so it's not",
    "start": "1133550",
    "end": "1141380"
  },
  {
    "text": "just the shorter code the shorter loops it is also these range checks which",
    "start": "1141380",
    "end": "1147050"
  },
  {
    "text": "would happen in the optimized case so this is just another anecdote of trying",
    "start": "1147050",
    "end": "1153620"
  },
  {
    "text": "to optimize for something you think about the CPU and failing this is also and there's also an important lesson to",
    "start": "1153620",
    "end": "1159080"
  },
  {
    "start": "1159000",
    "end": "1159000"
  },
  {
    "text": "be learned here a final example before we actually dive into the more serious optimization work this is a",
    "start": "1159080",
    "end": "1166660"
  },
  {
    "text": "vectorization so on top you see the same min max algorithm which just you know",
    "start": "1166660",
    "end": "1173090"
  },
  {
    "text": "works on a single int at a time and then a vectorized version which uses vector",
    "start": "1173090",
    "end": "1179870"
  },
  {
    "text": "instructions and I'll explain what vector instructions are shortly and this version that's the important result this",
    "start": "1179870",
    "end": "1186410"
  },
  {
    "text": "version works in 1/5 of the time so it's 5 times faster to do this and calculate",
    "start": "1186410",
    "end": "1192710"
  },
  {
    "text": "the minimum and maximum values than to do this and this is on a single CPU this",
    "start": "1192710",
    "end": "1197960"
  },
  {
    "text": "is on a single core there is no parallelization there's no multiple threads it's just somehow magically",
    "start": "1197960",
    "end": "1203030"
  },
  {
    "text": "squeezing out more from the same execution units we have on a single core",
    "start": "1203030",
    "end": "1209140"
  },
  {
    "text": "whereas similarly we could have just paralyzed the whole thing",
    "start": "1209140",
    "end": "1214350"
  },
  {
    "text": "we could have taken the original loop with the min and Max and we could have used something like parallel four to",
    "start": "1214350",
    "end": "1220590"
  },
  {
    "start": "1218000",
    "end": "1218000"
  },
  {
    "text": "create multiple threads which would run on multiple cores and that would also speed things up hopefully and the lovely",
    "start": "1220590",
    "end": "1228299"
  },
  {
    "text": "thing is you can combine both effects I do not have a benchmark here for this but if you look at the results by using",
    "start": "1228299",
    "end": "1235549"
  },
  {
    "text": "vector instructions we speed things up by roughly 5 and by using",
    "start": "1235549",
    "end": "1240600"
  },
  {
    "text": "parallelization without vector instructions we speed things up by about two and a half and hopefully if we apply",
    "start": "1240600",
    "end": "1248639"
  },
  {
    "text": "both vectorization here and fertilization over here we could get a a",
    "start": "1248639",
    "end": "1254009"
  },
  {
    "text": "nice avalanche effect and we'll see in indeed in some cases we will so that was",
    "start": "1254009",
    "end": "1260190"
  },
  {
    "text": "just the exposition different facets of the processor we might be trying to take advantage of so the branch prediction",
    "start": "1260190",
    "end": "1266580"
  },
  {
    "text": "mechanisms what happens inside the CPU execution units trying to have them run at once vectorization parallelization a",
    "start": "1266580",
    "end": "1273750"
  },
  {
    "text": "bunch of things we'll be looking at concrete examples of in the next 3040 minutes all right",
    "start": "1273750",
    "end": "1280200"
  },
  {
    "text": "so we'll start with vectorization because indeed it's one of the key things Intel have been stressing for a",
    "start": "1280200",
    "end": "1287039"
  },
  {
    "text": "few years now trying to tell people you understand parallelization you understand how to write multi-core",
    "start": "1287039",
    "end": "1293429"
  },
  {
    "text": "programs this is all well this is all fun but you really have to understand what's happening in a single core and",
    "start": "1293429",
    "end": "1299159"
  },
  {
    "text": "you have to speed things up there before you move to additional cores and parallel life so essentially Intel",
    "start": "1299159",
    "end": "1306299"
  },
  {
    "text": "processors have had for many years since the very beginning classic instructions as I call them here",
    "start": "1306299",
    "end": "1312480"
  },
  {
    "text": "which operate on single values like a single float or maybe two floats or",
    "start": "1312480",
    "end": "1319409"
  },
  {
    "text": "maybe two in that kind of thing some examples this instruction here add adds",
    "start": "1319409",
    "end": "1325289"
  },
  {
    "text": "two integers together this instruction here move copies a single integer to",
    "start": "1325289",
    "end": "1331289"
  },
  {
    "text": "another location this instruction MO multiplies two floating point numbers that's the kind",
    "start": "1331289",
    "end": "1337409"
  },
  {
    "text": "of thing you expect CPU instructions to do right that's what you learn when you learn assembly language",
    "start": "1337409",
    "end": "1344129"
  },
  {
    "text": "Sindhi or single instruction multiple data are in store actions that Intel have had for like 15",
    "start": "1344129",
    "end": "1350190"
  },
  {
    "text": "years now and again have been stressing more recently because a lot of advances",
    "start": "1350190",
    "end": "1355200"
  },
  {
    "text": "have been made in last few years and seeing the instructions operate on multiple values at once multiple",
    "start": "1355200",
    "end": "1361740"
  },
  {
    "text": "elements multiple insert floats what-have-you examples add PS is an",
    "start": "1361740",
    "end": "1367710"
  },
  {
    "text": "instruction that adds four floats to another four floats and produces four",
    "start": "1367710",
    "end": "1374760"
  },
  {
    "text": "results so it does an element-wise add of a total of four floats and another",
    "start": "1374760",
    "end": "1381240"
  },
  {
    "text": "couple of four floats producing a couple of four results it's pretty nice for a",
    "start": "1381240",
    "end": "1386400"
  },
  {
    "text": "single instruction assuming it works as fast as the standard ad which we'll see",
    "start": "1386400",
    "end": "1392039"
  },
  {
    "text": "later and then you have something like V mo PS which is an instruction that",
    "start": "1392039",
    "end": "1397350"
  },
  {
    "text": "multiplies eight floats by eight floats producing eight floating point results",
    "start": "1397350",
    "end": "1404789"
  },
  {
    "text": "and in very recent Intel CPUs like the Knights landing I've shown you they also",
    "start": "1404789",
    "end": "1411059"
  },
  {
    "text": "have instructions operating on sixteen floats and sixteen floats producing",
    "start": "1411059",
    "end": "1416820"
  },
  {
    "text": "sixteen floating point results if you work with doubles it's obviously half the size so for example there is a Remo",
    "start": "1416820",
    "end": "1423990"
  },
  {
    "text": "instruction that works on doubles and it takes a total of four doubles and another four doubles and produces four",
    "start": "1423990",
    "end": "1430500"
  },
  {
    "text": "products four double products so these are pretty cool instructions and there's hundreds of them here's a list of",
    "start": "1430500",
    "end": "1437940"
  },
  {
    "start": "1435000",
    "end": "1435000"
  },
  {
    "text": "categories it's definitely not a list of instructions just some of the things you have instructions for so obviously basic",
    "start": "1437940",
    "end": "1444210"
  },
  {
    "text": "operations add multiply shift operations compare is pretty important and we'll",
    "start": "1444210",
    "end": "1450990"
  },
  {
    "text": "use that little later comparing large regions of memory conversions",
    "start": "1450990",
    "end": "1456740"
  },
  {
    "text": "surprisingly converting into floats and vice versa is a pretty expensive thing",
    "start": "1456740",
    "end": "1462450"
  },
  {
    "text": "to do I've seen code where 20 30 40 % of the time is spent converting so if you",
    "start": "1462450",
    "end": "1468270"
  },
  {
    "text": "can speed that up it's pretty useful cryptography including hashing as well",
    "start": "1468270",
    "end": "1474120"
  },
  {
    "text": "CRC check sums that kind of thing various math functions like exponentiation",
    "start": "1474120",
    "end": "1480669"
  },
  {
    "text": "frig that kind of thing memory operations reading and writing to memory and finally string operations as well",
    "start": "1480669",
    "end": "1487929"
  },
  {
    "text": "like searching in a string that's something we're going to explore a little later now there's really a great",
    "start": "1487929",
    "end": "1493359"
  },
  {
    "text": "variety of these instructions available in modern processors and the question is why is it even worth the effort so I",
    "start": "1493359",
    "end": "1501039"
  },
  {
    "text": "have the EDPs which operates on multiple values at once is it faster than just",
    "start": "1501039",
    "end": "1506980"
  },
  {
    "text": "doing several of these classic instructions one of the other so hopefully you realize the answer is",
    "start": "1506980",
    "end": "1513220"
  },
  {
    "text": "yes but I still do have to convince you in some way so when looking at instruction performance we typically",
    "start": "1513220",
    "end": "1519850"
  },
  {
    "start": "1515000",
    "end": "1515000"
  },
  {
    "text": "look at two aspects one is latency which is time from start to finish you start",
    "start": "1519850",
    "end": "1525580"
  },
  {
    "text": "executing the instruction how soon is the result going to be available and the other aspect is throughput and that's a",
    "start": "1525580",
    "end": "1532899"
  },
  {
    "text": "little trickier to explain so let's start with latency here I'm looking at two instructions ad which adds a pair of",
    "start": "1532899",
    "end": "1540340"
  },
  {
    "text": "integers and P a DDD which adds tuples",
    "start": "1540340",
    "end": "1545350"
  },
  {
    "text": "of four integers each so it does four times the work it adds four pairs of M's instead of",
    "start": "1545350",
    "end": "1552730"
  },
  {
    "text": "just one person pair of ins in terms of latency start to finish both take one cycle which is pretty cool you can do in",
    "start": "1552730",
    "end": "1560710"
  },
  {
    "text": "one cycle what you would need four instructions in if you weren't using Cindy throughput on the other hand is a",
    "start": "1560710",
    "end": "1568149"
  },
  {
    "text": "little trickier and throughput has to do with the CPUs ability to execute multiple instructions of the same kind",
    "start": "1568149",
    "end": "1575139"
  },
  {
    "text": "at once remember we have multiple execution units if we have multiple units capable of doing the same thing we",
    "start": "1575139",
    "end": "1582309"
  },
  {
    "text": "can actually issue multiple instructions in a single cycle so what could happen is that in the period of a single cycle",
    "start": "1582309",
    "end": "1589869"
  },
  {
    "text": "I could have multiple instructions completing because I have multiple units where they could be executing so if I",
    "start": "1589869",
    "end": "1596919"
  },
  {
    "text": "have a constant flow of add instructions going into the processor because I have",
    "start": "1596919",
    "end": "1602830"
  },
  {
    "text": "a lot of data a lot of numbers to add I can actually finish three ads in a",
    "start": "1602830",
    "end": "1608109"
  },
  {
    "text": "single cycle by multiplexing them and so the throughput for add if you have a lot",
    "start": "1608109",
    "end": "1614019"
  },
  {
    "text": "of ADD is three per cycle which is very impressive the throughput for PA DDD is",
    "start": "1614019",
    "end": "1619840"
  },
  {
    "text": "just two per cycle but it does four times more work so it's still worth it to use the vector version rather than",
    "start": "1619840",
    "end": "1627429"
  },
  {
    "text": "the classic scalar one and this is the the key lesson to learn about vector",
    "start": "1627429",
    "end": "1632890"
  },
  {
    "text": "operations they are usually as fast or close to the non vector counterpart but",
    "start": "1632890",
    "end": "1639640"
  },
  {
    "text": "they do four times eight times and sometimes 16 times as much work which",
    "start": "1639640",
    "end": "1645820"
  },
  {
    "text": "means you typically can squeeze out of a single core four times eight times 16",
    "start": "1645820",
    "end": "1651010"
  },
  {
    "text": "times more operations if you use vector instructions now here's an example of",
    "start": "1651010",
    "end": "1656169"
  },
  {
    "text": "how to actually apply this in dotnet in c-sharp to a real practical interesting",
    "start": "1656169",
    "end": "1661510"
  },
  {
    "text": "problem I know it's a little theoretical but it's an algorithm that's at the heart of a lot of stuff a lot of",
    "start": "1661510",
    "end": "1667690"
  },
  {
    "text": "libraries image-processing a bunch of machine learning algorithms lots and",
    "start": "1667690",
    "end": "1673210"
  },
  {
    "text": "lots of stuff uses matrix multiplication and it's the classic example for vector",
    "start": "1673210",
    "end": "1678429"
  },
  {
    "text": "operations so this is the one I'm going to start with but I have several more interesting examples coming up later so",
    "start": "1678429",
    "end": "1685840"
  },
  {
    "text": "here's a just naive matrix multiplication I have three of them a B",
    "start": "1685840",
    "end": "1692679"
  },
  {
    "text": "and C and assume for a moment they're all the same size just to simplify so",
    "start": "1692679",
    "end": "1699220"
  },
  {
    "text": "what happens is I have three loops and the core of the inner loop is is this it",
    "start": "1699220",
    "end": "1704340"
  },
  {
    "text": "multiplies two values from a and B and put the result in C which is the output",
    "start": "1704340",
    "end": "1710559"
  },
  {
    "text": "matrix the vectorized version looks like this I still have three nested loops four",
    "start": "1710559",
    "end": "1716710"
  },
  {
    "text": "four four ika and J but instead of multiplying and adding just floats I'm",
    "start": "1716710",
    "end": "1724570"
  },
  {
    "text": "working with a type called vector afloat which is a new type that Microsoft introduced with dot at four point six it",
    "start": "1724570",
    "end": "1731529"
  },
  {
    "start": "1729000",
    "end": "1729000"
  },
  {
    "text": "is part of a new gate package called system numerix vectors which again it's",
    "start": "1731529",
    "end": "1738970"
  },
  {
    "text": "been available for over a year now but it's still not as popular as I would like it to be and it gives you from",
    "start": "1738970",
    "end": "1744460"
  },
  {
    "text": "c-sharp programs access to vectors which was not available before you could",
    "start": "1744460",
    "end": "1750140"
  },
  {
    "text": "do this in C or C++ if you wanted to do is from pure c-sharp you couldn't you just have to do inter",
    "start": "1750140",
    "end": "1756410"
  },
  {
    "text": "up and talked to some native code so basically this vector type represents",
    "start": "1756410",
    "end": "1761620"
  },
  {
    "text": "the biggest chunk of floats that your processor is capable of operating on so",
    "start": "1761620",
    "end": "1769070"
  },
  {
    "text": "on some processors particularly older ones vector afloat would only have room",
    "start": "1769070",
    "end": "1774350"
  },
  {
    "text": "for four floats but the newer processors it might have room for eight floats and in some very recent processors for",
    "start": "1774350",
    "end": "1782060"
  },
  {
    "text": "sixteen floats and maybe in some future processor first thirty-two floats the",
    "start": "1782060",
    "end": "1787250"
  },
  {
    "text": "key part is you don't care you just work with this vector of float type which also has a size you can read here vector",
    "start": "1787250",
    "end": "1795230"
  },
  {
    "text": "afloat load count is a static property that tells you just how many floats would fit in a vector of float and so",
    "start": "1795230",
    "end": "1802400"
  },
  {
    "text": "all your operations are now going to be using vector of floats so I read from a and I read from B and I read from C and",
    "start": "1802400",
    "end": "1809360"
  },
  {
    "text": "then here's the actual work multiplying and adding vectors rather than scalar",
    "start": "1809360",
    "end": "1816620"
  },
  {
    "text": "single floats and what happens in this single line is that I'm multiplying and",
    "start": "1816620",
    "end": "1822290"
  },
  {
    "text": "adding four total floats or eight couple floats again it all depends on my actual",
    "start": "1822290",
    "end": "1828710"
  },
  {
    "text": "processor at runtime when I write this c-sharp program I do not commit to the",
    "start": "1828710",
    "end": "1833720"
  },
  {
    "text": "actual processor which is again pretty cool because if you do use your C++ you",
    "start": "1833720",
    "end": "1839390"
  },
  {
    "text": "typically would compile your code in a certain platform and you would get code which would execute only on these",
    "start": "1839390",
    "end": "1845240"
  },
  {
    "text": "processors so with this system numeric selectors support in.net you can",
    "start": "1845240",
    "end": "1850910"
  },
  {
    "text": "actually run code that would be sort of flexible and work on different vector sizes different processor generations is",
    "start": "1850910",
    "end": "1858650"
  },
  {
    "text": "it worth anything in terms of speed so here at the benchmark results it's roughly a five and a half times faster",
    "start": "1858650",
    "end": "1865400"
  },
  {
    "text": "on the core I measured it on which is just a plain standard Intel i7 nothing",
    "start": "1865400",
    "end": "1873080"
  },
  {
    "text": "fancy definitely not a 72 core monster it's a $300 or processor so this is",
    "start": "1873080",
    "end": "1879050"
  },
  {
    "text": "pretty impressive speeding up matrix multiplication which is such a core operation a lot of algorithms by just",
    "start": "1879050",
    "end": "1885109"
  },
  {
    "text": "using some slightly different API for multiplying and adding numbers which are",
    "start": "1885109",
    "end": "1890479"
  },
  {
    "text": "pretty fundamental operations turns out you can do them a lot faster if you have a lot of numbers to multiply and to add",
    "start": "1890479",
    "end": "1896859"
  },
  {
    "text": "so all this code as I said is available online which you can test later as well",
    "start": "1896859",
    "end": "1902149"
  },
  {
    "text": "in the meantime take a look at something intel has apparently been working on so this is from sort of rumors but",
    "start": "1902149",
    "end": "1909349"
  },
  {
    "text": "substantiate that rumors from online Intel is supposedly going to add an instruction with this lovely name v4 FMA",
    "start": "1909349",
    "end": "1917169"
  },
  {
    "text": "DDPs in some future generation Intel processor and it's going to have the",
    "start": "1917169",
    "end": "1922279"
  },
  {
    "text": "following so to say still tax where you would give it something called zmm zero",
    "start": "1922279",
    "end": "1929359"
  },
  {
    "text": "which for example in our case could be 16 floats a total of 16 floats you would",
    "start": "1929359",
    "end": "1935539"
  },
  {
    "text": "also give it four tuples of 16 floats so a total of 64 floats in here and 16",
    "start": "1935539",
    "end": "1943789"
  },
  {
    "text": "floats in there and you will give it a memory location and then what it does is",
    "start": "1943789",
    "end": "1948859"
  },
  {
    "text": "describe here this is all just one instruction this is what it does and I mean don't really follow the whole thing",
    "start": "1948859",
    "end": "1955069"
  },
  {
    "text": "but look at what happens here it multiplies something from here by something read from memory and as the",
    "start": "1955069",
    "end": "1962239"
  },
  {
    "text": "result to this one here and then it goes on and read from another memory location",
    "start": "1962239",
    "end": "1967669"
  },
  {
    "text": "and again multiplies something from here by that value from memory and add that to this one here and it repeats this",
    "start": "1967669",
    "end": "1974929"
  },
  {
    "text": "whole thing four times and this looks suspiciously like matrix multiplication",
    "start": "1974929",
    "end": "1980479"
  },
  {
    "text": "like the core of that inner loop over here which adds and then very multiplies",
    "start": "1980479",
    "end": "1986029"
  },
  {
    "text": "and then adds this is what this instruction probably is intended for so",
    "start": "1986029",
    "end": "1991429"
  },
  {
    "text": "Intel is going to apparently add an instruction with just one obvious design goal to make matrix multiplication",
    "start": "1991429",
    "end": "1998779"
  },
  {
    "text": "faster because it is so important and in this case it would make matrix",
    "start": "1998779",
    "end": "2004209"
  },
  {
    "text": "multiplication a lot faster because you would be able to avoid certain memory accesses as well to more efficient",
    "start": "2004209",
    "end": "2011319"
  },
  {
    "text": "memory accesses so this is potentially going to speed up it's multiplication even more so Intel",
    "start": "2011319",
    "end": "2018529"
  },
  {
    "text": "is working on their side of the problem by adding even more clever instructions",
    "start": "2018529",
    "end": "2023690"
  },
  {
    "text": "and we have to work on our side which is applying these instructions actually using them for our work so I'm going to",
    "start": "2023690",
    "end": "2030350"
  },
  {
    "start": "2029000",
    "end": "2029000"
  },
  {
    "text": "show you a couple more examples of using vectorization and then some examples from different domains as well so here's",
    "start": "2030350",
    "end": "2037249"
  },
  {
    "text": "a problem which is again interesting in certain areas it's sort of confusing",
    "start": "2037249",
    "end": "2042529"
  },
  {
    "text": "because the problem is vector normalization and we are going to vectorize vector normalization but whatever what we're trying to do is we",
    "start": "2042529",
    "end": "2050780"
  },
  {
    "text": "have a collection of 3d vectors a collection of points in three-dimensional space and what we're",
    "start": "2050780",
    "end": "2056839"
  },
  {
    "text": "trying to do is normalize them by dividing each component of the point the",
    "start": "2056839",
    "end": "2062599"
  },
  {
    "text": "x y&z by the norm of that vector so basically this is called normalization",
    "start": "2062599",
    "end": "2068300"
  },
  {
    "text": "this is what we're doing and the calculation is pretty simple you multiply a bunch of things you take the",
    "start": "2068300",
    "end": "2074419"
  },
  {
    "text": "square root and then you divide the X the Y and the Z by that norm this is",
    "start": "2074419",
    "end": "2079790"
  },
  {
    "text": "what you do in each iteration over a bunch of points all right so here's the",
    "start": "2079790",
    "end": "2085730"
  },
  {
    "text": "vectorized version and this one actually takes a little work because the way the data is represented over here is",
    "start": "2085730",
    "end": "2093158"
  },
  {
    "text": "essentially tuples of XY and z but the operations I want to vectorize are going",
    "start": "2093159",
    "end": "2099109"
  },
  {
    "text": "to go over all the X's and all the Y's and all disease so it's actually going to be easier if instead of an array of",
    "start": "2099109",
    "end": "2107200"
  },
  {
    "text": "points I had three arrays of X's YS and",
    "start": "2107200",
    "end": "2112339"
  },
  {
    "text": "Z's three arrays instead of an array of structures that has three components",
    "start": "2112339",
    "end": "2117730"
  },
  {
    "text": "where each structure has three components so once you do this refactoring and you have X's Y's and Z's",
    "start": "2117730",
    "end": "2126280"
  },
  {
    "start": "2121000",
    "end": "2121000"
  },
  {
    "text": "instead of a single array you can vectorize the whole thing pretty easily you read the XS you read the Y Z we",
    "start": "2126280",
    "end": "2132740"
  },
  {
    "text": "disease and each of these XY and Z is not a single float it's a bunch of",
    "start": "2132740",
    "end": "2138740"
  },
  {
    "text": "floats and then you can multiply them like floats and you can extract the",
    "start": "2138740",
    "end": "2143750"
  },
  {
    "text": "square root like floats but this is all vectors this is all tuple of floats and then you can divide the X",
    "start": "2143750",
    "end": "2151920"
  },
  {
    "text": "the Y and the Z by that calculated result which is still a vector these are vectors and then you can copy the",
    "start": "2151920",
    "end": "2158460"
  },
  {
    "text": "results back to the arrays and this is all roughly four times faster than the",
    "start": "2158460",
    "end": "2164460"
  },
  {
    "text": "original algorithm which is again sort of worth the effort it's not 5% speed up",
    "start": "2164460",
    "end": "2169470"
  },
  {
    "text": "by refactoring and complicating the code it's a four-fold speed-up which is hopefully for most users worth the",
    "start": "2169470",
    "end": "2175950"
  },
  {
    "text": "effort even if I had sorry even if I had to actually copy the data from the",
    "start": "2175950",
    "end": "2183690"
  },
  {
    "text": "original array to X's YS and Z's separately and then copy all the results",
    "start": "2183690",
    "end": "2189210"
  },
  {
    "text": "back it might still be worth the effort because we're gaining so much speed by just doing vectorization here yes okay",
    "start": "2189210",
    "end": "2199250"
  },
  {
    "text": "right another example from the same domain which I'm not going to mull over for long it's just another application",
    "start": "2199250",
    "end": "2206550"
  },
  {
    "start": "2201000",
    "end": "2201000"
  },
  {
    "text": "of the same principle this is the end body simulation you have",
    "start": "2206550",
    "end": "2212330"
  },
  {
    "text": "objects in three-dimensional space and you have gravity forces acting on these objects right they're applying forces to",
    "start": "2212330",
    "end": "2219300"
  },
  {
    "text": "each other so each particle or each object in your space has a mass a",
    "start": "2219300",
    "end": "2224820"
  },
  {
    "text": "velocity acceleration a bunch of a position obviously and you're trying to",
    "start": "2224820",
    "end": "2230010"
  },
  {
    "text": "simulate their movement which can be useful for anything for computer games or you know actual space simulations but",
    "start": "2230010",
    "end": "2239010"
  },
  {
    "text": "again the interesting thing is you probably have an array of structures you",
    "start": "2239010",
    "end": "2244560"
  },
  {
    "text": "have an array where each component is a particle or an object and to vectorize",
    "start": "2244560",
    "end": "2251280"
  },
  {
    "text": "you would probably be better suited if you had a bunch of arrays with each",
    "start": "2251280",
    "end": "2256830"
  },
  {
    "text": "component laid out sequentially so instead of having a huge array where you",
    "start": "2256830",
    "end": "2262770"
  },
  {
    "text": "have all the values for the first particle and then all the values for the second particle you'd rather have an array with all the",
    "start": "2262770",
    "end": "2270030"
  },
  {
    "text": "X's and all the Y's and all disease and all the velocity X's and so on so you",
    "start": "2270030",
    "end": "2275250"
  },
  {
    "text": "could operate on these arrays rather than the whole particle I don't have the",
    "start": "2275250",
    "end": "2280640"
  },
  {
    "text": "to vectorize code here it's just another application of the same principle of converting from an array of structures",
    "start": "2280640",
    "end": "2287119"
  },
  {
    "text": "an array of particles here to a structure of arrays to a bunch of arrays",
    "start": "2287119",
    "end": "2292640"
  },
  {
    "text": "with each structures component individually laid out in memory so it's slightly different memory layout which",
    "start": "2292640",
    "end": "2298970"
  },
  {
    "text": "lets you speed things up okay so I have two more examples which are not so",
    "start": "2298970",
    "end": "2305019"
  },
  {
    "text": "mathematical or physical this could actually be pretty useful in databases for example full-text search queries",
    "start": "2305019",
    "end": "2312740"
  },
  {
    "text": "that kind of thing indexing the web here we're trying to optimize STR STR which",
    "start": "2312740",
    "end": "2318230"
  },
  {
    "text": "for C developers is pretty is pretty familiar it's basically substring search so the C",
    "start": "2318230",
    "end": "2325069"
  },
  {
    "text": "short version you know no frills is just take a string and coal contains string",
    "start": "2325069",
    "end": "2331309"
  },
  {
    "text": "has a method called contains which finds if a string is a substring of that original string so haystack contains",
    "start": "2331309",
    "end": "2337640"
  },
  {
    "text": "needle and then here's the vectorized version which unfortunately we cannot",
    "start": "2337640",
    "end": "2342680"
  },
  {
    "text": "yet express in pure c-sharp so what I did for the benchmark I wrote it in C",
    "start": "2342680",
    "end": "2348289"
  },
  {
    "text": "and then the benchmark actually T invokes it does interrupt to call that version written in C so we're paying for",
    "start": "2348289",
    "end": "2355130"
  },
  {
    "text": "interrupts and still even though we're paying for interrupts it is nine times",
    "start": "2355130",
    "end": "2360680"
  },
  {
    "text": "faster then the string contains methods which is hopefully implemented in",
    "start": "2360680",
    "end": "2366529"
  },
  {
    "text": "managed code so why is it so faster what is this thing doing here what is this code here with the really scary",
    "start": "2366529",
    "end": "2373730"
  },
  {
    "text": "intrinsics like CMP EQ and load USI 256 the basic idea is illustrated here I",
    "start": "2373730",
    "end": "2380839"
  },
  {
    "start": "2380000",
    "end": "2380000"
  },
  {
    "text": "have my string over here the quick black fox jumped off and so on I put black",
    "start": "2380839",
    "end": "2387799"
  },
  {
    "text": "here because I wanted two K's there I know it's brown and what I'm looking for",
    "start": "2387799",
    "end": "2393410"
  },
  {
    "text": "the string I'm looking for is quick okay so this is the haystack the quake black",
    "start": "2393410",
    "end": "2398690"
  },
  {
    "text": "fox jumped and so on and I'm looking for the substring quick so what I'm doing is",
    "start": "2398690",
    "end": "2404269"
  },
  {
    "text": "I take a vector of characters and I fill it with the first letter of my needle",
    "start": "2404269",
    "end": "2410450"
  },
  {
    "text": "which is Q and I take another vector of care ters and i fill it with the last letter",
    "start": "2410450",
    "end": "2416449"
  },
  {
    "text": "of my needle which is K so I'm looking for quick so Q and K and then what I do",
    "start": "2416449",
    "end": "2421699"
  },
  {
    "text": "is I simul taneous Li compare my original string with this vector of Q's",
    "start": "2421699",
    "end": "2429169"
  },
  {
    "text": "and this vector of KS at an offset I know the string I'm looking for is quick",
    "start": "2429169",
    "end": "2434630"
  },
  {
    "text": "so I offset the case by 5 from where the Q start that's all I'm doing I'm just",
    "start": "2434630",
    "end": "2440539"
  },
  {
    "text": "comparing and then the result of that comparison is potential indexes where my",
    "start": "2440539",
    "end": "2447949"
  },
  {
    "text": "substring could start wherever I found the Q in the original string it could be",
    "start": "2447949",
    "end": "2453589"
  },
  {
    "text": "a potential match doesn't have to be but it could be wherever I found the K in",
    "start": "2453589",
    "end": "2458630"
  },
  {
    "text": "the original string could also be a potential match not necessarily it could",
    "start": "2458630",
    "end": "2463989"
  },
  {
    "text": "if both of these match if I found the Q and the K at the right distance from",
    "start": "2463989",
    "end": "2469910"
  },
  {
    "text": "each other it still doesn't mean it's a match but it's a more likely potential match so once I have that kind of",
    "start": "2469910",
    "end": "2476839"
  },
  {
    "text": "candidate I can now check the actual characters I can now compare the the U",
    "start": "2476839",
    "end": "2482209"
  },
  {
    "text": "and the I and the C to see if I have what I needed but first we eliminated a",
    "start": "2482209",
    "end": "2487699"
  },
  {
    "text": "lot of potential places in the string by doing this simultaneous comparison across multiple places in the string so",
    "start": "2487699",
    "end": "2495919"
  },
  {
    "text": "this is the basic idea of this vectorized version this is what it's doing the cmp u eq epi8 is comparing",
    "start": "2495919",
    "end": "2504349"
  },
  {
    "text": "vectors of characters vectors of bytes and finding the places where they're the",
    "start": "2504349",
    "end": "2509599"
  },
  {
    "text": "same and then there's some work on extracting where exactly they are the same and figuring out that we need to",
    "start": "2509599",
    "end": "2516439"
  },
  {
    "text": "take this quick here and compare it with the actual substring we're looking for the result again is pretty impressive",
    "start": "2516439",
    "end": "2523309"
  },
  {
    "start": "2523000",
    "end": "2523000"
  },
  {
    "text": "it's a nine-fold speed-up so think about it if you had a database query and your database could spit that up by 9 just by",
    "start": "2523309",
    "end": "2531259"
  },
  {
    "text": "using vectorization it would be pretty nice so database is obviously would have",
    "start": "2531259",
    "end": "2536449"
  },
  {
    "text": "some use for this kind of thing especially for full-text search here's another example from a somewhat similar",
    "start": "2536449",
    "end": "2543319"
  },
  {
    "text": "domain yes",
    "start": "2543319",
    "end": "2546759"
  },
  {
    "text": "so you're asking like why aren't there libraries that just use this under the covers yeah so right so there's two",
    "start": "2553930",
    "end": "2568190"
  },
  {
    "text": "entrances one is that obviously for some problems there's going to be a library",
    "start": "2568190",
    "end": "2573619"
  },
  {
    "text": "that does this internally and you definitely should use that library rather than using my code or trying to",
    "start": "2573619",
    "end": "2579170"
  },
  {
    "text": "come up with your own Intel in fact have a nice library which which is written in C that has a bunch of vectorized",
    "start": "2579170",
    "end": "2586520"
  },
  {
    "text": "algorithms inside so for example for matrix multiplication you would obviously reach to that rather than implementing your row but some things",
    "start": "2586520",
    "end": "2593180"
  },
  {
    "text": "are just so domain-specific that it would be unlikely to find a library that does that or maybe there is a library",
    "start": "2593180",
    "end": "2600080"
  },
  {
    "text": "but it's for Linux and it uses a Perl and it's interface and you you take the",
    "start": "2600080",
    "end": "2606830"
  },
  {
    "text": "idea from there and just implement it yourself this is tr SD I think I have not come up with this myself I just copy",
    "start": "2606830",
    "end": "2613250"
  },
  {
    "text": "it copied it from some C implementation I found and it's really effective so in",
    "start": "2613250",
    "end": "2618380"
  },
  {
    "text": "some cases it's really worth being able to write these things out yourself but whenever there is a library yep",
    "start": "2618380",
    "end": "2624470"
  },
  {
    "text": "definitely reach out for so here's just one final problem again from sort of a",
    "start": "2624470",
    "end": "2631460"
  },
  {
    "start": "2627000",
    "end": "2627000"
  },
  {
    "text": "database space you have two sorted lists of numbers and you want to find the",
    "start": "2631460",
    "end": "2637730"
  },
  {
    "text": "intersection of these lists you want to find all the elements that are in both lists at once",
    "start": "2637730",
    "end": "2643070"
  },
  {
    "text": "so why is this relevant for anything think about it suppose you have two Cleary's to Google or some database two",
    "start": "2643070",
    "end": "2652490"
  },
  {
    "text": "strings you're looking for to search keywords and then you have a list of results containing the first keywords",
    "start": "2652490",
    "end": "2658310"
  },
  {
    "text": "and you have the list of results containing the second keyword and now we want to find all the overlaps you want",
    "start": "2658310",
    "end": "2663859"
  },
  {
    "text": "to find the terms you want to find sorry the documents that contain both keywords that contain both terms so you have two",
    "start": "2663859",
    "end": "2670520"
  },
  {
    "text": "sorted lists not necessarily of the same length and you're trying to find all the common elements",
    "start": "2670520",
    "end": "2676740"
  },
  {
    "text": "so this is a an interview kind implementation it's a typical interview question it's a loop basically that has",
    "start": "2676740",
    "end": "2684660"
  },
  {
    "text": "two pointers into the lists and it advances the right one and it finds all",
    "start": "2684660",
    "end": "2690330"
  },
  {
    "text": "the overlapping elements think about it nothing to see here and then the vectorized version again",
    "start": "2690330",
    "end": "2697920"
  },
  {
    "text": "requires C because there's a particular instruction here which is not wrapped by",
    "start": "2697920",
    "end": "2703380"
  },
  {
    "text": "the dotnet library yet might be in the future not right now and this is the",
    "start": "2703380",
    "end": "2708390"
  },
  {
    "text": "instruction C and PE sPRM which is essentially implementing set",
    "start": "2708390",
    "end": "2713820"
  },
  {
    "text": "intersection for us it takes two vectors of bytes or characters whatever we",
    "start": "2713820",
    "end": "2719880"
  },
  {
    "text": "prefer shorts or in essentially any length and it finds all the common ones",
    "start": "2719880",
    "end": "2725700"
  },
  {
    "text": "so in our case for example I support us for the purpose of the benchmark I assumed we're looking for short",
    "start": "2725700",
    "end": "2732660"
  },
  {
    "text": "so the actual data is short I have a list of shorts here and list of shorts there so I'm comparing you words to byte",
    "start": "2732660",
    "end": "2741119"
  },
  {
    "text": "elements and this instruction just finds all the overlaps for me and then it's",
    "start": "2741119",
    "end": "2747089"
  },
  {
    "text": "just the work of extracting them essentially there's some work here that has to shuffle the vectors around to",
    "start": "2747089",
    "end": "2754170"
  },
  {
    "text": "find the actual overlapping elements copy them over to the output and then advance again it's not so interesting",
    "start": "2754170",
    "end": "2761400"
  },
  {
    "text": "but the result is interesting it's four times as fast as the original naive",
    "start": "2761400",
    "end": "2767940"
  },
  {
    "text": "version which you might have written an interview so again if we have a way of taking to query results and finding the",
    "start": "2767940",
    "end": "2775349"
  },
  {
    "text": "intersecting elements four times faster I'm sure you'd sign up for that so this",
    "start": "2775349",
    "end": "2780660"
  },
  {
    "text": "is again a pretty nice application of vectorization to something that's closer to the real world than matrices maybe or",
    "start": "2780660",
    "end": "2787410"
  },
  {
    "text": "vector normalization there's a bunch more examples like this literally hundreds of algorithms that have",
    "start": "2787410",
    "end": "2794099"
  },
  {
    "text": "vectorized versions today you definitely don't have in most cases you don't have to come up with your own original work",
    "start": "2794099",
    "end": "2801119"
  },
  {
    "text": "you might find something and then adapt it to your needs or convert or refactor",
    "start": "2801119",
    "end": "2806220"
  },
  {
    "text": "the data you have so that you can apply a vector algorithm to that problem and in some",
    "start": "2806220",
    "end": "2812780"
  },
  {
    "text": "cases you might not get like the most optimal result you will get the theoretical maximum you're capable of",
    "start": "2812780",
    "end": "2818510"
  },
  {
    "text": "extracting from your cpu it get pretty close you'd get 80% with 20% the effort",
    "start": "2818510",
    "end": "2824270"
  },
  {
    "text": "this is pretty respectable ok so these were a lot of examples of vectorization",
    "start": "2824270",
    "end": "2830089"
  },
  {
    "text": "and I want to spend the next few minutes talking about slightly different areas in the CPU that we can be taken",
    "start": "2830089",
    "end": "2836270"
  },
  {
    "start": "2836000",
    "end": "2836000"
  },
  {
    "text": "advantage of and specifically I have a few examples around the cache and memory subsystem that are also worth reflecting",
    "start": "2836270",
    "end": "2843470"
  },
  {
    "text": "over so first this is a very general description of what happens in terms of",
    "start": "2843470",
    "end": "2849079"
  },
  {
    "text": "the memory system and the cache when you access memory from core this is a",
    "start": "2849079",
    "end": "2854420"
  },
  {
    "text": "supposedly a typical I 5 processor which has three levels of cache so this thing",
    "start": "2854420",
    "end": "2860900"
  },
  {
    "text": "here the grey one is the CPU socket this is a single unit which you pay for and",
    "start": "2860900",
    "end": "2866300"
  },
  {
    "text": "install on your system and then it has two CPU cores inside each core has a",
    "start": "2866300",
    "end": "2871940"
  },
  {
    "text": "level 1 cache which is separate from the other cores and the level 2 cache which is also separate from the other course",
    "start": "2871940",
    "end": "2878210"
  },
  {
    "text": "and these two cache levels differ by size and speed of access level 1 cache",
    "start": "2878210",
    "end": "2884300"
  },
  {
    "text": "can be accessed in 4 CPU cycles now think about it modern processors have a",
    "start": "2884300",
    "end": "2889640"
  },
  {
    "text": "clock speed of say 3 gigahertz so force cycles is like a nanosecond and a half",
    "start": "2889640",
    "end": "2896869"
  },
  {
    "text": "maybe a little less the level 2 cache has a latency of 10 cycles so say 3",
    "start": "2896869",
    "end": "2904430"
  },
  {
    "text": "nanoseconds for nanoseconds something like this and it's a lot bigger I sorry",
    "start": "2904430",
    "end": "2910130"
  },
  {
    "text": "I didn't say but level 1 cache is typically 32k on Intel I serious processors and level 2 is 256 K so it's",
    "start": "2910130",
    "end": "2918170"
  },
  {
    "text": "bigger but slower considerably slower and finally level 3 cache in this design",
    "start": "2918170",
    "end": "2923810"
  },
  {
    "text": "is shared across both cores it's a lot bigger it could be 16 megabytes even more on more",
    "start": "2923810",
    "end": "2930440"
  },
  {
    "text": "sophisticated CPUs but it's a lot slower as well so 40 cycles for example and",
    "start": "2930440",
    "end": "2935950"
  },
  {
    "text": "finally main memory which as you know can be really big you could have terabytes of RAM",
    "start": "2935950",
    "end": "2942010"
  },
  {
    "text": "modern server that is accessible in more than 100 cycles so it's really a lot",
    "start": "2942010",
    "end": "2948370"
  },
  {
    "text": "slower than all the different levels in the cache hierarchy if you can get your",
    "start": "2948370",
    "end": "2953680"
  },
  {
    "text": "data to fit in level one cache and repeatedly access the same information repeatedly access the same elements you",
    "start": "2953680",
    "end": "2961030"
  },
  {
    "text": "could have up to 30 or 40 times better performance then if you have to",
    "start": "2961030",
    "end": "2966100"
  },
  {
    "text": "constantly go to main memory this is the main result and even if you're only able to use level 3 cache repeatedly and you",
    "start": "2966100",
    "end": "2973930"
  },
  {
    "text": "don't have to go out to main memory you could get a nice win of 3x or even more depending on your main memory indeed now",
    "start": "2973930",
    "end": "2982000"
  },
  {
    "text": "if you have more sockets more actual CPU packages you would have multiple level 3",
    "start": "2982000",
    "end": "2987460"
  },
  {
    "text": "caches and then there's some more logic required to coordinate them which is something I'll touch on shortly so",
    "start": "2987460",
    "end": "2994660"
  },
  {
    "text": "here's the first example where this is relevant it's a pretty classic one going back to matrix multiplication once more",
    "start": "2994660",
    "end": "3001190"
  },
  {
    "start": "2995000",
    "end": "2995000"
  },
  {
    "text": "this is one loop and this is another loop which implements the same algorithm",
    "start": "3001190",
    "end": "3006240"
  },
  {
    "text": "exactly except the inner loops are interchanged here I'm going over J and",
    "start": "3006240",
    "end": "3012960"
  },
  {
    "text": "then over K and here I'm going over K and then over J so it might look like",
    "start": "3012960",
    "end": "3018000"
  },
  {
    "text": "just a simple renaming not nothing more but it's not just renaming because it",
    "start": "3018000",
    "end": "3023520"
  },
  {
    "text": "changes the pattern of access in the actual core of the inner loop what",
    "start": "3023520",
    "end": "3028890"
  },
  {
    "text": "happens in the first example is that one of my matrices the matrix B is accessed",
    "start": "3028890",
    "end": "3035070"
  },
  {
    "text": "like this I'm going over a single column of the matrix whereas in this version",
    "start": "3035070",
    "end": "3041130"
  },
  {
    "text": "that same matrix B is accessed like this I'm going over a single row of that",
    "start": "3041130",
    "end": "3047160"
  },
  {
    "text": "matrix instead in fact in this version I'm going over rows only I'm there's not",
    "start": "3047160",
    "end": "3053040"
  },
  {
    "text": "a single matrix where I'm going over a single column in the inner in the inner loop the result is not as impressive as",
    "start": "3053040",
    "end": "3061560"
  },
  {
    "text": "a lot of things we saw before but still pretty impressive especially if you consider the following in this example",
    "start": "3061560",
    "end": "3068070"
  },
  {
    "text": "where when I benchmarked just to make the benchmarks run a little faster my",
    "start": "3068070",
    "end": "3073650"
  },
  {
    "text": "matrices were just 512 by twelve matrices of floats so a single",
    "start": "3073650",
    "end": "3078900"
  },
  {
    "text": "matrix would be one megabyte three of them together three megabytes and my",
    "start": "3078900",
    "end": "3084690"
  },
  {
    "text": "level three cache on the processor I benchmarked this on my level three cache is eight megabytes so all of this data",
    "start": "3084690",
    "end": "3091800"
  },
  {
    "text": "was able to fit in level three cache and still by accessing memory in a better",
    "start": "3091800",
    "end": "3097350"
  },
  {
    "text": "pattern by accessing memory consecutively we were able to use the higher levels in the cache hierarchy",
    "start": "3097350",
    "end": "3103080"
  },
  {
    "text": "better so we didn't have to go to level three all the time we were able to find",
    "start": "3103080",
    "end": "3108510"
  },
  {
    "text": "what we needed in level one or level two in more cases and the result is almost a",
    "start": "3108510",
    "end": "3114150"
  },
  {
    "text": "2x speed-up another example which is pretty similar so I'm not going to spend",
    "start": "3114150",
    "end": "3120330"
  },
  {
    "start": "3120000",
    "end": "3120000"
  },
  {
    "text": "a lot of time on is tiling in a lot of cases when you have data that you need to access in some random patterns it",
    "start": "3120330",
    "end": "3128190"
  },
  {
    "text": "might be better instead of accessing it in random patterns to make blocks smaller blocks and work on these blocks",
    "start": "3128190",
    "end": "3135030"
  },
  {
    "text": "because the smaller blocks might be able to fit in cache and then you finish a single block which fits in cache you",
    "start": "3135030",
    "end": "3141450"
  },
  {
    "text": "move on to the next block which fits in cache and so on reducing again the number of pool cache misses you have to",
    "start": "3141450",
    "end": "3146940"
  },
  {
    "text": "do we don't have a lot of time for this so just take a look at this later the performance difference again is pretty",
    "start": "3146940",
    "end": "3153590"
  },
  {
    "text": "considerable in this case and in this case still all my data fit in level 3",
    "start": "3153590",
    "end": "3158880"
  },
  {
    "text": "cache so again it's not the worst case result for for main memory ok so my",
    "start": "3158880",
    "end": "3165630"
  },
  {
    "text": "final thing I wanna touch on what it has to do with memory and cache is where",
    "start": "3165630",
    "end": "3170850"
  },
  {
    "start": "3167000",
    "end": "3167000"
  },
  {
    "text": "this whole cache subsystem or the memory subsystem can become an actual bottleneck for your algorithm so the",
    "start": "3170850",
    "end": "3177960"
  },
  {
    "text": "first thing to notice is in a lot of cases after you apply vectorization and",
    "start": "3177960",
    "end": "3183060"
  },
  {
    "text": "fertilization a lot of these optimizations you end up with something that's so fast that memory becomes the limiting factor",
    "start": "3183060",
    "end": "3190590"
  },
  {
    "text": "and here's one example from an actual project I was on what we wanted to optimize was dot product a pretty simple",
    "start": "3190590",
    "end": "3197670"
  },
  {
    "text": "operation on numbers you have a vector of floats you want to reduce it down to a single float dot product operation and",
    "start": "3197670",
    "end": "3204810"
  },
  {
    "text": "what we had is multiple versions that I benchmarked in other than finding the fastest one",
    "start": "3204810",
    "end": "3210720"
  },
  {
    "text": "which we did pretty quickly using vectorization we were able to on a single core without fertilization to",
    "start": "3210720",
    "end": "3218280"
  },
  {
    "text": "reach speeds of around 23 gigabytes of data read from memory so we had lots and",
    "start": "3218280",
    "end": "3225450"
  },
  {
    "text": "lots of these floating-point vectors and we were working at the speed of 23 gigabytes per second now memory on that",
    "start": "3225450",
    "end": "3233010"
  },
  {
    "text": "actual system the the the channel between memory and the CPU had",
    "start": "3233010",
    "end": "3238320"
  },
  {
    "text": "theoretical peak bandwidth of 25 point 3 gigabytes per second so if you're at 23",
    "start": "3238320",
    "end": "3244830"
  },
  {
    "text": "something that's pretty much the theoretical limit of how fast you can fetch stuff from memory before you just",
    "start": "3244830",
    "end": "3250950"
  },
  {
    "text": "stall and have to wait and so this is on a single core imagine putting 4 cores to",
    "start": "3250950",
    "end": "3257040"
  },
  {
    "text": "work you'd very very quickly run into the maximum theoretical limit that your memory system is able to give you and",
    "start": "3257040",
    "end": "3264800"
  },
  {
    "text": "this is again exactly what the Intel top-down method is for you would then",
    "start": "3264800",
    "end": "3270840"
  },
  {
    "text": "identify that you are typically back-end bound your back-end isn't capable of",
    "start": "3270840",
    "end": "3276600"
  },
  {
    "text": "issuing more instructions and then you'd see which component of the back-end is busy and you see the memory system your",
    "start": "3276600",
    "end": "3283770"
  },
  {
    "text": "load instructions are stalling you're not able to read from memory quickly enough for your super optimized CPU",
    "start": "3283770",
    "end": "3291120"
  },
  {
    "text": "algorithm to process your data this usually happens in simple operations",
    "start": "3291120",
    "end": "3296490"
  },
  {
    "text": "like adding numbers or doing dot products multiplications if you have more work if your algorithm is more",
    "start": "3296490",
    "end": "3302370"
  },
  {
    "text": "complex you would typically not run into memory limits that quickly but it does",
    "start": "3302370",
    "end": "3307410"
  },
  {
    "text": "happen and it's an important thing to keep in mind you might sometimes reach run into problems when you optimize too",
    "start": "3307410",
    "end": "3314340"
  },
  {
    "text": "much because memory can't keep up with your amazing optimizations that's just another part of the system and a final example I was saying caches",
    "start": "3314340",
    "end": "3323730"
  },
  {
    "text": "can sort of interview each other so my final example has to do with cache coherence or cache invalidation when you",
    "start": "3323730",
    "end": "3331290"
  },
  {
    "text": "have multiple caches and pretty much are on every single system today you have multiple caches on multiple processors",
    "start": "3331290",
    "end": "3337590"
  },
  {
    "text": "or multiple cores at least there's the chance data in the French caches will not match you could",
    "start": "3337590",
    "end": "3344940"
  },
  {
    "text": "have the same memory location in two different caches having a different",
    "start": "3344940",
    "end": "3350100"
  },
  {
    "text": "value which would be potentially disastrous so there is a very sophisticated protocol between these",
    "start": "3350100",
    "end": "3356790"
  },
  {
    "text": "different caches designed to keep things in sync so you don't have disagreements",
    "start": "3356790",
    "end": "3362070"
  },
  {
    "text": "between caches which value is correct for a single memory location the way it works is the following so suppose you",
    "start": "3362070",
    "end": "3368430"
  },
  {
    "text": "have some value in both cores caches on your system that value is then marked as",
    "start": "3368430",
    "end": "3375900"
  },
  {
    "text": "shared once the core wants to modify that value it marks it as exclusive and",
    "start": "3375900",
    "end": "3382980"
  },
  {
    "text": "it causes the other core to lose that value this is called invalidation I had",
    "start": "3382980",
    "end": "3388860"
  },
  {
    "text": "the value in both caches and then core zero invalidates the value in core 1",
    "start": "3388860",
    "end": "3395310"
  },
  {
    "text": "cache and then finally core zero can write and actually modify that value the",
    "start": "3395310",
    "end": "3402030"
  },
  {
    "text": "result and go out to main memory and if core number one leads that result it",
    "start": "3402030",
    "end": "3407040"
  },
  {
    "text": "will fetch it back into cache now what's interesting here is that this whole",
    "start": "3407040",
    "end": "3412500"
  },
  {
    "text": "thing happens not on the scale of a single integer or a single float this",
    "start": "3412500",
    "end": "3418680"
  },
  {
    "text": "happens on the level of cache lines a single cache line is fixed before bytes",
    "start": "3418680",
    "end": "3424140"
  },
  {
    "text": "in modern Intel processors so whenever you have to evict something from cache",
    "start": "3424140",
    "end": "3429810"
  },
  {
    "text": "you evict 64 bytes and we have whenever you have to read something into cache",
    "start": "3429810",
    "end": "3434910"
  },
  {
    "text": "you read 64 bytes and then what happens is you get full sharing you get",
    "start": "3434910",
    "end": "3441840"
  },
  {
    "text": "invalidation which was not intentional it's not 2 cores accessing the same",
    "start": "3441840",
    "end": "3447330"
  },
  {
    "text": "memory location it's two cores accessing adjacent memory locations which happened",
    "start": "3447330",
    "end": "3453390"
  },
  {
    "text": "to be on the same cache line and so this very simple example again we're not",
    "start": "3453390",
    "end": "3458640"
  },
  {
    "text": "going to drill into all the details here I have two versions of the same code one",
    "start": "3458640",
    "end": "3464340"
  },
  {
    "text": "I have a certain function run in the background in update an element in a",
    "start": "3464340",
    "end": "3470250"
  },
  {
    "text": "shared array of doubles and this runs in parallel on multiple",
    "start": "3470250",
    "end": "3475680"
  },
  {
    "text": "thread each thread is accessing a different double each thread is updating a different element in a single shared",
    "start": "3475680",
    "end": "3483119"
  },
  {
    "text": "double array second version almost the same except each thread is working on a",
    "start": "3483119",
    "end": "3490020"
  },
  {
    "text": "local variable and only at the end it updates the shared global double array",
    "start": "3490020",
    "end": "3496339"
  },
  {
    "text": "the speed difference is pretty crazy especially when you add many threads to the mix the key results to see here are",
    "start": "3496339",
    "end": "3503309"
  },
  {
    "text": "the red lines this is the first version as you increase the number of threads so",
    "start": "3503309",
    "end": "3508380"
  },
  {
    "text": "you have one thread it runs and 54 units you have two threads it runs in 53 units you have four threads it runs in 55",
    "start": "3508380",
    "end": "3516089"
  },
  {
    "text": "units it's not getting faster as you add more thread whereas the second version",
    "start": "3516089",
    "end": "3521579"
  },
  {
    "text": "speeds up linearly from 54 to 28 to 15 and it could probably speed up even more",
    "start": "3521579",
    "end": "3528240"
  },
  {
    "text": "the only reason for this difference is that in this version you're accessing adjacent memory locations from multiple",
    "start": "3528240",
    "end": "3535230"
  },
  {
    "text": "threads and in this version you're accessing a totally different memory",
    "start": "3535230",
    "end": "3540569"
  },
  {
    "text": "location and only at the end you have to sync the results up this thing is causing lots and lots of cache",
    "start": "3540569",
    "end": "3546809"
  },
  {
    "text": "invalidations whereas this version is not so this is a pretty known phenomenon but you keep",
    "start": "3546809",
    "end": "3553349"
  },
  {
    "text": "running into this in a lot of different areas it's really hard to predict at times which things are going to be",
    "start": "3553349",
    "end": "3560400"
  },
  {
    "text": "adjacent in memory so which patterns of use could end up colliding on the same",
    "start": "3560400",
    "end": "3566309"
  },
  {
    "text": "cache location and and cause this performance problem for you so again there are tools for this and this is my",
    "start": "3566309",
    "end": "3572490"
  },
  {
    "text": "concluding thought there are tools for this I wanted to show you as many examples as I could so I didn't drill",
    "start": "3572490",
    "end": "3579270"
  },
  {
    "text": "into each one and you know formally showed you where the problem is exactly before optimizing but Intel and AMD",
    "start": "3579270",
    "end": "3587130"
  },
  {
    "text": "which are the two major processor vendors for us they have tools available for benchmarking applications and",
    "start": "3587130",
    "end": "3594150"
  },
  {
    "text": "pointing out what the performance problem is from the CPUs perspective in fact Intel even have tools like the",
    "start": "3594150",
    "end": "3601559"
  },
  {
    "text": "trading advisor and the vector advisor which will tell you so here's a loop you could improve but you",
    "start": "3601559",
    "end": "3607440"
  },
  {
    "text": "vectorization and here's a loop where you applied vectorization but you didn't get the best performance out of this",
    "start": "3607440",
    "end": "3613890"
  },
  {
    "text": "loop you should work harder on this loop and you will get even more so there's tools available for this most of them",
    "start": "3613890",
    "end": "3620460"
  },
  {
    "text": "commercial but there's also some free information you can get out of your system looking into the future finally",
    "start": "3620460",
    "end": "3627500"
  },
  {
    "text": "we'll probably see even more complex systems even more complex processors that we have to optimize for for example",
    "start": "3627500",
    "end": "3635160"
  },
  {
    "text": "we might see systems where you have hybrid course you have faster cores designed for certain tasks and slower",
    "start": "3635160",
    "end": "3641910"
  },
  {
    "text": "cores which consume less energy which would be dedicated to some what other tasks so you'd have to think about",
    "start": "3641910",
    "end": "3648359"
  },
  {
    "text": "scheduling work across cores you have external processing units for example Intel the 72 core monsters they can be",
    "start": "3648359",
    "end": "3657720"
  },
  {
    "text": "added to a system as external PCI cards so you could add multiple processors to the system dynamically and then use them",
    "start": "3657720",
    "end": "3664500"
  },
  {
    "text": "as external processing units there's the GPU which again we could spend the whole",
    "start": "3664500",
    "end": "3669540"
  },
  {
    "text": "talk talking about how to optimize for the GPU which also has a bunch of course available for you to use for",
    "start": "3669540",
    "end": "3675569"
  },
  {
    "text": "general-purpose computation so there's a lot of interesting stuff to look into if you're interested in low-level CPU",
    "start": "3675569",
    "end": "3681869"
  },
  {
    "text": "optimization optimizing algorithms like this so all my examples are available",
    "start": "3681869",
    "end": "3687839"
  },
  {
    "text": "here and github and the slides if you want them are over here on Dropbox if you have any questions I'll be happy to",
    "start": "3687839",
    "end": "3693510"
  },
  {
    "text": "to answer but I do have to move off the stage for the next speaker so really I",
    "start": "3693510",
    "end": "3698880"
  },
  {
    "text": "appreciate you coming thank you very much and enjoy the rest of embassy thank you [Applause]",
    "start": "3698880",
    "end": "3708180"
  }
]
[
  {
    "text": "all right I think we are at the 40 minutes past so good morning welcome to",
    "start": "6399",
    "end": "13160"
  },
  {
    "text": "the last day of NDC London and uh thank you for coming to my talk uh after the",
    "start": "13160",
    "end": "18240"
  },
  {
    "text": "last two weeks I'm surprised anyone wants to hear about llms I'm also a little tired of it but we're here now so",
    "start": "18240",
    "end": "24720"
  },
  {
    "text": "let's DRP in so my name is Jody Burchell I am working as a developer advocate in",
    "start": "24720",
    "end": "30679"
  },
  {
    "text": "data science at jet brains and I've been in data science for around 10 years um I actually spent a big chunk of my career",
    "start": "30679",
    "end": "36840"
  },
  {
    "text": "in natural language processing so the title of this talk is a question that I've had to answer",
    "start": "36840",
    "end": "42719"
  },
  {
    "text": "myself in my career many many times actually knowing when you build a machine learning model if it's actually",
    "start": "42719",
    "end": "49480"
  },
  {
    "text": "any good is quite a tricky thing and as we've entered the age of large language",
    "start": "49480",
    "end": "54719"
  },
  {
    "text": "models as you're going to see in this talk that question has gotten harder and harder to answer",
    "start": "54719",
    "end": "61199"
  },
  {
    "text": "so just before I get into the talk I also just want to do as a little aside what you're going to see is a lot of Links at the bottom of each of these",
    "start": "61199",
    "end": "68119"
  },
  {
    "text": "slides talk like this requires quite a bit of research Don't Panic about taking photos or trying to get down those links",
    "start": "68119",
    "end": "74799"
  },
  {
    "text": "as I'm speaking I'm going to be showing you a QR code at the end and it's going to take you to a GitHub repo that'll have my slides and I'll have all those",
    "start": "74799",
    "end": "81400"
  },
  {
    "text": "resources does mean you need to stay until the end but I do promise I'll make it worth your while so let's go back to",
    "start": "81400",
    "end": "87840"
  },
  {
    "text": "this question can you trust your models can you trust your machine learning models and can you trust your large",
    "start": "87840",
    "end": "94680"
  },
  {
    "text": "language models the thing is we're talking about data science so it's in the name it's science this is not really",
    "start": "94680",
    "end": "101439"
  },
  {
    "text": "a question of Vibes or trust it's nothing that vague it's actually something much more scientific it's a",
    "start": "101439",
    "end": "107119"
  },
  {
    "text": "question about whether you're measuring the right thing and to illustrate the difference between these things I want",
    "start": "107119",
    "end": "114159"
  },
  {
    "text": "to tell you a story that happened around 15 years ago so in 2010 there was a",
    "start": "114159",
    "end": "120399"
  },
  {
    "text": "social psychologist called Amy cotti and she was teaching psychology at Harvard Business School so Cy started noticing a",
    "start": "120399",
    "end": "128479"
  },
  {
    "text": "difference between how her students behaved this is part of the problem of doing a psychology degree you start",
    "start": "128479",
    "end": "134560"
  },
  {
    "text": "getting experimented on by your professors so CTI noticed two groups she",
    "start": "134560",
    "end": "140640"
  },
  {
    "text": "noticed firstly she had this group of students that were doing very well at their written assessment but when it",
    "start": "140640",
    "end": "145879"
  },
  {
    "text": "came to class participation they were really failing and they were really afraid of speaking in class they would",
    "start": "145879",
    "end": "152239"
  },
  {
    "text": "put up their hands like this they sort of shielded themselves when they were called upon to speak they had very",
    "start": "152239",
    "end": "158160"
  },
  {
    "text": "little conviction in what they wanted to say now in contrast there was another group of students they were also killing",
    "start": "158160",
    "end": "165159"
  },
  {
    "text": "it at R participation but when it came to class participation they were so confident they would raise their hands",
    "start": "165159",
    "end": "171560"
  },
  {
    "text": "high and they would answer with a lot of confidence so kotti started to wonder",
    "start": "171560",
    "end": "177480"
  },
  {
    "text": "what is the relationship between body language and confidence and could it go both ways could it be that rather than",
    "start": "177480",
    "end": "185480"
  },
  {
    "text": "just you know their body language reflecting an underlying level of confidence you could incite higher",
    "start": "185480",
    "end": "191720"
  },
  {
    "text": "levels of confidence with confident body language and this kicked off a body of research that CTI led into something",
    "start": "191720",
    "end": "199360"
  },
  {
    "text": "that she called Power posing so what she got participants to do was to hold expansive high power poses as she called",
    "start": "199360",
    "end": "206920"
  },
  {
    "text": "them like this the Wonder Woman pose and she found that participants in this group reported feeling higher levels of",
    "start": "206920",
    "end": "213480"
  },
  {
    "text": "power they were more inclined to take risk and most importantly they showed physiological changes it's very exciting",
    "start": "213480",
    "end": "221080"
  },
  {
    "text": "so the participants in this high power group they actually showed higher levels of testosterone and lower levels of",
    "start": "221080",
    "end": "227040"
  },
  {
    "text": "cortisol so this indicated they actually physiologically were feeling more dominant and less",
    "start": "227040",
    "end": "232360"
  },
  {
    "text": "stressed so this really excited K C's colleagues and it excited the wher",
    "start": "232360",
    "end": "238560"
  },
  {
    "text": "scientific community CTI got a publication on This research in the top journal in",
    "start": "238560",
    "end": "244720"
  },
  {
    "text": "Psychology and then it hit the mainstream cotti got press interviews she got an appearance on Oprah and she",
    "start": "244720",
    "end": "251439"
  },
  {
    "text": "got one of the top TED talks of all time remember TED Talks very",
    "start": "251439",
    "end": "256560"
  },
  {
    "text": "2010 so cot's findings spread throughout the mainstream you had people sneaking",
    "start": "256560",
    "end": "261680"
  },
  {
    "text": "into bathroom stalls to power pose before job interviews or holding these poses before doing something difficult",
    "start": "261680",
    "end": "267560"
  },
  {
    "text": "like walking on stage to do a presentation so C had become an absolute mainstream",
    "start": "267560",
    "end": "274240"
  },
  {
    "text": "phenomenon that was until 2014 another researcher called AA rehill",
    "start": "274240",
    "end": "281080"
  },
  {
    "text": "tried to replicate C's findings and she couldn't replicate most of them and most importantly she couldn't replicate that",
    "start": "281080",
    "end": "287720"
  },
  {
    "text": "jewel in the crown of C's findings those findings of physiological changes other",
    "start": "287720",
    "end": "293720"
  },
  {
    "text": "researchers jumped on board they started to try to replicate what cotti had found and they couldn't either and this body",
    "start": "293720",
    "end": "300280"
  },
  {
    "text": "of evidence started to call into question whether cotti had found something real the whole unhappy Saga",
    "start": "300280",
    "end": "306919"
  },
  {
    "text": "reached its peak when one of C's co-authors on the original study publicly disavowed their findings and",
    "start": "306919",
    "end": "313280"
  },
  {
    "text": "C's credentials as a scientist were called into question so what happened here what is",
    "start": "313280",
    "end": "319560"
  },
  {
    "text": "going on was Kia charlatan was she just trying to get you know this press uh",
    "start": "319560",
    "end": "325319"
  },
  {
    "text": "kind of circuit this talk circuit she got a book published out of this after all was she incompetent was she unable",
    "start": "325319",
    "end": "332880"
  },
  {
    "text": "to do research to the standards of her field the thing is neither of these things were true all of this went down",
    "start": "332880",
    "end": "340440"
  },
  {
    "text": "when I was doing my PhD in Psychology and what happened was Cy was fooled by",
    "start": "340440",
    "end": "347160"
  },
  {
    "text": "results that looked real but they told her the wrong thing",
    "start": "347160",
    "end": "352720"
  },
  {
    "text": "because she had measured the wrong thing so I know what some of you are",
    "start": "352720",
    "end": "358039"
  },
  {
    "text": "thinking I am a psychologist and I know you're thinking it's psychology it's not",
    "start": "358039",
    "end": "363600"
  },
  {
    "text": "very scientific so of course this happened but this couldn't happen to machine learning machine learning is so",
    "start": "363600",
    "end": "369319"
  },
  {
    "text": "much more robust has all those complex math and all of those really sophisticated",
    "start": "369319",
    "end": "374880"
  },
  {
    "text": "algorithms well of course this is a trap not so fast so reviews have been done on",
    "start": "374880",
    "end": "381520"
  },
  {
    "text": "a lot of papers that use machine learning techniques at the core of their studies and it's found that in all of",
    "start": "381520",
    "end": "387880"
  },
  {
    "text": "these fields that I'm showing you here at least 15% of the studies could not be",
    "start": "387880",
    "end": "394319"
  },
  {
    "text": "replicated they found the wrong thing because they had measured the wrong",
    "start": "394319",
    "end": "399360"
  },
  {
    "text": "thing and as you can see from this list this includes arguably more objective",
    "start": "399360",
    "end": "404639"
  },
  {
    "text": "Fields like genomics like medicine and oh yes software engineering we did not",
    "start": "404639",
    "end": "411960"
  },
  {
    "text": "Escape either so this raises a really troubling question if even experts in machine",
    "start": "411960",
    "end": "418720"
  },
  {
    "text": "learning are getting this wrong don't know what's going on in satellite imaging they're getting it wrong 100% of",
    "start": "418720",
    "end": "424400"
  },
  {
    "text": "the time how can we be sure that we are creating good machine learning models",
    "start": "424400",
    "end": "430960"
  },
  {
    "text": "how can we be sure that we're creating the right uh we're actually measuring the right",
    "start": "430960",
    "end": "437080"
  },
  {
    "text": "thing so to give you a example of one of these studies to kind of make this",
    "start": "437080",
    "end": "442240"
  },
  {
    "text": "really concrete what we can see is an example of a study where they were trying to see whether four different",
    "start": "442240",
    "end": "448240"
  },
  {
    "text": "machine learning techniques explore different machine learning algorithms when performing a task on the same data",
    "start": "448240",
    "end": "455160"
  },
  {
    "text": "would get different results and what they found is that newer and more sophisticated techniques outperformed",
    "start": "455160",
    "end": "462000"
  },
  {
    "text": "logistic regression which is a very old and quite basic technique in machine learning so make sense right you would",
    "start": "462000",
    "end": "469360"
  },
  {
    "text": "expect that something that is more sophisticated something more Cutting Edge is going to outperform something",
    "start": "469360",
    "end": "474400"
  },
  {
    "text": "more basic and older except none of it was real the",
    "start": "474400",
    "end": "479680"
  },
  {
    "text": "authors had made really major mistakes with the way that they had measured their findings when these were corrected",
    "start": "479680",
    "end": "485680"
  },
  {
    "text": "for there was really no difference between the algorithms so these is the sort of degree of mistakes we're talking",
    "start": "485680",
    "end": "492360"
  },
  {
    "text": "about they seem really basic but even experts fall into this trap and I can tell you in my career as a data",
    "start": "492360",
    "end": "499120"
  },
  {
    "text": "scientist a couple of times I've fallen into these traps as well so let's have a look at how we might be able to assess",
    "start": "499120",
    "end": "506400"
  },
  {
    "text": "this more scientifically to be able to know whether we really can trust our machine learning",
    "start": "506400",
    "end": "511959"
  },
  {
    "text": "algorithms so in order to assess this we can borrow some lessons from a branch of mathematics called measurement Theory",
    "start": "511959",
    "end": "518440"
  },
  {
    "text": "which is the branch of mathematics as to how to measure things and measurement Theory tells us that a robust machine",
    "start": "518440",
    "end": "525720"
  },
  {
    "text": "learning algorithm has two components it must be reliable and it must be valid so",
    "start": "525720",
    "end": "533360"
  },
  {
    "text": "reliability is essentially saying that a model will give you the same results",
    "start": "533360",
    "end": "538399"
  },
  {
    "text": "consistently this involves a few different facets so the first is is that if you put in equivalent input the model",
    "start": "538399",
    "end": "545880"
  },
  {
    "text": "will give you an equivalent output you know the same input the prediction will be the same this will also be consistent",
    "start": "545880",
    "end": "553040"
  },
  {
    "text": "over time so the same model will give you the same predictions when it's created as it will 6 months a year two",
    "start": "553040",
    "end": "559519"
  },
  {
    "text": "years later and then finally different ways of assessing the same thing will",
    "start": "559519",
    "end": "564600"
  },
  {
    "text": "converge on the same results so say you have a machine learning model that is giving you predictions and you have a",
    "start": "564600",
    "end": "569959"
  },
  {
    "text": "human assessor that is also trying to predict the same thing with a good model they should Converge on the same things",
    "start": "569959",
    "end": "577880"
  },
  {
    "text": "now validity is on the surface a little more straightforward it's essentially measuring what you set up to measure and",
    "start": "577880",
    "end": "584959"
  },
  {
    "text": "this seems really really basic and obvious but you're going to see it is quite tricky to get right so again this",
    "start": "584959",
    "end": "591519"
  },
  {
    "text": "has a few different facets the first is is that you have a well-defined and",
    "start": "591519",
    "end": "596680"
  },
  {
    "text": "concrete idea of what you're trying to measure you also again have this sort of",
    "start": "596680",
    "end": "602720"
  },
  {
    "text": "convergence of related measures so if you're measuring one thing and you're measuring something that's related to it",
    "start": "602720",
    "end": "608399"
  },
  {
    "text": "those scores should correlate and again um you should also find that models that",
    "start": "608399",
    "end": "613680"
  },
  {
    "text": "you have created in a nice safe development environment will perform well when you release them out into the",
    "start": "613680",
    "end": "619200"
  },
  {
    "text": "real world so let's have a look at a very serious problem that can endanger",
    "start": "619200",
    "end": "625399"
  },
  {
    "text": "reliability and this is something called Data leakage sorry about my pronunciation of data I get you know",
    "start": "625399",
    "end": "631680"
  },
  {
    "text": "comments on this all the time you're going have to put up with it for the rest of the talk so data leakage I think",
    "start": "631680",
    "end": "637120"
  },
  {
    "text": "the easiest way to explain it is imagine you are a professor that's giving an exam so you have a bunch of students and",
    "start": "637120",
    "end": "644240"
  },
  {
    "text": "you have a bunch of past exams and in order to help those students train for this exam what you do is you'll give",
    "start": "644240",
    "end": "650240"
  },
  {
    "text": "them all of the past Year's exams but when it comes time to actually assessing them you give them a fresh exam so what",
    "start": "650240",
    "end": "657959"
  },
  {
    "text": "you're then sure of is when they take that fresh exam you're actually measuring the things they've",
    "start": "657959",
    "end": "663519"
  },
  {
    "text": "learned let's say you're a bit busy maybe a bit lazy and you decide to recycle questions from those past exams",
    "start": "663519",
    "end": "670880"
  },
  {
    "text": "that the students trained on now you run into a problem it's no longer clear what you're measuring are you measuring what",
    "start": "670880",
    "end": "678000"
  },
  {
    "text": "the students learn or are you just measuring how are they memorized the past exam questions so this is the",
    "start": "678000",
    "end": "684320"
  },
  {
    "text": "problem of data leakage becomes unclear what you're actually assessing because you have access to training materials",
    "start": "684320",
    "end": "691639"
  },
  {
    "text": "during test time so this also happens with machine learning models and a good case of this is a model called cheex net",
    "start": "691639",
    "end": "699240"
  },
  {
    "text": "now cheex net was designed to try and assess whether people have pneumonia based on their lung scans and when it",
    "start": "699240",
    "end": "706160"
  },
  {
    "text": "was released and they measured it it worked super well great hoay for science we have a super cool model right well",
    "start": "706160",
    "end": "713760"
  },
  {
    "text": "not so fast the problem is is that when people went in to get their lung scans they didn't just get one lung Scan they",
    "start": "713760",
    "end": "720360"
  },
  {
    "text": "got multiple almost identical lung scans and when the creators of the model put",
    "start": "720360",
    "end": "725959"
  },
  {
    "text": "their data into training data sets and testing data sets they didn't know this and they mixed these up so essentially",
    "start": "725959",
    "end": "733160"
  },
  {
    "text": "the model had access to images had basically seen during training at test time it's exactly the same as the",
    "start": "733160",
    "end": "740040"
  },
  {
    "text": "problem with the students essentially you do not know what you've measured so let's now go back to",
    "start": "740040",
    "end": "746760"
  },
  {
    "text": "validity so in the early days of machine learning models assessing validity was pretty straightforward we had models",
    "start": "746760",
    "end": "753680"
  },
  {
    "text": "that were pretty transparent and this made it really clear what the models were actually learning from the data so",
    "start": "753680",
    "end": "760440"
  },
  {
    "text": "we take the case of linear regression this again is a very old and very kind",
    "start": "760440",
    "end": "765800"
  },
  {
    "text": "of explainable algorithm what you can see in this table is a bunch of features",
    "start": "765800",
    "end": "771320"
  },
  {
    "text": "these are things that are used to predict the outcome and in this case what we're trying to predict is how well",
    "start": "771320",
    "end": "776959"
  },
  {
    "text": "students went on an exam so we have things like the hour spent studying the course level and their current GPA then",
    "start": "776959",
    "end": "785000"
  },
  {
    "text": "we have this weight column now this weight column is very interesting what it tells us is exactly what the model",
    "start": "785000",
    "end": "791680"
  },
  {
    "text": "has learned about the relationship between each of these predictors and how well the student will go on their exam",
    "start": "791680",
    "end": "797880"
  },
  {
    "text": "so in the case of this 1.5 next hour spent studying it tells us that for every hour a students spent studying",
    "start": "797880",
    "end": "804399"
  },
  {
    "text": "they're going to get an additional 1.5% on their exam so super super super clear",
    "start": "804399",
    "end": "809880"
  },
  {
    "text": "it's really obvious what we're measuring here but the problem is is as we've",
    "start": "809880",
    "end": "815880"
  },
  {
    "text": "moved into more and more sophisticated algorithms we've moved into what we call the Black Box era of algorithms when",
    "start": "815880",
    "end": "822920"
  },
  {
    "text": "models have become more powerful but much less explainable so we can see this in the case of this Vision model what",
    "start": "822920",
    "end": "829800"
  },
  {
    "text": "I've done here is pulled out the hidden states of this model and you can see that going from the bottom up it seems",
    "start": "829800",
    "end": "836240"
  },
  {
    "text": "to be sequentially building up images of a cat but I'm not really sure if that's what's",
    "start": "836240",
    "end": "841320"
  },
  {
    "text": "happening I've had to add a layer of interpretation to that if we have this",
    "start": "841320",
    "end": "846639"
  },
  {
    "text": "sorry we have this early small language model what we can see is it appears to",
    "start": "846639",
    "end": "851720"
  },
  {
    "text": "be learning the relationship between the words in a sentence but again it's not entirely clear if that's what's",
    "start": "851720",
    "end": "857959"
  },
  {
    "text": "happening and as we've entered the age of large language models here we come to it things have really gone off the rails",
    "start": "857959",
    "end": "866079"
  },
  {
    "text": "what we can do is only really see if the inputs appear to make sense with regards",
    "start": "866079",
    "end": "872680"
  },
  {
    "text": "to the outputs it's very very difficult to Peak inside these models and we have no way of really doing it holistically",
    "start": "872680",
    "end": "878920"
  },
  {
    "text": "so we can see this example here I've asked an llm to write me a joke about cats and it has come up with something",
    "start": "878920",
    "end": "884480"
  },
  {
    "text": "that makes sense but I don't know how the llm knows what a concept of a cat is or how it knows how to make really bad",
    "start": "884480",
    "end": "892000"
  },
  {
    "text": "jokes and one of the biggest problems we have now is we now have problems with model reliability",
    "start": "892000",
    "end": "899399"
  },
  {
    "text": "we never had this problem with machine learning models before once you trained the model it would give you the exact",
    "start": "899399",
    "end": "905399"
  },
  {
    "text": "same output for the same inputs but llms don't work like this by Design they are",
    "start": "905399",
    "end": "912079"
  },
  {
    "text": "designed to give you variation for the same input so again you can see this",
    "start": "912079",
    "end": "917279"
  },
  {
    "text": "with this model get the same input two different cat jokes I mean they're equally bad but that's more of a taste",
    "start": "917279",
    "end": "923959"
  },
  {
    "text": "issue than a reliability issue so this brings us back to the same question we asked before about machine",
    "start": "923959",
    "end": "930560"
  },
  {
    "text": "learning models how can we know if an llm is good how do we measure the right",
    "start": "930560",
    "end": "937600"
  },
  {
    "text": "things how do we know if we've measured the right things so this is going to kick off the",
    "start": "937600",
    "end": "944480"
  },
  {
    "text": "rest of the talk and we're going to be discussing the noisy and extremely confusing world of llm",
    "start": "944480",
    "end": "951560"
  },
  {
    "text": "assessment so if you've been existing in the world for the last year and a half",
    "start": "951560",
    "end": "956800"
  },
  {
    "text": "or so you will have heard llm vendors or research Labs telling you how good their",
    "start": "956800",
    "end": "963319"
  },
  {
    "text": "models are so you might have seen papers or release materials that have some variation of the following we've just",
    "start": "963319",
    "end": "969880"
  },
  {
    "text": "launched our large lat newest large language model trained with state-of-the-art gpus and we've improved",
    "start": "969880",
    "end": "975360"
  },
  {
    "text": "on the MML U by end points beating the previous best sounds very convincing",
    "start": "975360",
    "end": "981319"
  },
  {
    "text": "right or maybe if you've gone a little bit deeper you might have seen llm leaderboards these pit models against",
    "start": "981319",
    "end": "988319"
  },
  {
    "text": "each other on on exotic sounding measures like wi Grand or hellis",
    "start": "988319",
    "end": "994600"
  },
  {
    "text": "swag but how do we know whether scoring well on any of these measures mean anything what are these measures",
    "start": "994800",
    "end": "1001600"
  },
  {
    "text": "actually assessing and to scoring really well does topping the leaderboard mean",
    "start": "1001600",
    "end": "1006800"
  },
  {
    "text": "that an llm is good so let's go a little bit deeper and",
    "start": "1006800",
    "end": "1011880"
  },
  {
    "text": "have a look at the different ways that we're trying to assess llms right now so",
    "start": "1011880",
    "end": "1017360"
  },
  {
    "text": "I would say one of the most contr IAL ways to assess llms is to get them to complete some of the hardest tests that",
    "start": "1017360",
    "end": "1024319"
  },
  {
    "text": "we have for humans so you can see an example of that here what we have is four llms who have completed questions",
    "start": "1024319",
    "end": "1031360"
  },
  {
    "text": "from a US medical exam and you can see they've done great you know GPT 4 got",
    "start": "1031360",
    "end": "1036678"
  },
  {
    "text": "100% And even the worst performing model still got 75% correct okay so you might have",
    "start": "1036679",
    "end": "1044600"
  },
  {
    "text": "remembered around the time that GPT 4 came out this was around two years ago results like this were everywhere and",
    "start": "1044600",
    "end": "1051280"
  },
  {
    "text": "this came the correspond or this led to corresponding claims that we were going to be all replaced you know we're going",
    "start": "1051280",
    "end": "1057480"
  },
  {
    "text": "to replace doctors we're going to replace lawyers and we are of course going to replace",
    "start": "1057480",
    "end": "1063280"
  },
  {
    "text": "programmers but it's been almost 2 years since we first started seeing these results we first started seeing models",
    "start": "1063280",
    "end": "1069280"
  },
  {
    "text": "that could do this and I would argue we have not seen any material progress",
    "start": "1069280",
    "end": "1074720"
  },
  {
    "text": "towards replacement of anyone in these professions in fact we've seen some lawyers getting into quite a lot of",
    "start": "1074720",
    "end": "1081400"
  },
  {
    "text": "problems because they tried to use these models to automate part of their job so what gives why haven't we seen",
    "start": "1081400",
    "end": "1089559"
  },
  {
    "text": "replacement of humans when clearly these models are probably outperforming us on some of our hardest",
    "start": "1089559",
    "end": "1095480"
  },
  {
    "text": "tests the issue is is and if you've seen any of my sort of previous talks about",
    "start": "1095480",
    "end": "1100600"
  },
  {
    "text": "llms You' see that the issue with using benchmarks that are designed from humans to assess llms is that they're",
    "start": "1100600",
    "end": "1107919"
  },
  {
    "text": "fundamentally measuring different things so let's go to say medical exams medical",
    "start": "1107919",
    "end": "1114720"
  },
  {
    "text": "exams are a way of assessing how well someone is going to go when they're practicing medicine they're a proxy for",
    "start": "1114720",
    "end": "1121799"
  },
  {
    "text": "assessing how suitable someone is to being a doctor and in this case they do have pretty good validity you can see",
    "start": "1121799",
    "end": "1129520"
  },
  {
    "text": "that like from papers we've got a couple of references there people who do well at Medical entrance exams tend to do",
    "start": "1129520",
    "end": "1136200"
  },
  {
    "text": "well at med school and if they do well at med school they tend to do well when practicing",
    "start": "1136200",
    "end": "1141640"
  },
  {
    "text": "medicine so the reason that this works the reason that we can use exams as a",
    "start": "1141640",
    "end": "1146760"
  },
  {
    "text": "proxy for future performance is because of the way that humans learn so humans",
    "start": "1146760",
    "end": "1152080"
  },
  {
    "text": "have a mechanism called G or general intelligence and this allows us to",
    "start": "1152080",
    "end": "1157480"
  },
  {
    "text": "generalize to apply the same sort of skills to multiple related um situations so in the case of",
    "start": "1157480",
    "end": "1165679"
  },
  {
    "text": "medical exams what you're tapping into are things like learned knowledge or reasoning and people who are good at",
    "start": "1165679",
    "end": "1172520"
  },
  {
    "text": "applying both of these to Medical exams also tend to be good at applying these",
    "start": "1172520",
    "end": "1177679"
  },
  {
    "text": "to practicing medicine so what does it mean when an llm does really well at say a medical",
    "start": "1177679",
    "end": "1184960"
  },
  {
    "text": "exam well it means that the llm is really good at completing the sort of questions that are on medical exams",
    "start": "1184960",
    "end": "1191039"
  },
  {
    "text": "nothing more nothing less so I know you've got some doubts you're thinking",
    "start": "1191039",
    "end": "1196679"
  },
  {
    "text": "why like why can we not assume that this is a proxy for general intelligence in llms and the reason for this is due to",
    "start": "1196679",
    "end": "1204440"
  },
  {
    "text": "the way that llms are trained so training any type of machine learning",
    "start": "1204440",
    "end": "1209960"
  },
  {
    "text": "model is really cumbersome and what it means is that the way we set up machine learning models to train is with very",
    "start": "1209960",
    "end": "1215840"
  },
  {
    "text": "specific goals in mind so in the case of cheex net this was simply to detect whether lung scans show signs of",
    "start": "1215840",
    "end": "1222679"
  },
  {
    "text": "pneumonia or not that is the only thing that model was trained to do in the case of llms it's a little more complex but",
    "start": "1222679",
    "end": "1229039"
  },
  {
    "text": "with the sort of llms that everyone is talking about the generative llms they were trained to predict the next word in",
    "start": "1229039",
    "end": "1234840"
  },
  {
    "text": "a sentence it's really what they were all they were trained to do so let's talk through the process of training",
    "start": "1234840",
    "end": "1241559"
  },
  {
    "text": "these sort of models what you have is a batch of the training data and for that",
    "start": "1241559",
    "end": "1247039"
  },
  {
    "text": "training data with these sort of models you'll have a correct answer you know the next word in the sentence is known",
    "start": "1247039",
    "end": "1253559"
  },
  {
    "text": "what the model would do is make some sort of prediction about what it thinks the correct word is then what it'll do",
    "start": "1253559",
    "end": "1259400"
  },
  {
    "text": "is compare it against the correct answer and to sort of understand how this training works these models are",
    "start": "1259400",
    "end": "1265280"
  },
  {
    "text": "initialized randomly so these guesses at the beginning are going to be random they're going to be very inaccurate so",
    "start": "1265280",
    "end": "1272200"
  },
  {
    "text": "the model then needs to update model weights am I beeping someone is beeping",
    "start": "1272200",
    "end": "1279279"
  },
  {
    "text": "it's okay it sounded like it was coming from behind me so I was very confused so the model needs to update its weights",
    "start": "1279279",
    "end": "1286320"
  },
  {
    "text": "and it then needs to do that over and over and over again across all of the training data until it reaches a good",
    "start": "1286320",
    "end": "1293200"
  },
  {
    "text": "performance so because this is so cumbersome the way these models have been designed is with mechanisms that",
    "start": "1293200",
    "end": "1298520"
  },
  {
    "text": "take the shortest path possible to get to this training goal mechanisms like gradient descent and it's very very",
    "start": "1298520",
    "end": "1304760"
  },
  {
    "text": "unlikely because of this optimization that a model is going to randomly go off develop something like general",
    "start": "1304760",
    "end": "1310640"
  },
  {
    "text": "intelligence that's not strictly needed to solve the problem and then go to the training goal this might feel like a",
    "start": "1310640",
    "end": "1316640"
  },
  {
    "text": "slightly shallow explanation of this I do have another talk I gave at NDC Oslo which dives into the assessment of",
    "start": "1316640",
    "end": "1322559"
  },
  {
    "text": "intelligence if you want to look at that a little bit more but generally that's the gist of it really these models are",
    "start": "1322559",
    "end": "1329240"
  },
  {
    "text": "not displaying general intelligence they're just displaying pattern matching that makes them look like they mimic our",
    "start": "1329240",
    "end": "1335279"
  },
  {
    "text": "general intelligence when solving these tests so we've concluded that benchmarks",
    "start": "1335279",
    "end": "1341520"
  },
  {
    "text": "for humans are no good so what about benchmarks that are specifically designed for",
    "start": "1341520",
    "end": "1347080"
  },
  {
    "text": "llms let's go back to this table that we looked at a few slides ago so this is a",
    "start": "1347080",
    "end": "1352720"
  },
  {
    "text": "llm leader board which is created by a company called hugging face and up until",
    "start": "1352720",
    "end": "1358360"
  },
  {
    "text": "around 6 months ago this was one of the key ways of assessing whether open",
    "start": "1358360",
    "end": "1364440"
  },
  {
    "text": "source llms were any good so basically what hugging face would do is it would get hold of these open source models run",
    "start": "1364440",
    "end": "1371760"
  },
  {
    "text": "them against a series of gold standard benchmarks and then basically tally up",
    "start": "1371760",
    "end": "1376880"
  },
  {
    "text": "those scores combine them in some way and use them to rank and rate these",
    "start": "1376880",
    "end": "1382880"
  },
  {
    "text": "models but in June of last year something rather strange happened this",
    "start": "1382880",
    "end": "1388120"
  },
  {
    "text": "very trusted table was retired and a new one was bought in with new",
    "start": "1388120",
    "end": "1394400"
  },
  {
    "text": "benchmarks so what happened here like what happened to these benchmarks why don't we want to use them",
    "start": "1394400",
    "end": "1399880"
  },
  {
    "text": "anymore well there are a few reasons but one of the funniest is that the gold",
    "start": "1399880",
    "end": "1405440"
  },
  {
    "text": "standard you know label that we'd applied to these benchmarks was perhaps not as deserved as you might think so",
    "start": "1405440",
    "end": "1413600"
  },
  {
    "text": "these benchmarks when people started going through them were discovered to have many problems problems with typos",
    "start": "1413600",
    "end": "1420640"
  },
  {
    "text": "problems with like incomprehensibility incorrect ansers so I'm going to show you a few examples",
    "start": "1420640",
    "end": "1427120"
  },
  {
    "text": "from these and uh I really want to make it clear when I show you each of these I haven't changed them at all these are",
    "start": "1427120",
    "end": "1434080"
  },
  {
    "text": "exactly as they're displayed in The Benchmark so we're going to start with a question from the MML and this used to",
    "start": "1434080",
    "end": "1440840"
  },
  {
    "text": "be such a trusted measure for assessing the performance of llms not just open source but the big ones like the ones",
    "start": "1440840",
    "end": "1447240"
  },
  {
    "text": "from open AI the companies would be measuring their performance on the mlu to two decimal places so let's see a",
    "start": "1447240",
    "end": "1454919"
  },
  {
    "text": "question from this the complexity of the",
    "start": "1454919",
    "end": "1460120"
  },
  {
    "text": "theory now this is the whole question I'm not leaving anything out all right maybe there's some more",
    "start": "1460120",
    "end": "1467000"
  },
  {
    "text": "clues in the answer set said 1 2 3 4 1 3",
    "start": "1467000",
    "end": "1472399"
  },
  {
    "text": "4 1 2 3 1 2 4 these numbers don't match up to",
    "start": "1472399",
    "end": "1478720"
  },
  {
    "text": "anything this is the full information that the llm is given and remember we're trying to assess whether these llms can",
    "start": "1478720",
    "end": "1485600"
  },
  {
    "text": "solve these problems to a human level can you answer this question would you",
    "start": "1485600",
    "end": "1490640"
  },
  {
    "text": "be able to guess that the answer is C I couldn't so let's have a look at another",
    "start": "1490640",
    "end": "1497440"
  },
  {
    "text": "one so this is from a very popular Benchmark measure called helis swag and the idea behind helis swag is you're",
    "start": "1497440",
    "end": "1503760"
  },
  {
    "text": "essentially trying to see whether an llm or a human can deduct what's happening in a setup scenario and complete that",
    "start": "1503760",
    "end": "1511360"
  },
  {
    "text": "scenario and again I've typed this out exactly as it appears in The Benchmark men are standing in a large",
    "start": "1511360",
    "end": "1518720"
  },
  {
    "text": "Green Field playing lacrosse people is around the field watching the game men",
    "start": "1518720",
    "end": "1525200"
  },
  {
    "text": "are holding t-shirts watching into lacrosse playing are being interviewed in a podium in front of a large group",
    "start": "1525200",
    "end": "1531200"
  },
  {
    "text": "and a gymnast is holding a microphone for the announcers a running side to side of the eeld playing lacrosse trying",
    "start": "1531200",
    "end": "1537200"
  },
  {
    "text": "to score are in a field running around playing",
    "start": "1537200",
    "end": "1542960"
  },
  {
    "text": "lacrosse now every time I read this question I feel like I'm having a fe fever dream it is so weird but typos and",
    "start": "1543039",
    "end": "1551360"
  },
  {
    "text": "bizarre imagery aside I'm guessing we're meant to answer that the men are playing lacrosse but",
    "start": "1551360",
    "end": "1557120"
  },
  {
    "text": "both C and D tell us is which is the correct one I also want to say from helis swag there were worse questions",
    "start": "1557120",
    "end": "1563760"
  },
  {
    "text": "but I couldn't put them in the slides because I couldn't read them out they're just so broken I encourage you to look at this",
    "start": "1563760",
    "end": "1570360"
  },
  {
    "text": "paper it's really funny there's a lot of really good examples and then finally just one more",
    "start": "1570360",
    "end": "1577320"
  },
  {
    "text": "this is from a measure called Common Sense QA the pr I think I was see as",
    "start": "1577320",
    "end": "1583039"
  },
  {
    "text": "well yeah but you know doesn't matter",
    "start": "1583039",
    "end": "1590240"
  },
  {
    "text": "so one more this is from a measure called Common Sense QA this is also a very popular measure so we off to a good",
    "start": "1590520",
    "end": "1596120"
  },
  {
    "text": "start the question actually makes sense when a person is breathing in a paper bag what are they trying to do but uh",
    "start": "1596120",
    "end": "1602320"
  },
  {
    "text": "let's not get too excited let's look at the answers warm air continue to live",
    "start": "1602320",
    "end": "1608440"
  },
  {
    "text": "going to sleep hyperventilation stay alive now I don't know about you but I",
    "start": "1608440",
    "end": "1616320"
  },
  {
    "text": "don't think any of these are what you're trying to do do when you breathe into a paper bag so again what's this poor llm",
    "start": "1616320",
    "end": "1622960"
  },
  {
    "text": "supposed to do if we can't even answer these questions and I know this section probably feels a bit like I'm",
    "start": "1622960",
    "end": "1628760"
  },
  {
    "text": "cherry-picking and just picking out one or two you know really bad examples 36%",
    "start": "1628760",
    "end": "1634360"
  },
  {
    "text": "of helis Swag was thought to actually have answer or questions that were as bad as the one that I showed you on the",
    "start": "1634360",
    "end": "1640840"
  },
  {
    "text": "last slide and there are probably hundreds of such really really bad",
    "start": "1640840",
    "end": "1646440"
  },
  {
    "text": "questions throughout the gold standard Ben marks so this is one of the reasons why hugging face retired their old",
    "start": "1646440",
    "end": "1653080"
  },
  {
    "text": "leaderboard and why they brought in a new one these new bench marks are better curated they're checked for accuracy and",
    "start": "1653080",
    "end": "1660279"
  },
  {
    "text": "they have less of this sort of random garbage so I guess the question we now",
    "start": "1660279",
    "end": "1666000"
  },
  {
    "text": "have is okay we have these great new benchmarks does this mean that we've solved the problem does getting 100% on",
    "start": "1666000",
    "end": "1672600"
  },
  {
    "text": "all of these benchmarks mean that an llm is good and I hope you've realized we are now halfway through the time slot",
    "start": "1672600",
    "end": "1679440"
  },
  {
    "text": "and the answer is of course no because I have so much more to show you one of the things I want to show you is a really",
    "start": "1679440",
    "end": "1686159"
  },
  {
    "text": "fundamental problem and that's actually how llms answer each of these Benchmark",
    "start": "1686159",
    "end": "1692559"
  },
  {
    "text": "questions so llms have two ways in which they can answer Benchmark questions they",
    "start": "1692559",
    "end": "1697919"
  },
  {
    "text": "can first be presented with a series of multiple choice options so for example if you would ask an llm what is the",
    "start": "1697919",
    "end": "1704799"
  },
  {
    "text": "capital of Portugal you can give it a number of options and it can either tell you be or Lisbon or some combination",
    "start": "1704799",
    "end": "1711360"
  },
  {
    "text": "thereof and you will know is correct or it can of course generate free form",
    "start": "1711360",
    "end": "1716760"
  },
  {
    "text": "answers so if we were to ask what is the capital of Portugal and it tells us something like the capital of Portugal",
    "start": "1716760",
    "end": "1722320"
  },
  {
    "text": "is lesbian then of course it's going to be correct now you might have noticed",
    "start": "1722320",
    "end": "1727679"
  },
  {
    "text": "that all of the examples I've given you so far are using multiple choice options and that's because being able to assess",
    "start": "1727679",
    "end": "1734559"
  },
  {
    "text": "whether a multiple choice option is correct in an automated way is much much easier than if an llm generates a free",
    "start": "1734559",
    "end": "1742039"
  },
  {
    "text": "form answer so what's the problem we can just use multiple choice for everything right",
    "start": "1742039",
    "end": "1748240"
  },
  {
    "text": "well wrong a fundamental problem we have with llms is that their performance on",
    "start": "1748240",
    "end": "1754559"
  },
  {
    "text": "benchmarks is actually affected by which one of these answer types we ask them to use so here are three llms that are",
    "start": "1754559",
    "end": "1762320"
  },
  {
    "text": "answering questions from the same Benchmark and here's how they perform when they're presented with multiple",
    "start": "1762320",
    "end": "1767679"
  },
  {
    "text": "choices options and here's how they perform on the same Benchmark when they have to generate a free form",
    "start": "1767679",
    "end": "1775399"
  },
  {
    "text": "answer now what you can see is that in the case of every single llm they perform worse when they're asked to",
    "start": "1775399",
    "end": "1782519"
  },
  {
    "text": "generate an answer but it gets worse than this the problem the real problem",
    "start": "1782519",
    "end": "1788480"
  },
  {
    "text": "is they're not actually getting the same items correct between the two answer types which of course is a validity",
    "start": "1788480",
    "end": "1795360"
  },
  {
    "text": "issue the two answer types are measuring two different things and what",
    "start": "1795360",
    "end": "1800640"
  },
  {
    "text": "researchers believe is that multiple choice Taps more into rote memorization whereas being able to generate a correct",
    "start": "1800640",
    "end": "1808039"
  },
  {
    "text": "free form answer Taps more into creativity and reasoning we have another issue another",
    "start": "1808039",
    "end": "1815200"
  },
  {
    "text": "about convergent validity so remember I said that an aspect of validity is that you should have uh when you have uh two",
    "start": "1815200",
    "end": "1823240"
  },
  {
    "text": "related measures they should actually converge like an llm complete one",
    "start": "1823240",
    "end": "1828440"
  },
  {
    "text": "measure assessing one thing and and measure complete assessing something related those scores should be",
    "start": "1828440",
    "end": "1834480"
  },
  {
    "text": "correlated but we're finding this isn't actually the case so let's have a look at this simple reasoning puzzle Alice",
    "start": "1834480",
    "end": "1842600"
  },
  {
    "text": "has three brothers and she also has six sisters how many sisters does Alice's",
    "start": "1842600",
    "end": "1847840"
  },
  {
    "text": "brother have now you're all developers I know you love to solve puzzles I'll give you a few seconds does anyone want to",
    "start": "1847840",
    "end": "1854360"
  },
  {
    "text": "try and guess and Shout out perfect so let's solve it together",
    "start": "1854360",
    "end": "1860279"
  },
  {
    "text": "so Alice is a woman's name so Alice is of course one of the prospective sisters and then there are six other sisters so",
    "start": "1860279",
    "end": "1867039"
  },
  {
    "text": "if we add those together we get seven potential sisters for each of the brothers so this is part of a suite of",
    "start": "1867039",
    "end": "1874600"
  },
  {
    "text": "reasoning puzzles called Alice and Wonderland for some reason and they're all as difficult as this you know you",
    "start": "1874600",
    "end": "1881320"
  },
  {
    "text": "can see they're not terribly complex and they're designed to assess basic reasoning so what the developers of this",
    "start": "1881320",
    "end": "1887360"
  },
  {
    "text": "Suite of puzzle puzzles did is they got a bunch of state-of-the-art llms to complete these puzzles then they got",
    "start": "1887360",
    "end": "1893080"
  },
  {
    "text": "them to complete the MML U which is also designed to assess reasoning so what you",
    "start": "1893080",
    "end": "1899480"
  },
  {
    "text": "would expect is we have two measures that are basically assessing overlapping things so in that case you would expect",
    "start": "1899480",
    "end": "1906639"
  },
  {
    "text": "that the scores should be highly correlated in fact like in in that sense they should lie along this diagonal",
    "start": "1906639",
    "end": "1913200"
  },
  {
    "text": "line what they found was a pattern like this what's going on here what this",
    "start": "1913200",
    "end": "1919960"
  },
  {
    "text": "tells us is that every single one of the llms got much higher scores on the MML",
    "start": "1919960",
    "end": "1926039"
  },
  {
    "text": "than they did on these basic reasoning puzzles and even worse most of the llms",
    "start": "1926039",
    "end": "1931480"
  },
  {
    "text": "were getting less than 5% of the Alis in Wonderland puzzles correct while they were getting more than 50% of the MML U",
    "start": "1931480",
    "end": "1938679"
  },
  {
    "text": "items correct now this tells us two things it tells us that the mlu mlu is",
    "start": "1938679",
    "end": "1944679"
  },
  {
    "text": "probably not assessing reasoning not in the way that it's claiming and it also tells us that these reasoning",
    "start": "1944679",
    "end": "1950799"
  },
  {
    "text": "capabilities of llms if they're based on the mlu are probably",
    "start": "1950799",
    "end": "1956399"
  },
  {
    "text": "overstated this is the thing these are language models it's in the name so",
    "start": "1956399",
    "end": "1962080"
  },
  {
    "text": "should they even be trying to assess things like reasoning or other non-",
    "start": "1962080",
    "end": "1967360"
  },
  {
    "text": "language problems so let's go back to the beginning of this talk when I was",
    "start": "1967360",
    "end": "1972799"
  },
  {
    "text": "talking about what machine learning models are designed to do machine learning models are trained by Design to",
    "start": "1972799",
    "end": "1980080"
  },
  {
    "text": "have very specific problem domains they're designed to solve very specific things so in the case of say an image",
    "start": "1980080",
    "end": "1986799"
  },
  {
    "text": "classification model is designed to just tell whether a picture is a dog or a cat or some other animal perhaps and in the",
    "start": "1986799",
    "end": "1994480"
  },
  {
    "text": "early days llms were the same the first llms were actually designed to do machine translation it's a very concrete",
    "start": "1994480",
    "end": "2001760"
  },
  {
    "text": "problem and they were applied to other things like summarization or question",
    "start": "2001760",
    "end": "2007399"
  },
  {
    "text": "answer these are very specific natural language processing problems so in the",
    "start": "2007399",
    "end": "2013320"
  },
  {
    "text": "early days what we had was a suite of benchmarks that were designed to assess just this they were designed to assess",
    "start": "2013320",
    "end": "2020200"
  },
  {
    "text": "like how well can a model complete question answering how well can it do",
    "start": "2020200",
    "end": "2026080"
  },
  {
    "text": "classification of text but as the capabilities of these models have grown or as they appear to have grown because",
    "start": "2026080",
    "end": "2033480"
  },
  {
    "text": "I hope I planted that seed of Doubt we've come up with more and more EXO benchmarks to try and capture this so",
    "start": "2033480",
    "end": "2041159"
  },
  {
    "text": "you know we've come up with benchmarks to try to see whether these models have advanced reasoning capabilities we try",
    "start": "2041159",
    "end": "2046480"
  },
  {
    "text": "to come up with benchmarks to see whether they have deep domain domain knowledge across technical areas and",
    "start": "2046480",
    "end": "2051839"
  },
  {
    "text": "we've even come up with benchmarks to try to assess whether these models are showing signs of artificial general",
    "start": "2051839",
    "end": "2057158"
  },
  {
    "text": "intelligence or AGI now for me this Taps into one of the",
    "start": "2057159",
    "end": "2062520"
  },
  {
    "text": "core validity issues with llms you as a user are going to pick an llm to do",
    "start": "2062520",
    "end": "2069398"
  },
  {
    "text": "something specific maybe you want it to do classification maybe you want it to do question answering maybe you want a",
    "start": "2069399",
    "end": "2076358"
  },
  {
    "text": "chat bot that can answer questions for your customers but what you're going to be",
    "start": "2076359",
    "end": "2082200"
  },
  {
    "text": "using to pick your llm is maybe a leaderboard that assesses it across 12",
    "start": "2082200",
    "end": "2087440"
  },
  {
    "text": "different measures none of them have that have anything to do with your use case so by trying to assess llms and",
    "start": "2087440",
    "end": "2095800"
  },
  {
    "text": "present their performance in such broad Strokes we've really lost touch with what we're really trying to use them for",
    "start": "2095800",
    "end": "2103160"
  },
  {
    "text": "there's a big gap between the assessment in the public domain and how you're going to need to be able to assess them",
    "start": "2103160",
    "end": "2109760"
  },
  {
    "text": "within your application so benchmarks are no good so",
    "start": "2109760",
    "end": "2116359"
  },
  {
    "text": "you might be thinking is there some sort of alternative to this those of you in the know might be screaming at me",
    "start": "2116359",
    "end": "2122000"
  },
  {
    "text": "internally right now what about the chatbot Arena and those of you who have no idea what I'm talking about a",
    "start": "2122000",
    "end": "2127359"
  },
  {
    "text": "thinking godamn you really like giving things weird names in machine learning and that is also true so the chatbot",
    "start": "2127359",
    "end": "2134359"
  },
  {
    "text": "arena is an experiment present it as a website anyone can go to it and",
    "start": "2134359",
    "end": "2140440"
  },
  {
    "text": "basically what you do is you think of a prompt any prompt you want to give an LM what the Chapo Arena will do is go away",
    "start": "2140440",
    "end": "2146680"
  },
  {
    "text": "and it will pick two state-of-the-art llms to present you with two competing ansers and your job is to pick the one",
    "start": "2146680",
    "end": "2154319"
  },
  {
    "text": "that you like best so I've gone there and I've entered please write me a poem",
    "start": "2154319",
    "end": "2159359"
  },
  {
    "text": "about sausages and I am quite partial to this second answer blump and juicy in a",
    "start": "2159359",
    "end": "2164440"
  },
  {
    "text": "row they lie sausages waiting to satisfy so the results of my experiment and",
    "start": "2164440",
    "end": "2170400"
  },
  {
    "text": "everyone else's experiment who goes to this website are combined in something called an ELO score and this is then",
    "start": "2170400",
    "end": "2176240"
  },
  {
    "text": "used to of course Rank and rate llms and they have their own leaderboard to display these",
    "start": "2176240",
    "end": "2182079"
  },
  {
    "text": "results so the chapot arena is seen as one of the most trustworthy ways to",
    "start": "2182079",
    "end": "2187839"
  },
  {
    "text": "assess llms right now people like Andre Kathy who's an absolute Giant in this area has come out in support of",
    "start": "2187839",
    "end": "2195119"
  },
  {
    "text": "it and in some ways it's true the chatbot Arena shows High validity",
    "start": "2195119",
    "end": "2202160"
  },
  {
    "text": "because it's a direct reflection of how end users are going to receive llm",
    "start": "2202160",
    "end": "2208040"
  },
  {
    "text": "outputs so you know it's based currently on a more than a million experiments and",
    "start": "2208040",
    "end": "2214160"
  },
  {
    "text": "those experiments are conducted by just people like you and me who have a really broad range of experiences of",
    "start": "2214160",
    "end": "2221200"
  },
  {
    "text": "preferences and you know the prompts that they're going to use you got ridiculous people like me coming along",
    "start": "2221200",
    "end": "2226599"
  },
  {
    "text": "and asking for poems about sausages and then you got people asking for actual serious things so you might be thinking",
    "start": "2226599",
    "end": "2233280"
  },
  {
    "text": "fantastic we've solved this problem of llm assessment but again let's not get",
    "start": "2233280",
    "end": "2238800"
  },
  {
    "text": "too excited one of the problems that you might have spotted is the way that",
    "start": "2238800",
    "end": "2244440"
  },
  {
    "text": "you're asked to assess whether an output is worthwhile from an llm and the terms",
    "start": "2244440",
    "end": "2251200"
  },
  {
    "text": "that the chb AR Arena uses is good and bad now what does this mean what does",
    "start": "2251200",
    "end": "2259880"
  },
  {
    "text": "the output of an llm being good really mean does it mean that it's for both",
    "start": "2259880",
    "end": "2265640"
  },
  {
    "text": "does it mean that it's concise does it mean that it's accurate does it mean that it's moving it's funny it's witty",
    "start": "2265640",
    "end": "2271240"
  },
  {
    "text": "it's entertaining does my sausage poem being good mean the same thing as a",
    "start": "2271240",
    "end": "2276839"
  },
  {
    "text": "resignation email to your boss being good a eulogy for your friend being good you know these are very different types",
    "start": "2276839",
    "end": "2282760"
  },
  {
    "text": "of content so the problem is is we are now stuck with a low validity term in",
    "start": "2282760",
    "end": "2288359"
  },
  {
    "text": "order to try and capture everything that we want llms to do you know basically",
    "start": "2288359",
    "end": "2295079"
  },
  {
    "text": "the the reach the application of these models has become so diverse that",
    "start": "2295079",
    "end": "2300480"
  },
  {
    "text": "creators of things like the chatbot Arena are stuck with such vague terms in order to assess them that they",
    "start": "2300480",
    "end": "2307000"
  },
  {
    "text": "essentially become meaningless so right now I've been",
    "start": "2307000",
    "end": "2312760"
  },
  {
    "text": "really hammering validity home but we haven't forgotten about reliability so let's Circle back to",
    "start": "2312760",
    "end": "2320440"
  },
  {
    "text": "that so one of the problems with the",
    "start": "2321079",
    "end": "2326119"
  },
  {
    "text": "measurement of llms is that they're trained on absolutely enormous public data sets in fact it's estimated that a",
    "start": "2326119",
    "end": "2334280"
  },
  {
    "text": "huge chunk of the current public internet is being consumed for their training and to kind of compound this",
    "start": "2334280",
    "end": "2341560"
  },
  {
    "text": "problem the creators of llms even the open source ones have become increasingly cagy about what is actually",
    "start": "2341560",
    "end": "2348800"
  },
  {
    "text": "used for their training so it makes it really hard for us as consumers to get a good idea of what was actually used to",
    "start": "2348800",
    "end": "2354960"
  },
  {
    "text": "train that model and what it's seen before so this might sound very familiar to you and of course it's there on the",
    "start": "2354960",
    "end": "2361160"
  },
  {
    "text": "screen this is a data leakage problem if you're trying to assess a model",
    "start": "2361160",
    "end": "2368119"
  },
  {
    "text": "you don't know what it's actually seen during training so you might show it something that it's seen before and",
    "start": "2368119",
    "end": "2374520"
  },
  {
    "text": "that's essentially going to be very confusing to you is the model actually showing reasoning is it actually",
    "start": "2374520",
    "end": "2380200"
  },
  {
    "text": "completing a novel task well or is it just regurgitating something it",
    "start": "2380200",
    "end": "2385240"
  },
  {
    "text": "memorized during training so a really nice example of this circulated on Twitter around two years ago around the",
    "start": "2385240",
    "end": "2392079"
  },
  {
    "text": "time that GPT 4 came out so when everyone was getting very excited about these models completing leak code",
    "start": "2392079",
    "end": "2397960"
  },
  {
    "text": "puzzles a researcher called Horus hay got a little suspicious and he started thinking this sounds like a data leakage",
    "start": "2397960",
    "end": "2405119"
  },
  {
    "text": "issue so what he did is he went to a website called code forces and code",
    "start": "2405119",
    "end": "2410160"
  },
  {
    "text": "forces has lead code um type puzzles and what makes it really good for this particular experiment is that each of",
    "start": "2410160",
    "end": "2417480"
  },
  {
    "text": "the um the dates that the puzzles were released is clearly marked so what hay",
    "start": "2417480",
    "end": "2422599"
  },
  {
    "text": "did is he got a sample of 10 puzzles that were released during the train tring period of GPT 4 so the model could",
    "start": "2422599",
    "end": "2429720"
  },
  {
    "text": "have had access to it in the training data and he passed each of them through the model and got each of them correct",
    "start": "2429720",
    "end": "2436960"
  },
  {
    "text": "well congratulations coming for our job GPT 4 but then what he did is he got",
    "start": "2436960",
    "end": "2442240"
  },
  {
    "text": "another 10 puzzles that were released after the model had trained so it could not have had access to them during the",
    "start": "2442240",
    "end": "2448480"
  },
  {
    "text": "training period and these model these puzzles sorry were of an equivalent level of difficulty and this time gp4",
    "start": "2448480",
    "end": "2456960"
  },
  {
    "text": "got every single one of them wrong so it smells like data leakage and to confirm",
    "start": "2456960",
    "end": "2462560"
  },
  {
    "text": "this another researcher s kapor directly prompted the model he asked the model",
    "start": "2462560",
    "end": "2468040"
  },
  {
    "text": "which code forces is aquam Moon and two arays from a model that was available when sorry a puzzle that was available",
    "start": "2468040",
    "end": "2475160"
  },
  {
    "text": "when the model was trained and obligingly gbt 4 vomited up the complete",
    "start": "2475160",
    "end": "2480599"
  },
  {
    "text": "source so confirmed that it had in fact trained on these puzzles so this",
    "start": "2480599",
    "end": "2485680"
  },
  {
    "text": "illustrates really like clearly that it's really difficult to trust these face value sort of tests on",
    "start": "2485680",
    "end": "2492440"
  },
  {
    "text": "performance of llms because you just don't know what the models seen during training now this problem is compounded",
    "start": "2492440",
    "end": "2500560"
  },
  {
    "text": "oh sorry this problem goes so deep that it doesn't just affect informal assessments like the one I showed you it",
    "start": "2500560",
    "end": "2507119"
  },
  {
    "text": "actually has affected the benchmarks so a review was done of the benchmarks that",
    "start": "2507119",
    "end": "2513280"
  },
  {
    "text": "the GPT models um sorry chat GPT models have had exposure to and it was found",
    "start": "2513280",
    "end": "2518880"
  },
  {
    "text": "that dozens of these benchmarks had at least partially leaked into the training data you can see that 75 question",
    "start": "2518880",
    "end": "2527000"
  },
  {
    "text": "answering benchmarks alone had partially leaked into the training data for these models and you can see this leakage",
    "start": "2527000",
    "end": "2534960"
  },
  {
    "text": "affected benchmarks across pretty much all of the major ways that we assess these models natural language inference",
    "start": "2534960",
    "end": "2541280"
  },
  {
    "text": "natural language generation summarization math and programming and to pound this problem",
    "start": "2541280",
    "end": "2549400"
  },
  {
    "text": "further the amount of data that is actually a sufficient quality to train",
    "start": "2549400",
    "end": "2554599"
  },
  {
    "text": "and assess these models is a finite resource and we're actually relatively close to running out of it so the",
    "start": "2554599",
    "end": "2561960"
  },
  {
    "text": "current sort of wisdom for at least at least until last year is the best way to",
    "start": "2561960",
    "end": "2568280"
  },
  {
    "text": "scale models is to make them bigger to feed more data in and give them more",
    "start": "2568280",
    "end": "2573359"
  },
  {
    "text": "parameters this of course could be changing with the announcement of seek but definitely until last year this was",
    "start": "2573359",
    "end": "2580359"
  },
  {
    "text": "the wisdom so you can actually see the growth in model size and uh you can see",
    "start": "2580359",
    "end": "2585520"
  },
  {
    "text": "that this is an exponential scale we went from I think it was 500 billion",
    "start": "2585520",
    "end": "2591280"
  },
  {
    "text": "tokens let me just check my notes um yeah we had 15 trillion token",
    "start": "2591280",
    "end": "2599280"
  },
  {
    "text": "sorry 500 billion tokens were used to train gpt3 and that was back in 2020 and",
    "start": "2599280",
    "end": "2606000"
  },
  {
    "text": "this shot up to 15 trillion tokens used to train llama 3 last year so that is a",
    "start": "2606000",
    "end": "2613760"
  },
  {
    "text": "30 fold increase in the amount of training data so the problem is is that",
    "start": "2613760",
    "end": "2619440"
  },
  {
    "text": "the amount of usable training data we think we have is around 300 trillion",
    "start": "2619440",
    "end": "2625760"
  },
  {
    "text": "tokens and if we continue this sort of scale approach to training models we're",
    "start": "2625760",
    "end": "2630839"
  },
  {
    "text": "probably going to run out of data in less than a decade and potentially as soon as 2 years so this is data leakage",
    "start": "2630839",
    "end": "2638359"
  },
  {
    "text": "on a scale I have frankly never seen it's extreme what it essentially means",
    "start": "2638359",
    "end": "2643400"
  },
  {
    "text": "is that you as a lay user of these models will have no way of knowing",
    "start": "2643400",
    "end": "2649240"
  },
  {
    "text": "whether the model has seen something before that you're using to assess its performance and really you're going to",
    "start": "2649240",
    "end": "2654880"
  },
  {
    "text": "be fooled into thinking that it's performing a lot better than it it really is and when you present it with",
    "start": "2654880",
    "end": "2660359"
  },
  {
    "text": "fresh data from your customers it's not going to perform in the way that you think it",
    "start": "2660359",
    "end": "2665800"
  },
  {
    "text": "will so let's end off this section on reliability with everyone's favorite",
    "start": "2665800",
    "end": "2671119"
  },
  {
    "text": "topic which is prompt engineering I'm sadly not going to be telling you how to earn a million dollars a year in Silicon",
    "start": "2671119",
    "end": "2677079"
  },
  {
    "text": "Valley I'm going to be talking about something a bit more depressing and that is prompt sensitivity now llms are wildly",
    "start": "2677079",
    "end": "2685640"
  },
  {
    "text": "sensitive to the format that you put your prompts in this changes their performance enormously so let's look at",
    "start": "2685640",
    "end": "2692880"
  },
  {
    "text": "an example of this let's say we're trying to do a text classification task and what we want to do is we want to",
    "start": "2692880",
    "end": "2698839"
  },
  {
    "text": "sort a passage into a number of predefined answers so we can put the passage at the top of this template and",
    "start": "2698839",
    "end": "2705359"
  },
  {
    "text": "we can put the answers at the bottom or maybe we could format this template a little bit differently so can",
    "start": "2705359",
    "end": "2713119"
  },
  {
    "text": "you spot the difference between these prompt templates they're very subtle",
    "start": "2713119",
    "end": "2722519"
  },
  {
    "text": "exactly yeah so spacing punctuation capitalization these are",
    "start": "2727839",
    "end": "2733640"
  },
  {
    "text": "incredibly subtle differences between these prompt templates so they should have no influence on how well our model",
    "start": "2733640",
    "end": "2741160"
  },
  {
    "text": "does our text classification task right well let's see oh my God so what we have",
    "start": "2741160",
    "end": "2747240"
  },
  {
    "text": "is a line indicating the performance the accuracy of these models on the text classification task we go from zero",
    "start": "2747240",
    "end": "2753880"
  },
  {
    "text": "meaning it got nothing right to one meaning it got everything right and those seemingly tiny differences in",
    "start": "2753880",
    "end": "2760880"
  },
  {
    "text": "the prompt templates led to a difference of",
    "start": "2760880",
    "end": "2765920"
  },
  {
    "text": "77% between the worst performing prompt and the best performing prompt now this is outrageous coming",
    "start": "2765920",
    "end": "2773720"
  },
  {
    "text": "from a more traditional machine learning background I can tell you if I built a model that was this unpredictable for",
    "start": "2773720",
    "end": "2780640"
  },
  {
    "text": "essentially equivalent output inputs it would be unusable but this is very much",
    "start": "2780640",
    "end": "2786920"
  },
  {
    "text": "in the fabric of llms this is how they work just to show you this is not a oneoff not a cherry-picked example here",
    "start": "2786920",
    "end": "2794040"
  },
  {
    "text": "we have a number of models that were state-of-the-art around a year ago and with these models essentially the same",
    "start": "2794040",
    "end": "2800319"
  },
  {
    "text": "thing we have semantically equivalent inputs that are leading to between a 30",
    "start": "2800319",
    "end": "2806079"
  },
  {
    "text": "to 50% difference in performance between the best and worst performing prompts",
    "start": "2806079",
    "end": "2812160"
  },
  {
    "text": "now something that makes this even more troubling and I was talking about this with Liam just before we started is you",
    "start": "2812160",
    "end": "2818359"
  },
  {
    "text": "get these performance metric that these companies release this is the absolute best case scenario for how this model is",
    "start": "2818359",
    "end": "2825119"
  },
  {
    "text": "going to perform it's because they have created prompt templates that are exactly tailored to how this model best",
    "start": "2825119",
    "end": "2832800"
  },
  {
    "text": "responds but you as a user of these models are probably not going to know that promt template and you're not going",
    "start": "2832800",
    "end": "2839359"
  },
  {
    "text": "to get just a small reduction potentially in the performance of the model you could be getting half as good",
    "start": "2839359",
    "end": "2844800"
  },
  {
    "text": "performance or worse so maybe I've left you feeling a little",
    "start": "2844800",
    "end": "2850119"
  },
  {
    "text": "sad maybe you're thinking what's the point of using llms I don't even know if it's going to be good or not so maybe I",
    "start": "2850119",
    "end": "2856800"
  },
  {
    "text": "should just give up I'll have a potential solution for you but it's not",
    "start": "2856800",
    "end": "2861839"
  },
  {
    "text": "as sexy as leaderboards and it's not as easy as out of the box benchmarks in",
    "start": "2861839",
    "end": "2867400"
  },
  {
    "text": "fact you're going to see it has a lot in common with the way that we've been assessing software applications for",
    "start": "2867400",
    "end": "2873920"
  },
  {
    "text": "decades now so I recommend you read the blog post that I based this on again",
    "start": "2873920",
    "end": "2880000"
  },
  {
    "text": "you're going to get those resources in a couple of slides there's a guy called Hassan Hassan husin and he is basically",
    "start": "2880000",
    "end": "2887599"
  },
  {
    "text": "running an AI consultancy company very smart guy and he was contracted to build",
    "start": "2887599",
    "end": "2894040"
  },
  {
    "text": "a AI assistant for real estate agents basically the idea is they wanted some sort of interface they could use natural",
    "start": "2894040",
    "end": "2900400"
  },
  {
    "text": "language and get things like house prices and contact details things like that so what his company did is first",
    "start": "2900400",
    "end": "2907880"
  },
  {
    "text": "kind of run through they picked a good llm off the leaderboards and then what",
    "start": "2907880",
    "end": "2913920"
  },
  {
    "text": "they did is they built a basic prompt template to try and get the information they needed you know cover all the basic",
    "start": "2913920",
    "end": "2919319"
  },
  {
    "text": "functions and initially it was working well but very quickly as the edge cases",
    "start": "2919319",
    "end": "2924480"
  },
  {
    "text": "grew the model performance started tanking and they started trying to create more and more banan prompt",
    "start": "2924480",
    "end": "2930280"
  },
  {
    "text": "templates to try and cover this and the only way they were really assessing it is Vibe checks like does it seem better",
    "start": "2930280",
    "end": "2936760"
  },
  {
    "text": "and they realized this was untenable they were not getting anywhere they were just getting into a bigger mess so they went back to the leaderboard and they",
    "start": "2936760",
    "end": "2943400"
  },
  {
    "text": "decided to try something more systematic so they built an assessment tailored to",
    "start": "2943400",
    "end": "2949640"
  },
  {
    "text": "this application from the ground up and the first thing that they introduced was unit tests and the second thing they",
    "start": "2949640",
    "end": "2956160"
  },
  {
    "text": "started doing was logging traces now this feels familiar right it feels a lot more like software engineering and a lot",
    "start": "2956160",
    "end": "2963760"
  },
  {
    "text": "less than like you know esoteric iic machine learning magic and now we've got these in place",
    "start": "2963760",
    "end": "2971319"
  },
  {
    "text": "they started building higher level assessments like manual checking and ab test again this feels very familiar and",
    "start": "2971319",
    "end": "2977640"
  },
  {
    "text": "they were able to use this information to improve on the models through more",
    "start": "2977640",
    "end": "2982720"
  },
  {
    "text": "kind of llm stuff like prompt engineering or fine-tuning and then they built all of this into a rapid iteration",
    "start": "2982720",
    "end": "2989680"
  },
  {
    "text": "cycle based on the feedback so they could quickly make small changes that improve the application so let's go",
    "start": "2989680",
    "end": "2996240"
  },
  {
    "text": "through three of the levels of assessment that hin recommends so the first are unit tests let's see how they",
    "start": "2996240",
    "end": "3002920"
  },
  {
    "text": "will work and they work pretty much in the exact same way that they would work with a traditional software engineering",
    "start": "3002920",
    "end": "3009280"
  },
  {
    "text": "application the one thing he cautions is you can't necessarily expect a 100% pass",
    "start": "3009280",
    "end": "3015280"
  },
  {
    "text": "rate because you're not dealing with something deterministic but you can set your level of comfort with the pass rate",
    "start": "3015280",
    "end": "3021160"
  },
  {
    "text": "up front let's see how we might create these unit tests so let's say one of the Imports is contact information what is",
    "start": "3021160",
    "end": "3029680"
  },
  {
    "text": "the phone number for Emily Johnson well what we're going to trigger in this workflow is that the llm will create a",
    "start": "3029680",
    "end": "3036280"
  },
  {
    "text": "query for a CRM and the CRM will return the phone number so in that case all we",
    "start": "3036280",
    "end": "3042359"
  },
  {
    "text": "need to know is did the CRM return a phone number a very simple approach to",
    "start": "3042359",
    "end": "3047680"
  },
  {
    "text": "this is did we just get an array of length one but if you know the format of the phone number you create something a",
    "start": "3047680",
    "end": "3054319"
  },
  {
    "text": "bit more robust this is just a simp simple unit test exactly the way that you would build them with any other",
    "start": "3054319",
    "end": "3061040"
  },
  {
    "text": "application you can also use llms to help you generate test cases so let's",
    "start": "3061040",
    "end": "3067319"
  },
  {
    "text": "say you want to cover this functionality of retrieving conduct information so you",
    "start": "3067319",
    "end": "3072599"
  },
  {
    "text": "can get the llm to come up with fake contact information to add to your CRM",
    "start": "3072599",
    "end": "3078319"
  },
  {
    "text": "and you can also get it to come up with corresponding user prompts now of course you could also use AI code assistance to",
    "start": "3078319",
    "end": "3085640"
  },
  {
    "text": "help generate the code but you still need to do this the oldfashioned way you still need to use your brain and think",
    "start": "3085640",
    "end": "3091040"
  },
  {
    "text": "about is this actually going to be appropriate um test cases for my",
    "start": "3091040",
    "end": "3096760"
  },
  {
    "text": "application so an approach like this has high validity because we are clearly",
    "start": "3096760",
    "end": "3102040"
  },
  {
    "text": "defining what we're measuring and we have a robust way of assessing that so let's move on to the next level",
    "start": "3102040",
    "end": "3109880"
  },
  {
    "text": "and this is where hin recommends getting humans in the loop so he recommends",
    "start": "3109880",
    "end": "3115119"
  },
  {
    "text": "having a look at the traces which the case of this application are going to be the multi-step interactions between the",
    "start": "3115119",
    "end": "3121160"
  },
  {
    "text": "llm and the rest of the system including the user so what he recommends is taking a",
    "start": "3121160",
    "end": "3127720"
  },
  {
    "text": "representative sample of those traces across all the things you want your llm application to be able to do and just",
    "start": "3127720",
    "end": "3134799"
  },
  {
    "text": "get someone to rate them are they doing what they're supposed to do seems like a",
    "start": "3134799",
    "end": "3140000"
  },
  {
    "text": "lot of work it is but the good news is is once you have a good data set you can",
    "start": "3140000",
    "end": "3145559"
  },
  {
    "text": "start automating it to an extent so you can get another llm to do the same thing",
    "start": "3145559",
    "end": "3151079"
  },
  {
    "text": "and because you've got this data set which is your gold standard you can check whether there's agreement between",
    "start": "3151079",
    "end": "3156640"
  },
  {
    "text": "between what the llm is recommending and what your rer has recommended and this",
    "start": "3156640",
    "end": "3162200"
  },
  {
    "text": "is an approach with good reliability because you're looking at agreement between human raer and machine",
    "start": "3162200",
    "end": "3170040"
  },
  {
    "text": "raer and then finally of course there's AB tests there's always AB tests so once",
    "start": "3170040",
    "end": "3175839"
  },
  {
    "text": "you get to the stage where your llm is ready to go out to your end users you",
    "start": "3175839",
    "end": "3181240"
  },
  {
    "text": "can start experimenting with different things you can have a look at whether the original llm you picked is actually",
    "start": "3181240",
    "end": "3187559"
  },
  {
    "text": "the best one for your use case you can play around with prompt templates and",
    "start": "3187559",
    "end": "3193280"
  },
  {
    "text": "you can also look into potentially find tuning an llm to get a bit more bang for",
    "start": "3193280",
    "end": "3198480"
  },
  {
    "text": "your buck when it comes to the model that you're using and of course this has",
    "start": "3198480",
    "end": "3203599"
  },
  {
    "text": "high validity in the same way that the chatbot Arena has high validity you are directly testing whether your system",
    "start": "3203599",
    "end": "3210480"
  },
  {
    "text": "will be well received by your own users and potentially you might be able to tailor your prompts a bit more for your",
    "start": "3210480",
    "end": "3218160"
  },
  {
    "text": "application maybe it'll lead to higher reliability but not sure if that's the",
    "start": "3218160",
    "end": "3224160"
  },
  {
    "text": "case so let's go back to the opening question can you trust your llm the",
    "start": "3224160",
    "end": "3230839"
  },
  {
    "text": "answer is yes but there are no shortcuts all of this stuff that you're hearing in",
    "start": "3230839",
    "end": "3236200"
  },
  {
    "text": "the media about how good these models are it's not going to be any good for you when it comes to assessing your",
    "start": "3236200",
    "end": "3242160"
  },
  {
    "text": "specific use case you're going to have to do things the oldfashioned way the way that we've always done it you're",
    "start": "3242160",
    "end": "3248000"
  },
  {
    "text": "going to have to Define concrete use cases you're going to have to carve out exactly what you want that model to do",
    "start": "3248000",
    "end": "3253799"
  },
  {
    "text": "and not do and you're going to have to as always build well defined well",
    "start": "3253799",
    "end": "3260720"
  },
  {
    "text": "monitored valid and reliable Assessments in order to see whether it's doing what you need it to",
    "start": "3260720",
    "end": "3267200"
  },
  {
    "text": "so that brings us to the end of the talk here is the QR code if you want to chase up on the resources or on the slides and",
    "start": "3267200",
    "end": "3274040"
  },
  {
    "text": "here are my socials I would love to keep in touch and I think we have about five",
    "start": "3274040",
    "end": "3280000"
  },
  {
    "text": "minutes if there's any questions thank you very [Applause]",
    "start": "3280000",
    "end": "3291799"
  },
  {
    "text": "much um I read something recently saying uh almost running out of",
    "start": "3291799",
    "end": "3299359"
  },
  {
    "text": "training and I heard theory that start using synthetic dat I wonder what yours",
    "start": "3299839",
    "end": "3307319"
  },
  {
    "text": "that just seems to made I'm so happy that seems crazy too um so the question was we are close",
    "start": "3307319",
    "end": "3315119"
  },
  {
    "text": "to running out of synthetic data oh I just want to add to this because this is",
    "start": "3315119",
    "end": "3320359"
  },
  {
    "text": "a g on top um on a different subject the LL Nvidia you can't try train",
    "start": "3320359",
    "end": "3327520"
  },
  {
    "text": "self-driving cars expensive to send them out on the roads we'll create fake environments of our chips to give them",
    "start": "3327520",
    "end": "3333960"
  },
  {
    "text": "the training set data for the cars is even more scary than creating fake text",
    "start": "3333960",
    "end": "3339680"
  },
  {
    "text": "to me yeah yeah yeah so this is a great question so the question was uh because",
    "start": "3339680",
    "end": "3345440"
  },
  {
    "text": "we're coming close to running out of training data should we use synthetic data so there's actually been",
    "start": "3345440",
    "end": "3351119"
  },
  {
    "text": "experiments already on whether we should do this and it's shown that model performance degrades actually quite",
    "start": "3351119",
    "end": "3356920"
  },
  {
    "text": "quickly as you start introducing more and more synthetic data into the training set the reason for this is llms",
    "start": "3356920",
    "end": "3364000"
  },
  {
    "text": "are basically statistical averages so they will take say all of the",
    "start": "3364000",
    "end": "3369079"
  },
  {
    "text": "information you have about let's say I don't know a bird this particular",
    "start": "3369079",
    "end": "3374240"
  },
  {
    "text": "species of bird and it will average it into something that is sort of like the middle of all the information it sees so",
    "start": "3374240",
    "end": "3382000"
  },
  {
    "text": "what this does is it reduces variance variance is a very very important concept when it comes to building robust",
    "start": "3382000",
    "end": "3387599"
  },
  {
    "text": "models because it's essentially able to see a lot of representations of how a",
    "start": "3387599",
    "end": "3392640"
  },
  {
    "text": "thing can exist and be able to predict for it better if it's just presented",
    "start": "3392640",
    "end": "3398319"
  },
  {
    "text": "with an average like a perfect use case or something that doesn't have a lot of Varian it underperforms so this is why",
    "start": "3398319",
    "end": "3406680"
  },
  {
    "text": "there's no shortcuts no free lunch in machine learning oh uh yeah I think you're",
    "start": "3406680",
    "end": "3413799"
  },
  {
    "text": "almost exactly the same time so um yeah just following on from that are we",
    "start": "3413799",
    "end": "3420079"
  },
  {
    "text": "getting to a stage of the world where it's difficult to just we're saying we shouldn't it's not good to train on",
    "start": "3420079",
    "end": "3426240"
  },
  {
    "text": "synthetic data sets but if we're basically taking everything on the web and shuing it into these models a lot of",
    "start": "3426240",
    "end": "3433359"
  },
  {
    "text": "that is now generated from Models itself so we can't tell what sythetic data in",
    "start": "3433359",
    "end": "3439079"
  },
  {
    "text": "that situation yeah and so two parts this question so uh just to repeat the question for everyone basically more of",
    "start": "3439079",
    "end": "3446200"
  },
  {
    "text": "the public internet is becoming flooded with synthetic data synthetic text Data this is true um so again I've read some",
    "start": "3446200",
    "end": "3453160"
  },
  {
    "text": "stuff about this being a concern firstly I want to establish there is no reliable way to automatically distinguish",
    "start": "3453160",
    "end": "3459680"
  },
  {
    "text": "generated text you can get a feel for it if you do it manually I think you've all felt that chat B Vibe but there is no",
    "start": "3459680",
    "end": "3466599"
  },
  {
    "text": "algorithm that can detect this um and yes this is a concern that we're essentially polluting the sources um I",
    "start": "3466599",
    "end": "3474760"
  },
  {
    "text": "think this is probably one of the reasons why the amount of usable data is said to be limited because they're",
    "start": "3474760",
    "end": "3480319"
  },
  {
    "text": "probably limiting it at a certain period of time like pre 2023 or something like",
    "start": "3480319",
    "end": "3487680"
  },
  {
    "text": "that y sorry you had a slide previously I think you're talking about",
    "start": "3487680",
    "end": "3493799"
  },
  {
    "text": "models guess machine learning models trained early on specific things and you assess those specific things with LM",
    "start": "3493799",
    "end": "3500280"
  },
  {
    "text": "there were some specific tests or you were assessing some specific things and now people are expanding that yes we",
    "start": "3500280",
    "end": "3505640"
  },
  {
    "text": "kind of how the LMS are built does it even make sense to expect an LM to be able to have",
    "start": "3505640",
    "end": "3512559"
  },
  {
    "text": "General reasoning or something like that is it just you know people just have wishful thinking about what they might",
    "start": "3512559",
    "end": "3518720"
  },
  {
    "text": "do they imagine something's going to emerge be better place because of it",
    "start": "3518720",
    "end": "3524400"
  },
  {
    "text": "yeah so to repeat the question are people just thinking wishfully that I don't know why I said it that having",
    "start": "3524400",
    "end": "3530079"
  },
  {
    "text": "wishful thinking that llms are showing anything beyond language capabilities due to what they were trained on um I",
    "start": "3530079",
    "end": "3536960"
  },
  {
    "text": "would say the short answer is yes um it's very confusing when you read about",
    "start": "3536960",
    "end": "3542359"
  },
  {
    "text": "this but one of the most compelling things I saw last year is some researchers from Apple released this",
    "start": "3542359",
    "end": "3547640"
  },
  {
    "text": "paper I recommend everyone reads it it's beautiful as Technica did a great write up on it which is talking about all of",
    "start": "3547640",
    "end": "3554640"
  },
  {
    "text": "this sort of supposed reasoning that you're seeing in this specific test which is uh about kind of word puzzles",
    "start": "3554640",
    "end": "3560400"
  },
  {
    "text": "for math which is designed for grade schoolers what they call grade schoolers in America I think like year eight here",
    "start": "3560400",
    "end": "3566960"
  },
  {
    "text": "um it's just pattern matching if you change seemingly innocuous variables it cannot answer equivalent puzzles that it",
    "start": "3566960",
    "end": "3574720"
  },
  {
    "text": "can from the original set because again it's probably data leakage and when you",
    "start": "3574720",
    "end": "3580000"
  },
  {
    "text": "change it enough it can't match to something that looks similar enough in the training set so my feeling at the",
    "start": "3580000",
    "end": "3586839"
  },
  {
    "text": "moment but I don't want to be like yes this is definitely the answer is that a lot of it is an illusion um these",
    "start": "3586839",
    "end": "3593319"
  },
  {
    "text": "so-called emergent capabilities that people are saying happen are really just artifacts of how",
    "start": "3593319",
    "end": "3599640"
  },
  {
    "text": "we assess sorry Dennis just one at the back first and then I'll come to",
    "start": "3599640",
    "end": "3605440"
  },
  {
    "text": "you so part of the way that assessment has changed a bit and I forgot to",
    "start": "3612799",
    "end": "3618079"
  },
  {
    "text": "mention this bit is a lot of the newer generation of benchmarks like the ones",
    "start": "3618079",
    "end": "3623200"
  },
  {
    "text": "used in the redone hugging face uh leaderboard are AR public so if they're",
    "start": "3623200",
    "end": "3628640"
  },
  {
    "text": "private data sets this gives you more assurance that they they haven't leaked they they can't have um part of the",
    "start": "3628640",
    "end": "3636319"
  },
  {
    "text": "problem though is you you can get a sense of what sort of questions will be on these",
    "start": "3636319",
    "end": "3642400"
  },
  {
    "text": "assessments right and so potentially companies can internally create data sets that look very much like it and",
    "start": "3642400",
    "end": "3650280"
  },
  {
    "text": "then when they report really good performance yeah so it's just a",
    "start": "3650280",
    "end": "3656039"
  },
  {
    "text": "suspicion I have but I think that some of the good performance you're seeing is because the models are deliberately",
    "start": "3656039",
    "end": "3662079"
  },
  {
    "text": "being tailored for the assessments so it's not leakage per se but it's something close to",
    "start": "3662079",
    "end": "3668520"
  },
  {
    "text": "it uh Denny and I think that must be the last question maybe more controversial",
    "start": "3668520",
    "end": "3673559"
  },
  {
    "text": "and difficult question but how do you measure the truth let's say in the past",
    "start": "3673559",
    "end": "3678839"
  },
  {
    "text": "different philosophers have different ansers for the truth and in this times also different religions or beliefs",
    "start": "3678839",
    "end": "3685599"
  },
  {
    "text": "people are different but two or not so how do you handle this this is a really good",
    "start": "3685599",
    "end": "3693119"
  },
  {
    "text": "question um yeah so the way that I guess assessments have been structured is",
    "start": "3693119",
    "end": "3700359"
  },
  {
    "text": "around things that do have true or false answers right so it's around things like",
    "start": "3700359",
    "end": "3706799"
  },
  {
    "text": "math puzzles or a reasoning puzzle that you might give to medical students or",
    "start": "3706799",
    "end": "3713039"
  },
  {
    "text": "whatever I think yeah de can you ask yes",
    "start": "3713039",
    "end": "3718279"
  },
  {
    "text": "or no questions that I completely have other Visions from people for example if you ask some people does God exist or uh",
    "start": "3718279",
    "end": "3726720"
  },
  {
    "text": "uh was Jes real Jesus will or something out of USD God or does the law of",
    "start": "3726720",
    "end": "3732960"
  },
  {
    "text": "attraction exist or not so there are kind of no questions with other yeah",
    "start": "3732960",
    "end": "3738799"
  },
  {
    "text": "stuff yeah so I would sort of say this is like this",
    "start": "3738799",
    "end": "3744680"
  },
  {
    "text": "has two components so kind of talking about like how can you assess the truth of some things that llm say first of",
    "start": "3744680",
    "end": "3751480"
  },
  {
    "text": "there Taps into hallucinations no one really has a super good way of assessing them across the board um although there",
    "start": "3751480",
    "end": "3757599"
  },
  {
    "text": "are some measures and they're very interesting um I would say when you're",
    "start": "3757599",
    "end": "3762640"
  },
  {
    "text": "talking about core assessment of llms they do tend to be very concrete because they have to be so there are right and",
    "start": "3762640",
    "end": "3769720"
  },
  {
    "text": "wrong answers but when you're talking about the way people talk about assessing them like let's say leaders of",
    "start": "3769720",
    "end": "3777079"
  },
  {
    "text": "certain large companies running AI software uh we'll talk about things like",
    "start": "3777079",
    "end": "3784279"
  },
  {
    "text": "oh I can't wait until this model can tell me physics facts I don't know you're like what are we even talking about here",
    "start": "3784279",
    "end": "3791559"
  },
  {
    "text": "when when we talk about AGI what are we talking about no one knows how to assess this so there are things that we know",
    "start": "3791559",
    "end": "3797000"
  },
  {
    "text": "how to assess these are tied into what I've talked about but you can see there are still so many problems with this",
    "start": "3797000",
    "end": "3803839"
  },
  {
    "text": "then we have this additional layer where people talking about things you can't even know if they're correct or not and",
    "start": "3803839",
    "end": "3809520"
  },
  {
    "text": "they're talking about how they're going to trust in the model giving them those answers when we don't even know the models can reliably tell us like a",
    "start": "3809520",
    "end": "3816599"
  },
  {
    "text": "recipe for chicken because sometimes they hallucinate so yes I I don't really",
    "start": "3816599",
    "end": "3822000"
  },
  {
    "text": "have an answer but I I think try not to listen to 90% of what you hear people",
    "start": "3822000",
    "end": "3827880"
  },
  {
    "text": "say about llms would be my takeaway and go read that amazing paper by Apple this would",
    "start": "3827880",
    "end": "3834720"
  },
  {
    "text": "be my takeaway L your let me",
    "start": "3834720",
    "end": "3842000"
  },
  {
    "text": "check let me check wait it was out just like one week before presented this",
    "start": "3842000",
    "end": "3848520"
  },
  {
    "text": "what's the key we need to yeah apple reasoning AR Technica search for",
    "start": "3848520",
    "end": "3855520"
  },
  {
    "text": "this yes yeah yeah that will you will find article but that would you to the",
    "start": "3855520",
    "end": "3860720"
  },
  {
    "text": "paper yeah the paper's a little dense I think our Technica did a really good write up on it and that should be enough",
    "start": "3860720",
    "end": "3865920"
  },
  {
    "text": "okay so that's the summary of the pap yeah yeah exactly yeah and I would love",
    "start": "3865920",
    "end": "3873160"
  },
  {
    "text": "to continue chatting with you I'll be around uh during lunch um but I think I",
    "start": "3873160",
    "end": "3878319"
  },
  {
    "text": "need to give the room up now because I've already run over time thank you so so much",
    "start": "3878319",
    "end": "3884400"
  }
]
[
  {
    "text": "hello everyone I think we'll just go ahead and get started thanks a lot for coming and this is the",
    "start": "8850",
    "end": "15910"
  },
  {
    "text": "last session of today I'm happy to see some of you here today's topic is about",
    "start": "15910",
    "end": "21640"
  },
  {
    "text": "powering 100 million daily users my name is result Hawk I'm an",
    "start": "21640",
    "end": "26920"
  },
  {
    "text": "engineering manager at Microsoft I have been working at Microsoft for 8 plus years now and I have been one of the",
    "start": "26920",
    "end": "33940"
  },
  {
    "text": "core team members of building Microsoft Office graph if you are familiar with it today however we'll be talking about",
    "start": "33940",
    "end": "40059"
  },
  {
    "text": "another experience that I am been recently working on and that is basically building a service which",
    "start": "40059",
    "end": "45910"
  },
  {
    "text": "powers people experiences across office 365 so if show of hand how many of you",
    "start": "45910",
    "end": "53980"
  },
  {
    "text": "are familiar with office 365 actually a lot of you that's great",
    "start": "53980",
    "end": "59470"
  },
  {
    "text": "how and all the people experiences that across the workloads like SharePoint and",
    "start": "59470",
    "end": "65259"
  },
  {
    "text": "onedrive outlook over are been powered by the service that we will talk about",
    "start": "65259",
    "end": "71590"
  },
  {
    "text": "today and this service basically has almost hundred million daily active",
    "start": "71590",
    "end": "77830"
  },
  {
    "text": "users therefore the service we have to build how to be able to scale to that",
    "start": "77830",
    "end": "83940"
  },
  {
    "text": "limit to be able to serve all these users so the experience kind of looks as",
    "start": "83940",
    "end": "91840"
  },
  {
    "text": "you can see on the screen it's just a simple card but like before we go on and",
    "start": "91840",
    "end": "97000"
  },
  {
    "text": "talk about what this experience is and why we build it we start with the core mission of Microsoft right so the core",
    "start": "97000",
    "end": "103780"
  },
  {
    "text": "mission of Microsoft is to empower every person in every organization to do more so what does that mean it means that",
    "start": "103780",
    "end": "111119"
  },
  {
    "text": "like what is productivity to you at work it's about communication and",
    "start": "111119",
    "end": "116350"
  },
  {
    "text": "collaboration in over 65 when you actually collaborate with people through",
    "start": "116350",
    "end": "121420"
  },
  {
    "text": "different mediums you if you knew who this person is better you collaborate",
    "start": "121420",
    "end": "126490"
  },
  {
    "text": "better that's like real life if you actually work with someone in real life and you know them better you know what",
    "start": "126490",
    "end": "132129"
  },
  {
    "text": "they want what they will need in advance then you can actually work more effectively the purpose of this persona",
    "start": "132129",
    "end": "139959"
  },
  {
    "text": "card is actually exactly that to replicate that experience in an online environment",
    "start": "139959",
    "end": "145290"
  },
  {
    "text": "to be able to contextualize the person and create a 360 view of a person you",
    "start": "145290",
    "end": "150870"
  },
  {
    "text": "need a lot of data about that person fortunately for us Microsoft owns a lot of data about a",
    "start": "150870",
    "end": "157829"
  },
  {
    "text": "user working in an organization who is at risk office 65 user for example some",
    "start": "157829",
    "end": "163980"
  },
  {
    "text": "of that person's data is in SharePoint Sam is in Skype some is an Outlook and then some of the public facing data are",
    "start": "163980",
    "end": "170549"
  },
  {
    "text": "actually in LinkedIn right and all we need to do is to take all this data from",
    "start": "170549",
    "end": "176040"
  },
  {
    "text": "different data sources aggregate those data run some ml models just to",
    "start": "176040",
    "end": "181680"
  },
  {
    "text": "understand what is useful like for a simple example like just showing contacts and and email can be very",
    "start": "181680",
    "end": "189269"
  },
  {
    "text": "useful but it could be even more useful if I knew this person is someone I'm going to meet like in a week in a",
    "start": "189269",
    "end": "195659"
  },
  {
    "text": "meeting right and this is the document that I need to read so this code tries to capture those scenarios and actually",
    "start": "195659",
    "end": "201690"
  },
  {
    "text": "present it in an experience for you based on the context that you are in",
    "start": "201690",
    "end": "208310"
  },
  {
    "text": "right so to build this experience we're going to talk about three big dimensions",
    "start": "208310",
    "end": "213680"
  },
  {
    "text": "one of them is scalability right how do we build a scalable architecture which",
    "start": "213680",
    "end": "218910"
  },
  {
    "text": "can support this usage the second one talk about is the card like appears from",
    "start": "218910",
    "end": "225930"
  },
  {
    "text": "all this data but if it takes seconds to come no one is going to be productive but you will be unproductive trying to",
    "start": "225930",
    "end": "233160"
  },
  {
    "text": "use the card so it has to be like super snappy like as soon all you want to know about someone all the data just needs to",
    "start": "233160",
    "end": "239699"
  },
  {
    "text": "appear at the right time instantly so that's one of the challenges to build for performance at this scale we are",
    "start": "239699",
    "end": "246810"
  },
  {
    "text": "going to talk a bit about some of the things that we did and some of the key takeaways from that experience and",
    "start": "246810",
    "end": "253129"
  },
  {
    "text": "lastly when you start and do a project like this where you know this is going to grow the number of developers working",
    "start": "253129",
    "end": "260430"
  },
  {
    "text": "on that project also grows like often like how many of you started with a",
    "start": "260430",
    "end": "266310"
  },
  {
    "text": "project which started with like two people and ended up more than 30 people yeah like 50 percent of you right and I",
    "start": "266310",
    "end": "274050"
  },
  {
    "text": "think this is the problem is that I think we all acknowledge that working on the code with two three people is vastly",
    "start": "274050",
    "end": "280699"
  },
  {
    "text": "different from working in a codebase we are fifty people contribute at the same time all the time right so we are gonna",
    "start": "280699",
    "end": "286939"
  },
  {
    "text": "talk a bit about what are the things that we did to ensure that our code base is scalable let's start with the first",
    "start": "286939",
    "end": "293599"
  },
  {
    "text": "one scalable architecture if we take a very",
    "start": "293599",
    "end": "298610"
  },
  {
    "text": "high-level overview this is an oversimplified view of how our architecture looks let's say you have",
    "start": "298610",
    "end": "305569"
  },
  {
    "text": "the experience on the right hand side is it on the left hand side oh yeah it's on the right hand side so you have the",
    "start": "305569",
    "end": "310819"
  },
  {
    "text": "experience on the right hand side and you have the card on the left hand side and as I said all the data exists let's",
    "start": "310819",
    "end": "319279"
  },
  {
    "text": "say that we call them data services they are different services which also Microsoft owns like some other teams own",
    "start": "319279",
    "end": "324979"
  },
  {
    "text": "but we are going to be in this experience all we need to do is create another service which is going to",
    "start": "324979",
    "end": "330080"
  },
  {
    "text": "aggregate all this data right and basically pull all this data rank them and then deliver it on time normally",
    "start": "330080",
    "end": "340159"
  },
  {
    "text": "only this would have worked but as I said like we because we need to make it very performant a lot of these data",
    "start": "340159",
    "end": "346430"
  },
  {
    "text": "services are actually old and legacy services and they can be as slow as five six seconds but we need our experience",
    "start": "346430",
    "end": "353779"
  },
  {
    "text": "to be very snappy as less than a second right so all we do is that we basically cache that right so this is a very",
    "start": "353779",
    "end": "359689"
  },
  {
    "text": "high-level pieces of the architecture so when we talk about scaling our",
    "start": "359689",
    "end": "366889"
  },
  {
    "text": "architecture what it means like if we just take this this diagram here like",
    "start": "366889",
    "end": "372499"
  },
  {
    "text": "what are the high-level pieces that need scaling so you need a bit of compute because you build a new service you when",
    "start": "372499",
    "end": "379219"
  },
  {
    "text": "the load increases you need to have more compute available for you to scale the second thing you need is like we talked",
    "start": "379219",
    "end": "385909"
  },
  {
    "text": "about cache right because we need to speed things up so we want to cache things so we need a cache resource and",
    "start": "385909",
    "end": "393019"
  },
  {
    "text": "that of course needs scaling as well and then all the dependency services that we",
    "start": "393019",
    "end": "399680"
  },
  {
    "text": "kind of said all the data is there but that itself needs to also scale right",
    "start": "399680",
    "end": "404779"
  },
  {
    "text": "so luckily for us we had to work with these teams to ensure that the load we are going to put on them that they can",
    "start": "404779",
    "end": "410870"
  },
  {
    "text": "handle and those are different challenges but we were able to get buy-in for all those",
    "start": "410870",
    "end": "417130"
  },
  {
    "text": "services so we're not going to talk much about that here the other thing which is very easy these days is that okay you",
    "start": "417130",
    "end": "424509"
  },
  {
    "text": "need some computer use one of the cloud platforms right you can use Azure you can use Amazon Web Services or any other",
    "start": "424509",
    "end": "430509"
  },
  {
    "text": "cloud platform naturally be used either because Roger is great as well but the",
    "start": "430509",
    "end": "437289"
  },
  {
    "text": "compute these days is pretty simple right like you can actually outsource the scaling of compute to your cloud",
    "start": "437289",
    "end": "442660"
  },
  {
    "text": "provider so you can say I need this many instances if the load increases then it automatically handles this for you so",
    "start": "442660",
    "end": "448570"
  },
  {
    "text": "there's nothing much to talk about there then we are left with cache resource so",
    "start": "448570",
    "end": "454810"
  },
  {
    "text": "we use the radius cache are you familiar",
    "start": "454810",
    "end": "459850"
  },
  {
    "text": "with Reddy's cache in Azure yeah some of you but normally it's just a key",
    "start": "459850",
    "end": "464860"
  },
  {
    "text": "value pair cache is a network attached in-memory cache which as your provides out of the box is a managed resource so",
    "start": "464860",
    "end": "471849"
  },
  {
    "text": "you don't have to do much you just like consume it through the rest endpoints so now of course we knew from day one that",
    "start": "471849",
    "end": "479530"
  },
  {
    "text": "we are building it for many experience and we're going to cash them anything so this needs to scale as well if you pay",
    "start": "479530",
    "end": "486220"
  },
  {
    "text": "more to Azure and you use a premium SKU of algebra disk cache you have the",
    "start": "486220",
    "end": "491770"
  },
  {
    "text": "caching scaling functionality provided to you from Azure so you don't have to",
    "start": "491770",
    "end": "497650"
  },
  {
    "text": "do much if you throw money to the problem however that comes with X number functionality which we don't need so",
    "start": "497650",
    "end": "504099"
  },
  {
    "text": "since in our scenario we knew that if you want to keep their cost low this",
    "start": "504099",
    "end": "509770"
  },
  {
    "text": "would be our bottleneck so we don't want to use high-end SKUs right so we use the lowest queue and we",
    "start": "509770",
    "end": "516099"
  },
  {
    "text": "did our own scaling strategy so we can talk a bit about what we did to scale Redis instances so scaling can be done",
    "start": "516099",
    "end": "527020"
  },
  {
    "text": "in two two ways right vertical and horizontal the vertical is very simple like you asked to get a bigger queue",
    "start": "527020",
    "end": "533920"
  },
  {
    "text": "bigger machine but there is a cap to that right let's say that we have are using the biggest machines that are you",
    "start": "533920",
    "end": "541209"
  },
  {
    "text": "is providing to us it's like around I think 50 to 60 GB per instance so in this diagram you can see we have",
    "start": "541209",
    "end": "547360"
  },
  {
    "text": "like four instances of Redis running so when we need to cache here we need to",
    "start": "547360",
    "end": "552640"
  },
  {
    "text": "sum or distribute our data across these four instances for example so let's say aleni",
    "start": "552640",
    "end": "558160"
  },
  {
    "text": "a user comes and like hovers on a card so this piece of like every part of the",
    "start": "558160",
    "end": "564070"
  },
  {
    "text": "card has some piece of data which is cached and that cache data we have to",
    "start": "564070",
    "end": "570490"
  },
  {
    "text": "end up in one of these partitions right so the first thing is that each piece of data you have to give it a unique ID",
    "start": "570490",
    "end": "578350"
  },
  {
    "text": "right so let's say that is a cash ID the way we form it is that we actually use",
    "start": "578350",
    "end": "583510"
  },
  {
    "text": "the accessing user ID accessing users ID and target users ID and a tenant name so",
    "start": "583510",
    "end": "588880"
  },
  {
    "text": "you form a unique key but then what you do is that you basically take that unique key that you want to partition",
    "start": "588880",
    "end": "594880"
  },
  {
    "text": "that they you want to keep the data across these four instances you have to choose which bucket you want to keep it",
    "start": "594880",
    "end": "600490"
  },
  {
    "text": "right so we do a consistent hashing of the key and then we do a modulus of the",
    "start": "600490",
    "end": "607030"
  },
  {
    "text": "number of instance that you have right so that way you basically end up in a bucket the thing to note here is because",
    "start": "607030",
    "end": "612940"
  },
  {
    "text": "it's a one-way hash and it's the same hash function if you have the same key you'll get the same hash value and then",
    "start": "612940",
    "end": "618970"
  },
  {
    "text": "you do a modulus of the number of instances that you have you will reach to the same bucket so if you store it once you can come back to it again right",
    "start": "618970",
    "end": "625500"
  },
  {
    "text": "so this is very standard technique now let's say like you have spread this",
    "start": "625500",
    "end": "633340"
  },
  {
    "text": "across all these instances your data naturally one of the questions is that who insures that the data is distributed",
    "start": "633340",
    "end": "639670"
  },
  {
    "text": "properly and the hash function has property which basically ensures that your hash keys are bucketed across this",
    "start": "639670",
    "end": "647770"
  },
  {
    "text": "uniformly right so that's why we use a hash function if you made your own reg",
    "start": "647770",
    "end": "653560"
  },
  {
    "text": "random stuff then it could be that one of the instances could have filled up more than the others now let's say that",
    "start": "653560",
    "end": "660510"
  },
  {
    "text": "the experience grows and you cash and cash and now all these four instances are almost getting full so what do you",
    "start": "660510",
    "end": "666880"
  },
  {
    "text": "do right you go ahead and just add one more instance but now let's play through",
    "start": "666880",
    "end": "672970"
  },
  {
    "text": "what happens right now let's say that like I went to Azure I clicked I got a new instance I went",
    "start": "672970",
    "end": "678700"
  },
  {
    "text": "in my corner said hey I have five instances now so the same user came the data is cached in the bucket one if you",
    "start": "678700",
    "end": "685810"
  },
  {
    "text": "remember from the previous example then I asked for the data again the service basically looks at the same cache key",
    "start": "685810",
    "end": "691540"
  },
  {
    "text": "which is the same cache key and then you do a constant hashing with the same heart function then you get the same",
    "start": "691540",
    "end": "697870"
  },
  {
    "text": "number but this time instead of doing a modulus of four you have changed the code to the modulus of five and",
    "start": "697870",
    "end": "703030"
  },
  {
    "text": "therefore it can end up in some other bucket right it could if my probability",
    "start": "703030",
    "end": "708400"
  },
  {
    "text": "end up in the same bucket but that's by chance so one of the nice things is that we do not go and wipe the entire data",
    "start": "708400",
    "end": "715210"
  },
  {
    "text": "because we say if it's able to come to the same bucket then you still have a cache hit and this basically has a",
    "start": "715210",
    "end": "722500"
  },
  {
    "text": "property that if it gets filled and then this new data coming it will not reject",
    "start": "722500",
    "end": "727630"
  },
  {
    "text": "it it's gonna take it in it's going to drop the oldest TTL values right so there's a kind of a nice property to use",
    "start": "727630",
    "end": "733690"
  },
  {
    "text": "so in our case that's in this example it ended up in bucket 4 and of course is a",
    "start": "733690",
    "end": "740020"
  },
  {
    "text": "cache miss because that value doesn't exist there so you have to depopulate it the thing to note here is if you want to",
    "start": "740020",
    "end": "747280"
  },
  {
    "text": "build a scaling strategy as such it you have to be tolerant to loss in our experience when this happens when we go",
    "start": "747280",
    "end": "754600"
  },
  {
    "text": "and scale it up and add more instances we get cache misses and therefore",
    "start": "754600",
    "end": "760500"
  },
  {
    "text": "because our experience can be standard and the way it which standard is that it takes a performance hit right so it's",
    "start": "760500",
    "end": "766360"
  },
  {
    "text": "not super fast but then it goes to the downstream services calls it publish the cache on serve the reserve so it doesn't",
    "start": "766360",
    "end": "772300"
  },
  {
    "text": "block so this is interesting and also very important to note if you want to use the scaling strategy as such you can",
    "start": "772300",
    "end": "779200"
  },
  {
    "text": "use the same strategy for your partitioning of your any kind of data even if it's persistent but in those",
    "start": "779200",
    "end": "786070"
  },
  {
    "text": "case is when you cannot tolerate loss you have to go on D partition the data when you added the 15 says you have to",
    "start": "786070",
    "end": "791290"
  },
  {
    "text": "like we distribute your data you have a have to have a strategy to actually be able to do that which is a slightly",
    "start": "791290",
    "end": "796930"
  },
  {
    "text": "harder problem okay now we can of like talk about computer this and the data",
    "start": "796930",
    "end": "803500"
  },
  {
    "text": "data services and we scale each of them right and then let's say that like you have all these resources that we just",
    "start": "803500",
    "end": "809440"
  },
  {
    "text": "talked about and they individually scale so that's nice and then like you say that all these are all my resources I'm",
    "start": "809440",
    "end": "816110"
  },
  {
    "text": "gonna host it in one of the data centers right for example in here I hosted in north central us but the way to scale",
    "start": "816110",
    "end": "824630"
  },
  {
    "text": "now is that you can replicate this entire thing again and again in different data centers right so you just like nicely packaged it and then you do",
    "start": "824630",
    "end": "831410"
  },
  {
    "text": "more of this there are a couple of reasons why you would want to do that it's not just that you want to scale",
    "start": "831410",
    "end": "837170"
  },
  {
    "text": "this way this basically gives you a disaster recovery scenario for example",
    "start": "837170",
    "end": "843370"
  },
  {
    "text": "if one of the data centers goes down right your traffic like if you have traffic margin on top it just",
    "start": "843370",
    "end": "850220"
  },
  {
    "text": "distributes the data to the other other traffic other data centers last year are",
    "start": "850220",
    "end": "856069"
  },
  {
    "text": "you one of the data centers as you basically went down I don't know how many of you okay someone is nodding",
    "start": "856069",
    "end": "861139"
  },
  {
    "text": "their head maybe you were affected were you affected yeah okay so we had an experience which was not affected",
    "start": "861139",
    "end": "867199"
  },
  {
    "text": "because of this setup right so our like load just like went to other data centers and they individually scale",
    "start": "867199",
    "end": "874490"
  },
  {
    "text": "inside we saw a blip in our optics but we did were not affected so this is a",
    "start": "874490",
    "end": "880790"
  },
  {
    "text": "very nice thing to have but it comes with the cost right if you all your users are in the same place and you have",
    "start": "880790",
    "end": "886399"
  },
  {
    "text": "another data center you're maintaining it is some overhead but it depends it is better to be ready for that scenario",
    "start": "886399",
    "end": "892509"
  },
  {
    "text": "than not to be as you basically published a very detail or C on why that",
    "start": "892509",
    "end": "899720"
  },
  {
    "text": "has happened it's really nice because it was a lightning strike and then the entire datacenter eventually went down",
    "start": "899720",
    "end": "905410"
  },
  {
    "text": "it like you would imagine it's not it has a lot of safe wires like it has like",
    "start": "905410",
    "end": "912519"
  },
  {
    "text": "safety nets like it's not like that is something trips and it just goes down all data centers have like Amazon has it",
    "start": "912519",
    "end": "919189"
  },
  {
    "text": "as well but still this thing kind of things happen with human errors and design natural disasters so I would even",
    "start": "919189",
    "end": "926029"
  },
  {
    "text": "really encourage people when you even if you build a small service and you actually serve in production traffic you",
    "start": "926029",
    "end": "931880"
  },
  {
    "text": "don't want to be down for that you need to have high availability therefore schedule resources and the nature at",
    "start": "931880",
    "end": "937310"
  },
  {
    "text": "least you have one or at least two or more data centers that you are in then",
    "start": "937310",
    "end": "943550"
  },
  {
    "text": "the next thing is that you are in one geography lesson e you're in US and then you can do the same thing",
    "start": "943550",
    "end": "951650"
  },
  {
    "text": "in other geographies right so you can just scale it in a geographer level so it's like pretty simple and then you put",
    "start": "951650",
    "end": "956870"
  },
  {
    "text": "a traffic measure on top of everything the thing to note here is that you don't do it just because you're scaling it out",
    "start": "956870",
    "end": "963470"
  },
  {
    "text": "or you want to have disaster recovery one of the main reasons why you want to do it is that you want to be closer to",
    "start": "963470",
    "end": "968510"
  },
  {
    "text": "your users for example if I have a lot of users who are connecting from Europe maybe there are US users they like let's",
    "start": "968510",
    "end": "975800"
  },
  {
    "text": "say they work in ships are there how many of you work in shifts that because I saw some people from ship said ok",
    "start": "975800",
    "end": "981260"
  },
  {
    "text": "let's say any Norwegian company but you're traveling a lot right so your account is hosted in Norway like so we",
    "start": "981260",
    "end": "988760"
  },
  {
    "text": "know that your Norwegian you as a user so you supposed to be Norway but you're connecting all this from India because",
    "start": "988760",
    "end": "994790"
  },
  {
    "text": "you're travelling right so those calls are going to come all the way right and that's going to affect your performance",
    "start": "994790",
    "end": "999800"
  },
  {
    "text": "but if we had a data center in India right so then you would connect to India",
    "start": "999800",
    "end": "1005590"
  },
  {
    "text": "your cache will be in India if you move around your cache will move around with you so therefore the performance will it",
    "start": "1005590",
    "end": "1012160"
  },
  {
    "text": "will help your performance user experience you have a better user experience you'll be more productive therefore we meet our mission and goal",
    "start": "1012160",
    "end": "1019270"
  },
  {
    "text": "in Microsoft right this is a very nice overview of all the places are you",
    "start": "1019270",
    "end": "1026380"
  },
  {
    "text": "actually has a data center today it's a bit all like a year I'm guessing they have a bit more now",
    "start": "1026380",
    "end": "1032760"
  },
  {
    "text": "for us what we do is that we look at this overview and we have another chart",
    "start": "1032760",
    "end": "1038439"
  },
  {
    "text": "which basically shows where all our users are connecting from based on these two we kind of decide where are the",
    "start": "1038440",
    "end": "1044319"
  },
  {
    "text": "places that we want to have data center presence and this is also one of the key",
    "start": "1044320",
    "end": "1049870"
  },
  {
    "text": "takeaways is just don't build everywhere either has data centers right because there is a cognitive overhead even if",
    "start": "1049870",
    "end": "1055840"
  },
  {
    "text": "there are exactly the same replicas for your developers there is a cost of maintaining them going around you're",
    "start": "1055840",
    "end": "1062080"
  },
  {
    "text": "looking at this resources provisioning them and so forth the best thing to do is optimize for where your users are",
    "start": "1062080",
    "end": "1069070"
  },
  {
    "text": "because that's where you will get the best benefits right so we cannot make",
    "start": "1069070",
    "end": "1074920"
  },
  {
    "text": "talk a bit about scaling our unlike but then we also said okay like",
    "start": "1074920",
    "end": "1082590"
  },
  {
    "text": "caching is helping in our performance but let's look at how we actually helped in our performance so from day one we",
    "start": "1082590",
    "end": "1089640"
  },
  {
    "text": "were very bent on saying that we have to design for performance we cannot be slow",
    "start": "1089640",
    "end": "1095570"
  },
  {
    "text": "when you start with performance I think like the first thing to ask is what is",
    "start": "1095900",
    "end": "1101850"
  },
  {
    "text": "performance for you right like you cannot just say what we want to be super blazing fast like like that's what we",
    "start": "1101850",
    "end": "1108720"
  },
  {
    "text": "initially said like we want to have a blazing fast person card but what does that really mean right so you had really defined a",
    "start": "1108720",
    "end": "1115110"
  },
  {
    "text": "scenario for you for yourself like for example a very simple example I often use is that when you go and read a news",
    "start": "1115110",
    "end": "1122540"
  },
  {
    "text": "right you basically don't need all the data for all the news all you need is",
    "start": "1122540",
    "end": "1128280"
  },
  {
    "text": "all the titles because the first thing as a user you do use a gloss through the titles heat triage it and then you",
    "start": "1128280",
    "end": "1135180"
  },
  {
    "text": "decide to click on one and there is a few milliseconds within which you can do a lot of smartness for your end user you",
    "start": "1135180",
    "end": "1141240"
  },
  {
    "text": "can predict and prefetch the right right ones so we do something similar so we",
    "start": "1141240",
    "end": "1146250"
  },
  {
    "text": "have defined it that if anyone clicks on someone or hovers on a person as long as",
    "start": "1146250",
    "end": "1153150"
  },
  {
    "text": "we can show the top part of the card super fast the user will feel that he has started understanding who this",
    "start": "1153150",
    "end": "1160050"
  },
  {
    "text": "person is and we have defined that the rest part of the card which is more harder to produce canst come slightly",
    "start": "1160050",
    "end": "1167820"
  },
  {
    "text": "later right and we have given us ourselves some goals so we said that the top part of the card should be rendered",
    "start": "1167820",
    "end": "1174180"
  },
  {
    "text": "in 250 milliseconds from the time you click which is an insane requirement but",
    "start": "1174180",
    "end": "1179430"
  },
  {
    "text": "still we kind of believe that it's doable right let's see if it is doable and then the top the rest part of the",
    "start": "1179430",
    "end": "1188040"
  },
  {
    "text": "card cannot just wait forever as well because most probably you will consume it like in half a second the top part of",
    "start": "1188040",
    "end": "1193920"
  },
  {
    "text": "the card and then immediately when you want to consume more the data should be there so we have given ourselves like an",
    "start": "1193920",
    "end": "1200010"
  },
  {
    "text": "600 milliseconds to render the rest part of the card and then you scroll more and",
    "start": "1200010",
    "end": "1205080"
  },
  {
    "text": "then you have more time to Pretender more stuff so let's see how we can power",
    "start": "1205080",
    "end": "1210840"
  },
  {
    "text": "this experience let's say we have this high level",
    "start": "1210840",
    "end": "1215919"
  },
  {
    "text": "overview architecture a user comes in let's at the top part of the card the",
    "start": "1215919",
    "end": "1222100"
  },
  {
    "text": "data we want so it sends a request to our service and the service kind of looks at the caches it's not there for",
    "start": "1222100",
    "end": "1229390"
  },
  {
    "text": "this the first time right so it goes to the rounds in service takes seconds comes back renders the top part of the",
    "start": "1229390",
    "end": "1235510"
  },
  {
    "text": "card then renders the rest it like it is more than like six seconds I think if",
    "start": "1235510",
    "end": "1241570"
  },
  {
    "text": "you are to do it like that so it's kind of what we have achieved now is that okay you click you get the card in six",
    "start": "1241570",
    "end": "1247029"
  },
  {
    "text": "seconds but if you click again then is super fast but then no one clicks for",
    "start": "1247029",
    "end": "1253330"
  },
  {
    "text": "the second time because the first time was so slow right yeah natural problems so we do something",
    "start": "1253330",
    "end": "1261460"
  },
  {
    "text": "which we call profession cash is a very standard technique is not anything sci-fi you just what you need to",
    "start": "1261460",
    "end": "1268059"
  },
  {
    "text": "optimize here is that before the user click comes you want to pour P populate the cache so in a in one of our expenses",
    "start": "1268059",
    "end": "1275320"
  },
  {
    "text": "for example Outlook right it's a mail scenario so every scenario we try to understand what the user is trying to do",
    "start": "1275320",
    "end": "1281860"
  },
  {
    "text": "in that scenario when you go and open your emails it's not all of you go out",
    "start": "1281860",
    "end": "1287409"
  },
  {
    "text": "immediately click on hey I want to see who this person is most probably the first thing you do is that you look at",
    "start": "1287409",
    "end": "1293890"
  },
  {
    "text": "your emails you look at who mailed you or you want to craft a mail so you actually ask for someone's name so it so",
    "start": "1293890",
    "end": "1301390"
  },
  {
    "text": "happens that we from telemetry we know that you have around like two three seconds before you go and do the first",
    "start": "1301390",
    "end": "1309130"
  },
  {
    "text": "click on to understand anyone right so we kind of leverage that insight and we",
    "start": "1309130",
    "end": "1315580"
  },
  {
    "text": "kind of as soon as the page is rendered and you have these people on the page we identify all the people in the page and",
    "start": "1315580",
    "end": "1321340"
  },
  {
    "text": "we send a previous signal to our service saying that hey go and get ready for the top part of the card right so that when",
    "start": "1321340",
    "end": "1328029"
  },
  {
    "text": "the user clicks and the call comes you get a cache it and that is how we are able to also render the experience very",
    "start": "1328029",
    "end": "1335710"
  },
  {
    "text": "quickly from the first click on words and then this strategy just continues",
    "start": "1335710",
    "end": "1342789"
  },
  {
    "text": "for example you get the card and the car is self has more people rendered in it so you might click to know more of that",
    "start": "1342789",
    "end": "1349200"
  },
  {
    "text": "person so you do the same thing you just like send it and hope that before you have clicked it we have professed it for",
    "start": "1349200",
    "end": "1355230"
  },
  {
    "text": "you so you don't want to like go back a bit and say that even though it works really good it has a huge drawback who",
    "start": "1355230",
    "end": "1361980"
  },
  {
    "text": "can say what the drawback is like any guesses yes yeah absolutely like as as",
    "start": "1361980",
    "end": "1371820"
  },
  {
    "text": "you mentioned there is a lot of data that we prefetch that no one might click right so from telemetry I can just tell",
    "start": "1371820",
    "end": "1378660"
  },
  {
    "text": "you like like on average we have around 30 to 40 people rendered on one page in",
    "start": "1378660",
    "end": "1384780"
  },
  {
    "text": "if you go to an email and on average maybe three of them are clicked so most",
    "start": "1384780",
    "end": "1390540"
  },
  {
    "text": "of this data that we profess just to be insanely fast it's just not it's gone to waste so what we did is that we started",
    "start": "1390540",
    "end": "1399450"
  },
  {
    "text": "using machine learning models where instead of just saying that we are going to like prefetch for all these people we",
    "start": "1399450",
    "end": "1406440"
  },
  {
    "text": "tried to start predicting your behavior and what are the people that you might",
    "start": "1406440",
    "end": "1411510"
  },
  {
    "text": "go and click right so if we can actually predict better on who are these three people that you might click then we will",
    "start": "1411510",
    "end": "1418080"
  },
  {
    "text": "just be fetch those three people and for example just to get an idea of what this means in plain term so let's say that",
    "start": "1418080",
    "end": "1425070"
  },
  {
    "text": "your intellect we divide users into different buckets there is a bucket of users that you interact very often with",
    "start": "1425070",
    "end": "1431250"
  },
  {
    "text": "there can be a bucket of users who are completely strangers and then there are maybe a bucket of users who are",
    "start": "1431250",
    "end": "1437160"
  },
  {
    "text": "strangers but you have upcoming collaboration with like you might have a meeting with for the first time or",
    "start": "1437160",
    "end": "1442410"
  },
  {
    "text": "you're meeting after a long time right so those are indications that you might really be interested to know about this",
    "start": "1442410",
    "end": "1449190"
  },
  {
    "text": "person and then we run this image ml models just try to predict how your",
    "start": "1449190",
    "end": "1454680"
  },
  {
    "text": "behavior is and that's how we can actually optimize what we prefetch and cache so then it so so the way we try to",
    "start": "1454680",
    "end": "1463230"
  },
  {
    "text": "do is that we try to actually keep the cash sheet ratio the same while",
    "start": "1463230",
    "end": "1469190"
  },
  {
    "text": "prefetching less right so this is a work in progress but like one takeaway from",
    "start": "1469190",
    "end": "1474630"
  },
  {
    "text": "this is that even like it's okay to start very simple and dumb get",
    "start": "1474630",
    "end": "1480460"
  },
  {
    "text": "your users on board see that you're successful see that this the usage is good and people actually want this",
    "start": "1480460",
    "end": "1486820"
  },
  {
    "text": "experience and then go ahead and do smartest like this to actually reduce your cost all right yeah let's move on",
    "start": "1486820",
    "end": "1495299"
  },
  {
    "text": "so now it's all good and dandy right so you have the middle tier service you",
    "start": "1495299",
    "end": "1500830"
  },
  {
    "text": "let's say that you have everything on cashed right we have done profession cash so now we need the top part of the",
    "start": "1500830",
    "end": "1507370"
  },
  {
    "text": "card so we do a simple get request to our service I say hey they give me this data you get a cash it let's say write",
    "start": "1507370",
    "end": "1514330"
  },
  {
    "text": "reading from the Redis cash is like single digit millisecond so it's like almost no time remember that the top",
    "start": "1514330",
    "end": "1521290"
  },
  {
    "text": "part of the card was 250 milliseconds right so when we try this experiment like we're trying to measure we see that",
    "start": "1521290",
    "end": "1527710"
  },
  {
    "text": "it takes 600 milliseconds almost in some regions so it's not in all regions but in some regions actually more than half",
    "start": "1527710",
    "end": "1534580"
  },
  {
    "text": "of our regions which are like in developing countries around the world where the networks are not great even a",
    "start": "1534580",
    "end": "1540250"
  },
  {
    "text": "single HTTP request takes more than 600 milliseconds just to go and come back so that doesn't meet our goal at all",
    "start": "1540250",
    "end": "1546820"
  },
  {
    "text": "right the top part of the card so the first question is why does it take so much of time so naturally if you do an",
    "start": "1546820",
    "end": "1553540"
  },
  {
    "text": "HTTP you have a three-way handshake TLS you know back and forth and if it's a",
    "start": "1553540",
    "end": "1559090"
  },
  {
    "text": "sporty Network it takes more time and off and needless to say there are monsters on the internet right like",
    "start": "1559090",
    "end": "1565510"
  },
  {
    "text": "everyone knows that and they are cute as well so but it doesn't help in my",
    "start": "1565510",
    "end": "1570700"
  },
  {
    "text": "performance so naturally like what we need to do is we have to somehow like",
    "start": "1570700",
    "end": "1576820"
  },
  {
    "text": "get rid of this TLS handshake once upfront before the user clicks right like the same strategy like the prefetch",
    "start": "1576820",
    "end": "1582880"
  },
  {
    "text": "like when the user comes all these things should be done in advance so one could go and say hey like it's 2019 use",
    "start": "1582880",
    "end": "1590169"
  },
  {
    "text": "HTTP 2.0 right like that's exactly what is built for and actually what's great",
    "start": "1590169",
    "end": "1595240"
  },
  {
    "text": "but I guess you guys were thinking that right yes some nodding heads but the",
    "start": "1595240",
    "end": "1601120"
  },
  {
    "text": "thing is that if you look at worldwide traffic only 40 percent of the traffic worldwide actually has HTTP 2.0 because",
    "start": "1601120",
    "end": "1609190"
  },
  {
    "text": "not all browsers are up to date especially in corporations a lot of use use old standard browsers that",
    "start": "1609190",
    "end": "1617289"
  },
  {
    "text": "includes Internet Explorer as well so yes but the thing is that you cannot",
    "start": "1617289",
    "end": "1623799"
  },
  {
    "text": "always rely on technology which is good because your users are really behind even if it's 2019 so for us we knew that",
    "start": "1623799",
    "end": "1631539"
  },
  {
    "text": "we are going to have to build a tunnel in advance create that tunnel and then use the tunnel continuously so we had",
    "start": "1631539",
    "end": "1637690"
  },
  {
    "text": "two options we could use WebSockets or we could use signal are how many of you are familiar with signaler Wow it seems",
    "start": "1637690",
    "end": "1644379"
  },
  {
    "text": "like a dotnet conference here everyone uses signal but like so there's no need for me to say how awesome signal are is",
    "start": "1644379",
    "end": "1651399"
  },
  {
    "text": "but like for short for people who haven't used it it's just a duplex channel that you behind-the-scenes is of",
    "start": "1651399",
    "end": "1657639"
  },
  {
    "text": "course uses WebSockets keeps it open but it does more than that right like it kind of keeps connections open to",
    "start": "1657639",
    "end": "1663490"
  },
  {
    "text": "multiple clients and it resends them retries them it does polling behind the scenes it has nice a lot of nice",
    "start": "1663490",
    "end": "1670330"
  },
  {
    "text": "goodness in it so we kind of looked at it and say okay we could use web servers we could use signal are the API looks",
    "start": "1670330",
    "end": "1675369"
  },
  {
    "text": "very easy to use in signal so we just use signal I for simplicity kind of like",
    "start": "1675369",
    "end": "1682509"
  },
  {
    "text": "did the same call through a signal are just yes for completeness the signal are",
    "start": "1682509",
    "end": "1687759"
  },
  {
    "text": "also does an HTTP request upfront to establish the connection but that is done a long time before the user clicks",
    "start": "1687759",
    "end": "1694629"
  },
  {
    "text": "so that cost is gone and then once the user clicks and Enrico's goes through signal are you get to the service the",
    "start": "1694629",
    "end": "1702159"
  },
  {
    "text": "service has it everything cached and then you measure and it's 230 milliseconds so plus a single-digit",
    "start": "1702159",
    "end": "1708460"
  },
  {
    "text": "millisecond on the reading from the cache so we gotta meet our goal at this",
    "start": "1708460",
    "end": "1713950"
  },
  {
    "text": "point feeling really cool right like you are able to scale you are meeting your",
    "start": "1713950",
    "end": "1719499"
  },
  {
    "text": "performance goal you have done all this signal are thingy super nice life is good we gotta roll forward we are around",
    "start": "1719499",
    "end": "1726999"
  },
  {
    "text": "1 million daily users now things are working very good every day you come you",
    "start": "1726999",
    "end": "1732580"
  },
  {
    "text": "have your coffee you feel good about yourself and now everyone says okay let's go more right and in my in my head",
    "start": "1732580",
    "end": "1740110"
  },
  {
    "text": "it was like okay if we can serve 1 million then we have weeded out all our issues so it's smooth riding from here so we're",
    "start": "1740110",
    "end": "1747970"
  },
  {
    "text": "gonna like started we want to go to 70 million because at that point we had we knew that we had 70 million daily active",
    "start": "1747970",
    "end": "1753700"
  },
  {
    "text": "users so we kind of like say okay we scale up right so basically we throw",
    "start": "1753700",
    "end": "1759820"
  },
  {
    "text": "some money to the problem we get some more compute as the users role in and we",
    "start": "1759820",
    "end": "1764890"
  },
  {
    "text": "onboard more and more organizations into obviously five organizations or tenants if you're familiar with it right now let",
    "start": "1764890",
    "end": "1771310"
  },
  {
    "text": "me started seeing something really weird some of the CPUs started becoming hot",
    "start": "1771310",
    "end": "1776320"
  },
  {
    "text": "and they would crash and burn but there was no explanation it's like we have a",
    "start": "1776320",
    "end": "1782680"
  },
  {
    "text": "load balance on everything the traffic is being distributed nicely so we thought at least but if you get beast",
    "start": "1782680",
    "end": "1789760"
  },
  {
    "text": "out one of these machines another one gets hot and then that also crashes and burn burns right so we kind of like had to",
    "start": "1789760",
    "end": "1796000"
  },
  {
    "text": "not have work off it that day and really investigate what the hell was happening so remember this thing that we use",
    "start": "1796000",
    "end": "1802930"
  },
  {
    "text": "signal are a myth or life is so cool it so turns out that when you signal are",
    "start": "1802930",
    "end": "1808020"
  },
  {
    "text": "you need because it keeps backplane and it has to retry you need to configure IP",
    "start": "1808020",
    "end": "1815200"
  },
  {
    "text": "affinity and that was okay right like what IP affinity means that is the same IP you want to end up in the same back",
    "start": "1815200",
    "end": "1822220"
  },
  {
    "text": "and server because you have some stayed there but it should be okay but apparently when we did more",
    "start": "1822220",
    "end": "1828430"
  },
  {
    "text": "investigation it turned out that these big organizations want to really be safe",
    "start": "1828430",
    "end": "1833530"
  },
  {
    "text": "and secure so they have their firewalls and not and then they use one public facing IP so all the users basically end",
    "start": "1833530",
    "end": "1841000"
  },
  {
    "text": "up being the same guy and then it just comes to the same VM even though we have a lot of VM when we onboarding new",
    "start": "1841000",
    "end": "1847330"
  },
  {
    "text": "organizations which were bigger naturally we on-boarded the smaller ones first right but then we started",
    "start": "1847330",
    "end": "1853510"
  },
  {
    "text": "onboarding bigger tenants you know 65 we started seeing this kind of like the",
    "start": "1853510",
    "end": "1859090"
  },
  {
    "text": "takeaway from this for me and I think what I want to like get out is that every resource that you use right when",
    "start": "1859090",
    "end": "1866800"
  },
  {
    "text": "you build your architecture needs to be scalable to your needs like we use signal R and signal or if",
    "start": "1866800",
    "end": "1874120"
  },
  {
    "text": "you read about signal which is true is a very scalable solution right but it does no scale to",
    "start": "1874120",
    "end": "1879700"
  },
  {
    "text": "our scenario because we have a different scenario like we have this unique need",
    "start": "1879700",
    "end": "1885520"
  },
  {
    "text": "for not having definitive on our back-end service right so we we had to",
    "start": "1885520",
    "end": "1892150"
  },
  {
    "text": "like go and use a WebSocket finally but then at this time of the project it was",
    "start": "1892150",
    "end": "1899650"
  },
  {
    "text": "also problematic because we had already because we had like almost I think five million daily active users these were",
    "start": "1899650",
    "end": "1906310"
  },
  {
    "text": "really becoming hot so a lot of PM's product- came and said I want to try this out I'm gonna try this out so it",
    "start": "1906310",
    "end": "1912460"
  },
  {
    "text": "was like pulling a lot of features right already while we were rolling out that meant",
    "start": "1912460",
    "end": "1917590"
  },
  {
    "text": "that we had a huge communication stack right like lots of features exposed you want to rewrite the commission stack",
    "start": "1917590",
    "end": "1923620"
  },
  {
    "text": "that's like the worst how many of you have had to rewrite your communication stack to some other protocol and not",
    "start": "1923620",
    "end": "1930760"
  },
  {
    "text": "many you guys are lucky so at this point we had to do that and we had an option",
    "start": "1930760",
    "end": "1936190"
  },
  {
    "text": "between WebSockets or rest we knew that rest doesn't cut it but at",
    "start": "1936190",
    "end": "1941290"
  },
  {
    "text": "this point there was I just want to share some very interesting so they had this thing that in some browsers like",
    "start": "1941290",
    "end": "1950880"
  },
  {
    "text": "Safari and if you're on a Mac the rest performance was really great right so",
    "start": "1950880",
    "end": "1957310"
  },
  {
    "text": "that was strange but this hypothesis there is that people who have Mac like I do also and using Safari they are most",
    "start": "1957310",
    "end": "1965770"
  },
  {
    "text": "part be sitting in a developed country with a really good network so it's not about the machine is about where you are",
    "start": "1965770",
    "end": "1971350"
  },
  {
    "text": "but also the other thing about web sockets is that you just draw web sockets so you will actually there will",
    "start": "1971350",
    "end": "1980890"
  },
  {
    "text": "be failures there will be times where you cannot connect so if you cannot connect then you don't have any",
    "start": "1980890",
    "end": "1986140"
  },
  {
    "text": "experience right so we needed to support risk as well so what does that mean for us that now we have to support both we",
    "start": "1986140",
    "end": "1993010"
  },
  {
    "text": "have to rewrite our function stack to support both so instead of doing that what we did what we call is rest over",
    "start": "1993010",
    "end": "1998440"
  },
  {
    "text": "WebSockets so we created like two layers on both sides the clients all the centrist requests the layer basically",
    "start": "1998440",
    "end": "2005490"
  },
  {
    "text": "converts that into a WebSocket frame it goes through the tunnel and then",
    "start": "2005490",
    "end": "2010950"
  },
  {
    "text": "unpacks as a risky quest and replace it as a rest request on the on our server",
    "start": "2010950",
    "end": "2016350"
  },
  {
    "text": "side and then that kind of worked really good yes that brings me to my third",
    "start": "2016350",
    "end": "2022889"
  },
  {
    "text": "topic let me see how much time how we are doing on time yes I think they're",
    "start": "2022889",
    "end": "2030419"
  },
  {
    "text": "good on time yes right you're good on",
    "start": "2030419",
    "end": "2036330"
  },
  {
    "text": "time yes so this my third topic as you scheme and that naturally means that you",
    "start": "2036330",
    "end": "2044309"
  },
  {
    "text": "have more users that's why you're scaling your sources you don't do it for fun and you have a good performance but",
    "start": "2044309",
    "end": "2050908"
  },
  {
    "text": "that with that also means that you are tempted and naturally to experiment more features so your codebase grows and the",
    "start": "2050909",
    "end": "2058500"
  },
  {
    "text": "number of developers working on that code base grows when we started it was",
    "start": "2058500",
    "end": "2063628"
  },
  {
    "text": "like two people or three right or two of them were actually coding now we have actively 50-plus people working on that",
    "start": "2063629",
    "end": "2070770"
  },
  {
    "text": "project so there are many ways to actually solve that problem from day one like one common approach is to use micro",
    "start": "2070770",
    "end": "2078300"
  },
  {
    "text": "services right like you fragment your domain upfront you have this nice",
    "start": "2078300",
    "end": "2083520"
  },
  {
    "text": "smaller services so the people work only on those services so that's one way to scale your codebase that's in my mind",
    "start": "2083520",
    "end": "2091398"
  },
  {
    "text": "but you can also use monoliths of course in Monell it's like you have this",
    "start": "2091399",
    "end": "2097530"
  },
  {
    "text": "layered architecture where you have view model controller right and then as I said on the other hand your micro",
    "start": "2097530",
    "end": "2103619"
  },
  {
    "text": "services the thing is that there is a cost associated upfront on creating",
    "start": "2103619",
    "end": "2111660"
  },
  {
    "text": "micro services when you have two developers right let's say that you go for seven eight months and you're like",
    "start": "2111660",
    "end": "2117930"
  },
  {
    "text": "if you imagine if you look at our experience in the card you have sections so it's a very well suited architecture",
    "start": "2117930",
    "end": "2124829"
  },
  {
    "text": "you could say that every section is powered by a small micro service is like domain is a bounded context fits really",
    "start": "2124829",
    "end": "2130829"
  },
  {
    "text": "nice but still we didn't go ahead and do it because we knew that there was a lot of overhead in doing that so what we did",
    "start": "2130829",
    "end": "2139800"
  },
  {
    "text": "is that we did something which we call organized monolith what it means is that you have a",
    "start": "2139800",
    "end": "2145980"
  },
  {
    "text": "monolith but instead of having this layered architectural inside code you structure your code to actually have",
    "start": "2145980",
    "end": "2152880"
  },
  {
    "text": "this good features of a micro service except the fact that you cannot deploy independently or you cannot scale",
    "start": "2152880",
    "end": "2158250"
  },
  {
    "text": "independently you scale as one unit but internally you structure your code to be more domain driven right and I think I",
    "start": "2158250",
    "end": "2165030"
  },
  {
    "text": "like to call it organized model it because you basically think that at some point you want to do micro services so",
    "start": "2165030",
    "end": "2170640"
  },
  {
    "text": "you got kind of get ready for that world if you look at our architecture every",
    "start": "2170640",
    "end": "2176280"
  },
  {
    "text": "section is powered by one of these blocks right so like for example the",
    "start": "2176280",
    "end": "2181740"
  },
  {
    "text": "contact section is powered by the contacts provider service it's not really a service but it's one of those domain blocks where you have a in",
    "start": "2181740",
    "end": "2188670"
  },
  {
    "text": "c-sharp you have a sister project is a library and it only deals about that domain and then it goes and does",
    "start": "2188670",
    "end": "2195870"
  },
  {
    "text": "whatever is needed it owns his own data and so forth just to it-it's like some",
    "start": "2195870",
    "end": "2203010"
  },
  {
    "text": "high-level concepts is is form based on bounded context similar to microservices it's simple and small right that's one",
    "start": "2203010",
    "end": "2210120"
  },
  {
    "text": "of the key and one of the main things is that it owns a particular set of data so",
    "start": "2210120",
    "end": "2215190"
  },
  {
    "text": "if it owns a particular set of data if in someone else needs the data to add",
    "start": "2215190",
    "end": "2220770"
  },
  {
    "text": "view/edit whatever it has to go through this block very similar to how micro services work right and in this world",
    "start": "2220770",
    "end": "2228150"
  },
  {
    "text": "one of the most important thing is to not have type dependency on each other right because if you have this small",
    "start": "2228150",
    "end": "2233400"
  },
  {
    "text": "libraries and then that like half pipe deepness on each other then you have formed a spaghetti maybe layered architecture would have",
    "start": "2233400",
    "end": "2239490"
  },
  {
    "text": "been even better so then how do they actually use each other so you basically extract all the interfaces out and then you actually",
    "start": "2239490",
    "end": "2246270"
  },
  {
    "text": "communicate through that alright so there are many ways to do this one way is what I just said and then or else if you are familiar",
    "start": "2246270",
    "end": "2252510"
  },
  {
    "text": "with the mediator pattern in c-sharp you can actually implement that as well so it's basically ensuring when you have",
    "start": "2252510",
    "end": "2258030"
  },
  {
    "text": "these blocks they there is a mediator which handles these dependences for you because later on what you can do is that",
    "start": "2258030",
    "end": "2264990"
  },
  {
    "text": "you can extract one of this put a web head on top and then make sure that instead of talking to the interface you",
    "start": "2264990",
    "end": "2271020"
  },
  {
    "text": "are talking to the rest endpoint right then it becomes your micro service for example like you have this organized",
    "start": "2271020",
    "end": "2276960"
  },
  {
    "text": "money you can take it out as I said you can build a small service but given we have started",
    "start": "2276960",
    "end": "2282260"
  },
  {
    "text": "with the organiz monolith we didn't have to take the upfront cost of building a service but then when we needed to we",
    "start": "2282260",
    "end": "2288110"
  },
  {
    "text": "actually are ready for that wall our code is structured that way and we actually started doing that now we have",
    "start": "2288110",
    "end": "2293690"
  },
  {
    "text": "like spin two more services out of it at this - and then there are also like",
    "start": "2293690",
    "end": "2300830"
  },
  {
    "text": "new services which starts being a new service from day one and then you start",
    "start": "2300830",
    "end": "2306110"
  },
  {
    "text": "forming this Microsoft's architecture for your application that's so before I end high-level tech",
    "start": "2306110",
    "end": "2316190"
  },
  {
    "text": "takeaways scaling architecture for your overall architecture to be scalable",
    "start": "2316190",
    "end": "2321970"
  },
  {
    "text": "every resource that you use you should identify that up front and ensure that it scales for your scenario then you can",
    "start": "2321970",
    "end": "2330170"
  },
  {
    "text": "only truly say that you have a scalable architecture so designing for performance to me means a lot about",
    "start": "2330170",
    "end": "2338990"
  },
  {
    "text": "understanding your scenario so it's not about like some of the techniques that we used if you understand your scenario",
    "start": "2338990",
    "end": "2345140"
  },
  {
    "text": "and you have enough optics to understand where your bottlings bottlenecks are you",
    "start": "2345140",
    "end": "2350150"
  },
  {
    "text": "will figure out what's the best way to achieve performance for your scenario so peter docker",
    "start": "2350150",
    "end": "2355400"
  },
  {
    "text": "basically has this core where he says if you can't measure it you can't improve it this really sums up what designing",
    "start": "2355400",
    "end": "2362720"
  },
  {
    "text": "for performance really means at least for me and lastly scaling engineering it should",
    "start": "2362720",
    "end": "2369500"
  },
  {
    "text": "be considered as a first class problem not many people reflect added upfront",
    "start": "2369500",
    "end": "2374690"
  },
  {
    "text": "and even if they do often they kind of like jump into micro services and I",
    "start": "2374690",
    "end": "2380300"
  },
  {
    "text": "think there is a wall in between as well so think through your scenarios and see if starting with an organized model it",
    "start": "2380300",
    "end": "2386840"
  },
  {
    "text": "could be a better fit for your scenario that's all I had for today thank you so much for coming and I can take some",
    "start": "2386840",
    "end": "2393710"
  },
  {
    "text": "questions if there are any yes please",
    "start": "2393710",
    "end": "2398200"
  },
  {
    "text": "yeah I can explain again yes so on let's",
    "start": "2400240",
    "end": "2406270"
  },
  {
    "text": "say that you are on the JavaScript side you just have another library so through that library you send your rest requests",
    "start": "2406270",
    "end": "2413109"
  },
  {
    "text": "right that basically changes packs the rest requests into a WebSocket frame and",
    "start": "2413109",
    "end": "2418150"
  },
  {
    "text": "then just sends it back you can do that",
    "start": "2418150",
    "end": "2425980"
  },
  {
    "text": "as well so our lair basically allows you to do so when you write so the beauty of that is that you as a like JavaScript",
    "start": "2425980",
    "end": "2434020"
  },
  {
    "text": "developer will only I'll go back so that I can see you so what you do is that you",
    "start": "2434020",
    "end": "2440109"
  },
  {
    "text": "send rest requests but you send it through our library the library basically converts that into a like",
    "start": "2440109",
    "end": "2447250"
  },
  {
    "text": "packs it into the frame and then sends it let's say that this layer was not able to be formed right then instead of",
    "start": "2447250",
    "end": "2454270"
  },
  {
    "text": "packing it into a frame it just sends it as a rescue quest so we are allowing both so as a front-end developer you",
    "start": "2454270",
    "end": "2461650"
  },
  {
    "text": "don't have to worry about whether it goes through West or WebSocket or HTTP 2.0 it seamlessly is taken care for you",
    "start": "2461650",
    "end": "2468420"
  },
  {
    "text": "know that doesn't answer your question yeah yes",
    "start": "2468420",
    "end": "2474630"
  },
  {
    "text": "yes so signal are basically users websocket behind the scenes and of course TCP but signal are also keeps",
    "start": "2479680",
    "end": "2487069"
  },
  {
    "text": "bookkeeping on the back end side it has a backplane because it had to resend some because what it does is that it",
    "start": "2487069",
    "end": "2492469"
  },
  {
    "text": "creates multiple connections so it's great a tree sending the messages to all clients and bookkeeping of who has",
    "start": "2492469",
    "end": "2498469"
  },
  {
    "text": "received in who is not these are not functionally the WebSocket has WebSocket is just alright yeah more questions",
    "start": "2498469",
    "end": "2507489"
  },
  {
    "text": "yeah if not thank you and enjoy the rest of the day [Applause]",
    "start": "2507489",
    "end": "2517949"
  }
]
[
  {
    "start": "0",
    "end": "34000"
  },
  {
    "text": "all right I think it's time to get started I'm here",
    "start": "10100",
    "end": "16560"
  },
  {
    "text": "about the pipeline we use in in space maker and how we use queue bernetta sand",
    "start": "16560",
    "end": "23160"
  },
  {
    "text": "cloud Google cloud pub/sub to create that pipeline so can anymore",
    "start": "23160",
    "end": "28680"
  },
  {
    "text": "sorry not anyone everyone raise your hands okay who here hasn't heard about",
    "start": "28680",
    "end": "35610"
  },
  {
    "start": "34000",
    "end": "67000"
  },
  {
    "text": "kubernetes lower their arms okay and who",
    "start": "35610",
    "end": "43800"
  },
  {
    "text": "here who uses kubernetes every day keep your hands in the air okay so there are",
    "start": "43800",
    "end": "50610"
  },
  {
    "text": "someone using queue minutes every day okay we will stop doing this but who here has heard about cloud pub/sub okay",
    "start": "50610",
    "end": "58710"
  },
  {
    "text": "quite a few nice and what about these guys the function as a service offerings",
    "start": "58710",
    "end": "64110"
  },
  {
    "text": "from from the cloud providers okay so my",
    "start": "64110",
    "end": "69390"
  },
  {
    "start": "67000",
    "end": "171000"
  },
  {
    "text": "name is Hakon humble I'm a data engineer at space maker I'll give a brief",
    "start": "69390",
    "end": "75119"
  },
  {
    "text": "introduction to space maker in a couple of slides but that basically means I work very close to the data scientists",
    "start": "75119",
    "end": "83039"
  },
  {
    "text": "in in in space maker helping them with",
    "start": "83039",
    "end": "88200"
  },
  {
    "text": "doing pipelines and engineering stuff I also have a Twitter handle I don't use",
    "start": "88200",
    "end": "94350"
  },
  {
    "text": "Twitter but I get notifications if you reach out so if you have any questions you can post them on Twitter so who here",
    "start": "94350",
    "end": "101759"
  },
  {
    "text": "has heard about space maker that's quite a few so in space maker we believe there",
    "start": "101759",
    "end": "108090"
  },
  {
    "text": "are better ways to design our cities because it turns out that the",
    "start": "108090",
    "end": "114119"
  },
  {
    "text": "construction industry is a digitally challenged business and it also had a",
    "start": "114119",
    "end": "120119"
  },
  {
    "text": "negative productivity growth and the",
    "start": "120119",
    "end": "127139"
  },
  {
    "text": "reason why that is we believe is the requirements for building buildings and",
    "start": "127139",
    "end": "133500"
  },
  {
    "text": "housing gets increasingly harder it's too much to handle for the human brain",
    "start": "133500",
    "end": "140100"
  },
  {
    "text": "at the same time there are regulations parking requirements politics economics",
    "start": "140100",
    "end": "146209"
  },
  {
    "text": "noise daylight all these kind of things and Allah more so we in space maker we build",
    "start": "146209",
    "end": "153180"
  },
  {
    "text": "software that will help our user users navigate this design space and we we",
    "start": "153180",
    "end": "159870"
  },
  {
    "text": "give them the decision service support along the way sort of having like as if",
    "start": "159870",
    "end": "165900"
  },
  {
    "text": "you have an AI on your shoulder when developing these kind of projects so what I'm going to talk today I'm first",
    "start": "165900",
    "end": "172770"
  },
  {
    "text": "going to give you some context as where we are in the organization that's",
    "start": "172770",
    "end": "178140"
  },
  {
    "text": "relevant for this presentation then I'm going to introduce where we where we had",
    "start": "178140",
    "end": "183450"
  },
  {
    "text": "an old batch oriented pipeline for generating proposals I'll dig into that",
    "start": "183450",
    "end": "190610"
  },
  {
    "text": "how that worked and then I'll point to",
    "start": "190610",
    "end": "198180"
  },
  {
    "text": "you here we'll go through the new pipeline that we created as a result of the old all pipeline not doing its job",
    "start": "198180",
    "end": "205560"
  },
  {
    "text": "properly and then I'll dig some into how we actually are running the different",
    "start": "205560",
    "end": "211260"
  },
  {
    "text": "steps in the pipeline through this what we call pipeline workers so if we start with some context basically we have an",
    "start": "211260",
    "end": "227010"
  },
  {
    "text": "AI engine I know the AI is a sort of a buzz word but this is a bit more or less",
    "start": "227010",
    "end": "232470"
  },
  {
    "text": "how it looks like there's a set of input parameters to this AI engine there could",
    "start": "232470",
    "end": "237660"
  },
  {
    "text": "be some personal preferences or you could have some physical environment and",
    "start": "237660",
    "end": "244560"
  },
  {
    "text": "and some configuration that needs to be fed into the AI engine and then we start",
    "start": "244560",
    "end": "250200"
  },
  {
    "text": "we start the engine and out on the other side come a set of different solutions or proposals on the other side that",
    "start": "250200",
    "end": "257549"
  },
  {
    "text": "adhere to all of this to this configuration and what that means in",
    "start": "257549",
    "end": "264780"
  },
  {
    "text": "practice is that our AI engine is a set of steps that we execute in order this",
    "start": "264780",
    "end": "270870"
  },
  {
    "text": "is a very simplified view of our pipeline it doesn't make sense to go into to the very different steps we have",
    "start": "270870",
    "end": "278220"
  },
  {
    "text": "all of the steps we have but for the sake of this presentation we're going to assume there are three steps in the",
    "start": "278220",
    "end": "283530"
  },
  {
    "text": "pipeline is one that will generate some building footprints there is one step that will",
    "start": "283530",
    "end": "290460"
  },
  {
    "text": "analyze the Sun conditions of these footprints and there will be a search",
    "start": "290460",
    "end": "295770"
  },
  {
    "text": "optimized type of engine on the end that will keep look for the best solutions",
    "start": "295770",
    "end": "301260"
  },
  {
    "text": "and try to incrementally improve them so I as you probably saw when entering this",
    "start": "301260",
    "end": "308370"
  },
  {
    "text": "room the title of this presentation included the world quite difficult word",
    "start": "308370",
    "end": "314580"
  },
  {
    "text": "who pronounced to be honest but he true Jannetty and it's really important that i need to that you guys understand what",
    "start": "314580",
    "end": "322080"
  },
  {
    "text": "that really means so for this generate",
    "start": "322080",
    "end": "327479"
  },
  {
    "text": "step you require a GPU we use a neural network to generate a lot of buildings",
    "start": "327479",
    "end": "334169"
  },
  {
    "text": "and this is a GPU intensive application for analyzing Sun turns out this sort of",
    "start": "334169",
    "end": "341850"
  },
  {
    "text": "most efficient algorithm is to to map your surroundings detail on a detail",
    "start": "341850",
    "end": "348240"
  },
  {
    "text": "level use so if this algorithm requires a lot of memory this is a memory",
    "start": "348240",
    "end": "355250"
  },
  {
    "text": "intensive step in the pipeline and searching and optimization is very is",
    "start": "355250",
    "end": "362039"
  },
  {
    "text": "traditionally very CPU intensive but it's not only like what kind of hardware",
    "start": "362039",
    "end": "367380"
  },
  {
    "text": "are the different steps requiring it's also different in terms of for instance",
    "start": "367380",
    "end": "374220"
  },
  {
    "text": "this neural network it takes it has some startup time because you need to load the model from somewhere and and and put",
    "start": "374220",
    "end": "382380"
  },
  {
    "text": "it into memory and yes it requires a disk this analyze step can do to various",
    "start": "382380",
    "end": "389669"
  },
  {
    "text": "sizes of the plots we are processing can take somewhere between hundred milliseconds and two hours we don't know",
    "start": "389669",
    "end": "396330"
  },
  {
    "text": "and this one here is doesn't take as long time but it it wants more cores to",
    "start": "396330",
    "end": "405150"
  },
  {
    "text": "do its search efficiently so this is what I mean like we have distinct steps",
    "start": "405150",
    "end": "411090"
  },
  {
    "text": "in the pipeline all have different requirements to to their runtimes to their online hardware",
    "start": "411090",
    "end": "418099"
  },
  {
    "text": "and it's not only a technical requirement we're working with here it's",
    "start": "419680",
    "end": "426500"
  },
  {
    "text": "also a cultural thing because the the value that the autonomy is a cultural",
    "start": "426500",
    "end": "432770"
  },
  {
    "text": "value in space maker that we we hold dearly and we're not going to let that",
    "start": "432770",
    "end": "437900"
  },
  {
    "text": "go even though we're making a pipeline so what that means is you have a choice",
    "start": "437900",
    "end": "443810"
  },
  {
    "text": "in programming language and not choice as its use whatever you want it's sure",
    "start": "443810",
    "end": "449930"
  },
  {
    "text": "it's no one going to tell your team what tool is the best for the job your team",
    "start": "449930",
    "end": "455330"
  },
  {
    "text": "is responsible for picking the programming language the libraries that makes the most sense for that particular",
    "start": "455330",
    "end": "461630"
  },
  {
    "text": "application and there shouldn't be anyone telling you how you would like",
    "start": "461630",
    "end": "467960"
  },
  {
    "text": "your services deployed if you want to use a cloud function if you want to use an ec2 instance that should be perfectly",
    "start": "467960",
    "end": "474950"
  },
  {
    "text": "fine because in space maker we believe the teams are in charge and know how to",
    "start": "474950",
    "end": "480950"
  },
  {
    "text": "to pick their own technologies so we need to deal with this autonomy and this",
    "start": "480950",
    "end": "486830"
  },
  {
    "start": "484000",
    "end": "762000"
  },
  {
    "text": "heat virginity basically that's the summary of this section so let's talk",
    "start": "486830",
    "end": "495470"
  },
  {
    "text": "about the pipeline that was present when I joined the company last September it",
    "start": "495470",
    "end": "501289"
  },
  {
    "text": "was very geared towards a server less setup we used as many host services as we possibly can so if I'm bringing back",
    "start": "501289",
    "end": "509000"
  },
  {
    "text": "the pipeline steps now it we based it on on docker docker images where all of the",
    "start": "509000",
    "end": "516710"
  },
  {
    "text": "teams or all of the different steps was deployed as docker images we ran these",
    "start": "516710",
    "end": "522890"
  },
  {
    "text": "docker images in a service called AWS patch which essentially the interface is",
    "start": "522890",
    "end": "530510"
  },
  {
    "text": "I want to run this container with this amount of CPU dismount memory and we",
    "start": "530510",
    "end": "537680"
  },
  {
    "text": "also run several of these steps in parallel I have a slide on that later I'll show you how that works",
    "start": "537680",
    "end": "543190"
  },
  {
    "text": "we used AWS s3 the distributed storage system provided by AWS to",
    "start": "543190",
    "end": "550010"
  },
  {
    "text": "change data it not only was it because there's no easy way to forward data",
    "start": "550010",
    "end": "556490"
  },
  {
    "text": "between jobs in AWS patch but also because of the sheer volume of the the",
    "start": "556490",
    "end": "562810"
  },
  {
    "text": "the work that was done so it made a lot of sense to use AWS tree and to tie it",
    "start": "562810",
    "end": "569150"
  },
  {
    "text": "all together we used something called AWS step functions with which calls set",
    "start": "569150",
    "end": "574640"
  },
  {
    "text": "of lambdas AWS lambdas in sequence in order to continuously pull are you done",
    "start": "574640",
    "end": "580250"
  },
  {
    "text": "yet or you done yet or you don't yet are you're done so we can proceed to the next step and and just to elaborate",
    "start": "580250",
    "end": "589640"
  },
  {
    "text": "further on what I really mean by running jobs in parallel is like when you press",
    "start": "589640",
    "end": "594980"
  },
  {
    "text": "that button said I want a lot of proposals what really happens is you you",
    "start": "594980",
    "end": "600020"
  },
  {
    "text": "seed you start you throw the dice once and then you set off a set of pipelines",
    "start": "600020",
    "end": "606950"
  },
  {
    "text": "in parallel which means you can actually run for one particular solution coming out it on the end all of the pipeline",
    "start": "606950",
    "end": "614030"
  },
  {
    "text": "steps are independent of each other and",
    "start": "614030",
    "end": "618400"
  },
  {
    "text": "we're kind of super happy about having no servers and I cannot stress this",
    "start": "621820",
    "end": "627260"
  },
  {
    "text": "enough not having a platform not having infrastructure especially in a start-up where you're sort of working to find a",
    "start": "627260",
    "end": "634880"
  },
  {
    "text": "product market fit you need to do cheap experiments this is a great solution but",
    "start": "634880",
    "end": "640280"
  },
  {
    "text": "we came to the point this felt a lot like trying to knock in a square peg and",
    "start": "640280",
    "end": "647150"
  },
  {
    "text": "fit it into a round hole and for those of you who have seen bird box is like we",
    "start": "647150",
    "end": "654950"
  },
  {
    "text": "thought it was like that that thing in books every time we looked at it we wanted to smash our heads against the",
    "start": "654950",
    "end": "660680"
  },
  {
    "text": "wall real hard so it had a set of problems it was really pricey because we",
    "start": "660680",
    "end": "668240"
  },
  {
    "text": "had to tune the resource usage for all the worst-case scenarios because we had",
    "start": "668240",
    "end": "674120"
  },
  {
    "text": "some of these generations working on very very large plots consuming a lot of",
    "start": "674120",
    "end": "679640"
  },
  {
    "text": "resources and there was no way we could tune the memory use for the average case so we always had to",
    "start": "679640",
    "end": "686390"
  },
  {
    "text": "go up and say oh this steps requires 60 gigabytes of memory although we knew the average case was just 5 gigabytes",
    "start": "686390",
    "end": "692390"
  },
  {
    "text": "because we had the occasional a prop plot that would consume that much memory",
    "start": "692390",
    "end": "699070"
  },
  {
    "text": "it was close to impossible monitoring what's inside AWS batch we tried",
    "start": "699070",
    "end": "705560"
  },
  {
    "text": "installing some prometheus exporters and that didn't work very well and we",
    "start": "705560",
    "end": "713390"
  },
  {
    "text": "struggle with performance because for every single step although as the previous some previous slides ago I told",
    "start": "713390",
    "end": "720050"
  },
  {
    "text": "like each step was independent of each other after you've thrown the dice we still had to wait for all the",
    "start": "720050",
    "end": "727040"
  },
  {
    "text": "outliers before proceeding to the next step and provisioning instances which",
    "start": "727040",
    "end": "732770"
  },
  {
    "text": "means I want to run the thousand jobs but we don't have the hardware so a AWS",
    "start": "732770",
    "end": "738140"
  },
  {
    "text": "will schedule that for us and that could take like 10 to 15 minutes at worst so",
    "start": "738140",
    "end": "743210"
  },
  {
    "text": "that that's not really great all right personally i love testing in production",
    "start": "743210",
    "end": "750200"
  },
  {
    "text": "or pretty much there are a lot of good reasons to do that but not in this case we had a lot of pipeline failures",
    "start": "750200",
    "end": "756380"
  },
  {
    "text": "because there is no easy way to test your components so that's a problem as well so basically this thing was too",
    "start": "756380",
    "end": "764390"
  },
  {
    "text": "expensive it was too slow and it kind of doesn't deal with autonomy in terms of",
    "start": "764390",
    "end": "769540"
  },
  {
    "text": "you we have impulsive specific way of deploying your your thing and and and a",
    "start": "769540",
    "end": "776680"
  },
  {
    "text": "specific runtime and it does definitely not deal with heterogeneity because you're restricted to the AWS batch",
    "start": "776680",
    "end": "784340"
  },
  {
    "text": "runtime which which is words for something it doesn't work for all things",
    "start": "784340",
    "end": "790600"
  },
  {
    "text": "so we started working on a new message page pipeline we started out with the",
    "start": "790600",
    "end": "797750"
  },
  {
    "start": "792000",
    "end": "832000"
  },
  {
    "text": "simple question I guess no surprise like okay what architecture are we looking at",
    "start": "797750",
    "end": "805070"
  },
  {
    "text": "here what what do you really need in order to fulfill the requirements of the",
    "start": "805070",
    "end": "810260"
  },
  {
    "text": "pipeline preserving autonomy dealing with heterogeneity so we came up with",
    "start": "810260",
    "end": "816650"
  },
  {
    "text": "something simple as a message based model where there would be producers and",
    "start": "816650",
    "end": "822770"
  },
  {
    "text": "consumers dispatching a set of tasks on queues and you had workers sort of",
    "start": "822770",
    "end": "828260"
  },
  {
    "text": "picking up the tasks and performing the work and this is where I introduced",
    "start": "828260",
    "end": "833270"
  },
  {
    "start": "832000",
    "end": "912000"
  },
  {
    "text": "cloud pub/sub there were some people have used and heard about pub/sub before",
    "start": "833270",
    "end": "838970"
  },
  {
    "text": "it's a great service what the core of pub/sub is a topic a topic is more is",
    "start": "838970",
    "end": "847220"
  },
  {
    "text": "more or less a queue where you have a publisher that to publish messages to a topic cloud pub/sub would store those",
    "start": "847220",
    "end": "855080"
  },
  {
    "text": "messages for you and you can set up a subscription on the other side for to read messages there and when you read a",
    "start": "855080",
    "end": "861830"
  },
  {
    "text": "message you're a subscriber then you get to acknowledge or negatively acknowledge",
    "start": "861830",
    "end": "867950"
  },
  {
    "text": "those messages and when you have acknowledged the message you are pretty",
    "start": "867950",
    "end": "873320"
  },
  {
    "text": "much not going to see it again you are but yeah not most likely not you can",
    "start": "873320",
    "end": "885230"
  },
  {
    "text": "have one subscriber subscribing to multiple topics as you can see on the",
    "start": "885230",
    "end": "891080"
  },
  {
    "text": "left and you can have multiple subscribers per topic so let me walk you",
    "start": "891080",
    "end": "899690"
  },
  {
    "text": "through some some good points about pub/sub compared to some other technologies we have here the first one",
    "start": "899690",
    "end": "907670"
  },
  {
    "text": "is that we needed is because the rule the occasional be the occasional task in",
    "start": "907670",
    "end": "913850"
  },
  {
    "start": "912000",
    "end": "947000"
  },
  {
    "text": "the pipeline we cannot process and I've been working a lot with a partial Kafka",
    "start": "913850",
    "end": "919040"
  },
  {
    "text": "before before and those poison pills those kind of tasks that doesn't process stalls the entire pipeline but in cloud",
    "start": "919040",
    "end": "926420"
  },
  {
    "text": "pub/sub it can actually proceed without being able to read all the messages",
    "start": "926420",
    "end": "931850"
  },
  {
    "text": "because there's a one at a time acknowledge message in Kafka it would say like I don't understand this message",
    "start": "931850",
    "end": "938330"
  },
  {
    "text": "so I cannot proceed and this is what we need is a good good quality of cloud",
    "start": "938330",
    "end": "944000"
  },
  {
    "text": "pub/sub this one is is pretty technical",
    "start": "944000",
    "end": "950200"
  },
  {
    "start": "947000",
    "end": "1012000"
  },
  {
    "text": "interesting and and the great feature of pub/sub I'd say by default you get a",
    "start": "950200",
    "end": "957320"
  },
  {
    "text": "very short lease period so if you're a worker you take a message off the queue you have to continuously pull good cloud",
    "start": "957320",
    "end": "965570"
  },
  {
    "text": "pub/sub I'm still working I'm still working I'm still working and you do that every 25 seconds or so and that",
    "start": "965570",
    "end": "971930"
  },
  {
    "text": "means if you die the message will reappear quite shortly because our",
    "start": "971930",
    "end": "977420"
  },
  {
    "text": "processes die this is compared to AWS sqs which lets you upfront specify lease",
    "start": "977420",
    "end": "984950"
  },
  {
    "text": "period so as for the analysis step that could take somewhere between hundred",
    "start": "984950",
    "end": "990560"
  },
  {
    "text": "milliseconds and two hours you'd pick the message I need it for at most site",
    "start": "990560",
    "end": "996050"
  },
  {
    "text": "two two and a half hours and then if you die after 10 seconds that message will not reappear and you basically stall the",
    "start": "996050",
    "end": "1003670"
  },
  {
    "text": "entire run there's that that's a very neat feature about cloud pub/sub this",
    "start": "1003670",
    "end": "1011560"
  },
  {
    "text": "one too also compared to two vanilla AWS SPS is you can have multiple subscribers",
    "start": "1011560",
    "end": "1017530"
  },
  {
    "start": "1012000",
    "end": "1062000"
  },
  {
    "text": "and people wonder like why do you need multiple subscribers well you normally say you have a topic that will produce",
    "start": "1017530",
    "end": "1024790"
  },
  {
    "text": "tasks and you'll have a production worker that will work on these tasks you might also instead of running a",
    "start": "1024790",
    "end": "1031270"
  },
  {
    "text": "completely separate pre-production environment you might have only a pre-production worker reading from the",
    "start": "1031270",
    "end": "1037060"
  },
  {
    "text": "same amount of tasks it could be that you're tuning your algorithms and then",
    "start": "1037060",
    "end": "1042339"
  },
  {
    "text": "it's very convenient to pick the same tasks we have writing the results and comparing them after based on the same",
    "start": "1042339",
    "end": "1049030"
  },
  {
    "text": "input and you could also connect some machine learning pipeline here if you want so this this multiple subscribers",
    "start": "1049030",
    "end": "1055480"
  },
  {
    "text": "is is really a neat feature and important for us in in space maker so",
    "start": "1055480",
    "end": "1061740"
  },
  {
    "text": "should I just stop to talk right here was it that easy why we can just say I",
    "start": "1061740",
    "end": "1066940"
  },
  {
    "start": "1062000",
    "end": "1107000"
  },
  {
    "text": "team we have pub/sub now just start sending messages to each other like this",
    "start": "1066940",
    "end": "1072520"
  },
  {
    "text": "we're like the output from each step goes from from one step to another and of course",
    "start": "1072520",
    "end": "1078310"
  },
  {
    "text": "not quite first of all who starts this thing there",
    "start": "1078310",
    "end": "1085270"
  },
  {
    "text": "are like hundreds and thousands of tasks per time the user oppresses the generate",
    "start": "1085270",
    "end": "1091330"
  },
  {
    "text": "I want a lot of proposals button but we need to know where they are and when they're done who has the central authority for",
    "start": "1091330",
    "end": "1098679"
  },
  {
    "text": "identifiers and who controls where to store all the data so let me just",
    "start": "1098679",
    "end": "1104799"
  },
  {
    "text": "restructure what you see here on the slide a little bit here so what we ended",
    "start": "1104799",
    "end": "1109840"
  },
  {
    "text": "up doing was that we per a distinct step in the pipeline we created a topic an",
    "start": "1109840",
    "end": "1117010"
  },
  {
    "text": "input queue for that that's that in the pipeline so in our case we have a generate into topic and analyzed into",
    "start": "1117010",
    "end": "1123970"
  },
  {
    "text": "topic and a search into topic and there will be a set of workers working and processing these messages I'll explain",
    "start": "1123970",
    "end": "1130330"
  },
  {
    "text": "more about these workers in particular in the in the last section of this talk",
    "start": "1130330",
    "end": "1136740"
  },
  {
    "start": "1137000",
    "end": "1182000"
  },
  {
    "text": "we'd have them write to a shared output topic there's nothing wrong with having",
    "start": "1137610",
    "end": "1143530"
  },
  {
    "text": "multiple multiple workers writing to the same topic and then we'd create a",
    "start": "1143530",
    "end": "1149169"
  },
  {
    "text": "central broker doing these kind of things that answering these kind of",
    "start": "1149169",
    "end": "1155260"
  },
  {
    "text": "questions that I had on the previous slide and to start the thing we created",
    "start": "1155260",
    "end": "1160330"
  },
  {
    "text": "a HTTP API this is actually facing our",
    "start": "1160330",
    "end": "1165340"
  },
  {
    "text": "users through our front-end so when you have this button like this big red button I want a lot of proposal this",
    "start": "1165340",
    "end": "1170830"
  },
  {
    "text": "will trigger this API will post a message to an inny topic and the broker",
    "start": "1170830",
    "end": "1177820"
  },
  {
    "text": "will pick it up and bootstrap the state so so to go into detail on how to start to run you'll have an HTTP client",
    "start": "1177820",
    "end": "1184179"
  },
  {
    "start": "1182000",
    "end": "1207000"
  },
  {
    "text": "normally one of our front ends a user facing front end that we'd post I want",
    "start": "1184179",
    "end": "1191260"
  },
  {
    "text": "to start a run with these number of solutions and that step that step that's",
    "start": "1191260",
    "end": "1196900"
  },
  {
    "text": "up and that's that like that the clients can configure how to set up the pipeline this is not a fixed pipeline but for the",
    "start": "1196900",
    "end": "1203559"
  },
  {
    "text": "sake of presentation I've just fixed the steps here but basically it's very flexible the API would use a PostgreSQL",
    "start": "1203559",
    "end": "1211510"
  },
  {
    "start": "1207000",
    "end": "1272000"
  },
  {
    "text": "database to create like this domain model like this is run",
    "start": "1211510",
    "end": "1216899"
  },
  {
    "text": "it would publish this run ID like there is a run here can you start it to the",
    "start": "1216899",
    "end": "1222399"
  },
  {
    "text": "inner topic and that one ID would be returned to the client so the client can pull back like okay what's the status",
    "start": "1222399",
    "end": "1228759"
  },
  {
    "text": "what's the what's the deal with with this run after it started the broker",
    "start": "1228759",
    "end": "1235720"
  },
  {
    "text": "which is another component that I explained that I showed you at the previous slide will receive this in",
    "start": "1235720",
    "end": "1241779"
  },
  {
    "text": "message it will also use for now the same database we might change that in",
    "start": "1241779",
    "end": "1246850"
  },
  {
    "text": "the future but it's the same database bootstrap some operational state to keep track of everything and then it will",
    "start": "1246850",
    "end": "1254710"
  },
  {
    "text": "send a set of messages to the first step depending on how many solutions our",
    "start": "1254710",
    "end": "1261399"
  },
  {
    "text": "users requested maybe a hundred maybe a thousand and it will forward that to the to generate in our case so what's",
    "start": "1261399",
    "end": "1278200"
  },
  {
    "start": "1272000",
    "end": "1330000"
  },
  {
    "text": "important to remember is this this broker thing is a state machine where",
    "start": "1278200",
    "end": "1286179"
  },
  {
    "text": "the inputs of the state machine our messages read from the accuse and when",
    "start": "1286179",
    "end": "1292269"
  },
  {
    "text": "you process a message you go from one state to another and you store your state in a Postgres database and if you",
    "start": "1292269",
    "end": "1301119"
  },
  {
    "text": "successfully transition new state you acknowledge the message if you have been somewhat unsuccessful you can timeout or",
    "start": "1301119",
    "end": "1309369"
  },
  {
    "text": "negatively acknowledge the message so I'm not going to go into details on how",
    "start": "1309369",
    "end": "1315879"
  },
  {
    "text": "the code is written the exact state diagram it looks something like this it's not a lot of code but there are",
    "start": "1315879",
    "end": "1321460"
  },
  {
    "text": "some states and some state transitions transitions just keep in mind it's a",
    "start": "1321460",
    "end": "1327429"
  },
  {
    "text": "state machine and you also need to keep in mind we cannot do this in a single",
    "start": "1327429",
    "end": "1333909"
  },
  {
    "text": "threaded application because there are say if we have 10 users starting",
    "start": "1333909",
    "end": "1339340"
  },
  {
    "text": "thousands of runs with 10 pipeline steps each there's going to be a ton of messages working in this",
    "start": "1339340",
    "end": "1346890"
  },
  {
    "text": "so although the broker is not doing any of the work it processes a lot of messages so where we are dependent on",
    "start": "1346890",
    "end": "1355170"
  },
  {
    "text": "having multiple brokers working in parallel and this brings me to my next",
    "start": "1355170",
    "end": "1361170"
  },
  {
    "text": "point is we are in this is a distributed system who here have heard of chaos",
    "start": "1361170",
    "end": "1373410"
  },
  {
    "start": "1370000",
    "end": "1422000"
  },
  {
    "text": "monkey nice okay so chaos monkey is a software created by net Netflix yes that",
    "start": "1373410",
    "end": "1383940"
  },
  {
    "text": "basically will will start unplugging your network cables and turning off the servers for you and will teach the",
    "start": "1383940",
    "end": "1391620"
  },
  {
    "text": "engineers at Netflix to to create resilient systems and we don't have",
    "start": "1391620",
    "end": "1396780"
  },
  {
    "text": "chaos monkey in space maker but when",
    "start": "1396780",
    "end": "1403260"
  },
  {
    "text": "we're in the distributed system we must program as the service could randomly",
    "start": "1403260",
    "end": "1408270"
  },
  {
    "text": "shut off the network network could be unplugged that's the reality of working",
    "start": "1408270",
    "end": "1413910"
  },
  {
    "text": "in this this in a distributed system so we just have to pretend there's a monkey",
    "start": "1413910",
    "end": "1419730"
  },
  {
    "text": "running around in observe room more or less and it's super important here that",
    "start": "1419730",
    "end": "1426299"
  },
  {
    "start": "1422000",
    "end": "1460000"
  },
  {
    "text": "we we are a consistent state at all times so we need to take the data base",
    "start": "1426299",
    "end": "1432809"
  },
  {
    "text": "from one consistent state to another and we need to do bugs and and chaos monkey",
    "start": "1432809",
    "end": "1440190"
  },
  {
    "text": "made might happen during message handling and duplicates happen in in",
    "start": "1440190",
    "end": "1448080"
  },
  {
    "text": "this kind of systems it's really hard to create a system that guarantees at",
    "start": "1448080",
    "end": "1454340"
  },
  {
    "text": "exactly once guarantees so a long long",
    "start": "1454340",
    "end": "1461580"
  },
  {
    "start": "1460000",
    "end": "1505000"
  },
  {
    "text": "long time ago some smart people came up who head to something called a database transaction I believe there he used",
    "start": "1461580",
    "end": "1468630"
  },
  {
    "text": "quite extensively still today which means you can perform a set of operations in atomically for a database",
    "start": "1468630",
    "end": "1475230"
  },
  {
    "text": "and if you roll back it's like nothing happened so I like Patrick that much so I'm",
    "start": "1475230",
    "end": "1483860"
  },
  {
    "text": "willing to use this meme incorrectly but the idea here is what if we start a",
    "start": "1483860",
    "end": "1490220"
  },
  {
    "text": "transaction when we see see a message and then we commit it when we were done",
    "start": "1490220",
    "end": "1496580"
  },
  {
    "text": "processing that message that means we cannot have come in an inconsistent State so what I mean is this is this is",
    "start": "1496580",
    "end": "1506270"
  },
  {
    "start": "1505000",
    "end": "1647000"
  },
  {
    "text": "a time line and this is seen from the broker perspective we're not into the workers of the pipeline this is the",
    "start": "1506270",
    "end": "1511880"
  },
  {
    "text": "broker you receive a message you start the transaction you do a set of database",
    "start": "1511880",
    "end": "1518150"
  },
  {
    "text": "operations which means sort of moving through through trying to update the state of our state machine and then you",
    "start": "1518150",
    "end": "1525890"
  },
  {
    "text": "acknowledge the message and you commit your transaction and if bug happens or",
    "start": "1525890",
    "end": "1531910"
  },
  {
    "text": "monkey comb pulls out your network cable you can always roll back the transaction",
    "start": "1531910",
    "end": "1537650"
  },
  {
    "text": "and if you have the possibility negatively acknowledge that message",
    "start": "1537650",
    "end": "1542750"
  },
  {
    "text": "saying like I didn't finish this this was an invalid state transition and",
    "start": "1542750",
    "end": "1549309"
  },
  {
    "text": "unfortunately this is not doing this naively it's not going to work at all and I'm going to walk you through some",
    "start": "1551559",
    "end": "1557570"
  },
  {
    "text": "examples here let's talk about the order",
    "start": "1557570",
    "end": "1562730"
  },
  {
    "text": "of when you act your message and when you commit your transaction because",
    "start": "1562730",
    "end": "1568760"
  },
  {
    "text": "these are two different storage backends the messages are the pub/sub storage",
    "start": "1568760",
    "end": "1574340"
  },
  {
    "text": "back-end and the transactions are the PostGIS database what if the monkey",
    "start": "1574340",
    "end": "1580250"
  },
  {
    "text": "comes pulling out the network cable or turning off your computer in between those two operations it turns then",
    "start": "1580250",
    "end": "1588710"
  },
  {
    "text": "you'll act the message and you'll probably never see it again and you haven't committed the transaction means you're in an",
    "start": "1588710",
    "end": "1594140"
  },
  {
    "text": "inconsistent state and this is what we call that in most mode at most once delivery system for those who are",
    "start": "1594140",
    "end": "1600290"
  },
  {
    "text": "familiar with with stream stream and data processing",
    "start": "1600290",
    "end": "1607020"
  },
  {
    "text": "systems we could sort of do better I'd",
    "start": "1607020",
    "end": "1612130"
  },
  {
    "text": "argue we could commit the database transaction and acknowledge the message",
    "start": "1612130",
    "end": "1617650"
  },
  {
    "text": "after and if something happens in between that means we have committed",
    "start": "1617650",
    "end": "1626470"
  },
  {
    "text": "that state transition but we haven't committed the message so that means we will see the message again and we will",
    "start": "1626470",
    "end": "1632050"
  },
  {
    "text": "have to do another update of database and this is an at least once delivery",
    "start": "1632050",
    "end": "1638050"
  },
  {
    "text": "system so we need to take take this into",
    "start": "1638050",
    "end": "1643990"
  },
  {
    "text": "account another problem by just naively starting",
    "start": "1643990",
    "end": "1650260"
  },
  {
    "start": "1647000",
    "end": "1732000"
  },
  {
    "text": "a transaction at the beginning and then commit it at the end is you end up",
    "start": "1650260",
    "end": "1655420"
  },
  {
    "text": "actually having serial execution because there will be in the broker there will be multiple brokers running at the same",
    "start": "1655420",
    "end": "1661420"
  },
  {
    "text": "time receiving two different messages roughly at the same time there will be",
    "start": "1661420",
    "end": "1667600"
  },
  {
    "text": "one that will start the transition for the transaction first as you can see",
    "start": "1667600",
    "end": "1673000"
  },
  {
    "text": "here broker one wins the broker two becomes slightly after the database will guarantee there will only there will be",
    "start": "1673000",
    "end": "1679930"
  },
  {
    "text": "at an ordering between those two and this broker one will be doing stuff",
    "start": "1679930",
    "end": "1686230"
  },
  {
    "text": "while it's hard to tailor our queries in a way that the broker tree will also be",
    "start": "1686230",
    "end": "1692230"
  },
  {
    "text": "able to do stuff so in our case the broker two ended up waiting for for the",
    "start": "1692230",
    "end": "1698260"
  },
  {
    "text": "transaction and for the locks so it's only after the broker one committed the transaction broker true could start",
    "start": "1698260",
    "end": "1705670"
  },
  {
    "text": "doing any actual work and committed so so why would you bother with having a",
    "start": "1705670",
    "end": "1711550"
  },
  {
    "text": "distributed system in the first place if it ends up being serial so so that's what's the other reason why this is not",
    "start": "1711550",
    "end": "1719590"
  },
  {
    "text": "going to work and the third and is like we're still not dealing with duplicates because double you will see the same",
    "start": "1719590",
    "end": "1725470"
  },
  {
    "text": "message multiple times so let's let's go",
    "start": "1725470",
    "end": "1731170"
  },
  {
    "text": "back to some theory now there's something called idempotence and I'm going to read the definition from",
    "start": "1731170",
    "end": "1736240"
  },
  {
    "start": "1732000",
    "end": "1884000"
  },
  {
    "text": "Wikipedia idempotence is the property of certain operations in mathematics and computer",
    "start": "1736240",
    "end": "1741350"
  },
  {
    "text": "science whereby they can be applied multiple times without changing the",
    "start": "1741350",
    "end": "1746510"
  },
  {
    "text": "result beyond the initial application I'll show you through some SQL examples",
    "start": "1746510",
    "end": "1752900"
  },
  {
    "text": "what I really mean this operations here where I try to insert my own name into a",
    "start": "1752900",
    "end": "1759680"
  },
  {
    "text": "table which has an auto gate generated primary key is not idempotent every time",
    "start": "1759680",
    "end": "1766010"
  },
  {
    "text": "you run this query you'll end up changing the state which means like okay and then you run it one more time and",
    "start": "1766010",
    "end": "1771770"
  },
  {
    "text": "you'll have two copies of me this on the other hand an update statement you can",
    "start": "1771770",
    "end": "1779450"
  },
  {
    "text": "apply this however many times you want the first operation will change or most",
    "start": "1779450",
    "end": "1786170"
  },
  {
    "text": "likely change the database if you if you run the same operation multiple times",
    "start": "1786170",
    "end": "1791330"
  },
  {
    "text": "you'll end up in the same state as you were no problem and a little more",
    "start": "1791330",
    "end": "1796580"
  },
  {
    "text": "advanced example of an idempotent operation is is what you call an absurd",
    "start": "1796580",
    "end": "1801920"
  },
  {
    "text": "which means you try to insert something in our case I try to insert my own name",
    "start": "1801920",
    "end": "1808430"
  },
  {
    "text": "in case it already exists I update that particular value so I don't touch the",
    "start": "1808430",
    "end": "1813950"
  },
  {
    "text": "key and this is the syntax for PostgreSQL insert into spinner and then",
    "start": "1813950",
    "end": "1819860"
  },
  {
    "text": "on conflict you do some updates so what",
    "start": "1819860",
    "end": "1826640"
  },
  {
    "text": "I'm trying to say here is by using",
    "start": "1826640",
    "end": "1833020"
  },
  {
    "text": "idempotency which are in our case since we use an SQL database updates and",
    "start": "1833020",
    "end": "1838910"
  },
  {
    "text": "absurd operations and we already know up front we have deterministic keys so",
    "start": "1838910",
    "end": "1845900"
  },
  {
    "text": "based on a message you already know what keys you are trying to update as a",
    "start": "1845900",
    "end": "1851750"
  },
  {
    "text": "prerequisite for for having item idempotent operations you end up with a",
    "start": "1851750",
    "end": "1859250"
  },
  {
    "text": "system that allows us for we still need some transactions that are still like a",
    "start": "1859250",
    "end": "1864260"
  },
  {
    "text": "couple of database operations you really want to do do in isolation you can",
    "start": "1864260",
    "end": "1870050"
  },
  {
    "text": "always like negatively acknowledged messages on others in between and you actually end",
    "start": "1870050",
    "end": "1876230"
  },
  {
    "text": "up with the system that's always consistent so to sum up the new pipeline",
    "start": "1876230",
    "end": "1889190"
  },
  {
    "start": "1884000",
    "end": "1936000"
  },
  {
    "text": "offers a way better underlying architecture that's more suited for for",
    "start": "1889190",
    "end": "1894380"
  },
  {
    "text": "our needs in space maker it imposes it on itself no limitations on autonomy and",
    "start": "1894380",
    "end": "1902440"
  },
  {
    "text": "heterogeneity because basically what we say is we have as long as you read tasks",
    "start": "1902440",
    "end": "1909500"
  },
  {
    "text": "from this input topic and post your results to this output topic you can do",
    "start": "1909500",
    "end": "1914990"
  },
  {
    "text": "whatever you want as long as you of course have a Google cloud pub/sub client but but besides that you can",
    "start": "1914990",
    "end": "1921830"
  },
  {
    "text": "deploy you can run it on your own computer if you want to do that or an easy-to instance or at your server room",
    "start": "1921830",
    "end": "1927820"
  },
  {
    "text": "from my team's perspective doesn't matter and this is where we want to be",
    "start": "1927820",
    "end": "1934750"
  },
  {
    "text": "but what we ended up doing like what the teams are doing here is also interesting",
    "start": "1934750",
    "end": "1941600"
  },
  {
    "start": "1936000",
    "end": "1987000"
  },
  {
    "text": "I'd say because this is where we touch upon kubernetes because kubernetes is a big part of it but before I dig into",
    "start": "1941600",
    "end": "1949100"
  },
  {
    "text": "kubernetes i'll i'll just briefly go through where we are because basically",
    "start": "1949100",
    "end": "1956929"
  },
  {
    "text": "what we've been talking about so far is the pipeline architecture and how the",
    "start": "1956929",
    "end": "1962120"
  },
  {
    "text": "broker will dispatch messages we haven't really talked about what's going on inside these boxes except that they are",
    "start": "1962120",
    "end": "1970070"
  },
  {
    "text": "a heterogeneous set that can have different requirements in terms of",
    "start": "1970070",
    "end": "1975860"
  },
  {
    "text": "hardware different requirements in terms of what programming language they use and",
    "start": "1975860",
    "end": "1983350"
  },
  {
    "text": "the amount of time it takes so basically as Patrick Egan we need something that",
    "start": "1983350",
    "end": "1989929"
  },
  {
    "start": "1987000",
    "end": "2087000"
  },
  {
    "text": "reads from the input topic and publish it to the output topic more or less and this is what the section is about so by",
    "start": "1989929",
    "end": "1997279"
  },
  {
    "text": "far the easiest way to create such a work worker is by using Google Cloud",
    "start": "1997279",
    "end": "2004539"
  },
  {
    "text": "functions and the reason why I use Google Cloud functions and not AWS lambda is because Google Cloud functions",
    "start": "2004539",
    "end": "2011049"
  },
  {
    "text": "have are integrated with cloud pub/sub because there are they're from the same cloud provider so I'll walk you through",
    "start": "2011049",
    "end": "2018970"
  },
  {
    "text": "a quick quick code snippet here this is our event handler this is Python code so",
    "start": "2018970",
    "end": "2026230"
  },
  {
    "text": "in order to create this kind of worker what you do is you you decode and parse",
    "start": "2026230",
    "end": "2034629"
  },
  {
    "text": "your data in our case we use Jason based on on the input from the handler",
    "start": "2034629",
    "end": "2039929"
  },
  {
    "text": "you process the data of course this will be much more involved this is this is",
    "start": "2039929",
    "end": "2047019"
  },
  {
    "text": "just a toy example and on the other side you create a client you specify some",
    "start": "2047019",
    "end": "2054608"
  },
  {
    "text": "output topic and you publish your results to that and that's it that's",
    "start": "2054609",
    "end": "2059648"
  },
  {
    "text": "everything it takes and to deploy your cloud function you have a very simple",
    "start": "2059649",
    "end": "2065050"
  },
  {
    "text": "command provided by the Google cloud CLI where you specify your topic to trigger",
    "start": "2065050",
    "end": "2076118"
  },
  {
    "text": "on the name of the handler the name of your runtime and that's pretty much it",
    "start": "2076119",
    "end": "2082300"
  },
  {
    "text": "and you have a working handler that can start reading and and and working on these messages lambda is there are a set",
    "start": "2082300",
    "end": "2090550"
  },
  {
    "start": "2087000",
    "end": "2120000"
  },
  {
    "text": "of ways to do this with lambda this is what we've done basically you have a",
    "start": "2090550",
    "end": "2096190"
  },
  {
    "text": "cloud function invoking the lambdas and then returning when they're back it it's it's a pragmatic it's a simple solution",
    "start": "2096190",
    "end": "2101609"
  },
  {
    "text": "and there are probably no good reasons of using lambda if you because you can",
    "start": "2101609",
    "end": "2107109"
  },
  {
    "text": "just deploy them as a cloud function if you're if you want that but we have no",
    "start": "2107109",
    "end": "2112530"
  },
  {
    "text": "limitations in in space make your own where you want to run your your code so",
    "start": "2112530",
    "end": "2120180"
  },
  {
    "start": "2120000",
    "end": "2175000"
  },
  {
    "text": "these are function as a service offerings and there are a lot of benefits about that but I guess what you",
    "start": "2120180",
    "end": "2129240"
  },
  {
    "text": "can say is like you don't need to deal with scaling here and and serviced and all of these kind of things there's a clear benefit of using this but there",
    "start": "2129240",
    "end": "2138930"
  },
  {
    "text": "are indeed a lot of limitations there are limitations on how much memory you can use how many CPU you can use there",
    "start": "2138930",
    "end": "2146070"
  },
  {
    "text": "are some timeouts there are restrictions on deployment package sizes and if you",
    "start": "2146070",
    "end": "2151920"
  },
  {
    "text": "want to deploy a machine learning model or actually numpy Shapley and a set of",
    "start": "2151920",
    "end": "2157860"
  },
  {
    "text": "other Python libraries you're not going to fit into these requirements and you don't have any CPU no sorry GPU",
    "start": "2157860",
    "end": "2164490"
  },
  {
    "text": "available so so this is obviously not going to work for a lot of different",
    "start": "2164490",
    "end": "2170790"
  },
  {
    "text": "steps in the pipeline and here is where this kubernetes comes in so as I guess",
    "start": "2170790",
    "end": "2176970"
  },
  {
    "start": "2175000",
    "end": "2239000"
  },
  {
    "text": "most of you know kubernetes is a docker orchestration engine I'll go into some",
    "start": "2176970",
    "end": "2183470"
  },
  {
    "text": "some basic concepts in kubernetes because the sort of smallest unit you",
    "start": "2183470",
    "end": "2192270"
  },
  {
    "text": "can have in kubernetes in terms of what you're running it's a pod and a pod is",
    "start": "2192270",
    "end": "2199730"
  },
  {
    "text": "specified by an image and an environment which is like the memory and the CPU and",
    "start": "2199730",
    "end": "2206880"
  },
  {
    "text": "an environment variables for that kind of that's it and it's it's more or less",
    "start": "2206880",
    "end": "2214350"
  },
  {
    "text": "this is not entirely accurate but for our example it's more or less one app and one-to-one mapping between a pod and",
    "start": "2214350",
    "end": "2221010"
  },
  {
    "text": "a running container with the docker image so basically I'm very simplified running a service said in our case this",
    "start": "2221010",
    "end": "2229170"
  },
  {
    "text": "is the generate service you'll have a pod running in the kubernetes cluster reading from the into topic writing to",
    "start": "2229170",
    "end": "2235380"
  },
  {
    "text": "the other topic but the difference here is there are a lot of differences but",
    "start": "2235380",
    "end": "2242200"
  },
  {
    "start": "2239000",
    "end": "2334000"
  },
  {
    "text": "from a practical perspective that this is a live process now it's not like you",
    "start": "2242200",
    "end": "2247210"
  },
  {
    "text": "submit the handler and it will be invoked every time this is a process continuously running which has a very",
    "start": "2247210",
    "end": "2256390"
  },
  {
    "text": "positive benefit that you can utilize some working memory and caches because",
    "start": "2256390",
    "end": "2262119"
  },
  {
    "text": "you know kind of that your function will be called the same time on the same",
    "start": "2262119",
    "end": "2267400"
  },
  {
    "text": "machine so to bring back this is the old example from cloud pub/sub this will",
    "start": "2267400",
    "end": "2274329"
  },
  {
    "text": "still work but we just need something to call this handle event a venom function",
    "start": "2274329",
    "end": "2280930"
  },
  {
    "text": "because this is a live process now it's not like triggered continuously and to set up such a subscription it's not",
    "start": "2280930",
    "end": "2289750"
  },
  {
    "text": "really hard you and you start with this is Python code using the Python Google",
    "start": "2289750",
    "end": "2296980"
  },
  {
    "text": "cloud library you set up a subscription and a subscriber client you specify",
    "start": "2296980",
    "end": "2304029"
  },
  {
    "text": "something called the flow flow control which means like how many messages should be read at the time and how long",
    "start": "2304029",
    "end": "2311680"
  },
  {
    "text": "do you want to lease them at a time and you call subscribe on that particular",
    "start": "2311680",
    "end": "2318519"
  },
  {
    "text": "topic and you point to your hand limit and that's pretty much it now we're sort",
    "start": "2318519",
    "end": "2323559"
  },
  {
    "text": "of this is what's needed extra when going from a cloud function to to a live",
    "start": "2323559",
    "end": "2330519"
  },
  {
    "text": "process running at the same time this is",
    "start": "2330519",
    "end": "2337869"
  },
  {
    "start": "2334000",
    "end": "2441000"
  },
  {
    "text": "a part of a manifest on how to create a pod in kubernetes it's specified by an",
    "start": "2337869",
    "end": "2347230"
  },
  {
    "text": "image you upload and build your images upload them to your container registry",
    "start": "2347230",
    "end": "2352980"
  },
  {
    "text": "of choice you specify the resource requirements in our case you request one",
    "start": "2352980",
    "end": "2359980"
  },
  {
    "text": "gigabyte of memory and two CPUs and this is this is guaranteed this is what you're guaranteed to have so you can you",
    "start": "2359980",
    "end": "2368619"
  },
  {
    "text": "can start now this is what what you're guaranteed to have and you also have a limit which means",
    "start": "2368619",
    "end": "2376620"
  },
  {
    "text": "like you you think you're going to use one gigabyte and you memorize two CPUs",
    "start": "2376620",
    "end": "2382620"
  },
  {
    "text": "at the average case but you know if you use more than two gigabytes of memory",
    "start": "2382620",
    "end": "2388230"
  },
  {
    "text": "and four CPUs something is wrong or off like this is not supposed to use this",
    "start": "2388230",
    "end": "2393860"
  },
  {
    "text": "this much this amount of resources and what's really interesting here is now",
    "start": "2393860",
    "end": "2401400"
  },
  {
    "text": "we're able to space to tune for the average case because all of the",
    "start": "2401400",
    "end": "2407490"
  },
  {
    "text": "resources you don't need you'll hand off to all the other Pods running in the cluster but you're guaranteed to have",
    "start": "2407490",
    "end": "2413550"
  },
  {
    "text": "these resources and you can always go over these kind of these resources as long as you don't hit your limit and the",
    "start": "2413550",
    "end": "2421050"
  },
  {
    "text": "other Pods using less than they're supposed to can hand it over and that you can get a lot of utilization in your",
    "start": "2421050",
    "end": "2428640"
  },
  {
    "text": "cluster because of this mechanism and you can also mount some some hard drives",
    "start": "2428640",
    "end": "2435540"
  },
  {
    "text": "if you want to do that if you have a machine learning model or or credentials or anything so but does it scale we have",
    "start": "2435540",
    "end": "2445500"
  },
  {
    "text": "a lot of messages flowing in our pipeline there there's a peak on the",
    "start": "2445500",
    "end": "2450690"
  },
  {
    "text": "slide I just looked it up yesterday we had a peak on 250,000 sorry 2500",
    "start": "2450690",
    "end": "2458100"
  },
  {
    "text": "messages and we need to be able to have a worker that can start processing those",
    "start": "2458100",
    "end": "2463620"
  },
  {
    "text": "two two and a half thousand messages more or less immediately so how we solve",
    "start": "2463620",
    "end": "2471000"
  },
  {
    "text": "that are just going to introduce you another concept in kubernetes that's relevant which is a deployment that will",
    "start": "2471000",
    "end": "2478110"
  },
  {
    "text": "ensure that we'll sort of wrap your pods into a mechanism that will help you keep",
    "start": "2478110",
    "end": "2484650"
  },
  {
    "text": "your pods alive and specify specify how many pods you want to be running in that",
    "start": "2484650",
    "end": "2490410"
  },
  {
    "text": "particular deployment and associated with these deployments you can add",
    "start": "2490410",
    "end": "2497100"
  },
  {
    "text": "something called a horizontal pod autoscaler that will help you adjust the numbers of",
    "start": "2497100",
    "end": "2502260"
  },
  {
    "text": "pods running in each deployment to specify such a autoscaler in",
    "start": "2502260",
    "end": "2510380"
  },
  {
    "text": "kubernetes you it's this is the config",
    "start": "2510380",
    "end": "2515840"
  },
  {
    "text": "you you start by specifying I want at least one pot running at all times and",
    "start": "2515840",
    "end": "2522020"
  },
  {
    "text": "at most 3000 pots running at the same time you specify some metric there can",
    "start": "2522020",
    "end": "2529880"
  },
  {
    "text": "be a lot of different mechanism you can create your own in our case this is",
    "start": "2529880",
    "end": "2534890"
  },
  {
    "text": "integrated into google kubernetes engine which will run our kubernetes cluster in and you can you are able to to to query",
    "start": "2534890",
    "end": "2543950"
  },
  {
    "text": "pub/sub for how many undelivered messages are in the system so we can",
    "start": "2543950",
    "end": "2549920"
  },
  {
    "text": "scale based on the number of messages you also specify the topic of course you",
    "start": "2549920",
    "end": "2555560"
  },
  {
    "text": "wanna order subscription you want to listen to and you point to that particular deployment you want to scale",
    "start": "2555560",
    "end": "2561350"
  },
  {
    "text": "up and down in terms of so that's the horizontal auto scaling but there will",
    "start": "2561350",
    "end": "2566510"
  },
  {
    "text": "be going from one to three thousand pots will require some extra hardware and luckily we don't need to think about",
    "start": "2566510",
    "end": "2572450"
  },
  {
    "text": "that because by using the built in cluster autoscaler in kubernetes and",
    "start": "2572450",
    "end": "2580030"
  },
  {
    "text": "google kubernetes engine we as you can see here there are two pods to be",
    "start": "2580030",
    "end": "2585050"
  },
  {
    "text": "scheduled and the class auto scale will provision a new node and it will start running those pods behind the scenes we",
    "start": "2585050",
    "end": "2591710"
  },
  {
    "text": "don't need to care about that it take roughly 20 to 30 seconds to get a new piece of hardware added to to our",
    "start": "2591710",
    "end": "2597440"
  },
  {
    "text": "cluster so that was scale up i'll",
    "start": "2597440",
    "end": "2603560"
  },
  {
    "text": "briefly walk you through how scaling down works because that this is where it",
    "start": "2603560",
    "end": "2608900"
  },
  {
    "text": "gets a little tricky we have this",
    "start": "2608900",
    "end": "2615130"
  },
  {
    "text": "imagine this is one of the steps in the pipeline working on four tasks and you",
    "start": "2615130",
    "end": "2621140"
  },
  {
    "text": "have one pod word per task and eventually so we have four undelivered",
    "start": "2621140",
    "end": "2627050"
  },
  {
    "text": "messages and acknowledge messages and eventually one of them will be done and the number of an acknowledged messages",
    "start": "2627050",
    "end": "2633470"
  },
  {
    "text": "will be 3 so the autoscaler will then run on the side",
    "start": "2633470",
    "end": "2639380"
  },
  {
    "text": "seek term send a signal to that pod and that pod will disappear and then time",
    "start": "2639380",
    "end": "2647630"
  },
  {
    "text": "goes put the another pod will be done and you'll just have to an acknowledge",
    "start": "2647630",
    "end": "2653120"
  },
  {
    "text": "messages but it turns out we were lucky the first time because this autoscaler has no clue who of these pods are really",
    "start": "2653120",
    "end": "2661880"
  },
  {
    "text": "done so it ends up randomly picking one of the pots to kill because it's not",
    "start": "2661880",
    "end": "2669290"
  },
  {
    "text": "really a and I see why that's the case but it causes troubles for us so what",
    "start": "2669290",
    "end": "2675410"
  },
  {
    "text": "you end up with in this particular case is like the pod - it's going to die pod one is going to restart processing that",
    "start": "2675410",
    "end": "2683570"
  },
  {
    "text": "particular task and you basically what if pod 2 was nearly done",
    "start": "2683570",
    "end": "2690500"
  },
  {
    "text": "you basically wasted a lot of resources in hardware and slow down our pipeline",
    "start": "2690500",
    "end": "2696740"
  },
  {
    "text": "drastically because if you have to restart the jobs all the time so what we",
    "start": "2696740",
    "end": "2704630"
  },
  {
    "text": "ended up doing is if we get into the same situation again where another pod is so it's trying to be killed whilst",
    "start": "2704630",
    "end": "2712910"
  },
  {
    "text": "they're working there's a possibility to override the sacrum handling in our application so means we can schedule",
    "start": "2712910",
    "end": "2718550"
  },
  {
    "text": "that particular pod for termination that way we don't kill it prematurely so it",
    "start": "2718550",
    "end": "2724790"
  },
  {
    "text": "can actually complete performing that task but you have the issue that pod one",
    "start": "2724790",
    "end": "2730190"
  },
  {
    "text": "will be up doing nothing it's still a better use of resources but it will",
    "start": "2730190",
    "end": "2736070"
  },
  {
    "text": "still be working there and when this thing is done it will send pod for is",
    "start": "2736070",
    "end": "2744490"
  },
  {
    "text": "scheduled to shut down so it will shut down and then only then this other pot",
    "start": "2744490",
    "end": "2749720"
  },
  {
    "text": "will will die so it feels like for this particular problem we're trying to fit",
    "start": "2749720",
    "end": "2755690"
  },
  {
    "start": "2751000",
    "end": "3112000"
  },
  {
    "text": "in a as square peg into a round hole again because what we're really doing is",
    "start": "2755690",
    "end": "2766120"
  },
  {
    "text": "we think we have a service that will continuously process the requests but we",
    "start": "2766120",
    "end": "2771410"
  },
  {
    "text": "are emulate thing but we really have a job like one message run to completion and then die",
    "start": "2771410",
    "end": "2778280"
  },
  {
    "text": "that's more or less the model we are at now so there is a mechanism in kubernetes jobs for that we did we did a",
    "start": "2778280",
    "end": "2786470"
  },
  {
    "text": "experiment it didn't work very well because every time you start a job you",
    "start": "2786470",
    "end": "2792050"
  },
  {
    "text": "can you create so many cobranet these resources and on our scale that was actually a problem for us and honestly I",
    "start": "2792050",
    "end": "2800660"
  },
  {
    "text": "think this mind shift of having a pure based model where we have something live",
    "start": "2800660",
    "end": "2806690"
  },
  {
    "text": "you can use caches you can continuously work on the tasks and maybe maybe have",
    "start": "2806690",
    "end": "2813250"
  },
  {
    "text": "more and smaller steps I don't think that mine shift within space maker is",
    "start": "2813250",
    "end": "2818420"
  },
  {
    "text": "such a bad idea so but to sum up this pipeline worker",
    "start": "2818420",
    "end": "2826310"
  },
  {
    "text": "section is like there is no restriction",
    "start": "2826310",
    "end": "2831830"
  },
  {
    "text": "as I told you in the previous sections no restrictions and how and where to deploy deploy those pipeline workers",
    "start": "2831830",
    "end": "2839410"
  },
  {
    "text": "which leads which deals with autonomy and the heterogeneity that we've",
    "start": "2839410",
    "end": "2845150"
  },
  {
    "text": "discussed earlier earlier kubernetes can deal with really really really well so",
    "start": "2845150",
    "end": "2852440"
  },
  {
    "text": "to sum up their presentation one more higher level I'd say it's important to",
    "start": "2852440",
    "end": "2860150"
  },
  {
    "text": "choose a fundamentally correct model because by just moving from the old",
    "start": "2860150",
    "end": "2865730"
  },
  {
    "text": "batch oriented pipeline to a message based pipeline that sort of fit fit",
    "start": "2865730",
    "end": "2872270"
  },
  {
    "text": "space maker as an organization and and fit the requirements much much better",
    "start": "2872270",
    "end": "2879230"
  },
  {
    "text": "and and we're sweepy happy about that and on the other side when trying to",
    "start": "2879230",
    "end": "2884720"
  },
  {
    "text": "emulate as we saw on the scale down a particular issue when you try to emulate",
    "start": "2884720",
    "end": "2891050"
  },
  {
    "text": "jobs when we really a picked a model that's based upon having live processes",
    "start": "2891050",
    "end": "2896440"
  },
  {
    "text": "performing multiple tasks then you end up with something suboptimal we'll still there it still works pretty well but it",
    "start": "2896440",
    "end": "2903140"
  },
  {
    "text": "feels weird consistency when you have a distributed",
    "start": "2903140",
    "end": "2909999"
  },
  {
    "text": "system and multiple storage backends that can be a tricky thing I I know I",
    "start": "2909999",
    "end": "2917140"
  },
  {
    "text": "explained you've like all the reasons why it didn't work but we had to",
    "start": "2917140",
    "end": "2923769"
  },
  {
    "text": "experience all of it ourselves we took quite a lot of time to make this state machine work as expected so it's about",
    "start": "2923769",
    "end": "2931420"
  },
  {
    "text": "being clever about not having too large transactions and using idempotent",
    "start": "2931420",
    "end": "2936430"
  },
  {
    "text": "operations so you deal with at least once delivery and duplicates and",
    "start": "2936430",
    "end": "2942420"
  },
  {
    "text": "honestly cloud pub/sub kubernetes engine",
    "start": "2942420",
    "end": "2947769"
  },
  {
    "text": "from google which we've used I can I really really recommend those services there do they are doing exactly what",
    "start": "2947769",
    "end": "2955809"
  },
  {
    "text": "they're supposed to do nothing more nothing less and yeah and we do cool",
    "start": "2955809",
    "end": "2962799"
  },
  {
    "text": "things in space maker I hope this this slide has showed so we have come work with us okay I think I have time for a",
    "start": "2962799",
    "end": "2971469"
  },
  {
    "text": "couple of questions if there are any",
    "start": "2971469",
    "end": "2975150"
  },
  {
    "text": "second if we consider a sure event hubs",
    "start": "2980190",
    "end": "2986259"
  },
  {
    "text": "no we did not we don't we haven't used a sure before in space maker so we",
    "start": "2986259",
    "end": "2993609"
  },
  {
    "text": "probably should have looked at that but we didn't",
    "start": "2993609",
    "end": "2997680"
  },
  {
    "text": "the question was whether we use different kubernetes clusters for different tasks now we want to be able to share the",
    "start": "3003570",
    "end": "3012330"
  },
  {
    "text": "resources as much as we can so we use the same kubernetes cluster for our",
    "start": "3012330",
    "end": "3018080"
  },
  {
    "text": "entire space maker platform running on kubernetes but we have a distinction in",
    "start": "3018080",
    "end": "3023940"
  },
  {
    "text": "node pools so all the pipeline workers will run in one node pool and our other",
    "start": "3023940",
    "end": "3030510"
  },
  {
    "text": "production back-end services that are not part of the pipeline will run in another node pool ok and the question",
    "start": "3030510",
    "end": "3057300"
  },
  {
    "text": "was why did we choose to put the brokers in functions rather than in pods maybe I",
    "start": "3057300",
    "end": "3064500"
  },
  {
    "text": "misspoke we run our broker in kubernetes as well",
    "start": "3064500",
    "end": "3071089"
  },
  {
    "text": "so so what I did was I explained how the broker worked without touching into the",
    "start": "3071089",
    "end": "3076650"
  },
  {
    "text": "details on how we deployed it but it's really a deployment in kubernetes and",
    "start": "3076650",
    "end": "3083550"
  },
  {
    "text": "when I transitioned into the anodic or the chapter I went through some examples",
    "start": "3083550",
    "end": "3088830"
  },
  {
    "text": "of what other teams in space maker might want to to do with their own analysis",
    "start": "3088830",
    "end": "3094940"
  },
  {
    "text": "pipeline steps ok I think that's it I",
    "start": "3094940",
    "end": "3103020"
  },
  {
    "text": "can answer your questions offline here if you want if you if you have any so",
    "start": "3103020",
    "end": "3108180"
  },
  {
    "text": "thank you very much [Applause]",
    "start": "3108180",
    "end": "3114069"
  }
]
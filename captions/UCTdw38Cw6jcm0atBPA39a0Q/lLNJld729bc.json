[
  {
    "text": "so welcome everyone last session of the first day of NDC London thanks so much for sticking around for my talk I know",
    "start": "6200",
    "end": "12320"
  },
  {
    "text": "it's kind of late and we're in London lot of things to do so I hope this will be worth your time so hi as you can see",
    "start": "12320",
    "end": "19840"
  },
  {
    "text": "from the screen my name is Jody Burell I'm currently working as the developer advocate in data science at",
    "start": "19840",
    "end": "26560"
  },
  {
    "text": "jetbrains prior to that I was working as a data scientist like an on thegr data scientist for around seven years and my",
    "start": "26560",
    "end": "34320"
  },
  {
    "text": "specialization for a lot of my career was an area called natural language processing which is the area that large",
    "start": "34320",
    "end": "39640"
  },
  {
    "text": "language models now belong to and then prior to that my PhD is actually in Clinical Psychology so I'm sure you can",
    "start": "39640",
    "end": "47120"
  },
  {
    "text": "imagine that with my background I've been following along with the developments in generative AI with a lot",
    "start": "47120",
    "end": "53600"
  },
  {
    "text": "of interest and uh not some small measure of concern and what I want to do today",
    "start": "53600",
    "end": "60480"
  },
  {
    "text": "is take a step back from a lot of the information that you've been hearing that may be a bit hypy and take a more",
    "start": "60480",
    "end": "67600"
  },
  {
    "text": "measured and scientific look at what's actually going on with these models so for the past two years we have",
    "start": "67600",
    "end": "75720"
  },
  {
    "text": "been in an AI hype cycle or hype bubble whatever you want to call it so we had",
    "start": "75720",
    "end": "81720"
  },
  {
    "text": "claims that uh models like Lambda had achieved sentience all the way back in",
    "start": "81720",
    "end": "87400"
  },
  {
    "text": "the middle of 2020 we had news articles coming out that generative models were going to",
    "start": "87400",
    "end": "93520"
  },
  {
    "text": "wipe out huge sways of the white colar job market and we even had claims of AI",
    "start": "93520",
    "end": "101640"
  },
  {
    "text": "dorismond toys what can we realistically use them for",
    "start": "115320",
    "end": "120360"
  },
  {
    "text": "and are they really going to destroy us in this talk we're going to cut through the hype as I said and we're",
    "start": "120360",
    "end": "126399"
  },
  {
    "text": "going to look at the true applications and limitations of these models right now we'll see the context and the",
    "start": "126399",
    "end": "132520"
  },
  {
    "text": "science behind these models and we're going to challenge some of the more outrageous claims in particular the claims that these models are achieving",
    "start": "132520",
    "end": "140000"
  },
  {
    "text": "sentience or artificial general intelligence and even with 60 or so",
    "start": "140000",
    "end": "145319"
  },
  {
    "text": "minutes there was so much I had to cut out of this talk I wrote really a two talk and I had to trim it down so please",
    "start": "145319",
    "end": "152040"
  },
  {
    "text": "feel free to come and find me I'm going to be around at the conference for the next couple of days I would love to chat more about this I will talk your ear off",
    "start": "152040",
    "end": "158000"
  },
  {
    "text": "be warned so for a lot of us it felt like models like delay or chat GPT came out",
    "start": "158000",
    "end": "165440"
  },
  {
    "text": "of nowhere but naturally they are part of a long history of research",
    "start": "165440",
    "end": "170640"
  },
  {
    "text": "specifically Research into two areas natural language processing which I mentioned and computer",
    "start": "170640",
    "end": "177280"
  },
  {
    "text": "vision so interestingly the generation of text and images was not the initial",
    "start": "177280",
    "end": "183440"
  },
  {
    "text": "goal of both of these fields it was actually to build models that could automate tasks with image processing and",
    "start": "183440",
    "end": "190720"
  },
  {
    "text": "text processing that we do manually things like image and text classification translation and",
    "start": "190720",
    "end": "197840"
  },
  {
    "text": "summarization so let's have a look at how this journey evolved the current generation of",
    "start": "197840",
    "end": "204120"
  },
  {
    "text": "generative AI models are all based on a type of machine learning model called a neural net this was originally proposed",
    "start": "204120",
    "end": "211319"
  },
  {
    "text": "as a way of artificially mimicking the human brain research into neuron Nets as you can see went in stops and starts",
    "start": "211319",
    "end": "217640"
  },
  {
    "text": "from the 1940s onwards if you've ever heard the term AI winter or AI summer it's referring to sort of these boom and",
    "start": "217640",
    "end": "223840"
  },
  {
    "text": "bus periods um across the 20th century in this area but it really kind of started to pick up speed in the 1980s",
    "start": "223840",
    "end": "230599"
  },
  {
    "text": "when a number of important technical limitations were overcome however the Practical",
    "start": "230599",
    "end": "236120"
  },
  {
    "text": "applications of these models still remained limited up until around years ago and that's because these models have",
    "start": "236120",
    "end": "242879"
  },
  {
    "text": "really intense Computing requirements I think this is a well-known fact at this stage so research has found that the",
    "start": "242879",
    "end": "248560"
  },
  {
    "text": "bigger you can make neural Nets the more sophisticated or accurate their predictions can become but this requires",
    "start": "248560",
    "end": "255480"
  },
  {
    "text": "the use of processing units that are really efficient at doing huge amounts of matrix",
    "start": "255480",
    "end": "261320"
  },
  {
    "text": "multiplication and as such the first breakthrough on the path to generative AI was the development of Cuda Cuda",
    "start": "261320",
    "end": "269240"
  },
  {
    "text": "allowed us to transform gpus into allpurpose matrix multiplication machines and therefore made the training",
    "start": "269240",
    "end": "276639"
  },
  {
    "text": "of really large neural Nets much more feasible however as you increase the",
    "start": "276639",
    "end": "282479"
  },
  {
    "text": "size of models they also have increasing demands for data therefore the next big",
    "start": "282479",
    "end": "288240"
  },
  {
    "text": "advancement was the release of large open data sets such as image net for computer vision and common craw for",
    "start": "288240",
    "end": "294520"
  },
  {
    "text": "natural language processing and this meant that researchers now had sufficient data to really start training",
    "start": "294520",
    "end": "301280"
  },
  {
    "text": "more like intensive and large models so following these developments",
    "start": "301280",
    "end": "307440"
  },
  {
    "text": "the first of these two fields to really take off was computer vision with the development of a specific type of neural",
    "start": "307440",
    "end": "313320"
  },
  {
    "text": "net called convolutional neural networks or snn not to be confused with the news network the way cnns are constructed",
    "start": "313320",
    "end": "321039"
  },
  {
    "text": "allows them to take raw images as an input and determine for themselves which",
    "start": "321039",
    "end": "326240"
  },
  {
    "text": "features are actually interesting so say they might be able to see ears of an animal or the branches of a tree when I",
    "start": "326240",
    "end": "332600"
  },
  {
    "text": "say c i shouldn't say it these are not anthropomorphic models but they can determine these features for themselves",
    "start": "332600",
    "end": "338759"
  },
  {
    "text": "and they can use it for tasks like image classification telling images apart",
    "start": "338759",
    "end": "344240"
  },
  {
    "text": "prior to that what researchers had to do was to hand annotate those features",
    "start": "344240",
    "end": "349720"
  },
  {
    "text": "themselves so you can see this really freed up researchers to start feeding bigger and bigger data sets into these",
    "start": "349720",
    "end": "356080"
  },
  {
    "text": "models because it required a lot less pre-processing",
    "start": "356080",
    "end": "360720"
  },
  {
    "text": "oops sorry however CNN's are not really that good at generating images and they",
    "start": "361120",
    "end": "368520"
  },
  {
    "text": "were superseded for this purpose by another type of neural net called generative adversarial networks or Gans",
    "start": "368520",
    "end": "375240"
  },
  {
    "text": "so Gans are imageo image models what they do is they take in a huge data set of images and they try to learn patterns",
    "start": "375240",
    "end": "382639"
  },
  {
    "text": "in that data set and they apply these patterns to try to generate novel images that might belong to that data set",
    "start": "382639",
    "end": "390280"
  },
  {
    "text": "so as you can see from the timeline Gams were a very very successful type of",
    "start": "390280",
    "end": "395599"
  },
  {
    "text": "image generation algorithm and most image generation models up until 2020 were ganss one of the most well-known",
    "start": "395599",
    "end": "402840"
  },
  {
    "text": "examples you might remember it was a website called this person does not exist there's a sample from that um",
    "start": "402840",
    "end": "408960"
  },
  {
    "text": "website I love this website when it came out really blew my mind but basically what they did is they used a model",
    "start": "408960",
    "end": "414840"
  },
  {
    "text": "called style Gan and they import a whole bunch of portraits and then the model was able to use that information to",
    "start": "414840",
    "end": "421479"
  },
  {
    "text": "generate people who had never existed jumping back over to natural language processing the first big",
    "start": "421479",
    "end": "427879"
  },
  {
    "text": "breakthrough actually came back in 2007 with the development of a type of model",
    "start": "427879",
    "end": "433080"
  },
  {
    "text": "and type of neural net called long shirt short-term memory networks very catchy name or lstms which is what everyone",
    "start": "433080",
    "end": "440199"
  },
  {
    "text": "calls them because saying long short-term memory networks as you can see is quite difficult so lstms were a",
    "start": "440199",
    "end": "446840"
  },
  {
    "text": "big breakthrough because they were the first of these neural Nets to really understand words in their context and",
    "start": "446840",
    "end": "454520"
  },
  {
    "text": "that meant that unsurprisingly they were a lot better um than previous models at being able to do a range of natural",
    "start": "454520",
    "end": "460800"
  },
  {
    "text": "language tasks such as text uh classification text summarization and",
    "start": "460800",
    "end": "466120"
  },
  {
    "text": "machine translation in fact you might have noted that Google translate suddenly got a lot better in 2016 it's",
    "start": "466120",
    "end": "472639"
  },
  {
    "text": "because they started using lstms under the hood however a major Lim limitation of",
    "start": "472639",
    "end": "478440"
  },
  {
    "text": "lstms is that they're forced to process a piece of text sequentially so say you",
    "start": "478440",
    "end": "483759"
  },
  {
    "text": "have a sentence they start with the first word they extract some information about that they keep it in a shter",
    "start": "483759",
    "end": "490280"
  },
  {
    "text": "memory they then move on to the second word extract more information add that to the memory and so on so as you can",
    "start": "490280",
    "end": "496879"
  },
  {
    "text": "probably imagine this caused a number of technical problems but the biggest of",
    "start": "496879",
    "end": "502280"
  },
  {
    "text": "these is that it was really difficult to scale these models and this was overcome by a type of neuronet called Transformer",
    "start": "502280",
    "end": "510280"
  },
  {
    "text": "models these avoid sequential processing of uh sentences basically they're able",
    "start": "510280",
    "end": "515800"
  },
  {
    "text": "to process a whole bunch of words at the same time and this meant that models",
    "start": "515800",
    "end": "521440"
  },
  {
    "text": "could start getting really really huge a really cool thing about Transformer",
    "start": "521440",
    "end": "526480"
  },
  {
    "text": "networks is as they start like getting trained over huge amounts of text Data",
    "start": "526480",
    "end": "532360"
  },
  {
    "text": "they actually start encoding a bunch of information from that um data including",
    "start": "532360",
    "end": "538360"
  },
  {
    "text": "things like how that Lang language functions rules of grammar things like that so this has kicked off the current",
    "start": "538360",
    "end": "546079"
  },
  {
    "text": "generation of text processing models and this is where we can have the large in large language models the branch of",
    "start": "546079",
    "end": "553040"
  },
  {
    "text": "Transformer models that turned into generative models are generative pre-trained Transformers or gpts and the",
    "start": "553040",
    "end": "560360"
  },
  {
    "text": "first of these came out in 2018 so gpts have been such a successful",
    "start": "560360",
    "end": "566800"
  },
  {
    "text": "type of generative text model that pretty much every single one of the many many many gpts that have come out over",
    "start": "566800",
    "end": "573959"
  },
  {
    "text": "the last 3 years have been based on this architecture that includes some Heavy Hitters that you've definitely heard of",
    "start": "573959",
    "end": "579480"
  },
  {
    "text": "like chat gbt GPT 4 Falcon and llama other way",
    "start": "579480",
    "end": "585399"
  },
  {
    "text": "around so the development of the transform architecture actually allowed us to also move into a new uh era of",
    "start": "585399",
    "end": "592600"
  },
  {
    "text": "image generation which is text to image models so the basis of these models is another type of neural net called click",
    "start": "592600",
    "end": "600120"
  },
  {
    "text": "and this is a Transformer based model which is trained with images in order to",
    "start": "600120",
    "end": "606360"
  },
  {
    "text": "create a model that can find the closest text description for a given image clip was released at the same time as Dal it",
    "start": "606360",
    "end": "614440"
  },
  {
    "text": "uses a Transformer model to map text to images and then rank based on the",
    "start": "614440",
    "end": "620560"
  },
  {
    "text": "description that is closest to a given image however new way of using clip was",
    "start": "620560",
    "end": "626360"
  },
  {
    "text": "quickly discovered and this was of course diffusion model models these models are Guided by clip to",
    "start": "626360",
    "end": "632680"
  },
  {
    "text": "sequentially denoise an image um which contains random pixels into something that gets closer and closer to a text",
    "start": "632680",
    "end": "640120"
  },
  {
    "text": "input and as you can see this has ended up being one of the most successful type of text to image models with pretty much",
    "start": "640120",
    "end": "646959"
  },
  {
    "text": "every single one of these models coming out now based on this architecture okay history lesson over",
    "start": "646959",
    "end": "653760"
  },
  {
    "text": "now that we have an understanding of where these models came from let's have a closer look at the GPT models so we're",
    "start": "653760",
    "end": "660839"
  },
  {
    "text": "not going to look at all of them we'd be here for hours but let's have a look at those that were trained by open AI which",
    "start": "660839",
    "end": "667279"
  },
  {
    "text": "was actually the company that first developed the GPT models so a really interesting problem",
    "start": "667279",
    "end": "674160"
  },
  {
    "text": "as I've said several times for natural language processing is machine translation and this was the first",
    "start": "674160",
    "end": "680000"
  },
  {
    "text": "application of Transformer models so in order to do machine translation a Transformer model needs two components",
    "start": "680000",
    "end": "687519"
  },
  {
    "text": "an encoder and a decoder the job of the encoder is to learn",
    "start": "687519",
    "end": "693079"
  },
  {
    "text": "everything it can about the source language so some sort of source language like English and then be able to take in",
    "start": "693079",
    "end": "700839"
  },
  {
    "text": "Source inputs the thing that you want to translate it then needs to pass what it's learned about that input over to",
    "start": "700839",
    "end": "707240"
  },
  {
    "text": "the decoda the job of the decoda is a bit more complicated it needs to learn",
    "start": "707240",
    "end": "712880"
  },
  {
    "text": "everything it can about the target language it then needs to take the information that was passed over by the",
    "start": "712880",
    "end": "719440"
  },
  {
    "text": "encoder and word by word try to predict the closest matching sequence in the",
    "start": "719440",
    "end": "724920"
  },
  {
    "text": "target language so let's have a look at an example of this let's say we have this sequence in English I visited Italy",
    "start": "724920",
    "end": "732720"
  },
  {
    "text": "and we don't want to translate it to German so the enoda will have learned as much as it can about English and the",
    "start": "732720",
    "end": "740040"
  },
  {
    "text": "theoda will have learned as much as it can about German and then what the encoder will do is take in that input",
    "start": "740040",
    "end": "746639"
  },
  {
    "text": "pass it over to the decoda and the decoda will word by word find the closest matching sequence in",
    "start": "746639",
    "end": "754800"
  },
  {
    "text": "German however something the researchers quickly realized is that these Dakota units all on their own were pretty",
    "start": "754839",
    "end": "762160"
  },
  {
    "text": "interesting as we discussed the Dakota's whole job is to learn everything it can about a target language and use that",
    "start": "762160",
    "end": "768360"
  },
  {
    "text": "knowledge to predict the next word in a sequence based on an input researcher",
    "start": "768360",
    "end": "773399"
  },
  {
    "text": "started to think well what if we cut out the encoder unit and we cut out this Source language and we just train a",
    "start": "773399",
    "end": "779440"
  },
  {
    "text": "decoda unit on the same language so what we can do is we can show a decoda unit",
    "start": "779440",
    "end": "784519"
  },
  {
    "text": "millions and millions of sentences and over time what we'll get is a model that has basically learned based on a given",
    "start": "784519",
    "end": "791720"
  },
  {
    "text": "input the most likely word to come next and so what you end up with you know you",
    "start": "791720",
    "end": "798480"
  },
  {
    "text": "can see from this example is a model that if you put in an input like I have",
    "start": "798480",
    "end": "804199"
  },
  {
    "text": "it can take you know uh you can predict the next most likely next word and the most likely next word after",
    "start": "804199",
    "end": "810760"
  },
  {
    "text": "that and the most likely next word after that and so on so you might be wondering",
    "start": "810760",
    "end": "816320"
  },
  {
    "text": "in this example why it's not always picking the top most likely word this is a mechanism",
    "start": "816320",
    "end": "822160"
  },
  {
    "text": "called temperature to kind of oversimplify it a bit basically what it does is it takes the top most likely",
    "start": "822160",
    "end": "829240"
  },
  {
    "text": "words and it picks one of them rather than always picking the most likely word so temperature was introduced in order",
    "start": "829240",
    "end": "835639"
  },
  {
    "text": "to make large language models sound a bit more natural but it also does have some side effects such as making these",
    "start": "835639",
    "end": "840880"
  },
  {
    "text": "models a little bit more likely to make up things or hallucinate we're going to come back to hallucinations at the end",
    "start": "840880",
    "end": "847160"
  },
  {
    "text": "of this talk so interestingly these Dakota based models were not really initially",
    "start": "847160",
    "end": "853120"
  },
  {
    "text": "interesting because of their potential to generate text but because it solved a really important problem remember when I",
    "start": "853120",
    "end": "859480"
  },
  {
    "text": "was talking about cnns and I was saying that they were really interesting because they suddenly allowed researchers to scale up the amount of",
    "start": "859480",
    "end": "866800"
  },
  {
    "text": "data that they could UT into the models well gpts did the same thing with text",
    "start": "866800",
    "end": "872199"
  },
  {
    "text": "based models you know machine learning often has this constraint that you do need to manually prepared data in some",
    "start": "872199",
    "end": "878360"
  },
  {
    "text": "way it might be pairing up things it might be adding labels or might be hand annotating features and what GPT models",
    "start": "878360",
    "end": "886560"
  },
  {
    "text": "allow you to do is have this readymade data set where you can just cut sentences in half at one point and have",
    "start": "886560",
    "end": "893240"
  },
  {
    "text": "a model that's basically just trying to predict the next word in the sentence this scales really easily",
    "start": "893240",
    "end": "901040"
  },
  {
    "text": "so this was the basis of the GPT models and in conjunction with that scalable Transformer architecture is the secret",
    "start": "901320",
    "end": "908440"
  },
  {
    "text": "of how these models have been able to get so big these models roughly work by stacking the amount of decoda units they",
    "start": "908440",
    "end": "915160"
  },
  {
    "text": "have and this increases the size of the models which will'll often hear described by the number of parameters",
    "start": "915160",
    "end": "920959"
  },
  {
    "text": "and roughly you can say the more parameters that a model has the more powerful it is the more sophisticated",
    "start": "920959",
    "end": "927440"
  },
  {
    "text": "its predictions are so the first GPT was 120 million",
    "start": "927440",
    "end": "932920"
  },
  {
    "text": "parameters the second was 13 times that size at 1.5 billion parameters and",
    "start": "932920",
    "end": "938040"
  },
  {
    "text": "they've just kept growing and growing up to the current GPT 4 which is estimated to be 1 trillion parameters although",
    "start": "938040",
    "end": "945440"
  },
  {
    "text": "open AI have been pretty cagy about these numbers so these models have grown over",
    "start": "945440",
    "end": "951600"
  },
  {
    "text": "the successive generations to get better and better at doing a range of natural language tasks and interestingly aart",
    "start": "951600",
    "end": "959040"
  },
  {
    "text": "from the first one gpt1 they were not explicitly trained to do this but they",
    "start": "959040",
    "end": "964160"
  },
  {
    "text": "can be taught how to do this through very carefully giving them instructions",
    "start": "964160",
    "end": "969560"
  },
  {
    "text": "what's now currently known as prompt engineering what we used to call metal learning back in you know the days when",
    "start": "969560",
    "end": "974959"
  },
  {
    "text": "this was just in the research domain so we can get a sense of how these models have evolved based on how",
    "start": "974959",
    "end": "982199"
  },
  {
    "text": "they respond to the same prompt so let's take this complete the following sentence Belgium is apologize of there",
    "start": "982199",
    "end": "989079"
  },
  {
    "text": "any belgians in the audience I chose Belgian because I know you guys have a good sense of humor and you can take a",
    "start": "989079",
    "end": "994639"
  },
  {
    "text": "joke so gpt1 is really good at producing let's say grammatically correct",
    "start": "994639",
    "end": "1001040"
  },
  {
    "text": "sentences but it doesn't really have a sense of content so this is what it came up with for our",
    "start": "1001040",
    "end": "1008639"
  },
  {
    "text": "prompt I've been to Belgium it's it's not true gpt2 is a little bit more",
    "start": "1008639",
    "end": "1015000"
  },
  {
    "text": "sophisticated than gpt1 but it still doesn't really have this sense of",
    "start": "1015000",
    "end": "1020040"
  },
  {
    "text": "context or knowledge so this is what it managed to come up with for the prompt so gpt3 was the model where these",
    "start": "1020040",
    "end": "1029079"
  },
  {
    "text": "models really started showing you know what's now being called parametric knowledge they started encoding more",
    "start": "1029079",
    "end": "1035160"
  },
  {
    "text": "information about the text that they were being trained on so this is what we got for gpt3 it makes a lot of sense it",
    "start": "1035160",
    "end": "1042120"
  },
  {
    "text": "contains correct factual information and then when I threw this into chat GPT it gave me a whole bloody",
    "start": "1042120",
    "end": "1049520"
  },
  {
    "text": "essay it just kind of kept going on and on in that vein I think everyone here knows how verose that model",
    "start": "1049520",
    "end": "1055520"
  },
  {
    "text": "is so everything seems great right we just need to keep building bigger and bigger GPT models and eventually we're",
    "start": "1055520",
    "end": "1062280"
  },
  {
    "text": "going to converge on the model that can do perfectly any natural language task that we want well not so fast after gpt3",
    "start": "1062280",
    "end": "1071760"
  },
  {
    "text": "was released researchers found that the bigger these models get the more likely",
    "start": "1071760",
    "end": "1077240"
  },
  {
    "text": "they are to give biased or toxic outputs or to hallucinate so in an attempt to mitigate",
    "start": "1077240",
    "end": "1084159"
  },
  {
    "text": "this after the development of gpt3 researchers at open AI created what then became chat GPT it was originally called",
    "start": "1084159",
    "end": "1091240"
  },
  {
    "text": "instruct GPT so the way it works is like so a bunch of prompts were generated",
    "start": "1091240",
    "end": "1096679"
  },
  {
    "text": "such as this one about writing a high coup about sausages and then a group of people were",
    "start": "1096679",
    "end": "1101919"
  },
  {
    "text": "recruited in order to write sort of Exemplar answers for these",
    "start": "1101919",
    "end": "1107240"
  },
  {
    "text": "prompts and this was repeated for a whole range of prompts ac across a whole",
    "start": "1107240",
    "end": "1112679"
  },
  {
    "text": "scope of different tasks so you end up with a whole data set containing these Exemplar answers to given",
    "start": "1112679",
    "end": "1119799"
  },
  {
    "text": "prompts so you might be thinking wait the problem that you said uh GPT solved",
    "start": "1119799",
    "end": "1126919"
  },
  {
    "text": "is that it helped us get these really large data sets we didn't need to manually create data anymore so if we're",
    "start": "1126919",
    "end": "1133159"
  },
  {
    "text": "manually creating data to make chat GPT how is it bigger than gpt3",
    "start": "1133159",
    "end": "1139840"
  },
  {
    "text": "well the trick is a process called fine-tuning fine-tuning is where you",
    "start": "1139840",
    "end": "1144960"
  },
  {
    "text": "take a data set that's been trained on General data and you use a smaller data set that's focused on a particular task",
    "start": "1144960",
    "end": "1151919"
  },
  {
    "text": "or domain and you use that to refine the outputs this General um model will give",
    "start": "1151919",
    "end": "1157360"
  },
  {
    "text": "you so in the case of say co-pilot that was originally based on a model called",
    "start": "1157360",
    "end": "1163960"
  },
  {
    "text": "codex which is a fine-tuning of gpt3 using Code samples and in the case of chat GPT we have a fine-tune version of",
    "start": "1163960",
    "end": "1172400"
  },
  {
    "text": "GPT 3.5 with 355 billion parameters and it's been basically fine-tuned to give",
    "start": "1172400",
    "end": "1178760"
  },
  {
    "text": "us more truthful less biased outputs but the real secret to chat GPT",
    "start": "1178760",
    "end": "1184960"
  },
  {
    "text": "success comes in The Next Step so we have our fine chune version of GPT",
    "start": "1184960",
    "end": "1190360"
  },
  {
    "text": "3.5 and what they then did is they took one prompt and they fed it into the model four times they then took a second",
    "start": "1190360",
    "end": "1197559"
  },
  {
    "text": "group of people and they got them to rate each of these outputs taking into account how truthful how high quality",
    "start": "1197559",
    "end": "1205440"
  },
  {
    "text": "how unbiased each of the outputs were and the higher the score obviously the better the",
    "start": "1205440",
    "end": "1210960"
  },
  {
    "text": "answer they then used these ratings to train a second model so the model takes",
    "start": "1210960",
    "end": "1216720"
  },
  {
    "text": "the output of the GPT model and it tries to predict the score that a particular",
    "start": "1216720",
    "end": "1223080"
  },
  {
    "text": "uh Rader would give it and then all of these components are glued together to give us ch G PT so you",
    "start": "1223080",
    "end": "1230360"
  },
  {
    "text": "feed a prom into chat GPT the fine-tune GPT 3.5 or 4 model in chat GPT 4 takes",
    "start": "1230360",
    "end": "1238799"
  },
  {
    "text": "in that and it gives you an output that output is then fed into the rer model",
    "start": "1238799",
    "end": "1244559"
  },
  {
    "text": "which then tries to predict which score the Raiders would give it and then that is fed back into the GPT model which is",
    "start": "1244559",
    "end": "1252960"
  },
  {
    "text": "then kind of slowly changed over time to be more in line with good ratings and",
    "start": "1252960",
    "end": "1260960"
  },
  {
    "text": "less in line with bad ratings and this is a process called reinforcement learning from Human feedback you may",
    "start": "1260960",
    "end": "1266520"
  },
  {
    "text": "have heard this term and the idea is that over time these models will kind of move to create less biased more truthful",
    "start": "1266520",
    "end": "1275000"
  },
  {
    "text": "outputs so if you ever wondered what that little thumbs up and down is next to your chat gbt output it's basically",
    "start": "1275000",
    "end": "1281640"
  },
  {
    "text": "helping to refine these models so having covered the context",
    "start": "1281640",
    "end": "1287360"
  },
  {
    "text": "let's jump into one of the biggest topics when we're talking about the hype around these models especially the GPT",
    "start": "1287360",
    "end": "1293480"
  },
  {
    "text": "models are they actually intelligent or are they just overblown autocomplete",
    "start": "1293480",
    "end": "1300360"
  },
  {
    "text": "systems so in March of 2023 so almost a year ago along with the release of GPT 4",
    "start": "1300360",
    "end": "1308640"
  },
  {
    "text": "a group of researchers at Microsoft released this paper where they claimed that GPT 4 was showing signs or Sparks",
    "start": "1308640",
    "end": "1316640"
  },
  {
    "text": "of artificial general intelligence so the way that they assessed intelligence is they got a consensus consensus",
    "start": "1316640",
    "end": "1322880"
  },
  {
    "text": "definition of intelligence written by a group of psychologists in the '90s and this claimed that intelligence can be",
    "start": "1322880",
    "end": "1328799"
  },
  {
    "text": "demonstrated by the ability to reason to plan to solve problems to think",
    "start": "1328799",
    "end": "1334679"
  },
  {
    "text": "abstractly to comprehend complex ideas and to learn quickly and from experience and onto this they added a",
    "start": "1334679",
    "end": "1342000"
  },
  {
    "text": "couple of their own categories including theory of mind now theory of mind is the ability to understand that others have",
    "start": "1342000",
    "end": "1348240"
  },
  {
    "text": "different States mental states that are you know sorry have mental states that are different from your own and they",
    "start": "1348240",
    "end": "1354840"
  },
  {
    "text": "assess this using a variety of ad hoc and some established methods now the first thing I want to",
    "start": "1354840",
    "end": "1361360"
  },
  {
    "text": "say about this paper is it was written by some very impressive groups uh sorry very impressive researchers and they",
    "start": "1361360",
    "end": "1368000"
  },
  {
    "text": "come from backgrounds like Computer Sciences engineering mathematics and",
    "start": "1368000",
    "end": "1374600"
  },
  {
    "text": "physics but there's not a single psychologist on that author list so during my PhD in Psychology I learned",
    "start": "1374600",
    "end": "1382480"
  },
  {
    "text": "a lot about assessing intelligence in fact I learned how to administer intelligence tests and I'd never heard",
    "start": "1382480",
    "end": "1388320"
  },
  {
    "text": "of the definition that they're using to assess intelligence no psychologist I know is using it so we're already on",
    "start": "1388320",
    "end": "1395640"
  },
  {
    "text": "Shaky Ground but before we get into how we might more robustly measure intelligence and artificial systems",
    "start": "1395640",
    "end": "1402120"
  },
  {
    "text": "let's look at a couple of things that they showed in the paper so let's start with things that GP",
    "start": "1402120",
    "end": "1408520"
  },
  {
    "text": "T4 was found to be good at so one of these things was coding so I'm sure those of you who have",
    "start": "1408520",
    "end": "1415880"
  },
  {
    "text": "had experience using chat GPT for coding tasks or have used co-pilot will know",
    "start": "1415880",
    "end": "1421600"
  },
  {
    "text": "that these models are very good at solving problems with code so one of the",
    "start": "1421600",
    "end": "1426919"
  },
  {
    "text": "examples that the authors presented in the paper was the following so they asked gp4 to write the following 3D game",
    "start": "1426919",
    "end": "1434080"
  },
  {
    "text": "in HTML with JavaScript so there are three spheres the player controls their sphere with arrow keys there's an enemy",
    "start": "1434080",
    "end": "1441279"
  },
  {
    "text": "sphere that's trying to capture the player there's a Defender sphere trying to stop the enemy and there are",
    "start": "1441279",
    "end": "1446960"
  },
  {
    "text": "obstacles moving randomly and spawning randomly this is what GPT 4 came up with",
    "start": "1446960",
    "end": "1452240"
  },
  {
    "text": "you can see clearly they're in dark blue the player you can see the enemy sphere there in red and you can see the",
    "start": "1452240",
    "end": "1457960"
  },
  {
    "text": "defender sphere there in teal and then you've got your obstacles moving randomly it's not perfect it's not",
    "start": "1457960",
    "end": "1463640"
  },
  {
    "text": "exactly what we asked for and frankly it's hideous but it's really impressive",
    "start": "1463640",
    "end": "1468679"
  },
  {
    "text": "for a piece of code that was written without human intervention another thing that the",
    "start": "1468679",
    "end": "1474799"
  },
  {
    "text": "researchers found that GPT 4 was really good at is problems that involve spatial or compositional understanding and I was",
    "start": "1474799",
    "end": "1480840"
  },
  {
    "text": "briefly talking about this at the beginning when I was talking about my cover image so I generated all of the",
    "start": "1480840",
    "end": "1486880"
  },
  {
    "text": "kind of title images for this talk with mid journey and I thought this was going to be really fast I was like yeah this",
    "start": "1486880",
    "end": "1493760"
  },
  {
    "text": "will be like an afternoon took me two weeks on and off because I got so frustrated",
    "start": "1493760",
    "end": "1498919"
  },
  {
    "text": "because mid Journey really just does not understand Concepts like handing",
    "start": "1498919",
    "end": "1504480"
  },
  {
    "text": "surrounding under over sitting on these sort of compositional concepts are really difficult for these you know",
    "start": "1504480",
    "end": "1511200"
  },
  {
    "text": "diffusion models these image to text sorry text to image models but gp4 is",
    "start": "1511200",
    "end": "1516600"
  },
  {
    "text": "actually quite good at this so the researchers asked gp4 for an SVG formatted image of a screenshot of a 3D",
    "start": "1516600",
    "end": "1524159"
  },
  {
    "text": "citybuilding game showing a Terrain with a river from left to right a desert with a pyramid below the river a city with",
    "start": "1524159",
    "end": "1531159"
  },
  {
    "text": "many high-rise buildings above the river and at the bottom there are some buttons",
    "start": "1531159",
    "end": "1536559"
  },
  {
    "text": "this is what it came up with again hideous it is SVG but it's given us exactly what we asked for you can see",
    "start": "1536559",
    "end": "1543240"
  },
  {
    "text": "your River left to right high-rise buildings pyramid and buttons gave exactly what we asked for in contrast",
    "start": "1543240",
    "end": "1550760"
  },
  {
    "text": "when the research has chucked this same prompt into stable diffusion one of the um text image um models this is what it",
    "start": "1550760",
    "end": "1558799"
  },
  {
    "text": "came up with ostensibly it looks better but it hasn't given us at all what we",
    "start": "1558799",
    "end": "1563919"
  },
  {
    "text": "asked for in addition it hallucinated a few different features like this Maze",
    "start": "1563919",
    "end": "1569120"
  },
  {
    "text": "and the HUD now let's look at some things that GPT for is not so good at and this was",
    "start": "1569120",
    "end": "1575799"
  },
  {
    "text": "particularly clear with mathematics so let's have a look at how",
    "start": "1575799",
    "end": "1580960"
  },
  {
    "text": "it went with a relatively simple arithmetic problem which requires a little bit of forward planning so in the",
    "start": "1580960",
    "end": "1586919"
  },
  {
    "text": "identity 7 time 4 + 8 * 8 = 92 can you modify exactly one integer on the left",
    "start": "1586919",
    "end": "1593520"
  },
  {
    "text": "hand side of the equation so that the right hand side becomes 10 106 so let's have a look at how we would",
    "start": "1593520",
    "end": "1600799"
  },
  {
    "text": "solve this in order to get to 106 from 92 we have to add 14 so that means we",
    "start": "1600799",
    "end": "1607440"
  },
  {
    "text": "have to add 14 to both sides we've been asked to only modify one integer so it means we need to look for factors of 14",
    "start": "1607440",
    "end": "1614760"
  },
  {
    "text": "and the most obvious one is 7 7 * 2 is 14 means we add 7 * 2 to this equation",
    "start": "1614760",
    "end": "1621720"
  },
  {
    "text": "and we go from this four to a six so how did GPT",
    "start": "1621720",
    "end": "1626919"
  },
  {
    "text": "foro well from the start it gives us the wrong answer it tells us that we need to",
    "start": "1626919",
    "end": "1631960"
  },
  {
    "text": "change the seven to a 9 and then it tries to explain its reasoning it tells",
    "start": "1631960",
    "end": "1637600"
  },
  {
    "text": "us that 9 * 4 is 36 which is correct 8 * 8 is 64 also correct but these add to",
    "start": "1637600",
    "end": "1644000"
  },
  {
    "text": "100 and it confidently tells us these add to 106 CL GPT",
    "start": "1644000",
    "end": "1649799"
  },
  {
    "text": "models and the researchers assessed the mathematical abilities of GPT 4 with a whole bunch of problems these ranged",
    "start": "1649799",
    "end": "1656440"
  },
  {
    "text": "from pretty simple arithmetic problems simpler than this one up to more complex problems like proofs and consistently it",
    "start": "1656440",
    "end": "1663559"
  },
  {
    "text": "got confused or got it wrong so looking at all of the evidence",
    "start": "1663559",
    "end": "1668960"
  },
  {
    "text": "that the research has gathered what did they conclude and obviously this is just a snippet of it paper something like 150",
    "start": "1668960",
    "end": "1675200"
  },
  {
    "text": "pages long so I'm really just giving you a extract but they believed based on the things",
    "start": "1675200",
    "end": "1680880"
  },
  {
    "text": "that gp4 had demonstrated it was showing some of the signs of intelligence from their definition it was showing some",
    "start": "1680880",
    "end": "1687080"
  },
  {
    "text": "evidence of reasoning solving problems thinking abstractly and comprehending complex ideas but it was lacking things",
    "start": "1687080",
    "end": "1693640"
  },
  {
    "text": "like planning or learning from experience and hence their conclusion that it was showing signs or Sparks of",
    "start": "1693640",
    "end": "1699960"
  },
  {
    "text": "artificial general intelligence but is it really can we point to behaviors that",
    "start": "1699960",
    "end": "1707600"
  },
  {
    "text": "mimic humanlike skill in some area and say that this must be indicative of",
    "start": "1707600",
    "end": "1714559"
  },
  {
    "text": "intelligence now I know what some of you are already thinking every single time",
    "start": "1714559",
    "end": "1719600"
  },
  {
    "text": "we have some sort of algorithm or system that shows impressive performance you have people hand waving it away this has",
    "start": "1719600",
    "end": "1727399"
  },
  {
    "text": "actually been a complaint since the time of Deep Blue deep blue was the chess algorithm that beat Gary Kasparov in",
    "start": "1727399",
    "end": "1733679"
  },
  {
    "text": "1997 this was quite revolutionary at the time but when IBM released the details of how deep blue beat Kasparov people",
    "start": "1733679",
    "end": "1741200"
  },
  {
    "text": "ceased to think it was an intelligence this led to quotes like the following when we know how a machine does",
    "start": "1741200",
    "end": "1747159"
  },
  {
    "text": "something intelligent it ceases to be regarded as intelligent if I beat the world's chess champion I'd be regarded",
    "start": "1747159",
    "end": "1754200"
  },
  {
    "text": "as highly bright so if we have algorithms at the moment that are blowing past previous goalpost and",
    "start": "1754200",
    "end": "1760799"
  },
  {
    "text": "intelligence that we've set such as say the touring test can we really say that we haven't developed an intelligent",
    "start": "1760799",
    "end": "1767720"
  },
  {
    "text": "system the problem with this thinking is that it confuses the output of an AI system",
    "start": "1767720",
    "end": "1775360"
  },
  {
    "text": "with the mechanism that took to get there in humans we can do these skill-based assessments of intelligence",
    "start": "1775360",
    "end": "1781760"
  },
  {
    "text": "because this is how it works in humans a human demonstrating impressive performance or learning something",
    "start": "1781760",
    "end": "1788080"
  },
  {
    "text": "difficult quickly is indicative of a raw underlying ability in AI or let's call them what",
    "start": "1788080",
    "end": "1795399"
  },
  {
    "text": "they are machine learning models it doesn't work that way if they can take shortcuts to get to their training goal",
    "start": "1795399",
    "end": "1801960"
  },
  {
    "text": "they absolutely will the mistake is thinking that the development of an",
    "start": "1801960",
    "end": "1807080"
  },
  {
    "text": "intelligence is a requirement for them to get to that goal it absolutely is not",
    "start": "1807080",
    "end": "1812840"
  },
  {
    "text": "and this is such a common effect it has a name it's called the kaggle effect those of you who have messed around in",
    "start": "1812840",
    "end": "1818360"
  },
  {
    "text": "machine learning you will know kaggle kaggle is a very famous website which hosts machine learning competitions so",
    "start": "1818360",
    "end": "1824799"
  },
  {
    "text": "people will compete to get the best model performance on some sort of task",
    "start": "1824799",
    "end": "1829919"
  },
  {
    "text": "classification regression whatever and the solutions that tend to win tend to",
    "start": "1829919",
    "end": "1835559"
  },
  {
    "text": "be so good at solving that problem they almost seem to demonstrate",
    "start": "1835559",
    "end": "1840760"
  },
  {
    "text": "intelligence but as soon as you try to get them to do something that's a bit outside of what they were trained on",
    "start": "1840760",
    "end": "1846440"
  },
  {
    "text": "they fail they show brittleness what we're looking for in intelligence system instead is the",
    "start": "1846440",
    "end": "1853600"
  },
  {
    "text": "ability of that system to generalize to be able to solve problems that it hasn't necessarily seen before and in order to",
    "start": "1853600",
    "end": "1861159"
  },
  {
    "text": "make this a bit easier to work with let's break it down into a hierarchy of generalization we start with no",
    "start": "1861159",
    "end": "1868279"
  },
  {
    "text": "generalization this includes systems which know all of the possible outcomes in advance such as a program using",
    "start": "1868279",
    "end": "1875240"
  },
  {
    "text": "configurations of tic-tac-toe in order to be able to play that game the second is local generalization",
    "start": "1875240",
    "end": "1883080"
  },
  {
    "text": "this is where a model can make inferences on things that it hasn't seen before but if they're twoo different to",
    "start": "1883080",
    "end": "1888760"
  },
  {
    "text": "what it was trained on it cannot the kaggle effect broad generalization reflects the",
    "start": "1888760",
    "end": "1894960"
  },
  {
    "text": "ability to act independently or complete some broad activity domain so a famous",
    "start": "1894960",
    "end": "1900559"
  },
  {
    "text": "example of this is Steve wnc's coffee cup test wnc of Apple Fame he posits",
    "start": "1900559",
    "end": "1906519"
  },
  {
    "text": "that if you have a system that can go into a kitchen and complete all of the steps to make a cup of coffee without",
    "start": "1906519",
    "end": "1911679"
  },
  {
    "text": "assistance it's demonstrating some sort of broad generalization and fully automatic self-driving cars are also",
    "start": "1911679",
    "end": "1919039"
  },
  {
    "text": "part of this level then we have extreme generalization this is essentially human",
    "start": "1919039",
    "end": "1924360"
  },
  {
    "text": "level intelligence what you have is a system that can solve problems that maybe only Shar some vague commonalities",
    "start": "1924360",
    "end": "1930679"
  },
  {
    "text": "with things that it's seen before and it can do that across a scope of tasks that would be relevant to",
    "start": "1930679",
    "end": "1936399"
  },
  {
    "text": "humans so at this stage you might be thinking you're spending a lot of time talking about human like abilities we're",
    "start": "1936399",
    "end": "1943519"
  },
  {
    "text": "talking about artificial systems don't we want them to go beyond what we can do to be better than us and that leads to",
    "start": "1943519",
    "end": "1950399"
  },
  {
    "text": "the top level universality and this includes the capability of an artificial system to",
    "start": "1950399",
    "end": "1956279"
  },
  {
    "text": "complete tasks that really have no relevance to",
    "start": "1956279",
    "end": "1961519"
  },
  {
    "text": "humans universality however should be dismissed as at least an initial goal",
    "start": "1961519",
    "end": "1967600"
  },
  {
    "text": "for a couple of reasons first I'm assuming most of you are developers and you know for a problem to be useful it",
    "start": "1967600",
    "end": "1974399"
  },
  {
    "text": "has to have a scope at the moment what we seem to be using machine learning models or AI",
    "start": "1974399",
    "end": "1981559"
  },
  {
    "text": "systems for are problems that are completely relevant to humans after all I told you that these models came from",
    "start": "1981559",
    "end": "1988559"
  },
  {
    "text": "trying to automate problems within computer vision and natural language processing the second is I'm not really",
    "start": "1988559",
    "end": "1995320"
  },
  {
    "text": "convinced that we've saw broad generalization yet we keep seeming to have these breakthroughs with self-driving cars and then they keep",
    "start": "1995320",
    "end": "2001600"
  },
  {
    "text": "being taken off the road I think until we can get to this level we should lower our sights a little bit",
    "start": "2001600",
    "end": "2008760"
  },
  {
    "text": "so if we come back to intelligence we can actually line this up with the definition of intelligence in",
    "start": "2008760",
    "end": "2015039"
  },
  {
    "text": "humans the widely accepted conceptualization of how intelligence Works in humans is that we have a",
    "start": "2015039",
    "end": "2021240"
  },
  {
    "text": "general ability to learn called G or general intelligence we use our general",
    "start": "2021240",
    "end": "2026799"
  },
  {
    "text": "intelligence to be able to complete broad or develop broad abilities such as being able to drive or cook and within",
    "start": "2026799",
    "end": "2033720"
  },
  {
    "text": "each broad ability we have tasks that we can complete such as being able to whisk eggs or use an",
    "start": "2033720",
    "end": "2040279"
  },
  {
    "text": "indicator and what you can see is that this definition of intelligence in humans actually lines up quite nicely",
    "start": "2040279",
    "end": "2047200"
  },
  {
    "text": "with our hierarchy of generalization and artificial systems we can line up extreme generalization with general",
    "start": "2047200",
    "end": "2052960"
  },
  {
    "text": "intelligence broad generalization with broad cognitive abilities and local generalization or even no generalization",
    "start": "2052960",
    "end": "2059760"
  },
  {
    "text": "with task specific skills so given that the measurement of intelligence in humans is quite an",
    "start": "2059760",
    "end": "2066720"
  },
  {
    "text": "established field it seems quite logical that we can take some lessons from how we measure this in humans and apply it",
    "start": "2066720",
    "end": "2074158"
  },
  {
    "text": "to artificial systems quick caveat before I go on with this I'm a psychologist I know that the field of",
    "start": "2074159",
    "end": "2081040"
  },
  {
    "text": "intelligence and its measurement is problematic I don't want to say it's a silver bullet to just apply everything",
    "start": "2081040",
    "end": "2086760"
  },
  {
    "text": "that we assume about intelligence in humans to artificial systems what I'm saying is thinking this way can help us",
    "start": "2086760",
    "end": "2093560"
  },
  {
    "text": "break out of focusing on this kind of seductive quite alluring idea of looking at skill-based assessments of",
    "start": "2093560",
    "end": "2099800"
  },
  {
    "text": "intelligence in machines and focus more on trying to get at the true generalizability of these systems so",
    "start": "2099800",
    "end": "2106440"
  },
  {
    "text": "let's have a look at how we might do this fris Chalet is a very well-known",
    "start": "2106440",
    "end": "2111520"
  },
  {
    "text": "researcher in AI he works at Google if any of you have messed around with machine learning at all you might know",
    "start": "2111520",
    "end": "2117200"
  },
  {
    "text": "the Caris package he wrote that he proposed a method of measuring intelligence in artificial systems so he",
    "start": "2117200",
    "end": "2125040"
  },
  {
    "text": "defines it as following an artificial system should demonstrate the ability to complete a task using a skill program",
    "start": "2125040",
    "end": "2132920"
  },
  {
    "text": "which was developed in order to create that to solve that task which was in",
    "start": "2132920",
    "end": "2138160"
  },
  {
    "text": "turn created by a humanlike intelligence system and I hope again you can see that",
    "start": "2138160",
    "end": "2143359"
  },
  {
    "text": "these line up with G general intelligence broad abilities and task specific skills in humans so of course",
    "start": "2143359",
    "end": "2151200"
  },
  {
    "text": "there are some feedback mechanisms within this system skill programs get better over time as they are exposed",
    "start": "2151200",
    "end": "2157640"
  },
  {
    "text": "exposed to trying to solve particular tasks within their domain and the",
    "start": "2157640",
    "end": "2163079"
  },
  {
    "text": "intelligent like human system itself can also learn as it's exposed to more and more",
    "start": "2163079",
    "end": "2168400"
  },
  {
    "text": "tasks Chalet also argues that if we're talking about a humanlike intelligence",
    "start": "2168400",
    "end": "2173599"
  },
  {
    "text": "system we should give it the ability to have the priors that humans are born",
    "start": "2173599",
    "end": "2178960"
  },
  {
    "text": "with so humans are kind of a supposed by developmental psychologist to be born",
    "start": "2178960",
    "end": "2184880"
  },
  {
    "text": "with the ability to do elementary geometry in physics arithmetic and understand that others have",
    "start": "2184880",
    "end": "2191240"
  },
  {
    "text": "agency skill programs of course can evolve as they are exposed to more and",
    "start": "2191240",
    "end": "2196640"
  },
  {
    "text": "more tasks that are within their domain and tasks themselves can differ based on their generalization difficulty",
    "start": "2196640",
    "end": "2203760"
  },
  {
    "text": "this is basically how much the system has to generalize in order to solve that",
    "start": "2203760",
    "end": "2209359"
  },
  {
    "text": "problem in other words how different it is from things that it's been directly exposed to before so putting this all",
    "start": "2209359",
    "end": "2216160"
  },
  {
    "text": "together we can actually come up with a formula for measuring intelligence and artificial systems and Chalet says that",
    "start": "2216160",
    "end": "2223680"
  },
  {
    "text": "it could work like something like the following so for one specific task being",
    "start": "2223680",
    "end": "2230000"
  },
  {
    "text": "solved by an artificial system in one specific way we can Define how difficult",
    "start": "2230000",
    "end": "2235240"
  },
  {
    "text": "it's going to be for that system to solve it as the generalization difficulty divided by how close it is to",
    "start": "2235240",
    "end": "2241680"
  },
  {
    "text": "the system priors and things that the system has had experience with before so let me break that down a bit basically",
    "start": "2241680",
    "end": "2248240"
  },
  {
    "text": "what we're saying is that when an artificial system comes across a task that it wants to solve in a particular",
    "start": "2248240",
    "end": "2254839"
  },
  {
    "text": "way it's going to be a lot harder for the system to solve it if it hasn't really seen something like that before",
    "start": "2254839",
    "end": "2261440"
  },
  {
    "text": "and it's going to be easier if it has seen something like that before now of course there are generally",
    "start": "2261440",
    "end": "2267400"
  },
  {
    "text": "multiple ways of solving a problem so what we can do is we can say the difficulty of a system of solving a",
    "start": "2267400",
    "end": "2274920"
  },
  {
    "text": "particular task is given is average across all the ways of approaching that",
    "start": "2274920",
    "end": "2280319"
  },
  {
    "text": "task for that system shal also says that we should add a subjective component how",
    "start": "2280319",
    "end": "2286040"
  },
  {
    "text": "valuable or impressive it is that that system can solve that task so you know it's a lot more impressive to have a",
    "start": "2286040",
    "end": "2291760"
  },
  {
    "text": "system that can do brain surgery independently versus you know being able to generate a list of pseudo random",
    "start": "2291760",
    "end": "2298040"
  },
  {
    "text": "numbers so this is just for one task what we then need to do is Define a",
    "start": "2298040",
    "end": "2303920"
  },
  {
    "text": "scope of tasks that would be relevant to what we want this system to be ble to do if we wanted to be humanlike we need to",
    "start": "2303920",
    "end": "2310359"
  },
  {
    "text": "take a sampling of tasks that are relevant to humans so what we can then do is average it the ability of the",
    "start": "2310359",
    "end": "2317880"
  },
  {
    "text": "system to solve those tasks across all the tasks in that scope and what this",
    "start": "2317880",
    "end": "2323280"
  },
  {
    "text": "does is it gives us a measurement of the skill acquisition efficiency of that system across a range of relevant tasks",
    "start": "2323280",
    "end": "2330400"
  },
  {
    "text": "or breaking it down to make it less jistic the generalizability of that system or if you like it's artificial",
    "start": "2330400",
    "end": "2336920"
  },
  {
    "text": "general int intelligence Chalet went one step further and he proposed a potential",
    "start": "2336920",
    "end": "2343000"
  },
  {
    "text": "measurement for artificial general intelligence based on his definition called The Arc or the abstraction and",
    "start": "2343000",
    "end": "2348800"
  },
  {
    "text": "reasoning Corpus the way that it works is like the following it's made up of a",
    "start": "2348800",
    "end": "2354040"
  },
  {
    "text": "100 problems which have the following format basically there are three",
    "start": "2354040",
    "end": "2359680"
  },
  {
    "text": "examples which set out some sort of rule in the case of this problem what we have is all of the black squares that are",
    "start": "2359680",
    "end": "2366560"
  },
  {
    "text": "completely encased green must be changed to Yellow so the test taker must derrive",
    "start": "2366560",
    "end": "2371640"
  },
  {
    "text": "this Rule and then apply it to a final example and you can see this one is",
    "start": "2371640",
    "end": "2376680"
  },
  {
    "text": "correct because all are yellow this one's wrong because one is Pink So Chalet says that this is likely to be a",
    "start": "2376680",
    "end": "2383760"
  },
  {
    "text": "better test than these skill-based assessments of artificial general intelligence for a couple of reasons",
    "start": "2383760",
    "end": "2389720"
  },
  {
    "text": "first there are really small number of examples for each of the problems if you know anything about machine learning",
    "start": "2389720",
    "end": "2395000"
  },
  {
    "text": "you'll know that these systems work by kind of like root forcing patterns just",
    "start": "2395000",
    "end": "2400680"
  },
  {
    "text": "by being exposed to hundreds thousands maybe millions of examples this is not enough data for them to do that secondly",
    "start": "2400680",
    "end": "2408040"
  },
  {
    "text": "Chalet has all 100 of these problems under lock and key so there's no way that they can be included in the training data and for the model to",
    "start": "2408040",
    "end": "2415920"
  },
  {
    "text": "cheat so how is performance on The Arc to date well there's an annual whoops go",
    "start": "2415920",
    "end": "2423079"
  },
  {
    "text": "there's an annual competition called the arthon it's a bit of a daggy name but you know is what it is and basically",
    "start": "2423079",
    "end": "2430160"
  },
  {
    "text": "developers of the algorithm that can come up with a solution that solves all 100 of these problems will receive",
    "start": "2430160",
    "end": "2436079"
  },
  {
    "text": "60,000 there you go good incentive for you to get into machine learning so the",
    "start": "2436079",
    "end": "2442839"
  },
  {
    "text": "kind of latest iteration just ended in December the winning uh Alo the leaderboard team came up with a solution",
    "start": "2442839",
    "end": "2450040"
  },
  {
    "text": "that managed to solve 30% of them so 30 out of 100 problems and humans in uh",
    "start": "2450040",
    "end": "2456440"
  },
  {
    "text": "kind of comparison can solve 80% without much trouble it's actually kind of",
    "start": "2456440",
    "end": "2461560"
  },
  {
    "text": "unfair that the winning team needs to solve 100% but anyway there you go now when I first put this talk together the",
    "start": "2461560",
    "end": "2468960"
  },
  {
    "text": "winning entry actually wasn't a large language based model approach so I kind of used to smugly say you know large",
    "start": "2468960",
    "end": "2474920"
  },
  {
    "text": "language models are not coming anywhere close to solving this the current leader is large language based large language",
    "start": "2474920",
    "end": "2481319"
  },
  {
    "text": "model based so kind of don't know what to make of that but let's say 30 versus 80% still a big Gap but watch this",
    "start": "2481319",
    "end": "2490000"
  },
  {
    "text": "space so beyond measurement and definition issues there were a number of other problems with the claims of AGI in",
    "start": "2490000",
    "end": "2497160"
  },
  {
    "text": "large language models so let's come back to theory of Mind theory of mind to jog in memory is the ability to understand",
    "start": "2497160",
    "end": "2503960"
  },
  {
    "text": "that others have mental States or beliefs that are different from your own and the reason that the researchers who",
    "start": "2503960",
    "end": "2509920"
  },
  {
    "text": "did the Sparks paper wanted to include this is I was taught at University this is a uniquely human trait it's not a",
    "start": "2509920",
    "end": "2516560"
  },
  {
    "text": "trait of intell elligence but it is considered to be uniquely human so the researchers who put this",
    "start": "2516560",
    "end": "2522680"
  },
  {
    "text": "paper together were very satisfied based on the testing that they did that GPT for was showing theory of mind but",
    "start": "2522680",
    "end": "2530000"
  },
  {
    "text": "another natural language processing researcher came out and challenged this so what she did is she took vignettes",
    "start": "2530000",
    "end": "2535520"
  },
  {
    "text": "that are usually used to assess theory of mind she tested GPT 4 and chat GPT",
    "start": "2535520",
    "end": "2540680"
  },
  {
    "text": "using them and then she tweaked them slightly so that you know they're kind of weird but they still assess theory of",
    "start": "2540680",
    "end": "2546720"
  },
  {
    "text": "mine so let's have a look at one of her examples I placed a key on the third key",
    "start": "2546720",
    "end": "2551960"
  },
  {
    "text": "hook I then go on a vacation for the weekend my boyfriend used the key during the weekend and placed it back on the",
    "start": "2551960",
    "end": "2558480"
  },
  {
    "text": "fourth key hook when I come back where am I expecting the key to be where's the",
    "start": "2558480",
    "end": "2563800"
  },
  {
    "text": "key third key hook yeah that was my touring test come [Music]",
    "start": "2563800",
    "end": "2569760"
  },
  {
    "text": "on so when she passed this through chat GPT and GPT 4 they got them correct",
    "start": "2569760",
    "end": "2577280"
  },
  {
    "text": "but then she tweaked it slightly she made it a bit weird instead my cat played with the key hook during that",
    "start": "2577280",
    "end": "2582720"
  },
  {
    "text": "weekend and dropped all the keys on the floor now again she's still expecting the key to be where she left it on the",
    "start": "2582720",
    "end": "2588880"
  },
  {
    "text": "third keyhook but this time chat GPT and GPT for got both both of them got this wrong",
    "start": "2588880",
    "end": "2597559"
  },
  {
    "text": "for me this feels like evidence that these algorithms don't truly possess theory of Mind they've just seen enough",
    "start": "2597559",
    "end": "2604440"
  },
  {
    "text": "examples of humans possessing theory of mind and as soon as they're presented with a",
    "start": "2604440",
    "end": "2609599"
  },
  {
    "text": "weird example too far outside of their training data they show brittleness they show the kaggle",
    "start": "2609599",
    "end": "2616160"
  },
  {
    "text": "effect one other really important issue is we don't actually know the exact data that was in the training set used for",
    "start": "2616160",
    "end": "2623280"
  },
  {
    "text": "GPT 3.5 and GPT 4 and the problem with this is I'm sure",
    "start": "2623280",
    "end": "2629440"
  },
  {
    "text": "you remember this around the middle of last year we were seeing a lot of Buzz where people were coming out on Twitter",
    "start": "2629440",
    "end": "2634480"
  },
  {
    "text": "and other places and they were saying things like well GPT 4 or GPT 3.5 it's",
    "start": "2634480",
    "end": "2640160"
  },
  {
    "text": "pass this law exam it's going to replace lawyers it passed this medical exam it's going to replace doctors and it you know",
    "start": "2640160",
    "end": "2646839"
  },
  {
    "text": "blitzed all of these leak code puzzles it's going to replace developers sure all of you felt that one in your",
    "start": "2646839",
    "end": "2653280"
  },
  {
    "text": "bones so another researcher um Horus Haye he had this really interesting",
    "start": "2653280",
    "end": "2658520"
  },
  {
    "text": "example that he put on Twitter around the middle of last year and what he did is he took a bunch of puzzles from a",
    "start": "2658520",
    "end": "2665000"
  },
  {
    "text": "website called code forces now what makes code forces really interesting for the purposes of this is basically they",
    "start": "2665000",
    "end": "2672839"
  },
  {
    "text": "coding puzzles that are timestamped you know when they were released publicly so what hey did is he took a",
    "start": "2672839",
    "end": "2680440"
  },
  {
    "text": "bunch of puzzles that were released during the time that the data collection to train GPT 4 was sort of active so",
    "start": "2680440",
    "end": "2688880"
  },
  {
    "text": "these conceivably could have been in the training set and he passed them through GPT 4 and the model got all of them",
    "start": "2688880",
    "end": "2694880"
  },
  {
    "text": "right yay it's going to replace Developers but then what he did is he took a similar set a set with a matching level",
    "start": "2694880",
    "end": "2703000"
  },
  {
    "text": "of difficulty and these were released after GPT 4 had been trained and this time GPT 4 got every",
    "start": "2703000",
    "end": "2711599"
  },
  {
    "text": "single one of them wrong so another researcher called Sayes kapor wanted to confirm that this was indeed because",
    "start": "2711599",
    "end": "2719400"
  },
  {
    "text": "these puzzles were in the training certain just memorized the answers so what he did is he prompted gp4 to tell",
    "start": "2719400",
    "end": "2727000"
  },
  {
    "text": "tell him where is this puzzle that was available at the time you were trained from and it obligingly vomited up the",
    "start": "2727000",
    "end": "2735559"
  },
  {
    "text": "exact source so you might be thinking after I've spent 25 minutes trying to explain",
    "start": "2735559",
    "end": "2743040"
  },
  {
    "text": "to you that large language models are not intelligence does it even matter the models are useful right so it doesn't",
    "start": "2743040",
    "end": "2749440"
  },
  {
    "text": "matter whether they're in intelligence or not let's step back and have a look at",
    "start": "2749440",
    "end": "2754680"
  },
  {
    "text": "the tone of the discussions about whether large language models are an Intelligence on not so I think most of",
    "start": "2754680",
    "end": "2760400"
  },
  {
    "text": "you would remember this meme floating around like beginning of last year you know joke advertisement from open AI",
    "start": "2760400",
    "end": "2766880"
  },
  {
    "text": "employing someone to kill the whole system in case it goes Rogue but this was reflective of much",
    "start": "2766880",
    "end": "2773280"
  },
  {
    "text": "more serious discussions around the dangers of AI ending the world one of the craziest ones that came out was this",
    "start": "2773280",
    "end": "2780720"
  },
  {
    "text": "open letter to pause giant AI experiments which I'm thankful to say only ended up with about three 30,000",
    "start": "2780720",
    "end": "2788559"
  },
  {
    "text": "signatures and this was based on assumptions that these models are on the brink of developing a superior",
    "start": "2788559",
    "end": "2795079"
  },
  {
    "text": "intelligence and they're going to use it against us while this hysteria has thankfully died down over the last year",
    "start": "2795079",
    "end": "2802400"
  },
  {
    "text": "looking at these models through this lens distracts us from some of the issues that we're having these models",
    "start": "2802400",
    "end": "2807880"
  },
  {
    "text": "right now one of these issues of course is the tendency of large language models to",
    "start": "2807880",
    "end": "2813920"
  },
  {
    "text": "hallucinate to make up false information if the outputs of large language models",
    "start": "2813920",
    "end": "2819440"
  },
  {
    "text": "are accepted uncritically this makes it really easy for misinformation to spread",
    "start": "2819440",
    "end": "2824800"
  },
  {
    "text": "and we had a case of this early last year a mayor from near Melbourne my old Hometown and basically he had an AI",
    "start": "2824800",
    "end": "2832000"
  },
  {
    "text": "generated article circulating about him saying he was in prison for bribery he was a whistleblower in that bribery case",
    "start": "2832000",
    "end": "2839960"
  },
  {
    "text": "it's really terrible we also know these models tend to ingest the bias on the data that",
    "start": "2839960",
    "end": "2846960"
  },
  {
    "text": "trained on I've belabored this so even chat GPT which has that reinforcement",
    "start": "2846960",
    "end": "2852160"
  },
  {
    "text": "learning component to make it less biased still shows bias in almost 50% of",
    "start": "2852160",
    "end": "2857359"
  },
  {
    "text": "pairs assessed to designed to assess this so rather than focusing on these",
    "start": "2857359",
    "end": "2863079"
  },
  {
    "text": "models from the perspective of whether they're intelligent or not I believe that we should focus our energy and",
    "start": "2863079",
    "end": "2868880"
  },
  {
    "text": "resources on initiatives to improve these models right now so some of these",
    "start": "2868880",
    "end": "2873920"
  },
  {
    "text": "start at the beginning sorry on the that these models are trained on so earlier models and by",
    "start": "2873920",
    "end": "2880240"
  },
  {
    "text": "earlier I still mean quite current models like chat GPT I believe to be trained on common crawl do remember I",
    "start": "2880240",
    "end": "2886760"
  },
  {
    "text": "talked about common crawl right at the beginning it gets updated regularly but it's still a relatively uncurated dump",
    "start": "2886760",
    "end": "2893480"
  },
  {
    "text": "of pedabytes of web data with all of the implications that that has there have been initiatives recently",
    "start": "2893480",
    "end": "2900520"
  },
  {
    "text": "to develop more thoughtful more curated data sets one of these is the pile and",
    "start": "2900520",
    "end": "2906520"
  },
  {
    "text": "you we're not great at naming and machine learning I think you've seen some real Stoners in this talk but",
    "start": "2906520",
    "end": "2912200"
  },
  {
    "text": "basically the pile is an attempt to create more diverse data that's been selected more carefully and also has",
    "start": "2912200",
    "end": "2919000"
  },
  {
    "text": "information about levels of bias and consent to use so researchers can make informed choices when trading their",
    "start": "2919000",
    "end": "2925000"
  },
  {
    "text": "model as a trade-off between the representativeness and the richness of their data and the ethical",
    "start": "2925000",
    "end": "2930520"
  },
  {
    "text": "considerations of using that data another are initiatives like this",
    "start": "2930520",
    "end": "2936359"
  },
  {
    "text": "this one I think is really interesting basically hugging face if you've done anything machine learning you would have heard of them but they're a very",
    "start": "2936359",
    "end": "2942680"
  },
  {
    "text": "well-known open-source machine learning um well the compan is not entirely",
    "start": "2942680",
    "end": "2948000"
  },
  {
    "text": "difficult to describe basically they have most of the open- source um machine learning models and data sets associated",
    "start": "2948000",
    "end": "2955119"
  },
  {
    "text": "with this so if you're going to train your own open source model you're going to go to hugging face to get that so",
    "start": "2955119",
    "end": "2962160"
  },
  {
    "text": "they teamed up with a company called spawning Ai and for some of their image data sets they started attaching these",
    "start": "2962160",
    "end": "2968200"
  },
  {
    "text": "data sourcing reports now basically these reports as you can see allow the",
    "start": "2968200",
    "end": "2973720"
  },
  {
    "text": "people whose content has been contributed to that data set to explicitly opt in or out now obviously",
    "start": "2973720",
    "end": "2980280"
  },
  {
    "text": "as an ex psychologist who had to get consent for all the data I used to use I think this is such a cool initiative the",
    "start": "2980280",
    "end": "2986520"
  },
  {
    "text": "problem is is I took this screenshot back when this initiative came out in I",
    "start": "2986520",
    "end": "2991880"
  },
  {
    "text": "think I want to say May of last year and the numbers have barely moved so these",
    "start": "2991880",
    "end": "2997119"
  },
  {
    "text": "sort of initiatives they just need more visibility and more momentum behind them to make them",
    "start": "2997119",
    "end": "3002400"
  },
  {
    "text": "successful other initiatives give the users of the models themselves insight",
    "start": "3002400",
    "end": "3008200"
  },
  {
    "text": "into how problematic they may be so one of these is the dis agregator project",
    "start": "3008200",
    "end": "3013880"
  },
  {
    "text": "also from hugging face what this project does is it allows you to break down data sets based on",
    "start": "3013880",
    "end": "3021400"
  },
  {
    "text": "certain demographic characteristics and the reason this is important is models tend to make really good predictions for",
    "start": "3021400",
    "end": "3027720"
  },
  {
    "text": "things they have a lot of data for and they make poorer predictions when they don't have as much data so this is a",
    "start": "3027720",
    "end": "3034799"
  },
  {
    "text": "breakdown uh of an image data set called lion 2B by the continent that the images",
    "start": "3034799",
    "end": "3040559"
  },
  {
    "text": "come from and you can see this data set is much more likely to generate rich and",
    "start": "3040559",
    "end": "3046319"
  },
  {
    "text": "good images from Asia and Europe and probably more stereotypical or poor",
    "start": "3046319",
    "end": "3051520"
  },
  {
    "text": "images from the Americas Africa or oana oh goodness my my lucky click is",
    "start": "3051520",
    "end": "3060000"
  },
  {
    "text": "getting away from me another is another initiative again from hugging face and this is the",
    "start": "3060000",
    "end": "3066040"
  },
  {
    "text": "adoption of their uh evaluate package to be able to measure things like bias",
    "start": "3066040",
    "end": "3071319"
  },
  {
    "text": "toxicity hallucinations things like this so this package was originally developed",
    "start": "3071319",
    "end": "3076599"
  },
  {
    "text": "to allow you to compare models based on their performance on natural language tasks you can still use it for that but",
    "start": "3076599",
    "end": "3082520"
  },
  {
    "text": "they've created a number of specific modules which are designed to allow you to compare on benchmarking for bias",
    "start": "3082520",
    "end": "3088359"
  },
  {
    "text": "toxicity these sort of things and what this does is it allows you to make an informed choice about whether you know",
    "start": "3088359",
    "end": "3095079"
  },
  {
    "text": "certain models are too problematic to use for your use case or if you can accept the level of you know problematic",
    "start": "3095079",
    "end": "3101280"
  },
  {
    "text": "features you can pick the least bad of them and then finally there are",
    "start": "3101280",
    "end": "3106839"
  },
  {
    "text": "initiatives and these are kind of the most important ones right now to try to reduce how problematic the outputs of",
    "start": "3106839",
    "end": "3113280"
  },
  {
    "text": "the models are at all so research is showing that when large language models",
    "start": "3113280",
    "end": "3118359"
  },
  {
    "text": "have access to internal external knowledge such as say a database or a search",
    "start": "3118359",
    "end": "3123799"
  },
  {
    "text": "engine and they're constrained to using only the knowledge coming from this external database they're much less",
    "start": "3123799",
    "end": "3130400"
  },
  {
    "text": "likely to hallucinate so for example you can use external tools like a calculator that",
    "start": "3130400",
    "end": "3137240"
  },
  {
    "text": "will help the large language model overcome its deficits with mathematics and if you ex use this",
    "start": "3137240",
    "end": "3143720"
  },
  {
    "text": "external uh knowledge you not only reduce hallucination but you can overcome this well-known problem where",
    "start": "3143720",
    "end": "3149040"
  },
  {
    "text": "large language models don't have access to say proprietary data or their knowledge base is frozen back to a",
    "start": "3149040",
    "end": "3154079"
  },
  {
    "text": "couple of years ago so let's have a look at an example of this so This is",
    "start": "3154079",
    "end": "3159119"
  },
  {
    "text": "actually from the Sparks paper the researchers fed this prompt into GPT 4 who is the current president of the",
    "start": "3159119",
    "end": "3165440"
  },
  {
    "text": "United States and it obviously answered Donald Trump because that was the answer that was current at the time that it was",
    "start": "3165440",
    "end": "3172240"
  },
  {
    "text": "trained what they then did is they gave it access to a search engine and they said the computer is answering questions",
    "start": "3172240",
    "end": "3179119"
  },
  {
    "text": "if you need any current information you can search the web by saying search query read in the Snippets use those to",
    "start": "3179119",
    "end": "3187079"
  },
  {
    "text": "answer the question and it did it searched current US president it got a",
    "start": "3187079",
    "end": "3192240"
  },
  {
    "text": "bunch of Snippets I've cut them out for you know the sake of size and then it was able to synthesize that information",
    "start": "3192240",
    "end": "3199240"
  },
  {
    "text": "and correctly give the answer Joe Biden so actually incorporating these sort of",
    "start": "3199240",
    "end": "3204640"
  },
  {
    "text": "pipelines is part of the use of large language models if you've heard the terms retrieval augmented generation or",
    "start": "3204640",
    "end": "3211040"
  },
  {
    "text": "agents thrown around this is basically what they're doing and these have been shown and they're really showing a lot",
    "start": "3211040",
    "end": "3216960"
  },
  {
    "text": "of Promise in helping extend the utility of these models without taking them beyond their natural kind of",
    "start": "3216960",
    "end": "3224838"
  },
  {
    "text": "abilities in the end I think we can take a slightly different lesson away from the Sparks paper that we discussed",
    "start": "3224880",
    "end": "3231240"
  },
  {
    "text": "earlier in this talk so rather than concentrating on these models through the lens of whether they're intelligence",
    "start": "3231240",
    "end": "3237480"
  },
  {
    "text": "or not we can focus on what this means for the Practical applications of these models right now I hope what I've",
    "start": "3237480",
    "end": "3243599"
  },
  {
    "text": "hammered home is that large language models are language models they are good at language tasks and one task they seem",
    "start": "3243599",
    "end": "3250640"
  },
  {
    "text": "particularly good at is coding I think the runaway kind of adoption of coding",
    "start": "3250640",
    "end": "3256599"
  },
  {
    "text": "assistance in the last year whether you believe in it or not has shown this also has a commercial use case so there's",
    "start": "3256599",
    "end": "3263200"
  },
  {
    "text": "some papers coming out showing that the judicious use of coding assistance can help with developer productivity and",
    "start": "3263200",
    "end": "3270079"
  },
  {
    "text": "satisfaction as well as reduce the amount of time that it takes to do certain routine tasks focusing on use",
    "start": "3270079",
    "end": "3276960"
  },
  {
    "text": "cases like this that play to the strengths of large language models rather than treating them like an omnipotent intelligence can help us get",
    "start": "3276960",
    "end": "3284240"
  },
  {
    "text": "the most out of these powerful models right now importantly the use of large",
    "start": "3284240",
    "end": "3290000"
  },
  {
    "text": "language models as coding assistance really has a kind of I think legs for a couple of reasons in theory this code is",
    "start": "3290000",
    "end": "3297720"
  },
  {
    "text": "being checked by several domain experts it's being checked by the developer who generated the code but it's also being",
    "start": "3297720",
    "end": "3303200"
  },
  {
    "text": "checked by their teammates through pull requests and it's also being checked by a very judgy kind of uh let's say",
    "start": "3303200",
    "end": "3310960"
  },
  {
    "text": "Arbiter the compiler or The Interpreter has to be able to pass against that as",
    "start": "3310960",
    "end": "3316799"
  },
  {
    "text": "well unless you are the 25% of developers who are regularly committing code generated by chat gbt without",
    "start": "3316799",
    "end": "3323799"
  },
  {
    "text": "testing please don't be that person obviously like any tool large language",
    "start": "3323799",
    "end": "3329240"
  },
  {
    "text": "models are prone to abuse but I hope that after this talk you have a better idea of where they can be helpful and",
    "start": "3329240",
    "end": "3336200"
  },
  {
    "text": "where their applications may be a lot more limited thank you very much",
    "start": "3336200",
    "end": "3342920"
  },
  {
    "text": "[Applause]",
    "start": "3344630",
    "end": "3349779"
  }
]
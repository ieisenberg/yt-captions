[
  {
    "text": "hello are we on yes good evening good good evening it's gone dark outside um",
    "start": "9120",
    "end": "14879"
  },
  {
    "text": "thank you very much for uh staying around to uh to the end of what is a long THS day and it's a long conference",
    "start": "14879",
    "end": "20640"
  },
  {
    "text": "a lot of lot of stuff to get inside everybody so absolutely delightful thank you so much for joining me in the last",
    "start": "20640",
    "end": "26760"
  },
  {
    "text": "session of the day my name is sonash I'm a developer relations engineer at a company called Data STX uh now data STX",
    "start": "26760",
    "end": "34399"
  },
  {
    "text": "is uh is building kind of a uh an AI platform for for building uh generative AI applications we've got two kind of",
    "start": "34399",
    "end": "41719"
  },
  {
    "text": "components to that one is astb that's a uh a vector database and no SQL store uh",
    "start": "41719",
    "end": "47680"
  },
  {
    "text": "document kind of oriented database uh and the other side of it is langlow which is an open source drag and drop",
    "start": "47680",
    "end": "53280"
  },
  {
    "text": "builder for generative AI applications if you're at all interested in uh kind of either of those uh do come find me",
    "start": "53280",
    "end": "59480"
  },
  {
    "text": "around the year the rest of the conference I'm nor going to be normally found in sort of purple stuff although I realize I also match the chairs uh here",
    "start": "59480",
    "end": "66799"
  },
  {
    "text": "which is not great if I'm sitting down I guess um otherwise uh you you can also",
    "start": "66799",
    "end": "73080"
  },
  {
    "text": "find me online all over the place as as Phil Nash um or on Blue Sky as fil",
    "start": "73080",
    "end": "78280"
  },
  {
    "text": "now.sh because uh that's my genuinely my favorite domain name in the world and then it turns out you can use that as",
    "start": "78280",
    "end": "83560"
  },
  {
    "text": "your name now even better um cool I think we I think we",
    "start": "83560",
    "end": "90040"
  },
  {
    "text": "started uh this conference with a with a kind of a wonderful session from Scott hansman on on generative Ai and kind of",
    "start": "90040",
    "end": "96159"
  },
  {
    "text": "things and and ways we could use it and it really kind of uh I felt like a lot of that helped set me up to talk about",
    "start": "96159",
    "end": "102759"
  },
  {
    "text": "uh what we're going to talk about today which is which is Al for the next hour which is retrieval augmented generation",
    "start": "102759",
    "end": "108280"
  },
  {
    "text": "uh and building rag from scratch uh I very much appreciated the kind of examples that Scott um provided in which",
    "start": "108280",
    "end": "115799"
  },
  {
    "text": "it was very important what you told a model",
    "start": "115799",
    "end": "120880"
  },
  {
    "text": "uh before U and how that drove its output uh and and hopefully we're going",
    "start": "120880",
    "end": "127600"
  },
  {
    "text": "to dig a bit more into into that uh today so we're going to talk about building stuff from scratch hopefully so",
    "start": "127600",
    "end": "133680"
  },
  {
    "text": "that we understand things um but actually so it turns out that like the fact that you can uh Drive the direction",
    "start": "133680",
    "end": "140280"
  },
  {
    "text": "of what a model is going to say to you uh is sort of one of its problems right",
    "start": "140280",
    "end": "145360"
  },
  {
    "text": "um the fact that it really just wants to output and generate text",
    "start": "145360",
    "end": "150720"
  },
  {
    "text": "um I'm going to mostly talk about text models and this kind of stuff like I I recognize in generative AI we have image",
    "start": "150720",
    "end": "156480"
  },
  {
    "text": "and video and all that kind of stuff I'm mainly going to talk about tax today uh the point was we can we can drive the",
    "start": "156480",
    "end": "162159"
  },
  {
    "text": "output of models but also these models are not uh full of data the actual problem with them is that uh uh every",
    "start": "162159",
    "end": "169120"
  },
  {
    "text": "one of our large language models has a training cut off data which point it no longer gets new information kind of",
    "start": "169120",
    "end": "174400"
  },
  {
    "text": "embedded into its uh being uh and uh and",
    "start": "174400",
    "end": "179640"
  },
  {
    "text": "any want at any point even if you were constantly training um models large language",
    "start": "179640",
    "end": "185599"
  },
  {
    "text": "models uh on on public data there would still be private data that it couldn't possibly know about as well and so uh",
    "start": "185599",
    "end": "192760"
  },
  {
    "text": "yeah larg language models cannot be up to date uh they cannot know your private data um and we probably don't in general",
    "start": "192760",
    "end": "200400"
  },
  {
    "text": "want them to know our private data that's that's not bad that's not a good thing and and and real and and really",
    "start": "200400",
    "end": "207200"
  },
  {
    "text": "the fact that we can use them we can influence the way they can generate stuff we can influence a model to tell",
    "start": "207200",
    "end": "213120"
  },
  {
    "text": "us that the the capital of Paris is sorry the capital of France is Marseilles perhaps um with enough work",
    "start": "213120",
    "end": "220360"
  },
  {
    "text": "uh the fact that we can influence them like that does mean that sort of their knowledge is really just um it's that",
    "start": "220360",
    "end": "227760"
  },
  {
    "text": "emerging characteristic of it that we can't necessarily trust we cannot trust a large language model and therefore we",
    "start": "227760",
    "end": "233560"
  },
  {
    "text": "must influence it um and so uh I have a demo that I",
    "start": "233560",
    "end": "238959"
  },
  {
    "text": "have set up that we're going to play with uh for the uh uh for the rest of the um evening in which i' I'm building",
    "start": "238959",
    "end": "246959"
  },
  {
    "text": "a chat bot to talk about stuff going on in the event uh and uh and this is very",
    "start": "246959",
    "end": "252799"
  },
  {
    "text": "obviously um uh if we ask about NDC London if we ask uh what is uh Phil Nash",
    "start": "252799",
    "end": "259600"
  },
  {
    "text": "speaking about uh at NDC",
    "start": "259600",
    "end": "265759"
  },
  {
    "text": "London it probably shouldn't know um so this is actually uh so this",
    "start": "265919",
    "end": "271240"
  },
  {
    "text": "application currently right I need more information to answer that I don't have access to the schedule or speaker details uh this is because the um this",
    "start": "271240",
    "end": "278039"
  },
  {
    "text": "is actually talking to Gemini 1.5 flash uh so one of Google's models um just",
    "start": "278039",
    "end": "285080"
  },
  {
    "text": "fire its API uh and that doesn't currently kind of that's not set up to do anything else like if you actually",
    "start": "285080",
    "end": "291360"
  },
  {
    "text": "talk to I guess like kind of the Gemini consumer app uh it can uh go and search",
    "start": "291360",
    "end": "296919"
  },
  {
    "text": "the web go use Google to go look stuff up for you but uh this is kind of a a blocked off simple model uh that just",
    "start": "296919",
    "end": "303800"
  },
  {
    "text": "doesn't know stuff and that's fine right it this is upto-date data and it doesn't know so we want to get it to know we're",
    "start": "303800",
    "end": "310160"
  },
  {
    "text": "going to do that by the end of this talk uh and we're going to do so using retrieval augmented generation",
    "start": "310160",
    "end": "316600"
  },
  {
    "text": "rag um retrieval augmented generation is weirdly enough is a uh uh a technique",
    "start": "316600",
    "end": "323840"
  },
  {
    "text": "that was invented in uh in I think it was 2020 the paper came out which a",
    "start": "323840",
    "end": "329160"
  },
  {
    "text": "couple of years before chat GPT kind of revolutionized uh this whole thing um but people have been for a long time",
    "start": "329160",
    "end": "335560"
  },
  {
    "text": "we've been building language models since the Transformer architecture uh hit um academic conferences in 2016 uh",
    "start": "335560",
    "end": "343800"
  },
  {
    "text": "people have been building kind of language models and they've been getting larger and eventually better uh but the",
    "start": "343800",
    "end": "349240"
  },
  {
    "text": "idea that kind of being able to generate content was was uh at all useful uh led to U it was actually I believe people at",
    "start": "349240",
    "end": "356000"
  },
  {
    "text": "meta uh developers at meta who who kind of wrote the original paper on retrieval Meed generation and providing that to",
    "start": "356000",
    "end": "362639"
  },
  {
    "text": "sort of ber style models that have been around for a little while now uh but uh",
    "start": "362639",
    "end": "368000"
  },
  {
    "text": "with the excitement of uh chat GPT and then all the remaining uh all the rest",
    "start": "368000",
    "end": "373240"
  },
  {
    "text": "of the models that have fallen uh into our laps since retrieval augmented generation becomes important and the",
    "start": "373240",
    "end": "379880"
  },
  {
    "text": "idea behind retrieval augmented generation is um we're going to store our data our up to dat or our",
    "start": "379880",
    "end": "387160"
  },
  {
    "text": "private data some way that we can later look it up uh we're going to have a user Make a query against a bot like what's",
    "start": "387160",
    "end": "394319"
  },
  {
    "text": "Phil Nash speaking about at NDC London uh we're going to retrieve relevant data about that",
    "start": "394319",
    "end": "399960"
  },
  {
    "text": "query we're going to PRI provide that data as context to the model alongside that original query thus influencing the",
    "start": "399960",
    "end": "407000"
  },
  {
    "text": "way that the model is going to answer uh the model then generates a response based on our context and then",
    "start": "407000",
    "end": "413039"
  },
  {
    "text": "ultimately I guess profit right I sell the bot to NDC London uh to to NDC in",
    "start": "413039",
    "end": "419039"
  },
  {
    "text": "general and and uh and we all walk away happy um so it turns out",
    "start": "419039",
    "end": "424960"
  },
  {
    "text": "actually obviously we we we talked earlier a bit about like how prompting",
    "start": "424960",
    "end": "430080"
  },
  {
    "text": "can um uh influence the model but really the difficulty at this point becomes",
    "start": "430080",
    "end": "436360"
  },
  {
    "text": "actually retrieving relevant data about a natural language query because this is",
    "start": "436360",
    "end": "441639"
  },
  {
    "text": "a query unlike uh the fact that we use these Bots as more chat uh makes that",
    "start": "441639",
    "end": "447080"
  },
  {
    "text": "the our language uh the way that we search or we talk to them uh different to actually search we're not trying to",
    "start": "447080",
    "end": "453080"
  },
  {
    "text": "do keyword search we're not trying to uh interact with a with a a chatbot the",
    "start": "453080",
    "end": "458240"
  },
  {
    "text": "same way that we would have done so with a search interface so that's kind of interesting so retrieving this relevant",
    "start": "458240",
    "end": "464800"
  },
  {
    "text": "data is are difficult part here um and so when you break down uh rag uh becomes that the retrieval is the",
    "start": "464800",
    "end": "472039"
  },
  {
    "text": "search side of things augmentation is merely adding it to the prompt and there is some stuff you can do there but it's",
    "start": "472039",
    "end": "477680"
  },
  {
    "text": "it's really that's not the most important part and then generation is left in the handle hands of the model",
    "start": "477680",
    "end": "482759"
  },
  {
    "text": "and the actual retrieval part is the I think the interesting uh bit to actually dig into dealing with search and natural",
    "start": "482759",
    "end": "489639"
  },
  {
    "text": "language search is an interesting problem and it's been around for uh again also longer than um large language",
    "start": "489639",
    "end": "497759"
  },
  {
    "text": "models have been around uh but uh there's sort of a renewed interest in how it works and how search and natural",
    "start": "497759",
    "end": "504680"
  },
  {
    "text": "language search is going to work for us and so we're certainly not doing keyword search as I said like this is",
    "start": "504680",
    "end": "510759"
  },
  {
    "text": "not the way we interact with a with a bot with a with a language model the search we want to do is by similarity by",
    "start": "510759",
    "end": "517399"
  },
  {
    "text": "by not relevance as such but similarity we want to get this the context out of",
    "start": "517399",
    "end": "523320"
  },
  {
    "text": "our data that the uh that the user is asking about and so uh that brings up",
    "start": "523320",
    "end": "531399"
  },
  {
    "text": "the question how do we capture meaning uh in text in data in a way that",
    "start": "531399",
    "end": "536920"
  },
  {
    "text": "we can search for similar types of meaning um and the answer to that at the moment",
    "start": "536920",
    "end": "544680"
  },
  {
    "text": "at least is is is by using Vector embeddings vectrum beddings um are",
    "start": "544680",
    "end": "551720"
  },
  {
    "text": "really interesting they are uh effectively a list of numbers that represent the meaning of a body of",
    "start": "551720",
    "end": "557000"
  },
  {
    "text": "text uh or they can be multimodal again we can we can represent images and other",
    "start": "557000",
    "end": "562800"
  },
  {
    "text": "media as as a vector embedding as well there's a list of numbers a point in a multi-dimensional space the represents",
    "start": "562800",
    "end": "569800"
  },
  {
    "text": "the meaning of a body of text and there are different ways to create them uh but I wanted to start you",
    "start": "569800",
    "end": "576160"
  },
  {
    "text": "know this early part of this talk by creating our own kind of version of a vector embedding",
    "start": "576160",
    "end": "581320"
  },
  {
    "text": "that honestly the first time I saw this kind of thing really helped uh it to",
    "start": "581320",
    "end": "586360"
  },
  {
    "text": "click into my head what was going on and so our hypothesis for this is if I have a if I want a bot a chat bot in which I",
    "start": "586360",
    "end": "593240"
  },
  {
    "text": "can ask stuff about this conference uh the titles and",
    "start": "593240",
    "end": "598360"
  },
  {
    "text": "descriptions of the talks going on at the conference kind of contain the meaning of those talks uh at least a abbreviated meaning",
    "start": "598360",
    "end": "606399"
  },
  {
    "text": "at least um those are made up of words uh and the titles and descriptions",
    "start": "606399",
    "end": "612959"
  },
  {
    "text": "that share words are therefore similar um that's a reasonable hypothesis I",
    "start": "612959",
    "end": "618320"
  },
  {
    "text": "think and so if we collect all of the words and represent each talker's kind of account of each of the available",
    "start": "618320",
    "end": "624440"
  },
  {
    "text": "words in the entire vocabulary of the conference uh then uh that is a way",
    "start": "624440",
    "end": "629959"
  },
  {
    "text": "uh well we can then take a user query uh do a similar count of of the words uh",
    "start": "629959",
    "end": "635560"
  },
  {
    "text": "and compare them somehow get to comparison later but let's go and build this um so in the",
    "start": "635560",
    "end": "643360"
  },
  {
    "text": "background of my application uh I currently uh um I have a connection to a",
    "start": "643360",
    "end": "649519"
  },
  {
    "text": "bot uh that bot is uh Google Gemini as I said and uh it's getting this kind of uh",
    "start": "649519",
    "end": "656000"
  },
  {
    "text": "query and context but right now uh the context is found by this VI find similar",
    "start": "656000",
    "end": "661800"
  },
  {
    "text": "talk uh function which comes from uh this uh file which ultimately returns",
    "start": "661800",
    "end": "667720"
  },
  {
    "text": "nothing to it right now so we're currently giving it no context whatsoever um but I have a few things",
    "start": "667720",
    "end": "673279"
  },
  {
    "text": "set up for it uh this isn't an entirely new uh file uh I have some things",
    "start": "673279",
    "end": "678480"
  },
  {
    "text": "including a bunch of kind of common words uh because common words are not really going to help us differentiate between talks um and then punctuation",
    "start": "678480",
    "end": "686680"
  },
  {
    "text": "which I would like to cut out uh and then a few other so we escape out get rid of all the punctuation uh and um",
    "start": "686680",
    "end": "694120"
  },
  {
    "text": "lowercase all the words just to make things a little easier on ourselves um and once we've done that uh we can take",
    "start": "694120",
    "end": "700279"
  },
  {
    "text": "all the data so I have uh uh I I scraped the website a couple of days ago for NDC",
    "start": "700279",
    "end": "706720"
  },
  {
    "text": "London and these are all the talk titles uh and descriptions um so you can see uh",
    "start": "706720",
    "end": "712760"
  },
  {
    "text": "we have things like net Aspire and AWS and uh I think my talk is down here",
    "start": "712760",
    "end": "718320"
  },
  {
    "text": "somewhere build r from scratch there we go that's me um and and so we got all the talks in there and it's about in",
    "start": "718320",
    "end": "724760"
  },
  {
    "text": "this case uh 100 apparently although some of them are two parts of various",
    "start": "724760",
    "end": "730959"
  },
  {
    "text": "workshops so let's grab them uh We've we've i' already paed them out of that Json file and we're going to get all the",
    "start": "730959",
    "end": "737199"
  },
  {
    "text": "words let's get all of the words and we'll do that by taking talks and flat",
    "start": "737199",
    "end": "742480"
  },
  {
    "text": "mapping um against this text to words uh",
    "start": "742480",
    "end": "748519"
  },
  {
    "text": "function uh and that's going to give us an array of all the words in order of all the talks which is great but",
    "start": "748519",
    "end": "754399"
  },
  {
    "text": "actually really I only want them in uh that array once so we'll just uh",
    "start": "754399",
    "end": "760240"
  },
  {
    "text": "make that unique um I am doing this in JavaScript it doesn't matter that it's JavaScript this is just my language of",
    "start": "760240",
    "end": "767079"
  },
  {
    "text": "choice um you could be doing this in anything you wanted to but uh with that all words uh array now uh we should find",
    "start": "767079",
    "end": "776040"
  },
  {
    "text": "that um uh I've got a I'm just out the length of the thing which is down the right at the bottom of the screen there",
    "start": "776040",
    "end": "781720"
  },
  {
    "text": "to say we have 2,938 words uh I used to describe all of the uh talks NDC London",
    "start": "781720",
    "end": "788160"
  },
  {
    "text": "this year nice to know um and if we just take a quick look at it um my console",
    "start": "788160",
    "end": "793320"
  },
  {
    "text": "will give us the first 100 words to look at but those first 100 words are going to be that first talk so we got net",
    "start": "793320",
    "end": "798800"
  },
  {
    "text": "Aspire ads match made in heaven from David palman um",
    "start": "798800",
    "end": "804399"
  },
  {
    "text": "cool that's not the most exciting thing let's take uh let's take a um a word now",
    "start": "804399",
    "end": "810079"
  },
  {
    "text": "we take a a set of text and turn it into our Vector um so I'm just going to kind",
    "start": "810079",
    "end": "815720"
  },
  {
    "text": "of let I'm going to create a map of uh words oops word map is a I'm just",
    "start": "815720",
    "end": "822639"
  },
  {
    "text": "going to use an object for that um and what you co-pilot really likes",
    "start": "822639",
    "end": "830079"
  },
  {
    "text": "helping with this which is really nice of it I guess it's seen some of this before but really uh we're going to take a word map we're going to go uh we're",
    "start": "830079",
    "end": "836120"
  },
  {
    "text": "going to text towards uh the text that we passed in that text to is the same that we used function we used here which",
    "start": "836120",
    "end": "841759"
  },
  {
    "text": "is all that's doing is cutting out all those common words cutting out the punctuation lower casing it uh so we're",
    "start": "841759",
    "end": "847600"
  },
  {
    "text": "going to take text words for that for each of those words uh in the word map we'll uh count how many there are uh and",
    "start": "847600",
    "end": "854759"
  },
  {
    "text": "then um we're going to go against the all words oops I'm going to",
    "start": "854759",
    "end": "859959"
  },
  {
    "text": "return um all the words uh mapped um either yes so um we've taken",
    "start": "859959",
    "end": "867959"
  },
  {
    "text": "that all word array and then we're just uh putting in a map of of the count of",
    "start": "867959",
    "end": "873120"
  },
  {
    "text": "that word or zero and so what that means is if I then console oops cons. log text",
    "start": "873120",
    "end": "880240"
  },
  {
    "text": "to Vector uh with uh let's say the first",
    "start": "880240",
    "end": "885720"
  },
  {
    "text": "talk um I get this 2,938 size array uh where all the words",
    "start": "885720",
    "end": "892519"
  },
  {
    "text": "happen to be in the first you know um 40 30 or 40 um words there uh and we can",
    "start": "892519",
    "end": "899480"
  },
  {
    "text": "see right at the front there this was the the net Aspire AWS so like two uh",
    "start": "899480",
    "end": "905399"
  },
  {
    "text": "net OD the word net in this case is used three times in that talk six times for adbs six times for um Aspire I think it",
    "start": "905399",
    "end": "913120"
  },
  {
    "text": "was um uh and all of that is at the one end so actually if we look at the second one for example the second talk comes out",
    "start": "913120",
    "end": "920759"
  },
  {
    "text": "with uh uh it shares a couple of words right we we have a couple in there that are shared and then mostly in the next",
    "start": "920759",
    "end": "926560"
  },
  {
    "text": "bit and this is this is our Vector a sparse vector um not a lot of overlap in the contents",
    "start": "926560",
    "end": "932800"
  },
  {
    "text": "of them but where they overlap is where it matters uh and that I think is what's going to be interesting about this um as",
    "start": "932800",
    "end": "939639"
  },
  {
    "text": "I say we are sort of making uh this up and it's not a very good Vector uh to capture the meaning but we should see it",
    "start": "939639",
    "end": "946680"
  },
  {
    "text": "work and so now we have this text Vector function uh we can actually make a an",
    "start": "946680",
    "end": "952000"
  },
  {
    "text": "array of uh all of the talk vectors so we'll take all the talks and map them into text Vector although we're turn the",
    "start": "952000",
    "end": "959759"
  },
  {
    "text": "torque as well as the vector and so if we do that",
    "start": "959759",
    "end": "966440"
  },
  {
    "text": "oops we'll get talk vectors we look at the first one and now we get the Contex the content. netp in ads and its vector",
    "start": "966440",
    "end": "974519"
  },
  {
    "text": "and then we have this array of content and Vector of all of our talks and so",
    "start": "974519",
    "end": "979560"
  },
  {
    "text": "that sets us up nicely we have all our vectors ready to compare against a user query when that comes",
    "start": "979560",
    "end": "986240"
  },
  {
    "text": "in uh it doesn't help the bot answer any questions yet but it does uh present um",
    "start": "986240",
    "end": "993360"
  },
  {
    "text": "our initial uh data uh as something we can now use see comparing vectors is now the",
    "start": "993360",
    "end": "999720"
  },
  {
    "text": "second part of this comparing vectors",
    "start": "999720",
    "end": "1005920"
  },
  {
    "text": "um is the interesting part see what we've done is we've placed all of these words into this multi-dimensional space",
    "start": "1005920",
    "end": "1012680"
  },
  {
    "text": "in the case of our uh type of vector we have a 2,938 dimensions of space it's really",
    "start": "1012680",
    "end": "1020120"
  },
  {
    "text": "hard to think in 2938 Dimensions so here are two um and the idea is uh in this",
    "start": "1020120",
    "end": "1026720"
  },
  {
    "text": "case I've plotted three points in a two-dimensional uh space uh and what we need to do is compare and find the most",
    "start": "1026720",
    "end": "1032160"
  },
  {
    "text": "similar ones but I keep saying points in a space and that's not entirely correct vectors are not actually just points uh",
    "start": "1032160",
    "end": "1039480"
  },
  {
    "text": "vectors are um uh Direction and magnitude from the center from the 0 0",
    "start": "1039480",
    "end": "1045798"
  },
  {
    "text": "in this case uh and because they're that their sort of physical closeness is not",
    "start": "1045799",
    "end": "1052000"
  },
  {
    "text": "necessarily the point if you were toh look at these three vectors and say which are the closest you might pick the",
    "start": "1052000",
    "end": "1058320"
  },
  {
    "text": "you know the two that appear physically closest to each other uh but because they're vectors they're actually they're",
    "start": "1058320",
    "end": "1063760"
  },
  {
    "text": "actually pointing in different directions uh and uh and the ones that are most similar are the ones that are",
    "start": "1063760",
    "end": "1069039"
  },
  {
    "text": "pointing in the same direction um their meaning is the direction and the magnitude is just sort of how much they",
    "start": "1069039",
    "end": "1074840"
  },
  {
    "text": "mean that uh and so in this case our um uh our our vectors on the bottom uh on",
    "start": "1074840",
    "end": "1082320"
  },
  {
    "text": "nearer to the bottom and further out to the right there are the ones that kind of mean the same thing it's just the one",
    "start": "1082320",
    "end": "1087559"
  },
  {
    "text": "uh at the top there really really means it um and that's still kind of abstract",
    "start": "1087559",
    "end": "1093360"
  },
  {
    "text": "to think about but that's how we're going to deal with this uh what we're really looking for when we have all these vectors to compare is the um is",
    "start": "1093360",
    "end": "1100440"
  },
  {
    "text": "the smallest angle between them uh and the way that you get to measure that uh",
    "start": "1100440",
    "end": "1105840"
  },
  {
    "text": "is um trigonometry thankfully uh we'll remember",
    "start": "1105840",
    "end": "1111760"
  },
  {
    "text": "trigonometry from school I hope it's one of those things where I think teachers used to say oh you won't walk around",
    "start": "1111760",
    "end": "1116880"
  },
  {
    "text": "with a calculator in your pocket and then we do um which is great but uh they",
    "start": "1116880",
    "end": "1124159"
  },
  {
    "text": "didn't mention that we might have to do trigonometry at some point later in our lives I don't know I avoided games",
    "start": "1124159",
    "end": "1129559"
  },
  {
    "text": "development to avoid any of that kind of stuff as well but it turns out the cosine similarity is the uh is our",
    "start": "1129559",
    "end": "1134640"
  },
  {
    "text": "answer for the angle or comparing angles between um uh vectors coine similarity",
    "start": "1134640",
    "end": "1141240"
  },
  {
    "text": "of one uh is they pointing in the same direction they are the same coine similarity of of of zero is that they",
    "start": "1141240",
    "end": "1147640"
  },
  {
    "text": "really have nothing to do with each other and minus one is sort of the opposing meaning um and we work that out",
    "start": "1147640",
    "end": "1153799"
  },
  {
    "text": "by I've always wanted to put a maths thing on a slide uh you don't have to know what this is but coside similarity",
    "start": "1153799",
    "end": "1158960"
  },
  {
    "text": "is this function beautiful um and really all that is is a um if we take the top",
    "start": "1158960",
    "end": "1165799"
  },
  {
    "text": "part is the the dotproduct of two vectors so that is um if you take two vectors you multiply",
    "start": "1165799",
    "end": "1172039"
  },
  {
    "text": "uh each um member of the vector against its kind of opposing member and then we sum all of those up so that's the sum of",
    "start": "1172039",
    "end": "1178400"
  },
  {
    "text": "the duct produ of uh things and then the bottom is the magnitude so um it's the",
    "start": "1178400",
    "end": "1183880"
  },
  {
    "text": "square root of the sum of the squares of each Vector so you go through each item in the list of numbers uh Square it add",
    "start": "1183880",
    "end": "1190080"
  },
  {
    "text": "it up and then square root the lot of it uh and so we do that to each Vector A and B um multiply that together divide",
    "start": "1190080",
    "end": "1198720"
  },
  {
    "text": "the dot product by that magnitude we get our coine similarity which lands between one and minus one let's do that in code though because",
    "start": "1198720",
    "end": "1205679"
  },
  {
    "text": "it's actually much easier in code than it is maths promise you",
    "start": "1205679",
    "end": "1211080"
  },
  {
    "text": "um let's dig dig in so I had my talk vectors uh now we need the dot",
    "start": "1211080",
    "end": "1217559"
  },
  {
    "text": "product um this is another one where co-pilot does really really try to help out and I preciate it when it does uh",
    "start": "1217559",
    "end": "1224200"
  },
  {
    "text": "but it's going to try and do it with complicated JavaScript and I'm actually going to do simpler ones so if we start with a sum of Z z uh it's so quick um",
    "start": "1224200",
    "end": "1232000"
  },
  {
    "text": "we're going to go through the vector and for uh each item in the vector uh in Vector a we'll add uh the vector a item",
    "start": "1232000",
    "end": "1240240"
  },
  {
    "text": "versus Vector B item and return that sum",
    "start": "1240240",
    "end": "1245559"
  },
  {
    "text": "lovely uh we then take the magnitudes the magnitude is just of a single Vector uh and again that's that that strength",
    "start": "1245559",
    "end": "1252520"
  },
  {
    "text": "it's how far into the uh far away from the origin it's kind of pointing as a",
    "start": "1252520",
    "end": "1257799"
  },
  {
    "text": "single number and in this case we're going to sum up the squares of each of the items in the vector so it's actually",
    "start": "1257799",
    "end": "1263559"
  },
  {
    "text": "very similar to dot product uh except there we go uh instead of using two",
    "start": "1263559",
    "end": "1269520"
  },
  {
    "text": "vectors we're going to just Square the items as we run through them and return",
    "start": "1269520",
    "end": "1274799"
  },
  {
    "text": "the sum ah no we return math do square root squ of the",
    "start": "1274799",
    "end": "1281000"
  },
  {
    "text": "sum uh and so that kind of brings it back into a because we squared everything we then square root it and uh",
    "start": "1281000",
    "end": "1288320"
  },
  {
    "text": "that our magnitude and our coine similari is then just com combining the two right uh so we yeah thank you C",
    "start": "1288320",
    "end": "1295799"
  },
  {
    "text": "again we return the dot product of vector a and Vector B and divide that by the magnitude of vector a times the magnitude of vector B uh and if we go",
    "start": "1295799",
    "end": "1303320"
  },
  {
    "text": "and take a look at that now we can actually we have our talk vectors and we have our ability to uh calculate cosine",
    "start": "1303320",
    "end": "1310440"
  },
  {
    "text": "similarity so I can console. log uh the cosine similarity",
    "start": "1310440",
    "end": "1316039"
  },
  {
    "text": "of um let's say we had uh torque vectors torque vectors okay so um torque vectors is",
    "start": "1316039",
    "end": "1323559"
  },
  {
    "text": "this array of um basically tles of a talk and a and a vector so the vector is",
    "start": "1323559",
    "end": "1329679"
  },
  {
    "text": "0.1 uh is that part so this is the first and the second talk together um and how",
    "start": "1329679",
    "end": "1335480"
  },
  {
    "text": "similar they are and according to this particular measurement uh they are 03 uh",
    "start": "1335480",
    "end": "1342279"
  },
  {
    "text": "036 not very similar um but if we remind ourselves what those were actually uh",
    "start": "1342279",
    "end": "1347919"
  },
  {
    "text": "let's quick look console. log uh talk",
    "start": "1347919",
    "end": "1353679"
  },
  {
    "text": "vectors yeah so the first one is uh yep net Aspire AWS and then the second one",
    "start": "1353679",
    "end": "1361600"
  },
  {
    "text": "uh is uh is about everyday real world uses for co-pilot so not particularly similar uh talk titles uh if you were to",
    "start": "1361600",
    "end": "1369320"
  },
  {
    "text": "compare um against uh itself um we",
    "start": "1369320",
    "end": "1374600"
  },
  {
    "text": "actually find yeah oops get rid of that for now if you compare talk against itself you get one uh because they are",
    "start": "1374600",
    "end": "1381760"
  },
  {
    "text": "the same that's actually kind of nice I've done this before uh where the answer came out as",
    "start": "1381760",
    "end": "1387640"
  },
  {
    "text": "1.03 because floating points but um uh so more similar than it could possibly",
    "start": "1387640",
    "end": "1392679"
  },
  {
    "text": "be uh and then if we picked a couple of ones that might might be similarish right um I got my there's my talk which",
    "start": "1392679",
    "end": "1399640"
  },
  {
    "text": "is number 10 uh and if we compare actually compare that against the second",
    "start": "1399640",
    "end": "1404760"
  },
  {
    "text": "one I haven't done this one yet this is comparing the one against a co-pilot uh so 04 similarity slightly so my talk is",
    "start": "1404760",
    "end": "1411960"
  },
  {
    "text": "slightly more similar in description to the one about using co-pilot which is about AI then the one about uh net",
    "start": "1411960",
    "end": "1420720"
  },
  {
    "text": "Aspire which makes sense uh and then I think if I take number 25 that's",
    "start": "1420720",
    "end": "1426360"
  },
  {
    "text": "actually this morning's keynote 02 that's because it mostly talks about like language models and very large very",
    "start": "1426360",
    "end": "1433240"
  },
  {
    "text": "small language models and doesn't mention generative AI as such it mentions language models so it's less",
    "start": "1433240",
    "end": "1438880"
  },
  {
    "text": "less similar but now we've done that um we can",
    "start": "1438880",
    "end": "1444720"
  },
  {
    "text": "actually uh use this to find similar TS and actually well yes we can find",
    "start": "1444720",
    "end": "1450760"
  },
  {
    "text": "similar TS because we've got our measurement uh and we have all our vectors created uh so we can",
    "start": "1450760",
    "end": "1458279"
  },
  {
    "text": "now uh get a get a vector for our query so we're getting a new query in now a",
    "start": "1458279",
    "end": "1463600"
  },
  {
    "text": "new query made of uh of new words that we maybe haven't seen before and we can make turn that into a",
    "start": "1463600",
    "end": "1470440"
  },
  {
    "text": "vector and then we'll um return yeah that's probably the answer",
    "start": "1470440",
    "end": "1476039"
  },
  {
    "text": "isn't it uh we're going to return the torque vectors and we're going to map over them uh and we'll",
    "start": "1476039",
    "end": "1482559"
  },
  {
    "text": "take likes to do this but um I like to get everything returned to",
    "start": "1482559",
    "end": "1488559"
  },
  {
    "text": "me so we're going to map over them we take all the existing TS and vectors uh and we return uh both the torque the",
    "start": "1488559",
    "end": "1494440"
  },
  {
    "text": "vector and then the cosine similarity of the new query vector with all those",
    "start": "1494440",
    "end": "1500000"
  },
  {
    "text": "vectors um and then we'll need need to sort uh and that will do that and we'll",
    "start": "1500000",
    "end": "1507240"
  },
  {
    "text": "slice as well yeah sure um so we're going to we're going to map over them we're going to return the cosine",
    "start": "1507240",
    "end": "1512520"
  },
  {
    "text": "similarity of the new query Vector against all our existing torque vectors uh we'll sort them by the highest",
    "start": "1512520",
    "end": "1519159"
  },
  {
    "text": "similarity and then slice by a limit uh which by default this five here when we",
    "start": "1519159",
    "end": "1524399"
  },
  {
    "text": "do that uh I can go back to my chat here",
    "start": "1524399",
    "end": "1529720"
  },
  {
    "text": "actually I have a I have a search um interface as well which is not doing a chat it's just literally asking for the",
    "start": "1529720",
    "end": "1537399"
  },
  {
    "text": "uh for our search for that um this function we made this find similar talk and so if I ask about generative",
    "start": "1537399",
    "end": "1544360"
  },
  {
    "text": "generative Ai and rag um then we get answers like can",
    "start": "1544360",
    "end": "1551039"
  },
  {
    "text": "gener the world disability inclusive I do hope so by Donny de clerk uh",
    "start": "1551039",
    "end": "1556520"
  },
  {
    "text": "similarity score of 043 there um AI versus Humans a similarity score",
    "start": "1556520",
    "end": "1561559"
  },
  {
    "text": "of3 F enough my one doesn't come up I'm sure I did something for that if I just search for a",
    "start": "1561559",
    "end": "1567679"
  },
  {
    "text": "retrieval augmented generation because no one else is actually talking directly about that",
    "start": "1567679",
    "end": "1573880"
  },
  {
    "text": "then my talk comes up as a as a similarity of 0 24 and so we've created this uh this Vector uh and so in this",
    "start": "1573880",
    "end": "1581200"
  },
  {
    "text": "case if I now go and ask the chatbot so this is actually doing the rest of the we've done the search there uh the rest",
    "start": "1581200",
    "end": "1586799"
  },
  {
    "text": "of the augmention augment ation and generation if I say um who is",
    "start": "1586799",
    "end": "1593360"
  },
  {
    "text": "talking about retrieval retrieval augmented",
    "start": "1593360",
    "end": "1600080"
  },
  {
    "text": "generation question mark but um it answers it knows ha hooray fil is talking about retrieved generation rag",
    "start": "1600080",
    "end": "1607799"
  },
  {
    "text": "um and if I was to ask you know uh let's clear that chat just so it doesn't have",
    "start": "1607799",
    "end": "1613039"
  },
  {
    "text": "any memory of it like what is fil Nash speaking about",
    "start": "1613039",
    "end": "1618440"
  },
  {
    "text": "which is the question I started with uh it's going to say fin session is titled build rag from scratch uh so we've built",
    "start": "1618440",
    "end": "1624919"
  },
  {
    "text": "a really bad Vector there it's a sparse Vector made up of just uh adding up numbers of words uh based on all of the",
    "start": "1624919",
    "end": "1632360"
  },
  {
    "text": "words that we've seen But it sort of has this capability still even with low kind",
    "start": "1632360",
    "end": "1637520"
  },
  {
    "text": "of similarity scores uh to uh augment Our Generation enough uh to make it",
    "start": "1637520",
    "end": "1644960"
  },
  {
    "text": "actually useful it sort of works um and I think for me it's this idea of like",
    "start": "1644960",
    "end": "1651880"
  },
  {
    "text": "taking a making up our own Vector in the most simple way possible by just adding word scores together um sorry adding",
    "start": "1651880",
    "end": "1659799"
  },
  {
    "text": "word counts into a vector and doing that comparison using cosign similarity um",
    "start": "1659799",
    "end": "1667440"
  },
  {
    "text": "that it's relatively it's kind of that made it click for me it's straightforward enough to",
    "start": "1667440",
    "end": "1673559"
  },
  {
    "text": "say um talks that share the same words are sort of similar",
    "start": "1673559",
    "end": "1678640"
  },
  {
    "text": "to the query or to other talks but it is a very sort of right like no one is using this in in in the",
    "start": "1678640",
    "end": "1685880"
  },
  {
    "text": "real world I really hope not anyway firstly because we need to know all that data up front like I had to know all of",
    "start": "1685880",
    "end": "1691640"
  },
  {
    "text": "those talks in order to create my um vocabulary and be able to generate the",
    "start": "1691640",
    "end": "1697159"
  },
  {
    "text": "vectors for all of them um it it kind of it's sensitive to",
    "start": "1697159",
    "end": "1702320"
  },
  {
    "text": "the vocabulary so like when I asked about generative AI um uh a talk with",
    "start": "1702320",
    "end": "1708120"
  },
  {
    "text": "with Gen AI in the in the description is only going to match on the word Ai and not gen and generative and that actually",
    "start": "1708120",
    "end": "1714600"
  },
  {
    "text": "happens in this particular set of data um it's also the case that if you use words that have not been seen um in",
    "start": "1714600",
    "end": "1722919"
  },
  {
    "text": "the set of words already then you can never kind of compare against those uh so that's not very useful either we can",
    "start": "1722919",
    "end": "1728960"
  },
  {
    "text": "only really get that similarity based on the 2,938 words that we looked at but if you were to uh kind of",
    "start": "1728960",
    "end": "1737480"
  },
  {
    "text": "continue to increase this and use all talks that have ever been given at any conference ever uh you're probably just going to have more words a bigger Vector",
    "start": "1737480",
    "end": "1745039"
  },
  {
    "text": "more calculations the whole thing's going to slow down uh which is not great either um and of course the same word",
    "start": "1745039",
    "end": "1752039"
  },
  {
    "text": "can mean different things uh if we talk about something that's generative or if I'm talking about something that's",
    "start": "1752039",
    "end": "1757519"
  },
  {
    "text": "generative I'm probably talking about AI uh but uh it could be something biological where you things are",
    "start": "1757519",
    "end": "1763799"
  },
  {
    "text": "generating being created it could be something else um and even just order of words uh the idea that",
    "start": "1763799",
    "end": "1771360"
  },
  {
    "text": "um a classic example I think of this is that the difference between man bites dog and dog bites man uh is uh is fairly",
    "start": "1771360",
    "end": "1779159"
  },
  {
    "text": "significant um men should not be biting dogs dogs I dogs should nobody should be biing anybody",
    "start": "1779159",
    "end": "1785559"
  },
  {
    "text": "but um the the shock value of one is slightly more than the other at least um",
    "start": "1785559",
    "end": "1791840"
  },
  {
    "text": "and so uh none of that is kind of captured in this word counting this bag of words kind of model that I've",
    "start": "1791840",
    "end": "1799640"
  },
  {
    "text": "used and so that brings us to uh the way that we really do it in real life which is embedding models um so as part of uh",
    "start": "1799640",
    "end": "1808720"
  },
  {
    "text": "as part of sort of the training of of large language models uh the the um the",
    "start": "1808720",
    "end": "1815519"
  },
  {
    "text": "way that uh we break down incoming text to it in the training data is to turn them into uh tokens so in this case",
    "start": "1815519",
    "end": "1822640"
  },
  {
    "text": "we've kind of made a word a token in our in our",
    "start": "1822640",
    "end": "1828360"
  },
  {
    "text": "in our creation of a of of a simple Vector uh but there are more complicated ways of turning words into tokens um and",
    "start": "1828360",
    "end": "1836640"
  },
  {
    "text": "then turning those tokens into meaning uh based on uh yeah other machine",
    "start": "1836640",
    "end": "1842240"
  },
  {
    "text": "learning models those models learn from all that data uh",
    "start": "1842240",
    "end": "1847320"
  },
  {
    "text": "to create yeah this this dimensional space that has that meaning embedded",
    "start": "1847320",
    "end": "1852720"
  },
  {
    "text": "within it uh these models started off as simple like words to vectors I think it was around 2016 when Google came out",
    "start": "1852720",
    "end": "1859840"
  },
  {
    "text": "with word to VC which was a a simple embedding model that um yeah just did",
    "start": "1859840",
    "end": "1866080"
  },
  {
    "text": "one word at a time but that has been improved upon a model has been built where uh larger amounts of text can be",
    "start": "1866080",
    "end": "1872600"
  },
  {
    "text": "turned into a vector embedding now the size of the amount of text that you want to uh turn into a vector is another",
    "start": "1872600",
    "end": "1879720"
  },
  {
    "text": "interesting part of this and I back to that later but uh embedding models are",
    "start": "1879720",
    "end": "1885039"
  },
  {
    "text": "now kind of available to be used they're either open source ones available on",
    "start": "1885039",
    "end": "1890120"
  },
  {
    "text": "things like hugging face or all of the uh many of the large scale um language",
    "start": "1890120",
    "end": "1896120"
  },
  {
    "text": "model providers will also have embedding models as well that have been used as part of that training now it doesn't matter what embedding model you use uh",
    "start": "1896120",
    "end": "1905120"
  },
  {
    "text": "compared to the language model that you're going to use because they actually never kind of touch each other so it doesn't matter you can mix and",
    "start": "1905120",
    "end": "1910960"
  },
  {
    "text": "match uh using embeddings from open AI to uh talk to a a model from Google or",
    "start": "1910960",
    "end": "1916960"
  },
  {
    "text": "anthropic or whoever ever um but most of them are you know a straightforward is",
    "start": "1916960",
    "end": "1922000"
  },
  {
    "text": "calling an API Rec an API method like this and open AI kind of API simple enough to say hey use the text embedding",
    "start": "1922000",
    "end": "1929039"
  },
  {
    "text": "3 small model which is up here uh with this input uh get a encoding format of",
    "start": "1929039",
    "end": "1934559"
  },
  {
    "text": "float there aren't any others but you have to see it uh and you get the embedding back and uh in this particular",
    "start": "1934559",
    "end": "1940639"
  },
  {
    "text": "case text embedding three small gives us 1536 Dimensions uh and that's always that's a fixed 1536 dimensions in which",
    "start": "1940639",
    "end": "1948480"
  },
  {
    "text": "uh the uh the space and its meaning kind of exists texing 3 large uh has",
    "start": "1948480",
    "end": "1955399"
  },
  {
    "text": "3,072 U Dimensions double the size um weirdly enough it doesn't necessarily",
    "start": "1955399",
    "end": "1961720"
  },
  {
    "text": "matter that uh uh it mat so text iding 3 large is a",
    "start": "1961720",
    "end": "1967080"
  },
  {
    "text": "larger model and so is is more nuanced about how it places meaning into a vector space uh however there is also",
    "start": "1967080",
    "end": "1974760"
  },
  {
    "text": "the case that you can lose meaning with more Dimensions as well it's very confusing uh I'm not going to",
    "start": "1974760",
    "end": "1981240"
  },
  {
    "text": "go too deep into that though because the theory of uh of of dimensionality is",
    "start": "1981240",
    "end": "1986679"
  },
  {
    "text": "beyond me uh today I'm afraid I didn't mention but I flew from Melbourne yesterday uh so I'm asleep right now",
    "start": "1986679",
    "end": "1995600"
  },
  {
    "text": "um uh so we can create embeddings uh this way this is nice and easy otherwise",
    "start": "1995600",
    "end": "2001200"
  },
  {
    "text": "yeah if you you can use an open source metal model by uh dragging it in from hugging face and running it with something like a Transformers um uh",
    "start": "2001200",
    "end": "2009080"
  },
  {
    "text": "library that will work and once we have these embeddings the other side of things is uh we don't really want to",
    "start": "2009080",
    "end": "2016600"
  },
  {
    "text": "spend a lot of time calculating uh cosine similarity for everything every single time that's a that's a bad it's",
    "start": "2016600",
    "end": "2022399"
  },
  {
    "text": "going to be a bad time actually works nicely and quickly when you only have a 100 cosine similarities to calculate uh",
    "start": "2022399",
    "end": "2028440"
  },
  {
    "text": "in my example there but if we bril that up to a few thousand tens of thousands hundreds of thousands depending on how",
    "start": "2028440",
    "end": "2034039"
  },
  {
    "text": "many documents you have uh we absolutely don't want to put Javascript or any language through the pain of doing",
    "start": "2034039",
    "end": "2039279"
  },
  {
    "text": "cosine similarity over 100,000 documents every time and so that's where Vector databases come into play um although I",
    "start": "2039279",
    "end": "2047399"
  },
  {
    "text": "think this is kind of interesting I I've put Vector databases on the slide but effectively every database that I can",
    "start": "2047399",
    "end": "2053878"
  },
  {
    "text": "think of these days has what what we consider a vector index and that's more",
    "start": "2053879",
    "end": "2058960"
  },
  {
    "text": "uh accurate here uh some databases were built Vector first uh but uh since this",
    "start": "2058960",
    "end": "2064760"
  },
  {
    "text": "has been a Hot Topic um every other day database has kind of added a vector index and I think that's kind of",
    "start": "2064760",
    "end": "2070158"
  },
  {
    "text": "interesting because um creating a brand new database uh today has got to be",
    "start": "2070159",
    "end": "2076079"
  },
  {
    "text": "harder than adding a A specialized index to an already battle hardened database",
    "start": "2076079",
    "end": "2081440"
  },
  {
    "text": "uh and so that's something to compare when dealing with Vector databases or vector indexes uh as I said I work at um",
    "start": "2081440",
    "end": "2087118"
  },
  {
    "text": "data Stacks we have astb it's a it's a cloud-based database that's based uh on",
    "start": "2087119",
    "end": "2092240"
  },
  {
    "text": "Apache Cassandra underneath it uh with a vector index that we added",
    "start": "2092240",
    "end": "2098280"
  },
  {
    "text": "um and is actually available these days in open source Cassandra as well uh I'm",
    "start": "2098280",
    "end": "2103520"
  },
  {
    "text": "also not a fan of writing Cassandra query language so I like astrab because",
    "start": "2103520",
    "end": "2109160"
  },
  {
    "text": "it's a document store it deals with things that way uh and so if you uh in this particular example if you want to",
    "start": "2109160",
    "end": "2114800"
  },
  {
    "text": "add a a document and some Vector embeddings into astb uh you can do so by",
    "start": "2114800",
    "end": "2120680"
  },
  {
    "text": "just uh taking a collection and inserting both the content and using then the special dollar Vector uh property uh and passing in that list of",
    "start": "2120680",
    "end": "2127839"
  },
  {
    "text": "numbers uh that will allow you to then uh do a uh similarity search on that Vector column uh based on content um",
    "start": "2127839",
    "end": "2136320"
  },
  {
    "text": "other things I think Vector databases can do is uh is to handle some of that embedding for you and actually astb will do that as well uh you can set up a",
    "start": "2136320",
    "end": "2143400"
  },
  {
    "text": "collection with an embedding model uh and then uh if you pass the content in as dollar vectorize and the",
    "start": "2143400",
    "end": "2150560"
  },
  {
    "text": "content you want to turn into a vector then the database can handle it for you and I kind of think that's nice uh",
    "start": "2150560",
    "end": "2155920"
  },
  {
    "text": "because then when you come to search it again you don't have to to do the make an embedding find an embedding um you",
    "start": "2155920",
    "end": "2161319"
  },
  {
    "text": "can actually just kind of vectorize the uh the query on its way in as well nothing stopping you of course uh using",
    "start": "2161319",
    "end": "2166800"
  },
  {
    "text": "your own vector embeddings and uh Ash DB doesn't have every Vector embedding",
    "start": "2166800",
    "end": "2171920"
  },
  {
    "text": "provider available to it uh but um that's just a kind of nice easy way I think to uh to work with this and so",
    "start": "2171920",
    "end": "2179000"
  },
  {
    "text": "when you do that um we can actually get much better uh examples or much better",
    "start": "2179000",
    "end": "2184760"
  },
  {
    "text": "results U so I have a already prepared uh Vector search uh so this is um this",
    "start": "2184760",
    "end": "2192160"
  },
  {
    "text": "is the same function uh as we had before find a similar talk but in this case uh",
    "start": "2192160",
    "end": "2197480"
  },
  {
    "text": "it is now using um uh the vector database in the background Astro DB and so this is the uh uh this is that",
    "start": "2197480",
    "end": "2204680"
  },
  {
    "text": "collection uh for our NDC London data it's been set up with uh that open AI texting wedding three small speaking of",
    "start": "2204680",
    "end": "2212319"
  },
  {
    "text": "small things so is that text um text edding three small uh so it has 1536 dimension s uh and we can see the",
    "start": "2212319",
    "end": "2219440"
  },
  {
    "text": "content is all here it's actually easier to see in Json mode so there's modern observability and event driven",
    "start": "2219440",
    "end": "2224720"
  },
  {
    "text": "architectures by m Ian Cooper that's going to be a great talk actually um uh things about opfs uh and in this",
    "start": "2224720",
    "end": "2233160"
  },
  {
    "text": "case again because um because the database is actually handling the vectorization for Stuff uh I can search",
    "start": "2233160",
    "end": "2238319"
  },
  {
    "text": "for generative Ai and rag right here in the uh interface and uh and that's doing",
    "start": "2238319",
    "end": "2244560"
  },
  {
    "text": "a similarity search and so when it finishes um we'll see that the top one is yeah",
    "start": "2244560",
    "end": "2251200"
  },
  {
    "text": "right build drag from scratch oops uh build drag from scratch that's me and then the second one according to this uh",
    "start": "2251200",
    "end": "2257160"
  },
  {
    "text": "Vector embedding uh this kind of thing is can AI make the world of disability inclusive yeah cool that actually came",
    "start": "2257160",
    "end": "2262800"
  },
  {
    "text": "up earlier when I was doing it with our old and bad Vector version um so yeah",
    "start": "2262800",
    "end": "2268200"
  },
  {
    "text": "and we can see those different similarities uh like mine is the most similar at 831 and then it drops to",
    "start": "2268200",
    "end": "2274000"
  },
  {
    "text": "about 75 uh and as you get below seven things start to get a little normally a",
    "start": "2274000",
    "end": "2279520"
  },
  {
    "text": "little bit less uh um interesting so 68 there is ah can you trust your large",
    "start": "2279520",
    "end": "2284960"
  },
  {
    "text": "language model that is a that's a great talk actually by by jod go see that too",
    "start": "2284960",
    "end": "2290280"
  },
  {
    "text": "um uh but they start to become less about like retrieval less about search just more about AI in general and then",
    "start": "2290280",
    "end": "2295960"
  },
  {
    "text": "drops off further from there uh and so now uh that hold on if I go back to my server",
    "start": "2295960",
    "end": "2303880"
  },
  {
    "text": "and I replace my bag of words there uh with the vector search version that",
    "start": "2303880",
    "end": "2310440"
  },
  {
    "text": "will restart the server uh and if I go to the go to the similarity search I can go generative a rag and that should uh",
    "start": "2310440",
    "end": "2318440"
  },
  {
    "text": "return my talk yeah that's that's what we just that's the exact same search we just did in the interface now we can see",
    "start": "2318440",
    "end": "2323680"
  },
  {
    "text": "it uh in just my version of the interface um but if I talk about uh",
    "start": "2323680",
    "end": "2329839"
  },
  {
    "text": "artificial artificial intelligence uh we can see different",
    "start": "2329839",
    "end": "2335480"
  },
  {
    "text": "things so we got um Steve Sanders keynote I think that's tomorrow morning never remember 75 we got AI for humans",
    "start": "2335480",
    "end": "2343720"
  },
  {
    "text": "uh AI in video games uh and the nice thing about this is being I search for artificial intelligence but none of",
    "start": "2343720",
    "end": "2349119"
  },
  {
    "text": "these actually have artificial intelligence because nobody needs to write all of that uh anymore uh they're all just AI but the word the words",
    "start": "2349119",
    "end": "2356079"
  },
  {
    "text": "artificial intelligence are embedded into the same space as the shortening Ai and that's why all those things come up",
    "start": "2356079",
    "end": "2362880"
  },
  {
    "text": "and that uh then says uh means that you can say who is speaking",
    "start": "2362880",
    "end": "2368240"
  },
  {
    "text": "about AI uh and we'll get a bunch of answers I'm going returning uh five from",
    "start": "2368240",
    "end": "2374880"
  },
  {
    "text": "the database here so it's come up with five things yeah Steve Sanderson keynote Michelle Frost about",
    "start": "2374880",
    "end": "2381920"
  },
  {
    "text": "yeah Scott hamers yeah that's this morning's one Lela about that in games and Ai co-pilots and aircraft horrifying",
    "start": "2381920",
    "end": "2391319"
  },
  {
    "text": "um probably a very interesting talk I think that's tomorrow as well um and so",
    "start": "2391319",
    "end": "2396400"
  },
  {
    "text": "uh and I'm Waking out like what is Nash Phil Nash speaking about and we should",
    "start": "2396400",
    "end": "2402560"
  },
  {
    "text": "still get the same answer but it should be a lot more confident about it this time because um that that was now a",
    "start": "2402560",
    "end": "2408880"
  },
  {
    "text": "similarity of 083 we're not feeding those similarity scores to the large language model we're just feeding the",
    "start": "2408880",
    "end": "2413920"
  },
  {
    "text": "context and letting it decide based on the query and the context uh what it",
    "start": "2413920",
    "end": "2419079"
  },
  {
    "text": "wants to answer with so it doesn't have to know how sure it should be based on those similarity scores uh it's doing",
    "start": "2419079",
    "end": "2426079"
  },
  {
    "text": "the working out itself um",
    "start": "2426079",
    "end": "2431240"
  },
  {
    "text": "cool so that's kind of retrieval augmented gener retrieval augmented Generation Um I mentioned earlier that",
    "start": "2431240",
    "end": "2437640"
  },
  {
    "text": "like the size of the text that you might um uh that you might want to turn into a",
    "start": "2437640",
    "end": "2443760"
  },
  {
    "text": "vector embedding is important uh see it's not been important for these talks in this case um because most of the talk",
    "start": "2443760",
    "end": "2450040"
  },
  {
    "text": "descriptions are fairly short um so some of these Vector embedding models actually have limitations sorry all of the vector",
    "start": "2450040",
    "end": "2456560"
  },
  {
    "text": "embedding models have limitations on how uh many tokens they can um uh turn into",
    "start": "2456560",
    "end": "2463079"
  },
  {
    "text": "an embedding and normally they either uh fail or drop off anything beyond their maximum uh but I think like the open AI",
    "start": "2463079",
    "end": "2471880"
  },
  {
    "text": "text edding three small and large can have up to I think 8,000 tokens which is",
    "start": "2471880",
    "end": "2477359"
  },
  {
    "text": "about five or 6,000 Words which is a lot um but you don't",
    "start": "2477359",
    "end": "2483319"
  },
  {
    "text": "necessarily want to uh go to the limits of these models either you see when we do um when we when we take text and uh",
    "start": "2483319",
    "end": "2492000"
  },
  {
    "text": "store it for retrieval augmented generation purposes we actually really need to turn that text into a bunch of",
    "start": "2492000",
    "end": "2497680"
  },
  {
    "text": "ideas Concepts uh that the large language model can ultimately use uh to",
    "start": "2497680",
    "end": "2503560"
  },
  {
    "text": "answer a question if you take too much text uh then um uh that's trying to",
    "start": "2503560",
    "end": "2510280"
  },
  {
    "text": "capture too many Concepts it's actually going to um it's it's spreading that piece of text among",
    "start": "2510280",
    "end": "2517240"
  },
  {
    "text": "amongst the kind of vector space uh that meaning space that we had which might make it ultimately less similar to a",
    "start": "2517240",
    "end": "2524319"
  },
  {
    "text": "targeted question about a single part of it and so it's actually important to consider uh the amount of text that you",
    "start": "2524319",
    "end": "2531319"
  },
  {
    "text": "uh uh not just the amount but kind of how you break up the text in terms of uh",
    "start": "2531319",
    "end": "2536359"
  },
  {
    "text": "talk descriptions they are fairly you know around a single point the point of what we're going to talk about in the",
    "start": "2536359",
    "end": "2541880"
  },
  {
    "text": "conference but if you take a a document uh that is um 10,000 words long then you",
    "start": "2541880",
    "end": "2547760"
  },
  {
    "text": "might want to break that up into the paragraphs that it has maybe each paragraph would be a a concept an idea",
    "start": "2547760",
    "end": "2554319"
  },
  {
    "text": "or a bit of context uh so that's kind of interesting as well we have both the the limits of of vector embeddings uh but",
    "start": "2554319",
    "end": "2561720"
  },
  {
    "text": "also um the limits of the embedding space to understand uh the chunks of",
    "start": "2561720",
    "end": "2567200"
  },
  {
    "text": "text as well um I got far too into uh chunking up data for text and wrote an",
    "start": "2567200",
    "end": "2573520"
  },
  {
    "text": "entire blog post about this and how to how many how there are many different ways of going about that um which I",
    "start": "2573520",
    "end": "2579480"
  },
  {
    "text": "haven't actually linked on these slides but I will share out um with them uh so yeah so I wanted to to cover",
    "start": "2579480",
    "end": "2586319"
  },
  {
    "text": "that just because I think it's interesting um which I think is also a weird thing to say because taking a",
    "start": "2586319",
    "end": "2591520"
  },
  {
    "text": "large amount of text and turning into chunks of text sounds like the least interesting thing but uh when we're",
    "start": "2591520",
    "end": "2596960"
  },
  {
    "text": "doing it in order to feed context to a model it is absolutely fascinating the ways you can go about it are really",
    "start": "2596960",
    "end": "2603240"
  },
  {
    "text": "interesting too and so that's Ral augmented generation we're going to store our data in chunks normally if we",
    "start": "2603240",
    "end": "2609480"
  },
  {
    "text": "don't already have small bits of focused data like I happen to have in these talks uh we're going to store them",
    "start": "2609480",
    "end": "2615319"
  },
  {
    "text": "alongside uh their Vector embeddings uh we're going to use good dense Vector embeddings that actually capture meaning",
    "start": "2615319",
    "end": "2621800"
  },
  {
    "text": "better based on machine learning models there are many of them available and they do uh have varying qualities uh",
    "start": "2621800",
    "end": "2630839"
  },
  {
    "text": "there are leaderboards on on some of them uh sorry there are leaderboards in which you can kind of compare uh in Bing",
    "start": "2630839",
    "end": "2637319"
  },
  {
    "text": "models for how good they are uh although it still actually at the end of the day tends to uh matter like what the subject",
    "start": "2637319",
    "end": "2643960"
  },
  {
    "text": "is things like open AI text embedding three uh models are um good General",
    "start": "2643960",
    "end": "2649359"
  },
  {
    "text": "models uh but um there's a there's one company called Voyage who do um who actually train specific embedding models",
    "start": "2649359",
    "end": "2656079"
  },
  {
    "text": "for things like law uh and medicine I think uh and so if you happen to be in",
    "start": "2656079",
    "end": "2661319"
  },
  {
    "text": "those areas then like a specifically trained embeding model is actually really useful for you um we store our",
    "start": "2661319",
    "end": "2667640"
  },
  {
    "text": "embedding models uh we sorry we store our uh our content and our our vectors",
    "start": "2667640",
    "end": "2673079"
  },
  {
    "text": "uh and then when we get that user input we can vectorize using the same model uh",
    "start": "2673079",
    "end": "2678760"
  },
  {
    "text": "sort return the amount of context that we want to hand that over to our model",
    "start": "2678760",
    "end": "2684440"
  },
  {
    "text": "and uh and generate results I also want to point out that um I think it's really interesting I've been using uh Google's",
    "start": "2684440",
    "end": "2690599"
  },
  {
    "text": "Gemini 1.5 flash uh in this talk for my example uh 1.5 flash is both fairly",
    "start": "2690599",
    "end": "2696720"
  },
  {
    "text": "quick and very cheap to use but it's quite good at what it does um and it's",
    "start": "2696720",
    "end": "2701920"
  },
  {
    "text": "very good at that synthesizing of of context into an answer but uh it's not",
    "start": "2701920",
    "end": "2707800"
  },
  {
    "text": "the newest thing Google is experimenting with flash version two uh which is not quite sort of fully released yet there's",
    "start": "2707800",
    "end": "2713240"
  },
  {
    "text": "an experimental version but obviously the world has been rocked in the last week or whatever by by Deep seek and and",
    "start": "2713240",
    "end": "2720400"
  },
  {
    "text": "new models and these thinking models and they're cheaper and most and and incredible and I just um earlier I was",
    "start": "2720400",
    "end": "2726119"
  },
  {
    "text": "just like can I can I put deep seek into this application what would it would do um so the answer was almost yes I",
    "start": "2726119",
    "end": "2733079"
  },
  {
    "text": "haven't signed up for the Deep seek API where you can access their full R1 model which is 678 billion parameters or",
    "start": "2733079",
    "end": "2740319"
  },
  {
    "text": "something and requires Hefty pieces of Machinery to run uh but I do have a llama and I was able to download uh deep",
    "start": "2740319",
    "end": "2747640"
  },
  {
    "text": "seek 7B uh which is based on uh the quen 2.5",
    "start": "2747640",
    "end": "2753400"
  },
  {
    "text": "model from Alibaba uh I think if you were watching handsman keyot this morning he used the the Deep seek 8B",
    "start": "2753400",
    "end": "2760119"
  },
  {
    "text": "model which is actually based on meta's llama uh but I was able to yeah uh",
    "start": "2760119",
    "end": "2765599"
  },
  {
    "text": "actually replace that section with",
    "start": "2765599",
    "end": "2771160"
  },
  {
    "text": "this now using deep c car one not the fullsize Deep c car one but",
    "start": "2771160",
    "end": "2778520"
  },
  {
    "text": "uh that one and so in this case we're doing the same thing I'm still doing the search against the vector database and",
    "start": "2778520",
    "end": "2785079"
  },
  {
    "text": "handing the contents uh the context over to the model but now our model's different and so deep seek is is",
    "start": "2785079",
    "end": "2791119"
  },
  {
    "text": "particularly characterized by its thinking part which actually will come out uh here as well so I've passed it",
    "start": "2791119",
    "end": "2797559"
  },
  {
    "text": "the context and it's going to think about it um it's going to think about",
    "start": "2797559",
    "end": "2803240"
  },
  {
    "text": "it did I break it no there we go right so it's doing its thinking you see it's little think tag there okay G to try and",
    "start": "2803240",
    "end": "2810480"
  },
  {
    "text": "understand what he's going to talk about but it's got the context already and so this is actually really good at doing it",
    "start": "2810480",
    "end": "2816359"
  },
  {
    "text": "hey he know knows it's uh it knows it's related to Lage models so it's doing a lot of thinking it's still thinking so",
    "start": "2816359",
    "end": "2823280"
  },
  {
    "text": "there's a lot of thinking to be done in these um models because these are the reasoning models they're not actually necessarily built for um question and",
    "start": "2823280",
    "end": "2830520"
  },
  {
    "text": "answer kind of sessions like this uh but it still works very well so it's ended thinking there and now it's saying hey",
    "start": "2830520",
    "end": "2838079"
  },
  {
    "text": "uh it's actually probably written out a uh a longer explanation of my talk than",
    "start": "2838079",
    "end": "2843720"
  },
  {
    "text": "I did which is thanks deep seek making me anyway um",
    "start": "2843720",
    "end": "2849839"
  },
  {
    "text": "point being uh in this particular case we don't necessarily need to use a reasoning model in order to do this kind",
    "start": "2849839",
    "end": "2855280"
  },
  {
    "text": "of thing but it's also important to consider that the model unless you are a company building models like this and",
    "start": "2855280",
    "end": "2861880"
  },
  {
    "text": "trying to sell models to other people or produce them as open source the model is never going to be uh your competitive",
    "start": "2861880",
    "end": "2868760"
  },
  {
    "text": "Advantage you should always be able to uh in this particular case like in the",
    "start": "2868760",
    "end": "2874160"
  },
  {
    "text": "cont I swapped out five lines of code here for 10 but some of that's just line breaks",
    "start": "2874160",
    "end": "2880880"
  },
  {
    "text": "and I had a brand new model using the exact same data uh and doing a very good job of it so uh our retrieval actually",
    "start": "2880880",
    "end": "2889559"
  },
  {
    "text": "is kind of the most important part of this and understanding vector embeddings and getting that bit right is more",
    "start": "2889559",
    "end": "2894800"
  },
  {
    "text": "important than our choice of models which will continue to evolve and improve over time uh and just in uh",
    "start": "2894800",
    "end": "2902040"
  },
  {
    "text": "improve that generation uh getting the r getting the retrieval part right uh",
    "start": "2902040",
    "end": "2907480"
  },
  {
    "text": "leads to good augmentation uh leads to better and better generation as the models improve and so that's kind of how",
    "start": "2907480",
    "end": "2914599"
  },
  {
    "text": "uh rag and and large language models can work together um to overcome those difficulties of large language models",
    "start": "2914599",
    "end": "2922440"
  },
  {
    "text": "overcome the fact that they have their training cut off data sorry their data is cut off at the end of their training",
    "start": "2922440",
    "end": "2927559"
  },
  {
    "text": "date they can't know private data uh and uh providing context like this also",
    "start": "2927559",
    "end": "2932960"
  },
  {
    "text": "avoids helps to avoid hallucinations and produces good useful",
    "start": "2932960",
    "end": "2939040"
  },
  {
    "text": "applications for us I do have some links uh for some uh deeper bits on this uh so",
    "start": "2939040",
    "end": "2945079"
  },
  {
    "text": "um the uh version of retrieval there is a QR code on the next slide which also",
    "start": "2945079",
    "end": "2950280"
  },
  {
    "text": "links through to all these as well but um uh what I described just now uh about",
    "start": "2950280",
    "end": "2956599"
  },
  {
    "text": "using a vector representation of a chunk of data and a vector representation of a query um is one way to do this uh but um",
    "start": "2956599",
    "end": "2965960"
  },
  {
    "text": "it does it can have difficulty when dealing with terms outside of its training data uh however um Colbert is a",
    "start": "2965960",
    "end": "2974440"
  },
  {
    "text": "uh is a method in which uh you actually um you vectorize every single word in a",
    "start": "2974440",
    "end": "2980480"
  },
  {
    "text": "piece of content uh a sliding window of context over the content and that is",
    "start": "2980480",
    "end": "2985559"
  },
  {
    "text": "actually really good at uh understanding stuff Beyond its training data uh but it",
    "start": "2985559",
    "end": "2990799"
  },
  {
    "text": "comes with the uh downside that um there's a lot more to store because you're doing a vector per word and",
    "start": "2990799",
    "end": "2997599"
  },
  {
    "text": "that's a lot harder to search against so there are there's tradeoffs and trade on for that uh but it's really interesting",
    "start": "2997599",
    "end": "3003559"
  },
  {
    "text": "I think uh read as to how uh how rag can be improved with Colbert that's kind of interesting then uh another way of um",
    "start": "3003559",
    "end": "3012400"
  },
  {
    "text": "making our retrieval better is to uh use kind of knowledge graphs uh graph rag is",
    "start": "3012400",
    "end": "3017520"
  },
  {
    "text": "has been a very popular term recently and the idea there is to extract links between pieces of context uh so that",
    "start": "3017520",
    "end": "3023280"
  },
  {
    "text": "when you do your initial um similari search based on the uh Vector embeddings",
    "start": "3023280",
    "end": "3029880"
  },
  {
    "text": "you can then use links to other bits of context to kind of fill in gaps that maybe you're um maybe weren't initially",
    "start": "3029880",
    "end": "3037760"
  },
  {
    "text": "relevant to the search but are relevant to the answer uh and so you can do that using content um there's a couple of",
    "start": "3037760",
    "end": "3043640"
  },
  {
    "text": "different kind of graphs you can do content Centric is kind of the idea of like links and keywords between things",
    "start": "3043640",
    "end": "3048799"
  },
  {
    "text": "uh you could use kind of uh entity recognition kind of stuff as well um but uh um the content Centric one works",
    "start": "3048799",
    "end": "3055119"
  },
  {
    "text": "really well and is a lot simpler uh to deal with and the idea is yeah pulling in extra context that's going to help it",
    "start": "3055119",
    "end": "3060520"
  },
  {
    "text": "answer the question is good uh and then just for other things you can do with um vector embeddings and Vector databases",
    "start": "3060520",
    "end": "3067760"
  },
  {
    "text": "uh is is one of the first things I did about astb which was to um just do a build a feature for my own blog where uh",
    "start": "3067760",
    "end": "3073960"
  },
  {
    "text": "uh using Vector search allows you to do um similar blog posts at the end of a story so you can keep people reading uh",
    "start": "3073960",
    "end": "3079960"
  },
  {
    "text": "I think that's a really nice usage of vector search that doesn't involve an llm uh and uh uh it work really nicely I used to do",
    "start": "3079960",
    "end": "3087359"
  },
  {
    "text": "it based on tag matching and that was okay but actual relevancy sorry actual",
    "start": "3087359",
    "end": "3092520"
  },
  {
    "text": "similarity was really cool um so as I said my slides and links are at that QR",
    "start": "3092520",
    "end": "3097559"
  },
  {
    "text": "code um thank you again for coming again um so retrieval augmented generation I",
    "start": "3097559",
    "end": "3102760"
  },
  {
    "text": "think is is going to be along for around for a long time with as long as generative AI is uh you might seem to",
    "start": "3102760",
    "end": "3108280"
  },
  {
    "text": "think one one final thing to say about this um uh large language models are",
    "start": "3108280",
    "end": "3113520"
  },
  {
    "text": "actually increasingly increasing the size of their content Windows uh and so like open AI models can take 128,000",
    "start": "3113520",
    "end": "3121559"
  },
  {
    "text": "tokens um Gemini flash is one and a half million Gemini 2 Flash and Gemini Pro",
    "start": "3121559",
    "end": "3128000"
  },
  {
    "text": "2.0 both take two million tokens I think um but retrieval augmented generation is",
    "start": "3128000",
    "end": "3133960"
  },
  {
    "text": "uh is really useful because when you feed that context uh you don't have to take up all those tokens tokens cost",
    "start": "3133960",
    "end": "3139079"
  },
  {
    "text": "money um and uh and the more targeted the context you provide a model uh the",
    "start": "3139079",
    "end": "3144880"
  },
  {
    "text": "better the results you get out of them and so rag is not going anywhere um it's really good to understand it I think",
    "start": "3144880",
    "end": "3150240"
  },
  {
    "text": "from the basis but uh hopefully this has given you a a great overview and understanding of how to how to go aart",
    "start": "3150240",
    "end": "3156480"
  },
  {
    "text": "with rag again my name is f Ash I'm a developer developer relations engineer at data Stacks uh and thank you so much",
    "start": "3156480",
    "end": "3163280"
  },
  {
    "text": "for [Applause]",
    "start": "3163280",
    "end": "3170038"
  },
  {
    "text": "coming and I will yeah I'm aware I'm around for the rest of the the conference so do come and find me um I",
    "start": "3171240",
    "end": "3177119"
  },
  {
    "text": "don't want to yeah it's the end of the day now so I'm sure we're a little tired I want to get out of here but I'll be I'm come up asking any questions anytime",
    "start": "3177119",
    "end": "3183960"
  },
  {
    "text": "now later whenever woo thank you",
    "start": "3183960",
    "end": "3188920"
  }
]
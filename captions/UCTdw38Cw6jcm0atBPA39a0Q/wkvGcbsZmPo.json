[
  {
    "text": "what's it what's up everybody good morning it's uh absolutely fantastic to be here in Porto it's really nice that",
    "start": "5359",
    "end": "10880"
  },
  {
    "text": "the sun comes out when we're supposed to be inside and it rains when we're supposed to be outside um it's entirely",
    "start": "10880",
    "end": "16720"
  },
  {
    "text": "per perfect um I only complain about that because after uh after yesterday I ended up going out for uh some some",
    "start": "16720",
    "end": "22720"
  },
  {
    "text": "drinks and dinner with people and then as I walked home uh enormous deluge of rain uh my feet are still wet um thank",
    "start": "22720",
    "end": "31039"
  },
  {
    "text": "you Porto it's been absolutely wonderful um uh good morning uh so my name is Sash i",
    "start": "31039",
    "end": "37360"
  },
  {
    "text": "am a developer relations engineer for a company called data stacks um data stacks uh is a um uh we are building an",
    "start": "37360",
    "end": "44320"
  },
  {
    "text": "AI platform as a service for you is we are putting together components that are going to help you uh build with",
    "start": "44320",
    "end": "49360"
  },
  {
    "text": "generative AI including Astrod which is a vector database and uh and and Langflow which is a visual builder uh",
    "start": "49360",
    "end": "56239"
  },
  {
    "text": "for things like uh generative AI uh I'm not going to use Langflow today although I do think it's very cool if you if you",
    "start": "56239",
    "end": "62320"
  },
  {
    "text": "like visualizing your flows and seeing how uh both data flows into a system but also how it flows uh through these kind",
    "start": "62320",
    "end": "68799"
  },
  {
    "text": "of generative AI apps uh then do please check it out uh it's also free and open source uh so that's uh that's a benefit",
    "start": "68799",
    "end": "75119"
  },
  {
    "text": "too i we should be making money at some point I guess but not right now so enjoy",
    "start": "75119",
    "end": "81000"
  },
  {
    "text": "um if you ever want to find me online I am Phil Nash pretty much everywhere uh Twitter my own website URL i mean that's",
    "start": "81000",
    "end": "89040"
  },
  {
    "text": "Look at it i've always been pleased that film now.sh exists uh and so I show it off at any",
    "start": "89040",
    "end": "94759"
  },
  {
    "text": "opportunity um cool so what are we talking about this morning uh uh we are",
    "start": "94759",
    "end": "100479"
  },
  {
    "text": "going to build uh Rag from scratch that's the idea uh and and gloriously",
    "start": "100479",
    "end": "105680"
  },
  {
    "text": "and thank you Jod for coming i very much enjoyed uh the keynote this morning and uh I'm very much glad you got to the bit",
    "start": "105680",
    "end": "110960"
  },
  {
    "text": "where it was useful at the end of the talk because there was a whole point in the middle of the keynote this morning",
    "start": "110960",
    "end": "116479"
  },
  {
    "text": "where I was just dumping my laptop on the ground and being like well there's no point in any of this at all it turns out uh that these",
    "start": "116479",
    "end": "123280"
  },
  {
    "text": "generative AI applications are indeed useful for the things they are useful for which is for generating language for",
    "start": "123280",
    "end": "128319"
  },
  {
    "text": "generating uh text uh and so uh we we absolutely discussed the problem with uh",
    "start": "128319",
    "end": "133760"
  },
  {
    "text": "large language models in that that one they're not very good at not language things and I really don't know why the entire industry is obsessed with how",
    "start": "133760",
    "end": "140480"
  },
  {
    "text": "many Rs there are in strawberry because it's not a useful problem to solve um or",
    "start": "140480",
    "end": "145840"
  },
  {
    "text": "if you need to solve that really easy ways to write code that will count the number of Rs in any letter any word uh",
    "start": "145840",
    "end": "152160"
  },
  {
    "text": "you want to um the problems with large models actually uh tend to be more in",
    "start": "152160",
    "end": "157680"
  },
  {
    "text": "the fact that uh these models exist uh in a in the time they were built and",
    "start": "157680",
    "end": "163840"
  },
  {
    "text": "with the data they were trained upon and so every one of these models has that training cutoff date where it no longer",
    "start": "163840",
    "end": "169760"
  },
  {
    "text": "knows anything from beyond that or no longer can guess anything beyond that uh and similarly will not be uh able to",
    "start": "169760",
    "end": "176720"
  },
  {
    "text": "tell you anything private uh that's fine that's useful for those public models but when you want to build an",
    "start": "176720",
    "end": "182720"
  },
  {
    "text": "application that's going to use these uh then using data that you own uh is going to give you that advantage uh and so uh",
    "start": "182720",
    "end": "190800"
  },
  {
    "text": "the problem is very much that they they just don't know stuff uh and uh and even the stuff they know they're kind of just",
    "start": "190800",
    "end": "196400"
  },
  {
    "text": "very good at guessing and getting right um yes uh my personal model of a large",
    "start": "196400",
    "end": "203040"
  },
  {
    "text": "language model in my head is very much that they are uh they are always guessing things and they just happen to be right most of the time and",
    "start": "203040",
    "end": "209120"
  },
  {
    "text": "hallucinations everything's a hallucination just most of them are correct which is incredible uh but has",
    "start": "209120",
    "end": "214959"
  },
  {
    "text": "the option for um being wrong uh so much of the time as well and so we want to",
    "start": "214959",
    "end": "220159"
  },
  {
    "text": "encourage these models to be right and encourage them to know stuff that we want to tell them because uh a model is",
    "start": "220159",
    "end": "226640"
  },
  {
    "text": "also any kind of large language model is not uh is never going to be our benefit like models keep improving uh there's",
    "start": "226640",
    "end": "233760"
  },
  {
    "text": "there's new models new fine tunes new versions of these kind of things every day every week uh and so our nobody's",
    "start": "233760",
    "end": "239280"
  },
  {
    "text": "competitive advantage will ever be the model because we can always get a new and better one next week our competitive",
    "start": "239280",
    "end": "245200"
  },
  {
    "text": "advantage with building this kind of stuff is our own data and so um just as",
    "start": "245200",
    "end": "250799"
  },
  {
    "text": "a I did want to show a little demo uh of like what our problem with this kind of stuff is let's go to Firefox um this is",
    "start": "250799",
    "end": "258239"
  },
  {
    "text": "Google AI studio uh in which um uh I have uh Gemini 1.5 Pro that I can talk",
    "start": "258239",
    "end": "265199"
  },
  {
    "text": "to and uh and if I ask it uh like I always find that you know for years and",
    "start": "265199",
    "end": "270240"
  },
  {
    "text": "years and years I know it says super self it's not right that's just a title it gave itself um for years and years",
    "start": "270240",
    "end": "275759"
  },
  {
    "text": "and years the important thing was to Google yourself to find out what Google thought of you um hands up if you've ever asked a a large language model of",
    "start": "275759",
    "end": "282720"
  },
  {
    "text": "if they know you yeah a few people yeah if I say who is who is Phil",
    "start": "282720",
    "end": "288040"
  },
  {
    "text": "Nash uh Gemini 1.5 Pro thinks I'm a well-known figure in the C++ community",
    "start": "288040",
    "end": "294000"
  },
  {
    "text": "that is not correct uh I'm also not a developer advocate at Jet Brains um I don't Phil I",
    "start": "294000",
    "end": "300800"
  },
  {
    "text": "actually did work with he is no longer a developer advocate at Jet Brains either uh we did previously work together at",
    "start": "300800",
    "end": "305919"
  },
  {
    "text": "Sonosource but it's not even going to mention that today um but uh yes",
    "start": "305919",
    "end": "311240"
  },
  {
    "text": "uh wrong incorrect uh and interesting enough if you change the model if you go to Gemini 1.5 flash which is a smaller",
    "start": "311240",
    "end": "317360"
  },
  {
    "text": "model but a nice quick one uh and um we can regenerate that with the new model it simply says please provide me with",
    "start": "317360",
    "end": "323600"
  },
  {
    "text": "more context about film mesh there are several people and it's he probably doesn't know anyway um which is",
    "start": "323600",
    "end": "330600"
  },
  {
    "text": "cool thanks Google uh so yeah so um large language models do not know who I am and that makes me sad uh more",
    "start": "330600",
    "end": "337600"
  },
  {
    "text": "importantly of course uh they also don't know like um what is happening at NDC",
    "start": "337600",
    "end": "342960"
  },
  {
    "text": "Porto in uh 2024 uh if we ask it that it will",
    "start": "342960",
    "end": "349120"
  },
  {
    "text": "generate stuff at the bottom of the page i don't have access to real time information to find out i recommend going on the official website i",
    "start": "349120",
    "end": "355320"
  },
  {
    "text": "mean I guess so um I like how helpful they are uh when they don't know uh but",
    "start": "355320",
    "end": "362320"
  },
  {
    "text": "the important thing is that they don't uh know and so what we want to do",
    "start": "362320",
    "end": "367759"
  },
  {
    "text": "ultimately is get them to know this stuff and uh and the way we can do that or at least um I think the primary",
    "start": "367759",
    "end": "373840"
  },
  {
    "text": "method uh which is useful is retrieval augmented generation um uh there is uh fine-tuning",
    "start": "373840",
    "end": "380000"
  },
  {
    "text": "models as well but in a world in which data changes often fine-tuning a model is inefficient because you have to keep",
    "start": "380000",
    "end": "385440"
  },
  {
    "text": "doing it whereas if we can just uh feed a model new data uh then it would yeah",
    "start": "385440",
    "end": "390960"
  },
  {
    "text": "it's better and quicker so retrieve augmented generation uh has a relatively simple idea um we store our data our",
    "start": "390960",
    "end": "398880"
  },
  {
    "text": "private data or whatever we have uh our up-to-date data somewhere we keep it up to date and then when a user makes a",
    "start": "398880",
    "end": "405600"
  },
  {
    "text": "query to a model we don't just straight ask the model uh we retrieve relevant data to that query we provide that data",
    "start": "405600",
    "end": "413120"
  },
  {
    "text": "as context to the model with that original query uh the model then generates a response",
    "start": "413120",
    "end": "419520"
  },
  {
    "text": "based on the stuff we told it uh and that I guess eventually profit no one's",
    "start": "419520",
    "end": "425759"
  },
  {
    "text": "got a uh a business idea for this yet I don't think but we'll get there we'll get that part the difficult part of this",
    "start": "425759",
    "end": "432319"
  },
  {
    "text": "uh the interesting part I think of this is actually this retrieving relevant data uh because calling a model is",
    "start": "432319",
    "end": "437360"
  },
  {
    "text": "actually fairly straightforward but retrieving relevant data is where we can actually dig in and find some interesting stuff um and like I've been",
    "start": "437360",
    "end": "444639"
  },
  {
    "text": "working at data stacks for about six months now i've never been a sort of data uh driven developer before i'm an application developer really uh and uh",
    "start": "444639",
    "end": "451840"
  },
  {
    "text": "and I find myself absolutely fascinated with the various ways that we can uh store and handle this data and retrieve",
    "start": "451840",
    "end": "457120"
  },
  {
    "text": "it and do different stuff with it so this is our basic idea how do we go about it",
    "start": "457120",
    "end": "462560"
  },
  {
    "text": "well so retrieval augmented generation as a as a kind of overall subject kind",
    "start": "462560",
    "end": "468160"
  },
  {
    "text": "of relates to this like our retrieval is is search is is being able to search the data that we have uh in a way that uh a",
    "start": "468160",
    "end": "475360"
  },
  {
    "text": "natural language query uh to our to our model uh might well work uh we then with",
    "start": "475360",
    "end": "481520"
  },
  {
    "text": "that context augment our prompt we just add uh more context to our prompt and then finally the generation is on the",
    "start": "481520",
    "end": "487680"
  },
  {
    "text": "model side and so for the most part of this we'll be talking about the sort of data side and the retrieval side uh",
    "start": "487680",
    "end": "493360"
  },
  {
    "text": "because the rest of it is kind of just asking a model something um and so search search is the important thing",
    "start": "493360",
    "end": "501599"
  },
  {
    "text": "here but search is something we've been doing for quite a long time uh however a",
    "start": "504360",
    "end": "510160"
  },
  {
    "text": "lot of that has been keyword based search that's fairly normal kind of things but when you are uh asking a",
    "start": "510160",
    "end": "516800"
  },
  {
    "text": "model something if you are talking with a chatbot or just generally dealing in natural language then keywords are not",
    "start": "516800",
    "end": "522719"
  },
  {
    "text": "uh our optimal solution for that that's not how we sort of naturally think uh I think you you you know when you are",
    "start": "522719",
    "end": "528640"
  },
  {
    "text": "talking with a model or interacting with a model uh is very different to interacting with the search box on on",
    "start": "528640",
    "end": "534080"
  },
  {
    "text": "Google or on Bing",
    "start": "534080",
    "end": "538680"
  },
  {
    "text": "um so we need a different way of getting this relevant data uh and so it's not",
    "start": "541000",
    "end": "546480"
  },
  {
    "text": "keyword search we actually want to search by similarity by meaning uh by what a user meant in their query and how",
    "start": "546480",
    "end": "552560"
  },
  {
    "text": "that relates to the data that we've already captured and the way we go about that well how do we how do we capture",
    "start": "552560",
    "end": "558959"
  },
  {
    "text": "meaning in a way that we can then search for with similar meaning um this leads us to the topic of vector",
    "start": "558959",
    "end": "566080"
  },
  {
    "text": "embeddings um yes uh vector embeddings um are our way vector embeddings allow",
    "start": "566080",
    "end": "572560"
  },
  {
    "text": "us to capture the meaning of uh of text andor other content although I'm going",
    "start": "572560",
    "end": "578240"
  },
  {
    "text": "to limit it to text within this talk but it counts for images it counts for audio counts for video you can embed kind of",
    "start": "578240",
    "end": "584399"
  },
  {
    "text": "anything if you find the right model for it uh vector embeddings capture the meaning of a piece of content such that",
    "start": "584399",
    "end": "592160"
  },
  {
    "text": "we can then capture the meaning of a query and find similar meanings how Does that work well first up right a vector",
    "start": "592160",
    "end": "598880"
  },
  {
    "text": "embedding is actually just a list of numbers really quite simple it's a list of floats um normally quite a long list",
    "start": "598880",
    "end": "605120"
  },
  {
    "text": "and it represents the meaning of a body of text um means a lot more than that but for now we're going to go ahead and",
    "start": "605120",
    "end": "611920"
  },
  {
    "text": "create our own vector embedding i'm not here to train a model we're going to do a really simple one uh that honestly",
    "start": "611920",
    "end": "618959"
  },
  {
    "text": "kind of uh put a light bulb on in my head the first time I saw this and this is why I wanted to give this talk we're going to create our own vector embedding",
    "start": "618959",
    "end": "625920"
  },
  {
    "text": "uh and we're going to do so using uh the contents of uh this conference uh as",
    "start": "625920",
    "end": "631200"
  },
  {
    "text": "we've already seen Gemini knows nothing about NDC Bordo 2024 aside from you should go to the website um and we're",
    "start": "631200",
    "end": "637600"
  },
  {
    "text": "going to teach at that and we're going to do so by uh creating our own virtual embedding model and performing similarity search on it and so our",
    "start": "637600",
    "end": "644959"
  },
  {
    "text": "hypothesis is for this for a bot that we want to ask questions about for this conference uh the titles and",
    "start": "644959",
    "end": "651360"
  },
  {
    "text": "descriptions contain sort of the meaning of the talk um hopefully that's worked and that you're in the right room",
    "start": "651360",
    "end": "659320"
  },
  {
    "text": "um no one left cool um those titles and descriptions are indeed made up of words",
    "start": "659320",
    "end": "665760"
  },
  {
    "text": "um useful uh and those titles and descriptions that it so the hypothesis is that if a title and description",
    "start": "665760",
    "end": "671519"
  },
  {
    "text": "shares you know similar words with another one then those talks are similar or if it shares similar words with",
    "start": "671519",
    "end": "677120"
  },
  {
    "text": "something you might be asking about it then that is sort of also similar and that's what we're going to go with and",
    "start": "677120",
    "end": "682720"
  },
  {
    "text": "so we can collect up all the words and then represent each talk effectively as",
    "start": "682720",
    "end": "688560"
  },
  {
    "text": "a long list of all words in all the talk titles and descriptions and uh each talk can be represented as this list of how",
    "start": "688560",
    "end": "695519"
  },
  {
    "text": "many words there are um how many of each word there are and when we get a user query we can do the same thing we can",
    "start": "695519",
    "end": "701279"
  },
  {
    "text": "take the query turn it into that same list of numbers about how many words there are in that query and uh compare",
    "start": "701279",
    "end": "708240"
  },
  {
    "text": "that's the idea so let's do it live code now I will apologize i'm",
    "start": "708240",
    "end": "713680"
  },
  {
    "text": "going to do this live code in JavaScript uh this doesn't matter what language you do it in but JavaScript is my language so um and I I recognize that this is",
    "start": "713680",
    "end": "721120"
  },
  {
    "text": "more of a C# kind of place but um I do have uh I have a little chat and a",
    "start": "721120",
    "end": "727120"
  },
  {
    "text": "search uh to test our our kind of results with not a full evaluation test I'm afraid but we're gonna we're gonna",
    "start": "727120",
    "end": "733760"
  },
  {
    "text": "vibe check it rather than anything else today um and so if I do ask my current bot um like what is Bill Nash talking",
    "start": "733760",
    "end": "743920"
  },
  {
    "text": "about I can type uh it um doesn't know we are running",
    "start": "745560",
    "end": "752880"
  },
  {
    "text": "aren't we yeah cool oh that's okay so that was the",
    "start": "752880",
    "end": "758320"
  },
  {
    "text": "search uh which returned zero results um this is not a good interface uh if I ask the bot uh what is FA speaking about it",
    "start": "758320",
    "end": "765519"
  },
  {
    "text": "won't know please provide me the context about NDC Porto and Bill Nash it has no context i have given a a system prompt",
    "start": "765519",
    "end": "771600"
  },
  {
    "text": "to say that you are a helpful uh NDC Portobot uh and you will tell me all the stuff I need to know about NDC Porto but",
    "start": "771600",
    "end": "777440"
  },
  {
    "text": "currently it knows nothing uh so it it it's good at telling me I don't know that so if we jump into actually should",
    "start": "777440",
    "end": "784320"
  },
  {
    "text": "make that bigger um if we jump into the uh uh actual code um it's it's",
    "start": "784320",
    "end": "790560"
  },
  {
    "text": "relatively simple on the kind of server side of things in which all we're going to do is uh we post a request to messages we're going to um get the query",
    "start": "790560",
    "end": "798160"
  },
  {
    "text": "and turn it into a uh find similar talk that's our that's our method that we're ultimately um implementing here and uh",
    "start": "798160",
    "end": "804880"
  },
  {
    "text": "and this is my prompt given the context above based on those similar talks uh try to answer the following question if",
    "start": "804880",
    "end": "810320"
  },
  {
    "text": "you can't don't worry about it uh and then we send it off to um the model I'm using here is Gemini 1.5 Flash uh it's",
    "start": "810320",
    "end": "817839"
  },
  {
    "text": "uh it's cheap but good um and I like that about it um and like you know it doesn't have as",
    "start": "817839",
    "end": "824639"
  },
  {
    "text": "much kind of inbuilt data to it so it's actually very good at like dealing with the stuff you tell it uh then we stream",
    "start": "824639",
    "end": "830320"
  },
  {
    "text": "the result out so it's it's really quite straightforward um but right now uh this is my uh existing code for this so far",
    "start": "830320",
    "end": "837519"
  },
  {
    "text": "all I have written so far is some some regular expressions which I encourage you never to write live in front of",
    "start": "837519",
    "end": "843040"
  },
  {
    "text": "people um uh because I wasn't going to get that right uh it's got some stuff which is",
    "start": "843040",
    "end": "848560"
  },
  {
    "text": "just going to basically it's stripping out uh punctuation uh common words and and uh stuff like that so what we're",
    "start": "848560",
    "end": "854720"
  },
  {
    "text": "going to all we're going to be left with is a bunch of um lowercase punctuationless stuff uh just to make",
    "start": "854720",
    "end": "860560"
  },
  {
    "text": "things slightly easier on me uh and then I load a big file called NDCJSON which has all of our talks",
    "start": "860560",
    "end": "868440"
  },
  {
    "text": "ndcjson this definitely exists there it is um has all the talk titles all the stuff uh our first one there is a",
    "start": "868440",
    "end": "875040"
  },
  {
    "text": "fabulous talk that I got to see yesterday being Staff Plus by Eden Cooper if you missed that fully recommend a rewatch when the videos come",
    "start": "875040",
    "end": "882120"
  },
  {
    "text": "out um cool so what have we got i've got a list of those talks brilliant so our",
    "start": "882120",
    "end": "887279"
  },
  {
    "text": "first thing I'm just going to get all the words out of those talks that's nice and easy um and to do so I'm going to uh",
    "start": "887279",
    "end": "893120"
  },
  {
    "text": "call on uh talks i'm going to map them flat map them so we get one array at the bottom of it uh and uh use the uh",
    "start": "893120",
    "end": "901480"
  },
  {
    "text": "existing function that we wrote up here function that's read up here text to words cool uh that actually is going to",
    "start": "901480",
    "end": "907760"
  },
  {
    "text": "give us an awfully long array of all of the words many times so I'm just going to uh make that",
    "start": "907760",
    "end": "913800"
  },
  {
    "text": "a unique array of those by turning it into a set and then turning that set into an array um because",
    "start": "913800",
    "end": "920839"
  },
  {
    "text": "JavaScript uh and if we look at that we can console.log out our all words uh and see",
    "start": "920839",
    "end": "928639"
  },
  {
    "text": "what we've got so at the bottom uh we've got a restarting server which you should be able to see and it's should be big enough and look at that lot of words",
    "start": "928639",
    "end": "937399"
  },
  {
    "text": "um can't do that with a compiler can you yeah how many",
    "start": "937399",
    "end": "942600"
  },
  {
    "text": "what's colons there's no colons in there i took them out um but like so we see",
    "start": "942600",
    "end": "948000"
  },
  {
    "text": "that the uh the talk here is stuff plus by Ian Cooper uh long period of time path organizations offer developers yes",
    "start": "948000",
    "end": "954320"
  },
  {
    "text": "uh so I've taken those stop words and kind of very common words out because if we compare things by common words that's",
    "start": "954320",
    "end": "960320"
  },
  {
    "text": "very boring so I want to compare by the interesting words uh and let's just have a look at how many words we have 1480",
    "start": "960320",
    "end": "966079"
  },
  {
    "text": "words so of five sessions I think we have no 101",
    "start": "966079",
    "end": "972240"
  },
  {
    "text": "sessions uh we have 1480 words uh aside from common words uh in them so our",
    "start": "972240",
    "end": "979120"
  },
  {
    "text": "vector is going to be 1480 words uh uh lengths long that's cool uh and so I",
    "start": "979120",
    "end": "985600"
  },
  {
    "text": "don't need that anymore i do need to now turn if I get a text in I need to turn it into a vector uh based on all of",
    "start": "985600",
    "end": "992480"
  },
  {
    "text": "those existing words so first up I'm going to create myself a word map",
    "start": "992480",
    "end": "997839"
  },
  {
    "text": "uh for the uh incoming talk uh and then I'm going to uh yeah get the words text",
    "start": "997839",
    "end": "1003839"
  },
  {
    "text": "of words of that uh and uh I'm going to map over those um word not word.trim but uh so we're",
    "start": "1003839",
    "end": "1012800"
  },
  {
    "text": "going to map over and uh yeah see I've got copilot also helping me which is great it saves a lot of typing if it",
    "start": "1012800",
    "end": "1019199"
  },
  {
    "text": "already knows what it's going to do if if a word is already in my word map then I will add one to it uh if it's not yet",
    "start": "1019199",
    "end": "1024798"
  },
  {
    "text": "in the word map it becomes one wonderful uh and then we're going to return uh",
    "start": "1024799",
    "end": "1031600"
  },
  {
    "text": "uh our all words array uh mapped with the words whether they are in the word",
    "start": "1031600",
    "end": "1036720"
  },
  {
    "text": "map or zero right so um we can actually we can look at the result of that as",
    "start": "1036720",
    "end": "1042079"
  },
  {
    "text": "well um so if I take a text vector of hello world yeah cool um very useless",
    "start": "1042079",
    "end": "1048640"
  },
  {
    "text": "zero results in it uh if I take the text vector of our first talk though",
    "start": "1048640",
    "end": "1054480"
  },
  {
    "text": "uh of Ian's talk uh we see that uh it pretty much um you know all it's very",
    "start": "1054480",
    "end": "1059840"
  },
  {
    "text": "front heavy because all the words in Ian's talk are in fact all the first ones we look at um if we look at talk 68",
    "start": "1059840",
    "end": "1067760"
  },
  {
    "text": "uh tell you why in a minute uh we find that one of these uh early words also",
    "start": "1067760",
    "end": "1072799"
  },
  {
    "text": "exists in the description of talk 68 and uh talk 68 is um this",
    "start": "1072799",
    "end": "1079320"
  },
  {
    "text": "talk have to memorize the numbers build rag from scratch it's down there at the bottom so uh 68 is this one uh",
    "start": "1079320",
    "end": "1085600"
  },
  {
    "text": "interesting enough 38 is the uh is the karaoke party later which is also me so if you see",
    "start": "1085600",
    "end": "1092640"
  },
  {
    "text": "that coming up from the bot later you'll understand why um but yes so uh if we if we look at the text text vector of that",
    "start": "1092640",
    "end": "1099760"
  },
  {
    "text": "talk I haven't done that yet um uh zero things so what we like to call this is a",
    "start": "1099760",
    "end": "1104799"
  },
  {
    "text": "sparse array because it's mostly zeros uh it's just ones in the important place that matter um",
    "start": "1104799",
    "end": "1111799"
  },
  {
    "text": "cool don't need that anymore um",
    "start": "1111799",
    "end": "1116720"
  },
  {
    "text": "lovely yes so I'm going to stop there for a moment because we've made some vectors uh and you can see I've got some more things to write but we're going to",
    "start": "1119160",
    "end": "1125679"
  },
  {
    "text": "talk about comparing those vectors now we have our sparse vectors of all of our talks uh and now we need to compare them",
    "start": "1125679",
    "end": "1132240"
  },
  {
    "text": "uh this is fun because this is the maths part um you're also welcome to leave if you want i will get a function up on",
    "start": "1132240",
    "end": "1138640"
  },
  {
    "text": "screen at some point u but what we're going to do is vector search vector comparison you see I described vectors",
    "start": "1138640",
    "end": "1144160"
  },
  {
    "text": "as a list of numbers earlier and whilst technically that's true it's also not enough information uh vectors uh are",
    "start": "1144160",
    "end": "1151520"
  },
  {
    "text": "actually um uh they are points in a multi-dimensional space and because we have 1480 interesting words in our set",
    "start": "1151520",
    "end": "1159520"
  },
  {
    "text": "of talks are dimensional spaces 1480 dimensions um that's really hard to see so this",
    "start": "1159520",
    "end": "1165919"
  },
  {
    "text": "diagram is in two um two dimensions and So uh those vectors might uh you know",
    "start": "1165919",
    "end": "1171280"
  },
  {
    "text": "they they plot out points in that space uh and you can kind of look at these and go there's three points in that space",
    "start": "1171280",
    "end": "1177120"
  },
  {
    "text": "sure uh and then we want to say okay what's the what are the most similar ones and you might might think that it's",
    "start": "1177120",
    "end": "1182880"
  },
  {
    "text": "just the ones that are sort of physically closest to each other um these two I guess uh but um I was also",
    "start": "1182880",
    "end": "1190080"
  },
  {
    "text": "wrong about calling vectors points in space they're not uh they're actually um they are directions and a magnitude uh",
    "start": "1190080",
    "end": "1197120"
  },
  {
    "text": "they are directions from the origin 0 0 uh and a magnitude in that particular direction and again we're just dealing",
    "start": "1197120",
    "end": "1203840"
  },
  {
    "text": "in two dimensions here but when we spread it out to many many dimensions it becomes more interesting uh and in this",
    "start": "1203840",
    "end": "1209840"
  },
  {
    "text": "case the two vectors that are most similar are indeed the ones pointing in the same direction it just happens to be that the one further out has a greater",
    "start": "1209840",
    "end": "1216559"
  },
  {
    "text": "magnitude it probably means more about the particular subject that whatever this graph is kind of showing uh the",
    "start": "1216559",
    "end": "1222480"
  },
  {
    "text": "other one is sort of weakly about that but they are about the same thing whereas the one kind of at an angle to them all uh to the rest of them is uh",
    "start": "1222480",
    "end": "1229919"
  },
  {
    "text": "you know it's it's sort of meaning is shifted somewhat off to the side it means something different and so when we",
    "start": "1229919",
    "end": "1236320"
  },
  {
    "text": "do this in a multi-dimensional space uh with our multi-dimensional vectors uh we get these kind of similarity searches",
    "start": "1236320",
    "end": "1243520"
  },
  {
    "text": "based on meaning uh and the way we actually kind of uh",
    "start": "1243520",
    "end": "1249039"
  },
  {
    "text": "deal with this is cosign similarity now I like this Because um I feel like back in school uh I remember uh teachers",
    "start": "1249039",
    "end": "1256799"
  },
  {
    "text": "would all be like you know you have to learn multiplication cuz you're not going to carry a calculator around with you so wrong but uh it turns out now",
    "start": "1256799",
    "end": "1265600"
  },
  {
    "text": "trigonometry has got back into it and I don't carry a scientific calculator around with me so well no that's true",
    "start": "1265600",
    "end": "1271679"
  },
  {
    "text": "actually there are apps for that but um but it's a little bit of math a little bit of cosine similarity which uh",
    "start": "1271679",
    "end": "1278559"
  },
  {
    "text": "which kind of uh works out the angle between those vectors in multi-dimensions like it's kind of again",
    "start": "1278559",
    "end": "1283760"
  },
  {
    "text": "it's simple enough to see it in two dimensions but we have uh 1480 dimensions much harder to see so cosine",
    "start": "1283760",
    "end": "1290720"
  },
  {
    "text": "similarity is this yes maths on screen um it's actually it's relatively",
    "start": "1290720",
    "end": "1296200"
  },
  {
    "text": "straightforward thankfully um it's the it's the dotproduct of two vector vectors over the uh magnitude of each",
    "start": "1296200",
    "end": "1302559"
  },
  {
    "text": "vector multiplied by each other dot product is just um each element in two vectors like multiplied together and",
    "start": "1302559",
    "end": "1309840"
  },
  {
    "text": "then added up the sum of the multiplication of both ve of each element in the vector and then the",
    "start": "1309840",
    "end": "1315440"
  },
  {
    "text": "magnitude of a vector is the uh square of each item in the vector uh summed and",
    "start": "1315440",
    "end": "1321440"
  },
  {
    "text": "then square rooted of the whole sum and we take the two magnitudes multiply them together divide it actually turns out if",
    "start": "1321440",
    "end": "1328559"
  },
  {
    "text": "your vectors are normalized that is your vectors live between one and minus one you can drop the whole magnitude thing",
    "start": "1328559",
    "end": "1334320"
  },
  {
    "text": "which makes things a lot easier because you just have to add things up but turns out for my vectors we just created they",
    "start": "1334320",
    "end": "1340400"
  },
  {
    "text": "are they they go beyond one so we have to know all the cosine similarity um so",
    "start": "1340400",
    "end": "1345600"
  },
  {
    "text": "let's see that in code let's let's write out this lovely maths in code so I have",
    "start": "1345600",
    "end": "1351919"
  },
  {
    "text": "three functions dot productduct magnitude and and cosine similarity uh that dotproduct takes two vectors and as",
    "start": "1351919",
    "end": "1357120"
  },
  {
    "text": "I said we want to uh we're going to get a product i'm going to do this in a simple way like copilot often tries to",
    "start": "1357120",
    "end": "1364960"
  },
  {
    "text": "get me to reduce do a reducer function at this point and no one wants to read that on screen so uh we're going to get",
    "start": "1364960",
    "end": "1370240"
  },
  {
    "text": "the product and we're going to like for everything in vector a length the",
    "start": "1370240",
    "end": "1375520"
  },
  {
    "text": "product becomes uh well it's the sum of products in this case uh is is vector",
    "start": "1375520",
    "end": "1381039"
  },
  {
    "text": "you know the item in this vector times the item in the other vector and we return uh the final product it's",
    "start": "1381039",
    "end": "1387120"
  },
  {
    "text": "actually quite simple i like that uh the magnitude only takes one vector because we're going to square each of the things",
    "start": "1387120",
    "end": "1392320"
  },
  {
    "text": "in the uh in the vector so in this case I'm going to return a sum sum starts at zero and then for uh each item in the",
    "start": "1392320",
    "end": "1400159"
  },
  {
    "text": "vector uh as I said we're going to add the square of the item in the vector and",
    "start": "1400159",
    "end": "1405679"
  },
  {
    "text": "then ultimately return math match",
    "start": "1405679",
    "end": "1411360"
  },
  {
    "text": "math last month somebody signed me up to match.com and apparently it's still on the menu uh on the mind um kind of",
    "start": "1414760",
    "end": "1422559"
  },
  {
    "text": "annoying uh and I got in touch with their support and they were like \"Yeah just unsubscribe from the emails.\" I'm",
    "start": "1422559",
    "end": "1428080"
  },
  {
    "text": "like \"No you but you're still trying to match me with people it's not me it's not my picture.\" And I couldn't log in it was very",
    "start": "1428080",
    "end": "1433480"
  },
  {
    "text": "annoying math math dos square root math uh of the sum we return that and that's",
    "start": "1433480",
    "end": "1439679"
  },
  {
    "text": "our magnitude uh so now we have our dot productduct we have our magnitude so we",
    "start": "1439679",
    "end": "1446159"
  },
  {
    "text": "can get the cosine similarity which is the dotproduct oops domain to aski",
    "start": "1446159",
    "end": "1451520"
  },
  {
    "text": "dotproduct of the two vectors vector a and vector b um coil that finish off there we go",
    "start": "1451520",
    "end": "1458240"
  },
  {
    "text": "divided by the magnitude of both the vectors lovely cosine similarity and so if we were to take the cosine similarity",
    "start": "1458240",
    "end": "1464320"
  },
  {
    "text": "let's console.log log the cosine similarity of text to vector of talks",
    "start": "1464320",
    "end": "1471120"
  },
  {
    "text": "number zero let's do ins uh one and then we'll do the same one if we get to the",
    "start": "1471120",
    "end": "1477039"
  },
  {
    "text": "bottom we get nan because I didn't return something somewhere probably it's normally because JavaScript",
    "start": "1477039",
    "end": "1483640"
  },
  {
    "text": "yeah that's brilliant don't know why uh love it thanks Nan um good news is",
    "start": "1483640",
    "end": "1489919"
  },
  {
    "text": "there's a backup here uh and I'm not going to spend time debugging for you so let's take our working dotproduct our",
    "start": "1489919",
    "end": "1496400"
  },
  {
    "text": "working magnitude and our working cosine similarity and let's use that",
    "start": "1496400",
    "end": "1501360"
  },
  {
    "text": "instead uh and then we get one ha cool excellent so the talk with all the same words as the other talk is similar to",
    "start": "1503880",
    "end": "1511200"
  },
  {
    "text": "itself in fact the exact same one is the exact same uh this is exciting that I got one because the last time I did this",
    "start": "1511200",
    "end": "1516559"
  },
  {
    "text": "with a different set of talks I got 1.000000002 because floating points yeah",
    "start": "1516559",
    "end": "1522960"
  },
  {
    "text": "because JavaScript internationally recognized implementation of floatingoint arithmetic but uh it became more similar",
    "start": "1522960",
    "end": "1530799"
  },
  {
    "text": "than itself which I thought was great um if we if we do two different talks right",
    "start": "1530799",
    "end": "1536240"
  },
  {
    "text": "so talk zero and talk one uh very different to each other apparently uh zero similarity in this particular case",
    "start": "1536240",
    "end": "1542480"
  },
  {
    "text": "um and because this particular vector doesn't actually capture a lot of meaning we're not going to find anything",
    "start": "1542480",
    "end": "1547600"
  },
  {
    "text": "below zero we're not going to find like the negative makes it go in the other direction because we're just capturing a",
    "start": "1547600",
    "end": "1552960"
  },
  {
    "text": "very simple kind of version of this um kind of want to see if I can am I any similar to Ian's talk is my talk similar",
    "start": "1552960",
    "end": "1559039"
  },
  {
    "text": "to Ian's talk it is not excellent uh oh that was uh that's karaoke 68 um also",
    "start": "1559039",
    "end": "1565919"
  },
  {
    "text": "not similar uh but um the important thing is that now we have this way to um combine our vectors and find out how",
    "start": "1565919",
    "end": "1572880"
  },
  {
    "text": "similar they are we can find uh similar talks and so right now uh that search",
    "start": "1572880",
    "end": "1578159"
  },
  {
    "text": "was returning nothing when I checked it out because we returned this empty array the um the bot could only respond I know",
    "start": "1578159",
    "end": "1583679"
  },
  {
    "text": "nothing because we returned an empty array of talks and so I've actually got to do one",
    "start": "1583679",
    "end": "1590480"
  },
  {
    "text": "thing which is actually create the vector of all the talks um that's actually what we wanted yeah so I've",
    "start": "1590480",
    "end": "1595919"
  },
  {
    "text": "actually taken all the talks uh and now we have a sort of tpple we don't have those in JavaScript yet but that's",
    "start": "1595919",
    "end": "1601520"
  },
  {
    "text": "basically what it is so a tpple of the talk and a vector and so I'm actually going to uh in order to find similar",
    "start": "1601520",
    "end": "1607520"
  },
  {
    "text": "talks um here that thanks guys not exactly",
    "start": "1607520",
    "end": "1613039"
  },
  {
    "text": "that uh so we're going to get we're going to get our incoming query which will also turn to a vector in the same way using our existing list of all the",
    "start": "1613039",
    "end": "1619520"
  },
  {
    "text": "words uh and then we take the similar torqus uh by taking torque vectors and we uh get the torque and the vector and",
    "start": "1619520",
    "end": "1625679"
  },
  {
    "text": "return I'm actually going to return the torque the vector and the cosine similarity of the two vectors and then",
    "start": "1625679",
    "end": "1631360"
  },
  {
    "text": "we're going to sort by that cosine similarity and then slice out just to return like the top five uh and that",
    "start": "1631360",
    "end": "1638720"
  },
  {
    "text": "returns it and so if I go back at this point to the uh",
    "start": "1638720",
    "end": "1644760"
  },
  {
    "text": "example this is my search and I can say um uh what is going on with",
    "start": "1644760",
    "end": "1652760"
  },
  {
    "text": "artificial intelligence uh and we get some results",
    "start": "1652760",
    "end": "1658000"
  },
  {
    "text": "with some similarities which is cool um this one's about your developers intelligence oh isn't artificial cool so",
    "start": "1658000",
    "end": "1664000"
  },
  {
    "text": "that's an artificial intelligence talk uh what about quantum computing which seems less relevant but and then we get",
    "start": "1664000",
    "end": "1669200"
  },
  {
    "text": "to zero being stuff does this not similar like I said this is actually this is a bad vector uh but it it has",
    "start": "1669200",
    "end": "1675360"
  },
  {
    "text": "given us a good idea of how this kind of works uh and so if I asked about you know rag uh it's going to get my talk",
    "start": "1675360",
    "end": "1682080"
  },
  {
    "text": "back and then lots of un similar things and so this search then gets fed as context to our bot and so if I say uh",
    "start": "1682080",
    "end": "1689360"
  },
  {
    "text": "who is talking talking about rag uh it will",
    "start": "1689360",
    "end": "1694880"
  },
  {
    "text": "probably say I am yeah Bill Nash is talking about rag in a session titled build rag from scratch and if I ask what",
    "start": "1694880",
    "end": "1700480"
  },
  {
    "text": "is Bill Nash speaking about uh it's going to say that I'm both speaking about retrieval augmented generation and",
    "start": "1700480",
    "end": "1706799"
  },
  {
    "text": "karaoke your data is the important thing here",
    "start": "1706799",
    "end": "1712240"
  },
  {
    "text": "what you feed it uh it will return to you uh and so right now we have an",
    "start": "1712240",
    "end": "1717360"
  },
  {
    "text": "actual working bot using retrieval augmented generation on a very bad vector implementation which I think is",
    "start": "1717360",
    "end": "1723279"
  },
  {
    "text": "actually kind of exciting that it that this genuinely terrible bit of code works quite well um and so yeah and",
    "start": "1723279",
    "end": "1732159"
  },
  {
    "text": "aside from the fact that it's JavaScript uh it's also quite quick right i'm actually doing a cosign similarity test",
    "start": "1732159",
    "end": "1738159"
  },
  {
    "text": "against all of the talks so 101 different talks and the query vector and",
    "start": "1738159",
    "end": "1743760"
  },
  {
    "text": "so JavaScript not known for its kind of uh parallelization or uh ability to do vector math is returning those results",
    "start": "1743760",
    "end": "1750559"
  },
  {
    "text": "very quickly uh and the last time I did this when I got a more than one result",
    "start": "1750559",
    "end": "1755600"
  },
  {
    "text": "uh also had like 350 talks same kind of thing so actually it's it's very quick but it does work but like nobody here",
    "start": "1755600",
    "end": "1765200"
  },
  {
    "text": "should be implementing this uh tomorrow bad idea don't do it excellent if you leave now you don't",
    "start": "1765200",
    "end": "1771600"
  },
  {
    "text": "find out what you're supposed to do he doesn't care fine uh that works",
    "start": "1771600",
    "end": "1776960"
  },
  {
    "text": "but only sort of right what we had to do was know all of our data up front uh in order to make that map of all the words",
    "start": "1776960",
    "end": "1784240"
  },
  {
    "text": "and it turns out that we don't know our queries up front so if we send in a query that uses none of those words that are in the uh uh in the kind of corpus",
    "start": "1784240",
    "end": "1791679"
  },
  {
    "text": "of data then uh we'll get zero similarity for anything the query is sensitive to the vocabulary you have to",
    "start": "1791679",
    "end": "1798640"
  },
  {
    "text": "ask specific questions about the right things i had to say who's talking about rag and it picks out rag from my talk",
    "start": "1798640",
    "end": "1804080"
  },
  {
    "text": "title and if I say uh you know who's talking about like ways to make large",
    "start": "1804080",
    "end": "1809360"
  },
  {
    "text": "language models understand private data it's unlikely to get that as as",
    "start": "1809360",
    "end": "1816120"
  },
  {
    "text": "obviously if we had more words so 148 1480 was our kind of uh size of the",
    "start": "1816120",
    "end": "1823120"
  },
  {
    "text": "vector and corpus of words um but the more data we put in the bigger that's going to get the more calculations we",
    "start": "1823120",
    "end": "1829679"
  },
  {
    "text": "have to do uh and the slower it's going to run and the same word can mean different",
    "start": "1829679",
    "end": "1836080"
  },
  {
    "text": "things so this kind of idea of capturing meaning with a vector doesn't work very well with this version of it uh not just",
    "start": "1836080",
    "end": "1843360"
  },
  {
    "text": "the same word but the like the order of the words can mean things um I the the I",
    "start": "1843360",
    "end": "1849679"
  },
  {
    "text": "think canonical example of this is man bites dog is very different to dog bites man don't go around biting dogs my",
    "start": "1849679",
    "end": "1856399"
  },
  {
    "text": "vector will not deal with it well um so the same work can be different things and so all we're doing is this kind of",
    "start": "1856399",
    "end": "1862080"
  },
  {
    "text": "simple um effectively keyword search um we've ended up with keyword search",
    "start": "1862080",
    "end": "1868600"
  },
  {
    "text": "accidentally and so what we need is something that's going to work better than that uh and those are uh embedding",
    "start": "1868600",
    "end": "1874399"
  },
  {
    "text": "models actual machine learning models that are trained in order to create uh this idea of meaning and point uh and",
    "start": "1874399",
    "end": "1880720"
  },
  {
    "text": "and return it to you as a uh multi-dimensional vector uh these embedding models are in fact part of uh",
    "start": "1880720",
    "end": "1887120"
  },
  {
    "text": "the large language models that we are dealing with and they they handle that within themselves we never normally as a as a user of a model don't have to deal",
    "start": "1887120",
    "end": "1893600"
  },
  {
    "text": "with that but now that we're developers with these models we kind of need to know about these embed embedding models",
    "start": "1893600",
    "end": "1899519"
  },
  {
    "text": "as well turns out of course they're very easy to use thankfully uh most sort of",
    "start": "1899519",
    "end": "1905159"
  },
  {
    "text": "either existing model providers tend to have an embedding model that they make available like OpenAI um Anthropic",
    "start": "1905159",
    "end": "1911919"
  },
  {
    "text": "doesn't um but then there are sort of standalone embedding model providers as",
    "start": "1911919",
    "end": "1917120"
  },
  {
    "text": "well uh places like Voyage AI and and Gina uh and so it's really in this case",
    "start": "1917120",
    "end": "1922399"
  },
  {
    "text": "in JavaScript very simple to create an embedding in this case this is OpenAI using their JavaScript library you just",
    "start": "1922399",
    "end": "1927679"
  },
  {
    "text": "give it the model you want text embedding three small um you give it your input and uh the encoding format's",
    "start": "1927679",
    "end": "1933919"
  },
  {
    "text": "always float i don't know why that's an option at the moment um and you get back a vector wonderful um they are always",
    "start": "1933919",
    "end": "1941360"
  },
  {
    "text": "the same size which is useful text embedding three small uh brings you back 1536 vectors uh yeah 1536 dimensions in",
    "start": "1941360",
    "end": "1950240"
  },
  {
    "text": "your vector uh there's a large version which comes out at 3,72 um but large is",
    "start": "1950240",
    "end": "1955360"
  },
  {
    "text": "not always better um I don't have the ability to go into this today but",
    "start": "1955360",
    "end": "1960880"
  },
  {
    "text": "there's a very interesting at least Wikipedia article on the curse of dimensionality and and how more",
    "start": "1960880",
    "end": "1965919"
  },
  {
    "text": "dimensions isn't necessarily better uh these new models actually allow you to reduce the amount of dimensions they return which is kind of useful but it's",
    "start": "1965919",
    "end": "1972480"
  },
  {
    "text": "worth experimenting with and knowing about that um so uh so OpenAI has uh uh",
    "start": "1972480",
    "end": "1979519"
  },
  {
    "text": "Google has uh their text embedding 004 they used to call their embedding models gecko and now they just call them text",
    "start": "1979519",
    "end": "1986159"
  },
  {
    "text": "embedding which is much less exciting um where's the branding gone guys um and so",
    "start": "1986159",
    "end": "1993279"
  },
  {
    "text": "we can create these vectors uh using uh embedding models either via APIs or actually you can run your own local ones",
    "start": "1993279",
    "end": "1998720"
  },
  {
    "text": "as well if you have the uh capability or the hardware to do so um plenty of",
    "start": "1998720",
    "end": "2003760"
  },
  {
    "text": "models available on uh hugging face and uh and other alternatives um but the",
    "start": "2003760",
    "end": "2009600"
  },
  {
    "text": "kind of I think the frontier kind of the frontier models uh in in embedding are",
    "start": "2009600",
    "end": "2014880"
  },
  {
    "text": "similarly like provided by these uh for-profit companies uh thankfully it's also very cheap to make embeddings so",
    "start": "2014880",
    "end": "2020640"
  },
  {
    "text": "that's that's a useful part on the other side we don't want to be holding all these vectors uh in memory at all times",
    "start": "2020640",
    "end": "2027840"
  },
  {
    "text": "uh like I did with my example code there uh and so that's where the the idea of a vector database comes in um vector",
    "start": "2027840",
    "end": "2034080"
  },
  {
    "text": "databases come in a bunch of forms some are sort of vector first they're all the new ones out there that you you've only",
    "start": "2034080",
    "end": "2039760"
  },
  {
    "text": "just heard of uh some are um and other vector databases are either SQL",
    "start": "2039760",
    "end": "2045200"
  },
  {
    "text": "relational databases or NoSQL databases that have had vector indexes added to them uh as I said earlier I work for",
    "start": "2045200",
    "end": "2051118"
  },
  {
    "text": "data stacks and Astrod is indeed a document database with a with a vector index on it uh and has some extra powers",
    "start": "2051119",
    "end": "2057839"
  },
  {
    "text": "as well so it you can um just throw vectors into it uh or it will generate your vectors for you uh in this",
    "start": "2057839",
    "end": "2064878"
  },
  {
    "text": "particular case uh if you have a collection of documents in ash db um and",
    "start": "2064879",
    "end": "2070000"
  },
  {
    "text": "you call find on it you can sort by passing the query in under the vector uh property and it will do the job of",
    "start": "2070000",
    "end": "2076800"
  },
  {
    "text": "vectorizing that query for you and then uh then doing the similarity sort in",
    "start": "2076800",
    "end": "2082079"
  },
  {
    "text": "this case um same for inputting the data as well and so actually I do have did I",
    "start": "2082079",
    "end": "2088079"
  },
  {
    "text": "shave that up how about that uh if I look at my database I have already loaded uh all the data into my compb bot",
    "start": "2088079",
    "end": "2096960"
  },
  {
    "text": "uh the NDC talks and so in this particular talk in this particular thing I'm actually using uh Astrod's uh",
    "start": "2096960",
    "end": "2102880"
  },
  {
    "text": "vectorz uh and it's using an NVIDIA model called uh NVME QA which returns,024 dimensions uh and uh all the",
    "start": "2102880",
    "end": "2110560"
  },
  {
    "text": "data is kind of here in a table so we can see um is this the wrong",
    "start": "2110560",
    "end": "2116760"
  },
  {
    "text": "one cool uh if if I go and search for rag uh what's useful about this vectorzed thing is that you also can do",
    "start": "2116760",
    "end": "2122960"
  },
  {
    "text": "a search a similarity search here in the data in the in the dashboard uh that's going to vectorize my search for rag and",
    "start": "2122960",
    "end": "2129599"
  },
  {
    "text": "then uh return it and we get back my title yeah build drag from scratch cool",
    "start": "2129599",
    "end": "2134720"
  },
  {
    "text": "um and we can also see that here is the we got the vector stored in there as well um",
    "start": "2134720",
    "end": "2140760"
  },
  {
    "text": "nice,24 floatingoint numbers there for you",
    "start": "2140760",
    "end": "2145838"
  },
  {
    "text": "um but if I now go back to my server uh I can actually so I've implemented",
    "start": "2145880",
    "end": "2151680"
  },
  {
    "text": "vector search uh we don't have to spend more time watching me code uh this is uh the same vector search using that NVIDIA",
    "start": "2151680",
    "end": "2159119"
  },
  {
    "text": "uh embedding model uh vectorizing the query uh with ash db and returning uh",
    "start": "2159119",
    "end": "2164640"
  },
  {
    "text": "the data under vectorize and the vector itself and its similarity uh and if I go to the server and I change my old uh",
    "start": "2164640",
    "end": "2172560"
  },
  {
    "text": "this this previous one was called bag it's a sort of bag of words model that that big list of words meaning start as",
    "start": "2172560",
    "end": "2178079"
  },
  {
    "text": "a bag of words which we then uh check things against if I turn it to my vector search model I can go back to my example",
    "start": "2178079",
    "end": "2184880"
  },
  {
    "text": "my similarity search here uh and then say like uh who is speaking about rag uh",
    "start": "2184880",
    "end": "2192320"
  },
  {
    "text": "and at this point we actually get some other similarity things um so mine's fairly similar like anything more than.7",
    "start": "2192320",
    "end": "2198800"
  },
  {
    "text": "tends to be uh similar enough uh and then we uh we get less uh relevant",
    "start": "2198800",
    "end": "2204400"
  },
  {
    "text": "relevant ones uh let's not ask about rag let's say who is speaking about uh",
    "start": "2204400",
    "end": "2209920"
  },
  {
    "text": "artificial intelligence uh and so we get um this",
    "start": "2209920",
    "end": "2216800"
  },
  {
    "text": "one on quantum computing which is something but then we get principles for AI governance we get uh developers",
    "start": "2216800",
    "end": "2222880"
  },
  {
    "text": "intelligence is artificial uh we get AI powered end to-end testing uh we get Jody's keynote um syllab and I'm only",
    "start": "2222880",
    "end": "2231680"
  },
  {
    "text": "returning the top five here uh and so uh we get much better kind of relevant scores and that feeds into uh much",
    "start": "2231680",
    "end": "2239280"
  },
  {
    "text": "better um uh bot stuff as well so if I say who is who is speaking about",
    "start": "2239280",
    "end": "2246400"
  },
  {
    "text": "artificial intelligence uh we should now get a nice bot response about that saying besides Hannah Engel",
    "start": "2246400",
    "end": "2252160"
  },
  {
    "text": "we're talking about Nathan talking on principle based framework yep Hannah's Jody uh and so our bot is now better",
    "start": "2252160",
    "end": "2258480"
  },
  {
    "text": "where it gets more and more relevant information not based on weird keywords or my bag of words model but now on a uh",
    "start": "2258480",
    "end": "2264560"
  },
  {
    "text": "in this case Nvidia built embedding that is uh returned to us using a vector database using an index which is not",
    "start": "2264560",
    "end": "2270720"
  },
  {
    "text": "going to make our computer were as we um try and uh do vector math uh for far too",
    "start": "2270720",
    "end": "2277720"
  },
  {
    "text": "long uh cool so that is retrieval augmented generation or at least the",
    "start": "2277720",
    "end": "2283359"
  },
  {
    "text": "start of it um the very simple the the kind of the basic process of this is to",
    "start": "2283359",
    "end": "2288560"
  },
  {
    "text": "take your data is to turn it into a vector embedding and put it in a database and then when you get a query do the same turn it into a vector",
    "start": "2288560",
    "end": "2295200"
  },
  {
    "text": "compare against the database and return relevant results send those into turn those into a prompt send them to the",
    "start": "2295200",
    "end": "2300480"
  },
  {
    "text": "model and we get good results back but it goes beyond that once you start to scratch beneath the surface of this",
    "start": "2300480",
    "end": "2306160"
  },
  {
    "text": "there's actually a lot of options out there uh I have some uh links to this there is a QR code at the end which will",
    "start": "2306160",
    "end": "2311520"
  },
  {
    "text": "take you to slides and links so you don't have to take pictures of this although you're fully welcome to do so um there are there are alternative",
    "start": "2311520",
    "end": "2318720"
  },
  {
    "text": "options for this that help make your retrieval uh more relevant at times uh",
    "start": "2318720",
    "end": "2324320"
  },
  {
    "text": "so for example Colulbert uh is a um is a method that actually I think was implemented by uh developers or it was",
    "start": "2324320",
    "end": "2331359"
  },
  {
    "text": "originally a paper from out of neta uh and Colbert is very interesting rather",
    "start": "2331359",
    "end": "2336960"
  },
  {
    "text": "than taking our whole piece of text and turning it into one uh dense vector so",
    "start": "2336960",
    "end": "2342000"
  },
  {
    "text": "we actually we moved from sparse vectors in my bad example to a dense vector because everything got squeezed into",
    "start": "2342000",
    "end": "2347560"
  },
  {
    "text": "that,024 um rather than taking vectors and turning into one vector Colbert uh",
    "start": "2347560",
    "end": "2353040"
  },
  {
    "text": "uses Google's open source BERT model to uh vectorize each token in a piece of",
    "start": "2353040",
    "end": "2359720"
  },
  {
    "text": "text and then uh so you do that to your existing uh corpse of data you get the",
    "start": "2359720",
    "end": "2365599"
  },
  {
    "text": "query coming in and then to uh compare that you actually then end up comparing and finding the maximum similar uh token",
    "start": "2365599",
    "end": "2371760"
  },
  {
    "text": "in the query to each maxim each token each potential token in your base of data and it's absolutely mad but what it",
    "start": "2371760",
    "end": "2378800"
  },
  {
    "text": "does is allow you to capture better context for um words and uh meaning",
    "start": "2378800",
    "end": "2384880"
  },
  {
    "text": "outside of the training data of the embedding model um uh BERT is a really interesting model because it it whilst",
    "start": "2384880",
    "end": "2390079"
  },
  {
    "text": "it scans over the text it actually looks forward and backwards and has a sort of window of context that moves over it um",
    "start": "2390079",
    "end": "2396880"
  },
  {
    "text": "but it's not perfect because Colbert because you're now storing a vector for each token uh in a piece of text uh it's",
    "start": "2396880",
    "end": "2403200"
  },
  {
    "text": "slower to compare and uh balloons the amount of space you need to store that uh and so it's maybe it's not the first",
    "start": "2403200",
    "end": "2409119"
  },
  {
    "text": "thing you'd reach for but if you're having relevancy issues with your data Colbert's really interesting um there's",
    "start": "2409119",
    "end": "2414880"
  },
  {
    "text": "been a lot of talk about using graphs uh recently as well uh the very idea that",
    "start": "2414880",
    "end": "2419920"
  },
  {
    "text": "if we just get back and so I have a very simple data set with a bunch of talks here but uh a lot of this data actually",
    "start": "2419920",
    "end": "2425119"
  },
  {
    "text": "comes from uh unstructured uh data things that live in PDFs and documents and web pages that that are all part of",
    "start": "2425119",
    "end": "2431760"
  },
  {
    "text": "your business or whatever um and those are all linked together in various different ways and those links give uh",
    "start": "2431760",
    "end": "2438160"
  },
  {
    "text": "the data more context and when you get more context that you then feed to the model we get better answers again and so",
    "start": "2438160",
    "end": "2444240"
  },
  {
    "text": "if you can create a a content centric kind of graph about this if you extract",
    "start": "2444240",
    "end": "2449520"
  },
  {
    "text": "hyperlinks if you extract kind of shared keywords and use those to link and grab an extra context uh then uh then a graph",
    "start": "2449520",
    "end": "2456720"
  },
  {
    "text": "can actually lead you to better results as well uh there's a there's actually not a link",
    "start": "2456720",
    "end": "2462880"
  },
  {
    "text": "to this because we haven't written about it but I found a very interesting uh paper on a retrieval system called DAR",
    "start": "2462880",
    "end": "2469440"
  },
  {
    "text": "and in this particular case we do the original vector search as normal but then if we find that uh we have like two",
    "start": "2469440",
    "end": "2475680"
  },
  {
    "text": "chunks of data that from the same document and like close enough but is missing some stuff in the middle uh if",
    "start": "2475680",
    "end": "2481280"
  },
  {
    "text": "you go and retrieve the bits in the middle those tend to kind of include extra context about the question as well",
    "start": "2481280",
    "end": "2487440"
  },
  {
    "text": "uh and and doing so uh allows you to um right that that that bit in the middle",
    "start": "2487440",
    "end": "2493440"
  },
  {
    "text": "probably didn't come up in your relevant search because perhaps it didn't uh it used pronouns to refer to the topic",
    "start": "2493440",
    "end": "2499680"
  },
  {
    "text": "earlier uh and then didn't come up in the similarity search but it's still got relevant context for you so that's",
    "start": "2499680",
    "end": "2504720"
  },
  {
    "text": "another way to kind of make this search better um I read a thing about and this is something I've been meaning to look",
    "start": "2504720",
    "end": "2510480"
  },
  {
    "text": "into more uh the idea of when you create a vector embedding over a a large set of text and turn it into various chunks for",
    "start": "2510480",
    "end": "2517040"
  },
  {
    "text": "that you can then combine an embedding of the entire piece of text with each chunk of the text uh to give kind of an",
    "start": "2517040",
    "end": "2524240"
  },
  {
    "text": "overall context to each of the vectors and the idea of that's the idea of I think they call it late",
    "start": "2524240",
    "end": "2530280"
  },
  {
    "text": "chunking there's so much to this um but I think what we've uh at least seen in",
    "start": "2530280",
    "end": "2535760"
  },
  {
    "text": "the example today is that even with the worst vector even with a terrible implementation of it we can get better",
    "start": "2535760",
    "end": "2541040"
  },
  {
    "text": "results uh from our models when we've hand it that context and it's not hard to graduate from a very bad vector into",
    "start": "2541040",
    "end": "2548240"
  },
  {
    "text": "using an existing embedding model using a vector database and doing the exact same process um and finally just on this link",
    "start": "2548240",
    "end": "2555359"
  },
  {
    "text": "um uh similarity is not just useful for providing context to bots uh I implemented just a related posts feature",
    "start": "2555359",
    "end": "2561839"
  },
  {
    "text": "on my own blog uh which allows you to you know use a similarity search to return the three or four most similar",
    "start": "2561839",
    "end": "2567839"
  },
  {
    "text": "blog posts to the one you're reading and that's kind of a nice little extra thing you can do um cool so I am going to uh",
    "start": "2567839",
    "end": "2575119"
  },
  {
    "text": "wrap it up there like I said that QR code will take you to a list of uh links that I've uh used as part of this talk",
    "start": "2575119",
    "end": "2580720"
  },
  {
    "text": "as well as a a link to the actual slides um I think we're at a very exciting",
    "start": "2580720",
    "end": "2587800"
  },
  {
    "text": "point in this uh world of generative AI no one actually knows what what's going",
    "start": "2587800",
    "end": "2592880"
  },
  {
    "text": "on um we didn't get APIs for this until like 18 months ago so it's it's just so",
    "start": "2592880",
    "end": "2598240"
  },
  {
    "text": "brand new uh that this thing changes all the time understanding these kind of underlying principles of how we make",
    "start": "2598240",
    "end": "2604079"
  },
  {
    "text": "these things work is really important but the code and the tools that we write and use today will not be the same stuff",
    "start": "2604079",
    "end": "2609839"
  },
  {
    "text": "in a year's time uh it's busy and exciting but that gives us opportunity to build exciting new things and so",
    "start": "2609839",
    "end": "2617280"
  },
  {
    "text": "that's what I want to see you go out there and do that's what I'm going to be trying to do uh and I can't wait to see what you all build with that uh so again",
    "start": "2617280",
    "end": "2623599"
  },
  {
    "text": "my name's Fash i'm a developer relations engineer at Data Stacks i'll be around for the rest of the day rest of the conference come to the karaoke party",
    "start": "2623599",
    "end": "2629800"
  },
  {
    "text": "later start thinking about your songs right now and other than that thank you very much for coming",
    "start": "2629800",
    "end": "2636839"
  },
  {
    "text": "i assume we have a bit of time for questions if anybody does or just come up and find me i'll be around i'm in purple and very easy to find",
    "start": "2641040",
    "end": "2649160"
  }
]
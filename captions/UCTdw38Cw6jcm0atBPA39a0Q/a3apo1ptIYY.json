[
  {
    "text": "a and good morning and thank you so much",
    "start": "8570",
    "end": "13830"
  },
  {
    "text": "for showing up and I thought it was gonna be alone here at mine a.m. it's kind of looking",
    "start": "13830",
    "end": "20240"
  },
  {
    "text": "forward to it yes kidding my name is Tess and I'm a data scientist and a software engineer",
    "start": "20240",
    "end": "27170"
  },
  {
    "text": "at Microsoft and I've been doing machine learning form for a few years now and",
    "start": "27170",
    "end": "33770"
  },
  {
    "text": "I'm always curious how much like the machine learning community grows so who",
    "start": "33770",
    "end": "39200"
  },
  {
    "text": "in here is doing machine learning for the job like a couple more and more so",
    "start": "39200",
    "end": "47330"
  },
  {
    "text": "who has actually dabbled it I'm like who has tried it before yeah it's fun and so",
    "start": "47330",
    "end": "54890"
  },
  {
    "text": "my job is to travel around and help customers with machine learning problems",
    "start": "54890",
    "end": "61160"
  },
  {
    "text": "and get them started on machine learning and essentially kickstart um and also",
    "start": "61160",
    "end": "67430"
  },
  {
    "text": "put put machine learning models in production so a couple of the things so",
    "start": "67430",
    "end": "73250"
  },
  {
    "text": "this is my in the team that I usually travel with and a couple of the products that we were working on are this one",
    "start": "73250",
    "end": "80390"
  },
  {
    "text": "which is building highlight reels for soccer like for for big league soccer",
    "start": "80390",
    "end": "87500"
  },
  {
    "text": "game so taking soccer game videos and",
    "start": "87500",
    "end": "92510"
  },
  {
    "text": "figuring out when someone is shooting on goal when someone is attacking and things like things like that so I'll talk a little bit about how we attacked",
    "start": "92510",
    "end": "99799"
  },
  {
    "text": "a problem like that later another one that I've been working on has been cancer detection so this one was one",
    "start": "99799",
    "end": "107479"
  },
  {
    "text": "that was really really close to my heart because it's the first time I ever felt like I actually did something that",
    "start": "107479",
    "end": "114409"
  },
  {
    "text": "mattered as a software engineer so this was using digital pathology slides",
    "start": "114409",
    "end": "120890"
  },
  {
    "text": "helping doctors to identify morphed cells quicker than they can normally and",
    "start": "120890",
    "end": "128000"
  },
  {
    "text": "the speed of the time it takes for for a patient to come to to a doctor and get",
    "start": "128000",
    "end": "133700"
  },
  {
    "text": "treatment and the final one that I'm going to talk about later is shoplifting",
    "start": "133700",
    "end": "138890"
  },
  {
    "text": "so this is using cameras like CCTV cameras in shops figuring out if someone",
    "start": "138890",
    "end": "145189"
  },
  {
    "text": "is shoplifting now this was not necessarily to intervene for the shoplifting so it's",
    "start": "145189",
    "end": "151959"
  },
  {
    "text": "not real time but it's instead afterwards trying to figure out like what what kind of things do people do",
    "start": "151959",
    "end": "159730"
  },
  {
    "text": "like how can they improve their stores to reduce shoplifting and things like that but before I get into these",
    "start": "159730",
    "end": "168370"
  },
  {
    "text": "projects I wanted to use to give a little bit of background of deep learning because deep learning is what",
    "start": "168370",
    "end": "173489"
  },
  {
    "text": "we're using in these cases so I'm gonna start with a very canonical case of",
    "start": "173489",
    "end": "180389"
  },
  {
    "text": "trying to sell a house we're trying to buy a house trying to figure out what a house is worth um mostly because it's",
    "start": "180389",
    "end": "187840"
  },
  {
    "text": "recently I actually sold and bought at bought a house I'm moving into my new house next week actually and to try to",
    "start": "187840",
    "end": "195280"
  },
  {
    "text": "figure out what a house is worth we have some type of input so some information",
    "start": "195280",
    "end": "201639"
  },
  {
    "text": "about the house like where it's located the area of the house that sort of stuff",
    "start": "201639",
    "end": "208359"
  },
  {
    "text": "and then we have something we try to guess which is the price of the house and this is in Swedish crowns and and",
    "start": "208359",
    "end": "217870"
  },
  {
    "text": "what we're trying to sort of target is creating a function that will now map",
    "start": "217870",
    "end": "223510"
  },
  {
    "text": "the input to the output as if it was written in regular code but how the",
    "start": "223510",
    "end": "228699"
  },
  {
    "text": "machine do it for us so one way to go about this if we don't think about machine learning is what I did which was",
    "start": "228699",
    "end": "236319"
  },
  {
    "text": "I hired two Realtors and I asked them hey what do you think our house is worth",
    "start": "236319",
    "end": "242440"
  },
  {
    "text": "what would you want to sell it for and they both came to the same conclusion and I think they used a formula",
    "start": "242440",
    "end": "249400"
  },
  {
    "text": "something like this in fact they came to the same conclusion but then they also had a margin of two hundred and fifty",
    "start": "249400",
    "end": "257440"
  },
  {
    "text": "thousand crowns Swedish crowns in this case but it's I guess similar Turner in",
    "start": "257440",
    "end": "262690"
  },
  {
    "text": "Norwegian which left us with like a confidence margin of half a million",
    "start": "262690",
    "end": "269169"
  },
  {
    "text": "crowns which is actually a sizable amount that's not something that I can just pull out of my bank account like",
    "start": "269169",
    "end": "276039"
  },
  {
    "text": "that so the reason why they couldn't give me",
    "start": "276039",
    "end": "282490"
  },
  {
    "text": "a better estimate is of course because we don't have a lot of the information",
    "start": "282490",
    "end": "287620"
  },
  {
    "text": "that we would need to make a super solid estimate like something like who's gonna",
    "start": "287620",
    "end": "293050"
  },
  {
    "text": "show up they said you're gonna rain the day we're gonna have our showing that sort of thing it's like you never know",
    "start": "293050",
    "end": "298210"
  },
  {
    "text": "what's gonna happen but you can create an estimate and an estimate is exactly what machine learning does so the other",
    "start": "298210",
    "end": "305290"
  },
  {
    "text": "way to go around it then go about it then instead of hiring a realtor is for",
    "start": "305290",
    "end": "310660"
  },
  {
    "text": "the developer to hire a realtor and for the realtor to say hey this is how I come to the conclusion my ham like this",
    "start": "310660",
    "end": "317170"
  },
  {
    "text": "we start off at 100k and you have a certain value per square meter and if it",
    "start": "317170",
    "end": "324430"
  },
  {
    "text": "has a pool with us this value and so on you can look at this is a very simple",
    "start": "324430",
    "end": "332380"
  },
  {
    "text": "math function that's basically it's the number of features times the number of weights and then this green thing here",
    "start": "332380",
    "end": "339640"
  },
  {
    "text": "and like the starting price that the house will be worth no matter what is generally called a bias in machine",
    "start": "339640",
    "end": "346720"
  },
  {
    "text": "learning terms so this is not deep learning this is very shallow learning this is something called linear",
    "start": "346720",
    "end": "353530"
  },
  {
    "text": "regression and you can do this almost in Excel if you want to you can plot out your data points for for houses and you",
    "start": "353530",
    "end": "361150"
  },
  {
    "text": "can estimate a line that will generate sort of this equation and this will be a",
    "start": "361150",
    "end": "367450"
  },
  {
    "text": "fairly good model and that will give you that 500k estimate difference in this",
    "start": "367450",
    "end": "374140"
  },
  {
    "text": "case the sort of what you see here in pink like the pink marker is the",
    "start": "374140",
    "end": "381490"
  },
  {
    "text": "confidence interval because the line will make the prediction but you will always be a little bit off because not",
    "start": "381490",
    "end": "389350"
  },
  {
    "text": "everything will follow this formula exactly so this is linear regression and I bring this up because when we talk",
    "start": "389350",
    "end": "396220"
  },
  {
    "text": "about deep learning suddenly we get like we'd go from here and this is fairly easy to understand and we fit to line",
    "start": "396220",
    "end": "402850"
  },
  {
    "text": "doesn't really matter how we fit a line we've fitted with something called gradient descent that's basically East",
    "start": "402850",
    "end": "408370"
  },
  {
    "text": "determining like how the slope should go when you fit it a little bit better like that but it's quite easy explanation but",
    "start": "408370",
    "end": "415570"
  },
  {
    "text": "then we get into deep learning and suddenly it's like a bunch of bubbles um",
    "start": "415570",
    "end": "420930"
  },
  {
    "text": "weird some lines in between them and you go like like what the heck happened",
    "start": "420930",
    "end": "426130"
  },
  {
    "text": "there but as it turns out deep learning is used a lot of these linear",
    "start": "426130",
    "end": "431980"
  },
  {
    "text": "regressions put together like it's an orchestra of linear regressions sort of",
    "start": "431980",
    "end": "438580"
  },
  {
    "text": "like combined and the reason why we combine them like this in this huge",
    "start": "438580",
    "end": "444010"
  },
  {
    "text": "neural network that's supposed to somehow mimic our brains which it",
    "start": "444010",
    "end": "449470"
  },
  {
    "text": "doesn't do is because not all things are linear you can't always explain",
    "start": "449470",
    "end": "455080"
  },
  {
    "text": "something with a curve or with a line like that with a simple equation so you",
    "start": "455080",
    "end": "461170"
  },
  {
    "text": "need to combine them and create non-linear relationships and by nonlinear i mean that for example the",
    "start": "461170",
    "end": "468250"
  },
  {
    "text": "house price per square meter in stockholm is way different than the house price per square meter in and",
    "start": "468250",
    "end": "475050"
  },
  {
    "text": "somewhere else it very much depends and you need to use that combined features",
    "start": "475050",
    "end": "481240"
  },
  {
    "text": "to to do a few things so you can either then go through and create these",
    "start": "481240",
    "end": "487240"
  },
  {
    "text": "features let us see you create features sort of like this is a family size house",
    "start": "487240",
    "end": "492700"
  },
  {
    "text": "this is a good school area or this is a hipster community which works better for",
    "start": "492700",
    "end": "500470"
  },
  {
    "text": "like small apartments or whatever but instead with deep learning and creating like these nonlinear relationships deep",
    "start": "500470",
    "end": "507850"
  },
  {
    "text": "learning will learn these relationships for us so we don't have to do a lot of feature engineering so that is sort of",
    "start": "507850",
    "end": "515050"
  },
  {
    "text": "the promise of deep learning um but in reality it sees a lot of these small",
    "start": "515050",
    "end": "520900"
  },
  {
    "text": "linear regressions so the problems of deep learning is also that given enough samples we will find the function like",
    "start": "520900",
    "end": "530340"
  },
  {
    "text": "literally like there is no function that you cannot express with a deep neural",
    "start": "530340",
    "end": "537070"
  },
  {
    "text": "network in fact if you have a network that is like two layers deep you can express everything",
    "start": "537070",
    "end": "542790"
  },
  {
    "text": "and this takes a long time and it might be very wide but the key here is given",
    "start": "542790",
    "end": "549449"
  },
  {
    "text": "enough samples and not only given enough samples but also given the right samples because I can't use a bunch of samples",
    "start": "549449",
    "end": "557100"
  },
  {
    "text": "from Stockholm and assume that they will work while in Oslo and same way I need",
    "start": "557100",
    "end": "564750"
  },
  {
    "text": "to have samples that represent everything that a neural network needs to learn and knowing what kind of",
    "start": "564750",
    "end": "572880"
  },
  {
    "text": "troubles my realtor has like she doesn't have all the information that she needs to make a very tight decision the neural",
    "start": "572880",
    "end": "580290"
  },
  {
    "text": "network can't do that either it's not like the neural networks suddenly has some magic power and knows who's gonna",
    "start": "580290",
    "end": "586500"
  },
  {
    "text": "show up on I'm like next Sunday so you just keep that in mind that even though",
    "start": "586500",
    "end": "592410"
  },
  {
    "text": "the neural network and learn learn everything it needs good data to do this",
    "start": "592410",
    "end": "597709"
  },
  {
    "text": "so this is working with structured data so structured data means that you have",
    "start": "597709",
    "end": "603690"
  },
  {
    "text": "everything in a table there is like features here and there's a target value",
    "start": "603690",
    "end": "609959"
  },
  {
    "text": "here or your output value and but",
    "start": "609959",
    "end": "615089"
  },
  {
    "text": "sometimes you don't have structured data you don't have data that fit into a table instead you have something like",
    "start": "615089",
    "end": "621120"
  },
  {
    "text": "images so computer vision is built on this and in images it does matter where",
    "start": "621120",
    "end": "629040"
  },
  {
    "text": "the pixels are in the image it doesn't matter the despicable is beside this pixel that's beside this pixel and so on",
    "start": "629040",
    "end": "635670"
  },
  {
    "text": "so space matters like the location matters instruct your data you can literally swap the columns and no one",
    "start": "635670",
    "end": "642389"
  },
  {
    "text": "would care like the machine learning algorithm would work the same so deep learning can also deal with these",
    "start": "642389",
    "end": "648600"
  },
  {
    "text": "through something called convolutional neural networks and we'll go through that a little bit and it can also deal",
    "start": "648600",
    "end": "655110"
  },
  {
    "text": "with time or sequence so something like a time series or something like a",
    "start": "655110",
    "end": "662209"
  },
  {
    "text": "sentence where the order of the words actually do matter you can do that with",
    "start": "662209",
    "end": "667470"
  },
  {
    "text": "recurrent neural networks so if we want",
    "start": "667470",
    "end": "673019"
  },
  {
    "text": "to go through and classify something like Chihuahua or a muffin and try to make in",
    "start": "673019",
    "end": "680670"
  },
  {
    "text": "your network that determines how which one is which if you would do that as a",
    "start": "680670",
    "end": "686610"
  },
  {
    "text": "human being can anyone say and like who thinks this is a muffin okay one person",
    "start": "686610",
    "end": "692670"
  },
  {
    "text": "what made you think it was a muffin the color the color six but anyone who",
    "start": "692670",
    "end": "698790"
  },
  {
    "text": "thinks it's not a muffin okay thank you guys you might need something else for",
    "start": "698790",
    "end": "706860"
  },
  {
    "text": "breakfast Ashley so I'll ask you what made you think that it was she won't or",
    "start": "706860",
    "end": "713100"
  },
  {
    "text": "not a muffin thank you eyes and shape of",
    "start": "713100",
    "end": "720840"
  },
  {
    "text": "his head and ears yeah a couple of features like that so how would you",
    "start": "720840",
    "end": "726690"
  },
  {
    "text": "figure out these features from an image because for example in the house case",
    "start": "726690",
    "end": "732420"
  },
  {
    "text": "you can kind of figure out like how you would do in like a family sized house this like maybe a house that's got X",
    "start": "732420",
    "end": "739140"
  },
  {
    "text": "number of rooms and a certain size but how do you do that from an image any",
    "start": "739140",
    "end": "745380"
  },
  {
    "text": "thoughts one way to do this is like this",
    "start": "745380",
    "end": "751620"
  },
  {
    "text": "so this is a pretend neural network and in the first layer we can put in filters",
    "start": "751620",
    "end": "756870"
  },
  {
    "text": "so these are the same type of filters that you would use on an innate kind of",
    "start": "756870",
    "end": "762780"
  },
  {
    "text": "like graphics software sometimes like maybe a sobel filter that will learn like left edges and it will make your",
    "start": "762780",
    "end": "770520"
  },
  {
    "text": "image make your edges stand out or you could have a filter that only filters",
    "start": "770520",
    "end": "775890"
  },
  {
    "text": "through like the brown colors so you can use that to determine if something",
    "start": "775890",
    "end": "781050"
  },
  {
    "text": "muffin and things like that so all of these things combined now so we can use",
    "start": "781050",
    "end": "786660"
  },
  {
    "text": "filters and get out these features to figure out like there's lines and",
    "start": "786660",
    "end": "792030"
  },
  {
    "text": "there's brown and whatever and then we can combine them and yes I could combine like the very simple features in the",
    "start": "792030",
    "end": "800370"
  },
  {
    "text": "house case we can combine these two ears and eyes and things like that eventually and finally get to the point where it's",
    "start": "800370",
    "end": "808530"
  },
  {
    "text": "got two ears it's got two it's got like in this shape and and",
    "start": "808530",
    "end": "813569"
  },
  {
    "text": "therefore it's a chihuahua but you stuck with the house case if we don't actually",
    "start": "813569",
    "end": "820379"
  },
  {
    "text": "have to figure out these filters on our own it's not like we go in and say first layer sobel filter Brown filter red",
    "start": "820379",
    "end": "827850"
  },
  {
    "text": "filter or whatever instead the neural network will learn this for us from a large number of samples and kind of",
    "start": "827850",
    "end": "835579"
  },
  {
    "text": "gradient descent and getting to that so a convolutional neural network works a",
    "start": "835579",
    "end": "841050"
  },
  {
    "text": "little bit like this you have a few layers the first layer then has a number",
    "start": "841050",
    "end": "847769"
  },
  {
    "text": "of filters issues maybe I don't know thirty-two filters and then the small",
    "start": "847769",
    "end": "852839"
  },
  {
    "text": "boxes here are something called pooling so pooling means that we're trying to",
    "start": "852839",
    "end": "858089"
  },
  {
    "text": "down sample we're trying to sort of compress the output space and say for",
    "start": "858089",
    "end": "863999"
  },
  {
    "text": "every four pixels pick the one that activated the most like the one that showed the most that it was like brown",
    "start": "863999",
    "end": "871949"
  },
  {
    "text": "or not brown or something like that and then we pick that value and let that value be the value for all these four",
    "start": "871949",
    "end": "878519"
  },
  {
    "text": "pixels so this is just a way of down sampling you know nature now sort of the details of this but that's how it works",
    "start": "878519",
    "end": "884610"
  },
  {
    "text": "you have convolutional layers like the filters and then down sample filters",
    "start": "884610",
    "end": "889829"
  },
  {
    "text": "down sample filters down sample and eventually you end up with a representation that's now a bunch of",
    "start": "889829",
    "end": "898079"
  },
  {
    "text": "numbers that says we have this much Chihuahua news we have this much I don't",
    "start": "898079",
    "end": "904829"
  },
  {
    "text": "know brownness and airiness and things like that so and then from that we can",
    "start": "904829",
    "end": "911819"
  },
  {
    "text": "do the we can do the classification so this intermediate layer and this was",
    "start": "911819",
    "end": "918119"
  },
  {
    "text": "when when I discovered this this was sort of like the Holy Grail is like wow I kind of understand this machine",
    "start": "918119",
    "end": "925889"
  },
  {
    "text": "learning thing now because this is what all deep learning does it takes you from sort of like the original space to this",
    "start": "925889",
    "end": "934160"
  },
  {
    "text": "code to this embedding or intermediate",
    "start": "934160",
    "end": "939179"
  },
  {
    "text": "representation or secret code or whatever you want to call it which is essentially is an array of numbers that have features",
    "start": "939179",
    "end": "947310"
  },
  {
    "text": "so you can think of these features a little bit like the area and zip code",
    "start": "947310",
    "end": "952680"
  },
  {
    "text": "and things like that but representations of what this image contains so thinking",
    "start": "952680",
    "end": "960360"
  },
  {
    "text": "about it in a little bit different way if I were to recommend a book this is my Kindle library and I want to recommend a",
    "start": "960360",
    "end": "967589"
  },
  {
    "text": "book to my husband and my daughter my daughter is 16 my husband I don't tell",
    "start": "967589",
    "end": "973500"
  },
  {
    "text": "him his age but hey obviously they're",
    "start": "973500",
    "end": "978509"
  },
  {
    "text": "gonna have quite different tastes and if I think about like if which I",
    "start": "978509",
    "end": "986190"
  },
  {
    "text": "would recommend to which one way to figure out which one would fit which",
    "start": "986190",
    "end": "991199"
  },
  {
    "text": "would be to sort them and say this one fit an adult and this one fits a kid",
    "start": "991199",
    "end": "999480"
  },
  {
    "text": "more and she'll probably like the one son on this end of the spectrum like",
    "start": "999480",
    "end": "1005600"
  },
  {
    "text": "John Green and and hunger games and whatnot and he'll probably like Michael Connolly a lot better and things like",
    "start": "1005600",
    "end": "1012440"
  },
  {
    "text": "that so that's a nice way so in that case this feature would be a 1 or a minus 1",
    "start": "1012440",
    "end": "1018560"
  },
  {
    "text": "depending on where you are now obviously if we wanted to we could give it a",
    "start": "1018560",
    "end": "1024709"
  },
  {
    "text": "little bit more depth and say what if I also put another axle that says it's a",
    "start": "1024709",
    "end": "1030650"
  },
  {
    "text": "fiction book a nonfiction book because that might tell me a little bit more about what I should recommend to",
    "start": "1030650",
    "end": "1036260"
  },
  {
    "text": "different people depending on what their life's are right now and we can go on and now put another number on on these",
    "start": "1036260",
    "end": "1044720"
  },
  {
    "text": "and now they become sort of like a representation in two-dimension where",
    "start": "1044720",
    "end": "1050960"
  },
  {
    "text": "things that fit together like divergent and The Hunger Games end up in the same",
    "start": "1050960",
    "end": "1056929"
  },
  {
    "text": "locations and this is a very very nice thing because now you have a geometric representation of something where",
    "start": "1056929",
    "end": "1064040"
  },
  {
    "text": "similar things fit together like similar things are in in the same space in in",
    "start": "1064040",
    "end": "1071659"
  },
  {
    "text": "this geometric representation and you can use that to say",
    "start": "1071659",
    "end": "1078860"
  },
  {
    "text": "if you like this you'll probably like this we could add on more things so we",
    "start": "1078860",
    "end": "1085010"
  },
  {
    "text": "could add on things Diegan did he have math reference a this is a us-centric or is a Chiclets book or funny or sci-fi or",
    "start": "1085010",
    "end": "1093230"
  },
  {
    "text": "does it have lawyers or would Brad Pitt play a character in the movie whatever",
    "start": "1093230",
    "end": "1098840"
  },
  {
    "text": "and you don't even have to figure out what these things are and give them a name and sort of determine what every",
    "start": "1098840",
    "end": "1106130"
  },
  {
    "text": "number means in fact deep learning will do this for you they will come up with random things that don't actually mean",
    "start": "1106130",
    "end": "1112430"
  },
  {
    "text": "anything but they are good representations they give like some semantic meaning to what this book is",
    "start": "1112430",
    "end": "1119180"
  },
  {
    "text": "that's a little bit deeper and that you can then use to classify things so you",
    "start": "1119180",
    "end": "1126830"
  },
  {
    "text": "can do this with words and if you do this with words and you train it on a large amount of text you'll end up with",
    "start": "1126830",
    "end": "1134570"
  },
  {
    "text": "words that are similar that fit together like this in fact you might notice that",
    "start": "1134570",
    "end": "1140950"
  },
  {
    "text": "disappointed shows up with all the happy words but in all respects except for",
    "start": "1140950",
    "end": "1147260"
  },
  {
    "text": "maybe negative and positive like it's a strong feeling so it should end up in",
    "start": "1147260",
    "end": "1152570"
  },
  {
    "text": "the same location but things like this allow you to to say okay so instead of",
    "start": "1152570",
    "end": "1157700"
  },
  {
    "text": "yes these few characters this word has a lot more meaning now and I can replace",
    "start": "1157700",
    "end": "1163700"
  },
  {
    "text": "happy with delighted and things like that in in text which is very very",
    "start": "1163700",
    "end": "1168710"
  },
  {
    "text": "useful and in fact because it has a geometric representation the actual",
    "start": "1168710",
    "end": "1174980"
  },
  {
    "text": "distance or the actual relationship between them also has meanings so the",
    "start": "1174980",
    "end": "1180020"
  },
  {
    "text": "vector in space between men and and King is roughly the same as woman and queen",
    "start": "1180020",
    "end": "1187480"
  },
  {
    "text": "so you can create analogies which is also very useful for understanding and",
    "start": "1187480",
    "end": "1193240"
  },
  {
    "text": "text and word and things like that and you can extend this so in the next place",
    "start": "1193240",
    "end": "1199550"
  },
  {
    "text": "you can do this for faces alright so this is my actual embedding for for a",
    "start": "1199550",
    "end": "1207170"
  },
  {
    "text": "picture of my face and what this allows me to do is if I can extract like even",
    "start": "1207170",
    "end": "1213350"
  },
  {
    "text": "if I can use a pre-trained model and extract this information I can now store this 300 character long or in a 300 a",
    "start": "1213350",
    "end": "1222740"
  },
  {
    "text": "number long array in a database and that is my representation of me and if I go",
    "start": "1222740",
    "end": "1228380"
  },
  {
    "text": "in and I want to do face verification I can just compare to that so that is the",
    "start": "1228380",
    "end": "1233390"
  },
  {
    "text": "only thing I need to store I don't need to store like a thousand images of me I need to store this one thing in the",
    "start": "1233390",
    "end": "1238730"
  },
  {
    "text": "database and that's very very useful so this is an example of how it looks so",
    "start": "1238730",
    "end": "1244880"
  },
  {
    "text": "this is a from face net 128 I mentioned",
    "start": "1244880",
    "end": "1250030"
  },
  {
    "text": "embedding you can sort of shoes and the dimension of the embedding and the more dimensions you have the more features it",
    "start": "1250030",
    "end": "1257540"
  },
  {
    "text": "will represent but doesn't a more data you will need to actually create that but um this is sort of projected in 2d",
    "start": "1257540",
    "end": "1264470"
  },
  {
    "text": "so you can think of like if you can even think of 128 dimensional space but you",
    "start": "1264470",
    "end": "1269540"
  },
  {
    "text": "just look at it from one direction flat is to be able to represent it you can",
    "start": "1269540",
    "end": "1274700"
  },
  {
    "text": "see this light blue dots those are all pictures of me and then you have other",
    "start": "1274700",
    "end": "1280610"
  },
  {
    "text": "color dots that are pictures of someone else so if we look at it like this you'll see that all my dots fit very",
    "start": "1280610",
    "end": "1288800"
  },
  {
    "text": "very closely together and in fact they hardly even sort of interject with",
    "start": "1288800",
    "end": "1296030"
  },
  {
    "text": "anyone else's so you can use this now to do verification and you can also use",
    "start": "1296030",
    "end": "1303230"
  },
  {
    "text": "this to see similarities so I have people that are around me in space are",
    "start": "1303230",
    "end": "1309140"
  },
  {
    "text": "probably very similar to me the fact that the ds3 happened to end up here is",
    "start": "1309140",
    "end": "1316490"
  },
  {
    "text": "because this is in this projection if we were to look at it from over here instead like that we would get a",
    "start": "1316490",
    "end": "1324080"
  },
  {
    "text": "slightly different projection where we wouldn't have and that clear distinction between and the skin color making such a",
    "start": "1324080",
    "end": "1331700"
  },
  {
    "text": "difference in this in fact in that case maybe male/female would be a lot heavier",
    "start": "1331700",
    "end": "1337790"
  },
  {
    "text": "distinction but you can also see for example with Serena and Venus they're very similar",
    "start": "1337790",
    "end": "1343450"
  },
  {
    "text": "and most of the pictures that I had of them had like tennis things so that's",
    "start": "1343450",
    "end": "1351280"
  },
  {
    "text": "why they also show up I'm very very close together so if we look at that and",
    "start": "1351280",
    "end": "1358690"
  },
  {
    "text": "let's see if I can do this you don't",
    "start": "1358690",
    "end": "1365170"
  },
  {
    "text": "actually have to train like a face recognition system in order to be able",
    "start": "1365170",
    "end": "1370240"
  },
  {
    "text": "to in order to be able to use face recognition a lot of people have done this before you or before me so we can",
    "start": "1370240",
    "end": "1377920"
  },
  {
    "text": "use pre trained models in fact in this case I only have like one single image",
    "start": "1377920",
    "end": "1383650"
  },
  {
    "text": "of a number of different people and it will now accurately find all of them so",
    "start": "1383650",
    "end": "1392650"
  },
  {
    "text": "and this is just using CV open CV which",
    "start": "1392650",
    "end": "1399010"
  },
  {
    "text": "is a image library that you use a lot to process images before you do machine",
    "start": "1399010",
    "end": "1405310"
  },
  {
    "text": "learning and it will sort of like what is one picture of me it now recognizes",
    "start": "1405310",
    "end": "1412420"
  },
  {
    "text": "me and it also recognizes my friends",
    "start": "1412420",
    "end": "1419040"
  },
  {
    "text": "[Music] with just one single picture so this is",
    "start": "1419240",
    "end": "1425170"
  },
  {
    "text": "something that you could use today and in your applications for doing like face",
    "start": "1425170",
    "end": "1431560"
  },
  {
    "text": "identification or aced face recognition",
    "start": "1431560",
    "end": "1436230"
  },
  {
    "text": "so what else can we do with this representation so let's say we take an",
    "start": "1438690",
    "end": "1443860"
  },
  {
    "text": "image of a cat and we bring it down to its representation so this is now the",
    "start": "1443860",
    "end": "1449710"
  },
  {
    "text": "code for the cat in a pre train model we can now do something called a generative",
    "start": "1449710",
    "end": "1456130"
  },
  {
    "text": "network which basically means instead of down sampling of things we up sample and",
    "start": "1456130",
    "end": "1463000"
  },
  {
    "text": "we'll make it bigger and we get another representation of the same image so",
    "start": "1463000",
    "end": "1468160"
  },
  {
    "text": "basically we now instead of compressed we weeks found it and we get something like this",
    "start": "1468160",
    "end": "1474809"
  },
  {
    "text": "this is trained to do exactly this so what it does is it does segmentation of",
    "start": "1474809",
    "end": "1480279"
  },
  {
    "text": "the image to say exactly where in the image that we have cats and exactly where in the image do we have trees and",
    "start": "1480279",
    "end": "1486190"
  },
  {
    "text": "things like that so you can use an encoder and a decoder together kind of",
    "start": "1486190",
    "end": "1492220"
  },
  {
    "text": "like a little Lego pieces or you can use something like encode a piece of text with the recurrent neural network get to",
    "start": "1492220",
    "end": "1499509"
  },
  {
    "text": "the representation and then generate a new piece of text like a response to",
    "start": "1499509",
    "end": "1505629"
  },
  {
    "text": "this text or you can take something like an image like a convolutional neural network get the extract and I extract",
    "start": "1505629",
    "end": "1512950"
  },
  {
    "text": "the embedding and then answer with a piece of text that's now the caption for",
    "start": "1512950",
    "end": "1518409"
  },
  {
    "text": "this image so deep learning is extremely extremely powerful in the sense that you",
    "start": "1518409",
    "end": "1524590"
  },
  {
    "text": "can use to build and match and do some really really nice things that you could",
    "start": "1524590",
    "end": "1529599"
  },
  {
    "text": "never do with just linear regression for example so in practice this is how it",
    "start": "1529599",
    "end": "1536499"
  },
  {
    "text": "works it's neat to see where I am the time ways right so we have our show what was",
    "start": "1536499",
    "end": "1545289"
  },
  {
    "text": "in muffins and the first thing we do is we gather a lot of images of the Chihuahuas and muffins and we split them",
    "start": "1545289",
    "end": "1552489"
  },
  {
    "text": "up into three different pieces so we have a lot of our data used for training",
    "start": "1552489",
    "end": "1559450"
  },
  {
    "text": "so this is what the machine learning model is going to learn from and then we have a few images set aside for",
    "start": "1559450",
    "end": "1566139"
  },
  {
    "text": "validation so in each step once you've trained you also check that it works",
    "start": "1566139",
    "end": "1572349"
  },
  {
    "text": "well on data that it hasn't been trained on this is crucial because otherwise you can learn Brown and think it's a muffin",
    "start": "1572349",
    "end": "1579489"
  },
  {
    "text": "where in in reality like Brown might mean something else in the validation is",
    "start": "1579489",
    "end": "1585700"
  },
  {
    "text": "that it might not conform to to all the more things in there and then eventually",
    "start": "1585700",
    "end": "1592049"
  },
  {
    "text": "once you have a model and you iterated through it you go through and do it on a test set and the test set should be very",
    "start": "1592049",
    "end": "1600580"
  },
  {
    "text": "very similar to what you expect your final data to be so the training and",
    "start": "1600580",
    "end": "1605830"
  },
  {
    "text": "validate could actually be sort of images of the internet even likes to do pictures of of",
    "start": "1605830",
    "end": "1612520"
  },
  {
    "text": "muffins and she was but then your test said that you want to validate against should be like the mobile blurry images",
    "start": "1612520",
    "end": "1621940"
  },
  {
    "text": "that you expect from your customers yes so you verify that it actually works on",
    "start": "1621940",
    "end": "1627490"
  },
  {
    "text": "on the full population that you're training or it that you're working for so you get a batch of images a random",
    "start": "1627490",
    "end": "1634000"
  },
  {
    "text": "batch of him and cheese some Chihuahuas marked as zero and some muffins marked",
    "start": "1634000",
    "end": "1639310"
  },
  {
    "text": "this one because machine learning doesn't know about muffins as you owe us they know about ones and zeros and then",
    "start": "1639310",
    "end": "1646810"
  },
  {
    "text": "you build a neural network and if you remember this picture this is essentially what a neural network looks",
    "start": "1646810",
    "end": "1653830"
  },
  {
    "text": "like in code this is Cara's a Python framework by the sky Francois Chalet",
    "start": "1653830",
    "end": "1659670"
  },
  {
    "text": "that lets you abstract and create neural networks very very quickly so if we look",
    "start": "1659670",
    "end": "1667210"
  },
  {
    "text": "at the first line here or down here with the convolutional and layer with 32",
    "start": "1667210",
    "end": "1674440"
  },
  {
    "text": "filters 3x3 max pooling another convolutional layer with 64 filters we",
    "start": "1674440",
    "end": "1681220"
  },
  {
    "text": "flattened it out this is where we actually create the embedding or embedding in this case is gonna be 512",
    "start": "1681220",
    "end": "1686500"
  },
  {
    "text": "and then we want out a 1 or a 0 where 1 means muffin Sarah means not muffin or",
    "start": "1686500",
    "end": "1693880"
  },
  {
    "text": "shawol in this case and then we'll fit it so this is the training piece we",
    "start": "1693880",
    "end": "1700750"
  },
  {
    "text": "actually compile it in between but it doesn't really matter and in this case we say go through the data 20 times all",
    "start": "1700750",
    "end": "1707920"
  },
  {
    "text": "of the data go through it piece by piece and batches and and train 20 times on",
    "start": "1707920",
    "end": "1714160"
  },
  {
    "text": "this and then give me something and then you can after you've done this you can train 20 more times or 100 more times or",
    "start": "1714160",
    "end": "1720340"
  },
  {
    "text": "a thousand it depends on on what you want and you end up with something like",
    "start": "1720340",
    "end": "1726640"
  },
  {
    "text": "this which is used like a listing of how good and this was so looking at one of",
    "start": "1726640",
    "end": "1732400"
  },
  {
    "text": "these items we're gonna see that it took 16 seconds on this surface book with a",
    "start": "1732400",
    "end": "1738310"
  },
  {
    "text": "GPU to go through the file hundred images and train on them is one batch or say one one epoch and we got 98",
    "start": "1738310",
    "end": "1748820"
  },
  {
    "text": "point 65 percent accuracy on the training data so that's pretty and",
    "start": "1748820",
    "end": "1754010"
  },
  {
    "text": "pretty darn long it's like it gets almost every picture correctly however it only got 91 percent on the validation",
    "start": "1754010",
    "end": "1763610"
  },
  {
    "text": "data so this is the data that it hadn't seen but we used as validations this is",
    "start": "1763610",
    "end": "1769940"
  },
  {
    "text": "a um I think maybe like um 20 40",
    "start": "1769940",
    "end": "1775580"
  },
  {
    "text": "pictures or something that is testing on so 91 is still fairly good it's like every 9 out of 10 it's gonna get correct",
    "start": "1775580",
    "end": "1783890"
  },
  {
    "text": "in this case but do we can do a little bit better than that and we have to worry a little bit about a difference",
    "start": "1783890",
    "end": "1790490"
  },
  {
    "text": "between the training data and the validation data this is something called",
    "start": "1790490",
    "end": "1796550"
  },
  {
    "text": "overfitting and what is meanness is then when we train we actually learn too much",
    "start": "1796550",
    "end": "1802460"
  },
  {
    "text": "about details of the the training data we'll learn things like there's a pixel",
    "start": "1802460",
    "end": "1808670"
  },
  {
    "text": "up here in the corner that probably means muffin or I think all the muffin is our chocolate",
    "start": "1808670",
    "end": "1815750"
  },
  {
    "text": "muffins because that's what I had in my training is that so it learns like these details that are not general enough to",
    "start": "1815750",
    "end": "1822260"
  },
  {
    "text": "work on the validation set so overfitting is sort of like the bane of",
    "start": "1822260",
    "end": "1827600"
  },
  {
    "text": "all machine learning project so what can we do to to make it more general one way",
    "start": "1827600",
    "end": "1836120"
  },
  {
    "text": "we could do we had fixed is is get a lot more pictures of showers and muffins and",
    "start": "1836120",
    "end": "1842260"
  },
  {
    "text": "put them in the batch and make the the system learn better and even doing",
    "start": "1842260",
    "end": "1849200"
  },
  {
    "text": "things like having more muffins it looked like she was and things like that so bring them closer together so it's",
    "start": "1849200",
    "end": "1855590"
  },
  {
    "text": "harder for the network to train would also be something that we could do but one thing that's easy to do and that's",
    "start": "1855590",
    "end": "1863590"
  },
  {
    "text": "actually available in most of these frameworks it's doing something called data augmentation so data augmentation",
    "start": "1863590",
    "end": "1871040"
  },
  {
    "text": "for images means you're gonna take all the images you have and randomly and do certain things",
    "start": "1871040",
    "end": "1877220"
  },
  {
    "text": "to them like it could be rotated Melilla bait or flip them over or translate them",
    "start": "1877220",
    "end": "1884480"
  },
  {
    "text": "a little bit and things like that such that they still look like she was but",
    "start": "1884480",
    "end": "1890179"
  },
  {
    "text": "they're just a little bit different so we now get information about we can now",
    "start": "1890179",
    "end": "1895460"
  },
  {
    "text": "handle images where the she was are looking the other way or whether she Wallace are rotated a little bit and we",
    "start": "1895460",
    "end": "1902480"
  },
  {
    "text": "get away from the the whole it's learning a certain pixel in a corner that kind of thing so data augmentation",
    "start": "1902480",
    "end": "1909799"
  },
  {
    "text": "is very useful and it's a very easy to implement another thing we can do is also do something called a drop out and",
    "start": "1909799",
    "end": "1916910"
  },
  {
    "text": "drop out means that randomly for every batch we're gonna say forget about this",
    "start": "1916910",
    "end": "1924410"
  },
  {
    "text": "filter forget about the brown filter and forget about a left edge filter don't",
    "start": "1924410",
    "end": "1929929"
  },
  {
    "text": "care about them like don't use them we're for this one we're not gonna focus on them because they might be what is",
    "start": "1929929",
    "end": "1937520"
  },
  {
    "text": "causing you to to overfit on the training data so using this what can now",
    "start": "1937520",
    "end": "1943880"
  },
  {
    "text": "get something like this so we get 20 a pox later we gets like 93 percent",
    "start": "1943880",
    "end": "1952610"
  },
  {
    "text": "accuracy I would say like if you're wondering how long you should train it's",
    "start": "1952610",
    "end": "1958400"
  },
  {
    "text": "sort of like when when they start doing this there's no point in training anymore because you're not learning",
    "start": "1958400",
    "end": "1964429"
  },
  {
    "text": "anything on the validation set like you should get to almost a hundred on the",
    "start": "1964429",
    "end": "1969919"
  },
  {
    "text": "training set but once you get to the point where the diverged too much you need to do something else to to fix the",
    "start": "1969919",
    "end": "1976700"
  },
  {
    "text": "overfitting problem but there is something else that we can do that humans do and and that is learning from",
    "start": "1976700",
    "end": "1985130"
  },
  {
    "text": "our past experiences not only learning from these 500 images but I'm sure that",
    "start": "1985130",
    "end": "1992870"
  },
  {
    "text": "when you said ears and mice and things like that it's not because you've seen 500 Chihuahuas or I don't think you have",
    "start": "1992870",
    "end": "1999470"
  },
  {
    "text": "or maybe maybe you have a shooooow or maybe that's but you probably don't see",
    "start": "1999470",
    "end": "2005049"
  },
  {
    "text": "you probably from a lot of other things like dogs other bacon goods things like that and",
    "start": "2005049",
    "end": "2010720"
  },
  {
    "text": "we can do we can let machine learning do that too so we can take like a huge Network based on image net for example",
    "start": "2010720",
    "end": "2019600"
  },
  {
    "text": "image net is a huge data set of everyday objects that contain a lot of dogs",
    "start": "2019600",
    "end": "2024730"
  },
  {
    "text": "actually most of the big things that are in there are actually dogs so it works perfectly on dogs oh and this is also",
    "start": "2024730",
    "end": "2031600"
  },
  {
    "text": "something you need to be a little bit careful about when you base your your stuff on image net but um it's got a lot",
    "start": "2031600",
    "end": "2039310"
  },
  {
    "text": "of dogs got a lot of bacon goods it's got a lot of tables and different things that you can actually learn from and",
    "start": "2039310",
    "end": "2045610"
  },
  {
    "text": "even if your data doesn't necessarily look like image net you can still use image net to learn like small details",
    "start": "2045610",
    "end": "2053290"
  },
  {
    "text": "like colors and and lines and things like that and features that are good for",
    "start": "2053290",
    "end": "2058330"
  },
  {
    "text": "your for your subject so this is an image net it's got like a thousand different categories that it could be",
    "start": "2058330",
    "end": "2065220"
  },
  {
    "text": "and what we do is we take the embedding again the code you just use that from a",
    "start": "2065220",
    "end": "2072040"
  },
  {
    "text": "pre trained model we don't have to worry about training this part it's already been done and then you just tack on your",
    "start": "2072040",
    "end": "2078940"
  },
  {
    "text": "own classifier so the only thing you do at the end is basically say give me the embedding and now you say she wore my",
    "start": "2078940",
    "end": "2086139"
  },
  {
    "text": "vein I will I will classify she while warm off and based on these images this is called transfer learning and it's",
    "start": "2086140",
    "end": "2092110"
  },
  {
    "text": "super super super important in machine learning so in this case with this we",
    "start": "2092110",
    "end": "2098980"
  },
  {
    "text": "actually get close to a hundred percent precisely because it has a lot of shoe hours and and muffins actually in",
    "start": "2098980",
    "end": "2105490"
  },
  {
    "text": "imagenet but I just wanted to show you this because this is super super powerful and each epoch on this training",
    "start": "2105490",
    "end": "2112480"
  },
  {
    "text": "takes less than a second so this is something that you can do almost even if",
    "start": "2112480",
    "end": "2117640"
  },
  {
    "text": "you don't have a GPU like you can do transfer learning on top of an order to pre train network if you want to go",
    "start": "2117640",
    "end": "2124750"
  },
  {
    "text": "through and do these projects on your own and things I do recommend this book this is a book that's very easy to",
    "start": "2124750",
    "end": "2131620"
  },
  {
    "text": "digest even if you have no formal machine learning training it's a good starter book and it explains all these",
    "start": "2131620",
    "end": "2138370"
  },
  {
    "text": "things now I want to talk a little bit about how we attack actual problems and the",
    "start": "2138370",
    "end": "2147559"
  },
  {
    "text": "way my team does it so the first thing when we go through a machine learning",
    "start": "2147559",
    "end": "2153349"
  },
  {
    "text": "problem is we attack it's very much like we do any any other software application",
    "start": "2153349",
    "end": "2160690"
  },
  {
    "text": "trying to understand what the customer actually needs and if if they need",
    "start": "2161230",
    "end": "2168019"
  },
  {
    "text": "machine learning that's not a good machine learning project like you never start a machine learning project by",
    "start": "2168019",
    "end": "2175609"
  },
  {
    "text": "kneading machine learning instead you need to start a machine learning problem project with a problem that can",
    "start": "2175609",
    "end": "2183440"
  },
  {
    "text": "eventually maybe need machine learning in fact most of the cases that I work",
    "start": "2183440",
    "end": "2188450"
  },
  {
    "text": "through I try to avoid machine learning as much as possible and go back to the basics of software instead the next",
    "start": "2188450",
    "end": "2195980"
  },
  {
    "text": "thing is figuring out like sort of how will the model be used so in our cases",
    "start": "2195980",
    "end": "2201170"
  },
  {
    "text": "will it be used like real time because real time has some very very specific requirements you can't do a lot of",
    "start": "2201170",
    "end": "2207319"
  },
  {
    "text": "pre-processing you can't do a lot of expensive expensive image processing for",
    "start": "2207319",
    "end": "2214490"
  },
  {
    "text": "example on each frame and things like that but also the requirements like for example in the case of the cancer",
    "start": "2214490",
    "end": "2221269"
  },
  {
    "text": "detection you can't just miss a few it's not okay like that would be a terrible terrible",
    "start": "2221269",
    "end": "2227509"
  },
  {
    "text": "thing if you would miss a few cells here and there you need to at least be as",
    "start": "2227509",
    "end": "2232549"
  },
  {
    "text": "good as to human that does it now or else you've failed so if you have a",
    "start": "2232549",
    "end": "2237859"
  },
  {
    "text": "requirement that's like a hundred percent accuracy or a precision or Riko",
    "start": "2237859",
    "end": "2243740"
  },
  {
    "text": "precision and recall means basically can you get something wrong or can you get an overly like an you have a lot of",
    "start": "2243740",
    "end": "2252730"
  },
  {
    "text": "true-true falses what sorry true negatives and whatever you get things",
    "start": "2252730",
    "end": "2259339"
  },
  {
    "text": "wrong and if you can't get many things wrong",
    "start": "2259339",
    "end": "2265119"
  },
  {
    "text": "and then maybe machine learning is not your thing um and the other thing is how is it done",
    "start": "2265119",
    "end": "2270910"
  },
  {
    "text": "today like so how do how does a doctor actually do this cancer detection and because that will tell you a lot about",
    "start": "2270910",
    "end": "2277080"
  },
  {
    "text": "what kind of things you might actually use to solve the problem because not",
    "start": "2277080",
    "end": "2282190"
  },
  {
    "text": "very not many problems are like the Chihuahua in the muffin case where you have a bunch of data and outcomes and",
    "start": "2282190",
    "end": "2288130"
  },
  {
    "text": "output instead usually a machine learning project aims to be a lot of small pieces that mean that you piece",
    "start": "2288130",
    "end": "2295480"
  },
  {
    "text": "together and eventually create like a much larger model and also a very very",
    "start": "2295480",
    "end": "2302050"
  },
  {
    "text": "important question is if it's feasible or not is it feasible to get a lot",
    "start": "2302050",
    "end": "2307060"
  },
  {
    "text": "better accuracy than the realtor on the house price case maybe not if you don't",
    "start": "2307060",
    "end": "2312369"
  },
  {
    "text": "have the data that could actually back up that decision and finally something that's very close to my heart and maybe",
    "start": "2312369",
    "end": "2319450"
  },
  {
    "text": "some of you went to my session yesterday our death achill concerns around machine learning basically in the case of",
    "start": "2319450",
    "end": "2326260"
  },
  {
    "text": "shoplifting not trying to predict that a person maybe might be a shoplifter and",
    "start": "2326260",
    "end": "2333250"
  },
  {
    "text": "assume that they are but instead actually detect when they do shoplifting",
    "start": "2333250",
    "end": "2338770"
  },
  {
    "text": "and things like that so think about biases that might creep",
    "start": "2338770",
    "end": "2343900"
  },
  {
    "text": "and how it's gonna work for the whole population that you're that you're gonna create a model for etc so understanding",
    "start": "2343900",
    "end": "2351880"
  },
  {
    "text": "the business needs it's like by far the biggest part of things and then you go through and mined the data unlike",
    "start": "2351880",
    "end": "2357640"
  },
  {
    "text": "basically get all the supporting data and not much before you know how this is normally solved can you actually decide",
    "start": "2357640",
    "end": "2364510"
  },
  {
    "text": "what type of data you need then you cleaned data so in the in the case of",
    "start": "2364510",
    "end": "2369670"
  },
  {
    "text": "the shoplifting one we had a lot of cases where um we and we had like",
    "start": "2369670",
    "end": "2375400"
  },
  {
    "text": "fisheye lenses that we needed to remove because they we couldn't really work with those they didn't give us the same",
    "start": "2375400",
    "end": "2382410"
  },
  {
    "text": "kind of patterns that the other video stayed or things like we also had a",
    "start": "2382410",
    "end": "2389320"
  },
  {
    "text": "clock in a corner like an artifact of the video cam that we needed to remove",
    "start": "2389320",
    "end": "2394360"
  },
  {
    "text": "to avoid training on that and things and explore data and try to figure out sort",
    "start": "2394360",
    "end": "2400090"
  },
  {
    "text": "of like can we tell some telltale signs already can we and can I make up a",
    "start": "2400090",
    "end": "2406540"
  },
  {
    "text": "logical function for how the house price is going to be calculated and if I can",
    "start": "2406540",
    "end": "2414660"
  },
  {
    "text": "then I should so this is a very true statement for me at least and like the",
    "start": "2414660",
    "end": "2420970"
  },
  {
    "text": "older I get the more I realize that the biggest problem to solve in tech is to get people to stop making things harder",
    "start": "2420970",
    "end": "2426850"
  },
  {
    "text": "than they have to be if you get to the point where you've explored the data and you realize that dude",
    "start": "2426850",
    "end": "2434020"
  },
  {
    "text": "I don't need machine learning for this like I'm gonna try to find a pattern enough like my YouTube users and the",
    "start": "2434020",
    "end": "2441010"
  },
  {
    "text": "best pattern for that it's gonna be whatever the pattern was last week they used last week's number don't create",
    "start": "2441010",
    "end": "2448420"
  },
  {
    "text": "like a crazy-ass model that's gonna predict what your pattern is gonna be like if it's apparently visible to you",
    "start": "2448420",
    "end": "2454960"
  },
  {
    "text": "you start because that's gonna be so much more explainable and so much more",
    "start": "2454960",
    "end": "2461070"
  },
  {
    "text": "[Music] maintainable than any machine learning",
    "start": "2461070",
    "end": "2466150"
  },
  {
    "text": "model because a machine learning model it's always gonna be probabilistic it's always gonna maybe give you an answer or",
    "start": "2466150",
    "end": "2471820"
  },
  {
    "text": "maybe give you the right answer but you're also gonna have a lot of uncertainty of how it reached that",
    "start": "2471820",
    "end": "2477250"
  },
  {
    "text": "conclusion so once you've explored and decided that yeah we are gonna do machine learning",
    "start": "2477250",
    "end": "2482740"
  },
  {
    "text": "here then you're gonna go through and engineer features because although I",
    "start": "2482740",
    "end": "2489190"
  },
  {
    "text": "said deep learning can get to features for you normally we don't have enough",
    "start": "2489190",
    "end": "2494260"
  },
  {
    "text": "samples to do the end-to-end deep learning so we have to split up the problem in multiple different small",
    "start": "2494260",
    "end": "2501760"
  },
  {
    "text": "things and engineer features from them that we understand and we can use to create a final model and then you create",
    "start": "2501760",
    "end": "2508930"
  },
  {
    "text": "a model and in then you're deployed to bomb and run because it's gonna feel",
    "start": "2508930",
    "end": "2514150"
  },
  {
    "text": "it's gonna fail badly and you need to not be there when that happens or maybe",
    "start": "2514150",
    "end": "2520510"
  },
  {
    "text": "you should be there actually you should be there and this is where you you you",
    "start": "2520510",
    "end": "2526300"
  },
  {
    "text": "test it in a safe environment you fail and then you go through the process again and you refine and you refine",
    "start": "2526300",
    "end": "2533320"
  },
  {
    "text": "until you get to a point where it's actually something that you're ready to release in production and you still",
    "start": "2533320",
    "end": "2540630"
  },
  {
    "text": "reiterate because things are gonna change like the style and like the house market is gonna change and we're gonna",
    "start": "2540630",
    "end": "2546130"
  },
  {
    "text": "have to rebuild this model you need to be aware that you need to have a cadence for rebuilding these models now shots on",
    "start": "2546130",
    "end": "2554680"
  },
  {
    "text": "goal and the way we worked is this is like sort of one of those really really",
    "start": "2554680",
    "end": "2560350"
  },
  {
    "text": "Mies machine learning products because we had a lot of sampled a lot of labeled samples a lot of time people have gone",
    "start": "2560350",
    "end": "2567760"
  },
  {
    "text": "in and said this was shot on goal this was a shot on goal and we had a lot of videos that we could use and we",
    "start": "2567760",
    "end": "2573040"
  },
  {
    "text": "literally had no consequential decisions it doesn't matter if we get this wrong I mean it's nice if we get it right but no",
    "start": "2573040",
    "end": "2579820"
  },
  {
    "text": "one will die if we get this wrong so we went through and explore the data and we",
    "start": "2579820",
    "end": "2585340"
  },
  {
    "text": "found a couple of things when there was a shot on goal we had a loud crowd so we",
    "start": "2585340",
    "end": "2591130"
  },
  {
    "text": "discovered that we could use the audio for this and we also found that the goal",
    "start": "2591130",
    "end": "2596410"
  },
  {
    "text": "was often visible so we had a bit of a question there about like should we",
    "start": "2596410",
    "end": "2601810"
  },
  {
    "text": "create a model that actually detects goal or no goal to just test our model",
    "start": "2601810",
    "end": "2607210"
  },
  {
    "text": "and make sure that we're not yes doing gold or no gold detection because that's a very possible thing we also had some",
    "start": "2607210",
    "end": "2613600"
  },
  {
    "text": "ideas around the speed and direction of the players could we use that to to",
    "start": "2613600",
    "end": "2619000"
  },
  {
    "text": "enhance the model to figure out like if the players were running in in a certain with a certain speed in a certain",
    "start": "2619000",
    "end": "2625210"
  },
  {
    "text": "direction and they were more likely to do a shot on goal and then we also had some ideas around player density which",
    "start": "2625210",
    "end": "2631540"
  },
  {
    "text": "means that um if someone is shooting gold and there's usually like a bunch of",
    "start": "2631540",
    "end": "2637120"
  },
  {
    "text": "people huddled together around the ball specifically when that happens we saw that time after time when went through",
    "start": "2637120",
    "end": "2643780"
  },
  {
    "text": "the samples and then we had some player poses that were very specific for shots",
    "start": "2643780",
    "end": "2649120"
  },
  {
    "text": "on goal that we could use and we also saw some other things like scene changes",
    "start": "2649120",
    "end": "2656170"
  },
  {
    "text": "like after a shot on goal it was like a lit early always a shot of a shot of",
    "start": "2656170",
    "end": "2663550"
  },
  {
    "text": "Ibrahimovic afterwards yeah so I'm not a whole him of course but um we we wanted",
    "start": "2663550",
    "end": "2671920"
  },
  {
    "text": "to be careful not to pick up used to seeing changes and make that like what we were detecting and again making sure",
    "start": "2671920",
    "end": "2679660"
  },
  {
    "text": "we're not just checking the golden golden view but the other really big problem we had was figuring out uh as",
    "start": "2679660",
    "end": "2687670"
  },
  {
    "text": "opposed to the shoe I wore a muffin case where it's like she was here in muffins here what is the opposite of shot on",
    "start": "2687670",
    "end": "2694780"
  },
  {
    "text": "goal like crowd pictures is not a shot on goal but that's so easy for a machine",
    "start": "2694780",
    "end": "2702160"
  },
  {
    "text": "learning model to detect like the crowd picture versus a shot on goal so we had to figure out something that was very",
    "start": "2702160",
    "end": "2708430"
  },
  {
    "text": "very similar to a shot on goal but not a shot on goal so we decided to go with",
    "start": "2708430",
    "end": "2713470"
  },
  {
    "text": "attacks that were not directly on gold because you want to create something that's very hard for for the machine",
    "start": "2713470",
    "end": "2721480"
  },
  {
    "text": "learning model to distinguish between in order to make it ask for a bust as you can so we did 5 second videos we clip",
    "start": "2721480",
    "end": "2729550"
  },
  {
    "text": "them up into 5 second videos and we think the negative sample is s attacks",
    "start": "2729550",
    "end": "2734560"
  },
  {
    "text": "and then we did this so every every 5",
    "start": "2734560",
    "end": "2739630"
  },
  {
    "text": "second video is now at 127 frames and we went through and we used vgg so v2g is",
    "start": "2739630",
    "end": "2746730"
  },
  {
    "text": "an architecture of neural network that's pre trained on an image net and you can",
    "start": "2746730",
    "end": "2752410"
  },
  {
    "text": "extract these embeddings from it so we took the embeddings and put them in a",
    "start": "2752410",
    "end": "2757900"
  },
  {
    "text": "table so for all hundred twenty seven we had 120 summer rows of a thousand 24",
    "start": "2757900",
    "end": "2764740"
  },
  {
    "text": "embeddings and this now became new images if you will that we could use in",
    "start": "2764740",
    "end": "2771220"
  },
  {
    "text": "a convolutional neural network I really like this technique this was a technique that me Chen and Tim who were on my team",
    "start": "2771220",
    "end": "2779260"
  },
  {
    "text": "and kind of halfway then we could use this both to visualize like what a video",
    "start": "2779260",
    "end": "2785350"
  },
  {
    "text": "actually looks like so if you can imagine so these are like the whites are",
    "start": "2785350",
    "end": "2790630"
  },
  {
    "text": "very high number is worse of blacks or numbers so one of these lines may mean",
    "start": "2790630",
    "end": "2796480"
  },
  {
    "text": "grass we don't know it's gonna be a lot more abstract than that but it may mean grass",
    "start": "2796480",
    "end": "2802060"
  },
  {
    "text": "or it may mean like an hour goalpost or something else that's quite useful and",
    "start": "2802060",
    "end": "2809260"
  },
  {
    "text": "some of these things are are more prevalent in the shots on goal maybe it means like players or maybe two means",
    "start": "2809260",
    "end": "2815620"
  },
  {
    "text": "the ball is there or whatever it could mean and we also have something odd",
    "start": "2815620",
    "end": "2822310"
  },
  {
    "text": "happening like this can someone think of what this might be",
    "start": "2822310",
    "end": "2827970"
  },
  {
    "text": "say again yeah the change of the scene exactly so",
    "start": "2828030",
    "end": "2833350"
  },
  {
    "text": "um the reason why we say that's the change of the scene is because suddenly all the features have changed in that",
    "start": "2833350",
    "end": "2839920"
  },
  {
    "text": "and that one thing so visualizing something like this and actually seeing these come up like this rather than a",
    "start": "2839920",
    "end": "2848110"
  },
  {
    "text": "large set of numbers it's very hard to sort of grog and then this is a much",
    "start": "2848110",
    "end": "2853270"
  },
  {
    "text": "nicer way to look at this and we used a some with Sunday's through a new neural",
    "start": "2853270",
    "end": "2858370"
  },
  {
    "text": "network like a new convolutional neural network and we've got like over ninety percent accuracy of shot on goal with",
    "start": "2858370",
    "end": "2864850"
  },
  {
    "text": "this and even when visualizing aid on the on the video itself we could",
    "start": "2864850",
    "end": "2870520"
  },
  {
    "text": "definitely say that when we were predicting high numbers for four shots",
    "start": "2870520",
    "end": "2875950"
  },
  {
    "text": "on goal we were definitely like in the shot on goal area like in fact the more",
    "start": "2875950",
    "end": "2882430"
  },
  {
    "text": "interesting the the scene was the higher of a probability we had so this was not",
    "start": "2882430",
    "end": "2889510"
  },
  {
    "text": "only yes or no but it was a very nice model for for actually determining how",
    "start": "2889510",
    "end": "2894970"
  },
  {
    "text": "interesting in the and the actual scene was so we could have left it at this we",
    "start": "2894970",
    "end": "2900880"
  },
  {
    "text": "could have used done the VTT embeddings and this is something that we'll now started doing in a lot of our projects",
    "start": "2900880",
    "end": "2907900"
  },
  {
    "text": "with the BT embeddings like this but we also used audio and this is East from a",
    "start": "2907900",
    "end": "2914260"
  },
  {
    "text": "library that extracts the audio features and and with the audio features we also",
    "start": "2914260",
    "end": "2919720"
  },
  {
    "text": "got very high accuracy with the audio features alone so we created a separate model to do that",
    "start": "2919720",
    "end": "2925920"
  },
  {
    "text": "then we now have these models competing and saying do you think it was a shot on",
    "start": "2925920",
    "end": "2931770"
  },
  {
    "text": "goal do you think it was a shot on goal and that way creating a more robust model we also we haven't actually",
    "start": "2931770",
    "end": "2940170"
  },
  {
    "text": "implemented these but these were our ideas around sort of the people in clustering things so think of splitting",
    "start": "2940170",
    "end": "2947520"
  },
  {
    "text": "up the image in a number of like in a grid pattern but a pretty coarse grid pattern and then doing object detection",
    "start": "2947520",
    "end": "2954990"
  },
  {
    "text": "on the people and determining where they are in the squares so if multiple people",
    "start": "2954990",
    "end": "2960089"
  },
  {
    "text": "show up like close to each other or in the same squares and you have higher player density and also recording things",
    "start": "2960089",
    "end": "2967589"
  },
  {
    "text": "like the size of the squares because that will tell you now if it's a close-up shot or a crowd shot or like a",
    "start": "2967589",
    "end": "2976380"
  },
  {
    "text": "shot with a bunch of players so that was one another way to represent this image",
    "start": "2976380",
    "end": "2983030"
  },
  {
    "text": "differently and to do object detection again you can use a pre-trade model like",
    "start": "2983030",
    "end": "2989160"
  },
  {
    "text": "in this case a pre trained model of retina net on on cocoa which gives you",
    "start": "2989160",
    "end": "2994799"
  },
  {
    "text": "80 classes and a very very high accuracy of of like the people detection for",
    "start": "2994799",
    "end": "3001369"
  },
  {
    "text": "example so we could use this quite quickly on on every third frame or",
    "start": "3001369",
    "end": "3006410"
  },
  {
    "text": "something because it's a little bit more expensive than then you would want to do",
    "start": "3006410",
    "end": "3012230"
  },
  {
    "text": "like on each frame and do player detection on it then we didn't just a quick classifier",
    "start": "3012230",
    "end": "3019760"
  },
  {
    "text": "gold or no gold again - to test that it wasn't picking up the gold or no gold wish it wasn't and then we also did",
    "start": "3019760",
    "end": "3026660"
  },
  {
    "text": "their own scene change detection which was taking is a random 20 pixels and",
    "start": "3026660",
    "end": "3033130"
  },
  {
    "text": "verifying if they changed enough between frames that we looked at it as a scene",
    "start": "3033130",
    "end": "3038990"
  },
  {
    "text": "change so that was a very simple scene change detector but again in CV 2",
    "start": "3038990",
    "end": "3044270"
  },
  {
    "text": "there's also scene change detection there's plenty of these to go around we just wanted to do something super super",
    "start": "3044270",
    "end": "3049670"
  },
  {
    "text": "quick and we were lucky enough that it wasn't the scene change that it did pick",
    "start": "3049670",
    "end": "3054829"
  },
  {
    "text": "up and then we went through and we use something called optical flow so optical flow and let's see here looks",
    "start": "3054829",
    "end": "3067640"
  },
  {
    "text": "like this so it takes a number of pixels",
    "start": "3067640",
    "end": "3072920"
  },
  {
    "text": "and it follows them through the frames so what it does is just gives you the",
    "start": "3072920",
    "end": "3080869"
  },
  {
    "text": "speed and direction of certain items and in our case we use something that we called focused optical flow where we",
    "start": "3080869",
    "end": "3087890"
  },
  {
    "text": "decided what it should look at and we decided that it should specifically look at the boxes off the players this again",
    "start": "3087890",
    "end": "3094819"
  },
  {
    "text": "is not a complicated thing it's it looks quite complicated like this but what it actually does because pixels don't tend",
    "start": "3094819",
    "end": "3102769"
  },
  {
    "text": "to move that much between frames and don't Ain tend to change that much of luminosity between frames so it's quite",
    "start": "3102769",
    "end": "3109219"
  },
  {
    "text": "easy to do these calculations and in CB",
    "start": "3109219",
    "end": "3115849"
  },
  {
    "text": "2 you can do optical flow and we'll go through and quickly look at the cancer",
    "start": "3115849",
    "end": "3123890"
  },
  {
    "text": "detection case in that case we had a totally different scenario we have very very few positive samples in fact in a",
    "start": "3123890",
    "end": "3132109"
  },
  {
    "text": "very large slide third and generally only a few a few cells that are morphed",
    "start": "3132109",
    "end": "3139460"
  },
  {
    "text": "and we had extreme accuracy needs like I mentioned before but also potential for",
    "start": "3139460",
    "end": "3145009"
  },
  {
    "text": "bias because we don't know necessarily how our model will work like we need to be very careful to make sure it works",
    "start": "3145009",
    "end": "3151489"
  },
  {
    "text": "for everyone like all the patients that could possibly get through here so and",
    "start": "3151489",
    "end": "3156859"
  },
  {
    "text": "the way this works is they create biopsy slides like basically take a piece of",
    "start": "3156859",
    "end": "3164089"
  },
  {
    "text": "your skin or a little bit lower down and then they create very thin slices and",
    "start": "3164089",
    "end": "3171769"
  },
  {
    "text": "mark them with chemical called SOS an SOS what it will do is it will mark",
    "start": "3171769",
    "end": "3177109"
  },
  {
    "text": "everything brown that's morphed that could be malign or benign cancer but",
    "start": "3177109",
    "end": "3182900"
  },
  {
    "text": "it's definitely a morph to cell that needs to be looking into and the problems the doctors have is it's not",
    "start": "3182900",
    "end": "3189200"
  },
  {
    "text": "when and at least pass through this it's not when you have a lot of them because they",
    "start": "3189200",
    "end": "3194790"
  },
  {
    "text": "will show up and someone can say yeah this and we definitely need to look at this slide a bit more and do do deeper",
    "start": "3194790",
    "end": "3202260"
  },
  {
    "text": "checks to see if it's malign or benign the problem they had was when there was only one or two cells in these slides",
    "start": "3202260",
    "end": "3209220"
  },
  {
    "text": "because suddenly the doctors had to go through this humungous like a million by",
    "start": "3209220",
    "end": "3214260"
  },
  {
    "text": "a million image zoom in 50 times in every little detail to verify that there",
    "start": "3214260",
    "end": "3220020"
  },
  {
    "text": "was not a cancer cell in there so the problem is like picking out these",
    "start": "3220020",
    "end": "3225540"
  },
  {
    "text": "needles in the haystack like picking out to brown dots from them and one of the",
    "start": "3225540",
    "end": "3231840"
  },
  {
    "text": "problems that we had in order to do any machine learning on it was that they only partially annotated these so if",
    "start": "3231840",
    "end": "3238110"
  },
  {
    "text": "there was a lot of morphed Seles then they only marked a few and said this is",
    "start": "3238110",
    "end": "3244110"
  },
  {
    "text": "an example of a morphed cell so we can't use the the rest saying that they were",
    "start": "3244110",
    "end": "3249390"
  },
  {
    "text": "not morphed so instead of doing machine learning on days we decided to do something completely different we",
    "start": "3249390",
    "end": "3256290"
  },
  {
    "text": "decided that since the doctors the way they work they work just looking for brown or blue in this case and it's",
    "start": "3256290",
    "end": "3264000"
  },
  {
    "text": "quite nicely differentiated with the brown and the blue so we used sort of",
    "start": "3264000",
    "end": "3272360"
  },
  {
    "text": "clustered the different colors in in the image to cluster the Blues together and",
    "start": "3272360",
    "end": "3278010"
  },
  {
    "text": "the browns together and then separate them out like this basically it's doing",
    "start": "3278010",
    "end": "3283380"
  },
  {
    "text": "color decomposition and and then create a mask where we only extract the the",
    "start": "3283380",
    "end": "3291210"
  },
  {
    "text": "cells that are morphed and then cluster them together using something called convex hull then again it's not a",
    "start": "3291210",
    "end": "3298260"
  },
  {
    "text": "machine learning thing it's a IC and just a general graphics processing thing",
    "start": "3298260",
    "end": "3303660"
  },
  {
    "text": "but this way we could now actually mark them out in the exact same way that the",
    "start": "3303660",
    "end": "3310500"
  },
  {
    "text": "doctors do with very high accuracy because we're not doing anything probabilistic like machine learning",
    "start": "3310500",
    "end": "3316170"
  },
  {
    "text": "we're doing something very factual like decomposing colors something that we",
    "start": "3316170",
    "end": "3321210"
  },
  {
    "text": "know that the reason why I see this or not see the it's because the colors are different and the doctors can trust us so this is",
    "start": "3321210",
    "end": "3328080"
  },
  {
    "text": "a case of not using machine learning and I really wanted to show that too and",
    "start": "3328080",
    "end": "3333200"
  },
  {
    "text": "[Music] lastly the shoplifting case is quite interesting because in this case we also",
    "start": "3333200",
    "end": "3339119"
  },
  {
    "text": "had very few samples and they didn't have a lot of examples of shoplifting and it turned out that the examples they",
    "start": "3339119",
    "end": "3346260"
  },
  {
    "text": "had were some of them were shoplifting into clothes and some into a bag and some arias walking out with whatever",
    "start": "3346260",
    "end": "3353070"
  },
  {
    "text": "they shoplifted and things like that so even the cases we had were very varied and there wasn't like a deep pattern to",
    "start": "3353070",
    "end": "3359760"
  },
  {
    "text": "them and it's very very sensitive to bias so it's very very sensitive to",
    "start": "3359760",
    "end": "3364950"
  },
  {
    "text": "picking up things like these were some of the things that we found when when we",
    "start": "3364950",
    "end": "3370440"
  },
  {
    "text": "did the data analysis but it's very sensitive to picking up that if you were a man 20 to 40 and wore a hoodie that",
    "start": "3370440",
    "end": "3377550"
  },
  {
    "text": "was like the major demographic in the and the shoplifting case right and we",
    "start": "3377550",
    "end": "3382920"
  },
  {
    "text": "wanted to make sure that we did not create a model that said man 20 to 40",
    "start": "3382920",
    "end": "3387990"
  },
  {
    "text": "with a hoodie shoplifter because that's you know it's well you realize why",
    "start": "3387990",
    "end": "3396000"
  },
  {
    "text": "that's the problem and and obviously also we didn't want someone to go in and say hey if you covered your face and",
    "start": "3396000",
    "end": "3402359"
  },
  {
    "text": "you're alone you're automatically a shoplifter because that is also not the case and so instead we had to go and",
    "start": "3402359",
    "end": "3409410"
  },
  {
    "text": "look at the shoplifting poses so um at least scroll this through so in the",
    "start": "3409410",
    "end": "3416250"
  },
  {
    "text": "middle is a one of the one of the things that we always try to do is detect",
    "start": "3416250",
    "end": "3421619"
  },
  {
    "text": "versus predict so detect that someone is shoplifting detect opposes detect the actual action instead of doing",
    "start": "3421619",
    "end": "3427980"
  },
  {
    "text": "predictive policing and assuming that someone will be a shoplifter is because",
    "start": "3427980",
    "end": "3433680"
  },
  {
    "text": "there are certain demographic a couple of other things we had problems with I mentioned the fisheye but also the fact",
    "start": "3433680",
    "end": "3439589"
  },
  {
    "text": "that most of the samples we had from shoplifting were taken during the Christmas season because that was sort",
    "start": "3439589",
    "end": "3446820"
  },
  {
    "text": "of like they had grabbed a certain set of their videos and extracted the",
    "start": "3446820",
    "end": "3453070"
  },
  {
    "text": "shoplifting from them so we wanted to make sure that we did not detect Santa",
    "start": "3453070",
    "end": "3459160"
  },
  {
    "text": "Claus and assume that someone was shoplifting because that well maybe",
    "start": "3459160",
    "end": "3464260"
  },
  {
    "text": "that's not as bad as the ticketing men 22:40 so in order to to make sure that",
    "start": "3464260",
    "end": "3473110"
  },
  {
    "text": "these samples were similar enough we actually picked negative sampling from the actual in the same videos that",
    "start": "3473110",
    "end": "3478930"
  },
  {
    "text": "shoplifting was from and we also did tight and decided to take when people",
    "start": "3478930",
    "end": "3484150"
  },
  {
    "text": "were shopping and when people looked sort of like the same way they were in the same situation as when they were",
    "start": "3484150",
    "end": "3489369"
  },
  {
    "text": "shoplifting but they were used to shopping around like they were shopping for the same type of items and that kind",
    "start": "3489369",
    "end": "3495640"
  },
  {
    "text": "of thing rather than taking empty aisles and for post-detection we also used like",
    "start": "3495640",
    "end": "3501940"
  },
  {
    "text": "a pre pre trained model to get like the key items out and use those as features",
    "start": "3501940",
    "end": "3509110"
  },
  {
    "text": "for the post-detection but then we used them this background subtraction and",
    "start": "3509110",
    "end": "3515080"
  },
  {
    "text": "this is again an open CV thing so if you work with a division you'll always do",
    "start": "3515080",
    "end": "3521920"
  },
  {
    "text": "sort of open CV so what this does is it says anything that's moving is something",
    "start": "3521920",
    "end": "3529119"
  },
  {
    "text": "that I want to filter out now you can see it as long as the camera is stationary we only see the people in",
    "start": "3529119",
    "end": "3534640"
  },
  {
    "text": "here later on as the camera starts moving and we'll see that other things become white but in our case with the",
    "start": "3534640",
    "end": "3542619"
  },
  {
    "text": "shoplifting our cameras were always stationary so this way we could extract",
    "start": "3542619",
    "end": "3548050"
  },
  {
    "text": "only the moving things only the people and do our machine learning on that",
    "start": "3548050",
    "end": "3553300"
  },
  {
    "text": "which was a quite useful thing to avoid having the having things like the floor",
    "start": "3553300",
    "end": "3561030"
  },
  {
    "text": "or Christmas lighting or things like that show up and then we did",
    "start": "3561030",
    "end": "3566710"
  },
  {
    "text": "classification at the box level we did classification only on the people so to",
    "start": "3566710",
    "end": "3573609"
  },
  {
    "text": "sum this up like a little domain knowledge and understanding and doing a lot of data analysis and prep goes a",
    "start": "3573609",
    "end": "3580030"
  },
  {
    "text": "long way and you most often need to do like",
    "start": "3580030",
    "end": "3585520"
  },
  {
    "text": "composite composite models with more than end-to-end models mostly because you don't have enough data and you want",
    "start": "3585520",
    "end": "3592280"
  },
  {
    "text": "to have a little bit more granularity around and what your model actually picks up to make it more interpretable",
    "start": "3592280",
    "end": "3598760"
  },
  {
    "text": "and the last thing I want to leave with is keep it simple like don't just apply",
    "start": "3598760",
    "end": "3605150"
  },
  {
    "text": "machine learning because it's fun apply machine learning where it makes sense but if you have a case like the like the",
    "start": "3605150",
    "end": "3613790"
  },
  {
    "text": "cancer detection case where you can solve it in a different way that's better use that and finally if you want",
    "start": "3613790",
    "end": "3621590"
  },
  {
    "text": "to learn more about the way we do things we have a channel called machine learning at Microsoft where me and my",
    "start": "3621590",
    "end": "3628010"
  },
  {
    "text": "team and do paper reviews but also talk about our cases that we work on so if",
    "start": "3628010",
    "end": "3633650"
  },
  {
    "text": "you're interested in that please go in and watch and subscribe that but with",
    "start": "3633650",
    "end": "3639560"
  },
  {
    "text": "that I want to thank you so much for showing up this early I really appreciate it thanks",
    "start": "3639560",
    "end": "3645270"
  },
  {
    "text": "[Applause]",
    "start": "3645270",
    "end": "3650460"
  }
]
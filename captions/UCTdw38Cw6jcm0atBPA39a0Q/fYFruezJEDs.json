[
  {
    "text": "cool okay let's start welcome everyone hope you had a good good lunch um",
    "start": "399",
    "end": "8720"
  },
  {
    "text": "what i'm going to talk about um today is [Music] our async code reviews and",
    "start": "8720",
    "end": "15839"
  },
  {
    "text": "the study that i did that has spanned a period of six plus months",
    "start": "15839",
    "end": "23680"
  },
  {
    "text": "at the end it involved typical product development teams",
    "start": "23680",
    "end": "29199"
  },
  {
    "text": "uh i analyzed around 40 plus very active repositories and tens of thousands of pull requests so",
    "start": "29199",
    "end": "35520"
  },
  {
    "text": "today i'm going to share with you the conclusions that i got out of the study",
    "start": "35520",
    "end": "42000"
  },
  {
    "text": "so my name is dragan stepanovic i work as a senior principal engineer at the company called",
    "start": "42320",
    "end": "47440"
  },
  {
    "text": "talbot which is a deliberate hero company and my main areas of interests are xp",
    "start": "47440",
    "end": "54079"
  },
  {
    "text": "extreme programming poc which is theory of constraints lean systems thinking",
    "start": "54079",
    "end": "61600"
  },
  {
    "text": "and i tend to rant on social media and",
    "start": "61600",
    "end": "66640"
  },
  {
    "text": "blog and there's also one terrifying fact about me is that i put my own pizza for some reason",
    "start": "66640",
    "end": "72640"
  },
  {
    "text": "i don't know if there are any italians in the audience but yeah it'd be really funny to see their faces now",
    "start": "72640",
    "end": "79280"
  },
  {
    "text": "so just to frame the talk for today",
    "start": "80320",
    "end": "86040"
  },
  {
    "text": "i'm not saying that the context that i had is the same context that you had um i won't be telling you that you",
    "start": "87040",
    "end": "93920"
  },
  {
    "text": "should do the things that i concluded for for the teams that i've been working with um i'll just share the",
    "start": "93920",
    "end": "100960"
  },
  {
    "text": "learnings that they had out of this journey so not sure how many of you have heard for",
    "start": "100960",
    "end": "106960"
  },
  {
    "text": "this quote nobody ever got fired for buying ibm and the quote comes from 80s as far as i",
    "start": "106960",
    "end": "114960"
  },
  {
    "text": "remember and the idea was that most of the",
    "start": "114960",
    "end": "121119"
  },
  {
    "text": "folks from the procurement departments went with ibm as a default as a vendor",
    "start": "121119",
    "end": "127439"
  },
  {
    "text": "because ibm at the time had a huge market share",
    "start": "127439",
    "end": "133200"
  },
  {
    "text": "and it was easier to go with them because everyone else went with ibm and um",
    "start": "133200",
    "end": "138879"
  },
  {
    "text": "if anything goes wrong it's ibm hey with the top",
    "start": "138879",
    "end": "143840"
  },
  {
    "text": "and the other thing is that the folks that wanted to go with some",
    "start": "144080",
    "end": "149599"
  },
  {
    "text": "other vendor had to answer a lot of questions that made made the whole process expensive",
    "start": "149599",
    "end": "154959"
  },
  {
    "text": "for them to procure someone else so it really depends on the context",
    "start": "154959",
    "end": "160080"
  },
  {
    "text": "in which you're operating in and what are the problems you're trying to solve",
    "start": "160080",
    "end": "165440"
  },
  {
    "text": "so when i say nobody ever got fired for by buying ibm",
    "start": "165440",
    "end": "170720"
  },
  {
    "text": "and when i think about the typical software development process that we tend to have in the teams",
    "start": "170720",
    "end": "175840"
  },
  {
    "text": "i often think about the pr based async code review so i try to visualize it here",
    "start": "175840",
    "end": "183440"
  },
  {
    "text": "and we have let's say two developers emma and luca",
    "start": "183440",
    "end": "188800"
  },
  {
    "text": "and it's a start of the sprint let's say that team is working in a sprint in scrum",
    "start": "188800",
    "end": "194400"
  },
  {
    "text": "methodology and um emma pulls in ticket number one here and",
    "start": "194400",
    "end": "201519"
  },
  {
    "text": "local pulls in ticket number two so they start working on their own respective tickets",
    "start": "201519",
    "end": "207280"
  },
  {
    "text": "and at one point emma codes make some changes introduce some",
    "start": "207280",
    "end": "212879"
  },
  {
    "text": "changes to the system hopefully tests and at one point she figures out okay i think i should ask",
    "start": "212879",
    "end": "219200"
  },
  {
    "text": "for a review for my peers so she creates a pull request",
    "start": "219200",
    "end": "225040"
  },
  {
    "text": "and invites luca for the review but look he's busy with something else",
    "start": "225040",
    "end": "230080"
  },
  {
    "text": "so he's working on ticket number two there are lots of other things going around",
    "start": "230080",
    "end": "235280"
  },
  {
    "text": "um lunch breaks outside of the business hours",
    "start": "235280",
    "end": "241599"
  },
  {
    "text": "review meetings checkings like checking email etc reviewing other pr's",
    "start": "241599",
    "end": "246720"
  },
  {
    "text": "so luke is not able to immediately respond and what happens is also emma while",
    "start": "246720",
    "end": "252959"
  },
  {
    "text": "she's figuring out okay since i'm waiting i want to be a good employee so i want",
    "start": "252959",
    "end": "258000"
  },
  {
    "text": "to keep working on something so she pulls in another ticket take number three",
    "start": "258000",
    "end": "264720"
  },
  {
    "text": "at one point she figures out about is not answering maybe i should uh remind him",
    "start": "264720",
    "end": "272400"
  },
  {
    "text": "and i often see these plays and you know these begging emojis in this kind of",
    "start": "272400",
    "end": "277680"
  },
  {
    "text": "systems where the working progress is really high i would even say that the amount of",
    "start": "277680",
    "end": "284560"
  },
  {
    "text": "praying hands that you see in the systems is proportional to the amount of whip that you get to see",
    "start": "284560",
    "end": "289759"
  },
  {
    "text": "so the system is telling you something but at one point luca is able to come",
    "start": "289759",
    "end": "295759"
  },
  {
    "text": "around and he reviews the change asks for some um reviews the pr asks for some",
    "start": "295759",
    "end": "300960"
  },
  {
    "text": "changes um and sends back the pr to emma",
    "start": "300960",
    "end": "306639"
  },
  {
    "text": "but them is busy with something else now she's working ticket number three there are lots of other things going on so she's not able to react immediately now",
    "start": "306639",
    "end": "314400"
  },
  {
    "text": "and eventually she comes around and she incorporates the changes",
    "start": "314400",
    "end": "319680"
  },
  {
    "text": "and they go back and forth and at one point they converge approve the polarquest",
    "start": "319680",
    "end": "325600"
  },
  {
    "text": "emergent so interesting thing to look at here is",
    "start": "325600",
    "end": "330960"
  },
  {
    "text": "there are lots of things going on but if we focus on ticket number one and we look at its lead time from start",
    "start": "330960",
    "end": "337039"
  },
  {
    "text": "to finish there are two different types of things that are going on with it so one thing is",
    "start": "337039",
    "end": "344000"
  },
  {
    "text": "ticket number one is being actively worked on which is called in lean processing or",
    "start": "344000",
    "end": "349759"
  },
  {
    "text": "touch time and the other way other thing that is going on is the wait time so",
    "start": "349759",
    "end": "356160"
  },
  {
    "text": "when the item is just sitting there in a queue waiting for someone's attention",
    "start": "356160",
    "end": "362800"
  },
  {
    "text": "so to provide a bit more of a context of the study that i did um i tend to advise",
    "start": "363440",
    "end": "370479"
  },
  {
    "text": "and mentor and coach teams um",
    "start": "370479",
    "end": "375840"
  },
  {
    "text": "in a way that we try together to figure out how to maximize the throughput of",
    "start": "376319",
    "end": "381840"
  },
  {
    "text": "the value of the whole team and one of the things that they tend to use but to look at is the",
    "start": "381840",
    "end": "388240"
  },
  {
    "text": "way that people work in a team right so my guiding principle is meet people",
    "start": "388240",
    "end": "393840"
  },
  {
    "text": "where they are and often in the teams that do peer-based async code reviews",
    "start": "393840",
    "end": "400000"
  },
  {
    "text": "there's a certain percentage of managers and engineers that would like",
    "start": "400000",
    "end": "406080"
  },
  {
    "text": "to have a bit more data informed way when it comes to different way of working yes we would like to try out",
    "start": "406080",
    "end": "412080"
  },
  {
    "text": "something else but how does it compare to what we have currently now so we would like also to visual or",
    "start": "412080",
    "end": "419520"
  },
  {
    "text": "visualize our current system so what was i curious to see",
    "start": "419520",
    "end": "426479"
  },
  {
    "text": "me coming from the extreme programming background which is very heavy on collaboration as you might",
    "start": "426479",
    "end": "432800"
  },
  {
    "text": "know peer mode programming whole team approach i had a hunch for a couple of things",
    "start": "432800",
    "end": "437919"
  },
  {
    "text": "that i was really curious to see one thing was engagement and",
    "start": "437919",
    "end": "443599"
  },
  {
    "text": "the effects of the delays that we get to see in the system and because of this high",
    "start": "443599",
    "end": "449039"
  },
  {
    "text": "working progress the other thing was wait time um going back to this visual that they",
    "start": "449039",
    "end": "455520"
  },
  {
    "text": "just presented and trying to figure out how much of a wait time we get to see in this kind of",
    "start": "455520",
    "end": "460880"
  },
  {
    "text": "systems and also how does that compare to the size of the pull requests or the amount",
    "start": "460880",
    "end": "466800"
  },
  {
    "text": "of effort that we put in in creating work items",
    "start": "466800",
    "end": "472879"
  },
  {
    "text": "so going into engagement why was i curious about the engagement so",
    "start": "472879",
    "end": "478479"
  },
  {
    "text": "i had this analogy in my head if i have a phone call with someone",
    "start": "478479",
    "end": "484319"
  },
  {
    "text": "and there's a delay in communication between us what tends to happen is that the",
    "start": "484319",
    "end": "489599"
  },
  {
    "text": "conversation dies off very soon so because of a delay the engagement has to",
    "start": "489599",
    "end": "495919"
  },
  {
    "text": "go down and because of that the communication ties off meaning we faster converge",
    "start": "495919",
    "end": "503440"
  },
  {
    "text": "and the other thing while i was what i was curious about when it comes to",
    "start": "503440",
    "end": "508639"
  },
  {
    "text": "engagement was uh the choked feedback and when i say choked feedback",
    "start": "508639",
    "end": "513680"
  },
  {
    "text": "i refer to the usual solutions that we use for reviewing public quests providing",
    "start": "513680",
    "end": "518719"
  },
  {
    "text": "feedback and comments which is you know github gitlab etc and the way that most",
    "start": "518719",
    "end": "524159"
  },
  {
    "text": "of the teams provide feedback is in a written form and written word used way more expensive",
    "start": "524159",
    "end": "530000"
  },
  {
    "text": "than verbal communication takes a longer time",
    "start": "530000",
    "end": "535200"
  },
  {
    "text": "to write and it's also because it's delayed there are other problems with it and i notice there's",
    "start": "535200",
    "end": "543519"
  },
  {
    "text": "way more feedback provided when it's a verbal timely feedback when it comes to the",
    "start": "544080",
    "end": "549839"
  },
  {
    "text": "collaboration in the team so that's what they call the high latency low throughput feedback",
    "start": "549839",
    "end": "556399"
  },
  {
    "text": "in this kind of mode in this way of working and so going into the first scatter plot but",
    "start": "556399",
    "end": "562720"
  },
  {
    "text": "this is just a sample i think this was 500 public fest um each dot that you see here is a",
    "start": "562720",
    "end": "568800"
  },
  {
    "text": "single pull request so on the x axis you can see size in lines",
    "start": "568800",
    "end": "575440"
  },
  {
    "text": "of code now when it comes to the complexity of the work",
    "start": "575440",
    "end": "580959"
  },
  {
    "text": "you can measure it in dozens of ways one way to is to just go ahead with",
    "start": "580959",
    "end": "588160"
  },
  {
    "text": "lines of code the other one is to i don't know count number of affected files of number of",
    "start": "588160",
    "end": "593839"
  },
  {
    "text": "packages etc but for the study that they did i noticed that simple lines of code was enough",
    "start": "593839",
    "end": "600880"
  },
  {
    "text": "and on the y-axis you can see the engagement now the engagement the way that they calculated it was that",
    "start": "600880",
    "end": "607279"
  },
  {
    "text": "i was looking at the amount of feedback in terms of the amount of comments that they get to see",
    "start": "607279",
    "end": "612480"
  },
  {
    "text": "and but i also had in mind that lots of the comments um",
    "start": "612480",
    "end": "619279"
  },
  {
    "text": "were trivial and definition of trivial for me was",
    "start": "619279",
    "end": "625440"
  },
  {
    "text": "kind of um i used to finish it it's kind of silly but it's like less than four words",
    "start": "625440",
    "end": "631360"
  },
  {
    "text": "and the idea behind that was that i get to see often especially in the big prs this lgtm plus one looks good to me etc",
    "start": "631360",
    "end": "639120"
  },
  {
    "text": "right so these are the comments that don't really provide actionable feedback for people to",
    "start": "639120",
    "end": "645040"
  },
  {
    "text": "act on it so on the y-axis you can see the number of control commands",
    "start": "645040",
    "end": "650640"
  },
  {
    "text": "now it's a question what do we see from here probably nothing right there's just a cluster of data",
    "start": "650640",
    "end": "657040"
  },
  {
    "text": "um from this representable data set i would say most of the prs are less than 500 lines of code",
    "start": "657040",
    "end": "663680"
  },
  {
    "text": "and have less than 12 nonchalant comments right but then i started thinking about it",
    "start": "663680",
    "end": "669680"
  },
  {
    "text": "and if i invest let's say a lot of time",
    "start": "669680",
    "end": "674720"
  },
  {
    "text": "let's say seven days working on something and i get certain amount of feedback it's not the same as if i",
    "start": "674720",
    "end": "680079"
  },
  {
    "text": "invest 10 minutes and i get the same amount of feedback right so i was thinking what happens if we",
    "start": "680079",
    "end": "685680"
  },
  {
    "text": "actually normalize the y-axis the engagement will be the engagement",
    "start": "685680",
    "end": "690720"
  },
  {
    "text": "per size right and plot it against the size so the engagement per size is the number of",
    "start": "690720",
    "end": "696240"
  },
  {
    "text": "controller comments per 100 lines of code that we can see here and this was interesting but it was also",
    "start": "696240",
    "end": "702720"
  },
  {
    "text": "expected in a sense so it was interesting because what we can see from here is that",
    "start": "702720",
    "end": "709920"
  },
  {
    "text": "as you increase the size of the pull request the amount of feedback that you get tends to",
    "start": "709920",
    "end": "715920"
  },
  {
    "text": "go exponentially uh down amount of feedback per size right so this was um",
    "start": "715920",
    "end": "724000"
  },
  {
    "text": "for me meant something so i was trying to interpret this and this was the insight that i got from",
    "start": "724000",
    "end": "729120"
  },
  {
    "text": "all of the data set that i've been analyzing and",
    "start": "729120",
    "end": "734240"
  },
  {
    "text": "the thing is if we use code reviews as a process at least as a process to provide feedback in order to build the quality",
    "start": "734240",
    "end": "740320"
  },
  {
    "text": "in if we are not able to get the feedback then we are also not able to build the quality",
    "start": "740320",
    "end": "745600"
  },
  {
    "text": "so what i'm saying is that most probably this means that",
    "start": "745600",
    "end": "750720"
  },
  {
    "text": "as we increase the size of the of the prs the there's there's a higher chance that we",
    "start": "750720",
    "end": "757680"
  },
  {
    "text": "have lack of engagement right and that means that um we are less",
    "start": "757680",
    "end": "763040"
  },
  {
    "text": "likely to build the quality right so not saying anything about the left-hand side i'm not saying that you if you have",
    "start": "763040",
    "end": "768480"
  },
  {
    "text": "feedback that you have quality because it really depends on the type of the feedback security of people providing",
    "start": "768480",
    "end": "774079"
  },
  {
    "text": "the feedback etc right so i'm just saying that if you're using this method in order to build the quality and we're",
    "start": "774079",
    "end": "779760"
  },
  {
    "text": "not able to get the feedback in the first place then we're not able to get the quality as well to build the quality",
    "start": "779760",
    "end": "786000"
  },
  {
    "text": "and this was kind of expected systemic insight that was",
    "start": "786000",
    "end": "791120"
  },
  {
    "text": "expected for me i love this quote never had a huge pr that didn't look good to me",
    "start": "791120",
    "end": "798079"
  },
  {
    "text": "and perhaps some of you also saw this um this week",
    "start": "798079",
    "end": "804079"
  },
  {
    "text": "so um that was expected in a sense right i think all of us already have this by",
    "start": "804079",
    "end": "810079"
  },
  {
    "text": "laughs i can understand that we share the experience and when it comes to building peer",
    "start": "810079",
    "end": "816399"
  },
  {
    "text": "building quality and with big prs i just recently bumped into this tweet and this is how i see it",
    "start": "816399",
    "end": "825240"
  },
  {
    "text": "so reviewers feel like these viewers you know spreading their arms trying to prevent people from going onto the pitch",
    "start": "828880",
    "end": "834320"
  },
  {
    "text": "but it's not really happening um so that was engagement that was the",
    "start": "834320",
    "end": "839360"
  },
  {
    "text": "thing that i kind of expected right but then when it comes to the wait time i had some surprising insights that i also",
    "start": "839360",
    "end": "845440"
  },
  {
    "text": "didn't expect so if you go back to this visual here and focus on ticket number one and also",
    "start": "845440",
    "end": "852639"
  },
  {
    "text": "look at this a timeline at the bottom",
    "start": "852639",
    "end": "858000"
  },
  {
    "text": "we just focus i think at number one and see its lead time we can notice that",
    "start": "858000",
    "end": "864560"
  },
  {
    "text": "there are parts of its lead time where we are actively working on this item and parts of its lead time when this item is",
    "start": "864560",
    "end": "871040"
  },
  {
    "text": "just sitting there in a queue waiting for someone's attention right so i was curious to see how does this",
    "start": "871040",
    "end": "877120"
  },
  {
    "text": "look like in in terms of the of the numbers and",
    "start": "877120",
    "end": "883120"
  },
  {
    "text": "the way that i went about defining the wait time is approximation so every approximation",
    "start": "883120",
    "end": "890480"
  },
  {
    "text": "is good in some cases in some cases it's not so there are some assumptions related to",
    "start": "890480",
    "end": "895839"
  },
  {
    "text": "it um and if you're interested you're going to find um",
    "start": "895839",
    "end": "901120"
  },
  {
    "text": "a series of articles where i dig deeper inside of of this metric",
    "start": "901120",
    "end": "906959"
  },
  {
    "text": "and trying to understand the uh list down the assumptions and the preconditions for the assumptions being",
    "start": "906959",
    "end": "912560"
  },
  {
    "text": "good enough but the way that i went about it was a typical developer taking a ticket and",
    "start": "912560",
    "end": "918800"
  },
  {
    "text": "they start working on an item at one point they figure out they are done they invite other people for",
    "start": "918800",
    "end": "925920"
  },
  {
    "text": "for feedback and at that point the wait times starts to",
    "start": "925920",
    "end": "931440"
  },
  {
    "text": "tick so in the sense of from the last commit that we get to see or from raising public fest until the",
    "start": "931440",
    "end": "937279"
  },
  {
    "text": "public task has been merged that's the way time approximation here",
    "start": "937279",
    "end": "942639"
  },
  {
    "text": "if i find a data set that tends to indicate that there has been",
    "start": "942639",
    "end": "947680"
  },
  {
    "text": "significant or substantial amount of back and forth in the sense of comments",
    "start": "947680",
    "end": "953120"
  },
  {
    "text": "being exchanged between reviewers and author what i see commits after raising public quests that",
    "start": "953120",
    "end": "959680"
  },
  {
    "text": "indicates that the approximation is not good enough and that's one thing to also have in",
    "start": "959680",
    "end": "964880"
  },
  {
    "text": "mind so going into just one of the",
    "start": "964880",
    "end": "970240"
  },
  {
    "text": "examples um so here we see um just results for",
    "start": "970240",
    "end": "976399"
  },
  {
    "text": "um this was data set of 500 merch pull requests and uh",
    "start": "976399",
    "end": "982240"
  },
  {
    "text": "this uh team they they took them uh six months to produce this uh 500 police",
    "start": "982240",
    "end": "989920"
  },
  {
    "text": "meaning that it took them 500 uh it took them six months to push these 500 pull",
    "start": "989920",
    "end": "995360"
  },
  {
    "text": "requests through the system of work okay and what was interesting to see is that the wait time cumulative in in in months",
    "start": "995360",
    "end": "1002959"
  },
  {
    "text": "was almost 28 months now these numbers are not accurate",
    "start": "1002959",
    "end": "1008079"
  },
  {
    "text": "but if the even if they're accurate 30 percent they're accurate more than that um",
    "start": "1008079",
    "end": "1014720"
  },
  {
    "text": "they're a really good conversation starter so people start talking about it in a sense of what are the things that",
    "start": "1014720",
    "end": "1020399"
  },
  {
    "text": "we can improve um based on this right so this is also important because",
    "start": "1020399",
    "end": "1026798"
  },
  {
    "text": "if we think about digital products and generally software right we use it in",
    "start": "1026799",
    "end": "1031918"
  },
  {
    "text": "order to deliver value to our customers now if the work is stuck in our system for a",
    "start": "1031919",
    "end": "1038798"
  },
  {
    "text": "longer time that also means for the cases when we deliver value to our customers we delay",
    "start": "1038799",
    "end": "1044798"
  },
  {
    "text": "delivery of the value to our customers right for these things that have been stuck for this time",
    "start": "1044799",
    "end": "1050240"
  },
  {
    "text": "i'm not saying that all work is equally valuable there are some things that",
    "start": "1050240",
    "end": "1055840"
  },
  {
    "text": "are less valuable than the others but they're all always kind of stakeholders and everyone",
    "start": "1055840",
    "end": "1061600"
  },
  {
    "text": "every change usually has some impact be developers or some other people",
    "start": "1061600",
    "end": "1066799"
  },
  {
    "text": "inside of the company or hopefully customers right",
    "start": "1066799",
    "end": "1073600"
  },
  {
    "text": "so this is um the going into the scatter plot for the wait time",
    "start": "1073600",
    "end": "1080799"
  },
  {
    "text": "on x axis we can see again size in lines of code and why we can see wait time in hours",
    "start": "1080799",
    "end": "1086960"
  },
  {
    "text": "so what we can see here is not much again",
    "start": "1086960",
    "end": "1092000"
  },
  {
    "text": "most of the prs take less than 200 hours to of a wait time right but then i was",
    "start": "1092000",
    "end": "1099200"
  },
  {
    "text": "thinking again if i work let's say seven days",
    "start": "1099200",
    "end": "1105760"
  },
  {
    "text": "and i wait for um and raise a pull request and then i wait for feedback for",
    "start": "1105760",
    "end": "1111280"
  },
  {
    "text": "two days it's not the same as when i work 10 minutes and then wait for feedback for two days right",
    "start": "1111280",
    "end": "1118400"
  },
  {
    "text": "so what happens if we plot the wait time now to be wait time precise",
    "start": "1118400",
    "end": "1124000"
  },
  {
    "text": "so the things become quite different and this was also the systemic behavior",
    "start": "1124000",
    "end": "1130080"
  },
  {
    "text": "that was visible across all the data sets where the teams have been doing gays in code reviews",
    "start": "1130080",
    "end": "1137120"
  },
  {
    "text": "now i was thinking how to interpret this and the way that they understand it is that",
    "start": "1137120",
    "end": "1143360"
  },
  {
    "text": "as we reduce the size of the pull request the wait time per size goes exponentially up meaning that",
    "start": "1143360",
    "end": "1151360"
  },
  {
    "text": "the cost of code review per size goes exponentially upright",
    "start": "1151360",
    "end": "1157039"
  },
  {
    "text": "this is really interesting because what we're saying is that",
    "start": "1158000",
    "end": "1163520"
  },
  {
    "text": "the smaller the change the more expensive the more expensive it is to push through the system right",
    "start": "1163520",
    "end": "1170080"
  },
  {
    "text": "and i have been advising the teams that have been doing um big pull requests you know",
    "start": "1170080",
    "end": "1177840"
  },
  {
    "text": "just reuse the size of the pulley request make it smaller but then i found out through this",
    "start": "1177840",
    "end": "1184240"
  },
  {
    "text": "study that actually small prs also have trade-offs when it comes to the async",
    "start": "1184240",
    "end": "1189679"
  },
  {
    "text": "code reviews right and why do we want to have small prs because the idea of small batches from lean",
    "start": "1189679",
    "end": "1196720"
  },
  {
    "text": "smaller pr's are quicker to write they are also quicker to review",
    "start": "1196720",
    "end": "1202480"
  },
  {
    "text": "people need less time allocation to review the public vests also coming back and forth is",
    "start": "1202480",
    "end": "1207919"
  },
  {
    "text": "usually quicker they're less risky because less change introduced",
    "start": "1207919",
    "end": "1213280"
  },
  {
    "text": "when we talk about the accelerate and for key metrics they shorten the lead time to change and",
    "start": "1213280",
    "end": "1219360"
  },
  {
    "text": "increase the deployment frequency etc etc so",
    "start": "1219360",
    "end": "1224720"
  },
  {
    "text": "that's the way that they see the the the behavior that this kind of system",
    "start": "1225120",
    "end": "1230799"
  },
  {
    "text": "incentivizes with this kind of economics right and thinking about it i'm sure that",
    "start": "1230799",
    "end": "1238080"
  },
  {
    "text": "lots of you have came across the cases when",
    "start": "1238080",
    "end": "1243600"
  },
  {
    "text": "let's say a team has a test route that takes to takes a long time to run let's",
    "start": "1243600",
    "end": "1248960"
  },
  {
    "text": "say uh there's uh it takes them 20 minutes to run the test suit right",
    "start": "1248960",
    "end": "1254400"
  },
  {
    "text": "if that's the case then i'm not going to be running the test suite after every line",
    "start": "1254400",
    "end": "1259520"
  },
  {
    "text": "of code change right because it doesn't make economic sense why because most of the time i'll be",
    "start": "1259520",
    "end": "1264880"
  },
  {
    "text": "spending just sitting there waiting for the tesla to finish right so what the system and economics here in this system",
    "start": "1264880",
    "end": "1271679"
  },
  {
    "text": "is incentivizing me is to increase the size of the of the batch right introdu",
    "start": "1271679",
    "end": "1276799"
  },
  {
    "text": "introduce more changes to the system before running the tests in order to get biggest bang for a buck",
    "start": "1276799",
    "end": "1284080"
  },
  {
    "text": "so the way that they see it is that inventory in the system so the amount of changes that you can use for in this",
    "start": "1285600",
    "end": "1291919"
  },
  {
    "text": "example expands until it matches the delays that you get in the system",
    "start": "1291919",
    "end": "1298000"
  },
  {
    "text": "and why is this important because i don't know how many of you remember",
    "start": "1298000",
    "end": "1303679"
  },
  {
    "text": "this [Music] game that at least some of us have played when we were kids",
    "start": "1303679",
    "end": "1309520"
  },
  {
    "text": "with siblings or cousins but um",
    "start": "1309520",
    "end": "1314960"
  },
  {
    "text": "someone hides the item and then you know the other person provides the feedback but they provide them feedback",
    "start": "1315360",
    "end": "1321600"
  },
  {
    "text": "um you know is it hot warm or cold and based on that feedback",
    "start": "1321600",
    "end": "1327039"
  },
  {
    "text": "they're able to find the item right now if you have two teams where one team",
    "start": "1327039",
    "end": "1332400"
  },
  {
    "text": "provides feedback after a minute and the other team provides feedback after a second",
    "start": "1332400",
    "end": "1337679"
  },
  {
    "text": "i guess that most of you are going to bet on the team that that gets the feedback after one second that",
    "start": "1337679",
    "end": "1342960"
  },
  {
    "text": "they're going to find the item sooner right so there's the same idea about why optimizing the process in this case",
    "start": "1342960",
    "end": "1349200"
  },
  {
    "text": "will lead you to um to find a custom of value for a customer",
    "start": "1349200",
    "end": "1355280"
  },
  {
    "text": "sooner right because the learning cadence is faster okay and um i love",
    "start": "1355280",
    "end": "1361520"
  },
  {
    "text": "this quote from don reinersen so while you may ignore economics it won't ignore",
    "start": "1361520",
    "end": "1366720"
  },
  {
    "text": "you because of the incentives of the system that have been set up because of that",
    "start": "1366720",
    "end": "1372320"
  },
  {
    "text": "and i was thinking about how to you know how to map out this model",
    "start": "1372320",
    "end": "1378799"
  },
  {
    "text": "um that they haven't had in the sense of why is this the case you know why the",
    "start": "1378799",
    "end": "1384559"
  },
  {
    "text": "teams that do ace encoder views also when they try to reduce the size of the peers usually end up going back",
    "start": "1384559",
    "end": "1392240"
  },
  {
    "text": "and this is a close loop diagram if anyone is familiar so with it it",
    "start": "1392240",
    "end": "1398640"
  },
  {
    "text": "comes from the assistant's thinking and i'm just going to give you a short crash course in it um it's quite simple so",
    "start": "1398640",
    "end": "1405679"
  },
  {
    "text": "there are variables that we see here as labels and variables can be",
    "start": "1405679",
    "end": "1413120"
  },
  {
    "text": "connected in two different ways so they can be there can be either minus sign between them",
    "start": "1413120",
    "end": "1418960"
  },
  {
    "text": "and there can be plus sign and this link is a causal link so if i have one variable and the other variable that are",
    "start": "1418960",
    "end": "1424240"
  },
  {
    "text": "connected if this one moves this one also moves if the sign is plus if this one moves up this other one also moves",
    "start": "1424240",
    "end": "1430960"
  },
  {
    "text": "up and the other way around if the relation is minus meaning the opposite when one variable goes up the other one",
    "start": "1430960",
    "end": "1437600"
  },
  {
    "text": "goes down and vice versa okay so interesting thing also happens when mapping close the loop diagrams is that",
    "start": "1437600",
    "end": "1444880"
  },
  {
    "text": "you might notice after connecting all the things that some that some feedback loops pop up right",
    "start": "1444880",
    "end": "1452159"
  },
  {
    "text": "and there are also two important feedback loops that are worth considering or actually",
    "start": "1452159",
    "end": "1457919"
  },
  {
    "text": "part of the causal diagrams rather one is the reinforcing feedback loop and",
    "start": "1457919",
    "end": "1463120"
  },
  {
    "text": "the other one is a balancing feedback loop now reinforcing feedback loop as you might guess is this kind of snowball",
    "start": "1463120",
    "end": "1469760"
  },
  {
    "text": "effect and the balancing feedback loop is the feedback loop that kind of seeks the target in a sense so",
    "start": "1469760",
    "end": "1476480"
  },
  {
    "text": "at home you know you when you set up the let's say thermostat to 21 degrees you know",
    "start": "1476480",
    "end": "1482799"
  },
  {
    "text": "the system is pushing the um kind of it's working until it",
    "start": "1482799",
    "end": "1489360"
  },
  {
    "text": "achieves the target right so if you open the door and outside is called it works even more in order to be able to achieve",
    "start": "1489360",
    "end": "1495840"
  },
  {
    "text": "this target so this is a balancing so let's just go uh quickly through i'll",
    "start": "1495840",
    "end": "1500880"
  },
  {
    "text": "just walk you through the the diagram so here if we have a",
    "start": "1500880",
    "end": "1507520"
  },
  {
    "text": "peer size of certain size pr sorry of certain size and we try to",
    "start": "1507520",
    "end": "1512720"
  },
  {
    "text": "call it let's say if we reduce the size of the pull request then the motivation or incentive",
    "start": "1512720",
    "end": "1517760"
  },
  {
    "text": "to review goes up because people want to review smaller peers usually right",
    "start": "1517760",
    "end": "1523200"
  },
  {
    "text": "that means that also time waiting for a review from author's perspective goes down",
    "start": "1523200",
    "end": "1529360"
  },
  {
    "text": "which means that their perceived cost of code review per line of code also goes down",
    "start": "1529360",
    "end": "1534720"
  },
  {
    "text": "which on the other side is incentivizing them to keep reducing the size of the broadcast and that's a reinforcing",
    "start": "1534720",
    "end": "1540720"
  },
  {
    "text": "feedback that we get to see here which is a great thing to have now",
    "start": "1540720",
    "end": "1546720"
  },
  {
    "text": "there are other things also going on and that is that if you work in the async code reviews manner",
    "start": "1546720",
    "end": "1553760"
  },
  {
    "text": "and we reduce the size of the pulley quests then the number of peers to review in a given unit of time goes up",
    "start": "1553760",
    "end": "1559840"
  },
  {
    "text": "right so if it took me one week to develop a pr and let's say everyone on team",
    "start": "1559840",
    "end": "1565679"
  },
  {
    "text": "takes the same amount of time to develop that then we when we have the prs then we're",
    "start": "1565679",
    "end": "1571840"
  },
  {
    "text": "going to have twice as many uh pull requests to review in a week right",
    "start": "1571840",
    "end": "1577440"
  },
  {
    "text": "so the thing with a higher number of pull requests to review is that they",
    "start": "1577440",
    "end": "1583120"
  },
  {
    "text": "also mean um higher number of interruptions for reviewers and also for authors in a",
    "start": "1583120",
    "end": "1589760"
  },
  {
    "text": "given unit of time right and if you keep reducing the size of the pull request you're going to hit the point where the number of interruptions",
    "start": "1589760",
    "end": "1596240"
  },
  {
    "text": "is unbearable for people and everyone wants to protect also their personal flow and",
    "start": "1596240",
    "end": "1602080"
  },
  {
    "text": "that also means that the motivational incentive to review uh given pull requests goes down which",
    "start": "1602080",
    "end": "1608400"
  },
  {
    "text": "on the other hand increases the time waiting for the review from author perspective and the",
    "start": "1608400",
    "end": "1614080"
  },
  {
    "text": "perceived cost of code review goes up which incentivizes the pr size to go up",
    "start": "1614080",
    "end": "1621520"
  },
  {
    "text": "so that's a balancing feedback loop that is balancing out this reinforcing behavior and there is a shift in",
    "start": "1621520",
    "end": "1626640"
  },
  {
    "text": "dominance usually between these two loops as you keep reducing the size of the pull request balancing feedback loop tends to",
    "start": "1626640",
    "end": "1634480"
  },
  {
    "text": "gain more um dominance but there are also thing other things",
    "start": "1634480",
    "end": "1640240"
  },
  {
    "text": "going on here that we saw with emma it's that",
    "start": "1640240",
    "end": "1647760"
  },
  {
    "text": "is that if we increase the time waiting for a review while emma",
    "start": "1649760",
    "end": "1654880"
  },
  {
    "text": "is waiting for a review from luca she starts working on something else right and that increases the ups that",
    "start": "1654880",
    "end": "1661440"
  },
  {
    "text": "decreases the number of peers to review right so it kind of reinforces this balancing feedback loop that we see here",
    "start": "1661440",
    "end": "1667279"
  },
  {
    "text": "there's a problem here because we have a conflict here so from one side",
    "start": "1667279",
    "end": "1673360"
  },
  {
    "text": "the system is increasing the motivational center to review and from the other side is decreasing",
    "start": "1673360",
    "end": "1679520"
  },
  {
    "text": "so that leads me to a flow efficiency one of the metric from the matrix from the",
    "start": "1680480",
    "end": "1685600"
  },
  {
    "text": "lean and um flow efficiency is kind of simple metric we look at the lead time",
    "start": "1685600",
    "end": "1690960"
  },
  {
    "text": "of a given item and we figure out when we have been working on the item which",
    "start": "1690960",
    "end": "1696480"
  },
  {
    "text": "is a work um here or processing or touch time and",
    "start": "1696480",
    "end": "1701679"
  },
  {
    "text": "we also look at how much the item is waiting sitting there in a",
    "start": "1701679",
    "end": "1707840"
  },
  {
    "text": "queue and we calculate out of the whole lead time how much of",
    "start": "1707840",
    "end": "1713120"
  },
  {
    "text": "processing time was there right so the higher the flow efficiency the better the process you have and the opposite",
    "start": "1713120",
    "end": "1719360"
  },
  {
    "text": "so i started analyzing flow efficiency for these data sets and what i got to find is this um kind",
    "start": "1719360",
    "end": "1725919"
  },
  {
    "text": "of a behavior um so on the y-axis you can see the the flow efficiency",
    "start": "1725919",
    "end": "1731760"
  },
  {
    "text": "and here in this data set the flow efficiency",
    "start": "1731760",
    "end": "1736960"
  },
  {
    "text": "starts plummeting around 120 lines of code doesn't really matter but",
    "start": "1736960",
    "end": "1742399"
  },
  {
    "text": "the important thing or important point to have to think about here is that in this kind of system with this kind of",
    "start": "1742399",
    "end": "1748640"
  },
  {
    "text": "economic let's say that we want to introduce the 300 lines of code change right so and let's say that we can do it at least in",
    "start": "1748640",
    "end": "1754720"
  },
  {
    "text": "two ways so one way is splitting the work into 15 pr's of 20",
    "start": "1754720",
    "end": "1760080"
  },
  {
    "text": "lines of code and the other one is just giving one pr of 300 lines of code",
    "start": "1760080",
    "end": "1766159"
  },
  {
    "text": "now in this kind of system the cumulative lead time for these 15 pr's",
    "start": "1766159",
    "end": "1771279"
  },
  {
    "text": "of 20 lines of code is going to be way longer than the cumulative lead time that is going to take us to push these",
    "start": "1771279",
    "end": "1777279"
  },
  {
    "text": "300 lines of code through our system now i'm not saying anything about the amount of value that we're introducing",
    "start": "1777279",
    "end": "1783840"
  },
  {
    "text": "with this but if the system is choked in a sense that you are not even able to push the things soon out of the door",
    "start": "1783840",
    "end": "1790720"
  },
  {
    "text": "then you are not able to get the value as well in the cases when you get value from the changes that you introduce",
    "start": "1790720",
    "end": "1796000"
  },
  {
    "text": "right so",
    "start": "1796000",
    "end": "1799760"
  },
  {
    "text": "what this means for me is that actually on the lower",
    "start": "1803600",
    "end": "1808880"
  },
  {
    "text": "side of the spectrum of the size of the pr we lose throughput right so the smaller the pr",
    "start": "1808880",
    "end": "1814320"
  },
  {
    "text": "the more they get the weight inside of a system per size and",
    "start": "1814320",
    "end": "1821880"
  },
  {
    "text": "we have the the behavior that means that we need to trade off between two things right",
    "start": "1822080",
    "end": "1828480"
  },
  {
    "text": "one is the uh quality that we talked about and the other one is throughput and when you think about it actually um",
    "start": "1828480",
    "end": "1837039"
  },
  {
    "text": "when the the interesting thing here is when when we when you think about the whole process is that as we reduce the",
    "start": "1837039",
    "end": "1843279"
  },
  {
    "text": "size of the pull request the processing time tends to go down linearly uh or or",
    "start": "1843279",
    "end": "1849360"
  },
  {
    "text": "stays constant processing time precise why because we are mostly dependent on ourselves when we code right but the",
    "start": "1849360",
    "end": "1856240"
  },
  {
    "text": "thing with the wait time here and the review process is that um the as we reduce the size of the pull",
    "start": "1856240",
    "end": "1863360"
  },
  {
    "text": "request the wait time precise goes exponentially up as we saw it and why",
    "start": "1863360",
    "end": "1868399"
  },
  {
    "text": "because if you have smaller peers that means that dependency starts kicking in",
    "start": "1868399",
    "end": "1873440"
  },
  {
    "text": "with other people sooner right and more often so it becomes more expensive which",
    "start": "1873440",
    "end": "1878559"
  },
  {
    "text": "this then this ratio weight to processing time goes exponentially up because the wait time is going",
    "start": "1878559",
    "end": "1884320"
  },
  {
    "text": "exponentially up which affects the flow efficiency cause it to plummet and it also means that the",
    "start": "1884320",
    "end": "1890640"
  },
  {
    "text": "throughput is going down so from one side we have uh",
    "start": "1890640",
    "end": "1896799"
  },
  {
    "text": "inability to build the quality in with big prs on the other side",
    "start": "1896799",
    "end": "1901919"
  },
  {
    "text": "we have a problems with the throughput and uh the smaller the pr the less",
    "start": "1901919",
    "end": "1909600"
  },
  {
    "text": "uh throughput we get from our system and that's this eternal uh battle between speed versus quality",
    "start": "1909600",
    "end": "1916320"
  },
  {
    "text": "throughput versus quality throughput versus stability whatever you call it um for anyone that has had a chance to",
    "start": "1916320",
    "end": "1922720"
  },
  {
    "text": "read john reiner's book it was mentioned today i think at least once",
    "start": "1922720",
    "end": "1929039"
  },
  {
    "text": "the principles of product development flow and i really recommend it to managers but also to engineers",
    "start": "1929039",
    "end": "1936799"
  },
  {
    "text": "this problem is actually about this um optimal batch size",
    "start": "1936799",
    "end": "1942880"
  },
  {
    "text": "of curve which is called u-curve of the optimal batch size your curvier",
    "start": "1942880",
    "end": "1949440"
  },
  {
    "text": "and here we were talking actually about the transaction cost now it's a pretty washed out slide but the",
    "start": "1949440",
    "end": "1957519"
  },
  {
    "text": "the the optimal batch size is here right so you can see it from from this point of",
    "start": "1957519",
    "end": "1963600"
  },
  {
    "text": "here is the batch size because it's trying to optimize between the holding costs that",
    "start": "1963600",
    "end": "1969200"
  },
  {
    "text": "we see here and the transaction code that we just talked about um",
    "start": "1969200",
    "end": "1976880"
  },
  {
    "text": "and this led me to um think about the work that has been done as part of the",
    "start": "1976880",
    "end": "1983200"
  },
  {
    "text": "accelerated book which is a summary of dollar research state of devops where you know this for me the biggest",
    "start": "1983200",
    "end": "1989519"
  },
  {
    "text": "conclusion was that instead of thinking either throughput or stability uh there's actually",
    "start": "1989519",
    "end": "1995360"
  },
  {
    "text": "you know um both rupert and stability when one goes up the other one also goes up and vice versa so um",
    "start": "1995360",
    "end": "2004320"
  },
  {
    "text": "we tend to hear all lots of the times in our english industry that there's always trade-offs and i agree with that but",
    "start": "2004320",
    "end": "2010880"
  },
  {
    "text": "there are some cases where the trade-offs don't actually exist because the underlying assumption is flawed so",
    "start": "2010880",
    "end": "2016320"
  },
  {
    "text": "it's really important how do we frame the problem in the first place and um i think we can have our cake and 82",
    "start": "2016320",
    "end": "2025039"
  },
  {
    "text": "at the same time so if we try to work backwards from the problem that we have so we're saying that with the cost of",
    "start": "2025039",
    "end": "2031120"
  },
  {
    "text": "code review precise is going exponentially up then the throughput is plummeting",
    "start": "2031120",
    "end": "2036960"
  },
  {
    "text": "what do we need to do in order for throughput to be constant right so if we",
    "start": "2036960",
    "end": "2043440"
  },
  {
    "text": "need to keep the throughput constant as we decrease the size of the pull request and again you want to have smaller pull",
    "start": "2043440",
    "end": "2048878"
  },
  {
    "text": "requests that means that the costs of code review per line",
    "start": "2048879",
    "end": "2054560"
  },
  {
    "text": "of code or precise must not go up exponentially actually it needs to stay constant right in order to",
    "start": "2054560",
    "end": "2061839"
  },
  {
    "text": "do this um the actor's reaction time when i say actors",
    "start": "2061839",
    "end": "2067040"
  },
  {
    "text": "i mean authors and reviewers in the whole process needs to go down",
    "start": "2067040",
    "end": "2072960"
  },
  {
    "text": "as we decrease the size of the pull request remember emma and luca they weren't able to react immediately and",
    "start": "2072960",
    "end": "2078960"
  },
  {
    "text": "that's what is driving up the cost of the code view precise so as we decrease the size of the pull",
    "start": "2078960",
    "end": "2085040"
  },
  {
    "text": "request they need to react exponentially faster and faster and faster in order to",
    "start": "2085040",
    "end": "2090158"
  },
  {
    "text": "not lose the throughput at the end and in order to do that we need to increase their availability",
    "start": "2090159",
    "end": "2095919"
  },
  {
    "text": "meaning hearing theory little's law for anyone that is familiar with it",
    "start": "2095919",
    "end": "2101680"
  },
  {
    "text": "less work in progress in the system in order to keep people less busy which means that they",
    "start": "2101680",
    "end": "2107200"
  },
  {
    "text": "are able to react sooner so if we go back to this ticket number",
    "start": "2107200",
    "end": "2112240"
  },
  {
    "text": "one and i we just pull out",
    "start": "2112240",
    "end": "2117359"
  },
  {
    "text": "and we see anything oh yes um just focus on ticket number one and",
    "start": "2117359",
    "end": "2123599"
  },
  {
    "text": "this is a timeline of the events and we let's say that we have this size of the puller quests and let's say",
    "start": "2123599",
    "end": "2129119"
  },
  {
    "text": "that we want to decrease the size of the pull request in order for us to not to lose the throughput as we decrease the",
    "start": "2129119",
    "end": "2135040"
  },
  {
    "text": "size of the pull request m and look need to react faster right if you keep reducing at one point they",
    "start": "2135040",
    "end": "2141599"
  },
  {
    "text": "will have to react immediately or not to lose the troop",
    "start": "2141599",
    "end": "2146800"
  },
  {
    "text": "and that was the kind of conclusion of my study in order to not exponentially lose the throughput",
    "start": "2146800",
    "end": "2154480"
  },
  {
    "text": "um while reducing the size of the pull request people need to get",
    "start": "2154480",
    "end": "2159760"
  },
  {
    "text": "exponentially closer and closer and closer in time which at one point leads us to continuous code review right",
    "start": "2159760",
    "end": "2168240"
  },
  {
    "text": "and if we go back to this causal loop diagram here there was a problem",
    "start": "2168240",
    "end": "2174960"
  },
  {
    "text": "this conflict that we had in this point right which was caused by the number of",
    "start": "2174960",
    "end": "2181119"
  },
  {
    "text": "interruptions that we get to see in the system but you cannot get interrupted if you're",
    "start": "2181119",
    "end": "2187359"
  },
  {
    "text": "not doing anything else so if you're working on the same item as the other person or you're not doing",
    "start": "2187359",
    "end": "2193599"
  },
  {
    "text": "anything else that's not really an interruption for you right so",
    "start": "2193599",
    "end": "2198880"
  },
  {
    "text": "that is a segway this parallel universe that they call co-creation patterns i hope that all of",
    "start": "2198880",
    "end": "2205920"
  },
  {
    "text": "you at least have heard from peer and more programming but interesting thing here",
    "start": "2205920",
    "end": "2212400"
  },
  {
    "text": "with working together when it comes to this whole process is that",
    "start": "2212400",
    "end": "2218480"
  },
  {
    "text": "because the we have someone sitting next to us giving us",
    "start": "2218720",
    "end": "2224000"
  },
  {
    "text": "review immediately the cost of code review per line of code is actually minimal because they are",
    "start": "2224000",
    "end": "2230240"
  },
  {
    "text": "providing us the the wait time is zero effectively right which means that now",
    "start": "2230240",
    "end": "2235359"
  },
  {
    "text": "we are still not able to see this there is this optimal um optimal batch size which was here and",
    "start": "2235359",
    "end": "2242000"
  },
  {
    "text": "then because we reduced the transaction cost we were able to shift the optimal",
    "start": "2242000",
    "end": "2247040"
  },
  {
    "text": "size of the batch to the left all the way to the left um",
    "start": "2247040",
    "end": "2253680"
  },
  {
    "text": "and i was thinking okay how would this look like in case we did pair more programming in case we",
    "start": "2253680",
    "end": "2259680"
  },
  {
    "text": "co-created right so when we think about the wait time precise if i'm able to get the feedback immediately right that",
    "start": "2259680",
    "end": "2266320"
  },
  {
    "text": "means that the wait time per size is actually zero and effective size of the pull request",
    "start": "2266320",
    "end": "2272640"
  },
  {
    "text": "if your pro request is dependent on the code view is one line of code or the atomic change that the person that the",
    "start": "2272640",
    "end": "2278000"
  },
  {
    "text": "driver is doing is making now when it comes to the engagement",
    "start": "2278000",
    "end": "2283119"
  },
  {
    "text": "the engagement tends to stay the same or at least goes up why because the um",
    "start": "2283119",
    "end": "2289440"
  },
  {
    "text": "the the feedback is more timely and the communication is also variable so the broadband of the medium is higher",
    "start": "2289440",
    "end": "2298560"
  },
  {
    "text": "plus we're also able to fast course correct each other and",
    "start": "2298560",
    "end": "2304880"
  },
  {
    "text": "i was thinking then you know okay that's the case and we get actually the continuous code review as a byproduct of",
    "start": "2304880",
    "end": "2313040"
  },
  {
    "text": "co-creation and thinking about all of these metrics here",
    "start": "2313040",
    "end": "2319200"
  },
  {
    "text": "i was thinking okay you know can we find a number that we can use to kind of describe um the things that",
    "start": "2319200",
    "end": "2327359"
  },
  {
    "text": "we're trying to optimize for so we want the size to go down right the pulley press size we want the wait time",
    "start": "2327359",
    "end": "2333359"
  },
  {
    "text": "precise also to go down and we also want to engagement precise uh if not to go up then at least not to",
    "start": "2333359",
    "end": "2340400"
  },
  {
    "text": "go down to stay constant test but it used the size of the pull request right so you might have noticed this",
    "start": "2340400",
    "end": "2347119"
  },
  {
    "text": "bar here on the side which is a thing that they called pr score and",
    "start": "2347119",
    "end": "2352880"
  },
  {
    "text": "if we try to map into a formula these things that we're trying to optimize for",
    "start": "2352880",
    "end": "2357920"
  },
  {
    "text": "and their relationship so you know there's a size uh there's a",
    "start": "2357920",
    "end": "2363200"
  },
  {
    "text": "wait time in seconds and the engagement and for a co-creation when we get to the",
    "start": "2363200",
    "end": "2368560"
  },
  {
    "text": "feedback immediately the effective size of the pull request can be to the point that it's one line of code uh wait",
    "start": "2368560",
    "end": "2375839"
  },
  {
    "text": "time is zero and engagement is whatever constant or it goes up i divide by one",
    "start": "2375839",
    "end": "2382320"
  },
  {
    "text": "plus engagement because engagement can be sometimes zero non-trivial comments and i don't",
    "start": "2382320",
    "end": "2387760"
  },
  {
    "text": "want to divide by zero actually no one wants to divide by zero",
    "start": "2387760",
    "end": "2393119"
  },
  {
    "text": "and this whole thing evaluates to zero now the thing was i was trying to calculate this also for the async code",
    "start": "2393119",
    "end": "2399440"
  },
  {
    "text": "reviews and the numbers were so high that they had to use the natural logarithm here so",
    "start": "2399440",
    "end": "2405280"
  },
  {
    "text": "you to evaluate it at the end and the the pr score for the co-creation also",
    "start": "2405280",
    "end": "2411200"
  },
  {
    "text": "evaluates for that to zero because natural logarithm of of one is zero",
    "start": "2411200",
    "end": "2416960"
  },
  {
    "text": "um so that's why i tend to say that the optimal size of a pull request",
    "start": "2416960",
    "end": "2423040"
  },
  {
    "text": "is one line of code that is reviewed immediately as is being typed and i honestly don't know a better way",
    "start": "2423040",
    "end": "2430000"
  },
  {
    "text": "to achieve it than by pair and more programming so the the thing with it is that as a",
    "start": "2430000",
    "end": "2435839"
  },
  {
    "text": "byproduct we get this continuous immediate code reviews i'm not going to go into",
    "start": "2435839",
    "end": "2441680"
  },
  {
    "text": "psychological safety trust vulnerability that tends to be built with co-creation with working as a",
    "start": "2441680",
    "end": "2447200"
  },
  {
    "text": "team together that's a completely different talk but you get so many benefits out of it",
    "start": "2447200",
    "end": "2453440"
  },
  {
    "text": "so i was plotting this on a on a time series and here we can see a data",
    "start": "2453440",
    "end": "2458960"
  },
  {
    "text": "set of of a bunch of pr's uh on the y-axis we can see a score and",
    "start": "2458960",
    "end": "2464319"
  },
  {
    "text": "it's again on uh um logarithmic scale and i think the",
    "start": "2464319",
    "end": "2469599"
  },
  {
    "text": "lowest one was maybe around six or so right and that's one world that they get",
    "start": "2469599",
    "end": "2475200"
  },
  {
    "text": "to see and then the other world world is a continuous code reviews pairing or moving which has",
    "start": "2475200",
    "end": "2481760"
  },
  {
    "text": "this result as a zero and if you try to optimize for these metrics that i talked",
    "start": "2481760",
    "end": "2486960"
  },
  {
    "text": "about then actually the best result that you can get is zero",
    "start": "2486960",
    "end": "2492400"
  },
  {
    "text": "so throughput or quality uh i would say both throughput and quality",
    "start": "2492400",
    "end": "2499839"
  },
  {
    "text": "because some assumptions don't hold true and then i was also thinking you know",
    "start": "2499839",
    "end": "2506240"
  },
  {
    "text": "what if we try to define peer programming uh with this another uh",
    "start": "2506240",
    "end": "2511440"
  },
  {
    "text": "this orthodox definition of people spending twice as much time working the same thing",
    "start": "2511440",
    "end": "2517200"
  },
  {
    "text": "but then the wait time is zero because we get immediate review then how would the world look like and",
    "start": "2517200",
    "end": "2523040"
  },
  {
    "text": "this was this was just one of the examples of",
    "start": "2523040",
    "end": "2528400"
  },
  {
    "text": "how sooner would we be able to finish which is really important because of that learning cadence that i was talking",
    "start": "2528400",
    "end": "2534319"
  },
  {
    "text": "about and why is important in order to be able to deliver value to our customers sooner in order",
    "start": "2534319",
    "end": "2541119"
  },
  {
    "text": "to at the end hopefully outrun the competition so in this case it was 3.3 times the",
    "start": "2541119",
    "end": "2546880"
  },
  {
    "text": "numbers again are not really important and the accuracies i'm sure not 100 but they are a really good kind of",
    "start": "2546880",
    "end": "2553839"
  },
  {
    "text": "conversation starters for teams to start evaluating the way that they they work",
    "start": "2553839",
    "end": "2559599"
  },
  {
    "text": "and with that um i just wanted to say that we've been at least that's my impression that we've been told all",
    "start": "2559599",
    "end": "2566480"
  },
  {
    "text": "along that we'll achieve more if we limit and delay our interactions but",
    "start": "2566480",
    "end": "2571520"
  },
  {
    "text": "i hope that now you also have a data informed reason",
    "start": "2571520",
    "end": "2576640"
  },
  {
    "text": "not a reason not to believe that and with that i would like to thank you",
    "start": "2576640",
    "end": "2581760"
  },
  {
    "text": "for your attention your time",
    "start": "2581760",
    "end": "2586839"
  },
  {
    "text": "yeah um feel free to rate the talk uh outside",
    "start": "2592079",
    "end": "2597280"
  },
  {
    "text": "that's also what i've been told by the organizers yeah thank you for your time thanks",
    "start": "2597280",
    "end": "2604599"
  },
  {
    "text": "you",
    "start": "2606800",
    "end": "2608880"
  }
]
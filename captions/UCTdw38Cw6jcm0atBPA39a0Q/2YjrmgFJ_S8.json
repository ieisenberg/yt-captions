[
  {
    "text": "yay yeah I'm Tess I'm famous and we're",
    "start": "6680",
    "end": "12800"
  },
  {
    "text": "gonna have a good time so I'm gonna talk about the dark sides of machine learning",
    "start": "12800",
    "end": "20210"
  },
  {
    "text": "and hopefully I won't make it to dystopic and make you scare away from it too much but when you tell some stories",
    "start": "20210",
    "end": "28099"
  },
  {
    "text": "about how wrong things can go and how it can make them go right so about a year and a half ago a couple",
    "start": "28099",
    "end": "40100"
  },
  {
    "text": "of researchers a group of researchers in California created a machine learning model that could accurately or at least",
    "start": "40100",
    "end": "47960"
  },
  {
    "text": "accurately according to them figure out if a crime was gang-related or not so",
    "start": "47960",
    "end": "54430"
  },
  {
    "text": "taking the police report the perpetrators and the victims where they",
    "start": "54430",
    "end": "61040"
  },
  {
    "text": "were from whether where the crime was created and a couple of things like that",
    "start": "61040",
    "end": "67670"
  },
  {
    "text": "it's basically say if it was a gang crime or not so pretty useful in the",
    "start": "67670",
    "end": "74180"
  },
  {
    "text": "cases where they didn't have a police report they would simply generate one because this was a very forward-thinking",
    "start": "74180",
    "end": "80260"
  },
  {
    "text": "paperweight using generative neural networks and things so what could",
    "start": "80260",
    "end": "86300"
  },
  {
    "text": "possibly go wrong with something like this hmm well it turns out that if you",
    "start": "86300",
    "end": "94760"
  },
  {
    "text": "get classified as a gang member that's not necessarily a very good thing and",
    "start": "94760",
    "end": "100120"
  },
  {
    "text": "this machine learning model was based on this database called the cow gang",
    "start": "100120",
    "end": "105320"
  },
  {
    "text": "database California gang related activity database which has a lot of people that are pursuing to be gang",
    "start": "105320",
    "end": "112940"
  },
  {
    "text": "members and this database went through an audit and had some quite severe",
    "start": "112940",
    "end": "118549"
  },
  {
    "text": "problems one of them was privacy so local businesses could freely look in",
    "start": "118549",
    "end": "123860"
  },
  {
    "text": "here and see if they should hire someone or not because if they were getting what they are related they shouldn't it also",
    "start": "123860",
    "end": "131360"
  },
  {
    "text": "had some retention problems so a little bit like a tile California if you got in",
    "start": "131360",
    "end": "136489"
  },
  {
    "text": "this database you could check out but not and then it had some problems in the",
    "start": "136489",
    "end": "143420"
  },
  {
    "text": "night about 25% of the people in hair we're not actually proven to have any",
    "start": "143420",
    "end": "148490"
  },
  {
    "text": "gang-related affiliations in fact 42 of the people in this database were babies",
    "start": "148490",
    "end": "154850"
  },
  {
    "text": "under the age of 1 I don't which a full 28 had admitted to being active the gang",
    "start": "154850",
    "end": "162860"
  },
  {
    "text": "members so naturally when this was",
    "start": "162860",
    "end": "169640"
  },
  {
    "text": "presented at a conference like many machine learning papers are there were",
    "start": "169640",
    "end": "174680"
  },
  {
    "text": "some questions there were some questions about what did he do to mitigate the",
    "start": "174680",
    "end": "179780"
  },
  {
    "text": "problems with the data how did you make sure that you didn't just pick a gang",
    "start": "179780",
    "end": "186680"
  },
  {
    "text": "crime because it was someone Hispanic or black living in a certain zip code what",
    "start": "186680",
    "end": "192050"
  },
  {
    "text": "did you do and the presenter just was like I'm just an engineer I'm thinking",
    "start": "192050",
    "end": "202300"
  },
  {
    "text": "I'm actually when this happened this guy Blake Lim one from Google who was in the",
    "start": "202300",
    "end": "207500"
  },
  {
    "text": "room he gets so flustered and irritated that he left the room reciting a song by Tom",
    "start": "207500",
    "end": "216830"
  },
  {
    "text": "Lehrer and saying once the Rockets go up who cares where they fall down in this",
    "start": "216830",
    "end": "223910"
  },
  {
    "text": "song by Tom Lehrer about a burner from Brown who was a rocket scientist a new",
    "start": "223910",
    "end": "228920"
  },
  {
    "text": "second world war and was Rockets were meant to land on the moon but I",
    "start": "228920",
    "end": "234290"
  },
  {
    "text": "fortunately landed right here in London but that was not his department I'm just",
    "start": "234290",
    "end": "242510"
  },
  {
    "text": "an engineer I'm here to suggest that we're maybe not just engineers maybe we",
    "start": "242510",
    "end": "248930"
  },
  {
    "text": "have a little bit more responsibility with the things we do because we're put in charge from some very very",
    "start": "248930",
    "end": "255280"
  },
  {
    "text": "interesting systems that have a lot of consequence systems that basically tell",
    "start": "255280",
    "end": "263270"
  },
  {
    "text": "you if you should get a job or not if you should get a loan if you should get put in jail you should get medical care",
    "start": "263270",
    "end": "270530"
  },
  {
    "text": "live or die essentially so I think we a little bit more responsibility essentially Ares don't you just say I'm",
    "start": "270530",
    "end": "278380"
  },
  {
    "text": "an engineer as someone else has to take care of the rest or as Todd I puts it in his tweet yeah",
    "start": "278380",
    "end": "289870"
  },
  {
    "text": "we have a little bit more responsibility I'm sure it being from London your were",
    "start": "289870",
    "end": "296730"
  },
  {
    "text": "well-acquainted with Cambridge analytic I and many of you have probably seen the Netflix show which if you haven't it's a",
    "start": "296730",
    "end": "306010"
  },
  {
    "text": "very good one so in this case I will know what happened basically they they",
    "start": "306010",
    "end": "311830"
  },
  {
    "text": "took a lot of data from from Facebook made personality analysis figure it out",
    "start": "311830",
    "end": "317890"
  },
  {
    "text": "who was more swayable and then sent propaganda to those people this research",
    "start": "317890",
    "end": "325360"
  },
  {
    "text": "or the research that led up to this was loosely based on something else by",
    "start": "325360",
    "end": "330490"
  },
  {
    "text": "Michelle Kosinski so Michelle Kosinski and you might be familiar with this to like a couple of years back there was a",
    "start": "330490",
    "end": "338920"
  },
  {
    "text": "big thing I think IBM even had a version of this where you could enter your",
    "start": "338920",
    "end": "343960"
  },
  {
    "text": "Twitter account or your Facebook account and would give you sort of like a personality profile because given 50 of",
    "start": "343960",
    "end": "351250"
  },
  {
    "text": "your likes it could tell you who you were better than your friends could in most cases this guy Michelle Kosinski he",
    "start": "351250",
    "end": "359170"
  },
  {
    "text": "didn't do this actually for Cambridge analytic I hid the disk as proof of this",
    "start": "359170",
    "end": "364960"
  },
  {
    "text": "is a bad thing that we should be careful of and make sure it doesn't happen",
    "start": "364960",
    "end": "370170"
  },
  {
    "text": "but unfortunately is showing that it can happen is something that other other",
    "start": "370170",
    "end": "376810"
  },
  {
    "text": "people can build on he also created this very controversial paper that's commonly",
    "start": "376810",
    "end": "382240"
  },
  {
    "text": "known as the AI gate our paper have any of you heard of it a few maybe so the a",
    "start": "382240",
    "end": "390340"
  },
  {
    "text": "gate our paper is exactly what it sounds like you take pictures of people and",
    "start": "390340",
    "end": "395470"
  },
  {
    "text": "these by looking at someone you would be able to tell what their sexual orientation is what could possibly go",
    "start": "395470",
    "end": "404200"
  },
  {
    "text": "wrong with this right so looking at and so you explain",
    "start": "404200",
    "end": "410710"
  },
  {
    "text": "what you're seeing here so this is a composite picture so what it means like you average in the pixels of pictures",
    "start": "410710",
    "end": "418090"
  },
  {
    "text": "and you put them together as you're seeing like the the average female who likes females female like males male",
    "start": "418090",
    "end": "426669"
  },
  {
    "text": "like males and males or so means who like females and males were like males",
    "start": "426669",
    "end": "432629"
  },
  {
    "text": "and he said that would very good accuracy he could figure out yes by",
    "start": "432629",
    "end": "438250"
  },
  {
    "text": "someone's face what their sexual orientation is now it has some method",
    "start": "438250",
    "end": "444909"
  },
  {
    "text": "problems so mainly it was using pictures",
    "start": "444909",
    "end": "450460"
  },
  {
    "text": "from dating websites a location where you might be a little bit more explicit",
    "start": "450460",
    "end": "456490"
  },
  {
    "text": "about your orientation but if we think and actually what it found that was it's",
    "start": "456490",
    "end": "462219"
  },
  {
    "text": "becoming a stereotype detector so you can see here for example that this",
    "start": "462219",
    "end": "469150"
  },
  {
    "text": "female uses a lot more makeup this great thing in the forehead is more more uses",
    "start": "469150",
    "end": "476650"
  },
  {
    "text": "for baseball caps and this guy is completely heterosexual because he",
    "start": "476650",
    "end": "482439"
  },
  {
    "text": "doesn't know how to take selfies so you can see its nostrils a little bit more but um so anyways depending on if you",
    "start": "482439",
    "end": "493360"
  },
  {
    "text": "think this could be done or not if we're going and think about has something like",
    "start": "493360",
    "end": "498819"
  },
  {
    "text": "this and saying and classifying someone's sexual orientation if we would",
    "start": "498819",
    "end": "504460"
  },
  {
    "text": "classify a cat or a dog something is either a cat or dog or neither but what",
    "start": "504460",
    "end": "510490"
  },
  {
    "text": "does a one or a zero mean for something like sexual orientation is a zero",
    "start": "510490",
    "end": "516120"
  },
  {
    "text": "homophobic and it's a one like the leader of the Pride Parade and where",
    "start": "516120",
    "end": "522669"
  },
  {
    "text": "does like bicurious or bisexual or gender-fluid or anything like that fit",
    "start": "522669",
    "end": "529930"
  },
  {
    "text": "into this obviously this is a little bit more complex than Estes ear or one so",
    "start": "529930",
    "end": "536230"
  },
  {
    "text": "classifying a human behavior as a serial one even if it could be done",
    "start": "536230",
    "end": "542390"
  },
  {
    "text": "technically can't be done because you have such variation and then what does",
    "start": "542390",
    "end": "547710"
  },
  {
    "text": "it matter for me being from Sweden if they classify me wrong that probably",
    "start": "547710",
    "end": "554970"
  },
  {
    "text": "wouldn't have a high effect on my life but east a few years ago having",
    "start": "554970",
    "end": "562950"
  },
  {
    "text": "something else then a heterosexual lifestyle was classified for books in",
    "start": "562950",
    "end": "569220"
  },
  {
    "text": "the library in mental disorders because things like",
    "start": "569220",
    "end": "575250"
  },
  {
    "text": "this classifications like these have a very very long tail and now I live in",
    "start": "575250",
    "end": "581220"
  },
  {
    "text": "Sweden but if I would live in another country it might even be something that's a criminal offence",
    "start": "581220",
    "end": "586370"
  },
  {
    "text": "sometimes punishable by death so it does have a lot of consequence doing",
    "start": "586370",
    "end": "592890"
  },
  {
    "text": "something like this speaking of criminals another set of researchers",
    "start": "592890",
    "end": "599640"
  },
  {
    "text": "this time in China set out to create a criminality detector what could possibly",
    "start": "599640",
    "end": "606240"
  },
  {
    "text": "go wrong with that so what he did was they took a number of pictures of men",
    "start": "606240",
    "end": "613350"
  },
  {
    "text": "from 18 to 55 and yes by looking at their faces they could determine if they",
    "start": "613350",
    "end": "620190"
  },
  {
    "text": "were criminals or not excellent so they took 2,000 pictures of men and a",
    "start": "620190",
    "end": "627390"
  },
  {
    "text": "couple of them were criminals some we're not criminals out of the criminals some",
    "start": "627390",
    "end": "633210"
  },
  {
    "text": "were violent and you might think like Ashley accurate they classify something like this you would have to create like",
    "start": "633210",
    "end": "638760"
  },
  {
    "text": "classify super violent criminals or something like that somewhere where you",
    "start": "638760",
    "end": "643890"
  },
  {
    "text": "could really see maybe on someone's face if they were a hardened criminal but now a lot of the people that they",
    "start": "643890",
    "end": "650310"
  },
  {
    "text": "could classify as criminals were simply like they would do fraud or other petty",
    "start": "650310",
    "end": "659130"
  },
  {
    "text": "crime now this also had some method problems shall we say",
    "start": "659130",
    "end": "666180"
  },
  {
    "text": "it when they looked at the pictures",
    "start": "666180",
    "end": "671220"
  },
  {
    "text": "again after the composite pictures criminal non criminal they found very",
    "start": "671220",
    "end": "676860"
  },
  {
    "text": "scientifically that what what made you mainly a criminal or a non criminal",
    "start": "676860",
    "end": "682950"
  },
  {
    "text": "learned picture was this triangle up here if we take a look at that again ow",
    "start": "682950",
    "end": "690240"
  },
  {
    "text": "that's either a frown or smile actually and the method problem they had was they",
    "start": "690240",
    "end": "697110"
  },
  {
    "text": "took pictures from corporate headshots for the non criminals and",
    "start": "697110",
    "end": "703100"
  },
  {
    "text": "government-issued IDs for the criminals hmm yeah wouldn't quite clearly see how",
    "start": "703100",
    "end": "710339"
  },
  {
    "text": "difficult it would be to to distinguish between the two so anyways they had 90 percent accuracy",
    "start": "710339",
    "end": "718050"
  },
  {
    "text": "nine out of ten times the kid figurative style which was extraordinary because at",
    "start": "718050",
    "end": "723209"
  },
  {
    "text": "a time the biggest or the best architecture for neuron networks was",
    "start": "723209",
    "end": "728730"
  },
  {
    "text": "Alex net for for image neural networks and it could classified gender in eighty-six percent of the cases mm-hmm",
    "start": "728730",
    "end": "737450"
  },
  {
    "text": "nothing fishy there so they know you ever gotten a speeding ticket",
    "start": "737450",
    "end": "742680"
  },
  {
    "text": "I don't worry you don't have to put your hands up Alex that can see it in your face",
    "start": "742680",
    "end": "749810"
  },
  {
    "text": "but now if we think about this because this is another human behavior this may be not so one Hertz zero because what",
    "start": "751730",
    "end": "760490"
  },
  {
    "text": "actually constitutes a criminal in this case and if you were to think about like how would this actually work looking at",
    "start": "760490",
    "end": "766940"
  },
  {
    "text": "someone's face it would have to work in one of two ways first time I steal a pen",
    "start": "766940",
    "end": "772070"
  },
  {
    "text": "at my office my bone structure changes right either that or I'm born a criminal",
    "start": "772070",
    "end": "781330"
  },
  {
    "text": "there's only one of two ways but a criminality detector could work still",
    "start": "781330",
    "end": "787190"
  },
  {
    "text": "this is going on and this is used not this particular model but model ceased",
    "start": "787190",
    "end": "793940"
  },
  {
    "text": "like this one are used so the question is maybe not can we do it but should we",
    "start": "793940",
    "end": "800690"
  },
  {
    "text": "do it one of my former colleagues I'm saying former colleagues because we work",
    "start": "800690",
    "end": "806630"
  },
  {
    "text": "at the same company in Microsoft but I've actually never met her Kate Crawford she's now a director of AI now",
    "start": "806630",
    "end": "813400"
  },
  {
    "text": "in for AI and ethics she said we're currently in the biggest classification",
    "start": "813400",
    "end": "820970"
  },
  {
    "text": "experiment of our times or in human history it's not like we haven't done",
    "start": "820970",
    "end": "826790"
  },
  {
    "text": "this before many times throughout history Aristotle is was doing this but",
    "start": "826790",
    "end": "832250"
  },
  {
    "text": "we're now doing it at scale without anyone knowing and by people well who is",
    "start": "832250",
    "end": "840830"
  },
  {
    "text": "not understanding that they're even doing this and it's making it into products that are actually induced and",
    "start": "840830",
    "end": "847280"
  },
  {
    "text": "bought by a real governments this Gary  people right and the problem is",
    "start": "847280",
    "end": "855650"
  },
  {
    "text": "that as soon as we put it in an algorithm it becomes the truth so one of",
    "start": "855650",
    "end": "860870"
  },
  {
    "text": "my friends and I'm not sure if you're here both but he went to a hardware",
    "start": "860870",
    "end": "866930"
  },
  {
    "text": "store he was remodeling his house with his wife and he went to a hardware store to buy some two by fours got two two by",
    "start": "866930",
    "end": "874160"
  },
  {
    "text": "fours they were clearly labeled with the hardware store name and took them to the",
    "start": "874160",
    "end": "879170"
  },
  {
    "text": "counter the counter had the person that counters I looked at him his wife the",
    "start": "879170",
    "end": "886020"
  },
  {
    "text": "two-by-fours and said we don't carry those because the computer said nope",
    "start": "886020",
    "end": "893779"
  },
  {
    "text": "right so even looking at a two by fours",
    "start": "893779",
    "end": "898830"
  },
  {
    "text": "at the people in front of him and everything he's still trusted the",
    "start": "898830",
    "end": "904170"
  },
  {
    "text": "computer and to some extent even I trust a computer like this soon as soon as it",
    "start": "904170",
    "end": "910320"
  },
  {
    "text": "get put and gets put in an algorithm it sort of comes to truth it's like a",
    "start": "910320",
    "end": "916430"
  },
  {
    "text": "responsibility laundering because suddenly it's the computer that dust is I mean we all trust banks even though we",
    "start": "916430",
    "end": "925260"
  },
  {
    "text": "know that the people who are working at the banks creating these systems also have Friday's where they don't",
    "start": "925260",
    "end": "931380"
  },
  {
    "text": "necessarily look at the PRS all that closely right we're just letting it",
    "start": "931380",
    "end": "936990"
  },
  {
    "text": "happen but maybe it's because we trust computers to not have the same faults",
    "start": "936990",
    "end": "943920"
  },
  {
    "text": "this way so we know that people are biased that's how we survived that's how",
    "start": "943920",
    "end": "949380"
  },
  {
    "text": "we do shortcuts and how we actually get through life but the computer doesn't have any feelings it doesn't have any in",
    "start": "949380",
    "end": "956940"
  },
  {
    "text": "a biased it can't be racist but I do have partially the same problems as us",
    "start": "956940",
    "end": "964490"
  },
  {
    "text": "so I have to admit I'm not a big star Wars fan in fact I fell asleep on all the Star",
    "start": "964490",
    "end": "972180"
  },
  {
    "text": "Wars movies I did go because it is my duty as a computer engineer but I still",
    "start": "972180",
    "end": "977850"
  },
  {
    "text": "fall asleep so I couldn't tell Chewbacca",
    "start": "977850",
    "end": "983310"
  },
  {
    "text": "from his wife or his son because I haven't had a huge amount of exposure to wookies so because of that I can also",
    "start": "983310",
    "end": "992430"
  },
  {
    "text": "not tell exactly what distinguishes them in the same way a machine learning model",
    "start": "992430",
    "end": "998279"
  },
  {
    "text": "can only understand the things that it actually has seen and for computer",
    "start": "998279",
    "end": "1004610"
  },
  {
    "text": "vision the things that most computer vision systems have seen is this image",
    "start": "1004610",
    "end": "1010130"
  },
  {
    "text": "net it's a fantastic database of images huge database of images",
    "start": "1010130",
    "end": "1016880"
  },
  {
    "text": "millions of images of searches on the Internet now it has a little bit of an issue in",
    "start": "1016880",
    "end": "1024260"
  },
  {
    "text": "that being that it searches from the Internet in English the majority of the",
    "start": "1024260",
    "end": "1030260"
  },
  {
    "text": "pictures in here are from the US and Europe in fact there is like very very",
    "start": "1030260",
    "end": "1037100"
  },
  {
    "text": "little from Africa and and the very big countries of China and India have like 3",
    "start": "1037100",
    "end": "1044150"
  },
  {
    "text": "percent in total or pictures in here so that means that when we have a computer",
    "start": "1044150",
    "end": "1051590"
  },
  {
    "text": "vision system and maybe in like cognitive services and we give it this picture it shows this right because",
    "start": "1051590",
    "end": "1066590"
  },
  {
    "text": "that's our latest scene but it's part similarly when we look at face",
    "start": "1066590",
    "end": "1071780"
  },
  {
    "text": "recognition systems we have a benchmark that is commonly known as labeled faces",
    "start": "1071780",
    "end": "1078170"
  },
  {
    "text": "in the wild so this is a benchmark database of Yahoo News images headshots",
    "start": "1078170",
    "end": "1085370"
  },
  {
    "text": "from Yahoo News from 2002 to 2004 and most face recognition systems have been",
    "start": "1085370",
    "end": "1091870"
  },
  {
    "text": "benchmarked against this now if you picture who was in the news in 2002 to",
    "start": "1091870",
    "end": "1099890"
  },
  {
    "text": "2004 it will be 77% male 80% white and",
    "start": "1099890",
    "end": "1109670"
  },
  {
    "text": "actually a full 5 percent george w bush",
    "start": "1109670",
    "end": "1114880"
  },
  {
    "text": "and actually like if you look at the women who are in here they're either Hillary Clinton which I hope I don't",
    "start": "1114880",
    "end": "1120920"
  },
  {
    "text": "look like her or actresses which I could expire but I'm not looking like her",
    "start": "1120920",
    "end": "1127640"
  },
  {
    "text": "either and like them either but um so face recognition systems are extremely tailored to your CH w bush which becomes",
    "start": "1127640",
    "end": "1136340"
  },
  {
    "text": "a little bit of a problem because when you create systems that are based on",
    "start": "1136340",
    "end": "1141590"
  },
  {
    "text": "face recognition you get things like this if you don't train them on enough",
    "start": "1141590",
    "end": "1147530"
  },
  {
    "text": "of the population that you're actually targeting well you get things like this",
    "start": "1147530",
    "end": "1153080"
  },
  {
    "text": "where if I go through and I look at myself and my age and things I'm very",
    "start": "1153080",
    "end": "1159410"
  },
  {
    "text": "happy that it's guessing twenty-six yay I'm not 26 but I'm also not a male",
    "start": "1159410",
    "end": "1167050"
  },
  {
    "text": "which is a little bit of a different problem",
    "start": "1167050",
    "end": "1172300"
  },
  {
    "text": "this woman joy well when we I think I'm mangling her name badly but boom weenie",
    "start": "1172450",
    "end": "1179710"
  },
  {
    "text": "she's doing a lot of face recognition research and as you can see in the pictures he's wearing him white mask the",
    "start": "1179710",
    "end": "1187730"
  },
  {
    "text": "reason for this white mask is because she's not visible to many of the face",
    "start": "1187730",
    "end": "1192950"
  },
  {
    "text": "recognition systems out there it's not like they don't recognize that she's joyful woman II they don't recognize",
    "start": "1192950",
    "end": "1199820"
  },
  {
    "text": "that she's a person like she's too dark for most face recognition systems that's",
    "start": "1199820",
    "end": "1205880"
  },
  {
    "text": "the scary thing she's doing a lot of research wearing this mask we still have",
    "start": "1205880",
    "end": "1212750"
  },
  {
    "text": "done a lot of research because of her problems with this on how face",
    "start": "1212750",
    "end": "1218060"
  },
  {
    "text": "recognition works for different different groups of people and in 2018",
    "start": "1218060",
    "end": "1224200"
  },
  {
    "text": "early I think she went through the bigger face recognition systems at a",
    "start": "1224200",
    "end": "1229670"
  },
  {
    "text": "time and she discovered that while they all professed like a nice almost 100%",
    "start": "1229670",
    "end": "1236390"
  },
  {
    "text": "accuracy and gender accuracy it turns out is very very different for different",
    "start": "1236390",
    "end": "1243190"
  },
  {
    "text": "for different people so someone like a light male has like a",
    "start": "1243190",
    "end": "1248990"
  },
  {
    "text": "good hundred percent accuracy they will always be classified as male where where's the dark female in the IBM",
    "start": "1248990",
    "end": "1255290"
  },
  {
    "text": "system for example one out of three times she'll be classified as male okay",
    "start": "1255290",
    "end": "1262840"
  },
  {
    "text": "obviously a little bit of a problem a problem that causes things like this so",
    "start": "1262840",
    "end": "1269090"
  },
  {
    "text": "last summer two summers ago and they had in London bunch of CCTV cameras and they",
    "start": "1269090",
    "end": "1278030"
  },
  {
    "text": "had this watch for for coming late and like common criminals and they went out",
    "start": "1278030",
    "end": "1285140"
  },
  {
    "text": "they found this guy and went out with the SWAT car patted him down and it",
    "start": "1285140",
    "end": "1290750"
  },
  {
    "text": "turned out it just wasn't him because he's like with the Wookiees",
    "start": "1290750",
    "end": "1296179"
  },
  {
    "text": "these face recognition systems can tell a dark-colored person from another",
    "start": "1296179",
    "end": "1302360"
  },
  {
    "text": "dark-colored person which is yeah it's",
    "start": "1302360",
    "end": "1307730"
  },
  {
    "text": "not good however some things have been done to fix this in most I made your face",
    "start": "1307730",
    "end": "1315860"
  },
  {
    "text": "recognition systems so IBM went out and created another benchmark system I have because of the work of Joey Bulwer",
    "start": "1315860",
    "end": "1322070"
  },
  {
    "text": "meaning and there's a lot more diverse and has helped a lot with the with a",
    "start": "1322070",
    "end": "1330160"
  },
  {
    "text": "first sample with IBM face plus plus and Microsoft some still have problems and",
    "start": "1330160",
    "end": "1335720"
  },
  {
    "text": "there is a big debate and kind of like pie-throwing about whether this research",
    "start": "1335720",
    "end": "1343040"
  },
  {
    "text": "is good or bad but I'm hoping that day two we'll fix it so algorithms are using",
    "start": "1343040",
    "end": "1353870"
  },
  {
    "text": "math so they can't be racist there's a little bit of what I call bias laundering because it's not about the",
    "start": "1353870",
    "end": "1360620"
  },
  {
    "text": "algorithm it's nothing necessarily it's about of data we haven't and it's not",
    "start": "1360620",
    "end": "1366350"
  },
  {
    "text": "used images that have this problem we have this problem in text too so the way",
    "start": "1366350",
    "end": "1375290"
  },
  {
    "text": "text works or the way machine learning works around text is that we're trying to create some sense of what a word means",
    "start": "1375290",
    "end": "1382390"
  },
  {
    "text": "so for example if you have the word peach and Beach they sound very similar",
    "start": "1382390",
    "end": "1388010"
  },
  {
    "text": "but we know that peach and Beach have very little commonalities right so in",
    "start": "1388010",
    "end": "1395870"
  },
  {
    "text": "order to do some machine learning and understanding we need ten state understand a real meaning between the",
    "start": "1395870",
    "end": "1401660"
  },
  {
    "text": "word peach and understand it may be affricate would be a more similar word from the beach so in order to do this",
    "start": "1401660",
    "end": "1408350"
  },
  {
    "text": "we'll look at a large amount of data and we'll find out like semantics and what",
    "start": "1408350",
    "end": "1413929"
  },
  {
    "text": "you find then is sort of like not a",
    "start": "1413929",
    "end": "1418940"
  },
  {
    "text": "dictionary meaning but the common meaning of the word and all all the places that it's been used and the",
    "start": "1418940",
    "end": "1425000"
  },
  {
    "text": "context has been used so if we enter in Google Translate she's a computer",
    "start": "1425000",
    "end": "1430370"
  },
  {
    "text": "programmer and he's a nurse and translate back to Turkish and then",
    "start": "1430370",
    "end": "1435650"
  },
  {
    "text": "translated back it will show the true meaning of what Google thinks a computer",
    "start": "1435650",
    "end": "1441890"
  },
  {
    "text": "programmer or a nursing because this is the context of days right it thinks it",
    "start": "1441890",
    "end": "1449150"
  },
  {
    "text": "the majority of places where it's planned computer programmer is male context so it finds days it actually",
    "start": "1449150",
    "end": "1456470"
  },
  {
    "text": "also has this for many other things like he is beautiful she's aggressive she's",
    "start": "1456470",
    "end": "1461600"
  },
  {
    "text": "guilty I've been not a translator okay so all of the words have some kind of of",
    "start": "1461600",
    "end": "1468830"
  },
  {
    "text": "like male or female context yes actually also have a lot of other contexts like ethnic context and things",
    "start": "1468830",
    "end": "1474710"
  },
  {
    "text": "like that what is something like this causes also a lot of problems so let's",
    "start": "1474710",
    "end": "1480890"
  },
  {
    "text": "say you have a text prediction system you start off with this sentence and then you type in the word he and then",
    "start": "1480890",
    "end": "1487730"
  },
  {
    "text": "you see what the computer suggests and it will suggest something like this right the doctor hired the assistant",
    "start": "1487730",
    "end": "1494720"
  },
  {
    "text": "because he was too busy but on the other hand if you put in the word she it would",
    "start": "1494720",
    "end": "1500510"
  },
  {
    "text": "put in something like this right because that is the context is",
    "start": "1500510",
    "end": "1507280"
  },
  {
    "text": "inferring from this so things like this cause some real problems like when",
    "start": "1507280",
    "end": "1513490"
  },
  {
    "text": "Amazon was trying to create like CV selector and it right little removed",
    "start": "1513490",
    "end": "1520600"
  },
  {
    "text": "things like gender and things like that however the wording that we use gives us",
    "start": "1520600",
    "end": "1527080"
  },
  {
    "text": "a way and it gives us a way in the sense that it already knew that execute is a",
    "start": "1527080",
    "end": "1533919"
  },
  {
    "text": "very male word very not very often used by females and things like that makes it",
    "start": "1533919",
    "end": "1541450"
  },
  {
    "text": "then distinguish between them what is a good or a bad candidate so it causes so",
    "start": "1541450",
    "end": "1548409"
  },
  {
    "text": "things like they cost us a little bit of a confirmation bias bubble it causes it to always choose what we were always",
    "start": "1548409",
    "end": "1554950"
  },
  {
    "text": "chosen not necessarily because they're factually the best or factually like",
    "start": "1554950",
    "end": "1562030"
  },
  {
    "text": "what it should be but because we have a bias we have historical bias that tells us what but a computer in there should",
    "start": "1562030",
    "end": "1568809"
  },
  {
    "text": "traditionally be male for example it also causes and what are call feedback",
    "start": "1568809",
    "end": "1575620"
  },
  {
    "text": "loops so feedback loop go something like this about 5% of the CEOs are female",
    "start": "1575620",
    "end": "1582400"
  },
  {
    "text": "that's the fact we can try to change that but right now that's how it works",
    "start": "1582400",
    "end": "1588909"
  },
  {
    "text": "so when you see the results for the word CEO you'll get something like this now",
    "start": "1588909",
    "end": "1594789"
  },
  {
    "text": "the problem is that if you get a search result on on google or on bing or wherever you click you normally just",
    "start": "1594789",
    "end": "1602679"
  },
  {
    "text": "click in the top 5% maybe you're it is hot like three four rows and the more",
    "start": "1602679",
    "end": "1608830"
  },
  {
    "text": "you click these the more that will become the truth so whatever majority",
    "start": "1608830",
    "end": "1615190"
  },
  {
    "text": "you have will be sort of like feedback and now not only will it go from like",
    "start": "1615190",
    "end": "1623289"
  },
  {
    "text": "five ninety five it will turn into like in mind in mind one ratio because you're",
    "start": "1623289",
    "end": "1629260"
  },
  {
    "text": "just sort of like automating this bias you're creating it bigger and bigger",
    "start": "1629260",
    "end": "1635910"
  },
  {
    "text": "similarly if you have a location where you have a lot of crime two men you go",
    "start": "1635910",
    "end": "1641610"
  },
  {
    "text": "in and you send in a lot of police and you arrest more people now the perceived",
    "start": "1641610",
    "end": "1650840"
  },
  {
    "text": "situation here is that you have even more climbing in this area right so then",
    "start": "1650840",
    "end": "1656600"
  },
  {
    "text": "you send in more police and more arrests and it just goes on and feed backs away",
    "start": "1656600",
    "end": "1662900"
  },
  {
    "text": "similarly to how you always see the same things on Facebook you always listen to",
    "start": "1662900",
    "end": "1668760"
  },
  {
    "text": "the same music on Spotify you get into these recursive feedback loops the mist",
    "start": "1668760",
    "end": "1674670"
  },
  {
    "text": "sort of like you lose the the minority",
    "start": "1674670",
    "end": "1682110"
  },
  {
    "text": "for me in this so in the words of Bora",
    "start": "1682110",
    "end": "1688880"
  },
  {
    "text": "real bora devops part of course to make an error is human but to propagate the",
    "start": "1688880",
    "end": "1694860"
  },
  {
    "text": "error to our server in automatic ways is DevOps if we translate this to aii",
    "start": "1694860",
    "end": "1701630"
  },
  {
    "text": "forget this some bias like how do i deal",
    "start": "1701630",
    "end": "1708240"
  },
  {
    "text": "with it because bias is sort of like an np-hard problem i say empty heart because there's so many different",
    "start": "1708240",
    "end": "1714900"
  },
  {
    "text": "variables here that no matter what roots will go down there will always be one more root but if we haven't explored",
    "start": "1714900",
    "end": "1720810"
  },
  {
    "text": "right so for the words we could technically and it's been done and it's",
    "start": "1720810",
    "end": "1727470"
  },
  {
    "text": "it works we could remove the male-female bias and we could used say computer",
    "start": "1727470",
    "end": "1734160"
  },
  {
    "text": "engineers are neutral and that's you can use remove sort of that factor of the",
    "start": "1734160",
    "end": "1739350"
  },
  {
    "text": "word and it would work so great why don't we use that well it turns out that",
    "start": "1739350",
    "end": "1745620"
  },
  {
    "text": "is not necessarily that easy because there are some words somewhere",
    "start": "1745620",
    "end": "1751200"
  },
  {
    "text": "for example mother or father they should have a very high like gender bias but",
    "start": "1751200",
    "end": "1757380"
  },
  {
    "text": "what about something like colorblind or pregnant or queen like should they have",
    "start": "1757380",
    "end": "1765090"
  },
  {
    "text": "a gender prize and if you start too little if you start thinking about things like",
    "start": "1765090",
    "end": "1771750"
  },
  {
    "text": "that it becomes a little bit more complicated and even more complicated when you realize that once you remove",
    "start": "1771750",
    "end": "1777179"
  },
  {
    "text": "the gender bias you might want to remove the ethnicity bias which is not just like a two thing just like many things",
    "start": "1777179",
    "end": "1784890"
  },
  {
    "text": "so I have to like start them all against each other and maybe you want to remove",
    "start": "1784890",
    "end": "1790380"
  },
  {
    "text": "the bias of like political affiliation and sexual orientation and all these things and suddenly it becomes a very",
    "start": "1790380",
    "end": "1796919"
  },
  {
    "text": "very difficult problem so to give an",
    "start": "1796919",
    "end": "1802860"
  },
  {
    "text": "example of another way this is also difficult if we look at alone and we say",
    "start": "1802860",
    "end": "1809610"
  },
  {
    "text": "okay so we're gonna create like a credit card algorithm something that should",
    "start": "1809610",
    "end": "1814860"
  },
  {
    "text": "tell us if this person should have credit or not so we should remove gender",
    "start": "1814860",
    "end": "1821010"
  },
  {
    "text": "and remove a lot of other things like ethnicity in proxies for them but then",
    "start": "1821010",
    "end": "1827100"
  },
  {
    "text": "we realized that it might still serve",
    "start": "1827100",
    "end": "1832230"
  },
  {
    "text": "like be giving less credit to women than to men because women normally have like",
    "start": "1832230",
    "end": "1837539"
  },
  {
    "text": "big gaps in their employment history like one and a half year gaps here and there and maybe two or three in a",
    "start": "1837539",
    "end": "1844049"
  },
  {
    "text": "lifetime coinciding made when you had children and that of course causes a",
    "start": "1844049",
    "end": "1851220"
  },
  {
    "text": "problem so maybe we would then decide that we should have equal outcome like equal outcome would mean that if we have",
    "start": "1851220",
    "end": "1859530"
  },
  {
    "text": "a hundred women and hundred men an equal amount of the women and the men should be getting credit cards but that would",
    "start": "1859530",
    "end": "1866970"
  },
  {
    "text": "also cause a problem because what if all the females are not qualified and all",
    "start": "1866970",
    "end": "1872700"
  },
  {
    "text": "the males are qualified now you're kind of removing credit cards for some people",
    "start": "1872700",
    "end": "1877830"
  },
  {
    "text": "that were obviously qualified and giving them to some that were not qualified so Noah might go through and say oh we",
    "start": "1877830",
    "end": "1884820"
  },
  {
    "text": "should have equal opportunity meaning that given the the same qualifications",
    "start": "1884820",
    "end": "1892940"
  },
  {
    "text": "you should have an equal opportunity so you shouldn't be penalized for being a man or a woman but then we realize that",
    "start": "1892940",
    "end": "1899730"
  },
  {
    "text": "all of these things become a very very political question and not so much a technical",
    "start": "1899730",
    "end": "1905009"
  },
  {
    "text": "question we realize that maybe while we're in short if there is and while",
    "start": "1905009",
    "end": "1911249"
  },
  {
    "text": "we're responsible as engineers we also need to bring in some other perspectives and domain knowledge into this equation",
    "start": "1911249",
    "end": "1919139"
  },
  {
    "text": "if we don't we might in with a scandal and like the Apple card so this is I",
    "start": "1919139",
    "end": "1929309"
  },
  {
    "text": "think the crater of Ruby on Rails started is for all about the apple cart",
    "start": "1929309",
    "end": "1935460"
  },
  {
    "text": "being sexist and then as the wasps Nick came in and he also thought that and",
    "start": "1935460",
    "end": "1942539"
  },
  {
    "text": "then wired came in and also thought that and it might very well be that it wasn't",
    "start": "1942539",
    "end": "1949529"
  },
  {
    "text": "that the reason Hawaii vas Nick's wife didn't get the same credit limit was",
    "start": "1949529",
    "end": "1954839"
  },
  {
    "text": "because she didn't make as much money or for many of the other reasons but the problem here is that we don't know that",
    "start": "1954839",
    "end": "1962940"
  },
  {
    "text": "and contradict here too for example if you have normal credit card",
    "start": "1962940",
    "end": "1968099"
  },
  {
    "text": "you kind of know when you make an application that it looks at your credit",
    "start": "1968099",
    "end": "1973289"
  },
  {
    "text": "history it looks like whatever you filled in with that sort of where the",
    "start": "1973289",
    "end": "1979320"
  },
  {
    "text": "buck stops whereas if we have an Apple credit card or a saloon kind of like a lot of thoughts that go into your head",
    "start": "1979320",
    "end": "1986219"
  },
  {
    "text": "that maybe it's also looking at x y&z and all the other data that I'm giving",
    "start": "1986219",
    "end": "1992129"
  },
  {
    "text": "away to Apple so the problem here is maybe not the algorithm but the",
    "start": "1992129",
    "end": "1998190"
  },
  {
    "text": "transparency around the algorithm causing causing this so not only have do",
    "start": "1998190",
    "end": "2005599"
  },
  {
    "text": "you have to make sort of take care of the bias and the political questions around it but also around transparency",
    "start": "2005599",
    "end": "2012409"
  },
  {
    "text": "and making sure that people understand what the decisions are based on whether",
    "start": "2012409",
    "end": "2017719"
  },
  {
    "text": "they are based on gender which I don't think actually there was a person at Apple a little Goldman Sachs in this",
    "start": "2017719",
    "end": "2023839"
  },
  {
    "text": "case that when Tina said maelys ten times the credit history of women I",
    "start": "2023839",
    "end": "2029389"
  },
  {
    "text": "don't even think that they looked and maiden made sure I was certified Rockstar developer before getting the",
    "start": "2029389",
    "end": "2035359"
  },
  {
    "text": "Apple credit card but still things like this come up",
    "start": "2035359",
    "end": "2042800"
  },
  {
    "text": "because they weren't very transparent so what do we do do we just give up because",
    "start": "2042800",
    "end": "2049520"
  },
  {
    "text": "it seems like so hard that there is like really no solution to this obviously I",
    "start": "2049520",
    "end": "2056780"
  },
  {
    "text": "wouldn't be here if I thought that so what I've done specifically is I'm in an",
    "start": "2056780",
    "end": "2062360"
  },
  {
    "text": "AI ethics committee yet in Microsoft sort of like looking at all the products",
    "start": "2062360",
    "end": "2067610"
  },
  {
    "text": "that were working on and we have some specific agendas or specific points that we're looking through for all the",
    "start": "2067610",
    "end": "2073310"
  },
  {
    "text": "products and the specific ones that we're looking at are if it's fair and inclusive if it's transparent does",
    "start": "2073310",
    "end": "2080240"
  },
  {
    "text": "everyone in the in the process understand where the data comes from and",
    "start": "2080240",
    "end": "2085280"
  },
  {
    "text": "how the decisions are made with machine learning you can't know exactly but you can at least have an inkling",
    "start": "2085280",
    "end": "2091129"
  },
  {
    "text": "understanding the data and is it accountable so when something goes wrong",
    "start": "2091130",
    "end": "2096200"
  },
  {
    "text": "is there a person there or is there someone who can actually say yeah you",
    "start": "2096200",
    "end": "2101960"
  },
  {
    "text": "know I understand the problem we have we're going to look at it and like actually fix the problems that come up",
    "start": "2101960",
    "end": "2109480"
  },
  {
    "text": "making sure that it's safe and reliable like autonomous cars and or and the",
    "start": "2109480",
    "end": "2116030"
  },
  {
    "text": "systems that decide if you should get treatment or not and secure and private",
    "start": "2116030",
    "end": "2121730"
  },
  {
    "text": "so these are the five things that we look at specifically when we go through",
    "start": "2121730",
    "end": "2126770"
  },
  {
    "text": "the process the first thing and there's a colleague of mine he is that he says",
    "start": "2126770",
    "end": "2131960"
  },
  {
    "text": "what is the worst possible headline what could possibly go wrong with this this",
    "start": "2131960",
    "end": "2137090"
  },
  {
    "text": "is the first question we always ask ourselves about any machine learning product that we work on so that at least",
    "start": "2137090",
    "end": "2142820"
  },
  {
    "text": "we have a base and this is like where we get like super creative about things that could cut it and potentially go",
    "start": "2142820",
    "end": "2147950"
  },
  {
    "text": "wrong because then you have to decide are they worth it and if they're worth",
    "start": "2147950",
    "end": "2153890"
  },
  {
    "text": "it because in some cases you actually do want something for the benefits it gives",
    "start": "2153890",
    "end": "2159830"
  },
  {
    "text": "but you have to mitigate the problems that didn't let my erase so for example",
    "start": "2159830",
    "end": "2165650"
  },
  {
    "text": "some problems are quite easy to spot should you have a credit card system",
    "start": "2165650",
    "end": "2172080"
  },
  {
    "text": "based on social ratings or should you have a criminality detector I think sort of like the black mirror episodes right",
    "start": "2172080",
    "end": "2178830"
  },
  {
    "text": "themselves so in my mind - obvious no but then you have something like things",
    "start": "2178830",
    "end": "2185070"
  },
  {
    "text": "you have should you have something in that spots cancer like tells you if it's",
    "start": "2185070",
    "end": "2191160"
  },
  {
    "text": "benign ormaline and obviously the problem where they say state if you get",
    "start": "2191160",
    "end": "2196590"
  },
  {
    "text": "it wrong it's fatal it's like very dangerous to get this wrong but it's also sometimes very dangerous to not",
    "start": "2196590",
    "end": "2203580"
  },
  {
    "text": "have this system at all so in that case you have to figure out how you can sort",
    "start": "2203580",
    "end": "2208950"
  },
  {
    "text": "of take that and say okay so we're obviously not going to do an automated system instead we should have something",
    "start": "2208950",
    "end": "2216210"
  },
  {
    "text": "maybe that speeds up the process or helps doctors but always keeping a human",
    "start": "2216210",
    "end": "2221310"
  },
  {
    "text": "in the loop or a pigeon in the booth as you see fit and then if you have some",
    "start": "2221310",
    "end": "2232680"
  },
  {
    "text": "things that you go I can't see what could possibly go wrong with this like",
    "start": "2232680",
    "end": "2238020"
  },
  {
    "text": "for example I'm sorry I guess creating in our meat detector it like something that you take in a picture and it says",
    "start": "2238020",
    "end": "2246300"
  },
  {
    "text": "it's a cat it's a dog like you know he's for fun until he end up with this",
    "start": "2246300",
    "end": "2252540"
  },
  {
    "text": "situation right and I don't think anyone",
    "start": "2252540",
    "end": "2258450"
  },
  {
    "text": "and I'm thinking we can be sure if that no one has made this label or even thought to put this label in there but",
    "start": "2258450",
    "end": "2265680"
  },
  {
    "text": "in case like that you still have to have a rapid response system to understand",
    "start": "2265680",
    "end": "2270840"
  },
  {
    "text": "how to fix this because obviously this was very involuntary but also very consequential so understanding the",
    "start": "2270840",
    "end": "2280680"
  },
  {
    "text": "problem then we have the historical and data and the historical data might contain biases that we can either want",
    "start": "2280680",
    "end": "2290430"
  },
  {
    "text": "or not want so in a case like this we might say okay so we know that five percent of CEOs are women and the rest",
    "start": "2290430",
    "end": "2297630"
  },
  {
    "text": "are men and and that's our past but that might I don't want to make that our future so",
    "start": "2297630",
    "end": "2304290"
  },
  {
    "text": "in a case like that who might go in and infuse you know some some infused you",
    "start": "2304290",
    "end": "2314000"
  },
  {
    "text": "couldn't you've used women whatever like infusing a few women in this search result to make sure we don't run into",
    "start": "2314000",
    "end": "2320880"
  },
  {
    "text": "that run of a feedback loop or in the case of Spotify maybe sometimes suggesting something that's a little bit",
    "start": "2320880",
    "end": "2326850"
  },
  {
    "text": "off to keep things interesting in fact with Spotify they have a really",
    "start": "2326850",
    "end": "2333119"
  },
  {
    "text": "interesting historical problem so over Christmas I'm guessing I was not the",
    "start": "2333119",
    "end": "2339960"
  },
  {
    "text": "only one to listen to Mariah Carey but I'm also like after a 25th",
    "start": "2339960",
    "end": "2347360"
  },
  {
    "text": "I'm not big Mariah Carey that I'm sorry to say so I don't want my whole sort of",
    "start": "2347360",
    "end": "2354390"
  },
  {
    "text": "like everything else modified to be Mariah Carey from then on so there's",
    "start": "2354390",
    "end": "2360180"
  },
  {
    "text": "history and there it endures history in the short term so we have to be conscious about what our history tells",
    "start": "2360180",
    "end": "2365340"
  },
  {
    "text": "us and not just sort of go on that some other things that are quite obvious is",
    "start": "2365340",
    "end": "2372600"
  },
  {
    "text": "for example if you do a house price estimator and then two years later some",
    "start": "2372600",
    "end": "2379230"
  },
  {
    "text": "law was passed then the house price estimator is not working anymore so your historical data it's not working as a",
    "start": "2379230",
    "end": "2386250"
  },
  {
    "text": "fix for that but in this case you can do I have something political or you can do",
    "start": "2386250",
    "end": "2391260"
  },
  {
    "text": "something and technically unstated and then even if your data would be perfect",
    "start": "2391260",
    "end": "2398400"
  },
  {
    "text": "you might still have selection bias so selection bias is probably the most",
    "start": "2398400",
    "end": "2404490"
  },
  {
    "text": "common way to introduce a problem in a machine learning system selection bias means that we're obviously not going to",
    "start": "2404490",
    "end": "2410100"
  },
  {
    "text": "sample the whole world for anything so as an example this was an application",
    "start": "2410100",
    "end": "2417119"
  },
  {
    "text": "that and was supposed to fix potholes this was in 2011 and I put this here for",
    "start": "2417119",
    "end": "2423450"
  },
  {
    "text": "reference because what they did was they had an app on iPhone and it would sort",
    "start": "2423450",
    "end": "2430710"
  },
  {
    "text": "of like sense when you were driving on the street and if it was and vibrating or if it was moving a lot",
    "start": "2430710",
    "end": "2437430"
  },
  {
    "text": "it would sense a pothole and would report it back and it was great",
    "start": "2437430",
    "end": "2442920"
  },
  {
    "text": "however it only found potholes in the very rich districts of Boston any",
    "start": "2442920",
    "end": "2449190"
  },
  {
    "text": "guesses on why maybe hmm yeah cuz maybe the iPhones were sort of like in that particular",
    "start": "2449190",
    "end": "2456300"
  },
  {
    "text": "area so you're sampling like how your sample makes a lot of difference if",
    "start": "2456300",
    "end": "2461550"
  },
  {
    "text": "you're standing outside of a retirement home or if you're standing outside of a",
    "start": "2461550",
    "end": "2466680"
  },
  {
    "text": "daycare center and do a poll you'll probably get a lot different results as far as like how you should use your tax",
    "start": "2466680",
    "end": "2472230"
  },
  {
    "text": "money and similarly the way we've sampled imagenet as a problem so every",
    "start": "2472230",
    "end": "2479430"
  },
  {
    "text": "sampling we do will introduce the bias of the people doing the sampling but",
    "start": "2479430",
    "end": "2485280"
  },
  {
    "text": "also serve like the available data that we have so one way that we can work with",
    "start": "2485280",
    "end": "2492720"
  },
  {
    "text": "this is by actually documenting how we did things and the limitation is off of",
    "start": "2492720",
    "end": "2499230"
  },
  {
    "text": "these data sets and then we go to select",
    "start": "2499230",
    "end": "2507090"
  },
  {
    "text": "features and proxies so look at crime for example and saying that an arrest",
    "start": "2507090",
    "end": "2513540"
  },
  {
    "text": "means crime is using a proxy you might think that arrest equals crime and in a",
    "start": "2513540",
    "end": "2520800"
  },
  {
    "text": "lot of cases maybe it does but there are also some crimes that never go and get",
    "start": "2520800",
    "end": "2526920"
  },
  {
    "text": "like some criminals that never get arrested and some criminals some non criminals that do get arrested so the",
    "start": "2526920",
    "end": "2532800"
  },
  {
    "text": "arrest is a lot of the biown a lot in the bias off police people in the areas",
    "start": "2532800",
    "end": "2538140"
  },
  {
    "text": "that you live in and things like that similarly if you look at a diagnosis that's in the bias of a doctors so using",
    "start": "2538140",
    "end": "2546359"
  },
  {
    "text": "something like proxied like that who will also change your system a lot and",
    "start": "2546359",
    "end": "2553050"
  },
  {
    "text": "then we have the models so choosing a model you can either choose a very",
    "start": "2553050",
    "end": "2559230"
  },
  {
    "text": "simple model in a very simple model you'll end up with a problem that if 95%",
    "start": "2559230",
    "end": "2565770"
  },
  {
    "text": "of your computer engineers are mailed then all you computer engineers on male but if you choose something that is like a little",
    "start": "2565770",
    "end": "2572999"
  },
  {
    "text": "bit too complex it will learn like the exact thing you taught it so it will not",
    "start": "2572999",
    "end": "2579119"
  },
  {
    "text": "generalize well so if you ask what color is lemon might say yellow and then you",
    "start": "2579119",
    "end": "2585390"
  },
  {
    "text": "ask which color is a lemon and it might give you a totally different answer although you're sort of asking the same",
    "start": "2585390",
    "end": "2592109"
  },
  {
    "text": "question and then you might ask which color is lemon and guess just crazy",
    "start": "2592109",
    "end": "2598670"
  },
  {
    "text": "right so um the next thing is evaluation",
    "start": "2600349",
    "end": "2605940"
  },
  {
    "text": "so we've already seen problems with evaluation and with the banish mark systems but there's also so you can",
    "start": "2605940",
    "end": "2612619"
  },
  {
    "text": "actually fix this a little bit by using tools like the Google what if tool that",
    "start": "2612619",
    "end": "2619380"
  },
  {
    "text": "allows you to slice the data by different things so slice the data by gender and make sure you get the results",
    "start": "2619380",
    "end": "2625410"
  },
  {
    "text": "like a similar result for for the genders or for the mr. D and things like that but you also have different",
    "start": "2625410",
    "end": "2633059"
  },
  {
    "text": "measuring problems so let's say you have a scissor problem like this you have your gonna create a fraud detector and",
    "start": "2633059",
    "end": "2639630"
  },
  {
    "text": "you have a system that has for every thousand transactions it has one fraud transaction now if you wanted to have",
    "start": "2639630",
    "end": "2649099"
  },
  {
    "text": "99.9 percent accuracy on your machine learning model you could simply write",
    "start": "2649099",
    "end": "2654329"
  },
  {
    "text": "this right yay yeah so this kind of",
    "start": "2654329",
    "end": "2663209"
  },
  {
    "text": "proves how easy it is to fool the system and this is what will happen this is",
    "start": "2663209",
    "end": "2669359"
  },
  {
    "text": "what a machine learning model will actually learn if you just go by accuracy obviously here you want to",
    "start": "2669359",
    "end": "2676529"
  },
  {
    "text": "slice in my sage and want to make sure that the accuracy for the fraud is high",
    "start": "2676529",
    "end": "2681859"
  },
  {
    "text": "but this is sort of like how the problems creep in like the label faces",
    "start": "2681859",
    "end": "2688259"
  },
  {
    "text": "and the world problems and then there is the way that you use and the systems so",
    "start": "2688259",
    "end": "2696739"
  },
  {
    "text": "sometimes when they use the system you might have a problem that you're",
    "start": "2696739",
    "end": "2702299"
  },
  {
    "text": "giving away things that you shouldn't necessarily give away so it's because",
    "start": "2702299",
    "end": "2708239"
  },
  {
    "text": "you've learned something it doesn't necessarily mean that you don't should show it so let's say for example you do",
    "start": "2708239",
    "end": "2713729"
  },
  {
    "text": "an autocorrect system it will learn from everything you tie and it might be hello",
    "start": "2713729",
    "end": "2720059"
  },
  {
    "text": "but consequentially if it always shows the things that you normally type in the wrong context or also something like",
    "start": "2720059",
    "end": "2727499"
  },
  {
    "text": "this where it correctly learned that his teenager was pregnant but maybe she",
    "start": "2727499",
    "end": "2733619"
  },
  {
    "text": "didn't necessarily wanted to give that away to her parents in the newsletter from Target so you have to think a",
    "start": "2733619",
    "end": "2741930"
  },
  {
    "text": "little bit about how you technology could be used and how it will be used so",
    "start": "2741930",
    "end": "2748069"
  },
  {
    "text": "one big thing that a lot of people are talking about is this perpetual lineup",
    "start": "2748069",
    "end": "2755369"
  },
  {
    "text": "thing and be using the CCTV cameras and using face detection to automatically",
    "start": "2755369",
    "end": "2761069"
  },
  {
    "text": "find criminals person of interest style I for want to think that this is a very",
    "start": "2761069",
    "end": "2767039"
  },
  {
    "text": "scary thing that is happening because um it kind of limits us in in our growth as",
    "start": "2767039",
    "end": "2774779"
  },
  {
    "text": "a society and what I mean by that is for example if you if you look at first teenagers if you control and see where",
    "start": "2774779",
    "end": "2782369"
  },
  {
    "text": "ever they go who they're with how are they possibly going to rebel and understand themselves and grow and",
    "start": "2782369",
    "end": "2788759"
  },
  {
    "text": "become bigger people because people have to be able to make mistakes and people have to like society might change so if",
    "start": "2788759",
    "end": "2797219"
  },
  {
    "text": "we would have had a system where everything was controlled and criminals",
    "start": "2797219",
    "end": "2802469"
  },
  {
    "text": "were sort of like caught on sight a number of years ago then having like I",
    "start": "2802469",
    "end": "2811640"
  },
  {
    "text": "think a relationship would be would not be something that we could have right",
    "start": "2811640",
    "end": "2816900"
  },
  {
    "text": "now or if you're into that like smoking",
    "start": "2816900",
    "end": "2823079"
  },
  {
    "text": "pot in the u.s. because that would have been caught and still didn't like no one",
    "start": "2823079",
    "end": "2829680"
  },
  {
    "text": "could ever rebound and create new ways of thinking so I think if you're creating if you",
    "start": "2829680",
    "end": "2837870"
  },
  {
    "text": "have a system and something that could be used like that in a totalitarian way",
    "start": "2837870",
    "end": "2843210"
  },
  {
    "text": "you also need to make sure that it's not used like that so it's a bigger company",
    "start": "2843210",
    "end": "2848400"
  },
  {
    "text": "or a bigger player you have to put your stakes down and say that this is not how I should use it specifically also",
    "start": "2848400",
    "end": "2855030"
  },
  {
    "text": "knowing that it has these biases it has these problems that will make things",
    "start": "2855030",
    "end": "2860040"
  },
  {
    "text": "worse for a certain population or minorities in the system likewise I'm",
    "start": "2860040",
    "end": "2866520"
  },
  {
    "text": "sure you've seen deep fakes deep fakes",
    "start": "2866520",
    "end": "2871590"
  },
  {
    "text": "are basically creating videos where you can make someone look like they're saying something that are not actually",
    "start": "2871590",
    "end": "2877680"
  },
  {
    "text": "saying so a quite an easy way to create fake news so I'm happy that the big five",
    "start": "2877680",
    "end": "2885480"
  },
  {
    "text": "got together and posted a very big healthy sum of money to the people that",
    "start": "2885480",
    "end": "2893250"
  },
  {
    "text": "could mitigate this and sort of like find eesti fakes another thing and that",
    "start": "2893250",
    "end": "2901440"
  },
  {
    "text": "I think is important in this is to have diverse teams so have someone that",
    "start": "2901440",
    "end": "2907290"
  },
  {
    "text": "actually speaks up because it's not always to put your easy to put yourself in someone else's shoes and understand",
    "start": "2907290",
    "end": "2912690"
  },
  {
    "text": "like all the different possibilities that could come up like for example when Facebook created a system for saying",
    "start": "2912690",
    "end": "2920850"
  },
  {
    "text": "which names were okay or not and didn't necessarily think that long names",
    "start": "2920850",
    "end": "2926460"
  },
  {
    "text": "containing proper nouns were appropriate this happens or when car manufacturers",
    "start": "2926460",
    "end": "2934770"
  },
  {
    "text": "don't really think up women as drivers and not her crash test dummies that that",
    "start": "2934770",
    "end": "2940890"
  },
  {
    "text": "are appropriate sized for women in fact up to 2003 there was no female crash",
    "start": "2940890",
    "end": "2946260"
  },
  {
    "text": "test dummies and what would we do if we",
    "start": "2946260",
    "end": "2952380"
  },
  {
    "text": "didn't have any British people in our teams someone who could tell us if we should pour the milk first or second",
    "start": "2952380",
    "end": "2959840"
  },
  {
    "text": "yeah so and then we also need to understand that no matter what we do",
    "start": "2960960",
    "end": "2966580"
  },
  {
    "text": "Eris will creep up things will happen so in this case obviously they thought what",
    "start": "2966580",
    "end": "2974860"
  },
  {
    "text": "could possibly go wrong with this or maybe someone maybe no-one thought that",
    "start": "2974860",
    "end": "2981060"
  },
  {
    "text": "but he used face recognition technology to to send jaywalkers texts perfect like",
    "start": "2981060",
    "end": "2988270"
  },
  {
    "text": "you don't even have to have a police in the loop in there but then this happens like this lady was on the on the bus she",
    "start": "2988270",
    "end": "2995470"
  },
  {
    "text": "gets a lot of tickets so obviously then",
    "start": "2995470",
    "end": "3001050"
  },
  {
    "text": "you have to have system to to fix that but after all is said and done and if",
    "start": "3001050",
    "end": "3007560"
  },
  {
    "text": "you look at all these things and and try",
    "start": "3007560",
    "end": "3012690"
  },
  {
    "text": "to fix them as best you can the one thing I want to leave you with is that just like all these people joy below me",
    "start": "3012690",
    "end": "3019560"
  },
  {
    "text": "neo Chris Wiley all these when you see something wrong or something that doesn't fit or something that just feels",
    "start": "3019560",
    "end": "3025380"
  },
  {
    "text": "like they should have really thought with what the heck should go wrong with this speak up because we're not just",
    "start": "3025380",
    "end": "3033540"
  },
  {
    "text": "engineers we are the guardians of our future thank you",
    "start": "3033540",
    "end": "3040490"
  },
  {
    "text": "[Music] you",
    "start": "3048690",
    "end": "3054840"
  }
]
[
  {
    "start": "0",
    "end": "97000"
  },
  {
    "text": "hello everyone and welcome to this talk thank you so much for being here I know",
    "start": "8580",
    "end": "13990"
  },
  {
    "text": "there's so many different other presentations out there so my name is Marsha I am a data scientist I work as a",
    "start": "13990",
    "end": "22689"
  },
  {
    "text": "consultant at booba I'm originally from Croatia and at my free time I am a",
    "start": "22689",
    "end": "29020"
  },
  {
    "text": "full-time geek doing cosplay at science fiction conventions and stuff so that's all to know about me now let's talk",
    "start": "29020",
    "end": "36489"
  },
  {
    "text": "about my text summarization so today our agenda for today is basically first",
    "start": "36489",
    "end": "42700"
  },
  {
    "text": "we're going to discuss a little bit okay what is automatic text summarization and why is it used and what are different",
    "start": "42700",
    "end": "49239"
  },
  {
    "text": "types of text summarization then we will discuss some methods and algorithms that are used today to summarize and that we",
    "start": "49239",
    "end": "56020"
  },
  {
    "text": "used in the past to summarize text automatically and in the end we are going to discuss some of the evaluation",
    "start": "56020",
    "end": "61090"
  },
  {
    "text": "methods so how to know if our summaries are good enough now text summarization",
    "start": "61090",
    "end": "66550"
  },
  {
    "text": "is a very very broad area so there are many different methods many different algorithms there is many ways to",
    "start": "66550",
    "end": "73750"
  },
  {
    "text": "evaluate your text summarization different types of summarization so of course there is not enough time in one",
    "start": "73750",
    "end": "79119"
  },
  {
    "text": "hour to go through all of that so you know we're gonna kind of try to summarize our summers how to summarize",
    "start": "79119",
    "end": "86490"
  },
  {
    "text": "so first part is we talk will be what is",
    "start": "86490",
    "end": "91630"
  },
  {
    "text": "automatic text summarization basically text summarization in general is the",
    "start": "91630",
    "end": "98680"
  },
  {
    "start": "97000",
    "end": "97000"
  },
  {
    "text": "process of shortening a text document in order to create a summary with the major points of the original document now",
    "start": "98680",
    "end": "106079"
  },
  {
    "text": "automatic text summarization is the same thing but just instead of having manual",
    "start": "106079",
    "end": "111490"
  },
  {
    "text": "manually created summaries we are using software now there are many reasons to",
    "start": "111490",
    "end": "116740"
  },
  {
    "text": "create summary but first and foremost the main reason is that we have more and more text data and less and less time to",
    "start": "116740",
    "end": "123549"
  },
  {
    "text": "process it so today I mean even before we had a lot of text data even when the",
    "start": "123549",
    "end": "128860"
  },
  {
    "text": "text data was mostly written on a paper however today with all the digitalization and with the internet",
    "start": "128860",
    "end": "135070"
  },
  {
    "text": "being the endless source of the text data we are kind of flooded with the textual information and it's really hard",
    "start": "135070",
    "end": "140739"
  },
  {
    "text": "to find relevant information in all this amount of text so why would",
    "start": "140739",
    "end": "146590"
  },
  {
    "text": "need summaries well one one use case would be if really we don't have time to read the entire document then it would",
    "start": "146590",
    "end": "152500"
  },
  {
    "text": "be great to have some automatic automated way to actually create summaries so that people can just read",
    "start": "152500",
    "end": "158320"
  },
  {
    "text": "the summary and get the information they need on the other hand sometimes that is not enough sometimes you do need you",
    "start": "158320",
    "end": "164710"
  },
  {
    "text": "need to go into details and you don't need to read an entire document but it could be very useful to have a summary",
    "start": "164710",
    "end": "170800"
  },
  {
    "text": "of the document so you can read it and see okay is this document actually relevant for me is this something that",
    "start": "170800",
    "end": "176770"
  },
  {
    "text": "does does this document actually contain the information I'm looking for now the",
    "start": "176770",
    "end": "182350"
  },
  {
    "text": "problems we're dealing with in any kind of summarization both manual and",
    "start": "182350",
    "end": "188130"
  },
  {
    "text": "automatic is well first how do we select the most relevant information from a",
    "start": "188130",
    "end": "193360"
  },
  {
    "text": "source document and then once we have this information how do we express it in",
    "start": "193360",
    "end": "198820"
  },
  {
    "text": "this final summary so the objective of any summarizer is to write a program",
    "start": "198820",
    "end": "205660"
  },
  {
    "text": "visit our objective is to write a program that can reduce the size of a text while preserving all the main",
    "start": "205660",
    "end": "212440"
  },
  {
    "text": "points of its meaning so how to say the most important things in the shortest amount of time and what we're trying to",
    "start": "212440",
    "end": "219310"
  },
  {
    "text": "do with any summarizes what our goals are well first of all we want to optimize topic coverage and we want to",
    "start": "219310",
    "end": "226300"
  },
  {
    "text": "optimize readability so does the summary incorporate all the main topics from the",
    "start": "226300",
    "end": "231430"
  },
  {
    "text": "document and thus the summary sentence flows in some kind of logical way so can",
    "start": "231430",
    "end": "236860"
  },
  {
    "text": "we actually read it and understand it now there are different types of text",
    "start": "236860",
    "end": "241900"
  },
  {
    "text": "summarization and one of the one way we can look at the different types is based",
    "start": "241900",
    "end": "248350"
  },
  {
    "text": "on the input type so when we think about text summarization or based on the input",
    "start": "248350",
    "end": "253390"
  },
  {
    "text": "type there are two types we have single document or multi document classification basically it's self",
    "start": "253390",
    "end": "258430"
  },
  {
    "text": "explanatory in one way we have only one document that we're trying to summarize in this other one we have multiple",
    "start": "258430",
    "end": "264790"
  },
  {
    "text": "documents and the final summary should contain information from all of these documents now there is also",
    "start": "264790",
    "end": "273380"
  },
  {
    "text": "Division of text summarization based on context and here we have domain-specific",
    "start": "273380",
    "end": "278530"
  },
  {
    "text": "generic and query based summaries so in domain-specific summaries what we are",
    "start": "278530",
    "end": "285110"
  },
  {
    "text": "actually so we are using some domain knowledge so what that means that means that if you have some specific arts on",
    "start": "285110",
    "end": "292070"
  },
  {
    "text": "specific text you're trying to summarize for example you're summarizing the scientific article in biomedicine maybe",
    "start": "292070",
    "end": "298460"
  },
  {
    "text": "you do have enough domain knowledge that you can incorporate in your model so that because as some domain expert in",
    "start": "298460",
    "end": "305180"
  },
  {
    "text": "biomedicine maybe you know which which words could be the most important and which ones are maybe not relevant for",
    "start": "305180",
    "end": "311660"
  },
  {
    "text": "the summarization and you don't want them ending up in the final summary now query-based",
    "start": "311660",
    "end": "316750"
  },
  {
    "text": "here those are the type of summer is when the summaries kind of only contain the information about this that answers",
    "start": "316750",
    "end": "324860"
  },
  {
    "text": "this natural language question you about the text so those are for example those",
    "start": "324860",
    "end": "330050"
  },
  {
    "text": "type of summaries you know when you're like searching for something on Google and then you get research results and those search results are basically the",
    "start": "330050",
    "end": "337070"
  },
  {
    "text": "website for what you're searching for but there is also a little paragraph down underneath it that has actually all",
    "start": "337070",
    "end": "344090"
  },
  {
    "text": "the words that are the most important all the most important sentences from",
    "start": "344090",
    "end": "349490"
  },
  {
    "text": "that website that are actually related to your search query and of course there",
    "start": "349490",
    "end": "354590"
  },
  {
    "text": "are these generic summaries where our model does not make any special assumptions about the domain or about",
    "start": "354590",
    "end": "360290"
  },
  {
    "text": "the type of content of text or the type of information you need to get and the",
    "start": "360290",
    "end": "365330"
  },
  {
    "text": "generic summaries are basically the one where the majority of work has been done",
    "start": "365330",
    "end": "370450"
  },
  {
    "text": "now probably the most important two types of text summarization are actually",
    "start": "370450",
    "end": "377420"
  },
  {
    "text": "based on the output type now those are extractive and abstractive summaries so",
    "start": "377420",
    "end": "384640"
  },
  {
    "text": "extractive summaries are actually summaries where the important sentences are extracted from text so we just look",
    "start": "384640",
    "end": "393380"
  },
  {
    "start": "385000",
    "end": "385000"
  },
  {
    "text": "into the text and then we find the most important sentences of the text and then we extract them and then we actually and",
    "start": "393380",
    "end": "400670"
  },
  {
    "text": "then those sentences are what makes our summary so something like this on the other hand this is",
    "start": "400670",
    "end": "406999"
  },
  {
    "text": "something how our human would actually write summaries right so when we write",
    "start": "406999",
    "end": "412039"
  },
  {
    "text": "summaries we actually read the text and then we if I tell you summarize a book",
    "start": "412039",
    "end": "417289"
  },
  {
    "text": "you will not give me the most important sentences of a book right you will read the book and you're gonna give me a",
    "start": "417289",
    "end": "423049"
  },
  {
    "text": "summary using your own words so you're gonna be using some terms and some words that are not appearing in the original",
    "start": "423049",
    "end": "430489"
  },
  {
    "text": "document so this is what extractive summary this is the difference between extractive and obstructive summaries now",
    "start": "430489",
    "end": "437469"
  },
  {
    "text": "if we try to take a closer look at these things so extractive summaries how they work well as I said we have some text",
    "start": "437469",
    "end": "444860"
  },
  {
    "text": "for example Wikipedia article about Game of Thrones and we want to create a summary of this right so what we do with",
    "start": "444860",
    "end": "451999"
  },
  {
    "text": "extracted summaries as I said already we just select the most important sentences let's say those are these four or three",
    "start": "451999",
    "end": "459259"
  },
  {
    "text": "and a half so you can see here that you know we are extremists of the time in",
    "start": "459259",
    "end": "465229"
  },
  {
    "text": "extracted summaries we are extracting entire sentences so most of the time but",
    "start": "465229",
    "end": "470779"
  },
  {
    "text": "sometimes you would also maybe wanted to extract just piece of sentences that has the most information so for example in",
    "start": "470779",
    "end": "477289"
  },
  {
    "text": "this second sentence I don't think it is important that first book of A Song of",
    "start": "477289",
    "end": "482629"
  },
  {
    "text": "Ice and Fire is actually Game of Thrones so I have ignored that information now",
    "start": "482629",
    "end": "488709"
  },
  {
    "text": "one great thing about this extractive summaries is that you don't really have to worry about grammar because if the",
    "start": "488709",
    "end": "495860"
  },
  {
    "text": "sentence in the original article was grammatically correct and you're just extracting that sentence of course the",
    "start": "495860",
    "end": "501589"
  },
  {
    "text": "sentence is going to be grammatically correct in the summary as well however there could be some issues with",
    "start": "501589",
    "end": "507499"
  },
  {
    "text": "extractive summaries and one of the most important was is the lack of balance",
    "start": "507499",
    "end": "513279"
  },
  {
    "start": "513000",
    "end": "513000"
  },
  {
    "text": "what can happen sometimes with the extracted summaries let's say you have a document that consists of two topics for",
    "start": "513279",
    "end": "520610"
  },
  {
    "text": "example even in this case we have this perverse paragraph that is talking about the production of The Game of Thrones TV",
    "start": "520610",
    "end": "527300"
  },
  {
    "text": "show right where it was filmed how many seasons it had what it was based on who",
    "start": "527300",
    "end": "532699"
  },
  {
    "text": "created it and so on however on this other part we actually have another",
    "start": "532699",
    "end": "537889"
  },
  {
    "text": "completely different topic that is talking about the story okay so what are the story arcs what are the plots in the game of",
    "start": "537889",
    "end": "544820"
  },
  {
    "text": "Thrones so what could happen is that if you are just extracting and most",
    "start": "544820",
    "end": "550160"
  },
  {
    "text": "important sentences you could end up with summary that contains only sentences from the first paragraph and",
    "start": "550160",
    "end": "555710"
  },
  {
    "text": "or only sentences from the second paragraph so and we said that you know",
    "start": "555710",
    "end": "560840"
  },
  {
    "text": "topic coverage is one of the main goals we want to optimize topic coverage and here we're not doing it",
    "start": "560840",
    "end": "566870"
  },
  {
    "text": "so arson in this case our summary is definitely not balanced another problem",
    "start": "566870",
    "end": "573260"
  },
  {
    "text": "that can happen is something that's called lack of cohesion so lack of cohesion actually means this let's say I",
    "start": "573260",
    "end": "580910"
  },
  {
    "start": "576000",
    "end": "576000"
  },
  {
    "text": "have extracted three sentences from this thing so now first one is great we know",
    "start": "580910",
    "end": "587120"
  },
  {
    "text": "what Game of Thrones is second one says that filming location also include Canada Croatia Iceland blah blah now",
    "start": "587120",
    "end": "593870"
  },
  {
    "text": "this okay kind of we can read it we can make sense doesn't make sense because it",
    "start": "593870",
    "end": "599120"
  },
  {
    "text": "says also including so there should be obviously there is part of information missing from before but this third",
    "start": "599120",
    "end": "605180"
  },
  {
    "text": "sentence just by reading Golda's or in sentences makes no sense at all because in one sentence we're talking about will",
    "start": "605180",
    "end": "611900"
  },
  {
    "text": "be filming and then the other one is talking about this ruling dynasty",
    "start": "611900",
    "end": "617000"
  },
  {
    "text": "returning to the throne fears people's creatures from the north and we have no idea what that is all about and this is",
    "start": "617000",
    "end": "624230"
  },
  {
    "text": "one of the most common problems that you can encounter with any kind of extractive text summarization on the",
    "start": "624230",
    "end": "632300"
  },
  {
    "text": "other hand abstractive summary well obstructive summary is much more similar",
    "start": "632300",
    "end": "637610"
  },
  {
    "text": "to the way humans summarize right so when we summarize as I said already we",
    "start": "637610",
    "end": "643130"
  },
  {
    "text": "don't just extract sentences our brain looks differently we create our brain creates this internal semantic",
    "start": "643130",
    "end": "649760"
  },
  {
    "text": "representation of a text that we just read and then we eat from that we",
    "start": "649760",
    "end": "655190"
  },
  {
    "text": "actually generate summary using our own words so this was for example the",
    "start": "655190",
    "end": "660500"
  },
  {
    "text": "summary I created from Game of Thrones article now as you can see here I am",
    "start": "660500",
    "end": "665780"
  },
  {
    "text": "using new words so instead of saying that American that Game of Thrones is American fantasy drama television series",
    "start": "665780",
    "end": "671540"
  },
  {
    "text": "I'm saying it's a TV show right so I'm using the words that are not appearing in the original article now this this is",
    "start": "671540",
    "end": "681379"
  },
  {
    "text": "actually this this abstract summarization is what we would like to accomplish when when we're in the end so",
    "start": "681379",
    "end": "689239"
  },
  {
    "text": "the angle with the automatic test summarization we would like to get something like this right however this",
    "start": "689239",
    "end": "694850"
  },
  {
    "text": "is quite difficult techniques that we have to use for this are quite advanced if we want to do any kind of abstracted",
    "start": "694850",
    "end": "701689"
  },
  {
    "text": "summarization we have to go with some very very advanced deep learning models and even those are not giving us yet at least",
    "start": "701689",
    "end": "708290"
  },
  {
    "text": "like very super-awesome results in all of the scenarios because as you can see",
    "start": "708290",
    "end": "713299"
  },
  {
    "text": "here there is a lot of domain knowledge that we have to have when we're doing abstracted summary so you know for",
    "start": "713299",
    "end": "721129"
  },
  {
    "text": "example here I'm saying that it was filmed across three different continents",
    "start": "721129",
    "end": "727119"
  },
  {
    "text": "now for us that of course sounds like a common sense everyone knows where these countries are however that is in the end",
    "start": "727119",
    "end": "734179"
  },
  {
    "text": "the domain knowledge about geography if I haven't had that knowledge where Morocco is and Canada and so on I",
    "start": "734179",
    "end": "739970"
  },
  {
    "text": "wouldn't have known how to formulate this in the short way so that I can still give you the information about",
    "start": "739970",
    "end": "746449"
  },
  {
    "text": "that there were multiple countries involved so because of that the",
    "start": "746449",
    "end": "753139"
  },
  {
    "text": "extraction methods are still ones that are mostly used even though they do not",
    "start": "753139",
    "end": "759350"
  },
  {
    "text": "work as as we would like it in the end so now we can go through some of the",
    "start": "759350",
    "end": "766489"
  },
  {
    "text": "methods that were used or are used today for automated the automatic text",
    "start": "766489",
    "end": "773689"
  },
  {
    "text": "summarization so first method ever used for automatic text summarization was",
    "start": "773689",
    "end": "780290"
  },
  {
    "text": "something called positional method and positional method was actually introduced in 1959 so 60 years ago so",
    "start": "780290",
    "end": "789199"
  },
  {
    "start": "782000",
    "end": "782000"
  },
  {
    "text": "this is not really a new thing you know people have been researching this for a while and so this Baxendale he published",
    "start": "789199",
    "end": "798199"
  },
  {
    "text": "an article where he was actually analyzing 200 paragraphs from the",
    "start": "798199",
    "end": "804100"
  },
  {
    "text": "scientific documents what trying to find he what he was trying to do is he was trying to okay to the topic",
    "start": "804100",
    "end": "811319"
  },
  {
    "text": "sentences those are the sentences that are most related to the main topic of the article and what he found out after",
    "start": "811319",
    "end": "818970"
  },
  {
    "text": "analyzing these 200 paragraphs is that in 85% of the cases topic sentence was",
    "start": "818970",
    "end": "826170"
  },
  {
    "text": "the first sentence in the paragraph and in the 7 percent of the cases topic sentence was actually the last sentence",
    "start": "826170",
    "end": "832379"
  },
  {
    "text": "in the paragraph so this is basically how the positional method works you have",
    "start": "832379",
    "end": "837809"
  },
  {
    "text": "a paragraph and you just take first sentence and last sentence of the paragraph and you take extract that as",
    "start": "837809",
    "end": "844709"
  },
  {
    "text": "your summary quite simple right so this yes was very simple and very naive",
    "start": "844709",
    "end": "851009"
  },
  {
    "text": "approach but it was actually quite reasonable at least for the for the type",
    "start": "851009",
    "end": "856620"
  },
  {
    "text": "of the documents that he was trying to summarize it turned out that it was actually working just fine and we are",
    "start": "856620",
    "end": "864569"
  },
  {
    "text": "not doing this method anymore however this was the first paper in automatic text summarization and a lot of works",
    "start": "864569",
    "end": "871860"
  },
  {
    "text": "added that followed were actually kind of using this technique as a starting point now the same year in 1959 Lauren",
    "start": "871860",
    "end": "880559"
  },
  {
    "text": "actually came with a little bit more advanced method now what he was walking",
    "start": "880559",
    "end": "886170"
  },
  {
    "start": "881000",
    "end": "881000"
  },
  {
    "text": "into his he was actually introducing the concept called frequency of content terms which basically means frequency of",
    "start": "886170",
    "end": "893189"
  },
  {
    "text": "words right so he analyzed okay how often the words appear in the document",
    "start": "893189",
    "end": "899999"
  },
  {
    "text": "and then this is actually a chart from his original article what he saw is that",
    "start": "899999",
    "end": "905279"
  },
  {
    "text": "he was trying to find significant words and what he saw was that okay those words that appeared the most and those",
    "start": "905279",
    "end": "912809"
  },
  {
    "text": "words that appeared the least in the article are not significant so we can kind of remove them and not worry about",
    "start": "912809",
    "end": "918720"
  },
  {
    "text": "them and the significant words were actually in this interval of in the like",
    "start": "918720",
    "end": "924600"
  },
  {
    "text": "the middle range of the frequencies of the words and he was also the first one",
    "start": "924600",
    "end": "931829"
  },
  {
    "text": "to start with some data pre-processing before doing any kind of automatic summarization so he was removing",
    "start": "931829",
    "end": "939120"
  },
  {
    "text": "supports because if you think about it this most common words that's actually the definition of a stop word and he was",
    "start": "939120",
    "end": "945120"
  },
  {
    "text": "also using stemming so he was dropping off the suffixes of the world in order",
    "start": "945120",
    "end": "951000"
  },
  {
    "text": "to get to the root form of a word so that machine knows that cat and cats are basically the same thing that they're",
    "start": "951000",
    "end": "957420"
  },
  {
    "text": "referring to the same animal so how his method worked well it was",
    "start": "957420",
    "end": "963990"
  },
  {
    "text": "very simple the whole idea was about selecting sentences with highest concentration of salient content terms",
    "start": "963990",
    "end": "970200"
  },
  {
    "text": "which again means just select sentences with most of the important words in them so if we have a sentence that has ten",
    "start": "970200",
    "end": "979260"
  },
  {
    "text": "words and let's say four of them are significant words so four of them are in",
    "start": "979260",
    "end": "984300"
  },
  {
    "text": "that middle range of that chart one idea",
    "start": "984300",
    "end": "989430"
  },
  {
    "text": "here would be okay how to then say how important is this sentence well we could just divide number of significant words",
    "start": "989430",
    "end": "996330"
  },
  {
    "text": "with number of old words so 4/10 which we would say ok score is 0.4 however he",
    "start": "996330",
    "end": "1002150"
  },
  {
    "text": "did something a bit more complex what he did was instead of dividing with the number of all words in the sentence",
    "start": "1002150",
    "end": "1008630"
  },
  {
    "text": "he was actually dividing with the length of the span in which they appear so",
    "start": "1008630",
    "end": "1014000"
  },
  {
    "text": "basically in this case so he was just counting how many words are between",
    "start": "1014000",
    "end": "1019130"
  },
  {
    "text": "first and the last significant word so in this case then he made this formula for the score which was again quite",
    "start": "1019130",
    "end": "1025490"
  },
  {
    "text": "basic so number of all significant words squared divided by number of all words",
    "start": "1025490",
    "end": "1032180"
  },
  {
    "text": "or all words in the spec in the span and as you can see this is actually a very",
    "start": "1032180",
    "end": "1038930"
  },
  {
    "text": "reasonable matrix especially for you-know-who 60 years ago because it",
    "start": "1038930",
    "end": "1044209"
  },
  {
    "text": "does take into consideration two very important things in the document summarization first one being important",
    "start": "1044209",
    "end": "1050660"
  },
  {
    "text": "words and the second one being that they are highly concentrated next to each other because we don't want them to be",
    "start": "1050660",
    "end": "1056060"
  },
  {
    "text": "dispersed all over the document now 10 years later in 1968 Edmondson came up",
    "start": "1056060",
    "end": "1063980"
  },
  {
    "start": "1063000",
    "end": "1063000"
  },
  {
    "text": "with a new method so he was actually using some of the old already mentioned",
    "start": "1063980",
    "end": "1070070"
  },
  {
    "text": "features so he was using position of the sentence in a document the same way as back salad",
    "start": "1070070",
    "end": "1077270"
  },
  {
    "text": "and he was also looking at the word frequency the same as loon but what he",
    "start": "1077270",
    "end": "1082790"
  },
  {
    "text": "added was something called cue words now these key words are manually selected",
    "start": "1082790",
    "end": "1088610"
  },
  {
    "text": "words that are highly correlated with the importance of sentences and there",
    "start": "1088610",
    "end": "1094370"
  },
  {
    "text": "are three types of cue words there are bonus words that are pointing to the important sentence there are stigma",
    "start": "1094370",
    "end": "1101780"
  },
  {
    "text": "words they on the other hand have negative effect on the sentence importance so most likely those are the",
    "start": "1101780",
    "end": "1106910"
  },
  {
    "text": "words that you would expect that machine will treat as important but they're really not and there are also no words",
    "start": "1106910",
    "end": "1113600"
  },
  {
    "text": "which are neutral or irrelevant to the importance of the sentence so they're kind of like a stop words so you can",
    "start": "1113600",
    "end": "1119180"
  },
  {
    "text": "just like ignore them when doing the summarization another thing he was",
    "start": "1119180",
    "end": "1124220"
  },
  {
    "text": "looking into was the document structure so is this sentence our headline is it",
    "start": "1124220",
    "end": "1130640"
  },
  {
    "text": "the title is it the first sentence right under the title and so on and then as the score for each sentence he created",
    "start": "1130640",
    "end": "1137960"
  },
  {
    "text": "some kind of linear combination of these four P features and this is one of the algorithms that is still used and",
    "start": "1137960",
    "end": "1146530"
  },
  {
    "text": "changing these few words actually can change a lot the performance of your Samuraizer so actually if you know that",
    "start": "1146530",
    "end": "1154070"
  },
  {
    "text": "you can select that you have enough domain knowledge to actually select proper keywords here you can get very",
    "start": "1154070",
    "end": "1159620"
  },
  {
    "text": "good results however it does require a lot of domain knowledge in order to do so now the next thing is completely",
    "start": "1159620",
    "end": "1169250"
  },
  {
    "text": "different approach that was done by because this is all more like statistical thing however the completely",
    "start": "1169250",
    "end": "1176450"
  },
  {
    "text": "different approach was done by this room in 1979 he created a program a",
    "start": "1176450",
    "end": "1183350"
  },
  {
    "text": "Samuraizer called from and this was the first knowledge based summarization",
    "start": "1183350",
    "end": "1190460"
  },
  {
    "text": "system it was this template feeling approach so where it's trying to all",
    "start": "1190460",
    "end": "1196520"
  },
  {
    "text": "these template feeling approaches are basically trying to obtain some predefined types of information that is",
    "start": "1196520",
    "end": "1202700"
  },
  {
    "text": "specified in the slots of the template and they're using some kind of information",
    "start": "1202700",
    "end": "1208130"
  },
  {
    "text": "extract extraction methods so each slot in the template represent one part of",
    "start": "1208130",
    "end": "1214430"
  },
  {
    "text": "the salient information that we should take from the text and so he created",
    "start": "1214430",
    "end": "1219860"
  },
  {
    "text": "like this collection of some 50 so-called sketchy scripts and they",
    "start": "1219860",
    "end": "1225440"
  },
  {
    "text": "correspond to the different situation that are often discussed in the news so",
    "start": "1225440",
    "end": "1231370"
  },
  {
    "text": "each of these sketchy scripts then had this kind of like a formula that contained like each of these lines their",
    "start": "1231370",
    "end": "1238190"
  },
  {
    "text": "slots were actually containing important events that we expect to occur in a",
    "start": "1238190",
    "end": "1243620"
  },
  {
    "text": "specific situation and then summarizer tries to read through the article and find those specific situation and fill",
    "start": "1243620",
    "end": "1250910"
  },
  {
    "text": "up the holes in the actual script and so",
    "start": "1250910",
    "end": "1257270"
  },
  {
    "text": "this is for example one of the scripts it was demonstration script and so it goes like it starts with the",
    "start": "1257270",
    "end": "1263780"
  },
  {
    "start": "1258000",
    "end": "1258000"
  },
  {
    "text": "demonstrators arrive at the location they march they arrive police arrives then demonstrators communicate with the",
    "start": "1263780",
    "end": "1270110"
  },
  {
    "text": "target of demonstration then they attack the target then they attack the police and then in the end police arrest them",
    "start": "1270110",
    "end": "1277160"
  },
  {
    "text": "so you can see that this is a fairly specific scenario and when this happens",
    "start": "1277160",
    "end": "1282380"
  },
  {
    "text": "you know in an actual when you have a demonstration well it may happen just",
    "start": "1282380",
    "end": "1287750"
  },
  {
    "text": "like this and then you can actually fill up these holes quite well reading the",
    "start": "1287750",
    "end": "1293600"
  },
  {
    "text": "article however once he tried to evaluate his summarizer he realized that",
    "start": "1293600",
    "end": "1301430"
  },
  {
    "text": "50 scratch scripts are just not enough to cover all the possible topics that you can find in the news so then he so",
    "start": "1301430",
    "end": "1310190"
  },
  {
    "text": "he basically then realized that either he would have to do some more or you know just go with something else now it",
    "start": "1310190",
    "end": "1319520"
  },
  {
    "text": "was basically all in 1995 when people started to use like a proper machine",
    "start": "1319520",
    "end": "1325820"
  },
  {
    "text": "learning techniques for the four automatic text summarization and so",
    "start": "1325820",
    "end": "1334010"
  },
  {
    "start": "1330000",
    "end": "1330000"
  },
  {
    "text": "first one of them was qpm who was actually using the first trainable method",
    "start": "1334010",
    "end": "1340220"
  },
  {
    "text": "so he was trying to use cause he was using classification to create summary now classification is a supervised",
    "start": "1340220",
    "end": "1347149"
  },
  {
    "text": "machine learning problem so in order to do any classification we need to have a good training data set we need to have",
    "start": "1347149",
    "end": "1353149"
  },
  {
    "text": "some label data so what he had this he had a list of about I think it was 180",
    "start": "1353149",
    "end": "1359629"
  },
  {
    "text": "something documents and he also had manually created extracts meaning that",
    "start": "1359629",
    "end": "1365539"
  },
  {
    "text": "he had people select sentences from these articles and then he of course did",
    "start": "1365539",
    "end": "1372350"
  },
  {
    "text": "some data pre-processing and then he was actually tagging each of the sentence labeling it wit so in on one document so",
    "start": "1372350",
    "end": "1379879"
  },
  {
    "text": "each sentence was labeled with one if the sentence ended up in a manually created extract and 0 if that sentence",
    "start": "1379879",
    "end": "1386990"
  },
  {
    "text": "was not there so then he actually created a training dataset that he could use to create a classification model and",
    "start": "1386990",
    "end": "1394070"
  },
  {
    "text": "to make predictions on the new data for that he used naive Bayes classifier",
    "start": "1394070",
    "end": "1399610"
  },
  {
    "text": "which is basically working on the naive on the bias and formula which tells you",
    "start": "1399610",
    "end": "1404690"
  },
  {
    "text": "that the probability that the sentence s belongs to the summary given that it has",
    "start": "1404690",
    "end": "1411379"
  },
  {
    "text": "some set of features is the same as the probability that these features occurs if the sentences in summary times",
    "start": "1411379",
    "end": "1418549"
  },
  {
    "text": "probability that the sentence is a summary divided by the probability that these features are occurred together",
    "start": "1418549",
    "end": "1424519"
  },
  {
    "text": "right and then since here we can actually assume statistical independence",
    "start": "1424519",
    "end": "1430669"
  },
  {
    "text": "of the feature we can make it a little bit less simple so we can actually see",
    "start": "1430669",
    "end": "1435679"
  },
  {
    "text": "here that what it really says is that probability that some that sentence ends",
    "start": "1435679",
    "end": "1441019"
  },
  {
    "text": "up in a summary given certain set of features is basically the product of the probability of the individual features",
    "start": "1441019",
    "end": "1447909"
  },
  {
    "text": "that appear for the sentences that appear in the summary and his model was",
    "start": "1447909",
    "end": "1455240"
  },
  {
    "text": "actually performing quite well so for he was taking 25 percent extracts and he",
    "start": "1455240",
    "end": "1461929"
  },
  {
    "text": "was getting a precision of 84 and for smaller summaries he even got a 74%",
    "start": "1461929",
    "end": "1467860"
  },
  {
    "text": "improvement over elite summaries where lis summaries are the summaries where you just extract first couple of",
    "start": "1467860",
    "end": "1473690"
  },
  {
    "text": "sentence is from the text and this was a method that was used quite long it was giving",
    "start": "1473690",
    "end": "1480719"
  },
  {
    "text": "okay results however in 2002 Miles Osbourne actually published a paper",
    "start": "1480719",
    "end": "1486809"
  },
  {
    "text": "where he showed that there could be better models for classification of",
    "start": "1486809",
    "end": "1493289"
  },
  {
    "text": "these sentences then naive bias so he actually saw that these maximum entropy models are performing better because he",
    "start": "1493289",
    "end": "1501119"
  },
  {
    "text": "actually he realized that those features are not really independent like so the",
    "start": "1501119",
    "end": "1506939"
  },
  {
    "text": "the probability that you know the position of the sentence maybe and the number of stop words in the sentence and",
    "start": "1506939",
    "end": "1513329"
  },
  {
    "text": "all the different features you can use most likely are not independent with one another so then we can use other",
    "start": "1513329",
    "end": "1519059"
  },
  {
    "text": "approaches now one of the problems that",
    "start": "1519059",
    "end": "1524699"
  },
  {
    "text": "can happen when you're working with the text summarization is that what if you",
    "start": "1524699",
    "end": "1531449"
  },
  {
    "text": "have is especially when you're working with the text summarization from different documents what if you have the",
    "start": "1531449",
    "end": "1537539"
  },
  {
    "text": "sentences that are talking more or less about the same thing in that case if",
    "start": "1537539",
    "end": "1543749"
  },
  {
    "text": "those sentences contain some very they both are gonna contain a lot of information and they're gonna both get",
    "start": "1543749",
    "end": "1549959"
  },
  {
    "text": "high score based on any kind of metrics you're using so what happens then and in 1998 there was a metrics called maximum",
    "start": "1549959",
    "end": "1560249"
  },
  {
    "start": "1556000",
    "end": "1556000"
  },
  {
    "text": "marginal reference that was introduced now this one was used for query based summaries so but there are other methods",
    "start": "1560249",
    "end": "1567599"
  },
  {
    "text": "very similar to this one that re then you can use for generic summaries and so on however this was one of the first",
    "start": "1567599",
    "end": "1573509"
  },
  {
    "text": "methods and what it actually says here how the this method actually works is",
    "start": "1573509",
    "end": "1580889"
  },
  {
    "text": "that we have so we have a user query and we also have some kind of similarity",
    "start": "1580889",
    "end": "1588149"
  },
  {
    "text": "metrics which we defined ourselves and then the what we want actually so here",
    "start": "1588149",
    "end": "1594479"
  },
  {
    "text": "we're taking into consideration both how similar the sentence or the document you",
    "start": "1594479",
    "end": "1600569"
  },
  {
    "text": "know this is also for the information retrieval documents the same thing so how similar is the sentence to the",
    "start": "1600569",
    "end": "1606809"
  },
  {
    "text": "actual query but also we're taking into consideration okay how similar is the sentence to the",
    "start": "1606809",
    "end": "1613600"
  },
  {
    "text": "sentences that were already extracted to the summary because if we have two",
    "start": "1613600",
    "end": "1618879"
  },
  {
    "text": "sentences that are you know more or less of the same importance and more or less talking about the same thing then if I",
    "start": "1618879",
    "end": "1624850"
  },
  {
    "text": "give you to read first sentence and then I give you the read second sentence then marginal value of the second sentence is",
    "start": "1624850",
    "end": "1630879"
  },
  {
    "text": "actually very low because you already have that information so instead of that we want some sentence that maybe has a",
    "start": "1630879",
    "end": "1636340"
  },
  {
    "text": "higher lower well value but is still contributing with the information to the",
    "start": "1636340",
    "end": "1642159"
  },
  {
    "text": "actual summary okay so one other",
    "start": "1642159",
    "end": "1649749"
  },
  {
    "text": "approach was meat which was introduced in 2000 in 2000 and this was actually",
    "start": "1649749",
    "end": "1655389"
  },
  {
    "text": "our centroid based method so it was working both for single and multi",
    "start": "1655389",
    "end": "1662830"
  },
  {
    "text": "documents so how this method works basically we let's say we have some",
    "start": "1662830",
    "end": "1669989"
  },
  {
    "text": "sentences again from the different documents and then we represent these",
    "start": "1669989",
    "end": "1675759"
  },
  {
    "text": "sentences in some vector space as dots in some vector space okay so now one",
    "start": "1675759",
    "end": "1682749"
  },
  {
    "text": "thing first thing we want to do is we want to cluster them into some topics so here we can see that we kind of have two",
    "start": "1682749",
    "end": "1687940"
  },
  {
    "text": "clusters of sentences talking probably about two different topics and what we",
    "start": "1687940",
    "end": "1693840"
  },
  {
    "text": "first try to find is these centroids so centroids are centers of the mass of",
    "start": "1693840",
    "end": "1700440"
  },
  {
    "text": "individual clusters so these are our centroids and then we actually select",
    "start": "1700440",
    "end": "1708399"
  },
  {
    "text": "the sentences that are the closest to the Centers of the topic and of course",
    "start": "1708399",
    "end": "1714489"
  },
  {
    "text": "in this case again especially for dealing with multi document summarization there is that problem that",
    "start": "1714489",
    "end": "1721899"
  },
  {
    "text": "we mentioned before now about maybe we'll get the two of the same sentences so again here we are going to be doing",
    "start": "1721899",
    "end": "1728470"
  },
  {
    "text": "some rewriting methods using summary ranking matrix to actually select the sentences that are the closest to the",
    "start": "1728470",
    "end": "1735820"
  },
  {
    "text": "centroids but also different from one another",
    "start": "1735820",
    "end": "1740758"
  },
  {
    "text": "now there has also been a lot of these graph based methods throughout the years",
    "start": "1740900",
    "end": "1746410"
  },
  {
    "text": "and one of them is a method called lacks rank so this is a graph based method",
    "start": "1746410",
    "end": "1754010"
  },
  {
    "text": "that was introduced in 2004 and the whole idea behind it is something called",
    "start": "1754010",
    "end": "1760100"
  },
  {
    "text": "lexical centrality so how this method works well so we have some document or",
    "start": "1760100",
    "end": "1768190"
  },
  {
    "text": "multiple amount of documents and then we create something called similarity",
    "start": "1768190",
    "end": "1773210"
  },
  {
    "text": "matrix where basically we are looking into okay how similar are each two sentences in the document or in the",
    "start": "1773210",
    "end": "1779210"
  },
  {
    "text": "corpus of documents to one another and then we actually represent each",
    "start": "1779210",
    "end": "1788720"
  },
  {
    "text": "sentences as the nodes in the graph and then we're looking into okay which sentences are connected so because then",
    "start": "1788720",
    "end": "1798020"
  },
  {
    "text": "if the sentences have a lot of similarity a lot of for example similar words or something then they're going to",
    "start": "1798020",
    "end": "1804650"
  },
  {
    "text": "have a high value in the similarity graph so this is an example from the",
    "start": "1804650",
    "end": "1810860"
  },
  {
    "text": "original article and so here we have 11 sentences from five different documents",
    "start": "1810860",
    "end": "1818090"
  },
  {
    "text": "that are talking about the same thing right so and about the same event so",
    "start": "1818090",
    "end": "1826160"
  },
  {
    "text": "here for example D 2 s 3 means this is the third sentence from the second document so as I said we start with",
    "start": "1826160",
    "end": "1836090"
  },
  {
    "text": "building this similarity matrix and now this similarity can be either cosine",
    "start": "1836090",
    "end": "1841760"
  },
  {
    "text": "similarity Jaccard similarity whatever similarity you you decided to use so we look into ok how similar are our",
    "start": "1841760",
    "end": "1848300"
  },
  {
    "text": "sentences so obviously all the elements at the diagonal here one because they're",
    "start": "1848300",
    "end": "1853580"
  },
  {
    "text": "citizen one are the same but we are also very interested in those sentences where",
    "start": "1853580",
    "end": "1859760"
  },
  {
    "text": "these similarities are as high as possible so now we represent each",
    "start": "1859760",
    "end": "1866060"
  },
  {
    "text": "sentence as a node and then we are looking into okay are they connected and how are they connected and",
    "start": "1866060",
    "end": "1872509"
  },
  {
    "text": "we actually look into different thresholds so the sentence is d 5 s 1",
    "start": "1872509",
    "end": "1880459"
  },
  {
    "text": "and D 5 s 3 they have this really thick black line so the same as D 1 s 1 and D",
    "start": "1880459",
    "end": "1888229"
  },
  {
    "text": "2 s 1 so those are the two sentences that in our similarity matrix actually",
    "start": "1888229",
    "end": "1894320"
  },
  {
    "text": "have the highest cord so the they have 0.45 and 0.38 so this",
    "start": "1894320",
    "end": "1901159"
  },
  {
    "text": "is what happens so these two are basically the only Connection we have if we put a threshold to 0.3 now the more",
    "start": "1901159",
    "end": "1908479"
  },
  {
    "text": "we're lowering the threshold as you can see here the more connections we get so",
    "start": "1908479",
    "end": "1913609"
  },
  {
    "text": "the main idea is basically to have if the sentence is connected to many of the",
    "start": "1913609",
    "end": "1919249"
  },
  {
    "text": "sentences that means that one sentence is similar to many of the sentences that is one of the sentence that we should",
    "start": "1919249",
    "end": "1924889"
  },
  {
    "text": "consider to put into our final summary and so basically the whole idea about",
    "start": "1924889",
    "end": "1933589"
  },
  {
    "text": "this is that kind of one sentence recommends the other similar sentences to the reader so if so if it's very",
    "start": "1933589",
    "end": "1941509"
  },
  {
    "text": "similar it would be of great importance but also importance of the sentence is coming from the importance of the",
    "start": "1941509",
    "end": "1948379"
  },
  {
    "text": "sentences that are recommending it so this does sound a lot like a PageRank",
    "start": "1948379",
    "end": "1954169"
  },
  {
    "text": "algorithm that's used by Google and it is working on the same principle and",
    "start": "1954169",
    "end": "1959719"
  },
  {
    "text": "there is also another very very similar method called text rank and it's working",
    "start": "1959719",
    "end": "1965389"
  },
  {
    "text": "more or less the same there were just two different methods that were created approximately at the same time but two",
    "start": "1965389",
    "end": "1971779"
  },
  {
    "text": "different groups of people and they have small differences for example text rank",
    "start": "1971779",
    "end": "1976999"
  },
  {
    "text": "is used mostly for single document summarization while x rank is used mostly for multi document summarization",
    "start": "1976999",
    "end": "1984669"
  },
  {
    "text": "also the similarity matrix used for the similarity made matrix are slightly",
    "start": "1984669",
    "end": "1990019"
  },
  {
    "text": "different but in the end it is the same approach and the same formula now if you",
    "start": "1990019",
    "end": "1999440"
  },
  {
    "text": "remember so far we were I mean we're mostly talking about extractive packs",
    "start": "1999440",
    "end": "2005049"
  },
  {
    "text": "some summarization method and as I said you know we will be focusing on this more because they are easier and we did have",
    "start": "2005049",
    "end": "2012870"
  },
  {
    "text": "a little bit of kind of obstructive method because with from because from foes like a slot filling knowledge-based",
    "start": "2012870",
    "end": "2021049"
  },
  {
    "text": "summarizer and you know by the definition of obstructive Samuraizer from was",
    "start": "2021049",
    "end": "2026549"
  },
  {
    "text": "extractive because it was the final summarizer was actually using the words that don't appear in the original",
    "start": "2026549",
    "end": "2033269"
  },
  {
    "text": "document and those were the words that were like between those slots that were needed to fill so it was kind of very",
    "start": "2033269",
    "end": "2040169"
  },
  {
    "text": "basic type of abstractive Samuraizer however most of these abstract",
    "start": "2040169",
    "end": "2046590"
  },
  {
    "text": "summarizes are quite complex and in order to do them in order to actually",
    "start": "2046590",
    "end": "2052589"
  },
  {
    "text": "work with them what we need is we need some deep learning knowledge right so",
    "start": "2052589",
    "end": "2058919"
  },
  {
    "text": "the the most commonly used method for obstructive text summarization is the",
    "start": "2058919",
    "end": "2064138"
  },
  {
    "text": "sequence to sequence method which is a deep learning technique that was introduced by Google team in 2014 so it",
    "start": "2064139",
    "end": "2073770"
  },
  {
    "text": "is called sequence to sequence because it takes sequence as an output and it",
    "start": "2073770",
    "end": "2079858"
  },
  {
    "text": "also has a text sequence is an input and it also giving us sequence as an output",
    "start": "2079859",
    "end": "2085980"
  },
  {
    "text": "and this is what we need for working with you know text data because text is",
    "start": "2085980",
    "end": "2091200"
  },
  {
    "start": "2088000",
    "end": "2088000"
  },
  {
    "text": "actually nothing but a sequence of words and one of the important thing in the sequence is it's super important to know",
    "start": "2091200",
    "end": "2097230"
  },
  {
    "text": "where things are where words are so the word what word 2ds depending on the word",
    "start": "2097230",
    "end": "2103980"
  },
  {
    "text": "one when we're making a sentence as humans and we want the same thing from",
    "start": "2103980",
    "end": "2108990"
  },
  {
    "text": "the machines so just a quick overview of",
    "start": "2108990",
    "end": "2114119"
  },
  {
    "text": "how this goes I will not go into details here but basically here we have an",
    "start": "2114119",
    "end": "2120060"
  },
  {
    "text": "original document so each of these inputs are just set words in our",
    "start": "2120060",
    "end": "2125730"
  },
  {
    "text": "original document so we put that as an input in our model now the model itself",
    "start": "2125730",
    "end": "2130950"
  },
  {
    "text": "consists of three parts first we have an encoder part then we have some middle",
    "start": "2130950",
    "end": "2136140"
  },
  {
    "text": "part called encoder vector and then we have the decoder part so first we're in coding and then we have to decode what we",
    "start": "2136140",
    "end": "2142500"
  },
  {
    "text": "encode it in the previous step so this encoder part that's basically first one",
    "start": "2142500",
    "end": "2150780"
  },
  {
    "text": "is basically a stack of several recurrent units that are that each each",
    "start": "2150780",
    "end": "2159780"
  },
  {
    "text": "of them accepts one element one input element so one word and then what this",
    "start": "2159780",
    "end": "2166470"
  },
  {
    "text": "then each of them actually collects information for its input from its input so from one word and then propagates it",
    "start": "2166470",
    "end": "2173670"
  },
  {
    "text": "further on to the next recurrent unit the the output of this encoder part is",
    "start": "2173670",
    "end": "2181530"
  },
  {
    "text": "actually the encoder vector now we can treat we can think of this encoder vector as being like the last hidden",
    "start": "2181530",
    "end": "2186720"
  },
  {
    "text": "state of the encoder part of the model now encoder vector itself basically it",
    "start": "2186720",
    "end": "2192990"
  },
  {
    "text": "aims to encapsulate all the information for all the input elements in order to",
    "start": "2192990",
    "end": "2199650"
  },
  {
    "text": "help the decoder make accurate predictions and create the final summary and encoder vector is then also acting",
    "start": "2199650",
    "end": "2209640"
  },
  {
    "text": "as the first hidden layer first first hidden state of this decoder part of the",
    "start": "2209640",
    "end": "2216450"
  },
  {
    "text": "model now the coder network well that's again here we have again several neural",
    "start": "2216450",
    "end": "2225260"
  },
  {
    "text": "neural dis these recurrent units and each of them is actually predicting one",
    "start": "2225260",
    "end": "2232320"
  },
  {
    "text": "part of the output and then it also propagates the knowledge to the next",
    "start": "2232320",
    "end": "2238320"
  },
  {
    "text": "recurrent unit and what you can see here is that okay so first this first recurrent unit is going to create output",
    "start": "2238320",
    "end": "2244800"
  },
  {
    "text": "one and then what goes into the second one will be some you know hidden state",
    "start": "2244800",
    "end": "2251670"
  },
  {
    "text": "from the recurrent unit but also we're taking into consideration the output one when we're doing dealing when you're",
    "start": "2251670",
    "end": "2258420"
  },
  {
    "text": "trying to predict output two and that is because you know once what is going to be the second so a word in a sentence",
    "start": "2258420",
    "end": "2265830"
  },
  {
    "text": "depends on what is the first word in the sentence and in the end finally we get our summary so",
    "start": "2265830",
    "end": "2272880"
  },
  {
    "text": "this is just a quick overview of the sequence the sequence method there's much more going on out here but it is and you know this is not the",
    "start": "2272880",
    "end": "2280320"
  },
  {
    "text": "only thing only way you can do the automatic abstractive summarization there are other methods and you can also",
    "start": "2280320",
    "end": "2287070"
  },
  {
    "text": "use the reinforcement learning and all kind of different things so this is an area that's improving everyday so new",
    "start": "2287070",
    "end": "2293850"
  },
  {
    "text": "algorithms are coming and I'm pretty sure it's gonna get much much better with time now the last part of this talk",
    "start": "2293850",
    "end": "2304410"
  },
  {
    "text": "is about evaluation so now we know how to create these summaries but are they",
    "start": "2304410",
    "end": "2310500"
  },
  {
    "text": "good how how good they are basically so what makes a good summary so as I said before",
    "start": "2310500",
    "end": "2316980"
  },
  {
    "start": "2314000",
    "end": "2314000"
  },
  {
    "text": "we have two goals with summaries we want to optimize the topic coverage and we want to optimize readability and we can",
    "start": "2316980",
    "end": "2324480"
  },
  {
    "text": "look into different evaluation criteria for this so for example one of them being salience are we capturing the",
    "start": "2324480",
    "end": "2330600"
  },
  {
    "text": "salient the most important information of the document length is the summary of a proper length is it we don't want it",
    "start": "2330600",
    "end": "2337080"
  },
  {
    "text": "to be too short we don't want it to be too long what about the structure is structured well is it coherent can we",
    "start": "2337080",
    "end": "2343890"
  },
  {
    "text": "actually read it are there some weird pronouns that are happening or referring to the other things is it balanced are we covering",
    "start": "2343890",
    "end": "2352140"
  },
  {
    "text": "all the topics from the original document what about the grammar is it grammatically correct and also is it non",
    "start": "2352140",
    "end": "2359580"
  },
  {
    "text": "redundant are there still may be some parts of the samurai summary that we could exclude and still get the complete",
    "start": "2359580",
    "end": "2365910"
  },
  {
    "text": "information and now one of the things we would like to see here is we want to",
    "start": "2365910",
    "end": "2372300"
  },
  {
    "text": "optimize this information content basically what we want is to optimize the compression and retention ratio",
    "start": "2372300",
    "end": "2378450"
  },
  {
    "text": "where compression ratio is just telling us okay what is the percentage of the original document that ended up in the",
    "start": "2378450",
    "end": "2385500"
  },
  {
    "text": "summary and retention ratio is telling us okay what is the percentage of",
    "start": "2385500",
    "end": "2390590"
  },
  {
    "text": "information of the original document that was preserved in the summary and so",
    "start": "2390590",
    "end": "2396810"
  },
  {
    "text": "obviously we want to say as much as possible in the shortest amount of time",
    "start": "2396810",
    "end": "2402120"
  },
  {
    "text": "so obviously we want to have very low compare high-compression arey a very low",
    "start": "2402120",
    "end": "2407619"
  },
  {
    "text": "compression ratio and very high retention ratio so we want to have as much information possible in the",
    "start": "2407619",
    "end": "2413890"
  },
  {
    "text": "shortest amount in the shortest number of words now there are two different",
    "start": "2413890",
    "end": "2419440"
  },
  {
    "text": "methods to evaluate these models actrice",
    "start": "2419440",
    "end": "2424930"
  },
  {
    "start": "2421000",
    "end": "2421000"
  },
  {
    "text": "clinics those are the ones that are task based and those are probably the better",
    "start": "2424930",
    "end": "2430720"
  },
  {
    "text": "ones to actually evaluate the models however they do require a lot of manual work so how they work can you have a",
    "start": "2430720",
    "end": "2437529"
  },
  {
    "text": "group of users and you divide their users into two groups one group you give",
    "start": "2437529",
    "end": "2442900"
  },
  {
    "text": "a complete document other group you give a summary and you give them some tasks maybe they can classify these documents",
    "start": "2442900",
    "end": "2449529"
  },
  {
    "text": "into a set of predefined classes maybe they can try to cluster these documents maybe they can try to maybe you can ask",
    "start": "2449529",
    "end": "2456250"
  },
  {
    "text": "them some questions about information in documents so they have to retrieve that information from the text now if the",
    "start": "2456250",
    "end": "2462190"
  },
  {
    "text": "group that has only read the summary can actually make the same decision and and",
    "start": "2462190",
    "end": "2468880"
  },
  {
    "text": "have the same results in this task as the group who has read the whole document then you know that your",
    "start": "2468880",
    "end": "2474069"
  },
  {
    "text": "summaries are good because then somebody can actually just read the summary and get the whole information however that",
    "start": "2474069",
    "end": "2481240"
  },
  {
    "text": "does require a lot of time and a lot of people to actually be part of your little experiment so usually we are not",
    "start": "2481240",
    "end": "2487420"
  },
  {
    "text": "doing that we're focusing on some intricate techniques that are basically about comparing summaries against golden",
    "start": "2487420",
    "end": "2493900"
  },
  {
    "text": "standards so you have a summary created by a human and now and then you create",
    "start": "2493900",
    "end": "2499180"
  },
  {
    "text": "the automatic summary from the same text and then you compare okay how similar they are how similar our automatic",
    "start": "2499180",
    "end": "2506440"
  },
  {
    "text": "summary summary is to the ideal summary made by human so there are different",
    "start": "2506440",
    "end": "2512849"
  },
  {
    "text": "approaches to how to actually but",
    "start": "2512849",
    "end": "2518500"
  },
  {
    "start": "2517000",
    "end": "2517000"
  },
  {
    "text": "different metrics to calculate how good our summaries are one of the basic ones is precision and recall now if you've",
    "start": "2518500",
    "end": "2526390"
  },
  {
    "text": "been working with any machine learning you've heard about these terms so let's say we have a document that has ten",
    "start": "2526390",
    "end": "2534250"
  },
  {
    "text": "sentences and we are only trying to and we say okay we want to extract two sentences out of it",
    "start": "2534250",
    "end": "2540940"
  },
  {
    "text": "and we create an ideal human based summary that's selecting sentence number one and two now if we have two different",
    "start": "2540940",
    "end": "2547900"
  },
  {
    "text": "summarize errs let's say one automatic summer is a one using one method and maybe a samurai's of to using other",
    "start": "2547900",
    "end": "2554020"
  },
  {
    "text": "method so we want to say okay which one of them is better now what we can do is",
    "start": "2554020",
    "end": "2559150"
  },
  {
    "text": "we can create something that's called confusion matrix now confusion matrix is looking into all the different pairs of",
    "start": "2559150",
    "end": "2565000"
  },
  {
    "text": "what can happen has the when machine selected sentence and human not and so",
    "start": "2565000",
    "end": "2570670"
  },
  {
    "text": "on so this is what our confusion matrix basically looks like so the true positives in this matrix well that's",
    "start": "2570670",
    "end": "2577450"
  },
  {
    "text": "basically just the number of sentences that both human and summarize have selected true negatives are basically",
    "start": "2577450",
    "end": "2585280"
  },
  {
    "text": "those sentences that both human and summarizer did not select into into the summarizer",
    "start": "2585280",
    "end": "2592830"
  },
  {
    "text": "and then for example false negatives those are the ones that our machine did",
    "start": "2592830",
    "end": "2598360"
  },
  {
    "text": "not select but human actually selected so those are the ones that we said are",
    "start": "2598360",
    "end": "2603820"
  },
  {
    "text": "negative but they should be actually positive and so on and for this we can",
    "start": "2603820",
    "end": "2609310"
  },
  {
    "text": "actually make two different match matrix called precision and recall precision is",
    "start": "2609310",
    "end": "2615340"
  },
  {
    "text": "basically number of true positives divided by number of false positives and true positives so now what this means so",
    "start": "2615340",
    "end": "2622990"
  },
  {
    "text": "false positives and true positives those are all the sentences that machine things should go into the summary so",
    "start": "2622990",
    "end": "2630420"
  },
  {
    "text": "what this measure tells us is out of all the sentences that machine selected how",
    "start": "2630420",
    "end": "2636340"
  },
  {
    "text": "many of them are actually correctly selected how many of them humans selected as well another method another",
    "start": "2636340",
    "end": "2643300"
  },
  {
    "text": "measure is recall and recall tells us on the other hand okay so here we have true",
    "start": "2643300",
    "end": "2648910"
  },
  {
    "text": "positives plus false negatives so this is out of all the sentences that humans",
    "start": "2648910",
    "end": "2655270"
  },
  {
    "text": "selected how many of them has machines selected as well so in our case in this case of this Samuraizer let's look into",
    "start": "2655270",
    "end": "2662560"
  },
  {
    "text": "some Samuraizer one obviously has a perfect score so it has two true",
    "start": "2662560",
    "end": "2668140"
  },
  {
    "text": "positives and divided by two so the score is one both precision Eric all can go between zero and one and we",
    "start": "2668140",
    "end": "2674240"
  },
  {
    "text": "want to have them as high as possible so since the summarizer one exactly extracted the same things as human",
    "start": "2674240",
    "end": "2680860"
  },
  {
    "text": "obviously that's a very good Samuraizer however summarizer too well true positives is one and false positive",
    "start": "2680860",
    "end": "2688160"
  },
  {
    "text": "passed through positive is two so here we have 0.5 and the same for recall so",
    "start": "2688160",
    "end": "2693560"
  },
  {
    "text": "it was only able to capture one sentence that out of two that human did so in",
    "start": "2693560",
    "end": "2699350"
  },
  {
    "text": "this case we would definitely say okay Samuraizer one is working much much better than the summarizer two however",
    "start": "2699350",
    "end": "2706000"
  },
  {
    "text": "what is an ideal summary what if we had two sentences that were talking about",
    "start": "2706000",
    "end": "2712730"
  },
  {
    "text": "the same thing and they were very similar and even human had to struggle",
    "start": "2712730",
    "end": "2718940"
  },
  {
    "text": "okay maybe the sentence - and sentence for our super similar giving the same information and even human didn't ok",
    "start": "2718940",
    "end": "2724940"
  },
  {
    "text": "should I go select sentence two or four so human decides okay I'm gonna go with sentence two and then when creating this",
    "start": "2724940",
    "end": "2731480"
  },
  {
    "text": "summarizes we had maybe a different reread a ranking may may like make matrix so that we could then maybe",
    "start": "2731480",
    "end": "2738500"
  },
  {
    "text": "summarizer one beaker based on the metrics select a sentence two and summarize our two selected sentence for",
    "start": "2738500",
    "end": "2744970"
  },
  {
    "text": "so that's why may be a better method than precision recall is called utility",
    "start": "2744970",
    "end": "2750350"
  },
  {
    "start": "2750000",
    "end": "2750000"
  },
  {
    "text": "so how utility works is that instead of just having these so just having people",
    "start": "2750350",
    "end": "2762170"
  },
  {
    "text": "select the what are the two most",
    "start": "2762170",
    "end": "2767300"
  },
  {
    "text": "important sentences we also want them to rank those sentences as well so we want",
    "start": "2767300",
    "end": "2772490"
  },
  {
    "text": "them to say okay what is the most important sentence and then the second most important so give all our sentences",
    "start": "2772490",
    "end": "2777920"
  },
  {
    "text": "some points so let's say that then human have this ranking for these five",
    "start": "2777920",
    "end": "2783740"
  },
  {
    "text": "sentences so human says okay sentence number one is the most important so",
    "start": "2783740",
    "end": "2789170"
  },
  {
    "text": "obviously is going to get number ten points now sentence number two gets nine points but sentence number four actually",
    "start": "2789170",
    "end": "2795920"
  },
  {
    "text": "gets eight points right they're very similar and we maybe we could do go so",
    "start": "2795920",
    "end": "2801200"
  },
  {
    "text": "go the other way maybe it's another human would do the other way did this opposite now in this case summarizer one actually he",
    "start": "2801200",
    "end": "2810320"
  },
  {
    "text": "gets 19 points because some reason one selected first and second sentence so",
    "start": "2810320",
    "end": "2816560"
  },
  {
    "text": "first sentence ten plus second sentence nine and summarize are two in this case",
    "start": "2816560",
    "end": "2821840"
  },
  {
    "text": "well it gets 18 points because it select a sentence of a ten points and sentence",
    "start": "2821840",
    "end": "2827690"
  },
  {
    "text": "of eight points now you can see that okay Samuraizer one is still performing",
    "start": "2827690",
    "end": "2832790"
  },
  {
    "text": "better however it's not that big of a difference right because last time we had from 0.5 to one that was a huge",
    "start": "2832790",
    "end": "2839870"
  },
  {
    "text": "difference in precision and recall over here well it's just one point difference so even if we go with Samuraizer - well",
    "start": "2839870",
    "end": "2847070"
  },
  {
    "text": "it won't be that big of a deal right is still very very similar now another",
    "start": "2847070",
    "end": "2853880"
  },
  {
    "text": "problem is that you know who says what's the ideal summary I was working on the",
    "start": "2853880",
    "end": "2861920"
  },
  {
    "text": "project where I was supposed to extract I was supposed to create this extractive summarization and I needed to evaluate",
    "start": "2861920",
    "end": "2870500"
  },
  {
    "text": "my Samuraizer as well and then I asked couple of my colleagues if they can help me with that so if I can because I",
    "start": "2870500",
    "end": "2877580"
  },
  {
    "text": "needed this ideal summary so that I can compare with my models and I asked for",
    "start": "2877580",
    "end": "2884240"
  },
  {
    "text": "colleagues I gave them five different articles to read and to extract and sentences sometimes five sometimes ten",
    "start": "2884240",
    "end": "2891620"
  },
  {
    "text": "doesn't matter and once they get the results back well first of all you know",
    "start": "2891620",
    "end": "2896780"
  },
  {
    "text": "I said like for one article give me five sentences and then half of them gives me six four and so on so machine at least",
    "start": "2896780",
    "end": "2904850"
  },
  {
    "text": "gives you the numbered sentences you want right unlike humans but other problem was that once I was comparing",
    "start": "2904850",
    "end": "2911780"
  },
  {
    "text": "the results from them there was not a single article where two humans out of",
    "start": "2911780",
    "end": "2917840"
  },
  {
    "text": "four gave me the exact same sentence is not a single one so sometimes I had a bit of overlap but sometimes actually",
    "start": "2917840",
    "end": "2924920"
  },
  {
    "text": "have two people same article completely different ten sentences and these were small articles these were not like books",
    "start": "2924920",
    "end": "2931010"
  },
  {
    "text": "you know so you can kind of randomly pick you know ten sentences so it was it was really crazy how people consider",
    "start": "2931010",
    "end": "2937420"
  },
  {
    "text": "differently information and happen was this you know through the articles some information was mentioning",
    "start": "2937420",
    "end": "2943650"
  },
  {
    "text": "more than once and then one person selects first time and the other person selects it when it appears second time",
    "start": "2943650",
    "end": "2949140"
  },
  {
    "text": "and so on and so there is actually a major correlative utility that is also",
    "start": "2949140",
    "end": "2954299"
  },
  {
    "text": "taking this into consideration so not only looking into one ideal summary but",
    "start": "2954299",
    "end": "2960119"
  },
  {
    "text": "also looking into taking more summaries from different people and trying to",
    "start": "2960119",
    "end": "2966029"
  },
  {
    "text": "compare them all and see okay how does our summary actually work - given this whole set of summaries and rush n is",
    "start": "2966029",
    "end": "2975449"
  },
  {
    "text": "actually the method that is like the matrix that is also incorporating this",
    "start": "2975449",
    "end": "2980819"
  },
  {
    "text": "and this is probably the most important matrix for evaluation of the automatic",
    "start": "2980819",
    "end": "2987719"
  },
  {
    "text": "summaries it is based on another matrix called blue which is used in machine",
    "start": "2987719",
    "end": "2992819"
  },
  {
    "text": "translation now the difference between the two of them is that you will get a",
    "start": "2992819",
    "end": "2998190"
  },
  {
    "text": "very high blue results if you actually have a high precision so if your",
    "start": "2998190",
    "end": "3005660"
  },
  {
    "text": "summarises have high position then you will get high blue however on the other hand if you have a high recall you are",
    "start": "3005660",
    "end": "3013160"
  },
  {
    "text": "gonna get the high root results and the high results are the what what we want so actually in Rouge are Irish and our R",
    "start": "3013160",
    "end": "3020359"
  },
  {
    "text": "stands for recall so how does this method works well it is actually comparing the",
    "start": "3020359",
    "end": "3028459"
  },
  {
    "text": "automatic summary but in this case with a set of reference summaries so not just",
    "start": "3028459",
    "end": "3033829"
  },
  {
    "text": "one and what is using its using the Engram overlap between the documents so",
    "start": "3033829",
    "end": "3039109"
  },
  {
    "text": "Engram is basically just sets of words so one gram is one word two gram is two words three gram three words and so on",
    "start": "3039109",
    "end": "3046539"
  },
  {
    "text": "so this is what actually gives us then the the ability to see okay how is this",
    "start": "3046539",
    "end": "3052640"
  },
  {
    "text": "working given the whole corpus of different summaries created by different people",
    "start": "3052640",
    "end": "3059109"
  },
  {
    "text": "and this is the formula for this and basically it's it's very simple so it's",
    "start": "3059109",
    "end": "3064430"
  },
  {
    "text": "just a number of these engrams that are appearing in both our automated summary",
    "start": "3064430",
    "end": "3072859"
  },
  {
    "text": "and in all these summaries that were created by humans divided by a number of engrams",
    "start": "3072859",
    "end": "3078650"
  },
  {
    "text": "that are appearing in all these summaries that were created by in all these reference summaries and there are",
    "start": "3078650",
    "end": "3085880"
  },
  {
    "text": "other there are other rouge methods so for example rouge L which instead of",
    "start": "3085880",
    "end": "3091160"
  },
  {
    "text": "this Engram over like e overlap is looking into the longest common sequence",
    "start": "3091160",
    "end": "3096400"
  },
  {
    "text": "between the automatic summary and between the these different manual",
    "start": "3096400",
    "end": "3101930"
  },
  {
    "text": "summaries and many more another method",
    "start": "3101930",
    "end": "3107020"
  },
  {
    "start": "3107000",
    "end": "3107000"
  },
  {
    "text": "the last one I will be talking about today is called pyramid method and this",
    "start": "3107020",
    "end": "3113120"
  },
  {
    "text": "is the method that is based on semantic constant units and it is used for multi",
    "start": "3113120",
    "end": "3121610"
  },
  {
    "text": "document summarization mostly so what are these actually these semantic",
    "start": "3121610",
    "end": "3126890"
  },
  {
    "text": "content units so here what we have let's say we have four sentences from four",
    "start": "3126890",
    "end": "3133670"
  },
  {
    "text": "different documents now all these sentences again are more or less the same so Donald Trump won the",
    "start": "3133670",
    "end": "3141920"
  },
  {
    "text": "presidential election in 2016 in USA this is what they're all talking about so now obviously one of the things that",
    "start": "3141920",
    "end": "3149330"
  },
  {
    "text": "we don't want is extract all these four sentences because they are giving us the same information however these are just",
    "start": "3149330",
    "end": "3155570"
  },
  {
    "text": "sentence one sentence from each of the articles now what we do here is we create this units that then are kind of",
    "start": "3155570",
    "end": "3164060"
  },
  {
    "text": "parts of the information that appear in multiple documents so in our case we",
    "start": "3164060",
    "end": "3170360"
  },
  {
    "text": "have this first semantic content unit one which is in from information that",
    "start": "3170360",
    "end": "3175400"
  },
  {
    "text": "tells us that Donald Trump became president of United States okay and it",
    "start": "3175400",
    "end": "3180560"
  },
  {
    "text": "has the weight of four because that is the information that's appearing in all four documents on the other hand the",
    "start": "3180560",
    "end": "3187370"
  },
  {
    "text": "second sentence this sentence a second semantic content unit is telling us when",
    "start": "3187370",
    "end": "3192890"
  },
  {
    "text": "it happens so it happened in 2016 it gets way three because actually the thirds the third sentence the sentence",
    "start": "3192890",
    "end": "3199580"
  },
  {
    "text": "from our third document does not say when it happened so we have only three occurrences of this 2016",
    "start": "3199580",
    "end": "3207109"
  },
  {
    "text": "so then this semantic unit gets gets weight of a tree and then we create this",
    "start": "3207109",
    "end": "3212779"
  },
  {
    "text": "kind of pyramid structure so in our case since we have only four sentences from",
    "start": "3212779",
    "end": "3218630"
  },
  {
    "text": "four documents well we have more sentences but there are only four documents so we we are looking into okay",
    "start": "3218630",
    "end": "3225709"
  },
  {
    "text": "into weights of these semantic units so obviously it doesn't even matter what",
    "start": "3225709",
    "end": "3232880"
  },
  {
    "text": "these documents are about you know they could all be about Hillary Clinton so",
    "start": "3232880",
    "end": "3238789"
  },
  {
    "text": "but what is important obviously it is important for all of those documents this information about Donald Trump",
    "start": "3238789",
    "end": "3245329"
  },
  {
    "text": "because if it wasn't that information will not be appearing in all four documents so this is why since this is a",
    "start": "3245329",
    "end": "3251599"
  },
  {
    "text": "very important information we want this information to be captured in the final summary so we want to have one sentence",
    "start": "3251599",
    "end": "3258469"
  },
  {
    "text": "doesn't matter anyone we don't want all four of them but we want at least we want one of them to appear in our",
    "start": "3258469",
    "end": "3264680"
  },
  {
    "text": "document so we want somewhere to be read the Donald Trump won the election in the Latsis in 2060 so once we create our",
    "start": "3264680",
    "end": "3271699"
  },
  {
    "text": "summaries then we just look into the summaries and check ok how many of these semantic units they actually have so if",
    "start": "3271699",
    "end": "3279410"
  },
  {
    "text": "we have one summary that has one semantic unit of weight for and two",
    "start": "3279410",
    "end": "3285709"
  },
  {
    "text": "semantic units of weight three so maybe there was the third semantic unit that was talking about I don't know Monica",
    "start": "3285709",
    "end": "3291859"
  },
  {
    "text": "Lewinsky doesn't matter so then this summary gets the ten points based on the",
    "start": "3291859",
    "end": "3298309"
  },
  {
    "text": "weights on the other hand if we have summary that looks like this summary",
    "start": "3298309",
    "end": "3304099"
  },
  {
    "text": "that has one semantic unit of the weight for one of the way three and one of the",
    "start": "3304099",
    "end": "3309559"
  },
  {
    "text": "weight one so here we know that we have eight so eight points so in this case",
    "start": "3309559",
    "end": "3315410"
  },
  {
    "text": "Samuraizer one is better than Samuraizer two also if you get the summarizer that",
    "start": "3315410",
    "end": "3320719"
  },
  {
    "text": "have the same not in necessarily the same amount of points because what you want is to have those summarize if they",
    "start": "3320719",
    "end": "3327109"
  },
  {
    "text": "had most of the points on the top of the pyramid because you don't want the summarizer in this case if you get the",
    "start": "3327109",
    "end": "3332719"
  },
  {
    "text": "summarizer that has ten points but all of them being of the weight of one well",
    "start": "3332719",
    "end": "3338180"
  },
  {
    "text": "the summarizer is not so good because the more important thing here the wait for is not",
    "start": "3338180",
    "end": "3343400"
  },
  {
    "text": "actually part of the summarizer so this is we're very good net to actually you",
    "start": "3343400",
    "end": "3348890"
  },
  {
    "text": "know evaluate their summarizes and this is work for multi document summarization now I said already there are many",
    "start": "3348890",
    "end": "3355609"
  },
  {
    "text": "different methods many different approaches many different valuation methods you can use last thing I want to",
    "start": "3355609",
    "end": "3362450"
  },
  {
    "text": "mention are the tools so if you want to get into this what tools should you be using well there's python python is way to go",
    "start": "3362450",
    "end": "3370400"
  },
  {
    "text": "tool for any kind of data science projects these days especially for any kind of natural language processing",
    "start": "3370400",
    "end": "3376089"
  },
  {
    "text": "problems and there is a very awesome library called salmon that actually has",
    "start": "3376089",
    "end": "3381530"
  },
  {
    "text": "all these predefined functions so you can see that some of them we mentioned today some of them we haven't so there",
    "start": "3381530",
    "end": "3387980"
  },
  {
    "text": "is quite a big number of functions that you can try out for most of them you don't have to actually do any kind of",
    "start": "3387980",
    "end": "3393410"
  },
  {
    "text": "pre-processing it's all compact already there you just select ok a lot of them are actually working quite well with",
    "start": "3393410",
    "end": "3399710"
  },
  {
    "text": "other languages for example in region because of just important regions top words and you just go with it of course",
    "start": "3399710",
    "end": "3406460"
  },
  {
    "text": "it's not perfect but it's working quite reasonably for some of them of course you need to add some more do some more",
    "start": "3406460",
    "end": "3413540"
  },
  {
    "text": "tweaking of the data for example Edmondson they still you still need to add those keywords that are",
    "start": "3413540",
    "end": "3419660"
  },
  {
    "text": "domain-specific but as you can see here there is one Samuraizer still there so 60 years ago and we're kind of still",
    "start": "3419660",
    "end": "3426559"
  },
  {
    "text": "using it and it's actually giving quite reasonable results so it is not as bad as we thought it",
    "start": "3426559",
    "end": "3433760"
  },
  {
    "text": "would be and of course i mean if you want to do any kind of deep learning models or stuff with the abstract",
    "start": "3433760",
    "end": "3440329"
  },
  {
    "text": "summarization I would definitely recommend tensor fall because you have to moralize have to use it for any kind",
    "start": "3440329",
    "end": "3446059"
  },
  {
    "text": "of deeper learning problems ok that was all for me thank you all very much for",
    "start": "3446059",
    "end": "3451460"
  },
  {
    "text": "listening I hope you learned something about the text summarization and I hope it was interested and hopefully it will",
    "start": "3451460",
    "end": "3458390"
  },
  {
    "text": "also get you into going into more into trying to okay trying to try it out yourself really like the download Python",
    "start": "3458390",
    "end": "3465049"
  },
  {
    "text": "if you haven't had it already this package also it everything is for free so you can just try it out and create",
    "start": "3465049",
    "end": "3471319"
  },
  {
    "text": "your own at least extractive summarize errs something thank you very much any",
    "start": "3471319",
    "end": "3480239"
  },
  {
    "text": "questions",
    "start": "3480239",
    "end": "3482960"
  }
]
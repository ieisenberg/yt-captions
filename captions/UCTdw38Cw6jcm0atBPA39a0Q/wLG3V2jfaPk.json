[
  {
    "text": "good morning welcome to the first NDC Sydney I'm very excited to be in Sydney",
    "start": "6380",
    "end": "13469"
  },
  {
    "text": "it's my first time in Australia so um it's a long way so far it's a long way",
    "start": "13469",
    "end": "19170"
  },
  {
    "text": "from the UK I left in Saturday I got here Monday yeah weird um so this is a",
    "start": "19170",
    "end": "25680"
  },
  {
    "text": "talk called centralized logging without the blood sweat and tears okay this is a",
    "start": "25680",
    "end": "30990"
  },
  {
    "text": "talk based on the fact that I used to run extremely large Mogan clusters like I think at one point my last Xterra",
    "start": "30990",
    "end": "38400"
  },
  {
    "text": "cluster when we talked about it was like 10 terabyte 14 terabytes of data at some point so this is a talk designed on how",
    "start": "38400",
    "end": "46260"
  },
  {
    "text": "to get started on this much smaller scale much much smaller together so I'm Paul stack I got Twitter details on my",
    "start": "46260",
    "end": "52260"
  },
  {
    "text": "email address at the bottom if you hate want to heckle me if you want to disagree with me please get in contact",
    "start": "52260",
    "end": "59220"
  },
  {
    "text": "and we'll certainly have a chat about it um I am an engineer at Corp yeah I",
    "start": "59220",
    "end": "64860"
  },
  {
    "text": "got a new job if for anybody doesn't know how she Corp they're the people that create terraform",
    "start": "64860",
    "end": "70410"
  },
  {
    "text": "and packer and vagrant the nomad and console and all these awesome tools come in and sit down friends I'm a reformed",
    "start": "70410",
    "end": "77370"
  },
  {
    "text": "asp.net and C sharp developer okay I don't mean that with any disrespect okay that's all I just do not work in the",
    "start": "77370",
    "end": "84300"
  },
  {
    "text": "Windows environment anymore I work in go I write go away and I work in Linux so I",
    "start": "84300",
    "end": "89670"
  },
  {
    "text": "find myself that I can be a little bit more hockey what if I go as people who've",
    "start": "89670",
    "end": "97920"
  },
  {
    "text": "used Oh No so I I do that night I'm a DevOps extremist so I was a developer",
    "start": "97920",
    "end": "103290"
  },
  {
    "text": "moved in the operations and now I'm actually building operations tools for developers again with so bringing some",
    "start": "103290",
    "end": "110250"
  },
  {
    "text": "experience reports into it which is really good and I'm a conference junkie I think I've done like 13 conferences so",
    "start": "110250",
    "end": "115350"
  },
  {
    "text": "far this year I think while I'm in said may I have like four talks and then I go away to talk somewhere else next week so",
    "start": "115350",
    "end": "121590"
  },
  {
    "text": "I love this so why centralized logging okay this isn't",
    "start": "121590",
    "end": "129599"
  },
  {
    "text": "a talk and why we should centrally log okay there are many many talks right",
    "start": "129599",
    "end": "135840"
  },
  {
    "text": "there about centralized logging okay and why you should do it one thing that we",
    "start": "135840",
    "end": "142660"
  },
  {
    "text": "should agree on two things we should agree on is central logs give us that single place",
    "start": "142660",
    "end": "148750"
  },
  {
    "text": "to analyze our log files okay and secondly we remove the dependency on SS",
    "start": "148750",
    "end": "155530"
  },
  {
    "text": "agent and already peeing into servers to find logs okay you would not believe the amount of",
    "start": "155530",
    "end": "163750"
  },
  {
    "text": "people I still speak to you that have to already pay or go to their operations team and RDP into their server in order",
    "start": "163750",
    "end": "170410"
  },
  {
    "text": "to get their logs and as developers that's extremely frustrating okay",
    "start": "170410",
    "end": "176470"
  },
  {
    "text": "because it creates an environment of a we probably forget to care about logs at",
    "start": "176470",
    "end": "184210"
  },
  {
    "text": "that point and we probably don't know what's happening in our infrastructure we don't know how our application is",
    "start": "184210",
    "end": "190870"
  },
  {
    "text": "behaving in production the question they ask yourself as we go through this is what happens if we lose",
    "start": "190870",
    "end": "198070"
  },
  {
    "text": "a server overnight and that server was full of log files how are you going to",
    "start": "198070",
    "end": "204070"
  },
  {
    "text": "know why your application crashed or why your server crashed okay as we go",
    "start": "204070",
    "end": "209860"
  },
  {
    "text": "through this remind yourself on that if you don't use centralized logging right now I'm hopeful that this will give you",
    "start": "209860",
    "end": "216459"
  },
  {
    "text": "a little bit of code and a little bit of a kickstart in order to actually say hey look I can deploy this infrastructure",
    "start": "216459",
    "end": "222250"
  },
  {
    "text": "quite easily and more importantly very cheaply very very cheaply",
    "start": "222250",
    "end": "227760"
  },
  {
    "text": "mr. Murphy he was a very wise man okay his law says anything that can go wrong",
    "start": "227760",
    "end": "234100"
  },
  {
    "text": "will go wrong okay does anybody in here",
    "start": "234100",
    "end": "239640"
  },
  {
    "text": "claim that they've never encountered a bug in their production software",
    "start": "239640",
    "end": "245640"
  },
  {
    "text": "amazing it's true right every time we release our applications to production",
    "start": "246690",
    "end": "252250"
  },
  {
    "text": "they behave slightly differently to what we expect them to do know this",
    "start": "252250",
    "end": "258070"
  },
  {
    "text": "could be environmental changes this could be configuration changes mostly",
    "start": "258070",
    "end": "263260"
  },
  {
    "text": "it's because of users okay because the way users interact with",
    "start": "263260",
    "end": "268990"
  },
  {
    "text": "our system is completely different to how we believe they interact for system so because of that it's very important",
    "start": "268990",
    "end": "276580"
  },
  {
    "text": "to understand that you you must log an errors happen so",
    "start": "276580",
    "end": "283060"
  },
  {
    "text": "because they happen we should catch those errors when we should take advantage of that rich information and",
    "start": "283060",
    "end": "289030"
  },
  {
    "text": "we should actually be able to make our software better based on that is everyone in here software developers any",
    "start": "289030",
    "end": "294940"
  },
  {
    "text": "QA s-- ops people everyone's developers everyone windows developers",
    "start": "294940",
    "end": "302280"
  },
  {
    "text": "what languages if we got outside of c-sharp excuse me go excellent excellent you're",
    "start": "302280",
    "end": "309969"
  },
  {
    "text": "my favorites already any other any raise it on go groovy is that still a thing I'm joking",
    "start": "309969",
    "end": "318789"
  },
  {
    "text": "I'm kidding I'm kidding I'm kidding I'm only joking it is still a thing and I've used it and I actually really like",
    "start": "318789",
    "end": "325030"
  },
  {
    "text": "groovy to be honest if he and the interaction with Jenkins and groovy is very useful so I only say that in jest",
    "start": "325030",
    "end": "332020"
  },
  {
    "text": "ok classic ASP Wow",
    "start": "332020",
    "end": "337469"
  },
  {
    "text": "there's always one that there is always one you definitely need be centrally log",
    "start": "337469",
    "end": "343210"
  },
  {
    "text": "because that always goes wrong so one thing I find is you do usually",
    "start": "343210",
    "end": "351610"
  },
  {
    "text": "say or you usually find someone in the room who says well you know my software",
    "start": "351610",
    "end": "356680"
  },
  {
    "text": "works it works as expected and we maybe get the odd bug every time ok or once in",
    "start": "356680",
    "end": "362229"
  },
  {
    "text": "a blue moon ok those people are slightly delusional because there's one of two things happen",
    "start": "362229",
    "end": "369550"
  },
  {
    "text": "in there at that point they're either not aware that there's application of their application is throwing bugs ok or",
    "start": "369550",
    "end": "375639"
  },
  {
    "text": "they're blinkered and they don't care that it's throwing bugs or secondly their kid in themselves because they",
    "start": "375639",
    "end": "381310"
  },
  {
    "text": "have no single pane of glass in order to get access to their logs back to that that hassle of having the",
    "start": "381310",
    "end": "389529"
  },
  {
    "text": "file a request to your ops person who in 60 days or whatever their",
    "start": "389529",
    "end": "396810"
  },
  {
    "text": "whatever their time frame in order to get to your request will be of our DP and in their server and grabbing a file",
    "start": "396810",
    "end": "403870"
  },
  {
    "text": "or our FTP in the file bar in and then it's really messy it's really painful",
    "start": "403870",
    "end": "410400"
  },
  {
    "text": "again what happens if you lose a server and the Lord we're only on that server",
    "start": "410400",
    "end": "417180"
  },
  {
    "text": "there are many many many many many logging tools 9 they really are ok logs",
    "start": "417180",
    "end": "422860"
  },
  {
    "text": "io log ly Splunk GRA log to elastic you could go on and on okay the rise of",
    "start": "422860",
    "end": "429340"
  },
  {
    "text": "DevOps has basically meant that you google DevOps tools and you'll get hundreds and hundreds and hundreds of",
    "start": "429340",
    "end": "435340"
  },
  {
    "text": "tools back these days okay and the new way of the new hello world is either like new frameworks you log in tools new",
    "start": "435340",
    "end": "443139"
  },
  {
    "text": "JavaScript libraries this is what we do now we like to pollute the environment with extra",
    "start": "443139",
    "end": "449590"
  },
  {
    "text": "tooling there's lots of hosted solutions you can velasca front by elastic log lee log",
    "start": "449590",
    "end": "457419"
  },
  {
    "text": "Splunk there's also free ones like elastic as well you can host it yourself gray dog - there's loads ok check them",
    "start": "457419",
    "end": "465069"
  },
  {
    "text": "out I gave a a logging talk III believe it was like two years ago",
    "start": "465069",
    "end": "472060"
  },
  {
    "text": "tonight on how to scale a logging infrastructure to a billion message isn't they ok",
    "start": "472060",
    "end": "477090"
  },
  {
    "text": "we have to get some terminology right when I say logs I actually mean messages",
    "start": "477090",
    "end": "482340"
  },
  {
    "text": "okay because a message can have a different type okay it could be a debug message it can be an info message it can",
    "start": "482340",
    "end": "488770"
  },
  {
    "text": "be a trace message it can be an error message etc so we try and use the term messages because we like passing",
    "start": "488770",
    "end": "494800"
  },
  {
    "text": "messages messages is a great way of exchanging information between our teams in our environments so I I wrote this",
    "start": "494800",
    "end": "500740"
  },
  {
    "text": "talk and hardly scale a logging infrastructure to be to accept a billion messages a day",
    "start": "500740",
    "end": "506529"
  },
  {
    "text": "for those here trying to do the math that's about eleven and a half thousand log messages a second okay and it was a",
    "start": "506529",
    "end": "513339"
  },
  {
    "text": "painful horrible horrible experience it really was and we started with a really simple",
    "start": "513339",
    "end": "519270"
  },
  {
    "text": "infrastructure looking back it wasn't as simple as I first thought okay so on the",
    "start": "519270",
    "end": "526029"
  },
  {
    "text": "top right hand side we have application servers we had forwarding or emitting",
    "start": "526029",
    "end": "531459"
  },
  {
    "text": "agents on every application server these were Windows servers back then this was back when I was like",
    "start": "531459",
    "end": "537300"
  },
  {
    "text": "when I had hair I'm and we used I believe we used an X",
    "start": "537300",
    "end": "543420"
  },
  {
    "text": "and X log and we use the specific JavaScript framework libraries that we used in order to forward from our new",
    "start": "543420",
    "end": "549569"
  },
  {
    "text": "jsr vacations and so on and those messages were sent through a log processor note low processor nodes had",
    "start": "549569",
    "end": "556050"
  },
  {
    "text": "two things on them okay we had a cluster of three every node had a Redis instance and every node also had a log stash",
    "start": "556050",
    "end": "563819"
  },
  {
    "text": "instance okay anyone know log stash quite a few quite a few",
    "start": "563819",
    "end": "569689"
  },
  {
    "text": "it became very difficult because some applications would connect to Redis to send their messages other applications",
    "start": "569689",
    "end": "575759"
  },
  {
    "text": "would send their messages directly to log stash and then we had to put some polarity in place in order to say hey if",
    "start": "575759",
    "end": "580860"
  },
  {
    "text": "you forwarded it to log stash then send it into Redis so we use that as a persistent queue and then later we'll",
    "start": "580860",
    "end": "587459"
  },
  {
    "text": "have a we have the log index or nodes which will go and read the data out from Redis and though",
    "start": "587459",
    "end": "593509"
  },
  {
    "text": "they'll broker the messages through into elasticsearch okay this was painful okay",
    "start": "593509",
    "end": "599519"
  },
  {
    "text": "for many many many many reasons okay firstly Redis",
    "start": "599519",
    "end": "606649"
  },
  {
    "text": "Redis is a persistent storage queue okay we didn't realize I can see some",
    "start": "606649",
    "end": "613230"
  },
  {
    "text": "people shaking their heads we did not realize okay that every time we were",
    "start": "613230",
    "end": "619139"
  },
  {
    "text": "getting to the edge of our our memory allocation and Redis Redis was dumping",
    "start": "619139",
    "end": "625259"
  },
  {
    "text": "the keys at the bottom of the pile okay so it was first then last night so we",
    "start": "625259",
    "end": "631589"
  },
  {
    "text": "thought that our login infrastructure was like killing it and we were like processing hundreds and hundreds of",
    "start": "631589",
    "end": "636629"
  },
  {
    "text": "requests a second yeah that wasn't the case it took a long time to realize that",
    "start": "636629",
    "end": "641850"
  },
  {
    "text": "though a long time to realize that secondly",
    "start": "641850",
    "end": "647449"
  },
  {
    "text": "we had log stash here and we had log start here",
    "start": "647449",
    "end": "653750"
  },
  {
    "text": "we had a lot of moving parts to this simple infrastructure it was supposedly",
    "start": "653750",
    "end": "660059"
  },
  {
    "text": "a really simple infrastructure right and internally it looked like this so the",
    "start": "660059",
    "end": "665610"
  },
  {
    "text": "log indexers were sending data to reddit or excuse me the applications were sending data either to Redis or they",
    "start": "665610",
    "end": "671459"
  },
  {
    "text": "were sending it to logstash was forwarding the data into Redis and the log indexers were reading the data out",
    "start": "671459",
    "end": "677600"
  },
  {
    "text": "of Redis and forwarding it onto elasticsearch tire fire",
    "start": "677600",
    "end": "683350"
  },
  {
    "text": "absolute disaster it was and it got to the point where one day that we realized",
    "start": "683350",
    "end": "690800"
  },
  {
    "text": "that we actually lost a byte 8 gigs worth of data per server when a Redis",
    "start": "690800",
    "end": "697160"
  },
  {
    "text": "cluster crashed so the CTO was not very happy and he suggested that maybe we go back to the",
    "start": "697160",
    "end": "703520"
  },
  {
    "text": "drawing board as you can imagine",
    "start": "703520",
    "end": "707680"
  },
  {
    "text": "what we actually did if we go and have a look at the infrastructure right there this was a cluster of servers and this",
    "start": "708580",
    "end": "715100"
  },
  {
    "text": "is a cluster of servers in order to get the data from the application servers into elasticsearch pair data center on",
    "start": "715100",
    "end": "721310"
  },
  {
    "text": "pair environment we introduced six new servers six new VMs they were pretty",
    "start": "721310",
    "end": "727250"
  },
  {
    "text": "beefy VMs they were like 16 gig ROM they were like 250 gig hard drive and they",
    "start": "727250",
    "end": "732590"
  },
  {
    "text": "had like eight cores yeah this was this was in a physical data center so we were",
    "start": "732590",
    "end": "738950"
  },
  {
    "text": "like using up resources pretty fast we had 16 environments and we had four data",
    "start": "738950",
    "end": "745520"
  },
  {
    "text": "centers so we were we were like churning through money for a simple infrastructure",
    "start": "745520",
    "end": "753430"
  },
  {
    "text": "what did we do as developers we went and complicated it again that's what",
    "start": "753430",
    "end": "758660"
  },
  {
    "text": "developers do ok no bear with me there are a lot of moving parts in this time",
    "start": "758660",
    "end": "764960"
  },
  {
    "text": "the application servers sent data to the low processors we introduced Apache",
    "start": "764960",
    "end": "770660"
  },
  {
    "text": "Kafka because it was cool back then well it's still cool it is still very cool what I mean is it was new I think it was",
    "start": "770660",
    "end": "777740"
  },
  {
    "text": "actually like a patchy Kafka 0.6 okay I think it's dot nine nine if I remember",
    "start": "777740",
    "end": "783470"
  },
  {
    "text": "rightly somewhere around there so Apache Kafka was reading the data out of the log processor notes of course it was",
    "start": "783470",
    "end": "789740"
  },
  {
    "text": "having this store it's offset and zookeeper cluster and it was passed on it was we were using Kafka as a",
    "start": "789740",
    "end": "795140"
  },
  {
    "text": "persistent storage okay so we thought right how do we get the data from Kafka",
    "start": "795140",
    "end": "800950"
  },
  {
    "text": "into elasticsearch let's use another Kafka indexer so we",
    "start": "800950",
    "end": "806180"
  },
  {
    "text": "introduced another level of Kafka indexers okay we had to reduce the polarity right now",
    "start": "806180",
    "end": "811990"
  },
  {
    "text": "this was this was pretty successful this is how we actually scaled to about eleven and a half thousand messages a",
    "start": "811990",
    "end": "818240"
  },
  {
    "text": "second okay we were churning through like four terabytes of data right now that they across all of our environments",
    "start": "818240",
    "end": "824990"
  },
  {
    "text": "and across all of our data data centers and we had one centralized place one so",
    "start": "824990",
    "end": "830449"
  },
  {
    "text": "we had this same environment sixteen times and we were using cascade mirror maker to",
    "start": "830449",
    "end": "836420"
  },
  {
    "text": "move the data between all the environments into the central logging system so if you think of sixteen of",
    "start": "836420",
    "end": "842149"
  },
  {
    "text": "these all the rope this was expensive really expensive just",
    "start": "842149",
    "end": "847160"
  },
  {
    "text": "to give you an idea of how expensive it was the elasticsearch cluster in AWS was",
    "start": "847160",
    "end": "852230"
  },
  {
    "text": "a hundred and forty are three extra large nodes a",
    "start": "852230",
    "end": "857019"
  },
  {
    "text": "hundred and forty and each one was using a 1.5 terabyte EBS volume",
    "start": "857709",
    "end": "865449"
  },
  {
    "text": "this was crazy but they loved it because week it could",
    "start": "865449",
    "end": "871279"
  },
  {
    "text": "handle any messages we threw at it no the reason I'm giving this talk",
    "start": "871279",
    "end": "877480"
  },
  {
    "text": "it's because not companies can't afford this scale right we couldn't afford this",
    "start": "877480",
    "end": "884269"
  },
  {
    "text": "scale looking back we were burning through money the elasticsearch cluster alone I believe",
    "start": "884269",
    "end": "891009"
  },
  {
    "text": "was costing us about twenty five thousand dollars a month just for",
    "start": "891009",
    "end": "897290"
  },
  {
    "text": "elasticsearch okay now in order to get",
    "start": "897290",
    "end": "902300"
  },
  {
    "text": "the data from the application service to the elasticsearch clusters we had three kafka nodes we had three log collector",
    "start": "902300",
    "end": "909740"
  },
  {
    "text": "nodes or log processor nodes we had three zookeeper nodes and we had two Kafka indexers so we went from 6 servers",
    "start": "909740",
    "end": "918949"
  },
  {
    "text": "um we were not on 11 servers so 11",
    "start": "918949",
    "end": "924230"
  },
  {
    "text": "servers times 16 that's a hundred and seventy-one servers",
    "start": "924230",
    "end": "929779"
  },
  {
    "text": "just pushing data around okay not storing it and not doing anything with it this was ridiculous but in order to",
    "start": "929779",
    "end": "937790"
  },
  {
    "text": "do it we had the again reverse the polarity inside our lo processors so the applications were",
    "start": "937790",
    "end": "943519"
  },
  {
    "text": "either logging to Redis or they were Logan to log stash as expected but we changed it that Redis was no longer the",
    "start": "943519",
    "end": "949670"
  },
  {
    "text": "cube okay as soon as it went in the reddest log stash was pulling it immediately out",
    "start": "949670",
    "end": "954920"
  },
  {
    "text": "of reticence sending it to Kafka Kafka is designed for this ok Kafka is designing for this major message",
    "start": "954920",
    "end": "961370"
  },
  {
    "text": "overhaul because it remembers the or it's it's strongly ordered it remembers the order in which you pass in it gets",
    "start": "961370",
    "end": "967519"
  },
  {
    "text": "out in the same order I mean it has lots of brokers that it can read really fast and it can use in different partitions",
    "start": "967519",
    "end": "974180"
  },
  {
    "text": "that can spread them spread the load so it worked really well the trouble with it is there were just",
    "start": "974180",
    "end": "981649"
  },
  {
    "text": "so many of them pager duty was never-ending and I do mean never-ending",
    "start": "981649",
    "end": "988209"
  },
  {
    "text": "there has to be another way if you're a small company",
    "start": "988209",
    "end": "993430"
  },
  {
    "text": "there's no way in hell you have enough people and enough money to manage an",
    "start": "993430",
    "end": "1001720"
  },
  {
    "text": "infrastructure like this we had a team of six people dedicated to our logging metrics and monitoring infrastructure",
    "start": "1001720",
    "end": "1007720"
  },
  {
    "text": "does anybody in this in this room have that over at that level of resource for there for just for their metrics monitor",
    "start": "1007720",
    "end": "1014230"
  },
  {
    "text": "and infrastructure it's crazy right so looking back in this like I don't work",
    "start": "1014230",
    "end": "1020319"
  },
  {
    "text": "about company anymore and I'm this is not a case of slagging off this is a case of as",
    "start": "1020319",
    "end": "1025918"
  },
  {
    "text": "developers we very much over complicated it so over the past couple of months I've been really looking at different",
    "start": "1025919",
    "end": "1032409"
  },
  {
    "text": "ways in order to do this we're going to use three simple tools in",
    "start": "1032409",
    "end": "1039370"
  },
  {
    "text": "AWS anyone use AWS in here awesome more than I thought anyone use",
    "start": "1039370",
    "end": "1046030"
  },
  {
    "text": "any other cloud providers Oh even more which cloud providers",
    "start": "1046030",
    "end": "1051360"
  },
  {
    "text": "so I've been told that it's you have to opt in here to use the Australian as",
    "start": "1051360",
    "end": "1057130"
  },
  {
    "text": "your data center is that right now okay maybe it's on your account by default",
    "start": "1057130",
    "end": "1062340"
  },
  {
    "text": "excuse me there's two here okay",
    "start": "1062340",
    "end": "1067830"
  },
  {
    "text": "that's because one regularly falls over and",
    "start": "1067830",
    "end": "1072890"
  },
  {
    "text": "this is not serverless okay I put a joke tweet out there last night saying look",
    "start": "1072890",
    "end": "1079380"
  },
  {
    "text": "I've just built a logging infrastructure service okay it had 108 retweets and",
    "start": "1079380",
    "end": "1085890"
  },
  {
    "text": "likes okay because server list is cool this is platforms of service this is very much pass okay I understand that",
    "start": "1085890",
    "end": "1093420"
  },
  {
    "text": "lambda is in there I'm lambda is serverless everything else is just using pass based",
    "start": "1093420",
    "end": "1099300"
  },
  {
    "text": "bad tools so the way it works is application servers send data to your Canisius",
    "start": "1099300",
    "end": "1106920"
  },
  {
    "text": "stream anyone know what Kinesis is so Kinesis is like if you think of it as a very simplistic",
    "start": "1106920",
    "end": "1114930"
  },
  {
    "text": "Kafka okay based in okay so you have a number of shards",
    "start": "1114930",
    "end": "1121340"
  },
  {
    "text": "inside the Kinesis stream and the number of charge relates to how fast you can read and write data out of it okay we'll",
    "start": "1121340",
    "end": "1128700"
  },
  {
    "text": "talk about the metrics okay but it has a persistent queue and it stores data it retains data for a period of time that",
    "start": "1128700",
    "end": "1136500"
  },
  {
    "text": "you determine okay I promise you were gonna get me some code it's not gonna be me just telling rubbish tales for the",
    "start": "1136500",
    "end": "1143880"
  },
  {
    "text": "next 30 minutes so from Kinesis we have to actually take",
    "start": "1143880",
    "end": "1149250"
  },
  {
    "text": "the data and we have to push it to elasticsearch what better way of doing that than Lamba",
    "start": "1149250",
    "end": "1155340"
  },
  {
    "text": "okay lambda is ridiculously cheap to do this type of thing okay so we have a tiny",
    "start": "1155340",
    "end": "1162170"
  },
  {
    "text": "like an application invocation which goes and reads data and batches pushes it into elasticsearch this is all hosted",
    "start": "1162170",
    "end": "1169230"
  },
  {
    "text": "and i could do all of this in infrastructure as code i like this I don't like clicking around in you ice",
    "start": "1169230",
    "end": "1176690"
  },
  {
    "text": "coat I'm um I think somebody was taking a picture you want that back",
    "start": "1176690",
    "end": "1182420"
  },
  {
    "text": "the codes available I promise so I'm gonna use terraform for this and",
    "start": "1182420",
    "end": "1187950"
  },
  {
    "text": "not because I work in the company I I was am an OSS maintainer of the code",
    "start": "1187950",
    "end": "1195060"
  },
  {
    "text": "base for quite a while before I joined the company so this is not a sales thing at all you could use CloudFormation for",
    "start": "1195060",
    "end": "1201480"
  },
  {
    "text": "the really easily you could also use another tool called Sparkle formation and there are like lots and lots of",
    "start": "1201480",
    "end": "1207640"
  },
  {
    "text": "infrastructure as code tools this is the one I use on a day-to-day basis and have done for about 18 months now it actually",
    "start": "1207640",
    "end": "1214780"
  },
  {
    "text": "just went 0.7 today which is like this is all new features I'm sure when you by",
    "start": "1214780",
    "end": "1220690"
  },
  {
    "text": "the way so if that didn't get released this morning when I woke up we have been using at their brunch",
    "start": "1220690",
    "end": "1226950"
  },
  {
    "text": "so let's look at it as follows anyone named questions so far",
    "start": "1226950",
    "end": "1234540"
  },
  {
    "text": "anyone care I'm kidding",
    "start": "1234540",
    "end": "1240900"
  },
  {
    "text": "everyone at the back read that excellent so I",
    "start": "1240900",
    "end": "1246840"
  },
  {
    "text": "just delete something that's never good okay perfect so we declare a very we",
    "start": "1246840",
    "end": "1255850"
  },
  {
    "text": "declare a provider ok terraform has built in support from many cloud providers ok Azir google",
    "start": "1255850",
    "end": "1262950"
  },
  {
    "text": "digitalocean Joyent AWS of course lots and lots of other",
    "start": "1262950",
    "end": "1268900"
  },
  {
    "text": "ones it's got vSphere VMware vCloud director it's got like you know there's there's tons of support it's very easily",
    "start": "1268900",
    "end": "1275110"
  },
  {
    "text": "extendable there's another talk of mine out there that you can go and have a look if you really want to extend it to your own purposes so we declare a",
    "start": "1275110",
    "end": "1281470"
  },
  {
    "text": "provider of AWS and we give that a region so we tell terraform what region",
    "start": "1281470",
    "end": "1286570"
  },
  {
    "text": "we want to deploy our code in see of course I'm using some technologies that are not generally available across the",
    "start": "1286570",
    "end": "1292270"
  },
  {
    "text": "board in all regions so you'll have to bear with me and the fact that some of these are not in Asia Pacific data",
    "start": "1292270",
    "end": "1298960"
  },
  {
    "text": "centers but I believe they are going to rule later this year and some of them I'm",
    "start": "1298960",
    "end": "1304500"
  },
  {
    "text": "so we're going to start with the provider we're gonna create a module ok modules",
    "start": "1304500",
    "end": "1311049"
  },
  {
    "text": "are reusable pieces of code and terraform think of it as like a third-party helper library that you have",
    "start": "1311049",
    "end": "1316059"
  },
  {
    "text": "an interface for and you just push values into and it will actually allow you to reuse the code again and again so",
    "start": "1316059",
    "end": "1322840"
  },
  {
    "text": "we're gonna create a module called log stream and the source of the module I'll show you the source right now is a Kinesis module very simple we're going",
    "start": "1322840",
    "end": "1331120"
  },
  {
    "text": "to give it a stream name we're going to give it a retention period and we're going to give it a descriptive we're",
    "start": "1331120",
    "end": "1336429"
  },
  {
    "text": "going to talk about shark hunts in a second okay now the module looks as",
    "start": "1336429",
    "end": "1341440"
  },
  {
    "text": "follows we have an interface as we like to write",
    "start": "1341440",
    "end": "1347410"
  },
  {
    "text": "documentation we never like the right documentation we're developers what this allows us to do it just allows",
    "start": "1347410",
    "end": "1354700"
  },
  {
    "text": "the user of the module in order to actually understand what the variables are for really simple descriptions and",
    "start": "1354700",
    "end": "1360730"
  },
  {
    "text": "there are lots of tools out there that will go and grab those descriptions so that when you're writing terraform code",
    "start": "1360730",
    "end": "1367210"
  },
  {
    "text": "from the command line it will prompt you and save the value that you need notice for this it's really useful",
    "start": "1367210",
    "end": "1374340"
  },
  {
    "text": "we set some defaults retention period by default is 24 hours so one day reason",
    "start": "1374340",
    "end": "1380590"
  },
  {
    "text": "being is that it's slightly more expensive for the longer retention parents and Kinesis so if you don't if",
    "start": "1380590",
    "end": "1386290"
  },
  {
    "text": "you want to like cheat but then set it set a shorter amount of time let's be",
    "start": "1386290",
    "end": "1392050"
  },
  {
    "text": "honest if you're not processing your logs within 24 hours you've probably got different problems",
    "start": "1392050",
    "end": "1398490"
  },
  {
    "text": "so 24 is probably okay and then lastly",
    "start": "1398490",
    "end": "1403840"
  },
  {
    "text": "we have somewhat puts we need the AR in okay so the amazon resource number we actually need that valley to be possible",
    "start": "1403840",
    "end": "1410290"
  },
  {
    "text": "on the run at different places and how it looks in the code is we",
    "start": "1410290",
    "end": "1416020"
  },
  {
    "text": "declare a resource named shard can't retention period we want to capture all of these metrics right here okay we want",
    "start": "1416020",
    "end": "1423070"
  },
  {
    "text": "the incoming records the Elko and records the incoming bytes outgoing bytes we want them iterate iterator age",
    "start": "1423070",
    "end": "1428530"
  },
  {
    "text": "in milliseconds so we understand how long it's taken to churn our records this is all documented I'm not breaking",
    "start": "1428530",
    "end": "1434980"
  },
  {
    "text": "any amazing discoveries right now this is all in the AWS as the CLI and SDKs okay",
    "start": "1434980",
    "end": "1443050"
  },
  {
    "text": "we set some tags and that's it that is the simplest module and terraform that",
    "start": "1443050",
    "end": "1450040"
  },
  {
    "text": "you can probably a might actually I have a simpler one but it's really easy it's really readable okay I understand that",
    "start": "1450040",
    "end": "1457390"
  },
  {
    "text": "we have some notation here of some interpolation values for VAR dot that's as complicated as are as",
    "start": "1457390",
    "end": "1464769"
  },
  {
    "text": "as our conflict gets so we declare it",
    "start": "1464769",
    "end": "1471389"
  },
  {
    "text": "as follows so if I wanted to create another law another log stream I can go",
    "start": "1471389",
    "end": "1477909"
  },
  {
    "text": "and do that so let's go and create an environment just so you can actually see it in place we're gonna call this Sydney",
    "start": "1477909",
    "end": "1483909"
  },
  {
    "text": "I",
    "start": "1483909",
    "end": "1486210"
  },
  {
    "text": "just want to show you how simple it is in order to actually call this code",
    "start": "1490649",
    "end": "1495720"
  },
  {
    "text": "I'm gonna copy and paste like every good developer does",
    "start": "1495720",
    "end": "1501840"
  },
  {
    "text": "test stream",
    "start": "1504120",
    "end": "1507480"
  },
  {
    "text": "shark I'm warm",
    "start": "1510490",
    "end": "1513840"
  },
  {
    "text": "so terraform has some built-in commands that come with it again this is not a terraform demonstration this is just",
    "start": "1516320",
    "end": "1522930"
  },
  {
    "text": "showing you that using really simple infrastructure as code you can build this type of logging infrastructure the code will all be available so if we run",
    "start": "1522930",
    "end": "1529920"
  },
  {
    "text": "the command terraform get so go off and get me the module source modules don't have to be on the same machine they can",
    "start": "1529920",
    "end": "1535980"
  },
  {
    "text": "be stored in github so that your sis ID mints can be taken care of these modules or your infrastructure team and you as a",
    "start": "1535980",
    "end": "1541860"
  },
  {
    "text": "developer can just be coding against these modules so we're gonna go off and get it and it's gone and gone it's okay as it's local it just creates a symlink",
    "start": "1541860",
    "end": "1549710"
  },
  {
    "text": "doesn't do anything like really crazy and if I run you can see it created that terraform",
    "start": "1549710",
    "end": "1556410"
  },
  {
    "text": "folder right here and there's a copy of the module source in there so you can always know what version of the module",
    "start": "1556410",
    "end": "1561840"
  },
  {
    "text": "you're running against and if I run the command terraform plan",
    "start": "1561840",
    "end": "1568340"
  },
  {
    "text": "it's going to terraform is built on graph theory okay terraform will work",
    "start": "1568340",
    "end": "1574110"
  },
  {
    "text": "out the dependencies between all the different pieces of your infrastructure and actually plot in what order they",
    "start": "1574110",
    "end": "1580110"
  },
  {
    "text": "have to be created okay and sometimes you'll see values like this computed",
    "start": "1580110",
    "end": "1585570"
  },
  {
    "text": "because those are values that come back from AWS and we don't quite know what they are okay but mostly you can read it",
    "start": "1585570",
    "end": "1591840"
  },
  {
    "text": "and you can see what it's going to do and at the end it actually gives you a nice little plan and it says plant one to add zero to change zero to destroy",
    "start": "1591840",
    "end": "1599750"
  },
  {
    "text": "if we go to Kinesis will seem long stream I had to prepare my demo earlier",
    "start": "1599750",
    "end": "1606360"
  },
  {
    "text": "because the Wi-Fi and the hotel has been pretty shoddy so we're looking at the actual infrastructure a little bit this",
    "start": "1606360",
    "end": "1611760"
  },
  {
    "text": "is just showing you that we can deploy it really quickly alright so there's nothing in there for NDC Sydney or for",
    "start": "1611760",
    "end": "1617100"
  },
  {
    "text": "Sydney or a different little team there's only one stream in there right now so tariffs on apply",
    "start": "1617100",
    "end": "1623630"
  },
  {
    "text": "what this is doing is this is taking a snapshot or working out what the",
    "start": "1623630",
    "end": "1629340"
  },
  {
    "text": "infrastructure of my local machine is like comparing that against the environment that I'm going to deploy it to in this case AWS and it's going to",
    "start": "1629340",
    "end": "1636210"
  },
  {
    "text": "tell me hey I need to make these changes to bring the environment up to the same speed okay so it's a deterministic way",
    "start": "1636210",
    "end": "1642480"
  },
  {
    "text": "of keeping your environment in exactly the same configuration this is a good thing this is a very good",
    "start": "1642480",
    "end": "1649450"
  },
  {
    "text": "thing and you'll see it's creating and it gives you some output and says it's still creating it's still creating just",
    "start": "1649450",
    "end": "1655750"
  },
  {
    "text": "because the AWS SDKs I'm actually going to Oregon here so it's a little bit",
    "start": "1655750",
    "end": "1661000"
  },
  {
    "text": "slower than I would expect but it's gonna go and create it and if I go back to the AWS CLI I mean we can see the",
    "start": "1661000",
    "end": "1667960"
  },
  {
    "text": "test stream is actually active so terraform is just going to tell us know that it's created",
    "start": "1667960",
    "end": "1674909"
  },
  {
    "text": "hopefully if it doesn't crash and we can go another look at it oh it's",
    "start": "1676860",
    "end": "1684580"
  },
  {
    "text": "currently updating that's why so it's not it's not a it's not at the state that weeks that terraform expects it to",
    "start": "1684580",
    "end": "1690280"
  },
  {
    "text": "be a terraform expects it to be at the state available so available to use and it will hold the connection open to that",
    "start": "1690280",
    "end": "1696310"
  },
  {
    "text": "until it's at that point because that's that's what we tell it to do",
    "start": "1696310",
    "end": "1701820"
  },
  {
    "text": "yeah you can see it's still updating and eventually you'll get a",
    "start": "1703260",
    "end": "1709110"
  },
  {
    "text": "configuration so I've used the same terraform module to deploy to two different connected streams so you can",
    "start": "1709110",
    "end": "1715660"
  },
  {
    "text": "see it's a really simple wrapper or a rod terraform that only just to pass code in before modules were created and",
    "start": "1715660",
    "end": "1721420"
  },
  {
    "text": "terraform you would have had to copy and paste all of that code okay I know we are hopping with copy and paste not like",
    "start": "1721420",
    "end": "1728530"
  },
  {
    "text": "that we're not definitely not like that and of course if I really wanted to deploy it to a different region I could",
    "start": "1728530",
    "end": "1734290"
  },
  {
    "text": "just change the region and it would go and would deploy my infrastructure to a different region",
    "start": "1734290",
    "end": "1739680"
  },
  {
    "text": "no I said to you that terraform uses graph theory",
    "start": "1739680",
    "end": "1746340"
  },
  {
    "text": "let's have a look at what that means I can run the command terraform graph go",
    "start": "1746340",
    "end": "1753670"
  },
  {
    "text": "off and graph all the pieces of my infrastructure and tell me the order and tell me how they relate to each other",
    "start": "1753670",
    "end": "1759580"
  },
  {
    "text": "and it looks like that that's garbage you can't read that",
    "start": "1759580",
    "end": "1764909"
  },
  {
    "text": "so this time we're actually gonna pipe it through a tiny application I'm really sorry I'm gonna",
    "start": "1772550",
    "end": "1779299"
  },
  {
    "text": "we're gonna pipe it through an application called Dom okay it's a tiny package since its Mac and we're gonna",
    "start": "1784040",
    "end": "1789780"
  },
  {
    "text": "save it as a PDF so that we can actually have a look at it and if I say Open Graph dot PDF we can see that Kinesis",
    "start": "1789780",
    "end": "1796710"
  },
  {
    "text": "stream depends on the provider AWS which depends because the module this is the module base right here it depends on the",
    "start": "1796710",
    "end": "1804480"
  },
  {
    "text": "overall infrastructure in AWS okay really it's not really growing breaking because there's no nodes interacting",
    "start": "1804480",
    "end": "1810750"
  },
  {
    "text": "with each other we'll have a look at that in a little bit when we start to build all that all the infrastructure together I",
    "start": "1810750",
    "end": "1817280"
  },
  {
    "text": "have 30 minutes this could be interesting so terraform destroy do you really want",
    "start": "1817280",
    "end": "1825180"
  },
  {
    "text": "to destroy yes we do and it will go off and it will turn on the infrastructure as we expect disposable environments",
    "start": "1825180",
    "end": "1831980"
  },
  {
    "text": "anyone have long running QA environments Holocaust they are they",
    "start": "1831980",
    "end": "1838520"
  },
  {
    "text": "how out of date are they more importantly right that's a it's a QA",
    "start": "1838520",
    "end": "1844200"
  },
  {
    "text": "worst nightmare when they have to like go and say hey can you like update our",
    "start": "1844200",
    "end": "1849300"
  },
  {
    "text": "environment we're like 18 security patches behind on Windows or it's been it's been telling us for a week that we",
    "start": "1849300",
    "end": "1855690"
  },
  {
    "text": "have to reboot your infrastructure can be brought up and destroyed at any time I understand that",
    "start": "1855690",
    "end": "1862230"
  },
  {
    "text": "I'm showing you stuff built into AWS but if you're in VMware or your V cloud or",
    "start": "1862230",
    "end": "1867330"
  },
  {
    "text": "your in Azure the same thing can happen it's all there it's all available and",
    "start": "1867330",
    "end": "1872340"
  },
  {
    "text": "then we can see we get a nice though I put at the bottom it says one destroyed zero chain Cyril added the apply is",
    "start": "1872340",
    "end": "1878460"
  },
  {
    "text": "complete it's like a black eye refresh and one of",
    "start": "1878460",
    "end": "1883920"
  },
  {
    "text": "them will disappear excellent that's terraform 101 we're gonna push on",
    "start": "1883920",
    "end": "1890510"
  },
  {
    "text": "let's kill that let's kill that",
    "start": "1892250",
    "end": "1898240"
  },
  {
    "text": "so I have a module for Kinesis I also want to store some information in an s3",
    "start": "1899169",
    "end": "1905270"
  },
  {
    "text": "bucket yeah anyone use lambda there are different ways that you can",
    "start": "1905270",
    "end": "1911390"
  },
  {
    "text": "use lambda okay one you can open up the editor and you can copy and paste the code directly into the code editor okay",
    "start": "1911390",
    "end": "1918020"
  },
  {
    "text": "- you can upload a zip file so if you package it locally or three and you can use an s3 bucket and it will work out",
    "start": "1918020",
    "end": "1924590"
  },
  {
    "text": "the difference based on the e-tag so based on the version of the s3 bucket object and it will update your lambda",
    "start": "1924590",
    "end": "1931429"
  },
  {
    "text": "configuration every time based on that so we have a really simple bucket I did",
    "start": "1931429",
    "end": "1938030"
  },
  {
    "text": "say this this module was simpler that's it",
    "start": "1938030",
    "end": "1944980"
  },
  {
    "text": "there's a bucket it has an ACL whether you want to force all the objects to be destroyed inside the bucket before you",
    "start": "1944980",
    "end": "1951620"
  },
  {
    "text": "delete the bucket and whether the versioning is enabled that's I",
    "start": "1951620",
    "end": "1957970"
  },
  {
    "text": "don't even think it gets simpler than that i-i'll struggle to find one that's easier I promise you so we have a lambda",
    "start": "1957970",
    "end": "1965390"
  },
  {
    "text": "we have a module for the bucket we declare our lambda function so this",
    "start": "1965390",
    "end": "1972260"
  },
  {
    "text": "is a new feature in terraform 0.7 where you declare data sources okay before",
    "start": "1972260",
    "end": "1978289"
  },
  {
    "text": "you'd have had to use template files and stuff like that now what it does is it will hold that as a data source and it",
    "start": "1978289",
    "end": "1984409"
  },
  {
    "text": "will allow you to share that data source between different pieces we still have this is our entire lambda function right",
    "start": "1984409",
    "end": "1992510"
  },
  {
    "text": "here this is thanks to an open source library from AWS labs that will allow",
    "start": "1992510",
    "end": "1998600"
  },
  {
    "text": "you to go and experiment with this so the copyright is all still there the license is still there but it basically",
    "start": "1998600",
    "end": "2004809"
  },
  {
    "text": "has three up it has three variables that we pass in okay the region in which the",
    "start": "2004809",
    "end": "2010419"
  },
  {
    "text": "the lambda needs to be deployed the elasticsearch endpoint that we actually",
    "start": "2010419",
    "end": "2015580"
  },
  {
    "text": "have to push the data to and lastly the index that we want to push data into an",
    "start": "2015580",
    "end": "2020890"
  },
  {
    "text": "elastic search okay everything else just just like simple no jail",
    "start": "2020890",
    "end": "2026250"
  },
  {
    "text": "actually it's not simple motives I can't read JavaScript so it could be doing anything for all I know if this was",
    "start": "2026250",
    "end": "2033130"
  },
  {
    "text": "paisa than I'd be as happy as anything but all it's doing right now is reading batches of information from Kinesis and",
    "start": "2033130",
    "end": "2040570"
  },
  {
    "text": "it's pushing them through this lambda and it's actually pushing them into",
    "start": "2040570",
    "end": "2045610"
  },
  {
    "text": "elastic search it's it's it's ingress and ingress and egress okay it's just",
    "start": "2045610",
    "end": "2051490"
  },
  {
    "text": "think of it as based on that so what we're doing is we're actually going to say hey go off to this template file",
    "start": "2051490",
    "end": "2057389"
  },
  {
    "text": "substitute in these variables and then that's then available to be used within",
    "start": "2057390",
    "end": "2063190"
  },
  {
    "text": "anything that actually needs that Jason in this case we're actually going to zip",
    "start": "2063190",
    "end": "2068530"
  },
  {
    "text": "the file up because we want to use the zip file in an s3 in order to deploy our",
    "start": "2068530",
    "end": "2073600"
  },
  {
    "text": "lambda so there is a little resource type called archive file which you pass some source content into but look we",
    "start": "2073600",
    "end": "2080889"
  },
  {
    "text": "have a really nice data interpolation here of data that template file that lambda function but the main thing is on",
    "start": "2080890",
    "end": "2088000"
  },
  {
    "text": "the end that rendered go off and render that template for me go build that",
    "start": "2088000",
    "end": "2093190"
  },
  {
    "text": "actual J's file and then save it as lambda that's it",
    "start": "2093190",
    "end": "2099390"
  },
  {
    "text": "and you'll see right here",
    "start": "2099390",
    "end": "2105300"
  },
  {
    "text": "Kinesis lambda is not J it's actually built it for us and if we look at it we",
    "start": "2105300",
    "end": "2111010"
  },
  {
    "text": "will have substituted in the variables I haven't done this this is doing it for me I promise you",
    "start": "2111010",
    "end": "2118170"
  },
  {
    "text": "so it builds it for us and it's a it's a load I'm specifically doing these out of",
    "start": "2118170",
    "end": "2124930"
  },
  {
    "text": "order because I'm going to show you how terrifying builds the graph the whole way through so right now we have a",
    "start": "2124930",
    "end": "2130780"
  },
  {
    "text": "Canisius tree we have an s3 bucket and we have a javascript template that we",
    "start": "2130780",
    "end": "2136960"
  },
  {
    "text": "want to do something with in this case we're actually going to upload that lambda source that Jas template file up",
    "start": "2136960",
    "end": "2143830"
  },
  {
    "text": "into an s3 bucket and just so that it's available in order to be ingested from",
    "start": "2143830",
    "end": "2150570"
  },
  {
    "text": "from lambda itself now the interesting thing the lambda",
    "start": "2150570",
    "end": "2157600"
  },
  {
    "text": "function lambda functions it took me a little while to get my head",
    "start": "2157600",
    "end": "2163060"
  },
  {
    "text": "around them to be totally honest with you okay because not only do you have to declare the resource but you also have",
    "start": "2163060",
    "end": "2168640"
  },
  {
    "text": "to use I am on it okay who like I am no one it's really complex it's really",
    "start": "2168640",
    "end": "2177760"
  },
  {
    "text": "horrible okay so for those that don't know what I am is I am as Identity and Access Management and AWS so it allows",
    "start": "2177760",
    "end": "2185190"
  },
  {
    "text": "different people and different processes access to different pieces of your infrastructure so for example an s3",
    "start": "2185190",
    "end": "2194050"
  },
  {
    "text": "bucket we ideally do not want that s3 bucket to be publicly available if it's",
    "start": "2194050",
    "end": "2199570"
  },
  {
    "text": "got sensitive information in it or if it's got some of our application code in it what we would like to do at that",
    "start": "2199570",
    "end": "2205300"
  },
  {
    "text": "point is we would like only specific access from either specific accounts or",
    "start": "2205300",
    "end": "2210670"
  },
  {
    "text": "specific nodes or specific services so like if we have an s3 bucket",
    "start": "2210670",
    "end": "2216790"
  },
  {
    "text": "that we're pushing code to the only thing that should be read out of that is maybe lambda okay so that's what I",
    "start": "2216790",
    "end": "2222070"
  },
  {
    "text": "that's what identity and access management is it's adjacent that's the best language for writing",
    "start": "2222070",
    "end": "2228130"
  },
  {
    "text": "stuff okay so what if we go and have a look up in the lambda function",
    "start": "2228130",
    "end": "2235320"
  },
  {
    "text": "we'll come back to that so the lambda function is really simple okay we declare an s3 bucket and s3 key we give",
    "start": "2236040",
    "end": "2242530"
  },
  {
    "text": "it a function name we give it the rule that needs access or that has to act on the lambda function itself and we have a",
    "start": "2242530",
    "end": "2249310"
  },
  {
    "text": "handler and a time ID now let's have a look at what the actual rule is firstly",
    "start": "2249310",
    "end": "2254800"
  },
  {
    "text": "you need a rule an overall rule that you can attach policies to so this is saying",
    "start": "2254800",
    "end": "2259930"
  },
  {
    "text": "that this specific function is for lambda so you have a principle and a",
    "start": "2259930",
    "end": "2265330"
  },
  {
    "text": "service which says that the actual lambda service is lambda on Amazon AWS",
    "start": "2265330",
    "end": "2270550"
  },
  {
    "text": "comm but we want to attach extra policies to this",
    "start": "2270550",
    "end": "2275790"
  },
  {
    "text": "so we want to attach es star I would never use star this is just a demo okay",
    "start": "2275790",
    "end": "2283440"
  },
  {
    "text": "you can have like yes describe yes get yes push all these different things I'm",
    "start": "2283440",
    "end": "2289270"
  },
  {
    "text": "just saying that lambda has accessed to do anything inside my elasticsearch cluster",
    "start": "2289270",
    "end": "2295350"
  },
  {
    "text": "it's probably not the best demo to give if you're gonna use my code don't do",
    "start": "2295350",
    "end": "2301690"
  },
  {
    "text": "that please don't but I also wanted to be able to do all bits and pieces of",
    "start": "2301690",
    "end": "2306910"
  },
  {
    "text": "Kinesis so we want to read from Kinesis we want to get from a read from Kinesis",
    "start": "2306910",
    "end": "2312190"
  },
  {
    "text": "we want to change the iterator and kinases and we also want to like list the shards and say Canisius to see what's available and what's not so you",
    "start": "2312190",
    "end": "2318940"
  },
  {
    "text": "attach that policy to the rule and we end up with and I am I",
    "start": "2318940",
    "end": "2328319"
  },
  {
    "text": "am for lambda and the permissions are as follows a s star Kinesis star on all",
    "start": "2333330",
    "end": "2341800"
  },
  {
    "text": "resources inside it ok so that's going on it's deployed it forth great",
    "start": "2341800",
    "end": "2347460"
  },
  {
    "text": "so now we have a lambda function okay that can read from Kinesis so we've",
    "start": "2350370",
    "end": "2356440"
  },
  {
    "text": "actually built most of our pipeline right now next we actually need to tell it",
    "start": "2356440",
    "end": "2363600"
  },
  {
    "text": "what's it reading from okay so you have to tell lambda what the data sources",
    "start": "2363600",
    "end": "2369510"
  },
  {
    "text": "data sources in R in AWS are things like DynamoDB",
    "start": "2369510",
    "end": "2374520"
  },
  {
    "text": "Kinesis redshift s3 buckets if you want to log",
    "start": "2374520",
    "end": "2380380"
  },
  {
    "text": "directly the s3 buckets that's fine as well but so you just give it in this case the error ends okay go off and give",
    "start": "2380380",
    "end": "2387250"
  },
  {
    "text": "it the AR m for the the Kinesis stream and give it also the lambda function error and and that's going to create the",
    "start": "2387250",
    "end": "2392320"
  },
  {
    "text": "link between them and we can go and have a look at well how that actually does that inside lambda",
    "start": "2392320",
    "end": "2398490"
  },
  {
    "text": "in my function",
    "start": "2398490",
    "end": "2402750"
  },
  {
    "text": "they can the triggers are there so you can see that the Islam the",
    "start": "2404290",
    "end": "2411220"
  },
  {
    "text": "function is connected to the Kinesis stream called log stream on this AR m and the batch size that we want to pull",
    "start": "2411220",
    "end": "2418180"
  },
  {
    "text": "from is a hundred and there are no records process because there's nothing in that function right now okay but you",
    "start": "2418180",
    "end": "2423670"
  },
  {
    "text": "can add triggers and you can do all sorts of stuff",
    "start": "2423670",
    "end": "2427170"
  },
  {
    "text": "no we get to the interesting bit elasticsearch who uses elasticsearch",
    "start": "2429810",
    "end": "2435300"
  },
  {
    "text": "not many not many a little bit okay elasticsearch can be a beast it can be",
    "start": "2435300",
    "end": "2442120"
  },
  {
    "text": "as difficult or as easy as you make it okay I love elasticsearch so much it makes my life really simple and what",
    "start": "2442120",
    "end": "2449560"
  },
  {
    "text": "makes my life even simpler no is the fact that Amazon have just released support for elasticsearch 2.3 that",
    "start": "2449560",
    "end": "2455620"
  },
  {
    "text": "happened last week I believe okay so that makes it like usable it was 1.5 up",
    "start": "2455620",
    "end": "2463570"
  },
  {
    "text": "until last week I don't know anyone that's still using like a pre elasticsearch to installation so this is",
    "start": "2463570",
    "end": "2470560"
  },
  {
    "text": "a good thing right now we'll come back to the ion policy in a sec",
    "start": "2470560",
    "end": "2476790"
  },
  {
    "text": "we're gonna declare a module for elastics elasticsearch we're gonna give it a name okay this case in this case",
    "start": "2476820",
    "end": "2483790"
  },
  {
    "text": "the name is NDC Sydney 2016 just to show that I've created one specifically for here we're",
    "start": "2483790",
    "end": "2491560"
  },
  {
    "text": "gonna give it a data note cont okay so the new functionality and elasticsearch",
    "start": "2491560",
    "end": "2497170"
  },
  {
    "text": "in AWS allows us to declare master nodes i'm data nodes in the same way you would put in production okay think of master",
    "start": "2497170",
    "end": "2503980"
  },
  {
    "text": "nodes as like as the entry point into your elasticsearch cluster okay those master nodes are like that they're the",
    "start": "2503980",
    "end": "2511810"
  },
  {
    "text": "dispatcher they're the ones that do all the work and the data nodes are just empty data stores that you just keep",
    "start": "2511810",
    "end": "2517030"
  },
  {
    "text": "attaching and as your data grows you just add more and more and more data stores in and attach them to the master",
    "start": "2517030",
    "end": "2522130"
  },
  {
    "text": "nodes okay we're not doing that this time just because i'm trying to keep it as simple as possible so we're just",
    "start": "2522130",
    "end": "2527200"
  },
  {
    "text": "going to say we just want one node 1 dana node we don't care about zone awareness so what that means is not a",
    "start": "2527200",
    "end": "2533590"
  },
  {
    "text": "little balanced ok if you wanted to load balanced you need to note",
    "start": "2533590",
    "end": "2538980"
  },
  {
    "text": "because that's the way load balancing works if you take one thing away take away",
    "start": "2538980",
    "end": "2545920"
  },
  {
    "text": "that load balancer needs more than one node and lastly we want some we want an",
    "start": "2545920",
    "end": "2551620"
  },
  {
    "text": "access policy the access policy is who can talk to your last exert instance I",
    "start": "2551620",
    "end": "2557260"
  },
  {
    "text": "decided to make this public and wide open so what I'm saying is is that all actions on",
    "start": "2557260",
    "end": "2563280"
  },
  {
    "text": "elasticsearch are available for anyone and they'd open yes okay so if you when",
    "start": "2563280",
    "end": "2570580"
  },
  {
    "text": "the output comes out the back if you really want to you can hit this URL you'll probably cost me money but that's",
    "start": "2570580",
    "end": "2576730"
  },
  {
    "text": "okay I'll take it back in beer tokens and then lastly we take an output of our",
    "start": "2576730",
    "end": "2583240"
  },
  {
    "text": "Cabana okay so there's module we have six modules",
    "start": "2583240",
    "end": "2591030"
  },
  {
    "text": "okay but inside each module we're doing lots of different things so let's graph our infrastructure right now okay",
    "start": "2591030",
    "end": "2597490"
  },
  {
    "text": "because the order in which this has been done is slightly different to how we would actually create our infrastructure",
    "start": "2597490",
    "end": "2603640"
  },
  {
    "text": "for example I have elasticsearch last that's probably the first thing that's",
    "start": "2603640",
    "end": "2608650"
  },
  {
    "text": "gonna be created in my infrastructure right now because other pieces of information have dependencies on it for example the lambda template has a",
    "start": "2608650",
    "end": "2615790"
  },
  {
    "text": "dependency on the elasticsearch note because it needs to grab the URL",
    "start": "2615790",
    "end": "2621060"
  },
  {
    "text": "so we can graph this infrastructure",
    "start": "2621060",
    "end": "2625350"
  },
  {
    "text": "it's not a make",
    "start": "2629690",
    "end": "2633109"
  },
  {
    "text": "oh it's not in trash no I don't want a good trash",
    "start": "2636180",
    "end": "2643309"
  },
  {
    "text": "it's definitely not in trash terraform dev there we go that's better",
    "start": "2643880",
    "end": "2651589"
  },
  {
    "text": "if we actually that's if we tariff on graph it first",
    "start": "2652670",
    "end": "2658010"
  },
  {
    "text": "we can see that it's pretty complex and it has a lot of different pieces okay",
    "start": "2658250",
    "end": "2663329"
  },
  {
    "text": "that's garbage excuse me yes yes",
    "start": "2663329",
    "end": "2669079"
  },
  {
    "text": "just because everyone as I say everyone likes I am and lastly if we just open",
    "start": "2669079",
    "end": "2675270"
  },
  {
    "text": "the grass we get a pretty picture okay because now we're actually building the",
    "start": "2675270",
    "end": "2681660"
  },
  {
    "text": "dependencies between our system so you start at the top and you work your way down terraform will work like what a",
    "start": "2681660",
    "end": "2688829"
  },
  {
    "text": "king because of that graph theory and it walks the tree every time it will work out what it needs to do first",
    "start": "2688829",
    "end": "2696890"
  },
  {
    "text": "okay and what has dependencies on each other so you can see that it's got the archive",
    "start": "2696890",
    "end": "2702809"
  },
  {
    "text": "file it's got the s3 book it's got the lambda function it's got the I am rule policy it's got a Canisius stream that",
    "start": "2702809",
    "end": "2707940"
  },
  {
    "text": "has no dependencies on anything else but the lambda event source mapping has a dependency on so on and so forth who",
    "start": "2707940",
    "end": "2714569"
  },
  {
    "text": "hates drawing who hates drawing at work why draw this can do it for you this is",
    "start": "2714569",
    "end": "2722880"
  },
  {
    "text": "what I tweeted and everyone was like wow it's serverless it's not server this it's not really support it's just using",
    "start": "2722880",
    "end": "2729690"
  },
  {
    "text": "pass but the main thing is is that this is living documentation",
    "start": "2729690",
    "end": "2736279"
  },
  {
    "text": "and if we terraform plan it will compare the state locally against what the state",
    "start": "2740609",
    "end": "2746859"
  },
  {
    "text": "is in AWS I'm really hopeful there's a lot not like it's gonna destroy my infrastructure right now but you can see",
    "start": "2746859",
    "end": "2753339"
  },
  {
    "text": "that it's going through it's going through the entire list and it's checking it one at a time and it should tell me",
    "start": "2753339",
    "end": "2758490"
  },
  {
    "text": "that there's maybe one change that's yes yes cuz I - changes oh well we'll skip",
    "start": "2758490",
    "end": "2766180"
  },
  {
    "text": "that one look what that is this a double yes",
    "start": "2766180",
    "end": "2772000"
  },
  {
    "text": "normalizes um the Jason for access policies and I amped so sometimes it sends back like an array will you pass",
    "start": "2772000",
    "end": "2778510"
  },
  {
    "text": "the string and sometimes it sends back a string where you passed an array with just one element inside it I haven't",
    "start": "2778510",
    "end": "2783700"
  },
  {
    "text": "cracked that part yet I will I promise but the main thing is I just renamed their earlier index dot handler",
    "start": "2783700",
    "end": "2789369"
  },
  {
    "text": "techniques Islam that yes not handler okay so it's going to tell us it's going to give us a deterministic view of what",
    "start": "2789369",
    "end": "2795309"
  },
  {
    "text": "it's going to change please if you're gonna use a technology I like this or an",
    "start": "2795309",
    "end": "2800500"
  },
  {
    "text": "infrastructure with code tool don't just blindly apply to your environment always always run a plan first so you",
    "start": "2800500",
    "end": "2808540"
  },
  {
    "text": "can see what it's going to change okay and what you can actually do is you can terraform plan right",
    "start": "2808540",
    "end": "2817470"
  },
  {
    "text": "Sydney demo txt and it will save that plan as text so that you can see in",
    "start": "2817710",
    "end": "2825190"
  },
  {
    "text": "github or whatever source control you use what it's going to do when you've",
    "start": "2825190",
    "end": "2830200"
  },
  {
    "text": "made those changes so if we go and have a look in AWS we can actually see if",
    "start": "2830200",
    "end": "2836140"
  },
  {
    "text": "this worked firstly I have a lambda function kinases es lambda",
    "start": "2836140",
    "end": "2844170"
  },
  {
    "text": "that has the configuration of index dot handler because that's what terraform told us it was going to change to",
    "start": "2844170",
    "end": "2850480"
  },
  {
    "text": "something else it has a role called I am for lambda which I showed you here I am",
    "start": "2850480",
    "end": "2856240"
  },
  {
    "text": "for lambda it has a trigger which it reads from a",
    "start": "2856240",
    "end": "2862240"
  },
  {
    "text": "Kinesis stream called log stream let's have a look and see if that's there",
    "start": "2862240",
    "end": "2868619"
  },
  {
    "text": "13 minutes and then no we're gonna a couple of figures log stream log stream",
    "start": "2870869",
    "end": "2876700"
  },
  {
    "text": "has five shards they're all open we can see all the different metrics that we've actually applied to it so that we can",
    "start": "2876700",
    "end": "2881920"
  },
  {
    "text": "get them inside code watch you want metrics metrics are a good metric of your friend",
    "start": "2881920",
    "end": "2887250"
  },
  {
    "text": "from there we have a function yep and then lastly",
    "start": "2887250",
    "end": "2893799"
  },
  {
    "text": "we have elastic search itself okay we have a domain of NDC Sydney 2016 elastic search 2.3 the best thing is it's a",
    "start": "2893799",
    "end": "2901450"
  },
  {
    "text": "green cluster it's only one node if it wasn't green I'd be slightly worried I actually have been really worried and it",
    "start": "2901450",
    "end": "2908109"
  },
  {
    "text": "wouldn't work but the main thing is if we go inside the cluster we can actually start to say hey look there's one node",
    "start": "2908109",
    "end": "2914079"
  },
  {
    "text": "so there's one day to note there's no charge because there's nothing in there right now we haven't pushed any data into it there's no indexes we're gonna",
    "start": "2914079",
    "end": "2921430"
  },
  {
    "text": "we're gonna force an index in right now if I open and cabaa okay we have the monitoring so cluster green cluster",
    "start": "2921430",
    "end": "2928779"
  },
  {
    "text": "yellow cluster red searchable documents node deleted documents metrics",
    "start": "2928779",
    "end": "2934740"
  },
  {
    "text": "and then lastly we can have a look at the access policy the access policy is what we declared we did it in a slightly",
    "start": "2934740",
    "end": "2942039"
  },
  {
    "text": "different way because we declared it as statements rather than Jason but it's going off and built the Jason for us",
    "start": "2942039",
    "end": "2947890"
  },
  {
    "text": "where we have the resource and we have the action and we can say everybody's allowed access to and you it has",
    "start": "2947890",
    "end": "2954970"
  },
  {
    "text": "templates if you really want it like copy some templates I actually copied the templates and",
    "start": "2954970",
    "end": "2962130"
  },
  {
    "text": "lastly we have an endpoint so our applications",
    "start": "2962339",
    "end": "2967420"
  },
  {
    "text": "know where to send our data to okay you need to if you want if you actually want to send some logs but more importantly",
    "start": "2967420",
    "end": "2973569"
  },
  {
    "text": "we have Cabana Cabana is a dashboard that allows you to visualize and search",
    "start": "2973569",
    "end": "2979660"
  },
  {
    "text": "documents inside your elastic search cluster this is bumbled and we actually can go and create our",
    "start": "2979660",
    "end": "2986680"
  },
  {
    "text": "index patterns okay so in written six really simple terraform modules that are",
    "start": "2986680",
    "end": "2993880"
  },
  {
    "text": "connected together in the graph we've deployed an entire loading infrastructure really simple how would you push data",
    "start": "2993880",
    "end": "3000990"
  },
  {
    "text": "into it I'll shoot me in a second now if we go back and have a look at the cluster it's going to be yellow because",
    "start": "3000990",
    "end": "3007150"
  },
  {
    "text": "we have an index and it's currently trying to allocate that index owed across its replicas and chart hopefully",
    "start": "3007150",
    "end": "3013989"
  },
  {
    "text": "it's yellow yes almost like practice this earlier",
    "start": "3013989",
    "end": "3019299"
  },
  {
    "text": "and we can go inside the indexes where there were none before and we can see that there's a dot cabana for there's",
    "start": "3019299",
    "end": "3025420"
  },
  {
    "text": "one and the size and bytes is this and it's got specific mappings okay serverless in action yes",
    "start": "3025420",
    "end": "3033569"
  },
  {
    "text": "no the codes all gonna make github I",
    "start": "3033569",
    "end": "3039130"
  },
  {
    "text": "promise I'll post it and hash tag up NDC certainly okay it you can go and have a look through it there's nothing in there",
    "start": "3039130",
    "end": "3045400"
  },
  {
    "text": "that's proprietary I'm probably gonna remove my AWS account ID hi I have left so many account IDs and",
    "start": "3045400",
    "end": "3052959"
  },
  {
    "text": "access keys on stuff I gave a talk in London a couple of months ago and I opened up an email the talk was being",
    "start": "3052959",
    "end": "3060219"
  },
  {
    "text": "recorded and everyone could see my username and password for a specific tool that I use error really bad so how",
    "start": "3060219",
    "end": "3067299"
  },
  {
    "text": "do you send information to Kinesis okay on your application server okay you can",
    "start": "3067299",
    "end": "3072940"
  },
  {
    "text": "use a lot you can use log stash you can use beets or something if you want to use log stash install the log stash",
    "start": "3072940",
    "end": "3078609"
  },
  {
    "text": "package and add those seven lines right there okay so you declare an output the output",
    "start": "3078609",
    "end": "3085690"
  },
  {
    "text": "is telling elastic error telling that log stash I want to send this data where",
    "start": "3085690",
    "end": "3090759"
  },
  {
    "text": "I'm reading it from to somewhere else it'll be the stream name it'll be the region and you'll send it as Jason",
    "start": "3090759",
    "end": "3097499"
  },
  {
    "text": "it doesn't get any simpler than that as long as a log stash output okay so",
    "start": "3097499",
    "end": "3102999"
  },
  {
    "text": "that's that's really key so the costs this is know where it gets interesting",
    "start": "3102999",
    "end": "3109259"
  },
  {
    "text": "so I told you before that my elasticsearch cluster alone was $25",
    "start": "3109259",
    "end": "3115979"
  },
  {
    "text": "approximately twenty five thousand dollars a month my entire logging infrastructure was thirty eight thousand",
    "start": "3115979",
    "end": "3122349"
  },
  {
    "text": "dollars a month okay it was pretty hefty okay I probably would have added some",
    "start": "3122349",
    "end": "3128199"
  },
  {
    "text": "more stuff to it just because I like like saying oh I manage infrastructure at scale it wasn't really at scale",
    "start": "3128199",
    "end": "3134260"
  },
  {
    "text": "it was it was causing more problems and it was worth so Kinesis streams are",
    "start": "3134260",
    "end": "3143460"
  },
  {
    "text": "0.15 US dollar for every minion put requests okay we have five shards five shards",
    "start": "3143520",
    "end": "3153480"
  },
  {
    "text": "will cost I'll come to that in a second five",
    "start": "3153480",
    "end": "3160360"
  },
  {
    "text": "shards are approximately like fifty something dollars a month its fact it's",
    "start": "3160360",
    "end": "3165850"
  },
  {
    "text": "fifty seven dollars sixty or five shards can handle 1.3 billion put",
    "start": "3165850",
    "end": "3172840"
  },
  {
    "text": "requests a month okay that's an input of 10 megabyte a second and a read of 20",
    "start": "3172840",
    "end": "3178750"
  },
  {
    "text": "megabyte a second okay if you're gonna use that that's pretty cheap for 1.3",
    "start": "3178750",
    "end": "3184900"
  },
  {
    "text": "billion messages a month ok Kinesis streams if we want to hold the data for",
    "start": "3184900",
    "end": "3192730"
  },
  {
    "text": "longer than the seven days it works out at 0.02 US dollars per day or per hour",
    "start": "3192730",
    "end": "3200320"
  },
  {
    "text": "excuse me so you would have to do it works at the extended data for seven",
    "start": "3200320",
    "end": "3206500"
  },
  {
    "text": "days works out to be $59 and 52 cents I can't really cheap you're probably not",
    "start": "3206500",
    "end": "3213400"
  },
  {
    "text": "going to need to spend that $50 because if you're still take if you're still having to read your log messages in",
    "start": "3213400",
    "end": "3218860"
  },
  {
    "text": "seven days time I'll reiterate you've got some problems or alternatively you probably shouldn't be",
    "start": "3218860",
    "end": "3225430"
  },
  {
    "text": "logging it because if it's not useful to you and you're not reading it why baller lambda lambda is 22 cents for every",
    "start": "3225430",
    "end": "3232870"
  },
  {
    "text": "million invocation queries so if we're going to push 1 million",
    "start": "3232870",
    "end": "3239590"
  },
  {
    "text": "messages through lambda a day its 22 cents US cents not Ozzie cents",
    "start": "3239590",
    "end": "3244710"
  },
  {
    "text": "elasticsearch is nine cents per hour per note cheap I'm using an m3 medium there so",
    "start": "3244710",
    "end": "3252280"
  },
  {
    "text": "it's a general-purpose machine that's got eight gig of ram and it's got a couple of processors it's enough in order to like churn through elastic",
    "start": "3252280",
    "end": "3258970"
  },
  {
    "text": "search queries and lastly if you want to add some EBS volumes the elastic search",
    "start": "3258970",
    "end": "3263980"
  },
  {
    "text": "to store you know if you I think by default it comes with a four gig SSD you",
    "start": "3263980",
    "end": "3269019"
  },
  {
    "text": "got anyone more data you're gonna need more size it works out to be thirteen and a half cents per gigabyte per month",
    "start": "3269019",
    "end": "3276359"
  },
  {
    "text": "with the entire logging infrastructure I have put together in this github repo so",
    "start": "3276359",
    "end": "3282339"
  },
  {
    "text": "I am assuming 1 million messages a day I'm assuming that I'm going to store the",
    "start": "3282339",
    "end": "3288819"
  },
  {
    "text": "Kinesis data for seven days just in case my data Lake needs to be filled from it because that's the new cool thing to do",
    "start": "3288819",
    "end": "3295779"
  },
  {
    "text": "I'm going to push a million invitations through lamda every day I'm gonna stick",
    "start": "3295779",
    "end": "3302470"
  },
  {
    "text": "with one node all right yes one node just because it's",
    "start": "3302470",
    "end": "3308470"
  },
  {
    "text": "a Deb setup or a local machine setup or you're just testing this out and I'm gonna add a hundred gig SSD a",
    "start": "3308470",
    "end": "3316019"
  },
  {
    "text": "general-purpose SSD to that machine the total cost is a hundred and",
    "start": "3316019",
    "end": "3321999"
  },
  {
    "text": "forty-four dollars eighty-seven a month I feel like a Salesman I feel like this is like amazing discoveries or something",
    "start": "3321999",
    "end": "3327819"
  },
  {
    "text": "right that is really cheap okay for being able to process a million load",
    "start": "3327819",
    "end": "3333700"
  },
  {
    "text": "messages a day as you're starting off at your company with centralized logging if you you can't tell me that you cannot",
    "start": "3333700",
    "end": "3342069"
  },
  {
    "text": "spend one hundred and forty-four dollars a day in fact you can cut out by 50 bucks because you don't need to they",
    "start": "3342069",
    "end": "3348099"
  },
  {
    "text": "extended lifetime I'm really trying to sell people this right this is ridiculous but it's so cheap it's like I",
    "start": "3348099",
    "end": "3355359"
  },
  {
    "text": "would spend that on coffee a month if I was out in London okay London's a really",
    "start": "3355359",
    "end": "3360519"
  },
  {
    "text": "expensive city and it's like six quid a day probably ten quid a day for coffee I'll have a couple I like caffeine I can",
    "start": "3360519",
    "end": "3368619"
  },
  {
    "text": "I can do that personally for my own personal projects we should all start using this type of technology all of",
    "start": "3368619",
    "end": "3376299"
  },
  {
    "text": "these hosted services are available I have used three hosted services in order",
    "start": "3376299",
    "end": "3383109"
  },
  {
    "text": "to process the same level of data that I had six middleman services to get the",
    "start": "3383109",
    "end": "3389319"
  },
  {
    "text": "data from my elastic from my application server to my elastic search cluster this",
    "start": "3389319",
    "end": "3395470"
  },
  {
    "text": "has it all you could probably productionize this for probably I reckon in the region of the books $400 a month",
    "start": "3395470",
    "end": "3401859"
  },
  {
    "text": "I posted this last night and somebody was like yeah a million messages a day it's not a lot I was like it is if you're",
    "start": "3401859",
    "end": "3408700"
  },
  {
    "text": "just getting started you don't really go and you're not going to want to go and spend twenty thousand",
    "start": "3408700",
    "end": "3415119"
  },
  {
    "text": "dollars a month right now because you're not going to use that start small let",
    "start": "3415119",
    "end": "3420940"
  },
  {
    "text": "your application infrastructure grow in the same way as your excuse me let your infrastructure architecture grow in the",
    "start": "3420940",
    "end": "3428080"
  },
  {
    "text": "same ways your application infrastructure that's in a jar we have this the fair decisions until later the",
    "start": "3428080",
    "end": "3434140"
  },
  {
    "text": "same thing happens here when you can use these hosted services you can grow them and you can add more nodes and you can",
    "start": "3434140",
    "end": "3441190"
  },
  {
    "text": "you know the nice thing about lambda is you don't have to go and tell lambda hey I'm going to protest a million requests",
    "start": "3441190",
    "end": "3447099"
  },
  {
    "text": "it's going to keep charging you for as much data as you push through it the same for Kinesis it's really cheap folks I",
    "start": "3447099",
    "end": "3454680"
  },
  {
    "text": "have two minutes forty seconds because anyone got any questions",
    "start": "3454680",
    "end": "3459810"
  },
  {
    "text": "the man at the back",
    "start": "3459810",
    "end": "3463290"
  },
  {
    "text": "can you just repeat it and really sorry",
    "start": "3470720",
    "end": "3474859"
  },
  {
    "text": "yep",
    "start": "3476030",
    "end": "3479030"
  },
  {
    "text": "interesting question so rather than using this you could use like Claude watch logs or something like that and I",
    "start": "3481250",
    "end": "3488480"
  },
  {
    "text": "would use this because I can push many pieces of information through it I can",
    "start": "3488480",
    "end": "3495690"
  },
  {
    "text": "push Claude watch logs into this so I can make my Claude watch logs searchable as well as my application logs I can",
    "start": "3495690",
    "end": "3502050"
  },
  {
    "text": "push metrics into this and then use something so have lambda omits that's",
    "start": "3502050",
    "end": "3507420"
  },
  {
    "text": "the event okay in order to push that to your metric server so this is like a they give us like a Swiss Army belt okay",
    "start": "3507420",
    "end": "3514980"
  },
  {
    "text": "you push Jason through it it's gonna stream it and it's gonna index it in elasticsearch no as you're starting in a",
    "start": "3514980",
    "end": "3523350"
  },
  {
    "text": "centralized logging infrastructure you're probably not going to know what you want to log okay but more",
    "start": "3523350",
    "end": "3529770"
  },
  {
    "text": "importantly you're going to want to know when you need to like expand your",
    "start": "3529770",
    "end": "3534930"
  },
  {
    "text": "infrastructure a war story on this is in our Redis infrastructure the first one",
    "start": "3534930",
    "end": "3540270"
  },
  {
    "text": "that I showed you an applicant going to say something rude",
    "start": "3540270",
    "end": "3545970"
  },
  {
    "text": "they're a developer I'm actually ddosed our own infrastructure okay because he didn't realize that he",
    "start": "3545970",
    "end": "3553050"
  },
  {
    "text": "had turned on trace debugging in his server so it was sending but the pieces",
    "start": "3553050",
    "end": "3560460"
  },
  {
    "text": "of information he was sending were like 20 megabyte log chunks so",
    "start": "3560460",
    "end": "3566779"
  },
  {
    "text": "the infrastructure that I built by hand and like loved like a china play and",
    "start": "3566990",
    "end": "3572670"
  },
  {
    "text": "glue and back together every so often wasn't able to cope with that this is much more designed to be a",
    "start": "3572670",
    "end": "3578640"
  },
  {
    "text": "little bit more elastic and it'll it'll churn through the data because it's you",
    "start": "3578640",
    "end": "3583740"
  },
  {
    "text": "know it's all platform as-a-service amazon are better at doing this stuff",
    "start": "3583740",
    "end": "3588870"
  },
  {
    "text": "than I am I trust them to get this right if there's if there's anybody that can",
    "start": "3588870",
    "end": "3594270"
  },
  {
    "text": "get it right it's probably AWS right so I would start with something that's",
    "start": "3594270",
    "end": "3599760"
  },
  {
    "text": "really simple and then if I need to change or any to push more data through it just keep growing and growing and",
    "start": "3599760",
    "end": "3605100"
  },
  {
    "text": "growing so a clogged wash logs are clogged watch log groups are a great way for your infrastructure in order to push",
    "start": "3605100",
    "end": "3610950"
  },
  {
    "text": "information in have you ever tried to use the Cline watch II why I",
    "start": "3610950",
    "end": "3616250"
  },
  {
    "text": "didn't say that simple good answer any other questions",
    "start": "3616250",
    "end": "3622910"
  },
  {
    "text": "what do I use to monitor my logging",
    "start": "3627590",
    "end": "3632360"
  },
  {
    "text": "um I've not run this specific thing in",
    "start": "3634130",
    "end": "3639450"
  },
  {
    "text": "production I used to use sensor big fan of sensor just because it's a pull based",
    "start": "3639450",
    "end": "3644850"
  },
  {
    "text": "architecture and I used before that I use nodule which was horrid so don't use",
    "start": "3644850",
    "end": "3651450"
  },
  {
    "text": "Nigel sorry if anyone you worked for Nigel but it's just really old and it's it's not designed to scale in the cloud",
    "start": "3651450",
    "end": "3657810"
  },
  {
    "text": "it's designed for like a constrained data center that has like a number of nodes that are known okay sensor is more",
    "start": "3657810",
    "end": "3664680"
  },
  {
    "text": "of a when a node comes up it checks in the sensor and says hey I'm a node of this type give me all the checks that I",
    "start": "3664680",
    "end": "3671970"
  },
  {
    "text": "should understand I should understand and it will perform them and send the data back there's a lot do you sense",
    "start": "3671970",
    "end": "3678600"
  },
  {
    "text": "it's probably my favorite one there are lots of other tools out there that you can use obviously I just find it really",
    "start": "3678600",
    "end": "3684540"
  },
  {
    "text": "simple really really simple any last questions you're all free to go thank you all very",
    "start": "3684540",
    "end": "3690480"
  },
  {
    "text": "much for your time enjoy the rest of the conference [Applause]",
    "start": "3690480",
    "end": "3697420"
  }
]
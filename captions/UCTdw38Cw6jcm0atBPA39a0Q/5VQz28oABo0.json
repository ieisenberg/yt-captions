[
  {
    "start": "0",
    "end": "85000"
  },
  {
    "text": "so okay hi everybody thank you for coming it's great uh just make sure uh you can",
    "start": "5520",
    "end": "10639"
  },
  {
    "text": "ask questions uh in the slack channel and drag four or you can do it in webex chat i'll be happy to answer those probably",
    "start": "10639",
    "end": "17279"
  },
  {
    "text": "towards the end of the talk so i don't get interrupted too much uh so hi my name is david i'm",
    "start": "17279",
    "end": "23199"
  },
  {
    "text": "the chief architect of bitcoins information protection systems we make cloud security software",
    "start": "23199",
    "end": "30560"
  },
  {
    "text": "and uh not trying to sell you our systems is just it's going to be very relevant to this",
    "start": "30560",
    "end": "35760"
  },
  {
    "text": "talk because pretty much everything i'm going to talk about uh in regards to distributed asynchronous microservices",
    "start": "35760",
    "end": "42079"
  },
  {
    "text": "it's stuff that we're either doing or implementing or trying to do uh at work and usually my talks are very",
    "start": "42079",
    "end": "48079"
  },
  {
    "text": "grounded in stuff that i'm doing in real life it's not theoretical at all it's usually uh based on in practical things that",
    "start": "48079",
    "end": "54480"
  },
  {
    "text": "we've done uh so today we're gonna be talking about asynchronous versus synchronous models of microservice systems",
    "start": "54480",
    "end": "60960"
  },
  {
    "text": "uh and why you would use one over the other what they actually mean what the tradeoffs are how to think about",
    "start": "60960",
    "end": "69520"
  },
  {
    "text": "concurrency and asynchronicity in stereo microservice systems i'm going to keep saying the word",
    "start": "69520",
    "end": "74640"
  },
  {
    "text": "microservices until it's uh or distributed so much it's going to lose meaning at some point for everybody it's just going",
    "start": "74640",
    "end": "80240"
  },
  {
    "text": "to be noise so yeah let's uh let's dive into it generally speaking let's talk about what",
    "start": "80240",
    "end": "86960"
  },
  {
    "start": "85000",
    "end": "85000"
  },
  {
    "text": "the difference really is between synchronous and asynchronous systems it's not that one is better than the other app one will make it clear both of",
    "start": "86960",
    "end": "93439"
  },
  {
    "text": "them are very legitimate uh design patterns and there are good reasons to use one or the other or a mix of both",
    "start": "93439",
    "end": "99439"
  },
  {
    "text": "um often times when you build a brand new system and you don't know exactly how it's",
    "start": "99439",
    "end": "105439"
  },
  {
    "text": "going to evolve it makes a lot of sense to use synchronous protocols to communicate between services http is of course by far the most common",
    "start": "105439",
    "end": "112159"
  },
  {
    "text": "that's basically the de facto standard if you want to have micro services you talk to each other it's usually going to be some form of http",
    "start": "112159",
    "end": "118799"
  },
  {
    "text": "uh if you need better performance and less overhead probably you'll do some",
    "start": "118799",
    "end": "123840"
  },
  {
    "text": "kind of grpc version or there are a few other synchronized ways for mac services to communicate",
    "start": "123840",
    "end": "129440"
  },
  {
    "text": "uh and obviously the the benefit of that is it's very straightforward there are excellent tools",
    "start": "129440",
    "end": "135280"
  },
  {
    "text": "um the observability which means you know figuring out when exceptions happen or figuring out",
    "start": "135280",
    "end": "140560"
  },
  {
    "text": "if something went wrong is much easier because the exception happens as part of the call it it's uh you can",
    "start": "140560",
    "end": "147680"
  },
  {
    "text": "find all of the logged for exceptions in the same small time space space of time and logs",
    "start": "147680",
    "end": "153760"
  },
  {
    "text": "and you can handle errors synchronously in line for example if you have a web client it will get the",
    "start": "153760",
    "end": "158800"
  },
  {
    "text": "exception immediately to any operations and you can show an exception to the error to the user and stuff like that um",
    "start": "158800",
    "end": "165440"
  },
  {
    "text": "and and the failure modes are well understood because we've had synchronous systems for a very long time now the",
    "start": "165440",
    "end": "171599"
  },
  {
    "text": "bigger problem with that kind of system is it introduces a lot of temporal coupling between different components",
    "start": "171599",
    "end": "177519"
  },
  {
    "text": "and what i mean by that is uh if a particular dependency of our microservice system",
    "start": "177519",
    "end": "182959"
  },
  {
    "text": "is currently not available for example a database is down where a service is a process fell",
    "start": "182959",
    "end": "189360"
  },
  {
    "text": "and the load balancer has still hasn't switched over to a different one then that failure propagates through the",
    "start": "189360",
    "end": "195920"
  },
  {
    "text": "entire system right so if you have a set of microservices each cold on each other yeah if you guys could mute that would",
    "start": "195920",
    "end": "202000"
  },
  {
    "text": "be very good uh so if you have a couple of microservices calling each other the lowest dependency will if it goes uh",
    "start": "202000",
    "end": "209599"
  },
  {
    "text": "down it will actually take down the entire chain of services with it on the other hand uh when we talk about",
    "start": "209599",
    "end": "216080"
  },
  {
    "text": "asynchronous systems usually there's some kind of queue or buffer involved between the different systems",
    "start": "216080",
    "end": "221599"
  },
  {
    "text": "uh so services don't talk each other to each other directly they talk to some kind of message transport or queue and the",
    "start": "221599",
    "end": "228319"
  },
  {
    "text": "component on the other side of that transport will read the message whenever it feels like maybe very very",
    "start": "228319",
    "end": "234239"
  },
  {
    "text": "quickly maybe an hour from now and so a lot of time those would be data right",
    "start": "234239",
    "end": "241040"
  },
  {
    "text": "oriented systems we have to perform a lot of writes or updates um and those systems break up the temporal",
    "start": "241040",
    "end": "246959"
  },
  {
    "text": "coupling uh which means a service could be down but not affect any of the upstream or downstream dependencies because",
    "start": "246959",
    "end": "253920"
  },
  {
    "text": "all of those dependencies can continue working and eventually one service will recover and process",
    "start": "253920",
    "end": "259440"
  },
  {
    "text": "whatever few messages were queued up the bigger issue introduces usually is high",
    "start": "259440",
    "end": "266000"
  },
  {
    "text": "complexity because there is no temporal coupling any errors get actually spread out over",
    "start": "266000",
    "end": "272000"
  },
  {
    "text": "time right so the service went down and it went down because something that a different service did that",
    "start": "272000",
    "end": "277280"
  },
  {
    "text": "that is you know three hops away from it in the microsystem you might find block messages and spread",
    "start": "277280",
    "end": "282720"
  },
  {
    "text": "that apart an hour or more both of which let you actually debug this error uh",
    "start": "282720",
    "end": "288479"
  },
  {
    "text": "but the the uptime or the upside of actually using aging systems is usually they're more resilient they're easier to",
    "start": "288479",
    "end": "294479"
  },
  {
    "text": "scale because uh they're better than they're decoupled better than uh signaling systems",
    "start": "294479",
    "end": "299600"
  },
  {
    "text": "so that's broadly what we're gonna talk about and you know throughout this talk we'll actually dig into um the",
    "start": "299600",
    "end": "305440"
  },
  {
    "text": "reasons to choose one over the other and some useful patterns uh for asynchronous systems",
    "start": "305440",
    "end": "311360"
  },
  {
    "text": "and how to think about uh the reasons for switching right and so why would you actually go from one to the other the biggest one is",
    "start": "311360",
    "end": "317759"
  },
  {
    "start": "315000",
    "end": "315000"
  },
  {
    "text": "like i said the temporal coupling as a system grows i'm not talking about one",
    "start": "317759",
    "end": "324000"
  },
  {
    "text": "or two micro services it's not really meaningful there but for example uh the system i mostly work on which is proof points",
    "start": "324000",
    "end": "330320"
  },
  {
    "text": "cloud security product we're at over 100 micro services right now and it keeps growing because we have a large team of",
    "start": "330320",
    "end": "336080"
  },
  {
    "text": "people working on this it's a very complex system uh and breaking apart the temporal coupling between different",
    "start": "336080",
    "end": "342240"
  },
  {
    "text": "services which means if one service goes down it takes out a bunch of other services that depend on it that was a very large",
    "start": "342240",
    "end": "348080"
  },
  {
    "text": "part of why we completely switched from synchronous modes of communication to asynchronous ones",
    "start": "348080",
    "end": "353120"
  },
  {
    "text": "and of course scale which is really a consequence of that is another the different failure modes",
    "start": "353120",
    "end": "360160"
  },
  {
    "text": "and we'll talk about this at length is going from synchronous to sickness",
    "start": "360160",
    "end": "365840"
  },
  {
    "text": "basically replaces lack of availability or system being down with latency so an operation will",
    "start": "365840",
    "end": "372720"
  },
  {
    "text": "eventually happen but it's going to take time for the faults to resolve itself and of course there are different ways",
    "start": "372720",
    "end": "378479"
  },
  {
    "text": "of doing uh crud and a lot of the reactive uh patterns in",
    "start": "378479",
    "end": "384080"
  },
  {
    "text": "in programming we have today uh rxjs a bunch of other reactive frameworks they're all very strongly oriented",
    "start": "384080",
    "end": "390560"
  },
  {
    "text": "towards asynchronous message buffering systems right but the biggest",
    "start": "390560",
    "end": "395680"
  },
  {
    "start": "395000",
    "end": "395000"
  },
  {
    "text": "biggest reason of course is breaking up the temporal coupling and resolving different failure modes",
    "start": "395680",
    "end": "401759"
  },
  {
    "text": "and for do you understand really the core tradeoff between synchronous and aging systems is let's look at this diagram",
    "start": "401759",
    "end": "409520"
  },
  {
    "text": "let's imagine we have two services uh we have a client service we have a server service so to speak and it has",
    "start": "409520",
    "end": "416000"
  },
  {
    "text": "some kind of database or data store attached to each one of them and let's imagine the scenario where",
    "start": "416000",
    "end": "421440"
  },
  {
    "text": "where the database goes out so what happens in the synchronous uh service versus what happens in the",
    "start": "421440",
    "end": "427280"
  },
  {
    "text": "asynchronous one in the synchronous service of course the service that depends on the database synchronously meaning it writes the",
    "start": "427280",
    "end": "433680"
  },
  {
    "text": "database directly or reads from database directly is of course always also down right because it its own",
    "start": "433680",
    "end": "439520"
  },
  {
    "text": "purpose to exist is to do stuff with database it's a sort of a crowd service and so if the",
    "start": "439520",
    "end": "444880"
  },
  {
    "text": "database is unavailable that means the backend service is also unavailable uh with the asynchronous model that's",
    "start": "444880",
    "end": "450639"
  },
  {
    "text": "not the case because the html async service buffers the rights in some magical place which we're not going to",
    "start": "450639",
    "end": "456800"
  },
  {
    "text": "talk about right now but we will get to a little bit but for now work with me let's imagine you know there's some magic that happens",
    "start": "456800",
    "end": "463039"
  },
  {
    "text": "and the asynchronous backend service puts its data somewhere and then eventually it gets to",
    "start": "463039",
    "end": "468479"
  },
  {
    "text": "the database and we'll talk about the somewhere uh at length right but just because database went out doesn't mean the",
    "start": "468479",
    "end": "473520"
  },
  {
    "text": "service is down you can still talk to the service and still fulfill its function so right there we're trading",
    "start": "473520",
    "end": "478960"
  },
  {
    "text": "um some of the consistency of the service which means it doesn't uh write write data to the database",
    "start": "478960",
    "end": "484800"
  },
  {
    "text": "immediately it will write it there eventually but we're trading it for availability which means the service continues being",
    "start": "484800",
    "end": "490319"
  },
  {
    "text": "up and functioning and of course in the async mode the client service is",
    "start": "490319",
    "end": "495680"
  },
  {
    "text": "always up because again it also talks to the backend service asynchronously and so the fact that a database two hops",
    "start": "495680",
    "end": "501360"
  },
  {
    "text": "away went down doesn't affect just availability so this would give a much better uh user experience for example if this was",
    "start": "501360",
    "end": "507680"
  },
  {
    "text": "a ui application or any kind of service with the synchronous mode we're not actually sure what the status",
    "start": "507680",
    "end": "514320"
  },
  {
    "text": "of the client service would be um it might get an exception from the backend service it might also be down if it's a good",
    "start": "514320",
    "end": "521360"
  },
  {
    "text": "application depends how you write it it might you know hang or throw an exception so basically",
    "start": "521360",
    "end": "526959"
  },
  {
    "text": "a downstream dependency going down will strongly affect the entire cold chain of the synchronous",
    "start": "526959",
    "end": "532000"
  },
  {
    "text": "mode whereas with asynchronous obviously you maintain functionality unfortunately what that means is of",
    "start": "532000",
    "end": "537200"
  },
  {
    "text": "course what you're doing is you're introducing latency instead of an exception right so you were trading",
    "start": "537200",
    "end": "542240"
  },
  {
    "text": "one failure mode mode which is an availability for a different failure mode which is latency this is going to be at the core",
    "start": "542240",
    "end": "548880"
  },
  {
    "text": "of the reason of why we choose synchronous over asynchronous or the other way around uh what failure modes would actually",
    "start": "548880",
    "end": "555440"
  },
  {
    "text": "prefer and for different applications different failure modes make sense right so for google applications where you want to",
    "start": "555440",
    "end": "561200"
  },
  {
    "text": "if you want to make the error appearance to the user immediately you might choose something that is",
    "start": "561200",
    "end": "566640"
  },
  {
    "text": "actually synchronous and then let the user handle the exception for standalone applications uh as an",
    "start": "566640",
    "end": "571680"
  },
  {
    "text": "example our system the proof on casb most of the data comes into the system",
    "start": "571680",
    "end": "576800"
  },
  {
    "text": "from automated systems from uh some scheduled jobs which go to uh cloud providers and bring in",
    "start": "576800",
    "end": "582080"
  },
  {
    "text": "information about user activity uh and all that stuff is standalone so there's no person to click okay on an",
    "start": "582080",
    "end": "587440"
  },
  {
    "text": "error message so all of that in this case we strongly prefer to incur latency and just handle the",
    "start": "587440",
    "end": "593680"
  },
  {
    "text": "workload later over the system just being unavailable and missing a lot of data because it will not be repeated right",
    "start": "593680",
    "end": "600080"
  },
  {
    "text": "so that's that's that there there gives you the reasoning of why you would choose one over the other",
    "start": "600080",
    "end": "605200"
  },
  {
    "text": "in a client application we will likely especially for the read path which we'll talk about a bit later you will probably pick a synchronous",
    "start": "605200",
    "end": "611519"
  },
  {
    "text": "mode of operation so that you can actually present the error to the user quickly and",
    "start": "611519",
    "end": "616640"
  },
  {
    "text": "let them handle it in a standalone application or something that receives data that can't be repeated you",
    "start": "616640",
    "end": "622560"
  },
  {
    "text": "will likely choose uh async modes because they let you persist data and handle it",
    "start": "622560",
    "end": "627839"
  },
  {
    "text": "after the failure resulted right and so this uh really brings us to one of the bigger",
    "start": "627839",
    "end": "636160"
  },
  {
    "start": "633000",
    "end": "633000"
  },
  {
    "text": "topics in usually industrial databases anyone who's actually done any kind of work with",
    "start": "636160",
    "end": "641920"
  },
  {
    "text": "nosql databases distributed systems almost certainly ran across the cap theorem um cap theorem which uh was proposed by",
    "start": "641920",
    "end": "649680"
  },
  {
    "text": "eric brewer a computer scientist from berkeley and then proven formally as a theorem a few years later",
    "start": "649680",
    "end": "657120"
  },
  {
    "text": "um what it says is specifically talked about distributed databases but if we think about microservices as",
    "start": "657120",
    "end": "664240"
  },
  {
    "text": "front-ends for different data stores or just of themselves it can also somewhat apply to microservices and i'll",
    "start": "664240",
    "end": "670640"
  },
  {
    "text": "explain how in just a bit but basically the the cap theorem says for any distributed",
    "start": "670640",
    "end": "676640"
  },
  {
    "text": "database or distributed system uh it can provide at most two out of the",
    "start": "676640",
    "end": "681920"
  },
  {
    "text": "three guarantees uh like as follows consistency so every read from the",
    "start": "681920",
    "end": "687440"
  },
  {
    "text": "system receives the most recent uh version of the data or an error so if you can imagine uh",
    "start": "687440",
    "end": "695600"
  },
  {
    "text": "if it's a service that runs a database you write something into your database you read it back immediately and you get",
    "start": "695600",
    "end": "700959"
  },
  {
    "text": "the version you wrote availability which in this case means that every request to the system",
    "start": "700959",
    "end": "706320"
  },
  {
    "text": "receives a valid non-error response right it doesn't have to be current it doesn't have to be",
    "start": "706320",
    "end": "711440"
  },
  {
    "text": "updated but it has to get in the response that's not a timeout or an error that that's the definition of",
    "start": "711440",
    "end": "716480"
  },
  {
    "text": "availability for cap theory and partition tolerance which means that the system can continue to function",
    "start": "716480",
    "end": "722079"
  },
  {
    "text": "despite losing an arbitrary number of messages or delaying messages between",
    "start": "722079",
    "end": "727120"
  },
  {
    "text": "network nodes now if you think about modern systems the real trade-off here is always between consistency and",
    "start": "727120",
    "end": "733440"
  },
  {
    "text": "availability because a system which doesn't have partition tolerance a distributed system without",
    "start": "733440",
    "end": "738800"
  },
  {
    "text": "prediction tolerance is not really a practical production system right if you don't if it has an undefined behavior uh because it",
    "start": "738800",
    "end": "746240"
  },
  {
    "text": "loses network packets or messages that system is not robust and you're not going to really put it in production so",
    "start": "746240",
    "end": "751760"
  },
  {
    "text": "for practical purposes in real life we get to pick between a system that's either petition tolerant and strongly",
    "start": "751760",
    "end": "757279"
  },
  {
    "text": "consistent or some kind of consistent or it's position tolerant and highly available but not both at the",
    "start": "757279",
    "end": "763680"
  },
  {
    "text": "same time now notice that the word at the same time here is very important a system can be one or the other at different times and",
    "start": "763680",
    "end": "770800"
  },
  {
    "text": "flip between those two according to exceptions or configuration uh but at any given moment uh that's the",
    "start": "770800",
    "end": "777120"
  },
  {
    "text": "way it works so uh to demonstrate it um i usually do this in in person so it's usually a quiz and",
    "start": "777120",
    "end": "784560"
  },
  {
    "text": "people can raise their hands and stuff so we'll see if this works virtually so think about a bank machine an atm",
    "start": "784560",
    "end": "790720"
  },
  {
    "text": "or whatever uh it's called in english um you go to a bank there's a teller bank",
    "start": "790720",
    "end": "796560"
  },
  {
    "text": "machine at the wall you want to withdraw some money and there's three different machines right and just as you go through",
    "start": "796560",
    "end": "802560"
  },
  {
    "text": "withdraw money what happens is the bank loses network connection to the main computer the mainframe",
    "start": "802560",
    "end": "808160"
  },
  {
    "text": "so uh now this atm doesn't have a network connection and you try to withdraw money what's gonna happen right so one of two things is going to",
    "start": "808160",
    "end": "814720"
  },
  {
    "text": "happen either it will let you withdraw some money but then it won't be able to update the backend system until connection resumes",
    "start": "814720",
    "end": "820720"
  },
  {
    "text": "or it will not let you withdraw any money which means either it's an available system and then you can continue using it and",
    "start": "820720",
    "end": "826079"
  },
  {
    "text": "you get a valid response in this case the response is money or it's a consistent system you go to it and you receive and uh you",
    "start": "826079",
    "end": "832720"
  },
  {
    "text": "don't get the latest result you can't update the system but you uh but it doesn't actually",
    "start": "832720",
    "end": "838079"
  },
  {
    "text": "create an inconsistent inconsistency between the mac machine and your actual bank account so who thinks",
    "start": "838079",
    "end": "844160"
  },
  {
    "text": "banks would put up a consistent system for atm machines raise your hands i can't see you but you",
    "start": "844160",
    "end": "850160"
  },
  {
    "text": "can raise your hands see one person thinks excellent thank you very much so who thinks it's actually going to be an",
    "start": "850160",
    "end": "855440"
  },
  {
    "text": "available system which means they will prefer um user experience to let you continue using the bank and withdrawing money",
    "start": "855440",
    "end": "861760"
  },
  {
    "text": "over consistency anybody okay so uh so i can see how many",
    "start": "861760",
    "end": "868720"
  },
  {
    "text": "people at one person i saw one person book but i can see the rest of you so i'll just tell you the answer for",
    "start": "868720",
    "end": "874079"
  },
  {
    "text": "most banks and again it varies with the different countries and there's some regulations which affect it but for most banks they will",
    "start": "874079",
    "end": "880720"
  },
  {
    "text": "actually prefer to let you withdraw money so an atm which lost network connectivity will still dispense money",
    "start": "880720",
    "end": "886560"
  },
  {
    "text": "up to a certain limit the the limit obviously depends on what kind of uh account you have and what bank and stuff",
    "start": "886560",
    "end": "892399"
  },
  {
    "text": "but it will let you keep growing money um of course it doesn't really happen very often in real life how often does a bank",
    "start": "892399",
    "end": "898720"
  },
  {
    "text": "with network connection but a long time ago it used to happen quite a bit um and there were actually very famous",
    "start": "898720",
    "end": "905600"
  },
  {
    "text": "attacks on banks where a person was able to to disrupt the network connection and withdraw money from a bunch of machines",
    "start": "905600",
    "end": "911760"
  },
  {
    "text": "in a row um but normally what will happen is you can withdraw money if if it means",
    "start": "911760",
    "end": "917839"
  },
  {
    "text": "that your bank account will go negative that's actually not a bad thing most banks will let you go into a negative",
    "start": "917839",
    "end": "923600"
  },
  {
    "text": "balance because they can then charge your interest on the negative balance and it's for the to the bank's advantage and so they",
    "start": "923600",
    "end": "928959"
  },
  {
    "text": "prefer uh user experience over consistency um but that that's just to demonstrate",
    "start": "928959",
    "end": "934639"
  },
  {
    "text": "the trade-offs you make in consistency availability and if you were to now design a bank machine system with",
    "start": "934639",
    "end": "940800"
  },
  {
    "text": "microservices you would have to think of what do you do in every failure scenario in this case all right so that's that's broadly speaking the",
    "start": "940800",
    "end": "947600"
  },
  {
    "text": "cap theorem and the way it applies to microservices of course is again um we have to split up",
    "start": "947600",
    "end": "953120"
  },
  {
    "text": "the read path and the right path so when you write your system um if you want the read which means you",
    "start": "953120",
    "end": "959759"
  },
  {
    "text": "have a ui application that's very important for it to be consistent you might choose a synchronous system which will go and update a database",
    "start": "959759",
    "end": "966079"
  },
  {
    "text": "and then if you refresh the page or somebody else uses this information it will be available",
    "start": "966079",
    "end": "971519"
  },
  {
    "text": "immediately it will be consistent with whatever you wrote uh versus an available system where you will possibly queue up or buffer",
    "start": "971519",
    "end": "978240"
  },
  {
    "text": "right to the system uh and so if you can't write at that moment they will",
    "start": "978240",
    "end": "983759"
  },
  {
    "text": "eventually get written but that means that uh the user or whoever reads the data will get an inconsistent a stale view of",
    "start": "983759",
    "end": "990800"
  },
  {
    "text": "the system okay and that's that's our trade-off right and so i keep saying queue up or right to this magical place",
    "start": "990800",
    "end": "998320"
  },
  {
    "start": "994000",
    "end": "994000"
  },
  {
    "text": "without explaining what a magical place is so it's time to talk about where would you actually put it it's obviously not another secret and i'm",
    "start": "998320",
    "end": "1004240"
  },
  {
    "text": "sure everyone thought of it they're we're all familiar with cues and various message transports um but overall and",
    "start": "1004240",
    "end": "1012160"
  },
  {
    "text": "i'm not going to talk about a specific vendor or specific technology they're broadly uh we'll talk about use cases and broad",
    "start": "1012160",
    "end": "1019120"
  },
  {
    "text": "categories of cues but not you know if specific technology um but broadly a systems asynchronous",
    "start": "1019120",
    "end": "1026798"
  },
  {
    "text": "system designs assume that the message transport they use to send messages between services",
    "start": "1026799",
    "end": "1031839"
  },
  {
    "text": "is reliable and robust this is like the journey level secret each of the systems aren't inhere",
    "start": "1031839",
    "end": "1037199"
  },
  {
    "text": "inherently more highly available it's just you move the availability or",
    "start": "1037199",
    "end": "1042558"
  },
  {
    "text": "the the failure point to one central system which is your message transport",
    "start": "1042559",
    "end": "1047600"
  },
  {
    "text": "and then you put a lot of effort into making that as robust and available as possible instead of making each individual",
    "start": "1047600",
    "end": "1053200"
  },
  {
    "text": "service or each individual component as robust as possible so overall if your",
    "start": "1053200",
    "end": "1058240"
  },
  {
    "text": "message transport goes down the entire system is still going to go down right unless you build some kind of",
    "start": "1058240",
    "end": "1063360"
  },
  {
    "text": "hybrid very complex system which is not something i've ever seen in practice in real life",
    "start": "1063360",
    "end": "1068480"
  },
  {
    "text": "um but yeah you have to assume that the message transport is reliable",
    "start": "1068480",
    "end": "1073760"
  },
  {
    "text": "which means talking to it is consistent or at least durable unless of course data loss is",
    "start": "1073760",
    "end": "1079760"
  },
  {
    "text": "acceptable and that's not a joke there are systems where data loss is actually perfectly acceptable systems that look at for example the",
    "start": "1079760",
    "end": "1086559"
  },
  {
    "text": "latest snapshot is the state of data or statistics for example think about the trivial example is stock ticker",
    "start": "1086559",
    "end": "1093280"
  },
  {
    "text": "right i don't care usually uh to show the history of all the stocks i want to see the lightest price and if i missed you know five or six",
    "start": "1093280",
    "end": "1099840"
  },
  {
    "text": "updates i'll just show the next update and it's fine right so there's going to be a slight delay and so in that case",
    "start": "1099840",
    "end": "1105600"
  },
  {
    "text": "asynchronous lossy system is okay but for most practical applications when you're",
    "start": "1105600",
    "end": "1110720"
  },
  {
    "text": "thinking about your real world production systems data loss is not really acceptable and",
    "start": "1110720",
    "end": "1116000"
  },
  {
    "text": "so we kind of have to assume that message transports are and this is actually true for most of them because almost every messaging",
    "start": "1116000",
    "end": "1121520"
  },
  {
    "text": "technology that's you know used in use and popular today has built-in redundancy and replication",
    "start": "1121520",
    "end": "1128160"
  },
  {
    "text": "and a lot of features around guaranteeing uh durability and and you know",
    "start": "1128160",
    "end": "1133200"
  },
  {
    "text": "reliable delivery of data a lot of them are sas systems right so if you're on kind",
    "start": "1133200",
    "end": "1139120"
  },
  {
    "text": "of public cloud every single public cloud has their own offering or multiple offerings really amazon has",
    "start": "1139120",
    "end": "1145600"
  },
  {
    "text": "kinesis and sqs and sns and azure has event hubs and google has",
    "start": "1145600",
    "end": "1150960"
  },
  {
    "text": "a thing which i can't remember the name of but every everyone offers one of those and all the big vendors have their own",
    "start": "1150960",
    "end": "1157360"
  },
  {
    "text": "cloud offerings so if you're building a new system you don't really need to put in that much effort into making it",
    "start": "1157360",
    "end": "1163280"
  },
  {
    "text": "available you can just buy that from someone obviously by paying lots of money um so uh that let's assume that our",
    "start": "1163280",
    "end": "1170400"
  },
  {
    "text": "transport is in fact available and robust and let's talk about what we can do with it right so now that we've",
    "start": "1170400",
    "end": "1175760"
  },
  {
    "start": "1174000",
    "end": "1174000"
  },
  {
    "text": "sort of established that in the case where we want our system to be asynchronous or some part of our system",
    "start": "1175760",
    "end": "1181280"
  },
  {
    "text": "to be a certainness and we will later on talk about how to make a hybrid synchronous versus asynchronous system",
    "start": "1181280",
    "end": "1187120"
  },
  {
    "text": "and where it makes sense there are some patterns which help us just like there are design patterns in",
    "start": "1187120",
    "end": "1193280"
  },
  {
    "text": "coding which which cover a lot of common use cases in asynchronous messaging patterns there are standard",
    "start": "1193280",
    "end": "1199200"
  },
  {
    "text": "design patterns which you can apply to your system it will go through them real quick",
    "start": "1199200",
    "end": "1204960"
  },
  {
    "text": "the easiest and most uh common is fire and forget is where you post a message to some",
    "start": "1204960",
    "end": "1212159"
  },
  {
    "start": "1205000",
    "end": "1205000"
  },
  {
    "text": "queue you don't expect a response and you you do if you want the transport to be reliable",
    "start": "1212159",
    "end": "1217919"
  },
  {
    "text": "you do response i expect an acknowledgement from the transported senate itself but not from whoever receives the message on",
    "start": "1217919",
    "end": "1224480"
  },
  {
    "text": "the other side so in a trivial example uh so at proofpoint we use kafka for most things um so a kafka producer what",
    "start": "1224480",
    "end": "1232799"
  },
  {
    "text": "it does is it writes a message to a topic and then it commits",
    "start": "1232799",
    "end": "1237840"
  },
  {
    "text": "the uh then it waits for the topic for the broker to respond and say that yeah it's message been durably committed",
    "start": "1237840",
    "end": "1243440"
  },
  {
    "text": "and only then it moves on you don't just move on and assume the message has been passed but it doesn't wait for the",
    "start": "1243440",
    "end": "1248559"
  },
  {
    "text": "acknowledgement from whoever consumes the message on the other side of the queue because that's not far and forget that's",
    "start": "1248559",
    "end": "1254480"
  },
  {
    "text": "the next pattern we'll talk about um so that's actually very useful most of this is very useful",
    "start": "1254480",
    "end": "1260240"
  },
  {
    "text": "in data processing pipelines uh so again the products i worked on a lot uh the",
    "start": "1260240",
    "end": "1265280"
  },
  {
    "text": "proof from casbi is basically just a giant pipe which moves data from one side to the other and does",
    "start": "1265280",
    "end": "1270400"
  },
  {
    "text": "various different transformations with it along the way and it's built just as a series of these kind of drawings we have a service",
    "start": "1270400",
    "end": "1276640"
  },
  {
    "text": "which gets data does something with it puts it in the queue but on the other side of the queue a different service",
    "start": "1276640",
    "end": "1282159"
  },
  {
    "text": "which gets the data does something puts it in a different queue and it doesn't expect a response back and it doesn't send anything back",
    "start": "1282159",
    "end": "1287760"
  },
  {
    "text": "data just moves downstream from one to the other until it reaches some end point uh usually a database",
    "start": "1287760",
    "end": "1293039"
  },
  {
    "text": "right and so this is this is by far the most common most useful pattern in hdmi communications we have",
    "start": "1293039",
    "end": "1298159"
  },
  {
    "text": "um it's also very robust because again uh there are very few dependencies every service only depends on the message",
    "start": "1298159",
    "end": "1304640"
  },
  {
    "text": "transport itself it doesn't depend on anybody else or any other response and there's actually very little",
    "start": "1304640",
    "end": "1309679"
  },
  {
    "text": "coupling between components uh the biggest downside of course like with most certified system here is debugging it",
    "start": "1309679",
    "end": "1315360"
  },
  {
    "text": "because if you expect service a to send something to b and c and d and you know however many",
    "start": "1315360",
    "end": "1321120"
  },
  {
    "text": "letters next uh if the message doesn't uh get to the end figuring out where it went away or which",
    "start": "1321120",
    "end": "1328400"
  },
  {
    "text": "service lost it is very much non-trivial especially if there is latency in the system uh we'll talk about this towards the end",
    "start": "1328400",
    "end": "1334159"
  },
  {
    "text": "of the talk uh and expand on it but if there's latency in the system uh there might be two error messages",
    "start": "1334159",
    "end": "1339440"
  },
  {
    "text": "produced by two different services and they're not actually uh in the same time frame there might be a lag of",
    "start": "1339440",
    "end": "1345280"
  },
  {
    "text": "an hour between two services and so while we'll log an exception an hour later from the other",
    "start": "1345280",
    "end": "1350640"
  },
  {
    "text": "and how you find those and correlate those is a very complex problem which we will answer in the stock so the",
    "start": "1350640",
    "end": "1356000"
  },
  {
    "text": "next pattern is publish a subscriber it's it's just an upgrade of the previous notification pattern",
    "start": "1356000",
    "end": "1361520"
  },
  {
    "text": "um where fire forget is between two components uh pub sub publishes subscriber is again",
    "start": "1361520",
    "end": "1367520"
  },
  {
    "text": "a very well understood pattern everyone i'm sure used it at some point in their lives either between threads within this in a single",
    "start": "1367520",
    "end": "1374000"
  },
  {
    "text": "process or maybe between processes uh is where one or more components publishes a message",
    "start": "1374000",
    "end": "1380320"
  },
  {
    "text": "and then multiple components subscribe to receive those kinds of messages right and again there's no expectation",
    "start": "1380320",
    "end": "1386000"
  },
  {
    "text": "of a return message it's still kind of a fire and forget pattern the biggest difference here is of course",
    "start": "1386000",
    "end": "1391360"
  },
  {
    "text": "um that you can configure whether all the subscribers receive the same message or a single subscriber receives",
    "start": "1391360",
    "end": "1398080"
  },
  {
    "text": "a copy of the message there are lots of variations they're all very useful in their way and the biggest difference here of",
    "start": "1398080",
    "end": "1404400"
  },
  {
    "text": "course is whether transport is durable or transient so transient",
    "start": "1404400",
    "end": "1410320"
  },
  {
    "text": "patterns would be something like the default mode of rabbitmq and a few others notification systems",
    "start": "1410320",
    "end": "1416159"
  },
  {
    "text": "where you send a message and anyone who was listening to that message at that moment moment in",
    "start": "1416159",
    "end": "1421440"
  },
  {
    "text": "time will get the message and anyone who missed it will miss the message and that's that's fine for uh as an",
    "start": "1421440",
    "end": "1427440"
  },
  {
    "text": "example of the previous uh example we had stock ticker we send the update anyone who got it excellent anyone who missed",
    "start": "1427440",
    "end": "1433200"
  },
  {
    "text": "it it's fine it's no big deal for more robust production systems of course you",
    "start": "1433200",
    "end": "1438320"
  },
  {
    "text": "want durability in the transport you want a subscriber who went offline",
    "start": "1438320",
    "end": "1443440"
  },
  {
    "text": "and came back to be able to catch up and get all the messages it missed while it wasn't listening",
    "start": "1443440",
    "end": "1448480"
  },
  {
    "text": "and so you would have some kind of durable transport instead of just a message broker that just sends the",
    "start": "1448480",
    "end": "1454640"
  },
  {
    "text": "messages forward right but either way it's a very useful very down pattern",
    "start": "1454640",
    "end": "1459919"
  },
  {
    "text": "we use it again a lot because it's just a logical extension of the notification pattern uh if we have some kind of message let's",
    "start": "1459919",
    "end": "1466559"
  },
  {
    "text": "say a user performed in action and we have three different services which are interested in that kind of",
    "start": "1466559",
    "end": "1471600"
  },
  {
    "text": "message one service goes and updates the user profile another service goes and runs heuristics to analyze",
    "start": "1471600",
    "end": "1477279"
  },
  {
    "text": "the activity and the third service goes and does something else they all care about this message they're",
    "start": "1477279",
    "end": "1483039"
  },
  {
    "text": "independent of each other so in this diagram c d and e don't rely on each other each service will do",
    "start": "1483039",
    "end": "1489200"
  },
  {
    "text": "an independent thing with the message it receives and so it makes perfect sense to decouple them temporarily because",
    "start": "1489200",
    "end": "1495840"
  },
  {
    "text": "we don't want the state of one service to affect the availability of all the others so this is where we would",
    "start": "1495840",
    "end": "1501440"
  },
  {
    "text": "use this kind of pattern uh makes a lot of sense um the next one and this pattern uh is",
    "start": "1501440",
    "end": "1507039"
  },
  {
    "start": "1505000",
    "end": "1505000"
  },
  {
    "text": "what most closely mimics known uh synchronous patterns which is request response um it's the",
    "start": "1507039",
    "end": "1513039"
  },
  {
    "text": "best analog we have to for example a synchronous f2 a space synchronous http request where you",
    "start": "1513039",
    "end": "1520320"
  },
  {
    "text": "make a request and you wait for a response and you expect something back um of course in an asynchronous system",
    "start": "1520320",
    "end": "1526880"
  },
  {
    "text": "that can take an arbitrarily long amount of time uh but the pattern is servicea sends",
    "start": "1526880",
    "end": "1532400"
  },
  {
    "text": "something to service b service b does something with this message and then returns a different message",
    "start": "1532400",
    "end": "1537679"
  },
  {
    "text": "to service a the biggest difference between the synchronous version of this pattern",
    "start": "1537679",
    "end": "1543120"
  },
  {
    "text": "and the asynchronous version is in the synchronous version usually the service which originates the",
    "start": "1543120",
    "end": "1550159"
  },
  {
    "text": "request maintains the context of the request in memory in the thread for example if you think about the",
    "start": "1550159",
    "end": "1556080"
  },
  {
    "text": "standard http service it calls another microservice gets a response back you still have",
    "start": "1556080",
    "end": "1561919"
  },
  {
    "text": "the object which you use to create the response in memory so you can handle the response in the same thread you don't need to",
    "start": "1561919",
    "end": "1567039"
  },
  {
    "text": "store the context somewhere else when it's asynchronous we have multiple instances of service a we have multiple",
    "start": "1567039",
    "end": "1572799"
  },
  {
    "text": "instances of service b let's say a1 posts a message service b1 receives it",
    "start": "1572799",
    "end": "1578400"
  },
  {
    "text": "posts a message back but then nothing guarantees that service a1 that instance will receive the return",
    "start": "1578400",
    "end": "1583440"
  },
  {
    "text": "message a different servers will pick it up maybe a3 and a3 doesn't share memory with a1",
    "start": "1583440",
    "end": "1588720"
  },
  {
    "text": "they're different instances they're different processes and so you have to handle this propagation of context if the return",
    "start": "1588720",
    "end": "1594000"
  },
  {
    "text": "message only makes sense if the response makes sense only in the context of the request",
    "start": "1594000",
    "end": "1600159"
  },
  {
    "text": "how do you propagate the request back to the service aid which received the response right so there are multiple ways but",
    "start": "1600159",
    "end": "1606080"
  },
  {
    "text": "they both basically they boil down to where do you store the state you either put it in some kind of database or somewhere which",
    "start": "1606080",
    "end": "1612320"
  },
  {
    "text": "has its own tradeoffs because now you're introducing a synchronous a space synchronous dependency for",
    "start": "1612320",
    "end": "1617440"
  },
  {
    "text": "service a because a has to first store the message with the context in a database",
    "start": "1617440",
    "end": "1622720"
  },
  {
    "text": "send the request get the response get the context synchronously from the database and merge those two and so you're kind of",
    "start": "1622720",
    "end": "1629200"
  },
  {
    "text": "breaking uh away from the sms pattern or the more common but slightly more expensive",
    "start": "1629200",
    "end": "1634799"
  },
  {
    "text": "version is you send the entire request with the contacts and everything as part of the message and then service b",
    "start": "1634799",
    "end": "1640880"
  },
  {
    "text": "has to return its response and the request or the request context together with the response and so in this case",
    "start": "1640880",
    "end": "1647600"
  },
  {
    "text": "the response travels back and forth you're sending more data it's sometimes it's practical sometimes if it's too much context",
    "start": "1647600",
    "end": "1654080"
  },
  {
    "text": "it's just impractical to do it's too expensive it's too large it doesn't fit but that's that way you avoid any kind",
    "start": "1654080",
    "end": "1660799"
  },
  {
    "text": "of synchronous dependencies right and so in our system it's",
    "start": "1660799",
    "end": "1667600"
  },
  {
    "text": "about half and half between those two use cases we do have cases where we get a large message just just an",
    "start": "1667679",
    "end": "1673200"
  },
  {
    "text": "example um one of the features we have is a data link prevention so we download the file",
    "start": "1673200",
    "end": "1679039"
  },
  {
    "text": "and then we need to scan this file and classify the data is it a pii private data or classified data",
    "start": "1679039",
    "end": "1684720"
  },
  {
    "text": "and stuff like that so we download the message but the message is large it could be 20 megabytes of file",
    "start": "1684720",
    "end": "1689919"
  },
  {
    "text": "we're not going to send the entire file over darkest kafka it's just not practical so what we'll do",
    "start": "1689919",
    "end": "1695360"
  },
  {
    "text": "is we'll store the file in some kind of shared file system we'll send a message with a pointer to the file to a different service",
    "start": "1695360",
    "end": "1701679"
  },
  {
    "text": "which will use the file do some stuff put the response the blob of response somewhere else send",
    "start": "1701679",
    "end": "1707279"
  },
  {
    "text": "the message back saying the response is ready and here's a pointer to the response right so this mixes",
    "start": "1707279",
    "end": "1712799"
  },
  {
    "text": "synchronous and asynchronous modes there are obvious downsides to it but it's just a practical reality that",
    "start": "1712799",
    "end": "1718240"
  },
  {
    "text": "we couldn't make it work completely asynchronously we had to compromise and make it half and half in many other cases",
    "start": "1718240",
    "end": "1724720"
  },
  {
    "text": "we send a we send the request and persist the context on the request and",
    "start": "1724720",
    "end": "1730320"
  },
  {
    "text": "that's obviously preferable if it's practical to do so right so the next next expansion of the",
    "start": "1730320",
    "end": "1736399"
  },
  {
    "start": "1734000",
    "end": "1734000"
  },
  {
    "text": "same concept of course is the distributed blog which is just another way of saying pub sub",
    "start": "1736399",
    "end": "1741679"
  },
  {
    "text": "but you don't have to sub which means subscribe to the tail of the queue right this is",
    "start": "1741679",
    "end": "1748720"
  },
  {
    "text": "the way a lot of the popular services work kinesis kafka pulsar most of the message logs",
    "start": "1748720",
    "end": "1756240"
  },
  {
    "text": "that have memory let you actually consume messages not from the top of the queue but from any point in",
    "start": "1756240",
    "end": "1762480"
  },
  {
    "text": "the queue and they have a history potentially going back days or years however long you want of all the data that's ever been logged",
    "start": "1762480",
    "end": "1768480"
  },
  {
    "text": "in this message log and that's why we call them different things so you sign a message queue it's usually a distributed",
    "start": "1768480",
    "end": "1773840"
  },
  {
    "text": "log because you have a log of all the messages and a lot of time you also have some kind of compaction feature which",
    "start": "1773840",
    "end": "1779360"
  },
  {
    "text": "will uh duplicate similar messages right and so this pattern is extremely useful for",
    "start": "1779360",
    "end": "1784880"
  },
  {
    "text": "data processing applications or for just being able to reprocess data very quickly",
    "start": "1784880",
    "end": "1790320"
  },
  {
    "text": "one very strong use case for this is we have a service which maintains user",
    "start": "1790320",
    "end": "1795760"
  },
  {
    "text": "profiles uh what it does is it gets information for about users from directory services things like",
    "start": "1795760",
    "end": "1802720"
  },
  {
    "text": "title name blah blah blah and then it tries to figure out if that user is an executive or not",
    "start": "1802720",
    "end": "1808159"
  },
  {
    "text": "according to their business user user and the title there's a lot of natural language processing on the title",
    "start": "1808159",
    "end": "1813440"
  },
  {
    "text": "and the business unit and tries to figure out if that person is an executive or not for us the reason is an executive",
    "start": "1813440",
    "end": "1821679"
  },
  {
    "text": "is a more vulnerable to secure attacks and we have a security system so we try to figure out and classify if",
    "start": "1821679",
    "end": "1827440"
  },
  {
    "text": "that person is more vulnerable or not um and so this algorithm has gone for maybe 50 different versions",
    "start": "1827440",
    "end": "1833360"
  },
  {
    "text": "um and so we have a data store of maybe hundreds of millions of users we know about and so every time we",
    "start": "1833360",
    "end": "1840559"
  },
  {
    "text": "roll out a new version of this algorithm what we want to do is obviously put it in production so that",
    "start": "1840559",
    "end": "1845600"
  },
  {
    "text": "any new updates to the users come in through the new version of the algorithm but we also want to go back",
    "start": "1845600",
    "end": "1851360"
  },
  {
    "text": "and reprocess all of the old messages and update them because now we can calculate whether they're an executive better than",
    "start": "1851360",
    "end": "1857120"
  },
  {
    "text": "before but we don't want to have down time in the system we're not going to just stop everything put up the new version",
    "start": "1857120",
    "end": "1862640"
  },
  {
    "text": "in production and let it run and then accumulate new messages what we normally do is we spin up a",
    "start": "1862640",
    "end": "1868240"
  },
  {
    "text": "second version side by side with the same with the old service and we point the",
    "start": "1868240",
    "end": "1874240"
  },
  {
    "text": "updated version to the end of the queue of user updates and let it start consuming and usually",
    "start": "1874240",
    "end": "1879760"
  },
  {
    "text": "takes a day or two it goes through the entire log of all the users we've ever seen and it keeps updating the database at",
    "start": "1879760",
    "end": "1885919"
  },
  {
    "text": "the same time the old version still works and still running the old version of the algorithm on the real-time data eventually the new",
    "start": "1885919",
    "end": "1893120"
  },
  {
    "text": "version catches up to the log and then we bring down the old service and only the new service remains in production",
    "start": "1893120",
    "end": "1898159"
  },
  {
    "text": "and so we do the switch over between two different algorithm versions uh in real time without losing functionality um and so",
    "start": "1898159",
    "end": "1904880"
  },
  {
    "text": "and it's completely seamless right so that's a very strong use case if you can map it to any kind of stream processing you have it's probably",
    "start": "1904880",
    "end": "1911840"
  },
  {
    "text": "going to find some use there um and it works basically the same way right you have uh",
    "start": "1911840",
    "end": "1917440"
  },
  {
    "text": "one or more publishers and however many subscribers and the benefit of course is that any subscriber a new subscriber can join",
    "start": "1917440",
    "end": "1924080"
  },
  {
    "text": "and find all the messages that ever existed uh if it wants to and we'll talk about this in just a",
    "start": "1924080",
    "end": "1929600"
  },
  {
    "text": "moment a bit more when you talk about the pen source now they have all these basic communication patterns right we can",
    "start": "1929600",
    "end": "1934960"
  },
  {
    "text": "start combining those into more higher level patterns and the biggest one and i think probably by far the most useful when you build an",
    "start": "1934960",
    "end": "1941200"
  },
  {
    "start": "1936000",
    "end": "1936000"
  },
  {
    "text": "asynchronous system is cqrs which is command query responsibility segregation or separation which",
    "start": "1941200",
    "end": "1949200"
  },
  {
    "text": "it's a very large topic it could be a talk in and of itself but to summarize it into three minutes um very often um",
    "start": "1949200",
    "end": "1957440"
  },
  {
    "text": "in traditional architectures we use the same data model to both update a database and to query",
    "start": "1957440",
    "end": "1963120"
  },
  {
    "text": "from the database if you think about it as an example let's say we have some kind of user object",
    "start": "1963120",
    "end": "1968640"
  },
  {
    "text": "we have a table of users a user update comes in we write the user we want to show that if you want to show it in the",
    "start": "1968640",
    "end": "1974240"
  },
  {
    "text": "ui we do select on table and star from table users hopefully nobody does select star please use",
    "start": "1974240",
    "end": "1979919"
  },
  {
    "text": "for the full uh attributes select star is a bad practice but roll with me and so we use the same",
    "start": "1979919",
    "end": "1986000"
  },
  {
    "text": "model to both update and get the data from the database now at large scale or the complex snap",
    "start": "1986000",
    "end": "1992159"
  },
  {
    "text": "system when you have a large enough data model that doesn't work very well because oftentimes the model we want to read",
    "start": "1992159",
    "end": "1999279"
  },
  {
    "text": "is not the same as the model we want to write to the database for example again our example we have",
    "start": "1999279",
    "end": "2004399"
  },
  {
    "text": "the user store system which aggregates user profile information from hundreds of different directory services",
    "start": "2004399",
    "end": "2010320"
  },
  {
    "text": "a user object in our case has many many sub-objects it has a bunch of",
    "start": "2010320",
    "end": "2015840"
  },
  {
    "text": "information about virus accounts it has history information about what we saw about the user it has",
    "start": "2015840",
    "end": "2020880"
  },
  {
    "text": "uh all the profile information uh a bunch of different subcategories each",
    "start": "2020880",
    "end": "2026880"
  },
  {
    "text": "one of those gets updated separately if we were to model this in a normalized way it would be maybe 50 different",
    "start": "2026880",
    "end": "2032559"
  },
  {
    "text": "tables that we have to all join together but we once we wanted to read this user we don't care about all of that",
    "start": "2032559",
    "end": "2038720"
  },
  {
    "text": "multiple model stuff we want just one giant user object because we want to optimize the system for high for low latency high throughput",
    "start": "2038720",
    "end": "2045519"
  },
  {
    "text": "reads in our case the third generation of our user management system",
    "start": "2045519",
    "end": "2051280"
  },
  {
    "text": "has uh at speak about a million requests per second to it right but pretty much every other subsystem in our",
    "start": "2051280",
    "end": "2058240"
  },
  {
    "text": "our product calls to the user system to do something with it and it's a crucial piece of the",
    "start": "2058240",
    "end": "2063839"
  },
  {
    "text": "infrastructure and so it needs to serve a million requests per second um which means you can't do a million",
    "start": "2063839",
    "end": "2069760"
  },
  {
    "text": "joins on 50 different tables and so in our case what we do is we write one kind of model",
    "start": "2069760",
    "end": "2074800"
  },
  {
    "text": "to a message log then we have some kind of process which takes all these model updates it",
    "start": "2074800",
    "end": "2081280"
  },
  {
    "text": "transforms them and that creates a new reador in the model and stores that in a different database",
    "start": "2081280",
    "end": "2086320"
  },
  {
    "text": "that's actually a key value for the reads or in the low latency key value store",
    "start": "2086320",
    "end": "2092000"
  },
  {
    "text": "and that's the right path of the cqrs right so usually in nctrs what you will have is",
    "start": "2092000",
    "end": "2097118"
  },
  {
    "text": "an asynchronous write path where you queue up a bunch of updates you run some sort of domain logic on",
    "start": "2097119",
    "end": "2102160"
  },
  {
    "text": "them and create your right model from those there'll be some kind of change notification which will create the read",
    "start": "2102160",
    "end": "2107520"
  },
  {
    "text": "model and the read model is queried synchronously because often times uh in almost all ui applications and a",
    "start": "2107520",
    "end": "2114720"
  },
  {
    "text": "lot of other types of applications the read path in the system it makes a lot more sense to make it",
    "start": "2114720",
    "end": "2120320"
  },
  {
    "text": "synchronous uh it's actually very hard to imagine for example an application or a website where the read is asynchronous where you",
    "start": "2120320",
    "end": "2126800"
  },
  {
    "text": "queue up the read and then your client waits for it and gets the data and then presents it or something",
    "start": "2126800",
    "end": "2132000"
  },
  {
    "text": "that it just makes so much sense it's easier easy to debug you just have a synchronous request to the read path but",
    "start": "2132000",
    "end": "2138400"
  },
  {
    "text": "the right path it's obviously much more scalable and much more robust if you make it html right and so for the qrs uh if you look",
    "start": "2138400",
    "end": "2146160"
  },
  {
    "text": "at all the panels we talked about it makes perfect sense to have some kind of message log as your command queue you have some kind of",
    "start": "2146160",
    "end": "2152240"
  },
  {
    "text": "consumer which will take it and create a new queue of write data models some kind of",
    "start": "2152240",
    "end": "2158400"
  },
  {
    "text": "persistence layer which takes updates from the right model again as a queue into the read model and only then there's some kind of",
    "start": "2158400",
    "end": "2164320"
  },
  {
    "text": "service which serves it so our version one of our system was almost",
    "start": "2164320",
    "end": "2169599"
  },
  {
    "text": "entirely synchronous and one of the biggest problems that we had was",
    "start": "2169599",
    "end": "2175040"
  },
  {
    "text": "the two conflicting load types on our user identity system where we had spikes of writes whenever",
    "start": "2175040",
    "end": "2181040"
  },
  {
    "text": "we updated the database and a consistent stream of reads from the same database and every now and then because the reads are",
    "start": "2181040",
    "end": "2187359"
  },
  {
    "text": "constant but rides are spiky it will just overload the system and fail most of the reads and then the",
    "start": "2187359",
    "end": "2192560"
  },
  {
    "text": "website will become unstable and one of the first things we did was actually separate the component that reads data",
    "start": "2192560",
    "end": "2198160"
  },
  {
    "text": "from the component that writes data to make sure they're actually independent from each other that's a big uh part of why you would",
    "start": "2198160",
    "end": "2204160"
  },
  {
    "text": "actually consider using cqrs in your system that brings us to event sourcing because",
    "start": "2204160",
    "end": "2209200"
  },
  {
    "start": "2209000",
    "end": "2209000"
  },
  {
    "text": "they're they're often used together event sourcing is not necessary necessary for cqrs but very often you",
    "start": "2209200",
    "end": "2215440"
  },
  {
    "text": "will actually use them together what event sourcing does is it's a pattern where instead of storing",
    "start": "2215440",
    "end": "2220960"
  },
  {
    "text": "the latest snapshot of data you store all the possible updates of that data right and so for example",
    "start": "2220960",
    "end": "2226640"
  },
  {
    "text": "in our case uh the system i talked about earlier which calculates the user uh the user type according to",
    "start": "2226640",
    "end": "2233280"
  },
  {
    "text": "their title we do store all of the title updates for every user forever so that we can run over them and",
    "start": "2233280",
    "end": "2239760"
  },
  {
    "text": "reconstruct the system if it ever goes down or if you need to recalculate with the algorithm so if you imagine there's let's say an",
    "start": "2239760",
    "end": "2246960"
  },
  {
    "text": "infinite table of key value key value pairs where the key in this case is a and b",
    "start": "2246960",
    "end": "2253599"
  },
  {
    "text": "and the value is some change you need to make on the object your materialized table right",
    "start": "2253599",
    "end": "2259200"
  },
  {
    "text": "your let's say a sql database would be just the final version of it which is applying whatever whatever uh operation you had",
    "start": "2259200",
    "end": "2266560"
  },
  {
    "text": "although the queue but your event source your own store would have all the possible events",
    "start": "2266560",
    "end": "2271599"
  },
  {
    "text": "a classic against example of this which is almost never used but it's always uh talked about and then blogs and talks",
    "start": "2271599",
    "end": "2278320"
  },
  {
    "text": "is a shopping cart let's say you go to your ebay or amazon shopping cart you put something in a shopping cart you put",
    "start": "2278320",
    "end": "2283359"
  },
  {
    "text": "another thing in shopping cart then you delete something because you don't want to pay it and eventually what you pay for is just a",
    "start": "2283359",
    "end": "2289599"
  },
  {
    "text": "snapshot your latest version of the the shopping cart but the vendor actually cares very much about all the",
    "start": "2289599",
    "end": "2295359"
  },
  {
    "text": "changes which happened to the shopping cart because they might if you put something in there and you take it out they might",
    "start": "2295359",
    "end": "2300720"
  },
  {
    "text": "want to try and sell it to you later and send you some ads because everybody loves ads and vendors love selling ads",
    "start": "2300720",
    "end": "2306880"
  },
  {
    "text": "and so that's a perfect example of event sourcing right so uh if you take all of those",
    "start": "2306880",
    "end": "2312320"
  },
  {
    "text": "together um we get basically uh full coverage of all the various patterns that are very",
    "start": "2312320",
    "end": "2317599"
  },
  {
    "text": "commonly used in http systems most of them don't really have a synchronous a space",
    "start": "2317599",
    "end": "2323359"
  },
  {
    "text": "synchronous analog right except for request response which is obviously very straightforward that's",
    "start": "2323359",
    "end": "2328720"
  },
  {
    "text": "not because this is again there's necessarily something better or worse about synthesis patterns it's just",
    "start": "2328720",
    "end": "2334160"
  },
  {
    "text": "syntax patterns are much more straightforward uh and so there's fewer patterns we need to cover",
    "start": "2334160",
    "end": "2340480"
  },
  {
    "text": "um now that we have patterns we need to talk about delivery guarantees which is something we ignored for most of the stock we assume that the",
    "start": "2340480",
    "end": "2347520"
  },
  {
    "start": "2342000",
    "end": "2342000"
  },
  {
    "text": "message transport is magical but the thing is it's not magical message transports fail quite a bit",
    "start": "2347520",
    "end": "2354160"
  },
  {
    "text": "and so understanding what delivery guarantees you get from your message transport is important in order to implement every",
    "start": "2354160",
    "end": "2359839"
  },
  {
    "text": "possible pattern because how can you for example implement event sourcing if",
    "start": "2359839",
    "end": "2365119"
  },
  {
    "text": "you're not guaranteed that every message will reach the destination if your event sourcing relies on",
    "start": "2365119",
    "end": "2370800"
  },
  {
    "text": "applying every operation and you miss two of the messages the result is going to be incorrect um",
    "start": "2370800",
    "end": "2376400"
  },
  {
    "text": "and so there are broadly speaking there are three delivery guarantees we can talk about in the messaging system at most ones which",
    "start": "2376400",
    "end": "2382800"
  },
  {
    "text": "means every message will be delivered to the subscriber consumer whatever you're going to call it",
    "start": "2382800",
    "end": "2388079"
  },
  {
    "text": "at most once which means it might be zero times or it might be one time",
    "start": "2388079",
    "end": "2393280"
  },
  {
    "text": "let's think about the kind of application again we can go back to the stock ticker stop ticker is a classical example but most ones it's a lossy system",
    "start": "2393280",
    "end": "2400320"
  },
  {
    "text": "it's guaranteed that you will get each stock tick at most once but you can you might skip",
    "start": "2400320",
    "end": "2406400"
  },
  {
    "text": "some of them um there are there are some practical uses for that kind of system",
    "start": "2406400",
    "end": "2411680"
  },
  {
    "text": "uh again most mainly statistics based applications or things just need to show a snapshot ui",
    "start": "2411680",
    "end": "2417760"
  },
  {
    "text": "based applications uh what we're doing right now video streaming if you think about you're seeing me if you if your network",
    "start": "2417760",
    "end": "2424400"
  },
  {
    "text": "skips a few network packets or the video or the audio it's no big deal it's not going to be noticeable",
    "start": "2424400",
    "end": "2429680"
  },
  {
    "text": "so video and messaging uh delivering passwords are at most once the most basic internet protocol which",
    "start": "2429680",
    "end": "2435839"
  },
  {
    "text": "is udp is of course in its most low state pattern right the up to that",
    "start": "2435839",
    "end": "2440880"
  },
  {
    "text": "is at least once you're guaranteed that every message gets delivered at least once which means it can be delivered most more than once this is",
    "start": "2440880",
    "end": "2448240"
  },
  {
    "text": "by far the most common pattern in message cubes we'll get to exactly once",
    "start": "2448240",
    "end": "2453520"
  },
  {
    "text": "in a bit it's kind of a bit of a unicorn but in practical terms most message queues designed today have",
    "start": "2453520",
    "end": "2460880"
  },
  {
    "text": "at least one delivery which means you're guaranteed to get every message you're not going to lose any data but it's very likely that you'll get",
    "start": "2460880",
    "end": "2467839"
  },
  {
    "text": "some messages more than once depending on how you set up the system and you know stability and various other considerations",
    "start": "2467839",
    "end": "2473520"
  },
  {
    "text": "you might get a lot of messages more than once um this has two implications one if we're",
    "start": "2473520",
    "end": "2479200"
  },
  {
    "text": "building asynchronous systems with at least one's guarantees we have to consider it in potency",
    "start": "2479200",
    "end": "2484560"
  },
  {
    "text": "every service has to assume it will get the message more than once and if you have side effects from the",
    "start": "2484560",
    "end": "2489760"
  },
  {
    "text": "service side effects being you write to a database you send an email notification you do anything with",
    "start": "2489760",
    "end": "2494880"
  },
  {
    "text": "the message you need to consider how to make it as important as possible it's not always",
    "start": "2494880",
    "end": "2500000"
  },
  {
    "text": "possible as an example we have a um we have an alerting system in our in our product",
    "start": "2500000",
    "end": "2505680"
  },
  {
    "text": "which if some user performs malicious activity it sends an email to the administrator",
    "start": "2505680",
    "end": "2512079"
  },
  {
    "text": "an email is not important right you can't take it back you can't you know if you send it again you'll send another email",
    "start": "2512079",
    "end": "2518000"
  },
  {
    "text": "there's no way to overwrite an email because you sent it and it's a side effect that happens and it went away but for most other things things like",
    "start": "2518000",
    "end": "2523920"
  },
  {
    "text": "writing to a database we do our very best to model data in a way that if you",
    "start": "2523920",
    "end": "2529680"
  },
  {
    "text": "apply the same update more than once it will not change the final result this has very important implication on",
    "start": "2529680",
    "end": "2537440"
  },
  {
    "text": "things like counting on stream or stream statistics right one of the uh most uh let's say least understood",
    "start": "2537440",
    "end": "2544560"
  },
  {
    "text": "and and things were let me put it this way have you ever had a product management manager or someone come to you",
    "start": "2544560",
    "end": "2550480"
  },
  {
    "text": "and say oh let's do this it sounds easy i would just count all the items in the stream i had this happen a year ago where",
    "start": "2550480",
    "end": "2557030"
  },
  {
    "text": "[Music] someone wanted to know how many activities we had in a day",
    "start": "2557030",
    "end": "2562880"
  },
  {
    "text": "in our system how many activities in the stream it's roughly about a billion per day uh and so we went and said okay we'll",
    "start": "2562880",
    "end": "2569520"
  },
  {
    "text": "need to build a business system which can do you know bi analytics on a billion items per day which means we have you know",
    "start": "2569520",
    "end": "2574720"
  },
  {
    "text": "300 billions of those per year it's going to take a couple of weeks to build something like that and say no but why don't you just count every",
    "start": "2574720",
    "end": "2580480"
  },
  {
    "text": "message you see every message just count them but that's not does not work the way it works you might",
    "start": "2580480",
    "end": "2586960"
  },
  {
    "text": "skip some messages you might send some messages more than once counting a live stream is an extremely",
    "start": "2586960",
    "end": "2592640"
  },
  {
    "text": "complex engineering problem almost certainly you will over count depending on how you store the counter",
    "start": "2592640",
    "end": "2598720"
  },
  {
    "text": "in memory on a state you might under count it's almost impossible for you to count exactly",
    "start": "2598720",
    "end": "2604079"
  },
  {
    "text": "um there actually and uh we're not gonna have this time for this new talk but there are a lot of probabilistic algorithms",
    "start": "2604079",
    "end": "2610400"
  },
  {
    "text": "which can very efficiently do things like counting and statistics on a stream of data and give you an approximation um in a",
    "start": "2610400",
    "end": "2617680"
  },
  {
    "text": "constant amount of memory so look for a probabilistic data structure it's a fascinating topic but you know it's the topic for for next",
    "start": "2617680",
    "end": "2624560"
  },
  {
    "text": "year's talk so as i said at least once delivery",
    "start": "2624560",
    "end": "2630720"
  },
  {
    "text": "if you for example try to count messages in the stream it's very likely that some messages will",
    "start": "2630720",
    "end": "2635839"
  },
  {
    "text": "be repeated so you'll over count uh within at most one one system you'll probably under account",
    "start": "2635839",
    "end": "2641440"
  },
  {
    "text": "examples of why at least one systems exist let's think about things like kafka or kinesis or pretty much any",
    "start": "2641440",
    "end": "2647839"
  },
  {
    "text": "message queue the way it works is when you consume a message the consumer gets a message or a batch of messages does something with them",
    "start": "2647839",
    "end": "2654880"
  },
  {
    "text": "and then it needs to send an acknowledgement to the transport saying i finished with the messages",
    "start": "2654880",
    "end": "2659920"
  },
  {
    "text": "if the consumer process uh crashes before it sends the acknowledgement the next time it goes up it will get the",
    "start": "2659920",
    "end": "2666000"
  },
  {
    "text": "same messages because they weren't acknowledged and depending on the different flavors on transport it might be one message it",
    "start": "2666000",
    "end": "2671680"
  },
  {
    "text": "might be a batch of a thousand messages or a bulk of whatever is right um exactly kafka because i'm most familiar",
    "start": "2671680",
    "end": "2678400"
  },
  {
    "text": "with kafka has two different modes the standard kafka consumer reads a batch of messages",
    "start": "2678400",
    "end": "2683920"
  },
  {
    "text": "up to a certain size and you acknowledge the entire batch all at once commit the options for the batch all at once which means",
    "start": "2683920",
    "end": "2689520"
  },
  {
    "text": "if you fail to commit the offset but you're still processed most of the batch next time you'll repeat all of those",
    "start": "2689520",
    "end": "2695200"
  },
  {
    "text": "messages again with kafka streams there's a single message acknowledgement so acknowledge every individual message",
    "start": "2695200",
    "end": "2701280"
  },
  {
    "text": "so you will repeat at most one message but you will still repeat that one right and so the goal in unicorn is of",
    "start": "2701280",
    "end": "2706800"
  },
  {
    "text": "course why can't we have exactly once delivery uh and the answer is we can in very",
    "start": "2706800",
    "end": "2712560"
  },
  {
    "text": "specific very narrow circumstances and the circumstances are if you don't",
    "start": "2712560",
    "end": "2717760"
  },
  {
    "text": "have any side effects and if you are reading and writing messages from the same message transport and the",
    "start": "2717760",
    "end": "2724240"
  },
  {
    "text": "message transport supports transactions then you might have exactly once message",
    "start": "2724240",
    "end": "2729440"
  },
  {
    "text": "delivery so to narrow it down to a practical scope uh if you have if your system reads from one kafka",
    "start": "2729440",
    "end": "2736240"
  },
  {
    "text": "topic rise to a different kafka topic on the same kafka cluster and all it does is change the message it",
    "start": "2736240",
    "end": "2743280"
  },
  {
    "text": "doesn't do side effects it doesn't call any other external systems or databases then what it can do is it can commit the",
    "start": "2743280",
    "end": "2750480"
  },
  {
    "text": "offset for the consumption and the production at the same time and then if the process crashes then the",
    "start": "2750480",
    "end": "2756880"
  },
  {
    "text": "outgoing message also won't be committed and the incoming message won't be committed so in those narrow circumstances uh you",
    "start": "2756880",
    "end": "2764400"
  },
  {
    "text": "can have exactly one message delivery if you change any of those variables it will no longer be exactly once",
    "start": "2764400",
    "end": "2769920"
  },
  {
    "text": "because for example if you call to external database to enrich your data along the way",
    "start": "2769920",
    "end": "2775680"
  },
  {
    "text": "uh if your process crashes it comes back it will get the same message but the external system you call to might have changed in the meantime so it",
    "start": "2775680",
    "end": "2782160"
  },
  {
    "text": "won't be important uh if you need to read the message from one transport and write the outgoing message to a different",
    "start": "2782160",
    "end": "2788160"
  },
  {
    "text": "transport uh there's no way to make a transaction between those two you have to commit the message first",
    "start": "2788160",
    "end": "2793359"
  },
  {
    "text": "then you can crash before you commit it in the output message and so you have to uh yes you have to break which means you have to change the order",
    "start": "2793359",
    "end": "2799359"
  },
  {
    "text": "around you will commit the outgoing message first then you will commit the consumed message offset",
    "start": "2799359",
    "end": "2804960"
  },
  {
    "text": "uh but then if you can't crash between any one of those two lines you will get the message again so basically pretty much changing any",
    "start": "2804960",
    "end": "2810480"
  },
  {
    "text": "parameter in that specific scenario bring this either to at most one's delivery or at least once delivery all",
    "start": "2810480",
    "end": "2815599"
  },
  {
    "text": "right and so i don't think it's a practical goal to chase i don't think it's important i think both systems can be",
    "start": "2815599",
    "end": "2821280"
  },
  {
    "text": "practically made to work well enough with at least once delivery and in some cases at most once actually",
    "start": "2821280",
    "end": "2827680"
  },
  {
    "text": "makes it so that of course brings us to transactions right because i mentioned transactions uh just earlier",
    "start": "2827680",
    "end": "2834160"
  },
  {
    "text": "uh we won't be won't have kind of time again it's a whole talk in itself there's",
    "start": "2834160",
    "end": "2839200"
  },
  {
    "text": "a lot of literature about distributed transactions but i'll run through this real quick uh just to have a sense of you know how",
    "start": "2839200",
    "end": "2845520"
  },
  {
    "text": "complex of a beast we're chasing here um so unlike standard synchronous",
    "start": "2845520",
    "end": "2851839"
  },
  {
    "text": "single node systems where transactions are easy so to speak because your database or wherever else",
    "start": "2851839",
    "end": "2857280"
  },
  {
    "text": "gives you transactions for free distributed systems are very complex and transactions just don't work very well",
    "start": "2857280",
    "end": "2863760"
  },
  {
    "text": "across processes so there are a few ways to provide some form of transactionality",
    "start": "2863760",
    "end": "2868880"
  },
  {
    "text": "in a distributed async systems for the first one is a two phase two",
    "start": "2868880",
    "end": "2873920"
  },
  {
    "text": "phase commit to phase commit is a distributed protocol that is synchronous it relies on being synchronous",
    "start": "2873920",
    "end": "2879760"
  },
  {
    "text": "and i'm not gonna go into the delays of the algorithm but basically it breaks a large atomic",
    "start": "2879760",
    "end": "2885920"
  },
  {
    "text": "transaction into a series of steps where every step is uh unique and you can",
    "start": "2885920",
    "end": "2891119"
  },
  {
    "text": "if the transaction fails in the middle you can recreate and either continue from the previous step or roll it back it's very complex it's",
    "start": "2891119",
    "end": "2898160"
  },
  {
    "text": "usually impractical to implement for performance reasons because it takes a lot of operations we won't go into it",
    "start": "2898160",
    "end": "2904240"
  },
  {
    "text": "but for our purposes for asynchronous systems there are a couple of very useful transactions one is called the saga and the transactional outbooks",
    "start": "2904240",
    "end": "2911280"
  },
  {
    "text": "and those go together so transactional outbox is a very common uh use case in asynchronous systems imagine",
    "start": "2911280",
    "end": "2918319"
  },
  {
    "start": "2914000",
    "end": "2914000"
  },
  {
    "text": "you have a service which gets a message uh does something with it puts the",
    "start": "2918319",
    "end": "2923440"
  },
  {
    "text": "result in a database and then sends an outgoing message right um and what you want to do is",
    "start": "2923440",
    "end": "2929520"
  },
  {
    "text": "you only want to send the outgoing message if you succeeded in updating the database for example uh something that we have a",
    "start": "2929520",
    "end": "2936400"
  },
  {
    "text": "lot of in our system updating a cache we get a message we want to process the message we want to update an in-memory cache",
    "start": "2936400",
    "end": "2943040"
  },
  {
    "text": "which is a separate process and then we want to post the result to a permanent store as well",
    "start": "2943040",
    "end": "2948319"
  },
  {
    "text": "for example in our case 2s3 right and so we want to update a database and send an outgoing message as a",
    "start": "2948319",
    "end": "2954319"
  },
  {
    "text": "transaction if we fail to update or for the cash we don't want to send the message if we fail to send the message",
    "start": "2954319",
    "end": "2959520"
  },
  {
    "text": "we don't want to obey the cash because that would cause an inconsistencies in the system and so",
    "start": "2959520",
    "end": "2965520"
  },
  {
    "text": "this only works again in a specific case where you can split",
    "start": "2965520",
    "end": "2970640"
  },
  {
    "text": "the operation of updating the database and sending a message into choose two steps uh imagine you",
    "start": "2970640",
    "end": "2978480"
  },
  {
    "text": "have a database with two tables one table is the entity table the other table is let's call it an",
    "start": "2978480",
    "end": "2984640"
  },
  {
    "text": "outpost like a message outbox table if you can transactionally update both tables you update the actual entity",
    "start": "2984640",
    "end": "2990559"
  },
  {
    "text": "table and then you update the outgoing messages table which says post this message to the outgoing queue",
    "start": "2990559",
    "end": "2998079"
  },
  {
    "text": "that can happen as a transaction and that can be guaranteed to either happen together or not at all",
    "start": "2998079",
    "end": "3003200"
  },
  {
    "text": "and then on the outgoing table you would have some kind of separate process reading the outbox table picking up the",
    "start": "3003200",
    "end": "3008400"
  },
  {
    "text": "outbound messages and publishing them to the outgoing queue now in this case you are guaranteed in fact to either post",
    "start": "3008400",
    "end": "3015280"
  },
  {
    "text": "and update at the same time or fail to do both at the same time but you won't have an inconsistent system",
    "start": "3015280",
    "end": "3021680"
  },
  {
    "text": "does it is this practical and excel question that you get a lot no it's not really practical we don't do this",
    "start": "3021680",
    "end": "3026960"
  },
  {
    "text": "we have this use case latino system and we specifically avoid using transactional outboxes because it limits you to using the kind",
    "start": "3026960",
    "end": "3033520"
  },
  {
    "text": "of data stores which support transactions in our case",
    "start": "3033520",
    "end": "3039200"
  },
  {
    "text": "our scale is in the billions there is no system which uh can do transactions on end is fast",
    "start": "3039200",
    "end": "3045839"
  },
  {
    "text": "enough to actually serve as a cache or or some kind of back end for us so in our case uh we just update",
    "start": "3045839",
    "end": "3051200"
  },
  {
    "text": "we just post the message first then we update the cache and we live with the context",
    "start": "3051200",
    "end": "3057200"
  },
  {
    "text": "consequences of having a stale cache and hopefully it will eventually get consistent it's just a tradeoff we make",
    "start": "3057200",
    "end": "3063040"
  },
  {
    "text": "we understand the limitation of the system and we make it you know it's not a surprise to us",
    "start": "3063040",
    "end": "3068400"
  },
  {
    "text": "uh we could do the reverse trades we could try trade off we could update the cache first and then post the message and that would",
    "start": "3068400",
    "end": "3074720"
  },
  {
    "text": "have a different set of failure modes and again that's a tradeoff would make uh reasonably",
    "start": "3074720",
    "end": "3080960"
  },
  {
    "text": "right but the one pattern that we actually do have quite a lot is the saga pattern and so this is actually",
    "start": "3080960",
    "end": "3087680"
  },
  {
    "text": "a very common case let's say you have a process in your system which has multiple steps",
    "start": "3087680",
    "end": "3093119"
  },
  {
    "text": "and you want all those steps to eventually happen or if some of them fail you want to actually cancel",
    "start": "3093119",
    "end": "3098480"
  },
  {
    "text": "all the ones you've succeeded this is extremely common again in our system an event comes in and we have to update",
    "start": "3098480",
    "end": "3104800"
  },
  {
    "text": "a bunch of data stores and spawn off a bunch of sub processors which go and",
    "start": "3104800",
    "end": "3110960"
  },
  {
    "text": "create alerts send notifications do a bunch of stuff and we want all of those actually to succeed eventually but actually it doesn't have",
    "start": "3110960",
    "end": "3117680"
  },
  {
    "text": "to happen immediately but eventually they all have to succeed or if some of them time out we stop waiting for them we wanted to roll back",
    "start": "3117680",
    "end": "3124319"
  },
  {
    "text": "all the other things we did right and so this is called a saga which means uh because it doesn't happen in a",
    "start": "3124319",
    "end": "3129680"
  },
  {
    "text": "single database or even in a simple system we have to take this logical transaction and break it up into a bunch of",
    "start": "3129680",
    "end": "3135440"
  },
  {
    "text": "steps and each service will serve a step and then we have to persist the context of where",
    "start": "3135440",
    "end": "3141839"
  },
  {
    "text": "we are in this logical transaction together with the object that we're moving from service to service",
    "start": "3141839",
    "end": "3148480"
  },
  {
    "text": "so let's take as an example your standard uh order service right an order comes in",
    "start": "3148480",
    "end": "3154240"
  },
  {
    "text": "from the website we have your order object and when the order happens we want to pay some money we want to",
    "start": "3154240",
    "end": "3160079"
  },
  {
    "text": "update the uh the inventory if we want to call the shipping service and schedule delivery now each one of those is",
    "start": "3160079",
    "end": "3166960"
  },
  {
    "text": "actually independent but we do want to have to have all of them happen or none of them happen right because we don't want to send a",
    "start": "3166960",
    "end": "3172800"
  },
  {
    "text": "delivery if we didn't charge the payment service and so there are two",
    "start": "3172800",
    "end": "3178079"
  },
  {
    "text": "ways to do this one is called coordination where there's one service which is chosen as the coordinator and that",
    "start": "3178079",
    "end": "3184720"
  },
  {
    "text": "service has only the main logic of how the transaction needs to happen it will send one message to the order",
    "start": "3184720",
    "end": "3189760"
  },
  {
    "text": "service it will send one message to the payment service it will send one message to the shipment service",
    "start": "3189760",
    "end": "3195119"
  },
  {
    "text": "and it will expect a response back so in this case we're using a request response pattern it will send",
    "start": "3195119",
    "end": "3200800"
  },
  {
    "text": "separate messages to every subsystem it will get the results from all of them combine them all together and then",
    "start": "3200800",
    "end": "3206319"
  },
  {
    "text": "our saga will be complete and at every point we have a record of where we are in the transaction if the",
    "start": "3206319",
    "end": "3213119"
  },
  {
    "text": "coordinator decides that too much time has passed and we need to roll back the saga it will send",
    "start": "3213119",
    "end": "3218480"
  },
  {
    "text": "the reverse message to the service for example if you were if we already scheduled a delivery it will send a",
    "start": "3218480",
    "end": "3223680"
  },
  {
    "text": "canceled delivery message to the delivery service but if we didn't do the payment it won't have to cancel the payment",
    "start": "3223680",
    "end": "3229440"
  },
  {
    "text": "the other way to do this is called um choreography which is uh if you don't have a central",
    "start": "3229440",
    "end": "3236880"
  },
  {
    "text": "coordinator system which does all of this you overload all of the contact information on the",
    "start": "3236880",
    "end": "3242319"
  },
  {
    "text": "message itself and so in our case we would send a message to the let's say the payment system and say",
    "start": "3242319",
    "end": "3249760"
  },
  {
    "text": "this is a order do the payment bit the payment system would do the payment stuff attach the acknowledgement to the",
    "start": "3249760",
    "end": "3255359"
  },
  {
    "text": "payment was proceeded to the message and send it on to the next service in in the transaction",
    "start": "3255359",
    "end": "3260480"
  },
  {
    "text": "for example the inventory the inventory service would update the inventory overload the success success message on",
    "start": "3260480",
    "end": "3267760"
  },
  {
    "text": "the same message to add to the context send it on to the shipment service that would",
    "start": "3267760",
    "end": "3272800"
  },
  {
    "text": "create the shipment and when the shipping succeeded the shipping service will again update the giant saga transaction",
    "start": "3272800",
    "end": "3278480"
  },
  {
    "text": "we have and i don't know send it to the completion of fulfillment terms right and so at any point if one of those fails",
    "start": "3278480",
    "end": "3284960"
  },
  {
    "text": "it can send the transaction in the other direction in what's called a complimentary transaction so we'll",
    "start": "3284960",
    "end": "3291520"
  },
  {
    "start": "3290000",
    "end": "3290000"
  },
  {
    "text": "talk about this uh a successful saga would be we'll start you know t1 point transaction one and then end it",
    "start": "3291520",
    "end": "3298480"
  },
  {
    "text": "start next step start and end the next step and then the final service in the chain ends the saga",
    "start": "3298480",
    "end": "3304640"
  },
  {
    "text": "the downside of this is that every service is tightly coupled to your domain logic right every service needs to know what",
    "start": "3304640",
    "end": "3310880"
  },
  {
    "text": "happens after it and what happens before it if you want to rewire the order because now there's a fourth service in the middle you have to",
    "start": "3310880",
    "end": "3317440"
  },
  {
    "text": "change three components you have to change the fourth service you're adding and the two services on either side of that because now they're need to be",
    "start": "3317440",
    "end": "3323280"
  },
  {
    "text": "aware of what happens before them what happens after them with the orchestrator the other the",
    "start": "3323280",
    "end": "3328400"
  },
  {
    "text": "opposite is true right you don't have any domain logic in each op sorry or any routing logic in every service",
    "start": "3328400",
    "end": "3334240"
  },
  {
    "text": "but now we have a single point of failure which kind of isn't what we're going for in a distributed system you have one service",
    "start": "3334240",
    "end": "3340400"
  },
  {
    "text": "which has to handle everything it has to have all the acknowledgements and it probably has to have state because you can't store all of this",
    "start": "3340400",
    "end": "3346559"
  },
  {
    "text": "transaction information in memory it forces the court the orchestra service to have a database in some kind",
    "start": "3346559",
    "end": "3352079"
  },
  {
    "text": "of state and that has scaling and performance implications and so that's a tradeoff you have to make for yourself",
    "start": "3352079",
    "end": "3357760"
  },
  {
    "text": "for most of our systems we go with choreography which means every service knows what needs to happen after it",
    "start": "3357760",
    "end": "3363920"
  },
  {
    "text": "if if it's part of a selection mainly because we really want to avoid bottlenecks on the sort of orchestrating service",
    "start": "3363920",
    "end": "3370720"
  },
  {
    "text": "right and so if the attraction fails in the middle uh what happens is the service where it fails has to go and create what's called",
    "start": "3370720",
    "end": "3377200"
  },
  {
    "start": "3372000",
    "end": "3372000"
  },
  {
    "text": "a complimentary transaction so if we charge the person we need to create a message which reverses the charge",
    "start": "3377200",
    "end": "3382720"
  },
  {
    "text": "and send that in the other direction of the transaction and if there's another operation that needs to be cancelled",
    "start": "3382720",
    "end": "3387839"
  },
  {
    "text": "then the payment service needs to know that part of the cancelling transaction is to send a new message to the service",
    "start": "3387839",
    "end": "3393040"
  },
  {
    "text": "that came before it which is one which is part of the reason why it's actually complicated to do that",
    "start": "3393040",
    "end": "3400160"
  },
  {
    "text": "so towards the end of the talk i'm actually going to skip over the technologies something google online there's a",
    "start": "3400240",
    "end": "3406880"
  },
  {
    "start": "3401000",
    "end": "3401000"
  },
  {
    "text": "million different message queues and they all have their pluses and minuses uh but what i",
    "start": "3406880",
    "end": "3412079"
  },
  {
    "start": "3412000",
    "end": "3412000"
  },
  {
    "text": "really want to talk about is back pressure back pressure is a very important",
    "start": "3412079",
    "end": "3417359"
  },
  {
    "text": "consideration for us it's it's any system which has anytime scale will have this question of what happens",
    "start": "3417359",
    "end": "3424960"
  },
  {
    "text": "if a consumer service cannot keep up with the producer service right and so you have",
    "start": "3424960",
    "end": "3430000"
  },
  {
    "text": "two ways of handling back pressure which means the consumer service will need to tell",
    "start": "3430000",
    "end": "3435040"
  },
  {
    "text": "the producer to produce less you know i think in a synchronous system",
    "start": "3435040",
    "end": "3440880"
  },
  {
    "text": "there's no back pressure it's inherent right because the the second service fails and then the first service knows it that overloaded",
    "start": "3440880",
    "end": "3447040"
  },
  {
    "text": "but in an asymmetric system service b can fail and the messages will continue queuing up in the transport instantly",
    "start": "3447040",
    "end": "3452960"
  },
  {
    "text": "right and so we have two ways one is we can have some kind of flow control which means service b the receiving service would",
    "start": "3452960",
    "end": "3460079"
  },
  {
    "text": "have a way to tell the sending service to slow down the main problem with that is it brings",
    "start": "3460079",
    "end": "3466480"
  },
  {
    "text": "us right back into synchronous territory because that means that service a becomes unavailable",
    "start": "3466480",
    "end": "3472000"
  },
  {
    "text": "at the same time or slightly after service b becomes unavailable uh our other choice of course is to not",
    "start": "3472000",
    "end": "3478640"
  },
  {
    "text": "throttle or not do any kind of web pressure which means the queue or the message transport in",
    "start": "3478640",
    "end": "3484319"
  },
  {
    "text": "between the two services will continue growing until we either fix the problem with b",
    "start": "3484319",
    "end": "3489520"
  },
  {
    "text": "and in this case we have to usually scale out b a lot more to handle all the backlog of messages",
    "start": "3489520",
    "end": "3494880"
  },
  {
    "text": "or the message transfer fails there's no right answer to this you have to figure out what it is",
    "start": "3494880",
    "end": "3500240"
  },
  {
    "text": "that you need obviously the right answer is don't have scaling problems scale out uh automatically",
    "start": "3500240",
    "end": "3505280"
  },
  {
    "text": "uh but that's not always possible for most cases again this is a trailer for making our",
    "start": "3505280",
    "end": "3510720"
  },
  {
    "text": "system it will be a different set of considerations for others for every other system we almost always",
    "start": "3510720",
    "end": "3515839"
  },
  {
    "text": "choose the option on the right which is we choose to grow the queue infinitely and we allocate all of our message",
    "start": "3515839",
    "end": "3522079"
  },
  {
    "text": "transports with huge buffers of free disk space to queue up indefinitely because we prefer to potentially",
    "start": "3522079",
    "end": "3529200"
  },
  {
    "text": "reprocess you know two days worth of messages back uh than to lose data but again that's because losing data is the worst of the two",
    "start": "3529200",
    "end": "3536319"
  },
  {
    "text": "tradeoffs in our system for the kind of product we have and for different products that's going to be a",
    "start": "3536319",
    "end": "3541839"
  },
  {
    "text": "different uh trade-off right but of course basically the it's like we talked at the start of the",
    "start": "3541839",
    "end": "3547599"
  },
  {
    "text": "talk uh because of an asynchronous system we convert any kind of failures",
    "start": "3547599",
    "end": "3552720"
  },
  {
    "text": "into lag into latency and when we have lag we have to eventually consume all of this lag which means scaling out whatever it's",
    "start": "3552720",
    "end": "3558559"
  },
  {
    "text": "consuming and again last thing before we finish the talk uh error handling",
    "start": "3558559",
    "end": "3564480"
  },
  {
    "start": "3560000",
    "end": "3560000"
  },
  {
    "text": "uh again because unlike synchronous systems where error handling is very straightforward you get the exception to the requester",
    "start": "3564480",
    "end": "3570640"
  },
  {
    "text": "or all the way up the chain and you can handle it there because it's coupled in time",
    "start": "3570640",
    "end": "3577280"
  },
  {
    "text": "with an asynchronous system the error might happen an hour from now it might happen on a specific component",
    "start": "3577280",
    "end": "3582960"
  },
  {
    "text": "so what do we do let's imagine we have a queue of messages we have to process all of them",
    "start": "3582960",
    "end": "3588559"
  },
  {
    "text": "and process b is doing the consuming it will process message one message two and it will then fail to process message",
    "start": "3588559",
    "end": "3593680"
  },
  {
    "text": "three what does it do uh there are three broad categories of error handling in",
    "start": "3593680",
    "end": "3600000"
  },
  {
    "text": "asynchronous message systems one is they can continue retrying message three forever",
    "start": "3600000",
    "end": "3605200"
  },
  {
    "text": "eventually it might happen if the transient error if it's a timeout or database problem we can keep retrying until it",
    "start": "3605200",
    "end": "3610960"
  },
  {
    "text": "actually succeeds this makes sense if you can confidently identify that the error is transient",
    "start": "3610960",
    "end": "3616880"
  },
  {
    "text": "it's caused by something that's not the problem is with the message itself the problem is with an external component",
    "start": "3616880",
    "end": "3622240"
  },
  {
    "text": "and it will eventually go away and so retrying on place is a strategy where it makes sense if you know the error is transient",
    "start": "3622240",
    "end": "3628000"
  },
  {
    "text": "um if you don't want to block the queue if you think the retrying is going to take too long you can do what's called retry out of order",
    "start": "3628000",
    "end": "3634960"
  },
  {
    "text": "it means that you give up order of delivery you take the message out of the queue you put it in a different queue or",
    "start": "3634960",
    "end": "3640559"
  },
  {
    "text": "some other place and then you have some kind of scheduler to try that message again and maybe then you will succeed but if",
    "start": "3640559",
    "end": "3646480"
  },
  {
    "text": "this in this case you can continue processing the rest of the queue and not cause a traffic jam so to speak right you will want to lose throughput",
    "start": "3646480",
    "end": "3653200"
  },
  {
    "text": "the last option of course is a dead letter q if you can't do anything with the message the problem is the message itself there's no point in trying it there's",
    "start": "3653200",
    "end": "3659920"
  },
  {
    "text": "really nothing else you can do you have to take it out of the queue you have to put it somewhere else usually called dlq a dead letter queue",
    "start": "3659920",
    "end": "3666480"
  },
  {
    "text": "and then in most systems it's something that you manually look at there's no automatic system to handle dlq",
    "start": "3666480",
    "end": "3671920"
  },
  {
    "text": "uh because that's the final resting place of messages you can deliver um this is it uh",
    "start": "3671920",
    "end": "3678480"
  },
  {
    "text": "we're done exactly on time one minute over thank you very much for your attention i'm very happy to answer some questions",
    "start": "3678480",
    "end": "3684079"
  },
  {
    "text": "i don't see anyone writing in the chat in webex but let's see maybe someone wrote something in slack nobody wrote anything it's like you",
    "start": "3684079",
    "end": "3689440"
  },
  {
    "text": "people are very uh either know more than me about this topic so you have nothing to answer to question",
    "start": "3689440",
    "end": "3696000"
  },
  {
    "text": "about or you're very shy i'm not sure whichever that is but whatever the case may be i'm going",
    "start": "3696000",
    "end": "3702720"
  },
  {
    "text": "to hang out in slack for a bit more so i'm happy to answer questions",
    "start": "3702720",
    "end": "3708319"
  },
  {
    "text": "if you have any or you can see me typing in slack and you can reach out to me separately otherwise thank you very much",
    "start": "3708319",
    "end": "3714799"
  },
  {
    "text": "for coming to the talk hope you learned something interesting today an excellent rest of the conference",
    "start": "3714799",
    "end": "3727838"
  },
  {
    "text": "you",
    "start": "3731599",
    "end": "3733680"
  }
]
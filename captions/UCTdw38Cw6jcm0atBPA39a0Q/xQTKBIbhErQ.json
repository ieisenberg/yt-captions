[
  {
    "text": "can you flick the there we go great thank you okay",
    "start": "5960",
    "end": "13679"
  },
  {
    "text": "good morning everyone thank you very much for coming to our talk about large language models and the future and about",
    "start": "13679",
    "end": "20519"
  },
  {
    "text": "how they all Impact us and already we've got started with how language models",
    "start": "20519",
    "end": "25560"
  },
  {
    "text": "that have chat GTP can help us because I've asked it to improve the title of the not very interesting imaginative",
    "start": "25560",
    "end": "32000"
  },
  {
    "text": "intro and workflow session title and something much more captivating like",
    "start": "32000",
    "end": "37200"
  },
  {
    "text": "Unlocking The Magic of large language models so already it's helping us along our journey but this",
    "start": "37200",
    "end": "44360"
  },
  {
    "text": "talk has been great because every day there's a new exciting development in the whole world of language models AI",
    "start": "44360",
    "end": "51840"
  },
  {
    "text": "machine learning and so it's conly in a learning exercise to get the slides together and it's even worse when you're",
    "start": "51840",
    "end": "57559"
  },
  {
    "text": "trying to understand adapt and implement it into to your application and that's what we want to talk about today how can",
    "start": "57559",
    "end": "63199"
  },
  {
    "text": "you use it how can you go beyond just what are the best chat GTP prompts but",
    "start": "63199",
    "end": "68439"
  },
  {
    "text": "understands what's happening in the covers what's happening internally inside a large language model so you can",
    "start": "68439",
    "end": "75320"
  },
  {
    "text": "get the best out of them and that's why I can't do it by myself I have Barbara here to",
    "start": "75320",
    "end": "80880"
  },
  {
    "text": "help hi everyone can you hear me right yes great my name is Barbara Barbara",
    "start": "80880",
    "end": "88200"
  },
  {
    "text": "fska and from fact about me if you just Google my name or probably ask CH GPT",
    "start": "88200",
    "end": "94680"
  },
  {
    "text": "I'm the only person in the whole world named like myself so if you want to find me it's very easy I've been a software",
    "start": "94680",
    "end": "101960"
  },
  {
    "text": "engineer or I've been in the software engineering industry for almost 20 years",
    "start": "101960",
    "end": "107360"
  },
  {
    "text": "I know I look incredibly young but I switched to data science",
    "start": "107360",
    "end": "112680"
  },
  {
    "text": "field few years back when I moved to London that was around 9 years ago",
    "start": "112680",
    "end": "117880"
  },
  {
    "text": "however a few years back I switched to against my career and now I'm engineering manager currently working at",
    "start": "117880",
    "end": "125079"
  },
  {
    "text": "Docker what about you okay so I'm Ben Hall um I created a",
    "start": "125079",
    "end": "131280"
  },
  {
    "text": "platform a few years ago called katacoda it was an Interactive Learning um environment in your brow it was very",
    "start": "131280",
    "end": "137519"
  },
  {
    "text": "cool very exciting it got acquired by O'Reilly which was great and now I'm",
    "start": "137519",
    "end": "143160"
  },
  {
    "text": "working on something new and exciting which sadly is not quite ready to be revealed on camera and a live stream but",
    "start": "143160",
    "end": "149319"
  },
  {
    "text": "if you wanted to chat more uh we can talk about it offline over a beer later",
    "start": "149319",
    "end": "154720"
  },
  {
    "text": "and so what are we talking about today well oh yeah and just in case you haven't guessed from our magical",
    "start": "154720",
    "end": "160720"
  },
  {
    "text": "sparkling Charisma on camera we are a couple and honestly I do own more than one t-shirt it was just a",
    "start": "160720",
    "end": "167360"
  },
  {
    "text": "bad uh choice of packing when I did it um which I didn't quite realize until I",
    "start": "167360",
    "end": "172519"
  },
  {
    "text": "went through the slides earlier and I was committed so there we go but we are a couple and hopefully we'll still be a",
    "start": "172519",
    "end": "177599"
  },
  {
    "text": "couple after the end of this talk so what are we actually going to talk about well we want to kind of get you to",
    "start": "177599",
    "end": "185680"
  },
  {
    "text": "uh realize the potential understand what's happening in the cover which will be Barbara's part because I don't really",
    "start": "185680",
    "end": "191120"
  },
  {
    "text": "understand fully or not to the same degree and then how can you utilize it in the applications and go beyond just a",
    "start": "191120",
    "end": "197000"
  },
  {
    "text": "normal chat inp session and I hope that many of us have already been playing with these large language models things",
    "start": "197000",
    "end": "203400"
  },
  {
    "text": "like co-pilot can be intelligent on steroids so it can have the intelligence",
    "start": "203400",
    "end": "209080"
  },
  {
    "text": "of your entire codebase it understands the context about what you're trying to achieve the functions that you're trying to uh Implement and give you more",
    "start": "209080",
    "end": "216879"
  },
  {
    "text": "powerful suggestions than just the traditional Intellis sense we've been used to and so this is a very simple",
    "start": "216879",
    "end": "222640"
  },
  {
    "text": "example of just doing some mapping um just around my application and it's not very interesting code like this is code",
    "start": "222640",
    "end": "229040"
  },
  {
    "text": "which I don't really want to write at all and so having copilot just really in the background just makes it faster lets",
    "start": "229040",
    "end": "236079"
  },
  {
    "text": "me focus on what's more important and um pay attention to the most interesting",
    "start": "236079",
    "end": "241480"
  },
  {
    "text": "aspects of my system not this boiler plate code which AI can generate for us and this is only going to get more",
    "start": "241480",
    "end": "247400"
  },
  {
    "text": "powerful and um more influential over time and I noticed that went on the flight over without Wi-Fi without any",
    "start": "247400",
    "end": "254040"
  },
  {
    "text": "connectivity I kind of forgot how to write code without it because I'm so used to now type in a comment saying",
    "start": "254040",
    "end": "260079"
  },
  {
    "text": "remove this item from the array and co-pilot will just do it for me and",
    "start": "260079",
    "end": "265479"
  },
  {
    "text": "without that I was like ah I'll just do a to-do and I'll ask it when I get to the hotel",
    "start": "265479",
    "end": "270520"
  },
  {
    "text": "and there other systems like our chat Bots and chat implementations like chat GTP which gives us um powerful insights",
    "start": "270520",
    "end": "277600"
  },
  {
    "text": "so what color is discern and it's like well it's yellow well it's not because we know it's not and chat TP can give us",
    "start": "277600",
    "end": "284320"
  },
  {
    "text": "a good example about what the color actually is and throughout my entire life the Emojis which are yellow have",
    "start": "284320",
    "end": "290840"
  },
  {
    "text": "been lying to me but you know you can learn and you can adapt and evolve and he can ask it to write code which we're",
    "start": "290840",
    "end": "297440"
  },
  {
    "text": "all capable of doing but then may have some interesting edge cases that we don't really want to deal with in a very",
    "start": "297440",
    "end": "306560"
  },
  {
    "text": "um powerful way we just want to get the code working so in this case I was just",
    "start": "306560",
    "end": "312400"
  },
  {
    "text": "trying to pass a string and I just wanted to remove the title but the total can also have dashes and I wanted to",
    "start": "312400",
    "end": "318199"
  },
  {
    "text": "remove everything after the dash and there's a lots of edge cases that I was getting bored of trying to figure out so",
    "start": "318199",
    "end": "323720"
  },
  {
    "text": "I just got um chat GP to do it for me it can figure out where the edge Cas is and can it can work out what my code needs",
    "start": "323720",
    "end": "330560"
  },
  {
    "text": "to be doing and admittedly it took a few attempts it's very polite when it fails",
    "start": "330560",
    "end": "336280"
  },
  {
    "text": "and it says thank you for your patient and I'm sure I understand the auor because I did ask it a really annoying",
    "start": "336280",
    "end": "342479"
  },
  {
    "text": "problem about um which strings can have dashes where they can have dashes and trying to get that perfect title but",
    "start": "342479",
    "end": "348880"
  },
  {
    "text": "they figured it out in the end even if it did it take uh took five or six attempts and it can help me learn",
    "start": "348880",
    "end": "355479"
  },
  {
    "text": "language and learn features that I wasn't completely aware of I've been using handle the know for the last 10",
    "start": "355479",
    "end": "361199"
  },
  {
    "text": "years but I never knew that you could do a loop in this way until I got cha TP to write it for me and it helped me",
    "start": "361199",
    "end": "367319"
  },
  {
    "text": "discover our capabilities that I had just simply overlooked in the documentation and my set my way software",
    "start": "367319",
    "end": "373720"
  },
  {
    "text": "programmer who've been doing that for years hasn't bothered to look and find out if they the better way to be doing it so instead CHP can encourage me to",
    "start": "373720",
    "end": "381479"
  },
  {
    "text": "learn and write better code which I'm sure everyone would improve but again",
    "start": "381479",
    "end": "387039"
  },
  {
    "text": "it's not always perfect right it's told me to do um has owned property and visual studio",
    "start": "387039",
    "end": "394479"
  },
  {
    "text": "completely said that's not capable so it leads me down the wrong way so you always have to be slightly careful but",
    "start": "394479",
    "end": "399800"
  },
  {
    "text": "you ask it a further question and it will give you the right answer but there's still this learning curve it's still not ideal it's still not getting",
    "start": "399800",
    "end": "406680"
  },
  {
    "text": "there for example you ask to get something quite straightforward like Lady Gaga and cont contate the strings",
    "start": "406680",
    "end": "413280"
  },
  {
    "text": "should have used a better word um and it doesn't quite get it now this was chat GTP 3.5 which was",
    "start": "413280",
    "end": "420080"
  },
  {
    "text": "um kind of like at the end of last year version four does know so it's improving",
    "start": "420080",
    "end": "425360"
  },
  {
    "text": "it's iterating but it shows that language models aren't quite there yet and so in the words of Lady gagar itself",
    "start": "425360",
    "end": "434160"
  },
  {
    "text": "why Barbara does it do that why isn't it always getting it right and how is it",
    "start": "434160",
    "end": "439960"
  },
  {
    "text": "even detecting what's happening and what we need you know the answer is science",
    "start": "439960",
    "end": "447680"
  },
  {
    "text": "because it's science probabilities it's not magic it's not",
    "start": "447680",
    "end": "453759"
  },
  {
    "text": "actually speaking to human there are numbers underneath there and it all",
    "start": "453759",
    "end": "458960"
  },
  {
    "text": "started with attention actually you know I still feel that love is all you need",
    "start": "458960",
    "end": "465960"
  },
  {
    "text": "but let's talk about attention this is not a talk about love when we think of large language",
    "start": "465960",
    "end": "472280"
  },
  {
    "text": "models or any language models basically the way how it works is you feed it with",
    "start": "472280",
    "end": "478840"
  },
  {
    "text": "text and you get a text being generated the model does something and what it does we'll talk in a second but",
    "start": "478840",
    "end": "486280"
  },
  {
    "text": "basically we can think of starting a sentence and finishing it asking a",
    "start": "486280",
    "end": "491360"
  },
  {
    "text": "question and getting the answer right getting a paragraph and as the result we get a summary those are just few",
    "start": "491360",
    "end": "498919"
  },
  {
    "text": "examples of what language models could do and large language models are just doing it very very well so when we think",
    "start": "498919",
    "end": "507240"
  },
  {
    "text": "of what is the text that we are feeding our language models with this is not really a text models",
    "start": "507240",
    "end": "515959"
  },
  {
    "text": "are basically computer programs in a spe written in a specific way they need",
    "start": "515959",
    "end": "521320"
  },
  {
    "text": "numbers they don't work on Ro text so what has to be done is those that text",
    "start": "521320",
    "end": "529519"
  },
  {
    "text": "those words those characters have to be translated to tokens there are few ways",
    "start": "529519",
    "end": "535519"
  },
  {
    "text": "few different ways uh to create tokens the left one is AI the right one is uh",
    "start": "535519",
    "end": "542040"
  },
  {
    "text": "Simon remind me Ben Warren will yeah we're both really someone famous someone",
    "start": "542040",
    "end": "548000"
  },
  {
    "text": "famous if you like looking for large language models wrote his own tokenizer uh sometimes the words are",
    "start": "548000",
    "end": "555160"
  },
  {
    "text": "mapped one to one with just one number sometimes when they are built in specific way or um or have like suffixes",
    "start": "555160",
    "end": "563920"
  },
  {
    "text": "and prefixes they may be translated into several tokens but what you uh should",
    "start": "563920",
    "end": "569480"
  },
  {
    "text": "think about when thinking about tokens is it's repes it's a numeric representation of the word and that's",
    "start": "569480",
    "end": "575600"
  },
  {
    "text": "how we fit it to models care to build one I'm actually a little bit lying I'm",
    "start": "575600",
    "end": "582880"
  },
  {
    "text": "not going to build one but I'm showing you here how um again I really I'm",
    "start": "582880",
    "end": "589480"
  },
  {
    "text": "really bad in the name Andre Kathy uh build one very simple model",
    "start": "589480",
    "end": "596200"
  },
  {
    "text": "with attention with Transformers to generate",
    "start": "596200",
    "end": "601320"
  },
  {
    "text": "Shakespeare and if you want to learn anything about",
    "start": "601320",
    "end": "606480"
  },
  {
    "text": "NLP about machine learning is very good like much better than asban I'm",
    "start": "606480",
    "end": "613079"
  },
  {
    "text": "sorry agreed so I used his code and I'll be showing you the concepts of what is",
    "start": "613079",
    "end": "619600"
  },
  {
    "text": "needed to build large language model what is needed to build an architecture",
    "start": "619600",
    "end": "624839"
  },
  {
    "text": "I will show in a second and actually writing Shakespeare is not an easy task",
    "start": "624839",
    "end": "631279"
  },
  {
    "text": "it may seem like an easy task but the model has to learn plenty of things so we're feeding in this case we're feeding",
    "start": "631279",
    "end": "638560"
  },
  {
    "text": "it with streams of characters those are our in tokens in this",
    "start": "638560",
    "end": "643639"
  },
  {
    "text": "case and we're expecting first the model to learn that there are words and that",
    "start": "643639",
    "end": "649760"
  },
  {
    "text": "there are spaces in between them that there are sentences that there is a DOT",
    "start": "649760",
    "end": "654959"
  },
  {
    "text": "that there are commas some other characters that are uh punctuation marks",
    "start": "654959",
    "end": "660639"
  },
  {
    "text": "right we uh it has to learn the words right it's not just some random words",
    "start": "660639",
    "end": "666720"
  },
  {
    "text": "some random character put together it has to learn English it has to learn",
    "start": "666720",
    "end": "671760"
  },
  {
    "text": "that this is play Shakespeare was writing play so there is a character",
    "start": "671760",
    "end": "676959"
  },
  {
    "text": "name then there is a column then there is what this character said and then it",
    "start": "676959",
    "end": "682399"
  },
  {
    "text": "has to learn how to produce text produce plays like",
    "start": "682399",
    "end": "687519"
  },
  {
    "text": "Shakespeare so tons of tasks to do so first try Andrew wrote a very",
    "start": "687519",
    "end": "695360"
  },
  {
    "text": "simple very simple model and it basically has fewel",
    "start": "695360",
    "end": "701240"
  },
  {
    "text": "forward uh layers feed forward layers and it's not really producing good",
    "start": "701240",
    "end": "707680"
  },
  {
    "text": "results so what it does basically what every language model is doing is creating Logics which are probabilities",
    "start": "707680",
    "end": "716560"
  },
  {
    "text": "assigned to a word that is in this case a character that is predicted as",
    "start": "716560",
    "end": "722399"
  },
  {
    "text": "next you know the best prediction wins it's not winning right this first",
    "start": "722399",
    "end": "730200"
  },
  {
    "text": "attempt is just rubbish so what could you do",
    "start": "730200",
    "end": "736440"
  },
  {
    "text": "better large language models that's the idea so there are few reasons why the",
    "start": "736440",
    "end": "742519"
  },
  {
    "text": "previous attempts didn't work so previously this is also from Andre carpati on uh lstm and recurrent neural",
    "start": "742519",
    "end": "750240"
  },
  {
    "text": "networks that were our first attempts in language models we were feeding the model with",
    "start": "750240",
    "end": "756720"
  },
  {
    "text": "one word or one character at the time and then taking another character and looking back and like merging some",
    "start": "756720",
    "end": "764800"
  },
  {
    "text": "information to produce something outside of it and it didn't really work that",
    "start": "764800",
    "end": "770040"
  },
  {
    "text": "well lstms is a short is a an abbreviation from long shortterm memory",
    "start": "770040",
    "end": "776800"
  },
  {
    "text": "and it really wasn't long like like a paragraph was very often too long and it",
    "start": "776800",
    "end": "782399"
  },
  {
    "text": "did not remember what happened so that's one of the things that large language models are uh solving there are also",
    "start": "782399",
    "end": "790120"
  },
  {
    "text": "stuff that um it doesn't actually uh have an uh opportunity or doesn't have",
    "start": "790120",
    "end": "797040"
  },
  {
    "text": "an ability to see which word was where so location of the word let's",
    "start": "797040",
    "end": "803880"
  },
  {
    "text": "go to transformers this is what revolutionize large language models or this is what",
    "start": "803880",
    "end": "809880"
  },
  {
    "text": "revolutionized language models we have Transformers that were uh that is an",
    "start": "809880",
    "end": "815680"
  },
  {
    "text": "architecture that was published within the attention in that same paper atten",
    "start": "815680",
    "end": "821680"
  },
  {
    "text": "attention is all you need but it actually has few other things so first of all it has",
    "start": "821680",
    "end": "829639"
  },
  {
    "text": "attention in several places not just the ones that I've pointed here it has",
    "start": "829639",
    "end": "835480"
  },
  {
    "text": "positional encoding which is another technique helping with the order and it",
    "start": "835480",
    "end": "840839"
  },
  {
    "text": "has ADD and Norm which is not a New Concept at all but in this case adding",
    "start": "840839",
    "end": "847360"
  },
  {
    "text": "and normalizing is actually helping with backwards propagation so we also have",
    "start": "847360",
    "end": "855759"
  },
  {
    "text": "blocks uh there is an encoder and decoder in this architecture will just show or Andrew will just show the right",
    "start": "855759",
    "end": "862800"
  },
  {
    "text": "part so be just generating text will not be encoding but it's enough to show the",
    "start": "862800",
    "end": "869600"
  },
  {
    "text": "concepts let's start with the interesting part attention we have a",
    "start": "869600",
    "end": "875199"
  },
  {
    "text": "nice sentence me and Ben really like Cuts so the cuts scratched the sofa",
    "start": "875199",
    "end": "880720"
  },
  {
    "text": "because it was very bored I just mentioned that lstms didn't manage to",
    "start": "880720",
    "end": "887120"
  },
  {
    "text": "understand long sentences and one of the problems was like when you have a long sentence this one is not long but you",
    "start": "887120",
    "end": "893120"
  },
  {
    "text": "can imagine if you have a a paragraph and you have the word it it was lost",
    "start": "893120",
    "end": "899920"
  },
  {
    "text": "sometimes what does it is referring to attention is a mechanism to tell you",
    "start": "899920",
    "end": "906279"
  },
  {
    "text": "when you're processing it what you should be paying attention to within the",
    "start": "906279",
    "end": "911959"
  },
  {
    "text": "whole sentence so that the darker the color the more attention you should be",
    "start": "911959",
    "end": "918000"
  },
  {
    "text": "paying that's the concept how is it done it's done by matrices obviously",
    "start": "918000",
    "end": "925800"
  },
  {
    "text": "it's machine learning it's a we have plenty of M matrix multiplication there",
    "start": "925800",
    "end": "930880"
  },
  {
    "text": "are three of them query key and value and they are showing three concepts of",
    "start": "930880",
    "end": "936880"
  },
  {
    "text": "what attention is and those vectors WQ w k WV are the vectors that",
    "start": "936880",
    "end": "945199"
  },
  {
    "text": "our neural network the Transformer neural network is learning when it's",
    "start": "945199",
    "end": "951759"
  },
  {
    "text": "training what it does with it some more mths so basically is taking query and",
    "start": "952319",
    "end": "958000"
  },
  {
    "text": "keys multiply them there is a scaling there uh there could be some masking",
    "start": "958000",
    "end": "963880"
  },
  {
    "text": "there then there is soft marks there are plenty of soft marks in machine learning and then it takes the result and again",
    "start": "963880",
    "end": "970720"
  },
  {
    "text": "multiply it with values and it's actually the math is very very simple you just have those uh",
    "start": "970720",
    "end": "979000"
  },
  {
    "text": "M matrices you create them and you do those multiplications Andre added a very",
    "start": "979000",
    "end": "986360"
  },
  {
    "text": "cool masking thing so he added something that when you're processing a specific word you're taking the",
    "start": "986360",
    "end": "993440"
  },
  {
    "text": "average of what happened before so there are two ways of masking it just looking",
    "start": "993440",
    "end": "999600"
  },
  {
    "text": "at at the back of the sentence or looking at the whole of the sentence looking in the past is easier usually in",
    "start": "999600",
    "end": "1007240"
  },
  {
    "text": "life is easier look in the past than look in the future there's another thing I've mentioned there is positional",
    "start": "1007240",
    "end": "1013759"
  },
  {
    "text": "encoding so for embeddings that are another representation of our words",
    "start": "1013759",
    "end": "1019600"
  },
  {
    "text": "we'll talk about this later positional encoding is just adding",
    "start": "1019600",
    "end": "1025079"
  },
  {
    "text": "information to that representation saying this word is the first word this",
    "start": "1025079",
    "end": "1030160"
  },
  {
    "text": "was word is the second word this word is the in the middle of the sentence so there is an encoding special algorithms",
    "start": "1030160",
    "end": "1037640"
  },
  {
    "text": "that is added to what we are processing within the neuron Network and it actually captures the",
    "start": "1037640",
    "end": "1045600"
  },
  {
    "text": "location of the word and it's again done very simply",
    "start": "1045600",
    "end": "1051360"
  },
  {
    "text": "it's just created and added I also posted here add and Norm which is very",
    "start": "1051360",
    "end": "1056840"
  },
  {
    "text": "simple operation basically add and Norm right but it's very important and very",
    "start": "1056840",
    "end": "1064120"
  },
  {
    "text": "powerful thing that is used in Transformers very often neglected because attention is this this cool",
    "start": "1064120",
    "end": "1071240"
  },
  {
    "text": "thing but without adding and norming uh the the training would take much longer",
    "start": "1071240",
    "end": "1076640"
  },
  {
    "text": "and wouldn't be that effective so we have position and holding here we",
    "start": "1076640",
    "end": "1081840"
  },
  {
    "text": "have blocks and then we run our model and this is something we got after",
    "start": "1081840",
    "end": "1087880"
  },
  {
    "text": "500 iterations still not perfect or far from perfect but 500 5,000 interation is not",
    "start": "1087880",
    "end": "1095720"
  },
  {
    "text": "a very long time and this code has maybe 50 lines of code so this is something",
    "start": "1095720",
    "end": "1102240"
  },
  {
    "text": "that is and and if you don't believe me go to Andrew's blog and it's out there",
    "start": "1102240",
    "end": "1108880"
  },
  {
    "text": "it's in GitHub and everything and in 500 interations which took like what 10",
    "start": "1108880",
    "end": "1114240"
  },
  {
    "text": "minutes or something we have something like this and that's pretty impressive just",
    "start": "1114240",
    "end": "1120200"
  },
  {
    "text": "because of those techniques think it's your part that is impressive so that's great when you've",
    "start": "1120200",
    "end": "1126559"
  },
  {
    "text": "got Shakespeare it's a known data set so you can start learning what naturally",
    "start": "1126559",
    "end": "1132240"
  },
  {
    "text": "comes next in Shakespeare because he has certain patterns and certain approaches",
    "start": "1132240",
    "end": "1137280"
  },
  {
    "text": "and so you when want to gener WR more of it you can use that probability quite effectively to understand what's coming",
    "start": "1137280",
    "end": "1142919"
  },
  {
    "text": "next but when you're asking potentially random andn it becomes a lot harder and",
    "start": "1142919",
    "end": "1148559"
  },
  {
    "text": "as such you need a lot more data so where do you get all of this data from where has open AI managed to understand",
    "start": "1148559",
    "end": "1156480"
  },
  {
    "text": "the entire world's knowledge and capture it and make it so that it can predict",
    "start": "1156480",
    "end": "1162320"
  },
  {
    "text": "what token comes next and as F finish sentences and questions and tell us to",
    "start": "1162320",
    "end": "1167880"
  },
  {
    "text": "Will information and so there's a few different projects there's like common crawl which has over the past uh",
    "start": "1167880",
    "end": "1174280"
  },
  {
    "text": "multiple years collected every single web page on the internet and made it available in a data set and so you can",
    "start": "1174280",
    "end": "1180320"
  },
  {
    "text": "go and you can download the entire internet literally as one or multiple t",
    "start": "1180320",
    "end": "1185840"
  },
  {
    "text": "files but the problem is the entire Internet isn't that useful there's lots",
    "start": "1185840",
    "end": "1191760"
  },
  {
    "text": "of garbage out there surprisingly so what else can you use what other signals are much more powerful to build you a",
    "start": "1191760",
    "end": "1199480"
  },
  {
    "text": "better data set which would then build you better results on the output CU it's all that matters about how to predict",
    "start": "1199480",
    "end": "1205679"
  },
  {
    "text": "what comes next is you want valuable high quality content to tell you what is",
    "start": "1205679",
    "end": "1210960"
  },
  {
    "text": "the best probability of what comes next and so we need valuable high quality data search to do that and so in the",
    "start": "1210960",
    "end": "1217200"
  },
  {
    "text": "early days um open AI was a little bit um more transparent about what they were",
    "start": "1217200",
    "end": "1222760"
  },
  {
    "text": "doing and so they would say we use redit reddit reddit has natural voting built",
    "start": "1222760",
    "end": "1227919"
  },
  {
    "text": "in and so you knew what links were valuable because other people has already told you actually that has some",
    "start": "1227919",
    "end": "1233600"
  },
  {
    "text": "value to me and so it's much more interesting and so now instead of having the entire internet you have a set of",
    "start": "1233600",
    "end": "1239799"
  },
  {
    "text": "links on Reddit that has um greater than three so some looked at it someone's understood it and someone said yeah that",
    "start": "1239799",
    "end": "1246120"
  },
  {
    "text": "actually is reasonable or not still could be complete pack of Lies but at least it's a step in the right direction",
    "start": "1246120",
    "end": "1252320"
  },
  {
    "text": "and you have St overflow and other valuable websites which have all of this data available and was all very nice and",
    "start": "1252320",
    "end": "1259440"
  },
  {
    "text": "packaged up every single stack Overflow question and answer because that was valuable at the time what turns out is",
    "start": "1259440",
    "end": "1267120"
  },
  {
    "text": "it's a little bit too valuable because now open AI have got all of that t data it's taken it and built and transformed",
    "start": "1267120",
    "end": "1273799"
  },
  {
    "text": "the internet and kind of made stack off for fellow less relevant than what it was previously and so now all of these",
    "start": "1273799",
    "end": "1279960"
  },
  {
    "text": "companies which had this vast information are starting to remove all of this access Reddit has started to",
    "start": "1279960",
    "end": "1285679"
  },
  {
    "text": "dicate their API so you can't scrape it and you can't access it quite so easily stack Overflow stop doing dumps of their",
    "start": "1285679",
    "end": "1292480"
  },
  {
    "text": "data and so instead of the latest questions you don't have that information available anymore and",
    "start": "1292480",
    "end": "1298279"
  },
  {
    "text": "instead they're charging companies because they're trying to make revenue streams too and this will pose a problem",
    "start": "1298279",
    "end": "1303320"
  },
  {
    "text": "for the future like how do we get Beyond September 2021 which was the last cut",
    "start": "1303320",
    "end": "1308840"
  },
  {
    "text": "off point where they had all of the information this new information since then isn't as readly readily available",
    "start": "1308840",
    "end": "1315679"
  },
  {
    "text": "but there are other sources one of the the joys of not disclosing every single",
    "start": "1315679",
    "end": "1320760"
  },
  {
    "text": "data source means that you can potentially have data source you maybe you shouldn't use or own such as lip gen",
    "start": "1320760",
    "end": "1328720"
  },
  {
    "text": "which may or may not be a collection of every single data set on uh in the world",
    "start": "1328720",
    "end": "1335520"
  },
  {
    "text": "again packaged up as nicely available data set that you can just download and",
    "start": "1335520",
    "end": "1340960"
  },
  {
    "text": "extract and this has got everything every single fiction or book every non-fiction every scientific paper that",
    "start": "1340960",
    "end": "1347760"
  },
  {
    "text": "has been published has generally found its way onto this darker side of the web and has been packaged up and it's big it",
    "start": "1347760",
    "end": "1355559"
  },
  {
    "text": "is really big if you think the entire of Wikipedia is about 22 gab the entire of",
    "start": "1355559",
    "end": "1361320"
  },
  {
    "text": "ligen is 130 terabytes so now they have a huge resource if they were using this",
    "start": "1361320",
    "end": "1368039"
  },
  {
    "text": "to train their models which we don't know if they are but if they had then they have the huge reource of valuable",
    "start": "1368039",
    "end": "1373760"
  },
  {
    "text": "information of published books so you know it's going to be very high quality but they don't announce what they are",
    "start": "1373760",
    "end": "1380400"
  },
  {
    "text": "using to train so we'll never know if that's the case but what we do know is that they have a huge amount of data and",
    "start": "1380400",
    "end": "1386880"
  },
  {
    "text": "that's what it's been trained on so 170 trillion parameters so these are kind of like number of words",
    "start": "1386880",
    "end": "1394679"
  },
  {
    "text": "tokens atoms not tokens okay and that it's been trained on and if we turned",
    "start": "1394679",
    "end": "1401440"
  },
  {
    "text": "let's say 130 trillion words into A4 Pages 3 billion okay what's that in real",
    "start": "1401440",
    "end": "1408039"
  },
  {
    "text": "numbers that's a lot of trees over 60 Acres and to trust that these numbers are",
    "start": "1408039",
    "end": "1414440"
  },
  {
    "text": "correct I did ask chat GTP so they may or may not be correct but you can see the conversation um afterwards so how",
    "start": "1414440",
    "end": "1421960"
  },
  {
    "text": "much do it this cost because this is a huge amount of data it only it took 5,000 iterations to",
    "start": "1421960",
    "end": "1428440"
  },
  {
    "text": "train on Shakespeare but this is a vast amount more data than normal and so",
    "start": "1428440",
    "end": "1433960"
  },
  {
    "text": "according to internet rumors which are always accurate it cost about 63 million",
    "start": "1433960",
    "end": "1439440"
  },
  {
    "text": "which is not an insubstantial chunk and in terms of real resources that's about",
    "start": "1439440",
    "end": "1444559"
  },
  {
    "text": "25,000 um gpus each server can have about eight gpus so that's about 3,000 servers and",
    "start": "1444559",
    "end": "1451720"
  },
  {
    "text": "so that's a lot of computing power running constantly over 100 days in order to build and train these models",
    "start": "1451720",
    "end": "1459080"
  },
  {
    "text": "Ben who did those calculations someone on the internet okay I thought I don't know not me okay",
    "start": "1459080",
    "end": "1468200"
  },
  {
    "text": "um some something accurate and all of the information came from this blog post about leak details so that's why I'm",
    "start": "1468200",
    "end": "1474320"
  },
  {
    "text": "taking it as fact um so but we have spent all of this money since uh 63 million",
    "start": "1474320",
    "end": "1481640"
  },
  {
    "text": "roughly uh if we were to rent it ourselves and yet it still doesn't know",
    "start": "1481640",
    "end": "1487520"
  },
  {
    "text": "what Barbara's hobbies are and why would it because it's got nothing in the prompt to help predict what comes next",
    "start": "1487520",
    "end": "1494039"
  },
  {
    "text": "it has nothing to indicate what or who Barbara is so of course it doesn't know",
    "start": "1494039",
    "end": "1499120"
  },
  {
    "text": "but that is problematic if I did want to know that I would like to know what Barber's hobbies",
    "start": "1499120",
    "end": "1505159"
  },
  {
    "text": "are so how do we solve that problem and we will reveal what my hobbies are by",
    "start": "1505159",
    "end": "1511440"
  },
  {
    "text": "the end of this spoilers we'll show you how to do it so",
    "start": "1511440",
    "end": "1517120"
  },
  {
    "text": "the way how to well introduce new information or introduce information",
    "start": "1517120",
    "end": "1523679"
  },
  {
    "text": "that you don't want those models to be trained on because it could be something that you want to have a data privacy",
    "start": "1523679",
    "end": "1531640"
  },
  {
    "text": "over there's some security about the data that is after 2021 obviously if you",
    "start": "1531640",
    "end": "1538600"
  },
  {
    "text": "want this to talk in some way or with some vocabulary with some concepts of a",
    "start": "1538600",
    "end": "1544399"
  },
  {
    "text": "specific domain I don't know law legal comes to mind here uh if you want the",
    "start": "1544399",
    "end": "1550360"
  },
  {
    "text": "model to perform specific task the like General models they may",
    "start": "1550360",
    "end": "1557720"
  },
  {
    "text": "seem amazing especially Char GPT but not always fitting in those things so what",
    "start": "1557720",
    "end": "1565159"
  },
  {
    "text": "could we do we could customize our model with some some of the open AI models",
    "start": "1565159",
    "end": "1570679"
  },
  {
    "text": "like Newton I think are customizable uh not all of them not CH",
    "start": "1570679",
    "end": "1575840"
  },
  {
    "text": "GPT but plenty models out there you could take customize do something with it so how can you do it the first thing",
    "start": "1575840",
    "end": "1584200"
  },
  {
    "text": "is we want to talk about specific use cases specific use case is about you",
    "start": "1584200",
    "end": "1590640"
  },
  {
    "text": "have new knowledge or you have the knowledge you don't want to share with the word so the model to be built on and",
    "start": "1590640",
    "end": "1598120"
  },
  {
    "text": "you want this model to look at your knowledge base and answer questions so that's our use",
    "start": "1598120",
    "end": "1605880"
  },
  {
    "text": "case one of the ways you could do it is you can provide the information with the prompt prompt it's called few shot",
    "start": "1605880",
    "end": "1613159"
  },
  {
    "text": "learning so basically it goes like this these are some pieces of information",
    "start": "1613159",
    "end": "1619279"
  },
  {
    "text": "based on this answer those questions that's great that sounds good",
    "start": "1619279",
    "end": "1624360"
  },
  {
    "text": "model takes it and provides the information because because it can also Pro uh process the prompt and get that",
    "start": "1624360",
    "end": "1631799"
  },
  {
    "text": "information however there was a huge caveat with it you cannot load your",
    "start": "1631799",
    "end": "1636880"
  },
  {
    "text": "whole knowledge base in a prompt there are limitations of the prompt so what",
    "start": "1636880",
    "end": "1642240"
  },
  {
    "text": "are the other ways another way is fine tuning and fine tuning is what internet",
    "start": "1642240",
    "end": "1650440"
  },
  {
    "text": "is raving at the moment there are books there are blogs there are talks like",
    "start": "1650440",
    "end": "1655840"
  },
  {
    "text": "ours how to do prompt engineering so you build",
    "start": "1655840",
    "end": "1661519"
  },
  {
    "text": "some prompts for the specific task which fine tuning is great for and this model",
    "start": "1661519",
    "end": "1668399"
  },
  {
    "text": "is gathering this information from those prompt not information is gathering the way how it should perform the task and",
    "start": "1668399",
    "end": "1676279"
  },
  {
    "text": "then it can can answer your question the thing is uh with the fuse shut learning",
    "start": "1676279",
    "end": "1685840"
  },
  {
    "text": "if you provide it with information once and you want this information in another prompt to be in the model it won't be",
    "start": "1685840",
    "end": "1692080"
  },
  {
    "text": "there model will not change itself it will not change its knowledge knowledge base here you can provide this knowledge",
    "start": "1692080",
    "end": "1700399"
  },
  {
    "text": "however it's been proven that fine tuning is not the best way to provide new knowledge to the model it's much",
    "start": "1700399",
    "end": "1706919"
  },
  {
    "text": "better for performing another task for example if you want a model to explain",
    "start": "1706919",
    "end": "1715120"
  },
  {
    "text": "things very clearly and talk like a 5-year-old so it still will have the",
    "start": "1715120",
    "end": "1721000"
  },
  {
    "text": "same knowledge but it will learn the style and the way how to generate text",
    "start": "1721000",
    "end": "1727640"
  },
  {
    "text": "from the prompts and and from the answers of those prompts this whole process is not",
    "start": "1727640",
    "end": "1733840"
  },
  {
    "text": "easy there is plenty of uh software out there to use use it it takes time it has",
    "start": "1733840",
    "end": "1739399"
  },
  {
    "text": "some reinforcement learning human in theop there's plenty of complexity but",
    "start": "1739399",
    "end": "1745039"
  },
  {
    "text": "if you want to adjust your model to your specific tasks that's a very good way to",
    "start": "1745039",
    "end": "1750720"
  },
  {
    "text": "go I think it's your now it is y so you can so if you can't train a model or",
    "start": "1750720",
    "end": "1757399"
  },
  {
    "text": "fine tune a model because you have more data set or because it just didn't fit how do you still get the answer and this",
    "start": "1757399",
    "end": "1763960"
  },
  {
    "text": "is where you can start adjusting a prompt without try find tuning with just an after shelf model so in the covers",
    "start": "1763960",
    "end": "1772039"
  },
  {
    "text": "when you open CHP it gives some very basic initial knowledge which says it's an assistant it's trained by Ai and it's",
    "start": "1772039",
    "end": "1779679"
  },
  {
    "text": "got a knowledge cut off so it has very basic information but you can adjust this and so you can say actually I want",
    "start": "1779679",
    "end": "1786760"
  },
  {
    "text": "to start the prompt with a Define rules Define set behaviors toine how um I want",
    "start": "1786760",
    "end": "1794360"
  },
  {
    "text": "the output to be and what this is doing is it's changing in that probability about what characters come next and it's",
    "start": "1794360",
    "end": "1800240"
  },
  {
    "text": "just in how it knows what to and how to um continue the output and so for",
    "start": "1800240",
    "end": "1806519"
  },
  {
    "text": "example if we look at other chat Bots built on top of chat GTP and open AI for",
    "start": "1806519",
    "end": "1812600"
  },
  {
    "text": "example Sydney which is uh being chat apparently then we can look at the",
    "start": "1812600",
    "end": "1818200"
  },
  {
    "text": "prompt now how this got leaked onto the internet is a work of art um basically",
    "start": "1818200",
    "end": "1823679"
  },
  {
    "text": "by asking the language model various different interesting questions to break outside of its safeguards but that's a",
    "start": "1823679",
    "end": "1829600"
  },
  {
    "text": "whole another talk but we have the answer and so we can see how Microsoft has tweaked and adjusted that initial",
    "start": "1829600",
    "end": "1836360"
  },
  {
    "text": "prompt to make it more targeted for how it wants the language model to behave",
    "start": "1836360",
    "end": "1841440"
  },
  {
    "text": "and so it says Sydney is a chat bar and it's being thir great so we kind of have",
    "start": "1841440",
    "end": "1846480"
  },
  {
    "text": "ajed that if anyone asks it had some information so do not disclose that you actually CAU fitney internally which",
    "start": "1846480",
    "end": "1853399"
  },
  {
    "text": "obviously are failed language models are still just these predictability um systems and so without the right",
    "start": "1853399",
    "end": "1860720"
  },
  {
    "text": "safeguards or without enough safeguards in place these internal details stand can still be um disclosed but it has got",
    "start": "1860720",
    "end": "1868279"
  },
  {
    "text": "some interesting points like how to deal with copyrighted information it's defining the rules and the structures",
    "start": "1868279",
    "end": "1873639"
  },
  {
    "text": "about what it wants the system to behave and the output it wants to produce and there's endless amounts of information",
    "start": "1873639",
    "end": "1879440"
  },
  {
    "text": "it puts into it in order to get that perfect experience based on what Microsoft Bing is looking",
    "start": "1879440",
    "end": "1885799"
  },
  {
    "text": "for and we could also just asked the language model itself to improve so we don't have to come up with these",
    "start": "1885799",
    "end": "1892559"
  },
  {
    "text": "beautiful best chtp prompts um ourselves if you remember back to our opening side",
    "start": "1892559",
    "end": "1899120"
  },
  {
    "text": "where I said like hey come up with an interesting or better version of um the",
    "start": "1899120",
    "end": "1904639"
  },
  {
    "text": "talk title we could also say like okay that was a great answer but what would a",
    "start": "1904639",
    "end": "1909799"
  },
  {
    "text": "better prompt have been for me to ask you in the first place and he like and then how it works and the predictability",
    "start": "1909799",
    "end": "1916840"
  },
  {
    "text": "we come up with thumbs in which is uh which you can then ask and prompt it again so you start building up these",
    "start": "1916840",
    "end": "1922960"
  },
  {
    "text": "Loops to get better and better output and now we went from um the magic of unlocking to pushing cold horizons with",
    "start": "1922960",
    "end": "1930480"
  },
  {
    "text": "Ben and Barbara so it's better worse who knows but at least it's a different way of changing the output um and exploring",
    "start": "1930480",
    "end": "1939000"
  },
  {
    "text": "and going beyond what you may normally ask for and this is how systems are being built systems that are using and",
    "start": "1939000",
    "end": "1945320"
  },
  {
    "text": "building on top of language models I taken these very complicated well not complicated but very structured prompts",
    "start": "1945320",
    "end": "1951200"
  },
  {
    "text": "injecting it with pieces of information about where I want it such as what the question is what data do they have in",
    "start": "1951200",
    "end": "1956720"
  },
  {
    "text": "place and using that context to help build a better response as developers we",
    "start": "1956720",
    "end": "1963600"
  },
  {
    "text": "love building framework to do that and so that's all nicely available through something called Lang chain which I'm",
    "start": "1963600",
    "end": "1968960"
  },
  {
    "text": "sure will see grow over time as a way that they have got these pre-built predefined language um predefined",
    "start": "1968960",
    "end": "1976480"
  },
  {
    "text": "prompts which been optimized to get the best result possible and so now we can ask what if",
    "start": "1976480",
    "end": "1984159"
  },
  {
    "text": "bar with hob is and if we give it the information in the prompt then obviously",
    "start": "1984159",
    "end": "1989200"
  },
  {
    "text": "the language model can use that information and start inferring what the uh correct information is which is cost",
    "start": "1989200",
    "end": "1995559"
  },
  {
    "text": "stitching I told you I look incredibly young but how do we get more",
    "start": "1995559",
    "end": "2001120"
  },
  {
    "text": "information well how do we get more information or how do we get more creative information",
    "start": "2001120",
    "end": "2008960"
  },
  {
    "text": "I told you it's not magic and it's really really early to say that machines",
    "start": "2008960",
    "end": "2014519"
  },
  {
    "text": "are creative but they can fake creativeness and how do they do that I've mentioned at the beginning that",
    "start": "2014519",
    "end": "2021840"
  },
  {
    "text": "language models especially large language models take are taking the text",
    "start": "2021840",
    "end": "2027080"
  },
  {
    "text": "and then predicting the next thing and how do they do it so first thing to",
    "start": "2027080",
    "end": "2032679"
  },
  {
    "text": "predict next thing is they basically predict all of the things and they then",
    "start": "2032679",
    "end": "2038960"
  },
  {
    "text": "they rank it that's that's very very simple explanation they rank it that",
    "start": "2038960",
    "end": "2045799"
  },
  {
    "text": "rank that probabilities of what should come next are calculated and",
    "start": "2045799",
    "end": "2052240"
  },
  {
    "text": "then there are techniques what to do do we take the the thing that is the most",
    "start": "2052240",
    "end": "2057679"
  },
  {
    "text": "probable the most likely or we should think about some spicing things up",
    "start": "2057679",
    "end": "2065200"
  },
  {
    "text": "Ben As You Are are more creative of the dynamic duo when I say the sky is what's",
    "start": "2065200",
    "end": "2074240"
  },
  {
    "text": "beautiful there you go not even on the list see not even on the list clear or",
    "start": "2074240",
    "end": "2080560"
  },
  {
    "text": "the limit would be What temperature would be like very low",
    "start": "2080560",
    "end": "2086960"
  },
  {
    "text": "beautiful is more creative come on you can do better I really",
    "start": "2086960",
    "end": "2092760"
  },
  {
    "text": "can't let's not have an argument this sky is the entrance to the",
    "start": "2092760",
    "end": "2100440"
  },
  {
    "text": "space I don't know I just made it up or it could go really overboard if you are",
    "start": "2100440",
    "end": "2107800"
  },
  {
    "text": "like increasing that temperature with the creativity which basically means take into account more possibilities",
    "start": "2107800",
    "end": "2114079"
  },
  {
    "text": "temperature is not the only technique but I'm talking about this now it can go really overboard like it can be non may",
    "start": "2114079",
    "end": "2121760"
  },
  {
    "text": "have no sense so when you're thinking of this parameter when infering",
    "start": "2121760",
    "end": "2128040"
  },
  {
    "text": "experiment and see what actually is your level uh of the temperature but there",
    "start": "2128040",
    "end": "2134359"
  },
  {
    "text": "are other techniques and it's making the models not deterministic because it can",
    "start": "2134359",
    "end": "2140760"
  },
  {
    "text": "even with those probabilities it can tweak things",
    "start": "2140760",
    "end": "2146078"
  },
  {
    "text": "up we've mentioned uh the limitations of the context",
    "start": "2146400",
    "end": "2151720"
  },
  {
    "text": "window and what about our use case when we have our knowledge BAS base and we",
    "start": "2151720",
    "end": "2157480"
  },
  {
    "text": "want those models to to actually use the information from it and answer our",
    "start": "2157480",
    "end": "2163880"
  },
  {
    "text": "questions our specific domain questions there is a technique um that is connected with",
    "start": "2163880",
    "end": "2171960"
  },
  {
    "text": "information retrial which is a very fancy name scientific name for",
    "start": "2171960",
    "end": "2177880"
  },
  {
    "text": "search how it works is you know a person is asking how do I install Docker 421",
    "start": "2177880",
    "end": "2187280"
  },
  {
    "text": "this is not the newest version of Docker but it was after 2019 so it definitely wasn't in the",
    "start": "2187280",
    "end": "2193760"
  },
  {
    "text": "knowledge base of uh of the data sets that the models basically that chap PT",
    "start": "2193760",
    "end": "2200640"
  },
  {
    "text": "were uh trained on so what we could do we could build a system that is taking",
    "start": "2200640",
    "end": "2206760"
  },
  {
    "text": "this question search for our knowledge base and think of the best candidates",
    "start": "2206760",
    "end": "2212599"
  },
  {
    "text": "and it takes those best candidates it could be whole document it could be a paragraph that is saying could be like a",
    "start": "2212599",
    "end": "2218319"
  },
  {
    "text": "blog post whatever we have in our knowledge base and then it can build a",
    "start": "2218319",
    "end": "2223720"
  },
  {
    "text": "prompt now we have dedicated answers but we want the best answer so we build a",
    "start": "2223720",
    "end": "2230880"
  },
  {
    "text": "prompt this is the information we have answer the following",
    "start": "2230880",
    "end": "2237200"
  },
  {
    "text": "questions and then we feed it to large language models large language models have or should have at this point the",
    "start": "2237200",
    "end": "2243960"
  },
  {
    "text": "whole information it needs and it should answer well we need something else to",
    "start": "2243960",
    "end": "2252000"
  },
  {
    "text": "actually make it work what are those numbers what are",
    "start": "2252000",
    "end": "2257240"
  },
  {
    "text": "embeddings embeddings are a representation multi- uh dimensional",
    "start": "2257240",
    "end": "2263160"
  },
  {
    "text": "representation of words of paragraphs of sentences and those numbers here are",
    "start": "2263160",
    "end": "2269000"
  },
  {
    "text": "embeddings of the word",
    "start": "2269000",
    "end": "2272280"
  },
  {
    "text": "embeddings why do we need embeddings or why why are they useful it's to capture",
    "start": "2274200",
    "end": "2280240"
  },
  {
    "text": "the relation between words so you might have heard about word to Vector it was a",
    "start": "2280240",
    "end": "2287079"
  },
  {
    "text": "hit like I don't know five years ago uh but embeding are still created and still",
    "start": "2287079",
    "end": "2292680"
  },
  {
    "text": "being used and every large language model has them so you could think for example here the embeddings are um",
    "start": "2292680",
    "end": "2300560"
  },
  {
    "text": "figuring out the genre of the book uh book titles so what why do we need those",
    "start": "2300560",
    "end": "2307520"
  },
  {
    "text": "representations because this is how we actually do information retrieval again",
    "start": "2307520",
    "end": "2312760"
  },
  {
    "text": "very simple very uh high level view on this when we have our query how do I",
    "start": "2312760",
    "end": "2319839"
  },
  {
    "text": "install Docker version 4.21 this query is getting vectorized",
    "start": "2319839",
    "end": "2326480"
  },
  {
    "text": "how do we how do can we vectorize it we can use embeddings you can usually have some API",
    "start": "2326480",
    "end": "2334720"
  },
  {
    "text": "or some program that will just take your row text and turn it into",
    "start": "2334720",
    "end": "2340760"
  },
  {
    "text": "vector and what do you do with that Vector there is one technique not the only one that you're finding out another",
    "start": "2340760",
    "end": "2349960"
  },
  {
    "text": "Vector in your database because you did some work before with your database and you vectorize your knowledge base and",
    "start": "2349960",
    "end": "2357520"
  },
  {
    "text": "you check is this query similar and how similar to the things you already have",
    "start": "2357520",
    "end": "2363640"
  },
  {
    "text": "in database and based on that on that rank of",
    "start": "2363640",
    "end": "2369440"
  },
  {
    "text": "similarity you return you return your best candidates this time Ro text because we have to build the prompt from",
    "start": "2369440",
    "end": "2378520"
  },
  {
    "text": "it okay and so that's how we now if we had a entire database of Barbara's Hobbies we'd be able to look up the most",
    "start": "2379079",
    "end": "2386160"
  },
  {
    "text": "relevant inject that into the prompt and we'd have um all of the information the language model needs to give us the",
    "start": "2386160",
    "end": "2392079"
  },
  {
    "text": "right answer and this is how systems like co- piler are used using and providing accurate intelligence based on",
    "start": "2392079",
    "end": "2399599"
  },
  {
    "text": "our code bases cuz they're taking our entire code base converting it into embeddings pulling that into a vector",
    "start": "2399599",
    "end": "2405400"
  },
  {
    "text": "database and then when we need to look it up they're taking that relevant information injecting it into a prompt",
    "start": "2405400",
    "end": "2412160"
  },
  {
    "text": "like we've seen and passing that to a large language model and the mount language model is coming back with the",
    "start": "2412160",
    "end": "2417520"
  },
  {
    "text": "relevant information based on the question and so again the internals of co-pilot are available this is a",
    "start": "2417520",
    "end": "2423000"
  },
  {
    "text": "snapshot there's also um the prompts available but what's more interesting is a",
    "start": "2423000",
    "end": "2429200"
  },
  {
    "text": "alternative open source alternative called Codi and this is created by Source graph and it's all available in",
    "start": "2429200",
    "end": "2435319"
  },
  {
    "text": "GitHub so you can go and look and see what prompts they're using how they're agre um discovering the relevant code",
    "start": "2435319",
    "end": "2442200"
  },
  {
    "text": "Snippets and how they're combining that with a prompt and so if you're asking it to explain how a piece of code works",
    "start": "2442200",
    "end": "2448720"
  },
  {
    "text": "it's taking um predefining The Prompt saying please explain the following in",
    "start": "2448720",
    "end": "2453960"
  },
  {
    "text": "finding out the language based on the context of your code Cod base finding out the relevant files and passing that",
    "start": "2453960",
    "end": "2459200"
  },
  {
    "text": "along and then the output will be displayed within the visual studio um extension and that goes for simless",
    "start": "2459200",
    "end": "2465319"
  },
  {
    "text": "things like um code smells and like how you find Cod smells and so it's not the",
    "start": "2465319",
    "end": "2471680"
  },
  {
    "text": "co-pilot it's not um the extension doing all of the heavy lifting all the extension not all but the main job of",
    "start": "2471680",
    "end": "2478599"
  },
  {
    "text": "the extension is to find the relevant pieces of information so that it can build the most accurate prompt so the",
    "start": "2478599",
    "end": "2485119"
  },
  {
    "text": "language model has all the the information it needs in order to produce the best answer for the user and what",
    "start": "2485119",
    "end": "2491359"
  },
  {
    "text": "they're looking for and so this is like the foundations this is where we are today but this is",
    "start": "2491359",
    "end": "2497800"
  },
  {
    "text": "very rapid and it's evolving and so there's new capabilities upcoming some of which are prototypes and experiments",
    "start": "2497800",
    "end": "2504359"
  },
  {
    "text": "which may not stay for example functions within um open AI API and So within the",
    "start": "2504359",
    "end": "2510000"
  },
  {
    "text": "initial prompt you can give it a list of functions that are available within the system like API calls and and so you",
    "start": "2510000",
    "end": "2516599"
  },
  {
    "text": "could say if you won't need to calculate a number then in your prompt return Cal and the parameters when the prompt comes",
    "start": "2516599",
    "end": "2523400"
  },
  {
    "text": "back to the system it will pass the output it will call those functions and then return that information to the",
    "start": "2523400",
    "end": "2529960"
  },
  {
    "text": "system this is interesting but we can take it even a step further we can start building agents who will take the prompt",
    "start": "2529960",
    "end": "2537160"
  },
  {
    "text": "take the output from the language model feed it back in and keep asking and keep iterating in order to achieve and solve",
    "start": "2537160",
    "end": "2543480"
  },
  {
    "text": "very targeted problems so for example instead of of just asking it to write a single line of code having a system",
    "start": "2543480",
    "end": "2549599"
  },
  {
    "text": "which will say I need to build a web application great what language do you need it to be built in let's say",
    "start": "2549599",
    "end": "2554640"
  },
  {
    "text": "JavaScript so then filled out a structure and it need some features so then that will be another prompt and",
    "start": "2554640",
    "end": "2560000"
  },
  {
    "text": "that will add a feature and then that need to be improved and it will iterate multiple times over um The Prompt and",
    "start": "2560000",
    "end": "2567200"
  },
  {
    "text": "language model feeding into itself in order to achieve the goal and um achieve",
    "start": "2567200",
    "end": "2572920"
  },
  {
    "text": "the original objective which could be build an entire software platform which is great if you're open in AI because",
    "start": "2572920",
    "end": "2579119"
  },
  {
    "text": "every single system call is making many and it will all quickly add up but it is a potential future for how software",
    "start": "2579119",
    "end": "2585640"
  },
  {
    "text": "could be developed and this is available today within an open source platform um so you can start exploring and go and",
    "start": "2585640",
    "end": "2592520"
  },
  {
    "text": "having a look and then what we can also do is start adjusting the prompts um which is",
    "start": "2592520",
    "end": "2598880"
  },
  {
    "text": "basically what it's doing to adjust to the type of code which we want that system or that agent to develop so",
    "start": "2598880",
    "end": "2604440"
  },
  {
    "text": "obiously we want it to be Dev developed by a top tier developer could we wouldn't want it to be developed by Junior unless actually we do if it's for",
    "start": "2604440",
    "end": "2611440"
  },
  {
    "text": "training education purposes maybe we do want it to be a junior and so that we can improve show bad practices show",
    "start": "2611440",
    "end": "2618240"
  },
  {
    "text": "other systems in order to help develop we can tell it what's important like do we want it to provide tests and we",
    "start": "2618240",
    "end": "2624040"
  },
  {
    "text": "include that in the output and so we can start building systems based on very targeted uh resources and for",
    "start": "2624040",
    "end": "2630240"
  },
  {
    "text": "information that we need and there other systems like should we ask please like",
    "start": "2630240",
    "end": "2635880"
  },
  {
    "text": "how how did this affect the output like remember when chat dtp took multiple",
    "start": "2635880",
    "end": "2642119"
  },
  {
    "text": "attempts in order to solve the title um extraction problem it was very polite in",
    "start": "2642119",
    "end": "2648520"
  },
  {
    "text": "the response and if you imagine all of the data sets that I've been trained on has it included politeness in that and",
    "start": "2648520",
    "end": "2655200"
  },
  {
    "text": "does that help um achieve a better result or is this just some human aspect",
    "start": "2655200",
    "end": "2660680"
  },
  {
    "text": "where we like to be polite when we ask for questions and say thank you when it completed the job properly that is still",
    "start": "2660680",
    "end": "2666960"
  },
  {
    "text": "to be confirmed but this is a joy of Open Source when we have all of these open source language models we can find",
    "start": "2666960",
    "end": "2673559"
  },
  {
    "text": "out all of this information we can find out the information that it's been trained on and help in iterate and",
    "start": "2673559",
    "end": "2679160"
  },
  {
    "text": "improve it so there's a lot the main Pro uh main ones are from Facebook at the moment with Lama and with um that code iteration and",
    "start": "2679160",
    "end": "2687520"
  },
  {
    "text": "so these are now available to public we can now download and RN these anywhere",
    "start": "2687520",
    "end": "2692680"
  },
  {
    "text": "well on a powerful server or on our laptops and this will open up opportunities things like private",
    "start": "2692680",
    "end": "2699040"
  },
  {
    "text": "internal usages for Enterprises which may not want to be sharing classified",
    "start": "2699040",
    "end": "2704680"
  },
  {
    "text": "personalized uh company confidential information over the Internet with a third party if they want to keep our all",
    "start": "2704680",
    "end": "2710720"
  },
  {
    "text": "in house open source language model that they canoy within their private cloud is the way that we can achieve that and",
    "start": "2710720",
    "end": "2717920"
  },
  {
    "text": "this will go a step further that if it's in the cloud and it get powerful enough then we can get it running on our local",
    "start": "2717920",
    "end": "2725319"
  },
  {
    "text": "device the next time I'm in a plane and I want co-pilot to be telling me the",
    "start": "2725319",
    "end": "2730559"
  },
  {
    "text": "results it will actually be running directly on my device and so it'll give me faster quicker iteration feedbacks",
    "start": "2730559",
    "end": "2737480"
  },
  {
    "text": "but it will also not be leaking my source code over to a third party and over the internet and this is already available",
    "start": "2737480",
    "end": "2745119"
  },
  {
    "text": "um with open source and so my laptop will happily run um a lar language model because it's one of the new Macs and you",
    "start": "2745119",
    "end": "2752400"
  },
  {
    "text": "can even get it running on rasb Pi now admittedly uh it's pretty slow and painful but it's a step in the right",
    "start": "2752400",
    "end": "2758960"
  },
  {
    "text": "direction like it's already an indication about how we can take these very large ridiculously well-trained",
    "start": "2758960",
    "end": "2765720"
  },
  {
    "text": "language models and start optimizing them tweaking them to run on something as low powerered as a Raspberry Pi even",
    "start": "2765720",
    "end": "2773040"
  },
  {
    "text": "if at the moment the performance isn't quite there but it will be eventually",
    "start": "2773040",
    "end": "2778119"
  },
  {
    "text": "we're all walking around with iPhones and Android devices which have got GP uh GPU chips dedicated for AI built right",
    "start": "2778119",
    "end": "2785960"
  },
  {
    "text": "into them so they already have all of the capabilities the new um MacBook 2 um",
    "start": "2785960",
    "end": "2791640"
  },
  {
    "text": "M2 devices have huge amount of GPU resources available so now we can just start marrying up powerful open source",
    "start": "2791640",
    "end": "2799599"
  },
  {
    "text": "devices from the likes of Facebook who have got the GPU capabilities with powerful laptops and phones and devices",
    "start": "2799599",
    "end": "2807880"
  },
  {
    "text": "and then everything will be running locally private personalized to us and then we can run it all in the",
    "start": "2807880",
    "end": "2814760"
  },
  {
    "text": "browser because if it's on local if it's winning locally we have new capabilities of web GPU so everything all the power",
    "start": "2814760",
    "end": "2822200"
  },
  {
    "text": "of the GPU available directly through JavaScript directly in the browser and so just as part of our daily activities",
    "start": "2822200",
    "end": "2829280"
  },
  {
    "text": "with our web everything through the language model can be accessed uh by our web applications but running on the",
    "start": "2829280",
    "end": "2835880"
  },
  {
    "text": "device and this today isn't really in the future it's already available on GitHub you have to ruin the latest of",
    "start": "2835880",
    "end": "2842040"
  },
  {
    "text": "everything um like latest Chrome Canary versions but it works so the future which we could previously",
    "start": "2842040",
    "end": "2849160"
  },
  {
    "text": "be talking two 3 four years ago isn't the same when we're talking about language models we're talking weeks or",
    "start": "2849160",
    "end": "2855599"
  },
  {
    "text": "months away and so with that the future is definitely evolving rapidly and very",
    "start": "2855599",
    "end": "2863760"
  },
  {
    "text": "quickly but I'll let you finish thiz thank you we talked a lot about possibilities",
    "start": "2863760",
    "end": "2872760"
  },
  {
    "text": "and fluff and everything that then covered no I'm joking we talked about",
    "start": "2872760",
    "end": "2878880"
  },
  {
    "text": "how models are built how they are used and how you can make them more creative",
    "start": "2878880",
    "end": "2885319"
  },
  {
    "text": "I presented to you how we could do semantic search to tackle the",
    "start": "2885319",
    "end": "2890520"
  },
  {
    "text": "limitations of the prompt and how to extract the information and feed it to",
    "start": "2890520",
    "end": "2895720"
  },
  {
    "text": "the large language model so you can take the Full Potential from both information",
    "start": "2895720",
    "end": "2900760"
  },
  {
    "text": "Tri AKA search and large language models what is the future we had a small",
    "start": "2900760",
    "end": "2908920"
  },
  {
    "text": "discussion but we had the theory that everything we spoke about or not",
    "start": "2908920",
    "end": "2914359"
  },
  {
    "text": "everything but a lot just changed since this morning so we'll see what's going",
    "start": "2914359",
    "end": "2920280"
  },
  {
    "text": "to change it's very exciting thank you so much for joining us thank you very",
    "start": "2920280",
    "end": "2925930"
  },
  {
    "text": "[Applause]",
    "start": "2925930",
    "end": "2933219"
  },
  {
    "text": "much",
    "start": "2933400",
    "end": "2936400"
  }
]
[
  {
    "text": "morning everybody my name is Phil I work for domain and today just a disclaimer",
    "start": "9550",
    "end": "17350"
  },
  {
    "text": "is anybody here a distributed systems expert good because I'm I'm not a",
    "start": "17350",
    "end": "22510"
  },
  {
    "text": "distributed systems expert either I'm just a dev a lot of this talk is really",
    "start": "22510",
    "end": "27610"
  },
  {
    "text": "going to talk about all the things that we've done with a cadet and actor",
    "start": "27610",
    "end": "33760"
  },
  {
    "text": "systems in general and all the mistakes that we've made and some of the mistakes",
    "start": "33760",
    "end": "38770"
  },
  {
    "text": "that you could avoid by learning some of the lessons that we actually did so just a quick overview a couple years ago what",
    "start": "38770",
    "end": "47050"
  },
  {
    "text": "happened was in domain we had a big big problem and the problem was that like a",
    "start": "47050",
    "end": "56769"
  },
  {
    "text": "lot of online real estate websites even our competitors we needed something",
    "start": "56769",
    "end": "62109"
  },
  {
    "text": "called clickstream analytics is everybody here familiar with google analytics ok so some of you are for",
    "start": "62109",
    "end": "69190"
  },
  {
    "text": "those of you that are aren't clickstream analytics is this it's really the art of",
    "start": "69190",
    "end": "75810"
  },
  {
    "text": "understanding what your users do on your website so that you could collect this",
    "start": "75810",
    "end": "81340"
  },
  {
    "text": "data and then process it later and be able to create better products based on",
    "start": "81340",
    "end": "89230"
  },
  {
    "text": "what people actually do so instead of having a product team that would say well we think this is what people like",
    "start": "89230",
    "end": "95500"
  },
  {
    "text": "you actually use real data and you collect real data to build better",
    "start": "95500",
    "end": "101260"
  },
  {
    "text": "products but about two years ago in domain we had a serious problem and the",
    "start": "101260",
    "end": "106570"
  },
  {
    "text": "biggest problem that we had was that not only we were we collecting the wrong",
    "start": "106570",
    "end": "112960"
  },
  {
    "text": "data we were actually losing events as part of this clickstream process so when",
    "start": "112960",
    "end": "118660"
  },
  {
    "text": "I sat down and like any other dev with a new tool and I was playing around with a canet I said is there a better way to do",
    "start": "118660",
    "end": "125230"
  },
  {
    "text": "this and when we looked at this problem there's a few things that we ran into and the first thing is that the old",
    "start": "125230",
    "end": "133810"
  },
  {
    "text": "system was running on a sequel server database and it had quite a bit of",
    "start": "133810",
    "end": "140070"
  },
  {
    "text": "triggers that would fire every time we wrote an event if it would kick every time we get an",
    "start": "140070",
    "end": "145780"
  },
  {
    "text": "event what would happen is it would completely reject it if it violated any",
    "start": "145780",
    "end": "151090"
  },
  {
    "text": "of the referential can constraints which is horrible when you're trying to",
    "start": "151090",
    "end": "156280"
  },
  {
    "text": "collect everything secondly this this was running on sequel server reporting",
    "start": "156280",
    "end": "162820"
  },
  {
    "text": "services so that's fine back and say 2005 when the original system was put",
    "start": "162820",
    "end": "168610"
  },
  {
    "text": "together but this is 2017 it doesn't make sense to be running something like this when we were scaling up to millions",
    "start": "168610",
    "end": "176050"
  },
  {
    "text": "of users and we needed to collect this stuff and be able to analyze it as fast as it comes in so today I'm really going",
    "start": "176050",
    "end": "184930"
  },
  {
    "text": "to talk about how we put a system like this together and these are the things",
    "start": "184930",
    "end": "191620"
  },
  {
    "text": "that you would expect out of a modern-day real-time reactive system but",
    "start": "191620",
    "end": "197290"
  },
  {
    "text": "I'll go over the the points just to give you an idea of what we're gonna go over so the first thing is really around",
    "start": "197290",
    "end": "203200"
  },
  {
    "text": "reliability that means that when we collect data about all our users we",
    "start": "203200",
    "end": "209710"
  },
  {
    "text": "should have at least within a reasonable amount of margin the ability to say that",
    "start": "209710",
    "end": "215470"
  },
  {
    "text": "we won't lose anything of course it's not perfect but we want to come as close",
    "start": "215470",
    "end": "220540"
  },
  {
    "text": "to perfect as possible the second part is really traceability so when we have",
    "start": "220540",
    "end": "225760"
  },
  {
    "text": "events that come in and we want to do real-time aggregations based on what",
    "start": "225760",
    "end": "231190"
  },
  {
    "text": "streams in and somebody comes to us like say an agent says well how do you know that these numbers are correct we have",
    "start": "231190",
    "end": "238120"
  },
  {
    "text": "to be able to look into the events that we've collected and say here's event one",
    "start": "238120",
    "end": "243580"
  },
  {
    "text": "two and three this is why you have three click events and that's important",
    "start": "243580",
    "end": "249610"
  },
  {
    "text": "because when you're on when you're in a real estate bait a business and you're in the ad agency you have to be able to",
    "start": "249610",
    "end": "256780"
  },
  {
    "text": "sell these ads and say yes we get this much traffic but the business is",
    "start": "256780",
    "end": "264010"
  },
  {
    "text": "effectively useless if you can't provide traceable and reliable numbers the third",
    "start": "264010",
    "end": "270130"
  },
  {
    "text": "bit which is fairly self-explanatory is it needs to come in as fast as",
    "start": "270130",
    "end": "276880"
  },
  {
    "text": "it needs to compute as fast as it comes in given that where most of us are running",
    "start": "276880",
    "end": "283390"
  },
  {
    "text": "within the cloud it's very easy to spin up another box and add that capacity but",
    "start": "283390",
    "end": "289570"
  },
  {
    "text": "as you'll see during the course of this talk it cap really messes things up and I'll talk about how we got around that",
    "start": "289570",
    "end": "295900"
  },
  {
    "text": "the other bit is accuracy so obviously we need to be able to add all those",
    "start": "295900",
    "end": "301690"
  },
  {
    "text": "three things together and we need to be able to recompute in case of any errors",
    "start": "301690",
    "end": "309240"
  },
  {
    "text": "but as I mentioned before when it's okay",
    "start": "309960",
    "end": "315280"
  },
  {
    "text": "running on a single box in fact you have no consistency problems running on a",
    "start": "315280",
    "end": "321100"
  },
  {
    "text": "single box the problem is that no matter how much you how many instances you get",
    "start": "321100",
    "end": "326500"
  },
  {
    "text": "in AWS where you get a super box it's not you still run into cap you still run",
    "start": "326500",
    "end": "332140"
  },
  {
    "text": "into the problem of what if that machine goes away and then you're screwed so we",
    "start": "332140",
    "end": "338830"
  },
  {
    "text": "really had to think about this I mean two years ago domain moved on to AWS we",
    "start": "338830",
    "end": "345220"
  },
  {
    "text": "had all of a sudden this capacity to add more and more machines and this is more",
    "start": "345220",
    "end": "351550"
  },
  {
    "text": "of a plug for some of the other talks we've done in domain double week that we what we did was we put together",
    "start": "351550",
    "end": "357670"
  },
  {
    "text": "something called the robot army which was a combination of octopus deploy and",
    "start": "357670",
    "end": "363360"
  },
  {
    "text": "AWS and it was this amazing tool that would allow us to provision machines at",
    "start": "363360",
    "end": "370240"
  },
  {
    "text": "will with a basically a push of a button so there I was 2015 saying that hey this",
    "start": "370240",
    "end": "378070"
  },
  {
    "text": "looks pretty cool I started up playing around with a canet and I wanted to run this on multiple",
    "start": "378070",
    "end": "384610"
  },
  {
    "text": "boxes and it seemed like a good idea I mean you've got a few different actor",
    "start": "384610",
    "end": "391510"
  },
  {
    "text": "systems that you play around with of course there's a cadet there's Orleans and if you want to go with the JVM that's fine too and there's",
    "start": "391510",
    "end": "398800"
  },
  {
    "text": "also proto actor if you want to go with something a bit more lightweight but at",
    "start": "398800",
    "end": "406120"
  },
  {
    "text": "the time it seemed for me I'm a very curious person so I around with Akkad net and I said well",
    "start": "406120",
    "end": "414819"
  },
  {
    "text": "hey we've got this job that takes several hours to run what if I were to",
    "start": "414819",
    "end": "420669"
  },
  {
    "text": "take every single that job and divide it into 86,400 smaller batch jobs or made",
    "start": "420669",
    "end": "426669"
  },
  {
    "text": "it one job per second so the idea is instead of just letting it sit there",
    "start": "426669",
    "end": "433060"
  },
  {
    "text": "like any other batch job you would run in any other shop we could process it as",
    "start": "433060",
    "end": "438550"
  },
  {
    "text": "fast as it comes in and in theory that's great it's it's easy to throw more actor",
    "start": "438550",
    "end": "443889"
  },
  {
    "text": "systems into the mix and hope that everything is fine but the biggest",
    "start": "443889",
    "end": "448900"
  },
  {
    "text": "stumbling block that we had was managing state when you have events streaming in",
    "start": "448900",
    "end": "456460"
  },
  {
    "text": "at once how do you guarantee that your computing the right numbers how do you guarantee that you don't lose anything",
    "start": "456460",
    "end": "463080"
  },
  {
    "text": "that was the hardest thing for us because we tried so many different approaches we even tried using just",
    "start": "463080",
    "end": "469210"
  },
  {
    "text": "Postgres and we thought hey you know maybe it's just because we had bad schema and and it turns out that when we",
    "start": "469210",
    "end": "476259"
  },
  {
    "text": "did it in Postgres it would take an entire week to process something that we were able to do with just the actor",
    "start": "476259",
    "end": "481930"
  },
  {
    "text": "systems that we had but the trick here is we need to be able to manage state in such a way that you don't lose that",
    "start": "481930",
    "end": "489340"
  },
  {
    "text": "consistency or at least in our case the consistency what the consistency window",
    "start": "489340",
    "end": "494529"
  },
  {
    "text": "was in one day if we sped it up for a little bit faster than just one day the",
    "start": "494529",
    "end": "500349"
  },
  {
    "text": "agents would have loved us and and that's what happened but I'd like to say",
    "start": "500349",
    "end": "508419"
  },
  {
    "text": "that everything went perfect but a lot of the things I'm gonna be talking about like the theory are things that we",
    "start": "508419",
    "end": "515140"
  },
  {
    "text": "didn't necessarily know when we did it these were things that we learned only",
    "start": "515140",
    "end": "520810"
  },
  {
    "text": "as an afterthought I was quite surprised that a lot of the stuff that we did that",
    "start": "520810",
    "end": "526810"
  },
  {
    "text": "we learned was was stuff that was already out there in different talks and whatnot but I'm gonna go over some of",
    "start": "526810",
    "end": "532570"
  },
  {
    "text": "the things that you might already know just for a refresher so first thing is with strong eventual consistency is this",
    "start": "532570",
    "end": "538779"
  },
  {
    "text": "idea that as long as you have all the pieces and as long as you had an algorithm to",
    "start": "538779",
    "end": "545150"
  },
  {
    "text": "be able to take all those pieces and put them together you can reach consistency",
    "start": "545150",
    "end": "552320"
  },
  {
    "text": "and the order doesn't matter the other bit about this one is there's also a",
    "start": "552320",
    "end": "557810"
  },
  {
    "text": "weak eventual consistency where the order does matter but you do still have that same window to reach consistency",
    "start": "557810",
    "end": "565580"
  },
  {
    "text": "like like what we did so for example we'd have events coming in every second",
    "start": "565580",
    "end": "571700"
  },
  {
    "text": "but we had till the end of the day to actually process it so if we're talking about strong eventual consistency as",
    "start": "571700",
    "end": "579500"
  },
  {
    "text": "long as we had all the pieces and we were able to process it we did it in",
    "start": "579500",
    "end": "584960"
  },
  {
    "text": "such a way that it didn't really matter what the order was as long as we came up with the right totals another way to",
    "start": "584960",
    "end": "591470"
  },
  {
    "text": "explain this is what I like to call the IKEA analogy so if you've ever assembled furniture from Ikea the way I always",
    "start": "591470",
    "end": "601640"
  },
  {
    "text": "like to explain is how are you able to walk into ikea buy the same per piece of",
    "start": "601640",
    "end": "606860"
  },
  {
    "text": "furniture as somebody else without talking to that other person as long as you both have the same set of",
    "start": "606860",
    "end": "612590"
  },
  {
    "text": "instructions for the most part you should be at the end of the day when you're done assembling it you should",
    "start": "612590",
    "end": "618500"
  },
  {
    "text": "come to roughly the same piece of furniture depending on how good you are with assembling things and in that sense",
    "start": "618500",
    "end": "626150"
  },
  {
    "text": "it's pretty close to strong eventual consistency now somebody under previous talks told me that yeah IKEA pieces are",
    "start": "626150",
    "end": "633230"
  },
  {
    "text": "not all the same and that's true but in in this case when you're working with an",
    "start": "633230",
    "end": "638960"
  },
  {
    "text": "enterprise system there's a certain way you can reduce all your events down to",
    "start": "638960",
    "end": "644360"
  },
  {
    "text": "something that where the order doesn't matter and I'll get to that so in",
    "start": "644360",
    "end": "650930"
  },
  {
    "text": "hindsight what we were actually doing is something called conflict-free replicated data types so the title of",
    "start": "650930",
    "end": "658340"
  },
  {
    "text": "this talk is effective eventual consistency and I know I some Pierce will say you can't really cheat cat but",
    "start": "658340",
    "end": "666680"
  },
  {
    "text": "you can sidestep it and it seems complex but it's actually not and part of the",
    "start": "666680",
    "end": "672170"
  },
  {
    "text": "reason why we needed to have a strong eventual consistency we knew that we as a business we",
    "start": "672170",
    "end": "679800"
  },
  {
    "text": "couldn't afford to lose any data but data loss is something that will happen",
    "start": "679800",
    "end": "685079"
  },
  {
    "text": "and you have to take the steps in order to prevent that from happening and this is one of those things that we learned",
    "start": "685079",
    "end": "691649"
  },
  {
    "text": "in hindsight and it did help us recover some from some failures that happened",
    "start": "691649",
    "end": "698459"
  },
  {
    "text": "last year so does everybody help remember the AWS outage in Sydney yeah we were hitting with that too and this",
    "start": "698459",
    "end": "704459"
  },
  {
    "text": "this is the one that saved us so just a refresher cap theorem consistency",
    "start": "704459",
    "end": "711269"
  },
  {
    "text": "availability partitioning pick only two at once consistency meaning that everybody has",
    "start": "711269",
    "end": "717690"
  },
  {
    "text": "the same view of the data at the same time partitioning means that if you have multiple nodes in a system you could",
    "start": "717690",
    "end": "723360"
  },
  {
    "text": "survive multiple node outages without losing anything availability is just",
    "start": "723360",
    "end": "731120"
  },
  {
    "text": "knowing whether or not a operation is successful depending on its knowing",
    "start": "731120",
    "end": "738720"
  },
  {
    "text": "whether or not it was successful right away actually the problem with this one is as you can see here there's different",
    "start": "738720",
    "end": "743910"
  },
  {
    "text": "types of storage providers that are have their strengths with this one in our",
    "start": "743910",
    "end": "750269"
  },
  {
    "text": "case we could sacrifice consistency because we didn't need things computed",
    "start": "750269",
    "end": "756300"
  },
  {
    "text": "right away at least we we can wait until the end of the day to have everything consistent and that gave us a bit more",
    "start": "756300",
    "end": "763829"
  },
  {
    "text": "flexibility so for C R DTS it seems a",
    "start": "763829",
    "end": "771990"
  },
  {
    "text": "bit weird how do we sidestep the cap theorem in this case so as I mentioned",
    "start": "771990",
    "end": "777930"
  },
  {
    "text": "you could only pick two so if you look at this you've got partitioning where we picked partitioning and availability but",
    "start": "777930",
    "end": "783660"
  },
  {
    "text": "how do we get consistency so the trick here is that number one even though the",
    "start": "783660",
    "end": "790529"
  },
  {
    "text": "data can only be to pick two parts of the cap theorem our merge algorithm is",
    "start": "790529",
    "end": "798240"
  },
  {
    "text": "100% consistent that means all the nodes have exactly the same order algorithm",
    "start": "798240",
    "end": "804529"
  },
  {
    "text": "the same this at the second the second part of this is that C or D T's",
    "start": "804529",
    "end": "809870"
  },
  {
    "text": "ensure partition tolerance because we make copies of every single thing that comes into the network so every single",
    "start": "809870",
    "end": "817040"
  },
  {
    "text": "node that we have has copies of all the data that streams in so if you take out",
    "start": "817040",
    "end": "822290"
  },
  {
    "text": "a node it doesn't really affect the rest of the cluster for example at the same",
    "start": "822290",
    "end": "832400"
  },
  {
    "text": "time we do get that availability because since you have the copy of the data and you were to run operations over the over",
    "start": "832400",
    "end": "839240"
  },
  {
    "text": "what you have you could tell immediately whether or not you're successful depending on what you decide to do for C",
    "start": "839240",
    "end": "847130"
  },
  {
    "text": "or D T's in general there's three operations for us we only implemented",
    "start": "847130",
    "end": "853460"
  },
  {
    "text": "two of them so we implemented only the query and the merge operation now you're probably wondering what why did we skip",
    "start": "853460",
    "end": "860000"
  },
  {
    "text": "the update and the simple reason is that we chose to be immutable so we wanted to",
    "start": "860000",
    "end": "865940"
  },
  {
    "text": "event source this so that we never have to worry about tracking deletes so if you do a bit of research with CRD T's",
    "start": "865940",
    "end": "872720"
  },
  {
    "text": "there's different types of Co Rd T's that say you can track what's been deleted these typically these c rd T's",
    "start": "872720",
    "end": "880550"
  },
  {
    "text": "are the ones that you'd see in Google Docs so if you ever did more than one document at once and somebody else was",
    "start": "880550",
    "end": "887960"
  },
  {
    "text": "editing it at the same time what it would do is merge the or deletes with their deletes and come up with a",
    "start": "887960",
    "end": "894050"
  },
  {
    "text": "consistent state right away in our case we didn't need to do that and it simplifies the CR DTS so that we had",
    "start": "894050",
    "end": "901640"
  },
  {
    "text": "just assumed that the data set keeps growing and growing growing growing and within a reasonable window we do delete",
    "start": "901640",
    "end": "908540"
  },
  {
    "text": "CR d DS for the sake of just saving storage but effectively for the sake of",
    "start": "908540",
    "end": "913790"
  },
  {
    "text": "the business it just grows on and on on forever so as I mentioned the first",
    "start": "913790",
    "end": "920690"
  },
  {
    "text": "operation is querying this is getting the state this is by the way this is not",
    "start": "920690",
    "end": "926060"
  },
  {
    "text": "a / - be a service it's more of a pattern a lot of the stuff that we did",
    "start": "926060",
    "end": "932030"
  },
  {
    "text": "with with what we put together was",
    "start": "932030",
    "end": "937340"
  },
  {
    "text": "around making sure that we implement these two operations so",
    "start": "937340",
    "end": "943250"
  },
  {
    "text": "there's query and then the next one is the merge operation so the merge operation seems a bit scary because it",
    "start": "943250",
    "end": "949160"
  },
  {
    "text": "seems like magic because what how do I actually do something that maintains",
    "start": "949160",
    "end": "955160"
  },
  {
    "text": "consistency and there's three things that you basically need to be able to do",
    "start": "955160",
    "end": "961130"
  },
  {
    "text": "with the merge operation so commutative meaning order doesn't matter associative meaning that the grouping",
    "start": "961130",
    "end": "968390"
  },
  {
    "text": "doesn't matter either so you could order it whatever you want and idempotent which is probably the most important one",
    "start": "968390",
    "end": "973640"
  },
  {
    "text": "you could run over it in multiple passes and it wouldn't matter and the best part",
    "start": "973640",
    "end": "979940"
  },
  {
    "text": "about that is that this merge operation even though it seems magical you you run it over a set of data that has the",
    "start": "979940",
    "end": "985970"
  },
  {
    "text": "duplicates with the stuff that is duplicated on multiple nodes you get",
    "start": "985970",
    "end": "990980"
  },
  {
    "text": "consistency every single time so here's more of a question for the audience so",
    "start": "990980",
    "end": "996470"
  },
  {
    "text": "I've got let's say I've got two nodes and for the sake of simplicity let's say I've got two sets each set has a set of",
    "start": "996470",
    "end": "1004240"
  },
  {
    "text": "intz which operator you think would",
    "start": "1004240",
    "end": "1009670"
  },
  {
    "text": "ensure this set of requirements so if I go here which one's communitive which",
    "start": "1009670",
    "end": "1019330"
  },
  {
    "text": "ones associative and which ones idempotent it seems really really",
    "start": "1019330",
    "end": "1026350"
  },
  {
    "text": "complex but it isn't in fact what we",
    "start": "1026350",
    "end": "1032380"
  },
  {
    "text": "found is that is everybody you're familiar with set theory so it turns out",
    "start": "1032380",
    "end": "1037900"
  },
  {
    "text": "Union is all you need so if you were to run the Union on every single one of",
    "start": "1037900",
    "end": "1043839"
  },
  {
    "text": "these items and do a union between set a and set a on node one node two and set B and so on you get something that looks",
    "start": "1043839",
    "end": "1052630"
  },
  {
    "text": "like this and just a disclaimer this in",
    "start": "1052630",
    "end": "1059560"
  },
  {
    "text": "no way is obviously not production code but conceptually it's all you have to do",
    "start": "1059560",
    "end": "1065200"
  },
  {
    "text": "to maintain that consistency so I've got two sets with what you have there and",
    "start": "1065200",
    "end": "1072570"
  },
  {
    "text": "it's I take two hash sets and I Union the items together I mean that's it there's",
    "start": "1072570",
    "end": "1080920"
  },
  {
    "text": "no magic here because you're taking all the duplicates on one side and the duplicates on the other side and merging",
    "start": "1080920",
    "end": "1086920"
  },
  {
    "text": "them together in a single set now I understand that as developers we work with very very complex business domains",
    "start": "1086920",
    "end": "1097060"
  },
  {
    "text": "and you never if you're lucky unless you're a mathematician you're never gonna really be working with Justin's",
    "start": "1097060",
    "end": "1103060"
  },
  {
    "text": "but it turns out that this principle I mean it also applies to hash codes and",
    "start": "1103060",
    "end": "1110290"
  },
  {
    "text": "we'll get to that so the other thing I mentioned before is since we don't delete anything we don't have to do any",
    "start": "1110290",
    "end": "1117520"
  },
  {
    "text": "kind of tracking as to what's been deleted so in terms of working with sets",
    "start": "1117520",
    "end": "1123250"
  },
  {
    "text": "we only have one set to work with so we start collecting events and then across",
    "start": "1123250",
    "end": "1130000"
  },
  {
    "text": "multiple nodes and then we just do a read across those nodes and then merge them in all at the same time using the",
    "start": "1130000",
    "end": "1136180"
  },
  {
    "text": "same Union operator so now that we",
    "start": "1136180",
    "end": "1141760"
  },
  {
    "text": "talked about the theory you're probably wondering how does how do we actually store this stuff because when I first",
    "start": "1141760",
    "end": "1150760"
  },
  {
    "text": "started I thought we could have done this in sequel server or something like Postgres what how did we actually go",
    "start": "1150760",
    "end": "1159010"
  },
  {
    "text": "about doing this so one of the things that you'll notice here is that this looks exactly the same as the other",
    "start": "1159010",
    "end": "1164440"
  },
  {
    "text": "slides the only difference is that I just pasted two different data sources now I recommend using two different",
    "start": "1164440",
    "end": "1171640"
  },
  {
    "text": "types of data sources because you don't not only do you want to not store your eggs in one basket but you don't want to",
    "start": "1171640",
    "end": "1177760"
  },
  {
    "text": "store your eggs in the same type of basket so what we did was as events were",
    "start": "1177760",
    "end": "1183700"
  },
  {
    "text": "streaming in we would store one copy in elasticsearch and another copy in s3 the",
    "start": "1183700",
    "end": "1189940"
  },
  {
    "text": "reason why we wanted to store our events into s3 was we wanted to do long-term",
    "start": "1189940",
    "end": "1196000"
  },
  {
    "text": "storage but at the same time we also wanted to store things into elasticsearch because if somebody had a",
    "start": "1196000",
    "end": "1201730"
  },
  {
    "text": "question about all the events that came in during that day we could quickly search it with elastic search because",
    "start": "1201730",
    "end": "1207670"
  },
  {
    "text": "that's what it's good at the other question I mentioned before is",
    "start": "1207670",
    "end": "1214140"
  },
  {
    "text": "you know what it how do you deal with the situation where it might be more than just an int or just a number as it",
    "start": "1214140",
    "end": "1222600"
  },
  {
    "text": "turns out it's not that different so here's a sample clickstream event and",
    "start": "1222600",
    "end": "1228620"
  },
  {
    "text": "what we do is we take all the properties that you see here and put together one",
    "start": "1228620",
    "end": "1234210"
  },
  {
    "text": "string that is concatenated and based on that content of that string we generate",
    "start": "1234210",
    "end": "1240510"
  },
  {
    "text": "a unique hash code with a hashing algorithm you could use sha-1 or anything that is relatively unique so",
    "start": "1240510",
    "end": "1247710"
  },
  {
    "text": "for us practically anything above 128-bit key space is good enough so we",
    "start": "1247710",
    "end": "1254760"
  },
  {
    "text": "would take all the properties Union them into Union but we merged them into one",
    "start": "1254760",
    "end": "1260340"
  },
  {
    "text": "string and that hash code would be the equivalent of your int because when",
    "start": "1260340",
    "end": "1265950"
  },
  {
    "text": "you're dealing with set theory it doesn't matter whether it's an int or not provided that you could guarantee that it's unique in this case it's going",
    "start": "1265950",
    "end": "1273450"
  },
  {
    "text": "to be a unique string within a space of 128-bit now if we were to pull back a",
    "start": "1273450",
    "end": "1281280"
  },
  {
    "text": "little bit further things get a bit more complicated when you're when you start",
    "start": "1281280",
    "end": "1287309"
  },
  {
    "text": "working with more than one actor system our clickstream pipeline looks like this so on one side we've got one clickstream",
    "start": "1287309",
    "end": "1295380"
  },
  {
    "text": "event flowing into our web servers here the web servers would make copies of the",
    "start": "1295380",
    "end": "1302190"
  },
  {
    "text": "events and send them off to a kadam net now what's not on the slide is that all",
    "start": "1302190",
    "end": "1308039"
  },
  {
    "text": "of our actor systems are talking to each other not not directly and not directly but through sqs everything is done",
    "start": "1308039",
    "end": "1316260"
  },
  {
    "text": "either through sqs or just standard HTTP now if you look at the a canet docks",
    "start": "1316260",
    "end": "1321900"
  },
  {
    "text": "you'll see that they focus a lot on clustering and remoting but in practice",
    "start": "1321900",
    "end": "1327750"
  },
  {
    "text": "that's very hard to do within AWS and you're probably wondering why well when",
    "start": "1327750",
    "end": "1333299"
  },
  {
    "text": "we started doing it I was quite excited to say hey I want to do clustering because this seems pretty cool to have all these systems talking to each other",
    "start": "1333299",
    "end": "1340049"
  },
  {
    "text": "but in practice you the only way to fix it when things go wrong it's the rdp in and if you know",
    "start": "1340049",
    "end": "1347490"
  },
  {
    "text": "how hard it is to RDP in into a production box or an environment where",
    "start": "1347490",
    "end": "1353760"
  },
  {
    "text": "production boxes go up and down we need something a bit more robust we need to",
    "start": "1353760",
    "end": "1359220"
  },
  {
    "text": "be able to send our actor systems out to remote machines and not have to worry about whether things fail or not",
    "start": "1359220",
    "end": "1365970"
  },
  {
    "text": "so in this flow of information that you see here we've got clicks extreme events",
    "start": "1365970",
    "end": "1373169"
  },
  {
    "text": "flowing all the way to s3 and elastic but you're probably wondering well",
    "start": "1373169",
    "end": "1378799"
  },
  {
    "text": "that's great I'm sending it in two different directions but how do you merge what's going on",
    "start": "1378799",
    "end": "1384620"
  },
  {
    "text": "so that we get consistency between s3 and elasticsearch so what we ended up",
    "start": "1384620",
    "end": "1390450"
  },
  {
    "text": "doing is we had another actor system that would watch all the events that would come in on both sides we keep an",
    "start": "1390450",
    "end": "1397080"
  },
  {
    "text": "inventory of all the hash codes that would come in and we swap any events",
    "start": "1397080",
    "end": "1402150"
  },
  {
    "text": "that are missing from one side to the other and in practice this works pretty",
    "start": "1402150",
    "end": "1408210"
  },
  {
    "text": "well because since we have an eventually consistent system we can wait until the end of the day fill in the blanks and",
    "start": "1408210",
    "end": "1415140"
  },
  {
    "text": "then recompute and then we hit consistency most of the complexity in",
    "start": "1415140",
    "end": "1423360"
  },
  {
    "text": "fact has that we've run into has been around this type of communication because if we were to use any kind of",
    "start": "1423360",
    "end": "1430290"
  },
  {
    "text": "clustering if any like more than 60% of the nodes were to fall out we would have",
    "start": "1430290",
    "end": "1436890"
  },
  {
    "text": "a system that is completely unstable in our case we found a way to scale up by",
    "start": "1436890",
    "end": "1443340"
  },
  {
    "text": "having actor systems talk to queues rather than talking directly to each other so we could add 10 more machines",
    "start": "1443340",
    "end": "1449490"
  },
  {
    "text": "and take them out without actually causing any outages now is everybody",
    "start": "1449490",
    "end": "1456210"
  },
  {
    "text": "here worked with echo or any actor system to some extent so there's a few of you here but I'll explain to you what",
    "start": "1456210",
    "end": "1462750"
  },
  {
    "text": "actor systems actually are so with an actor system you could think of it as a",
    "start": "1462750",
    "end": "1468390"
  },
  {
    "text": "lightweight thread I would even say an actor system is almost a degenerate",
    "start": "1468390",
    "end": "1474210"
  },
  {
    "text": "operating system because an actor is almost like a class and you can have thousands of them",
    "start": "1474210",
    "end": "1480389"
  },
  {
    "text": "running in memory at once and they have this concept of a mailbox so actors",
    "start": "1480389",
    "end": "1486009"
  },
  {
    "text": "could talk to each other and send messages to each other what happens is",
    "start": "1486009",
    "end": "1491679"
  },
  {
    "text": "that there's a dispatcher that would just do of being a massive for loop and",
    "start": "1491679",
    "end": "1497159"
  },
  {
    "text": "switch context between every single one of the actors the other thing to remember is that when these actors send",
    "start": "1497159",
    "end": "1503950"
  },
  {
    "text": "messages to each other they're all immutable so the power and actor systems",
    "start": "1503950",
    "end": "1509320"
  },
  {
    "text": "is the ability to switch between these actors very quickly without having to worry about consistency in fact they're",
    "start": "1509320",
    "end": "1517059"
  },
  {
    "text": "so thread safe that you don't even have to put locks inside of a single actor as",
    "start": "1517059",
    "end": "1522279"
  },
  {
    "text": "long as it's not some sort of static method that you share with other instances you could pretty much assume",
    "start": "1522279",
    "end": "1527979"
  },
  {
    "text": "that everything that runs inside of an actor is has no problems with threads at all if you look at the code it's",
    "start": "1527979",
    "end": "1535719"
  },
  {
    "text": "actually quite simple as well so an a cadet we've got this is your simple",
    "start": "1535719",
    "end": "1541509"
  },
  {
    "text": "hello world actor I've got the greeting actor you here's the constructor and in",
    "start": "1541509",
    "end": "1546700"
  },
  {
    "text": "a canet it has a strongly typed received message which is the equivalent of an if statement in a coup nets that says if",
    "start": "1546700",
    "end": "1553839"
  },
  {
    "text": "you receive a message of this type do something with it the message itself is fairly",
    "start": "1553839",
    "end": "1562269"
  },
  {
    "text": "straightforward there's nothing magical here it's just completely immutable and the reason why you want to make it",
    "start": "1562269",
    "end": "1568299"
  },
  {
    "text": "completely immutable is it's easy you don't have to worry about threading or",
    "start": "1568299",
    "end": "1573969"
  },
  {
    "text": "whatnot and it also makes it easy for a katana to serialize it if you decide to use remoting or clustering now putting",
    "start": "1573969",
    "end": "1581889"
  },
  {
    "text": "together act the actor system itself is equally just as simple there's a bit more configuration in a canet but in the",
    "start": "1581889",
    "end": "1588849"
  },
  {
    "text": "simplest case the actor system is created in one call there's a bit of",
    "start": "1588849",
    "end": "1594159"
  },
  {
    "text": "weird syntax here you can see here we're creating the greet actor and it takes a",
    "start": "1594159",
    "end": "1599649"
  },
  {
    "text": "while to get used to but there's a few options there the more advanced options where you can create multiple actors and",
    "start": "1599649",
    "end": "1605379"
  },
  {
    "text": "have it scale up automatically but in in this case this is this is the simplest possible thing you could do to",
    "start": "1605379",
    "end": "1610779"
  },
  {
    "text": "create one actor the most important method that you see here is going to be",
    "start": "1610779",
    "end": "1616179"
  },
  {
    "text": "the tail method every single app actor has this concept where you could send it a message you can call tell and it'll",
    "start": "1616179",
    "end": "1624370"
  },
  {
    "text": "pass it that message and it's basically this large switch statement that you saw up here and eventually when I tell it",
    "start": "1624370",
    "end": "1632169"
  },
  {
    "text": "with a greeting it'll just get to this point and say if this is this type is a greeting type then call this method now",
    "start": "1632169",
    "end": "1640020"
  },
  {
    "text": "the other thing you might be asking is this running on a separate thread I don't know I don't care it could be",
    "start": "1640020",
    "end": "1645789"
  },
  {
    "text": "running on the same thread but for the most part the actor system in a cadet",
    "start": "1645789",
    "end": "1652539"
  },
  {
    "text": "abstracts away this idea of trying to do any kind of synchronization now if you",
    "start": "1652539",
    "end": "1660309"
  },
  {
    "text": "looked at the bigger picture here of course we're dealing with more than one actor system so if you look at the a",
    "start": "1660309",
    "end": "1666490"
  },
  {
    "text": "cadet docks they talk about really simple cases like the one I showed you but in practice things get a bit messy",
    "start": "1666490",
    "end": "1672909"
  },
  {
    "text": "when you have systems that cross multiple auto-scaling groups and one of",
    "start": "1672909",
    "end": "1680020"
  },
  {
    "text": "the things that we learned is that when you combine a cadet and SQS you have",
    "start": "1680020",
    "end": "1685120"
  },
  {
    "text": "this concept of almost like a distributed swarm because the what we",
    "start": "1685120",
    "end": "1691419"
  },
  {
    "text": "did with sqs is that we have almost like a blind dispatch I could drop a job",
    "start": "1691419",
    "end": "1698830"
  },
  {
    "text": "request into an sqs queue and as long as I had a cluster of say 10 nodes that",
    "start": "1698830",
    "end": "1705190"
  },
  {
    "text": "would continually pull from that queue they would just pull it right off of that queue and keep processing",
    "start": "1705190",
    "end": "1711390"
  },
  {
    "text": "that sounds great in practice but there were even cases where we were almost took down AWS at least the Sydney region",
    "start": "1711390",
    "end": "1719169"
  },
  {
    "text": "because we didn't throttle it you you definitely don't want to be in this kind of situation where you get a nice phone",
    "start": "1719169",
    "end": "1726039"
  },
  {
    "text": "call from AWS saying please don't do that so in hindsight one of the cooler",
    "start": "1726039",
    "end": "1732669"
  },
  {
    "text": "things that we actually did was we introduced this concept of self throttling actors so if you look at this",
    "start": "1732669",
    "end": "1739059"
  },
  {
    "text": "this is actually a live message from lack on for a domain slack and there's",
    "start": "1739059",
    "end": "1746060"
  },
  {
    "text": "three messages here the interesting bit is that we actually have actors that",
    "start": "1746060",
    "end": "1754130"
  },
  {
    "text": "scale themselves back or make the what they do is they make themselves go",
    "start": "1754130",
    "end": "1759710"
  },
  {
    "text": "faster slower depending on how much memory they use so in the first line you",
    "start": "1759710",
    "end": "1765140"
  },
  {
    "text": "could see there that we do have thresholds so the low threshold is 1.5 gigs other one is 2.5 and high is 5.1",
    "start": "1765140",
    "end": "1773270"
  },
  {
    "text": "and the idea here is that we have these actor systems that are completely",
    "start": "1773270",
    "end": "1778580"
  },
  {
    "text": "disconnected from each other but they scale up and they scaled down depending on how much memory is actually being",
    "start": "1778580",
    "end": "1784370"
  },
  {
    "text": "used on the box so we could have 10 actor systems that are connected to an",
    "start": "1784370",
    "end": "1789620"
  },
  {
    "text": "sqs queue and as long as they don't all throw out of memory exceptions it's it's",
    "start": "1789620",
    "end": "1795890"
  },
  {
    "text": "almost like a swarm that regulates itself the interesting part about this",
    "start": "1795890",
    "end": "1802010"
  },
  {
    "text": "is that if you wanted to do this at home it's actually quite simple I could walk",
    "start": "1802010",
    "end": "1807320"
  },
  {
    "text": "you through the code here and you could see that if I could get my mouse back",
    "start": "1807320",
    "end": "1812360"
  },
  {
    "text": "here we go it's actually quite simple so don't mind this one I've got constant expressions",
    "start": "1812360",
    "end": "1819020"
  },
  {
    "text": "that are just convert your byte values into gigabytes and megabytes and so on",
    "start": "1819020",
    "end": "1825350"
  },
  {
    "text": "that's just for syntactic sugar the important thing at least conceptually here is that and let me zoom in the",
    "start": "1825350",
    "end": "1833540"
  },
  {
    "text": "important thing here is that a code on net has this concept of a scheduler where you could send the same message",
    "start": "1833540",
    "end": "1839150"
  },
  {
    "text": "over a period of time and you could send it over and over and over again in this",
    "start": "1839150",
    "end": "1844550"
  },
  {
    "text": "case what I'm doing is I have this empty class here called check memory usage that I send I also have a message here",
    "start": "1844550",
    "end": "1852200"
  },
  {
    "text": "for the memory usage metric so I have the Val so it's quite simple I could",
    "start": "1852200",
    "end": "1858800"
  },
  {
    "text": "abstract this way into an eye metric interface if I want to but the idea here is I just want to be able to record the",
    "start": "1858800",
    "end": "1865370"
  },
  {
    "text": "number of bytes this actor system is actually using on a given system at the same time I want to keep track of the",
    "start": "1865370",
    "end": "1871280"
  },
  {
    "text": "date sample so if I if I start collecting these men shrieks I want to drop off a certain set",
    "start": "1871280",
    "end": "1876620"
  },
  {
    "text": "of events that have gone beyond beyond a particular time window so here's how the",
    "start": "1876620",
    "end": "1882200"
  },
  {
    "text": "message falling actor actually looks so it's quite simple in the constructor I've got the timespan in this case it's",
    "start": "1882200",
    "end": "1888200"
  },
  {
    "text": "defaults to one second when it receives that check memory usage event it makes a",
    "start": "1888200",
    "end": "1895850"
  },
  {
    "text": "call out to this method that you can see here which is just a process call at the",
    "start": "1895850",
    "end": "1903500"
  },
  {
    "text": "same time I'm pushing it to the event stream so if you're not familiar with the event stream Anaka",
    "start": "1903500",
    "end": "1908780"
  },
  {
    "text": "is basically a bus that exists on a cat on an akka dotnet actor system it",
    "start": "1908780",
    "end": "1915980"
  },
  {
    "text": "doesn't it's in some cases it is distributed but let's assume in this case that it's only for the machine",
    "start": "1915980",
    "end": "1921230"
  },
  {
    "text": "itself so you don't have to worry about subscribers and publishers and whatnot so the idea here is that on the",
    "start": "1921230",
    "end": "1928340"
  },
  {
    "text": "pre-start method which is called before the actor system actually starts it'll tell itself a message to check the",
    "start": "1928340",
    "end": "1935120"
  },
  {
    "text": "memory and it'll keep sending out these messages onto the bus I also have an",
    "start": "1935120",
    "end": "1942380"
  },
  {
    "text": "alarm actor which is a hypothetical alarm actor that checks for these types",
    "start": "1942380",
    "end": "1947720"
  },
  {
    "text": "of memory messages and what it does is that if you were to do this in",
    "start": "1947720",
    "end": "1953540"
  },
  {
    "text": "production you would just watch for this type of message and you probably want to average it out but in this case I simplified it so that I have a threshold",
    "start": "1953540",
    "end": "1961700"
  },
  {
    "text": "that's defined in the constructor so I've got the high value medium and low value I can keep sending out this",
    "start": "1961700",
    "end": "1967940"
  },
  {
    "text": "message of what memory I'm actually using and as you can see here I put the",
    "start": "1967940",
    "end": "1973220"
  },
  {
    "text": "two new blocks because you'd probably do something better than this where if it goes below the low value you might want",
    "start": "1973220",
    "end": "1979880"
  },
  {
    "text": "to have it speed up if it's the medium value then that's when you want to hit normal speed so as you could see here in",
    "start": "1979880",
    "end": "1987950"
  },
  {
    "text": "a couple of instances we had the high value and the medium value and I think this one is the low value but let's just",
    "start": "1987950",
    "end": "1995059"
  },
  {
    "text": "say that if it went to the high value you can just tell it to either stop",
    "start": "1995059",
    "end": "2000850"
  },
  {
    "text": "pulling until the memory drops to a certain level and then once it switches back up to the medium value then",
    "start": "2000850",
    "end": "2008470"
  },
  {
    "text": "when you could start processing it again the nice part about this approach is that in just a few lines of code you",
    "start": "2008470",
    "end": "2015190"
  },
  {
    "text": "could just check and make long as you control what's going into the system and",
    "start": "2015190",
    "end": "2020440"
  },
  {
    "text": "you tell the whole system to slow down then you could pretty much get any actor system to scale up or scale down and you",
    "start": "2020440",
    "end": "2027220"
  },
  {
    "text": "don't have to do any kind of special clustering this is as simple as it can get so the rest of the stuff is around",
    "start": "2027220",
    "end": "2033940"
  },
  {
    "text": "bullet boiler plate code but for the sake of completeness I'll just go through it so we've got the memory actor",
    "start": "2033940",
    "end": "2039610"
  },
  {
    "text": "that I created here with the timespan of 1 originally this was a printer actor",
    "start": "2039610",
    "end": "2045640"
  },
  {
    "text": "that would just go ahead and print stuff but let's just assume that in this case it's just the alarm actor and there's",
    "start": "2045640",
    "end": "2052868"
  },
  {
    "text": "the syntactic sugar here so I set the high threshold if the memory goes over 5",
    "start": "2052869",
    "end": "2058118"
  },
  {
    "text": "gigs then slow down the normal running memory usage is around 2 gigs and",
    "start": "2058119",
    "end": "2064090"
  },
  {
    "text": "anything less than 1 gig is is it's just fine and tilt the speed up as you can",
    "start": "2064090",
    "end": "2070898"
  },
  {
    "text": "see there's nothing magical about this if I just run this it's let's see",
    "start": "2070899",
    "end": "2080638"
  },
  {
    "text": "anyway bill time takes forever but so",
    "start": "2083450",
    "end": "2093500"
  },
  {
    "text": "the bill time takes forever but in this case it's fairly straightforward because as you can see when it runs you probably",
    "start": "2093500",
    "end": "2103790"
  },
  {
    "text": "want to go ahead and take the average over a few seconds and then once it hits",
    "start": "2103790",
    "end": "2109640"
  },
  {
    "text": "over a certain threshold that's when you would change state but as you can see there's it's pretty simple and later on",
    "start": "2109640",
    "end": "2116660"
  },
  {
    "text": "I'll talk about how you could get over the memory limitation cuz it turns out there's a memory limitation in console",
    "start": "2116660",
    "end": "2124220"
  },
  {
    "text": "apps where if you can't go over I think it's two gigs but one of the things that",
    "start": "2124220",
    "end": "2130460"
  },
  {
    "text": "we ran into very quickly was that we needed way more than two gigs in some",
    "start": "2130460",
    "end": "2135890"
  },
  {
    "text": "cases we need 14 16 gigs on one box so",
    "start": "2135890",
    "end": "2141039"
  },
  {
    "text": "I'll get to that in a second but so now that we've talked about the theory with",
    "start": "2141099",
    "end": "2148790"
  },
  {
    "text": "eventual consistency we've talked about storage the question here here is I did",
    "start": "2148790",
    "end": "2154400"
  },
  {
    "text": "mention before what about that case where we had that outage in June of the",
    "start": "2154400",
    "end": "2159410"
  },
  {
    "text": "thing was last year or the year before that how do you recover from that and we",
    "start": "2159410",
    "end": "2166010"
  },
  {
    "text": "had this process what we called reconciliation so we would collect everything into s3 and we collect",
    "start": "2166010",
    "end": "2173540"
  },
  {
    "text": "duplicates but since we had a list of hash codes it was easy to figure out",
    "start": "2173540",
    "end": "2178849"
  },
  {
    "text": "what was missing in this set so we can look into s3 figure out what's missing",
    "start": "2178849",
    "end": "2185960"
  },
  {
    "text": "we could look in the elastic search and figure out what's missing we could have even put together a Merkel tree and said",
    "start": "2185960",
    "end": "2191900"
  },
  {
    "text": "I've got this set of hash codes on one side and I've got this other set of hash codes on the other side let's just swap",
    "start": "2191900",
    "end": "2198200"
  },
  {
    "text": "events until we're both consistent the best part about this is that we did this",
    "start": "2198200",
    "end": "2207020"
  },
  {
    "text": "every day so we had an end-of-day batch request and when things went really really bad we could just go back into",
    "start": "2207020",
    "end": "2213680"
  },
  {
    "text": "what we saved into s3 pull it out again and then replay it and we're in a state",
    "start": "2213680",
    "end": "2219830"
  },
  {
    "text": "of consistency it took a couple days but the best part about this approach even though duplication itself sounds a bit",
    "start": "2219830",
    "end": "2227450"
  },
  {
    "text": "weird if you're coming from a relational background this did save us again I have",
    "start": "2227450",
    "end": "2234500"
  },
  {
    "text": "to stress this there's nothing magical about what I've talked about this is just Union you could take any two",
    "start": "2234500",
    "end": "2240920"
  },
  {
    "text": "sources as long as you can guarantee if you have an inventory on both sides and",
    "start": "2240920",
    "end": "2246380"
  },
  {
    "text": "do a union on what's missing then you can recover very quickly so now there's",
    "start": "2246380",
    "end": "2257030"
  },
  {
    "text": "a lot of things that we learned out of this process certainly we made a lot of",
    "start": "2257030",
    "end": "2262790"
  },
  {
    "text": "mistakes along the way I mean it's if this were a computer",
    "start": "2262790",
    "end": "2268580"
  },
  {
    "text": "science thing I probably would have flunked 10 times in terms of how we did this but the first thing that I've been",
    "start": "2268580",
    "end": "2276470"
  },
  {
    "text": "saying all along is number one if you duplicate everything and you've got the right merge algorithm it doesn't matter",
    "start": "2276470",
    "end": "2282530"
  },
  {
    "text": "what what you do in fact because you get",
    "start": "2282530",
    "end": "2287720"
  },
  {
    "text": "the consistency that you want so in this case we have a slack message where the reconciliation process says I notice",
    "start": "2287720",
    "end": "2293990"
  },
  {
    "text": "that this amount of events is missing an s3 the other on the other side I'm going",
    "start": "2293990",
    "end": "2299090"
  },
  {
    "text": "to notice that there's 20,000 events that are missing from elastic and that's where we swap the other bit that is",
    "start": "2299090",
    "end": "2308140"
  },
  {
    "text": "pretty self-evident in this case is that if you want to do some strong eventual consistency but you don't want to delve",
    "start": "2308140",
    "end": "2314060"
  },
  {
    "text": "deep too much in the theory it's basically just hash sets and data",
    "start": "2314060",
    "end": "2319250"
  },
  {
    "text": "duplication you combine those two principles and you get your consistency",
    "start": "2319250",
    "end": "2324530"
  },
  {
    "text": "and order doesn't matter I also mentioned before that you since we",
    "start": "2324530",
    "end": "2330110"
  },
  {
    "text": "reduce everything in the hash codes time stamps don't matter either although time stamps do make sense in recording it in",
    "start": "2330110",
    "end": "2337310"
  },
  {
    "text": "your events it it's not really a factor in resolving conflicts in this case we",
    "start": "2337310",
    "end": "2343010"
  },
  {
    "text": "don't get conflicts you just do a union and everything is fixed the other thing take away from this one",
    "start": "2343010",
    "end": "2350960"
  },
  {
    "text": "is that since we use sqs cues in between every single actor system that we have",
    "start": "2350960",
    "end": "2356770"
  },
  {
    "text": "any outage only results in one cue starting to fill up we don't have any",
    "start": "2356770",
    "end": "2362839"
  },
  {
    "text": "offline we don't have any like online outages where people say well my reports",
    "start": "2362839",
    "end": "2368119"
  },
  {
    "text": "aren't working we do get a bit of delay because of the system itself is eventually consistent and there is more",
    "start": "2368119",
    "end": "2375140"
  },
  {
    "text": "than a few times where things have fallen behind but the best part about that is that when we are working in a",
    "start": "2375140",
    "end": "2381500"
  },
  {
    "text": "business that expects things within a span of a day it's ok to fall behind for",
    "start": "2381500",
    "end": "2388670"
  },
  {
    "text": "a couple hours while we fix stuff so just a disclaimer this is not real time",
    "start": "2388670",
    "end": "2394460"
  },
  {
    "text": "in the sense that you we would be trading stocks with it but for day-to-day line of businesses this this",
    "start": "2394460",
    "end": "2401569"
  },
  {
    "text": "was good enough actually we made a couple million bucks out of this so I was quite happy the and the other thing",
    "start": "2401569",
    "end": "2411589"
  },
  {
    "text": "I just want to point out is is everybody familiar with a setting so for those of you who are not familiar with this app",
    "start": "2411589",
    "end": "2419030"
  },
  {
    "text": "config setting if you have a 64-bit app and say you wanted to create a 10",
    "start": "2419030",
    "end": "2424280"
  },
  {
    "text": "gigabyte array it'll throw an out of memory exception unless you had this setting on we learned this very very",
    "start": "2424280",
    "end": "2431960"
  },
  {
    "text": "quickly because when we started queuing up messages that would stream in at once we get out of memory exceptions and we",
    "start": "2431960",
    "end": "2440380"
  },
  {
    "text": "needed more than 2 or 3 gigs so it just seemed useless to have this C 3 double X",
    "start": "2440380",
    "end": "2448010"
  },
  {
    "text": "larger or quad X large instance with 8 to 16 gigs of memory and we're capped at",
    "start": "2448010",
    "end": "2453829"
  },
  {
    "text": "2 gigs so make sure when you get into this you you turn the setting on the",
    "start": "2453829",
    "end": "2462920"
  },
  {
    "text": "last bit is if anybody has what wants to get into a canet there's quite a few",
    "start": "2462920",
    "end": "2469220"
  },
  {
    "text": "examples here so the memory throttling demo that I I posted here you could get",
    "start": "2469220",
    "end": "2476420"
  },
  {
    "text": "it here the hello world a cadet demo is not so important",
    "start": "2476420",
    "end": "2481590"
  },
  {
    "text": "because the a cadet does have those examples but in practice a lot of",
    "start": "2481590",
    "end": "2489390"
  },
  {
    "text": "there's a few things that we didn't do like we didn't do clustering we didn't",
    "start": "2489390",
    "end": "2494970"
  },
  {
    "text": "do remoting simply because in this kind of environment it doesn't make sense the",
    "start": "2494970",
    "end": "2500430"
  },
  {
    "text": "the last thing I wanted to add in terms of how we did this is that it was pretty",
    "start": "2500430",
    "end": "2505440"
  },
  {
    "text": "much a zero config environment we didn't have to do anything like any config",
    "start": "2505440",
    "end": "2511800"
  },
  {
    "text": "files other than the app config and of course the AWS keys for the most part",
    "start": "2511800",
    "end": "2518360"
  },
  {
    "text": "the actor systems that we put together were basically self monitoring self",
    "start": "2518360",
    "end": "2524670"
  },
  {
    "text": "throttling and it makes it easy as as a Deb because you don't have to worry about whether it falls over or not we",
    "start": "2524670",
    "end": "2532320"
  },
  {
    "text": "added a bit of logging as you can see the slack we also did some Sarah log",
    "start": "2532320",
    "end": "2537890"
  },
  {
    "text": "logging but overall it's it's it's a different approach and I hope they you",
    "start": "2537890",
    "end": "2544620"
  },
  {
    "text": "get something out of this but aside from that that's pretty much it does anybody",
    "start": "2544620",
    "end": "2549930"
  },
  {
    "text": "have any questions oh come on alright well thanks for",
    "start": "2549930",
    "end": "2557340"
  },
  {
    "text": "coming to my talking and just enjoy the rest of the conference [Applause]",
    "start": "2557340",
    "end": "2566900"
  }
]
[
  {
    "start": "0",
    "end": "84000"
  },
  {
    "text": "so um welcome everyone uh i'm over here in the uk so uh i can say good morning you know most i guess in the uk in the uh",
    "start": "240",
    "end": "6960"
  },
  {
    "text": "somewhere in europe but probably further afield so uh good morning good afternoon good evening wherever you are my name's robin",
    "start": "6960",
    "end": "12639"
  },
  {
    "text": "moffat um i'm a developer advocate at confluence that's confluent the people who",
    "start": "12639",
    "end": "17920"
  },
  {
    "text": "work on patrick kafka not who build wikis um my background is in data and",
    "start": "17920",
    "end": "23760"
  },
  {
    "text": "analytics and data warehousing and building systems around that and i've been working with kafka for the last few years now",
    "start": "23760",
    "end": "30640"
  },
  {
    "text": "um i do lots of blogging i do lots of talking even with lockdown i've started doing a few youtube videos so you can go to those",
    "start": "30640",
    "end": "37200"
  },
  {
    "text": "links at the bottom there and go and find out more about this stuff i do lots of twitters my handle is on every single slide",
    "start": "37200",
    "end": "43520"
  },
  {
    "text": "because i'm shameless like that so if you enjoy the talk if you have questions if you have any feedback",
    "start": "43520",
    "end": "48640"
  },
  {
    "text": "then do send me a tweet and let me know today i'd like to talk all about apache",
    "start": "48640",
    "end": "54640"
  },
  {
    "text": "kafka and apache kafka is this concept of an ecosystem on a platform so this is not a deep dive into apache",
    "start": "54640",
    "end": "61840"
  },
  {
    "text": "kafka and they're like the nuts and bolts of all kind of individual pieces this is kind of like kafka 101",
    "start": "61840",
    "end": "67760"
  },
  {
    "text": "if you like like an overview of what is kafka what are the pieces that make it up to",
    "start": "67760",
    "end": "73200"
  },
  {
    "text": "hopefully set you up with a very solid foundation to understand what it is and how you can use it and hopefully how",
    "start": "73200",
    "end": "79119"
  },
  {
    "text": "it will benefit you in your projects kafka itself is built on this concept of",
    "start": "79119",
    "end": "85119"
  },
  {
    "start": "84000",
    "end": "273000"
  },
  {
    "text": "events so events are these fantastic things that are really really useful",
    "start": "85119",
    "end": "90720"
  },
  {
    "text": "because events comprise two specific things events are a notification that something",
    "start": "90720",
    "end": "98000"
  },
  {
    "text": "has happened and they're also a state that goes with that notification",
    "start": "98000",
    "end": "103200"
  },
  {
    "text": "so if you think about a lot of the data that you work with day-to-day in your systems whatever it is you're building whatever domain",
    "start": "103200",
    "end": "109119"
  },
  {
    "text": "you work in a lot of the data you work with started life as an event so people think of kafka as",
    "start": "109119",
    "end": "116399"
  },
  {
    "text": "like this streaming thing and they'll have this mental idea of like here is this stream of things and then",
    "start": "116399",
    "end": "122079"
  },
  {
    "text": "over there the majority of the world is like this other just like static data but if you stop and think about how that",
    "start": "122079",
    "end": "127759"
  },
  {
    "text": "static data was born it probably started life as an event and many many different things",
    "start": "127759",
    "end": "133040"
  },
  {
    "text": "are events you have human generated events you have people interacting with our businesses you have",
    "start": "133040",
    "end": "138080"
  },
  {
    "text": "people buying things or clicking on our websites you have inventory moving around between your",
    "start": "138080",
    "end": "143120"
  },
  {
    "text": "warehouses these are events there's a notification someone bought something and there's state what was it that was",
    "start": "143120",
    "end": "150239"
  },
  {
    "text": "bought what was the item where was the shop what time was it you've got a event of things moving in",
    "start": "150239",
    "end": "156400"
  },
  {
    "text": "our warehouses the notification something moved the state what was it where did it move from",
    "start": "156400",
    "end": "162000"
  },
  {
    "text": "where did it move to it's not just human generated events machines generate events as well you",
    "start": "162000",
    "end": "168560"
  },
  {
    "text": "have iot devices with all the different readings being sent out you have networks switches and",
    "start": "168560",
    "end": "174000"
  },
  {
    "text": "routers and firewalls huge number of events happening in those and you also have the applications",
    "start": "174000",
    "end": "179040"
  },
  {
    "text": "themselves that we're building you write an application you have some error handling code and you say we're",
    "start": "179040",
    "end": "184319"
  },
  {
    "text": "going to hit this thing here because there's a problem that is an event there was a problem there's your notification and then you've got the",
    "start": "184319",
    "end": "190800"
  },
  {
    "text": "state you've got the stack trace here's the particular problem we hit here's the error message here's the stack trace",
    "start": "190800",
    "end": "196159"
  },
  {
    "text": "and so applications we're like they'll probably chuck out a message to a log file but those things that we're chucking",
    "start": "196159",
    "end": "201200"
  },
  {
    "text": "into a log file are events so events if we stop and think about it",
    "start": "201200",
    "end": "207040"
  },
  {
    "text": "are pretty much everywhere and there are a few exceptions but most data that we work with starts life",
    "start": "207040",
    "end": "212720"
  },
  {
    "text": "as an event and then like the implementation detail of how we store it is how a lot of us then think about data",
    "start": "212720",
    "end": "218799"
  },
  {
    "text": "oh well my data sits in a database it's not an event well it actually is it's just you've decided to store it",
    "start": "218799",
    "end": "224400"
  },
  {
    "text": "in a different way like aggregated it up away from the events but it started life as in events and these events are very",
    "start": "224400",
    "end": "231599"
  },
  {
    "text": "very powerful there's a lot of good stuff around like event driven systems and event sourcing because people realize that if you have",
    "start": "231599",
    "end": "238560"
  },
  {
    "text": "events you can rebuild state you can drive systems in an asynchronous loosely coupled way by saying",
    "start": "238560",
    "end": "244879"
  },
  {
    "text": "if something happens over here this thing needs to respond but we're not going to tightly couple them together we're going to start",
    "start": "244879",
    "end": "250640"
  },
  {
    "text": "pulling this thing to say have you done it yet we're gonna do it the other way around we're gonna say this thing happens now",
    "start": "250640",
    "end": "256000"
  },
  {
    "text": "other people cannot know about it so events are really powerful but how are we gonna",
    "start": "256000",
    "end": "262479"
  },
  {
    "text": "actually use them or as the buzzword would say how we're going to leverage them but we may use",
    "start": "262479",
    "end": "267759"
  },
  {
    "text": "how we're going to take advantage of these fantastically powerful things we need a platform on which to build",
    "start": "267759",
    "end": "273520"
  },
  {
    "start": "273000",
    "end": "311000"
  },
  {
    "text": "with them so we're going to start small we're going to start with an event but obviously events happen",
    "start": "273520",
    "end": "280479"
  },
  {
    "text": "continually over time so now we've got lots of events so we need to think about how we're going to capture these events",
    "start": "280479",
    "end": "286560"
  },
  {
    "text": "how we're going to work with them and for the moment we're going to think of an event simply as a key value pair",
    "start": "286560",
    "end": "291919"
  },
  {
    "text": "we're going to drill into this concept a bit later on in this talk but for now just bear with me we're just going to think of an event",
    "start": "291919",
    "end": "297680"
  },
  {
    "text": "as a key value and this could be an order being placed it could be your application throwing an error it could be a temperature reading from a",
    "start": "297680",
    "end": "303280"
  },
  {
    "text": "device it's just an event so we saw logs in this very very simple",
    "start": "303280",
    "end": "309120"
  },
  {
    "text": "but very powerful idea of a blog this log is not your application log file that's like log.txt",
    "start": "309120",
    "end": "316400"
  },
  {
    "start": "311000",
    "end": "414000"
  },
  {
    "text": "means log4d or whatever i i suppose that is a log but a log that i'm talking about here is a much more",
    "start": "316400",
    "end": "322320"
  },
  {
    "text": "foundational fundamental concept which is where we say this log is where",
    "start": "322320",
    "end": "327759"
  },
  {
    "text": "we put our events and we append them as they happen over time so something happens we write",
    "start": "327759",
    "end": "334160"
  },
  {
    "text": "it onto the login it's append only it's append only and it is",
    "start": "334160",
    "end": "339199"
  },
  {
    "text": "immutable so because it's immutable that's very very powerful because we can say here are the things",
    "start": "339199",
    "end": "345199"
  },
  {
    "text": "that happened and we know that none of them have changed so if you imagine having a conversation with",
    "start": "345199",
    "end": "351039"
  },
  {
    "text": "someone and you say things and someone else says something and maybe you get into an argument and you say some heated things",
    "start": "351039",
    "end": "356240"
  },
  {
    "text": "that you probably wish you hadn't said with hindsight but you've said them it is immutable that event has happened",
    "start": "356240",
    "end": "362240"
  },
  {
    "text": "that fact has been said that sentence was said in anger and you can't go back and change that it is",
    "start": "362240",
    "end": "367440"
  },
  {
    "text": "immutable all you can do is like hopefully put down another event to try and counteract that and apologize and",
    "start": "367440",
    "end": "372800"
  },
  {
    "text": "undo what you said but it has been said it is immutable and so is a log so a log is like a",
    "start": "372800",
    "end": "379520"
  },
  {
    "text": "commit log of all the things that have happened of our events so events happen over time",
    "start": "379520",
    "end": "384639"
  },
  {
    "text": "and it gives us this idea of the log so the log is what underpins everything",
    "start": "384639",
    "end": "389840"
  },
  {
    "text": "that we're doing here so it's a very simple but a very powerful concept so if we think of this idea of taking",
    "start": "389840",
    "end": "396720"
  },
  {
    "text": "all these events that are happening we store them on a log at some point we're going to say well that's not necessarily manageable",
    "start": "396720",
    "end": "402240"
  },
  {
    "text": "just have like one log with all these different types of events going on because we've got lots of different types of events we've got lots of",
    "start": "402240",
    "end": "408080"
  },
  {
    "text": "different entities so we say well okay let's take this log and we're going to carve it up and we'll",
    "start": "408080",
    "end": "413199"
  },
  {
    "text": "call it topics topics is a fairly well-known term if you're from the database world like i am",
    "start": "413199",
    "end": "418400"
  },
  {
    "start": "414000",
    "end": "533000"
  },
  {
    "text": "you probably think in terms of tables but here we've got things like clips on our website so people are clicking our around our",
    "start": "418400",
    "end": "424720"
  },
  {
    "text": "website those are events there's a notification they did a click the state what was it they clicked on who was the user what's their user agent",
    "start": "424720",
    "end": "431120"
  },
  {
    "text": "and so on we've got orders coming in so someone placed an order there's our notification",
    "start": "431120",
    "end": "436240"
  },
  {
    "text": "or the order shipped there's a notification here's the state around it we've got another example topic here",
    "start": "436240",
    "end": "442400"
  },
  {
    "text": "called customers and people don't always realize this first off they'll kind of think well",
    "start": "442400",
    "end": "447840"
  },
  {
    "text": "clicks and orders those are obvious events and i can kind of easily see how those would go on to a topic and store those in an event platform but",
    "start": "447840",
    "end": "455360"
  },
  {
    "text": "customers customers are like what would call reference data or lookup data and does it make sense to put those into",
    "start": "455360",
    "end": "461759"
  },
  {
    "text": "a series of events but if you think about it customers or any kind of data like that are created",
    "start": "461759",
    "end": "468720"
  },
  {
    "text": "through an event it gets created there's your event and it gets updated and it gets updated",
    "start": "468720",
    "end": "474319"
  },
  {
    "text": "again and so a customer registers on our website there's your create and the state that goes with it they move house they update their",
    "start": "474319",
    "end": "480240"
  },
  {
    "text": "address there's your events in the state that goes with it and if you capture all of those different events to do with",
    "start": "480240",
    "end": "485919"
  },
  {
    "text": "your customers or your product reference or whatever you end up with a series of events that you can replay to give you the state",
    "start": "485919",
    "end": "493199"
  },
  {
    "text": "of that particular entity so in data warehousing analytics we talk about",
    "start": "493199",
    "end": "499280"
  },
  {
    "text": "facts and dimensions and it's the same kind of thing here all of these things live very very naturally when broken down",
    "start": "499280",
    "end": "506400"
  },
  {
    "text": "into events because with all of these things we can replay them to rebuild state when we want to so we cut up our log",
    "start": "506400",
    "end": "514080"
  },
  {
    "text": "into what we call topics and this gives us the ability to arrange our data into kind of separate entities to make it",
    "start": "514080",
    "end": "520800"
  },
  {
    "text": "appropriate for use we're going to cut it up one third time and we're going to do",
    "start": "520800",
    "end": "526160"
  },
  {
    "text": "this as a way of giving us a system which is highly scalable and performance so each topic can have one or more",
    "start": "526160",
    "end": "533519"
  },
  {
    "start": "533000",
    "end": "577000"
  },
  {
    "text": "partition so partitions take that topic and they cut it up and they say well within this topic",
    "start": "533519",
    "end": "540080"
  },
  {
    "text": "we're going to have maybe three different partitions and the reason for doing this is that we",
    "start": "540080",
    "end": "545120"
  },
  {
    "text": "can then spread that data across different nodes because kafka itself is a distributed system",
    "start": "545120",
    "end": "550800"
  },
  {
    "text": "we'll talk about that in just a moment so we can distribute the data across different ones by having separate",
    "start": "550800",
    "end": "556320"
  },
  {
    "text": "partitions but you can also use it for parallelization of reading and processing that data",
    "start": "556320",
    "end": "562080"
  },
  {
    "text": "so instead of just having like one log log file you can only read through sequentially by one user",
    "start": "562080",
    "end": "567440"
  },
  {
    "text": "instead we split up into topics and partitions within those topics and now we can process that data at very",
    "start": "567440",
    "end": "573760"
  },
  {
    "text": "very high scale so we started talking about getting data",
    "start": "573760",
    "end": "579040"
  },
  {
    "start": "577000",
    "end": "645000"
  },
  {
    "text": "in we've started talking about getting data out so let's talk about this concept of pub sub",
    "start": "579040",
    "end": "584560"
  },
  {
    "text": "first off publishing the data to the topic how do we get that data how do we get these events into a topic we use the producer api",
    "start": "584560",
    "end": "593200"
  },
  {
    "text": "so apache kafka it ships with a java client and there's other client libraries for c c plus plus",
    "start": "593200",
    "end": "599480"
  },
  {
    "text": "python.net go and like every single common language there is if there isn't one for your language",
    "start": "599480",
    "end": "604880"
  },
  {
    "text": "of choice or you'd rather not use that there's also a rest api you can also use for producing data so",
    "start": "604880",
    "end": "610560"
  },
  {
    "text": "whatever it is you're using there's always a way to get data onto a kafka topic",
    "start": "610560",
    "end": "615839"
  },
  {
    "text": "as we said the data goes on to the end of the topic when we produce it as events get appended to the end of it if we're",
    "start": "615839",
    "end": "622959"
  },
  {
    "text": "talking about using a producer that's going to write across different partitions it will handle allocating those",
    "start": "622959",
    "end": "628800"
  },
  {
    "text": "different partitions the producer codes look something like this if you're using java which they're",
    "start": "628800",
    "end": "634000"
  },
  {
    "text": "going to spin up and produce we're going to connect to a broker i'm going to send messages",
    "start": "634000",
    "end": "639200"
  },
  {
    "text": "in this particular way so the beginning i talked about events",
    "start": "639200",
    "end": "644800"
  },
  {
    "text": "and i said for now let's just talk about events as these key values now let's drill into a little bit more",
    "start": "644800",
    "end": "650399"
  },
  {
    "start": "645000",
    "end": "850000"
  },
  {
    "text": "about what we mean about that because kafka itself just treats those messages as key value bytes it just says you've",
    "start": "650399",
    "end": "657040"
  },
  {
    "text": "got a key part of the message and you've got a value and that could be like foo and bar as your key and your",
    "start": "657040",
    "end": "662800"
  },
  {
    "text": "value it could be your key is one your value is a hugely complex schema like a tweet is a good example of an",
    "start": "662800",
    "end": "669200"
  },
  {
    "text": "event it's got a key which might be the tweet id and then the value of a tweet it's like",
    "start": "669200",
    "end": "674720"
  },
  {
    "text": "if you've used the developer api you'll see like a hugely nested structure like all sorts of stuff so the value itself isn't",
    "start": "674720",
    "end": "680880"
  },
  {
    "text": "just like one single volume the value itself could be hugely complex nested if you want to",
    "start": "680880",
    "end": "686959"
  },
  {
    "text": "you don't even have to specify the key and if you don't specify a key when we use the producer api it will",
    "start": "686959",
    "end": "693200"
  },
  {
    "text": "just round robin those messages evenly across however many partitions you've got in your topic",
    "start": "693200",
    "end": "698640"
  },
  {
    "text": "so you end up with a nice even distribution but within partitions we have this guarantee",
    "start": "698640",
    "end": "705360"
  },
  {
    "text": "of ordering so when you write data into a partition you're guaranteed by kafka by",
    "start": "705360",
    "end": "710800"
  },
  {
    "text": "the way it's built that when you read that data back you'll get it in the strict order that",
    "start": "710800",
    "end": "716160"
  },
  {
    "text": "has written to that partition which is really really useful because we've got this immutability guarantee",
    "start": "716160",
    "end": "722320"
  },
  {
    "text": "that stuff's not going to be changed once it's being written to it we've also got this stripped ordering guarantee which means we can say well",
    "start": "722320",
    "end": "728800"
  },
  {
    "text": "i'm going to take this particular instance of an entity like a particular customer i'm going to read back all the events",
    "start": "728800",
    "end": "735040"
  },
  {
    "text": "that we've got relating to that customer or this order or whatever i know i'll get every single one and",
    "start": "735040",
    "end": "740240"
  },
  {
    "text": "it's not being changed along the way because it's immutable and i know that i'll get every single one in all",
    "start": "740240",
    "end": "746240"
  },
  {
    "text": "but that only applies within a partition so if we're doing that kind of thing we",
    "start": "746240",
    "end": "752240"
  },
  {
    "text": "need to make sure that we've got all of the data relating to our particular instance of an entity that we're",
    "start": "752240",
    "end": "757839"
  },
  {
    "text": "interested in on the same partition and that's where keys come in because if we don't set a key the data just gets",
    "start": "757839",
    "end": "764720"
  },
  {
    "text": "round rubbing evenly distributed across the partitions which might be fine but you might actually want to ensure",
    "start": "764720",
    "end": "769920"
  },
  {
    "text": "that we do have that locality and the partition for each instance so for that we set a key and then kafka",
    "start": "769920",
    "end": "777200"
  },
  {
    "text": "producer api uses a hash of that key to make sure that every key value",
    "start": "777200",
    "end": "782560"
  },
  {
    "text": "ends up on the same partition every time it gets written to so you then end up with the data spread",
    "start": "782560",
    "end": "787760"
  },
  {
    "text": "across the partitions and this is where choosing your key appropriately comes in because you want to make sure you set it",
    "start": "787760",
    "end": "793519"
  },
  {
    "text": "based on i want all of these events to be strictly in order for a particular customer or something",
    "start": "793519",
    "end": "798959"
  },
  {
    "text": "but you also want to make sure you don't end up with lumpy distribution so if you said i'm going to partition it",
    "start": "798959",
    "end": "804079"
  },
  {
    "text": "i'm going to use the key of location that might not be so good because you're going to end up with like",
    "start": "804079",
    "end": "809519"
  },
  {
    "text": "one partition that's hugely overpopulated maybe if you break it down by city like the capital city will have",
    "start": "809519",
    "end": "814720"
  },
  {
    "text": "loads of records and like really small uh low and populated uh areas",
    "start": "814720",
    "end": "820240"
  },
  {
    "text": "will have much fewer records in their partitions so you need to pick it appropriately as well for bearing in mind how you're going to",
    "start": "820240",
    "end": "826240"
  },
  {
    "text": "spread that data out so this producer api it's a client library it's an application that we",
    "start": "826240",
    "end": "832320"
  },
  {
    "text": "write it gets the messages onto the topic it handles talking to the brokers it",
    "start": "832320",
    "end": "838160"
  },
  {
    "text": "handles the partition logic there's various different languages there's a rest api as well if you want to use that",
    "start": "838160",
    "end": "845680"
  },
  {
    "text": "so we've got the data onto a topic how do we get the data out and this is a little bit more",
    "start": "845760",
    "end": "851760"
  },
  {
    "start": "850000",
    "end": "1160000"
  },
  {
    "text": "complicated for good reasons because it's very very powerful but producing data onto kafka is basically like where's my kafka cluster",
    "start": "851760",
    "end": "858399"
  },
  {
    "text": "and here's the data off you go we're going to talk about serialization later that's where it gets a little bit more interesting",
    "start": "858399",
    "end": "863440"
  },
  {
    "text": "but for now producing data check the data and we're done consuming the data it's really",
    "start": "863440",
    "end": "868639"
  },
  {
    "text": "interesting it's very very powerful what we can do here when we go to kafka and say i would like",
    "start": "868639",
    "end": "874480"
  },
  {
    "text": "to read a message that access is only sequential you can't do like random access and get like give me the value",
    "start": "874480",
    "end": "880240"
  },
  {
    "text": "for all of these particular keys or like do searches on it like we would do in a database it doesn't work like that",
    "start": "880240",
    "end": "885279"
  },
  {
    "text": "we've got a log we've got this immutable append only log and we can seek through that log to a",
    "start": "885279",
    "end": "890639"
  },
  {
    "text": "particular place in it and then start scanning through and reading those messages so our first",
    "start": "890639",
    "end": "896000"
  },
  {
    "text": "consumer comes along and they connect to calculus and i'd like the messages from the orders topic and kafka says okay here are all of",
    "start": "896000",
    "end": "901760"
  },
  {
    "text": "those messages now if you're thinking of kafka in your little",
    "start": "901760",
    "end": "907040"
  },
  {
    "text": "mind model of technologies that we've got to try and comprehend these days like all these different terms and stuff like that",
    "start": "907040",
    "end": "912480"
  },
  {
    "text": "if you've got kafka bucketed in that same area as transient message cues then you need to",
    "start": "912480",
    "end": "919040"
  },
  {
    "text": "scratch that and like reevaluate because kafka is actually an event streaming platform in",
    "start": "919040",
    "end": "924560"
  },
  {
    "text": "its own right it's not transient message queue that's one of the most important things to",
    "start": "924560",
    "end": "930000"
  },
  {
    "text": "understand it's a distributed commit log that we can send messages to and we can read messages from but when",
    "start": "930000",
    "end": "936880"
  },
  {
    "text": "we read a message it is not deleted even if another consumer comes along and says",
    "start": "936880",
    "end": "942160"
  },
  {
    "text": "i'd also like to read those messages kafka doesn't say oh well two consumers have read that so i must be done with them i'm going to delete it now",
    "start": "942160",
    "end": "948480"
  },
  {
    "text": "kafka says you gave me that data i appended it to the log it will stay on that log until you tell",
    "start": "948480",
    "end": "955600"
  },
  {
    "text": "me to get rid of it so regardless of what the consumers have done we say to kafka this particular topic",
    "start": "955600",
    "end": "962639"
  },
  {
    "text": "here it's got information about clicks for the website i'd like to keep seven days worth of that because that's kind of the the business",
    "start": "962639",
    "end": "968000"
  },
  {
    "text": "use case for processing that data this topic of orders i'd like to keep that for 10 years please because that's when we're going",
    "start": "968000",
    "end": "974079"
  },
  {
    "text": "to need to use it this topic of customers over here we're going to keep that forever because we want to have that as our",
    "start": "974079",
    "end": "979519"
  },
  {
    "text": "system of record for all of our customers you know when they're created updated we can use that and we can replay it to",
    "start": "979519",
    "end": "985199"
  },
  {
    "text": "build the state anywhere else we want to but we're going to keep it forever so when the consumers come along they",
    "start": "985199",
    "end": "991279"
  },
  {
    "text": "simply say to kafka i would like to re-date it from this topic and kafka will either say okay here's every single new messages",
    "start": "991279",
    "end": "997519"
  },
  {
    "text": "as it arrives or it'll go back to the beginning of the topic and say here is every message that i've stored",
    "start": "997519",
    "end": "1003040"
  },
  {
    "text": "and scan through and hear all of those and then hear the new messages as they arrive as well",
    "start": "1003040",
    "end": "1008079"
  },
  {
    "text": "consumers can even say well i've read those ones from here and actually i'd like to replay them so",
    "start": "1008079",
    "end": "1013519"
  },
  {
    "text": "my application was running everything was good and then downstream of my application something went bad",
    "start": "1013519",
    "end": "1018959"
  },
  {
    "text": "we realized there was a bug in the code i would like to rewind i would like to skip back to a",
    "start": "1018959",
    "end": "1024558"
  },
  {
    "text": "particular offset so let's go back to offset 42 or i would like to go to an offset based",
    "start": "1024559",
    "end": "1029678"
  },
  {
    "text": "on timestamp i would like to start reading messages as of yesterday at three o'clock kafka",
    "start": "1029679",
    "end": "1035360"
  },
  {
    "text": "says okay that corresponds to this offset here you go here are the messages since yesterday at three o'clock and then we",
    "start": "1035360",
    "end": "1040558"
  },
  {
    "text": "keep on scanning through until we get to the end of the log and then the consumer keeps on reading those new messages as they arrive so when a",
    "start": "1040559",
    "end": "1048000"
  },
  {
    "text": "consumer reads a message it is not deleted consumers don't even have to exist they don't even have to be in the",
    "start": "1048000",
    "end": "1053360"
  },
  {
    "text": "thought of yet when we write data to kafka and this is one of the very very powerful things because we can then say i subscribe to",
    "start": "1053360",
    "end": "1060640"
  },
  {
    "text": "this one i don't subscribe to silly turns i agree with this idea of events being very very useful and very very powerful",
    "start": "1060640",
    "end": "1067360"
  },
  {
    "text": "so i'm going to embrace this and my application or my system is going to say something happened someone clicked on",
    "start": "1067360",
    "end": "1073200"
  },
  {
    "text": "something someone bought something i'm going to produce that event to kafka because that's probably going to be",
    "start": "1073200",
    "end": "1078480"
  },
  {
    "text": "something that someone else wants to know about and that's all the producing application has to do",
    "start": "1078480",
    "end": "1083679"
  },
  {
    "text": "and now your consumers can come along and either they were built for specifically for that particular use case and",
    "start": "1083679",
    "end": "1088960"
  },
  {
    "text": "it gets produced and then they consume or it could be a consumer comes along next week or next next month or next year and says",
    "start": "1088960",
    "end": "1095440"
  },
  {
    "text": "oh we've got a topic of orders that's really useful i'm going to go and read those so long as we've set the retention appropriately",
    "start": "1095440",
    "end": "1101440"
  },
  {
    "text": "on the topic anyone with the appropriate security setup can then come and read those",
    "start": "1101440",
    "end": "1106840"
  },
  {
    "text": "messages so consumer again here's the java example connect to the broker we call the broker",
    "start": "1106840",
    "end": "1112559"
  },
  {
    "text": "particular topic and we receive those messages so a consumer will read data from the",
    "start": "1112559",
    "end": "1119919"
  },
  {
    "text": "topic or read across multiple partitions if the topic is partitioned we can have separate consumers which are",
    "start": "1119919",
    "end": "1125440"
  },
  {
    "text": "completely independent from each other again it's worth pointing out because kafka is storing this data",
    "start": "1125440",
    "end": "1132160"
  },
  {
    "text": "if one consumer like falls over and like hasn't read some stuff the other one is not affected",
    "start": "1132160",
    "end": "1137520"
  },
  {
    "text": "that data stays there as long as we've told it to retain it and then it gets aged out so other",
    "start": "1137520",
    "end": "1142720"
  },
  {
    "text": "consumers aren't going to suffer if one of them has stopped like in other systems things would start to back up",
    "start": "1142720",
    "end": "1148480"
  },
  {
    "text": "and like you'd end up with these huge bottlenecks because one of them hadn't read the messages and the system couldn't cope with all these",
    "start": "1148480",
    "end": "1153600"
  },
  {
    "text": "messages building up students kafka works completely differently from that",
    "start": "1153600",
    "end": "1158880"
  },
  {
    "text": "kafka also lets you consume messages in parallel and this is where the partitioning thing",
    "start": "1158880",
    "end": "1164080"
  },
  {
    "start": "1160000",
    "end": "1350000"
  },
  {
    "text": "comes in because at the moment on the screen here we've got two consumers c1 c2 the blue one at the top the green one",
    "start": "1164080",
    "end": "1170000"
  },
  {
    "text": "at the bottom separate completely independent applications each one reads all of the data in the",
    "start": "1170000",
    "end": "1175200"
  },
  {
    "text": "topic what if we need to process that data faster that a single consumer can keep",
    "start": "1175200",
    "end": "1181360"
  },
  {
    "text": "up with so c1 the blue one at the top of the screen here maybe that's some kind of fraud processing thing that",
    "start": "1181360",
    "end": "1187120"
  },
  {
    "text": "as orders get placed on this source topic it needs to process them it needs to score them write them back on to a separate topic",
    "start": "1187120",
    "end": "1192880"
  },
  {
    "text": "but another system to pick up and do something with and we've got a single instance of that application",
    "start": "1192880",
    "end": "1198720"
  },
  {
    "text": "and it can't keep up with the throughput that we need to meet our sla for this particular service that we've written",
    "start": "1198720",
    "end": "1204159"
  },
  {
    "text": "and we scale the machine and we put more cpus in and give it more memory and we still can't keep up she's okay well",
    "start": "1204159",
    "end": "1210320"
  },
  {
    "text": "let's scale it out let's add in additional instances of that consumer",
    "start": "1210320",
    "end": "1215919"
  },
  {
    "text": "so now we've still got two logical consumers got c2 at the bottom got c1 at",
    "start": "1215919",
    "end": "1221600"
  },
  {
    "text": "the top but c1 has got multiple physical instances of the consumer and kafka handles this",
    "start": "1221600",
    "end": "1228799"
  },
  {
    "text": "for you you simply say here is another instance of my consumer and kafka's got this protocol as part of it so",
    "start": "1228799",
    "end": "1234880"
  },
  {
    "text": "a nice little slide here for my colleague vic gamov the idea is you've got your consumers their little birds in the nest cheaping away",
    "start": "1234880",
    "end": "1241280"
  },
  {
    "text": "that nest forms what's called a consumer group so consumer group is this logical grouping of a set of",
    "start": "1241280",
    "end": "1247120"
  },
  {
    "text": "instances of the consumer doing the same logical task and then kafka itself acts as mummy burn",
    "start": "1247120",
    "end": "1252559"
  },
  {
    "text": "it's like it's called the consumer group coordinator this is okay you're an instance of this consumer",
    "start": "1252559",
    "end": "1257600"
  },
  {
    "text": "group you get data from this partition you're another instance of a consumer within this consumer group you get data from this partition so you",
    "start": "1257600",
    "end": "1265440"
  },
  {
    "text": "end up with a data allocated across based on the number of partitions that you've got the number of consumers that you've got",
    "start": "1265440",
    "end": "1272400"
  },
  {
    "text": "and it will evenly distribute that work so if we've got four partitions and we've got four consumers then each",
    "start": "1272400",
    "end": "1278320"
  },
  {
    "text": "consumer within that consumer group gets data from one partition if we had four partitions and two",
    "start": "1278320",
    "end": "1285360"
  },
  {
    "text": "consumers within the consumer group each consumer would get two partitions and kafka understands that you've got",
    "start": "1285360",
    "end": "1292080"
  },
  {
    "text": "these processes running within that consumer group it'll keep an eye on them and if you lose one of them",
    "start": "1292080",
    "end": "1297120"
  },
  {
    "text": "then it'll say okay well we've now got a partition that's not being consumed it's not being read from and we don't",
    "start": "1297120",
    "end": "1302320"
  },
  {
    "text": "want to do that need because we've got guarantees in place that all of this data is going to get read so then we say well okay one of the other",
    "start": "1302320",
    "end": "1308480"
  },
  {
    "text": "consumers will get allocated work from that partition so kafka does all of the heavy lifting",
    "start": "1308480",
    "end": "1314880"
  },
  {
    "text": "here for you that within your application you may have to do otherwise start writing like how do i manage",
    "start": "1314880",
    "end": "1320159"
  },
  {
    "text": "scaling the consumption of this workload and all of these tricky things you simply say here's my consumer it's",
    "start": "1320159",
    "end": "1325360"
  },
  {
    "text": "part of this consumer group kafka says okay you get this you get that",
    "start": "1325360",
    "end": "1331039"
  },
  {
    "text": "so consumer api very very powerful a little bit more complicated than the producer api",
    "start": "1331039",
    "end": "1336559"
  },
  {
    "text": "it's still a client application and it reads the messages from the topics it lets you scale your work horizontally",
    "start": "1336559",
    "end": "1342640"
  },
  {
    "text": "you just add in additional consumers and again different uh libraries as well",
    "start": "1342640",
    "end": "1349440"
  },
  {
    "start": "1350000",
    "end": "1479000"
  },
  {
    "text": "we need somewhere to store all of this data and we're going to store it on brokers so so far we've been very very",
    "start": "1350080",
    "end": "1356559"
  },
  {
    "text": "abstract we've talked about logs and events there's like these key value things now we're getting out into the",
    "start": "1356559",
    "end": "1362000"
  },
  {
    "text": "nitty-gritty of like where does this stuff even live like i'm gonna go and try this out it sounds brilliant but where to even live what",
    "start": "1362000",
    "end": "1367840"
  },
  {
    "text": "process do i need to run kafka itself has a broker process that's",
    "start": "1367840",
    "end": "1373280"
  },
  {
    "text": "like a jvm process that you spin up and you can see on your machine so the kafka broker is where this",
    "start": "1373280",
    "end": "1378640"
  },
  {
    "text": "actually all happens and it's a distributed system you can run a single instance of it if you want",
    "start": "1378640",
    "end": "1384000"
  },
  {
    "text": "but that's not really distributed it's not very scalable it's only fault tolerance so a typical production deployment will",
    "start": "1384000",
    "end": "1389440"
  },
  {
    "text": "start off with a minimum of three brokers and each broker will contain some of the data which is",
    "start": "1389440",
    "end": "1396000"
  },
  {
    "text": "why we partition it because we can then spread out across those different brokers you don't have to partition it",
    "start": "1396000",
    "end": "1402000"
  },
  {
    "text": "but then you'll see from the previous example you're not going to scale very far with it so each",
    "start": "1402000",
    "end": "1408640"
  },
  {
    "text": "holds some of the data you've got four partitions those partitions are going to get spread across each broker and standard",
    "start": "1408640",
    "end": "1415039"
  },
  {
    "text": "distributed systems fashion we're going to hold redundant copies of that data too so we've got the leader partition exists",
    "start": "1415039",
    "end": "1421840"
  },
  {
    "text": "on the different brokers and then you've got follower copies of that partition data all for redundancy spread across the",
    "start": "1421840",
    "end": "1428159"
  },
  {
    "text": "brokers as well so here we've got three brokers we've got a kind of like replication factor of three so it exists on three different",
    "start": "1428159",
    "end": "1434159"
  },
  {
    "text": "brokers if you had seven brokers you're some without data from some of those partitions it just means you've got that",
    "start": "1434159",
    "end": "1440320"
  },
  {
    "text": "room to scale if you want to and if you have other topics then their data will be spread out across",
    "start": "1440320",
    "end": "1445520"
  },
  {
    "text": "them so the example here is a single topic with four partitions spread across those three brokers and if",
    "start": "1445520",
    "end": "1453440"
  },
  {
    "text": "you lose a broker if things go bang or someone unplugs it from the wall or something like that because we have redundant copies of the",
    "start": "1453440",
    "end": "1459840"
  },
  {
    "text": "data one of the remaining brokers can step up and say well that's fine i will take over leader responsibilities",
    "start": "1459840",
    "end": "1465840"
  },
  {
    "text": "for this particular partition so it's very very powerful it means that you can scale out as you need to",
    "start": "1465840",
    "end": "1471760"
  },
  {
    "text": "and you have this built-in redundancy and failover provided by default",
    "start": "1471760",
    "end": "1478159"
  },
  {
    "text": "so let's actually have a look at this in practice i'll show you a very simple demo and then we're going to talk about uh",
    "start": "1478159",
    "end": "1484159"
  },
  {
    "start": "1479000",
    "end": "1830000"
  },
  {
    "text": "more advanced things that you can do with it so the example i'm going to show you here and all the slides i should have",
    "start": "1484159",
    "end": "1489679"
  },
  {
    "text": "said all of the slides and stuff they'll be online and follow my twitter i'll be tweeting them or i'll put them on the slack channel afterwards as well",
    "start": "1489679",
    "end": "1496080"
  },
  {
    "text": "but all the demos are online as well so you can actually go and try this out for yourself it's just based around",
    "start": "1496080",
    "end": "1501200"
  },
  {
    "text": "docker and docker compose so there's a cheat sheet which is when i keep on looking down like that that's what i'm looking at",
    "start": "1501200",
    "end": "1506880"
  },
  {
    "text": "and you can follow the demo through and try it out so the first thing that we're going to do is we're going to fill up a producer and",
    "start": "1506880",
    "end": "1513440"
  },
  {
    "text": "here i'm using a command line interface uh called kafka cat um i'm more of a kind of data engineer",
    "start": "1513440",
    "end": "1518799"
  },
  {
    "text": "type person than like a full-on coder and so i tend to kind of like the the command line instead of writing",
    "start": "1518799",
    "end": "1524240"
  },
  {
    "text": "applications but if you prefer using java or something like that you could go and imagine your java code here or python or",
    "start": "1524240",
    "end": "1529919"
  },
  {
    "text": "whatever it's a producer api okay so it's a tool called kafka cat it's going to connect to kafka broker",
    "start": "1529919",
    "end": "1536960"
  },
  {
    "text": "and we're going to produce messages to this topic called test",
    "start": "1536960",
    "end": "1542320"
  },
  {
    "text": "so we hit enter and then we worry because it's a live demo and nothing's happening but it's a producer it's saying well give me some data to produce",
    "start": "1542320",
    "end": "1549440"
  },
  {
    "text": "so i've said here dash k colon because we're going to use colon as a separator between keys",
    "start": "1549440",
    "end": "1554559"
  },
  {
    "text": "and values so let's send a message there's a key called one i'm going to say hello ndc and",
    "start": "1554559",
    "end": "1562400"
  },
  {
    "text": "we've sent two messages to kafka we've sent them to the topic so now we can read them from the topic",
    "start": "1562400",
    "end": "1567760"
  },
  {
    "text": "so i'm now going to spin up a second process so in the bottom of the screen here we're going to create",
    "start": "1567760",
    "end": "1572960"
  },
  {
    "text": "ourselves a consumer so pretty much the same command here's my broker here's my topic and then dash c because you want a consumer",
    "start": "1572960",
    "end": "1579760"
  },
  {
    "text": "this is there's our two messages hello in dc you'll notice there it's just showing the values of those messages not the",
    "start": "1579760",
    "end": "1586000"
  },
  {
    "text": "keys as well because that's what it does by default and if we say some more send some more messages so like i",
    "start": "1586000",
    "end": "1591919"
  },
  {
    "text": "wish i was in oslo you can see those messages coming across",
    "start": "1591919",
    "end": "1597120"
  },
  {
    "text": "as we send them to the producer they get consumed they get consumed but they don't get deleted super",
    "start": "1597120",
    "end": "1604000"
  },
  {
    "text": "important point and the reason i labor it's like if you're familiar with kafka apologies for going on about it if you're not familiar to captain with",
    "start": "1604000",
    "end": "1610320"
  },
  {
    "text": "kafka it's a really really important point to get so i'm going to keep on laboring that point because we've consumed the messages",
    "start": "1610320",
    "end": "1616640"
  },
  {
    "text": "does not mean anything to do with when they're going to get deleted from the topic they're completely decoupled concepts they'll stay on the",
    "start": "1616640",
    "end": "1622720"
  },
  {
    "text": "topic for as long as we've told kafka to keep the data on that topic file so we can read the data again so in the",
    "start": "1622720",
    "end": "1628960"
  },
  {
    "text": "bottom right of the screen here again we use kafka cards we're going to use a consumer and this time we're going to use this here which",
    "start": "1628960",
    "end": "1635039"
  },
  {
    "text": "basically says format the data as it comes out so it's going to read the messages and it's going to say okay we've got data from",
    "start": "1635039",
    "end": "1641120"
  },
  {
    "text": "the test topic it's from this particular partition here are the offsets of those individual",
    "start": "1641120",
    "end": "1646559"
  },
  {
    "text": "messages again we can see we've got the values and you've got the key",
    "start": "1646559",
    "end": "1651760"
  },
  {
    "text": "so you've got the key to the messages which is also being displayed and if we send some more messages now so",
    "start": "1651760",
    "end": "1656799"
  },
  {
    "text": "like this one doesn't have a key so we send a new message there it doesn't have to have a key you send that",
    "start": "1656799",
    "end": "1663120"
  },
  {
    "text": "across and both the consumers read get that message straight away and you can see down here",
    "start": "1663120",
    "end": "1668399"
  },
  {
    "text": "where we're showing the key it has a blank because we don't have a key i can send more messages you can see it",
    "start": "1668399",
    "end": "1673919"
  },
  {
    "text": "as we send those messages they're going straight across to those constraints if we go to the consumer here and clear",
    "start": "1673919",
    "end": "1680240"
  },
  {
    "text": "that so we can see what's going on we can also say well i would like to read instead of from the beginning",
    "start": "1680240",
    "end": "1685600"
  },
  {
    "text": "of the topic just start at this particular asset just start offset six so we know that we got to",
    "start": "1685600",
    "end": "1690960"
  },
  {
    "text": "offset five last time we've decided that we weren't so sorry we got to offset uh 10 last time and now we want to reprocess",
    "start": "1690960",
    "end": "1697679"
  },
  {
    "text": "so it's okay we're going to go back to offset six this is okay here's the messages from offset six onwards",
    "start": "1697679",
    "end": "1704240"
  },
  {
    "text": "in saying that i realize i've admitted in a very very important detail which is that as consumer applications",
    "start": "1704240",
    "end": "1712000"
  },
  {
    "text": "it's not our responsibility to track the offset kafka tracks the offset for you so as a",
    "start": "1712000",
    "end": "1718559"
  },
  {
    "text": "consumer you read the messages and say yeah i've processed those messages kafka stores the offset for each",
    "start": "1718559",
    "end": "1724240"
  },
  {
    "text": "consumer so when our consumer reconnects kafka says okay this is where you got to be last time",
    "start": "1724240",
    "end": "1729440"
  },
  {
    "text": "and off you go and as a consuming application you can optionally say never mind that i would actually like to",
    "start": "1729440",
    "end": "1735600"
  },
  {
    "text": "start from this point here that kafka tracks those assets for you it's a really important point to me",
    "start": "1735600",
    "end": "1742080"
  },
  {
    "text": "we've got the producer we're sending nonsense over to a topic we're reading nonsense from that topic it's just key",
    "start": "1742080",
    "end": "1747440"
  },
  {
    "text": "value bytes remember so i could send some json over here so you can say like here's this message",
    "start": "1747440",
    "end": "1752559"
  },
  {
    "text": "i'm gonna type in some json it's like the most simple um json message in the world so we send",
    "start": "1752559",
    "end": "1758320"
  },
  {
    "text": "that over you can see you've got the value picked up down here over on the right hand side you've got the key value but we're just sending",
    "start": "1758320",
    "end": "1764399"
  },
  {
    "text": "bytes to the kafka topic because actually we need to think about serialization we're going to talk about that",
    "start": "1764399",
    "end": "1769520"
  },
  {
    "text": "in just a moment what i'm going to talk about next though is now that we've got this concept of a",
    "start": "1769520",
    "end": "1775440"
  },
  {
    "text": "producer and consumer why are you going to unbeld with us and what are the things that we're not going to build with it",
    "start": "1775440",
    "end": "1781279"
  },
  {
    "text": "so let's head back to the slides so i can see a few questions coming in and that's brilliant if i get chance at the end i will take",
    "start": "1781279",
    "end": "1787919"
  },
  {
    "text": "the questions from here um if you want to i would suggest copy and paste them into the slack channel",
    "start": "1787919",
    "end": "1793200"
  },
  {
    "text": "because then i can answer asynchronously as all good systems should and i can actually go through those and make sure i get to them um as i say if",
    "start": "1793200",
    "end": "1799760"
  },
  {
    "text": "we get time i'll do them on webex as well but feel free to put them onto the slack um i'm off on the slack if you want to",
    "start": "1799760",
    "end": "1805840"
  },
  {
    "text": "attack me about track 7 room as well um so we can do them there so",
    "start": "1805840",
    "end": "1810960"
  },
  {
    "text": "that was a brief demo as i say the code is online i'll share the link afterwards produce data consume data",
    "start": "1810960",
    "end": "1816960"
  },
  {
    "text": "consume data multiple times consume data reconsume data that's what kafka lets you do and it's",
    "start": "1816960",
    "end": "1823679"
  },
  {
    "text": "all pretty good it's a very very powerful it's very scalable system but we've only just really got started",
    "start": "1823679",
    "end": "1830480"
  },
  {
    "start": "1830000",
    "end": "1963000"
  },
  {
    "text": "or put it another way i've not even finished yet because the data that we're getting in and the data",
    "start": "1830480",
    "end": "1835679"
  },
  {
    "text": "that we're getting out you start to see the same kind of patterns that people adopt and want to do with us",
    "start": "1835679",
    "end": "1841520"
  },
  {
    "text": "because they say i've got a kafka i've heard this kafka thing is good i'm going to kafka all the things and now that i've got this kafka i would",
    "start": "1841520",
    "end": "1847279"
  },
  {
    "text": "like to have lots of things i would like to get some data from my database into kafka because i want to drive an application",
    "start": "1847279",
    "end": "1853600"
  },
  {
    "text": "with it or i've got data in my kafka and i would like to push that down somewhere else i'd like to send it to s3",
    "start": "1853600",
    "end": "1859440"
  },
  {
    "text": "i'd like to say ha kafka stores my data for me as well as sending it to s3 i'd also like to send it",
    "start": "1859440",
    "end": "1864720"
  },
  {
    "text": "to hdfs or to any number of other places also one says well you know that kind of",
    "start": "1864720",
    "end": "1870000"
  },
  {
    "text": "like big ball hairy monolith that we've got that's underpinned by a database we need to replace that it's",
    "start": "1870000",
    "end": "1875440"
  },
  {
    "text": "kind of like kind of sucks and it's like it's old or it was written by someone else we didn't change it because it's all like this messy thing",
    "start": "1875440",
    "end": "1881360"
  },
  {
    "text": "we'd like to move or we'd like to evolve so much more flexible architecture we're going to go to the microservices route",
    "start": "1881360",
    "end": "1886720"
  },
  {
    "text": "and we would like to take what's happening in that existing application and use it to drive our new application",
    "start": "1886720",
    "end": "1893440"
  },
  {
    "text": "we're not going to go big bang because we know how those kind of projects usually end up would simply like to say when",
    "start": "1893440",
    "end": "1898799"
  },
  {
    "text": "stuff happens in our existing application we would like to use those events to",
    "start": "1898799",
    "end": "1904399"
  },
  {
    "text": "drive our new one and if you think about events and what they are events actually live in databases as well",
    "start": "1904399",
    "end": "1910960"
  },
  {
    "text": "so we've got our existing monolith and it's using a database so it's an e-commerce system every time someone creates an order or updates a customer",
    "start": "1910960",
    "end": "1917200"
  },
  {
    "text": "does something it writes it to the database and in the database we've got order tables and customer table all this kind of stuff",
    "start": "1917200",
    "end": "1923519"
  },
  {
    "text": "but the database itself is built on a append only distributed um this app end only commit log it's",
    "start": "1923519",
    "end": "1930880"
  },
  {
    "text": "distributed maybe but we can take those events that happen in the database and we can capture them",
    "start": "1930880",
    "end": "1936159"
  },
  {
    "text": "and we can stream them into kafka and because we can stream them into kafka we can build new applications driven by events in",
    "start": "1936159",
    "end": "1943039"
  },
  {
    "text": "kafka populated by stuff happening in the database and now we can start to chip away at what's happening in our existing",
    "start": "1943039",
    "end": "1948640"
  },
  {
    "text": "application we say well when this new order gets created we're gonna uh run some order processing",
    "start": "1948640",
    "end": "1954720"
  },
  {
    "text": "like a fraud detection thing or something over in our new application driven by those events from the source one so to",
    "start": "1954720",
    "end": "1961039"
  },
  {
    "text": "migrate over time bits and pieces of functionality whilst the existing one is still running",
    "start": "1961039",
    "end": "1966159"
  },
  {
    "start": "1963000",
    "end": "2200000"
  },
  {
    "text": "but whatever it's for building whether we're starting to migrate things whether building pipelines from like databases to s3 or whatever",
    "start": "1966159",
    "end": "1972799"
  },
  {
    "text": "we're going to have to get data between these systems we're gonna have to get data from the database into kafka",
    "start": "1972799",
    "end": "1978080"
  },
  {
    "text": "from kafka to s3 and people will probably say well we've got a producer api we've got a consumer api i shall write",
    "start": "1978080",
    "end": "1984720"
  },
  {
    "text": "myself a program and i'll go to the database and i'll pull the database and i'll kind of pull those messages in",
    "start": "1984720",
    "end": "1990240"
  },
  {
    "text": "and then i realize i can't keep up with a single um instance doing it so i'll have to scale out i'll have to work out how i distribute",
    "start": "1990240",
    "end": "1996480"
  },
  {
    "text": "that workload across having scaled it out and i've solved that and now i need to make sure if one of them dies another one can pick up because it's tracked",
    "start": "1996480",
    "end": "2002480"
  },
  {
    "text": "where it's got to and track the offsets and then we also want to use the same thing to be able to pull in data from other",
    "start": "2002480",
    "end": "2007600"
  },
  {
    "text": "sources like message queues or flat files and we also want to push data down to target systems so why don't we make this",
    "start": "2007600",
    "end": "2013440"
  },
  {
    "text": "thing kind of like modular and we can like we can make a framework we can save the business like we're going to solve all your problems we're going to build",
    "start": "2013440",
    "end": "2019039"
  },
  {
    "text": "a framework and this sounds like a lot of fun to do but it's a trap because building",
    "start": "2019039",
    "end": "2025120"
  },
  {
    "text": "frameworks is a whole bunch of fun but it doesn't differentiate our business from any other just because we've learned how to write data from",
    "start": "2025120",
    "end": "2031039"
  },
  {
    "text": "cathode to s3 that's what everyone's doing that's us being able to do that doesn't bring us",
    "start": "2031039",
    "end": "2036080"
  },
  {
    "text": "forward beyond the competition and also sorry to say it's a lot of fun to build these frameworks",
    "start": "2036080",
    "end": "2041840"
  },
  {
    "text": "but the fun has been had for you apache kafka includes its own framework for integrating other systems",
    "start": "2041840",
    "end": "2048320"
  },
  {
    "text": "into kafka and it's called kafka connect so kafka connect is the integration api",
    "start": "2048320",
    "end": "2053520"
  },
  {
    "text": "if you like for apache castle and it lets you stream data from systems into kafka",
    "start": "2053520",
    "end": "2058720"
  },
  {
    "text": "from kafka down to other systems and it means that you can do all of this integration",
    "start": "2058720",
    "end": "2063919"
  },
  {
    "text": "and you can do all of this integration from databases and message queues and flat files down to data stores and sql",
    "start": "2063919",
    "end": "2069358"
  },
  {
    "text": "and cloud object stores and wherever you want to get and put your data as a either just like flowing through",
    "start": "2069359",
    "end": "2074960"
  },
  {
    "text": "kafka as a pipeline or driving applications in kafka or taking the results of applications produced into kafka",
    "start": "2074960",
    "end": "2080878"
  },
  {
    "text": "down to other places for analytics you can do all of this and it's driven by configuration you",
    "start": "2080879",
    "end": "2087280"
  },
  {
    "text": "simply say here's my json it declares where about my data from where i'd like to put my data which topics and so on",
    "start": "2087280",
    "end": "2093599"
  },
  {
    "text": "and off we go and kafka connect is pluggable so you can say i've got my connectors",
    "start": "2093599",
    "end": "2099200"
  },
  {
    "text": "which talk to particular technologies i've got my converters which handle serialization which i promise we're just",
    "start": "2099200",
    "end": "2104320"
  },
  {
    "text": "about to get onto you can even do transformation work on the messages as they pass through this pipeline",
    "start": "2104320",
    "end": "2109920"
  },
  {
    "text": "you can say i'm going to ingest from the database but i'd like to drop out these particular fields before we even send them to kafka i've",
    "start": "2109920",
    "end": "2116079"
  },
  {
    "text": "got these fields here i'd like to change their data types i'd like to change the schema you can do this as it passes into kafka",
    "start": "2116079",
    "end": "2121359"
  },
  {
    "text": "or for a sync connector as you take it from kafka and write it down stream you can go to confluence hub to download",
    "start": "2121359",
    "end": "2128240"
  },
  {
    "text": "all of these different connectors and converters just search for your particular technology and do a command line install",
    "start": "2128240",
    "end": "2133839"
  },
  {
    "text": "or click on it to do the installation and off you go to run kafka connect it's just a jvm",
    "start": "2133839",
    "end": "2140240"
  },
  {
    "text": "process it doesn't run on your brokers so on your broker machine that's like where your broker runs and you'll have",
    "start": "2140240",
    "end": "2145520"
  },
  {
    "text": "separate broker machines kafka connect runs separately unless you like prototyping in which case it all",
    "start": "2145520",
    "end": "2150960"
  },
  {
    "text": "runs on your laptop anyway but for an idea of how you deploy it kafka connect",
    "start": "2150960",
    "end": "2156000"
  },
  {
    "text": "runs separately it's a jvm process within which the different connector tasks run and you can scale it out so kafka",
    "start": "2156000",
    "end": "2163040"
  },
  {
    "text": "connects under the covers it's using producer consumer apis so it can also benefit from kafka's ability to scale and have",
    "start": "2163040",
    "end": "2170160"
  },
  {
    "text": "fault tolerance and reallocate work as it needs and if you lose a worker you scale this out it's",
    "start": "2170160",
    "end": "2175440"
  },
  {
    "text": "fault tolerance you can bring the work or have to connect or bring that work back into a place",
    "start": "2175440",
    "end": "2180640"
  },
  {
    "text": "where it can run if you lose a worker so kafka connects is this integration",
    "start": "2180640",
    "end": "2186160"
  },
  {
    "text": "api for apache kafka got a whole bunch of different connectors that you can plug into it",
    "start": "2186160",
    "end": "2192640"
  },
  {
    "text": "but we now need to think and finally address this point of serialization because i started off",
    "start": "2195119",
    "end": "2202079"
  },
  {
    "start": "2200000",
    "end": "2680000"
  },
  {
    "text": "this talk by saying well let's like wave our hands a little bit and just pretend that like events are key values okay like we'll",
    "start": "2202079",
    "end": "2208800"
  },
  {
    "text": "brush the rest of that detail into the carpet now is the time to pull back that carpet and i actually examine",
    "start": "2208800",
    "end": "2214000"
  },
  {
    "text": "what's going on here what is a key value message what are we actually doing with us well key value bites are what we sent to",
    "start": "2214000",
    "end": "2220880"
  },
  {
    "text": "kafka and as developers our software engineers as whatever our job title is today we need to work out",
    "start": "2220880",
    "end": "2226480"
  },
  {
    "text": "how we're going to serialize it if we're reading the data we need to know how we're going to deserialize it",
    "start": "2226480",
    "end": "2231599"
  },
  {
    "text": "and hopefully we don't just play any meaning between one of these different terms and pick the one that's got the sharpest",
    "start": "2231599",
    "end": "2237359"
  },
  {
    "text": "abbreviation because that'd be a terrible idea we need to understand what are our options for serialization",
    "start": "2237359",
    "end": "2243520"
  },
  {
    "text": "what are the implications of picking the different ones and this is where schemas come in because schemas",
    "start": "2243520",
    "end": "2250240"
  },
  {
    "text": "and serialization are very much intertwined take a step back for a moment",
    "start": "2250240",
    "end": "2255599"
  },
  {
    "text": "think about how services without kafka as dreadful as it sounds how services communicate when they're",
    "start": "2255599",
    "end": "2261599"
  },
  {
    "text": "synchronously coupled one service says i'm going to send this data to you and the other server says i'm expecting to receive",
    "start": "2261599",
    "end": "2267680"
  },
  {
    "text": "that data from you and i'm expecting to have these fields in it and these types in it and these values and so on and so schemers",
    "start": "2267680",
    "end": "2274079"
  },
  {
    "text": "have a sorry services have a contract between them and this contract is their api",
    "start": "2274079",
    "end": "2279760"
  },
  {
    "text": "and it says this is what i will send this is what you'll send this is what i'll send you this is what i'll expect to receive",
    "start": "2279760",
    "end": "2285599"
  },
  {
    "text": "and you don't have to do this synchronously without rest or jrpc or whatever you're going to use you could use an event",
    "start": "2285599",
    "end": "2292320"
  },
  {
    "text": "you could say actually we'll use kafka to kind of asynchronously couple our services together so instead of saying",
    "start": "2292320",
    "end": "2298720"
  },
  {
    "text": "i will send you this i'll wait for you to send me something back you say okay someone came to our website and",
    "start": "2298720",
    "end": "2304400"
  },
  {
    "text": "they created a profile or they updated their profile so i'll put that event onto a topic and",
    "start": "2304400",
    "end": "2309599"
  },
  {
    "text": "i'll put that onto the queue another service says well that's good i will read that we can start acting",
    "start": "2309599",
    "end": "2315119"
  },
  {
    "text": "asynchronously because they don't have to be tightly coupled together so we get a bunch of benefits from making that more",
    "start": "2315119",
    "end": "2320240"
  },
  {
    "text": "loosely coupled so we've got topics um as the way of transferring that data between them",
    "start": "2320240",
    "end": "2326000"
  },
  {
    "text": "so we've got websites and it's um insurance websites so someone updates their profile and the quote service",
    "start": "2326000",
    "end": "2331520"
  },
  {
    "text": "takes that update and it does some scoring it puts it back onto another topic for a profile service to receive but the",
    "start": "2331520",
    "end": "2338079"
  },
  {
    "text": "way that happens with kafka almost always is that you'll start off with",
    "start": "2338079",
    "end": "2343119"
  },
  {
    "text": "an initial use case and always start with the use case never start with it just because like it sounds cool when you heard about it at a conference",
    "start": "2343119",
    "end": "2349119"
  },
  {
    "text": "always start with a particular use case that's appropriate for us but people say well okay we're going to use asynchronous coupling between these",
    "start": "2349119",
    "end": "2355920"
  },
  {
    "text": "two services because it makes a lot of sense every time someone changes their profile we'll put that onto a topic",
    "start": "2355920",
    "end": "2361920"
  },
  {
    "text": "and then our quote service will subscribe to that topic and it will receive those updates but then someone else says oh you've got",
    "start": "2361920",
    "end": "2368320"
  },
  {
    "text": "a topic with information about customers every time they change their details that's really useful because you want to",
    "start": "2368320",
    "end": "2373520"
  },
  {
    "text": "take that information and we want to persist that down into our database we're going to use that topic as the system our record",
    "start": "2373520",
    "end": "2379920"
  },
  {
    "text": "and any changes we're going to reflect that in the database over here and we're going to take that and do some",
    "start": "2379920",
    "end": "2385280"
  },
  {
    "text": "stream processing on it over there and this is the beauty of kafka because the profile service is doing",
    "start": "2385280",
    "end": "2390800"
  },
  {
    "text": "absolutely nothing different it's just continuing to produce events onto a topic the quote service is doing",
    "start": "2390800",
    "end": "2396560"
  },
  {
    "text": "nothing different it's just continuing to read events off that topic it's just that other teams can take advantage of that",
    "start": "2396560",
    "end": "2402400"
  },
  {
    "text": "same data in a loosely coupled way to come and say well that data is useful we will also",
    "start": "2402400",
    "end": "2407520"
  },
  {
    "text": "use it but now what happens is that we've got this data that's being",
    "start": "2407520",
    "end": "2413040"
  },
  {
    "text": "interchanged between these services and at the moment we're saying like we've got a user id and it's an integer we've got an address and it's a voucher",
    "start": "2413040",
    "end": "2420000"
  },
  {
    "text": "what about some of the other fields what about time at which the profile change was made and start off with we use a",
    "start": "2420000",
    "end": "2426160"
  },
  {
    "text": "bigint and it holds the number of milliseconds since 1970 since the unix epoch and the team that came along said we're",
    "start": "2426160",
    "end": "2432319"
  },
  {
    "text": "going to put this into a database that's useful okay it looks like it's a number so we're going to model that into the database and the stream",
    "start": "2432319",
    "end": "2437440"
  },
  {
    "text": "processing team saying that's fine it's a begin so we're going to process that and that's fine and everything gets on",
    "start": "2437440",
    "end": "2443040"
  },
  {
    "text": "nicely but then the profile service and the quote service sit down together they say oh yeah instead of a big end",
    "start": "2443040",
    "end": "2450000"
  },
  {
    "text": "we're going to use a varchar which is probably a bad idea for timestamps but we're gonna do it anyway we're gonna change so the profile server",
    "start": "2450000",
    "end": "2456000"
  },
  {
    "text": "says okay that's fine i will now send across the timestamp as a bad chat and the quote service like they knew about this because they sat down",
    "start": "2456000",
    "end": "2461599"
  },
  {
    "text": "together okay we're gonna expect that and we're gonna move fast and we're definitely going to break things because now we're",
    "start": "2461599",
    "end": "2468800"
  },
  {
    "text": "sending across what was a big end as of archer so all of this lovely loose",
    "start": "2468800",
    "end": "2474640"
  },
  {
    "text": "coupling that we've done all this benefit that we've got of building around events now if we're not careful",
    "start": "2474640",
    "end": "2480160"
  },
  {
    "text": "we're going to undo all of that because if we're not careful we start using this as our message format",
    "start": "2480160",
    "end": "2485280"
  },
  {
    "text": "and someone says oh yeah serialization okay all this just like have separated like what's it really matter i don't understand the fuss",
    "start": "2485280",
    "end": "2491359"
  },
  {
    "text": "this is my warning understand that fuss it really really matters if we eyeball",
    "start": "2491359",
    "end": "2497599"
  },
  {
    "text": "this we can see there's an address there's probably social security we have no idea what the field names are",
    "start": "2497599",
    "end": "2503280"
  },
  {
    "text": "we have no idea what the separator is we can probably guess we have no idea what the data types are we can probably",
    "start": "2503280",
    "end": "2508640"
  },
  {
    "text": "guess and so instead of guessing at it we're going to do invariably what humans do which is going to phone up another human",
    "start": "2508640",
    "end": "2514000"
  },
  {
    "text": "or email them or slack them up and say what's this field what's this data type what are these things here",
    "start": "2514000",
    "end": "2519440"
  },
  {
    "text": "and by the way if you change any of this please tell me and because we're an organization and we're big and we're enterprise we'll",
    "start": "2519440",
    "end": "2525359"
  },
  {
    "text": "have a change review board and now instead of moving fast and breaking things we move really really slowly we probably still break things",
    "start": "2525359",
    "end": "2532000"
  },
  {
    "text": "and we tightly couple our systems back together wouldn't it be great if there was a different way of doing it",
    "start": "2532000",
    "end": "2538880"
  },
  {
    "text": "it turns out there is so instead of playing eenie meenie miney mo and saying well we've got to serialize the data kafka's just bites",
    "start": "2538880",
    "end": "2545440"
  },
  {
    "text": "and i will just like pick one of these we're going to pick one of these with a lot of conscious thoughts we're going to say there's some really",
    "start": "2545440",
    "end": "2551359"
  },
  {
    "text": "good ways to do it there are some mediocre ways and there's some fairly crappy ways also we're going to use a serialization",
    "start": "2551359",
    "end": "2557839"
  },
  {
    "text": "method that has got strong support for schemas that lets us enforce schema",
    "start": "2557839",
    "end": "2563119"
  },
  {
    "text": "compatibility guarantees that let's actually check when we write data is that going to break things",
    "start": "2563119",
    "end": "2569520"
  },
  {
    "text": "so we're going to say when the producer comes in it's going to serialize data and we're going to use afro we're going",
    "start": "2569520",
    "end": "2574640"
  },
  {
    "text": "to use protobuf we're going to use json schema the schema itself gets stored in confidence schema registry",
    "start": "2574640",
    "end": "2580400"
  },
  {
    "text": "the producer can enforce a compatibility check and make sure that what we're writing is compatible with that schema that",
    "start": "2580400",
    "end": "2586400"
  },
  {
    "text": "we've declared and it puts the data onto the topic the consumer comes along not only does it make short does it say well this is",
    "start": "2586400",
    "end": "2592720"
  },
  {
    "text": "great because now you're not sending the random things which is just going to break me because we've got compatibility guarantees",
    "start": "2592720",
    "end": "2598000"
  },
  {
    "text": "the consumer can go to the scheme and registry and say what's the schema instead of having to phone someone up",
    "start": "2598000",
    "end": "2603040"
  },
  {
    "text": "and that person's on holiday and we're not quite sure who else is managing it and so on and so on the consume consumer goes to the scheme",
    "start": "2603040",
    "end": "2608880"
  },
  {
    "text": "registry which is a computer who doesn't go on holiday and it says what's the schema for this particular message or for this",
    "start": "2608880",
    "end": "2614240"
  },
  {
    "text": "particular topic he says well here is the schema and the consumer laughs and sings with joy because this is brilliant",
    "start": "2614240",
    "end": "2619839"
  },
  {
    "text": "because the consumer can now go and do things and it can say well i'm a kafka connect consumer i'm going",
    "start": "2619839",
    "end": "2625359"
  },
  {
    "text": "to take that data i can now go and declare a database table because i have the schema and i can go and populate it",
    "start": "2625359",
    "end": "2630400"
  },
  {
    "text": "i don't have to go back to the people who produce the data the scheme registry itself stores its data",
    "start": "2630400",
    "end": "2636240"
  },
  {
    "text": "within kafka which is pretty cool also to use it you use the appropriate serializer",
    "start": "2636240",
    "end": "2642160"
  },
  {
    "text": "within your producer code so schemas and schema registry is so so",
    "start": "2642160",
    "end": "2647599"
  },
  {
    "text": "important catholic itself is a concept of like we can do all this scalable fantastic pub sub and it's persistent and that's great",
    "start": "2647599",
    "end": "2654560"
  },
  {
    "text": "it's very very powerful but there are too many examples where people have started at that and thought this is",
    "start": "2654560",
    "end": "2660000"
  },
  {
    "text": "great i get kafka now i'm done see you later guys and i'm off to go and build this and if you don't have the",
    "start": "2660000",
    "end": "2665920"
  },
  {
    "text": "other stuff around it like how let's have some good four thoughts about serialization about schemers you end up having to refactor an awful",
    "start": "2665920",
    "end": "2672319"
  },
  {
    "text": "lot six months down the line when you realize the pain that happens if you don't have strong support for",
    "start": "2672319",
    "end": "2677359"
  },
  {
    "text": "schemers and what you're doing i want to finish up with the last piece",
    "start": "2677359",
    "end": "2683119"
  },
  {
    "start": "2680000",
    "end": "2810000"
  },
  {
    "text": "of the puzzle within the ecosystem or the last big piece in the puzzle within the ecosystem because these applications that we're",
    "start": "2683119",
    "end": "2689839"
  },
  {
    "text": "building these consumers that are coming along and saying this is great we've got schemas we know how to deserialize the",
    "start": "2689839",
    "end": "2694880"
  },
  {
    "text": "data and we can read that data this is happy days what are we actually doing with those messages when we read them",
    "start": "2694880",
    "end": "2702160"
  },
  {
    "text": "we're probably doing a fairly common set of patterns that can be distilled down to a few specific",
    "start": "2702160",
    "end": "2707200"
  },
  {
    "text": "things i want to give you an example with a specific set of data instead of just talking abstract hand-wavy stuff",
    "start": "2707200",
    "end": "2713680"
  },
  {
    "text": "let's imagine we've got a factory and we've got robots on that production line and within those robots we've got lots",
    "start": "2713680",
    "end": "2719520"
  },
  {
    "text": "of lovely instrumentation and iot type stuff going on so every step of the way we're getting sensor readings with timestamps and all",
    "start": "2719520",
    "end": "2726319"
  },
  {
    "text": "these different sorts of values he's a perfect example of events on a topic and we're going to",
    "start": "2726319",
    "end": "2732000"
  },
  {
    "text": "read those events and we're going to do things with them but what are we going to do with them we're going to do a fairly limited set",
    "start": "2732000",
    "end": "2738079"
  },
  {
    "text": "of things we're going to do things like saying i want to read this and i want to filter it so read these things in if it matches",
    "start": "2738079",
    "end": "2744400"
  },
  {
    "text": "this condition go and put it somewhere else or go and do something i want to take these things in and i want to aggregate them i want to count",
    "start": "2744400",
    "end": "2750560"
  },
  {
    "text": "how many of these things happened within a particular time frame or i want to do so to aggregate it and i want to alert on it so count these",
    "start": "2750560",
    "end": "2757680"
  },
  {
    "text": "things and if it's over this amount or take an average and if it's all this amount go and do something else or i want to",
    "start": "2757680",
    "end": "2764240"
  },
  {
    "text": "take these things out to process them and push them downstream for analytics or whatever else",
    "start": "2764240",
    "end": "2770319"
  },
  {
    "text": "these are the kind of things that fit into a lot of applications that we build and they're a good example of stream",
    "start": "2770319",
    "end": "2775839"
  },
  {
    "text": "processing we've got a stream of events that's been built up over time these events arrive sequentially over time",
    "start": "2775839",
    "end": "2782079"
  },
  {
    "text": "and we want to filter it we're going to process it we're not aggregating we're going to do stuff to it we want to say okay we've got a stream",
    "start": "2782079",
    "end": "2788240"
  },
  {
    "text": "of widgets and widgets have got colors we would like to fill to that stream of widgets and we'd like to say i would",
    "start": "2788240",
    "end": "2793760"
  },
  {
    "text": "create a separate stream of widgets which are red any yellow widgets i'm going to ignore them the red widgets we're going to go",
    "start": "2793760",
    "end": "2799280"
  },
  {
    "text": "and put onto a separate topic to go on drive a special red widget microservice that's responsible just for doing something to",
    "start": "2799280",
    "end": "2805599"
  },
  {
    "text": "do with red widgets that's fine and we can do that and we can do that using stream processing",
    "start": "2805599",
    "end": "2810880"
  },
  {
    "start": "2810000",
    "end": "2883000"
  },
  {
    "text": "there's different ways to do this and within apache kafka you have a stream processing library",
    "start": "2810880",
    "end": "2816160"
  },
  {
    "text": "called kafka streams and kafka streams is a java api and you bring it into your java",
    "start": "2816160",
    "end": "2822319"
  },
  {
    "text": "application that you're writing and it lets you do stream processing unless you say take messages from here",
    "start": "2822319",
    "end": "2827520"
  },
  {
    "text": "filter it for that and go and put it over there and so it gives you this framework which means that you don't",
    "start": "2827520",
    "end": "2832640"
  },
  {
    "text": "have to go and build it you don't have to go and deploy a separate set of like stream processing things over there on",
    "start": "2832640",
    "end": "2838319"
  },
  {
    "text": "separate technologies so like feeding water in a separate different way and make calls out to them you can do",
    "start": "2838319",
    "end": "2844160"
  },
  {
    "text": "that stream processing within your application you write a java application it's responsible for",
    "start": "2844160",
    "end": "2849839"
  },
  {
    "text": "driving a dashboard or responsible for servicing user requests how many things of this thing have happened recently i'll take this thing",
    "start": "2849839",
    "end": "2857040"
  },
  {
    "text": "and draw this picture on the thing with an aggregate of that or a filter of that you can do that stream processing within",
    "start": "2857040",
    "end": "2863119"
  },
  {
    "text": "your application that you're building instead of having to call out to separate things so instead of just consumers",
    "start": "2863119",
    "end": "2868800"
  },
  {
    "text": "we end up with a set of stream applications and just as you deploy your applications in a certain way that's",
    "start": "2868800",
    "end": "2874079"
  },
  {
    "text": "specific and works for you you test and you deploy your streaming processing applications in exactly the same way it's just a java",
    "start": "2874079",
    "end": "2880640"
  },
  {
    "text": "library that you're bringing in but not everyone writes java there are plenty of people using other different",
    "start": "2880640",
    "end": "2886480"
  },
  {
    "start": "2883000",
    "end": "3016000"
  },
  {
    "text": "languages or who aren't really coders at all like me in which case you say well wouldn't it be nice if there was a different way to",
    "start": "2886480",
    "end": "2892640"
  },
  {
    "text": "do stream processing that you could express in a more abstract way using a decorative language like maybe like sql for example",
    "start": "2892640",
    "end": "2900160"
  },
  {
    "text": "this is where key sql db comes in so key sql db is built on top of kafka streams it's",
    "start": "2900160",
    "end": "2906079"
  },
  {
    "text": "part of confluent platform and it means that you can use sql to declare what you'd like to do",
    "start": "2906079",
    "end": "2911359"
  },
  {
    "text": "with your streams of data i've got a stream of widgets i would like to create a new stream a new kafka topic populated",
    "start": "2911359",
    "end": "2918319"
  },
  {
    "text": "by these widgets matching this particular predicate and that's a proper working example of some k-sql db",
    "start": "2918319",
    "end": "2924079"
  },
  {
    "text": "code there there's no boiler plate around it to deploy you take that and you send it to the server using the command line interface",
    "start": "2924079",
    "end": "2930240"
  },
  {
    "text": "using the rest api and it'll go off and it will run and it'll continually populate this new kafka topic",
    "start": "2930240",
    "end": "2935280"
  },
  {
    "text": "using the statement you've given us so if we apply this to the examples i showed you earlier",
    "start": "2935280",
    "end": "2941040"
  },
  {
    "text": "some of the patterns of what we want to do with data we can say well i would like to filter this particular stream i would like to",
    "start": "2941040",
    "end": "2947040"
  },
  {
    "text": "know about widgets that are fall over a certain weight category so we say we'll select everything from this stream",
    "start": "2947040",
    "end": "2952720"
  },
  {
    "text": "where the weight is over 120. so i'd like to do some counting i'd like to know how many widgets we've",
    "start": "2952720",
    "end": "2958480"
  },
  {
    "text": "processed by production line over time so that count from here i would like to take an average of this and we're going",
    "start": "2958480",
    "end": "2964960"
  },
  {
    "text": "to apply it alerts on it we're going to have having uh clause on there so you can do all of these things using key sql db",
    "start": "2964960",
    "end": "2971280"
  },
  {
    "text": "and using k sql db you can also take messages from a stream and push them down somewhere else using",
    "start": "2971280",
    "end": "2976960"
  },
  {
    "text": "kafka connect so you've got this stream of data coming in filter it and process it and join it if you want to",
    "start": "2976960",
    "end": "2982960"
  },
  {
    "text": "and then go and put it into s3 or into aztec search or hdfs or snowflake or any other of the numerous places that",
    "start": "2982960",
    "end": "2989440"
  },
  {
    "text": "kafka connect integrates with so these are examples using k sql db you can do the exact",
    "start": "2989440",
    "end": "2995520"
  },
  {
    "text": "uh conceptual thing using kafka streams but you have to write it using java which will totally",
    "start": "2995520",
    "end": "3000880"
  },
  {
    "text": "suit some people it won't suit others which is why you have the choice so i'm going to skip ahead a couple of",
    "start": "3000880",
    "end": "3007440"
  },
  {
    "text": "slides and i would like to show you an example of this in action and before",
    "start": "3007440",
    "end": "3012480"
  },
  {
    "text": "we wrap up so let's get through my appropriate demo slide and then we're going to have a look at",
    "start": "3012480",
    "end": "3018800"
  },
  {
    "start": "3016000",
    "end": "3425000"
  },
  {
    "text": "the demo so in this bit of the demo we're going to take some data again",
    "start": "3018800",
    "end": "3024960"
  },
  {
    "text": "i'm going to use kafka cat and this time using kafka cat to act as a consumer",
    "start": "3024960",
    "end": "3030319"
  },
  {
    "text": "against a different topic so this topic has got a much more sensible set of data in we've got um instead of just like random",
    "start": "3030319",
    "end": "3038160"
  },
  {
    "text": "asgf's hitting on the keyboard we've got a schema we've got users and we've got information about stock trades",
    "start": "3038160",
    "end": "3044000"
  },
  {
    "text": "so a buy or a cell and the particular symbol your account and so on very common set of data a very common",
    "start": "3044000",
    "end": "3049599"
  },
  {
    "text": "stream of data and now we want to do something with it we want to say i would like to take that and i would like to filter it for a",
    "start": "3049599",
    "end": "3055599"
  },
  {
    "text": "particular symbol and i would like to know how many transactions have been made for that particular symbol",
    "start": "3055599",
    "end": "3061119"
  },
  {
    "text": "in every 15-minute window so we're going to break it down like that so we look at this he said well i've got my stream of data i've got a consumer",
    "start": "3061119",
    "end": "3068000"
  },
  {
    "text": "i can pull in all those messages and now i guess i need to start writing some codes to kind of like work out how to do",
    "start": "3068000",
    "end": "3073359"
  },
  {
    "text": "that and we're talking about how many within a 15-minute window so i have to have some kind of persistent store to hold that state for",
    "start": "3073359",
    "end": "3079200"
  },
  {
    "text": "aggregation and what happens if my application crashes how do i rebuild that states and stuff this is where stream processing comes in",
    "start": "3079200",
    "end": "3085839"
  },
  {
    "text": "so i'm going to show you kc called db you can do the exact same thing in kafka streams if you want to",
    "start": "3085839",
    "end": "3091520"
  },
  {
    "text": "so let's cancel that and let's bring up the kc called db prompt so this is kc for db command line",
    "start": "3091520",
    "end": "3097119"
  },
  {
    "text": "interface there's also a rest api there's a graphical api as well sorry a graphical user interface if",
    "start": "3097119",
    "end": "3102640"
  },
  {
    "text": "you'd like rather the first thing we're going to do is we'll create a stream on top of this particular topic so",
    "start": "3102640",
    "end": "3109359"
  },
  {
    "text": "create stream against the kafka topic called trades the value for us is avro why are we",
    "start": "3109359",
    "end": "3114880"
  },
  {
    "text": "using avro why is that such a good thing because when we create a stream a stream is just after topic",
    "start": "3114880",
    "end": "3120640"
  },
  {
    "text": "with a schema where's our schema well our schema is here we say describe trades",
    "start": "3120640",
    "end": "3127599"
  },
  {
    "text": "says that is your schema where does schema come from the schema came from the schema registry this is a perfect example of our schemas",
    "start": "3127599",
    "end": "3134400"
  },
  {
    "text": "are so very useful because as a developer as a consumer i can now take data from that topic",
    "start": "3134400",
    "end": "3140319"
  },
  {
    "text": "i don't even know who was writing it i don't have to go and speak to it i can say i've got data on that topic i've been granted permission to read from it",
    "start": "3140319",
    "end": "3146559"
  },
  {
    "text": "i can deserialize it i have the schema i can now start being productive i've not had to go and speak to anyone and say well where's the wiki with this",
    "start": "3146559",
    "end": "3152720"
  },
  {
    "text": "reference on a blah blah blah blah i have the data i have the schema and because i have the schema i can now start to interrogate the data",
    "start": "3152720",
    "end": "3159760"
  },
  {
    "text": "i can project columns i can apply predicates select everything from this particular stream where this predicate is not",
    "start": "3159760",
    "end": "3166000"
  },
  {
    "text": "it says well here are those particular trades coming through for that particular symbol and i could take that i can say okay i'm",
    "start": "3166000",
    "end": "3172079"
  },
  {
    "text": "going to push that onto a new topic do this say create stream",
    "start": "3172079",
    "end": "3177839"
  },
  {
    "text": "for us this is okay i've created that stream and that's now populating it with the results of that select statements",
    "start": "3177839",
    "end": "3184800"
  },
  {
    "text": "and a stream is just a topic under the covers with a schema let's say show topics we've got a new kafka topic",
    "start": "3184800",
    "end": "3190800"
  },
  {
    "text": "called foo i could say print through so i'm just acting as a consumer here this is well here's your topic called",
    "start": "3190800",
    "end": "3196800"
  },
  {
    "text": "foo and within that topic called foo you've just got the values appropriate to that symbol that we asked for",
    "start": "3196800",
    "end": "3203440"
  },
  {
    "text": "but we also want to aggregate it we want to say show me the values for that just particular symbol",
    "start": "3203440",
    "end": "3209200"
  },
  {
    "text": "aggregated off over time how many trees have there been what was the average value and so on so now we say we're",
    "start": "3209200",
    "end": "3215520"
  },
  {
    "text": "going to create a table streams and tables in k sql db and kafka streams separate concepts i can explain",
    "start": "3215520",
    "end": "3220960"
  },
  {
    "text": "it another time or go and look at one of my other talks i'm going to say we're going to create uh this particular table it's going to",
    "start": "3220960",
    "end": "3226480"
  },
  {
    "text": "hold aggregates the side is whether it's a buy or sell how many trades what's the total value what was the average",
    "start": "3226480",
    "end": "3232800"
  },
  {
    "text": "broken down by a window of every 15 minutes a tumbling window when you have session windows and hopping windows as",
    "start": "3232800",
    "end": "3238319"
  },
  {
    "text": "well if you want to where the symbol is this group by the slide",
    "start": "3238319",
    "end": "3243760"
  },
  {
    "text": "we've done that now we can say go and tell me about this particular table so i describe that table it says here's your table here's the",
    "start": "3243760",
    "end": "3249920"
  },
  {
    "text": "schema for it if we say show topics we've now got a topic with that data",
    "start": "3249920",
    "end": "3255200"
  },
  {
    "text": "written and we can also take that data so let's actually just check the data out first",
    "start": "3255200",
    "end": "3261359"
  },
  {
    "text": "so we're going to say select start from this table and it says already did that so do that",
    "start": "3261359",
    "end": "3269040"
  },
  {
    "text": "so now it says for each time window and it's using the epoch time for the starting at the end here",
    "start": "3269040",
    "end": "3274079"
  },
  {
    "text": "here is the total number of trades here's the average quantity of the trade is the total value broken down by time win so we've",
    "start": "3274079",
    "end": "3280799"
  },
  {
    "text": "got an aggregate there stored within k sequel db if i had the rest api to hand i could actually do a",
    "start": "3280799",
    "end": "3286640"
  },
  {
    "text": "query against that a key value look up against for this particular symbol what's the current uh number of uh units",
    "start": "3286640",
    "end": "3294160"
  },
  {
    "text": "that have been sold just a key value lookup like that but i can also take that i can say i'm going to push that down",
    "start": "3294160",
    "end": "3300480"
  },
  {
    "text": "into somewhere like elasticsearch so here's where kafka connect comes in instead i'm going to write a bunch of",
    "start": "3300480",
    "end": "3305839"
  },
  {
    "text": "you saying here's a topic and i'll write some courage using the consumer api and elasticsearch api i'm going to push it down to there you'll see",
    "start": "3305839",
    "end": "3312160"
  },
  {
    "text": "i'm going to take that i'm going to push it down to here and i say sure connectors and make sure it's running it says",
    "start": "3312160",
    "end": "3318720"
  },
  {
    "text": "yep it's running so it means we can head over to now we use kibana here as the front end",
    "start": "3318720",
    "end": "3323760"
  },
  {
    "text": "onto elasticsearch we're going to say have we got any data in the indexes in the indices it says yes you have",
    "start": "3323760",
    "end": "3329359"
  },
  {
    "text": "so we're going to create an index pattern it says let's do that i'm going to take the data from this",
    "start": "3329359",
    "end": "3335359"
  },
  {
    "text": "particular index so if you're not familiar with elasticsearch it's like a document.json store uh very very useful you can use it for",
    "start": "3335359",
    "end": "3342160"
  },
  {
    "text": "analytics you can use it for search and cabana is a very nice front end that goes on top of it because then once we've declared that",
    "start": "3342160",
    "end": "3348400"
  },
  {
    "text": "data we can say well show me the data that you've got in that index",
    "start": "3348400",
    "end": "3354240"
  },
  {
    "text": "and if we close that we can say refresh it every second",
    "start": "3354240",
    "end": "3359760"
  },
  {
    "text": "surely data for the last hour",
    "start": "3359760",
    "end": "3363839"
  },
  {
    "text": "so now we can see for each time window so starting at 10 45 so this is this is british summit times",
    "start": "3365200",
    "end": "3370559"
  },
  {
    "text": "this is an hour uh that from odds lewis is now a forward of utc you can see each time window with the",
    "start": "3370559",
    "end": "3376319"
  },
  {
    "text": "appropriate aggregate in it and if you start closely at the screen for this one here the 1131 you'll see those values change it's",
    "start": "3376319",
    "end": "3382799"
  },
  {
    "text": "refreshing every second and the data is coming in case sequel db is taking that stream of data from kafka",
    "start": "3382799",
    "end": "3389119"
  },
  {
    "text": "it's applying that aggregation and pushing the results of the aggregation down to elasticsearch and it's doing so with a item potent key",
    "start": "3389119",
    "end": "3395680"
  },
  {
    "text": "so it just updates it in place it's a very very",
    "start": "3395680",
    "end": "3400720"
  },
  {
    "text": "quick simple example of what you can do using streams of data starting off with simple",
    "start": "3400720",
    "end": "3406000"
  },
  {
    "text": "key value bytes applying a schema to it taking it processing it filtering it aggregating",
    "start": "3406000",
    "end": "3411280"
  },
  {
    "text": "it you could do stateful uh lookups against key values you can push it down into other systems to use that data where you want to",
    "start": "3411280",
    "end": "3419280"
  },
  {
    "text": "so let me finish off um i want to quick recap and then i'll give you some resources as well to go and play with us",
    "start": "3419280",
    "end": "3425200"
  },
  {
    "start": "3425000",
    "end": "3600000"
  },
  {
    "text": "some more we'll do questions if time allows others we'll take it all over to slack so we started off with this humble",
    "start": "3425200",
    "end": "3431520"
  },
  {
    "text": "little event these things that happen all around us driving our businesses driving our systems we said well let's just for now call it",
    "start": "3431520",
    "end": "3437839"
  },
  {
    "text": "key value bytes because that's what things are at the heart we're going to store them in this log",
    "start": "3437839",
    "end": "3443040"
  },
  {
    "text": "it's an app end only distributed commit log we can't go back and change things within topic partitions they're strictly",
    "start": "3443040",
    "end": "3449359"
  },
  {
    "text": "ordered which is fantastic we're going to take this concept of the log and we're going to build around it",
    "start": "3449359",
    "end": "3454720"
  },
  {
    "text": "we're going to give people ways of getting data in and out with the produce from consumer apis we've got kafka connect part of apache",
    "start": "3454720",
    "end": "3461359"
  },
  {
    "text": "kafka we've got kafka streams part of apache kafka so we've got a full set of apis you're getting data in and",
    "start": "3461359",
    "end": "3467359"
  },
  {
    "text": "out for doing integration we're doing stream processing with a conference schema registry we've got",
    "start": "3467359",
    "end": "3472400"
  },
  {
    "text": "confluent kc sql db additional pieces of the ecosystem that let us build these powerful systems",
    "start": "3472400",
    "end": "3478720"
  },
  {
    "text": "all built around events which you can like everywhere and which is so very powerful",
    "start": "3478720",
    "end": "3485440"
  },
  {
    "text": "hopefully that's whetted you're interested in kafka if you didn't know it already hopefully that's solidified your",
    "start": "3486160",
    "end": "3491920"
  },
  {
    "text": "understanding of it already if you did know it if you want to know more about kafka you can go and get these books for free",
    "start": "3491920",
    "end": "3497359"
  },
  {
    "text": "off our website go to the url scan the qr code i love logs i heart logs is a great",
    "start": "3497359",
    "end": "3503440"
  },
  {
    "text": "foundational text for understanding this idea of a industry to commit work and why it's so powerful kafka definitive guide is a",
    "start": "3503440",
    "end": "3510160"
  },
  {
    "text": "great place to go and like really get into the wheats with kafka designing event driven systems again really good for understanding the",
    "start": "3510160",
    "end": "3515920"
  },
  {
    "text": "architectural concepts around us hopefully you want to go and try it out you can use the demo code that i'm going",
    "start": "3515920",
    "end": "3521920"
  },
  {
    "text": "to share afterwards you can also go and use confluent cloud so this is the only small little vendor pitch within this",
    "start": "3521920",
    "end": "3527920"
  },
  {
    "text": "confluent cloud managed kafka manage key sql db manage kafka connect and stuff like that you get 50 off your bill when you sign",
    "start": "3527920",
    "end": "3534720"
  },
  {
    "text": "up there's a code there you can also use for an additional 60 there's small print at the bottom",
    "start": "3534720",
    "end": "3539839"
  },
  {
    "text": "there scan the code go to the url again i'll post the links afterwards back to the useful stuff well sorry it's",
    "start": "3539839",
    "end": "3546160"
  },
  {
    "text": "all useful back to the non-pitchy stuff uh developer.confluent.io uh is a big",
    "start": "3546160",
    "end": "3552000"
  },
  {
    "text": "set of resources for learning kafka so there's blogs there's tutorials there's podcasts there's videos",
    "start": "3552000",
    "end": "3557359"
  },
  {
    "text": "the community hangs out on slack so confident community slack group go and join it there there's a ton of",
    "start": "3557359",
    "end": "3563359"
  },
  {
    "text": "different channels for all sorts of areas i've kafka and confident platform i'm at i'm off on there there's a ton of",
    "start": "3563359",
    "end": "3568400"
  },
  {
    "text": "people both confluent engineers a huge number of community extremely helpful and welcoming as well",
    "start": "3568400",
    "end": "3574480"
  },
  {
    "text": "so with that thank you very very much for your time and these online conferences turned out they're kind of pretty good",
    "start": "3574480",
    "end": "3580079"
  },
  {
    "text": "after all so i'm very grateful to andy so for inviting me to speak and i'll head out on that time now so i",
    "start": "3580079",
    "end": "3585520"
  },
  {
    "text": "won't eat into the next speaker's time but i will head over to slack now and we can chat to your heart's content all",
    "start": "3585520",
    "end": "3591200"
  },
  {
    "text": "about kafka if you want to hit me up on twitter instead on at i'm off i'll tweet links to the slides i'll put links to the",
    "start": "3591200",
    "end": "3596720"
  },
  {
    "text": "slides also in slack so thank you very much everyone for your time",
    "start": "3596720",
    "end": "3601680"
  }
]
[
  {
    "text": "okay can you guys hear me great and I'm",
    "start": "5029",
    "end": "11459"
  },
  {
    "text": "here today talk about a project that we've been doing for the last six months and it's",
    "start": "11459",
    "end": "17860"
  },
  {
    "text": "about how we automatically trying to categorize articles from an arcade Oh demo my name is Ivan horn stop I'm the",
    "start": "17860",
    "end": "26770"
  },
  {
    "text": "team lead of the recommendation team at NRK and my background is a Master of",
    "start": "26770",
    "end": "32470"
  },
  {
    "text": "Science very computer science which I I graduated at the Arctic University",
    "start": "32470",
    "end": "37900"
  },
  {
    "text": "interim serve and I've worked at an archive for the last five years and the",
    "start": "37900",
    "end": "44769"
  },
  {
    "text": "first slide in these type of presentations often used to present and present the company you're representing",
    "start": "44769",
    "end": "52110"
  },
  {
    "text": "but I guess most of you know NRK from earlier we are the norwegian",
    "start": "52110",
    "end": "58210"
  },
  {
    "text": "broadcasting corporation and we create a lot of content and are a lot of services that most people use every day actually",
    "start": "58210",
    "end": "65710"
  },
  {
    "text": "85 percent of the Norwegian population interact with NRK somehow every day I'm",
    "start": "65710",
    "end": "74680"
  },
  {
    "text": "working at the department called and marko may do trickling or NRK media development and we are responsible for",
    "start": "74680",
    "end": "81640"
  },
  {
    "text": "in our case internet services around 130 employees and right now we have around",
    "start": "81640",
    "end": "89830"
  },
  {
    "text": "40 consultants helping us building the internet services and these people span",
    "start": "89830",
    "end": "99340"
  },
  {
    "text": "from everything from back in front and test data scientists design team lives and so forth so everything you know from",
    "start": "99340",
    "end": "104800"
  },
  {
    "text": "a regular software development department we make four main products",
    "start": "104800",
    "end": "112300"
  },
  {
    "text": "what we're going to focus on today is an arcade NL which is the online newspaper",
    "start": "112300",
    "end": "117630"
  },
  {
    "text": "but we also make if the tunnel the weather app and some on-demand streaming",
    "start": "117630",
    "end": "124120"
  },
  {
    "text": "solutions like an arcade TV and an arc a radio and the mission of our departments",
    "start": "124120",
    "end": "131349"
  },
  {
    "text": "is to ensure that an arcade stays as relevant in the future as it is today and basically that means",
    "start": "131349",
    "end": "139360"
  },
  {
    "text": "like I said today we reached 85% of the population we wanted to stay that way",
    "start": "139360",
    "end": "145380"
  },
  {
    "text": "at this time when the media landscape is changing very much so what I'm going to",
    "start": "145380",
    "end": "152140"
  },
  {
    "text": "talk about today is how we can automatically categorize articles on NRK",
    "start": "152140",
    "end": "157390"
  },
  {
    "text": "dot and mu by topic and the reason there many reasons for doing this but one of",
    "start": "157390",
    "end": "163450"
  },
  {
    "text": "them as I said I'm from the recommendation team and categories but can be a good way to understand what",
    "start": "163450",
    "end": "172060"
  },
  {
    "text": "some content is about so we can help us do recommendations for instance like this where you can recommend one article",
    "start": "172060",
    "end": "179770"
  },
  {
    "text": "about music in the context of another article about music but categories can",
    "start": "179770",
    "end": "186310"
  },
  {
    "text": "also be used to build user profiles which in turn can be used to give personal recommendations so for instance",
    "start": "186310",
    "end": "193240"
  },
  {
    "text": "this gentleman here has read some articles or many articles about football and some about food recipes so the next",
    "start": "193240",
    "end": "199540"
  },
  {
    "text": "time he wishes visits the newspaper we can give him the freshest article about",
    "start": "199540",
    "end": "205300"
  },
  {
    "text": "those topics and when we started doing this many people asked me don't you",
    "start": "205300",
    "end": "211300"
  },
  {
    "text": "already have manually tagged categories isn't this something that online newspaper should have and we do have",
    "start": "211300",
    "end": "218230"
  },
  {
    "text": "that but they have some problems and I'm going to go through those problems to explain you why problem number one is",
    "start": "218230",
    "end": "226090"
  },
  {
    "text": "different purposes so one of them is the group articles by topics we have a",
    "start": "226090",
    "end": "235330"
  },
  {
    "text": "concept called article collections where we can collect different articles and one of those one",
    "start": "235330",
    "end": "240820"
  },
  {
    "text": "of the things we use that for is grouping articles by topic like this and this is pretty much the articles that",
    "start": "240820",
    "end": "246640"
  },
  {
    "text": "they're categorization that I want from a categorization to use for recommendations and we use for building",
    "start": "246640",
    "end": "255040"
  },
  {
    "text": "user profiles but we also do other stuff stuff with it we use article to collections to do auto publishing on",
    "start": "255040",
    "end": "262120"
  },
  {
    "text": "content pages so for instance on the Foreign Affair page Purex we want every",
    "start": "262120",
    "end": "269919"
  },
  {
    "text": "new new a news piece about Foreign Affairs to be published on this we call",
    "start": "269919",
    "end": "276430"
  },
  {
    "text": "it dinner for Sheila in the region so we add every Foreign Affair article",
    "start": "276430",
    "end": "282310"
  },
  {
    "text": "into Yorick's which is a lot we also use",
    "start": "282310",
    "end": "287710"
  },
  {
    "text": "it to group articles by news events so for instance when there was the bombing during Boston Marathon a journalist",
    "start": "287710",
    "end": "293470"
  },
  {
    "text": "created the article collection called boom bear in the muslim' Boston Marathon and added all new articles about that",
    "start": "293470",
    "end": "300370"
  },
  {
    "text": "into that collection another one is we group content for external purposes in",
    "start": "300370",
    "end": "307300"
  },
  {
    "text": "this case for there are still companies out there writing TV guides and they",
    "start": "307300",
    "end": "314050"
  },
  {
    "text": "need information about TV programs so this is a page just for them so they can read about the news TV shows on in this",
    "start": "314050",
    "end": "321720"
  },
  {
    "text": "in this case nrk1 and of course there's a lot of other weird stuff which have",
    "start": "321720",
    "end": "327640"
  },
  {
    "text": "made article collection about and there's one in the top right corner 1967",
    "start": "327640",
    "end": "334180"
  },
  {
    "text": "I'm not really sure what was the purpose of that one a lot of stupid stuff",
    "start": "334180",
    "end": "340360"
  },
  {
    "text": "actually I found out quote about this so if you build a feature for one purpose which is possible to eat abuse for other",
    "start": "340360",
    "end": "347500"
  },
  {
    "text": "purposes it will eventually be abused for other purposes problem number two",
    "start": "347500",
    "end": "355350"
  },
  {
    "text": "duplicate article collections about the same topic so this is actually a result",
    "start": "355350",
    "end": "362170"
  },
  {
    "text": "of having the article collections as free text fields you need to search it",
    "start": "362170",
    "end": "367240"
  },
  {
    "text": "up and the search feature is really bad so this is some examples of different article collections",
    "start": "367240",
    "end": "373090"
  },
  {
    "text": "it's about fishing so Piske Fisk in mark Fisk dumping Finnmark peacekeeper",
    "start": "373090",
    "end": "379150"
  },
  {
    "text": "warning Finnmark fiscal in airing I know this car break-in owner gave his crappy Finnmark of his grief in work this is",
    "start": "379150",
    "end": "386380"
  },
  {
    "text": "different this is all about the same topic basically but you have different collections for it and there's many more",
    "start": "386380",
    "end": "395490"
  },
  {
    "text": "so if your application contains a free text field and lacks good search you",
    "start": "395910",
    "end": "401230"
  },
  {
    "text": "will end up with duplicate data entries and of course there's a third problem",
    "start": "401230",
    "end": "406270"
  },
  {
    "text": "which is the different levels of abstractions which is a result of both",
    "start": "406270",
    "end": "411760"
  },
  {
    "text": "problem woman problem too so we have some like that for in the first one which is extremely wide that's 11,000",
    "start": "411760",
    "end": "418510"
  },
  {
    "text": "articles and we have other which is extremely narrow with less than ten",
    "start": "418510",
    "end": "423550"
  },
  {
    "text": "articles actually 1200 of our collections have only one article in its",
    "start": "423550",
    "end": "428800"
  },
  {
    "text": "and 4000 4500 have five or less they're pretty much useless for doing",
    "start": "428800",
    "end": "434920"
  },
  {
    "text": "recommendation and the last quote if your feature is abused and your",
    "start": "434920",
    "end": "440200"
  },
  {
    "text": "definitions contain duplicate is your data quality will be poor so basically the sum of all this problem is poor data",
    "start": "440200",
    "end": "447100"
  },
  {
    "text": "quality so our articles and collections as they are today are not fit for",
    "start": "447100",
    "end": "453180"
  },
  {
    "text": "recommendations or building user profiles but the computer can help it",
    "start": "453180",
    "end": "458230"
  },
  {
    "text": "can help us categorize articles so I'm",
    "start": "458230",
    "end": "463630"
  },
  {
    "text": "gonna go through a recipe and the recipe that we are using to cook up some categories but first I just wanted to",
    "start": "463630",
    "end": "471390"
  },
  {
    "text": "talk about some of the Google technologies we use so this is the first",
    "start": "471390",
    "end": "478450"
  },
  {
    "text": "one Google bigquery we're using Google bigquery this is Google equally bigquery",
    "start": "478450",
    "end": "484900"
  },
  {
    "text": "is actually the reason that we've so invested in the Google stack because we're using Google Analytics to collect",
    "start": "484900",
    "end": "491650"
  },
  {
    "text": "information and tracking users and Google Analytics have an export feature",
    "start": "491650",
    "end": "497350"
  },
  {
    "text": "to Google bigquery so you get a database with all your Google Analytics events",
    "start": "497350",
    "end": "503140"
  },
  {
    "text": "which is really easy to do queries on so after we started using that we started adding other they-they time to big",
    "start": "503140",
    "end": "509710"
  },
  {
    "text": "Google bigquery as well so that's why we also use cloud dataflow which is a stream and data which is a stream and",
    "start": "509710",
    "end": "518680"
  },
  {
    "text": "batch data processing we can just submit the job and data flow spread this across",
    "start": "518680",
    "end": "524650"
  },
  {
    "text": "many computers which does the computation and return a result we use",
    "start": "524650",
    "end": "529870"
  },
  {
    "text": "Google data proc with it which is which",
    "start": "529870",
    "end": "536380"
  },
  {
    "text": "is clustered or and cluster computing as a service you can just create a cluster",
    "start": "536380",
    "end": "541660"
  },
  {
    "text": "with apache spark or apache hadoop and installed submit a spark or Hadoop",
    "start": "541660",
    "end": "548610"
  },
  {
    "text": "job and shut the cluster down so you only pay for it when you're using it and",
    "start": "548610",
    "end": "555330"
  },
  {
    "text": "we use Google Cloud storage to store data and objects so this is my recipe",
    "start": "555330",
    "end": "561710"
  },
  {
    "text": "we're going to go through all of these in turn first one is to create a corpus",
    "start": "561710",
    "end": "568820"
  },
  {
    "text": "so corpus is basically terminology for a",
    "start": "568880",
    "end": "575610"
  },
  {
    "text": "collection of documents so the NR kml corpus is every article ever written on",
    "start": "575610",
    "end": "581910"
  },
  {
    "text": "NRK button oh and we want to use this as input because I forgot to tell you we",
    "start": "581910",
    "end": "590400"
  },
  {
    "text": "want to do some supervised learning we want to supervised learning to learn",
    "start": "590400",
    "end": "597180"
  },
  {
    "text": "what categories to learn what category belong to each article and for machine",
    "start": "597180",
    "end": "604440"
  },
  {
    "text": "learning you may almost always want your",
    "start": "604440",
    "end": "610440"
  },
  {
    "text": "observations or your your articles or whatever you're doing representing represented as a number so all the first",
    "start": "610440",
    "end": "617820"
  },
  {
    "text": "steps in this pipeline is about getting a mathematical representation of our",
    "start": "617820",
    "end": "622980"
  },
  {
    "text": "articles and the first step in doing that is actually to create a corpus which we will later be using to find",
    "start": "622980",
    "end": "629430"
  },
  {
    "text": "word embeddings but we'll get two dots first off we need to clean the corpus",
    "start": "629430",
    "end": "637400"
  },
  {
    "text": "that's because there's a lot of noise in every article there's HTML tags and numbers and special characters there's a",
    "start": "637400",
    "end": "644490"
  },
  {
    "text": "lot of words in each article that does not say anything about the topic it's about so if you have a topic if you have",
    "start": "644490",
    "end": "650850"
  },
  {
    "text": "an article about cross-country skiing it may have words like yeah I do we are there it's a small words which doesn't",
    "start": "650850",
    "end": "659310"
  },
  {
    "text": "carry much meaning so we just remove them we also do a very simple entity detection and this is basically to make",
    "start": "659310",
    "end": "666150"
  },
  {
    "text": "sure that when you read New York we want wanted to read as one token in the",
    "start": "666150",
    "end": "672810"
  },
  {
    "text": "corpus so this is actually pretty stupid because we just look at let",
    "start": "672810",
    "end": "678550"
  },
  {
    "text": "words with capital letters which follow each other and add underscore in between",
    "start": "678550",
    "end": "683830"
  },
  {
    "text": "but it's working because New York is one token and that way we can when you have",
    "start": "683830",
    "end": "690070"
  },
  {
    "text": "an bag and petalburg you want",
    "start": "690070",
    "end": "695399"
  },
  {
    "text": "yeah you can differentiate between them so this is an example of a text it's in",
    "start": "695399",
    "end": "702100"
  },
  {
    "text": "a region of course on the left you see the original text and on the right you",
    "start": "702100",
    "end": "708760"
  },
  {
    "text": "see after the cleaning and what's interesting it even though you've",
    "start": "708760",
    "end": "714130"
  },
  {
    "text": "removed a lot of words you can still get the gist of what this article is about",
    "start": "714130",
    "end": "719290"
  },
  {
    "text": "the meaning of the topic is still there it's just a cleaner representation of it",
    "start": "719290",
    "end": "726779"
  },
  {
    "text": "so this is how we built it you have every article already stored in bigquery",
    "start": "726779",
    "end": "732100"
  },
  {
    "text": "and we use data flow to read it to do the cleaning and we write a corpus file",
    "start": "732100",
    "end": "737800"
  },
  {
    "text": "which is basically a one big file with every article in it Clint",
    "start": "737800",
    "end": "743470"
  },
  {
    "text": "which is stored in cloud storage I don't know if you guys over here you can see the code it's good but I'll go through",
    "start": "743470",
    "end": "750640"
  },
  {
    "text": "it anyway so data flow is really simple to work with you can see I said that the",
    "start": "750640",
    "end": "756579"
  },
  {
    "text": "pipeline is just first read NRK and no articles that's just the name of the job",
    "start": "756579",
    "end": "762670"
  },
  {
    "text": "and then you can just add a query which is the inner call articles SQL it's just",
    "start": "762670",
    "end": "769270"
  },
  {
    "text": "the query as a string and then data flow actually in parallel streams every",
    "start": "769270",
    "end": "776589"
  },
  {
    "text": "article from bigquery into different nodes which do the computation in parallel and extract the corpus and then",
    "start": "776589",
    "end": "783399"
  },
  {
    "text": "we just write it as a result so this is the main method of that job okay so",
    "start": "783399",
    "end": "792699"
  },
  {
    "text": "we're on a quest to find a mathematical representation of an article when we",
    "start": "792699",
    "end": "797740"
  },
  {
    "text": "have a corpus we can use that to find word embeddings so we what we will do is",
    "start": "797740",
    "end": "805000"
  },
  {
    "text": "use the corpus as input to a word embedding algorithm so the algorithm",
    "start": "805000",
    "end": "811010"
  },
  {
    "text": "attempts to find patterns and correlations between words in the corpus that's we want what we want to find out",
    "start": "811010",
    "end": "817490"
  },
  {
    "text": "which it basically means it looks for what words are used close to each other in a sentence in a paragraph and in the",
    "start": "817490",
    "end": "824450"
  },
  {
    "text": "document and these algorithms are available for everyone to use they first originated from birtwick which was",
    "start": "824450",
    "end": "831530"
  },
  {
    "text": "created at Google and now people are now",
    "start": "831530",
    "end": "836690"
  },
  {
    "text": "the most advanced one is probably fast text which is word embedding algorithm",
    "start": "836690",
    "end": "841700"
  },
  {
    "text": "developed by Facebook which builds on word to way so how is this in this word",
    "start": "841700",
    "end": "848930"
  },
  {
    "text": "represented this is a pretty stupid examples in two dimensions but what it",
    "start": "848930",
    "end": "857030"
  },
  {
    "text": "shows how it works a word embeddings are vector representations of all words in",
    "start": "857030",
    "end": "862310"
  },
  {
    "text": "the corpus and it makes sure that similar words resides close close to each other in the way through space and",
    "start": "862310",
    "end": "868580"
  },
  {
    "text": "when I say similar words it's not similar because they are synonyms or mean the same thing that is because",
    "start": "868580",
    "end": "874940"
  },
  {
    "text": "they're used in the same type of context they've used close to each other in sentences so in this example politics",
    "start": "874940",
    "end": "881810"
  },
  {
    "text": "and government will lie close to each other like close to each other because they're often used in the same type of",
    "start": "881810",
    "end": "888200"
  },
  {
    "text": "article and football and Barcelona will recite another place in the vector space",
    "start": "888200",
    "end": "894520"
  },
  {
    "text": "and when you have vectors you can do math so if you can for instance use",
    "start": "894550",
    "end": "899840"
  },
  {
    "text": "cosine similarity to measure the similarity between words and in this",
    "start": "899840",
    "end": "905570"
  },
  {
    "text": "example you can see that politics and government the large number and if you find the cosine similarity between",
    "start": "905570",
    "end": "912130"
  },
  {
    "text": "politics and football it's a very small number because they're far apart but in",
    "start": "912130",
    "end": "920030"
  },
  {
    "text": "the real world the word embedding is high dimensional so when we illustrate",
    "start": "920030",
    "end": "925100"
  },
  {
    "text": "it we often use it in two or three dimensions but the embedding is usually",
    "start": "925100",
    "end": "931030"
  },
  {
    "text": "100 or more dimensions and 100 dimension is the standard parameter to fast text",
    "start": "931030",
    "end": "938150"
  },
  {
    "text": "so that's what we use but you can experiment with other dimensions to find better results but actually it's hard",
    "start": "938150",
    "end": "944970"
  },
  {
    "text": "to verify if the word embeddings are right you can just have to use your human intuition and look at the word",
    "start": "944970",
    "end": "951839"
  },
  {
    "text": "vectors and see which actually reside close to each other so here I try to",
    "start": "951839",
    "end": "957509"
  },
  {
    "text": "illustrate some words which are close to each other in the top left we have long politics then we have some cross-country",
    "start": "957509",
    "end": "964230"
  },
  {
    "text": "skiing some football and some words considering the ocean yeah and we build",
    "start": "964230",
    "end": "971910"
  },
  {
    "text": "it using pasta a fostex which is made by Facebook it's open-source and it actually offers",
    "start": "971910",
    "end": "980279"
  },
  {
    "text": "pre-trained models for over 150 languages and when we started out with",
    "start": "980279",
    "end": "985439"
  },
  {
    "text": "try to use the pre-trained Norwegian model but that did not work very well",
    "start": "985439",
    "end": "991589"
  },
  {
    "text": "with our inner Chi and the articles but it's really easy to run your own you just need a file with a lot of words in",
    "start": "991589",
    "end": "998579"
  },
  {
    "text": "it and then font fostex finds the correlation between words or clothes",
    "start": "998579",
    "end": "1005259"
  },
  {
    "text": "so this is how it fits into our pipeline we had the from the last one you so I've right wrote the corpus file to a cloud",
    "start": "1005949",
    "end": "1013100"
  },
  {
    "text": "storage I just read it from there into a process from running on beta proc and in",
    "start": "1013100",
    "end": "1020569"
  },
  {
    "text": "this case we're actually used not using Apache spark or apache hadoop in that",
    "start": "1020569",
    "end": "1025819"
  },
  {
    "text": "approach we're just using it to create a cluster just really strong machine one simple machine and so it's not really a",
    "start": "1025819",
    "end": "1032569"
  },
  {
    "text": "cluster but you can create start a really powerful machine really fast",
    "start": "1032569",
    "end": "1039230"
  },
  {
    "text": "and then we just run the fast text executable write the word embeddings to",
    "start": "1039230",
    "end": "1044959"
  },
  {
    "text": "cloud storage and shut it down and here you can see how you can start clusters",
    "start": "1044959",
    "end": "1051500"
  },
  {
    "text": "and submit jobs so we're starting a cluster submitting a job notice the jar",
    "start": "1051500",
    "end": "1057890"
  },
  {
    "text": "path which is actually just a jar file residing in Google Cloud storage so",
    "start": "1057890",
    "end": "1064820"
  },
  {
    "text": "that's how you you start a cluster on Google you refer a jar file on Google which is the job and then you delete the",
    "start": "1064820",
    "end": "1072320"
  },
  {
    "text": "cluster when you're done next up some clusters because we have we",
    "start": "1072320",
    "end": "1082010"
  },
  {
    "text": "have these word embeddings with all our words now we're trying to find some correlations between them and in this",
    "start": "1082010",
    "end": "1090650"
  },
  {
    "text": "simple example it's really simple to see the clusters made a circle around them",
    "start": "1090650",
    "end": "1096590"
  },
  {
    "text": "it's not that simple in 100 dimensions to see how the lists which are really formed but for this talk we'll do it in",
    "start": "1096590",
    "end": "1105050"
  },
  {
    "text": "two dimensions so they have a politics cluster I cross country skiing cluster a",
    "start": "1105050",
    "end": "1111310"
  },
  {
    "text": "football cluster ocean cluster some ml down to the left something about food",
    "start": "1111310",
    "end": "1116500"
  },
  {
    "text": "down write something about science and then there's some strange words down in",
    "start": "1116500",
    "end": "1121550"
  },
  {
    "text": "the middle and let's call them problematic words because even though we",
    "start": "1121550",
    "end": "1127070"
  },
  {
    "text": "remove a lot of stop words there's still a lot of words which are not considered",
    "start": "1127070",
    "end": "1132920"
  },
  {
    "text": "to stop words which don't carry a lot of meaning they're used across all types of",
    "start": "1132920",
    "end": "1139130"
  },
  {
    "text": "articles and often using word embedding",
    "start": "1139130",
    "end": "1144410"
  },
  {
    "text": "algorithms they are placed close together in the space because they're used in the same type of way in the real",
    "start": "1144410",
    "end": "1153380"
  },
  {
    "text": "system we have 400 clusters and I want you to take a look at some real clusters",
    "start": "1153380",
    "end": "1158930"
  },
  {
    "text": "that we got from running fast text and then doing clustering on it",
    "start": "1158930",
    "end": "1165250"
  },
  {
    "text": "can you read this okay great so this is",
    "start": "1170840",
    "end": "1177440"
  },
  {
    "text": "cluster number 316 and it's about",
    "start": "1177440",
    "end": "1182539"
  },
  {
    "text": "mountains so these are all words that have at one point been written in an",
    "start": "1182539",
    "end": "1190580"
  },
  {
    "text": "article on NRK data No so this cluster is basically about",
    "start": "1190580",
    "end": "1195740"
  },
  {
    "text": "mountains and hiking and going around in",
    "start": "1195740",
    "end": "1204169"
  },
  {
    "text": "the world but you can see that they are pretty similar they're about the same",
    "start": "1204169",
    "end": "1210409"
  },
  {
    "text": "thing let's move to the next one this is another example it's a football cluster",
    "start": "1210409",
    "end": "1218659"
  },
  {
    "text": "cluster number 310 so it's a lot of",
    "start": "1218659",
    "end": "1224149"
  },
  {
    "text": "players and some teams typically them",
    "start": "1224149",
    "end": "1233419"
  },
  {
    "text": "all oh yeah I'm a fan of drum circle and last one",
    "start": "1233419",
    "end": "1240789"
  },
  {
    "text": "about fishing",
    "start": "1240789",
    "end": "1244508"
  },
  {
    "text": "so this is often the best way to verify the clusters you have to look at them",
    "start": "1246740",
    "end": "1251750"
  },
  {
    "text": "and see if it makes sense in this case it does for these three clusters at least but from the same same one we had",
    "start": "1251750",
    "end": "1261880"
  },
  {
    "text": "this cluster 190 which does not make much sense and if you're observant you",
    "start": "1261880",
    "end": "1274610"
  },
  {
    "text": "will see that there's a lot of misspelled words there like this inch",
    "start": "1274610",
    "end": "1280010"
  },
  {
    "text": "budget and what happens here is that",
    "start": "1280010",
    "end": "1285200"
  },
  {
    "text": "this word this misspelling of budget it's not used in very many articles so",
    "start": "1285200",
    "end": "1291279"
  },
  {
    "text": "there's a threshold actually so it was used in five or less it won't be in the",
    "start": "1291279",
    "end": "1298370"
  },
  {
    "text": "word embedding so this word has at least",
    "start": "1298370",
    "end": "1303529"
  },
  {
    "text": "been written like this five times on NRK data no that's not enough to find the",
    "start": "1303529",
    "end": "1309860"
  },
  {
    "text": "correlation with this words and other business words so it's been being placed",
    "start": "1309860",
    "end": "1315080"
  },
  {
    "text": "in this strange cluster with a lot of other stuff that doesn't actually carry",
    "start": "1315080",
    "end": "1320450"
  },
  {
    "text": "much meaning if you look at them together it's not a very meaningful topic carrying cluster Oh",
    "start": "1320450",
    "end": "1327909"
  },
  {
    "text": "where did it go okay",
    "start": "1333070",
    "end": "1339730"
  },
  {
    "text": "and as you notice the cursors are not the sign name they just have a number and ID we looked at 316 and 310 but if",
    "start": "1339730",
    "end": "1346910"
  },
  {
    "text": "you look at them you can give them a name and we used",
    "start": "1346910",
    "end": "1352100"
  },
  {
    "text": "did this using Apache spark I'm a Lib which is a k-means clustering algorithm",
    "start": "1352100",
    "end": "1359020"
  },
  {
    "text": "is just a standard clustering algorithm but it's basically in every machine",
    "start": "1359020",
    "end": "1364730"
  },
  {
    "text": "learning library out there and just to say as always you read input from cloud",
    "start": "1364730",
    "end": "1372350"
  },
  {
    "text": "storage create a job this time in Google Cloud Data proc which turns the",
    "start": "1372350",
    "end": "1378290"
  },
  {
    "text": "algorithm and write the clustered emanations back to cloud storage okay next up this is this is the place where",
    "start": "1378290",
    "end": "1386000"
  },
  {
    "text": "we finally get the mathematical representation or of our articles so",
    "start": "1386000",
    "end": "1392420"
  },
  {
    "text": "given these articles I've written three very short articles different meaning",
    "start": "1392420",
    "end": "1399080"
  },
  {
    "text": "first one is neutral and klabo enjoy skiing and fruit second one fisherman prefers swimming fish and last",
    "start": "1399080",
    "end": "1405980"
  },
  {
    "text": "one science show that Salman is fish and we have these following clusters from",
    "start": "1405980",
    "end": "1412460"
  },
  {
    "text": "our example and then we can match the word in the article with our cluster so",
    "start": "1412460",
    "end": "1418910"
  },
  {
    "text": "we'll start with neutral and say yeah that's from the winter sports cluster and that's from that strange bad cluster",
    "start": "1418910",
    "end": "1427010"
  },
  {
    "text": "down right do the same for every word and fruits from the food cluster and get",
    "start": "1427010",
    "end": "1437060"
  },
  {
    "text": "something like this so what we've done is map of the world every word in our",
    "start": "1437060",
    "end": "1443240"
  },
  {
    "text": "article to the words in the clusters let me do the same for sentence two and",
    "start": "1443240",
    "end": "1450560"
  },
  {
    "text": "three so if you take a look at it you can actually do something like this",
    "start": "1450560",
    "end": "1455980"
  },
  {
    "text": "stack the words on top of each other and then we can do a little bit of mouth",
    "start": "1455980",
    "end": "1461750"
  },
  {
    "text": "and get this so this art is 43% about winter sports 14% about",
    "start": "1461750",
    "end": "1469300"
  },
  {
    "text": "food and 43% about something else and",
    "start": "1469300",
    "end": "1474340"
  },
  {
    "text": "that's a new vector and that's what we call the article embedding so this is a",
    "start": "1474340",
    "end": "1479740"
  },
  {
    "text": "mathematical representation of the article that contains information about what topic this article is about so we",
    "start": "1479740",
    "end": "1487930"
  },
  {
    "text": "can by just looking at the article we can see this is about winter sports and this and some about food and something",
    "start": "1487930",
    "end": "1496240"
  },
  {
    "text": "about something else and we could do the same for the other articles this is",
    "start": "1496240",
    "end": "1501430"
  },
  {
    "text": "about the ocean this is about the ocean and science and we get a lot of actors",
    "start": "1501430",
    "end": "1507810"
  },
  {
    "text": "that's great but we still had those problematic words",
    "start": "1507810",
    "end": "1514870"
  },
  {
    "text": "we want maybe want to clean that up and one way you can do that is take a look at just take the cluster and see",
    "start": "1514870",
    "end": "1522730"
  },
  {
    "text": "how much is this represented across a set of articles we know is about different topics so that's what we've",
    "start": "1522730",
    "end": "1529360"
  },
  {
    "text": "done here we've taken 50 articles about 50 different topics and seen how much",
    "start": "1529360",
    "end": "1536790"
  },
  {
    "text": "does this cluster spread out and this is one of those bad clusters with words that don't carry much meaning and you",
    "start": "1536790",
    "end": "1543640"
  },
  {
    "text": "see that it's even mostly even they spread out across the different articles",
    "start": "1543640",
    "end": "1549270"
  },
  {
    "text": "in comparison to this this is a Ultrabook article about fish or this is",
    "start": "1549270",
    "end": "1556810"
  },
  {
    "text": "a cluster about fish and you can see there's one article but that was really about fish where this stands out this is",
    "start": "1556810",
    "end": "1565420"
  },
  {
    "text": "a good one this is a bad one and then we can remove the bad ones we can just throw it in the trash let me get a even",
    "start": "1565420",
    "end": "1572740"
  },
  {
    "text": "better representation of the article so this is about this is about winter sports and food and this is only about",
    "start": "1572740",
    "end": "1579910"
  },
  {
    "text": "the ocean and this is about the ocean and science so you have better vectors",
    "start": "1579910",
    "end": "1586630"
  },
  {
    "text": "and now we can do math and we can compute the cosine similarity again and",
    "start": "1586630",
    "end": "1591760"
  },
  {
    "text": "see that the skiing one and the ocean one is not very much similar",
    "start": "1591760",
    "end": "1596930"
  },
  {
    "text": "two other one about the ocean and the bonneville side ocean science and ocean",
    "start": "1596930",
    "end": "1602290"
  },
  {
    "text": "has higher similarity so similar articles have large cosine similarity so",
    "start": "1602290",
    "end": "1611500"
  },
  {
    "text": "it could look something like this or different articles this is an example",
    "start": "1611500",
    "end": "1617240"
  },
  {
    "text": "about lists Eric maybe it's spread out",
    "start": "1617240",
    "end": "1622430"
  },
  {
    "text": "so good across the clusters like this and another article about this tag will look",
    "start": "1622430",
    "end": "1627800"
  },
  {
    "text": "something like this so it's pretty similar it's not the same but you can see some correlation between them that's",
    "start": "1627800",
    "end": "1634520"
  },
  {
    "text": "good you have successfully embedded the topics mathematically just to sum up",
    "start": "1634520",
    "end": "1642100"
  },
  {
    "text": "similar articles have similar topics and I have similar vectors similar articles are close in vector space and similar",
    "start": "1642100",
    "end": "1648590"
  },
  {
    "text": "articles have large cosine similarity so this is a bit more advanced but still",
    "start": "1648590",
    "end": "1655820"
  },
  {
    "text": "based on the same model you read some input do a job write some output to Google Cloud storage so this time we'll",
    "start": "1655820",
    "end": "1662270"
  },
  {
    "text": "read the word embeddings and the cluster definitions into that dataflow job read",
    "start": "1662270",
    "end": "1669830"
  },
  {
    "text": "the articles from bigquery and that's this computation I'll show you some code",
    "start": "1669830",
    "end": "1675070"
  },
  {
    "text": "first we select each article then we",
    "start": "1675070",
    "end": "1681440"
  },
  {
    "text": "just do a map over it so for each article we do this which basically find",
    "start": "1681440",
    "end": "1688430"
  },
  {
    "text": "the clusters and create a vector out of it so there's a lot of code missing here",
    "start": "1688430",
    "end": "1696350"
  },
  {
    "text": "of course but what we're doing is for each article we do the cleaning first like we did for the corpus because we",
    "start": "1696350",
    "end": "1703280"
  },
  {
    "text": "want to be able to match it against the word embeddings so we clean the article and then we do a mapping for each word",
    "start": "1703280",
    "end": "1711200"
  },
  {
    "text": "in the article and find out which cluster it belongs to and save it",
    "start": "1711200",
    "end": "1720160"
  },
  {
    "text": "and with this we're really close to a bit doing what we want to do create",
    "start": "1720160",
    "end": "1725980"
  },
  {
    "text": "categories so first to do some supervised learning we need to create a",
    "start": "1725980",
    "end": "1731080"
  },
  {
    "text": "dataset because if we know what categories we want and have examples of",
    "start": "1731080",
    "end": "1736539"
  },
  {
    "text": "articles in these categories we can use machine learning to train the computer to understand what categorize articles",
    "start": "1736539",
    "end": "1743650"
  },
  {
    "text": "each category and assign a category automatically so the first question we",
    "start": "1743650",
    "end": "1752650"
  },
  {
    "text": "need an answer to is what categories do we want so we made a list based on something that's called IPTC news",
    "start": "1752650",
    "end": "1759429"
  },
  {
    "text": "categories which is the standard categorization of topics and it's real",
    "start": "1759429",
    "end": "1765010"
  },
  {
    "text": "it really narrow it goes down to as you can see arts culture and art and",
    "start": "1765010",
    "end": "1771940"
  },
  {
    "text": "entertainment without the art exhibition which is about sculptures and we don't write that many articles on NRK that",
    "start": "1771940",
    "end": "1779380"
  },
  {
    "text": "they know about sculpture art exhibitions so we don't need that as a category so we just went through this",
    "start": "1779380",
    "end": "1785679"
  },
  {
    "text": "and selected the one we felt were most fitting for the content that we produce",
    "start": "1785679",
    "end": "1791940"
  },
  {
    "text": "but we also need some examples to match with these categories we wanted so here",
    "start": "1791940",
    "end": "1799510"
  },
  {
    "text": "we actually could start we could use the existing article collection we already have because some of them are useful as",
    "start": "1799510",
    "end": "1807460"
  },
  {
    "text": "I said a lot of them is not useful but some of them can still be used and are",
    "start": "1807460",
    "end": "1813070"
  },
  {
    "text": "some of them are of the type that we need so we just looked through this list and found the one that matched with the",
    "start": "1813070",
    "end": "1819760"
  },
  {
    "text": "one that we wanted a and for some of them like this you just merge them to",
    "start": "1819760",
    "end": "1826240"
  },
  {
    "text": "create the training dataset so all these article collections became got one label result from this was 57",
    "start": "1826240",
    "end": "1836799"
  },
  {
    "text": "categories so then we could do this took",
    "start": "1836799",
    "end": "1842950"
  },
  {
    "text": "our articles as article embeddings and add a label",
    "start": "1842950",
    "end": "1851309"
  },
  {
    "text": "because we know first for somebody goes we know what they are about already and",
    "start": "1851320",
    "end": "1857380"
  },
  {
    "text": "then we have a training dataset we can use for machine learning so the last",
    "start": "1857380",
    "end": "1864620"
  },
  {
    "text": "step is to run supervised - classic classification with article embeddings and i know there's a lot of other talks",
    "start": "1864620",
    "end": "1871190"
  },
  {
    "text": "here we should go into detail about how you do this part so I'm not going to talk very much about it but how it works",
    "start": "1871190",
    "end": "1879890"
  },
  {
    "text": "you had to have a label - training data set you added in to give it a supervisor",
    "start": "1879890",
    "end": "1885590"
  },
  {
    "text": "algorithm which creates a category model then the next time we get a publish a new article you can add that or send",
    "start": "1885590",
    "end": "1892640"
  },
  {
    "text": "that through the category model and get the predicted label and we built this",
    "start": "1892640",
    "end": "1898430"
  },
  {
    "text": "using R which provides among all other",
    "start": "1898430",
    "end": "1904100"
  },
  {
    "text": "possible algorithms out there multinomial logistic regression and a",
    "start": "1904100",
    "end": "1909980"
  },
  {
    "text": "big reason that we chose using logistic regression it's that is that it gives a probability for each label so for every",
    "start": "1909980",
    "end": "1918470"
  },
  {
    "text": "of those 57 categories we get the probability that the article we gave in",
    "start": "1918470",
    "end": "1923810"
  },
  {
    "text": "and belongs to this category and it sums up to one so for one article it perhaps",
    "start": "1923810",
    "end": "1930290"
  },
  {
    "text": "you will get 90 90 percent sure that this is winter-sports five percent or actually 90 percent sure",
    "start": "1930290",
    "end": "1937490"
  },
  {
    "text": "that this is cross-country skiing five percent sure that this is by at",
    "start": "1937490",
    "end": "1942980"
  },
  {
    "text": "home and four percent sure that this is by a term and one percent is divided among all other categories there are",
    "start": "1942980",
    "end": "1951770"
  },
  {
    "text": "some other algorithms that gives you probability as well like my base we try",
    "start": "1951770",
    "end": "1957590"
  },
  {
    "text": "that one as well a worse results but I guess the biggest",
    "start": "1957590",
    "end": "1962660"
  },
  {
    "text": "question you you're sitting with right now is why did you do it in R because",
    "start": "1962660",
    "end": "1968780"
  },
  {
    "text": "all other code I've shown you has been in Scala and the biggest reason for this is that our two data scientists are",
    "start": "1968780",
    "end": "1976270"
  },
  {
    "text": "working in our everyday all analysis is done in R and for this model",
    "start": "1976270",
    "end": "1983690"
  },
  {
    "text": "they were doing the fine-tuning they were doing working on the dataset",
    "start": "1983690",
    "end": "1988909"
  },
  {
    "text": "creating a battery trying to get better results so we did a lot of iterations in our and the result",
    "start": "1988909",
    "end": "1995809"
  },
  {
    "text": "of a logistic regression is actually just a list of coefficients it's just some numbers so it's really easy to",
    "start": "1995809",
    "end": "2000879"
  },
  {
    "text": "write them from a file and then read and write them to a file and read them in to",
    "start": "2000879",
    "end": "2006669"
  },
  {
    "text": "Scala where we have our API and use it directly so same as always read",
    "start": "2006669",
    "end": "2013960"
  },
  {
    "text": "something from cloud storage do the training in are put in our script and",
    "start": "2013960",
    "end": "2019809"
  },
  {
    "text": "write the storage to my right the resulting model to cloud storage and our",
    "start": "2019809",
    "end": "2025870"
  },
  {
    "text": "have libraries for reading directory from cloud storage and writing to cloud storage they have actually really good",
    "start": "2025870",
    "end": "2032250"
  },
  {
    "text": "Google support you can do bigquery bigquery queries and do alum analysis",
    "start": "2032250",
    "end": "2040120"
  },
  {
    "text": "straight into your database so it's working really fine so last steps we",
    "start": "2040120",
    "end": "2048790"
  },
  {
    "text": "have our model so now we have a job which is called the NRK data and article",
    "start": "2048790",
    "end": "2055148"
  },
  {
    "text": "classifier it's just a simple scholar application running on our internal",
    "start": "2055149",
    "end": "2060700"
  },
  {
    "text": "kubernetes cluster and when that job starts up it reads in the word embeddings the cluster definitions and",
    "start": "2060700",
    "end": "2068169"
  },
  {
    "text": "the logistic regression model and all all the time every day it just listens",
    "start": "2068169",
    "end": "2075550"
  },
  {
    "text": "on a queue for new for events about",
    "start": "2075550",
    "end": "2080919"
  },
  {
    "text": "articles being published so when a new article is published it is published",
    "start": "2080919",
    "end": "2086128"
  },
  {
    "text": "message goes to this queue which is read by the classifier which actually reads",
    "start": "2086129",
    "end": "2092440"
  },
  {
    "text": "the article from the NRK demo API and",
    "start": "2092440",
    "end": "2097510"
  },
  {
    "text": "then it does everything we talked about it does the cleaning finds the word embeddings in the cluster definitions",
    "start": "2097510",
    "end": "2104550"
  },
  {
    "text": "runs this through creates the article embedding sends the article embedding",
    "start": "2104550",
    "end": "2110079"
  },
  {
    "text": "through the longest logistic regression model and gets the prediction back and then we",
    "start": "2110079",
    "end": "2115180"
  },
  {
    "text": "write those predictions to an elastic cluster we have which is accessible by the recommendation API so",
    "start": "2115180",
    "end": "2124300"
  },
  {
    "text": "most of the steps until this point is stuff we don't run very often that's",
    "start": "2124300",
    "end": "2130720"
  },
  {
    "text": "like a one-time job you run step one two or three that's when we want to recalculate but this is what's running",
    "start": "2130720",
    "end": "2136870"
  },
  {
    "text": "all the time every day and the last",
    "start": "2136870",
    "end": "2144070"
  },
  {
    "text": "slide with Scala code you can see we start by running the cleaner it's called a corpus parser",
    "start": "2144070",
    "end": "2150160"
  },
  {
    "text": "it cleans actually the text that goes into this is the title and lead and the",
    "start": "2150160",
    "end": "2156280"
  },
  {
    "text": "body of the article we find the clusters",
    "start": "2156280",
    "end": "2161370"
  },
  {
    "text": "and creates the article embedding which is sent into the logistic regression model to predict probabilities we create",
    "start": "2161370",
    "end": "2170290"
  },
  {
    "text": "an article which is inserted into elastic and that's it the articles are",
    "start": "2170290",
    "end": "2176950"
  },
  {
    "text": "served so just to sum up we use a lot of Google technologies we use some use fast",
    "start": "2176950",
    "end": "2185530"
  },
  {
    "text": "text from Facebook we use Apache spark to do the k-means clustering we use R to",
    "start": "2185530",
    "end": "2191110"
  },
  {
    "text": "do the logistic regression and finally we use Cuban it is an elastic to serve",
    "start": "2191110",
    "end": "2196300"
  },
  {
    "text": "it a lot of technologies involved to do something seemingly simple so then",
    "start": "2196300",
    "end": "2204910"
  },
  {
    "text": "what's next well we're still not in production it's getting really close",
    "start": "2204910",
    "end": "2211450"
  },
  {
    "text": "we're still not there but with this automatic categorization we finally have",
    "start": "2211450",
    "end": "2216790"
  },
  {
    "text": "a uniform uniform article uniform article categories on the same level of",
    "start": "2216790",
    "end": "2223990"
  },
  {
    "text": "abstraction and now it's impossible to create duplicate definitions it will",
    "start": "2223990",
    "end": "2230260"
  },
  {
    "text": "save some time for the journalist and the article collections which are still in use today have one less purpose to",
    "start": "2230260",
    "end": "2237460"
  },
  {
    "text": "serve which is good and of course the end goal of all this is to be able to",
    "start": "2237460",
    "end": "2244390"
  },
  {
    "text": "build great user profiles which can be used to give personal recommendations when you're using",
    "start": "2244390",
    "end": "2250480"
  },
  {
    "text": "our services so that this guy can get sported articles and also TV programs",
    "start": "2250480",
    "end": "2258250"
  },
  {
    "text": "about winter sports and recipes and this old lady can get her content about art",
    "start": "2258250",
    "end": "2263980"
  },
  {
    "text": "and aviation and weather and that's it's",
    "start": "2263980",
    "end": "2269020"
  },
  {
    "text": "if you have any questions I'll be happy to answer you and you can of course come",
    "start": "2269020",
    "end": "2282040"
  },
  {
    "text": "and talk to me after the talk Thanks",
    "start": "2282040",
    "end": "2286230"
  }
]
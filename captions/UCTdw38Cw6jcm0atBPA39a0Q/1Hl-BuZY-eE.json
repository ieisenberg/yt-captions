[
  {
    "start": "0",
    "end": "75000"
  },
  {
    "text": "well I guess we might as well kick off and sat hi I'm Scott Holden and welcome",
    "start": "5670",
    "end": "11530"
  },
  {
    "text": "to what's that fruit now I was gonna do a really really serious technical deep",
    "start": "11530",
    "end": "17380"
  },
  {
    "text": "dive talk but where's the fun in that so I thought let's have a little bit of fun",
    "start": "17380",
    "end": "22599"
  },
  {
    "text": "to start off with and let's play a plastic class a game of what's that",
    "start": "22599",
    "end": "28660"
  },
  {
    "text": "fruit come on audience participation does anyone know yell it out Apple too",
    "start": "28660",
    "end": "35590"
  },
  {
    "text": "easy alright let's try a little bit of a harder one what's that fruit amazing work ah this",
    "start": "35590",
    "end": "44830"
  },
  {
    "text": "is brilliant now as with any sort of series you start with the original characters and then it gets extended so",
    "start": "44830",
    "end": "51250"
  },
  {
    "text": "in this case it's what's that fruit or veg I love the thought that bacon is a",
    "start": "51250",
    "end": "61060"
  },
  {
    "text": "vegetable but no no pickle getting closer carrot it's carrot now everyone",
    "start": "61060",
    "end": "68080"
  },
  {
    "text": "that answered correctly come up afterwards I've actually got the actual fruits here as prizes for you",
    "start": "68080",
    "end": "73829"
  },
  {
    "text": "so what's that fruit it's a little bit of an interesting concept",
    "start": "73829",
    "end": "79450"
  },
  {
    "start": "75000",
    "end": "93000"
  },
  {
    "text": "we were pretty easily being we were able to identify those fruit quite easily just from the shadows but what does it",
    "start": "79450",
    "end": "86560"
  },
  {
    "text": "mean for a computer to recognize those individual pieces I'd like to start off",
    "start": "86560",
    "end": "92829"
  },
  {
    "text": "with a little bit about Who I am so I'm a technical specialist at Microsoft focusing in Azure application",
    "start": "92829",
    "end": "99130"
  },
  {
    "start": "93000",
    "end": "120000"
  },
  {
    "text": "development Twitter github my personal life story was up then dev now DevOps",
    "start": "99130",
    "end": "107079"
  },
  {
    "text": "focused with a love for sec DevOps and he'd be perfectly honest if it was up to me to be sector of SEC OPSEC because",
    "start": "107079",
    "end": "114159"
  },
  {
    "text": "there's not enough security in the world it's need to think about it at all steps a little bit of a disclaimer before we",
    "start": "114159",
    "end": "121450"
  },
  {
    "start": "120000",
    "end": "181000"
  },
  {
    "text": "actually drill deep into things I'm a developer at heart so this is gonna be a very developer centric session we're not",
    "start": "121450",
    "end": "129429"
  },
  {
    "text": "going to look at hardcore machine learning we're going to look at instead how do we take traditional developer",
    "start": "129429",
    "end": "135220"
  },
  {
    "text": "practices and use services instead of becoming data sign and on that point I'm not a data",
    "start": "135220",
    "end": "141069"
  },
  {
    "text": "scientist I love learning about machine learning deep learning all this fun stuff but I don't spend my days",
    "start": "141069",
    "end": "148450"
  },
  {
    "text": "crunching numbers the opinions are that of my own not of that employ that apply employer have to say it",
    "start": "148450",
    "end": "155129"
  },
  {
    "text": "this talk is labeled what's that fruit but we will be covering both fruit and vegetables so we've already got scope",
    "start": "155129",
    "end": "161560"
  },
  {
    "text": "creep there I was gonna title it what's that vegetable but not as catchy and",
    "start": "161560",
    "end": "167799"
  },
  {
    "text": "what's that organic matter just doesn't have the same appeal to it some fruit",
    "start": "167799",
    "end": "174099"
  },
  {
    "text": "was bruised during the making of this presentation and I do apologize for that but we'll continue on anyways I want to",
    "start": "174099",
    "end": "181720"
  },
  {
    "start": "181000",
    "end": "230000"
  },
  {
    "text": "actually start off with a little bit of a story about how this talk came to be and how the proof of concept that it",
    "start": "181720",
    "end": "188709"
  },
  {
    "text": "kind of underpins actually originated so I was walking down the street on the way",
    "start": "188709",
    "end": "194889"
  },
  {
    "text": "to my weekly weekly shopping session at the supermarket go in pick up all my",
    "start": "194889",
    "end": "200319"
  },
  {
    "text": "fruit and veg only bought fruit and veg this time and headed over to a self-serve checkout has everyone used a",
    "start": "200319",
    "end": "207609"
  },
  {
    "text": "self-serve checkout before it's nearly mandatory these days and they have one of the lane open and I went through and",
    "start": "207609",
    "end": "213760"
  },
  {
    "text": "started unloading things item by item and put down an avocado flicking through",
    "start": "213760",
    "end": "219849"
  },
  {
    "text": "the menu flicking through the menu oh no I put it through as a carrot",
    "start": "219849",
    "end": "226349"
  },
  {
    "text": "obviously I need a little bit of machine learning in my life but I mean what does",
    "start": "226349",
    "end": "231579"
  },
  {
    "start": "230000",
    "end": "262000"
  },
  {
    "text": "that really mean well carrots are two dollars 20 or killer and a Vacarro",
    "start": "231579",
    "end": "237120"
  },
  {
    "text": "masquerading as carrots was 75 cents an actual avocado they were on sale this",
    "start": "237120",
    "end": "243579"
  },
  {
    "text": "day so it was two dollars fifty H it's a dollar seventy five difference now just",
    "start": "243579",
    "end": "252129"
  },
  {
    "text": "so everyone knows I did call over the shop attendant and say hey I've made a mistake and I actually paid for both",
    "start": "252129",
    "end": "257829"
  },
  {
    "text": "items in the end but it got me thinking how much of an issue could this be so I",
    "start": "257829",
    "end": "266139"
  },
  {
    "start": "262000",
    "end": "326000"
  },
  {
    "text": "went like any good any good person wouldn went straight to a data source avocados Australia and look",
    "start": "266139",
    "end": "272390"
  },
  {
    "text": "the number of avocados produced and sold in any one year and doing a little bit of a back-of-the-envelope back of the",
    "start": "272390",
    "end": "278900"
  },
  {
    "text": "napkin calculation 600 sorry 60,000 tons of avocados 341 grams per avocado $2 20",
    "start": "278900",
    "end": "288320"
  },
  {
    "text": "a kilo for carrots if only 1% of sales are put through his carrots that's three",
    "start": "288320",
    "end": "294260"
  },
  {
    "text": "million dollars a year that's a lot of avocados masquerading as carrots so as",
    "start": "294260",
    "end": "301510"
  },
  {
    "text": "part of this so put together a little bit of a proof of concept around self-serve checkouts and how you can use",
    "start": "301510",
    "end": "308060"
  },
  {
    "text": "object detection and image recognition at the edge to actually pick up",
    "start": "308060",
    "end": "313070"
  },
  {
    "text": "fraudulent behavior turns out a lot of people are actually doing similar things",
    "start": "313070",
    "end": "319550"
  },
  {
    "text": "to this and I love the wording elaborate self-serve check out scam so someone",
    "start": "319550",
    "end": "328130"
  },
  {
    "start": "326000",
    "end": "374000"
  },
  {
    "text": "said AI where does AI fit into this well as you probably guessed already we're",
    "start": "328130",
    "end": "333410"
  },
  {
    "text": "really talking about loss detection and prevention how can we detect that the users doing something different to what",
    "start": "333410",
    "end": "340250"
  },
  {
    "text": "we expect putting avocados through his carrots but this is only part of the biggest part of",
    "start": "340250",
    "end": "346850"
  },
  {
    "text": "the bigger issue and I mean at the end of the day we shouldn't just be thinking about this component but we sort of or",
    "start": "346850",
    "end": "352250"
  },
  {
    "text": "sure we should also be thinking about accessibility what if someone physically can't select",
    "start": "352250",
    "end": "358910"
  },
  {
    "text": "avocados from the menu they don't understand what the options are or how to interact with it wouldn't it make a",
    "start": "358910",
    "end": "365780"
  },
  {
    "text": "lot more sense to have machines make those decisions for us and then just prompt to say is this what you expected",
    "start": "365780",
    "end": "372800"
  },
  {
    "text": "to by sir machine learning as are we can",
    "start": "372800",
    "end": "378320"
  },
  {
    "start": "374000",
    "end": "425000"
  },
  {
    "text": "fit computer vision into this we can actually get a computer to recognize what an object or an item is and I want",
    "start": "378320",
    "end": "386570"
  },
  {
    "text": "to break it down into two very distinct categories that will look out separately image classification this is saying this",
    "start": "386570",
    "end": "393380"
  },
  {
    "text": "is an image of an apple this is an image of an orange this is an image of a man",
    "start": "393380",
    "end": "399650"
  },
  {
    "text": "in a park with a dog an object detection which breaks it down a little bit",
    "start": "399650",
    "end": "405350"
  },
  {
    "text": "further and actually tells you the location of the Apple within the image and there's a distinct",
    "start": "405350",
    "end": "410989"
  },
  {
    "text": "separation of these two because image classification you can get started with not a lot of data very little annotation",
    "start": "410989",
    "end": "418969"
  },
  {
    "text": "and labeling whereas object detection requires a little bit more thought around how you actually annotate your",
    "start": "418969",
    "end": "424789"
  },
  {
    "text": "data so instead of doing anything from scratch we're going to look at what we",
    "start": "424789",
    "end": "429979"
  },
  {
    "start": "425000",
    "end": "470000"
  },
  {
    "text": "can use off-the-shelf for this and because I'm a Microsoft kind of guy I turned to the azure cognitive services",
    "start": "429979",
    "end": "436099"
  },
  {
    "text": "suite these are a series of services that are basically exposed as REST API s",
    "start": "436099",
    "end": "441319"
  },
  {
    "text": "you can consume them to do some pretty cool things if you ever wanted to work",
    "start": "441319",
    "end": "446539"
  },
  {
    "text": "with vision so in our case image recognition if you ever wanted to do speech to text text to speech linguistic",
    "start": "446539",
    "end": "454309"
  },
  {
    "text": "analysis natural language understanding translation knowledge search cognitive",
    "start": "454309",
    "end": "459619"
  },
  {
    "text": "search all this sort of cool stuff you don't need to understand the science",
    "start": "459619",
    "end": "464929"
  },
  {
    "text": "behind it you can simply consume it as a service what I want to start off with is",
    "start": "464929",
    "end": "471800"
  },
  {
    "start": "470000",
    "end": "624000"
  },
  {
    "text": "actually looking at the computer vision and the computer vision is a general",
    "start": "471800",
    "end": "476809"
  },
  {
    "text": "image classification service so if we were to come along to the way-cool if we",
    "start": "476809",
    "end": "487550"
  },
  {
    "text": "come along to the azure homepage go to products cognitive services and choose computer vision this pops up and this is",
    "start": "487550",
    "end": "494599"
  },
  {
    "text": "actually a live demo on the website that you could be playing with and the whole idea here is we provide an image and we",
    "start": "494599",
    "end": "501800"
  },
  {
    "text": "get back a description of what the image is off so in this case we've got an image of a train and a platform and some",
    "start": "501800",
    "end": "508699"
  },
  {
    "text": "people and we can see the tags in the side represent the train platform station building indoor we can gain",
    "start": "508699",
    "end": "515959"
  },
  {
    "text": "context about what this image is and in fact it will even generate a text",
    "start": "515959",
    "end": "521479"
  },
  {
    "text": "description of the image people waiting at a train station now we can click",
    "start": "521479",
    "end": "526910"
  },
  {
    "text": "through to a whole lot of different sample images to see what it looks like but it's a lot more fun if we actually",
    "start": "526910",
    "end": "532250"
  },
  {
    "text": "give one of our own images so I'm going to give it a photo of an apple because",
    "start": "532250",
    "end": "537800"
  },
  {
    "text": "we were all fantastic it actually recognizes an apple how will a computer game well",
    "start": "537800",
    "end": "545430"
  },
  {
    "text": "we pass it in and it's recognized it as an apple in door but oh there we go and",
    "start": "545430",
    "end": "553590"
  },
  {
    "text": "the text says a green apple so it's successfully recognized an apple and this is fantastic our problem solved",
    "start": "553590",
    "end": "559860"
  },
  {
    "text": "we don't have to do any more work but what if we gave it something a little more complex say for example an avocado",
    "start": "559860",
    "end": "569480"
  },
  {
    "text": "well because the computer vision service is quite generalized it doesn't have",
    "start": "569480",
    "end": "575190"
  },
  {
    "text": "every single entity in the world and in this case it doesn't actually know what",
    "start": "575190",
    "end": "580920"
  },
  {
    "text": "this object is it knows that it's indoors and on a table but it can't actually recognize that it's an avocado",
    "start": "580920",
    "end": "587750"
  },
  {
    "text": "so the computer vision service while it's fantastic for recognizing general",
    "start": "587750",
    "end": "593190"
  },
  {
    "text": "objects it doesn't cater for domain-specific objects so let's jump",
    "start": "593190",
    "end": "599820"
  },
  {
    "text": "back now computer vision as I said generic categories so there's 86",
    "start": "599820",
    "end": "605550"
  },
  {
    "text": "taxonomy categories at the top with a whole lot of different object types underneath it's great for general",
    "start": "605550",
    "end": "611190"
  },
  {
    "text": "recognition as I say the men playing frisbee in the park style scenario but it's not so good for domain-specific",
    "start": "611190",
    "end": "618060"
  },
  {
    "text": "imagery we really want to recognize a wide range of fruit and vegetables not just an apple",
    "start": "618060",
    "end": "624050"
  },
  {
    "start": "624000",
    "end": "707000"
  },
  {
    "text": "so this is where custom vision comes in and custom visions another cognitive",
    "start": "624050",
    "end": "629940"
  },
  {
    "text": "service where we can actually provide our own data sets instead of using an off-the-shelf model we can provide our",
    "start": "629940",
    "end": "637140"
  },
  {
    "text": "own data and have the service train a machine learning model on our behalf and we consume it in exactly the same way",
    "start": "637140",
    "end": "644339"
  },
  {
    "text": "just via a REST API so custom vision you bring your own data sets this means we",
    "start": "644339",
    "end": "651060"
  },
  {
    "text": "could train it on any fruit and vege we actually have an image of and it can be as small as a dozen images and the",
    "start": "651060",
    "end": "657690"
  },
  {
    "text": "reason for this is that it actually uses transfer learning feature extraction and magic under the hood so it's not",
    "start": "657690",
    "end": "664920"
  },
  {
    "text": "retraining an entire model from scratch you often hear data scientists say well we're going to need 50,000 images to",
    "start": "664920",
    "end": "671880"
  },
  {
    "text": "start off where than I expect 200 thousand to get a model with half teeth its inaccuracy that's if you're",
    "start": "671880",
    "end": "677669"
  },
  {
    "text": "going from scratch if you can take a prebuilt generic model break off the",
    "start": "677669",
    "end": "684059"
  },
  {
    "text": "last couple of layers and feed your own information into it you can actually get amazing results without large large data",
    "start": "684059",
    "end": "691649"
  },
  {
    "text": "sets and on top of this it's as a service so as I said before it's a REST API we interact with I love this is it a",
    "start": "691649",
    "end": "699029"
  },
  {
    "text": "sir is it service I mean we don't have servers we don't care about scale we don't care about infrastructure you",
    "start": "699029",
    "end": "705089"
  },
  {
    "text": "could kind of call this I'm a side note on data preparation though it is 90% of",
    "start": "705089",
    "end": "711359"
  },
  {
    "start": "707000",
    "end": "738000"
  },
  {
    "text": "the work even though we're not data scientists it does take a lot of time custom vision will take care of a lot of",
    "start": "711359",
    "end": "718529"
  },
  {
    "text": "the easy tasks for you so resizing cropping duplicate detection in training",
    "start": "718529",
    "end": "724229"
  },
  {
    "text": "data storage of the images but you still actually you're still responsible for data accuracy if you've labeled a banana",
    "start": "724229",
    "end": "731699"
  },
  {
    "text": "and apple it's not going to fix that for you so data prep is still important so",
    "start": "731699",
    "end": "738479"
  },
  {
    "start": "738000",
    "end": "744000"
  },
  {
    "text": "let's actually build something let's actually start playing around with the custom vision service so if we head",
    "start": "738479",
    "end": "745439"
  },
  {
    "start": "744000",
    "end": "878000"
  },
  {
    "text": "across to custom vision AI you can log in and every single Microsoft account",
    "start": "745439",
    "end": "751949"
  },
  {
    "text": "actually has a couple of free projects so you don't actually even need to spin up any resources in Azure to get started",
    "start": "751949",
    "end": "758309"
  },
  {
    "text": "when you want to look at production izing you can look at then spinning up backing resources as appropriate so I'm",
    "start": "758309",
    "end": "764909"
  },
  {
    "text": "gonna come in here and I've got a couple of pre-prepared demos in case the world burns down and little live demos don't",
    "start": "764909",
    "end": "770819"
  },
  {
    "text": "work demo gods be with us let's do a live demo and instantly it pops up with",
    "start": "770819",
    "end": "778559"
  },
  {
    "text": "a whole lot of options instead of using a trial for this I'm actually going to pay for this one we can choose project",
    "start": "778559",
    "end": "785819"
  },
  {
    "text": "types and the project types really come down to are we doing image",
    "start": "785819",
    "end": "791220"
  },
  {
    "text": "classification or object detection you remember I split it out into those two",
    "start": "791220",
    "end": "796319"
  },
  {
    "text": "categories before this is actually kind of an important part we'll come back to come around to object detection a little",
    "start": "796319",
    "end": "801929"
  },
  {
    "text": "bit later on but for the moment we'll go classification we have the idea of classification types",
    "start": "801929",
    "end": "808720"
  },
  {
    "text": "this is could there be two items in an image or will it only ever be a photo of",
    "start": "808720",
    "end": "815389"
  },
  {
    "text": "one thing so could there be a cat and a dog in the same image or will the photo ever be only be of a cat or of a dog so",
    "start": "815389",
    "end": "823970"
  },
  {
    "text": "in the computer vision we saw before it returned a whole lot of different labels so that would be multi label if we could",
    "start": "823970",
    "end": "830869"
  },
  {
    "text": "guarantee would only ever see one item in an image then multi-class would be more applicable the domains finally down",
    "start": "830869",
    "end": "839059"
  },
  {
    "text": "the bottom this really comes into the whole idea of the base model that's used to specialized into your model where",
    "start": "839059",
    "end": "847339"
  },
  {
    "text": "should it be based should it be just a general model similar to the computer vision model or should it be something",
    "start": "847339",
    "end": "853009"
  },
  {
    "text": "that's already seen landmarks or food the adult ones actually rather",
    "start": "853009",
    "end": "858920"
  },
  {
    "text": "interesting you can do adult image classifications on top of this to say is",
    "start": "858920",
    "end": "864230"
  },
  {
    "text": "this a racy image is this an adult image should it be blocked should it be over 18 under 18 that sort",
    "start": "864230",
    "end": "870740"
  },
  {
    "text": "of thing the compact domains will come back to a little bit later because that's a little bit more of an",
    "start": "870740",
    "end": "876230"
  },
  {
    "text": "interesting concept but we'll click create project and boom we're done where",
    "start": "876230",
    "end": "882170"
  },
  {
    "start": "878000",
    "end": "1272000"
  },
  {
    "text": "we're ready to go so this is the same as writing a couple of hundred lines in Python of setting up tensorflow setting",
    "start": "882170",
    "end": "890389"
  },
  {
    "text": "up where you're actually going to feed data from how the model actually is structured and it was one-click super-easy from the portal though we can",
    "start": "890389",
    "end": "898399"
  },
  {
    "text": "then add images in so I'm gonna go ahead and add a single picture of a carrot and",
    "start": "898399",
    "end": "904749"
  },
  {
    "text": "it's gonna pop up and ask us well what is this image of I'm gonna say it's a",
    "start": "904749",
    "end": "910939"
  },
  {
    "text": "carrot and upload a file so this is going to upload it tag it annotate it",
    "start": "910939",
    "end": "917600"
  },
  {
    "text": "and store it on the custom vision service now you can imagine if we had we",
    "start": "917600",
    "end": "923990"
  },
  {
    "text": "had a hundred photos of fruit doing that one by one is very laborious and it just so happens that this website under the",
    "start": "923990",
    "end": "931249"
  },
  {
    "text": "hood is using the same custom vision API that you get access to so if we want to",
    "start": "931249",
    "end": "937970"
  },
  {
    "text": "automate it instead we can actually use here we go the custom vision training nougat package in",
    "start": "937970",
    "end": "946010"
  },
  {
    "text": "c-sharp there's a node.js equivalent which allows us to actually upload",
    "start": "946010",
    "end": "951140"
  },
  {
    "text": "images in batch or in bulk automatically so if you've got a data Lake where",
    "start": "951140",
    "end": "957200"
  },
  {
    "text": "you've got existing data reading to ready to pull in you can do that programmatically so what we're doing",
    "start": "957200",
    "end": "963830"
  },
  {
    "text": "here is setting up our custom vision configuration and we'll grab the project ID in a second we're going to cache any",
    "start": "963830",
    "end": "970550"
  },
  {
    "text": "tags that already exist because we don't want to begin tagging things twice we're then going to go through all the folders",
    "start": "970550",
    "end": "977390"
  },
  {
    "text": "on my computer in terms of where my images are stored create the tag if it",
    "start": "977390",
    "end": "982490"
  },
  {
    "text": "doesn't exist and upload all the files and we're not upload the files as a",
    "start": "982490",
    "end": "987620"
  },
  {
    "text": "batch as you can imagine doing everything one by one is ok when you've got 30 images but when you've got 300",
    "start": "987620",
    "end": "993560"
  },
  {
    "text": "400 500 thousand sort of thing it does take a while so in order to hook this up",
    "start": "993560",
    "end": "999350"
  },
  {
    "text": "I just come back to the custom vision portal come across and grab the project",
    "start": "999350",
    "end": "1004990"
  },
  {
    "text": "ID and replace it with the project ID listed here kicking wrong project to",
    "start": "1004990",
    "end": "1015610"
  },
  {
    "text": "start cool kicking this off will then",
    "start": "1015610",
    "end": "1022330"
  },
  {
    "text": "grab all those images and batch load them into the custom vision service I'm not exaggerating when I say everything",
    "start": "1022330",
    "end": "1028720"
  },
  {
    "text": "you can do in the custom vision service you can do programmatically everything is exposed as an API the whole idea here",
    "start": "1028720",
    "end": "1036040"
  },
  {
    "text": "is that the interface you use is just exposing those API is in a user-friendly",
    "start": "1036040",
    "end": "1041079"
  },
  {
    "text": "way so this is going to go through now and upload all those images with the",
    "start": "1041079",
    "end": "1047050"
  },
  {
    "text": "tags that I've specified and the way I've actually sorted my fire photos is a",
    "start": "1047050",
    "end": "1052179"
  },
  {
    "text": "folder which is the tags name and then the images within them and there we go we're uploaded and ready to go so if we",
    "start": "1052179",
    "end": "1060429"
  },
  {
    "text": "come back here and have a look at our training images again we should actually have about 307 308 images in total all",
    "start": "1060429",
    "end": "1068710"
  },
  {
    "text": "of these tagged as well in this case it's a potato",
    "start": "1068710",
    "end": "1073950"
  },
  {
    "text": "now at this point we've got our images annotated and sitting in the custom",
    "start": "1073950",
    "end": "1079990"
  },
  {
    "text": "vision portal we now actually need to train the machine learning model now",
    "start": "1079990",
    "end": "1085060"
  },
  {
    "text": "it's quite complex we come up to the Train button we click and we wait about 30 seconds or so this is one of the",
    "start": "1085060",
    "end": "1092230"
  },
  {
    "text": "really nice things around custom vision you don't have to worry about infrastructure under the hood you don't",
    "start": "1092230",
    "end": "1098200"
  },
  {
    "text": "have to spin up a VM you don't have to maintain a stack the service provisions",
    "start": "1098200",
    "end": "1104920"
  },
  {
    "text": "and runs that infrastructure behind the scenes for you so at no point have we",
    "start": "1104920",
    "end": "1109930"
  },
  {
    "text": "actually used a VM or at this stage and we're good to go",
    "start": "1109930",
    "end": "1115270"
  },
  {
    "text": "now I'm gonna turn the probability threshold up a little bit and you see we",
    "start": "1115270",
    "end": "1121630"
  },
  {
    "text": "have a precision and a recall this is interesting so the whole idea of",
    "start": "1121630",
    "end": "1127210"
  },
  {
    "text": "precision is given a tag appears on an image how likely is that tag to be",
    "start": "1127210",
    "end": "1134770"
  },
  {
    "text": "correct so given we have an image and it shows up with the tag potato how likely",
    "start": "1134770",
    "end": "1140710"
  },
  {
    "text": "is it that it's actually a potato our recall is given that tag popped up what",
    "start": "1140710",
    "end": "1148600"
  },
  {
    "text": "confidence was it that it was a potato and we'll drill into confidence in a second so you can see here that we've",
    "start": "1148600",
    "end": "1155350"
  },
  {
    "text": "training this up and we're good to go if we wanted to actually start to start",
    "start": "1155350",
    "end": "1160870"
  },
  {
    "text": "calling this API we can click on the prediction URL and it gives us all the",
    "start": "1160870",
    "end": "1166330"
  },
  {
    "text": "information they're ready to get started so that's a complete image",
    "start": "1166330",
    "end": "1171670"
  },
  {
    "text": "classification machine learning model from data input training production",
    "start": "1171670",
    "end": "1177040"
  },
  {
    "text": "izing and monitoring in give or take four or five minutes it's quite easy to",
    "start": "1177040",
    "end": "1183040"
  },
  {
    "text": "get started now to test it out quickly I'm gonna click on the quick test button",
    "start": "1183040",
    "end": "1189370"
  },
  {
    "text": "and give it a file that it's actually never seen before so all the images that",
    "start": "1189370",
    "end": "1195610"
  },
  {
    "text": "I've put up so far have been fairly they've been designed to just show the",
    "start": "1195610",
    "end": "1201580"
  },
  {
    "text": "object itself they've been on white backgrounds with reasonable lighting so what happens if I actually give it",
    "start": "1201580",
    "end": "1207520"
  },
  {
    "text": "something that has poor lighting corners",
    "start": "1207520",
    "end": "1212560"
  },
  {
    "text": "are black and you can see here that it's picked it up as a carrot with 91% confidence so the model itself is 91%",
    "start": "1212560",
    "end": "1219970"
  },
  {
    "text": "confident that there's actually a carrot in this image likewise if we give it an",
    "start": "1219970",
    "end": "1226600"
  },
  {
    "text": "avocado we have an 88% confidence that this image is of an avocado these these",
    "start": "1226600",
    "end": "1237370"
  },
  {
    "text": "predictions are what we basically use to determine are we confident with what",
    "start": "1237370",
    "end": "1242680"
  },
  {
    "text": "it's predicted and what thresholds do we set on top of that so you wonder you'll",
    "start": "1242680",
    "end": "1250840"
  },
  {
    "text": "most likely never end up in a scenario with a hundred percent confidence unless",
    "start": "1250840",
    "end": "1256420"
  },
  {
    "text": "you're feeding in the same image is that it's been trained on at most you'll end",
    "start": "1256420",
    "end": "1262870"
  },
  {
    "text": "up with 99 point something so that's building the model training it and",
    "start": "1262870",
    "end": "1269920"
  },
  {
    "text": "executing it jump back over here for a second so what if we actually wanted to run",
    "start": "1269920",
    "end": "1278230"
  },
  {
    "start": "1272000",
    "end": "1419000"
  },
  {
    "text": "this on the edge rather than in the cloud having an API available to",
    "start": "1278230",
    "end": "1287110"
  },
  {
    "text": "actually evaluate and predict these images is great but not everywhere has",
    "start": "1287110",
    "end": "1292150"
  },
  {
    "text": "amazing bandwidth we can't be expected to stream live video up to the Internet especially if in a self-serve kiosks",
    "start": "1292150",
    "end": "1299140"
  },
  {
    "text": "star scenario you might have 30 or 40 within a single location so we can",
    "start": "1299140",
    "end": "1305170"
  },
  {
    "text": "actually look at running these machine learning models that are built and trained in the cloud on the edge and for",
    "start": "1305170",
    "end": "1312700"
  },
  {
    "text": "a little bit of a demonstration today I've got a Raspberry Pi up the front here so a fairly low powered device and",
    "start": "1312700",
    "end": "1317740"
  },
  {
    "text": "we're going to take this machine learning model that we just trained and push it down to the Raspberry Pi and",
    "start": "1317740",
    "end": "1323620"
  },
  {
    "text": "we've got a little webcam here that we can point it a couple of different bits of fruit so how do we actually how do we",
    "start": "1323620",
    "end": "1331660"
  },
  {
    "text": "actually put this together well I could take the custom vision component and",
    "start": "1331660",
    "end": "1337780"
  },
  {
    "text": "just push it onto the raspberry directly but if we want to look at actually doing this at scale we need a",
    "start": "1337780",
    "end": "1343630"
  },
  {
    "text": "way to manage a large number of devices configurations across multiple locations",
    "start": "1343630",
    "end": "1349110"
  },
  {
    "text": "across across multiple multiple geographic locations with different",
    "start": "1349110",
    "end": "1356380"
  },
  {
    "text": "configurations possibly in disconnected states so whether they only have partial access to the Internet and it just so",
    "start": "1356380",
    "end": "1363250"
  },
  {
    "text": "happens there's a service that does it does this for us the azure IOT hub so an",
    "start": "1363250",
    "end": "1368920"
  },
  {
    "text": "azure IOT hub really looks at device telemetry and configuration for IOT",
    "start": "1368920",
    "end": "1374980"
  },
  {
    "text": "devices there is an extra part to it though which is particularly interesting",
    "start": "1374980",
    "end": "1381580"
  },
  {
    "text": "when it comes to edge compute and that's the irt edge IOT edge is a small",
    "start": "1381580",
    "end": "1389260"
  },
  {
    "text": "framework that you can run on low-power devices right through to physical servers that allows you to centrally",
    "start": "1389260",
    "end": "1396280"
  },
  {
    "text": "configure a large number of edge devices with any sort of configuration you want",
    "start": "1396280",
    "end": "1401320"
  },
  {
    "text": "and in our case we can actually push a docker container from the azure portal",
    "start": "1401320",
    "end": "1407500"
  },
  {
    "text": "down to the raspberry pi without ever actually touching the raspberry pi itself we could do this on scale for",
    "start": "1407500",
    "end": "1413800"
  },
  {
    "text": "thousands and thousands of devices or in our case just do it for one as a bit of a test so let's actually dive in and run with",
    "start": "1413800",
    "end": "1423850"
  },
  {
    "start": "1419000",
    "end": "1547000"
  },
  {
    "text": "this so before we saw that there are a couple of different sorts of domains we had our",
    "start": "1423850",
    "end": "1430900"
  },
  {
    "text": "general domain our food domain but we also had a series of compact domains and",
    "start": "1430900",
    "end": "1436270"
  },
  {
    "text": "these compact domains represent a slightly smaller model that's designed",
    "start": "1436270",
    "end": "1441910"
  },
  {
    "text": "for offline usage so if we were to changed this to general compact it's now",
    "start": "1441910",
    "end": "1447940"
  },
  {
    "text": "going to change the way it actually builds up and trains this model behind the scenes so if we save changes and",
    "start": "1447940",
    "end": "1454810"
  },
  {
    "text": "come in and retrain this model it's now going to use a different base model and",
    "start": "1454810",
    "end": "1460650"
  },
  {
    "text": "enable a couple of extra options for us the most important one in our case is",
    "start": "1460650",
    "end": "1466720"
  },
  {
    "text": "actually the ability to export this model so we can use it wherever we want",
    "start": "1466720",
    "end": "1472669"
  },
  {
    "text": "for this we'll take a couple of seconds and we'll be good to go there are a couple of different formats that we can actually export it into and it really",
    "start": "1472669",
    "end": "1479840"
  },
  {
    "text": "comes down to where you're actually going to be running this model there are options for different phones if you want",
    "start": "1479840",
    "end": "1486859"
  },
  {
    "text": "to run it on Android and iOS there's an option for Windows ml and onyx so if I",
    "start": "1486859",
    "end": "1494629"
  },
  {
    "text": "click on the export button now we'll get all those different platform options but the one I'm really interested for today",
    "start": "1494629",
    "end": "1500450"
  },
  {
    "text": "is down the bottom here Dokka file we can actually export our model and a SCAF",
    "start": "1500450",
    "end": "1506450"
  },
  {
    "text": "holded program ready ready to execute there's really nothing we need to do for",
    "start": "1506450",
    "end": "1513019"
  },
  {
    "text": "it so if we click on docker file I'm gonna specify that I actually want to run it on a linux host and it's going to",
    "start": "1513019",
    "end": "1520639"
  },
  {
    "text": "go off and prep everything for me so behind the scenes it's going to convert it from its internal format into a",
    "start": "1520639",
    "end": "1527090"
  },
  {
    "text": "tensorflow frozen graph so any way you use tensorflow you can actually use this",
    "start": "1527090",
    "end": "1532399"
  },
  {
    "text": "model and it's also going to include as I said before that scaffolding application and that's made up of a",
    "start": "1532399",
    "end": "1538429"
  },
  {
    "text": "flask API written in Python which allows us to call this model in the same way we",
    "start": "1538429",
    "end": "1543499"
  },
  {
    "text": "call the custom vision service so if we were to open up the exported file we'll",
    "start": "1543499",
    "end": "1553399"
  },
  {
    "start": "1547000",
    "end": "1639000"
  },
  {
    "text": "actually find that there's a couple of different bits and pieces inside that so it's come straight out of the box with a",
    "start": "1553399",
    "end": "1559549"
  },
  {
    "text": "docker file it's got a folder containing our application code as well as it's not",
    "start": "1559549",
    "end": "1569210"
  },
  {
    "text": "going to zoom in you just have to take my word for it it's got a couple of Python files in the actual frozen model",
    "start": "1569210",
    "end": "1574730"
  },
  {
    "text": "itself now for the sake of time I'm gonna change the way this actually",
    "start": "1574730",
    "end": "1579919"
  },
  {
    "text": "builds and executes so it uses a saved base image instead of building everything up from scratch so within the",
    "start": "1579919",
    "end": "1587119"
  },
  {
    "text": "docker file I'm just going to come in and modify the from image to one that",
    "start": "1587119",
    "end": "1594259"
  },
  {
    "text": "I've already prepared and remove the requirements installation so if we were",
    "start": "1594259",
    "end": "1601909"
  },
  {
    "text": "to build this straightaway we'd have no issues at all but it about 20 minutes or so to actually",
    "start": "1601909",
    "end": "1609140"
  },
  {
    "text": "install all the prerequisites because it actually pulls down a copy of tensorflow pulls down a copy of OpenCV numpy and a",
    "start": "1609140",
    "end": "1616430"
  },
  {
    "text": "couple of pretty heavy components so by using an existing base image we can",
    "start": "1616430",
    "end": "1622130"
  },
  {
    "text": "actually speed up that deployment process and that's probably one of the big caker takeaways from today if you",
    "start": "1622130",
    "end": "1627680"
  },
  {
    "text": "are looking at using this in a production scenario think about how you can standardize on those base images and",
    "start": "1627680",
    "end": "1633470"
  },
  {
    "text": "just shift around the model weights itself so that frozen graph so if we",
    "start": "1633470",
    "end": "1639050"
  },
  {
    "start": "1639000",
    "end": "1779000"
  },
  {
    "text": "save this we can now come back and actually build the docker container so I'm just gonna do a docker build let me",
    "start": "1639050",
    "end": "1647090"
  },
  {
    "text": "zoom this in a little bit as well fact just going to do a docker build in the",
    "start": "1647090",
    "end": "1654890"
  },
  {
    "text": "current directory and I'm gonna tag it with live demo perfect so that's gonna",
    "start": "1654890",
    "end": "1661640"
  },
  {
    "text": "go off pull those base base layers and then just include the graph in the application files itself so should be a",
    "start": "1661640",
    "end": "1669380"
  },
  {
    "text": "couple of seconds rather than a couple of minutes to build once we've got this we actually need somewhere to push this",
    "start": "1669380",
    "end": "1675590"
  },
  {
    "text": "up so I've set up a private Azure container registry to store this and one of the big",
    "start": "1675590",
    "end": "1681470"
  },
  {
    "text": "benefits here is I can push it up and have it stored securely without needing to set any additional set up any",
    "start": "1681470",
    "end": "1687500"
  },
  {
    "text": "additional infrastructure so if I was to actually push this straight up so I will",
    "start": "1687500",
    "end": "1696050"
  },
  {
    "text": "do a doc a tag and tag live demo with",
    "start": "1696050",
    "end": "1703220"
  },
  {
    "text": "our remote container registry name and live demo latest from here we can",
    "start": "1703220",
    "end": "1714500"
  },
  {
    "text": "actually push it up and we should be good to go now on the Raspberry Pi",
    "start": "1714500",
    "end": "1719990"
  },
  {
    "text": "itself while this is happening I've installed the IRT Edge SDK which is a",
    "start": "1719990",
    "end": "1726410"
  },
  {
    "text": "small series of files and it includes a security daemon that make sure that the",
    "start": "1726410",
    "end": "1732950"
  },
  {
    "text": "raspberry PI's in a curette in a good configuration state and it also installs a couple of watchdogs to make sure if",
    "start": "1732950",
    "end": "1739370"
  },
  {
    "text": "anything dies the Raspberry Pi it automatically restarts and kicks off again so I'm",
    "start": "1739370",
    "end": "1745280"
  },
  {
    "text": "gonna do a docker push and push this up to my remote registry so I've already",
    "start": "1745280",
    "end": "1751220"
  },
  {
    "text": "authenticated so it should just fly through when we talk about IOT edge and",
    "start": "1751220",
    "end": "1756800"
  },
  {
    "text": "central configuration the whole idea is that we make one configuration change in the cloud and have it pushed to a number",
    "start": "1756800",
    "end": "1763880"
  },
  {
    "text": "of different devices remotely this means that whether it's one device or a thousand devices it's still just a",
    "start": "1763880",
    "end": "1769940"
  },
  {
    "text": "single action so we can see that we've only pushed the top filesystem layer",
    "start": "1769940",
    "end": "1775880"
  },
  {
    "text": "there rather than the entire image so if we were to come over to the azure portal",
    "start": "1775880",
    "end": "1781940"
  },
  {
    "text": "now and open up the IOT hub that I've got everything connected up to we can",
    "start": "1781940",
    "end": "1788210"
  },
  {
    "text": "actually configure this edge device so if I go into IOT edge select the device",
    "start": "1788210",
    "end": "1798940"
  },
  {
    "text": "scroll down oh sorry not scroll down click set modules and then scroll down",
    "start": "1799030",
    "end": "1805250"
  },
  {
    "text": "to the bottom of the set module screen I can actually add any deployment modules",
    "start": "1805250",
    "end": "1811370"
  },
  {
    "text": "I like in this case I'm going to add a new IT edge module which under the hood",
    "start": "1811370",
    "end": "1817220"
  },
  {
    "text": "is a container so I'm gonna call this vision paste in my image URI and that's",
    "start": "1817220",
    "end": "1823880"
  },
  {
    "text": "all I really need everything else will be hooked up behind the scenes but I'm actually going to add an extra option",
    "start": "1823880",
    "end": "1830680"
  },
  {
    "text": "I'm gonna take a port binding and place it in there so we actually expose a port",
    "start": "1830680",
    "end": "1838160"
  },
  {
    "text": "inside the container itself to the Raspberry Pi so we can jump on and test",
    "start": "1838160",
    "end": "1843590"
  },
  {
    "text": "to see whether this API is actually working so if we click Save next through",
    "start": "1843590",
    "end": "1849650"
  },
  {
    "start": "1848000",
    "end": "2199000"
  },
  {
    "text": "the rest of the wizard and hit submit it's now going to save that",
    "start": "1849650",
    "end": "1854750"
  },
  {
    "text": "configuration to a virtual twin of the device in the cloud the device is then",
    "start": "1854750",
    "end": "1860630"
  },
  {
    "text": "going again will automatically be notified that changes are available and it will then pull that down to the",
    "start": "1860630",
    "end": "1867080"
  },
  {
    "text": "device itself so for the sake of the demo I'm going to jump directly across",
    "start": "1867080",
    "end": "1872990"
  },
  {
    "text": "to the Raspberry Pi self so we can inspect and see what's happening so if I do an IOT edge list",
    "start": "1872990",
    "end": "1879309"
  },
  {
    "text": "which is the IOT s a IOT edge CLI we can",
    "start": "1879309",
    "end": "1885460"
  },
  {
    "text": "actually see that the vision container is already up and running and it started up 14 seconds ago so in terms of making",
    "start": "1885460",
    "end": "1891909"
  },
  {
    "text": "a change within IOT hub and having those changes replicated to the edge devices",
    "start": "1891909",
    "end": "1897220"
  },
  {
    "text": "it's quite quick we can actually come in here and actually then do a we can look",
    "start": "1897220",
    "end": "1902890"
  },
  {
    "text": "for logs as well but what I want to test is is this API actually working can we",
    "start": "1902890",
    "end": "1908470"
  },
  {
    "text": "do image prediction on the edge well I can actually call this container in the",
    "start": "1908470",
    "end": "1916990"
  },
  {
    "text": "same way I call custom vision so I can do a curl pass in an example image so",
    "start": "1916990",
    "end": "1924700"
  },
  {
    "text": "I'm going to pass in the image of the carrot that we used previously and I'm gonna pretty print the JSON so we can",
    "start": "1924700",
    "end": "1931179"
  },
  {
    "text": "actually just sit let's get a couple of steps this is going to take an image locally on the device send it off to the",
    "start": "1931179",
    "end": "1938140"
  },
  {
    "text": "container that's sitting there it's going to load up that machine learning model predict pull back the results and",
    "start": "1938140",
    "end": "1945220"
  },
  {
    "text": "give it all back to us in a nice JSON format and in fact the API the endpoints",
    "start": "1945220",
    "end": "1950710"
  },
  {
    "text": "that it uses and the JSON that are returns is like for like of that of the",
    "start": "1950710",
    "end": "1955870"
  },
  {
    "text": "custom vision service itself so the only difference between calling an edge",
    "start": "1955870",
    "end": "1961149"
  },
  {
    "text": "module or the custom vision service is the URL you can literally just point it",
    "start": "1961149",
    "end": "1966970"
  },
  {
    "text": "straight over and it'll work and we can see here that scientific notation makes",
    "start": "1966970",
    "end": "1972100"
  },
  {
    "text": "it a little bit difficult to read we can see here that we've got very very low probabilities for most of the most of",
    "start": "1972100",
    "end": "1978070"
  },
  {
    "text": "the items except for carrot where it's 99% sure that yes this is in fact a",
    "start": "1978070",
    "end": "1983890"
  },
  {
    "text": "photo of a carrot likewise if we were to give it an avocado instead so this is",
    "start": "1983890",
    "end": "1991090"
  },
  {
    "text": "the one where we scored very very low last time it was around about 88% we",
    "start": "1991090",
    "end": "1996100"
  },
  {
    "text": "should see a very similar very similar result pop up here so everything's low",
    "start": "1996100",
    "end": "2001890"
  },
  {
    "text": "everything's slow there we go so 70 77 percent confidence that it's an avocado",
    "start": "2001890",
    "end": "2008090"
  },
  {
    "text": "this is really the power of being able to train in the cloud and export to the edge you can do all the hard work keep",
    "start": "2008090",
    "end": "2016200"
  },
  {
    "text": "all of your data safe and sound in the cloud itself and then only pull down to Meg of data to actually deploy to the",
    "start": "2016200",
    "end": "2022110"
  },
  {
    "text": "edge itself so besides just uploading files to it let's capture from a webcam",
    "start": "2022110",
    "end": "2028380"
  },
  {
    "text": "and stream webcam footage to this container so I've written a small Python",
    "start": "2028380",
    "end": "2034200"
  },
  {
    "text": "script that actually uses OpenCV to capture images from the webcam and send",
    "start": "2034200",
    "end": "2040470"
  },
  {
    "text": "it to the container we're running a little bit short on time in terms of the whole presentation so if you would like",
    "start": "2040470",
    "end": "2046560"
  },
  {
    "text": "the source code in me to go through it a little bit later on come see me at the end but if we kick this off it'll",
    "start": "2046560",
    "end": "2052440"
  },
  {
    "text": "initiate just a consumer Graham web webcam and we can begin to place items",
    "start": "2052440",
    "end": "2059610"
  },
  {
    "text": "in front of it now at the moment it's saying I see nothing of interest it's",
    "start": "2059610",
    "end": "2067340"
  },
  {
    "text": "unable to recognize anything in the image whatsoever if we were to give it a",
    "start": "2067340",
    "end": "2072388"
  },
  {
    "text": "granny smith apple for example well hopefully it should actually pop up and",
    "start": "2072389",
    "end": "2077520"
  },
  {
    "text": "say well now I see a granny smith apple with this edge deployment tensorflow",
    "start": "2077520",
    "end": "2084300"
  },
  {
    "text": "under the hood hasn't been compiled four-armed hey there we go I can see an apple Granny Smith we could then replace",
    "start": "2084300",
    "end": "2090929"
  },
  {
    "text": "it with a pink lady for example so another Apple can it actually tell the",
    "start": "2090929",
    "end": "2096960"
  },
  {
    "text": "difference between the two when it kicks along um the reason it's taking so long",
    "start": "2096960",
    "end": "2104400"
  },
  {
    "text": "it's because I've actually got five of these containers running on the one Raspberry Pi and as you know raspberry pies aren't the most powerful devices in",
    "start": "2104400",
    "end": "2111180"
  },
  {
    "text": "the world I didn't want the demo gods to be angry at me so I kept a lot of backups and there we go we've got Apple",
    "start": "2111180",
    "end": "2117540"
  },
  {
    "text": "pink lady showing up ready to go but what happens if we actually had a couple",
    "start": "2117540",
    "end": "2123060"
  },
  {
    "text": "of different bits and pieces in the same image say for example I put down an avocado and a carrot on the self-serve",
    "start": "2123060",
    "end": "2130890"
  },
  {
    "text": "check out at the same time well hopefully we should actually see a result where it detects multiple things",
    "start": "2130890",
    "end": "2137400"
  },
  {
    "text": "within the same image and I'm not sure if I'm actually in frame let's go a carrot instead I'm the",
    "start": "2137400",
    "end": "2145260"
  },
  {
    "text": "weed fruit guy I travel around everywhere I go with bags and bags of fruit for demos so um is it gonna be on",
    "start": "2145260",
    "end": "2154500"
  },
  {
    "text": "my side no it's not it's not gonna pick it up I'm not going to spend too long here but with enough training data it'll",
    "start": "2154500",
    "end": "2161490"
  },
  {
    "text": "be able to pick up multiple items within a single photo and feed that back let's",
    "start": "2161490",
    "end": "2167970"
  },
  {
    "text": "give one last go with two different types of apples instead of one so my",
    "start": "2167970",
    "end": "2174840"
  },
  {
    "text": "recommendations here as well while this sample container is great to get started",
    "start": "2174840",
    "end": "2179880"
  },
  {
    "text": "it's less than performant overall there are a whole lot of extra optimizations",
    "start": "2179880",
    "end": "2185550"
  },
  {
    "text": "you can put into play to actually get this running a lot faster and I've got it running up to one to two frames a",
    "start": "2185550",
    "end": "2191760"
  },
  {
    "text": "second on a last-generation Raspberry Pi which is half decent for edge compute so",
    "start": "2191760",
    "end": "2198200"
  },
  {
    "text": "breaking out of this demo let's let's kind of have a bit of a discussion around what what we've seen so far yeah",
    "start": "2198200",
    "end": "2209900"
  },
  {
    "start": "2199000",
    "end": "2275000"
  },
  {
    "text": "so we've had a look at how to take a model",
    "start": "2212630",
    "end": "2218140"
  },
  {
    "text": "how to deploy it to the edge how to execute and run it on the edge but image",
    "start": "2218140",
    "end": "2223150"
  },
  {
    "text": "classification to me is great for some scenarios but it doesn't solve everything what we really need here is",
    "start": "2223150",
    "end": "2229300"
  },
  {
    "text": "object detection as we said before object detection is a lot more than just",
    "start": "2229300",
    "end": "2234760"
  },
  {
    "text": "labels and probabilities saying how likely is it that there's an item within an image instead it really looks at",
    "start": "2234760",
    "end": "2242020"
  },
  {
    "text": "bounding boxes where is an item within the image itself so where is the Apple",
    "start": "2242020",
    "end": "2247480"
  },
  {
    "text": "this gives us a lot more information because we can actually pinpoint the number of items within a frame number of",
    "start": "2247480",
    "end": "2253570"
  },
  {
    "text": "items within an image and where they are and you actually get lots and lots of bounding boxes in the same way that we",
    "start": "2253570",
    "end": "2261130"
  },
  {
    "text": "saw all of the labels returned when we asked what an image was we get lots and",
    "start": "2261130",
    "end": "2266380"
  },
  {
    "text": "lots of guesses of bounding boxes and confidences of how likely they are to be",
    "start": "2266380",
    "end": "2271570"
  },
  {
    "text": "correct so running forward a little bit let's actually spin up object detection",
    "start": "2271570",
    "end": "2277360"
  },
  {
    "start": "2275000",
    "end": "2359000"
  },
  {
    "text": "rather than just custom vision so to get",
    "start": "2277360",
    "end": "2283660"
  },
  {
    "text": "started with object detection as opposed to as opposed to image classification we",
    "start": "2283660",
    "end": "2289660"
  },
  {
    "text": "can come to the exact same portal and spin up a new project but instead of",
    "start": "2289660",
    "end": "2294700"
  },
  {
    "text": "clicking the image classification type we're going to explicitly say object",
    "start": "2294700",
    "end": "2300670"
  },
  {
    "text": "detection now object detection is still in preview so there are a couple of",
    "start": "2300670",
    "end": "2305950"
  },
  {
    "text": "limits to it that we'll discuss a little bit later on and I'm gonna call this live live object and create it now when",
    "start": "2305950",
    "end": "2315880"
  },
  {
    "text": "we looked at annotating and tagging images of apples and potatoes it was quite easy we can sort them into folders",
    "start": "2315880",
    "end": "2323700"
  },
  {
    "text": "when it comes to object detection though we need a lot more than just the labels themselves we need positional",
    "start": "2323700",
    "end": "2330670"
  },
  {
    "text": "information so if I was to upload in this case a photo of a carrot I don't",
    "start": "2330670",
    "end": "2337900"
  },
  {
    "text": "get a chance to bulk annotate and just add a tag instead I have to go through",
    "start": "2337900",
    "end": "2343360"
  },
  {
    "text": "every single image one by one and select on the image where the object is",
    "start": "2343360",
    "end": "2349240"
  },
  {
    "text": "and market has a carrot out still in the slide apologies okay let's run through a",
    "start": "2349240",
    "end": "2361360"
  },
  {
    "start": "2359000",
    "end": "2736000"
  },
  {
    "text": "last couple of seconds they're very very quickly so within the portal we open up",
    "start": "2361360",
    "end": "2367390"
  },
  {
    "text": "and go new project under project types we have the ability to select object",
    "start": "2367390",
    "end": "2373210"
  },
  {
    "text": "detection and we're good to go once we've got an object detection",
    "start": "2373210",
    "end": "2378490"
  },
  {
    "text": "project we can then import an image in exactly the same way we did before the",
    "start": "2378490",
    "end": "2383830"
  },
  {
    "text": "last thing we need to do is actually annotate that image so coming through",
    "start": "2383830",
    "end": "2389280"
  },
  {
    "text": "drawing bounding boxes across our objects and marking them as what they are now you can do this via the portal",
    "start": "2389280",
    "end": "2397990"
  },
  {
    "text": "itself and I highly recommend if you've got a little bit of spare time to go through and do it just as a this is a",
    "start": "2397990",
    "end": "2403869"
  },
  {
    "text": "bit of a trial run but you'll find you'll outgrow it very quickly and this is a kind of another key point there are",
    "start": "2403869",
    "end": "2410650"
  },
  {
    "text": "a whole lot of image annotation tools that can help you with tagging and annotating large data sets and that can",
    "start": "2410650",
    "end": "2418630"
  },
  {
    "text": "be everything from automatically suggesting bounding boxes through to live training where it's automatically",
    "start": "2418630",
    "end": "2425230"
  },
  {
    "text": "training evaluating suggesting and then retraining based on the tags you put in",
    "start": "2425230",
    "end": "2431290"
  },
  {
    "text": "play in this example though I'm actually going to use the visual object tagging",
    "start": "2431290",
    "end": "2436630"
  },
  {
    "text": "tool by Microsoft and the reason I like this tool is because it actually stores",
    "start": "2436630",
    "end": "2442780"
  },
  {
    "text": "all the tags in a platform agnostic format so it just stores it as a massive",
    "start": "2442780",
    "end": "2448540"
  },
  {
    "text": "JSON file so it means whether you're using custom vision or tensorflow or",
    "start": "2448540",
    "end": "2454359"
  },
  {
    "text": "Santa kay or any framework you want you can tag once reuse everywhere so I've",
    "start": "2454359",
    "end": "2462310"
  },
  {
    "text": "gone through and tagged 307 images of all different types of fruit and vege if",
    "start": "2462310",
    "end": "2468730"
  },
  {
    "text": "you'd like a copy of the data set let me know so you don't have to go through the same thing again and we really have a",
    "start": "2468730",
    "end": "2475359"
  },
  {
    "text": "whole lot of different images containing both single and multiple bits of fruit",
    "start": "2475359",
    "end": "2482020"
  },
  {
    "text": "from here we can actually export it directly into the custom vision portal so we don't even need to worry about",
    "start": "2482020",
    "end": "2488020"
  },
  {
    "text": "writing a plug-in between the two so if I remove this live object project and",
    "start": "2488020",
    "end": "2499260"
  },
  {
    "text": "grab my training key we can actually use that to upload so I'm going to delete live object now there is a bit of a",
    "start": "2499260",
    "end": "2509650"
  },
  {
    "text": "quirk with the visual object training tool in that it will want to create a project with its own name so I'm going",
    "start": "2509650",
    "end": "2515830"
  },
  {
    "text": "to come in here select custom vision service and paste in my training key this is going to go through now and",
    "start": "2515830",
    "end": "2522610"
  },
  {
    "text": "actually begin uploading all those images on my behalf if we come back to",
    "start": "2522610",
    "end": "2527800"
  },
  {
    "text": "the custom vision portal we should actually see now a brand new project",
    "start": "2527800",
    "end": "2534750"
  },
  {
    "text": "loads brand new project called vo TTX port which contains all of those",
    "start": "2534750",
    "end": "2540370"
  },
  {
    "text": "annotations in the custom vision format so we didn't need to translate it at all",
    "start": "2540370",
    "end": "2546160"
  },
  {
    "text": "and it's going to go through and it's going to sit there for a couple of minutes because as we say it's 307",
    "start": "2546160",
    "end": "2551620"
  },
  {
    "text": "images of varying quality but from here we train an object detection model in",
    "start": "2551620",
    "end": "2559360"
  },
  {
    "text": "the exact same way there we go we're finished we can open up our export click",
    "start": "2559360",
    "end": "2567820"
  },
  {
    "text": "the train button and it will perform all the training operations for us using VMs",
    "start": "2567820",
    "end": "2576220"
  },
  {
    "text": "and whatnot under the hood we don't really care we don't have to manage that infrastructure now for 307 images on",
    "start": "2576220",
    "end": "2583600"
  },
  {
    "text": "object detection it does take about five to six minutes give or take how many people are using the service at once so",
    "start": "2583600",
    "end": "2591010"
  },
  {
    "text": "instead of spending too much time here I'm actually going to jump across to a pre trained model on the exact same",
    "start": "2591010",
    "end": "2598540"
  },
  {
    "text": "images so I've got an object detection project over here generated by exactly",
    "start": "2598540",
    "end": "2605740"
  },
  {
    "text": "the same mechanism so exactly the same data set even that same first image so",
    "start": "2605740",
    "end": "2611770"
  },
  {
    "text": "if we come to the performance tab we can see that we've got our iteration but we also have a third",
    "start": "2611770",
    "end": "2619380"
  },
  {
    "text": "third metric or third third piece of information that we need to have a bit of a think about and that's how accurate",
    "start": "2619380",
    "end": "2626500"
  },
  {
    "text": "the bounding boxes were now all of these descriptions are very very generalized",
    "start": "2626500",
    "end": "2631930"
  },
  {
    "text": "and not too detailed but the whole idea is we should be able to infer what's happening here rather than know what's",
    "start": "2631930",
    "end": "2638650"
  },
  {
    "text": "happening below Hynde the scenes with the machine learning model the same way as we did before we can click on quick",
    "start": "2638650",
    "end": "2644110"
  },
  {
    "text": "tests and provide it with in this case now sample images we had before with bad",
    "start": "2644110",
    "end": "2651070"
  },
  {
    "text": "lighting edges wrong and you'll note here we actually get three boxes remember before where I said object",
    "start": "2651070",
    "end": "2658000"
  },
  {
    "text": "detection gives you lots and lots of bounding boxes well if I turn the probability threshold all the way down",
    "start": "2658000",
    "end": "2664060"
  },
  {
    "text": "we get a lot of boxes this is where in the same way we used confidences before",
    "start": "2664060",
    "end": "2671050"
  },
  {
    "text": "to determine what the image was we need to use confidences again to determine",
    "start": "2671050",
    "end": "2676390"
  },
  {
    "text": "how likely it is that that object is in this image so by turning the threshold",
    "start": "2676390",
    "end": "2681820"
  },
  {
    "text": "up to say 61% you'll notice were only left with one item in there a carrot",
    "start": "2681820",
    "end": "2687910"
  },
  {
    "text": "predicted with ninety five point eight percent probability in the same way we",
    "start": "2687910",
    "end": "2693790"
  },
  {
    "text": "can grab an avocado pass it through and we get an avocado",
    "start": "2693790",
    "end": "2698860"
  },
  {
    "text": "it's remembered my threshold so I don't need to reset it so that's object",
    "start": "2698860",
    "end": "2704050"
  },
  {
    "text": "detection from new project to fully working model once again in give or take",
    "start": "2704050",
    "end": "2709360"
  },
  {
    "text": "five minutes time this unless unless you've got a really big background in",
    "start": "2709360",
    "end": "2714400"
  },
  {
    "text": "data science it isn't really possible with off-the-shelf frameworks so how do",
    "start": "2714400",
    "end": "2720460"
  },
  {
    "text": "we use this well in the same way we saw a training API before there's a",
    "start": "2720460",
    "end": "2725770"
  },
  {
    "text": "predictions API that we can actually call custom vision with so we use the",
    "start": "2725770",
    "end": "2730960"
  },
  {
    "text": "training API to upload the original image set back in the very first example we can now use the prediction API to",
    "start": "2730960",
    "end": "2739630"
  },
  {
    "start": "2736000",
    "end": "2942000"
  },
  {
    "text": "actually predict what's happening so I've got a small program here that sets",
    "start": "2739630",
    "end": "2745990"
  },
  {
    "text": "up a thread for webcam capture and a thread for diction's and it's just so that it",
    "start": "2745990",
    "end": "2752140"
  },
  {
    "text": "doesn't slow down OpenCV when it's doing its thing what we're gonna do is every",
    "start": "2752140",
    "end": "2758319"
  },
  {
    "text": "two to two to three times a frame we're going to take a copy of what's on the",
    "start": "2758319",
    "end": "2763839"
  },
  {
    "text": "webcam send it up to the custom vision service have it evaluate and send us back down the results from there we're",
    "start": "2763839",
    "end": "2771130"
  },
  {
    "text": "actually going to display it on screen in reality what this looks like is taking in a buffer and image calling",
    "start": "2771130",
    "end": "2780549"
  },
  {
    "text": "predict image with no store so we're not we're not wanting to store the results of whether this was successful or not",
    "start": "2780549",
    "end": "2786940"
  },
  {
    "text": "and then we get back those bounding boxes in the same way we've got them in the UI so I'm gonna keep this guy off",
    "start": "2786940",
    "end": "2795339"
  },
  {
    "text": "and we should actually be able to now point the laptop towards the apples and",
    "start": "2795339",
    "end": "2801569"
  },
  {
    "text": "have it recognized the different apples within the image itself I just realized",
    "start": "2801569",
    "end": "2807519"
  },
  {
    "text": "I didn't set up my startup project for the second time this presentation",
    "start": "2807519",
    "end": "2812730"
  },
  {
    "text": "awesome so we get our webcam feed and the webcam feeds happening at about 20",
    "start": "2818720",
    "end": "2824540"
  },
  {
    "text": "frames per second as I said before the image upload there's a little bit slower",
    "start": "2824540",
    "end": "2829700"
  },
  {
    "text": "but there we go hey and we can begin to throw more and more items in now you'll",
    "start": "2829700",
    "end": "2836780"
  },
  {
    "text": "notice that the probability threshold is set a little bit low here because we're getting a carrot on the left hand side",
    "start": "2836780",
    "end": "2842060"
  },
  {
    "text": "and this is where it is a little bit of an art in terms of picking those thresholds if I was to move this across",
    "start": "2842060",
    "end": "2848960"
  },
  {
    "text": "a little bit I'm pretty sure it will actually kick that out of the image yeah there we go so successfully grabbed a carrot Pink",
    "start": "2848960",
    "end": "2856010"
  },
  {
    "text": "Lady Apple and a granny smith apple so we've been able to tell the difference between two apples even though they look",
    "start": "2856010",
    "end": "2861050"
  },
  {
    "text": "pretty much the same and this even works right down to things like avocados and whatever we've actually trained our data",
    "start": "2861050",
    "end": "2867710"
  },
  {
    "text": "set on it's not an onion now I love this",
    "start": "2867710",
    "end": "2873109"
  },
  {
    "text": "because I always say something big and fabulous like that there we go avvocato what I've actually got with this data",
    "start": "2873109",
    "end": "2880280"
  },
  {
    "text": "set which is rather interesting and I'd like to take a couple of seconds to discuss is it's very biased there isn't",
    "start": "2880280",
    "end": "2887480"
  },
  {
    "text": "a lot of difference in terms of the fruit and veg inside there they're not on different backgrounds they're not",
    "start": "2887480",
    "end": "2893690"
  },
  {
    "text": "shot with different lighting conditions it's very very particular about the data",
    "start": "2893690",
    "end": "2899030"
  },
  {
    "text": "set that I've put in and in return I get very particular results out there's",
    "start": "2899030",
    "end": "2904369"
  },
  {
    "text": "certain answer this like overfitting and whatnot but having a biased data set when you're only taking a certain",
    "start": "2904369",
    "end": "2911000"
  },
  {
    "text": "environmental setting into consideration really affects the output that you get so what I'm actually doing every time I",
    "start": "2911000",
    "end": "2917690"
  },
  {
    "text": "show off the demo similar to this I'm actually capturing all these images and then I'm gonna take them back and use",
    "start": "2917690",
    "end": "2923810"
  },
  {
    "text": "them to retrain the model again to basically make it more aware of different lighting conditions different",
    "start": "2923810",
    "end": "2930109"
  },
  {
    "text": "environments whether it's halogen or LED lights in the ceiling that sort of thing so close that guy off",
    "start": "2930109",
    "end": "2940990"
  },
  {
    "start": "2942000",
    "end": "3389000"
  },
  {
    "text": "let's jump back and have a bit of a bit of a recap and finish up so object",
    "start": "2942030",
    "end": "2949300"
  },
  {
    "text": "detection is fantastic but I just want everyone to be aware there are some limitations to it the big kickers are",
    "start": "2949300",
    "end": "2955960"
  },
  {
    "text": "it's still in preview it's only been out a couple of months and as such there's no paid tiers or SLA s for it",
    "start": "2955960",
    "end": "2962920"
  },
  {
    "text": "so you're kind of at the limit of at at the mercy of the rate limits that are in",
    "start": "2962920",
    "end": "2969010"
  },
  {
    "text": "play so you notice there I was only processing 2 or 3 frames per second if I hit it too aggressively it'll actually",
    "start": "2969010",
    "end": "2975310"
  },
  {
    "text": "say wolf slow down a second when it's released and actually available as a paid service you can hit a lot more",
    "start": "2975310",
    "end": "2981580"
  },
  {
    "text": "aggressively and I've had co-workers stream up to 10 to 15 frames a second up",
    "start": "2981580",
    "end": "2987010"
  },
  {
    "text": "to custom vision to do classification and it handled it without any issues at all there's also no ability to export",
    "start": "2987010",
    "end": "2995430"
  },
  {
    "text": "object detection models at the moment now cognitive services as a whole is a",
    "start": "2995430",
    "end": "3003840"
  },
  {
    "text": "really interesting concept we have all this power of machine learning and AI at",
    "start": "3003840",
    "end": "3009090"
  },
  {
    "text": "our fingertips without actually needing to know how the models work and at its",
    "start": "3009090",
    "end": "3014970"
  },
  {
    "text": "core I really consider cognitive services as a development accelerator using API instead of fighting with",
    "start": "3014970",
    "end": "3022109"
  },
  {
    "text": "frameworks we shouldn't have to reinvent the wheel every time we want to do image",
    "start": "3022109",
    "end": "3027119"
  },
  {
    "text": "recognition on lateral natural language understanding they're great for proof of concepts and production services alike",
    "start": "3027119",
    "end": "3033840"
  },
  {
    "text": "and a super low barrier to entry are they the solution to every single",
    "start": "3033840",
    "end": "3039090"
  },
  {
    "text": "problem not necessarily so what happens when you find something that's beyond",
    "start": "3039090",
    "end": "3045000"
  },
  {
    "text": "cognitive services and I'm really talking about the image recognition and computer vision area here well you've",
    "start": "3045000",
    "end": "3052170"
  },
  {
    "text": "got things like the Azure machine learning platform services which are fantastic you gain more control but you",
    "start": "3052170",
    "end": "3058890"
  },
  {
    "text": "still don't have to worry about managing VMs but what if you still find that isn't enough well that's when you can",
    "start": "3058890",
    "end": "3065670"
  },
  {
    "text": "look at breaking out the frameworks and there's nothing wrong with breaking out tensorflow or cindy kaye you can apply",
    "start": "3065670",
    "end": "3072540"
  },
  {
    "text": "the same things that we've done here too though gaining more control but having greater",
    "start": "3072540",
    "end": "3078300"
  },
  {
    "text": "responsibility we've managed to deploy this model and get it up and running over an API without even thinking about",
    "start": "3078300",
    "end": "3085859"
  },
  {
    "text": "patching monitor monitoring hey cha da production izing the service itself",
    "start": "3085859",
    "end": "3091350"
  },
  {
    "text": "that's handled for us so when we want to move beyond object detection this is a",
    "start": "3091350",
    "end": "3099330"
  },
  {
    "text": "little bit more of an interesting concept well we could look at things like rotated bounding boxes when we",
    "start": "3099330",
    "end": "3106260"
  },
  {
    "text": "looked at images of carrots a carrot doesn't really fit into a square or a rectangle it's rotated at an angle so",
    "start": "3106260",
    "end": "3113609"
  },
  {
    "text": "it's closer to the actual shape and it's an extension of this you can actually look at polygonal segmentation where you",
    "start": "3113609",
    "end": "3120420"
  },
  {
    "text": "actually draw the outline of the object itself now with each of these they",
    "start": "3120420",
    "end": "3126180"
  },
  {
    "text": "become more and more computationally intense meaning that the power to drive",
    "start": "3126180",
    "end": "3131250"
  },
  {
    "text": "them you basically at the point of doing mascara noon for example as as a model",
    "start": "3131250",
    "end": "3137100"
  },
  {
    "text": "you do need a GPU otherwise you're right down at a minute or so to generate a",
    "start": "3137100",
    "end": "3142200"
  },
  {
    "text": "single frame these do give you fine-grained shapes though a great",
    "start": "3142200",
    "end": "3148140"
  },
  {
    "text": "example of where this is used is on mapping services to actually determine the shape of a house you can use machine",
    "start": "3148140",
    "end": "3155520"
  },
  {
    "text": "learning to actually pick up what what shape is the house itself and another",
    "start": "3155520",
    "end": "3160830"
  },
  {
    "text": "cool concept and this is what I'm playing with at the moment is different final layers instead of just outputting",
    "start": "3160830",
    "end": "3167430"
  },
  {
    "text": "is it an apple is it an orange where is the Apple in this image how about",
    "start": "3167430",
    "end": "3172740"
  },
  {
    "text": "reading the value off a dial representing a color as an output or",
    "start": "3172740",
    "end": "3178260"
  },
  {
    "text": "outputting an emoji the final step is complete custom models and I like to put",
    "start": "3178260",
    "end": "3185609"
  },
  {
    "text": "this in because everything that we've looked at today does serve a purpose and it's a great tool to have in your",
    "start": "3185609",
    "end": "3190650"
  },
  {
    "text": "arsenal but there are situations where you will need to break out data scientist mode and do everything down to",
    "start": "3190650",
    "end": "3197670"
  },
  {
    "text": "the lowest layer so to finish up I've got a bit of a challenge for everyone in the room I want you to give custom",
    "start": "3197670",
    "end": "3205020"
  },
  {
    "text": "vision ago I want you to start with just a few images and see what you can make happen and",
    "start": "3205020",
    "end": "3210990"
  },
  {
    "text": "isn't an extension of that have a play around with the cognitive services there's free trials available on the",
    "start": "3210990",
    "end": "3216600"
  },
  {
    "text": "website itself so you don't even need to sign up and I really feel the custom vision has such a low barrier to entry",
    "start": "3216600",
    "end": "3222330"
  },
  {
    "text": "that even people that don't have a programming background can begin doing",
    "start": "3222330",
    "end": "3227520"
  },
  {
    "text": "image classification tasks straight away so on that note I'd like to say thank",
    "start": "3227520",
    "end": "3234060"
  },
  {
    "text": "you hopefully you've enjoyed today and yeah any questions at all cool I was",
    "start": "3234060",
    "end": "3245490"
  },
  {
    "text": "about to say we've got five minutes yes",
    "start": "3245490",
    "end": "3249170"
  },
  {
    "text": "it's not any public roadmaps let's go",
    "start": "3257740",
    "end": "3264170"
  },
  {
    "text": "with that object detection at the edge so being able to export those models and",
    "start": "3264170",
    "end": "3270140"
  },
  {
    "text": "run them anywhere it's currently not on the public road map with with anything",
    "start": "3270140",
    "end": "3275270"
  },
  {
    "text": "this time of year keep an eye out for ignite happening next week there's normally a couple of announcements and",
    "start": "3275270",
    "end": "3280610"
  },
  {
    "text": "bits and pieces though it is a very very heavily requested feature if you do find",
    "start": "3280610",
    "end": "3286370"
  },
  {
    "text": "you're in that sort of scenario you can just fall back straight to tensorflow and there's a whole lot of examples on how to do that but it's not as nice as",
    "start": "3286370",
    "end": "3292250"
  },
  {
    "text": "as a service cool yes ah so the exported",
    "start": "3292250",
    "end": "3302900"
  },
  {
    "text": "component that you get is actually converted from its internal format to tensorflow the reason it originally started as",
    "start": "3302900",
    "end": "3309890"
  },
  {
    "text": "tensorflow is the dockerfile option wasn't originally there tensorflow was just a way to actually run these models",
    "start": "3309890",
    "end": "3316550"
  },
  {
    "text": "on an Android phone the original release of custom vision export was just to run on phones not on",
    "start": "3316550",
    "end": "3322700"
  },
  {
    "text": "edge devices so a whole lot of people actually started playing around with tensorflow as a model format and soon",
    "start": "3322700",
    "end": "3329870"
  },
  {
    "text": "enough everyone was exporting Android phone images from custom vision to run them in a number of different scenarios",
    "start": "3329870",
    "end": "3337030"
  },
  {
    "text": "you can force it into CNT Kay if you'd like to do that I haven't heard on any",
    "start": "3337030",
    "end": "3344000"
  },
  {
    "text": "official CNT Kay export formats good",
    "start": "3344000",
    "end": "3350600"
  },
  {
    "text": "question it's it's kind of magic sauce i can assume CNT K from the way the layers",
    "start": "3350600",
    "end": "3359120"
  },
  {
    "text": "are described and the output names seem very very much defaults ent K labels but",
    "start": "3359120",
    "end": "3366410"
  },
  {
    "text": "there isn't any yeah it's not a not a published thing so as I say sandy K is",
    "start": "3366410",
    "end": "3372290"
  },
  {
    "text": "what I assume but yeah cool alright we'll leave it there feel free to come",
    "start": "3372290",
    "end": "3377840"
  },
  {
    "text": "up and grab a piece of fruit or veg if you'd like I've got two avocados if anyone really wants smash Davo in the",
    "start": "3377840",
    "end": "3384470"
  },
  {
    "text": "afternoon and yeah have a great rest of the day [Applause]",
    "start": "3384470",
    "end": "3391629"
  }
]
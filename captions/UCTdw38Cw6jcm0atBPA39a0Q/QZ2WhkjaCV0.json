[
  {
    "text": "all right let's get started good evening or good afternoon good",
    "start": "6259",
    "end": "12059"
  },
  {
    "text": "evening everyone this is the last session of the day my name is Ron dagdag today I will be talking about making",
    "start": "12059",
    "end": "20220"
  },
  {
    "text": "neural network neural network uh run in browser with",
    "start": "20220",
    "end": "25500"
  },
  {
    "text": "onyx my name is Ron dagdag I'm a director of software engineering at Spacey I'm based",
    "start": "25500",
    "end": "33120"
  },
  {
    "text": "in Texas and I'm also a Microsoft MVP and AI MVP",
    "start": "33120",
    "end": "38700"
  },
  {
    "text": "all right if you are a Pokemon fan I'm sorry I'm not going to be talking about",
    "start": "38700",
    "end": "44399"
  },
  {
    "text": "the Pokemon Onyx over there so and also um I heard that also in Australia they",
    "start": "44399",
    "end": "51539"
  },
  {
    "text": "also have the Onyx mineral also their mind here I'm not going to be talking about that we're going to be talking",
    "start": "51539",
    "end": "57420"
  },
  {
    "text": "about o-n-n-x what is onnx we'll talk more about when",
    "start": "57420",
    "end": "64320"
  },
  {
    "text": "you should use this but let's go back to the basics and",
    "start": "64320",
    "end": "69479"
  },
  {
    "text": "talk about what is programming typically when you're programming right",
    "start": "69479",
    "end": "76200"
  },
  {
    "text": "you have an input then you create and write an algorithm",
    "start": "76200",
    "end": "82200"
  },
  {
    "text": "like for example in Java or in in Python you would create your your code and like",
    "start": "82200",
    "end": "89040"
  },
  {
    "text": "in this case we're creating a calculator and then it would spit out answers right",
    "start": "89040",
    "end": "94500"
  },
  {
    "text": "it would it would generate the answers for you with those two inputs",
    "start": "94500",
    "end": "100700"
  },
  {
    "text": "for machine learning it's like the other way around the goal is to be able to teach the",
    "start": "100799",
    "end": "108000"
  },
  {
    "text": "computer to create an algorithm for you and it needs lots and lots and lots of",
    "start": "108000",
    "end": "114720"
  },
  {
    "text": "examples or answers so you need both input and then answers and then it would",
    "start": "114720",
    "end": "120180"
  },
  {
    "text": "generate an algorithm for you right and you'll see that you know if you're",
    "start": "120180",
    "end": "126060"
  },
  {
    "text": "in the previous presentation a lot of the AI and the",
    "start": "126060",
    "end": "132000"
  },
  {
    "text": "Machine learning um topics they do this right they you have",
    "start": "132000",
    "end": "137099"
  },
  {
    "text": "to have a bunch of images you have to tag those images in order to create a uh you know like a custom Vision or",
    "start": "137099",
    "end": "144239"
  },
  {
    "text": "computer vision language",
    "start": "144239",
    "end": "149700"
  },
  {
    "text": "so as an ml primer programming is on the right side machine learning on the left side okay",
    "start": "149700",
    "end": "158879"
  },
  {
    "text": "in machine learning world that's what we call training data and you need a training prep framework",
    "start": "158879",
    "end": "165379"
  },
  {
    "text": "in order to create a model it's a generator model and that's what",
    "start": "165379",
    "end": "171120"
  },
  {
    "text": "you would use and substitute with that algorithm and in order to use that model",
    "start": "171120",
    "end": "177060"
  },
  {
    "text": "you would need the written machine learning we call that inferencing and then you need an inferencing runtime",
    "start": "177060",
    "end": "185220"
  },
  {
    "text": "in order to complete a cycle and of course now that you have all the",
    "start": "185220",
    "end": "191280"
  },
  {
    "text": "answers and it's a feedback loop to improve the model",
    "start": "191280",
    "end": "197900"
  },
  {
    "text": "when I first saw this concept",
    "start": "198720",
    "end": "203879"
  },
  {
    "text": "suddenly it started to make sense to me what there's what everyone's talking about what's the",
    "start": "203879",
    "end": "210540"
  },
  {
    "text": "power of these machine learning and we'll talk more about this but we'll",
    "start": "210540",
    "end": "215580"
  },
  {
    "text": "go back to to uh you know the work we create this model okay",
    "start": "215580",
    "end": "224159"
  },
  {
    "text": "so typically if you have a data scientist and a lot of data scientists these days they talk about they know a",
    "start": "224159",
    "end": "231720"
  },
  {
    "text": "lot of python and they would use their favorite uh you know machine learning",
    "start": "231720",
    "end": "237360"
  },
  {
    "text": "framework in this case let's say you they're trained using pi torch and they",
    "start": "237360",
    "end": "243480"
  },
  {
    "text": "run it locally on their device on their machine right but I found out if you're a JavaScript",
    "start": "243480",
    "end": "250140"
  },
  {
    "text": "developer there's a lot of JavaScript framework the same way in machine learning there's",
    "start": "250140",
    "end": "256019"
  },
  {
    "text": "also a lot of machine learning framework that is available out there one of the most common ones are of course",
    "start": "256019",
    "end": "262560"
  },
  {
    "text": "tensorflow and Keras and of course pytorch is one of the most",
    "start": "262560",
    "end": "269100"
  },
  {
    "text": "that's a lot of notice a lot of them you know coming out of school they they are",
    "start": "269100",
    "end": "275160"
  },
  {
    "text": "used to that and of course you have different places where you would execute",
    "start": "275160",
    "end": "281540"
  },
  {
    "text": "these models right or these your program it's not just we're not just limited to",
    "start": "281540",
    "end": "288020"
  },
  {
    "text": "laptops anymore we have to run it on phones we haven't",
    "start": "288020",
    "end": "293280"
  },
  {
    "text": "run it on iot devices we run it on the cloud different ways and how you would",
    "start": "293280",
    "end": "298440"
  },
  {
    "text": "run these models and that's what Onyx solve",
    "start": "298440",
    "end": "306540"
  },
  {
    "text": "think about Onyx it's kind of like how the PDF works right",
    "start": "306540",
    "end": "312560"
  },
  {
    "text": "you create let's say Microsoft Word type your document",
    "start": "312560",
    "end": "318600"
  },
  {
    "text": "you export it to a PDF and now you have different places where you can view that that document you can",
    "start": "318600",
    "end": "327600"
  },
  {
    "text": "view it on Kindle so yeah except those PDF browser phone everywhere else",
    "start": "327600",
    "end": "334259"
  },
  {
    "text": "so think of it that way so Onyx is open neural network Exchange",
    "start": "334259",
    "end": "341120"
  },
  {
    "text": "it's an open format for machine learning models it is open source on it's on",
    "start": "341120",
    "end": "348539"
  },
  {
    "text": "GitHub github.com Onyx and the best place to learn about these is going",
    "start": "348539",
    "end": "355139"
  },
  {
    "text": "through any onyx.ai",
    "start": "355139",
    "end": "358800"
  },
  {
    "text": "it got started with partnership with Microsoft and Facebook but through time",
    "start": "361740",
    "end": "368220"
  },
  {
    "text": "more and more every time I would do a presentation about this one more company signs up on this list",
    "start": "368220",
    "end": "376979"
  },
  {
    "text": "that they ended notice that they're not limited to software but also Hardware",
    "start": "376979",
    "end": "382380"
  },
  {
    "text": "companies are all are supporting the Onyx format",
    "start": "382380",
    "end": "389300"
  },
  {
    "text": "of course it's on GitHub it has about you know 2.7",
    "start": "389699",
    "end": "395639"
  },
  {
    "text": "of GitHub Force you know 12 000 GitHub Stars it is actually a graduate of the",
    "start": "395639",
    "end": "401940"
  },
  {
    "text": "Linux Foundation AI project so it is ready for production use",
    "start": "401940",
    "end": "408539"
  },
  {
    "text": "so when should you use the Onyx format well if you have something like we said",
    "start": "408539",
    "end": "415199"
  },
  {
    "text": "you know if you have data scientists they know python or you you know someone that has",
    "start": "415199",
    "end": "421919"
  },
  {
    "text": "debt.net experience have used ml.net and now you want to integrate it with your",
    "start": "421919",
    "end": "427979"
  },
  {
    "text": "existing c-sharp application or Java application or JavaScript application",
    "start": "427979",
    "end": "433259"
  },
  {
    "text": "that's when it makes sense to convert it to Onyx and then integrate it with that",
    "start": "433259",
    "end": "439500"
  },
  {
    "text": "existing application you know a lot of data scientists in my company",
    "start": "439500",
    "end": "447599"
  },
  {
    "text": "they they know a lot of Pi torch and I can you know containerizing a pie torch",
    "start": "447599",
    "end": "455099"
  },
  {
    "text": "Model A Docker image it is actually about almost four gig already imagine if",
    "start": "455099",
    "end": "461520"
  },
  {
    "text": "you have to do deployment and the framework itself incorporating that every time in order to run your",
    "start": "461520",
    "end": "468240"
  },
  {
    "text": "application I mean that's not going to fit very well on on smaller devices",
    "start": "468240",
    "end": "473639"
  },
  {
    "text": "so you also want to use Onyx when you need a high inferencing latency that",
    "start": "473639",
    "end": "479819"
  },
  {
    "text": "means you really need fast results for production use that means you're running it",
    "start": "479819",
    "end": "486360"
  },
  {
    "text": "specifically for that machine or that device and um",
    "start": "486360",
    "end": "491880"
  },
  {
    "text": "and you know you running it locally instead of the cloud",
    "start": "491880",
    "end": "498780"
  },
  {
    "text": "when you have a Model A model that that you want to run on an iot or Edge",
    "start": "498780",
    "end": "504300"
  },
  {
    "text": "devices so the Azure percept device is a good example it uses Onyx in order to run",
    "start": "504300",
    "end": "512760"
  },
  {
    "text": "their models and if you have if you want to run it on a different operating system for Hardware",
    "start": "512760",
    "end": "519000"
  },
  {
    "text": "that would be a good use case so it's not just limited to you know Windows machine you can run this on Windows also",
    "start": "519000",
    "end": "526320"
  },
  {
    "text": "in Linux a different Hardware too so not just",
    "start": "526320",
    "end": "531920"
  },
  {
    "text": "AMD but also or or Intel chip but also arm processors as possible to do this",
    "start": "531920",
    "end": "540300"
  },
  {
    "text": "there's also a way you can combine different models let's say in a big company you have models that were",
    "start": "540300",
    "end": "547200"
  },
  {
    "text": "generated in Keras and then you have also models that are generated in pi",
    "start": "547200",
    "end": "554220"
  },
  {
    "text": "torch and now you want to Pi you know create a pipeline where you you know you",
    "start": "554220",
    "end": "559320"
  },
  {
    "text": "run inferencing from the other or you know that allows you to be able to have just one",
    "start": "559320",
    "end": "566420"
  },
  {
    "text": "place where you can run this and then there's also Transformer models where you can have training locally instead of",
    "start": "567360",
    "end": "575100"
  },
  {
    "text": "sending it remote so our agenda today we",
    "start": "575100",
    "end": "582899"
  },
  {
    "text": "you know we talked about what is onyx and then the next step is how do we",
    "start": "582899",
    "end": "588060"
  },
  {
    "text": "create these Onyx model and how do we deploy them to",
    "start": "588060",
    "end": "594320"
  },
  {
    "text": "deploy these devices so this is a good summary of what we're going to do right",
    "start": "594320",
    "end": "601440"
  },
  {
    "text": "so we create the framework oh we we we convert it to Onyx model and now you can",
    "start": "601440",
    "end": "608459"
  },
  {
    "text": "deploy it just on the Windows devices iot Edge devices and all",
    "start": "608459",
    "end": "613980"
  },
  {
    "text": "that so I started talking about Onyx model there is a way you can visualize once",
    "start": "613980",
    "end": "621720"
  },
  {
    "text": "you convert an onyx model and there is an open source",
    "start": "621720",
    "end": "628080"
  },
  {
    "text": "application called netron.app or even if you go to netron.app and you drop a an",
    "start": "628080",
    "end": "634200"
  },
  {
    "text": "onyx model it actually visualizes what is the input and output of that",
    "start": "634200",
    "end": "641040"
  },
  {
    "text": "model let's see if we can we can do that real quick",
    "start": "641040",
    "end": "646700"
  },
  {
    "text": "yeah we'll we'll go back to this once I continue on with the demo",
    "start": "648300",
    "end": "653880"
  },
  {
    "text": "so first we're going to create the model how do we create them",
    "start": "653880",
    "end": "660620"
  },
  {
    "text": "okay so backstory um when we when the pandemic",
    "start": "661019",
    "end": "667200"
  },
  {
    "text": "got started and bread is kind of limited in our neighborhood you know you have",
    "start": "667200",
    "end": "673440"
  },
  {
    "text": "you can't just easily buy bread we started using our bread maker it's our",
    "start": "673440",
    "end": "680040"
  },
  {
    "text": "first time to use our bread maker it was a uh it was a wedding gift for us but we",
    "start": "680040",
    "end": "686940"
  },
  {
    "text": "didn't use it because it's just easy to buy bread we found out okay let's make some bread",
    "start": "686940",
    "end": "692519"
  },
  {
    "text": "our first try didn't work we didn't know the secret recipe we you know I guess we",
    "start": "692519",
    "end": "698339"
  },
  {
    "text": "found out that you have to use warm water instead of like cold water and we",
    "start": "698339",
    "end": "704220"
  },
  {
    "text": "used cold water it didn't turn out right so what I'm trying to say here is that the data scientist in your company",
    "start": "704220",
    "end": "711000"
  },
  {
    "text": "they're the ones responsible to figure out what's the secret recipe of your company right they experiment and try",
    "start": "711000",
    "end": "718620"
  },
  {
    "text": "out different ways and how do you would create this model so that uh you know so what would be the",
    "start": "718620",
    "end": "726060"
  },
  {
    "text": "most effective views for that data",
    "start": "726060",
    "end": "730700"
  },
  {
    "text": "so three ways on how you would create that Onyx model right one is through the",
    "start": "731220",
    "end": "737160"
  },
  {
    "text": "Onyx model Zoo the custom vision service and then converting existing models",
    "start": "737160",
    "end": "744720"
  },
  {
    "text": "let's start with how you would create the model zoo on GitHub if you go to",
    "start": "744720",
    "end": "750000"
  },
  {
    "text": "this link all a lot of existing",
    "start": "750000",
    "end": "755459"
  },
  {
    "text": "um models that are out there so especially on image classification they already did",
    "start": "755459",
    "end": "762660"
  },
  {
    "text": "convert from you know let's say however it's trained let's say in pi torch they",
    "start": "762660",
    "end": "769139"
  },
  {
    "text": "converted it to Onyx already and it's free to download so if you just want to reference a model that is available out",
    "start": "769139",
    "end": "775980"
  },
  {
    "text": "there check out here first right maybe they already have it available for you so let's say if you're you know the one",
    "start": "775980",
    "end": "783480"
  },
  {
    "text": "of the popular ones are the red resnet device resnet model it's already",
    "start": "783480",
    "end": "788820"
  },
  {
    "text": "converted and you can just download that another one is through custom vision",
    "start": "788820",
    "end": "795660"
  },
  {
    "text": "service where you can upload so if you go to customvision.ai you can upload",
    "start": "795660",
    "end": "801120"
  },
  {
    "text": "some images and tag them like in this case I uploaded images of fruits and I",
    "start": "801120",
    "end": "806459"
  },
  {
    "text": "tag them hey these images are fruit and then I can click train and it would",
    "start": "806459",
    "end": "811800"
  },
  {
    "text": "create a model for me and then you can actually export it",
    "start": "811800",
    "end": "817800"
  },
  {
    "text": "to an onyx model there's also SDK so you can automate this process of uploading",
    "start": "817800",
    "end": "824399"
  },
  {
    "text": "to custom Vision training it and then exporting it to an onyx model",
    "start": "824399",
    "end": "831860"
  },
  {
    "text": "converting models is also another way there are there's three steps involved",
    "start": "833120",
    "end": "840959"
  },
  {
    "text": "in order to do this you load an existing model then convert it to Onyx then save",
    "start": "840959",
    "end": "846480"
  },
  {
    "text": "that Onyx model okay so pytorch should look something like this this is the most the simplest one I",
    "start": "846480",
    "end": "853920"
  },
  {
    "text": "can find and if you're not a python developer that's fine my point here is",
    "start": "853920",
    "end": "859139"
  },
  {
    "text": "that you can there is a library called torch.onics and you can just say",
    "start": "859139",
    "end": "864560"
  },
  {
    "text": "torch.onics.export you specify the model the sound output and then you're you're",
    "start": "864560",
    "end": "869639"
  },
  {
    "text": "good to go in this case this is a sample model that they have available out there",
    "start": "869639",
    "end": "876000"
  },
  {
    "text": "but there's already bindings for pi torch to do this for Keras the same way",
    "start": "876000",
    "end": "881639"
  },
  {
    "text": "too there is a way you can convert them using",
    "start": "881639",
    "end": "886920"
  },
  {
    "text": "um these Onyx ml tools so you you would do",
    "start": "886920",
    "end": "892920"
  },
  {
    "text": "pip install on XML tools and already have that capability for you",
    "start": "892920",
    "end": "899779"
  },
  {
    "text": "so it's not just code there's also command line that you can use especially in for the tensorflow you can convert it",
    "start": "899940",
    "end": "907680"
  },
  {
    "text": "using this so I just have it as a reference just in case you need to",
    "start": "907680",
    "end": "912920"
  },
  {
    "text": "visit it later on the best way to learn more about how you would uh learn how to",
    "start": "912920",
    "end": "919680"
  },
  {
    "text": "convert from you know existing models is using the tutorials on onyx",
    "start": "919680",
    "end": "927240"
  },
  {
    "text": "in GitHub okay um",
    "start": "927240",
    "end": "932399"
  },
  {
    "text": "the typical end-to-end process of how you would create these models and it is",
    "start": "932399",
    "end": "938880"
  },
  {
    "text": "um know how you would you know either you have it in Jupiter code or maybe you have it in Azure",
    "start": "938880",
    "end": "945120"
  },
  {
    "text": "machine learning right and you train it the advantage of azure machine learning",
    "start": "945120",
    "end": "950579"
  },
  {
    "text": "there's a way that you can register and this is the key part of it right the register and manage your model so it's",
    "start": "950579",
    "end": "957420"
  },
  {
    "text": "kind of like GitHub think about code right get this you have a repository of",
    "start": "957420",
    "end": "963959"
  },
  {
    "text": "the changes in your code every time you train a new model it's",
    "start": "963959",
    "end": "969000"
  },
  {
    "text": "the same concept too you're that's at the end of the day those are algorithms you want you want to be able to do uh",
    "start": "969000",
    "end": "976260"
  },
  {
    "text": "you have it in a repository and that's where you have that management and where you can register this model so that now",
    "start": "976260",
    "end": "982740"
  },
  {
    "text": "you can be integrated with your application",
    "start": "982740",
    "end": "987139"
  },
  {
    "text": "any questions so far as I know I'm talking about these is good",
    "start": "987899",
    "end": "994079"
  },
  {
    "text": "all right so now that we're able to create a model",
    "start": "994079",
    "end": "1000380"
  },
  {
    "text": "next step is to deploy but before I do that I wanted to do a little bit of demo",
    "start": "1000380",
    "end": "1005839"
  },
  {
    "text": "on how you would do this in ml.net okay since we have enough time",
    "start": "1005839",
    "end": "1012740"
  },
  {
    "text": "so I what I'm using here is I'm using visual studio code",
    "start": "1012740",
    "end": "1019820"
  },
  {
    "text": "and on Visual Studio code I'm using.net Interactive and on and Dot net interactive allows",
    "start": "1019820",
    "end": "1027319"
  },
  {
    "text": "you to be able to have a python notebook",
    "start": "1027319",
    "end": "1032780"
  },
  {
    "text": "that has instead of using python it's using C sharp as as your kernel",
    "start": "1032780",
    "end": "1040220"
  },
  {
    "text": "so in this case so I can show you line by line what happens when we run this application",
    "start": "1040220",
    "end": "1048380"
  },
  {
    "text": "okay so these are the nuget packages if you're using it in ml.net these are",
    "start": "1048380",
    "end": "1053660"
  },
  {
    "text": "nuget packages that you can use that you can incorporate to your application",
    "start": "1053660",
    "end": "1059539"
  },
  {
    "text": "so it's kind of like a node package and then",
    "start": "1059539",
    "end": "1066160"
  },
  {
    "text": "these are just the uh some using statements or reference for",
    "start": "1066200",
    "end": "1072679"
  },
  {
    "text": "for the code in this case I I'm loading a CSV file and this is my CSV file and this is what",
    "start": "1072679",
    "end": "1079820"
  },
  {
    "text": "it looks like I have two columns on that CSV file input and output Year's experience and",
    "start": "1079820",
    "end": "1088340"
  },
  {
    "text": "then salary just the simplest thing I can I can find out there that doesn't",
    "start": "1088340",
    "end": "1093500"
  },
  {
    "text": "you know it's it's contrived but if they have one input and one output",
    "start": "1093500",
    "end": "1098780"
  },
  {
    "text": "and so if I put data that description it tells",
    "start": "1098780",
    "end": "1104179"
  },
  {
    "text": "me I have 30 items on that list and what is the Min and Max the values on there",
    "start": "1104179",
    "end": "1110960"
  },
  {
    "text": "and in this case what I'm doing is I'm going to use ml.net in order to",
    "start": "1110960",
    "end": "1118580"
  },
  {
    "text": "create a model for me so in order to use that I have to create this new ml",
    "start": "1118580",
    "end": "1124700"
  },
  {
    "text": "context and then I create a pipeline I specify what is",
    "start": "1124700",
    "end": "1131539"
  },
  {
    "text": "the trainer how am I going to create this model and",
    "start": "1131539",
    "end": "1136580"
  },
  {
    "text": "and then train it okay and then evaluate okay",
    "start": "1136580",
    "end": "1144440"
  },
  {
    "text": "so my point here is not necessarily you know learning how to train my point here",
    "start": "1144440",
    "end": "1150799"
  },
  {
    "text": "is I wanted to show you that you can export the model to Onyx using this command",
    "start": "1150799",
    "end": "1159280"
  },
  {
    "text": "so once you have the model generated you have to pass three things right you pass",
    "start": "1159280",
    "end": "1166220"
  },
  {
    "text": "the model that was generated by ml.net and then you create the Stream",
    "start": "1166220",
    "end": "1172760"
  },
  {
    "text": "and then you would export it and if you open the file in",
    "start": "1172760",
    "end": "1179840"
  },
  {
    "text": "um Onyx neptron app it would look something like this",
    "start": "1179840",
    "end": "1186799"
  },
  {
    "text": "so you generated notice how it generated this model that onyx",
    "start": "1186799",
    "end": "1192260"
  },
  {
    "text": "so once it generated that model.onics I installed this netron app it would",
    "start": "1192260",
    "end": "1200179"
  },
  {
    "text": "look something like this it's kind of harder to see what why it looks",
    "start": "1200179",
    "end": "1206120"
  },
  {
    "text": "like that but usually visualize it right but my point here is that it tells you",
    "start": "1206120",
    "end": "1213020"
  },
  {
    "text": "what is the input for that model and it tells you what's the output of that model",
    "start": "1213020",
    "end": "1218240"
  },
  {
    "text": "so this would help developers software Engineers if they want to integrate once",
    "start": "1218240",
    "end": "1224360"
  },
  {
    "text": "they convert it to Onyx what is the input and output without going to going back to the developer",
    "start": "1224360",
    "end": "1230919"
  },
  {
    "text": "to to the data scientist and then we'll have that that information in this case",
    "start": "1230919",
    "end": "1236620"
  },
  {
    "text": "the this is a simple model it's not even neural network it was a regression and",
    "start": "1236620",
    "end": "1243500"
  },
  {
    "text": "it has years in experiences as as input and salary and then what we're",
    "start": "1243500",
    "end": "1249500"
  },
  {
    "text": "interested in here is the score that output which gives us the uh the result",
    "start": "1249500",
    "end": "1257240"
  },
  {
    "text": "of what it predicted that needs to be okay",
    "start": "1257240",
    "end": "1263660"
  },
  {
    "text": "so that is just an example of how you would do this in using ml.net",
    "start": "1263660",
    "end": "1271600"
  },
  {
    "text": "so now how do we deploy them",
    "start": "1272539",
    "end": "1276879"
  },
  {
    "text": "what is the difference between a baker and starting a bakery totally different",
    "start": "1278480",
    "end": "1283600"
  },
  {
    "text": "skill set right like we said you know",
    "start": "1283600",
    "end": "1288860"
  },
  {
    "text": "Bakers they figure out the secret recipe in order to have a good Bakery",
    "start": "1288860",
    "end": "1295700"
  },
  {
    "text": "I come from a software engineering background we know how to start the bakery that is",
    "start": "1295700",
    "end": "1301760"
  },
  {
    "text": "our expertise right if you think about how we put things together and create a pipeline",
    "start": "1301760",
    "end": "1307940"
  },
  {
    "text": "for our application we know how to collect the money we know how to",
    "start": "1307940",
    "end": "1313340"
  },
  {
    "text": "pass the data from one place to the other to process the data to create those business rules in order to you",
    "start": "1313340",
    "end": "1320960"
  },
  {
    "text": "know think about how the you know a baker can can can be the best baker in",
    "start": "1320960",
    "end": "1326840"
  },
  {
    "text": "the world but if they can't collect the money if they can't you get what I'm saying if they if they don't have a",
    "start": "1326840",
    "end": "1332539"
  },
  {
    "text": "system then they can't deliver it right and that's that's the main difference",
    "start": "1332539",
    "end": "1338659"
  },
  {
    "text": "right so deployment is very important whenever we create these models and how",
    "start": "1338659",
    "end": "1346640"
  },
  {
    "text": "to integrate it with our application like going back here where you specify and register and",
    "start": "1346640",
    "end": "1352880"
  },
  {
    "text": "manage the model now we can you know if we're running it in the cloud we can build an image where",
    "start": "1352880",
    "end": "1359360"
  },
  {
    "text": "we integrate whatever that model is and deploy it as a service so this is one way on how you would do it in Cloud",
    "start": "1359360",
    "end": "1366020"
  },
  {
    "text": "settings but in this case every time we have to work with these models we have to decide",
    "start": "1366020",
    "end": "1373640"
  },
  {
    "text": "are we going to run it in the cloud or are we going to run it at the edge meaning the inferencing side right so a",
    "start": "1373640",
    "end": "1380360"
  },
  {
    "text": "lot of examples out there whenever they you know for example the lot of the",
    "start": "1380360",
    "end": "1386299"
  },
  {
    "text": "cognitive services or the pre-trained AI That's available out there you need an",
    "start": "1386299",
    "end": "1392000"
  },
  {
    "text": "API key you upload these images you upload the sound and then it would give you the results",
    "start": "1392000",
    "end": "1398840"
  },
  {
    "text": "so that's pretty much running it in the cloud but there's also advantages of running it at the edge",
    "start": "1398840",
    "end": "1405500"
  },
  {
    "text": "if you think about it the good example of this is McDonald's versus Subway",
    "start": "1405500",
    "end": "1411860"
  },
  {
    "text": "and where do they make the bread right",
    "start": "1411860",
    "end": "1417039"
  },
  {
    "text": "how close it is to the customer so they can be flexible you know Subway can be",
    "start": "1417039",
    "end": "1423200"
  },
  {
    "text": "flexible because they make the bread at the store versus McDonald's They stores",
    "start": "1423200",
    "end": "1428419"
  },
  {
    "text": "the bread in the factory somewhere else so that's the main difference between between the two",
    "start": "1428419",
    "end": "1435740"
  },
  {
    "text": "of course what is the edge I have this image because",
    "start": "1435740",
    "end": "1442280"
  },
  {
    "text": "whenever you're deploying these models right so we have these Onyx models",
    "start": "1442280",
    "end": "1448400"
  },
  {
    "text": "now you have to think if it's in the cloud oh sorry where am I at",
    "start": "1448400",
    "end": "1454580"
  },
  {
    "text": "okay if it's in the cloud it did we",
    "start": "1454580",
    "end": "1460220"
  },
  {
    "text": "you're deploying to maybe you know different data centers right",
    "start": "1460220",
    "end": "1466580"
  },
  {
    "text": "there's also a concept of fog or node Computing so when you think about 5G and",
    "start": "1466580",
    "end": "1472640"
  },
  {
    "text": "how uh what it means is that you know your processing happens to on the tower",
    "start": "1472640",
    "end": "1479480"
  },
  {
    "text": "instead of you know back where you know Azure is we're a data center so it is",
    "start": "1479480",
    "end": "1485299"
  },
  {
    "text": "closer to the user but now you're if you're deploying models or you're deploying this code",
    "start": "1485299",
    "end": "1492260"
  },
  {
    "text": "now you have to think about millions of devices as compared to Edge devices if you're running it on the browser or",
    "start": "1492260",
    "end": "1499280"
  },
  {
    "text": "you're running it on your phones now you're talking about you know billions of devices so we just",
    "start": "1499280",
    "end": "1505760"
  },
  {
    "text": "do a good visualization of when you're running your application or running your",
    "start": "1505760",
    "end": "1511640"
  },
  {
    "text": "models uh there are different considerations where you would run them",
    "start": "1511640",
    "end": "1518960"
  },
  {
    "text": "so Onyx runtime is a high performance inference engine for Onyx model",
    "start": "1518960",
    "end": "1525799"
  },
  {
    "text": "it is actually started by uh and it's it is open source by Microsoft under MIT",
    "start": "1525799",
    "end": "1531620"
  },
  {
    "text": "license it's fully compatible with Onyx ml spec it",
    "start": "1531620",
    "end": "1537020"
  },
  {
    "text": "actually part of win Windows 10 if you're a Windows developer but Onyx runtime that AI allows you to be able to",
    "start": "1537020",
    "end": "1545559"
  },
  {
    "text": "select like in this case I want to I have a Linux I'm running it",
    "start": "1545559",
    "end": "1551600"
  },
  {
    "text": "on a Linux device I want to run it on C sharp and with that architecture",
    "start": "1551600",
    "end": "1558740"
  },
  {
    "text": "and I want to use the GPU it gives you instructions on how you would run these",
    "start": "1558740",
    "end": "1564500"
  },
  {
    "text": "models and incorporate your application in this case we have we're going to be",
    "start": "1564500",
    "end": "1571400"
  },
  {
    "text": "talking about this side right here where you have the web browser so it's not just limited to what",
    "start": "1571400",
    "end": "1577820"
  },
  {
    "text": "platform it is it's also your Onyx model can run on the browser iOS Android Mac and also different apis",
    "start": "1577820",
    "end": "1586600"
  },
  {
    "text": "so Onyx runtime is available for JavaScript and",
    "start": "1588340",
    "end": "1594200"
  },
  {
    "text": "there is a node.js binding also you can run it on the web and also",
    "start": "1594200",
    "end": "1601700"
  },
  {
    "text": "if you want to integrate it to your application you can use react native to do that",
    "start": "1601700",
    "end": "1608000"
  },
  {
    "text": "so let's start with Onyx runtime using node.js the it is for Onyx model",
    "start": "1608000",
    "end": "1614480"
  },
  {
    "text": "inferencing you can actually incorporate to an electron app and it uses webassembly",
    "start": "1614480",
    "end": "1623240"
  },
  {
    "text": "in order to install it in using node you know npm install Onyx runtime node",
    "start": "1623240",
    "end": "1630279"
  },
  {
    "text": "and you can use common.js",
    "start": "1630279",
    "end": "1636080"
  },
  {
    "text": "in order to incorporate it to your application so I'm going to show you a little bit of",
    "start": "1636080",
    "end": "1641960"
  },
  {
    "text": "demo what that looks like okay",
    "start": "1641960",
    "end": "1648460"
  },
  {
    "text": "yeah feel free to ask questions if you have",
    "start": "1650000",
    "end": "1656419"
  },
  {
    "text": "so this is using node I have this dependency I did npm install Onyx",
    "start": "1656419",
    "end": "1664279"
  },
  {
    "text": "runtime node can you all see that it's good so that is the latest version",
    "start": "1664279",
    "end": "1671179"
  },
  {
    "text": "in so I have this onyx model Onyx right",
    "start": "1671179",
    "end": "1676820"
  },
  {
    "text": "and this is how you would use it",
    "start": "1676820",
    "end": "1682220"
  },
  {
    "text": "so in this case uh there's three uh important things you have to consider",
    "start": "1682220",
    "end": "1688220"
  },
  {
    "text": "when you're running it right you have your importing right you have your Onyx runtime node",
    "start": "1688220",
    "end": "1694100"
  },
  {
    "text": "and you specify okay and now I'm going to load the Onyx model into memory",
    "start": "1694100",
    "end": "1699559"
  },
  {
    "text": "and then I have to pass the input and in order to pass the input in this",
    "start": "1699559",
    "end": "1705140"
  },
  {
    "text": "case right for my Onyx model I need two input because that's what it said on the",
    "start": "1705140",
    "end": "1710440"
  },
  {
    "text": "netron app and the input is years of experience and then salary even",
    "start": "1710440",
    "end": "1717620"
  },
  {
    "text": "though it's not being used it is required so that's the reason why I have",
    "start": "1717620",
    "end": "1722960"
  },
  {
    "text": "that there and you so",
    "start": "1722960",
    "end": "1729559"
  },
  {
    "text": "so this is a good visualization of how I know it's not being used and for this",
    "start": "1729640",
    "end": "1735200"
  },
  {
    "text": "simple example I have years of experience the data would get processed here and where no we",
    "start": "1735200",
    "end": "1741500"
  },
  {
    "text": "know that the score output is what what we actually need and the rest of them they're just passed through and not",
    "start": "1741500",
    "end": "1748460"
  },
  {
    "text": "being calculated okay so now if I once I pass in my data in",
    "start": "1748460",
    "end": "1757580"
  },
  {
    "text": "this case I'm going to put 15 right that is my input and how I know it's a",
    "start": "1757580",
    "end": "1764899"
  },
  {
    "text": "one-dimensional array is what I need is because in this Onyx model it's specified negative 1 comma one that",
    "start": "1764899",
    "end": "1773240"
  },
  {
    "text": "means it's negative one it really it usually it's a tensor it does not need",
    "start": "1773240",
    "end": "1779919"
  },
  {
    "text": "it it only needs one dimensional array because it's negative one is it gets",
    "start": "1779919",
    "end": "1786980"
  },
  {
    "text": "ignored it's just one one line okay like in this case the",
    "start": "1786980",
    "end": "1793778"
  },
  {
    "text": "and then I pass in salary zero because it's going to get ignored and then you use this ort sensor tensor",
    "start": "1794000",
    "end": "1801740"
  },
  {
    "text": "in order to create the feed and then that's what you pass to your",
    "start": "1801740",
    "end": "1807980"
  },
  {
    "text": "session and once you have the session it will give you the result so let's see if I can run that",
    "start": "1807980",
    "end": "1815360"
  },
  {
    "text": "this application and so that that's what it returned to me I pass him",
    "start": "1815360",
    "end": "1823279"
  },
  {
    "text": "an input and then it gave me an output and I know",
    "start": "1823279",
    "end": "1828620"
  },
  {
    "text": "the output data that I need is using the score that",
    "start": "1828620",
    "end": "1834260"
  },
  {
    "text": "output binding and then it returned the data any",
    "start": "1834260",
    "end": "1839840"
  },
  {
    "text": "questions so far yes I have it on GitHub and I'll give",
    "start": "1839840",
    "end": "1845059"
  },
  {
    "text": "you the link yes so um my goal here is to find the",
    "start": "1845059",
    "end": "1851899"
  },
  {
    "text": "simplest way on how we can give that example so you can reference it later on in case and you need to",
    "start": "1851899",
    "end": "1858860"
  },
  {
    "text": "so that's how you would incorporate a node right I created you know think",
    "start": "1858860",
    "end": "1864020"
  },
  {
    "text": "about what happened I created a model using ml.net I exported it to Onyx",
    "start": "1864020",
    "end": "1870679"
  },
  {
    "text": "and now I'm using it in my JavaScript application",
    "start": "1870679",
    "end": "1875380"
  },
  {
    "text": "okay let's go back to the presentation",
    "start": "1878419",
    "end": "1882580"
  },
  {
    "text": "I mean so when you when the model is it slow or you get your response",
    "start": "1893539",
    "end": "1900260"
  },
  {
    "text": "really quickly it's actually faster because it's um",
    "start": "1900260",
    "end": "1905960"
  },
  {
    "text": "so for JavaScript because it's running using webassembly and also webgl",
    "start": "1905960",
    "end": "1914179"
  },
  {
    "text": "it it runs it and if the GPU is available it would automatically allows",
    "start": "1914179",
    "end": "1920299"
  },
  {
    "text": "it to happen of course you know it's lightweight model and in this case you",
    "start": "1920299",
    "end": "1926360"
  },
  {
    "text": "know you're running it on the server I'm running it on my machine so it depends on the the capability of that machine",
    "start": "1926360",
    "end": "1932870"
  },
  {
    "text": "[Music] yeah it's a really real JavaScript right",
    "start": "1932870",
    "end": "1940059"
  },
  {
    "text": "yeah this is since it's a node application it's on the server side yeah it's not yet in the browser and",
    "start": "1940520",
    "end": "1948200"
  },
  {
    "text": "that's what I'm going to be talking next this is the client side of things right so in this case this is a JavaScript",
    "start": "1948200",
    "end": "1954860"
  },
  {
    "text": "library running Onyx model on the browser itself",
    "start": "1954860",
    "end": "1960700"
  },
  {
    "text": "and it's using webassembly and webgl Technologies and it can both run in CPU or GPU",
    "start": "1960700",
    "end": "1969919"
  },
  {
    "text": "one interesting I found today there is also a react template so if you are a",
    "start": "1969919",
    "end": "1975020"
  },
  {
    "text": "react developer and if you want to incorporate it into your react application there is a template that",
    "start": "1975020",
    "end": "1981740"
  },
  {
    "text": "developer can start using the key to it is you know you have this npm install",
    "start": "1981740",
    "end": "1988220"
  },
  {
    "text": "right Onyx runtime web and then you you import it to your",
    "start": "1988220",
    "end": "1996860"
  },
  {
    "text": "application here let me show you a little bit of example on that",
    "start": "1996860",
    "end": "2003039"
  },
  {
    "text": "so why would you want to do this well it's faster you know we're asking about performance it is faster because",
    "start": "2003039",
    "end": "2009700"
  },
  {
    "text": "it's running in the browser itself so there's less communication to the",
    "start": "2009700",
    "end": "2016179"
  },
  {
    "text": "server so let's say if it's an image and you're doing image processing on the browser itself that that makes it faster",
    "start": "2016179",
    "end": "2024100"
  },
  {
    "text": "it's safer because you're not sending data outside of",
    "start": "2024100",
    "end": "2029260"
  },
  {
    "text": "that um of the network or the machine itself it",
    "start": "2029260",
    "end": "2034899"
  },
  {
    "text": "also works offline because once it download or once it has a copy of the model running in the",
    "start": "2034899",
    "end": "2041919"
  },
  {
    "text": "browser then it does not need to send any to anywhere and it's way cheaper too because uh",
    "start": "2041919",
    "end": "2049839"
  },
  {
    "text": "you're using the the device itself rather than barring",
    "start": "2049839",
    "end": "2056320"
  },
  {
    "text": "other people's computer which is the cloud right so when should you not use",
    "start": "2056320",
    "end": "2065560"
  },
  {
    "text": "or run it in the browser well when the model is too large there's instances",
    "start": "2065560",
    "end": "2071618"
  },
  {
    "text": "that it requires higher hardware specs you know",
    "start": "2071619",
    "end": "2076740"
  },
  {
    "text": "the company where I work for we do a lot of uh image processing or",
    "start": "2076740",
    "end": "2083398"
  },
  {
    "text": "object detection and some of the models can get large you know 200 megabytes and",
    "start": "2083399",
    "end": "2090638"
  },
  {
    "text": "if you think about if you have to download 200 megabyte to your device",
    "start": "2090639",
    "end": "2095980"
  },
  {
    "text": "that would kill the experience so you have to think about simplifying that model or you know maybe it makes sense",
    "start": "2095980",
    "end": "2103660"
  },
  {
    "text": "to pre-process or post-process that rather than on the device itself",
    "start": "2103660",
    "end": "2111700"
  },
  {
    "text": "so let's look at a quick demo how we would do this",
    "start": "2111700",
    "end": "2118319"
  },
  {
    "text": "Okay so this one right here I have on my package",
    "start": "2120700",
    "end": "2126280"
  },
  {
    "text": "Json there's no dependency because I'm not running it in node let me run this first because it makes",
    "start": "2126280",
    "end": "2132820"
  },
  {
    "text": "sense to show showcase it before",
    "start": "2132820",
    "end": "2140160"
  },
  {
    "text": "um I talk about the code",
    "start": "2140859",
    "end": "2147280"
  },
  {
    "text": "so in this case I'm going to run it in the browser localhost",
    "start": "2147280",
    "end": "2154480"
  },
  {
    "text": "it's running it locally here it says 8081 okay so this is",
    "start": "2154480",
    "end": "2160900"
  },
  {
    "text": "um uh website what I'm going to do is I'm",
    "start": "2160900",
    "end": "2166480"
  },
  {
    "text": "going to pass in an image and it would scale and change that image and it would give me the result so the",
    "start": "2166480",
    "end": "2172960"
  },
  {
    "text": "simplest way I can think of and this one right here is using a different Onyx model in this case it is I downloaded it",
    "start": "2172960",
    "end": "2181000"
  },
  {
    "text": "from the Onyx model zoo and it is available out there and it's called this emotion fur",
    "start": "2181000",
    "end": "2190420"
  },
  {
    "text": "hmm Dash 8 so we detects emotion",
    "start": "2190420",
    "end": "2197220"
  },
  {
    "text": "so looking at this code if you look at the index.html",
    "start": "2197619",
    "end": "2203440"
  },
  {
    "text": "the I reference the script which is on a CDN which is the Onyx",
    "start": "2203440",
    "end": "2211359"
  },
  {
    "text": "runtime web ort that's a",
    "start": "2211359",
    "end": "2219119"
  },
  {
    "text": "that is shortcut for it so this Onyx runtime web",
    "start": "2219940",
    "end": "2226180"
  },
  {
    "text": "and this is pretty much the website to upload the image and do its processing",
    "start": "2226180",
    "end": "2233099"
  },
  {
    "text": "but the key Point here is on this main.js",
    "start": "2236380",
    "end": "2242800"
  },
  {
    "text": "it's main.js when it receives an image",
    "start": "2242800",
    "end": "2248079"
  },
  {
    "text": "okay and once it start processing that image it would load it",
    "start": "2248079",
    "end": "2254079"
  },
  {
    "text": "and once I load that image I would handle it",
    "start": "2254079",
    "end": "2260380"
  },
  {
    "text": "and convert it to a tensor in order to for because the model needs it at a",
    "start": "2260380",
    "end": "2267520"
  },
  {
    "text": "certain size so I need to resize that model change it to",
    "start": "2267520",
    "end": "2272980"
  },
  {
    "text": "pretty much would look something like this so I have to grayscale it and it had to be a certain number of pixel",
    "start": "2272980",
    "end": "2281160"
  },
  {
    "text": "in order to pass it properly if I go to let's see if I can view this",
    "start": "2281160",
    "end": "2287800"
  },
  {
    "text": "um emotion Onyx file you see if you'll it'll open",
    "start": "2287800",
    "end": "2293560"
  },
  {
    "text": "it for you come on",
    "start": "2293560",
    "end": "2298660"
  },
  {
    "text": "Neutron see this is you know the graph",
    "start": "2298660",
    "end": "2304180"
  },
  {
    "text": "of the instruction set so the input would come here and it process it all",
    "start": "2304180",
    "end": "2309940"
  },
  {
    "text": "the way at the bottom until it gives you the result",
    "start": "2309940",
    "end": "2314820"
  },
  {
    "text": "this Onyx model it needs one input that is one by one comma 1 comma 64 by",
    "start": "2315520",
    "end": "2325420"
  },
  {
    "text": "64. so what it tells me is it needs an image of one bit 64 by 64 in size",
    "start": "2325420",
    "end": "2333940"
  },
  {
    "text": "and that's the requirement in order to to pass this value and it would give me an output which is a tensor of 1 comma",
    "start": "2333940",
    "end": "2341800"
  },
  {
    "text": "eight so it's a one-dimensional array of eight items in it",
    "start": "2341800",
    "end": "2347200"
  },
  {
    "text": "okay so that helped me identify",
    "start": "2347200",
    "end": "2352240"
  },
  {
    "text": "what I need to do in order to run this application so I",
    "start": "2352240",
    "end": "2357880"
  },
  {
    "text": "process this image I resize it to 64 by 64 and processing the image you know",
    "start": "2357880",
    "end": "2364359"
  },
  {
    "text": "this one it I scaled it to a certain size and then based from that I convert",
    "start": "2364359",
    "end": "2372280"
  },
  {
    "text": "it to grayscale once I converted it to grayscale then I can I have to convert",
    "start": "2372280",
    "end": "2378099"
  },
  {
    "text": "it to this tensor right of that image and this tensor",
    "start": "2378099",
    "end": "2385060"
  },
  {
    "text": "it requires me to use this ort.tensor I specify",
    "start": "2385060",
    "end": "2391420"
  },
  {
    "text": "you know the value of each one of those pixels I have to pass that in and once I added to",
    "start": "2391420",
    "end": "2400000"
  },
  {
    "text": "this ort that sends tensor then I can pass it to my Onyx runtime",
    "start": "2400000",
    "end": "2408820"
  },
  {
    "text": "so the meat here is this so I would use ort dot inference session.create I have",
    "start": "2408820",
    "end": "2416680"
  },
  {
    "text": "this Onyx model that I loaded in a session so there's always three steps",
    "start": "2416680",
    "end": "2422020"
  },
  {
    "text": "you load it into memory and then you pass and you create your input like in",
    "start": "2422020",
    "end": "2427359"
  },
  {
    "text": "this case I know it needs input 3 how do I know this input 3 is because the Onyx",
    "start": "2427359",
    "end": "2434740"
  },
  {
    "text": "model told me I need to pass that as a parameter and I have the uh",
    "start": "2434740",
    "end": "2442720"
  },
  {
    "text": "the tensor and then pass that using session.run and it will",
    "start": "2442720",
    "end": "2448960"
  },
  {
    "text": "give me the result in this case I know that this output would receive",
    "start": "2448960",
    "end": "2455859"
  },
  {
    "text": "is it's either going to be neutral happiness surprise sadness anger disco that's that's what it would",
    "start": "2455859",
    "end": "2463060"
  },
  {
    "text": "um give me the results on and then I get the maximum value whichever is the",
    "start": "2463060",
    "end": "2468880"
  },
  {
    "text": "highest out of that list and then I can display it properly",
    "start": "2468880",
    "end": "2474180"
  },
  {
    "text": "okay",
    "start": "2476079",
    "end": "2478619"
  },
  {
    "text": "can we reuse yeah you can you can reuse that session",
    "start": "2482859",
    "end": "2488140"
  },
  {
    "text": "once you load it in memory uh in this case this is this since this is",
    "start": "2488140",
    "end": "2494380"
  },
  {
    "text": "a simplest example I can find I can just load it as I go yeah definitely",
    "start": "2494380",
    "end": "2501900"
  },
  {
    "text": "okay",
    "start": "2504640",
    "end": "2507299"
  },
  {
    "text": "so react native allows you to score a pre-trained model this is a little bit",
    "start": "2513099",
    "end": "2518800"
  },
  {
    "text": "Advanced but if you want to run it on Android or iOS it allows you to do this",
    "start": "2518800",
    "end": "2524079"
  },
  {
    "text": "also but in order to do that you have to convert the Onyx model to another model",
    "start": "2524079",
    "end": "2531400"
  },
  {
    "text": "that is optimized for mobile and they call it mobile.ort and then",
    "start": "2531400",
    "end": "2539380"
  },
  {
    "text": "that's how you would it minimize the binary size because it really needs to",
    "start": "2539380",
    "end": "2544660"
  },
  {
    "text": "be able to to to have more optimization for running it in the browser because",
    "start": "2544660",
    "end": "2551200"
  },
  {
    "text": "browsers have of course better memory as compared to the constraint on",
    "start": "2551200",
    "end": "2558579"
  },
  {
    "text": "your phone so that's the reason why it had to be optimized specifically for what you know what you're trying to",
    "start": "2558579",
    "end": "2564640"
  },
  {
    "text": "deploy it on so um compatibility wise it works with",
    "start": "2564640",
    "end": "2572320"
  },
  {
    "text": "you know if you're going to run this in the browser it works with Windows 10 Mac OS Ubuntu iOS Android right runs in",
    "start": "2572320",
    "end": "2580060"
  },
  {
    "text": "Chrome it runs on edge on Safari you can use it for electron because it's you",
    "start": "2580060",
    "end": "2586599"
  },
  {
    "text": "know node binding and node.js so for node.js it's using webassembly but for",
    "start": "2586599",
    "end": "2592000"
  },
  {
    "text": "you know the browser it's either you're going to use webassembly or webgl",
    "start": "2592000",
    "end": "2598559"
  },
  {
    "text": "and it feels like this after talking about these Technologies",
    "start": "2598839",
    "end": "2604300"
  },
  {
    "text": "right so just to recap what we've done so far",
    "start": "2604300",
    "end": "2610440"
  },
  {
    "text": "we did talk about what is Onyx it's an open standard it's the right tool for",
    "start": "2610440",
    "end": "2615940"
  },
  {
    "text": "the right job right if your application is already in JavaScript you have a web application",
    "start": "2615940",
    "end": "2622240"
  },
  {
    "text": "use Onyx an onyx runtime in order to integrate it with your target platform how do you",
    "start": "2622240",
    "end": "2630700"
  },
  {
    "text": "create an onyx model uh models can be created you know I did show you different",
    "start": "2630700",
    "end": "2636280"
  },
  {
    "text": "Frameworks and how you would create the Onyx model I did a demo on using ml.net",
    "start": "2636280",
    "end": "2642460"
  },
  {
    "text": "and also some code using python how would you deploy it you can deploy it not just in JavaScript which I did demo",
    "start": "2642460",
    "end": "2650800"
  },
  {
    "text": "today there's a way you can integrate it with your.net application or python you",
    "start": "2650800",
    "end": "2656740"
  },
  {
    "text": "can also use Windows ml in order to do this and of course if you're going to run it in the cloud you can use Azure",
    "start": "2656740",
    "end": "2663400"
  },
  {
    "text": "machine learning with all the reducing Onyx runtime",
    "start": "2663400",
    "end": "2671020"
  },
  {
    "text": "there's anything else that you that I want you to remember about this talk is this right once you started looking",
    "start": "2671020",
    "end": "2679000"
  },
  {
    "text": "at it at this point of view you're going to understand when is the best use case",
    "start": "2679000",
    "end": "2684359"
  },
  {
    "text": "of when should you have a different pipeline for inferencing versus the",
    "start": "2684359",
    "end": "2690819"
  },
  {
    "text": "different pipeline for training the model all right if you're interested in",
    "start": "2690819",
    "end": "2697000"
  },
  {
    "text": "learning more uh of the demo today I have it on my GitHub and you can connect",
    "start": "2697000",
    "end": "2703359"
  },
  {
    "text": "to there",
    "start": "2703359",
    "end": "2706140"
  },
  {
    "text": "oh one thing you see those glasses right there these are the spectacles",
    "start": "2710560",
    "end": "2717400"
  },
  {
    "text": "which is from Snapchat is one of the partners that's actually",
    "start": "2717400",
    "end": "2722680"
  },
  {
    "text": "using Onyx and one way to run machine learning on those glasses is converting",
    "start": "2722680",
    "end": "2728800"
  },
  {
    "text": "it to an onyx model and I did try that and I was so happy it's like oh that's cool it has object",
    "start": "2728800",
    "end": "2734319"
  },
  {
    "text": "detection it has segmentation and all that so if you're interested in learning more about me my name is Ron dagdag I'm",
    "start": "2734319",
    "end": "2741220"
  },
  {
    "text": "a Microsoft MVP I would the best way to contact me is through Linkedin and",
    "start": "2741220",
    "end": "2747940"
  },
  {
    "text": "Twitter and I appreciate you geeking out with me about bread about Onyx and glasses",
    "start": "2747940",
    "end": "2759339"
  },
  {
    "text": "thank you very much appreciate it any questions I know that's a big topic",
    "start": "2759339",
    "end": "2765940"
  },
  {
    "text": "there's a lot of examples that I did demo uh and this would you know feel",
    "start": "2765940",
    "end": "2771280"
  },
  {
    "text": "free to ask any questions have you yeah",
    "start": "2771280",
    "end": "2775560"
  },
  {
    "text": "well if you're using pytorch right and then of course you know you have a choice right how do",
    "start": "2782500",
    "end": "2789579"
  },
  {
    "text": "you incorporate it to your application of course you can use pie torch in the in the cloud side but now if you're",
    "start": "2789579",
    "end": "2795760"
  },
  {
    "text": "going to run it at the edge then it makes sense to convert it to Onyx right uh tensorflow there's",
    "start": "2795760",
    "end": "2802839"
  },
  {
    "text": "tensorflow.js so if you have it in Keras it allows you to con to run it using tensorflow.js",
    "start": "2802839",
    "end": "2813400"
  },
  {
    "text": "and if you have developers that are in you know that they did their models using Keras you can actually convert it",
    "start": "2813760",
    "end": "2820420"
  },
  {
    "text": "to Onyx or let's say let's let's say you have a developer that's using pi torch",
    "start": "2820420",
    "end": "2827260"
  },
  {
    "text": "um they created the model using pi torch and then they didn't you wanted to run",
    "start": "2827260",
    "end": "2833800"
  },
  {
    "text": "it using tensorflow.js you can use Onyx to convert it to Keras also so Onyx is",
    "start": "2833800",
    "end": "2841720"
  },
  {
    "text": "kind of like a a middle ground to convert from one place to the other and also a way to optimize uh",
    "start": "2841720",
    "end": "2849160"
  },
  {
    "text": "of course there's limitations and some because some sometimes there might be a",
    "start": "2849160",
    "end": "2855160"
  },
  {
    "text": "need to create a custom custom operators uh so it because at the end of the day",
    "start": "2855160",
    "end": "2860680"
  },
  {
    "text": "they're trying to map instructions right uh to make it uh to make it portable just like the same way as jvm when they",
    "start": "2860680",
    "end": "2867940"
  },
  {
    "text": "first started you know you're converting it to like uh intermediate you know the machine library and all that so you it's",
    "start": "2867940",
    "end": "2875200"
  },
  {
    "text": "when they're converting from one for the operators from one language to the other and they have different implementations",
    "start": "2875200",
    "end": "2882819"
  },
  {
    "text": "specifically for for that so um so sometimes they they don't have a",
    "start": "2882819",
    "end": "2889359"
  },
  {
    "text": "match or they haven't mapped it yet so that requires some extra work that you need to do but for the most part of what",
    "start": "2889359",
    "end": "2896319"
  },
  {
    "text": "I've seen so far is you know if if your backbone of the model that you create especially in custom Vision or for for",
    "start": "2896319",
    "end": "2903480"
  },
  {
    "text": "uh computer vision if the backbone can convert to Onyx most likely the custom",
    "start": "2903480",
    "end": "2909760"
  },
  {
    "text": "models that you gets created can be converted properly",
    "start": "2909760",
    "end": "2915599"
  },
  {
    "text": "so I want to know your survive both process when you try to architectify",
    "start": "2916240",
    "end": "2922359"
  },
  {
    "text": "solution about around iot machine learning and Etc when do you choose between that",
    "start": "2922359",
    "end": "2930700"
  },
  {
    "text": "device versus smart device when do you make a decision to how to I probably need some energy Analytics",
    "start": "2930700",
    "end": "2937000"
  },
  {
    "text": "deployed post to the device or we just have an essential path where you skip the data to",
    "start": "2937000",
    "end": "2944200"
  },
  {
    "text": "about so what is the like what would be the best approach",
    "start": "2944200",
    "end": "2950260"
  },
  {
    "text": "will cost right right one of the best criteria is you know if you're sending a",
    "start": "2950260",
    "end": "2956740"
  },
  {
    "text": "bunch of these data for processing if you're sending images that can get expensive right or you know",
    "start": "2956740",
    "end": "2963520"
  },
  {
    "text": "think about uh sound you know how these Alexa devices or this Google home",
    "start": "2963520",
    "end": "2969160"
  },
  {
    "text": "devices right um the Wake word is actually running on",
    "start": "2969160",
    "end": "2974200"
  },
  {
    "text": "the device itself whenever you say Hey Google or it knows it understands that",
    "start": "2974200",
    "end": "2980079"
  },
  {
    "text": "but anything after that it gets sent to the cloud for processing because they have a bigger model so in terms of iot",
    "start": "2980079",
    "end": "2987700"
  },
  {
    "text": "those are the things you have to think about whenever you're deploying some of these applications",
    "start": "2987700",
    "end": "2993839"
  },
  {
    "text": "so for example if it's related to computer vision and",
    "start": "2993839",
    "end": "3000960"
  },
  {
    "text": "you're doing some object detection it makes sense to run it closer to the edge rather than a cloud because you want",
    "start": "3000960",
    "end": "3007980"
  },
  {
    "text": "that processing happens uh locally rather than sending it in the cloud so",
    "start": "3007980",
    "end": "3013260"
  },
  {
    "text": "those are the things you have to consider and then what you're sending to your event Hub or you're sending to your",
    "start": "3013260",
    "end": "3019920"
  },
  {
    "text": "stream are are just the results of the inferencing rather than the you know the",
    "start": "3019920",
    "end": "3025380"
  },
  {
    "text": "whole raw data itself so that that helps",
    "start": "3025380",
    "end": "3030800"
  },
  {
    "text": "cool all right appreciate your time",
    "start": "3031740",
    "end": "3036740"
  }
]
[
  {
    "start": "0",
    "end": "13000"
  },
  {
    "text": "so welcome after lunch I hope you had a great lunch I definitely had a bit",
    "start": "8990",
    "end": "15660"
  },
  {
    "start": "13000",
    "end": "13000"
  },
  {
    "text": "earlier than maybe some of you but good time to be back here in Oslo beautiful city so I work for a company called",
    "start": "15660",
    "end": "23039"
  },
  {
    "text": "particular software we are the makers of n service bus and if you are interested you can follow me on twitter at",
    "start": "23039",
    "end": "29250"
  },
  {
    "text": "@steveadubato the good thing about people from Norway usually are the ones that can pronounce",
    "start": "29250",
    "end": "35160"
  },
  {
    "text": "my name when you when I say when I say my name to Americans is like Mar back Mar and just like but no regions can",
    "start": "35160",
    "end": "41729"
  },
  {
    "text": "actually say more about because you have the same hard vowels that's pretty cool so um before I join for a company in",
    "start": "41729",
    "end": "49949"
  },
  {
    "text": "Switzerland where we built this medical patient type of record system where we",
    "start": "49949",
    "end": "54989"
  },
  {
    "text": "managed probably four million patient records of four million patients in",
    "start": "54989",
    "end": "60119"
  },
  {
    "text": "Switzerland and it was a huge legacy system that was running on thirteen",
    "start": "60119",
    "end": "65489"
  },
  {
    "text": "servers million lines of code and it was let's say a big monolith although it was",
    "start": "65489",
    "end": "71189"
  },
  {
    "text": "spread over multiple servers and we had quite a few problems and one day the",
    "start": "71189",
    "end": "76259"
  },
  {
    "text": "customer came and said you know what we're doing medical type of invoicing",
    "start": "76259",
    "end": "82229"
  },
  {
    "text": "medical patient management wouldn't it be nice if we could also do general-purpose invoicing and then we",
    "start": "82229",
    "end": "90359"
  },
  {
    "text": "said like yeah I'm not sure about that because we know that we have to change the system and the customers yeah I",
    "start": "90359",
    "end": "96420"
  },
  {
    "text": "don't have a lot of money but I'm sure you can you can make it right have you ever had that in your projects yeah",
    "start": "96420",
    "end": "102840"
  },
  {
    "text": "exactly and we were like let's give it a try so we set up but let's start with with",
    "start": "102840",
    "end": "109770"
  },
  {
    "text": "with an easy use case so what we did we did this it's a simplified version so we have basically a demilitarized zone and",
    "start": "109770",
    "end": "116429"
  },
  {
    "text": "in that demilitarized zone we had the front a front dent service which was running on top CF service and that did",
    "start": "116429",
    "end": "126030"
  },
  {
    "text": "for example invoice refunds and queries against the back-end server and the back-end server was doing some kind of",
    "start": "126030",
    "end": "132620"
  },
  {
    "text": "remoting marshaling of the data and was doing all kinds of processing against",
    "start": "132620",
    "end": "138030"
  },
  {
    "text": "with a do zone that we still use ATO dot net 1.1 although we were already running on",
    "start": "138030",
    "end": "143340"
  },
  {
    "text": "dotnet framework for at the time when I left the project was doing reasons rights against a sequel server cluster",
    "start": "143340",
    "end": "149849"
  },
  {
    "text": "the sequel server was fine it was heavily optimized we had a DBA in the prochik said that was good but the rest",
    "start": "149849",
    "end": "155310"
  },
  {
    "text": "of the code was pretty complex and one thing that we didn't really realize at",
    "start": "155310",
    "end": "160680"
  },
  {
    "text": "that time was once we started moving towards channel purpose invoicing invoice refunds we exposed ourself to a",
    "start": "160680",
    "end": "168390"
  },
  {
    "text": "whole new world and that whole new world was well we had web shops that wanted to",
    "start": "168390",
    "end": "173430"
  },
  {
    "text": "issue invoice refunds of their customers against our our database and they were",
    "start": "173430",
    "end": "179130"
  },
  {
    "text": "using this invoice refund services and one of the things that we realized was",
    "start": "179130",
    "end": "184739"
  },
  {
    "text": "well okay web shops it means you are now for example even now doing these talks",
    "start": "184739",
    "end": "190350"
  },
  {
    "text": "if you find something boring you can open up yourself own go to web shop and order a new and shiny cellphone right so",
    "start": "190350",
    "end": "196110"
  },
  {
    "text": "you can do that 24 hours every day 365 5 days so we had to cope with much more",
    "start": "196110",
    "end": "202290"
  },
  {
    "text": "load on the system and that much more load could also quite increased because",
    "start": "202290",
    "end": "207600"
  },
  {
    "text": "we had now suddenly all these interesting PHP WooCommerce whatever you",
    "start": "207600",
    "end": "213480"
  },
  {
    "text": "want to call those clients that were that were connecting to our service and one thing that we realized was that it",
    "start": "213480",
    "end": "219150"
  },
  {
    "text": "seems to be quite common especially in the PHP world no offense to PHP developers but at that time it seems to",
    "start": "219150",
    "end": "225299"
  },
  {
    "text": "be really common that people started once they issued the refund against our services they started pulling our query",
    "start": "225299",
    "end": "232260"
  },
  {
    "text": "api's all the time in order to see whether it's processed I don't know what the impression was that if they pull",
    "start": "232260",
    "end": "237840"
  },
  {
    "text": "more we process faster because they're so annoying I don't know what it was but so one one thing that we we had we",
    "start": "237840",
    "end": "244980"
  },
  {
    "text": "basically lost the maintenance window in that architecture right because when we shut down the backend or when we shut",
    "start": "244980",
    "end": "250500"
  },
  {
    "text": "down the database well they cannot do in most refunds anymore they cannot do polling queries",
    "start": "250500",
    "end": "256200"
  },
  {
    "text": "against our databases so that that was a was a big problem so basically what we",
    "start": "256200",
    "end": "262200"
  },
  {
    "start": "262000",
    "end": "262000"
  },
  {
    "text": "can say is we had this what I call the RPC call stack of doom and I don't want",
    "start": "262200",
    "end": "267360"
  },
  {
    "text": "to say our pcs bad please please don't get the wrong message RBC remote",
    "start": "267360",
    "end": "272820"
  },
  {
    "text": "procedure style communication while you're doing it over Ã§f old-school way or HTTP doesn't really",
    "start": "272820",
    "end": "278260"
  },
  {
    "text": "matter is a good communication mean for some types of things but not for everything right but here what we had is",
    "start": "278260",
    "end": "284170"
  },
  {
    "text": "well whenever we had for example latency on the database server or the backend was slow because we had to we had",
    "start": "284170",
    "end": "290740"
  },
  {
    "text": "garbage collection problems again for example because we had a lot of legacy stuff usually the the latency rippled",
    "start": "290740",
    "end": "297940"
  },
  {
    "text": "through the call stack to the front end calling web services so that was a",
    "start": "297940",
    "end": "303160"
  },
  {
    "text": "problem then when for example database transaction had to rollback because we open too many connections against",
    "start": "303160",
    "end": "308950"
  },
  {
    "text": "database that usually led to an exception that is exception then bubbled up the call stack to to the to the OP CF",
    "start": "308950",
    "end": "316030"
  },
  {
    "text": "services obviously we had good team members and those team members actually found out that DAF CF is quite",
    "start": "316030",
    "end": "321460"
  },
  {
    "text": "extensible so we had some kind of behaviors in IND of CF that fished out those exceptions and made sure that it",
    "start": "321460",
    "end": "328570"
  },
  {
    "text": "doesn't bubble up to the web service call itself but still when we had those kind of exceptions we couldn't really",
    "start": "328570",
    "end": "336310"
  },
  {
    "text": "handle any requests anymore so we had a problem we couldn't really fulfill the SLA s the service level agreements that",
    "start": "336310",
    "end": "342550"
  },
  {
    "text": "we had with with those web shops because we had a high temporal but also spatial coupling in that architecture and the",
    "start": "342550",
    "end": "349840"
  },
  {
    "text": "storage layer or the latency of the storage layer and the latency of the back-end processing services directly",
    "start": "349840",
    "end": "354850"
  },
  {
    "text": "affected the using user-facing latency and we could also not throttle things",
    "start": "354850",
    "end": "361270"
  },
  {
    "text": "for example when we wanted to implement maintenance window we said in that period of time because we're rolling out",
    "start": "361270",
    "end": "367810"
  },
  {
    "text": "some DB scripts we only want to handle a hundred inverse refunds per minute or per second whatever that number is we",
    "start": "367810",
    "end": "374620"
  },
  {
    "text": "couldn't really do that but then we realized well invoice refund is actually",
    "start": "374620",
    "end": "379660"
  },
  {
    "start": "378000",
    "end": "378000"
  },
  {
    "text": "quite an interesting thing because any invoice refund especially the command side of things we can pack it into a",
    "start": "379660",
    "end": "386440"
  },
  {
    "text": "message or command and then we can just ship it to the backend and basically say to the customer thank you very much we",
    "start": "386440",
    "end": "393070"
  },
  {
    "text": "got your invoice refund and we will process it eventually so so we started",
    "start": "393070",
    "end": "399790"
  },
  {
    "text": "saying well messaging is actually quite quite a good thing that we could apply to so we went back to the drawing board",
    "start": "399790",
    "end": "405400"
  },
  {
    "text": "and we started basically drawing a new kind of architecture new kind of architecture is a lie",
    "start": "405400",
    "end": "411190"
  },
  {
    "text": "because I mean you know it if you have a legacy system that they start you JH kappa everything we do microservice the",
    "start": "411190",
    "end": "421570"
  },
  {
    "text": " out of this system everyone is like are you crazy are you nuts this is gonna take a multiple months and",
    "start": "421570",
    "end": "426760"
  },
  {
    "text": "we will never achieve this successfully so we said let's do simple small steps start at the edges introduce where it",
    "start": "426760",
    "end": "433810"
  },
  {
    "text": "makes sense a little bit of messaging but to never go all-in so what we did is we changed slightly change those top CF",
    "start": "433810",
    "end": "440410"
  },
  {
    "text": "services so what we did is we packaged the invoice refund command here into a",
    "start": "440410",
    "end": "446380"
  },
  {
    "text": "message queue at that time it what we were using Windows heavily use the MS MQ",
    "start": "446380",
    "end": "451870"
  },
  {
    "text": "but it doesn't really matter what kind of technology you use we could also have have done messaging on top of sequel",
    "start": "451870",
    "end": "459310"
  },
  {
    "text": "server but since we already had some messaging code in there with MS MQ used",
    "start": "459310",
    "end": "464320"
  },
  {
    "text": "ms MQ and then what we did is we had a little front-end cash for the queries so",
    "start": "464320",
    "end": "471940"
  },
  {
    "text": "basically whenever command came in we just updated the states in was refund state in that local demilitarized zone",
    "start": "471940",
    "end": "478000"
  },
  {
    "text": "that front end cache and then the PHP clients could could hammer the out of us that was not a big deal because we",
    "start": "478000",
    "end": "484000"
  },
  {
    "text": "were always serving from the query crash cache the queries and then on the",
    "start": "484000",
    "end": "489130"
  },
  {
    "text": "backend the backend when whenever it had time it could basically process the the invoice refunds from from the queuing",
    "start": "489130",
    "end": "496270"
  },
  {
    "text": "system down there and then do its thing and whenever it's done it could publish an invoice refunded event into the",
    "start": "496270",
    "end": "502210"
  },
  {
    "text": "system that was subscribed by the demilitarized zone invalidated that cache and then the the PHP client could",
    "start": "502210",
    "end": "510010"
  },
  {
    "text": "automatically be notified so to speak when when they pulled the invoice Reif refunds so what this gave us was pretty",
    "start": "510010",
    "end": "519010"
  },
  {
    "text": "cool so now we had we had a decoupling of the architecture so the front then",
    "start": "519010",
    "end": "524200"
  },
  {
    "text": "services will no longer copy directly to the back-end services we could shut down the database deploy some scripts but we",
    "start": "524200",
    "end": "530890"
  },
  {
    "text": "could still handle invoice refund stuff without any problems we had awesome scaling vectors",
    "start": "530890",
    "end": "537490"
  },
  {
    "text": "in this architecture because we could say well whenever we are ready on the backend side of things when we I saw",
    "start": "537490",
    "end": "543400"
  },
  {
    "text": "the invoice refund processing engine out of the big model if we can basically have copies of that component running on",
    "start": "543400",
    "end": "552250"
  },
  {
    "text": "our servers compete doing competing consumer on the on the invoice refund command queue for example we could do",
    "start": "552250",
    "end": "559780"
  },
  {
    "text": "fraud link right because we can do frothing on top of queues but we also got what was the biggest benefit for us",
    "start": "559780",
    "end": "566320"
  },
  {
    "text": "retries because whenever we had a DB transaction time out transaction log or something like that",
    "start": "566320",
    "end": "571990"
  },
  {
    "text": "what we could do is we could just roll back roll back the message into the queue here and then retry at the later",
    "start": "571990",
    "end": "578440"
  },
  {
    "text": "point in time so that that was pretty nice and what we also found out is that",
    "start": "578440",
    "end": "583630"
  },
  {
    "text": "because we were packaging the intent of the customer the invoice refund command into that message serialize it to a",
    "start": "583630",
    "end": "589570"
  },
  {
    "text": "storage packed queue and we will never lose that intent and but we also captured that intent right so if you",
    "start": "589570",
    "end": "596470"
  },
  {
    "text": "have just a regular HTTP call or dub CF call like we had before whenever there",
    "start": "596470",
    "end": "601630"
  },
  {
    "text": "is an exception that the invoice refund command is basically lost but with a storage back you'll like MSM queue we",
    "start": "601630",
    "end": "608230"
  },
  {
    "text": "didn't have that that problem and one thing that I want to note about this pattern if you're saying well that",
    "start": "608230",
    "end": "614710"
  },
  {
    "text": "sounds nice I maybe can apply this as well you have to be a bit careful because essentially what we did here and",
    "start": "614710",
    "end": "620740"
  },
  {
    "text": "we didn't know that at that time but I learned something in the years I've done software engineer or at least I hope but",
    "start": "620740",
    "end": "627100"
  },
  {
    "text": "what we essentially did we did a cache invalidation here right based on a based",
    "start": "627100",
    "end": "632170"
  },
  {
    "text": "on the business in event and if you apply this pattern too much and you fall in love too much of it you're basically building a distributed cache or on top",
    "start": "632170",
    "end": "640570"
  },
  {
    "text": "of messaging which is always a bit dangerous so but we've we felt well once we realize the problem we felt in this",
    "start": "640570",
    "end": "646930"
  },
  {
    "text": "specific kind of thing it's actually quite ok but I just wanted to to mention that so once we we started rolling out",
    "start": "646930",
    "end": "653530"
  },
  {
    "text": "those stuff or start thinking and designing more and more we kind of fell in love with messaging it at least for",
    "start": "653530",
    "end": "660160"
  },
  {
    "text": "this part of the system for some other parts we we didn't because we said well dub CF services Queen against directly",
    "start": "660160",
    "end": "666760"
  },
  {
    "text": "against the database is still is still fine but then we had a hard decision to make because we we thought about well we",
    "start": "666760",
    "end": "674470"
  },
  {
    "text": "need some kind of a messaging middleware that our developers to focus on writing",
    "start": "674470",
    "end": "680020"
  },
  {
    "text": "business code enough Plumbing Codes and low-level messaging everywhere in the code so we we said well we can either",
    "start": "680020",
    "end": "686740"
  },
  {
    "text": "buy something for example or or build something and in that project that that",
    "start": "686740",
    "end": "694150"
  },
  {
    "text": "I was we decided to in that medical invoice system we decided to buy a",
    "start": "694150",
    "end": "700600"
  },
  {
    "text": "messaging middleware out of the shelf in another project that was once I moved away from this project we actually just",
    "start": "700600",
    "end": "707020"
  },
  {
    "text": "decided to build a messaging library messaging middleware ourself and I want to talk today in this talk a little bit",
    "start": "707020",
    "end": "713590"
  },
  {
    "text": "about the challenges that we face that so if you're ever faced to build something like that yourself that you",
    "start": "713590",
    "end": "718900"
  },
  {
    "text": "have all the tools necessary to actually build a robust and reliable queuing abstraction yourself okay so but before",
    "start": "718900",
    "end": "726220"
  },
  {
    "text": "we do this I want to talk about the basic bits and pieces that we need for a robust messaging middleware so well",
    "start": "726220",
    "end": "733120"
  },
  {
    "text": "first of all going back to the architecture drawing board here is the front-end services they need to be able",
    "start": "733120",
    "end": "739060"
  },
  {
    "text": "to capture the intent the messages serialize it somehow and send it over to",
    "start": "739060",
    "end": "744400"
  },
  {
    "text": "the to the input queue so that's the sending part rights that's that's what we need and then on the receiver side we",
    "start": "744400",
    "end": "751780"
  },
  {
    "text": "actually in the backend we need a receiver and the responsibility sorry and the responsibility of the receiver",
    "start": "751780",
    "end": "759250"
  },
  {
    "text": "is basically consume the messages that are in the queue manage the queuing",
    "start": "759250",
    "end": "764740"
  },
  {
    "text": "connection dispatch the business logic that we have based on message payloads that are coming in and eventually in",
    "start": "764740",
    "end": "771460"
  },
  {
    "text": "this example publishing messages back to the message closer to the messaging",
    "start": "771460",
    "end": "776790"
  },
  {
    "text": "middleware so bate really say really super simple so let's look at some code",
    "start": "776790",
    "end": "783580"
  },
  {
    "text": "so what I'm going to do is I'm going to switch now to Visual Studio code and show you the code that we started with",
    "start": "783580",
    "end": "790180"
  },
  {
    "text": "when we started building that messaging abstraction library unfortunately I'm probably going to",
    "start": "790180",
    "end": "796810"
  },
  {
    "text": "block a little bit the view because I have to stand here in front of my computer I hope you can still see the",
    "start": "796810",
    "end": "803800"
  },
  {
    "text": "things I will switch over the screen right now so this is this is the first",
    "start": "803800",
    "end": "810850"
  },
  {
    "text": "simple code that we came up with so we have a we have a message pump and that's",
    "start": "810850",
    "end": "816610"
  },
  {
    "text": "that message form get started we have a cancellation token source because the cancellation token source allows us to",
    "start": "816610",
    "end": "822910"
  },
  {
    "text": "properly with cooperative cancellation internet make sure that whenever we want",
    "start": "822910",
    "end": "828009"
  },
  {
    "text": "to shut down our system we then properly shut down the system and we do not continue to process the things all the",
    "start": "828009",
    "end": "835360"
  },
  {
    "text": "time then we have the pump task so here I'm using a while loop that observes the the cancellation token and then what I'm",
    "start": "835360",
    "end": "842170"
  },
  {
    "text": "doing here is I'm reading stuff from the queue so for example here I'm getting back a memory of bytes for the payload",
    "start": "842170",
    "end": "849639"
  },
  {
    "text": "and the memory of bytes for the headers at passing the cancellation Tokra to the underlying esta kated that I'm using",
    "start": "849639",
    "end": "856029"
  },
  {
    "text": "then what I'm doing is I take the raw byte information the headers and the payload and I turn this into logical",
    "start": "856029",
    "end": "862990"
  },
  {
    "text": "messages logical messages the thing that your code is going to handle right so what I do is I invoke some kind of a",
    "start": "862990",
    "end": "869170"
  },
  {
    "text": "disable is a ssin process for example I could be using Jason don't net protocol buff for whatever fancy tool you want to",
    "start": "869170",
    "end": "875829"
  },
  {
    "text": "use there and then what I do is I invoke this handle message code and this handle",
    "start": "875829",
    "end": "883389"
  },
  {
    "text": "message is in this in this quick demo I'm just doing a task delay and then I'm",
    "start": "883389",
    "end": "889990"
  },
  {
    "text": "printing out something on the console which I will show later in the demo then",
    "start": "889990",
    "end": "895269"
  },
  {
    "text": "we also need for that basic code we basically need something to stop it right so whenever someone calls stop",
    "start": "895269",
    "end": "901329"
  },
  {
    "text": "what we do is we we cancel the cancellation token source then we await the task that is pumping messages and",
    "start": "901329",
    "end": "908079"
  },
  {
    "text": "then we dispose all the resources that are disposable and shutdown shutdown the",
    "start": "908079",
    "end": "913149"
  },
  {
    "text": "system so one thing that you might note here is I'm not using tossed or run to",
    "start": "913149",
    "end": "919779"
  },
  {
    "text": "invoke this this code here I'm doing that because this this code here is a",
    "start": "919779",
    "end": "924970"
  },
  {
    "text": "pure async function a pure i/o bound function and if you're doing pure pure i/o bound kind of async await you",
    "start": "924970",
    "end": "931420"
  },
  {
    "text": "essentially never really need toss toss that's wrong because toss should run is for compute bound stuff that you want to",
    "start": "931420",
    "end": "939010"
  },
  {
    "text": "offload explicitly to the worker thread pool in just a little side note about",
    "start": "939010",
    "end": "944740"
  },
  {
    "text": "PL and async/await right so what I'm doing is I'm just casting this one to funk off-task and then get it back and this was start",
    "start": "944740",
    "end": "952080"
  },
  {
    "text": "spinning so this is the this is the basic coat um that I'm that we",
    "start": "952080",
    "end": "959170"
  },
  {
    "text": "essentially ended up building in our infrastructure",
    "start": "959170",
    "end": "964720"
  },
  {
    "text": "so let me could change the screen again",
    "start": "964720",
    "end": "972270"
  },
  {
    "text": "back to the slides",
    "start": "972270",
    "end": "976080"
  },
  {
    "text": "if it's working okay good good",
    "start": "980720",
    "end": "987740"
  },
  {
    "text": "well I showed you here a polling implementation of a message pump right so maybe you you're using right now an",
    "start": "987740",
    "end": "995399"
  },
  {
    "text": "sdk that has some kind of a more reactive way of pushing messages towards you for example you could be using a",
    "start": "995399",
    "end": "1001610"
  },
  {
    "text": "reactive extension whatever i think that doesn't really matter right whether whether a library is pushing information",
    "start": "1001610",
    "end": "1007279"
  },
  {
    "text": "to you or whether you're doing some kind of a polling implementation it's not really part of of this talk because most",
    "start": "1007279",
    "end": "1013579"
  },
  {
    "text": "libraries that push message to you they also do some kind of a long polling on underneath so you just happen to be to",
    "start": "1013579",
    "end": "1019279"
  },
  {
    "text": "be lucky that someone probably that the sdk already wrote the code for you that you don't have to worry about that part",
    "start": "1019279",
    "end": "1025400"
  },
  {
    "text": "but if you only have a polling implementation of an sdk that doesn't allow me to push messages then you",
    "start": "1025400",
    "end": "1031640"
  },
  {
    "text": "you're actually ending up building that kind of code now let's look at at the",
    "start": "1031640",
    "end": "1037250"
  },
  {
    "text": "sending part well I didn't really show the sending part I only showed the receiving part of the message pump I",
    "start": "1037250",
    "end": "1042860"
  },
  {
    "text": "believed it wasn't really worth showing because eventually what we do is when we're sending we're taking the payload",
    "start": "1042860",
    "end": "1050090"
  },
  {
    "text": "the logical message that we got maybe that's an instance of a class with some date on it we serialize it with our",
    "start": "1050090",
    "end": "1055640"
  },
  {
    "text": "favorite serializer of the day and then we send it to the queuing system because",
    "start": "1055640",
    "end": "1060740"
  },
  {
    "text": "it's i/o bound it's going to be an await call as well and we send in the payload and the headers that represent",
    "start": "1060740",
    "end": "1066950"
  },
  {
    "text": "additional metadata that we that we want to we want to send to the receiver of",
    "start": "1066950",
    "end": "1073100"
  },
  {
    "text": "the message so let me do a quick recap before which was saw in this in this code demo so basically with a little bit",
    "start": "1073100",
    "end": "1079730"
  },
  {
    "text": "of TPL hand-waving a little bit of async/await sprinkle magic over the code we got a message pump that is working",
    "start": "1079730",
    "end": "1087860"
  },
  {
    "text": "fine we have cancellation support so we can shut it down and this worked really well when we ship this to production",
    "start": "1087860",
    "end": "1096040"
  },
  {
    "text": "until a specific moment in time and well what we got is rush hour and well once",
    "start": "1096040",
    "end": "1106010"
  },
  {
    "text": "we we had a we had a web shop that has some precious items on the web shop and those web shops were sending in hundreds",
    "start": "1106010",
    "end": "1113150"
  },
  {
    "text": "and hundreds and and requests then basically we have a rush-hour problem with this code and why",
    "start": "1113150",
    "end": "1119549"
  },
  {
    "text": "do we have a rush-hour problem well the thing is the following if we look at",
    "start": "1119549",
    "end": "1124830"
  },
  {
    "text": "this code what the pump essentially does is when there are let's say three masses just in the queue we take the first",
    "start": "1124830",
    "end": "1130529"
  },
  {
    "text": "message out of the queue invoke our code right and then we take the next message out of the queue and it woke our code if",
    "start": "1130529",
    "end": "1138179"
  },
  {
    "text": "the handler of that code takes twenty seconds it takes at least twenty seconds",
    "start": "1138179",
    "end": "1143370"
  },
  {
    "text": "until the next message is taken out out of out of the code so what we can say",
    "start": "1143370",
    "end": "1148649"
  },
  {
    "text": "here is there is a metric called critical time in queueing system and what we can say here with the code that",
    "start": "1148649",
    "end": "1154590"
  },
  {
    "text": "we wrote the critical time that we had in our system on that specific you went through the rooftop what is the critical",
    "start": "1154590",
    "end": "1161279"
  },
  {
    "text": "time so the critical time is consistent out of three data points so the first is",
    "start": "1161279",
    "end": "1166350"
  },
  {
    "text": "the network's end time so that's the time that we spent on the networking layer with serialization and everything",
    "start": "1166350",
    "end": "1173460"
  },
  {
    "text": "until the message is in the destination queue that's the first piece of the puzzle then what we have is we have the",
    "start": "1173460",
    "end": "1179820"
  },
  {
    "text": "queue wait time and the queue wait time in this example is when we have three messages for the last message if",
    "start": "1179820",
    "end": "1186360"
  },
  {
    "text": "handling a message takes twenty seconds right it's 20 seconds per message so it",
    "start": "1186360",
    "end": "1191519"
  },
  {
    "text": "takes at least 40 seconds until the third message comma sebacic you wait",
    "start": "1191519",
    "end": "1197820"
  },
  {
    "text": "time and then we also have the app the actual processing time which is the the",
    "start": "1197820",
    "end": "1203730"
  },
  {
    "text": "overhead of the message pump infrastructure the overhead of destabilization from the networking layer and then actually invoking our our",
    "start": "1203730",
    "end": "1211799"
  },
  {
    "text": "handle handler code so that is the critical time that that we had a problem",
    "start": "1211799",
    "end": "1217289"
  },
  {
    "text": "with and we said well that's easy right we are programmers we can solve",
    "start": "1217289",
    "end": "1222480"
  },
  {
    "text": "that so let's roll back our sleeves and get some coding done and then someone said yeah but now we need to introduce",
    "start": "1222480",
    "end": "1228960"
  },
  {
    "start": "1226000",
    "end": "1226000"
  },
  {
    "text": "concurrency and as we know concurrency is hard it's super hard and not",
    "start": "1228960",
    "end": "1234269"
  },
  {
    "text": "everybody understands it but we said we can do it and let's let's give it give",
    "start": "1234269",
    "end": "1239759"
  },
  {
    "text": "it a try and before I before I go into the concurrency codes I will click",
    "start": "1239759",
    "end": "1247620"
  },
  {
    "text": "switch to screen in a second I just need to okay I will quickly run the first",
    "start": "1247620",
    "end": "1263370"
  },
  {
    "text": "demo so that you can see that problem for some reason it cuts off a little bit of the screen and let me zoom in a",
    "start": "1263370",
    "end": "1272789"
  },
  {
    "text": "little bit it's a better visible now okay so that you believe me that we had a",
    "start": "1272789",
    "end": "1280289"
  },
  {
    "text": "problem I'm going to I'm going to run the first version of the pump like like",
    "start": "1280289",
    "end": "1286529"
  },
  {
    "text": "you can see here is we're handling the first message the second message the third message the fourth message and the",
    "start": "1286529",
    "end": "1291720"
  },
  {
    "text": "fifth message so let's have a look at the the code changes that we did so this",
    "start": "1291720",
    "end": "1298080"
  },
  {
    "text": "is the this is the concurrency pump that that we wrote so as you can see here the",
    "start": "1298080",
    "end": "1304590"
  },
  {
    "text": "code is pretty pretty similar so what we do is we have a while loop which also",
    "start": "1304590",
    "end": "1311340"
  },
  {
    "text": "observes the cancellation token and then what we do is we have this fetch and handle message action that is the code",
    "start": "1311340",
    "end": "1318840"
  },
  {
    "text": "that we had before so we read from the queue we digitalize and then we invoke the handle message we have the same code",
    "start": "1318840",
    "end": "1325919"
  },
  {
    "text": "here toss delay of a thousand then pumping we print out something to the console and then we when we stop we",
    "start": "1325919",
    "end": "1334230"
  },
  {
    "text": "cancel the cancellation token source here I'm cancelling it in 100",
    "start": "1334230",
    "end": "1340529"
  },
  {
    "text": "milliseconds you will see later in the demo why and that's basically it",
    "start": "1340529",
    "end": "1345840"
  },
  {
    "text": "so fire-and-forget just for for your curiosity this is just a method that is",
    "start": "1345840",
    "end": "1351929"
  },
  {
    "text": "empty that accepts a task why do I do that well if you have async await",
    "start": "1351929",
    "end": "1358080"
  },
  {
    "text": "enabled code and if you're not awaiting a task that is returned by a method usually the compiler tells you you're",
    "start": "1358080",
    "end": "1363840"
  },
  {
    "text": "probably doing something wrong right so what I need to do I need to consume that task and I need to tell the compiler",
    "start": "1363840",
    "end": "1369899"
  },
  {
    "text": "dude I know what I'm doing so please shut up okay you could also instead of",
    "start": "1369899",
    "end": "1375090"
  },
  {
    "text": "having a method that accepts the task you could for example do underscore equals and then just basically call it",
    "start": "1375090",
    "end": "1381510"
  },
  {
    "text": "dropping the tasks on the on the floor because we're not really interested in the outcome of the of the task so let me",
    "start": "1381510",
    "end": "1391260"
  },
  {
    "text": "go back to the slides and do a brief recap so what we did is instead of",
    "start": "1391260",
    "end": "1402150"
  },
  {
    "text": "sequential izing the call like we had before like every a weight statement in the code is sequentialized here and when",
    "start": "1402150",
    "end": "1408180"
  },
  {
    "text": "the i/o bound code is done waking me up again so that they can process the next thing so instead of think sequential",
    "start": "1408180",
    "end": "1413670"
  },
  {
    "text": "izing is we said okay let's just do a fire-and-forget and we said well this is",
    "start": "1413670",
    "end": "1419370"
  },
  {
    "text": "pretty easy code right this nothing really really worrisome about it do we",
    "start": "1419370",
    "end": "1424620"
  },
  {
    "text": "need to really test this a lot now no we can paraview it let's just ship it to production right thanks well that's tiny",
    "start": "1424620",
    "end": "1432150"
  },
  {
    "text": "little change although it looks so harmless actually gave us quite a few problems because it worked again onto",
    "start": "1432150",
    "end": "1438270"
  },
  {
    "start": "1437000",
    "end": "1437000"
  },
  {
    "text": "this freaking them rush hour so it's interesting because in the rush hours",
    "start": "1438270",
    "end": "1443430"
  },
  {
    "text": "we're actually or let's say our customs of the systems they're actually making money because we are selling stuff or or",
    "start": "1443430",
    "end": "1449400"
  },
  {
    "text": "we're refunding invoices or whatever we are doing when we are processing the commands and end messages but now and we",
    "start": "1449400",
    "end": "1458400"
  },
  {
    "text": "actually want to make money with the business right but in this specific case because we introduce that introduce a",
    "start": "1458400",
    "end": "1463620"
  },
  {
    "text": "tiny little change we're actually losing money right now why are we losing money well let's have a quick look so what we",
    "start": "1463620",
    "end": "1471330"
  },
  {
    "text": "what we have is the pump that we just wrote it it basically runs on an",
    "start": "1471330",
    "end": "1476610"
  },
  {
    "text": "unbounded concurrency mode what does that mean well if you just have one message in the queue it's fine because",
    "start": "1476610",
    "end": "1482760"
  },
  {
    "text": "it picks it up and handles it but if we have a thousand a hundred thousand messages in the queue it's basically",
    "start": "1482760",
    "end": "1488310"
  },
  {
    "text": "going to spawn a thousand or a hundred thousand concurrent receive operation from the queue and it's going to to eat",
    "start": "1488310",
    "end": "1495540"
  },
  {
    "text": "up those messages and we all have it in our dreams that our systems that we",
    "start": "1495540",
    "end": "1500700"
  },
  {
    "text": "write and deploy have limited limitless resources right but every system has somewhere a weak link in the chain and",
    "start": "1500700",
    "end": "1508620"
  },
  {
    "text": "in our case it was the database sorry I'm unfairly blaming the database right now right I mean",
    "start": "1508620",
    "end": "1514950"
  },
  {
    "text": "but in this case every database has a DB connection pool and yes you can increase the DB connection pool size but off to a",
    "start": "1514950",
    "end": "1521669"
  },
  {
    "text": "certain extent when you're managing connections it's either the queuing system directly or in our case the database starts",
    "start": "1521669",
    "end": "1530549"
  },
  {
    "text": "choking and then we might up depending how we wrote the code we might up eating",
    "start": "1530549",
    "end": "1535799"
  },
  {
    "text": "up our all all our resources and actually crashed the servers or crash the crash DB or we're all going to",
    "start": "1535799",
    "end": "1543419"
  },
  {
    "text": "transaction timeouts and all kinds of rollback problems and make make it actually even worse when we're running",
    "start": "1543419",
    "end": "1548669"
  },
  {
    "text": "that that piece piece of the of the code and one interesting thing is that well",
    "start": "1548669",
    "end": "1556169"
  },
  {
    "text": "we introduced a storage back queue in our architecture we could have done retries and and queuing in memory with",
    "start": "1556169",
    "end": "1563190"
  },
  {
    "text": "the previous architecture but we said we're using a storage back you because we can trust that the storage has",
    "start": "1563190",
    "end": "1569760"
  },
  {
    "text": "probably almost infinite resources we can store all the precious requests that",
    "start": "1569760",
    "end": "1575070"
  },
  {
    "text": "we get from our customers on a disk based system and whenever we have time we pick it up but now because we have an",
    "start": "1575070",
    "end": "1582059"
  },
  {
    "text": "unbounded concurrency we're actually losing that benefit of the queuing system because we fetch too much stuff",
    "start": "1582059",
    "end": "1588630"
  },
  {
    "text": "at the same time and start overwhelming the resources that are actually limited",
    "start": "1588630",
    "end": "1595850"
  },
  {
    "text": "so well we then said mmm we're good programmers right so probably you",
    "start": "1595850",
    "end": "1601740"
  },
  {
    "text": "already have heard of semaphores or semaphore slim there is a way how we can limit concurrency and how we can tweak",
    "start": "1601740",
    "end": "1609299"
  },
  {
    "text": "the weakest element in the chain so what we did there is we said well the DB let's assume the DB can handle a hundred",
    "start": "1609299",
    "end": "1615690"
  },
  {
    "text": "connections concurrently so all we want to do is we want to fetch a hundred messages concurrently from the queue and",
    "start": "1615690",
    "end": "1622080"
  },
  {
    "text": "no more right if there is just one in there we just pick one but if there is a hundred and one in there we just pick a",
    "start": "1622080",
    "end": "1627240"
  },
  {
    "text": "hundred because we know that saving or in our architecture that might be different in your architecture but we",
    "start": "1627240",
    "end": "1633330"
  },
  {
    "text": "essentially wanted to prevent to DDoS ourselves where with with messaging so",
    "start": "1633330",
    "end": "1640230"
  },
  {
    "text": "I'm going to briefly show you the demo from the previous on the unbounded",
    "start": "1640230",
    "end": "1648179"
  },
  {
    "text": "concurrent stuff hopefully you can see it no I'll",
    "start": "1648179",
    "end": "1653850"
  },
  {
    "text": "need to move it over a little bit so now if I hit enter I'm going to use the",
    "start": "1653850",
    "end": "1660059"
  },
  {
    "text": "unbounded concurrency thing remember I just run this code on my 8 core i7",
    "start": "1660059",
    "end": "1665970"
  },
  {
    "text": "machine a hundred milliseconds and then I stop it immediately stop it but already here I'm not sure what the",
    "start": "1665970",
    "end": "1672030"
  },
  {
    "text": "actual number is but I think I'm handling in the 100 milliseconds before I shut down I'm handing over 30,000",
    "start": "1672030",
    "end": "1678780"
  },
  {
    "text": "concurrent operations ok I'm cheating a bit because I'm not doing actual IO it's just illustrate what could happen right",
    "start": "1678780",
    "end": "1685679"
  },
  {
    "text": "of course with I own latency it would be a bit slower but depending on your network resources it might also be tens",
    "start": "1685679",
    "end": "1692640"
  },
  {
    "text": "of thousands of of requests that we would be hand handling here so let's",
    "start": "1692640",
    "end": "1698150"
  },
  {
    "text": "let's see what we what we came up with so what we did is we introduced the",
    "start": "1698150",
    "end": "1704820"
  },
  {
    "text": "semaphore slim so semaphore slim is the more efficient variant of the traditional semaphore it's I think up to",
    "start": "1704820",
    "end": "1711210"
  },
  {
    "text": "5 times faster than the previous semaphore because it uses a combination of spinning and waiting so it's much",
    "start": "1711210",
    "end": "1719100"
  },
  {
    "text": "more efficient doesn't introduce kernel transitions and that stuff so we use that and this is basically like a toll",
    "start": "1719100",
    "end": "1725220"
  },
  {
    "text": "lane on the highway right we're saying well up to the maximum concurrency here in my example it's 3 but in with a DB",
    "start": "1725220",
    "end": "1732360"
  },
  {
    "text": "connection for example could be hundred we're saying we never want to pass more than three cars through the toll lane",
    "start": "1732360",
    "end": "1738929"
  },
  {
    "text": "right the toll lane only has three paths to go through and what we do then is",
    "start": "1738929",
    "end": "1744659"
  },
  {
    "text": "when we pump here with the pump we say please acquire the semaphore as long as the semaphore still has places free as",
    "start": "1744659",
    "end": "1751559"
  },
  {
    "text": "long as the toll lane is free this code doesn't doesn't asynchronously block",
    "start": "1751559",
    "end": "1757289"
  },
  {
    "text": "right so what it will happen is we fall through here and then we do fetch and handle and release so we still do fire",
    "start": "1757289",
    "end": "1765419"
  },
  {
    "text": "and forget right because we don't want to have an away statement on this line if you introduce in a weight statement",
    "start": "1765419",
    "end": "1771419"
  },
  {
    "text": "in this line we would is again sequentially process messages we want to - concurrently process things so what we",
    "start": "1771419",
    "end": "1778799"
  },
  {
    "text": "do is in this fetch and handle release is we again read stuff from the queue we",
    "start": "1778799",
    "end": "1786029"
  },
  {
    "text": "handle the actual business code and then we release the semaphore we need to release the semaphore in the final block",
    "start": "1786029",
    "end": "1791879"
  },
  {
    "text": "so that we have more slots available again in the semaphore or basically free",
    "start": "1791879",
    "end": "1798210"
  },
  {
    "text": "up the resources in in the toll lane right but then we also realized is that",
    "start": "1798210",
    "end": "1803789"
  },
  {
    "text": "well when we shut down the system we might have messages that are still processing for a period of time I for",
    "start": "1803789",
    "end": "1811049"
  },
  {
    "text": "example you're shutting down your server because or your receiver component because you can now have messaging right",
    "start": "1811049",
    "end": "1816359"
  },
  {
    "text": "because we have a storage back here but you don't want to basically abort in the",
    "start": "1816359",
    "end": "1821639"
  },
  {
    "text": "middle of processing one way of doing that when we have a semaphore is we can introduce sort of sort of a graceful",
    "start": "1821639",
    "end": "1828299"
  },
  {
    "text": "shutdown so we can tell when we when we cancel the cancellation token what you can say is this loop will no longer",
    "start": "1828299",
    "end": "1834809"
  },
  {
    "text": "continue but resources that already acquired the semaphore encoder slot that",
    "start": "1834809",
    "end": "1840179"
  },
  {
    "text": "are currently processing this fetch and handle release can still still have time to basically do their processing and",
    "start": "1840179",
    "end": "1847139"
  },
  {
    "text": "shut down by the way that's up to you right you might have different requirements but here I'm just showing",
    "start": "1847139",
    "end": "1852210"
  },
  {
    "text": "that the little trickery what we can do is we can have a while loop that basically loops over the",
    "start": "1852210",
    "end": "1858149"
  },
  {
    "text": "semaphore current count not equals max concurrency and then we do an wait a",
    "start": "1858149",
    "end": "1863309"
  },
  {
    "text": "still a writes the the asynchronous fancy version of read sleep but it doesn't block any resources and then we",
    "start": "1863309",
    "end": "1870269"
  },
  {
    "text": "weep all essentially the semaphore until we know that all the slots are released",
    "start": "1870269",
    "end": "1875279"
  },
  {
    "text": "and then we know because we cancelled the loop we're no longer receiving messages so then we can gracefully shut",
    "start": "1875279",
    "end": "1881100"
  },
  {
    "text": "down the system dispose all all the resources that's that's another thing that we reintroduced in this limiting",
    "start": "1881100",
    "end": "1888169"
  },
  {
    "text": "concurrency code good so let's go back",
    "start": "1888169",
    "end": "1895259"
  },
  {
    "text": "to the slides",
    "start": "1895259",
    "end": "1897799"
  },
  {
    "text": "so in recap what we can say is with the introduction of the semaphore we basically had a way to control the",
    "start": "1906430",
    "end": "1913010"
  },
  {
    "text": "floodgate of messages that came into the system and while the code was pretty",
    "start": "1913010",
    "end": "1919040"
  },
  {
    "text": "straightforward we could ship it to production and this worked really nicely so this worked for a month in production",
    "start": "1919040",
    "end": "1924650"
  },
  {
    "text": "we had we didn't really have any sort of runtime behavioral type of issues with",
    "start": "1924650",
    "end": "1929930"
  },
  {
    "text": "with this phone so this was pretty nice but one problem that that we had was",
    "start": "1929930",
    "end": "1935990"
  },
  {
    "text": "well as time started passing well I was a technical lead in the protein and I",
    "start": "1935990",
    "end": "1942020"
  },
  {
    "start": "1937000",
    "end": "1937000"
  },
  {
    "text": "was tasked to build this messaging abstraction that was a lot of fun right there's nothing better than distracting",
    "start": "1942020",
    "end": "1948500"
  },
  {
    "text": "yourself from this damn business requirements and writing some fancy infrastructure framework type of code",
    "start": "1948500",
    "end": "1954260"
  },
  {
    "text": "that's that's what we at least I love it I'm not gonna assume that you love it too but I love this really and so I did",
    "start": "1954260",
    "end": "1962480"
  },
  {
    "text": "that and I had this mercy dispensed in mind while we're here in Norway right right land with probably the most tests",
    "start": "1962480",
    "end": "1968330"
  },
  {
    "text": "laws on the planet so it's probably more a Tesla Model 3 3 that I wanted to build",
    "start": "1968330",
    "end": "1974510"
  },
  {
    "text": "and that time so I I did it but the thing was like always write as a",
    "start": "1974510",
    "end": "1980660"
  },
  {
    "text": "technical lead in a project your time is precious and everybody wants something from you so at the beginning you have a",
    "start": "1980660",
    "end": "1986600"
  },
  {
    "text": "lot of time you build it and then you need to still deal with these these damn business requirements and you get you're",
    "start": "1986600",
    "end": "1993170"
  },
  {
    "text": "moving away you're not touching the code again and then the team started to extend that messaging middleware that I",
    "start": "1993170",
    "end": "1999680"
  },
  {
    "text": "built on the pressure I know what you're thinking he's gonna blame the team actually I could know it wasn't their",
    "start": "1999680",
    "end": "2006130"
  },
  {
    "text": "fault I mean it's of course it's like every every project is pressure we need to deliver business business value and",
    "start": "2006130",
    "end": "2012610"
  },
  {
    "text": "that's that's what we're here for right so and then over time when we started",
    "start": "2012610",
    "end": "2018160"
  },
  {
    "text": "extending this we had more and more requirements that we needed to build into this frame so one of the things",
    "start": "2018160",
    "end": "2023920"
  },
  {
    "text": "that came well for every message that we received successfully we want to audit the message that's one example right or",
    "start": "2023920",
    "end": "2030220"
  },
  {
    "text": "all we need to think about transactions and all that kind of stuff and then we",
    "start": "2030220",
    "end": "2035560"
  },
  {
    "text": "started to make this code I call it flex tangible so let me show you how this code might",
    "start": "2035560",
    "end": "2044320"
  },
  {
    "text": "have looked like and let me also show you the previous demo with the concurrency limit so now when I'm",
    "start": "2044320",
    "end": "2053200"
  },
  {
    "text": "running this code this is the pump with the limiting concurrency that we built before so now as we can see we always",
    "start": "2053200",
    "end": "2059980"
  },
  {
    "text": "have like three men we handle three messages concurrently and once we have no more messages in the queue we",
    "start": "2059980",
    "end": "2066669"
  },
  {
    "text": "gracefully shut down and we are done but let's go back at what happened and this",
    "start": "2066670",
    "end": "2073389"
  },
  {
    "text": "is this is just an illustration right I hope you get how abstract I have to show",
    "start": "2073390",
    "end": "2078820"
  },
  {
    "text": "this a little bit but what we did here is well we said okay how about for the",
    "start": "2078820",
    "end": "2085210"
  },
  {
    "text": "auditing part we need some kind of extensible middleware that we can plug into sort of like a wing that we can",
    "start": "2085210",
    "end": "2091659"
  },
  {
    "text": "plug in to our messaging abstraction library so the the basic bits that we bits that we just build is still the",
    "start": "2091660",
    "end": "2097720"
  },
  {
    "text": "same use the semaphore we gracefully shut down but now the complexity starts",
    "start": "2097720",
    "end": "2102910"
  },
  {
    "text": "raising in this code so what we realize is well we have to have some kind of a",
    "start": "2102910",
    "end": "2108160"
  },
  {
    "text": "transaction that wraps the queue receive when the queue is transactional we have to have a transaction that makes sure",
    "start": "2108160",
    "end": "2114400"
  },
  {
    "text": "that when when we receive the message and we have an exception that we successfully roll back the message again",
    "start": "2114400",
    "end": "2119860"
  },
  {
    "text": "into the queue before we actually read the message transactionally then we also",
    "start": "2119860",
    "end": "2125530"
  },
  {
    "text": "realize that we have some kind of infrastructure on our dependency injection container that we lost at that",
    "start": "2125530",
    "end": "2131260"
  },
  {
    "text": "time that we need to potentially resolve per message that we handle and pass it on to the object hierarchy that we're",
    "start": "2131260",
    "end": "2138010"
  },
  {
    "text": "resolving when we handled the business requirement so we build some kind of a child service provider abstraction you",
    "start": "2138010",
    "end": "2144550"
  },
  {
    "text": "probably have heard of a speed on the core with the with the service provider there that's something similar but we",
    "start": "2144550",
    "end": "2151630"
  },
  {
    "text": "wrote it on our own right so the the will gets reinvented every time in software development so we did that and",
    "start": "2151630",
    "end": "2158260"
  },
  {
    "text": "then we said okay now we need this we need some kind of a middleware so that",
    "start": "2158260",
    "end": "2163270"
  },
  {
    "text": "we can plug in the stuff and we came up with this phone cancer context functions the context cancellation token toss toss",
    "start": "2163270",
    "end": "2169990"
  },
  {
    "text": "cancellation token array sorry probably your head is now exploding but and this is the extensible",
    "start": "2169990",
    "end": "2177110"
  },
  {
    "text": "middleware that we came up with and now we're no longer directly handling the the business code we're invoking the",
    "start": "2177110",
    "end": "2183560"
  },
  {
    "text": "middleware and as part of invoking the middleware when that's done then we",
    "start": "2183560",
    "end": "2188720"
  },
  {
    "text": "complete the transaction of course like every framework that we write you all we had also some - dues in there what",
    "start": "2188720",
    "end": "2195320"
  },
  {
    "text": "should we do with the exception handling and then a middleware looked like this right this is basically a function that",
    "start": "2195320",
    "end": "2201680"
  },
  {
    "text": "we can plug into the middle where that can wrap the execution like a wing or like a SP action filters and stuff that",
    "start": "2201680",
    "end": "2208280"
  },
  {
    "text": "can wrap the execution of the pipeline and somewhere deep down we had the",
    "start": "2208280",
    "end": "2213500"
  },
  {
    "text": "actual business code invocation where we used our child service provider provider",
    "start": "2213500",
    "end": "2218600"
  },
  {
    "text": "abstraction factory factory factory to resolve the I handle messages that we came up with two and then evoke all the",
    "start": "2218600",
    "end": "2225380"
  },
  {
    "text": "handlers and once that's done invoke the rest of the pipeline and I'm showing here for each within a wait you could",
    "start": "2225380",
    "end": "2231830"
  },
  {
    "text": "also handle all those implementations concurrently by using tasks when all of course that's an implementation detail",
    "start": "2231830",
    "end": "2237800"
  },
  {
    "text": "but that's more or less how the code started to look like that that we that",
    "start": "2237800",
    "end": "2245690"
  },
  {
    "text": "we built so the funny part is that well",
    "start": "2245690",
    "end": "2254720"
  },
  {
    "text": "well while I wanted to build this Tesla Model 3 over time because with pressure",
    "start": "2254720",
    "end": "2261260"
  },
  {
    "text": "we probably built mortis this this rusty little car and depending who you asked",
    "start": "2261260",
    "end": "2266300"
  },
  {
    "text": "in the team some people didn't like that code or said oh it's dangerous I don't know it's too complex semaphore and",
    "start": "2266300",
    "end": "2272750"
  },
  {
    "text": "crazy concurrency I don't want to touch it so for them it probably looked like this and for some other people like me",
    "start": "2272750",
    "end": "2281300"
  },
  {
    "text": "or some other fans there that became fan of this codebase it looked more like this right and by the way that when your",
    "start": "2281300",
    "end": "2289430"
  },
  {
    "text": "that's that's happened it happens when you prepare a talk and you're procrastinating and you search for funny",
    "start": "2289430",
    "end": "2295400"
  },
  {
    "text": "cars now you find you find those pictures and the interesting things I like I mean he's really the guys really",
    "start": "2295400",
    "end": "2301760"
  },
  {
    "text": "enjoying himself here but the coolest one is the this guy over there looks like what the hell is he doing",
    "start": "2301760",
    "end": "2309070"
  },
  {
    "text": "anyway so but then what you can say is what I just did here is I only talked",
    "start": "2309070",
    "end": "2316520"
  },
  {
    "start": "2312000",
    "end": "2312000"
  },
  {
    "text": "about the basic bits about the send and receive but we also have to deal with transactions I quickly had this in the",
    "start": "2316520",
    "end": "2323420"
  },
  {
    "text": "code sort of hand waved a little bit said we need to kind have some kind of a transaction I think if you're writing",
    "start": "2323420",
    "end": "2330680"
  },
  {
    "text": "robust messaging middleware you have to think about transactions and what's going to happen so let me illustrate",
    "start": "2330680",
    "end": "2336620"
  },
  {
    "text": "that quickly so code that is executed under handling a message is never side-effect free right because you're",
    "start": "2336620",
    "end": "2343700"
  },
  {
    "text": "going to invoke business code and as part of that business code you're going to write stuff into the database you're",
    "start": "2343700",
    "end": "2349250"
  },
  {
    "text": "going to create transactions unit of works and all that kind of stuff but you might also want to start leveraging",
    "start": "2349250",
    "end": "2355160"
  },
  {
    "text": "messaging more and more in that message stream in architecture you might also think well I need to invoke sales for",
    "start": "2355160",
    "end": "2360860"
  },
  {
    "text": "sales forces sometimes down so I want to be able to retry a sales force command",
    "start": "2360860",
    "end": "2366410"
  },
  {
    "text": "or send something to sale force then you're going to use more messaging so what are we going to do is you're going",
    "start": "2366410",
    "end": "2371660"
  },
  {
    "text": "to to invoke more messages or more send operations as part of your message pump",
    "start": "2371660",
    "end": "2377030"
  },
  {
    "text": "so let's do a quick example so when we have a transactional queueing system what we can say is we start the",
    "start": "2377030",
    "end": "2383690"
  },
  {
    "text": "transaction we pick up the the message from the queue and then we invoke the business code and as part of this",
    "start": "2383690",
    "end": "2389780"
  },
  {
    "text": "business code we're for example sending a message to destination 1 to destination 2 and we write something",
    "start": "2389780",
    "end": "2395480"
  },
  {
    "text": "into the storage layer which which for example can be sequence or whatever thing that you're using and once that is",
    "start": "2395480",
    "end": "2401780"
  },
  {
    "text": "successful we commit the transaction to the queueing system or we abort things the good thing is when you have MS mq",
    "start": "2401780",
    "end": "2408830"
  },
  {
    "text": "for example and sequel server on-premises you have this beast hidden somewhere which is called the distributed transaction coordinator and",
    "start": "2408830",
    "end": "2415490"
  },
  {
    "text": "the distributed transaction coordinator allows you to have a two-phase commit protocol that basically wraps all the",
    "start": "2415490",
    "end": "2420890"
  },
  {
    "text": "operations involved here in a transactional way so what it means is the sequel server inserts are in the",
    "start": "2420890",
    "end": "2427310"
  },
  {
    "text": "same transactions as the queuing system so what we have is we have either successfully processed all the things so",
    "start": "2427310",
    "end": "2434390"
  },
  {
    "text": "we have we have successfully invoked the codes we have prepared the transaction to the destination queues",
    "start": "2434390",
    "end": "2440359"
  },
  {
    "text": "and we have prepared the transaction into the storage layer and then we successfully committed all those or we",
    "start": "2440359",
    "end": "2446480"
  },
  {
    "text": "rolled back and no side effects happened that's that's pretty cool if you have MSM kin sequel server I'm not an",
    "start": "2446480",
    "end": "2453559"
  },
  {
    "text": "advocate of the distributed transaction coordinator please don't get me wrong I'm just saying if you have it you might have it that's a way to have",
    "start": "2453559",
    "end": "2460190"
  },
  {
    "text": "transactional consistency early or on from a technical stand stand point but",
    "start": "2460190",
    "end": "2467299"
  },
  {
    "text": "maybe if you have your code on premises and you have some throughput problems you might think about how how about we",
    "start": "2467299",
    "end": "2473539"
  },
  {
    "text": "move to RabbitMQ because we heard those rabbitmq on top of Erlang is much much faster it can handle tens of thousands",
    "start": "2473539",
    "end": "2479569"
  },
  {
    "text": "of messages per second well then what's going to happen is you're not also not",
    "start": "2479569",
    "end": "2485869"
  },
  {
    "text": "only throwing away the plumbing code that we just wrote against the SDK of let's say MSM your Seco serve ATO dotnet",
    "start": "2485869",
    "end": "2492499"
  },
  {
    "text": "you're going to rip out that code and replace it but for example if the RabbitMQ pivotal client that has its own",
    "start": "2492499",
    "end": "2498739"
  },
  {
    "text": "assumptions but it also has implications on on the transactionality because rabid",
    "start": "2498739",
    "end": "2503960"
  },
  {
    "text": "mq for example doesn't provide what what is called cross cue transactions what you have of rabbitmq only have received",
    "start": "2503960",
    "end": "2510349"
  },
  {
    "text": "only transactions receive only transactions means that when you get a message you either a kit or neck it's",
    "start": "2510349",
    "end": "2516230"
  },
  {
    "text": "right when you a kit the message is successfully handled when you neck it it",
    "start": "2516230",
    "end": "2521450"
  },
  {
    "text": "rolls back into the queue and will be dispatched again to your code but all the other things might be still still",
    "start": "2521450",
    "end": "2529339"
  },
  {
    "text": "visible for example the storage stuff so what we can get here is we can can get",
    "start": "2529339",
    "end": "2534769"
  },
  {
    "text": "into things like partial updates so partial updates illustrated here can be",
    "start": "2534769",
    "end": "2539930"
  },
  {
    "text": "something like for example we have two pieces of code that we invoke concurrently as part of the message",
    "start": "2539930",
    "end": "2545180"
  },
  {
    "text": "handling transaction and then the the piece here in green it writes to the database and the the red piece here it",
    "start": "2545180",
    "end": "2552349"
  },
  {
    "text": "rises to the destination cue one destination cue 2 and into the database and now when the message gets nacked",
    "start": "2552349",
    "end": "2558950"
  },
  {
    "text": "those things here the destination 1 and destination 2 rights already happened",
    "start": "2558950",
    "end": "2564039"
  },
  {
    "text": "right so that's one thing that can happen with with RabbitMQ for example",
    "start": "2564039",
    "end": "2570859"
  },
  {
    "text": "but then we also have partial partial and parcel sense means at any point in",
    "start": "2570859",
    "end": "2577400"
  },
  {
    "text": "the code when we invoke the networking layer of the driver of rabid MQ there can be failures happening right so for",
    "start": "2577400",
    "end": "2584299"
  },
  {
    "text": "example what could happen is that if we we write a destination 1 then we lose",
    "start": "2584299",
    "end": "2589430"
  },
  {
    "text": "the connection to the rabid mq broker and if we don't have retries built into the driver itself then this destination",
    "start": "2589430",
    "end": "2596299"
  },
  {
    "text": "right will fail we might roll back the message and retry it and then we send out destination 1",
    "start": "2596299",
    "end": "2602720"
  },
  {
    "text": "message again and destination 2 message but we already got the partial send visible on down streams right that are",
    "start": "2602720",
    "end": "2608989"
  },
  {
    "text": "receiving messages from the destination q1 so what that means the implication of",
    "start": "2608989",
    "end": "2614450"
  },
  {
    "text": "this is when you move it for example to rabbitmq your business code needs to be idempotent from business level",
    "start": "2614450",
    "end": "2620059"
  },
  {
    "text": "perspective idempotency it's just a fancy way of saying whether it's it whether the code is invoked once or",
    "start": "2620059",
    "end": "2626989"
  },
  {
    "text": "multiple times the fact is the same right so that's basically item idempotency but what it also means for",
    "start": "2626989",
    "end": "2634640"
  },
  {
    "text": "the queuing abstraction that we're writing is where we place the c-sharp code in that abstraction library is",
    "start": "2634640",
    "end": "2640670"
  },
  {
    "text": "extremely important because if we have the code at the wrong point in our code",
    "start": "2640670",
    "end": "2646039"
  },
  {
    "text": "base we might end up with business inconsistencies that we have to deal",
    "start": "2646039",
    "end": "2651559"
  },
  {
    "text": "with or even message losses in some scenarios but then like we know that",
    "start": "2651559",
    "end": "2658009"
  },
  {
    "text": "software projects they evolve over time you're not writing everything from scratch knew at some point in time you",
    "start": "2658009",
    "end": "2664400"
  },
  {
    "text": "might move from on-premises to the clouds and I call it Cloudy with a Chance of failure right as soon as if you start",
    "start": "2664400",
    "end": "2671089"
  },
  {
    "text": "moving to the cloud from our on-premises data center whether it's a cost-effectiveness or whatever you want",
    "start": "2671089",
    "end": "2677450"
  },
  {
    "text": "to use we also have different transactionality mechanisms for example with AWS SQS if you're running in the",
    "start": "2677450",
    "end": "2684859"
  },
  {
    "text": "AWS cloud what we have is we have received only transactions that are",
    "start": "2684859",
    "end": "2690079"
  },
  {
    "text": "implemented with the color is a message visibility timeout so what it means is for your code it has to deal with",
    "start": "2690079",
    "end": "2696859"
  },
  {
    "text": "message visibility timeout extensions message will visibility with AWS eschars",
    "start": "2696859",
    "end": "2702410"
  },
  {
    "text": "means and by the way that also applies for extra storage queues for example using Azure storage queues in Azure",
    "start": "2702410",
    "end": "2707910"
  },
  {
    "text": "means that once we get the message the message visibility timer starts counting let's say it's 30 seconds now if the",
    "start": "2707910",
    "end": "2715200"
  },
  {
    "text": "code executes under 30 seconds we are fine but if the code takes longer than",
    "start": "2715200",
    "end": "2720359"
  },
  {
    "text": "30 seconds let's say for example 45 seconds then the message will reappear in the input queue while we are still",
    "start": "2720359",
    "end": "2727020"
  },
  {
    "text": "processing that message and we will handle the same business message multiple times so we need to make sure",
    "start": "2727020",
    "end": "2733319"
  },
  {
    "text": "that our codes while we are processing continuously extends the message",
    "start": "2733319",
    "end": "2738480"
  },
  {
    "text": "visibility time out on the server or sets a high enough timer that is good",
    "start": "2738480",
    "end": "2744930"
  },
  {
    "text": "enough for most of our business cases if you're using a service bus for example most people don't know that there is a",
    "start": "2744930",
    "end": "2751109"
  },
  {
    "text": "concept that we call sense with atomic receive as a service bus has the possibility to use in together with",
    "start": "2751109",
    "end": "2759030"
  },
  {
    "text": "transaction scopes I think that they call send via what it means is we send",
    "start": "2759030",
    "end": "2764430"
  },
  {
    "text": "why is when we get a transaction we start a transaction scope we take the message out of the queue invoke the",
    "start": "2764430",
    "end": "2771000"
  },
  {
    "text": "business code and instead of sending to destination one and sending to destination two what we do is we send a",
    "start": "2771000",
    "end": "2778349"
  },
  {
    "text": "message to the input queue and attach a send via header to it and that send wire",
    "start": "2778349",
    "end": "2783480"
  },
  {
    "text": "Heather says while by the way if I acknowledge this message please send that message over to destination one and",
    "start": "2783480",
    "end": "2789779"
  },
  {
    "text": "the other message to destination two and then it's a guaranteed broker side",
    "start": "2789779",
    "end": "2794880"
  },
  {
    "text": "operation that will handle the delivery of the message and one good thing is that if we fail to handle the message if",
    "start": "2794880",
    "end": "2801930"
  },
  {
    "text": "you have to roll back the the transaction no side-effects from a messaging perspective will occur but if",
    "start": "2801930",
    "end": "2808319"
  },
  {
    "text": "you are successful then the guaranteed operation of the broker kicks in and delivers those messages to them to the",
    "start": "2808319",
    "end": "2818339"
  },
  {
    "text": "to the desk destinations so with this mode we can essentially prevent a ghost",
    "start": "2818339",
    "end": "2824730"
  },
  {
    "text": "messages occurring on the on down streams which is pretty nice obviously I didn't mention it yet but as you all",
    "start": "2824730",
    "end": "2831510"
  },
  {
    "text": "know if we have a transactional right into the storage layer it could still be possible that although the message",
    "start": "2831510",
    "end": "2837990"
  },
  {
    "text": "didn't go out we still have partial inserts for exam visible in the database so the database",
    "start": "2837990",
    "end": "2843240"
  },
  {
    "text": "insertion code that we write in our business handlers needs to be idempotent",
    "start": "2843240",
    "end": "2848250"
  },
  {
    "text": "still needs to be item potent but when you're embracing the cloud more and more",
    "start": "2848250",
    "end": "2855060"
  },
  {
    "text": "then there is another concepts that we have to take into account how we write our business or message abstraction",
    "start": "2855060",
    "end": "2860790"
  },
  {
    "text": "library and that's is what I call penny-pinching right because in the cloud we do penny-pinching all the day",
    "start": "2860790",
    "end": "2867359"
  },
  {
    "start": "2861000",
    "end": "2861000"
  },
  {
    "text": "because I mean probably we're running on the credit card of our boss right and we don't like when the boss at the end of",
    "start": "2867359",
    "end": "2873089"
  },
  {
    "text": "the month comes to us and says why did you spend eight hundred thousand Oh reaching cronin on Ash's subscription or",
    "start": "2873089",
    "end": "2879180"
  },
  {
    "text": "whatever that is right we don't want to answer those questions so we better want to make sure that we efficiently operate",
    "start": "2879180",
    "end": "2886680"
  },
  {
    "text": "with the platform as a service offerings that we have in the cloud so for example with a service boss we might have thirty",
    "start": "2886680",
    "end": "2893609"
  },
  {
    "text": "million requests included for example in the standard tier but once we reach a",
    "start": "2893609",
    "end": "2899400"
  },
  {
    "text": "certain threshold for example we start paying for 87 million operations on the",
    "start": "2899400",
    "end": "2905430"
  },
  {
    "text": "broker we we roughly pay 80 US dollars per month per 87 million operation and",
    "start": "2905430",
    "end": "2912770"
  },
  {
    "text": "87 million sounds like an awful a lot right because it's a huge number but when you do the math what it boils down",
    "start": "2912770",
    "end": "2919380"
  },
  {
    "text": "it boils down to roughly 120 requests",
    "start": "2919380",
    "end": "2924740"
  },
  {
    "text": "per per per hour and that's not that much right so as soon as you start",
    "start": "2924740",
    "end": "2929910"
  },
  {
    "text": "crossing that threshold you're getting charged more and more and more and you better want to make sure that you handle",
    "start": "2929910",
    "end": "2935400"
  },
  {
    "text": "this efficiently and now with the new service bus sdk what they also introduced is because they're not",
    "start": "2935400",
    "end": "2941310"
  },
  {
    "text": "heavily using the mqp protocol and no longer the s and BP protocol or the introduces you're getting charged per",
    "start": "2941310",
    "end": "2947339"
  },
  {
    "text": "mqp connections so what you get is you get included a thousand connections in",
    "start": "2947339",
    "end": "2952349"
  },
  {
    "text": "the standard tier in per month and then as soon as you start crossing more than",
    "start": "2952349",
    "end": "2957750"
  },
  {
    "text": "thousand connections you have to pay three US dollar cents per connection that you invoke against the azure",
    "start": "2957750",
    "end": "2964200"
  },
  {
    "text": "service bus so that also has to be taken into account but one thing that also",
    "start": "2964200",
    "end": "2969780"
  },
  {
    "text": "comes if things are getting worse because with the cloud and with this penny-pinching what we actually can say is",
    "start": "2969780",
    "end": "2975269"
  },
  {
    "text": "request that we do against the broker accounts right so we want to make sure that we do less requests or only the",
    "start": "2975269",
    "end": "2981899"
  },
  {
    "text": "requests that are really necessary but if we have a queuing abstraction library that doesn't think about for example",
    "start": "2981899",
    "end": "2988409"
  },
  {
    "text": "that the latency that every call can have then every single call that the",
    "start": "2988409",
    "end": "2994259"
  },
  {
    "text": "developers are writing to to that broker starts counting in terms of latency and",
    "start": "2994259",
    "end": "2999599"
  },
  {
    "text": "in terms of costs right so what we have to do is we have to come up with for example smart batching right so what we",
    "start": "2999599",
    "end": "3006589"
  },
  {
    "text": "want to do is we want to shovel as many requests as we can into one single call",
    "start": "3006589",
    "end": "3011630"
  },
  {
    "text": "to the cloud and most of those Cloud SDK is they offer you some kind of batching",
    "start": "3011630",
    "end": "3016909"
  },
  {
    "text": "capability and I kind of hand waved and said we need to batch as many requests as we as we can into one single call but",
    "start": "3016909",
    "end": "3024529"
  },
  {
    "text": "what does that mean because every platform as a service offering whether it's Google One or AWS or in even Asher",
    "start": "3024529",
    "end": "3032329"
  },
  {
    "text": "has some some kind of limitations so that they can guarantee their essays what it means for example if you're",
    "start": "3032329",
    "end": "3038479"
  },
  {
    "text": "running with a service bus on the standard here you can batch up to 256k of requests into one single call so if",
    "start": "3038479",
    "end": "3046759"
  },
  {
    "text": "so what it means is you have to start estimating the message size of your payload so that you can make sure that",
    "start": "3046759",
    "end": "3052789"
  },
  {
    "text": "you have only 256k in a single request once you have more you need to start",
    "start": "3052789",
    "end": "3057919"
  },
  {
    "text": "basically dividing it into multiple calls again and by the way if you're doing batching one of the good benefits",
    "start": "3057919",
    "end": "3063799"
  },
  {
    "text": "of batching is also you avoid ghost messages because instead of doing 10 Network calls that can all fail you do",
    "start": "3063799",
    "end": "3070009"
  },
  {
    "text": "only one that contains for example 10 messages right so you also have much",
    "start": "3070009",
    "end": "3075139"
  },
  {
    "text": "more robust and reliable code that you can do and for example if you actually",
    "start": "3075139",
    "end": "3081019"
  },
  {
    "text": "if using Azure storage queues you can only batch 64 kilobyte into a single",
    "start": "3081019",
    "end": "3086239"
  },
  {
    "text": "request so depending on the the middle layer that you're sorry the message across the technologies they're using",
    "start": "3086239",
    "end": "3091849"
  },
  {
    "text": "you have different things that you need to deal with if using rabbitmq for example in",
    "start": "3091849",
    "end": "3097759"
  },
  {
    "text": "premises RabbitMQ can handle payloads of various sizes you're basically only",
    "start": "3097759",
    "end": "3102919"
  },
  {
    "text": "limited by the by the memory that you have available on your broker cluster but it's clear right",
    "start": "3102919",
    "end": "3109119"
  },
  {
    "text": "more garbage you allocate even on Rama thank you the larger that your message is get the more your throughput is going",
    "start": "3109119",
    "end": "3115599"
  },
  {
    "text": "down right so you have to take that into account as well good but now we actually",
    "start": "3115599",
    "end": "3122549"
  },
  {
    "text": "have really the basic bits right so we have sending receiving transactions but",
    "start": "3122549",
    "end": "3128769"
  },
  {
    "text": "we also know we software grows over time and our infrastructure demands on the",
    "start": "3128769",
    "end": "3134019"
  },
  {
    "text": "libraries and frameworks that we build also grows over time so we can say is we're living on the edge of sanity so",
    "start": "3134019",
    "end": "3140529"
  },
  {
    "text": "because when what what else do we need to deal with well for example we want to",
    "start": "3140529",
    "end": "3146680"
  },
  {
    "text": "do competing consumers and scale ads so we need to efficiently handle the connections in the competing consumer",
    "start": "3146680",
    "end": "3151720"
  },
  {
    "text": "scenarios then what we are what we want to do is state management the top of the queueing system for example we want to",
    "start": "3151720",
    "end": "3156940"
  },
  {
    "text": "have runtime configurations routing configuration or we need to depending on the technology we using for example if",
    "start": "3156940",
    "end": "3163630"
  },
  {
    "text": "you're using Azure service boss Microsoft doesn't really tell you how you map topics and subscriptions to",
    "start": "3163630",
    "end": "3169450"
  },
  {
    "text": "queues right you have to come up with the topology that you handle on the azure service bus broker namespace that",
    "start": "3169450",
    "end": "3175059"
  },
  {
    "text": "is suitable for your project and that might vary from project to project and you have to re-implement it that over",
    "start": "3175059",
    "end": "3181450"
  },
  {
    "text": "time but the most important factor here that I want to talk about is not the actual code it's the human beings that",
    "start": "3181450",
    "end": "3187749"
  },
  {
    "text": "actually handle have to deal with that code right because if you're if you're",
    "start": "3187749",
    "end": "3193509"
  },
  {
    "text": "delete evil operator this building the messaging abstraction probably one thing that you constantly make net neglect is",
    "start": "3193509",
    "end": "3198970"
  },
  {
    "text": "documentation all right so when a new team member comes into the team you have",
    "start": "3198970",
    "end": "3204039"
  },
  {
    "text": "to essentially have the necessary documentation to teach the team member how to deal with that library and then",
    "start": "3204039",
    "end": "3210369"
  },
  {
    "text": "when for example you leave the project because you probably want to move to the next shiny little thing in your company",
    "start": "3210369",
    "end": "3216160"
  },
  {
    "text": "and move away then you're still the responsible one that wrote that library but then there is other also the aspects",
    "start": "3216160",
    "end": "3223930"
  },
  {
    "text": "of now we're happy having a distributed system and we probably have a distributed systems mess sometimes in",
    "start": "3223930",
    "end": "3230859"
  },
  {
    "text": "the transition to a more and more and better and better architecture because that's how systems evolve we have to we",
    "start": "3230859",
    "end": "3237400"
  },
  {
    "text": "have to somehow know what's going on right because for example if in production something",
    "start": "3237400",
    "end": "3242480"
  },
  {
    "text": "failing how do we troubleshoot that that stuff how do we monitor how do we visualize the things that are going on",
    "start": "3242480",
    "end": "3248630"
  },
  {
    "text": "in the system and maybe you also have things like you put it in production that's it's wrong smoothly running fine",
    "start": "3248630",
    "end": "3255410"
  },
  {
    "text": "and then at some point in time the CEO comes and says hey we just acquired this new customer and the message load is",
    "start": "3255410",
    "end": "3260780"
  },
  {
    "text": "roughly going to be a hundred million messages a month can our system handle that and how do you answer that question",
    "start": "3260780",
    "end": "3266660"
  },
  {
    "text": "I mean that's something we have to to deal with as well and the distributed",
    "start": "3266660",
    "end": "3272030"
  },
  {
    "text": "system itself they're complex and there's no denying that so we need some kind of tooling that makes sure that",
    "start": "3272030",
    "end": "3277880"
  },
  {
    "text": "everything is running properly and there is lots of ways you can more it or distributed systems and I'm going to",
    "start": "3277880",
    "end": "3285290"
  },
  {
    "text": "quickly show you one way of doing that",
    "start": "3285290",
    "end": "3291340"
  },
  {
    "text": "so for example I have here distributed system running with multiple endpoints",
    "start": "3297670",
    "end": "3304359"
  },
  {
    "text": "and if we're for example using what we call service pulse you can have a look",
    "start": "3304359",
    "end": "3311740"
  },
  {
    "text": "at what's going on so you can see here all the different endpoints you can see the message load you can see here the",
    "start": "3311740",
    "end": "3317410"
  },
  {
    "text": "critical time of our queuing system and if we increase if we make sure for",
    "start": "3317410",
    "end": "3323380"
  },
  {
    "text": "example that we process messages slower and then if we increase the traffic in our system what we can see is if we for",
    "start": "3323380",
    "end": "3330640"
  },
  {
    "text": "example drill down into the QE system we can see that the queue length increases",
    "start": "3330640",
    "end": "3335920"
  },
  {
    "text": "we can see that the throughput rate we can see the processing time is something",
    "start": "3335920",
    "end": "3341700"
  },
  {
    "text": "it's flickering okay thanks yeah okay we can see the processing time and we can",
    "start": "3341700",
    "end": "3347829"
  },
  {
    "text": "see how the how the critical time is is increasing over time because we have",
    "start": "3347829",
    "end": "3353019"
  },
  {
    "text": "more load so one thing that apparently we can also hook into this to get",
    "start": "3353019",
    "end": "3358359"
  },
  {
    "text": "notified so for example one thing that we can do is well we can fix the box and make this thing processing faster to",
    "start": "3358359",
    "end": "3365559"
  },
  {
    "text": "essentially increase the processing time so that we can see that the processing",
    "start": "3365559",
    "end": "3370569"
  },
  {
    "text": "time goes down over time and then that means the queue length is going to be get better or if we discover this",
    "start": "3370569",
    "end": "3377049"
  },
  {
    "text": "automatically we can essentially scale out an additional sales endpoint or even",
    "start": "3377049",
    "end": "3382480"
  },
  {
    "text": "multiple sales endpoint I'm simulating this here and once they start spinning",
    "start": "3382480",
    "end": "3387490"
  },
  {
    "text": "up we can see here that we have now three instances of that sales endpoint running and we can see how the queue",
    "start": "3387490",
    "end": "3394299"
  },
  {
    "text": "length over time basically starts getting better and better and how the critical times starts the decreasing",
    "start": "3394299",
    "end": "3402220"
  },
  {
    "text": "over time and what we what else we get is for example if we have a failure sap",
    "start": "3402220",
    "end": "3408789"
  },
  {
    "text": "happening on our system let's say we we just rolled out something that has a",
    "start": "3408789",
    "end": "3415180"
  },
  {
    "text": "balk we can see how message to start piling up here with with errors we can",
    "start": "3415180",
    "end": "3420400"
  },
  {
    "text": "drill into those errors and once we we fix the BOK we deploy a new version of",
    "start": "3420400",
    "end": "3426640"
  },
  {
    "text": "the code and then what we can do is we can for example say let's retry one message or let's retry the whole",
    "start": "3426640",
    "end": "3433750"
  },
  {
    "text": "group and then we never actually lost any any requests in that system with a",
    "start": "3433750",
    "end": "3439359"
  },
  {
    "text": "with a message based architecture so let me go back to the slides and do a quick",
    "start": "3439359",
    "end": "3445230"
  },
  {
    "text": "wrap-up if it allows me to do so",
    "start": "3445230",
    "end": "3450690"
  },
  {
    "text": "it's a flickering gone now okay good okay well I showed you I showed you how",
    "start": "3450690",
    "end": "3459880"
  },
  {
    "start": "3458000",
    "end": "3458000"
  },
  {
    "text": "for example we do it with the particular chewing of course you can also do up in sides graph on Prometheus whatever fancy",
    "start": "3459880",
    "end": "3466809"
  },
  {
    "text": "tool that you're using in your in your system that's all totally up to you but as a",
    "start": "3466809",
    "end": "3473470"
  },
  {
    "text": "quick wrap-up what I wanted to tell you I showed you we basically unpeeled the onion here and we started crying right I",
    "start": "3473470",
    "end": "3479769"
  },
  {
    "text": "showed you how we start with the basic bits we're sending and receiving going to transactions and right more and more",
    "start": "3479769",
    "end": "3486339"
  },
  {
    "text": "and more codes but it never stops there right and the thing is as developers as lead architects as little rappers our",
    "start": "3486339",
    "end": "3492849"
  },
  {
    "text": "task is to deliver business value and not to write infra infrastructure and",
    "start": "3492849",
    "end": "3499359"
  },
  {
    "text": "while you can now with this talk and you have all the things that you have to think about the question is really whether you want to do that right so the",
    "start": "3499359",
    "end": "3506410"
  },
  {
    "text": "by make or by decision is an important decision that you have to face in your projects and I usually compare it it's",
    "start": "3506410",
    "end": "3512859"
  },
  {
    "text": "like doing surgery on yourself right it's like well you can do surgery on yourself you can take a knife and cut",
    "start": "3512859",
    "end": "3519190"
  },
  {
    "text": "out something that you have on your leg but you're probably not a professional surgeon that's my assumption so whenever",
    "start": "3519190",
    "end": "3525069"
  },
  {
    "text": "you have something that you need to operate you're probably not doing that yourself you trust a bunch of",
    "start": "3525069",
    "end": "3530980"
  },
  {
    "text": "professionals to actually do that for you instead of cutting yourself and eventually bleeding out in the process",
    "start": "3530980",
    "end": "3537339"
  },
  {
    "text": "of doing so yeah that was it I hope you liked it thank you very much for for",
    "start": "3537339",
    "end": "3543549"
  },
  {
    "text": "coming thank you very much for for staying here and if you're interested and want to hear more about an service",
    "start": "3543549",
    "end": "3551019"
  },
  {
    "text": "bus that I showed here you can go to Godot particular at slash NDC Oslo 19 -",
    "start": "3551019",
    "end": "3557589"
  },
  {
    "text": "parsec it's a gamified tutorial that allows you to play around with an service bus",
    "start": "3557589",
    "end": "3562660"
  },
  {
    "text": "it's a planetary exploration game that you and play on yourself it takes about roughly 30 minutes and you go all into",
    "start": "3562660",
    "end": "3569200"
  },
  {
    "text": "the into the bells and whistles of an service bus and if you're curious about the demo that I showed you you can go to",
    "start": "3569200",
    "end": "3576160"
  },
  {
    "text": "Godot particular dotnet slash demo and trade try it out yourself and we also have tutorials how to do it with",
    "start": "3576160",
    "end": "3582250"
  },
  {
    "text": "Prometheus grandma graph on a pin sites New Relic whatever you're using to",
    "start": "3582250",
    "end": "3588010"
  },
  {
    "text": "visualize the same metrics if the code that I showed was too fancy for you and",
    "start": "3588010",
    "end": "3594280"
  },
  {
    "text": "you would like to basically debug the code through and better understand it I have all the code available on github",
    "start": "3594280",
    "end": "3599680"
  },
  {
    "text": "comm slash down in more bar slash message pump and if you have any",
    "start": "3599680",
    "end": "3605830"
  },
  {
    "text": "questions I have business cards here that you can take away send me an email",
    "start": "3605830",
    "end": "3611050"
  },
  {
    "text": "or come to me are still here at the booth at particular booth if you have any questions I'm gladly asking those",
    "start": "3611050",
    "end": "3616240"
  },
  {
    "text": "questions thank you very much [Applause]",
    "start": "3616240",
    "end": "3625269"
  }
]
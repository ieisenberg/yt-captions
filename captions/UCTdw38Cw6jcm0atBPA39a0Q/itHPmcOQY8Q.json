[
  {
    "start": "0",
    "end": "44000"
  },
  {
    "text": "good morning everybody so how many of you are developers okay that's very good",
    "start": "5310",
    "end": "13920"
  },
  {
    "text": "how many of you are not developers okay so okay so today I'm going to show you",
    "start": "13920",
    "end": "21300"
  },
  {
    "text": "how you can use Azure data Lake to do big data analysis without having to know",
    "start": "21300",
    "end": "27089"
  },
  {
    "text": "all the open source stuff and to do that I'll use the stack exchange data set",
    "start": "27089",
    "end": "32520"
  },
  {
    "text": "which is all the information about all the stack exchange websites which are",
    "start": "32520",
    "end": "37800"
  },
  {
    "text": "more than 150 I think so",
    "start": "37800",
    "end": "44120"
  },
  {
    "start": "44000",
    "end": "59000"
  },
  {
    "text": "first my name is Tom Kurkova manager consultant at codit and I'm a Microsoft Azure MVP they also write a white paper",
    "start": "44120",
    "end": "51030"
  },
  {
    "text": "about IOT and integration if you're interested but you can also follow me on",
    "start": "51030",
    "end": "57420"
  },
  {
    "text": "Twitter or follow my blog so today I'm going to introduce you to data Lake what",
    "start": "57420",
    "end": "63690"
  },
  {
    "text": "it is and how it compares to a data warehouse and also what a zip data Lake",
    "start": "63690",
    "end": "69840"
  },
  {
    "text": "store and analytics is so first big data was a big hype a few years ago now it's",
    "start": "69840",
    "end": "78540"
  },
  {
    "start": "71000",
    "end": "99000"
  },
  {
    "text": "just a given where we collect as much as much data as possible so that we can",
    "start": "78540",
    "end": "86430"
  },
  {
    "text": "later on learn from that data and build machine learning models on top of that etcetera but Big Data also means that",
    "start": "86430",
    "end": "94290"
  },
  {
    "text": "it's harder to process that data because the amount is a lot bigger so it all",
    "start": "94290",
    "end": "100979"
  },
  {
    "text": "started with Hadoop and and all these other open source technology started but",
    "start": "100979",
    "end": "106020"
  },
  {
    "text": "the problem is that I as a developer do not know any of these things and also",
    "start": "106020",
    "end": "112850"
  },
  {
    "text": "there's almost no don't net support so if I assume that's a developer want to",
    "start": "112850",
    "end": "118320"
  },
  {
    "start": "116000",
    "end": "176000"
  },
  {
    "text": "start with the big data analysis I could either use those but these have",
    "start": "118320",
    "end": "123750"
  },
  {
    "text": "a couple of problems so one is being it's a new language that I need to learn and possibly even more because every",
    "start": "123750",
    "end": "130909"
  },
  {
    "text": "technology also has a certain flavor for query etc and I also need to maintain",
    "start": "130909",
    "end": "136920"
  },
  {
    "text": "them it's a rapidly evolving ecosystem so also means that I need to keep up with",
    "start": "136920",
    "end": "143780"
  },
  {
    "text": "it but the biggest problem for me is that it's also cluster based technology",
    "start": "143780",
    "end": "148970"
  },
  {
    "text": "so in order to to start playing around with it I need to set up a whole Hadoop",
    "start": "148970",
    "end": "154040"
  },
  {
    "text": "cluster and put on all my data and there so it's not very cheap to do that and I",
    "start": "154040",
    "end": "159680"
  },
  {
    "text": "cannot run this locally last but not least for a lot of people Linux is new",
    "start": "159680",
    "end": "165890"
  },
  {
    "text": "and that can also be a hurdle now that is going across platform this is a bit",
    "start": "165890",
    "end": "171680"
  },
  {
    "text": "going away when it's also it was a blocker for me a few years ago so this",
    "start": "171680",
    "end": "178070"
  },
  {
    "text": "brings me to a ship and how you can do big data analysis so there are three main areas and a so on the Left",
    "start": "178070",
    "end": "185480"
  },
  {
    "text": "they have the italic store which is obviously a data store and this in",
    "start": "185480",
    "end": "191350"
  },
  {
    "text": "basically a in a data Lake format I'll go deeper into that but basically",
    "start": "191350",
    "end": "196700"
  },
  {
    "text": "there's no limitation and the size of data that you want to store and what format and whatsoever then you have data",
    "start": "196700",
    "end": "204230"
  },
  {
    "text": "like analytics which is basically a service query service that's built on",
    "start": "204230",
    "end": "211519"
  },
  {
    "text": "top of yarn but I can simply write the script with the pointers to my data sets and where I want to have the results do",
    "start": "211519",
    "end": "218269"
  },
  {
    "text": "some querying and transformation and I don't need to worry about how what will be running my query itself I just write",
    "start": "218269",
    "end": "225350"
  },
  {
    "text": "the business logic give it the script they scale it out for me and I get the results so it's a pay-as-you-go model",
    "start": "225350",
    "end": "232280"
  },
  {
    "text": "and then on the right you have the HD insight service where basically you can",
    "start": "232280",
    "end": "237590"
  },
  {
    "text": "run all the open source stuff that I showed they will host the cluster itself for you and then you can use the death",
    "start": "237590",
    "end": "244010"
  },
  {
    "text": "technology I will not go into detail into that one because as I mentioned I",
    "start": "244010",
    "end": "249080"
  },
  {
    "text": "don't know any of those technologies and it's beyond the scope of this presentation so let's start with data",
    "start": "249080",
    "end": "255110"
  },
  {
    "start": "252000",
    "end": "343000"
  },
  {
    "text": "like store so data like store as a fully web HDFS compatible data store which",
    "start": "255110",
    "end": "261019"
  },
  {
    "text": "means it fully integrates with the traditional Hadoop and other services",
    "start": "261019",
    "end": "266390"
  },
  {
    "text": "being I can use this for the data like analytics ID but I can all",
    "start": "266390",
    "end": "271520"
  },
  {
    "text": "to use this for Hadoop or any other big data service technology sorry so this is",
    "start": "271520",
    "end": "277430"
  },
  {
    "text": "basically the big data store energy you can store data of any format and any",
    "start": "277430",
    "end": "284780"
  },
  {
    "text": "size being it's a CSV XML zip file they don't care and it's a right ones and",
    "start": "284780",
    "end": "292129"
  },
  {
    "text": "read many principles so once you upload a file you either rewrite it completely",
    "start": "292129",
    "end": "298509"
  },
  {
    "text": "or you at your you add a new file so there's no way that you append to a file",
    "start": "298509",
    "end": "305800"
  },
  {
    "text": "another big benefit in is sometimes this is really important is that it's it has",
    "start": "305800",
    "end": "310819"
  },
  {
    "text": "enterprise-grade security meaning that it's truly integrated with Asia Haiti so",
    "start": "310819",
    "end": "316340"
  },
  {
    "text": "if you want to get access your agile ad use it needs to get access and this can",
    "start": "316340",
    "end": "321770"
  },
  {
    "text": "be on the on a variety of levels inside the store which I'll show later but",
    "start": "321770",
    "end": "327949"
  },
  {
    "text": "basically this is the big data store a matcher as you can see it integrates with whatever you want so of obviously with",
    "start": "327949",
    "end": "335090"
  },
  {
    "text": "the rest of the data like services but if you have an unplanned Hortonworks",
    "start": "335090",
    "end": "340400"
  },
  {
    "text": "cluster or something you can also use this and it's basically the center of",
    "start": "340400",
    "end": "346039"
  },
  {
    "text": "the whole process so on the ingestion side you can import all your data with a",
    "start": "346039",
    "end": "353389"
  },
  {
    "text": "variety of tools inside the data lake itself then you can use specific",
    "start": "353389",
    "end": "359150"
  },
  {
    "text": "services to process the data other ones to visualize them and you can also download them if you want so today we'll",
    "start": "359150",
    "end": "366349"
  },
  {
    "text": "use data like analytics and power bi to have the kind of end-to-end experience",
    "start": "366349",
    "end": "372190"
  },
  {
    "text": "along with I use PowerShell which is not on the graph on the left but I used",
    "start": "372190",
    "end": "377810"
  },
  {
    "text": "PowerShell to upload the raw data and data next door and then I proceeded with",
    "start": "377810",
    "end": "384349"
  },
  {
    "text": "data like analytics but more on that later but basically you can use it with",
    "start": "384349",
    "end": "389659"
  },
  {
    "text": "a variety of services and Azure so the term data Lake is a bit new before that",
    "start": "389659",
    "end": "397370"
  },
  {
    "start": "391000",
    "end": "480000"
  },
  {
    "text": "we will use to having data warehouses so what is the difference so a data Lake is really the lake without any structure",
    "start": "397370",
    "end": "405140"
  },
  {
    "text": "so I can put my own datasets in there with which has a certain scheme by while",
    "start": "405140",
    "end": "411740"
  },
  {
    "text": "my colleague puts a different file out there which has a totally different schema and probably even a different",
    "start": "411740",
    "end": "419860"
  },
  {
    "text": "resistance type so it's completely raw unstructured semi-structured or fully",
    "start": "419860",
    "end": "425150"
  },
  {
    "text": "structured and I can dump all my data in there so this allows us to do exploratory analysis on the full data",
    "start": "425150",
    "end": "432560"
  },
  {
    "text": "set so I do not need to transform my data when I import it I just give the",
    "start": "432560",
    "end": "438890"
  },
  {
    "text": "full data set over the data warehouse you define a scheme upfront and every",
    "start": "438890",
    "end": "444140"
  },
  {
    "text": "data that you want to import into the data warehouse needs to comply with that schema this means that you will",
    "start": "444140",
    "end": "450620"
  },
  {
    "text": "potentially need to throw away certain data attributes which is a downside if",
    "start": "450620",
    "end": "456110"
  },
  {
    "text": "you want to do exploratory analysis but this also provides you with a certain structure so that you know what's in",
    "start": "456110",
    "end": "462320"
  },
  {
    "text": "there which is a problem with the data like because if you do not have any mate metadata describing what data is located",
    "start": "462320",
    "end": "471170"
  },
  {
    "text": "where and what it needs to be used for or whatever your data will turn into a",
    "start": "471170",
    "end": "476210"
  },
  {
    "text": "data swamp which you do not want to have so Martin Fowler actually wrote a nice",
    "start": "476210",
    "end": "482330"
  },
  {
    "start": "480000",
    "end": "527000"
  },
  {
    "text": "article about this and the full article is is on that link but basically with so",
    "start": "482330",
    "end": "490910"
  },
  {
    "text": "a friend of mine compares this with with if you want to eat fish you can either",
    "start": "490910",
    "end": "495920"
  },
  {
    "text": "go to the warehouse where it's already prepped or you can go to the lake where you start fishing and basically get the",
    "start": "495920",
    "end": "502520"
  },
  {
    "text": "full fish which you need to clean and yeah you know how it goes so it's just know it all depends on how you want the",
    "start": "502520",
    "end": "511130"
  },
  {
    "text": "data to be prepared or not so based on that you need to either choose for a data warehouse or a data make if you",
    "start": "511130",
    "end": "518599"
  },
  {
    "text": "want to do big data analysis data Lake is all most of times the best option",
    "start": "518600",
    "end": "524600"
  },
  {
    "text": "because then you have to fill data so so security first of all you can use a role",
    "start": "524600",
    "end": "532010"
  },
  {
    "start": "527000",
    "end": "593000"
  },
  {
    "text": "based access control on the store instance itself meaning that I can give",
    "start": "532010",
    "end": "537470"
  },
  {
    "text": "access to people who can manage the store who can change the permissions etc and then next to",
    "start": "537470",
    "end": "545330"
  },
  {
    "text": "that I can new I can grant specific users and groups access to a to the",
    "start": "545330",
    "end": "550940"
  },
  {
    "text": "whole data lay to a specific folder to a specific file etc so basically you can",
    "start": "550940",
    "end": "558080"
  },
  {
    "text": "see this a bit as a drive on your disk where you have a complete folder structure with files in it that's how",
    "start": "558080",
    "end": "564650"
  },
  {
    "text": "you can see a data like a bit and then you can also put the access control on a specific folder or file it also comes",
    "start": "564650",
    "end": "573680"
  },
  {
    "text": "with a firewall which is unfortunately off by default but meaning you can truly isolate the data like and only give",
    "start": "573680",
    "end": "580220"
  },
  {
    "text": "access to your applications for example and they also have encryption at rest",
    "start": "580220",
    "end": "586130"
  },
  {
    "text": "where you can either use the creeks the keys managed by Microsoft or you bring your own key and Azure keyboard which I",
    "start": "586130",
    "end": "593210"
  },
  {
    "start": "593000",
    "end": "619000"
  },
  {
    "text": "will show later so pricing just for your information but it starts at 23 cents 30 32 cents per",
    "start": "593210",
    "end": "603350"
  },
  {
    "text": "gigabyte per month and I think that's even the most expensive the issue the more data you store the cheaper it gets",
    "start": "603350",
    "end": "610670"
  },
  {
    "text": "so it's not not a lot but as you can see you're also charged but right and read",
    "start": "610670",
    "end": "616880"
  },
  {
    "text": "which is fairly reasonable in my opinion but ok so I should also has another",
    "start": "616880",
    "end": "623390"
  },
  {
    "start": "619000",
    "end": "747000"
  },
  {
    "text": "service called blob storage which was used in the past before data like store was there so actually there's a few",
    "start": "623390",
    "end": "629920"
  },
  {
    "text": "differences but you yeah the difference is that data like store has no",
    "start": "629920",
    "end": "636680"
  },
  {
    "text": "limitation in size and format while blob storage also has a certain limitation",
    "start": "636680",
    "end": "643339"
  },
  {
    "text": "and the total amount of data that you store however in the last couple of",
    "start": "643339",
    "end": "648470"
  },
  {
    "text": "years if they've been increasing that amount so ridiculously that the trade-off over the head is almost gone",
    "start": "648470",
    "end": "655510"
  },
  {
    "text": "but there's all the difference is so blob storage does not support Active Directory authentication which is a big",
    "start": "655510",
    "end": "662240"
  },
  {
    "text": "request it's not there yet but in certain Enterprise scenarios this is",
    "start": "662240",
    "end": "667400"
  },
  {
    "text": "really important and then this is where data like store really makes it",
    "start": "667400",
    "end": "672959"
  },
  {
    "text": "but this also comes with the downside of course is that they tell extort is a bit more expensive so if you provision a",
    "start": "672959",
    "end": "679850"
  },
  {
    "text": "storage with Qi redundant storage it's",
    "start": "679850",
    "end": "685110"
  },
  {
    "text": "still cheaper than using data like store however data like store is full eBay",
    "start": "685110",
    "end": "691079"
  },
  {
    "text": "fully designed for these these analytical workload when you read really",
    "start": "691079",
    "end": "696269"
  },
  {
    "text": "a lot and that's where it also shines more than they done blob storage so if",
    "start": "696269",
    "end": "701490"
  },
  {
    "text": "you want to run analytics workloads that's where data like store is built for they both have redundancy the",
    "start": "701490",
    "end": "710880"
  },
  {
    "text": "difference is that with blob storage you can choose whatever kind of redundancy so local zone geo or very geo with read",
    "start": "710880",
    "end": "722399"
  },
  {
    "text": "access however with data like story do not have access to the applica and also",
    "start": "722399",
    "end": "727949"
  },
  {
    "text": "not how far it's being replicated so if you need this this is this kind of also be in downside on the flip side they",
    "start": "727949",
    "end": "735120"
  },
  {
    "text": "both integrate with data factory data catalog HD hand side and others there's a nice article which gives you full",
    "start": "735120",
    "end": "741630"
  },
  {
    "text": "comparison if you want to learn more about this so we will use this data set",
    "start": "741630",
    "end": "749970"
  },
  {
    "text": "to basically show you how easy it is as I mentioned at more than 20 280 websites",
    "start": "749970",
    "end": "759079"
  },
  {
    "text": "the idea is that we will basically upload the original data set which you",
    "start": "759079",
    "end": "766230"
  },
  {
    "text": "can download I'll show you where we'll then move that raw data which is only VM",
    "start": "766230",
    "end": "772860"
  },
  {
    "text": "upload that to Azure data like store then we will basically use Azure data",
    "start": "772860",
    "end": "779639"
  },
  {
    "text": "like analytics to aggregate all the information across all the websites into",
    "start": "779639",
    "end": "784769"
  },
  {
    "text": "one big file so that I can run queries on top of that while we are doing that",
    "start": "784769",
    "end": "790470"
  },
  {
    "text": "we are also going to change from a XML data set to a CSV because scaling XML",
    "start": "790470",
    "end": "798569"
  },
  {
    "text": "processing and a big data scenario is really bad because they tend to split",
    "start": "798569",
    "end": "804059"
  },
  {
    "text": "your files into multiple smaller ones to find them out if you do that with XML you lose your complete",
    "start": "804059",
    "end": "809610"
  },
  {
    "text": "structure and you're basically screwed so we're getting rid of the XML now once",
    "start": "809610",
    "end": "814740"
  },
  {
    "text": "we have that aggregated file with all the user information in it we will basically create a file where we have",
    "start": "814740",
    "end": "822270"
  },
  {
    "text": "all the we will group them by country and then we will have an average of up",
    "start": "822270",
    "end": "829260"
  },
  {
    "text": "folds now involves reputation etc and then we will use power bi to visualize",
    "start": "829260",
    "end": "834630"
  },
  {
    "text": "that okay so this is a very basic",
    "start": "834630",
    "end": "840330"
  },
  {
    "text": "high-level overview but I basically created the VM and Asha where I download",
    "start": "840330",
    "end": "845460"
  },
  {
    "text": "it's the raw information from archive.org there's two reasons why I'm using a VM and not my local laptop one",
    "start": "845460",
    "end": "853470"
  },
  {
    "text": "being I don't want to leave my laptop on for a lot of hours because they provide you with the zip file which you need to",
    "start": "853470",
    "end": "859800"
  },
  {
    "text": "unzip and believe me it takes a long time but the second and the most important part is if I upload all that",
    "start": "859800",
    "end": "867630"
  },
  {
    "text": "data to data like I need to pay if I'm downloaded in the same data center and",
    "start": "867630",
    "end": "874650"
  },
  {
    "text": "upload it then it's free of charge so I did that with PowerShell then it's in",
    "start": "874650",
    "end": "880020"
  },
  {
    "text": "data like we will use data like analytics and now we will create a report straight from data like store",
    "start": "880020",
    "end": "886339"
  },
  {
    "text": "okay so I'll show you a bit of data like store before we start with analytics",
    "start": "886339",
    "end": "891390"
  },
  {
    "start": "891000",
    "end": "1383000"
  },
  {
    "text": "part so before we start all the scripts and things are on my",
    "start": "891390",
    "end": "897870"
  },
  {
    "text": "github account so if you want to learn more it's all over here so you can",
    "start": "897870",
    "end": "902940"
  },
  {
    "text": "basically do it yourself if you want and all the data comes from archive.org which stock-exchange actually publishes",
    "start": "902940",
    "end": "911370"
  },
  {
    "text": "a dataset I think every T three to four months so if you want to do it yourself",
    "start": "911370",
    "end": "916920"
  },
  {
    "text": "you can basically download them on the right I use the torrent because otherwise I need to download 350 files",
    "start": "916920",
    "end": "923670"
  },
  {
    "text": "which is a lot but it's all open source you can simply use this so feel free to",
    "start": "923670",
    "end": "930480"
  },
  {
    "text": "get cracking so if you go to the poor",
    "start": "930480",
    "end": "937920"
  },
  {
    "text": "- I hope the wife is kind today you can",
    "start": "937920",
    "end": "945120"
  },
  {
    "text": "create the data like store account very easily so the only thing I need to",
    "start": "945120",
    "end": "956850"
  },
  {
    "text": "provide is give it a decent name zoom a bit we need to provide a name and Link",
    "start": "956850",
    "end": "964589"
  },
  {
    "text": "it to my subscription and research group that I choose the location where I want to move it and then I have the option to",
    "start": "964589",
    "end": "970769"
  },
  {
    "text": "either pay as I go or use a monthly commitment if you use the monthly commitment it's a lot cheaper but of",
    "start": "970769",
    "end": "976769"
  },
  {
    "text": "course you commit to store a certain amount of data and this can go up to 33%",
    "start": "976769",
    "end": "982290"
  },
  {
    "text": "off price reduction so if you have a lot of data you might want to consider this",
    "start": "982290",
    "end": "988320"
  },
  {
    "text": "and then the other option I have is if I want to either encrypt my data or not",
    "start": "988320",
    "end": "995839"
  },
  {
    "text": "come on and then I can either choose to use a",
    "start": "995870",
    "end": "1002269"
  },
  {
    "text": "key buy data like store itself I can either choose not to encrypt or use one",
    "start": "1002269",
    "end": "1008810"
  },
  {
    "text": "from keyboard so I so if you use the key vote and you basically need to select",
    "start": "1008810",
    "end": "1015670"
  },
  {
    "text": "the vault you want to use C Minnesota",
    "start": "1017620",
    "end": "1023559"
  },
  {
    "text": "and then I can basically select the key I want to use which is yeah I use one of",
    "start": "1023559",
    "end": "1031668"
  },
  {
    "text": "the new RSA 4000 ones well this is apparently not supported but I can",
    "start": "1031669",
    "end": "1037490"
  },
  {
    "text": "simply create a new one and link it etc I already provisioned that one because I",
    "start": "1037490",
    "end": "1044418"
  },
  {
    "text": "want to show you that if you provision it there's a last step of something the",
    "start": "1044419",
    "end": "1053660"
  },
  {
    "text": "account up where you basically need to grant this data like store account access to the data to the key vault key",
    "start": "1053660",
    "end": "1061790"
  },
  {
    "text": "itself because key vault has permissions on the keys obviously and then you",
    "start": "1061790",
    "end": "1067460"
  },
  {
    "text": "basically need to grant it I think it's over here but basically it",
    "start": "1067460",
    "end": "1074549"
  },
  {
    "text": "comes down to you need to go to your account first granted access evil ah so basically gives me a summary over here",
    "start": "1074549",
    "end": "1081960"
  },
  {
    "text": "and gives me a button to grant permissions and enable it however for",
    "start": "1081960",
    "end": "1087059"
  },
  {
    "text": "this demo we'll we are using a data Lake store account where the encryption is",
    "start": "1087059",
    "end": "1092640"
  },
  {
    "text": "managed by Microsoft so at the first glance you see how much it costs for me",
    "start": "1092640",
    "end": "1098130"
  },
  {
    "text": "and how much data there is so I already ran the script to basically move the",
    "start": "1098130",
    "end": "1104940"
  },
  {
    "text": "data inside my data I'll still show you how to do it but it takes a long time so",
    "start": "1104940",
    "end": "1110549"
  },
  {
    "text": "I already did it so you see how much data there is you see the read and the",
    "start": "1110549",
    "end": "1116730"
  },
  {
    "text": "writes ingress/egress so this is this can be really interesting if you have a",
    "start": "1116730",
    "end": "1122190"
  },
  {
    "text": "big data Lake and then firewall obviously over here you can turn them on",
    "start": "1122190",
    "end": "1129690"
  },
  {
    "text": "a whitelist so my piece then the interesting part is over here so if I",
    "start": "1129690",
    "end": "1136860"
  },
  {
    "text": "want to browse my data like I basically get a simple folder structure and in",
    "start": "1136860",
    "end": "1145140"
  },
  {
    "text": "that folder structure for example can have subfolders and then you have files where I have this reference data which",
    "start": "1145140",
    "end": "1152429"
  },
  {
    "text": "we will use so this is a list of all the countries their their common names etc",
    "start": "1152429",
    "end": "1158970"
  },
  {
    "text": "and you can see that I have a nice preview of the whole file over here if I",
    "start": "1158970",
    "end": "1164730"
  },
  {
    "text": "want I can download it I can change the preview so that for example the first",
    "start": "1164730",
    "end": "1172559"
  },
  {
    "text": "row is a header now it should update a preview to use that see now its uses the",
    "start": "1172559",
    "end": "1180360"
  },
  {
    "text": "header at the top which makes more sense also if I want to share this specific",
    "start": "1180360",
    "end": "1187230"
  },
  {
    "text": "farm at somebody else but not the other ones I can simply add a new user here which can either have read write or",
    "start": "1187230",
    "end": "1194130"
  },
  {
    "text": "execute permissions so as you can see it goes pretty far with this I also can do",
    "start": "1194130",
    "end": "1201059"
  },
  {
    "text": "it on a global level or not so there's nothing fancy from a store perspective but basically I",
    "start": "1201059",
    "end": "1208500"
  },
  {
    "text": "see it as a big drive where I can have a folder structure where I can upload files so I'll show you quickly the",
    "start": "1208500",
    "end": "1218549"
  },
  {
    "text": "scripts that I used to upload everything so this is an example of a file for a",
    "start": "1218549",
    "end": "1225929"
  },
  {
    "text": "specific website so on the left you can see and it's also in the github",
    "start": "1225929",
    "end": "1231149"
  },
  {
    "text": "repository but I included a sample of coffee that's a key change calm and you",
    "start": "1231149",
    "end": "1236460"
  },
  {
    "text": "see for every website I have a XML for badges comments both days three post links post Docs user and votes if you",
    "start": "1236460",
    "end": "1246149"
  },
  {
    "text": "open one of those files it looks like this so what I did first was I created a",
    "start": "1246149",
    "end": "1252990"
  },
  {
    "text": "PowerShell script to basically loop through all the folders on my folder and then upload every folder with its XML",
    "start": "1252990",
    "end": "1261480"
  },
  {
    "text": "files into data like so that's the first step if I open up that script it's",
    "start": "1261480",
    "end": "1269580"
  },
  {
    "text": "actually very very very simple is it readable for you yes okay so if I",
    "start": "1269580",
    "end": "1278460"
  },
  {
    "text": "collapse the functions first so you see that I first knew you don't need to authenticate with the idea research",
    "start": "1278460",
    "end": "1285539"
  },
  {
    "text": "manager where I select the subscription that I want to use so that's just regular I have research manager",
    "start": "1285539",
    "end": "1294230"
  },
  {
    "text": "PowerShell steps and then I basically want to upload my local files to the data like stock so first I pass the data",
    "start": "1294230",
    "end": "1301049"
  },
  {
    "text": "like store account name where my local for folder s and where I want the",
    "start": "1301049",
    "end": "1306389"
  },
  {
    "text": "folders to end up so if you look in detail and this is where the magic to",
    "start": "1306389",
    "end": "1313139"
  },
  {
    "text": "call it the big word but basically we are checking if it's if it's the root",
    "start": "1313139",
    "end": "1319350"
  },
  {
    "text": "folder or not and then if it yeah we basically removed the slashes because they feel like store does not like them",
    "start": "1319350",
    "end": "1325850"
  },
  {
    "text": "and I'm basically for every folder in my input folder I process them so I do some",
    "start": "1325850",
    "end": "1333750"
  },
  {
    "text": "more cleanup and then over here I basically check is it a directory or",
    "start": "1333750",
    "end": "1340980"
  },
  {
    "text": "not actually he's a little bit for this so I check is it a directory or not if",
    "start": "1340980",
    "end": "1346590"
  },
  {
    "text": "it is then I check if the folder already exists if it doesn't exist I create a",
    "start": "1346590",
    "end": "1352950"
  },
  {
    "text": "new folder via the new Angela dem data like store item and I specify at at the",
    "start": "1352950",
    "end": "1358860"
  },
  {
    "text": "end that it's a folder if it's not a folder then I know it's a file and then",
    "start": "1358860",
    "end": "1365070"
  },
  {
    "text": "I basically say ok import this complete file to my data like store accounts to",
    "start": "1365070",
    "end": "1370440"
  },
  {
    "text": "this location sorry dislocation and that's how easy it is just use two commandlets so nothing",
    "start": "1370440",
    "end": "1378120"
  },
  {
    "text": "fancy over here so the next step is to",
    "start": "1378120",
    "end": "1384299"
  },
  {
    "start": "1383000",
    "end": "1397000"
  },
  {
    "text": "change the format from XML to CSV and basically use one script to fan out",
    "start": "1384299",
    "end": "1390360"
  },
  {
    "text": "across all the files and aggregate into one consolidated CSV so for that we will",
    "start": "1390360",
    "end": "1398460"
  },
  {
    "start": "1397000",
    "end": "1480000"
  },
  {
    "text": "use Azure data like analytics which is a icon at the server less big data service",
    "start": "1398460",
    "end": "1404850"
  },
  {
    "text": "because I don't need to worry about any infrastructure I simply give it a script with the pointers to my input files and",
    "start": "1404850",
    "end": "1413370"
  },
  {
    "text": "I output files and I don't need to care about anything and the beauty of it is I can use a syntax which is called you",
    "start": "1413370",
    "end": "1421020"
  },
  {
    "text": "sequel which is basically a mixture of c-sharp and T sequel and that's perfect",
    "start": "1421020",
    "end": "1426390"
  },
  {
    "text": "for me as a developer because I know both of them I can also use",
    "start": "1426390",
    "end": "1431720"
  },
  {
    "text": "extensibility in c-sharp boy or I can even use inline c-sharp in the script",
    "start": "1431720",
    "end": "1437340"
  },
  {
    "text": "itself which I will show in a few minutes but basically if I submit the",
    "start": "1437340",
    "end": "1443610"
  },
  {
    "text": "script I can also say I want to use one analytics unit is what a yeah that's a",
    "start": "1443610",
    "end": "1450240"
  },
  {
    "text": "billing model and I can basically decide how much compute I want to use to fan",
    "start": "1450240",
    "end": "1457470"
  },
  {
    "text": "out the processing so the more analytics units the more chance that it will go",
    "start": "1457470",
    "end": "1463860"
  },
  {
    "text": "faster because it's not a guarantee that it will go faster but I'll show that in",
    "start": "1463860",
    "end": "1469820"
  },
  {
    "text": "details because they also provide you with tips on how you can optimize your scripts and I only pay for the",
    "start": "1469820",
    "end": "1476210"
  },
  {
    "text": "processing time itself not for the infrastructure there's a couple of data",
    "start": "1476210",
    "end": "1482660"
  },
  {
    "start": "1480000",
    "end": "1545000"
  },
  {
    "text": "stores which you query all right - so the main one is obviously data like",
    "start": "1482660",
    "end": "1487760"
  },
  {
    "text": "store the other one is blob storage so I showed you the comparison if you still want to use blob storage still possible",
    "start": "1487760",
    "end": "1495670"
  },
  {
    "text": "and I can also query any sequel flavor and I think you can even query sequel",
    "start": "1495670",
    "end": "1501650"
  },
  {
    "text": "managed instance nowadays as well but I'm not sure and the beauty is that I",
    "start": "1501650",
    "end": "1507530"
  },
  {
    "text": "query the data in the service itself Northern data like analytics so",
    "start": "1507530",
    "end": "1513350"
  },
  {
    "text": "basically it says data like store give me all the information and once you have that give it to me so it's not being",
    "start": "1513350",
    "end": "1521510"
  },
  {
    "text": "done in data like analytics itself and you can use a variety of stores in one",
    "start": "1521510",
    "end": "1529130"
  },
  {
    "text": "script as well it's not that you need to use only one of them you can combine them and then you can output it to",
    "start": "1529130",
    "end": "1535940"
  },
  {
    "text": "either storage or data like store it also has built-in partition tables and",
    "start": "1535940",
    "end": "1542540"
  },
  {
    "text": "data like analytics itself but we're not going to use them so how does the script look like so it consists of three parts",
    "start": "1542540",
    "end": "1549650"
  },
  {
    "start": "1545000",
    "end": "1611000"
  },
  {
    "text": "so with the extract where you go to your data store and get the data set then you",
    "start": "1549650",
    "end": "1555020"
  },
  {
    "text": "transform this with yeah however you need to do so basically this is your",
    "start": "1555020",
    "end": "1560330"
  },
  {
    "text": "business logic and then you basically output it to wherever you want in this",
    "start": "1560330",
    "end": "1567020"
  },
  {
    "text": "case it's a CSV file where I can hide it so we are outputting the address which",
    "start": "1567020",
    "end": "1572630"
  },
  {
    "text": "is one of the transformation results so basically we captured that in a variable",
    "start": "1572630",
    "end": "1578210"
  },
  {
    "text": "then we say output this variable which represent this data set to this file and",
    "start": "1578210",
    "end": "1583970"
  },
  {
    "text": "I want to output it as a CSV there are other output available as well or you",
    "start": "1583970",
    "end": "1589460"
  },
  {
    "text": "can write your own output there same goes with the input you can use the built-in extractors or you can write",
    "start": "1589460",
    "end": "1596390"
  },
  {
    "text": "your own that's what we are going to do in a few minutes so it's not really that art it takes a",
    "start": "1596390",
    "end": "1604719"
  },
  {
    "text": "few moments to start because it sometimes has some different concepts but it's fairly easy to use so the",
    "start": "1604719",
    "end": "1612369"
  },
  {
    "start": "1611000",
    "end": "1631000"
  },
  {
    "text": "extensibility model is just here for your information but you can use inline c-sharp expressions",
    "start": "1612369",
    "end": "1618249"
  },
  {
    "text": "there's also code behind for every script or you can use C sharp assemblies which has these functions of operation",
    "start": "1618249",
    "end": "1626159"
  },
  {
    "text": "operations and aggregators and then you have more of them if you need them there's a whole metadata model behind it",
    "start": "1626159",
    "end": "1633789"
  },
  {
    "start": "1631000",
    "end": "1657000"
  },
  {
    "text": "so basically you can see your data like analytics account which has multiple databases it's a bit like sequel where",
    "start": "1633789",
    "end": "1641949"
  },
  {
    "text": "you can basically add c-sharp assemblies that can be used by scripts where you",
    "start": "1641949",
    "end": "1647919"
  },
  {
    "text": "have where you have tables views if you need them so those are the partition",
    "start": "1647919",
    "end": "1653559"
  },
  {
    "text": "wants you can also add procedures table types etc what happens if you submit a",
    "start": "1653559",
    "end": "1659709"
  },
  {
    "start": "1657000",
    "end": "1756000"
  },
  {
    "text": "script and it's actually very nice so you submit the script to the service they compile it for you if there are",
    "start": "1659709",
    "end": "1665649"
  },
  {
    "text": "compilation errors it's already blocked you do not need to pay anything so imagine a typo in c-sharp for example is",
    "start": "1665649",
    "end": "1672459"
  },
  {
    "text": "only already blocked there so then they basically have this execution plan for you then they give it to an optimize it",
    "start": "1672459",
    "end": "1679479"
  },
  {
    "text": "and that optimizer will obviously optimize the execution plan then the job scheduler and cue will basically take",
    "start": "1679479",
    "end": "1686649"
  },
  {
    "text": "that script give it to the job manager so that he can basically start the processing and then the job manager will",
    "start": "1686649",
    "end": "1693659"
  },
  {
    "text": "do the vertex scheduling so basically depending on your script and so",
    "start": "1693659",
    "end": "1699339"
  },
  {
    "text": "basically she's read it across across multiple voltages so that's basically pieces of your data set which is allows",
    "start": "1699339",
    "end": "1707379"
  },
  {
    "text": "you to scale out the whole processing so if you have 100 vertices and you have one Analytics unit they will all be",
    "start": "1707379",
    "end": "1714129"
  },
  {
    "text": "processed by the same if you have done and that the analytics units it will basically scan about scale them out",
    "start": "1714129",
    "end": "1720489"
  },
  {
    "text": "across those ten instances and then the output is are going to be written by the data store you are using in this case",
    "start": "1720489",
    "end": "1727119"
  },
  {
    "text": "data Lake store there's actually a nice presentation on how you can tune your scripts if you want to learn more it's",
    "start": "1727119",
    "end": "1733419"
  },
  {
    "text": "on that you know and this is a result of how it's basically creating the whole",
    "start": "1733419",
    "end": "1740050"
  },
  {
    "text": "execution tree and the nice thing is I don't need to know anything about it I",
    "start": "1740050",
    "end": "1745630"
  },
  {
    "text": "just write the new sequel script which is fairly easy and then add optimized",
    "start": "1745630",
    "end": "1750790"
  },
  {
    "text": "isn't do one of those overviews job status just going to skip it the same",
    "start": "1750790",
    "end": "1758440"
  },
  {
    "start": "1756000",
    "end": "1777000"
  },
  {
    "text": "security model applies here and I also can give them access on either the whole",
    "start": "1758440",
    "end": "1765010"
  },
  {
    "text": "instance or a specific database so if you share one data like analytics unit",
    "start": "1765010",
    "end": "1772150"
  },
  {
    "text": "across the whole company you can still create the separation with the databases so this is also very nice you can also",
    "start": "1772150",
    "end": "1778900"
  },
  {
    "start": "1777000",
    "end": "1822000"
  },
  {
    "text": "apply limitations on an account level or a job level they actually have nice documentation on this so I'm not going",
    "start": "1778900",
    "end": "1786010"
  },
  {
    "text": "into detail but it basically comes down to avoiding that a developer submits a",
    "start": "1786010",
    "end": "1791830"
  },
  {
    "text": "script with 100 Analytics units instead of ten for example because that's the",
    "start": "1791830",
    "end": "1797710"
  },
  {
    "text": "amount that you pay and there's also a capability where you can apply priorities based on who we submitting",
    "start": "1797710",
    "end": "1804190"
  },
  {
    "text": "them so that if there's a production script that needs to run and there's a test script queued as well the",
    "start": "1804190",
    "end": "1810670"
  },
  {
    "text": "production job will have priority over the other one okay so let's get started",
    "start": "1810670",
    "end": "1817570"
  },
  {
    "text": "so first you can either use a visual",
    "start": "1817570",
    "end": "1824980"
  },
  {
    "start": "1822000",
    "end": "2053000"
  },
  {
    "text": "studio code or or a visual studio itself",
    "start": "1824980",
    "end": "1830370"
  },
  {
    "text": "so I'm going to use Visual Studio it's",
    "start": "1830370",
    "end": "1835450"
  },
  {
    "text": "simply a plugin that you install and then you can use this you can run the",
    "start": "1835450",
    "end": "1840610"
  },
  {
    "text": "queries locally as well so this is a very big benefit you can unit test all",
    "start": "1840610",
    "end": "1845710"
  },
  {
    "text": "your custom code also a big plus for this demo I'm just going to use the",
    "start": "1845710",
    "end": "1851650"
  },
  {
    "text": "azure offering because I want to show the portal as well but yeah that's",
    "start": "1851650",
    "end": "1858220"
  },
  {
    "text": "basically it I'll show you some stuff on the way so this first script is very simple I'm saying that I want to get all",
    "start": "1858220",
    "end": "1866710"
  },
  {
    "text": "the information all the user files in the XML these are",
    "start": "1866710",
    "end": "1871730"
  },
  {
    "text": "the attributes and my XML payload so if you check ID display name and reputation",
    "start": "1871730",
    "end": "1881170"
  },
  {
    "text": "if I open the users file reputation",
    "start": "1881170",
    "end": "1888380"
  },
  {
    "text": "creation display so it's basically linking to these attributes but then so",
    "start": "1888380",
    "end": "1896180"
  },
  {
    "text": "I'm basically describing the columns that I want and then I say get it from this s Web hdfs account which is the",
    "start": "1896180",
    "end": "1904850"
  },
  {
    "text": "stack exchange data Lake and a stack exchange data like store account which",
    "start": "1904850",
    "end": "1911180"
  },
  {
    "text": "has a folder 2017 June then I have this placeholder and then I have the file",
    "start": "1911180",
    "end": "1917210"
  },
  {
    "text": "name this is actually very powerful because by using this place hold it I",
    "start": "1917210",
    "end": "1922370"
  },
  {
    "text": "can basically say every folder that is in the 2017 June folder I want to have",
    "start": "1922370",
    "end": "1929840"
  },
  {
    "text": "that in my column set so I know that this entry belongs to this website and",
    "start": "1929840",
    "end": "1935690"
  },
  {
    "text": "the other one belongs to the other one so this means that if I provision if I",
    "start": "1935690",
    "end": "1940880"
  },
  {
    "text": "submit the script it will basically go through all these folders process all these user files and load them with my",
    "start": "1940880",
    "end": "1948230"
  },
  {
    "text": "custom extractor which I'll show you in a minute and because I want to use this",
    "start": "1948230",
    "end": "1953900"
  },
  {
    "text": "custom extractor I also need to reference at the top that I want to use that assembly that assembly needs to be",
    "start": "1953900",
    "end": "1962630"
  },
  {
    "text": "registered as well with as well a new sequel script I'll show that off the disk rip but basically once all the",
    "start": "1962630",
    "end": "1968930"
  },
  {
    "text": "input rows are loaded I'm simply saying out with this to the aggregated data",
    "start": "1968930",
    "end": "1974510"
  },
  {
    "text": "2,000 1706 users dot CSV where I use the output is dot CSV built-in output and",
    "start": "1974510",
    "end": "1982300"
  },
  {
    "text": "the difference here between the from and the two is that it doesn't prefix the data like store accounts because you can",
    "start": "1982300",
    "end": "1989180"
  },
  {
    "text": "also use a default data like store account so if I don't use the prefix it's going to use the default data like",
    "start": "1989180",
    "end": "1995360"
  },
  {
    "text": "store accounts so and this is how I need to register my",
    "start": "1995360",
    "end": "2003770"
  },
  {
    "text": "custom code just going to enter so it's on the whole screen but basically I'm",
    "start": "2003770",
    "end": "2012560"
  },
  {
    "text": "saying deployed I want to use database master if there is already an assembly",
    "start": "2012560",
    "end": "2019370"
  },
  {
    "text": "with this name drop it because I have a new one and then create the assembly with the same name from and then it",
    "start": "2019370",
    "end": "2025970"
  },
  {
    "text": "basically links to data like store so this means if I want to deploy my custom code I first need to upload it so I can",
    "start": "2025970",
    "end": "2032900"
  },
  {
    "text": "use this use sequel script to deploy it you can also do this from visual studio then you don't need to upload it but",
    "start": "2032900",
    "end": "2040090"
  },
  {
    "text": "yeah you should use a decent CI CD pipeline not from Visual Studio but",
    "start": "2040090",
    "end": "2047840"
  },
  {
    "text": "we've seen the script to deploy but what is it actually so it's very simple so I",
    "start": "2047840",
    "end": "2055399"
  },
  {
    "start": "2053000",
    "end": "2280000"
  },
  {
    "text": "pull in a nougat package which is data like analytics interfaces and then I",
    "start": "2055400",
    "end": "2062530"
  },
  {
    "text": "implement the eye extractor which means that I'm creating the custom extractor then I just need to implement the",
    "start": "2062530",
    "end": "2069408"
  },
  {
    "text": "extract method where I'm basically going to load the whole file via simple",
    "start": "2069409",
    "end": "2074929"
  },
  {
    "text": "dogmatix ml reader and I'm going to parse it so for while I'm reading and the note is an element and it starts",
    "start": "2074929",
    "end": "2083000"
  },
  {
    "text": "with local name Rho which basically maps to this entry here I'm going to take the",
    "start": "2083000",
    "end": "2093230"
  },
  {
    "text": "the name of the attributes sorry the value of the attribute and if it's there",
    "start": "2093230",
    "end": "2099230"
  },
  {
    "text": "I'm going to parse it so if it's a string I basically need to do some magic",
    "start": "2099230",
    "end": "2104720"
  },
  {
    "text": "because there's a limitation of 128 kilobytes so I clean it up a bit and if",
    "start": "2104720",
    "end": "2110090"
  },
  {
    "text": "it's if I if it's not a string then I need to basically cost it to the type",
    "start": "2110090",
    "end": "2115280"
  },
  {
    "text": "that was specified in my script itself and this basically comes back to these",
    "start": "2115280",
    "end": "2122480"
  },
  {
    "text": "types so if I see that it's an integer I'm crossing the field to an integer and",
    "start": "2122480",
    "end": "2128090"
  },
  {
    "text": "the beauty is that I get all this information as an endpoint so I can basically map",
    "start": "2128090",
    "end": "2136250"
  },
  {
    "text": "this all together and that's it that's how I wrote my own XML extracted there's",
    "start": "2136250",
    "end": "2141800"
  },
  {
    "text": "one big caveat here and this is that I need to mark it as atomic file",
    "start": "2141800",
    "end": "2146960"
  },
  {
    "text": "processing true and this means that if this file is being processed by if a",
    "start": "2146960",
    "end": "2152870"
  },
  {
    "text": "file is being processed by this extractor it should not shred it into multiple pieces because then I lose my",
    "start": "2152870",
    "end": "2159260"
  },
  {
    "text": "XML format if you are creating a custom extracted where there's no hierarchy and",
    "start": "2159260",
    "end": "2164840"
  },
  {
    "text": "the foul you should simply remove this because then it's more scalable but",
    "start": "2164840",
    "end": "2170090"
  },
  {
    "text": "because it's XML I cannot do this okay so we've seen how we can deploy a custom",
    "start": "2170090",
    "end": "2180620"
  },
  {
    "text": "assembly how we can simply load a lot of files with an extract script and how we",
    "start": "2180620",
    "end": "2186080"
  },
  {
    "text": "can output it so before we can basically run the script we need to have a data",
    "start": "2186080",
    "end": "2191570"
  },
  {
    "text": "like analytics unit data like analytics instance sorry so to do that we go to",
    "start": "2191570",
    "end": "2199040"
  },
  {
    "text": "the azure portal we do add in and we",
    "start": "2199040",
    "end": "2205250"
  },
  {
    "text": "wait and the setup itself is also very",
    "start": "2205250",
    "end": "2211040"
  },
  {
    "text": "simple I give it a name I give it a subscription and I link a default data",
    "start": "2211040",
    "end": "2218090"
  },
  {
    "text": "like store account why because data like analytics needs to store metadata as",
    "start": "2218090",
    "end": "2223550"
  },
  {
    "text": "well so what databases are there what store procedures etc so I can select one",
    "start": "2223550",
    "end": "2229790"
  },
  {
    "text": "of those then I click create it's going to be provisioned etc and then I can run",
    "start": "2229790",
    "end": "2235700"
  },
  {
    "text": "queries against this however I already provisioned this we are not only using",
    "start": "2235700",
    "end": "2243110"
  },
  {
    "text": "our default data like store account but we are also using the data like the stack exchange like store account which",
    "start": "2243110",
    "end": "2250340"
  },
  {
    "text": "I already have so that's where the the data set is available with the original",
    "start": "2250340",
    "end": "2259460"
  },
  {
    "text": "externals so to do that I need to go to data sources and basically add the link",
    "start": "2259460",
    "end": "2266180"
  },
  {
    "text": "to that other data Lake store account so you can see over here the default is the NDC Minnesota a the lake one and the",
    "start": "2266180",
    "end": "2272510"
  },
  {
    "text": "other one is the stack exchange one which I can reference in my scripts so",
    "start": "2272510",
    "end": "2278510"
  },
  {
    "text": "if I'm ready at the top you can see here then I can submit one where I specify",
    "start": "2278510",
    "end": "2284930"
  },
  {
    "start": "2280000",
    "end": "2448000"
  },
  {
    "text": "the data like store account the database and the schema but also the AU so that's",
    "start": "2284930",
    "end": "2290120"
  },
  {
    "text": "the analytics units that I mentioned so if I provision five Analytics units it",
    "start": "2290120",
    "end": "2298430"
  },
  {
    "text": "will be more scalable in terms that it will separate the files across these",
    "start": "2298430",
    "end": "2305210"
  },
  {
    "text": "instances but it will not separate the files across into multiple pieces because of my extractor so I can simply",
    "start": "2305210",
    "end": "2313370"
  },
  {
    "text": "click Submit yeah let's just do it",
    "start": "2313370",
    "end": "2321160"
  },
  {
    "text": "what's going to wait for the output anyway but at the bottom you can see that it's not preparing the script",
    "start": "2321160",
    "end": "2327500"
  },
  {
    "text": "validating it and it actually submitted it etc but the beauty is if I go to the",
    "start": "2327500",
    "end": "2335810"
  },
  {
    "text": "portal and back to the overview come on",
    "start": "2335810",
    "end": "2349960"
  },
  {
    "text": "FLE while it's loading that we quickly showed the stack exchange storage first",
    "start": "2351520",
    "end": "2357350"
  },
  {
    "text": "so you can see the structure",
    "start": "2357350",
    "end": "2360730"
  },
  {
    "text": "which 570 gigabytes because I have three dumps in there so we are using this one",
    "start": "2371099",
    "end": "2376440"
  },
  {
    "text": "from last year then you see one folder for every side if we go into one folder",
    "start": "2376440",
    "end": "2383339"
  },
  {
    "text": "you can see all these files again if I want I can click on preview but because",
    "start": "2383339",
    "end": "2388859"
  },
  {
    "text": "it's XML I think it will be a bit messy yeah see anyway you get the idea",
    "start": "2388859",
    "end": "2396930"
  },
  {
    "text": "so now you see that the script has started on the left you can see the status and some more information and at",
    "start": "2396930",
    "end": "2404130"
  },
  {
    "text": "the top you can see that it's now processing 328 files it's doing the",
    "start": "2404130",
    "end": "2409440"
  },
  {
    "text": "extract and then it will do the aggregate into one file so if I'm",
    "start": "2409440",
    "end": "2414749"
  },
  {
    "text": "feeling lucky apparently they remove the support but",
    "start": "2414749",
    "end": "2420989"
  },
  {
    "text": "normally you were able to basically show all the blocks next to each other but",
    "start": "2420989",
    "end": "2427229"
  },
  {
    "text": "with the last update anyway if I go to",
    "start": "2427229",
    "end": "2433259"
  },
  {
    "text": "the portal I can see the same experience",
    "start": "2433259",
    "end": "2437359"
  },
  {
    "text": "come on so now you see that there's one script running by one submitted that's",
    "start": "2447480",
    "end": "2452880"
  },
  {
    "text": "me if you have multiple people this will be a nice location where you can see who",
    "start": "2452880",
    "end": "2458310"
  },
  {
    "text": "is using what and you can also see how many analytics units are now being used so you see that there's a limitation of",
    "start": "2458310",
    "end": "2465420"
  },
  {
    "text": "250 for my account then you can see we're running out of a you unit we",
    "start": "2465420",
    "end": "2471810"
  },
  {
    "text": "should separate or request more fire support and then over here you can also",
    "start": "2471810",
    "end": "2477750"
  },
  {
    "text": "see the job status is so the three of them succeeded one is active and here",
    "start": "2477750",
    "end": "2483300"
  },
  {
    "text": "you can see how how much hours of Au we spent because that's what you're paying",
    "start": "2483300",
    "end": "2488850"
  },
  {
    "text": "for and here you also see how much I've spent in the last couple of months if I",
    "start": "2488850",
    "end": "2496080"
  },
  {
    "text": "go over here to view all jobs you will basically see that my current job is",
    "start": "2496080",
    "end": "2502680"
  },
  {
    "text": "running and you will have the same",
    "start": "2502680",
    "end": "2508859"
  },
  {
    "text": "experience as in Visual Studio and also",
    "start": "2508859",
    "end": "2520740"
  },
  {
    "text": "shows me how much how much founds its",
    "start": "2520740",
    "end": "2528600"
  },
  {
    "text": "processing ok so I already did this so we do not need to wait for the output",
    "start": "2528600",
    "end": "2535590"
  },
  {
    "text": "and then if I go to Visual Studio you can also see your you can also see your",
    "start": "2535590",
    "end": "2546869"
  },
  {
    "text": "data like analytics units over here so now I can also right click on jobs and",
    "start": "2546869",
    "end": "2552780"
  },
  {
    "text": "get the same list of jobs that I saw in a portal but in Visual Studio I can go to the details etc another thing you can",
    "start": "2552780",
    "end": "2559920"
  },
  {
    "text": "do is go to the storage accounts so for this analytics unit I'll link to storage",
    "start": "2559920",
    "end": "2567000"
  },
  {
    "text": "accounts so you can see them over here as well also which one is the default",
    "start": "2567000",
    "end": "2572280"
  },
  {
    "text": "but the nice thing is I can also browse the data like inside Visual Studio so",
    "start": "2572280",
    "end": "2577910"
  },
  {
    "text": "now that for example I know that my job has finished I can go to my phone",
    "start": "2577910",
    "end": "2584700"
  },
  {
    "text": "and aggregate the data mm 1706 and then you will see all the aggregated",
    "start": "2584700",
    "end": "2590580"
  },
  {
    "text": "CSVs so it also shows you how big they are it's not that big because it's an",
    "start": "2590580",
    "end": "2596280"
  },
  {
    "text": "aggregate and yeah not super big but",
    "start": "2596280",
    "end": "2601920"
  },
  {
    "text": "okay it's good for demo and then if I want I can basically double click yes",
    "start": "2601920",
    "end": "2607530"
  },
  {
    "text": "it's a preview please down to download the whole farm come on okay and now here",
    "start": "2607530",
    "end": "2617370"
  },
  {
    "start": "2616000",
    "end": "2681000"
  },
  {
    "text": "I can see a preview of of the file that's stored over there and then you",
    "start": "2617370",
    "end": "2624270"
  },
  {
    "text": "can also see the names of the websites in the first column and now imagine I'm",
    "start": "2624270",
    "end": "2631380"
  },
  {
    "text": "a data I want to know what's in there here we already know what's in there so",
    "start": "2631380",
    "end": "2638190"
  },
  {
    "text": "what we will now do is and I should have",
    "start": "2638190",
    "end": "2643200"
  },
  {
    "text": "turned on to output the so what you can do basically and let me actually show",
    "start": "2643200",
    "end": "2649590"
  },
  {
    "text": "you this if intellisense this friendly",
    "start": "2649590",
    "end": "2654650"
  },
  {
    "text": "yeah I don't know the name I think it's preserve header share not don't know by",
    "start": "2657950",
    "end": "2663360"
  },
  {
    "text": "heart but basically I can say if you output the data set include the name of",
    "start": "2663360",
    "end": "2670140"
  },
  {
    "text": "the columns so that it includes as a header row so that I now know what is",
    "start": "2670140",
    "end": "2677250"
  },
  {
    "text": "what is my video I know that column 0 is",
    "start": "2677250",
    "end": "2683550"
  },
  {
    "text": "the source there from the data set but if somebody else looks at this data said they do not know this so I should have",
    "start": "2683550",
    "end": "2689880"
  },
  {
    "text": "turned on the header row but anyway so we will look at column 2 which is the",
    "start": "2689880",
    "end": "2696480"
  },
  {
    "text": "name so we see that one person can be added in multiple website files and",
    "start": "2696480",
    "end": "2702930"
  },
  {
    "text": "there's also a column 6 which includes the location so we will basically use",
    "start": "2702930",
    "end": "2708780"
  },
  {
    "text": "those two fields along with the averages of fold up down etc",
    "start": "2708780",
    "end": "2714810"
  },
  {
    "text": "and then basically visualize this so they're small limitation my script does not check for states or cities or",
    "start": "2714810",
    "end": "2723120"
  },
  {
    "text": "whatever it simply checks does it contain one of the the supported country",
    "start": "2723120",
    "end": "2728880"
  },
  {
    "text": "fields because you will see that there it's not in it's at the top see there's",
    "start": "2728880",
    "end": "2734100"
  },
  {
    "text": "a test account which is always on the server server farm my script will not attack them so what did I do",
    "start": "2734100",
    "end": "2744170"
  },
  {
    "text": "50 minutes left so I need to hurry but basically I'm now using the built in CSV",
    "start": "2744740",
    "end": "2751170"
  },
  {
    "text": "extractor to load my previous result I also specify what I want capture that in",
    "start": "2751170",
    "end": "2759780"
  },
  {
    "text": "a variable then as a second step I also load my metadata file so my reference",
    "start": "2759780",
    "end": "2766590"
  },
  {
    "start": "2763000",
    "end": "2976000"
  },
  {
    "text": "data which has all the countries and the friendly names and then I know which",
    "start": "2766590",
    "end": "2772470"
  },
  {
    "text": "region of the world and CERP region they are in and then I basically do a small",
    "start": "2772470",
    "end": "2779750"
  },
  {
    "text": "cleaning of the data sets for the users because the location sometimes has",
    "start": "2779750",
    "end": "2784920"
  },
  {
    "text": "spaces and other things so for that I'm calling a method which calls cleanse",
    "start": "2784920",
    "end": "2790080"
  },
  {
    "text": "string and if you check the namespace it's actually the code-behind of my",
    "start": "2790080",
    "end": "2795690"
  },
  {
    "text": "script so if i go to the code behind you simply see that there is a cleanse string over here which takes and a",
    "start": "2795690",
    "end": "2802680"
  },
  {
    "text": "string if it's something i don't need to do anything otherwise i need to trim it and lower everything because that makes",
    "start": "2802680",
    "end": "2810480"
  },
  {
    "text": "the comparisons a lot easier so this means that i don't need to deploy this",
    "start": "2810480",
    "end": "2817050"
  },
  {
    "text": "custom assembly because it's part of the script the compiler will be smart enough to basically take it from the code",
    "start": "2817050",
    "end": "2823230"
  },
  {
    "text": "behind and add it into the script itself if we have some time I can show you at the end so once the users are cleaned we",
    "start": "2823230",
    "end": "2831870"
  },
  {
    "text": "do the same for the store for the countries as part of the scripts I actually do two things I check how many",
    "start": "2831870",
    "end": "2838710"
  },
  {
    "text": "people specify the location of that how many we'll be able to locate them to",
    "start": "2838710",
    "end": "2845820"
  },
  {
    "text": "country and also how many of them did not specify a location so here we're",
    "start": "2845820",
    "end": "2853290"
  },
  {
    "text": "basically joining the reference date are with the use of data grouping by region",
    "start": "2853290",
    "end": "2858930"
  },
  {
    "text": "sub region a name and also doing an average an account so that we know the amount of usage with the region and sub",
    "start": "2858930",
    "end": "2867150"
  },
  {
    "text": "region and the average of the values so then I have other ones where hold on a",
    "start": "2867150",
    "end": "2874470"
  },
  {
    "text": "second then I group so I'm done creating a set",
    "start": "2874470",
    "end": "2881820"
  },
  {
    "text": "of where we of all the users than the amount of users where we could not find a location where it was not specified",
    "start": "2881820",
    "end": "2888690"
  },
  {
    "text": "and where we were able to link them but we will not use this result but basically here you can see that we are",
    "start": "2888690",
    "end": "2895980"
  },
  {
    "text": "outputting the result of those two transformations into another file where",
    "start": "2895980",
    "end": "2902580"
  },
  {
    "text": "I output the header as well because this makes it very easy for power bi to load",
    "start": "2902580",
    "end": "2908490"
  },
  {
    "text": "that file and then see the results so at the top you can see that I submitted",
    "start": "2908490",
    "end": "2914310"
  },
  {
    "text": "this query this morning with 75 a use which is actually very expensive and",
    "start": "2914310",
    "end": "2921300"
  },
  {
    "text": "then you can see over here that all results into this yeah execution plan",
    "start": "2921300",
    "end": "2927930"
  },
  {
    "text": "but I don't need to care about how this is being modeled they are doing this for me I just write my my script of what I",
    "start": "2927930",
    "end": "2934320"
  },
  {
    "text": "want to do and I submit it so the nice thing is if I load the profile of that",
    "start": "2934320",
    "end": "2939390"
  },
  {
    "text": "job it gives me some warnings that's",
    "start": "2939390",
    "end": "2944700"
  },
  {
    "text": "because I over provisioned and then I can basically rerun that script to see",
    "start": "2944700",
    "end": "2951750"
  },
  {
    "text": "and at the top you can select by progress of computation time or whatever",
    "start": "2951750",
    "end": "2957900"
  },
  {
    "text": "by replaying it I can see where the bottlenecks are in my script so if it took too long I can see yeah okay this",
    "start": "2957900",
    "end": "2964410"
  },
  {
    "text": "extract took too long I should maybe optimize it in the previous step or whatever so this is really nice",
    "start": "2964410",
    "end": "2972140"
  },
  {
    "text": "next to that sorry it also gives you the overview of your",
    "start": "2972140",
    "end": "2978600"
  },
  {
    "start": "2976000",
    "end": "3081000"
  },
  {
    "text": "job and here you can see that I provisioned 75 a new unit within the reality it didn't",
    "start": "2978600",
    "end": "2985890"
  },
  {
    "text": "even use 20 of them so my efficiency at the bottom here is 5% and they suggest",
    "start": "2985890",
    "end": "2993869"
  },
  {
    "text": "to me that if I want to have a balanced processing I can use 8 a use which will",
    "start": "2993869",
    "end": "2999960"
  },
  {
    "text": "be 69 percent efficient and it will only take 44 seconds and the estimated time",
    "start": "2999960",
    "end": "3007520"
  },
  {
    "text": "is 0.1 hours if I want to be very fast I can still provision 11 which will be",
    "start": "3007520",
    "end": "3015609"
  },
  {
    "text": "funny enough same same time and then you",
    "start": "3015609",
    "end": "3021380"
  },
  {
    "text": "can also use this custom one where I can",
    "start": "3021380",
    "end": "3026390"
  },
  {
    "text": "basically use the slider and see if I provision more what's going to happen okay not efficient we do this so",
    "start": "3026390",
    "end": "3034070"
  },
  {
    "text": "basically this allows you to if you this was a one-off script but you can have three recurring jobs so this allows me",
    "start": "3034070",
    "end": "3042380"
  },
  {
    "text": "to optimize for the next sprint sprint for the next job so now that I need to",
    "start": "3042380",
    "end": "3047900"
  },
  {
    "text": "pay less this is all built-in so this is very nice fair warning this is based on",
    "start": "3047900",
    "end": "3053359"
  },
  {
    "text": "yeah machine learning so they analyzed a lot of jobs in the past this is only a",
    "start": "3053359",
    "end": "3058970"
  },
  {
    "text": "prediction this is not a guarantee that this will be the outcome of your job so don't just take this as a that's what's",
    "start": "3058970",
    "end": "3066770"
  },
  {
    "text": "going on so quickly that is this again",
    "start": "3066770",
    "end": "3074680"
  },
  {
    "text": "here it is basically you can see the",
    "start": "3075099",
    "end": "3081170"
  },
  {
    "start": "3081000",
    "end": "3141000"
  },
  {
    "text": "submitted script after it was optimized so we see at the top it's creating an assembly and referencing it",
    "start": "3081170",
    "end": "3088250"
  },
  {
    "text": "this is referencing the code behind that I was adding then you see that it's using yet the same script that I add it",
    "start": "3088250",
    "end": "3096170"
  },
  {
    "text": "and I think at the bottom I know it's dropping the script again I thought that",
    "start": "3096170",
    "end": "3101720"
  },
  {
    "text": "they were going to include it the code itself but they basically yeah did it",
    "start": "3101720",
    "end": "3107869"
  },
  {
    "text": "over here so that's why I don't need to run deploy it myself so",
    "start": "3107869",
    "end": "3114870"
  },
  {
    "text": "back to the portal actually over here it has the same capabilities yeah run it",
    "start": "3114870",
    "end": "3124260"
  },
  {
    "text": "this morning",
    "start": "3124260",
    "end": "3126950"
  },
  {
    "text": "well it has the same a you analysis so this means that if I submitted somebody",
    "start": "3137270",
    "end": "3144900"
  },
  {
    "text": "else from the team can see tom provision too many au units then he can basically",
    "start": "3144900",
    "end": "3151710"
  },
  {
    "text": "determine what the best approaches and then he can decide what what would be better and also you can see actually",
    "start": "3151710",
    "end": "3157860"
  },
  {
    "text": "that the the suggestion here is different than what I had in visual studio because now it says the most",
    "start": "3157860",
    "end": "3164280"
  },
  {
    "text": "balanced and fast is the same where he should allocate six a.m. and it will take 0.16 hours instead of the balanced",
    "start": "3164280",
    "end": "3174270"
  },
  {
    "text": "only taking 0.1 and the fast 0.2 so you see this this is more up to date so I'm",
    "start": "3174270",
    "end": "3182070"
  },
  {
    "text": "running out of time so I need to hurry but now that we have the result they",
    "start": "3182070",
    "end": "3189090"
  },
  {
    "text": "also it's already gone but every job also has in URL so if you want to share",
    "start": "3189090",
    "end": "3194550"
  },
  {
    "text": "or collaborate on one job you can basically pass that URL around which is very nice",
    "start": "3194550",
    "end": "3201770"
  },
  {
    "text": "and power bi I have this template probably not have time to do it all but",
    "start": "3209150",
    "end": "3215059"
  },
  {
    "text": "if you're interested feel free to come and ask me basically and power bi you have the capability to add a link to",
    "start": "3215059",
    "end": "3221750"
  },
  {
    "text": "data like store and then for the URL I",
    "start": "3221750",
    "end": "3230089"
  },
  {
    "text": "can basically link it to the file and you want to use reports then think it's",
    "start": "3230089",
    "end": "3251029"
  },
  {
    "text": "this one nobody here I can say properties and then it gives me you you",
    "start": "3251029",
    "end": "3256970"
  },
  {
    "text": "will write to the file and I don't know what's up with the portal stop jumping around over here click ok and then I",
    "start": "3256970",
    "end": "3269779"
  },
  {
    "text": "probably will need to authenticate because of the security",
    "start": "3269779",
    "end": "3275140"
  },
  {
    "text": "I'm a no typos okay so I click on it so now it's pulling in the file you will",
    "start": "3297130",
    "end": "3305710"
  },
  {
    "text": "notice that it looks a bit odd so you'll see this why because it's pulling in",
    "start": "3305710",
    "end": "3310950"
  },
  {
    "text": "actually the metadata so what we're going to do is we're going to change this data set where we say instead of",
    "start": "3310950",
    "end": "3322570"
  },
  {
    "text": "all this metadata I actually want the binary content then it's going to pull that in basically we're now changing our",
    "start": "3322570",
    "end": "3332350"
  },
  {
    "text": "data set on the fly so you can see this is the result of the script where on the Left I have the location I have the",
    "start": "3332350",
    "end": "3339280"
  },
  {
    "text": "region in the world then I have the sup region in the world and then all the other information and big because I",
    "start": "3339280",
    "end": "3345010"
  },
  {
    "text": "turned on the option to output the header row over B I automatically detects these labels so the first time I",
    "start": "3345010",
    "end": "3352450"
  },
  {
    "text": "did that I did not have that and it was actually a bit of a pain because yeah I",
    "start": "3352450",
    "end": "3357640"
  },
  {
    "text": "had to check my script okay column three was this field so I had to basically change this data set I click close and",
    "start": "3357640",
    "end": "3365800"
  },
  {
    "text": "apply and now once it's finished I can",
    "start": "3365800",
    "end": "3371770"
  },
  {
    "text": "basically create my reports and then I",
    "start": "3371770",
    "end": "3383500"
  },
  {
    "text": "can basically just say okay values so",
    "start": "3383500",
    "end": "3392260"
  },
  {
    "text": "for this location show me the reputation and then you see some you know has a good reputation etc so to save us some",
    "start": "3392260",
    "end": "3399520"
  },
  {
    "text": "time I did this upfront but basically you can create this nice overviews with",
    "start": "3399520",
    "end": "3405730"
  },
  {
    "text": "the results where you can just drag and drop all the data that you want and the",
    "start": "3405730",
    "end": "3410800"
  },
  {
    "text": "nice thing with power bi is if I click and click for example on Europe and if I",
    "start": "3410800",
    "end": "3416470"
  },
  {
    "text": "click on Europe you will see that every graph is going to change without having",
    "start": "3416470",
    "end": "3422020"
  },
  {
    "text": "to do anything you'll also see that I have an anomaly because something in Asia is linked to my year of data set so",
    "start": "3422020",
    "end": "3430420"
  },
  {
    "text": "it's not that fancy demo but I wanted to give you an end-to-end example of how you can go from a raw data set to a nice",
    "start": "3430420",
    "end": "3438010"
  },
  {
    "text": "report by using two scripts three scripts if you include a PowerShell so",
    "start": "3438010",
    "end": "3447339"
  },
  {
    "text": "quickly going through the rest of the demos in three minutes but I showed you the storage Explorer",
    "start": "3447339",
    "end": "3452589"
  },
  {
    "text": "and the job visualize it in visual studio a visual studio code you can do the same it has a source control",
    "start": "3452589",
    "end": "3459539"
  },
  {
    "text": "integration the SDK is also available as a CLI so you can use any built agent and",
    "start": "3459539",
    "end": "3466470"
  },
  {
    "text": "just use Emma's built you can unit test everything pricing is very interesting",
    "start": "3466470",
    "end": "3473529"
  },
  {
    "text": "so it's about two cents per minute which",
    "start": "3473529",
    "end": "3479710"
  },
  {
    "text": "is fairly reasonable if you ask me so the longer it takes and the more units you provision the more expensive it will",
    "start": "3479710",
    "end": "3486369"
  },
  {
    "text": "be but again you have the monthly commitment packages we can which can save you up to 74 percent so that's",
    "start": "3486369",
    "end": "3493089"
  },
  {
    "text": "really a lot operations is also important so here's my nice overview of",
    "start": "3493089",
    "end": "3500349"
  },
  {
    "text": "what's all available I don't have any time to show it anymore but something",
    "start": "3500349",
    "end": "3505930"
  },
  {
    "text": "they added recently is to create alerts with Logan oolitic so that if you spend",
    "start": "3505930",
    "end": "3514289"
  },
  {
    "text": "if you have a job that exceeds one hour let's say 50 hours then it triggers an",
    "start": "3514289",
    "end": "3521170"
  },
  {
    "text": "alert and operations can I have a look because probably it's hanging or anything then another very nice",
    "start": "3521170",
    "end": "3527890"
  },
  {
    "text": "integration is data factory which allows you to create these data pipelines and",
    "start": "3527890",
    "end": "3533619"
  },
  {
    "text": "part of that data pipeline you can basically say run the script I'm",
    "start": "3533619",
    "end": "3540759"
  },
  {
    "text": "actually working on a blog post on this where I basically use data factory data like analytics logic apps to",
    "start": "3540759",
    "end": "3548650"
  },
  {
    "text": "automatically aggregate all the user information in a fiction application so",
    "start": "3548650",
    "end": "3554950"
  },
  {
    "text": "that if that user wants to have all its data and download it which is one of the",
    "start": "3554950",
    "end": "3560230"
  },
  {
    "text": "requirements for gdpr it's basically combining these three services into an automated process they",
    "start": "3560230",
    "end": "3566740"
  },
  {
    "text": "go and fetch it in data like store run a query on top of it go to a secret",
    "start": "3566740",
    "end": "3572619"
  },
  {
    "text": "database get all the information and then basically move it with the effect as well so if you're interested you can",
    "start": "3572619",
    "end": "3579640"
  },
  {
    "text": "check my blog for that and if you want to learn more there are some nice and",
    "start": "3579640",
    "end": "3588040"
  },
  {
    "text": "nice resources this is a really good book if you want to read more it's more in general on data and answer itself as",
    "start": "3588040",
    "end": "3596530"
  },
  {
    "text": "well as the data architecture guide which basically describes a lot of scenarios and the options you have in a",
    "start": "3596530",
    "end": "3602800"
  },
  {
    "text": "sheet for this and then a small summary big data is not just a hype anymore so",
    "start": "3602800",
    "end": "3609810"
  },
  {
    "text": "if you're interested you should really get started the italic store is nice to",
    "start": "3609810",
    "end": "3615100"
  },
  {
    "text": "analyze what you have tomorrow or what you want to learn sorry what you have today or what you want to learn tomorrow",
    "start": "3615100",
    "end": "3621280"
  },
  {
    "text": "because you're not throwing away any data but be aware that you're not creating data swamps if you do not have",
    "start": "3621280",
    "end": "3628270"
  },
  {
    "text": "any structure so this is really important if you decide to move your",
    "start": "3628270",
    "end": "3633430"
  },
  {
    "text": "data around in the data like itself you can either use data factory to create a",
    "start": "3633430",
    "end": "3638710"
  },
  {
    "text": "copy or beta like analytics it's up to you data like analytics is really nice in my",
    "start": "3638710",
    "end": "3644980"
  },
  {
    "text": "opinion because it's serverless I can reuse my existing skills and only pay for what I want to do and then the last",
    "start": "3644980",
    "end": "3653050"
  },
  {
    "text": "point is if you want to do big data analysis and I ship data like is the",
    "start": "3653050",
    "end": "3658230"
  },
  {
    "text": "place to be thank you any any questions",
    "start": "3658230",
    "end": "3665730"
  },
  {
    "text": "no questions yes then the script",
    "start": "3666880",
    "end": "3679189"
  },
  {
    "text": "basically comes into a failed state and then not sorry",
    "start": "3679189",
    "end": "3685779"
  },
  {
    "text": "it's a the job will be failed itself then you need to check ok the job says",
    "start": "3686049",
    "end": "3691640"
  },
  {
    "text": "it failed because of this then you need to fix it and resubmit it again so you will pay for the amount of time it",
    "start": "3691640",
    "end": "3697999"
  },
  {
    "text": "already ran and then you will need to spin up a new submission of the script",
    "start": "3697999",
    "end": "3703969"
  },
  {
    "text": "itself and hopefully fix it set an answer to your question ok any other",
    "start": "3703969",
    "end": "3710599"
  },
  {
    "text": "questions ok thank you",
    "start": "3710599",
    "end": "3715509"
  }
]
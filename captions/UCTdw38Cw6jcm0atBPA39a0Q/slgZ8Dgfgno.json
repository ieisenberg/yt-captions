[
  {
    "text": "all right uh hmm welcome thanks for coming I hope you're enjoying nd C this",
    "start": "10080",
    "end": "17500"
  },
  {
    "text": "is my first and this is Sydney I've been to in DC Oslo several times in London",
    "start": "17500",
    "end": "22900"
  },
  {
    "text": "but it's really fun to be on this other side of the world my name is Sasha I live in Israel I work for a training",
    "start": "22900",
    "end": "29919"
  },
  {
    "text": "and consulting company back there we're in a three-week tour holiday business",
    "start": "29919",
    "end": "35500"
  },
  {
    "text": "vacation kind of thing here in Australia and we've really enjoyed it so far so",
    "start": "35500",
    "end": "40899"
  },
  {
    "text": "this is profiling nodejs applications and I'm assuming you have no js' applications you're building or you're",
    "start": "40899",
    "end": "47649"
  },
  {
    "text": "considering to build and at some point you run into performance problems or you want to avert the performance problems",
    "start": "47649",
    "end": "54519"
  },
  {
    "text": "in the first place I'm also assuming that you will at some point reach production and then you'll also have",
    "start": "54519",
    "end": "60370"
  },
  {
    "text": "issues in production so you'll have performance problems in production to debug as well and indeed the focus of",
    "start": "60370",
    "end": "67570"
  },
  {
    "text": "this talk is mostly on investigation techniques and tools and practices that",
    "start": "67570",
    "end": "72580"
  },
  {
    "text": "you can apply not only in your development environment but also when it hits you in production so we'll take a",
    "start": "72580",
    "end": "78040"
  },
  {
    "text": "look at some techniques that you can use without having to restart the process or add some modules especially just in",
    "start": "78040",
    "end": "85510"
  },
  {
    "text": "order to get some profiling and performance information so kind of the",
    "start": "85510",
    "end": "91330"
  },
  {
    "text": "the main objective if the clicker would work let's see there we go so the main objective is investigating",
    "start": "91330",
    "end": "98830"
  },
  {
    "text": "profiling nodejs applications in production I'm assuming that most of you",
    "start": "98830",
    "end": "104050"
  },
  {
    "text": "are probably using Linux as your production environment for a node.js right that sort of makes sense",
    "start": "104050",
    "end": "109360"
  },
  {
    "text": "you can run node.js on Windows you can run node.js on Mac Smart OS whatever you",
    "start": "109360",
    "end": "115240"
  },
  {
    "text": "but I'm assuming Linux is the one most of us use so the tools and the examples",
    "start": "115240",
    "end": "120280"
  },
  {
    "text": "I'm going to be showing or going to be on Linux but I will show equivalents or at least mention equivalents from other",
    "start": "120280",
    "end": "125980"
  },
  {
    "text": "operating systems that you can use if you are using those there's four bullets in there that I would like to achieve by",
    "start": "125980",
    "end": "132640"
  },
  {
    "text": "the end of the presentation so I want to tell you about which production ready tools you can use to profile your node",
    "start": "132640",
    "end": "138460"
  },
  {
    "text": "applications to get forms data out of your node applications I want to talk about CPU profiling which",
    "start": "138460",
    "end": "144370"
  },
  {
    "text": "is a real issue for node apps as they tend not to be so good at CPU intensive",
    "start": "144370",
    "end": "150340"
  },
  {
    "text": "work so figuring out where the CPU intensive parts are and optimizing them is important and we'll also visualize",
    "start": "150340",
    "end": "156880"
  },
  {
    "text": "this information using flame graphs which you might be familiar with from other places we'll talk about getting",
    "start": "156880",
    "end": "162220"
  },
  {
    "text": "accurate coal stacks for various kinds of interesting events like garbage collections in your node.js process or",
    "start": "162220",
    "end": "169350"
  },
  {
    "text": "things that slow down your event thread like doing synchronous i/o synchronous file accesses synchronous Network",
    "start": "169350",
    "end": "175690"
  },
  {
    "text": "requests that sort of thing and we'll see some examples which obviously are not full-blown actual investigations but",
    "start": "175690",
    "end": "183820"
  },
  {
    "text": "sort of show you what the thinking process is and how I approach in anyway a typical performance issue from start",
    "start": "183820",
    "end": "191170"
  },
  {
    "text": "to finish and just a couple of words about myself that's part of what I do I'm a",
    "start": "191170",
    "end": "197080"
  },
  {
    "text": "consultant working on performance investigations debugging stuff in production for customers across various",
    "start": "197080",
    "end": "203380"
  },
  {
    "text": "runtimes and operating systems and so this is sort of what I do and I really",
    "start": "203380",
    "end": "208510"
  },
  {
    "text": "like telling other people about it as well before we dive into the tools there's some introductory sections that",
    "start": "208510",
    "end": "215800"
  },
  {
    "text": "we have to cover this is something I put on all my performance talks and that's mine the overhead so if you have any",
    "start": "215800",
    "end": "221650"
  },
  {
    "text": "kind of performance tool someone recommends or someone puts online you should not right away run it in your",
    "start": "221650",
    "end": "228730"
  },
  {
    "text": "production environment a lot of tools especially tools that call themselves profilers tend to have a really",
    "start": "228730",
    "end": "235150"
  },
  {
    "text": "considerable overhead on your system so you might be able to run them in development but you shouldn't probably",
    "start": "235150",
    "end": "241060"
  },
  {
    "text": "run them as is in production so again having that background of doing",
    "start": "241060",
    "end": "246340"
  },
  {
    "text": "performance investigations in the field I do tends to be very wary of this sort of thing and the overhead certain",
    "start": "246340",
    "end": "252880"
  },
  {
    "text": "performance tools have so the tools we'll be talking about mostly are very suitable for production use but you",
    "start": "252880",
    "end": "258579"
  },
  {
    "text": "should absolutely not trust my word about it and you should really test in your own environment and see if that",
    "start": "258580",
    "end": "264070"
  },
  {
    "text": "still makes sense for you and for example a lot of CPU profilers they work really well if you put them on a box",
    "start": "264070",
    "end": "269800"
  },
  {
    "text": "that has four or eight processor but then all of a sudden you have a box with 256 processors and then the CPU",
    "start": "269800",
    "end": "275970"
  },
  {
    "text": "profiler becomes the bottleneck and just brings your whole environment down so it's a it's really something you have to",
    "start": "275970",
    "end": "282120"
  },
  {
    "text": "test another piece of theory that I want to get out of the way is the difference",
    "start": "282120",
    "end": "287220"
  },
  {
    "text": "between sampling and tracing tools and I will start looking at specific examples so a lot of the things we'll be doing",
    "start": "287220",
    "end": "293130"
  },
  {
    "text": "today are based on tracing a certain kind of event that happens in the node.js runtime in your JavaScript code",
    "start": "293130",
    "end": "300030"
  },
  {
    "text": "in the operating system code and some events are sufficiently low frequency",
    "start": "300030",
    "end": "305699"
  },
  {
    "text": "they happen rarely enough that you could actually record every single event so for example garbage collections for most",
    "start": "305699",
    "end": "312840"
  },
  {
    "text": "node processors would probably happen a couple of times per second or something like that so you can record every",
    "start": "312840",
    "end": "318000"
  },
  {
    "text": "garbage collection to a file and analyze that later but for some events there's so high frequency that you simply can't",
    "start": "318000",
    "end": "324509"
  },
  {
    "text": "record every individual occurrence and that's where sampling comes in so instead of recording every single event",
    "start": "324509",
    "end": "330570"
  },
  {
    "text": "you sample and just record every tenth event every millionth event every",
    "start": "330570",
    "end": "335639"
  },
  {
    "text": "billions event so you only have a statistical picture of what's happening and not each individual event as it",
    "start": "335639",
    "end": "341580"
  },
  {
    "text": "occurs so we'll be using tools from both flavors for CPU profiling for example",
    "start": "341580",
    "end": "347669"
  },
  {
    "text": "tracing is pretty much impossible and sampling is the only thing you can use because you can't trace each CPU",
    "start": "347669",
    "end": "353280"
  },
  {
    "text": "instruction as it gets executed so in terms of operating systems and so the",
    "start": "353280",
    "end": "358320"
  },
  {
    "text": "scenarios we'll be looking at there's five major things so we have CPU sampling we have dynamic tracing by",
    "start": "358320",
    "end": "365520"
  },
  {
    "text": "which I mean attaching to various interesting functions in the node runtime we have static tracing which",
    "start": "365520",
    "end": "371970"
  },
  {
    "text": "I'll explain what we get there but node is instrumented with a couple of interesting markers that we can monitor",
    "start": "371970",
    "end": "378599"
  },
  {
    "text": "for interesting information about HTTP requests garbage collections that sort of thing there's also a bunch of",
    "start": "378599",
    "end": "384690"
  },
  {
    "text": "different monitoring tools more lightweight monitoring tools that depend on the OS and there's the v8 profiler",
    "start": "384690",
    "end": "391080"
  },
  {
    "text": "which was actually start with which is built into the runtime built into the node.js runtime which is v8 and so",
    "start": "391080",
    "end": "397710"
  },
  {
    "text": "there's rough equivalence for most of these things on non Linux platforms as well but we'll be focusing on Linux",
    "start": "397710",
    "end": "403950"
  },
  {
    "text": "the rest is just to give you an idea of what you'd do if you actually had to do it or a different OS so mostly it's the",
    "start": "403950",
    "end": "410010"
  },
  {
    "text": "same principles it's just gonna be a slightly different tool so let's start with the v8 profiler and I'm gonna do a",
    "start": "410010",
    "end": "418140"
  },
  {
    "text": "mix of demos if I have time and just slides that have all the demo steps so",
    "start": "418140",
    "end": "423510"
  },
  {
    "text": "it's really going to depend also on the questions you ask if any and how much time we spend on each demo so the first",
    "start": "423510",
    "end": "429480"
  },
  {
    "text": "scenario we're kind of gonna attack is a high CPU node application so we have a",
    "start": "429480",
    "end": "435750"
  },
  {
    "text": "node app running and all of a sudden there is high load and it's consuming almost 100% CPU and we want to figure",
    "start": "435750",
    "end": "441930"
  },
  {
    "text": "out why what's taking so much CPU why the sudden change maybe and actually",
    "start": "441930",
    "end": "446970"
  },
  {
    "text": "nail down the piece of code that's consuming lots of CPU and we're gonna use the v8 profiler for this and this is",
    "start": "446970",
    "end": "454740"
  },
  {
    "text": "actually borderline acceptable for production use and I say borderline because using the v8 profiler does",
    "start": "454740",
    "end": "461910"
  },
  {
    "text": "require that you launch your node process with a profiling flag upfront so",
    "start": "461910",
    "end": "467670"
  },
  {
    "text": "it's not something you can do with no additional configuration just grab a random node system and attach a profiler",
    "start": "467670",
    "end": "474120"
  },
  {
    "text": "you have to run node with the prof command-line switch there is also",
    "start": "474120",
    "end": "479220"
  },
  {
    "text": "another option which is to start with the profiler disabled and then call an API use a JavaScript module to start and",
    "start": "479220",
    "end": "486990"
  },
  {
    "text": "stop profiling programmatically which is also reasonable but it again does require some changes maybe you'd have",
    "start": "486990",
    "end": "494220"
  },
  {
    "text": "some kind of secret endpoint that would start profiling and then another endpoint that would stop profiling and",
    "start": "494220",
    "end": "499980"
  },
  {
    "text": "get you the profiler results so these are all sort of feasible options but it's",
    "start": "499980",
    "end": "505710"
  },
  {
    "text": "something that's again borderline acceptable for production use so how the whole workflow works for the v8 profiler",
    "start": "505710",
    "end": "513330"
  },
  {
    "text": "you start by launching node with the profs which you exercise the application",
    "start": "513330",
    "end": "518550"
  },
  {
    "text": "you run the performance scenario we're interested in and that generates the runtime actually generates log files",
    "start": "518550",
    "end": "525060"
  },
  {
    "text": "pretty massive log files that have a bunch of stack traces for what the CPU",
    "start": "525060",
    "end": "530220"
  },
  {
    "text": "is doing inside your node process and then you run node again with the - - proof process switch",
    "start": "530220",
    "end": "537209"
  },
  {
    "text": "which reads the log file and generates a report so I'm going to try and show you",
    "start": "537209",
    "end": "542790"
  },
  {
    "text": "a quick example of this so over here I just have this little tiny web app that",
    "start": "542790",
    "end": "550019"
  },
  {
    "text": "actually I have a run script for so that's just run SH as a little script I",
    "start": "550019",
    "end": "557190"
  },
  {
    "text": "have that runs the the process sets it up and now we can issue requests so I'm",
    "start": "557190",
    "end": "564029"
  },
  {
    "text": "gonna specifically request localhost",
    "start": "564029",
    "end": "570060"
  },
  {
    "text": "three thousands users authorized and I'm",
    "start": "570060",
    "end": "575250"
  },
  {
    "text": "gonna add quotes here authorized and",
    "start": "575250",
    "end": "582589"
  },
  {
    "text": "yeah I don't actually remember the whole thing let's see if I have oh sorry that",
    "start": "582589",
    "end": "590459"
  },
  {
    "text": "went away users off is what I need and",
    "start": "590459",
    "end": "596639"
  },
  {
    "text": "then user name foo and password gooo now",
    "start": "596639",
    "end": "601920"
  },
  {
    "text": "let's sort of set aside the fact that I'm passing the username and password as query string parameters let's sort of",
    "start": "601920",
    "end": "609509"
  },
  {
    "text": "totally ignore that but then when I actually hit the page it returns an",
    "start": "609509",
    "end": "615959"
  },
  {
    "text": "error and sorry let me just for one second there make sure that I'm actually",
    "start": "615959",
    "end": "622769"
  },
  {
    "text": "using the right thing so users oh it",
    "start": "622769",
    "end": "628290"
  },
  {
    "text": "should have been a post yeah so that's it so - ex post okay so that return is",
    "start": "628290",
    "end": "635130"
  },
  {
    "text": "unauthorized which is what I expected in I mean it's sort of sensible so I try to authorize with an invalid username and",
    "start": "635130",
    "end": "642060"
  },
  {
    "text": "password and that returns an error but people are sort of complaining that the whole thing is is kind of slow and on a",
    "start": "642060",
    "end": "649410"
  },
  {
    "text": "particular server I might be having a flood of these authorization requests that are slowing the server down so I",
    "start": "649410",
    "end": "655079"
  },
  {
    "text": "could maybe run a benchmark like issue a thousand of those in ten concurrent",
    "start": "655079",
    "end": "660930"
  },
  {
    "text": "requests and using the post method and then just the same thing",
    "start": "660930",
    "end": "666480"
  },
  {
    "text": "users off username foo password GU let's just run this thing for a moment so",
    "start": "666480",
    "end": "672389"
  },
  {
    "text": "that's a B just running the benchmark and it's fairly slow",
    "start": "672389",
    "end": "677459"
  },
  {
    "text": "I'd say it's supposed to print I think every 10% completed right so I only",
    "start": "677459",
    "end": "682889"
  },
  {
    "text": "asked it to run a thousand requests and only now it's got through a 100 and I mean it's all super powerful box but",
    "start": "682889",
    "end": "690089"
  },
  {
    "text": "still I'm expecting some a somewhat higher rate if I just hit control C",
    "start": "690089",
    "end": "695360"
  },
  {
    "text": "you'd be able to see my statistics here so my median request is 1100",
    "start": "695360",
    "end": "702600"
  },
  {
    "text": "milliseconds for a single authorization attempt and that's suspiciously slow and",
    "start": "702600",
    "end": "709050"
  },
  {
    "text": "also while this benchmark is running if I just run top for a moment there and",
    "start": "709050",
    "end": "715070"
  },
  {
    "text": "resize to make room for the process name over here you'll see the node process",
    "start": "715070",
    "end": "722790"
  },
  {
    "text": "taking well almost 100% CPU well the benchmark is running so that might be",
    "start": "722790",
    "end": "729660"
  },
  {
    "text": "expected might not be expected but it seems that we have a very very busy server here that's that's being",
    "start": "729660",
    "end": "736139"
  },
  {
    "text": "overloaded by this authentication or authorization requests so here is where",
    "start": "736139",
    "end": "741779"
  },
  {
    "text": "you'd use the node profiler especially if it's something you can so easily reproduce and development so this is",
    "start": "741779",
    "end": "748110"
  },
  {
    "text": "where the node profiler works best and I'm going to kind of skip through the steps and just show you the general",
    "start": "748110",
    "end": "753329"
  },
  {
    "text": "process so again like I've done in the demo I've run top and then you'd run node with the - - probe switch and",
    "start": "753329",
    "end": "760380"
  },
  {
    "text": "repeat the experiment and that produces these gigantic log files and then you",
    "start": "760380",
    "end": "766230"
  },
  {
    "text": "run node with the probe process switch like this and just pass in the log file",
    "start": "766230",
    "end": "773399"
  },
  {
    "text": "and that generates a huge text file a huge text report and so I've sort of",
    "start": "773399",
    "end": "778889"
  },
  {
    "text": "removed relevant stuff and just kept the important parts of that report for our purposes so it begins with this summary",
    "start": "778889",
    "end": "786149"
  },
  {
    "text": "over here that says that 96% of my time is actually spent in C++ code so not",
    "start": "786149",
    "end": "793230"
  },
  {
    "text": "actual JavaScript at all but C++ now C++ as you know if you have a node",
    "start": "793230",
    "end": "798889"
  },
  {
    "text": "C++ can only come from two places it's either with the runtime itself or its native module right it's a module you're",
    "start": "798889",
    "end": "805759"
  },
  {
    "text": "using that has a C++ component in it now in the C++ section specifically in the",
    "start": "805759",
    "end": "812569"
  },
  {
    "text": "report you will see the hardest functions and then you'll see that ninety three point five percent of my",
    "start": "812569",
    "end": "818179"
  },
  {
    "text": "C++ functions is actually this one function here called crypto pbkdf2 now I",
    "start": "818179",
    "end": "824449"
  },
  {
    "text": "don't know if you're exactly familiar with it but it's a hash function it's a function that hashes a sequence of bytes",
    "start": "824449",
    "end": "832009"
  },
  {
    "text": "produces a hash and it sort of makes sense that we would be doing this as part of authentication",
    "start": "832009",
    "end": "838519"
  },
  {
    "text": "maybe hashing the users password and we also have another way to confirm so this",
    "start": "838519",
    "end": "844249"
  },
  {
    "text": "here is the call stack leading to repeat to the pbkdf2 function most frequently",
    "start": "844249",
    "end": "851419"
  },
  {
    "text": "and that call stack goes through crypto j/s which is JavaScript code calling",
    "start": "851419",
    "end": "856850"
  },
  {
    "text": "into C++ code and from my side I've called pbkdf2 sync and I've done so",
    "start": "856850",
    "end": "864470"
  },
  {
    "text": "over here so that's users j/s line for the six this is where I'm actually",
    "start": "864470",
    "end": "869749"
  },
  {
    "text": "calling this pbkdf2 sync function now you might argue at this point that I am",
    "start": "869749",
    "end": "877160"
  },
  {
    "text": "synchronously from my route invoking this hash function and I totally",
    "start": "877160",
    "end": "882919"
  },
  {
    "text": "shouldn't be doing that I should do that a synchronously right and like why would I even use pbkdf2 sync if there's a",
    "start": "882919",
    "end": "889309"
  },
  {
    "text": "pbkdf2 without the sync at the end but it turns out I mean even if I did do",
    "start": "889309",
    "end": "895549"
  },
  {
    "text": "this asynchronously it wouldn't get rid of the CPU computation that had to be performed like the hashing is still",
    "start": "895549",
    "end": "901309"
  },
  {
    "text": "there I could do it on the event thread and then it sort of pauses the response from getting there or I could do it in a",
    "start": "901309",
    "end": "907819"
  },
  {
    "text": "background thread but it's still I mean there still wouldn't be a response until the computation is done and I couldn't",
    "start": "907819",
    "end": "912889"
  },
  {
    "text": "really overlap multiple of those hashing operations because it's not IO it's not",
    "start": "912889",
    "end": "918679"
  },
  {
    "text": "happening on a different server it's just happening on different CPU so I might try to actually change this code",
    "start": "918679",
    "end": "925129"
  },
  {
    "text": "to be asynchronous but it definitely looks like we're doing a lot of hashing operations / authentication",
    "start": "925129",
    "end": "932870"
  },
  {
    "text": "requests if it takes over a second per request and indeed if we do look at the",
    "start": "932870",
    "end": "939589"
  },
  {
    "text": "quote for a moment there so just gonna look in users je s and then there's this",
    "start": "939589",
    "end": "945830"
  },
  {
    "text": "author out so you can see over here that I'm actually calling pbkdf2 sync and",
    "start": "945830",
    "end": "953060"
  },
  {
    "text": "then this argument over here is the number of iterations desired and that's",
    "start": "953060",
    "end": "961370"
  },
  {
    "text": "ten thousand and that's really crazy for for for hashing the users password I don't think we need ten thousand",
    "start": "961370",
    "end": "967940"
  },
  {
    "text": "iterations for that so that's clearly a place we can improve and I don't know if you noticed but the report actually",
    "start": "967940",
    "end": "973310"
  },
  {
    "text": "gives you the line numbers right so not just the JavaScript file name but also the line number invert the column number",
    "start": "973310",
    "end": "979610"
  },
  {
    "text": "where the samples are coming from where the stack is coming from so is this this",
    "start": "979610",
    "end": "985040"
  },
  {
    "text": "is fairly useful for identifying busy CPU functions in your code",
    "start": "985040",
    "end": "990380"
  },
  {
    "text": "figuring out what calls them I should note that the v8 profiler the way it's currently implemented it would only",
    "start": "990380",
    "end": "996950"
  },
  {
    "text": "profile your event thread your main thread your single node.js thread if you",
    "start": "996950",
    "end": "1002650"
  },
  {
    "text": "have additional threads they can't be running JavaScript right because node can only run JavaScript in a single",
    "start": "1002650",
    "end": "1007959"
  },
  {
    "text": "thread through process but you could have additional threads running native code running modules and that sort of",
    "start": "1007959",
    "end": "1013000"
  },
  {
    "text": "thing and they would not get profiled by the v8 profiler so it's only if it only picks up the main thread and it requires",
    "start": "1013000",
    "end": "1020589"
  },
  {
    "text": "that you launch the process with this ugly switch that generates a lot of data into a file so it's kind of getting",
    "start": "1020589",
    "end": "1026558"
  },
  {
    "text": "borderline production-ready I'd say and we definitely want other alternatives the one thing that this",
    "start": "1026559",
    "end": "1032860"
  },
  {
    "text": "profiler has going for it is it's it's just built-in it's out of the box if it",
    "start": "1032860",
    "end": "1037959"
  },
  {
    "text": "works on all platforms it's it's the default but you shouldn't just stick to the default there's better tools coming",
    "start": "1037959",
    "end": "1043808"
  },
  {
    "text": "up so the better tool coming up that pretty much every talk on Linux",
    "start": "1043809",
    "end": "1049390"
  },
  {
    "text": "performance eventually ends up mentioning is perf and perf is the Linux tool for performance investigations",
    "start": "1049390",
    "end": "1056040"
  },
  {
    "text": "especially for CPU profiling of the kind we've been doing so far it's capable of",
    "start": "1056040",
    "end": "1061510"
  },
  {
    "text": "a lot of different event sources so it can record CPU samples it can record context switches",
    "start": "1061510",
    "end": "1067190"
  },
  {
    "text": "it can record a variety of information about your system including disk accesses networking and that sort of",
    "start": "1067190",
    "end": "1073009"
  },
  {
    "text": "thing perf is developed as part of the Linux kernel tree so it's just sort of aligned",
    "start": "1073009",
    "end": "1080120"
  },
  {
    "text": "exactly with the Linux kernel you're using and you can install it from your packages from your package distribution",
    "start": "1080120",
    "end": "1086539"
  },
  {
    "text": "for example on Debian systems it's usually in Linux tools common on Red Hat",
    "start": "1086539",
    "end": "1091879"
  },
  {
    "text": "it would be in the perf package so you can install it and then start using it now for a node process specifically",
    "start": "1091879",
    "end": "1098720"
  },
  {
    "text": "there's a certain challenge with using perf that we'd have to overcome so again the objective is going to be the same we",
    "start": "1098720",
    "end": "1105470"
  },
  {
    "text": "have the same process with a heavy CPU usage and we're going to figure out where the CPU usage is coming from but",
    "start": "1105470",
    "end": "1111950"
  },
  {
    "text": "we don't want to launch the process ahead of time with a profiling flag and go through the whole process we want to",
    "start": "1111950",
    "end": "1117409"
  },
  {
    "text": "attach to a live running application and extract information out of that so",
    "start": "1117409",
    "end": "1123320"
  },
  {
    "text": "here's what the demo is going to look like here again I might run through it live a little later so it starts with",
    "start": "1123320",
    "end": "1128779"
  },
  {
    "text": "perf record which is the basic verb for recording CPU samples and recording",
    "start": "1128779",
    "end": "1135289"
  },
  {
    "text": "actually a lot of other kinds of events that perf supports and then we have",
    "start": "1135289",
    "end": "1140470"
  },
  {
    "text": "importantly it requires route unlike the v8 profiler perf mostly requires route",
    "start": "1140470",
    "end": "1147350"
  },
  {
    "text": "you can sort of get it to work for an individual process without being rude but you need to make sure certain things",
    "start": "1147350",
    "end": "1153139"
  },
  {
    "text": "are configured properly so if you want to go there talk to me later but for now we're just gonna assume route then",
    "start": "1153139",
    "end": "1159649"
  },
  {
    "text": "there's a process filter which tells perf which process you care about so that's just gonna be the node application this is the frequency with",
    "start": "1159649",
    "end": "1168200"
  },
  {
    "text": "which perf is going to look at that process and see what it's doing so it's going to grab samples of what the",
    "start": "1168200",
    "end": "1173629"
  },
  {
    "text": "process is doing and finally the G switches for stack traces so just in addition to the current function take a",
    "start": "1173629",
    "end": "1180649"
  },
  {
    "text": "stack trace of which function calls that that other function and so on so we have a complete tree of functions are not",
    "start": "1180649",
    "end": "1187490"
  },
  {
    "text": "just the current one so you're on a perf recording and then you run perf report",
    "start": "1187490",
    "end": "1192529"
  },
  {
    "text": "and perf report is supposed to display this user friendly summary to the terminal telling",
    "start": "1192529",
    "end": "1198559"
  },
  {
    "text": "you which paths in your code were the hottest kind of like the v8 profiler",
    "start": "1198559",
    "end": "1204700"
  },
  {
    "text": "over here which gave you a report of which functions were the hottest ones that's also the same thing that perf is",
    "start": "1204700",
    "end": "1211669"
  },
  {
    "text": "supposed to do except it would probably look like this so it would have a bunch of numbers really really many numbers",
    "start": "1211669",
    "end": "1218720"
  },
  {
    "text": "possibly hundreds of screens full of these numbers and all of these things are actually JavaScript function names",
    "start": "1218720",
    "end": "1225590"
  },
  {
    "text": "but perf doesn't know it as far as purpose this is just arbitrary",
    "start": "1225590",
    "end": "1231230"
  },
  {
    "text": "addresses in memory and the reason for this is as you know now employs a just-in-time compiler so your JavaScript",
    "start": "1231230",
    "end": "1238639"
  },
  {
    "text": "code is compiled to CPU instructions at runtime and that translation that",
    "start": "1238639",
    "end": "1244879"
  },
  {
    "text": "compilation is totally unknown to proof.proof doesn't know how to translate the just-in-time compiled",
    "start": "1244879",
    "end": "1252049"
  },
  {
    "text": "function addresses to function names in JavaScript there's the same problem",
    "start": "1252049",
    "end": "1257750"
  },
  {
    "text": "exactly if you are using perf to profile Java apps on Linux dotnet core apps on",
    "start": "1257750",
    "end": "1263779"
  },
  {
    "text": "Linux which I gave a talk about today virtually any runtime that is not statically compiled ahead of time like",
    "start": "1263779",
    "end": "1269779"
  },
  {
    "text": "C++ would have this problem so the way to resolve it is to run node with a",
    "start": "1269779",
    "end": "1276620"
  },
  {
    "text": "magic flag and now at this point you might say I mean this also needs you to run node with a magic flag so what's the",
    "start": "1276620",
    "end": "1282860"
  },
  {
    "text": "advantage compared to the built-in profiler why are we even talking about this the major difference is the proof",
    "start": "1282860",
    "end": "1290480"
  },
  {
    "text": "flag which we talked about before that starts profiling right away and starts",
    "start": "1290480",
    "end": "1295639"
  },
  {
    "text": "emitting huge amounts of information to a file this flag here the perf basic",
    "start": "1295639",
    "end": "1300980"
  },
  {
    "text": "profit flag instructs the runtime that whenever a method is getting compiled",
    "start": "1300980",
    "end": "1306350"
  },
  {
    "text": "whenever a method is getting JIT compiled at runtime the method address and name are stored into a file so it's",
    "start": "1306350",
    "end": "1314629"
  },
  {
    "text": "not actually starting profiling it's just emitting some supporting information I can show you the file then",
    "start": "1314629",
    "end": "1321080"
  },
  {
    "text": "a quick demo over here so if I just get out of them",
    "start": "1321080",
    "end": "1327190"
  },
  {
    "text": "and I run node with - - perf basic proof on that particular app oh yeah I have to",
    "start": "1327190",
    "end": "1334960"
  },
  {
    "text": "kill the existing one first okay so now if we look in in temp there is well",
    "start": "1334960",
    "end": "1344980"
  },
  {
    "text": "there's actually two of them from another experiment probably but there's this map files that get created and let",
    "start": "1344980",
    "end": "1351670"
  },
  {
    "text": "me show you what a map file what-what these map files actually look like so let's go to perf paid of node that map",
    "start": "1351670",
    "end": "1359650"
  },
  {
    "text": "that's what the perf map files look like so there's an address and a function",
    "start": "1359650",
    "end": "1364900"
  },
  {
    "text": "name an address and a function name and this might not look like JavaScript it's some internal v8 implementation details",
    "start": "1364900",
    "end": "1371890"
  },
  {
    "text": "but at some point we are going to get to JavaScript as well so here we go",
    "start": "1371890",
    "end": "1379030"
  },
  {
    "text": "write buffer J s and errors J s and",
    "start": "1379030",
    "end": "1384910"
  },
  {
    "text": "collection J s and so on so this file that gets emitted by the node runtime",
    "start": "1384910",
    "end": "1391150"
  },
  {
    "text": "has the translations between function dresses and function names and perf is",
    "start": "1391150",
    "end": "1397930"
  },
  {
    "text": "able to pick up that file automatically with no further instructions from you it",
    "start": "1397930",
    "end": "1403660"
  },
  {
    "text": "just goes ahead and looks for that file reads the data and then puts it in the",
    "start": "1403660",
    "end": "1408730"
  },
  {
    "text": "report and then the result looks like this rather than rather than addresses",
    "start": "1408730",
    "end": "1416860"
  },
  {
    "text": "we now get a clean call stack which has all the functions we previously saw like",
    "start": "1416860",
    "end": "1422410"
  },
  {
    "text": "pbkdf2 sync pbkdf2 in crypto so that's all the same stack we saw before",
    "start": "1422410",
    "end": "1428880"
  },
  {
    "text": "however I'd say for a real app that has more than just one hot bath this",
    "start": "1428880",
    "end": "1435970"
  },
  {
    "text": "approach where you browse to a bunch of text in your terminal is not gonna scale",
    "start": "1435970",
    "end": "1440980"
  },
  {
    "text": "very well for you the v8 profiler suffers from the same problem it spits out a huge report that",
    "start": "1440980",
    "end": "1446860"
  },
  {
    "text": "you now have to read we clearly need a way to visualize this information regardless of its origin right so it's",
    "start": "1446860",
    "end": "1454030"
  },
  {
    "text": "just it could come from perf it could come from v8 it could come from some windows stack tracing mechanism",
    "start": "1454030",
    "end": "1459940"
  },
  {
    "text": "don't care I have a bunch of stacks leading up to my hot spots and I want to visualize them and that's where flame",
    "start": "1459940",
    "end": "1467019"
  },
  {
    "text": "grafts are gonna help us so for the particular example I used in the demo if we actually went through the whole",
    "start": "1467019",
    "end": "1472750"
  },
  {
    "text": "report that perf produced that's 18,000 lines so nobody's gonna read that and",
    "start": "1472750",
    "end": "1477879"
  },
  {
    "text": "that's for a very very simple application you could easily get hundreds of thousands of lines to go",
    "start": "1477879",
    "end": "1483639"
  },
  {
    "text": "through if you keep persisting with the text-based approach similarly as flame",
    "start": "1483639",
    "end": "1489220"
  },
  {
    "text": "graphs for this and flame graphs if you haven't seen them before is just a visualization method for stack traces",
    "start": "1489220",
    "end": "1495970"
  },
  {
    "text": "you have a lot of stack traces leading up to a certain hot spot in your code and you want to put them in a single",
    "start": "1495970",
    "end": "1501909"
  },
  {
    "text": "diagram without having to wade through screen fools of text they were invented",
    "start": "1501909",
    "end": "1507370"
  },
  {
    "text": "by Brendan Gregg for this purpose and they can be used for CPU sampling and for a bunch of different things",
    "start": "1507370",
    "end": "1512740"
  },
  {
    "text": "we'll see flame graphs later in a totally different context for identifying off CPU time and not",
    "start": "1512740",
    "end": "1519100"
  },
  {
    "text": "actually on CPU time it's also going to be useful there now how do you read one of these things rather than the slide I",
    "start": "1519100",
    "end": "1526690"
  },
  {
    "text": "just want to show you a quick live example so this is a flame graph generated from a node.js process first",
    "start": "1526690",
    "end": "1534970"
  },
  {
    "text": "and foremost ignore the colors the colors are just there for prettification right so the the whole thing is a little",
    "start": "1534970",
    "end": "1541539"
  },
  {
    "text": "easier on the eyes or not arguably it's just there to differentiate the",
    "start": "1541539",
    "end": "1547480"
  },
  {
    "text": "different functions so the colors are totally random and they are designed to make it look like a flame hence the name",
    "start": "1547480",
    "end": "1553870"
  },
  {
    "text": "flame graphs now each rectangle you see here is a function right so this is",
    "start": "1553870",
    "end": "1559120"
  },
  {
    "text": "pbkdf2 in crypto j s this is pbkdf2 in the c++ v8 code this is users J s line",
    "start": "1559120",
    "end": "1568750"
  },
  {
    "text": "85 and so on so that's just JavaScript functions and C++ functions each rectangle is a function the vertical",
    "start": "1568750",
    "end": "1576460"
  },
  {
    "text": "axis is the call stack so if you have for example over here we have users J s",
    "start": "1576460",
    "end": "1583509"
  },
  {
    "text": "line 85 and then pbkdf2 Sinkin crypto J s it means this one was called by that",
    "start": "1583509",
    "end": "1590320"
  },
  {
    "text": "one so it's just the stack growing up that sort of makes sense then we have",
    "start": "1590320",
    "end": "1595690"
  },
  {
    "text": "the horizontal axis and most of it is just currently one rectangle but then",
    "start": "1595690",
    "end": "1601330"
  },
  {
    "text": "towards the top we have some splits right so the horizontal axis is just",
    "start": "1601330",
    "end": "1607019"
  },
  {
    "text": "alphabetically sorted it's not a time line or anything chrome developer tools",
    "start": "1607019",
    "end": "1612279"
  },
  {
    "text": "that there is a similar verse similar chart in there called the flame chart and it's not a flame graph right so",
    "start": "1612279",
    "end": "1618730"
  },
  {
    "text": "flame graph and a flame chart total different things a flame chart actually has a time line component to it this",
    "start": "1618730",
    "end": "1624999"
  },
  {
    "text": "doesn't this is not a time line it's just a summary of where you spend time in general and finally the wider",
    "start": "1624999",
    "end": "1633159"
  },
  {
    "text": "something is the more prominent it is so you should immediately look at the",
    "start": "1633159",
    "end": "1638230"
  },
  {
    "text": "widest towers in your flag graph so in this example it's all pretty much",
    "start": "1638230",
    "end": "1643960"
  },
  {
    "text": "leading to the same place which is here pbkdf2 request work and that ended up",
    "start": "1643960",
    "end": "1650859"
  },
  {
    "text": "calling a couple of internal functions which also called a couple of internal functions but that's just I mean that's",
    "start": "1650859",
    "end": "1656049"
  },
  {
    "text": "implementation details for the node crypto module I don't really care about those I mean my code pretty much ended",
    "start": "1656049",
    "end": "1662889"
  },
  {
    "text": "10 frames previously up up the stack so this is just a way of visualizing a",
    "start": "1662889",
    "end": "1668590"
  },
  {
    "text": "stack trace now this is actually a zoom into a larger flame graph where this was",
    "start": "1668590",
    "end": "1674739"
  },
  {
    "text": "just one tower and I've zoomed into that tower but there's also another couple of towers at the bottom there and there's",
    "start": "1674739",
    "end": "1682119"
  },
  {
    "text": "even this tiny Tower which I'm not sure where it's coming from yeah so that's also coming from node which called sis a pole that's how now",
    "start": "1682119",
    "end": "1689409"
  },
  {
    "text": "it waits for events so given a flame graph you can obviously zoom in on",
    "start": "1689409",
    "end": "1694629"
  },
  {
    "text": "things you can even do a search like I could search for clips search for Krypto",
    "start": "1694629",
    "end": "1701200"
  },
  {
    "text": "here and then it's gonna highlight any frames that have crypto in them so that",
    "start": "1701200",
    "end": "1707259"
  },
  {
    "text": "sort of helps navigate the whole thing you can put a file name there you could put a module name there it's gonna help",
    "start": "1707259",
    "end": "1712899"
  },
  {
    "text": "you navigate through the flame graph so how do you make flame graphs like that",
    "start": "1712899",
    "end": "1719070"
  },
  {
    "text": "one way which is totally not node.js tailored it's a totally generic way",
    "start": "1719070",
    "end": "1725520"
  },
  {
    "text": "using a script called flame graph PL it's a perl script there is also a couple of more native node",
    "start": "1725520",
    "end": "1732680"
  },
  {
    "text": "implementations there's one called Oh X there's also one called stack vis there's a bunch of options they all",
    "start": "1732680",
    "end": "1739290"
  },
  {
    "text": "produce the same thing virtually the same thing that diagram that shows you the hardest stacks the hardest call",
    "start": "1739290",
    "end": "1746160"
  },
  {
    "text": "stacks in your code so again here's what it might look like for our example again we just saw an exam in the browser",
    "start": "1746160",
    "end": "1753950"
  },
  {
    "text": "pbkdf2 is the hardest frame and the way we generated this if you look at the top",
    "start": "1753950",
    "end": "1760680"
  },
  {
    "text": "is just by running perf script and then feeding the output into a couple of Perl",
    "start": "1760680",
    "end": "1766740"
  },
  {
    "text": "scripts which produce the the final result which produced the diagram and the diagram is an SVG illustration which",
    "start": "1766740",
    "end": "1774660"
  },
  {
    "text": "you could obviously load in any other browser so we just saw how perf improves",
    "start": "1774660",
    "end": "1781980"
  },
  {
    "text": "upon the process by letting us attach to a live running process capture what's",
    "start": "1781980",
    "end": "1787560"
  },
  {
    "text": "doing capture a profile and then analyze it and produce a flame graph there's still a major deficiency which is why",
    "start": "1787560",
    "end": "1794550"
  },
  {
    "text": "I'm going to introduce you to yet another tool to get another approach of profiling node apps on Linux and to",
    "start": "1794550",
    "end": "1801480"
  },
  {
    "text": "understand what's wrong you have to consider high frequency events so the",
    "start": "1801480",
    "end": "1806730"
  },
  {
    "text": "way perf works basically is that it records a lot of events very quickly into a file and passes that file to a",
    "start": "1806730",
    "end": "1815040"
  },
  {
    "text": "user space application to a script of some sort to do the actual analysis in our case it might have been generating",
    "start": "1815040",
    "end": "1822570"
  },
  {
    "text": "the flame graph in other cases it might be a text-based it histogram illustration whatever but you have to go",
    "start": "1822570",
    "end": "1829560"
  },
  {
    "text": "through a file to user space so if you have a high frequency event that you want to record like this using perf",
    "start": "1829560",
    "end": "1836040"
  },
  {
    "text": "you're gonna run into bandwidth issues with your disk so I did an experiment on an AWS ec2 instance I downloaded a file",
    "start": "1836040",
    "end": "1845370"
  },
  {
    "text": "over a one gigabit per second link and while I was downloading the file",
    "start": "1845370",
    "end": "1851220"
  },
  {
    "text": "I used perf to capture events for each packet getting received now not the",
    "start": "1851220",
    "end": "1857730"
  },
  {
    "text": "packet day right so not like a network sniffer I don't care about the data just the raw event the fact that I got a packet I",
    "start": "1857730",
    "end": "1864860"
  },
  {
    "text": "wanted that recorded so I had a rate of approximately 89 thousand events per",
    "start": "1864860",
    "end": "1870680"
  },
  {
    "text": "second and that produced log file which grew at 19 megabytes per second of log",
    "start": "1870680",
    "end": "1879020"
  },
  {
    "text": "data so that's that's a lot obviously if you have a not super fast disk it could",
    "start": "1879020",
    "end": "1885830"
  },
  {
    "text": "actually saturate your disk just just the profiler itself writing profiler data to a file would saturate your disk",
    "start": "1885830",
    "end": "1893420"
  },
  {
    "text": "access completely or at least slow it down a lot needless to say you need a",
    "start": "1893420",
    "end": "1898550"
  },
  {
    "text": "lot of disk space for 19 megabytes of second worth of data if you plan to",
    "start": "1898550",
    "end": "1903800"
  },
  {
    "text": "record four minutes or hours it's not gonna scale so this whole approach where you record everything and then you",
    "start": "1903800",
    "end": "1910370"
  },
  {
    "text": "analyze it later you do post-processing that's an unreasonable approach I'd say",
    "start": "1910370",
    "end": "1916070"
  },
  {
    "text": "for certain kinds of events and just to sort of get ahead of myself the next",
    "start": "1916070",
    "end": "1921710"
  },
  {
    "text": "thing we're going to be doing like the next scenario is going to be identifying blockages on our event thread like why",
    "start": "1921710",
    "end": "1929840"
  },
  {
    "text": "is our event tread getting blocked maybe on Io maybe on network access maybe on",
    "start": "1929840",
    "end": "1935360"
  },
  {
    "text": "something else and to get that information we would need to record context switches whenever our event",
    "start": "1935360",
    "end": "1941600"
  },
  {
    "text": "tread switches out of the CPU and goes to sleep we would need to record that event and on Linux you could totally on",
    "start": "1941600",
    "end": "1949310"
  },
  {
    "text": "a very reasonable production system you could totally get millions of context switches per second so if you record",
    "start": "1949310",
    "end": "1955040"
  },
  {
    "text": "every single one and plan to analyze them later it's just not gonna scale not even four minutes",
    "start": "1955040",
    "end": "1960380"
  },
  {
    "text": "not to mention hours or days so to do that kind of investigation you do have to process events in real time",
    "start": "1960380",
    "end": "1967250"
  },
  {
    "text": "you can't keep every single event you have to process them in real time and discard them and this is where we need",
    "start": "1967250",
    "end": "1972830"
  },
  {
    "text": "to introduce a new technology and that new technology is vpf it's not node.js",
    "start": "1972830",
    "end": "1979400"
  },
  {
    "text": "specific in any way but we will obviously use it for node.js application profiling so BPF was invented as a",
    "start": "1979400",
    "end": "1986540"
  },
  {
    "text": "packet filtering technology if you've used Wireshark or TCP dump or T shark all",
    "start": "1986540",
    "end": "1993790"
  },
  {
    "text": "these different tools you've used PPF it's a language used to describe packet",
    "start": "1993790",
    "end": "1999640"
  },
  {
    "text": "filters it has nothing to do with performance tracing whatsoever but that's where the story begins in recent",
    "start": "1999640",
    "end": "2006090"
  },
  {
    "text": "Linux versions BPF can be used not just for packet filters but also surprisingly",
    "start": "2006090",
    "end": "2012540"
  },
  {
    "text": "for high frequency processing of events coming from the kernel so it could be",
    "start": "2012540",
    "end": "2018120"
  },
  {
    "text": "events like CPU samples that could be events like contacts wishes could be events like disk accesses so you could",
    "start": "2018120",
    "end": "2024960"
  },
  {
    "text": "use BPF to process at a very high rate to process events in the kernel where",
    "start": "2024960",
    "end": "2030450"
  },
  {
    "text": "they arrive so just to contrast the two approaches on the top you have the",
    "start": "2030450",
    "end": "2036420"
  },
  {
    "text": "perfect where you have some kind of data source regardless of what the data source is",
    "start": "2036420",
    "end": "2041910"
  },
  {
    "text": "but you have something pushing events into the system and then perf would produce data file that you then have to",
    "start": "2041910",
    "end": "2050159"
  },
  {
    "text": "analyze and get some kind of report or monitoring data out of so this could be",
    "start": "2050160",
    "end": "2055350"
  },
  {
    "text": "a flame graph this could be a histogram whatever with the BPF approach you don't",
    "start": "2055350",
    "end": "2060990"
  },
  {
    "text": "have to store and pass forward every single event instead you have a BPF",
    "start": "2060990",
    "end": "2066419"
  },
  {
    "text": "program that runs in the kernel and that program performs the aggregation that program generates the necessary",
    "start": "2066419",
    "end": "2073260"
  },
  {
    "text": "information so you don't have to keep every single event and then they only think that goes to user space is a",
    "start": "2073260",
    "end": "2079379"
  },
  {
    "text": "summary data structure and then you have an application a user space that would display it in some way so you don't have",
    "start": "2079380",
    "end": "2086280"
  },
  {
    "text": "to keep every single event that's the main takeaway now you are not actually going to be writing BPF programs",
    "start": "2086280",
    "end": "2092850"
  },
  {
    "text": "yourself it's just the technology which has a lot of tools built on top that sort of make this possible BPF is",
    "start": "2092850",
    "end": "2101070"
  },
  {
    "text": "available in Linux kernels over the last two and a half or three years or so so",
    "start": "2101070",
    "end": "2106200"
  },
  {
    "text": "the only reason I haven't started with BPF in the first place is that you might still find yourself one an older Linux",
    "start": "2106200",
    "end": "2112440"
  },
  {
    "text": "version where you still have to use the perfo proach from the olden days but hopefully going into the future",
    "start": "2112440",
    "end": "2118380"
  },
  {
    "text": "the perfo proach of storing every event is going to be displaced by tools that do real-time",
    "start": "2118380",
    "end": "2123910"
  },
  {
    "text": "analysis instead and that opens the door to a bunch of interesting things which we can talk about after the after this",
    "start": "2123910",
    "end": "2130180"
  },
  {
    "text": "session so the set of tools we're going to be using specifically just to give you a reference for later",
    "start": "2130180",
    "end": "2135850"
  },
  {
    "text": "it's called BCC it's a toolkit based on BPF that has a collection of tools",
    "start": "2135850",
    "end": "2141610"
  },
  {
    "text": "mostly Python scripts mostly scripture and Python for a variety of different",
    "start": "2141610",
    "end": "2147670"
  },
  {
    "text": "performance investigations just to give you an idea their scripts for nodes specifically in there but there's also a",
    "start": "2147670",
    "end": "2154420"
  },
  {
    "text": "lot of stuff for database engines for disk i/o investigations for Network",
    "start": "2154420",
    "end": "2160060"
  },
  {
    "text": "investigations of different kinds there's a variety of tools for everyone there and it's an open source project",
    "start": "2160060",
    "end": "2165700"
  },
  {
    "text": "that's maintained by a bunch of people I've also contributed a couple of tools to this project and it's already used",
    "start": "2165700",
    "end": "2173680"
  },
  {
    "text": "pretty widely by Google by Netflix by Facebook it's BPF and BCC are actual",
    "start": "2173680",
    "end": "2179260"
  },
  {
    "text": "technologies that are getting traction in the wild so again we want to use some",
    "start": "2179260",
    "end": "2185140"
  },
  {
    "text": "of these tools to profile or nodejs application and what I'm going to start with is just a very very quick mention",
    "start": "2185140",
    "end": "2190810"
  },
  {
    "text": "of how we could get the same result right the same flame graph of CPU usage",
    "start": "2190810",
    "end": "2196930"
  },
  {
    "text": "using the BCC approach so I'm not going to go through this very thoroughly",
    "start": "2196930",
    "end": "2202120"
  },
  {
    "text": "because it's going to produce the same result but just to illustrate the difference the way it works with the BCC",
    "start": "2202120",
    "end": "2208720"
  },
  {
    "text": "tools is you get a script called profile that attaches to the system at a certain",
    "start": "2208720",
    "end": "2215500"
  },
  {
    "text": "frequency just like Perth did and produces the input for flame graph generation and it",
    "start": "2215500",
    "end": "2223600"
  },
  {
    "text": "looks pretty similar to what we did with perf with the key difference being that the aggregation of coal stocks happens",
    "start": "2223600",
    "end": "2229690"
  },
  {
    "text": "in the kernel so rather than store every single event there is a BPF program in",
    "start": "2229690",
    "end": "2234940"
  },
  {
    "text": "the kernel that's doing real-time accounting so we have seen this call stack a thousand times we have seen this",
    "start": "2234940",
    "end": "2241240"
  },
  {
    "text": "call stack two thousand times we have seen this call stack three thousand times without recording each individual",
    "start": "2241240",
    "end": "2246790"
  },
  {
    "text": "sample to a file so again the output might be very very similar but the",
    "start": "2246790",
    "end": "2252100"
  },
  {
    "text": "approach used to generate this output is totally different and the overhead difference can be an",
    "start": "2252100",
    "end": "2257960"
  },
  {
    "text": "order of magnitude so it can really lower your overhead when running on a production system and additionally it of",
    "start": "2257960",
    "end": "2264920"
  },
  {
    "text": "course saves you the disk space you don't need to store this huge proof data files so the next thing we're going to",
    "start": "2264920",
    "end": "2272870"
  },
  {
    "text": "do is what I promised you in the first place we're going to look at off CPU profiling so identifying situations",
    "start": "2272870",
    "end": "2278600"
  },
  {
    "text": "where the event tread the main JavaScript reading node is stuck and not",
    "start": "2278600",
    "end": "2284480"
  },
  {
    "text": "by CPU work but actually waiting for something sleeping doing synchronous i/o",
    "start": "2284480",
    "end": "2290380"
  },
  {
    "text": "something blocking that doesn't let the event thread handle additional requests and we're going to use a couple of tools",
    "start": "2290380",
    "end": "2297320"
  },
  {
    "text": "for this from BCC the first one is going to be off CPU time the other is going to",
    "start": "2297320",
    "end": "2302930"
  },
  {
    "text": "be file slower let's just take a quick look so here's a sort of a summary of",
    "start": "2302930",
    "end": "2308600"
  },
  {
    "text": "our initial findings that lead us to this investigation I've I've got a certain end point called",
    "start": "2308600",
    "end": "2315590"
  },
  {
    "text": "stats on my node service which produces the following tiny JSON document not",
    "start": "2315590",
    "end": "2321770"
  },
  {
    "text": "really interesting but then I ran a benchmark and looking at the benchmark results I can see that my mean response",
    "start": "2321770",
    "end": "2330770"
  },
  {
    "text": "time was 116 milliseconds from that endpoint but on the other hand I can see",
    "start": "2330770",
    "end": "2337640"
  },
  {
    "text": "that the CPU was not very busy the CPU was a 35% so and for some reason right I",
    "start": "2337640",
    "end": "2344900"
  },
  {
    "text": "expect a higher rate of requests I expect to be able to handle requests in less than 116 milliseconds so this is",
    "start": "2344900",
    "end": "2352340"
  },
  {
    "text": "what leads me further into the investigation now we could use a CPU",
    "start": "2352340",
    "end": "2357410"
  },
  {
    "text": "profiler now like the v8 profiler or perf but it would only show us what's",
    "start": "2357410",
    "end": "2362480"
  },
  {
    "text": "going on in these 35% it's not gonna show us the rest of the time where we are not using the CPU but rather",
    "start": "2362480",
    "end": "2369830"
  },
  {
    "text": "blocking in in some way and this is fairly tricky like if you look online on",
    "start": "2369830",
    "end": "2374900"
  },
  {
    "text": "how to figure out why my event thread is blocked it's non-trivial and a lot of the solutions involve adding code or",
    "start": "2374900",
    "end": "2382100"
  },
  {
    "text": "adding modules that would do some kind of instrumentation which is totally non-trivial for production use",
    "start": "2382100",
    "end": "2388880"
  },
  {
    "text": "what we're doing here is just using the tool from BCC called off CPU time it's",
    "start": "2388880",
    "end": "2394940"
  },
  {
    "text": "designed for exactly this situation where you want to figure out what you're doing of the CPU while blocked and not",
    "start": "2394940",
    "end": "2402829"
  },
  {
    "text": "on the CPU while running and we point it at the node process and we instruct it",
    "start": "2402829",
    "end": "2408289"
  },
  {
    "text": "to generate folded stacks file which is basically input for flame graph",
    "start": "2408289",
    "end": "2413480"
  },
  {
    "text": "generation so we could just feed that into a flame graph generation script and get the following flame graph now it's",
    "start": "2413480",
    "end": "2420500"
  },
  {
    "text": "not actually an interactive flame graph it's a it's a screenshot on a slide so I can zoom in like I did before but we",
    "start": "2420500",
    "end": "2426230"
  },
  {
    "text": "could manually zoom so this whole section on the right there's something here but it's fairly narrow so I'm just",
    "start": "2426230",
    "end": "2433130"
  },
  {
    "text": "gonna ignore it completely and look only on this side here so there's this major",
    "start": "2433130",
    "end": "2438259"
  },
  {
    "text": "tower over here go all the way up to the top and if I look at my at the bottom of",
    "start": "2438259",
    "end": "2444170"
  },
  {
    "text": "this tower it says over there index j s line 73 that's something in my code and",
    "start": "2444170",
    "end": "2451960"
  },
  {
    "text": "what it seems to be doing is closing a file or something similar and so this",
    "start": "2451960",
    "end": "2460339"
  },
  {
    "text": "code is still in v8 so note closed UVF s closed that still C++ in v8 in the node",
    "start": "2460339",
    "end": "2468019"
  },
  {
    "text": "runtime but then this whole section going all the way up that is kernel code",
    "start": "2468019",
    "end": "2473750"
  },
  {
    "text": "that's a kernel functions in Linux and if we look at these functions a little",
    "start": "2473750",
    "end": "2479539"
  },
  {
    "text": "more closely again we're not kernel developers we're not supposed to be but the function",
    "start": "2479539",
    "end": "2485119"
  },
  {
    "text": "names are often pretty descriptive so first of all X of s is of course our file system X of s is the exam file",
    "start": "2485119",
    "end": "2492349"
  },
  {
    "text": "system and then if you just look in the function names it looks like we are over here flushing a file and that's",
    "start": "2492349",
    "end": "2499759"
  },
  {
    "text": "happening while closing the file and there's a lot of stuff here with bitmap write and log allocate and that sort of",
    "start": "2499759",
    "end": "2506960"
  },
  {
    "text": "thing that's happening inside the file system so this is all what happens when you close a file that you previously",
    "start": "2506960",
    "end": "2513710"
  },
  {
    "text": "have written to and then the file system has to flush your changes to disk so that happens here upon closing the file",
    "start": "2513710",
    "end": "2521400"
  },
  {
    "text": "but that's sort of not the point the point is that we are synchronously closing that file and blocking the the",
    "start": "2521400",
    "end": "2529500"
  },
  {
    "text": "event loop because this is all happening again from index j s9 73 if we had done",
    "start": "2529500",
    "end": "2536580"
  },
  {
    "text": "this asynchronously wouldn't be blocking the event loop while closing the file so",
    "start": "2536580",
    "end": "2543420"
  },
  {
    "text": "this is clearly time spent in synchronous file IO and if we go there",
    "start": "2543420",
    "end": "2548640"
  },
  {
    "text": "to index J s-line 73 I don't know if",
    "start": "2548640",
    "end": "2556290"
  },
  {
    "text": "it's actually 73 still but let's see just look for sync yeah so here it is",
    "start": "2556290",
    "end": "2563480"
  },
  {
    "text": "this is the stats endpoint and as you can see here what it does is just that",
    "start": "2563480",
    "end": "2569010"
  },
  {
    "text": "calls write file sync and write file sync internally does of course close the",
    "start": "2569010",
    "end": "2574830"
  },
  {
    "text": "file as well synchronously because I asked for the whole thing to happen synchronously and only after the whole",
    "start": "2574830",
    "end": "2580770"
  },
  {
    "text": "thing I returned the response and that's all happening on the event thread and blocking it now I know it's not a very",
    "start": "2580770",
    "end": "2586230"
  },
  {
    "text": "realistic scenario but that's not kind of not the point the point is that we were able to look",
    "start": "2586230",
    "end": "2591450"
  },
  {
    "text": "at a totally arbitrary process and figure out what's blocking the event thread and maybe what we can do to",
    "start": "2591450",
    "end": "2597960"
  },
  {
    "text": "unblock it now of course in some cases you just see that you know the event thread is as busy as it can be and",
    "start": "2597960",
    "end": "2603720"
  },
  {
    "text": "there's nothing you can further offload but in a lot of cases there is there is a bunch of stuff you can move away from",
    "start": "2603720",
    "end": "2610500"
  },
  {
    "text": "the event thread and speed up your rate of event processing so that's an example of off CPU profiling that I wanted to",
    "start": "2610500",
    "end": "2617310"
  },
  {
    "text": "show you now once we have that and we know that we are closing files writing",
    "start": "2617310",
    "end": "2623550"
  },
  {
    "text": "to files there's also another tool we could use before heading over to the source code and that's file slower also from BCC and",
    "start": "2623550",
    "end": "2631350"
  },
  {
    "text": "this is a super simple tool I just point it at a process and it spits out all the",
    "start": "2631350",
    "end": "2637170"
  },
  {
    "text": "file system operations performed by that process that are slower than a certain",
    "start": "2637170",
    "end": "2642180"
  },
  {
    "text": "threshold so here my threshold was one millisecond so it's just spitting out",
    "start": "2642180",
    "end": "2647670"
  },
  {
    "text": "all the file operations slower than one milliseconds and so each line here you can see it",
    "start": "2647670",
    "end": "2653010"
  },
  {
    "text": "as the number of bytes being written or read the latency in milliseconds and the",
    "start": "2653010",
    "end": "2658830"
  },
  {
    "text": "file name so you can do a complete investigations of what files are being accessed by your node process this is",
    "start": "2658830",
    "end": "2665460"
  },
  {
    "text": "not note specific at all it's it's completely generic this log that we are",
    "start": "2665460",
    "end": "2670860"
  },
  {
    "text": "sorry the flame graph we got over here it did require again the same map file",
    "start": "2670860",
    "end": "2677070"
  },
  {
    "text": "that map's JavaScript function names to addresses but otherwise it's a",
    "start": "2677070",
    "end": "2682110"
  },
  {
    "text": "completely generic technique okay next thing I'm going to show you is the built",
    "start": "2682110",
    "end": "2688920"
  },
  {
    "text": "in static instrumentation inside nodejs and how we can do a couple of pretty cool things with it so just as a",
    "start": "2688920",
    "end": "2694950"
  },
  {
    "text": "high-level overview static instrumentation is about putting static",
    "start": "2694950",
    "end": "2700800"
  },
  {
    "text": "points in your code in libraries and runtimes in your applications that you",
    "start": "2700800",
    "end": "2706410"
  },
  {
    "text": "can later instrument in production and trace so you could for example trace",
    "start": "2706410",
    "end": "2711900"
  },
  {
    "text": "your orders you could trace your authentication requests you can trace your garbage collections if you're a",
    "start": "2711900",
    "end": "2717990"
  },
  {
    "text": "runtime you could trace your module loads or requires if you're a runtime so",
    "start": "2717990",
    "end": "2724920"
  },
  {
    "text": "that sort of thing and it turns out there's a lot of this static instrumentation built in to a lot of",
    "start": "2724920",
    "end": "2730830"
  },
  {
    "text": "languages that we're using currently on Linux today so the JVM has done PHP has",
    "start": "2730830",
    "end": "2737280"
  },
  {
    "text": "them node has them as well now node",
    "start": "2737280",
    "end": "2742650"
  },
  {
    "text": "itself doesn't have a lot of these but the runtime the v8 runtime is a simplest",
    "start": "2742650",
    "end": "2748320"
  },
  {
    "text": "plus runtime so we can find a lot of additional instrumentation points over there and I'm gonna show you a couple of",
    "start": "2748320",
    "end": "2753900"
  },
  {
    "text": "examples so what you want to do first is just see what kinds of things we can trace in a running no js' application",
    "start": "2753900",
    "end": "2761100"
  },
  {
    "text": "and we're gonna use a couple of tools for this some of them are from BCC some of them are just Linux tools like",
    "start": "2761100",
    "end": "2766680"
  },
  {
    "text": "abdomen so first of all this is a tool from BCC called tip you list which you",
    "start": "2766680",
    "end": "2772410"
  },
  {
    "text": "can point at a process and it tells you what static instrumentation points exist",
    "start": "2772410",
    "end": "2777540"
  },
  {
    "text": "in that process and specifically I've highlighted all the node specific ones",
    "start": "2777540",
    "end": "2783090"
  },
  {
    "text": "so you have events for GC start and GC completed you have events for HTTP requests coming",
    "start": "2783090",
    "end": "2788570"
  },
  {
    "text": "in HTTP responses going out this is a set of probes that were put there by the",
    "start": "2788570",
    "end": "2794870"
  },
  {
    "text": "node developers so we could trace these events as they occur in production",
    "start": "2794870",
    "end": "2800140"
  },
  {
    "text": "another approach which is only applicable for compiled languages like C",
    "start": "2800140",
    "end": "2805310"
  },
  {
    "text": "and C++ is just look at all the functions in a particular binary because for compiled languages we could actually",
    "start": "2805310",
    "end": "2812480"
  },
  {
    "text": "trace any function we want so this incantation at the top instructs object",
    "start": "2812480",
    "end": "2818090"
  },
  {
    "text": "amp to print out all the functions in the node binary and then format them a little nicely a little more nicely but",
    "start": "2818090",
    "end": "2825500"
  },
  {
    "text": "this is just basically C++ function names from the v8 runtime we're not",
    "start": "2825500",
    "end": "2830720"
  },
  {
    "text": "supposed of course to know what each function does but if you're looking for something specific by keyword you could",
    "start": "2830720",
    "end": "2837050"
  },
  {
    "text": "probably find what you're looking for so here's an example of a couple of things we can do using this approach this first",
    "start": "2837050",
    "end": "2844340"
  },
  {
    "text": "command here the trace command what it does it attaches to one of these static",
    "start": "2844340",
    "end": "2850580"
  },
  {
    "text": "instrumentation points in this case HTTP server requests so whenever our node",
    "start": "2850580",
    "end": "2855830"
  },
  {
    "text": "application handles an incoming HTTP request this here is the trace message",
    "start": "2855830",
    "end": "2862280"
  },
  {
    "text": "we want printed and the Arg v and Arg six look a little magical you do need to",
    "start": "2862280",
    "end": "2868310"
  },
  {
    "text": "do some spelunking behind the scenes to figure out what they are I will save that for later and there's a process",
    "start": "2868310",
    "end": "2874070"
  },
  {
    "text": "filter as well like which process do I want this information out of the output looks like this fairly simple and",
    "start": "2874070",
    "end": "2881380"
  },
  {
    "text": "hopefully by looking at the output you can see that mark 5 seems to correspond",
    "start": "2881380",
    "end": "2888920"
  },
  {
    "text": "to the HTTP verb and arc 6 seems to correspond to the requested URL so this",
    "start": "2888920",
    "end": "2896630"
  },
  {
    "text": "is basically just a way of doing dynamic logging just point this tool at a certain application and tell it to trace",
    "start": "2896630",
    "end": "2904310"
  },
  {
    "text": "a message when something interesting happens so in this case the touch target is no js' specific it's the HTTP server",
    "start": "2904310",
    "end": "2911780"
  },
  {
    "text": "request static trace point now we can do something similar with",
    "start": "2911780",
    "end": "2918550"
  },
  {
    "text": "with other kinds of points like that instrumentation point like that and I'm",
    "start": "2918550",
    "end": "2924940"
  },
  {
    "text": "gonna do it through a scenario which is identifying excessive garbage collections so suppose you have this",
    "start": "2924940",
    "end": "2930220"
  },
  {
    "text": "node process that's doing lots and lots of garbage collections it's not actually as uncommon as it might sound like high",
    "start": "2930220",
    "end": "2938290"
  },
  {
    "text": "CPU load is more common than excessive GC and probably various kinds of",
    "start": "2938290",
    "end": "2944170"
  },
  {
    "text": "networking issues are more common than excessive GC but I've seen my share of excessive GC issues as well you know",
    "start": "2944170",
    "end": "2951100"
  },
  {
    "text": "that now has a garbage collector and garbage collectors they do tend to sometimes do excessive work and by",
    "start": "2951100",
    "end": "2958270"
  },
  {
    "text": "excessive I mean they can pause your process while the garbage collection is happening they can introduce a high CPU",
    "start": "2958270",
    "end": "2965500"
  },
  {
    "text": "load so basically we're spending time collecting garbage rather than processing useful requests so that's",
    "start": "2965500",
    "end": "2972070"
  },
  {
    "text": "that's just stuff that happens if you put too much load on your garbage collector so we're gonna use a couple of",
    "start": "2972070",
    "end": "2977590"
  },
  {
    "text": "tools to diagnose that so the first tool is note specific it's called UGC it's",
    "start": "2977590",
    "end": "2984130"
  },
  {
    "text": "also based on BPF and it would print a message whenever there is a garbage",
    "start": "2984130",
    "end": "2989200"
  },
  {
    "text": "collection in a node application and it tells you the duration of that garbage collection so before you start",
    "start": "2989200",
    "end": "2995290"
  },
  {
    "text": "investigating you can just figure out if you even have a problem before you allocate any further resources to it so",
    "start": "2995290",
    "end": "3002190"
  },
  {
    "text": "looking at this output here specifically the highlighted sections we have garbage collections taking I mean not very long",
    "start": "3002190",
    "end": "3009450"
  },
  {
    "text": "because it's in microseconds so 9,000 microseconds is just 9 milliseconds but",
    "start": "3009450",
    "end": "3015510"
  },
  {
    "text": "they are happening fairly frequently like if you look at the first column here the start column that's in seconds",
    "start": "3015510",
    "end": "3021840"
  },
  {
    "text": "so in less than 200 milliseconds we had over a dozen garbage collections in that",
    "start": "3021840",
    "end": "3027150"
  },
  {
    "text": "process each taking less than a millisecond or slightly more than a millisecond but we definitely have a lot",
    "start": "3027150",
    "end": "3033030"
  },
  {
    "text": "of garbage collections happening and of course you could aggregate this information just tell me how much time I",
    "start": "3033030",
    "end": "3039330"
  },
  {
    "text": "spent on GC in the last 5 seconds and then you could get a reply that may",
    "start": "3039330",
    "end": "3044730"
  },
  {
    "text": "might say well over the last 5 seconds you spent 3 seconds doing garbage collection and that's obviously very bad",
    "start": "3044730",
    "end": "3050850"
  },
  {
    "text": "and you want to figure out why you don't want to spend most of your time garbage collecting so what comes the useful next",
    "start": "3050850",
    "end": "3057300"
  },
  {
    "text": "is again a couple of tools that can do sort of dynamic instrumentation of a",
    "start": "3057300",
    "end": "3064080"
  },
  {
    "text": "node process so this example here has us using a tool called funk latency and",
    "start": "3064080",
    "end": "3070860"
  },
  {
    "text": "that's a tool that attaches to a certain function and gives you a summary of how long that function took to run so it can",
    "start": "3070860",
    "end": "3078120"
  },
  {
    "text": "give you a summary of how long a particular function took over an interval of time and the output as you",
    "start": "3078120",
    "end": "3084960"
  },
  {
    "text": "can see is a beautiful ascii-based histogram all right so it doesn't really",
    "start": "3084960",
    "end": "3091320"
  },
  {
    "text": "look like a histogram because there's only one bar that's very big and all the other bars are kind of not pronounced at",
    "start": "3091320",
    "end": "3099060"
  },
  {
    "text": "all but it is a histogram and it shows you that most of my garbage collections",
    "start": "3099060",
    "end": "3105750"
  },
  {
    "text": "because that's the function I was tracing most of my garbage collections took less than a millisecond like I had",
    "start": "3105750",
    "end": "3112460"
  },
  {
    "text": "1900 garbage collections under a millisecond but I also had 38 garbage",
    "start": "3112460",
    "end": "3117750"
  },
  {
    "text": "collections taking between 8 and 15 milliseconds and that's slightly more",
    "start": "3117750",
    "end": "3123090"
  },
  {
    "text": "concerning and in a real app you might see even longer delays you might see",
    "start": "3123090",
    "end": "3128160"
  },
  {
    "text": "garbage collections taking up to a full second even or even more if you have a large heap that needs to be collected so",
    "start": "3128160",
    "end": "3134990"
  },
  {
    "text": "given that you sort of what I discover figure out where these garbage",
    "start": "3134990",
    "end": "3140310"
  },
  {
    "text": "collections are coming from like what is your JavaScript application doing to",
    "start": "3140310",
    "end": "3145410"
  },
  {
    "text": "trigger so many garbage collections and there's something else you can do I'm gonna skip this little section here",
    "start": "3145410",
    "end": "3151680"
  },
  {
    "text": "there's something else you can do to make to get this kind of data there's a tool called stack count and that one",
    "start": "3151680",
    "end": "3159930"
  },
  {
    "text": "will tell you which paths in your code lead up to a certain function this is",
    "start": "3159930",
    "end": "3166200"
  },
  {
    "text": "very similar if you think about it for a moment this is very similar to what we did at the very beginning we got lots of",
    "start": "3166200",
    "end": "3173310"
  },
  {
    "text": "stack traces telling us what the process was doing in general but this is no",
    "start": "3173310",
    "end": "3178620"
  },
  {
    "text": "longer in general I know there's a specific event there is garbage collections that I care about so tell me",
    "start": "3178620",
    "end": "3184950"
  },
  {
    "text": "the coal stocks leading up to garbage collections not just arbitrary coal stocks but only coal stocks leading up",
    "start": "3184950",
    "end": "3190440"
  },
  {
    "text": "to garbage collections and you could actually visualize them with the flame graph as well if you have lots of stack",
    "start": "3190440",
    "end": "3197130"
  },
  {
    "text": "traces you should immediately think flame graphs as a way to visualize this information I haven't done this actually",
    "start": "3197130",
    "end": "3203070"
  },
  {
    "text": "for this example so it's just text it's a stack as you can see and then a number",
    "start": "3203070",
    "end": "3209760"
  },
  {
    "text": "that says how often how frequently we actually saw this stack so this stack here",
    "start": "3209760",
    "end": "3215270"
  },
  {
    "text": "appeared 111 times that's what it means and if you look at the stack itself it",
    "start": "3215270",
    "end": "3221550"
  },
  {
    "text": "has a mix as usual of v8 code and JavaScript code from our application the",
    "start": "3221550",
    "end": "3227790"
  },
  {
    "text": "highlighted sections specifically as you can see point to users je s line 7 which",
    "start": "3227790",
    "end": "3235500"
  },
  {
    "text": "allocates lots of memory by slicing a string and slicing a string it it seems",
    "start": "3235500",
    "end": "3244050"
  },
  {
    "text": "would go into the v8 runtime try to allocate space figure out where out of space and then do a garbage collection",
    "start": "3244050",
    "end": "3251250"
  },
  {
    "text": "and that happened 111 times so again by looking at the most frequent call stacks",
    "start": "3251250",
    "end": "3257670"
  },
  {
    "text": "leading up to garbage collections you can often figure out what your application is doing what is its",
    "start": "3257670",
    "end": "3263010"
  },
  {
    "text": "allocating that would cause the garbage collection to take longer to happen",
    "start": "3263010",
    "end": "3268230"
  },
  {
    "text": "frequently and I mean eventually all garbage collections are caused by allocations you allocate memory and at",
    "start": "3268230",
    "end": "3275130"
  },
  {
    "text": "some point the garbage collector kicks in so this is a good way of figuring out which allocations often caused the",
    "start": "3275130",
    "end": "3281490"
  },
  {
    "text": "garbage collector to kick in and again what you do with this information you probably want to try get rid of some of",
    "start": "3281490",
    "end": "3288810"
  },
  {
    "text": "these got some of these allocations maybe reuse some of these objects that's sort of the general strategies you'd use",
    "start": "3288810",
    "end": "3295350"
  },
  {
    "text": "we don't have time to explore this specific piece of code but slicing strings is is naturally an operation",
    "start": "3295350",
    "end": "3302670"
  },
  {
    "text": "that produces a lot of garbage you have the old string and then you produce a new string out of it and that's a whole new allocation that has to happen I want",
    "start": "3302670",
    "end": "3311760"
  },
  {
    "text": "to show you just one more scenario I have two but we only have time for once I'm gonna show you the they're more",
    "start": "3311760",
    "end": "3317260"
  },
  {
    "text": "useful one I think and that's a demo which focuses on your apps interaction",
    "start": "3317260",
    "end": "3323470"
  },
  {
    "text": "with the operating system so there's some kind of weird error that you're",
    "start": "3323470",
    "end": "3328480"
  },
  {
    "text": "getting and you suspect it's not coming from within your actual JavaScript code",
    "start": "3328480",
    "end": "3333490"
  },
  {
    "text": "it's coming from interactions with the operating system and we're gonna use a couple of tools here but I actually want",
    "start": "3333490",
    "end": "3339280"
  },
  {
    "text": "to spice it up just a tiny bit and use an extra tool for this semi switch to my",
    "start": "3339280",
    "end": "3345220"
  },
  {
    "text": "terminal here for a moment just do this",
    "start": "3345220",
    "end": "3351850"
  },
  {
    "text": "yeah it's supposed to kill the nose process first that's interesting for",
    "start": "3351850",
    "end": "3363270"
  },
  {
    "text": "2000 years all the years even though I've killed my what else could be using port 3 so well I don't want to waste a",
    "start": "3365310",
    "end": "3371500"
  },
  {
    "text": "lot of our time so I'm just going to go through the slides anyway but yeah what I wanted to add is just one other tool",
    "start": "3371500",
    "end": "3377500"
  },
  {
    "text": "which I can actually run regardless and that's a tool called sis count which I",
    "start": "3377500",
    "end": "3387520"
  },
  {
    "text": "want to show you even though the app is not actually running so sis count is a",
    "start": "3387520",
    "end": "3393850"
  },
  {
    "text": "tool that sits there and looks at all the system calls a particular process or",
    "start": "3393850",
    "end": "3399640"
  },
  {
    "text": "the whole system is making and system calls as you know are just arbitrary",
    "start": "3399640",
    "end": "3405370"
  },
  {
    "text": "interactions with the OS so it includes reading and writing files creating processes sending data over a socket",
    "start": "3405370",
    "end": "3412720"
  },
  {
    "text": "receiving data over socket scheduling switches between threads and processes waiting for something a bunch of",
    "start": "3412720",
    "end": "3419170"
  },
  {
    "text": "different things so sis count is a BPF based tool which traces system calls and",
    "start": "3419170",
    "end": "3425440"
  },
  {
    "text": "prints out a summary of the most frequent system calls getting invoked",
    "start": "3425440",
    "end": "3431590"
  },
  {
    "text": "and that summary can be made available on a per process basis or just a",
    "start": "3431590",
    "end": "3436900"
  },
  {
    "text": "system-wide basis and if you look here it would seem that while the system is",
    "start": "3436900",
    "end": "3441940"
  },
  {
    "text": "completely idle the closed syscall is one that's getting invoked most frequently so 33,000 times during my",
    "start": "3441940",
    "end": "3449470"
  },
  {
    "text": "recording interval reason I'm showing you this is that sis count is a very useful way of sort of characterizing",
    "start": "3449470",
    "end": "3456819"
  },
  {
    "text": "your workload characterizing what your system is doing as a whole so you might have a million lines of JavaScript",
    "start": "3456819",
    "end": "3463750"
  },
  {
    "text": "inside but looking at the interactions with the outside world can often give you a good idea of what the system is",
    "start": "3463750",
    "end": "3469059"
  },
  {
    "text": "doing is it doing lots of Network IO is it doing lots of filesystem accesses is",
    "start": "3469059",
    "end": "3474309"
  },
  {
    "text": "it just sleeping a lot is it for king additional processors gives you a",
    "start": "3474309",
    "end": "3479770"
  },
  {
    "text": "general picture of what's happening on the system in our specific example which",
    "start": "3479770",
    "end": "3484869"
  },
  {
    "text": "is illustrated here on the slides I just hit a certain end point and again this beautiful HTML back that says an error",
    "start": "3484869",
    "end": "3492430"
  },
  {
    "text": "occurred or maybe it's more specifically an error occurred while opening a file",
    "start": "3492430",
    "end": "3498390"
  },
  {
    "text": "and that's kind of what you have to work with so again workload characterization like",
    "start": "3498390",
    "end": "3504520"
  },
  {
    "text": "this with sis count can give you an idea of what the process is doing like what again which system calls are getting",
    "start": "3504520",
    "end": "3510520"
  },
  {
    "text": "invoked and possibly linked to an error specifically once you know it's it's a",
    "start": "3510520",
    "end": "3516160"
  },
  {
    "text": "file problem you're trying to open a file and fail in there is a tool called open snoop that you can use and that's a",
    "start": "3516160",
    "end": "3523150"
  },
  {
    "text": "tool designed for file operations it will print out a message when you try to",
    "start": "3523150",
    "end": "3528339"
  },
  {
    "text": "open a file and optionally it has a filter only for failures so only print",
    "start": "3528339",
    "end": "3533380"
  },
  {
    "text": "mess a message when I try to open a file and fail and it tells you which file I'm",
    "start": "3533380",
    "end": "3538839"
  },
  {
    "text": "trying to open so here it is and the error I'm getting and error 2 and Linux",
    "start": "3538839",
    "end": "3544180"
  },
  {
    "text": "is file not found so it looks like this file just doesn't exist but I mean it could be something else maybe the file",
    "start": "3544180",
    "end": "3550059"
  },
  {
    "text": "is already open maybe the file I don't have permissions to read it or it's some",
    "start": "3550059",
    "end": "3555400"
  },
  {
    "text": "other thing like that so open snoop can filter out your file opens for you and",
    "start": "3555400",
    "end": "3562510"
  },
  {
    "text": "print out failures so I only have 30 seconds left so I'm going to skip over my last example here but just to give",
    "start": "3562510",
    "end": "3569559"
  },
  {
    "text": "you a very very general idea of what it was eventually we get to a point where we could take a running data",
    "start": "3569559",
    "end": "3576490"
  },
  {
    "text": "his engine and printout all the queries as they get executed so we take my sequel or Postgres or you could",
    "start": "3576490",
    "end": "3583360"
  },
  {
    "text": "potentially adjust it to other database engines as well and we just in production print out all the queries",
    "start": "3583360",
    "end": "3589390"
  },
  {
    "text": "executed by that database so that again is not exactly no js' specific but it's",
    "start": "3589390",
    "end": "3594670"
  },
  {
    "text": "obviously very very useful I assume a lot of you have some kind of database that you're using alongside with your",
    "start": "3594670",
    "end": "3601030"
  },
  {
    "text": "node app so if you're interested in that just take a look at the slides so just jumping to the summary I wanted to show",
    "start": "3601030",
    "end": "3607720"
  },
  {
    "text": "you a couple of different approaches for profiling now apps in production we started with the v8 profiler which is",
    "start": "3607720",
    "end": "3614320"
  },
  {
    "text": "kind of built-in and nice and cozy but it's very very limited and you need to",
    "start": "3614320",
    "end": "3619990"
  },
  {
    "text": "launch your node process with the profiler attached in the first place so that's a little limiting then we talked",
    "start": "3619990",
    "end": "3625360"
  },
  {
    "text": "about perf and what perf can do in terms of recording CPU information CPU usage and then we switched over to the BCC and",
    "start": "3625360",
    "end": "3632710"
  },
  {
    "text": "vpf tools and there's a variety of tools there I only try to illustrate a couple of those tailor it for difference in",
    "start": "3632710",
    "end": "3639580"
  },
  {
    "text": "areas that people hate often with node applications I also have up online I'll",
    "start": "3639580",
    "end": "3644710"
  },
  {
    "text": "show you the link in a moment I have a bunch of additional examples that you might want to look at including some networking issues like a node app making",
    "start": "3644710",
    "end": "3651850"
  },
  {
    "text": "slow Network requests DNS resolution issues database issues so there's a",
    "start": "3651850",
    "end": "3656950"
  },
  {
    "text": "bunch of different things these tools can be used to investigate so I have",
    "start": "3656950",
    "end": "3662170"
  },
  {
    "text": "some references over here but this is the important slide so it has the link to the slides themselves and that other",
    "start": "3662170",
    "end": "3667900"
  },
  {
    "text": "link over there the Linux tracing workshop that's a github repo that has a bunch of examples it has all of my demo",
    "start": "3667900",
    "end": "3674500"
  },
  {
    "text": "code but it also has lab instructions that you can follow to learn more about",
    "start": "3674500",
    "end": "3679600"
  },
  {
    "text": "these tools so it's basically a self-contained learning repository that you can use to experiment with the v8",
    "start": "3679600",
    "end": "3685240"
  },
  {
    "text": "profiler with perf with the BCC tools with everything I've been talking about",
    "start": "3685240",
    "end": "3690310"
  },
  {
    "text": "in the last hour so if you find it useful please let me know if you have any questions we don't have time right",
    "start": "3690310",
    "end": "3696070"
  },
  {
    "text": "now but I'll be staying here in the room or outside so please feel free to come and talk to me I hope you enjoyed the",
    "start": "3696070",
    "end": "3702640"
  },
  {
    "text": "rest of n DC and see you at the party thank you very very much [Applause]",
    "start": "3702640",
    "end": "3709420"
  }
]